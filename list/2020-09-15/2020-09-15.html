<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-09-15の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: ICASSP 2021 Acoustic Echo Cancellation Challenge: Datasets and Testing
  Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.SD/paper_0.html">
      <font color="black">ICASSP 2021 Acoustic Echo Cancellation Challenge: Datasets and Testing
  Framework</font>
    </a>
  </h2>
  <font color="black">ITU-T P.808に基づくオンライン主観テストフレームワークをオープンソースで使用して、研究者が結果をすばやくテストできるようにしています。これらのデータセットは、実際の環境での2,500以上のリアルオーディオデバイスと人間のスピーカーからの録音、および合成データセットで構成されています。 ..しかし、実際の録音では、AECパフォーマンスが大幅に低下することがよくあります。 
[ABSTRACT]最近の多くのaec調査では、合成データセットで妥当なパフォーマンスが報告されています。ただし、従来の客観的な指標のほとんどは、主観的な音声品質テストと十分に相関していません。環境</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Toward the pre-cocktail party problem with TasTas$+$ -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.SD/paper_1.html">
      <font color="black">Toward the pre-cocktail party problem with TasTas$+$</font>
    </a>
  </h2>
  <font color="black">デュアルパス双方向長期短期メモリ（BiLSTM）ブロックを備えたディープニューラルネットワークは、シーケンスモデリング、特に音声分離などで非常に効果的であることが証明されています。新しいアプローチはTasTas $ + $と呼ばれ、5人の話者の混合発話を5つの分離された発話にマッピングし、各発話には1人の発話者の声のみが含まれます。DPRNN-TasNet\ cite {luo2019dual}、TasTas \ cite {shi2020speech }。 
[ABSTRACT]新しいパスはtastas $ memoryと呼ばれ、5つの話者の混合発話が検出されます。tastasdata datanetと呼ばれる新しいアプローチは、パブリックwsj0-5mixデータコーパスからのデータに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Joint Generative Learning and Super-Resolution For Real-World
  Camera-Screen Degradation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/eess.IV/paper_0.html">
      <font color="black">Joint Generative Learning and Super-Resolution For Real-World
  Camera-Screen Degradation</font>
    </a>
  </h2>
  <font color="black">SISRモデルの一般化を改善するために、より実際の劣化を含むことがポジティブであることを実証するために広範な実験を行います。さらに、共同の2段階モデルを提案します。まず、ダウンサンプリング劣化GAN（DD-GAN）は、劣化し、より多様なLRイメージが生成されます。これは、データ拡張に効率的であることが検証されています。 
[ABSTRACT]バイキュービック補間（bi）などの合成低解像度生成は、一般に合成低解像度生成で研究されています。ただし、表示デバイスには、より複雑な劣化も含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-01">
        <br><font color="black">2020-08-01</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient multi-class fetal brain segmentation in high resolution MRI
  reconstructions with noisy labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/eess.IV/paper_1.html">
      <font color="black">Efficient multi-class fetal brain segmentation in high resolution MRI
  reconstructions with noisy labels</font>
    </a>
  </h2>
  <font color="black">したがって、ノイズのあるマルチクラスラベルを使用した転移学習を使用して、1つの再構成法で作成され、他の再構成法で一般化可能性がテストされた1組のセグメンテーションを使用して、高解像度の胎児脳MRIを自動的にセグメント化することを提案します。使用される再構成法とは関係なく、胎児の脳の定量分析に必要な手動のセグメンテーションの必要性を排除する可能性。正常および病理学的な神経発達を定量化する公平な方法を提供します。 
[要約]ネットワークは自動的に-胎児の脳再建を7つの異なる組織タイプに自動的にセグメント化</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Super Resolution of Arterial Spin Labeling MR Imaging Using Unsupervised
  Multi-Scale Generative Adversarial Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/eess.IV/paper_2.html">
      <font color="black">Super Resolution of Arterial Spin Labeling MR Imaging Using Unsupervised
  Multi-Scale Generative Adversarial Network</font>
    </a>
  </h2>
  <font color="black">ネットワークがトレーニングされた後、アップサンプリングされたLR ASL画像と対応するT1加重画像を最後のレイヤーのジェネレーターに提供することにより、超解像（SR）画像が生成されました。トレーニングペアや事前トレーニングは必要ありません。提案された方法は、最も近い、線形、およびスプライン補間法に、より詳細な構造情報を復元し、視覚的に画像ノイズを低減し、HR ASL画像をグラウンドトゥルースとして使用した場合に最高のPSNRおよびSSIMを実現します。 
[ABSTRACT]従来のaslは、信号対雑音比（snr）が低く、空間分解能が低く、取得時間が長い</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: SNR-enhanced diffusion MRI with structure-preserving low-rank denoising
  in reproducing kernel Hilbert spaces -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/eess.IV/paper_3.html">
      <font color="black">SNR-enhanced diffusion MRI with structure-preserving low-rank denoising
  in reproducing kernel Hilbert spaces</font>
    </a>
  </h2>
  <font color="black">方法：カーネル主成分分析（KPCA）、カーネルヒルベルト空間を再現するPCAの非線形一般化によって、dMRIデータの非線形冗長性を活用します。残差の統計分析は、ノイズのみが削除されていることを示しています。高次元空間への信号では、データの非線形性にもかかわらず、より優れた冗長性が実現され、線形PCAよりも優れたノイズ除去が可能になります。 
[要旨] kpcaは、pcatoよりもカーネルグリントスペースを再現するpcatoの非線形一般化です。dmcaデータの冗長性を使用するのは、pcaよりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Modeling adult skeletal stem cell response to laser-machined
  topographies through deep learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/eess.IV/paper_4.html">
      <font color="black">Modeling adult skeletal stem cell response to laser-machined
  topographies through deep learning</font>
    </a>
  </h2>
  <font color="black">モデルとしてディープニューラルネットワークを適用すると、細胞の挙動の理解を深めるために必要な実験的な細胞培養の量が地形的手がかりに減少し、重要なことに、組織の作製と細胞に対する新しい表面構造の影響を迅速に予測できますシグナル伝達..フェムト秒レーザー加工によって生成された表面トポグラフィーに対する成人の骨髄間質幹細胞の応答は、ディープニューラルネットワークによって予測できます。このネットワークは、細胞応答を統計的に有意なレベルに予測できます。確率P &lt;0.001であり、したがって、細胞構造に必要な最小線分離を決定するモデルとして使用でき、組織構造の発達と組織工学に影響を与えます。 
[ABSTRACT]ネットワークは、細胞の反応を統計的に有意なレベルまで予測できます。これは、最小ライン分離を決定するためのモデルとして使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-30">
        <br><font color="black">2020-05-30</font>
      </time>
    </span>
</section>
<!-- paper0: L2-Constrained RemNet for Camera Model Identification and Image
  Manipulation Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/eess.IV/paper_5.html">
      <font color="black">L2-Constrained RemNet for Camera Model Identification and Image
  Manipulation Detection</font>
    </a>
  </h2>
  <font color="black">L2損失とカテゴリカルクロスエントロピー損失の組み合わせである総損失を最小化することにより、ネットワーク全体がエンドツーエンドでトレーニングされます。ドレスデンデータベースでネットワークをトレーニングおよびテストし、全体的な精度を達成します98.15％。すべてのテスト画像は、実際のアプリケーションを複製するためのトレーニング中に使用されないデバイスとシーンからのものです。提案されているネットワークアーキテクチャは、動的プリプロセッサブロックと分類ブロックで構成されています。 
[ABSTRACT]データ適応型プリプロセッサは、不要な画像コンテンツを抑制できます。ネットワークは、画像が操作された場合でも、他の最新技術よりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Far-field intensity signature of sub-wavelength microscopic objects -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/eess.IV/paper_6.html">
      <font color="black">Far-field intensity signature of sub-wavelength microscopic objects</font>
    </a>
  </h2>
  <font color="black">スパース性に関係のないフーリエドメインのl1ノルムベースの最適化は、l2ベースの対応物よりもノイズに対してロバストであることを示します。この超解像への新しいパスは、圧縮センシングと機械学習を使用して最近調査されました。スパースデータで動作するフーリエ変換ベースの反復アルゴリズム用の非常に高速な汎用制限付きドメイン計算方法を紹介します。 
[ABSTRACT]このシステムは、デコンボリューションと遺伝的駐車場に基づいています。これらには、非常に高速な一般目的の制限付きドメイン化手法が含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Key Points Estimation and Point Instance Segmentation Approach for Lane
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/eess.IV/paper_7.html">
      <font color="black">Key Points Estimation and Point Instance Segmentation Approach for Lane
  Detection</font>
    </a>
  </h2>
  <font color="black">したがって、トレーニングされたモデルのサイズは、ターゲット環境の計算能力に従って選択できます。予測されたキーポイントのクラスタリング問題をインスタンスセグメンテーション問題としてキャストします。 PINetは、動線の数に関係なくトレーニングできます。自動運転の知覚技術は、さまざまな環境に適応する必要があります。 
[要約]ピネットには、同時に訓練されるいくつかの砂時計ネットワークが含まれています。動線の数に関係なく訓練できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-16">
        <br><font color="black">2020-02-16</font>
      </time>
    </span>
</section>
<!-- paper0: SpinalNet: Deep Neural Network with Gradual Input -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/eess.IV/paper_8.html">
      <font color="black">SpinalNet: Deep Neural Network with Gradual Input</font>
    </a>
  </h2>
  <font color="black">提案されたSpinalNetでは、隠れ層の構造は3つのセクターに割り当てられます。1）入力行、2）中間行、3）出力行です。SpinalNetの中間行にはいくつかのニューロンが含まれています。また、SpinalNetを完全に調査します-いくつかの有名なDNNモデルにレイヤーを接続し、従来の学習と転移学習を実行します。 
[ABSTRACT]典型的なニューラルネットワーク（nn）アーキテクチャでは、非表示層は最初の層でニューロンを受信します。次に、中間結果を次の層に転送します。非表示セグメントの入力ウェイトの数は、従来のdnnsよりも大幅に低くなります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Attention based Writer Independent Handwriting Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/eess.IV/paper_9.html">
      <font color="black">Attention based Writer Independent Handwriting Verification</font>
    </a>
  </h2>
  <font color="black">アテンションメカニズムにより、ネットワークは入力の関連領域にさらに焦点を当てることができるため、分類パフォーマンスが向上します。提案されたアプローチでは、CEDAR筆記体「AND」データセットのライター内ケースを検出するために86 \％の精度を実現します。アテンションマップは、ネットワークの出力尤度スコアの説明の前提となります。 
[ABSTRACT]クロスアテンションネットワークとソフトアテンションネットワークを実装して統合し、2D入力の特徴空間で相関性の高い顕著なポイントをキャプチャします。アテンションメカニズムにより、ネットワークは入力の関連領域により焦点を当てることができるため、分類性能</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: VC-Net: Deep Volume-Composition Networks for Segmentation and
  Visualization of Highly Sparse and Noisy Image Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/eess.IV/paper_10.html">
      <font color="black">VC-Net: Deep Volume-Composition Networks for Segmentation and
  Visualization of Highly Sparse and Noisy Image Data</font>
    </a>
  </h2>
  <font color="black">MIP埋め込み機能は、局所血管信号を強化し、微小血管追跡で重要な血管の幾何学的変動性とスケーラビリティに適応できます。提案されたフレームワークは、小型/微小血管をよりよくキャプチャし、血管接続を改善できます。これは、共同の畳み込み埋め込み空間を構築する最初のディープラーニングフレームワークであり、ボリュームレンダリングベースの2D投影と3Dボリュームから計算された血管確率を探索し、相乗的に統合できます。 
[要約]主な目新しさは、高忠実度の3D血管構造を自動的に抽出して視覚化することです。これは、ディープラーニングツールを構築する最初のディープラーニングフレームワークです。システムが3Dデータ探索を強化することが望まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Joint Generative Learning and Super-Resolution For Real-World
  Camera-Screen Degradation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_0.html">
      <font color="black">Joint Generative Learning and Super-Resolution For Real-World
  Camera-Screen Degradation</font>
    </a>
  </h2>
  <font color="black">さらに、私たちは共同の2段階モデルを提案します。典型的な合成と複雑な実世界の両方での広範な実験結果により、提案されたメソッドは、パラメータが少なく、速度が速く、視覚的な結果が優れている既存のSOTAモデルよりも優れています。 L1損失と提案されたラプラシアン損失は、高周波エッジをシャープにするために適用されます。 
[ABSTRACT]バイキュービック補間（bi）などの合成低解像度生成は、一般に合成低解像度生成で研究されています。ただし、表示デバイスには、より複雑な劣化も含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-01">
        <br><font color="black">2020-08-01</font>
      </time>
    </span>
</section>
<!-- paper0: 4Seasons: A Cross-Season Dataset for Multi-Weather SLAM in Autonomous
  Driving -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_1.html">
      <font color="black">4Seasons: A Cross-Season Dataset for Multi-Weather SLAM in Autonomous
  Driving</font>
    </a>
  </h2>
  <font color="black">直接ステレオ視覚慣性オドメトリとRTK-GNSSの融合から得られた最大1センチメートルの精度でグローバルに一貫した参照ポーズを提供します。完全なデータセットはwww.4seasons-dataset.com。で入手できます。自動運転のための季節的で挑戦的な知覚条件。 
[要約] 350 kmを超える記録が9つの異なる環境で記録されました。これらには、視覚オドメトリ、世界的な場所認識、マップベースの再ローカリゼーション追跡の広範な使用が含まれていました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Adaptive Convolution Kernel for Artificial Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_2.html">
      <font color="black">Adaptive Convolution Kernel for Artificial Neural Networks</font>
    </a>
  </h2>
  <font color="black">MNIST、MNIST-CLUTTERED、CIFAR-10、Fashion、および「Faces in the Wild」などの一般的な画像分類データセットの結果は、適応カーネルが通常の畳み込みカーネルに対して統計的に有意な改善を提供できることを示しています。セグメンテーション実験Oxford-Petsデータセットでは、U字型ネットワークの単一の通常の畳み込み層を単一の7 $ \ times $ 7アダプティブレイヤーに置き換えると、学習パフォーマンスと一般化能力が向上することを示しました。多くのディープニューラルネットワークは、スタックを使用して構築されています固定および単一サイズ（多くの場合3 $ \ times $ 3）カーネルのたたみ込み層。 
[要約]私たちの実験では、提案されたアダプティブレイヤーを通常の畳み込みレイヤーと比較しました。これらには、単純な2レイヤーネットワーク、より深い残余ネットワーク、およびauアーキテクチャが含まれていました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: OrthographicNet: A Deep Transfer Learning Approach for 3D Object
  Recognition in Open-Ended Domains -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_3.html">
      <font color="black">OrthographicNet: A Deep Transfer Learning Approach for 3D Object
  Recognition in Open-Ended Domains</font>
    </a>
  </h2>
  <font color="black">特に、OrthographicNetは、特定のオブジェクトに対して回転およびスケール不変のグローバル機能を生成し、異なる視点から見た同じまたは類似のオブジェクトを認識できるようにします。サービスロボットは、より自律的で、人間中心の環境で効率的に動作することが期待されています。このタイプのロボット、オープンエンドのオブジェクト認識は、2つの必須機能に対する高い需要があるため、困難なタスクです。（i）正確でリアルタイムの応答、および（ii）非常に少数の例から新しいオブジェクトカテゴリを学習する機能現場で。 
[ABSTRACT]オープン-終了したオブジェクトの認識は、人間にとって難しい課題です。これは、2つの必須環境に対する需要が高いためです。これには、非常に少数の例から新しいオブジェクトカテゴリを学習する機能が含まれます。これは人間が初めて見た可能性がありますオープン-終了したオブジェクト</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-02-08">
        <br><font color="black">2019-02-08</font>
      </time>
    </span>
</section>
<!-- paper0: Accurate and Lightweight Image Super-Resolution with Model-Guided Deep
  Unfolding Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_4.html">
      <font color="black">Accurate and Lightweight Image Super-Resolution with Model-Guided Deep
  Unfolding Network</font>
    </a>
  </h2>
  <font color="black">深いノイズ除去と非ローカル正則化をディープラーニングフレームワーク内のトレーニング可能なモジュールとして統合することで、モデルベースのSISRの反復プロセスを、3つの相互接続されたモジュール（ノイズ除去、非ローカルAR、および再構築）を含むビルディングブロックの多段階連結に展開できます..コヒーレンスの壁を打破することを目標として、私たちは確立されたイメージの以前の名前付き非ローカル自動回帰モデルで作業し、それを使用してDNN設計をガイドすることを選択します。説明可能性に加えて、MoG-DUNは正確です（エイリアシングの生成が少ない）アーティファクト）、計算効率（モデルパラメーターを削減）、多用途（複数の劣化を処理できます）。 
[要約]このペーパーでは、sisr名前付きモデル-ガイド付きディープアンフォールディングネットワーク（mog-dun）への説明可能なアプローチを提示し、提唱します。これらには、ディープラーニングフレームワークでトレーニング可能なモジュールとしてディープノイズ除去と非ローカル正則化を使用することが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: AIM 2020 Challenge on Video Extreme Super-Resolution: Methods and
  Results -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_5.html">
      <font color="black">AIM 2020 Challenge on Video Extreme Super-Resolution: Methods and
  Results</font>
    </a>
  </h2>
  <font color="black">トラック1は、このような厳しいタスクの最先端技術を評価するように設定されており、グラウンドトゥルースへの忠実度はPSNRとSSIMによって測定されます。したがって、トラック2は、視覚的に満足のいく結果を生成することを目的としています。ユーザー調査によって評価された人間の知覚。低解像度（LR）ドメインの単一ピクセルは、高解像度（HR）ドメインの256ピクセルに対応します。 
[要約]この課題のタスクは、極端な因数16でビデオを拡大することです。これにより、ビデオの構造の完全性にも影響する、より深刻な劣化が発生します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Measuring Robustness to Natural Distribution Shifts in Image
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_6.html">
      <font color="black">Measuring Robustness to Natural Distribution Shifts in Image
  Classification</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、実際のデータで発生する分布シフトが現在未解決の研究問題であることを示しています。主な例外は、より大きく多様なデータセットでのトレーニングです。これにより、複数のケースで堅牢性が向上しますが、パフォーマンスのギャップを埋めることはできません。最新の手法では、テストベッドでの自然な分布の変化にロバスト性がありません。 
[ABSTRACT]ロバスト性に関するほとんどの研究は、合成データの摂動に焦点を合わせています。主な例外は、より大規模で多様なデータセットのトレーニングです。将来の作業のためのリソースとしてテストベッドとデータを提供しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-01">
        <br><font color="black">2020-07-01</font>
      </time>
    </span>
</section>
<!-- paper0: REXUP: I REason, I EXtract, I UPdate with Structured Compositional
  Reasoning for Visual Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_7.html">
      <font color="black">REXUP: I REason, I EXtract, I UPdate with Structured Compositional
  Reasoning for Visual Question Answering</font>
    </a>
  </h2>
  <font color="black">REXUPネットワークは、画像オブジェクト指向とシーングラフ指向の2つのブランチで構成され、超対角型フュージョン構成的注意ネットワークと共同で機能します。GQAデータセットでREXUPを定量的および定性的に評価し、REXUPの背後にある理由を調査するために広範なアブレーション研究を実施します。有効性..最高のモデルは、検証セットで92.7％、test-devセットで73.1％を実現する貴重な最先端技術を大幅に上回っています。 
[ABSTRACT]当社の最良のモデルは、最先端の貴重な性能を大幅に上回っており、検証セットで92. 7％、テストで73. 1％遅れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Cascade Network for Self-Supervised Monocular Depth Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_8.html">
      <font color="black">Cascade Network for Self-Supervised Monocular Depth Estimation</font>
    </a>
  </h2>
  <font color="black">この論文では、カスケードネットワークに基づく新しい自己監視学習方法を提案します。ターゲットシーンを異なる視距離の部分に分割し、それらを個別にトレーニングして、より良い深度マップを生成するカスケードニューラルネットワークを示します。この問題では、一部の研究者は自主学習モデルを使用してこの問題を克服し、手動でラベル付けされたデータへの依存を減らしています。 
[要約]以前の方法に加えて、この方法では精度と信頼性が向上し、実験によりこれを証明しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: GINet: Graph Interaction Network for Scene Parsing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_9.html">
      <font color="black">GINet: Graph Interaction Network for Scene Parsing</font>
    </a>
  </h2>
  <font color="black">SC損失によりGIユニットがさらに改善され、見本ベースのセマンティックグラフよりもセマンティック表現が強化されています。最近、ローカル畳み込みを超えた画像領域を使用したコンテキスト推論により、シーン解析の大きな可能性が示されました。 Pascal-ContextやCOCO Stuffなどの人気のベンチマークに関する最先端のアプローチ。 
[ABSTRACT]データセット-ベースの言語知識が最初にgiユニットに組み込まれ、ビジュアルグラフに対するコンテキスト推論を促進します。次に、ビジュアルネットワークの進化した表現が各ローカル表現にマッピングされ、シーン解析の識別機能が強化されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Deep intrinsic decomposition trained on surreal scenes yet with
  realistic light effects -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_10.html">
      <font color="black">Deep intrinsic decomposition trained on surreal scenes yet with
  realistic light effects</font>
    </a>
  </h2>
  <font color="black">内在する画像の推定は、小さすぎるか、非現実的な問題を提示するグラウンドトゥルースデータセットの弱点のため、依然として困難な作業です。この作業では、2つのフレームワークを提示します。（a）克服する画像の柔軟な生成サイズが大きくなるなどの古典的なデータセットの問題とコヒーレントな照明の外観（b）固有の損失を介して物理的特性を結び付ける柔軟なアーキテクチャー。私たちの提案は用途が広く、計算時間が短く、最先端の結果を実現します。 
[ABSTRACT]ディープラーニングアーキテクチャは興味深い結果を出し始めます。いくつかの主要な物理的なヒントが無視されなかった場合、これは改善される可能性があります。これは技術的な問題が原因です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: A Multisensory Learning Architecture for Rotation-invariant Object
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_11.html">
      <font color="black">A Multisensory Learning Architecture for Rotation-invariant Object
  Recognition</font>
    </a>
  </h2>
  <font color="black">結果は、単一のモダリティと決定レベルのマルチモーダルフュージョンメソッドからの入力を使用するモデルと比較して、私たちのアーキテクチャが認識精度を向上させることを示しています。オブジェクトを認識するためにそれらを使用します。さまざまなセンサーの入力と最新のデータフュージョン技術、つまり意思決定レベルフュージョンで個別にトレーニングされたモデルで得られた結果をベンチマークすることにより、提案されたアーキテクチャのパフォーマンスを評価します。 
[要約]提案されたアーキテクチャは、畳み込みニューラルネットワークを組み合わせて、グレースケールのカラー画像の表現と、深度データを処理する多層パーセプトロンアルゴリズムを形成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: IntroVAC: Introspective Variational Classifiers for Learning
  Interpretable Latent Subspaces -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_12.html">
      <font color="black">IntroVAC: Introspective Variational Classifiers for Learning
  Interpretable Latent Subspaces</font>
    </a>
  </h2>
  <font color="black">ディープニューラルネットワークの普及に伴い、変分オートエンコーダは、画像の生成と低次元の部分空間でのエンコードの両方が可能なエンコーダ/デコーダアーキテクチャに基づくデータ分布の明示的なモデルを提供するため、多くの注目を集めています。複雑なデータの有用な表現を学習することは、長年にわたって広範囲にわたる研究の主題でした。私たちは、CelebAデータセットに対するアプローチを検証します。 
[ABSTRACT]内省的変分分類器（introvac）は、追加のラベルからの情報を利用して、解釈可能な潜在的慰めを学習するモデルです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-03">
        <br><font color="black">2020-08-03</font>
      </time>
    </span>
</section>
<!-- paper0: Project RISE: Recognizing Industrial Smoke Emissions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_13.html">
      <font color="black">Project RISE: Recognizing Industrial Smoke Emissions</font>
    </a>
  </h2>
  <font color="black">これらの日中のクリップは、4シーズンすべてを含む2年間で30日間に及びます。私たちは、市民科学のアプローチを採用して、地域社会のメンバーと協力し、ビデオクリップに煙が出るかどうかを注釈します。以前の研究では、コンピュータビジョン（CV）煙を視覚的証拠として特定する手法は、規制当局の態度に影響を与え、市民に環境正義を追求する力を与えることができます。 
[ABSTRACT]産業用煙の排出を認識する最初の大規模なビデオ品質のビデオデータセットを紹介します。このデータセットには、3つの産業施設を監視したカメラからの19の異なるビューからの12、567のクリップが含まれています。パフォーマンスベースラインと煙認識の課題を明らかにする</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br><font color="black">2020-05-13</font>
      </time>
    </span>
</section>
<!-- paper0: Lunar Crater Identification in Digital Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_14.html">
      <font color="black">Lunar Crater Identification in Digital Images</font>
    </a>
  </h2>
  <font color="black">これらの手法は、合成画像と実際の画像の両方で示されています。これらの記述子は、既知のクレーターパターンに対して事前に計算され、高速認識のために検索可能なインデックスに配置される場合があります。透視投影によって形成された画像の楕円形のクレーターの縁のパターン。 
[ABSTRACT]クレーターベースの地形相対ナビゲーションと科学的画像の自動登録の両方で、「失われた空間」のクレーター識別問題が一般的です。クレーターリム観測からポーズを計算するため、およびクレーターリム対応を評価するための新しい手法も開発されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: A Class of Linear Programs Solvable by Coordinate-Wise Minimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_15.html">
      <font color="black">A Class of Linear Programs Solvable by Coordinate-Wise Minimization</font>
    </a>
  </h2>
  <font color="black">提示されたLP緩和は、より効率的な方法（max-flowなど）で解決できますが、結果は理論的には重要であり、将来的に新しい大規模最適化アルゴリズムにつながる可能性があります。このクラスにはもはや存在しないメソッドは、適度に優れた準最適値を生成します。座標ごとの最小化が正確に解く線形プログラムのクラスを提示します。 
[ABSTRACT]いくつかのよく知られている線形問題の二重lp緩和はこのクラスにあります。このメソッドは、妥当な実行時間で十分な精度のグローバル最小値を見つけます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-28">
        <br><font color="black">2020-01-28</font>
      </time>
    </span>
</section>
<!-- paper0: Key Points Estimation and Point Instance Segmentation Approach for Lane
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_16.html">
      <font color="black">Key Points Estimation and Point Instance Segmentation Approach for Lane
  Detection</font>
    </a>
  </h2>
  <font color="black">予測されたキーポイントのクラスタリング問題をインスタンスセグメンテーション問題としてキャストします。 PINetは、動線の数に関係なくトレーニングできます。したがって、トレーニングされたモデルのサイズは、ターゲット環境の計算能力に応じて選択できます。自動運転の知覚技術は、さまざまな環境に適応する必要があります。 
[要約]ピネットには、同時に訓練されるいくつかの砂時計ネットワークが含まれています。動線の数に関係なく訓練できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-16">
        <br><font color="black">2020-02-16</font>
      </time>
    </span>
</section>
<!-- paper0: OCR Graph Features for Manipulation Detection in Documents -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_17.html">
      <font color="black">OCR Graph Features for Manipulation Detection in Documents</font>
    </a>
  </h2>
  <font color="black">このドメインのほとんどすべてのアプローチは、データ駆動型の一般化可能なアプローチではなく、慎重に生成された機能と手動で調整されたスコアリングシステムを使用した手続き型アプローチに依存しています。実際のビジネスドキュメントから構築されたデータセットに対するアルゴリズムの偽造検出パフォーマンスを評価します。わずかな偽造欠陥..提案されたモデルは、このタスクで最も密接に関連するドキュメント操作検出モデルよりも劇的に優れています。 
[要約]これは、画像編集ソフトウェアの急増が原因です。これは、文字の境界ボックスを使用したパターン比較の問題が原因です。ocr（光学式文字認識）を使用してグラフ機能を活用するモデルが提案されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: SpinalNet: Deep Neural Network with Gradual Input -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_18.html">
      <font color="black">SpinalNet: Deep Neural Network with Gradual Input</font>
    </a>
  </h2>
  <font color="black">提案されたSpinalNetでは、非表示層の構造は3つのセクターに割り当てられます。1）入力行、2）中間行、3）出力行です。SpinalNetのすべての層が出力行に直接寄与するため、勾配の消失問題は存在しない..過去数年にわたって、ディープニューラルネットワーク（DNN）は、さまざまな実世界のアプリケーションで驚くべき成功を収めてきました。 
[ABSTRACT]典型的なニューラルネットワーク（nn）アーキテクチャでは、非表示層は最初の層でニューロンを受信します。次に、中間結果を次の層に転送します。非表示セグメントの入力ウェイトの数は、従来のdnnsよりも大幅に低くなります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: DeepWriteSYN: On-Line Handwriting Synthesis via Deep Short-Term
  Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_19.html">
      <font color="black">DeepWriteSYN: On-Line Handwriting Synthesis via Deep Short-Term
  Representations</font>
    </a>
  </h2>
  <font color="black">これは、完全に合成された、または指定された手書きサンプルの自然なバリエーションとして、長期的な現実的な手書き生成に向けたモジュールとして非常に役立ちます。私たちの知る限り、これは現実的なオンライン手書きを生成できる最初の合成アプローチです。ディープラーニングによる短期（手書きの署名を含む）。これらの2つのケースは、個別の数字と手書きの署名のそれぞれについて実験的に開発され、どちらのケースでも顕著な結果を達成しています。 
[ABSTRACT] deepwritesynは、リアルな手書きのバリエーションを生成できます。これらの2つのプロパティは、シンセサイザに多くの柔軟性を与えます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: One-bit Supervision for Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_20.html">
      <font color="black">One-bit Supervision for Image Classification</font>
    </a>
  </h2>
  <font color="black">1ビットの監視でモデルをトレーニングするための2つの鍵があります：推定の精度を向上させることと、誤った推定を利用することです。これらの目的のために、負のラベル抑制を既製に組み込む多段階のトレーニングパラダイムを提案します。半教師付き学習アルゴリズム..このペーパーでは、画像分類のシナリオにおける、不完全な注釈からの学習の新しい設定である1ビットの監視を紹介します。 
[ABSTRACT]各サンプルの正確なラベルに基づいてモデルをトレーニングする代わりに、この設定では、モデルが答えから推測が容易かどうかを学習する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Boosting Network Weight Separability via Feed-Backward Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_21.html">
      <font color="black">Boosting Network Weight Separability via Feed-Backward Reconstruction</font>
    </a>
  </h2>
  <font color="black">この目的のために、我々は、行列の半直交性とフロベニウス距離に基づく重み分離可能性の評価基準と、重み行列の列ベクトル間の重み分離可能性を明示的に促進するフィードバック後方再構成損失を提案します。ニューラルネットワーク設計における重み分離性の新しい評価メトリックとブースティング方法。画像分類と顔認識の実験結果は、フィードバック再構成損失の最小化による重み分離性ブースティングが視覚認識パフォーマンスを向上させ、パフォーマンスを一般的に向上させることを示しています。さまざまな視覚認識タスク。 
[要約]フィードの最小化による重量分離性の向上-後方再構成の損失により、視覚認識のパフォーマンスを向上できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-20">
        <br><font color="black">2019-10-20</font>
      </time>
    </span>
</section>
<!-- paper0: Attention based Writer Independent Handwriting Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_22.html">
      <font color="black">Attention based Writer Independent Handwriting Verification</font>
    </a>
  </h2>
  <font color="black">アテンションマップは、ネットワークの出力尤度スコアの説明の前提として機能します。アテンションメカニズムにより、ネットワークは入力の関連領域にさらに焦点を当てることができるため、分類パフォーマンスが向上します。提案されたアプローチは、86 \％の精度を達成します。 CEDAR筆記体「AND」データセットのライター内ケースを検出するため。 
[ABSTRACT]クロスアテンションネットワークとソフトアテンションネットワークを実装して統合し、2D入力の特徴空間で相関性の高い顕著なポイントをキャプチャします。アテンションメカニズムにより、ネットワークは入力の関連領域により焦点を当てることができるため、分類性能</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised learning for vascular heterogeneity assessment of
  glioblastoma based on magnetic resonance imaging: The Hemodynamic Tissue
  Signature -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_23.html">
      <font color="black">Unsupervised learning for vascular heterogeneity assessment of
  glioblastoma based on magnetic resonance imaging: The Hemodynamic Tissue
  Signature</font>
    </a>
  </h2>
  <font color="black">最後に、この論文で考案された方法、テクノロジー、独創的なアイデアは、ONCOhabitatsテクノロジーの工業化を促進する手段と考えられている、医薬品のコンパニオン診断のビジネスモデルに組み込まれた会社であるONCOANALYTICS CDXの基礎に至りました。この論文の結果は、医学情報学、統計と確率、放射線医学と核医学、機械学習とデータマイニングと生物医学工学の分野におけるトップランクのジャーナルと会議を含む10の科学的寄稿で発表されています。HTSは、生息地の概念。 
[要約] htsメソッドは、神経膠芽腫内の4つの生息地を描写します。これらには、血管新生腫瘍（帽子）の生息地が含まれます。これは、強化腫瘍の最も灌流された領域であるためです。血管芽腫の生息地は、最低の灌流プロファイルを持つ病変の残りの浮腫です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: VC-Net: Deep Volume-Composition Networks for Segmentation and
  Visualization of Highly Sparse and Noisy Image Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_24.html">
      <font color="black">VC-Net: Deep Volume-Composition Networks for Segmentation and
  Visualization of Highly Sparse and Noisy Image Data</font>
    </a>
  </h2>
  <font color="black">MIP埋め込み機能は、局所血管信号を強化し、微小血管追跡に重要な血管の幾何学的変動性とスケーラビリティに適応します。私たちの仕事の動機は、直接3Dボリュームを組み合わせる新しい視覚化ガイドコンピューティングパラダイムを提示することです生体内での微細構造の抽出と視覚化などの効果的な3D探索のための処理とボリュームレンダリングの手がかり。提案されたフレームワークは、小型/微小血管をより適切に捕捉し、血管接続を改善できます。 
[要約]主な目新しさは、高忠実度の3D血管構造を自動的に抽出して視覚化することです。これは、ディープラーニングツールを構築する最初のディープラーニングフレームワークです。システムが3Dデータ探索を強化することが望まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Triple Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_25.html">
      <font color="black">Triple Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">特に、一般的に採用されている13層CNN分類器を使用すると、データ拡張が適用されているかどうかに関係なく、Triple-GANは実質的に10を超えるベンチマークで広範な半教師付き学習方法よりも優れています。ジェネレーターと分類器は、画像間の条件付き分布を特徴付けます3つのプレーヤーのメカニズムの副産物として、Triple-GANは、さまざまな半教師付き分類子とGANアーキテクチャを組み込むことができる柔軟性があります。 
[ABSTRACT]ゲームはジェネレーター、分類子、および識別子で構成されます。トリプルプラスと呼ばれ、優れた分類結果を達成し、特定のクラスから意味のあるサンプルを同時に生成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-20">
        <br><font color="black">2019-12-20</font>
      </time>
    </span>
</section>
<!-- paper0: Mathematical Morphology via Category Theory -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_26.html">
      <font color="black">Mathematical Morphology via Category Theory</font>
    </a>
  </h2>
  <font color="black">画像のよく知られた行列表現を採用すると、Matと呼ばれる行列のカテゴリを画像として表すことができます。ブールや（max、+）の半リングなどのさまざまな半環に対してMatを拡張すると、古典的な定義に到達できます。 Mat。のカテゴリカルテンソル積を使用したバイナリイメージとグレースケールイメージ。このアプローチにより、ブールおよび（max、+）セミリング以外の異なるセミリングを使用して、行列で表される2つの画像間の新しいタイプの膨張と収縮を定義できます。 
[要約]これらの方法のいくつかは基本的であると考えられていますが、データ処理の最も重要な基本です。画像の膨張ツールを使用すると、有名なバイナリとセミを使用して侵食に到達できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial symmetric GANs: bridging adversarial samples and adversarial
  networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_27.html">
      <font color="black">Adversarial symmetric GANs: bridging adversarial samples and adversarial
  networks</font>
    </a>
  </h2>
  <font color="black">AS-GANの有効性は、さまざまなネットワークアーキテクチャでのCIFAR-10、CelebA、およびLSUNでの画像生成で検証されます。したがって、弁別器はより堅牢であり、敵対的なノイズが少ない情報勾配を提供することで、トレーニングを安定させ、収束を加速します。 。生成的敵対的ネットワークは、さまざまなタスクで驚くべきパフォーマンスを達成していますが、トレーニングの不安定さに悩まされています。 
[ABSTRACT]これは、トレーニングの安定性を改善するために提案された多くのトレーニング戦略にもかかわらずです。しかし、この問題はこの問題への挑戦として残っています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-20">
        <br><font color="black">2019-12-20</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Object Detection and Tracking Based on Streaming Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_28.html">
      <font color="black">3D Object Detection and Tracking Based on Streaming Data</font>
    </a>
  </h2>
  <font color="black">私たちのフレームワークは、フレームごとのパラダイムと比較してオブジェクト検出が大幅に改善されているだけでなく、KITTIオブジェクトトラッキングベンチマークでも競争力のある結果を生み出すことが証明されています（MOTAでそれぞれ76.68％、MOTPで81.65％）。最近のアプローチディープラーニングの開発により、3Dオブジェクト検出が大幅に進歩しました。このホワイトペーパーでは、ストリーミングデータの時間情報を活用して、3Dストリーミングベースのオブジェクト検出と追跡について検討します。 
[ABSTRACT]これは、個々のフレームに基づいて一連の研究が行われたのは初めてです。これにより、フレーム間の情報へのアクセスが制限されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Learning from Multimodal and Multitemporal Earth Observation Data for
  Building Damage Mapping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_29.html">
      <font color="black">Learning from Multimodal and Multitemporal Earth Observation Data for
  Building Damage Mapping</font>
    </a>
  </h2>
  <font color="black">深い畳み込みニューラルネットワークアルゴリズムに基づいて、損傷を受けた建物のセマンティックセグメンテーションのための損傷マッピングフレームワークを定義しました。この結果は、ディープラーニングネットワークとともに、データセットがすべてのデータモダリティシナリオで許容可能な予測を可能にすることを示しています。損傷マッピングのための別の最先端のベースラインモデルへのアプローチ。 
[ABSTRACT]両方のデータモダリティからの画像は、災害の余波における完全な損傷状態を正確に伝えるために互いに補完できます。これらには、3つの災害タイプ、地震、津波、台風による建物の損傷特性、および3つの建物の損傷カテゴリが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: SCOUTER: Slot Attention-based Classifier for Explainable Image
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_30.html">
      <font color="black">SCOUTER: Slot Attention-based Classifier for Explainable Image
  Recognition</font>
    </a>
  </h2>
  <font color="black">SCOUTERに合わせて調整された新しい損失を設計し、モデルの動作を制御して、正と負の説明、および説明領域のサイズを切り替えます。実験結果は、SCOUTERが大規模なデータセットで優れた精度を維持しながら、より優れた視覚的説明を提供できることを示しています。ただし、ほとんどの既存の方法は、分類子の意思決定プロセスに直接関与しない勾配または中間機能に基づいています。 
[ABSTRACT]調査は、スカウターが大規模なデータセットの精度を維持しながら視覚的説明を改善できることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: RelativeNAS: Relative Neural Architecture Search via Slow-Fast Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_31.html">
      <font color="black">RelativeNAS: Relative Neural Architecture Search via Slow-Fast Learning</font>
    </a>
  </h2>
  <font color="black">比較的精度の高いネットワーク）とペアワイズ方式の遅い学習者。コードはhttps://github.com/EMI-Group/RelativeNASで入手できます。コンピュータービジョンにおけるたたみ込みニューラルネットワーク（CNN）の著しい成功にもかかわらず、CNNを手動で設計することは時間がかかり、エラーが発生しやすくなります。 
[ABSTRACT]微分可能なnasとポピュレーションベースのnasがますます関心を集めています。効率的な検索の鍵として、relativenasはfast-learnersの間で共同学習を実行します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Player Identification in Hockey Broadcast Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_32.html">
      <font color="black">Player Identification in Hockey Broadcast Videos</font>
    </a>
  </h2>
  <font color="black">これにより、新しいデータセットのテストスプリットでプレーヤー全体の識別精度スコアが87％を超えます。さらに、ResNet +の出力を分類するための後半のスコアレベルフュージョンメソッドとして、2次1次元畳み込みニューラルネットワーク分類器を採用しています。 LSTMネットワーク..この作業では、ホッケー選手のバウンディングボックスのシーケンスを含む新しいホッケー選手トラックレットデータセットを作成しました。 
[ABSTRACT]エンドツーエンドのトレーニング可能なresnet変数ネットワークを提案します。これには、長期短期記憶（lstm）レイヤーが含まれます。後期スコアレベルフュージョンメソッドとして、セカンダリ1州プレーヤー分類子を使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-05">
        <br><font color="black">2020-09-05</font>
      </time>
    </span>
</section>
<!-- paper0: P-DIFF: Learning Classifier with Noisy Labels based on Probability
  Difference Distributions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_33.html">
      <font color="black">P-DIFF: Learning Classifier with Noisy Labels based on Probability
  Difference Distributions</font>
    </a>
  </h2>
  <font color="black">ベンチマークデータセットの実験は、P-DIFFが最新のサンプル選択方法よりも優れていることも示しています。このホワイトペーパーでは、DNN分類器をトレーニングできる、P-DIFFと呼ばれる非常にシンプルで効果的なトレーニングパラダイムを紹介します。ノイズの多いラベルの悪影響を明らかに軽減します。P-DIFFは、トレーニングサンプルのノイズレートに関する事前の知識がなくても、優れたパフォーマンスを実現できます。 
[ABSTRACT] p-diffはdnn分類子をトレーニングできますが、ノイズの多いラベルの悪影響を軽減できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Discovering Latent Classes for Semi-Supervised Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_34.html">
      <font color="black">Discovering Latent Classes for Semi-Supervised Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">注釈コストが高いことは、セマンティックセグメンテーションシステムのトレーニングの主要なボトルネックです。ラベル付き画像では、セマンティッククラスと一致する潜在クラスが学習されるため、潜在クラスに割り当てられるセマンティッククラスの種類はできるだけ少なくなります。 、潜在クラスの確率マップを予測し、セマンティックセグメンテーションを学習するための監視信号として使用します。 
[ABSTRACT]これは、トレーニング画像の小さなサブセットのみに注釈が付けられることを意味します。さらに、他の画像には注釈が含まれていません。ラベル付けされた画像に、意味クラスと一致する潜在クラスを学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-30">
        <br><font color="black">2019-12-30</font>
      </time>
    </span>
</section>
<!-- paper0: Deforming the Loss Surface -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_35.html">
      <font color="black">Deforming the Loss Surface</font>
    </a>
  </h2>
  <font color="black">次に、元の確率的勾配降下オプティマイザーは、鋭い最小値を除外する才能を備えたフラット最小値フィルターであることが理論的に証明されています。ディープラーニングでは、通常、損失曲面の形状が固定されていると想定されます。さまざまな変形関数が設計されており、損失曲面への寄与がさらに提供されます。 
[要約]提案された手術システムを活用することで、より平坦な最小値を得ることができます。これは、cifar-100で検証されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-24">
        <br><font color="black">2020-07-24</font>
      </time>
    </span>
</section>
<!-- paper0: Prior Knowledge about Attributes: Learning a More Effective Potential
  Space for Zero-Shot Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_36.html">
      <font color="black">Prior Knowledge about Attributes: Learning a More Effective Potential
  Space for Zero-Shot Recognition</font>
    </a>
  </h2>
  <font color="black">潜在的な識別スペースとユーザー定義の属性スペースを組み合わせると、目に見えないクラスをより適切に分類できます。このアプローチは、従来のZSLでも一般化されたZSLでも、いくつかのベンチマークデータセットで既存の最先端のメソッドよりも優れています。ゼロショット学習（ZSL）は、見たクラスと既知の属性を学習することにより、目に見えないクラスを正確に認識することを目的としていますが、属性の相関関係は以前の研究では無視されていたため、分類結果が混乱しました。 
[ABSTRACT]属性相関ポテンシャル空間生成（acpsg）モデルを構築します。これは、グラフの畳み込みネットワークと属性相関を使用して、より識別可能な潜在空間空間スペースを生成します。いくつかのベンチマークデータセットで、既存の最先端の手法よりも優れたアプローチを採用しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: PRAFlow_RVC: Pyramid Recurrent All-Pairs Field Transforms for Optical
  Flow Estimation in Robust Vision Challenge 2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_37.html">
      <font color="black">PRAFlow_RVC: Pyramid Recurrent All-Pairs Field Transforms for Optical
  Flow Estimation in Robust Vision Challenge 2020</font>
    </a>
  </h2>
  <font color="black">私たちのモデルは、いくつかのシミュレートおよび実画像データセットでトレーニングされ、同じモデルとパラメーターを使用して複数のリーダーボードに送信され、ECCV 2020ワークショップのオプティカルフロータスクの2位を獲得しました。堅牢なビジョンチャレンジです。オプティカルフローの推定は、2つのフレーム間の密な対応を推定することを目的とする重要なコンピュータービジョンタスクです。 
[ABSTRACT]ラフトは現在、オプティカルフローのチャレンジの状態を表しています。現在、複数のオプティカルフロー推定における最先端の技術を表しています。ラフトユニットは、現在の解像度でオプティカルフローを推定するために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Residual Learning for Effective joint Demosaicing-Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_38.html">
      <font color="black">Residual Learning for Effective joint Demosaicing-Denoising</font>
    </a>
  </h2>
  <font color="black">実際、ここでは、最初にデモザイキングを適用し、次に適応ノイズ除去を使用して、従来のCFA処理パイプラインを反転させます。これは、統計的仮定に強く依存する従来のノイズ除去モデルでは非常に困難です。これは、畳み込みニューラルネットワーク（CNN）をトレーニングすることによって実現されます。従来のアルゴリズムの残差を学習します。 
[ABSTRACT]高品質の動画を取得するために、アルゴリズムとディープラーニングを組み合わせます。この方法は、定量的かつ視覚的な品質の点で、いくつかの最先端の方法よりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: A metric on the space of finite sets of trajectories for evaluation of
  multi-target tracking algorithms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CV/paper_39.html">
      <font color="black">A metric on the space of finite sets of trajectories for evaluation of
  multi-target tracking algorithms</font>
    </a>
  </h2>
  <font color="black">この論文では、マルチターゲット追跡アルゴリズムを数学的に健全な方法で評価するために、軌道の有限セットの空間に関するメトリックを提案します。軌道のセットに関する提案されたメトリックを軌道のランダムな有限セットに拡張します。メトリックの下限を提案します。これは、軌跡のセットのメトリックでもあり、線形計画法を使用して多項式時間で計算できます。 
[要約]メトリックの主な用途は、軌跡の推定値を軌跡のグラウンドトゥルースと比較することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2016-05-04">
        <br><font color="black">2016-05-04</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Robust Neural Machine Translation: Modeling Orthographic and
  Interpunctual Variation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CL/paper_0.html">
      <font color="black">Robust Neural Machine Translation: Modeling Orthographic and
  Interpunctual Variation</font>
    </a>
  </h2>
  <font color="black">この測定値を使用して、クリーンなデータでトレーニングされたベースラインと比較した場合、平均で敵対的な例でトレーニングされたシステムは、50％の一貫性の向上をもたらすことを示します。機械翻訳システムのトレーニングデータを増強し、ノイズの多いデータでテストすると、敵対的な例を使用してトレーニングされたシステムはクリーンなデータを翻訳する場合とほぼ同じように機能しますが、ベースラインシステムのパフォーマンスは2〜3 BLEUポイント低下します。 
[ABSTRACT]これらを使用して、機械翻訳システムのトレーニングデータを補強します。敵対的な例を使用してトレーニングされたシステムは、クリーンなデータを翻訳する場合とほぼ同じように機能しますが、ベースラインシステムのパフォーマンスは2〜3ブルーポイント低下します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-11">
        <br><font color="black">2020-09-11</font>
      </time>
    </span>
</section>
<!-- paper0: KRED: Knowledge-Aware Document Representation for News Recommendations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CL/paper_1.html">
      <font color="black">KRED: Knowledge-Aware Document Representation for News Recommendations</font>
    </a>
  </h2>
  <font color="black">ニュース記事には通常、著名人や組織などのナレッジエンティティが含まれています。ただし、既存のドキュメント理解モデルは、ナレッジエンティティ（BERTなど）を考慮せずにニュース記事を表すか、特定のタイプのテキストエンコーディングモデル（DKNなど）に依存しているため、一般化機能と効率性が損なわれます。最後に、情報抽出層は、元のドキュメント表現のガイダンスの下でエンティティの埋め込みを集約し、ドキュメントベクトルを新しいものに変換します。 
[ABSTRACT]記事は重要なメッセージを伝え、より直接的な方法でコンテンツを理解するのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br><font color="black">2019-10-25</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Training with Fast Gradient Projection Method against
  Synonym Substitution based Text Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CL/paper_2.html">
      <font color="black">Adversarial Training with Fast Gradient Projection Method against
  Synonym Substitution based Text Attacks</font>
    </a>
  </h2>
  <font color="black">画像に対して非常に効率的な勾配ベースの攻撃は、語彙、文法、および意味の制約と離散テキスト入力スペースのため、同義語置換ベースのテキスト攻撃に対して実装するのは困難です。次に、FGPMに敵対的なトレーニングを組み込んで、 Logitペアリング（ATFL）によって強化されたFGPMを使用したAdversarial Trainingと呼ばれるテキスト防御方法。実験により、ATFLがモデルのロバスト性を大幅に向上させ、敵対的な例の転送可能性をブロックできることが示されています。 
[ABSTRACT] fgpmは高速のテキスト攻撃手法を提案しました。fgpmはシンセ置換に基づいています。これは既存のテキスト攻撃手法よりも約20倍高速です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-09">
        <br><font color="black">2020-08-09</font>
      </time>
    </span>
</section>
<!-- paper0: An Investigation of Few-Shot Learning in Spoken Term Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CL/paper_3.html">
      <font color="black">An Investigation of Few-Shot Learning in Spoken Term Classification</font>
    </a>
  </h2>
  <font color="black">この問題を解決するために、モデルにとらわれないメタ学習（MAML）アルゴリズムに変更を加えることを提案します。ほとんどの少数ショット学習研究では、すべてのNクラスがN方向問題で新しいと想定されています。論文では、スピーチタスクに少数ショット学習アルゴリズムを適用することの実現可能性を調査しています。 
[ABSTRACT] Google音声コマンドデータセットは、私たちのアプローチが従来の教師あり学習アプローチと元のmamlよりも優れていることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-26">
        <br><font color="black">2018-12-26</font>
      </time>
    </span>
</section>
<!-- paper0: Learning an Effective Context-Response Matching Model with
  Self-Supervised Tasks for Retrieval-based Dialogues -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CL/paper_4.html">
      <font color="black">Learning an Effective Context-Response Matching Model with
  Self-Supervised Tasks for Retrieval-based Dialogues</font>
    </a>
  </h2>
  <font color="black">これらの問題に対処するために、このホワイトペーパーでは、事前トレーニング済みの言語モデルに基づいて、対話データ用に設計された補助自己監視タスクを使用してコンテキスト応答マッチングモデルを学習することを提案します。具体的には、次のセッションを含む4つの自己監視タスクを紹介します。予測、発話の回復、インコヒーレンスの検出と一貫性の識別、およびマルチタスクの方法でこれらの補助タスクを使用してPLMベースの応答選択モデルを共同でトレーニングします。マルチに従って適切な応答を選択する機能を備えたインテリジェントな対話システムを構築します。 -ターンコンテキストは、非常にやりがいのある作業です。 
[ABSTRACT]既存の研究は、コンテキストの構築に焦点を当てています-さまざまなニューラルアーキテクチャまたはplmsを使用した応答マッチングモデル。これらは通常、単一の応答予測タスクで学習しています。従来の方法で監視されている既存の対話システムから取得した応答は、依然としていくつかの重要な課題に直面しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Semantic Relations and Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CL/paper_5.html">
      <font color="black">Semantic Relations and Deep Learning</font>
    </a>
  </h2>
  <font color="black">本の新しい第5章では、初版の登場後に生じたディープラーニングパラダイムの関係分類/抽出について説明しています。これは、第5章のプレビューであり、モーガン＆クレイプールの親切な許可によって公開されています。第2版「名義間の意味関係」（Vivi Nastase、Stan Szpakowicz、Preslav Nakov、およびDiarmuid \ &#39;OS \&#39; eaghdhaによる）はMorgan＆Claypoolによって出版されます。 
[要約]本の新しい第5章は、評判を保護するのに役立つ情報の使用について詳しく説明しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-11">
        <br><font color="black">2020-09-11</font>
      </time>
    </span>
</section>
<!-- paper0: GeDi: Generative Discriminator Guided Sequence Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CL/paper_6.html">
      <font color="black">GeDi: Generative Discriminator Guided Sequence Generation</font>
    </a>
  </h2>
  <font color="black">また、GeDisがGPT-2からの直接生成と同じレベルの言語的受容性を維持しながら、生成と制御のトピックを解毒できることを示します（1.5Bパラメーター）。私たちの人間の評価実験では、GeDisが映画のレビューは、本のテキストのトーンを制御できます。最後に、4つのトピックのみでトレーニングされたGeDiが、単語の埋め込みから新しい制御コードに一般化できることを示し、幅広いトピックに向けて生成をガイドできるようにします。 
[ABSTRACT] gedisは、embeddingsという単語から新しい制御コードに一般化できます。映画レビューの感情制御のためにトレーニングされたgedisは、ブックコードのトーンを制御できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Composing Answer from Multi-spans for Reading Comprehension -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CL/paper_7.html">
      <font color="black">Composing Answer from Multi-spans for Reading Comprehension</font>
    </a>
  </h2>
  <font color="black">一方、生成デコーダーを使用しても、長い文に遭遇したときに整形式の構文とセマンティクスで結果の回答を十分に保証することはできません。したがって、両側の明らかな欠点を軽減するために、抽出された複数の回答から回答を作成する方法を提案します。特定のパッセージで非常に信頼性の高い$ n $ -gram候補としてモデルによって学習されたスパン。つまり、返された回答は不連続なマルチスパンで構成されていますが、指定されたパッセージの連続する1つのスパンだけではありません。 
[要約]提案された方法は、長い回答を正確に生成する上でより優れたパフォーマンスを発揮し、2つの競合する典型的な1つのスパンおよびseq2seqベースラインデコーダーを大幅に上回ります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Not-NUTs at W-NUT 2020 Task 2: A BERT-based System in Identifying
  Informative COVID-19 English Tweets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CL/paper_8.html">
      <font color="black">Not-NUTs at W-NUT 2020 Task 2: A BERT-based System in Identifying
  Informative COVID-19 English Tweets</font>
    </a>
  </h2>
  <font color="black">さまざまなBERTweetモデル構成を組み合わせることにより、情報量の多いクラスのF1スコアに関して、最高のパフォーマンスを誇るチームによるものに恥ずかしがるだけの競争力のある結果を達成しました。競技後、さまざまな実験も行いました新しいデータセットへの一般化を促進する可能性のある他のアプローチ..これに対応して、英語のツイートが与えられると、そのツイートにCOVID-19に関する有益なコンテンツが含まれているかどうかを自動的に識別するモデルを提案しました。 
[ABSTRACT]モデルは、そのツイートにcovid-19に関する有益なコンテンツが含まれているかどうかを自動的に識別します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Contrastive Triple Extraction with Generative Transformer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CL/paper_9.html">
      <font color="black">Contrastive Triple Extraction with Generative Transformer</font>
    </a>
  </h2>
  <font color="black">3つのデータセット（つまり、NYT、WebNLG、およびMIE）の実験結果は、私たちのアプローチがベースラインのパフォーマンスよりも優れたパフォーマンスを達成することを示しています。具体的には、エンコーダーデコーダーベースの生成用に単一の共有トランスモジュールを導入します。さらに、モデルのパフォーマンスをさらに向上させる2つのメカニズム（つまり、バッチ単位の動的注意マスキングとトリプル単位のキャリブレーション）。 
[要約]このホワイトペーパーでは、シーケンス生成のトリプル抽出タスクを再検討します。デコーダーベースの生成用に単一の共有変換モジュールを紹介します。プロジェクトは、モデルのパフォーマンスをさらに向上させる2つのメカニズムも導入しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Graph-based Modeling of Online Communities for Fake News Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CL/paper_10.html">
      <font color="black">Graph-based Modeling of Online Communities for Fake News Detection</font>
    </a>
  </h2>
  <font color="black">提案されたフレームワークは、1）普及したコンテンツの性質、2）ユーザーのコンテンツ共有行動、および3）これらのユーザーのソーシャルネットワークに関する情報を集約します。さらに、このためのいくつかのGNNモデルを体系的に比較しますタスクと、以前はNLP内のユーザーまたはコミュニティモデリングに使用されていなかった、リレーショナルおよび双曲線GNNに基づく新しい方法を紹介します。この作業では、グラフニューラルに基づく新しいソーシャルコンテキスト認識の偽ニュース検出フレームワークSAFERネットワーク（GNN）。 
[ABSTRACT]既存の研究は、オンライン投稿の普及における構造、スタイル、コンテンツ、およびパターンをモデル化しています。この研究では、グラフニューラルネットワーク（gnns）に基づいて、新しいソーシャルコンテキスト対応の偽のニュース検出フレームワーク、より安全なものを提案しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-14">
        <br><font color="black">2020-08-14</font>
      </time>
    </span>
</section>
<!-- paper0: A Comparison of Two Fluctuation Analyses for Natural Language Clustering
  Phenomena: Taylor and Ebeling & Neiman Methods -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CL/paper_11.html">
      <font color="black">A Comparison of Two Fluctuation Analyses for Natural Language Clustering
  Phenomena: Taylor and Ebeling & Neiman Methods</font>
    </a>
  </h2>
  <font color="black">さらに、どちらの方法もスクリプトの種類をキャプチャする可能性を示しています。分析の側面を検討した後、この記事では、これらの方法のテキストへの大規模な適用を示します。どちらの方法でも、実際のテキストを独立して同一に分散されたものから区別できます（ iid）
[ABSTRACT]どちらの方法でも、実際のテキストを独立して同一に分散されているものと区別できます。これは、ebelingとneimanにも当てはまりますが、程度は低いです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Dialogue Relation Extraction with Document-level Heterogeneous Graph
  Attention Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CL/paper_12.html">
      <font color="black">Dialogue Relation Extraction with Document-level Heterogeneous Graph
  Attention Networks</font>
    </a>
  </h2>
  <font color="black">ただし、有意義に接続されたスピーカー、エンティティ、エンティティタイプ、および発話ノードを含むグラフが作成されるDREのグラフアテンションネットワークベースの方法を示します。対話関係抽出（DRE）は、マルチパーティのダイアログで言及されている2つのエンティティ..私たちのコードはhttps://github.com/declare-lab/dialog-HGAT 
[ABSTRACT]でリリースされています。私たちのコードはgithub.comでリリースされており、コードとして宣言されています。ベンチからの情報の観察に基づいています。会話データに基づいてナレッジグラフを作成することで機能します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Can Fine-tuning Pre-trained Models Lead to Perfect NLP? A Study of the
  Generalizability of Relation Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/cs.CL/paper_13.html">
      <font color="black">Can Fine-tuning Pre-trained Models Lead to Perfect NLP? A Study of the
  Generalizability of Relation Extraction</font>
    </a>
  </h2>
  <font color="black">これらの調査結果は、将来の改善の機会を強調しています。たとえば、優れたパフォーマンスが汎化モデルの完成にどのようにつながるかはわかりません。コード、モデル、およびデータセットを備えたオープンソースのテストベッドDiagnoseREは、公開後にリリースされます。 
[ABSTRACT]テストベッドは公開後にリリースできます。コード、モデル、データセットのテストテストに使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Approximal operator with application to audio inpainting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/eess.AS/paper_0.html">
      <font color="black">Approximal operator with application to audio inpainting</font>
    </a>
  </h2>
  <font color="black">驚くべきことに、ほとんどの場合、そのような近似（近似演算子と呼ばれます）は、適切な同等物と比較して、オーディオインペインティングでより良い数値結果を提供する一方で、計算的にはるかに効果的であることが示されています。さらに、リーブとスタークの演算子は、適切なマッピングの近似として理解できます。しかし、それらのマッピングは不適切に正当化されます。 
[ABSTRACT]現在の記事は、それらのマッピングが実際に近位演算子であることを証明し、適切な対応物も導出しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-04">
        <br><font color="black">2020-05-04</font>
      </time>
    </span>
</section>
<!-- paper0: ICASSP 2021 Acoustic Echo Cancellation Challenge: Datasets and Testing
  Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/eess.AS/paper_1.html">
      <font color="black">ICASSP 2021 Acoustic Echo Cancellation Challenge: Datasets and Testing
  Framework</font>
    </a>
  </h2>
  <font color="black">この課題では、シングルトークとダブルトークの両方のシナリオでAECモデルをトレーニングするために、2つの大きなデータセットをオープンソースにします。これらのデータセットは、実際の環境での2,500以上のリアルオーディオデバイスとヒューマンスピーカーからの録音、および合成データセットで構成されます。 。私たちは、ITU-T P.808に基づくオンラインの主観的テストフレームワークをオープンソース化し、研究者が結果をすばやくテストできるようにしています。 
[ABSTRACT]最近の多くのaec調査では、合成データセットで妥当なパフォーマンスが報告されています。ただし、従来の客観的な指標のほとんどは、主観的な音声品質テストと十分に相関していません。環境</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Monolingual Data Selection Analysis for English-Mandarin Hybrid
  Code-switching Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/eess.AS/paper_2.html">
      <font color="black">Monolingual Data Selection Analysis for English-Mandarin Hybrid
  Code-switching Speech Recognition</font>
    </a>
  </h2>
  <font color="black">マンダリンデータは、コードスイッチングデータのマンダリン部分と密接に一致していますが、英語データはそうではありません。ただし、マンダリンデータは、マンダリンが著しく支配している発話にのみ役立ちます。次に、単一言語データを活用するために、データマッチングを見つけます。重要です。 
[ABSTRACT]トレーニングセット全体には、コードスイッチングデータセット、英語（librispeech）、マンダリンデータセットの3つのサブセットがあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-12">
        <br><font color="black">2020-06-12</font>
      </time>
    </span>
</section>
<!-- paper0: ICASSP 2021 Deep Noise Suppression Challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/eess.AS/paper_3.html">
      <font color="black">ICASSP 2021 Deep Noise Suppression Challenge</font>
    </a>
  </h2>
  <font color="black">この課題では、トレーニングデータセットとテストデータセットの両方を拡張しています。主観的な評価フレームワークをオープンソース化し、ツールを使用して最終的な勝者を評価および選択しました。学界や業界の多くの研究者がフィールドを前進させるために多大な貢献をしました。 
[ABSTRACT]私たちは最近、interspeech 2020でDNSチャレンジ特別セッションを開催しました。主観的な評価フレームワークをオープンソース化し、ツールを使用して最終的な勝者を評価および選択しました。研究コミュニティとして、私たちは優れた目標を達成する長い道のりがまだあります音声品質</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Toward the pre-cocktail party problem with TasTas$+$ -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-15/eess.AS/paper_4.html">
      <font color="black">Toward the pre-cocktail party problem with TasTas$+$</font>
    </a>
  </h2>
  <font color="black">新しいアプローチはTasTas $ + $と呼ばれ、5人の話者の混合発話を5つの分離された発話にマッピングし、各発話には1人の発話者の声のみが含まれます。目的のために、発話レベルを直接最適化してネットワークをトレーニングします順列不変トレーニング（PIT）スタイルでのスケール不変信号対歪み比（SI-SDR）。シーケンスモデリング、特に音声分離で効果的です。たとえば、
[ABSTRACT]新しいパスはtastas $ memoryと呼ばれ、5人の話者の混合発話が検出されます。tastasdata datanetと呼ばれる新しいアプローチは、公衆からのデータに基づいていますwsj0-5mixデータコーパス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
