<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-04-29の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: ASMD: an automatic framework for compiling multimodal datasets with
  audio and scores -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.SD/paper_0.html">
      ASMD: an automatic framework for compiling multimodal datasets with
  audio and scores
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      すべてのコードとグラウンドトゥルースは、適切なオープンライセンスの下でリリースされます。具体的には、Python APIを提供して、作曲家の交差やユニオン、楽器などの特定の属性に基づくブールセット演算を通じてデータセットにアクセスします。フレームワークは、新しいデータセットとそれぞれのグラウンドトゥルースアノテーションを簡単に含めることができるように設計されているため、独自のコレクションを構築、変換、拡張し、準拠した形式で配布してAPIを利用できます。 
[要約]フレームワークは、新しいデータセットを簡単に含めることができるように設計されています。ツールは、ユーザーが独自のコレクションを構築、変換、および拡張できるように設計されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-04">
        <br>2020-03-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Blind Audio Source Separation with Minimum-Volume Beta-Divergence NMF -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.SD/paper_1.html">
      Blind Audio Source Separation with Minimum-Volume Beta-Divergence NMF
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは、$ \ beta $ -divergencesの最小化と、ディクショナリマトリックスの列のボリュームを小さくするペナルティ項に基づいています。いくつかの穏やかな仮定とノイズのない条件下で、このモデルが証明可能であることを証明しますソースを特定します。実際、この状況では、モデルはソースを自動的にゼロに設定するため、モデルの次数選択が自動的に実行されます。 
[要約]非負性行列因数分解は、時間と信号の周波数表現を使用する標準および最先端の技術です。これは、$＆beta $の最小化に基づいています-発散と、列の列を促進するペナルティ項小さなボリュームを持つ辞書行列
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-04">
        <br>2019-07-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Data Efficient Direct Speech-to-Text Translation with Modality Agnostic
  Meta-Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.SD/paper_2.html">
      Data Efficient Direct Speech-to-Text Translation with Modality Agnostic
  Meta-Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      多言語音声翻訳コーパス（MuST-C）からの英語-ドイツ語（En-De）と英語-フランス語（En-Fr）言語のペアのSTタスクに提案されたメタ学習アプローチを評価します。この作業では、ソースタスク= ASR + MTからターゲットタスク= STにナレッジを転送するモダリティにとらわれないマルチタスクモデルをトレーニングするメタ学習アルゴリズム。STタスクにはデータが大幅に不足しています。エンドツーエンドの音声翻訳（ST）モデルにはいくつかあります。自動音声認識（ASR）モデルとテキスト機械翻訳（MT）モデルを組み合わせた従来のパイプラインに比べて、レイテンシが低く、モデルサイズが小さく、エラーの複合が少ないなどの利点があります。 
[ABSTRACT] stタスクは、asrおよびmtタスクよりも困難です。これらのアプローチは、教師付きの弱いトレーニングデータから恩恵を受けます。ただし、新しい方法は、以前の転移学習アプローチよりも優れています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.SD/paper_3.html">
      Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのレイテンシを削減するために、最近提案された接頭辞から接頭辞へのフレームワークに基づいて、最初のニューラルインクリメンタルTTSアプローチを考案します。音声をオンラインで合成し、音声のセグメントを再生しながら次のセグメントを生成して、$ O（ 1）$ O（n）$レイテンシではなく$。ただし、これらの取り組みには、2つのタイプのレイテンシがあります：（a）{\ em計算レイテンシ}（合成時間）。並列アプローチ、および（b）入力テキストが段階的に生成されるシナリオ（同時翻訳、ダイアログ生成、支援技術など）での{\ em入力待ち時間}。 
[要約]これらの取り組みには、2つのタイプのレイテンシがまだあります。これらには、「合成時間」が含まれます。これは、並列アプローチでも、文の長さに比例して増加します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-07">
        <br>2019-11-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Adversarial Feature Learning and Unsupervised Clustering based Speech
  Synthesis for Found Data with Acoustic and Textual Noise -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.SD/paper_4.html">
      Adversarial Feature Learning and Unsupervised Clustering based Speech
  Synthesis for Found Data with Acoustic and Textual Noise
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最先端の音声強調モデルに基づくノイズ除去アプローチを超えて、ノイズの多いデータに基づいて構築されたシステムは、クリーンな対応物上に構築されたシステムに近いMOSでクリーンで高品質の音声を合成できます。側のノイズについては、敵対的なトレーニングとデータ拡張を通じて、自己回帰デコーダーのノイズに依存しない機能を学習することを提案します。これには、追加の音声強調モデルは必要ありません。実験は、テキストを扱う際の提案されたアプローチの有効性を示しています。側と音声側のノイズ。 
[要約]提案されたシステムは、通信コミュニケーションの欠如に基づいています。たとえば、vqvaeベースのヒューリスティック手法を提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: When Hearing Defers to Touch -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.SD/paper_5.html">
      When Hearing Defers to Touch
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は、弱い刺激を検出するためのタッチと聴覚の能力は、感知されたオブジェクトのサイズとその振動の周波数によって変化することを示しています。特に、タッチは、小さい聴覚よりも聴覚よりも効果的です。遅いオブジェクト..私たちは、合理的な仮定の下で、聴覚および触覚の検出しきい値が平等な競技場で調整できることを示しています。 
[ABSTRACT]この主張は、触覚と弱い刺激の比較に基づいています。触覚は、小さくて遅い物体の検出において、聴覚よりも効果的であることがわかります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Self-supervised Learning of Visual Speech Features with Audiovisual
  Speech Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.SD/paper_6.html">
      Self-supervised Learning of Visual Speech Features with Audiovisual
  Speech Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの結果は、視聴覚音声強調の重要な側面についての洞察を提供し、そのようなモデルが視覚音声アプリケーションの自己監視タスクにどのように使用できるかを示しています。この発見の興味深い副産物は、学習された視覚的埋め込みが他の視覚的音声アプリケーションの機能として使用できることです。 
[要旨]口形素を分類するための学習された視覚表現の有効性を実証しました（音素への視覚的な類似）
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-25">
        <br>2020-04-25
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Embarrassingly Simple Unsupervised Aspect Extraction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_0.html">
      Embarrassingly Simple Unsupervised Aspect Extraction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      アスペクト抽出のための現在のベンチマークデータセットの単純さを考えると、そのような複雑なモデルは必要ないことを示します。RBFカーネルに基づく新しいシングルヘッドアテンションメカニズムであるContrastive Attention（CAt）を導入し、パフォーマンスを大幅に向上させます。以前の作業は構文機能と複雑なニューラルモデルに依存していました。 
[要旨]教師なしの方法では、単語の埋め込みとpos taggerのみが必要です。新しいドメインと言語に注意が必要
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Autoencoding Word Representations through Time for Semantic Change
  Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_1.html">
      Autoencoding Word Representations through Time for Semantic Change
  Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、意味的にシフトした単語を検出するための逐次モデルの3つのバリアントを提案し、時間的に敏感な方法で、時間の経過に伴う単語表現の変化を効果的に説明します。 、単語表現の時間モデリングがパフォーマンスの明確な利点をもたらすことを示しています。意味的変化の検出は、時間の経過とともに意味が変化した単語を識別するタスクに関係しています。 
[ABSTRACT]現在の状態-時間の経過に伴う変化を考慮せずに、2つの異なる期間の単語を比較するステップアップの状態
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: How Much Knowledge Can You Pack Into the Parameters of a Language Model? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_2.html">
      How Much Knowledge Can You Pack Into the Parameters of a Language Model?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      非構造化テキストでトレーニングされたニューラル言語モデルは、自然言語クエリを使用して暗黙的に知識を保存および取得できることが最近観察されました。再現性と将来の作業を容易にするために、コードとトレーニングされたモデルをリリースします。このアプローチは、モデルサイズと、Natural QuestionsおよびWebQuestionsのオープンドメインバリアントに関する知識を明示的に検索するモデルよりも優れています。 
[ABSTRACT]新しい論文では、事前にトレーニングされたモデルを使用して、外部コンテキストや知識にアクセスせずに質問に回答することにより、このアプローチの実用性を測定しています。コードとトレーニング済みドメインモデルをリリースします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-10">
        <br>2020-02-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: LAMBERT: Layout-Aware (Language) Modeling using BERT for information
  extraction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_3.html">
      LAMBERT: Layout-Aware (Language) Modeling using BERT for information
  extraction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、ローカルセマンティクスが重要なレイアウトの影響を受けるドキュメントを理解するという問題への新しいアプローチを紹介します。つまり、レイアウトで定義されたグラフィック機能を使用できるように、Transformerアーキテクチャを変更します。古典的な言語モデリングタスクで事前トレーニングされたモデルからトレーニングプロセスを開始したおかげで、言語セマンティクスをゼロから再学習する必要がありません。 
[ABSTRACT]レイアウトによって定義された視覚的機能を使用できるようにトランスフォーマアーキテクチャを変更しました。トランスフォーマアーキテクチャは既存の既存の機能を使用するように設計されています。言語を最初から文法的に再学習する必要はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Introducing a framework to assess newly created questions with Natural
  Language Processing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_4.html">
      Introducing a framework to assess newly created questions with Natural
  Language Processing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、質問も評価する必要があります。IRTを使用して、すでに数人の学生が回答した質問の特性を推定することは可能ですが、この手法は、新しく生成された質問には使用できません。派生したものなどの統計モデル項目応答理論（IRT）は、特定の主題に関する学生の評価を可能にします。これは、いくつかの目的（学習パスのカスタマイズ、ドロップアウト予測など）に役立ちます。このホワイトペーパーでは、トレーニングと評価を行うためのフレームワークを提案します。質問と可能な選択肢のテキストから意味のある特徴を抽出することにより、新しく作成された多肢選択問題の難易度と識別を推定するためのモデル。 
[ABSTRACT]システムはcloudacademyの学生によって開発されました。既存のモデルよりもパフォーマンスが優れており、6.7％から10.8％削減されています。結果はcloudacademyのデータに基づいていることが示されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Kungfupanda at SemEval-2020 Task 12: BERT-Based Multi-Task Learning for
  Offensive Language Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_5.html">
      Kungfupanda at SemEval-2020 Task 12: BERT-Based Multi-Task Learning for
  Offensive Language Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      OffensEval-2020コンテストでは、私たちのモデルは英語サブタスクAで91.51％のF1スコアを達成しました。これは、1位（92.23％F1）に匹敵します。現在、ソーシャルメディアの攻撃的なコンテンツは深刻な問題になり、自動的に攻撃的な言語の検出は不可欠なタスクです。さらに、攻撃的な言語検出のパフォーマンスを向上させるために、他の関連タスクからの監視信号を利用します。 
[要旨]攻撃的な言語検出システムは、マルチタスク学習とbertベースのモデルを組み合わせます。このホワイトペーパーでは、ノイズの多いテキスト学習とソーシャルネットワークを組み合わせた攻撃的な言語システムを構築します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Scheduled DropHead: A Regularization Method for Transformer Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_6.html">
      Scheduled DropHead: A Regularization Method for Transformer Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      機械翻訳とテキスト分類のベンチマークデータセットの両方の実験結果は、提案されたアプローチの有効性を示しています。マルチヘッド注意メカニズムの学習ダイナミクスに関する最近の研究に動機付けられて、我々は、特定のドロップアウト率スケジュールを提案して、 DropHeadは、より良い正則化効果を実現します。トレーニング中にアテンションヘッド全体をドロップし、マルチヘッドアテンションモデルがアテンションヘッドのごく一部に支配されるのを防ぎながら、トレーニングデータの過剰適合のリスクを低減します。マルチヘッド注意メカニズムをより効率的に。 
[要約]提案されたドロップヘッドは、システムの構造化された部分です。システムは、マルチタッチシステムの注意を減らすのに役立つように設計されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Self-Attention with Cross-Lingual Position Representation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_7.html">
      Self-Attention with Cross-Lingual Position Representation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、機械翻訳などのクロスリンガルシナリオでは、ソースとターゲットの文のPEは独立してモデル化されます。広範な分析により、パフォーマンスの向上はクロスリンガル情報から得られることが確認されています。WMT&#39;14English $の実験結果Rightarrow $ドイツ語、WAT&#39;17日本語$ \ Rightarrow $英語、およびWMT&#39;17中国語$ \ Leftrightarrow $英語の翻訳タスクは、私たちのアプローチが強力なベースラインを超えて翻訳品質を大幅かつ一貫して向上させることを示しています。 
[ABSTRACT]クロスリンガルシナリオでは、ソースとターゲットのセンテンスのペスは独立してモデル化されます。これらは「クロスリンガルシナリオ」に基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Grayscale Data Construction and Multi-Level Ranking Objective for
  Dialogue Response Selection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_8.html">
      Grayscale Data Construction and Multi-Level Ranking Objective for
  Dialogue Response Selection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2つのベンチマークデータセットの実験結果は、新しいトレーニング戦略により、さまざまな評価指標の点で既存の最先端のマッチングモデルよりもパフォーマンスが大幅に向上することを示しています。グレースケールトレーニングデータを最大限に活用するには、マルチレベルの提案ランキング戦略..応答選択は、検索ベースの会話システムを構築する上で重要な役割を果たします。 
[ABSTRACT]新しいトレーニング戦略により、既存の状態よりもパフォーマンスが大幅に向上します-さまざまな評価指標の点で最先端のマッチングモデル
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: MAVEN: A Massive General Domain Event Detection Dataset -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_9.html">
      MAVEN: A Massive General Domain Event Detection Dataset
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果と実証分析は、既存のEDメソッドは小さなデータセットのように有望な結果を達成できないことを示しています。これは、現実世界のEDは依然として困難な作業であり、さらなる研究努力が必要であることを示唆しています。MAVENはデータ問題の欠如を軽減し、より一般的なイベントの種類..データセットに加えて、最新のEDモデルを再現し、MAVENでこれらのモデルを徹底的に評価します。 
[ABSTRACT]大規模なイベント検出データセット（maven）には、4、480のWikipediaドキュメント、117、200のイベント言及インスタンス、および207のイベントタイプが含まれています。データセットとベースラインコードは、このフィールドを宣伝するために将来リリースされる予定です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Active Learning for Coreference Resolution using Discrete Annotation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_10.html">
      Active Learning for Coreference Resolution using Discrete Annotation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      既存のベンチマーク相互参照データセットを使った実験では、この追加の質問からの信号が人間の注釈時間あたりのパフォーマンスの大幅な向上につながることを示しています。将来の作業では、注釈プロトコルを使用して新しいドメインの相互参照モデルを効果的に開発できます。ラベル付けする例を選択するための新しい言及クラスタリングアルゴリズムと組み合わせると、注釈予算ごとに得られるパフォーマンスの点で非常にコスト効率が高くなります。 
[ABSTRACT]アップグレードはアクティブな言及antecom.itに関連していません。注釈予算ごとに取得されるパフォーマンスの点で非常にコスト効果があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: DTCA: Decision Tree-based Co-Attention Networks for Explainable Claim
  Verification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_11.html">
      DTCA: Decision Tree-based Co-Attention Networks for Explainable Claim
  Verification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、まず意思決定ツリーベースのエビデンスモデル（DTE）を構築して、信頼性の高いコメントをエビデンスとして透明で解釈可能な方法で選択します。次に、選択したエビデンスと相互作用させる共同注意セルフアテンションネットワーク（CaSa）を設計します。これは、1）最適な決定しきい値を決定し、より強力な証拠を取得するためにDTEをトレーニングするためのものです。および2）証拠を利用してクレームの誤った部分を見つける。このホワイトペーパーでは、説明可能なクレーム検証の証拠を見つけるために、決定木ベースの共同注意モデル（DTCA）を提案します。 
[ABSTRACT]このホワイトペーパーでは、説明可能なクレームの証拠を発見するために、決定木ベースの共同注意モデル（dtca）を提案します。次に、選択された証拠をクレームと相互作用させるために、順序付けられた証拠ネットワークを設計します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Assessing the Bilingual Knowledge Learned by Neural Machine Translation
  Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_12.html">
      Assessing the Bilingual Knowledge Learned by Neural Machine Translation
  Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、バイリンガル知識の学習に影響を与える可能性のあるいくつかの進歩（例えば、逆翻訳）を再検討し、いくつかの興味深い結果を報告します。広く使用されているデータセットに対する広範な実験により、フレーズテーブルは言語ペアとランダムシードに対して妥当で一貫している.. NMTモデルが正しく予測するトレーニング例からフレーズテーブルを抽出します。 
[ABSTRACT]それがどのようにそしてなぜ機能するかについての理解が不十分です。合理的なトレーニングの例からフレーズテーブルを抽出します。これらは解釈可能なシステムに基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Optimizing the Factual Correctness of a Summary: A Study of Summarizing
  Radiology Reports -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_13.html">
      Optimizing the Factual Correctness of a Summary: A Study of Summarizing
  Radiology Reports
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案された方法を、事実の正確さが重要な要件である放射線医学レポートの要約に適用します。ニューラル抽象要約モデルは、人間の参照と高いオーバーラップを持つ要約を生成できます。病院から収集された2つの個別のデータセットで、提案されたアプローチが、競合する神経要約システムよりも出力の事実の正確性と全体的な品質を大幅に向上させ、人間が作成したものの品質に近づく放射線要約を生成するという、自動評価と人間評価の両方。 
[ABSTRACT]既存のモデルは、事実の正確さのために最適化されていません。提案されたアプローチは、競合する神経集計システムよりも、事実の正確さと出力の全体的な品質を大幅に向上させます。人間が作成したものの品質に近い放射線サマリーを生成します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-06">
        <br>2019-11-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Out-of-Sample Representation Learning for Multi-Relational Graphs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_14.html">
      Out-of-Sample Representation Learning for Multi-Relational Graphs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、この問題は、驚くべきことに、非属性グラフでは調査されないままになっています。このホワイトペーパーでは、非属性マルチリレーショナルグラフのサンプル外表現学習問題を紹介し、このタスクのベンチマークデータセットを作成し、いくつかのモデルを開発します。とベースライン、そして提案されたモデルとベースラインの実証分析と比較を提供します。これは、属性付きグラフ（各エンティティに初期特徴ベクトルがある）と非属性付きグラフ（唯一の初期情報が既知の関係から得られる）の両方に当てはまります。他のエンティティ）。 
[要約]表現学習は、トランスダクティブ推論に非常に効果的であることが証明されています。サンプル外の推論では、より多くの人々が予測を行う必要があります。例には、トレーニング時に見られなかった証言が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural
  Language Processing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_15.html">
      TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural
  Language Processing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      シンプルな構成で、類似した数のパラメーターを持つ公衆蒸留BERTモデルと同等かそれ以上の結果を達成します。これは、さまざまなニューラルネットワークモデルで動作し、テキスト分類、読解などのさまざまな種類の教師あり学習タスクをサポートします、シーケンスのラベリング..この論文では、自然言語処理のために設計されたオープンソースの知識抽出ツールキットであるTextBrewerを紹介します。 
[ABSTRACT]このツールはさまざまなモデルで動作し、さまざまな種類の教師あり学習タスクをサポートします。事前定義された蒸留方法のセットを提供し、カスタムコードで拡張できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-28">
        <br>2020-02-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Let's be Humorous: Knowledge Enhanced Humor Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_16.html">
      Let's be Humorous: Knowledge Enhanced Humor Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、自由な形式とユーモアの背景知識に焦点を当てた作品はほとんどありません。私たちの知る限り、これは知識強化モデルでパンチラインを生成する最初の試みです。実験結果は、私たちの方法が知識を利用して流暢な、面白いパンチラインは、いくつかのベースラインよりも優れています。 
[要約]ユーモアの言語理論は、ユーモアの文の構造を関連性のあるパンチラインとして定義します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: KoParadigm: A Korean Conjugation Paradigm Generator -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_17.html">
      KoParadigm: A Korean Conjugation Paradigm Generator
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      KoParadigmは、言語的に十分に確立されているだけでなく、計算的にも単純で効率的です。私たちの知る限りでは、これはすべての現代韓国語の動詞と語尾をカバーする最初の韓国語活用モジュールです。韓国語は形態学的に豊かな言語です。 
[ABSTRACT] koparadigmは韓国語の活用ジェネレーターであり、koparadigm.koparadigmと呼ばれますが、言語的に十分に確立されているだけでなく、数学的にも単純です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Weakly Supervised POS Taggers Perform Poorly on Truly Low-Resource
  Languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_18.html">
      Weakly Supervised POS Taggers Perform Poorly on Truly Low-Resource
  Languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの結果は、真に低リソースの言語に対するPOSタギングへの新しい異なるアプローチの必要性を浮き彫りにします。これらの言語では、現実的な量のリソースが与えられると、私たちの最高のモデルでさえ、単語の半分未満しか正しくなりません。 
[ABSTRACT] posタガーは通常、真に低リソースの言語とは非常に異なる言語でのみ評価されます。タガーは、高カバレッジやほとんどエラーのない辞書など、リソース-貧困層には利用できない可能性のある情報源を使用します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Data Efficient Direct Speech-to-Text Translation with Modality Agnostic
  Meta-Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_19.html">
      Data Efficient Direct Speech-to-Text Translation with Modality Agnostic
  Meta-Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、これらのモデルのパラメーターは各タスクとは無関係に更新されるため、次善のソリューションにつながる可能性があります。私たちは、英語-ドイツ語（En-De）と英語-フランス語（En -Fr）多言語音声翻訳コーパス（MuST-C）からの言語ペア。ただし、STタスクの大量の並列データを収集することは、ASRおよびMTタスクに比べて困難です。 
[ABSTRACT] stタスクは、asrおよびmtタスクよりも困難です。これらのアプローチは、教師付きの弱いトレーニングデータから恩恵を受けます。ただし、新しい方法は、以前の転移学習アプローチよりも優れています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Contextual Neural Machine Translation Improves Translation of Cataphoric
  Pronouns -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_20.html">
      Contextual Neural Machine Translation Improves Translation of Cataphoric
  Pronouns
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、ターゲット化されたカタフォラテストスイートの評価を実行し、BLEUの観点から、コンテキストにとらわれないトランスフォーマーよりも大幅に向上したことを報告します。この作業では、トレーニングされたコンテキストNMTモデルのパフォーマンスを比較することにより、コンテキストとして将来の文の効果を調査します。将来のコンテキストを過去のコンテキストでトレーニングしたものに置き換えます。一般的な代名詞に焦点を当てた自動メトリックを使用した私たちの実験と評価は、将来のコンテキストの使用がコンテキストにとらわれないトランスフォーマーを大幅に改善するだけでなく、過去のコンテキストでトレーニングされた同等のものと比較して、場合によっては改善されたパフォーマンス。 
[要約]将来のコンテキストの使用により、コンテキストが大幅に改善されました。また、過去のコンテキストでトレーニングされた対応物よりも改善されました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br>2020-04-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Entity Type Prediction in Knowledge Graphs using Embeddings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_21.html">
      Entity Type Prediction in Knowledge Graphs using Embeddings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このアプローチを現在の最先端のタイプの予測方法と比較し、KGを使用した実験について報告します。この問題に対処するために、この作業では、KG埋め込みを使用したエンティティタイプのマルチラベル分類アプローチを提案します。これらのKGのほとんどは、ほとんどの場合、ウィキペディアのスナップショットからの自動情報抽出、またはユーザーが提供した情報の蓄積、またはヒューリスティックを使用して作成されます。 
[要旨]私たちのアプローチを現在のwibdaタイプ予測方法と比較し、kgsを使用した実験について報告します。このタイプ情報は、多くの場合、ノイズが多く、不完全で、正しくありません。ただし、これらのkgsのタイプ情報が機能することが確認されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: MultiMix: A Robust Data Augmentation Strategy for Cross-Lingual NLP -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_22.html">
      MultiMix: A Robust Data Augmentation Strategy for Cross-Lingual NLP
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの実験は、ベースラインよりも優れたマージンで両方のタスクの大幅な改善を示しています。MultiMixは、本質的に、データの増強と教師なしのサンプル選択を伴うセルフトレーニングを同時に実行します。転移学習は、多くの分野で最先端の結果をもたらしました教師付き自然言語処理タスク。 
[ABSTRACT]すべてのターゲット言語のすべてのターゲットタスクの注釈付きデータは、特にリソースの少ない言語ではまれです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Assessing Discourse Relations in Language Generation from Pre-trained
  Language Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_23.html">
      Assessing Discourse Relations in Language Generation from Pre-trained
  Language Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は、GPT-2が有効な談話関係を含むテキストを常に生成するとは限らないことを示しています。それにもかかわらず、そのテキストは微調整されたシナリオでの人間の期待とより一致しています。これらの問題を軽減し、談話情報を明示的にモデル化することの重要性を強調する分離戦略を提案します。NLPの最近の進歩は、大規模なものの出現に起因しています規模の事前トレーニング済み言語モデル。 
[ABSTRACT] gpt-2は、特に、生成タスクに適しています。ただし、生成されたテキストの言語品質はほとんど未調査のままです。これらの問題を軽減するためのデコスケール戦略を提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-26">
        <br>2020-04-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Joint Keyphrase Chunking and Salience Ranking with BERT -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_24.html">
      Joint Keyphrase Chunking and Salience Ranking with BERT
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      JointKPEは、チャンキングネットワークを使用して高品質のフレーズを識別し、ランキングネットワークを使用してドキュメント内の顕著性を学習します。効果的なキーフレーズ抽出システムでは、ドキュメントトピックの鍵となる自己完結型の高品質フレーズを生成する必要があります。 2つのベンチマークは、さまざまなBERTバリアントに対するJointKPEの強力な効果を示しています。 
[要約]モデルはキーフレーズ抽出用のマルチタスクbertベースのモデルです。これは、チャンクタスクとランク付けタスクで共同でトレーニングされ、キーフレーズの品質とsalienceの推定のバランスをとります。テストは、jointkpeが長いキーフレーズの予測に有利であることを示していますエンティティではなく意味のあるフレーズを抽出する
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: KACC: A Multi-task Benchmark for Knowledge Abstraction, Concretization
  and Completion -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_25.html">
      KACC: A Multi-task Benchmark for Knowledge Abstraction, Concretization
  and Completion
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、ウィキデータから抽出された大規模なデータセットを提案します。これにより、よりサイズのバランスがとれたコンセプトグラフと豊富なクロスビューリンクが提供されます。 、2つのグラフ間の知識伝達に十分な情報を提供できません。データセットに基づいて、知識の抽象化、具体化、および完了（KACC）に関する既存のモデルの能力をテストするベンチマークをさらに提案します。 
[ABSTRACT]コンセプトグラフは、コンセプトテストと同じくらい簡単に見ることができます。コンセプトテストは、それぞれの理解を深めるために使用できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Novel Cascade Binary Tagging Framework for Relational Triple
  Extraction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_26.html">
      A Novel Cascade Binary Tagging Framework for Relational Triple
  Extraction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験により、CasRelフレームワークは、エンコーダーモジュールがランダムに初期化されたBERTエンコーダーを使用する場合でも、最先端のメソッドよりもすでに優れており、新しいタグ付けフレームワークの威力を示しています。トリプルが重複するさまざまなシナリオの詳細な分析では、この方法は、これらすべてのシナリオにわたって一貫したパフォーマンスの向上を実現します。非構造化テキストからリレーショナルトリプルを抽出することは、大規模な知識グラフの構築に不可欠です。 
[ABSTRACT]新しいシステムは事前トレーニング済みの条件付きエンコーダーを使用します。最も強いベースラインよりも17.5および30優れています。2f1の絶対ゲイン
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-07">
        <br>2019-09-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_27.html">
      Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのレイテンシを削減するために、最近提案された接頭辞から接頭辞へのフレームワークに基づいて、最初のニューラル増分TTSアプローチを考案しました。テキストから音声への合成（TTS）は、近年急速な進歩を遂げており、ニューラルメソッドが生成できるようになりました。自然性の高いオーディオ。オンラインで音声を合成し、オーディオのセグメントを再生しながら次のセグメントを生成するため、遅延は$ O（n）$ではなく$ O（1）$になります。 
[要約]これらの取り組みには、2つのタイプのレイテンシがまだあります。これらには、「合成時間」が含まれます。これは、並列アプローチでも、文の長さに比例して増加します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-07">
        <br>2019-11-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to Learn Morphological Inflection for Resource-Poor Languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_28.html">
      Learning to Learn Morphological Inflection for Resource-Poor Languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      特に、以前に提案されたクロスリンガル転送モデルよりも31.7％高い絶対精度が得られ、言語全体で平均して1.7％の絶対精度で従来の技術よりも優れています。ファミリーは、提案されたアプローチがすべてのベースラインよりも優れていることを示しています。リソースの乏しい言語について、形態学習の活用-補題を指定された活用形態にマッピングするタスクをメタ学習問題としてキャストすることを提案します。 
[ABSTRACT]リソースの多いソース言語からのデータを使用して、リソースを微調整するための強力な初期化ポイントとして機能する一連のモデルパラメータを学習します-ターゲット言語が不十分です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Logical Natural Language Generation from Open-Domain Tables -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_29.html">
      Logical Natural Language Generation from Open-Domain Tables
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案された論理NLG問題の調査を容易にするために、テストベッドとして幅広い論理/記号推論を備えた既存のTabFactデータセット\ cite {chen2019tabfact}を使用し、生成モデルの忠実度を評価するための新しい自動メトリックを提案します\論理的推論..このホワイトペーパーでは、モデルに、オープンドメインの半構造化テーブルのファクトによって\ emph {論理的に伴われる}自然言語ステートメントの生成を任せる新しいNLGタスクを提案します。新しいタスクシーケンスの順序と論理的な順序の不一致により、既存の単調な生成フレームワークに課題をもたらします。 
[要約]神経Nlgに関するこれまでの研究は、主に表面レベルの実現に焦点が当てられており、論理的な結論に重点が限定されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-22">
        <br>2020-04-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to Update Natural Language Comments Based on Code Changes -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_30.html">
      Learning to Update Natural Language Comments Based on Code Changes
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      オープンソースソフトウェアプロジェクトのコミット履歴から収集したデータセットを使用してモデルをトレーニングし、評価します。各例は、メソッドへの同時更新とそれに対応するコメントで構成されています。両方の自動メトリックを使用して、アプローチを複数のベースラインと比較します。人間の評価。私たちは、付随するコードの本体の変更に基づいて、既存の自然言語コメントを自動的に更新するという新しいタスクを定式化します。 
[要約] 2つの異なる言語表現の変更を相互に関連付ける方法を学習するアプローチを提案します。自動メトリックと人間の評価の両方を使用して、複数のベースラインに対してアプローチを比較します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-25">
        <br>2020-04-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Event Extraction by Answering (Almost) Natural Questions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_31.html">
      Event Extraction by Answering (Almost) Natural Questions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この問題を回避するために、エンドツーエンドの方法でイベント引数を抽出する質問応答（QA）タスクとして定式化することにより、イベント抽出の新しいパラダイムを導入します。経験的結果は、フレームワークが以前の方法を大幅に上回ることを実証しています。 ;さらに、トレーニング時に見られないロールのイベント引数を抽出することができます（ゼロショット学習設定）。イベント抽出の問題は、イベントトリガーを検出し、対応する引数を抽出する必要があります。 
[ABSTRACT]イベント引数の抽出には、トレーニング時に表示されないロールのイベント引数の抽出が含まれます。これは、トリガーとして使用できるイベント引数が原因です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Conversational Word Embedding for Retrieval-Based Dialog System -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_32.html">
      Conversational Word Embedding for Retrieval-Based Dialog System
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      検索ベースのダイアログシステムのシングルターンおよびマルチターンの応答選択タスクでメソッドを評価します。実験結果は、PR埋め込みが選択した応答の品質を向上できることを示しています。PR埋め込みソースコードはhttpsで入手できます：//github.com/wtma/PR-Embedding 
[ABSTRACT]会話型の単語の埋め込み方法はpr-embeddingと呼ばれます。この方法では、利用可能な会話のペアを使用して単語の埋め込みを学習します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning Interpretable and Discrete Representations with Adversarial
  Training for Unsupervised Text Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_33.html">
      Learning Interpretable and Discrete Representations with Adversarial
  Training for Unsupervised Text Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      潜在的なトピックを表すために抽出されたトピックの単語は、TIGANが一貫性のある非常に解釈可能なトピックを学習することを示しています。ノイズはトピック内の分散を制御します。他の教師なしベースラインと比較して、提案されたTIGANは6つの異なるコーパスで優れたパフォーマンスを実現します。 
[ABSTRACT] tiganのコードはベースラインのテキスト分類に使用できます。パフォーマンスは最近提案された弱い-教師ありテキスト分類方法と同等です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: DialoGPT: Large-Scale Generative Pre-training for Conversational
  Response Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_34.html">
      DialoGPT: Large-Scale Generative Pre-training for Conversational
  Response Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      DialoGPTを活用する会話型システムは、強力なベースラインシステムよりも、関連性が高く、内容が豊富で、コンテキストに一貫した応答を生成することを示しています。 PyTorchトランスは、単一ターンの対話設定で自動および人間評価の両方で人間に近いパフォーマンスを達成します。事前トレーニング済みモデルとトレーニングパイプラインが公開され、神経応答生成とよりインテリジェントなオープンの開発の研究を促進します。 -ドメイン対話システム。 
[ABSTRACT] 2005年から2017年にかけて1億4700万人の会話についてトレーニングを受けました。新世代の人間対話システムをトレーニングしています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-01">
        <br>2019-11-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Generate, Delete and Rewrite: A Three-Stage Framework for Improving
  Persona Consistency of Dialogue Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_35.html">
      Generate, Delete and Rewrite: A Three-Stage Framework for Improving
  Persona Consistency of Dialogue Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人間のような応答の生成に関する既存のペルソナベースのモデルの成功にもかかわらず、それらの1段階のデコードフレームワークでは、一貫性のないペルソナ単語の生成をほとんど回避できません。人間と自動の両方のメトリックによる評価を実行します。ペルソナの実験チャットデータセットは、私たちのアプローチが優れたパフォーマンスを達成していることを示しています。 
[要旨]人間ベースの対話生成タスクが導入され、人間-一貫性のない応答に対処します。この作業では、生成された応答プロトタイプから一貫性のない単語をデコードし、さらにパーソナリティ-一貫性に書き換える3段階のフレームワークを紹介します1
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Endowing Empathetic Dialogue Systems with Personas -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_36.html">
      Endowing Empathetic Dialogue Systems with Personas
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、まず、ペルソナとの共感的な対話のための新しい大規模マルチドメインデータセットを提示します。次に、データセットで最先端のパフォーマンスを取得する効率的なBERTベースの応答選択モデルであるCoBERTを提案します。最後に、私たちは広範な実験を行って、ペルソナが共感的な応答に与える影響を調査します。 
[ABSTRACT]ペルソナとの対話型対話システムは、ペルソナとの共感型対話システムを提供するための新しいタスクです。これは、ペルソナとペルソナの影響に関する最初の研究です。次に、状態を取得する効率的なベルトベースの応答選択モデルであるcobertを提案しますデータセットの共感パフォーマンスの
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-26">
        <br>2020-04-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Don't Let Me Be Misunderstood: Comparing Intentions and Perceptions in
  Online Discussions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_37.html">
      Don't Let Me Be Misunderstood: Comparing Intentions and Perceptions in
  Online Discussions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      感情や主観性などの特性を定量化するためにサードパーティのラベルに大きく依存してきたオンラインディスカッションの以前の研究とは異なり、私たちのアプローチは、コメントを書くときにスピーカーが実際に意図したものを直接キャプチャします。発話およびその発話に対する他者の認識..特に、これらの概念はしばしば混乱していることが示されたため、コメントが事実または意見を述べているかどうかの判断に焦点を当てています。 
[ABSTRACT]人々は意図するよりも意見を知覚する可能性が高くなります。意図するよりもコメントにつながる人が多くなります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: How Does NLP Benefit Legal System: A Summary of Legal Artificial
  Intelligence -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_38.html">
      How Does NLP Benefit Legal System: A Summary of Legal Artificial
  Intelligence
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの作業の実装は、https：//github.com/thunlp/legal_theme。から見つけることができます。法務専門家およびNLP研究者の観点からタスクを説明し、LegalAIでいくつかの代表的なアプリケーションを示します。実験を行い、既存の作品の長所と短所を詳細に分析し、将来の方向性を探ります。 
[ABSTRACT] legalaiは、法務専門家を迷路の事務処理から解放するための法制度に有益です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-25">
        <br>2020-04-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Self-supervised Learning of Visual Speech Features with Audiovisual
  Speech Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_39.html">
      Self-supervised Learning of Visual Speech Features with Audiovisual
  Speech Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの結果は、視聴覚音声強調の重要な側面についての洞察を提供し、そのようなモデルが視覚音声アプリケーションの自己監視タスクにどのように使用できるかを示しています。音声アプリケーション..視覚的機能が音声活動に関する高レベルの情報を提供するだけではないことを示します。つまり、
[要約]口形素（音素への視覚的な類似）を分類するための学習された視覚表現の有効性を示しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-25">
        <br>2020-04-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An Effective Transition-based Model for Discontinuous NER -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_40.html">
      An Effective Transition-based Model for Discontinuous NER
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      一般的なドメインで広く使用されているNamed Entity Recognition（NER）データセットとは異なり、生物医学NERデータセットには、不連続なスパンからなる言及が含まれていることがよくあります。 3つの生物医学データセットで、連続した言及の正確さを犠牲にすることなく、モデルが不連続な言及を効果的に認識できることを示しています。 
[ABSTRACT] netroenは、継続的な言及の正確さを犠牲にすることなく、モデルが不連続な言及を認識できると主張しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On the Importance of Word and Sentence Representation Learning in
  Implicit Discourse Relation Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_41.html">
      On the Importance of Word and Sentence Representation Learning in
  Implicit Discourse Relation Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      広範な実験は、提案されたモデルがPDTBデータセットでBERTおよびその他の最先端システムより約8％、CoNLL 2016データセットで約16％優れていることを示しています。強力な文脈化表現モジュールである双方向マルチパースペクティブマッチングモジュール、およびグローバル情報融合モジュールはすべて暗黙的な談話分析にとって重要です。また、暗黙的な談話関係分類タスクにおけるさまざまなモジュールの有効性を分析し、表現学習のさまざまなレベルが結果にどのように影響するかを示します。 
[要約]システムはモジュールを組み合わせることが提案されています。テキストメッセージは、表現学習のさまざまなレベルが結果にどのように影響するかを説明するのに役立ちます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br>2020-04-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Semantics-Aware Inferential Network for Natural Language Understanding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_42.html">
      Semantics-Aware Inferential Network for Natural Language Understanding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SAINの推論モジュールは、明示的なコンテキスト化されたセマンティクスを補完的な入力として受け取り、注意メカニズムを通じてセマンティックな手がかりに対する一連の推論ステップを可能にします。は、パフォーマンスをよりよく理解するための関係するモデリングの有利な機能です。フロントエンドエンコーダーとしての事前トレーニング済みの言語モデルに関して、このモデルは、機械読み取りの理解や自然言語の推論など、11のタスクで大幅な改善を実現します。 
[ABSTRACT]推論ネットワーク（sain）は、人々が理解するためのツールとして使用できます。それは、私たちの言語を理解するための1つの方法である可能性があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving BERT with Self-Supervised Attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_43.html">
      Improving BERT with Self-Supervised Attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      経験的に、さまざまなパブリックデータセットで、SSA拡張BERTモデルを使用してパフォーマンスの大幅な改善を示しています。具体的には、SSAは前の反復から微調整されたモデルを「プローブ」することにより、弱いトークンレベルの注意ラベルを繰り返し自動的に生成します。 SSAをBERTに統合する2つの異なる方法を調査し、それらの利点を組み合わせるハイブリッドアプローチを提案します。 
[ABSTRACT]微調整されたパフォーマンスモデルは、多くの場合、拡張データセットにオーバーフィットします。ただし、微調整されたパフォーマンスはしばしばオーバーフィットするため、課題が1つ残っています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The Curse of Performance Instability in Analysis Datasets: Consequences,
  Source, and Suggestions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_44.html">
      The Curse of Performance Instability in Analysis Datasets: Consequences,
  Source, and Suggestions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、分析検証セットと標準検証セットの間の予想よりも低い相関関係を観察し、現在のモデル選択ルーチンの有効性に疑問を投げかけています。次に、2番目の質問に答えるために、ソースに関する理論的説明と経験的証拠の両方を示します不安定性の主な原因は、分析セット内のサンプル間の高い相関関係にあることを示しています。最初の質問では、分析セットに対して徹底的な実証研究を行い、不安定な最終パフォーマンスに加えて、すべての不安定性が存在することがわかりました。トレーニング曲線に沿って。 
[ABSTRACT]これは、不安定性がこれらの分析セットに基づいて作成された結論の信頼性にどのように影響するかについて3つの質問を提起します。この不安定性をどのように処理する必要があるか、およびいくつかの潜在的な解決策は何ですか？
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On the Reliability of Test Collections for Evaluating Systems of
  Different Types -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_45.html">
      On the Reliability of Test Collections for Evaluating Systems of
  Different Types
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      主に語彙の類似性に基づく従来の方法とは対照的に、単語の埋め込み）と高度な表現では、元のプーリングで識別されなかったさまざまな種類の関連ドキュメントが返される場合があります。その場合、従来の方法を使用して構築されたテストコレクションは、これは、ディープラーニング（ニューラル）システムの偏った評価結果と不公平な評価結果につながります。これは、再利用可能な評価に大きな課題を提起します。しかし最近まで、これにはディープラーニングシステムは含まれていませんでした。テストでは、従来のシステムに基づくプーリングは偏った評価しかできないことを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Showing Your Work Doesn't Always Work -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_46.html">
      Showing Your Work Doesn't Always Work
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      現在の研究では、この論文を批判的に検討します。それらの推定量に偏りがあり、エラーが発生しやすいという仮定を使用していることを分析的に示します。 
[ABSTRACT]最適に調整されたモデルは、模範的な出版物でテストされることが期待されています。このアプローチにはトークンの落とし穴と警告があります。当社のコードベースはwwwにあります。 github。 com / castorini / meanmax。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Deep Conversational Recommender Systems: A New Frontier for
  Goal-Oriented Dialogue Systems -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_47.html">
      Deep Conversational Recommender Systems: A New Frontier for
  Goal-Oriented Dialogue Systems
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、この活気に満ちた領域の今後の方向性について説明します。この作業では、CRSの最近の進化の要約を提供します。ここでは、深層学習アプローチがCRSに適用され、実りある結果がもたらされています。自然言語処理技術を利用するレコメンダーシステムは多くの注目を集めており、そのアプリケーションの1つに会話型レコメンダーシステム（CRS）があります。 
[ABSTRACT]会話の深い推奨事項の開発に加えて、CRSはインタラクティブな対話による会話を通じてユーザーの好みを学習およびモデル化します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: LogicalFactChecker: Leveraging Logical Operations for Fact Checking with
  Graph Module Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_48.html">
      LogicalFactChecker: Leveraging Logical Operations for Fact Checking with
  Graph Module Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、異種グラフが作成され、テーブルとプログラムの構造だけでなく、異なるモダリティを持つ入力間の接続もキャプチャされます。このグラフは、Transformerベースのアーキテクチャで単語のグラフ拡張コンテキスト表現を取得するために使用されます。テキストとしてのステートメントとテーブルを入力として使用して、LogicalFactCheckerは自動的にプログラムを導出します（別名
[ABSTRACT] logicalfactalicker、ニューラルネットワークは、ファクトチェックに論理演算を利用できます。これは、トランスフォーマー上に構築されたグラフモジュールネットワークによって実現されます-変圧器上に構築-ベースのアーキテクチャ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: $R^3$: Reverse, Retrieve, and Rank for Sarcasm Generation with
  Commonsense Knowledge -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_49.html">
      $R^3$: Reverse, Retrieve, and Rank for Sarcasm Generation with
  Commonsense Knowledge
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人間の評価によると、私たちのシステムは、34％は人間のアノテーターよりも皮肉を生成し、90％は強化されたハイブリッドベースラインよりも良い皮肉を生成します。常識知識に基づく意味的不一致は、より高品質の皮肉を生成します。非皮肉な入力文に基づく皮肉生成のための教師なしアプローチを提案します。 
[ABSTRACT]私たちの方法は、検索と編集のフレームワークを使用して、sarcasmの2つの主要な特性をインスタンス化します。価数の逆転と意味的な意味の不一致は、話者とリスナーの間で共有された常識または世界の知識を含むことができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: VD-BERT: A Unified Vision and Dialog Transformer with BERT -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_50.html">
      VD-BERT: A Unified Vision and Dialog Transformer with BERT
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      https://github.com/yuewang-cuhk/VD-BERT。で、このペーパーからの結果を再現するためのコードと事前トレーニング済みモデルをリリースします。さらに重要なことに、視覚的に接地された視覚とダイアログコンテンツの効果的な融合のためにBERTを採用しています。トレーニング..対照的に、この作業では、VD-BERTを提案します。これは、ビジュアルダイアログタスクの事前トレーニング済みBERT言語モデルを活用する、統一されたビジョンダイアログトランスフォーマーのシンプルで効果的なフレームワークです。 
[ABSTRACT]私たちのモデルは、ビジュアルダイアログを通じて新しい最先端の技術を提供します。シングルモデルとアンサンブルペーパーの両方でトップの位置を獲得しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploiting Cross-Lingual Subword Similarities in Low-Resource Document
  Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_51.html">
      Exploiting Cross-Lingual Subword Similarities in Low-Resource Document
  Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      関連言語からの文字レベルの知識の伝達がテキスト分類に役立つかどうかを調査します。テキスト分類は、ラベル付けされたトレーニングデータのない低リソース言語で適用する必要がある場合があります。実験により、文字レベルの知識伝達はデータよりも効率的であることが確認されています関連する言語間の単語レベルの転送。 
[ABSTRACT]クロスリンガルドキュメント分類フレームワーク（caco）は、文字ベースの埋め込みと単語ベースの分類子を使用します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-22">
        <br>2018-12-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On Extractive and Abstractive Neural Document Summarization with
  Transformer Language Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_52.html">
      On Extractive and Abstractive Neural Document Summarization with
  Transformer Language Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      要約を生成する前に簡単な抽出ステップを実行します。これを使用して、要約を生成する前に関連情報に基づいてトランスフォーマー言語モデルを条件付けします。また、このアプローチでは、より高いルージュスコアを達成しながら、コピーメカニズムを使用する以前の作業と比較して、より抽象的な要約が生成されることも示しています。 
[ABSTRACT]要約を生成する前に簡単な抽出ステップを実行します。次に、関連情報に基づいて変換言語モデルを条件付けるために使用されます。このアプローチは、より抽象的な要約を生成します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-07">
        <br>2019-09-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Recipes for building an open-domain chatbot -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_53.html">
      Recipes for building an open-domain chatbot
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのレシピのバリエーションを90M、2.7B、および9.4Bパラメータモデルで構築し、モデルとコードを総称してBlenderという名前で一般公開します。人間の評価では、最良のモデルがマルチターンダイアログの既存のアプローチよりも優れていることを示しています。次に、私たちのモデルの失敗例を分析することにより、この作業の限界について説明します。 
[ABSTRACT]人間の評価によると、私たちの最高のモデルは、マルチターンの対話における既存のアプローチよりも優れている
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unnatural Language Processing: Bridging the Gap Between Synthetic and
  Natural Language Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_54.html">
      Unnatural Language Processing: Bridging the Gap Between Synthetic and
  Natural Language Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      自然発話に一般化するために、学習された文の埋め込みを使用して距離メトリックを定義することにより、自然言語発話の投影を合成言語のサポートに自動的に見つけます。これらの結果は、シミュレーションから実際の転送がNLPを開発するための実用的なフレームワークであることを示唆しています。アプリケーション、および転送用の改善されたモデルは、ダウンストリームタスクで広範囲の改善を提供する可能性があります。合成トレーニングデータのみを使用することにより、私たちのアプローチは、いくつかのドメインの自然言語データでトレーニングされた最先端のモデルと一致またはパフォーマンスを向上させます。 
[ABSTRACT]合成データ生成手順から始め、データジェネレーターによって生成された発話を解釈できるモデルをトレーニングします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Not All Claims are Created Equal: Choosing the Right Statistical
  Approach to Assess Hypotheses -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_55.html">
      Not All Claims are Created Equal: Choosing the Right Statistical
  Approach to Assess Hypotheses
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      一歩前進として、NLP研究に合わせたベストプラクティスとガイドライン、および仮説のベイズ評価のための「HyBayes」と呼ばれる使いやすいパッケージを提供し、既存のツールを補完します。これは、一般的な誤解、誤解、仮説の評価方法を取り巻く誤解は、主張したいものと実際に使用されている方法が実際に評価するものとの間の不一致に起因することがよくあります。これらの問題は、NLPの研究コミュニティに遍在していることがわかりました。 
[ABSTRACT]代替案は他の分野でも十分に議論され採用されていますが、nlp研究コミュニティ内で議論または使用されることはほとんどありません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br>2019-11-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Extending Multilingual BERT to Low-Resource Languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/cs.CL/paper_56.html">
      Extending Multilingual BERT to Low-Resource Languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、M-BERT（E-BERT）を拡張して新しい言語にメリットをもたらすシンプルで効果的なアプローチを提案し、このアプローチがすでにM-BERTにある言語にもメリットをもたらすことを示します。多言語BERT （M-BERT）は、教師ありとゼロショットのクロスリンガル転移学習の両方で大成功を収めています。27の言語でNamed Entity Recognition（NER）を使用して広範なセットの実験を行います。 BERT、およびすでにM-BERTにある言語では平均F1が約6％増加し、新しい言語ではF1が23％増加します。 
[ABSTRACT]私たちは27の言語で広範な実験を行いました。そのうちの16のみがm-bertにあります。これは、すでにm-bertにある言語で平均約6％f1増加し、新しい言語で23％増加していることを示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: ASMD: an automatic framework for compiling multimodal datasets with
  audio and scores -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/eess.AS/paper_0.html">
      ASMD: an automatic framework for compiling multimodal datasets with
  audio and scores
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、特定の属性（作曲家や楽器などの共通部分や和集合など）に基づくブール集合演算を介してデータセットにアクセスするためのPython APIを提供しています。すべてのコードとグラウンドトゥルースは、適切なオープンライセンスの下でリリースされています。このペーパーでは、音楽処理タスクのデータセットを処理するためのオープンソースのPythonフレームワークについて説明します。このフレームワークは、音楽コンピューティングにおける研究プロジェクトの再現性の向上と機械学習モデルの一般化機能の評価を目的として構築されています。 
[要約]フレームワークは、新しいデータセットを簡単に含めることができるように設計されています。ツールは、ユーザーが独自のコレクションを構築、変換、および拡張できるように設計されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-04">
        <br>2020-03-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Blind Audio Source Separation with Minimum-Volume Beta-Divergence NMF -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/eess.AS/paper_1.html">
      Blind Audio Source Separation with Minimum-Volume Beta-Divergence NMF
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは、$ \ beta $ -divergencesの最小化と、ディクショナリマトリックスの列のボリュームを小さくするペナルティ項に基づいています。いくつかの穏やかな仮定とノイズのない条件下で、このモデルが証明可能であることを証明しますソースを特定するために。このタスクにより適した新しいNMFモデルを提示します。 
[要約]非負性行列因数分解は、時間と信号の周波数表現を使用する標準および最先端の技術です。これは、$＆beta $の最小化に基づいています-発散と、列の列を促進するペナルティ項小さなボリュームを持つ辞書行列
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-04">
        <br>2019-07-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Data Efficient Direct Speech-to-Text Translation with Modality Agnostic
  Meta-Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/eess.AS/paper_2.html">
      Data Efficient Direct Speech-to-Text Translation with Modality Agnostic
  Meta-Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      多言語音声翻訳コーパス（MuST-C）からの英語-ドイツ語（En-De）と英語-フランス語（En-Fr）言語のペアでのSTタスクの提案されたメタ学習アプローチを評価します。転送学習アプローチを使用して上記の困難を克服します。エンドツーエンドの音声翻訳（ST）モデルには、自動音声認識（ASR）を組み合わせた従来のパイプラインと比較して、レイテンシが低い、モデルサイズが小さい、エラーの複合が少ないなどのいくつかの利点があります。テキスト機械翻訳（MT）モデル。 
[ABSTRACT] stタスクは、asrおよびmtタスクよりも困難です。これらのアプローチは、教師付きの弱いトレーニングデータから恩恵を受けます。ただし、新しい方法は、以前の転移学習アプローチよりも優れています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/eess.AS/paper_3.html">
      Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのレイテンシを削減するために、最近提案された接頭辞から接頭辞へのフレームワークに基づいて、最初のニューラル増分TTSアプローチを考案します。音声をオンライン形式で合成し、音声のセグメントを再生しながら次のセグメントを生成し、$ O（ 1）$ O（n）$レイテンシではなく$。音声合成（TTS）は近年急速に進歩しており、ニューラル方式では自然性の高いオーディオを生成できるようになりました。 
[要約]これらの取り組みには、2つのタイプのレイテンシがまだあります。これらには、「合成時間」が含まれます。これは、並列アプローチでも、文の長さに比例して増加します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-07">
        <br>2019-11-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Speech Separation Using Spatially Distributed Microphones -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/eess.AS/paper_4.html">
      Neural Speech Separation Using Spatially Distributed Microphones
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたネットワークは、これらの2種類のレイヤーを交互に積み重ねることにより、時間と空間にわたって情報を活用します。これを克服するために、チャネル間処理レイヤーと時間処理レイヤーをインターリーブする新しいネットワークアーキテクチャが提案されます。時間処理レイヤーは、双方向長期短期記憶（BLSTM）モデルであり、各チャネルに個別に適用されます。 
[要約]提案されたネットワークは、固有のネットワークを使用するマイクのネットワークを使用するネットワークを利用するために使用できます。ネットワークは現在、音声認識を可能にするために複数の複数の複数のネットワークを使用しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Adversarial Feature Learning and Unsupervised Clustering based Speech
  Synthesis for Found Data with Acoustic and Textual Noise -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/eess.AS/paper_5.html">
      Adversarial Feature Learning and Unsupervised Clustering based Speech
  Synthesis for Found Data with Acoustic and Textual Noise
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最先端の音声強調モデルに基づくノイズ除去アプローチを超えて、ノイズの多いデータに基づいて構築されたシステムは、クリーンな対応物上に構築されたシステムに近いMOSでクリーンで高品質の音声を合成できます。側のノイズについては、敵対的なトレーニングとデータ拡張を通じて、自己回帰デコーダーのノイズに依存しない機能を学習することを提案します。これには、追加の音声強調モデルは必要ありません。実験は、テキストを扱う際の提案されたアプローチの有効性を示しています。側と音声側のノイズ。 
[要約]提案されたシステムは、通信コミュニケーションの欠如に基づいています。たとえば、vqvaeベースのヒューリスティック手法を提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Self-supervised Learning of Visual Speech Features with Audiovisual
  Speech Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/eess.AS/paper_6.html">
      Self-supervised Learning of Visual Speech Features with Audiovisual
  Speech Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの結果は、視聴覚音声強調の重要な側面についての洞察を提供し、そのようなモデルを視覚音声アプリケーションの自己監視タスクにどのように使用できるかを示しています。この発見の興味深い副産物は、学習した視覚埋め込みを他の視覚的埋め込みの機能として使用できることです音声アプリケーション..私たちは視聴覚音声強調モデルの内省を提示します。 
[要旨]口形素を分類するための学習された視覚表現の有効性を実証しました（音素への視覚的な類似）
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-25">
        <br>2020-04-25
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Functionally reversible organ shrinkage in rotifers and its modulation by a human-type aggregate -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-29/biorxiv.physiology/paper_0.html">
      Functionally reversible organ shrinkage in rotifers and its modulation by a human-type aggregate
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      絶食したワムシの両側性生殖器官（germovitellaria）の経験的に理解しやすいサイズの縮小は、A {beta} 42によって救助され、器官収縮期の栄養源およびペプチドシーケンス固有の減衰器として機能し、卵の再生を含む再生型。特定の規制の役割を持つ有名な神経毒性A {beta} 42（bdelloidsを除く）とは対照的に、人工的に設計されたスクランブルバージョン（アミノ酸のランダムな順序）は、自己異化作用の減衰において非効率的であり、ネガティブコントロール..我々は、グルコースサイズの飢餓モデルで、A {beta} 42によって引き起こされる自己異化関連の変化を探索する、臓器サイズに基づくin vivoモニタリングシステムを再適用しました。 
[ABSTRACT] autocatabolismはautocatabolismを制御します-autocatabolism.autocatabolismに関連する変更は、germovitellariaの損失につながるautocatabolismに関連しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
