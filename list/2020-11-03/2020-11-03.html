<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-11-03の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Guided multi-branch learning systems for sound event detection with
  sound separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.SD/paper_0.html">
      <font color="black">Guided multi-branch learning systems for sound event detection with
  sound separation</font>
    </a>
  </h2>
  <font color="black">したがって、さまざまな目的を追求し、データのさまざまな特性に焦点を当てた複数のブランチは、機能エンコーダーが機能空間をより適切にモデル化し、過剰適合を回避するのに役立ちます。システムは、DCASE2019タスク4の1位システムに基づいています。注意ベースの埋め込みレベルのプーリングモジュールとガイド付き学習という半教師あり学習アプローチを備えた弱教師ありフレームワーク。音分離（SS）と音イベント検出（SED）を組み合わせるために、SEDシステムの結果をSSと融合します。 -SSシステムによって分離されたサウンド出力を使用してトレーニングされたSEDシステム。 
[概要]システムは、dcase 2019タスク4の最初の場所のシステムに基づいています。それは、不十分な-注意を払った監視ありフレームワーク-ベースの埋め込み-レベルプーリングモジュールと、ガイド付き学習という名前の半教師あり学習アプローチを採用しています。モデルの同じ機能エンコーダーを共有する、さまざまなプーリング戦略とさまざまなプーリングモジュール</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-21">
        <br><font color="black">2020-07-21</font>
      </time>
    </span>
</section>
<!-- paper0: An Audio-Video Deep and Transfer Learning Framework for Multimodal
  Emotion Recognition in the wild -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.SD/paper_1.html">
      <font color="black">An Audio-Video Deep and Transfer Learning Framework for Multimodal
  Emotion Recognition in the wild</font>
    </a>
  </h2>
  <font color="black">この論文では、ABAWの表情チャレンジへの貢献を紹介します。エンドツーエンドのディープラーニングを使用し、転移学習アプローチの恩恵を受けて、42.10％のテストセットチャレンジパフォーマンス測定に到達しました。提案されたシステムとチャレンジプロトコルに準拠した公式のチャレンジ結果。 
[概要]提案システムと公式チャレンジ結果を報告します。公式結果も報告します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-07">
        <br><font color="black">2020-10-07</font>
      </time>
    </span>
</section>
<!-- paper0: Prediction of head motion from speech waveforms with a
  canonical-correlation-constrained autoencoder -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.SD/paper_2.html">
      <font color="black">Prediction of head motion from speech waveforms with a
  canonical-correlation-constrained autoencoder</font>
    </a>
  </h2>
  <font color="black">MFCCベースのシステムと比較して、提案されたシステムは、客観的評価で同等のパフォーマンスを示し、被験者評価でより良いパフォーマンスを示します。この問題を克服するために、隠れ層がトレーニングされる正準相関制約付き自動エンコーダー（CCCAE）を提案します。エラーを最小化するだけでなく、頭の動きとの正準相関を最大化します。この研究では、音声駆動の頭の動きの合成のために頭の動きを予測するための音声波形の直接使用を調査しますが、基本的な入力としてMFCCなどのスペクトル機能を使用します。エネルギーやF0などの追加機能とともに機能は文献で一般的です。 
[概要]新しい研究では、波形が頭の動きを予測するのにより効果的であることが示されています。エラーを最小限に抑えるために新しいシステムが使用されたのはこれが初めてである可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-05">
        <br><font color="black">2020-02-05</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Normalization for Speaker Vectors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.SD/paper_3.html">
      <font color="black">Deep Normalization for Speaker Vectors</font>
    </a>
  </h2>
  <font color="black">これらの実験では、DNFベースの正規化によりパフォーマンスが大幅に向上し、ドメイン外テストでも強力な一般化機能が示されました。これらの不規則な分布は、特に、均一なガウス分布を想定する一般的なPLDAスコアリング方法で、話者認識パフォーマンスに深刻な影響を与える可能性があります。分布..広く使用されているSITWおよびCNCelebコーパスを使用した実験で、提案されたアプローチの有効性を示します。 
[概要]この論文は、新しい識別正規化フロー（dnf）モデルに基づく深い正規化アプローチを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br><font color="black">2020-04-07</font>
      </time>
    </span>
</section>
<!-- paper0: Quasi-Periodic Parallel WaveGAN: A Non-autoregressive Raw Waveform
  Generative Model with Pitch-dependent Dilated Convolution Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.SD/paper_4.html">
      <font color="black">Quasi-Periodic Parallel WaveGAN: A Non-autoregressive Raw Waveform
  Generative Model with Pitch-dependent Dilated Convolution Neural Network</font>
    </a>
  </h2>
  <font color="black">客観的および主観的な実験結果は、補助$ F_ {0} $機能がスケーリングされたときにQPPWGがPWGよりも優れていることを示しています。さらに、QPPWGの中間出力の分析は、スペクトルと励起をそれぞれモデル化するQPPWGのより優れた扱いやすさと解釈可能性も示しています。 QP構造のカスケードされた固定および適応ブロックを使用する信号のように..PWGは忠実度の高い音声生成を実現しますが、一般的で単純なネットワークアーキテクチャには、次のような目に見えない補助基本周波数（$ F_ {0} $）機能のピッチ制御性がありません。スケーリングされた$ F_ {0} $。 
[ABSTRACT] pwgは、小さい-フットプリントganベースの生の波形生成モデルです。コンパクトなモデルと非自己回帰（非-ar）および非因果的メカニズムにより、生成時間はリアルタイムよりもはるかに高速です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-25">
        <br><font color="black">2020-07-25</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Multi-Modal Active Learning for Automatic Liver Fibrosis Diagnosis based
  on Ultrasound Shear Wave Elastography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.IV/paper_0.html">
      <font color="black">Multi-Modal Active Learning for Automatic Liver Fibrosis Diagnosis based
  on Ultrasound Shear Wave Elastography</font>
    </a>
  </h2>
  <font color="black">米国と3種類のせん断波エラストグラフィ（SWE）を含む4つの画像モダリティが活用されています。実験結果は、提案された方法が30％未満のデータを使用し、約80％のみを使用することにより、最先端のパフォーマンスを上回っていることを示しています。データ、提案された融合ネットワークは、高いAUC 89.27％と精度70.59％を達成します。ノイズの多いデータ、米国の画像の高価な注釈のため、人工知能（AI）支援アプローチのアプリケーションはボトルネックに遭遇します。 
[概要]アプローチを支援する人工知能（ai）のアプリケーションがボトルネックに遭遇します。この方法では、複数のモダリティの情報を活用する必要があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Clinical Evaluation of Real-Time Optical-Tracking Navigation and Live
  Time-Intensity Curves to Provide Feedback During Blinded 4D Contrast-Enhanced
  Ultrasound Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.IV/paper_1.html">
      <font color="black">Clinical Evaluation of Real-Time Optical-Tracking Navigation and Live
  Time-Intensity Curves to Provide Feedback During Blinded 4D Contrast-Enhanced
  Ultrasound Imaging</font>
    </a>
  </h2>
  <font color="black">この設定をテストするために、5人の経験豊富なオペレーターに、EPIQ7システムに接続されたX6-1を使用してBモード画像でボランティア肝臓内の画像ランドマークを見つけるように依頼しました。対照的に、追跡フィードバックの平均変位は同等でした。 3.48 mm（SD。0.8mm）でBモードに。 
[概要]この研究の目的は、トランスデューサートラッキングを使用して位置決めフィードバックを提供し、画像を再調整して定量化を改善することを調査することでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: ASIST: Annotation-free synthetic instance segmentation and tracking for
  microscope video analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.IV/paper_2.html">
      <font color="black">ASIST: Annotation-free synthetic instance segmentation and tracking for
  microscope video analysis</font>
    </a>
  </h2>
  <font color="black">実験結果から、提案された注釈なしの方法は、教師あり学習と比較して優れたパフォーマンスを達成しました。この論文の貢献は3つあります。（1）新しい注釈なしのビデオ分析パラダイムを提案します。監視ありピクセル埋め込みベースの方法を顕微鏡ビデオに適用することの制限は、リソースを大量に消費する手動ラベリングです。これには、ビデオフレーム全体での時間的関連を伴う数百のオーバーラップしたオブジェクトのトレースが含まれます。 
[要約]注釈の導入-細胞内微絨毛の顕微鏡ビデオを分析するための無料の合成インスタンスセグメンテーションおよび追跡（アシスト）アルゴリズム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Statistical Analysis of Signal-Dependent Noise: Application in Blind
  Localization of Image Splicing Forgery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.IV/paper_3.html">
      <font color="black">Statistical Analysis of Signal-Dependent Noise: Application in Blind
  Localization of Image Splicing Forgery</font>
    </a>
  </h2>
  <font color="black">完全なブラインド検出を確実にするために、反復交互法を採用してMRFパラメータを推定します。SDNモデルの統計分析を通じて、ノイズを特定の明るさのガウス近似としてモデル化できると仮定し、ノイズレベル関数..この作業では、SDNをスプライシング偽造ローカリゼーションタスクに適用します。 
[ABSTRACT]ノイズは、推定され、異常を明らかにするために使用される加法性ガウスモデルを含むと想定されます。ただし、たとえば、この方法は効果的であり、相対的なローカリゼーションパフォーマンスパフォーマンスを提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-30">
        <br><font color="black">2020-10-30</font>
      </time>
    </span>
</section>
<!-- paper0: SIMDive: Approximate SIMD Soft Multiplier-Divider for FPGAs with Tunable
  Accuracy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.IV/paper_4.html">
      <font color="black">SIMDive: Approximate SIMD Soft Multiplier-Divider for FPGAs with Tunable
  Accuracy</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、フィールドプログラマブルゲートアレイ（FPGA）を対象とした、調整可能な精度を備えた新しい乗算器と除算器に基づくSIMDアーキテクチャを初めて紹介します。Vivado、マルチメディア、およびDNNアプリケーションから得られた実験結果は、提案されたアーキテクチャの優位性を示しています（特に、提案されたSISD分周器は、ザイリンクスが提供する正確なIntellectual Property（IP）分周器よりも、4倍高速、4.6倍少ないエネルギーで、許容範囲のみを上回っています。 &lt;0.8％エラー。 
[概要]提案されたハイブリッドアーキテクチャは、エネルギーを軽減するために使用されています。これは、主要なリソースリソース要件としてエネルギーを軽減するのに役立ちます。現在、単純な単純化で開発されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: A Deep Learning Study on Osteosarcoma Detection from Histological Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.IV/paper_5.html">
      <font color="black">A Deep Learning Study on Osteosarcoma Detection from Histological Images</font>
    </a>
  </h2>
  <font color="black">より信頼できるパフォーマンスを実現するには、CNNを大量のデータでトレーニングする必要があります。この研究では、転送学習手法である事前トレーニング済みのCNNを骨肉腫の組織画像の公開データセットに適合させて、非骨肉腫の壊死画像を検出します。 -壊死性で健康な組織..本研究の目的は、コンピューター支援検出（CAD）と診断（CADx）を使用して骨肉腫の検出と診断を改善することです。 
[概要]骨肉腫は米国で最も一般的な骨腫瘍です。骨肉腫は最も一般的なタイプの骨腫瘍です。骨肉腫は畳み込みニューラルネットワークによって制御できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-Relaxed Quantization with DropBits: Training Low-Bit Neural
  Networks via Bit-wise Regularization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.IV/paper_6.html">
      <font color="black">Semi-Relaxed Quantization with DropBits: Training Low-Bit Neural
  Networks via Bit-wise Regularization</font>
    </a>
  </h2>
  <font color="black">この問題を解決するために、マルチクラスのストレートスルー推定量を使用してバイアスと分散を効果的に低減する新しい方法であるSemi-Relaxed Quantization（SRQ）と、ドロップアウト正則化を置き換えてランダムにドロップする新しい正則化手法であるDropBitsを提案します。 SRQのマルチクラスストレートスルー推定量のバイアスをさらに減らすために、ニューロンの代わりにビットを使用します。さまざまなベンチマークデータセットとネットワークアーキテクチャでメソッドを実験的に検証し、量子化された宝くじチケットの仮説をサポートします。同じであるが固定された量子化レベルを最初から使用する場合..DropBitsの自然な拡張として、DropBitsを使用して各層の適切なビット長を見つけるために異種の量子化レベルを学習する方法をさらに紹介します。 
[ABSTRACT]緩和された量子化はバイアスを減らす新しい方法です。この方法は異なるタイプの量子化の異なるレベルを学習することを含みます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-29">
        <br><font color="black">2019-11-29</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning in Computer-Aided Diagnosis and Treatment of Tumors: A
  Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.IV/paper_7.html">
      <font color="black">Deep Learning in Computer-Aided Diagnosis and Treatment of Tumors: A
  Survey</font>
    </a>
  </h2>
  <font color="black">次に、腫瘍の診断と治療の4つの段階における最近の進歩を要約します。これは、体外診断（IVD）、画像診断（ID）、病理診断（PD）、および治療計画（TP）と呼ばれます。特定のデータによると各段階の種類と医療タスク、腫瘍のコンピュータ支援診断と治療における深層学習の応用を提示し、その優れた研究を分析します。この調査は、研究課題を議論し、将来の改善のための課題を提案することによって終了します。 
[概要]これらには、主流のタスクシナリオで生成された正確なポジショニングと優れたパフォーマンスを備えた深層学習モデルが含まれます。これらには、invitro学習や治療などの詳細で詳細な深層学習技術が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Self-Supervised Methods for Medical Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.IV/paper_8.html">
      <font color="black">3D Self-Supervised Methods for Medical Imaging</font>
    </a>
  </h2>
  <font color="black">わずかな計算コストで最先端のソリューションに匹敵する結果を達成します。私たちの実験では、3Dタスクを使用してモデルを事前トレーニングすると、より強力なセマンティック表現が得られ、ダウンストリームタスクをより正確かつ効率的に解決できることが示されています。モデルを最初からトレーニングし、2Dスライスで事前トレーニングします。各タスクで、データ効率、パフォーマンス、および収束速度の向上を評価します。 
[概要]開発されたアルゴリズムは、3Dコントラスト予測コーディング、3D回転予測、3Dジグソーパズル、相対3Dパッチ位置、および3D模範ネットワークです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-06">
        <br><font color="black">2020-06-06</font>
      </time>
    </span>
</section>
<!-- paper0: Shack-Hartmann sensor as an imaging system with a phase diversity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.IV/paper_9.html">
      <font color="black">Shack-Hartmann sensor as an imaging system with a phase diversity</font>
    </a>
  </h2>
  <font color="black">シャックハルトマンセンサーの生データから波面を再構築する従来の方法では、焦点シフトを使用し、波面に関する高周波情報を破棄します。シミュレーションデータと実験データの両方でこのアプローチの有効性を示します。フェーズ-検索ベースの方法では、ハルトマンパターンを回折画像として扱い、レイリー-ゾンマーフェルト伝搬を使用して、より高い精度と解像度で波面を推定します。 
[ABSTRACT]モデルでは、位相追跡システムを使用して波面を再構築できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Parameter retrieval methods in ptychography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.IV/paper_10.html">
      <font color="black">Parameter retrieval methods in ptychography</font>
    </a>
  </h2>
  <font color="black">アプリケーション2については、長方形のパラメータの相関について説明します。計算結果を使用して、アプリケーション1のさまざまなノイズレベルの下限と粒子の相関を報告します。提案された方法は、2つのアプリケーションに適用されます。（1）パラメータフーリエプチコグラフ暗視野測定からの小さな粒子の検索; （2）実空間プチコグラフィーによるリタングルのパラメーター検索。 
[要約]提案された方法は2つのアプリケーションに適用されます。計算された下限を検証するために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Image Inpainting with Learnable Feature Imputation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.IV/paper_11.html">
      <font color="black">Image Inpainting with Learnable Feature Imputation</font>
    </a>
  </h2>
  <font color="black">学習された特徴の繰り込みとは対照的に、私たちの方法は効率的であり、最小限の数のパラメーターを導入します。ただし、これらのモデルは、特徴の繰り込みに大量の学習可能なパラメーターを使用するか、出力の確実性のバイナリ表現を想定します。 .. FDFデータセットの定量的評価は、修正された勾配ペナルティと代替コンボリューションにより、生成された画質が大幅に向上することを反映しています。 
[概要]以前の研究では、畳み込みの出力の機能の繰り込みが示されています。これらのモデルには、修正された意図されたフィルターと、敵対的損失のみでトレーニングされた新しいガンアーキテクチャが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: U-Net and its variants for medical image segmentation: theory and
  applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.IV/paper_12.html">
      <font color="black">U-Net and its variants for medical image segmentation: theory and
  applications</font>
    </a>
  </h2>
  <font color="black">U-netの可能性はまだ高まっているので、このレビューでは、U-netアーキテクチャで行われたさまざまな開発を見て、最近の傾向を観察します。さらに、U-netが存在する画像モダリティとアプリケーション領域を調べます。 -netが適用されました。U-netの成功は、CTスキャンやMRIからX線や顕微鏡までのすべての主要な画像モダリティで広く使用されていることから明らかです。 
[概要] u-netは、mriのチャンク化タスクの主要なツールです。他のアプリケーションでこのツールを使用する例があります。ディープラーニングで行われたさまざまなイノベーションを検証します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Genetic U-Net: Automatically Designing Lightweight U-shaped CNN
  Architectures Using the Genetic Algorithm for Retinal Vessel Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.IV/paper_13.html">
      <font color="black">Genetic U-Net: Automatically Designing Lightweight U-shaped CNN
  Architectures Using the Genetic Algorithm for Retinal Vessel Segmentation</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案された方法が3つの公開データセット、DRIVE、CHASE \ _DB1、STAREの既存の方法よりも優れていることを示しています。網膜血管セグメンテーションの深層学習に基づく以前の多くの研究は、U字型畳み込みニューラルネットワークを手動で設計することによって有望なパフォーマンスを達成しています（ CNN）..さらに、提案された方法によって得られたアーキテクチャは、最先端のモデルよりも軽量ですが正確です。 
[ABSTRACT] cnsは、検索スペースを駆動する遺伝的アルゴリズムに基づいています。この方法では、遺伝的アルゴリズムを使用して優れたアーキテクチャを検索します。これらは、最先端のモデルよりも軽量ですが正確です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: nnU-Net for Brain Tumor Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.IV/paper_14.html">
      <font color="black">nnU-Net for Brain Tumor Segmentation</font>
    </a>
  </h2>
  <font color="black">私たちの最終的なアンサンブルは、BraTS 2020コンテストで第1位になり、ダイススコアは88.95、85.06、82.03、HD95値は8.498、17.337、17.805で、腫瘍全体、腫瘍コア、強化腫瘍にそれぞれ適用されます。nnU-NetをBraTS 2020チャレンジのセグメンテーションタスク..後処理、地域ベースのトレーニング、より積極的なデータ拡張、およびnnUNetパイプラインへのいくつかのマイナーな変更に関するBraTS固有の変更を組み込むことにより、セグメンテーションパフォーマンスを大幅に向上させることができます。 
[概要]変更されていないnnu-ネットベースライン構成のスコアは良好です。bratsランキングの変更はbratsランキングの一部です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Observer Dependent Lossy Image Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.IV/paper_15.html">
      <font color="black">Observer Dependent Lossy Image Compression</font>
    </a>
  </h2>
  <font color="black">品質という用語は、大多数の文献で人間であると想定されている画像の観察者に決定的に依存します。これら2つの目的関数を組み合わせることにより、人間間の圧縮品質に顕著なトレードオフがあることを示します。視覚系と分類精度..私たちの広範な実験は、知覚損失関数を使用して圧縮システムをトレーニングすると、圧縮画像の分類器の再トレーニングを必要とせずに、BPGなどの従来のコーデックよりもはるかに優れた分類精度を維持することを示しています。 
[概要]調査によると、圧縮システムは分類精度を向上させることができます。人間に優しい損失関数を使用して圧縮システムをトレーニングします。これにより、従来のコーデックよりも分類精度が低下します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-08">
        <br><font color="black">2019-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Predicting Brain Degeneration with a Multimodal Siamese Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.IV/paper_16.html">
      <font color="black">Predicting Brain Degeneration with a Multimodal Siamese Neural Network</font>
    </a>
  </h2>
  <font color="black">この作業では、マルチモーダル学習用のニューラルネットワークアーキテクチャを紹介します。2つの時点からのイメージングと臨床データを使用して神経変性疾患の進展を予測でき、欠測値に対してロバストです。マルチモーダルネットワークは92.5 \％の精度と57人の被験者のテストセットで0.978のAUCスコア。一部のデータも欠落している可能性があります。 
[概要]マルチモーダル学習のためのニューラルネットワークアーキテクチャを紹介します。2つの時点からの画像と臨床データを使用して神経変性疾患の進展を予測でき、欠測値に対してロバストです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Data-free Knowledge Distillation for Segmentation using Data-Enriching
  GAN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.IV/paper_17.html">
      <font color="black">Data-free Knowledge Distillation for Segmentation using Data-Enriching
  GAN</font>
    </a>
  </h2>
  <font color="black">DeGANトレーニングフレームワークを利用して、少数のクラスが過小評価されている設定で多様性を適用するための新しい損失関数を提案します。さらに、データのない設定で知識蒸留を実行するための新しいトレーニングフレームワークを探索します。セグメンテーションに固有のいくつかの課題を特定します。 
[概要]真のトレーニングデータセットは、関連する知識を抽出するために使用されています。これらには、データで学習するための新しいトレーニングフレームワークが含まれています-無料の設定</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: What BERT Sees: Cross-Modal Transfer for Visual Question Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_0.html">
      <font color="black">What BERT Sees: Cross-Modal Transfer for Visual Question Generation</font>
    </a>
  </h2>
  <font color="black">さらに、BERTは主にエンコーダーとして設計されているため、タスクの生成の側面には適応が必要です。提案されたモデルは、2つの確立されたVQGデータセットの最新技術を大幅に改善しています。異なる構成で報告された結果は、利用可能なデータが少ない場合でも、BERT-genがマルチモーダルデータとテキスト生成に適応するための固有の機能により、費用のかかる事前トレーニングを回避できます。 
[ABSTRACT]テキスト生成用のbertベースのアーキテクチャであるbert-genは、モノモードまたはマルチモーダル表現を活用できます。提案されたモデルは、2つの確立されたデータセットの最新技術を大幅に改善します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-25">
        <br><font color="black">2020-02-25</font>
      </time>
    </span>
</section>
<!-- paper0: Gibbs Sampling with People -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_1.html">
      <font color="black">Gibbs Sampling with People</font>
    </a>
  </h2>
  <font color="black">マルコフ連鎖モンテカルロと人（MCMCP）は、そのような表現を研究するための優れた方法であり、参加者には、決定がマルコフ連鎖モンテカルロ受容規則に従うように構築されたバイナリ選択試行が提示されます。認知科学と機械のコア問題学習とは、人間が知覚オブジェクトから意味表現をどのように導き出すかを理解することです。たとえば、リンゴの色、音楽のコードからの心地よさ、顔からの深刻さなどです。ただし、MCMCPには強い漸近特性がありますが、そのバイナリ選択パラダイムは比較的少ない情報を生成します。試行ごとに、そのローカル提案関数により、パラメーター空間の探索と分布のモードの検索が遅くなります。 
[要約] mcmcpは、そのような表現を研究するための優れた方法です。参加者には、決定がマルコフ連鎖モンテカルロ受容規則に従うように構築されたバイナリ選択試行が提示されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-06">
        <br><font color="black">2020-08-06</font>
      </time>
    </span>
</section>
<!-- paper0: SketchEmbedNet: Learning Novel Concepts by Imitating Drawings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_2.html">
      <font color="black">SketchEmbedNet: Learning Novel Concepts by Imitating Drawings</font>
    </a>
  </h2>
  <font color="black">次に、それらを使用して、Omniglotおよびmini-ImageNetベンチマークでの教師なし数ショット分類の最先端のパフォーマンスを超えます。また、モデルの生成能力を活用して、以下に基づいた新しいクラスの高品質のスケッチを作成します。単一の例..以前の研究では、反復ニューラルネットワークが一度に単一または少数のクラスのスケッチ図を作成できることが示されています。 
[ABSTRACT]スケッチはリカレントニューラルネットワークによって開発されました。一度に1つまたは少数のクラスからスケッチ図面を作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding Anomaly Detection with Deep Invertible Networks through
  Hierarchies of Distributions and Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_3.html">
      <font color="black">Understanding Anomaly Detection with Deep Invertible Networks through
  Hierarchies of Distributions and Features</font>
    </a>
  </h2>
  <font color="black">CIFAR10のような自然画像データセットで最尤法を介してトレーニングされた深い生成ネットワークは、多くの場合、異なるオブジェクト（SVHNなど）を持つデータセットからの画像に高い尤度を割り当てます。コードはhttps://github.com/boschresearch/hierarchical_anomaly_detectionにあります。この方法は、適切な一般的なディストリビューションにアクセスできない場合に特に役立ちます。 
[概要]不満を持つネットワークは、自然なデータセットでトレーニングすると、同様の低レベルの特徴を学習します。これらの低レベルの特徴は、高レベルの違いの可能性を支配します。この方法は、適切な一般的な分布にアクセスできない場合に特に役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br><font color="black">2020-06-18</font>
      </time>
    </span>
</section>
<!-- paper0: Google Landmarks Dataset v2 -- A Large-Scale Benchmark for
  Instance-Level Recognition and Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_4.html">
      <font color="black">Google Landmarks Dataset v2 -- A Large-Scale Benchmark for
  Instance-Level Recognition and Retrieval</font>
    </a>
  </h2>
  <font color="black">グラウンドトゥルースの構築には、800時間以上の人間のアノテーター作業が含まれていました。画像検索とインスタンス認識技術は急速に進歩していますが、実際のアプリケーションに関連する新しい課題を提起しながら、パフォーマンスを正確に測定するためにデータセットに挑戦する必要があります。 。そのテストセットは、検索タスクと認識タスクの両方のグラウンドトゥルース注釈付きの118k画像で構成されています。 
[ABSTRACT] googleランドマークデータセットv2（gldv2）は、人間が作成した自然のランドマークのドメインでの大規模で細かい粒度のインスタンス認識と画像検索の新しいベンチマークです。テストセットは、グラウンドトゥルースアノテーション付きの118kの画像で構成されています。検索タスクと認識タスクの両方。新しいデータセットには、以前のデータセットでは考慮されていなかった実際のアプリケーションに触発されたいくつかの課題があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-03">
        <br><font color="black">2020-04-03</font>
      </time>
    </span>
</section>
<!-- paper0: Statistical Analysis of Signal-Dependent Noise: Application in Blind
  Localization of Image Splicing Forgery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_5.html">
      <font color="black">Statistical Analysis of Signal-Dependent Noise: Application in Blind
  Localization of Image Splicing Forgery</font>
    </a>
  </h2>
  <font color="black">完全なブラインド検出を確実にするために、反復交互法を採用してMRFパラメーターを推定します。ただし、実際のセンサーノイズの場合は、信号依存ノイズ（SDN）としてモデル化する必要があります。最大の後方マルコフランダムフィールドを構築することによって（MAP-MRF）フレームワークでは、ノイズの可能性を利用して、確率の組み合わせの改良戦略を使用して、スプライスされたオブジェクトのエイリアン領域を明らかにします。 
[ABSTRACT]ノイズは、推定され、異常を明らかにするために使用される加法性ガウスモデルを含むと想定されます。ただし、たとえば、この方法は効果的であり、相対的なローカリゼーションパフォーマンスパフォーマンスを提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-30">
        <br><font color="black">2020-10-30</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-Relaxed Quantization with DropBits: Training Low-Bit Neural
  Networks via Bit-wise Regularization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_6.html">
      <font color="black">Semi-Relaxed Quantization with DropBits: Training Low-Bit Neural
  Networks via Bit-wise Regularization</font>
    </a>
  </h2>
  <font color="black">さまざまなベンチマークデータセットとネットワークアーキテクチャでメソッドを実験的に検証し、量子化された抽選チケットの仮説もサポートします。異種の量子化レベルを学習することは、同じであるが固定された量子化レベルを最初から使用する場合よりも優れています。この問題を解決するために、新しい方法を提案します。 、マルチクラスストレートスルー推定器を使用してバイアスと分散を効果的に低減するSemi-Relaxed Quantization（SRQ）、新しい正規化手法、ドロップアウト正規化を置き換えてニューロンの代わりにビットをランダムにドロップしてバイアスをさらに低減するDropBits SRQのマルチクラスストレートスルー推定器の概要..ネットワークの重みとアクティベーションのビット長を削減することを目的としたネットワーク量子化は、ニューラルネットワークの展開のサイズを削減するための重要な要素の1つとして浮上しています。リソースが制限されたデバイス。 
[ABSTRACT]緩和された量子化はバイアスを減らす新しい方法です。この方法は異なるタイプの量子化の異なるレベルを学習することを含みます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-29">
        <br><font color="black">2019-11-29</font>
      </time>
    </span>
</section>
<!-- paper0: Variational Inference and Learning of Piecewise-linear Dynamical Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_7.html">
      <font color="black">Variational Inference and Learning of Piecewise-linear Dynamical Systems</font>
    </a>
  </h2>
  <font color="black">ただし、単一の線形動作では特徴付けられない実際のプロセスが多数あります。モデルパラメータを静的パラメータと動的パラメータの2つのセットに分割でき、前者のパラメータをオフラインで一緒に推定できることを示します。線形モードの数、またはスイッチング変数の状態の数を使用します。2つの変分期待値最大化アルゴリズム、フィルターとスムーザーの導出の詳細を提供します。 
[ABSTRACT]モデルは区分的線形モデルで構成されています。これらには、役割を果たすために使用できるスイッチメカニズムが含まれています。ただし、区分的スタイルのモデルを検討することは可能です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-02">
        <br><font color="black">2020-06-02</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Self-Supervised Methods for Medical Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_8.html">
      <font color="black">3D Self-Supervised Methods for Medical Imaging</font>
    </a>
  </h2>
  <font color="black">各タスクで、データ効率、パフォーマンス、収束速度の向上を評価します。実験では、3Dタスクを使用してモデルを事前トレーニングすると、トレーニングと比較して、より強力なセマンティック表現が得られ、ダウンストリームタスクをより正確かつ効率的に解決できることが示されています。モデルを最初から作成し、2Dスライスで事前トレーニングします。他の研究者がメソッドを適用および拡張できるように、開発したアルゴリズム（3Dバージョンと2Dバージョンの両方）の実装をオープンソースライブラリとして公開します。データセット。 
[概要]開発されたアルゴリズムは、3Dコントラスト予測コーディング、3D回転予測、3Dジグソーパズル、相対3Dパッチ位置、および3D模範ネットワークです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-06">
        <br><font color="black">2020-06-06</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring Dynamic Context for Multi-path Trajectory Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_9.html">
      <font color="black">Exploring Dynamic Context for Multi-path Trajectory Prediction</font>
    </a>
  </h2>
  <font color="black">この論文では、Dynamic Context Encoder Network（DCENet）という名前の新しいフレームワークを提案します。次に、2つのLSTMエンコーダーをトレーニングして、観測された軌跡と抽出された動的空間コンテキストをそれぞれ入力として、ステップ間の時間コンテキストを学習します。 DCENetは、最大かつ最も困難な軌道予測ベンチマークTrajnetで評価され、新しい最先端のパフォーマンスを報告します。 
[要約]私たちのフレームワークでは、最初に、エージェント間の空間コンテキストがセルフエンコーダー（cvae）モジュールを使用して探索されます。条件付き変分オートエンコーダー（cs）モジュールを使用して潜在空間にエンコードされます。エージェントがたどることができる社会的に可能な1つのパスよりも</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-30">
        <br><font color="black">2020-10-30</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Phase Correlation for End-to-End Heterogeneous Sensor Measurements
  Matching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_10.html">
      <font color="black">Deep Phase Correlation for End-to-End Heterogeneous Sensor Measurements
  Matching</font>
    </a>
  </h2>
  <font color="black">結果は、私たちの方法が異種センサーの測定値と一致し、従来の位相相関や他の学習ベースの方法と比較して優れていることを示しています。また、以前のいくつかの方法での徹底的な評価を排除し、効率を向上させます。コードはhttpsで入手できます。 ：//github.com/jessychen1016/DPCN。 
[要約]結果は、私たちの方法が異種センサー測定値と一致できることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-21">
        <br><font color="black">2020-08-21</font>
      </time>
    </span>
</section>
<!-- paper0: Fully Test-time Adaptation by Entropy Minimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_11.html">
      <font color="black">Fully Test-time Adaptation by Entropy Minimization</font>
    </a>
  </h2>
  <font color="black">テントは、ImageNetおよびCIFAR-10 / 100での画像分類の破損に対する堅牢性を向上させ、ResNet-50のImageNet-Cで最先端のエラーを実現します。適応のためのテスト時間エントロピー最小化（テント）を提案します。予測のエントロピーによって測定されるモデルの信頼性を最適化します。テスト中に、正規化統計を推定し、チャネルごとのアフィン変換を最適化することにより、モデルの特徴を適応させます。 
[ABSTRACT]テスト時間の適応には、ラベルのないテストデータとモデルパラメータのみが与えられます。テスト中、正規化統計を推定し、チャネルごとのアフィン変換を最適化することにより、モデルの特徴を適応させます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br><font color="black">2020-06-18</font>
      </time>
    </span>
</section>
<!-- paper0: SuPEr-SAM: Using the Supervision Signal from a Pose Estimator to Train a
  Spatial Attention Module for Personal Protective Equipment Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_12.html">
      <font color="black">SuPEr-SAM: Using the Supervision Signal from a Pose Estimator to Train a
  Spatial Attention Module for Personal Protective Equipment Recognition</font>
    </a>
  </h2>
  <font color="black">ポーズ推定器からの監視信号を使用してトレーニングされる空間注意メカニズムを追加することにより、分類器の神経アーキテクチャを変更します。人の検出器、体のポーズ推定器、分類器の3つのコンポーネントを使用する斬新で正確なアプローチを提案します。 ..このようにして、分類器は、推論中の計算オーバーヘッドがほとんどないポーズ推定器からの知識を使用して、PPEアイテムに焦点を当てることを学習します。 
[ABSTRACT]検出器によって予測されたバウンディングボックスを取得し、対応するppeアイテムを着用している人と着用していない人を区別する分類器。その結果、分類器は、ポーズ推定器からの知識を使用して、ppeアイテムに焦点を当てることを学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-25">
        <br><font color="black">2020-09-25</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Non-I.I.D. and Invisible Data with FedNAS: Federated Deep
  Learning via Neural Architecture Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_13.html">
      <font color="black">Towards Non-I.I.D. and Invisible Data with FedNAS: Federated Deep
  Learning via Neural Architecture Search</font>
    </a>
  </h2>
  <font color="black">具体的には、設計プロセスを自動化できるニューラルアーキテクチャ検索（NAS）を介してAutoFLを研究します。分散した作業者がより高い精度でより優れたアーキテクチャを共同で検索できるように、フェデレーションNAS（FedNAS）アルゴリズムを提案します。フェデレーションラーニング（FL）にはプライバシー、通信コスト、規制上の制限のためにデータを一元化できない場合に、効果的な学習フレームワークであることが証明されています。 
[概要]人々は、中央環境で発見された事前定義されたモデルアーキテクチャを採用しています。私たちは、労働者がより高い精度でより良いアーキテクチャを検索できるように、統合学習アルゴリズムを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-18">
        <br><font color="black">2020-04-18</font>
      </time>
    </span>
</section>
<!-- paper0: PeeledHuman: Robust Shape Representation for Textured 3D Human Body
  Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_14.html">
      <font color="black">PeeledHuman: Robust Shape Representation for Textured 3D Human Body
  Reconstruction</font>
    </a>
  </h2>
  <font color="black">対応するRGBマップは、頂点レベルのテクスチャの詳細を提供します。PeeledHumanを紹介します。これは、自己閉塞に対して堅牢な人体の新しい形状表現です。3Dシャンファー損失およびその他の2D損失を使用してPeelGANをトレーニングし、複数の深度値を生成します。デュアルブランチ設定でのピクセルごとおよび対応する頂点ごとのRGBフィールド。 
[ABSTRACT] peeledhumanは、人体を2Dの剥離深度とRGBマップのセットとしてエンコードします。これは、3Dボディモデルでレイトレーシングを実行し、各レイを最初の交差点を超えて拡張することによって取得されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-16">
        <br><font color="black">2020-02-16</font>
      </time>
    </span>
</section>
<!-- paper0: Genetic U-Net: Automatically Designing Lightweight U-shaped CNN
  Architectures Using the Genetic Algorithm for Retinal Vessel Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_15.html">
      <font color="black">Genetic U-Net: Automatically Designing Lightweight U-shaped CNN
  Architectures Using the Genetic Algorithm for Retinal Vessel Segmentation</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案された方法が3つの公開データセット、DRIVE、CHASE \ _DB1、STAREの既存の方法よりも優れていることを示しています。この問題に対処するために、遺伝的アルゴリズム（GA）を使用して軽量のU字型CNNを自動的に設計する新しい方法を提案します。遺伝的U-Netと呼ばれる網膜血管セグメンテーション用。さらに、提案された方法によって得られたアーキテクチャは、最先端のモデルよりも軽量ですが正確です。 
[ABSTRACT] cnsは、検索スペースを駆動する遺伝的アルゴリズムに基づいています。この方法では、遺伝的アルゴリズムを使用して優れたアーキテクチャを検索します。これらは、最先端のモデルよりも軽量ですが正確です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: JHU-CROWD++: Large-Scale Crowd Counting Dataset and A Benchmark Method -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_16.html">
      <font color="black">JHU-CROWD++: Large-Scale Crowd Counting Dataset and A Benchmark Method</font>
    </a>
  </h2>
  <font color="black">データセットはhttp://www.crowd-counting.comからダウンロードできます。提案された信頼性ガイド付き深部残余カウントネットワーク（CG-DRCN）は、最近の複雑なデータセットで評価され、エラーの大幅な改善を実現します。これらのアプローチ基本的に、ネットワークパラメータをトレーニングするために大量のデータを必要とする畳み込みニューラルネットワークに基づいています。 
[概要]新しい大規模な制約のない群集カウントデータセット（jhu-群集）には、「151万」の注釈が付いた「4,372」の画像が含まれています。データセットには、天候に基づく劣化と暗闇の変化の画像がいくつか含まれているため、非常に困難です。データセット</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br><font color="black">2020-04-07</font>
      </time>
    </span>
</section>
<!-- paper0: VD-BERT: A Unified Vision and Dialog Transformer with BERT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_17.html">
      <font color="black">VD-BERT: A Unified Vision and Dialog Transformer with BERT</font>
    </a>
  </h2>
  <font color="black">コードと事前トレーニング済みモデルはhttps://github.com/salesforce/VD-BERTでリリースされています。外部の視覚言語データを事前トレーニングする必要がないため、モデルは新しい最先端技術を生み出し、両方でトップの地位を獲得しています。ビジュアルダイアログリーダーボードの単一モデルとアンサンブルの設定（74.54および75.35 NDCGスコア）。ビジュアルダイアログは、ダイアログエージェントが画像の内容とダイアログの履歴を推論して一連の質問に答える必要がある、難しいビジョン言語タスクです。 。 
[概要]モデルは、シングルストリームトランスフォーマーエンコーダーを使用して画像とマルチターンダイアログ間の相互作用をキャプチャするという点で統一されています。200,000平方フィート（4.5 m）以上は、ビジュアルダイアログリーダーボードの最高レベルです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br><font color="black">2020-04-28</font>
      </time>
    </span>
</section>
<!-- paper0: Learning event representations for temporal segmentation of image
  sequences by dynamic graph embedding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_18.html">
      <font color="black">Learning event representations for temporal segmentation of image
  sequences by dynamic graph embedding</font>
    </a>
  </h2>
  <font color="black">DGEは、基本的に2つのステップを繰り返すことで機能します。1）現在のデータ表現に基づいてデータの意味的および時間的類似性を表すグラフを更新し、2）現在のデータグラフ構造を考慮してデータ表現を更新します。 。一定の時間間隔でキャプチャされた実際の画像シーケンスの2つのベンチマークデータセットでの実験結果は、提案されたDGEが時間的セグメンテーションに効果的なイベント表現につながることを示しています。2つのヒューマンモーションセグメンテーションベンチマークデータセットでの追加の実験は、提案されたDGEの一般化機能を示しています。 
[概要]提案されたアートワークは、2つのステップを繰り返すことによって機能します：意味的および時間的類似性の両方をエンコードするパターンから学習します。メイン、dgeは、視覚的表現に効果的であると考えられていますが、高価な手動注釈は必要ありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-08">
        <br><font color="black">2019-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Bijective Feature Maps for Linear ICA -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_19.html">
      <font color="black">Learning Bijective Feature Maps for Linear ICA</font>
    </a>
  </h2>
  <font color="black">そうすることで、フローベースのモデル、線形ICA、画像の変分オートエンコーダーよりも、すばやく収束し、トレーニングが簡単で、教師なし潜在因子の発見に優れたモデルを作成します。このようなハイブリッドモデルを共同でトレーニングすることの複雑さを考えると、線形ICAを直交直交行列の多様体であるStiefel多様体の近くに配置するように制約する新しい理論を紹介します。これに対処するために、高次元の解釈可能な潜在構造を学習するために、双ジェクティブ特徴マップと線形ICAモデルを組み合わせたDGMを提案します。データ。 
[概要]「簡単な」モデルは、非線形icaタスクではパフォーマンスが低下します。これらはc4 c4、c4に基づいており、画像データ用にカスタマイズされています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br><font color="black">2020-02-18</font>
      </time>
    </span>
</section>
<!-- paper0: Training Object Detectors from Few Weakly-Labeled and Many Unlabeled
  Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_20.html">
      <font color="black">Training Object Detectors from Few Weakly-Labeled and Many Unlabeled
  Images</font>
    </a>
  </h2>
  <font color="black">最近の代表的な弱教師ありパイプラインPCLに基づいて、私たちの方法は、より多くのラベルなし画像を使用して、多くの最近の弱教師あり検出ソリューションよりも優れたパフォーマンスを実現できます。これは、ラベル付きデータがない半教師あり学習の極端なケースです。検出器の学習をブートストラップするのに十分です。弱教師ありオブジェクト検出は、境界ボックスの必要性をなくすことによって教師ありの量を制限しようとしますが、トレーニングセット全体で画像レベルのラベルを想定します。 
[概要]私たちの方法は、画像レベルのラベルとラベルのない画像のより大きなセットを使用して、1つまたはいくつかの画像からオブジェクト検出器をトレーニングすることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-01">
        <br><font color="black">2019-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Observer Dependent Lossy Image Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_21.html">
      <font color="black">Observer Dependent Lossy Image Compression</font>
    </a>
  </h2>
  <font color="black">品質という用語は、大多数の文献で人間であると想定されている画像の観察者に決定的に依存します。これら2つの目的関数を組み合わせることにより、人間間の圧縮品質に顕著なトレードオフがあることを示します。視覚システムと分類の精度..ディープニューラルネットワークは最近、画像圧縮の最先端を進歩させ、多くの従来の圧縮アルゴリズムを上回りました。 
[概要]調査によると、圧縮システムは分類精度を向上させることができます。人間に優しい損失関数を使用して圧縮システムをトレーニングします。これにより、従来のコーデックよりも分類精度が低下します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-08">
        <br><font color="black">2019-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: AutoPruning for Deep Neural Network with Dynamic Channel Masking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_22.html">
      <font color="black">AutoPruning for Deep Neural Network with Dynamic Channel Masking</font>
    </a>
  </h2>
  <font color="black">ただし、現在のほとんどのプルーニングアルゴリズムは、手作りのルールまたはドメインの専門知識に依存しています。ベンチマークデータセットの予備実験結果は、私たちのスキームがニューラルネットワークプルーニングの競争力のある結果を達成することを示しています。この問題を克服するために、ディープの学習ベースの自動プルーニングアルゴリズムを提案します。最近の自動機械学習（AutoML）に触発されたニューラルネットワーク。 
[概要]たとえば、ディープニューラルネットワーク用の学習ベースの自動プルーニングアルゴリズムを提案します。これは、最近の自動機械学習（automl）に触発されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-22">
        <br><font color="black">2020-10-22</font>
      </time>
    </span>
</section>
<!-- paper0: Model-Based Robust Deep Learning: Generalizing to Natural,
  Out-of-Distribution Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CV/paper_23.html">
      <font color="black">Model-Based Robust Deep Learning: Generalizing to Natural,
  Out-of-Distribution Data</font>
    </a>
  </h2>
  <font color="black">私たちの広範な実験は、さまざまな自然発生条件およびさまざまなデータセットにわたって、モデルベースのアルゴリズムでトレーニングされたディープニューラルネットワークが、標準のディープラーニングアルゴリズムと標準に制限された堅牢なディープラーニングアルゴリズムの両方を大幅に上回っていることを示しています。 、摂動ベースの敵対的ロバスト性からモデルベースのロバストな深層学習へのパラダイムシフトを提案します。私たちのパラダイムにとって重要なのは、最初に、自然条件の範囲にわたってデータを変化させるために使用できる自然変化のモデルを取得することです。 
[ABSTRACT]敵対的トレーニングは、規範境界の摂動に関して深層学習の堅牢性を高めるための原則的なアプローチとして登場しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br><font color="black">2020-05-20</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Sticking to the Facts: Confident Decoding for Faithful Data-to-Text
  Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_0.html">
      <font color="black">Sticking to the Facts: Confident Decoding for Faithful Data-to-Text
  Generation</font>
    </a>
  </h2>
  <font color="black">WikiBio（Lebretet al。、2016）データセットでの実験は、PARENTスコア（Dhingra et al。、2019）と人間の評価の両方によると、私たちのアプローチが既存の最先端のアプローチよりもソースに忠実であることを示しています。 。また、WebNLG（Gardent et al。、2017）データセットで強力な結果を報告します。データからテキストへの生成における幻覚の問題、つまり、ソースによってサポートされていないテキストの生成を減らすことに対処します。 
[概要]幻覚はエンコーダー-デコーダーモデルによって引き起こされる可能性があると考えています。必要なときにモデルがソースに確実に対応できるように、信頼スコアを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-19">
        <br><font color="black">2019-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: Reference and Document Aware Semantic Evaluation Methods for Korean
  Language Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_1.html">
      <font color="black">Reference and Document Aware Semantic Evaluation Methods for Korean
  Language Summarization</font>
    </a>
  </h2>
  <font color="black">ただし、ROUGEスコアはn-gramオーバーラップに基づいて計算されるため、生成された要約と参照要約の間の意味意味の対応を反映しません。この論文では、参照要約と元のドキュメントである参照の意味意味を反映する評価メトリックを提案します。およびDocumentAware Semantic Score（RDASS）..韓国語は、さまざまな形態を組み合わせていくつかの意味を表す単語にする凝集言語であるため、ROUGEは韓国語の要約には適していません。 
[要約]テキスト要約のための多くの既存の作品は一般的に評価されますが、それらは50のメトリックの使用には適していません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br><font color="black">2020-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: What BERT Sees: Cross-Modal Transfer for Visual Question Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_2.html">
      <font color="black">What BERT Sees: Cross-Modal Transfer for Visual Question Generation</font>
    </a>
  </h2>
  <font color="black">私たちは、各モダリティの影響を研究することを可能にする、接地された対話にとって非常に興味深いタスクである視覚的質問生成を研究することを選択します（入力は視覚的および/またはテキストである可能性があるため）。BERTベースのアーキテクチャであるBERT-genを紹介します。テキスト生成の場合、モノモーダル表現またはマルチモーダル表現のいずれかを活用できます。このペーパーでは、補足データで行われる事前トレーニングを回避することにより、BERTの視覚的機能をすぐに評価することに関心があります。 
[ABSTRACT]テキスト生成用のbertベースのアーキテクチャであるbert-genは、モノモードまたはマルチモーダル表現を活用できます。提案されたモデルは、2つの確立されたデータセットの最新技術を大幅に改善します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-25">
        <br><font color="black">2020-02-25</font>
      </time>
    </span>
</section>
<!-- paper0: A Sentence Cloze Dataset for Chinese Machine Reading Comprehension -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_3.html">
      <font color="black">A Sentence Cloze Dataset for Chinese Machine Reading Comprehension</font>
    </a>
  </h2>
  <font color="black">提案されたタスクは、いくつかの空白があるパッセージに正しい候補文を埋めることを目的としています。SC-MRCタスクの難易度を評価するためにCMRC2019と呼ばれる中国語のデータセットを構築しました。https：//github.com/から入手可能なリソースymcui / cmrc2019 
[ABSTRACT] sc --mrcタスクの難易度を評価するために中国語のデータセットを作成しました。中国語のデータセットには、1万を超えるパッセージ内に10万を超える空白が含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br><font color="black">2020-04-07</font>
      </time>
    </span>
</section>
<!-- paper0: Provenance for Linguistic Corpora Through Nanopublications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_4.html">
      <font color="black">Provenance for Linguistic Corpora Through Nanopublications</font>
    </a>
  </h2>
  <font color="black">別々のコーパスからの言語アノテーションを最初から確実にリンクし、それによって単一のデータセットであるかのようにアクセスしてクエリを実行する方法を示します。このようなナノパブリケーションを作成する方法と、SPARQLクエリを実行して興味深いものを抽出する方法を示します。新しい表現からのコンテンツ..クエリは、異なるコーパスの情報が統一されたデータ形式で表されるため、複数のコーパスの情報をより簡単かつ効果的に取得できることを示しています。 
[要約]この論文は、イベント注釈付きコーパスのケーススタディに異議を唱えました。彼は、これにより、ナノパブリケーションの形でこのデータの新しい、より相互運用可能な表現が作成されると主張しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br><font color="black">2020-06-11</font>
      </time>
    </span>
</section>
<!-- paper0: Definition Frames: Using Definitions for Hybrid Concept Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_5.html">
      <font color="black">Definition Frames: Using Definitions for Hybrid Concept Representations</font>
    </a>
  </h2>
  <font color="black">単語表現の進歩は、下流のNLPタスクで大幅な改善を示しましたが、意味解釈可能性に欠けています。私たちの結果は、DFが単語類似性タスクで他の分布意味アプローチと競合するパフォーマンスを持っていることを示しています。DF次元はQualia構造関係に対応します。用語を一意に定義する関係。 
[概要]この論文では、定義フレーム（df）を紹介します。dfsは他の分散セマンティックアプローチと競合するパフォーマンスを持っています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-10">
        <br><font color="black">2019-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Contextual Salience for Fast and Accurate Sentence Vectors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_6.html">
      <font color="black">Contextual Salience for Fast and Accurate Sentence Vectors</font>
    </a>
  </h2>
  <font color="black">CoSalは、異常な単語ベクトルがフレーズベクトルに不均衡に影響を与えるという洞察に依存しています。最近の単語ベクトルベースの提案では、コンテキストに関係なく、単語埋め込みスペース内の距離が等しく重要であると暗黙的に想定しています。コンテキスト顕著性（CoSal）コンテキストベクトルの分布を使用して距離と重みを正規化する単語の重要度。 
[概要]バッグ-cosalベースの重みを使用した単語モデルのバッグ-分類のための正確な監視されていない文またはドキュメント表現を生成</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-03-22">
        <br><font color="black">2018-03-22</font>
      </time>
    </span>
</section>
<!-- paper0: An End-to-End Multi-Task Learning to Link Framework for Emotion-Cause
  Pair Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_7.html">
      <font color="black">An End-to-End Multi-Task Learning to Link Framework for Emotion-Cause
  Pair Extraction</font>
    </a>
  </h2>
  <font color="black">結果は、提案されたモデルが一連の最先端のアプローチよりも優れていることを示しています。ECPEへの既存のアプローチは、一般に2段階の方法を採用しています。つまり、（1）感情と原因の検出、そして（2）ペアリング検出された感情と原因..具体的には、私たちのモデルはペア抽出をリンク予測タスクと見なし、感情句から原因句へのリンクを学習します。つまり、リンクは方向性があります。 
[ABSTRACT]前の感情原因抽出（ece）タスク、それでもeceのように事前に与えられた感情句のセットを必要としない方法は直感的ですが、ステージ間のエラー通信を含む2つの重大な問題に悩まされています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-25">
        <br><font color="black">2020-02-25</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Topic-Guided Conversational Recommender System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_8.html">
      <font color="black">Towards Topic-Guided Conversational Recommender System</font>
    </a>
  </h2>
  <font color="black">広範な実験により、トピック予測、アイテムの推奨、応答の生成という3つのサブタスクに対するアプローチの有効性が実証されました。データセットには2つの主要な機能があります。次に、半自動で作成されるため、人間による注釈はより合理的で制御可能。 
[概要]効果的なクロタを開発するには、高品質のデータセットのサポートが不可欠です。新しいデータセットはtgに基づいています-リダイヤル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: WikiUMLS: Aligning UMLS to Wikipedia via Cross-lingual Neural Ranking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_9.html">
      <font color="black">WikiUMLS: Aligning UMLS to Wikipedia via Cross-lingual Neural Ranking</font>
    </a>
  </h2>
  <font color="black">700k UMLSコンセプトのランク付けされたウィキペディアページや、UMLSとウィキペディア間のアライメントモデルのトレーニングと評価のためのデータセットであるウィキペディアなどのリソースをリリースします。これにより、医療専門家、患者、NLPシステムなどのウィキペディアに簡単にアクセスできるようになります。多言語設定で..UMLSの概念をウィキペディアのページと一致させるための言語間ニューラル再ランク付けモデルを提案します。これにより、recall @ 1が72％になり、単語レベルおよび文字レベルのBM25よりも20％大幅に改善され、最小限の労力で手動調整。 
[概要] umlsの概念をウィキペディアのページと一致させるためのクロスリンガル再ランク付けモデルを提案します。これにより、多言語設定を含め、医療専門家、患者、およびnlpシステムがウィキペディアに簡単にアクセスできるようになります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-04">
        <br><font color="black">2020-05-04</font>
      </time>
    </span>
</section>
<!-- paper0: Experience Grounds Language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_10.html">
      <font color="black">Experience Grounds Language</font>
    </a>
  </h2>
  <font color="black">大規模なテキストのみのコーパスでトレーニングされた表現学習アプローチの現在の成功には、コミュニケーションのより深い問題に対処するために、言語のより広い物理的および社会的文脈に関する研究の並行した伝統が必要であると私たちは考えます。言語をそれが説明する物理的世界およびそれが促進する社会的相互作用に関連付けることに失敗する。テキストのみで訓練された後にタスクに取り組むための言語処理モデルの信じられないほどの効果にもかかわらず、成功する言語コミュニケーションは世界の共有された経験に依存する。 
[抽象]言語処理は多様な分野ですが、成功する社会的コミュニケーションは世界の共有された経験に依存しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br><font color="black">2020-04-21</font>
      </time>
    </span>
</section>
<!-- paper0: VD-BERT: A Unified Vision and Dialog Transformer with BERT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_11.html">
      <font color="black">VD-BERT: A Unified Vision and Dialog Transformer with BERT</font>
    </a>
  </h2>
  <font color="black">コードと事前トレーニング済みモデルはhttps://github.com/salesforce/VD-BERTでリリースされています。さらに重要なのは、視覚的に根拠のあるトレーニングを介して、視覚とダイアログのコンテンツを効果的に融合するためにBERTを適応させることです。 （1）シングルストリームTransformerエンコーダーを使用して、画像とマルチターンダイアログ間のすべての相互作用をキャプチャし、（2）同じアーキテクチャを通じてシームレスに回答のランク付けと回答の生成の両方をサポートします。 
[概要]モデルは、シングルストリームトランスフォーマーエンコーダーを使用して画像とマルチターンダイアログ間の相互作用をキャプチャするという点で統一されています。200,000平方フィート（4.5 m）以上は、ビジュアルダイアログリーダーボードの最高レベルです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br><font color="black">2020-04-28</font>
      </time>
    </span>
</section>
<!-- paper0: Leveraging Extracted Model Adversaries for Improved Black Box Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_12.html">
      <font color="black">Leveraging Extracted Model Adversaries for Improved Black Box Attacks</font>
    </a>
  </h2>
  <font color="black">まず、モデル抽出を介して被害者のブラックボックスモデルを近似します（Krishna et al。、2020）。次に、独自のホワイトボックス法を使用して、近似モデルを失敗させる入力摂動を生成します。これらの摂動入力は、に対して使用されます。被害者。 
[概要]独自のホワイトボックス法を使用して、モデルが失敗する原因となる摂動を生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-30">
        <br><font color="black">2020-10-30</font>
      </time>
    </span>
</section>
<!-- paper0: Revisiting Pre-Trained Models for Chinese Natural Language Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_13.html">
      <font color="black">Revisiting Pre-Trained Models for Chinese Natural Language Processing</font>
    </a>
  </h2>
  <font color="black">実験結果は、MacBERTが多くのNLPタスクで最先端のパフォーマンスを達成できることを示しています。また、将来の研究に役立つ可能性のあるいくつかの調査結果で詳細を削除します。8つの中国のNLPタスクで広範な実験を行い、既存の-トレーニングされた言語モデルと提案されたMacBERT ..利用可能なリソース：https：//github.com/ymcui/MacBERT 
[ABSTRACT]既存の事前トレーニングされた言語モデルを再検討するために、8つの中国のnlpタスクで実験を行いました。結果コミュニティにリリースされる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br><font color="black">2020-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: MPNet: Masked and Permuted Pre-training for Language Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_14.html">
      <font color="black">MPNet: Masked and Permuted Pre-training for Language Understanding</font>
    </a>
  </h2>
  <font color="black">ただし、XLNetは文の完全な位置情報を活用しないため、事前トレーニングと微調整の間で位置の不一致が発生します。コードと事前トレーニング済みモデルは、https：//github.com/microsoftで入手できます。 / MPNet ..大規模なデータセット（160GBを超えるテキストコーパス）でMPNetを事前トレーニングし、さまざまなダウンストリームタスク（GLUE、SQuADなど）で微調整します。 
[ABSTRACT] xlnetは、この問題に対処するための事前トレーニング用の順列言語モデリング（plm）を導入します。これは、bertとxlnetの利点を継承し、それらの制限を回避する新しい事前トレーニング方法です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br><font color="black">2020-04-20</font>
      </time>
    </span>
</section>
<!-- paper0: Reinforced Multi-task Approach for Multi-hop Question Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_15.html">
      <font color="black">Reinforced Multi-task Approach for Multi-hop Question Generation</font>
    </a>
  </h2>
  <font color="black">マルチホップ質問応答データセットHotPotQAでの実験を通じて、アプローチの有効性を示します。QGの場合、高品質の質問を生成するために複数の裏付けとなる事実が必要になることがよくあります。回答認識の補助タスクを使用したマルチタスク学習を採用しています。質問ジェネレータをガイドするためのファクト予測のサポート。 
[ABSTRACT]コンテキスト内のサポートファクトに基づいて関連する質問を生成することを目的としたマルチホップ質問生成が必要です。また、サポートファクトを最大限に活用するための質問認識報酬関数（rl）を提案しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-05">
        <br><font color="black">2020-04-05</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Spoken Language Representations with Neural Lattice Language
  Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_16.html">
      <font color="black">Learning Spoken Language Representations with Neural Lattice Language
  Modeling</font>
    </a>
  </h2>
  <font color="black">提案された2段階の事前トレーニングアプローチは、音声データの需要を減らし、効率を向上させます。意図検出と対話行為認識データセットの実験は、提案された方法が音声入力で評価されたときに一貫して強力なベースラインを上回っていることを示しています。コードが利用可能です。 https://github.com/MiuLab/Lattice-ELMoで。 
[概要]音声言語理解タスクのコンテキスト化された表現を提供するために神経格子言語モデルをトレーニングするフレームワークを提案します。提案された方法は、音声入力で評価されたときに一貫して強力なベースラインを上回ります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Drinking from a Firehose: Continual Learning with Web-scale Natural
  Language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_17.html">
      <font color="black">Drinking from a Firehose: Continual Learning with Web-scale Natural
  Language</font>
    </a>
  </h2>
  <font color="black">Firehoseデータセットによって可能になり、前例のない規模での継続学習アルゴリズムの厳密な評価を提示します。この論文では、大規模な継続学習の自然な設定を研究します。パーソナライズされたオンライン言語学習（POLL）の問題を紹介します。 ）。これには、時間の経過とともに進化するユーザーの集団にパーソナライズされた言語モデルを適合させることが含まれます。 
[概要]パーソナライズされたオンライン言語学習（投票）の問題を紹介します。これには、時間の経過とともに進化するユーザーの母集団にパーソナライズされた言語モデルを適合させることが含まれます。データセット、firehose10mおよびfirehose100mは、100万人のユーザーによって投稿された1億のツイートで構成されます。 6年以上</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-18">
        <br><font color="black">2020-07-18</font>
      </time>
    </span>
</section>
<!-- paper0: RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_18.html">
      <font color="black">RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark</font>
    </a>
  </h2>
  <font color="black">ユニバーサル言語モデルとトランスフォーマーの分野における最近の進歩には、自然言語の推論の検出、常識的な推論、テキストの件名や辞書に関係なく単純な論理操作を実行する能力など、幅広い診断と一般的な知的スキルのテストのための方法論の開発が必要です。 。SuperGLUE方法論と同様に収集および編成された、9つのタスクのベンチマークが初めて、ロシア語用にゼロから開発されました。ベースライン、人間レベルの評価、モデルを評価するためのオープンソースフレームワークを提供します（https： //github.com/RussianNLP/RussianSuperGLUE）、およびロシア語のトランスフォーマーモデルの全体的なリーダーボード。 
[ABSTRACT]ユニバーサル言語モデルとトランスフォーマーの分野における最近の進歩には、新しい方法の開発が必要です。新しい技術には、自然言語の可能性の検出、常識的な推論、テキストの主題や辞書に関係なく単純な論理操作を実行する機能が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Learning ASR-Robust Contextualized Embeddings for Spoken Language
  Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_19.html">
      <font color="black">Learning ASR-Robust Contextualized Embeddings for Spoken Language
  Understanding</font>
    </a>
  </h2>
  <font color="black">ソースコードはhttps://github.com/MiuLab/SpokenVecで入手できます。具体的には、LMを微調整して、ASRによって生成された単語混同ネットワーク（WCN）から取得される音響的に混乱する単語の同様の表現を生成します。したがって、このペーパーでは、コンテキスト化された表現をよりASRロバストにすることに焦点を当てます。 
[要約]提案された方法は、事前に訓練されたlmへのasrエラーの影響を軽減するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-24">
        <br><font color="black">2019-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Text Classification of Manifestos and COVID-19 Press Briefings using
  BERT and Convolutional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_20.html">
      <font color="black">Text Classification of Manifestos and COVID-19 Press Briefings using
  BERT and Convolutional Neural Networks</font>
    </a>
  </h2>
  <font color="black">BERTなどのトランスフォーマーと組み合わせたCNNは、他の埋め込み（Word2Vec、Glove、ELMo）と組み合わせたCNNよりも優れていること、および事前にトレーニングされた分類子を使用して、追加のトレーニングなしでさまざまな政治テキストの自動分類を実行できることを示します。手動で注釈を付けて使用します。ローカルトピックConvolutionalNeuralNetwork（CNN）分類器をトレーニングするためのトレーニングデータとしての政治マニフェスト。次に、それをCOVID-19PressBriefings Corpusに適用して、テストコーパス内の文を自動的に分類します。文レベルの分類タスク用に事前にトレーニングされた埋め込みの上にトレーニングされたCNNを使用した一連の実験について報告します。文レベルの政治を構築します。マニフェストプロジェクト（Volkens et al。、2020a）からの既存の人間の専門家が注釈を付けた政治マニフェストのコーパスを使用し、それらをCOVID-19Pressブリーフィングのコーパス（Chatsiou、2020）に適用する談話分類器。 
[ABSTRACT] cnnの選挙マニフェストは、政治マニフェストを使用して人々を訓練するために使用されます。cnnの埋め込みは、人々が自分の信念を理解するのを助けるために使用されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-20">
        <br><font color="black">2020-10-20</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Long-Tail Relation Extraction with Collaborating
  Relation-Augmented Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/cs.CL/paper_21.html">
      <font color="black">Improving Long-Tail Relation Extraction with Collaborating
  Relation-Augmented Attention</font>
    </a>
  </h2>
  <font color="black">間違ったラベリング問題とロングテール関係は、関係抽出における遠隔監視によって引き起こされる2つの主要な課題です。次に、提案された基本モデルによって促進され、階層内の関係間で共有される協調関係機能を導入して、関係拡張プロセスとバランスを促進します。ロングテール関係のトレーニングデータ..特に、最初にベースモデルとして関係拡張注意ネットワークを提案します。 
[概要]ロング-補助アテンションネットワークに加えて、階層内のリレーション間で共有される接続リレーション機能を導入して、リレーション-拡張プロセスを促進し、ロングテールリレーションのトレーニングデータのバランスを取ります。人気のベンチマークデータセットnytでの実験で、提案されたコーラは、以前の最先端のパフォーマンスを大幅に改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Transformer-based Arabic Dialect Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_0.html">
      <font color="black">Transformer-based Arabic Dialect Identification</font>
    </a>
  </h2>
  <font color="black">また、CNNとトランスフォーマーベースのシステムのスコアレベルの融合により、ADI17データベースで86.29％の全体的な精度が得られることも報告します。言語とDID、およびトランスフォーマーの自己注意メカニズムにとって、長距離情報も同様に重要であると考えています。長期的な依存関係をキャプチャします。このプロセスは、まばらでありながら有益な機能を抽出します。 
[ABSTRACT] cnnネットワークは、より短い受容体とより短い受容体を使用します。これらのシステムは、代替システムを作成するために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Guided multi-branch learning systems for sound event detection with
  sound separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_1.html">
      <font color="black">Guided multi-branch learning systems for sound event detection with
  sound separation</font>
    </a>
  </h2>
  <font color="black">このシステムは、DCASE 2019タスク4の1位のシステムに基づいています。このシステムは、注意ベースの埋め込みレベルのプーリングモジュールと、ガイド付き学習という名前の半教師あり学習アプローチを備えた弱教師ありフレームワークを採用しています。MBLは、さまざまなブランチを使用します。モデルの同じ機能エンコーダーを共有するプーリング戦略（インスタンスレベルおよび埋め込みレベルの戦略を含む）および異なるプーリングモジュール（アテンションプーリング、グローバル最大プーリングまたはグローバル平均プーリングモジュールを含む）。したがって、異なる目的を追求する複数のブランチまた、データのさまざまな特性に焦点を当てることで、特徴エンコーダーが特徴空間をより適切にモデル化し、過剰適合を回避するのに役立ちます。 
[概要]システムは、dcase 2019タスク4の最初の場所のシステムに基づいています。それは、不十分な-注意を払った監視ありフレームワーク-ベースの埋め込み-レベルプーリングモジュールと、ガイド付き学習という名前の半教師あり学習アプローチを採用しています。モデルの同じ機能エンコーダーを共有する、さまざまなプーリング戦略とさまざまなプーリングモジュール</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-21">
        <br><font color="black">2020-07-21</font>
      </time>
    </span>
</section>
<!-- paper0: What's All the FUSS About Free Universal Sound Separation Data? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_2.html">
      <font color="black">What's All the FUSS About Free Universal Sound Separation Data?</font>
    </a>
  </h2>
  <font color="black">最後に、改良された時間領域畳み込みネットワーク（TDCN ++）に基づいて、混合物内の可変数の音源を分離できるオープンソースのベースライン分離モデルを紹介します。残響をシミュレートするには、音響室シミュレーターを使用して生成します。周波数依存の反射壁を備えた箱型の部屋のインパルス応答..このデータセットが新しい研究への障壁を下げ、他の機械学習領域からの新しい技術の音の分離の課題への迅速な反復と適用を可能にすることを願っています。 
[概要]データセットは、357クラスの23時間のシングルソースオーディオデータで構成されています。データセットは、1〜4つのソースの混合物を作成するために使用されます。世界で合計3,000人が録音されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Speaker anonymisation using the McAdams coefficient -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_3.html">
      <font color="black">Speaker anonymisation using the McAdams coefficient</font>
    </a>
  </h2>
  <font color="black">提案されたソリューションは、McAdams係数を使用して、音声信号のスペクトルエンベロープを変換します。一般的なVoicePrivacy 2020データベースとプロトコルを使用して得られた結果は、ランダムで最適化された変換が、匿名化の点で競合するソリューションよりも優れている一方で、了解度をわずかにさらに低下させることを示しています。半情報に基づくプライバシーの敵の場合でも..匿名化は、明瞭度や自然性に関連するものなど、音声の他の側面を維持しながら、話者認識への自動アプローチの信頼性を低下させるために音声信号を操作することを目的としています。 
[概要]匿名化へのアプローチは、トレーニングデータを必要とせず、よく知られた信号処理技術に基づいており、効率的かつ効果的です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Into the Wild with AudioScope: Unsupervised Audio-Visual Separation of
  On-Screen Sounds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_4.html">
      <font color="black">Into the Wild with AudioScope: Unsupervised Audio-Visual Separation of
  On-Screen Sounds</font>
    </a>
  </h2>
  <font color="black">AudioScopeは、これらの制限を克服し、ソースの数が可変で、ラベルや事前の視覚的セグメンテーションなしで、サウンドのオープンドメインで動作します。と画面外の音を抑制するために..評価と半監視実験のために、クリップの小さなサブセットに画面上の音と画面外の音が存在するかどうかを示す人間のラベルを収集しました。 
[ABSTRACT]視覚的分離作業は、サウンドクラスのドメインに人為的な制限を想定しました。ソースの数を制限し、強力なサウンドラベルを必要としました。これらのサウンドは、教師なしオーディオによって作成されました-視覚的一致モデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: CVC: Contrastive Learning for Non-parallel Voice Conversion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_5.html">
      <font color="black">CVC: Contrastive Learning for Non-parallel Voice Conversion</font>
    </a>
  </h2>
  <font color="black">CVCはさらに、多対1の音声変換でパフォーマンスの向上を示し、見えない話者からの変換を可能にします。ただし、通常、モデルのトレーニングが困難で、結果が不十分です。この論文では、対照的な学習ベースのCVCを提案します。音声変換の敵対モデル。 
[ABSTRACT] cvcは、非並列の1つから1つの音声変換に関しては、一方向のganトレーニングのみを必要とします。どちらもモデルトレーニングの難しさと不十分な結果に悩まされています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: One In A Hundred: Select The Best Predicted Sequence from Numerous
  Candidates for Streaming Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_6.html">
      <font color="black">One In A Hundred: Select The Best Predicted Sequence from Numerous
  Candidates for Streaming Speech Recognition</font>
    </a>
  </h2>
  <font color="black">すべての実験は、中国の北京語データセットAISHELL-1で実行されます。次に、トランスデコーダは、対応する音響エンコード状態に基づいて最適な候補を選択します。したがって、ハイブリッドCTCと注意モデルを改善し、2段階の推論を導入します。 100分の1（OAH）という名前のメソッド。 
[要約]結果は、提案されたモデルが高速で簡単な方法でストリームデコードを実装できることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Optimize what matters: Training DNN-HMM Keyword Spotting Model Using End
  Metric -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_7.html">
      <font color="black">Optimize what matters: Training DNN-HMM Keyword Spotting Model Using End
  Metric</font>
    </a>
  </h2>
  <font color="black">DNNは、以前の方法では、HMMパラメーターとは独立してトレーニングされ、予測状態とグラウンドトゥルース状態の確率の間のクロスエントロピー損失を最小限に抑えます。DNNトレーニング損失（クロスエントロピー）と終了の間の不一致メトリック（検出スコア）は、キーワードスポッティングタスクの最適ではないパフォーマンスの主な原因です。さらに、同じ誤ったトリガーエクスペリエンスで誤った拒否率（FRR）が大幅に減少することを示しています（独立したDNNトレーニングよりも70％以上）。 
[概要] dnnは特定の音声フレームの状態確率を予測します。hrデコーダーは複数の音声フレームのdnn予測を組み合わせます。dnnはカリフォルニア大学からの情報の欠如に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Using a Bi-directional LSTM Model with Attention Mechanism trained on
  MIDI Data for Generating Unique Music -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_8.html">
      <font color="black">Using a Bi-directional LSTM Model with Attention Mechanism trained on
  MIDI Data for Generating Unique Music</font>
    </a>
  </h2>
  <font color="black">本論文では、MIDIデータに基づいて同様のタイプの音楽を生成できる注意メカニズムを備えた双方向LSTM（長短期記憶）モデルを提案します。GANの出現により、訓練されたものに基づいて新しい同様の画像を生成することが可能になります。データ..したがって、音楽がデジタル形式でどのように表現されるかを理解する必要があります。 
[ABSTRACT]人間の創造性を模倣することはコンピュータビジョンの分野で人気がありますが、音楽には余分なテンポがあるため、これは音楽に対して行うことができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: An Audio-Video Deep and Transfer Learning Framework for Multimodal
  Emotion Recognition in the wild -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_9.html">
      <font color="black">An Audio-Video Deep and Transfer Learning Framework for Multimodal
  Emotion Recognition in the wild</font>
    </a>
  </h2>
  <font color="black">エンドツーエンドの深層学習を使用し、転移学習アプローチの恩恵を受けて、42.10％のテストセットチャレンジパフォーマンス測定に到達しました。この論文では、ABAW表情チャレンジへの貢献を示します。提案されたシステムとチャレンジプロトコルに準拠した公式のチャレンジ結果。 
[概要]提案システムと公式チャレンジ結果を報告します。公式結果も報告します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-07">
        <br><font color="black">2020-10-07</font>
      </time>
    </span>
</section>
<!-- paper0: Learning generic feature representation with synthetic data for
  weakly-supervised sound event detection by inter-frame distance loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_10.html">
      <font color="black">Learning generic feature representation with synthetic data for
  weakly-supervised sound event detection by inter-frame distance loss</font>
    </a>
  </h2>
  <font color="black">2つの方法を併用すると、最高のパフォーマンスが得られることがわかります。メトリック学習に基づいて、ドメイン適応のためのフレーム間距離損失関数を提案し、サウンドイベント検出での有効性を証明します。サウンドイベント検出システムのパフォーマンスを改善するために合成データを使用する、強力なラベルのサウンドイベント検出データセットの制限は、新しい研究の焦点となっています。 
[概要]合成データの使用を活用して、特徴音を改善しようとしています。合成損失に基づいて、マルチタスク学習も適用しました。dcase2018タスク4テストセットとdcase2019タスク4合成セットの両方の実験は競争力を示しています結果</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Perceptually Guided End-to-End Text-to-Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_11.html">
      <font color="black">Perceptually Guided End-to-End Text-to-Speech</font>
    </a>
  </h2>
  <font color="black">MOS予測モデルの監督下で、TTSモデルは音声の知覚品質を直接向上させることを学習できます。実験では、音声変換チャレンジ2018評価で事前トレーニングされたMOS予測モデルを使用して、韓国の内部データセットでFastSpeechをトレーニングします。結果..MOSテストの結果は、提案されたアプローチが音声品質においてFastSpeechよりも優れていることを示しています。 
[概要]トレーニングの損失関数と評価の平均オピニオン評点（mos）の間に不一致があります。実験では、mos予測モデルを使用して韓国語の内部データセットで高速音声をトレーニングします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-end anti-spoofing with RawNet2 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_12.html">
      <font color="black">End-to-end anti-spoofing with RawNet2</font>
    </a>
  </h2>
  <font color="black">私たちの結果はオープンソースソフトウェアで再現可能です。なりすまし対策は、自動話者認証システムを、なりすまし音声信号を使用して信頼性を操作しようとする試みから保護することを目的としています。このペーパーでは、RawNet2のなりすまし防止への最初の適用について報告します。 
[概要]最新のasvspoof2019評価の結果は、ほとんどの形態の攻撃を検出する大きな可能性を示しています。rawnet2は生の音声を取り込み、検出できない手がかりを学習する可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Multitask Learning and Joint Optimization for Transformer-RNN-Transducer
  Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_13.html">
      <font color="black">Multitask Learning and Joint Optimization for Transformer-RNN-Transducer
  Speech Recognition</font>
    </a>
  </h2>
  <font color="black">広く使用されているLibrispeechデータセットに対してよく知られているESPNETツールキットを利用して実験を行うことにより、その有効性を証明します。また、提案された方法により、テストクリーンおよびテストで単語誤り率（WER）を16.6％および13.3％削減できることも示します。モデル全体の構造を変更したり、外部LMを利用したりすることなく、他のデータセットをそれぞれ使用します。提案された方法には、モデルが大きなテキストコーパスに関する情報を維持できるという主な利点があります。 
[概要]これらのタイプの方法によると、これらは一般にトランスフォーマーベースのニューラルネットワークによってモデル化されますが、予測ネットワークはトランスフォーマーまたはリカレントニューラルネットワーク（rnn）のいずれかによってモデル化できます。提案された方法には、モデルが次のことができるという主な利点があります。大きなテキストコーパスに関する情報を維持する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Prediction of head motion from speech waveforms with a
  canonical-correlation-constrained autoencoder -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_14.html">
      <font color="black">Prediction of head motion from speech waveforms with a
  canonical-correlation-constrained autoencoder</font>
    </a>
  </h2>
  <font color="black">MFCCベースのシステムと比較して、提案されたシステムは、客観的評価で同等のパフォーマンスを示し、被験者評価でより優れたパフォーマンスを示します。波形ベースのアプローチの課題は、波形に頭の動きの予測に関係のない大量の情報が含まれていることです。ニューラルネットワークのトレーニングを妨げます。この問題を克服するために、エラーを最小化するだけでなく、頭の動きとの正規相関を最大化するように隠れ層をトレーニングする、正規相関制約付き自動エンコーダー（CCCAE）を提案します。 
[概要]新しい研究では、波形が頭の動きを予測するのにより効果的であることが示されています。エラーを最小限に抑えるために新しいシステムが使用されたのはこれが初めてである可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-05">
        <br><font color="black">2020-02-05</font>
      </time>
    </span>
</section>
<!-- paper0: Acoustic scene classification in DCASE 2020 Challenge: generalization
  across devices and low complexity solutions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_15.html">
      <font color="black">Acoustic scene classification in DCASE 2020 Challenge: generalization
  across devices and low complexity solutions</font>
    </a>
  </h2>
  <font color="black">チャレンジの提出期限後、チャレンジの結果と提出の分析が追加されます。ここでは、データセットとベースラインシステムについて説明します。タスクは、複数のデバイスからのデータの分類、優れた一般化プロパティの必要性、およびを使用した分類の2つのサブタスクで構成されます。複雑度の低いソリューション。 
[要約]タスクは2つのサブタスクで構成されます：複数のデバイスからのデータの分類。チャレンジの提出期限後、チャレンジの結果と提出の分析が追加されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-29">
        <br><font color="black">2020-05-29</font>
      </time>
    </span>
</section>
<!-- paper0: Focus on the present: a regularization method for the ASR source-target
  attention layer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_16.html">
      <font color="black">Focus on the present: a regularization method for the ASR source-target
  attention layer</font>
    </a>
  </h2>
  <font color="black">観察に触発されて、CTCを活用して、デコーダーによって予測される出力トークンに対応するフレームにソースターゲットの注意をより集中させる新しい正則化方法が提案されます。実験により、最大7 \％および13 \％の安定した改善が明らかになりました。 TED-LIUM 2とLibriSpeechで提案されている正則化と比較して..ソースターゲットのアテンションヘッドは、現在のトークンよりもいくつかのトークンを予測できることがわかりました。 
[要約]この方法は、ctcとsource-ターゲットアテンションの両方が同じエンコーダ表現に作用しているという事実に基づいています。新しい方法を使用して、さらにいくつかのトークンを予測できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Normalization for Speaker Vectors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_17.html">
      <font color="black">Deep Normalization for Speaker Vectors</font>
    </a>
  </h2>
  <font color="black">広く使用されているSITWおよびCNCelebコーパスを使用した実験で、提案されたアプローチの有効性を示します。これらの実験では、DNFベースの正規化により、パフォーマンスが大幅に向上し、ドメイン外テストでも強力な一般化機能が示されました。分布は、特に均一なガウス分布を想定する一般的なPLDAスコアリング方法では、話者認識のパフォーマンスに深刻な影響を与える可能性があります。 
[概要]この論文は、新しい識別正規化フロー（dnf）モデルに基づく深い正規化アプローチを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br><font color="black">2020-04-07</font>
      </time>
    </span>
</section>
<!-- paper0: Quasi-Periodic Parallel WaveGAN: A Non-autoregressive Raw Waveform
  Generative Model with Pitch-dependent Dilated Convolution Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_18.html">
      <font color="black">Quasi-Periodic Parallel WaveGAN: A Non-autoregressive Raw Waveform
  Generative Model with Pitch-dependent Dilated Convolution Neural Network</font>
    </a>
  </h2>
  <font color="black">客観的および主観的な実験結果は、補助$ F_ {0} $機能がスケーリングされたときにQPPWGがPWGよりも優れていることを示しています。PWGは忠実度の高い音声生成を実現しますが、一般的で単純なネットワークアーキテクチャには、目に見えない補助基本周波数のピッチ制御性がありません（スケーリングされた$ F_ {0} $などの$ F_ {0} $）機能。さらに、QPPWGの中間出力の分析は、カスケード接続を使用してスペクトル信号と励起のような信号をそれぞれモデル化するQPPWGのより優れた扱いやすさと解釈可能性も示しています。 QP構造の固定および適応ブロック。 
[ABSTRACT] pwgは、小さい-フットプリントganベースの生の波形生成モデルです。コンパクトなモデルと非自己回帰（非-ar）および非因果的メカニズムにより、生成時間はリアルタイムよりもはるかに高速です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-25">
        <br><font color="black">2020-07-25</font>
      </time>
    </span>
</section>
<!-- paper0: Sound Event Detection and Separation: a Benchmark on Desed Synthetic
  Soundscapes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_19.html">
      <font color="black">Sound Event Detection and Separation: a Benchmark on Desed Synthetic
  Soundscapes</font>
    </a>
  </h2>
  <font color="black">サウンドイベントの時間のローカリゼーションがSEDシステムにとって依然として問題であることを示します。時間に関連する変更（イベントの時間位置とクリップの長さ）に応じて、DCASE2021タスク4への送信のパフォーマンスを分析します。非ターゲットサウンドイベントと残響の影響..また、残響と非ターゲットサウンドイベントがSEDシステムのパフォーマンスを大幅に低下させていることも示しています。 
[概要]特定のサウンドイベント検出の課題に焦点を当てた総合評価を設計しました。サウンドイベントの時間内のローカリゼーションがsedシステムにとって依然として問題であることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: CAMP: a Two-Stage Approach to Modelling Prosody in Context -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_20.html">
      <font color="black">CAMP: a Two-Stage Approach to Modelling Prosody in Context</font>
    </a>
  </h2>
  <font color="black">セグメント情報とバックグラウンドノイズ）; （2）十分なコンテキストなしで適切な韻律を決定することは不適切な問題です。また、注意を共同で訓練された期間モデルに置き換えると、韻律が大幅に改善されることがわかります。韻律モデリングの不適切な性質を軽減するために、構文と韻律空間よりも前に文脈依存を学習するためのテキストから派生した意味情報。 
[概要]この論文では、韻律モデリングの不適切な性質に対する解決策を提案します。テキストから派生した構文情報と意味情報を使用して、韻律空間上のコンテキスト依存アートを学習します。注意を共同でトレーニングされた期間モデルに置き換えます。韻律を大幅に改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Learning ASR-Robust Contextualized Embeddings for Spoken Language
  Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_21.html">
      <font color="black">Learning ASR-Robust Contextualized Embeddings for Spoken Language
  Understanding</font>
    </a>
  </h2>
  <font color="black">ソースコードはhttps://github.com/MiuLab/SpokenVecで入手できます。事前にトレーニングされた言語モデル（LM）を使用してコンテキスト化された単語表現を抽出することで、さまざまなNLPタスクで最先端のパフォーマンスを実現しました。ASRエラーの影響を軽減するための新しい混乱を意識した微調整方法を提案します。 -トレーニングを受けたLM。 
[要約]提案された方法は、事前に訓練されたlmへのasrエラーの影響を軽減するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-24">
        <br><font color="black">2019-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: FeatherTTS: Robust and Efficient attention based Neural TTS -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-03/eess.AS/paper_22.html">
      <font color="black">FeatherTTS: Robust and Efficient attention based Neural TTS</font>
    </a>
  </h2>
  <font color="black">さらに、自己回帰生成プロセスを所有する推論速度が遅いという問題があります。全体として、提案されたFeatherTTSは、単一のCPUでリアルタイムよりも$ 35 $ x高速になる可能性があります。この方法により、一般的に使用される停止トークン予測アーキテクチャを置き換えます。注意深い停止予測付き。 
[ABSTRACT] featherssiのシステムは、工業製品の安定性要件を満たすには十分ではありませんが、有用で有用な言語の要件を満たすことはまだできていません。また、音響機能の生成を3.5倍高速化しますタコトロンを超える回数</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
