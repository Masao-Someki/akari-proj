<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<title>Akari-2019-11-20の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
  <div class="header-logo">
    <a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
  </div>
</header>
<input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">

<div class="menubar">
<span class="bar"></span>
<span class="bar"></span>
<span class="bar"></span>
</div>

<ul>
<li><a id="home" href="../../index.html">Home</a></li>
<li><a id="about" href="../../teamAkariとは.html">About</a></li>
<li><a id="contact" href="../../contact.html">Contact</a></li>
<li><a id="contact" href="../../list/newest.html">New Papers</a></li>
<li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
</ul>

</label>
<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Transferring neural speech waveform synthesizers to musical instrument
  sounds generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.SD/paper_0.html">
      Transferring neural speech waveform synthesizers to musical instrument
  sounds generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      シンセサイザーの中で、WaveGlowはゼロショット学習で最高の可能性を示し、NSFは他のシナリオで最高の性能を発揮し、知覚的に自然なオーディオに近いサンプルを生成できました。WaveNet、WaveGlow、neural-sourceなどの最新の神経波形シンセサイザー-filter（NSF）モデルは、さまざまな波形生成方法にもかかわらず、音声合成で良好なパフォーマンスを示しました。大規模な知覚テストの結果は、3つのシンセサイザーのパフォーマンスが、音声データと事前に訓練されたときに改善されることを実証しました-音楽データの調整。これは、音楽オーディオ生成のための音声データからの知識の有用性を示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-27">
        <br>2019-10-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Network based End-to-End Query by Example Spoken Term Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.SD/paper_1.html">
      Neural Network based End-to-End Query by Example Spoken Term Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ここでは、CNNベースのマッチングがボトルネック機能を使用したDTWベースのマッチングよりも優れていることを示します。この場合、QbE-STDシステムの特徴抽出とパターンマッチングのステージは、互いに独立して最適化されます。多言語のボトルネック機能、および多言語機能がより多くのトレーニング言語でパフォーマンスを向上させることを示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Distributed Microphone Speech Enhancement based on Deep Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.SD/paper_2.html">
      Distributed Microphone Speech Enhancement based on Deep Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      3つのDNN SEシステムはすべて、拡散ノイズフィールド環境の音声信号の音響周波数ドメインで動作します。最初のシステムは、マイクごとにDNNモデルを構築して、記録されたノイズの多い音声信号を強調します。 3番目のシステムでは、チャネル依存のDNNを使用して、対応するノイズのある入力を強化し、チャネルごとに強化されたすべての出力が、ほぼクリーンな信号を構築するためのDNN融合モデル。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Partial AUC optimization based deep speaker embeddings with class-center
  learning for text-independent speaker verification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.SD/paper_3.html">
      Partial AUC optimization based deep speaker embeddings with class-center
  learning for text-independent speaker verification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      検証損失関数は話者検証のパイプラインと一致しますが、その実装は困難です。本書では、受信者動作特性（ROC）曲線（pAUC）の下の部分領域の最大化と呼ばれる検証損失関数を提案します。ディープ埋め込みベースのテキストに依存しない話者検証用。Speakerin the Wild（SITW）およびNIST SRE 2016データセットの実験は、提案されたpAUC損失関数が最新の識別損失関数と非常に競合することを示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern
  Architectures -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.SD/paper_4.html">
      End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern
  Architectures
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CTCまたはSeq2Seq基準でトレーニングされたResNet、Time-Depth Separable ConvNets、およびTransformerベースの音響モデルを研究します。LMデコードの有無にかかわらず、オプションでビームリスコアリングを使用してLibriSpeechデータセットで実験を行います。デコードおよび再スコアリング用の外部言語モデルを使用した％WER。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Neural Graph Embedding Methods for Natural Language Processing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_0.html">
      Neural Graph Embedding Methods for Natural Language Processing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、この欠点に対処するためにグラフ畳み込みネットワーク（GCN）が提案され、いくつかの問題にうまく適用されています。（2）既存のGCNモデルのほとんどは無向グラフの処理に制限されています。CNNやRNNなどの従来のニューラルネットワークはユークリッドデータを処理するように制限されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-08">
        <br>2019-11-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Span-based Joint Entity and Relation Extraction with Transformer
  Pre-training -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_1.html">
      Span-based Joint Entity and Relation Extraction with Transformer
  Pre-training
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このモデルは、単一のBERTパスで効率的に抽出される強力な文内ネガティブサンプルを使用してトレーニングされます。アブレーション研究では、事前トレーニング、強力なネガティブサンプリング、およびローカライズされたコンテキストの利点を実証します。共同エンティティおよび関係抽出のための複数のデータセットで最大2.6％のF1スコア。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-17">
        <br>2019-09-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Error Analysis for Vietnamese Named Entity Recognition on Deep Neural
  Network Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_2.html">
      Error Analysis for Vietnamese Named Entity Recognition on Deep Neural
  Network Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ベトナムのNERデータセットに異なる単語を埋め込んだBLSTM-CNN-CRFおよびBLSTM-CRFモデルで実験を行った後、BLSTM-CNN-CRFがより良い結果をもたらすことに気づいたため、このモデルのエラーを詳細に分析します。エラー分析の結果は、ベトナム語のNERのパフォーマンスを向上させ、将来の作業でコーパスの品質を向上させるために、徹底的な洞察を提供します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-17">
        <br>2019-11-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Deep and Dense Sarcasm Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_3.html">
      Deep and Dense Sarcasm Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、最終的な特徴マップの生成における以前の畳み込み出力の依存性の分析を提供します。最後に、ケーススタディを示し、標準CNNが誤分類する明確な皮肉の追加使用を正確に分類することをサポートします。確かに背景知識と常識的な推論が必要であり、以前の研究では、テキスト内に存在する語彙的、構文的、意味的な手がかりをキャプチャするための浅いモデルのみを調査しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-18">
        <br>2019-11-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: DCMN+: Dual Co-Matching Network for Multi-choice Reading Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_4.html">
      DCMN+: Dual Co-Matching Network for Multi-choice Reading Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、パッセージ、質問および回答オプション間の関係を双方向にモデル化するデュアルコマッチングネットワーク（DCMN）を提案します。2つの戦略（DCMN +）と統合されたDCMNは、5つのマルチ異なるドメインからの選択読解データセット：RACE、SemEval-2018タスク11、ROCStories、COIN、MCTest。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-30">
        <br>2019-08-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Deep Spiking Neural Networks for Large Vocabulary Automatic Speech
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_5.html">
      Deep Spiking Neural Networks for Large Vocabulary Automatic Speech
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、音響モデリングにSNNを使用し、いくつかの大規模な語彙認識シナリオでのパフォーマンスを評価します。前例のないエネルギー効率と迅速な情報処理能力に動機付けられ、音声認識にSNNを使用する方法を探ります。したがって、エネルギー効率の良いニューロモーフィックハードウェアを備えたSNNは、モバイルおよび組み込みデバイスでローカルに実行されるASRアプリケーションに魅力的なソリューションを提供します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Revision in Continuous Space: Unsupervised Text Style Transfer without
  Adversarial Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_6.html">
      Revision in Continuous Space: Unsupervised Text Style Transfer without
  Adversarial Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、提案された方法には、テキストスタイルの転送タスクを実行するときに、文の長さや特定の単語の存在など、複数のきめ細かい属性を同時に操作する能力があります。提案された方法は、5つの最先端の方法よりも大幅に優れています。VAEと2種類の予測子により、表現を見つけるために、離散空間の文からマッピングされる連続空間で勾配ベースの最適化を実行できます。目的の属性と保存されたコンテンツを持つターゲット文の。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-29">
        <br>2019-05-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: MMM: Multi-stage Multi-task Learning for Multi-choice Reading
  Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_7.html">
      MMM: Multi-stage Multi-task Learning for Multi-choice Reading
  Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの方法には、ドメイン外のデータセットを使用した粗調整段階と、より大きなドメイン内のデータセットを使用したマルチタスク学習段階の2つの連続段階が含まれます。 -多肢選択読解のためのタスク学習フレームワーク。MMMが4つの代表的なMCQAデータセットの最新技術を大幅に進歩させることを実証します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-01">
        <br>2019-10-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards unstructured mortality prediction with free-text clinical notes -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_8.html">
      Towards unstructured mortality prediction with free-text clinical notes
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは、死亡率予測の強化における非構造化データの可能性を示しており、現在の臨床予測方法により多くの生の非構造化データを組み込む必要性を示しています。 MIMIC-IIIデータセットでの院内死亡率の予測で評価されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Retrospective and Prospective Mixture-of-Generators for Task-oriented
  Dialogue Response Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_9.html">
      Retrospective and Prospective Mixture-of-Generators for Task-oriented
  Dialogue Response Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      前者は、現在のタイムステップまでの歴史的な専門家が生成した応答のみを考慮し、後者は、探索を奨励することによって将来の専門家が生成した応答を考慮します。また、各専門家をローカル損失を使用して特定の意図に特化させ、議長とすべての専門家がグローバル損失を使用して調整するように強制するグローバルおよびローカル（GL）学習スキームも考案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Hybrid Morpheme-Word Representation for Machine Translation of
  Morphologically Rich Languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_10.html">
      A Hybrid Morpheme-Word Representation for Machine Translation of
  Morphologically Rich Languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      モデルを従来のモデルと組み合わせることにより、さらなる改善が達成されます。このモデルは、（1）単語境界を認識する形態素レベルのフレーズ抽出、（2）形態素の最小エラー率トレーニングによって、古典的なフレーズベースのモデルを拡張します。単語レベルのBLEUを使用した高レベル翻訳モデル、および（3）形態素および単語レベルの言語モデルとの共同スコアリング.. Europarl（714K文のペア; 1550万英語の単語）を使用した英語からフィンランド語の評価は、統計的に有意な改善を示していますBLEUと人間の判断に基づく古典的なモデル。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Network based End-to-End Query by Example Spoken Term Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_11.html">
      Neural Network based End-to-End Query by Example Spoken Term Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      単一言語と多言語の両方のボトルネック機能を使用し、多言語機能がより多くのトレーニング言語でパフォーマンスが向上することを示します。以前は、DTWベースのマッチングを後部機能を使用しながらCNNベースのマッチングに置き換えることができることが示されました。 CNNベースのマッチングは、ボトルネック機能を使用したDTWベースのマッチングよりも優れていることを示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Hierarchical Contextualized Representation for Named Entity Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_12.html">
      Hierarchical Contextualized Representation for Named Entity Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、これらの2つの欠陥に対処し、階層的なコンテキスト表現で強化されたモデルを提案します。文レベルの表現と文書レベルの表現です。文レベルでは、単一の文の単語の異なる貢献を考慮して、ラベル埋め込みアテンションメカニズムを介して、独立したBiLSTMから学習した文表現。ドキュメントレベルでは、キー値メモリネットワークを採用して、コンテキスト情報の類似性に敏感な一意の単語ごとにドキュメント認識情報を記録します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-06">
        <br>2019-11-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: TENER: Adapting Transformer Encoder for Named Entity Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_13.html">
      TENER: Adapting Transformer Encoder for Named Entity Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、Transformerは、その並列性と有利なパフォーマンスにより、さまざまな自然言語処理（NLP）タスクで広く採用されています。方向と相対距離を意識した注意とスケールなしの注意を組み込むことにより、TransformerのようなエンコーダーがまさにNERにとっては、他のNLPタスクと同じくらい効果的です。それでも、NERのTransformerのパフォーマンスは、他のNLPタスクほど優れていません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br>2019-11-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Extended Answer and Uncertainty Aware Neural Question Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_14.html">
      Extended Answer and Uncertainty Aware Neural Question Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SQuADデータセットで実験を行った結果、このアプローチによりパフォーマンスが大幅に改善されることがわかりました。UBSは、入力テキストの段落から単語をコピーするモデルの信頼性と語彙から単語を生成する信頼性のバランスを改善することを目指しています。この論文では、テキストの特定の範囲が回答として機能する対応するテキストパッセージから質問を作成するタスクである、自動質問生成を研究します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Comprehensive Comparison of Machine Learning Based Methods Used in
  Bengali Question Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_15.html">
      A Comprehensive Comparison of Machine Learning Based Methods Used in
  Bengali Question Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      音質質問分類（QC）システムモデルは、音質QAシステムの前提条件です。この作業では、QAタイプ分類モデルを組み立てるフェーズを示します。QA分類システムは、人間が出した質問を適切な回答カテゴリにマッピングします。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-08">
        <br>2019-11-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: In Search of Credible News -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_16.html">
      In Search of Credible News
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは重要な問題です。疑わしい信頼性のニュースが最近、ソーシャルメディアで驚くべき規模で広まっているためです。これは、特に英語以外の言語については十分に研究されていない問題なので、 vs. 4つのオンラインソースから派生した偽のニュースデータセット。その後、豊富な機能セットに基づいて、信頼できるニュースと偽のニュースを自動的に区別するための、言語に依存しないアプローチを提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning Cross-lingual Embeddings from Twitter via Distant Supervision -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_17.html">
      Learning Cross-lingual Embeddings from Twitter via Distant Supervision
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本論文では、文献で驚くほど無視されてきた研究の方向性を探ります。特に、ソーシャルメディアの用途に合わせて調整された言語間の埋め込みを学習するために、ノイズの多いユーザー生成テキストを活用します。言語間埋め込み方法への挑戦、それはまた、コード切り替えの豊富さと絵文字と名前付きエンティティの共有語彙の存在のために重要な機会を提供することがわかります。最近の研究は、そのような表現を構築することが可能であることを示しています独立して学習した単一言語の埋め込みスペースを調整することにより、外部のバイリンガルデータがなくても正確な調整を取得できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-17">
        <br>2019-05-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Decompressing Knowledge Graph Representations for Link Prediction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_18.html">
      Decompressing Knowledge Graph Representations for Link Prediction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、エンティティとリレーションシップの埋め込みは、まず関数を解凍することにより、より表現力豊かで堅牢な空間に解凍され、その後、知識グラフ埋め込みモデルがこの新しい機能空間でトレーニングされます。いくつかのベンチマーク知識グラフと高度なリンク予測システムの実験結果は、本手法の一般化と有効性を示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern
  Architectures -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_19.html">
      End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern
  Architectures
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      LibriSpeechデータセットで、LMデコードの有無にかかわらず、オプションでビームリスコアリングを使用して実験を実行します。さらに、半教師ありトレーニングを行うことでLibriVoxのラベルなしデータを活用し、テストその他で5.29％WERに到達できることを示しますLibriSpeechからの標準の960時間のみをラベル付きデータとして使用します。デコードおよびリスコアリング用の外部言語モデルで5.18％WERに達します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Deep Poetry: A Chinese Classical Poetry Generation System -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_20.html">
      Deep Poetry: A Chinese Classical Poetry Generation System
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに重要なことは、ユーザーがシステムで詩を書くプロセスに参加できることです。ユーザーの便宜のために、システムをWeChatアプレットプラットフォームに展開し、ユーザーはいつでもどこでもモバイルデバイスでシステムを使用できます。このペーパーのデモビデオは、https：//youtu.be/jD1R_u9TA3Mで入手できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Hunting for Troll Comments in News Community Forums -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_21.html">
      Hunting for Troll Comments in News Community Forums
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      トロルとは異なる定義があります。これらの定義が賢明であることを示します。このような有料トロルの投稿を非トロルの投稿と81-82％の精度で区別できる2つの分類子を作成します。同じ分類子は、いわゆるトロールと非トロールの投稿で81-82％の精度を達成します。私たちの作業では、2種類の意見操作トロールを調べます。漏洩した評判管理契約から明らかになった有料トロールと、いくつかの異なる人々によってそのように呼ばれています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Adapt or Get Left Behind: Domain Adaptation through BERT Language Model
  Finetuning for Aspect-Target Sentiment Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_22.html">
      Adapt or Get Left Behind: Domain Adaptation through BERT Language Model
  Finetuning for Aspect-Target Sentiment Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      クロスドメイン適応BERT言語モデルは、バニラBERTベースやXLNetベースなどの強力なベースラインモデルよりも大幅に優れていることを示します。最後に、モデル予測エラーを解釈するためのケーススタディを実施します。ドメイン固有の言語モデルの微調整により、SemEval 2014 Task 4レストランデータセットで最新のパフォーマンスを実現できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-30">
        <br>2019-08-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Snowball for Few-Shot Relation Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_23.html">
      Neural Snowball for Few-Shot Relation Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験により、モデルは高品質のインスタンスを収集して少数ショットの関係学習を改善し、ベースラインと比較して大幅な改善を達成できることが示されています。その後、新しい関係とその少数ショットインスタンスが与えられると、RSNを使用してラベルのないコーパスから信頼できるインスタンスを蓄積します;これらのインスタンスは、リレーション分類子をトレーニングするために使用されます。リレーション分類子は、新しいリレーションの新しい事実をさらに識別できます。より具体的には、Relational Siamese Networks（RSN）を使用して、既存のリレーションとそのラベル付きデータに基づいて、インスタンス間の関係の類似性のメトリックを学習します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-29">
        <br>2019-08-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Sequential Attention-based Network for Noetic End-to-End Response
  Selection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_24.html">
      Sequential Attention-based Network for Noetic End-to-End Response
  Selection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      我々の結果は、過去にマルチターン応答選択のシーケンシャルマッチングアプローチの可能性が完全に活用されていないことを示しています。この論文では、マルチターン応答選択のチェーンシーケンスのみに基づくシーケンシャルマッチングモデルを調査します。提案されたモデルは、課題の上位にランクされることに加えて、最新の階層ベースのモデルを含む以前のすべてのモデルよりも優れており、2つの大規模なパブリックマルチモデルで新しい最新のパフォーマンスを実現します。応答選択ベンチマークデータセットを有効にします。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-01-09">
        <br>2019-01-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Natural Question Answering with a Small Model -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_25.html">
      Unsupervised Natural Question Answering with a Small Model
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この研究の貢献は、ここで紹介する方法が教師なし学習技術に依存し、言語モデルの教師なしトレーニングを補完することです。この研究ラインの目標は、広範なトレーニングなしで明示的に知識を追加できるようにすることです。論文では、「生の」外部知識を活用することで、はるかに小さなモデルでもこのような質問に答えることができるアーキテクチャについて説明しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Span Model for Open Information Extraction on Accurate Corpus -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_26.html">
      Span Model for Open Information Extraction on Accurate Corpus
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      新しく導入されたモデルは、両方のベンチマーク評価データセットで新しい最先端のパフォーマンスを実現します。この作業では、最初にトレーニングとテストセットの両方の側面からこの困難を軽減します。 n-ary Open IEにシーケンスラベリング定式化を採用。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-01-30">
        <br>2019-01-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Event detection in Colombian security Twitter news using fine-grained
  latent topic analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/cs.CL/paper_27.html">
      Event detection in Colombian security Twitter news using fine-grained
  latent topic analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの方法は、イベント固有のニュースのセットを発見することができます。これは、セキュリティ、暴力、犯罪関連のツイートに重点を置いて、さまざまなタイプのニュースでのTwitterスレッドへの人々の関与の広範な分析を行うためのベースラインです。私たちが使用する潜在的なトピック発見方法は、FastTextを使用してツイートのベクトル表現を構築し、K-meansクラスタリングアルゴリズムを介してツイートのクラスターを見つけます。約。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Transferring neural speech waveform synthesizers to musical instrument
  sounds generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/eess.AS/paper_0.html">
      Transferring neural speech waveform synthesizers to musical instrument
  sounds generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      シンセサイザーの中で、WaveGlowはゼロショット学習で最高の可能性を示し、NSFは他のシナリオで最高の性能を発揮し、知覚的に自然なオーディオに近いサンプルを生成できました。WaveNet、WaveGlow、neural-sourceなどの最新の神経波形シンセサイザー-filter（NSF）モデルは、さまざまな波形生成方法にもかかわらず、音声合成で良好なパフォーマンスを示しました。大規模な知覚テストの結果は、3つのシンセサイザーのパフォーマンスが、音声データと事前に訓練されたときに改善されることを実証しました-音楽データの調整。これは、音楽オーディオ生成のための音声データからの知識の有用性を示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-27">
        <br>2019-10-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Network based End-to-End Query by Example Spoken Term Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/eess.AS/paper_1.html">
      Neural Network based End-to-End Query by Example Spoken Term Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      単一言語と多言語の両方のボトルネック機能を使用し、多言語機能がより多くのトレーニング言語でパフォーマンスが向上することを示します。ここでは、CNNベースのマッチングがボトルネック機能を使用したDTWベースのマッチングよりも優れていることを示します。この場合、機能抽出QbE-STDシステムのパターンマッチングステージは、互いに独立して最適化されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Distributed Microphone Speech Enhancement based on Deep Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/eess.AS/paper_2.html">
      Distributed Microphone Speech Enhancement based on Deep Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最初のシステムは、マイクごとにDNNモデルを構築して、記録されたノイズの多い音声信号を強化し、2番目のシステムは、すべてのノイズのある記録を大きな特徴構造に結合し、DNNモデルによって強化します。ヒアリングインノイズテスト（TMHINT）データベース、および結果は、3つすべてのDNNベースのSEシステムが、音声品質と明瞭度が向上した元のノイズ破損信号を提供するのに対し、3番目のシステムは最高の信号対雑音比（ SNR）改善と最適な音声明瞭度.. 3番目のシステムに関しては、チャネル依存のDNNを使用して、対応するノイズのある入力を強化し、チャネルごとの強化された出力をすべてDNN融合モデルに入力して、ほぼクリーンな信号。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Partial AUC optimization based deep speaker embeddings with class-center
  learning for text-independent speaker verification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/eess.AS/paper_3.html">
      Partial AUC optimization based deep speaker embeddings with class-center
  learning for text-independent speaker verification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本論文では、テキストに依存しない話者照合に基づく深い埋め込みのために、受信者動作特性（ROC）曲線下の部分領域の最大化と呼ばれる検証損失関数を提案します。また、クラスセンターも提案します。提案された損失関数がパフォーマンスの識別損失に匹敵するために重要である訓練効率を改善するための訓練トライアル構築方法に基づく。損失関数は、最新の識別損失関数と非常に競争力があります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern
  Architectures -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-20/eess.AS/paper_4.html">
      End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern
  Architectures
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      デコードとリスコアリング用の外部言語モデルで5.18％WERに達しています。LibriSpeechデータセットで、LMデコードありとなし、オプションでビームリスコアリングを使用して実験を行います。ResNet-、Time-Depth Separable ConvNets-、およびTransformer- CTCまたはSeq2Seq基準で訓練された音響モデル。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本日更新された論文はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br>
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
