<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-08-11の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Predicting Afrobeats Hit Songs Using Spotify Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.SD/paper_0.html">
      <font color="black">Predicting Afrobeats Hit Songs Using Spotify Data</font>
    </a>
  </h2>
  <font color="black">この研究は、Afrobeatsジャンルのどの曲がSpotifyリスナーの間で人気になるかを予測することを目的として、ヒットソングサイエンスの問題に取り組みました。曲は、提供されたオーディオ機能を使用して、Spotify Web APIを介して生成されました。 
[要約] 2063曲のデータセットは、spotify web apiを介して生成されました。データセットは、spotifyのソフトウェアによって生成されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: VAW-GAN for Singing Voice Conversion with Non-parallel Training Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.SD/paper_1.html">
      <font color="black">VAW-GAN for Singing Voice Conversion with Non-parallel Training Data</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案されたフレームワークがベースラインフレームワークよりも優れたパフォーマンスを達成することを示しています。音声コンテンツから歌手のアイデンティティと歌の韻律（F0輪郭）のもつれを解くようにエンコーダーをトレーニングします。目に見えないターゲット歌手のアイデンティティを持ち、F0レンダリングを改善します。 
[要約]このペーパーでは、vawに基づく歌声変換フレームワークを提案します-gan.itは歌手IDとfsteinを使用してf0レンダリングを改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Acoustic Integrity Codes: Secure Device Pairing Using Short-Range
  Acoustic Communication -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.SD/paper_2.html">
      <font color="black">Acoustic Integrity Codes: Secure Device Pairing Using Short-Range
  Acoustic Communication</font>
    </a>
  </h2>
  <font color="black">私たちのシステムは、しきい値付きの3値決定関数を使用して、覆い隠し攻撃を検出できます。最初のペアリングには短距離音響通信を使用することを提案します。音響整合性コード（AIC）を設計することにより、以前のアプローチを改善します。音響物理層でのメッセージ認証。 
[ABSTRACT]これには既存のsdpシステムの使用を制限する共通のハードウェアインターフェイスが必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-18">
        <br><font color="black">2020-05-18</font>
      </time>
    </span>
</section>
<!-- paper0: Pop Music Transformer: Beat-based Modeling and Generation of Expressive
  Pop Piano Compositions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.SD/paper_3.html">
      <font color="black">Pop Music Transformer: Beat-based Modeling and Generation of Expressive
  Pop Piano Compositions</font>
    </a>
  </h2>
  <font color="black">特に、トランスフォーマーが音楽のビートバーフレーズの階層構造をより簡単に認識できるように、入力データにメトリック構造を課そうとしています。新しいデータ表現は、ローカルテンポ変更の柔軟性を維持し、このアプローチにより、既存のトランスフォーマーモデルよりも優れたリズム構造を持つポップピアノ音楽を構成するポップミュージックトランスフォーマーを構築します。 
[ABSTRACT]トランスフォーマーモデルは、大規模なmusic.data表現の主要な部分と見なすことができ、ローカルテンポの変更に柔軟性を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-01">
        <br><font color="black">2020-02-01</font>
      </time>
    </span>
</section>
<!-- paper0: ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in
  TDNN Based Speaker Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.SD/paper_4.html">
      <font color="black">ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in
  TDNN Based Speaker Verification</font>
    </a>
  </h2>
  <font color="black">最後に、チャネル依存フレームアテンションで統計プーリングモジュールを改善します。提案されたECAPA-TDNNアーキテクチャは、VoxCelebテストセットおよび2019 VoxCelebスピーカー認識チャレンジに基づく最新のTDNNベースのシステムを大幅に上回ります。SEブロックは、記録のグローバルプロパティに従ってチャネルを再スケーリングすることにより、フレームレイヤーの時間的コンテキストを拡張します。 
[ABSTRACT]時間遅延ニューラルネットワークは統計プーリングを使用して埋め込みを投影します。これにより、ネットワークはフレームに基づいてフレームの異なるサブセットに焦点を合わせることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-14">
        <br><font color="black">2020-05-14</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Speaker Diarization for an Unknown Number of Speakers with
  Encoder-Decoder Based Attractors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.SD/paper_5.html">
      <font color="black">End-to-End Speaker Diarization for an Unknown Number of Speakers with
  Encoder-Decoder Based Attractors</font>
    </a>
  </h2>
  <font color="black">話者数が不明な状態では、CALLHOMEでこのメソッドは15.29％DERを達成しましたが、x-vectorベースのクラスタリング方法は19.43％DER。を達成しました。2スピーカー条件では、この方法は2.69％のダイアライゼーションエラー率を達成しました（ DER）はシミュレートされた混合物で、CALLHOMEの2スピーカーサブセットでは8.07％DER、一方、バニラSA-EENDはそれぞれ4.56％および9.54％を達成しました。音声埋め込みシーケンスは、従来の自己注意型のend-to-ニューラルスピーカーダイアライゼーション（SA-EEND）ネットワークを終了します。 
[ABSTRACT]この方法は、話者の数の点で柔軟性が低くなります。これにより、同じ数の話者アクティビティを作成するために、いくつかの埋め込みシーケンスが作成されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br><font color="black">2020-05-20</font>
      </time>
    </span>
</section>
<!-- paper0: On Cross-Corpus Generalization of Deep Learning Based Speech Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.SD/paper_6.html">
      <font color="black">On Cross-Corpus Generalization of Deep Learning Based Speech Enhancement</font>
    </a>
  </h2>
  <font color="black">これらの技術は共に、訓練されていないコーパスの客観的了解度と品質スコアを大幅に改善します。さらに、一般化が期待できる公的に入手可能なデータセットを評価します。最後に、音声の短時間処理で小さなフレームシフトを使用すると、大幅に改善できることがわかります。コーパスの汎化。 
[ABSTRACT] dnnsは、多数のノイズとスピーカーを使用してトレーニングされた場合、トレーニングされていないノイズとスピーカーに一般化します。これらには、チャネルの正規化、より優れたトレーニングコーパス、短時間の1990年の変換におけるフレームシフト（stft）が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-10">
        <br><font color="black">2020-02-10</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring TTS without T Using Biologically/Psychologically Motivated
  Neural Network Modules (ZeroSpeech 2020) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.SD/paper_7.html">
      <font color="black">Exploring TTS without T Using Biologically/Psychologically Motivated
  Neural Network Modules (ZeroSpeech 2020)</font>
    </a>
  </h2>
  <font color="black">システムはまず、Mel Frequency Cepstral Coefficient（MFCC）フレームをEcho-State Network（ESN）で処理し、皮質マイクロ回路での計算をシミュレートします。次に、離散化された信号は、ソースフィルターのニューラルネットワーク実装を介して音波形に戻されます。音声生成のモデル..私たちは、生物学的/心理学的問題としての人間の言語の教師なし学習に特に関心を持つ人工ニューラルネットワーク（ANN）の生物学的/心理学的動機付けモジュールを使用して課題に対処しました。 
[要約]人工ニューラルネットワークの生物学的/心理学的に動機付けられたモジュールを使用して課題に対処しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br><font color="black">2020-05-11</font>
      </time>
    </span>
</section>
<!-- paper0: Subword Regularization: An Analysis of Scalability and Generalization
  for End-to-End Automatic Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.SD/paper_8.html">
      <font color="black">Subword Regularization: An Analysis of Scalability and Generalization
  for End-to-End Automatic Speech Recognition</font>
    </a>
  </h2>
  <font color="black">最近の研究では、トレーニング中にサブワードセグメンテーションをサンプリングすると、ニューラル機械翻訳および音声認識モデルの正則化機能として機能し、パフォーマンスが向上することが示唆されています。特に、トレーニングデータセットのサイズに応じてサブワード正則化の寄与を評価します。この作業では、ストリーミングエンドツーエンドの音声認識タスクに対するサブワードセグメンテーションサンプリング法の正則化効果に関する原理的な調査を行います。 
[ABSTRACT]サブワードの正則化により、最大2万時間のデータセットを持つ大規模な設定でも、相対的なワードエラーレートの削減（2-8％）が一貫して改善されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Opus Low Bit Rate Quality with Neural Speech Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.SD/paper_9.html">
      <font color="black">Improving Opus Low Bit Rate Quality with Neural Speech Synthesis</font>
    </a>
  </h2>
  <font color="black">LPCNetは複雑性が低く、レイテンシが低いRNNベースの生成モデルであり、携帯電話で実際に実装できます。リスニングテストでは、同じ6 kb / sのOpusビットストリームに対して、LPCNetを使用した合成音声が明らかに標準のOpusデコーダ..レートがさらに低下すると、パラメトリックコーダーは波形コーダーよりもパフォーマンスが向上する傾向があります。 
[ABSTRACT] opusは波形マッチングコーダーであり、レートが10 kb / sを下回ると品質が急速に低下します。これにより、互換性を損なうことなく既存の音声およびオーディオ波形コーダーのデコード品質を向上させる方法が開かれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-12">
        <br><font color="black">2019-05-12</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Lingual Speaker Verification with Domain-Balanced Hard Prototype
  Mining and Language-Dependent Score Normalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.SD/paper_10.html">
      <font color="black">Cross-Lingual Speaker Verification with Domain-Balanced Hard Prototype
  Mining and Language-Dependent Score Normalization</font>
    </a>
  </h2>
  <font color="black">クロスリンガルトライアルのスコアリングを強化するために、言語に依存するs-normスコアの正規化を提案します。ガウスバックエンド言語モデルが英語を含むように埋め込んだテストスピーカーを検出した場合、AAMでクロスランゲージ補正オフセットが決定されます-softmaxスピーカーのプロトタイプは、予想される最大の詐称者平均スコアから差し引かれます。サンプルマイニング手法は、人気のあるAAM-softmax損失関数のスピーカープロトタイプ間のスピーカー距離を効率的に活用して、ドメインレベルでバランスの取れた挑戦的なトレーニングバッチを構築します。 
[ABSTRACT]サンプルマイニング手法は、人気のaann-softmax損失関数のスピーカープロトタイプ間のスピーカー距離を効率的に活用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-15">
        <br><font color="black">2020-07-15</font>
      </time>
    </span>
</section>
<!-- paper0: A fully recurrent feature extraction for single channel speech
  enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.SD/paper_11.html">
      <font color="black">A fully recurrent feature extraction for single channel speech
  enhancement</font>
    </a>
  </h2>
  <font color="black">この目的のために、CNNレイヤーを抽出する機能に反復係数を追加して、単一チャネルの音声強調のためのロバストなコンテキスト認識機能抽出戦略を導入します。抽出された機能でノイズ属性のローカル統計をキャプチャする上でロバストであるため、提案されたモデルは、非常に騒々しい条件でも、音声キューの区別に非常に効果的です。しかし、バニラCNNモジュールの特徴抽出能力は、統合されたたたみ込みカーネルの次元制約によって制限され、ノイズコンテキスト情報を適切にモデル化できませんでした特徴抽出段階で。 
[ABSTRACT] cnnモジュールの特徴抽出能力は、ネットワークのノイズコンテキストを適切にモデル化できませんでした。新しいモデルは、非常に騒々しい状況でも、音声キューの区別に非常に効果的です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-09">
        <br><font color="black">2020-06-09</font>
      </time>
    </span>
</section>
<!-- paper0: Class LM and word mapping for contextual biasing in End-to-End ASR -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.SD/paper_12.html">
      <font color="black">Class LM and word mapping for contextual biasing in End-to-End ASR</font>
    </a>
  </h2>
  <font color="black">また、コンテキストFSTとベースモデルの間のコストの不一致を調整する簡単な方法を提案します。このアルゴリズムは、名前付きエンティティ発話のWERをさらに31％削減します。ASRでは、多くの発話に豊富な名前付きエンティティが含まれます。 
[ABSTRACT]これらのエンティティはユーザーまたは場所に固有であり、トレーニング中には表示されません。これらは単一のトレーニング可能なニューラルネットワークモデルで使用されます。論文では、まれなエンティティの単語を発音を介して一般的な単語にマッピングするアルゴリズムを提案しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-10">
        <br><font color="black">2020-07-10</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Learning Bloch Simulations for MR Fingerprinting by Invertible Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.IV/paper_0.html">
      <font color="black">Learning Bloch Simulations for MR Fingerprinting by Invertible Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">MRの物理的制約によりMRパラメータの推定が困難な場合、この利点は特に顕著になります。磁気共鳴指紋法（MRF）により、高速でマルチパラメトリックなMRイメージングが可能になります。概念実証として、前方学習の利点を示すさまざまな実験を行いますMRパラメータ推定を改善するためのプロセス、つまりブロッホシミュレーション。 
[ABSTRACT] mrfは、mrf.mrfに基づくディクショナリスタイルの再構成に基づいています。可逆ニューラルネットワークを利用して、mrパラメーターからフィンガープリントへのフォワードプロセスとバックワードプロセスを学習できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Estimation of Attenuation Coefficients for Simultaneous PET/MRI Using
  Both MRI and PET Data Combining Bayesian Deep Learning pseudo-CT and Maximum
  Likelihood Estimation of Activity and Attenuation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.IV/paper_1.html">
      <font color="black">Estimation of Attenuation Coefficients for Simultaneous PET/MRI Using
  Both MRI and PET Data Combining Bayesian Deep Learning pseudo-CT and Maximum
  Likelihood Estimation of Activity and Attenuation</font>
    </a>
  </h2>
  <font color="black">これらの出力は、減衰マップを改善するためにPET放出データを使用するMLAA再構成と組み合わされます。UpCT-MLAAは、金属インプラント領域外の質的および量的に正確な解剖学的描写を提供しながら、金属インプラントの減衰係数を推定しました。アプローチ（UpCT-MLAA）、骨盤病変におけるPETの取り込みの正確な推定を示し、金属インプラントの回復を示します。 
[要約]提案されたアプローチは、mriコントラストに基づく脳ネットワークに基づいています。それは、疑似の不確実性推定値を生成します-mrデータの制限を定量化するためのct</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-10">
        <br><font color="black">2020-01-10</font>
      </time>
    </span>
</section>
<!-- paper0: Norm-in-Norm Loss with Faster Convergence and Better Performance for
  Image Quality Assessment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.IV/paper_2.html">
      <font color="black">Norm-in-Norm Loss with Faster Convergence and Better Performance for
  Image Quality Assessment</font>
    </a>
  </h2>
  <font color="black">トレーニング後、最小二乗回帰を適用して、予測品質から主観品質への線形マッピングを決定します。再現可能な科学研究については、当社のコードがhttps://github.com/lidq92/LinearityIQAで公開されています。モデルは、この困難な問題に対して最先端の予測パフォーマンスも実現します。 
[ABSTRACT]新しい損失は2つの一般的なiqaパフォーマンス基準と密接に関連しています。msは他の2つのパフォーマンス基準に関連していることが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: The Ensemble Method for Thorax Diseases Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.IV/paper_3.html">
      <font color="black">The Ensemble Method for Thorax Diseases Classification</font>
    </a>
  </h2>
  <font color="black">胸部X線画像データセットの実験結果は、この新しい重み付けスキームが分類パフォーマンスを向上させること、またEfficientNetからのトレーニング最適化がパフォーマンスをさらに向上させることを示しています。実際の単語の医療画像分類で見られる一般的な問題は、正のパターンが通常まれであるデータセット内の正と負のパターン。このホワイトペーパーでは、損失関数のトレーニングパターンの重みは、クラスのトレーニングパターンの数だけでなく、さまざまなノードにも基づいて設計されています。それらの1つはこのトレーニングパターンをポジティブとして扱い、他の1つはネガティブとして扱います。 
[要約]提案された方法は、胸部疾患分類問題の最先端のディープネットワークアーキテクチャに基づいています。提案された代替方法との公平な比較を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-07">
        <br><font color="black">2020-08-07</font>
      </time>
    </span>
</section>
<!-- paper0: Benchmarking the Robustness of Semantic Segmentation Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.IV/paper_4.html">
      <font color="black">Benchmarking the Robustness of Semantic Segmentation Models</font>
    </a>
  </h2>
  <font color="black">まず、全画像分類とは逆に、モデルの堅牢性はモデルのパフォーマンスとともに増加します。ほとんどの場合、ベンチマーク調査に基づいて、いくつかの新しい洞察を得ています。調査の現実性を高めるために、Cityscapesから生成された約400,000枚の画像を利用します。 、PASCAL VOC 2012、ADE20K。 
[ABSTRACT]ベンチマーク調査に基づいて、多くの新しい洞察を得ています。これには、最先端のモデルを使用するdeeplabv3というモデルが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-14">
        <br><font color="black">2019-08-14</font>
      </time>
    </span>
</section>
<!-- paper0: IF-Net: An Illumination-invariant Feature Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.IV/paper_5.html">
      <font color="black">IF-Net: An Illumination-invariant Feature Network</font>
    </a>
  </h2>
  <font color="black">さらに、ROI損失とハードポジティブマイニング戦略をトレーニングスキームとともに提案します。これにより、大きな照明変化条件を処理する生成された記述子の能力を強化できます。トレーニングデータの種類だけでなく、次の順序もわかります。公開されたパッチマッチングベンチマークでのアプローチを評価し、いくつかの最先端の方法と比較して最高の結果を達成します。 
[ABSTRACT]記述子は多くの場合、パフォーマンスを低下させる多くの実用的な要因の影響を受けます。これらの要因の中で、堅牢な汎用記述子を生成することを目的としたif-netを提案します。このために、いくつかのデータセットのスケジューリング方法を調査し、分離を提案しますマッチング精度を向上させるトレーニングスキーム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Nighttime Dehazing with a Synthetic Benchmark -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.IV/paper_6.html">
      <font color="black">Nighttime Dehazing with a Synthetic Benchmark</font>
    </a>
  </h2>
  <font color="black">この問題に対処するために、ヘイズ除去から色補正をほどく前に、最適なスケールの最大反射率を提案し、それらを順番に処理します。アクティブな人工光源からの不均一な照明とヘイズ吸収/ scattering ..データセットとソースコードの両方が\ url {https://github.com/chaimi2013/3R}で利用できるようになります。 
[ABSTRACT]大規模なベンチマークデータセットがないと、進行が妨げられます。代わりに、以前の分析分布から実際の明るい色をサンプリングすることにより、現実的な夜間ファジーを作成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: An Explainable 3D Residual Self-Attention Deep Neural Network FOR Joint
  Atrophy Localization and Alzheimer's Disease Diagnosis using Structural MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.IV/paper_7.html">
      <font color="black">An Explainable 3D Residual Self-Attention Deep Neural Network FOR Joint
  Atrophy Localization and Alzheimer's Disease Diagnosis using Structural MRI</font>
    </a>
  </h2>
  <font color="black">私たちが提案する3D ResAttNetメソッドは、2つの変化する分類タスクの実際のデータセットからの被験者の大規模コホートで評価されました（つまり、AD対NCおよびsMCI対pMCIタスクの精度はそれぞれ97.1％および84.1％です。.実験結果提案されたアプローチは、最新のモデルよりもパフォーマンスが大幅に向上することを示しています。
[要約]提案された方法は、アルツハイマー病の発症に使用されています。広告の早期診断のために、コンピューター支援アプローチによって提案されました。 。新しい方法は、広告を開発するためのツールとして使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: FISTA-Net: Learning A Fast Iterative Shrinkage Thresholding Network for
  Inverse Problems in Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.IV/paper_8.html">
      <font color="black">FISTA-Net: Learning A Fast Iterative Shrinkage Thresholding Network for
  Inverse Problems in Imaging</font>
    </a>
  </h2>
  <font color="black">FISTA-Netの重要な部分は、エンドツーエンドのトレーニングを通じて効果的に学習できる非線形しきい値処理の近位オペレーターネットワークを開発することです。この論文では、FISTA-Netという名前のモデルベースの深層学習ネットワークを提案します。モデルベースの高速反復収縮/しきい値アルゴリズム（FISTA）の解釈可能性と一般性のメリット、およびデータ駆動型ニューラルネットワークの強力な正則化と調整不要のメリットを組み合わせることにより。勾配ステップサイズ、しきい値、およびしきい値を含むFISTA-Netのすべてのパラメーター2ステップの更新ウェイトは調整不要であり、手作りではなくトレーニングデータから学習されます。 
[ABSTRACT] fista-netは、fistaをディープネットワークにキャストすることによって設計されました。すべての側面には、さまざまなイメージングタスクのさまざまなパラメーターを最適化できるユーザーのモデルが含まれます。emtとsparse-両方のビューctで、優れた結果が得られます状態-最先端のモデル-ベースのディープラーニング手法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-06">
        <br><font color="black">2020-08-06</font>
      </time>
    </span>
</section>
<!-- paper0: A model-guided deep network for limited-angle computed tomography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.IV/paper_9.html">
      <font color="black">A model-guided deep network for limited-angle computed tomography</font>
    </a>
  </h2>
  <font color="black">この論文では、最初に限定角度コンピュータ断層撮影（CT）画像再構成の変分モデルを提案し、次にモデルをエンドツーエンドのディープネットワークに変換します。ペナルティ法を使用してモデルを解決し、それを3つの反復サブ問題。最初のサブ問題は、周波数領域のサイノグラムの以前の情報を使用してサイノグラムを完成させ、2番目は、空間ドメインのCT画像の以前の情報を使用してCTイメージを調整し、最後のサブ問題は、最初の2つのサブ問題..私たちのネットワークは、サイノグラムとCT画像の両方に取り組み、不完全なデータによって引き起こされるアーティファクトを同時に抑制し、CT画像の微細な構造情報を回復できます。各反復で、畳み込みニューラルネットワーク（CNN）を使用します。 ）最初の2つのサブ問題の解を近似し、それにより、限定角度CT画像再構成のためのエンドツーエンドのディープネットワークを取得します。 
[要約]研究者は、私たちの方法が既存の限定角度ct画像再構成法よりも優れていることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning from Dual-Energy Information for Whole-Heart Segmentation
  in Dual-Energy and Single-Energy Non-Contrast-Enhanced Cardiac CT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.IV/paper_10.html">
      <font color="black">Deep Learning from Dual-Energy Information for Whole-Heart Segmentation
  in Dual-Energy and Single-Energy Non-Contrast-Enhanced Cardiac CT</font>
    </a>
  </h2>
  <font color="black">VNC画像の自動セグメンテーションは、参照セグメンテーションとの良好な一致を示し、平均Dice類似度係数は0.897 \ pm 0.034、平均対称表面距離は1.42 \ pm 0.45 mmでした。独立した複数のNCCT画像から214（74％）のNCCT画像ベンダーのマルチセンターセットでは、2人のオブザーバーが自動セグメンテーションがほぼ正確またはそれ以上であることに同意しました。各CCTA画像で、左心室（LV）心筋、LV腔、右心室、左心房、右心房の手動参照セグメンテーション大動脈および肺動脈幹が取得され、対応するVNC画像に伝播されました。 
[ABSTRACT]これは、ct（ncct）スキャンの使用を促進するために使用できます。これは、vnc画像またはncct画像のいずれかで自動セグメンテーションのために3d cnnsをトレーニングするために使用されました。この方法は、追加の心臓測定の定量化を可能にする可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: A Bayesian Filter for Multi-view 3D Multi-object Tracking with Occlusion
  Handling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.IV/paper_11.html">
      <font color="black">A Bayesian Filter for Multi-view 3D Multi-object Tracking with Occlusion
  Handling</font>
    </a>
  </h2>
  <font color="black">提案されたアルゴリズムは、最新のWILDTRACKSデータセットで評価され、新しいデータセットの非常に混雑したシーンで機能することが実証されています。この論文では、マルチカメラとは関係なく、単眼検出器トレーニングのみを必要とするオンラインマルチカメラマルチオブジェクトトラッカーを提案提案されたアルゴリズムは、カメラ全体の検出の総数が線形に複雑であるため、カメラの数に応じて適切にスケーリングされます。 
[要約]提案されたアルゴリズムは、カメラ全体の検出の総数に線形の複雑さがあるため、カメラの数に応じて適切にスケーリングされます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br><font color="black">2020-01-13</font>
      </time>
    </span>
</section>
<!-- paper0: Reinforcement Learning Based Handwritten Digit Recognition with
  Two-State Q-Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.IV/paper_12.html">
      <font color="black">Reinforcement Learning Based Handwritten Digit Recognition with
  Two-State Q-Learning</font>
    </a>
  </h2>
  <font color="black">アプローチのベンチマークには3つのデータセットが使用されています。提案されたハイブリッド分類器のパフォーマンスは、確立された強化学習技術、AlexNet、CNN最近傍分類器、CNNSupport Vector Machine Classifierなどの他の現代的な技術と比較されています。手法は、畳み込みニューラルネットワーク（CNN）から抽出された特徴マップを使用して、過去の履歴と共にQstatesに含めます。 
[ABSTRACT]特徴マップの次元が高いため、状態の数が非常に多いです。私たちのアプローチは、これらの現代的なハイブリッド分類子よりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-28">
        <br><font color="black">2020-06-28</font>
      </time>
    </span>
</section>
<!-- paper0: Spatially Regularized Parametric Map Reconstruction for Fast Magnetic
  Resonance Fingerprinting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.IV/paper_13.html">
      <font color="black">Spatially Regularized Parametric Map Reconstruction for Fast Magnetic
  Resonance Fingerprinting</font>
    </a>
  </h2>
  <font color="black">この方法では、50人の患者のテストセットでの辞書マッチングと比較して、T1H2Oマップでは0.048 $ \ pm $ 0.011、FFマップでは0.027 $ \ pm $ 0.004の正規化二乗平均平方根誤差が達成されました。大腿および脚で撮像されたさまざまな神経筋疾患の164人の患者からなる高度に不均一なデータセット。MRFT1-FF、水のT1緩和時間（T1H2O）および脂肪分率（FF）マッピングのMRFシーケンスを使用してメソッドを評価しました。 
[ABSTRACT] mrfは辞書照合ベースの再構築に基づいています。非常に高速なシステムを取り除くのは困難です。mrfを使用して新しいメソッドを開発できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-09">
        <br><font color="black">2019-11-09</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Learning Bloch Simulations for MR Fingerprinting by Invertible Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_0.html">
      <font color="black">Learning Bloch Simulations for MR Fingerprinting by Invertible Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">概念実証として、フォワードプロセス、つまりブロッホシミュレーションを学習してMRパラメータ推定を改善することの利点を示すさまざまな実験を実行します。したがって、INNは現在の逆方向ベースのNNに代わる実行可能な代替策になる可能性があります。 MRF再構成用.. MRの物理的制約のためにMRパラメータの推定が困難な場合、この利点は特に強調されます。 
[ABSTRACT] mrfは、mrf.mrfに基づくディクショナリスタイルの再構成に基づいています。可逆ニューラルネットワークを利用して、mrパラメーターからフィンガープリントへのフォワードプロセスとバックワードプロセスを学習できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Minimum Class Confusion for Versatile Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_1.html">
      <font color="black">Minimum Class Confusion for Versatile Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">このようなペアごとのクラスの混乱を減らすことで、大幅な転送の増加につながることを明らかにします。コードはhttps://github.com/thuml/Versatile-Domain-Adaptation。で入手できます。このために、このペーパーではVersatile Domain Adaptation（VDA）について説明します。ここで、1つのメソッドが変更なしで複数の異なるDAシナリオを処理できます。 
[ABSTRACT]新しいdaメソッドは通常、特定のシナリオに対してのみ設計されており、調整されていないシナリオでは十分に機能しない可能性があります。この目標がなければ、ドメインアライメント以外のより一般的な帰納的バイアスを検討する必要があります。これにはペアワイズクラスの削除が含まれます大幅な転送の増加につながる混乱</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-08">
        <br><font color="black">2019-12-08</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Low-bitwidth Data Free Quantization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_2.html">
      <font color="black">Generative Low-bitwidth Data Free Quantization</font>
    </a>
  </h2>
  <font color="black">コードはhttps://github.com/xushoukai/GDFQで入手できます。3つのデータセットでの広範囲な実験により、この方法の有効性が実証されています。さらに、元のデータがないため、最近開発された生成的敵対的ネットワーク（GAN）データの生成には適用できません。 
[ABSTRACT]既存の量子化方法では、キャリブレーションのために元のデータが必要です。そのため、それらを適用してデータを生成することはできません。これは、元のデータがないためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-07">
        <br><font color="black">2020-03-07</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Private and Agnostic Feature for Modality Adaptive Face
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_3.html">
      <font color="black">Domain Private and Agnostic Feature for Modality Adaptive Face
  Recognition</font>
    </a>
  </h2>
  <font color="black">具体的には、この論文では、特徴集約ネットワーク（FAN）を提案します。これには、絡み合い表現モジュール（DRM）、特徴融合モジュール（FFM）、および適応ペナルティメトリック（APM）学習セッションが含まれます。次に、FFMで、アイデンティティ特徴が融合されます。ドメイン機能は、クロスモーダル双方向アイデンティティ機能変換を実現します。これにより、モダリティ情報とアイデンティティ情報がさらに解かれます。ベンチマークのクロスモーダル顔データセットでの広範な実験により、当社のFANがSOTAメソッドよりも優れていることが示されています。 
[ABSTRACT]ほとんどの既存の作品は、クロスモーダルの顔の合成用に設計された差別的な機能に焦点を当てています。代わりに、ドメインを学習して利用する方法-この機能の焦点はプライベートな機能です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Norm-in-Norm Loss with Faster Convergence and Better Performance for
  Image Quality Assessment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_4.html">
      <font color="black">Norm-in-Norm Loss with Faster Convergence and Better Performance for
  Image Quality Assessment</font>
    </a>
  </h2>
  <font color="black">再現可能な科学研究のために、私たちのコードはhttps://github.com/lidq92/LinearityIQAで公開されています。提案されたモデルはまた、この困難な問題に関する最先端の予測パフォーマンスを実現します。具体的には、まず、予測された品質スコアと対応する主観的な品質スコア。 
[ABSTRACT]新しい損失は2つの一般的なiqaパフォーマンス基準と密接に関連しています。msは他の2つのパフォーマンス基準に関連していることが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: The Ensemble Method for Thorax Diseases Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_5.html">
      <font color="black">The Ensemble Method for Thorax Diseases Classification</font>
    </a>
  </h2>
  <font color="black">胸部X線画像データセットの実験結果は、この新しい重み付けスキームが分類パフォーマンスを向上させること、またEfficientNetからのトレーニング最適化がパフォーマンスをさらに向上させることを示しています。このホワイトペーパーでは、損失関数のトレーニングパターンの重みは、クラス内のトレーニングパターンの数だけでなく、それらの1つがこのトレーニングパターンをポジティブとして処理し、他のノードがネガティブとして処理するさまざまなノードでも同様です。実際の単語の医用画像分類でよく見られる問題は、ポジティブパターンが通常まれであるデータセット内のポジティブパターンとネガティブパターンの固有の不均衡。 
[要約]提案された方法は、胸部疾患分類問題の最先端のディープネットワークアーキテクチャに基づいています。提案された代替方法との公平な比較を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-07">
        <br><font color="black">2020-08-07</font>
      </time>
    </span>
</section>
<!-- paper0: MHSA-Net: Multi-Head Self-Attention Network for Occluded Person
  Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_6.html">
      <font color="black">MHSA-Net: Multi-Head Self-Attention Network for Occluded Person
  Re-Identification</font>
    </a>
  </h2>
  <font color="black">MHSAMは主要な地元の人物情報を適応的にキャプチャし、人物照合のために画像の効果的な多様性埋め込みを生成します。https：//github.comでモデルをリリースしました（および論文が承認された後にソースコードをリリースします）。 / hongchenphd / MHSA-Net ..広範なアブレーション研究を通じて、構造化自己注意ブランチと注意競合メカニズムの両方がMHSA-Netのパフォーマンス向上に寄与することを確認しました。 
[ABSTRACT] mhsa-紙には2つの新しいコンポーネントが含まれています：マルチヘッド自己注意ブランチ（mhsab）と注意競合メカニズム（acm）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Road Segmentation for Remote Sensing Images using Adversarial Spatial
  Pyramid Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_7.html">
      <font color="black">Road Segmentation for Remote Sensing Images using Adversarial Spatial
  Pyramid Networks</font>
    </a>
  </h2>
  <font color="black">ジェネレーターは高品質の合成画像を生成するように学習され、弁別器はそれらを区別しようとします。特に、このモデルは、マサチューセッツのデータセットで14.89Mパラメーターと86.78B FLOPを使用し、4分の1に削減しています。 FLOPsですが、評価で使用される最先端のアプローチの中で、トップパフォーマーよりも高い精度（+ 3.47％IOU）です。生成ピラミッドネットワークに機能ピラミッドネットワークを組み込んで、ソースドメインとターゲットドメインの差を最小限に抑えます。 
[ABSTRACT]たとえば、私たちは合成画像に構造化ドメイン適応を適用する新しいモデルを導入します。ジェネレータは高品質の合成画像を生成するように学習され、弁別器はそれらを区別しようとします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Eyes: Binocular Depth-from-Focus on Focal Stack Pairs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_8.html">
      <font color="black">Deep Eyes: Binocular Depth-from-Focus on Focal Stack Pairs</font>
    </a>
  </h2>
  <font color="black">これらを統合BDfF-Netに統合して高品質の深度マップを取得する方法を示します。このホワイトペーパーでは、両方のタイプのキューを同時に使用して深度推論を行う統合学習ベースの手法を紹介します。包括的な実験により、アプローチは、精度と速度の両方で最先端技術を上回り、人間の視覚システムを効果的にエミュレートします。 
[ABSTRACT]調査によると、私たちのアプローチは、最新の精度と速度の両方を上回っています。これにより、両方の人間の視覚システムが効果的にエミュレートされます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2017-11-29">
        <br><font color="black">2017-11-29</font>
      </time>
    </span>
</section>
<!-- paper0: DeepSFM: Structure From Motion Via Deep Bundle Adjustment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_9.html">
      <font color="black">DeepSFM: Structure From Motion Via Deep Bundle Adjustment</font>
    </a>
  </h2>
  <font color="black">この作業では、従来のバンドル調整（BA）に触発された物理駆動型アーキテクチャ、つまりDeepSFMを設計します。これは、深度とポーズの推定にそれぞれ2つのコストボリュームベースのアーキテクチャで構成され、両方を繰り返し実行して両方を改善します。有望なトレンドの1つ明示的な構造制約を適用することです。ネットワークへの3Dコスト量。 
[ABSTRACT]既存の方法は通常、正確なカメラポーズを前提としています。既存の設計作業は実際には非現実的です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-20">
        <br><font color="black">2019-12-20</font>
      </time>
    </span>
</section>
<!-- paper0: Measuring shape relations using r-parallel sets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_10.html">
      <font color="black">Measuring shape relations using r-parallel sets</font>
    </a>
  </h2>
  <font color="black">測定値は、オブジェクトの体積や面積のように単純ですが、個々のオブジェクトの形状とそれらのペアごとの幾何学的関係についてさらに詳しく説明します。参照オブジェクトの$ r $ -parallelセットを生成し、 $ r $ -parallelセットと観測されたオブジェクト、そしてこれらの交差のメジャーを定義します。最後に、形状のコレクションとそれらの相互作用の要約統計量を提案します。 
[要約]私たちの理論は、2つのオブジェクト間の関係に基づいています：参照オブジェクトと観測されたオブジェクト。私たちは、公に入手可能なfib-大人の齧歯類のsem 3dデータセットでこれらの測定値を評価します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: RocNet: Recursive Octree Network for Efficient 3D Deep Representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_11.html">
      <font color="black">RocNet: Recursive Octree Network for Efficient 3D Deep Representation</font>
    </a>
  </h2>
  <font color="black">実験結果は、特に3D再構築タスクで、既存の方法と比べてトレーニング時間が短いのに、アルゴリズムが精度を維持しながらメモリ消費を抑えていることを示しています。32、64、128グリッドを潜在空間のわずか80フロートに圧縮した結果を示しています。 3D形状分類、3D形状再構成、形状生成の3つの実験により、いくつかの公に利用可能なデータセットで提案された方法の有効性と効率を実証します。 
[要約]公開されているいくつかのデータセットに対して、提案された方法の有効性と効率を実証しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Accelerated Stochastic Gradient-free and Projection-free Methods -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_12.html">
      <font color="black">Accelerated Stochastic Gradient-free and Projection-free Methods</font>
    </a>
  </h2>
  <font color="black">特に、提案された運動量加速技術に基づくフランクウルフ法の加速フレームワークを提示します。具体的には、SPIDERの分散減少法に基づく加速確率ゼロ次フランクウルフ（Acc-SZOFW）法を提案します。 / SpiderBoostと新しい運動量加速技術..本稿では、制約付きの確率的および有限和の非凸最適化を解決するために、加速確率勾配なしおよび投影なし（別名、ゼロ次フランクウォルフ）メソッドのクラスを提案します。 。 
[ABSTRACT]これは、加速された確率的ゼロ次です-解決します。この方法は、スパイダー/スパイダーブーストの新しい変動削減手法に基づいています。これらの方法は、必要な大きなバッチを緩和するために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Benchmarking the Robustness of Semantic Segmentation Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_13.html">
      <font color="black">Benchmarking the Robustness of Semantic Segmentation Models</font>
    </a>
  </h2>
  <font color="black">まず、全画像分類とは逆に、モデルの堅牢性はモデルのパフォーマンスとともに増加します。ほとんどの場合、ベンチマーク調査に基づいて、いくつかの新しい洞察を得ています。調査の現実性を高めるために、Cityscapesから生成された約400,000枚の画像を利用します。 、PASCAL VOC 2012、ADE20K。 
[ABSTRACT]ベンチマーク調査に基づいて、多くの新しい洞察を得ています。これには、最先端のモデルを使用するdeeplabv3というモデルが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-14">
        <br><font color="black">2019-08-14</font>
      </time>
    </span>
</section>
<!-- paper0: IF-Net: An Illumination-invariant Feature Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_14.html">
      <font color="black">IF-Net: An Illumination-invariant Feature Network</font>
    </a>
  </h2>
  <font color="black">このため、いくつかのデータセットのスケジューリング方法を調査し、マッチングの精度を向上させるための分離トレーニングスキームを提案します。さらに、生成された記述子の能力を強化できるトレーニングスキームとともに、ROI損失とハードポジティブマイニング戦略を提案します。大きな照明変化条件に対処する..これらの要因の中で、照明の変動は最も影響力のあるものであり、特に、以前の記述子学習はこの問題に対処することに焦点を当てていません。 
[ABSTRACT]記述子は多くの場合、パフォーマンスを低下させる多くの実用的な要因の影響を受けます。これらの要因の中で、堅牢な汎用記述子を生成することを目的としたif-netを提案します。このために、いくつかのデータセットのスケジューリング方法を調査し、分離を提案しますマッチング精度を向上させるトレーニングスキーム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Hybrid Discriminative-Generative Training via Contrastive Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_15.html">
      <font color="black">Hybrid Discriminative-Generative Training via Contrastive Learning</font>
    </a>
  </h2>
  <font color="black">対照学習と教師あり学習の両方に大きな進歩と成功が見られました。このホワイトペーパーでは、エネルギーベースのモデルのハイブリッド識別生成トレーニングの観点から、対照学習と教師あり学習を直接接続できることを示します。堅牢性、分布外検出、およびキャリブレーションのパフォーマンスが向上します。 
[要約]エネルギーの類比の具体的な選択を示します。cifar-10とcifar-100のWidedesnetの分類精度の点で、ベースの損失は既存のプラクティスよりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-17">
        <br><font color="black">2020-07-17</font>
      </time>
    </span>
</section>
<!-- paper0: Driving among Flatmobiles: Bird-Eye-View occupancy grids from a
  monocular camera for holistic trajectory planning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_16.html">
      <font color="black">Driving among Flatmobiles: Bird-Eye-View occupancy grids from a
  monocular camera for holistic trajectory planning</font>
    </a>
  </h2>
  <font color="black">この変換を車両などの3Dオブジェクトに適用できるようにする重要な要素は、カメラビューでのフットプリントのみを予測することです。したがって、ホモグラフィによって示唆されるフラットな世界の仮説を尊重します。最近の研究では、明示的な中間体を使用することの重要性が示されています。ネットワークの決定の解釈可能性と精度の両方を向上させるという利点を持つ表現。カメラ画像からのBEVのOGMの予測を容易にするために、OGMが最初にカメラビューでセマンティックマスクとして予測され、次に2つの平面間のホモグラフィを使用してBEVで反りました。 
[ABSTRACT]カメラベースのネットワークは、手間のかかる手間のかかるビルディングブロックに取って代わるため魅力的です。しかし、これらのネットワークは、カメラビューではスケールが頑丈ではなく、したがってモーション予測に適していません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Prototype Mixture Models for Few-shot Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_17.html">
      <font color="black">Prototype Mixture Models for Few-shot Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">期待値最大化アルゴリズムによって推定されたPMMは、限られたサポート画像から豊富なチャネル別および空間セマンティクスを組み込んでいます。PascalVOCおよびMS-COCOデータセットでの広範な実験は、PMMが最新技術を大幅に改善することを示しています。表現だけでなく分類子も、PMMはセマンティクスを完全に活用して、クエリ画像内のオブジェクトをアクティブにしながら、背景領域を二重に押し下げます。 
[要旨] 1つのプロトタイプを使用して、pmmsは豊富なチャネルを組み込んでいます-限られたサポート画像からの賢い空間的な意味</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: DR^2Track: Towards Real-Time Visual Tracking for UAV via Distractor
  Repressed Dynamic Regression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_18.html">
      <font color="black">DR^2Track: Towards Real-Time Visual Tracking for UAV via Distractor
  Repressed Dynamic Regression</font>
    </a>
  </h2>
  <font color="black">リグレッサ学習でディストラクタの応答を抑制することにより、回帰ターゲットを動的かつ適応的に変更して、追跡のロバスト性と適応性を活用できます。ただし、事前定義された変更されていない回帰ターゲットは、ロバストネスと不確実な空中追跡シナリオへの適応性をもたらします。 .. 3つの挑戦的なUAVベンチマークで行われた実質的な実験は、優れたパフォーマンスと並外れた速度（安価なCPUで約50fps）の両方をトラッカーに示しています。 
[ABSTRACT]高度な相互相関フィルター（dcf）タイプのトラッカーは、一般に、学習したリグレッサーを使用して前景と背景を区別します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Describe What to Change: A Text-guided Unsupervised Image-to-Image
  Translation Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_19.html">
      <font color="black">Describe What to Change: A Text-guided Unsupervised Image-to-Image
  Translation Approach</font>
    </a>
  </h2>
  <font color="black">この作品では、「髪の色を黒に変更する」などのコマンドのような文を通じて特定の画像の属性を変更する、画像から画像への変換に基づく、監視なしの新しいアプローチを提案します。最新のアプローチでは、モデルには人間が注釈を付けたデータセットも必要な画像のすべての属性のテキストによる説明も必要ありませんが、変更が必要な属性のみが必要です。黄金、氷、砂）、私たちのメソッドは同じ翻訳の複数の確率的バージョン。 
[ABSTRACT]以前の調査では、通常、ユーザーは目的の画像のすべての特性を説明するか、豊富な注釈付きデータセットを使用する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Nighttime Dehazing with a Synthetic Benchmark -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_20.html">
      <font color="black">Nighttime Dehazing with a Synthetic Benchmark</font>
    </a>
  </h2>
  <font color="black">大規模なベンチマークデータセットが存在しないと、この領域の進行が妨げられます。この問題に対処するために、ヘイズの除去から色補正をほどく前に、最適なスケールの最大反射率を提案し、それらを順番に処理します。データセットとソースコードの両方が\ url {https://github.com/chaimi2013/3R}で入手できます。 
[ABSTRACT]大規模なベンチマークデータセットがないと、進行が妨げられます。代わりに、以前の分析分布から実際の明るい色をサンプリングすることにより、現実的な夜間ファジーを作成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: An Explainable 3D Residual Self-Attention Deep Neural Network FOR Joint
  Atrophy Localization and Alzheimer's Disease Diagnosis using Structural MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_21.html">
      <font color="black">An Explainable 3D Residual Self-Attention Deep Neural Network FOR Joint
  Atrophy Localization and Alzheimer's Disease Diagnosis using Structural MRI</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案されたアプローチが最先端のモデルよりもパフォーマンスが大幅に向上することを示しています。提案された3D ResAttNetメソッドは、2つの変更分類タスク（つまり、 AD対NCおよびsMCI対pMCIタスクの精度は、それぞれ97.1％および84.1％です。
[要約]提案された方法は、アルツハイマー病を発症させるために使用されています。 。新しい方法は、広告を開発するためのツールとして使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: FDFtNet: Facing Off Fake Images using Fake Detection Fine-tuning Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_22.html">
      <font color="black">FDFtNet: Facing Off Fake Images using Fake Detection Fine-tuning Network</font>
    </a>
  </h2>
  <font color="black">GANsベースのデータセット（Progressive Growing GAN）とDeepfakeベースのデータセット（DeepfakeとFace2Face）でFDFtNetを試し、64x64の小さな入力画像解像度で検出を複雑にします。この作業では、軽量で堅牢な細かいニューラルネットワークベースの分類器アーキテクチャのチューニング。FakeDetection Fine-Tuning Network（FDFtNet）と呼ばれます。これは、新しい偽の顔画像生成モデルの多くを検出でき、既存の画像分類ネットワークと簡単に組み合わせて、いくつかのデータセットで微調整することができます。多くの既存の方法とは対照的に、私たちのアプローチは、微調整のために少数の画像のみで人気のある事前トレーニング済みモデルを再利用して、偽の画像を効果的に検出することを目的としています。 
[ABSTRACT]私たちのアプローチは、いくつかの画像のみで事前トレーニング済みモデルを再利用することを目的としています。このモジュールは事前トレーニング済みモデルに追加され、いくつかのデータで微調整されます。fdftnetは、全体の精度を90に達成します。検出における64％偽の画像</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-05">
        <br><font color="black">2020-01-05</font>
      </time>
    </span>
</section>
<!-- paper0: Improved Adaptive Type-2 Fuzzy Filter with Exclusively Two Fuzzy
  Membership Function for Filtering Salt and Pepper Noise -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_23.html">
      <font color="black">Improved Adaptive Type-2 Fuzzy Filter with Exclusively Two Fuzzy
  Membership Function for Filtering Salt and Pepper Noise</font>
    </a>
  </h2>
  <font color="black">提案されたフィルターは、さまざまなノイズレベルの標準画像で検証されます。画像のノイズ除去は、ノイズの存在により画質が劣化する可能性がある画像処理方法の準備段階の1つです。提案されたフィルターのパフォーマンスは、さまざまなノイズと比較されます。ピークの信号対雑音比と計算時間の観点から、最先端の方法。 
[ABSTRACT]提案されたフィルタは、画像からソルトアンドペッパーノイズをフィルタリングするために提案されています。第2ステージでは、フィルタウィンドウで修正された通常のファジーロジックを使用してノイズのあるピクセルがノイズ除去されます。提案されたフィルタはノイズを除去し、有用な画像特性を保持します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: A Sensitivity Analysis Approach for Evaluating a Radar Simulation for
  Virtual Testing of Autonomous Driving Functions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_24.html">
      <font color="black">A Sensitivity Analysis Approach for Evaluating a Radar Simulation for
  Virtual Testing of Autonomous Driving Functions</font>
    </a>
  </h2>
  <font color="black">実際のテストドライブの代替として有望ですが、仮想テストはレーダーシステム全体を詳細にシミュレーションし、電磁波の伝播を概算するために計算集約型シミュレーション技術を使用するため、時間がかかります。シミュレーションベースのテストは自動運転機能の検証労力を大幅に削減する有望なアプローチ。モジュール式レーダーシステムシミュレーションが提示され、レーダーからの出力を比較しながら、テスト対象のシステムとして空間クラスタリングアルゴリズムを評価するために感度分析を実施するためにパラメーター化されます。モデルを実際の運転測定値に合わせて、現実的なモデルの動作を保証します。 
[ABSTRACT]レーダーは、モデル化するのが最も難しいセンサーの1つです。カメラやレーダーなどのセンサーは、このテスト作業で重要な役割を果たします。システムは現在、日本でテストされています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-06">
        <br><font color="black">2020-08-06</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Deep-Learning Based Deformable Image Registration: A
  Bayesian Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_25.html">
      <font color="black">Unsupervised Deep-Learning Based Deformable Image Registration: A
  Bayesian Framework</font>
    </a>
  </h2>
  <font color="black">教師なしDLベースの変形可能な画像のレジストレーションのための完全なベイズフレームワークを導入します。さらに、私たちのアプローチは、真の事後分布を特徴付けることによって変形場の不確実性の推定を提供します。 MNISTおよびMGH10データセットそれぞれの平均二乗誤差（$ 0.0063 $対$ 0.0065 $）およびダイス係数（$ 0.73 $対$ 0.71 $）による変形場。 
[要約]トレーニングプロセスは、ネットワークの重みのポイント推定を効果的に提供します。事後分布全体を特徴付けるのではなく、ポイントモデルを提供します。ただし、結果を使用して、移動イメージとターゲットイメージ間の類似度関数を計算できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Invertible Neural BRDF for Object Inverse Rendering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_26.html">
      <font color="black">Invertible Neural BRDF for Object Inverse Rendering</font>
    </a>
  </h2>
  <font color="black">また、ディープニューラルネットワークの構造的バイアスを利用して、事前にディープイルミネーションを考案します。新しいニューラルネットワークベースのBRDFモデルと、オブジェクトの逆レンダリング用のベイジアンフレームワークを導入します。既知のジオメトリのオブジェクトの。このモデルを調整することにより、実際の反射率の潜在空間を抽出します。これにより、事前に強い反射率が直接得られます。 
[ABSTRACT]結果は、ディープニューラルネットワークがラジオメトリック逆問題の解決に役立つ新しい方法を示しています。ディープニューラルシステムがラジオメトリック逆に関する質問への回答にどのように役立つかを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Reinforcement Learning with Label Embedding Reward for Supervised
  Image Hashing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_27.html">
      <font color="black">Deep Reinforcement Learning with Label Embedding Reward for Supervised
  Image Hashing</font>
    </a>
  </h2>
  <font color="black">この作業では、深い教師付きハッシュのための新しい意思決定アプローチを紹介します。バイナリコード空間の頂点を移動するときのハッシュ問題を定式化し、Boseによって定義された新しいラベル埋め込み報酬でディープQネットワークを学習します-Chaudhuri-Hocquenghem（BCH）コードを使用して最適なパスを探索します。CIFAR-10およびNUS-WIDEデータセットに対する広範な実験と分析により、さまざまなコード長で、私たちのアプローチが最先端の教師付きハッシュ法よりも優れていることが示されています。 
[ABSTRACT]ほとんどの既存のディープハッシュアプローチは非常に似ていますが、ほとんどの既存の手法は似ています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: RARTS: a Relaxed Architecture Search Method -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_28.html">
      <font color="black">RARTS: a Relaxed Architecture Search Method</font>
    </a>
  </h2>
  <font color="black">微分可能アーキテクチャ検索（DARTS）は、バイレベル最適化問題の解決に基づくデータ駆動型ニューラルネットワーク設計の効果的な方法です。重み/アーキテクチャ変数分割とGauss-Seidel反復により、コアアルゴリズムは精度と検索効率が大幅にDARTSよりも優れています。解決可能なモデルとCIFAR-10ベースのアーキテクチャ検索の両方で示されているように。私たちのモデルは、ImageNetへの転送時に引き続きDARTSよりも優れており、私たちの革新は純粋にトレーニングアルゴリズムに基づいていますが、最近のDARTSのバリアントと同等です。 
[ABSTRACT]新しいメソッドは、同じ損失関数を使用せずに、トレーニングと検証のデータセットをアーキテクチャ学習で使用します。メソッドは、損失関数の結果のテストに使用できないアルゴリズムに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Exploiting the Redundancy in Convolutional Filters for Parameter
  Reduction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_29.html">
      <font color="black">Exploiting the Redundancy in Convolutional Filters for Parameter
  Reduction</font>
    </a>
  </h2>
  <font color="black">この作業では、この冗長性を活用して、層の畳み込みフィルター間の相関として観察し、それを効率的に再現する別のアプローチを提案します。機能..私たちの実験は、LinearConvモデルが対応するパラメーターと同等のパフォーマンスを達成し、パラメーターの平均が約50％削減され、推論時の計算要件と速度が同じであることを確認しています。 
[ABSTRACT]この作業では、冗長性を活用し、レイヤーの畳み込みフィルター間の相関として観察し、効率的に再現するための代替アプローチを提案します。効率の向上</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-26">
        <br><font color="black">2019-07-26</font>
      </time>
    </span>
</section>
<!-- paper0: Incomplete Descriptor Mining with Elastic Loss for Person
  Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_30.html">
      <font color="black">Incomplete Descriptor Mining with Elastic Loss for Person
  Re-Identification</font>
    </a>
  </h2>
  <font color="black">Elastic Lossでは、トレーニングプロセス全体でハードモデルペアと簡単なサンプルペアのバランスをディープモデルで適切に調整できるように、新しい体重管理項目を設計します。CBDB-Netが3人の一般的な人の競争力を発揮できることを示していますRe-IDデータセット（Market-1501、DukeMTMC-Re-ID、およびCUHK03データセット）、3つのオクルージョンPerson Re-IDデータセット（Occluded DukeMTMC、Partial-REID、Partial iLIDSデータセット）、およびその他画像検索データセット（店内の服の検索データセット）。連続バッチDropBlockモジュール（CBDBM）では、最初に機能マップで均一なパーティション分割を実行します。 
[ABSTRACT] cbdb-netには2つの新しいモジュールが含まれています：連続バッチドロップブロックモジュール（cbdbm）と弾性損失</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: SiamSNN: Spike-based Siamese Network for Energy-Efficient and Real-time
  Object Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_31.html">
      <font color="black">SiamSNN: Spike-based Siamese Network for Energy-Efficient and Real-time
  Object Tracking</font>
    </a>
  </h2>
  <font color="black">この論文では、深いスパイク特徴の類似性マッチング方法に焦点を当て、SiamSNNと呼ばれるオブジェクト追跡のための最初のスパイクベースのシャムネットワークを提示します。具体的には、膜電位と時間ステップを用いたハイブリッドスパイキング類似性マッチング方法を提案し、 SiamFCの相関レイヤーと同じ機能を持つ、模範イメージと候補イメージ間の応答マップ。スパイクニューラルネットワーク（SNN）は、エネルギー効率の高いコンピューティングの機能により注目を集めていることはよく知られています。 
[要約]スパイクニューラルネットワーク（snns）は、エネルギー効率の高いコンピューティングの機能により、より多くの注目を集めています。しかし、レイテンシの短縮に関するいくつかの研究と、複雑なデータセットでのより困難なタスクのスパイクベースのモジュール</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-17">
        <br><font color="black">2020-03-17</font>
      </time>
    </span>
</section>
<!-- paper0: Shape Adaptor: A Learnable Resizing Module -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_32.html">
      <font color="black">Shape Adaptor: A Learnable Resizing Module</font>
    </a>
  </h2>
  <font color="black">ソースコードはhttps://github.com/lorenmt/shape-adaptor。で入手できます。7つの画像分類データセットに対して実験を行いました。結果は、元のサイズ変更レイヤーの代わりに形状アダプターのセットを使用するだけであることが示されています、すべてのデータセットにわたって、人間が設計したネットワーク全体でパフォーマンスが一貫して向上します。さらに、ネットワーク圧縮と転送学習という2つの他のアプリケーションでのシェイプアダプターの有効性を示します。 
[ABSTRACT] 7つの画像分類データセットで実験を行いました。結果は、シェイプアダプターのセットを使用するだけで、すべての拡張機能でヒューマンネットワークのパフォーマンスが向上することを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-03">
        <br><font color="black">2020-08-03</font>
      </time>
    </span>
</section>
<!-- paper0: Projected-point-based Segmentation: A New Paradigm for LiDAR Point Cloud
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_33.html">
      <font color="black">Projected-point-based Segmentation: A New Paradigm for LiDAR Point Cloud
  Segmentation</font>
    </a>
  </h2>
  <font color="black">具体的には、LiDARポイントの固有の順序付けされた情報をポイントサンプリングおよびグループ化に利用することで、不要な計算を削減します。問題は、以前のポイントベースのセグメンテーション方法をLiDARポイントクラウドに直接適用すると、通常、ドメイン間のギャップにより不十分な結果になる屋内と屋外のシナリオ。投影された点に基づく方法を、挑戦的なSemanticKITTIデータセットの点に基づく方法と比較し、実験結果は、投影された点に基づく方法がすべてのベースラインよりもより正確に達成できることを示しています。 
[要約]目的は、ポイントベースのメソッドをLIDARポイントクラウドサンプリングに適した形式に変換することです。ただし、すべての計算は投影された画像に対して実行され、点ごとのポイントしかありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: A model-guided deep network for limited-angle computed tomography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_34.html">
      <font color="black">A model-guided deep network for limited-angle computed tomography</font>
    </a>
  </h2>
  <font color="black">私たちのネットワークは、サイノグラムとCT画像の両方に取り組み、不完全なデータによって引き起こされるアーティファクトを同時に抑制し、CT画像の微細な構造情報を回復することができます。各反復で、畳み込みニューラルネットワーク（CNN）を使用して解を近似します最初の2つのサブ問題の結果、制限角度のCT画像再構成のためのエンドツーエンドのディープネットワークを取得します。この論文では、まず、制限角度のコンピューター断層撮影（CT）画像再構成の変分モデルを提案します。次に、モデルをエンドツーエンドのディープネットワークに変換します。ペナルティメソッドを使用してモデルを解決し、それを3つの反復サブ問題に分割します。最初のサブ問題は、周波数領域のサイノグラムの以前の情報を利用してサイノグラムを完成させます。 2番目は、空間領域でのCT画像の以前の情報を使用してCT画像を調整し、最後は最初の2つのサブ問題の出力をマージします。 
[要約]研究者は、私たちの方法が既存の限定角度ct画像再構成法よりも優れていることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: HMOR: Hierarchical Multi-Person Ordinal Relations for Monocular
  Multi-Person 3D Pose Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_35.html">
      <font color="black">HMOR: Hierarchical Multi-Person Ordinal Relations for Monocular
  Multi-Person 3D Pose Estimation</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチでは、統合されたトップダウンモデルがこれらの序数関係を学習プロセスで活用するように設計されています。提案された方法は、公的に利用可能な複数人の3Dポーズデータセットの最新の方法を大幅に上回っています。統合されたモデルは、人間の境界ボックス、人間の深度、およびルートに関連する3Dポーズを同時に推定します。粗から微細へのアーキテクチャにより、深度推定の精度が向上します。 
[要約] hmorは、相互作用情報を深さと角度の順序関係としてエンコードします。体をキャプチャします-パーツと関節のレベルのセマンティックを取得し、同時にグローバルな一貫性を維持します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-01">
        <br><font color="black">2020-08-01</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Sketch-guided Cartoon Video Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_36.html">
      <font color="black">Deep Sketch-guided Cartoon Video Synthesis</font>
    </a>
  </h2>
  <font color="black">一般的なフレーム補間法と比較して、私たちのアプローチは比較的大きな動きのあるフレームに対処でき、ユーザーがスケッチガイダンスを編集して生成されたビデオシーケンスを制御できる柔軟性も備えています。最後に、ビデオ後処理アプローチを使用してさらに改善します結果..フレームとスケッチ間の対応を明示的に考慮することにより、私たちの方法は、画像合成方法と比較して高品質の合成結果を達成できます。 
[ABSTRACT]提案されたアプローチの重要なアイデアは、スケッチと漫画のビデオフレーム間の密なクロスドメイン対応を推定することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Space-Time Video Upsampling Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_37.html">
      <font color="black">Deep Space-Time Video Upsampling Networks</font>
    </a>
  </h2>
  <font color="black">結果は、ベースラインと比較して、計算時間（x7高速）とパラメーターの数（30％）を削減しながら、定量的および定性的に優れた結果を示しています。これは、各ソリューションに重いディープニューラルネットワーク（DNN）が関与しているため、非常に非効率的です。 ..これに対する1つの解決策は、VSRとFIを1つずつ個別に実行することです。 
[ABSTRACT]新しい調査によると、ビデオは空間と時間の両方でアップサンプリングされています。これは、各ソリューションに重いディープニューラルネットワーク（dnn）が関与しているため、非常に非効率的です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: A Bayesian Filter for Multi-view 3D Multi-object Tracking with Occlusion
  Handling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_38.html">
      <font color="black">A Bayesian Filter for Multi-view 3D Multi-object Tracking with Occlusion
  Handling</font>
    </a>
  </h2>
  <font color="black">提案されたアルゴリズムは最新のWILDTRACKSデータセットで評価され、新しいデータセットの非常に混雑したシーンで機能することが実証されています。このアルゴリズムは3Dワールドフレームで動作し、オブジェクトの3D軌跡推定を提供します。重要な革新は高い忠実度ですさらに扱いやすい3Dオクルージョンモデル。最適なベイジアンマルチビューマルチオブジェクトフィルタリングが可能で、単一のベイジアン再帰、トラック管理のサブタスク、状態推定、クラッター拒否、オクルージョン/誤検出処理にシームレスに統合されています。 
[要約]提案されたアルゴリズムは、カメラ全体の検出の総数に線形の複雑さがあるため、カメラの数に応じて適切にスケーリングされます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br><font color="black">2020-01-13</font>
      </time>
    </span>
</section>
<!-- paper0: Lane Detection Model Based on Spatio-Temporal Network with Double
  ConvGRUs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_39.html">
      <font color="black">Lane Detection Model Based on Spatio-Temporal Network with Double
  ConvGRUs</font>
    </a>
  </h2>
  <font color="black">1つは、レーンマーキングの最も可能性の高い低レベルの特徴の情報を抽出するために使用されます。両方のConvGRUは同じ構造ですが、ネットワーク内の場所と機能が異なります。この論文では、二重の畳み込みによる時空間ネットワークゲートリカレントユニット（ConvGRU）は、困難なシーンでのレーン検出に対処するために提案されています。 
[ABSTRACT]多くの車線検出モデルが提案されています。交差点のマージと分割、カーブ、境界、オクルージョン、シーンタイプの組み合わせが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Cooperative Bi-path Metric for Few-shot Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_40.html">
      <font color="black">Cooperative Bi-path Metric for Few-shot Learning</font>
    </a>
  </h2>
  <font color="black">第2に、ベースラインに基づいて、分類の協調バイパスメトリックを提案します。これは、基本クラスと新規クラス間の相関を利用して、精度をさらに向上させます。この論文では、少数ショット分類を調査するために2つの貢献をします。問題..十分なラベル付きサンプルを持つ基本クラスが与えられた場合、少数ショット分類のターゲットは、ラベル付きサンプルが少数しかない新規クラスのラベルなしサンプルを認識することです。 
[ABSTRACT]新しいメソッドは、基本クラス内の情報を十分に活用していない、新規クラスのラベル付きサンプルとラベルなしサンプルの関係にのみ注意を払います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: SynDistNet: Self-Supervised Monocular Fisheye Camera Distance Estimation
  Synergized with Semantic Segmentation for Autonomous Driving -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_41.html">
      <font color="black">SynDistNet: Self-Supervised Monocular Fisheye Camera Distance Estimation
  Synergized with Semantic Segmentation for Autonomous Driving</font>
    </a>
  </h2>
  <font color="black">単眼深度推定のための最先端の自己監視学習アプローチは、通常、スケールのあいまいさに悩まされています。この論文では、魚眼およびピンホールカメラ画像の自己監視単眼距離推定を改善する新しいマルチタスク学習戦略を紹介します。 ..魚眼カメラでの作業は限られているため、提案された方法をピンホールモデルを使用してKITTIで評価しました。外部のスケール推定を必要とせずに、自己監視法の中で最先端のパフォーマンスを達成しました。 
[概要]魚眼カメラでの作業は限られています。ピンホールモデルを使用して、kittiで提案された方法を評価しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: DQI: A Guide to Benchmark Evaluation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_42.html">
      <font color="black">DQI: A Guide to Benchmark Evaluation</font>
    </a>
  </h2>
  <font color="black">最近の研究は答えを提供します：偽のバイアス..データ品質メトリックをデビューさせることによってベンチマーク品質を定量化するこの未踏のタスクを解決するための新しいアプローチを提案します：DQI ..根本的なタスクを「真に学習する」モデルに進むには、既存のバイナリアプローチやブラックボックスアプローチとは対照的に、連続するベンチマークの違いを定量化します。 
[ABSTRACT]ベンチマークは、以前のベンチマークとの違いを解決できないはずであると専門家は言う</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Failure Recovery and Re-Initialization for Online UAV Tracking
  with Joint Scale and Aspect Ratio Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_43.html">
      <font color="black">Automatic Failure Recovery and Re-Initialization for Online UAV Tracking
  with Joint Scale and Aspect Ratio Optimization</font>
    </a>
  </h2>
  <font color="black">具体的には、追跡タスク全体が2つの2Dフィルターに割り当てられます。（i）空間ドメインでの位置予測のための変換フィルター、（ii）サイズドメインでのスケールとアスペクト比の最適化のためのサイズフィルター。4つのUAVでの大規模実験ベンチマークは、低コストのCPUでの計算の実現可能性がある提示された方法の優位性を示しています。現在の無人航空機（UAV）視覚追跡アルゴリズムは、主に次の点で制限されています。（i）処理できるサイズの変化の種類、 （ii）リアルタイム要件をほとんど満たさない実装速度。 
[ABSTRACT]現在、さまざまな高速追跡アルゴリズムがあります。これらには、強力なサイズ推定機能を備えたリアルタイムのuav追跡アルゴリズムが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: 2nd Place Scheme on Action Recognition Track of ECCV 2020 VIPriors
  Challenges: An Efficient Optical Flow Stream Guided Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_44.html">
      <font color="black">2nd Place Scheme on Action Recognition Track of ECCV 2020 VIPriors
  Challenges: An Efficient Optical Flow Stream Guided Framework</font>
    </a>
  </h2>
  <font color="black">コードはまもなくリリースされます。アクション認識タスクの小規模なデータセットでのトレーニングの問題に対処するため、ほとんどの以前の作業は多数のトレーニングサンプルに基づいているか、他の大きなデータセットから転送された事前トレーニング済みモデルが過剰適合問題に取り組む必要があります..大規模なデータセットで事前トレーニングされたモデルがなくても、私たちの方法が有望な結果を達成できることが証明されています。 
[要約]新しいc3dニューラルネットワークの目的はタスクに使用されます。この方法では、事前に計画されたモデルなしでデータセットを転送できることが証明されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Labels Are Not Perfect: Improving Probabilistic Object Detection via
  Label Uncertainty -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_45.html">
      <font color="black">Labels Are Not Perfect: Improving Probabilistic Object Detection via
  Label Uncertainty</font>
    </a>
  </h2>
  <font color="black">KITTIデータセットの実験結果は、この方法がベースラインモデルと単純なヒューリスティックスに基づくモデルの両方を平均精度で最大3.6％上回ることを示しています。自動運転におけるロバストな物体検出には、信頼性の高い不確実性の推定が重要です。これにより、不安定なトレーニングや次善の検出パフォーマンスに。 
[ABSTRACT]確率的オブジェクト検出に関するこれまでの研究では、単純なヒューリスティックを使用して不確実性の正則化を行ってきました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Spatially Structured Image Transformations Using Planar Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_46.html">
      <font color="black">Learning Spatially Structured Image Transformations Using Planar Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">ネットワークトポロジ、トレーニングデータ、画像の形状などのバリエーションが、新しいタイプのデータの操作への転送の有効性など、視覚的画像変換の学習の効率と効果にどのように影響するかを調査します。画像変換の学習は、認知的推論の方法としてのメンタルシミュレーションのアイデア。私たちは、平面ニューラルネットワークを使用してコネクショニストモデリングアプローチを採用し、画像シーケンスの形の知覚体験から、並進、回転、スケーリングなどの基本的な画像変換を学習します。 
[ABSTRACT]コネクショニストモデリングアプローチを使用して、イメージの形式での知覚体験からイメージを学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-03">
        <br><font color="black">2019-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning-based Human Detection for UAVs with Optical and Infrared
  Cameras: System and Experiments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_47.html">
      <font color="black">Deep Learning-based Human Detection for UAVs with Optical and Infrared
  Cameras: System and Experiments</font>
    </a>
  </h2>
  <font color="black">バウンディングボックスアンカーを最適化し、画像の解像度を高めることで、高高度からの検出されなかった検出の数が20％以上減少することを示しています。提案されたネットワークは、RetinaNetとYOLOのさまざまなバリアント、および従来の光赤外線と比較されます。手作りの機能を使用する人間の検出フレームワーク。さらに、このペーパーの公開とともに、捜索救助フィールドテスト中に実装されたさまざまなUAVで記録された注釈付き光学赤外線データセットと実装されたソースコードのコレクションをリリースします。注釈ツール。 
[要約]提案されたネットワークは、異なる網膜および長期バージョンと比較されます。それは、全体的な誤検出率を最小限に抑えるために後で融合される人間の検出を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: HAPI: Hardware-Aware Progressive Inference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_48.html">
      <font color="black">HAPI: Hardware-Aware Progressive Inference</font>
    </a>
  </h2>
  <font color="black">この作業では、推論時に中間出口の配置と初期出口戦略を同時に最適化することにより、高性能初期出口ネットワークを生成するための新しい方法論であるHAPIについて説明します。さらに、効率的な設計空間探索アルゴリズムを提案します。多数の代替アーキテクチャをより高速にトラバースし、ユースケースの要件とターゲットハードウェアに合わせて調整された、最高のパフォーマンスを発揮する設計を生成します。定量的な評価により、当社のシステムは、代替の検索メカニズムと最新の技術を常に早期に上回っています。 -さまざまなレイテンシバジェットにわたる終了スキーム。 
[ABSTRACT]早期終了に関する初期の調査では、ユースケースの要件や導入プラットフォームを考慮せずに、主にトレーニングスキームに焦点を当ててきました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: T-GD: Transferable GAN-generated Images Detection Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_49.html">
      <font color="black">T-GD: Transferable GAN-generated Images Detection Framework</font>
    </a>
  </h2>
  <font color="black">T-GDは、破滅的な忘却を克服し、メタデータ情報のない少量のデータのみで最新のGAN画像を効果的に検出することにより、ソースデータセットで高いパフォーマンスを実現します。ジェネレーティブアドバーサリネットワーク（GAN）の最近の進歩により、非常にリアルな画像の生成。悪意のある目的での誤用の懸念を引き起こします。T-GDは、教師と生徒のモデルで構成され、相互に繰り返し教えて評価し、検出パフォーマンスを向上させることができます。 
[ABSTRACT]これらのガン生成画像（ガン画像）の制御は、他のアーティファクトと特定のパターンの大幅な減少により、ますます困難になっています。これは、特定の側面の欠如など、他の脳震と特定の減量の開示が原因です.gdはセルフトレーニング方式ですが、ガンアートの転送可能性の向上に焦点を当てることにより、以前のアプローチから自身を識別します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Reinforcement Learning Based Handwritten Digit Recognition with
  Two-State Q-Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_50.html">
      <font color="black">Reinforcement Learning Based Handwritten Digit Recognition with
  Two-State Q-Learning</font>
    </a>
  </h2>
  <font color="black">私たちの方法は2つのQ状態のみを使用するため、シンプルで最適化するパラメーターの数がはるかに少なく、報酬関数も簡単です。アプローチのベンチマークには3つのデータセットが使用されています。従来の手法では、畳み込みニューラルネットワーク（CNN）を使用して、過去の履歴と共にQstatesに含めます。 
[ABSTRACT]特徴マップの次元が高いため、状態の数が非常に多いです。私たちのアプローチは、これらの現代的なハイブリッド分類子よりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-28">
        <br><font color="black">2020-06-28</font>
      </time>
    </span>
</section>
<!-- paper0: Spatially Regularized Parametric Map Reconstruction for Fast Magnetic
  Resonance Fingerprinting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_51.html">
      <font color="black">Spatially Regularized Parametric Map Reconstruction for Fast Magnetic
  Resonance Fingerprinting</font>
    </a>
  </h2>
  <font color="black">この方法では、50人の患者のテストセットでの辞書マッチングと比較すると、T1H2Oマップでは0.048 $ \ pm $ 0.011、FFマップでは0.027 $ \ pm $ 0.004の正規化二乗平均平方根誤差が達成されました。磁気共鳴フィンガープリント法（MRF）により、複数の定量的MRパラメータを同時に高速で取得するための独自のコンセプト。高速MRFシーケンスと組み合わせて、提案された方法は、臨床的に実行可能な時間でマルチパラメトリックMRイメージングを可能にする可能性があります。 
[ABSTRACT] mrfは辞書照合ベースの再構築に基づいています。非常に高速なシステムを取り除くのは困難です。mrfを使用して新しいメソッドを開発できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-09">
        <br><font color="black">2019-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Vision Meets Wireless Positioning: Effective Person Re-identification
  with Recurrent Context Propagation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CV/paper_52.html">
      <font color="black">Vision Meets Wireless Positioning: Effective Person Re-identification
  with Recurrent Context Propagation</font>
    </a>
  </h2>
  <font color="black">既存の人の再識別方法は、歩行者をキャプチャするために視覚センサーに依存しています。この作業では、ビジョンとワイヤレスポジショニングの両方からのセンシングデータを使用して人の再識別に取り組みます。一方、ほとんどの人にとって、最も重要な機内持ち込みアイテムは携帯電話で、WiFiや携帯電話ネットワークで無線測位信号の形で感知できます。 
[要約]これは、視覚情報を使用して視覚データと無線測位データの間を伝播することに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: VAW-GAN for Singing Voice Conversion with Non-parallel Training Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CL/paper_0.html">
      <font color="black">VAW-GAN for Singing Voice Conversion with Non-parallel Training Data</font>
    </a>
  </h2>
  <font color="black">シンガーアイデンティティと歌う韻律（F0輪郭）を音声コンテンツから解きほぐすようにエンコーダーをトレーニングします。シンガーアイデンティティとF0に条件を付けることにより、デコーダーは目に見えないターゲットシンガーアイデンティティを持つ出力スペクトル特徴を生成し、F0レンダリングを改善します。提案されたフレームワークは、ベースラインフレームワークよりも優れたパフォーマンスを実現します。 
[要約]このペーパーでは、vawに基づく歌声変換フレームワークを提案します-gan.itは歌手IDとfsteinを使用してf0レンダリングを改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: A survey of embedding models of entities and relationships for knowledge
  graph completion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CL/paper_1.html">
      <font color="black">A survey of embedding models of entities and relationships for knowledge
  graph completion</font>
    </a>
  </h2>
  <font color="black">エンティティとその関係に関する現実世界の事実のナレッジグラフ（KG）は、さまざまな自然言語処理タスクに役立つリソースです。ただし、ナレッジグラフは通常不完全であるため、ナレッジグラフの完了またはリンク予測を実行すると便利です。 。ナレッジグラフにない関係が真である可能性が高いかどうかを予測します。 
[ABSTRACT]ナレッジグラフの補完が役立つ可能性があります。ただし、関係情報は関連していないため、便利です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2017-03-23">
        <br><font color="black">2017-03-23</font>
      </time>
    </span>
</section>
<!-- paper0: Knowledge Distillation and Data Selection for Semi-Supervised Learning
  in CTC Acoustic Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CL/paper_2.html">
      <font color="black">Knowledge Distillation and Data Selection for Semi-Supervised Learning
  in CTC Acoustic Models</font>
    </a>
  </h2>
  <font color="black">私たちの目的は、信頼度、話者、コンテンツの変動性などの属性に基づいて、ラベル付けされていないデータの大規模なプールからサンプルを選択する際の適切な基準の重要性を確立することです。半教師付き学習（SSL）は、音声認識システムの精度を向上させるためのラベルなしデータ。私たちが回答しようとしている質問は、ランダムに選択されたラベルなしサンプルの大きなセットへの依存を、Wordエラー率に妥協することなく削減できるデータ選択メカニズムを設計することは可能ですか？ WER）？ 
[ABSTRACT]問題は、ラベル付けされていないサンプルの学習を減らすデータ選択メカニズムを設計することが可能であるということです。現在、この研究は2つの主要なアイデアを統合する方法を提案しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: A Large-Scale Chinese Short-Text Conversation Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CL/paper_3.html">
      <font color="black">A Large-Scale Chinese Short-Text Conversation Dataset</font>
    </a>
  </h2>
  <font color="black">LCCCベースとLCCC大でそれぞれトレーニングされる事前トレーニングダイアログモデルもリリースします。ニューラルダイアログ生成モデルの進歩により、ショートテキスト会話のモデリングで有望な結果が示されます。クリーンなデータセットと事前トレーニングモデルは、ショートテキストの会話モデリングの研究を促進します。 
[要約]データクリーニングパイプラインは、手動で注釈が付けられた110kのダイアログペアでトレーニングされた一連のルールと分類子に基づいて構築されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Navigating Language Models with Synthetic Agents -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CL/paper_4.html">
      <font color="black">Navigating Language Models with Synthetic Agents</font>
    </a>
  </h2>
  <font color="black">さらに、モデルがチェス盤の正確な潜在表現を作成し、この知識を使用して法的移動の軌跡をプロットできることもわかります。この研究では、コーパスでGPT-2のバージョンをトレーニングします歴史的なチェスゲームのパターンを学習し、モデルで学習した単語の関係を、チェス盤の既知のグラウンドトゥルースと比較し、合法性とプレーの歴史的なパターンを分析します。モデルを使用した駒ごとの移動の割合は、人間のパターンと似ています。 
[ABSTRACT]モデルを使用した動きのパーセンテージはよく知られていることがわかります。また、これらの動きは人間のパターンと実質的に類似していることがわかります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Gender Detection on Social Networks using Ensemble Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CL/paper_5.html">
      <font color="black">Gender Detection on Social Networks using Ensemble Deep Learning</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、マルチモデルのディープラーニングアーキテクチャを使用してさまざまな特徴空間から専門的な理解を生成するアンサンブル分類を通じて、性別検出のコンテキストでこの問題に対処します。ドキュメント分類はこのタスクの中心ですが、従来の教師付き分類器のパフォーマンスは次のように低下しました。ソーシャルメディアの量は増加しています。FacebookやTwitterなどのソーシャルメディアサイトで増加し続ける投稿の量を分析するには、著者情報をプロファイリングするための改善された情報処理方法が必要です。 
[ABSTRACT]これは、ソーシャルメディアネットワークがprof profとソーシャルメディアの使用を目にしたのはこれが初めてです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-13">
        <br><font color="black">2020-04-13</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Speaker Diarization for an Unknown Number of Speakers with
  Encoder-Decoder Based Attractors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CL/paper_6.html">
      <font color="black">End-to-End Speaker Diarization for an Unknown Number of Speakers with
  Encoder-Decoder Based Attractors</font>
    </a>
  </h2>
  <font color="black">最近提案されたエンドツーエンドのスピーカーダイアライゼーションは、従来のクラスタリングベースのスピーカーダイアライゼーションを上回りましたが、1つの欠点があります。 ）、これは最初にスピーチ埋め込みシーケンスからアトラクタの柔軟な数を生成します。2スピーカー条件で、本手法はシミュレートされた混合物で2.69％のダイアライゼーションエラーレート（DER）を達成し、2スピーカーサブセットで8.07％DERを達成しました。バニラSA-EENDはそれぞれ4.56％と9.54％を達成しました。 
[ABSTRACT]この方法は、話者の数の点で柔軟性が低くなります。これにより、同じ数の話者アクティビティを作成するために、いくつかの埋め込みシーケンスが作成されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br><font color="black">2020-05-20</font>
      </time>
    </span>
</section>
<!-- paper0: Convolutional Complex Knowledge Graph Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CL/paper_7.html">
      <font color="black">Convolutional Complex Knowledge Graph Embeddings</font>
    </a>
  </h2>
  <font color="black">https://github.com/conex-kge/ConEx。で事前にトレーニングされたモデルとともにトレーニング、評価スクリプトを含むオープンソースの実装を提供することにより、結果の再現性を確保しています。 WN18RR、FB15K-237、KINSHIP、およびUMLSベンチマークデータセットに対する最新のアプローチ。私たちの実験結果は、ConExがRotatE、QuatE、TuckERなどの最新のアプローチよりも優れたパフォーマンスを達成することを示しています。少なくとも8倍少ないパラメーターを必要としながら、すべてのデータセットの予測タスクをリンクします。 
[ABSTRACT] conexは、状態およびumデータシステムよりも優れたパフォーマンスを発揮します。この方法では抜け穴を使用してミッシングリンクを制定します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-07">
        <br><font color="black">2020-08-07</font>
      </time>
    </span>
</section>
<!-- paper0: FireBERT: Hardening BERT-based classifiers against adversarial attack -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CL/paper_8.html">
      <font color="black">FireBERT: Hardening BERT-based classifiers against adversarial attack</font>
    </a>
  </h2>
  <font color="black">オリジナルのベンチマークパフォーマンスの98％を維持しながら、事前に製造された敵対サンプルの95％から保護するための非常に効果的な方法として、合成データジェネレーターとの調整を提示します。強化されていない分類器での作業と比較したFireBERTの操作.. 1つのアプローチでは、トレーニングデータと合成敵対サンプルに対してBERTを調整します。 
[ABSTRACT]通常のベンチマークサンプルの精度を大幅に低下させることなく、敵対攻撃に直面してbertベースのモデルの精度を向上させることが可能であることを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: An Empirical Study on Robustness to Spurious Correlations using
  Pre-trained Language Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CL/paper_9.html">
      <font color="black">An Empirical Study on Robustness to Spurious Correlations using
  Pre-trained Language Models</font>
    </a>
  </h2>
  <font color="black">自然言語の推論と言い換えの識別に関する私たちの実験は、適切な補助タスクを使用したMTLが、分布内のパフォーマンスを損なうことなく、挑戦的な例のパフォーマンスを大幅に向上させることを示しています。極端なマイノリティの場合、マルチタスク学習（MTL）の使用を提案します。さらに、MTLからの利益は主にマイノリティの例からの一般化の改善から得られることを示します。 
[ABSTRACT]成功の鍵は、偽の相関関係が保持されない少量の反例からの一般化です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-14">
        <br><font color="black">2020-07-14</font>
      </time>
    </span>
</section>
<!-- paper0: Describe What to Change: A Text-guided Unsupervised Image-to-Image
  Translation Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CL/paper_10.html">
      <font color="black">Describe What to Change: A Text-guided Unsupervised Image-to-Image
  Translation Approach</font>
    </a>
  </h2>
  <font color="black">この作品では、「髪の色を黒に変える」などのコマンドのような文を使用して、特定の画像の属性を変更する、画像から画像への変換に基づく、新しい教師なしアプローチを提案します。テキストと音声コマンドを視覚属性と組み合わせた新しい研究への道を切り開きます。提案されたモデルは、視覚的属性から画像コンテンツのもつれを解き、テキスト記述を使用して後者を変更することを学習してから、コンテンツと変更された属性表現。 
[ABSTRACT]以前の調査では、通常、ユーザーは目的の画像のすべての特性を説明するか、豊富な注釈付きデータセットを使用する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring TTS without T Using Biologically/Psychologically Motivated
  Neural Network Modules (ZeroSpeech 2020) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CL/paper_11.html">
      <font color="black">Exploring TTS without T Using Biologically/Psychologically Motivated
  Neural Network Modules (ZeroSpeech 2020)</font>
    </a>
  </h2>
  <font color="black">生物学的/心理学的問題としての人間の言語の教師なし学習に特に関心がある、人工ニューラルネットワーク（ANN）の生物学的/心理学的に動機付けられたモジュールを使用して課題に対処しました。次に、離散化された信号がニューラルネットワークを介して音波形に戻されます音声生成用のソースフィルターモデルの実装。システムは、まず、Mel Frequency Cepstral Coefficient（MFCC）フレームをEcho-State Network（ESN）で処理し、皮質マイクロ回路での計算をシミュレートします。 
[要約]人工ニューラルネットワークの生物学的/心理学的に動機付けられたモジュールを使用して課題に対処しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br><font color="black">2020-05-11</font>
      </time>
    </span>
</section>
<!-- paper0: Quran Intelligent Ontology Construction Approach Using Association Rules
  Mining -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CL/paper_12.html">
      <font color="black">Quran Intelligent Ontology Construction Approach Using Association Rules
  Mining</font>
    </a>
  </h2>
  <font color="black">コーランの詩からオントロジーを手動で取得すると、非常にコストがかかる可能性があります。したがって、コーランの概念とコーランの詩からの意味関係を発見するためのパターンベースのスキームと関連付けルールを使用したコーランのオントロジー構築のためのインテリジェントなシステムが必要です。概念的な関係は、相関ルール手法に基づいて検出されます。オントロジーは、知識の正式な表現と見なすことができます。 
[ABSTRACT]コーランオントロジーは、コーランの知識の新しい強力な表現を提供します。関連付けルールは、コーランオントロジーの接続された概念のすべてのクラス間の関係を表します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-07">
        <br><font color="black">2020-08-07</font>
      </time>
    </span>
</section>
<!-- paper0: Does BERT Solve Commonsense Task via Commonsense Knowledge? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CL/paper_13.html">
      <font color="black">Does BERT Solve Commonsense Task via Commonsense Knowledge?</font>
    </a>
  </h2>
  <font color="black">特に、BERTが曖昧性解消のために浅い構文パターンまたはより深い常識の知識に依存しているかどうかは興味深い研究問題です。アテンションヘッドは、ConceptNetでエンコードされた構造化された常識知識を正常にキャプチャし、BERTが常識タスクを直接解決するのに役立ちます。 
[ABSTRACT] bertはcommonsenseqaタスクを解決し、commonsenseqaを解決します。bert内の知識を分析する2つの注意ベースの方法、またはモデル予測に対するそのような知識の貢献を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: KR-BERT: A Small-Scale Korean-Specific Language Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CL/paper_14.html">
      <font color="black">KR-BERT: A Small-Scale Korean-Specific Language Model</font>
    </a>
  </h2>
  <font color="black">韓国語は非ラテンアルファベットを使用してリソースが不足している形態学的に豊かな言語の1つであるため、多言語BERTモデルが見逃した言語固有の言語現象をキャプチャすることも重要です。これらの調整により、KR-BERTモデルは同等に、さらにはサイズの約1/10のコーパスを使用する他の既存の事前トレーニング済みモデルよりも優れています。BidirectionalWordPieceTokenizerを含むいくつかのトークナイザーをテストし、トークンの最小スパンを調整して、サブ文字レベルから文字レベルまでのトークン化を行い、私たちのモデルのためのより良い語彙。 
[ABSTRACT]たとえば、韓国語固有のモデルkr-bertをトレーニングしました。モデルは小さな語彙とデータセットを使用しています。サブ文字番号などの多くの要素を使用して、より良い語彙を作成しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Question Identification in Arabic Language Using Emotional Based
  Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CL/paper_15.html">
      <font color="black">Question Identification in Arabic Language Using Emotional Based
  Features</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、アラビア語のテキストを質問検索回答に分類するかどうかを分類するバイナリ分類子を実装しました。実験的評価を行ったところ、これらの感情的な特徴により分類分類の精度が向上したことがわかりました。ソーシャルメディアネットワークとそのカテゴリを定義することで、既存の回答を見つけたり、カスタマーサービスの質問に回答する責任者にルーティングすることで、自動的に回答できます。 
[ABSTRACT]アラビア語のユーザーの増加に正比例して増加するテキストの増加により、手動で追跡することが非常に困難になります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: DQI: A Guide to Benchmark Evaluation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CL/paper_16.html">
      <font color="black">DQI: A Guide to Benchmark Evaluation</font>
    </a>
  </h2>
  <font color="black">「最先端の」モデルAは、ベンチマークBで人間を上回っていますが、同様のベンチマークC、D、およびEでは失敗します。他のベンチマークではできない、Bの特徴は何ですか。最近の調査は答えを提供します：偽のバイアス..データ品質メトリックをデビューさせることによってベンチマーク品質を定量化するこの未踏のタスクを解決するための新しいアプローチを提案します：DQI。 
[ABSTRACT]ベンチマークは、以前のベンチマークとの違いを解決できないはずであると専門家は言う</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Low Rank Factorization for Compact Multi-Head Self-Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CL/paper_17.html">
      <font color="black">Low Rank Factorization for Compact Multi-Head Self-Attention</font>
    </a>
  </h2>
  <font color="black">Transformerモデルの計算の複雑さに大きく貢献している主要なボトルネックの1つは、自己注意レイヤーです。これは、計算コストが高く、パラメーターを集中的に使用します。このアプローチの効率は、主に2つの最適化に由来します。 1）アフィニティマトリックスの低ランクマトリックス因数分解を使用して、各頭に個別のパラメーターを設定する代わりに、複数の注意分布を効率的に取得します2）注意スコアは、文内のすべての単語を密にクエリする代わりに、グローバルコンテキストベクトルをクエリすることによって取得されます。多くのNLPタスクに対する現在の最先端のアプローチでは、表現の学習にBERT、XLNetなどの事前トレーニング済みの大規模な言語モデルを使用しています。 
[ABSTRACT]これらのモデルはトランスアーキテクチャに基づいています。これらには、マルチヘッドセルフアテンションおよびレイヤーネットワークが含まれています。これらのモデルは、セルフよりも安価でリソースが多いことが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-26">
        <br><font color="black">2019-11-26</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Lingual Speaker Verification with Domain-Balanced Hard Prototype
  Mining and Language-Dependent Score Normalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CL/paper_18.html">
      <font color="black">Cross-Lingual Speaker Verification with Domain-Balanced Hard Prototype
  Mining and Language-Dependent Score Normalization</font>
    </a>
  </h2>
  <font color="black">クロスリンガルトライアルのスコアリングを強化するために、言語依存のsノルムスコアの正規化を提案します。偽者コホートには、常にペルシア語である登録データをシミュレートするペルシア語のターゲットドメインからのデータのみが含まれています。ドメインバランスの導入最先端のECAPA-TDNN x-vectorベースのスピーカー埋め込み抽出器を微調整するハードプロトタイプマイニング。 
[ABSTRACT]サンプルマイニング手法は、人気のaann-softmax損失関数のスピーカープロトタイプ間のスピーカー距離を効率的に活用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-15">
        <br><font color="black">2020-07-15</font>
      </time>
    </span>
</section>
<!-- paper0: Class LM and word mapping for contextual biasing in End-to-End ASR -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/cs.CL/paper_19.html">
      <font color="black">Class LM and word mapping for contextual biasing in End-to-End ASR</font>
    </a>
  </h2>
  <font color="black">このアルゴリズムは、名前付きエンティティ発話のWERをさらに31％削減します。E2Eモデルは発音辞書を必要としませんが、精度を向上させるために既存の発音知識を利用することは興味深いです。また、簡単な方法を調整して、コンテキストFSTとベースモデルのコストの不一致。 
[ABSTRACT]これらのエンティティはユーザーまたは場所に固有であり、トレーニング中には表示されません。これらは単一のトレーニング可能なニューラルネットワークモデルで使用されます。論文では、まれなエンティティの単語を発音を介して一般的な単語にマッピングするアルゴリズムを提案しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-10">
        <br><font color="black">2020-07-10</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Audio-visual Speaker Recognition with a Cross-modal Discriminative
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_0.html">
      <font color="black">Audio-visual Speaker Recognition with a Cross-modal Discriminative
  Network</font>
    </a>
  </h2>
  <font color="black">VFNetを使用すると、2019 NIST SREの評価セットでスコアレベルのフュージョンオーディオビジュアルベースラインと比較して16.54％の同等のエラー率の相対的な削減を実現します。オーディオビジュアルスピーカー認識は、最近の2019 NISTスピーカー認識評価（SREのタスクの1つです。 ..実験は、VFNetが追加のスピーカー識別情報を提供することを示しています。 
[要約]すべての研究は、視覚と聴覚神経信号が認知プロセスで相互作用するという事実を指しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Self-Supervised Hierarchical Clustering for Speaker Diarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_1.html">
      <font color="black">Deep Self-Supervised Hierarchical Clustering for Speaker Diarization</font>
    </a>
  </h2>
  <font color="black">表現学習ネットワークは、現在のステップでクラスタリングソリューションを使用して、正則化された三重項損失でトレーニングされますが、クラスタリングアルゴリズムは表現学習ステップからの深い埋め込みを使用します。提案されているアプローチは、自己監視学習の原則に基づいています。監視は、クラスタリングアルゴリズムから導出されます。さらに、提案されたアプローチは、DERが10％改善されたPLDAアフィニティマトリックスを備えた最先端のシステムよりも改善されています。 
[要約] ahcアルゴリズムはそれ以上の学習を必要としません。提案された方法は、自己監視学習の概念に基づいています。ahcアルゴリズムは、大幅に29％の相対改善</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Predicting Afrobeats Hit Songs Using Spotify Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_2.html">
      <font color="black">Predicting Afrobeats Hit Songs Using Spotify Data</font>
    </a>
  </h2>
  <font color="black">ランダムフォレストおよびグラデーションブースティングアルゴリズムは、F1スコアが約86％で成功することが証明されました。2063曲のデータセットが、提供されたオーディオ機能を使用して、Spotify Web APIを介して生成されました。 Afrobeatsジャンルのどの曲がSpotifyリスナーの間で人気になるかを予測します。 
[要約] 2063曲のデータセットは、spotify web apiを介して生成されました。データセットは、spotifyのソフトウェアによって生成されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: A Perceptually-Motivated Approach for Low-Complexity, Real-Time
  Enhancement of Fullband Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_3.html">
      <font color="black">A Perceptually-Motivated Approach for Low-Complexity, Real-Time
  Enhancement of Fullband Speech</font>
    </a>
  </h2>
  <font color="black">CPUコアの5％未満でフルバンド（48 kHz）音声の高品質なリアルタイム拡張を実証します。この作業では、以下に焦点を当てることにより音声の人間の知覚に依存する効率的なアプローチであるPercepNetを提案します。スペクトル包絡線と音声の周期性。これらの新しい手法の多くは、短時間フーリエ変換（STFT）ドメインで直接動作するため、計算が非常に複雑になります。 
[ABSTRACT]これらの新しいテクニックの多くは、ショートに直接作用します-sttraに基づく学習。これにより、注目度の高いパフォーマンスが得られます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: VAW-GAN for Singing Voice Conversion with Non-parallel Training Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_4.html">
      <font color="black">VAW-GAN for Singing Voice Conversion with Non-parallel Training Data</font>
    </a>
  </h2>
  <font color="black">音声コンテンツから歌手のアイデンティティと歌う韻律（F0輪郭）のもつれを解くようにエンコーダーをトレーニングします。変分自動エンコーディングWasserstein生成的敵対的ネットワーク（VAW-GAN）などの最近のエンコーダー/デコーダー構造は、非を通じてマッピングを学習する効果的な方法を提供します-並列トレーニングデータ..歌唱音声変換システムのトレーニングには、通常、並列トレーニングデータが必要ですが、実際のアプリケーションでは実用的ではありません。 
[要約]このペーパーでは、vawに基づく歌声変換フレームワークを提案します-gan.itは歌手IDとfsteinを使用してf0レンダリングを改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Knowledge Distillation and Data Selection for Semi-Supervised Learning
  in CTC Acoustic Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_5.html">
      <font color="black">Knowledge Distillation and Data Selection for Semi-Supervised Learning
  in CTC Acoustic Models</font>
    </a>
  </h2>
  <font color="black">半教師あり学習（SSL）は、音声認識システムの精度を向上させるためにラベルのないデータを利用することを目的とした活発な研究分野です。この問題に答えるためにさまざまなデータ選択方法の実証的調査を行い、さまざまな効果を定量化しますサンプリング戦略..現在の研究では、2つの主要なアイデアを統合するための方法論を提案しています。1）コネクショニストの時間的分類（CTC）の目的と教師-学生ベースの学習を使用したSSL 2）ラベルなしデータを活用して、学生モデル。 
[ABSTRACT]問題は、ラベル付けされていないサンプルの学習を減らすデータ選択メカニズムを設計することが可能であるということです。現在、この研究は2つの主要なアイデアを統合する方法を提案しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Acoustic Integrity Codes: Secure Device Pairing Using Short-Range
  Acoustic Communication -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_6.html">
      <font color="black">Acoustic Integrity Codes: Secure Device Pairing Using Short-Range
  Acoustic Communication</font>
    </a>
  </h2>
  <font color="black">初期ペアリングに短距離音響通信を使用することを提案します。それらのセキュリティを分析し、自己相関の低い信号を設計することで信号キャンセル攻撃から防御できることを示します。このシステムは、しきい値。 
[ABSTRACT]これには既存のsdpシステムの使用を制限する共通のハードウェアインターフェイスが必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-18">
        <br><font color="black">2020-05-18</font>
      </time>
    </span>
</section>
<!-- paper0: Pop Music Transformer: Beat-based Modeling and Generation of Expressive
  Pop Piano Compositions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_7.html">
      <font color="black">Pop Music Transformer: Beat-based Modeling and Generation of Expressive
  Pop Piano Compositions</font>
    </a>
  </h2>
  <font color="black">特に、トランスフォーマーが音楽のビートバーフレーズの階層構造をより簡単に認識できるように、入力データにメトリック構造を課そうとしています。新しいデータ表現は、ローカルテンポ変更の柔軟性を維持し、音楽のリズミカルで調和的な構造を制御するためのハードル。この一般的なアプローチとは対照的に、このペーパーでは、楽譜がトランスフォーマーモデルに供給されるデータに変換される方法を改善すると、トランスフォーマーが音楽モデリングに対してさらに優れた機能を発揮できることを示しています。 。 
[ABSTRACT]トランスフォーマーモデルは、大規模なmusic.data表現の主要な部分と見なすことができ、ローカルテンポの変更に柔軟性を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-01">
        <br><font color="black">2020-02-01</font>
      </time>
    </span>
</section>
<!-- paper0: ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in
  TDNN Based Speaker Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_8.html">
      <font color="black">ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in
  TDNN Based Speaker Verification</font>
    </a>
  </h2>
  <font color="black">最後に、チャネル依存フレームアテンションを使用して統計プーリングモジュールを改善します。SE-ResNetと同様に、これらのモジュールにスクイーズアンドエキサイトブロックを導入して、チャネルの相互依存性を明示的にモデル化します。提案されたECAPA-TDNNアーキテクチャは、状態を大幅に上回ります。 VoxCelebテストセットと2019 VoxCelebスピーカー認識チャレンジに基づく最新のTDNNベースのシステム。 
[ABSTRACT]時間遅延ニューラルネットワークは統計プーリングを使用して埋め込みを投影します。これにより、ネットワークはフレームに基づいてフレームの異なるサブセットに焦点を合わせることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-14">
        <br><font color="black">2020-05-14</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Speaker Diarization for an Unknown Number of Speakers with
  Encoder-Decoder Based Attractors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_9.html">
      <font color="black">End-to-End Speaker Diarization for an Unknown Number of Speakers with
  Encoder-Decoder Based Attractors</font>
    </a>
  </h2>
  <font color="black">この論文では、最初に音声埋め込みシーケンスから柔軟な数のアトラクタを生成する、エンコーダ/デコーダベースのアトラクタ計算（EDA）の方法を提案します。話者数が不明な場合、本方法はCALLHOMEで15.29％DERを達成しましたが、 x-ベクトルベースのクラスタリング手法は、19.43％のDERを達成しました。音声埋め込みシーケンスは、従来の自己注意型エンドツーエンドニューラルスピーカーダイアライゼーション（SA-EEND）ネットワークを使用して抽出されます。 
[ABSTRACT]この方法は、話者の数の点で柔軟性が低くなります。これにより、同じ数の話者アクティビティを作成するために、いくつかの埋め込みシーケンスが作成されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br><font color="black">2020-05-20</font>
      </time>
    </span>
</section>
<!-- paper0: TinySpeech: Attention Condensers for Deep Speech Recognition Neural
  Networks on Edge Devices -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_10.html">
      <font color="black">TinySpeech: Attention Condensers for Deep Speech Recognition Neural
  Networks on Edge Devices</font>
    </a>
  </h2>
  <font color="black">限られた語彙の音声認識のためのGoogle Speech Commandsベンチマークデータセットの実験結果は、TinySpeechネットワークが大幅に低いアーキテクチャの複雑さ（$ 207 \ times $少ないパラメーター）および低い計算の複雑さ（$ 21 \ times $少ない乗算）を達成したことを示しました研究文献の以前のディープニューラルネットワークと比較した場合、操作を追加します。この研究では、エッジ上のオンデバイス音声認識用の低フットプリント、高効率のディープニューラルネットワークを構築するための注意コンデンサーの概念を紹介します。ディープラーニングでは、多数の音声認識タスクで最先端のパフォーマンスを実現しています。 
[ABSTRACT]オンのディープニューラルネットワーク-デバイスの音声認識は依然として課題です。これは、ディープニューラル接続が広く使用されているためです。これらには、圧縮された埋め込みを学習して生成するアテンションデバイスが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: On Cross-Corpus Generalization of Deep Learning Based Speech Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_11.html">
      <font color="black">On Cross-Corpus Generalization of Deep Learning Based Speech Enhancement</font>
    </a>
  </h2>
  <font color="black">近年、ディープニューラルネットワーク（DNN）を使用した教師ありアプローチが音声強調の主流になりました。さらに、一般化が期待できる公的に入手可能なデータセットを評価します。ただし、DNNは新しい音声コーパスに一般化できないことがわかりました。低い信号対雑音比（SNR）条件。 
[ABSTRACT] dnnsは、多数のノイズとスピーカーを使用してトレーニングされた場合、トレーニングされていないノイズとスピーカーに一般化します。これらには、チャネルの正規化、より優れたトレーニングコーパス、短時間の1990年の変換におけるフレームシフト（stft）が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-10">
        <br><font color="black">2020-02-10</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Learning of Audio-Visual Objects from Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_12.html">
      <font color="black">Self-Supervised Learning of Audio-Visual Objects from Video</font>
    </a>
  </h2>
  <font color="black">また、漫画や人形などの人間以外の話者にもこのメソッドを適用することで、このメソッドの一般性を示しています。このモデルは、他の自己監視アプローチよりもはるかに優れており、監視顔検出を使用するメソッドと競合するパフォーマンスを実現しています。タスクは、オブジェクト検出器を使用せずに、ラベル付けされていないビデオでトレーニングすることで完全に解決できます。4つのダウンストリームの音声指向タスクに使用することで、モデルが学習する視聴覚オブジェクトの埋め込みの有効性を示します：（a）マルチスピーカーの音源分離、（b）スピーカーの位置特定と追跡、（c）調整されていないオーディオビジュアルデータの修正、（d）アクティブなスピーカーの検出。 
[ABSTRACT]これらのタスクは、オブジェクト検出器を使用せずに、ラベルなしのビデオでトレーニングすることで完全に解決できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring TTS without T Using Biologically/Psychologically Motivated
  Neural Network Modules (ZeroSpeech 2020) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_13.html">
      <font color="black">Exploring TTS without T Using Biologically/Psychologically Motivated
  Neural Network Modules (ZeroSpeech 2020)</font>
    </a>
  </h2>
  <font color="black">次に、離散化された信号は、音声生成用のソースフィルターモデルのニューラルネットワーク実装を介して音波形に戻されます。システムは、まず、Mel Frequency Cepstral Coefficient（MFCC）フレームをエコー状態ネットワーク（ESN）で処理し、シミュレーションします。皮質マイクロ回路での計算..生物学的/心理学的問題としての人間の言語の教師なし学習に特に関心がある、人工ニューラルネットワーク（ANN）の生物学的/心理学的動機付けモジュールを使用して課題に対処しました。 
[要約]人工ニューラルネットワークの生物学的/心理学的に動機付けられたモジュールを使用して課題に対処しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br><font color="black">2020-05-11</font>
      </time>
    </span>
</section>
<!-- paper0: Data Efficient Voice Cloning from Noisy Samples with Domain Adversarial
  Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_14.html">
      <font color="black">Data Efficient Voice Cloning from Noisy Samples with Domain Adversarial
  Training</font>
    </a>
  </h2>
  <font color="black">前者は少数のターゲットスピーカーデータを使用して、直接モデル更新を通じてマルチスピーカーモデルをターゲットスピーカーの音声に転送しますが、後者では、数秒だけのターゲットスピーカーの音声が、モデルを更新せずにターゲットスピーカーの音声を合成するマルチスピーカーモデル。ただし、ユーザーが提供するサンプルには、実際のアプリケーションでは必然的に音響ノイズが含まれる場合があります。実験により、スピーカーの適応とエンコーディングの両方について、提案されたアプローチは騒々しい話者のサンプルは、明らかに最先端の音声強調モジュールを採用した方法よりも優れています。 
[ABSTRACT]ターゲット音声の話者適応は、複数の話者から訓練されたモデルの一種です。2つの方法には、話者データと話者データが必要です。ただし、両方の話者データが必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Subword Regularization: An Analysis of Scalability and Generalization
  for End-to-End Automatic Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_15.html">
      <font color="black">Subword Regularization: An Analysis of Scalability and Generalization
  for End-to-End Automatic Speech Recognition</font>
    </a>
  </h2>
  <font color="black">さらに、目に見えない単語の認識に対するサブワード正則化の影響と、ビームダイバーシティに対するその影響を分析します。最近の研究では、トレーニング中にサブワードセグメンテーションをサンプリングすると、ニューラル機械翻訳と音声認識モデルの正則化として機能し、パフォーマンスの向上につながることが示唆されています。ただし、テキストをサブワードにマッピングすることはあいまいであり、多くの場合、複数のセグメンテーションバリアントが可能です。 
[ABSTRACT]サブワードの正則化により、最大2万時間のデータセットを持つ大規模な設定でも、相対的なワードエラーレートの削減（2-8％）が一貫して改善されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Opus Low Bit Rate Quality with Neural Speech Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_16.html">
      <font color="black">Improving Opus Low Bit Rate Quality with Neural Speech Synthesis</font>
    </a>
  </h2>
  <font color="black">Opusオーディオコーダーの音声モードは、6 kb / sから40 kb / sの範囲のビットレートで広帯域音声を圧縮できます。リスニングテストでは、同じ6 kb / sのOpusビットストリームで、LPCNetを使用した合成音声が明らかに優れていることを示しています標準のOpusデコーダーの出力。レートがさらに低下すると、パラメトリックコーダーは波形コーダーよりもパフォーマンスが向上する傾向があります。 
[ABSTRACT] opusは波形マッチングコーダーであり、レートが10 kb / sを下回ると品質が急速に低下します。これにより、互換性を損なうことなく既存の音声およびオーディオ波形コーダーのデコード品質を向上させる方法が開かれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-12">
        <br><font color="black">2019-05-12</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Lingual Speaker Verification with Domain-Balanced Hard Prototype
  Mining and Language-Dependent Score Normalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_17.html">
      <font color="black">Cross-Lingual Speaker Verification with Domain-Balanced Hard Prototype
  Mining and Language-Dependent Score Normalization</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、2020年の短期話者検証（SdSV）チャレンジのテキスト非依存タスクのトップスコアIDLab提出について説明します。クロスリンガル試験のスコアリングを強化するために、言語依存のs-normを提案しますスコアの正規化.. Gaussian-Backend言語モデルが英語を含むように埋め込まれたテストスピーカーを検出した場合、AAM-softmaxスピーカープロトタイプで決定された言語間補正オフセットが、予想される最大の偽者平均スコアから差し引かれます。 
[ABSTRACT]サンプルマイニング手法は、人気のaann-softmax損失関数のスピーカープロトタイプ間のスピーカー距離を効率的に活用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-15">
        <br><font color="black">2020-07-15</font>
      </time>
    </span>
</section>
<!-- paper0: A fully recurrent feature extraction for single channel speech
  enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_18.html">
      <font color="black">A fully recurrent feature extraction for single channel speech
  enhancement</font>
    </a>
  </h2>
  <font color="black">この目的のために、CNNレイヤーを抽出する機能に反復係数を追加して、単一チャネルの音声強調のためのロバストなコンテキスト認識機能抽出戦略を導入します。抽出された機能でノイズ属性のローカル統計をキャプチャする上でロバストであるため、提案されたモデルは、非常に騒々しい条件でも、音声キューの区別に非常に効果的です。しかし、バニラCNNモジュールの特徴抽出能力は、統合されたたたみ込みカーネルの次元制約によって制限され、ノイズコンテキスト情報を適切にモデル化できませんでした特徴抽出段階で。 
[ABSTRACT] cnnモジュールの特徴抽出能力は、ネットワークのノイズコンテキストを適切にモデル化できませんでした。新しいモデルは、非常に騒々しい状況でも、音声キューの区別に非常に効果的です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-09">
        <br><font color="black">2020-06-09</font>
      </time>
    </span>
</section>
<!-- paper0: Class LM and word mapping for contextual biasing in End-to-End ASR -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_19.html">
      <font color="black">Class LM and word mapping for contextual biasing in End-to-End ASR</font>
    </a>
  </h2>
  <font color="black">また、コンテキストFSTとベースモデル間のコストの不一致を調整する簡単な方法を提案します。このアルゴリズムは、通常の発話の精度をほとんど低下させずに、名前付きエンティティの発話WERを57％削減できます。このアルゴリズムは、WERをさらに削減します。名前付きエンティティの発話でさらに31％。 
[ABSTRACT]これらのエンティティはユーザーまたは場所に固有であり、トレーニング中には表示されません。これらは単一のトレーニング可能なニューラルネットワークモデルで使用されます。論文では、まれなエンティティの単語を発音を介して一般的な単語にマッピングするアルゴリズムを提案しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-10">
        <br><font color="black">2020-07-10</font>
      </time>
    </span>
</section>
<!-- paper0: improving partition-block-based acoustic echo canceler in under-modeling
  scenarios -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-11/eess.AS/paper_20.html">
      <font color="black">improving partition-block-based acoustic echo canceler in under-modeling
  scenarios</font>
    </a>
  </h2>
  <font color="black">PFKFの定常状態の動作の分析を提示し、フィルターが不十分な長さである場合、バイアスされた定常状態のソリューションの影響を受けることを発見しました。シミュレーションは、提案された方法の改善されたパフォーマンスを検証するために行われます。音響エコーキャンセレーション用に、分割ブロックベースの周波数領域カルマンフィルター（PFKF）が提案されています。 
[要約] pfkfフィルターが通常の周波数と比較されました-ドメインカルマンフィルター。開発可能なシステムを開発するには、システムの分析が必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
