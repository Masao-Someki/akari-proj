<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<title>Akari-2020-01-30の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
  <div class="header-logo">
    <a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
  </div>
</header>
<input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">

<div class="menubar">
<span class="bar"></span>
<span class="bar"></span>
<span class="bar"></span>
</div>

<ul>
<li><a id="home" href="../../index.html">Home</a></li>
<li><a id="about" href="../../teamAkariとは.html">About</a></li>
<li><a id="contact" href="../../contact.html">Contact</a></li>
<li><a id="contact" href="../../list/newest.html">New Papers</a></li>
<li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
</ul>

</label>
<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: From Speech-to-Speech Translation to Automatic Dubbing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-30/cs.SD/paper_0.html">
      From Speech-to-Speech Translation to Automatic Dubbing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      英語からイタリア語へのTED Talksの抜粋の自動ダビングの主観的評価について報告します。自動ダビングの知覚された自然さと提案された各拡張の相対的な重要性を測定します。自動ダビングを実行するために..私たちのアーキテクチャは、好ましい長さの出力を生成するニューラル機械翻訳、元の音声セグメントとの翻訳の韻律的整列、各発話の持続時間の微調整を伴うニューラルテキスト音声変換、および最終的に、元の音声から抽出された背景ノイズと残響でテキスト音声出力を強化する音声レンダリング。 
[概要]アーキテクチャはcnnのボトックスと人間追跡機械翻訳を特徴としています。このソフトウェアは、失敗した研究に基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-19">
        <br>2020-01-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Environment-aware Reconfigurable Noise Suppression -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-30/cs.SD/paper_1.html">
      Environment-aware Reconfigurable Noise Suppression
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたNSは、Voice over Internet Protocol、音声トリガー、および自動音声認識アプリケーションのキャプチャパスと再生パスの両方に採用できます。-5〜2.5 dBの入力SNRに対して、提案されたNSはSTIとSIを入力SNRが2.5〜8 dBの場合、STIとSIは提案されたNSによって「良好」から「優れた」に改善されます。 
[ABSTRACT]提案されたノイズ抑制（ns）ソリューションは、音声伝送インデックス、音声明瞭度、信号雑音比（snr）を大幅に向上させます。提案されたne neネゴシエータは、stiの雑音とsiを抑制するために使用できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-29">
        <br>2020-01-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Language Identification for Multilingual Speakers -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-30/cs.SD/paper_2.html">
      Improving Language Identification for Multilingual Speakers
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この研究で示すように、LIDシステムは、ほとんどの言語の組み合わせに対して高い平均精度を持ち、アクセントのある音声が存在する場合、他の言語のパフォーマンスを大幅に低下させます。しかし、ほとんど無視されてきた1つの側面は、LIDテクノロジーを利用する多くのシステムの主な対象読者であるにもかかわらず、多言語話者の言語の差別です。 
[要約]システムには言語差別の例がたくさんあります。これらはリッド技術を使用するシステムとして識別できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-29">
        <br>2020-01-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Audio-Visual Decision Fusion for WFST-based and seq2seq Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-30/cs.SD/paper_3.html">
      Audio-Visual Decision Fusion for WFST-based and seq2seq Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2番目に、別々のseq2seq音響モデルと視覚モデルをトレーニングします。最初に、別々のRNN-HMMベースの音響モデルと視覚モデルをトレーニングします。共通の仮説ビームを維持しながら、浅いフュージョンを使用して両方のモダリティで同時に復号ステップを実行します。 
[要約]さまざまなsnrで結果を提示し、我々の方法が音響のみのwerに大幅な改善をもたらすことを示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-29">
        <br>2020-01-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Compact recurrent neural networks for acoustic event detection on
  low-energy low-complexity platforms -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-30/cs.SD/paper_4.html">
      Compact recurrent neural networks for acoustic event detection on
  low-energy low-complexity platforms
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      貢献は2つあります。まず、現在のマイクロコントローラーに適合するサウンドイベント検出用の最先端のニューラルネットワークを作成するための2段階の学生教師アプローチが提示されています。次に、特に8ビットの量子化に関連する問題に焦点を当てて、ARM Cortex M4でアプローチをテストします。組み込みの実装により、Urbansound8kの認識で68％の精度を達成できます。オーディオストリームの1秒ごとに125 msの推論時間、わずか34.3 kBのRAMで5.5 mWの電力消費。ただし、現在の組み込み技術とマイクロコントローラーは、エネルギー効率を損なうことなく機能を向上させています。 
[要約]この課題は、リソースの効率的な使用が必要なiot実装を妨げます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-29">
        <br>2020-01-29
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: From Speech-to-Speech Translation to Automatic Dubbing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-30/cs.CL/paper_0.html">
      From Speech-to-Speech Translation to Automatic Dubbing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      英語からイタリア語へのTED Talksの抜粋の自動ダビングの主観的評価について報告します。自動ダビングの知覚された自然さと提案された各拡張の相対的な重要性を測定します。自動ダビングを実行するために..私たちのアーキテクチャは、好ましい長さの出力を生成するニューラル機械翻訳、元の音声セグメントとの翻訳の韻律的整列、各発話の持続時間の微調整を伴うニューラルテキスト音声変換、および最終的に、元の音声から抽出された背景ノイズと残響でテキスト音声出力を強化する音声レンダリング。 
[概要]アーキテクチャはcnnのボトックスと人間追跡機械翻訳を特徴としています。このソフトウェアは、失敗した研究に基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-19">
        <br>2020-01-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Dolphin: A Spoken Language Proficiency Assessment System for Elementary
  Education -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-30/cs.CL/paper_1.html">
      Dolphin: A Spoken Language Proficiency Assessment System for Elementary
  Education
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Dolphinは、音韻的流encyさと学生のVFT回答の意味的関連性の両方を自動的に評価できます。オンラインA / B実験では、中国の2つの主要都市（杭州と西安）の183人の教師と10週間、結果は、VFT課題のグレーディングカバレッジが22 \％向上することを示しています。生徒が口頭での語学能力を学校で習得できるように、言語流tasks性タスク（VFT）が考案されました。 
[要旨]中国では、教育資源が限られており、バランスが取れていないため、言語スキルが制限されています。これらは難しいが、具体的な数学関連の質問で、生徒に答えを報告し、思考プロセス全体を話すように求めます。この問題を軽減するために、中国の初等教育のための語学能力評価システム
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-01">
        <br>2019-08-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Healthcare NER Models Using Language Model Pretraining -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-30/cs.CL/paper_2.html">
      Healthcare NER Models Using Language Model Pretraining
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業は、最初のHealth Search and Data Mining Workshop（HSDM 2020）
[26]で発表されました。さらに、注釈付きのデータセットと事前トレーニングモデルをコミュニティにリリースして、医療健康記録のさらなる研究を行う予定です。 。トランスファーラーニングと言語モデルの事前トレーニングテクニックを適用することにより、ドメインシフトをターゲットとすることを目的としたNLPの最近の進歩を活用したツールとテクニックの組み合わせを紹介します
[3]。 
[概要]ソリューションでは、自然言語処理技術とWebベースの注釈ツールの組み合わせを使用して、限られた量のehrトレーニングデータでトレーニングされたカスタム名前付きエンティティ認識（ner）
[1]モデルのパフォーマンスを最適化します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-23">
        <br>2019-10-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Permutation Invariant Gaussian Matrix Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-30/cs.CL/paper_3.html">
      Permutation Invariant Gaussian Matrix Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      順列不変ガウスマトリックスモデルは、計算言語学のアプリケーション向けに最近開発されました。これらのパラメーターは、対称グループ$ S_D $の特定の既約表現で変換するマトリックス変数の適切な線形結合に関する単純な2次式の係数です。行列のサイズ。アクションの2つの線形項と11の2次項を、表現理論パラメーターの観点から表現します。 
[抽象]モデルの5パルシアン形成が解決されました。表現ガウスの観点から、モデルを識別できます。現在、13種類のモデルがあります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-09-20">
        <br>2018-09-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: AMR Similarity Metrics from Principles -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-30/cs.CL/paper_4.html">
      AMR Similarity Metrics from Principles
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      その適合性を評価し、SmatchおよびSemBleuに対する優位性を示します。たとえば、識別不能ルールのアイデンティティに違反し、制御が困難なバイアスを導入します。 iii）私たちは、ごくわずかな意味の逸脱にのみ貢献し、確立されたすべての基準を満たすことを目標とする新しいメトリックS2matchを提案します。最近リリースされたSemBleuメトリック（Song and Gildea、2019）は、機械翻訳メトリックBleu（ Papineni et al。、2002）、可変アラインメントステップを除去し、よりグローバルなグラフプロパティをキャプチャすることを目的として、計算効率を向上させました。 
[要旨] hgjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjはマッチ指標の使用について批判されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-29">
        <br>2020-01-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Mogrifier LSTM -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-30/cs.CL/paper_5.html">
      Mogrifier LSTM
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験では、Penn TreebankおよびWikitext-2で3〜4のパープレキシティポイント、4つの文字ベースのデータセットで0.01〜0.05 bpcの範囲で言語モデリングの一般化が著しく改善されていることが実証されています。 Enwik8の例外は、LSTMモデルとTransformerモデルの間の大きなギャップを埋めるということです。同様に、このモデルは、LSTMによって与えられる遷移関数をコンテキスト依存にするものと見なすことができます。 
[概要]これらの変更は、ペンツリーバンクとウィキテキストの3〜4のパープレキシティポイントの範囲で確認できます-2、4文字ベースのデータセットの0.01％bpc
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-04">
        <br>2019-09-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Modeling Global and Local Node Contexts for Text Generation from
  Knowledge Graphs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-30/cs.CL/paper_6.html">
      Modeling Global and Local Node Contexts for Text Generation from
  Knowledge Graphs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの実験では、モデルがKGからテキストへの生成を大幅に改善し、アジェンダデータセットで17.81のBLEUスコアを達成し、見られたカテゴリのWebNLGデータセットで63.10を達成し、最新技術を3.51および2.51上回ることを実証します。対照的に、ローカルノードエンコーディングは、グラフ構造をキャプチャする直接接続されたノード間の関係を考慮しますが、長距離関係をキャプチャできない場合があります。 
[ABSTRACT]グローバルノードスキャンは、2つの離れたノード間の明示的な通信を可能にします。この作業では、両方のキャプチャ戦略のベストを収集します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-29">
        <br>2020-01-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards Scalable Multi-domain Conversational Agents: The Schema-Guided
  Dialogue Dataset -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-30/cs.CL/paper_7.html">
      Towards Scalable Multi-domain Conversational Agents: The Schema-Guided
  Dialogue Dataset
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      言語理解、スロット充填、対話状態の追跡、応答生成など、多くのタスクに挑戦的なテストベッドを提供します。同じ行に沿って、タスク指向対話のスキーマガイドパラダイムを提示します。これにより、単一の対話システムで多数のサービスを簡単にサポートでき、追加のトレーニングデータを必要とせずに新しいサービスを簡単に統合できます。 
[概要]データセットは、既存のタスク-管理ダイアログコーパスの規模を超えていますが、大規模な仮想アシスタントの構築に関連する課題も強調しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-12">
        <br>2019-09-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Interpretable Rumor Detection in Microblogs by Attending to User
  Interactions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-30/cs.CL/paper_8.html">
      Interpretable Rumor Detection in Microblogs by Attending to User
  Interactions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最良のモデルが両方のデータセットの現在の最先端モデルよりも優れていることを示します。このモデルのバリエーションを調査しました。（1）ツリー構造情報を組み込む構造認識自己注意モデル（StA-PLAN）トランスフォーマーネットワーク、および（2）トークンレベルの自己アテンションで文の表現を学習する階層トークンおよびポストレベルアテンションモデル（StA-HiTPLAN）。さらに、アテンションメカニズムにより、両方の噂検出予測を説明できます。トークンレベルとポストレベル。 
[概要]投稿者レベルのアテンションモデル（計画）を提案し、トランスネットワークのマルチヘッドアテンションメカニズムを使用してツイート間の長距離相互作用をモデル化します。知識の限りでは、2つのモデルを最初に評価します。噂検出データセット：phemeデータセットとtwitter15およびtwitter16データセット
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-29">
        <br>2020-01-29
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: From Speech-to-Speech Translation to Automatic Dubbing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-30/eess.AS/paper_0.html">
      From Speech-to-Speech Translation to Automatic Dubbing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      英語からイタリア語へのTED Talksの抜粋の自動ダビングの主観的評価について報告します。自動ダビングの知覚された自然さと提案された各拡張の相対的な重要性を測定します。自動ダビングを実行するために..私たちのアーキテクチャは、好ましい長さの出力を生成するニューラル機械翻訳、元の音声セグメントとの翻訳の韻律的整列、各発話の持続時間の微調整を伴うニューラルテキスト音声変換、および最終的に、元の音声から抽出された背景ノイズと残響でテキスト音声出力を強化する音声レンダリング。 
[概要]アーキテクチャはcnnのボトックスと人間追跡機械翻訳を特徴としています。このソフトウェアは、失敗した研究に基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-19">
        <br>2020-01-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Environment-aware Reconfigurable Noise Suppression -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-30/eess.AS/paper_1.html">
      Environment-aware Reconfigurable Noise Suppression
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたNSは、Voice over Internet Protocol、音声トリガー、および自動音声認識アプリケーションのキャプチャパスと再生パスの両方に採用できます。2.5〜8 dBの入力SNRの場合、STIとSIは「良好」から提案されたNSによる「優れた」。-5〜2.5 dBの入力SNRに対して、提案されたNSはSTIとSIを「公平」から「良好」に改善します。 
[ABSTRACT]提案されたノイズ抑制（ns）ソリューションは、音声伝送インデックス、音声明瞭度、信号雑音比（snr）を大幅に向上させます。提案されたne neネゴシエータは、stiの雑音とsiを抑制するために使用できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-29">
        <br>2020-01-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Language Identification for Multilingual Speakers -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-30/eess.AS/paper_2.html">
      Improving Language Identification for Multilingual Speakers
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この研究で示すように、LIDシステムは、ほとんどの言語の組み合わせに対して高い平均精度を持ち、アクセントのある音声が存在する場合、他の言語のパフォーマンスを大幅に低下させることができます。この組み合わせシステムは、すべての言語の組み合わせで平均97％の精度を達成し、ベースラインと比較して最悪の場合の精度を60％以上改善します。 
[要約]システムには言語差別の例がたくさんあります。これらはリッド技術を使用するシステムとして識別できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-29">
        <br>2020-01-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Audio-Visual Decision Fusion for WFST-based and seq2seq Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-30/eess.AS/paper_3.html">
      Audio-Visual Decision Fusion for WFST-based and seq2seq Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、重み付けパラメーターを使用しない新規seq2seq融合の結果も提示します。2番目に、別々のseq2seq音響モデルと視覚モデルをトレーニングします。最初に、別個のRNN-HMMベースの音響モデルと視覚モデルをトレーニングします。 
[要約]さまざまなsnrで結果を提示し、我々の方法が音響のみのwerに大幅な改善をもたらすことを示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-29">
        <br>2020-01-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Compact recurrent neural networks for acoustic event detection on
  low-energy low-complexity platforms -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-30/eess.AS/paper_4.html">
      Compact recurrent neural networks for acoustic event detection on
  low-energy low-complexity platforms
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      貢献は2つあります。まず、現在のマイクロコントローラーに適合するサウンドイベント検出用の最先端のニューラルネットワークを作成するための2段階の学生教師アプローチが提示されています。次に、特に8ビットの量子化に関連する問題に焦点を当てて、ARM Cortex M4でアプローチをテストします。組み込みの実装により、Urbansound8kの認識で68％の精度を達成できます。オーディオストリームの1秒あたり125ミリ秒の推論時間、およびわずか34.3 kBのRAMでの消費電力5.5 mW。屋外音響イベントの検出はエキサイティングな研究分野ですが、複雑なアルゴリズムと深層学習技術の必要性に挑戦しています。通常、多くの計算、メモリ、エネルギーリソースが必要です。 
[要約]この課題は、リソースの効率的な使用が必要なiot実装を妨げます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-29">
        <br>2020-01-29
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本日更新された論文はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br>
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
