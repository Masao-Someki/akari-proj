<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-10-27の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Deep Composer Classification Using Symbolic Representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.SD/paper_0.html">
      <font color="black">Deep Composer Classification Using Symbolic Representation</font>
    </a>
  </h2>
  <font color="black">この研究では、シンボリックドメインで作曲家を分類するためにディープニューラルネットワークをトレーニングします。MAESTROデータセットで実施された実験では、13〜古典的な作曲家の分類について0.8333のF1値を報告します。モデルは2チャネルを取ります。 2次元入力、つまり、タイムピッチ表現の開始とノートのアクティブ化。これは、MIDI録音から変換され、単一ラベルの分類を実行します。 
[概要]モデルは、時間の開始とノートのアクティブ化を含む、2つのチャネル2の知覚入力を取ります-ピッチ表現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-02">
        <br><font color="black">2020-10-02</font>
      </time>
    </span>
</section>
<!-- paper0: Audio Cover Song Identification using Convolutional Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.SD/paper_1.html">
      <font color="black">Audio Cover Song Identification using Convolutional Neural Network</font>
    </a>
  </h2>
  <font color="black">次に、カバー曲のペアと非カバー曲のペアで構成されるデータセットを構築します。これらはそれぞれポジティブトレーニングサンプルとネガティブトレーニングサンプルとして使用されます。カバー曲間に意味のあるパターンがあり、これを学習できるという観察に基づいています。 、機械学習フレームワークでカバー曲の識別問題を再定式化しました。トレーニングされたCNNは、任意の2つの音楽から生成された相互類似度マトリックスが与えられた場合に、カバー曲の関係にある確率を出力し、ランク付けによってカバー曲を識別します。確率。 
[ABSTRACT] cnnは、曲のペアからの相互類似性マトリックスを使用して構築されました。トレーニングされたcnnは、カバー曲の関係にある確率を生成します。テストは、確率でランク付けすることにより、カバー曲を識別するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2017-12-01">
        <br><font color="black">2017-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Sequential Skip Prediction with Few-shot in Streamed Music Contents -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.SD/paper_2.html">
      <font color="black">Sequential Skip Prediction with Few-shot in Streamed Music Contents</font>
    </a>
  </h2>
  <font color="black">この論文では、WSDMカップ2019 Spotifyシーケンシャルスキップ予測チャレンジ（チーム名：ミンブリス）に提出されたアルゴリズムの概要を説明します。メトリック学習とシーケンス学習に基づいた2種類のアルゴリズムを提案しました。さらに、追加のアルゴリズムを実施しました。完全なユーザーログ情報を使用して、パフォーマンスを大幅に向上できることを確認するための実験。 
[概要]チャレンジでは、リスニングセッションの前半の音響機能とユーザーインタラクションログを含む完全な情報が提供されます。目標は、完全なユーザーログ情報を使用して大幅なパフォーマンスの向上を達成できることを見つけることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-01-24">
        <br><font color="black">2019-01-24</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Audio Fingerprint for High-specific Audio Retrieval based on
  Contrastive Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.SD/paper_3.html">
      <font color="black">Neural Audio Fingerprint for High-specific Audio Retrieval based on
  Contrastive Learning</font>
    </a>
  </h2>
  <font color="black">コードとデータセットが利用可能になります。これらのレプリカは、小さな時間オフセットと、バックグラウンドノイズや部屋/マイクのインパルス応答などのさまざまなタイプの歪みを適用することにより、元のオーディオ信号に対する劣化効果をシミュレートできます。セグメントレベルの検索タスクで、従来のオーディオフィンガープリントシステムが失敗していた場所で、10分の1の小さなストレージを使用するシステムは有望な結果を示しています。 
[概要]この作業では、オーディオの短い単位セグメントから低次元を生成します。このフィンガープリントを使用して、高速の最大内積検索を作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-22">
        <br><font color="black">2020-10-22</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Convergence Guarantees for Non-Convex Optimisation with Cauchy-Based
  Penalties -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.IV/paper_0.html">
      <font color="black">Convergence Guarantees for Non-Convex Optimisation with Cauchy-Based
  Penalties</font>
    </a>
  </h2>
  <font color="black">コーシー正則化に基づく提案された方法は、一般的な信号処理の例を解くことによって評価されます。さまざまなケースで提案された収束条件を実験的に検証し、$ L_1 $や全変動（$ TV $）ノルムなどの最先端のペナルティ関数に対する提案されたCauchyベースの非凸ペナルティ関数の有効性を示します。 。周波数領域での1D信号のノイズ除去、ブレ除去とノイズ除去を含む2つの画像再構成タスク、および複数アンテナ通信システムでのエラー回復。 
[要約]コーシープリアーに加えて、近位演算子を計算するためのオープンフォーム式を最初に提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-10">
        <br><font color="black">2020-03-10</font>
      </time>
    </span>
</section>
<!-- paper0: VoteNet++: Registration Refinement for Multi-Atlas Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.IV/paper_1.html">
      <font color="black">VoteNet++: Registration Refinement for Multi-Atlas Segmentation</font>
    </a>
  </h2>
  <font color="black">マルチアトラスセグメンテーション（MAS）は、医用画像の一般的な画像セグメンテーション手法です。初期空間アライメントの影響と、MASパフォーマンスにラベル情報を使用することの有益な効果を示します。具体的には、体積変位フィールドを使用します。画像の解剖学的外観と予測されたラベルに基づいて登録を改良します。 
[概要]この作品では、ラベル融合の前に登録エラーを修正することにより、マスのパフォーマンスを向上させます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Sequential Learning for Cervical Spine Fracture Detection on
  Computed Tomography Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.IV/paper_2.html">
      <font color="black">Deep Sequential Learning for Cervical Spine Fracture Detection on
  Computed Tomography Imaging</font>
    </a>
  </h2>
  <font color="black">検証結果は、平衡（104陽性および104陰性症例）および不平衡（104陽性および419陰性症例）テストデータセットで70,92％および79.18％の分類精度を示しています。3,666CTスキャンの注釈付きデータセットを使用しました（モデルをトレーニングおよび検証するための729の陽性および2,937の陰性症例）。この論文では、頸椎骨折の自動検出のための双方向長短期記憶（BLSTM）層を備えた深い畳み込みニューラルネットワーク（DCNN）を提案します。 CTアキシャル画像。 
[ABSTRACT]骨折が疑われる場合の正確な診断は、患者の管理にとって重要です。データの分析は、患者の体の分析に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Low-rank plus Sparse Network for Dynamic MR Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.IV/paper_3.html">
      <font color="black">Deep Low-rank plus Sparse Network for Dynamic MR Imaging</font>
    </a>
  </h2>
  <font color="black">特に、交互線形化最小化法を使用して、低ランクでスパースな正則化の最適化問題を解決します。次に、正則化パラメーターが学習可能なネットワークに反復ステップが展開されます。これらの問題に対処するために、多くの深層学習アプローチが提案されました。 、しかしそれらのいくつかは低ランクの事前を使用しました。 
[要約]この論文では、動的mr再構成のためにモデルベースの低ランクプラススパースネットワークが提案されています。提案されたモデルは、ls-netと呼ばれ、最先端のcsおよび既存の深層学習方法よりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Optical Flow for Fast MRI Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.IV/paper_4.html">
      <font color="black">Learning Optical Flow for Fast MRI Reconstruction</font>
    </a>
  </h2>
  <font color="black">より正確には、学習した辞書上でまばらに表されるオプティカルフローモデルの形式でダイナミクスをエンコードすることを提案します。提案するアプローチは、-\ textit {マルチタスクおよびハイブリッドモデル}-従来の圧縮センシングの定式化を組み合わせたものです。オプティカルフロー近似を学習することによる動き補償を伴う動的MRIの再構成のために..アンダーサンプリングされた生データから高品質の磁気共鳴画像（MRI）を再構成することは、技術的および臨床的観点の両方から非常に興味深い。 
[概要]この研究では、数回の測定から高品質の医療用MRIを再構築するための新しい数学モデルを提案します。これは、学習した辞書上で大まかに表されるオプティカルフローモデルの形式でダイナミクスを組み合わせます。これは、データがデータから欠落しているという事実の重要な欠落情報につながる</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-22">
        <br><font color="black">2020-04-22</font>
      </time>
    </span>
</section>
<!-- paper0: COL0RME: COvariance-based $\ell_0$ super-Resolution Microscopy with
  intensity Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.IV/paper_5.html">
      <font color="black">COL0RME: COvariance-based $\ell_0$ super-Resolution Microscopy with
  intensity Estimation</font>
    </a>
  </h2>
  <font color="black">これは、共分散領域で定式化された非凸最適化問題を介して、蛍光分子のまばらな分布とエミッタ間の時間的および空間的独立性の仮定を体系化します。分子の変動を利用することで、優れた時空間分解能の生細胞イメージングが可能になります。一般的な顕微鏡と従来の蛍光色素の比較..実際のデータを処理するために、提案されたアプローチは、バックグラウンドとノイズの統計も推定します。 
[概要]超耐性超耐性イメージング法はしばしば困難です。これらには最先端の超耐性イメージング法が含まれます。提案されたアプローチはバックグラウンドとノイズ統計も推定します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Optimal transport-based metric for SMLM -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.IV/paper_6.html">
      <font color="black">Optimal transport-based metric for SMLM</font>
    </a>
  </h2>
  <font color="black">この論文では、フラットメトリックの基礎を紹介し、制御された合成例とSMLM 2016チャレンジのデータに適用することにより、この測定値を検証します。フラットメトリックを使用して、単一分子の再構成法のパフォーマンスを評価することを提案します。グラウンドトゥルースが利用可能なシナリオでのローカリゼーション顕微鏡法（SMLM）。フラットメトリックは、異なる質量の測定値間の最適な輸送の概念と密接に関連しており、SMLM評価の強固な数学的基盤を提供し、ローカリゼーションと検出の両方のパフォーマンスを統合します。 
[要約]フラットメトリックは、smlm評価のための堅実な数学的基礎を提供します。それはsmlmのシステムに堅実で不均衡を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Geometrically Matched Multi-source Microscopic Image Synthesis Using
  Bidirectional Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.IV/paper_7.html">
      <font color="black">Geometrically Matched Multi-source Microscopic Image Synthesis Using
  Bidirectional Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">画像合成は1つの有望なソリューションです。C.elegansの3Dライブタイムラプス胚画像へのモデルの適用は、好ましい結果を示します。さまざまなモダリティからの顕微鏡画像は、より完全な実験情報を提供できます。 
[概要] 3Dライブタイムへのモデルの適用-cのラプス顕微鏡画像。 elegansは異なる結果を示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: ST-GREED: Space-Time Generalized Entropic Differences for Frame Rate
  Dependent Video Quality Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.IV/paper_8.html">
      <font color="black">ST-GREED: Space-Time Generalized Entropic Differences for Frame Rate
  Dependent Video Quality Prediction</font>
    </a>
  </h2>
  <font color="black">一般化ガウス分布（GGD）を使用してバンドパス応答をモデル化し、GGDモデルでの参照ビデオと歪んだビデオ間のエントロピー変動を使用して、フレームレートの変化から生じるビデオ品質の変動をキャプチャします。Spaceと呼ばれる客観的なVQAモデルを考案します。 -空間的および時間的バンドパスビデオ係数の統計を分析するTimeGeneRalized Entropic Difference（GREED）。エントロピー差は、複数の時間的および空間的サブバンドにわたって計算され、学習されたリグレッサを使用してマージされます。 
[概要]知覚品質がフレームレートによってどのように影響を受けるか、およびフレームレートと圧縮分析が知覚品質にどのように影響するかを研究します。貪欲の方法がオンラインで利用可能になりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Interpreting Uncertainty in Model Predictions For COVID-19 Diagnosis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.IV/paper_9.html">
      <font color="black">Interpreting Uncertainty in Model Predictions For COVID-19 Diagnosis</font>
    </a>
  </h2>
  <font color="black">ただし、これらの予測の不確実性を定量化し、不確実性を解釈し、これをモデルまたはデータの不確実性に分解することについては、あまり検討されていません。これらのニーズに対処するために、不確実性とそのコンポーネントの解釈可能性に対処する視覚化フレームワークを開発します。ベイジアン畳み込みニューラルネットワークで計算された予測。ただし、従来の畳み込みネットワークは、予測に点推定を使用し、不確実性の捕捉が不足しているため、採用の信頼性が低くなります。 
[概要]胸部X線-コビッドケースの光線は肺の変化を示す傾向があります。畳み込みニューラルネットワークは、不確実性の注入可能性に対処することを目的としています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Optimization for Medical Image Segmentation: Theory and Practice when
  evaluating with Dice Score or Jaccard Index -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.IV/paper_10.html">
      <font color="black">Optimization for Medical Image Segmentation: Theory and Practice when
  evaluating with Dice Score or Jaccard Index</font>
    </a>
  </h2>
  <font color="black">理論的な観点から、メトリックに敏感な損失関数のグループ内の関係を調査し、テスト時にダイススコアとジャッカードインデックスを最適化するための加重クロスエントロピーの最適な加重スキームの存在に疑問を投げかけます。対象となるパフォーマンス指標がダイススコアまたはジャッカードインデックスである医療セグメンテーションタスクにメトリックセンシティブ損失関数を採用します。これは、マルチクラス設定で、さまざまなオブジェクトサイズと前景/背景比にわたってさらに当てはまります。 
[要約]調査によると、メトリックに敏感な損失は、クロスネバダベースの損失関数よりも優れています。これらの結果は、6つの医療セグメンテーションタスクで広範な検証が行われています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: A Systematic Evaluation of Coding Strategies for Sparse Binary Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.IV/paper_11.html">
      <font color="black">A Systematic Evaluation of Coding Strategies for Sparse Binary Images</font>
    </a>
  </h2>
  <font color="black">コンテキストミキシングを使用して、これらの成分を新しいコーデックに組み合わせ、より優れた圧縮率または速度とパフォーマンスの間のより有利なトレードオフを提供します。その後、アブレーション研究により、既存の方法の最も有用なコンポーネントを特定して分離できます。修復ベースの圧縮は、ピクセルデータのまばらなサブセットの観点から画像を表します。 
[概要]これにより、高密度で散在することが多い画像に可逆圧縮の問題が発生します。これまでにこの問題の最初の調査を実施しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Does contextual information improve 3D U-Net based brain tumor
  segmentation? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.IV/paper_12.html">
      <font color="black">Does contextual information improve 3D U-Net based brain tumor
  segmentation?</font>
    </a>
  </h2>
  <font color="black">BraTS 2020データセットは、従来のMR画像モダリティに加えてコンテキスト情報を追加チャネルとして使用する標準の3D U-Netモデルのトレーニングとテストに使用されました。結論として、コンテキストを使用した場合のセグメンテーションパフォーマンスの向上はありません。追加チャネルとしての情報..現在の研究の大部分は、セグメンテーションの精度を向上させるための新しいネットワークアーキテクチャの開発に専念しています。 
[ABSTRACT]畳み込みニューラルネットワークは、磁気共鳴（mr）画像で腫瘍領域を特定する際に最先端のパフォーマンスを示しています。脳腫瘍領域の大部分が改善することが示されています。テストデータセットは、統計的に有意な差を示さない場合2つのモデルのダイススコアの比較</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Matthews Correlation Coefficient Loss for Deep Convolutional Networks:
  Application to Skin Lesion Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.IV/paper_13.html">
      <font color="black">Matthews Correlation Coefficient Loss for Deep Convolutional Networks:
  Application to Skin Lesion Segmentation</font>
    </a>
  </h2>
  <font color="black">3つの皮膚鏡画像データセットの評価：ISBI ISIC 2017皮膚病変セグメンテーションチャレンジデータセット、DermoFit画像ライブラリ、およびPH2データセットは、提案された損失関数を使用してトレーニングされたモデルが、ダイス損失を使用してトレーニングされたモデルより11.25％、4.87％、および0.76優れていることを示しています深層学習ベースのアプローチはセグメンテーションパフォーマンスを改善しましたが、これらのモデルはデータのクラスの不均衡、特に背景の健康な肌が占める画像の割合の影響を受けやすいことがよくあります。肌のセグメンテーション病変は、皮膚病変のコンピュータ支援診断のための臨床決定支援システムにおける重要なタスクです。 
[概要]ディープラーニングベースのアプローチにより、モデルモデルモデルのパフォーマンスが向上しました。これらのモデルは、データのクラスの不均衡の影響を受けやすくなっています。この特定の特定は、背景の健康な肌が占める画像の割合です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Dual Encoder Fusion U-Net (DEFU-Net) for Cross-manufacturer Chest X-ray
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.IV/paper_14.html">
      <font color="black">Dual Encoder Fusion U-Net (DEFU-Net) for Cross-manufacturer Chest X-ray
  Segmentation</font>
    </a>
  </h2>
  <font color="black">本論文では、膨張を伴うインセプション畳み込みニューラルネットワーク、DEFU-Netと名付けられた密に接続された再帰畳み込みニューラルネットワークに基づく胸部X線用のデュアルエンコーダ融合U-Netフレームワークを提案します。ネットワークと機能の豊富な表現、拡張を伴う開始ブロックが採用されています。ただし、ほとんどのバリアントU-Netは、主にコンテキスト情報の抽出と接続のスキップに重点を置いています。 
[概要]最も有名な手法は、胸部X線を含む多くの医療データセットに使用されているu-netです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-11">
        <br><font color="black">2020-09-11</font>
      </time>
    </span>
</section>
<!-- paper0: SuperDTI: Ultrafast diffusion tensor imaging and fiber tractography with
  deep learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.IV/paper_15.html">
      <font color="black">SuperDTI: Ultrafast diffusion tensor imaging and fiber tractography with
  deep learning</font>
    </a>
  </h2>
  <font color="black">スキャン時間のこのような大幅な短縮により、多くの潜在的なアプリケーションの臨床ルーチンにDTIを含めることができます。結果：提案された手法は、わずか6つのアンダーサンプリングから、部分異方性と平均拡散係数マップ、およびファイバートラクトグラフィーを生成できます。生のDWI ..スーパーDTIは、DWIのノイズやアーティファクトの影響を非常に受けやすいことがよく知られているテンソルフィッティング手順をバイパスします。 
[ABSTRACT] superdtiを州と比較-ファイバートラッキングのイメージング方法。superdtiの最先端の方法と比較。ネットワークは、人間のコネクトームプロジェクトと虚血性脳卒中の患者からのデータセットを使用してトレーニングおよびテストされています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br><font color="black">2020-02-03</font>
      </time>
    </span>
</section>
<!-- paper0: What is the best data augmentation approach for brain tumor segmentation
  using 3D U-Net? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.IV/paper_16.html">
      <font color="black">What is the best data augmentation approach for brain tumor segmentation
  using 3D U-Net?</font>
    </a>
  </h2>
  <font color="black">ここでは、標準の3D U-Netをトレーニングするときに、さまざまなタイプのデータ拡張（フリッピング、回転、スケーリング、明るさ調整、弾性変形）を適用し、多くの場合、拡張によって検証セット（125人の被験者）のパフォーマンスが大幅に向上することを示します。私たちの結論は、明るさの増強と弾性変形が最も効果的であり、異なる増強技術の組み合わせは、1つの増強技術のみを使用する場合と比較してそれ以上の改善を提供しないということです。セグメンテーションネットワークのトレーニングには大きな注釈付きデータセットが必要であり、医療画像では取得が難しい場合があります。 。 
[要約]データ拡張は、脳腫瘍のセグメンテーションについて十分に調査されていません。データ拡張は完全には調査されていませんが、完全には調査されていません。データ拡張と弾性変形が最適に機能します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: A Dark and Bright Channel Prior Guided Deep Network for Retinal Image
  Quality Assessment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.IV/paper_17.html">
      <font color="black">A Dark and Bright Channel Prior Guided Deep Network for Retinal Image
  Quality Assessment</font>
    </a>
  </h2>
  <font color="black">具体的には、暗いチャネルと明るいチャネルの事前情報がネットワークの開始層に埋め込まれ、深い特徴の識別能力が向上します。現在の最先端技術では、元々自然画像用に設計された分類ネットワークを網膜画像の品質分類に直接転送します。または、複数のCNNブランチまたは独立したCNNを介して追加の画質の事前情報を導入します。網膜画質データセットEye-Qualityの実験結果は、提案されたGuidedNetの有効性を示しています。 
[概要]以前は、網膜画像の品質を評価するための新しいディープモデルがあります。この論文では、ガイドネットと呼ばれる網膜画像品質評価への暗くて明るい事前ガイド付きディープネットワークを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Smart Inference for Multidigit Convolutional Neural Network based
  Barcode Decoding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_0.html">
      <font color="black">Smart Inference for Multidigit Convolutional Neural Network based
  Barcode Decoding</font>
    </a>
  </h2>
  <font color="black">これらの困難なバーコードを解決するためにいくつかの作業が試みられましたが、まだ多くの制限があります。まず、予測フェーズでスマート推論（SI）と呼ばれる、チェックサムとテスト時間の拡張を備えた機能に基づく推論の特別な変更を提案しました。訓練されたモデル..この作業は、ポータブルデバイスで実行できる可能性のある深い畳み込みニューラルネットワークを使用して、デコードの問題を解決することを目的としています。 
[概要]これらの作品は、これらの挑戦的なバーコードを解決しようとしましたが、まだ多くの制限があります。これらの作品には、他の研究者が公開している携帯型の妊娠の隠蔽が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-14">
        <br><font color="black">2020-04-14</font>
      </time>
    </span>
</section>
<!-- paper0: The Convolution Exponential and Generalized Sylvester Flows -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_1.html">
      <font color="black">The Convolution Exponential and Generalized Sylvester Flows</font>
    </a>
  </h2>
  <font color="black">さらに、シルベスターフローを一般化し、基底変換としての一般化と畳み込み指数に基づく畳み込みシルベスターフローを提案します。この論文では、線形変換の指数を取ることにより、線形フローを構築する新しい方法を紹介します。畳み込み指数がCIFAR10の生成フローで他の線形変換よりも優れており、グラフ畳み込み指数がグラフ正規化フローのパフォーマンスを向上させることを示します。 
[概要]線形化はそれ自体が可逆である必要はありません。対数ヤコビ行列式は線形変換のトレースに等しい</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-02">
        <br><font color="black">2020-06-02</font>
      </time>
    </span>
</section>
<!-- paper0: Selecting Data Augmentation for Simulating Interventions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_2.html">
      <font color="black">Selecting Data Augmentation for Simulating Interventions</font>
    </a>
  </h2>
  <font color="black">多くのドメイン一般化手法では、この疑似相関が明示的に考慮されていないことがわかります。理論と実践の間のギャップを埋めるために、ドメイン一般化の問題に関する因果関係の視点を開発します。因果関係の概念を使用して説明できると主張します。観測されたドメインとタスクラベルの間の疑似相関を弱める方法を説明することによるデータ拡張の成功。 
[ABSTRACT]ヒューリスティックに基づくデータ拡張手法を使用して、ドメイン靭帯の特徴を学習します。因果関係の概念を使用して、観測されたドメインとタスクの間の疑似相関を弱める方法を説明することで、データ拡張の成功を説明できると主張します。ラベル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-04">
        <br><font color="black">2020-05-04</font>
      </time>
    </span>
</section>
<!-- paper0: Spin-Weighted Spherical CNNs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_3.html">
      <font color="black">Spin-Weighted Spherical CNNs</font>
    </a>
  </h2>
  <font color="black">2番目のタイプは、畳み込みを球に直接適用します。これは、ゾーン（等方性）フィルターに制限されているため、表現力が制限されます。スピン加重関数は、球形ベクトル場として解釈することもでき、入力または出力が行われるタスクにアプリケーションを使用できます。はベクトル場です。球形CNNは成功例であり、球形入力のSO（3）等価表現を生成します。 
[概要]球形cnnは成功例であり、次のように生成されます（3）-球形入力の同変表現。これらは、回転時に位相が変化する球上の単純な-複雑な-値の関数です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br><font color="black">2020-06-18</font>
      </time>
    </span>
</section>
<!-- paper0: Interactive Annotation of 3D Object Geometry using 2D Scribbles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_4.html">
      <font color="black">Interactive Annotation of 3D Object Geometry using 2D Scribbles</font>
    </a>
  </h2>
  <font color="black">2つの使いやすいインタラクションモジュールを紹介します。最初に、3D形状を自動的に推測し、ユーザーが目的の2Dビューに落書きを描くことで、大きなエラーに関するフィードバックを提供できるようにします。このアプローチの背後にある重要なアイデアは、完全な3D形状にインタラクティブに注釈を付けるために、人間が3D世界について持っている強力な事前情報を活用します。 
[概要]私たちのアプローチの背後にある重要なアイデアは、完全な3D形状にインタラクティブに注釈を付けるために、人間が3D世界について持っている強力な事前情報を活用することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Phase Correlation for End-to-End Heterogeneous Sensor Measurements
  Matching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_5.html">
      <font color="black">Deep Phase Correlation for End-to-End Heterogeneous Sensor Measurements
  Matching</font>
    </a>
  </h2>
  <font color="black">解釈可能なモデリングにより、ネットワークは軽量であり、より良い一般化が期待できます。結果は、私たちの方法が異種センサーの測定値と一致し、従来の位相相関や他の学習ベースの方法よりも優れていることを示しています。以前のいくつかの方法での徹底的な評価を排除し、効率を向上させます。 
[要約]結果は、私たちの方法が異種センサー測定値と一致できることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-21">
        <br><font color="black">2020-08-21</font>
      </time>
    </span>
</section>
<!-- paper0: Extending DeepSDF for automatic 3D shape retrieval and similarity
  transform estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_6.html">
      <font color="black">Extending DeepSDF for automatic 3D shape retrieval and similarity
  transform estimation</font>
    </a>
  </h2>
  <font color="black">最後に、3Dモデル圧縮の一形態としてのこのアプローチの実行可能性も強調します。合成データセットと実際のデータセットに対するこの定式化の有効性を実証するための実験を実施し、最先端技術との良好な比較を報告します。ただし、このアプローチトレーニング中に観察されたものと同じ標準的なスケールとポーズのクエリ形状を持つ必要性によって制限されており、実際のシーンでの効果が制限されています。 
[概要]合成データセットと実際のデータセットに対するこのプレゼンテーションの有効性を実証するための実験を実施します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br><font color="black">2020-04-20</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Learning by Cross-Modal Audio-Video Clustering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_7.html">
      <font color="black">Self-Supervised Learning by Cross-Modal Audio-Video Clustering</font>
    </a>
  </h2>
  <font color="black">最も重要なことは、大規模なラベルなしデータで事前トレーニングされたビデオモデルは、HMDB51とUCF101でのアクション認識のためにImageNetとKineticsで完全な監視で事前トレーニングされた同じモデルを大幅に上回っています。 2つのモダリティの間で..私たちの知る限り、XDCは、同じアーキテクチャでの行動認識のための大規模な完全教師あり事前トレーニングよりも優れた最初の自己教師あり学習方法です。 
[ABSTRACT] cross-モーダルディープクラスタリング（xdc）は、新しい自己監視方式です。一方のモダリティで教師なしクラスタリングを他方の監視信号として使用します。これを使用して、一方の有効性を他方から予測できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-28">
        <br><font color="black">2019-11-28</font>
      </time>
    </span>
</section>
<!-- paper0: A Comparison of Few-Shot Learning Methods for Underwater Optical and
  Sonar Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_8.html">
      <font color="black">A Comparison of Few-Shot Learning Methods for Underwater Optical and
  Sonar Image Classification</font>
    </a>
  </h2>
  <font color="black">少数ショット学習（FSL）の取り組みにより、低いデータ可用性に対処するための多くの有望な方法が生み出されました。ただし、十分な量のデータを取得してラベル付けすることは、特に希少なオブジェクトを観察したりリアルタイムで実行したりする場合、比較的コストと時間がかかる可能性があります。私たちの仕事がFSLを自律型水中システムに適用し、その学習能力を拡大するのに役立つことを願っています。 
[概要]このような方法の多くは、目に見えないオブジェクトにうまく一般化するために、クラスごとに数千とは言わないまでも数百の画像を必要とします。ただし、このような手法の多くは、何年にもわたって数百のfsl画像を必要とします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-10">
        <br><font color="black">2020-05-10</font>
      </time>
    </span>
</section>
<!-- paper0: Backdoor Learning: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_9.html">
      <font color="black">Backdoor Learning: A Survey</font>
    </a>
  </h2>
  <font color="black">既存のバックドア攻撃と防御をその特性に基づいて要約および分類し、中毒ベースのバックドア攻撃を分析するための統一されたフレームワークを提供します。最後に、レビューされた作業に基づいて特定の将来の研究の方向性を簡単に概説します。さらに、関係も分析します。バックドア攻撃と関連フィールド（$ ie、$敵対的攻撃とデータポイズニング）の間で、ベンチマークデータセットを要約します。 
[ABSTRACT]バックドア攻撃は、トレーニングがユーザーによって完全に制御されていない場合に発生する可能性があります。サードパーティのデータセットでトレーニングしたり、サードパーティのモデルを採用したりするために使用される可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-17">
        <br><font color="black">2020-07-17</font>
      </time>
    </span>
</section>
<!-- paper0: GIMP-ML: Python Plugins for using Computer Vision Models in GIMP -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_10.html">
      <font color="black">GIMP-ML: Python Plugins for using Computer Vision Models in GIMP</font>
    </a>
  </h2>
  <font color="black">GIMP-MLは、numpy、pytorch、open-cv、scipyなどの標準のPythonパッケージに依存しています。これらとは別に、これらのプラグインを使用したいくつかの画像操作技術がコンパイルされ、YouTubeチャンネル（https://youtube.com/ user / kritiksoman）は、機械学習ベースの画像修正のユースケースを示すことを目的としています。これにより、コンピュータービジョンの最近の進歩を従来の画像編集パイプラインに使用できるようになります。 
[概要] gimpはコンピュータビジョンの最近の進歩の使用を可能にします。これらの進歩は従来の画像編集パイプラインに使用されています。これらの技術は編集され、YouTubeチャンネルでデモンストレーションされています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br><font color="black">2020-04-27</font>
      </time>
    </span>
</section>
<!-- paper0: Restoring Negative Information in Few-Shot Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_11.html">
      <font color="black">Restoring Negative Information in Few-Shot Object Detection</font>
    </a>
  </h2>
  <font color="black">この論文では、新しいネガティブおよびポジティブ代表ベースのメトリック学習フレームワークと、ネガティブおよびポジティブ代表による新しい推論スキームを導入することにより、少数ショットオブジェクト検出におけるネガティブ情報を復元します。少数ショット学習の最近の進歩は主に焦点を当てていますこのホワイトペーパーでは、オブジェクトの検出に焦点を当てながら、画像の分類について説明します。トレーニングとテストの両方でネガティブな情報をエンコードするために、いくつかの新しいモジュールを備えた最近の数ショットのパイプラインRepMetで作業を構築します。 
[概要]最近のいくつかの進歩-ショット学習は主に画像分類に焦点を当てています。この論文では、オブジェクトの検出に焦点を当てています。ネガは空間学習を埋め込むために不可欠です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-22">
        <br><font color="black">2020-10-22</font>
      </time>
    </span>
</section>
<!-- paper0: Joint Architecture and Knowledge Distillation in CNN for Chinese Text
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_12.html">
      <font color="black">Joint Architecture and Knowledge Distillation in CNN for Chinese Text
  Recognition</font>
    </a>
  </h2>
  <font color="black">蒸留の手法は、面倒なニューラルネットワークをコンパクトなネットワークに変換して、モデルを代替ハードウェアデバイスに展開できるようにします。バニラ畳み込みレイヤーの場合、深さ方向に分離可能な畳み込みと点ごとの畳み込みのみで構成される提案された節約畳み込み（ParConv）ブロックはネットワークの幅や深さなどの他の調整を行わずに直接置き換える。次に、最も人気のあるデータセットの1つであるMNISTで実験を行うことにより、提案されたアプローチが主流のバックボーンネットワークにも正常に適用できることを示します。 
[ABSTRACT]蒸留ベースのアプローチには、ほとんどの既成のディープラーニングソフトウェアでサポートされている簡単なトレーニングプロセスが含まれ、ハードウェアの特別な要件はありません。提案されたアルゴリズムは、オフラインの手書き中国語テキスト認識（hctr）で最初に検証されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-17">
        <br><font color="black">2019-12-17</font>
      </time>
    </span>
</section>
<!-- paper0: Progressive Multi-stage Feature Mix for Person Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_13.html">
      <font color="black">Progressive Multi-stage Feature Mix for Person Re-Identification</font>
    </a>
  </h2>
  <font color="black">具体的には、1。モデルに画像内のさまざまな手がかりを探すように強制するために、多段階分類器を採用し、モデルが各段階の相補領域に焦点を合わせることができることを期待します。小さな局所領域からの画像の特徴個人の再識別タスクで強力な証拠を提供します。この作業では、モデルがより正確で多様な特徴を漸進的に見つけることを可能にするプログレッシブ多段階特徴混合ネットワーク（PMM）を提案します。 
[ABSTRACT] cnnは、最も目立つ地域に注意を払いすぎることがよくあります。ただし、髪の毛、靴、衣服のロゴなど、他の識別的な手がかりは見られません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-17">
        <br><font color="black">2020-07-17</font>
      </time>
    </span>
</section>
<!-- paper0: Big Self-Supervised Models are Strong Semi-Supervised Learners -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_14.html">
      <font color="black">Big Self-Supervised Models are Strong Semi-Supervised Learners</font>
    </a>
  </h2>
  <font color="black">ラベルの10％で、私たちの方法でトレーニングされたResNet-50は77.5％のトップ1精度を達成し、すべてのラベルで標準の教師ありトレーニングを上回ります。この手順は、ラベルのわずか1％で73.9％のImageNetトップ1精度を達成します（ ResNet-50を使用すると、クラスあたり$ \ le $ 13のラベル付き画像）、以前の最先端技術よりもラベル効率が$ 10 \ times $向上します。微調整後、大きなネットワークをさらに改善して、ラベルのない例を2回使用することにより、分類精度の損失がほとんどない、はるかに小さいものですが、タスク固有の方法です。 
[概要]提案された半教師あり学習アルゴリズムは、ラベルのないデータを使用します。ラベルのない例を使用した事前トレーニングと蒸留に驚くほど効果的です。この方法は、次の3つのステップで説明できます。simclrv2を使用した大きなresnetモデルの教師なし事前トレーニング</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br><font color="black">2020-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Self-Supervised Contrastive Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_15.html">
      <font color="black">Adversarial Self-Supervised Contrastive Learning</font>
    </a>
  </h2>
  <font color="black">既存の敵対的学習アプローチは、ほとんどの場合、クラスラベルを使用して、誤った予測につながる敵対的サンプルを生成します。このサンプルは、モデルのトレーニングを強化して堅牢性を向上させるために使用されます。データサンプルのランダムな増加とそのインスタンスごとの敵対的摂動との間の類似性を最大化することを目的とした、ラベル付けされたデータのないニューラルネットワーク。最先端の監視された敵対的学習方法に匹敵する堅牢な精度、およびブラックボックスや目に見えないタイプの攻撃に対する堅牢性が大幅に向上しました。 
[概要]この方法は、複数のベンチマークデータセットに基づいています。これを使用して、ブラックボックスや目に見えない攻撃に対する精度を向上させることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-13">
        <br><font color="black">2020-06-13</font>
      </time>
    </span>
</section>
<!-- paper0: Coarse-to-Fine Pseudo-Labeling Guided Meta-Learning for
  Inexactly-Supervised Few-Shot Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_16.html">
      <font color="black">Coarse-to-Fine Pseudo-Labeling Guided Meta-Learning for
  Inexactly-Supervised Few-Shot Classification</font>
    </a>
  </h2>
  <font color="black">代表的なベンチマークでの実験は、私たちのアプローチがベースラインモデルよりも大きな利点を示していることを示しています。さらに、不正確な監視で視覚的側面と意味的側面の両方で優れた画像類似性測定値を取得するために、バイレベル識別埋め込み（BDE）を開発します。 Coarse-to-Fine（C2F）疑似ラベル付けプロセスを提案し、類似性マッチングを介して各粗いクラスを疑似細かいクラスにグループ化することにより、粗いラベル付けされたデータから疑似タスクを構築します。 
[概要]さらに、シンプルからファインまでのタスクに焦点を当てるシンプルなものを提案します。これらはシンプルでシンプルでシンプルなラベル付けプロセスです。これには、各不良クラスをファインファインファインに配置することが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-11">
        <br><font color="black">2020-07-11</font>
      </time>
    </span>
</section>
<!-- paper0: Trading via Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_17.html">
      <font color="black">Trading via Image Classification</font>
    </a>
  </h2>
  <font color="black">画像を使用して、12を超える機械学習分類モデルをトレーニングし、データが視覚的に表されるときに、アルゴリズムが複雑でマルチスケールのラベル生成ルールを復元するのに非常に効率的であることを発見しました。財務時系列の大規模なサンプルを作成します。ローソク足（ボックスおよびウィスカー）チャートとしてエンコードされた画像と、アルゴリズムで定義された3つのバイナリトレード戦略に従ってサンプルにラベルを付けます。この作業では、画像認識の成功に基づいて、従来の時系列分析をそれに変換することの価値を検証します。画像分類の。 
[概要]財務時系列画像の大規模なサンプルを作成します。数学的に定義された3つのバイナリー取引戦略に従ってサンプルにラベルを付けます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-23">
        <br><font color="black">2019-07-23</font>
      </time>
    </span>
</section>
<!-- paper0: Vision-based Robotic Grasping From Object Localization, Object Pose
  Estimation to Grasp Estimation for Parallel Grippers: A Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_18.html">
      <font color="black">Vision-based Robotic Grasping From Object Localization, Object Pose
  Estimation to Grasp Estimation for Parallel Grippers: A Review</font>
    </a>
  </h2>
  <font color="black">多くの物体姿勢推定法は、物体の位置特定を必要とせず、物体の位置特定と物体の姿勢推定を一緒に行います。把持推定タスクには、2D平面把持法と6DoF把持法が含まれ、前者は一方向からの把持に制約されます。さらに、ビジョンベースのロボットによる把握に関する課題と、これらの課題に対処するための将来の方向性も指摘されています。 
[概要]視覚ベースのロボット把持中に3つの主要なタスクを終了します。さらに、タスクはターゲットオブジェクトの領域を提供します。把持推定タスクには、2d平面把持法と6dof把持法が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-16">
        <br><font color="black">2019-05-16</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Implicit Functions for Topology-Varying Dense 3D Shape
  Correspondence -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_19.html">
      <font color="black">Learning Implicit Functions for Topology-Varying Dense 3D Shape
  Correspondence</font>
    </a>
  </h2>
  <font color="black">両方の関数は、形状潜在コードを生成するエンコーダとともに、いくつかの有効な損失関数と一緒に学習されます。このようなメカニズムは、本質的に、異なるパーツ構成を持つ人工オブジェクトに利益をもたらします。この論文の目的は、高密度を学習することです。監視されていない方法でのトポロジーが変化するオブジェクトの3D形状対応。 
[概要]私たちのアプローチの効果的な部分は、3Dセマンティック対応と形状セグメンテーションを通じて示されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-23">
        <br><font color="black">2020-10-23</font>
      </time>
    </span>
</section>
<!-- paper0: Inferring Point Clouds from Single Monocular Images by Depth
  Intermediation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_20.html">
      <font color="black">Inferring Point Clouds from Single Monocular Images by Depth
  Intermediation</font>
    </a>
  </h2>
  <font color="black">単一画像の3Dオブジェクト再構成タスクの実験結果は、提案された方法が既存の最先端の方法よりも優れていることを示しています。この論文では、単一ビューRGB画像からオブジェクトの3D点群を生成するパイプラインを提案します。 ..これまでのほとんどの研究では、単一のRGB画像から3D点座標を直接予測しています。 
[要約]提案された方法は、既存の最先端の方法よりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-04">
        <br><font color="black">2018-12-04</font>
      </time>
    </span>
</section>
<!-- paper0: Synergistic saliency and depth prediction for RGB-D saliency detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_21.html">
      <font color="black">Synergistic saliency and depth prediction for RGB-D saliency detection</font>
    </a>
  </h2>
  <font color="black">RGB-D顕著性データセットで私たちの方法を一般化するために、2つのそれぞれのタスク間の相互精製によって顕著性と深さの両方を共同で推定する新しい予測ガイドクロスリファインメントモジュール、および敵対的学習アプローチが採用されています。RGBから利用可能な深度情報-Dカメラは、RGBチャネルからの図/地面の手がかりが弱い場合に顕著なオブジェクトをセグメント化するのに役立ちます。ここでは、顕著性の地面のない小さなRGB-D顕著性データセットでトレーニングできるRGB-D顕著性検出の半監視システムを提案します。真実、また、顕著性グラウンドトゥルースと一緒に大規模なRGB顕著性データセットを効果的に共同使用します。 
[概要] rgb-d顕著性検出のシステムは、顕著性のグラウンドトゥルースなしで、より小さな顕著性データセットでトレーニングできます。これらの顕著性データセットは、トレーニングと結論の両方にrgb-dcデータの4つのチャネルすべてを使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-03">
        <br><font color="black">2020-07-03</font>
      </time>
    </span>
</section>
<!-- paper0: Calibrating Deep Neural Networks using Focal Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_22.html">
      <font color="black">Calibrating Deep Neural Networks using Focal Loss</font>
    </a>
  </h2>
  <font color="black">実際の焦点損失の使用を容易にするために、損失関数に含まれるハイパーパラメータを自動的に選択する原理的なアプローチも提供します。al。、2017]は、すでに非常によく較正されているモデルを学習することを可能にします。温度と組み合わせるとスケーリングは、精度を維持しながら、最先端のキャリブレーションされたモデルを生成します。 
[要約]このシステムにより、すでに非常によく調整されているモデルを学習できます。要因の徹底的な分析を提供し、これから収集した洞察を使用して、誤った調整を正当化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-21">
        <br><font color="black">2020-02-21</font>
      </time>
    </span>
</section>
<!-- paper0: Dual Encoder Fusion U-Net (DEFU-Net) for Cross-manufacturer Chest X-ray
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CV/paper_23.html">
      <font color="black">Dual Encoder Fusion U-Net (DEFU-Net) for Cross-manufacturer Chest X-ray
  Segmentation</font>
    </a>
  </h2>
  <font color="black">この論文では、膨張を伴うInception Convolutional Neural Network、DEFU-Netという名前の密に接続されたRecurrent Convolutional Neural Networkに基づく胸部X線用のデュアルエンコーダフュージョンU-Netフレームワークを提案します。ただし、ほとんどのバリアントU-Net主にコンテキスト情報の抽出と接続のスキップに焦点を当てます。ネットワークの幅を広げ、特徴の表現を充実させるために、拡張を伴う開始ブロックが採用されています。 
[概要]最も有名な手法は、胸部X線を含む多くの医療データセットに使用されているu-netです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-11">
        <br><font color="black">2020-09-11</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: TweetEval: Unified Benchmark and Comparative Evaluation for Tweet
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CL/paper_0.html">
      <font color="black">TweetEval: Unified Benchmark and Comparative Evaluation for Tweet
  Classification</font>
    </a>
  </h2>
  <font color="black">また、出発点として強力なベースラインのセットを提供し、さまざまな言語モデリングの事前トレーニング戦略を比較します。ソーシャルメディアの自然言語処理の実験的展望は断片化されすぎています。したがって、現在の最先端技術が何であるかは不明です。つまり、標準化された評価プロトコルがないため、そのようなドメイン固有のデータでトレーニングされた強力なベースラインのセットもありません。 
[概要]毎年、感情分析などの古典的なものから皮肉な検出や絵文字の予測に至るまで、新しい共有タスクとデータセットが提案されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-23">
        <br><font color="black">2020-10-23</font>
      </time>
    </span>
</section>
<!-- paper0: Infusing Sequential Information into Conditional Masked Translation
  Model with Self-Review Mechanism -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CL/paper_1.html">
      <font color="black">Infusing Sequential Information into Conditional Masked Translation
  Model with Self-Review Mechanism</font>
    </a>
  </h2>
  <font color="black">具体的には、CMTMの同じデコーダーに左から右のマスクを挿入し、CMTMから生成された各単語が置き換えられるか、保持されるかを自動回帰的に確認するように誘導します。知識の蒸留により、モデルは通常のモデルを上回ります。左から右へのTransformerモデルで、デコードを大幅に高速化します。したがって、TransformerベースのCMTMをトレーニングするだけでなく、シーケンシャル情報を注入するセルフレビューメカニズムを提案します。 
[概要]有望なアプローチは、条件付きマスク変換モデル（cmtm）をトレーニングすることです。トランスフォーマーベースのcmtmをトレーニングするだけでなく、視覚情報を注入するセルフレビューメカニズムを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-19">
        <br><font color="black">2020-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: At Which Level Should We Extract? An Empirical Analysis on Extractive
  Document Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CL/paper_2.html">
      <font color="black">At Which Level Should We Extract? An Empirical Analysis on Extractive
  Document Summarization</font>
    </a>
  </h2>
  <font color="black">具体的には、構成要素解析ツリーに基づいてサブセンテンス単位を抽出することを提案します。広範な実験と分析により、サブセンテンス単位の抽出は、自動評価と人間評価の両方の評価の下で、全文抽出と比較して競争力があることが示されています。自動ドキュメント要約で効果的であることが証明されています。 
[要約]研究者は、完全な文を抽出するときに不必要性と冗長性の問題が存在することを示しました。サブセンテンス単位の抽出は有望な代替手段です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: Language Model Prior for Low-Resource Neural Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CL/paper_3.html">
      <font color="black">Language Model Prior for Low-Resource Neural Machine Translation</font>
    </a>
  </h2>
  <font color="black">この目的は、LMがターゲット言語についてTMを教えると見なすことができる知識蒸留に関連しています。さまざまな方法がTMの分布に与える影響の分析を示します。提案されたアプローチはデコード速度を損なうことはありません。 、推論中にそれを必要とする以前の作業とは異なり、LMはトレーニング時にのみ使用されるためです。 
[要約]一般的な解決策は、豊富な単一言語データでトレーニングされた言語モデル（lm）の知識を活用することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: SIGTYP 2020 Shared Task: Prediction of Typological Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CL/paper_4.html">
      <font color="black">SIGTYP 2020 Shared Task: Prediction of Typological Features</font>
    </a>
  </h2>
  <font color="black">類型的KBの幅広い採用を妨げる主な欠点は、ほとんどの言語が一部の機能の注釈しか持たないという意味で、それらがまばらに配置され、広い範囲をカバーする機能がほとんどないという意味で歪んでいることです。類型的機能はしばしば相互に相関します。それらを予測して、この共有タスクの焦点でもある類型KBを自動的に入力することができます。全体として、タスクは5チームから8件の提出を集め、そのうち最も成功した方法はそのような機能の相関関係を利用します。 
[ABSTRACT]類型的特徴はしばしば相互に相関します。それらを予測することが可能であるため、類型的特性を自動的に設定します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-16">
        <br><font color="black">2020-10-16</font>
      </time>
    </span>
</section>
<!-- paper0: A Survey on Text Classification: From Shallow to Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CL/paper_5.html">
      <font color="black">A Survey on Text Classification: From Shallow to Deep Learning</font>
    </a>
  </h2>
  <font color="black">関連するテキストと特徴抽出および分類に使用されるモデルに従って、テキスト分類の分類法を作成します。次に、これらの各カテゴリについて詳細に説明し、予測のテストをサポートする技術開発とベンチマークデータセットの両方を扱います。この調査では、さまざまな手法間の包括的な比較、およびさまざまな評価指標の長所と短所の特定も提供されます。 
[概要]このペーパーでは、1961年から2020年までの最先端のアプローチを確認し、ギャップを埋めます。包括的な学習からディープラーニングまでのモデルに焦点を当てます。次に、主要な影響、将来の研究の方向性、および研究領域が直面する課題を要約して結論を出します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-02">
        <br><font color="black">2020-08-02</font>
      </time>
    </span>
</section>
<!-- paper0: Let's Stop Incorrect Comparisons in End-to-end Relation Extraction! -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CL/paper_6.html">
      <font color="black">Let's Stop Incorrect Comparisons in End-to-end Relation Extraction!</font>
    </a>
  </h2>
  <font color="black">このメタアナリシスは、評価設定とデータセット統計の両方のレポートで厳密さの必要性を強調し、エンドツーエンドのREで評価設定を統合することを求めます。次に、の影響を定量化するための小規模な実証研究を提案します。最も一般的な間違いとそれを評価すると、ACE05で最終的なREパフォーマンスが約5％過大評価されます。また、この機会を利用して、言語モデルの事前トレーニング（具体的にはBERT）とスパンの使用という2つの最近の開発の未踏のアブレーションを研究します。レベルNER。 
[概要]最初に、公開された論文で無効な比較のパターンを特定します。それらは、送信を回避するためにそれらを説明します。また、この機会を利用して、最近の2つの開発のアブレーションを研究します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Differentially Private Language Models Benefit from Public Pre-training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CL/paper_7.html">
      <font color="black">Differentially Private Language Models Benefit from Public Pre-training</font>
    </a>
  </h2>
  <font color="black">DPの微調整により、プライベートドメインの言語モデルのパフォーマンスが向上し、そのようなモデルのトレーニングが可能になることがわかりました。ただし、差分プライバシーを適用するトレーニングアルゴリズムは、モデルの品質を低下させることがよくあります。機密情報、差分プライバシー（DP）により、個人データが保護されている程度を定量化できます。 
[概要]機密情報に関する言語モデルをトレーニングする場合、自動プライバシー（dp）により、個人データが保護されている程度を定量化できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-13">
        <br><font color="black">2020-09-13</font>
      </time>
    </span>
</section>
<!-- paper0: ENT-DESC: Entity Description Generation by Exploring Knowledge Graph -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/cs.CL/paper_8.html">
      <font color="black">ENT-DESC: Entity Description Generation by Exploring Knowledge Graph</font>
    </a>
  </h2>
  <font color="black">私たちのデータセットは、大規模なナレッジグラフ（KG）からさまざまなタイプの主要エンティティの豊富な知識を取得することを含みます。これにより、現在のグラフからシーケンスへのモデルは、説明の生成中に情報の損失とパラメータの爆発的な問題に深刻な影響を受けます。論文では、KG-to-textでのこのような実用的なシナリオの研究を容易にするために、大規模でやりがいのあるデータセットを紹介します。さらに、豊富なグラフ情報を抽出することを学習する集計方法も組み込んでいます。 
[要約]この論文では、このような実用的なシナリオの研究を容易にするための大規模でやりがいのあるデータセットをkgでテキストに紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: The Frequency Spectrum and Geometry of the Hal Saflieni Hypogeum Appear
  Tuned -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.AS/paper_0.html">
      <font color="black">The Frequency Spectrum and Geometry of the Hal Saflieni Hypogeum Appear
  Tuned</font>
    </a>
  </h2>
  <font color="black">また、ピーク周波数は等間隔であり、音楽の全音階に似ていることにも注意してください。これも偶然ではなく、スペクトル自体が文化的な重要性を持っている可能性があることを示唆しています。ハルサフリエニ地下墳墓はユニークな地下マルタネオリシックです。その音響に興味のある十分に文書化された歴史を持つ聖域..この作品は、その内部建築に重要な音楽的要素を持つ人工構造の最も初期の既知の例の1つを識別します。 
[概要]以前の研究では、異常なスペクトルが指摘されていますが、これが一致したかどうかは不明です。結果として得られたスペクトルには、複数のチャンバーを備えた複数の非隣接洞窟壁の寸法の接合が必要でした。サイトの新石器時代のクリエイターの動機付けまたは文化的役割</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Effect of Language Proficiency on Subjective Evaluation of Noise
  Suppression Algorithms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.AS/paper_1.html">
      <font color="black">Effect of Language Proficiency on Subjective Evaluation of Noise
  Suppression Algorithms</font>
    </a>
  </h2>
  <font color="black">P.835アプローチ、ただしITU-TRec。に準拠したクラウドソーシング設定で実装。実験は標準化されたITU-TRec。に従って実施されました。この仮定をテストするために、英語とドイツ語のネイティブで実施された2つの主観的テストの結果を報告します。ネイティブの英語、ドイツ語、および北京語のスピーカーによって録音された音声サンプルの品質を判断するリスナー。これらは、さまざまなバックグラウンドノイズレベルとノイズ抑制効果によって劣化します。 
[ABSTRACT]ノイズ-音声の減少と残差テストは、ターゲット言語のネイティブリスナーと非ネイティブリスナーにさまざまな方法で影響を与える可能性があります。実験は、ドイツ語によって翻訳された標準言語に従って実施されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Composer Classification Using Symbolic Representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.AS/paper_2.html">
      <font color="black">Deep Composer Classification Using Symbolic Representation</font>
    </a>
  </h2>
  <font color="black">この研究では、シンボリックドメインで作曲家を分類するためにディープニューラルネットワークをトレーニングします。MAESTROデータセットで実施された実験では、13〜古典的な作曲家の分類について0.8333のF1値を報告します。モデルは2チャネルを取ります。 2次元入力、つまり、タイムピッチ表現の開始とノートのアクティブ化。これは、MIDI録音から変換され、単一ラベルの分類を実行します。 
[概要]モデルは、時間の開始とノートのアクティブ化を含む、2つのチャネル2の知覚入力を取ります-ピッチ表現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-02">
        <br><font color="black">2020-10-02</font>
      </time>
    </span>
</section>
<!-- paper0: Speaker Anonymization with Distribution-Preserving X-Vector Generation
  for the VoicePrivacy Challenge 2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.AS/paper_3.html">
      <font color="black">Speaker Anonymization with Distribution-Preserving X-Vector Generation
  for the VoicePrivacy Challenge 2020</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、システムの匿名化コンポーネントとして他の方法と簡単に統合でき、匿名化中に使用するスピーカーのプールを分散する必要がなくなります。人口データを使用して、Xベクトル空間のプロパティを学習してから、偽のXベクトルをサンプリングするために使用する生成モデル..このアプローチが、有機スピーカーXベクトルの予想される類似性内分布により厳密に従うXベクトルを生成する方法を示します。 
[概要]偽のx中心を生成する新しい方法を提案します。これにより、有機スピーカーの分布特性が低下します。このアプローチで同じ特性がどのように生成されるかを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Improved Mask-CTC for Non-Autoregressive End-to-End ASR -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.AS/paper_4.html">
      <font color="black">Improved Mask-CTC for Non-Autoregressive End-to-End ASR</font>
    </a>
  </h2>
  <font color="black">次に、部分的なターゲットシーケンスの長さを予測する補助目的を導入することにより、新しいトレーニングとデコードの方法を提案します。これにより、モデルは推論中にトークンを削除または挿入できます。さまざまなASRタスクの実験結果は、提案されたアプローチがマスクを改善することを示しています。 CTCは、標準のCTCモデル（WSJで15.5％$ \ rightarrow $ 9.1％WER）を大幅に上回っています。また、エンドツーエンドの音声変換へのMask-CTCの潜在的なアプリケーションも示しています。 
[ABSTRACT] mask --ctcは、非自己回帰方式でトークンを生成することにより、この要求を満たします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Audio Cover Song Identification using Convolutional Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.AS/paper_5.html">
      <font color="black">Audio Cover Song Identification using Convolutional Neural Network</font>
    </a>
  </h2>
  <font color="black">次に、カバー曲のペアと非カバー曲のペアで構成されるデータセットを作成します。これらはそれぞれ正と負のトレーニングサンプルとして使用されます。トレーニングされたCNNは、相互類似性マトリックスが与えられた場合にカバー曲の関係にある確率を出力します任意の2曲から生成され、確率でランク付けしてカバー曲を識別します。カバー曲間に意味のあるパターンがあり、これを学習できるという観察に基づいて、マシンでカバー曲の識別問題を再定式化しました。学習フレームワーク。 
[ABSTRACT] cnnは、曲のペアからの相互類似性マトリックスを使用して構築されました。トレーニングされたcnnは、カバー曲の関係にある確率を生成します。テストは、確率でランク付けすることにより、カバー曲を識別するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2017-12-01">
        <br><font color="black">2017-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Integrating end-to-end neural and clustering-based diarization: Getting
  the best of both worlds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.AS/paper_6.html">
      <font color="black">Integrating end-to-end neural and clustering-based diarization: Getting
  the best of both worlds</font>
    </a>
  </h2>
  <font color="black">シミュレートされたノイズの多い残響2スピーカー会議のようなデータに基づく実験で、特に入力データが長い場合、提案されたフレームワークが元のEENDよりも大幅に優れていることを示します。この論文では、シンプルで効果的なハイブリッドダイアリゼーションフレームワークを提案します。これは、重複した音声と、任意の数の話者を含む長い録音で機能します。最近のダイアリゼーション技術は、クラスタリングとエンドツーエンドのニューラルアプローチの2つのアプローチに分類できます。これらのアプローチには、長所と短所があります。 
[概要]このシステムは、ニューラルネットワークを使用してダイアリゼーションラベルを予測するために使用できます。x-シールドなどのスピーカー埋め込みで動作します。エンドツーエンドの自然なダイアリゼーション（eend）は、重複した音声を処理するために開発されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Improving pronunciation assessment via ordinal regression with anchored
  reference samples -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.AS/paper_7.html">
      <font color="black">Improving pronunciation assessment via ordinal regression with anchored
  reference samples</font>
    </a>
  </h2>
  <font color="black">パフォーマンスは、人間のパリティレベルまたは人間の評価者よりも優れています。この論文では、2つの新しい統計的特徴、平均GOP（aGOP）と混乱GOP（cGOP）を提案し、それらを使用して、順序回帰でバイナリ分類器をトレーニングします。アンカー参照サンプル（ORARS）。提案されたアプローチをMicrosoft mTutor ESLデータセットでテストすると、従来のGOPベースのアプローチよりも26.9％のピアソン相関係数の相対的な改善が得られます。 
[要約]音声発音評価は、発音の良さ（gop）アルゴリズムに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Distributed Node-Specific Block-Diagonal LCMV Beamforming in Wireless
  Acoustic Sensor Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.AS/paper_8.html">
      <font color="black">Distributed Node-Specific Block-Diagonal LCMV Beamforming in Wireless
  Acoustic Sensor Networks</font>
    </a>
  </h2>
  <font color="black">提案されたビームフォーマは、基盤となるネットワークトポロジに制限を課したり、計算の複雑さをスケーリングしたりすることなく、完全に分散可能です。つまり、新しいノードがネットワークに追加されても、ノードごとの複雑さは増加しません。最新技術と比較して多くの場合時間再帰的である分散ノード固有のアルゴリズムにより、提案されたビームフォーマーは、LCMVビームフォーマーをフレームごとに最適に正確に解決します。これにより、計算の複雑さがはるかに低くなり、音響伝達関数の推定エラーや音声アクティビティ検出器エラーに対してより堅牢になります。そのため、交換された信号はノード間でより低い次元で計算でき、各ノードがすべての生のセンサー信号観測を送信するかのように、各ノードで最適なLCMVビームフォーマーを引き続き使用できます。 
[概要]提案されたビームフォーマーは、ネットワークの対角線に制限なしで配布可能です。新しいノードがネットワークに追加されても、ノードごとの複雑さは増加しません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Emotion controllable speech synthesis using emotion-unlabeled dataset
  with the assistance of cross-domain speech emotion recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.AS/paper_9.html">
      <font color="black">Emotion controllable speech synthesis using emotion-unlabeled dataset
  with the assistance of cross-domain speech emotion recognition</font>
    </a>
  </h2>
  <font color="black">次に、訓練されたSERモデルによって予測されたTTSデータセットの感情ラベルを使用して、補助SERタスクを構築し、TTSモデルと共同で訓練します。実験結果は、提案された方法が、指定された感情表現力を備えた音声を生成できることを示しています。具体的には、提案手法は、クロスドメイン音声感情認識（SER）モデルと感情的TTSモデルで構成されています。 
[ABSTRACT]感情的なtts合成の新しいアプローチが、感情ラベルのないデータセットで提案されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: TTS-by-TTS: TTS-driven Data Augmentation for Fast and High-Quality
  Speech Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.AS/paper_10.html">
      <font color="black">TTS-by-TTS: TTS-driven Data Augmentation for Fast and High-Quality
  Speech Synthesis</font>
    </a>
  </h2>
  <font color="black">特に、5時間のトレーニングデータベースを179時間の合成データベースに拡張しました。この方法では、音素持続時間のテキスト波形ペアを含む大規模な合成コーパスがAR TTSシステムによって生成され、トレーニングに使用されます。ターゲットの非ARモデル..FastSpeech2などの最近提案された非ARモデルは、高速音声合成システムの実現に成功しました。 
[ABSTRACT] fastspeech 2などの新しい非arモデルは、高速音声合成システムの実現に成功しました。ただし、適切に設計されたarttsシステムを使用した効果的なデータ拡張方法を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Melody Harmonization Using Orderless NADE, Chord Balancing, and Blocked
  Gibbs Sampling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.AS/paper_11.html">
      <font color="black">Melody Harmonization Using Orderless NADE, Chord Balancing, and Blocked
  Gibbs Sampling</font>
    </a>
  </h2>
  <font color="black">実験は、18,005のメロディ/コードペアのデータセットで実施されました。提案されたモデルは、コード/メロディの調和性とコード進行に基づく6つの異なる客観的指標のうち5つで、最先端のシステムMTHarmonizerよりも優れています。クラスの重み付けは、トレーニングセットではめったに見られないいくつかの合理的なコードラベルを補正するために使用されます。 
[概要]この研究では、メロディとその部分的にマスクされたコードシーケンスをbilstmベースのネットワークの入力として使用して、マスクされたグラウンドトゥルースを学習する、順序のないnadeの概念を適用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Sound Event Detection Metrics: Insights from DCASE 2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.AS/paper_12.html">
      <font color="black">Improving Sound Event Detection Metrics: Insights from DCASE 2020</font>
    </a>
  </h2>
  <font color="black">さらに、PSDSは、システムの動作点とは無関係にサウンドイベントモデリングパフォーマンスを測定することにより、SEDシステムの比較を強化します。あるいは、PSDSの交差ベースの基準は、サウンドイベント期間への評価の依存性を克服し、主観性のラベル付けに堅牢性を提供します。中断されたイベントの有効な検出..これは、カラーに依存することにより、従来のイベントベースの基準がサウンドイベントの長さに応じて異なる厳密レベルを導入し、セグメントベースの基準が精度に欠け、アプリケーションに依存する可能性があることを示しています。 
[概要]ポリフォニックサウンド検出スコア（psds）は、dcase2020チャレンジタスク4から選択したシステムに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Sequential Skip Prediction with Few-shot in Streamed Music Contents -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.AS/paper_13.html">
      <font color="black">Sequential Skip Prediction with Few-shot in Streamed Music Contents</font>
    </a>
  </h2>
  <font color="black">実験結果は、シーケンス学習アプローチがメトリック学習アプローチよりも大幅に優れていることを示しました。メトリック学習とシーケンス学習に基づく2種類のアルゴリズムを提案しました。私たちの目標は、後半の個々のトラックかどうかを予測することです。セッションの一部はスキップされるかどうかにかかわらず、音響機能のみが与えられます。 
[概要]チャレンジでは、リスニングセッションの前半の音響機能とユーザーインタラクションログを含む完全な情報が提供されます。目標は、完全なユーザーログ情報を使用して大幅なパフォーマンスの向上を達成できることを見つけることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-01-24">
        <br><font color="black">2019-01-24</font>
      </time>
    </span>
</section>
<!-- paper0: Contrastive Unsupervised Learning for Audio Fingerprinting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.AS/paper_14.html">
      <font color="black">Contrastive Unsupervised Learning for Audio Fingerprinting</font>
    </a>
  </h2>
  <font color="black">一連の実験により、AFP法が音声識別に効果的であり、困難な速度変化やピッチシフトなどの深刻な音声歪みに対するロバスト性があることが示されました。私たちの作業では、音声トラックとその異なる歪みのバージョンを同様に考慮しながら検討します。異なるオーディオトラックは異なるものとして..対照学習は、類似したサンプルを効果的にグループ化し、異なるサンプルを区別できる表現を学習するための教師なしアプローチです。 
[概要]バックグラウンドオーディオトラックを持つ人々のビデオビデオがリリースされました。これには、慎重に編集されたバックグラウンドオーディオトラックが含まれ、深刻な音声の変化、ピッチシフト、さまざまな種類のオーディオ効果が含まれる可能性があります。この方法は、教師なし学習アプローチです。サンプルを効果的にグループ化し、異なるサンプルを区別できる表現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Decentralizing Feature Extraction with Quantum Convolutional Neural
  Network for Automatic Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.AS/paper_15.html">
      <font color="black">Decentralizing Feature Extraction with Quantum Convolutional Neural
  Network for Automatic Speech Recognition</font>
    </a>
  </h2>
  <font color="black">提案された分散型フレームワークは、量子学習の進歩を利用してモデルを保護し、プライバシー漏洩攻撃を回避します。分散型アーキテクチャでモデルパラメータ保護を強化するために、入力音声は最初に量子コンピューティングサーバーにアップストリームされてMelスペクトルを抽出します。 、および対応する畳み込み特徴は、ランダムパラメータを使用した量子回路アルゴリズムを使用してエンコードされます。また、QCNNベースの特徴抽出器の設計に関する洞察を提供するために、さまざまな量子回路エンコーダアーキテクチャの詳細な調査を実施します。 
[ABSTRACT]量子畳み込みニューラルネットワーク（qcnn）は、量子回路エンコーダーとリカレントニューラルネットワーク上に構築されています。再生機能はダウンストリームされ、最終的な認識のためにローカルrnnモデルにストリーミングされます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Audio Fingerprint for High-specific Audio Retrieval based on
  Contrastive Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-27/eess.AS/paper_16.html">
      <font color="black">Neural Audio Fingerprint for High-specific Audio Retrieval based on
  Contrastive Learning</font>
    </a>
  </h2>
  <font color="black">これらのレプリカは、小さな時間オフセットと、バックグラウンドノイズや部屋/マイクのインパルス応答などのさまざまなタイプの歪みを適用することにより、元のオーディオ信号への劣化効果をシミュレートできます。セグメントレベルの検索タスクでは、従来のオーディオフィンガープリントシステムが失敗した場合、10分の1のストレージを使用するシステムは有望な結果を示しています。コードとデータセットが利用可能になります。 
[概要]この作業では、オーディオの短い単位セグメントから低次元を生成します。このフィンガープリントを使用して、高速の最大内積検索を作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-22">
        <br><font color="black">2020-10-22</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
