<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-10-13の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Dance Revolution: Long-Term Dance Generation with Music via Curriculum
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.SD/paper_0.html">
      <font color="black">Dance Revolution: Long-Term Dance Generation with Music via Curriculum
  Learning</font>
    </a>
  </h2>
  <font color="black">さらに、ロングモーションシーケンス生成における自己回帰モデルのエラー蓄積を軽減するカリキュラム学習戦略を提案します。これにより、トレーニングプロセスが、以前のグラウンドトゥルースムーブメントを使用した完全にガイドされた教師強制スキームから、ほとんどガイドされていない自己回帰スキームに穏やかに変更されます。代わりに生成された動きを使用します。この論文では、音楽駆動型ダンス生成をシーケンス間学習問題として形式化し、新しいseq2seqアーキテクチャを考案して、音楽機能の長いシーケンスを効率的に処理し、間のきめ細かい対応をキャプチャします。音楽とダンス..さらに、スタイル、リズム、ビートに関するダンスと音楽の一貫性は、モデリング時にまだ考慮されていません。 
[ABSTRACT]ダンスと音楽は機械学習アーキテクチャの問題です。ただし、これはニューラルネットワークにフィードバックされる予測エラーが豊富なためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br><font color="black">2020-06-11</font>
      </time>
    </span>
</section>
<!-- paper0: Pay Attention to the cough: Early Diagnosis of COVID-19 using
  Interpretable Symptoms Embeddings with Cough Sound Signal Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.SD/paper_1.html">
      <font color="black">Pay Attention to the cough: Early Diagnosis of COVID-19 using
  Interpretable Symptoms Embeddings with Cough Sound Signal Processing</font>
    </a>
  </h2>
  <font color="black">実験の結果は、モデルがCOVID-19患者の咳と、95.04 $ \ pm $ 0.18％および96.83 $ \ pmのより高い特異性と精度で、いくつかのタイプの非COVID-19咳を区別するためのより優れた堅牢な機能の埋め込みをキャプチャすることを示しています。解釈可能性を維持しながら、それぞれ0.18％ドル。提案されたフレームワークのパフォーマンスは、30000のオーディオセグメントの症状と人口統計データ、4つの咳クラス（COVID-19、喘息、気管支炎）の150人の患者からの328の咳音を含む医療データセットを使用して評価されました。 、そして健康的）。COVID-19の現在の診断は、逆転写ポリマー連鎖反応（RT-PCR）テストによって行われます。 
[概要]提案されたフレームワークのパフォーマンスは、医療データセットを使用して評価されました。4つの咳クラスを持つ150人の患者からの328の咳音</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: The role of context in neural pitch accent detection in English -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.SD/paper_2.html">
      <font color="black">The role of context in neural pitch accent detection in English</font>
    </a>
  </h2>
  <font color="black">また、すべての内容語の高低アクセントを予測するだけの単純なベースラインでは82.2％の精度が得られることがわかり、これがこのタスクの適切なベースラインであることがわかります。これらの革新により、87.5％から88.7に改善されることがわかりました。ボストン大学ラジオニュースコーパスでのアメリカ英語音声の高低アクセント検出の％精度、最先端の結果。私たちのモデルは、入力として完全な発話を使用し、LSTMレイヤーを追加することにより、コンテキストをより活用します。 
[概要]音声の韻律イベントを検出する方法が必要です。これらの革新により、87.5％から88％の改善が見られます。7％。ピッチがこのタスクの最も重要な音響機能であることを示すアブレーションテストを実施します。コーパス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Miniscope3D: optimized single-shot miniature 3D fluorescence microscopy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/eess.IV/paper_0.html">
      <font color="black">Miniscope3D: optimized single-shot miniature 3D fluorescence microscopy</font>
    </a>
  </h2>
  <font color="black">位相マスクは、3D蛍光強度を単一の2D測定にエンコードし、スパース性に制約のある逆問題を解くことによって3Dボリュームを復元します。高さ17 mm、重さ2.5グラムのプロトタイプを示し、2.76 $ \ mu $を達成します。横方向にm、900x700x390 $ \ mu m ^ 3 $ボリュームの大部分で15 $ \ mu $ m軸方向の解像度、毎秒40ボリューム。当社の顕微鏡設計は、コンパクトなプラットフォームが重要なアプリケーションにシングルショット3Dイメージングを提供します。自由に動く動物の体積神経イメージング、およびインキュベーターとラボオンチップデバイスの動的サンプルの3Dモーション研究として。 
[概要]広視野ミニチュア顕微鏡は2D情報のみをキャプチャし、3D機能を有効にする変更により、サイズと重量が増加し、狭い深度範囲外では解像度が低下します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: Ensemble Hyperspectral Band Selection for Detecting Nitrogen Status in
  Grape Leaves -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/eess.IV/paper_1.html">
      <font color="black">Ensemble Hyperspectral Band Selection for Detecting Nitrogen Status in
  Grape Leaves</font>
    </a>
  </h2>
  <font color="black">提案されたパイプラインは、農業以外のドメインでのアプリケーション固有のマルチスペクトルセンサー設計にも使用できます。パイプラインは、ブドウの窒素状態について最も有益なバンドの0.45％未満を識別しました。この研究は、スペクトルの最適なセットを識別することを目的としました。 150のFlameSeedlessテーブルブドウからの3,000を超える葉からのハイパースペクトルデータのアンサンブル機能選択を使用したブドウの葉の窒素検出のバンド。 
[概要]ハイパースペクトルデータは通常、青、緑、赤、赤のエッジ、およびニアスペクトルバンドに制限されています。これらのデータはブドウの窒素を検出するために使用されます。リモートスペクトルデータの潜在的な改善は有望であり、さらに調査する価値があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Early Exit or Not: Resource-Efficient Blind Quality Enhancement for
  Compressed Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/eess.IV/paper_2.html">
      <font color="black">Early Exit or Not: Resource-Efficient Blind Quality Enhancement for
  Compressed Images</font>
    </a>
  </h2>
  <font color="black">具体的には、私たちのアプローチは、早期出口戦略が組み込まれている動的ディープニューラルネットワーク（DNN）を介して、圧縮された画像の品質を盲目的かつ漸進的に向上させます。強化された画像の品質..その結果、わずかなアーティファクトをより簡単で高速なプロセスで削除でき、深刻なアーティファクトをより複雑なプロセスでさらに削除できます。 
[概要]この論文では、リソース効率の高いブラインド品質強化（rbqe）モデルを提案します。具体的には、私たちのアプローチは、強化された画像の評価された品質に応じて、強化を終了するか継続するかを自動的に決定できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br><font color="black">2020-06-30</font>
      </time>
    </span>
</section>
<!-- paper0: Local Facial Attribute Transfer through Inpainting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/eess.IV/paper_3.html">
      <font color="black">Local Facial Attribute Transfer through Inpainting</font>
    </a>
  </h2>
  <font color="black">口ひげを取り除く）..画像の一部のみを削除して再生成する、属性転送インペインティング生成的敵対的ネットワーク（ATI-GAN）は、ローカルコンテキスト情報を利用して、背景を変更せずに属性に焦点を合わせ、視覚的に健全な結果をもたらすことができます。新しい（グローバル）画像を生成することによってそのようなローカル変更が実装されていた以前の方法とは対照的に、我々はローカル属性転送を修復問題として定式化することを提案します。 
[ABSTRACT]新しい論文では、ローカル属性転送を定式化することを提案します。代わりに、意味の変更を実現するために顔の一部のみを変更する必要があります。これには、髪の色の変更など、顔の特徴や表情の変更が含まれます。笑顔を追加</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-07">
        <br><font color="black">2020-02-07</font>
      </time>
    </span>
</section>
<!-- paper0: Deep learning for photoacoustic imaging: a survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/eess.IV/paper_4.html">
      <font color="black">Deep learning for photoacoustic imaging: a survey</font>
    </a>
  </h2>
  <font color="black">ディープニューラルネットワークは、医用画像技術、医療データ分析、医療診断、その他の医療問題において大きな可能性を秘めており、前臨床段階と臨床段階の両方で推進されています。画像分析から自然言語処理に至るまで、その魔法を十分に発揮しました。そして今、最先端の機械学習モデルになります。機械学習は劇的に開発され、過去数年にわたってさまざまな分野で多くのアプリケーションを目撃しました。 
[概要]深い人工ニューラルネットワークは、最先端の機械学習モデルになりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: A Self-ensembling Framework for Semi-supervised Knee Cartilage Defects
  Assessment with Dual-Consistency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/eess.IV/paper_5.html">
      <font color="black">A Self-ensembling Framework for Semi-supervised Knee Cartilage Defects
  Assessment with Dual-Consistency</font>
    </a>
  </h2>
  <font color="black">正確な注意マスクを得るために、新しい注意損失関数が開発されました。特に、同じ構造の学生ネットワークと教師ネットワークで構成される自己アンサンブルフレームワークを設計します。学生ネットワークは、ラベル付けされたデータとラベルのないデータと教師ネットワークは、トレーニングコースを通じて学生モデルの重みを平均します。 
[概要]この論文は、膝軟骨欠損評価のための新しいアプローチを提案します。これらには、重症度分類と病変の局在化が含まれます。これらには、同じ構造の学生ネットワークと教師ネットワークが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-19">
        <br><font color="black">2020-05-19</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Sea Robotic Imaging Simulator -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/eess.IV/paper_6.html">
      <font color="black">Deep Sea Robotic Imaging Simulator</font>
    </a>
  </h2>
  <font color="black">浅瀬の状態とは異なり、人工照明はシーンの外観に強く影響するため、深海の画像形成に重要な役割を果たします。現在、水中ビジョンシステムは海洋研究に広く適用されています。深海の画像の不足とそれに対応するグラウンドトゥルース評価とトレーニングのためのデータは、水中コンピュータビジョン手法の開発のボトルネックになりつつあります。 【概要】深海の画像は浅瀬で撮影した画像とは大きく異なります。この地域はコミュニティからあまり注目されていませんでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-27">
        <br><font color="black">2020-06-27</font>
      </time>
    </span>
</section>
<!-- paper0: FeatureNMS: Non-Maximum Suppression by Learning Feature Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/eess.IV/paper_7.html">
      <font color="black">FeatureNMS: Non-Maximum Suppression by Learning Feature Embeddings</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、従来のNMSおよび派生アプローチよりも優れており、最先端のパフォーマンスを実現します。これらの特徴ベクトルは、視覚的外観などのより多くの情報をエンコードできます。FeatureNMSは、境界ボックス間の結合の交差に基づいてだけでなく、特徴ベクトルの違い。 
[要約]重複は、非最大抑制と呼ばれる後処理ステップで削除されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br><font color="black">2020-02-18</font>
      </time>
    </span>
</section>
<!-- paper0: MADGAN: unsupervised Medical Anomaly Detection GAN using multiple
  adjacent brain MRI slice reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/eess.IV/paper_8.html">
      <font color="black">MADGAN: unsupervised Medical Anomaly Detection GAN using multiple
  adjacent brain MRI slice reconstruction</font>
    </a>
  </h2>
  <font color="black">したがって、教師なし医療異常検出生成的敵対的ネットワーク（MADGAN）を提案します。これは、GANベースの複数隣接脳MRIスライス再構成を使用して、マルチシーケンス構造MRIのさまざまな段階で脳異常を検出する新しい2段階の方法です。（再構成）ワッサースタイン損失勾配ペナルティ+ 100L1損失-次の3つのスライスを再構築するために3つの健康な脳軸MRIスライスでトレーニング-目に見えない健康/異常スキャンを再構築します。 （診断）スキャンごとの平均L2損失は、グラウンドトゥルース/再構成されたスライスを比較してそれらを識別します。私たちの自己注意MADGANは、非常に早い段階でT1スキャンのADを検出できます。軽度認知障害（MCI）、曲線下面積（ AUC）0.727、およびAUC 0.894で後期のAD、AUC 0.921でT1cスキャンで脳転移を検出します。ただし、複数の隣接するスライス間の連続性を考慮しないと、微妙な解剖学的異常の蓄積で構成される疾患を直接区別することはできません。アルツハイマー病（AD）など。 
[ABSTRACT]教師なし手法では、3Dスキャンを使用して外れ値を検出します。教師なし異常検出は、病期、さまざまな疾患、またはマルチシーケンス磁気共鳴画像法（mri）スキャンなどの疾患に関連しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-24">
        <br><font color="black">2020-07-24</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Facial Pose Estimation by Deep Learning from Label Distributions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_0.html">
      <font color="black">Facial Pose Estimation by Deep Learning from Label Distributions</font>
    </a>
  </h2>
  <font color="black">AFLW2000、BIWI、AFLW、AFWなど、いくつかの一般的なベンチマークで広範な実験が行われ、私たちのアプローチは他の最先端の方法よりも大きな利点を示しています。顔のポーズ推定は、多くの実用的なアプリケーションで多くの注目を集めています。 、人間とロボットの相互作用、視線推定、ドライバーの監視など。ただし、顔のポーズ推定には、多くのポーズ、特に大きなポーズの十分なトレーニングデータがないという重要な課題があります。 
[ABSTRACT]顔のポーズの推定は、ラベル分布の学習問題です。新しい手法により、人々は自分の顔のポーズを研究できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-30">
        <br><font color="black">2019-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: Activation Density driven Energy-Efficient Pruning in Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_1.html">
      <font color="black">Activation Density driven Energy-Efficient Pruning in Training</font>
    </a>
  </h2>
  <font color="black">トレーニング中に定期的にネットワークサイズを縮小することで、以前に提案されたプルーニング方法よりも短い合計トレーニング時間を実現します。CIFAR-10、CIFAR-100、およびTinyImageNet上のVGG-19およびResNet18の場合、非常にスパースなネットワークが得られます（ベースラインネットワークに匹敵する精度で、パラメータが最大$ 200 \ times $削減され、推論計算操作が最大$ 60 \ times $削減されます。この方法はアーキテクチャに依存しないため、さまざまな種類のネットワークで使用できます。システム。 
[概要]一般的なプルーニング方法では、開始点として十分にトレーニングされた大規模なネットワークが必要です。元の精度を取り戻すために、時間のかかる反復的なプルーニングと再トレーニングの手順を実行します。提案された方法では、トレーニングの計算の複雑さが軽減されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-07">
        <br><font color="black">2020-02-07</font>
      </time>
    </span>
</section>
<!-- paper0: Theory-Inspired Path-Regularized Differential Network Architecture
  Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_2.html">
      <font color="black">Theory-Inspired Path-Regularized Differential Network Architecture
  Search</font>
    </a>
  </h2>
  <font color="black">次に、2つの主要モジュールで構成される理論に着想を得たパス正則化DARTSを提案します。（i）操作間の不正競争を回避するために各操作に導入された差分グループ構造のスパースバイナリゲート、および（ii）パスの深さ正則化は、理論に示されているように浅いアーキテクチャよりも収束が遅く、検索中に十分に探索されない深いアーキテクチャの検索探索を促すために使用されます。この結果は、初めて、高速へのスキップ接続の影響を理論的かつ明示的に明らかにします。ネットワークの最適化と、DARTSの他のタイプの操作に対するその競争上の利点。スキップ接続が多いアーキテクチャは、他の候補よりも速く収束できるため、DARTSによって選択されます。 
[ABSTRACT]理論スキップ接続を使用してネットワークロービングを高速化できます。これは初めてであり、スキップ深度の影響を明らかにする可能性があります。また、ダーツの他のタイプの操作に対する競争上の優位性も明らかにします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br><font color="black">2020-06-30</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Invariant Representations and Risks for Semi-supervised Domain
  Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_3.html">
      <font color="black">Learning Invariant Representations and Risks for Semi-supervised Domain
  Adaptation</font>
    </a>
  </h2>
  <font color="black">上記の観察に触発されて、本論文では、半教師ありドメイン適応（Semi-DA）の設定の下で不変表現とリスクを同時に学習することを目的とした最初の方法を提案します。しかし、最近の研究では、これでは不十分であることが示されています。ターゲットドメインでの適切な一般化を保証するため、そして実際には、ラベル配布シフトの下で明らかに有害です。さらに、多くの実際のアプリケーションでは、ターゲットドメインから少量のラベル付きデータを取得し、それらを使用してソースデータを使用してモデルのトレーニングを容易にします。 
[概要]教師なしドメイン適応のほとんどの既存の方法は、ターゲットの達成に焦点を当てています-レスポンシブ表現と小さなソースドメインエラー。最近の研究では、lirrは、アシュトンアシュトンアシュトンをほとんど学習しない方法と比較して、シフトパフォーマンスと大幅な改善を一貫して達成していることが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-09">
        <br><font color="black">2020-10-09</font>
      </time>
    </span>
</section>
<!-- paper0: Ensemble Hyperspectral Band Selection for Detecting Nitrogen Status in
  Grape Leaves -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_4.html">
      <font color="black">Ensemble Hyperspectral Band Selection for Detecting Nitrogen Status in
  Grape Leaves</font>
    </a>
  </h2>
  <font color="black">パイプラインは、ブドウの窒素状態について最も有益なバンドの0.45％未満を識別しました。提案されたパイプラインは、農業以外のドメインでのアプリケーション固有のマルチスペクトルセンサー設計にも使用できます。この研究は、スペクトルの最適なセットを識別することを目的としました。 150のFlameSeedlessテーブルブドウからの3,000を超える葉からのハイパースペクトルデータのアンサンブル機能選択を使用したブドウの葉の窒素検出のバンド。 
[概要]ハイパースペクトルデータは通常、青、緑、赤、赤のエッジ、およびニアスペクトルバンドに制限されています。これらのデータはブドウの窒素を検出するために使用されます。リモートスペクトルデータの潜在的な改善は有望であり、さらに調査する価値があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Continual Prototype Evolution: Learning Online from Non-Stationary Data
  Streams -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_5.html">
      <font color="black">Continual Prototype Evolution: Learning Online from Non-Stationary Data
  Streams</font>
    </a>
  </h2>
  <font color="black">継続的な学習の主要な作業とは対照的に、データストリームは追加のタスク情報なしでオンラインで処理され、効率的なメモリスキームは、不均衡なデータストリームに対する堅牢性を提供します。最近傍ベースの予測に加えて、学習はクラスプロトタイプに関するクラスター密度とクラス間分散の増加を促進する新しい目的関数。さらに、潜在空間の品質は、メモリからのエグザンプラの再生によって構成される各バッチの疑似プロトタイプによって高められます。 
[ABSTRACT]プロトタイプが共有潜在空間で継続的に進化し、任意の時点での学習と予測を可能にする、両方の問題に対処するシステム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: An Efficient Data Retrieval Parallel Reeb Graph Algorithm -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_6.html">
      <font color="black">An Efficient Data Retrieval Parallel Reeb Graph Algorithm</font>
    </a>
  </h2>
  <font color="black">標準データセットでのアルゴリズムの実行時間を示します。Reebグラフは、過去10年間で、幾何学的処理、画像処理、コンピューターグラフィックス、および計算論的トポロジーにおいて非常に重要であることが示されています。定義されたスカラー関数のReebグラフドメイン上では、そのドメインのトポロジ的に意味のある要約が表示されます。 
[ABSTRACT]レーブグラフは過去10年間で非常に重要であることが示されています。たとえば、レーブグラフ構造から元の多様体データを抽出する方法について説明します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-10-18">
        <br><font color="black">2018-10-18</font>
      </time>
    </span>
</section>
<!-- paper0: Early Exit or Not: Resource-Efficient Blind Quality Enhancement for
  Compressed Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_7.html">
      <font color="black">Early Exit or Not: Resource-Efficient Blind Quality Enhancement for
  Compressed Images</font>
    </a>
  </h2>
  <font color="black">具体的には、私たちのアプローチは、早期出口戦略が組み込まれている動的ディープニューラルネットワーク（DNN）を介して、圧縮画像の品質を盲目的かつ段階的に向上させます。さらに、圧縮画像の品質が不明であることが実際には一般的です。ブラインド品質向上に適したモデルを選択するための既存のアプローチでは扱いにくいです。コードはhttps://github.com/RyanXingQL/RBQEで入手できます。 
[概要]この論文では、リソース効率の高いブラインド品質強化（rbqe）モデルを提案します。具体的には、私たちのアプローチは、強化された画像の評価された品質に応じて、強化を終了するか継続するかを自動的に決定できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br><font color="black">2020-06-30</font>
      </time>
    </span>
</section>
<!-- paper0: Local Facial Attribute Transfer through Inpainting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_8.html">
      <font color="black">Local Facial Attribute Transfer through Inpainting</font>
    </a>
  </h2>
  <font color="black">口ひげの除去）。この論文では、セマンティックな変更を実現するために顔の一部のみを変更する必要がある、ローカル属性転送の一般的なサブタスクの新しい方法を示します（例：一部のみの削除と再生成）画像の場合、属性転送インペインティング敵対的生成ネットワーク（ATI-GAN）は、ローカルコンテキスト情報を利用して、背景を変更せずに属性に焦点を合わせ、視覚的に健全な結果を得ることができます。
[要約]新しい論文で、ローカル属性の転送。代わりに、セマンティックの変更を実現するために顔の一部のみを変更する必要があります。これには、髪の色の変更や笑顔の追加など、顔の特徴や表情の変更が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-07">
        <br><font color="black">2020-02-07</font>
      </time>
    </span>
</section>
<!-- paper0: Neural gradients are near-lognormal: improved quantized and sparse
  training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_9.html">
      <font color="black">Neural gradients are near-lognormal: improved quantized and sparse
  training</font>
    </a>
  </h2>
  <font color="black">リファレンス実装はこのペーパーに付属しています。私たちの知る限り、このペーパーは、（1）勾配を6ビット浮動小数点形式に量子化する、または（2）最大85％の勾配スパース性を実現する最初の論文です。精度の低下がない場合..各メソッドは、ImageNetで最先端の結果を実現します。 
[概要]神経勾配の認知および記憶の負担を軽減するための2つの閉じた形式の分析方法。最初の方法は人間の剪定のスパース性しきい値を正確に設定します。2番目の方法は剪定のスパース性しきい値を正確に設定します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Keyword Extraction for Full-sentence VQA -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_10.html">
      <font color="black">Unsupervised Keyword Extraction for Full-sentence VQA</font>
    </a>
  </h2>
  <font color="black">識別デコーダーは、このような分解を実現するように設計されており、このメソッドは、全文の回答を含むVQAデータセットに実験的に実装されました。既存の視覚的質問応答（VQA）調査の大部分では、回答は短い、多くの場合1つの単語で構成されています。データセットの構築中にアノテーターに与えられた指示に従って..結果は、提案されたモデルが、キーワードを説明する明示的な注釈を与えられることなく、キーワードを正確に抽出できることを示しています。 
[概要]提案されたモデルは、全文の回答を2つの主要部分に分解できるという原則に基づいています。新しいモデルは、明示的な注釈を付けなくてもキーワードを正確に抽出できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-23">
        <br><font color="black">2019-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Deep learning for photoacoustic imaging: a survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_11.html">
      <font color="black">Deep learning for photoacoustic imaging: a survey</font>
    </a>
  </h2>
  <font color="black">ディープニューラルネットワークは、医用画像技術、医療データ分析、医療診断、その他の医療問題において大きな可能性を秘めており、前臨床段階と臨床段階の両方で推進されています。このレビューでは、いくつかの新しい開発と課題の概要を説明しました。医療画像分析への機械学習の応用において、特に光音響イメージングの深層学習に焦点を当てています。画像分析から自然言語処理に至るまで、それはその魔法を十分に発揮し、現在では最先端の機械学習になっています。モデル。 
[概要]深い人工ニューラルネットワークは、最先端の機械学習モデルになりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Cell Complex Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_12.html">
      <font color="black">Cell Complex Neural Networks</font>
    </a>
  </h2>
  <font color="black">さらに、セルラー間メッセージパッシングスキーム、基礎となる空間のトポロジーを考慮に入れたセルコンプレックスでのメッセージパッシングスキームを紹介します。セルコンプレックスでニューラルネットワークタイプの計算を実行するための一般的な組み合わせの統合構造を提案します。特に、私たちの方法は、最も一般的なタイプのグラフニューラルネットワークの多くを一般化します。 
[概要]実用的なアプリケーションにとって重要なドメインを形成する複体を一般化する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-02">
        <br><font color="black">2020-10-02</font>
      </time>
    </span>
</section>
<!-- paper0: Weaponizing Unicodes with Deep Learning -- Identifying Homoglyphs with
  Weakly Labeled Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_13.html">
      <font color="black">Weaponizing Unicodes with Deep Learning -- Identifying Homoglyphs with
  Weakly Labeled Data</font>
    </a>
  </h2>
  <font color="black">私たちのモデルは、ペアワイズホモグリフ識別の正規化圧縮距離アプローチを大幅に上回り、平均精度0.97を達成しています。また、ホモグリフを同等クラスのセットにクラスター化する最初の試みを示します。これは、セキュリティ担当者向けのペアワイズ情報よりも効率的です。ホモグリフをすばやく検索したり、紛らわしい文字列エンコーディングを正規化したりするには..ソースコードと予測されたホモグリフのリストがGithubにアップロードされます：https：//github.com/PerryXDeng/weaponizing_unicode 
[ABSTRACT]攻撃者が特定する能力を理解することが重要ですホモグリフ-特に以前に発見されていないもの-。私たちのアプローチは、ほとんどの文字がホモグリフではないという事実から生じる弱いラベルを独自に利用しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-09">
        <br><font color="black">2020-10-09</font>
      </time>
    </span>
</section>
<!-- paper0: Overfit Neural Networks as a Compact Shape Representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_14.html">
      <font color="black">Overfit Neural Networks as a Compact Shape Representation</font>
    </a>
  </h2>
  <font color="black">このようなオーバーフィットネットワークをNeuralImplicitsと呼びます。通常のグリッドに格納されたSDFと同様に、Neural Implicitsは固定のストレージプロファイルとメモリレイアウトを備えていますが、はるかに高い精度を提供します。これは、新しい損失関数、サンプリング戦略、および堅牢な形状の過剰適合を促進するように設計された監視プロトコル。 
[ABSTRACT]たとえば、代わりに、コンパクトとしての適合性を調査します-意図的にオーバーフィットする場合-個々の形状のsdf表現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: FCOS: A simple and strong anchor-free object detector -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_15.html">
      <font color="black">FCOS: A simple and strong anchor-free object detector</font>
    </a>
  </h2>
  <font color="black">提案されたFCOSフレームワークが、他の多くのインスタンスレベルのタスクのシンプルで強力な代替手段として役立つことを願っています。対照的に、提案された検出器FCOSは、アンカーボックスがなく、提案もありません。さらに重要なことに、すべてを回避します。アンカーボックスに関連するハイパーパラメータ。多くの場合、最終的な検出パフォーマンスに敏感です。 
[概要] 1段階の方法は、そのシンプルな設計と競争力のあるパフォーマンスにより、2段階のアプローチよりも多くの注目を集めています。ほとんどすべての最先端のオブジェクト検出器（網膜、ssd、yolov3、高速r-cnnなど）はpreに依存しています-定義されたアンカーボックス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-14">
        <br><font color="black">2020-06-14</font>
      </time>
    </span>
</section>
<!-- paper0: Dance Revolution: Long-Term Dance Generation with Music via Curriculum
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_16.html">
      <font color="black">Dance Revolution: Long-Term Dance Generation with Music via Curriculum
  Learning</font>
    </a>
  </h2>
  <font color="black">広範な実験は、私たちのアプローチが自動メトリックと人間の評価に関する既存の方法を大幅に上回っていることを示しています。さらに、ロングモーションシーケンス生成における自己回帰モデルのエラー蓄積を軽減するカリキュラム学習戦略を提案します。これにより、トレーニングプロセスが完全ガイドから穏やかに変更されます。以前のグラウンドトゥルースムーブメントを使用した教師強制スキーム、代わりに生成されたムーブメントを主に使用するガイドの少ない自己回帰スキームに向けて..この論文では、音楽駆動型ダンス生成をシーケンス間の学習問題として形式化し、長いシーケンスの音楽機能を効率的に処理し、音楽とダンスの間のきめ細かい対応をキャプチャするための新しいseq2seqアーキテクチャ。 
[ABSTRACT]ダンスと音楽は機械学習アーキテクチャの問題です。ただし、これはニューラルネットワークにフィードバックされる予測エラーが豊富なためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br><font color="black">2020-06-11</font>
      </time>
    </span>
</section>
<!-- paper0: A Self-ensembling Framework for Semi-supervised Knee Cartilage Defects
  Assessment with Dual-Consistency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_17.html">
      <font color="black">A Self-ensembling Framework for Semi-supervised Knee Cartilage Defects
  Assessment with Dual-Consistency</font>
    </a>
  </h2>
  <font color="black">この論文では、重症度分類や病変の位置特定など、膝軟骨欠損評価の新しいアプローチを提案します。学生ネットワークはラベル付きデータとラベルなしデータの両方から学習し、教師ネットワークはトレーニングコースを通じて学生モデルの重みを平均します。正確なアテンションマスクを得るために、新しいアテンションロス関数が開発されました。 
[概要]この論文は、膝軟骨欠損評価のための新しいアプローチを提案します。これらには、重症度分類と病変の局在化が含まれます。これらには、同じ構造の学生ネットワークと教師ネットワークが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-19">
        <br><font color="black">2020-05-19</font>
      </time>
    </span>
</section>
<!-- paper0: Augmented Cyclic Consistency Regularization for Unpaired Image-to-Image
  Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_18.html">
      <font color="black">Augmented Cyclic Consistency Regularization for Unpaired Image-to-Image
  Translation</font>
    </a>
  </h2>
  <font color="black">元の画像と摂動された画像のペアが供給されたときに同様の予測を出力するように弁別器を正則化します。私たちの主なアイデアは、実際のサンプル、偽のサンプル、再構築されたサンプル、および拡張されたサンプルを活用する半教師あり学習に由来する一貫性の正則化を実施することです。偽のサンプルと再構成されたサンプルの整合性正則化がうまく機能する理由。 
[概要]ペアになっていないi2isモデルは、リアルな画像を生成できないことがよくあります。ただし、明示的な監視がないため、ペアになっていないi2iモデルはリアルな画像を作成できません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-29">
        <br><font color="black">2020-02-29</font>
      </time>
    </span>
</section>
<!-- paper0: AdamP: Slowing Down the Slowdown for Momentum Optimizers on
  Scale-invariant Weights -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_19.html">
      <font color="black">AdamP: Slowing Down the Slowdown for Momentum Optimizers on
  Scale-invariant Weights</font>
    </a>
  </h2>
  <font color="black">ウィキテキスト）と音声分類（例：これは重大な問題です。なぜなら、現代のディープニューラルネットワークの大部分は（1）運動量ベースのGDで構成されているためです（例：ただし、GDに運動量が追加されていることは見過ごされがちです。オプティマイザーは、スケール不変の重みの有効なステップサイズをはるかに急速に縮小します。これは、まだ研究されておらず、現在の慣行で望ましくない副作用を引き起こしている可能性がある現象です。
[要約] gdオプティマイザーの勢いにより、スケールの有効なステップサイズがはるかに急速に減少します-応答性のある重み</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
</section>
<!-- paper0: Orientation-aware Vehicle Re-identification with Semantics-guided Part
  Attention Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_20.html">
      <font color="black">Orientation-aware Vehicle Re-identification with Semantics-guided Part
  Attention Network</font>
    </a>
  </h2>
  <font color="black">いくつかの研究は、車両の再IDを支援するために空間的注意メカニズムを組み込んでいますが、高価なキーポイントラベルが必要な場合や、高価なラベルでトレーニングされていない場合はノイズの多い注意マスクに悩まされることがよくあります。車両の再識別（re-ID）は、異なるカメラ間で同じ車両..広範な実験により、提案された方法の有効性が検証され、私たちのフレームワークが最先端のアプローチよりも優れていることが示されています。 
[ABSTRACT]パーツアテンションネットワーク（スパン）は、トレーニング中に画像レベルのセマンティックラベルのみが与えられた場合、車両のさまざまなビューのパーツアテンションマスクを予測できます。パーツパーツ識別（cpdm）は、の特徴距離を評価するときに、共起車両パーツに重点を置きます。 2つの画像</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-26">
        <br><font color="black">2020-08-26</font>
      </time>
    </span>
</section>
<!-- paper0: Unpaired Image-to-Image Translation using Adversarial Consistency Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_21.html">
      <font color="black">Unpaired Image-to-Image Translation using Adversarial Consistency Loss</font>
    </a>
  </h2>
  <font color="black">この損失は、変換された画像を特定のソース画像に変換して戻す必要はありませんが、変換された画像がソース画像の重要な機能を保持し、上記のサイクル整合性損失の欠点を克服するように促すことができます。画像変換は、対になっていないトレーニングデータを使用して異なる画像ドメイン間のマッピングを見つけることを目的とする視覚問題のクラスです。私たちの方法は、ガラスの取り外し、男性から女性への変換という3つの困難なタスクで最先端の結果を達成します。 、およびselfieからanimeへの翻訳。 
[概要]この方法は、画像から画像への変換の新しいレベルの「一貫性の喪失」に基づいています。これは、ソースがビジョンの状態の達成を達成することに成功したのは初めてです。この方法も成功を収めます。画像と自分撮りを-アニメにマッピングした結果</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-10">
        <br><font color="black">2020-03-10</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Sea Robotic Imaging Simulator -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_22.html">
      <font color="black">Deep Sea Robotic Imaging Simulator</font>
    </a>
  </h2>
  <font color="black">浅海の状態とは異なり、人工照明はシーンの外観に大きな影響を与えるため、深海の画像形成に重要な役割を果たします。深海の画像の不足とそれに対応する評価およびトレーニング用のグラウンドトゥルースデータは、開発のボトルネックになりつつあります。水中コンピュータビジョン手法..コミュニティによる深海ビジョン研究をさらに刺激するために、深海画像コンバータのソースコードを一般に公開します。 【概要】深海の画像は浅瀬で撮影した画像とは大きく異なります。この地域はコミュニティからあまり注目されていませんでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-27">
        <br><font color="black">2020-06-27</font>
      </time>
    </span>
</section>
<!-- paper0: Bounding Boxes Are All We Need: Street View Image Classification via
  Context Encoding of Detected Buildings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_23.html">
      <font color="black">Bounding Boxes Are All We Need: Street View Image Classification via
  Context Encoding of Detected Buildings</font>
    </a>
  </h2>
  <font color="black">さらに、既存のBIC GSV 
[1]に基づいて、19,070のストリートビュー画像と38,857の建物の「BEAUTY」（建物の検出と都市機能ゾーンの描写）という名前の二重ラベル付きデータセットを作成しました
[1]。 「Detector-Encoder-Classifier」フレームワークに基づいて提案されています。「BEAUTY」での実験は、提案されたアプローチが、画像レベルのCNNベースのモデルよりもマクロ精度で12.65％、マクロリコールで12％のパフォーマンス向上を達成することを示しています。 
[ABSTRACT]視覚的特徴のみを使用する分類モデルは、満足のいくパフォーマンスを達成できないことがよくあります。画像全体の視覚的特徴を共通の画像として直接使用する代わりに、畳み込みニューラルネットワーク（cnns）に基づくレベルモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-03">
        <br><font color="black">2020-10-03</font>
      </time>
    </span>
</section>
<!-- paper0: Pose Estimation for Ground Robots: On Manifold Representation,
  Integration, Re-Parameterization, and Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_24.html">
      <font color="black">Pose Estimation for Ground Robots: On Manifold Representation,
  Integration, Re-Parameterization, and Optimization</font>
    </a>
  </h2>
  <font color="black">広範なシミュレーションおよび実世界の実験を実施することにより、提案されたアルゴリズムが、特に複雑な大規模な実世界環境に展開された場合に、ポーズ推定の精度において、競合する最先端のアルゴリズムよりも大幅に優れていることを示します。対照的に、本論文では、地上ロボットのモーションマニホールドをモデル化して利用することにより、6D姿勢推定にホイール走行距離計を利用する新しい方法を提案します。提案されたアルゴリズムモジュールの有効性と適用性を実証するために、それをスライディングに統合します。 -ホイール走行距離計と単眼カメラからの測定値を使用したウィンドウポーズ推定器。 
[ABSTRACT]地上ロボットの場合、車輪走行距離計は、ポーズ推定タスク、特に平面シーンベースの環境でのアプリケーションで広く使用されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-08">
        <br><font color="black">2019-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: Explainable Deep One-Class Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_25.html">
      <font color="black">Explainable Deep One-Class Classification</font>
    </a>
  </h2>
  <font color="black">グラウンドトゥルースアノマリーマップを提供する最近の製造データセットであるMVTec-ADで、FCDDは教師なし設定で新しい最先端技術を設定します。最後に、FCDDの説明を使用して、偽の画像機能に対する深い1クラス分類モデルの脆弱性を示します。画像の透かしなど。FCDDは、競争力のある検出パフォーマンスを実現し、CIFAR-10およびImageNetを使用した一般的な異常検出ベンチマークに関する合理的な説明を提供します。 
[ABSTRACT] fcddは、競争力のある検出パフォーマンスを実現します。一般的な異常検出ベンチマークに関する合理的な説明を提供します。いくつかの離れたマップを使用しても、パフォーマンスが大幅に向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-03">
        <br><font color="black">2020-07-03</font>
      </time>
    </span>
</section>
<!-- paper0: A Sensitivity Analysis Approach for Evaluating a Radar Simulation for
  Virtual Testing of Autonomous Driving Functions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_26.html">
      <font color="black">A Sensitivity Analysis Approach for Evaluating a Radar Simulation for
  Virtual Testing of Autonomous Driving Functions</font>
    </a>
  </h2>
  <font color="black">カメラ、レーダー、LIDARなどの環境認識センサーの現実的なモデルがこのテスト戦略で重要な役割を果たします。特にレーダーは、従来、モデル化が最も難しいセンサーの1つでした。実際のテストドライブの代替として有望ですが、仮想テストは、レーダーシステム全体を詳細にシミュレートし、計算量の多いシミュレーション手法を使用して電磁波の伝搬を概算するため、時間がかかります。 
[ABSTRACT]レーダーはモデル化が最も難しいセンサーの1つです。カメラやレーダーなどのセンサーがこのテスト作業で重要な役割を果たします。システムは現在日本でテストされています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-06">
        <br><font color="black">2020-08-06</font>
      </time>
    </span>
</section>
<!-- paper0: Balanced Meta-Softmax for Long-Tailed Visual Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_27.html">
      <font color="black">Balanced Meta-Softmax for Long-Tailed Visual Recognition</font>
    </a>
  </h2>
  <font color="black">理論的には、マルチクラスSoftmax回帰の一般化限界を導き出し、損失が限界を最小化することを示します。さらに、Balanced Meta-Softmaxを導入し、補完的なMeta Samplerを適用して、最適なクラスサンプルレートを推定し、ロングテール学習をさらに改善します。 。深い分類器は、視覚認識で大きな成功を収めています。 
[概要]このペーパーでは、トレーニングとテストの間のラベル分布のシフトに対応するために、softmaxのエレガントで偏りのない拡張であるバランスソフトマックスを紹介しました。さらに、バランスメタサンプラーを適用して最適なクラスサンプルレートを推定するバランスメタソフトマックスを示します。ロングテール学習をさらに改善する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-21">
        <br><font color="black">2020-07-21</font>
      </time>
    </span>
</section>
<!-- paper0: Interactive Gibson Benchmark: A Benchmark for Interactive Navigation in
  Cluttered Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_28.html">
      <font color="black">Interactive Gibson Benchmark: A Benchmark for Interactive Navigation in
  Cluttered Environments</font>
    </a>
  </h2>
  <font color="black">私たちのベンチマークは、2つの新しい要素で構成されています。1）新しい実験セットアップ、屋内シーンの忠実度の高いビジュアルをシミュレートするインタラクティブギブソン環境、およびこれらのシーンで見られるロボットと一般的なオブジェクトの忠実度の高い物理的ダイナミクス。 2）ナビゲーションと物理的相互作用の間の相互作用を研究することを可能にする一連のインタラクティブナビゲーションメトリック..インタラクティブギブソンで複数の学習ベースのベースラインを提示および評価し、ナビゲーションパス間のさまざまなトレードオフでナビゲーションのレジームへの洞察を提供します周囲のオブジェクトの効率と妨害..ベンチマークを公開し（https://sites.google.com/view/interactivegibsonenv）、ロボット工学のすべての分野の研究者を奨励します（例：
[ABSTRACT]複数の学習を提示および評価します-ベースインタラクティブgibson.itのベースラインは、さまざまな表示ツールを使用したナビゲーションのレジームへの洞察を提供します。これらのツールには、目標位置につながるパスを確認するために使用できるツールが含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-30">
        <br><font color="black">2019-10-30</font>
      </time>
    </span>
</section>
<!-- paper0: EIS -- a family of activation functions combining Exponential, ISRU, and
  Softplus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_29.html">
      <font color="black">EIS -- a family of activation functions combining Exponential, ISRU, and
  Softplus</font>
    </a>
  </h2>
  <font color="black">ReLU、Sigmoid、Tanh、Softplusなどの基本関数は、その単純さからディープラーニングコミュニティで人気があります。長年にわたって、いくつかのタスクの精度を向上させるために多数の活性化関数が提案されてきました。近年、いくつかの新しい活性化これらの基本的な関数から生じる関数が提案されており、いくつかの難しいデータセットの精度が向上しています。 
[ABSTRACT] relu、sigmoid、tanh、またはsoftplusは、その単純さからディープラーニングコミュニティの間で人気があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: FeatureNMS: Non-Maximum Suppression by Learning Feature Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_30.html">
      <font color="black">FeatureNMS: Non-Maximum Suppression by Learning Feature Embeddings</font>
    </a>
  </h2>
  <font color="black">この問題を解決するためにFeatureNMSを提案します。FeatureNMSは、境界ボックス間の結合の交差に基づいてだけでなく、特徴ベクトルの違いにも基づいて重複を認識します。古典的な非最大抑制には、高いオブジェクトを含むシーンに欠点があります。オーバーラップ：このヒューリスティックは、2つの境界ボックス間のオーバーラップが大きいと、一方が重複する可能性が高いことを前提としています。 
[要約]重複は、非最大抑制と呼ばれる後処理ステップで削除されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br><font color="black">2020-02-18</font>
      </time>
    </span>
</section>
<!-- paper0: A Practical Online Method for Distributionally Deep Robust Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_31.html">
      <font color="black">A Practical Online Method for Distributionally Deep Robust Optimization</font>
    </a>
  </h2>
  <font color="black">文献では、DROを解くためのほとんどの方法は、確率的プライマルデュアル法に基づいています。提案されたオンライン確率的方法は、ディープニューラルネットワークの学習に広く使用されているいくつかの観点から、実用的な確率的ネステロフの方法に似ています。ディープラーニングの分布ロバスト最適化（DRO）を解決するための実用的なオンライン手法。これは、ニューラルネットワークのロバスト性を向上させるための機械学習に重要なアプリケーションがあります。 
[要約]文献では、droを解くためのほとんどの方法は、確率論的-二重法に基づいています。これらの問題に対処するために、最小-最大バージョンを最小化に変換します。提案された方法は、最適なサンプルの複雑さとより良いラウンドの複雑さを享受できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br><font color="black">2020-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: MADGAN: unsupervised Medical Anomaly Detection GAN using multiple
  adjacent brain MRI slice reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CV/paper_32.html">
      <font color="black">MADGAN: unsupervised Medical Anomaly Detection GAN using multiple
  adjacent brain MRI slice reconstruction</font>
    </a>
  </h2>
  <font color="black">したがって、教師なし医療異常検出生成的敵対的ネットワーク（MADGAN）を提案します。これは、GANベースの複数隣接脳MRIスライス再構成を使用して、マルチシーケンス構造MRIのさまざまな段階で脳異常を検出する新しい2段階の方法です。（再構成）ワッサースタイン損失勾配ペナルティ+ 100L1損失-次の3つのスライスを再構築するために3つの健康な脳軸MRIスライスでトレーニング-目に見えない健康/異常スキャンを再構築します。 （診断）スキャンごとの平均L2損失は、グラウンドトゥルース/再構成されたスライスを比較してそれらを識別します。私たちの自己注意MADGANは、非常に早い段階でT1スキャンのADを検出できます。軽度の認知障害（MCI）、曲線下面積（ AUC）0.727、およびAUC 0.894で後期のAD、AUC 0.921でT1cスキャンで脳転移を検出します。監視されていない学習では、健康な被験者の大規模な注釈なしの医療画像に依存して、さまざまな目に見えない異常を発見できます。 
[ABSTRACT]教師なし手法では、3Dスキャンを使用して外れ値を検出します。教師なし異常検出は、病期、さまざまな疾患、またはマルチシーケンス磁気共鳴画像法（mri）スキャンなどの疾患に関連しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-24">
        <br><font color="black">2020-07-24</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Appraisal Theories for Emotion Classification in Text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CL/paper_0.html">
      <font color="black">Appraisal Theories for Emotion Classification in Text</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、イベントの説明における高品質の評価次元の割り当てが、個別の感情カテゴリの分類の改善につながることを示しています。したがって、自動分類アプローチでは、潜在変数としてイベントのプロパティを学習する必要があります（たとえば、不確実性と精神的または肉体的努力ヘビとの遭遇に関連して恐怖につながる）。この感情の再構築は、主観的な感情の明示的な報告にアクセスしなくても可能です（たとえば、「私は恐れています」という言葉でこれを表現します）。 
[概要]このアプローチは、イベントの知覚に基づく既存の心理学理論を無視します。この感情の再構築は、主観的な感情の明示的なレポートにアクセスしなくても可能です。これらの例は、感情分類の可能性を示すことを目的としています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br><font color="black">2020-03-31</font>
      </time>
    </span>
</section>
<!-- paper0: Relation of the Relations: A New Paradigm of the Relation Extraction
  Problem -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CL/paper_1.html">
      <font color="black">Relation of the Relations: A New Paradigm of the Relation Extraction
  Problem</font>
    </a>
  </h2>
  <font color="black">したがって、手作りのルールを必要としないが、グラフニューラルネットワークと関係行列トランスフォーマーを使用してRoRを単独で学習するデータ駆動型アプローチを開発します。このようなアプローチは、2次計算時間を誘発し、相互依存性も見落とします。複数の関係、つまり関係の関係（RoR）。自然な言語では、多くの場合、複数のエンティティが同じテキストに表示されます。 
[ABSTRACT]関係抽出（ror）の以前の作業は、一度に2つのエンティティ間の関係を識別することに範囲を制限します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-05">
        <br><font color="black">2020-06-05</font>
      </time>
    </span>
</section>
<!-- paper0: What Should/Do/Can LSTMs Learn When Parsing Auxiliary Verb
  Constructions? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CL/paper_2.html">
      <font color="black">What Should/Do/Can LSTMs Learn When Parsing Auxiliary Verb
  Constructions?</font>
    </a>
  </h2>
  <font color="black">定形動詞（FMV）と比較して助動詞構文（AVC）の推移性と一致情報を調べます。アーキテクチャでシーケンシャルモデル（BiLSTM）のみが使用されている場合、パーサーはAVCとFMVに関するさまざまな情報を学習します。再帰層が使用される場合の同様の情報..ニューラルNLPモデルが言語について何を学習するかを調査することに関心が高まっています。 
[概要]助動詞構文（avcs）の推移性と一致情報を調べます。これを定形動詞（fmvs）と比較します。avcは分離された核であり、fmvは分離されていない対応物であり、1つの単語のみで構成されます。 。ネットワークで情報がどのように学習されるかについての説明があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-18">
        <br><font color="black">2019-07-18</font>
      </time>
    </span>
</section>
<!-- paper0: The Secret is in the Spectra: Predicting Cross-lingual Task Performance
  with Spectral Similarity Measures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CL/paper_3.html">
      <font color="black">The Secret is in the Spectra: Predicting Cross-lingual Task Performance
  with Spectral Similarity Measures</font>
    </a>
  </h2>
  <font color="black">次に、個々のスペクトルの関連する統計に基づいて、2つの埋め込みスペース間にいくつかの同型測定を導入します。各単一言語の埋め込みスペースのスペクトルの統計は、それらがどれだけうまく整列できるかを示していると仮定します。クロスリンガルNLPタスクのパフォーマンス手元にある言語の（非）類似性の影響を受けます。たとえば、以前の研究では、バイリンガルレキシコン誘導（BLI）の期待される成功と、単一言語の埋め込みスペース間の（おおよその）同型の仮定との間に関連があることが示唆されています。 
[概要]単言語の埋め込み空間の類似性とタスクのパフォーマンスの相関関係に焦点を当てた大規模な研究。これらの測定値は、類型的および言語の距離の測定値とは異なる情報をキャプチャします。2つのファミリの測定値を組み合わせると、タスクのパフォーマンスの相関関係がさらに高くなります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br><font color="black">2020-01-30</font>
      </time>
    </span>
</section>
<!-- paper0: PoinT-5: Pointer Network and T-5 based Financial NarrativeSummarisation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CL/paper_4.html">
      <font color="black">PoinT-5: Pointer Network and T-5 based Financial NarrativeSummarisation</font>
    </a>
  </h2>
  <font color="black">提案された方法は、すべてのメトリックで最高の精度スコアとROUGE1、LCSで最高のF1スコアを達成し、ROUGE-LCSメトリックでMUSEソリューションのベースラインを超える唯一のソリューションです。提案された方法は、ポインタネットワークを使用して重要な説明文を抽出します。次に、T-5を使用して、抽出された文を簡潔でありながら有益な文に言い換えます。ROUGE-N（1,2）、L、およびSU4を使用してメソッドを評価します。 
[概要]レポートの平均点は80で、最大250ページに及ぶ可能性があります。提案された方法では、ポインタネットワークを使用して重要な物語文を抽出します。次に、t-5を使用して、抽出された文を簡潔で有益な文に言い換えます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: What's so special about BERT's layers? A closer look at the NLP pipeline
  in monolingual and multilingual models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CL/paper_5.html">
      <font color="black">What's so special about BERT's layers? A closer look at the NLP pipeline
  in monolingual and multilingual models</font>
    </a>
  </h2>
  <font color="black">さらに、品詞タグ付けの詳細な分析を通じて、特定のタスク内でも、情報がネットワークのさまざまな部分に分散し、パイプラインが見た目ほどきれいではない可能性があることを示しています。各レイヤーには異なる専門分野。全体的な最高のパフォーマンスに基づいて単一の情報を選択するのではなく、異なるレイヤーからの情報を組み合わせる方が便利な場合があります。これらの結果が英語以外の言語にもどの程度当てはまるかを調査するために、オランダ語を調査します。オランダ語のNLPタスク用のBERTベースのモデルと多言語BERTモデル。 
[概要] dutchbertベースのモデルとdutchnlpタスクの多言語bertモデルには異なる専門分野があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-14">
        <br><font color="black">2020-04-14</font>
      </time>
    </span>
</section>
<!-- paper0: Plug and Play Autoencoders for Conditional Text Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CL/paper_6.html">
      <font color="black">Plug and Play Autoencoders for Conditional Text Generation</font>
    </a>
  </h2>
  <font color="black">この方法の成功にとって重要なのは、オートエンコーダーのマニフォールドにマッピングされた埋め込みを維持するための損失項と、オフセットベクトルを学習することによってマニフォールドをナビゲートするようにトレーニングされたマッピングです。テキストオートエンコーダーは、スタイルなどの条件付き生成タスクに一般的に使用されます。転送..これにより、タスクのラベル付きトレーニングデータの必要性が減り、トレーニング手順がより効率的になります。 
[ABSTRACT]オートエンコーダーを使用して、オートエンコーダーの埋め込みスペース内のマッピングを学習できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Keyword Extraction for Full-sentence VQA -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CL/paper_7.html">
      <font color="black">Unsupervised Keyword Extraction for Full-sentence VQA</font>
    </a>
  </h2>
  <font color="black">識別デコーダーはそのような分解を実現するように設計されており、この方法は全文回答を含むVQAデータセットに実験的に実装されました。結果は、提案されたモデルがキーワードを説明する明示的な注釈を付けなくても、キーワードを正確に抽出できることを示しています。自然な状況でのVQAタスク。回答は、単一の単語ではなく文である可能性が高くなります。 
[概要]提案されたモデルは、全文の回答を2つの主要部分に分解できるという原則に基づいています。新しいモデルは、明示的な注釈を付けなくてもキーワードを正確に抽出できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-23">
        <br><font color="black">2019-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: AIN: Fast and Accurate Sequence Labeling with Approximate Inference
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CL/paper_8.html">
      <font color="black">AIN: Fast and Accurate Sequence Labeling with Approximate Inference
  Network</font>
    </a>
  </h2>
  <font color="black">このアルゴリズムに基づいて、ニューラルCRFモデルのエンコーダーに接続してエンドツーエンドネットワークを形成できる近似推論ネットワークを設計します。これにより、並列化が可能になり、トレーニングと予測が高速化されます。提案するアプローチでは、従来のCRFアプローチと比較して、長い文でのデコード速度が12.7倍向上し、競争力のある精度が得られます。ただし、これらのアルゴリズムでは、並列化を不可能にする順次計算が必要です。 
[概要] crfモデルは正確な確率的アルゴリズムに基づいています。これらのアルゴリズムは通常、モデルのトレーニング段階と予測段階で適用されます。実験結果は、モデルが12倍改善されていることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: The Explanation Game: Towards Prediction Explainability through Sparse
  Communication -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CL/paper_9.html">
      <font color="black">The Explanation Game: Towards Prediction Explainability through Sparse
  Communication</font>
    </a>
  </h2>
  <font color="black">このフレームワークを使用して、勾配法、表現の消去、注意メカニズムなど、説明を抽出するためのいくつかの以前のアプローチを、コミュニケーションの成功の観点から比較します。説明者のさまざまな構成を使用した、テキスト分類、自然言語の含意、および機械翻訳の実験と素人（機械と人間の両方を含む）は、勾配法と消去法よりも注意に基づく説明者の利点を明らかにします。さらに、人間の評価実験は、コミュニケーションの成功と忠実さを最適化するように訓練された事後説明者による有望な結果を示しています。 
[ABSTRACT]説明可能性は、説明者と素人の間のコミュニケーションの問題です。これに先立って、古典的な特徴選択に照らしてこれらの方法を再解釈します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br><font color="black">2020-04-28</font>
      </time>
    </span>
</section>
<!-- paper0: Biomedical Event Extraction with Hierarchical Knowledge Graphs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CL/paper_10.html">
      <font color="black">Biomedical Event Extraction with Hierarchical Knowledge Graphs</font>
    </a>
  </h2>
  <font color="black">接地されたグラフは、複雑なイベントを推測する機能を強化するための新しいグラフニューラルネットワークであるGEANetによって伝播されます。アブレーション研究により、GEANetと階層型KGの重要性が確認されます。BioNLP2011GENIAイベント抽出タスクで、私たちのアプローチは1.41％F1を達成しました。すべてのイベントと複雑なイベントでそれぞれ3.19％のF1の改善。 
[ABSTRACT]たとえば、非インジケーターに関連付けられたネストされた構造を識別できます。トリガーワードをより適切に認識するために、各文は最初に文グラフに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-20">
        <br><font color="black">2020-09-20</font>
      </time>
    </span>
</section>
<!-- paper0: Thieves on Sesame Street! Model Extraction of BERT-based APIs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CL/paper_11.html">
      <font color="black">Thieves on Sesame Street! Model Extraction of BERT-based APIs</font>
    </a>
  </h2>
  <font color="black">したがって、私たちの作業は、NLPコミュニティ内の転送学習方法への移行によってのみ実現可能になったエクスプロイトを強調しています。数百ドルのクエリ予算で、攻撃者は被害者モデルよりもわずかにパフォーマンスが悪いモデルを抽出できます。モデル抽出に対する2つの防御戦略---メンバーシップ分類とAPIウォーターマーク---は、ナイーブな敵に対しては成功しますが、より洗練された敵に対しては効果がありません。2019）、敵は実際のトレーニングデータを必要としないことを示します。攻撃を正常にマウントします。 
[概要]単語のランダムシーケンスとタスク固有のヒューリスティックが、nlpの犠牲者の多様なセットでモデル抽出のための効果的なクエリを形成することを示します。また、モデル抽出に対する2つの防御戦略を研究しました。これは、ナイーブな敵に対しては成功しますが、洗練されたもの</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-27">
        <br><font color="black">2019-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Linear Time Neural Machine Translation with Capsule Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CL/paper_12.html">
      <font color="black">Towards Linear Time Neural Machine Translation with Capsule Networks</font>
    </a>
  </h2>
  <font color="black">パッシブでボトムアップの方法でソースセンテンスを格納する前の作業\ cite {sutskever2014sequence}とは異なり、動的ルーティングポリシーは、ソースセンテンスを反復プロセスでエンコードして、下位層と上位層のノード間のクレジット属性を決定します。\ textsc {CapsNMT}には、2つのコアプロパティがあります。シーケンスの長さが線形である時間内に実行され、ソースセンテンスの部分全体の情報を選択、表現、および集約するためのより柔軟な方法を提供します。\ textsc {CapsNMT}集約メカニズムを使用して、ソースセンテンスを事前に決定されたサイズのマトリックスにマッピングし、次にディープLSTMネットワークを適用してソース表現からターゲットシーケンスをデコードします。 
[ABSTRACT] `私たちは、ソースセンテンスを事前に決定されたサイズの行列にマッピングするための少しの軌道メカニズムを持っています。次に、ディープlstmネットワークを適用して、ソース表現からターゲットシーケンスをデコードします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-11-01">
        <br><font color="black">2018-11-01</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Learn to Disambiguate: Meta-Learning for Few-Shot Word Sense
  Disambiguation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CL/paper_13.html">
      <font color="black">Learning to Learn to Disambiguate: Meta-Learning for Few-Shot Word Sense
  Disambiguation</font>
    </a>
  </h2>
  <font color="black">このシナリオにいくつかの一般的なメタ学習アプローチを拡張し、この新しい挑戦的な設定での長所と短所を分析します。メタ学習は、目的を持って、多数の数ショットのタスクでモデルをトレーニングすることにより、この問題を解決することを目的としています。少数の例から新しいタスクをすばやく学習するには..その性質上、WSDはこの制御されたセットアップから逸脱し、モデルが多数の非常に不均衡なクラスを処理する必要があります。 
[要約]目標は、ラベル付けされた少数のインスタンスから見えない単語を明確にすることを学ぶことです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br><font color="black">2020-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: UCD-CS at W-NUT 2020 Shared Task-3: A Text to Text Approach for COVID-19
  Event Extraction on Social Media -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CL/paper_14.html">
      <font color="black">UCD-CS at W-NUT 2020 Shared Task-3: A Text to Text Approach for COVID-19
  Event Extraction on Social Media</font>
    </a>
  </h2>
  <font color="black">私たちのコードは、再現性を高めるために公開されています。私たちのアプローチは、トランスフォーマーベースのT5テキストツーテキストモデルを活用することにより、イベント抽出タスクを質問応答タスクとして扱います。そのような実行の中には、スロットの質問にうまく答えることができるものもありますが、ゴールドスタンダードと完全に一致するものではない場合があります。答えます。 
[概要]このタスクは、ツイートからスロットを埋める質問への回答を抽出することです。担当者は、5つのcovidをテーマにしたイベントのうち3つで、最高の参加ランおよび最先端のf1スコアと同じレベルのパフォーマンスを扱いました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-21">
        <br><font color="black">2020-09-21</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Debiasing NLU Models from Unknown Biases -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CL/paper_15.html">
      <font color="black">Towards Debiasing NLU Models from Unknown Biases</font>
    </a>
  </h2>
  <font color="black">提案されたフレームワークは一般的であり、既存のバイアス除去方法を補完します。さらに、評価は、フレームワークを適用すると全体的な堅牢性が向上することを示唆しています。NLUモデルは、意図したタスクを適切に学習せずに、バイアスを利用して高いデータセット固有のパフォーマンスを実現することがよくあります。 
[要約]最近のバイアス除去方法は、問題を軽減するのに効果的であることが示されています。しかし、彼らは、新しい方法が効果的であると知られていると主張しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-25">
        <br><font color="black">2020-09-25</font>
      </time>
    </span>
</section>
<!-- paper0: The role of context in neural pitch accent detection in English -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CL/paper_16.html">
      <font color="black">The role of context in neural pitch accent detection in English</font>
    </a>
  </h2>
  <font color="black">また、すべての内容語の高低アクセントを予測するだけの単純なベースラインでは82.2％の精度が得られることがわかり、これがこのタスクの適切なベースラインであることがわかります。これらの革新により、87.5％から88.7に改善されることがわかりました。ボストン大学ラジオニュースコーパスでのアメリカ英語音声の高低アクセント検出の％精度、最先端の結果。私たちのモデルは、入力として完全な発話を使用し、LSTMレイヤーを追加することにより、コンテキストをより活用します。 
[概要]音声の韻律イベントを検出する方法が必要です。これらの革新により、87.5％から88％の改善が見られます。7％。ピッチがこのタスクの最も重要な音響機能であることを示すアブレーションテストを実施します。コーパス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: Examining the Ordering of Rhetorical Strategies in Persuasive Requests -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/cs.CL/paper_17.html">
      <font color="black">Examining the Ordering of Rhetorical Strategies in Persuasive Requests</font>
    </a>
  </h2>
  <font color="black">次に、テキスト要求の成功を予測する注意LSTMを介して、コンテンツと戦略の間の相互作用を視覚化します。戦略の順序が説得力にどのように寄与するかを調べるために、まず、Variational Autoencoderモデルを利用して、大規模な要求からのテキスト要求のコンテンツと修辞戦略を解きほぐします。スケールローンリクエストコーパス..特定の（順序付けされた）戦略がリクエストのコンテンツと一意に相互作用して、成功率、したがってリクエストの説得力に影響を与えることがわかりました。 
[ABSTRACT]説得は、変分オートエンコーダモデルを使用して、大規模な融資要求コーパスからの文学的要求の内容と修辞戦略を解きほぐします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-09">
        <br><font color="black">2020-10-09</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Conditioning Trick for Training Stable GANs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/eess.AS/paper_0.html">
      <font color="black">Conditioning Trick for Training Stable GANs</font>
    </a>
  </h2>
  <font color="black">この論文では、GANトレーニング中の不安定性の問題に対応してジェネレータネットワークに適用される、正規性からの差異逸脱と呼ばれる条件付けトリックを提案します。オーディオ信号の2D表現を合成するために、残差ネットワークを組み込んだBigGANアーキテクチャをわずかに変更します。いくつかの保存された位相情報を備えた高品質のサウンド..Schur分解のスペクトル領域で計算された実際のサンプルの正規性関数からの逸脱に近づくようにジェネレーターを強制します。 
[概要] bigganアーキテクチャは、いくつかの保存された位相情報を使用して高品質のサウンドを再構築するために使用できます。3つの客観的な指標によると、コンディショニングトリックを使用した提案されたgan構成は、ベースラインアーキテクチャを大幅に上回っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: HiFi-GAN: Generative Adversarial Networks for Efficient and High
  Fidelity Speech Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/eess.AS/paper_1.html">
      <font color="black">HiFi-GAN: Generative Adversarial Networks for Efficient and High
  Fidelity Speech Synthesis</font>
    </a>
  </h2>
  <font color="black">単一スピーカーデータセットの主観的な人間の評価（平均オピニオン評点、MOS）は、提案された方法が、単一のV100GPUでリアルタイムより167.9倍高速な22.05kHzのハイファイオーディオを生成しながら、人間の品質との類似性を示すことを示しています。フットプリントの小さいバージョンのHiFi-GANは、CPU上でリアルタイムの13.4倍の速度でサンプルを生成し、自動回帰の対応するものと同等の品質を備えています。さらに、HiFi-GANの一般性を、見えないスピーカーのメルスペクトル反転とエンドツーエンドで示します。音声合成を終了します。 
[ABSTRACT] hifi-gan to themel-実際の話者のスペクトログラム反転と音声合成。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: Designing a 9-channel location microphone from scratch -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/eess.AS/paper_2.html">
      <font color="black">Designing a 9-channel location microphone from scratch</font>
    </a>
  </h2>
  <font color="black">最後に、そのようなシステムのマイクマウントやフロントガラスなどの実用的な側面を紹介します。再生レイアウトの分析、ステレオ録音角度（SRA）、ウィリアムズカーブ、さまざまな再生のスケールファクターなどの録音コンセプトを紹介します。 60度を超える角度と拡散フィールドの無相関化..リグは、AURO-3D 9チャンネル再生システム（4つの高さのスピーカー）用に設計されています。 
[概要]設計システムは、個々のセクターの角度に一致するように設計されています。ソフトウェアは分析に利用できるようになります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: AI Song Contest: Human-AI Co-Creation in Songwriting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/eess.AS/paper_3.html">
      <font color="black">AI Song Contest: Human-AI Co-Creation in Songwriting</font>
    </a>
  </h2>
  <font color="black">これらの調査結果は、より分解可能、操作可能、解釈可能、適応性のある機械学習を活用した音楽インターフェースを設計する必要性を反映しています。これにより、アーティストはAIが個人的な表現を拡張する方法をより効果的に探求できるようになります。クリエイティブプロセスの「フレアとフォーカス」の側面を管理するだけでなく、複数のMLモデルと出力を探索およびキュレートする並行プロセスとそれらを両立させます。多くのチームは、複数の小さなモデルを個別に実行するなど、モジュラーアプローチを採用しました。結果を再結合する前の、曲の音楽の構成要素。 
[概要]調査により、音楽モデルの機能と流暢さが向上しました。調査によると、人間がこの新しいクラスのアルゴリズムと提携することは困難な場合があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: Enhancement Of Coded Speech Using a Mask-Based Post-Filter -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/eess.AS/paper_4.html">
      <font color="black">Enhancement Of Coded Speech Using a Mask-Based Post-Filter</font>
    </a>
  </h2>
  <font color="black">この論文では、時間周波数領域でのマスキングに依存するデータ駆動型ポストフィルタを提案します。ポストフィルタは、コード化された音声の品質を向上させるために一般的に使用されます。客観的評価と主観的評価の両方で、コード化された音声であり、ITU-TG.718などの標準で使用されている従来のヒューリスティックポストフィルターに対するマスクベースのニューラルネットワークシステムの優位性も示しています。 
[概要]ポストフィルターは、コード化された音声の品質を高めるために一般的に使用されます。完全に接続されたニューラルネットワーク（fcnn）、畳み込みエンコーダーデコーダー（ced）ネットワーク、および長短期記憶（lstm）ネットワークが実装されます。時間ごとの実際の値のマスクを推定するには-周波数ビン</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: Dance Revolution: Long-Term Dance Generation with Music via Curriculum
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/eess.AS/paper_5.html">
      <font color="black">Dance Revolution: Long-Term Dance Generation with Music via Curriculum
  Learning</font>
    </a>
  </h2>
  <font color="black">この論文では、音楽主導のダンス生成をシーケンス間の学習問題として形式化し、新しいseq2seqアーキテクチャを考案して、音楽機能の長いシーケンスを効率的に処理し、音楽とダンスの間のきめ細かい対応をキャプチャします。研究者は、再発神経ネットワーク（RNN）のような自己回帰モデルを介して人間の運動シーケンスを合成します。さらに、完全にガイドされた教師からトレーニングプロセスを穏やかに変更する、長い運動シーケンス生成における自己回帰モデルのエラー蓄積を軽減するカリキュラム学習戦略を提案します。以前のグラウンドトゥルースの動きを使用するスキームを強制し、代わりに生成された動きを主に使用する、ガイドの少ない自動回帰スキームに向けます。 
[ABSTRACT]ダンスと音楽は機械学習アーキテクチャの問題です。ただし、これはニューラルネットワークにフィードバックされる予測エラーが豊富なためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br><font color="black">2020-06-11</font>
      </time>
    </span>
</section>
<!-- paper0: Discriminative Sounding Objects Localization via Self-supervised
  Audiovisual Matching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/eess.AS/paper_6.html">
      <font color="black">Discriminative Sounding Objects Localization via Self-supervised
  Audiovisual Matching</font>
    </a>
  </h2>
  <font color="black">現実的なカクテルパーティービデオと合成されたカクテルパーティービデオの両方での実験結果は、私たちのモデルがサイレントオブジェクトを除外し、さまざまなクラスのサウンドオブジェクトの場所を指摘するのに優れていることを示しています。次に、クラス認識オブジェクトローカリゼーションマップがカクテルパーティーで生成されます。事前に学習したオブジェクトの知識を参照することでシナリオを作成し、それに応じて、オーディオとビジュアルのオブジェクトカテゴリの分布を一致させることでサウンドオブジェクトを選択します。オーディオビジュアルの一貫性は、自己監視信号と見なされます。コードはhttps：// githubで入手できます。 com / DTaoo / Discriminative-Sounding-Objects-Localization。 
[概要]自己教師ありクラス認識オブジェクトローカリゼーションのための2段階学習フレームワークが開発されています。最初に、音声制御クラス認識オブジェクトローカリゼーションのための2段階学習ツールを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: Pay Attention to the cough: Early Diagnosis of COVID-19 using
  Interpretable Symptoms Embeddings with Cough Sound Signal Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/eess.AS/paper_7.html">
      <font color="black">Pay Attention to the cough: Early Diagnosis of COVID-19 using
  Interpretable Symptoms Embeddings with Cough Sound Signal Processing</font>
    </a>
  </h2>
  <font color="black">実験の結果は、モデルがCOVID-19患者の咳と、95.04 $ \ pm $ 0.18％および96.83 $ \ pmのより高い特異性と精度で、いくつかのタイプの非COVID-19咳を区別するためのより優れた堅牢な機能の埋め込みをキャプチャすることを示しています。解釈可能性を維持しながら、それぞれ0.18％ドル。提案されたフレームワークのパフォーマンスは、30000のオーディオセグメントの症状と人口統計データ、4つの咳クラス（COVID-19、喘息、気管支炎）の150人の患者からの328の咳音を含む医療データセットを使用して評価されました。 、そして健康的）。COVID-19の現在の診断は、逆転写ポリマー連鎖反応（RT-PCR）テストによって行われます。 
[概要]提案されたフレームワークのパフォーマンスは、医療データセットを使用して評価されました。4つの咳クラスを持つ150人の患者からの328の咳音</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: The role of context in neural pitch accent detection in English -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-13/eess.AS/paper_8.html">
      <font color="black">The role of context in neural pitch accent detection in English</font>
    </a>
  </h2>
  <font color="black">また、すべての内容語の高低アクセントを予測するだけの単純なベースラインでは82.2％の精度が得られることもわかりました。これが、このタスクに適したベースラインであることをお勧めします。このモデルでは、完全な発話を入力として使用することで、コンテキストをさらに活用します。 LSTMレイヤーを追加します。最後に、ピッチがこのタスクとこのコーパスにとって最も重要な音響機能であることを示すアブレーションテストを実施します。 
[概要]音声の韻律イベントを検出する方法が必要です。これらの革新により、87.5％から88％の改善が見られます。7％。ピッチがこのタスクの最も重要な音響機能であることを示すアブレーションテストを実施します。コーパス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
