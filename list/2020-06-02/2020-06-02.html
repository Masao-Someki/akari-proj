<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-06-02の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: High-Fidelity Audio Generation and Representation Learning with Guided
  Adversarial Autoencoder -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.SD/paper_0.html">
      High-Fidelity Audio Generation and Representation Learning with Guided
  Adversarial Autoencoder
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、表現学習中に、モデルが下流のタスクに大きく偏っている場合は、下流のジョブに直接メリットをもたらす一般化機能が失われますが、他の関連タスクにスケーリングする機能は失われます。オーディオデータと高音質オーディオ生成は、機械学習研究分野で2つの要となっています。さらに、提案モデルは、実際のオーディオサンプルと区別がつかない優れた品質のオーディオを生成できます。 
[要約]提案されたモデルは「ガイド付き敵対オートエンコーダー」と呼ばれます。ポスト固有の表現と一般的な表現の両方を学習できます。これにより、将来の関連タスクに適しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Guided Generative Adversarial Neural Network for Representation Learning
  and High Fidelity Audio Generation using Fewer Labelled Audio Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.SD/paper_1.html">
      Guided Generative Adversarial Neural Network for Representation Learning
  and High Fidelity Audio Generation using Fewer Labelled Audio Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、特定のタスクを対象とする場合、モデルは冗長になる可能性があります。このホワイトペーパーでは、GANが学習に集中するように導く新しいGANフレームワーク：Guided Generative Neural Network（GGAN）を提案することで、この課題に対処することを目指しています。より少ないラベル付きサンプルを活用して、オーディオデータの望ましい表現と優れた品質のサンプルを生成します。ジェネレーティブアドバサリアルニューラルネットワーク（GAN）の最近の改善により、高品質のサンプルを生成し、転移学習の優れた表現を学習する能力が示されました。 
[ABSTRACT]ほとんどのgansの表現は、使用後のシナリオを無視して表現を学習します。これにより、汎化能力が向上する可能性があります。これは、教師なし表現表現の基本的な課題です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-05">
        <br>2020-03-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Similarity-and-Independence-Aware Beamformer: Method for Target Source
  Extraction using Magnitude Spectrogram as Reference -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.SD/paper_2.html">
      Similarity-and-Independence-Aware Beamformer: Method for Target Source
  Extraction using Magnitude Spectrogram as Reference
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最尤推定によってこの抽出問題を解決するために、類似性を反映できる2種類のソースモデルを導入します。SIBFの利点は、ターゲットによって生成されたスペクトログラムと比較して、正確なターゲット信号を取得できることです。ディープニューラルネットワーク（DNN）に基づく音声強調などの強調方法。CHiME3データセットを使用した実験結果は、SIBFがDNNによって生成された参照よりも正確にターゲット信号を抽出できることを示しています。 
[ABSTRACT] sibfは、大まかなマグニチュードスペクトログラムを参照信号として使用してターゲット信号を抽出できます。メソッドは、chime3データセットを使用してsibfを作成します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Time-Scale Modification Dataset with Subjective Quality Labels -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.SD/paper_3.html">
      A Time-Scale Modification Dataset with Subjective Quality Labels
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ラベル付きのデータセットは、http：//ieee-dataport.org/1987で入手できます。公開された客観的測定値と主観的スコアの比較は、主観的品質の不十分な指標である客観的測定値を示しています。結果の分析では、年齢と品質の間に相関関係はありません評価の;エキスパートリスナーと非エキスパートリスナーが同等であること。聴覚に問題がある場合とない場合の参加者のわずかな違いテスト方法間の最小限の違い。 
[要約]データセットの分析では、年齢とフィールドの品質の間に相関関係はありません。結果の分析では、年齢、評価の品質の間に相関関係がないことが示されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Phase-aware Single-stage Speech Denoising and Dereverberation with U-Net -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.SD/paper_4.html">
      Phase-aware Single-stage Speech Denoising and Dereverberation with U-Net
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、音声強調性能を改善するために、新しい時間領域損失関数を提案し、複雑な領域でのMSE損失と比較して妥当な性能向上を示しています。このために、位相認識ベータと呼ばれる新しいマスキング方法を提案します。 -シグモイドマスク（PHM）。これは、推定されたマグニチュード値を再利用して、混合、ソース、残りなどの3つの信号コンポーネント間の複素領域における三角形の不等式を考慮してクリーンな位相を推定します。この作業では、ノイズ除去とシングルステージフレームワークの残響問題。 
[要約]単一のベータsigmeネットワークを共有して、残響除去をマスクできます。リアルタイムの利点を実現するために、u-netのアップグレードが提案されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to Recognize Code-switched Speech Without Forgetting
  Monolingual Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.SD/paper_5.html">
      Learning to Recognize Code-switched Speech Without Forgetting
  Monolingual Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、コード交換音声の自動音声認識（ASR）が大幅に進歩し、多くの言語ペアのコード交換データセットの精度が向上しています。このフレームワークを使用してモデルをトレーニングすることが可能であることを示しています。コード切り替えテストセットと単一言語テストセットの両方で良好に機能します。プールされたデータと単純な微調整を使用するベースラインと比較して、単一言語テストセットとコード切り替えテストセットのWord Error Rate（WER）の改善を報告します。 
[ABSTRACT]コード-切り替え可能な音声の同時発生-片方または両方の言語の単一言語の音声が混在している場合に発生します。コードのモデルを最適化する必要があります-切り替えと同時に、単一言語のパフォーマンスが犠牲にならないようにします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards Learning a Universal Non-Semantic Representation of Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.SD/paper_6.html">
      Towards Learning a Universal Non-Semantic Representation of Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      埋め込みは、一般公開されているデータセットでトレーニングされ、パーソナライゼーションタスクや医療メインなど、さまざまな低リソースダウンストリームタスクでテストされます。ベンチマーク4、モデル5、および評価コード6は一般公開されています。提案された表現は、ベンチマークの他の表現よりも優れており、いくつかの転移学習タスクでの最先端のパフォーマンスさえも上回っています。 
[要約]提案された表現は埋め込みを比較するために使用できます-音声コミュニティはまだそうしていません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-25">
        <br>2020-02-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Streaming Language Identification using Combination of Acoustic
  Representations and ASR Hypotheses -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.SD/paper_7.html">
      Streaming Language Identification using Combination of Acoustic
  Representations and ASR Hypotheses
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、処理コストとレイテンシを削減するために、ストリーミングアーキテクチャを活用して、システムが所定の信頼レベルに達したときに音声言語を早期に特定し、入力クエリの最後まで複数のASRシステムを実行する必要性を軽減します。教師モデルとして新しく提案されたモデルアーキテクチャを使用した半教師あり学習（SSL）技術を採用した結果。従来、LIDは音響のみの情報に依存して入力言語を検出していました。 
[要約]音響システムとテキストシステムを組み合わせて使用すると、平均して1500ミリ秒の早期識別が可能であり、50％以上の発話が可能
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Evaluation of CNN-based Automatic Music Tagging Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.SD/paper_8.html">
      Evaluation of CNN-based Automatic Music Tagging Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、評価のために異なるデータセットの分割やソフトウェアバージョンを使用するなど、研究者が行った実験設定の違いにより、提案されたアーキテクチャを互いに直接比較することは困難です。ディープラーニングの最近の進歩により、コンテンツの開発が加速しました-ベースの自動音楽タグ付けシステム..再現性のために、私たちはPyTorch実装に事前トレーニング済みモデルを提供します。 
[ABSTRACT]新しいアーキテクチャは、畳み込みニューラルネットワーク（cnns）に基づいています。これらのアーキテクチャは、このマルチラベルバイナリ分類タスクで最先端の結果を達成するように設計されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Cross-cultural data shows musical scales evolved to maximise imperfect
  fifths -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.SD/paper_9.html">
      Cross-cultural data shows musical scales evolved to maximise imperfect
  fifths
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ほとんどのスケールは、完全な5分の1（「不完全な5分の1」）に近いサイズの間隔を含む傾向があり、パッキング引数は、分布の顕著な特徴を説明します。間隔が圧縮可能である場合、スケールも好ましいです。音階はさまざまな選択圧力に従って進化するように見えますが、最も単純なhの5分の1のパッキングモデルは経験的データに最もよく適合します。 
[ABSTRACT]スケールは調和系列に基づいていますが、伝達するのは簡単ではありません。単純なh不完全-5分の1のパッキングモデルはデータに最もよく適合します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-13">
        <br>2019-06-13
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: When Bert Forgets How To POS: Amnesic Probing of Linguistic Properties
  and MLM Predictions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_0.html">
      When Bert Forgets How To POS: Amnesic Probing of Linguistic Properties
  and MLM Predictions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この新しい分析ツールを装備して、以前は不可能であったような質問をすることができます。品詞情報は単語予測にとって重要ですか？これらのタイプの質問に答えるために、BERTで一連の分析を実行します。 
[要約]記憶処理による方法は、特定のタスクで使用されるプロパティの有用性は、表現からそれを削除する因果的介入の影響を測定することによって評価できるという直感に従います
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Elephant in the Room: An Evaluation Framework for Assessing Adversarial
  Examples in NLP -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_1.html">
      Elephant in the Room: An Evaluation Framework for Assessing Adversarial
  Examples in NLP
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、テキスト入力の長さや分類子のアーキテクチャなど、複数の要因が攻撃パフォーマンスに影響する可能性があることも学びました。前述の特性に基づいて、敵対的な例の品質を厳密に評価します。敵対的な例は、機械学習モデルが一貫して誤って分類する小さな摂動によって変換された入力です。 
[ABSTRACT] 6つのベンチマークを実験したところ、一部の方法では、可読性と機械学習が劣悪な例が生成されていることがわかりました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br>2020-01-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Sarcasm Detection using Context Separators in Online Discourse -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_2.html">
      Sarcasm Detection using Context Separators in Online Discourse
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたアーキテクチャが両方のデータセットに対して競争的に機能することを示します。皮肉は複雑な形の音声であり、意味は暗黙的に伝えられます。さらに、3つの異なる入力のタイプ-Response-only、Context-Response、およびContext-Response（Separated）。 
[ABSTRACT]皮肉を使用して埋め込みベースのモデルのパフォーマンスを向上させます。また、コンテキストとターゲットの応答の間の分離トークンにより、5の改善が得られることも示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Toxicity Detection: Does Context Really Matter? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_3.html">
      Toxicity Detection: Does Context Really Matter?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      コードとデータを公開しています。これは、コンテキストで注釈が付けられたコメントのより大きなデータセットが必要であることを示しています。コンテキストにより、認識された投稿の毒性を増幅または軽減できることがわかりました。 
[ABSTRACT]ウィキペディアの会話を実験し、コンテキストの概念を前の投稿に限定します。アノテーターにコンテキストが提供されていない場合、手動でラベル付けされた投稿の小さいが重要なサブセットは、反対の毒性ラベルを持つことになります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The State and Fate of Linguistic Diversity and Inclusion in the NLP
  World -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_4.html">
      The State and Fate of Linguistic Diversity and Inclusion in the NLP
  World
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーを通じて、ACLコミュニティがここで強調した苦境の解決に優先順位を付け、言語が取り残されないように説得することを試みます。私たちの定量的調査は、特にリソースの観点から、言語間の格差を強調し、疑問を投げかけています現在のモデルとシステムの「言語にとらわれない」ステータス。言語テクノロジーは、世界中の多言語主義と言語の多様性の促進に貢献しています。 
[ABSTRACT]世界の7000を超える言語の数は、言語技術とアプリケーションで表されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Efficient EUD Parsing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_5.html">
      Efficient EUD Parsing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      公式提出で平均74.04のELASを取得し、全体で4位にランクインしました。私たちのモデルは、抽出された神経依存性パーサーと、UDツリーをEUDグラフに投影するルールベースのシステムを組み合わせたものです。効率。 
[要約]効率に焦点を当ててタスクに取り組みました。モデルは、蒸留された神経依存性パーサーと、udツリーをeudに投影するルールベースのシステムの組み合わせです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Neural Network Model of Lexical Competition during Infant Spoken Word
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_6.html">
      A Neural Network Model of Lexical Competition during Infant Spoken Word
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      視覚世界の研究は、関連するアイテムと無関係のアイテムを含むターゲットのない視覚的コンテキストで単語を聞くと、幼児と大人が音韻的に関連するアイテムに視線を向けた後、意味論的に視覚的に関連するアイテムにシフトすることを示しています。音韻表現は、意味論的視覚表現へのボトムアップ方式は、視覚世界のタスクで報告された初期の音韻的選好効果をキャプチャします。このような試行で後に観察される意味論的視覚選好は、意味論的または視覚的システムからのトップダウンフィードバックを必要としません。 
[要約]動的な展開音韻表現を処理し、静的な内部意味論的および視覚的表現にマップするニューラルネットワークモデルを提示します。この調査結果は、発話された単語の増分展開自体が、視覚的な一時的な好みを説明するのに十分であるという仮説をサポートしていますアイテム
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SBERT-WK: A Sentence Embedding Method by Dissecting BERT-based Word
  Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_7.html">
      SBERT-WK: A Sentence Embedding Method by Dissecting BERT-based Word
  Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、10の文レベルのプロービングタスクが詳細な言語分析のために提示されます。SBERT-WKでこれ以上のトレーニングは必要ありません。この作業では、深い文脈モデルの単語表現のレイヤーごとのパターンを研究します。 
[ABSTRACT]これはsbert-wkメソッドと呼ばれます。これは、単語転送のパターンに基づいています。これは、いくつかのnlpタスクで実行できることを示唆しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-16">
        <br>2020-02-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Translating Natural Language Instructions for Behavioral Robot
  Navigation with a Multi-Head Attention Mechanism -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_8.html">
      Translating Natural Language Instructions for Behavioral Robot
  Navigation with a Multi-Head Attention Mechanism
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      マルチヘッドアテンションメカニズムをニューラルネットワークモデルのブレンディングレイヤーとして提案し、自然言語を屋内ロボットのナビゲーション用の高水準行動言語に変換します。この結果は、以前は目に見えなかった環境で命令を変換するときに大幅なパフォーマンスの向上を示し、したがって、モデルの一般化機能。タスクの知識ベースとしてナビゲーショングラフの使用を提案する（Zang et al。、2018a）によって確立されたフレームワークに従います。 
[要約]タスクのツールとしてナビゲーショングラフの使用を提案するシステムに従います。ナビゲーションシステムの例に従います
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Batch Normalized Inference Network Keeps the KL Vanishing Away -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_9.html">
      A Batch Normalized Inference Network Keeps the KL Vanishing Away
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、近似正規化パラメーターの分布を正則化することで期待値の下限を設定するシンプルで効果的なアプローチであるバッチ正規化VAE（BN-VAE）を提案します。新しいモデルコンポーネントを導入したり、目的を変更したりせずに、このアプローチ以前のアプローチでは、各データポイントのカルバックレイブラーダイバージェンス（KL）を個別に考慮します。 
[ABSTRACT] vaeは、「事後崩壊」と呼ばれる縮退したローカル最適値に収束することがよくあります。vaeのアプローチは、言語モデリング、テキスト分類、およびダイアログ生成の強力な自己回帰ベースラインを超えています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br>2020-04-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Influence via Ethos: On the Persuasive Power of Reputation in
  Deliberation Online -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_10.html">
      Influence via Ethos: On the Persuasive Power of Reputation in
  Deliberation Online
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      個人の評判は、その説得の有効性、強さ、および提示を超えて、説得率に大きな影響を与えることがわかります。また、評判の影響は、理論モデルと一貫した方法で、論拠内容の特性によって緩和されることもわかりました。これは、評判の説得力を認知過負荷下でのヒューリスティックな情報処理に起因するものとします。オンラインおよびパブリックおよびプライベート組織の審議的意思決定を容易にするプラットフォームの管理上の影響について説明します。 
[ABSTRACT]過去の討論競争の測定値から評判のための手段を構築することにより、説得に対する評判の因果関係を特定します。10の追加の評判ポイントがあると、プラットフォームの平均を超えて成功する説得の確率が31％増加します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Language Models are Few-Shot Learners -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_11.html">
      Language Models are Few-Shot Learners
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、GPT-3は、人間の評価者が人間が書いた記事と区別するのが難しいニュース記事のサンプルを生成できることがわかります。対照的に、人間は通常、いくつかの例または単純な指示から新しい言語タスクを実行できます。現在のNLPシステムはまだ大部分が苦労しています。ここでは、言語モデルをスケールアップすると、タスクにとらわれない、ショット数の少ないパフォーマンスが大幅に向上し、場合によっては、従来の最先端の微調整アプローチで競争力が向上することもあります。 
[ABSTRACT]言語モデルをスケールアップすると、タスクが大幅に改善されます。これは、以前のモデルアプローチとの競争力に達する場合があります。これらには、言語テスト、言語テスト、言語テストが含まれます。これらのデータセットは、モデルとのテキストインタラクションに変換できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Quantum Accelerated Estimation of Algorithmic Information -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_12.html">
      Quantum Accelerated Estimation of Algorithmic Information
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの知る限り、これは量子計算のためにアルゴリズム情報の近似が実装されるのは初めてです。計算モデルは、ターゲットメトリックの近似で計算できるように、時間と空間のリソースが制限されています。重ね合わせを実行できる正確な量子回路設計オートマトンの紹介です。 
[ABSTRACT]これにより、因果的な属モデルを発見するためのデータのアルゴリズム構造の推論が加速されます。推論アルゴリズムは、一連の超高速関数で示されています。さらに、メタ生物学のDNAシーケンスを実験するためのアプリケーションフレームワークが提案されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Rhetoric, Logic, and Dialectic: Advancing Theory-based Argument Quality
  Assessment in Natural Language Processing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_13.html">
      Rhetoric, Logic, and Dialectic: Advancing Theory-based Argument Quality
  Assessment in Natural Language Processing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの研究は、大規模な理論ベースの引数品質アノテーションの実現可能性、理論ベースの引数品質ディメンション間の関係を利用してパフォーマンスの向上をもたらすことができるという事実などの興味深い発見をもたらし、理論ベースの引数品質予測の有用性を次のように示しています。実用的なAQ評価ビューに関して。まず、言語学の専門家とクラウドワーカーによる注釈研究から始め、理論ベースの引数の品質スコアで注釈が付けられた最初の大規模な英語コーパス（AQCorpusと呼ばれる）を作成します。これらの個々の側面は、引数の質の理論ベースの次元ですが、実際のテキストの自動評価はまだ初期段階にあります-大規模なコーパスと計算モデルがありません。 
[ABSTRACT]引数の品質（aq）は、3種類のオンライン引数記述の分析に基づいています。authorann ann annは、理論に基づいた引数品質の研究を開発しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to Recognize Code-switched Speech Without Forgetting
  Monolingual Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_14.html">
      Learning to Recognize Code-switched Speech Without Forgetting
  Monolingual Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、コード交換音声の自動音声認識（ASR）が大幅に進歩し、多くの言語ペアのコード交換データセットの精度が向上しました。プールデータと単純な微調整を使用するベースラインと比較したコードスイッチテストセット。単一言語モデルは、新しいモデルの再トレーニングに利用できない場合がある数千時間の音声でトレーニングされる場合があります。 
[ABSTRACT]コード-切り替え可能な音声の同時発生-片方または両方の言語の単一言語の音声が混在している場合に発生します。コードのモデルを最適化する必要があります-切り替えと同時に、単一言語のパフォーマンスが犠牲にならないようにします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Attention Word Embedding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_15.html">
      Attention Word Embedding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人気のあるword2vecの連続バッグオブワード（CBOW）モデルは、センテンス内の特定の単語をマスクし、他の単語をコンテキストとして使用して予測することにより、ベクトルの埋め込みを学習します。AWEとAWE-Sがさまざまな単語類似性データセットと、NLPモデルの初期化に使用された場合の両方で、最先端の単語埋め込みモデルを使用します。アテンションメカニズムをAWEに統合するAttention Word Embedding（AWE）モデルを導入して、この非効率性に取り組みます。 CBOWモデル。 
[ABSTRACT]私たちは、注意メカニズムをcbowモデルに統合する注意ワード埋め込み（awe）モデルを導入することで、この非効率性に取り組みます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Conversational Machine Comprehension: a Literature Review -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_16.html">
      Conversational Machine Comprehension: a Literature Review
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      したがって、この文献レビューは、CMCの全体的な概要を提供する、これまでにない最初の試みであり、特に、会話履歴に取り組むためのアプローチにおいて、最近公開されたモデル全体の共通の傾向に重点を置いています。このレビューは、このドメインの将来の研究者向けの概要表として機能します。会話型データセットへのモデルの提出量が毎年増加する中、将来の研究を合理化するためにこのドメインに散在する知識を統合する必要があります。 
[ABSTRACT]研究調査へのモデルの提出量が増加しています。データを取り巻く情報を統合する必要があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Online Versus Offline NMT Quality: An In-depth Analysis on
  English-German and German-English -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_17.html">
      Online Versus Offline NMT Quality: An In-depth Analysis on
  English-German and German-English
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2つのシーケンス間モデル：たたみ込みパーベイシブアテンション（Elbayad et al.。評価結果により、オンラインセットアップに移行したときの各モデルの長所と短所を特定できます。両方のアーキテクチャについて、英語-ドイツ語とドイツ語-英語のペアについて慎重に設計された人間の評価による翻訳品質のオンラインデコードの制約。後者はレイテンシの制約に特に敏感です。
[要旨]に移行すると、各モデルの長所と短所を特定できます。オンライン設定
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transcription-Enriched Joint Embeddings for Spoken Descriptions of
  Images and Videos -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_18.html">
      Transcription-Enriched Joint Embeddings for Spoken Descriptions of
  Images and Videos
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      EPIC-KitchenとPlacesの音声キャプションデータセットでの実験では、人間が生成した音声ナレーションのテキスト文字起こしを導入することで、トレーニング手順を改善し、埋め込み表現を改善できることがわかりました。この作業では、ユニークなトレーニングに効果的なアプローチを提案します3つの同時モダリティを組み合わせて表現を埋め込む：画像と音声およびテキストのナラティブ。提案された方法論は、音声によるナラティブと画像の手がかりのみでトレーニングされた埋め込みスペースを生成するベースラインシステムから逸脱します。 
[ABSTRACT]埋め込みスペースは、話されたナラティブと画像キューのみでトレーニングされます。新しい仮定により、ポイント埋め込みのより良い推定が可能になります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Probing Emergent Semantics in Predictive Agents via Question Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_19.html">
      Probing Emergent Semantics in Predictive Agents via Question Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さまざまなオブジェクト、色、形状、空間構成を備えた視覚的に豊富な3D環境でこれらの予測目標を使用してエージェントをトレーニングした後、質問応答から勾配を逆伝播することなく、内部状態表現を合成（英語）質問で調査しますエージェントへのデコーダー..この方法で調査したときのさまざまなエージェントのパフォーマンスは、オブジェクト、プロパティ、および物理的環境からの空間的関係についての事実上の、構成的に見える情報をエンコードすることを学習することを明らかにします。 、エージェントが学習するときに取得するプロパティと関係、質問条件付きエージェントの調査は、より強力な予測学習目標の設計と開発を刺激します。 
[ABSTRACT]私たちは質問-回答を提案し、そのようなエージェントが開発する表現をデコードして理解するための一般的なツールとして使用します。調査結果から、エージェントは物理環境からオブジェクト、プロパティ、空間関係に関する情報をエンコードする方法を学ぶことがわかります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Streaming Language Identification using Combination of Acoustic
  Representations and ASR Hypotheses -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_20.html">
      Streaming Language Identification using Combination of Acoustic
  Representations and ASR Hypotheses
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、処理コストとレイテンシを削減するために、ストリーミングアーキテクチャを活用して、システムが所定の信頼レベルに達したときに音声言語を早期に特定し、入力クエリの最後まで複数のASRシステムを実行する必要性を軽減します。教師モデルとして新しく提案されたモデルアーキテクチャを使用した半教師あり学習（SSL）技術を採用した結果。音響LIDとテキストLIDを、提案されたストリーミングランタイムアーキテクチャと組み合わせると、平均で1500ミリ秒以上の早期識別発話の50％、精度の低下はほとんどありません。 
[要約]音響システムとテキストシステムを組み合わせて使用すると、平均して1500ミリ秒の早期識別が可能であり、50％以上の発話が可能
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: COVID-19: Social Media Sentiment Analysis on Reopening -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_21.html">
      COVID-19: Social Media Sentiment Analysis on Reopening
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、私たちの分析では、再開に対する公共の感情を分析することに特に関心があります。このCOVID-19のパンデミック期間中、研究者は、封鎖と自宅での滞在に関するさまざまなソーシャルメディアデータセットについていくつかの分析を行いました。再開の状況に対する感情。 
[ABSTRACT]人々はソーシャルメディアを使用して、covidに関連する多くの問題について意見を表明しています-19この在宅滞在の注文。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Distilling Neural Networks for Greener and Faster Dependency Parsing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_22.html">
      Distilling Neural Networks for Greener and Faster Dependency Parsing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      元のモデルのトレーニング可能なパラメーターの20 \％に蒸留すると、ベースラインよりも2.30倍（1.19倍）高速でありながら、多数の多様なUniversal Dependencyツリーバンク全体でUASとLASの両方の$ \ sim $ 1ポイントの平均低下のみが観察されます推論時のCPU（GPU）のモデル。一部のツリーバンクで80 \％に圧縮すると、パフォーマンスがわずかに向上することも観察されます。自然言語処理研究のカーボンフットプリントは、その大規模への依存により、近年増加しています非効率的なニューラルネットワークの実装。 
[要約]蒸留は、大きなモデルから小さなモデルに依存関係を限定しようとするネットワーク圧縮技術です。元のモデルの速度の20％に蒸留する場合、uasとの両方の平均1ドルの減少のみが観察されます。いくつかの多様な普遍的依存性研究の研究全体で、最後に、ペンツリーバンクの最速のモダンパーサーよりも速い蒸留を達成しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Stance in Replies and Quotes (SRQ): A New Dataset For Learning Stance in
  Twitter Conversations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/cs.CL/paper_23.html">
      Stance in Replies and Quotes (SRQ): A New Dataset For Learning Stance in
  Twitter Conversations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに重要なのは、拒否タイプの応答の選択を優先するツイート収集方法論を設計したことです。このため、1つのイベントでトレーニングされたモデルは他のイベントに一般化されません。さらに、既存のデータセットは異なるタイプを区別しません。ソーシャルメディアでの会話（たとえば、Twitterでの返信と引用）。 
[ABSTRACT]これは現在、5200を超えるスタンスラベルを使用したTwitter会話用の人間がラベルを付けたスタンスデータセットの中で最大です。データセットは、噂の特定やユーザー間の拮抗関係の特定に役立つと期待されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: High-Fidelity Audio Generation and Representation Learning with Guided
  Adversarial Autoencoder -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/eess.AS/paper_0.html">
      High-Fidelity Audio Generation and Representation Learning with Guided
  Adversarial Autoencoder
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、教師なしの設定から学習した表現は、手元にある下流のタスクの使用可能性を保証するものではありません。その特定の事後ジョブに対してトレーニングを行った場合、リソースの浪費となる可能性があります。オーディオデータと高忠実度オーディオ生成は、機械学習研究分野で2つの要となっています。それを他の関連タスクにスケーリングする機能は失われます。 
[要約]提案されたモデルは「ガイド付き敵対オートエンコーダー」と呼ばれます。ポスト固有の表現と一般的な表現の両方を学習できます。これにより、将来の関連タスクに適しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Guided Generative Adversarial Neural Network for Representation Learning
  and High Fidelity Audio Generation using Fewer Labelled Audio Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/eess.AS/paper_1.html">
      Guided Generative Adversarial Neural Network for Representation Learning
  and High Fidelity Audio Generation using Fewer Labelled Audio Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーでは、新しいGANフレームワークを提案することでこの課題に対処することを目指しています。ガイド付きジェネレーティブニューラルネットワーク（GGAN）は、GANが目的の表現の学習と、少数のラベル付きサンプルを活用してオーディオデータの優れた品質のサンプルを生成することに焦点を当てるようにガイドします。たとえば、ラベル付けされていない膨大なオーディオデータセットがあり、このデータセットから表現を学習して、小さなラベル付けされたオーディオデータセットの感情認識パフォーマンスを改善できるようにしたいとします。GenerativeAdversarial Neural Networks（GANs ）は、より高品質のサンプルを生成する能力、および転移学習の適切な表現を学習する能力を示しています。 
[ABSTRACT]ほとんどのgansの表現は、使用後のシナリオを無視して表現を学習します。これにより、汎化能力が向上する可能性があります。これは、教師なし表現表現の基本的な課題です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-05">
        <br>2020-03-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Modeling of Rakugo Speech and Its Limitations: Toward Speech Synthesis
  That Entertains Audiences -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/eess.AS/paper_2.html">
      Modeling of Rakugo Speech and Its Limitations: Toward Speech Synthesis
  That Entertains Audiences
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、グローバルスタイルトークンと手動でラベル付けされたコンテキスト機能を使用して、スピーキングスタイルを充実させました。改善の余地はありますが、これはプロフェッショナルレベルで楽しい音声合成を実現するための重要な足がかりであると考えています。合成落語音声は専門家の音声に近づくことができます。制限された条件下では人間の音声と同じくらい自然に聞こえる音声を生成できる最先端の音声合成システムであるTacotron 2を使用して、落語音声をモデル化しました。長期的な依存関係をより適切に検討するように注意を払います。 
[ABSTRACT]落語は、伝統的な日本語の言葉による娯楽です。最先端の音声合成システムであるタコトロン2を使用しました。彼らは、文字の自然さと識別可能性、コンテンツの理解可能性、および娯楽の度合いを測定しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-31">
        <br>2019-10-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Similarity-and-Independence-Aware Beamformer: Method for Target Source
  Extraction using Magnitude Spectrogram as Reference -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/eess.AS/paper_3.html">
      Similarity-and-Independence-Aware Beamformer: Method for Target Source
  Extraction using Magnitude Spectrogram as Reference
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この研究では、ソース抽出のための類似性と独立性を意識したビームフォーマー（SIBF）と呼ばれる新しい方法を紹介します。 、ディープニューラルネットワーク（DNN）に基づく音声強調など。この抽出問題を最尤推定で解決するために、類似性を反映できる2種類のソースモデルを導入します。 
[ABSTRACT] sibfは、大まかなマグニチュードスペクトログラムを参照信号として使用してターゲット信号を抽出できます。メソッドは、chime3データセットを使用してsibfを作成します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Time-Scale Modification Dataset with Subjective Quality Labels -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/eess.AS/paper_4.html">
      A Time-Scale Modification Dataset with Subjective Quality Labels
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ソース資料には、スピーチ、ソロハーモニック、パーカッシブな楽器、効果音、さまざまな音楽ジャンルが含まれています。実験室および遠隔収集法を使用して、633セッションから42,529件の評価が収集されました。エキスパートリスナーと非エキスパートリスナーが同等であること。聴覚に問題がある場合とない場合の参加者のわずかな違いテスト方法間の最小限の違い。 
[要約]データセットの分析では、年齢とフィールドの品質の間に相関関係はありません。結果の分析では、年齢、評価の品質の間に相関関係がないことが示されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Tonal harmony, the topology of dynamical score networks and the Chinese
  postman problem -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/eess.AS/paper_5.html">
      Tonal harmony, the topology of dynamical score networks and the Chinese
  postman problem
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、動的ネットワークは非定常信号の時系列と見なすことができ、時系列分析と変化点検出のための確立された手法を使用して、キー領域の自動識別のために分割することができます。最後に、この作業で説明されている原理を使用して、調性構成設計の生成モデルを設計する方法について説明します。調性調和のコンテキストでは、このネットワークがスケールフリーのプロパティを表示し、解くことによって最適な（最も経済的な）コード進行を見つけることができる中国の郵便配達問題のような経路最適化。 
[ABSTRACT]調性の調和のコンテキストでは、このネットワークはスケール-無料のプロパティを表示します。ネットワークには、十分に確立された手法の比較に依存しないキーを見つけるアルゴリズムがあります。これには、キーマッチ検索システムが含まれていません多数の事前に確立された手法に依存
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Phase-aware Single-stage Speech Denoising and Dereverberation with U-Net -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/eess.AS/paper_6.html">
      Phase-aware Single-stage Speech Denoising and Dereverberation with U-Net
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このために、位相認識ベータシグモイドマスク（PHM）と呼ばれる新しいマスキング方法を提案します。PHMは、推定された大きさの値を再利用して、混合などの3つの信号成分間の複素領域の三角形の不等式を考慮して、クリーンな位相を推定します。ソースと残り..この作業では、1段階のフレームワークでノイズ除去と残響除去の問題に取り組みます。さらに、音声強調のパフォーマンスを改善するために、新しい時間領域損失関数を提案し、妥当なパフォーマンスの向上を示しています。複雑なドメインでのMSE損失と比較。 
[要約]単一のベータsigmeネットワークを共有して、残響除去をマスクできます。リアルタイムの利点を実現するために、u-netのアップグレードが提案されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to Recognize Code-switched Speech Without Forgetting
  Monolingual Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/eess.AS/paper_7.html">
      Learning to Recognize Code-switched Speech Without Forgetting
  Monolingual Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      プールされたデータと単純な微調整を使用するベースラインと比較した、単一言語およびコード切り替えテストセットのWord Error Rate（WER）の改善を報告します。最近、コードの自動音声認識（ASR）が大幅に進歩しました。多くの言語ペアのコード交換データセットで精度が向上する音声を切り替えます。単一言語モデルにのみアクセスでき、データがない場合は、コード交換ASRにLearning For Forgetting（LWF）フレームワークを使用することをお勧めします。それは訓練された。 
[ABSTRACT]コード-切り替え可能な音声の同時発生-片方または両方の言語の単一言語の音声が混在している場合に発生します。コードのモデルを最適化する必要があります-切り替えと同時に、単一言語のパフォーマンスが犠牲にならないようにします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards Learning a Universal Non-Semantic Representation of Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/eess.AS/paper_8.html">
      Towards Learning a Universal Non-Semantic Representation of Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ベンチマーク4、モデル5、および評価コード6は一般にリリースされています。埋め込みは一般に公開されているデータセットでトレーニングされ、パーソナライズタスクや医療メインなど、さまざまな低リソースダウンストリームタスクでテストされます。提案された表現は、ベンチマークの他の表現よりも優れており、いくつかの転移学習タスクでの最先端のパフォーマンスさえも上回っています。 
[要約]提案された表現は埋め込みを比較するために使用できます-音声コミュニティはまだそうしていません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-25">
        <br>2020-02-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Streaming Language Identification using Combination of Acoustic
  Representations and ASR Hypotheses -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/eess.AS/paper_9.html">
      Streaming Language Identification using Combination of Acoustic
  Representations and ASR Hypotheses
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、教師モデルとして新しく提案されたモデルアーキテクチャを使用して、半教師あり学習（SSL）技術を採用することにより、改善された結果を示しています。さらに、処理コストとレイテンシを削減するために、ストリーミングアーキテクチャを活用して、音声言語を早期に識別します。システムは所定の信頼レベルに達し、入力クエリの最後まで複数のASRシステムを実行する必要性を軽減します。音響レベルの表現を学習し、ASR仮説で推定された埋め込みと組み合わせて、最大50％の相対削減をもたらすアプローチを提案します。音響のみの機能を使用するモデルと比較した、識別エラー率。 
[要約]音響システムとテキストシステムを組み合わせて使用すると、平均して1500ミリ秒の早期識別が可能であり、50％以上の発話が可能
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Evaluation of CNN-based Automatic Music Tagging Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/eess.AS/paper_10.html">
      Evaluation of CNN-based Automatic Music Tagging Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、評価のために異なるデータセットの分割やソフトウェアバージョンを使用するなど、研究者が行った実験設定の違いにより、提案されたアーキテクチャを互いに直接比較することは困難です。 3つのデータセット（MagnaTagATune、Million Song Dataset、およびMTG-Jamendo）のさまざまな音楽タグ付けモデルの一貫した評価と、一般的な評価指標（ROC-AUCおよびPR-AUC）を使用した参照結果を提供します。再現性のために、PyTorchの実装に事前トレーニング済みモデル。 
[ABSTRACT]新しいアーキテクチャは、畳み込みニューラルネットワーク（cnns）に基づいています。これらのアーキテクチャは、このマルチラベルバイナリ分類タスクで最先端の結果を達成するように設計されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Cross-cultural data shows musical scales evolved to maximise imperfect
  fifths -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/eess.AS/paper_11.html">
      Cross-cultural data shows musical scales evolved to maximise imperfect
  fifths
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      スケールはさまざまな選択圧力に従って進化しているように見えますが、最も単純なhの5分の1のパッキングモデルは、経験的なデータに最もよく適合します。パッキング引数は、分布の顕著な特徴を説明します。間隔が圧縮可能である場合、スケールも推奨されます。これにより、メロディーの効率的な通信と記憶が容易になります。 
[ABSTRACT]スケールは調和系列に基づいていますが、伝達するのは簡単ではありません。単純なh不完全-5分の1のパッキングモデルはデータに最もよく適合します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-13">
        <br>2019-06-13
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Lung Bronchial Epithelial Cells are HIV Targets for Proviral Genomic Integration -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/biorxiv.physiology/paper_0.html">
      Lung Bronchial Epithelial Cells are HIV Targets for Proviral Genomic Integration
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人間の気管支上皮細胞（HBECs）はHIV共受容体を発現し、肺の免疫応答の調節に重要ですが、HIVの伝染におけるそれらの役割は不明のままです。 / reservoir、OLDsと他のHIV関連の肺併存症に貢献しています。ここでは、HIV-1が正常なHBECに感染し、ウイルスDNAがウイルス潜伏期を確立するためにゲノムに組み込まれているという証拠を提示します。 
[要約]ヒト気管支上皮腫瘍細胞（hbecs）はhivコレセプターを発現します。これらは肺の免疫応答の調節に重要です。しかしhivの伝達におけるそれらの役割は不明のままです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ToR-ORd-dynCl: an update of the ToR-ORd model of human ventricular cardiomyocyte with dynamic intracellular chloride -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-02/biorxiv.physiology/paper_1.html">
      ToR-ORd-dynCl: an update of the ToR-ORd model of human ventricular cardiomyocyte with dynamic intracellular chloride
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      モデルキャリブレーションは、主要な生理学的細胞機能の再現を保証し、独立したマルチスケール検証により、チャネル遮断薬および病態生理学的リモデリングに対する正しい応答を実証しました。モデルの複雑さが少し増加します。これは、非常に長いプロトコルを考慮したシミュレーション、またはモデルの安定性に関する研究の制限となる場合があります。 
[ABSTRACT] tor-ord-dynclは、人間の実験データを使用して作成されました。キャリブレーションと検証は、主要な人間のデータを使用して実行されました。塩化物濃度を定数値としてモデル化することにより、その動作にドリフトが見られました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br>2020-06-01
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
