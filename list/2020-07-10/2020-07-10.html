<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-07-10の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: DeepSinger: Singing Voice Synthesis with Data Mined From the Web -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.SD/paper_0.html">
      <font color="black">DeepSinger: Singing Voice Synthesis with Data Mined From the Web</font>
    </a>
  </h2>
  <font color="black">結果は、Webから純粋にマイニングされた歌唱データを使用して、DeepSingerがピッチの正確さと音声の自然さの両方の観点から高品質の歌声を合成できることを示しています（脚注：音声サンプルはhttps://speechresearch.github.io/に示されています） deepsinger /。）。 DeepSingerには、以前のSVSシステムに比べていくつかの利点があります。1）私たちの知る限り、これは音楽Webサイトからトレーニングデータを直接マイニングする最初のSVSシステムです。2）歌詞と歌唱のアラインメントモデルは、アラインメントのための人間の努力をさらに回避します。ラベリングし、ラベリングコストを大幅に削減します。3）フィードフォワードトランスフォーマーに基づく歌唱モデルは、パラメトリック合成の複雑な音響機能モデリングを削除し、リファレンスエンコーダーを利用して歌手のデータをノイズの多い歌唱データからキャプチャすることにより、シンプルで効率的です。 、および4）複数の言語と複数の歌手で歌声を合成できます。具体的には、歌詞と歌声のアラインメントモデルを設計して、粗粒度の文レベルから細かい粒度まで、歌詞の各音素の継続時間を自動的に抽出します。音素レベル、さらにフィードフォワードトランスフォーマーに基づく多言語、マルチシンガー歌唱モデルを設計して、歌詞から線形スペクトログラムを直接生成し、 d Griffin-Limを使用して音声を合成します。 
[ABSTRACT] deepsingerは、音楽Webサイトからトレーニングデータを直接マイニングする最初のsvsシステムです。ピッチ精度と音声の自然さの点で、高品質の歌声を合成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: RWCP-SSD-Onomatopoeia: Onomatopoeic Word Dataset for Environmental Sound
  Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.SD/paper_1.html">
      <font color="black">RWCP-SSD-Onomatopoeia: Onomatopoeic Word Dataset for Environmental Sound
  Synthesis</font>
    </a>
  </h2>
  <font color="black">この論文では、このようにRWCP-SSD-Onomatopoeiaを提示します。これは、155,568の擬音語と音声サンプルを組み合わせた環境音合成からなるデータセットです。擬音語を使用すると、合成音の細かい時間周波数構造を制御できると考えています。 ..環境音合成は、自然な環境音を生成する技術です。 
[ABSTRACT]環境音の合成では、サウンドイベントラベルを使用して環境を作成します。ただし、環境音に使用できるデータセットはありません。また、自己報告された信頼スコアなど、オノマトペ単語の受容スコアも収集しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-task Regularization Based on Infrequent Classes for Audio
  Captioning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.SD/paper_2.html">
      <font color="black">Multi-task Regularization Based on Infrequent Classes for Audio
  Captioning</font>
    </a>
  </h2>
  <font color="black">オーディオキャプションの重要な課題は、キャプション内の単語の分布です。いくつかの単語は非常に頻繁ですが、音響的には情報を提供しません。 captions）..この論文では、このクラスの不均衡の問題を緩和するための2つの方法を提案します。 
[ABSTRACT]オーディオキャプションの自動エンコーダ設定で、トレーニング損失に対する各単語の寄与を、データセット全体での発生数に反比例して重み付けします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: MuSe 2020 -- The First International Multimodal Sentiment Analysis in
  Real-life Media Challenge and Workshop -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.SD/paper_3.html">
      <font color="black">MuSe 2020 -- The First International Multimodal Sentiment Analysis in
  Real-life Media Challenge and Workshop</font>
    </a>
  </h2>
  <font color="black">サブチャレンジごとに、参加者の競争力のあるベースラインが設定されます。つまり、テストでは、MuSe-Wildの結合した（価数と覚醒）CCCが2568、MuSe-Topicのスコア（0.34 $ \ cdot $ UAR + 0.66 $ \ cdot $ F1として計算）が76.78％ 10クラスのトピック、3クラスの感情予測で40.64％、MuSe-Trustの場合、.4359のCCC。MuSe2020の目的は、さまざまな分野のコミュニティをまとめることです。主に、視聴覚感情認識コミュニティ（シグナルベース）、および感情分析コミュニティ（シンボルベース）です。このホワイトペーパーでは、MuSe-CaRについて詳しく説明します。挑戦のために利用されるデータベース、ならびに適用される最先端の機能およびモデリングアプローチ。 
[ABSTRACT] muse-車はその種の最初の-より包括的なデータベースです。これは、課題と同様に利用されます。8.museの目的は、さまざまな分野のコミュニティをまとめることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.SD/paper_4.html">
      <font color="black">PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern
  Recognition</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、AudioSetでトレーニングされた事前トレーニング済みのオーディオニューラルネットワーク（PANN）を提案します。次に、PANNを他のオーディオ関連タスクに転送します。さまざまな畳み込みニューラルネットワークでモデル化されたPANNのパフォーマンスと計算の複雑さを調査します。 
[ABSTRACT]このペーパーでは、重要なトピックでトレーニングされた事前トレーニング済みのオーディオニューラルネットワーク（パン）を提案します。パン転送の最適なシステムは、最新の平均平均精度（マップ）です。ソースコードをリリースし、事前トレーニング済みパンのモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-21">
        <br><font color="black">2019-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Capturing scattered discriminative information using a deep architecture
  in acoustic scene classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.SD/paper_5.html">
      <font color="black">Capturing scattered discriminative information using a deep architecture
  in acoustic scene classification</font>
    </a>
  </h2>
  <font color="black">最大フィーチャマップ法を採用して、ディープニューラルネットワークの従来の非線形アクティベーションを置き換えるため、畳み込み層の出力の異なるフィルター間で要素ごとの比較を適用します。多くの共通の音響を共有するクラスの頻繁に誤って分類されたペアプロパティは、音響シーン分類（ASC）に存在します。提案された方法を検証するために、音響シーンとイベント2020 task1-aデータセットの検出と分類を使用して、さまざまな実験が行われます。 
[ABSTRACT]提案されたシステムは一貫してベースラインを上回っています。単一の最高性能システムは70の精度を持っています。4％.2つのデータ補強方法と2つのディープアーキテクチャモジュールが過剰適合を減らすためにさらに検討されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Neural Video Coding using Multiscale Motion Compensation and
  Spatiotemporal Context Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_0.html">
      <font color="black">Neural Video Coding using Multiscale Motion Compensation and
  Spatiotemporal Context Model</font>
    </a>
  </h2>
  <font color="black">NVCの新しい機能は次のとおりです。1）広範囲の大きさにわたってモーションを推定して補正するために、マルチスケールフローフィールドを生成するモーション機能をコーディングするために、VAEのピラミッドデコーダーとともに監視なしマルチスケールモーション補正ネットワーク（MS-MCN）を提案します。 、2）モーション情報の効率的なエントロピーコーディング用の新しい適応時空間コンテキストモデルを設計します。3）VAEのボトルネックで非ローカルアテンションモジュール（NLAM）を採用し、暗黙的な適応機能の抽出とアクティブ化により、高い変換能力と不平等を活用します。共同のグローバル情報とローカル情報による重み付け、4）マルチモジュール最適化とマルチフレームトレーニング戦略を導入して、Pフレーム間の時間エラー伝搬を最小限に抑えます。NVCは低遅延の因果設定について評価され、Hと比較されます。 .265 / HEVC、H.264 / AVC、および一般的なテスト条件に従ったその他の学習したビデオ圧縮方法により、すべてのpで一貫したゲインを示しますPSNRとMS-SSIMの両方の歪みメトリックのopularテストシーケンス。いくつかの以前の作品は、従来の方法と比較して大きな可能性を示す、エンドツーエンドの方法で学習したビデオコーディングアルゴリズムを探索しました。 
[要約]エンドツーエンドのディープニューラルビデオコーディングフレームワーク（nvc）を提案します。変分オートエンコーダー（vaes）を使用して、フレーム内ピクセル、系列の動き、およびフレーム間補償の残差の相関を活用します。これらには超解像度が含まれます3（4）と2（dnnder）は、一般的なテスト条件に従ってビデオ圧縮方法を学習しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Interpretable Deep Models for Cardiac Resynchronisation Therapy Response
  Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_1.html">
      <font color="black">Interpretable Deep Models for Cardiac Resynchronisation Therapy Response
  Prediction</font>
    </a>
  </h2>
  <font color="black">ディープラーニング（DL）の進歩により、一部の医用画像分類タスクで印象的な精度が得られましたが、多くの場合、ディープモデルには解釈性がありません。CRT応答予測のタスクに関する提案モデルの感度と特異度は、それぞれ88.43％と84.39％です。また、CRT応答に寄与する要因の理解を高めるためのモデルの可能性を紹介します。変分オートエンコーダー（VAE）に基づく画像ベースの分類のための新しいDLフレームワークを提案します。 
[ABSTRACT]モデルモデルモデルモデルモデルはcrt応答にリンクされています。モデルモデルモデルモデルはバイオマーカーまたはバイオマーカーにリンクされている可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-24">
        <br><font color="black">2020-06-24</font>
      </time>
    </span>
</section>
<!-- paper0: Prostate motion modelling using biomechanically-trained deep neural
  networks on unstructured nodes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_2.html">
      <font color="black">Prostate motion modelling using biomechanically-trained deep neural
  networks on unstructured nodes</font>
    </a>
  </h2>
  <font color="black">さらに、トレーニング時のブートストラップサンプリングとモデルの平均推論で構成されるさまざまな患者の形状に起因する可変数の特徴ベクトルに対応するために、多目的なブートストラップ集約メカニズムが検証されています。次に、ポイントセットにポイント固有の材料特性が割り当てられますおよび変位荷重。順序付けされていない入力特徴ベクトルを形成します。グラウンドトゥルースデータとして有限要素（FE）シミュレーションを使用して、節点変位を予測するように適応PointNetをトレーニングできます。 
[ABSTRACT] pointnetは、特定の関心領域を予測するようにトレーニングできます。非構造化画像に基づいて、ユーザーは非構造化画像に割り当てられます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Texture Hallucination for Large-Factor Painting Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_3.html">
      <font color="black">Texture Hallucination for Large-Factor Painting Super-Resolution</font>
    </a>
  </h2>
  <font color="black">同時に、画像再構成損失によってもたらされる平滑化効果を減らすために、縮小された超解像結果と低解像度入力との間の一貫性を保証する劣化損失で再構成制約をさらに緩和します。超解像を目指します。デジタルペインティング、非常に大きなスケールファクター（8X、16Xなど）の高解像度リファレンスペインティングマテリアルからリアルなディテールを合成します。より詳細なテクスチャを転送するために、ウェーブレットテクスチャ損失を設計します。これにより、高周波コンポーネントを強化できます。 
[ABSTRACT]以前の単一画像の超解像（sisr）メソッドは、テクスチャの詳細を失うか、不快なアーティファクトを導入します。これらの問題を解決するために、損失によってもたらされるスムージング効果を減らすのに役立つ効率的な高解像度幻覚ネットワークを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-01">
        <br><font color="black">2019-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: PAD-UFES-20: a skin lesion dataset composed of patient data and clinical
  images collected from smartphones -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_4.html">
      <font color="black">PAD-UFES-20: a skin lesion dataset composed of patient data and clinical
  images collected from smartphones</font>
    </a>
  </h2>
  <font color="black">皮膚病変の100％を含む、皮膚病変の58.4％は生検で証明されています。このギャップを埋めるために、スマートフォンデバイスから収集された臨床画像と、以下を含む一連の患者の臨床データで構成される皮膚病変ベンチマークをリリースします。最大22の機能..データセットは、1,373例の患者、1,641の皮膚病変、6種類の診断（3種類の皮膚疾患と3種類の皮膚癌）の2,298画像で構成されています。 
[要約]データセットは、患者1,373人、皮膚病変1,641個、画像2,298個で構成されています。データセットには、3つの皮膚疾患と3つの皮膚癌の4つの異なる診断情報が含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-01">
        <br><font color="black">2020-07-01</font>
      </time>
    </span>
</section>
<!-- paper0: Tractogram filtering of anatomically non-plausible fibers with geometric
  deep learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_5.html">
      <font color="black">Tractogram filtering of anatomically non-plausible fibers with geometric
  deep learning</font>
    </a>
  </h2>
  <font color="black">この研究では、最近のヒューリスティック手法で得られたグラウンドトゥルースアノテーションを活用して、トラクトグラムフィルタリングの問題を教師あり学習問題として扱います。 、これらの繊維の大部分は解剖学的に妥当ではなく、追跡アルゴリズムのアーチファクトと見なすことができます。 
[ABSTRACT]これらのファイバーの大部分は解剖学的に妥当ではなく、追跡アルゴリズムのアーティファクトと見なすことができます。これは動的エッジコンボリューションモデルの拡張です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-24">
        <br><font color="black">2020-03-24</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient detection of adversarial images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_6.html">
      <font color="black">Efficient detection of adversarial images</font>
    </a>
  </h2>
  <font color="black">数値実験は、提案された検出方式が競合アルゴリズムよりも優れている一方で、計算の複雑さがかなり低いことを示しています。提案された前処理アルゴリズムは、主成分分析（PCA）ベースの画像の特定の組み合わせと、ランダム摂動ベースの検出を含みます。計算の複雑さを軽減します。次に、このアルゴリズムの適応バージョンを提案します。ここでは、ランダムな数の摂動が二重しきい値ポリシーを使用して適応的に選択され、予測される摂動数を最小限にするために、確率的近似によってしきい値が学習されます。誤警報と見逃された検出確率の制約に。 
[要約]一部の調査では、悪意のある詐欺攻撃に対するdnnの脆弱性が示されています。このような攻撃は、多くのコンピューターベースの画像の攻撃と似ています。これらには、そのような変更された画像を検出する前処理技術が含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Attention-based Residual Speech Portrait Model for Speech to Face
  Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_7.html">
      <font color="black">Attention-based Residual Speech Portrait Model for Speech to Face
  Generation</font>
    </a>
  </h2>
  <font color="black">この目的のために、この論文では、顔の前の機能が音声の出力とマージされるハイブリッドエンコーダー/デコーダーアーキテクチャに残差の理想を導入することにより、新しい注意ベースの残差音声ポートレートモデル（AR-SPM）を提案します。最終的な顔の特徴を形成するエンコーダー。特に、L2ノルム、L1ノルム、負の余弦損失の重み付き線形結合である3項目損失関数を革新的に確立し、最終的な顔の特徴と真の顔の特徴..話者のスピーチを前提として、この話者の顔を生成できるかどうかを確認するのは興味深いことです。 
[要約]主な課題は、顔と音声の不一致を緩和することです。これは、言語を使用する機能で不一致を緩和することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Early Exit Or Not: Resource-Efficient Blind Quality Enhancement for
  Compressed Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_8.html">
      <font color="black">Early Exit Or Not: Resource-Efficient Blind Quality Enhancement for
  Compressed Images</font>
    </a>
  </h2>
  <font color="black">具体的には、私たちのアプローチは、ダイナミックディープニューラルネットワーク（DNN）を介して圧縮画像の品質を盲目的に段階的に向上させます。DNNには早期終了戦略が組み込まれています。通信帯域幅を節約するために損失のある画像圧縮が広範に行われ、望ましくない圧縮アーティファクトが発生します。 ..次に、私たちのアプローチは、強化された画像の評価された品質に従って、強化を終了するか続行するかを自動的に決定できます。 
[要約]このホワイトペーパーでは、リソース効率の高いブラインド品質向上（rbqe）モデルを提案します。具体的には、私たちのアプローチは、強化された画像の評価された品質に応じて、強化を自動的に終了または続行することを決定できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br><font color="black">2020-06-30</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-end Learned Image Compression with Fixed Point Weight
  Quantization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_9.html">
      <font color="black">End-to-end Learned Image Compression with Fixed Point Weight
  Quantization</font>
    </a>
  </h2>
  <font color="black">2番目に、最適なグループ化と量子化スキームを探索します。最後に、新しいウェイトクリッピング微調整スキームを開発します。学習画像圧縮（LIC）は、JPEG2000やBPGなどの伝統的な手作りの方法に到達しました。 。 
[ABSTRACT]ネットワークのモデルサイズが大きいため、リソースが限られた組み込みシステムでのlicの使用が禁止されています。これは、固定小数点の重みでlicを完全に調査および評価する最初の作業です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Modelling the Distribution of 3D Brain MRI using a 2D Slice VAE -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_10.html">
      <font color="black">Modelling the Distribution of 3D Brain MRI using a 2D Slice VAE</font>
    </a>
  </h2>
  <font color="black">また、セグメンテーションが真の脳の解剖学とどれだけ一致するかを定量化する、生成されたボリュームの新しい評価方法を紹介します。2DスライスVAEとガウスモデルを組み合わせて、3D MR脳ボリュームの分布をモデル化する方法を提案します。スライス..確率的モデリングは、特に脳の磁気共鳴画像（MRI）を分析するための医用画像分析において不可欠なツールです。 
[要約]新しい方法は、3D mr脳ボリューム分布をモデル化するために使用できます。2DスライスVAEとスライス間の関係をキャプチャするモデルを組み合わせます。この組み合わせモデルにより、潜在変数の新しいコヒーレントスタックをサンプリングして、ボリューム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: An Open-source Tool for Hyperspectral Image Augmentation in Tensorflow -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_11.html">
      <font color="black">An Open-source Tool for Hyperspectral Image Augmentation in Tensorflow</font>
    </a>
  </h2>
  <font color="black">Tensorflowツールは、ディープラーニングモデルの迅速なプロトタイピングとテストを可能にしますが、その組み込み画像ジェネレーターは最大4つのスペクトルチャネルを処理するように設計されています。Tensorflowがいかにアクセスしやすく使いやすいかを考えると、このツールは多くの機能を提供します。リモートセンシングアプリケーションのディープラーニングモデルを実装、テスト、展開する手段を備えた研究者。これには、リモートセンシングのドメインでのユーティリティの評価を可能にする衛星画像のディープラーニングモデルを最適化する研究努力が必要です。 
[要約]コンピュータビジョンシステムの急速な発展により、衛星画像の使用に新たな地平が開かれる可能性があります。これらの画像は衛星画像とは異なる分布を示しますが、これらの画像は衛星画像とは異なるサブセットのみを表示します。これにより、研究努力を最適化できます。衛星画像のディープラーニングモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br><font color="black">2020-03-30</font>
      </time>
    </span>
</section>
<!-- paper0: Medical Instrument Detection in Ultrasound-Guided Interventions: A
  Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_12.html">
      <font color="black">Medical Instrument Detection in Ultrasound-Guided Interventions: A
  Review</font>
    </a>
  </h2>
  <font color="black">最後に、いくつかの主要な出版物を選択して、コンピューター支援介入コミュニティの主要な問題と潜在的な研究の方向性を要約しました。最初に、従来の非データ駆動の方法とデータ駆動の方法を含む機器検出方法の包括的なレビューを提示します。メソッド..非データ主導のメソッドは、機械学習の時代の前に広範囲にわたって研究されました。つまり、
[要約]超音波における医療機器検出の主な臨床アプリケーションについて説明します。これらには、麻酔、生検、前立腺近接照射療法、心臓カテーテル検査が含まれます。これらのアプリケーションは臨床データセットで検証されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Algorithm Unrolling: Interpretable, Efficient Deep Learning for Signal
  and Image Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_13.html">
      <font color="black">Algorithm Unrolling: Interpretable, Efficient Deep Learning for Signal
  and Image Processing</font>
    </a>
  </h2>
  <font color="black">この記事では、信号と画像処理のアルゴリズム展開を検討します。ディープニューラルネットワークは、信号と画像処理の多くの現実世界の問題で前例のないパフォーマンスの向上を実現します。最近、この方向は非常に注目され、理論的に急速に成長しています。調査および実用的なアプリケーション。 
[ABSTRACT]実際のネットワークの人気が高まっているのは、妥当なサイズのトレーニングセットから効率的で高性能でありながら解釈可能なネットワークアーキテクチャを開発する可能性があるためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-22">
        <br><font color="black">2019-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Weakly supervised multiple instance learning histopathological tumor
  segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_14.html">
      <font color="black">Weakly supervised multiple instance learning histopathological tumor
  segmentation</font>
    </a>
  </h2>
  <font color="black">$ 6481 $で生成された腫瘍マップとデータ処理を含む完全なフレームワークは、\ url {https://github.com/marvinler/tcga\_segmentation} ..で入手できます。特に、トレーニングモデルには複数インスタンスの学習スキームを利用しています。この論文では、ほとんどの医療システムで利用可能な標準の臨床アノテーションに依存するスライド全体の画像セグメンテーションのための弱く監視されたフレームワークを提案します。 
[ABSTRACT]最先端の方法は手作りの注釈に依存しています。組織学は、がんの表現型間の有意差に悩まされています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-10">
        <br><font color="black">2020-04-10</font>
      </time>
    </span>
</section>
<!-- paper0: Cortical surface registration using unsupervised learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_15.html">
      <font color="black">Cortical surface registration using unsupervised learning</font>
    </a>
  </h2>
  <font color="black">SphereMorphは、球形カーネルに関連付けられたUNetスタイルのネットワークを使用して変位場を学習し、修正された空間変換層を使用して球をワープします。この研究では、これらに対処する深層ネットワークを使用した皮質表面の微分同相登録フレームワークであるSphereMorphを提示します。問題..実験は、提案されたSphereMorphがCNNフレームワークで幾何学的レジストレーション問題をモデル化でき、優れたレジストレーション精度と計算効率を実証することを示しています。 
[ABSTRACT]その空間で皮質の折りたたみパターンを位置合わせして位置合わせを行うには、表面特性の球体表現が必要です。cnnsは、体積の位置合わせを劇的に高速化する可能性を示しています。しかし、cnnsは、歪みやその他の形式のデータフィッティングで、新しいツールを開発するために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: Low Dose CT Denoising via Joint Bilateral Filtering and Intelligent
  Parameter Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_16.html">
      <font color="black">Low Dose CT Denoising via Joint Bilateral Filtering and Intelligent
  Parameter Optimization</font>
    </a>
  </h2>
  <font color="black">最近、ディープラーニング手法がCT画像のノイズ除去に使用されて成功しています。この手法は、最先端のディープニューラルネットワークを大幅に上回っています。報酬ネットワークは、強化学習タスクを指示するように設計されています。 
[ABSTRACT]現在臨床的に承認されている方法は、ct画像のノイズを低減するために反復再構成法を使用しています。臨床画像の状況での使用に必要な説明責任が低くなっています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Motion-Attentive Transition for Zero-Shot Video Object Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_17.html">
      <font color="black">Motion-Attentive Transition for Zero-Shot Video Object Segmentation</font>
    </a>
  </h2>
  <font color="black">さらに、ブリッジネットワークが提案されて、マルチレベルエンコーダー機能のコンパクトで判別的でスケールに敏感な表現を取得し、さらにデコーダーに入力してセグメンテーション結果を達成します。このようにして、エンコーダーは深くインターリーブされ、オブジェクトの動きと外観の間の密接に階層的な相互作用。これは、各ストリームで動きと外観を個別に扱い、外観情報への過剰適合に悩まされることが多い、典型的な2ストリームアーキテクチャより優れています。 
[ABSTRACT]モーション-注意深い遷移（マット）は、2ストリームエンコーダー内で設計されています。これは、外観機能を各畳み込みステージでモーション-減衰表現に変換します。これは、モーションと外観を別々に処理する一般的な2ストリームアーキテクチャより優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br><font color="black">2020-03-09</font>
      </time>
    </span>
</section>
<!-- paper0: Towards an Effective and Efficient Deep Learning Model for COVID-19
  Patterns Detection in X-ray Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_18.html">
      <font color="black">Towards an Effective and Efficient Deep Learning Model for COVID-19
  Patterns Detection in X-ray Images</font>
    </a>
  </h2>
  <font color="black">健康な非COVID-19肺炎とCOVID-19患者に分割された13,569 X線画像のデータセットを使用して、提案されたアプローチと他の5つの競合するアーキテクチャをトレーニングします。COVID-19同定の標準的な方法である逆転写ポリメラーゼ連鎖反応法は、パンデミックのために時間がかかり、不足しています。これらの方法の成功にもかかわらず、これらの方法の計算コストは高いままであり、アクセスと可用性に困難を課しています。 
[要約]この作業の主な目的は、胸部X線でのcovid-19スクリーニングの問題に対する正確な方法を提案することです。この方法に加えて、3つのクラスの230枚以上の画像を使用して、メソッド</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-12">
        <br><font color="black">2020-04-12</font>
      </time>
    </span>
</section>
<!-- paper0: JBFnet -- Low Dose CT Denoising by Trainable Joint Bilateral Filtering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_19.html">
      <font color="black">JBFnet -- Low Dose CT Denoising by Trainable Joint Bilateral Filtering</font>
    </a>
  </h2>
  <font color="black">JBFnetは4つのフィルタリングブロックに分割され、それぞれが結合バイラテラルフィルタリングを実行します。ガイダンス画像は、ディープニューラルネットワークによって推定されます。結合バイラテラルフィルター（JBF）のフィルター機能は、浅い畳み込みネットワークを介して学習されます。 
[要約]ジョイントバイラテラルフィルターのフィルター機能は、浅い畳み込みネットワークを介して学習されます。jbfnetは4つのフィルタリングブロックに分割され、それぞれがジョイントバイラテラルフィルタリングを実行します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: A Deep Joint Sparse Non-negative Matrix Factorization Framework for
  Identifying the Common and Subject-specific Functional Units of Tongue Motion
  During Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_20.html">
      <font color="black">A Deep Joint Sparse Non-negative Matrix Factorization Framework for
  Identifying the Common and Subject-specific Functional Units of Tongue Motion
  During Speech</font>
    </a>
  </h2>
  <font color="black">この作業では、これらの課題に対処するために、スピーチ中の舌の動きの共通および被験者固有の機能単位を特定するための新しい深層学習フレームワークを開発します。シミュレーションデータセットを使って行った実験は、提案された方法が比較方法を上回っていることを示しています。詳細具体的には、反復的収縮しきい値処理アルゴリズムを展開して解釈可能な構築ブロックと関連する重み付けマップを学習することにより、スパースで多様な正則化を伴うNMFをディープニューラルネットワークに類似したモジュラーアーキテクチャに変換します。 
[要約]提案された方法は、共通性と被験者固有の機能単位を決定でき、解釈性が向上し、サイズのばらつきが減少します。被験者間で識別された単位を、それらの実質的なばらつきにより比較できるように保つことは困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Attention Neural Network for Trash Detection on Water Channels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_21.html">
      <font color="black">Attention Neural Network for Trash Detection on Water Channels</font>
    </a>
  </h2>
  <font color="black">この論文の終わりに向けて、我々の手法と最先端の物体検出器との詳細な比較を提供し、この手法が小さな物体の検出を大幅に改善することを示します。この論文では、目に見えるゴミの検出方法を提案します。都市部の運河の水面に浮かぶ。オブジェクトレベルの注釈を含む大きなデータセット、最初の種類は水路のゴミ。 
[ABSTRACT]これにより淡水路が汚染され、下水道が閉塞します。ゴミは水面に浮いていることがよくあります。データセットは一般に公開されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Brain Tumor Anomaly Detection via Latent Regularized Adversarial Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.IV/paper_22.html">
      <font color="black">Brain Tumor Anomaly Detection via Latent Regularized Adversarial Network</font>
    </a>
  </h2>
  <font color="black">脳腫瘍データと希少なラベル付きデータの不均衡を目指して、革新的な脳腫瘍異常検出アルゴリズムを提案します。健康な（正常な）脳画像のみをトレーニングする半教師付き異常検出モデルを提案します。モデルトレーニングプロセスで通常の画像の一般的なパターンをキャプチャし、潜在空間の再構成エラーに基づいて異常を検出します。 
[要約]半監視付きの異常検出モデルが提案されており、健康な脳の画像のみがトレーニングされます。この方法では、最初に特異値を使用して潜在空間を制約し、複数の損失関数の基礎を共同最適化して、正常なサンプルと異常なサンプルをさらに増やします分離可能</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: A Cordial Sync: Going Beyond Marginal Policies for Multi-Agent Embodied
  Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_0.html">
      <font color="black">A Cordial Sync: Going Beyond Marginal Policies for Multi-Agent Embodied
  Tasks</font>
    </a>
  </h2>
  <font color="black">データセット、コード、事前トレーニング済みのモデルは、https：//unnat.github.io/cordial-syncで入手できます。SYNCポリシーとCORDIALを使用して、エージェントはFurnMoveで58％の完了率を達成しました。分散型の競争力のあるベースラインを超えるパーセンテージポイント。グリッドワールドのような環境でマルチエージェントコラボレーションの研究が盛んに行われている一方で、視覚的にリッチなドメインを検討する作業は比較的わずかです。 
[ABSTRACT]エージェントは共同で家具をリビングルームからゴールまで動かします。furnmoveで58％の完了率が得られます。これは、競争力のある分散ベースラインよりも25パーセントポイントも印象的です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Pedestrian Detection: The Elephant In The Room -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_1.html">
      <font color="black">Pedestrian Detection: The Elephant In The Room</font>
    </a>
  </h2>
  <font color="black">したがって、実験を通じて、汎用オブジェクト検出器は、最新の歩行者検出器と比較して直接クロスデータセット評価でより効果的に機能することがわかり、Webのクロールによって収集された多様で高密度のデータセットは、歩行者検出のための事前トレーニングの効率的なソースです。2つ目は、トレーニングソースは一般的に歩行者が密集しておらず、シナリオが多様であるということです。1つ目は、従来の単一データセットのトレーニングとテストパイプラインの一般的なデータセットに適合しすぎています。 
[ABSTRACT]既存の状態-最先端の歩行者検出器は、あるデータセットから別のデータセットへの一般化が不十分です。また、汎用オブジェクト検出器が直接クロスデータセット評価でうまく機能するという懸念もあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-19">
        <br><font color="black">2020-03-19</font>
      </time>
    </span>
</section>
<!-- paper0: Inertial Measurements for Motion Compensation in Weight-bearing
  Cone-beam CT of the Knee -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_2.html">
      <font color="black">Inertial Measurements for Motion Compensation in Weight-bearing
  Cone-beam CT of the Knee</font>
    </a>
  </h2>
  <font color="black">提示された研究は、この新しいアプローチの実現可能性を示し、CアームCTでの純粋なIMUベースのモーション補正に向けて有望な結果をもたらします。このモーションでは、XCAT数値膝ファントムは、CTスキャンの作成中に非剛体的に変形します。モーションプロジェクションが破損しました。膝の重量を支えるコーンビームコンピュータ断層撮影（CT）スキャン中の不随意運動により、再構成されたボリュームにアーティファクトが発生し、臨床診断に使用できなくなります。 
[ABSTRACT]現在、画像ベースまたはマーカーベースの方法がこの動きを修正するために適用されていますが、多くの場合、実行または準備に長い時間が必要です。これらの結果は、最先端のマーカーベースのアプローチに基づいています。それらは、光学3D追跡システムで測定された実際の動きを使用した研究と比較されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Video Coding using Multiscale Motion Compensation and
  Spatiotemporal Context Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_3.html">
      <font color="black">Neural Video Coding using Multiscale Motion Compensation and
  Spatiotemporal Context Model</font>
    </a>
  </h2>
  <font color="black">NVCの新しい機能は次のとおりです。1）広範囲の大きさにわたってモーションを推定して補正するために、マルチスケールフローフィールドを生成するモーション機能をコーディングするために、VAEのピラミッドデコーダーとともに監視なしマルチスケールモーション補正ネットワーク（MS-MCN）を提案します。 、2）モーション情報の効率的なエントロピーコーディング用の新しい適応時空間コンテキストモデルを設計します。3）VAEのボトルネックで非ローカルアテンションモジュール（NLAM）を採用し、暗黙的な適応機能の抽出とアクティブ化により、高い変換能力と不平等を活用します。グローバル情報とローカル情報を組み合わせた重み付け、4）マルチモジュール最適化とマルチフレームトレーニング戦略を導入して、Pフレーム間の時間エラー伝搬を最小限に抑えます。以前のいくつかの研究では、学習したビデオコーディングアルゴリズムをエンド従来の方法と比較して大きな可能性を示すエンドエンドの方法です。NVCは、低遅延の因果設定とcom H.265 / HEVC、H.264 / AVC、および一般的なテスト条件に従って学習したその他のビデオ圧縮方法と比較して、PSNRとMS-SSIMの両方の歪みメトリックの一般的なすべてのテストシーケンスで一貫したゲインを示しています。 
[要約]エンドツーエンドのディープニューラルビデオコーディングフレームワーク（nvc）を提案します。変分オートエンコーダー（vaes）を使用して、フレーム内ピクセル、系列の動き、およびフレーム間補償の残差の相関を活用します。これらには超解像度が含まれます3（4）と2（dnnder）は、一般的なテスト条件に従ってビデオ圧縮方法を学習しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: A Systematic Review on Context-Aware Recommender Systems using Deep
  Learning and Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_4.html">
      <font color="black">A Systematic Review on Context-Aware Recommender Systems using Deep
  Learning and Embeddings</font>
    </a>
  </h2>
  <font color="black">系統的レビューは、書誌的レビューを実行するための正式かつ体系的な方法を採用しており、公開された関連研究を分析することにより、特定の研究分野におけるすべての研究を特定および評価するために使用されます。学習と埋め込みの技術を適用して、コンテキスト認識型の推奨システムを改善しています。より適切な推奨を生成するには、推奨プロセスで情報のコンテキストを使用する必要があります。 
[要約]状況認識型レコメンダーシステムを改善するために手法がどのように適用されているかを理解するためにレビューが行われました。最も顕著な進歩の2つは、レコメンダーシステムでデータを表すための埋め込みの使用です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: InfoMax-GAN: Improved Adversarial Image Generation via Information
  Maximization and Contrastive Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_5.html">
      <font color="black">InfoMax-GAN: Improved Adversarial Image Generation via Information
  Maximization and Contrastive Learning</font>
    </a>
  </h2>
  <font color="black">これを達成するには、GANに対照的な学習と相互情報の最大化アプローチを採用し、改善の原因を理解するために広範な分析を実行します。再現性については、https：//github.com/kwotsin/mimicryでコードを利用できます。は、GANトレーニングを大幅に安定させ、最新の作品に対する同じトレーニングおよび評価条件下で5つのデータセットにわたる画像合成のGANパフォーマンスを向上させます。 
[要約]この作業では、ガンの2つの基本的な問題に対処するための原則的なフレームワークを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Interpretable Deep Models for Cardiac Resynchronisation Therapy Response
  Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_6.html">
      <font color="black">Interpretable Deep Models for Cardiac Resynchronisation Therapy Response
  Prediction</font>
    </a>
  </h2>
  <font color="black">変分オートエンコーダー（VAE）に基づく画像ベースの分類のための新しいDLフレームワークを提案します。このフレームワークにより、オートエンコーダーの潜在空間から関心のある出力を予測できるだけでなく、決定の境界を越えて分類子の解釈可能性を高める効果。さらに、医学の多くの問題について、既存の臨床知識が豊富にあり、説明を生成するのに役立ちますが、これがどのように行われるかは明らかではありません。知識をDLモデルにエンコードできます。ほとんどのモデルは、ゼロから、または別のドメインからの転移学習を使用して学習されます。 
[ABSTRACT]モデルモデルモデルモデルモデルはcrt応答にリンクされています。モデルモデルモデルモデルはバイオマーカーまたはバイオマーカーにリンクされている可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-24">
        <br><font color="black">2020-06-24</font>
      </time>
    </span>
</section>
<!-- paper0: Aligning Videos in Space and Time -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_7.html">
      <font color="black">Aligning Videos in Space and Time</font>
    </a>
  </h2>
  <font color="black">オーバーラップするパッチを接続するサイクルは、オーバーラップしていないパッチを接続するサイクルよりも高いスコアを獲得することをお勧めします。トレーニング中に、ビデオのペアが与えられた場合、最初のビデオの特定のフレームのパッチを接続するサイクルを計算します。 2番目のビデオ.. Penn ActionおよびPouringデータセットでの実験は、提案された方法がビデオ全体で意味的に類似したパッチに対応することを首尾よく学習でき、オブジェクトとアクションの状態に敏感な表現を学習できることを示しています。 
[ABSTRACT]私たちは、アクションクラスを時間と空間のビデオに合わせることを目指しています。これらの作品は、アクションクラスのビデオクリップに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: A convolutional neural network reaches optimal sensitivity for detecting
  some, but not all, patterns -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_8.html">
      <font color="black">A convolutional neural network reaches optimal sensitivity for detecting
  some, but not all, patterns</font>
    </a>
  </h2>
  <font color="black">空間コントラスト感度に関して、最新の畳み込みニューラルネットワーク（CNN）および線形サポートベクターマシン（SVM）のパフォーマンスを調査します。ただし、CNN感度は、特定の複雑なテクスチャパターンの検出において最適値をはるかに下回っていました。これらの刺激については、 CNNはSVMを大幅に上回っています。 
[ABSTRACT] cnnの感度を線形の理想的なオブザーバーの感度と比較します。これらの刺激の場合、cnnはsvmを大幅に上回りますが、cnnの感度は最適値よりはるかに低かった</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-12">
        <br><font color="black">2019-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Not only Look, but also Listen: Learning Multimodal Violence Detection
  under Weak Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_9.html">
      <font color="black">Not only Look, but also Listen: Learning Multimodal Violence Detection
  under Weak Supervision</font>
    </a>
  </h2>
  <font color="black">さらに、広範な実験結果は、マルチモーダル入力とモデリング関係のプラスの影響も示しています。この問題に対処するために、この作業では、最初に、合計時間が217時間のXD-Violenceという名前の大規模でマルチシーンのデータセットをリリースします。次に、オーディオスニペットとウィークラベルが付いたトリミングされていない4754ビデオを含みます。次に、ビデオスニペット間のさまざまな関係をキャプチャし、機能を統合する3つの並列ブランチを含むニューラルネットワークを提案します。以前の近接性を使用した関係、およびスコアブランチは、予測スコアの近接性を動的にキャプチャします。 
[要約]コードとデータセットはhttps：wwwでリリースされます。 roc-ng。 io / xd-violence &#39;。これには、ビデオスニペット間のさまざまな関係をキャプチャして機能を統合するための3つの並列ブランチを含むニューラルネットワークが含まれます。このメソッドは、リリースされたデータセットおよび他の既存のベンチマークで他の最先端のメソッドよりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: SalsaNext: Fast, Uncertainty-aware Semantic Segmentation of LiDAR Point
  Clouds for Autonomous Driving -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_10.html">
      <font color="black">SalsaNext: Fast, Uncertainty-aware Semantic Segmentation of LiDAR Point
  Clouds for Autonomous Driving</font>
    </a>
  </h2>
  <font color="black">また、ソースコードhttps://github.com/TiagoCortinhal/SalsaNext ..もリリースしています。Jaccardインデックスを直接最適化するために、加重クロスエントロピー損失とLovasz-Softmax損失
[2]をさらに組み合わせます。 Semantic-KITTIデータセットの評価
[3]。提案されたSalsaNextは、他の最先端のセマンティックセグメンテーションネットワークよりも優れており、Semantic-KITTIリーダーボードで1位にランクされています。 
[ABSTRACT] salsanextはsalsanetの次のバージョンで、エンコーダー-デコーダーアーキテクチャを備えています。残余ブロックのアップコーダー機能を組み合わせるデコーダーパーツを使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-07">
        <br><font color="black">2020-03-07</font>
      </time>
    </span>
</section>
<!-- paper0: Anyone here? Smart embedded low-resolution omnidirectional video sensor
  to measure room occupancy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_11.html">
      <font color="black">Anyone here? Smart embedded low-resolution omnidirectional video sensor
  to measure room occupancy</font>
    </a>
  </h2>
  <font color="black">このような自己学習全方位人物検出アルゴリズムの最適化と組み込み実装の次に、この作業では、空間的および時間的画像データを組み合わせて、極端な低解像度画像でのシステムのパフォーマンスを向上させる新しいアプローチを提案します。同様の問題このようなスマートルーム占有率センサーは、たとえば
[ABSTRACT]会社が天井に取り付けられた全方位カメラを使用し、人検知器と組み合わせて使用されます。場合によっては、フレックス-予約されたデスクは、予約システムなしで空いています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: PIE-NET: Parametric Inference of Point Cloud Edges -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_12.html">
      <font color="black">PIE-NET: Parametric Inference of Point Cloud Edges</font>
    </a>
  </h2>
  <font color="black">CADモデルの大規模なデータセットであるABCデータセットでメソッドをトレーニングおよび評価し、その結果を従来の（非学習）処理パイプライン、および最近のディープラーニングベースのエッジ検出器（EC-NET）によって生成されたものと比較します..私たちの結果は、定量的および定性的の両方の観点から、最先端の技術を大幅に上回っています。 
[ABSTRACT]ネットワークは「リージョンプロポーザル」アーキテクチャに依存しています。私たちの結果は、最新のものよりも大幅に向上しています-最新技術</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Building Robust Industrial Applicable Object Detection Models Using
  Transfer Learning and Single Pass Deep Learning Architectures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_13.html">
      <font color="black">Building Robust Industrial Applicable Object Detection Models Using
  Transfer Learning and Single Pass Deep Learning Architectures</font>
    </a>
  </h2>
  <font color="black">コンピュータビジョンと人工知能における深層学習の急増傾向は無視できません。領域の提案、分類、確率推定を1回の実行で統合する深層学習アーキテクチャを使用することにより、リアルタイムのパフォーマンスを得ることが目的です。高い平均精度を維持しながら、転移学習を探索することにより、必要なトレーニングデータの量を大幅に削減することに焦点を当てます。 
[ABSTRACT]ディープラーニングは神経結果を得ることができ、一流のパフォーマンスに到達します。これは、検出からセグメンテーションまで、最も多様なタスクで達成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Switch CNNs with Model Agnostic Meta Learning for Fine
  Precision Visual Servoing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_14.html">
      <font color="black">Learning to Switch CNNs with Model Agnostic Meta Learning for Fine
  Precision Visual Servoing</font>
    </a>
  </h2>
  <font color="black">CNNを切り替えるアイデアは、ビジュアルサーボ制御の相対カメラポーズリグレッサをトレーニングするためのデータセットに、非常に小さなスケールから最終的にはより大きなスケールまでの範囲の相対ポーズの変動が含まれている必要があるという事実によるものです。ストレージと実行時のオーバーヘッドはほとんど無視できますが、素朴なアプローチよりも優れています。このホワイトペーパーでは、ビジュアルサーボ制御の精度を向上させるためのCNNの切り替えについて説明します。 
[ABSTRACT]訓練されたcnnは、ポーズに基づくビジュアルサーボコントロール（est）を実行するために使用できます。被験者のデータセットに基づいて、ビジュアルサーボの品質を向上させることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Texture Hallucination for Large-Factor Painting Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_15.html">
      <font color="black">Texture Hallucination for Large-Factor Painting Super-Resolution</font>
    </a>
  </h2>
  <font color="black">私たちは、デジタル絵画を超解像し、非常に大きな倍率（8X、16Xなど）の高解像度の参照画材から現実的な詳細を合成することを目指しています。同時に、画像再構成の損失によるスムージング効果を低減します。再構成の制約を劣化損失でさらに緩和し、ダウンスケールされた超解像度の結果と低解像度の入力との間の一貫性を保証します。これらの問題を解決するために、効率的なネットワークを備えた非常に大規模なスケーリング因子のための効率的な高解像度幻覚ネットワークを提案します構造と機能の転送。 
[ABSTRACT]以前の単一画像の超解像（sisr）メソッドは、テクスチャの詳細を失うか、不快なアーティファクトを導入します。これらの問題を解決するために、損失によってもたらされるスムージング効果を減らすのに役立つ効率的な高解像度幻覚ネットワークを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-01">
        <br><font color="black">2019-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchical nucleation in deep neural networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_16.html">
      <font color="black">Hierarchical nucleation in deep neural networks</font>
    </a>
  </h2>
  <font color="black">このプロセスは、出力層の確率密度にフットプリントを残します。ここで、ピークのトポグラフィーにより、カテゴリーの意味的関係を再構築できます。この作業では、一部の非表示層にわたるImageNetデータセットの確率密度の進化を調べます最先端のDCN ..深い畳み込みネットワーク（DCN）は、同じ抽象的な特性を共有するデータがますます近くに配置される意味のある表現を学習します。 
[要約]密度とそれらがどのように生成されるかを理解することは、実用的かつ理論的に興味深いものです。この研究では、初期層が意味論的なビットを生成することがわかりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: EPI-based Oriented Relation Networks for Light Field Depth Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_17.html">
      <font color="black">EPI-based Oriented Relation Networks for Light Field Depth Estimation</font>
    </a>
  </h2>
  <font color="black">ライトフィールドは、観測されたシーンの空間情報だけでなく、すべての入射光線の方向も記録します。ライトフィールドのユニークな2D空間角スライスであるエピポーラー平面画像（EPI）には、方向付けられた線のパターンが含まれています。 EPIのこの特性、いくつかの代表的な方法は、EPIの各ラインの視差を分析することによって深度マップを推定します。 
[要約]情報と線形構造には隣接ピクセルが含まれており、これを利用して深度推定のパフォーマンスを向上させることができます。episは、隣接ピクセル間の関係を無視しながら、epiからラインの最適な勾配を抽出するために使用されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: The Phong Surface: Efficient 3D Model Fitting using Lifted Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_18.html">
      <font color="black">The Phong Surface: Efficient 3D Model Fitting using Lifted Optimization</font>
    </a>
  </h2>
  <font color="black">計算量がiPhone 7の約100分の1であるHoloLens 2ハンドトラッキングのモデルフィッティング問題を解決するために、新しい表面モデルである「フォン表面」を導入します。混合現実におけるリアルタイムの知覚および相互作用機能には、ヘッドマウントデバイスなどのリソースに制約のあるハードウェアで低レイテンシで解決される3Dトラッキングの問題の範囲。三角形のメッシュではなく、Phongサーフェスがより滑らかなサーフェスモデルの収束の利点を保持することを示します。 
[ABSTRACT]フォンサーフェスは、三角形メッシュモデルと同じ3dceですが、連続サーフェストラッキングシステムを備えています。三角形メッシュモデルと同じモデルを使用していますが、連続範囲ベースのソリューションを使用しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Long-Term Residual Blending Network for Blur Invariant Single Image
  Blind deblurring -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_19.html">
      <font color="black">Long-Term Residual Blending Network for Blur Invariant Single Image
  Blind deblurring</font>
    </a>
  </h2>
  <font color="black">続いて、推定されたブラーカーネルを使用して鮮明な画像を復元する長期残差ブレンディングネットワークを提案します。まず、ブラー画像の分析に基づいて適応ブラーカーネルを生成するカーネル推定ネットワークを導入します。実験により、モデルで各データセットで優れた結果を達成します。 
[概要]私たちのモデルは、ブレ除去問題を2つの連続するタスクに分割することで解決します。ぼやけた画像とぼかしカーネルの両方の特徴を低現実空間にエンコードするブレンディングブロックを提案します。カーネルを効率的に使用するために、画像の表現を作成することを提案します-特定のぼかしカーネル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Tractogram filtering of anatomically non-plausible fibers with geometric
  deep learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_20.html">
      <font color="black">Tractogram filtering of anatomically non-plausible fibers with geometric
  deep learning</font>
    </a>
  </h2>
  <font color="black">トラクトグラムフィルタリングの一般的な方法は、原理的なアプローチである信号再構成に基づいていますが、脳の解剖学の知識を考慮することはできません。この作業では、トラクトグラムフィルタリングの問題を、最近のヒューリスティック手法。確立された解剖学的特性に従って、繊維を解剖学的に妥当または非妥当のいずれかに分類します。残念ながら、これらの繊維の大部分は解剖学的に妥当ではなく、追跡アルゴリズムのアーティファクトと見なすことができます。 
[ABSTRACT]これらのファイバーの大部分は解剖学的に妥当ではなく、追跡アルゴリズムのアーティファクトと見なすことができます。これは動的エッジコンボリューションモデルの拡張です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-24">
        <br><font color="black">2020-03-24</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervising Fine-grained Region Similarities for Large-scale Image
  Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_21.html">
      <font color="black">Self-supervising Fine-grained Region Similarities for Large-scale Image
  Localization</font>
    </a>
  </h2>
  <font color="black">推定された画像と領域の類似性は、世代を超えてネットワークを改善するための追加のトレーニング監視として役立ち、次に、きめの細かい類似性を徐々に改善して、最適なパフォーマンスを実現できます。この手法は、顕著なマージンによる標準のローカリゼーションベンチマークと複数の画像検索データセットでの優れた汎化能力を示しています。提案された自己強化画像と領域の類似性ラベルは、追加のパラメーターなしで最先端のパイプラインのトレーニングボトルネックを効果的に処理しますまたはトレーニングと推論の両方での手動注釈。 
[ABSTRACT]一般的な公開ベンチマークは、類似性を学習するための弱い監視として機能する、トレーニング画像に関連付けられたノイズのあるgpsラベルのみを提供します。これらには、サブ領域と一緒に写真を学習するのに効果的であると思われるgpsタグが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-06">
        <br><font color="black">2020-06-06</font>
      </time>
    </span>
</section>
<!-- paper0: Point Set Voting for Partial Point Cloud Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_22.html">
      <font color="black">Point Set Voting for Partial Point Cloud Analysis</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、部分的な点群分析の一般的なモデルを提案します。この場合、完全な点群をエンコードする潜在的な特徴は、局所的な点集合の投票戦略を適用することによって推論されます。このアプローチにより、後続の点群分析が部分的な観測に対して堅牢であると同時に、提案されたモデルは、複数の可能な結果を出力することができます。残念ながら、これらと同じ最先端のアプローチは、不完全な点群に適用するとパフォーマンスが低下します。 
[要約]点群の分類とセグメンテーションのための新しい手法は、部分的に大規模な合成データセットを活用することで、驚異的なパフォーマンスを実現しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient detection of adversarial images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_23.html">
      <font color="black">Efficient detection of adversarial images</font>
    </a>
  </h2>
  <font color="black">数値実験は、提案された検出スキームが競合アルゴリズムよりも優れている一方で、計算の複雑さがかなり低いことを示しています。このような攻撃では、画像の一部またはすべてのピクセル値が外部の攻撃者によって変更されるため、その変化は人間の目にはほとんど見えませんしかし、DNNベースの分類器が誤分類するのに十分なほど重要です。次に、このアルゴリズムの適応バージョンが提案されます。ここでは、2倍のしきい値ポリシーを使用してランダムな数の摂動が適応的に選択され、しきい値は、確率的近似によって学習されます。誤警報と見逃された検出確率に対する制約の影響を受けて、予測される摂動の数を最小限に抑えるため。 
[要約]一部の調査では、悪意のある詐欺攻撃に対するdnnの脆弱性が示されています。このような攻撃は、多くのコンピューターベースの画像の攻撃と似ています。これらには、そのような変更された画像を検出する前処理技術が含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Interpretation of ResNet by Visualization of Preferred Stimulus in
  Receptive Fields -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_24.html">
      <font color="black">Interpretation of ResNet by Visualization of Preferred Stimulus in
  Receptive Fields</font>
    </a>
  </h2>
  <font color="black">ResNetは学習方法の点では高度なモデルですが、生物学的観点からは解釈されていません。この研究では、ImageNetでの分類タスクにおけるResNetの受容野を調査します。CNNのアーキテクチャは決定されています哺乳類の視覚皮質のモデルに基づいています。 
[要約]この研究では、resnetの最初のレイヤーのimagenet.neuronsで分類タスクのresnetの受容フィールドを調べます。さらに、最初のレイヤーのいくつかの非アクティブなニューロンがタスクに影響することを示唆しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-02">
        <br><font color="black">2020-06-02</font>
      </time>
    </span>
</section>
<!-- paper0: ThreeDWorld: A Platform for Interactive Multi-Modal Physical Simulation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_25.html">
      <font color="black">ThreeDWorld: A Platform for Interactive Multi-Modal Physical Simulation</font>
    </a>
  </h2>
  <font color="black">インタラクティブなマルチモーダル物理シミュレーションのプラットフォームであるThreeDWorld（TDW）を紹介します。マルチモーダルの物理シーンの理解、マルチモーダルを含む、コンピュータビジョン、機械学習、認知科学の新たな研究の方向を中心に、プラットフォームによって可能になった初期実験を紹介します。 -エージェントの相互作用、「子供のように学習する」モデル、および人間とニューラルネットワークの注意力研究。TDWは、複数のエージェントがシミュレーション内で相互作用し、状態を表す一連のセンサーと物理データを返すことを可能にする豊富なAPIも提供します。世界。 
[ABSTRACT] tdwを使用すると、ユーザーは高忠実度の感覚データをシミュレーションできます。シミュレーション内で複数のエージェントが対話できるようにする豊富なAPIを提供します。ビデオプラットフォームは公開されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: AI Assisted Apparel Design -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_26.html">
      <font color="black">AI Assisted Apparel Design</font>
    </a>
  </h2>
  <font color="black">Apparel-Style-Mergeは、アパレルの高レベルのコンポーネントを組み合わせることで新しいデザインを生成しますが、Apparel-Style-Transferは、異なるスタイル、色、およびパターンを適用することで、アパレルの複数のカスタマイズを生成します。 ..新しい属性、DeepAttributeStyleという名前の新しいデータセットを作成します。ネック、スリーブなど、さまざまなアパレルコンポーネントのランドマークのきめの細かいアノテーションを使用します。
[ABSTRACT]衣類は、製造で簡単に使用できる高品質のデザインを生成します。デザイナーは無数のデザインを作成する必要があります新鮮なデザイン、デザイナーと言う彼らはまた、デザイナーのデザインの旅を支援するAIアシスタントのシステムを必要としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Attention-based Residual Speech Portrait Model for Speech to Face
  Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_27.html">
      <font color="black">Attention-based Residual Speech Portrait Model for Speech to Face
  Generation</font>
    </a>
  </h2>
  <font color="black">この目的のために、この論文では、顔の前の機能が音声の出力とマージされるハイブリッドエンコーダーデコーダーアーキテクチャに残差の理想を導入することにより、新しい注意ベースの残差音声ポートレートモデル（AR-SPM）を提案します。エンコーダを使って最終的な顔の特徴を形成します。話者のスピーチを前提として、この話者の顔を生成できるかどうかを確認するのは興味深いことです。特に、加重線形結合L2ノルム、L1ノルム、および負のコサイン損失。最終的な顔の特徴と真の顔の特徴を比較してモデルをトレーニングします。 
[要約]主な課題は、顔と音声の不一致を緩和することです。これは、言語を使用する機能で不一致を緩和することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Maximum Entropy Regularization and Chinese Text Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_28.html">
      <font color="black">Maximum Entropy Regularization and Chinese Text Recognition</font>
    </a>
  </h2>
  <font color="black">私たちは理論的に収束確率分布を与え、正則化が学習プロセスにどのように影響するかを分析します。中国語の文字認識、中国語のテキスト行認識、およびきめの細かい画像分類に関する実験は、一貫した改善を実現し、正則化が一般化と堅牢性に有益であることを証明します認識モデル..中国語のテキスト認識は、大量の細かい中国語の文字とクラス間の大きな不均衡のためにラテン語のテキストよりも困難であり、深刻なオーバーフィッティングの問題を引き起こします。 
[ABSTRACT]細かい-粒子の粗い画像分類は一貫した改善を証明しました。正則化は、認識モデルの一般化と堅牢性に有益です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Comparative Study and Optimization of Feature-Extraction Techniques for
  Content based Image Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_29.html">
      <font color="black">Comparative Study and Optimization of Feature-Extraction Techniques for
  Content based Image Retrieval</font>
    </a>
  </h2>
  <font color="black">また、画像のトリミングによるクエリ変更のアイデアを導入することにより、画像検索のパフォーマンスを向上させることも提案しています。ただし、これらの手法を個別に使用すると、パフォーマンスが低下します。画像記述子には、画像内のオブジェクトのテクスチャ、色、強度、形状が含まれます。 
[要約]トレーニング済みの画像から一意の記述子を使用すると、一意の記述子を使用して大規模なデータベース内の画像を見つけることができます。これらの手法の組み合わせも評価されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2012-08-30">
        <br><font color="black">2012-08-30</font>
      </time>
    </span>
</section>
<!-- paper0: Computer Analysis of Architecture Using Automatic Image Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_30.html">
      <font color="black">Computer Analysis of Architecture Using Automatic Image Understanding</font>
    </a>
  </h2>
  <font color="black">実験結果は、自動コンピュータ分析がストリートビュー画像の地理的位置を自動的に識別できることを示しています。この実験は、従来の手動による観察と分析を強化できる定量的アプローチに基づいて、アーキテクチャを研究するための新しいパラダイムを提供します。これらの結果は、コンピュータビジョンとパターン認識アルゴリズムは、建物の画像を分析するという複雑な認知タスクを実行でき、異なるスタイルのアーキテクチャ間の視覚的な類似点と相違点を測定および定量化するために使用できます。 
[ABSTRACT]建物の画像は建物の定量分析を実行できます。建物は、異なるスタイルのアーキテクチャ間の類似性を測定および定量化するために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-07-13">
        <br><font color="black">2018-07-13</font>
      </time>
    </span>
</section>
<!-- paper0: VisImages: A Large-scale, High-quality Image Corpus in Visualization
  Publications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_31.html">
      <font color="black">VisImages: A Large-scale, High-quality Image Corpus in Visualization
  Publications</font>
    </a>
  </h2>
  <font color="black">このプロセスでは、「ゴールドスタンダード」などの手法や品質管理のための多数決投票を利用します。次に、出版物の視覚化を分類するために、マルチラウンドのパイロット調査を通じて既存の分類法を拡張して反復的に絞り込みます。有用性を示します。次の4つのユースケースによるVisImagesの使用：1）長年にわたるVASTおよびInfoVisペーパーでの色の使用の分析、2）視覚化タイプに関する研究者の好みの議論、3）視覚分析システムでの視覚化の空間分布分析、および4）トレーニング可視化検出モデル。 
[要約]このような画像コーパスの作成は、視覚表現の観点からの文献分析を含む、多くの側面でコミュニティに貢献できます。結果のコーパスには、12、267の画像から35,000の注釈付きビジュアライゼーションが含まれ、1397の論文に12、517のキャプションが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: One Policy to Control Them All: Shared Modular Policies for
  Agent-Agnostic Control -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_32.html">
      <font color="black">One Policy to Control Them All: Shared Modular Policies for
  Agent-Agnostic Control</font>
    </a>
  </h2>
  <font color="black">さらに、メッセージはモジュール間で渡され、離れたモジュール間で情報が伝播されます。単一のモジュラーポリシーが、一脚ホッパー、四足歩行、二足歩行などの異なる骨格構造を持ついくつかの平面エージェントの移動動作を正常に生成し、バリアントに一般化できないことを示しています。トレーニング中に見られる-通常は各形態のトレーニングと手動のハイパーパラメータ調整を必要とするプロセス。このグローバルポリシーを、それぞれに対応する共有モジュラーポリシー（SMP）と呼ばれる同一のモジュラーニューラルネットワークのコレクションとして表現することを提案します。エージェントのアクチュエータの。 
[要約]さまざまなエージェントの形態を制御するために一般化できる単一のグローバルポリシーが存在するかどうかを調査します。単一のモジュラーポリシーが、一脚ホッパー、四足動物などの異なる骨格構造を持ついくつかの平面エージェントの移動動作を正常に生成できることを示します、Biped、およびトレーニング中に見られないバリアントに一般化</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Novel Subtypes of Pulmonary Emphysema Based on Spatially-Informed Lung
  Texture Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_33.html">
      <font color="black">Novel Subtypes of Pulmonary Emphysema Based on Spatially-Informed Lung
  Texture Learning</font>
    </a>
  </h2>
  <font color="black">MESA COPDおよびEMCAP研究からの完全肺CTスキャンの2つのコホートを活用して、最初に空間マッピングが肺気腫の空間位置の集団全体の研究を可能にすることを示します。ただし、CTベースの肺気腫のサブタイプはテクスチャベースのパターンに限定されています空間的位置を考慮せずに。コンピュータ断層撮影（CT）での気腫サブタイプの教師なし学習は、気腫サブタイプの新しい定義への道を開き、手作業による完全なラベル付けの必要性を排除します。 
[要約]ニューヨークに基づくct ctは、気腫サブタイプの再生成が、気腫サブタイプの新しい定義への道を開くことを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Pollen13K: A Large Scale Microscope Pollen Grain Image Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_34.html">
      <font color="black">Pollen13K: A Large Scale Microscope Pollen Grain Image Dataset</font>
    </a>
  </h2>
  <font color="black">さらに、構築されたデータセットでの花粉分類のタスクのベースラインの実験的評価が、達成された結果に関するディスカッションと共に提示されます。花粉粒分類の問題とその動機を紹介した後、この論文では、エアロバイオロジカルサンプリング、顕微鏡画像の取得、オブジェクトの検出、セグメンテーション、ラベリングなどの採用されたデータ取得手順に焦点を当てます。 
[ABSTRACT]花粉粒の分類は、関連するすべてのアプリケーションと領域にとって重要なタスクです。このペーパーでは、採用したデータ取得手順に焦点を当てています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Making DensePose fast and light -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_35.html">
      <font color="black">Making DensePose fast and light</font>
    </a>
  </h2>
  <font color="black">これを達成するために、私たちは近年の多くのディープラーニングの革新をテストし、取り入れました。具体的には、23の効率的なバックボーンアーキテクチャ、複数の2ステージ検出パイプラインの変更、およびカスタムモデルの量子化方法でアブレーション研究を行いました。 DensePose R-CNNモデルのアーキテクチャを再設計して、最終的なネットワークがほとんどの精度を維持しながら、より軽量かつ高速になるようにします。その結果、モデルサイズを$ 17 \ times $削減し、レイテンシを$ 2 \ times $改善しましたベースラインモデルに。 
[要約]新しいシステムモデルは、組み込みデバイスまたはモバイルデバイスに接続される可能性がはるかに高くなります。ここでは、近年の多くのディープラーニングアーキテクチャをテストおよび組み込みました。これには、23の効率的なバックボーンアーキテクチャに関するアブレーション研究、複数の2段階検出パイプラインの変更、およびカスタムモデルの量子化方法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-26">
        <br><font color="black">2020-06-26</font>
      </time>
    </span>
</section>
<!-- paper0: Uncertainty Quantification in Deep Residual Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_36.html">
      <font color="black">Uncertainty Quantification in Deep Residual Neural Networks</font>
    </a>
  </h2>
  <font color="black">最後に、提案されたアプローチを使用して、顔認証アプリケーションで不確実性推定値を取得する方法を示します。さまざまな深度と重みを共有する残差ネットワークの分布からサンプリングすることで、意味のある不確実性推定値を取得できることを示します。一般的なコンピュータービジョンデータセットにアプローチし、不確実性推定の質を測定します。 
[ABSTRACT]確率的深さを使用した残差ネットワークのトレーニングは、重みに対する難治性確率への通常の追加として解釈できることを示しています。この方法では、ネットワークの構造にわずかな変更を加えるだけで、十分に調整されたソフトマックス確率が生成されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Early Exit Or Not: Resource-Efficient Blind Quality Enhancement for
  Compressed Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_37.html">
      <font color="black">Early Exit Or Not: Resource-Efficient Blind Quality Enhancement for
  Compressed Images</font>
    </a>
  </h2>
  <font color="black">具体的には、私たちのアプローチは、ダイナミックディープニューラルネットワーク（DNN）を介して圧縮画像の品質を盲目的かつ段階的に向上させます。DNNには、早期終了戦略が組み込まれています。さらに、圧縮画像の品質が不明であり、ブラインド品質向上のための適切なモデルを選択する既存のアプローチでは扱いにくいです。次に、私たちのアプローチは、強化された画像の評価された品質に応じて、拡張を終了または続行することを自動的に決定できます。 
[要約]このホワイトペーパーでは、リソース効率の高いブラインド品質向上（rbqe）モデルを提案します。具体的には、私たちのアプローチは、強化された画像の評価された品質に応じて、強化を自動的に終了または続行することを決定できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br><font color="black">2020-06-30</font>
      </time>
    </span>
</section>
<!-- paper0: Monocular Vision based Crowdsourced 3D Traffic Sign Positioning with
  Unknown Camera Intrinsics and Distortion Coefficients -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_38.html">
      <font color="black">Monocular Vision based Crowdsourced 3D Traffic Sign Positioning with
  Unknown Camera Intrinsics and Distortion Coefficients</font>
    </a>
  </h2>
  <font color="black">この作業では、カメラの焦点距離、主点、歪み係数を事前に知らなくても3D交通標識の位置を計算する方法を示します。交通標識の位置など、これらのランドマークのクラウドソーシングによるマッピングは魅力的な代替手段を提供します。 KITTIの交通標識の公開データセットに対する提案されたアプローチ。 
[ABSTRACT]クラウドソーシングされたマッピングはグラウンドトゥルースカメラのパラメーターを使用します。これは、常にわかっているとは限らないか、時間とともに変化する可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Generalized Many-Way Few-Shot Video Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_39.html">
      <font color="black">Generalized Many-Way Few-Shot Video Classification</font>
    </a>
  </h2>
  <font color="black">ラベル付けされた例の必要性を回避するために、タグ検索を使用して大規模なデータセットから弱くラベル付けされたビデオを活用し、視覚的に類似している最高のクリップを選択して、さらに改善することを提案します。 、少数ショットのビデオ認識は比較的探索されておらず、2D CNNに基づく方法は時間情報を学習できません。少数ショットの学習方法は、低いデータ体制で動作します。 
[ABSTRACT]目的は、クラスごとにいくつかのトレーニング例で学習することです。これらには、ビデオ分析とクラスの混合が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: MuSe 2020 -- The First International Multimodal Sentiment Analysis in
  Real-life Media Challenge and Workshop -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_40.html">
      <font color="black">MuSe 2020 -- The First International Multimodal Sentiment Analysis in
  Real-life Media Challenge and Workshop</font>
    </a>
  </h2>
  <font color="black">私たちは3つの異なるサブチャレンジを提示します。MuSe-Wildは、継続的な感情（覚醒と価数）の予測に焦点を当てています。 MuSe-Topic。参加者はドメイン固有のトピックを3クラス（低、中、高）感情のターゲットとして認識します。信頼性の新しい側面が予測されるMuSe-Trust。このホワイトペーパーでは、MuSe-CaRに関する詳細情報を提供します。最先端の機能と適用されたモデリングアプローチと同様に。サブチャレンジごとに、参加者の競争力のあるベースラインが設定されます。つまり、テストでは、MuSe-Wildの結合された（価数と覚醒）CCCが2568、MuSe-Topicのスコア（0.34 $ \ cdot $ UAR + 0.66 $ \ cdot $ F1として計算）が76.78％ 10クラスのトピック、3クラスの感情予測では40.64％、MuSe-Trustでは.4359のCCC。 
[ABSTRACT] muse-車はその種の最初の-より包括的なデータベースです。これは、課題と同様に利用されます。8.museの目的は、さまざまな分野のコミュニティをまとめることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: Single architecture and multiple task deep neural network for altered
  fingerprint analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_41.html">
      <font color="black">Single architecture and multiple task deep neural network for altered
  fingerprint analysis</font>
    </a>
  </h2>
  <font color="black">提案されたアプローチは、SO.CO.FINGでの偽装、変更、性別、手指の分類について、それぞれ98.21％、98.46％、92.52％、97.53％、92,18％の精度を達成します。 」は、摩擦の隆起パターンの意図的な損傷を指し、それらは法執行機関を回避するためにスマート犯罪者によってしばしば使用されます。この論文は、変更された指紋の検出、変更のタイプの識別、性別、手と指。 
[ABSTRACT]指紋はシステムに応じて変更できます。たとえば、指紋の影響を特定するために使用できます。これらの変更は簡単に特定できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Modelling the Distribution of 3D Brain MRI using a 2D Slice VAE -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_42.html">
      <font color="black">Modelling the Distribution of 3D Brain MRI using a 2D Slice VAE</font>
    </a>
  </h2>
  <font color="black">ただし、利用可能な計算データとトレーニングデータに対する制約により、2D画像用に十分に開発されたVAEを効果的に活用することが困難になるため、ボリュームデータのモデリングは依然として課題です。潜在空間のサンプル平均と共分散を推定することにより、スライス方向の2Dモデルの分析。2DスライスVAEとスライス間の関係をキャプチャするガウスモデルを組み合わせることにより、3D MR脳ボリューム分布をモデル化する方法を提案します。 
[要約]新しい方法は、3D mr脳ボリューム分布をモデル化するために使用できます。2DスライスVAEとスライス間の関係をキャプチャするモデルを組み合わせます。この組み合わせモデルにより、潜在変数の新しいコヒーレントスタックをサンプリングして、ボリューム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Object-Contextual Representations for Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_43.html">
      <font color="black">Object-Contextual Representations for Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、コンテキスト集約戦略に重点を置いて、セマンティックセグメンテーションの問題に対処します。提案されたアプローチが、さまざまな挑戦的なセマンティックセグメンテーションベンチマーク（Cityscapes、ADE20K、LIP、PASCAL-Context、COCO-）で競争力のあるパフォーマンスを実現することを実証します。スタッフ..対応するオブジェクトクラスの表現を利用してピクセルを特徴付ける、シンプルで効果的なアプローチであるオブジェクトコンテキスト表現を示します。 
[要旨]動機は、ピクセルのラベルが、ピクセルが属しているオブジェクトのカテゴリであるということです。単純なオブジェクトの領域で、グラウンドトゥルースピクセルの監視下にあります。second.last、％このタイプの表現。オブジェクトを使用して各ピクセルの表現を拡張します-コンテキスト表現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-24">
        <br><font color="black">2019-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Invertible Zero-Shot Recognition Flows -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_44.html">
      <font color="black">Invertible Zero-Shot Recognition Flows</font>
    </a>
  </h2>
  <font color="black">上記の制限に取り組むために、この作業は初めて、生成モデル（つまり、フローベースのモデル）の新しいファミリをZSLに組み込みます。ただし、GANおよびVAEの根本的な欠点（たとえば、ZSLでのトレーニングの難しさ）指向の正則化機能と限られた生成品質）は、既存の生成ZSLモデルが目に見えないバイアスを完全に回避するのを妨げます。広く採用されているZSLベンチマークの実験は、クラシック設定と一般化設定の両方で、既存の方法よりもIZFのパフォーマンスが大幅に向上することを示しています。 
[ABSTRACT]提案された可逆ゼロショットフロー（izf）は、可逆フローネットワークのフォワードパスで因数分解されたデータの埋め込みを学習します。バイアスの問題を明示的に解決するために、私たちのモデルは、距離に基づいて、負のサンプルに基づいて見られる見えない分布の不一致を拡大します測定</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Auxiliary Tasks Speed Up Learning PointGoal Navigation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_45.html">
      <font color="black">Auxiliary Tasks Speed Up Learning PointGoal Navigation</font>
    </a>
  </h2>
  <font color="black">）私たちは、複数の補助タスクを単純に組み合わせると、サンプルの効率が向上するが、ポイントを超えてわずかな利益しか得られないことがわかります。これを克服するために、個々の補助タスクから学習した表現を組み合わせることに注意を払います。軌跡などからの2つの観測間の距離の予測
[要旨]私たちは、自己監視補助タスクを使用してpointnavを学習する際にサンプルと時間の効率を大幅に向上させる方法を開発します。複数の補助タスクを単純に組み合わせると、サンプルの効率が向上しますが、ポイントを超えてわずかな利益しか得られないことがわかります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: An Open-source Tool for Hyperspectral Image Augmentation in Tensorflow -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_46.html">
      <font color="black">An Open-source Tool for Hyperspectral Image Augmentation in Tensorflow</font>
    </a>
  </h2>
  <font color="black">Tensorflowがいかにアクセスしやすく使いやすいかを考えると、このツールは、リモートセンシングアプリケーションのディープラーニングモデルを実装、テスト、展開する手段を多くの研究者に提供します。Tensorflowツールは、ディープラーニングモデルの迅速なプロトタイピングとテストを可能にします。ただし、組み込みの画像ジェネレータは最大4つのスペクトルチャネルを処理するように設計されています。これには、リモートセンシングの分野でのユーティリティの評価を可能にする衛星画像のディープラーニングモデルを最適化する研究努力が必要です。 
[要約]コンピュータビジョンシステムの急速な発展により、衛星画像の使用に新たな地平が開かれる可能性があります。これらの画像は衛星画像とは異なる分布を示しますが、これらの画像は衛星画像とは異なるサブセットのみを表示します。これにより、研究努力を最適化できます。衛星画像のディープラーニングモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br><font color="black">2020-03-30</font>
      </time>
    </span>
</section>
<!-- paper0: Patient-Specific Domain Adaptation for Fast Optical Flow Based on
  Teacher-Student Knowledge Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_47.html">
      <font color="black">Patient-Specific Domain Adaptation for Fast Optical Flow Based on
  Teacher-Student Knowledge Transfer</font>
    </a>
  </h2>
  <font color="black">現在のディープラーニングOFモデルは、一般的な速度と精度のトレードオフを示しています。教師と生徒の学習を採用することで、欠落しているグラウンドトゥルースを処理しています。これにより、ターゲットドメインを能力に減らしながら、トレーニングとアプリケーションデータ間のドメインギャップを最小限に抑えます。下の複雑な高速モデルの。 
[ABSTRACT]高速の学生モデルflownet2sは、患者固有のドメインのflownet2sにすることができます。モデルは数分以内に実行できるため、手術室で実現可能です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Body Shape Privacy in Images: Understanding Privacy and Preventing
  Automatic Shape Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_48.html">
      <font color="black">Body Shape Privacy in Images: Understanding Privacy and Preventing
  Automatic Shape Extraction</font>
    </a>
  </h2>
  <font color="black">機械学習モデルの出力（特に、エンドツーエンドのディープラーニングアプローチ）を操作するために敵対的な摂動が効果的であることが示されていますが、最先端の形状推定法は複数のステージで構成されています。と身体形状推定は、困難な実世界の条件下でも最近強力なパフォーマンスを達成しています。元の画像の全体的な外観を維持しながら、自動形状推定を効果的に操作するために使用できるさまざまな戦略の最初の調査を実行します。 
[要約]モデルを使用して、さまざまな体型をモデル化できます。脱衣した体のリアルな描写は、非常にプライベートと見なされます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-27">
        <br><font color="black">2019-05-27</font>
      </time>
    </span>
</section>
<!-- paper0: The autonomous hidden camera crew -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_49.html">
      <font color="black">The autonomous hidden camera crew</font>
    </a>
  </h2>
  <font color="black">これにより、システムの結果を訓練を受けた専門家の作業と比較することができました。次に、PTZカメラを制御して、自動的に映画撮影に適したショットを撮ることで、仮想カメラマンを作成します。このホワイトペーパー全体を通して、実際のカメラと密接に連携しましたクルー。 
[要約]このペーパーでは、カメラマンを使用してビデオスイッチマトリックスを制御するなど、日常生活の中で人々をフォローする方法を示します。これは、記録されたデータの量を制限するシステムに追加されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Dual-attention Guided Dropblock Module for Weakly Supervised Object
  Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_50.html">
      <font color="black">Dual-attention Guided Dropblock Module for Weakly Supervised Object
  Localization</font>
    </a>
  </h2>
  <font color="black">SAGDは、個々のピクセルではなく、フィーチャマップの隣接領域を消去することにより、最も特徴的な情報を効率的に削除できます。実験結果は、提案された方法が新しい最先端のローカリゼーションパフォーマンスを達成することを示しています。トレーニング中に重要になった場合に価値を高める要素。 
[ABSTRACT]二重注意ガイド付きドロップブロックモジュール（dgdm）は、wsolの有益で補完的な視覚パターンを学習することを目的としています。sagdは、個々のピクセルではなく、フィーチャマップの隣接領域を消去することにより、最も特徴的な情報を効率的に削除できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br><font color="black">2020-03-09</font>
      </time>
    </span>
</section>
<!-- paper0: Real-time Embedded Person Detection and Tracking for Shopping Behaviour
  Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_51.html">
      <font color="black">Real-time Embedded Person Detection and Tracking for Shopping Behaviour
  Analysis</font>
    </a>
  </h2>
  <font color="black">このために追加のスタッフを使用する代わりに、自動オンプレミスソリューションが推奨されます。これらの自動システムは、コスト効率が高く、できれば軽量の組み込みハードウェアで、非常に困難な状況（頻繁に訪れる場所など）で機能する必要があります。 
[要旨]この問題を解決するには、リアルタイムの光子最適化されたyolov3ベースの歩行者検出器を導入します。当社の検出器-トラッカーベースのソリューションは、10 fpsの処理速度で平均81. 59％の精度を達成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Which Tasks Should Be Learned Together in Multi-task Learning? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_52.html">
      <font color="black">Which Tasks Should Be Learned Together in Multi-task Learning?</font>
    </a>
  </h2>
  <font color="black">いくつかの異なる学習設定でのタスクの協力と競争を研究し、いくつかのニューラルネットワークにタスクを割り当てるためのフレームワークを提案します。これにより、協力するタスクは同じニューラルネットワークによって計算され、競合するタスクは異なるネットワークによって計算されます。ニューラルネットワークは、マルチタスク学習を使用して複数のタスクを同時に解決するようにトレーニングされています。単一のネットワークのみを評価する必要があるため、推論時に計算を節約できます。 
[要約]ニューラルネットワークは、複数のタスクを同時に解決するようにトレーニングできます。これにより、タスクの目的が競合する可能性があるため、全体的なパフォーマンスが低下することがよくあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-18">
        <br><font color="black">2019-05-18</font>
      </time>
    </span>
</section>
<!-- paper0: Alleviating the Burden of Labeling: Sentence Generation by Attention
  Branch Encoder-Decoder Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_53.html">
      <font color="black">Alleviating the Burden of Labeling: Sentence Generation by Attention
  Branch Encoder-Decoder Network</font>
    </a>
  </h2>
  <font color="black">結果は、ABENがこれらのメトリックに関してベースラインを上回ったことを示しています。他のアプローチとは異なり、ABENには、サブワードレベルの注意を使用し、サブワードの埋め込みに基づいて文を生成するマルチモーダル注意ブランチがあります。この背景に基づいて、フェッチ命令の文生成：たとえば、「テーブルに緑茶の瓶を持ってきて」 
[ABSTRACT] dsrsは多くの視覚的視覚視覚的質問を生成することはできません。ただし、言語を介して自然に対話することはできません。代わりに、自動文生成を実行することを目指しています。これらには次のものが含まれます。テーブルの上の瓶」</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: How Does Topology of Neural Architectures Impact Gradient Propagation
  and Model Performance? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_54.html">
      <font color="black">How Does Topology of Neural Architectures Impact Gradient Propagation
  and Model Performance?</font>
    </a>
  </h2>
  <font color="black">この目的のために、ネットワークサイエンスの観点からディープラーニングアーキテクチャ設計の問題を定式化し、NN-Massと呼ばれる新しいメトリックを導入して、特定のアーキテクチャを介して情報がどの程度効果的に流れるかを定量化します。提案されたNN-Massがより効果的であることを示しますグラジエントフローの特性を特徴付け、サイズ/計算の要件が大幅に異なるにもかかわらず、同様の精度でモデルを識別するためのパラメーターの数よりも多い。合成データセットと実際のデータセットの両方に関する詳細な実験（例：MNISTとCIFAR-10 / 100）私たちの洞察のための広範な経験的証拠。 
[ABSTRACT]提案された新しいnn-massは、勾配流の特性を特徴付けるパラメーターの数よりも効果的であることを実証しました。次に、新しいセットを活用して効率的なアーキテクチャを直接設計し、損失しながら最大3倍のパラメーターとフロップを実現しました。 cifar-10での大きなcnnの最小精度</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-02">
        <br><font color="black">2019-10-02</font>
      </time>
    </span>
</section>
<!-- paper0: Medical Instrument Detection in Ultrasound-Guided Interventions: A
  Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_55.html">
      <font color="black">Medical Instrument Detection in Ultrasound-Guided Interventions: A
  Review</font>
    </a>
  </h2>
  <font color="black">医療機器の検出は、外科医がより良い解釈で機器を効率的に見つけ、より良い結果につながるため、コンピューター支援の介入にとって不可欠です。この記事では、超音波ガイド下の介入における医療機器の検出方法をレビューします。 、私たちはいくつかの主要な出版物を選択して、コンピューター支援介入コミュニティの主要な問題と潜在的な研究の方向性をまとめました。 
[要約]超音波での医療機器検出の主な臨床アプリケーションについて説明します。これらには、麻酔、生検、前立腺近接照射療法、心臓カテーテル検査が含まれます。これらのアプリケーションは、臨床データセットで検証されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: CCNet: Criss-Cross Attention for Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_56.html">
      <font color="black">CCNet: Criss-Cross Attention for Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">Cityscapes、ADE20K、人間の解析ベンチマークLIP、インスタンスセグメンテーションベンチマークCOCO、ビデオセグメンテーションベンチマークCamVidなどのセマンティックセグメンテーションベンチマークで広範な実験を行っています。ソースコードは\ url {https://github.com/speedinghzl/CCNet}で入手できます。具体的には、各ピクセルについて、新しい十字型注意モジュールが、その十字型パス上のすべてのピクセルのコンテキスト情報を収集します。 
[ABSTRACT] crissモジュール（ccnet）は、メモリビジュアルビジュアルビジュアル情報を必要とします。これには、メモリフレンドリーで非スペックレベルレベルlevelレベルが含まれます。ただし、結果は当時のものよりはるかに低くなります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-11-28">
        <br><font color="black">2018-11-28</font>
      </time>
    </span>
</section>
<!-- paper0: Attribute Mix: Semantic Data Augmentation for Fine Grained Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_57.html">
      <font color="black">Attribute Mix: Semantic Data Augmentation for Fine Grained Recognition</font>
    </a>
  </h2>
  <font color="black">さらに、同じスーパーカテゴリの画像間で属性を共有できるため、汎用ドメインの画像を使用して、属性レベルのラベルでトレーニングサンプルをさらに充実させます。広く使用されている細かいベンチマークでの実験は、提案された方法の有効性を示しています。この目標に向けて、同じスーパーカテゴリに属する属性を発見する自動属性マイニングアプローチを提案し、属性ミックスは2つの画像から意味的に意味のある属性特徴を混合することによって操作されます。 
[ABSTRACT]属性ミックスは、きめの細かいサンプルを拡張するために広く使用されているデータ拡張戦略です。2つの画像から意味的に意味のある特徴を組み合わせるために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Multi-task Learning for Facial Expression Recognition and Synthesis
  Based on Selective Feature Sharing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_58.html">
      <font color="black">Deep Multi-task Learning for Facial Expression Recognition and Synthesis
  Based on Selective Feature Sharing</font>
    </a>
  </h2>
  <font color="black">提案された方法は、役に立たない有害な情報を除外しながら、さまざまなタスク間で有益な機能を効果的に転送できます。実験結果は、提案された方法が、一般的に使用される表情認識ベンチマークで最先端のパフォーマンスを達成し、現実世界の表情認識問題の潜在的な解決策。さらに、提案された方法の一般化能力をさらに強化するために、トレーニングデータセットを拡大してバランスをとるために表情合成タスクを使用します。 
[要約]提案された方法は、異なるタスク間で機能を効果的に転送できます。有害で有害な情報を効果的に削除できます。方法は、状態認識を実現します-表情認識ベンチマークの学習</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Multiple Expert Brainstorming for Domain Adaptive Person
  Re-identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_59.html">
      <font color="black">Multiple Expert Brainstorming for Domain Adaptive Person
  Re-identification</font>
    </a>
  </h2>
  <font color="black">大規模なデータセット（Market-1501およびDukeMTMC-reID）での広範な実験により、最先端のMEB-Netの優れたパフォーマンスが実証されています。多くの場合、最も優れたディープニューラルモデルは、複数のベースレベルネットワークのアンサンブルです。それにもかかわらず、ドメイン適応人物re-IDに関するアンサンブル学習はまだ調査されていません。MEB-Netは、さまざまなアーキテクチャで学習した専門家の異質性に対応し、権限の正規化スキームを導入することで、適応されたre-IDモデルの識別機能を強化します。専門家。 
[要旨]ドメイン適応型個人リード用の複数のエキスパートブレーンストーミングネットワーク（meb-net）は、監視されていない条件下でのモデルアンサンブル問題に関する有望な方向を切り開きます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-03">
        <br><font color="black">2020-07-03</font>
      </time>
    </span>
</section>
<!-- paper0: Algorithm Unrolling: Interpretable, Efficient Deep Learning for Signal
  and Image Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_60.html">
      <font color="black">Algorithm Unrolling: Interpretable, Efficient Deep Learning for Signal
  and Image Processing</font>
    </a>
  </h2>
  <font color="black">ディープニューラルネットワークは、信号および画像処理における多くの現実世界の問題において、これまでにないパフォーマンスの向上を提供します。イメージング、視覚および認識、音声処理など、信号および画像処理のさまざまな領域でアルゴリズムを展開するための一般的な手法を幅広くカバーします。動作し、反復アルゴリズムとニューラルネットワークの関係を明らかにし、最近の理論的な結果を示します。 
[ABSTRACT]実際のネットワークの人気が高まっているのは、妥当なサイズのトレーニングセットから効率的で高性能でありながら解釈可能なネットワークアーキテクチャを開発する可能性があるためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-22">
        <br><font color="black">2019-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Weakly supervised multiple instance learning histopathological tumor
  segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_61.html">
      <font color="black">Weakly supervised multiple instance learning histopathological tumor
  segmentation</font>
    </a>
  </h2>
  <font color="black">$ 6481 $で生成された腫瘍マップとデータ処理を含む完全なフレームワークは、\ url {https://github.com/marvinler/tcga\_segmentation}。で入手できます。このホワイトペーパーでは、スライドイメージング全体のための弱監視フレームワークを提案しますほとんどの医療システムで利用可能な標準の臨床アノテーションに依存するセグメンテーション。組織病理学的画像セグメンテーションは、臨床診療において途方もない潜在的影響を伴う医用イメージングにおける挑戦的で重要なトピックです。 
[ABSTRACT]最先端の方法は手作りの注釈に依存しています。組織学は、がんの表現型間の有意差に悩まされています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-10">
        <br><font color="black">2020-04-10</font>
      </time>
    </span>
</section>
<!-- paper0: Client Adaptation improves Federated Learning with Simulated Non-IID
  Clients -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_62.html">
      <font color="black">Client Adaptation improves Federated Learning with Simulated Non-IID
  Clients</font>
    </a>
  </h2>
  <font color="black">クライアントの適応は、条件付きゲーティッドアクティベーションユニットによって実装され、フェデレーション学習の一般的なシナリオである各クライアントのデータ分布に大きな違いがある場合に特に有益です。クライアントに適応可能な堅牢なモデルを学習するためのフェデレーション学習アプローチを紹介します。クライアント間でデータが非同一かつ非独立に分散（非IID）されている場合。異種のクライアントをシミュレートすることにより、学習したクライアント固有の条件付けを追加するとモデルのパフォーマンスが向上し、バランスの取れたデータとバランスの取れていないデータで動作するアプローチが示されます音声ドメインと画像ドメインの両方から設定します。 
[ABSTRACT]このアプローチは、音声ドメインと画像ドメインの両方からのバランスのとれたデータセットで機能することが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Cortical surface registration using unsupervised learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_63.html">
      <font color="black">Cortical surface registration using unsupervised learning</font>
    </a>
  </h2>
  <font color="black">この研究では、これらの問題に対処する深いネットワークを使用して、皮質表面の微分同相登録フレームワークであるSphereMorphを提示します。この戦略は、正確な空間配置を生成しますが、多くの場合、高い計算コストが必要です。カーネルは、変位場を学習し、変更された空間変換層を使用して球をワープします。 
[ABSTRACT]その空間で皮質の折りたたみパターンを位置合わせして位置合わせを行うには、表面特性の球体表現が必要です。cnnsは、体積の位置合わせを劇的に高速化する可能性を示しています。しかし、cnnsは、歪みやその他の形式のデータフィッティングで、新しいツールを開発するために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: Low Dose CT Denoising via Joint Bilateral Filtering and Intelligent
  Parameter Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_64.html">
      <font color="black">Low Dose CT Denoising via Joint Bilateral Filtering and Intelligent
  Parameter Optimization</font>
    </a>
  </h2>
  <font color="black">最近、ディープラーニング手法がCT画像のノイズ除去にうまく使用されています。報酬ネットワークは強化学習タスクを指示するように設計されています。私たちのノイズ除去方法は、構造情報を保持しながら、優れたノイズ除去性能を示します。 
[ABSTRACT]現在臨床的に承認されている方法は、ct画像のノイズを低減するために反復再構成法を使用しています。臨床画像の状況での使用に必要な説明責任が低くなっています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Unsupervised Learning for Instrument Segmentation in Robotic
  Surgery with Cycle-Consistent Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_65.html">
      <font color="black">Towards Unsupervised Learning for Instrument Segmentation in Robotic
  Surgery with Cycle-Consistent Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">手術画像データ自体とは異なり、注釈は取得が難しく、品質が変動する可能性があります。Endovis2017チャレンジデータセットで提案された方法をテストし、監視付きセグメンテーション方法と競合することを示します。ロボットのフォワードキネマティックモデルとツールのCADモデルを使用して、それらを画像平面に投影することにより、自動的に生成されます。 
[ABSTRACT]人工アノテーションは、ロボットの運動学モデルとツールのCADモデルを使用して、それらを画像平面に投影することにより、自動的に生成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Implicit Geometric Regularization for Learning Shapes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_66.html">
      <font color="black">Implicit Geometric Regularization for Learning Shapes</font>
    </a>
  </h2>
  <font color="black">線形の場合のこの特性の理論的分析を提供し、実際に、私たちの方法が、以前の方法と比較してより高い詳細レベルと忠実度を備えた最先端の暗黙的な神経表現につながることを示します。生データ（つまり、点群、通常の情報の有無にかかわらず）から直接、高忠実度の暗黙のニューラル表現を計算するための新しいパラダイムを提供します。ニューラルネットワークのレベルセットとして形状を表現することは、さまざまな形状分析や再構成に役立つことが最近証明されましたタスク。 
[ABSTRACT]たとえば、有用な有用な構造がマッピングされています。これらの例には、構造の変化、損失関数などがあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-24">
        <br><font color="black">2020-02-24</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-view Drone-based Geo-localization via Style and Spatial Alignment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_67.html">
      <font color="black">Multi-view Drone-based Geo-localization via Style and Spatial Alignment</font>
    </a>
  </h2>
  <font color="black">さらに、画像の配置のばらつきを減らし、特徴の統合を強化するスタイル配置戦略を提供します。この欠点に対処するために、パターンに合わせて方向付けに基づくエレガントな方法を提案し、配置された部分的な特徴を抽出する新しいブランチを導入します。ただし、これらの方法では、空間情報（特に視点の分散）に十分な注意を払うことができません。 
[ABSTRACT]パターンに合わせてエレガントなタスクベースの方法を提案し、新しいブランチを導入して、位置合わせされた部分的な特徴を抽出します。この欠点に対処するために、大規模ベンチマークデータセットで大規模な実験を行います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-23">
        <br><font color="black">2020-06-23</font>
      </time>
    </span>
</section>
<!-- paper0: Motion-Attentive Transition for Zero-Shot Video Object Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_68.html">
      <font color="black">Motion-Attentive Transition for Zero-Shot Video Object Segmentation</font>
    </a>
  </h2>
  <font color="black">さらに、ブリッジネットワークが提案されて、マルチレベルエンコーダー機能のコンパクトで判別的でスケールに敏感な表現を取得し、さらにデコーダーに入力してセグメンテーション結果を達成します。このようにして、エンコーダーは深くインターリーブされ、オブジェクトの動きと外観の間の密接に階層的な相互作用。これは、各ストリームで動きと外観を個別に扱い、外観情報への過剰適合に悩まされることが多い、典型的な2ストリームアーキテクチャより優れています。 
[ABSTRACT]モーション-注意深い遷移（マット）は、2ストリームエンコーダー内で設計されています。これは、外観機能を各畳み込みステージでモーション-減衰表現に変換します。これは、モーションと外観を別々に処理する一般的な2ストリームアーキテクチャより優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br><font color="black">2020-03-09</font>
      </time>
    </span>
</section>
<!-- paper0: Towards an Effective and Efficient Deep Learning Model for COVID-19
  Patterns Detection in X-ray Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_69.html">
      <font color="black">Towards an Effective and Efficient Deep Learning Model for COVID-19
  Patterns Detection in X-ray Images</font>
    </a>
  </h2>
  <font color="black">健康な非COVID-19肺炎とCOVID-19患者に分けられた13,569 X線画像のデータセットは、提案されたアプローチと他の5つの競合するアーキテクチャをトレーニングするために使用されます。COVID-19のパンデミックに直面している今日、したがって、この作業の主な目的は、胸部X線におけるCOVID-19スクリーニングの問題について、記憶と処理時間の点で正確かつ効率的な方法を提案することです。 
[要約]この作業の主な目的は、胸部X線でのcovid-19スクリーニングの問題に対する正確な方法を提案することです。この方法に加えて、3つのクラスの230枚以上の画像を使用して、メソッド</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-12">
        <br><font color="black">2020-04-12</font>
      </time>
    </span>
</section>
<!-- paper0: JBFnet -- Low Dose CT Denoising by Trainable Joint Bilateral Filtering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_70.html">
      <font color="black">JBFnet -- Low Dose CT Denoising by Trainable Joint Bilateral Filtering</font>
    </a>
  </h2>
  <font color="black">JBFnetは、構造を維持しながら、ノイズ除去に関してテストデータセットでCPCE3D、GAN、および深いGFnetよりも優れています。ガイダンス画像は、ディープニューラルネットワークによって推定されます。 
[要約]ジョイントバイラテラルフィルターのフィルター機能は、浅い畳み込みネットワークを介して学習されます。jbfnetは4つのフィルタリングブロックに分割され、それぞれがジョイントバイラテラルフィルタリングを実行します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Modal Weighting Network for RGB-D Salient Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_71.html">
      <font color="black">Cross-Modal Weighting Network for RGB-D Salient Object Detection</font>
    </a>
  </h2>
  <font color="black">深度マップには、顕著なオブジェクトの検出（SOD）を支援するための幾何学的な手がかりが含まれています。徹底的な評価により、CMWNetは、7つの一般的なベンチマークで15の最新のRGB-D SODメソッドよりも常に優れていることを示しています。これらのモジュールは、深度対RGB重み付け（ DW）およびRGBからRGBへの重み付け（RW）により、さまざまなネットワークブロックによって生成されたフィーチャレイヤー間で、モーダルおよびクロススケールの相互作用を実現できます。 
[ABSTRACT] cmwnetは、深さから-RGBへの重み付け（rw）およびRGB情報を使用するネットワークネットワークネットワークです。これは、m-d sodのRGBチャネルと深さチャネル間の相互作用を促進するためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Ocean: Object-aware Anchor-free Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_72.html">
      <font color="black">Ocean: Object-aware Anchor-free Tracking</font>
    </a>
  </h2>
  <font color="black">まず、参照アンカーボックスを調整する代わりに、ターゲットオブジェクトの位置とスケールをアンカーなしで直接予測します。次に、予測されたバウンディングボックスからオブジェクト認識機能を学習するための機能整列モジュールを導入します。 、アンカーフリーモデルに基づく新しい追跡フレームワークを提示します。 
[ABSTRACT] anchor-無料のネットワークは、ターゲットオブジェクトの予測を修正できます。この機能は、ターゲットの分類にさらに貢献できます。この実験では、5つのベンチマークで、アンカー-無料のトラッカーが最先端のパフォーマンスを実現していることが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br><font color="black">2020-06-18</font>
      </time>
    </span>
</section>
<!-- paper0: Animated GIF optimization by adaptive color local table management -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_73.html">
      <font color="black">Animated GIF optimization by adaptive color local table management</font>
    </a>
  </h2>
  <font color="black">1000のGIFファイルに対して実行されたテストは、提案された最適化戦略の有効性を示しています。一方、人気は、ホスティングプラットフォームにとってストレージの節約が問題になることを意味します。提案された手法は、ローカルカラーテーブルの選択と色の再マッピングに基づいており、元の形式を維持しながら、最適化されたアニメーションGIFを作成します。 
[ABSTRACT] gif画像をエンコードする元の圧縮方法は少し変更されていませんが、gif画像の元の形式が一般的になりつつあります。このペーパーでは、アニメーションgifのパラメトリック分析手法を紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: A Deep Joint Sparse Non-negative Matrix Factorization Framework for
  Identifying the Common and Subject-specific Functional Units of Tongue Motion
  During Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_74.html">
      <font color="black">A Deep Joint Sparse Non-negative Matrix Factorization Framework for
  Identifying the Common and Subject-specific Functional Units of Tongue Motion
  During Speech</font>
    </a>
  </h2>
  <font color="black">この作業では、これらの課題に対処するために、スピーチ中の舌の動きの共通および被験者固有の機能単位を識別するための新しい深層学習フレームワークを開発します。シミュレーションデータセットを使って行った実験は、提案された方法が比較方法を上回っていることを示しています。次に、スペクトルクラスタリングを一般的な被験者固有の機能単位に適用します。 
[要約]提案された方法は、共通性と被験者固有の機能単位を決定でき、解釈性が向上し、サイズのばらつきが減少します。被験者間で識別された単位を、それらの実質的なばらつきにより比較できるように保つことは困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Style-Content Disentanglement in Image-to-Image Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_75.html">
      <font color="black">Improving Style-Content Disentanglement in Image-to-Image Translation</font>
    </a>
  </h2>
  <font color="black">私たちの方法の結果は、現在の方法で生成された結果よりもはるかに絡みがなく、視覚的な品質と翻訳の多様性がさらに改善されていることを示しています。各表現への情報の流れに合わせて、コンテンツのボトルネックとなる追加の損失項を導入します。 
[ABSTRACT]これに加えて、コンテンツとして機能する追加の損失期間を導入します-ボトルネック</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Attention Neural Network for Trash Detection on Water Channels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_76.html">
      <font color="black">Attention Neural Network for Trash Detection on Water Channels</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーの終わりに向けて、私たちの方法と最新のオブジェクト検出器との詳細な比較を提供し、この方法が小さなオブジェクトの検出を大幅に改善することを示します。この汚染された水が農業分野に到達すると、土壌の劣化と重大な環境および経済的脅威を引き起こします。ゴミは変形し、部分的に水没し、より小さな破片に分解され、他の物体と一緒に固まり、その形状を覆い隠し、困難な検出問題を引き起こします。 
[ABSTRACT]これにより淡水路が汚染され、下水道が閉塞します。ゴミは水面に浮いていることがよくあります。データセットは一般に公開されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: How low can you go? Privacy-preserving people detection with an
  omni-directional camera -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_77.html">
      <font color="black">How low can you go? Privacy-preserving people detection with an
  omni-directional camera</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、このアプローチの機能性を証明し、認識精度とプライバシー保護の間の最適なトレードオフを決定するために、解像度をどれだけ低くできるかを探ります。この作業では、天井に取り付けられた全方位カメラを使用しますこのような組み込み実装により、必要なメタデータのみを出力する分散型スマートカメラの開発が可能になります（つまり、
[要旨]これは、会議室の占有率を測定するセンサーとして使用できます。フレックスの量も測定可能-デスクの作業スペースが利用可能</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: ESA-ReID: Entropy-Based Semantic Feature Alignment for Person re-ID -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_78.html">
      <font color="black">ESA-ReID: Entropy-Based Semantic Feature Alignment for Person re-ID</font>
    </a>
  </h2>
  <font color="black">セマンティックセグメンテーションの不確実性を考慮して、エントロピーベースのマスクを使用してセマンティックアラインメントを導入します。これにより、マスクセグメンテーションエラーの悪影響を軽減できます。既存のデータセットと新しいデータセットの両方に関する広範な研究は、提案されたモデルの優れたパフォーマンスを示しています。個人の再識別（re-ID）は、現実の世界では困難な作業です。 
[ABSTRACT] re-idには、テレビや映画からの人物識別の再現率を改善するための重要な値もあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Granularity Modularized Network for Abstract Visual Reasoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_79.html">
      <font color="black">Multi-Granularity Modularized Network for Abstract Visual Reasoning</font>
    </a>
  </h2>
  <font color="black">認知研究に触発されて、生の感覚情報の処理とシンボリック推論との間のギャップを埋めるために、マルチグラニュラリティモジュール化ネットワーク（MMoN）を提案します。具体的には、モジュール化推論機能を学習して、ニューロシンボリックと半監視の方法。それを目的として、認知的推論を測定するために設計されたレイヴンプログレッシブマトリックステストに焦点を当てます。 
[ABSTRACT] mmonは抽象的な視覚的推論に適し、一般化テストでも説明可能です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: PointMask: Towards Interpretable and Bias-Resilient Point Cloud
  Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_80.html">
      <font color="black">PointMask: Towards Interpretable and Bias-Resilient Point Cloud
  Processing</font>
    </a>
  </h2>
  <font color="black">PointMaskレイヤーを任意のモデルと組み合わせると、予測スコアに最も貢献する入力空間内のポイントを識別できるため、解釈可能性につながることを示します。具体的には、PointMaskは、入力間の相互情報を最小限に抑える正則化項を導入関係のない変数をマスクするために使用される潜在的な特徴。PointMaskは、一般的なソリューションに徐々に収束しながら、入力スペースの変動要因の大部分を探索することをお勧めします。 
[ABSTRACT] pointmaskは、モデル-俊敏性のある情報-点群モデルの属性のボトルネックアプローチです。提案された方法は、データバイアスの処理に効果的です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Placepedia: Comprehensive Place Understanding with Multi-Faceted
  Annotations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_81.html">
      <font color="black">Placepedia: Comprehensive Place Understanding with Multi-Faceted
  Annotations</font>
    </a>
  </h2>
  <font color="black">この作業では、24万のユニークな場所からの35Mを超える写真を含む大規模な場所データセットであるPlacepediaを提供します。特に、私たちの研究では、1）マルチレベルの場所認識のための統合フレームワークであるPlaceNetを開発します。都市の埋め込み方法。視覚的および多面的な側面情報の両方をキャプチャする都市のベクトル表現を生成できます。写真に加えて、各場所には大量の多面的な情報も含まれます。たとえば、
[ABSTRACT]場所の認識が以前の研究で広く研究されていますが、包括的な場所の理解にはまだ長い道のりがあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Wandering Within a World: Online Contextualized Few-Shot Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_82.html">
      <font color="black">Wandering Within a World: Online Contextualized Few-Shot Learning</font>
    </a>
  </h2>
  <font color="black">この設定に基づいて、大規模な屋内画像に基づく新しい数ショット学習データセットを提案します。これは、世界をさまよっているエージェントの視覚体験を模倣します。さらに、人気の数ショット学習アプローチをオンラインバージョンに変換します。最近の過去の時空間コンテキスト情報を利用できるコンテキストプロトタイプメモリという名前の新しいモデルを提案します。オブジェクトクラスはコンテキスト内で関連付けられ、正しいコンテキストを推測することでパフォーマンスが向上します。 
[ABSTRACT]同じ設定では、エピソードに個別のトレーニングフェーズとテストフェーズはありません。代わりに、新しいクラスを学習しながらモデルがオンラインで評価されます。正しいコンテキストを推測すると、パフォーマンスが向上する可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: JGR-P2O: Joint Graph Reasoning based Pixel-to-Offset Prediction Network
  for 3D Hand Pose Estimation from a Single Depth Image -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_83.html">
      <font color="black">JGR-P2O: Joint Graph Reasoning based Pixel-to-Offset Prediction Network
  for 3D Hand Pose Estimation from a Single Depth Image</font>
    </a>
  </h2>
  <font color="black">具体的には、最初に、グラフ畳み込みネットワーク（GCN）ベースのジョイントグラフ推論モジュールを提案して、ジョイント間の複雑な依存関係をモデル化し、各ピクセルの表現能力を増強します。次に、画像平面と深度の両方で、ジョイントへのすべてのピクセルのオフセットを密に推定します。すべてのピクセルの予測に対する加重平均によってジョイントの位置を計算し、複雑な後処理操作を完全に破棄します。提案されたモデルは、効率的な2D完全たたみ込みネットワーク（FCN）バックボーンで実装され、パラメーターは約1.4Mです。 
[ABSTRACT]新しい方法は、3D手のポーズ推定ベンチマークを使用して新しい方法を作成します。新しい方法は、それがどれだけ効果的に機能するかを予測するために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: SegFix: Model-Agnostic Boundary Refinement for Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_84.html">
      <font color="black">SegFix: Model-Agnostic Boundary Refinement for Segmentation</font>
    </a>
  </h2>
  <font color="black">境界ピクセルから内部ピクセルへの方向を学習することにより、対応を構築します。既存のセグメンテーションモデルによって生成されるセグメンテーション結果の境界品質を改善するために、モデルにとらわれない後処理スキームを提示します。経験的に当社のSegFixが、Cityscapes、ADE20K、GTA5のさまざまな最新モデルから生成されたセグメンテーション結果の境界エラーを一貫して削減していることを確認します。 
[ABSTRACT]元の-信頼できない境界ピクセルの予測を置き換えることをお勧めします。境界ピクセルから内部ピクセルへの方向を学習して対応を構築します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Brain Tumor Anomaly Detection via Latent Regularized Adversarial Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_85.html">
      <font color="black">Brain Tumor Anomaly Detection via Latent Regularized Adversarial Network</font>
    </a>
  </h2>
  <font color="black">モデルは、トレーニングプロセスで通常の画像の一般的なパターンをキャプチャし、潜在空間の再構築エラーに基づいて異常を検出します。さらに、この方法ではまず特異値を使用して潜在空間を制約し、複数の損失関数を通じて画像空間を共同で最適化します。機能レベルで正常サンプルと異常サンプルをより分離できるようにします。このペーパーでは、BraTS、HCP、MNIST、およびCIFAR-10データセットを利用して、有効性と実用性を総合的に評価します。 
[要約]半監視付きの異常検出モデルが提案されており、健康な脳の画像のみがトレーニングされます。この方法では、最初に特異値を使用して潜在空間を制約し、複数の損失関数の基礎を共同最適化して、正常なサンプルと異常なサンプルをさらに増やします分離可能</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Automated analysis of eye-tracker-based human-human interaction studies -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CV/paper_86.html">
      <font color="black">Automated analysis of eye-tracker-based human-human interaction studies</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、このシングルパイプラインフレームワークを使用すると、フィールドでの以前の作業よりも正確で高速な堅牢な結果が得られることを示します。このホワイトペーパーのケーススタディでは、モバイルアイトラッカーの記録に焦点を当てます人間と人間の対面での対話中に作成されました。最近の2つの公開フレームワーク（YOLOv2とOpenPose）を比較して、アイトラッカーによって生成された注視位置をシーンのカメラデータで見える頭と手に関連付けました。 
[要約]モバイルの目を分析するためのソフトウェア-追跡データには依然として堅牢性と機能性が欠けています。この論文では、この単一のパイプライン分析を使用すると堅牢な結果が得られることを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: DeepSinger: Singing Voice Synthesis with Data Mined From the Web -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CL/paper_0.html">
      <font color="black">DeepSinger: Singing Voice Synthesis with Data Mined From the Web</font>
    </a>
  </h2>
  <font color="black">結果は、Webから純粋にマイニングされた歌唱データを使用して、DeepSingerがピッチの正確さと音声の自然さの両方の観点から高品質の歌声を合成できることを示しています（脚注：音声サンプルはhttps://speechresearch.github.io/に示されています） deepsinger /。）。 DeepSingerには、以前のSVSシステムに比べていくつかの利点があります。1）私たちの知る限り、これは音楽Webサイトからトレーニングデータを直接マイニングする最初のSVSシステムです。2）歌詞と歌唱のアラインメントモデルは、アラインメントのための人間の努力をさらに回避します。ラベリングし、ラベリングコストを大幅に削減します。3）フィードフォワードトランスフォーマーに基づく歌唱モデルは、パラメトリック合成で複雑な音響機能モデリングを削除し、参照エンコーダーを利用して歌手の音色を騒々しい歌唱データからキャプチャすることにより、シンプルで効率的です。 、および4）複数の言語および複数の歌手で歌声を合成できます。このホワイトペーパーでは、ディープシンガーを開発しました。ディープシンガーは、マイニングされた歌声トレーニングデータを使用してゼロから構築された多言語マルチシンガー歌声合成（SVS）システムです。音楽のウェブサイトから。 
[ABSTRACT] deepsingerは、音楽Webサイトからトレーニングデータを直接マイニングする最初のsvsシステムです。ピッチ精度と音声の自然さの点で、高品質の歌声を合成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Language (Re)modelling: Towards Embodied Language Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CL/paper_1.html">
      <font color="black">Language (Re)modelling: Towards Embodied Language Understanding</font>
    </a>
  </h2>
  <font color="black">ECLによると、自然言語は本質的に実行可能（プログラミング言語のように）であり、身体的相互作用を通じて学習された構造とスキーマの階層的構成に対するメンタルシミュレーションと比喩的マッピングによって駆動されます。自然言語理解（NLU）は急速に進歩していますが、今日の技術は基本的な方法、特にその劣った効率、解釈可能性、および一般化における人間のような言語の理解。このポジションペーパーは、比喩的な推論およびシミュレーションによる接地の使用がNLUシステムに大きな利益をもたらすと主張し、ロードマップとともにシステムアーキテクチャを提案します。このビジョンの実現に向けて。 
[要約]この作品は、フィリピンの認知言語の理念に基づいた表現と学習へのアプローチを提案しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: Normalizador Neural de Datas e Endereços -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CL/paper_2.html">
      <font color="black">Normalizador Neural de Datas e Endereços</font>
    </a>
  </h2>
  <font color="black">また、この問題を、テキストで発生する可能性のあるエラーをシミュレートするノイズの多いデータで扱います。この課題を回避するために、事前構成されていない日付と住所の形式を90％を超える精度で処理する最新のディープニューラルネットワークのソリューションを提示します。このモデルを使用すると、日付と住所を正規化するタスクが一般化されます。 
[ABSTRACT]アドレスのパターンの乱れは、交換される可能性が高いため、大きくなります。パターンのパターンの乱れは、パターンのパターンパターンで可能です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-27">
        <br><font color="black">2020-06-27</font>
      </time>
    </span>
</section>
<!-- paper0: Pruned Wasserstein Index Generation Model and wigpy Package -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CL/paper_3.html">
      <font color="black">Pruned Wasserstein Index Generation Model and wigpy Package</font>
    </a>
  </h2>
  <font color="black">Word2Vecモデルから埋め込みの単語を取得した後、これらの高次元ベクトルを$ k $ -meansクラスタリングによってクラスター化し、各クラスター内で最も頻繁に使用されるトークンを選択して、「基本語彙」を形成します。Wassersteinインデックス生成モデルの最近の提案（WIG）は、インデックスを自動生成するための新しい方向性を示しています。このバリアントは、剪定WIG（pWIG）と呼ばれ、語彙の次元を自由に縮小できますが、それでも高精度を達成できます。 
[ABSTRACT]ニューヨークベースのツールを使用して新しいツールを作成できます。大規模なデータセットを両方の方法に適合させることは難しいと言います。彼は投げ縄に基づく収縮法を提案して重量を減らします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br><font color="black">2020-03-30</font>
      </time>
    </span>
</section>
<!-- paper0: Rethinking Positional Encoding in Language Pre-training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CL/paper_4.html">
      <font color="black">Rethinking Positional Encoding in Language Pre-training</font>
    </a>
  </h2>
  <font color="black">自己注意モジュールでは、単語のコンテキスト相関と位置相関は、異なるパラメーター化で別々に計算され、その後一緒に追加されます。位置情報をニューラルネットワークに明示的にエンコードする方法は、BERTなどの自然言語の表現を学習する上で重要です。 GLUEベンチマークに関する広範な実験とアブレーション研究は、提案された方法の有効性と効率を実証しています。TUPEは、ほとんどすべてのタスクでいくつかのベースラインを大幅に上回っています。 
[ABSTRACT] transpeercodeに基づくtupeは、単語の埋め込みを入力としてのみ使用します。この設計では、入力の異種の埋め込みに対する追加が削除されます。単語/位置間の関係を特徴付ける表現力が向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-28">
        <br><font color="black">2020-06-28</font>
      </time>
    </span>
</section>
<!-- paper0: Principal Word Vectors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CL/paper_5.html">
      <font color="black">Principal Word Vectors</font>
    </a>
  </h2>
  <font color="black">1つ目は2次変換です。これは、語彙単位と文脈上の特徴に対するさまざまなタイプの重み付けを考慮します。このために、2つのレベルの変換を定義します。外部評価メトリックから得られた結果は、主要な単語ベクトルがいくつかの単語埋め込み方法よりもよく、一般的な単語埋め込み方法と同等です。 
[要約]一般化は2つの主要なレベルで行われます。主な分析はキーレベルに行われます。これらの主な効果には、データ分布を意味のあるものに再形成する適応型非線形変換が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Cultural Cartography with Word Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CL/paper_6.html">
      <font color="black">Cultural Cartography with Word Embeddings</font>
    </a>
  </h2>
  <font color="black">第2に、埋め込みスペースを一定に保ち、ドキュメントまたは作成者がそれに対してどのように移動するかを確認することもできます。これは、船が特定の夜に星を使用して場所を決定するのと同じです。米国での移民言説の経験的事例を使用すると、文化分析への正式なアプローチを進めるためのこれら2つの広範な戦略のメリットを示します。最初に、条件を一定に保ち、埋め込み空間がそれらの周りを移動する方法を測定できます。これは、天文学者が季節による天体の変化を測定したのと同じです。 
[ABSTRACT]単語には、自然言語サンプルでの使用方法に基づいて、との類似性との違いに基づいて場所が割り当てられます。文化分析への正式なアプローチを進めるためのこれら2つの広範な戦略のメリットを示しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: MuSe 2020 -- The First International Multimodal Sentiment Analysis in
  Real-life Media Challenge and Workshop -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CL/paper_7.html">
      <font color="black">MuSe 2020 -- The First International Multimodal Sentiment Analysis in
  Real-life Media Challenge and Workshop</font>
    </a>
  </h2>
  <font color="black">リアルライフメディア（MuSe）2020におけるマルチモーダル感情分析は、視聴覚と言語のモダリティをより包括的に統合することにより、感情認識のタスクに加え、感情ターゲットの関与と信頼性の検出に焦点を当てたチャレンジベースのワークショップです。このホワイトペーパーでは、課題に利用される、この種の最初のインザワイルドデータベースであるMuSe-CaRの詳細情報と、適用される最新の機能およびモデリングアプローチについて説明します。各サブチャレンジに対して、参加者の競争力のあるベースラインが設定されます。つまり、テストでは、MuSe-Wildの結合された（価数と覚醒）CCCが2568、MuSe-Topicのスコア（0.34 $ \ cdot $ UAR + 0.66 $ \ cdot $ F1として計算）が76.78％ 10クラスのトピック、3クラスの感情予測では40.64％、MuSe-Trustでは.4359のCCC。 
[ABSTRACT] muse-車はその種の最初の-より包括的なデータベースです。これは、課題と同様に利用されます。8.museの目的は、さまざまな分野のコミュニティをまとめることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: DISCO PAL: Diachronic Spanish Sonnet Corpus with Psychological and
  Affective Labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CL/paper_8.html">
      <font color="black">DISCO PAL: Diachronic Spanish Sonnet Corpus with Psychological and
  Affective Labels</font>
    </a>
  </h2>
  <font color="black">ただし、この提案は一部の言語で詩に役立つことが証明されていますが、スペイン語の詩と、ソネットなどの高度に構造化された詩の構成の両方に対する研究はありません。このおかげで、ソネットのコーパスは、詩のレコメンダーシステム、著者の性格テキストマイニング研究、治療目的での詩の使用など、さまざまなアプリケーション。この記事では、スペイン語のソネットのラベル付きコーパスに関する研究を紹介し、構築できるかどうかを分析しています。彼らのGAMを予測するために彼らの個々の単語からの特徴。 
[要約]コーパスには15日から19日までの230のスペインのソネットが含まれています。研究者は詩に感情的な特徴と心理学に属するドメインの概念を注釈しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Understand Child-directed and Adult-directed Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CL/paper_9.html">
      <font color="black">Learning to Understand Child-directed and Adult-directed Speech</font>
    </a>
  </h2>
  <font color="black">CDSが学習の初期段階で役立つという兆候が見られますが、最終的には、ADSでトレーニングされたモデルは同等のタスクパフォーマンスに達し、一般化します。子供向けの音声は、繰り返し、単語の選択などの言語的側面で成人向け音声とは異なります。と文の長さだけでなく、韻律や音素変化などの音声信号自体の側面でも同じ結果が得られます。これは、同じパターンが見られるため、これは2つのレジスタの音響特性ではなく言語特性によるものであることを示唆しています。音響的に比較可能な合成音声で訓練されたモデルを見るとき。 
[ABSTRACT]人間の言語習得調査は、子供向けのスピーチが言語学習者を助けることを示しています。これは、2人の話者とは関係がないという事実が原因であることがわかります。結果は、スピーチが原因である可能性があることを示唆していますが、早すぎるのかもしれません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br><font color="black">2020-05-06</font>
      </time>
    </span>
</section>
<!-- paper0: Greedy Transition-Based Dependency Parsing with Discrete and Continuous
  Supertag Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CL/paper_10.html">
      <font color="black">Greedy Transition-Based Dependency Parsing with Discrete and Continuous
  Supertag Features</font>
    </a>
  </h2>
  <font color="black">このようにして、スーパータグ機能を使用した貪欲な遷移ベースの解析で最良の結果を達成します。$ 88.6 \％$ LASおよび$ 90.9 \％$ UASで、英国のペンツリーバンクはスタンフォードディペンデンシーズに変換されます。遷移ベースの依存関係の解析..以前の研究では、単語の1-bestスーパータグを表すスパースブール機能により解析精度が向上することが示されていますが、単語。 
[ABSTRACT]スーパータグ機能により、解析の精度が向上します。スーパータグの継続的な表現を追加することで、さらに改善できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: CompRes: A Dataset for Narrative Structure in News -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CL/paper_11.html">
      <font color="black">CompRes: A Dataset for Narrative Structure in News</font>
    </a>
  </h2>
  <font color="black">データセットが構築されたプロセスについて説明します。最初に、LabovとWaletzkyのナラティブ理論の要素を適用し、新しいナラティブ要素を追加することにより、ニュースメディアにより適した新しいナラティブアノテーションスキームを設計しました。私たち自身（成功）;次に、このスキームを使用して、ニュースおよびパルチザンのウェブサイトから収集された29の英語のニュース記事（1,099文を含む）のセットに注釈を付けます。最後に、将来の作業に対するいくつかの有望な指示を提案します。このペーパーでは、物語の構造を自動的に検出するタスクについて説明します。生のテキストで。 
[ABSTRACT] compresを導入-ニュースメディアでのナラティブインパクトの最初の新しいデータセット。また、社会的インパクトの最初のデータセットであるcompresも導入します。注釈付きデータセットを使用して、いくつかの監視モデルをトレーニングし、さまざまなナラティブ要素を特定します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Reducing Gender Bias in Neural Machine Translation as a Domain
  Adaptation Problem -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CL/paper_12.html">
      <font color="black">Reducing Gender Bias in Neural Machine Translation as a Domain
  Adaptation Problem</font>
    </a>
  </h2>
  <font color="black">新しいドメインでの転移学習の既知の落とし穴は「破局的な忘却」であり、適応と推論の両方で対処します。推論中に、WinoMTのStanovsky et al（2019）で評価されたすべてのシステムよりも優れた格子リスコアリングスキームを提案します。一般的なテストセットBLEUの低下はなく、このスキームを適用して、「ブラックボックス」のオンライン商用MTシステムの出力における性別バイアスを取り除くことができることを示します。適応中に、弾性重み統合により、一般的なテストセット間のパフォーマンスのトレードオフが可能になることを示します。翻訳品質とバイアス削減。 
[ABSTRACT]特に翻訳先の言語に文法上の性別がある場合、性別による偏見は翻訳の質を低下させることが示されています。トレーニングの前にすべてのデータの偏りをなくすことにより、システムの偏見を軽減する必要がありますが、これを効果的に達成すること自体が課題です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: Best-First Beam Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CL/paper_13.html">
      <font color="black">Best-First Beam Search</font>
    </a>
  </h2>
  <font color="black">ベストファーストビームサーチを提案します。これは、最適性（モジュロビームサイズ）を保証するためのスコアリング関数呼び出しの最小数ではありますが、標準のビームサーチと同じ結果のセットを返す可能性があるアルゴリズムです。他のスコアリング機能の中でも、長さの正規化と相互情報の復号化で使用できます。最後に、ダウンストリームのパフォーマンスの点で同様の検索バイアスを持っていますが、数分の一で実行されるベストファーストビーム検索のメモリ削減バリアントを提案します。当時の。 
[ABSTRACT]このジョブのデフォルトのアルゴリズムはビーム検索です。幅の剪定バージョン-最初の検索です。実際には、正確な可能性よりも優れた結果が返されます。これは有益な検索バイアスがあるためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Less is More: Rejecting Unreliable Reviews for Product Question
  Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CL/paper_14.html">
      <font color="black">Less is More: Rejecting Unreliable Reviews for Product Question
  Answering</font>
    </a>
  </h2>
  <font color="black">私たちの調査は、多くの質問が有限のレビューのセットでは答えられない可能性があるという直感に基づいています。コミュニティの質問応答プラットフォームでは）応答が遅くなり、スケーリングされません。さらに、答えられる質問の場合、最も関連性のあるレビューのみ結果に質問への回答を含める必要があります。 
[ABSTRACT]最近の調査によると、製品レビューはリアルタイムの自動製品質問回答（pqa）の優れたソースであることを示しています。このホワイトペーパーでは、レビューを使用してpqaの回答可能性と回答の信頼性の問題に焦点を当てます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Is Japanese gendered language used on Twitter ? A large scale study -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CL/paper_15.html">
      <font color="black">Is Japanese gendered language used on Twitter ? A large scale study</font>
    </a>
  </h2>
  <font color="black">このコーパスに対して大規模なテキスト分析が実行され、テキストに現れるセンテンスファイナルパーティクル（SFP）と一人称代名詞が識別および検査されます。さらに、SFPと代名詞は増加または減少傾向を示し、使用されている言語の進化を示しています。 Twitterで..ツイートの約6％で、実際に性別言語がTwitterでも使用されており、注目すべき例外を除いて、「男性」と「女性」の言語への規範的な分類は、常に期待に応えるものではないことがわかります。 。 
[ABSTRACT] 2015年から2019年までの4億800万のツイートのコレクション。1,000以上のツイートがtwitterで分析されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-29">
        <br><font color="black">2020-06-29</font>
      </time>
    </span>
</section>
<!-- paper0: FinBERT: A Pretrained Language Model for Financial Communications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CL/paper_16.html">
      <font color="black">FinBERT: A Pretrained Language Model for Financial Communications</font>
    </a>
  </h2>
  <font color="black">これが、金融NLPタスクに取り組んでいる実務家や研究者に役立つことを願っています。3つの金融感情分類タスクの実験は、汎用ドメインBERTモデルに対するFinBERTの利点を確認します。コードと事前トレーニング済みモデルは、https：// githubで入手できます。 com / yya518 / FinBERT。 
[ABSTRACT]金融ドメイン固有のbertモデルfinbertが使用可能です。コードと事前学習済みモデルはサイトで入手できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
</section>
<!-- paper0: A Speech Act Classifier for Persian Texts and its Application in
  Identify Speech Act of Rumors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CL/paper_17.html">
      <font color="black">A Speech Act Classifier for Persian Texts and its Application in
  Identify Speech Act of Rumors</font>
    </a>
  </h2>
  <font color="black">実験結果は、RFとSVMを最良の分類子として使用する提案された方法が、ペルシャSAの分類に対して0.95の精度で最先端のパフォーマンスを達成したことを示しています。テキストのSAの知識は、分析に役立ちます。自然言語処理アプリケーションでのそのテキスト。提案されている手法は、テキストを、字句、構文、意味、および表面の4つの基準に基づいて7つのSAクラスに分類します。 
[要約]提案された手法は、字句、構文、意味、表面の4つの基準に基づいて、テキストをsaの7つのクラスに分類します。結果は、ペルシア語の噂が、ナラティブ、質問、脅威を含む3つのsaクラスで表現されることが多いことを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-01-12">
        <br><font color="black">2019-01-12</font>
      </time>
    </span>
</section>
<!-- paper0: Placepedia: Comprehensive Place Understanding with Multi-Faceted
  Annotations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CL/paper_18.html">
      <font color="black">Placepedia: Comprehensive Place Understanding with Multi-Faceted
  Annotations</font>
    </a>
  </h2>
  <font color="black">この作業では、24万のユニークな場所からの35Mを超える写真を含む大規模な場所のデータセットであるPlacepediaを提供します。特に、私たちの研究では、1）マルチレベルの場所認識のための統合フレームワークであるPlaceNetを開発します。都市の埋め込み方法。視覚的および多面的な側面情報の両方をキャプチャする都市のベクトル表現を生成できます。GDP、人口など、および機能、都市、国などを含む複数のレベルのラベル。 
[要約]場所の認識は以前の研究で広く研究されてきましたが、包括的な場所の理解に向けた長い道のりが残っています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Personality Prediction; an Enhanced Method Using Ensemble
  Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/cs.CL/paper_19.html">
      <font color="black">Automatic Personality Prediction; an Enhanced Method Using Ensemble
  Modeling</font>
    </a>
  </h2>
  <font color="black">この目的のために、用語頻度ベクトルベース、オントロジーベース、豊富なオントロジーベース、潜在的意味分析（LSA）ベース、および深層学習ベース（BiLSTM）メソッドを含む5つの新しいAPPメソッドを提案します。主な目的この研究は、テキストからAPPの精度を高めることです。これらのメソッドは基本的なものとして、メタモデルとしての階層的注意ネットワーク（HAN）に基づくアンサンブルモデリング（スタッキング）を通じてAPPの精度を高めるために互いに貢献します。 。 
[要約]この研究の主な目的は、基本的な方法としてapp.theseメソッドの精度を高めることであり、精度を高めるために互いに貢献します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: DeepSinger: Singing Voice Synthesis with Data Mined From the Web -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.AS/paper_0.html">
      <font color="black">DeepSinger: Singing Voice Synthesis with Data Mined From the Web</font>
    </a>
  </h2>
  <font color="black">結果は、Webから純粋にマイニングされた歌唱データを使用して、DeepSingerがピッチの正確さと音声の自然さの両方の観点から高品質の歌声を合成できることを示しています（脚注：音声サンプルはhttps://speechresearch.github.io/に示されています） deepsinger /。）。 DeepSingerには、以前のSVSシステムに比べていくつかの利点があります。1）私たちの知る限り、これは音楽Webサイトからトレーニングデータを直接マイニングする最初のSVSシステムです。2）歌詞と歌唱のアラインメントモデルは、アラインメントのための人間の努力をさらに回避します。ラベリングし、ラベリングコストを大幅に削減します。3）フィードフォワードトランスフォーマーに基づく歌唱モデルは、パラメトリック合成の複雑な音響機能モデリングを削除し、リファレンスエンコーダーを利用して歌手のデータをノイズの多い歌唱データからキャプチャすることにより、シンプルで効率的です。 、および4）複数の言語と複数の歌手で歌声を合成できます。具体的には、歌詞と歌声のアラインメントモデルを設計して、粗粒度の文レベルから細かい粒度まで、歌詞の各音素の継続時間を自動的に抽出します。音素レベル、さらにフィードフォワードトランスフォーマーに基づく多言語、マルチシンガー歌唱モデルを設計して、歌詞から線形スペクトログラムを直接生成し、 d Griffin-Limを使用して音声を合成します。 
[ABSTRACT] deepsingerは、音楽Webサイトからトレーニングデータを直接マイニングする最初のsvsシステムです。ピッチ精度と音声の自然さの点で、高品質の歌声を合成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: RWCP-SSD-Onomatopoeia: Onomatopoeic Word Dataset for Environmental Sound
  Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.AS/paper_1.html">
      <font color="black">RWCP-SSD-Onomatopoeia: Onomatopoeic Word Dataset for Environmental Sound
  Synthesis</font>
    </a>
  </h2>
  <font color="black">そこで本稿では、環境音合成用の音声サンプルと155,568個の擬音語を組み合わせたデータセットRWCP-SSD-Onomatopoeiaを提示する。擬音語は環境音合成に利用できると考える。擬音語は説明に有効である音の特徴。 
[ABSTRACT]環境音の合成では、サウンドイベントラベルを使用して環境を作成します。ただし、環境音に使用できるデータセットはありません。また、自己報告された信頼スコアなど、オノマトペ単語の受容スコアも収集しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-task Regularization Based on Infrequent Classes for Audio
  Captioning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.AS/paper_2.html">
      <font color="black">Multi-task Regularization Based on Infrequent Classes for Audio
  Captioning</font>
    </a>
  </h2>
  <font color="black">&quot;a&quot;、 &quot;the&quot;）、および他の単語はまれですが、有益です。次に、マルチクラスのワードレベルの音声キャプションタスクに加えて、別のデコーダーをトレーニングすることにより、クリップレベルのコンテンツワード検出に基づいてマルチラベルのサイドタスクを定義します。このホワイトペーパーでは、このクラスを軽減する2つの方法を提案します。不均衡の問題。 
[ABSTRACT]オーディオキャプションの自動エンコーダ設定で、トレーニング損失に対する各単語の寄与を、データセット全体での発生数に反比例して重み付けします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: MuSe 2020 -- The First International Multimodal Sentiment Analysis in
  Real-life Media Challenge and Workshop -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.AS/paper_3.html">
      <font color="black">MuSe 2020 -- The First International Multimodal Sentiment Analysis in
  Real-life Media Challenge and Workshop</font>
    </a>
  </h2>
  <font color="black">サブチャレンジごとに、参加者の競争力のあるベースラインが設定されます。つまり、テストでは、MuSe-Wildの結合した（価数と覚醒）CCCが2568、MuSe-Topicのスコア（0.34 $ \ cdot $ UAR + 0.66 $ \ cdot $ F1として計算）が76.78％ 10クラスのトピックと3クラスの感情予測に関する40.64％、およびMuSe-Trustの場合、CCCは4359です。現実世界のメディアにおけるマルチモーダル感情分析（MuSe）2020は、次のタスクに焦点を当てたチャレンジベースのワークショップです感情認識、および視聴覚と言語のモダリティをより包括的に統合することによる、感情ターゲットの関与と信頼性の検出。このホワイトペーパーでは、この種の業界初のMuSe-CaRに関する詳細情報を提供します。挑戦のために利用される野生のデータベース、ならびに適用される最先端の機能およびモデリングアプローチ。 
[ABSTRACT] muse-車はその種の最初の-より包括的なデータベースです。これは、課題と同様に利用されます。8.museの目的は、さまざまな分野のコミュニティをまとめることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.AS/paper_4.html">
      <font color="black">PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern
  Recognition</font>
    </a>
  </h2>
  <font color="black">PANNのソースコードと事前トレーニング済みモデルをリリースしました：https://github.com/qiuqiangkong/audioset_tagging_cnn ..最近、ニューラルネットワークが音声パターン認識の問題に取り組むために適用されています。音声パターン認識は、機械学習領域には、オーディオのタグ付け、音響シーンの分類、音楽の分類、スピーチの感情の分類、サウンドイベントの検出など、いくつかのタスクが含まれます。 
[ABSTRACT]このペーパーでは、重要なトピックでトレーニングされた事前トレーニング済みのオーディオニューラルネットワーク（パン）を提案します。パン転送の最適なシステムは、最新の平均平均精度（マップ）です。ソースコードをリリースし、事前トレーニング済みパンのモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-21">
        <br><font color="black">2019-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Capturing scattered discriminative information using a deep architecture
  in acoustic scene classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-10/eess.AS/paper_5.html">
      <font color="black">Capturing scattered discriminative information using a deep architecture
  in acoustic scene classification</font>
    </a>
  </h2>
  <font color="black">提案された方法を検証するために、音響シーンとイベント2020 task1-aデータセットの検出と分類を使用して、さまざまな実験が行われます。音響シーン分類（ASC）には、多くの一般的な音響特性を共有するクラスのペアが頻繁に誤分類されます。ディープニューラルネットワークの従来の非線形アクティベーションを置き換える最大機能マップ手法。したがって、畳み込み層の出力の異なるフィルター間に要素ごとの比較を適用します。 
[ABSTRACT]提案されたシステムは一貫してベースラインを上回っています。単一の最高性能システムは70の精度を持っています。4％.2つのデータ補強方法と2つのディープアーキテクチャモジュールが過剰適合を減らすためにさらに検討されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
