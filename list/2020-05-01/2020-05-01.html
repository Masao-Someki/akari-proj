<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-05-01の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: CopyCat: Many-to-Many Fine-Grained Prosody Transfer for Neural
  Text-to-Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.SD/paper_0.html">
      CopyCat: Many-to-Many Fine-Grained Prosody Transfer for Neural
  Text-to-Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本稿では、並列データを使用せずに、ソーススピーカーの漏れに対してロバストな、新規の多対多のPTシステムであるCopyCatを提案します。これは、ロバストな時間韻律表現をキャプチャできる新しいリファレンスエンコーダアーキテクチャによって実現します。この問題を軽減するために、彼らはPTの品質に妥協します。 
[ABSTRACT]新しいテクニックは、ソーススピーカーの声から、リズム、強調、メロディー、持続時間、ラウドネスなどの韻律の側面をキャプチャすることを目的としています。目的は、韻律の品質を維持し、それらを韻律の異なるターゲットスピーカーに転送することですボイス
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: MuSe 2020 -- The First International Multimodal Sentiment Analysis in
  Real-life Media Challenge and Workshop -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.SD/paper_1.html">
      MuSe 2020 -- The First International Multimodal Sentiment Analysis in
  Real-life Media Challenge and Workshop
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちは3つの異なるサブチャレンジを提示します。MuSe-Wildは、継続的な感情（覚醒と価数）の予測に焦点を当てています。 MuSe-Topic。参加者はドメイン固有のトピックを3クラス（低、中、高）感情のターゲットとして認識します。信頼性の新しい側面が予測されるMuSe-Trust。このホワイトペーパーでは、MuSe-CaRに関する詳細情報を提供します。最先端の機能と適用されたモデリングアプローチだけでなく。サブチャレンジごとに、参加者の競争力のあるベースラインが設定されます。つまり、テストでは、MuSe-Wildの結合した（価数と覚醒）CCCが2568、MuSe-Topicのスコア（0.34 $ \ cdot $ UAR + 0.66 $ \ cdot $ F1として計算）が76.78％ 10クラスのトピック、3クラスの感情予測では40.64％、MuSe-Trustでは.4359のCCC。 
[ABSTRACT] muse-車はその種の最初の-より包括的なデータベースです。これは、課題に使用されます。同様に、8.museの目的とは、さまざまな分野のコミュニティをまとめることです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A convolutional neural-network model of human cochlear mechanics and
  filter tuning for real-time applications -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.SD/paper_2.html">
      A convolutional neural-network model of human cochlear mechanics and
  filter tuning for real-time applications
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      聴覚モデルは、自動音声認識システムの特徴抽出器として、またはロボット工学、機械聴覚、補聴器アプリケーションのフロントエンドとして一般的に使用されています。取り込みを可能にするために、畳み込みニューラルネットワークを計算神経科学と組み合わせるハイブリッドアプローチを提示します。人間の蝸牛力学とレベル依存の蝸牛フィルター調整（CoNNear）のリアルタイムのエンドツーエンドモデルを生成します。CoNNearモデルは音響音声材料でトレーニングされましたが、そのパフォーマンスと適用性は（目に見えない）音刺激を使用して評価されました蝸牛力学研究で一般的です。 
[ABSTRACT] connearモデルは音響音声資料でトレーニングされましたが、そのパフォーマンスと適用性は（目に見えない）音刺激を使用して評価されました。このモデルには、リアルタイムの聴覚アプリケーションを人間のパフォーマンスに活用し、次世代の音声認識を刺激する力があります、ロボット工学、補聴器システム
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The role of context in neural pitch accent detection in English -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.SD/paper_3.html">
      The role of context in neural pitch accent detection in English
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      すべてのコンテンツワードのピッチアクセントを予測するだけの単純なベースラインが82.2％の精度をもたらすこともわかりました。これがこのタスクに適切なベースラインであることをお勧めします。最後に、ピッチが最も重要な音響であることを示すアブレーションテストを実施しますこのタスクとコーパスの機能..これらの革新により、ボストン大学ラジオニュースコーパスでのアメリカ英語音声のピッチアクセント検出の精度が87.5％から88.7％に向上し、最新の結果が得られます。 。 
[要約]音声の韻律的イベントを検出する方法が必要です。これらの革新により、87.5％から88％の改善が見られます。7％。アブレーションテストを実施し、ピッチがこのタスクとこれの最も重要な音響機能であることを示していますコーパス
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Paraphrasing vs Coreferring: Two Sides of the Same Coin -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_0.html">
      Paraphrasing vs Coreferring: Two Sides of the Same Coin
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最初に、遠くの監督としてイベント共参照データセットからの注釈を使用して、ヒューリスティックに抽出された述語の言い換えを再スコアリングします。この結果は、各タスクのデータとモデルを活用して、他のタスクに利益をもたらす有望な方向を示唆しています。 2つの異なるNLPタスク間の潜在的な相乗効果。どちらも字句の変動性に直面しています。つまり、述語の言い換えとイベントの共参照の解決です。 
[要約]さまざまな機能を使用して、ヒューリスティックにスコアを付け直しました-抽出された述語の言い換え
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Semantic Triple Encoder for Fast Open-Set Link Prediction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_1.html">
      Semantic Triple Encoder for Fast Open-Set Link Prediction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      リンク予測用に特別に設計された2つの目的を最適化することにより、このセマンティックトリプルエンコーダーをトレーニングします。さらに、最近のコンテキストベースのエンコーディングアプローチと比較して、推論コストを1桁または2桁経験的に削減し、その間、優れた品質の予測を維持します。 ..実験では、人気のある3つのリンク予測ベンチマークで、最先端または競争力のあるパフォーマンスを達成しています。 
[要旨] stint stint stintsなどの以前のメソッドは、グラフ埋め込みモデルに基づいて構築されました。これらには、各部分とそのコンテキストを潜在的意味空間にマッピングするエンコーダーの説明が含まれています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: STARC: Structured Annotations for Reading Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_2.html">
      STARC: Structured Annotations for Reading Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、エラーの分布や推測能力など、機械と人間の読解動作の詳細な分析と比較が可能であることを示します。複数選択の読解を評価するための新しい注釈フレームワークであるSTARC（読解のための構造化注釈）を提示します。質問..私たちの実験では、NLPの標準的な多肢選択データセットであるRACEも、読解力を測定する能力が制限されていることがわかりました。 
[ABSTRACT] starcはsatの開発のための重要な新しいアプリケーションに活用できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploring Contextualized Neural Language Models for Temporal Dependency
  Parsing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_3.html">
      Exploring Contextualized Neural Language Models for Temporal Dependency
  Parsing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーでは、BERTベースの時間依存パーサーのいくつかのバリアントを開発し、BERTが時間依存パースを大幅に改善することを示しています（ZhangおよびXue、2018a）。と時間に関連する質問への回答。これは、BERTなどのディープ言語モデルによってキャプチャされる可能性のある文または談話レベルの構文情報と意味情報を必要とする挑戦的な問題です（Devlin et al。、2019）。 
[ABSTRACT]問題には構文情報と意味情報が必要です。これらの情報はディープ言語モデルによって取得される可能性があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Vocabulary Adaptation for Distant Domain Adaptation in Neural Machine
  Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_4.html">
      Vocabulary Adaptation for Distant Domain Adaptation in Neural Machine
  Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      英語から日本語への翻訳およびドイツ語から英語への翻訳の遠方ドメイン適応に関する実験結果は、語彙の適応により微調整のパフォーマンスが3.6 BLEUポイント向上することを示しています。微調整の前に、この方法はターゲットドメインの単一言語データから誘導された一般的な単語の埋め込みをソースドメインの埋め込みスペースに投影することにより、NMTモデルのレイヤーを埋め込みます。ただし、遠く離れたドメイン（サブタイトルや研究論文など）間のドメイン適応は、語彙の不一致;多くのドメイン固有の未知の単語（たとえば、「angstrom」）とドメイン間で意味が変化する単語（たとえば、「コンダクター」）に遭遇します。 
[要約]この問題に対する標準的なアプローチは、ターゲットドメインに小さな並列データを構築し、大量の並列データが利用可能なソースドメインからドメイン適応を実行することです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Mind Your Inflections! Improving NLP for Non-Standard English with
  Base-Inflection Encoding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_5.html">
      Mind Your Inflections! Improving NLP for Non-Standard English with
  Base-Inflection Encoding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      言語的および統計的手法を組み合わせることによって達成される、英語テキストの新しいBase-Inflection Encodingを紹介します。この新しいエンコーディングの下でダウンストリームタスクの事前トレーニング済みNLPモデルを微調整すると、標準のパフォーマンスを維持しながら、非標準の活用の使用に対する堅牢性を実現できます英語の例..このエンコーディングを使用するモデルは、明示的なトレーニングを行わなくても、非標準の方言により一般化されます。 
[ABSTRACT]新しいベースを導入します-英語のテキストを活用します。これらのモデルは、非標準の方言にも一般化します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Few-Shot Learning for Abstractive Multi-Document Opinion Summarization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_6.html">
      Few-Shot Learning for Abstractive Multi-Document Opinion Summarization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、矛盾する情報を反映する可能性が高く、流暢でより優れた抽象的要約も、監視なしの方法で作成できることが示されています。この作業では、要約のブートストラップ生成に十分な要約でも十分であることを示しています。書体、情報量、流暢さ、感情保持など、予想されるすべてのプロパティを含むテキスト。モデルはプロパティを認識しています。最初にプロパティ値を生成し、次に、それらに基づいてレビューを作成します。 
[要約]タスクは実際に重要であり、多くの注目を集めています。代わりに、伝統的に抽出方法でアプローチされていました。これらのモデルは、実際の要約に公開されていないため、本質的なプロパティを取得できません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Conditional Neural Generation using Sub-Aspect Functions for Extractive
  News Summarization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_7.html">
      Conditional Neural Generation using Sub-Aspect Functions for Extractive
  News Summarization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      どのサブアスペクト関数を柔軟に制御できるニューラルフレームワークを提案します（これらの結果は、より柔軟なニューラル要約フレームワークがさまざまなアプリケーションのニーズに合わせて調整するためのより多くの制御オプションを提供できることを示唆しています。最小の位置バイアスで要約を自動的に抽出することを示します位置バイアスを利用する標準モデルと少なくとも同等のパフォーマンスを達成できます。
[要約]多様性に焦点を当てて生成されたニュースの要約は、人間の評価者がより好む可能性があることも示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Retrospective Reader for Machine Reading Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_8.html">
      Retrospective Reader for Machine Reading Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      機械読解（MRC）は、特定のパッセージに基づいて質問に対する正しい答えを決定するために機械を必要とするAIチャレンジです。人間が読解の質問をどのように解決するかに触発されて、2つの段階を統合する回顧的リーダー（レトロリーダー）を提案しました読解と検証の戦略：1）パッセージと質問の全体的な相互作用を簡単に調査し、最初の判断をもたらす大ざっぱな読解。 2）回答を検証し、最終的な予測を与える集中的な読書。提案された読者は、2つのベンチマークMRCチャレンジデータセットSQuAD2.0およびNewsQAで評価され、新しい最先端の結果を達成します。 
[要約]提案されたリーダーは、2つのベンチマークmrcチャレンジデータセットsquad2で評価されます。 0とnewsqa、新しい最先端の結果を達成
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-27">
        <br>2020-01-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Look at the First Sentence: Position Bias in Question Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_9.html">
      Look at the First Sentence: Position Bias in Question Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      位置バイアスなしで安全に位置情報を提供するために、エントロピー正則化やバイアスエンサンブルなど、さまざまなバイアス解除方法でモデルをトレーニングします。その中でも、バイアスモデルとして応答位置の事前分布を使用すると、位置バイアスを減らすのに非常に効果的であることがわかりました。バイアスされたSQuADデータセットでトレーニングされたときにBERTのパフォーマンスを35.24％から81.17％に回復します。位置としての予測回答の選択は、主にその単純さと有効性によるものです。 
[ABSTRACT]回答を位置として予測することの選択は、主にその単純さと有効性によるものです。調査では、回答モデルの事前分布をバイアスモデルとして使用することが、位置バイアスを減らすのに非常に効果的であり、ベルトのパフォーマンスを35から24に回復しています。 81. 17％
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Injection of Knowledge into Dialogue Generation via
  Language Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_10.html">
      Unsupervised Injection of Knowledge into Dialogue Generation via
  Language Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      したがって、外部の知識なしでモデルが魅力的な応答を生成することも重要です。外部の知識を使用したトレーニングとテストの成功にもかかわらず、実際には、議論されたトピックに関する十分な背景知識が常にあるとは限りません。経験的に、異なる量の知識が与えられた場合のパフォーマンスの差異は重要です。 
[ABSTRACT]知識のないモデルのテスト、知識の部分的および全文。効果は、部分的または全文でモデルをテストすることによってさらに分析されます。この方法は、ベースラインよりも監視された方法に近いパフォーマンスを発揮します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Automatic Machine Translation Evaluation in Many Languages via Zero-Shot
  Paraphrasing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_11.html">
      Automatic Machine Translation Evaluation in Many Languages via Zero-Shot
  Paraphrasing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      前述の言い換えを多言語NMTシステムとしてトレーニングし、言い換えをゼロショットの「言語ペア」として扱います（たとえば、ロシア語からロシア語）。言い換えは、人間の参照を入力として受け取り、MTシステムを強制デコードしてスコア付けします。 output ..自動機械翻訳評価のために、シーケンスからシーケンスへの言い換えを使用することを提案します。 
[ABSTRACT]モデルの出力確率のモードはコピーを中心としているため、言い換えを「偏りのない」と表現します。参照ではなく、ソースを条件とするモデルを使用して探索します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Mutlitask Learning for Cross-Lingual Transfer of Semantic Dependencies -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_12.html">
      Mutlitask Learning for Cross-Lingual Transfer of Semantic Dependencies
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      英語がソースでチェコ語がターゲット言語である設定では、ドメイン内のSemEvalデータ（Oepen et al。、2015）で、シングルタスクベースラインよりも優れたマルチタスクモデルにより、ラベル付きF1スコアが1.8向上します。ドメイン外テストセットの2.5と同様です。監視対象のセマンティック依存関係解析アノテーションを並列データを通じてリッチリソース言語から低リソース言語に転送し、予測データでセマンティックパーサーをトレーニングします。注釈投影法と組み合わせたマルチタスク学習フレームワーク。 
[要旨]監視付き構文解析をマルチタスク学習フレームワークの補助タスクとして使用します。さまざまなマルチタスク学習設定により、一貫して単一タスクのベースラインを改善します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Facet-Aware Evaluation for Extractive Summarization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_13.html">
      Facet-Aware Evaluation for Extractive Summarization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      データはhttps://github.com/morningmoni/FAR。にあります。この新しい評価設定を容易にするために、CNN / Daily Mailデータセットの抽出バージョンを作成し、徹底的な定量調査を実行して、そのファセットを示しますを意識した評価は、ROUGEよりも人間の判断との相関性が高く、きめの細かい評価と比較分析を可能にし、最新の要約方法に関する貴重な洞察を明らかにします。具体的には、参照サマリーの各文を\ textit {facet}、各ファセットのセマンティクスを表現するドキュメント内の文をファセットの\ textit {support文}として識別し、抽出された文のインデックスを比較することにより抽出要約手法を自動的に評価し、すべての参照サマリーのファセット。 
[要約]このホワイトペーパーでは、情報をより適切に評価するために、cnn /毎日のメールデータセットの抽出バージョンを作成します。データを比較することにより、ファセット-意識的な評価は、ルージュよりも人間の判断との相関性が優れていることを示しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-27">
        <br>2019-08-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Using Punkt for Sentence Segmentation in non-Latin Scripts: Experiments
  on Kurdish (Sorani) Texts -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_14.html">
      Using Punkt for Sentence Segmentation in non-Latin Scripts: Experiments
  on Kurdish (Sorani) Texts
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの実験では、91.10％のF1スコアを達成し、エラー率は16.32％でした。文献によると、ラテン語以外のデータでパンクを使用した研究は不十分です。さまざまなセグメント化されたコーパスの欠如は、クルド語の処理における主要なボトルネック。 
[要約] kurdishdinaは多方言、リソース不足の言語です。異なるスクリプトで記述され、非商用目的で記述されています。データはwwwで公開されています。 github。 com
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br>2020-04-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Logic2Text: High-Fidelity Natural Language Generation from Logical Forms -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_15.html">
      Logic2Text: High-Fidelity Natural Language Generation from Logical Forms
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      データセットとコードは\ url {https://github.com/czyssrs/Logic2Text}で入手できます。新しい大規模なデータセット\ textsc {Logic2Text}を提供します。基本の論理形式..私たちのデータセットが、自然で忠実な人間のような生成が可能な高度なNLGシステムの構築に向けた研究を促進することを願っています。 
[要約]この作品では、制御可能で忠実な忠実な世代を得るために、論理レベルからの世代として論理レベルnlgを定式化します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Text Segmentation by Cross Segment Attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_16.html">
      Text Segmentation by Cross Segment Attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ドキュメントと談話のセグメンテーションは、テキストを構成要素に分割することに関連する2つの基本的なNLPタスクであり、情報の取得やテキストの要約などの下流のタスクを支援するために一般的に使用されます。特に、すべてのケースで大きなマージンによるエラー率。この作業では、3つのトランスベースのアーキテクチャを提案し、3つの標準データセットで以前に提案されたアプローチとの包括的な比較を提供します。 
[ABSTRACT]この作業では、3つのトランスフォーマーベースのアーキテクチャを提案します。これらには、3つの標準データセットに関する以前に提案された提案との比較が含まれます。さらにモデルサイズを分析し、良好なパフォーマンスを維持しながら、質問の数がはるかに少ないモデルを構築できることを確認します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to Ask Screening Questions for Job Postings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_17.html">
      Learning to Ask Screening Questions for Job Postings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      LinkedInで$ 20 $ Mのアクティブな求人すべてに選別用の質問を追加するために、特定の求人情報の選別用の質問を自動的に生成することを目的とした新しいタスクを提案します。これは履歴データのない新製品なので、限られたトレーニングデータで複雑なモデルをトレーニングします。採用効率を向上させ、各応募者を手動でスクリーニングする必要性を減らすために、採用担当者がオンラインでスクリーニングの質問をすることができる新製品を開発し、適格な候補者を簡単にフィルタリングできるようにします。 
[ABSTRACT] Linkedinで$ 20 $ mのすべてのアクティブジョブに選別用の質問を追加するために、ジョブの作成を目的とした新しいタスクを提案します。ディープトランスファーラーニングを使用して、限られたトレーニングデータで複雑なモデルをトレーニングします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: TextAT: Adversarial Training for Natural Language Understanding with
  Token-Level Perturbation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_18.html">
      TextAT: Adversarial Training for Natural Language Understanding with
  Token-Level Perturbation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、入力が単純な正規化ボールの下で制約されるのではなく、個別のトークンであることを考慮して、これらの摂動を制約します。したがって、シーケンスレベルのタスクに敵対的なトレーニングを組み込むために、新しいトレーニング戦略を導入します。トークンレベルの摂動によるテキスト敵対トレーニング..敵対的トレーニングは、ニューラルネットワークの堅牢性の向上に効果的です。 
[ABSTRACT]細かいトークンを使用して初期化されるクラフトの摂動を拳化します。このような正規化方法の有効性を検証します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Universal Dependencies according to BERT: both more specific and more
  general -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_19.html">
      Universal Dependencies according to BERT: both more specific and more
  general
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのアプローチは、以前の研究よりもはるかに一貫性のある依存関係ツリーを生成し、BERTの構文抽象化をよりよく説明することを示しています。関係の識別と構文ツリーの構築の方法を提案します。BERT関係をユニバーサル依存関係と明示的に比較することにより、これらの結果を拡張します（ UD）アノテーションは、1対1で一致しないことが多いことを示しています。 
[ABSTRACT]以前の研究では、個々のバートヘッドが特定の依存関係タイプをエンコードする傾向があることが示されています。最小限の監視のみで正常に適用できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Molweni: A Challenge Multiparty Dialogues-based Machine Reading
  Comprehension Dataset with Discourse Structure -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_20.html">
      Molweni: A Challenge Multiparty Dialogues-based Machine Reading
  Comprehension Dataset with Discourse Structure
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Molweniは、Ubuntu Chat Corpusからのソースサンプルで、88,303発話を含む10,000ダイアログが含まれています。Molweniは、マルチパーティダイアログの談話依存性アノテーションにも独自に貢献しており、大規模な（78,246の注釈付き談話関係）データを提供して、マルチパーティダイアログの理解のタスクに関与しています。 。このコーパスでは、答えられる質問と答えられない質問の両方を含む32,700の質問に注釈を付けます。 
[要約] umチャットチームが10,000件のubuntuチャットコーパスを分析しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-10">
        <br>2020-04-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: TLDR: Extreme Summarization of Scientific Documents -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_21.html">
      TLDR: Extreme Summarization of Scientific Documents
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      科学論文のTLDR生成、エキスパートの背景知識と複雑な言語の理解を必要とする高ソース圧縮を備えた新しい自動要約タスクを紹介します。さらに、ピアレビューコメントを書き換えて追加の金要約をスケーラブルにキュレートするための新しい注釈プロトコルを紹介します。 TLDR生成と、極端な要約およびタイトル生成の関連タスクとの間の類似性を活用する事前トレーニング済み言語モデルを適応させるためのトレーニング戦略。強力な抽出および抽象要約ベースラインよりも優れています。 
[要約]このプロトコルを使用してテストセットを拡張し、評価用に複数のゴールドTLDRを生成します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Capsule-Transformer for Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_22.html">
      Capsule-Transformer for Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      広く使用されている機械翻訳データセットの実験結果は、提案されたカプセルトランスフォーマーが強力なトランスフォーマーのベースラインを大幅に上回っていることを示しています。具体的には、SANの注意の重みのグループは低層カプセルとして見られます。ヘッドセルフアテンションネットワーク（SAN）。与えられた入力をさまざまな部分空間に変換することにより、さまざまな視点から情報を抽出します。 
[ABSTRACT]変圧器によって開発されたソフトウェアは、マルチジェネレーター戦略に基づいています。ソフトウェアは、乗客の乗客のデータを取り除くために使用できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Analyzing the Surprising Variability in Word Embedding Stability Across
  Languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_23.html">
      Analyzing the Surprising Variability in Word Embedding Stability Across
  Languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      単語の埋め込みは、英語と他の言語の両方で、多くの自然言語処理アーキテクチャとタスクの基礎を形成する強力な表現です。複数の言語の単語の埋め込みについてさらに理解を深めるために、最も近い言語間の重なりとして定義されるそれらの安定性を調査します異なる埋め込みスペース内の単語の隣接。安定性に関連する言語特性について説明し、形態学的およびその他の機能が安定性にどのように関連するかについての洞察を引き出します。 
[ABSTRACT]複数の言語での単語の埋め込みについてさらに理解を深めるために、単語の最も近い隣同士の重なりとして定義されるそれらの安定性を調査します。これは、埋め込みの使用に影響を与えます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Measuring Societal Biases in Text Corpora via First-Order Co-occurrence -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_24.html">
      Measuring Societal Biases in Text Corpora via First-Order Co-occurrence
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この2次関係は測定に無関係な概念を導入し、バイアスの不正確な測定を引き起こすと主張します。新しいコーパスバイアス測定方法を研究するために、テキストから推定された性別バイアス値の実際の相関を計算します最近の2つのコレクションによって提供された、米国の求人市場の性別バイアス統計。結果は、提案された一次測度をさまざまな単語埋め込みモデルとともに使用した場合、一貫してより高い相関関係を示し、特により深刻なバイアスいくつかの特定の職業の女性に。 
[ABSTRACT]単語の概念への偏りは通常、類似性を使用して推定され、単語と概念の単語が環境内で他の単語を共有するかどうかを測定します。代わりに、単語間の直接正規化共起関連を使用して偏りを測定することを提案します代表的なコンセプトワード
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-13">
        <br>2018-12-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Imitation Attacks and Defenses for Black-box Machine Translation Systems -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_25.html">
      Imitation Attacks and Defenses for Black-box Machine Translation Systems
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの脆弱性を軽減するために、模倣モデルの最適化を誤った方向に向けるために翻訳の出力を変更する防御策を提案します。ブラックボックス機械翻訳（MT）システムを盗用または攻撃して金銭的利益を得たり、攻撃したりする敵を検討します。モデルエラーの悪用..意味論的に正しくない翻訳、コンテンツのドロップ、下品なモデル出力につながる入力を公開する勾配ベースの攻撃を使用します。 
[要旨] 3つのデータシステムの0. 6ブルー以内に到達するレプリカモデルをテストします。翻訳、コンテンツのドロップ、下品なモデル出力を公開するシステムを使用します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ktrain: A Low-Code Library for Augmented Machine Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_26.html">
      ktrain: A Low-Code Library for Augmented Machine Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      TensorFlowおよび他の多くのライブラリ（トランスフォーマー、scikit-learn、stellargraphなど）のラッパーとして、洗練された最先端の機械学習モデルを簡単に構築、トレーニング、検査、デプロイできるように設計されています初心者と経験豊富な実務家..テキストデータ（テキスト分類、シーケンスタグ付け、オープンドメインの質問応答など）、ビジョンデータ（画像分類など）、グラフデータ（ノード分類、リンク予測など）をサポートするモジュールを搭載、ktrainは、3つまたは4つの「コマンド」またはコード行で幅広いタスクをすばやく解決できるシンプルな統合インターフェースを提供します。機械学習をよりアクセスしやすくする低コードのPythonライブラリであるktrainを提示します。適用が簡単です。 
[ABSTRACT]洗練された最先端の機械学習モデルをシンプルにするように設計されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-19">
        <br>2020-04-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: RikiNet: Reading Wikipedia Pages for Natural Question Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_27.html">
      RikiNet: Reading Wikipedia Pages for Natural Question Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Natural Questions（NQ）データセットでは、単一のRikiNetが74.3 F1と57.9 F1をロングアンサーとショートアンサーのタスクで達成します。このホワイトペーパーでは、RikiNetと呼ばれる新しいモデルを紹介します。 ..さらに、アンサンブルRikiNetは、ロングアンサータスクとショートアンサータスクで76.1 F1および61.3 F1を取得し、公式のNQリーダーボードで最高のパフォーマンスを達成します。ウィキペディアのページを読むために使用される最初のモデルです。このモデルは、rikinetと呼ばれる新しいモデルに適合するように設計されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improved Natural Language Generation via Loss Truncation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_28.html">
      Improved Natural Language Generation via Loss Truncation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      識別可能性を最適化するために、トレーニング中に高損失の例を適応的に削除する損失切り捨てを提案します。これは、ログ損失と同じように最適化が容易であり、ノイズ下での識別可能性を厳密に制限します。最適化は簡単ですが、このアプローチではモデルが強制的に再現されますノイズの多い無効な参照（誤記や幻覚の事実など）を含む、データセット内のすべてのバリエーション。 
[ABSTRACT]モデルの識別性により、誤記や幻覚の事実が取り除かれることを示します。これは、対数損失と同じくらい大きく、ノイズ下での識別性を厳密に制限します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Simulated Multiple Reference Training Improves Low-Resource Machine
  Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_29.html">
      Simulated Multiple Reference Training Improves Low-Resource Machine
  Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      英語の言い換えを使用して、1.2〜7 BLEUのゲインで、低リソース設定でのメソッドの有効性を示します。特定の文に対して多くの有効な翻訳が存在しますが、機械翻訳（MT）は単一の参照翻訳でトレーニングされます、低リソース設定でのデータスパース性を悪化させます。可能な翻訳の全空間を近似する新しいMTトレーニング方法を導入します。パラフレーズから参照文の言い換えをサンプリングし、MTモデルをトレーニングして可能な以上のパラフレーズの分布を予測トークン。 
[ABSTRACT]可能なトークンの数を予測する新しいmtトレーニング方法を導入します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Fact or Fiction: Verifying Scientific Claims -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_30.html">
      Fact or Fiction: Verifying Scientific Claims
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ウィキペディアの記事または政治ニュースでトレーニングされたファクトチェックモデルは、私たちのタスクに一般化することが困難ですが、単純なドメイン適応技術は改善の有望な手段を表します。さらに、証拠の形でその予測の根拠を提供する必要があります。取得した要約からの文。ベースラインモデルを提示し、SciFactでのそのパフォーマンスを評価します。 
[要約] 1.4kの専門家のデータセットを紹介します-証拠と対になった科学的主張を書いてください。データセットはwwwsで公開されます。アレンビッドのアプリ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Recipes for Adapting Pre-trained Monolingual and Multilingual Models to
  Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_31.html">
      Recipes for Adapting Pre-trained Monolingual and Multilingual Models to
  Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ベトナム語から英語へのドメイン外のトレーニングセットに制限すると、微調整のベースラインが0.9 BLEUを上回ります。BARTの場合、モデルパラメータのほとんどをフリーズし、位置埋め込みを追加することで、最高のパフォーマンスが得られます。単言語データの事前トレーニングと機械翻訳（MT）の微調整は最近成功していますが、特定のMTタスクに対して事前トレーニングされたモデルを最適に活用する方法は依然として不明です。 
[ABSTRACT] snowに加えて、25言語からの単一言語データのモデルを微調整しています。mbartの場合は、素朴な細かいパフォーマンスと一致し、ネパール語の場合は英語（0. 5 bleu）とチェコ語の場合よりも優れています。トレーニング時のメモリコストの削減
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CheXbert: Combining Automatic Labelers and Expert Annotations for
  Accurate Radiology Report Labeling Using BERT -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_32.html">
      CheXbert: Combining Automatic Labelers and Expert Annotations for
  Accurate Radiology Report Labeling Using BERT
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最終的なモデルであるCheXbertは、統計的有意性を備えた以前の最高のルールベースのラベラーよりも優れており、胸部X線の最大のデータセットの1つにレポートラベル付け用の新しいSOTAを設定できることがわかりました。医療分野の知識に基づく高度な機能エンジニアリングまたは専門家による手動注釈のいずれかに依存しています。放射線医学テキストレポートからラベルを抽出することで、医療画像モデルの大規模なトレーニングが可能になります。 
[ABSTRACT]レポートのラベル付けに対する既存のアプローチは、通常、医療分野の知識または専門家による手動注釈に基づく高度な機能エンジニアリングに依存しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Indirect Identification of Psychosocial Risks from Natural Language -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_33.html">
      Indirect Identification of Psychosocial Risks from Natural Language
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの機能を使用して、正規化された回帰を使用して、親密なパートナーによるうつ病と心理的侵略のスクリーニング測定を予測します。トピックモデルと感情機能によって定量化されたジャーナルテキストエントリは、閉じた形式の質問とほぼ同じパフォーマンスでうつ病予測の可能性を示します。周産期の間に、うつ病や親密なパートナーの暴力を含む心理社会的健康リスクは、親と子供の深刻な健康への悪影響に関連しています。 
[要旨]適切に介入するには、医療従事者はリスクのある人を特定する必要があります。スティグマは、評価を促すために必要な情報を人々が直接開示することを妨げることがよくあります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Conditional Augmentation for Aspect Term Extraction via Masked
  Sequence-to-Sequence Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_34.html">
      Conditional Augmentation for Aspect Term Extraction via Masked
  Sequence-to-Sequence Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、この方法がデータ不足の問題を大幅に軽減することを確認しています。データ拡張は上記の問題に対処するための効果的な手法である可能性がありますが、アスペクトワードとアスペクトラベルを予期せず変更する可能性があるため、制御できません。既存の拡張アプローチとは異なり、制御可能で、より多様な文を生成できます。 
[ABSTRACT]データ拡張は条件付きの生成タスクです。元のオピニオンターゲットとラベルを保持しながら新しい文を生成しました。このメソッドは、アスペクト用語抽出用の現在のいくつかのモデルのパフォーマンスも効果的に向上させます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Crisscrossed Captions: Extended Intramodal and Intermodal Semantic
  Similarity Judgments for MS-COCO -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_35.html">
      Crisscrossed Captions: Extended Intramodal and Intermodal Semantic
  Similarity Judgments for MS-COCO
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは検索評価を損ない、モダリティ間学習がモダリティ内タスクにどのように影響するかについての研究を制限します。モダリティ内学習とモダリティ間学習の両方を強調して、検索と人間のランキングの相関の両方についてベースラインモデルのパフォーマンス結果を提供します。このギャップに対処するには、\ textit {Crisscrossed Captions}（CxC）データセットを作成し、MS-COCOを\ textbf {247,315}のモダリティ内およびモダリティ間ペアの新しいセマンティック類似性判断で拡張します。 
[ABSTRACT]画像は他とペアになっておらず、キャプションは同じ画像を説明する他のものとのみペアになっています。負の関連はなく、正のクロスモーダル関連がありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: WiC-TSV: An Evaluation Benchmark for Target Sense Verification of Words
  in Context -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_36.html">
      WiC-TSV: An Evaluation Benchmark for Target Sense Verification of Words
  in Context
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は、BERTなどの既存の最先端の言語モデルがドメイン内データとドメイン外データの両方で高いパフォーマンスを実現できることを示していますが、それらにはまだ改善の余地があります。 WSDとELのベンチマークは、一般的な感覚のインベントリから独立しているため、さまざまなドメインのさまざまなモデルとシステムの評価に非常に柔軟に対応できます。ハイパーニーとターゲット感覚に関する定義情報）。 
[ABSTRACT]テストデータは、一般、コンピュータサイエンス、カクテル、医療の4つのドメインで利用できます。テストデータは、wic-tsvを含むさまざまなタイプでテストできます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: TACRED Revisited: A Thorough Evaluation of the TACRED Relation
  Extraction Task -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_37.html">
      TACRED Revisited: A Thorough Evaluation of the TACRED Relation
  Extraction Task
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      再ラベル付けされたテストセットでは、大規模なベースラインモデルセットの平均F1スコアが62.1から70.1。に改善されます。これらの質問に答えるために、最初に、トレーニングされたアノテーターを使用して、開発およびテストセットで最も困難な5Kの例を検証します。検証後、困難なインスタンスの誤分類を分析し、それらを言語学的に動機付けられたエラーグループに分類し、3つの最新のREモデルで結果のエラー仮説を検証します。 
[ABSTRACT]テストエラーの50％以上を再ラベル付けする必要があるとtator.weは、関係エラーは8％の絶対f1テストエラーを占めることがわかりました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Do Neural Models Learn Systematicity of Monotonicity Inference in
  Natural Language? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_38.html">
      Do Neural Models Learn Systematicity of Monotonicity Inference in
  Natural Language?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      単調性推論の4つの側面を考慮し、モデルが異なるトレーニング/テスト分割で字句現象と論理現象を体系的に解釈できるかどうかをテストします。ただし、すべての語彙を保持しながらテストセットで構造をわずかに変更すると、モデルのパフォーマンスが大幅に低下します。一連の実験は、3つのニューラルモデルが、文の構文構造がトレーニングセットとテストセットの間で類似している場合に、目に見えない字句現象と論理現象の組み合わせについて体系的に推論することを示しています。 
[要約]一連の実験は、3つのニューラルモデルが体系的に語彙と論理現象の目に見えない組み合わせについて結論を導き出すことを示しています。これは、ニューラルモデルの一般化能力が、構文構造がトレーニングとほぼ同じ場合に限られていることを示していますセットする
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: When does data augmentation help generalization in NLP? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_39.html">
      When does data augmentation help generalization in NLP?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      一連のおもちゃの学習問題を設計して、このようなデータ拡張が役立つ条件を調査します。ニューラルモデルは、一般的な（「強い」）機能を導出するのではなく、表面的な（「弱い」）機能を利用して良いパフォーマンスを達成することがよくあります。最近の研究では、モデルに強力な機能を優先するように勧める手段として、データ拡張を使用すること、つまり、これらの弱い機能が失敗するトレーニング例を生成することを提案しています。 
[ABSTRACT]このようなデータが役立つ条件を調査するために設計された一連のおもちゃの学習問題。多くの場合、一般的なエラー率に到達するための使用回数は、トレーニングデータの量とは無関係であることがわかります。このタイプのターゲットの強力な機能が学習しにくくなると、データ拡張の効果が低下します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: EnsembleGAN: Adversarial Learning for Retrieval-Generation Ensemble
  Model on Short-Text Conversation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_40.html">
      EnsembleGAN: Adversarial Learning for Retrieval-Generation Ensemble
  Model on Short-Text Conversation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      大規模な短いテキストの会話データに関する実験結果は、人間と自動の両方の評価指標の改善によるensembleGANの有効性を示しています。2つのアンサンブルモデルの自然なアイデアにもかかわらず、既存のアンサンブルメソッドは、1つのアプローチの活用にのみ焦点を当てていますもう1つを強化するために、適切なトレーニング戦略で相互に強化できると主張します。グラウンドトゥルースに近い応答を生成し、弁別子から高いランキングスコアを受け取ることを目的として、2つのジェネレーターは、関連性の高い応答を生成する方法を学びます差別的なランカーは敵対的なものからの真の応答を特定するように訓練されているため、両方のジェネレーター対応のメリットを備えています。 
[要約]アンサンブルガンのコンセプトは、オープンドメイン会話シナリオでの検索-生成アンサンブルモデルを強化するように設計されています。2つのジェネレーターは、より関連性の高い応答と競合する観察されていない候補をそれぞれ生成する方法を学習します。識別ランク付けツールは、メトリック、したがって、両方のジェネレーターの対応する機能の特長
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Matter of Framing: The Impact of Linguistic Formalism on Probing
  Results -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_41.html">
      A Matter of Framing: The Impact of Linguistic Formalism on Probing
  Results
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      形式論に応じて、BERTによるセマンティックロールおよびプロトロール情報のエンコーディングに言語学的に意味のある違いが見つかり、層のプローブが同じ言語形式の実装間の微妙な違いを検出できることを示しています。 ？。プロービングに関する最近の一連の研究では、事前トレーニング中にこれらのモデルによって暗黙的に学習された言語知識を調査しています。 
[ABSTRACT]プローブに関する最近の一連の研究では、事前トレーニング中にこれらのモデルによって学習された言語知識を調査します。これには、基礎となるデータに注釈を付けるために使用される形式が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Automated Essay Scoring and Coherence Modeling for Adversarially
  Crafted Input -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_42.html">
      Neural Automated Essay Scoring and Coherence Modeling for Adversarially
  Crafted Input
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちは多くのベースラインに対してアプローチを評価し、AESタスクと敵対的入力にフラグを立てるタスクの両方でその有効性を実験的に示し、ニューラルエッセイスコアリングモデルの有効性を強化するアプローチの開発にさらに貢献しています。自動エッセイスコアリング（AES）への最先端のアプローチは、文法的であるが一貫性のない一連の文の敵対的に作成された入力をキャプチャするのにはあまり適していません。ローカルコヒーレンスのニューラルモデルを開発して、文間の接続機能を効果的に学習できます、ローカルコヒーレンスモデルを最新のAESモデルと統合して共同でトレーニングするためのフレームワークを提案します。 
[ABSTRACT] aesは、最先端のアプローチへの最先端のアプローチです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-04-18">
        <br>2018-04-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: memeBot: Towards Automatic Image Meme Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_43.html">
      memeBot: Towards Automatic Image Meme Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      エンコーダーは、選択されたミームテンプレートと入力文をミーム埋め込みにマップするために使用され、デコーダーは、ミーム埋め込みからミームキャプションをデコードするために使用されます。与えられた入力文に対して、ミームテンプレートを組み合わせることにより、画像ミームが生成されます。画像とテキストキャプション。ミームテンプレート画像は、選択モジュールを使用して人気のある候補のセットから選択され、ミームキャプションはエンコーダーデコーダーモデルによって生成されます。実験は、生成されたミームがどれだけうまく表現できるかをスコアリングするように設計されています。 Twitterの会話からのツイート。 
[ABSTRACT] memeはエンコーダーを使用して作成されました-デコーダーarchitecture.modelは、memeキャプションとミームテンプレートイメージ間の依存関係を学習し、学習した依存関係を使用して新しいミームを生成します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Investigating Transferability in Pretrained Language Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_44.html">
      Investigating Transferability in Pretrained Language Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、BERTは単に個々のレイヤーに適した初期化子を見つけるだけではありません。代わりに、レイヤー間の相互作用が重要であり、微調整の前にBERTのレイヤーを並べ替えると、評価指標に大きな悪影響を与えます。データセットのサイズは層の転送可能性に影響します。データの微調整が少ないほど、BERTの中間層とそれ以降の層が重要になります。 
[ABSTRACT]調査者はプロービングを別の転送可能性の尺度と比較します。これは、部分的に再初期化されたモデルの微調整パフォーマンスの低下です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Preventing Posterior Collapse with Levenshtein Variational Autoencoder -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_45.html">
      Preventing Posterior Collapse with Levenshtein Variational Autoencoder
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      モデル分布からのLDベースのカーネル密度推定器の扱いにくいカルバックライバー分岐の限界の最適化に密接に関連していることを示すことにより、この方法を確率論的な観点から動機付けます。このレベンシュタインVAEでは、最適化が簡単で、事後崩壊を防止する新しい目的を備えた証拠下限（ELBO）。直感的には、オートエンコーダからシーケンスを生成し、モデルを使用して、レーベンシュタイン距離（LD）に従って最適な継続を予測することを推奨します。生成されたシーケンスの各タイムステップでの参照文。 
[ABSTRACT] leintは、学習の結果として学習するための効果的なツールです。自動エンコーダは、自動エンコーダに将来を予測する機会を与えます。これは、学習の問題を制御する方法です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: How do Decisions Emerge across Layers in Neural Models? Interpretation
  with Differentiable Masking -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_46.html">
      How do Decisions Emerge across Layers in Neural Models? Interpretation
  with Differentiable Masking
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      入力トークンを含めるか無視するかの決定は、分析されたモデルの中間の非表示レイヤーに基づく単純な線形モデルで行われます。これにより、属性ヒートマップをプロットするだけでなく、ネットワークレイヤー全体で決定がどのように形成されるかを分析することもできます。結果のプルーニング過度に攻撃的であり、モデルが予測に到達する方法を反映していません。 
[ABSTRACT] diffmaskは、単純なモデルに依存して入力の特定のサブセットをマスクします。ただし、結果のプルーニングは過度に積極的であり、モデルが予測に到達する方法を反映していません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Accurate Word Alignment Induction from Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_47.html">
      Accurate Word Alignment Induction from Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      注意の重みを使用して提案された方法を使用すると、単語の整列の誘導の高速整列よりも大幅に改善されます。以前の研究とは対照的に、注意の重みは、私たちの設定の下でのリーブアウトメジャーよりも優れた単語の整列をキャプチャすることがわかります。 、トランスフォーマーモデルをトレーニングするマルチタスク学習フレームワークを提示し、GIZA ++アライメントをマルチタスクトレーニングに組み込むことで、GIZA ++よりもはるかに優れたアライメントを誘導できることを示します。 
[ABSTRACT]調査は、注意の重みが正確な単語の整列をキャプチャすることを示しています。これは、単語の整列を誘導するために正しいデコードステップとレイヤーを選択した場合にのみ明らかになると言います
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Perturbed Masking: Parameter-free Probing for Analyzing and Interpreting
  BERT -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_48.html">
      Perturbed Masking: Parameter-free Probing for Analyzing and Interpreting
  BERT
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの方法では、プローブタスクから直接監視する必要はありません。また、プローブプロセスに追加のパラメーターを導入する必要もありません。経験的に誘発された依存構造を下流の感情分類タスクにフィードし、その改善が人間が設計した依存スキーマと互換性があるか、それよりも優れていることを確認します。 
[ABSTRACT]シンプルなシンプルなプローブには、事前トレーニング済みの言語モデルを分析するためのツールの導入が含まれます。直接プローブツールなど、より完全にトレーニング済みの言語モデルを調べるためのツールが必要です。この方法は、事前トレーニング済みという事実に基づいていますトレインモデルは言語知識をエンコードします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: MuSe 2020 -- The First International Multimodal Sentiment Analysis in
  Real-life Media Challenge and Workshop -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_49.html">
      MuSe 2020 -- The First International Multimodal Sentiment Analysis in
  Real-life Media Challenge and Workshop
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちは3つの異なるサブチャレンジを提示します。MuSe-Wildは、継続的な感情（覚醒と価数）の予測に焦点を当てています。 MuSe-Topic。参加者はドメイン固有のトピックを3クラス（低、中、高）感情のターゲットとして認識します。 MuSe-Trustでは、信頼性の新しい側面が予測されます。MuSe2020の目的は、さまざまな分野のコミュニティをまとめることです。主に、視聴覚的感情認識コミュニティ（信号ベース）と感情分析コミュニティ（シンボルベース）です。サブチャレンジごとに、参加者の競争力のあるベースラインが設定されます。つまり、テストでは、MuSe-Wildの結合した（価数と覚醒）CCCが2568、MuSe-Topicのスコア（0.34 $ \ cdot $ UAR + 0.66 $ \ cdot $ F1として計算）が76.78％ 10クラスのトピック、3クラスの感情予測では40.64％、MuSe-Trustでは.4359のCCC。 
[ABSTRACT] muse-車はその種の最初の-より包括的なデータベースです。これは、課題に使用されます。同様に、8.museの目的とは、さまざまな分野のコミュニティをまとめることです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Boosting Naturalness of Language in Task-oriented Dialogues via
  Adversarial Training -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_50.html">
      Boosting Naturalness of Language in Task-oriented Dialogues via
  Adversarial Training
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちは敵対的なトレーニングを統合して、より人間のような応答を生成することを提案します。したがって、生成された応答が自然で流暢であることが重要です。たとえば、RNN-LGレストランデータセットでは、モデルAdvNLGが以前の状態よりも優れています。 BLEUで3.6％の最先端の結果。 
[ABSTRACT]敵対的なトレーニングは、自動評価と人間評価の両方で言語生成の品質を効果的に向上させることができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: WT5?! Training Text-to-Text Models to Explain their Predictions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_51.html">
      WT5?! Training Text-to-Text Models to Explain their Predictions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このアプローチにより、説明可能性ベンチマークに関する最新の結果が得られるだけでなく、ラベル付きの説明の限られたセットからの学習が可能になり、データセット間で合理化能力を伝達できるようになります。このホワイトペーパーでは、テキストからRaffelらによって提案されたテキストフレームワーク。再現性と将来の作業を容易にするために、モデルのトレーニングに使用するコードをリリースします。 
[要約]このホワイトペーパーでは、raffelが提案したテキストからテキストへのフレームワークを利用します。（自然なテキスト）予測を生成した後、モデルをトレーニングして説明を出力するだけです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Use of Machine Translation to Obtain Labeled Datasets for
  Resource-Constrained Languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_52.html">
      Use of Machine Translation to Obtain Labeled Datasets for
  Resource-Constrained Languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのシステムを活用して、英語のデータセットを自動的に翻訳できますか？ 2つの大きな英語のNLIデータセットをトルコ語に翻訳し、専門家チームにその品質を検証してもらいました。これらのデータセットが対処するのに役立つ新しい問題の例として、トルコ固有の埋め込みの値と、開発における形態学的解析の重要性を評価します堅牢なトルコNLIモデル。 
[ABSTRACT]これは他の言語の進歩に対する障害です。ただし、言語言語サービスは現在堅牢です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploiting Sentence Order in Document Alignment -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_53.html">
      Exploiting Sentence Order in Document Alignment
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、この方法をParaCrawlからのWebスクラップのSinhala-Englishドキュメントに適用し、現在のParaCrawlドキュメントの配置方法よりもMTのパフォーマンスが1.2 BLEU向上することを確認しました。この作業では、ドキュメントとその翻訳という単純なアイデアを活用します。ほぼ同じ情報がほぼ同じ順序で含まれている必要があります。この方法では、以前に公開されたWMT16ドキュメントアライメント共有タスクの最良の結果と比較して、エラーが61％減少します。 
[ABSTRACT]ドキュメントペア候補の生成と再スコアリングの両方の方法を提案します。当社の方法は、現在のパラクロールドキュメントの位置合わせ方法よりもmtのパフォーマンスを1.2ブルー向上させます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Semi-Supervised Text Simplification with Back-Translation and Asymmetric
  Denoising Autoencoders -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_54.html">
      Semi-Supervised Text Simplification with Back-Translation and Asymmetric
  Denoising Autoencoders
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この問題に取り組むために、個別の複雑さを持つ文に対して非対称のノイズ除去方法を提案します。教師なし機械翻訳（NMT）では、言語モデリング用のノイズ除去オートエンコーダーや反復逆変換による並列データの自動生成など、逆変換アーキテクチャを採用しています。ただし、単純なコーパスと複雑なコーパスのセットを2つの異なる言語として直接処理する場合、2つのタイプの文は非常に似ており、モデルが異なるタイプの文の特徴。 
[ABSTRACT]これらには、言語モデリング用のノイズ除去オートエンコーダと、反復逆変換による並列データの自動生成が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Self-Supervised and Controlled Multi-Document Opinion Summarization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_55.html">
      Self-Supervised and Controlled Multi-Document Opinion Summarization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      グラフベースの最近のニューラル抽象教師なしモデルに対する2つのデータセットのベンチマークは、提案された方法が優れた品質と関連性を持つ要約を生成することを示しています。これは、幻覚を制御する際の制御設定の重要性を示し、入力レビューで要約の高い感情とトピックの整列を達成することを示しています。私たちは、自己監督と制御を使用して、ユーザー生成レビューのコレクションの教師なし抽象的要約の問題に対処します。制御コードを使用して幻覚の問題に対処し、生成をより一貫した関連性のある要約に向けます。最後に、Transformerアーキテクチャを拡張して、複数のレビューを入力として使用できるようにします。 
[ABSTRACT]一連の類似トピックのターゲットリストとして個々のドキュメントを表示する自己主導型の調査を提案します。自己抗議システムは、入力として複数のレビューを許可します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Control, Generate, Augment: A Scalable Framework for Multi-Attribute
  Text Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_56.html">
      Control, Generate, Augment: A Scalable Framework for Multi-Attribute
  Text Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      テキストを制御、生成、および拡張するためのVariational AutoencoderアーキテクチャであるCGAを紹介します。私たちの作業の主なアプリケーションとして、データ拡張のユースケースでこの新しいモデルの可能性をテストします。さらに、一連の自動および人間の評価による、生成された文の高品質、多様性、および属性制御。 
[ABSTRACT]複数のオートエンコーダアーキテクチャであるcgaは、テキストを制御、生成、および拡張するように設計されています。このアプローチのスケーラビリティは、属性の数に関係なく、単一の識別子によって確立されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Modelling Suspense in Short Stories as Uncertainty Reduction over Neural
  Representation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_57.html">
      Modelling Suspense in Short Stories as Uncertainty Reduction over Neural
  Representation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、不確実性の低減を使用して、映画のあらすじのサスペンスイベントを予測できることも示します。サスペンスをモデル化する2つの方法を比較します。不確実性の低減、ストーリーの継続がどれほど予期せぬものであるかを予測する前向きな尺度。 
[ABSTRACT]ストーリーに対する不確実性の低減が最良の予測因子であり、人間に近い精度が得られることがわかりました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Recipes for building an open-domain chatbot -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_58.html">
      Recipes for building an open-domain chatbot
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちはこれらのレシピのバリエーションを90M、2.7B、および9.4Bパラメータモデルで構築し、モデルとコードを公開しています。人間の評価は、魅力と人間性の測定に関して、マルチターンダイアログの既存のアプローチよりも優れたモデルが優れていることを示しています。 ..適切なトレーニングデータと生成戦略の選択が与えられると、大規模モデルがこれらのスキルを学習できることを示します。 
[ABSTRACT]人間の評価によると、私たちの最高のモデルは、マルチターンの対話における既存のアプローチよりも優れている
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: PhoBERT: Pre-trained language models for Vietnamese -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_59.html">
      PhoBERT: Pre-trained language models for Vietnamese
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ベトナムのNLPの将来の研究とダウンストリームアプリケーションを容易にするためにPhoBERTをリリースします。実験結果は、PhoBERTが常に最新の最高の多言語モデルXLM-R（Conneau et al。、2020）よりも優れており、最新の技術を改善していることを示しています。品詞タグ付け、依存解析、名前付きエンティティ認識、自然言語推論など、ベトナム固有の複数のNLPタスク。PhoBERTモデルは、次の場所で入手できます。最近の最高の多言語モデルxlmを上回る-r.itは、複数のベトナム語-特定のnlpタスクで最新の状態を改善します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-02">
        <br>2020-03-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Robust Question Answering Through Sub-part Alignment -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_60.html">
      Robust Question Answering Through Sub-part Alignment
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SQuAD v1.1でモデルをトレーニングし、いくつかの敵対的でドメイン外のデータセットでテストします。アラインメントを明示的に使用することで、発生する特定のタイプの悪い動作を禁止できる一連の制約を調査できます。クロスドメイン設定..私たちのモデルはBERTを使用してアライメントスコアを計算し、構造化SVMを使用することで、複雑な推論にもかかわらずエンドツーエンドでトレーニングできます。 
[ABSTRACT]質問の回答を位置合わせの問題としてモデル化します。エンドツーエンドでトレーニングし、表面の回答を使用できます。調査結果から、モデルはqaモデルよりも堅牢なクロスドメインであることがわかります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Stay Hungry, Stay Focused: Generating Informative and Specific Questions
  in Information-Seeking Conversations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_61.html">
      Stay Hungry, Stay Focused: Generating Informative and Specific Questions
  in Information-Seeking Conversations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果として得られる実用的な質問者は、基準モデルで生成された質問の有益性と特異性を、メトリックと人間によって評価されるように、大幅に改善することを示しています。実用的な質問を生成するために、強化学習を使用して、提案された有益性メトリックを組み合わせて最適化しますより具体的な質問を促進するように設計された報酬機能を備えています。（1）潜在的な質問の情報量を正式に定義すること、および（2）非常に大きな潜在的な質問のスペースを探索して適切な候補者を見つけること、という2つの主要な課題を特定します。 
[ABSTRACT]質問者に回答の引き出されるコンテキストが与えられないが、新しい情報を取得する方法を説明する必要があるシナリオに関心がある
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Graph-to-Graph Transformer for Transition-based Dependency Parsing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_62.html">
      Graph-to-Graph Transformer for Transition-based Dependency Parsing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      新しいTransformerとGraph2Graph Transformerの両方のパーサーは、英語のペンツリーバンクと11の言語のUniversal Dependencies Treebanksの両方で、遷移ベースの依存関係解析の最先端を大幅に上回っています。Graph2GraphTransformerは、以前の多くの構造化予測と統合できます。メソッドを使用して、幅広いNLPタスクに簡単に適用できます。遷移ベースの依存関係解析の新しいTransformerモデルを提案した後、グラフ入力とグラフ出力の提案されたメカニズムにより、この強力なベースラインを大幅に改善できることを示します。特にBERT事前トレーニングで。 
[ABSTRACT]グラフ入力とグラフ出力のために提案されたメカニズムは、特にバートの事前トレーニングにより、強いベースラインを大幅に改善します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-08">
        <br>2019-11-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Highway Transformer: Self-Gating Enhanced Self-Attentive Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_63.html">
      Highway Transformer: Self-Gating Enhanced Self-Attentive Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      補助的なコンテンツベースのSDUゲートにより、スキップされた接続を介して変調された潜在的な埋め込みの情報フローが可能になり、勾配降下アルゴリズムを使用して収束速度の明確なマージンが得られます。自己注意メカニズムにより、最先端の（SOTA ）さまざまなシーケンス学習タスクの進捗状況、さまざまな場所でのすべてのグローバルコンテキストに注意を払うことでマルチヘッドドット積の注意に立って。コンテキストベースのトランスフォーマーモジュールを支援するゲーティングメカニズムの役割を明らかにするかもしれません。 SDUゲートは、特に浅いレイヤーでは、最適化プロセス中に次善のポイントに向けてステップを高速化する可能性があります。 
[要旨] lstmスタイルのゲーティングユニットを組み込んだゲートコンポーネントセルフディペンデンシーユニット（sdu）は、内部のセマンティックの重要性を補充します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-17">
        <br>2020-04-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Language Model Prior for Low-Resource Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_64.html">
      Language Model Prior for Low-Resource Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この目的は、LMがターゲット言語についてTMを教えていると見なすことができる知識抽出に関連しています。推論中にそれを必要とする以前の作業とは異なり、LMはトレーニング時にのみ使用されるため、提案されたアプローチはデコード速度を低下させません。 ..異なる方法がTMの分布に及ぼす影響の分析を提示します。 
[要約]一般的な解決策は、豊富な単一言語データでトレーニングされた言語モデル（lm）の知識を活用することです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Tired of Topic Models? Clusters of Pretrained Word Embeddings Make for
  Fast and Good Topics too! -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_65.html">
      Tired of Topic Models? Clusters of Pretrained Word Embeddings Make for
  Fast and Good Topics too!
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      重み付けクラスタリングのドキュメント情報を組み込んで、すぐに利用できる事前トレーニング済みの単語の埋め込みに基づく代替アプローチを提案し、上位の単語を再ランク付けします。従来のトピックモデリングに代わるもの。生成的なストーリーを想定する確率モデルは、トピックモデリングの主要なアプローチでした。 
[ABSTRACT]確率モデルはトピックモデリングの主要なアプローチでした。異なる単語の埋め込みとクラスタリングアルゴリズムの組み合わせにベンチマークを提供しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: You are right. I am ALARMED -- But by Climate Change Counter Movement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_66.html">
      You are right. I am ALARMED -- But by Climate Change Counter Movement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      偽のニュースの検出におけるかなりの作業にもかかわらず、気候変動のドメインに固有の利用可能な誤った情報のデータセットはありません。既知の気候変動の誤った情報を持つ記事をこすり、解放することにより、このギャップを埋めようとします。これらの記事は慎重に作成されています気候変動に関するナラティブに影響を与えるための気候変動反対運動（cccm）組織による。 
[ABSTRACT]気候の誤報を広める記事がウェブに殺到しています。社会科学の気候の誤報に関する文献を再検討します。既知の気候変動の誤報のある記事をこすり、解放することで、ギャップを埋めようとしています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Focused Study to Compare Arabic Pre-training Models on Newswire IE
  Tasks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_67.html">
      A Focused Study to Compare Arabic Pre-training Models on Newswire IE
  Tasks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのGigaBERTモデルは、言語ごとおよび/またはゼロ転送のパフォーマンスに関して、NER、POS、およびARLタスクでmBERTおよびXLM-Rベースを上回ることができます。この作業では、Gigawordベースのバイリンガル言語を事前トレーニングしますモデル（GigaBERT）を使用して、これら2つの遠く離れた言語と、情報抽出タスクのゼロショート転送学習を研究します。IEタスクでのパフォーマンス、特に英語からアラビア語へのクロスリンガル転送機能はあまり知られていません。 
[要約]いくつかの多言語の事前トレーニング済みモデルが提案され、アラビア語で優れたパフォーマンスを示しています。ほとんどの実験結果は、自然言語の可能性、質問応答、感情分析などの言語理解タスクについて報告されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Can Your Context-Aware MT System Pass the DiP Benchmark Tests? :
  Evaluation Benchmarks for Discourse Phenomena in Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_68.html">
      Can Your Context-Aware MT System Pass the DiP Benchmark Tests? :
  Evaluation Benchmarks for Discourse Phenomena in Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      驚くべきことに、既存のコンテキスト認識モデルでは、言語や現象全体で談話関連の翻訳が一貫して改善されないことがわかりました。4つの主要な談話現象（照応、語彙、一貫性、一貫性、読みやすさ、談話結合翻訳など。文脈情報を含む機械翻訳（MT）システムのインスタンスが増加しているにもかかわらず、特に談話現象の場合、翻訳品質の改善の証拠はまばらです。 
[ABSTRACT]ブルーなどの人気のある指標は、表現力や感度が十分でないため、品質の向上を捉えることができません。これらのタスクの評価方法を紹介し、いくつかのベースラインシステムを評価
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Hierarchical Encoders for Modeling and Interpreting Screenplays -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_69.html">
      Hierarchical Encoders for Modeling and Interpreting Screenplays
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作品は特に脚本に取り組んでいますが、基礎となるアプローチをさまざまな構造化ドキュメントに一般化する方法について説明します。映画のスクリプトは、このように高度に構造化されたテキストの例です。スクリプトはシーンにセグメント化され、さらにダイアログと説明コンポーネントに分解されます..長い形式のドキュメントの自然言語理解は未解決の課題ですが、そのようなドキュメントには、それらをエンコードするためのモデルの設計に通知できる構造情報が含まれていることがよくあります。 
[ABSTRACT]教師なしの「解釈可能性」モジュールを拡張することにより、洞察の層を追加します。これにより、物語の軌跡の抽出と視覚化が可能になります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ToTTo: A Controlled Table-To-Text Generation Dataset -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_70.html">
      ToTTo: A Controlled Table-To-Text Generation Dataset
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      データセットと注釈プロセスの体系的な分析と、いくつかの最先端のベースラインによって達成された結果を提示します。通常は流暢ですが、既存の方法では、表でサポートされていないフレーズを幻覚化することが多く、このデータセットが役立つことが示唆されています高精度の条件付きテキスト生成のための有用な研究ベンチマークとして。.ToTToを提示します。これは、制御された生成タスクを提案する120,000を超えるトレーニング例を含むオープンドメインの英語の表からテキストへのデータセットです。表のセル。1文の説明を作成します。 
[要旨]アノテーターが既存のウィキペディアの文章を直接修正するデータセット構築プロセスを紹介します。既存の方法では、表でサポートされていないフレーズが幻覚になることがよくあります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Generate, Delete and Rewrite: A Three-Stage Framework for Improving
  Persona Consistency of Dialogue Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_71.html">
      Generate, Delete and Rewrite: A Three-Stage Framework for Improving
  Persona Consistency of Dialogue Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このように、ペルソナベースの対話生成タスクは、明示的なペルソナテキストを対話生成モデルに組み込むことにより、パーソナリティの不整合問題に取り組むために導入されます。人間と自動の両方のメトリックによる評価を実行します。人間のような応答を生成するため、1ステージのデコードフレームワークでは、一貫性のないペルソナワードの生成をほとんど回避できません。 
[要旨]人間ベースの対話生成タスクが導入され、人間-一貫性のない応答に対処します。この作業では、生成された応答プロトタイプから一貫性のない単語をデコードし、さらにパーソナリティ-一貫性に書き換える3段階のフレームワークを紹介します1
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Vision-and-Language Navigation with Image-Text Pairs from the
  Web -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_72.html">
      Improving Vision-and-Language Navigation with Image-Text Pairs from the
  Web
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      比較的データが不足している具体化された知覚タスク（Vision-and-Language Navigation）のパフォーマンスが向上しますか？具体的には、VLN-BERTを開発しました。これは、命令（「茶色のソファーで止まる」）とエージェントがキャプチャした一連のパノラマRGB画像との互換性をスコアリングするための視覚言語変換器ベースのモデルです。「階段」）環境内の視覚的コンテンツ（「階段」に対応するピクセル）。 
[ABSTRACT] eln-bert、Visiolinguistic Transformer-エージェントによってキャプチャされた一連の画像と命令との間の互換性をスコアリングするためのモデル
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Span-based Linearization for Constituent Trees -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_73.html">
      A Span-based Linearization for Constituent Trees
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      PTB（95.8 F1）とCTB（92.4 F1）の実験は、モデルが既存のローカルモデルを大幅に上回り、グローバルモデルとの競争力のある結果を効率的に達成することを示しています。グローバルモデルと比較して、モデルは高速で並列化可能です。以前のローカルモデルとは異なります。 、私たちの線形化方法はスパンに直接結び付けられており、スパン予測を実行するときに、より解釈可能で効果的なより多くのローカル機能を考慮します。 
[要約]私たちのモデルは、スプリットポイントで終わるすべてのスパンでノーマライザを分析します。次に、単一のスパンスパンスパンからツリースパンを予測します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CohEval: Benchmarking Coherence Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_74.html">
      CohEval: Benchmarking Coherence Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、別のユースケースとして、事前トレーニング済みの言語モデル出力のモデル生成ランキングも示します。コヒーレンスモデリングは、新規モデルの開発において長い道のりを歩んできましたが、ダウンストリームアプリケーションでの評価はほとんど無視されてきました。この作業により、コヒーレンスモデリングのさらなる研究を促進するリーダーボードを作成します。 
[要約]標準のコヒーレンス評価の必要性が今まで以上に重要になっています。機械翻訳、要約、次の発話予測のためのコヒーレンス評価
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Forget Me Not: Reducing Catastrophic Forgetting for Domain Adaptation in
  Reading Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_75.html">
      Forget Me Not: Reducing Catastrophic Forgetting for Domain Adaptation in
  Reading Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      新しい補助ペナルティ項を導入し、補助ペナルティ項の組み合わせを使用して、理解モデルを適合させるための微調整プロセスを正則化したときに最高のパフォーマンスを観察します。メソッドをテストするために、可能性のある6つの狭いドメインデータセットを開発してリリースします。読解のベンチマークとして使用できます。近年、大規模なオープンドメインの読解データセットを作成することで、エンドツーエンドの神経理解モデルの開発が可能になり、有望な結果が得られます。 
[要約]このホワイトペーパーでは、ソースドメインからのデータにアクセスせずに学習を克服する方法を探ります。結果をテストするために、読解のベンチマークとして使用できる可能性のある6つの狭いドメインデータセットをリリースするために開発しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-01">
        <br>2019-11-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SegaBERT: Pre-training of Segment-aware BERT for Language Understanding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_76.html">
      SegaBERT: Pre-training of Segment-aware BERT for Language Understanding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これを検証するために、Transformerのトークン位置の埋め込みを段落インデックス、文インデックス、およびトークンインデックスの埋め込みの組み合わせに置き換えることにより、セグメント対応のBERTを提案します。BERTでマスクされた言語モデリングタスクについてSegaBERTを事前トレーニングしましたただし、関連するタスクはありません。事前にトレーニングされた言語モデルは、さまざまな自然言語処理タスクで最先端の結果を達成しています。 
[要約]豊富な位置情報を使用して、テキストエンコーダーからより適切なコンテキスト表現を生成できると仮定します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Character-Level Translation with Self-attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_77.html">
      Character-Level Translation with Self-attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      標準トランスフォーマーモデルと、エンコーダーブロックがコンボリューションを使用して近くのキャラクターからの情報を組み合わせる新しいバリアントをテストします。トランスフォーマーバリアントは、標準トランスフォーマーよりも常に文字レベルで優れており、より堅牢な文字レベルを学習しながらより速く収束します。アラインメント..私たちは、文字レベルのニューラル機械翻訳のための自己注意モデルの適合性を調査します。 
[ABSTRACT]標準のトランスフォーマモデルと、エンコーダブロックが近くのキャラクターからの情報を組み合わせて畳み込みを作成する新しいバリアントをテストします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Dual Supervised Learning for Natural Language Understanding and
  Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_78.html">
      Dual Supervised Learning for Natural Language Understanding and
  Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      予備実験は、提案されたアプローチが両方のタスクのパフォーマンスを向上させることを示しています。しかし、このような二重関係は文献では調査されていません。この論文では、言語を理解し生成するための新しい学習フレームワークを提案します。二元性を利用する方法。 
[ABSTRACT]自然言語理解は、指定された発話から感覚を抽出することです。目標は、指定された意味に基づいて対応する文を構築することです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-15">
        <br>2019-05-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: User-Guided Aspect Classification for Domain-Specific Texts -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_79.html">
      User-Guided Aspect Classification for Domain-Specific Texts
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、事前定義されたアスペクトの分類子をトレーニングし、次にそれを利用してその他のアスペクトの監督を誘導します。アスペクト分類、テキストセグメントのアスペクトの識別は、感情分析やレビュー要約などの多数のアプリケーションを容易にします。新規フレームワーク、ARYA。これは、反復分類子トレーニングとシード更新を介して、事前定義されたアスペクトとその他のアスペクト間の相互強化を可能にします。 
[ABSTRACT]その他の側面は、事前定義された側面のシード単語を提供する少数のユーザーのみに基づいてノイズの多いテキストを分類する際の問題です。システムを使用して、その他の微調整システムを開発できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Few-Shot Natural Language Generation by Rewriting Templates -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_80.html">
      Few-Shot Natural Language Generation by Rewriting Templates
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Googleアシスタント、Alexa、Siriなどの仮想アシスタントを使用すると、ユーザーは自然言語を使用してウェブ上の多数のサービスやAPIと対話できます。一連のシンプルなテンプレートを使用して、アクションを発話に変換します。正しいが、場合によっては一貫性がなく、文法に反する発話。自動メトリックと人間の評価により、サンプルの効率が大幅に向上する一方で、この方法が強力なベースラインを改善することを示しています。 
[要約]応答生成モジュールは、ポリシーモジュールによって生成されたアクションを自然言語発話に変換します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Bridging linguistic typology and multilingual machine translation with
  multi-view language representations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_81.html">
      Bridging linguistic typology and multilingual machine translation with
  multi-view language representations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの方法では、関連するアプローチの主な欠点である大規模な多言語モデルまたはランク付けモデルの高価な再トレーニングなしで、新しい言語を簡単に予測して評価できます。特異ベクトル正準相関分析を使用して両方のビューを融合し、どのような情報であるかを研究することを提案します次に、各ソースから誘導されます。次に、多言語機械翻訳にマルチビュー言語ベクトル空間を利用します。ここで、言語のクラスタリングや多言語転送の候補のランク付けなど、言語の類似性に関する情報を必要とするタスクで競争力のある全体的な翻訳精度を実現します。 
[要約]特異な相関分析を使用して両方のビューを融合することを提案します。また、各ソースからどのような情報が誘導されるかを調査することも提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multiscale Collaborative Deep Models for Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_82.html">
      Multiscale Collaborative Deep Models for Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、当社のディープMSCは、最新のディープNMTモデルを大幅に上回るWMT14英語-ドイツ語タスクで30.56のBLEUスコアを達成します。次に、エンコーダースタック全体を強制して直接目的の表現を学習させる代わりに、各エンコーダーブロックはきめ細かい表現を学習し、コンテキストスケールのコラボレーションを使用して空間依存性をエンコードすることでそれを強化します。3つの変換方向を持つIWSLT変換タスクでは、非常に深いモデル（72レイヤーエンコーダー付き）が強いベースラインを+2.2超えます。 〜+ 3.1 BLEUポイント。 
[要旨]マルチスケールの協調的フレームワークを提示して、以前に使用されたものよりも大幅に深いモデルのトレーニングを容易にします。各モデルブロックにきめの細かい表現を学習させ、空間依存性をキャプチャすることでそれを強化します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Named Entity Recognition without Labelled Data: A Weak Supervision
  Approach -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_83.html">
      Named Entity Recognition without Labelled Data: A Weak Supervision
  Approach
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このアプローチは、幅広いラベル付け機能に依存して、ターゲットドメインからのテキストに自動的に注釈を付けます。名前付きエンティティ認識（NER）のパフォーマンスは、トレーニング中に観察されたテキストとは異なるターゲットドメインに適用されると、しばしば急速に低下します。しかし、弱い監視を通じてラベル付きデータがない場合にNERモデルを学習するための強力なアプローチ。 
[ABSTRACT]ドメイン内のラベル付きデータが利用可能な場合、移管学習手法を使用して既存のnerモデルをターゲットドメインに適応させることができます。このホワイトペーパーでは、弱い監視を通じてラベル付きデータがない場合にnerモデルを学習するためのシンプルで強力なアプローチを紹介します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Explicit Representation of the Translation Space: Automatic Paraphrasing
  for Machine Translation Evaluation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_84.html">
      Explicit Representation of the Translation Space: Automatic Paraphrasing
  for Machine Translation Evaluation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      すべての英語への方向付けに関するWMT19メトリックタスクに関する私たちの実験は、いくぶん驚くべきことに、多様な言い換えを追加しても、人間によって作成されたものであっても、BLEUの人間の判断との相関関係に小さな一貫性のない変化しか生じないことを示しており、BLEUの能力複数の参照を正しく活用するには制限があります。自動言い換えに関するこれまでの研究に続き、最先端の神経言い換え手法を使用してBLEUを改善する可能性を評価し（Papineni et al。、2002）、追加の参照を生成します。人間が作成した参照に対する両方のアプローチを用語で比較します。多様性と、MT品質の人間の判断とBLEUの相関関係の改善。 
[要約]多様な言い換えが有効な翻訳のスペースを適切にカバーできる範囲を調査します。mt出力によって制約される言い換えを生成する別のアプローチと比較します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On the Evaluation of Contextual Embeddings for Zero-Shot Cross-Lingual
  Transfer Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_85.html">
      On the Evaluation of Contextual Embeddings for Zero-Shot Cross-Lingual
  Transfer Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ゼロショットの結果と一緒にoracleスコアを提供することをお勧めします。英語を使用して微調整しますが、ターゲットdevセットでチェックポイントを選択します。英語devの精度は、ターゲット言語の精度と無相関（または反相関）であることが多く、ゼロです。 -ショットのクロスリンガルパフォーマンスは、同じ微調整実行内および異なる微調整実行間で大きく異なります。ただし、ベースラインのmBERTゼロショット精度の公開結果は、4つの論文でMLDoc分類タスクで17ポイントも異なります。 
[ABSTRACT]ベースラインmbertゼロの公開結果の精度は、4つの論文にわたってmldoc分類タスクで17ポイントも異なります。標準の英語の開発精度は、ターゲット言語の精度と相関がない（または反相関している）ことがよくあります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards Unsupervised Language Understanding and Generation by Joint Dual
  Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_86.html">
      Towards Unsupervised Language Understanding and Generation by Joint Dual
  Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、理解と生成の間の二重の特性はめったに検討されていません。以前の研究は、NLUとNLGの間の双対性を利用して、双対教師あり学習フレームワークを介してパフォーマンスを改善した最初の試みです。ベンチマークの実験では、提案されたアプローチがNLUとNLGの両方のパフォーマンスを向上させることができます。 
[要約]理解と生成の間の二重の特性はめったに調査されていません。ただし、以前の研究では、両方のコンポーネントを監視された方法で学習しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Call for More Rigor in Unsupervised Cross-lingual Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_87.html">
      A Call for More Rigor in Unsupervised Cross-lingual Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、教師なしのクロスリンガルモデルのチューニングと評価における一般的な方法論の問題について説明し、ベストプラクティスを提示します。教師なしのクロスリンガル学習の動機、定義、アプローチ、および方法論を確認し、それぞれでより厳密な位置を求めます。最後に、この分野におけるさまざまなタイプの研究（つまり、クロスリンガルの単語の埋め込み、深い多言語の事前トレーニング、および教師なし機械翻訳）の統一された展望を提供し、これらのモデルの同等の評価を主張します。 
[要約]調査は、世界の多くの言語の並行データの欠如に基づいています。ただし、さまざまなタイプの調査について統一された見通しを提供します。これらのモデルの同等の評価を主張します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Modular Representation Underlies Systematic Generalization in Neural
  Natural Language Inference Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_88.html">
      Modular Representation Underlies Systematic Generalization in Neural
  Natural Language Inference Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、本質的な要素はモジュール表現を形成する能力であると主張します。私たちの仕事は、含意と否定について推論する能力についてシステムを評価するために設計された新しい課題自然言語推論データセットに経験的に基づいています。.敵対的（課題）テストでは、モデルで見つかったソリューションへの洞察を得るために、難しい一般化タスクを実行します。 
[ABSTRACT]私たちの中心的な貢献は、表現がモジュラーであることの意味の定義です。成功したbertモデルは驚くほど成功していることがわかります。アクティブな操作は、理由を理解するのに役立ちます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Normalizing Compositional Structures Across Graphbanks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_89.html">
      Normalizing Compositional Structures Across Graphbanks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ここでは、MR間のどの設計上の違いが意味があり、意味的に根付いているか、そして表面的なものであるかという質問をします。構成レベルでのMR間の差異を正規化する方法論を提示し（Lindemann et al。、2019）、言語的に根拠のあるルールを使用して、発散現象の大部分を正規化できます。私たちの作業は、MR間の構成構造の一致を大幅に向上させ、低リソース設定でのマルチタスク学習（MTL）を改善し、注意深いMR設計分析の有用性を示します。比較。 
[ABSTRACT]これらは、さまざまな理論的および設計上の考慮事項を反映する構造上の違いを示します。構成レベルでのmrs間の不一致を正規化する方法を提示します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Reducing Sentiment Bias in Language Models via Counterfactual Evaluation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_90.html">
      Reducing Sentiment Bias in Language Models via Counterfactual Evaluation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ライティングプロンプト）と言語モデルを使用して、生成されたテキストの感情が機密属性の値の変化に影響されるかどうか（およびその方法）を分析します（たとえば、言語モデルアーキテクチャの最近の進歩と大きなテキストコーパスの可用性により、進展が促進されています）テキストの自動生成について。国名、職業、性別）。 
[ABSTRACT]これらの研究は、トレーニングコーパスの可用性と社会的バイアスに基づいています。ただし、存在する社会的バイアスを内部化するためのモデルも促します。感情予測の使用-言語モデルの潜在表現に関する導出正則化
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-08">
        <br>2019-11-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: End-to-End Neural Word Alignment Outperforms GIZA++ -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_91.html">
      End-to-End Neural Word Alignment Outperforms GIZA++
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ワードアラインメントは、統計的機械翻訳（MT）モデルのトレーニングで重要な役割を果たしたため、かつて自然言語処理の中核となる教師なし学習タスクでした。統計的MTメソッドは、優れたパフォーマンスを持つニューラルアプローチに取って代わられましたが、20歳のGIZA ++ツールキットは、最先端の単語アライメントシステムの主要コンポーネントであり続けます。3つのデータセットでGIZA ++よりも一貫して優れた最初のエンドツーエンドのニューラルワードアライメント手法を紹介します。 
[要約]神経単語の整列に関する以前の作業は、トレーニング中にその出力を使用することによってのみギザより優れた性能を発揮できました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: NUBIA: NeUral Based Interchangeability Assessor for Text Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_92.html">
      NUBIA: NeUral Based Interchangeability Assessor for Text Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      コアコンポーネントとして機械学習モデルのみを使用してテキスト生成の自動評価指標を構築する方法論であるNUBIAを紹介します。実装されたモデルはモジュール式であり、説明可能であり、時間の経過とともに継続的に改善されるように設定されています。現在、メトリックより優れたNUBIAの実装を示します機械翻訳、要約、およびWMTセグメントレベルの直接評価タスク、文レベルのランキング、画像キャプションの評価における人間の判断との相関に関する最新のメトリックをわずかに超える/一致するために使用されます。 
[要旨]モデルの実装は人間ベースであり、human.itは、神経特徴抽出器とキャリブレータを含む3つのモジュールに基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: AMPERSAND: Argument Mining for PERSuAsive oNline Discussions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_93.html">
      AMPERSAND: Argument Mining for PERSuAsive oNline Discussions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      議論のマイクロレベル（製品としての議論）とマクロレベル（プロセスとしての議論）のモデルをまとめたオンラインの説得力のあるディスカッションフォーラムでの議論マイニングの計算モデルを提案します。議論は、スピーカーが説得しようとする一種の言説です。関係を予測するための私たちのアプローチは、事前訓練された言語モデルを微調整し、修辞構造理論に基づいて談話関係を活用するという観点からコンテキスト情報を使用します。 
[ABSTRACT]引数マイニングは、モノローグの引数の分析に基づいています。また、他の参加者が対象者のどの部分をターゲットにするかを予測する候補情報システムを提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: PLATO: Pre-trained Dialogue Generation Model with Discrete Latent
  Variable -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_94.html">
      PLATO: Pre-trained Dialogue Generation Model with Discrete Latent
  Variable
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      3つの公開データセットでの包括的な実験により、提案されたフレームワークの有効性と優位性が検証されます。応答生成と潜在行為認識の2つの相互タスクが共有ネットワーク内で同時に設計および実行されます。また、固有の問題に取り組むために離散潜在変数を導入します応答生成における1対多のマッピングの問題。 
[ABSTRACT]コンセプトは、さまざまな種類の会話をサポートするように設計されています。これらには、チャット、知識に基づく対話、会話による質問への回答など
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-17">
        <br>2019-10-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transformer-based Acoustic Modeling for Hybrid Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_95.html">
      Transformer-based Acoustic Modeling for Hybrid Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、トランスフォーマーモデルで限られた適切なコンテキストを使用する予備的な研究を提示します。これにより、ストリーミングアプリケーションが可能になります。また、調査結果は、より大きな内部データセットでも確認されています。 Librispeechに関する最新の結果。 
[ABSTRACT] transformer-based amは、標準のn-グラム言語モデルを使用した場合、最も優れたハイブリッド結果よりも19〜26％優れています。また、調査結果は、より大きな内部データセットでも確認されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-22">
        <br>2019-10-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Endowing Empathetic Dialogue Systems with Personas -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_96.html">
      Endowing Empathetic Dialogue Systems with Personas
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、データセットで最先端のパフォーマンスを取得する、効率的なBERTベースの応答選択モデルであるCoBERTを提案します。具体的には、まず、ペルソナとの共感的な対話のための新しい大規模マルチドメインデータセットを提示します。共感的な対話システムは、多くの分野でユーザーの満足度とタスクの成果を向上させることが示されています。 
[ABSTRACT]ペルソナとの感情的な対話システムは、ペルソナとの共感的な対話システムを与えるための新しいタスクです。これは、ペルソナとペルソナの影響に関する最初の研究です。次に、状態を取得する効率的なベルトベースの応答選択モデルであるcobertを提案しますデータセットの共感パフォーマンスの
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-26">
        <br>2020-04-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: MLSUM: The Multilingual Summarization Corpus -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_97.html">
      MLSUM: The Multilingual Summarization Corpus
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらは、多言語データセットの使用を動機付ける既存のバイアスを強調しています。収集されたデータは、人気のあるCNN / Dailyメールデータセットの英字新聞とともに、大規模な多言語データセットを形成し、テキスト要約コミュニティの新しい研究の方向性を可能にします。 。最先端のシステムに基づくクロスリンガル比較分析を報告します。 
[ABSTRACT]ドキュメントには5つの異なる言語の150万の記事/要約のペアが含まれています。世界で最も多くの記事が含まれています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Addressing Zero-Resource Domains Using Document-Level Context in Neural
  Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_98.html">
      Addressing Zero-Resource Domains Using Document-Level Context in Neural
  Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、複数のドメインを一度にモデリングする場合の大きなコンテキストの有用性を示す実験を紹介します。ドメインレベルの並列データが利用できない場合、ドキュメントレベルのコンテキストを使用してドメインの一般性をキャプチャできることを示します。2つのドキュメントレベルのトランスフォーマーを紹介します。大きなコンテキストサイズを使用できるモデル。これらのモデルを強力なTransformerベースラインと比較します。 
[ABSTRACT]大きなコンテキストサイズを使用できる2つのモデルを提示します。これらのモデルを強力なトランスのベースラインと比較します。さらに、大きなコンテキストの有用性を示す実験を提示します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Pretraining on Non-linguistic Structure as a Tool for Analyzing Learning
  Bias in Language Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_99.html">
      Pretraining on Non-linguistic Structure as a Tool for Analyzing Learning
  Bias in Language Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人間の言語間の転送に関するさらなる実験により、テスト言語でのゼロショットパフォーマンスは、語彙の重複を削除した後でも、トレーニング言語との構文の類似性と高い相関があることがわかります。非言語構造化データでLSTMをトレーニングし、そのパフォーマンスをテストしますLSTMが自然言語に使用できる一般化可能なエンコードを誘発するデータの種類を評価するための人間の言語の結果。ニューラルネットワークが言語構造をどのように表すか、また学習者が言語をモデル化する能力を与える種類の構造的バイアスについての洞察を提供します。 
[ABSTRACT]言語モデルが内部表現を活用して、言語や記号システム間で知識を伝達する方法をテストします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The role of context in neural pitch accent detection in English -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_100.html">
      The role of context in neural pitch accent detection in English
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの革新により、ボストン大学ラジオニュースコーパスでのアメリカ英語のスピーチのピッチアクセント検出の精度が87.5％から88.7％に向上することがわかりました。これは、最先端の結果です。すべてのコンテンツワードのピッチアクセントを予測するだけで82.2％の精度が得られます。これがこのタスクの適切なベースラインであることをお勧めします。最後に、ピッチがこのタスクとこのコーパスの最も重要な音響機能であることを示すアブレーションテストを実施します。 
[要約]音声の韻律的イベントを検出する方法が必要です。これらの革新により、87.5％から88％の改善が見られます。7％。アブレーションテストを実施し、ピッチがこのタスクとこれの最も重要な音響機能であることを示していますコーパス
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Lexical Semantic Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_101.html">
      Lexical Semantic Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      セグメンテーションと（セグメント）ラベル付けは、通常、字句セマンティクスで別々に処理され、相互依存が密接であり、ジョイントアノテーションが必要であるために問題が発生します。STREUSLEコーパスのバージョン4.3で利用可能なすべてのアノテーション軸に沿って神経CRFモデルを評価します：字句ユニットセグメント化（マルチワード式）、単語レベルの構文タグ、名詞、動詞、前置詞/所有単位のスーパーセンスクラス。ベースラインモデルと評価指標を確立することにより、語彙セマンティクスの包括的で正確なモデリングの道を開きます。 
[ABSTRACT]マルチワード表現とスーパーセンス曖昧性解消の字句意味認識タスクを調査します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-Domain Spoken Language Understanding Using Domain- and Task-Aware
  Parameterization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_102.html">
      Multi-Domain Spoken Language Understanding Using Domain- and Task-Aware
  Parameterization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、データが少ない新しいドメインに適応すると、以前の最良のモデルを12.4 \％上回ることで、その転送可能性を示します。ドメイン固有およびタスク固有のモデルパラメーターを使用して、このメソッドのパラメーター化を改善することを提案します。知識の学習と伝達..既存のアプローチの1つは、複数のドメインにまたがる共同トレーニングの共有パラメータを使用して、マルチドメイン学習を行うことで問題を解決します。 
[ABSTRACT]各ドメインのデータに注釈を付けると、経済的にコストがかかり、拡張性が低下します。すべてのドメインの情報を十分に活用する必要があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Progressive Transformers for End-to-End Sign Language Production -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_103.html">
      Progressive Transformers for End-to-End Sign Language Production
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、ドリフトの問題を克服し、SLPモデルのパフォーマンスを向上させるために、いくつかのデータ拡張プロセスを提供します。2つのモデル構成、テキストから直接符号を生成するエンドツーエンドネットワークと、光沢中間を利用するスタックネットワークを提示します。 ..私たちの変圧器ネットワークアーキテクチャは、トレーニングと推論で連続シーケンス生成を可能にするカウンターを導入します。 
[要約]このペーパーでは、プログレッシブトランスフォーマーを提案します。これは、堅い話し言葉の文章から連続的な3Dスケルトン手話に翻訳できる新しいアーキテクチャです。slpの逆翻訳評価メカニズムを提案し、チャレンジのベースラインを設定する必要があるというベンチマークの定量的結果を提示します。今後の研究
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-Task Learning for Coherence Modeling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_104.html">
      Multi-Task Learning for Coherence Modeling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちは、フレームワークがさまざまなドメインと予測タスクに一般化する程度を評価し、標準のバイナリ評価コヒーレンスタスクだけでなく、さまざまな程度のコヒーレンスの予測を含む実際のタスクにもその有効性を示し、新しい状態を達成します技術を活用し、単語レベルの文法上の役割（最下層）とともに、ドキュメントレベルの一貫性スコア（ネットワークの最上層）を予測することを学習する、マルチタスク方式でトレーニングされた階層型ニューラルネットワークを提案します。 2つのタスク間の帰納的転送の。.要約や言語評価など、多くのNLPタスクに不可欠なテキスト品質の側面である談話の一貫性を評価するタスクに対処します。 
[要約]システムは、文書レベルの一貫性スコア（ネットワークの最上位レイヤー）を単語レベルの文法上の役割とともに予測できます。また、帰納的転送の影響を予測するためにも使用できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-04">
        <br>2019-07-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Enriched Pre-trained Transformers for Joint Slot Filling and Intent
  Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_105.html">
      Enriched Pre-trained Transformers for Joint Slot Filling and Intent
  Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ここでは、そのようなモデル、つまりBERTを活用し、その上に新しいアーキテクチャを設計します。最近、事前トレーニング済みの言語モデル、つまりELMoやBERTなどのコンテキスト化モデルの進歩により、トレーニングの可能性を活用することで分野に革命を起こしましたタスク固有のデータセットで微調整を数ステップ行うだけの非常に大きなモデル。標準データセットの実験結果は、私たちのモデルが現在の非BERTの最先端技術といくつかのより強力なBERTベースのベースラインの両方を上回ることを示しています。 
[ABSTRACT]事前トレーニング済みの言語モデルの進歩により、フィールドに革命が起こりました。インテントプーリングアテンションメカニズムを提案し、スロット充填タスクを強化します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Consistent Dialogue Generation with Self-supervised Feature Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_106.html">
      Consistent Dialogue Generation with Self-supervised Feature Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      評価結果は、有意義なトピックとペルソナの機能をキャプチャするモデルの機能を示しています。学習した機能を組み込むことで、2つのデータセットで生成された応答の品質に関して、明示的なペルソナ情報であるモデルと比較しても、大幅な改善がもたらされます。バイナリ機能表現を採用し、制御可能な応答生成手法と組み合わせて、特定の学習したトピックやペルソナ機能を昇格または降格できる機能のもつれを解消する損失を導入します。ユーザーIDなどの外部の監督を必要とする過去の作業とは異なり、多くの場合利用できません。機密情報として分類される、または私たちのアプローチは、対話データの自然な構造を利用することにより、自主的な方法でトピックとペルソナの特徴抽出をトレーニングします。 
[ABSTRACT]論文では、会話全体でトピックとペルソナに関連する特定の機能を維持することにより、一貫した応答を生成する神経会話モデルを提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-03-13">
        <br>2019-03-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Filtering before Iteratively Referring for Knowledge-Grounded Response
  Selection in Retrieval-Based Chatbots -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_107.html">
      Filtering before Iteratively Referring for Knowledge-Grounded Response
  Selection in Retrieval-Based Chatbots
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      その後、コンテキストと応答の間、および知識と応答の間で繰り返し参照が行われ、詳細で幅広いマッチング情報が収集されます。実験結果は、FIREモデルが以前の方法よりもマージンが大きいことを示しています。 PERSONA-CHATデータセットの元のペルソナでは2.8％、改訂されたペルソナでは4.1％、CMU_DoGデータセットではトップ1の精度で3.1％。最初に、コンテキストで構成されるプレフィルターを提案します。フィルターと知識フィルター。 
[ABSTRACT]新しい方法は、繰り返し参照する前にフィルタリング（fire）と呼ばれます。これは、最初に参照する前にフィルタリングという名前のシステムに基づいています。このシステムは事前に知識に基づいて会話を行い、会話に従って知識を理解します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Word Rotator's Distance: Decomposing Vectors Gives Better
  Representations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_108.html">
      Word Rotator's Distance: Decomposing Vectors Gives Better
  Representations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      アラインメントベースの方法が劣っている理由は、それらが単語の重要性と単語の意味を区別しないという事実に起因すると仮定します。経験的に、提案された方法は、単語移動子の距離を含む単語ごとの整列を考慮して現在の方法よりも優れています大きな違いがあります。さらに、このメソッドは、最も競争力のあるデータセットであるSTS-benchmarkで最先端の付加的な文章エンコーダよりも優れています。方向ベクトルは単位超球上の回転によって整列されるため、メソッドワードをローテーターの距離（WRD）と呼びます。 
[ABSTRACT]単語の重要性と単語の意味を分離することを提案します。これには、単語をその基準と方向に分解することが含まれます。これには、土工業者の距離の助けが含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On the Cross-lingual Transferability of Monolingual Representations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_109.html">
      On the Cross-lingual Transferability of Monolingual Representations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このアプローチは、共有された語彙や共同トレーニングに依存しません。私たちの結果は、多言語モデルの一般化能力の基礎に関する一般的な信念と矛盾し、深い単一言語モデルが言語間で一般化するいくつかの抽象化を学習することを示唆しています。この仮説は、単一言語モデルを語彙レベルで新しい言語に転送する代替アプローチ。 
[要旨]まず、トランスフォーマーベースのマスク言語モデルを1つの言語でトレーニングし、同じマスク言語モデリングの目的で新しい埋め込み行列を学習することで、新しい言語にそれを転送します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: PlotMachines: Outline-Conditioned Generation with Dynamic Plot State
  Tracking -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_110.html">
      PlotMachines: Outline-Conditioned Generation with Dynamic Plot State
  Tracking
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、モデルが物語のさまざまな部分に対応するさまざまな書き方を学習できるように、PlotMachinesを高レベルの談話構造で充実させます。アウトライン条件付きのストーリー生成のタスクを提案します。ストーリーに表示される主要なキャラクターとイベントを説明するタスクは、提供されたアウトラインと一致する一貫したナラティブを生成することです。これには、モデルが潜在的なプロットの動的状態を追跡し、入力アウトラインを調整する必要がありますストーリー全体を生成しながら。 
[ABSTRACT]動的なプロット状態を追跡することにより、アウトラインを一貫したストーリーに変換することを学習するシステムを提示します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Natural Language Premise Selection: Finding Supporting Statements for
  Mathematical Text -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_111.html">
      Natural Language Premise Selection: Finding Supporting Statements for
  Mathematical Text
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さまざまなベースラインを使用して、タスクに関連する根本的な解釈の課題を示します。この作業では、非公式な数学の生成に役立つサポート定義とサポート命題を取得するために使用される新しいNLPタスク、自然前提選択を提案します。特定のステートメントの証明..データセットNL-PSも利用できます。NL-PSは、自然前提選択タスクのさまざまなアプローチを評価するために使用できます。 
[要旨]データセットnl-psも利用可能にします。これは、自然前提選択タスクtask taskのさまざまなアプローチを評価するために使用できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Knowledge Graph Embeddings and Explainable AI -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_112.html">
      Knowledge Graph Embeddings and Explainable AI
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ナレッジグラフの埋め込みは、エンティティと関係がベクトル空間に埋め込まれている知識表現への広く採用されているアプローチです。ここでは、知識を表すために導入されたアプローチを説明することにより、この分野の最先端技術を要約します。ベクトル空間..この章では、ナレッジグラフの埋め込みの概念を説明し、それらの生成方法と評価方法を説明します。 
[要約]この章では、ナレッジグラフの埋め込みの概念について説明します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Knowledge Graph Empowered Entity Description Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/cs.CL/paper_113.html">
      Knowledge Graph Empowered Entity Description Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、豊富なグラフ情報のアンサンブルを学習する集計方法も組み込んでいます。このデータセットには、さまざまなタイプの主要エンティティの豊富な知識を取得するための大規模なナレッジグラフ（KG）の探索が含まれているため、現在のグラフからシーケンスへのモデルは深刻な影響を受けます説明テキストの生成中の情報損失とパラメータ爆発の問題から。広範囲な実験により、モデルアーキテクチャの有効性が実証されています。 
[ABSTRACT] wikibio、webnlg、およびe2eなどの既存のデータセットは、基本的に入力トリプル/ペアセットとその出力テキストの間に適切な調整があります。これらの課題には、元のグラフ情報をより包括的に表すことができるマルチグラフ構造の作成が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: CopyCat: Many-to-Many Fine-Grained Prosody Transfer for Neural
  Text-to-Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/eess.AS/paper_0.html">
      CopyCat: Many-to-Many Fine-Grained Prosody Transfer for Neural
  Text-to-Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、並列データを使用せずに、ソーススピーカーの漏れに対してロバストな、新規の多対多のPTシステムであるCopyCatを提案します。この問題を軽減するために、PT。の品質に妥協します。これは、ソーススピーカーの漏れに対してロバストな時間的韻律表現をキャプチャできる新しいリファレンスエンコーダアーキテクチャを介して行われます。 
[ABSTRACT]新しいテクニックは、ソーススピーカーの声から、リズム、強調、メロディー、持続時間、ラウドネスなどの韻律の側面をキャプチャすることを目的としています。目的は、韻律の品質を維持し、それらを韻律の異なるターゲットスピーカーに転送することですボイス
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: MuSe 2020 -- The First International Multimodal Sentiment Analysis in
  Real-life Media Challenge and Workshop -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/eess.AS/paper_1.html">
      MuSe 2020 -- The First International Multimodal Sentiment Analysis in
  Real-life Media Challenge and Workshop
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちは3つの異なるサブチャレンジを提示します。MuSe-Wildは、継続的な感情（覚醒と価数）の予測に焦点を当てています。 MuSe-Topic。参加者はドメイン固有のトピックを3クラス（低、中、高）感情のターゲットとして認識します。信頼性の新しい側面が予測されるMuSe-Trust。各サブチャレンジに対して、参加者の競争力のあるベースラインが設定されます。つまり、テストでは、MuSe-Wildの結合された（価数と覚醒）CCCが2568、MuSe-Topicのスコア（0.34 $ \ cdot $ UAR + 0.66 $ \ cdot $ F1として計算）が76.78％ 10クラスのトピック、3クラスの感情予測で40.64％、MuSe-Trustの場合、CCCは4359。主に、視聴覚感情認識コミュニティ（シグナルベース）、および感情分析コミュニティ（シンボルベース）。 
[ABSTRACT] muse-車はその種の最初の-より包括的なデータベースです。これは、課題に使用されます。同様に、8.museの目的とは、さまざまな分野のコミュニティをまとめることです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A convolutional neural-network model of human cochlear mechanics and
  filter tuning for real-time applications -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/eess.AS/paper_2.html">
      A convolutional neural-network model of human cochlear mechanics and
  filter tuning for real-time applications
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      取り込みを可能にするために、畳み込みニューラルネットワークを計算神経科学と組み合わせて、人間の蝸牛力学とレベル依存の蝸牛フィルター調整（CoNNear）のリアルタイムのエンドツーエンドモデルを生成するハイブリッドアプローチを示します。CoNNearモデルは音響音声資料で訓練されましたが、その性能と適用性は、蝸牛力学研究で一般的な（目に見えない）音響刺激を使用して評価されました。聴覚モデルは、自動音声認識システムの特徴抽出器として、またはロボット工学、機械聴覚のフロントエンドとして一般的に使用されますおよび補聴器のアプリケーション。 
[ABSTRACT] connearモデルは音響音声資料でトレーニングされましたが、そのパフォーマンスと適用性は（目に見えない）音刺激を使用して評価されました。このモデルには、リアルタイムの聴覚アプリケーションを人間のパフォーマンスに活用し、次世代の音声認識を刺激する力があります、ロボット工学、補聴器システム
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Spiking neural networks trained with backpropagation for low power
  neuromorphic implementation of voice activity detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/eess.AS/paper_3.html">
      Spiking neural networks trained with backpropagation for low power
  neuromorphic implementation of voice activity detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この問題を克服するために、RNNのようなモデルに再キャストでき、既知のディープラーニングテクニックでトレーニングできるSNNモデルを利用します。スパイク..スパイクの少ないアクティビティとプルーニングアルゴリズムを実現し、ネットワーク接続の85％をパフォーマンスの低下なしに削除するSNNトレーニング手順について説明します。 
[ABSTRACT]これは、スパイクニューラルネットワーク（snns）を可能にするニューロモーフィックハードウェアによって実現できます。スパイク情報は、非常に低いエネルギー消費でカスケードを実行できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-22">
        <br>2019-10-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transformer-based Acoustic Modeling for Hybrid Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/eess.AS/paper_4.html">
      Transformer-based Acoustic Modeling for Hybrid Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      リスコアリングのためにニューラルネットワークLMと組み合わせると、提案されたアプローチはLibrispeechで最先端の結果を達成します。また、トランスフォーマーモデルで制限された正しいコンテキストを使用する予備的な研究を提示します。これにより、ストリーミングアプリケーションが可能になります。広く使用されているLibrispeechベンチマークで、標準のN-gram言語モデル（LM）を使用した場合、トランスフォーマーベースのAMは、最も優れたハイブリッド結果よりも19〜26％優れています。 
[ABSTRACT] transformer-based amは、標準のn-グラム言語モデルを使用した場合、最も優れたハイブリッド結果よりも19〜26％優れています。また、調査結果は、より大きな内部データセットでも確認されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-22">
        <br>2019-10-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The role of context in neural pitch accent detection in English -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/eess.AS/paper_5.html">
      The role of context in neural pitch accent detection in English
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのモデルは、完全な発話を入力として使用し、LSTMレイヤーを追加することで、コンテキストをより有効に活用します。この情報を下流のタスクで利用できるようにするには、音声の韻律的イベントを検出する方法が必要です。これらの革新により、ボストン大学ラジオニュースコーパスでのアメリカ英語のスピーチのピッチアクセント検出の精度が87.5％から88.7％に改善されました。これは最新の結果です。 
[要約]音声の韻律的イベントを検出する方法が必要です。これらの革新により、87.5％から88％の改善が見られます。7％。アブレーションテストを実施し、ピッチがこのタスクとこれの最も重要な音響機能であることを示していますコーパス
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Novel diets as nutraceuticals to alter lifespan and healthspan trajectories in C. elegans -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/biorxiv.physiology/paper_0.html">
      Novel diets as nutraceuticals to alter lifespan and healthspan trajectories in C. elegans
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験室で使用する細菌の食事オプションの拡大は、健康のための遺伝子と食事の相互作用の複雑さをよりよく理解するための重要なツールを提供します。研究室でC. elegansを培養するために利用できるメニューを多様化するために、そしてメチロバクテリウム、キサントモナス、スフィンゴモナスなどの3つの微生物を培養しました。ダイエットは、生物が自然の生息地でさらされているさまざまなオプションのために、人生においてより変化しやすい側面の1つです。 
[ABSTRACT]ダイエット-汚染物質の存在を含め、動物のセクシュアリティに強力な影響を与える可能性があります。これらのダイエットの食事は独特であり、cに給餌すると細菌の食事オプションの拡大は、遺伝子の複雑さを理解するための重要なツールを提供します-健康のための食事の相互作用
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Proteomic and functional mapping of cardiac NaV1.5 channel phosphorylation reveals multisite regulation of surface expression and gating -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-01/biorxiv.physiology/paper_1.html">
      Proteomic and functional mapping of cardiac NaV1.5 channel phosphorylation reveals multisite regulation of surface expression and gating
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      リン酸化セリン664と-667は、チャネル活性化の電圧依存性を累積的に調節しますが、障害のある心臓で増加する近くのセリン671のリン酸化は、細胞表面NaV1.5発現とピークNa +電流を減少させます。ほとんどのサイトがクラスター化され、これらのクラスターの3つは高度にリン酸化されています。ホスホサイレントおよびホスホミメティックNaV1.5変異体の分析により、NaV1.5チャネルの発現とゲーティングの調節における3つのホスホサイトの役割が明らかになりました。 
[ABSTRACT] nav1。失敗しないマウスと失敗したマウスの左心室から精製された5チャネル複合体.nav1.5は、42のリン酸化部位であることが判明しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
