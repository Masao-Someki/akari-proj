<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-10-22の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: FastEmit: Low-latency Streaming ASR with Sequence-level Emission
  Regularization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_0.html">
      <font color="black">FastEmit: Low-latency Streaming ASR with Sequence-level Emission
  Regularization</font>
    </a>
  </h2>
  <font color="black">ストリーミング自動音声認識（ASR）は、仮定された各単語を可能な限り迅速かつ正確に発することを目的としています。音声検索テストセットの以前の手法よりも大幅に高い精度で150〜300ミリ秒の遅延を削減します。この作業では、提案します。 FastEmitという名前のシーケンスレベルの放出正規化方法。これは、トレーニングトランスデューサモデルのシーケンスごとの確率に直接レイテンシ正規化を適用し、調整を必要としません。 
[ABSTRACT] fastemitは、librispeechで90パーセンタイルのレイテンシーを30ミリ秒に短縮します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Emformer: Efficient Memory Transformer Based Acoustic Model For Low
  Latency Streaming Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_1.html">
      <font color="black">Emformer: Efficient Memory Transformer Based Acoustic Model For Low
  Latency Streaming Speech Recognition</font>
    </a>
  </h2>
  <font color="black">ベンチマークLibriSpeechデータで実験を実行します。Emformerはトレーニングで並列化されたブロック処理を適用して低遅延モデルをサポートします。この論文では、低遅延ストリーミング音声認識のための効率的なメモリトランスフォーマーEmformerを提案します。 
[概要]平均レイテンシが80ミリ秒の低レイテンシシナリオの場合、emformerは$ 2. 50-クリーン、テストで$ 5. 62 /％$-その他。同じレイテンシシナリオで、emformerはwer $ 3.01を達成します。 7.999ドルとテストで$-その他</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Trends at NIME -- Reflections on Editing "A NIME Reader" -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_2.html">
      <font color="black">Trends at NIME -- Reflections on Editing "A NIME Reader"</font>
    </a>
  </h2>
  <font color="black">アンソロジーには批判的言説も含まれており、NIMEコミュニティの長所と短所を認めることで、この分野をさらに多様化および強化できる活動を提案します。選考プロセスを紹介し、私たちが観察したいくつかの傾向を振り返ります。会議の15年の長い歴史の中で発表された1200以上のNIME論文のコレクションを再発見することで..この論文で提示するように、目的は、芸術的、科学的、技術的アプローチの広い範囲を表すことでした。 NIME会議の特徴。 
[要約] 1200以上のニメ論文のコレクションは、会議の15年の長い歴史を通して公開されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: BERT for Joint Multichannel Speech Dereverberation with Spatial-aware
  Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_3.html">
      <font color="black">BERT for Joint Multichannel Speech Dereverberation with Spatial-aware
  Tasks</font>
    </a>
  </h2>
  <font color="black">事前トレーニングからの明示的な表現を教師ありの方法で利用する代わりに、トランスフォーマーでエンコードされた隠れた表現を教師ありの方法で利用します。提案された方法は、トランスフォーマーからの双方向エンコーダー表現（BERT）の優れたシーケンスモデリング機能に触発されています。マルチチャネルスペクトルの大きさとスペクトル位相情報の両方がエンコードされます。 
[ABSTRACT]提案された方法は、シーケンスからシーケンスへのマッピング問題としてタスクに対処します。これは、さまざまなフロントエンド音声処理タスクに十分一般的です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Sentence Boundary Augmentation For Neural Machine Translation Robustness -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_4.html">
      <font color="black">Sentence Boundary Augmentation For Neural Machine Translation Robustness</font>
    </a>
  </h2>
  <font color="black">具体的には、入力トランスクリプトが自動音声認識（ASR）から取得される長い形式の音声翻訳システムのコンテキストでは、NMTモデルは、音声置換、文法構造、文の境界などのエラーを処理する必要があります。 NMTの堅牢性..詳細なエラー分析を通じて、文の境界セグメンテーションが品質に最大の影響を与えることを示し、セグメンテーションの堅牢性を向上させるための単純なデータ拡張戦略を開発します。ニューラル機械翻訳（NMT）モデルは整形式のトレーニングおよび評価データが提供される翻訳タスクでのアートパフォーマンスですが、さまざまなタイプのエラーを含む入力に敏感なままです。 
[概要]理解システムと連携できる必要があります。音素置換、文法構造、文の境界などのエラーを処理する必要があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Addressing the Recitative Problem in Real-time Opera Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_5.html">
      <font color="black">Addressing the Recitative Problem in Real-time Opera Tracking</font>
    </a>
  </h2>
  <font color="black">この論文では、2つの特殊なトラッカーを並行して使用することを提案することにより、この特定の問題に対処します。1つは音楽に焦点を当て、もう1つは音声に敏感な機能に焦点を当てます。まず、音声関連の機能について体系的な調査を行い、同じオペラのさまざまなパフォーマンスからの対応するレチタティーヴォのアラインメント。次に、事前にトレーニングされた音楽と音声分類器に基づいて、2つのトラッカーを組み合わせて、オペラ全体のグローバルな精度を向上させるさまざまなソリューションを提案します。 
[概要]現在のオーディオからオーディオへの位置合わせアルゴリズムは、比較的堅牢な方法で、オペラ全体を最初から最後まで追跡するように作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Knowledge Distillation for Improved Accuracy in Spoken Question
  Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_6.html">
      <font color="black">Knowledge Distillation for Improved Accuracy in Spoken Question
  Answering</font>
    </a>
  </h2>
  <font color="black">実験は、私たちのアプローチがSpoken-SQuADデータセットのいくつかの最先端の言語モデルよりも優れていることを示しています。具体的には、音声ドキュメントと書面の対応物から知識蒸留（KD）を実行するトレーニング戦略を考案します。自動音声認識（ ASR）は、QAシステムの開発において重要な役割を果たします。 
[ABSTRACT]自動音声認識（asr）は、qaシステムの開発において重要な役割を果たします。このシステムは、問題の理解を理解するために使用され、新しい蒸留フレームワークを提示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Prediction of Object Geometry from Acoustic Scattering Using
  Convolutional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_7.html">
      <font color="black">Prediction of Object Geometry from Acoustic Scattering Using
  Convolutional Neural Networks</font>
    </a>
  </h2>
  <font color="black">現在の作業では、モデルから作成された予測がグラウンドトゥルースと高精度で一致することがわかりました。さらに、使用するデータチャネルが少なくても解像度が低くても精度は低下しません。データ劣化に対するアプローチの堅牢性が評価されます。さまざまなレベルのデータ劣化を伴うデータセットを使用してトレーニングされたネットワークのパフォーマンスを比較することによって。 
[概要]本研究では、散乱特徴からオブジェクトの彫刻を推測する方法を提案します。シミュレーションの完全なセットをサンプリングして、複数のデータセットを生成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: WaveTransformer: A Novel Architecture for Audio Captioning Based on
  Learning Temporal and Time-Frequency Information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_8.html">
      <font color="black">WaveTransformer: A Novel Architecture for Audio Captioning Based on
  Learning Temporal and Time-Frequency Information</font>
    </a>
  </h2>
  <font color="black">その内容のキャプション）.. Clothoデータセットの自由に利用可能な分割を利用して私たちの方法を評価します..私たちの結果は、以前に報告された最高のSPIDErを16.2から17.3に増やします。 
[概要]これは、広く使用されているトランスデコーダーを抽出する作業です。この方法は、ローカルメソッドの使用に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Complex data labeling with deep learning methods: Lessons from fisheries
  acoustics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_9.html">
      <font color="black">Complex data labeling with deep learning methods: Lessons from fisheries
  acoustics</font>
    </a>
  </h2>
  <font color="black">このアプローチのさらなる開発は、漁業音響におけるラベリングプロセスの標準化への道を開き、非自明なデータラベリングプロセスの良い事例研究です。海底から海面への音響後方散乱信号の定量的および定性的分析は魚の資源評価と海洋生態系のモニタリングに世界中で使用されています。大量の生データが収集されますが、面倒な専門家によるラベル付けが必要です。 
[ABSTRACT]データデータデータは分析するのに十分ではありませんが、調査する必要があります。データを収集し、データを分析する必要があります。このプロセスはデータデータ分析に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Contextualized Attention-based Knowledge Transfer for Spoken
  Conversational Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_10.html">
      <font color="black">Contextualized Attention-based Knowledge Transfer for Spoken
  Conversational Question Answering</font>
    </a>
  </h2>
  <font color="black">また、教師モデルの推定確率から生徒にASRロバストな知識を抽出するための従来の知識蒸留フレームワークを紹介します。ただし、ASRシステムは、予期しないノイズの多い信号を文字起こしに導入し、SCQAのパフォーマンスを低下させます。 Spoken-CoQAデータセットで広範な実験を実施し、私たちのアプローチがこのタスクで驚くべきパフォーマンスを達成することを示しています。 
[ABSTRACT] scqaは、従来のテキスト質問応答（qa）タスクとは異なります。音声信号処理、パッセージの理解、コンテキストの理解が含まれます。音声からcoqaのデータセットに対して広範な実験を行います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-task Metric Learning for Text-independent Speaker Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_11.html">
      <font color="black">Multi-task Metric Learning for Text-independent Speaker Verification</font>
    </a>
  </h2>
  <font color="black">結果は、提案された方法の有効性を示しています。提案された方法を評価するために、Speaker in the Wild（SITW）データセットで実験を行います。補助MLタスクでは、ミニバッチのトレーニングサンプルを最初にペアに配置します。 、次に、正と負のペアが選択され、それら自体の相対的な類似性によって重み付けされ、最後に、選択されたペアの類似性によって補助ML損失が計算されます。 
[概要]ディープスピーカー埋め込みネットワークは、多くの変更を加えてトレーニングされています。システムをテストするための方法が提案されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Real-time Speech Frequency Bandwidth Extension -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_12.html">
      <font color="black">Real-time Speech Frequency Bandwidth Extension</font>
    </a>
  </h2>
  <font color="black">低遅延により、双方向音声通信システムで実行可能になります。さらに、ストリーミングモードでデバイスに展開できるSEANetのバリアントを提案し、16ミリ秒のアーキテクチャ遅延を実現します。モデルアーキテクチャはSEANetに基づいています。 （Sound EnhAncement Network）は、波から波への完全な畳み込みモデルであり、特徴損失と敵対的損失の組み合わせを使用して、入力音声の拡張バージョンを再構築します。 
[概要]モデルアーキテクチャは、波から波への完全畳み込みモデルであるシーネットに基づいています。特徴損失と敵対的損失の組み合わせを使用して、入力音声の拡張バージョンを再構築します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Towards End-to-End Training of Automatic Speech Recognition for Nigerian
  Pidgin -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_13.html">
      <font color="black">Towards End-to-End Training of Automatic Speech Recognition for Nigerian
  Pidgin</font>
    </a>
  </h2>
  <font color="black">また、この言語で最初のエンドツーエンドの音声認識システム（QuartzNetおよびJasperモデル）をトレーニングしました。これらは両方ともConnectionist Temporal Classification（CTC）損失を使用して最適化されました。この作業では、最初の並列（speech-to-テキスト）ナイジェリアピジンのデータ..ベースラインの結果により、データセットで貪欲なデコーダーを使用して、0.77％の低い単語エラー率（WER）を達成することができました。 
[概要]この言語は、イギリス、カナダ、アメリカのナイジェリア移民を通じて、ディアスポラのコミュニティに広まりました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Detection of COVID-19 through the analysis of vocal fold oscillations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_14.html">
      <font color="black">Detection of COVID-19 through the analysis of vocal fold oscillations</font>
    </a>
  </h2>
  <font color="black">このために、声帯の振動に動的システムモデルを使用し、最近開発されたADLESアルゴリズムを使用してそれを解決し、録音された音声から直接声帯の振動パターンを生成します。COVID-19陽性の臨床的にキュレートされたデータセットでの実験結果否定的な被験者は、COVID-19と相関する声帯振動の特徴的なパターンを明らかにします。発声、または声帯の振動は、人間による声の音の生成における発声の主な原因です。 
[概要]バイオ-機械的プロセスは、話者の呼吸状態の変化に非常に敏感です。これらの変化は、たとえば音声からのcovid-19にリンクされています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Contrastive Learning of General-Purpose Audio Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_15.html">
      <font color="black">Contrastive Learning of General-Purpose Audio Representations</font>
    </a>
  </h2>
  <font color="black">コンピュータービジョンの対照学習と強化学習の最近の進歩に基づいて、軽量で実装が簡単な音声の自己教師ありモデルを設計します。大規模なオーディオセットデータベースに埋め込みを事前トレーニングし、これらの表現を転送します。音声、音楽、動物の音、音響シーンなど、9つの多様な分類タスクに..私たちのアプローチは、対照学習に基づいています。同じ録音から抽出されたオーディオセグメントに高い類似性を割り当て、からのセグメントに低い類似性を割り当てる表現を学習します。さまざまな録音。 
[概要]大規模なオーディオセットデータベースに埋め込みを事前トレーニングします。これらの表現を9つの多様な分類タスクに転送します。また、主要な設計の選択を特定するためにアブレーション研究を実施します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Disentangled Phone and Speaker Representations in a
  Semi-Supervised VQ-VAE Paradigm -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_16.html">
      <font color="black">Learning Disentangled Phone and Speaker Representations in a
  Semi-Supervised VQ-VAE Paradigm</font>
    </a>
  </h2>
  <font color="black">スピーカーVQコンポーネントを追加すると、音声合成品質の客観的尺度（推定MOS、スピーカー類似性、ASRベースの了解度）が向上し、意味のある学習表現が提供されます。新しいコンポーネントを導入することにより、スピーカーの音声と電話のコンテンツを解きほぐす新しいアプローチを紹介します。音声合成用のVQ-VAEアーキテクチャ..この問題を軽減するために、既存のサブ電話コードブックとは完全に別個のグローバルスピーカー特性を学習するスピーカーエンコーダーとスピーカーVQコードブックを組み込みました。 
[概要]元のvq-vaeは、目に見えない話者にうまく一般化されません。また、2つのトレーニング方法を比較します。自己-話者ラベルで監視</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: The UPC Speaker Verification System Submitted to VoxCeleb Speaker
  Recognition Challenge 2020 (VoxSRC-20) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_17.html">
      <font color="black">The UPC Speaker Verification System Submitted to VoxCeleb Speaker
  Recognition Challenge 2020 (VoxSRC-20)</font>
    </a>
  </h2>
  <font color="black">VoxCeleb-1テスト、VoxSRC-20検証、およびテストセットに関するシステムの結果を提供します。このレポートでは、カタロニア工科大学（UPC）からInterspeech 2020でのVoxCeleb話者認識チャレンジ（VoxSRC-20）への提出について説明します。二重分岐シャムは、トレーニング中にクロスエントロピー損失を使用してバイナリ分類を実行します。 
[要約]最終的な提出は、3つのシステムの組み合わせです。cnnエンコーダーであるvoxへの応答です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Joint Blind Room Acoustic Characterization From Speech And Music Signals
  Using Convolutional Recurrent Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_18.html">
      <font color="black">Joint Blind Room Acoustic Characterization From Speech And Music Signals
  Using Convolutional Recurrent Neural Networks</font>
    </a>
  </h2>
  <font color="black">これらは音声明瞭度と音質に密接に関連しています。ただし、RIRを測定するには、特定の機器と押し付けがましい音を再生する必要があります。最近の音声と機械学習を組み合わせると、音声または音楽信号を使用してこれらのパラメータを盲目的に推定できることがわかります。 
[ABSTRACT]残響時間、明瞭度、および直接対残響比は、残響環境を表すために定義された音響パラメータです。これらは、部屋のインパルス応答（rir）と呼ばれる部屋の測定値から導出できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: VENOMAVE: Clean-Label Poisoning Against Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_19.html">
      <font color="black">VENOMAVE: Clean-Label Poisoning Against Speech Recognition</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、VENOMAVEと呼ばれるオーディオドメインでの最初のデータポイズニング攻撃を紹介します。データセットの平均0.94％のみをポイズニングすると、攻撃の成功率は83.33％になります。画像ドメインでの以前の作業では、いくつかのことが実証されました。データポイズニング攻撃の種類ですが、オーディオドメインには適用できません。 
[概要]最新のasrシステムはニューラルネットワークに基づいています。以前の調査では、これらのシステムは敵対的な例の影響を受けやすいことが示されています。これらのシステムには、誤分類につながる悪意のある音声入力が含まれています。asrシステムに対するデータポイズニング攻撃は実際の脅威であると結論付けています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: The LOCATA Challenge: Acoustic Source Localization and Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.SD/paper_20.html">
      <font color="black">The LOCATA Challenge: Acoustic Source Localization and Tracking</font>
    </a>
  </h2>
  <font color="black">評価は、フィールドでの成果、未解決の課題を強調し、潜在的な将来の方向性を特定します。ソースとマイクプラットフォームが移動する可能性がある動的シナリオでは、信号はソースセンサーの形状の変化によってさらに影響を受けます。 LOCAlization and TrAcking（LOCATA）チャレンジは、音源の位置特定と追跡のための幅広いクラスのアルゴリズムの客観的な評価とベンチマークのためのオープンアクセスフレームワークです。 
[概要]現実的なシナリオでは、オーディオ信号は、残響、ノイズ、干渉、および音声の非アクティブ期間の影響を受けます。実際には、音源の位置特定と追跡へのアプローチは、アクティブな音源の推定値の欠落、推定誤差、および誤った見積もり</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-03">
        <br><font color="black">2019-09-03</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Information Transfer as a Framework for Optimized Phase Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.IV/paper_0.html">
      <font color="black">Information Transfer as a Framework for Optimized Phase Imaging</font>
    </a>
  </h2>
  <font color="black">フィッシャー情報（FI）を使用して、さまざまな位相イメージングスキームの効率を評価し、情報伝達関数（ITF）を計算します。サンプルの十分な事前知識があれば、ゼルニケ位相コントラストの一般化バージョンが効率的であることを示します。事前の知識がなくても、ランダムセンシング測定によって利用可能な情報のかなりの部分が得られることを示しています。 
[概要]線形情報（fi）を使用して、さまざまな位相イメージングスキームの効率を評価し、情報伝達関数を計算します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-19">
        <br><font color="black">2020-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: Land Cover Classification from Remote Sensing Images Based on
  Multi-Scale Fully Convolutional Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.IV/paper_1.html">
      <font color="black">Land Cover Classification from Remote Sensing Images Based on
  Multi-Scale Fully Convolutional Network</font>
    </a>
  </h2>
  <font color="black">この論文では、マルチスケール畳み込みカーネルを備えたマルチスケール完全畳み込みネットワーク（MSFCN）を提案して、2次元（2D）衛星画像からの識別表現を活用します。 
[概要] 2階建ての衛星画像からの識別表現を活用するために、マルチスケール畳み込みカーネルを備えたマルチスケール完全畳み込みネットワーク（msfcn）が提案されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-01">
        <br><font color="black">2020-08-01</font>
      </time>
    </span>
</section>
<!-- paper0: Instance-aware, Context-focused, and Memory-efficient Weakly Supervised
  Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.IV/paper_2.html">
      <font color="black">Instance-aware, Context-focused, and Memory-efficient Weakly Supervised
  Object Detection</font>
    </a>
  </h2>
  <font color="black">インスタンス対応のセルフトレーニングアルゴリズムと学習可能なConcreteDropBlockを採用し、メモリ効率の高いシーケンシャルバッチバックプロパゲーションを考案します。提案された方法は、COCOで最先端の結果を達成します（$ 12.1 \％〜AP $、 $ 24.8 \％〜AP_ {50} $）、VOC 2007（$ 54.9 \％〜AP $）、およびVOC 2012（$ 52.1 \％〜AP $）は、ベースラインを大幅に改善します。これらの課題に対処することは、多くの場合、困難です。不確実性と些細な解決策を排除する必要があります。 
[概要]システムはこれらの問題を対象とするように設計されています。オブジェクトインスタンスの検出を減らすことを目的としています。グラウンドトゥルースがなければ、オブジェクトの提案は高いリコールのために冗長である必要があり、大量のメモリ消費を引き起こします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: Simultaneous use of Individual and Joint Regularization Terms in
  Compressive Sensing: Joint Reconstruction of Multi-Channel Multi-Contrast MRI
  Acquisitions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.IV/paper_3.html">
      <font color="black">Simultaneous use of Individual and Joint Regularization Terms in
  Compressive Sensing: Joint Reconstruction of Multi-Channel Multi-Contrast MRI
  Acquisitions</font>
    </a>
  </h2>
  <font color="black">マルチコントラスト画像は通常、補完的な診断情報を最大化するために一緒に取得されますが、スキャン時間が長くなります。ただし、これらの用語により、コントラストのサブセットに固有の機能が他のコントラストに漏れる可能性があります。共同正規化用語グループのスパース性と色の合計の変化は、画像全体の共通の特徴を活用するために使用され、個々のスパース性と全体の変化は、コントラスト全体の異なる特徴の漏れを防ぐためにも使用されます。 
[ABSTRACT]提案された方法は、再構成で個別および共同の正則化項のみを使用することと比較されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-03-02">
        <br><font color="black">2019-03-02</font>
      </time>
    </span>
</section>
<!-- paper0: Anatomically-Informed Deep Learning on Contrast-Enhanced Cardiac MRI for
  Scar Segmentation and Clinical Feature Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.IV/paper_4.html">
      <font color="black">Anatomically-Informed Deep Learning on Contrast-Enhanced Cardiac MRI for
  Scar Segmentation and Clinical Feature Extraction</font>
    </a>
  </h2>
  <font color="black">多くの心臓病は、心筋の構造的リモデリングに関連しています。後期ガドリニウム増強（LGE）などのコントラスト増強を伴う心臓磁気共鳴（CMR）イメージングは、線維性組織リモデリングを視覚化する比類のない機能を備えており、病態生理学的異常の直接的な特性評価を可能にします。不整脈と心臓突然死（SCD）につながります。この技術は、解剖学的精度と完全な自動化を保証することにより、臨床使用を可能にします。 
[ABSTRACT]後期ガドリニウム造影（lge）などのコントラスト強調を伴う心臓磁気共鳴（cmr）イメージングは、線維性組織のリモデリングを視覚化する比類のない機能を備えています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: One Model to Reconstruct Them All: A Novel Way to Use the Stochastic
  Noise in StyleGAN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.IV/paper_5.html">
      <font color="black">One Model to Reconstruct Them All: A Novel Way to Use the Stochastic
  Noise in StyleGAN</font>
    </a>
  </h2>
  <font color="black">提案されたアーキテクチャは、単一のGPUで毎秒最大40の画像を処理できます。これは、以前のアプローチよりも約28倍高速です。複数のデータドメインにわたって非常に高品質で画像を再構築できる、新しいStyleGANベースのオートエンコーダアーキテクチャを紹介します。最後に、私たちのモデルは、画像のノイズ除去タスクの最新技術と比較した場合、このタスク用に明示的に設計されていませんが、有望な結果も示しています。 
[要約]さまざまな研究により、ガンの潜在空間の限られた理解が向上しました。これまで知られていなかった一般化可能性のグレードを示しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Generalization for Medical Imaging Classification with
  Linear-Dependency Regularization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.IV/paper_6.html">
      <font color="black">Domain Generalization for Medical Imaging Classification with
  Linear-Dependency Regularization</font>
    </a>
  </h2>
  <font color="black">2つの挑戦的な医用画像分類タスクの実験結果は、私たちの方法が最先端のベースラインと比較してより優れたクロスドメイン一般化機能を達成できることを示しています。その結果、訓練されたニューラルネットワークはより優れた一般化機能を備えていることが期待されます。 「見えない」医療データ..医用画像のドメイン変動性がある程度コンパクトであるという観察に動機付けられて、共有可能な情報をキャプチャするための新しい線形依存性正規化項を使用した変分エンコーディングを通じて代表的な特徴空間を学習することを提案します。異なるドメインから収集された医療データの中で。 
[概要]最近の高度なモデルでは、トレーニングに十分なデータセットにアクセスする必要があります。単純なデバイスベンダーまたは患者集団によってキャプチャされたデータは、別のディストリビューションでデータに一般化できない場合があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-27">
        <br><font color="black">2020-09-27</font>
      </time>
    </span>
</section>
<!-- paper0: AMPA-Net: Optimization-Inspired Attention Neural Network for Deep
  Compressed Sensing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.IV/paper_7.html">
      <font color="black">AMPA-Net: Optimization-Inspired Attention Neural Network for Deep
  Compressed Sensing</font>
    </a>
  </h2>
  <font color="black">すべてのパラメータが自動的に学習されます。さらに、3つの注意ネットワークを使用してAMP-Netの表現能力を向上させるAMPA-Netを提案します。AMP-Netは、近似メッセージパッシング（AMP）アルゴリズムとニューラルの融合を実現します。通信網。 
[概要] amp--netとampa--netは4つのcs再構築ベンチマークデータセットにあります。システムはamp--ニューヨークベースのシステムによって開発されました。これを使用して初めて新しいシステムを作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: On Learned Operator Correction in Inverse Problems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.IV/paper_8.html">
      <font color="black">On Learned Operator Correction in Inverse Problems</font>
    </a>
  </h2>
  <font color="black">次に、学習した補正による変分問題の解が正しい演算子で得られた解に収束する条件を導き出します。提案されたアプローチは、限定ビュー光音響トモグラフィーへの適用で評価され、ベイズ近似誤差法の確立されたフレームワークと比較されます。このペーパーでは、このような前方モデル補正を学習するための概念的な難しさについて説明し、データ空間とソリューション空間の両方で明示的に補正する前方隣接補正として可能な解決策を提示します。 
[概要]提案されたアプローチは、限定ビュー光音響トモグラフィーへの適用で評価されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-14">
        <br><font color="black">2020-05-14</font>
      </time>
    </span>
</section>
<!-- paper0: Capturing Video Frame Rate Variations via Entropic Differencing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.IV/paper_9.html">
      <font color="black">Capturing Video Frame Rate Variations via Entropic Differencing</font>
    </a>
  </h2>
  <font color="black">この方向で、我々は、空間的および時間的バンドパスドメインで表現された一般化ガウス分布モデルに基づく新しい統計的エントロピー差分法を考案します。これは、参照ビデオと歪んだビデオの品質の違いを測定します。提案された設計は非常に一般化可能であり、参照シーケンスと歪んだシーケンスのフレームレートが異なる場合に使用できます。提案されたモデルは、最近提案されたLIVE-YT-HFRデータベースの主観的スコアと非常によく相関し、既存の方法と比較して最先端のパフォーマンスを実現します。 
[概要]提案された設計は非常に一般化可能です。業界が異なるフレームを持っている場合に使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-19">
        <br><font color="black">2020-06-19</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Integrodifferential Models for Image Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.IV/paper_10.html">
      <font color="black">Learning Integrodifferential Models for Image Denoising</font>
    </a>
  </h2>
  <font color="black">これにより、ノイズ除去パフォーマンスを大幅に低下させることなく、3つのパラメーターのみを持つ透過モデルが得られます。実験により、拡散ベースの先行モデルよりも優れていることが実証されています。機能。 
[概要]私たちのモデルは、マルチスケール統合によって異方性を作成する最初のモデルです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Deep learning based registration using spatial gradients and noisy
  segmentation labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.IV/paper_11.html">
      <font color="black">Deep learning based registration using spatial gradients and noisy
  segmentation labels</font>
    </a>
  </h2>
  <font color="black">画像レジストレーションは、医療画像分析で最も困難な問題の1つです。当社のコードとモデルはhttps://github.com/TheoEst/abdominal_registrationおよび\ https：//github.com/TheoEst/hippocampus_registrationで公開されています。メソッドは、テストセットでタスク3が$ 0.64 $、タスク4が$ 0.85 $の平均ダイスを報告し、チャレンジで3位になります。 
[概要]コードとモデルはwwwで公開されています。 github。 com</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Breaking Rayleigh's Criterion via Discernibility in High-Dimensional
  Light-Field Space with Snapshot Ghost Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.IV/paper_12.html">
      <font color="black">Breaking Rayleigh's Criterion via Discernibility in High-Dimensional
  Light-Field Space with Snapshot Ghost Imaging</font>
    </a>
  </h2>
  <font color="black">この論文では、高次元のライトフィールド空間での解像度は依然として回折によって制限されますが、GISCカメラの統計的空間解像度は、高い識別性を利用することにより、古典的なレイリーの基準と比較して大幅に改善できることを理論的および実験的に示します-次元のライトフィールド空間..高次元のライトフィールド空間におけるイメージング解像度、ライトフィールドの自由度、およびオブジェクトの自由度の間の相互作用も示されます。高次元のライトフィールドイメージングをエンコードすることによって検出可能な2次元スペックル平面への情報、スパース性制約を介したゴーストイメージングカメラ（GISCカメラ）は、1つのスナップショットだけで高次元のライトフィールドイメージング情報を直接キャッチできます。 
[概要]これにより、この光学イメージングシステムの空間分解能の限界を再検討する価値があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br><font color="black">2020-03-31</font>
      </time>
    </span>
</section>
<!-- paper0: Deeply Learned Spectral Total Variation Decomposition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.IV/paper_13.html">
      <font color="black">Deeply Learned Spectral Total Variation Decomposition</font>
    </a>
  </h2>
  <font color="black">私たちが提案するネットワークTVSpecNETは、基礎となるPDEを暗黙的に学習でき、完全にデータ駆動型であるにもかかわらず、モデルベースの変換の不変性を継承します。この論文では、非線形スペクトル分解のニューラルネットワーク近似を示します。驚異的な計算上の利点が得られるだけでなく、このアプローチは、画像を手作りの関数ではなく、ユーザーが定義したスペクトル成分に分解できるニューラルネットワークを研究するためのステップと見なすこともできます。 
[概要]提案された画像のネットワークは、データ駆動型データを取得できますが、画像を手作りの機能ではなく、ユーザーが定義した構造に分解できるニューラルネットワークを研究するためのステップと見なすことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br><font color="black">2020-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: A statistical framework for model-based inverse problems in ultrasound
  elastography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.IV/paper_14.html">
      <font color="black">A statistical framework for model-based inverse problems in ultrasound
  elastography</font>
    </a>
  </h2>
  <font color="black">結果として生じる正則化された最適化問題を解決するために、近位分割法を活用する固定小数点アルゴリズムを提案します。予備的な定性的および定量的結果は、提案された方法論の有効性と堅牢性を示します。この目的のために、私たちはリードする新しい統計手法を提案します。弾性イメージングのための統一された最適化問題に。 
[ABSTRACT]既存の準弾性法に基づくと、変位観測誤差の影響は十分に対処されていません。提案された方法は、ヤング率の観測モデルにつながる可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Adaptive Structured Sparse Network for Efficient CNNs with Feature
  Regularization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.IV/paper_15.html">
      <font color="black">Adaptive Structured Sparse Network for Efficient CNNs with Feature
  Regularization</font>
    </a>
  </h2>
  <font color="black">ただし、最近のアルゴリズムは、構造が複雑すぎて組み込みシステムに展開できない傾向があります。さらに、スパース性のレベルを定量的に制御する方法を提案し、マルチスパース性をサポートする1つのモデルをトレーニングする方法を設計します。定性的な理論的分析と実験によるピクセル間タスクのための私たちの方法の有効性。 
[ABSTRACT]超解像、スタイル転送、画像ノイズ除去..新しいメソッドは95％以上の超解像タスクを生成できます。メソッドは超解像のために80％以上削減できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Parametric Sequential Method for MRI-based Wall Shear Stress
  Quantification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.IV/paper_16.html">
      <font color="black">Parametric Sequential Method for MRI-based Wall Shear Stress
  Quantification</font>
    </a>
  </h2>
  <font color="black">新しい方法は、ファントム内の乱流定常流と生理学的拍動流の十分に制御された高解像度のin vitro測定で検証されました。壁せん断応力（WSS）は、さまざまな心血管疾患の潜在的なバイオマーカーとして提案されており、フェーズから推定できます。 -コントラスト磁気共鳴画像法（PC-MRI）速度測定..3人のボランティアの上行大動脈の2D PC-MRIデータを使用して、invivoへの基本的な適用性が実証されました。 
[要約]新しい方法は、2dpcを使用して実証されました-3人のボランティアの上行大動脈のmriデータ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Reinforcement learning using Deep Q Networks and Q learning accurately
  localizes brain tumors on MRI with very small training sets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_0.html">
      <font color="black">Reinforcement learning using Deep Q Networks and Q learning accurately
  localizes brain tumors on MRI with very small training sets</font>
    </a>
  </h2>
  <font color="black">次に、トレーニング済みのDeep Qネットワークを30個のテストセット画像の別のセットでテストしました。ただし、状態アクションスペースを制限する放射線科医の視線追跡ポイントを含む画像に適用しました。比較のために、トレーニングとテストも行いました。キーポイント検出は、同じセットのトレーニング/テスト画像の深層学習ネットワークを監視しました。 
[概要]最近、3つすべてに対処するアクションを提案しました。ここでは、画像と画像マスクのみが必要になるように、deep-q学習をgridworldベースの環境に一般化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Five Points to Check when Comparing Visual Perception in Humans and
  Machines -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_1.html">
      <font color="black">Five Points to Check when Comparing Visual Perception in Humans and
  Machines</font>
    </a>
  </h2>
  <font color="black">2番目のケーススタディでは、視覚的推論タスクの必要十分メカニズムの違いを強調します。3番目のケーススタディでは、実験条件を調整することの重要性を強調します。ここでは、次のような実験の設計、実施、解釈の方法に関するアイデアを提案します。それらは、人間と機械の知覚を比較する際のメカニズムの調査を適切にサポートします。 
[概要]これらの研究は、他のシステムを研究することによって一方のシステムについて学ぶための刺激的な機会です。3つの人間のケーススタディを通じてこれらのアイデアを実証し、適用します。別のケーススタディでは、視覚的推論の必要十分メカニズムの違いを強調しますタスク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br><font color="black">2020-04-20</font>
      </time>
    </span>
</section>
<!-- paper0: ApproxDet: Content and Contention-Aware Approximate Object Detection for
  Mobiles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_2.html">
      <font color="black">ApproxDet: Content and Contention-Aware Approximate Object Detection for
  Mobiles</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、モバイルデバイス向けの適応型ビデオオブジェクト検出フレームワークである、コンテンツとリソースの競合シナリオの変化に直面した場合の精度と遅延の要件を満たすための約Detを紹介します。特性を備え、すべてのベースラインを上回ります。たとえば、YOLOv3よりも52％低いレイテンシと11.1％高い精度を実現します。これを実現するために、データを組み込んだマルチブランチオブジェクト検出カーネル（Faster R-CNNに階層化）を導入します。パフォーマンスメトリクスのドリブンモデリングアプローチ、および実行時に最適な実行ブランチを選択するためのレイテンシSLAドリブンスケジューラ。 
[概要]これにより、3種類のダイナミズムに直面しても、実行時に適応できなくなります。実行時に最適な実行ブランチを選択するために、マルチブランチオブジェクト検出カーネルとレイテンシーsla駆動スケジューラを導入します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: A Simple Baseline for Pose Tracking in Videos of Crowded Scenes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_3.html">
      <font color="black">A Simple Baseline for Pose Tracking in Videos of Crowded Scenes</font>
    </a>
  </h2>
  <font color="black">最後に、オプティカルフローを使用して、ビデオの時間情報を利用し、最終的なポーズ追跡結果を生成します。このペーパーでは、ACM MMの課題に対するソリューションを紹介します：複雑なイベントでの大規模な人間中心のビデオ分析\ cite { lin2020human};具体的には、ここではTrack3：複雑なイベントでの群集ポーズの追跡に焦点を当てます。最初に、マルチオブジェクト追跡方法を使用して、検出モデルによって生成された各境界ボックスに人間のIDを割り当てます。 
[ABSTRACT]マルチポーズトレーニングは近年行われています。簡単なタスクは問題を解決することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-16">
        <br><font color="black">2020-10-16</font>
      </time>
    </span>
</section>
<!-- paper0: SCOP: Scientific Control for Reliable Neural Network Pruning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_4.html">
      <font color="black">SCOP: Scientific Control for Reliable Neural Network Pruning</font>
    </a>
  </h2>
  <font color="black">たとえば、私たちの方法では、ResNet-101の57.8％のパラメータと60.2％のFLOPを削減でき、ImageNetではトップ1の精度が0.01％低下するだけです。理論的には、ネットワーク層の情報伝播を考慮して、模倣品の状態をほぼ維持できることをお勧めします。 。中間層の実際の特徴マップに加えて、対応する模造品は、後続の層の別の補助入力信号として取り込まれます。 
[概要]ネットワークフィルターを使用して、フィルターの異なるバージョンを作成できます。この方法は、フィルターの速度を下げるためのテストで使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Land Cover Classification from Remote Sensing Images Based on
  Multi-Scale Fully Convolutional Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_5.html">
      <font color="black">Land Cover Classification from Remote Sensing Images Based on
  Multi-Scale Fully Convolutional Network</font>
    </a>
  </h2>
  <font color="black">この論文では、マルチスケール畳み込みカーネルを備えたマルチスケール完全畳み込みネットワーク（MSFCN）を提案して、2次元（2D）衛星画像からの識別表現を活用します。 
[概要] 2階建ての衛星画像からの識別表現を活用するために、マルチスケール畳み込みカーネルを備えたマルチスケール完全畳み込みネットワーク（msfcn）が提案されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-01">
        <br><font color="black">2020-08-01</font>
      </time>
    </span>
</section>
<!-- paper0: Instance-aware, Context-focused, and Memory-efficient Weakly Supervised
  Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_6.html">
      <font color="black">Instance-aware, Context-focused, and Memory-efficient Weakly Supervised
  Object Detection</font>
    </a>
  </h2>
  <font color="black">私たちが提案する方法は、COCO（$ 12.1 \％〜AP $、$ 24.8 \％〜AP_ {50} $）、VOC 2007（$ 54.9 \％〜AP $）、およびVOC 2012（$ 52.1 \）で最先端の結果を達成します。 ％〜AP $）、大幅なマージンでベースラインを改善します。メモリ効率の高いシーケンシャルバッチバックプロパゲーションを考案しながら、インスタンス対応のセルフトレーニングアルゴリズムと学習可能なConcrete DropBlockを採用しています。さらに、提案された方法は最初のものです。 ResNetベースのモデルと弱く監視されたビデオオブジェクト検出のベンチマークを行います。 
[概要]システムはこれらの問題を対象とするように設計されています。オブジェクトインスタンスの検出を減らすことを目的としています。グラウンドトゥルースがなければ、オブジェクトの提案は高いリコールのために冗長である必要があり、大量のメモリ消費を引き起こします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Accurate Human Pose Estimation in Videos of Crowded Scenes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_7.html">
      <font color="black">Towards Accurate Human Pose Estimation in Videos of Crowded Scenes</font>
    </a>
  </h2>
  <font color="black">本論文では、時間的コンテキストの活用と新しいデータの収集の観点から、混雑したシーンのビデオにおける人間の姿勢推定の改善に焦点を当てます。次に、オプティカルフローから派生した時間的コンテキストを使用してフレームベースのポーズ推定を改良します。具体的には、1つのフレームについて、前のフレームからの過去のポーズを転送し、次のフレームから現在のフレームに将来のポーズを逆方向に転送して、ビデオでの安定した正確な人間のポーズ推定を実現します。 
[概要]このように、私たちのモデルは13本の動画のうち7本で最高のパフォーマンスを実現しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-16">
        <br><font color="black">2020-10-16</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning Frameworks for Pavement Distress Classification: A
  Comparative Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_8.html">
      <font color="black">Deep Learning Frameworks for Pavement Distress Classification: A
  Comparative Analysis</font>
    </a>
  </h2>
  <font color="black">この研究では、著者は、舗装の苦痛を検出して特徴づけるために、さまざまなネットワークバックボーンに基づく最先端の深層学習アルゴリズムを展開します。モデルは、日本、チェコ共和国、インドの都市と農村の街路でキャプチャされた21,041枚の画像を使用してトレーニングされました。 ..トレーニング済みモデルを含むソースコードは
[1]で入手できます。 
[概要]近年、広範囲にわたる舗装欠陥評価が改善されました。これは、舗装欠陥評価を開発するための一連の新しいシステムの最新のものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Visual Navigation in Real-World Indoor Environments Using End-to-End
  Deep Reinforcement Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_9.html">
      <font color="black">Visual Navigation in Real-World Indoor Environments Using End-to-End
  Deep Reinforcement Learning</font>
    </a>
  </h2>
  <font color="black">したがって、トレーニングされたポリシーを実際のロボットに直接展開できる新しいアプローチを提案します。ビジュアルナビゲーションは、操作からモバイルロボット、自動運転まで、ロボット工学の多くのアプリケーションに不可欠です。ただし、現在まで、DRLベースビジュアルナビゲーションは、シミュレーションでのみ検証されました。シミュレータは、ロボットの位置や画像セグメンテーションマスクなど、現実の世界では利用できない情報を提供します。 
[概要]深く強化された学習は、エレガントなマップを提供します-調整されたアプローチ。トレーニングできるため、特定の環境に最適化できます。これにより、実際のロボットで学習したeを使用できなくなります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Anatomically-Informed Deep Learning on Contrast-Enhanced Cardiac MRI for
  Scar Segmentation and Clinical Feature Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_10.html">
      <font color="black">Anatomically-Informed Deep Learning on Contrast-Enhanced Cardiac MRI for
  Scar Segmentation and Clinical Feature Extraction</font>
    </a>
  </h2>
  <font color="black">線維症分布を伴う心室のセグメンテーションの自動化は、心臓病の臨床研究および不整脈とSCDのリスクのある患者の管理におけるLGE-CMRの有用性を劇的に高める可能性があります。臨床的特徴抽出のためのアプローチ。学習プロセスを阻害することは、心臓病学を超えて、さらには医学の外でも、コンピュータビジョンに幅広い適用性をもたらす可能性があります。ここでは、心筋および瘢痕のセグメンテーションとLGEからの臨床的特徴の抽出に対する解剖学的情報に基づく深層学習（DL）アプローチについて説明します。 CMR画像。 
[ABSTRACT]後期ガドリニウム造影（lge）などのコントラスト強調を伴う心臓磁気共鳴（cmr）イメージングは、線維性組織のリモデリングを視覚化する比類のない機能を備えています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: A Wigner-Eckart Theorem for Group Equivariant Convolution Kernels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_11.html">
      <font color="black">A Wigner-Eckart Theorem for Group Equivariant Convolution Kernels</font>
    </a>
  </h2>
  <font color="black">GCNNの理論的記述における最近の進歩により、このようなモデルは一般に、Gステアブルカーネル、つまり、同変制約自体を満たすカーネルで畳み込みを実行するものとして理解できることが明らかになりました。私たちの調査は、ステアブルの基礎となる制約間の顕著な類似性によって動機付けられています。一方ではカーネル、他方では量子力学からの球形テンソル演算子..この作業は、Gが任意のコンパクトグループであるという実際に関連するケースにそのような特性を提供します。 
[概要] g-操作可能なカーネルはgcnnsで動作することができました。これらのモデルは、一般にg-操作可能なカーネルで畳み込みを実行するものとして理解できます。これらの作業は、gが任意のコンパクトグループであるという実際に関連するケースにそのような特性を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: One Model to Reconstruct Them All: A Novel Way to Use the Stochastic
  Noise in StyleGAN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_12.html">
      <font color="black">One Model to Reconstruct Them All: A Novel Way to Use the Stochastic
  Noise in StyleGAN</font>
    </a>
  </h2>
  <font color="black">複数のデータドメインにわたって非常に高品質で画像を再構築できる、新しいStyleGANベースのオートエンコーダアーキテクチャを紹介します。最後に、画像のノイズ除去タスクの最新技術と比較した場合、モデルは有望な結果も示しています。このタスク用に明示的に設計されたわけではありませんが、提案されたアーキテクチャは、単一のGPUで1秒あたり最大40の画像を処理できます。これは、以前のアプローチよりも約28倍高速です。 
[要約]さまざまな研究により、ガンの潜在空間の限られた理解が向上しました。これまで知られていなかった一般化可能性のグレードを示しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Generalization for Medical Imaging Classification with
  Linear-Dependency Regularization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_13.html">
      <font color="black">Domain Generalization for Medical Imaging Classification with
  Linear-Dependency Regularization</font>
    </a>
  </h2>
  <font color="black">最近、ディープニューラルネットワークを採用することにより、医用画像分類の分野で大きな進歩を遂げました。医用画像のドメイン変動がある程度コンパクトであるという観察に動機付けられて、変分符号化を通じて代表的な特徴空間を学習することを提案します。異なるドメインから収集された医療データ間で共有可能な情報をキャプチャするための新しい線形依存正則化項を使用すると、特定のデバイスベンダーまたは患者集団によってキャプチャされたデータは、別の分布のデータに一般化できない場合があります。 
[概要]最近の高度なモデルでは、トレーニングに十分なデータセットにアクセスする必要があります。単純なデバイスベンダーまたは患者集団によってキャプチャされたデータは、別のディストリビューションでデータに一般化できない場合があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-27">
        <br><font color="black">2020-09-27</font>
      </time>
    </span>
</section>
<!-- paper0: Recurrent neural network-based volumetric fluorescence microscopy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_14.html">
      <font color="black">Recurrent neural network-based volumetric fluorescence microscopy</font>
    </a>
  </h2>
  <font color="black">Recurrent-MZと呼ばれる反復畳み込みニューラルネットワークを介して、サンプル内のいくつかのアキシャル面からの2D蛍光情報が明示的に組み込まれ、拡張された被写界深度にわたってサンプルボリュームをデジタルで再構築します。さまざまな軸方向の順列や未知の軸方向の位置決めエラーをカバーする、入力画像のさまざまなシーケンスなど、さまざまなイメージング条件に対する復元力を示すことにより、3Dイメージング用のこのリカレントネットワークの概要を示します。ここでは、サンプルボリューム内の任意の軸方向位置で標準的な広視野蛍光顕微鏡によってまばらにキャプチャされた2D画像。 
[ABSTRACT] recurrent-mzは、63x / 1の被写界深度を増加させることが実証されています。 4na対物レンズを50倍に。同じサンプルボリュームを画像化するために必要な画像の数を30分の1に削減します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: AMPA-Net: Optimization-Inspired Attention Neural Network for Deep
  Compressed Sensing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_15.html">
      <font color="black">AMPA-Net: Optimization-Inspired Attention Neural Network for Deep
  Compressed Sensing</font>
    </a>
  </h2>
  <font color="black">AMP-Netは、近似メッセージパッシング（AMP）アルゴリズムとニューラルネットワークの融合を実現します。圧縮センシング（CS）は、限られた測定からほぼ完全な画像を再構築するため、画像処理における困難な問題です。自動的に学習しました。 
[概要] amp--netとampa--netは4つのcs再構築ベンチマークデータセットにあります。システムはamp--ニューヨークベースのシステムによって開発されました。これを使用して初めて新しいシステムを作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Continuous Meta-Learning without Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_16.html">
      <font color="black">Continuous Meta-Learning without Tasks</font>
    </a>
  </h2>
  <font color="black">微分可能なベイズ変化点検出スキームでメタ学習アルゴリズムを強化するアプローチであるオンライン変化点分析（MOCA）を介したメタ学習を提示します。この作業では、このタスクが行われる設定に一般的なメタ学習アルゴリズムを適用できるようにします。時変タスクを使用した継続的なオンライン学習など、セグメンテーションは利用できません。ただし、これまでのメタ学習の文献は、トレーニング時にオフラインデータが次のように分割されると想定されるタスクのセグメント化設定に焦点を当ててきました。基礎となるタスク、およびテスト時に、アルゴリズムは単一のタスクで学習するように最適化されます。 
[概要]オンライン変化点分析（moca）によるメタ学習を紹介します。これは、微分可能な変化点検出スキームでメタ学習アルゴリズムを強化するアプローチです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br><font color="black">2019-12-18</font>
      </time>
    </span>
</section>
<!-- paper0: DiSCO: Differentiable Scan Context with Orientation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_17.html">
      <font color="black">DiSCO: Differentiable Scan Context with Orientation</font>
    </a>
  </h2>
  <font color="black">最後に、DiSCOは、長期の屋外条件でNCLTおよびOxfordデータセットで検証され、比較された方法よりも優れたパフォーマンスを示します。スペクトルの大きさを場所の署名として利用します。これは、理論的には回転不変です。制約、ネットワークはエンドツーエンドの方法で学習でき、バックボーンは2つのタスクによって完全に共有され、解釈可能性と軽量化を実現します。 
[概要]この論文では、LIDARベースの場所認識方法を提案します。これは、同様の場所でスキャンを同時に検出し、それらの相対的な向きを推定します。目標は、特徴メトリックを周波数に変換することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Semantics-Guided Representation Learning with Applications to Visual
  Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_18.html">
      <font color="black">Semantics-Guided Representation Learning with Applications to Visual
  Synthesis</font>
    </a>
  </h2>
  <font color="black">ATNLによって導かれる潜在空間を使用して、画像のセマンティックワーピングを生成するために球面セマンティック補間をさらに利用し、望ましい視覚データの合成を可能にします。MNISTおよびCMU Multi-PIEデータセットでの実験により、この方法の有効性が定性的および定量的に検証されます。ほとんどの既存のアプローチは、補間可能な潜在空間を導き出し、画像の外観にスムーズな遷移を引き起こしますが、関心のある意味情報を含む望ましい表現を観察する方法はまだ明確ではありません。 
[要約]ニューヨークベースの研究は、分布が関心のある情報と一致する潜在表現を学習することを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_19.html">
      <font color="black">Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News</font>
    </a>
  </h2>
  <font color="black">攻撃者が悪用できる可能性のある弱点を特定するために、4つの異なるタイプの生成された記事で構成されるNeuralNewsデータセットを作成し、このデータセットに基づいて一連の人間ユーザー調査実験を実施します。ユーザーから収集した貴重な洞察に加えて研究実験では、視覚的セマンティックの不整合の検出に基づく比較的効果的なアプローチを提供します。これは、効果的な防御の第一線として機能し、機械によって生成された情報からの防御における将来の作業の有用なリファレンスとして機能します。画像やキャプションも含まれる、機械で生成されたニュースから身を守るという、より現実的でやりがいのあるタスク。 
[概要]画像、動画、自然言語モデルの急速な進歩により、効果的な防衛機制の必要性が高まっています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Removing Bias in Multi-modal Classifiers: Regularization by Maximizing
  Functional Entropies -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_20.html">
      <font color="black">Removing Bias in Multi-modal Classifiers: Regularization by Maximizing
  Functional Entropies</font>
    </a>
  </h2>
  <font color="black">これに対処するために、log-Sobolev不等式に基づく方法を開発します。これは、関数エントロピーを関数フィッシャー情報で制限します。分類子は本質的にモダリティのサブセットに偏っているため、これは最適ではありません。直感的には、これ用語は、分類結果への各モダリティの寄与のバランスをとることを奨励します。 
[概要]多くのモダリティは、他のモダリティよりも分類結果に簡単に貢献できます。これにより、関数シンプソンに基づいた新しい正則化項が作成されます。ただし、データの正則化は困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Progressive Batching for Efficient Non-linear Least Squares -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_21.html">
      <font color="black">Progressive Batching for Efficient Non-linear Least Squares</font>
    </a>
  </h2>
  <font color="black">経験的結果は、提案された方法が、画像の位置合わせや本質的な行列の推定など、非常に多くの残差がある一般的なコンピュータービジョンの問題に対して、従来の2次アプローチと比較して競争力のある収束率を達成することを示しています。と統計、および収束を保証すると同時に必要な計算量を大幅に削減する非線形最小二乗のアプローチを提示します。非線形最小二乗ソルバーは、オフラインおよびリアルタイムの幅広い範囲で使用されます。モデルフィッティングの問題。 
[要約]ガウスのタイプのほとんどの改善-ニュートンアルゴリズムは問題に取り組みます。これは、多くの作業を提供する単純で単純なシステムの結果です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Example Games -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_22.html">
      <font color="black">Adversarial Example Games</font>
    </a>
  </h2>
  <font color="black">攻撃のジェネレーターと分類子の間のミニマックスゲームとして敵対的な例の作成をモデル化するフレームワークである敵対的な例のゲーム（AEG）を紹介します。AEGは、ジェネレーターと与えられた仮説クラス（例えば、アーキテクチャ）からの分類器。この作業では、仮説クラス全体に転送可能な敵対的な例を作成するための理論的基盤を提供します。 
[要約]この作業では、仮説クラス全体に転送可能な敵対的な例を作成するための理論的基盤を提供します。aegは、特定の理論クラスからジェネレータと分類子をトレーニングすることにより、敵対的な例を設計する新しい方法を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-01">
        <br><font color="black">2020-07-01</font>
      </time>
    </span>
</section>
<!-- paper0: Probabilistic Numeric Convolutional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_23.html">
      <font color="black">Probabilistic Numeric Convolutional Neural Networks</font>
    </a>
  </h2>
  <font color="black">実験では、私たちのアプローチにより、SuperPixel-MNISTデータセットの以前の最先端技術からのエラーが$ 3 \ times $削減され、医療時系列データセットPhysioNet2012で競争力のあるパフォーマンスが得られることを示しています。次に、畳み込み層を進化として定義します。このGPで定義されたPDEの後に、非線形性が続きます。回転群。 
[概要]システムは、畳み込みの畳み込み層に基づいています。これらには、偏微分方程式、欠落した偏微分方程式、畳み込み畳み込みが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: On Learned Operator Correction in Inverse Problems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_24.html">
      <font color="black">On Learned Operator Correction in Inverse Problems</font>
    </a>
  </h2>
  <font color="black">提案されたアプローチは、限定ビュー光音響トモグラフィーへの適用で評価され、ベイズ近似誤差法の確立されたフレームワークと比較されます。次に、学習された補正による変分問題の解が正しい演算子で得られた解に収束する条件を導き出します。このペーパーでは、このような前方モデル補正を学習するための概念的な難しさについて説明し、データ空間とソリューション空間の両方で明示的に補正する前方隣接補正として可能な解決策を提示します。 
[概要]提案されたアプローチは、限定ビュー光音響トモグラフィーへの適用で評価されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-14">
        <br><font color="black">2020-05-14</font>
      </time>
    </span>
</section>
<!-- paper0: TargetDrop: A Targeted Regularization Method for Convolutional Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_25.html">
      <font color="black">TargetDrop: A Targeted Regularization Method for Convolutional Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">他の方法と比較した、または異なるネットワークに適用された実験結果は、私たちの方法の正則化効果を示しています。具体的には、ターゲットチャネルに対応する特徴マップのターゲット領域をマスクします。ドロップアウト正則化は深層学習で広く使用されていますが空間的に相関する機能により、ドロップされた情報がネットワークを通過できるため、畳み込みニューラルネットワークのパフォーマンスは低下します。 
[概要]これに対処するために、いくつかの効果的なドロップアウトの形式が提案されています。ただし、特徴がランダムにドロップされるため、ターゲット化は正則化を上回ったり下回ったりする傾向があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Guide Local Feature Matches -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_26.html">
      <font color="black">Learning to Guide Local Feature Matches</font>
    </a>
  </h2>
  <font color="black">特に、エピポーラジオメトリからの弱い監視は、より強力であるがより偏ったポイントレベルの監視よりも高いパフォーマンスにつながり、弱い画像レベルの監視よりも明らかに改善されることを示します。画像間の正確で堅牢なキーポイントの対応を見つける問題に取り組みます。 。YFCC100Mデータセットのインターネット画像とSUN3Dデータセットの屋内画像のローカリゼーション、Aachenの昼夜ベンチマークでの堅牢なローカリゼーション、およびLTLL履歴画像データを使用した困難な条件。 
[概要]学習した正確な画像マッチングを介してローカル機能の一致をガイドする学習ベースのアプローチを提案します。さまざまなレベルのコンテキストを導入して調査し、分析を学習します。これらの調査は、アプローチの利点を示すためにも使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Capturing Video Frame Rate Variations via Entropic Differencing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_27.html">
      <font color="black">Capturing Video Frame Rate Variations via Entropic Differencing</font>
    </a>
  </h2>
  <font color="black">この方向で、我々は、空間的および時間的バンドパスドメインで表現された一般化ガウス分布モデルに基づく新しい統計的エントロピー差分法を考案します。これは、参照ビデオと歪んだビデオの品質の違いを測定します。提案された設計は非常に一般化可能であり、参照シーケンスと歪んだシーケンスのフレームレートが異なる場合に使用できます。高フレームレートのビデオは、消費者に高品質のエクスペリエンスを提供するというエンターテインメントおよびストリーミング業界の強い要件に牽引されて、近年ますます人気が高まっています。 
[概要]提案された設計は非常に一般化可能です。業界が異なるフレームを持っている場合に使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-19">
        <br><font color="black">2020-06-19</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Real-time Drowsiness Detection for Elderly Care -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_28.html">
      <font color="black">Towards Real-time Drowsiness Detection for Elderly Care</font>
    </a>
  </h2>
  <font color="black">まぶたと口の開閉状態の分類精度は94.3％〜97.2％でした。この論文の主な焦点は、ビデオから眠気情報を抽出して、一人暮らしの高齢者を支援するための概念実証を作成することです。時間の経過に伴うあくび、まぶた、頭の動きを定量化し、OpenCVライブラリと統合された深層学習モデルのトレーニングとテストのためにキャプチャしたビデオから3000枚の画像を抽出しました。 
[概要] opencvライブラリと統合された深層学習モデルのトレーニングとテストのために、キャプチャしたビデオから3000枚の画像を抽出しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Black-Box Ripper: Copying black-box models using generative evolutionary
  algorithms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_29.html">
      <font color="black">Black-Box Ripper: Copying black-box models using generative evolutionary
  algorithms</font>
    </a>
  </h2>
  <font color="black">経験的証拠は、私たちのモデルが考慮されたベースラインよりも優れていることを示しています。私たちのフレームワークは、3つのベンチマークデータセットでいくつかのベースラインおよび最先端の方法と比較されます。学生を訓練するための有用なデータサンプルを生成するために、私たちのフレームワーク（i）プロキシデータセット（ブラックボックスのトレーニングに使用されるものとは異なる画像とクラスを使用）で画像を生成することを学習し、（ii）進化的戦略を適用して、生成された各データサンプルがブラックボックスへの入力として指定された場合の特定のクラス。 
[概要]ブラックボックス（教師）モデルを最小限の精度損失で学生モデルに抽出できる教師-学生フレームワークを提示します。メソッドは逆戻りしません-ブラックボックスネットワークを介して伝播します。しかし、一般的に状態を超えます-教師をガラスボックスモデルと見なす芸術的手法の</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Synthetic Expressions are Better Than Real for Learning to Detect Facial
  Actions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_30.html">
      <font color="black">Synthetic Expressions are Better Than Real for Learning to Detect Facial
  Actions</font>
    </a>
  </h2>
  <font color="black">顔のアクションを検出するための分類器のトレーニングにおける重大な障害は、注釈付きビデオデータベースのサイズが限られていることと、多くのアクションの発生頻度が比較的低いことです。両方のネットワークは同じトレインパーティションと検証パーティションを使用し、FERA17の実際のビデオのテストパーティションでテストされました。 ..私たちのアプローチは、各ビデオフレームから顔の3D形状を再構築し、3Dメッシュを標準ビューに位置合わせしてから、GANベースのネットワークをトレーニングして、関心のある顔のアクションユニットで新しい画像を合成します。 
[概要]このビューを評価するために、2つの別々のデータセットでディープニューラルネットワークがトレーニングされました。これは、fera17から生成された表情と実際の表情の他のネットワークに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: UAV LiDAR Point Cloud Segmentation of A Stack Interchange with Deep
  Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_31.html">
      <font color="black">UAV LiDAR Point Cloud Segmentation of A Stack Interchange with Deep
  Neural Networks</font>
    </a>
  </h2>
  <font color="black">提案された方法は、積み重ねられた畳み込みを伴う複雑な交換シナリオで3D機能をキャプチャすることが証明され、その結果は93％を超える分類精度を達成しました。さらに、計り知れないロゼットを備えた新しい低コストの半固体LiDARセンサーLivoxMid-40スキャンパターンは、高解像度の都市マッピングでその可能性を示しています。スタックインターチェンジは、輸送システムの重要なコンポーネントです。 
[ABSTRACT]既存のシステムシステムシステムを使用して点群を分類できます。高度な高度な深層学習フレームワークが点群を分類するために提案されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Integrodifferential Models for Image Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_32.html">
      <font color="black">Learning Integrodifferential Models for Image Denoising</font>
    </a>
  </h2>
  <font color="black">スケール適応重み付けとコントラストパラメータのトレーニング結果を調査して、滑らかな関数による明示的なモデリングを取得します。画像のノイズ除去のためのエッジ強調異方性拡散モデルの積分微分拡張を導入します。マルチスケール情報と異方性の両方が重要であることを示します。その成功のために。 
[概要]私たちのモデルは、マルチスケール統合によって異方性を作成する最初のモデルです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: UFO$^2$: A Unified Framework towards Omni-supervised Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_33.html">
      <font color="black">UFO$^2$: A Unified Framework towards Omni-supervised Object Detection</font>
    </a>
  </h2>
  <font color="black">最後に、UFO $ ^ 2 $の一般化を示し、境界ボックスの注釈なしで1,000を超える異なるオブジェクトを検出します。このホワイトペーパーでは、さまざまな形式の監視を同時に処理できる統合オブジェクト検出フレームワークであるUFO $ ^ 2 $を紹介します。 .. UFO $ ^ 2 $を使用して、予算を意識したオムニ監視学習を調査します。つまり、固定の注釈予算の下でさまざまな注釈ポリシーを調査します。競争力のあるパフォーマンスでは、すべてのデータに強力なラベルを付ける必要がないことを示しています。 
[概要]これらの2歳児は注釈予算に基づいています。彼らは、競争力のあるパフォーマンスがすべてのデータに強力なラベルを必要としないことを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Experimental Quantum Generative Adversarial Networks for Image
  Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_34.html">
      <font color="black">Experimental Quantum Generative Adversarial Networks for Image
  Generation</font>
    </a>
  </h2>
  <font color="black">私たちの仕事は、短期量子デバイス上で高度な量子生成モデルを開発するためのガイダンスを提供し、さまざまなGAN関連の学習タスクにおける量子の利点を探求するための道を開きます。ここでは、この知識のギャップを狭めるための柔軟な量子GANスキームを考案します。任意の高次元の特徴を備えた画像生成を実現でき、量子重ね合わせを利用して複数の例を並行してトレーニングすることもできます。さらに、グレースケールバーデータセットを利用して、量子GANと従来のGANベースの競合パフォーマンスを示します。 Fr \ &#39;echet Distanceスコアによってベンチマークされた、多層パーセプトロンと畳み込みニューラルネットワークアーキテクチャでそれぞれ。 
[ABSTRACT]量子ボーダは、古典的なガンよりも指数関数的に有利になる可能性があるため、幅広い注目を集めています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Transformer Networks for Trajectory Forecasting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_35.html">
      <font color="black">Transformer Networks for Trajectory Forecasting</font>
    </a>
  </h2>
  <font color="black">提案されたトランスフォーマーは、シーン内の個々の人物の軌跡を予測します。最後に、実際のセンサーデータの場合と同様に、トランスフォーマーが欠落した観測を処理する可能性があることを示します。これらは、各人物がモデル化されているため、「単純な」モデルです。複雑な人間と人間またはシーンの相互作用の用語なしで個別に。 
[概要] lstmモデルの使用に疑問を呈し、軌道にトランスフォーマーネットワークを新たに使用することを提案します。これらは「単純な」モデルです。これは、各人が複雑な人間-人間またはシーンの相互作用項なしで個別にモデル化されているためです。拡張機能も実行できます。倫理の5つのデータセットに関するより設計された技術と同等</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br><font color="black">2020-03-18</font>
      </time>
    </span>
</section>
<!-- paper0: Deep learning based registration using spatial gradients and noisy
  segmentation labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_36.html">
      <font color="black">Deep learning based registration using spatial gradients and noisy
  segmentation labels</font>
    </a>
  </h2>
  <font color="black">私たちの方法では、テストセットのタスク3で$ 0.64 $、タスク4で$ 0.85 $の平均サイコロが報告され、チャレンジで3位になります。この短いペーパーでは、Learn2Regチャレンジ2020で提示された作業を要約します。モデルはhttps://github.com/TheoEst/abdominal_registrationおよび\ https：//github.com/TheoEst/hippocampus_registrationで公開されています。 
[概要]コードとモデルはwwwで公開されています。 github。 com</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Deformable Kernel Networks for Joint Image Filtering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_37.html">
      <font color="black">Deformable Kernel Networks for Joint Image Filtering</font>
    </a>
  </h2>
  <font color="black">デプスマップのアップサンプリング、顕著性マップのアップサンプリング、クロスモダリティ画像の復元、テクスチャの削除、セマンティックセグメンテーションのタスクにおけるモデルの有効性と柔軟性を示します。フィルタリング結果は、加重平均として計算されます。ジョイント画像フィルタ空間解像度の向上やノイズの抑制などのタスクで、ターゲット画像の前に使用されるガイダンス画像から構造の詳細を転送するために使用されます。 
[概要]変形可能なカーネルネットワーク（dkn）はcnnアーキテクチャです。これは、隣接ピクセルのセットと対応する重みを各ピクセルに適応的に生成します。dknの高速バージョンは、サイズ640 x480の画像で17倍高速に実行されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-17">
        <br><font color="black">2019-10-17</font>
      </time>
    </span>
</section>
<!-- paper0: AE TextSpotter: Learning Visual and Linguistic Representation for
  Ambiguous Text Spotting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_38.html">
      <font color="black">AE TextSpotter: Learning Visual and Linguistic Representation for
  Ambiguous Text Spotting</font>
    </a>
  </h2>
  <font color="black">1（c））..テキスト検出に視覚的特徴を単に採用した以前の作品とは異なり、この作品は、テキストの曖昧さを大幅に減らすために視覚的特徴と言語的特徴の両方を学習する、Ambiguity Elimination Text Spotter（AE TextSpotter）という名前の新しいテキストスポッターを提案します。検出..シーンテキストスポッティングは、自然画像内の複数の文字を含む単語または文全体を検出および認識することを目的としています。 
[概要]提案されたaetextspotterには、3つの重要な利点があります。言語モデルを使用してテキスト検出を改善するのは初めてです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-03">
        <br><font color="black">2020-08-03</font>
      </time>
    </span>
</section>
<!-- paper0: A Coarse-To-Fine (C2F) Representation for End-To-End 6-DoF Grasp
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_39.html">
      <font color="black">A Coarse-To-Fine (C2F) Representation for End-To-End 6-DoF Grasp
  Detection</font>
    </a>
  </h2>
  <font color="black">また、単一オブジェクトシーンでの成功率とクラッターシーンでの完了率の点で、それぞれ8％と40％正確です。さらに、回転エラーと遷移エラーの両方を考慮した新しいAPベースのメトリックを提案します。これは、把握検出モデルのより包括的な評価ツールです。私たちの方法は、ビューと入力ポイントの数が異なる設定の中で優れた結果を示します。 
[概要]私たちのアーキテクチャは少なくとも20倍高速です。以前の2-fアプローチよりも正確です。私たちの方法は設定で優れた結果を示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Fully Convolutional Mesh Autoencoder using Efficient Spatially Varying
  Kernels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_40.html">
      <font color="black">Fully Convolutional Mesh Autoencoder using Efficient Spatially Varying
  Kernels</font>
    </a>
  </h2>
  <font color="black">これは、グローバルに共有された重みとローカルに変化する係数で学習された新しい畳み込みと（アン）プーリング演算子によって可能になり、不規則なメッシュ接続によって提示される空間的に変化するコンテンツを効率的にキャプチャできます。私たちのモデルは、再構築に関する最先端の方法よりも優れています。精度..より一般的なグラフ畳み込み法を使用できますが、再構成の精度に欠け、より高いメモリ使用量が必要です。 
[概要]これらの方法は、テンプレート（比表面積ネットワーク）にのみ適用できます。これは、テトラキアや非多様体メッシュなどのより一般的なメッシュには適用されません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-08">
        <br><font color="black">2020-06-08</font>
      </time>
    </span>
</section>
<!-- paper0: Study of star clusters in the M83 galaxy with a convolutional neural
  network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_41.html">
      <font color="black">Study of star clusters in the M83 galaxy with a convolutional neural
  network</font>
    </a>
  </h2>
  <font color="black">渦巻銀河M83の星団候補の進化的および構造的パラメーターの研究を提示します。また、多数の渦巻銀河を発見しました。銀河の中心近くにある密集した古い星団と、中心から離れた典型的な星団サイズのわずかな増加。 
[概要]渦巻銀河の後部、ダストレーンの近くに高絶滅クラスター候補が見つかりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: LCD -- Line Clustering and Description for Place Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_42.html">
      <font color="black">LCD -- Line Clustering and Description for Place Recognition</font>
    </a>
  </h2>
  <font color="black">フレームワイズラインクラスタリングの注意メカニズムに基づくニューラルネットワークアーキテクチャを提示します。この論文では、視覚的および幾何学的特徴としてRGB-Dカメラとラインクラスターを使用して、場所認識への新しい学習ベースのアプローチを紹介します。場所認識の問題は、個々のパッチではなく線のクラスターを認識し、構造情報を維持する問題として説明します。 
[概要]研究は、最先端のイメージング技術を使用して行われます。これらには、rgb-d画像で検出される3D線分が含まれます。これらは、取得されたトレーニングデータのトリプレット損失でトレーニングされた128個の浮動小数点数のネットワークに基づいています。 innerladデータセットから</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Dense Dual-Path Network for Real-time Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_43.html">
      <font color="black">Dense Dual-Path Network for Real-time Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">提案されたDDPNetは、精度と速度のバランスをとる上で明らかな利点を示しています。ネットワーク全体での機能の再利用を容易にする高密度の接続性を備えた軽量で強力なバックボーンと、マルチスケールを十分に集約するための提案されたデュアルパスモジュール（DPM）を設計します。コンテキスト..一方、シンプルで効果的なフレームワークは、高解像度の特徴マップを利用してセグメンテーション出力を洗練するスキップアーキテクチャと、特徴マップからのコンテキスト情報を活用してヒートマップを洗練するアップサンプリングモジュールで構築されます。 
[概要]このペーパーでは、スキップアーキテクチャを備えた新しい高密度デュアルバックボーンを提案します。これは、改良するアップサンプリングモジュールを備えており、heatmaps.ddpnetは、シングルで1024 x2048の解像度の入力に対して52.6fpsで75.3％miouを達成します。 gtx1080tiカード</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Multilinear Compressive Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_44.html">
      <font color="black">Multilinear Compressive Learning</font>
    </a>
  </h2>
  <font color="black">圧縮学習は、圧縮センシングによる信号取得と機械学習を組み合わせて、少数の測定値に対して直接推論タスクを実行する新しいトピックです。この論文では、マルチの感覚的性質を考慮したフレームワークであるマルチリニア圧縮学習を提案します。取得ステップで次元信号を作成し、構造的に検出された測定値に基づいて後続の推論モデルを構築します。ただし、既存の圧縮学習フレームワークでは、圧縮検出コンポーネントは、ベクトル化された信号のランダムまたは学習線形投影を利用して信号取得を実行するため、破棄されます。信号の多次元構造。 
[概要]マルチリニア圧縮学習を作成するために多くのフレームワークが提案されています。これは、多層信号の光子の性質を考慮したフレームワークです。ただし、システムがオブジェクト分類および顔認識タスクのメインツールよりも優れていることも示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-17">
        <br><font color="black">2019-05-17</font>
      </time>
    </span>
</section>
<!-- paper0: Deeply Learned Spectral Total Variation Decomposition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_45.html">
      <font color="black">Deeply Learned Spectral Total Variation Decomposition</font>
    </a>
  </h2>
  <font color="black">私たちが提案するネットワークTVSpecNETは、基礎となるPDEを暗黙的に学習でき、完全にデータ駆動型であるにもかかわらず、モデルベースの変換の不変性を継承します。異なるサイズとコントラストのオブジェクトに対応するスペクトル成分を抽出する機能により、このような分解フィルタリング、機能転送、画像融合、その他のアプリケーションを有効にします。従来のGPU実装と比較して、メガピクセルサイズの画像の処理が最大4桁（$ \ times 10,000 $）高速化されることを報告します。 
[概要]提案された画像のネットワークは、データ駆動型データを取得できますが、画像を手作りの機能ではなく、ユーザーが定義した構造に分解できるニューラルネットワークを研究するためのステップと見なすことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br><font color="black">2020-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: Deep learning algorithms out-perform veterinary pathologists in
  detecting the mitotically most active tumor region -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_46.html">
      <font color="black">Deep learning algorithms out-perform veterinary pathologists in
  detecting the mitotically most active tumor region</font>
    </a>
  </h2>
  <font color="black">予測された有糸分裂数とグラウンドトゥルース有糸分裂数の相関もこのアプローチに最適でした（0.963〜0.979）。2段階の物体検出器は、ほとんどの腫瘍症例でほとんどの人間の病理学者を上回り、最高のパフォーマンスを示しました。 H＆Eで染色された犬の皮膚マスト細胞腫瘍の32枚のスライド画像全体のセットで、有糸分裂像が完全に注釈されています。 
[ABSTRACT]有糸分裂像は腫瘍切片における不均一で不均一な有糸分裂像の分布。領域の選択は有糸分裂数に影響を与える可能性があり、これは既知の高い評価者の不一致があります。有糸分裂像は電位差を評価するために作成されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-02-12">
        <br><font color="black">2019-02-12</font>
      </time>
    </span>
</section>
<!-- paper0: Geometry-based Occlusion-Aware Unsupervised Stereo Matching for
  Autonomous Driving -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_47.html">
      <font color="black">Geometry-based Occlusion-Aware Unsupervised Stereo Matching for
  Autonomous Driving</font>
    </a>
  </h2>
  <font color="black">本論文では、オクルージョン領域を検出する効果的な方法を紹介し、そのジオメトリ特徴を反復的に利用することにより、予測された左視差マップのみを使用するオクルージョンに対処するための新しい教師なしトレーニング戦略を提案します。 -認識戦略を他のステレオメソッドに便利に拡張して、パフォーマンスを向上させることができます。以前の教師なしメソッドは、オクルージョン処理でジオメトリプロパティを十分に活用できませんでした。 
[概要]それらの多くは、再構成損失を利用して、視差の根拠への依存を取り除きます。これは、効果的な方法がオクルージョンを十分に活用できなかったのは初めてです。この方法は、オクルージョンの問題に効果的に対処し、他の教師なしを上回ります。ステレオマッチングの方法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: 2nd Place Solution to Instance Segmentation of IJCAI 3D AI Challenge
  2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_48.html">
      <font color="black">2nd Place Solution to Instance Segmentation of IJCAI 3D AI Challenge
  2020</font>
    </a>
  </h2>
  <font color="black">さらに、ResNeSt、FPN、DCNv2を統合する優れたエンジンと、マルチスケールトレーニングやテスト時間の拡張などのさまざまな効果的なトリックを適用して、セグメンテーションのパフォーマンスを向上させます。最高のパフォーマンスは、4つのモデル（3つのPointRend-ベースモデルとSOLOv2）は、IJCAI-PRICAI 3D AIチャレンジ2020：インスタンスセグメンテーションで2位を獲得しました。MS-COCOと比較して、競争のデータセットには、面積が96x96ピクセルを超える大きなオブジェクトの割合が高くなっています。 
[ABSTRACT] mask r --cnn with pointrentは、高品質のオブジェクト境界を生成するための基本セグメンテーションフレームワークです。私たちの最良の範囲は、ijcaiで2位を獲得した4つのモデルのアンサンブルです-pricai 3daiチャレンジ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Progressive Skeletonization: Trimming more fat from a network at
  initialization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_49.html">
      <font color="black">Progressive Skeletonization: Trimming more fat from a network at
  initialization</font>
    </a>
  </h2>
  <font color="black">大規模な一連の実験の経験的分析によると、私たちのアプローチは、中程度の剪定レベルで他の最近のアプローチと少なくとも同等のパフォーマンスを提供しながら、より高い剪定レベルで著しく改善されたパフォーマンスを提供します（維持しながら最大$ 99.5 \％$パラメーターを削除できます）この目的のために、プルーニングされたネットワークの接続感度の観点からのトレーニング可能性が考慮される、最大の{\ em foresight接続感度}（FORCE）を持つスケルトン化されたネットワークを見つける目的を提案します。 。コードはhttps://github.com/naver/forceにあります。 
[概要]これは一定レベルのスパース性を超えていることがわかりましたが、これらのアプローチではネットワークパフォーマンスを維持できません。驚いたことに、多くの場合、些細なランダムプルーニングよりもパフォーマンスが低下します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-16">
        <br><font color="black">2020-06-16</font>
      </time>
    </span>
</section>
<!-- paper0: ResNet-like Architecture with Low Hardware Requirements -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_50.html">
      <font color="black">ResNet-like Architecture with Low Hardware Requirements</font>
    </a>
  </h2>
  <font color="black">この論文では、層を双極形態学的構造に変換することにより、はるかに複雑なResNetアーキテクチャから得られた双極形態学的ResNet（BM-ResNet）モデルを紹介します。現代の認識システムで最も計算量の多い部分の1つは、深層の推論です。画像の分類、セグメンテーション、エンハンスメント、認識に使用されるニューラルネットワーク。また、結果のモデルの計算の複雑さを推定します。 
[概要]エッジコンピューティングの人気の高まりにより、モバイルデバイスや組み込みデバイスの時間を短縮する方法を模索しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Underwater Image Color Correction by Complementary Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_51.html">
      <font color="black">Underwater Image Color Correction by Complementary Adaptation</font>
    </a>
  </h2>
  <font color="black">本論文では、CIELAB色空間におけるTikhonov型最適化モデルに基づく水中画像色補正の新しいアプローチを提案します。強調の大きさは色相選択的で画像ベースであるため、私たちの方法はさまざまな水中に対してロバストです。イメージング環境..さまざまな数値実験により、提案されたモデルを分析および検証します。 
[要約]精神物理学における代替適応理論の新しい解釈は、cielabの新しい方法を示唆しています。cielabの均一性を改善するために、正確な色相-前処理としての線形化とヘルムホルツのイーグル変換-コールラウシュ効果を後処理</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: HalluciNet-ing Spatiotemporal Representations Using a 2D-CNN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_52.html">
      <font color="black">HalluciNet-ing Spatiotemporal Representations Using a 2D-CNN</font>
    </a>
  </h2>
  <font color="black">実用的な観点から、実際の3D-CNNなしで時空間表現を幻覚化できると、計算能力が制限されている、帯域幅が狭いなど、リソースに制約のあるシナリオでの展開が可能になります。3D畳み込みニューラルネットワーク（CNN）を使用して学習した時空間表現現在、アクション関連タスクの最先端のアプローチで使用されています。徹底的な実験的評価は、幻覚タスクが実際にアクション認識、アクション品質評価、および動的シーン認識タスクのパフォーマンスの向上に役立つことを示しています。 
[ABSTRACT]幻覚タスクは、アクション認識、アート品質評価、および動的シーン認識タスクのパフォーマンスを向上させるのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-10">
        <br><font color="black">2019-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning-based Single Image Face Depth Data Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_53.html">
      <font color="black">Deep Learning-based Single Image Face Depth Data Enhancement</font>
    </a>
  </h2>
  <font color="black">合成画像、KinectFaceDB画像、および追加のカスタムRealSense D435画像の定性的な例を示します。定量的評価は、合成データ、およびKinectFaceDBからのKinect v1画像で実行されます。テストされたすべてのエンハンサータイプは、入力として深度データのみを使用します。これは、可視光カラー画像などの追加の入力データに基づいて深度を拡張する方法とは異なります。 
[ABSTRACT]合成顔深度画像は、深層学習エンハンサーをトレーニングするために使用されます。これには、生体認証セキュリティに関連する、閉塞された顔深度入力の改ざんの評価が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-19">
        <br><font color="black">2020-06-19</font>
      </time>
    </span>
</section>
<!-- paper0: Adaptive Structured Sparse Network for Efficient CNNs with Feature
  Regularization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_54.html">
      <font color="black">Adaptive Structured Sparse Network for Efficient CNNs with Feature
  Regularization</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、各ピクセルのチャネル次元に沿ってプルーニングすることにより、中間フィーチャのスパース性レベルを60％から95％以上改善できるため、計算とメモリの負担が軽減されます。それらの多くは、さまざまな入力に対する柔軟性に欠けています。ニューラルネットワークは優れています。 
[ABSTRACT]超解像、スタイル転送、画像ノイズ除去などのピクセル間画像処理タスクの進歩..新しい方法では、超解像タスクの95％以上を生成できます。超解像の場合、方法を80％以上削減できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: High-Capacity Complex Convolutional Neural Networks For I/Q Modulation
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_55.html">
      <font color="black">High-Capacity Complex Convolutional Neural Networks For I/Q Modulation
  Classification</font>
    </a>
  </h2>
  <font color="black">この作業では、ベンチマーク分類問題であるRadioML 2016.10aデータセットで92.4％のピーク分類精度で、残差および/または密な接続を含む大容量アーキテクチャが複素数値の畳み込みを計算できるようにすることで、最先端のパフォーマンスを主張します。 。I/ Q変調分類の複雑な畳み込みを持つすべてのネットワークで統計的に有意な改善を示します。以前の作業では、これらのサンプルを複雑な値の信号として扱い、深い学習フレームワーク内で複雑な値の畳み込みを計算すると、同等の浅いCNNアーキテクチャよりもパフォーマンスが大幅に向上することが示されています。 。 
[概要]複雑なデータデータを使用するすべてのネットワークで改善が見られます。データは周波数認識の改善を示しています。データは大きな改善であることがわかりました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: In-the-wild Drowsiness Detection from Facial Expressions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_56.html">
      <font color="black">In-the-wild Drowsiness Detection from Facial Expressions</font>
    </a>
  </h2>
  <font color="black">私たちの最高のパフォーマンスモデルは、ベースラインモデルの0.72と比較して0.78のマクロROC-AUCを達成します。人間が収集したビデオを4つのレベルの眠気にラベル付けできるようにする眠気アノテーションガイドラインを開発します：「アラート」、「やや眠気」 、「中程度の眠気」および「非常に眠気」..ただし、大量の現実的な眠気データの収集および進化する眠気の複雑な時間的ダイナミクスのモデル化に関連する困難さのため、現実世界のシナリオでうまく機能する眠気検出システムの開発は困難です。状態。 
[概要]眠気は、命を救う影響を与える可能性のある眠気システムの結果です。眠気状態は、ドライバーの顔の視覚的表現に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Sample Dropout for Accelerated Training and Better Generalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_57.html">
      <font color="black">Multi-Sample Dropout for Accelerated Training and Better Generalization</font>
    </a>
  </h2>
  <font color="black">重複した操作による追加の計算コストは、深い畳み込みネットワークでは重要ではありません。これは、計算時間のほとんどが、重複していないドロップアウト層の前の畳み込み層で消費されるためです。ImageNet、CIFAR-などの画像分類タスクを使用した実験結果10、およびCIFAR-100は、マルチサンプルドロップアウトがトレーニングを加速することを示しました。損失はサンプルごとに計算され、サンプル損失が平均化されて最終損失が得られます。 
[概要]この手法はニューラルネットワークで簡単に実装できます。これには、ドロップアウトレイヤーの後にネットワークの一部を削除することも含まれます。これは、ファイナルで重みを共有することでも簡単に使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-23">
        <br><font color="black">2019-05-23</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Meta Point Signature: Learning to Learn 3D Point Signature for 3D
  Dense Shape Correspondence -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_58.html">
      <font color="black">3D Meta Point Signature: Learning to Learn 3D Point Signature for 3D
  Dense Shape Correspondence</font>
    </a>
  </h2>
  <font color="black">テスト中に、すべてのタスクの分散で学習されたメタラーナーは、ベースラーナーのパラメーターを適応的に変更して、目に見えないローカルネイバーフッドに適応できます。実験結果は、私たちの方法がベースラインモデルよりも大幅に改善され、達成されるだけではないことを示しています。最先端の結果だけでなく、目に見えない3D形状を処理することもできます。高密度の3D形状の対応について、2つのデータセット（FAUSTとTOSCAなど）でMEPSモデルを評価します。 
[ABSTRACT]ポイント署名モデルは3dmetapointsignature（meps）ネットワークと呼ばれます。3D形状の堅牢なポイント署名を学習できます。モデルは、最先端の対応のために、faustとtoscaなどの2つのデータセットに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Universally Quantized Neural Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_59.html">
      <font color="black">Universally Quantized Neural Compression</font>
    </a>
  </h2>
  <font color="black">これにより、完全に微分可能な損失関数を維持しながら、トレーニングフェーズとテストフェーズの不一致を排除できます。不可逆圧縮用のエンコーダを学習するための一般的なアプローチは、トレーニング中に加法的な均一ノイズをテスト時間量子化の微分可能な近似として使用することです。均一なノイズチャネルは、ユニバーサル量子化を使用してテスト時にも実装できることを示しています（Ziv、1985）。 
[ABSTRACT]均一なノイズチャネルは、ユニバーサル量子化を使用してテスト時に実装することもできます（ziv、1985）。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br><font color="black">2020-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: What is Wrong with Continual Learning in Medical Image Segmentation? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_60.html">
      <font color="black">What is Wrong with Continual Learning in Medical Image Segmentation?</font>
    </a>
  </h2>
  <font color="black">しかし、ほとんどの場合、次の欠陥の少なくとも1つがあります。a）推論中にドメインID情報に過度に依存している、またはb）トレーニングの初期段階で見られるデータは、後のデータでトレーニングしてもメリットがない。継続的に学習するための多くの手法が存在する分類タスク用であり、いくつかはセマンティックセグメンテーションに適合しています。医療データに関連する固有のプライバシーリスクを考えると、この設定は、深層学習診断放射線システムの展開の現実を反映しています。 
[要約]継続的なセットアップでは、さまざまなソースからのデータが継続的に到着します。各タスクは限られた期間のみ利用可能です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Boosting Gradient for White-Box Adversarial Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_61.html">
      <font color="black">Boosting Gradient for White-Box Adversarial Attacks</font>
    </a>
  </h2>
  <font color="black">対照的に、この論文では、広く使用されているReLU活性化関数の特性に焦点を当て、バックプロパゲーション中のReLUの勾配の計算を誤解させる2つの現象（つまり、誤ったブロッキングと過剰伝送）が存在することを発見します。ホワイトボックス攻撃アルゴリズムは強力な敵対的例を生成できます。したがって、勾配ベースのホワイトボックス攻撃アルゴリズムのパフォーマンスを向上させるために、ADV-ReLUと呼ばれる普遍的な敵対的例生成方法を提案します。 
[概要]一部の研究では、dnnsに敵対的な例があることが示されています。これらは、敵対的なパフォーマンスを改善する方法に基づいています。ただし、勾配を最大限に活用する方法を模索している研究もあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Mutual-Supervised Feature Modulation Network for Occluded Pedestrian
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_62.html">
      <font color="black">Mutual-Supervised Feature Modulation Network for Occluded Pedestrian
  Detection</font>
    </a>
  </h2>
  <font color="black">上記の問題に対処するために、本論文では、閉塞した歩行者の検出をより適切に処理するための新しい相互教師あり特徴変調（MSFM）ネットワークを提案します。これらの2つのブランチは、それぞれ全身アノテーションと可視ボディアノテーションを使用して、相互に監視された方法でトレーニングされます。 
[概要]これらの2つのブランチは、追加の可視ボディアノテーションを使用して個別にトレーニングされます。また、相互に監視された方法でトレーニングされ、潜在的な機能をテストします。システムは、全身ボックスと可視ボディボックスの類似性損失を計算します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: MonoComb: A Sparse-to-Dense Combination Approach for Monocular Scene
  Flow -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_63.html">
      <font color="black">MonoComb: A Sparse-to-Dense Combination Approach for Monocular Scene
  Flow</font>
    </a>
  </h2>
  <font color="black">このように、既存の単眼法は動的な前景領域で優れており、挑戦的なKITTI 2015シーンフローベンチマークで競合他社の中で2番目に良い結果につながります。MonoCombはオプティカルフローを使用して、再構築された3D位置を時間の経過とともに関連付け、遮蔽された領域を補間します。単一のセンサー。 
[概要]これらのセンサーを使用すると、他のどのシステムよりも複雑になります。たとえば、単一のセンサーを使用したワイヤレスの使用が含まれます。monocombは、オプティカルフローを使用して、再構築された3D位置を経時的に関連付けます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: A Short Note on the Kinetics-700-2020 Human Action Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_64.html">
      <font color="black">A Short Note on the Kinetics-700-2020 Human Action Dataset</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、データセットのこの新しいリリースで導入された変更について詳しく説明し、包括的な統計セットとI3Dネットワークを使用したベースライン結果を示します。Kineticsを補充および拡張するDeepMindKineticsヒューマンアクションデータセットの2020年版について説明します。 -700データセット..この新しいバージョンでは、700のクラスごとに異なるYouTubeビデオから少なくとも700のビデオクリップがあります。 
[概要] YouTubeの新版には、700のクラスごとにビデオクリップがあります。これには、クラスのさまざまなビデオのビデオクリップが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Curves for Analysis of Deep Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_65.html">
      <font color="black">Learning Curves for Analysis of Deep Networks</font>
    </a>
  </h2>
  <font color="black">学習曲線を使用して、事前トレーニング、アーキテクチャ、データ拡張などの設計選択の影響を分析する方法を調査します。学習曲線をロバストに推定し、それらのパラメーターをエラーとデータ依存性に抽象化し、評価する方法を提案します。さまざまなパラメーター化の有効性..学習曲線は、トレーニングサンプルの数の関数として分類器のテストエラーをモデル化します。 
[概要]学習曲線をロバストに推定する方法を提案します。学習曲線は、テストおよびテストのツールとして使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: JGAN: A Joint Formulation of GAN for Synthesizing Images and Labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CV/paper_66.html">
      <font color="black">JGAN: A Joint Formulation of GAN for Synthesizing Images and Labels</font>
    </a>
  </h2>
  <font color="black">2つ目は、元の画像データと相関関係のあるあらゆる種類の弱いラベルまたは画像特徴を使用して、無条件の画像生成を強化できることです。1つ目の利点は、適切にモデル化されている場合、ジョイントの定式化がラベルノイズに対してより堅牢になることです。この共同定式化には、条件付きアプローチに比べて2つの利点があります。 
[概要]最新のガンフレームワークでは、ジェネレーターとディスクリミネーターの両方が、ラベルで指定された画像の条件付き分布をモデル化するように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-28">
        <br><font color="black">2019-05-28</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: FastEmit: Low-latency Streaming ASR with Sequence-level Emission
  Regularization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_0.html">
      <font color="black">FastEmit: Low-latency Streaming ASR with Sequence-level Emission
  Regularization</font>
    </a>
  </h2>
  <font color="black">FastEmitは、RNN-Transducer、Transformer-Transducer、ConvNet-Transducer、Conformer-TransducerなどのさまざまなエンドツーエンドストリーミングASRネットワークに適用することにより、ストリーミングASRのトランスデューサーモデルのシーケンスレベルの最適化により適していることを示します。音声検索テストセットの以前の手法よりも大幅に高い精度で150〜300ミリ秒の遅延削減を達成します。この作業では、シーケンスごとの確率に直接遅延正規化を適用するFastEmitという名前のシーケンスレベルの放射正規化方法を提案します。トランスデューサーモデルのトレーニングで、調整は必要ありません。 
[ABSTRACT] fastemitは、librispeechで90パーセンタイルのレイテンシーを30ミリ秒に短縮します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Emformer: Efficient Memory Transformer Based Acoustic Model For Low
  Latency Streaming Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_1.html">
      <font color="black">Emformer: Efficient Memory Transformer Based Acoustic Model For Low
  Latency Streaming Speech Recognition</font>
    </a>
  </h2>
  <font color="black">強力なベースライン拡張メモリトランスフォーマー（AM-TRF）と比較すると、Emformerは、トレーニングのスピードアップが4.6ドル倍になり、デコードで相対リアルタイム係数（RTF）が18ドル％減少し、テストクリーンとWERの相対的なWERが17ドル減少します。テストで$ 9 \％$-その他..ベンチマークLibriSpeechデータで実験を実行します。同じレイテンシとモデルサイズのLSTMベースラインと比較すると、Emformerはテストで相対的なWER削減$ 9 \％$と$ 16 \％$を取得します-それぞれ、cleanとtest-other。 
[概要]平均レイテンシが80ミリ秒の低レイテンシシナリオの場合、emformerは$ 2. 50-クリーン、テストで$ 5. 62 /％$-その他。同じレイテンシシナリオで、emformerはwer $ 3.01を達成します。 7.999ドルとテストで$-その他</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Quasi Error-free Text Classification and Authorship Recognition in a
  large Corpus of English Literature based on a Novel Feature Set -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_2.html">
      <font color="black">Quasi Error-free Text Classification and Authorship Recognition in a
  large Corpus of English Literature based on a Novel Feature Set</font>
    </a>
  </h2>
  <font color="black">特定のテキストカテゴリまたは著者の認知的および感情的な処理を共同決定する特徴についての定量的予測を生成する短い詩と長い小説の両方に適用可能なシンプルなツールを提供することにより、私たちのデータは、文学または実験の多くの将来の計算および経験的研究への道を開きます私たちの結果は、これらのタスクの最も診断的なものとして、2つの標準機能と2つの新しい機能（つまり、タイプトークン比、頻度、ソノリティスコア、驚き）を特定しています。GutenbergLiteraryEnglish Corpus（GLEC）は、デジタルヒューマニティ、計算言語学、または神経認知詩学の研究のためのテキストデータ。 
[概要]グーテンベルク英語詩コーパスがテキスト分析に提出されました。結果は、2つの標準機能と2つの新規機能を識別します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: DuoRAT: Towards Simpler Text-to-SQL Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_3.html">
      <font color="black">DuoRAT: Towards Simpler Text-to-SQL Models</font>
    </a>
  </h2>
  <font color="black">DuoRATをベースラインモデルとして使用して、いくつかのアブレーション実験を実行します。この傾向に反して、このペーパーでは、テキストからSQLへのモデルを簡略化できる側面を特定します。実験により、いくつかの手法とポイントの有用性が確認されます。構造SQL機能や、質問をスキーマにリンクする機能など、他の冗長性を排除します。 
[概要]研究者はますます洗練されたモデルを提案してきました。彼らは現在、主にスパイダーデータセットに取り組んでいます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: ProphetNet: Predicting Future N-gram for Sequence-to-Sequence
  Pre-training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_4.html">
      <font color="black">ProphetNet: Predicting Future N-gram for Sequence-to-Sequence
  Pre-training</font>
    </a>
  </h2>
  <font color="black">ProphetNetは、従来のシーケンス間モデルで1ステップ先の予測を最適化する代わりに、各タイムステップで前のコンテキストトークンに基づいて次のn個のトークンを同時に予測するnステップ先の予測によって最適化されます。 ProphetNetは、同じスケールの事前トレーニングコーパスを使用するモデルと比較して、これらすべてのデータセットで新しい最先端の結果を達成します。次に、抽象的な要約と質問のために、CNN / DailyMail、Gigaword、およびSQuAD1.1ベンチマークで実験を行います。生成タスク。 
[要約]預言者はnによって最適化されます-各タイムステップで前のコンテキストトークンに基づいて次のn個のトークンを同時に予測するステップアヘッド予測</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br><font color="black">2020-01-13</font>
      </time>
    </span>
</section>
<!-- paper0: TMT: A Transformer-based Modal Translator for Improving Multimodal
  Sequence Representations in Audio Visual Scene-aware Dialog -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_5.html">
      <font color="black">TMT: A Transformer-based Modal Translator for Improving Multimodal
  Sequence Representations in Audio Visual Scene-aware Dialog</font>
    </a>
  </h2>
  <font color="black">マルチモーダルトランスフォーマーネットワーク（MTN）に基づいて、TMTをビデオとダイアログに適用し、ビデオに基づいたダイアログシステム用のMTN-TMTを提案します。ただし、モダリティのより良い表現を学習するにはいくつかの制限があります。MTN、MTN-と比較してTMTはすべてのメトリックを改善し、特にCIDErで最大14.1％の相対的な改善を達成します。 
[概要]トランスフォーマーベースのモーダルトランスレーター（tmt）は、ソースモーダルシーケンスの表現を学習できます。ビデオに基づいて、tmtは、ビデオタスクとテキストタスクおよびテキストタスクの両方で、mtnおよびその他の送信モデルよりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: RECONSIDER: Re-Ranking using Span-Focused Cross-Attention for Open
  Domain Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_6.html">
      <font color="black">RECONSIDER: Re-Ranking using Span-Focused Cross-Attention for Open
  Domain Question Answering</font>
    </a>
  </h2>
  <font color="black">スパン抽出タスク用のシンプルで効果的な再ランク付けアプローチ（RECONSIDER）を開発します。これにより、事前にトレーニングされた大規模なMRCモデルのパフォーマンスが向上します。その結果、RECONSIDERは、近接した誤検知のパッセージを排除することを学習し、新しい4つのQAタスクに関する最新技術。これには、実際のユーザーの質問との自然な質問での45.5％の完全一致精度、およびTriviaQAでの61.7％が含まれます。 -より小さな候補セットに対してスパンに焦点を合わせた再ランク付けを実行するためのパッセージスパンアノテーション。 
[ABSTRACT] reconsiderは、mrcモデルの信頼性の高い予測から抽出された正と負の例についてトレーニングされています。-パッセージ注釈を使用して、スパンを実行します-焦点を絞った再-より小さな候補セットに対してランク付けします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Bootleg: Chasing the Tail with Self-Supervised Named Entity
  Disambiguation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_7.html">
      <font color="black">Bootleg: Chasing the Tail with Self-Supervised Named Entity
  Disambiguation</font>
    </a>
  </h2>
  <font color="black">シンプルなTransformerアーキテクチャで推論パターンをエンコードすることで、Bootlegは3つのNEDベンチマークで最先端技術を満たしているか上回っています。明確化のためのコア推論パターンを定義し、自己監視モデルがパターンを学習するように促す学習手順を作成します。 、および弱い監視を使用してトレーニングデータの信号を強化する方法を示します。さらに、Bootlegから学習した表現が、エンティティベースの知識を必要とする他の明確化されていないタスクに正常に転送されることを示します。新しい状態を設定します。最先端の人気のあるTACRED関係抽出タスクで1.0F1ポイント、主要なテクノロジー企業で高度に最適化されたプロダクション検索およびアシスタントタスクで最大8％のパフォーマンス向上を実証
[要約]明確化のためのコア推論パターンを定義します。学習手順を作成します。自己曖昧化モデルがパターンを学習することを奨励し、弱い監視を使用してトレーニングデータの信号を強化する方法を示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-20">
        <br><font color="black">2020-10-20</font>
      </time>
    </span>
</section>
<!-- paper0: The Adapter-Bot: All-In-One Controllable Conversational Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_8.html">
      <font color="black">The Adapter-Bot: All-In-One Controllable Conversational Model</font>
    </a>
  </h2>
  <font color="black">スキルに応じて、モデルはテキスト、表、グラフなどの複数の知識タイプをシームレスに処理できます。既存の最先端の会話と比較することにより、自動評価を使用してモデルを評価します。モデル、およびadapter.bot.ust.hkでインタラクティブシステムをリリースしました。天気情報、映画の推奨など。
[概要]これらのモデルは、生成された応答をほとんどまたはまったく制御できません。これらのモデルには、2つの重要な機能がありません。対話スキルの統合</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-28">
        <br><font color="black">2020-08-28</font>
      </time>
    </span>
</section>
<!-- paper0: Layer-Wise Cross-View Decoding for Sequence-to-Sequence Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_9.html">
      <font color="black">Layer-Wise Cross-View Decoding for Sequence-to-Sequence Learning</font>
    </a>
  </h2>
  <font color="black">体系的な実験により、階層バイパスの問題にうまく対処し、さまざまなタスクを詳細に表現することでシーケンス間の学習のパフォーマンスを大幅に向上させることが示されています。それでも、デコーダーはソースシーケンスの単一のビューしか取得しないため、階層バイパスの問題が原因で、エンコーダ層スタックのトレーニングが不十分です。シーケンス間の学習では、デコーダーはアテンションメカニズムに依存してエンコーダーから情報を効率的に抽出します。 
[ABSTRACT]デコードには、異なるエンコーダレイヤーからの表現の使用が含まれます。これらには、最後のエンコーダレイヤーからのデコードが含まれます。他のエンコーダレイヤーは、ソースシーケンスの立体視ビューを提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-16">
        <br><font color="black">2020-05-16</font>
      </time>
    </span>
</section>
<!-- paper0: Beyond English-Centric Multilingual Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_10.html">
      <font color="black">Beyond English-Centric Multilingual Machine Translation</font>
    </a>
  </h2>
  <font color="black">英語中心以外のモデルに焦点を当てることで、英語以外の方向を直接翻訳しながら、WMTの最高の単一システムと競争力を発揮しながら、10 BLEU以上の利益をもたらします。この作業では、真の多対多多言語を作成します。 100言語の任意のペア間で直接翻訳できる翻訳モデル。次に、高密度スケーリングと言語固有のスパースパラメータを組み合わせてモデルの容量を効果的に増やし、高品質のモデルを作成する方法を探ります。 
[要約]この作業では、100言語の真の多くのカバーを作成します。他の人がデータ、評価、および最終的なm2m-100モデルを再現できるように、スクリプトをオープンソース化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Deciphering Undersegmented Ancient Scripts Using Phonetic Prior -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_11.html">
      <font color="black">Deciphering Undersegmented Ancient Scripts Using Phonetic Prior</font>
    </a>
  </h2>
  <font color="black">さらに、ゴシック語とウガリット語の関連言語を正しく識別する言語の近さの尺度を提案します。解読された言語（ゴシック語、ウガリット語）と解読されていない言語（イベリア語）の両方でモデルを評価します。明確で一貫した利益に。 
[要約]結果は、組み込みの課題が明確で一貫した利益につながったことを示しています。イベリア語の場合、この方法は、関連言語としてバスク語をサポートする強力な証拠を示していません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Open-Domain Frame Semantic Parsing Using Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_12.html">
      <font color="black">Open-Domain Frame Semantic Parsing Using Transformers</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、トランスベースのモデルを使用したすべてのサブタスクのマルチタスク学習について説明します。フレームセマンティック解析は、複数の基礎となるサブタスクを含む複雑な問題です。純粋に生成的なエンコーダ-デコーダアーキテクチャが、以前の状態を簡単に上回っていることを示します。 FrameNet 1.7解析の技術であり、混合デコードマルチタスクアプローチはさらに優れたパフォーマンスを実現します。 
[概要]マルチタスクには、サブタスクの学習と関連タスクのマルチタスク学習が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: BERT for Joint Multichannel Speech Dereverberation with Spatial-aware
  Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_13.html">
      <font color="black">BERT for Joint Multichannel Speech Dereverberation with Spatial-aware
  Tasks</font>
    </a>
  </h2>
  <font color="black">提案された方法は、トランスフォーマー（BERT）からの双方向エンコーダー表現の優れたシーケンスモデリング機能に触発されています。マルチチャネルスペクトルの大きさとスペクトル位相情報の両方がエンコードされます。2つの空間認識を備えた共同マルチチャネル音声残響除去の方法を提案します。マルチチャネルタスク：到着方向（DOA）の推定と音声の分離。 
[ABSTRACT]提案された方法は、シーケンスからシーケンスへのマッピング問題としてタスクに対処します。これは、さまざまなフロントエンド音声処理タスクに十分一般的です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Transliteration of Judeo-Arabic Texts into Arabic Script Using Recurrent
  Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_14.html">
      <font color="black">Transliteration of Judeo-Arabic Texts into Arabic Script Using Recurrent
  Neural Networks</font>
    </a>
  </h2>
  <font color="black">また、ネットワークの収束を改善するために、損失関数が異なる事前トレーニング段階を利用します。トレーニングに使用できるパラレルテキストのソースは1つだけであるため、データを合成的に生成する可能性を利用します。学習へのコンテキストの寄与を測定する、エラーが2.5％に上昇するワードシャッフルデータもテストしました。 
[概要]リカレントニューラルネットワーク（rnn）を使用し、接続主義の時間分類（ctc）損失と組み合わせます。また、ネットワーク入力を改善するために、損失関数が異なる事前トレーニングステージを使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-23">
        <br><font color="black">2020-04-23</font>
      </time>
    </span>
</section>
<!-- paper0: Sentence Boundary Augmentation For Neural Machine Translation Robustness -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_15.html">
      <font color="black">Sentence Boundary Augmentation For Neural Machine Translation Robustness</font>
    </a>
  </h2>
  <font color="black">詳細なエラー分析を通じて、文の境界セグメンテーションが品質に最大の影響を与えることを示し、セグメンテーションの堅牢性を向上させるための単純なデータ拡張戦略を開発します。具体的には、入力が入力される長い形式の音声翻訳システムのコンテキストでトランスクリプトは自動音声認識（ASR）から取得され、NMTモデルは、音素置換、文法構造、文の境界などのエラーを処理する必要があります。これらはすべて、NMTの堅牢性に課題をもたらします。ニューラル機械翻訳（NMT）モデルは、整形式のトレーニングおよび評価データが提供される翻訳タスクでのアートパフォーマンスですが、さまざまなタイプのエラーを含む入力に敏感なままです。 
[概要]理解システムと連携できる必要があります。音素置換、文法構造、文の境界などのエラーを処理する必要があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Knowledge Distillation for Improved Accuracy in Spoken Question
  Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_16.html">
      <font color="black">Knowledge Distillation for Improved Accuracy in Spoken Question
  Answering</font>
    </a>
  </h2>
  <font color="black">実験は、私たちのアプローチがSpoken-SQuADデータセットのいくつかの最先端の言語モデルよりも優れていることを示しています。具体的には、音声ドキュメントと書面の対応物から知識蒸留（KD）を実行するトレーニング戦略を考案します。自動転写と手動転写の間の不整合を減らすことにより、監督信号として言語モデルから知識を抽出し、学生の正確性を向上させるためのステップ。 
[ABSTRACT]自動音声認識（asr）は、qaシステムの開発において重要な役割を果たします。このシステムは、問題の理解を理解するために使用され、新しい蒸留フレームワークを提示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: PARENTing via Model-Agnostic Reinforcement Learning to Correct
  Pathological Behaviors in Data-to-Text Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_17.html">
      <font color="black">PARENTing via Model-Agnostic Reinforcement Learning to Correct
  Pathological Behaviors in Data-to-Text Generation</font>
    </a>
  </h2>
  <font color="black">広く使用されているWikiBIOおよびWebNLGベンチマークの評価は、最先端のモデルと比較したこのフレームワークの有効性を示しています。構造化データによって条件付けられた言語生成モデルでは、最尤法による古典的なトレーニングにより、ほとんどの場合、モデルが採用されます。データセットの相違（つまり、幻覚または脱落）、および推論時にそれらを自分の世代に誤って組み込むこと。この作業では、以前の強化学習ベースのアプローチに基づいて構築し、最近導入されたPARENTに依存するモデルに依存しないフレームワークを示します。メトリックは、幻覚と脱落の両方を減らすのに効率的です。 
[要約]この作業では、古典的な方法の省略の上に構築します。それらは、モデル-親メトリックに依存するag theoフレームワークが、幻覚と省略の両方を減らすのに効率的であることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: CharacterBERT: Reconciling ELMo and BERT for Word-Level Open-Vocabulary
  Representations From Characters -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_18.html">
      <font color="black">CharacterBERT: Reconciling ELMo and BERT for Word-Level Open-Vocabulary
  Representations From Characters</font>
    </a>
  </h2>
  <font color="black">この新しいモデルは、さまざまな医療ドメインタスクでのBERTのパフォーマンスを向上させると同時に、堅牢で単語レベルのオープンボキャブラリー表現を生成することを示します。さらに、ワードピーストークン化を採用すると、焦点が単語レベルからサブワードレベルにより、モデルは概念的に複雑になり、実際にはおそらく不便になります。このシステムは、文字の柔軟性と完全な単語の効率のバランスが取れていると考えられていますが、一般的なドメインの事前定義された単語の語彙を使用することはできません。特に特殊なドメイン（医療ドメインなど）のモデルを構築する場合は、常に適しています。 
[概要]バートと呼ばれる新しいモデルの新しいバージョンは、ワードピースモデルを使用して、ドメインを参照して単語全体を表します。ワードピースを使用する代わりに、新しいモデルを使用して、文字の柔軟性と効率のバランスをとることができます。完全な言葉</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-20">
        <br><font color="black">2020-10-20</font>
      </time>
    </span>
</section>
<!-- paper0: Analyzing the Source and Target Contributions to Predictions in Neural
  Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_19.html">
      <font color="black">Analyzing the Source and Target Contributions to Predictions in Neural
  Machine Translation</font>
    </a>
  </h2>
  <font color="black">その基礎となる「保存則」により、関連性の伝播が一意になります。他の方法とは異なり、トークンの重要性を反映する抽象的な量ではなく、各トークンの影響の割合を評価します。より多くのデータでトレーニングされたモデルは、ソース情報に依存する傾向があることがわかります。そして、より鋭いトークンの貢献をすること。トレーニングプロセスは非単調であり、性質の異なるいくつかの段階があります。さまざまなタイプのプレフィックスを条件とする場合、トレーニングの目的やトレーニングデータの量を変更する場合、およびトレーニングプロセス中に、これらの寄与の変化を分析します。 
[要約]それらのすべてが世代決定との関係を明示的に評価するわけではありません。また、トークンの重要性を反映する抽象的な量ではないと主張します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Using the Full-text Content of Academic Articles to Identify and
  Evaluate Algorithm Entities in the Domain of Natural Language Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_20.html">
      <font color="black">Using the Full-text Content of Academic Articles to Identify and
  Evaluate Algorithm Entities in the Domain of Natural Language Processing</font>
    </a>
  </h2>
  <font color="black">予備調査として、本論文では、学術論文に記載されているアルゴリズムの影響を分析し、その結果を将来の大規模アルゴリズムの自動抽出のためのトレーニングデータとして使用することができます。アルゴリズムは、そのアルゴリズムの影響を分析するための指標として使用されます。私たちの結果は、NLP論文で最も影響力のあるアルゴリズムを明らかにし、分類アルゴリズムが影響の大きいアルゴリズムの中で最大の割合を表すことを示しています。 
[ABSTRACT]さまざまな分野、特にコンピュータサイエンスの学術論文には、多数のアルゴリズムが含まれています。この目的のために、この記事では自然言語処理の分野を例として取り上げます。アルゴリズムの影響の進化は、研究タスクの変化を反映しています。とフィールドのトピック</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Explaining black-box text classifiers for disease-treatment information
  extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_21.html">
      <font color="black">Explaining black-box text classifiers for disease-treatment information
  extraction</font>
    </a>
  </h2>
  <font color="black">医学的概念とセマンティクスを説明プロセスに組み込んで、説明者はブラックボックス分類器の決定空間のさまざまな部分で入力と出力の間のセマンティック関係を見つけます。事後説明方法はブラックボックスAIの動作を近似できます。特徴値と結果の間の関係を抽出することによってモデルを作成します。ディープニューラルネットワークおよびその他の複雑な人工知能（AI）モデルは、多くの生物医学的自然言語処理タスクで高レベルの精度に達しました。 
[要約]実験結果は、私たちの精度が摂動および意思決定セットベースの説明子よりも優れていることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Language Representation in Multilingual BERT and its applications to
  improve Cross-lingual Generalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_22.html">
      <font color="black">Language Representation in Multilingual BERT and its applications to
  improve Cross-lingual Generalization</font>
    </a>
  </h2>
  <font color="black">多言語BERT（m-BERT）に埋め込まれたトークンには、言語情報と意味情報の両方が含まれます。さらに、観察に基づいてm-BERTの言語間能力を向上させるための計算上安価で効果的なアプローチを提案します。トークンの埋め込みを操作することで多言語BERTの出力言語を制御し、教師なしトークン翻訳を実現できます。 
[ABSTRACT]言語の代表は、言語のトークンの埋め込みを平均するだけで取得できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-20">
        <br><font color="black">2020-10-20</font>
      </time>
    </span>
</section>
<!-- paper0: Classifying Syntactic Errors in Learner Language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_23.html">
      <font color="black">Classifying Syntactic Errors in Learner Language</font>
    </a>
  </h2>
  <font color="black">既存のエラー分類方法とは異なり、私たちの方法は言語間で適用可能であり、学習者の英語と学習者のロシア語の構文エラーの詳細な図を作成することによって示します。学習者の言語の構文エラー、つまり修正によって変更されるエラーを分類する方法を示します。文の形態統語構造..さらに、主要な文法エラー修正（GEC）システムの出力を分析するための方法論の有用性を示します。 
[要約]構文システムは、確立されたユニバーサル依存関係の構文表現スキームに基づいて構築されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_24.html">
      <font color="black">Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News</font>
    </a>
  </h2>
  <font color="black">ニューラルフェイクニュースを防ぐために既存のアプローチが提案されていますが、それらは一般に、記事にタイトルや著者などのテキストとメタデータしかないという非常に限られた設定に制限されています。この論文では、より現実的で挑戦的なタスクを紹介します。画像やキャプションも含まれるマシン生成のニュースに対する防御..敵が悪用できる可能性のある弱点を特定するために、4つの異なるタイプの生成された記事で構成されるNeuralNewsデータデータを作成し、に基づいて一連の人間ユーザー調査実験を実施します。このデータセット。 
[概要]画像、動画、自然言語モデルの急速な進歩により、効果的な防衛機制の必要性が高まっています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Contextualized Attention-based Knowledge Transfer for Spoken
  Conversational Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_25.html">
      <font color="black">Contextualized Attention-based Knowledge Transfer for Spoken
  Conversational Question Answering</font>
    </a>
  </h2>
  <font color="black">音声CoQAデータセットで広範な実験を行い、このアプローチがこのタスクで優れたパフォーマンスを達成することを示します。また、教師モデルの推定確率から学生にASRロバストな知識を抽出するための音声従来の知識蒸留フレームワークを紹介します。 ..ただし、ASRシステムは、予期しないノイズの多い信号を文字起こしに導入し、SCQAのパフォーマンスを低下させます。 
[ABSTRACT] scqaは、従来のテキスト質問応答（qa）タスクとは異なります。音声信号処理、パッセージの理解、コンテキストの理解が含まれます。音声からcoqaのデータセットに対して広範な実験を行います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Deep Learning based Multiple Choices Question Answering:
  Start Learning from Basic Knowledge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_26.html">
      <font color="black">Unsupervised Deep Learning based Multiple Choices Question Answering:
  Start Learning from Basic Knowledge</font>
    </a>
  </h2>
  <font color="black">提案された方法は、RACEのベースラインアプローチよりも優れており、MC500のいくつかの教師あり学習アプローチと同等でさえあることが示されています。この論文では、ほとんど教師なしの多肢選択式質問応答（MCQA）の可能性を研究します。 、MCQAモデルのトレーニングをガイドします。 
[要約]提案された方法は、レースでのベースラインアプローチよりも優れており、mc500でのいくつかの教師あり学習アプローチと同等でさえあることが示されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: LemMED: Fast and Effective Neural Morphological Analysis with Short
  Context Windows -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_27.html">
      <font color="black">LemMED: Fast and Effective Neural Morphological Analysis with Short
  Context Windows</font>
    </a>
  </h2>
  <font color="black">モデルは原則として文レベルでグローバルコンテキストを説明できますが、私たちの実験では、各ターゲット単語の周りにコンテキストの単一の単語を使用する方が計算上実行可能であるだけでなく、より良い結果も得られることが示されています。さらに、LemMEDは依存しています。文字レベルの表現とローカルコンテキストのみに基づいて..私たちのアプローチでは、個別のレンマ化とタグ付けモデルをトレーニングする必要はなく、形態論的辞書や変換器などの追加のリソースやツールも必要ありません。 
[ABSTRACT] lemmedは拡張され、他の2つの注意ベースのモデルにちなんで名付けられています。文字レベルの表現とローカルコンテキストのみに依存しています。それがどの程度機能するかを調べるためのツールとして使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: LadaBERT: Lightweight Adaptation of BERT through Hybrid Model
  Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_28.html">
      <font color="black">LadaBERT: Lightweight Adaptation of BERT through Hybrid Model
  Compression</font>
    </a>
  </h2>
  <font color="black">この論文では、LadaBERT（ハイブリッドモデル圧縮によるBERTの軽量適応）という名前のハイブリッドソリューションを提案することでこの問題に対処します。これは、重みの剪定、行列因数分解、知識蒸留など、さまざまなモデル圧縮方法の利点を組み合わせたものです。LadaBERTは状態を実現します。 -さまざまな公開データセットでの最先端の精度と、トレーニングのオーバーヘッドを1桁削減できます。BERTは、大規模なコーパスによって事前トレーニングされた最先端の言語表現モデルであり、さまざまな自然言語で優れたパフォーマンスを実現します。タスクを理解する。 
[概要]オンラインサービスにbertを適用すると、メモリを大量に消費し、ユーザーの行動の待ち時間が不十分になります。知識蒸留のトレーニング手順は、教師モデルを模倣するのに十分なトレーニングデータが必要なため、費用がかかります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br><font color="black">2020-04-08</font>
      </time>
    </span>
</section>
<!-- paper0: Generalized Conditioned Dialogue Generation Based on Pre-trained
  Language Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_29.html">
      <font color="black">Generalized Conditioned Dialogue Generation Based on Pre-trained
  Language Model</font>
    </a>
  </h2>
  <font color="black">両方の場合の実験結果は、私たちのアプローチが最先端のベースラインよりも大幅に優れた応答を生成できることを示しています。したがって、ラベル付きのダイアログデータをラベル付きの非ダイアログテキストデータで補完し、BERTベースを微調整することを提案します。ターゲット（生成）側では、新しいアテンションルーティングメカニズムを使用して、各位置で一般的な単語または条件関連の単語を生成するかどうかを選択します。 
[要約]主要な課題は、条件でラベル付けされた実質的な対話データの欠如です。私たちのモデルは、主題関連の対話としてのステータスにインスタンス化されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Unit Transformer for Neural Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_30.html">
      <font color="black">Multi-Unit Transformer for Neural Machine Translation</font>
    </a>
  </h2>
  <font color="black">本稿では、多様で補完的なユニットを導入することでトランスの表現力を高めることを目的としたマルチユニットトランスフォーマー（MUTE）を提案します。3つの機械翻訳タスク、NIST中国語から英語、WMTの実験結果14英語からドイツ語およびWMT&#39;18中国語から英語は、MUTEモデルがTransformer-Baseを最大+ 1.52、+ 1.90、および+1.10 BLEUポイントだけ大幅に上回り、推論速度がわずかに低下することを示しています。 （約3.1％）。さらに、マルチユニット設定の利点をより有効に活用するために、異なるユニット間の補完性を導き、促進するバイアスモジュールと順次依存関係を設計します。 
[ABSTRACT] 3つの機械翻訳タスクの実験では、ミュートモデルがトランスフォーマー（ベース）を最大1.52、1.90、および1. 10ブルーポイントだけ大幅に上回っていますが、結論の速度はわずかに低下しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Semantic Role Labeling as Syntactic Dependency Parsing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_31.html">
      <font color="black">Semantic Role Labeling as Syntactic Dependency Parsing</font>
    </a>
  </h2>
  <font color="black">私たちの調査結果は、局所性の構文ドメイン内で意味役割関係をエンコードする際の構文依存ツリーの可能性を示し、将来、構文メソッドが意味役割ラベリングにさらに統合される可能性を示しています。この観察に基づいて、次のような変換スキームを提示します。 SRLアノテーションをジョイントラベルを介して依存関係ツリー表現にパックし、元の形式に非常に正確に復元できるようにします。（スパンベースの）PropBankスタイルのセマンティックロールラベリング（SRL）のタスクを構文上の依存関係解析に減らします。 
[概要]言語とソーシャルメディアへの依存を減らしようとしています。srlに取り組むために依存関係パーサーを減らす必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Is Retriever Merely an Approximator of Reader? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_32.html">
      <font color="black">Is Retriever Merely an Approximator of Reader?</font>
    </a>
  </h2>
  <font color="black">コミュニティで見過ごされがちな質問は、レトリーバーとリーダーの関係です。特に、レトリーバーの目的全体がリーダーの簡単な近似であるかどうかです。実験結果は、私たちの方法がドキュメントのリコール率を高めることができることを示しています。オープンドメインのQAタスクにおける既製のレトリーバーのエンドツーエンドのQA精度と同様に..次に、レトリーバーが独自の強度を維持しながらリーダーの強度を吸収するように、リーダーをレトリーバーに蒸留することを提案します。利益。 
[概要]かなり見過ごされている質問は、レトリーバーとリーダーの関係です。レトリーバーのアーキテクチャ上の制約により、大規模な検索でモデルがより堅牢になるように思われることを慎重に推測します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Grapheme or phoneme? An Analysis of Tacotron's Embedded Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_33.html">
      <font color="black">Grapheme or phoneme? An Analysis of Tacotron's Embedded Representations</font>
    </a>
  </h2>
  <font color="black">テキストの前処理をほとんどまたはまったく行わずに、高品質の合成音声を生成できます。さらに、Tacotronモデルによって学習された表現の分析を実行し、コンテキスト書記素の埋め込みが音素情報をエンコードし、それらを使用できることを示します。合成音声の書記素から音素への変換と音素制御..この作業では、適切にキュレートされたフランス語データセットの場合、発音エラーの量を増やすことなく、書記素を入力として使用できることを示します。 
[概要]テキストの前処理をほとんどまたはまったく行わずに、高品質の音声を生成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Online Conversation Disentanglement with Pointer Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_34.html">
      <font color="black">Online Conversation Disentanglement with Pointer Networks</font>
    </a>
  </h2>
  <font color="black">タイムスタンプ、話者、メッセージテキストで構成される発話全体を埋め込む新しい方法を設計し、発話間の相互作用をエンドツーエンドで効果的にキャプチャしながら、解きほぐしをポインティング問題としてモデル化するカスタムアテンションメカニズムを提案します。この作業では、時間のかかるドメイン固有の機能エンジニアリングを回避する、会話の解きほぐしのためのエンドツーエンドのオンラインフレームワークを提案します。会話の解きほぐしは、混ざり合ったメッセージを切り離された会話に分離することを目的としています。 
[ABSTRACT]解きほぐし方法は、データセット固有に基づいており、一般化と適応性を妨げます。解きほぐしをポインティング問題としてモデル化するカスタム注意メカニズムを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Networks for Entity Matching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_35.html">
      <font color="black">Neural Networks for Entity Matching</font>
    </a>
  </h2>
  <font color="black">具体的には、ニューラルネットワークを使用して既存の作業が対象としているエンティティマッチングプロセスのどのステップを特定し、各ステップで使用されるさまざまな手法の概要を示します。エンティティマッチングは、どのレコードが同じ実世界のエンティティを参照しているかを特定する問題です。 ..それは何十年にもわたって活発に研究されており、さまざまな異なるアプローチが開発されてきました。 
[概要]何十年にもわたって活発に研究されており、さまざまなアプローチが開発されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Towards End-to-End Training of Automatic Speech Recognition for Nigerian
  Pidgin -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_36.html">
      <font color="black">Towards End-to-End Training of Automatic Speech Recognition for Nigerian
  Pidgin</font>
    </a>
  </h2>
  <font color="black">最後に、この方向での将来の研究を促進するために、この出版物とともにデータとコードをオープンソース化します。また、この言語で最初のエンドツーエンドの音声認識システム（QuartzNetおよびJasperモデル）をトレーニングしました。 Connectionist Temporal Classification（CTC）損失を使用して最適化。ベースラインの結果により、データセットで貪欲なデコーダーを使用して、0.77％の低い単語誤り率（WER）を達成することができました。 
[概要]この言語は、イギリス、カナダ、アメリカのナイジェリア移民を通じて、ディアスポラのコミュニティに広まりました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Language as a Cognitive Tool to Imagine Goals in Curiosity-Driven
  Exploration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_37.html">
      <font color="black">Language as a Cognitive Tool to Imagine Goals in Curiosity-Driven
  Exploration</font>
    </a>
  </h2>
  <font color="black">この能力をモデル化する本質的に動機付けられた深層強化学習アーキテクチャであるIMAGINEを紹介します。この限定されたエージェントは、既知の効果の分布内で目標をサンプリングします。最近のアプローチでは、固定されて手動で定義された、または生成モデルを使用して学習された目標空間が考慮されています。州の。 
[要約]これらのエージェントは、目標を作成して表現し、追求する目標を選択し、それらを達成することを学ぶ必要があります。この限られたエージェントは、既知の効果の分布内で目標をサンプリングします。子供たちは、想像するツールとして言語の構成性を活用することによってそうします。彼らがこれまで経験したことのない結果のアイデア、プレー中の目標としてそれらをターゲットにする</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-21">
        <br><font color="black">2020-02-21</font>
      </time>
    </span>
</section>
<!-- paper0: PBoS: Probabilistic Bag-of-Subwords for Generalizing Word Embedding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_38.html">
      <font color="black">PBoS: Probabilistic Bag-of-Subwords for Generalizing Word Embedding</font>
    </a>
  </h2>
  <font color="black">単語の類似性とPOSタグ付けの実験は、言語間で生成された単語の埋め込みの品質において、以前のサブワードレベルのモデルに対するPBoSの明らかな利点を示しています。単語のスペルのみに依存し、効率的なアルゴリズムとともに、同時にモデル化するモデルを提案します。サブワードセグメンテーションとサブワードベースの構成的単語埋め込みの計算.. \ emph {generalizing}単語埋め込みのタスクを調べます。有限の語彙に対して事前にトレーニングされた単語ベクトルのセットが与えられた場合、目標は、アウトの埋め込みベクトルを予測することです。 of-語彙、\ emph {なし}追加のコンテキスト情報。 
[ABSTRACT] pbosは、詳細なしで意味のあるサブ埋め込みを生成できます。モデルを使用して、サブレベルのサブレジスタンスを作成できます。pbosは、単語の知識がなくてもモデルを埋め込むことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Complaint Identification in Social Media with Transformer Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_39.html">
      <font color="black">Complaint Identification in Social Media with Transformer Networks</font>
    </a>
  </h2>
  <font color="black">最先端の事前トレーニング済み神経言語モデルと、トピックまたは感情からの他の言語情報との組み合わせを苦情予測に適応させることは、まだ検討されていません。公開されている苦情のデータセットでの実験は、モデルが以前よりも優れていることを示しています。最大87のマクロF1を達成する大幅なマージンによる最先端の方法。この論文では、トランスネットワークによって支えられた一連の神経モデルを評価し、その後、言語情報と組み合わせます。 
[概要]以前の研究は、ソーシャルメディアを使用して苦情を特定することに焦点を当てていました。以前の研究は、ニューラルネットワークの使用に焦点を当てていました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Token Drop mechanism for Neural Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_40.html">
      <font color="black">Token Drop mechanism for Neural Machine Translation</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、より少ない情報でターゲット翻訳を生成するモデルを強制することを目的としています。これにより、モデルはテキスト表現をより適切に学習できます。数百万のパラメータを含むニューラル機械翻訳は、見慣れない入力に対して脆弱です。単語のドロップアウトと同様ですが、ドロップされたトークンを次のように置き換えます。単語にゼロを設定する代わりに、特別なトークン。 
[概要]一般化を改善し、過剰適合を回避するためにトークンドロップを提案します。さらに、2つの自己監視目的を導入します。置き換えられたトークン表現とドロップされたトークン予測です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Decouple Relations: Few-Shot Relation Classification with
  Entity-Guided Attention and Confusion-Aware Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_41.html">
      <font color="black">Learning to Decouple Relations: Few-Shot Relation Classification with
  Entity-Guided Attention and Confusion-Aware Training</font>
    </a>
  </h2>
  <font color="black">一方、文を真の関係に分類することとその紛らわしい関係との間のプッシュアウェイゲームをプレイすることによって関係を区別することを明示的に学習するための混乱認識トレーニング（CAT）方法が提案されています。さらに、アブレーションテストとケース研究は、特に関係の混乱の問題に対処する際に、提案されたEGAとCATの有効性を検証します。上記の関係の混乱の問題を軽減するために、これらの簡単に混乱する関係を分離することを学ぶ2つのメカニズムを備えたモデルであるCTEGを提案します。 
[ABSTRACT]エンティティ-ガイド付き注意メカニズムが導入され、混乱を引き起こす情報を除外するように注意をガイドします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: A Survey on Machine Reading Comprehension: Tasks, Evaluation Metrics and
  Benchmark Datasets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_42.html">
      <font color="black">A Survey on Machine Reading Comprehension: Tasks, Evaluation Metrics and
  Benchmark Datasets</font>
    </a>
  </h2>
  <font color="black">機械読解（MRC）は、幅広い実世界のアプリケーションを備えた挑戦的な自然言語処理（NLP）研究分野です。現在、既存のMRC間の明らかな巨大なギャップにもかかわらず、多くのMRCモデルがさまざまなベンチマークデータセットで人間のパフォーマンスをすでに上回っています。モデルと本物の人間レベルの読解..既存のMRCタスク、評価指標、およびデータセットの包括的な調査の現在の欠如に対処するために、ここでは、（1）57のMRCタスクとデータセットを分析し、MRCのより正確な分類方法を提案します。 4つの異なる属性を持つタスク。 （2）MRCタスクの9つの評価指標、7つの属性、およびMRCデータセットの10の特性を要約しました。 （3）また、MRC研究における主要な未解決の問題について議論し、将来の研究の方向性を強調します。 
[概要]これは、現在のmrcモデルを「実際の」理解に向けて動かすために、既存のデータセット、評価指標、モデルを改善する必要があることを示しています。mrcの研究は、主に大規模なデータセットとディープラーニングの出現によるものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-21">
        <br><font color="black">2020-06-21</font>
      </time>
    </span>
</section>
<!-- paper0: LT3 at SemEval-2020 Task 9: Cross-lingual Embeddings for Sentiment
  Analysis of Hinglish Social Media Text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_43.html">
      <font color="black">LT3 at SemEval-2020 Task 9: Cross-lingual Embeddings for Sentiment
  Analysis of Hinglish Social Media Text</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、コード混合ソーシャルメディアテキストの感情分析に関するSemEval-2020タスク9への貢献について説明します。結果は、2番目のアプローチが最も効果的であり、保持されたテストデータのF1スコアが70.52％であることを示しています。 。最初のアプローチでは、同じスペースにHinglishと事前にトレーニングされた英語のFastText単語の埋め込みを投影した結果として生じる言語間の埋め込みを使用します。 
[概要]ヒングリッシュ感情分析は、ヒングリッシュツイートの一形態です。ヒングリッシュツイートは、ヒングリッシュ分析プロジェクトの一部です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Domain Dialogue State Tracking based on State Graph -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_44.html">
      <font color="black">Multi-Domain Dialogue State Tracking based on State Graph</font>
    </a>
  </h2>
  <font color="black">リレーショナルGCNでエンコードされた状態グラフは、Transformerエンコーダーに融合されます。実験結果は、私たちのアプローチが効率を維持しながらタスクの新しい最先端を達成することを示しています。この論文では、対話状態を構築することを提案します。前のダイアログ状態のドメイン、スロット、および値が正しく接続されているグラフ。 
[概要]私たちのアプローチは、エンコーダーへの対話状態と対話履歴を組み合わせます。ただし、誤った接続に注意が払われ、誤った結論につながる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Multilingual Contextual Affective Analysis of LGBT People Portrayals in
  Wikipedia -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_45.html">
      <font color="black">Multilingual Contextual Affective Analysis of LGBT People Portrayals in
  Wikipedia</font>
    </a>
  </h2>
  <font color="black">実際には、このモデルを使用して、ウィキペディアの記事を表面化し、さらに手動で分析することができます---コンテンツのギャップや特定の社会集団の不均衡な表現が含まれている可能性のある記事。物語の文化の違いと社会的偏見の兆候..次に、英語、ロシア語、スペイン語の3つの言語にわたるLGBTコミュニティのメンバーのウィキペディアの伝記ページを分析することにより、この方法の有用性を示します。 
[概要]以前の作業では、英語での人々の説明を調べました。私たちの結果は、lgbtコミュニティが言語間でどのように表現されているかについて体系的な違いを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Stacking Neural Network Models for Automatic Short Answer Scoring -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_46.html">
      <font color="black">Stacking Neural Network Models for Automatic Short Answer Scoring</font>
    </a>
  </h2>
  <font color="black">データラベリングプロセスは、その分野の専門家である人間のアノテーターを必要とするため、簡単ではありません。この論文では、ニューラルネットワークとXGBoostに基づくスタッキングモデルを使用して、文埋め込み機能を使用した分類プロセスを提案します。 、正解のラベルの数は常に間違った答えよりもはるかに少ないため、データの不均衡プロセスも課題です。 
[要約]正解のラベルの数は常に間違った答えよりもはるかに少ないため、データの不均衡プロセスも課題です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring Sequence-to-Sequence Models for SPARQL Pattern Composition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_47.html">
      <font color="black">Exploring Sequence-to-Sequence Models for SPARQL Pattern Composition</font>
    </a>
  </h2>
  <font color="black">シーケンス間モデルは、長い発話を複雑なSPARQLクエリに変換するための実行可能で有望なオプションであることを示します。ただし、ユーザーは、複雑で、基本的なグラフパターンに分解するために、ある程度の抽象化と推論を必要とする質問を送信することがよくあります。 ..この短い論文では、パターン構成を学習するために、Neural SPARQLMachinesと呼ばれるNeuralMachineTranslationに基づくアーキテクチャの使用について説明します。 
[ABSTRACT]質問応答システムは、質問応答システムの目的です。一般ユーザーは、正式なクエリを記述せずに、自然言語を使用してデータにアクセスできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: TurnGPT: a Transformer-based Language Model for Predicting Turn-taking
  in Spoken Dialog -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_48.html">
      <font color="black">TurnGPT: a Transformer-based Language Model for Predicting Turn-taking
  in Spoken Dialog</font>
    </a>
  </h2>
  <font color="black">また、アブレーション研究、注意および勾配分析についても報告します。これは、モデルが対話コンテキストと実用的な完全性を利用してターンテイク予測を行うことができることを示しています。最後に、検出だけでなく、モデルの可能性を探ります。モデルは、さまざまな書き言葉と話し言葉のダイアログデータセットでトレーニングされ、評価されています。 
[概要]ターンを予測するためのトランスフォーマーベースの言語モデルであるturngptを紹介します-音声ダイアログのシフト。モデルが以前の作業で使用された2つのベースラインよりも優れていることを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: STN4DST: A Scalable Dialogue State Tracking based on Slot Tagging
  Navigation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_49.html">
      <font color="black">STN4DST: A Scalable Dialogue State Tracking based on Slot Tagging
  Navigation</font>
    </a>
  </h2>
  <font color="black">いくつかのベンチマークデータセットでの広範な実験は、提案されたモデルが最先端のベースラインよりも大幅に優れていることを示しています。ただし、候補生成ベースのDSTは、パイプライン化された2段階のプロセスのためにエラー伝播に悩まされることがよくあります。一方、スパン抽出ベースのDSTには、開始位置と終了位置のポインタ間に意味上の制約がないため、無効なスパンが生成されるリスクがあります。不明なスロット値を処理するスケーラビリティは、ダイアログ状態追跡（DST）の重要な問題です。 【要約】本論文では、スロットタグナビゲーションに基づく新しいスケーラブルな対話状態追跡法を提案する。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: NeuSpell: A Neural Spelling Correction Toolkit -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_50.html">
      <font color="black">NeuSpell: A Neural Spelling Correction Toolkit</font>
    </a>
  </h2>
  <font color="black">合成例をトレーニングすることで、ランダムにサンプリングされた文字の摂動でモデルをトレーニングした場合と比較して、修正率が9％（絶対）向上します。多くのシステムでは、スペルミストークンのコンテキストを適切に活用していないことがわかります。ツールキットneuspell.github.ioからアクセスできます。 
[概要]分離されたスペルミスをリバースエンジニアリングすることで合成的に構築された、コンテキスト内のスペルエラーを使用してニューラルモデルをトレーニングします。より豊富なコンテキスト表現を使用すると、修正率がさらに3％向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: ReSCo-CC: Unsupervised Identification of Key Disinformation Sentences -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_51.html">
      <font color="black">ReSCo-CC: Unsupervised Identification of Key Disinformation Sentences</font>
    </a>
  </h2>
  <font color="black">また、このタスクの評価を支援するために、文レベルの偽情報スコアを使用して新しいデータセットをキュレートします。データセットは、さらなる調査を容易にするために公開されています。これらの機能を使用して表された文は、クラスター化され、その後、近接スコアリングによって重要な文が識別されます。クレーム検出やクレーム検出などの関連タスクからの手法に対する包括的な経験的評価に基づいています。要約、および提案されたアプローチの単純化された変形に対して、私たちの方法がコアの偽情報を効果的に識別できることを示します。 
[概要]これらの記事には通常、信頼できる文が多数含まれています。これらには、タスク用に設計された特注の機能スペース内に文を埋め込むことが含まれます。データセットは、さらなる調査を容易にするために公開されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: KnowDis: Knowledge Enhanced Data Augmentation for Event Causality
  Detection via Distant Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_52.html">
      <font color="black">KnowDis: Knowledge Enhanced Data Augmentation for Event Causality
  Detection via Distant Supervision</font>
    </a>
  </h2>
  <font color="black">このデータ不足の問題を解決するために、Knowledge Enhanced Distant Data Augmentation（KnowDis）と呼ばれるECDのデータ拡張フレームワークを調査します。2つのベンチマークデータセットEventStoryLineコーパスとCausal-TimeBankの実験結果は、1）KnowDisが利用可能なトレーニングデータを拡張できることを示しています。遠隔監視によるECDの語彙的および因果的常識的知識の支援、および2）自動的にラベル付けされたトレーニングデータの支援により、私たちの方法は以前の方法よりも大幅に優れています。イベント因果関係検出（ECD）の最新モデルは、主に小さな手書きのコーパス。 
[概要]手作業でラベル付けされたトレーニングデータは、作成に費用がかかります。因果関係の表現の範囲が狭く、サイズが制限されています。これにより、監視ありメソッドがイベント間のリンクを検出するのが困難になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Controllable Text Simplification with Explicit Paraphrasing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_53.html">
      <font color="black">Controllable Text Simplification with Explicit Paraphrasing</font>
    </a>
  </h2>
  <font color="black">テキストの簡略化は、語彙の言い換え、削除、分割など、いくつかの書き換え変換を通じて文の読みやすさを向上させます。ただし、このようなシステムは、ほとんどの場合単語の削除に限定され、さまざまな対象読者の要件に簡単に適応できません。現在の簡略化システムは主に、これらすべての操作を同時に実行するようにエンドツーエンドでトレーニングされたシーケンス間モデル。 
[ABSTRACT]言い換えは、タスクの新しい最先端技術であり、既存のシステムよりも頻繁に言い換えることができ、テキストに適用される各簡略化操作の程度を制御できます。提案されたモデルは、分割と削除の言語ベースのルールを組み合わせたものです。それらを神経言い換えモデルと組み合わせて、さまざまな書き換えスタイルを作成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Cascaded Models With Cyclic Feedback For Direct Speech Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_54.html">
      <font color="black">Cascaded Models With Cyclic Feedback For Direct Speech Translation</font>
    </a>
  </h2>
  <font color="black">直接音声翻訳は、音声入力と対応する翻訳のみが利用できるシナリオを説明します。そのようなデータは悪名高いほど制限されています。自動音声認識（ASR）と機械翻訳（MT）のカスケードがドメイン内直接を活用できるようにする手法を紹介します。ドメイン外のMTおよびASRデータに加えて音声翻訳データ。 
[ABSTRACT]データはデータ上のデータからのデータでのみ利用可能です。データは言語とデータ上のデータに制限されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: A Graph Based and Patient Demographics Aware Dialogue System for Disease
  Diagnosis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_55.html">
      <font color="black">A Graph Based and Patient Demographics Aware Dialogue System for Disease
  Diagnosis</font>
    </a>
  </h2>
  <font color="black">具体的には、まず臨床対話に基づいて加重双向グラフを作成し、症状と疾患の関係を示し、次に対話管理のための双方向グラフベースのディープQネットワーク（BG-DQN）を提示します。さらに、BG-DQNは病気の診断プロセスを支援するための患者の人口統計学的属性..さらに重要なことに、私たちの方法は、より少ない対話ターンでタスクを完了でき、同様の症状を持つ病気をよりよく区別する能力を備えています。 
[概要]既存の疾患診断対話システムは、データ駆動型の方法と統計的特徴に依存しており、医学的知識の深い理解が不足しています。研究によると、提案された対話システムは、診断精度の点でいくつかの競合する方法よりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: FreeDOM: A Transferable Neural Architecture for Structured Information
  Extraction on Web Documents -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_56.html">
      <font color="black">FreeDOM: A Transferable Neural Architecture for Structured Information
  Extraction on Web Documents</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、FreeDOMという名前の新しい2段階のニューラルアプローチを紹介します。これは、これらの両方の制限を克服します。8つの異なる垂直市場を持つ公開データセットでの実験を通じて、FreeDOMが以前の最先端技術を3.7F1近く上回っていることを示します。レンダリングされたページ上の機能や高価な手作りの機能を必要とせずに、平均してポイントを獲得します。第2段階では、リレーショナルニューラルネットワークを使用して、より長い距離とセマンティックの関連性をキャプチャします。 
[ABSTRACT] freeは、そのカテゴリから少数のシードサイトでトレーニングした後、見えないサイトに一般化できます。最初のステージでは、テキストとマークアップ情報の両方を組み合わせて、各domノードの表現を学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: German's Next Language Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_57.html">
      <font color="black">German's Next Language Model</font>
    </a>
  </h2>
  <font color="black">トレーニング済みのモデルは、研究コミュニティに公開されます。既存のドイツのモデルと比較して、これらのモデルがこれまでで最高のドイツのモデルであることを示します。この作業では、BERTの作成につながる実験を紹介します。 ELECTRAベースのドイツ語モデル、GBERTおよびGELECTRA。 
[概要]ベースモデルとラージサイズの両方のモデルについて、一連のドキュメントトレーニングと固有表現抽出（ner）タスク全体でsotaパフォーマンスを達成することができました。既存のモデルに対するベンチマークを使用して、これらのモデルがドイツの最高のモデルであることを示します。日付</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Gender Prediction Based on Vietnamese Names with Machine Learning
  Techniques -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_58.html">
      <font color="black">Gender Prediction Based on Vietnamese Names with Machine Learning
  Techniques</font>
    </a>
  </h2>
  <font color="black">このデータセットは、調査目的で当社のWebサイトで入手できます。その結果、達成した最高のF1スコアはLSTMモデルで最大96 \％であり、トレーニング済みモデルに基づいてWebAPIを生成します。英語と中国語は途方もないです。それでも、ベトナム人のために行われた作業はこれまでほとんどありませんでした。 
[概要]このデータセットは、性別に基づいた26,000を超えるフルネームで構成されています。このデータセットは、インターネット上の26,000を超えるフルネームに基づいています。私たちが達成した最高のf1-スコアは、lstmモデルで最大96％です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: ProphetNet-Ads: A Looking Ahead Strategy for Generative Retrieval Models
  in Sponsored Search Engine -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_59.html">
      <font color="black">ProphetNet-Ads: A Looking Ahead Strategy for Generative Retrieval Models
  in Sponsored Search Engine</font>
    </a>
  </h2>
  <font color="black">ProphetNet-Adsは、Trie制約付き検索スペースを直接最適化することにより、検索能力を向上させます。最近提案されたTrieベースのLSTM生成検索モデルと比較して、単一モデルの結果と統合された結果により、リコールがそれぞれ15.58 \％と18.8 \％向上します。ビームサイズ5 ..実語でスポンサーされた検索エンジンからデータセットを構築し、さまざまな生成検索モデルを分析するための実験を実行します。 
[ABSTRACT]研究者は、実際の単語がスポンサーとなっている検索エンジンからデータセットを構築し、さまざまな検索エンジンを分析するための実験を実行します。これらは、ターゲットライブラリのルートに基づいており、生成されたすべての出力が合法であり、ターゲットによってカバーされていることを保証します。ライブラリ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Deep learning-based citation recommendation system for patents -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/cs.CL/paper_60.html">
      <font color="black">Deep learning-based citation recommendation system for patents</font>
    </a>
  </h2>
  <font color="black">さらに、テキスト情報とメタデータ（共同特許分類コードなど）の類似性を考慮した強力なベンチマークモデルを提案します。これらの問題を解決するために、Googleの約11万件の特許のテキスト情報とメタデータを含むPatentNetという新しいデータセットを提示します。 Big Queryサービス..ディープラーニングベースの推奨システムは、さまざまなドメイン（映画、製品、紙の引用など）で優れたパフォーマンスを示していますが、自由に利用できる高値がないため、特許引用での有効性は調査されていません。 -品質データセットと関連するベンチマークモデル。 
[要約]研究ベースのレコメンデーションシステムは卓越したパフォーマンスを示していますが、特許引用におけるそれらの有効性は調査されていません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: FastEmit: Low-latency Streaming ASR with Sequence-level Emission
  Regularization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_0.html">
      <font color="black">FastEmit: Low-latency Streaming ASR with Sequence-level Emission
  Regularization</font>
    </a>
  </h2>
  <font color="black">ストリーミング自動音声認識（ASR）は、仮定された各単語を可能な限り迅速かつ正確に出力することを目的としています。FastEmitは、さまざまなエンドツーエンドに適用することにより、ストリーミングASRのトランスデューサーモデルのシーケンスレベルの最適化により適していることを示します。 RNN-Transducer、Transformer-Transducer、ConvNet-Transducer、Conformer-TransducerなどのストリーミングASRネットワーク。この作業では、トレーニングのシーケンスごとの確率に直接レイテンシ正規化を適用する、FastEmitという名前のシーケンスレベルの放出正規化手法を提案します。トランスデューサーモデルであり、位置合わせは必要ありません。 
[ABSTRACT] fastemitは、librispeechで90パーセンタイルのレイテンシーを30ミリ秒に短縮します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Emformer: Efficient Memory Transformer Based Acoustic Model For Low
  Latency Streaming Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_1.html">
      <font color="black">Emformer: Efficient Memory Transformer Based Acoustic Model For Low
  Latency Streaming Speech Recognition</font>
    </a>
  </h2>
  <font color="black">ベンチマークLibriSpeechデータで実験を実行します。強力なベースライン拡張メモリトランスフォーマー（AM-TRF）と比較すると、Emformerは、相対WERを使用したデコードで$ 4.6 $倍のトレーニング速度向上と、$ 18 \％$の相対リアルタイム係数（RTF）の削減を実現します。 test-cleanで$ 17 \％$、test-otherで$ 9 \％$の削減。平均遅延が960ミリ秒の場合、Emformerはtest-cleanで$ 2.50 \％$、test-otherで$ 5.62 \％$を取得します。 
[概要]平均レイテンシが80ミリ秒の低レイテンシシナリオの場合、emformerは$ 2. 50-クリーン、テストで$ 5. 62 /％$-その他。同じレイテンシシナリオで、emformerはwer $ 3.01を達成します。 7.999ドルとテストで$-その他</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Trends at NIME -- Reflections on Editing "A NIME Reader" -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_2.html">
      <font color="black">Trends at NIME -- Reflections on Editing "A NIME Reader"</font>
    </a>
  </h2>
  <font color="black">アンソロジーには批判的言説も含まれており、NIMEコミュニティの長所と短所を認めることで、この分野をさらに多様化および強化できる活動を提案します。アンソロジーは必然的に選択的であり、私たちも例外ではありません。今後のアンソロジー「NIMEリーダー-音楽表現のための新しいインターフェースの15年」を編集するプロセスの概要。 
[要約] 1200以上のニメ論文のコレクションは、会議の15年の長い歴史を通して公開されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: BERT for Joint Multichannel Speech Dereverberation with Spatial-aware
  Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_3.html">
      <font color="black">BERT for Joint Multichannel Speech Dereverberation with Spatial-aware
  Tasks</font>
    </a>
  </h2>
  <font color="black">提案された方法は、トランス（BERT）からの双方向エンコーダ表現の優れたシーケンスモデリング機能に触発されています。実験結果は、提案された方法の有効性を示しています。マルチチャネルスペクトルの大きさとスペクトル位相情報の両方がエンコードされます。 
[ABSTRACT]提案された方法は、シーケンスからシーケンスへのマッピング問題としてタスクに対処します。これは、さまざまなフロントエンド音声処理タスクに十分一般的です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Sentence Boundary Augmentation For Neural Machine Translation Robustness -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_4.html">
      <font color="black">Sentence Boundary Augmentation For Neural Machine Translation Robustness</font>
    </a>
  </h2>
  <font color="black">ニューラル機械翻訳（NMT）モデルは、整形式のトレーニングおよび評価データが提供される翻訳タスクで強力な最先端のパフォーマンスを示していますが、さまざまなタイプのエラーを含む入力に敏感なままです。詳細なエラー分析を通じて、文の境界セグメンテーションが品質に最大の影響を与えることを示し、セグメンテーションの堅牢性を向上させるための単純なデータ拡張戦略を開発します。具体的には、入力トランスクリプトが自動音声認識から取得される長い形式の音声翻訳システムのコンテキストで（ ASR）、NMTモデルは、音韻置換、文法構造、文の境界などのエラーを処理する必要があります。これらはすべて、NMTの堅牢性に課題をもたらします。 
[概要]理解システムと連携できる必要があります。音素置換、文法構造、文の境界などのエラーを処理する必要があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Addressing the Recitative Problem in Real-time Opera Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_5.html">
      <font color="black">Addressing the Recitative Problem in Real-time Opera Tracking</font>
    </a>
  </h2>
  <font color="black">最初に、同じオペラのさまざまなパフォーマンスからの対応するレチタティーヴォの正確な配置を対象として、音声関連の機能に関する体系的な調査を実行します。次に、事前にトレーニングされた音楽と音声分類子に基づいて、2つのトラッカーを組み合わせるさまざまなソリューションを提案します。オペラ全体を通してグローバルな精度を向上させるために..この論文では、音楽に焦点を当てたものと音声に敏感な機能に焦点を当てた2つの特殊なトラッカーを並行して使用することを提案することでこの特定の問題に対処します。 
[概要]現在のオーディオからオーディオへの位置合わせアルゴリズムは、比較的堅牢な方法で、オペラ全体を最初から最後まで追跡するように作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Knowledge Distillation for Improved Accuracy in Spoken Question
  Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_6.html">
      <font color="black">Knowledge Distillation for Improved Accuracy in Spoken Question
  Answering</font>
    </a>
  </h2>
  <font color="black">実験は、私たちのアプローチがSpoken-SQuADデータセットのいくつかの最先端の言語モデルよりも優れていることを示しています。具体的には、音声ドキュメントと書面の対応物から知識蒸留（KD）を実行するトレーニング戦略を考案します。自動音声認識（ ASR）は、QAシステムの開発において重要な役割を果たします。 
[ABSTRACT]自動音声認識（asr）は、qaシステムの開発において重要な役割を果たします。このシステムは、問題の理解を理解するために使用され、新しい蒸留フレームワークを提示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Prediction of Object Geometry from Acoustic Scattering Using
  Convolutional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_7.html">
      <font color="black">Prediction of Object Geometry from Acoustic Scattering Using
  Convolutional Neural Networks</font>
    </a>
  </h2>
  <font color="black">現在の作業では、モデルから作成された予測がグラウンドトゥルースと高精度で一致することがわかりました。データ劣化に対応するアプローチの堅牢性は、データセットを使用してトレーニングされたネットワークのパフォーマンスをさまざまなレベルのデータ劣化と比較することによって評価されます。本研究では、畳み込みニューラルネットワークをトレーニングすることにより、散乱特徴からオブジェクトの形状を推測する方法を提案します。 
[概要]本研究では、散乱特徴からオブジェクトの彫刻を推測する方法を提案します。シミュレーションの完全なセットをサンプリングして、複数のデータセットを生成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: WaveTransformer: A Novel Architecture for Audio Captioning Based on
  Learning Temporal and Time-Frequency Information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_8.html">
      <font color="black">WaveTransformer: A Novel Architecture for Audio Captioning Based on
  Learning Temporal and Time-Frequency Information</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、以前に報告された最高のSPIDErを16.2から17.3に増やします。キャプションを生成するために、広く使用されているTransformerデコーダーを使用します。Clothoデータセットの自由に利用可能な分割を利用して方法を評価します。 
[概要]これは、広く使用されているトランスデコーダーを抽出する作業です。この方法は、ローカルメソッドの使用に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Complex data labeling with deep learning methods: Lessons from fisheries
  acoustics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_9.html">
      <font color="black">Complex data labeling with deep learning methods: Lessons from fisheries
  acoustics</font>
    </a>
  </h2>
  <font color="black">このアプローチのさらなる開発は、漁業音響学におけるラベリングプロセスの標準化への道を開き、非自明なデータラベリングプロセスの良いケーススタディです。大量の生データが収集されますが、退屈な専門家によるラベリングが必要です。定量的および定性的海底から海面への音響後方散乱信号の分析は、世界中で魚の資源評価と海洋生態系の監視に使用されています。 
[ABSTRACT]データデータデータは分析するのに十分ではありませんが、調査する必要があります。データを収集し、データを分析する必要があります。このプロセスはデータデータ分析に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Contextualized Attention-based Knowledge Transfer for Spoken
  Conversational Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_10.html">
      <font color="black">Contextualized Attention-based Knowledge Transfer for Spoken
  Conversational Question Answering</font>
    </a>
  </h2>
  <font color="black">音声会話型質問応答（SCQA）では、音声発話とテキストコーパスを考慮して、複雑な会話フローをモデル化するマシンが必要です。ただし、ASRシステムは、予期しないノイズの多い信号を文字起こしに導入し、SCQAのパフォーマンスを低下させます。教師モデルの推定確率から学生にASRロバストな知識を抽出するための知識蒸留フレームワーク。 
[ABSTRACT] scqaは、従来のテキスト質問応答（qa）タスクとは異なります。音声信号処理、パッセージの理解、コンテキストの理解が含まれます。音声からcoqaのデータセットに対して広範な実験を行います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-task Metric Learning for Text-independent Speaker Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_11.html">
      <font color="black">Multi-task Metric Learning for Text-independent Speaker Verification</font>
    </a>
  </h2>
  <font color="black">結果は、提案された方法の有効性を示しています。補助MLタスクの場合、ミニバッチのトレーニングサンプルは最初にペアに配置され、次に正と負のペアが選択され、それぞれの相対的な類似性によって重み付けされ、最後に補助ML損失は、選択したペアの類似性によって計算されます。提案された方法を評価するために、Speaker in the Wild（SITW）データセットで実験を行います。 
[概要]ディープスピーカー埋め込みネットワークは、多くの変更を加えてトレーニングされています。システムをテストするための方法が提案されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Real-time Speech Frequency Bandwidth Extension -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_12.html">
      <font color="black">Real-time Speech Frequency Bandwidth Extension</font>
    </a>
  </h2>
  <font color="black">さらに、ストリーミングモードでデバイスに展開できるSEANetのバリアントを提案し、16ミリ秒のアーキテクチャ遅延を実現します。低遅延により、双方向音声通信システムで実行可能になります。のシングルコアでプロファイルされた場合1つの16msフレームを処理するモバイルCPUは、わずか1.5msしかかかりません。 
[概要]モデルアーキテクチャは、波から波への完全畳み込みモデルであるシーネットに基づいています。特徴損失と敵対的損失の組み合わせを使用して、入力音声の拡張バージョンを再構築します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Towards End-to-End Training of Automatic Speech Recognition for Nigerian
  Pidgin -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_13.html">
      <font color="black">Towards End-to-End Training of Automatic Speech Recognition for Nigerian
  Pidgin</font>
    </a>
  </h2>
  <font color="black">ベースラインの結果により、データセットで貪欲なデコーダーを使用して、0.77％の低い単語誤り率（WER）を達成することができました。また、これについて最初のエンドツーエンド音声認識システム（QuartzNetおよびJasperモデル）をトレーニングしました。 Connectionist Temporal Classification（CTC）の損失を使用して最適化された言語。この作業では、ナイジェリアのpidginに関する最初の並列（音声からテキストへの）データを示します。 
[概要]この言語は、イギリス、カナダ、アメリカのナイジェリア移民を通じて、ディアスポラのコミュニティに広まりました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Detection of COVID-19 through the analysis of vocal fold oscillations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_14.html">
      <font color="black">Detection of COVID-19 through the analysis of vocal fold oscillations</font>
    </a>
  </h2>
  <font color="black">ロジスティック回帰などの単純な分類器でも、孤立した拡張母音の記録だけを使用して高い検出精度が得られるほど、これらが顕著で識別力があることを示します。COVID-19の陽性および陰性の被験者の臨床的にキュレートされたデータセットでの実験結果は、 COVID-19と相関する声帯振動..このために、声帯の振動に動的システムモデルを使用し、最近開発されたADLESアルゴリズムを使用してそれを解決し、録音された音声から直接声帯振動パターンを生成します。 
[概要]バイオ-機械的プロセスは、話者の呼吸状態の変化に非常に敏感です。これらの変化は、たとえば音声からのcovid-19にリンクされています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Contrastive Learning of General-Purpose Audio Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_15.html">
      <font color="black">Contrastive Learning of General-Purpose Audio Representations</font>
    </a>
  </h2>
  <font color="black">大規模なAudiosetデータベースに埋め込みを事前トレーニングし、これらの表現を、音声、音楽、動物の音、音響シーンなど、9つの多様な分類タスクに転送します。コンピュータービジョンと強化のための教師あり学習の最近の進歩に基づいて構築します。軽量で実装が簡単なオーディオの自己監視モデルの設計を学ぶ。その単純さにもかかわらず、私たちの方法は以前の自己監視システムを大幅に上回っていることを示しています。 
[概要]大規模なオーディオセットデータベースに埋め込みを事前トレーニングします。これらの表現を9つの多様な分類タスクに転送します。また、主要な設計の選択を特定するためにアブレーション研究を実施します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Disentangled Phone and Speaker Representations in a
  Semi-Supervised VQ-VAE Paradigm -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_16.html">
      <font color="black">Learning Disentangled Phone and Speaker Representations in a
  Semi-Supervised VQ-VAE Paradigm</font>
    </a>
  </h2>
  <font color="black">スピーカーVQコンポーネントを追加すると、音声合成品質の客観的尺度（推定MOS、スピーカーの類似性、ASRベースの了解度）が向上し、意味のある学習表現が提供されます。また、2つのトレーニング方法を比較します。グローバル条件での自己監視と半教師ありです。スピーカーラベル付き..スピーカーVQコードブックインデックスは、単純なスピーカーダイアリゼーションタスクで使用でき、xベクトルベースラインよりもわずかに優れたパフォーマンスを発揮します。 
[概要]元のvq-vaeは、目に見えない話者にうまく一般化されません。また、2つのトレーニング方法を比較します。自己-話者ラベルで監視</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: The UPC Speaker Verification System Submitted to VoxCeleb Speaker
  Recognition Challenge 2020 (VoxSRC-20) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_17.html">
      <font color="black">The UPC Speaker Verification System Submitted to VoxCeleb Speaker
  Recognition Challenge 2020 (VoxSRC-20)</font>
    </a>
  </h2>
  <font color="black">二重分岐シャムは、トレーニング中にクロスエントロピー損失を使用して二項分類を実行します。VoxCeleb-1テスト、VoxSRC-20検証、およびテストセットに関するシステムの結果を提供します。最終的な提出は、3つのシステムの組み合わせです。 
[要約]最終的な提出は、3つのシステムの組み合わせです。cnnエンコーダーであるvoxへの応答です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Joint Blind Room Acoustic Characterization From Speech And Music Signals
  Using Convolutional Recurrent Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_18.html">
      <font color="black">Joint Blind Room Acoustic Characterization From Speech And Music Signals
  Using Convolutional Recurrent Neural Networks</font>
    </a>
  </h2>
  <font color="black">これらは音声明瞭度と音質に密接に関連しています。ただし、RIRを測定するには、特定の機器と押し付けがましい音を再生する必要があります。ISO3382標準で説明されているように、これらはルームインパルス応答（RIR）と呼ばれる部屋の測定値から導出できます。 。 
[ABSTRACT]残響時間、明瞭度、および直接対残響比は、残響環境を表すために定義された音響パラメータです。これらは、部屋のインパルス応答（rir）と呼ばれる部屋の測定値から導出できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: VENOMAVE: Clean-Label Poisoning Against Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_19.html">
      <font color="black">VENOMAVE: Clean-Label Poisoning Against Speech Recognition</font>
    </a>
  </h2>
  <font color="black">攻撃の実際的な実現可能性を示すために、0から9までの数字のシーケンスを検出するASRシステムでVENOMAVEを評価します。このホワイトペーパーでは、VENOMAVEと呼ばれるオーディオドメインでの最初のデータポイズニング攻撃を紹介します。イメージドメインはいくつかのタイプのデータポイズニング攻撃を示しましたが、オーディオドメインには適用できません。 
[概要]最新のasrシステムはニューラルネットワークに基づいています。以前の調査では、これらのシステムは敵対的な例の影響を受けやすいことが示されています。これらのシステムには、誤分類につながる悪意のある音声入力が含まれています。asrシステムに対するデータポイズニング攻撃は実際の脅威であると結論付けています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: The LOCATA Challenge: Acoustic Source Localization and Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-22/eess.AS/paper_20.html">
      <font color="black">The LOCATA Challenge: Acoustic Source Localization and Tracking</font>
    </a>
  </h2>
  <font color="black">LOCAlization and TrAcking（LOCATA）チャレンジの目的は、音源のローカリゼーションとトラッキングのための幅広いクラスのアルゴリズムの客観的な評価とベンチマークのためのオープンアクセスフレームワークです。音源とマイクプラットフォームが移動する可能性がある動的なシナリオでは、信号は、ソースセンサーの形状の変化によってさらに影響を受けます。この記事では、関連するローカリゼーションおよび追跡アルゴリズムのレビューと、既存の文献のコンテキスト内で、LOCATA提出物の詳細な評価と普及について説明します。 
[概要]現実的なシナリオでは、オーディオ信号は、残響、ノイズ、干渉、および音声の非アクティブ期間の影響を受けます。実際には、音源の位置特定と追跡へのアプローチは、アクティブな音源の推定値の欠落、推定誤差、および誤った見積もり</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-03">
        <br><font color="black">2019-09-03</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
