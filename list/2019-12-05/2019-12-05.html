<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<title>Akari-2019-12-05の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
  <div class="header-logo">
    <a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
  </div>
</header>
<input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">

<div class="menubar">
<span class="bar"></span>
<span class="bar"></span>
<span class="bar"></span>
</div>

<ul>
<li><a id="home" href="../../index.html">Home</a></li>
<li><a id="about" href="../../teamAkariとは.html">About</a></li>
<li><a id="contact" href="../../contact.html">Contact</a></li>
<li><a id="contact" href="../../list/newest.html">New Papers</a></li>
<li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
</ul>

</label>
<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Environment Sound Classification using Multiple Feature Channels and
  Attention based Deep Convolutional Neural Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.SD/paper_0.html">
      Environment Sound Classification using Multiple Feature Channels and
  Attention based Deep Convolutional Neural Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、アテンションメカニズムを備えたディープコンボリューショナルニューラルネットワーク（CNN）への入力として与えられる複数の特徴チャネルで構成される環境音分類タスク（ESC）のモデルを提案します。または音声処理..パフォーマンスをさらに向上させるために、いくつかのデータ拡張技術を使用します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-28">
        <br>2019-08-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: PitchNet: Unsupervised Singing Voice Conversion with Pitch Adversarial
  Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.SD/paper_1.html">
      PitchNet: Unsupervised Singing Voice Conversion with Pitch Adversarial
  Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、提案されたPitchNetは、敵対的に訓練されたピッチ回帰ネットワークを追加して、ピッチ不変の音素表現を学習するエンコーダーネットワークを強制し、ソースオーディオから抽出されたピッチをデコーダーネットワークに供給する別のモジュールを追加しました。歌の内容を変更せずに他の人の声に音声を変換します。評価により、提案された方法により、変換された歌声の品質が大幅に改善されることがわかります（MOSで2.92対3.75）。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Integrating Whole Context to Sequence-to-sequence Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.SD/paper_2.html">
      Integrating Whole Context to Sequence-to-sequence Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、以前に提案した「教師からのスペルの学習」アプローチを利用して、CORからSeq2Seqモデルにコンテキスト全体の知識を統合します。中国の公開データセットAISHELL-1。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: On the Possibility of Rewarding Structure Learning Agents: Mutual
  Information on Linguistic Random Sets -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.CL/paper_0.html">
      On the Possibility of Rewarding Structure Learning Agents: Mutual
  Information on Linguistic Random Sets
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は、シミュレートされたセマンティック構造（オープン情報抽出トリプレット）が、構成要素間の相互情報を観察することにより、ランダムに構築された構造と区別できることの実証的証拠を示しました。提供される報酬を設計するための理論的および経験的アプローチを解明する最初の試みを提示しますこれは、事前学習済みの構造分析器（オラクルアクター/エキスパート）を使用せずに構造学習エージェントに報酬を与える可能性を示唆しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-09">
        <br>2019-10-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Rare Words: A Major Problem for Contextualized Embeddings And How to Fix
  it by Attentive Mimicking -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.CL/paper_1.html">
      Rare Words: A Major Problem for Contextualized Embeddings And How to Fix
  it by Attentive Mimicking
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      メソッドを評価するために、言語モデルがタスク固有の微調整なしで単語のセマンティックプロパティをキャプチャする能力をテストする新しいデータセットを作成します。この問題を修正するために、明示的に設計されたメソッドであるAttentive Mimickingこのデータセットを使用して、注意深い模倣の適合バージョンをBERTに追加すると、まれな単語の理解が大幅に向上することを示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-14">
        <br>2019-04-14
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Acquiring Knowledge from Pre-trained Model to Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.CL/paper_2.html">
      Acquiring Knowledge from Pre-trained Model to Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本論文では、事前訓練されたモデルからNMTに知識を獲得するためのAPTフレームワークを提案します。提案されたアプローチは、事前訓練されたモデルから適切な知識を統合してNMTを改善します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: TinyBERT: Distilling BERT for Natural Language Understanding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.CL/paper_3.html">
      TinyBERT: Distilling BERT for Natural Language Understanding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、TinyBERTの新しい2段階学習フレームワークを導入します。これは、事前トレーニング段階とタスク固有の学習段階の両方でトランス蒸留を実行します。このフレームワークは、TinyBERTが教師BERT.TinyBERTは経験的に効果的であり、GLUEベンチマークで教師BERTBASEのパフォーマンスを96％以上達成し、推論では7.5倍小さく9.4倍高速です。また、TinyBERTは約28％のパラメーターと約31％の推論時間でのBERT蒸留。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-23">
        <br>2019-09-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: BillSum: A Corpus for Automatic Summarization of US Legislation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.CL/paper_4.html">
      BillSum: A Corpus for Automatic Summarization of US Legislation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、神経文の表現と従来の文脈上の特徴を考慮した抽出方法のベンチマークを行います。このペーパーでは、米国議会およびカリフォルニア州法案の要約のための最初のデータセットであるBillSumを紹介します（https://github.com/FiscalNote/BillSum） ..最後に、議会法案に基づいて構築されたモデルを使用して、カリフォルニア州法案を要約できることを実証します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-01">
        <br>2019-10-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Enhancing Relation Extraction Using Syntactic Indicators and Sentential
  Contexts -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.CL/paper_5.html">
      Enhancing Relation Extraction Using Syntactic Indicators and Sentential
  Contexts
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      固定テキストトリガーを使用する他のアプローチでは、このような情報をキャプチャしますが、語彙の多様性は無視します。SemEval-2010Task 8ベンチマークデータセットの実験では、モデルが最先端の方法よりも大幅に優れていることが示されています。文全体からのノイズの多い情報の影響を軽減し、テキストトリガーの制限を打ち破ります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards Building a Multilingual Sememe Knowledge Base: Predicting
  Sememes for BabelNet Synsets -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.CL/paper_6.html">
      Towards Building a Multilingual Sememe Knowledge Base: Predicting
  Sememes for BabelNet Synsets
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      手動で15ドル以上のシンセット（BabelNetのエントリ）のセムに注釈を付けます。最初に、多言語セムKBのシードとして機能するデータセットを構築します。この作業のすべてのソースコードとデータはhttps：/で取得できます。 /github.com/thunlp/BabelNet-Sememe-Prediction。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Topic-aware chatbot using Recurrent Neural Networks and Nonnegative
  Matrix Factorization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.CL/paper_7.html">
      Topic-aware chatbot using Recurrent Neural Networks and Nonnegative
  Matrix Factorization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      トピック認識チャットボットは、非トピック対応チャットボットよりも優れているだけでなく、各トピック認識モデルが質的および文脈的に質問のトピックに応じて最も関連性の高い回答を提供することを示します。従来のリカレントニューラルネットワーク（RNN）エンコーダーデコーダーモデルと非負行列因子分解（NMF）に基づくトピックアテンションレイヤーを組み合わせることにより、チャットボットを認識します。NMFを介して補助テキストコーパスからトピックベクトルを学習した後、デコーダーは、最も相関の高いトピックベクトルから応答単語をサンプリングする可能性が高くなります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-01">
        <br>2019-12-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Resource for Computational Experiments on Mapudungun -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.CL/paper_8.html">
      A Resource for Computational Experiments on Mapudungun
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      コード切り替え、歴史的正書法の変更、言語構造、社会学および人類学の研究など、コーパスが適している他のアプリケーションをさらに探索します。会話は完全に転写され、スペイン語に翻訳されています。 Mapudungunで計算実験を行いました。Mapudungunは、チリで20万人以上の話者が話した多合成の先住民言語です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards Constructing a Corpus for Studying the Effects of Treatments and
  Substances Reported in PubMed Abstracts -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.CL/paper_9.html">
      Towards Constructing a Corpus for Studying the Effects of Treatments and
  Substances Reported in PubMed Abstracts
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      用語と略語を認識することが理論的文を決定するための鍵であることが判明しました。コーパスは、特定のセマンティックからのUMLS概念に基づく抽象用語の正規化で現在78.80％の精度を達成している分類子を改善するために適用されますグループと線形カーネルを持つSVM。.現在、コーパスは750の要約で構成されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Keyword Aware Influential Community Search in Large Attributed Graphs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.CL/paper_10.html">
      Keyword Aware Influential Community Search in Large Attributed Graphs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、大きな属性付きグラフで影響力のあるコミュニティを検索するための2つの効率的なアルゴリズムを提案します。まず、クエリ用語と述語（ANDまたはOR）のセットを使用して、ユーザーが直感的に影響力のあるCSクエリを発行できるようにするKICQを設計します。提案されたアプローチの有効性と効率性を実証するために、詳細な実験とケーススタディを提示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An Exploration of Data Augmentation and Sampling Techniques for
  Domain-Agnostic Question Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.CL/paper_11.html">
      An Exploration of Data Augmentation and Sampling Techniques for
  Domain-Agnostic Question Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ドメインごとのサンプリングと組み合わせて適用すると、XLNet（Yang et al。、2019）ベースの提出は、MRQAリーダーボード競技で2番目に最高の完全一致とF1を達成しました。単純なネガティブサンプリング手法が特に効果的であることがわかりました。通常、SQuAD 2.0などの回答不可能な質問を含むデータセットに使用されますが、機械読み取り質問応答（MRQA）2019共有タスクのドメインに依存しない質問応答モデルを作成するために、大規模な事前の相対的な利点を調査します。トレーニングされた言語モデル、さまざまなデータサンプリング戦略、逆翻訳によって生成されたクエリとコンテキストの言い換え。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Plug and Play Language Models: a Simple Approach to Controlled Text
  Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.CL/paper_12.html">
      Plug and Play Language Models: a Simple Approach to Controlled Text
  Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      PPLMは、微分可能な属性モデルの任意の組み合わせを使用してテキスト生成を操作できるため、柔軟性があります。これにより、このペーパーで示した例以外の多様で創造的なアプリケーションが可能になります。ユーザーが指定した単語のバッグまたはLMの100,000倍少ないパラメーターを持つ単一の学習レイヤーの..単純な代替案を提案します。制御可能な言語生成のためのプラグアンドプレイ言語モデル（PPLM）。または、LMのさらなるトレーニングなしでテキスト生成をガイドするより単純な属性分類子。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Scalable Bayesian Preference Learning for Crowds -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.CL/paper_13.html">
      Scalable Bayesian Preference Learning for Crowds
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      将来の作業のためにソフトウェアを一般公開します。ノイズやスパースデータから生じる不確実性を説明するベイジアンアプローチを使用して、マトリックス因数分解とガウスプロセスを組み合わせることにより、これらの課題に対処します。多数のユーザー、アイテム、またはペアワイズラベルの場合、計算コストとメモリコストを制限する確率的変分推論アプローチを提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: PitchNet: Unsupervised Singing Voice Conversion with Pitch Adversarial
  Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.CL/paper_14.html">
      PitchNet: Unsupervised Singing Voice Conversion with Pitch Adversarial
  Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、提案されたPitchNetは、敵対的に訓練されたピッチ回帰ネットワークを追加して、ピッチ不変の音素表現を学習するエンコーダーネットワークを強制し、ソースオーディオから抽出されたピッチをデコーダーネットワークに供給する別のモジュールを追加しました。変換された歌声の品質を大幅に改善します（MOSの2.92と3.75）。最近の研究では、オートエンコーダベースのアプローチを使用して、教師なしの歌声変換を実現できることが示されています[1]。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Machine Translation: A Review -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.CL/paper_15.html">
      Neural Machine Translation: A Review
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、最新のNMTアーキテクチャの起源を、単語と文の埋め込み、およびエンコーダ/デコーダネットワークファミリの以前の例にまでさかのぼります。この分野の最近の傾向の調査で締めくくります。主に依存する統計MT数十年に渡りMT研究を支配してきた様々なカウントベースのモデルについては、単一のニューラルネットワークで翻訳に取り組む神経機械翻訳（NMT）にほぼ取って代わられました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: PDC -- a probabilistic distributional clustering algorithm: a case study
  on suicide articles in PubMed -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.CL/paper_16.html">
      PDC -- a probabilistic distributional clustering algorithm: a case study
  on suicide articles in PubMed
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、用語空間で計算されたトピックを視覚化し、用語の各グループに最も関連するPubMed記事を取得する環境も提示します。自殺のトピックに関するPubMed文書に適用することでアルゴリズムを示します。アルゴリズムは、単語の共起の確率に依存して、ドキュメントのコレクションに現れる用語のセットを関連用語の互いに素なグループに分割します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Integrating Whole Context to Sequence-to-sequence Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/cs.CL/paper_17.html">
      Integrating Whole Context to Sequence-to-sequence Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、以前に提案した「教師からのスペルの学習」アプローチを利用して、CORからSeq2Seqモデルにコンテキスト全体の知識を統合します。中国の公開データセットAISHELL-1。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Environment Sound Classification using Multiple Feature Channels and
  Attention based Deep Convolutional Neural Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/eess.AS/paper_0.html">
      Environment Sound Classification using Multiple Feature Channels and
  Attention based Deep Convolutional Neural Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ESC-10およびESC-50データセットの場合、提案されたモデルによって達成される精度は、それぞれ95.7％および81.3％の人間の精度を超えています。UrbanSound8K（98.77％）、ESC-10（96.75％）およびESC-50（93.50 ％）..パフォーマンスをさらに向上させるために、いくつかのデータ拡張手法を使用します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-28">
        <br>2019-08-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: PitchNet: Unsupervised Singing Voice Conversion with Pitch Adversarial
  Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/eess.AS/paper_1.html">
      PitchNet: Unsupervised Singing Voice Conversion with Pitch Adversarial
  Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      歌声の変換とは、歌の内容を変えずに歌手の声を他の声に変換することです。評価により、提案された方法は変換された歌声の品質を大幅に改善できることがわかりました（MOSで2.92対3.75）。具体的には、提案されたPitchNet敵対的に訓練されたピッチ回帰ネットワークを追加して、エンコーダーネットワークにピッチ不変音素表現を学習させ、ソースオーディオから抽出されたピッチをデコーダーネットワークに供給する別のモジュールを追加しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Integrating Whole Context to Sequence-to-sequence Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-05/eess.AS/paper_2.html">
      Integrating Whole Context to Sequence-to-sequence Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、以前に提案した「教師からのスペルの学習」アプローチを使用して、CORからSeq2Seqモデルにコンテキスト全体の知識を統合します。公開された中国のデータセットAISHELL-1で実験を行います。 Seq2Seqモデルのパフォーマンスを改善します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本日更新された論文はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br>
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
