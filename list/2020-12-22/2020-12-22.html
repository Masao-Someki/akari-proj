<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-12-22の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Multi-talker ASR for an unknown number of sources: Joint training of
  source counting, separation and ASR -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.SD/paper_0.html">
      <font color="black">Multi-talker ASR for an unknown number of sources: Joint training of
  source counting, separation and ASR</font>
    </a>
  </h2>
  <font color="black">さらに、WSJ0-4mixデータベースでの実験で示されているように、私たちのシステムは、トレーニング中にこれまでに見たよりも多くのスピーカーにうまく一般化されます。とりわけ、新しい最先端の単語誤り率を設定しました。 WSJ0-2mixデータベース..私たちの実験は、WSJ0-2mixとWSJ0-3mixからのシミュレートされたクリーンな混合物でのカウント精度、ソース分離、および音声認識において非常に有望なパフォーマンスを示しています。 
[概要] wsj0-2mixデータベースに新しい注目度の高いエラー率を設定します。データベースにクリーンスポットエラー率も設定します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-04">
        <br><font color="black">2020-06-04</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-stream Convolutional Neural Network with Frequency Selection for
  Robust Speaker Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.SD/paper_1.html">
      <font color="black">Multi-stream Convolutional Neural Network with Frequency Selection for
  Robust Speaker Verification</font>
    </a>
  </h2>
  <font color="black">提案されたフレームワークは、音響モデリングのロバスト性を強化するために、複数のストリームから生成された多様な時間埋め込みに対応します。時間埋め込みの多様性については、周波数の全帯域を手動でいくつかのサブにセグメント化する周波数選択による特徴拡張を検討します。バンド、および各ストリームの特徴抽出器は、ターゲット周波数ドメインとして使用するサブバンドを選択できます。各発話が1回だけ処理される従来のシングルストリームソリューションとは異なり、このフレームワークでは、複数のストリーム処理があります。並行して。 
[概要]話者検証タスクのために、マルチストリーム畳み込みニューラルネットワーク（cnn）の新しいシステムが提案されました。全周波数範囲の代わりに音声認識を使用できるようにするには、複数の話者が必要です。これは、いわゆる周波数選択手法です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Adjust-free adversarial example generation in speech recognition using
  evolutionary multi-objective optimization under black-box condition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.SD/paper_2.html">
      <font color="black">Adjust-free adversarial example generation in speech recognition using
  evolutionary multi-objective optimization under black-box condition</font>
    </a>
  </h2>
  <font color="black">この論文で提案された方法は、ブラックボックスシナリオの下でロバストな敵対的な例を生成することを可能にする進化的多目的最適化（EMO）を採用します。実験結果は、提案された方法がタイミングに対して十分にロバストな調整なしの敵対的な例を首尾よく生成したことを示しました。攻撃者がターゲットの音声に対してそれを再生するタイミングを取る必要がないように遅れます。いくつかの研究は、音声認識のためにニューラルネットワークを攻撃しようとしました。ただし、これらの方法では、ターゲットスピーチとのタイミングラグに対する生成された敵対的な例の堅牢性は考慮されていませんでした。 
[概要]一部の研究では、音声認識のためにニューラルネットワークを攻撃しようとしましたが、これらの方法では、ターゲット音声とのタイミングラグに対する敵対的な例の堅牢性は考慮されていませんでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: A Bayesian methodology for localising acoustic emission sources in
  complex structures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.SD/paper_3.html">
      <font color="black">A Bayesian methodology for localising acoustic emission sources in
  complex structures</font>
    </a>
  </h2>
  <font color="black">起源が不明なアコースティックエミッションイベントが観察されると、構造の表面全体の放射位置の可能性を定量化するマッピングが生成されます。この論文では、これらの複雑さにロバストなベイズ音源定位戦略が提示されます。 ..この新しいフレームワークでは、最初にガウスプロセスを使用して、ソースの場所と、いくつかのセンサーペアの対応する到着時間の差の値との関係を学習します。 
[ABSTRACT]ガウス過程は、最初にソースの場所とそれに対応する到着値の時間差との関係を学習するために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: A Shift-insensitive Full Reference Image Quality Assessment Model Based
  on Quadratic Sum of Gradient Magnitude and LOG signals -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/eess.IV/paper_0.html">
      <font color="black">A Shift-insensitive Full Reference Image Quality Assessment Model Based
  on Quadratic Sum of Gradient Magnitude and LOG signals</font>
    </a>
  </h2>
  <font color="black">一方、提案されたモデルは、アプリケーションに効率的なCW-SSIMよりもはるかに単純です。画像の被写体品質を推定することを目的とした画質評価は、さまざまなアプリケーションでの画像の知覚品質を評価するためのモデルを構築します。結果は、提案されたモデルが、さまざまな歪みタイプとレベルを含む3つの大規模な主観的IQAデータベースで堅牢に機能し、単一の歪みタイプまたはデータベース全体に関係なく、最先端のFR-IQAモデルにとどまることを示しています。 。 
[概要]エッジ情報抽出は、さまざまなiqaメトリックに広く適用されます。新しいモデルは、3つの大規模な主観的iqaデータベースで堅牢に機能します。提案されたモデルは、cw-lapensimよりもはるかに単純です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: DAQ: Distribution-Aware Quantization for Deep Image Super-Resolution
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/eess.IV/paper_1.html">
      <font color="black">DAQ: Distribution-Aware Quantization for Deep Image Super-Resolution
  Networks</font>
    </a>
  </h2>
  <font color="black">第二に、特徴マップには量子化誤差を支配する可能性のある外れ値があります。これらの観察に基づいて、超低精度で正確なトレーニングなしの量子化を容易にする新しい分布認識量子化スキーム（DAQ）を提案します。DAQの単純な関数低い計算負荷で特徴マップと重みの動的範囲を決定します。 
[概要]既存の作品は、超低精度でパフォーマンスが大幅に低下します。新しい方法は、最新の画像超解像ネットワークに対する最近のトレーニング（無料およびトレーニングベースの量子化方法）よりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: CNN-Based Ultrasound Image Reconstruction for Ultrafast Displacement
  Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/eess.IV/paper_2.html">
      <font color="black">CNN-Based Ultrasound Image Reconstruction for Ultrafast Displacement
  Tracking</font>
    </a>
  </h2>
  <font color="black">この目的のために、相互相関に基づくスペックルトラッキングアルゴリズムと組み合わせた畳み込みニューラルネットワークベースの画像再構成法を展開しました。数キロヘルツでフルビューフレームを取得する機能のおかげで、超高速超音波イメージングは迅速な分析のロックを解除しました心臓血管系の超高感度フローイメージングやせん断波エラストグラフィなどの先駆的なアプリケーションで、人体の物理的現象を変化させます。平面波イメージングのコンテキストで実施された数値およびin vivo実験は、提案されたアプローチが可能であることを示していますサイドローブとグレーティングローブのアーティファクトの存在が、従来の遅延和ビームフォーミングに依存する最先端の技術による変位推定を妨げる領域での変位を推定する方法。 
[要約]提案されたアプローチは、高品質のフレームを再構築するために単一の超高速取得に依存し、迅速に取得するために2つの連続したフレームのみに依存します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Local Neighboring Structure for Robust 3D Shape Representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/eess.IV/paper_3.html">
      <font color="black">Learning Local Neighboring Structure for Robust 3D Shape Representation</font>
    </a>
  </h2>
  <font color="black">包括的な実験は、私たちのモデルが最先端の方法と比較して3D形状再構成に大幅な改善をもたらすことを示しています。この論文では、適応加重行列を学習する局所構造認識異方性畳み込み演算（LSA-Conv）を提案します。各ノードは、ローカルの隣接構造に従って、共有異方性フィルターを実行します。ただし、等方性フィルターまたは事前定義されたローカル座標系は、表現力を制限します。 
[ABSTRACT]表現等方性フィルターまたは事前定義されたローカル座標系は、表現力を制限します。実際、学習可能な重み付け行列は、ランダムシンセサイザーの注意行列に似ています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br><font color="black">2020-04-21</font>
      </time>
    </span>
</section>
<!-- paper0: Explainable Machine Learning based Transform Coding for High Efficiency
  Intra Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/eess.IV/paper_4.html">
      <font color="black">Explainable Machine Learning based Transform Coding for High Efficiency
  Intra Prediction</font>
    </a>
  </h2>
  <font color="black">まず、エネルギー圧縮または無相関化機能を最大化する最適化問題として、機械学習ベースの変換設計をモデル化します。実験結果は、提案された8 $ \ times $ 8Saab変換ベースのイントラビデオコーディングがBj {\ o} nteggardデルタビットを達成できることを示しています。主流の8 $ \ times $ 8 DCTベースのコーディングスキームと比較して、平均で-1.19％から-10.00％および-3.07％のレート（BDBR）。一方、モード内依存のSaab変換が開発されています。 
[概要]機械学習システムが開発されたのはこれが初めてです。これは、ab変換がイントラビデオとイントラビデオに基づいていることを説明しています。これらは、コーディング効率を向上させるために開発されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Diagnosis of Pneumothorax from Chest Radiographs: A Systematic
  Literature Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/eess.IV/paper_5.html">
      <font color="black">Automatic Diagnosis of Pneumothorax from Chest Radiographs: A Systematic
  Literature Review</font>
    </a>
  </h2>
  <font color="black">この研究では、胸部X線からの気胸の自動検出に関する既存の文献を要約し、利用可能な胸部X線写真データセットについて説明します。さまざまな医療画像ツールの中で、胸部X線写真は胸部病変の検出に最も重要で広く使用されている診断ツールです。 。この論文は、将来の研究のための最適なアプローチの選択において研究者を支援するための気胸検出のための現在の研究の簡単な概要を提供します。 
[要約]胸部X線写真から気胸を自動的かつ迅速に検出するための研究が行われています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning in Detection and Diagnosis of Covid-19 using Radiology
  Modalities: A Systematic Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/eess.IV/paper_6.html">
      <font color="black">Deep Learning in Detection and Diagnosis of Covid-19 using Radiology
  Modalities: A Systematic Review</font>
    </a>
  </h2>
  <font color="black">調査結果によると、深層学習ベースのモデルは、CTスキャンおよびX線画像の処理にそれらを使用することで、Covid-19の検出および診断のための正確で効率的なシステムを実現するための並外れた能力を備えています。感度と特異性の値の大幅な増加..結果：このレビュー研究は、放射線モダリティと深層学習に基づくそれらの処理によるCovid-19の検出と診断のためのすべてのモデルの現状の概要を提供します。病気、放射線画像に基づく診断方法は、診断センターで多くの用途があるにもかかわらず、欠点を抱えています。 
[要約]放射線画像に基づく診断方法には欠点があります。キーワードは、深層学習、診断、検出の19個でした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: A Naturalness Evaluation Database for Video Prediction Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/eess.IV/paper_7.html">
      <font color="black">A Naturalness Evaluation Database for Video Prediction Models</font>
    </a>
  </h2>
  <font color="black">私たちの機能設計が、IISc VINEデータベースでの人間の判断に従って、最先端の自然性予測につながることを示します。さまざまなアプリケーションを適用して取得した300本のビデオで構成されるインド科学研究所VIdeo自然性評価（IISc VINE）データベースを作成します。さまざまなデータセットの予測モデル、および付随する人間の意見スコア。このコンテキストでは、予測されたビデオがどのように自然または現実的に見えるかを指す自然性評価の問題を紹介します。 
[概要]インド科学研究所のビデオ自然性評価（iisc vine）データベースは、さまざまなデータセットにさまざまな予測モデルを適用して取得した300本のビデオで構成されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: Blurring Fools the Network -- Adversarial Attacks by Feature Peak
  Suppression and Gaussian Blurring -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/eess.IV/paper_8.html">
      <font color="black">Blurring Fools the Network -- Adversarial Attacks by Feature Peak
  Suppression and Gaussian Blurring</font>
    </a>
  </h2>
  <font color="black">実験結果は、PSと適切に設計されたガウスぼかしが、十分に訓練されたターゲットネットワークの分類結果を完全に変更する敵対的攻撃を形成する可能性があることを示しています。ガウスぼかしの強力な物理的重要性と幅広いアプリケーションにより、提案されたアプローチは実行することもできます。実世界の攻撃..PSのぼかしの精神に基づいて、データにガウスぼかしをさらに適用し、ネットワークのパフォーマンスに対するガウスぼかしの潜在的な影響と脅威を調査します。 
[ABSTRACT]ガウスぼかしは、画像前処理の一般的な手法です。特定の場面で攻撃的になり、現実世界の攻撃につながる可能性があります。提案されたアプローチは、現実世界の攻撃を実行することもできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: A Multi-View Dynamic Fusion Framework: How to Improve the Multimodal
  Brain Tumor Segmentation from Multi-Views? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/eess.IV/paper_9.html">
      <font color="black">A Multi-View Dynamic Fusion Framework: How to Improve the Multimodal
  Brain Tumor Segmentation from Multi-Views?</font>
    </a>
  </h2>
  <font color="black">そして、マルチビューから得られた情報に基づいて脳腫瘍を確認する包括的な決定を下します。この診断プロセスに触発され、データセットに隠された3D情報をさらに活用するために、この論文ではマルチビューダイナミクスを提案します。脳腫瘍セグメンテーションのパフォーマンスを改善するための融合フレームワーク..さらに、提案されたフレームワークは、他の対応する方法と比較して、より良いセグメンテーションパフォーマンスとより高い効率を達成します。 
[概要]提案されたフレームワークは、異なるビューから脳腫瘍をセグメント化するためのマルチ学習ネットワークを表すマルチビューディープニューラルネットワークアーキテクチャで構成されています。マルチビューからの融合結果は、セグメンテーションよりも優れたパフォーマンスを達成することがわかります。単一のビューからの結果</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Causal Contextual Prediction for Learned Image Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/eess.IV/paper_10.html">
      <font color="black">Causal Contextual Prediction for Learned Image Compression</font>
    </a>
  </h2>
  <font color="black">これら2つのモデルはどちらも、オーバーヘッドを送信せずにエントロピー推定を容易にします。チャネル間で潜在性を分離し、チャネル間の関係を利用して非常に有益なコンテキストを生成する因果コンテキストモデルを提案します。潜在空間の空間依存性をキャプチャするには、以前の研究では、ハイパープライアおよび空間コンテキストモデルを利用して、エンドツーエンドのレート歪み最適化のビットレートを推定するエントロピーモデルを構築しました。 
[概要]最近学習した画像コーデックは通常、オートエンコーダに基づいています。最初に画像を低ハイパー潜在表現にエンコードし、次に再構成の目的でデコードします。これらのモデルは、2つの側面から最適ではありません。潜在間の空間的にグローバルな相関関係をキャプチャできません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-19">
        <br><font color="black">2020-11-19</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Deep Hyperspectral Image Classification Performance with
  Spectral Unmixing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/eess.IV/paper_11.html">
      <font color="black">Improving Deep Hyperspectral Image Classification Performance with
  Spectral Unmixing</font>
    </a>
  </h2>
  <font color="black">提案手法の有効性は、アブレーション研究と比較実験によって検証されます。次に、複数のHSIからの存在量表現を収集して、拡大データセットを形成します。まず、すべてのHSIをスペクトルドメインから存在量ドメインに変換します。データセット固有のオートエンコーダ。 
[要約]単純な分類器と拡大されたトレーニングデータを使用するために提案された方法。関連するすべてのhsiデータセットを予測するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-01">
        <br><font color="black">2020-04-01</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic radiomics: a new methodology to extract quantitative
  time-related features from tomographic images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/eess.IV/paper_12.html">
      <font color="black">Dynamic radiomics: a new methodology to extract quantitative
  time-related features from tomographic images</font>
    </a>
  </h2>
  <font color="black">最初に動的ラジオミクスの数学的パラダイムを定義し、時間の経過に伴う特徴の変換プロセスを説明できる3つの特定の方法を紹介します。3つの異なる臨床問題を使用して、従来の2Dおよび3D静的特徴で提案された動的特徴のパフォーマンスを検証します。ラジオミクスの特徴抽出法は、主に特定の瞬間の静止断層画像に基づいていますが、病気の発生と進行は動的なプロセスであり、静的な特性だけでは完全に反映することはできません。 
[概要]新しい動的ラジオミクス特徴抽出ワークフローが開発されています。これは、同じ患者の時間依存の断層画像を使用し、時間の経過に伴う画像特徴の変化に焦点を当てています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-01">
        <br><font color="black">2020-11-01</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Optimizing Deep Neural Networks through Neuroevolution with Stochastic
  Gradient Descent -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_0.html">
      <font color="black">Optimizing Deep Neural Networks through Neuroevolution with Stochastic
  Gradient Descent</font>
    </a>
  </h2>
  <font color="black">階層的クラスターベースの抑制アルゴリズムも開発され、個体群の多様性を改善するために個人間の同様の重みの更新を克服します。代替アプローチとして、ニューロエボリューションは進化プロセスとより一致しており、SGDでは利用できないことが多いいくつかの重要な機能を提供します。ニューロエボリューションにおける個々のコラボレーションに基づくヒューリスティックブラックボックス検索戦略として..実験結果は、提案されたアプローチによって最適化された4つのDNNが、すべてのデータセットでSGDのみによって最適化された対応するDNNよりも優れていることを示しています。 
[概要]提案されたアプローチは、ニューロエボリューションとsgd.itを組み合わせて、進化的検索と最適なdnnsの効果的なプローブを可能にします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Image-based plant disease diagonasis with unsupervised anomaly detection
  based on reconstructability of colors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_1.html">
      <font color="black">Image-based plant disease diagonasis with unsupervised anomaly detection
  based on reconstructability of colors</font>
    </a>
  </h2>
  <font color="black">深層学習に基づく教師あり画像分類器は、植物の病気を特定するための強力なツールになる可能性がありますが、健康と病気のラベルが付けられた大量のデータセットが必要です。この作業の主な貢献は次のとおりです。（i）提案するpix2pixと呼ばれる条件付き敵対ネットワークを利用した新しい画像ベースの植物病害検出フレームワーク（ii）CIEDE2000の色差から計算された新しい異常スコアを導入します。PlantVillageデータセットを使用した実験を通じて、私たちの方法が既存のものより優れていることを示します正確性、解釈可能性、計算効率の観点から病気の作物画像を識別するためのAnoGANと呼ばれる異常検出器。 
[ABSTRACT]異常検出と呼ばれるデータマイニング技術には、まれなサンプルを必要としない教師なしアプローチが含まれます。提案された方法は、植物画像の色の再構成可能性に焦点を当てています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-29">
        <br><font color="black">2020-11-29</font>
      </time>
    </span>
</section>
<!-- paper0: On Success and Simplicity: A Second Look at Transferable Targeted
  Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_2.html">
      <font color="black">On Success and Simplicity: A Second Look at Transferable Targeted
  Attacks</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、標的型攻撃の転送可能性を再検討し、従来の評価手順の死角のために難易度が過大評価されていることを示します。具体的には、現在の作業では、攻撃の最適化が数回の反復に不当に制限されています。ここでは、標的型攻撃がゆっくりと収束して最適な転送可能性になり、反復回数を増やすと大幅に改善されることを示します。 
[ABSTRACT]既存の研究では、高度な損失や大規模なトレーニングに頼ることで、標的型攻撃の転送可能性を目指しています。より複雑な損失を超えても、標的ロジットを単純に最大化する攻撃は驚くほどうまく機能することを実証しました。また、攻撃が摂動を生み出すことも実証しました。これは、ターゲットの現実を反映しており、追加のトレーニング画像なしでターゲットを絞った普遍的な敵対的摂動を作成することができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Disease Forecast via Progression Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_3.html">
      <font color="black">Disease Forecast via Progression Learning</font>
    </a>
  </h2>
  <font color="black">生成モデルは、履歴データの依存関係を活用するために、リカレントニューラルネットワークによって実装されます。これら2つの要因をモデル化するために、DFPLにそれぞれ現在および進行予測子を導入します。具体的には、この事前情報に基づいて、将来の疾患の予測に寄与する2つの要因を分解します：i）現在のデータ（網膜画像、臨床属性）を与えられた現在の疾患ラベル、およびii）現在から現在の網膜画像の進行を与えられた将来の疾患ラベル未来。 
[概要]現在のデータと将来の疾患ラベルが遅い現在の疾患ラベル。これらの要因は、将来の疾患予測の可能性のせいです。これらは、現在の段階までの履歴データを十分に活用する方法を説明するのに役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Abnormal respiratory patterns classifier may contribute to large-scale
  screening of people infected with COVID-19 in an accurate and unobtrusive
  manner -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_4.html">
      <font color="black">Abnormal respiratory patterns classifier may contribute to large-scale
  screening of people infected with COVID-19 in an accurate and unobtrusive
  manner</font>
    </a>
  </h2>
  <font color="black">1人の被験者と2人の被験者の状況で機能するこの方法のデモビデオをオンラインでダウンロードできます。エピデミックの予防と管理の期間中、私たちの研究はCOVID-19（小説）に感染した患者の予後、診断、スクリーニングに役立ちます。コロナウイルス）呼吸特性に基づく..COVID-19に感染した人はより急速な呼吸をします。 
[ABSTRACT] covid-19、新しいコロナウイルスは、事前に実用化することができます。データは、深いモデルを取得するためのトレーニングには不十分です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-12">
        <br><font color="black">2020-02-12</font>
      </time>
    </span>
</section>
<!-- paper0: SENTRY: Selective Entropy Optimization via Committee Consistency for
  Unsupervised Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_5.html">
      <font color="black">SENTRY: Selective Entropy Optimization via Committee Consistency for
  Unsupervised Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">ランダム画像変換の委員会の下での予測整合性に基づいてターゲットインスタンスの信頼性を判断するUDAアルゴリズムであるCommitteeConsistency（SENTRY）による選択的エントロピー最適化を提案します。疑似ラベルベースの近似ターゲットクラスバランシングと組み合わせて、このアプローチにより、標準のUDAベンチマークおよびラベル分布シフトの下での適応をストレステストするように設計されたベンチマークからの27/31ドメインシフトに関する最新技術が大幅に改善されます。次に、アルゴリズムが予測エントロピーを選択的に最小化して信頼性を高めます。非常に一貫性のあるターゲットインスタンスで、予測エントロピーを最大化して、非常に一貫性のないインスタンスの信頼性を低下させます。 
[概要]調査は、ターゲットの疑似ラベルを使用したセルフトレーニングに基づいていますが、シフトが難しい場合は、信頼性が非常に低くなる可能性があります。これにより、エラーやドメインの不整合が発生する可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: PC-RGNN: Point Cloud Completion and Graph Neural Network for 3D Object
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_6.html">
      <font color="black">PC-RGNN: Point Cloud Completion and Graph Neural Network for 3D Object
  Detection</font>
    </a>
  </h2>
  <font color="black">一方では、ポイントクラウド完了モジュールを導入して、元の構造を保持したまま、密なポイントとビュー全体の高品質な提案を復元します。KITTIベンチマークでの広範な実験は、提案されたアプローチが以前の状態よりも優れていることを示しています。アートベースラインを目覚ましいマージンで、その有効性を強調します。一方、グラフニューラルネットワークモジュールが設計されています。これは、ローカル-グローバルアテンションメカニズムとマルチスケールグラフベースのコンテキスト集約を通じてポイント間の関係を包括的にキャプチャし、大幅に強化します。エンコードされた機能。 
[概要] pc-rgnnの概念が新しい論文で提案されています。開発中のパターンニューラルネットワークモジュールに従います。概念をどれだけ効果的に開発できるかを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-18">
        <br><font color="black">2020-12-18</font>
      </time>
    </span>
</section>
<!-- paper0: Using Feature Alignment Can Improve Clean Average Precision and
  Adversarial Robustness in Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_7.html">
      <font color="black">Using Feature Alignment Can Improve Clean Average Precision and
  Adversarial Robustness in Object Detection</font>
    </a>
  </h2>
  <font color="black">クリーンな画像での2Dオブジェクト検出は十分に研究されたトピックですが、敵対的攻撃に対する脆弱性は依然として懸念されています。PASCALVOCおよびMS-COCOデータセットで広範な実験を行い、提案されたアプローチの有効性を検証します。私たちの実験はhttps://github.com/grispeut/Feature-Alignment.gitで入手できます。 
[概要]実験コードはpascalのgrispeutで入手できます。敵対者のトレーニングに基づいて入手できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-08">
        <br><font color="black">2020-12-08</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Unsupervised Image Clustering With Robust Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_8.html">
      <font color="black">Improving Unsupervised Image Clustering With Robust Learning</font>
    </a>
  </h2>
  <font color="black">このモデルの柔軟な構造により、最先端のクラスタリング手法のアドオンモジュールとして使用できるようになり、複数のデータセットでパフォーマンスを向上させることができます。その再トレーニングプロセスにより、知識の不整合を修正し、自信過剰の問題を軽減できます。予測..広範な実験は、提案されたモデルがより良いキャリブレーションでモデルの信頼性を調整し、敵対的なノイズに対する追加のロバスト性を得ることができることを示しています。 
[概要]新しいモデルのrucは、堅牢な学習に触発されています。再トレーニングプロセスにより、不整合な知識を修正できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Amplifying the Anterior-Posterior Difference via Data Enhancement -- A
  More Robust Deep Monocular Orientation Estimation Solution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_9.html">
      <font color="black">Amplifying the Anterior-Posterior Difference via Data Enhancement -- A
  More Robust Deep Monocular Orientation Estimation Solution</font>
    </a>
  </h2>
  <font color="black">次に、トレーニングされた半円予測モデルは、範囲$ 
[0、\ pi] $の値を予測する方向角推定モデルに統合されます。提案された方法では、バックボーンは、適切に設計されたネットワーク構造を使用した既存のアプローチ..実験結果は、提案された半円予測が標定推定の精度を高め、上記の問題を軽減することを示しています。 
[概要]以前の研究では、提案された半円予測が方向推定の精度を高め、問題を軽減することが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Feature Space Trojan Attack of Neural Networks by Controlled
  Detoxification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_10.html">
      <font color="black">Deep Feature Space Trojan Attack of Neural Networks by Controlled
  Detoxification</font>
    </a>
  </h2>
  <font color="black">多くの既存のトロイの木馬攻撃のトリガーは、入力スペースパッチ/オブジェクト（たとえば、単色のポリゴン）またはInstagramフィルターなどの単純な入力変換です。有効性、ステルス性、制御性の5つの特性を備えた新しい深層空間トロイの木馬攻撃を提案します。 、堅牢性、およびディープ機能への依存..トロイの木馬（バックドア）攻撃は、攻撃者が悪意のあるデータでトレーニング/再トレーニングされたモデルを被害者に提供する、ディープニューラルネットワークに対する敵対的攻撃の一種です。 
[概要]通常の入力に特定のパターンがスタンプされるとバックドアがアクティブになり、誤分類が発生する可能性があります。これらの単純なトリガーは、最近のバックドア検出アルゴリズムの影響を受けやすくなっています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Predictive Analysis of Diabetic Retinopathy with Transfer Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_11.html">
      <font color="black">Predictive Analysis of Diabetic Retinopathy with Transfer Learning</font>
    </a>
  </h2>
  <font color="black">早期発見と治療は、患者への損傷の程度を減らすのに役立ちます。結果は、VGG 16モデルを使用したImageNetウェイトによる転送学習が、95％の最高の精度で最高の分類パフォーマンスを示すことを示しています。分類パフォーマンスは、いくつかを使用して分析されます。真陽性率、偽陽性率、精度などを含むパフォーマンス指標。
[要約]この病気は、最も生産的な年の個人に主に影響を及ぼします。研究は、vgg16、resnet50 v2、およびefficiencynetb0モデルに焦点を当てています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-08">
        <br><font color="black">2020-11-08</font>
      </time>
    </span>
</section>
<!-- paper0: An Overview of Facial Micro-Expression Analysis: Data, Methodology and
  Challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_12.html">
      <font color="black">An Overview of Facial Micro-Expression Analysis: Data, Methodology and
  Challenge</font>
    </a>
  </h2>
  <font color="black">さらに、限られた偏ったMEデータの問題を軽減するために、合成データ生成が調査され、微量発現データの多様性が強化されます。警察の尋問、臨床診断、うつ病分析、および商談。微量発現スポッティングは後押しできるため微量発現分析、最先端のスポッティング作業もこの論文で紹介されています。 
[概要] 3つの新しい側面からマーのアプローチをレビューします：マクロ-から-ミクロへの適応と顔のアクションユニットに基づく認識</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Growing Spatial Graph Network for Context-Aware Pedestrian
  Trajectory Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_13.html">
      <font color="black">Self-Growing Spatial Graph Network for Context-Aware Pedestrian
  Trajectory Prediction</font>
    </a>
  </h2>
  <font color="black">広く使用されているデータセットに基づく実験では、私たちの方法が最先端の方法よりも優れていることが示されています。私たちの最高のパフォーマンスモデルは、ETH-UCYデータセットで12 cmADEと$ \ sim $ 15 cmFDEを達成します。提案された方法はわずか0.49です。フレームごとに合計20Kの将来の軌道をサンプリングする場合の秒数。 
[ABSTRACT]既存の作品は、シーンとダイナミクスに関する空間的な仮定に依存しています。提案された方法は、フレームごとに合計20kの将来の軌道をサンプリングする場合、わずか0.49秒かかります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-11">
        <br><font color="black">2020-12-11</font>
      </time>
    </span>
</section>
<!-- paper0: Centralized Information Interaction for Salient Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_14.html">
      <font color="black">Centralized Information Interaction for Salient Object Detection</font>
    </a>
  </h2>
  <font color="black">上記の戦略とモジュールの恩恵を受けて、提案されたアプローチは、いくつかの追加パラメータを導入するだけで、より効果的に特徴を集約できます。U字型構造は、マルチスケール特徴を効率的に組み合わせるための顕著なオブジェクト検出においてその利点を示しています。新たに提案された戦略の可能性として、空間補間なしでマルチスケール入力を同時に処理できる相対グローバルキャリブレーションモジュールをさらに設計します。 
[概要]既存のu-形状ベースの方法は、ボトムアップとトップダウンの相互作用の改善に焦点を当てています。現在、ほとんどの既存のuターンベースの方法は、接続の改善に焦点を当てています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Image Translation via Fine-grained Knowledge Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_15.html">
      <font color="black">Image Translation via Fine-grained Knowledge Transfer</font>
    </a>
  </h2>
  <font color="black">さらに、膨大な知識ライブラリでの検索の難しさに対処するために、高速ANN検索アプローチであるBandpass Hierarchical K-Means（BHKM）を紹介します。広範な実験により、さまざまな画像翻訳タスクにおけるフレームワークの有効性と実現可能性が十分に実証されています。 ..本論文では、知識の検索と転送を通じて画像翻訳を実現する、解釈可能な知識ベースの画像翻訳フレームワークを提案する。 
[概要]コードはまもなくwwwで入手できるようになります。 github。 com / acesix</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: EMLight: Lighting Estimation via Spherical Distribution Approximation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_16.html">
      <font color="black">EMLight: Lighting Estimation via Spherical Distribution Approximation</font>
    </a>
  </h2>
  <font color="black">単一の画像からの照明推定は3Dレンダリングで重要であり、コンピュータービジョンおよびコンピューターグラフィック研究コミュニティで広く調査されています。広範な実験により、EMLightが正確な照明推定を実現し、3Dオブジェクト埋め込みで生成された再照明が優れた妥当性と忠実度を示すことが示されています。最先端の方法と比較して..EarthMoverの距離に動機付けられて、球形分布の微妙さを利用することにより、光分布パラメーターを正確に回帰するように導く新しい球形ムーバーの損失を設計します。 
[概要]イラストマップを球面光フレームワーク、光強度、周囲項に分解し、イラスト損失タスクを定義します。ニューラルプロジェクターは、現実的な光周波数でパノラマイラストマップを合成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Monocular Depth Parameterizing Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_17.html">
      <font color="black">Monocular Depth Parameterizing Networks</font>
    </a>
  </h2>
  <font color="black">パラメータ化を最適化することで、他の画像に関して写真の一貫性のあるソリューションの形状を検索できます。対照的に、複数のカメラを使用する従来のステレオ手法では、ピクセルマッチングが可能な場合に、非常に正確な推定が可能になります。単一の画像で観察することは困難であるだけでなく、学習の問題を緩和して、比較的小さなネットワークを使用できるようにします。 
[概要]新しい調査によると、私たちの方法は、競合する最先端のアプローチよりも正確な深度マップを生成し、一般化することができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Diverse Knowledge Distillation for End-to-End Person Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_18.html">
      <font color="black">Diverse Knowledge Distillation for End-to-End Person Search</font>
    </a>
  </h2>
  <font color="black">この目的のために、ボトルネックを解消するための多様な知識蒸留を備えたシンプルでありながら強力なエンドツーエンドネットワークを提案します。エンドツーエンドアプローチはより高い推論効率をもたらしますが、これらの2段階のアプローチよりも大幅に遅れています。正確さの..人の検索は、画像のギャラリーから特定の人をローカライズして識別することを目的としています。 
[ABSTRACT]最近の方法は、2つのステップとエンドツーエンドのアプローチに定義できます。これらには、エンドのネットワークであるre --id subが含まれます。これは、2種類のメソッド間のギャップが主にリードネットワークによって引き起こされます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Sim-to-real for high-resolution optical tactile sensing: From images to
  3D contact force distributions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_19.html">
      <font color="black">Sim-to-real for high-resolution optical tactile sensing: From images to
  3D contact force distributions</font>
    </a>
  </h2>
  <font color="black">この記事では、柔らかい材料内の球状粒子の動きを追跡する内部カメラに基づく視覚ベースの触覚センサーのシミュレーションで触覚画像を生成する戦略を提案します。材料の変形は、有限要素環境でシミュレートされます。さまざまな接触条件のセット、および球状粒子がシミュレートされた画像に投影されます。視覚ベースの触覚センサーによってキャプチャされた画像は、ソフトセンシング表面に適用される接触力の分布など、高解像度の触覚フィールドに関する情報を伝達します。 
[概要]画像にエンコードされた情報を抽出することは困難であり、学習ベースの視覚ベースの視覚ベースの視覚ベースの手法で対処されることがよくあります。結果として得られるモデルは、実世界の触覚画像で評価すると高精度を示し、複数の触覚間で転送可能です。さらなるトレーニングなしのセンサー</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Generalized Adversarially Learned Inference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_20.html">
      <font color="black">Generalized Adversarially Learned Inference</font>
    </a>
  </h2>
  <font color="black">ジェネレーターとエンコーダーのペアの非飽和最大化目標を設計し、結果として得られる敵対的ゲームが、すべての分布に同時に一致するグローバル最適化に対応することを証明します。GANのトレーニング中に潜在ベクトルの効果的な推論を可能にすることで、さまざまなアプリケーションでの適用性を大幅に高めることができます。ダウンストリームタスク..提案されたフレームワーク内で、パッチレベルの対応や再構成のサイクルの一貫性などのプロパティに基づいて、モデルに自己監視フィードバックを提供するための新しい一連の手法を紹介します。 
[要約]アリやビガンなどの最近のアプローチは、ガンの潜在変数をハンティングする方法を開発しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
</section>
<!-- paper0: DAQ: Distribution-Aware Quantization for Deep Image Super-Resolution
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_21.html">
      <font color="black">DAQ: Distribution-Aware Quantization for Deep Image Super-Resolution
  Networks</font>
    </a>
  </h2>
  <font color="black">私たちの知る限り、この低精度に対する脆弱性は、特徴マップ値の2つの統計的観測に依存しています。DAQの単純な関数は、計算負荷の少ない特徴マップと重みのダイナミックレンジを決定します。さらに、この方法では、計算によって混合精度の量子化が可能です。トレーニングプロセスを伴わない、各チャネルの相対感度。 
[概要]既存の作品は、超低精度でパフォーマンスが大幅に低下します。新しい方法は、最新の画像超解像ネットワークに対する最近のトレーニング（無料およびトレーニングベースの量子化方法）よりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Exploiting Vulnerability of Pooling in Convolutional Neural Networks by
  Strict Layer-Output Manipulation for Adversarial Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_22.html">
      <font color="black">Exploiting Vulnerability of Pooling in Convolutional Neural Networks by
  Strict Layer-Output Manipulation for Adversarial Attacks</font>
    </a>
  </h2>
  <font color="black">最初に、Strict Layer-Output Manipulation（SLOM）という名前の新しい敵対的攻撃手法を提案します。さまざまな深度でのSPMに基づく攻撃のパフォーマンスも調査および比較します。この論文では、CNNに対して次の観点から敵対的攻撃を行います。プーリングの脆弱性を調査および悪用することによるネットワーク構造。 
[概要]ロボットアプリケーションにおけるcnnのセキュリティは重要な問題であり、cnnに対する潜在的な敵対的攻撃は調査する価値があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Towards the Localisation of Lesions in Diabetic Retinopathy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_23.html">
      <font color="black">Towards the Localisation of Lesions in Diabetic Retinopathy</font>
    </a>
  </h2>
  <font color="black">眼科医が予測を非常に役立つようにするために、深層学習モデルの最後から2番目のレイヤーで勾配加重クラスアクティベーションマッピング（Grad-CAM）と呼ばれる注意後の手法を使用して、DR眼底画像上に粗いローカリゼーションマップを作成します。InceptionV3 96.07％のテスト分類精度で最高のパフォーマンスを達成し、他のモデルよりも優れた速度で病変を特定します。具体的には、この研究では、4つの最先端の深層学習モデルから事前にトレーニングされた重みを使用して生成します。 DR眼底画像のローカリゼーションマップを比較します。 
[概要]これは、画像内の識別領域を特定するのに役立ちます。これは、眼科医が診断を行うのに十分な証拠を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Estimating Displaced Populations from Overhead -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_24.html">
      <font color="black">Estimating Displaced Populations from Overhead</font>
    </a>
  </h2>
  <font color="black">私たちの提案するアプローチは、隔離されたキャンプ画像で7.02％の平均絶対パーセント誤差を達成します。実際の変位キャンプデータを使用した実験は、人道コミュニティが世界的な変位に効果的かつ迅速に対応できるようにするツールの開発に向けた重要なステップを構成すると考えています。危機.. 2018年と2019年にバングラデシュのコックスバザールにある難民キャンプの人口データと相互参照されたドローン画像に関するアプローチをトレーニングおよび評価します。
[概要]ドローン画像に関するアプローチをトレーニングおよび評価します。 -世界避難キャンプのデータは、ツールの開発に向けた重要なステップです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-25">
        <br><font color="black">2020-06-25</font>
      </time>
    </span>
</section>
<!-- paper0: CNN-Based Ultrasound Image Reconstruction for Ultrafast Displacement
  Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_25.html">
      <font color="black">CNN-Based Ultrasound Image Reconstruction for Ultrafast Displacement
  Tracking</font>
    </a>
  </h2>
  <font color="black">この目的のために、相互相関に基づくスペックルトラッキングアルゴリズムと組み合わせた畳み込みニューラルネットワークベースの画像再構成法を展開しました。これらの動き推定手法で達成可能な精度は、2つの相反する要件に強く依存します。連続フレームの高品質。確かに、画質は通常、ステアリングされた超高速取得の数を増やすことで改善できますが、フレームレートが低下し、モーションアーティファクトが発生する可能性があります。 
[要約]提案されたアプローチは、高品質のフレームを再構築するために単一の超高速取得に依存し、迅速に取得するために2つの連続したフレームのみに依存します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Automated segmentation of an intensity calibration phantom in clinical
  CT images using a convolutional neural network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_26.html">
      <font color="black">Automated segmentation of an intensity calibration phantom in clinical
  CT images using a convolutional neural network</font>
    </a>
  </h2>
  <font color="black">テストケースの場合、相関係数の中央値は1つの機関で0.9998、もう1つの機関で0.9999で、最小値は0.9863でした。CNNモデルのセグメンテーション精度は、ダイス係数と平均対称表面距離（ASD）で評価されました。結論：CNNモデルは、CT画像内のキャリブレーションファントムの領域を優れた精度でセグメント化することに成功し、自動化された方法は少なくとも従来の手動による方法と同等であることがわかりました。 
[ABSTRACT]ファントム（b-mas200、京都カガク、京都、日本）が使用されました。cnnのテストシステムは残りの1000ケースでテストされました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Reducing the Teacher-Student Gap via Spherical Knowledge Disitllation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_27.html">
      <font color="black">Reducing the Teacher-Student Gap via Spherical Knowledge Disitllation</font>
    </a>
  </h2>
  <font color="black">この新しい知識表現は、はるかに大きな教師がいるコンパクトなモデルを改善でき、温度に対してロバストであることがわかります。知識蒸留は、はるかに大きなモデルからマッピング関数を学習することにより、コンパクトで効果的なモデルを取得することを目的としています。このギャップを明示的に指定すると、適合不足の問題が緩和されます。 
[要約]蒸留は不適合の問題を緩和する可能性がある、とgithubは言います。これは生徒の限られた能力に基づいており、生徒は教師を過小評価します。したがって、生徒は教師間の信頼のギャップを研究することで過小評価することができます。と学生。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Accurate Object Association and Pose Updating for Semantic SLAM -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_28.html">
      <font color="black">Accurate Object Association and Pose Updating for Semantic SLAM</font>
    </a>
  </h2>
  <font color="black">提案された方法は、Kittiデータセット内のシミュレートされたシーケンスといくつかのシーケンスで評価されます。実験結果は、従来のSLAMおよび最先端のセマンティックSLAM方法に関して非常に印象的な改善を示しています。セマンティックSLAM、データの関連付けにセマンティック情報を正しく使用する方法は、まだ研究に値する問題です。 
[概要]この問題を解決するための鍵は、1つのオブジェクトランドマークの複数のオブジェクト測定値を正しく関連付け、オブジェクトランドマークのポーズを調整することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Infrared image pedestrian target detection based on Yolov3 and migration
  learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_29.html">
      <font color="black">Infrared image pedestrian target detection based on Yolov3 and migration
  learning</font>
    </a>
  </h2>
  <font color="black">実験結果は、CVCデータセットの歩行者検出タスクでは、Yolov3モデルの平均精度（AP）が96.35％に達し、Diou-Yolov3モデルの平均精度（AP）が72.14％であるが、後者の方が損失曲線の収束率が速いことを示しています。 ..自動運転における赤外線ナイトビジョン車両支援システムの段階的な適用により、歩行者の収集された赤外線画像の精度は徐々に向上します。ターゲット検出モデルYOLOv3はCVC赤外線歩行者データセットに移行され、Diou損失は元のYOLOモデルの損失関数を置き換えて、さまざまなスーパーパラメーターをテストし、最良の移行学習効果を取得するために使用されます。 
[概要]移行学習法を使用して、yolov3モデルを適用し、赤外線画像での歩行者ターゲットの検出を実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Local Neighboring Structure for Robust 3D Shape Representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_30.html">
      <font color="black">Learning Local Neighboring Structure for Robust 3D Shape Representation</font>
    </a>
  </h2>
  <font color="black">ただし、等方性フィルターまたは事前定義されたローカル座標系は表現力を制限します。この論文では、ローカル隣接構造に従って各ノードの適応加重行列を学習し、実行するローカル構造認識異方性畳み込み演算（LSA-Conv）を提案します。共有異方性フィルター..グラフ上のノードの不整合を克服するために、等方性フィルターまたは事前定義されたローカル座標系を使用して、3D形状のさまざまなグラフニューラルネットワークが開発されました。 
[ABSTRACT]表現等方性フィルターまたは事前定義されたローカル座標系は、表現力を制限します。実際、学習可能な重み付け行列は、ランダムシンセサイザーの注意行列に似ています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br><font color="black">2020-04-21</font>
      </time>
    </span>
</section>
<!-- paper0: Searching for Controllable Image Restoration Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_31.html">
      <font color="black">Searching for Controllable Image Restoration Networks</font>
    </a>
  </h2>
  <font color="black">27の画像効果を生成するときにFLOPの95.7％を削減し、4K解像度の画像でGPUレイテンシを73.0％高速化します。共有レイヤーでは機能の再利用が可能であるため、タスクに依存しないレイヤーの単一の推論のみが必要です。入力画像から複数の画像効果を生成します。提案されたタスクに依存しないおよびタスク固有のプルーニングスキームを一緒に使用すると、ベースラインと比較して、FLOPと推論の実際の待ち時間が大幅に削減されます。 
[要約]提案されたタスク-失認とタスク-特定の剪定スキームは、ベースラインと比較して、フロップと結論の実際の待ち時間を大幅に削減します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Knowledge Transfer Based Fine-grained Visual Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_32.html">
      <font color="black">Knowledge Transfer Based Fine-grained Visual Classification</font>
    </a>
  </h2>
  <font color="black">この論文では、知識移転学習の方法でこれに対処します。いくつかの既存の研究は、いくつかの検出技術または注意メカニズムによってより識別力のある領域をマイニングすることによってこの問題を解決しようとします。より識別力のある地域を見つけるために。 
[ABSTRACT]畳み込みニューラルネットワーク（cnns）はパフォーマンスが低いことを示しています。モデルは最も識別力のある部分のみを学習し、他の意味のある領域を無視できます。ただし、既存の領域は、より識別力のある領域を見つけようとすると、背景の問題に直面します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Better Than Ground-truth? Beyond Supervised Learning for Photoacoustic
  Imaging Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_33.html">
      <font color="black">Better Than Ground-truth? Beyond Supervised Learning for Photoacoustic
  Imaging Reconstruction</font>
    </a>
  </h2>
  <font color="black">グラウンドトゥルースの品質への依存を減らすために、本論文では、初めて、深層学習に基づく教師あり再構成フレームワーク（BSR-Net）を提案し、限定ビュー位置をフィードすることによって限定ビューの問題を補償します賢明なデータ..さらに、アーティファクトを抑制するために2つの新しい損失が設計されています。具体的には、私たちの方法は、教師あり再構成結果を超えて生成する残差構造を導入します。 
[ABSTRACT]モデルモデルモデルを使用して、モデルモデルモデルをモデル化およびモデル化できます。モデルモデルは、さまざまなモデルを使用して再構築できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-04">
        <br><font color="black">2020-12-04</font>
      </time>
    </span>
</section>
<!-- paper0: Improving unsupervised anomaly localization by applying multi-scale
  memories to autoencoders -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_34.html">
      <font color="black">Improving unsupervised anomaly localization by applying multi-scale
  memories to autoencoders</font>
    </a>
  </h2>
  <font color="black">オートエンコーダーとその変種は、異常検出に広く適用されています。以前の作業メモリー拡張ディープオートエンコーダーは、異常を検出するために正規性を記憶することを提案しましたが、異なる解像度スケール間の機能の不一致を無視しているため、スケール固有の記録にマルチスケールメモリを導入します。異常検出用のオートエンコーダのエンコーディングモジュールとデコーディングモジュール間の機能とマルチスケールアテンションフューザー、つまりMMAE.MMAEは、教師なし学習中にプロトタイプ機能として対応する解像度スケールでスロットを更新します。さまざまなデータセットでの実験結果は、MMAEが異常を正常に除去することを証明しています。さまざまなスケールで、同様の再構成ベースの方法と比較して、いくつかのデータセットで良好に機能します。異常検出では、各スケールで元のエンコードされた画像の特徴を最も関連性の高いプロトタイプの特徴に置き換えることで異常の除去を実現し、これらの特徴を融合してから再デコードするモジュール画像を作成します。 
[ABSTRACT]コード検出の場合、元のエンコードされた画像の特徴をデコードモジュールとして置き換えることにより、異常の除去を実現します。結果は、データのメモリのスケールで取得されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Learning content and context with language bias for Visual Question
  Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_35.html">
      <font color="black">Learning content and context with language bias for Visual Question
  Answering</font>
    </a>
  </h2>
  <font color="black">ただし、言語バイアスを減らすと、VQAモデルが事前にコンテキストを学習する能力も弱まります。具体的には、CCBはベースVQAモデルの上にコンテンツブランチとコンテキストブランチを確立し、ローカルキーコンテンツとグローバル有効コンテキストにそれぞれ焦点を合わせるように強制します。この問題に対処するために、CCBという名前の新しい学習戦略を提案します。これにより、VQAモデルは、言語バイアスを使用してコンテンツとコンテキストに依存する質問に回答するようになります。 
[概要]新しい戦略はccbと呼ばれ、vqaモデルに言語バイアスのあるコンテンツとコンテキストに依存する質問に回答するように強制します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Diagnosis of Pneumothorax from Chest Radiographs: A Systematic
  Literature Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_36.html">
      <font color="black">Automatic Diagnosis of Pneumothorax from Chest Radiographs: A Systematic
  Literature Review</font>
    </a>
  </h2>
  <font color="black">この研究は、胸部X線からの気胸の自動検出に関する既存の文献を要約し、利用可能な胸部X線写真データセットを説明します。文献の比較分析は、既存の文献の良さと限界の観点からも提供されます。さらに調査する必要がある研究ギャップ..さまざまな医療画像ツールの中で、胸部X線写真は、胸部病変の検出に最も重要で広く使用されている診断ツールです。 
[要約]胸部X線写真から気胸を自動的かつ迅速に検出するための研究が行われています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Physically Based Neural Simulator for Garment Animation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_37.html">
      <font color="black">Physically Based Neural Simulator for Garment Animation</font>
    </a>
  </h2>
  <font color="black">あるいは、制約のあるシナリオで高価な4Dスキャンを介してデータを収集することもできます。私たちの知る限り、布の神経シミュレーターを最初に提案します。暗黙のPBSとして定式化された深層学習を使用して、正確に学習することを提案します。制約されたシナリオでの布の変形：服を着た人間。 
[概要]コンピュータグラフィックスのアプローチは、物理ベースのシミュレーション（pbs）に依存して衣服をアニメーション化します。これらは暗黙的に高価であり、再シミュレーションが必要です。これらのアイデアには、データ収集のためのコンピューティングリソースへの多大な投資が必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: A Naturalness Evaluation Database for Video Prediction Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_38.html">
      <font color="black">A Naturalness Evaluation Database for Video Prediction Models</font>
    </a>
  </h2>
  <font color="black">私たちの機能設計が、IISc VINEデータベースでの人間の判断に従って、最先端の自然性予測につながることを示します。ビデオ予測モデルの研究は、ビデオの表現学習への基本的なアプローチであると考えられています。私たちの主観的な研究は、人間の観察者は、自然の判断において非常に一貫していたこと。 
[概要]インド科学研究所のビデオ自然性評価（iisc vine）データベースは、さまざまなデータセットにさまざまな予測モデルを適用して取得した300本のビデオで構成されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: Equivariant Neural Rendering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_39.html">
      <font color="black">Equivariant Neural Rendering</font>
    </a>
  </h2>
  <font color="black">実験を通じて、モデルがこれらのデータセットと標準のShapeNetベンチマークで説得力のある結果を達成することを示します。さらに、複雑な照明と背景を持つシーンを含む、シーン表現とニューラルレンダリングのための2つの挑戦的な新しいデータセットを紹介します。 3D変換に関してシーン表現の同変を強制する損失を導入します。 
[概要]私たちの紹介では、シーンをリアルタイムで推測してレンダリングすることができます。私たちのモデルがこれらのデータセットで説得力のある結果を達成していることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-13">
        <br><font color="black">2020-06-13</font>
      </time>
    </span>
</section>
<!-- paper0: Stratified Rule-Aware Network for Abstract Visual Reasoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_40.html">
      <font color="black">Stratified Rule-Aware Network for Abstract Visual Reasoning</font>
    </a>
  </h2>
  <font color="black">欠陥を修正するために、属性二分ツリー（ABT）と呼ばれる回答セット生成アルゴリズムを提案し、Impartial-RAVEN（略してI-RAVEN）という名前の改善されたデータセットを形成します。被験者は回答セットから正しい選択を特定するよう求められます。 RPMの右下にある欠落しているパネル（たとえば、3 $ \ times $ 3マトリックス）を埋めるために、マトリックス内の基本的なルールに従います。ただし、各内の順序感度など、RPMソルバーの必要な誘導バイアスを部分的に無視します。行/列および増分ルールの誘導。 
[要約]このテストは、抽象的な推論の能力を調べるために使用されます。これがシステムの変更パターンにつながることを期待していますが、欠陥を修正するためのツールとして使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-17">
        <br><font color="black">2020-02-17</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Domain Adaptation with Temporal-Consistent Self-Training
  for 3D Hand-Object Joint Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_41.html">
      <font color="black">Unsupervised Domain Adaptation with Temporal-Consistent Self-Training
  for 3D Hand-Object Joint Reconstruction</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、広く使用されている3つのベンチマークで、最先端の3D手オブジェクトジョイント再構築方法よりも優れていることを示し、コードを公開します。さらに、既存のほとんどの作業とは対照的に、監視のソースとしてラベルのない実際のビデオで利用可能な豊富な時間情報、私たちは自己監視方式でドメイン適応モデルを微調整するために短期および長期の時間的一貫性を強制することを提案します。この論文では、ドメイン適応を実行するためにサイクル生成敵対ネットワーク（CycleGAN）内の3D幾何学的制約を活用することにより、この課題に対処するための効果的なアプローチ。 
[概要]これは、3Dデータが実際の状況でうまく機能することを保証するものではありませんが、常にそうであるとは限らず、システムのテストに使用されます。これらの作業をで使用する必要があるのはこれが初めてです。 3d</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Blurring Fools the Network -- Adversarial Attacks by Feature Peak
  Suppression and Gaussian Blurring -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_42.html">
      <font color="black">Blurring Fools the Network -- Adversarial Attacks by Feature Peak
  Suppression and Gaussian Blurring</font>
    </a>
  </h2>
  <font color="black">実験結果は、PSと適切に設計されたガウスぼかしが敵対的攻撃を形成し、十分に訓練されたターゲットネットワークの分類結果を完全に変える可能性があることを示しています。PSのぼかし精神に基づいて、データにガウスぼかしをさらに適用して、可能性を調査します。ネットワークのパフォーマンスに対するガウスぼかしの影響と脅威。ガウスぼかしの強力な物理的重要性と幅広いアプリケーションにより、提案されたアプローチは実世界の攻撃を実行することもできます。 
[ABSTRACT]ガウスぼかしは、画像前処理の一般的な手法です。特定の場面で攻撃的になり、現実世界の攻撃につながる可能性があります。提案されたアプローチは、現実世界の攻撃を実行することもできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Image Annotation based on Deep Hierarchical Context Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_43.html">
      <font color="black">Image Annotation based on Deep Hierarchical Context Networks</font>
    </a>
  </h2>
  <font color="black">パラメータが最も影響力のある2レベルのコンテキスト関係に対応する基礎となるディープネットワークをトレーニングすることでこの表現学習の問題を解決し、挑戦的なImageCLEFベンチマークを使用して画像注釈でのパフォーマンスを評価します。幾何学的および意味的関係を含むコンテキストのさまざまなソースを活用するコンテキストネットワーク。ただし、コンテキストモデリングの可能性は現在十分に検討されておらず、既存のソリューションのほとんどはコンテキストフリーであるか、単純な手作りの幾何学的関係に制限されています。 
[概要]コンテキストモデリングの可能性は現在十分に検討されていません。既存のソリューションのほとんどは、コンテキストフリーであるか、単純な手作りの幾何学的関係に制限されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: A Multi-View Dynamic Fusion Framework: How to Improve the Multimodal
  Brain Tumor Segmentation from Multi-Views? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_44.html">
      <font color="black">A Multi-View Dynamic Fusion Framework: How to Improve the Multimodal
  Brain Tumor Segmentation from Multi-Views?</font>
    </a>
  </h2>
  <font color="black">さらに、提案されたフレームワークは、他の対応する方法と比較して、より優れたセグメンテーションパフォーマンスとより高い効率を実現します。脳腫瘍を診断する場合、医師は通常、アキシャルビュー、コロナルビュー、サジタルビューからマルチモーダル脳画像を観察して診断を行います。それぞれ..この診断プロセスに触発され、データセットに隠された3D情報をさらに活用するために、このペーパーでは、脳腫瘍セグメンテーションのパフォーマンスを向上させるためのマルチビュー動的融合フレームワークを提案します。 
[概要]提案されたフレームワークは、異なるビューから脳腫瘍をセグメント化するためのマルチ学習ネットワークを表すマルチビューディープニューラルネットワークアーキテクチャで構成されています。マルチビューからの融合結果は、セグメンテーションよりも優れたパフォーマンスを達成することがわかります。単一のビューからの結果</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Causal Contextual Prediction for Learned Image Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_45.html">
      <font color="black">Causal Contextual Prediction for Learned Image Compression</font>
    </a>
  </h2>
  <font color="black">これらの2つのモデルはどちらも、オーバーヘッドを送信せずにエントロピー推定を容易にします。（2）潜在性のクロスチャネル関係はまだ十分に検討されていません。潜在空間におけるエントロピー予測。 
[概要]最近学習した画像コーデックは通常、オートエンコーダに基づいています。最初に画像を低ハイパー潜在表現にエンコードし、次に再構成の目的でデコードします。これらのモデルは、2つの側面から最適ではありません。潜在間の空間的にグローバルな相関関係をキャプチャできません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-19">
        <br><font color="black">2020-11-19</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Deep Hyperspectral Image Classification Performance with
  Spectral Unmixing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_46.html">
      <font color="black">Improving Deep Hyperspectral Image Classification Performance with
  Spectral Unmixing</font>
    </a>
  </h2>
  <font color="black">次に、複数のHSIからの存在量表現を収集して、拡大されたデータセットを形成します。ニューラルネットワークの複雑さを軽減すると、ある程度の過剰適合を防ぐことができますが、より抽象的な特徴を表現するネットワークの能力も低下します。まず、すべてを変換します。データセット固有のオートエンコーダによるスペクトルドメインからアバンダンスドメインへのHSI。 
[要約]単純な分類器と拡大されたトレーニングデータを使用するために提案された方法。関連するすべてのhsiデータセットを予測するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-01">
        <br><font color="black">2020-04-01</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Object Detection with Pointformer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_47.html">
      <font color="black">3D Object Detection with Pointformer</font>
    </a>
  </h2>
  <font color="black">Global Transformerは、シーンレベルでコンテキストアウェア表現を学習するように設計されています。最先端のオブジェクト検出モデルのバックボーンとしてPointformerを使用し、屋内と屋外の両方のデータセットで元のモデルよりも大幅に改善されていることを示しています。マルチスケール表現間の依存関係をさらにキャプチャするために、ローカル機能をより高い解像度のグローバル機能と統合するローカルグローバルトランスフォーマーを提案します。 
[ABSTRACT] pointform artは、3Dポイントクラウドが機能を効果的に学習するために設計されたトランスフォーマーバックボーンです。グローバルトランスフォーマーは、シーンレベルでコンテキストアウェアな表現を学習するように設計されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Continuous Conditional Generative Adversarial Networks for Image
  Generation: Novel Losses and Label Input Mechanisms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_48.html">
      <font color="black">Continuous Conditional Generative Adversarial Networks for Image
  Generation: Novel Losses and Label Input Mechanisms</font>
    </a>
  </h2>
  <font color="black">Circular 2-D Gaussians、RC-49、UTKFace、Cell-200、およびSteering Angleデータセットに関する実験では、CcGANが特定の回帰ラベルを条件として画像分布から多様で高品質のサンプルを生成できることが示されています。2つの新しいベンチマークデータセット（RC-49およびCell-200）および新しい評価メトリック（Sliding Fr \ &#39;echet Inception Distance）も、この連続シナリオに対して提案されています。さらに、これらの実験では、CcGANは視覚的および定量的にcGANを大幅に上回っています。 
[ABSTRACT]既存の条件付きガン（cgans）は、主にカテゴリ条件（クラスラベルなど）用に設計されています。スランプラベルの条件付けは数学的に異なり、2つの基本的な問題が発生します。提案されたネットワークは、最初に既存のラボ損失を再定式化することによって問題を解決します。継続的なシナリオに適しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-15">
        <br><font color="black">2020-11-15</font>
      </time>
    </span>
</section>
<!-- paper0: ResizeMix: Mixing Data with Preserved Object Information and True Labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_49.html">
      <font color="black">ResizeMix: Mixing Data with Preserved Object Information and True Labels</font>
    </a>
  </h2>
  <font color="black">データを混合するための顕著性情報の重要性を体系的に調査し、増強性能を促進するために顕著性情報はそれほど必要ではないことを発見しました。得られたパッチは、従来のカットベースの方法と比較してより実質的なオブジェクト情報を保持します。ベースの増強戦略は大きな成功を収めています。 
[ABSTRACT]一連の作品は、画像の顕著性情報を使用してミキシングをガイドすることを探求しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: LQF: Linear Quadratic Fine-Tuning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_50.html">
      <font color="black">LQF: Linear Quadratic Fine-Tuning</font>
    </a>
  </h2>
  <font color="black">組み合わせて使用すると、線形二次最適化の単純さ、堅牢性、解釈可能性を享受しながら、同等のパフォーマンスを達成し、低データ領域でさらに優れたものにすることができます。LQFは、アーキテクチャ、損失関数、および分類に通常使用される最適化：ReLUの代わりにLeaky-ReLU、クロスエントロピーの代わりに平均二次損失、およびKronecker因数分解を使用した事前調整。DNNを線形化する以前の試みは、興味深い理論的洞察につながりましたが、標準の非線形最適化と比較して、大幅なパフォーマンスギャップが発生します。 
[概要]ディープニューラルネットワーク（dnns）は通常、非線形の細かい影響を受けたモデルによってトレーニングされます。これは、非線形の細かいネホワイトのパフォーマンスに近づくには不十分であるためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic radiomics: a new methodology to extract quantitative
  time-related features from tomographic images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CV/paper_51.html">
      <font color="black">Dynamic radiomics: a new methodology to extract quantitative
  time-related features from tomographic images</font>
    </a>
  </h2>
  <font color="black">まず、動的ラジオミクスの数学的パラダイムを定義し、時間の経過に伴う特徴の変換プロセスを説明できる3つの特定の方法を紹介します。ラジオミクスの特徴抽出方法は、主に特定の瞬間の静的断層画像に基づいています。疾患は、静的特性だけでは完全に反映できない動的プロセスです。3つの異なる臨床問題を使用して、従来の2Dおよび3D静的機能で提案された動的機能のパフォーマンスを検証します。 
[概要]新しい動的ラジオミクス特徴抽出ワークフローが開発されています。これは、同じ患者の時間依存の断層画像を使用し、時間の経過に伴う画像特徴の変化に焦点を当てています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-01">
        <br><font color="black">2020-11-01</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: An End-to-End Document-Level Neural Discourse Parser Exploiting
  Multi-Granularity Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_0.html">
      <font color="black">An End-to-End Document-Level Neural Discourse Parser Exploiting
  Multi-Granularity Representations</font>
    </a>
  </h2>
  <font color="black">さらに、このような表現を境界情報と階層情報でエンコードして、ドキュメントレベルの談話処理のより洗練されたモデリングを取得します。実験結果は、パーサーが最先端のパフォーマンスを達成し、ベンチマークされたRSTデータセットで人間レベルのパフォーマンスに近づくことを示しています。 ..課題には、ドキュメントレベルの談話ツリーの深い構造、微妙な意味判断の要件、および大規模なトレーニングコーパスの欠如が含まれます。 
[概要]最初に、高次および長距離の依存関係を具体化する事前トレーニング済みのコンテキスト言語モデルを使用して、より細かいセマンティック、構文、および組織の表現を可能にします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Learning for Visual Summary Identification in Scientific
  Publications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_1.html">
      <font color="black">Self-Supervised Learning for Visual Summary Identification in Scientific
  Publications</font>
    </a>
  </h2>
  <font color="black">これは主に、注釈付きのゴールドスタンダードの利用可能性が限られているためです。これは、堅牢で高性能な教師あり学習手法の適用を妨げます。さらに、図と図へのインライン参照のヒューリスティックマッチングに基づいて、自己教師あり学習アプローチを開発します。キャプション..生物医学とコンピューターサイエンスの両方の分野での実験は、私たちのモデルが自己監視されているにもかかわらず、注釈付きのトレーニングデータに依存していないにもかかわらず、最先端のパフォーマンスを上回ることができることを示しています。 
[概要]視覚的な出版物の要約を提供する取り組みはほとんどなく、主に生物医学分野に焦点を当てています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Document-Level Relation Extraction with Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_2.html">
      <font color="black">Document-Level Relation Extraction with Reconstruction</font>
    </a>
  </h2>
  <font color="black">再構築者は、グラフ表現からグラウンドトゥルースパスの依存関係を再構築し、提案されたDocREモデルがトレーニング内の関係を持つエンティティペアをエンコードすることにさらに注意を払うようにします。大規模なDocREデータセットでの実験結果は、提案されたDocREデータセットがモデルは、強力な異種グラフベースのベースラインでの関係抽出の精度を大幅に向上させることができます。さらに、再構築器は、推論における関係分類を支援する関係インジケーターと見なされ、DocREモデルのパフォーマンスをさらに向上させることができます。 
[概要]学習グラフ表現の広範なモデルの関係情報。これなしで、新しいエンコーダー-分類子-docreの再構成モデルを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: A Graph Reasoning Network for Multi-turn Response Selection via
  Customized Pre-training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_3.html">
      <font color="black">A Graph Reasoning Network for Multi-turn Response Selection via
  Customized Pre-training</font>
    </a>
  </h2>
  <font color="black">シーケンス推論モジュールは、グローバルな観点から発話応答ペアの高度に要約されたコンテキストベクトルに基づいて推論を実行します。この論文では、問題に対処するためのグラフ推論ネットワーク（GRN）を提案します。2つの会話型推論データセットでの実験私たちのモデルが強力なベースライン手法を劇的に上回り、人間レベルに近いパフォーマンスを達成できることを示しています。 
[概要]既存の研究では、学習機能に基づくマッチングスコアに注意が払われています。これにより、モデルの推論能力が不十分になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Type-augmented Relation Prediction in Knowledge Graphs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_4.html">
      <font color="black">Type-augmented Relation Prediction in Knowledge Graphs</font>
    </a>
  </h2>
  <font color="black">特に、タイプ情報とインスタンスレベルの情報は、それぞれ事前確率と関係の可能性としてエンコードされ、ベイズの定理に従って結合されます。既存の作業のほとんどは、観測されたインスタンスレベルのトリプルの可能性を最大化することによって提案されます。さらに重要なことに、特定のデータセットから抽出されたタイプ情報は、提案されたTaRPモデルを通じて他のデータセットにうまく一般化できます。 
[ABSTRACT]知識グラフの完成は、既存の事実を考慮して欠落している事実を推測するタスクです。ただし、エンティティやインスタンスのタイプ情報などのオントロジー情報にはあまり注意が払われていません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-talker ASR for an unknown number of sources: Joint training of
  source counting, separation and ASR -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_5.html">
      <font color="black">Multi-talker ASR for an unknown number of sources: Joint training of
  source counting, separation and ASR</font>
    </a>
  </h2>
  <font color="black">マルチトーカーの重複音声分離と認識へのほとんどのアプローチは、同時にアクティブな話者の数が与えられることを前提としていますが、現実的な状況では、通常は不明です。とりわけ、新しい最先端の単語誤り率を設定します。 WSJ0-2mixデータベースで..さらに、WSJ0-4mixデータベースでの実験で示されているように、私たちのシステムは、トレーニング中にこれまでに見たよりも多くのスピーカーにうまく一般化されます。 
[概要] wsj0-2mixデータベースに新しい注目度の高いエラー率を設定します。データベースにクリーンスポットエラー率も設定します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-04">
        <br><font color="black">2020-06-04</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Dimensional Explanation of Target Variables from Documents -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_6.html">
      <font color="black">Multi-Dimensional Explanation of Target Variables from Documents</font>
    </a>
  </h2>
  <font color="black">目新しさは、あいまいさを処理するためにターゲット変数のセット全体の関連性確率分布をモデル化するソフト多次元マスクにあります。過去の研究では、注意と理論的根拠のメカニズムを使用して、ドキュメントのターゲット変数を予測する単語を見つけました。 、これらの欠点に対処するためにマルチターゲットマスカー（MTM）を提案します。 
[概要] 2つのデータセットでmtmを評価し、結果のマスクが最先端の方法で生成されたものよりも正確で一貫性があることを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-25">
        <br><font color="black">2019-09-25</font>
      </time>
    </span>
</section>
<!-- paper0: Medical Entity Linking using Triplet Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_7.html">
      <font color="black">Medical Entity Linking using Triplet Network</font>
    </a>
  </h2>
  <font color="black">標準ベンチマークNCBI疾患データセットの実験結果は、私たちのシステムが以前の方法を大幅に上回っていることを示しています。これは、さまざまな医療および臨床オントロジーのマージにも使用できます。このタスクは、医療分野で非常に重要です。 
[要約]この論文では、疾患の言及との類似性に基づいて候補知識ベースエントリをランク付けするアプローチを提示します。これは、さまざまな種類の知識に基づいています。結果は論文に示されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Domain specific BERT representation for Named Entity Recognition of lab
  protocol -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_8.html">
      <font color="black">Domain specific BERT representation for Named Entity Recognition of lab
  protocol</font>
    </a>
  </h2>
  <font color="black">実験結果は、私たちのモデルがベースラインを大幅に改善し、F1スコアの点で4番目の次点者、リコールの点で1番目の次点者を立て、最高のスコアよりわずか2.21F1スコア遅れていることを示しています。 Bio-Bertに基づく名前付きエンティティのタグ付けシステムを説明するために..表現からプロパティを予測するようにトレーニングされた監視対象モデルは、さまざまなタスクで高精度を達成しています。 
[概要] bertファミリーは、nerタグ付けのダウンストリームタスクで非常にうまく機能しているようです。これにより、従来のbertモデルでコンテキスト化された埋め込みを作成することが困難になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: TechTexC: Classification of Technical Texts using Convolution and
  Bidirectional Long Short Term Memory Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_9.html">
      <font color="black">TechTexC: Classification of Technical Texts using Convolution and
  Bidirectional Long Short Term Memory Network</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、共有タスクTechDofication 2020への参加の一環として開発されたテクニカルテキスト分類システムとその結果の詳細な説明を示します。分類システム（「TechTexC」と呼ばれる）は、3つの手法を使用して分類タスクを実行するために開発されます。ニューラルネットワーク（CNN）、双方向長期短期メモリ（BiLSTM）ネットワーク、およびCNNとBiLSTMの組み合わせ。結果は、BiLSTMモデルを使用したCNNが、サブタスク（a、b、c、およびg）のタスク1に関する他の手法よりも優れていることを示しています。 ）およびタスク-2a。 
[概要]共有タスクは、2つのサブタスクで構成されます。特定の言語で指定されたテキストの退屈なサブタスクを識別します。2番目のタスクは、コンピュータサイエンスドメインのテキストをきめ細かいサブドメインに分類します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Leveraging ParsBERT and Pretrained mT5 for Persian Abstractive Text
  Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_10.html">
      <font color="black">Leveraging ParsBERT and Pretrained mT5 for Persian Abstractive Text
  Summarization</font>
    </a>
  </h2>
  <font color="black">現在の作業はこの種の最初のものであり、有望な結果を達成することにより、将来の作業のベースラインとして使用できます。事前にトレーニングされたトランスベースのエンコーダ-デコーダモデルがこれらのタスクで人気を博し始めています。これらのモデルはpn-summaryデータセットで微調整。 
[ABSTRACT]新しい論文は、このタスクに対処するための2つの方法を提案しています。pnという名前の新しいデータセット-ペルシア語の抽象テキスト要約の要約</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Incorporating Entity-specific Knowledge Graph Information in
  Predicting Drug-Drug Interactions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_11.html">
      <font color="black">Towards Incorporating Entity-specific Knowledge Graph Information in
  Predicting Drug-Drug Interactions</font>
    </a>
  </h2>
  <font color="black">この論文では、テキストコーパスから薬物間相互作用を予測するために、知識グラフ（KG）埋め込みから取得した生物医学エンティティ（薬物、疾患、遺伝子など）のドメイン知識を組み込む方法を探ります。DDIExtractionで実施された実験2013コーパスは、この戦略が他のベースラインアーキテクチャを4.1％マクロF1スコア改善することを明確に示しています。他の生物医学エンティティとの相互作用から得られた薬物埋め込みとドメイン固有のBioBERT埋め込みを組み合わせる新しい方法、BERTKG-DDIを提案します-ベースのRCアーキテクチャ。 
[概要]薬物埋め込みと新しいモデルを組み合わせる新しい方法を提案します。これらのタイプには、biobert埋め込みのbio％ベースのrcアーキテクチャが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Residual Energy-Based Models for Text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_12.html">
      <font color="black">Residual Energy-Based Models for Text</font>
    </a>
  </h2>
  <font color="black">エネルギーベースモデルフレームワークを使用してこれを形式化し、混乱と人間の評価の両方の観点から測定された生成モデルの結果を実際に改善することを示します。現在の大規模な自己回帰言語モデル印象的な流暢さを示し、説得力のあるテキストを生成できます。モデルのトレーニングデータにアクセスできる場合、答えは肯定的であり、アクセスできない場合でも慎重に肯定的であることが実験的にわかります。 
[要約]これは、自己回帰モデルを改善できることを示唆しています。これは、それらが時代のシステムを改善するために使用できることを示唆しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: A Contextual Hierarchical Attention Network with Adaptive Objective for
  Dialogue State Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_13.html">
      <font color="black">A Contextual Hierarchical Attention Network with Adaptive Objective for
  Dialogue State Tracking</font>
    </a>
  </h2>
  <font color="black">対話状態追跡（DST）の最近の研究では、履歴情報を活用して、一般にスロットと値のペアとして表される状態を決定します。さらに、トレーニング中にさまざまなスロットの重みを動的に調整することにより、スロットの不均衡の問題を軽減する適応目標を提案します。結果は、私たちのアプローチがMultiWOZ2.0およびMultiWOZ2.1データセットでそれぞれ52.68％および58.55％のジョイント精度に達し、大幅な改善（+ 1.24％および+ 5.98％）で新しい最先端のパフォーマンスを達成することを示しています。 
[概要]コンテキスト表現を学習するためにコンテキスト空間注意ネットワークを使用してdstを強化することを提案します。multiwoz2.0およびmultiwoz2.1データセットでそれぞれ52.68％および58. 55％以上のジョイント精度を実現し、新しい状態を実現します。かなりの改善を伴う芸術パフォーマンスの</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-02">
        <br><font color="black">2020-06-02</font>
      </time>
    </span>
</section>
<!-- paper0: Pattern-aware Data Augmentation for Query Rewriting in Voice Assistant
  Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_14.html">
      <font color="black">Pattern-aware Data Augmentation for Query Rewriting in Voice Assistant
  Systems</font>
    </a>
  </h2>
  <font color="black">このアプローチは、従来のヒューリスティックまたはルールベースの拡張方法を超えており、単語の交換/置換の事前定義されたパターンを生成するように制約されていません。私たちの実験結果は、完全にトレーニングされたQRベースラインと比較してその有効性を示し、QRのブーストにおけるその潜在的なアプリケーションを示しています低リソースのドメインまたはロケールでのパフォーマンス。したがって、既存のトレーニングペアからパターンを学習し、リライトラベルからリライト候補を逆に生成して、不十分なQRトレーニングデータを補う拡張フレームワークを提案します。 
[概要]基礎となる教師ありモデルには、多数のラベル付きペアが必要です。これらのペアは、収集するのが難しく、コストがかかります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: SARG: A Novel Semi Autoregressive Generator for Multi-turn Incomplete
  Utterance Restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_15.html">
      <font color="black">SARG: A Novel Semi Autoregressive Generator for Multi-turn Incomplete
  Utterance Restoration</font>
    </a>
  </h2>
  <font color="black">オープンドメインの対話システムは、簡単に入手できるシングルターンコーパスとディープラーニングの開発により大きな成功を収めましたが、頻繁な共参照と情報の省略のため、マルチターンシナリオは依然として課題です。さらに、2つの実験ベンチマークは、提案されたモデルが品質と推論速度の点で最先端のモデルを大幅に上回っていることを示しています。この論文では、最近の研究でマルチターン対話システムよりも一般的な改善をもたらした不完全な発話復元を調査します。 。 
[要約]研究は、システムの開発が最近の研究で改善されたことを示しています.2つのベンチマークでの実験は、提案されたモデルが、マルチターン対話システムの状態を大幅に上回っていることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Self-attention Comparison Module for Boosting Performance on
  Retrieval-based Open-Domain Dialog Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_16.html">
      <font color="black">Self-attention Comparison Module for Boosting Performance on
  Retrieval-based Open-Domain Dialog Systems</font>
    </a>
  </h2>
  <font color="black">候補応答間の比較情報を活用するために、この論文では、SCMと呼ばれる検索ベースのオープンドメインダイアログシステム用の新しいプラグイン自己注意比較モジュールを提案します。事前に訓練された言語モデル以来広く使用されている検索ベースのオープンドメインダイアログシステムは、最近研究者からかなりの注目を集めています。広範な実験結果は、提案された自己注意比較モジュールが既存の検索ベースのオープンドメインダイアログシステムのパフォーマンスを効果的に高めることを示しています。 
[要約]以前の作品は、比較によって適切な応答を選択するだけです。モデルが比較情報にアクセスできる場合、より良い決定を下すことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Adjust-free adversarial example generation in speech recognition using
  evolutionary multi-objective optimization under black-box condition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_17.html">
      <font color="black">Adjust-free adversarial example generation in speech recognition using
  evolutionary multi-objective optimization under black-box condition</font>
    </a>
  </h2>
  <font color="black">この論文で提案された方法は、ブラックボックスシナリオの下でロバストな敵対的な例を生成することを可能にする進化的多目的最適化（EMO）を採用します。攻撃者がターゲットスピーチに対してそれを再生するタイミングを取る必要がないようにラグ。この論文は、自動スピーチ認識システムへのブラックボックス敵対攻撃方法を提案します。 
[概要]一部の研究では、音声認識のためにニューラルネットワークを攻撃しようとしましたが、これらの方法では、ターゲット音声とのタイミングラグに対する敵対的な例の堅牢性は考慮されていませんでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Narrative Incoherence Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_18.html">
      <font color="black">Narrative Incoherence Detection</font>
    </a>
  </h2>
  <font color="black">セットアップは簡単ですが、モデルは複数文のナラティブテキストを理解して分析し、文レベルで決定を下す必要があるため、このタスクは困難です。副産物として、このような戦略により、インコヒーレンスの検出と入力/変更を同時に行うことができます。提案..インテリジェント編集アシスタントの人気の高まりに動機付けられて、ナラティブインコヒーレンス検出のタスクを紹介および調査します。（破損した）長い形式のナラティブを前提として、ナラティブフローに何らかの意味の不一致が存在するかどうかを判断します。 
[概要]欠落している文と一貫性のないテキストを分析します。このモデルは、トークンレベルのモデルと同等の検出精度を実現できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: MT-Teql: Evaluating and Augmenting Consistency of Text-to-SQL Models
  with Metamorphic Testing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_19.html">
      <font color="black">MT-Teql: Evaluating and Augmenting Consistency of Text-to-SQL Models
  with Metamorphic Testing</font>
    </a>
  </h2>
  <font color="black">ソフトウェアメタモルフィックテストの原則に触発されたMT-Teqlは、モデルに依存しないフレームワークを提供します。このフレームワークは、セマンティクスを保持する変換を実行するためのメタモルフィック関係（MR）の包括的なセットを実装します。さらに、変換された入力を活用して、モデルの堅牢性をさらに高めるためにモデルを再トレーニングします。同様に、ユーザーの好み（たとえば、通常の形式の選択）は、概念的に同一のスキーマを表現するときにテーブル構造に劇的な変化をもたらす可能性があります。 
[概要]システムは、sotaモデルから数千の予測エラーを公開します。既存のデータセットを桁違いに充実させ、標準の精度を損なうことなく40％を超える不整合エラーを排除します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Open Intent Classification with Adaptive Decision Boundary -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_20.html">
      <font color="black">Deep Open Intent Classification with Adaptive Decision Boundary</font>
    </a>
  </h2>
  <font color="black">オープンインテント分類は、対話システムでは難しいタスクです。次に、十分にトレーニングされた機能を使用して、既知の各インテントの適応球形決定境界を自動的に学習します。具体的には、経験的リスクと経験的リスクの両方のバランスをとるための新しい損失関数を提案します。オープンスペースのリスク。 
[概要]既知のインテントの分類品質を確保する必要があります。不合理なリスクとオープンスペースのリスクの両方のバランスをとるために、新しい損失関数が必要です。私たちのアプローチは、ラベル付けされたデータが少なく、既知のインテントが少ないため、驚くほど鈍感です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-18">
        <br><font color="black">2020-12-18</font>
      </time>
    </span>
</section>
<!-- paper0: Discovering New Intents with Deep Aligned Clustering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/cs.CL/paper_21.html">
      <font color="black">Discovering New Intents with Deep Aligned Clustering</font>
    </a>
  </h2>
  <font color="black">最後に、整列された疑似ラベルの監視下でインテント表現を学習します。最初に、いくつかのラベル付き既知のインテントサンプルを事前知識として活用して、モデルを事前トレーニングします。次に、k-meansを実行してクラスター割り当てを生成します。疑似ラベルとして。 
[概要]この作業では、限られた既知のインテントデータを使用して新しいインテントを発見するための効果的な方法（ディープアラインクラスタリング）を提案します。k-は、クラスター割り当てを疑似ラベルとして生成することを意味します。テスト中に、整列された疑似ラベルの監督下での意図表現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Multi-talker ASR for an unknown number of sources: Joint training of
  source counting, separation and ASR -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/eess.AS/paper_0.html">
      <font color="black">Multi-talker ASR for an unknown number of sources: Joint training of
  source counting, separation and ASR</font>
    </a>
  </h2>
  <font color="black">さらに、WSJ0-4mixデータベースでの実験で示されているように、私たちのシステムは、トレーニング中にこれまでに見たよりも多くの話者によく一般化されます。これに対処するために、私たちは反復音声抽出システムを拡張して、ソースを作成し、それをシングルトーカー音声認識装置と組み合わせて、未知の数のアクティブスピーカー用の最初のエンドツーエンドマルチトーカー自動音声認識システムを形成します。私たちの実験は、カウント精度、ソース分離、および音声において非常に有望なパフォーマンスを示しています。 WSJ0-2mixおよびWSJ0-3mixからのシミュレートされたクリーンな混合物の認識。 
[概要] wsj0-2mixデータベースに新しい注目度の高いエラー率を設定します。データベースにクリーンスポットエラー率も設定します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-04">
        <br><font color="black">2020-06-04</font>
      </time>
    </span>
</section>
<!-- paper0: Semantic Audio-Visual Navigation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/eess.AS/paper_1.html">
      <font color="black">Semantic Audio-Visual Navigation</font>
    </a>
  </h2>
  <font color="black">新しいタスクをサポートするために、SoundSpacesオーディオシミュレーションプラットフォームを拡張して、Matterport3Dのオブジェクトの配列に意味的に接地されたオブジェクトサウンドを提供します。モデルの永続的なマルチモーダルメモリにより、音響イベントが停止した後も目標に到達できます。セマンティックオーディオビジュアルナビゲーションを紹介します。このナビゲーションでは、環境内のオブジェクトがセマンティックの意味と一致する音を出し（トイレのフラッシング、ドアのきしみ音など）、音響の発明が散発的または短期間です。 
[ABSTRACT]セマンティックオーディオを導入します-ビジュアルナビゲーションでは、環境内のオブジェクトがセマンティックの意味と一致するサウンドを生成します。モデルの永続的なマルチモーダルメモリにより、音響イベントが停止した後も、目標のサウンドに到達できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Cross-Lingual Speech Emotion Recognition Using
  DomainAdversarial Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/eess.AS/paper_2.html">
      <font color="black">Unsupervised Cross-Lingual Speech Emotion Recognition Using
  DomainAdversarial Neural Network</font>
    </a>
  </h2>
  <font color="black">具体的には、特徴抽出器の後に言語分類子と勾配反転レイヤーを追加して、学習した表現を言語に依存せず、感情に意味のあるものにします。実験結果は、提案された方法が、覚醒と価数分類のベースラインシステムよりも平均3.91％向上することを示しています。タスク..私たちのメソッドは監視されていません。つまり、ターゲット言語のラベルは必要ありません。これにより、他の言語にメソッドを適用しやすくなります。 
[概要]ドメイン敵対的ニューラルネットワーク（dann）ベースのアプローチを提案して、クロスリンガルサーバーのこの分布シフトの問題を軽減します。この方法は教師なしです。つまり、ターゲット言語のラベルは不要であり、適用が容易になります。他の言語での方法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-stream Convolutional Neural Network with Frequency Selection for
  Robust Speaker Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/eess.AS/paper_3.html">
      <font color="black">Multi-stream Convolutional Neural Network with Frequency Selection for
  Robust Speaker Verification</font>
    </a>
  </h2>
  <font color="black">提案されたフレームワークは、音響モデリングのロバスト性を強化するために、複数のストリームから生成された多様な時間埋め込みに対応します。各発話が1回だけ処理される従来の単一ストリームソリューションとは異なり、このフレームワークでは、複数のストリームが並行して処理します。 ..時間埋め込みの多様性については、周波数選択による特徴拡張を検討します。これは、周波数の全帯域をいくつかのサブバンドに手動でセグメント化することであり、各ストリームの特徴抽出器は、使用するサブバンドを選択できます。ターゲット周波数ドメイン。 
[概要]話者検証タスクのために、マルチストリーム畳み込みニューラルネットワーク（cnn）の新しいシステムが提案されました。全周波数範囲の代わりに音声認識を使用できるようにするには、複数の話者が必要です。これは、いわゆる周波数選択手法です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Adjust-free adversarial example generation in speech recognition using
  evolutionary multi-objective optimization under black-box condition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/eess.AS/paper_4.html">
      <font color="black">Adjust-free adversarial example generation in speech recognition using
  evolutionary multi-objective optimization under black-box condition</font>
    </a>
  </h2>
  <font color="black">この論文で提案された方法は、ブラックボックスシナリオの下でロバストな敵対的な例を生成することを可能にする進化的多目的最適化（EMO）を採用します。攻撃者がターゲットスピーチに対してそれを再生するタイミングを取る必要がないようにラグ。この論文は、自動スピーチ認識システムへのブラックボックス敵対攻撃方法を提案します。 
[概要]一部の研究では、音声認識のためにニューラルネットワークを攻撃しようとしましたが、これらの方法では、ターゲット音声とのタイミングラグに対する敵対的な例の堅牢性は考慮されていませんでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: A Bayesian methodology for localising acoustic emission sources in
  complex structures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-22/eess.AS/paper_5.html">
      <font color="black">A Bayesian methodology for localising acoustic emission sources in
  complex structures</font>
    </a>
  </h2>
  <font color="black">起源が不明なアコースティックエミッションイベントが観察されると、構造の表面全体の放出位置の可能性を定量化するマッピングが生成されます。新しい確率的マッピングは複数の利点を提供し、より有益なローカリゼーション戦略につながります。決定論的予測または関連する信頼限界を伴う単一点推定よりも..アプローチのパフォーマンスは、多数の複雑な幾何学的特徴を備えた構造で調査され、他の同様のローカリゼーション方法と比較して好ましいパフォーマンスを示します。 
[ABSTRACT]ガウス過程は、最初にソースの場所とそれに対応する到着値の時間差との関係を学習するために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
