<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-09-04の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: FeatherWave: An efficient high-fidelity neural vocoder with multi-band
  linear prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.SD/paper_0.html">
      <font color="black">FeatherWave: An efficient high-fidelity neural vocoder with multi-band
  linear prediction</font>
    </a>
  </h2>
  <font color="black">マルチバンド方式により、モデルは複数の音声サンプルを1つのステップで並行して生成できます。さらに、主観的なリスニングテストでは、FeatherWaveがLPCNetよりも高品質の音声を生成できることが示されています。したがって、音声の効率を大幅に向上できます。合成。 
[ABSTRACT] wavernnアーキテクチャで音声信号の線形予測特性を使用するlpcnetは、リアルタイムよりも高速で高品質の音声を生成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br><font color="black">2020-05-12</font>
      </time>
    </span>
</section>
<!-- paper0: Real Time Speech Enhancement in the Waveform Domain -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.SD/paper_1.html">
      <font color="black">Real Time Speech Enhancement in the Waveform Domain</font>
    </a>
  </h2>
  <font color="black">提案されたモデルは、生の波形を直接処理しながら、因果法と非因果法の両方の最先端のパフォーマンスに一致します。客観的なメトリックと人間の判断の両方を使用して、いくつかの標準ベンチマークで評価を実行します。さらに、生の波形に直接適用されるデータ拡張手法のセット。モデルのパフォーマンスとその汎化能力をさらに向上させます。 
[要約]提案されたモデルは、スキップ接続を備えたエンコーダー/デコーダーアーキテクチャに基づいています。定常および非定常ノイズを含むさまざまな種類のバックグラウンドノイズ、およびルームリバーブを削除できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-23">
        <br><font color="black">2020-06-23</font>
      </time>
    </span>
</section>
<!-- paper0: Intra-Utterance Similarity Preserving Knowledge Distillation for Audio
  Tagging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.SD/paper_2.html">
      <font color="black">Intra-Utterance Similarity Preserving Knowledge Distillation for Audio
  Tagging</font>
    </a>
  </h2>
  <font color="black">ただし、ミニバッチ内の入力間のペアワイズの類似性を維持する代わりに、私たちの方法は、単一の入力発話のフレーム間のペアワイズの類似性を維持します。 DCASE 2019タスク5データセットのオーディオタグ付け..この新しいKDメソッド、「発話内類似性保持KD」（IUSP）は、オーディオタグ付けタスクの有望な結果を示しています。 
[ABSTRACT] kdメソッドは、単一の入力発話のフレーム間のペアごとの類似性を維持する代わりに、音声タグ付けタスクの有望な結果を示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Voice Conversion by Cascading Automatic Speech Recognition and
  Text-to-Speech Synthesis with Prosody Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.SD/paper_3.html">
      <font color="black">Voice Conversion by Cascading Automatic Speech Recognition and
  Text-to-Speech Synthesis with Prosody Transfer</font>
    </a>
  </h2>
  <font color="black">韻律エンコーダは、韻律コードを抽出するために使用されます。変換中に、ソース韻律は、Transformer TTSモデルをそのコードで調整することにより、変換された音声に転送されます。TTSモデルでは、韻律コードを使用して韻律を記述することを提案しました。音声に含まれるテキストおよび話者情報以外の情報。 
[ABSTRACT] asr-音声変換のttsメソッドは、韻律エンコーダを使用してコードを抽出します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: HiFiSinger: Towards High-Fidelity Neural Singing Voice Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.SD/paper_4.html">
      <font color="black">HiFiSinger: Towards High-Fidelity Neural Singing Voice Synthesis</font>
    </a>
  </h2>
  <font color="black">小さなサンプリングレートを採用する従来のSVSシステムは、上記の課題に十分に対処できません。実験結果は、HiFiSingerが高品質の歌声を合成することを示しています。 ..忠実度の高い歌声は、通常、表現や感情を伝えるために、より高いサンプリングレート（48kHzなど）を必要とします。 
[ABSTRACT]高音質の歌声に向けたsvsシステムであるhifisingerは、hifisingerに基づいています。hifisingerは、より高品質の高音質の歌声を合成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Knowing What to Listen to: Early Attention for Deep Speech
  Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.SD/paper_5.html">
      <font color="black">Knowing What to Listen to: Early Attention for Deep Speech
  Representation Learning</font>
    </a>
  </h2>
  <font color="black">提案モデルを、話者認識と音声感情認識の2つの一般的なタスクで評価します。また、バックボーンネットワークと比較して、堅牢性と感度の改善を示すさまざまなレベルの追加ノイズに対してモデルをテストしました。ディープラーニングテクニックにより、音声が大幅に改善されました近年の処理。 
[要約]ディープラーニングモデルによって抽出された音声表現は、音声認識、元の認識、音声感情認識など、幅広いタスクで使用されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Heightmap Reconstruction of Macula on Color Fundus Images Using
  Conditional Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.IV/paper_0.html">
      <font color="black">Heightmap Reconstruction of Macula on Color Fundus Images Using
  Conditional Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">この論文では、条件付き生成敵対的ネットワーク（cGAN）を使用して、眼底画像の黄斑領域の高さ情報を含む画像を生成します。最近のアプローチでは、3D再構成またはハイトマップ予測にシェーディング情報を使用しましたが、出力が正確ではなかったためです。近くのピクセル間の依存関係は無視されました。さらに、他の方法は、実際には利用できない目の複数の画像の可用性に依存していました。 
[ABSTRACT] 3D再建法は黄斑障害の治療に使用できます。これらには、黄斑の再建と再建が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal brain tumor classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.IV/paper_1.html">
      <font color="black">Multimodal brain tumor classification</font>
    </a>
  </h2>
  <font color="black">0.91、0.90および0.94）。検証）0.913、0.897および0.951のバランス精度、カッパおよびf1（それぞれ。メソッドの完全なコードはXXXXでオープンソースです。
[要約]放射線画像は、がん診断の有効性。2020年の海の精密医療の課題について、3クラスのアンバランス分類タスクで実験が行われます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Mononizing Binocular Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.IV/paper_2.html">
      <font color="black">Mononizing Binocular Videos</font>
    </a>
  </h2>
  <font color="black">この論文では、モノナイズの双眼鏡ビデオとそれを効果的に実現するためのフレームワークのアイデアを紹介します。通常の単眼ビデオとは異なり、オリジナルの双眼ビデオを復元して立体ディスプレイに表示できます。まず、エンコーディングを定式化します。左右のビュー間の長距離対応を活用するピラミッド型の変形可能な融合モジュール、復元アーティファクトを抑制する量子化レイヤー、および最新のビデオコーデックによって導入される圧縮ノイズに対抗する圧縮ノイズシミュレーションモジュールを備えたANDデコードフレームワーク。 
[ABSTRACT]ディスペンスされた両眼ビデオ、ステレオ情報は暗黙的に視覚的にエンコードされていますが、ほとんど認識できない形式です。元の両眼ビデオを復元して、立体ディスプレイに表示できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: A survey of loss functions for semantic segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.IV/paper_3.html">
      <font color="black">A survey of loss functions for semantic segmentation</font>
    </a>
  </h2>
  <font color="black">コードは、Githubで入手できます。https：//github.com/shruti-jadon/Semantic-Segmentation-Loss-Functions ..このホワイトペーパーでは、画像のセグメンテーションで広く使用されている既知の損失関数のいくつかをまとめ、画像のセグメンテーションは、自動化された病気の検出から自動運転車まで、幅広いアプリケーションを備えているため、活発な研究分野となっています。 
[ABSTRACT]新しいlog-coshダイス損失関数も導入しました。バイアスデータや不十分なデータなど、さまざまなケースで使用できます。コードはgithubで入手できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-26">
        <br><font color="black">2020-06-26</font>
      </time>
    </span>
</section>
<!-- paper0: CNN-Based Ultrasound Image Reconstruction for Ultrafast Displacement
  Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.IV/paper_4.html">
      <font color="black">CNN-Based Ultrasound Image Reconstruction for Ultrafast Displacement
  Tracking</font>
    </a>
  </h2>
  <font color="black">この目的のために、相互相関に基づくスペックル追跡アルゴリズムと組み合わせた畳み込みニューラルネットワークベースの画像再構成法を導入しました。実際、画像品質は通常、ステアリングされる超高速取得の数を増やすことで改善できますが、費用がかかります。フレームレートが低下し、モーションアーティファクトが発生する可能性があります。妥協のないフレームレートで正確なモーション推定を実現し、モーションアーティファクトを排除するために、提案されたアプローチは、単一の超高速取得に依存して高品質フレームを再構築し、2つの連続フレームのみを使用して2- D変位推定。 
[要約]提案されたアプローチは、高品質フレームを再スケーリングするための単一の超高速取得に依存し、迅速に取得するために2つの連続フレームのみに依存します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning-based Initialization of Iterative Reconstruction for
  Breast Tomosynthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.IV/paper_5.html">
      <font color="black">Deep Learning-based Initialization of Iterative Reconstruction for
  Breast Tomosynthesis</font>
    </a>
  </h2>
  <font color="black">ネットワークは、デジタルファントムを使用してトレーニングされました。一部は数学モデルに基づいており、一部は患者専用の乳房CTスキャンから導出されています。デジタル乳房トモシンセシスの再構築は、このようなシステムで利用できる角度データが限られているため、困難な問題です。これらの制限を回避しながら、ディープラーニングベースの再構築の利点の一部として、通常の高解像度反復法の初期化として低解像度のディープラーニングベースの再構築を使用することを提案します。 
[ABSTRACT]ディープラーニング-ベースの再構成は、通常の高解像度反復法の初期化です。ネットワークは、トレーニングに含まれていない9つの患者ベースのファントムの初期化として使用されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: VddNet: Vine Disease Detection Network Based on Multispectral Images and
  Depth Map -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.IV/paper_6.html">
      <font color="black">VddNet: Vine Disease Detection Network Based on Multispectral Images and
  Depth Map</font>
    </a>
  </h2>
  <font color="black">提案されたアーキテクチャは、SegNet、U-Net、DeepLabv3 +、PSPNetなどの最も知られているアーキテクチャと比較することによって評価されます。ディープラーニングアーキテクチャは、マルチスペクトルデータと深度マップ情報でトレーニングされました。提案されたアーキテクチャの結果は、VddNetアーキテクチャは、ベースライン方式よりも高いスコアを達成します。 
[ABSTRACT]提案されたアーキテクチャは、それを最もよく知られているアーキテクチャと比較しています：segnet、u-net、deeplabv3およびpspnet</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Fundus Image Analysis for Age Related Macular Degeneration: ADAM-2020
  Challenge Report -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.IV/paper_7.html">
      <font color="black">Fundus Image Analysis for Age Related Macular Degeneration: ADAM-2020
  Challenge Report</font>
    </a>
  </h2>
  <font color="black">また、病変の検出とセグメンテーション、中心窩検出、視神経乳頭のセグメンテーションなど、他の直接関連する補助タスクの方法も提案します。また、GANを使用した中心窩検出の新しい方法を提案します。加齢黄斑変性症（AMD）の1つ高齢者の失明の主な原因。 
[要約]このレポートでは、網膜分析のための深層学習に基づく方法を提案します。また、ガンを使用した中心窩検出の新しい方法を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Physics-Consistent Data-driven Waveform Inversion with Adaptive Data
  Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.IV/paper_8.html">
      <font color="black">Physics-Consistent Data-driven Waveform Inversion with Adaptive Data
  Augmentation</font>
    </a>
  </h2>
  <font color="black">パフォーマンスを検証するために、カリフォルニア州キンバリーナの炭素隔離サイトに構築された地下地質モデルから生成された合成弾性地震波形データにこの方法を適用します。この作業では、物理学を組み合わせたFWIを解決する新しいハイブリッド計算アプローチを開発しますベースのモデルとデータ駆動型の方法論。物理学に整合性のあるデータ駆動型の反転法を、純粋に物理学ベースのアプローチと純粋にデータ駆動型のアプローチの両方と比較し、このメソッドの方がより高い精度と一般化能力をもたらすことを確認します。 
[ABSTRACT] fwiアプローチは、その不適切性と高コストのために難しい場合があります。トレーニングセットの代表性を組み合わせることができるデータ拡張戦略を開発します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Finding New Diagnostic Information for Detecting Glaucoma using Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.IV/paper_9.html">
      <font color="black">Finding New Diagnostic Information for Detecting Glaucoma using Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">これらの結果は、異種データセットとスキャン環境全体のさまざまな設定で人間の医師に近いものです。人間の医師の行動と一致すると、モデルの予測は、実際に網膜神経線維層などのOCTプリントアウトの従来の診断パラメータと相関しました。 RNFLの大部分が除去された場合でも、LC領域は緑内障を区別できることがわかりました。 
[要約]画像は4か国の4つの眼科病院から取得されました。篩状板領域は、通常の診療中に医師がこれまで利用できなかった有用な診断情報の貴重な情報源になる可能性があることがわかりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-14">
        <br><font color="black">2019-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Random Style Transfer based Domain Generalization Networks Integrating
  Shape and Spatial Information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.IV/paper_10.html">
      <font color="black">Random Style Transfer based Domain Generalization Networks Integrating
  Shape and Spatial Information</font>
    </a>
  </h2>
  <font color="black">この作業では、ランダムスタイル転送ネットワークを提示して、マルチベンダーおよび中心心臓画像セグメンテーションのドメイン汎化問題に取り組みます。モデルは、教師ありセグメンテーションと教師なしスタイル変換を同時に最適化することにより、半教師付き方法でトレーニングできます。目的.. M \＆Ms challenge2020の40科目で提案されたフレームワークを評価し、未知のベンダーおよびセンターからのデータのセグメンテーションで有望なパフォーマンスを得ました。 
[ABSTRACT]モデルは、教師ありセクションと教師なしスタイルの翻訳目標を同時に最適化することにより、半教師付き方法でトレーニングできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Geometric Back-projection Network for Point Cloud Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.IV/paper_11.html">
      <font color="black">Geometric Back-projection Network for Point Cloud Classification</font>
    </a>
  </h2>
  <font color="black">さらに、チャネルアフィニティに基づくアテンションモジュールは、機能マップを支援して、明確なチャネルを強調することで冗長性の可能性を回避します。点群分析の基本的なタスクとして、分類は基本的ですが常に困難です。特に、エラーのアイデアを活用します。フィードバック構造を修正して、点群の局所的な特徴を包括的に捉えます。 
[要旨]いくつかの未解決の問題に対処するために、より良い表現のために点群の幾何学的特徴をキャプチャするネットワークを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-28">
        <br><font color="black">2019-11-28</font>
      </time>
    </span>
</section>
<!-- paper0: Limited View Tomographic Reconstruction Using a Deep Recurrent Framework
  with Residual Dense Spatial-Channel Attention Network and Sinogram
  Consistency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.IV/paper_12.html">
      <font color="black">Limited View Tomographic Reconstruction Using a Deep Recurrent Framework
  with Residual Dense Spatial-Channel Attention Network and Sinogram
  Consistency</font>
    </a>
  </h2>
  <font color="black">再発ブロックは、カスタム設計された残差密空間チャネルアテンションネットワークで構成されます。品質の再構築を導き出すために、以前の最先端の方法はUNetのようなニューラルアーキテクチャを使用して、限られたビューデータから完全なビューの再構築を直接予測します。しかし、これらの方法ではディープネットワークアーキテクチャの問題はほとんど影響を受けず、再構成された画像のサイノグラムと取得されたサイノグラムの間の一貫性が保証されないため、理想的でない再構成につながります。さらに、反復フレームワークにインターリーブされたサイノグラム一貫性レイヤーを開発サンプリングされたサイノグラムが反復ブロックの中間出力のサイノグラムと一致することを保証するため。 
[ABSTRACT]サイノグラムの不完全性は、高ノイズと深刻なアーチファクトにつながる可能性があります。ただし、これらの最先端の再構成はほとんど不完全です。代わりに、新しいシステムを使用して再構成を繰り返すことができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Light Field Image Super-Resolution Using Deformable Convolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.IV/paper_13.html">
      <font color="black">Light Field Image Super-Resolution Using Deformable Convolution</font>
    </a>
  </h2>
  <font color="black">さらに、ベースライン調整可能なLFデータセットを開発して、さまざまな視差変動でSRパフォーマンスを評価します。LF-DFnetは、より忠実な詳細を備えた高解像度画像を生成し、最先端の再構成精度を達成できます。 、LF画像SRの視差問題を処理するために、変形可能なたたみ込みネットワーク（つまり、LF-DFnet）を提案します。 
[ABSTRACT]私たちのアプローチを使用すると、角度情報を適切に組み込み、各ビューの機能に対してエンコードできます。これらの機能は、すべてのlf画像のsr再構成に役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Contour Sparse Representation with SDD Features for Object Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.IV/paper_14.html">
      <font color="black">Contour Sparse Representation with SDD Features for Object Recognition</font>
    </a>
  </h2>
  <font color="black">このレターでは、SDDフィーチャーが定義され、オブジェクトの輪郭の疎な表現を形成しています。したがって、オブジェクトの輪郭からのSDDによるフィーチャー検出も可能です。各オブジェクトの参照モデルは、SDDフィーチャーに基づいて構築されています。次に、モデルマッチングがオンラインのオブジェクト認識に使用されます。 
[ABSTRACT] sddは2つのパブリックデータセット（nusデータセットと近赤外線データセット）で100％の精度を達成しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-13">
        <br><font color="black">2019-10-13</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Heightmap Reconstruction of Macula on Color Fundus Images Using
  Conditional Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_0.html">
      <font color="black">Heightmap Reconstruction of Macula on Color Fundus Images Using
  Conditional Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">最近のアプローチでは、3D再構成またはハイトマップ予測にシェーディング情報を使用していますが、近くのピクセル間の依存関係を無視しているため、出力は正確ではありませんでした。網膜画像に基づく医療診断では、3D構造の明確な理解が必要ですが、2Dキャプチャされた画像の性質から、その情報を推測することはできません。さらに、定性的研究では、この方法が最近のアプローチよりも優れていることも示されています。 
[ABSTRACT] 3D再建法は黄斑障害の治療に使用できます。これらには、黄斑の再建と再建が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: TRACE: Transform Aggregate and Compose Visiolinguistic Representations
  for Image Search with Text Feedback -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_1.html">
      <font color="black">TRACE: Transform Aggregate and Compose Visiolinguistic Representations
  for Image Search with Text Feedback</font>
    </a>
  </h2>
  <font color="black">テキストのフィードバックからテキストの意味を理解し、これらの変更を視覚的表現に適用する必要があるため、このタスクはやりがいがあります。これらの課題に対処するために、複合的な視覚を学習するための階層機能集約モジュールを含む新しいアーキテクチャTRACEを提案します。言語表現..インデックス付きデータベースを介して画像を効率的に検索する機能は、いくつかのユーザーエクスペリエンスの基礎です。 
[要約]目的は、これらの入力モダリティの両方で指定された制約を満たす画像を取得することです。これらの課題には、新しいアーキテクチャトレースが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: MIPGAN -- Generating Robust and High QualityMorph Attacks Using Identity
  Prior Driven GAN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_2.html">
      <font color="black">MIPGAN -- Generating Robust and High QualityMorph Attacks Using Identity
  Prior Driven GAN</font>
    </a>
  </h2>
  <font color="black">私たちは\ textit {MIPGAN（アイデンティティ事前駆動GANによるモーフィング）}と呼ばれるアイデンティティ事前駆動生成敵対的ネットワークを使用した新しいアプローチを提示します。顔モーフィング攻撃は、顔画像を使用して顔認識システム（FRS）を回避することを標的としています複数のデータ主体（たとえば、共犯者や悪意のある俳優）から派生します。モーフィング攻撃の成功は、生成されたモーフ画像の品質に直接依存します。 
[ABSTRACT]研究者は、ロバストな攻撃を生成するための新しいアプローチを提示します。提案されたマイバーネットワークは、stylegan.itの名前に基づいています。魅力的な損失関数を使用して、アーティファクトが最小限で高解像度の高品質のモーフィング顔画像を生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Physics-based Shading Reconstruction for Intrinsic Image Decomposition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_3.html">
      <font color="black">Physics-based Shading Reconstruction for Intrinsic Image Decomposition</font>
    </a>
  </h2>
  <font color="black">最後に、生成されたシェーディングマップを新しいディープラーニングフレームワークに統合して、それを洗練し、対応するアルベド画像を予測して、固有の画像分解を実現します。これにより、シェーディング推定..大規模な実験は、物理学ベースの不変記述子によって操作された私たちのアプローチが、MIT組み込み関数、NIR-RGB組み込み関数、マルチ光源組み込み画像、スペクトル組み込み画像、可能な限り現実的であり、組み込み結果に関する競合結果で優れた結果を達成する最先端のシェーディング推定を達成しながら、ワイルドデータセット内の画像。 
[ABSTRACT]アルベドとシェーディングの重力は、物理学ベースのモデルに基づいています。これらは、シェーディングに従って、MITアートの結果に基づいています。完全なシェーディングマップを再構築するための方法が提案されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Examples on Object Recognition: A Comprehensive Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_4.html">
      <font color="black">Adversarial Examples on Object Recognition: A Comprehensive Survey</font>
    </a>
  </h2>
  <font color="black">まとめると、目標は、この成長している研究分野の包括的で自己完結型の調査を提供することです。まず、その存在の背後にある仮説、それらを構築または保護するために使用される方法、および敵対的な例を相互に転送する能力を紹介します異なる機械学習モデル..この記事では、ニューラルネットワークのセキュリティ、安全性、および堅牢性に対する敵対的な例の影響について説明します。 
[ABSTRACT]サンプルの小さな摂動で感度を引き起こすのに十分である可能性があります。これは、感度が非常に高いため、研究できるためです。しかし、非常に多様である可能性があるため、感度が高くなります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-07">
        <br><font color="black">2020-08-07</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal brain tumor classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_5.html">
      <font color="black">Multimodal brain tumor classification</font>
    </a>
  </h2>
  <font color="black">検証）0.913、0.897、0.951のバランス精度、カッパ、f1（それぞれ0.91、0.90、0.94）。メソッドの完全なコードはXXXXのオープンソースです。 
[要約]放射線画像は、がん診断の有効性についてより多くの知識をもたらすはずです。実験は、2020海の精密医療の課題について、3クラスのアンバランス分類タスクで行われます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Layer-specific Optimization for Mixed Data Flow with Mixed Precision in
  FPGA Design for CNN-based Object Detectors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_6.html">
      <font color="black">Layer-specific Optimization for Mixed Data Flow with Mixed Precision in
  FPGA Design for CNN-based Object Detectors</font>
    </a>
  </h2>
  <font color="black">混合データフローは、FPGAデバイスの最小オンチップメモリ（BRAM）リソースを要求しながら、オフチップアクセスを最小限に抑えることを目的としています。たたみ込みニューラルネットワーク（CNN）は、集中的な計算と頻繁なメモリアクセスの両方を必要とします。処理速度と大きな電力消費。混合精度の量子化は、ロスレス精度と積極的なモデル圧縮の両方を実現することで、オフチップアクセスをさらに削減します。 
[ABSTRACT]提案された設計は、2つのレイヤー-特定の混合データフローとレイヤー固有の混合精度を採用しています。損失アルゴリズムと積極的なモデル圧縮の両方を実現することを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Spatial Transformer Point Convolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_7.html">
      <font color="black">Spatial Transformer Point Convolution</font>
    </a>
  </h2>
  <font color="black">いくつかのパブリックデータセット（S3DIS、Semantic3D、SemanticKITTIを含む）に対する広範な実験により、点群のセマンティックセグメンテーションタスクにおける提案手法の有効性が実証されています。暗黙の幾何学的構造をキャプチャして表現するために、これらの潜在的な幾何学的コンポーネントを学習するための空間方向ディクショナリを具体的に導入します。 。順序付けられていない隣接ポイントをより適切にエンコードするために、方向ディクショナリ学習を使用してスパースデフォーマを設計し、正規の順序付けされたディクショナリ空間に変換します。 
[要約]この論文では、点群の異方性畳み込みフィルタリングを実現する空間変換ポイント畳み込み法を提案します。順序付けられていない隣接点をより適切にエンコードするために、方向辞書学習を使用してそれらを時系列の順序付け辞書空間に変換する高密度デフォーマを設計します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: A survey of loss functions for semantic segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_8.html">
      <font color="black">A survey of loss functions for semantic segmentation</font>
    </a>
  </h2>
  <font color="black">画像のセグメンテーションは、自動化された病気の検出から自動運転車に至るまで、幅広いアプリケーションを備えているため、活発な研究分野となっています。また、特定の損失関数がすべてのデータセットで良好に機能し、未知のデータ分散シナリオでの適切なベースラインの選択。コードはGithubで入手できます：https://github.com/shruti-jadon/Semantic-Segmentation-Loss-Functions。 
[ABSTRACT]新しいlog-coshダイス損失関数も導入しました。バイアスデータや不十分なデータなど、さまざまなケースで使用できます。コードはgithubで入手できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-26">
        <br><font color="black">2020-06-26</font>
      </time>
    </span>
</section>
<!-- paper0: Flow-edge Guided Video Completion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_9.html">
      <font color="black">Flow-edge Guided Video Completion</font>
    </a>
  </h2>
  <font color="black">DAVISデータセットでのアプローチを検証します。ただし、モーション境界が貫通できないバリアを形成するため、ビデオ内のすべての欠落領域に到達できるわけではありません。以前のフロー完了方法では、モーション境界の鋭さを維持できないことがよくあります。 
[ABSTRACT]私たちの方法は、非ローカルフロー接続を遠方のフレームに導入することでこの問題を軽減します。これにより、モーション境界を越えてビデオコンテンツを伝播できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Partial Supervision for Generic Object Counting in Natural
  Scenes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_10.html">
      <font color="black">Towards Partial Supervision for Generic Object Counting in Natural
  Scenes</font>
    </a>
  </h2>
  <font color="black">私たちのRLCフレームワークは、カテゴリーのサブセットに少ない数の監視を使用し、残りのものにはクラスラベルを使用するだけで、データセット内の多数のオブジェクトカテゴリーから生じる注釈コストをさらに削減します。私たちのフレームワークは、新しいデュアルブランチ上に構築されています。画像分類と密度ブランチを備えたアーキテクチャ。実験は、COCO、Visual Genome、およびPASCAL 2007データセットで実行されます。 
[ABSTRACT] lower-count（lc）という名前の2つの新しいフレームワークと、lower-countの削減（rlc）を導入し、この設定でオブジェクトのカウントを可能に</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-13">
        <br><font color="black">2019-12-13</font>
      </time>
    </span>
</section>
<!-- paper0: Auto-Classifier: A Robust Defect Detector Based on an AutoML Head -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_11.html">
      <font color="black">Auto-Classifier: A Robust Defect Detector Based on an AutoML Head</font>
    </a>
  </h2>
  <font color="black">したがって、このペーパーでは、表面欠陥検出のタスクでいくつかの最先端の畳み込みニューラルネットワークがどの程度うまく機能するかを判断しようとしました。畳み込みニューラルネットワークを使用すると、従来の方法よりも優れた結果が得られることを示します。また、自動分類子は、すべてのデータセット全体で100％の精度と100％のAUC結果を達成することにより、他のすべての方法よりも優れています。DAGM2007の異なるデータセットを使用して表面欠陥検出のタスクで提案された方法を評価する実験を行いました。 
[ABSTRACT] cnn-フュージョンは、すべてのネットワークの予測を最終的なものに結合します。auto-分類子は、automlを使用して分類コンポーネントを変更することにより、畳み込みニューラルネットワークを改善する新しい提案です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: CNN-Based Ultrasound Image Reconstruction for Ultrafast Displacement
  Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_12.html">
      <font color="black">CNN-Based Ultrasound Image Reconstruction for Ultrafast Displacement
  Tracking</font>
    </a>
  </h2>
  <font color="black">この目的のために、相互相関に基づくスペックル追跡アルゴリズムと組み合わせた畳み込みニューラルネットワークベースの画像再構成法を展開しました。したがって、提案されたアプローチは、超高感度心血管運動やフローなどのアプリケーションで、超高速超音波の潜在能力を最大限に引き出すことができます。解析またはせん断波エラストグラフィ。妥協のないフレームレートで正確なモーション推定を実現し、モーションアーティファクトを排除するために、提案されたアプローチは、単一の超高速取得に依存して高品質フレームを再構築し、2つの連続フレームのみを使用して2D変位推定を取得します。 。 
[要約]提案されたアプローチは、高品質フレームを再スケーリングするための単一の超高速取得に依存し、迅速に取得するために2つの連続フレームのみに依存します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Scaffold the Development of Robotic Manipulation Skills -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_13.html">
      <font color="black">Learning to Scaffold the Development of Robotic Manipulation Skills</font>
    </a>
  </h2>
  <font color="black">同様の戦略を採用することで、ロボットはよりロバストな操作も実現できます。外側のループでは、ロボットが器具をワークスペースに配置します。これにより、知覚と運動制御および足場操作スキルの学習から不確実性を漏らします。 
[要約]このホワイトペーパーでは、ロボットが自律的に環境を変更できるようにします。これらのフィクスチャは、ロボットアクションの結果を制限するハード制約を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-03">
        <br><font color="black">2019-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: 1st Place Solution of LVIS Challenge 2020: A Good Box is not a Guarantee
  of a Good Mask -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_14.html">
      <font color="black">1st Place Solution of LVIS Challenge 2020: A Good Box is not a Guarantee
  of a Good Mask</font>
    </a>
  </h2>
  <font color="black">最後に、LVIS v1.0 valおよびtest-dev分割でそれぞれ41.5および41.2 APを達成し、X101-FPN-MaskRCNNに基づくベースラインを大幅に上回っています。第2段階では、Balanced GroupSoftmaxを使用して分類子を促進します。 、そして、より正確なマスク予測を得るために、新しい提案割り当て戦略とマスクヘッドの新しいバランスマスク損失を提案します。最初の段階では、EQLとセルフトレーニングを組み込んで、一般化された表現を学習します。 
[概要] lvisデータセットの分析には、分析の分析と分析が含まれます。これには、ロングテール分布と高品質のインスタンスセグメンテーションマスクが含まれます。最後に、lvis v1で41. 5と41. 2 apを達成します。 0 val and test-開発スプリット</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: An End-to-End Geometric Deficiency Elimination Algorithm for 3D Meshes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_15.html">
      <font color="black">An End-to-End Geometric Deficiency Elimination Algorithm for 3D Meshes</font>
    </a>
  </h2>
  <font color="black">具体的には、頂点または面の発生時間を評価することにより、重複する要素を排除できます。 2つのエッジの外積に応じて、縮退面を削除できます。孤立した頂点は面の頂点には表示されないため、直接削除できます。自己交差する面はAABBツリーを使用して検出され、後で再メッシュされます。面から発射する複数のランダムな光線が無限に到達できるかどうかをシミュレートすることにより、表面が内面であるかどうかを判断し、それを削除するかどうかを決定できます。3Dメッシュは、幾何データの重要な表現です。 、3Dメッシュのための効果的かつ効率的な幾何学的欠陥除去アルゴリズムを提案します。 
[ABSTRACT]メッシュデータの生成では、幾何学的欠陥は避けられません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-14">
        <br><font color="black">2020-03-14</font>
      </time>
    </span>
</section>
<!-- paper0: SCG-Net: Self-Constructing Graph Neural Networks for Semantic
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_16.html">
      <font color="black">SCG-Net: Self-Constructing Graph Neural Networks for Semantic
  Segmentation</font>
    </a>
  </h2>
  <font color="black">グラフニューラルネットワークに関する最近の研究から発想を得て、画像から直接長距離依存グラフを学習し、それを使用してコンテキスト情報を効率的に伝播し、セマンティックセグメンテーションを改善する自己構築グラフ（SCG）モジュールを提案します。グローバルコンテキスト表現のキャプチャ長距離ピクセルピクセル依存性を活用することにより、セマンティックセグメンテーションパフォーマンスが向上することが示されています。モジュールは、新しい適応対角線強調法と、カスタマイズされたグラフ再構成項とカルバックライブラーダイバージェンス正則化項で構成される変分下限によって最適化されます。 。 
[ABSTRACT]モジュールは、新しい適応空間拡張ツールを介して最適化されます。異なる視野角を使用して、モデルの視野を改善します。これらには、カスタマイズされたグラフ再構成項とカルバックライバーダイバージェンス正則化項が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Fundus Image Analysis for Age Related Macular Degeneration: ADAM-2020
  Challenge Report -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_17.html">
      <font color="black">Fundus Image Analysis for Age Related Macular Degeneration: ADAM-2020
  Challenge Report</font>
    </a>
  </h2>
  <font color="black">また、病変の検出とセグメンテーション、中心窩の検出、視神経乳頭のセグメンテーションなど、その他の直接関連する補助タスクの方法も提案します。加齢黄斑変性症（AMD）は、高齢者の失明の主な原因の1つです。 GANを使用した中心窩検出の新しい方法を提案します。 
[要約]このレポートでは、網膜分析のための深層学習に基づく方法を提案します。また、ガンを使用した中心窩検出の新しい方法を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression
  Grounding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_18.html">
      <font color="black">Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression
  Grounding</font>
    </a>
  </h2>
  <font color="black">いくつかのバックボーン、ベンチマーク、タスクに関する広範なアブレーション研究は、Ref-NMSの優位性を一貫して実証しています。このために、最初の段階で式を意識した提案を生み出す最初の方法であるRef-NMSを提案します。論文では、これらの方法は2つの段階での提案の役割間の明らかな不一致を見落としていると主張します。提案は式のすべての正しいインスタンスを含むことを期待して、検出の信頼度（つまり式にとらわれない）のみに基づいて提案を生成します（つまり、式を認識します）。 
[ABSTRACT]新しい接地方法が開発され、広範囲に広がる広範囲の接地が開発されました。新しい接地方法は、新しい方法に簡単に統合できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Detection-Aware Trajectory Generation for a Drone Cinematographer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_19.html">
      <font color="black">Detection-Aware Trajectory Generation for a Drone Cinematographer</font>
    </a>
  </h2>
  <font color="black">パイプライン全体をオンザフライで更新して、ターゲットの動きに応答できます。効率的な離散パス生成のために、深さなしでトポロジカルソートを分析的に決定できる有向非循環グラフ（DAG）を構築します。最初の検索..滑らかなパスは、2次計画法（QP）フレームワークで取得されます。 
[要約]提案された方法は、撮影技師のドローンの動きをアクティブにガイドするため、ターゲットの色がドローンのビューの背景の色とよく区別されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: WaveFuse: A Unified Deep Framework for Image Fusion with Discrete
  Wavelet Transform -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_20.html">
      <font color="black">WaveFuse: A Unified Deep Framework for Image Fusion with Discrete
  Wavelet Transform</font>
    </a>
  </h2>
  <font color="black">したがって、トレーニング時間が大幅に短縮され、実用性とトレーニング効率の両方でモデルのパフォーマンスが向上します。特徴マップの有用な情報は、提案された方法のマルチスケール離散ウェーブレット変換を介して適切に利用できます。最先端の融合方法、提案されたアルゴリズムは、主観的評価と客観的評価の両方でより優れた融合パフォーマンスを示します。我々は、地域エネルギーによるマルチスケール離散ウェーブレット変換の組み合わせに基づいて、複数のアプリケーションシナリオのための教師なし画像融合アーキテクチャを提案しますそしてディープラーニング。 
[ABSTRACT]これは、従来の画像変換方法とディープラーニングを組み合わせた初めての方法です。ディープラーニングを使用して開発された方法と同じです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Which Tasks Should Be Learned Together in Multi-task Learning? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_21.html">
      <font color="black">Which Tasks Should Be Learned Together in Multi-task Learning?</font>
    </a>
  </h2>
  <font color="black">これにより、単一のネットワークのみを評価する必要があるため、推論時の計算を節約できます。複数の異なる学習設定でタスクの協調と競合を研究し、協調するタスクが同じように計算されるように、いくつかのニューラルネットワークにタスクを割り当てるためのフレームワークを提案しますニューラルネットワーク。競合するタスクは異なるネットワークによって計算されます。多くのコンピュータビジョンアプリケーションでは、複数のタスクをリアルタイムで解く必要があります。 
[要約]ニューラルネットワークは、複数のタスクを同時に解決するようにトレーニングできます。これにより、タスクの目的が競合する可能性があるため、全体的なパフォーマンスが低下することがよくあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-18">
        <br><font color="black">2019-05-18</font>
      </time>
    </span>
</section>
<!-- paper0: Computational Analysis of Deformable Manifolds: from Geometric Modelling
  to Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_22.html">
      <font color="black">Computational Analysis of Deformable Manifolds: from Geometric Modelling
  to Deep Learning</font>
    </a>
  </h2>
  <font color="black">いわゆるビッグデータ時代の始まりと、増大するサイズの社会的および科学的データベースの急増により、効率的に処理、分析、さらには高次元データを生成できるアルゴリズムが必要になりました。この作業全体を通して、通信の計算を、作業の動機付けと結果の分析の両方を目的とする線として計算するという考え。これらの悪影響の一部を回避する1つの手法は、コヒーレントデータの幾何学的構造を利用することです。 
[ABSTRACT]これには、これらの問題のサイズに関してどれほど多くの古典的なアプローチが適切に拡張されないかが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Synthetic-to-Real Unsupervised Domain Adaptation for Scene Text
  Detection in the Wild -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_23.html">
      <font color="black">Synthetic-to-Real Unsupervised Domain Adaptation for Scene Text
  Detection in the Wild</font>
    </a>
  </h2>
  <font color="black">コードはhttps://github.com/weijiawu/SyntoReal_STDで入手できます。 2つのコンポーネントは、合成から実際のシーンに適応するときのシーンテキスト検出器のパフォーマンス向上にプラスの影響を与えます。TSTは、不正確な疑似ラベルによる偽陽性〜（FP）と偽陰性〜（FN）の悪影響を軽減します。 
[ABSTRACT]このペーパーには、テキスト適応型シーンテキスト検出のためのテキスト自己検出方法と敵対的なテキストインスタンスアライメント（ata）が含まれています。tstは、不正確な疑似ラベルからの誤検知と誤検知の悪影響を軽減します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Modification method for single-stage object detectors that allows to
  exploit the temporal behaviour of a scene to improve detection accuracy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_24.html">
      <font color="black">Modification method for single-stage object detectors that allows to
  exploit the temporal behaviour of a scene to improve detection accuracy</font>
    </a>
  </h2>
  <font color="black">この方法を使用すると、ベースネットワークの検出精度が、特に隠されたオブジェクトと隠されたオブジェクトで大幅に改善されることが示されています。修正されたネットワークは、修正されていないものよりも信頼性の高い隠されたオブジェクトを検出する傾向があります。 .. YOLOやSSDなどの単一ステージの汎用オブジェクト検出ニューラルネットワークの簡単な修正方法が提案されています。これにより、検出パイプライン内のシーンの時間的挙動を利用してビデオデータの検出精度を向上させることができます。 
[要約]修正されたネットワークのトレーニングを可能にする簡単な検出方法が提案されています。この方法を使用すると、ベースネットワークの検出精度を大幅に向上できることが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Finding New Diagnostic Information for Detecting Glaucoma using Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_25.html">
      <font color="black">Finding New Diagnostic Information for Detecting Glaucoma using Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">まず、4つの異なる国にある4つの三次眼科病院から得られた緑内障と非緑内障の症例からなるOCTスキャンのユニークで多様な多民族データセットを収集しました。したがって、LC領域はこの交絡状態で緑内障を区別するのに役立つ可能性があります。3Dスペクトルドメイン光干渉断層法（OCT）視神経スキャンにおける自動緑内障検出への新しいアプローチについて説明します。 
[要約]画像は4か国の4つの眼科病院から取得されました。篩状板領域は、通常の診療中に医師がこれまで利用できなかった有用な診断情報の貴重な情報源になる可能性があることがわかりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-14">
        <br><font color="black">2019-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: TAP-Net: Transport-and-Pack using Reinforcement Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_26.html">
      <font color="black">TAP-Net: Transport-and-Pack using Reinforcement Learning</font>
    </a>
  </h2>
  <font color="black">監視なしでランダムに生成された初期ボックス構成でネットワークをトレーニングし、ポリシーグラディエントを介して最適なTAPポリシーを学習し、パッキング効率と安定性を最大化します。ネットワークはエンコーダーデコーダーアーキテクチャに基づいて構築され、エンコーダーはボックスジオメトリと優先順位グラフおよびデコーダーは、現在のエンコーダー出力とターゲットコンテナーの現在のボックスパッキング状態を入力し、次のパックするボックスとその向きを出力するリカレントニューラルネットワーク（RNN）です。 。さまざまな例でTAP-Netのパフォーマンスを実証し、アブレーション研究とベースラインとの比較および代替ネットワーク設計との比較を通じてネットワークを評価します。 
[ABSTRACT]ボックスをコンパクトに輸送してターゲットコンテナーに詰める効率的な方法を模索しています。ネットワークはエンコーダー-デコーダーアーキテクチャ上に構築され、エンコーダーはコンボリューションレイヤーを使用してボックスをエンコードします。タップネットのパフォーマンスを実証しましたさまざまな例で</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: A Comparison of Pre-trained Vision-and-Language Models for Multimodal
  Representation Learning across Medical Images and Reports -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_27.html">
      <font color="black">A Comparison of Pre-trained Vision-and-Language Models for Multimodal
  Representation Learning across Medical Images and Reports</font>
    </a>
  </h2>
  <font color="black">OpenIデータセットの外因性評価は、先駆的なCNN-RNNモデルと比較して、事前トレーニング済みのV + Lモデルによって学習された共同埋め込みが、胸部所見の分類タスクにおけるパフォーマンスの向上を実証していることを示しています。特定のモデルコンポーネントの組み合わせと、テキストのみの埋め込みに対する共同埋め込みの利点を検証します。V+ Lモデルの注意メカニズムを示すために注意マップも視覚化します。 
[ABSTRACT] cnnのerrol barnettが事前トレーニング済みのvlモデルのグループに参加します。模倣からマルチモーダル表現を学習します-cxrラジオグラフと関連レポート</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: One-Shot Informed Robotic Visual Search in the Wild -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_28.html">
      <font color="black">One-Shot Informed Robotic Visual Search in the Wild</font>
    </a>
  </h2>
  <font color="black">この論文では、データの高レベルの仕様としてユーザーが指定した見本の画像のように見えるシーンの部分に向かってロボットの視覚探索を誘導する、学習された視覚的類似性演算子を介したインフォームドビジュアルナビゲーションを可能にする方法を提案しますこのナビゲーション方法はしばしば必要ですが、ロボットには科学者が関連する視覚的観察であると見なすもののモデルがないため、制限があります。また、協調的環境での情報に基づくビジュアルナビゲーション中にこの類似性演算子の展開を示しますロボットと人間の科学者が共同で関連する視覚的コンテンツを検索する大規模な現場試験での監視シナリオ。 
[ABSTRACT]ほとんどのフィールドビジュアルビジュアルナビゲーションは、水中領域での類似タスクに対してimagenetよりも優れたビデオ表現学習方法に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-22">
        <br><font color="black">2020-03-22</font>
      </time>
    </span>
</section>
<!-- paper0: EPSNet: Efficient Panoptic Segmentation Network with Cross-layer
  Attention Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_29.html">
      <font color="black">EPSNet: Efficient Panoptic Segmentation Network with Cross-layer
  Attention Fusion</font>
    </a>
  </h2>
  <font color="black">さらに、共有プロトタイプの品質を高めるために、「クロスレイヤー注意融合モジュール」と呼ばれるモジュールを採用しています。これは、マルチスケール機能を注意メカニズムと統合し、相互間の長距離依存関係をキャプチャするのに役立ちます。パノプティックセグメンテーションはセマンティックセグメンテーションとインスタンスセグメンテーションを単一のタスクに統合するシーン解析タスク。基本的に、EPSNetは、プロトタイプマスクとマスク係数の単純な線形結合に基づいてマスクを生成します。 
[ABSTRACT]現在の状態-最先端の研究では結論にあまり関心がありません。共有プロトタイプの品質を向上させる「クロスレイヤーアテンションフュージョン」モジュールを開発しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-23">
        <br><font color="black">2020-03-23</font>
      </time>
    </span>
</section>
<!-- paper0: Random Style Transfer based Domain Generalization Networks Integrating
  Shape and Spatial Information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_30.html">
      <font color="black">Random Style Transfer based Domain Generalization Networks Integrating
  Shape and Spatial Information</font>
    </a>
  </h2>
  <font color="black">この作業では、マルチベンダーおよび中心心臓画像セグメンテーションのドメイン一般化問題に取り組むために、ランダムスタイル転送ネットワークを提示します。さらに、フレームワークは、2つの正則化用語を導入することにより、ターゲットの前に空間情報と形状を組み込みます。モデルは、教師付きセグメンテーションと教師なしスタイルの翻訳目的を同時に最適化することにより、半教師付き方法でトレーニングできます。 
[ABSTRACT]モデルは、教師ありセクションと教師なしスタイルの翻訳目標を同時に最適化することにより、半教師付き方法でトレーニングできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: TopoMap: A 0-dimensional Homology Preserving Projection of
  High-Dimensional Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_31.html">
      <font color="black">TopoMap: A 0-dimensional Homology Preserving Projection of
  High-Dimensional Data</font>
    </a>
  </h2>
  <font color="black">たとえば、マッピングプロセスが、接続されたコンポーネントやループなどのトポロジーの不変条件に関してある程度の保証を与える場合、クラスターや外れ値などの特定の構造の分析をより確実に実行できます。多次元投影は、高次元のデータ分析と視覚化..しかし、幾何学的関係は、投影で保持される唯一の興味深いプロパティではありません。 
[ABSTRACT]投影方法は、認識された空間から視覚空間にデータをマッピングして、駐車距離などの非類似度（類似度）の測定値を維持するように設計されています。ただし、このような構造だけが保存される興味深いプロパティではありません投影で</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Pathomic Fusion: An Integrated Framework for Fusing Histopathology and
  Genomic Features for Cancer Diagnosis and Prognosis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_32.html">
      <font color="black">Pathomic Fusion: An Integrated Framework for Fusing Histopathology and
  Genomic Features for Cancer Diagnosis and Prognosis</font>
    </a>
  </h2>
  <font color="black">教師あり学習に続いて、各モダリティ全体で機能を解釈およびローカライズし、マルチモーダル入力で条件付けするときに機能の重要性がどのように変化するかを理解できます。この作業では、エンドツーエンドマルチモーダルフュージョンの解釈可能な戦略であるPathomic Fusionを提案します。組織学画像とゲノム（突然変異、CNV、RNA-Seq）機能の生存結果予測のための機能。提案された方法は、直観的な方法でマルチモーダル生物医学データのディープネットワークをトレーニングする方法に関する洞察と理論を確立し、他の問題に役立ちます。病気を理解し、治療への反応と耐性を予測するために、異種のデータストリームを組み合わせようとする医学で。 
[要約]神経膠腫を使用してアプローチを検証し、癌ゲノムアトラスから細胞腎細胞癌のデータセットを消去する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br><font color="black">2019-12-18</font>
      </time>
    </span>
</section>
<!-- paper0: DESC: Domain Adaptation for Depth Estimation via Semantic Consistency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_33.html">
      <font color="black">DESC: Domain Adaptation for Depth Estimation via Semantic Consistency</font>
    </a>
  </h2>
  <font color="black">メインモデルとセマンティックセグメンテーションとエッジマップでトレーニングされた2番目のモデルとの間の一貫性を適用し、インスタンスの高さの形式で事前分布を導入します。正確な実際の深度アノテーションは取得が難しく、LiDARセンサーなどの特別なデバイスを使用する必要があります..セマンティック予測と低レベルのエッジ機能を利用してドメインのギャップを埋め、ターゲットドメインのガイダンスを提供します。 
[ABSTRACT]セマンティック予測と低レベルのデータを利用してドメインギャップを埋め、ターゲットインスタンスのガイダンスを提供します。私たちのアプローチは、単眼深度推定の標準的な使用で評価されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Adherent Mist and Raindrop Removal from a Single Image Using Attentive
  Convolutional Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_34.html">
      <font color="black">Adherent Mist and Raindrop Removal from a Single Image Using Attentive
  Convolutional Network</font>
    </a>
  </h2>
  <font color="black">さらに、空間情報の損失なしに大きな受容野を得るために平滑化された拡張畳み込みが採用され、チャネルと空間的特徴を効率的に選択するためにデュアルアテンションモジュールが利用されます。フロントガラス、カメラレンズなどに付着した温度差による霧..手作りの事前分布なしで空間的注意を強化するために、モデルに分類活性化マップの注意を適用します。 
[ABSTRACT]手作業なしで空間的注意を強化するため-細工された事前。これは簡単に視力を妨げ、画像を大幅に劣化させる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Geometric Back-projection Network for Point Cloud Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_35.html">
      <font color="black">Geometric Back-projection Network for Point Cloud Classification</font>
    </a>
  </h2>
  <font color="black">合成および実際の両方の点群データセットのパフォーマンスは、ネットワークの優位性と適用性を示しています。特に、エラー修正フィードバック構造のアイデアを活用して、点群のローカル機能を包括的にキャプチャしています。他の状態との比較-最先端の方法では、私たちのアプローチは正確さと効率のバランスをとっています。 
[要旨]いくつかの未解決の問題に対処するために、より良い表現のために点群の幾何学的特徴をキャプチャするネットワークを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-28">
        <br><font color="black">2019-11-28</font>
      </time>
    </span>
</section>
<!-- paper0: Limited View Tomographic Reconstruction Using a Deep Recurrent Framework
  with Residual Dense Spatial-Channel Attention Network and Sinogram
  Consistency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_36.html">
      <font color="black">Limited View Tomographic Reconstruction Using a Deep Recurrent Framework
  with Residual Dense Spatial-Channel Attention Network and Sinogram
  Consistency</font>
    </a>
  </h2>
  <font color="black">質の高い再構成を導き出すために、以前の最先端の方法ではUNetのようなニューラルアーキテクチャを使用して、限られたビューデータから完全なビューの再構成を直接予測していました。しかし、これらの方法では、ディープネットワークアーキテクチャの問題はほとんど影響を受けず、再構成された画像のサイノグラムと取得されたサイノグラムの間の一貫性が保証されないため、理想的でない再構成が発生します。チャネルアテンションネットワーク..さらに、Deep Lesionデータセットに関する実験結果は、私たちの方法が8つの主要な病変タイプに対して高品質の再構成を生成できることを示しています。 
[ABSTRACT]サイノグラムの不完全性は、高ノイズと深刻なアーチファクトにつながる可能性があります。ただし、これらの最先端の再構成はほとんど不完全です。代わりに、新しいシステムを使用して再構成を繰り返すことができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Few-shot Object Detection with Feature Attention Highlight Module in
  Remote Sensing Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_37.html">
      <font color="black">Few-shot Object Detection with Feature Attention Highlight Module in
  Remote Sensing Images</font>
    </a>
  </h2>
  <font color="black">パラメータが共有される事前トレーニング済みの特徴抽出機能は、一般的な特徴を生成します。特徴アテンションハイライトモジュールは、少数のショットのケースに適合するように軽量でシンプルになるように設計されています。シンプルですが、シリアル方式で、一般的な機能を少数のショットのオブジェクトに固有にすることは役立ちます。 
[ABSTRACT]機能-エクストラクタ、機能アテンションハイライトモジュール、2ステージ検出バックエンドは、新しいクラスにすばやく適応できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Dexterous Robotic Grasping with Object-Centric Visual Affordances -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_38.html">
      <font color="black">Dexterous Robotic Grasping with Object-Centric Visual Affordances</font>
    </a>
  </h2>
  <font color="black">私たちの主なアイデアは、オブジェクト中心の視覚的アフォーダンスモデルを深い強化学習ループ内に埋め込み、人々が好む同じオブジェクト領域を好むポリシーを把握することを学ぶことです。私たちは、30自由度の5本指のロボットハンドシミュレータで2つのデータセットからの40個のオブジェクト。安定した把握のためのポリシーを効果的かつ効率的に学習します。アフォーダンスに基づくポリシーは、はるかに効果的で、新規オブジェクトに一般化し、ベースラインより3倍速くトレーニングします。 
[ABSTRACT]提案された事前はオブジェクト中心であり、イメージに基づいています。これにより、エージェントは、ポリシー学習中に見えないオブジェクトの有用なアフォーダンス領域を予測できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Tasks Integrated Networks: Joint Detection and Retrieval for Image
  Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_39.html">
      <font color="black">Tasks Integrated Networks: Joint Detection and Retrieval for Image
  Search</font>
    </a>
  </h2>
  <font color="black">有名な画像レベルの検索指向のベンチマークデータセットでの広範な実験は、提案されたDC-I-Netが最新のタスク統合およびタスク分離の画像検索モデルよりも優れていることを示しています。2 ）格納されたクラスセンターを活用することによるクラスセンターガイド付きHEP損失（C2HEP）が提案され、最終的な検索のために内部類似性と内部非類似性をキャプチャできます。 
[ABSTRACT]オブジェクトレベルの取得は、境界ボックスの注釈なしでは扱いにくくなり、これは、新しい、しかし難しいトピックにつながります。画像検索の問題に対処するには、最初にエンドツーエンドの統合ネット（i-net）を導入します3つのメリットがあります。数十億ドル規模の検索プロセスを改善するには、新たな課題が必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Light Field Image Super-Resolution Using Deformable Convolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_40.html">
      <font color="black">Light Field Image Super-Resolution Using Deformable Convolution</font>
    </a>
  </h2>
  <font color="black">ADAMに基づいて、センタービュー機能と各サイドビュー機能の間で双方向の位置合わせを実行するための収集と配布のアプローチをさらに提案します。LF-DFnetは、より忠実な詳細で高解像度の画像を生成し、状態を実現できます。最先端の再構成精度。さらに、異なる視差変動下でSRパフォーマンスを評価するために、ベースライン調整可能なLFデータセットを開発します。 
[ABSTRACT]私たちのアプローチを使用すると、角度情報を適切に組み込み、各ビューの機能に対してエンコードできます。これらの機能は、すべてのlf画像のsr再構成に役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Modeling Global Body Configurations in American Sign Language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_41.html">
      <font color="black">Modeling Global Body Configurations in American Sign Language</font>
    </a>
  </h2>
  <font color="black">この論文の主な貢献は次のとおりです。これは、一部には、ウィリアムC.ストコエの1960年の出版まで言語としての認識が遅れたことが原因です。確率的グラフィカルモデル（PGM）を使用して、リデルとジョンソンのムーブメントホールド（MH）モデルの簡易バージョンを実現します。 
[ABSTRACT]英語と比較すると、aslの言語に対する研究は限られています。3つの流暢な署名者で収集されたデータセットであるaslingでモデルをトレーニングしました。最後に、pgmのさまざまな側面を解釈し、aslの発音について結論を出します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Loss Weighting with Coefficient of Variations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_42.html">
      <font color="black">Multi-Loss Weighting with Coefficient of Variations</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、これらのマルチタスクアプローチがシングルタスクでは機能しないことを示しています。しかし、自動ロスウェイトの恩恵を受けることができるシングルタスクマルチロスの問題がたくさんあります。このペーパーでは、ウェイト特定のバッチ損失、平均損失、各損失の分散など、モデルのトレーニング中に観察された特性に基づいて定義されます。 
[ABSTRACT]これらの損失の正しい（相対的な）重量を見つけるのは困難です。これは、重量の損失の欠如に基づいていますが、自動損失重み付けの恩恵を受けることができる多数のマルチパーティ問題があります。代わりに、方法が提案されています特にシングルタスクマルチロス問題のトレーニング全体で、ロスウェイトを自動的かつ動的に調整します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Contour Sparse Representation with SDD Features for Object Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CV/paper_43.html">
      <font color="black">Contour Sparse Representation with SDD Features for Object Recognition</font>
    </a>
  </h2>
  <font color="black">このレターでは、SDDフィーチャーが定義され、オブジェクトの輪郭の疎な表現を形成します。各オブジェクトの参照モデルはSDDフィーチャーに基づいて構築され、次にモデルマッチングがオンラインオブジェクト認識に使用されます。オブジェクトは画像のヒストグラムに似ています。 
[ABSTRACT] sddは2つのパブリックデータセット（nusデータセットと近赤外線データセット）で100％の精度を達成しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-13">
        <br><font color="black">2019-10-13</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Local Embeddings for Relational Data Integration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CL/paper_0.html">
      <font color="black">Local Embeddings for Relational Data Integration</font>
    </a>
  </h2>
  <font color="black">深層学習ベースの手法が最近使用され、データ統合の問題について有望な結果が得られています。しかし、このアプローチはタプルを盲目的に文として扱い、タプルに存在する大量のコンテキスト情報を失います。ローカル埋め込みを取得するアルゴリズムを提案しますリレーショナルデータベースでのデータ統合タスクに有効です。 
[ABSTRACT]これらには、wikipediaなどの大規模なコーパスでトレーニングされた埋め込みが含まれます。ただし、一部のメソッドは自然言語処理に適応して埋め込みを取得します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-03">
        <br><font color="black">2019-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Sparse Meta Networks for Sequential Adaptation and its Application to
  Adaptive Language Modelling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CL/paper_1.html">
      <font color="black">Sparse Meta Networks for Sequential Adaptation and its Application to
  Adaptive Language Modelling</font>
    </a>
  </h2>
  <font color="black">単純なオンライン強化学習から大規模な適応言語モデリングまで、さまざまな逐次適応シナリオで強力なパフォーマンスを発揮します。人間はその場で高速インクリメンタル学習を実行でき、脳内のメモリシステムが重要な役割を果たします。レイヤー固有の高速メモリを備えたディープニューラルネットワーク。 
[ABSTRACT] fast-重みは各タイムステップで不適格に生成されます。重みは時間とともに徐々に累積され、オンラインの継続的な適応に役立つ帰納的バイアスを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: A Python Library for Exploratory Data Analysis and Knowledge Discovery
  on Twitter Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CL/paper_2.html">
      <font color="black">A Python Library for Exploratory Data Analysis and Knowledge Discovery
  on Twitter Data</font>
    </a>
  </h2>
  <font color="black">要約すると、提示されたPythonライブラリは、アラビア語、英語、スペイン語、ロシア語の言語ごとに、単語、単語のバイグラム、およびその頻度に関して、Twitter（2015年12月以降）から処理された大量の情報を取得します。さまざまなアプリケーションが提示されています。この投稿では、ライブラリの機能を説明するために、つぶやきで発見されたトピックの探索的分析から始めて、スペイン語の方言間の類似性を調査し、さまざまな国のモビリティレポートで補足しています。Twitterはおそらくソーシャルメディアの方が研究に適しています。 
[要約]この提案は、Twitterデータに関心のある研究者、Twitterでのイベントのマイニングプロセスを促進することを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: HiFiSinger: Towards High-Fidelity Neural Singing Voice Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CL/paper_3.html">
      <font color="black">HiFiSinger: Towards High-Fidelity Neural Singing Voice Synthesis</font>
    </a>
  </h2>
  <font color="black">ただし、サンプリングレートが高いと、周波数帯域が広くなり、波形シーケンスが長くなるため、周波数ドメインと時間ドメインの両方で歌声合成（SVS）に課題を投げかけます。小さなサンプリングレートを採用する従来のSVSシステムでは、上記の課題に十分に対処できません。忠実度の高い歌声は、通常、表現や感情を伝えるために、より高いサンプリングレート（たとえば、48kHz）を必要とします。 
[ABSTRACT]高音質の歌声に向けたsvsシステムであるhifisingerは、hifisingerに基づいています。hifisingerは、より高品質の高音質の歌声を合成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: NLPContributions: An Annotation Scheme for Machine Reading of Scholarly
  Contributions in Natural Language Processing Literature -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CL/paper_4.html">
      <font color="black">NLPContributions: An Annotation Scheme for Machine Reading of Scholarly
  Contributions in Natural Language Processing Literature</font>
    </a>
  </h2>
  <font color="black">NLPContributionsの方法論は、そのトピックのさらなる改良と開発に向けた幅広い議論を生むと想定しています。自然言語処理（NLP）記事、特に機械学習についての記事（ ML）は、さまざまな情報抽出タスクのためのアプローチです。これらの情報単位に基づいて開発したアノテーションスキームは、NLPContributionsと呼ばれます。 
[要約]パイロットアノテーションタスクは、50 nlp-mlの文学記事に対するパイロットアノテーション演習に基づいています。目的は、記事のセマンティック構造化のための主語-述語-オブジェクトステートメントの体系的なパターンセットを見つけることです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-23">
        <br><font color="black">2020-06-23</font>
      </time>
    </span>
</section>
<!-- paper0: Data Programming by Demonstration: A Framework for Interactively
  Learning Labeling Functions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CL/paper_5.html">
      <font color="black">Data Programming by Demonstration: A Framework for Interactively
  Learning Labeling Functions</font>
    </a>
  </h2>
  <font color="black">ただし、データプログラム（ラベリング関数）を作成するには、プログラミングリテラシーとドメインの専門知識の両方が必要です。従来のデータプログラミングと同等の差別的なモデルパフォーマンスを提供しながら、定規は使いやすく学習しやすく、全体的な満足度も高くなっています。ここでは、ユーザーのインタラクティブなデモを使用してラベリングルールを生成するための新しいフレームワーク、デモによるデータプログラミング（DPBD）を提案します。 
[ABSTRACT]データプログラムを作成するには、プログラミングリテラシーとドメインの専門知識が必要です。ユーザースタディを通じて、定規を従来のデータプログラミングと比較します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Too good to be true? Predicting author profiles from abusive language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CL/paper_6.html">
      <font color="black">Too good to be true? Predicting author profiles from abusive language</font>
    </a>
  </h2>
  <font color="black">性格特性は実際の値の15％以内で予測され、年齢は10年の誤差範囲で予測され、性別は症例の70％で正しく分類されました。著者の特性と言語使用の間にいくつかの統計的関係が確立されましたが、これらはパターンは高い予測パフォーマンスに変換されませんでした。これらの結果は、著者のプロファイリングに関する以前の研究と比較すると不十分であるため、乱用する言葉や脅威の評価のコンテキスト内でこれを適用する場合は注意が必要です。 
[ABSTRACT]乱用言語は、予測に基づいて差異が生じるかどうかがまだテストされていない特定の言語のドメインです。研究は米国中の研究者によって行われました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: COVID-19 SignSym: A fast adaptation of general clinical NLP tools to
  identify and normalize COVID-19 signs and symptoms to OMOP common data model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CL/paper_7.html">
      <font color="black">COVID-19 SignSym: A fast adaptation of general clinical NLP tools to
  identify and normalize COVID-19 signs and symptoms to OMOP common data model</font>
    </a>
  </h2>
  <font color="black">臨床ノートと医学的対話の評価は有望な結果を示しました。抽出された情報はOHDSI OMOPの共通データモデルの標準の臨床概念にもマッピングされます。COVID-19パンデミックは世界中で広がり、数百万人に急速に感染しています。 
[要約]このツールは、電子カルテのフリーテキストからcovid-19の重要な臨床概念を正確に認識することができます。APIの汎用パッケージとして数百万人がすばやくアクセスできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-13">
        <br><font color="black">2020-07-13</font>
      </time>
    </span>
</section>
<!-- paper0: Biomedical named entity recognition using BERT in the machine reading
  comprehension framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CL/paper_8.html">
      <font color="black">Biomedical named entity recognition using BERT in the machine reading
  comprehension framework</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、BC4CHEMD、BC5CDR-Chem、BC5CDR-Disease、NCBI Disease、BC2GMおよびJNLPBAデータセットで最先端の（SOTA）パフォーマンスを達成し、F1スコアは92.38％、94.19％、87.36％、90.04％です。 、それぞれ84.98％と78.93％です。この作業では、BioNERタスクをシーケンスのラベル付け問題として扱う代わりに、機械読解（MRC）問題として定式化します。ただし、この方法では、多くの場合、十分に活用できません。データセット内のセマンティック情報のパフォーマンス、およびパフォーマンスは必ずしも満足できるものではありません。 
[要約]この方法は現在従来の方法です。バイオナータスクをシーケンスラベル付け問題として扱うのではなく、機械読解として定式化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression
  Grounding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CL/paper_9.html">
      <font color="black">Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression
  Grounding</font>
    </a>
  </h2>
  <font color="black">この目的のために、最初の段階で式に対応した提案を生成する最初の方法であるRef-NMSを提案します。これらのスコアは、NMS操作を導き、式に関係のないボックスを除外して、重要なオブジェクトの想起を増加させることができます。その結果、大幅に改善された接地パフォーマンスが得られます。参照式の接地を解決するための一般的なフレームワークは、2段階のプロセスに基づいています。 
[ABSTRACT]新しい接地方法が開発され、広範囲に広がる広範囲の接地が開発されました。新しい接地方法は、新しい方法に簡単に統合できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: orgFAQ: A New Dataset and Analysis on Organizational FAQs and User
  Questions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CL/paper_10.html">
      <font color="black">orgFAQ: A New Dataset and Analysis on Organizational FAQs and User
  Questions</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、このようなFAQのプロパティの分析を提供し、新しいデータセットをジョブズドメインの関連タスクで利用することで、新しいデータセットの有用性を示します。FAQは、ユーザーの質問に回答するなど、いくつかのシナリオで使用されます。 。よくある質問（FAQ）Webページは、組織がユーザーのために作成します。 
[ABSTRACT]この分野での研究を促進するために、いくつかのfaqデータセットが存在します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Word Representation for Rhythms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CL/paper_11.html">
      <font color="black">Word Representation for Rhythms</font>
    </a>
  </h2>
  <font color="black">より大きなスキームでは、体系的な考察のために、思考モード-言語としての音楽-が提案されています。BERTモデルは、リズムワードの構文上の可能性を探索するために作成されます。 
[ABSTRACT]サイズが450のリズム単語辞書（制御トークンなし）を作成</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-21">
        <br><font color="black">2020-07-21</font>
      </time>
    </span>
</section>
<!-- paper0: Knowing What to Listen to: Early Attention for Deep Speech
  Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CL/paper_12.html">
      <font color="black">Knowing What to Listen to: Early Attention for Deep Speech
  Representation Learning</font>
    </a>
  </h2>
  <font color="black">提案モデルは、話者認識と音声感情認識という2つの一般的なタスクで評価されます。ただし、現在の注意メカニズムでは、きめ細かい情報項目に対応できません。注意モデルは、深層学習モデルの改善に重要な役割を果たします。 
[要約]ディープラーニングモデルによって抽出された音声表現は、音声認識、元の認識、音声感情認識など、幅広いタスクで使用されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: GREEK-BERT: The Greeks visiting Sesame Street -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CL/paper_13.html">
      <font color="black">GREEK-BERT: The Greeks visiting Sesame Street</font>
    </a>
  </h2>
  <font color="black">興味深いことに、2つのベンチマークで、GREEK-BERTは2つの多言語トランスフォーマーベースのモデル（M-BERT、XLM-R）、および事前トレーニングされた単語の埋め込みで動作するより浅いニューラルベースラインを大幅に上回っています（5％-10 ％）..私たちはこれらのリソースが現代ギリシャ語のNLP研究とアプリケーションを後押しすることを期待しています..最も重要なこととして、GREEK-BERTとトレーニングコードの両方を公開し、GREEK-BERTをダウンストリーム用に微調整する方法を示すコードを公開しています。 NLPタスク。 
[ABSTRACT]これらのモデルは主にリソースに適用されています-豊富な英語。ただし、これらのモデルは主に現在の言語に使用されています。これらのモデルには、一部のbertと、ギリシャ語-bertをどのように微調整できるかを示すコードが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: A Practical Chinese Dependency Parser Based on A Large-scale Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CL/paper_14.html">
      <font color="black">A Practical Chinese Dependency Parser Based on A Large-scale Dataset</font>
    </a>
  </h2>
  <font color="black">このレポートでは、Baidu Chinese Treebank（DuCTB）と呼ばれる大規模な手動でラベル付けされたデータセットでトレーニングされた新しい中国の依存関係パーサーであるBaidu Dependency Parser（DDParser）を紹介します。このため、いくつかの産業指向の依存関係パーサーツールが公開されています。 2つのテストセットで実験を行います。トレーニングセットと同じ分布の標準テストセットと、他のソースからサンプリングされたランダムテストセット、およびそれらのラベル付き添付ファイルスコア（LAS）はそれぞれ92.9％と86.9％です。 
[ABSTRACT]ソーシャルネットワークベース（nnベース）の依存解析が大幅に進歩しました。2つのテストセット（標準のtestparparparと他のソースからサンプリングされたランダムテストセット）で実験を行います。ductserは、さまざまなものからの約100万の注釈付き文で構成されていますソース</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: The ADAPT Enhanced Dependency Parser at the IWPT 2020 Shared Task -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/cs.CL/paper_15.html">
      <font color="black">The ADAPT Enhanced Dependency Parser at the IWPT 2020 Shared Task</font>
    </a>
  </h2>
  <font color="black">その後、独自のグラフ接続修正を実装し、79.53（言語平均）または79.76（ツリーバンク平均）のスコアになりました。これは、競争評価で4番目になります。残念ながら、接続グラフを私たちのパイプラインアプローチと競争の提出は、公式の評価スコアを著しく損なう検証スクリプトを渡すために土壇場の修正に依存していました。拡張された依存関係グラフは、グラフベースのセマンティック依存関係パーサーによって生成されるか、または基本ツリーから構築されますヒューリスティックの小さなセットを使用します。 
[要旨] udpipeとudpipeを使用してパイプラインシステムを実装します。アノテーションを提供するために使用されることが予想されます。結果から、大多数の言語では、セマンティック依存関係パーサーは小さくなり得ることがわかります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: FeatherWave: An efficient high-fidelity neural vocoder with multi-band
  linear prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.AS/paper_0.html">
      <font color="black">FeatherWave: An efficient high-fidelity neural vocoder with multi-band
  linear prediction</font>
    </a>
  </h2>
  <font color="black">この論文では、マルチバンド信号処理と線形予測コーディングを組み合わせたWaveRNNボコーダーの別の変形であるFeatherWaveを提案します。マルチバンド方式では、モデルで複数の音声サンプルを1つのステップで並列に生成できます。 4つのサブバンドを持つ提案されたモデルは、音声生成に1.6 GFLOPS未満しか必要としません。 
[ABSTRACT] wavernnアーキテクチャで音声信号の線形予測特性を使用するlpcnetは、リアルタイムよりも高速で高品質の音声を生成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br><font color="black">2020-05-12</font>
      </time>
    </span>
</section>
<!-- paper0: Real Time Speech Enhancement in the Waveform Domain -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.AS/paper_1.html">
      <font color="black">Real Time Speech Enhancement in the Waveform Domain</font>
    </a>
  </h2>
  <font color="black">客観的な指標と人間の判断の両方を使用して、いくつかの標準ベンチマークの評価を実行します。提案されたモデルは、生の波形を直接処理しながら、因果法と非因果法の両方の最先端のパフォーマンスに一致します。因果スピーチを提示しますラップトップCPUでリアルタイムに実行される生の波形を処理する拡張モデル。 
[要約]提案されたモデルは、スキップ接続を備えたエンコーダー/デコーダーアーキテクチャに基づいています。定常および非定常ノイズを含むさまざまな種類のバックグラウンドノイズ、およびルームリバーブを削除できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-23">
        <br><font color="black">2020-06-23</font>
      </time>
    </span>
</section>
<!-- paper0: Intra-Utterance Similarity Preserving Knowledge Distillation for Audio
  Tagging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.AS/paper_2.html">
      <font color="black">Intra-Utterance Similarity Preserving Knowledge Distillation for Audio
  Tagging</font>
    </a>
  </h2>
  <font color="black">ただし、ミニバッチ内の入力間のペアワイズの類似性を維持する代わりに、この方法は単一入力発話のフレーム間のペアワイズの類似性を維持します。音響イベントの反復的な性質を考えると、この情報を活用してKDを調整することを提案しますオーディオのタグ付けのトレーニング..これは、以前に公開されたKDメソッド「Similarity Preserving KD」（SP）によって動機付けられています。 
[ABSTRACT] kdメソッドは、単一の入力発話のフレーム間のペアごとの類似性を維持する代わりに、音声タグ付けタスクの有望な結果を示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Voice Conversion by Cascading Automatic Speech Recognition and
  Text-to-Speech Synthesis with Prosody Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.AS/paper_3.html">
      <font color="black">Voice Conversion by Cascading Automatic Speech Recognition and
  Text-to-Speech Synthesis with Prosody Transfer</font>
    </a>
  </h2>
  <font color="black">また、音声変換チャレンジ2020の単一言語タスクで最高の自然さと類似性が得られました。TTSモデルでは、音声に含まれるテキストおよび話者情報以外の韻律情報を記述するために韻律コードを使用することを提案しました。韻律コードは、韻律エンコーダを使用して抽出されます。 
[ABSTRACT] asr-音声変換のttsメソッドは、韻律エンコーダを使用してコードを抽出します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: HiFiSinger: Towards High-Fidelity Neural Singing Voice Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.AS/paper_4.html">
      <font color="black">HiFiSinger: Towards High-Fidelity Neural Singing Voice Synthesis</font>
    </a>
  </h2>
  <font color="black">小さなサンプリングレートを採用する従来のSVSシステムは、上記の課題に十分に対処できません。実験結果は、HiFiSingerが高品質の歌声を合成することを示しています。 ..具体的には、1）高いサンプリングレートによって引き起こされるより広い範囲の周波数を処理するために、メルスペクトログラム生成で新しいサブ周波数GAN（SF-GAN）を提案します。これは、完全な80次元のメル周波数を複数に分割します。サブバンドおよび各サブバンドを個別の弁別子でモデル化します。 
[ABSTRACT]高音質の歌声に向けたsvsシステムであるhifisingerは、hifisingerに基づいています。hifisingerは、より高品質の高音質の歌声を合成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Knowing What to Listen to: Early Attention for Deep Speech
  Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-04/eess.AS/paper_5.html">
      <font color="black">Knowing What to Listen to: Early Attention for Deep Speech
  Representation Learning</font>
    </a>
  </h2>
  <font color="black">提案されたモデルを、話者認識と音声感情認識の2つの一般的なタスクで評価します。また、バックボーンネットワークと比較して、堅牢性と感度の改善を示すさまざまなレベルの追加ノイズに対してモデルをテストしました。ただし、現在の注意メカニズムでは、きめ細かい情報項目に注意してください。 
[要約]ディープラーニングモデルによって抽出された音声表現は、音声認識、元の認識、音声感情認識など、幅広いタスクで使用されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
