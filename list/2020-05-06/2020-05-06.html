<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-05-06の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Study of human phonation in a full body domain -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.SD/paper_0.html">
      Study of human phonation in a full body domain
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      VFの動きに関連する声門下の体積速度が一定の準1次元定式化に基づく新しい種類の流入境界条件が採用されました。全身領域には、VF付近の領域、ボーカルが含まれます軟口蓋と口の簡略化されたモデルであるトラクト、および音響の遠距離場に拡張されます。VF組織の材料特性は、さまざまな剛性を備えた多層構造であり、有限ひずみモデルが利用され、二次式で実装されます。有限要素コード。 
[要約]人間の声の流体は、圧縮性で粘性のある流体としてモデル化されます。流体-固体ドメインは境界を介して結合されます-適合したインターフェースとポアソンの説明に基づくメッシュ法
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: End-to-end Whispered Speech Recognition with Frequency-weighted
  Approaches and Layer-wise Transfer Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.SD/paper_1.html">
      End-to-end Whispered Speech Recognition with Frequency-weighted
  Approaches and Layer-wise Transfer Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これには、周波数で重み付けされたSpecAugmentポリシーと、周波数で分割されたCNN機能エクストラクタが含まれ、ささやき声の高周波構造をより適切にキャプチャします。通常の音声でモデルを事前トレーニングしてから、ささやき音声とささやき音声と通常の音声の間のギャップを埋めます。結果は、通常の音声で事前トレーニングされた優れたE2Eモデルがある限り、比較的小さなささやき音声のセットで、かなり良いE2Eささやき音声認識機能を取得するのに十分である可能性があります..比較的小さなささやきのTIMITコーパスで、PERが19.8％、CERが31.9％の全体的な相対削減を達成しました。 
[要約]新しい研究は、ささやき声を簡単に特定できる方法を示しています。これには、19。8％とcerの31.9％の減少が含まれます。これらの測定値には、ささやき声の特別な特性とデータの不足が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: EEG based Continuous Speech Recognition using Transformers -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.SD/paper_2.html">
      EEG based Continuous Speech Recognition using Transformers
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの結果は、トランスフォーマーベースのモデルが、リカレントニューラルネットワーク（RNN）ベースのシーケンス間EEGモデルと比較して高速なトレーニングを示し、テストセットボキャブラリーが小さい場合の推論時間中のパフォーマンスが向上しますが、ボキャブラリーサイズを大きくすると、RNNのパフォーマンスが向上しますこのモデルでは、最近導入されたエンドツーエンドのトランスフォーマーベースの自動音声認識（ASR）モデルを使用して、脳波記録（EEG）機能を使用した連続音声認識を調査します。 
[ABSTRACT]結果は、トランスフォーマーベースのモデルが、再帰型ニューラルネットワーク（rnn）ベースのシーケンス間シーケンス）eegモデルと比較してより高速なトレーニングを示すことを示しています。ボキャブラリサイズを増やすと、rnnベースのモデルのパフォーマンスはトランスフォーマーベースのモデルよりも優れていました限られた英語の語彙のモデル
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-31">
        <br>2019-12-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: DIHARD II is Still Hard: Experimental Results and Discussions from the
  DKU-LENOVO Team -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.SD/paper_3.html">
      DIHARD II is Still Hard: Experimental Results and Discussions from the
  DKU-LENOVO Team
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの提案するシステムは、Track1で18.84％DER、Track2で27.90％DERを達成します。変分ベイズ（VB）ダイアライゼーションが再セグメンテーション段階で適用され、オーバーラップ検出もわずかな改善をもたらします。公式ベースラインに比べて％、ダイアライジングタスクは依然として非常に難しいと考えています。 
[要約]提案されたシステムには、音声アクティビティ検出（vad）、パーソナライゼーション、スピーカー拡張が含まれます。システムには、resnet-lstmベースのスピーカー埋め込みとlstmベースの類似性スコアリングも含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-23">
        <br>2020-02-23
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Query Reformulation using Query History for Passage Retrieval in
  Conversational Search -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_0.html">
      Query Reformulation using Query History for Passage Retrieval in
  Conversational Search
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの線に沿って、2つのシンプルでありながら効果的なクエリ再定式アプローチを提案します。これは、履歴クエリ拡張（HQE）とニューラル転送再定式（NTR）です。2つのアプローチの異なる動作をさらに分析し、それらの出力を融合することでパフォーマンスギャップが減少することを示します。 （NDCG @ 3で測定）手動で書き換えられたクエリと自動生成されたクエリの間で、最高のCAsT提出と比較して22ポイントから4に。提案されたHQE方法は、TREC 2019でCAsTトラックの自動システムの最高の提出でした。
[ABSTRACT]会話型検索のパッセージランキングに効果的なマルチステージパイプラインを提示します。ntrは、会話型質問理解に関する人間の知識を神経質問再定式モデルに転送します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Lipschitz Constrained Parameter Initialization for Deep Transformers -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_1.html">
      Lipschitz Constrained Parameter Initialization for Deep Transformers
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      以前の調査の結果とは対照的に、Lipschitzパラメータの初期化により、元の計算順序の深いトランスフォーマーが収束し、最大24層のBLEUの大幅な改善が得られることをさらに実証します。次に、計算順序の微妙な違いをかなり詳細に比較します。 、および効果的にトレーニングの収束を保証するTransformerパラメーターの初期化に対するLipschitz制約を利用するパラメーター初期化メソッドを示します。このホワイトペーパーでは、最初に、公式の実装で行われた簡単な変更により、残差の計算順序が変わることを実証します。接続とレイヤーの正規化により、ディープトランスフォーマーの最適化が大幅に容易になります。 
[ABSTRACT]以前の調査によると、ディープトランスフォーマーはまだトレーニングに問題があります。12を超えるエンコーダー/デコーダーレイヤーを持つディープモデルは収束に失敗します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-08">
        <br>2019-11-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Survey on Dialog Management: Recent Advances and Challenges -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_2.html">
      A Survey on Dialog Management: Recent Advances and Challenges
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この調査は、対話管理の将来の研究に光を当てることができると信じています。対話の履歴から、DMは対話状態を予測し、対話エージェントが取るべき次のアクションを決定します。対話管理（DM）は、タスク指向の対話システム。 
[要約]新しいペーパーで、最近の進歩と課題を調査します。これらには、より良いタスクを達成するためのトレーニング効率の改善が含まれます-完了パフォーマンス
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Syntactic Preordering for Controlled Paraphrase Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_3.html">
      Neural Syntactic Preordering for Controlled Paraphrase Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      自然言語文の言い換えは多面的なプロセスです。個々の単語や短いフレーズの置き換え、コンテンツの局所的な再配置、トピック化やパッシブ化などの高レベルの再構築が必要になる場合があります。機械翻訳の先行予約文学に触発された私たちの作品は、構文を使用していますソース文を柔らかく「並べ替え」、神経言い換えモデルを導くための変換。自動と人間の両方の評価により、提案されたシステムはベースラインアプローチの品質を維持しながら、生成された言い換えの多様性を大幅に向上させることが示されています。 
[要約]言い換えは、言い換えの可能性を作成するために使用できます。これまでのアプローチは、言い換えの可能性のこのスペースをカバーするのに苦労しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SLEDGE: A Simple Yet Effective Baseline for Coronavirus Scientific
  Knowledge Search -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_4.html">
      SLEDGE: A Simple Yet Effective Baseline for Coronavirus Scientific
  Knowledge Search
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      https://github.com/Georgetown-IR-Lab/covid-neural-irで、この重要なタスクの将来の作業を容易にするためのコードをリリースします。 SRECGEの有効性は、TREC-COVIDチャレンジ（リーダーボードのnDCG @ 10が0.6844を上回っています）の強力なベースラインとして観察されます。カウント信号に大きく依存する神経方法の可能性。 
[ABSTRACT]モデルを一般的な-ドメイン回答ランキングデータセットでトレーニングします。関連性信号をsars-cov-2に評価のために転送します。詳細な分析によって提供される洞察は、いくつかの潜在的な課題を提供します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Self-organizing Pattern in Multilayer Network for Words and Syllables -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_5.html">
      Self-organizing Pattern in Multilayer Network for Words and Syllables
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      スケーリング構造の分析形式が導出され、インターネットスラングがどのようにファッショナブルになるかを定量化するために使用されます。これは、進化言語学の新しいツールとしての有用性を示しています。言語学者の究極の目標の1つは、人間の言語で普遍的な特性を見つけることです。一般に、言語形式と意味の間の任意のマッピングを表すと見なされます。Zipfを補完する、音節の同様に重要な役割を強調する新しい普遍法則を提案します。 
[要約]私たちは、音節の役割を強調する新しい普遍的な法則を提案します。提案された法則に加えて、単語と音節の多層ネットワークを発見します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Not All Claims are Created Equal: Choosing the Right Statistical
  Approach to Assess Hypotheses -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_6.html">
      Not All Claims are Created Equal: Choosing the Right Statistical
  Approach to Assess Hypotheses
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      一歩前進として、NLP研究に合わせたベストプラクティスとガイドライン、および仮説のベイズ評価のための「HyBayes」と呼ばれる使いやすいパッケージを提供し、既存のツールを補完します。これらの統計手法は、評価方法を選択する前に、開業医はまずターゲット仮説を決定する必要があると主張します。自然言語処理（NLP）の実証研究では、主にp値の計算に依存して仮説を評価するための狭い一連の原則を採用しています。いくつかの既知の問題から。 
[ABSTRACT]代替案は他の分野でも十分に議論され採用されていますが、nlp研究コミュニティ内で議論または使用されることはほとんどありません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br>2019-11-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CDL: Curriculum Dual Learning for Emotion-Controllable Response
  Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_7.html">
      CDL: Curriculum Dual Learning for Emotion-Controllable Response
  Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、カリキュラム学習を適用して、さまざまな感情を表現する難しさに基づいて高品質の応答を徐々に生成します。CDLは、感情とコンテンツに焦点を当てた2つの報酬を利用して、双対性を改善します。これらの問題を緩和するために、カリキュラムという新しいフレームワークを提案しますデュアルラーニング（CDL）。感情制御可能な応答の生成をデュアルタスクに拡張して、感情的な応答と感情的なクエリを生成します。 
[ABSTRACT] quelableは、感情表現を改善することを目的としています。標準のクロスネバダ損失に正則化用語を徐々に追加することで、感情学習を向上させることを目的としています。ただし、以前のモデルではこれらの質問は無視され、一貫性がさらに損なわれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br>2020-05-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Truthfulness of Headline Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_8.html">
      Improving Truthfulness of Headline Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最先端のエンコーダーデコーダーモデルによって生成されたヘッドラインを分析すると、モデルが不正確なヘッドラインを生成することがあることがわかります。理由の1つは、モデルのトレーニングに使用された不正確な監視データにあると推測します。データセット内の少数の不当なインスタンスであるこの研究では、監視データから不当なインスタンスを削除すると、モデルの不当な動作の問題が改善される可能性があると仮定しています。 
[ABSTRACT]最新のエンコーダー-デコーダーモデルが時々真実でない見出しを生成する
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-02">
        <br>2020-05-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Digraph of Senegal s local languages: issues, challenges and prospects
  of their transliteration -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_9.html">
      Digraph of Senegal s local languages: issues, challenges and prospects
  of their transliteration
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ラテン文字で書くことは、ICT（Wolofで翻訳されたWeb、辞書、WindowsおよびGoogleツールなど）のローカライズに使用されます。この作業は、共同オンライン辞書Wolof（Nguer EM、Khoule M、 Thiam MN、Mbaye BT、Thiare O.、Cisse MT、Mangeo M. 2014）。これは、アジャミライティングを使用する人々を対象としています。両方の集団に知識への一般的なアクセスを促進するには、これら2つの経典の間に文字変換ツールを設定すると便利です。 
[ABSTRACT]アルファベットベースのライティングには独自のアプリケーションがあります。ajami、伝統医学、伝統宗教医学はオプションの1つです。作品は共同オンライン辞書のプロジェクトの一部です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: It's Easier to Translate out of English than into it: Measuring Neural
  Translation Difficulty by Cross-Mutual Information -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_10.html">
      It's Easier to Translate out of English than into it: Measuring Neural
  Translation Difficulty by Cross-Mutual Information
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、最新のニューラル翻訳システムを使用したクロスリンガル翻訳の難しさの最初の体系的で制御された研究を紹介します。この論文では、クロス相互情報（XMI）を提案します。ほとんどの神経機械翻訳モデルの性質。実験を複製するためのコードは、https：//github.com/e-bug/nmt-difficultyからオンラインで入手できます。 
[要約]ブルーメトリックでは、どの翻訳方向をモデル化するのがより難しいかを評価できません。これは、ターゲット言語のプロパティと生成に依存しているためです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Deep Eyedentification: Biometric Identification using Micro-Movements of
  the Eye -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_11.html">
      Deep Eyedentification: Biometric Identification using Micro-Movements of
  the Eye
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      以前の作業と比較して、ネットワークは1桁低いエラーレートを達成し、2桁高速です。数秒以内にユーザーを正確に識別します。生体識別のために目の不随意の微小な動きを研究しています。研究では、ビデオベースのアイトラッキングシステムの出力から低周波数のマクロ動作を抽出し、これらのマクロ動作の明示的な機能を設計して、生のアイトラッキング信号を処理する深い畳み込みアーキテクチャを開発します。 
[要約]以前の研究では、ビデオの出力から低周波数のマクロの動きを抽出しています-ベースの眼-追跡システム
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-20">
        <br>2019-06-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Head-Driven Phrase Structure Grammar Parsing on Penn Treebank -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_12.html">
      Head-Driven Phrase Structure Grammar Parsing on Penn Treebank
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、変換された2つのツリー表現、分割スパンと結合スパンに対してそれぞれ2つの解析アルゴリズムが提案されます。このパーサーは、ペンツリーバンク（PTB）とチャイニーズペンツリーバンクの両方の解析タスクで新しい最先端のパフォーマンスを実現し、有効性を検証します。共同学習の構成要素と依存関係の構造の分析。詳細には、構成要素の解析の96.33 F1とPTBでの依存関係の解析の97.20 \％UASを報告します。 
[要約]提案されたhpsgパーサーは、両方のタイプの構造のジョイントデコーダになる可能性があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-05">
        <br>2019-07-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Dynamically Adjusting Transformer Batch Size by Monitoring Gradient
  Direction Change -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_13.html">
      Dynamically Adjusting Transformer Batch Size by Monitoring Gradient
  Direction Change
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      WMT 14の英語からドイツ語および英語からフランス語へのタスクでの実験では、25kの固定バッチサイズでトランスフォーマーをそれぞれ+0.73および+0.82 BLEU改善します。大規模モデルに対するアプローチの効率を改善するために、バッチサイズに敏感なパラメーターの勾配を選択するためのサンプリング手法。ミニバッチの勾配を累積し、勾配の方向が変動し始めたときに最適化ステップを実行することにより、バッチサイズを自動的かつ動的に決定することを提案します。 
[ABSTRACT]これは、ほんの一握りの論文がバッチサイズの影響に焦点を当てたのは初めてです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Creating a Multimodal Dataset of Images and Text to Study Abusive
  Language -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_14.html">
      Creating a Multimodal Dataset of Images and Text to Study Abusive
  Language
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      イタリア語のコメントを含むコーパスをさまざまな視点から分析し、画像の主題がコメントのトリガーに役割を果たすかどうかを調査しました。そこで、マルチモーダルを作成するために学校のクラスで使用されている注釈ツールであるCREENDERを開発しました。画像のデータセットと悪意のあるコメント。Apache2.0ライセンスの下で自由に利用できるようにします。写真に人物がいると不快なコメントを受け取る可能性が高くなりますが、ユーザーは同じ画像をさまざまな方法で判断します。 
[ABSTRACT]このツールはフランスの研究者によって開発されました。学校の授業で嫌われたデータセットを作成するために使用されています。ユーザーは同じ画像をさまざまな方法で判断しますが、写真に人物がいると不快なコメントを得る可能性が高くなります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CODA-19: Reliably Annotating Research Aspects on 10,000+ CORD-19
  Abstracts Using Non-Expert Crowd -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_15.html">
      CODA-19: Reliably Annotating Research Aspects on 10,000+ CORD-19
  Abstracts Using Non-Expert Crowd
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      エキスパートアノテーションの取得は遅くなる可能性がありますが、CODA-19は、エキスパートではない群衆をCOVID-19との戦闘に参加するために大規模に迅速に採用できることを実証しました。 AI / NLP研究のバッテリー..このペーパーでは、COVID-19オープンリサーチデータセット内の10,966英語のアブストラクトの背景、目的、方法、発見/貢献などを示す、人間が注釈を付けたデータセットCODA-19を紹介します。 
[ABSTRACT] coda-19は、amazonメカニカルタークの248人のクラウドワーカーによって10日以内にまとめて作成されました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Fine-grained Opinion Mining in Financial Data: A Survey and Research
  Agenda -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_16.html">
      Fine-grained Opinion Mining in Financial Data: A Survey and Research
  Agenda
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、提案された研究課題に対処するための可能な指示を提供します。このポジションペーパーでは、まず大まかな視点と細かい視点の両方から財務的見解を定義し、次にすでに取り組んだ問題の概要を示します。既存のトピックの研究課題をリストすることに加えて、私たちはさらに将来の研究のためのきめの細かい財務意見マイニングのロードマップを提案し、まだ探求していないいくつかの課題を指摘します。 
[要約]金融技術（fintech）開発は、投資家の意見の詳細な分析に関与する共同研究者を育成しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Revisiting Simple Domain Adaptation Methods in Unsupervised Neural
  Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_17.html">
      Revisiting Simple Domain Adaptation Methods in Unsupervised Neural
  Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのシナリオに基づいて、UNMTでのバッチ重み付けや微調整方法など、既存のドメイン適応方法の影響を再検討します。最後に、ドメイン固有のUNMTシステムのパフォーマンスを改善するための変更された方法を提案します。ドメイン適応は、教師付き神経機械翻訳（SNMT）で研究されています。 
[ABSTRACT] unmtは最近、いくつかのドメイン-特定の言語ペアで注目すべき結果を達成しました。以前の研究では、教師なし神経機械翻訳のさまざまなシナリオが示されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-26">
        <br>2019-08-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An Accurate Model for Predicting the (Graded) Effect of Context in Word
  Similarity Based on Bert -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_18.html">
      An Accurate Model for Predicting the (Graded) Effect of Context in Word
  Similarity Based on Bert
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの論文では主に、文脈が類似の単語の人間の知覚に与える影響を分析する方法論について説明します。これは、SemEval 2020の3番目のタスクです。サブタスク1のフィンランド語トラックで1位、英語トラックで2位サブタスク1の。トランスフォーマー（BERT）からの双方向エンコーダー表現によって生成された2つの埋め込みベクトル間の距離を計算する際に、いくつかの方法を適用します。 
[ABSTRACT]私たちのチームは `フィンランドで1位、英語で2位を獲得します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-03">
        <br>2020-05-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: End-to-end Whispered Speech Recognition with Frequency-weighted
  Approaches and Layer-wise Transfer Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_19.html">
      End-to-end Whispered Speech Recognition with Frequency-weighted
  Approaches and Layer-wise Transfer Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は、通常の音声で事前トレーニングされた優れたE2Eモデルがある限り、比較的小さなウィスパー音声のセットで、適度に優れたE2Eウィスパー音声認識機能を取得するのに十分である可能性があることを示しています。これには、周波数加重SpecAugmentポリシーと周波数ささやき音声の高周波構造をより適切にキャプチャするための分割CNN特徴抽出機能、および通常の音声でモデルを事前トレーニングし、ささやき音声でそれを微調整して、ささやき音声と通常の音声の間のギャップを埋めるレイヤー単位の転送学習アプローチ..ささやき声は人間の音声の重要なモードですが、おそらく利用可能なささやき声の音声データが不足しているため、それに関するエンドツーエンドの認識結果はまだ報告されていません。 
[要約]新しい研究は、ささやき声を簡単に特定できる方法を示しています。これには、19。8％とcerの31.9％の減少が含まれます。これらの測定値には、ささやき声の特別な特性とデータの不足が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Establishing Baselines for Text Classification in Low-Resource Languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_20.html">
      Establishing Baselines for Text Classification in Low-Resource Languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最初に、テキスト分類のベンチマークデータセットおよび低リソース言語フィリピンの低リソースマルチラベルテキスト分類として、以前にリリースされていない2つのデータセットを紹介します。研究コミュニティが使用するすべてのモデルとデータセットをリリースします。フィリピンの設定で使用するBERTおよびDistilBERTモデル。 
[ABSTRACT]フィリピンでの作業中、モデルをテストするためにシンプルなツールが使用されています。これらは、これらのモデルなど、シンプルでシンプルでシンプルな手段です。これらは、これらのモデルがより効果的であることを確認するために使用されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploring Contextual Word-level Style Relevance for Unsupervised Style
  Transfer -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_21.html">
      Exploring Contextual Word-level Style Relevance for Unsupervised Style
  Transfer
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このように、このモデルには、各出力ワードのスタイル関連性を自動的に予測する機能が備わっています。教師なしスタイル転送は、並列トレーニングデータを使用せずに元のコンテンツを維持しながら、入力センテンスのスタイルを変更することを目的としています。次に、このモデルのデコーダーにニューラルスタイルコンポーネントを装備し、予測されたワードレベルのスタイルの関連性を利用してスタイル転送を改善します。 
[要旨]スタイル分類子を事前トレーニングしました。各入力単語と元のスタイルとの関連性を定量化できます。このようにして、このモデルには、各出力単語のスタイルの有効性を自動的に予測する機能が備わっています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ExpBERT: Representation Engineering with Natural Language Explanations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_22.html">
      ExpBERT: Representation Engineering with Natural Language Explanations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      3つのリレーション抽出タスク全体で、私たちの方法であるExpBERTはBERTベースラインに一致しますが、ラベル付きデータが3〜20倍少なく、同じ量のラベル付きデータでベースラインが3〜10 F1ポイント向上します。指定するとします。結婚したカップルがテキストから配偶者のペアを抽出するタスクのために新婚旅行に行く典型的な帰納的バイアス。この論文では、モデル開発者がこれらのタイプの帰納的バイアスを自然言語の説明として指定できるようにします。 
[ABSTRACT]モデル開発者がこれらのタイプの帰納的バイアスを自然言語の説明として指定できるようにします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Code-switching patterns can be an effective route to improve performance
  of downstream NLP applications: A case study of humour, sarcasm and hate
  speech detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_23.html">
      Code-switching patterns can be an effective route to improve performance
  of downstream NLP applications: A case study of humour, sarcasm and hate
  speech detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この単純な言語的観察は、他の同様のNLPアプリケーションの改善にも役立つ可能性があると考えています。このホワイトペーパーでは、コードスイッチングパターンを利用して、さまざまなダウンストリームNLPアプリケーションを改善する方法を示します。特に、さまざまなスイッチング機能をエンコードしてユーモア、皮肉、ヘイトスピーチの検出タスクを改善します。 
[ABSTRACT]言語を改善するためのさまざまな方法を発明します。また、知性と知性を改善するためにさまざまな投票機能を発明します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural CRF Model for Sentence Alignment in Text Simplification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_24.html">
      Neural CRF Model for Sentence Alignment in Text Simplification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CRFアライナを適用して、Newsela-AutoとWiki-Autoの2つの新しいテキスト簡略化データセットを構築します。これらは、既存のデータセットに比べてはるかに大きく、品質が優れています。テキスト簡略化システムの成功は、品質と量に大きく依存します。並列の記事間で文を揃えることによって抽出される、トレーニングコーパス内の複雑な単純文のペアの比較。実験は、提案されたアプローチが、F1で5以上の点で、単一言語の文揃えタスクに関する以前のすべての作業よりも優れていることを示しています。 
[要旨]ウィキペディアとニュースラから作成された、手動で注釈が付けられた2つの文-拡大データセット
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: OpinionDigest: A Simple Framework for Opinion Summarization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_25.html">
      OpinionDigest: A Simple Framework for Opinion Summarization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      OpinionDigestは、特定のユーザーのニーズに合わせてカスタマイズされた要約を生成することもできます。選択した意見は、その側面や感情に従ってフィルタリングします。要約時に、複数のレビューからの抽出をマージし、最も人気のあるレビューを選択します。2つの人間の研究コーパスは、OpinionDigestが有益な要約を作成し、有望なカスタマイズ機能を示していることを確認します。 
[ABSTRACT]インフォームツールは、意見分析モデルを使用してレビューから意見フレーズを抽出します。トランスモデルをトレーニングして、これらの抽出から元のレビューを再構築します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Uncertain Natural Language Inference -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_26.html">
      Uncertain Natural Language Inference
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      直接スカラー回帰モデリングアプローチについて説明し、既存の明確にラベル付けされたNLIデータを事前トレーニングで使用できることを確認します。人間のパフォーマンスにアプローチする最良のモデルは、現在使用されているカテゴリービンの割り当てよりも微妙な推論が可能なモデルであることを示しています。 NLIタスク..不自然な自然言語推論（UNLI）を紹介します。これは、自然言語推論（NLI）の改良版で、カテゴリカルラベルから離れ、主観的な確率評価の直接予測を対象としています。 
[要約]確率的スケールでsnliデータセットの一部を再ラベル付けすることにより、unliの注釈を収集する可能性を実証しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-06">
        <br>2019-09-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL
  Parsers -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_27.html">
      RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL
  Parsers
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      BERTでさらに強化され、Spiderリーダーボードで65.6％の新しい最先端のパフォーマンスを実現します。挑戦的なSpiderデータセットでは、このフレームワークは正確な一致精度を57.2％に向上させ、最高の同等物を8.7％絶対的に超えます改善。さらに、スキーマのリンクとアラインメントに関するモデルの理解の質的な改善を観察します。 
[ABSTRACT]一般化の課題は、セマンティックパーサーがアクセスできる方法でデータベースの関係を登録することにあります。モデルのスキーマの理解における質の向上も観察します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br>2019-11-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transformers as Soft Reasoners over Language -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_28.html">
      Transformers as Soft Reasoners over Language
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      RuleTakersと呼ばれる私たちのモデルは、言語に関するこの種のソフト推論が学習可能であり、高い（99％）精度を達成でき、トレーニング中に見られるよりもかなり深い連鎖を必要とするテストデータ（95％+これらの調査結果は、トランスフォーマーの新しい役割を示唆しているため、つまり、言語の明示的な理論に対して動作する限定された「ソフト定理証明者」として重要であるため、重要です。また、モデルが2つの手書きのルールベースとルールベースはより自然な言語に言い換えられました。 
[ABSTRACT]新しい理論は、説明可能性、修正可能性、および反事実的推論の新しい可能性を示唆しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-14">
        <br>2020-02-14
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Artemis: A Novel Annotation Methodology for Indicative Single Document
  Summarization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_29.html">
      Artemis: A Novel Annotation Methodology for Indicative Single Document
  Summarization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Relative UtilityやPyramidなどの他のアノテーション手法と比較して、Artemisは扱いが簡単です。これは、同様に豊富なセンテンスのアノテーションを提供しながら、裁判官が1つのセンテンスの重要性を判断するときにドキュメントのすべてのセンテンスを見る必要がないためです。 。アノテーションプロセスを詳細に説明し、他の同様の評価システムと比較します。また、532のアノテーション付きドキュメントのサンプルセットの分析と実験結果も示します。 
[ABSTRACT]現在の要約評価データセットは単一ドメインであり、ニュースや科学記事など、自然に発生する要約が簡単に見つかるいくつかのドメインに焦点を当てています。また、532の注釈付きドキュメントのサンプルセットの分析と実験結果も表示します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Probabilistic Assumptions Matter: Improved Models for
  Distantly-Supervised Document-Level Question Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_30.html">
      Probabilistic Assumptions Matter: Improved Models for
  Distantly-Supervised Document-Level Question Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      以前に使用された確率空間と遠方の監視の仮定（弱い回答の文字列ラベルと可能な回答の言及スパンの間の対応に関する仮定）を比較します。このアプローチは、TriviaQAのF1で4.3ポイント、以前の最新モデルよりも優れています。 -WikiとNarrativeQAの要約に関するRouge-Lの1.7点。これらの仮定が相互作用し、異なる構成が補完的な利点を提供することを示します。 
[要約]以前に使用した確率空間と遠方のスーパービジョンの仮定を比較します。多目的モデルが複数の仮定の利点を効率的に組み合わせることができることを示しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An analysis of the utility of explicit negative examples to improve the
  syntactic abilities of neural language models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_31.html">
      An analysis of the utility of explicit negative examples to improve the
  syntactic abilities of neural language models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、トレーニングされたモデルの詳細な分析を提供します。構文を含むトレーニング文の拡張は多少役立ちますが、精度は主語相対句のレベルにまだ達していません。私たちの成功の鍵は、正しい単語と正しくない単語の対数尤度。 
[ABSTRACT]私たちの方法は、神経モデルの真のアーキテクチャ上の制限を分析するためのツールとなる可能性があります。ただし、直接認知的に魅力的ではありませんが、複雑な構造を探索する方法になる可能性があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: XtremeDistil: Multi-stage Distillation for Massive Multilingual Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_32.html">
      XtremeDistil: Multi-stage Distillation for Massive Multilingual Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのアプローチは、MBERTのような教師モデルを、パラメーターでは35倍、バッチ推論ではレイテンシで51倍に圧縮し、41言語以上でNERのF1スコアの95％を維持することを示しています。ラベル付けされていないデータの量、注釈リソース、モデルアーキテクチャ、推論の待ち時間など、いくつかの要因の役割を調査します。最近の並行作業では、知識の抽出を使用してこれらの巨大なモデルを浅いモデルに圧縮しています。 
[ABSTRACT]大きなサイズのモデルは、実際に使用する際の妨げになる可能性があります。これらのモデルは、実際に使用することもできます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-12">
        <br>2020-04-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Structured Tuning for Semantic Role Labeling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/cs.CL/paper_33.html">
      Structured Tuning for Semantic Role Labeling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      アプローチの影響を検証するための強力なベースライン（RoBERTa）から始め、宣言型の制約に準拠することを学ぶことにより、フレームワークがベースラインよりも優れていることを示します。当社のフレームワークは、ニューラルネットワークの表現力を活用し、構造化された損失コンポーネントの監視を提供します。 。さらに、トレーニングサイズを小さくして実験を行ったところ、リソースの少ないシナリオで一貫した改善を実現できることがわかりました。 
[ABSTRACT]柔らかくされた構造を使用してモデルを改善するためのフレームワークを提示します。宣言的な制約に準拠することを学ぶことにより、フレームワークがベースラインよりも優れていることを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br>2020-05-01
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Lipschitz Constrained Parameter Initialization for Deep Transformers -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/eess.AS/paper_0.html">
      Lipschitz Constrained Parameter Initialization for Deep Transformers
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      以前の調査の結果とは対照的に、Lipschitzパラメータの初期化により、元の計算順序のディープトランスフォーマーが収束し、最大24層のBLEUの大幅な改善が得られることをさらに実証します。このホワイトペーパーでは、まず、簡単な変更が公式の実装で行われ、残余接続とレイヤー正規化の計算順序を変更します。これにより、深いトランスフォーマーの最適化が大幅に容易になります。Transformer変換モデルは、残余接続とレイヤー正規化を使用して、マルチレイヤーエンコーダーによって引き起こされる最適化の問題を緩和します。 /デコーダ構造。 
[ABSTRACT]以前の調査によると、ディープトランスフォーマーはまだトレーニングに問題があります。12を超えるエンコーダー/デコーダーレイヤーを持つディープモデルは収束に失敗します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-08">
        <br>2019-11-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: End-to-end Whispered Speech Recognition with Frequency-weighted
  Approaches and Layer-wise Transfer Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/eess.AS/paper_1.html">
      End-to-end Whispered Speech Recognition with Frequency-weighted
  Approaches and Layer-wise Transfer Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ささやきは人間の音声の重要なモードですが、おそらく利用可能なささやき音声データが不足しているため、そのためのエンドツーエンドの認識結果はまだ報告されていません。これには、周波数加重SpecAugmentポリシーと周波数分割CNNが含まれますささやき声の高周波数構造をより適切にキャプチャするための特徴抽出、および通常の声でモデルを事前トレーニングし、ささやき声でそれを微調整して、ささやき声と通常の声の間のギャップを埋めるレイヤー単位の転送学習アプローチ。結果は、通常の音声で事前トレーニングされた優れたE2Eモデルがある限り、比較的小さなウィスパー音声のセットで、適度に優れたE2Eウィスパー音声認識機能を取得するのに十分な場合があります。 
[要約]新しい研究は、ささやき声を簡単に特定できる方法を示しています。これには、19。8％とcerの31.9％の減少が含まれます。これらの測定値には、ささやき声の特別な特性とデータの不足が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: EEG based Continuous Speech Recognition using Transformers -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/eess.AS/paper_2.html">
      EEG based Continuous Speech Recognition using Transformers
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーでは、最近導入されたエンドツーエンドのトランスフォーマーベースの自動音声認識（ASR）モデルを使用して脳波（EEG）機能を使用した連続音声認識を調査します。結果は、トランスフォーマーベースのモデルがリカレントニューラルネットワーク（RNN ）ベースのシーケンス間EEGモデルと小さいテストセット語彙の推論時間中のパフォーマンスが向上しますが、語彙サイズを増やすと、RNNベースのモデルのパフォーマンスは、限られた英語の語彙に基づくトランスフォーマーモデルよりも優れていました。 
[ABSTRACT]結果は、トランスフォーマーベースのモデルが、再帰型ニューラルネットワーク（rnn）ベースのシーケンス間シーケンス）eegモデルと比較してより高速なトレーニングを示すことを示しています。ボキャブラリサイズを増やすと、rnnベースのモデルのパフォーマンスはトランスフォーマーベースのモデルよりも優れていました限られた英語の語彙のモデル
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-31">
        <br>2019-12-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: DIHARD II is Still Hard: Experimental Results and Discussions from the
  DKU-LENOVO Team -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/eess.AS/paper_3.html">
      DIHARD II is Still Hard: Experimental Results and Discussions from the
  DKU-LENOVO Team
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      変分ベイズ（VB）ダイアライゼーションが再分割段階で適用され、オーバーラップ検出もわずかな改善をもたらします。提案されたシステムは、Track1で18.84％DERを達成し、Track2で27.90％DERを達成しています。公式ベースラインに比べて％、ダイアライジングタスクは依然として非常に難しいと考えています。 
[要約]提案されたシステムには、音声アクティビティ検出（vad）、パーソナライゼーション、スピーカー拡張が含まれます。システムには、resnet-lstmベースのスピーカー埋め込みとlstmベースの類似性スコアリングも含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-23">
        <br>2020-02-23
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: PHOSPHO1, a novel skeletal regulator of insulin resistance and obesity -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/biorxiv.physiology/paper_0.html">
      PHOSPHO1, a novel skeletal regulator of insulin resistance and obesity
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Phospho1-/-マウスの代謝保護は、オステオカルシンのレベルの変化がない場合に明らかになりました。この研究は、PHOSPHO1を肥満と糖尿病の治療のための潜在的な治療標的として識別しています。骨格は、代謝の主要な内分泌調節因子として認識されています。 
[要約]骨石灰化酵素phospho1を欠くマウスは、基本的なグルコース恒常性の改善を示した。phospho1は両方とも、グルコース輸送とインスリン受容体シグナル伝達に関連する遺伝子と活発に相互作用した
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Vanishing white matter disease expression of truncated EIF2B5 activates induced stress response -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/biorxiv.physiology/paper_1.html">
      Vanishing white matter disease expression of truncated EIF2B5 activates induced stress response
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ゼブラフィッシュeif2b2変異体におけるヒトEIF2B2の発現は、致死性とCNSアポトーシスを救い、ゼブラフィッシュとヒト間の機能の保存を示します。野生型幼虫における切り詰められたeif2b5の発現は、運動行動を損ない、ISRを活性化し、フィードフォワードメカニズムが示唆されますVWMで疾患の病態生理の重要なコンポーネントです。現在のモデルは、主要な疾患の特徴を部分的にのみ要約し、病態生理は十分に理解されていません。VWMのゼブラフィッシュ（Danio rerio）モデルの開発と検証を通じて、障害のあるものを含むゼブラフィッシュeif2b変異体phenocopy VWMを示します体細胞の成長、初期の致死、髄鞘形成障害、オリゴデンドロサイト前駆細胞の喪失、CNSのアポトーシスの増加、および運動水泳行動の障害。 
[要約]ゼブラフィッシュeif2b変異体がニューヨークベースのeif2bで見つかりました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Differential levels of dermatan sulfate generate distinct Collagen I gel architectures -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/biorxiv.physiology/paper_2.html">
      Differential levels of dermatan sulfate generate distinct Collagen I gel architectures
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      その原線維形成の主要な調節因子は、デルマタン硫酸プロテオグリカン（DSPG）、DSグリコサミノグリカン（GAG）を含むイズロン酸と共役したタンパク質です。第二高調波発生顕微鏡（SHG）を使用したDS（50-、200-、400- g / mL）。DSはコラーゲンIアーキテクチャーの変調を通じて組織機能を調節することが知られていますが、後者の正確な定量的理解はとらえどころのないままです。 
[ABSTRACT] dsは、コラーゲンiアーキテクチャーの変動を通じて組織機能を調節することが知られています。後者の正確な定量的理解は、とらえどころのないままです。それは、組織の微小環境に機械的能力を提供し、細胞を調節します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Single Cell RNA Profiling Reveals Adipocyte to Macrophage Signaling Sufficient to Enhance Thermogenesis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-06/biorxiv.physiology/paper_3.html">
      Single Cell RNA Profiling Reveals Adipocyte to Macrophage Signaling Sufficient to Enhance Thermogenesis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ここでは、SNF活動から完全に独立しているiWAT褐変の非細胞自律経路の最初の例を示します。したがって、脂肪細胞脂肪酸シンターゼ（iAdFASNKOマウス）の削除によって促された熱産生脂肪細胞の強い誘導は、除神経の影響を受けませんでした。 SNFモジュレーターニューレグリン4の削除..脂肪褐色化は交感神経線維（SNF）の活性化が必要であると報告されており、iWAT内で交互に活性化されるマクロファージによって支援されます。 
[ABSTRACT]脂肪の褐変は、交感神経線維（snf）の活性化が必要であると報告されており、iwat内で継続的に活性化されるマクロファージによって支援されます。これらの例は、脂肪細胞シグナルによって開始され、マクロファージによって引き起こされるキャンプ/ pka依存性のiwat褐色化の予期しない経路を明らかにします-交感神経の関与に依存しない細胞のような
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
