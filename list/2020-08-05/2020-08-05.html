<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-08-05の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: MIRNet: Learning Multiple Identity Representations in Overlapped Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.SD/paper_0.html">
      <font color="black">MIRNet: Learning Multiple Identity Representations in Overlapped Speech</font>
    </a>
  </h2>
  <font color="black">この論文では、重なり合った音声から複数の話者のアイデンティティを確実に抽出できる新しい深い話者表現戦略を提案します。私たちは、話者検証タスクにおけるアルゴリズムの有効性と、提案された方法。しかし、音声信号に複数の同時発話者がいる場合、アイデンティティ情報を決定することは困難です。 
[ABSTRACT]特定の混合物から各話者の識別情報を含む高レベルの埋め込みを抽出することを計画します。音声信号に複数の同時発話者がいる場合、識別するのは困難です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Wait-k Models for Simultaneous Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.SD/paper_1.html">
      <font color="black">Efficient Wait-k Models for Simultaneous Machine Translation</font>
    </a>
  </h2>
  <font color="black">IWSLTデータセットを使用して、音声コーパスの低リソース設定でのwait-kデコードの動作を調査します。また、2D畳み込みアーキテクチャは、音声言語の同時翻訳に関してトランスフォーマーと競合することを示します。ターゲットトークンの生成と別のソーストークンの読み取りを交互に行います。 
[ABSTRACT] iwsltデータセットを使用して、音声コーパスの低リソース設定で待機-kデコードの動作を調査します。2d-畳み込みアーキテクチャは、音声言語の同時翻訳のトランスフォーマーと競合することも示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-18">
        <br><font color="black">2020-05-18</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Granular Sound Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.SD/paper_2.html">
      <font color="black">Neural Granular Sound Synthesis</font>
    </a>
  </h2>
  <font color="black">音声記述子の基礎を、変分オートエンコーダーで学習した確率的潜在空間に効率的に置き換えます。これにより、粒子全体の局所的な類似性を反映した表現が提供されます。このモデルは、ピッチ音符を含む多くのタイプのライブラリーに適用できますまたはピッチのないドラムと環境騒音。 
[ABSTRACT]グラニュラーシンセシスは、サウンドを制御するために使用するようにプログラムできます。ただし、このグレインスペースの品質は、ディスクリプターの品質によって制限されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Timbre latent space: exploration and creative aspects -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.SD/paper_3.html">
      <font color="black">Timbre latent space: exploration and creative aspects</font>
    </a>
  </h2>
  <font color="black">あるいは、教師なしの次元が残りの機能を考慮に入れている間、いくつかの特定のサウンド属性を制御変数として学習できます。生成とニューラルネットワークにより、音色操作の新しい可能性が可能になりますが、それらの表現の探索と創造的な使用はほとんど残っていません。実験は2人の作曲家と協力して行われ、特別に設計されたインターフェイス（Max / MSP、Pure Data）または記述子ベースの合成のマッピングを使用して、音楽ティンバーの潜在的な音の合成を探求する新しい創造的な方向性を提案します。 
[ABSTRACT]潜在スペースは音色のプロパティを解き放ちません。疑いのない音色操作の新しい可能性が有効になります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Segment Aggregation for short utterances speaker verification using raw
  waveforms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.SD/paper_4.html">
      <font color="black">Segment Aggregation for short utterances speaker verification using raw
  waveforms</font>
    </a>
  </h2>
  <font color="black">提案された方法は、入力発話をいくつかの短い発話にセグメント化し、セグメント化された入力から抽出されたセグメント埋め込みを集約して話者埋め込みを構成します。話者検証システムに関するほとんどの研究は、十分な音声情報で構成される長時間の発話に焦点を当てています。次に、このメソッドは、セグメントの埋め込みと集約された話者の埋め込みを同時にトレーニングします。 
[要約]提案された方法は、アンサンブルベースの設計を使用して話者検証システムの精度を向上させます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br><font color="black">2020-05-07</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Composition of Guitar Tabs by Transformers and Groove Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.SD/paper_5.html">
      <font color="black">Automatic Composition of Guitar Tabs by Transformers and Groove Modeling</font>
    </a>
  </h2>
  <font color="black">2つ目は、指のスタイルのギター音楽に欠かせない、一貫したリズミカルなグルーヴを備えた楽曲を生成するかどうかです。1つ目は、ニューラルネットが意味のある音符と文字列の組み合わせを含む音符シーケンスを生成するかどうかです。このモデルでは、以下の調査問題を調査します。 
[ABSTRACT]このモデルは、タブ構成のディープラーニングの可能性を示す予備的な証拠を提供し、将来の研究の領域を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Weakly Supervised Construction of ASR Systems with Massive Video Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.SD/paper_6.html">
      <font color="black">Weakly Supervised Construction of ASR Systems with Massive Video Data</font>
    </a>
  </h2>
  <font color="black">広範な実験は、私たちのフレームワークがマンダリン音声認識用の6つのパブリックデータセットで最先端の結果を簡単に生成できることを示しています。このホワイトペーパーでは、大規模なビデオデータを使用してASRシステムを構築するための弱く監視されたフレームワークを示します。認識（ASR）システムを最初から作成することは非常に困難です。これは、多くの場合、トランスクリプトを使用して大量のオーディオデータに注釈を付けるために時間と費用がかかるプロセスが原因です。 
[ABSTRACT]現在、教師なしの事前トレーニングモデルがいくつかあります。これらには教師なしの事前トレーニングモデルが含まれますが、より多くのラベル付けされたトレーニングデータを大きなコストなしで取得できる場合、これらは依然として最適ではない可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: The Jazz Transformer on the Front Line: Exploring the Shortcomings of
  AI-composed Music through Quantitative Measures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.SD/paper_7.html">
      <font color="black">The Jazz Transformer on the Front Line: Exploring the Shortcomings of
  AI-composed Music through Quantitative Measures</font>
    </a>
  </h2>
  <font color="black">これには、ピッチクラス、グルービング、コード進行の統計の分析、フィットネススケーププロットの助けを借りて音楽の構造を評価すること、およびMIREXのような継続予測タスクを通じてモデルのジャズ音楽の理解を評価することが含まれます。トレーニングロスを低い値に減らすことができますが、リスニングテストでは、生成された楽曲と実際の楽曲の平均評価の間に明確なギャップがあることが示唆されています。このペーパーでは、Jazz Transformerと呼ばれるジャズ音楽のリードシートをモデリングするためのTransformer-XL。 
[ABSTRACT] modelは、生成された音楽に構造を誘導するために、weimarジャズデータベース（wjazzd）に存在する構造イベントを組み込むことを目指しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Intra-class variation reduction of speaker representation in
  disentanglement framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.SD/paper_8.html">
      <font color="black">Intra-class variation reduction of speaker representation in
  disentanglement framework</font>
    </a>
  </h2>
  <font color="black">スピーカーに関連する表現とスピーカーに関連しない表現の両方を生成するようにネットワークアーキテクチャを変更することにより、これらの絡み合っていない埋め込み間の相互情報を最小化する学習基準を活用します。提案された基準は、バックグラウンドの変化によって引き起こされるスピーカー特性の変動を減らすため、環境または音声コンテンツにより、各スピーカーの埋め込みがより一貫したものになります。アブレーション研究では、各基準が全体的なパフォーマンスに与える影響も示されます。 
[要約]効果的な方法は、話者の特性情報のみを含む潜在的な表現または埋め込みを学習することです。提案された方法の有効性は、解きほぐしのパフォーマンスと話者認識の精度の向上という2つのタスクで示されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Music SketchNet: Controllable Music Generation via Factorized
  Representations of Pitch and Rhythm -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.SD/paper_9.html">
      <font color="black">Music SketchNet: Controllable Music Generation via Factorized
  Representations of Pitch and Rhythm</font>
    </a>
  </h2>
  <font color="black">まず、SketchVAEを紹介します。これは、リズムとピッチの輪郭を明示的に因数分解して、提案されたモデルの基礎を形成する新しい変分オートエンコーダです。自動画像補完システムとの類似点を描き、ユーザーが指定できるニューラルネットワークフレームワークであるMusic SketchNetを提案します。自動音楽生成を導く部分的な音楽的アイデア..最後に、モデルが生成プロセス中にユーザー指定のスニペットを正常に組み込むことができることを示します。 
[ABSTRACT]私たちのアプローチは、客観的な測定基準と主観的なリスニングテストの両方の面で、最先端の技術を上回っています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: "This is Houston. Say again, please". The Behavox system for the
  Apollo-11 Fearless Steps Challenge (phase II) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.SD/paper_10.html">
      <font color="black">"This is Houston. Say again, please". The Behavox system for the
  Apollo-11 Fearless Steps Challenge (phase II)</font>
    </a>
  </h2>
  <font color="black">すべてのシステムについて、FSC-2ベースラインシステムと比較して大幅なパフォーマンスの向上を報告し、チャレンジでSDおよびASRの1位とSADの4位を達成しました。音声アクティビティ検出（SAD）について説明します。 BehavoxチームがInterspeech 2020 Fearless Steps Challenge（FSC-2）のために実施したスピーカーダイアライゼーション（SD）、および自動音声認識（ASR）実験。比較的少量のラベル付きデータ、多種多様なスピーカー、およびチャネル歪み、特定のレキシコンとスピーキングスタイルは、このデータを含むシステムで高いエラー率をもたらしました。 
[要約]いくつかの悲しいシステムとsdシステムを比較して、課題の最も難しいトラックをテストします。これらには、評価のために30分の長いオーディオ録音が提供されるダイアライゼーションとasrが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Expressive TTS Training with Frame and Style Reconstruction Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.SD/paper_11.html">
      <font color="black">Expressive TTS Training with Frame and Style Reconstruction Loss</font>
    </a>
  </h2>
  <font color="black">提案されたスタイル再構成損失は、発声レベルのスピーチスタイルがトレーニング中に確実に考慮されるように知覚損失として定式化されます。提案されたアイデアは、韻律が一連の韻律埋め込みによって明示的にモデル化されるスタイルトークンパラダイムからの脱却を示しています。実験は、提案されたトレーニング戦略が驚くべきパフォーマンスを達成し、自然さと表現力の両方で最先端のベースラインを上回ることを示しています。 
[ABSTRACT]提案されたトレーニング戦略は、タコトロンベースのttsフレームワークを使用することを提案します。タコトロンベースのttsフレームワークを使用して、入力テキストとその韻律スタイル間の関連付けをエンコードします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: From Speaker Verification to Multispeaker Speech Synthesis, Deep
  Transfer with Feedback Constraint -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.SD/paper_12.html">
      <font color="black">From Speaker Verification to Multispeaker Speech Synthesis, Deep
  Transfer with Feedback Constraint</font>
    </a>
  </h2>
  <font color="black">制約は、話者のアイデンティティに関連する追加の損失によって取られます。これは、統合された音声とその自然な参照音声の間の話者の類似性を改善するために集中化されます。話者確認ネットワーク。モデルは、公的に入手可能なデータセットでトレーニングおよび評価されます。 
[ABSTRACT]モデルは、公開されているIDデータセットでトレーニングおよび評価されます。インタラクティブなデータセットを含むデータセットに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-10">
        <br><font color="black">2020-05-10</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-supervised Learning for Multi-speaker Text-to-speech Synthesis
  Using Discrete Speech Representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.SD/paper_13.html">
      <font color="black">Semi-supervised Learning for Multi-speaker Text-to-speech Synthesis
  Using Discrete Speech Representation</font>
    </a>
  </h2>
  <font color="black">ペアになっていない音声データの一部にノイズが多い場合でも、提案された半教師あり学習アプローチからモデルが恩恵を受けることができることを発見しました。最近、エンドツーエンドのマルチスピーカーテキスト音声変換（TTS）システムがこの状況で成功を収めています多くの高品質の音声とそれに対応する文字起こしが利用できる場所です。実験結果は、1時間のペアの音声データだけで、ペアのデータが複数の話者または単一の話者からのものであっても、提案されたモデルは理解できる異なる声でのスピーチ。 
[要約]マルチスピーカーTTSモデルは、提案されたエンコーダー-単一の音声表現を備えたデコーダーフレームワークを介して、文字起こしされていないオーディオから学習できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-16">
        <br><font color="black">2020-05-16</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Deep Parallel MRI Reconstruction Network Without Coil Sensitivities -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.IV/paper_0.html">
      <font color="black">Deep Parallel MRI Reconstruction Network Without Coil Sensitivities</font>
    </a>
  </h2>
  <font color="black">既存のほとんどの深い画像再構成ネットワークとは異なり、私たちのネットワークは、推定するのが非常に難しく、現実のpMRIアプリケーションにおける画像再構成の主要なボトルネックとなっている感度マップの知識を必要としません。実験結果は、提案されたネットワークは、不完全なpMRIデータからのマルチコイル画像を均一なコントラストを持つ単一の画像に適応的に結合することを学習し、非線形エンコーダーに渡されてスパースな特徴を効率的に抽出します画像。 
[要約]提案されたネットワークは、不完全なpmriデータからの画像を、コントラストが均一な単一の画像に適応的に結合することを学習します。ネットワークは、ネットワークのデータのフィルターに応答することを学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: IMUTube: Automatic Extraction of Virtual on-body Accelerometry from
  Video for Human Activity Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.IV/paper_1.html">
      <font color="black">IMUTube: Automatic Extraction of Virtual on-body Accelerometry from
  Video for Human Activity Recognition</font>
    </a>
  </h2>
  <font color="black">仮想的に生成されたIMUデータが、既知のHARデータセットのさまざまなモデルのパフォーマンスをどのように向上させるかを示します。これにより、オンボディのセンサーベースのHARが、認識における大規模データセットの画期的な進歩のさらに別の成功事例になるはずです。この問題に対処するために、既存のコンピュータービジョンと信号処理技術を統合して人間の活動のビデオをIMUデータの仮想ストリームに変換する自動処理パイプラインであるIMUTubeを紹介します。 
[ABSTRACT]センサーは高価であり、注釈は時間がかかり、エラーが発生しやすいため、人間の活動の認識はほとんどなく、入手も困難です。これらの仮想imuストリームは、人体のさまざまな場所のアクセスを表しています。この作業の一部は、この作業を私たちが概説する方法に拡張するための集団的アプローチにあり</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-29">
        <br><font color="black">2020-05-29</font>
      </time>
    </span>
</section>
<!-- paper0: Guiding CNNs towards Relevant Concepts by Multi-task and Adversarial
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.IV/paper_2.html">
      <font color="black">Guiding CNNs towards Relevant Concepts by Multi-task and Adversarial
  Learning</font>
    </a>
  </h2>
  <font color="black">このようにして、深い表現のシフトを修正して、臨床医の仮定に一致させることができます。望ましくない誤解を招く概念は、勾配反転操作によって阻止されます。学習プロセスは、タスクに関連するか誤解を招く概念を特定することによって導かれます。 
[要旨]コードはgithubリポジトリで再現性のために共有されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: No-Reference Video Quality Assessment Using Space-Time Chips -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.IV/paper_3.html">
      <font color="black">No-Reference Video Quality Assessment Using Space-Time Chips</font>
    </a>
  </h2>
  <font color="black">暫定的にChipQAと呼ぶ提案された方法は、ビデオに影響を与える歪みのタイプにとらわれず、ビデオ品質を予測するために、自然で歪みのないSTチップの予想される統計からの偏差を特定および定量化することに基づいています。パラメータ化された統計的適合は、時空間チップの統計に適合して品質を特徴付け、これらのモデルからのパラメータは歪みの影響を受け、したがってビデオの品質を客観的に予測するために使用できることを示します。大規模なVQAデータベースと私たちのモデルがビデオ品質の人間の判断に対して高い相関を達成し、最先端のモデルと競争力があることを示します。 
[要約] chipqaと呼ばれる提案された方法は、ビデオデータの時空間の局所的なカットとして定義する、新しい品質を意識した機能空間です。これは、自然で歪んでいないstの予想される統計からの偏差を識別および定量化することに基づいています-チップ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-31">
        <br><font color="black">2020-07-31</font>
      </time>
    </span>
</section>
<!-- paper0: MSDPN: Monocular Depth Prediction with Partial Laser Observation using
  Multi-stage Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.IV/paper_4.html">
      <font color="black">MSDPN: Monocular Depth Prediction with Partial Laser Observation using
  Multi-stage Neural Networks</font>
    </a>
  </h2>
  <font color="black">対照的に、私たちのアプローチはモデルをトレーニングし、物理的に収集された2D LiDARデータセットを使用して実験を行います。提案された多段エンコーダー/デコーダーアーキテクチャは、2D LiDARの特性によって引き起こされる部分的な観測問題を軽減し、CSFAは複数の機能を希釈することからネットワークをステージングし、ネットワークが機能間の空間的関係をよりよく学習できるようにします。実験的に確認されたように、私たちのネットワークは最先端の方法に対して有望なパフォーマンスをもたらします。 
[ABSTRACT]提案されたネットワークは、マルチステージエンコーダー-デコーダーアーキテクチャとクロスステージ機能の集合体で構成されます。提案されたネットワークには、kaist rgbd-scan dataset.itというネットワークが含まれます。現実的な条件下でのmsdpnの有効性と堅牢性を検証しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Spatial images from temporal data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.IV/paper_5.html">
      <font color="black">Spatial images from temporal data</font>
    </a>
  </h2>
  <font color="black">シングルポイントの飛行時間（時間）データによるイメージングは、速度、サイズ、および機能の点で新しいルートを開きます。イメージングの従来のパラダイムは、検出器（ピクセル配列）またはここでは、あるシーンから反射した光子の到着時間を記録する単一点、単一光子アバランシェダイオードのみで完全な3D情報を取得するデータ駆動型アプローチを示します。光の短いパルスで照らされます。 
[要旨]シングルポイントセンサーだけを使用して画像を削除するには、長期的なソリューションが必要です。これには、解決されていないデータ量へのアプローチが必要になります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-02">
        <br><font color="black">2019-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Land Use and Land Cover Classification using a Human Group based
  Particle Swarm Optimization Algorithm with a LSTM classifier on
  hybrid-pre-processing Remote Sensing Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.IV/paper_6.html">
      <font color="black">Land Use and Land Cover Classification using a Human Group based
  Particle Swarm Optimization Algorithm with a LSTM classifier on
  hybrid-pre-processing Remote Sensing Images</font>
    </a>
  </h2>
  <font color="black">次に、選択した画像からの特徴抽出のために、ローカルガボールバイナリパターンヒストグラムシーケンス（LGBPHS）、配向勾配のヒストグラム（HOG）、ハラリックテクスチャの特徴を使用して、ハイブリッド最適化を実行します。最小0.01％とa提案された方法を適用すると、既存のモデルのGoogleNet、VGG、AlexNet、ConvNetと比較して、精度が最大2.56％向上します。LULC分類は、土4、土6、およびユーロサットデータセットを使用して評価されます。 
[概要] lulcは、ハイブリッド機能拡張アルゴリズムとディープラーニング分類器です。lulc分類のパフォーマンスを向上させ、野生生物の生息地の予測、環境品質の劣化、偶然などを予測するために提案されています。リモートセンシング画像の選択後、画像の品質を向上させるために、正規化およびヒストグラム均等化方法が使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Intensity-only Mode Decomposition on Multimode Fibers using a Densely
  Connected Convolutional Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.IV/paper_7.html">
      <font color="black">Intensity-only Mode Decomposition on Multimode Fibers using a Densely
  Connected Convolutional Network</font>
    </a>
  </h2>
  <font color="black">この作業では、121層のDenseNetを使用することで、6つのモードのハードルを突破できることが初めて示されました。物理層セキュリティまたはモード分割多重化を使用するアプリケーションの場合、複雑な伝送行列は提案されている方法は、デジタルホログラフィによる従来のアプローチと定量的に比較されます。 
[ABSTRACT]モード分解は通常、デジタルホログラフィーを使用して実行されます。この方法は、実験的に10モードのモード分解によって示されます。デジタルホログラフィーを使用する従来のアプローチと定量的に比較されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-03">
        <br><font color="black">2020-08-03</font>
      </time>
    </span>
</section>
<!-- paper0: Paying Per-label Attention for Multi-label Extraction from Radiology
  Reports -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.IV/paper_8.html">
      <font color="black">Paying Per-label Attention for Multi-label Extraction from Radiology
  Reports</font>
    </a>
  </h2>
  <font color="black">高密度）と臨床印象（たとえば、この論文では、脳卒中の疑いのある患者の画像化のために、ディープラーニングを使用して頭部CTレポートからの構造化ラベルの自動抽出に取り組みます。第2に、以前の研究に触発され、既存の状態を拡張します。ラベルに依存する注意メカニズムを備えた最新のニューラルネットワークモデル。
[ABSTRACT]画像には、フリーテキストの放射線医学レポートが添付されていることがよくあります。これらには、神経学的異常に関連する放射線レポートが含まれます。このメカニズムと単純な合成データの増強を使用して、放射線科医の報告に従って分類された単一のモデルで多くのラベルを抽出する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-31">
        <br><font color="black">2020-07-31</font>
      </time>
    </span>
</section>
<!-- paper0: Joint Demosaicing and Super-Resolution (JDSR): Network Design and
  Perceptual Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.IV/paper_9.html">
      <font color="black">Joint Demosaicing and Super-Resolution (JDSR): Network Design and
  Perceptual Optimization</font>
    </a>
  </h2>
  <font color="black">私たちの技術的貢献は主に2つあります。..ネットワーク設計では、前処理のステップとして、プレデモザイクネットワーク（PDNet）によってサポートされる残余高密度スクイーズアンドエキサイテーションネットワーク（RDSEN）を開発しました。画像デモザイキングと超解像は、カラーイメージングパイプラインにおける2つの重要なタスクです。 
[要約]不満のある画像は、ディープラーニングの公開文献でほとんど独立して研究されてきました。しかし、デモザイキングと超解像（jdsr）の共同問題の潜在的なアーキテクチャについてはほとんど知られていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-08">
        <br><font color="black">2019-11-08</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Domain Adaptive Object Detection: a Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.IV/paper_10.html">
      <font color="black">Deep Domain Adaptive Object Detection: a Survey</font>
    </a>
  </h2>
  <font color="black">ただし、実際には2つの仮定が常に当てはまるわけではありません。最初に、ディープドメインアダプテーションの基本概念を簡単に紹介します。次に、ディープドメインアダプティブ検出器を5つのカテゴリに分類し、各カテゴリの代表的な方法の詳細な説明を提供します。 
[要約]ディープドメイン適応オブジェクト検出（ddaod）は、上記の課題に対処するための新しい学習ツールとして登場しました。最初に、ディープドメイン適応の基本概念を簡単に紹介します。最後に、将来の研究動向に関する洞察を示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-17">
        <br><font color="black">2020-02-17</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient resource management in UAVs for Visual Assistance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.IV/paper_11.html">
      <font color="black">Efficient resource management in UAVs for Visual Assistance</font>
    </a>
  </h2>
  <font color="black">UAVをビジュアルアシスタンスタスクにリアルタイムで使用する上での主要な課題の1つは、これらのタスクのメモリ使用量と電力消費を管理することです。これらのタスクは、計算が集中し、UAVのローエンドプロセッサボードで実行することは困難です。しかし、ほとんどの評価モデルはハイエンドのCPUとGPUで実行されます。このプロジェクトでは、飛行時間に影響を与えず、レイテンシと精度を損なうことなく、リアルタイムシナリオでUAVハードウェアのオブジェクト追跡やオブジェクト検出などの一般的な画像処理タスクを最適化する新しい方法について説明しますこれらのモデル。 
[ABSTRACT] UAVを視覚的支援にリアルタイムで使用することは無人です。これらは、UAVオブジェクトのローエンドプロセッサボードで実行することは困難です。これは、コンピュータビジョンのディープラーニングモデルにもかかわらず</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-11">
        <br><font color="black">2020-07-11</font>
      </time>
    </span>
</section>
<!-- paper0: Two-Stage Deep Learning for Accelerated 3D Time-of-Flight MRA without
  Matched Training Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.IV/paper_12.html">
      <font color="black">Two-Stage Deep Learning for Accelerated 3D Time-of-Flight MRA without
  Matched Training Data</font>
    </a>
  </h2>
  <font color="black">具体的には、最初のネットワークは二乗和平方根（SSoS）ドメインでトレーニングされ、高品質の並列画像再構成を実現しますが、2番目の改良ネットワークは、双頭を使用して高度に活性化された血流の特性を効率的に学習するように設計されていますmax-pool discriminator ..広範囲にわたる実験は、一致する参照のない提案された学習プロセスが、最先端の圧縮センシング（CS）ベースの方法のパフォーマンスを超え、教師あり学習アプローチと同等またはそれ以上の結果を提供することを示しています。最適な輸送理論からのcycleGANの最近の理論的理解、ここでは、冠状面に沿ったマルチコイル再構成ネットワークとそれに続く軸方向に沿ったマルチ平面精密化ネットワークで構成される、新しい2段階の教師なし深層学習アプローチを提案します飛行機。 
[要約]アンダーサンプリングされたtofからの高品質の再構成-mraはディープラーニングの重要な研究トピックです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Applying Incremental Deep Neural Networks-based Posture Recognition
  Model for Injury Risk Assessment in Construction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.IV/paper_13.html">
      <font color="black">Applying Incremental Deep Neural Networks-based Posture Recognition
  Model for Injury Risk Assessment in Construction</font>
    </a>
  </h2>
  <font color="black">9人の労働者によるテストでは、浅い畳み込み層を使用したCLNモデルが、個別化（0.87）および一般化（0.84）モデリングの下で高い認識パフォーマンス（F1スコア）を達成したことが示されました。厄介な姿勢の監視は、建設における筋骨格障害（MSD）の予防的な予防策です。多対1 ILスキームの下の一般化された浅いCLNモデルは、適応（0.73）と学習した被験者の忘却（0.74）のバランスをとることができます。 
[要約]機械学習（mm）モデルは、ウェアラブルセンサーからの姿勢認識に有望な結果を示しています。これらのタイプの学習は、適応（0. 73）と被験者の忘却（0. 74）のバランスをとることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Dataset Builder for Machine Learning Applications to Satellite
  Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.IV/paper_14.html">
      <font color="black">Automatic Dataset Builder for Machine Learning Applications to Satellite
  Imagery</font>
    </a>
  </h2>
  <font color="black">今日では、リモートセンシングの分野で機械学習（ML）アルゴリズムの使用が広がっており、その用途は、土地利用の検出と分類から、対象となる多くの自然現象または人為現象の予測にまで及びます。アーキテクチャの2つのバージョンには、 Git-Hubで実装され、非エキスパートユーザー向けの特定のグラフィカルユーザーインターフェイス（GUI）で利用可能になりました。彼らの雇用の1つの主な制限は、選択したニューラルネットワークをトレーニングするための大量のデータの必要性に関連しています特定のアプリケーション、および必要なデータを収集するために必要な結果の計算の重みと時間。 
[要約]アーキテクチャの2つのバージョンが実装され、git-hubで利用できるようになりました。システムは、特定のアプリケーション用に選択されたニューラルネットワークをトレーニングするように設計されています。これらのデータは、脳をトレーニングするための大量のデータを作成するために必要です通信網</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: A Guaranteed Convergence Analysis for the Projected Fast Iterative
  Soft-Thresholding Algorithm in Parallel MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.IV/paper_15.html">
      <font color="black">A Guaranteed Convergence Analysis for the Projected Fast Iterative
  Soft-Thresholding Algorithm in Parallel MRI</font>
    </a>
  </h2>
  <font color="black">この作業では、2つのよく知られている並列イメージング再構成モデル、SENSEとSPIRiTを解決するために、並列イメージングバージョンpFISTAの保証された収束分析を提供します。生体内脳画像での実験は、収束基準の有効性を示しています。.pFISTA 、スパース再構成のためのシンプルで効率的なアルゴリズムは、並列イメージングに正常に拡張されました。 
[ABSTRACT]スローモーニングアルゴリズムは、パラレルイメージングに拡張されました。プロジェクトで使用するために商用スキャナーで使用されています。ただし、新しい方法はスローモーションpfistaには適用できません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-17">
        <br><font color="black">2019-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Multiscale Sparsifying Transform Learning for Image Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.IV/paper_16.html">
      <font color="black">Multiscale Sparsifying Transform Learning for Image Denoising</font>
    </a>
  </h2>
  <font color="black">この目的のために、最初にTLDを介して各ウェーブレットサブバンドを個別にノイズ除去する簡単な方法を採用します。最後に、詳細サブバンドをノイズ除去する必要を取り除きます。次に、この方法がウェーブレットサブバンドミキシングを使用して大幅に強化できることを示します。シングルスケールとマルチスケールの方法の結果を組み合わせるための安価な融合技術。 
[要約]提案されたマルチスケール手法は、驚くべきことに、単一スケールであり、画像のマルチスケールの性質を無視します。この単純化により、ベースラインに匹敵するパフォーマンスを備えた効率的なマルチスケールのノイズ除去方法が実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-25">
        <br><font color="black">2020-03-25</font>
      </time>
    </span>
</section>
<!-- paper0: Preliminary Forensics Analysis of DeepFake Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.IV/paper_17.html">
      <font color="black">Preliminary Forensics Analysis of DeepFake Images</font>
    </a>
  </h2>
  <font color="black">標準的な方法でのこれらの画像のフォレンジック分析が提示されます。当然のことながら、最先端の技術では偽物を完全に検出できません。これを解決するために、分析によって顔のDeepFake画像と戦う方法に関する予備的なアイデアを提示します周波数領域の異常..このペーパーでは、顔のDeepFake画像を生成できるテクノロジの概要を示します。 
[ABSTRACT]周波数領域の異常を分析することで、顔のディープフェイク画像が表示されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br><font color="black">2020-04-27</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Deep Parallel MRI Reconstruction Network Without Coil Sensitivities -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_0.html">
      <font color="black">Deep Parallel MRI Reconstruction Network Without Coil Sensitivities</font>
    </a>
  </h2>
  <font color="black">既存のほとんどの深い画像再構成ネットワークとは異なり、私たちのネットワークは、推定するのが非常に難しく、現実のpMRIアプリケーションにおける画像再構成の主要なボトルネックとなっている感度マップの知識を必要としません。実験結果は、提案されたネットワークは、不完全なpMRIデータからのマルチコイル画像を均一なコントラストを持つ単一の画像に適応的に結合することを学習し、非線形エンコーダーに渡されてスパースな特徴を効率的に抽出します画像。 
[要約]提案されたネットワークは、不完全なpmriデータからの画像を、コントラストが均一な単一の画像に適応的に結合することを学習します。ネットワークは、ネットワークのデータのフィルターに応答することを学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: IMUTube: Automatic Extraction of Virtual on-body Accelerometry from
  Video for Human Activity Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_1.html">
      <font color="black">IMUTube: Automatic Extraction of Virtual on-body Accelerometry from
  Video for Human Activity Recognition</font>
    </a>
  </h2>
  <font color="black">仮想的に生成されたIMUデータが、既知のHARデータセットのさまざまなモデルのパフォーマンスをどのように向上させるかを示します。これにより、本体のセンサーベースのHARが、認識における大規模データセットの画期的な進歩のさらに別の成功事例になるはずです。大規模なラベル付きデータセットの欠如は、身体センサーベースの人間活動認識（HAR）のための堅牢で一般化された予測モデルの開発の進展を妨げます。 
[ABSTRACT]センサーは高価であり、注釈は時間がかかり、エラーが発生しやすいため、人間の活動の認識はほとんどなく、入手も困難です。これらの仮想imuストリームは、人体のさまざまな場所のアクセスを表しています。この作業の一部は、この作業を私たちが概説する方法に拡張するための集団的アプローチにあり</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-29">
        <br><font color="black">2020-05-29</font>
      </time>
    </span>
</section>
<!-- paper0: Prime-Aware Adaptive Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_2.html">
      <font color="black">Prime-Aware Adaptive Distillation</font>
    </a>
  </h2>
  <font color="black">6つのデータセットで10組の教師と生徒の組み合わせにより、PADは既存の蒸留方法のパフォーマンスを促進し、最近の最先端の方法よりも優れています。知識蒸留（KD）は、強力な教師ネットワーク.. PADは根本的に異なり、不平等な訓練という革新的な見方で既存の方法を改良します。 
[ABSTRACT]以前の効果的なハードマイニング方法は蒸留に適さないことが判明しました。パッドは蒸留中の主要なサンプルを認識し、その効果を適応的に強調します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Transmission Map and Atmospheric Light Guided Iterative Updater Network
  for Single Image Dehazing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_3.html">
      <font color="black">Transmission Map and Atmospheric Light Guided Iterative Updater Network
  for Single Image Dehazing</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、質的および量的に、さまざまな曇り具合を描いた合成および実世界の曇りのある画像に効果的であり、最先端のパフォーマンスを上回っています。曇りのある画像は、コンテンツの可視性を妨げ、後続のいくつかのコンピュータービジョンタスクを妨げます。最後に、新しい反復更新フレームワークに基づく反復事前更新曇り取りネットワーク（IPUDN）を提案します。 
[ABSTRACT]エンドツーエッジエッジエッジディープネットワークは、曇りのない画像を適切な透過マップとともに分析し、ガイダンス用の大気光が効果的であると証明できます。ネットワークを推定するための新しい畳み込みアーキテクチャを提示します。地図は曇り取りネットワークの事前情報として使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Jointly Cross- and Self-Modal Graph Attention Network for Query-Based
  Moment Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_4.html">
      <font color="black">Jointly Cross- and Self-Modal Graph Attention Network for Query-Based
  Moment Localization</font>
    </a>
  </h2>
  <font color="black">クエリベースのモーメントローカリゼーションは、指定されたセンテンスクエリに応じて、トリミングされていないビデオで最も一致するセグメントをローカライズする新しいタスクです。パラメトリックメッセージパッシングにより、CMGはビデオおよびセンテンス全体で関連するインスタンスを強調表示し、SMGはそれぞれのペア内の関係をモデル化フレーム（単語）の相関関係のモダリティ。さらに、クエリのコンテキストの詳細をよりよく理解するために、クエリの理解を高めるための階層型文エンコーダーを開発します。 
[ABSTRACT]共同グラフは、クロスモーダル相互作用グラフ（cmg）とセルフモーダル関係グラフ（smg）で構成されています。クロスペアとセルフパララルノードのペア間の接続は、注意メカニズムによって記述されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Tracking Emerges by Looking Around Static Scenes, with Neural 3D Mapping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_5.html">
      <font color="black">Tracking Emerges by Looking Around Static Scenes, with Neural 3D Mapping</font>
    </a>
  </h2>
  <font color="black">2Dまたは2.5Dでビデオストリームを表すモデルとは対照的に、モデルの3Dシーン表現は、投影アーティファクトからほどかれ、カメラの動きの下で安定し、部分的なオクルージョンに対してロバストです。視点間で対応できるようにボクセル機能をトレーニングします。コントラスト損失を使用すると、時間の経過に伴う対応関係が自動的に現れます。ニューラル3Dマッパーは、RGB-Dデータを入力として使用し、深いフィーチャの3Dボクセルグリッドを出力として生成します。 
[要旨]物理的な世界自体はほとんど静的であり、マルチビューの対応ラベルは静的なシーンで収集するのが比較的安価であるという事実に動機づけられています。疑わしいシミュレーションデータと実際のデータで提案されたアーキテクチャをテストし、監視されていない3Dオブジェクトであることを示しますトラッカーは以前の教師なしマッピングをしのぐ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Augmentation: Generalizing Deep Networks to Unseen Classes for
  Few-Shot Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_6.html">
      <font color="black">Self-Augmentation: Generalizing Deep Networks to Unseen Classes for
  Few-Shot Learning</font>
    </a>
  </h2>
  <font color="black">次に、独自の分類子を備えた補助ブランチを持つバックボーンネットワークを使用して、知識の共有を実施します。最後に、ローカル表現学習器を提示して、目に見えないクラスのいくつかのトレーニング例をさらに活用します。この問題に取り組むために、自己混合と自己蒸留を統合する増強。 
[ABSTRACT]最近の研究では、標準のミニバッチトレーニングにより、目に見えないクラスの汎化能力が向上することが示されています。トレーニング統計の記憶など、ディープネットワークのよく知られた問題は、少数のショットラーニングではあまり調査されていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-01">
        <br><font color="black">2020-04-01</font>
      </time>
    </span>
</section>
<!-- paper0: Memory Efficient Class-Incremental Learning for Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_7.html">
      <font color="black">Memory Efficient Class-Incremental Learning for Image Classification</font>
    </a>
  </h2>
  <font color="black">ただし、忠実度の低いサンプルサンプルは、元のサンプルサンプルとは異なるドメインに分散している場合が多い、つまりドメインシフトです。忘却の問題に対処するために、多くのCILメソッドは、古いクラスの知識をサイズが制限されたメモリバッファーへのいくつかのサンプルサンプル。今後の調査を容易にするために、すべてのモデルのコード、ベースライン、およびトレーニング統計をリリースします。 
[ABSTRACT]多くのcilメソッドは、見本のサンプルをサイズに保存することにより、古いクラスの知識を転送します-制約されたメモリバッファー。例の保存スキームは、古い-クラスの知識の転送をより効果的にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Simultaneous Consensus Maximization and Model Fitting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_8.html">
      <font color="black">Simultaneous Consensus Maximization and Model Fitting</font>
    </a>
  </h2>
  <font color="black">2つ目は、バイナリ変数を含む制約のない定式化です。これにより、根本的な困難な組み合わせ最適化問題を処理するための効果的な半定値緩和（SDR）メソッドの使用が容易になります。SDR後も依然として非凸ですが、一部のアプリケーションでは両凸になります。交互最小化アルゴリズムを使用して解決します。通常、最初にインライアのコンセンサスセットを見つけてから、モデルをコンセンサスセットに適合させます。 
[ABSTRACT] mcmeはランサックおよび決定論的に正確にmcメソッドを上回ります。mcmeは、高い外れ値でmcメソッドを大幅に上回ります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Predicting the Blur Visual Discomfort for Natural Scenes by the Loss of
  Positional Information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_9.html">
      <font color="black">Predicting the Blur Visual Discomfort for Natural Scenes by the Loss of
  Positional Information</font>
    </a>
  </h2>
  <font color="black">この概念に従って、自然なシーンの一般的で安定した機能に調整された受容野機能モデルが採用され、視覚的な不快感を予測します。ガウスぼかしの場合から始めて、分析を位置の適用により一般的なぼかしタイプに拡張しますフィッシャー情報の同等性の基準。これは、空間領域と空間周波数領域の両方で方向選択性のある複素数値演算子です。 
[ABSTRACT]本論文では、この不快感はローカリゼーションの精度の低下に起因します。有意な例として、非点収差のぼやけが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Multiple Code Hashing for Efficient Image Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_10.html">
      <font color="black">Multiple Code Hashing for Efficient Image Retrieval</font>
    </a>
  </h2>
  <font color="black">その結果、学習したコードに基づいて、類似した画像を取得するために多数のハッシュバケットにアクセスする必要があります。その低いストレージコストと高速なクエリ速度により、ハッシュは大規模な画像取得タスクで広く使用されています。さらに、MCHのパラメーターを学習するための深層強化学習アルゴリズムを提案します。 
[要約] mctrihの主なアイデアは、各画像の複数のハッシュコードを学習することです。これは、各画像のメモリで提案する最初の作業です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Online Continual Learning under Extreme Memory Constraints -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_11.html">
      <font color="black">Online Continual Learning under Extreme Memory Constraints</font>
    </a>
  </h2>
  <font color="black">この論文では、可能性のあるアルゴリズムが壊滅的な忘却を回避するために使用できるメモリオーバーヘッドに厳しい制約を課す、メモリ制約のあるオンライン継続学習（MC-OCL）の新しい問題を紹介します。利用可能なベンチマークは、私たちのアプローチがMC-OCL問題にうまく対処し、より高いメモリオーバーヘッドを必要とする以前の蒸留法に匹敵する精度を達成することを実証的に実証しています。 -OCL：バッチレベル蒸留（BLD）、正則化ベースのCLアプローチ。安定性と可塑性を効果的にバランスさせ、データストリームから学習しながら、蒸留を通じて古いタスクを解決する機能を維持します。 
[ABSTRACT]継続的学習（mc-ocl）は、可能なアルゴリズムが壊滅的な忘却を回避するために使用できるメモリオーバーヘッドに厳しい制約を課します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Cross-Modal Alignment for Multi-Person 3D Pose Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_12.html">
      <font color="black">Unsupervised Cross-Modal Alignment for Multi-Person 3D Pose Estimation</font>
    </a>
  </h2>
  <font color="black">これは、妥当な3Dポーズ予測を保証するだけでなく、以前のボトムアップアプローチで採用されていた通常のキーポイントグループ化操作を排除する生成ポーズの埋め込みを学習することによって実現されます。教師のネットワークの制限を超えて実行するモデルの機能を強化することを目的としています。人工的に合成された複数人の3Dシーンサンプルを使用して、潜在から3Dへのポーズマッピングを強化します。ペアになった監督が存在しない場合は、凍結ネットワークを教師モデルとして活用し、複数の補助タスクでトレーニングします。人2Dポーズ推定。 
[要旨]私たちは複数人の3Dポーズの新しい神経表現を開発します。これは、人物インスタンスの位置を対応する3Dポーズ表現と統合します。これらには、2Dまたは3Dモデルアノテーションの組み合わせが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Guiding CNNs towards Relevant Concepts by Multi-task and Adversarial
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_13.html">
      <font color="black">Guiding CNNs towards Relevant Concepts by Multi-task and Adversarial
  Learning</font>
    </a>
  </h2>
  <font color="black">このようにして、深い表現のシフトを修正して、臨床医の想定に一致させることができます。望ましくない誤解を招く概念は、勾配反転演算によって推奨されません。Camelyonチャレンジからの乳房リンパ節の組織病理学データへの適用は、大幅な増加を示しています見えない患者（0.839から0.864までの平均AUC、$ \ text {p-value} = 0,0002 $）の汎化パフォーマンスでは、組織の取得センターと視覚的特徴に関する事前の知識によって内部表現が制御されます。 
[要旨]コードはgithubリポジトリで再現性のために共有されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Context Encoding for Video Retrieval with Contrastive Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_14.html">
      <font color="black">Context Encoding for Video Retrieval with Contrastive Learning</font>
    </a>
  </h2>
  <font color="black">提案された方法は、ビデオレベルの機能を備えた最新の方法よりも大幅にパフォーマンスが優れており（FIVR-200Kでは最大17％）、フレームレベルの機能と比較してはるかに低い計算コストで競争力のある結果をもたらします。 。FIVR、CC_WEB_VIDEO、EVVEなどのマルチビデオ取得タスクで広範な実験が行われています。既存のビデオ取得方法は、主にフレームレベルの機能を個別に抽出するため、フレーム間の機能の効率的な集約が欠如しており、効果的に処理することは困難です。モーションブラー、ピンぼけなどの低品質のフレーム。
[ABSTRACT]既存のビデオ検索方法は、主にフレームレベルの機能を個別に抽出します。モーションブラーのあるフレームなど、低品質のフレームを処理することは困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: MSDPN: Monocular Depth Prediction with Partial Laser Observation using
  Multi-stage Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_15.html">
      <font color="black">MSDPN: Monocular Depth Prediction with Partial Laser Observation using
  Multi-stage Neural Networks</font>
    </a>
  </h2>
  <font color="black">提案されたマルチステージエンコーダー/デコーダーアーキテクチャは、2D LiDARの特性によって引き起こされる部分的な観測問題を軽減し、CSFAはマルチステージネットワークが機能を希釈することを防ぎ、ネットワークが機能間の空間的関係をよりよく学習できるようにします。 。対照的に、私たちのアプローチはモデルをトレーニングし、物理的に収集された2D LiDARデータセットを使用して実験を行います。実験的に検証されたように、私たちのネットワークは最先端の方法に対して有望なパフォーマンスをもたらします。 
[ABSTRACT]提案されたネットワークは、マルチステージエンコーダー-デコーダーアーキテクチャとクロスステージ機能の集合体で構成されます。提案されたネットワークには、kaist rgbd-scan dataset.itというネットワークが含まれます。現実的な条件下でのmsdpnの有効性と堅牢性を検証しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Central object segmentation by deep learning for fruits and other
  roundish objects -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_16.html">
      <font color="black">Central object segmentation by deep learning for fruits and other
  roundish objects</font>
    </a>
  </h2>
  <font color="black">トレーニングされたニューラルネットワークCROPは、ユーザーフレンドリーなインターフェイスプログラムを備えたGitHubで利用できます。RGB画像の中心にあるオブジェクトを識別してペイントするCROP（Central Roundish Object Painter）を紹介します。この手法により、農場での果物の成長の統計データを自動的に収集する手段。 
[要約]農場での果物の成長を追跡するツールとして特定された手法。このツールは、統計データを自動的に収集する手段を提供することができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Few-shot Action Recognition with Permutation-invariant Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_17.html">
      <font color="black">Few-shot Action Recognition with Permutation-invariant Attention</font>
    </a>
  </h2>
  <font color="black">重要なのは、プール中にブロックの寄与を再重み付けするために、空間的および時間的注意モジュールと自己監視を利用することです。したがって、クリップのブロックを並べ替え、結果の注意領域を非置換クリップの同様に置換された注意領域と整列させてトレーニングします。ブロック（および長期ホットスポット）の置換に不変の注意メカニズム。最後に、クエリとサポートクリップ間の類似性学習を目的として、関係記述子がコンパレータに送られます。 
[ABSTRACT]（同じクラスの）自然主義的なクリップでは、時間的な分布のシフトがあります。差別的なアクションのホットスポットの場所に移動します。この方法は、hmdb51、ucf101、minimitデータセットの最新技術よりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-12">
        <br><font color="black">2020-01-12</font>
      </time>
    </span>
</section>
<!-- paper0: Class-Incremental Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_18.html">
      <font color="black">Class-Incremental Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">理論的および経験的観察に動機付けられて、私たちはプロトタイプのネットワークに触発された効果的な方法を提案します。 CIDAパラダイムにおけるDAとCIの両方の方法と比較して。この作業では、CIDAパラダイムにおけるこれらのアプローチの制限を効果的に特定します。 
[ABSTRACT]私たちのアプローチは、ドメイン内のdaおよびciメソッドの両方と比較して優れたパフォーマンスをもたらします-shift.existing daメソッドは、新しいクラスクラスの学習に取り組みますが、新しいターゲット-ドメインクラスの学習には適していません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Reinforced Agents with Counterfactual Simulation for Medical
  Automatic Diagnosis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_19.html">
      <font color="black">Learning Reinforced Agents with Counterfactual Simulation for Medical
  Automatic Diagnosis</font>
    </a>
  </h2>
  <font color="black">その結果、MADエージェントは通常、実際の観察を超えた反事実的な推論を利用せずにトレーニングされます。しかし、これらの既存の作業のほとんどは、患者の症状と疾患の因果関係を見落とします。PBPSからの有益で因果的な反応はモデリングに有益です診断の自信。 
[ABSTRACT]ヒューマンシミュレーターは患者-医師の対話レコードを使用してmad.itをトレーニングし、マッドエージェントのトレーニングで偽りの回答を生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-14">
        <br><font color="black">2020-03-14</font>
      </time>
    </span>
</section>
<!-- paper0: Structural Plan of Indoor Scenes with Personalized Preferences -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_20.html">
      <font color="black">Structural Plan of Indoor Scenes with Personalized Preferences</font>
    </a>
  </h2>
  <font color="black">提案されたモデルは、プロパティの所有者の好みに応じて、特定の屋内シーンのオブジェクトのレイアウトを自動的に生成できます。データセットに関する数値結果は、最新の方法と比較した提案されたモデルの有効性を示しています。このペーパーでは、プロのインテリアデザイナーが産業用インテリアソリューションを作成し、所有者の個人的な好みに対応するための支援モデルを提案します。 
[要約]提案されたモデルは、プロパティ所有者の好みに従ってオブジェクトのレイアウトを生成できます。さらに、モデルを使用してオブジェクトのデザインを作成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Simultaneous Semantic Alignment Network for Heterogeneous Domain
  Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_21.html">
      <font color="black">Simultaneous Semantic Alignment Network for Heterogeneous Domain
  Adaptation</font>
    </a>
  </h2>
  <font color="black">特に、ソースのカテゴリ予測分布の相関関係の知識をターゲットドメインに転送するための暗黙的な意味相関損失を提案します。異種ドメイン適応（HDA）は、異質性を示すソースドメインとターゲットドメイン間で知識を転送します（例：異なるドメイン分布や機能の違い）タイプまたはディメンション..以前のほとんどのHDAメソッドは、ドメイン不変の特徴部分空間を学習してドメイン間の不一致を減らすことでこの問題に取り組んでいます。 
[要約]この論文では、相関関係を同時に活用し、各カテゴリの重心を整列させる同時セマンティックアライメントネットワーク（ssan）を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Active Image Synthesis for Efficient Labeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_22.html">
      <font color="black">Active Image Synthesis for Efficient Labeling</font>
    </a>
  </h2>
  <font color="black">具体的には、補完的なAISELデータセットが生成され、物理ベースの方法を介してアクティブに取得されたラベルが手元にある物理的知識に組み込まれます。AISELメソッドの重要なコンポーネントは、解釈可能な機能を抽出できる双方向生成可逆ネットワーク（GIN）です。トレーニング画像から、物理的に意味のある仮想画像を生成します。ディープニューラルネットワークによって達成された大きな成功は、製造およびヘルスケアコミュニティからますます注目を集めています。 
[ABSTRACT]大動脈弁狭窄症に対するaiselフレームワークの有効性を実証しました。この方法では、ラベリングコストを$ 90＆％$削減し、予測精度を$ 15向上させました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-02-05">
        <br><font color="black">2019-02-05</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal Image-to-Image Translation via a Single Generative
  Adversarial Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_23.html">
      <font color="black">Multimodal Image-to-Image Translation via a Single Generative
  Adversarial Network</font>
    </a>
  </h2>
  <font color="black">この問題に対処するために、ペアになっていないデータを持つ複数のドメイン間で効率的なマルチモーダルI2I変換を行うための柔軟で一般的なSoloGANモデルを示します。そのため、既存のスキームの各ドメイン固有のコンテンツエンコーダーは、ドメイン不変の機能を効率的に抽出できません。 SoloGANアルゴリズムは、既存のメソッドに対して、追加の補助分類器を備えた単一の投影弁別器を使用し、すべてのドメインのエンコーダーとジェネレーターを共有します。 
[ABSTRACT]既存のマルチモーダルi2i変換方法は、複数のドメイン-異なるドメインの特定のコンテンツエンコーダーを採用しています。各画像は、同じドメインの画像でのみトレーニングされます。これは、ドメインを抽出できないためです-効果的な機能</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Decoupling Features and Coordinates for Few-shot RGB Relocalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_24.html">
      <font color="black">Decoupling Features and Coordinates for Few-shot RGB Relocalization</font>
    </a>
  </h2>
  <font color="black">私たちの重要な洞察は、座標回帰に使用されるフィーチャーエンコーダーは、座標系の注意散漫要因を取り除くことによって学習する必要があるということです。これにより、フィーチャーエンコーダーは、一般的なフィーチャー表現と、より重要でビューに依存しない機能のために複数のシーンから学習されます。 、および座標リグレッサと組み合わせると、新しいシーンでの数ショットの観察は、既存の統合ソリューションを使用したものよりも3Dの世界に接続するのがはるかに簡単です。しかし、既存の最先端のアプローチは、ほとんどサポートできません。画像特徴抽出とシーン座標回帰の絡み合いによるそのような数ショットのシーン適応。 
[ABSTRACT]カメラの再ローカリゼーションは、事前制御モデルで使用できます。代わりに、モデルを新しいシーンにすばやく適応させることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-26">
        <br><font color="black">2019-11-26</font>
      </time>
    </span>
</section>
<!-- paper0: Design and Deployment of Photo2Building: A Cloud-based Procedural
  Modeling Tool as a Service -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_25.html">
      <font color="black">Design and Deployment of Photo2Building: A Cloud-based Procedural
  Modeling Tool as a Service</font>
    </a>
  </h2>
  <font color="black">急速な都市化が気象と気候と資源の利用可能性に与える影響の増大に伴い、このようなサービスへのアクセスは、都市の天気予報の改善と気候の設計を追求する世界中の都市計画者、都市気象学者などのさまざまなユーザーを助けることが期待されています。これにより、都市の設計および計画アプリケーションで使用する建物モデルを作成するための、非常にスケーラブルで、おそらく広く普及したツールが提供されます。報告されたクラウドベースのWebアクセス可能なツールは、平均40秒で建物を再構築できます。現在の価格でたった0.60ドルの費用がかかります。 
[ABSTRACT]新しいツールは、以前のデスクトップバージョンのtimeに基づいています。ジョブキューとWebベースのサポートにより、クライアントサーバーモデルに変換されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Land Use and Land Cover Classification using a Human Group based
  Particle Swarm Optimization Algorithm with a LSTM classifier on
  hybrid-pre-processing Remote Sensing Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_26.html">
      <font color="black">Land Use and Land Cover Classification using a Human Group based
  Particle Swarm Optimization Algorithm with a LSTM classifier on
  hybrid-pre-processing Remote Sensing Images</font>
    </a>
  </h2>
  <font color="black">次に、ローカルガボールバイナリパターンヒストグラムシーケンス（LGBPHS）、配向勾配ヒストグラム（HOG）、ハラリックテクスチャフィーチャーを使用して、選択した画像からの特徴抽出のためにハイブリッド最適化を行います。このハイブリッド最適化の利点は、カラーおよびグレースケール画像に対する高い識別力と不変性。LULC分類は、土4、土6、およびユーロサットデータセットを使用して評価されます。 
[概要] lulcは、ハイブリッド機能拡張アルゴリズムとディープラーニング分類器です。lulc分類のパフォーマンスを向上させ、野生生物の生息地の予測、環境品質の劣化、偶然などを予測するために提案されています。リモートセンシング画像の選択後、画像の品質を向上させるために、正規化およびヒストグラム均等化方法が使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: A non-discriminatory approach to ethical deep learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_27.html">
      <font color="black">A non-discriminatory approach to ethical deep learning</font>
    </a>
  </h2>
  <font color="black">この作業では、NDRを提案します。これは、ANNモデルが、たとえば人間の顔の画像分類タスクの民族性など、いくつかの差別的な機能を使用してターゲットタスクを解決するのを防ぐ非差別的正則化戦略です。特に、 ANNモデルは、特定の学習タスクの学習にネットワークの残りの部分が集中するように、差別的な情報を隠すようにトレーニングされています。NDRを利用して、最小限の計算オーバーヘッドとパフォーマンスの損失の両方で非差別的なモデルを実現できることが示されています。 
[ABSTRACT]トレーニング戦略は、合法的、倫理的、差別的な潜在的な問題を考慮していません。特に、annモデルの一部は、差別的な情報を隠すようにトレーニングされています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: TextCaps: a Dataset for Image Captioning with Reading Comprehension -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_28.html">
      <font color="black">TextCaps: a Dataset for Image Captioning with Reading Comprehension</font>
    </a>
  </h2>
  <font color="black">データセットは、モデルにテキストを認識させ、テキストをその視覚的コンテキストに関連付け、コピーまたは言い換えるテキストの部分を決定し、複数のテキストトークンとオブジェクトなどの視覚的エンティティの間の空間的、意味的、視覚的な推論を必要とします。画像のコンテキストでテキストを理解する方法を研究します。28k画像の145kキャプションを備えた新規データセットTextCapsを収集します。ベースラインを研究し、既存のアプローチをこの新しいタスクに適用します。これは、読解を含む画像キャプションと呼ばれます。 
[ABSTRACT]データセットは、モデルにテキストを認識させ、その視覚的コンテキストに関連付け、コピーまたは言い換えるテキストの部分を決定します。新しいtextcapsデータセットは、以前のデータセットに対して多くの新しい技術的課題を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-24">
        <br><font color="black">2020-03-24</font>
      </time>
    </span>
</section>
<!-- paper0: Prior Guided Feature Enrichment Network for Few-Shot Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_29.html">
      <font color="black">Prior Guided Feature Enrichment Network for Few-Shot Segmentation</font>
    </a>
  </h2>
  <font color="black">当社のPFENetは、最先端の方法を大幅に上回って、効率を損なうこともありません。これは、（1）一般化能力を維持するだけでなく、モデルのパフォーマンスを向上させるだけでなく、トレーニング不要の事前マスク生成方法の新しい設計で構成されています。 （2）サポート機能と以前のマスクを使用してクエリ機能を適応的に強化することにより、空間の不整合を克服する機能強化モジュール（FEM）。最新のセマンティックセグメンテーションメソッドでは、良好な結果を達成し、目に見えないクラスでほとんど機能しない十分なラベル付きデータが必要です。微調整なし。 
[ABSTRACT]以前のガイド付きの機能強化ネットワーク（pfenet）は、この問題を軽減することを目的としています。以前の生成方法とfemの両方で、ベースライン方法が大幅に改善されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: PatchNets: Patch-Based Generalizable Deep Implicit 3D Shape
  Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_30.html">
      <font color="black">PatchNets: Patch-Based Generalizable Deep Implicit 3D Shape
  Representations</font>
    </a>
  </h2>
  <font color="black">さらに、既存のアプローチと比較して、はるかに少ない形状を使用してトレーニングできます。パッチのレベルでは、さまざまなカテゴリのオブジェクトが類似点を共有しているため、より一般化可能なモデルにつながります。形状を含む、新しい表現のいくつかのアプリケーションを示します補間と部分的な点群の完成。 
[要約]このホワイトペーパーでは、新しいミッドレベルパッチベースのサーフェス表現を紹介します。この時点で、このパッチをベースにした新しい表現方法を紹介します。ベースの表現です。これは、既存のカテゴリ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Fundamental Tradeoffs between Invariance and Sensitivity to Adversarial
  Perturbations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_31.html">
      <font color="black">Fundamental Tradeoffs between Invariance and Sensitivity to Adversarial
  Perturbations</font>
    </a>
  </h2>
  <font color="black">特に、モデルが（おそらく）堅牢であるにもかかわらず、人間のラベラーに従って入力のクラスを変更する小さな摂動を生成することにより、最先端の敵対的訓練を受けた信頼できる堅牢なモデルを壊します。最後に、正式に過度に不変の分類子の存在は、標準データセットに過度に堅牢な予測機能が存在することから生じることを示しています。感度ベースの攻撃に対する防御は、不変性ベースの攻撃に対するモデルの精度を積極的に損ない、新しいアプローチが必要であることを示しています。両方の攻撃タイプに抵抗します。 
[ABSTRACT]これらの例は、敏感なベースの敵対的な例に基づいています。これらには、異なるモデル予測をもたらす入力への小さな変更が含まれています。しかし、これら2つのタイプの被験者間の基本的なトレードオフを示しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-11">
        <br><font color="black">2020-02-11</font>
      </time>
    </span>
</section>
<!-- paper0: NWPU-Crowd: A Large-Scale Benchmark for Crowd Counting and Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_32.html">
      <font color="black">NWPU-Crowd: A Large-Scale Benchmark for Crowd Counting and Localization</font>
    </a>
  </h2>
  <font color="black">多くの畳み込みニューラルネットワーク（CNN）は、このタスクに取り組むために設計されています。他の実世界のデータセットと比較して、さまざまな照明シーンが含まれ、最大の密度範囲（0〜20,033）を持っています。群集の監視、公共の安全、空間設計などを含む、その広範なアプリケーションにより、研究者の多くの注目を集めています。
[要約]大規模な混雑した群集カウントおよびローカリゼーションデータセット、nwpu-crowdは、5、109画像合計2、133、375の注釈付きヘッド</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-10">
        <br><font color="black">2020-01-10</font>
      </time>
    </span>
</section>
<!-- paper0: SOLAR: Second-Order Loss and Attention for Image Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_33.html">
      <font color="black">SOLAR: Second-Order Loss and Attention for Image Retrieval</font>
    </a>
  </h2>
  <font color="black">1つは、ローカルとグローバルの両方の画像記述子のパフォーマンスを向上させるための2次の空間情報に焦点を当てています。2つの異なるタスクとデータセットでの画像の取得と画像の照合のためのアプローチを検証します。結果は、2つの2次のコンポーネントは相互に補完し合うため、両方のタスクでパフォーマンスが大幅に向上し、パブリックベンチマーク全体で最新の結果が得られます。 
[ABSTRACT] 2つの2次の空間情報は、ローカルとグローバルの両方の画像記述子のパフォーマンスを向上させることができます。データは、ハードネガティブマイニングで三重項損失を強化するために使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-24">
        <br><font color="black">2020-01-24</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchical Context Embedding for Region-based Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_34.html">
      <font color="black">Hierarchical Context Embedding for Region-based Object Detection</font>
    </a>
  </h2>
  <font color="black">包括的な実験は、HCEフレームワークが柔軟で一般化可能であることを示しており、FPN、カスケードR-CNN、マスクR-CNNなどのさまざまな領域ベースの検出器に大幅で一貫した改善をもたらします。具体的には、コンテキスト依存オブジェクトの認識を進めるためカテゴリでは、オブジェクトレベルの概念を学習するために全体的なイメージレベルのコンテキストを活用するイメージレベルのカテゴリカルな埋め込みモジュールを提案します。最先端の2段階のオブジェクト検出器は、オブジェクト提案のスパースセットに分類子を適用します。 RoIPoolまたはRoIAlignによって入力として抽出された地域ごとの機能に依存します。 
[要約]ワイヤレスベースのツールのコンセプトは、潜在的な潜在的なオブジェクトを検出するために使用できます。また、認識だけでなく、新しいモデルのツールとしても使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Discriminative Feature with CRF for Unsupervised Video Object
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_35.html">
      <font color="black">Learning Discriminative Feature with CRF for Unsupervised Video Object
  Segmentation</font>
    </a>
  </h2>
  <font color="black">挑戦的なデータセットPASCAL-VOCで実験を行い、DFNetの優位性を観察します。FBMSデータセットとビデオ顕著性データセットViSalでDFNetをさらに評価し、新しい最先端技術に到達します。D機能は次に、条件付きランダムフィールド（CRF）の定式化の下でテスト画像のすべての機能との対応を確立するために使用されます。これは、ピクセル間の一貫性を強化するために利用されます。 
[要約]実験により、dfnetはランダムな方法よりも平均マージンが83. 4％と大幅に優れていることが証明されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Associative Alignment for Few-shot Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_36.html">
      <font color="black">Associative Alignment for Few-shot Image Classification</font>
    </a>
  </h2>
  <font color="black">2つの連想アラインメント戦略を提案します。1）関連するベースサンプルと特徴空間内の新規インスタンスの重心との間の距離を最小化するためのメトリック学習損失、および2）Wasserstein距離に基づく条件付きの対立アラインメント損失。 4つの標準データセットと3つのバックボーンは、重心ベースのアライメント損失を組み合わせると、オブジェクト認識、きめの細かい分類に関する最新の5ショット学習で、絶対精度が4.4％、1.2％、6.2％向上することを示しています。これにより、いくつかの新規インスタンスに「関連する基本」インスタンスが追加され、効果的な新規トレーニングセットのサイズが拡大され、建設的な微調整が可能になります。 
[ABSTRACT]ベースデータの一部を活用するための連想アラインメントのアイデアを提案します。5,000以上の新しいトレーニングインスタンスを、ベーストレーニングセットの密接に関連するインスタンスに追加します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-11">
        <br><font color="black">2019-12-11</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Visual Representations with Caption Annotations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_37.html">
      <font color="black">Learning Visual Representations with Caption Annotations</font>
    </a>
  </h2>
  <font color="black">キャプション付きの画像は簡単にクロールできるという観察から始めて、この見落とされた情報源は、視覚表現のトレーニングを監視するために悪用される可能性があると主張します。私たちの実験では、画像のキャプションを活用して、グローバルおよびローカライズされた意味情報を視覚表現に注入できることを確認しています。 ..このタスクに取り組むために、専用のビジュアルおよびテキストエンコーダーを備えたハイブリッドモデルを提案し、このタスクを解決することの副産物として学習されたビジュアル表現が、さまざまなターゲットタスクにうまく移行することを示します。 
[要約]副産物として学習された視覚的表現-このタスクを解決した結果、さまざまなターゲットタスクに適切に転送されます。これは、画像上の視覚的表現を学習するためのプロキシタスクとして使用できます-キャプションペア</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Deep Cross-modality Spectral Hashing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_38.html">
      <font color="black">Unsupervised Deep Cross-modality Spectral Hashing</font>
    </a>
  </h2>
  <font color="black">2番目のステップでは、有益なデータ入力（画像と単語の埋め込み）から最初のステップで取得したバイナリコードへのマッピング関数を学習するために、画像の強力なCNNを活用し、CNNベースのディープアーキテクチャを提案してテキストモダリティを学習します。 3つの標準的なベンチマークデータセットの評価は、提案されたDCSHメソッドが他の最先端のメソッドよりも常に優れていることを示しています。最初のステップでは、単一モダリティとバイナリクロスモダリティを同時に学習する新しいスペクトル埋め込みベースのアルゴリズムを提案します。表現。 
[要約] dcshシステムは2段階のハッシュアプローチです。2段階のハッシュ方式に機能強化を分離します。2番目は、すべてのモダリティから隠されたパターンを明らかにします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-01">
        <br><font color="black">2020-08-01</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Uncertainty-Aware Multiview Triangulation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_39.html">
      <font color="black">Robust Uncertainty-Aware Multiview Triangulation</font>
    </a>
  </h2>
  <font color="black">インライアセットの反復更新により、最適化により精度とロバスト性が大幅に向上することを示します。3番目に、三角点の不確実性を3つの要因の関数としてモデル化します。カメラの数、平均再投影エラー、最大視差角。このモデルを学習することで、テスト時に不確実性をすばやく補間できます。 
[ABSTRACT]私たちは、2点ランサックと中点法を使用した外れ値拒否スキームを提案します。比較により、三角点を優先するためのさまざまな局所強調法を比較します。これらは、広範な評価を通じて本法を検証します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Graph Representation Adaptation for Cross-Domain Facial
  Expression Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_40.html">
      <font color="black">Adversarial Graph Representation Adaptation for Cross-Domain Facial
  Expression Recognition</font>
    </a>
  </h2>
  <font color="black">最近の研究では、ドメインシフトを軽減するためにドメイン不変の機能を学習する敵対的なメカニズムに頼っています。これを達成するために、まず、各ドメイン内の全体領域と局所領域を関連付けるグラフを作成し、別のドメイン間でこれらの領域を関連付ける別のグラフを作成します。次に、各ドメインのクラスごとの統計分布を学習し、入力画像から全体的な局所特徴を抽出して、対応するグラフノードを初期化します。 
[要約]提案されたagraフレームワークは、以前の状態より優れたパフォーマンスを実現します-最先端の方法です。これは、各ドメイン内の全体的領域と局所的領域を関連付けるパターンを開発するために使用されます。また、式認識のためのより詳細で識別的なコンテンツを備えています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-03">
        <br><font color="black">2020-08-03</font>
      </time>
    </span>
</section>
<!-- paper0: Hybrid Models for Open Set Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_41.html">
      <font color="black">Hybrid Models for Open Set Recognition</font>
    </a>
  </h2>
  <font color="black">表現空間は、インライア分類器と密度推定器（外れ値検出器として機能）から共同で学習する必要があると主張します。埋め込み空間は、多くの場合、判別分類器から取得されます。既存のフローベースモデルの典型的な問題は、彼らは外れ値により高い可能性を割り当てるかもしれません。 
[要旨] openhybridフレームワークは、入力データを埋め込みspace.classifierにエンコードしてサンプルをインライアクラスに分類するエンコーダーと、フローに基づいた密度推定器が、サンプルが不明なカテゴリに属しているかどうかを検出するために必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-27">
        <br><font color="black">2020-03-27</font>
      </time>
    </span>
</section>
<!-- paper0: BSD-GAN: Branched Generative Adversarial Network for Scale-Disentangled
  Representation Learning and Image Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_42.html">
      <font color="black">BSD-GAN: Branched Generative Adversarial Network for Scale-Disentangled
  Representation Learning and Image Synthesis</font>
    </a>
  </h2>
  <font color="black">このような明示的なサブベクトル指定の結果は、さまざまな機能スケールをモデル化する潜在的な（サブベクトル）コードを直接操作し、さらには組み合わせることができるということです。余分なラベルなしで、合成された高解像度画像の品質を損なうことなく、新しい画像コンテンツの合成。ソースコードは、https：//github.com/duxingren14/BSD-GANで入手できます。トレーニング中、「deより高い解像度の画像の新しいセットがトレーニングに使用され、より多くのネットワークレイヤーが追加されるため、サブベクトルを1つずつ「フリーズ」します。 
[ABSTRACT] bsd-ganの主要な機能は、複数のブランチでトレーニングされ、ネットワークの幅と深さの両方を段階的にカバーすることです。トレーニング画像の解像度が高くなるにつれて、より細かいスケールの機能が明らかになります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-03-22">
        <br><font color="black">2018-03-22</font>
      </time>
    </span>
</section>
<!-- paper0: Weight-Sharing Neural Architecture Search:\\A Battle to Shrink the
  Optimization Gap -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_43.html">
      <font color="black">Weight-Sharing Neural Architecture Search:\\A Battle to Shrink the
  Optimization Gap</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、NASに関する文献レビュー、特にウェイトシェアリング手法について説明し、主な課題はスーパーネットワークとサブアーキテクチャ間の最適化のギャップに起因することを指摘します。負担を軽減するために、ウェイトシェアリング手法指数関数的に多くのアーキテクチャが同じスーパーネットワークで重みを共有し、コストのかかるトレーニング手順が1回だけ実行されることが提案されました。著者の専門知識により、このペーパーは主にNASのコンピュータービジョンの問題への適用に焦点を当て、私たちのグループでの仕事への偏見。 
[ABSTRACT]この研究は幼い頃の研究者によって行われました。彼らは代替のアーキテクチャを作成するために重量試験方法を使用しました。しかし、彼らはしばしば不安定性の問題に苦しみます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Disentangling Human Error from the Ground Truth in Segmentation of
  Medical Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_44.html">
      <font color="black">Disentangling Human Error from the Ground Truth in Segmentation of
  Medical Images</font>
    </a>
  </h2>
  <font color="black">次に、3つのパブリックメディカルイメージングセグメンテーションデータセットに対して、シミュレーション（必要な場合）および実際の多様なアノテーションを使用して、メソッドの有用性を示します。1）MSLSC（多発性硬化症病変）。 2）BraTS（脳腫瘍）; 3）LIDC-IDRI（肺の異常）。2つの分離は、ノイズの多いトレーニングデータで高い忠実度を達成しながら、推定アノテーターを最大限に信頼できないようにすることで達成されます。実験は、複雑な空間特性をキャプチャする強力な能力も示していますアノテーターの間違いの。 
[ABSTRACT]アルゴリズムはアノテーターからのデータに基づいており、コストは2,000ドルです。これらのアルゴリズムはさまざまな人間の専門家に基づいています。これらのアルゴリズムの結果はラベルの品質に依存すると述べています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-31">
        <br><font color="black">2020-07-31</font>
      </time>
    </span>
</section>
<!-- paper0: DEMEA: Deep Mesh Autoencoders for Non-Rigidly Deforming Objects -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_45.html">
      <font color="black">DEMEA: Deep Mesh Autoencoders for Non-Rigidly Deforming Objects</font>
    </a>
  </h2>
  <font color="black">DEMEAは、変形が低次元の埋め込み変形グラフで定義されているため、変形のパラメータ化を最終的なメッシュ解像度から切り離します。メッシュオートエンコーダは、次元削減、サンプリング、メッシュモデリングによく使用されます。 -奥行きとシェーディングキューからの剛体3D再構築、非剛体サーフェストラッキング、および異なるメッシュ上での変形の転送。 
[ABSTRACT] shaeaは新しい形式の剛性を追加するオートエンコーダです。最終的なメッシュ解像度からデータを分離します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-24">
        <br><font color="black">2019-05-24</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-end Full Projector Compensation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_46.html">
      <font color="black">End-to-end Full Projector Compensation</font>
    </a>
  </h2>
  <font color="black">次に、シャムアーキテクチャを使用して設計された、CompenNeStという新しいフォトメトリック補正サブネットを提案します。これは、投影面と投影画像間のフォトメトリック相互作用をキャプチャし、そのような情報を使用して幾何学的に補正された画像を補正します。実用性を向上させるために、トレーニング画像の数とトレーニング時間を大幅に削減するために、新しい合成データベースの事前トレーニング戦略を提案します。このホワイトペーパーでは、CompenNeSt ++という最初のエンドツーエンドの微分可能なソリューションを提案し、二つの問題が一緒に。 
[ABSTRACT]新しいデザインはwarpingnetと呼ばれます。これは、カスケードされた微細構造と連携してサンプリング画像を学習します。サンプリング画像からサンプリング領域を学習するように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-30">
        <br><font color="black">2020-07-30</font>
      </time>
    </span>
</section>
<!-- paper0: Open-Edit: Open-Domain Image Manipulation with Open-Vocabulary
  Instructions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_47.html">
      <font color="black">Open-Edit: Open-Domain Image Manipulation with Open-Vocabulary
  Instructions</font>
    </a>
  </h2>
  <font color="black">さらに、操作された画像を正則化し、ソース画像の詳細を保持するように強制するために、サイクル一貫性制約を備えたオンザフライのサンプル固有の最適化アプローチを提案します。私たちのアプローチは、オープン語彙の色、テクスチャ、オープンドメイン画像のさまざまなシナリオの高レベルの属性..私たちのアプローチは、一般的な画像キャプションデータセットで事前トレーニングされた統合された視覚的意味の埋め込みスペースを利用し、テキストガイド付きベクトル演算を画像機能マップ。 
[要約]私たちのアプローチは、オープンドメイン画像のさまざまなシナリオのオープンサンプリングの色、テクスチャ、視覚的属性を操作することで有望な結果を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Shape Consistent 2D Keypoint Estimation under Domain Shift -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_48.html">
      <font color="black">Shape Consistent 2D Keypoint Estimation under Domain Shift</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、3つの異なるコンポーネントをシームレスに組み合わせます：特徴の整列、敵対的なトレーニング、および自己監視。さらに、出力空間での整列予測を保証するための敵対的な用語と、ターゲットサンプルとその摂動バージョン。深いアーキテクチャに基づく最近の教師なしドメイン適応手法は、従来の分類タスクだけでなく、構造化予測を含むより複雑な問題でも注目に値するパフォーマンスを示しています（たとえば、
[ABSTRACT]最近のテストでは、当社のアプローチがg。。。たとえば、私たちは問題を提示します..私たちの研究は、改善のシステムを開発する必要があることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Fisher Discriminative Least Squares Regression for Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_49.html">
      <font color="black">Fisher Discriminative Least Squares Regression for Image Classification</font>
    </a>
  </h2>
  <font color="black">このペーパーのMatlabコードは、https：//github.com/chenzhe207/FDLSR。で入手できます。さまざまなデータセットに対する広範な実験により、提案されたFDLSRメソッドが、他の最先端の分類方法よりも優れたパフォーマンスを実現することが示されています。 。FDLSRは初めて、フィッシャーの判別基準と$ \ epsilon $ -draggings手法を1つの統合モデルに統合しようとします。これは、これらが判別射影の学習において完全に補完的であるためです。 
[要約]提案されたfdlsrメソッドは、異なるクラスの緩和されたラベルの制御を支援するように設計されています。ただし、クラス間の分離性をさらに向上させることが期待されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-03-19">
        <br><font color="black">2019-03-19</font>
      </time>
    </span>
</section>
<!-- paper0: Joint Demosaicing and Super-Resolution (JDSR): Network Design and
  Perceptual Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_50.html">
      <font color="black">Joint Demosaicing and Super-Resolution (JDSR): Network Design and
  Perceptual Optimization</font>
    </a>
  </h2>
  <font color="black">ネットワーク設計では、前処理ステップとして、事前デモザイキングネットワーク（PDNet）でサポートされる残差密スクイーズアンドエキサイテーションネットワーク（RDSEN）を開発しました。画像のデモザイクと超解像は、カラーにおける2つの重要なタスクです。イメージングパイプライン..私たちの技術的貢献は主に2つあります。 
[要約]不満のある画像は、ディープラーニングの公開文献でほとんど独立して研究されてきました。しかし、デモザイキングと超解像（jdsr）の共同問題の潜在的なアーキテクチャについてはほとんど知られていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-08">
        <br><font color="black">2019-11-08</font>
      </time>
    </span>
</section>
<!-- paper0: Spherical Feature Transform for Deep Metric Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_51.html">
      <font color="black">Spherical Feature Transform for Deep Metric Learning</font>
    </a>
  </h2>
  <font color="black">その結果、特徴変換は、球状データ分布を尊重する回転によって実行されます。特徴空間でのデータ拡張は、データの多様性を高めるのに効果的です。クラス間の同一の共分散の仮定を、超球。 
[ABSTRACT]クラス間の同一の共分散の仮定を超球上の類似の共分散の仮定に緩和します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Adaptive Medical Image Segmentation via Adversarial Learning of
  Disease-Specific Spatial Patterns -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_52.html">
      <font color="black">Domain Adaptive Medical Image Segmentation via Adversarial Learning of
  Disease-Specific Spatial Patterns</font>
    </a>
  </h2>
  <font color="black">適応プロセスには継続的な監視が必要ですが、ターゲットドメインのグラウンドトゥルースマスクの存在を想定できないため、適応プロセスを監視するための2つの新しいメトリックと、セグメンテーションアルゴリズムを安定した方法でトレーニングするための戦略を提案します。このホワイトペーパーでは、新しいターゲットドメインからの手動アノテーションを使用せずに、ターゲットドメインからのいくつかの画像でネットワークを再キャリブレーションすることにより、複数のドメインにまたがる画像セグメンテーションパフォーマンスを向上させるための教師なしドメイン適応フレームワークを提案します。ターゲットドメインからのいくつかのラベル付けされていない画像の深いネットワークにより、セグメンテーションの精度が大幅に向上します。 
[要約]ネットワークを拒否してアーキテクチャを実施しますが、ありそうもないパターンは拒否します。これらは2つの異なるタイプの脳スキャンに基づいています。また、アルゴリズムを使用して、疾患-敵対的な特定の領域をキャプチャします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-25">
        <br><font color="black">2020-01-25</font>
      </time>
    </span>
</section>
<!-- paper0: Evaluating the performance of the LIME and Grad-CAM explanation methods
  on a LEGO multi-label image classification task -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_53.html">
      <font color="black">Evaluating the performance of the LIME and Grad-CAM explanation methods
  on a LEGO multi-label image classification task</font>
    </a>
  </h2>
  <font color="black">一般に、Grad-CAMはこの特定のタスクでLIMEよりも優れているように見えます。コアパフォーマンスの観点からより詳細な洞察が得られ、回答者の80 \％が、彼らが刺激する信頼に関して彼らから選択するように求めましたモデル内でGrad-CAMを選択します。このホワイトペーパーでは、画像にラベルを付けるLEGOブロックで画像にラベルを付けるようにトレーニングされた畳み込みニューラルネットワークで、LIMEとGrad-CAMの2つの説明方法を実行します。ただし、また、得られる洞察は補完的であるため、これら2つの方法を一緒に使用する方が便利であるとも考えています。 
[ABSTRACT]これら2つの方法を一緒に評価します。これらには、ネットワークのコアパフォーマンスの改善と、システムのユーザーに対して生成できる信頼が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: LoCo: Local Contrastive Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_54.html">
      <font color="black">LoCo: Local Contrastive Representation Learning</font>
    </a>
  </h2>
  <font color="black">ディープニューラルネットは、通常、エンドツーエンドのバックプロパゲーションを実行して重みを学習します。これは、レイヤー全体の重み更新ステップで同期制約を作成し、生物学的に妥当ではありません。GreedyInfoMaxはローカル目的で各ブロックを個別に学習しますが、最新の教師なし対照学習アルゴリズムでは、おそらく貪欲な目的と勾配分離が原因で、読み取り精度が一貫して損なわれることになります。この作業では、ローカルブロックを互いに積み重ねることにより、デコーダーの深さを効果的に増やし、上位のブロックが暗黙的に下位のブロックにフィードバックを送信できるようにします。 
[ABSTRACT]調査は、ローカルブロックを互いの上に積み重ねて周回させることにより、効率的にdecohrzationを増加させることを示しています。単純な学習アルゴリズムもローカルにすることができます。ただし、下位層の更新は上位層の計算に直接依存しません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: ExchNet: A Unified Hashing Network for Large-Scale Fine-Grained Image
  Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_55.html">
      <font color="black">ExchNet: A Unified Hashing Network for Large-Scale Fine-Grained Image
  Retrieval</font>
    </a>
  </h2>
  <font color="black">広範な実験によって検証されたこの提案は、5つのきめの細かいデータセットで最先端の一般的なハッシュ手法よりも常に優れており、これが私たちの有効性を示しています。さらに、これらの部分レベルの機能の識別能力と意味の一貫性を確保する画像を使用して、特徴交換操作を実行することにより、局所特徴整列アプローチを設計します。具体的には、ExchNetと呼ばれる統合されたエンドツーエンドのトレーニング可能なネットワークを提案します。 
[要約]このホワイトペーパーでは、細かいハッシュトピックを調査して、コンパクトなバイナリコードを生成します。exchnetを使用すると、ハッシュ学習の検索と格納の効率を向上させ、問題のある問題を緩和できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Domain Adaptive Object Detection: a Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_56.html">
      <font color="black">Deep Domain Adaptive Object Detection: a Survey</font>
    </a>
  </h2>
  <font color="black">第二に、ディープドメイン適応型検出器は5つのカテゴリに分類され、各カテゴリの代表的な方法の詳細な説明が提供されます。このホワイトペーパーは、ディープドメイン適応型オブジェクト検出アプローチに関する最先端のレビューを目的としています。最初に、ディープドメイン適応の基本的な概念を簡単に紹介します。 
[要約]ディープドメイン適応オブジェクト検出（ddaod）は、上記の課題に対処するための新しい学習ツールとして登場しました。最初に、ディープドメイン適応の基本概念を簡単に紹介します。最後に、将来の研究動向に関する洞察を示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-17">
        <br><font color="black">2020-02-17</font>
      </time>
    </span>
</section>
<!-- paper0: Weakly Supervised 3D Hand Pose Estimation via Biomechanical Constraints -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_57.html">
      <font color="black">Weakly Supervised 3D Hand Pose Estimation via Biomechanical Constraints</font>
    </a>
  </h2>
  <font color="black">この課題を受け入れ、一連の新しい損失を提案します。主な困難は、追加の2D監視を直接適用すると、主に2Dプロキシの目的に利益をもたらすが、深さとスケールのあいまいさを軽減することはほとんどないという事実に起因します。2Dキーポイントの注釈は取得がはるかに簡単であり、そのような弱く監視されたデータを効率的に活用して3D手のポーズ予測のタスクを改善する方法は、重要な未解決の問題のままです。 
[ABSTRACT]新しい最先端の手法は、完全に監視されたディープニューラルネットワークを3Dグラウンドでトレーニングします-真実データ。新しい最新の手法を使用して、3D手のポーズを改善します予測</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-20">
        <br><font color="black">2020-03-20</font>
      </time>
    </span>
</section>
<!-- paper0: AE TextSpotter: Learning Visual and Linguistic Representation for
  Ambiguous Text Spotting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_58.html">
      <font color="black">AE TextSpotter: Learning Visual and Linguistic Representation for
  Ambiguous Text Spotting</font>
    </a>
  </h2>
  <font color="black">図で「BERLIN」が「BERL」および「IN」として誤って検出されています。シーンテキストスポッティングは、自然画像内の複数の文字を含む単語または文全体を検出および認識することを目的としています。たとえば、非常に厳格な検証セットを慎重に選択しますIC19-ReCTSデータセットからのあいまいなサンプル。このアプローチでは、他の方法を4％以上上回っています。 
[ABSTRACT]提案されたae textspotterには3つの重要な利点があります。言語モデルを使用してテキスト検出を改善するのは初めてです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-03">
        <br><font color="black">2020-08-03</font>
      </time>
    </span>
</section>
<!-- paper0: Faster Stochastic Alternating Direction Method of Multipliers for
  Nonconvex Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_59.html">
      <font color="black">Faster Stochastic Alternating Direction Method of Multipliers for
  Nonconvex Optimization</font>
    </a>
  </h2>
  <font color="black">さらに、SPIDER-ADMMをオンライン設定に拡張し、より高速なオンラインSPIDER-ADMMを提案します。さらに、SPIDER-ADMMが$ \ mathcal {の記録を破る増分1次オラクル（IFO）の複雑さを実現することを証明します{ O}（n + n ^ {1/2} \ epsilon ^ {-1}）$は$ \ epsilon $近似の定常点を見つけるためのもので、確定的なADMMを係数$ \ mathcal {O}（n ^ {1/2}）$、ここで$ n $はサンプルサイズを示します。私たちの理論的な分析では、オンラインのSPIDER-ADMMのIFOの複雑度は$ \ mathcal {O}（\ epsilon ^ {-\ frac {3} {2}}）$は、既存の最良の結果を$ \ mathcal {O}（\ epsilon ^ {-\ frac {1} {2}}）$だけ改善します。 
[ABSTRACT] spider-admmは記録を破る-増分1次オラクル（ifoch）の複雑さ。新しい分析フレームワークは、新しいメソッドが既存の非営利、svrgおよびsaga-admmの最適なifo複雑さを持っていることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient resource management in UAVs for Visual Assistance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_60.html">
      <font color="black">Efficient resource management in UAVs for Visual Assistance</font>
    </a>
  </h2>
  <font color="black">UAVをビジュアルアシスタンスタスクにリアルタイムで使用する上での主要な課題の1つは、これらのタスクのメモリ使用量と電力消費を管理することです。これらのタスクは、計算が集中し、UAVのローエンドプロセッサボードで実行するのは困難です。このプロジェクトでは、飛行時間に影響を与えず、これらのモデルのレイテンシと精度を変更せずに、リアルタイムシナリオでUAVハードウェアのオブジェクトトラッキングやオブジェクト検出などの一般的な画像処理タスクを最適化する新しい方法です。しかし、ほとんどの評価モデルはハイエンドCPUで実行されます。とGPU。 
[ABSTRACT] UAVを視覚的支援にリアルタイムで使用することは無人です。これらは、UAVオブジェクトのローエンドプロセッサボードで実行することは困難です。これは、コンピュータビジョンのディープラーニングモデルにもかかわらず</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-11">
        <br><font color="black">2020-07-11</font>
      </time>
    </span>
</section>
<!-- paper0: Uncertainty quantification in medical image segmentation with
  normalizing flows -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_61.html">
      <font color="black">Uncertainty quantification in medical image segmentation with
  normalizing flows</font>
    </a>
  </h2>
  <font color="black">基本的な考え方は、エンコーダーの後にcFlow変換ステップを導入することにより、cVAEの表現力を高めることです。条件付き変分オートエンコーダー（cVAE）のクラスは、入力画像で条件付けされたもっともらしいセグメンテーションの分布を推測する原理的なアプローチを提供します。このような分布のサンプルから推定される不確実性は、ピクセルレベルの確率スコアを使用する場合よりも有益です。 
[ABSTRACT]セグメンテーションの不確実性は、関心のある構造の境界付近にあります。ただし、システムにもいくつかの違いがあります。これは、エンコーダーの表現力を高めるために新しいモデルを使用しているためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-04">
        <br><font color="black">2020-06-04</font>
      </time>
    </span>
</section>
<!-- paper0: MOR-UAV: A Benchmark Dataset and Baselines for Moving Object Recognition
  in UAV Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_62.html">
      <font color="black">MOR-UAV: A Benchmark Dataset and Baselines for Moving Object Recognition
  in UAV Videos</font>
    </a>
  </h2>
  <font color="black">したがって、このホワイトペーパーでは、MOR-UAVを紹介します。これは、空中ビデオにおけるMORの大規模ビデオデータセットです。複数のレイヤーの視覚化を通じて、ネットワーク内のモーションサリエント領域も分析します。リアルタイムのUAVビデオストリームが与えられます。 、動いているオブジェクトをローカライズして分類するにはどうすればよいですか。つまり、
[ABSTRACT]既存の動画はオブジェクト検出に焦点を当てています。ラベル付きのデータセットは、空中監視、捜索と救助、イベントの認識、都市と農村のシーンの理解に利用できません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Two-Stage Deep Learning for Accelerated 3D Time-of-Flight MRA without
  Matched Training Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_63.html">
      <font color="black">Two-Stage Deep Learning for Accelerated 3D Time-of-Flight MRA without
  Matched Training Data</font>
    </a>
  </h2>
  <font color="black">具体的には、最初のネットワークは二乗和平方根（SSoS）ドメインでトレーニングされ、高品質の並列画像再構成を実現しますが、2番目の改良ネットワークは、双頭を使用して高度に活性化された血流の特性を効率的に学習するように設計されていますmax-pool discriminator ..広範囲にわたる実験は、一致する参照のない提案された学習プロセスが、最先端の圧縮センシング（CS）ベースの方法のパフォーマンスを超え、教師あり学習アプローチと同等またはそれ以上の結果を提供することを示しています。最適な輸送理論からのcycleGANの最近の理論的理解、ここでは、冠状面に沿ったマルチコイル再構成ネットワークとそれに続く軸方向に沿ったマルチ平面精密化ネットワークで構成される、新しい2段階の教師なし深層学習アプローチを提案します飛行機。 
[要約]アンダーサンプリングされたtofからの高品質の再構成-mraはディープラーニングの重要な研究トピックです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Compact Global Descriptor for Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_64.html">
      <font color="black">Compact Global Descriptor for Neural Networks</font>
    </a>
  </h2>
  <font color="black">この記述子を使用すると、後続の畳み込みで、計算の複雑さとパラメーターがごくわずかな有益なグローバル機能にアクセスできます。コードは、https：//github.com/HolmesShuan/Compact-Global-Descriptor ..で入手できます。異なる次元（チャネル、フレームなど）にわたる位置間の相互作用をモデル化するためのグローバル記述子。 
[ABSTRACT]この記述子により、後続の畳み込みが有益なグローバル機能にアクセスできるようになります。このデスクマーカーにより、後続の情報に役立つグローバル機能にアクセスできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-23">
        <br><font color="black">2019-07-23</font>
      </time>
    </span>
</section>
<!-- paper0: Applying Incremental Deep Neural Networks-based Posture Recognition
  Model for Injury Risk Assessment in Construction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_65.html">
      <font color="black">Applying Incremental Deep Neural Networks-based Posture Recognition
  Model for Injury Risk Assessment in Construction</font>
    </a>
  </h2>
  <font color="black">ただし、以下についてさらに調査が必要です。i）インクリメンタルラーニング（IL）。訓練されたモデルが新しい姿勢を学習し、学習した姿勢の忘却を制御するために適応します。 ii）認識された姿勢によるMSDの評価..厄介な姿勢の監視は、建設における筋骨格障害（MSD）の予防的な予防策です。インクリメンタルCLNモデルから認識された姿勢を使用したMSDの評価には、グラウンドトゥルースとの小さな違いがあり、自動化の高い可能性を示しています。建設中のMSDモニタリング。 
[要約]機械学習（mm）モデルは、ウェアラブルセンサーからの姿勢認識に有望な結果を示しています。これらのタイプの学習は、適応（0. 73）と被験者の忘却（0. 74）のバランスをとることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: A Novel Indoor Positioning System for unprepared firefighting scenarios -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_66.html">
      <font color="black">A Novel Indoor Positioning System for unprepared firefighting scenarios</font>
    </a>
  </h2>
  <font color="black">消防環境では、煙と視界不良のためにサーマルイメージングカメラが使用されるため、消失点の推定から相対的な方向を取得することは非常に困難です。そして、犠牲者の消防士の位置..推測航法、WifiとBluetoothベースの三角測量、屋内測位システム用のモーションからの構造（SFM）ベースのシーン再構成のような他のテクニックはほとんどありません。 
[ABSTRACT]これらの技術は、火災関連の環境で必要な情報を中継するのに適していません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Spatially Adaptive Inference with Stochastic Feature Sampling and
  Interpolation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_67.html">
      <font color="black">Spatially Adaptive Inference with Stochastic Feature Sampling and
  Interpolation</font>
    </a>
  </h2>
  <font color="black">この問題を回避するために、Gumbel-Softmax分布に基づく再パラメーター化トリックを使用します。これにより、逆伝播によりこれらの変数をバイナリ値に向けて反復できます。この余分な計算を減らすために、まばらにサンプリングされた場所でのみ機能を計算することを提案します。は、活性化応答に従って確率論的に選択され、効率的な補間手順で特徴マップを密に再構築します。このサンプリングベースのアプローチの技術的な課題は、離散サンプリング位置を表すためのバイナリ決定変数が微分不可能であり、互換性がないことです。逆伝播あり。 
[ABSTRACT]この余分なコレクションを制限する代わりに、ペンシルベニア州のペンシルベニア州に拠点を置くスタートアップにカオス的である可能性を提案します。代わりに、効率的な補間手順で対応できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-19">
        <br><font color="black">2020-03-19</font>
      </time>
    </span>
</section>
<!-- paper0: Geometric Interpretations of the Normalized Epipolar Error -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_68.html">
      <font color="black">Geometric Interpretations of the Normalized Epipolar Error</font>
    </a>
  </h2>
  <font color="black">特に、次の量に直接関連していることを示します：（1）2つの逆投影光線間の最短距離、（2）2つの境界エピポーラ平面間の二面角、（3）$ L_1 $最適角度再投影エラー..この作業では、正規化されたエピポーラエラーの幾何学的解釈を提供します。 
[ABSTRACT] 2つの逆生成された光線間の最短距離に直接関連していることを示します。これには、2つの境界エピポーラ平面間の無効距離が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Addressing the Cold-Start Problem in Outfit Recommendation Using Visual
  Preference Modelling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_69.html">
      <font color="black">Addressing the Cold-Start Problem in Outfit Recommendation Using Visual
  Preference Modelling</font>
    </a>
  </h2>
  <font color="black">定性的に、パイロット調査を通じて、コールドスタートシナリオで多様で個別化された推奨事項を提供するためのシステムの有効性を実証します。定量的に、提案された視覚的選好モデリングアプローチは、衣服の属性予測の面で最新の技術より優れていることを示しています..コールドスタートの問題。 
[ABSTRACT]新しいエンティティでのパフォーマンスが低いため、このテクノロジーは依然として制限されています。提案されている衣服の視覚的嗜好モデルは、少数の入力画像に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Stereo from Single Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_70.html">
      <font color="black">Learning Stereo from Single Images</font>
    </a>
  </h2>
  <font color="black">この方法でトレーニングすると、単一のRGB画像の任意のコレクションをステレオトレーニングデータに変換できます。教師ありディープネットワークは、ステレオ画像ペアの対応を見つけるための最良の方法の1つです。しかし、正確で密な対応データを大量に収集することは非常に困難です。挑戦。 
[ABSTRACT]視差マップは、注意深く設計されたパイプラインでステレオトレーニングペアを生成するために使用されます。これにより、実際の深度を収集したり、合成データを手動で設計したりする必要なく、人間の労力を大幅に削減できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: A Guaranteed Convergence Analysis for the Projected Fast Iterative
  Soft-Thresholding Algorithm in Parallel MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_71.html">
      <font color="black">A Guaranteed Convergence Analysis for the Projected Fast Iterative
  Soft-Thresholding Algorithm in Parallel MRI</font>
    </a>
  </h2>
  <font color="black">in vivo脳画像の実験は、収束基準の有効性を示しています。この作業では、2つのよく知られた並列イメージング再構成モデルであるSENSEとSPIRiTを解決するために、並列イメージングバージョンpFISTAの保証された収束分析を提供します。不均一なサンプリングと圧縮センシング技術の組み合わせにより、磁気共鳴イメージングの長いデータ収集の問題が大幅に軽減されます。 
[ABSTRACT]スローモーニングアルゴリズムは、パラレルイメージングに拡張されました。プロジェクトで使用するために商用スキャナーで使用されています。ただし、新しい方法はスローモーションpfistaには適用できません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-17">
        <br><font color="black">2019-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Multiscale Sparsifying Transform Learning for Image Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_72.html">
      <font color="black">Multiscale Sparsifying Transform Learning for Image Denoising</font>
    </a>
  </h2>
  <font color="black">このため、最初にTLDを介して各ウェーブレットサブバンドを個別にノイズ除去する簡単な方法を採用します。提案された方法の有効性は、2つのデータセットで実験的に示されています。1）ガウスノイズで破損した古典的なテスト画像、2）破損した蛍光顕微鏡画像次に、この方法は、安価な融合手法であるウェーブレットサブバンドミキシングを使用して、シングルスケール法とマルチスケール法の結果を組み合わせると大幅に強化できることを示します。 
[要約]提案されたマルチスケール手法は、驚くべきことに、単一スケールであり、画像のマルチスケールの性質を無視します。この単純化により、ベースラインに匹敵するパフォーマンスを備えた効率的なマルチスケールのノイズ除去方法が実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-25">
        <br><font color="black">2020-03-25</font>
      </time>
    </span>
</section>
<!-- paper0: Hyperspectral Image Classification with Spatial Consistence Using Fully
  Convolutional Spatial Propagation Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_73.html">
      <font color="black">Hyperspectral Image Classification with Spatial Consistence Using Fully
  Convolutional Spatial Propagation Network</font>
    </a>
  </h2>
  <font color="black">最後に、CSPNが導入され、HSIの空間相関を取得することにより、HSIの空間的整合性を維持し、分類結果をさらに洗練させます。具体的には、信頼性の高い予備的な分類のために3D-FCNが最初に導入されました。新しいデュアル分離可能残差（DSR）ユニットが提案されており、少ないパラメーターで同時にスペクトルおよび空間情報を効果的にキャプチャします。このパッチレベルの分類は、多数の繰り返し計算につながり、適切なパッチを決定することは困難です。分類精度に有益なサイズ。 
[ABSTRACT]既存のcnnベースのモデルは、パッチレベルで動作します。この場合、ピクセルは、周囲の画像のパッチを使用してクラスに分類されます。これらは、6つの画像のパッチを含み、次にクラスに分類されます。これらは畳み込みです局所空間情報を使用して、コンテキスト空間情報のモデリングに失敗を引き起こします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Cylinder3D: An Effective 3D Framework for Driving-scene LiDAR Semantic
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_74.html">
      <font color="black">Cylinder3D: An Effective 3D Framework for Driving-scene LiDAR Semantic
  Segmentation</font>
    </a>
  </h2>
  <font color="black">この作業では、最初に2Dおよび3D空間のさまざまな表現とバックボーンについて詳細な分析を実行し、LiDARセグメンテーションにおける3D表現とネットワークの有効性を明らかにします。次に、3Dシリンダーパーティションと3Dシリンダーコンボリューションを開発します。 Cylinder3Dと呼ばれるフレームワークに基づいており、3Dトポロジの関係と運転シーンの点群の構造を利用します。このプロセスにより、点群は2D CNNベースのネットワークに適したものになりますが、3Dトポロジと幾何学的関係は必然的に変更および破棄されます。 。 
[要約]この方法は、3dモデルを使用して3d 3d 3dモデルを処理することを含みます。この方法は、成功している3dモデルモデルモデルに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Neuromorphic Computing for Content-based Image Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_75.html">
      <font color="black">Neuromorphic Computing for Content-based Image Retrieval</font>
    </a>
  </h2>
  <font color="black">ここでは、画像検索のコンピュータービジョンタスクへのIntelが開発したニューロモーフィックコンピューティングチップであるLoihiのアプリケーションについて説明します。多くの機械学習タスクでは、ニューロモーフィックチップはコストと電力効率の点で優れたソリューションを提供することが期待されます。ニューロモーフィックソリューションは、Intel Core i7 CPUと比較してエネルギー効率が約3.2倍、Nvidia T4 GPUと比較して12.5倍エネルギー効率が高いことを示しています。マッチング精度の。 
[要約]この研究は、機械学習におけるニューロモーフィックコンピューティングの長期的な可能性を検証します。ニューロモーフィックエネルギーの長期的な可能性を検証します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: 1st Place Solutions of Waymo Open Dataset Challenge 2020 -- 2D Object
  Detection Track -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_76.html">
      <font color="black">1st Place Solutions of Waymo Open Dataset Challenge 2020 -- 2D Object
  Detection Track</font>
    </a>
  </h2>
  <font color="black">私たちの手法を使用して、チームRW-TSDetは2Dオブジェクト検出トラックで1位を獲得しました。このテクニカルレポートでは、Waymo Open Dataset（WOD）チャレンジ2020-2Dオブジェクトトラックのソリューションを紹介します。 WODの小さなオブジェクトの検出の問題では、トレーニングとテストの両方に非常に大きな画像スケールを使用しています。 
[要約] wodでの小さなオブジェクトの検出問題を処理するために、トレーニングとテストに大きな画像スケールを使用します。非常に大きなオブジェクトスケールを使用してカメラを追跡します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Boundary Content Graph Neural Network for Temporal Action Proposal
  Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_77.html">
      <font color="black">Boundary Content Graph Neural Network for Temporal Action Proposal
  Generation</font>
    </a>
  </h2>
  <font color="black">時間アクション提案の生成は、高品質のアクションコンテンツを正確にローカライズする必要のあるビデオアクションの理解に重要な役割を果たします。この問題に対処するために、私たちは、グラフニューラルネットワークによる時間提案の境界とアクションコンテンツ。ただし、正確な境界と高品質のアクションコンテンツの両方を使用して時間提案を生成することは非常に困難です。 
[ABSTRACT]提案の境界とコンテンツは、それぞれグラフニューラルネットワークのコンテンツと見なされ、そこで自然にリンクされます。その後、1つの更新されたエッジとそれが接続する2つのノードを使用して、どのポイントが予測されます。結果は結合されます最終的な高品質の提案を生成する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Active Object Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_78.html">
      <font color="black">Active Object Search</font>
    </a>
  </h2>
  <font color="black">この作業では、文献で明示的に取り上げられていないアクティブオブジェクト検索（AOS）タスクを調査します。 3D屋内シーンでターゲットオブジェクトを検索して特定するために、できるだけ少ないアクションステップをアクティブに実行することを目的としています。この新しいタスクを評価するために、30のさまざまな屋内シーンからの5,845サンプルを含むアクティブオブジェクト検索（AOS）ベンチマークを作成します..このクロスモーダルタスクを処理するために、3Dオブジェクト検出器、状態コントローラー、およびクロスモーダルアクションプランナーで構成される強化学習フレームワークを作成し、最小限のアクションステップで協力してターゲットオブジェクトを見つけます。 
[ABSTRACT]タスクは、合理的なアクションプランニングを通じてインテリジェントエージェントがアクティブな検索を実行することを奨励します。特に、ターゲットがエージェントから遠く、障害物によってブロックされて見えないという困難な状況では、ターゲットオブジェクトをよりよく思い出すことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-03">
        <br><font color="black">2020-08-03</font>
      </time>
    </span>
</section>
<!-- paper0: Preliminary Forensics Analysis of DeepFake Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_79.html">
      <font color="black">Preliminary Forensics Analysis of DeepFake Images</font>
    </a>
  </h2>
  <font color="black">標準的な方法によるこれらの画像のフォレンジック分析が提示されます。驚くことではないが、最新の技術では偽物を完全に検出することはできません。現在、最も恐ろしい現象の1つは、DeepFakeです。人物の顔を自動的に置き換える可能性これを解決するために、周波数領域の異常を分析して、顔のDeepFake画像と戦う方法に関する予備的なアイデアを提示します。 
[ABSTRACT]周波数領域の異常を分析することで、顔のディープフェイク画像が表示されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br><font color="black">2020-04-27</font>
      </time>
    </span>
</section>
<!-- paper0: Appearance Consensus Driven Self-Supervised Human Mesh Recovery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_80.html">
      <font color="black">Appearance Consensus Driven Self-Supervised Human Mesh Recovery</font>
    </a>
  </h2>
  <font color="black">フォアグラウンド（FG）の人間を効果的に解きほぐすために、ラベルの付いていない野生のビデオから得られたさまざまなポーズと背景（BG）で同じ人物（一貫性のあるFG）を描いた画像ペアに依存します。提案されたFG外観の一貫性の目的は、新しい、外観ネットワークを必要とせずに頂点カラーを取得するための、区別可能なカラー回復モジュール。色を選ぶことと反射の対称性を効率的に実現します。これを認めて、私たちは新しい外観のコンセンサス主導の自己監視対物レンズを提案します。 
[ABSTRACT]提案された人間の外観の一貫性のあるシェイプの一貫性のあるシェイプ。新しい、差別化可能な色-回復モジュールを使用します。結果のカラーメッシュ予測は、さまざまな外観のフレームワークの使用を開きます-ポーズやシェイプの推定以外の関連タスク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Tracking Skin Colour and Wrinkle Changes During Cosmetic Product Trials
  Using Smartphone Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_81.html">
      <font color="black">Tracking Skin Colour and Wrinkle Changes During Cosmetic Product Trials
  Using Smartphone Images</font>
    </a>
  </h2>
  <font color="black">さらに、彼らはそれぞれ、試用期間を通して定期的に撮影された自分の顔の同じ領域の「自分撮り」を持っていました。結論：試用期間内に自分撮りスマートフォンの画像を定期的に使用すると、試用の有効性の解釈に付加価値をもたらす..結果：トライアルの開始時と終了時に撮影された画像は、スマートフォン画像の正規化のベースラインのグラウンドトゥルースとして機能し、多くのボランティアのトライアル中に色としわの大きさの両方に大きな変化を示しました。 
[要旨] 30歳から60歳の12人の女性が製品試験に参加しました。彼らの顔の頬とこめかみの領域の拡大画像が、最初と最後に高解像度のアンテラ3d csカメラで撮影されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervised Knowledge Distillation for Few-shot Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_82.html">
      <font color="black">Self-supervised Knowledge Distillation for Few-shot Learning</font>
    </a>
  </h2>
  <font color="black">2段階の学習プロセスに従います。最初に、特徴埋め込みのエントロピーを最大化するようにニューラルネットワークをトレーニングし、自己監視補助損失を使用して最適な出力多様体を作成します。2番目の段階では、エントロピーを最小化します。生徒の教師による蒸留でマニホールドを制約しながら、自己監視の双子をまとめることで埋め込み機能を実装します。当社のコードはhttps://github.com/brjathu/SKDで入手できます。 
[ABSTRACT]少数のサンプル学習で順不同に学習する能力があるため、少数のショット学習は有望な学習ツールです。これらには、生徒と教師の蒸留でマニホールドを制約しながら、教師付き双子をまとめることが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br><font color="black">2020-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: Controlling Information Capacity of Binary Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_83.html">
      <font color="black">Controlling Information Capacity of Binary Neural Network</font>
    </a>
  </h2>
  <font color="black">バイナリ畳み込みネットワークはこれらの問題を緩和できますが、重みのビット幅が限られているため、予測精度が大幅に低下することがよくあります。ディープラーニングテクノロジーの人気が高まっているにもかかわらず、高いメモリ要件と電力消費により、モバイルおよびIoT領域でのアプリケーションが本質的に制限されています。 ..このホワイトペーパーでは、シャノンエントロピーベースのペナルティを畳み込みフィルターに適用することにより、トレーニングプロセス全体で情報容量の安定した事前定義レベルを維持するバイナリネットワークのトレーニング方法を紹介します。 
[要約]提案されたアプローチはモバイルネットワークの精度を向上させるのに役立ちますが、重みのビット幅が制限されているため、予測精度が大幅に低下することがよくあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Kinship Identification through Joint Learning Using Kinship Verification
  Ensembles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CV/paper_84.html">
      <font color="black">Kinship Identification through Joint Learning Using Kinship Verification
  Ensembles</font>
    </a>
  </h2>
  <font color="black">既存の検証ネットワークは特定の親族で個別にトレーニングされ、異なる親族タイプ間のコンテキストを考慮しないため、親族検証の拡張機能は不足し、識別を適切に取得できません。トレーニングデータセットを再調整して、より現実的になるようにします。大規模な実験親族の身分証明に関する魅力的なパフォーマンスを示します。 
[要約]検証ネットワークは、特定の血族関係で個別にトレーニングされます。既存の検証ネットワークは、異なる品種間のコンテキストを考慮していません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-14">
        <br><font color="black">2020-04-14</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: NLPDove at SemEval-2020 Task 12: Improving Offensive Language Detection
  with Cross-lingual Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CL/paper_0.html">
      <font color="black">NLPDove at SemEval-2020 Task 12: Improving Offensive Language Detection
  with Cross-lingual Transfer</font>
    </a>
  </h2>
  <font color="black">また、ソーシャルメディアのテキストに合わせて調整されたさまざまな前処理手順と、攻撃的な言語識別のために事前に訓練された多言語BERT（mBERT）を微調整する方法を紹介します。半教師付きデータセットを活用すると、私たちの多言語システムは、OffensEval 2020でギリシャ語、デンマーク語、トルコ語で競争力のある結果を達成しました。
[要約]私たちの多言語システムは、offenseEval 2020でギリシャ語、デンマーク語、トルコ語で競争力のある結果を達成しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: An improved Bayesian TRIE based model for SMS text normalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CL/paper_1.html">
      <font color="black">An improved Bayesian TRIE based model for SMS text normalization</font>
    </a>
  </h2>
  <font color="black">提案されたトライの統計特性に関する2つの定理を証明し、それを使用して、単語の出現確率の不偏で一貫した推定量であると主張します。SMSテキストの正規化は、一般にテキストメッセージ言語として知られていますが、 10年..さらに、ノイズの多いチャネルベースのエラー訂正のパラダイムにモデルを融合し、ダメラウレーベンシュタイン距離1を超えるヒューリスティックを提供します。 
[要約]トライのデータ構造に基づく確率論的アプローチが文献で提案されました。テレベースのシミュレーションよりもパフォーマンスが優れていることがわかりました。これらには、既存のトライベースのモデルに対する構造変更が含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Comparative Analysis of N-gram Text Representation on Igbo Text Document
  Similarity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CL/paper_2.html">
      <font color="black">Comparative Analysis of N-gram Text Representation on Igbo Text Document
  Similarity</font>
    </a>
  </h2>
  <font color="black">2つのドキュメントの類似性は、距離の値がゼロ（0）に下がるにつれて増加します。このホワイトペーパーでは、Igboテキストドキュメントの類似性に関するn-gramテキスト表現の比較分析を紹介します。バイグラムは対応する距離の値が最も低くなります。 
[ABSTRACT] igboテキストドキュメントは、2つの単語ベースのn-gramテキスト表現（ユニグラムとバイグラム）モデルで表されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-01">
        <br><font color="black">2020-04-01</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Wait-k Models for Simultaneous Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CL/paper_3.html">
      <font color="black">Efficient Wait-k Models for Simultaneous Machine Translation</font>
    </a>
  </h2>
  <font color="black">一方向エンコーダーを使用したこれらのモデルのトレーニング、およびkの複数の値にわたるトレーニングを改善します。 Transformerと2Dたたみ込みアーキテクチャの実験では、待機kモデルが幅広いレイテンシレベルで一般化されていることを示しています。最初にk個のソーストークンを読み取り、その後、ターゲットトークンの生成と別のソーストークンの読み取りを交互に行います。また、2Dコンボリューションアーキテクチャは、話し言葉の同時翻訳に関してトランスフォーマーと競争力があることも示しています。 
[ABSTRACT] iwsltデータセットを使用して、音声コーパスの低リソース設定で待機-kデコードの動作を調査します。2d-畳み込みアーキテクチャは、音声言語の同時翻訳のトランスフォーマーと競合することも示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-18">
        <br><font color="black">2020-05-18</font>
      </time>
    </span>
</section>
<!-- paper0: SARG: A Novel Semi Autoregressive Generator for Multi-turn Incomplete
  Utterance Restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CL/paper_4.html">
      <font color="black">SARG: A Novel Semi Autoregressive Generator for Multi-turn Incomplete
  Utterance Restoration</font>
    </a>
  </h2>
  <font color="black">タスクでは、生成の自己回帰と重複した書き換えのシーケンスのラベル付けに触発された、高効率と柔軟性を備えた新しい半自己回帰ジェネレーター（SARG）を提案します。さらに、\ textit {Restoration-200k}の実験提案されたモデルは、推論速度が速く、最先端のモデルを大幅に上回っています。オープンドメインの対話システムは、大規模な会話データとディープラーニングの開発により大きな成功を収めていますが、マルチターンシステムはしばしば頻繁な相互参照と情報の省略により制限されています。 
[ABSTRACT]プロジェクトにより、異なるドメインのマルチターン対話システムに改善がもたらされました。プロジェクトの実験では、大規模なシステムのパフォーマンスが大幅に優れていることが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Prompt Agnostic Essay Scorer: A Domain Generalization Approach to
  Cross-prompt Automated Essay Scoring -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CL/paper_5.html">
      <font color="black">Prompt Agnostic Essay Scorer: A Domain Generalization Approach to
  Cross-prompt Automated Essay Scoring</font>
    </a>
  </h2>
  <font color="black">PAESは実際に簡単に適用でき、自動学生評価賞（ASAP）データセットで最先端のパフォーマンスを実現します。プロンプト固有のAES用に設計されたモデルは、プロンプト固有の知識に大きく依存しており、クロスでのパフォーマンスは低いです。プロンプト設定AESへの現在のアプローチは、ラベル付きターゲットプロンプトエッセイを一定量必要とするか、マルチステップ方式で転移学習を実行するためにラベルなしターゲットプロンプトエッセイを大量に必要とします。これらの問題に対処するには、クロスプロンプトAES用のプロンプト不可知論エッセイスコアラー（PAES）を紹介します。 
[ABSTRACT]クロスプロンプトaesのタスクは、実世界のaesシステムの開発に不可欠です。このシステムでは、特定のプロンプトをターゲットにするにはエッセイスコアラー（非現実的）が必要です。メソッドは「非現実的」と呼ばれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: TextCaps: a Dataset for Image Captioning with Reading Comprehension -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CL/paper_6.html">
      <font color="black">TextCaps: a Dataset for Image Captioning with Reading Comprehension</font>
    </a>
  </h2>
  <font color="black">画像の説明は、視覚障害者が画像コンテンツをすばやく理解するのに役立ちます。このデータセットは、モデルにテキストを認識させ、その視覚的コンテキストに関連付け、コピーまたは言い換えるテキストのどの部分を決定するかを決定します。空間的、意味的、視覚的な要素が必要です複数のテキストトークンとオブジェクトなどの視覚エンティティとの間の推論。ベースラインを調査し、既存のアプローチをこの新しいタスクに適用します。これは、読解機能付きの画像キャプションと呼ばれます。 
[ABSTRACT]データセットは、モデルにテキストを認識させ、その視覚的コンテキストに関連付け、コピーまたは言い換えるテキストの部分を決定します。新しいtextcapsデータセットは、以前のデータセットに対して多くの新しい技術的課題を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-24">
        <br><font color="black">2020-03-24</font>
      </time>
    </span>
</section>
<!-- paper0: Paying Per-label Attention for Multi-label Extraction from Radiology
  Reports -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CL/paper_7.html">
      <font color="black">Paying Per-label Attention for Multi-label Extraction from Radiology
  Reports</font>
    </a>
  </h2>
  <font color="black">画像には多くの場合、豊富な情報源であるフリーテキストの放射線医学レポートが含まれます。高密度。）臨床的印象（たとえば、前の研究から着想を得て、既存の最先端のニューラルネットワークモデルをラベルで拡張します）依存注意メカニズム。
[ABSTRACT]画像には、フリーテキストの放射線医学レポートが添付されていることがよくあります。これらには、神経学的異常に関連する放射線レポートが含まれます。このメカニズムと単純な合成データ拡張を使用すると、分類された単一のモデルで多くのラベルを抽出できます。放射線科医の報告によると</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-31">
        <br><font color="black">2020-07-31</font>
      </time>
    </span>
</section>
<!-- paper0: Reed at SemEval-2020 Task 9: Fine-Tuning and Bag-of-Words Approaches to
  Code-Mixed Sentiment Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CL/paper_8.html">
      <font color="black">Reed at SemEval-2020 Task 9: Fine-Tuning and Bag-of-Words Approaches to
  Code-Mixed Sentiment Analysis</font>
    </a>
  </h2>
  <font color="black">コンテストの評価段階で、最高のモデルで71.3％のFスコアを獲得しました。これにより、公式システムランキングの62エントリのうち$ 4 ^ {th} $が配置されました。Hinglishの感情分析のタスクを探索します（コード混合ヒンディー語-英語）SentiEix-2020コンテストとして知られるSemEval-2020コンテストのタスク9の参加者としてツイートします。2つの主要なアプローチがありました。1）事前トレーニング済みBERTモデルを微調整することによる転移学習の適用と2 ）bag-of-words表現に関するフィードフォワードニューラルネットワークのトレーニング。 
[要約]転移学習の研究には2つの主要なアプローチがありました。また、バッグのフィードフォワードニューラルネットワークをトレーニングする必要がありました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-26">
        <br><font color="black">2020-07-26</font>
      </time>
    </span>
</section>
<!-- paper0: A Survey of Orthographic Information in Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CL/paper_9.html">
      <font color="black">A Survey of Orthographic Information in Machine Translation</font>
    </a>
  </h2>
  <font color="black">これらの機械翻訳システムの広範で根本的な問題は、従来のアプローチに多くの問題を引き起こす正書法のバリエーションです。この領域での以前の研究を説明し、どのような根本的な仮定が行われたかを議論し、正書法の知識が機械のパフォーマンスを向上させる方法を示します。リソース不足の言語の翻訳。さまざまな種類の機械翻訳について説明し、正書法の情報と確立された機械翻訳方法とのリンクを求める最近の傾向を示します。 
[ABSTRACT]研究では、正字法情報を使用して機械翻訳システムを改善する方法を示しています。これは、正書法情報を使用して機械翻訳を改善する方法を説明しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Taking Notes on the Fly Helps BERT Pre-training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CL/paper_10.html">
      <font color="black">Taking Notes on the Fly Helps BERT Pre-training</font>
    </a>
  </h2>
  <font color="black">TNFは、事前トレーニング中にレアワードをオンザフライでメモし、次回の発生時にモデルがそれらを理解できるようにします。この問題を解決するために、テイクオンザフライ（TNF）を提案します。具体的には、TNFはメモ辞書を維持していますレアワードが文に出現したときに、レアワードのコンテキスト情報をメモとして保存します。 
[ABSTRACT]まれな単語の埋め込みは通常不十分に最適化されています。これらはデータ使用を非効率にし、モデル全体の事前トレーニングを遅くする可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Weakly Supervised Construction of ASR Systems with Massive Video Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CL/paper_11.html">
      <font color="black">Weakly Supervised Construction of ASR Systems with Massive Video Data</font>
    </a>
  </h2>
  <font color="black">基礎となるASRモデルを微調整して、弱く監視された事前トレーニング後に、ドメイン固有のターゲットトレーニングデータセットに適合させることができます。広範な実験により、私たちのフレームワークはマンダリン音声用の6つのパブリックデータセットで最先端の結果を簡単に生成できることが示されています認識..自動音声認識（ASR）システムを最初から構築することは非常に困難です。これは主に、大量の音声データに筆記録を注釈するために時間と費用がかかるプロセスが原因です。 
[ABSTRACT]現在、教師なしの事前トレーニングモデルがいくつかあります。これらには教師なしの事前トレーニングモデルが含まれますが、より多くのラベル付けされたトレーニングデータを大きなコストなしで取得できる場合、これらは依然として最適ではない可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: A Survey on Text Classification: From Shallow to Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CL/paper_12.html">
      <font color="black">A Survey on Text Classification: From Shallow to Deep Learning</font>
    </a>
  </h2>
  <font color="black">次に、予測のテストをサポートする技術開発とベンチマークデータセットの両方を扱い、これらの各カテゴリについて詳細に説明します。関係するテキストと、特徴の抽出と分類に使用されるモデルに従って、テキスト分類の分類法を作成します。Aこの調査では、さまざまな手法の包括的な比較や、さまざまな評価指標の長所と短所の特定も行っています。 
[要約]このペーパーは、1961年から2020年までの最新のアプローチをレビューすることでギャップを埋めます。包括的なモデルからディープラーニングまでのモデルに焦点を当てます。次に、重要な意味、将来の研究の方向性、および研究領域が直面する課題を要約して結論を出します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-02">
        <br><font color="black">2020-08-02</font>
      </time>
    </span>
</section>
<!-- paper0: Domain-Specific Language Model Pretraining for Biomedical Natural
  Language Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CL/paper_13.html">
      <font color="black">Domain-Specific Language Model Pretraining for Biomedical Natural
  Language Processing</font>
    </a>
  </h2>
  <font color="black">さらに、事前トレーニングとタスク固有の微調整の両方について、モデリングの選択を徹底的に評価すると、名前付きエンティティ認識（NER）で複雑なタグ付けスキームを使用するなど、BERTモデルでは一般的なプラクティスが不要であることがわかります。 、ほとんどの事前トレーニングの取り組みは、ニュースワイヤーやWebなどの一般的なドメインコーパスに焦点を当てています。この調査を容易にするために、公開されているデータセットから包括的な生物医学NLPベンチマークをまとめます。 
[要旨]ラベルのないテキストのあるドメインでは、言語モデルを最初から事前トレーニングすることで大幅な向上が得られることを示すことで、この仮定に挑戦します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-31">
        <br><font color="black">2020-07-31</font>
      </time>
    </span>
</section>
<!-- paper0: "This is Houston. Say again, please". The Behavox system for the
  Apollo-11 Fearless Steps Challenge (phase II) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CL/paper_14.html">
      <font color="black">"This is Houston. Say again, please". The Behavox system for the
  Apollo-11 Fearless Steps Challenge (phase II)</font>
    </a>
  </h2>
  <font color="black">すべてのシステムについて、FSC-2ベースラインシステムと比較して大幅なパフォーマンスの向上を報告し、チャレンジでSDおよびASRの1位とSADの4位を達成しました。比較的少量のラベル付きデータ、大きなさまざまなスピーカーとチャンネルの歪み、特定の辞書とスピーチスタイルにより、このデータを含むシステムでエラー率が高くなりました。約36時間の注釈付きNASAミッション録音に加えて、主催者ははるかに大きいがラベルのない19k時間のアポロFSR-2データのみのトレーニングと比較して17％以上の相対ワードエラー率の改善を観察し、ASR音響および言語モデルの半教師ありトレーニングについても調査する11のコーパス。 
[要約]いくつかの悲しいシステムとsdシステムを比較して、課題の最も難しいトラックをテストします。これらには、評価のために30分の長いオーディオ録音が提供されるダイアライゼーションとasrが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: On Learning Universal Representations Across Languages -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CL/paper_15.html">
      <font color="black">On Learning Universal Representations Across Languages</font>
    </a>
  </h2>
  <font color="black">GLUEベンチマークでの言語理解タスク（QQP、QNLI、SST-2、MRPC、STS-B、MNLI）、クロスリンガル自然言語推論（XNLI）、および機械翻訳の3つのベンチマークで評価を行います。実験結果は、 HiCTLは、GLUE / XNLIで1.0％/ 2.2％の絶対精度を獲得し、強力なベースラインを超える高リソースおよび低リソースの英語からXへの翻訳タスクで+ 1.7- + 3.6 BLEUの大幅な改善を実現します..この作業では、これらのアプローチを拡張して文レベルの表現を学習し、言語間の理解と生成に対する有効性を示します。 
[ABSTRACT]以前のアプローチは基本的にトークン間の共起をキャプチャしますが、hictlはparallelualsの普遍的な表現を学習できます。共有のクロスからクロスリンガルの単語を区別することが可能です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-31">
        <br><font color="black">2020-07-31</font>
      </time>
    </span>
</section>
<!-- paper0: Reliable Part-of-Speech Tagging of Historical Corpora through Set-Valued
  Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CL/paper_16.html">
      <font color="black">Reliable Part-of-Speech Tagging of Historical Corpora through Set-Valued
  Prediction</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、POSタグ付けを検討します。これにより、POSタガーは単一のタグを推測するのではなく、候補POSタグのセットを予測することで不確実性を表現できます。これらの不規則性により、自動POSのタスクがレンダリングされます。タグ付けはより難しく、エラーが発生しやすくなります。POSタグ付けの問題は基本的に現代の言語では解決されたと見なすことができますが、特にネイティブスピーカーがなく、トレーニングデータが少ないため、歴史的コーパスははるかに困難であることがわかります。 
[ABSTRACT]問題は通常、機械学習の方法を使用して対処されます。postaggerに自然なタグを予測してコミットさせるのではなく、不確実性を表現できるはずです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-supervised Learning for Multi-speaker Text-to-speech Synthesis
  Using Discrete Speech Representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/cs.CL/paper_17.html">
      <font color="black">Semi-supervised Learning for Multi-speaker Text-to-speech Synthesis
  Using Discrete Speech Representation</font>
    </a>
  </h2>
  <font color="black">さらに、私たちの分析は、ペアのデータの異なる話者特性が半教師ありTTSの有効性に影響を与えることを明らかにしています。実験結果は、ペアのデータが複数の話者からのものであっても、1時間のペアの音声データだけでまたは単一の話者の場合、提案されたモデルは、さまざまな声でわかりやすいスピーチを生成できます。最近、エンドツーエンドのマルチスピーカーのテキスト読み上げ（TTS）システムは、多くの高品質のスピーチに加えて、対応する文字起こしが利用可能です。 
[要約]マルチスピーカーTTSモデルは、提案されたエンコーダー-単一の音声表現を備えたデコーダーフレームワークを介して、文字起こしされていないオーディオから学習できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-16">
        <br><font color="black">2020-05-16</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: MIRNet: Learning Multiple Identity Representations in Overlapped Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.AS/paper_0.html">
      <font color="black">MIRNet: Learning Multiple Identity Representations in Overlapped Speech</font>
    </a>
  </h2>
  <font color="black">提案手法により得られた対象話者の埋め込みを条件とする話者検証タスクおよび音声分離システムにおけるアルゴリズムの有効性を実証します。この論文では、複数の話者のアイデンティティを確実に抽出できる新規の深い話者表現戦略を提案します。重複した音声..私たちは、与えられた混合物から各話者の識別情報を含む高レベルの埋め込みを抽出できるネットワークを設計します。 
[ABSTRACT]特定の混合物から各話者の識別情報を含む高レベルの埋め込みを抽出することを計画します。音声信号に複数の同時発話者がいる場合、識別するのは困難です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Wait-k Models for Simultaneous Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.AS/paper_1.html">
      <font color="black">Efficient Wait-k Models for Simultaneous Machine Translation</font>
    </a>
  </h2>
  <font color="black">一方向エンコーダーを使用したこれらのモデルのトレーニング、およびkの複数の値にわたるトレーニングを改善します。トランスフォーマーと2Dたたみ込みアーキテクチャの実験により、待機kモデルが幅広いレイテンシレベルで一般化されていることがわかります。IWSLTデータセットを使用して、コーパスの低リソース設定で待機kデコードの動作を調査します。また、 2D畳み込みアーキテクチャは、話し言葉の同時翻訳に関してトランスフォーマーと競争力があること。 
[ABSTRACT] iwsltデータセットを使用して、音声コーパスの低リソース設定で待機-kデコードの動作を調査します。2d-畳み込みアーキテクチャは、音声言語の同時翻訳のトランスフォーマーと競合することも示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-18">
        <br><font color="black">2020-05-18</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Granular Sound Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.AS/paper_2.html">
      <font color="black">Neural Granular Sound Synthesis</font>
    </a>
  </h2>
  <font color="black">モデルは、ピッチのあるノートやピッチのないドラム、環境ノイズなど、さまざまなタイプのライブラリに適用できます。オーディオ記述子の基礎を、変分オートエンコーダで学習した確率的潜在空間に効率的に置き換えます。これにより、何らかの形を反映した表現が提供されます。穀物全体の局所的な類似性の。 
[ABSTRACT]グラニュラーシンセシスは、サウンドを制御するために使用するようにプログラムできます。ただし、このグレインスペースの品質は、ディスクリプターの品質によって制限されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Timbre latent space: exploration and creative aspects -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.AS/paper_3.html">
      <font color="black">Timbre latent space: exploration and creative aspects</font>
    </a>
  </h2>
  <font color="black">あるいは、教師なしの次元が残りの機能を考慮に入れている間、いくつかの特定の音響属性を制御変数として学習できます。追加の知覚的正則化を使用すると、そのような潜在表現を以前に確立された多次元音色空間に揃えることができ、連続的な推論と合成が可能になります。生成とニューラルネットワークにより、音色操作の新しい可能性が可能になりますが、それらの表現の探索と創造的な使用はほとんどありません。 
[ABSTRACT]潜在スペースは音色のプロパティを解き放ちません。疑いのない音色操作の新しい可能性が有効になります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Segment Aggregation for short utterances speaker verification using raw
  waveforms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.AS/paper_4.html">
      <font color="black">Segment Aggregation for short utterances speaker verification using raw
  waveforms</font>
    </a>
  </h2>
  <font color="black">本論文では、「セグメント集約」と呼ばれる短い発話に対する話者検証の性能劣化を補償する方法を提案する。話者検証システムに関するほとんどの研究は、十分な音声情報で構成される長時間の発話に焦点を当てている..提案された方法は、入力発話をいくつかの短い発話にセグメント化し、次に、セグメント化された入力から抽出されたセグメント埋め込みを集約して、スピーカー埋め込みを構成します。 
[要約]提案された方法は、アンサンブルベースの設計を使用して話者検証システムの精度を向上させます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br><font color="black">2020-05-07</font>
      </time>
    </span>
</section>
<!-- paper0: Signal-Adaptive and Perceptually Optimized Sound Zones with Variable
  Span Trade-Off Filters -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.AS/paper_5.html">
      <font color="black">Signal-Adaptive and Perceptually Optimized Sound Zones with Variable
  Span Trade-Off Filters</font>
    </a>
  </h2>
  <font color="black">サウンドゾーンの作成は、アイデアが最初に提案されて以来、活発な研究分野でした。提案された方法は、音響コントラストなどの物理メトリックとSTOIなどの知覚メトリックに基づいて評価されています。漏れエラーの整形は、時間をかけて実行されます。 -スピーカー制御フィルターが計算されるとき、入力信号特性と人間の聴覚システムを考慮に入れて変化させます。 
[要約]提案された方法は、既存のサウンドゾーン制御方法と比較して、20％以上の知覚改善を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-22">
        <br><font color="black">2019-11-22</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Composition of Guitar Tabs by Transformers and Groove Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.AS/paper_6.html">
      <font color="black">Automatic Composition of Guitar Tabs by Transformers and Groove Modeling</font>
    </a>
  </h2>
  <font color="black">2つ目は、指のスタイルのギター音楽に欠かせない、一貫したリズミカルなグルーヴのある楽曲を生成するかどうかです。1つ目は、ニューラルネットが意味のある音符と文字列の組み合わせを含む音符シーケンスを生成するかどうかです。そして最後に、作曲された音楽は、実際の人間が作った作品と比べてどれほど楽しいか。 
[ABSTRACT]このモデルは、タブ構成のディープラーニングの可能性を示す予備的な証拠を提供し、将来の研究の領域を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Weakly Supervised Construction of ASR Systems with Massive Video Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.AS/paper_7.html">
      <font color="black">Weakly Supervised Construction of ASR Systems with Massive Video Data</font>
    </a>
  </h2>
  <font color="black">大規模な実験により、私たちのフレームワークはマンダリンの音声認識用の6つの公開データセットで最先端の結果を簡単に生成できることが示されています。基礎となるASRモデルは、事前に弱く監視された後、ドメイン固有のターゲットトレーニングデータセットに合わせて微調整できますトレーニング..多くの場合、動画には字幕に合わせて人間の音声が含まれるため、動画を重要な知識ソースと見なし、光学式文字認識（OCR）に基づいて動画からトランスクリプトに合わせて高品質の音声を抽出する効果的なアプローチを提案します。 
[ABSTRACT]現在、教師なしの事前トレーニングモデルがいくつかあります。これらには教師なしの事前トレーニングモデルが含まれますが、より多くのラベル付けされたトレーニングデータを大きなコストなしで取得できる場合、これらは依然として最適ではない可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: The Jazz Transformer on the Front Line: Exploring the Shortcomings of
  AI-composed Music through Quantitative Measures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.AS/paper_8.html">
      <font color="black">The Jazz Transformer on the Front Line: Exploring the Shortcomings of
  AI-composed Music through Quantitative Measures</font>
    </a>
  </h2>
  <font color="black">これには、ピッチクラス、グルービング、コード進行の統計の分析、フィットネススケーププロットの助けを借りて音楽の構造を評価すること、およびMIREXのような継続予測タスクを通じてモデルのジャズ音楽の理解を評価することが含まれます。トレーニングロスを低い値に減らすことができます。ただし、リスニングテストでは、生成された楽曲と実際の楽曲の平均評価の間に明確なギャップがあることが示唆されています。人間性のアートワークの、そしてさらに追求するために自動合成の将来の仕事のためのいくつかの目標を設定します。 
[ABSTRACT] modelは、生成された音楽に構造を誘導するために、weimarジャズデータベース（wjazzd）に存在する構造イベントを組み込むことを目指しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Intra-class variation reduction of speaker representation in
  disentanglement framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.AS/paper_9.html">
      <font color="black">Intra-class variation reduction of speaker representation in
  disentanglement framework</font>
    </a>
  </h2>
  <font color="black">スピーカーに関連する表現とスピーカーに関連しない表現の両方を生成するようにネットワークアーキテクチャを変更することにより、これらの絡み合っていない埋め込み間の相互情報を最小化する学習基準を活用します。提案された基準は、バックグラウンドの変化によって引き起こされるスピーカー特性の変動を減らすため、環境または話された内容、各スピーカーの結果として生じる埋め込みはより一貫性のあるものになります。同じ話者によって話された異なる発話に対して再構成エラーを利用するアイデンティティ変更損失基準も導入します。 
[要約]効果的な方法は、話者の特性情報のみを含む潜在的な表現または埋め込みを学習することです。提案された方法の有効性は、解きほぐしのパフォーマンスと話者認識の精度の向上という2つのタスクで示されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Music SketchNet: Controllable Music Generation via Factorized
  Representations of Pitch and Rhythm -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.AS/paper_10.html">
      <font color="black">Music SketchNet: Controllable Music Generation via Factorized
  Representations of Pitch and Rhythm</font>
    </a>
  </h2>
  <font color="black">アイルランドの民俗音楽の標準データセットでSketchNetを評価し、最近の作品のモデルと比較します。最初に、リズムとピッチの輪郭を明確に因数分解して提案モデルの基礎を形成する新しい変分オートエンコーダSketchVAEを紹介します。自動画像補完システムでは、ユーザーが自動音楽生成を導く部分的な音楽のアイデアを指定できるニューラルネットワークフレームワークであるMusic SketchNetを提案します。 
[ABSTRACT]私たちのアプローチは、客観的な測定基準と主観的なリスニングテストの両方の面で、最先端の技術を上回っています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: "This is Houston. Say again, please". The Behavox system for the
  Apollo-11 Fearless Steps Challenge (phase II) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.AS/paper_11.html">
      <font color="black">"This is Houston. Say again, please". The Behavox system for the
  Apollo-11 Fearless Steps Challenge (phase II)</font>
    </a>
  </h2>
  <font color="black">すべてのシステムで、FSC-2ベースラインシステムと比較して大幅なパフォーマンスの改善を報告し、チャレンジでSDおよびASRの1位とSADの4位を達成しました。約36時間の注釈付きNASAミッションに加えて記録では、主催者ははるかに大きいがラベルのない1万9千時間のApollo-11コーパスを提供しました。これは、FSR-2でのトレーニングと比較して17％を超える相対単語エラー率の改善を観察しながら、ASR音響および言語モデルの半教師付きトレーニングについても調査します。データのみ。Interspeech2020 Fearless Steps Challenge（FSC-2）のBehavoxチームが実施した音声アクティビティ検出（SAD）、話者ダイアライゼーション（SD）、および自動音声認識（ASR）実験について説明します。 
[要約]いくつかの悲しいシステムとsdシステムを比較して、課題の最も難しいトラックをテストします。これらには、評価のために30分の長いオーディオ録音が提供されるダイアライゼーションとasrが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Expressive TTS Training with Frame and Style Reconstruction Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.AS/paper_12.html">
      <font color="black">Expressive TTS Training with Frame and Style Reconstruction Loss</font>
    </a>
  </h2>
  <font color="black">私たちの知る限り、これは発話レベルの知覚品質を損失関数としてタコトロンのトレーニングに組み込んで表現力を向上させる最初の研究です。提案されたスタイル再構成損失は、発話レベルの発話スタイルが考慮されるように知覚損失として定式化されます。トレーニング中..提案されたトレーニング戦略は、2つの目的関数の組み合わせを採用しています。1）フレームレベルの再構成損失。これは、合成されたスペクトルフィーチャとターゲットスペクトルフィーチャの間で計算されます。 2）発話レベルスタイルの再構成損失。合成音声とターゲット音声の深いスタイルの特徴間で計算されます。 
[ABSTRACT]提案されたトレーニング戦略は、タコトロンベースのttsフレームワークを使用することを提案します。タコトロンベースのttsフレームワークを使用して、入力テキストとその韻律スタイル間の関連付けをエンコードします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: From Speaker Verification to Multispeaker Speech Synthesis, Deep
  Transfer with Feedback Constraint -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.AS/paper_13.html">
      <font color="black">From Speaker Verification to Multispeaker Speech Synthesis, Deep
  Transfer with Feedback Constraint</font>
    </a>
  </h2>
  <font color="black">高忠実度の音声は、近年エンドツーエンドのテキスト音声モデルによって合成できます。制約は、統合された音声間の話者の類似性を改善するために集中化されている話者のアイデンティティに関連する追加の損失によって行われます。そしてその自然な参照音声。モデルはトレーニングされ、公に利用可能なデータセットで評価されます。 
[ABSTRACT]モデルは、公開されているIDデータセットでトレーニングおよび評価されます。インタラクティブなデータセットを含むデータセットに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-10">
        <br><font color="black">2020-05-10</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-supervised Learning for Multi-speaker Text-to-speech Synthesis
  Using Discrete Speech Representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-05/eess.AS/paper_14.html">
      <font color="black">Semi-supervised Learning for Multi-speaker Text-to-speech Synthesis
  Using Discrete Speech Representation</font>
    </a>
  </h2>
  <font color="black">実験結果は、1時間のペアのスピーチデータだけで、ペアのデータが複数の話者または単一の話者からのものであるかどうかにかかわらず、提案されたモデルは異なる音声で明瞭なスピーチを生成できることを示しています。ペアになったデータの組み合わせは、半教師付きTTSの有効性に影響を与えます。マルチスピーカーTTSモデルは、離散音声表現を備えた提案されたエンコーダー/デコーダーフレームワークを介して、書き起こされていない音声から学習できます。 
[要約]マルチスピーカーTTSモデルは、提案されたエンコーダー-単一の音声表現を備えたデコーダーフレームワークを介して、文字起こしされていないオーディオから学習できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-16">
        <br><font color="black">2020-05-16</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
