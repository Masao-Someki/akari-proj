<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-07-30の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Understanding Optical Music Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.SD/paper_0.html">
      <font color="black">Understanding Optical Music Recognition</font>
    </a>
  </h2>
  <font color="black">このチュートリアルでは、これらの欠点に対処するために、（1）OMRとその関連フィールドとの関係の堅牢な定義を提供し、（2）OMRが音楽エンコーディングプロセスを反転させて、ドキュメントから音符と音楽セマンティクスを復元する方法を分析します（3 ）OMRの分類法を提案し、特にアプリケーションの新しい分類法を提案します。さらに、従来のパイプラインとは対照的に、ディープラーニングが現代のOMR研究にどのように影響するかについても説明します。50年以上にわたり、研究者はコンピューターに光学式音楽認識（OMR）と呼ばれる楽譜を読みます。 
[要約]フィールドはそれ自体の定義とomr。の共有定義の構築に苦労していますが、新しい研究者がアクセスするのは依然として難しい場合があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-07">
        <br><font color="black">2019-08-07</font>
      </time>
    </span>
</section>
<!-- paper0: DNN No-Reference PSTN Speech Quality Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.SD/paper_1.html">
      <font color="black">DNN No-Reference PSTN Speech Quality Prediction</font>
    </a>
  </h2>
  <font color="black">提案された非参照モデルは、検証とテストセットで完全参照POLQAおよび非参照P.563よりも優れています。このホワイトペーパーでは、1000を超えるクラウドソースの実際の電話による新しいオープンソースPSTN音声品質テストセットを紹介します。 ..しかし、現在の最先端の音声品質モデルは、ライブモニタリングに使用するには十分な信頼性がありません。 
[ABSTRACT] pstnの歪みは、プロバイダーや国によって異なる場合があります。これにより、さまざまなネットワークに適切に一般化されるモデルをトレーニングすることが難しくなります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Investigation of Phase Distortion on Perceived Speech Quality for
  Hearing-impaired Listeners -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.SD/paper_2.html">
      <font color="black">Investigation of Phase Distortion on Perceived Speech Quality for
  Hearing-impaired Listeners</font>
    </a>
  </h2>
  <font color="black">ある条件のセットでは、スピーチは-5から10 dBまでの4つの異なる信号対雑音比（SNR）でバブルノイズと混合されました。別の条件のセットでは、SNRは10 dBに固定され、ノイズのあるスピーチがは、T60が100〜1000ミリ秒のシミュレートされた残響室で提示されました。位相の強化が聴覚障害のある（HI）リスナーに有益であるかどうかは明らかではありません。 
[ABSTRACT]現在の音声強調アルゴリズムは位相の歪みに対処し始めています。ただし、アルゴリズムは通常の聴覚（nh）リスナーに焦点を合わせています。たとえば、snrは10 dbに固定され、ノイズのある音声はt60のシミュレーションされた反響室で提示されました100〜1000 msの範囲</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: From Sound Representation to Model Robustness -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.SD/paper_3.html">
      <font color="black">From Sound Representation to Model Robustness</font>
    </a>
  </h2>
  <font color="black">MFCC、短時間フーリエ変換（STFT）、および離散ウェーブレット変換（DWT）を評価して、2D表現空間で環境音信号を変調します。このホワイトペーパーでは、残留ディープニューラルネットワークアーキテクチャ（ResNet-18）の極端な脆弱性を示します。 ）オーディオ信号の時間周波数表現における敵対的攻撃に対して。ResNet-18は、認識精度の点で他の密な深層学習分類器（つまり、GoogLeNetおよびAlexNet）よりも優れているだけでなく、敵対的な例を他の犠牲者分類器にかなり転送します。 
[ABSTRACT] mfcc、短時間テオドール変換（stft）、および連続ウェーブレット学習（dwt）は、2D表現空間で環境音信号を変調します。18種類の広告主は、このモデルの攻撃がmfccおよびstft表現よりも比較的コストがかかることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Generative Adversarial Alignment Representation for Sheet
  music, Audio and Lyrics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.SD/paper_4.html">
      <font color="black">Unsupervised Generative Adversarial Alignment Representation for Sheet
  music, Audio and Lyrics</font>
    </a>
  </h2>
  <font color="black">特に、提案されたモデルは、潜在的な共有部分空間の相関関係を学習することにより、オーディオと楽譜の強い関係をオーディオ歌詞とシート歌詞のペアに転送できます。生成（G）モデルは、転送された2つのカップルの相関を学習します。ペアを使用して、固定歌詞の新しいオーディオシートペアを生成し、判別（D）モデルに挑戦します。オーディオとシートミュージックのCCAコンポーネントを適用して、新しいグラウンドトゥルースを確立します。 
[ABSTRACT]提案されたugaarモデルは、3つの主要な音楽モダリティにわたって共有される深い差別的な表現を学習します。これらには、楽譜、歌詞、オーディオが含まれ、3つのブランチでの深いニューラルネットワークベースのアーキテクチャが共同でトレーニングされます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Flexible framework for audio reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.SD/paper_5.html">
      <font color="black">Flexible framework for audio reconstruction</font>
    </a>
  </h2>
  <font color="black">提示された概念の実行可能性は、時間領域信号とその時間周波数係数の両方の部分的および量子化された観測からのオーディオ再構成が実行される例で示されます。この概念は、変換された類似の劣化モデルをカバーするようにさらに拡張されます。ドメイン、例えばこのペーパーでは、オーディオの修復、クリッピング、および逆量子化のタスクのための、統一された柔軟なフレームワークについて説明します。 
[ABSTRACT]オーディオ信号を再構築するコンセプトが開発されました。変換されたドメインで同じタスクをカバーするようにさらに拡張されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-23">
        <br><font color="black">2020-04-23</font>
      </time>
    </span>
</section>
<!-- paper0: On Loss Functions and Recurrency Training for GAN-based Speech
  Enhancement Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.SD/paper_6.html">
      <font color="black">On Loss Functions and Recurrency Training for GAN-based Speech
  Enhancement Systems</font>
    </a>
  </h2>
  <font color="black">全体として、客観的なメトリックの損失関数と平均二乗誤差（MSE）を組み合わせたCRGANモデルは、多くの評価メトリックにわたる比較アプローチに対して最高のパフォーマンスを提供します。反復層を含めることの利点も検討されます。この研究では、音声強調のための新しい畳み込み反復GAN（CRGAN）アーキテクチャ。 
[要約]提案されたcrganモデルは、同じロスバーを使用してsota ganベースのモデルよりも優れています。また、他の非ganベースのシステムよりも優れており、音声強調にガンを使用する利点を示唆しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Adversarial White Box Attacks on Music Instrument
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.SD/paper_7.html">
      <font color="black">End-to-End Adversarial White Box Attacks on Music Instrument
  Classification</font>
    </a>
  </h2>
  <font color="black">私たちの攻撃は、ランダムなベースラインに近い精度を低下させると同時に、摂動をほとんど感知できず、任意の目的の楽器を誤って分類する可能性があります。楽器の分類システムに対する最初のエンドツーエンドの敵対的攻撃を提示し、スペクトログラムではなく、オーディオ波形に直接摂動を追加します。入力データの小さな敵対的な摂動は、機械学習システムのパフォーマンスを劇的に変化させる可能性があり、それによって、そのようなシステムの妥当性に挑戦します。 
[ABSTRACT]楽器システムに対する最初の攻撃が公開されました。システムシステムシステムに対する一連の攻撃の最初の攻撃です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Transformer based unsupervised pre-training for acoustic representation
  learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.SD/paper_8.html">
      <font color="black">Transformer based unsupervised pre-training for acoustic representation
  learning</font>
    </a>
  </h2>
  <font color="black">すべての実験により、独自のトレーニングデータを使用した事前トレーニングにより、モデルの収束が大幅に高速化され、パフォーマンスが向上することが示されています。この問題を処理するために、トランスフォーマーベースのエンコーダーを使用した教師なし事前トレーニング方法を提案し、一般的で堅牢なすべての音響タスクの高レベルの表現。サウンドイベント検出の場合、F1スコアは、DCASE2018 task5開発セットで1.7％、評価セットで2.4％絶対的にさらに改善できます。 
[要約] 3種類の音響タスクについて実験が行われました。音響タスクには、音声翻訳、音声感情認識、サウンドイベント検出が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Representation Transferability of Adversarial Attacks: From
  Spectrograms to Audio Waveforms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.SD/paper_9.html">
      <font color="black">Cross-Representation Transferability of Adversarial Attacks: From
  Spectrograms to Audio Waveforms</font>
    </a>
  </h2>
  <font color="black">西洋音楽のデータセットの実験結果は、2D CNNが正当な例で平均精度の最大81.87％を達成し、そのようなパフォーマンスが敵対的な例で12.09％に低下することを示しています。この論文では、スペクトログラムベースのオーディオ分類器の敵対的感受性を示しています。攻撃およびそのような攻撃のオーディオ波形への転送可能性。さらに、摂動スペクトログラムから再構築されたオーディオ波形は、元のオーディオでトレーニングされた1D CNNをだますこともできます。 
[ABSTRACT]摂動スペクトログラムは、2D互換ネットワーク（cnn）をだますことができます。1dcnnは、元のオーディオでトレーニングされた1d cnnをだますこともできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-22">
        <br><font color="black">2019-10-22</font>
      </time>
    </span>
</section>
<!-- paper0: Improved Handling of Repeats and Jumps in Audio-Sheet Image
  Synchronization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.SD/paper_10.html">
      <font color="black">Improved Handling of Repeats and Jumps in Audio-Sheet Image
  Synchronization</font>
    </a>
  </h2>
  <font color="black">IMSLPからの未処理の楽譜PDFを慎重に制御した実験により、階層DTWがさまざまなタイプのジャンプの処理においてJump DTWよりも大幅に優れていることを示しています。最初に各楽譜ラインの機能レベルで位置合わせを実行し、次に2番目の位置合わせを実行します。セグメントレベル。システムパフォーマンスの大きなボトルネックは、ジャンプとリピートの処理です。 
[ABSTRACT]これまでの作品は、データがクリーンアップされ、前処理された合成楽譜に焦点を当てています。代わりに、未加工の生の楽譜の本当の乱雑さに対処できるシステムの開発に焦点を当てています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Streaming keyword spotting on mobile devices -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.SD/paper_11.html">
      <font color="black">Streaming keyword spotting on mobile devices</font>
    </a>
  </h2>
  <font color="black">このライブラリを使用して、携帯電話のストリーミングモードと非ストリーミングモードの両方で複数のKWSモデルのベンチマークを行い、レイテンシと精度の間のさまざまなトレードオフを示します。 -Google音声コマンドデータセットV2で10％増加。この作業では、携帯電話のストリーミングモードと非ストリーミングモードでのキーワードスポッティング（KWS）モデルのレイテンシと精度を調査します。 
[ABSTRACT]非ワードモードからストリーミングモードへのモデル変換には、手動での書き換えが必要な場合があります。携帯電話のストリーミングモードと非ストリーミングモードの両方で、複数のkwsモデルをベンチマークします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-14">
        <br><font color="black">2020-05-14</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Neural Network-based Reconstruction in Compressed Sensing MRI Without
  Fully-sampled Training Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_0.html">
      <font color="black">Neural Network-based Reconstruction in Compressed Sensing MRI Without
  Fully-sampled Training Data</font>
    </a>
  </h2>
  <font color="black">コードはhttps://github.com/alanqrwang/HQSNet。で入手できます。このホワイトペーパーでは、古典的な最適化スキームで広く使用されている損失関数を採用することにより、アンロールされた再構成ネットワークを教師なしの方法でトレーニングする新しい戦略を探ります。これらの方法は優れたパフォーマンスを発揮しますが、大量のグラウンドトゥルースイメージを必要とし、目に見えないデータに対して堅牢ではないことが示されています。 
[ABSTRACT]この戦略は、シンプルでシンプルなアルゴリズムを分析することによって開発されました。これらのモデルは大量のグラウンド-真実の画像を必要とし、目に見えないデータに対して堅牢ではないことが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: COVID-19 CT Image Synthesis with a Conditional Generative Adversarial
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_1.html">
      <font color="black">COVID-19 CT Image Synthesis with a Conditional Generative Adversarial
  Network</font>
    </a>
  </h2>
  <font color="black">ただし、ディープラーニングモデルのトレーニングには大量のデータが必要であり、COVID-19 CTのデータ要件を満たすために、COVID-19 CTデータを収集する場合、COVID-19 CTデータを収集する際に医療スタッフが高いリスクに直面します。イメージングでは、ディープラーニングベースの医用イメージングタスクで使用するための高品質でリアルなCOVID-19 CT画像を効果的に生成できる条件付き生成敵対ネットワークに基づくCT画像合成アプローチを提案します。最近、ディープラーニングベースコンピュータービジョン法は、X線、磁気共鳴画像、CT画像などの医療画像アプリケーションでの使用に大きな期待が寄せられています。 
[ABSTRACT] ctスキャンはcovid-19診断で重要な役割を果たします。これは、他の最先端の画像より優れた最新の方法です。提案された方法は、さまざまな機械学習アプリケーションに有望であることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Solving Phase Retrieval with a Learned Reference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_2.html">
      <font color="black">Solving Phase Retrieval with a Learned Reference</font>
    </a>
  </h2>
  <font color="black">次に、バックプロパゲーションを使用して、一定数の位相取得反復に対して最適な再構成を提供するリファレンスを学習します。信号を回復するには、反復位相取得法を展開されたネットワークとして実装します。この手法は、ホログラフィーで基準信号を追加する方法。 
[ABSTRACT]従来の方法は、固定数の線形最小化によってこの問題を解決します。これには、未知の画像の構造に関するいくつかの事前知識を活用することが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Automatic Embryo Staging in 3D+T Microscopy Images using
  Convolutional Neural Networks and PointNets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_3.html">
      <font color="black">Towards Automatic Embryo Staging in 3D+T Microscopy Images using
  Convolutional Neural Networks and PointNets</font>
    </a>
  </h2>
  <font color="black">これらの方法は、画像ベースの畳み込みニューラルネットワークと、検出された細胞核の重心の3D点群を直接操作するPointNetアーキテクチャに基づくアプローチで構成されます。さらに、シミュレーションされた3D + t点群に基づく概念実証評価データセットは、7分未満の平均偏差が可能であることを示しています。4つの野生型ゼブラフィッシュ胚を使用した実験では、平均偏差が21〜34分の自動ステージングに両方のアプローチが適しています。 
[ABSTRACT] 4つの野生型ゼブラフィッシュ胚を用いた実験では、21〜34分未満で動作することがわかりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-01">
        <br><font color="black">2019-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: COVID-CXNet: Detecting COVID-19 in Frontal Chest X-ray Images using Deep
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_4.html">
      <font color="black">COVID-CXNet: Detecting COVID-19 in Frontal Chest X-ray Images using Deep
  Learning</font>
    </a>
  </h2>
  <font color="black">COVID-CXNetは、完全に自動化された堅牢なCOVID-19検出システムに向けた一歩です。新規コロナウイルスによる感染症をスクリーニングするための主要な臨床観察の1つは、胸部X線画像のキャプチャです。この強力なモデルは、検出が可能です。正確なローカリゼーションを伴う関連性のある有意義な特徴に基づいた、新しいコロナウイルス肺炎。 
[ABSTRACT]ほとんどの患者では、胸部X線に異常が含まれています。これらはcovid-19ウイルス性肺炎の結果です。これは、完全に自動化された堅牢なcovid -19検出システムへのステップです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-16">
        <br><font color="black">2020-06-16</font>
      </time>
    </span>
</section>
<!-- paper0: Image Classification by Reinforcement Learning with Two-State Q-Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_5.html">
      <font color="black">Image Classification by Reinforcement Learning with Two-State Q-Learning</font>
    </a>
  </h2>
  <font color="black">私たちの手法は2つのQ状態のみを使用するため、簡単であり、その結果、最適化パラメーターの数がはるかに少なくなり、単純な報酬関数も得られます。この手法は、使用されるすべてのデータセットで他の手法よりも優れています。提案された手法のパフォーマンスは、ResNet50、InceptionV3などの他の最近のアルゴリズムと比較されます。
[ABSTRACT]この手法は、2つの状態と「2つまたは3つの」アクションで使用されています。これは、大きな次元のために状態の数が多いため、これらのアプローチで技術的な困難につながります特徴マップの。また、提案された技術は、画像を処理するための新しいアクションを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-28">
        <br><font color="black">2020-06-28</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Image Compression using Decoder Side Information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_6.html">
      <font color="black">Deep Image Compression using Decoder Side Information</font>
    </a>
  </h2>
  <font color="black">この問題は、情報理論では分散ソースコーディングと呼ばれ、このテクノロジーのいくつかの使用例について説明します。次に、実行時に、エンコーダー側がデコーダー側の画像について何も知らずに入力画像をエンコードし、デコーダーに送信します。 ..私たちのアルゴリズムをいくつかの画像圧縮アルゴリズムと比較し、デコーダのみのサイド情報を追加すると実際に結果が向上することを示します。 
[要旨]アルゴリズムは、enubとデコーダーで利用可能な画像が相関しているという仮定に基づいています。ネットワークにトレーニングフェーズでこれらの相関を学習させます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-14">
        <br><font color="black">2020-01-14</font>
      </time>
    </span>
</section>
<!-- paper0: Video compression with low complexity CNN-based spatial resolution
  adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_7.html">
      <font color="black">Video compression with low complexity CNN-based spatial resolution
  adaptation</font>
    </a>
  </h2>
  <font color="black">実験結果は、元のHEVC HMに比べて大幅なビットレートの節約（10％以上）と、エンコーダー（29％）とデコーダー（10％）の両方での計算の複雑さの低減により、提案されたアプローチの可能性を示しています。はHEVC HM 16.20ソフトウェアに統合され、All Intra構成を使用してJVET UHDテストシーケンスで評価されました。このアプローチは、エンコーダーでのビデオダウンサンプリングにCNNモデルを使用し、Lanczos3フィルターを使用してデコーダーで完全な解像度を再構築します。 
[ABSTRACT]畳み込みニューラルネットワーク（cnns）を使用して、解像度のアップサンプリングを実行しました。メソッドはソフトウェアに統合され、すべてのイントラダーを使用してテストシーケンスで評価されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: TR-GAN: Topology Ranking GAN with Triplet Loss for Retinal Artery/Vein
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_8.html">
      <font color="black">TR-GAN: Topology Ranking GAN with Triplet Loss for Retinal Artery/Vein
  Classification</font>
    </a>
  </h2>
  <font color="black">ランク付け損失は、ジェネレーターにさらに逆伝播され、より適切に接続されたA / Vマスクを生成します。提案されたフレームワークは、予測されたA / Vマスクのトポロジ接続を効果的に増加させ、最先端のA / V分類パフォーマンスを実現します公的に利用可能なAV-DRIVEデータセット上。さらに、高レベルのトポロジー特徴を抽出し、予測されたA / Vマスクとグラウンドトゥルースの間の特徴距離を狭めるために、トリプレット損失のあるトポロジー保存モジュールも提案されています。 。 
[ABSTRACT]順序党に基づくシステムは、グラウンド-真実、生成されたA / Vマスク、および意図的にシャッフルマスクをランク付けするために提案されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: On the unreasonable effectiveness of CNNs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_9.html">
      <font color="black">On the unreasonable effectiveness of CNNs</font>
    </a>
  </h2>
  <font color="black">画像間の問題を解決するためのベースラインCNNの機能に上限を設ける試みとして、広く使用されている標準の既製のネットワークアーキテクチャ（U-Net）を、ノイズからのXOR復号化の「逆問題」に適用しました。データと許容可能な結果を示します。たたみ込みニューラルネットワーク（CNN）を使用したディープラーニング手法は、実質的にすべてのイメージングの問題に、特に不適切で複雑なイメージングモデルを使用したイメージ再構成タスクに適用されています。 
[要旨] cnnsを使用すると、cnnsはノイズの多いデータからのxor復号化の問題を理解できました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Reliable Tuberculosis Detection using Chest X-ray with Deep Learning,
  Segmentation and Visualization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_10.html">
      <font color="black">Reliable Tuberculosis Detection using Chest X-ray with Deep Learning,
  Segmentation and Visualization</font>
    </a>
  </h2>
  <font color="black">結核（TB）は、細菌感染が原因で発生する慢性肺疾患であり、死因のトップ10の1つです。9つの異なる深部CNN（ResNet18、ResNet50、ResNet101、ChexNet、InceptionV3、Vgg19、DenseNet201、SqueezeNet、およびMobileNet）は、事前トレーニングされた初期の重みから転移学習に使用され、TBおよび非TBの通常のケースを分類するためにトレーニング、検証、テストされました。ただし、分類用のセグメント化肺は、X線画像ベースの分類全体よりも優れていました精度、精度、感度、F1スコア、特異度は、それぞれ99.9％、99.91％、99.9％、99.9％、99.52％でした。 
[要約]いくつかの公共データベースの研究者が、700 TBの感染と3500の正常な胸部X線画像のデータベースを作成するために使用しました。この研究ではさまざまな実験が行われました。コンピュータで役立つ-結核の迅速診断を支援</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: ClsGAN: Selective Attribute Editing Model Based On Classification
  Adversarial Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_11.html">
      <font color="black">ClsGAN: Selective Attribute Editing Model Based On Classification
  Adversarial Network</font>
    </a>
  </h2>
  <font color="black">さらに、アブレーション研究は、Tr-resnetとAtta-clsの優れたパフォーマンスを検証するように設計されています。エンコーダーデコーダー構造のスキップ接続により、編集画像が元の属性の影響を受けやすいことを考慮すると、上位の畳み込み残差ネットワーク（Tr-resnetと呼ばれる）は、ソース画像とターゲットラベルから情報を選択的に抽出するために表示されます。さらに、生成された画像の転送精度をさらに向上させるために、属性敵対分類器（Atta-clsと呼ばれる）は属性トランスファーイメージの欠陥を学習することにより、属性の観点からジェネレータをガイドするために導入されました。 
[要約]上位の畳み込み残差ネットワークが提示され、ソース画像とターゲットラベルから情報を選択的に抽出します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br><font color="black">2019-10-25</font>
      </time>
    </span>
</section>
<!-- paper0: Instance-aware, Context-focused, and Memory-efficient Weakly Supervised
  Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_12.html">
      <font color="black">Instance-aware, Context-focused, and Memory-efficient Weakly Supervised
  Object Detection</font>
    </a>
  </h2>
  <font color="black">これは、インスタンス対応のセルフトレーニングアルゴリズムと学習可能な具象DropBlockを採用し、メモリ効率の高い逐次バッチバックプロパゲーションを考案します。提案された方法は、COCO（$ 12.1 \％〜AP $、 $ 24.8 \％〜AP_ {50} $）、VOC 2007（$ 54.9 \％〜AP $）、およびVOC 2012（$ 52.1 \％〜AP $）。ベースラインを大幅に改善します。さらに、提案された方法は最初の方法ですResNetベースのモデルと監視の弱いビデオオブジェクト検出のベンチマークを行う。 
[ABSTRACT]このシステムは、これらの問題を対象とするように設計されています。オブジェクトインスタンスの検出を減らすことを目的としています。グラウンドトゥルースなしでは、オブジェクトの提案は、高いリコールのために冗長である必要があり、大量のメモリ消費を引き起こします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: Do Not Mask What You Do Not Need to Mask: a Parser-Free Virtual Try-On -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_13.html">
      <font color="black">Do Not Mask What You Do Not Need to Mask: a Parser-Free Virtual Try-On</font>
    </a>
  </h2>
  <font color="black">その結果、生徒は教師に対してマスクされた情報を利用します。このタスクでは、店内の布の画像を人物の画像に合わせる必要があります。これは、布のワープ、画像の合成、および合成が含まれるため、非常に困難です。敵対的損失なしに訓練された場合、この情報は使用されません。 
[ABSTRACT]このタスクでは、店内の布地の画像を人物の画像に合わせる必要があります。布地のプレビュー、画像の合成、および合成が含まれます。仮想現実は、仮想現実の現実の現実モデルを作成するために必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-03">
        <br><font color="black">2020-07-03</font>
      </time>
    </span>
</section>
<!-- paper0: Spatio-temporal Consistency to Detect Potential Aedes aegypti Breeding
  Grounds in Aerial Video Sequences -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_14.html">
      <font color="black">Spatio-temporal Consistency to Detect Potential Aedes aegypti Breeding
  Grounds in Aerial Video Sequences</font>
    </a>
  </h2>
  <font color="black">そうすることで、検出されたオブジェクトを登録し、誤検出を最小限に抑え、ほとんどの誤検出を修正できます。ビデオフレームに沿ってオブジェクト間の空間配置を取得するために、位相相関を使用してオブジェクトを追跡します。ResNet-101-の使用バックボーンとしてのFPN、提案されたデータセットで\ textit {F1-score}の観点から0.78を取得することが可能です。 
[要約]これらの病気と戦うための主な形式は、蚊の繁殖地となる可能性のある場所を検索して排除することにより、トランスミッターの繁殖を回避することです。ビデオフレームに沿ってオブジェクト間の空間的配置を取得するために、相関を使用してオブジェクトを追跡します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: PDCOVIDNet: A Parallel-Dilated Convolutional Neural Network Architecture
  for Detecting COVID-19 from Chest X-Ray Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_15.html">
      <font color="black">PDCOVIDNet: A Parallel-Dilated Convolutional Neural Network Architecture
  for Detecting COVID-19 from Chest X-Ray Images</font>
    </a>
  </h2>
  <font color="black">どちらの可視化方法も、最後の畳み込み層の特徴マップに関連する特定の画像カテゴリの勾配を計算して、クラス識別領域を作成します。放射線評価に胸部X線画像を使用することは、必須のスクリーニングの1つであることは間違いありません。技術..初期の研究のいくつかは、患者の胸部X線画像が異常を示していることを明らかにしました。これは、COVID-19に感染した患者にとって自然なことです。 
[要約]合計2 905件の胸部X線画像を使用して585枚の画像を作成しました。これらには、covid-19、正常、またはウイルス性肺炎の症例の58％が含まれていました。提案された方法は、疑われる疾患に関連するパフォーマンスも改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Camera-Based Piano Sheet Music Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_16.html">
      <font color="black">Camera-Based Piano Sheet Music Identification</font>
    </a>
  </h2>
  <font color="black">この論文では、ピアノ楽譜画像の大規模な検索方法を紹介します。まず、IMSLPデータセット全体のすべてのピアノ楽譜画像を検索可能なデータベースとして使用して、以前の研究よりもはるかに大規模な問題を調査します。以前に提案された楽譜検索のためのフィンガープリンティング方法は、リアルタイムアプリケーションには遅すぎることを示し、その欠点を診断します。 
[ABSTRACT]新しい方法は、入力クエリとして楽譜の携帯電話の画像を使用します。新しい方法は、データ量の分析に使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Broadband high-resolution terahertz single-pixel imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_17.html">
      <font color="black">Broadband high-resolution terahertz single-pixel imaging</font>
    </a>
  </h2>
  <font color="black">これは、近紫外からテラヘルツ領域で高度なイメージングシステムを開発するために拡張できます。薄いテラヘルツ周波数領域（3〜13 THz）で平均二乗誤差が低い単純な単一ピクセルのイメージングシステムを報告します。一連の直接穴あきランダムマスクとサブピクセルマスクデジタル化技術を備えた金属製リング。このイメージングシステムは、最大1200 x 1200ピクセルの高ピクセル解像度の再構成画像と、32 mm x 32 mmのイメージング領域を生成します。 
[ABSTRACT]ハイテクイメージングシステムは、高速シリーズの高速画像を生成します。それは、分析と分析の高速な組み合わせを生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-10">
        <br><font color="black">2020-06-10</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Architecture Search for Compressed Sensing Magnetic Resonance
  Image Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_18.html">
      <font color="black">Neural Architecture Search for Compressed Sensing Magnetic Resonance
  Image Reconstruction</font>
    </a>
  </h2>
  <font color="black">ただし、以前の方法で採用されたネットワークアーキテクチャはすべて手作りで設計されています。特に、モデル駆動型MR再構成パイプラインに統合された特定のセル構造は、柔軟な事前定義された操作検索スペースから差別化可能な方法で自動的に検索されました..私たちが提案する方法は、一般化可能性の高いMR再構成問題の計算コストと再構成パフォーマンスのトレードオフに到達し、他の医用画像アプリケーションのニューラルネットワークを設計するための洞察を提供します。 
[ABSTRACT]以前の方法で採用されたネットワークアーキテクチャはすべて手作りで設計されています。以前の試みで使用されたネットワークアーキテクチャはすべて手作りで開発されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-22">
        <br><font color="black">2020-02-22</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal Spatial Attention Module for Targeting Multimodal PET-CT Lung
  Tumor Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_19.html">
      <font color="black">Multimodal Spatial Attention Module for Targeting Multimodal PET-CT Lung
  Tumor Segmentation</font>
    </a>
  </h2>
  <font color="black">セグメンテーションは、さまざまなイメージングエキスパートによって手動で行われる傾向があり、労働集約的であり、エラーや不整合が発生しやすくなります。しかし、これらの方法は、セグメンテーションを導くことができる高いPET腫瘍感度を完全には活用していません。 PETおよびCTモダリティとは別に抽出された融合情報。各モダリティには補足情報が含まれているという基本的な前提があります。 
[要約]これは、マルチモーダル空間注意モジュール（msam）を導入する最初のステップです。これは、セグメンテーションに関連する領域（空間領域）を強調し、生理学的摂取量が多い正常領域を抑制することを自動的に学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Accurate 2D soft segmentation of medical image via SoftGAN network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_20.html">
      <font color="black">Accurate 2D soft segmentation of medical image via SoftGAN network</font>
    </a>
  </h2>
  <font color="black">この問題に対処するために、CT画像の超解像およびセグメンテーションタスクに対処するための新規のカスケード生成敵対的ネットワーク（CasGAN）を提案します。ここでは、正確な病変表現に関するセマンティックソフトセグメンテーションフォームが、私たちの知識に従って初めて導入されました。病変エッジは、セグメンテーション後も正確に保持でき、RECISTの弱い監視情報に基づいて高品質の大規模なアノテーションデータを迅速に取得できます。さらに、さらなる研究のために、困難な肺結節のソフトセグメンテーションデータセットを提供します。 ..医療用コンピューター断層撮影（CT）画像からの正確な2D肺結節のセグメンテーションは、医療アプリケーションで重要です。 
[ABSTRACT]最新のアプローチでは、正確なセグメンテーション結果を達成できます。結果は、肺結節の形状の最も小さな、複雑さ、および不規則性に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Improved Handling of Repeats and Jumps in Audio-Sheet Image
  Synchronization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.IV/paper_21.html">
      <font color="black">Improved Handling of Repeats and Jumps in Audio-Sheet Image
  Synchronization</font>
    </a>
  </h2>
  <font color="black">ジャンプの場所が不明な場合でもジャンプと繰り返しを処理できる階層DTWと呼ばれる新しい整列アルゴリズムを提案します。特に、以前に提案されたジャンプDTWアルゴリズムは、ジャンプの場所がアプリオリに未知である場合、ロバストに実行されないことを発見しました。紙は、オーディオ録音と生の楽譜画像を与えられたビデオに続いてピアノスコアを自動的に生成する問題を研究しています。 
[ABSTRACT]これまでの作品は、データがクリーンアップされ、前処理された合成楽譜に焦点を当てています。代わりに、未加工の生の楽譜の本当の乱雑さに対処できるシステムの開発に焦点を当てています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Compare and Select: Video Summarization with Multi-Agent Reinforcement
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_0.html">
      <font color="black">Compare and Select: Video Summarization with Multi-Agent Reinforcement
  Learning</font>
    </a>
  </h2>
  <font color="black">一般的なユーザーの行動に触発されて、要約プロセスを複数の連続した意思決定プロセスとして定式化し、マルチエージェント強化学習に基づく比較選択ネットワーク（CoSNet）を提案します。一般的なユーザーは通常、ビデオ全体を視聴し、興味深いクリップを比較し、いくつかのクリップを選択して最終的な要約を作成します。 
[ABSTRACT]一般的なユーザーは通常、動画全体を見て、興味深いクリップを比較し、いくつかのクリップを選択して最終的な要約を作成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: A Framework based on Deep Neural Networks to Extract Anatomy of
  Mosquitoes from Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_1.html">
      <font color="black">A Framework based on Deep Neural Networks to Extract Anatomy of
  Mosquitoes from Images</font>
    </a>
  </h2>
  <font color="black">特に翼の抽出において、再び好ましい結果を明らかにします。蚊の胸部、翼、腹部、および脚を自動的に検出して個別に抽出するために、マスク領域ベースの畳み込みニューラルネットワーク（マスクR-CNN）に基づくフレームワークを設計します。画像提案された手法では、最初のステップは、蚊の画像内の解剖学的コンポーネントを検出することです。 
[要約]バンブルビー画像の蚊の画像のみでトレーニングされたアーキテクチャをテストします。当社のデータセットは、フロリダに閉じ込められた9つの蚊の1500のスマートフォン画像で構成されていました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-21">
        <br><font color="black">2020-07-21</font>
      </time>
    </span>
</section>
<!-- paper0: MessyTable: Instance Association in Multiple Camera Views -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_2.html">
      <font color="black">MessyTable: Instance Association in Multiple Camera Views</font>
    </a>
  </h2>
  <font color="black">プロジェクトページ：$ \ href {https://caizhongang.github.io/projects/MessyTable/} {\ text {MessyTable}} $。データセットは、微妙な外観の違いをマイニングする既存の方法に挑戦し、コンテキストに基づいて推論し、外観を幾何学的な手がかりと関連付けて、関連付けを確立します。複数のカメラビューからキャプチャされた乱雑なテーブルを備えた多数のシーンを特徴とする興味深い挑戦的なデータセットを提示します。 
[ABSTRACT]このデータセットには、同一、乱雑、または乱雑である可能性のある複数のオブジェクトが含まれています。一見単純なタスクで、オブジェクトの関連付けで優れたパフォーマンスを想定している多くの一般的なメソッドまたはヒューリスティックが驚くほど失敗します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Network-based Reconstruction in Compressed Sensing MRI Without
  Fully-sampled Training Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_3.html">
      <font color="black">Neural Network-based Reconstruction in Compressed Sensing MRI Without
  Fully-sampled Training Data</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、古典的な最適化スキームで広く使用されている損失関数を採用することにより、アンロールされた再構成ネットワークを教師なしの方法でトレーニングする新しい戦略について説明します。コードはhttps://github.com/alanqrwang/HQSNetで入手できます。最近、ニューラルネットワークで反復を展開することにより、古典的な手法の反復的な性質をモデル化する深層学習モデルが開発されました。 
[ABSTRACT]この戦略は、シンプルでシンプルなアルゴリズムを分析することによって開発されました。これらのモデルは大量のグラウンド-真実の画像を必要とし、目に見えないデータに対して堅牢ではないことが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: COVID-19 CT Image Synthesis with a Conditional Generative Adversarial
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_4.html">
      <font color="black">COVID-19 CT Image Synthesis with a Conditional Generative Adversarial
  Network</font>
    </a>
  </h2>
  <font color="black">ただし、ディープラーニングモデルのトレーニングには大量のデータが必要であり、COVID-19 CTデータを収集する場合、疾患の感染力が高いため、医療スタッフは高いリスクに直面します。コロナウイルス病2019（COVID-19）は、進行中のグローバル2019年12月以降急速に広まったパンデミック。最近、ディープラーニングベースのコンピュータービジョン手法は、X線、磁気共鳴イメージング、CTイメージングなどの医療用イメージングアプリケーションでの使用に大きな期待を示しています。 
[ABSTRACT] ctスキャンはcovid-19診断で重要な役割を果たします。これは、他の最先端の画像より優れた最新の方法です。提案された方法は、さまざまな機械学習アプリケーションに有望であることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Solving Phase Retrieval with a Learned Reference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_5.html">
      <font color="black">Solving Phase Retrieval with a Learned Reference</font>
    </a>
  </h2>
  <font color="black">次に、バックプロパゲーションを使用して、一定数の位相取得反復に対して最適な再構成を提供するリファレンスを学習します。このホワイトペーパーでは、フーリエ振幅測定値をキャプチャする前に、既知の（学習された）リファレンスが信号に追加されると仮定します。信号を回復するために、繰返し位相検索法を展開されたネットワークとして実装します。 
[ABSTRACT]従来の方法は、固定数の線形最小化によってこの問題を解決します。これには、未知の画像の構造に関するいくつかの事前知識を活用することが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Automatic Embryo Staging in 3D+T Microscopy Images using
  Convolutional Neural Networks and PointNets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_6.html">
      <font color="black">Towards Automatic Embryo Staging in 3D+T Microscopy Images using
  Convolutional Neural Networks and PointNets</font>
    </a>
  </h2>
  <font color="black">これらの方法は、画像ベースの畳み込みニューラルネットワークと、検出された細胞核の重心の3D点群を直接操作するPointNetアーキテクチャに基づくアプローチで構成されます。さらに、シミュレーションされた3D + t点群に基づく概念実証評価データセットは、7分未満の平均偏差が可能であることを示しています。胚発生のさまざまな段階の自動分析と比較は、調査したデータセットの非常に正確な時空間アライメントに大きく依存しています。 
[ABSTRACT] 4つの野生型ゼブラフィッシュ胚を用いた実験では、21〜34分未満で動作することがわかりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-01">
        <br><font color="black">2019-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Robustness on In- and Out-Distribution Improves
  Explainability -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_7.html">
      <font color="black">Adversarial Robustness on In- and Out-Distribution Improves
  Explainability</font>
    </a>
  </h2>
  <font color="black">敵対的なトレーニングはクリーン精度の低下という代償を払うことになりますが、RATIOはCIFAR10で最先端の$ l_2 $敵対的な堅牢性を実現し、クリーンな精度を維持します。ニューラルネットワークは画像分類を大幅に改善しましたが、敵対的変化に対して非ロバストであり、アウトディストリビューションのサンプルとそれらの不可解なブラックボックス決定に関する信頼できない不確実性推定です。RATIOは敵対的トレーニングと同様の生成プロパティを備えているため、視覚的な反事実がクラス固有の機能を生成します。 
[ABSTRACT] ratioは、内外分布の敵対的トレーニングを介したロバストネスのトレーニングプロシージャであり、信頼性が高くロバストな信頼度推定を備えたロバストモデルを導きます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-20">
        <br><font color="black">2020-03-20</font>
      </time>
    </span>
</section>
<!-- paper0: Enriching Video Captions With Contextual Text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_8.html">
      <font color="black">Enriching Video Captions With Contextual Text</font>
    </a>
  </h2>
  <font color="black">視覚的な入力によってガイドされるモデルは、ポインタージェネレーターネットワークを介してコンテキストテキストから単語をコピーできるため、より具体的なビデオキャプションを生成できます。ビデオを生成するエンドツーエンドのシーケンスツーシーケンスモデルを提案します視覚的な入力に基づくキャプション、およびコンテキストテキストからの名前や場所などの関連知識のマイニング。以前のアプローチとは異なり、テキストをさらに前処理せず、モデルが直接それに参加することを学習します。 
[ABSTRACT]ニュースビデオデータセットで競争力のあるパフォーマンスを示します。アブレーション調査を通じて、コンテキストに応じたビデオキャプションの有効性を検証します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: The Unsupervised Method of Vessel Movement Trajectory Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_9.html">
      <font color="black">The Unsupervised Method of Vessel Movement Trajectory Prediction</font>
    </a>
  </h2>
  <font color="black">ほとんどの統計学習やディープラーニングの方法とは異なり、提案されたクラスタリングベースの軌跡再構成方法では、計算コストの高いモデルトレーニングは必要ありません。これにより、トレーニングセットを使用しなくても、リアルタイムの信頼性が高く正確な予測が可能になります。軌跡は正確に真の血管経路で構成されます。 
[要約]システムの提案されたアプリケーションは十分なセキュリティを必要としません。モデルのトレーニングは必要ないため、安定したモデルのトレーニングは必要ありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Chained-Tracker: Chaining Paired Attentive Regression Results for
  End-to-End Joint Multiple-Object Detection and Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_10.html">
      <font color="black">Chained-Tracker: Chaining Paired Attentive Regression Results for
  End-to-End Joint Multiple-Object Detection and Tracking</font>
    </a>
  </h2>
  <font color="black">連鎖構造と注意深い回帰の2つの主要な新機能により、CTrackerがシンプル、高速、かつ効果的になり、追加のトレーニングデータに依存することなく、MOT16およびMOT17チャレンジデータセット（それぞれ67.6および66.6）に新しいMOTAレコードが設定されます。ソースコードCTrackerは、github.com / pjl1995 / CTracker。にあります。これは、各ノードが2つの隣接するフレームをカバーする重複ノードから推定されたペアの境界ボックス回帰結果をチェーンします。 
[ABSTRACT] chained-tracker（ctracker）という名前のモデルは、オンラインモデルによって作成されました。3つのサブタスクすべてを、リンク先のend-to-に接続します。モデルは、object-attentionとidentity-attentionによって注意深くなります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding Optical Music Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_11.html">
      <font color="black">Understanding Optical Music Recognition</font>
    </a>
  </h2>
  <font color="black">さらに、従来のパイプラインとは対照的に、ディープラーニングが現代のOMR研究にどのように影響するかについても説明します。50年以上にわたり、研究者は光学式音楽認識（OMR）と呼ばれる楽譜を読むようにコンピューターに教えようとしてきました。この作品では、読者はOMRの基本的な理解を得ることができます。OMRの目的、固有の構造、他の分野との関係、最先端の技術、それがもたらす研究の機会です。 
[要約]フィールドはそれ自体の定義とomr。の共有定義の構築に苦労していますが、新しい研究者がアクセスするのは依然として難しい場合があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-07">
        <br><font color="black">2019-08-07</font>
      </time>
    </span>
</section>
<!-- paper0: Stylized Adversarial Defense -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_12.html">
      <font color="black">Stylized Adversarial Defense</font>
    </a>
  </h2>
  <font color="black">私たちの敵対的なトレーニングアプローチは、最先端の防御と比較して強力な堅牢性を示し、自然に発生する破損とデータ分散シフトに一般化し、クリーンな例でのモデルの正確性を保持します。ディープコンボリューションニューラルネットワーク（CNN）は、微妙な、入力画像への知覚できない変化..クラス境界情報のみを使用する既存の敵対的な訓練方法（たとえば、クロスエントロピー損失を使用）とは対照的に、特徴空間からの追加情報を活用して、より強力な敵を作成することを提案します。堅牢なモデルを学習するために使用されます。 
[ABSTRACT]敵対的トレーニングは摂動パターンを作成し、それらをトレーニングセットに含めてモデルをロバスト化します。敵対的トレーニングは、この脆弱性を敵対的に対処するために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Fast and Robust Small Infrared Target Detection Using Absolute
  Directional Mean Difference Algorithm -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_13.html">
      <font color="black">Fast and Robust Small Infrared Target Detection Using Absolute
  Directional Mean Difference Algorithm</font>
    </a>
  </h2>
  <font color="black">実際の赤外線画像のシミュレーション結果は、提案されたアルゴリズムの有意な効果を証明します。赤外線小型ターゲット検出アルゴリズムの大部分は方向情報を無視しますが、このホワイトペーパーでは、構造的背景を抑制し、より効果的な検出アルゴリズムを開発するための方向アプローチを示します。 ..また、提案されたアルゴリズムの効率的な実装手順を示します。 
[ABSTRACT]高灰色-強度の構造的背景が視野（fov）に表示されます。提案されたアルゴリズムはターゲット領域を効果的に拡張し、背景の乱雑さを排除</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-10-07">
        <br><font color="black">2018-10-07</font>
      </time>
    </span>
</section>
<!-- paper0: LaserFlow: Efficient and Probabilistic Object Detection and Motion
  Forecasting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_14.html">
      <font color="black">LaserFlow: Efficient and Probabilistic Object Detection and Motion
  Forecasting</font>
    </a>
  </h2>
  <font color="black">以前の研究とは異なり、私たちのアプローチは、LiDARのネイティブの範囲ビュー表現を利用します。これにより、ボクセル化やデータの圧縮なしでセンサーの全範囲でリアルタイムに操作できるようになります。さらに、新しい手法を提案します。カリキュラムの学習に触発された将来の軌道上の確率分布を学習するために。2つの自動運転データセットでLaserFlowを評価し、既存の最先端の方法と比較した場合に競争力のある結果を示します。 
[ABSTRACT]将来の軌跡の確率分布を学習する新しい手法を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-12">
        <br><font color="black">2020-03-12</font>
      </time>
    </span>
</section>
<!-- paper0: EAO-SLAM: Monocular Semi-Dense Object SLAM Based on Ensemble Data
  Association -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_15.html">
      <font color="black">EAO-SLAM: Monocular Semi-Dense Object SLAM Based on Ensemble Data
  Association</font>
    </a>
  </h2>
  <font color="black">オブジェクトレベルのデータの関連付けとポーズ推定は、セマンティックSLAMで基本的な役割を果たしますが、ロバストで正確なアルゴリズムがないため、未解決のままです。次に、外れ値とロバストな重心とスケール推定を行う正確なオブジェクトポーズ推定フレームワークを提示します。アルゴリズムとオブジェクトポーズ初期化アルゴリズムは、ポーズ推定結果の最適性を向上させるために開発されました。さらに、単眼カメラで半密度または軽量のオブジェクト指向マップを生成できるSLAMシステムを構築します。 
[ABSTRACT]イマーセズは、ポーズ推定結果の最適なソリティーを改善するのに役立ちます。これらには、外れ値-ロバストなセントロイドとスケールの推定が含まれます。プロジェクトはカリフォルニア大学の研究者チームによって作成されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br><font color="black">2020-04-27</font>
      </time>
    </span>
</section>
<!-- paper0: CelebA-Spoof: Large-Scale Face Anti-Spoofing Dataset with Rich
  Annotations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_16.html">
      <font color="black">CelebA-Spoof: Large-Scale Face Anti-Spoofing Dataset with Rich
  Annotations</font>
    </a>
  </h2>
  <font color="black">2）多様性：8つのシーン（2つの環境* 4つの照明条件）から10個以上のセンサーを使用して、なりすまし画像をキャプチャします。これらの障害を克服するために、大規模な顔のなりすましデータセット、CelebA-Spoof、次の魅力的なプロパティ：1）数量：CelebA-Spoofは、既存のデータセットよりも大幅に大きい、10,177人の被験者の625,537枚の写真で構成されています。元のCelebAデータセット。 
[ABSTRACT]顔のなりすましは重要な領域であり、その目的は、提示された顔がライブであるか、なりすましであるかを識別することです。主な理由は、現在の顔のなりすましデータセットは量と多様性の両方に制限があるためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-24">
        <br><font color="black">2020-07-24</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Multi-Scale Resemblance Network for the Sub-class Differentiation
  of Adrenal Masses on Computed Tomography Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_17.html">
      <font color="black">Deep Multi-Scale Resemblance Network for the Sub-class Differentiation
  of Adrenal Masses on Computed Tomography Images</font>
    </a>
  </h2>
  <font color="black">方法：これらの制限を克服する深いマルチスケール類似ネットワーク（DMRN）を開発し、ペアのCNNを活用してクラス内の類似性を評価しました。副腎腫瘤は良性または悪性であり、良性腫瘤はさまざまな有病率を持っています。分類方法に基づくたたみ込みニューラルネットワーク（CNN）は、大規模な医用画像トレーニングデータセットのクラス間差異を最大化する最先端の技術です。 
[ABSTRACT] cnnsの副腎腫瘤への適用は、クラス内変動が大きく、クラス間類似性が大きく、トレーニングデータが不均衡であるため、困難です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: COVID-CXNet: Detecting COVID-19 in Frontal Chest X-ray Images using Deep
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_18.html">
      <font color="black">COVID-CXNet: Detecting COVID-19 in Frontal Chest X-ray Images using Deep
  Learning</font>
    </a>
  </h2>
  <font color="black">ほとんどの患者では、胸部X線に、COVID-19ウイルス性肺炎の結果である地固めなどの異常が含まれています。新規コロナウイルスによる感染症をスクリーニングするための主な臨床所見の1つは、胸部X- ray image ..最後に、転移学習パラダイムを使用して、COVID-CXNetの開発に有名なCheXNetモデルを利用します。 
[ABSTRACT]ほとんどの患者では、胸部X線に異常が含まれています。これらはcovid-19ウイルス性肺炎の結果です。これは、完全に自動化された堅牢なcovid -19検出システムへのステップです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-16">
        <br><font color="black">2020-06-16</font>
      </time>
    </span>
</section>
<!-- paper0: Square Attack: a query-efficient black-box adversarial attack via random
  search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_19.html">
      <font color="black">Square Attack: a query-efficient black-box adversarial attack via random
  search</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、特に非対象設定で、最先端の方法と比較して、クエリ効率が大幅に向上し、高い成功率を達成しています。特に、ImageNetでは、さまざまなディープの非対象設定での平均クエリ効率が向上しています。最近の最先端のAl-Dujaili＆O&#39;Reillyの$ l_ \ infty $攻撃と比較して、少なくとも$ 1.8 $から最大$ 3 $の係数でネットワークを攻撃します。攻撃のコードは、 https://github.com/max-andr/square-attack。 
[ABSTRACT] square attackは、ランダム化された検索スキームに基づいています。ランダムな位置で局所的な状態サイズの更新を選択します。摂動は、実行可能なセットの境界にほぼ位置しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-29">
        <br><font color="black">2019-11-29</font>
      </time>
    </span>
</section>
<!-- paper0: NWPU-Crowd: A Large-Scale Benchmark for Crowd Counting and Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_20.html">
      <font color="black">NWPU-Crowd: A Large-Scale Benchmark for Crowd Counting and Localization</font>
    </a>
  </h2>
  <font color="black">過去10年間、群衆の監視、公衆安全、空間設計などを含む広範なアプリケーションにより、群衆のカウントとローカリゼーションが研究者の注目を集めています。多くの畳み込みニューラルネットワーク（CNN）は、このタスクに取り組むために設計されています。ただし、現在リリースされているデータセットは小規模であるため、監視付きCNNベースのアルゴリズムのニーズを満たすことができません。 
[要約]大規模な混雑した群集カウントおよびローカリゼーションデータセット、nwpu-crowdは、5、109の画像、合計2、133、375の注釈付きヘッドで構成されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-10">
        <br><font color="black">2020-01-10</font>
      </time>
    </span>
</section>
<!-- paper0: Meta-Learning with Context-Agnostic Initialisations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_21.html">
      <font color="black">Meta-Learning with Context-Agnostic Initialisations</font>
    </a>
  </h2>
  <font color="black">最初に、アルファベットをコンテキストとして使用して、Omniglot少数ショット文字分類について報告します。3つの一般的に使用されるメタ学習アルゴリズムと2つの問題に対するアプローチを評価します。メタ学習アプローチは、適切な初期化を見つけることで少数ショット問題に対処しています。ターゲットタスクに微調整します。 
[ABSTRACT]これにより、細かい-初期化を生成します-コンテキストであるターゲットに適応します-攻撃とタスク-一般化されます。たとえば、コンテキストを実証します-変則メタ-学習はそれぞれのケースで結果を改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Reconstruction of 3D flight trajectories from ad-hoc camera networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_22.html">
      <font color="black">Reconstruction of 3D flight trajectories from ad-hoc camera networks</font>
    </a>
  </h2>
  <font color="black">弱く制約された設定にもかかわらず、コンピュータービジョンの最近の開発により、非同期でキャリブレーションされていない家庭用カメラのネットワークから3Dで軌跡を再構築し、提案された方法を現実的なフィールド実験で検証できることがわかります。同期されていないカメラで記録されたビデオからのみ航空機搭載ロボットシステムの3D軌跡を再構築するには、ローリングシャッターの歪みがあり、視点が不明である可能性があります。cmに正確なグラウンドトゥルースを含むデータとともにコードを利用できるようにします差動GNSSナビゲーションから。 
[ABSTRACT]私たちのアプローチは、動的に飛行するターゲットの追跡において、ロバストで正確な外部を可能にします。cm-正確なグラウンド-真実を含むデータとともにコードを利用できるようにします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-10">
        <br><font color="black">2020-03-10</font>
      </time>
    </span>
</section>
<!-- paper0: Face2Face: Real-time Face Capture and Reenactment of RGB Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_23.html">
      <font color="black">Face2Face: Real-time Face Capture and Reenactment of RGB Videos</font>
    </a>
  </h2>
  <font color="black">ソースシーケンスも単眼のビデオストリームであり、商品のウェブカメラでライブキャプチャされます。Face2Faceは、単眼のターゲットビデオシーケンス（Youtubeビデオなど）のリアルタイムの顔の再現のための新しいアプローチです。私たちの目標はアニメーション化することです。ソースアクターによるターゲットビデオの表情と、操作された出力ビデオを写実的な方法で再レンダリングします。 
[要旨]まず、非剛体モデルによる単眼ビデオからの顔の同一性回復の制約された問題-ベースのバンドルに最初に対処します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Compact Global Descriptor for Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_24.html">
      <font color="black">Compact Global Descriptor for Neural Networks</font>
    </a>
  </h2>
  <font color="black">この記述子を使用すると、後続の畳み込みで、計算の複雑さとパラメーターがごくわずかな有益なグローバル機能にアクセスできます。https：//github.com/HolmesShuan/Compact-Global-Descriptor ..にあるコードを利用できます。追加のコンピューティングコストを大幅に削減する、最新の長距離メカニズム。 
[ABSTRACT]この記述子により、後続の畳み込みが有益なグローバル機能にアクセスできるようになります。このデスクマーカーにより、後続の情報に役立つグローバル機能にアクセスできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-23">
        <br><font color="black">2019-07-23</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic Character Graph via Online Face Clustering for Movie Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_25.html">
      <font color="black">Dynamic Character Graph via Online Face Clustering for Movie Analysis</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチには2つのコンポーネントがあります：（i）ビデオストリーム内の登場人物を検出するオンラインフェイスクラスタリングアルゴリズム、および（ii）結果として得られるクラスターの時間ダイナミクスを使用したCIGの同時作成。これを次のように呼びます。キャラクターインタラクショングラフ（CIG）。キャラクターインタラクションの時間的進化を捉えた動的なキャラクターグラフを作成するための教師なしアプローチを提案します。 
[ABSTRACT]キャラクターの進化のグラフ（cig）はキャラクターの進化のビデオをキャプチャします。2つの映画の自動化されたタスクに対するcigの有用性を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Image Classification by Reinforcement Learning with Two-State Q-Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_26.html">
      <font color="black">Image Classification by Reinforcement Learning with Two-State Q-Learning</font>
    </a>
  </h2>
  <font color="black">また、提案された手法は、文献にある他の手法と比較して、画像を処理するための新しいアクションを使用します。このアプローチは、使用されるすべてのデータセットで他の手法よりも優れています。提案された手法のパフォーマンスは、ResNet50、InceptionV3、など。
[ABSTRACT]テクニックは2つの状態と「2つまたは3つの」アクションで使用されています。フィーチャーマップのディメンションが大きいために状態の数が多いため、これらのアプローチでは技術的な問題が発生します。また、提案されたテクニックは画像を処理するための新しいアクション</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-28">
        <br><font color="black">2020-06-28</font>
      </time>
    </span>
</section>
<!-- paper0: A Deep Learning-based Detector for Brown Spot Disease in Passion Fruit
  Plant Leaves -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_27.html">
      <font color="black">A Deep Learning-based Detector for Brown Spot Disease in Passion Fruit
  Plant Leaves</font>
    </a>
  </h2>
  <font color="black">この作業では、ウガンダ国立作物研究所（NaCRRI）と提携して、病気にかかった健康なパッションフルーツの植物の葉と果物を専門的にラベル付けしたデータセットを開発しました。パッションフルーツ農家を含む農家の大多数として、国は低所得世帯の小規模農家であり、これらの課題に対処するための十分な情報と手段がありません。利回りが低下し、損失が増加するため、投資の損失につながります。 
[ABSTRACT]パッションフルーツは、農家の幸福を向上させる可能性があります。作物の健康に関する必要な知識がなければ、農家はすぐに介入して状況を変えることはできません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic GCN: Context-enriched Topology Learning for Skeleton-based
  Action Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_28.html">
      <font color="black">Dynamic GCN: Context-enriched Topology Learning for Skeleton-based
  Action Recognition</font>
    </a>
  </h2>
  <font color="black">特に、CeNのメリットとして、さまざまな深さのグラフの畳み込み層だけでなく、さまざまな入力サンプルに対して動的グラフトポロジが構築されます。CeNはベースラインモデルに最大7％の追加のFLOPをもたらし、動的GCNは$ 2 \でより優れたパフォーマンスを実現しますtimes $〜$ 4 \ times $は、既存の方法よりもFLOPが少なくなっています。グラフ畳み込みネットワーク（GCN）は、スケルトンベースのアクション認識のタスクへの関心を高めています。 
[ABSTRACT]畳み込み層を使用して、スケルトンの関心のための「グローバルgcn」を構築できます。これは、畳み込み畳み込み層の入力に基づいています。3つの代替コンテキストモデリングアーキテクチャが検討されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Image Compression using Decoder Side Information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_29.html">
      <font color="black">Deep Image Compression using Decoder Side Information</font>
    </a>
  </h2>
  <font color="black">次に、実行時に、エンコーダー側がデコーダー側の画像について何も知らずに入力画像をエンコードし、それをデコーダーに送信します。この問題は、情報理論の分散ソースコーディングと呼ばれ、このテクノロジーのいくつかの使用例について説明します。 ..次に、デコーダは、エンコードされた入力画像とサイド情報画像を使用して、元の画像を再構築します。 
[要旨]アルゴリズムは、enubとデコーダーで利用可能な画像が相関しているという仮定に基づいています。ネットワークにトレーニングフェーズでこれらの相関を学習させます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-14">
        <br><font color="black">2020-01-14</font>
      </time>
    </span>
</section>
<!-- paper0: COCO-FUNIT: Few-Shot Unsupervised Image Translation with a Content
  Conditioned Style Encoder -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_30.html">
      <font color="black">COCO-FUNIT: Few-Shot Unsupervised Image Translation with a Content
  Conditioned Style Encoder</font>
    </a>
  </h2>
  <font color="black">入力画像とサンプル画像のオブジェクトのポーズが大きく異なる場合、これは特に深刻です。コードと事前トレーニング済みモデルについては、https：//nvlabs.github.io/COCO-FUNIT/を確認してください。この問題に対処するには、我々は新しい少数ショット画像翻訳モデル、COCO-FUNITを提案します。これは、入力画像と一定のスタイルバイアスと呼ばれる新しいモジュールで条件付けされたサンプル画像のスタイル埋め込みを計算します。 
[ABSTRACT]モデルを未知のドメインに一般化する新しい試み。モデルはコンテンツ損失問題への対処に効果を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-15">
        <br><font color="black">2020-07-15</font>
      </time>
    </span>
</section>
<!-- paper0: Solving the Blind Perspective-n-Point Problem End-To-End With Robust
  Differentiable Geometric Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_31.html">
      <font color="black">Solving the Blind Perspective-n-Point Problem End-To-End With Robust
  Differentiable Geometric Optimization</font>
    </a>
  </h2>
  <font color="black">幸いなことに、これは結合された問題です。対応が与えられれば、ポーズを簡単に見つけることができます。その逆も同様です。最適化問題を区別する最近の結果を利用して、Sinkhorn、RANSACなどのエンドツーエンドの学習フレームワークに幾何学モデルのフィッティングを組み込みます。とPnPアルゴリズム。代わりに、ブラインドPnP問題を効率的かつグローバルに、つまりポーズの事前設定を必要とせずに解決する、最初の完全なエンドツーエンドのトレーニング可能なネットワークを提案します。 
[要約]ポーズと対応を同時に解決することは非常に困難です。既存のアプローチでは、ノイズの多い対応が提供されるか、適切なポーズを事前に利用できるか、または問題のサイズが小さいと想定しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Video compression with low complexity CNN-based spatial resolution
  adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_32.html">
      <font color="black">Video compression with low complexity CNN-based spatial resolution
  adaptation</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、エンコーダーとデコーダーの間の複雑さの柔軟な割り当てをサポートする新しいフレームワークを提案します。提案された方法は、HEVC HM 16.20ソフトウェアに統合され、All Intra構成を使用してJVET UHDテストシーケンスで評価されました。 
[ABSTRACT]畳み込みニューラルネットワーク（cnns）を使用して、解像度のアップサンプリングを実行しました。メソッドはソフトウェアに統合され、すべてのイントラダーを使用してテストシーケンスで評価されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: TR-GAN: Topology Ranking GAN with Triplet Loss for Retinal Artery/Vein
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_33.html">
      <font color="black">TR-GAN: Topology Ranking GAN with Triplet Loss for Retinal Artery/Vein
  Classification</font>
    </a>
  </h2>
  <font color="black">この論文では、セグメント化された動脈と静脈のトポロジ接続を改善し、さらにA / V分類パフォーマンスを向上させるために、トポロジランキング生成的敵対的ネットワーク（TR-GAN）を提案します。提案されたフレームワークは、予測されたA / Vは、一般に入手可能なAV-DRIVEデータセットで最先端のA / V分類パフォーマンスをマスクし、達成します。順序回帰に基づくトポロジランク付け弁別器が、地面のトポロジー接続レベルをランク付けするために提案されています。真実は、生成されたA / Vマスクと意図的にシャッフルされたマスクです。 
[ABSTRACT]順序党に基づくシステムは、グラウンド-真実、生成されたA / Vマスク、および意図的にシャッフルマスクをランク付けするために提案されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Fusion of Infrared Images with Dense RGB Reconstruction from Multiple
  Views -- with Application to Fire-fighting Robots -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_34.html">
      <font color="black">3D Fusion of Infrared Images with Dense RGB Reconstruction from Multiple
  Views -- with Application to Fire-fighting Robots</font>
    </a>
  </h2>
  <font color="black">このプロジェクトは、赤外線画像とRGB画像を統合して、複数のビューから再構築された高密度の3D環境モデルを生成します。結果の3Dマップには、被害者とアクティブな火災区域を特定するためのロボット消防アプリケーションで使用できる熱情報とRGB情報の両方が含まれます。 
[ABSTRACT]マップには、ロボットの消防-犠牲者とアクティブな消防区域を特定するための戦闘アプリケーションで使用できる熱情報とRGB情報が含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: On the unreasonable effectiveness of CNNs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_35.html">
      <font color="black">On the unreasonable effectiveness of CNNs</font>
    </a>
  </h2>
  <font color="black">畳み込みニューラルネットワーク（CNN）を使用した深層学習法は、実質的にすべてのイメージング問題に、特に不適切で複雑なイメージングモデルを使用した画像再構成タスクに正常に適用されています。ベースラインCNNの機能に上限を設定する試み画像間の問題を解決するために、広く使用されている標準の既製のネットワークアーキテクチャ（U-Net）を、ノイズの多いデータからのXOR復号化の「逆問題」に適用し、許容可能な結果を示しました。 
[要旨] cnnsを使用すると、cnnsはノイズの多いデータからのxor復号化の問題を理解できました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: What My Motion tells me about Your Pose: Self-Supervised Fine-Tuning of
  Observed Vehicle Orientation Angle -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_36.html">
      <font color="black">What My Motion tells me about Your Pose: Self-Supervised Fine-Tuning of
  Observed Vehicle Orientation Angle</font>
    </a>
  </h2>
  <font color="black">より具体的には、Virtual KittiからnuScenesに移行すると、監視対象メソッドの100％と比較して、最大70％のパフォーマンスが回復します。したがって、私たちの自己監視メソッドにより、車両の向きの推定を新しいドメインに安全に転送できます。高価な新しいラベル..単眼SLAM法から得られた自我運動の一貫性を活用することにより、私たちの自己管理微調整スキームが結果として得られるネットワークの精度を一貫して向上させることを示します。 
[ABSTRACT]これにより、教師なしまたは自己教師付きラベルの必要性が高まっています。私たちの自己教師付き微調整スキームにより、結果のネットワークの精度が一貫して向上することを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Between Subjectivity and Imposition: Power Dynamics in Data Annotation
  for Computer Vision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_37.html">
      <font color="black">Between Subjectivity and Imposition: Power Dynamics in Data Annotation
  for Computer Vision</font>
    </a>
  </h2>
  <font color="black">この義務は大部分は自然なものです。私たちの結果は、アノテーターの作業が、ステーションの上の他のアクターの興味、価値観、および優先順位によって深く知らされていることを示しています。個人と社会のために。 
[ABSTRACT]このペーパーでは、産業コンテキストで実行される画像データのアノテーションのプラクティスを探求します。これは、ラベルの偏りの主な原因としてデータアノテーターを使用するプラクティスを調べる最新のペーパーです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: A regularized deep matrix factorized model of matrix completion for
  image restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_38.html">
      <font color="black">A regularized deep matrix factorized model of matrix completion for
  image restoration</font>
    </a>
  </h2>
  <font color="black">したがって、低ランクの制約のみのアルゴリズムは、画像の復元を適切に実行するには不十分です。しかし、低ランクは、自然画像の固有の特性を反映するには不十分です。詳細な実験により、RDMFモデルの有効性を実証します。一般的な例では、特に少数の観察からの復元では、この方法が最新のモデルを上回っています。 
[ABSTRACT]低ランクは、自然画像の生来の特性を反映するのに十分ではありません。画像の復元には、正規化されたディープマトリックスファクターモデルを提案</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Reliable Tuberculosis Detection using Chest X-ray with Deep Learning,
  Segmentation and Visualization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_39.html">
      <font color="black">Reliable Tuberculosis Detection using Chest X-ray with Deep Learning,
  Segmentation and Visualization</font>
    </a>
  </h2>
  <font color="black">ただし、分類用のセグメント化された肺は、X線画像ベースの分類全体よりも優れており、精度、精度、感度、F1スコア、特異度はそれぞれ99.9％、99.91％、99.9％、99.9％、99.52％でした。精度、精度、感度、F1スコア、X線画像を使用した結核の検出の特異度は、それぞれ97.07％、97.34％、97.07％、97.14％および97.36％でした。9つの異なるディープCNN（ResNet18、ResNet50、ResNet101、ChexNet） 、InceptionV3、Vgg19、DenseNet201、SqueezeNet、およびMobileNet）。これらは事前トレーニング済みの初期ウェイトからの転移学習に使用され、TBと非TBの通常のケースを分類するためにトレーニング、検証、テストされました。 
[要約]いくつかの公共データベースの研究者が、700 TBの感染と3500の正常な胸部X線画像のデータベースを作成するために使用しました。この研究ではさまざまな実験が行われました。コンピュータで役立つ-結核の迅速診断を支援</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Translate the Facial Regions You Like Using Region-Wise Normalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_40.html">
      <font color="black">Translate the Facial Regions You Like Using Region-Wise Normalization</font>
    </a>
  </h2>
  <font color="black">Morph、RaFD、CelebAMask-HQは、私たちのアプローチが、StarGAN、SEAN、FUNITなどの最新のメソッドに比べて大幅な改善を示していることを示唆しています。3つの公開されているデータセット、すなわちその結果、地域レベルの表現の変化と段階的なメイクアップを実現できます。 
[要約]このドキュメントでは、地域を提案します-正規化フレームワークのように、地域レベルの顔の翻訳のために、地域からのデータに基づいて、さまざまな種類の異なる地域を開発しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Layer-wise Conditioning Analysis in Exploring the Learning Dynamics of
  DNNs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_41.html">
      <font color="black">Layer-wise Conditioning Analysis in Exploring the Learning Dynamics of
  DNNs</font>
    </a>
  </h2>
  <font color="black">さらに、BNは最適化問題の層ごとの条件付けを改善できることを実験的に観察します。このような分析は、実際にほぼ成立する穏やかな仮定の下で理論的にサポートされます。最後の線形の前に1つのBN層を追加するだけでこの問題を解決しますレイヤー。元のネットワークとアクティブ化前の残余ネットワークのパフォーマンスを向上させます。 
[要約]これは線形モデルに対して理論的に十分に検討されています。この目的のために、層ごとの条件付け分析を提案します。これは、各層に関して独立して進化のランドスケープを調査します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-25">
        <br><font color="black">2020-02-25</font>
      </time>
    </span>
</section>
<!-- paper0: ClsGAN: Selective Attribute Editing Model Based On Classification
  Adversarial Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_42.html">
      <font color="black">ClsGAN: Selective Attribute Editing Model Based On Classification
  Adversarial Network</font>
    </a>
  </h2>
  <font color="black">ただし、正確な属性変換を使用して高品質の画像を生成することは依然として困難です。さらに、アブレーション研究は、Tr-resnetおよびAtta-clsの優れたパフォーマンスを検証するためにも設計されています。エンコーダとデコーダの構造と生成的敵対的ネットワーク（GAN）。 
[要約]上位の畳み込み残差ネットワークが提示され、ソース画像とターゲットラベルから情報を選択的に抽出します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br><font color="black">2019-10-25</font>
      </time>
    </span>
</section>
<!-- paper0: Instance-aware, Context-focused, and Memory-efficient Weakly Supervised
  Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_43.html">
      <font color="black">Instance-aware, Context-focused, and Memory-efficient Weakly Supervised
  Object Detection</font>
    </a>
  </h2>
  <font color="black">これは、インスタンス対応のセルフトレーニングアルゴリズムと学習可能な具象DropBlockを採用し、メモリ効率の高い逐次バッチバックプロパゲーションを考案します。提案された方法は、COCO（$ 12.1 \％〜AP $、 $ 24.8 \％〜AP_ {50} $）、VOC 2007（$ 54.9 \％〜AP $）、およびVOC 2012（$ 52.1 \％〜AP $）。ベースラインを大幅に改善します。これらの課題への対処は、しばしば不確実性とささいな解決策を排除する必要があります。 
[ABSTRACT]このシステムは、これらの問題を対象とするように設計されています。オブジェクトインスタンスの検出を減らすことを目的としています。グラウンドトゥルースなしでは、オブジェクトの提案は、高いリコールのために冗長である必要があり、大量のメモリ消費を引き起こします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: Do Not Mask What You Do Not Need to Mask: a Parser-Free Virtual Try-On -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_44.html">
      <font color="black">Do Not Mask What You Do Not Need to Mask: a Parser-Free Virtual Try-On</font>
    </a>
  </h2>
  <font color="black">敵対的な損失なしに訓練された生徒はこの情報を使用しません。そのため、生徒は教師にマスクされた情報を悪用します。この手順にはいくつかの注意点があります。まず、人間のパーサーはエラーを起こしやすいです。第二に、これは費用のかかる前処理ステップであり、推論時にも適用する必要があります。最後に、マスクは手やアクセサリーなどの保持する必要のある情報をカバーしているため、作業が実際よりも難しくなります。 
[ABSTRACT]このタスクでは、店内の布地の画像を人物の画像に合わせる必要があります。布地のプレビュー、画像の合成、および合成が含まれます。仮想現実は、仮想現実の現実の現実モデルを作成するために必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-03">
        <br><font color="black">2020-07-03</font>
      </time>
    </span>
</section>
<!-- paper0: Object-and-Action Aware Model for Visual Language Navigation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_45.html">
      <font color="black">Object-and-Action Aware Model for Visual Language Navigation</font>
    </a>
  </h2>
  <font color="black">ただし、上記の解決策によって引き起こされる1つの問題は、指示で言及されたオブジェクトが2つ以上の候補視点の方向に観察される可能性があるため、OAAMが次のアクションとして最短経路上の視点を予測できない場合があります。論文では、これら2つの異なる形式の自然言語ベースの命令を個別に処理するオブジェクトアンドアクション認識モデル（OAAM）を提案します。実験結果は、提案されたモデルの有効性とパス損失、およびそれらとの組み合わせの優位性を示しています。目に見えない環境でのR2RデータセットのSPLスコアは50％、R4RデータセットのCLSスコアは40％で、これまでの最新技術を上回っています。 
[ABSTRACT]これは、2つの非常に異なるタイプの自然言語情報から値を抽出する必要があります。これは、オブジェクト中心の命令またはアクションベースの命令に適用されます。これにより、各プロセスがオブジェクトに一致します-中心/アクション中心の命令、独自の対応する視覚認識</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Difficulty-aware Glaucoma Classification with Multi-Rater Consensus
  Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_46.html">
      <font color="black">Difficulty-aware Glaucoma Classification with Multi-Rater Consensus
  Modeling</font>
    </a>
  </h2>
  <font color="black">ただし、モデルのトレーニングに使用する場合は、最終的なグラウンドトゥルースラベルのみが使用され、イージー/ハードケースである画像に関する生のマルチレートグレーディングに含まれる重要な情報は破棄されます。感度を高めるためにコンセンサスラベルの一貫した結果と不一致ラベルの反対の結果を生成するブランチと特異性ブランチ、2つのブランチの出力を制約するためのコンセンサス損失が提案されています。特に、マルチブランチモデル構造は、最も敏感な入力画像の具体的でバランスの取れた融合結果。 
[要約]マルチレイターコンセンサス情報を使用する提案された方法は、優れたパフォーマンスを達成しました。また、予測を行うときに、個々の入力画像の難易度を推定することもできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Spatio-temporal Consistency to Detect Potential Aedes aegypti Breeding
  Grounds in Aerial Video Sequences -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_47.html">
      <font color="black">Spatio-temporal Consistency to Detect Potential Aedes aegypti Breeding
  Grounds in Aerial Video Sequences</font>
    </a>
  </h2>
  <font color="black">位相相関を使用してオブジェクトを追跡し、ビデオフレームに沿ってオブジェクト間の空間的配置を取得します。これにより、検出されたオブジェクトを登録し、誤検出を最小限に抑え、ほとんどの誤検出を修正できます。これらに対処するメインフォーム病気は、蚊の繁殖地となる可能性のある場所を探して排除することにより、伝達物質の繁殖を避けることです。 
[要約]これらの病気と戦うための主な形式は、蚊の繁殖地となる可能性のある場所を検索して排除することにより、トランスミッターの繁殖を回避することです。ビデオフレームに沿ってオブジェクト間の空間的配置を取得するために、相関を使用してオブジェクトを追跡します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: PDCOVIDNet: A Parallel-Dilated Convolutional Neural Network Architecture
  for Detecting COVID-19 from Chest X-Ray Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_48.html">
      <font color="black">PDCOVIDNet: A Parallel-Dilated Convolutional Neural Network Architecture
  for Detecting COVID-19 from Chest X-Ray Images</font>
    </a>
  </h2>
  <font color="black">両方の可視化方法は、最後の畳み込み層の特徴マップに関連する特定の画像カテゴリの勾配を計算して、クラス識別領域を作成します。最初に、公的に利用可能な胸部X線コレクションが完全にプリロードおよび拡張され、提案された方法で分類されます。 ..初期のいくつかの研究では、患者の胸部X線画像に異常があることが明らかになりました。これは、COVID-19に感染した患者には自然なことです。 
[要約]合計2 905件の胸部X線画像を使用して585枚の画像を作成しました。これらには、covid-19、正常、またはウイルス性肺炎の症例の58％が含まれていました。提案された方法は、疑われる疾患に関連するパフォーマンスも改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: SipMask: Spatial Information Preservation for Fast Image and Video
  Instance Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_49.html">
      <font color="black">SipMask: Spatial Information Preservation for Fast Image and Video
  Instance Segmentation</font>
    </a>
  </h2>
  <font color="black">さらに、マスク予測とオブジェクト検出をより適切に関連付けるために、マスクアライメントの重み付け損失と機能アライメントスキームを導入しました。単一ステージのインスタンスセグメンテーションアプローチは、その速度とシンプルさのために最近人気を得ていますが、比較すると精度が遅れています。 2段階の方法へ。SipMaskは、最先端の1段階のTensorMaskと比較して、1.0％（マスクAP）の絶対ゲインを取得し、4倍のスピードアップを実現します。 
[ABSTRACT] sipmaskは、高速化された一段階の清算方法のインスタンスです。検出されたバウンディングボックスの異なるサブ領域にインスタンスの軽い予測を組み合わせます。また、空間的に隣接するインスタンスの正確な描写を可能にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Camera-Based Piano Sheet Music Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_50.html">
      <font color="black">Camera-Based Piano Sheet Music Identification</font>
    </a>
  </h2>
  <font color="black">動的n-gramフィンガープリントと呼ばれる新しいハッシュスキームを提案します。これにより、実行時間を大幅に短縮すると同時に、検索精度を向上させます。最初に、IMSLPデータセット全体ですべてのピアノ楽譜画像を使用して、以前の研究よりもはるかに大きなスケールで問題を調査します。検索可能なデータベースとして。以前に提案された楽譜検索のためのフィンガープリント法は、リアルタイムのアプリケーションには遅すぎることを示し、その欠点を診断します。 
[ABSTRACT]新しい方法は、入力クエリとして楽譜の携帯電話の画像を使用します。新しい方法は、データ量の分析に使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: GANHopper: Multi-Hop GAN for Unsupervised Image-to-Image Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_51.html">
      <font color="black">GANHopper: Multi-Hop GAN for Unsupervised Image-to-Image Translation</font>
    </a>
  </h2>
  <font color="black">私たちのネットワークは、中間の画像なしで、2つのドメインからのペアになっていない画像のみでトレーニングされます。すべてのホップは、各方向に沿って単一のジェネレーターを使用して生成されます。標準のサイクルの一貫性と敵対的な損失に加えて、新しいハイブリッド識別器。これは、ジェネレーターによって生成された中間画像を、所定のホップカウントに基づいた重み付きの重み付きハイブリッドとして分類するようにトレーニングされています。 
[ABSTRACT]画像は、各方向に1つのジェネレーターを使用して生成されます。各ホップの大きさを制限するための滑らかさの項が含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-24">
        <br><font color="black">2020-02-24</font>
      </time>
    </span>
</section>
<!-- paper0: Linear Attention Mechanism: An Efficient Attention for Semantic
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_52.html">
      <font color="black">Linear Attention Mechanism: An Efficient Attention for Semantic
  Segmentation</font>
    </a>
  </h2>
  <font color="black">セマンティックセグメンテーションで行われた実験は、線形注意メカニズムの有効性を実証しました。コードはhttps://github.com/lironui/Linear-Attention-Mechanism。で入手できます。このペーパーでは、この欠陥を修正するために、線形注意メカニズムを提案します。メモリと計算コストがはるかに少なく、ドット積の注意に近いものです。 
[ABSTRACT]効率的な設計により、注意メカニズムとニューラルネットワークの統合がより柔軟で多用途に</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Transfer Learning without Knowing: Reprogramming Black-box Machine
  Learning Models with Scarce Data and Limited Resources -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_53.html">
      <font color="black">Transfer Learning without Knowing: Reprogramming Black-box Machine
  Learning Models with Scarce Data and Limited Resources</font>
    </a>
  </h2>
  <font color="black">ゼロ次の最適化とマルチラベルマッピングテクニックを使用して、BARは、モデルアーキテクチャを知らない、またはパラメーターを変更せずに、入出力応答のみに基づいてブラックボックスMLモデルを再プログラムできます。現在の伝達学習方法は、主に事前学習済みの微調整に基づいていますターゲットドメインデータを使用したモデル。データの摂動を介してモデル予測を操作できる敵対的機械学習（ML）の手法に動機付けられており、このホワイトペーパーでは、新しいアプローチであるブラックボックス敵対再プログラミング（BAR）を提案します。は、特にデータが不足してリソースが制約されているシナリオで、さまざまなMLタスクを解決するために、よくトレーニングされたブラックボックスMLモデル（予測APIや独自のソフトウェアなど）を再利用します。 
[ABSTRACT]新しいアプローチであるブラックボックスの敵対的再プログラミング（バー）は、データの摂動を介してモデル予測を操作するために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-17">
        <br><font color="black">2020-07-17</font>
      </time>
    </span>
</section>
<!-- paper0: A SLAM Map Restoration Algorithm Based on Submaps and an Undirected
  Connected Graph -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_54.html">
      <font color="black">A SLAM Map Restoration Algorithm Based on Submaps and an Undirected
  Connected Graph</font>
    </a>
  </h2>
  <font color="black">多くの視覚的同時定位およびマッピング（SLAM）システムは、正確で堅牢であることが示され、屋内と地上の両方のデータセットでリアルタイムのパフォーマンス機能を備えています。多くのアプリケーションで問題となっている、欠けているマップの問題を解決するには、追跡が失われ、単眼視覚SLAMに基づいて、対応する無向接続グラフを介してサブマップを順次マージすることにより、UAVデータセットの完全なグローバルマップを再構築する方法を示します。提案された方法のパフォーマンスを示すために、最初にUAVデータセットでのパフォーマンス、および実験結果は、いくつかの追跡の失敗の場合、マッピングの整合性が現在の主流のSLAMメソッドの整合性よりもはるかに優れていることを示しました。 
[ABSTRACT]多くのビジュアルスラムシステムは、再配置戦略を使用して、欠けているマップの問題を修正します。追跡は失われましたが、新しい方法をツールとして使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Can Your Face Detector Do Anti-spoofing? Face Presentation Attack
  Detection with a Multi-Channel Face Detector -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_55.html">
      <font color="black">Can Your Face Detector Do Anti-spoofing? Face Presentation Attack
  Detection with a Multi-Channel Face Detector</font>
    </a>
  </h2>
  <font color="black">提案されたシステムは、個別のプレゼンテーション攻撃検出モジュールの必要をなくすライブフェイス検出器として使用でき、追加の計算オーバーヘッドなしで実際にシステムの信頼性を高めます。主なアイデアは、単一ステージのオブジェクト検出フレームワークを活用することです。 PADタスクの異なるチャネルから得られた共同表現を使用します。提案されたフレームワークの有効性を示すために、さまざまな攻撃を含むマルチチャネルWMCAデータセットでのアプローチを評価しました。 
[要約]顔検出器を使用して、マルチチャネル顔検出器を作成できます。システムは、顔検出器のツールとして簡単に識別できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br><font color="black">2020-06-30</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Architecture Search for Compressed Sensing Magnetic Resonance
  Image Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_56.html">
      <font color="black">Neural Architecture Search for Compressed Sensing Magnetic Resonance
  Image Reconstruction</font>
    </a>
  </h2>
  <font color="black">最近の研究により、ディープラーニング（DL）ベースの圧縮センシング（CS）実装は、サブサンプリングされたk空間データからMR画像を再構成することにより、磁気共鳴（MR）イメージングを加速できることが実証されています。ハイパーパラメータがどのように影響するかを分析するために、広範な実験が行われました。特に、モデル駆動型MR再構成パイプラインに統合された特定のセル構造が、事前定義された柔軟な操作検索スペースから差別化可能な方法で自動的に検索されました。 
[ABSTRACT]以前の方法で採用されたネットワークアーキテクチャはすべて手作りで設計されています。以前の試みで使用されたネットワークアーキテクチャはすべて手作りで開発されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-22">
        <br><font color="black">2020-02-22</font>
      </time>
    </span>
</section>
<!-- paper0: Sample Efficient Interactive End-to-End Deep Learning for Self-Driving
  Cars with Selective Multi-Class Safe Dataset Aggregation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_57.html">
      <font color="black">Sample Efficient Interactive End-to-End Deep Learning for Self-Driving
  Cars with Selective Multi-Class Safe Dataset Aggregation</font>
    </a>
  </h2>
  <font color="black">このアプローチには過去にいくつかの成功したデモンストレーションがありましたが、適切なポリシーを学習するには、エキスパートドライバーからの多くのサンプルが必要になる可能性があり、リソースを消費する可能性があります。エキスパートポリシーからディープニューラルネットワークをこのデータにフィッティングして方針の推進..パフォーマンスが低い軌道セグメントが特定されると、サンプリングアルゴリズムは、これらのセグメントに対してのみエキスパートポリシーの呼び出しに焦点を当て、収束率を向上させます。 
[ABSTRACT]効果的な方法は、自動運転車のポリシーの高度な知識を使用します。システムは、安全な日付セット集計（安全な短剣）アプローチに基づいています。現在学習したポリシーは、自動的に異なる軌跡分析にセグメント化されます。メソッドは、標準と比較して大幅に優れたパフォーマンスを生み出します。安全な短剣アルゴリズム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Simultaneously Learning Corrections and Error Models for Geometry-based
  Visual Odometry Methods -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_58.html">
      <font color="black">Simultaneously Learning Corrections and Error Models for Geometry-based
  Visual Odometry Methods</font>
    </a>
  </h2>
  <font color="black">自動運転画像シーケンスの実験は、視覚オドメトリを同時に改善する可能性を評価し、その出力に関連するエラーを推定します。視覚オドメトリプロセスに固有のバイアスを忠実に学習および補償できること、および確率論的損失関数に関連付けられた学習アーキテクチャが残差の完全共分散行列を共同で推定して、プロセスの異分散性を捉えたエラーモデル。 
[要約]確率的損失関数に関連付けられた学習アーキテクチャは、残差エラーの完全な共分散行列を共同で推定できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Composer Style Classification of Piano Sheet Music Images Using Language
  Model Pretraining -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_59.html">
      <font color="black">Composer Style Classification of Piano Sheet Music Images Using Language
  Model Pretraining</font>
    </a>
  </h2>
  <font color="black">最初にラベルなしデータのセットで言語モデルをトレーニングし、事前学習済みの言語モデルの重みで分類子を初期化してから、少量のラベル付きデータで分類子を微調整することにより、分類子のパフォーマンスを大幅に改善できることを示します。このトランスベースのアーキテクチャはCNNおよびLSTMモデルよりも優れており、事前トレーニングにより、GPT-2モデルの分類精度が9ウェイ分類タスクで46 \％から70 \％に向上します。このペーパーでは、ピアノ楽譜画像の作曲家スタイルの分類を研究します。 。 
[ABSTRACT]ピアノ楽譜の画像は、分析の分析に使用されます。システムは、システムが機能しないことを確認するために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Pooling Regularized Graph Neural Network for fMRI Biomarker Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_60.html">
      <font color="black">Pooling Regularized Graph Neural Network for fMRI Biomarker Analysis</font>
    </a>
  </h2>
  <font color="black">機能的磁気共鳴画像法（fMRI）によって構築された脳ネットワーク。具体的には、ノードプーリングスコアに基づいて特定の疾患を特定するためにどのROIが重要であるかを推測できるように、注目の関心領域（ROI）を強調する新規の正規化されたプーリングレイヤーを設計します。プーリング層によって計算されます。提案されたフレームワーク、プーリング正則化GNN（PR-GNN）は、合理的なROI選択を促進し、個人レベルまたはグループレベルのパターンを保持する柔軟性を提供します。 
[要旨]顕著な領域を特定するための有望なアプローチは、グラフ構造化データを分析するために使用できるグラフニューラルネットワーク（gnns）を使用しています。関連する神経学的脳バイオマーカーを決定するための新しい顕著領域選択メカニズムを備えた解釈可能なgnnフレームワークを提案します障害</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Force myography benchmark data for hand gesture recognition and transfer
  learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_61.html">
      <font color="black">Force myography benchmark data for hand gesture recognition and transfer
  learning</font>
    </a>
  </h2>
  <font color="black">このようなデータの1つの使用例を示し、転移学習を利用して他の複数の人からのデータを組み込むことでジェスチャー認識の精度を向上させる方法を示します。これは、データセットが転移学習アルゴリズムの研究を容易にするベンチマークデータセットとして機能できることも示しています。 ..私たちは、結果をさらに比較し、この研究分野へのより簡単なエントリーを可能にすることを期待して、18のユニークなジェスチャーをカバーする20人から市販のセンサー設定を使用して収集したベンチマークデータセットにアクセスできるようにすることで、この分野の進歩に貢献します。 。 
[ABSTRACT]公開されているベンチマークデータが不足しています。ほとんどの既存の研究では、カスタムハードウェアを使用して独自のデータを収集することがよくあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal Spatial Attention Module for Targeting Multimodal PET-CT Lung
  Tumor Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_62.html">
      <font color="black">Multimodal Spatial Attention Module for Targeting Multimodal PET-CT Lung
  Tumor Segmentation</font>
    </a>
  </h2>
  <font color="black">以前の自動セグメンテーション方法は、PETおよびCTモダリティとは別に抽出された融合情報に主に焦点を当て、各モダリティには補足情報が含まれるという根本的な仮定がありました。癌の。しかし、これらの方法は、セグメンテーションを導くことができる高いPET腫瘍感度を十分に活用していません。 
[要約]これは、マルチモーダル空間注意モジュール（msam）を導入する最初のステップです。これは、セグメンテーションに関連する領域（空間領域）を強調し、生理学的摂取量が多い正常領域を抑制することを自動的に学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Tracking against Adversarial Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_63.html">
      <font color="black">Robust Tracking against Adversarial Attacks</font>
    </a>
  </h2>
  <font color="black">提案された敵対的攻撃および防御アプローチを最先端のディープトラッキングアルゴリズムに適用します。一方で、元のビデオシーケンスに一時的な摂動を敵対的な例として追加して、追跡パフォーマンスを大幅に低下させます。この作業では、まず、ビデオシーケンスの上に敵対的な例を生成して、敵対的な攻撃に対する追跡の堅牢性を向上させることを試みます。 
[ABSTRACT]防御方法は、敵対的な攻撃によって引き起こされる大幅なパフォーマンスの低下を排除しますが、ディープトラッカーが敵対的な攻撃を受けていない場合にも追加のビデオパターンを実現します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-20">
        <br><font color="black">2020-07-20</font>
      </time>
    </span>
</section>
<!-- paper0: BiTraP: Bi-directional Pedestrian Trajectory Prediction with Multi-modal
  Goal Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_64.html">
      <font color="black">BiTraP: Bi-directional Pedestrian Trajectory Prediction with Multi-modal
  Goal Estimation</font>
    </a>
  </h2>
  <font color="black">BiTraPは、軌道の目標（エンドポイント）を推定し、新規の双方向デコーダーを導入して、長期の軌道予測精度を向上させます。また、CVAEのノンパラメトリックターゲットモデルとパラメトリックターゲットモデルのさまざまな選択が、予測される予測に直接影響することも示しています。マルチモーダル軌道分布..広範な実験は、BiTraPが一人称視点（FPV）と鳥瞰図（BEV）の両方のシナリオに一般化し、最先端の結果を約10-50％上回ることを示しています。 
[ABSTRACT]ロボットは、条件付き変分オートエンコーダ（cvae）とリカレントニューラルネットワーク（rnns）を使用して、観測された軌跡をエンコードし、マルチモーダルな将来のtrajectories.bitrapをデコードします。 、bitrap（fpv）に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Classification with 2-D Convolutional Neural Networks for breast cancer
  diagnosis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_65.html">
      <font color="black">Classification with 2-D Convolutional Neural Networks for breast cancer
  diagnosis</font>
    </a>
  </h2>
  <font color="black">VGGnet-16を使用してCNNで処理された変換済みデータは、WBCデータセットの競合結果を示し、WDBCデータセットの他の既知の方法よりも優れています。ウィスコンシン元乳がん（WBC）およびウィスコンシン診断乳がん（WDBC）データセットでメソッドをテストしました。 。私たちの知る限り、この作品は、非時系列データの非画像から画像へのデータ変換に関する小説です。 
[ABSTRACT] cnnは、隣接する要素との相関関係を示すデータを含む2次元行列のセットで機能するように設計されています。これらには、cnnで処理するために必要なデータ量を示す3dモデルが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: On the Comparison of Classic and Deep Keypoint Detector and Descriptor
  Methods -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_66.html">
      <font color="black">On the Comparison of Classic and Deep Keypoint Detector and Descriptor
  Methods</font>
    </a>
  </h2>
  <font color="black">テストされた実装の実行時間に関しては、SuperPointモデルが最速で、次にORBが続きます。私たちのベンチマークは、さまざまな幾何学的および照明の変化の下で実際の多様な画像を提供するHPSequencesデータセットに依存しています。結果は、特定の古典的で深いいくつかの古典的な検出器と記述子の組み合わせが事前学習済みのディープモデルを上回っているため、アプローチは依然として比較可能です。 
[ABSTRACT]ベンチマークは、実際の多様な画像を提供するhpsequencesデータセットに依存しています。一部のクラシックおよびディープアプローチは、いくつかのクラシックディテクターと比較できます-事前トレーニング済みのディープモデルを実行する記述子の組み合わせ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-20">
        <br><font color="black">2020-07-20</font>
      </time>
    </span>
</section>
<!-- paper0: Demystifying Contrastive Self-Supervised Learning: Invariances,
  Augmentations and Dataset Biases -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_67.html">
      <font color="black">Demystifying Contrastive Self-Supervised Learning: Invariances,
  Augmentations and Dataset Biases</font>
    </a>
  </h2>
  <font color="black">MOCOやPIRLのようなアプローチがオクルージョン不変の表現を学習することを示します。次に、これらのアプローチがImagenetのようなクリーンなオブジェクト中心のトレーニングデータセットへのアクセスからさらなる利益を得ることを示します。この作業では、最初に定量的な実験を説明して説明します。これらの利益。 
[ABSTRACT]私たちは、mocoやpirlのようなアプローチがオクルージョン（有形の表現）を学習することを実証しました。また、クリーンオブジェクトへのアクセスも学習します-imagenetのような中心的なトレーニングデータセット</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Video Representations from Textual Web Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_68.html">
      <font color="black">Learning Video Representations from Textual Web Supervision</font>
    </a>
  </h2>
  <font color="black">Kinetics、HMDB-51、UCF-101など、いくつかの下流のアクション認識タスクでモデルを微調整します。インターネット上で見つかったビデオは、タイトルや説明などのテキストとペアになっています。具体的には、すべてのベンチマークでゼロからのトレーニングを改善し、自己監視およびウェブ監視ビデオ表現学習の多くの方法より優れており、HMDB-51で2.2％の精度の向上を実現します。 
[ABSTRACT]これらの動画がインターネットで発見されたのは今回が初めてです。各動画を関連するテキストとペアにするモデルをトレーニングすることを目的としています。これらのアプローチは、動画表現を事前トレーニングする効果的な方法です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Accurate 2D soft segmentation of medical image via SoftGAN network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_69.html">
      <font color="black">Accurate 2D soft segmentation of medical image via SoftGAN network</font>
    </a>
  </h2>
  <font color="black">この問題に対処するために、CT画像の超解像およびセグメンテーションタスクに対処するための新規のカスケード生成敵対的ネットワーク（CasGAN）を提案します。ここでは、正確な病変表現に関するセマンティックソフトセグメンテーションフォームが、私たちの知識に従って初めて導入されました。 RECISTの弱い監視情報に基づく高品質の大規模なアノテーションデータの迅速な取得を促進できるセグメンテーション後、病変のエッジを正確に保持できます。医療用コンピューター断層撮影（CT）画像からの正確な2D肺結節セグメンテーションは、医療アプリケーションで重要です..加えて、我々はさらなる研究のために医療用CT画像の挑戦的な肺結節ソフトセグメンテーションデータセットを提供します。 
[ABSTRACT]最新のアプローチでは、正確なセグメンテーション結果を達成できます。結果は、肺結節の形状の最も小さな、複雑さ、および不規則性に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Active Learning for Video Description With Cluster-Regularized Ensemble
  Ranking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_70.html">
      <font color="black">Active Learning for Video Description With Cluster-Regularized Ensemble
  Ranking</font>
    </a>
  </h2>
  <font color="black">トランスフォーマーとLSTMベースのキャプションモデルの両方を使用して、MSR-VTTおよびLSMDCデータセットに対するアプローチを評価し、最新の強力なベースラインよりも最大60％少ないトレーニングデータを使用しながら、新しい戦略で高いパフォーマンスを実現できることを示します。学習は、ビデオキャプションタスクのトレーニングセットを効率的に構築しながら、情報のない例に手動でラベルを付ける必要性を減らす有望な方法です。自動ビデオキャプションは、ビデオのすべてのセグメントのテキスト説明を生成するようにモデルをトレーニングすることを目的としていますが、最も効果的なアプローチです。低速で高価な大量の手動注釈が必要です。 
[ABSTRACT]アクティブラーニングは、ビデオキャプションタスクのトレーニングセットを効率的に構築する一方で、情報のない例に手動でラベルを付ける必要性を減らすための有望な方法です。新しい戦略では、強力な状態よりも最大60％少ないトレーニングデータを使用しながら高いパフォーマンスを達成できます。アートのベースライン</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Simplicial Complex based Point Correspondence between Images warped onto
  Manifolds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_71.html">
      <font color="black">Simplicial Complex based Point Correspondence between Images warped onto
  Manifolds</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチの正確さとロバスト性は、グラウンドトゥルースの対応が既知の合成画像と現実世界の球形/ワープ（投影）画像の両方に示されています。この論文では、割り当て問題を、2つのグラフによって誘導された単体間の全単射マップを見つけることとして提起します。グラフのより高次の類似体である複合体。私たちは、最高から最低の次元まで反復する、単体の複合体の各pスケルトンに一致する制約付き2次割り当て問題（QAP）を提案します。 
[ABSTRACT]既存の方法は3D画像を「平坦化」して平面グラフ/ハイパーグラフマッチング方法を使用しますが、深刻な歪みやその他の望ましくないアーティファクトが発生し、不正確なマッチングが発生します。したがって、これらのワープした画像のマッチングは手ごわい課題として残ります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-05">
        <br><font color="black">2020-07-05</font>
      </time>
    </span>
</section>
<!-- paper0: CommuNety: A Deep Learning System for the Prediction of Cohesive Social
  Communities -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_72.html">
      <font color="black">CommuNety: A Deep Learning System for the Prediction of Cohesive Social
  Communities</font>
    </a>
  </h2>
  <font color="black">私たちはPIPAデータセットで提案された手法を広範囲に評価し、最先端の方法と比較します。実験結果は、さまざまな個人とコミュニティの凝集性との関係を予測するための提案された手法の優れたパフォーマンスを示しています。テキストデータには、ソーシャルユーザーとその関連グループに関する重要な情報が不足しています。 
[ABSTRACT]この論文では、images.proposedメソッドを使用した凝集性ソーシャルネットワークの予測のためのディープラーニングシステムであるサブセット性を提案します。提案された方法は、凝集性ソーシャルネットワークについて学習することを含みます。また、人の存在を定量化する新しい顔共起頻度アルゴリズムを提案します画像で</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Voice Puppetry: Audio-driven Facial Reenactment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_73.html">
      <font color="black">Neural Voice Puppetry: Audio-driven Facial Reenactment</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチはさまざまな人々を対象に一般化されており、未知のソースアクターの音声や、標準の音声合成アプローチを使用して生成できる合成音声でさえ、ターゲットアクターのビデオを合成できます。基礎となる3D表現を通じて、モデルニューラルレンダリングを利用して写真のようにリアルな出力フレームを生成しながら、本質的に時間的安定性を学習します。ニューラルボイスパペットには、オーディオ駆動のビデオアバター、ビデオダビング、トーキングヘッドのテキスト駆動のビデオ合成など、さまざまなユースケースがあります。 
[要旨]対象人物の写真のようなリアルな出力ビデオを作成します。ソース人物のオーディオシーケンスに基づいて、対象人物の写真のビデオを生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-11">
        <br><font color="black">2019-12-11</font>
      </time>
    </span>
</section>
<!-- paper0: Matching Images and Text with Multi-modal Tensor Fusion and Re-ranking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_74.html">
      <font color="black">Matching Images and Text with Multi-modal Tensor Fusion and Re-ranking</font>
    </a>
  </h2>
  <font color="black">次に、テスト中に、追加のトレーニング手順を必要とせずに、改良のための汎用的なクロスモーダル再ランキング（RR）スキームを展開します。ただし、これらのアプローチのいずれも、マッチングの精度とモデルの複雑さのバランスをとることはできません。実装コードはhttps://github.com/Wangt-CN/MTFN-RR-PyTorch-Codeで入手できます。 
[ABSTRACT]ほとんどの既存のアプローチは、埋め込みまたは分類に基づいています。最初の1つは、距離測定のために画像とテキストインスタンスを共通の埋め込みスペースにマッピングします。2つ目は画像に関するものです-バイナリ分類問題としてのテキストマッチング</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-12">
        <br><font color="black">2019-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Online Visual Place Recognition via Saliency Re-identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_75.html">
      <font color="black">Online Visual Place Recognition via Saliency Re-identification</font>
    </a>
  </h2>
  <font color="black">人間は常に、他よりも魅力的または興味深い突出領域またはランドマークを覚えることによって場所を認識するという事実に触発されて、視覚的な場所認識を顕著性再識別として公式化します。提案された方法はオープンソースであり、https： //github.com/wh200720041/SRLCD.git ..実験は、提案された方法が最新の機能ベースの方法よりも競争力のある精度とはるかに高速を達成することを示しています。 
[ABSTRACT]既存の方法では、視覚的な場所の認識を特徴のマッチングとして定式化することがよくあります。提案された方法はオープンであり、ソースとしてwwwから利用できます。よりもgithub</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Realistic Video Summarization through VISIOCITY: A New Benchmark and
  Evaluation Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_76.html">
      <font color="black">Realistic Video Summarization through VISIOCITY: A New Benchmark and
  Evaluation Framework</font>
    </a>
  </h2>
  <font color="black">VISIOCITYに存在する間接的なグラウンドトゥルースから複数のリファレンスサマリーを自動的に生成するパレート最適性に基づく新しいレシピを紹介します。さまざまな測定を使用して評価されたVISIOCITYに関するビデオ要約のいくつかの代表的なテクニックのパフォーマンスを報告し、テクニックの限界を引き出します。および/または人間の判断をモデル化する際の評価メカニズム。そのための評価フレームワークの有効性を実証します。次に、長いビデオの場合、人間のリファレンスサマリーを取得することは困難です。 
[ABSTRACT] visiocityは、6つの異なるカテゴリにまたがるより長い動画で構成される新しいベンチマークデータセットです。これには、さまざまな種類の動画要約をサポートできる高密度のコンセプトアノテーションが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Clarinet: A One-step Approach Towards Budget-friendly Unsupervised
  Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_77.html">
      <font color="black">Clarinet: A One-step Approach Towards Budget-friendly Unsupervised
  Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">この問題を緩和するために、ターゲットドメインの分類子をソースドメインからの補完ラベルデータと予算に適したUDA（BFUDA）という名前のターゲットドメインからのラベルなしデータでトレーニングする必要がある新しい問題設定を検討します。最後に、BFUDA問題を解決するために、補完的なラベル敵対ネットワーク（CLARINET）が提案されています。実験は、CLARINETが一連の有能なベースラインを大幅に上回ることを示しています。 
[ABSTRACT]問題を完全に収集することは困難-正しい-限られた予算でソースドメインのデータにラベルを付ける</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Advancing Visual Specification of Code Requirements for Graphs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CV/paper_78.html">
      <font color="black">Advancing Visual Specification of Code Requirements for Graphs</font>
    </a>
  </h2>
  <font color="black">人文科学研究者が視覚化をプログラムする方法を学ぶための障壁を下げるために、ユーザーがコード要件を視覚的に指定できるようにします。このペーパーでは、機械学習を使用してデータの有意義な視覚化を作成することに焦点を当てています。まだ存在する主要なハードルの1つは、このデータの視覚化をプロジェクトに組み込んでいます。 
[ABSTRACT]研究者は、pythonやrなどのプログラミング言語を視覚化に使用し始めています。また、対応するライブラリを使用して大規模なデータセットを操作しています。これらは、正式なトレーニングを受けている場合でも、使用方法を学ぶのが困難です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Women worry about family, men about the economy: Gender differences in
  emotional responses to COVID-19 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CL/paper_0.html">
      <font color="black">Women worry about family, men about the economy: Gender differences in
  emotional responses to COVID-19</font>
    </a>
  </h2>
  <font color="black">女性は愛する人と深刻な健康問題を心配しているが、男性は経済と社会への影響に専念していた。さらに、ii）感情的な反応に関するトピックでマークされた性差を発見した。この論文は、一般的な性差の理解に追加する他の場所で見つかった言語で、現在のユニークな状況がこれらの影響をおそらく増幅したことを示しています。 
[ABSTRACT]我々の調査結果は、短いテキストは長いテキストほど心理プロセスへの適切な洞察を提供しないことを示唆しています。男性は経済や社会への影響に専念している一方で、女性は愛する人や深刻な健康問題について心配しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-17">
        <br><font color="black">2020-04-17</font>
      </time>
    </span>
</section>
<!-- paper0: Enriching Video Captions With Contextual Text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CL/paper_1.html">
      <font color="black">Enriching Video Captions With Contextual Text</font>
    </a>
  </h2>
  <font color="black">ビデオコンテンツを理解し、コンテキストを使用してキャプションを生成することは、重要で挑戦的なタスクです。視覚的な入力に基づいて、モデルは、ポインタージェネレーターネットワークを介してコンテキストテキストから単語をコピーし、より具体的なビデオキャプションを作成できます。視覚的な入力に基づいてビデオキャプションを生成し、コンテキストテキストから名前や場所などの関連知識をマイニングするエンドツーエンドのシーケンスツーシーケンスモデルを提案します。 
[ABSTRACT]ニュースビデオデータセットで競争力のあるパフォーマンスを示します。アブレーション調査を通じて、コンテキストに応じたビデオキャプションの有効性を検証します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Mirostat: A Perplexity-Controlled Neural Text Decoding Algorithm -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CL/paper_2.html">
      <font color="black">Mirostat: A Perplexity-Controlled Neural Text Decoding Algorithm</font>
    </a>
  </h2>
  <font color="black">ここでは、最初にtop-k、top-p、および温度サンプリングでの複雑さの理論的分析を提供します。クロスエントロピーは、top-pサンプリングではpの関数としてほぼ線形に動作しますが、kの非線形関数です。 top-kサンプリング、Zipfian統計..実験では、top-kとtop-pサンプリングでkとpの値が低い場合、生成されたテキストの長さによってperplexityが大幅に低下し、テキストの過度の繰り返し（退屈なトラップ）。したがって、特定の言語モデルでは、混乱を制御することで繰り返しを制御することもできます。 
[ABSTRACT] top-k、top-p（nucleus）、および温度ベースのサンプリングは、言語モデルの信頼性の低い低確率の尾部を切り捨てるか、歪めます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: #Brexit: Leave or Remain? The Role of User's Community and Diachronic
  Evolution on Stance Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CL/paper_3.html">
      <font color="black">#Brexit: Leave or Remain? The Role of User's Community and Diachronic
  Evolution on Stance Detection</font>
    </a>
  </h2>
  <font color="black">分類実験は、そのような機能がスタンスを検出するための非常に有用な手がかりを提供することを示しています。TwitterのBREXIT国民投票に関する英国での政治的議論を分析し、機能の役割を調査することを主目的として、スタンス検出のための新しいアプローチと注釈スキーマを提案しましたソーシャルネットワークコミュニティと通時的なスタンスの進化に関連します。さらに、スタンスはディクロベートな視点で研究する必要があります。これは、ディベート中に記録できるユーザーの意見の変化のダイナミクスに光を当てるのに役立つためです。 
[要約]ソーシャルネットワークコミュニティと通時的なスタンスの進化に関連する機能の役割を検出する主な目的</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Development of POS tagger for English-Bengali Code-Mixed data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CL/paper_4.html">
      <font color="black">Development of POS tagger for English-Bengali Code-Mixed data</font>
    </a>
  </h2>
  <font color="black">私たちのシステムは100のPOSタグ付きのコード混合文を使用してチェックされ、75.29％の精度を返しました。 2つのシステムによって与えられたタグは後で結合され、最終結果はユニバーサルPOSタグセットにマッピングされます。これらのツイートは、システムを構築するための開発データセットとして使用されました。 
[ABSTRACT]システムは英語-ベンガル語コード-ベンガル語がローマ字で書かれた混合データにposタグを付けることができます。システムを構築するための開発データセットとして、tweetsが使用されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: g2pM: A Neural Grapheme-to-Phoneme Conversion Package for
  MandarinChinese Based on a New Open Benchmark Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CL/paper_5.html">
      <font color="black">g2pM: A Neural Grapheme-to-Phoneme Conversion Package for
  MandarinChinese Based on a New Open Benchmark Dataset</font>
    </a>
  </h2>
  <font color="black">これらに動機づけられて、この研究では、中国のポリフォン曖昧性解消のための99,000以上の文で構成される新しいベンチマークデータセットを紹介します。それに対処するために多くの学術的努力が行われましたが、標準的なベンチマークとして機能するオープンなデータセットはありませんこれまでの公平な比較のために。単純なニューラルネットワークモデルをトレーニングし、他の既存のG2Pシステムよりも優れていることを確認します。 
[要約]報告されたシステムのほとんどは、中国語のテキストを中国語に変換したい研究者や実務家に採用するのが難しい</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br><font color="black">2020-04-07</font>
      </time>
    </span>
</section>
<!-- paper0: Presentation and Analysis of a Multimodal Dataset for Grounded
  LanguageLearning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CL/paper_6.html">
      <font color="black">Presentation and Analysis of a Multimodal Dataset for Grounded
  LanguageLearning</font>
    </a>
  </h2>
  <font color="black">この作業では、話し言葉または書き言葉のいずれかを使用して記述された一般的な家庭用オブジェクトのマルチモーダルデータセットであるGrounded Language Dataset（GoLD）を示します。これにより、ロボット工学、NLP、およびHCIの共通部分を研究する研究者は、画像、テキスト、音声の複数のモダリティが相互作用し、これらのモダリティの固有の違いが結果に影響を与えることを示します。違いを分析し、異なるモダリティが人間の入力からの言語学習にどのように影響するかを示す実験を提示します。 
[要約]研究は、さまざまなモダリティが人間の言語学習にどのように影響するかを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Object-and-Action Aware Model for Visual Language Navigation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CL/paper_7.html">
      <font color="black">Object-and-Action Aware Model for Visual Language Navigation</font>
    </a>
  </h2>
  <font color="black">ビジョンと言語のナビゲーション（VLN）は、可視環境に基づいて、比較的一般的な自然言語の命令をロボットエージェントのアクションに変換する必要があるという点で独特です。このホワイトペーパーでは、オブジェクトとアクションを認識するモデルを提案します。 （OAAM）は、これら2つの異なる形式の自然言語ベースの命令を個別に処理します。1つ目はオブジェクトの説明（たとえば、「テーブル」、「ドア」）であり、それぞれがエージェントを見つけて次のアクションを決定するためのヒントとして提示されます。環境で表示されるアイテム。2つ目は、ロボットが視覚に依存せずに次の動きを直接予測できるようにするアクション仕様（たとえば、「直進」、「左折」）です。 
[ABSTRACT]これは、2つの非常に異なるタイプの自然言語情報から値を抽出する必要があります。これは、オブジェクト中心の命令またはアクションベースの命令に適用されます。これにより、各プロセスがオブジェクトに一致します-中心/アクション中心の命令、独自の対応する視覚認識</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Text Complexity Classification Based on Linguistic Information:
  Application to Intelligent Tutoring of ESL -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CL/paper_8.html">
      <font color="black">Text Complexity Classification Based on Linguistic Information:
  Application to Intelligent Tutoring of ESL</font>
    </a>
  </h2>
  <font color="black">スケーラビリティ評価は、そのような分類子が実際のアプリケーション内で使用できるかどうかをテストするために行われました。たとえば、検索エンジンやWebスクレイピングモジュールにプラグインできます。すでに作成されている6171テキストのコーパスを使用します。 ESLの専門家によって3つの異なるレベルの難易度に分類され、5つの機械学習アルゴリズムを使用してさまざまな実験が行われました。したがって、観測された結果は、実際のアプリケーション内でのこのような分類子の使いやすさを確認します。 
[ABSTRACT]結果は、採用された言語機能が優れた全体的な分類パフォーマンスを提供することを示しました（f-スコア= 0. 97）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-07">
        <br><font color="black">2020-01-07</font>
      </time>
    </span>
</section>
<!-- paper0: Biomedical and Clinical English Model Packages in the Stanza Python NLP
  Library -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CL/paper_9.html">
      <font color="black">Biomedical and Clinical English Model Packages in the Stanza Python NLP
  Library</font>
    </a>
  </h2>
  <font color="black">Stanza Python NLPライブラリの生物医学および臨床英語モデルパッケージを紹介します。パッケージのデモンストレーションは、http：//stanza.run/bio。で入手できます。私たちのパッケージは、構文解析と名前付きエンティティを実現することを、広範な実験を通じて示しています。最先端の結果と同等またはそれ以上の認識パフォーマンス
[ABSTRACT]これらのモデルは、医学および臨床テキストの正確な生物戦術分析および名前付きエンティティ認識機能を提供します。さらに、これらのモデルは、gpuアクセラレーションが利用可能な場合、既存のツールキットと比較して速度を低下させない</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Active Learning for Video Description With Cluster-Regularized Ensemble
  Ranking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CL/paper_10.html">
      <font color="black">Active Learning for Video Description With Cluster-Regularized Ensemble
  Ranking</font>
    </a>
  </h2>
  <font color="black">自動ビデオキャプションは、ビデオのすべてのセグメントのテキスト説明を生成するようにモデルをトレーニングすることを目的としていますが、最も効果的なアプローチは、低速で高価な大量の手動アノテーションを必要とします。MSR-VTTおよびLSMDCデータセットに対するアプローチを評価するには、トランスフォーマーとLSTMベースのキャプションモデルの両方を使用して、私たちの新しい戦略が強力な最先端のベースラインよりも最大60％少ないトレーニングデータを使用しながら高いパフォーマンスを実現できることを示しています。また、クラスター規則化されたアンサンブル戦略が、ビデオキャプションのトレーニングセットを効率的に収集するための最良のアクティブ学習アプローチを提供することを示しています。 
[ABSTRACT]アクティブラーニングは、ビデオキャプションタスクのトレーニングセットを効率的に構築する一方で、情報のない例に手動でラベルを付ける必要性を減らすための有望な方法です。新しい戦略では、強力な状態よりも最大60％少ないトレーニングデータを使用しながら高いパフォーマンスを達成できます。アートのベースライン</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: A Computational Analysis of Polarization on Indian and Pakistani Social
  Media -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CL/paper_11.html">
      <font color="black">A Computational Analysis of Polarization on Indian and Pakistani Social
  Media</font>
    </a>
  </h2>
  <font color="black">私たちはハッシュタグの同時発生に焦点を当てたラベル伝播技術を使用して、二極化したツイートとユーザーを見つけます。私たちの仕事は、インドとパキスタン間の緊張の高まりがTwitterにどのように現れているかを初めて分析し、二極化メッセージを研究するためのフレームワークを提供します。 、2019年3月4日、カシミールのプルワマでのテロ攻撃、それに続く報復攻撃により、インドとパキスタン、2つの核武装国の間の緊張が高まりました。 
[要約]カシミール分析は、パキスタンの与党が極性化されたハッシュタグを使用したことを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br><font color="black">2020-05-20</font>
      </time>
    </span>
</section>
<!-- paper0: TERA: Self-Supervised Learning of Transformer Encoder Representation for
  Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/cs.CL/paper_12.html">
      <font color="black">TERA: Self-Supervised Learning of Transformer Encoder Representation for
  Speech</font>
    </a>
  </h2>
  <font color="black">TERAは、音素分類、話者認識、音声認識など、いくつかのダウンストリームタスクで評価されます。モデルは、確率的ポリシーを使用して3次元に沿って変化する確率的ポリシーを使用して、音響フレームの再構築を通じて学習します。時間的、チャネル、そしてマグニチュード。。私たちはTERAと呼ばれる自己教師付き音声事前トレーニング方法を導入します。これは、変圧器エンコーダ表現を変更から表します。 
[要約]モデルは、変更された対応物からの音響フレームの再構成を通じて学習します。これらには、自己回帰予測、自己回帰予測、マスク再構成が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-12">
        <br><font color="black">2020-07-12</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Understanding Optical Music Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.AS/paper_0.html">
      <font color="black">Understanding Optical Music Recognition</font>
    </a>
  </h2>
  <font color="black">このチュートリアルでは、これらの欠点に対処するために、（1）OMRとその関連フィールドとの関係の堅牢な定義を提供し、（2）OMRが音楽の符号化プロセスをどのように反転させて、文書から音符と音楽のセマンティクスを復元するかを分析します（3 ）OMRの分類法を提案し、特にアプリケーションの新しい分類法を提案します。さらに、従来のパイプラインとは対照的に、深層学習が現代のOMR研究にどのように影響するかについても説明します。ただし、新しい研究者がこのフィールドにアクセスすることは依然として困難です。特に重要な音楽的背景のないもの：紹介資料はほとんどなく、さらに、フィールドはそれ自体を定義し、共通の用語を構築することに苦労しています。 
[要約]フィールドはそれ自体の定義とomr。の共有定義の構築に苦労していますが、新しい研究者がアクセスするのは依然として難しい場合があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-07">
        <br><font color="black">2019-08-07</font>
      </time>
    </span>
</section>
<!-- paper0: DNN No-Reference PSTN Speech Quality Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.AS/paper_1.html">
      <font color="black">DNN No-Reference PSTN Speech Quality Prediction</font>
    </a>
  </h2>
  <font color="black">ただし、現在の最先端の音声品質モデルは、ライブモニタリングに使用するには十分な信頼性がありません。検証とテストにおいて、提案された非参照モデルは、完全参照POLQAおよび非参照P.563よりも優れています。この文書では、1000を超えるクラウドソーシングされた実際の電話による新しいオープンソースのPSTN音声品質テストセットを示します。 
[ABSTRACT] pstnの歪みは、プロバイダーや国によって異なる場合があります。これにより、さまざまなネットワークに適切に一般化されるモデルをトレーニングすることが難しくなります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Investigation of Phase Distortion on Perceived Speech Quality for
  Hearing-impaired Listeners -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.AS/paper_2.html">
      <font color="black">Investigation of Phase Distortion on Perceived Speech Quality for
  Hearing-impaired Listeners</font>
    </a>
  </h2>
  <font color="black">ある条件のセットでは、スピーチは-5から10 dBまでの4つの異なる信号対雑音比（SNR）でバブルノイズと混合されました。別の条件のセットでは、SNRは10 dBに固定され、ノイズのあるスピーチがT60が100〜1000ミリ秒のシミュレートされた反響室で発表されました。NHリスナーの音声レベルは65 dB SPLに維持され、可聴性を確保するためにHIリスナーに増幅が適用されました。 
[ABSTRACT]現在の音声強調アルゴリズムは位相の歪みに対処し始めています。ただし、アルゴリズムは通常の聴覚（nh）リスナーに焦点を合わせています。たとえば、snrは10 dbに固定され、ノイズのある音声はt60のシミュレーションされた反響室で提示されました100〜1000 msの範囲</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: From Sound Representation to Model Robustness -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.AS/paper_3.html">
      <font color="black">From Sound Representation to Model Robustness</font>
    </a>
  </h2>
  <font color="black">3つのベンチマーク環境音データセットで、オーディオ信号を表すために一般的に使用される3つの2D表現ドメインとのこの関係を調査しました。ResNet-18は、認識の点で他の密な深層学習分類器（つまり、GoogLeNetおよびAlexNet）よりも優れています精度だけでなく、敵対的な例を他の被害者分類子にかなり転送します。実験結果は、DWTスペクトログラムでトレーニングされたResNet-18分類子が最高の認識精度を達成する一方で、このモデルを攻撃することは、敵対者に比べて比較的コストがかかることを示しています。 MFCCおよびSTFT表現。 
[ABSTRACT] mfcc、短時間テオドール変換（stft）、および連続ウェーブレット学習（dwt）は、2D表現空間で環境音信号を変調します。18種類の広告主は、このモデルの攻撃がmfccおよびstft表現よりも比較的コストがかかることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Generative Adversarial Alignment Representation for Sheet
  music, Audio and Lyrics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.AS/paper_4.html">
      <font color="black">Unsupervised Generative Adversarial Alignment Representation for Sheet
  music, Audio and Lyrics</font>
    </a>
  </h2>
  <font color="black">判別モデルは、生成モデルまたはグラウンドトゥルースからの入力を区別することを目的としています。2つのモデルは、敵対的な方法で同時にトレーニングして、ディープアライメント表現の学習能力を高めます。生成（G）モデルは、転送された2つのペアのペア。固定歌詞の新しいオーディオシートペアを生成して、判別（D）モデルに挑戦します。 
[ABSTRACT]提案されたugaarモデルは、3つの主要な音楽モダリティにわたって共有される深い差別的な表現を学習します。これらには、楽譜、歌詞、オーディオが含まれ、3つのブランチでの深いニューラルネットワークベースのアーキテクチャが共同でトレーニングされます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Flexible framework for audio reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.AS/paper_5.html">
      <font color="black">Flexible framework for audio reconstruction</font>
    </a>
  </h2>
  <font color="black">この概念はさらに拡張され、変換されたドメイン内の類似の劣化モデルに対応します。信号の時間周波数係数の量子化.. 2つの異なるドメインで劣化した観測からオーディオ信号を再構築するタスクは、逆問題として定式化され、いくつかのアルゴリズムによるソリューションが開発されます。 
[ABSTRACT]オーディオ信号を再構築するコンセプトが開発されました。変換されたドメインで同じタスクをカバーするようにさらに拡張されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-23">
        <br><font color="black">2020-04-23</font>
      </time>
    </span>
</section>
<!-- paper0: On Loss Functions and Recurrency Training for GAN-based Speech
  Enhancement Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.AS/paper_6.html">
      <font color="black">On Loss Functions and Recurrency Training for GAN-based Speech
  Enhancement Systems</font>
    </a>
  </h2>
  <font color="black">再発層を含めることの利点も検討されています。最近の研究では、音声強調に生成敵対ネットワーク（GAN）を使用することが可能であることが示されていますが、これらのアプローチは最先端（SOTA）と比較されていません非GANベースのアプローチ..全体として、客観的なメトリック損失関数と平均二乗誤差（MSE）を組み合わせたCRGANモデルは、多くの評価メトリックにわたって比較アプローチよりも優れたパフォーマンスを提供します。 
[要約]提案されたcrganモデルは、同じロスバーを使用してsota ganベースのモデルよりも優れています。また、他の非ganベースのシステムよりも優れており、音声強調にガンを使用する利点を示唆しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Adversarial White Box Attacks on Music Instrument
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.AS/paper_7.html">
      <font color="black">End-to-End Adversarial White Box Attacks on Music Instrument
  Classification</font>
    </a>
  </h2>
  <font color="black">私たちの攻撃は、ランダムなベースラインに近い精度を低下させると同時に、摂動をほとんど感知できず、任意の目的の楽器を誤って分類する可能性があります。楽器の分類システムに対する最初のエンドツーエンドの敵対的攻撃を提示し、スペクトログラムではなく、オーディオ波形に直接摂動を追加します。入力データの小さな敵対的な摂動は、機械学習システムのパフォーマンスを劇的に変化させる可能性があり、それによって、そのようなシステムの妥当性に挑戦します。 
[ABSTRACT]楽器システムに対する最初の攻撃が公開されました。システムシステムシステムに対する一連の攻撃の最初の攻撃です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Transformer based unsupervised pre-training for acoustic representation
  learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.AS/paper_8.html">
      <font color="black">Transformer based unsupervised pre-training for acoustic representation
  learning</font>
    </a>
  </h2>
  <font color="black">すべての実験により、独自のトレーニングデータを使用して事前トレーニングを行うと、モデルの収束が大幅に速くなり、パフォーマンスが向上することが示されています。計算音声分析は、関連する研究分野で中心的な問題となっており、さまざまな関連アプリケーションが発生しています。サウンドイベント検出では、F1スコアはDCASE2018 task5開発セットで1.7％、評価セットで2.4％絶対的にさらに改善できます。 
[要約] 3種類の音響タスクについて実験が行われました。音響タスクには、音声翻訳、音声感情認識、サウンドイベント検出が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Representation Transferability of Adversarial Attacks: From
  Spectrograms to Audio Waveforms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.AS/paper_9.html">
      <font color="black">Cross-Representation Transferability of Adversarial Attacks: From
  Spectrograms to Audio Waveforms</font>
    </a>
  </h2>
  <font color="black">西洋音楽のデータセットの実験結果は、2D CNNが正当な例で平均精度の最大81.87％を達成し、そのようなパフォーマンスが敵対的な例で12.09％に低下することを示しています。さらに、摂動スペクトログラムから再構築されたオーディオ波形も可能です。同様に、1D CNNは元のオーディオサンプルで最大78.29％の平均精度を達成し、そのようなパフォーマンスは摂動スペクトログラムから再構築された敵対的なオーディオ波形で27.91％に低下します。 
[ABSTRACT]摂動スペクトログラムは、2D互換ネットワーク（cnn）をだますことができます。1dcnnは、元のオーディオでトレーニングされた1d cnnをだますこともできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-22">
        <br><font color="black">2019-10-22</font>
      </time>
    </span>
</section>
<!-- paper0: Improved Handling of Repeats and Jumps in Audio-Sheet Image
  Synchronization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.AS/paper_10.html">
      <font color="black">Improved Handling of Repeats and Jumps in Audio-Sheet Image
  Synchronization</font>
    </a>
  </h2>
  <font color="black">ジャンプの場所が不明な場合でもジャンプと繰り返しを処理できる階層型DTWと呼ばれる新しい整列アルゴリズムを提案します。特に、以前に提案されたジャンプDTWアルゴリズムは、ジャンプの場所がアプリオリに未知である場合、堅牢に実行されないことがわかります。 IMSLPからの未処理の楽譜PDFを注意深く制御した実験により、Hierarachical DTWがさまざまなタイプのジャンプの処理においてJump DTWよりも大幅に優れていることがわかります。 
[ABSTRACT]これまでの作品は、データがクリーンアップされ、前処理された合成楽譜に焦点を当てています。代わりに、未加工の生の楽譜の本当の乱雑さに対処できるシステムの開発に焦点を当てています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Streaming keyword spotting on mobile devices -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.AS/paper_11.html">
      <font color="black">Streaming keyword spotting on mobile devices</font>
    </a>
  </h2>
  <font color="black">このライブラリを使用して、携帯電話のストリーミングモードと非ストリーミングモードの両方で複数のKWSモデルのベンチマークを行い、レイテンシと精度の間のさまざまなトレードオフを示します。すべての実験を含むストリーミングライブラリはオープンソースです。 Googleの音声コマンドデータセットV2で、最先端の分類エラーを10％削減する注目を集めました。 
[ABSTRACT]非ワードモードからストリーミングモードへのモデル変換には、手動での書き換えが必要な場合があります。携帯電話のストリーミングモードと非ストリーミングモードの両方で、複数のkwsモデルをベンチマークします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-14">
        <br><font color="black">2020-05-14</font>
      </time>
    </span>
</section>
<!-- paper0: TERA: Self-Supervised Learning of Transformer Encoder Representation for
  Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-30/eess.AS/paper_12.html">
      <font color="black">TERA: Self-Supervised Learning of Transformer Encoder Representation for
  Speech</font>
    </a>
  </h2>
  <font color="black">事前トレーニング済みモデルをダウンストリームモデルに組み込むためのさまざまな知識伝達方法を探索します。TERAは、表面機能を改善し、以前の方法よりも優れているため、これらのタスクで強力なパフォーマンスを実現しました。これは、変質器からのトランスフォーマーエンコーダー表現を表します。 
[要約]モデルは、変更された対応物からの音響フレームの再構成を通じて学習します。これらには、自己回帰予測、自己回帰予測、マスク再構成が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-12">
        <br><font color="black">2020-07-12</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
