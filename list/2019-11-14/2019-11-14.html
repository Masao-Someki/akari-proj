<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<title>Akari-2019-11-14の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
  <div class="header-logo">
    <a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
  </div>
</header>
<input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">

<div class="menubar">
<span class="bar"></span>
<span class="bar"></span>
<span class="bar"></span>
</div>

<ul>
<li><a id="home" href="../../index.html">Home</a></li>
<li><a id="about" href="../../teamAkariとは.html">About</a></li>
<li><a id="contact" href="../../contact.html">Contact</a></li>
<li><a id="contact" href="../../list/newest.html">New Papers</a></li>
<li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
</ul>

</label>
<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Voice Activity Detection in presence of background noise using EEG -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.SD/paper_0.html">
      Voice Activity Detection in presence of background noise using EEG
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      リカレントニューラルネットワーク（RNN）ベースのVADシステムを実装し、この論文で異なるノイズ条件の存在下で記録された2つの異なるデータセットの結果を示します。また、EEG機能のみを使用するVADは、この記事では、音響入力機能を脳波（EEG）機能と連結することにより、背景ノイズの存在下で動作する音声アクティビティ検出（VAD）システムのパフォーマンスを改善できることを実証します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-08">
        <br>2019-11-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Drum Machine : An Interactive System for Real-time Synthesis of
  Drum Sounds -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.SD/paper_1.html">
      Neural Drum Machine : An Interactive System for Real-time Synthesis of
  Drum Sounds
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      生成モデルは、条件付きワッサースタインオートエンコーダー（CWAE）で構成されます。これは、短いパーカッションサンプルのメルスケールのマグニチュードスペクトログラムを生成することを学習し、マグニチュードスペクトログラムから対応するオーディオ信号を推定するマルチヘッド畳み込みニューラルネットワーク（MCNN）と組み合わされます。このセットアップにより、システムをスタジオ制作環境に簡単に統合し、創造的なプロセスを強化できます。最後に、システムの利点と、音楽プロデューサーとそのようなツールの相互作用がドラムトラックのあり方を変える方法について説明します。構成された。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-04">
        <br>2019-07-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Robust End-to-End Speaker Verification Using EEG -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.SD/paper_2.html">
      Robust End-to-End Speaker Verification Using EEG
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本論文では、脳波記録（EEG）信号の特徴と音声信号を連結することにより、話者検証システムの性能を改善できることを実証します。EEG信号は話者検証システムの堅牢性を改善できることを示しています。話者検証を実行するための深層学習モデルを終了し、ノイズの多い音声の結果を示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-17">
        <br>2019-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: 'Warriors of the Word' -- Deciphering Lyrical Topics in Music and Their
  Connection to Audio Feature Dimensions Based on a Corpus of Over 100,000
  Metal Songs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.SD/paper_3.html">
      'Warriors of the Word' -- Deciphering Lyrical Topics in Music and Their
  Connection to Audio Feature Dimensions Based on a Corpus of Over 100,000
  Metal Songs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      503曲のサブサンプルについて、知覚される音楽の硬さ/重さおよび暗さ/暗さを予測するスコアがオーディオ機能モデルを使用して抽出されました。20の典型的なトピックが識別され、多次元スケーリング（MDS）を使用してトピックスペースに投影されました..高レベルのオーディオ機能の自動抽出と、このジャンルの124.288曲の歌詞のコーパスに対する定量的テキスト分析を組み合わせることによる、金属音楽の音楽的および叙情的なコンテンツ間の接続。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-12">
        <br>2019-11-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Spoken Speech Enhancement using EEG -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.SD/paper_4.html">
      Spoken Speech Enhancement using EEG
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、生成的敵対ネットワーク（GAN）ベースのモデルとロングショートタームメモリ（LSTM）回帰ベースのモデルを使用した脳波（EEG）信号を使用した発話音声の強化を示します。 LSTM回帰ベースのモデルと比較した強化結果..私たちの知る限りでは、話された音声と並行して記録されたEEG機能を使用して話された音声の強化が初めて示されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-13">
        <br>2019-09-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Advancing Speech Recognition With No Speech Or With Noisy Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.SD/paper_5.html">
      Advancing Speech Recognition With No Speech Or With Noisy Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、EEG機能と融合することにより、雑音のある音声に対するCSRを示します。この論文では、入力として音声信号を使用しない脳波記録（EEG）信号を使用したエンドツーエンド連続音声認識（CSR）を示します。認識を実行するために、認識（ASR）およびコネクショニスト時間分類（CTC）ベースのASRシステムが実装されました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-17">
        <br>2019-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: HCU400: An Annotated Dataset for Exploring Aural Phenomenology Through
  Causal Uncertainty -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.SD/paper_6.html">
      HCU400: An Annotated Dataset for Exploring Aural Phenomenology Through
  Causal Uncertainty
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      因果不確実性の既存の計算を拡張し、単語埋め込みを使用して自動化および一般化します。これは、因果属性の分析を含めるために利用可能な最大のオーディオデータセットとして聴覚現象学の障壁を下げることを目的としています。サウンドのソースがますます曖昧になるにつれて、偏りの少ない感情評価を提供します。一方、親しみやすさとイメージ可能性の個々の評価は、平均で明らかにマイナスの傾向がありますが、不確実性が増すにつれて分岐します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-11-15">
        <br>2018-11-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Enhanced Voice Post Processing Using Voice Decoder Guidance Indicators -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.SD/paper_7.html">
      Enhanced Voice Post Processing Using Voice Decoder Guidance Indicators
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、提案された変更は、ダウンリンク側の音声エンハンスメントの変更と音声デコードの情報の利用に焦点を当てています。予備的な結果は、このようなアプローチにより品質が向上することを示しています。両方とも、基礎となる信号の同様の機能を利用します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br>2019-11-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Supervised online diarization with sample mean loss for multi-domain
  data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.SD/paper_8.html">
      Supervised online diarization with sample mean loss for multi-domain
  data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      入力ベクトルとしてxベクトルを使用して、DIHARD IIチャレンジで採用されたマルチドメインデータセットに対する提案されたアプローチを評価します：オンラインメソッドは元のUIS-RNNに対して改善され、PLDAを使用したオフラインの凝集クラスタリングベースラインと同様のパフォーマンスを達成しますスコアリング..さらに、私たちのモデルは固定長音声セグメントでトレーニングできることを実証し、推論における話者変更情報の必要性を排除します。最近、話者をモデル化する完全に監督された話者ダイアライゼーションアプローチが提案されましたパラメータ共有リカレントニューラルネットワークの複数のインスタンスを使用します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-04">
        <br>2019-11-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: 3-D Feature and Acoustic Modeling for Far-Field Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.SD/paper_9.html">
      3-D Feature and Acoustic Modeling for Far-Field Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、多変量自己回帰（MAR）モデリングアプローチを使用して、マルチチャネル音声信号から特徴を直接抽出することを提案します。このアプローチでは、時間、周波数、チャネルの3次元すべての相関が活用されます。これらの実験では、提案された3D機能と音響モデリングアプローチにより、ビームフォーミングされたオーディオでトレーニングされたASRシステムを大幅に改善します（ワードエラー率の平均相対改善率は10％および9％です）。 CHiME-3およびREVERB Challengeデータセットのそれぞれ。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br>2019-11-13
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Challenges in detecting evolutionary forces in language change using
  diachronic corpora -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.CL/paper_0.html">
      Challenges in detecting evolutionary forces in language change using
  diachronic corpora
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      母集団の遺伝学からのテスト（頻度増加テスト）をいくつかの関連する例に適用した結果、言語進化において確率論が以前は過小評価されていた役割を持っていることが示唆されました。頻度のようなテストの結果の解釈には注意が必要であると結論付けましたコーパスデータにテストを適用する際に利用できる研究者の自由度、および遺伝データと言語データの基本的な違いを考慮すると、個々のシリーズの増分テスト。これらの調査結果は、一般に選択テストと時間ビニングに影響を与え、有用性を実証しますフィールドに新たに導入された方法を評価するためのシミュレーションの。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-11-03">
        <br>2018-11-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Release Strategies and the Social Impacts of Language Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.CL/paper_1.html">
      Release Strategies and the Social Impacts of Language Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、進行中のパートナーシップベースの研究について説明し、AIでのより良い調整と責任ある公開のための推奨事項を提供します。有益な用途：散文、詩、およびプログラミングを支援できます。データセットバイアスの分析。もっと。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-24">
        <br>2019-08-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Can a Gorilla Ride a Camel? Learning Semantic Plausibility from Text -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.CL/paper_2.html">
      Can a Gorilla Ride a Camel? Learning Semantic Plausibility from Text
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      したがって、テキストから直接物理的妥当性をモデル化する学習のより困難な問題を提示します。同時に、分布モデル、すなわち大規模な事前学習済み言語モデルは、多くの自然言語理解タスクの結果を改善しました。証明されたイベントを大きなコーパスから抽出することにより、これらの証明されたイベントのトレーニングを自己監視方式で行い、物理的妥当性タスクでテストするためのベースラインを提供します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br>2019-11-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: LexiPers: An ontology based sentiment lexicon for Persian -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.CL/paper_3.html">
      LexiPers: An ontology based sentiment lexicon for Persian
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最終的なセンチメントレキシコンは、最適な分類器によって生成されています。センチメントレキシコンは、表現するセンチメント方向に関連付けられた単語のセットです。分類には、K最近傍法と最近傍セントロイド法を使用しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br>2019-11-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Interpreting and improving natural-language processing (in machines)
  with natural language-processing (in the brain) -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.CL/paper_4.html">
      Interpreting and improving natural-language processing (in machines)
  with natural language-processing (in the brain)
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      構文NLPタスクを使用して変更されたBERTを調べると、脳のアライメントが増加したモデルが元のモデルよりも優れていることが明らかになります。レイヤーの深さ、コンテキストの長さ、アテンションタイプによって、それらの表現がどのように異なるかを研究します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-28">
        <br>2019-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Robustness to Capitalization Errors in Named Entity Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.CL/paper_5.html">
      Robustness to Capitalization Errors in Named Entity Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      データ増強に基づく簡単な代替アプローチを提案します。これにより、モデルはコンテキストでの有用性に応じて、正射投影情報を利用または無視することができます。私たちの実験は、さまざまなタイプの機械学習モデル、言語、およびデータセットサイズにわたって明確かつ一貫して私たちの主張を検証します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br>2019-11-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Mark my Word: A Sequence-to-Sequence Approach to Definition Modeling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.CL/paper_6.html">
      Mark my Word: A Sequence-to-Sequence Approach to Definition Modeling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの提案は、コンテキスト化および定義生成をエンドツーエンドでトレーニングすることを可能にします。これは、以前の作品を概念的に改善したものです。コンテキストおよび非コンテキスト定義モデリングの両方で最先端の結果を達成します。テキストコンテキスト内の単語は、実用的な目的と、分散された単語表現に対する洞察を得るための両方に役立つタスクです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br>2019-11-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Meta-Learning with Dynamic-Memory-Based Prototypical Network for
  Few-Shot Event Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.CL/paper_7.html">
      Meta-Learning with Dynamic-Memory-Based Prototypical Network for
  Few-Shot Event Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      バニラプロトタイプネットワークでは、イベントメンションを1回だけ消費する単純なイベントプロトタイプを単純に計算しますが、モデルはより堅牢で、DMNのマルチホップメカニズムにより、イベントメンションからコンテキスト情報を複数回抽出することができます。動的メモリベースのプロトタイプネットワーク（DMB-PN）。DynamicMemory Network（DMN）を活用して、イベントタイプのより良いプロトタイプを学習するだけでなく、イベントに関するより堅牢な文エンコーディングを生成します。実験により、DMB- PNは、一連のベースラインモデルよりもサンプル不足をうまく処理するだけでなく、さまざまなイベントタイプが比較的大きく、インスタンスの量が極端に少ない場合に、より堅牢に動作します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Duplicate Question Detection without Labeled Training Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.CL/paper_8.html">
      Neural Duplicate Question Detection without Labeled Training Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、2つの新しい方法を提案します-質問のタイトルと本文を使用した弱い監視、および重複する質問の自動生成-両方ともラベル付きデータを必要としない場合でもパフォーマンスが向上することを示します..一般的なトレーニング戦略の比較を提供し、提案されたアプローチはcQAフォーラムからの大量のデータを利用できるため、多くの場合により効果的であることを示します。また、直接的な回答の監督なしでcQA回答選択モデルをトレーニングする効果的な方法です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br>2019-11-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Stable Variational Autoencoder for Text Modelling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.CL/paper_9.html">
      A Stable Variational Autoencoder for Text Modelling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      既存のVAE-RNNアーキテクチャと比較して、モデルがはるかに安定したトレーニングプロセスを達成し、大幅に高品質のテキストを生成できることを示します。このような問題は、テキストモデリングにVAE-RNNアーキテクチャを使用する場合に特に一般的です（Bowman et al。 、2016）..ただし、VAEは潜在変数崩壊（またはKL損失消失）として知られる問題に悩まされる可能性があります。この問題では、事後が崩壊し、モデルが生成タスクの潜在コードを無視します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br>2019-11-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The Power of Communities: A Text Classification Model with Automated
  Labeling Process Using Network Community Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.CL/paper_10.html">
      The Power of Communities: A Text Classification Model with Automated
  Labeling Process Using Network Community Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この方法は、より正確な会話インテリジェンスおよびその他のテキスト分類システムの開発に役立つ可能性があります。具体的には、ネットワークノードとして文を使用し、ネットワークリンクの重みとして文のTFIDFベクトル表現間のペアワイズコサイン類似性を使用してネットワークを構築します。文ネットワーク内のコミュニティを検出するLouvainの方法。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-25">
        <br>2019-09-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: How to Evaluate Word Representations of Informal Domain? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.CL/paper_11.html">
      How to Evaluate Word Representations of Informal Domain?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      弱い教師付きパターンベースのブートストラップと自己学習線形チェーン条件付きランダムフィールド（CRF）の自動アプローチにより、UrbanDictionaryからバリアントスペルペアの大きなリストを導き出しました。これらの抽出された関係ペアを使用して、従来のNLPパイプラインのテキスト正規化手順、および非公式ドメインでの非標準語の表現の直接採用..にもかかわらず、Twitterやフォーラムなどの非公式ドメインでのこのような語の埋め込みを効率的に評価する方法は、十分な評価データセット。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-12">
        <br>2019-11-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Structured Sparsification of Gated Recurrent Neural Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.CL/paper_12.html">
      Structured Sparsification of Gated Recurrent Neural Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これにより、いくつかのゲートが一定になり、LSTM構造が単純化されます。ニューロン。具体的には、重みとニューロンのスパース化に加えて、ゲートの事前活性化のスパース化を提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br>2019-11-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: 'Warriors of the Word' -- Deciphering Lyrical Topics in Music and Their
  Connection to Audio Feature Dimensions Based on a Corpus of Over 100,000
  Metal Songs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.CL/paper_13.html">
      'Warriors of the Word' -- Deciphering Lyrical Topics in Music and Their
  Connection to Audio Feature Dimensions Based on a Corpus of Over 100,000
  Metal Songs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      20の典型的なトピックが識別され、多次元スケーリング（MDS）を使用してトピックスペースに投影されました。 &#39;、&#39;宗教と悪魔 &#39;、&#39;戦闘 &#39;、&#39;（心理的）狂気 &#39;、&#39;個人的な生活 &#39;や&#39;愛とロマンス &#39;などのトピックと否定的な関連性があります。.503曲のサブサンプルの場合、予測スコア知覚された音楽の硬さ/重さおよび暗さ/暗さは、オーディオ機能モデルを使用して抽出されました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-12">
        <br>2019-11-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Adapting and evaluating a deep learning language model for clinical
  why-question answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.CL/paper_14.html">
      Adapting and evaluating a deep learning language model for clinical
  why-question answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      臨床言語のカスタマイズに向けたトレーニングにより、精度が6％向上しました。質問駆動型の臨床情報抽出の有能なプロキシとして機能します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br>2019-11-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Prevalence of code mixing in semi-formal patient communication in low
  resource languages of South Africa -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.CL/paper_15.html">
      Prevalence of code mixing in semi-formal patient communication in low
  resource languages of South Africa
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このデータセット内で約10％のレベルでコード切り替えの証拠を示します。これは、将来のサービスに課題をもたらす可能性が高いレベルです。MomConnectヘルプデスクのユーザーによって生成された182kのユニークな質問で構成されるデータを調べます南アフリカの全国規模の公衆衛生プラットフォーム。このペーパーでは、リソース不足の言語設定におけるコード混合の問題に対処します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br>2019-11-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Advancing Speech Recognition With No Speech Or With Noisy Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.CL/paper_16.html">
      Advancing Speech Recognition With No Speech Or With Noisy Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、EEG機能と融合することにより、雑音のある音声に対するCSRを示します。この論文では、入力として音声信号を使用しない脳波記録（EEG）信号を使用したエンドツーエンド連続音声認識（CSR）を示します。認識を実行するために、認識（ASR）およびコネクショニスト時間分類（CTC）ベースのASRシステムが実装されました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-17">
        <br>2019-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: HCU400: An Annotated Dataset for Exploring Aural Phenomenology Through
  Causal Uncertainty -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.CL/paper_17.html">
      HCU400: An Annotated Dataset for Exploring Aural Phenomenology Through
  Causal Uncertainty
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      分析の結果、音のソースがあいまいになるにつれて、個人は偏極感情評価を提供することがわかります。一方、個々の親しみやすさとイメージ可能性の評価は、平均で明確な負の傾向にもかかわらず、不確実性が増加するにつれて分岐します。ソースの説明、親しみやすさ、画像化可能性、覚醒度、および価数評価。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-11-15">
        <br>2018-11-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A GRU-Gated Attention Model for Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/cs.CL/paper_18.html">
      A GRU-Gated Attention Model for Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      GAttは、ゲーテッドリカレントユニット（GRU）を使用して、2種類の情報を組み合わせます。元々双方向エンコーダーによって生成されたソースアノテーションベクトルを履歴状態として扱い、対応する以前のデコーダー状態をGRUへの入力として扱います。翻訳依存のソース表現を取得し、それをアテンションネットワークにフィードして識別コンテキストベクトルを生成します。ニューラルマシントランスレーション（NMT）はアテンションネットワークに大きく依存して、各ターゲット単語予測のコンテキストベクトルを生成します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2017-04-27">
        <br>2017-04-27
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Voice Activity Detection in presence of background noise using EEG -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/eess.AS/paper_0.html">
      Voice Activity Detection in presence of background noise using EEG
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      リカレントニューラルネットワーク（RNN）ベースのVADシステムを実装し、異なるノイズ条件の存在下で記録された2つの異なるデータセットの結果をこのペーパーで示します。このペーパーでは、音声アクティビティ検出（VAD）システムの動作バックグラウンドノイズが存在する場合、音響入力機能を脳波記録（EEG）機能と連結することにより改善できます。また、EEG機能のみを使用するVADは、バックグラウンドノイズが存在する音響機能のみを使用するVADよりも優れたパフォーマンスを示すことも示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-08">
        <br>2019-11-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Drum Machine : An Interactive System for Real-time Synthesis of
  Drum Sounds -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/eess.AS/paper_1.html">
      Neural Drum Machine : An Interactive System for Real-time Synthesis of
  Drum Sounds
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このセットアップにより、システムをスタジオ制作環境に簡単に統合し、創造的なプロセスを強化できます。この作業では、ドラムサウンドをリアルタイムで生成するためのシステムを紹介します。この生成モデルで。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-04">
        <br>2019-07-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Robust End-to-End Speaker Verification Using EEG -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/eess.AS/paper_2.html">
      Robust End-to-End Speaker Verification Using EEG
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      EEG信号は、スピーカー検証システムの堅牢性を向上させることができます。この論文では、脳波記録（EEG）信号の特徴を音声信号と連結することにより、スピーカー検証システムの性能を向上できることを示します。話者検証を実行するためのディープラーニングモデルを終了し、ノイズの多い音声の結果を示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-17">
        <br>2019-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: 'Warriors of the Word' -- Deciphering Lyrical Topics in Music and Their
  Connection to Audio Feature Dimensions Based on a Corpus of Over 100,000
  Metal Songs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/eess.AS/paper_3.html">
      'Warriors of the Word' -- Deciphering Lyrical Topics in Music and Their
  Connection to Audio Feature Dimensions Based on a Corpus of Over 100,000
  Metal Songs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      20の典型的なトピックが特定され、多次元スケーリング（MDS）を使用してトピックスペースに投影されました。高レベルオーディオ機能の自動抽出とコーパスの定量的テキスト分析を組み合わせることで、金属音楽の音楽コンテンツと叙情的コンテンツの関係を調べますこのジャンルの124.288曲の歌詞の中で。 「個人的な生活」や「愛とロマンス」などのトピックには否定的な関連性があります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-12">
        <br>2019-11-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Spoken Speech Enhancement using EEG -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/eess.AS/paper_4.html">
      Spoken Speech Enhancement using EEG
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーでは、生成的敵対ネットワーク（GAN）ベースのモデルとロングショートタームメモリ（LSTM）回帰ベースのモデルを使用して、脳波（EEG）信号を使用した音声スピーチの強化を示します。さらに、GANベースのモデルは、LSTM回帰ベースのモデルと比較して、より良いEEGベースの音声強調結果を示していることがわかりました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-13">
        <br>2019-09-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Advancing Speech Recognition With No Speech Or With Noisy Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/eess.AS/paper_5.html">
      Advancing Speech Recognition With No Speech Or With Noisy Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、入力として音声信号を使用しない脳波記録（EEG）信号を使用したエンドツーエンド連続音声認識（CSR）を示します。さらに、EEG機能と融合することにより、ノイズの多い音声に対するCSRを示します。認識を実行するために、認識（ASR）およびコネクショニスト時間分類（CTC）ベースのASRシステムが実装されました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-17">
        <br>2019-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: HCU400: An Annotated Dataset for Exploring Aural Phenomenology Through
  Causal Uncertainty -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/eess.AS/paper_6.html">
      HCU400: An Annotated Dataset for Exploring Aural Phenomenology Through
  Causal Uncertainty
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      因果的不確実性の既存の計算を拡張し、単語の埋め込みで自動化および一般化します。分析の結果、音のソースがますます曖昧になるにつれて、個人はより偏りの少ない感情評価を提供することがわかります。一方、親しみやすさとイメージ可能性の個々の評価は、平均で明確な負の傾向にもかかわらず不確実性が増加するにつれて分岐します。各サンプルには、クラウドソースの説明、親しみやすさ、イメージ化可能性、覚醒度、価数評価が付けられています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-11-15">
        <br>2018-11-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Enhanced Voice Post Processing Using Voice Decoder Guidance Indicators -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/eess.AS/paper_7.html">
      Enhanced Voice Post Processing Using Voice Decoder Guidance Indicators
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、提案された概念の将来の拡張に関する提案が提供されます。具体的には、提案された変更は、ダウンリンク側の音声強調の変更と音声復号の情報の利用に焦点を当てています。他の利益。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br>2019-11-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Supervised online diarization with sample mean loss for multi-domain
  data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/eess.AS/paper_8.html">
      Supervised online diarization with sample mean loss for multi-domain
  data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、パラメータ共有リカレントニューラルネットワークの複数のインスタンスを使用してスピーカーをモデル化する完全に監督されたスピーカーのダイアライゼーションアプローチが提案されました（UIS-RNN）。入力特徴としてxベクトルを使用して、マルチドメインデータセットで提案されたアプローチを評価しますDIHARD IIチャレンジで採用：オンラインメソッドは元のUIS-RNNに対して改善され、PLDAスコアリングを使用してオフラインの凝集クラスタリングベースラインと同様のパフォーマンスを達成します。さらに、固定長音声でモデルをトレーニングできることを示します。セグメント、スピーカーの変更情報の推論の必要性を削除します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-04">
        <br>2019-11-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: 3-D Feature and Acoustic Modeling for Far-Field Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/eess.AS/paper_9.html">
      3-D Feature and Acoustic Modeling for Far-Field Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、多変量自己回帰（MAR）モデリングアプローチを使用して、マルチチャネル音声信号から直接特徴を抽出することを提案します。このアプローチでは、時間、周波数、およびチャネルの3次元すべての相関が活用されます.3-D CNNアーキテクチャにより、マルチチャンネル機能を組み合わせて、音声認識コストを最適化することができます。これは、エンハンスメントタスクに焦点を当てた従来のビームフォーミングモデルに比べて最適です。MAR機能は、音響モデル三次元で。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br>2019-11-13
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Divergent Energy Expenditure Impacts Mouse Metabolic Adaptation to Acute High-Fat/High-Sucrose Diet Producing Sexually Dimorphic Weight Gain Patterns -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/biorxiv.physiology/paper_0.html">
      Divergent Energy Expenditure Impacts Mouse Metabolic Adaptation to Acute High-Fat/High-Sucrose Diet Producing Sexually Dimorphic Weight Gain Patterns
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      HFHSはすべてのグループで脂肪量を増加させましたが、30 {degrees} Cマウスでは20 {degrees} Cマウスと比較して2倍の増加が発生しました。 {degrees} C対20 {degrees} Cマウス。方法：ベースラインEEの堅牢な違いが、低脂肪および高脂肪、高スクロース（HFHS）の食事で体重と体組成の7日間の変化にどのように影響するかを判断するには、異なる温度（20 {degrees} C対30 {degrees} C）で飼育されたオスとメスのマウスで間接的な熱量測定を行いました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br>2019-11-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Chemical genetics strategy to profile kinase target engagement reveals role of FES in neutrophil phagocytosis via SYK activation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-14/biorxiv.physiology/paper_1.html">
      Chemical genetics strategy to profile kinase target engagement reveals role of FES in neutrophil phagocytosis via SYK activation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この戦略によって提供される一時的な制御により、骨髄分化中および最終分化した好中球の両方でFES活性の急性不活性化が可能になります。代わりに、FESは、好中球の免疫機能の中心的な調節因子であるSYKキナーゼの活性化により、好中球の食作用において重要な役割を果たします。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br>2019-11-13
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
