<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-12-25の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Wheel-Rail Interface Condition Estimation (W-RICE) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.SD/paper_0.html">
      <font color="black">Wheel-Rail Interface Condition Estimation (W-RICE)</font>
    </a>
  </h2>
  <font color="black">したがって、車輪とレールの相互作用に起因するノイズパターンの分析から、車輪とレールの間の接着状態を推定することができます。車輪とレールの境界面に霜やグリースなどの第3の物体が存在すると、接着係数の変化に寄与します。その結果、さまざまなレベルでノイズが発生します。ホイールとレールの間の表面の粗さは、ローリングノイズレベルに大きな影響を与えます。 
[概要]車輪とレールの境界面に第3の物体が存在することで、接着力が変化します。ローリングノイズを入力として使用する新しいアプローチが提案されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised neural adaptation model based on optimal transport for
  spoken language identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.SD/paper_1.html">
      <font color="black">Unsupervised neural adaptation model based on optimal transport for
  spoken language identification</font>
    </a>
  </h2>
  <font color="black">オリエンタル言語認識（OLR）チャレンジデータコーパスでSLID実験を実施し、トレーニングとテストのデータセットをさまざまな条件から収集しました。さらに、分布の不一致を測定するための最適なトランスポート（OT）の強力な能力に触発され、ワッサースタイン距離メトリックは、適応損失で設計されています。私たちの結果は、クロスドメインテストタスクで大幅な改善が達成されたことを示しました。 
[概要]このシステムは、教師なし神経適応モデルを開発するために使用できます。スライドの分布の不一致の問題に対処するために開発できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Code Switching Language Model Using Monolingual Training Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.SD/paper_2.html">
      <font color="black">Code Switching Language Model Using Monolingual Training Data</font>
    </a>
  </h2>
  <font color="black">結果は、RNNベースの言語モデルの出力埋め込みで平均二乗誤差（MSE）を使用して一貫して改善されました。この作業では、RNN言語モデルは、単一言語の英語とスペイン語のデータと言語モデルの複雑さのみからの代替バッチを使用してトレーニングされます。結果から、トレーニングで単言語データの代替バッチを使用すると、CS言語モデルの複雑さが軽減されたと結論付けられます。 
[要約]提案された方法は、コードスイッチトレーニングデータを使用した言語モデルの微調整に匹敵しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Spatio-temporal Multi-task Learning for Cardiac MRI Left Ventricle
  Quantification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.IV/paper_0.html">
      <font color="black">Spatio-temporal Multi-task Learning for Cardiac MRI Left Ventricle
  Quantification</font>
    </a>
  </h2>
  <font color="black">145人の被験者のシネMRシーケンスを使用し、パフォーマンスを他の最先端の定量化方法と比較して、提案された方法の有効性を示します。ただし、このプロセスは観察者間および観察者内の変動にさらされ、それは時間のかかる面倒な作業..提案された深層学習モデルは、MR画像から空間的および時間的特徴を抽出する3D時空間畳み込みに基づいています。 
[ABSTRACT]提案された方法は、3D空間-時間畳み込みに基づいています。これらの被験者は、mr画像から空間的および時間的特徴を抽出します。提案された方法は、高い予測精度を取得しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Automated Scoring of Nuclear Pleomorphism Spectrum with
  Pathologist-level Performance in Breast Cancer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.IV/paper_1.html">
      <font color="black">Automated Scoring of Nuclear Pleomorphism Spectrum with
  Pathologist-level Performance in Breast Cancer</font>
    </a>
  </h2>
  <font color="black">また、病理医が腫瘍の核多形性をスコアリングするように訓練され、比較のために正常な乳房上皮を有する日常的な臨床診療に続いて、ベースラインとして正常な上皮の追加の利点について議論する追加のアプローチを動機付けます。 -自動化されたアプローチは、それぞれ10人と4人の病理学者と比較して、関心のある選択された領域とスライド画像全体で最高の病理学者レベルのパフォーマンスを達成できます。ネットワークを従来の3つのカテゴリの分類に制約することなく、複数の病理学者の集合的な知識からの多種多様な腫瘍領域について。 
[概要]科学者は、複数の病理学者の集合的な知識から、多種多様な腫瘍領域でディープニューラルネットワークをトレーニングしました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: UMLE: Unsupervised Multi-discriminator Network for Low Light Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.IV/paper_2.html">
      <font color="black">UMLE: Unsupervised Multi-discriminator Network for Low Light Enhancement</font>
    </a>
  </h2>
  <font color="black">このモジュールは、チャネル注意とピクセル注意メカニズムを組み合わせて画像の特徴を抽出します。この問題に対処するために、複数の弁別子を含むリアルタイムの教師なし生成的敵対的ネットワーク（GAN）を提案します。さらに、異なるチャネル特徴が異なる情報を含み、照明が画像内で不均一であることを考慮して、特徴融合注意モジュールを提案する。 
[概要]低照度シナリオは、視覚ベースのアプリケーションに深刻な影響を及ぼします。これらには、マルチスケール弁別器、テクスチャ弁別器、および色弁別器が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Fine-grained Attention and Feature-sharing Generative Adversarial
  Networks for Single Image Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.IV/paper_3.html">
      <font color="black">Fine-grained Attention and Feature-sharing Generative Adversarial
  Networks for Single Image Super-Resolution</font>
    </a>
  </h2>
  <font color="black">超解像画像を物体認識に適用することにより、提案された方法が再構成機能と優れた超解像効果に力を与えることがさらに証明されます。まず、画像を本物と偽物で区別する単一のスコアを生成する代わりに、画像の超解像のための細粒度注意生成敵対ネットワーク（FASRGAN）と呼ばれるバリアントで、各ピクセルを本物と偽物で区別します。スコアマップはHR / SR画像と同じ空間サイズで、細粒度として機能します。各ピクセルの再構成の難易度を表すための注意。 
[概要]ジェネレーターに異なるネットワークを使用する代わりに、ジェネレーターとディスクリミネーターの両方に機能共有ネットワーク（fs-srgan）を使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br><font color="black">2019-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Style Transfer by Rigid Alignment in Neural Net Feature Space -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.IV/paper_4.html">
      <font color="black">Style Transfer by Rigid Alignment in Neural Net Feature Space</font>
    </a>
  </h2>
  <font color="black">この作業では、スタイルパターンをシームレスに転送し、スタイル画像のコンテンツ構造をそのまま維持する、任意のスタイル転送の効果的かつ効率的なアプローチを示します。高品質の定型化された画像を生成して比較することにより、提案されたアプローチの有効性を示します。任意のスタイルの転送のための現在の最先端技術による結果..任意のスタイルの転送は、任意のスタイルの画像から特定のコンテンツ画像にスタイルパターンを転送することを目的とするコンピュータビジョンの重要な問題です。 
[概要]これは、固定配置を使用してスタイル機能をコンテンツ機能に揃えることによって行います。これは、反対の方法を実行する既存の方法とは異なり、スタイル機能を変更することによって行います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-27">
        <br><font color="black">2019-09-27</font>
      </time>
    </span>
</section>
<!-- paper0: LEUGAN:Low-Light Image Enhancement by Unsupervised Generative
  Attentional Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.IV/paper_5.html">
      <font color="black">LEUGAN:Low-Light Image Enhancement by Unsupervised Generative
  Attentional Networks</font>
    </a>
  </h2>
  <font color="black">実験により、提案されたアルゴリズムが最先端の方法に対して、特に画像の鮮明度とノイズ制御の点で実世界の画像に対して良好に機能することが検証されます。実世界のデータセットがないため、一般化すると通常はパフォーマンスが低下します。実際には、画像のエッジと色の情報が失われます。既存のディープネットワークベースのアルゴリズムのほとんどは、ペアワイズ画像でトレーニングされるように設計されています。 
[概要]この記事では、教師なし生成ネットワークに注意を払い、低照度モジュールの拡張タスクを処理するためのガイダンスを提案します。生成された画像のエッジをより見やすくするための新しい損失関数が含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Image Reconstruction with Misaligned Structural Information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.IV/paper_6.html">
      <font color="black">Robust Image Reconstruction with Misaligned Structural Information</font>
    </a>
  </h2>
  <font color="black">したがって、提案されたフレームワークは、実際の条件下で複数のモダリティ間で共有情報を強力に活用することを可能にします。多くの場合、変分正則化として定式化された最先端の方法は、画像再構成を定量的および定性的に大幅に改善することを示しています。これらのモデルは、モダリティが完全に登録されているという仮定に依存していますが、これはほとんどの実際のアプリケーションには当てはまりません。 
[概要]マルチコントラストMRI、ペットMRI、および複数の手術は、定量的および定性的に画像再構成を大幅に改善することが示されています。これらのタイプのハイパースペクトルイメージングには、材料科学におけるハイパースペクトルイメージングとマルチコントラストMRIが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-01">
        <br><font color="black">2020-04-01</font>
      </time>
    </span>
</section>
<!-- paper0: An Aggregate Method for Thorax Diseases Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.IV/paper_7.html">
      <font color="black">An Aggregate Method for Thorax Diseases Classification</font>
    </a>
  </h2>
  <font color="black">胸部X線画像データセットの実験結果は、この新しい重み付けスキームが分類パフォーマンスを改善し、EfficientNetからのトレーニング最適化もパフォーマンスをさらに改善することを示しています。この論文では、損失関数のトレーニングパターンの重みはに基づいて設計されています。クラス内のトレーニングパターンの数だけでなく、1つがこのトレーニングパターンをポジティブとして扱い、他のノードがネガティブとして扱うさまざまなノードでも。さらに、ニューラルネットワークを使用した複数のクラスの分類では、トレーニングパターンは、1つの出力ノードでは正のパターンとして扱われ、残りのすべての出力ノードでは負のパターンとして扱われます。 
[概要]このシステムは、胸部疾患分類問題のための最先端のディープネットワークアーキテクチャに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-07">
        <br><font color="black">2020-08-07</font>
      </time>
    </span>
</section>
<!-- paper0: Joint super-resolution and synthesis of 1 mm isotropic MP-RAGE volumes
  from clinical MRI exams with scans of different orientation, resolution and
  contrast -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.IV/paper_8.html">
      <font color="black">Joint super-resolution and synthesis of 1 mm isotropic MP-RAGE volumes
  from clinical MRI exams with scans of different orientation, resolution and
  contrast</font>
    </a>
  </h2>
  <font color="black">SynthSRで生成された画像を一連の一般的なダウンストリーム分析でテストし、皮質下のセグメンテーションとボリューム測定、画像レジストレーション（テンソルベースの形態計測など）、およびいくつかの画質要件が満たされている場合に確実に使用できることを示します、皮質の厚さの形態計測でさえ..これらのスキャンを定量的に分析できないことは、ヘルスケアにおける定量的ニューロイメージングの採用を妨げ、巨大なサンプルサイズを達成し、それによって人間の脳の理解を大幅に向上させる可能性のある研究研究を妨げます。入力画像のコントラスト、解像度、向きに非常に敏感であるため、サイト内であっても、多様な臨床取得プロトコルに一般化されません。 
[概要]この制限により、臨床設定で毎年大きなスライス間間隔（「厚いスライス」）で取得された数百万のmriスキャンの分析が妨げられます。synthsrは、1つ以上の厚いスライススキャンを受信するcnnをトレーニングする方法です。さまざまなコントラスト、解像度、向き。高解像度のトレーニング分析を行わなくても、コントラスト、解像度、向きの任意の組み合わせでCNNをトレーニングするために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: White matter hyperintensities volume and cognition: Assessment of a deep
  learning based lesion detection and quantification algorithm on the
  Alzheimers Disease Neuroimaging Initiative -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.IV/paper_9.html">
      <font color="black">White matter hyperintensities volume and cognition: Assessment of a deep
  learning based lesion detection and quantification algorithm on the
  Alzheimers Disease Neuroimaging Initiative</font>
    </a>
  </h2>
  <font color="black">被験者のより大きなコホート（n = 290）で、より大きなWMHボリュームが、実行機能（P = .004）、記憶（P = .01）、および言語（P = .005）のパフォーマンスの低下と相関することを観察しました。そのため、WMHの正確な検出と定量化は非常に重要です。認知と白質高信号（WMH）ボリュームの関係は、使用される病変セグメンテーションアルゴリズムの精度に依存することがよくあります。 
[概要]被験者のサブセットを使用し、経験豊富な神経放射線科医から手動のwmhセグメンテーションを取得して、アルゴリズムの精度を実証しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Ensemble-CVDNet: A Deep Learning based End-to-End Classification
  Framework for COVID-19 Detection using Ensembles of Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.IV/paper_10.html">
      <font color="black">Ensemble-CVDNet: A Deep Learning based End-to-End Classification
  Framework for COVID-19 Detection using Ensembles of Networks</font>
    </a>
  </h2>
  <font color="black">この研究で提案された方法は、放射線科医が病気の早期診断に役立つ診断スクリーニングツールになると信じています。2019年12月に中国の武漢で始まった新しいタイプのコロナウイルス病（COVID-19）は続いています提案されたエンドツーエンドモデルでは、微調整後、ネットワークが特徴抽出器として並行して使用され、それらの上部にいくつかの追加レイヤーが使用されます。 
[要約] ctイメージングは、より多くの放射線量、より長い露光時間、より高いコストを必要とし、患者の動きに苦しむ可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: RAP-Net: Coarse-to-Fine Multi-Organ Segmentation with Single Random
  Anatomical Prior -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.IV/paper_11.html">
      <font color="black">RAP-Net: Coarse-to-Fine Multi-Organ Segmentation with Single Random
  Anatomical Prior</font>
    </a>
  </h2>
  <font color="black">私たちの方法を訓練および評価するために、十分に注釈が付けられた13の臓器を備えた100人の患者ボリュームからなる臨床研究コホートが使用されます。スコア84.58％対81.69％（p &lt;0.0001）..低解像度の粗いネットワークを使用して、3Dボリュームから複数の臓器のグローバルな事前コンテキストを抽出することから始まり、その後に、粗いパイプラインから細かいパイプラインを提案します。複数の臓器に対応するモデルではなく、単一の洗練されたモデルを使用してすべての腹部臓器をセグメント化するファインフェーズ。 
[ABSTRACT]高解像度で単一臓器の精密化を実行するために使用される13のモデル。解剖学的位置と境界情報を保持するために、対応する抽出パッチとともに腹部の事前を使用しました。また、4分割交差検証を使用してアルゴリズムをテストしました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Maximally Monotone Operators for Image Recovery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.IV/paper_12.html">
      <font color="black">Learning Maximally Monotone Operators for Image Recovery</font>
    </a>
  </h2>
  <font color="black">したがって、提案されたアプローチは、一次PnPアルゴリズムの漸近的振る舞いを分析するための健全な理論的フレームワークを提供します。最近、正則化に関連する演算子をより洗練されたデノイザーに置き換えるいくつかの研究が提案されています。 and-play（PnP）メソッドは、優れたパフォーマンスを示しています。 
[要約]これらは通常、不適切な逆問題に対処するように設計されています。関数の正則化を使用する代わりに、演算子の正則化を実行します。ここでは、最小単調関数が教師ありの方法で学習されます。代わりに、提案されたアプローチは、幅広いネットワークによるmmoの解決（nn）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: A Plug-and-Play Priors Framework for Hyperspectral Unmixing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.IV/paper_13.html">
      <font color="black">A Plug-and-Play Priors Framework for Hyperspectral Unmixing</font>
    </a>
  </h2>
  <font color="black">より具体的には、乗数の交互方向法（ADMM）を使用して、最適化問題を2つの反復サブ問題に分解します。ただし、強力な正則化を手作りすることは簡単ではなく、複雑な正則化は、最適化問題の解決にさらに困難をもたらす可能性があります。スペクトルアンミキシングの初期の解決策は、各ピクセルで独立して実行されます。 
[ABSTRACT]ハイパースペクトルアンミキシングは、ハイパースペクトルアンミキシングのためのツールです。混合ピクセルをコンポーネントマテリアルとそれに対応する存在量に分離することを目的としています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Using Spatial Logic and Model Checking for Nevus Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.IV/paper_14.html">
      <font color="black">Using Spatial Logic and Model Checking for Nevus Segmentation</font>
    </a>
  </h2>
  <font color="black">現在の研究では、母斑の（2D）画像の輪郭に取り組んでいます。最近の研究では、このモデル検査技術を、脳の磁気共鳴画像における腫瘍および関連する浮腫の（3D）輪郭に適用しました。大規模な公開データベースの画像に関する私たちの手法と、ドメインの専門家によって提供された関連するグラウンドトゥルースセグメンテーションと結果を比較します。 
[概要]最新の作品では、母斑の（2d）画像の輪郭に取り組んでいます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Contrast Computed Tomography Healthy Kidney Atlas -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.IV/paper_15.html">
      <font color="black">Multi-Contrast Computed Tomography Healthy Kidney Atlas</font>
    </a>
  </h2>
  <font color="black">ただし、マルチコントラストCT用の腹部および後腹膜臓器アトラスフレームワークはありません。アトラスと人口統計のリンクにより、集団間の腎臓の解剖学的構造の変化をよりよく理解できました。したがって、高解像度CT後腹膜アトラスを具体的に提案しました。非造影CTと初期動脈、後期動脈、静脈および遅延造影CTの腎臓に最適化されています。 
[概要]新しい高解像度のct後腹膜アトラスは、非造影CT全体の腎臓用に特別に最適化されています。これにより、集団全体の腎臓の解剖学的構造の変化をよりよく理解できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: An Efficient Recurrent Adversarial Framework for Unsupervised Real-Time
  Video Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.IV/paper_16.html">
      <font color="black">An Efficient Recurrent Adversarial Framework for Unsupervised Real-Time
  Video Enhancement</font>
    </a>
  </h2>
  <font color="black">ビデオエンハンスメントは、静止画よりも難しい問題です。これは主に、計算コストが高く、データ量が多く、時空間ドメインで一貫性を実現するのが難しいためです。特に、当社のビデオエンハンサーは1つあたり35フレーム以上をエンハンスできます。 FullHDビデオの2番目（1080x1920）。これらの課題に対処するために、ペアになっていないビデオの例から直接学習する効率的な敵対的なビデオエンハンスメントフレームワークを提案します。 
[ABSTRACT]新しいシステムでは、ペアになっていないビデオから周期的な敵対的な方法で学習できます。ここでは、提案された回帰ユニットが採用されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Unveiling Real-Life Effects of Online Photo Sharing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_0.html">
      <font color="black">Unveiling Real-Life Effects of Online Photo Sharing</font>
    </a>
  </h2>
  <font color="black">ソーシャルネットワークは、ユーザーのデータを悪用する権利と引き換えに、サービスへの無料アクセスを提供します。また、注意メカニズムを使用して、高評価の概念の検出を強化し、低評価の概念に圧倒されないようにします。 、データは、多くの場合透過的ではないさまざまなコンテキストでソーシャルネットワークやサードパーティによって使用されます。 
[ABSTRACT]ソーシャルネットワーキングは、ユーザーが選択した初期コンテキストで行われます。これらは、ユーザーレベルでのコンセプト評価とオブジェクト検出を集約する新しい画像記述子に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Soft-IntroVAE: Analyzing and Improving the Introspective Variational
  Autoencoder -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_1.html">
      <font color="black">Soft-IntroVAE: Analyzing and Improving the Introspective Variational
  Autoencoder</font>
    </a>
  </h2>
  <font color="black">Soft-IntroVAEを提案します。これは、生成されたサンプルのヒンジ損失項を滑らかな指数損失に置き換える修正IntroVAEです。興味深いことに、IntroVAEがデータ分布からのKL距離の合計を最小化する分布に収束することを示します。エントロピー用語..この作業では、IntroVAEモデル、その実際の実装、およびそのアプリケーションをよりよく理解するための一歩を踏み出します。 
[概要]はじめにの主なアイデアは、vaeエンコーダーを使用して、生成されたデータサンプルと実際のデータサンプルを区別して、vaeをトレーニングすることです。この変更により、トレーニングの安定性が大幅に向上し、完全なアルゴリズムの理論的分析も可能になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Spatio-temporal Multi-task Learning for Cardiac MRI Left Ventricle
  Quantification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_2.html">
      <font color="black">Spatio-temporal Multi-task Learning for Cardiac MRI Left Ventricle
  Quantification</font>
    </a>
  </h2>
  <font color="black">実験結果は、心臓の形態、画像の外観、および心臓のMRシーケンスのコントラストが低いにもかかわらず、提案された方法の堅牢性を強調しています。提案された方法は、129の平均平均絶対誤差（MAE）で高い予測精度を取得しました。 $ mm ^ 2 $、1.23 $ mm $、1.76 $ mm $、LVおよび心筋（Myo）キャビティ領域のピアソン相関係数（PCC）96.4％、87.2％、および97.5％、6 RWT、3 LV寸法、および位相分類のエラー率9.0 \％..この論文では、心臓のLV形態、局所壁厚（RWT）を定量化し、さらに検出する測定値の完全なセットを取得するための時空間マルチタスク学習アプローチを提案します。特定の3Dシネ磁気共鳴（MR）画像シーケンスの心臓位相サイクル（収縮期および拡張期）。 
[ABSTRACT]提案された方法は、3D空間-時間畳み込みに基づいています。これらの被験者は、mr画像から空間的および時間的特徴を抽出します。提案された方法は、高い予測精度を取得しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised deep clustering and reinforcement learning can accurately
  segment MRI brain tumors with very small training sets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_3.html">
      <font color="black">Unsupervised deep clustering and reinforcement learning can accurately
  segment MRI brain tumors with very small training sets</font>
    </a>
  </h2>
  <font color="black">ただし、病変/関心のある構造のセグメンテーションの基本的なタスクには対処しませんでした。このアプローチは、手でトレースした注釈を必要とせずに、放射線科医からの最小限の入力を必要とする人間同盟のAIを表しています。トレーニングデータをすぐにオーバーフィットし、テストセットで予想どおりにパフォーマンスが低下し（平均ダイススコア16％）、監視されていないディープクラスタリングと強化学習により、平均ダイススコア83％が達成されました。 
[ABSTRACT]テストは、病変の位置特定のために放射線画像に適用できます。また、病変/構造-関心のあるセグメンテーションを排除するために使用することもできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Learning from Crowds by Modeling Common Confusions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_4.html">
      <font color="black">Learning from Crowds by Modeling Common Confusions</font>
    </a>
  </h2>
  <font color="black">この作業では、アノテーションノイズを一般的なノイズと個々のノイズに分解し、インスタンスの難易度とアノテーターの専門知識に基づいて、インスタンスアノテーターごとに混乱の原因を区別する新しい視点を提供します。それぞれのノイズの原因を認識するアノテーションでは、補助ネットワークを使用して、インスタンスとアノテーターの両方に関して2つのノイズ適応レイヤーを選択します。クラウドソーシングは、低コストで大量のラベル付きデータを取得するための実用的な方法を提供します。 
[要約]クラウドソーシングされたアノテーションは、クラウドソーシングされたアノテーションから高品質のモデルを学習するための新しい課題を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Centralized Information Interaction for Salient Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_5.html">
      <font color="black">Centralized Information Interaction for Salient Object Detection</font>
    </a>
  </h2>
  <font color="black">この論文は、これらの接続を一元化することにより、それらの間のクロススケール情報相互作用を実現できることを示しています。したがって、意味的に強く、位置的に正確な特徴が得られます。計算の複雑さが少ない、広く使用されている5つのベンチマークに関する技術。新しく提案された戦略の可能性を刺激するために、空間補間なしでマルチスケール入力を同時に処理できる相対グローバルキャリブレーションモジュールをさらに設計します。 
[概要]既存のu-形状ベースの方法は、ボトムアップとトップダウンの相互作用の改善に焦点を当てています。現在、ほとんどの既存のuターンベースの方法は、接続の改善に焦点を当てています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Automated Scoring of Nuclear Pleomorphism Spectrum with
  Pathologist-level Performance in Breast Cancer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_6.html">
      <font color="black">Automated Scoring of Nuclear Pleomorphism Spectrum with
  Pathologist-level Performance in Breast Cancer</font>
    </a>
  </h2>
  <font color="black">核の多形性は変化の連続スペクトルを反映していることを考えると、ネットワークを従来の3つのカテゴリの分類に制約することなく、複数の病理学者の集合的な知識から、多種多様な腫瘍領域でディープニューラルネットワークをトレーニングしました。ここで定義する核の多形性腫瘍核の全体的な外観の異常の程度は、3層の乳がんの等級付けの要素の1つです。また、ルーチンに従って、ベースラインとして正常な上皮の追加の利点について説明する追加のアプローチを動機付けます病理学者が腫瘍の核多形性をスコアリングするように訓練され、比較のために正常な乳房上皮を持っている臨床診療。 
[概要]科学者は、複数の病理学者の集合的な知識から、多種多様な腫瘍領域でディープニューラルネットワークをトレーニングしました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Effective Deployment of CNNs for 3DoF Pose Estimation and Grasping in
  Industrial Settings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_7.html">
      <font color="black">Effective Deployment of CNNs for 3DoF Pose Estimation and Grasping in
  Industrial Settings</font>
    </a>
  </h2>
  <font color="black">ラベリング段階を自動化することで、本番レベルでの使用に適した非常に堅牢なシステムも得られます。ディープラーニングベースのソリューションが提案された場合、通常、トレーニングデータを生成する簡単な方法がありません。このホワイトペーパーでは、ロボット把持アプリケーションなどの実用的な産業環境でディープラーニングを効果的に展開します。 
[概要]ディープラーニングベースの目標が提案されていますが、トレーニングデータを生成するための簡単な方法は必要ありません。システムは畳み込みニューラルネットワーク（cnns）に基づく3自由度のポーズ推定器で構成されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic Facial Expression Recognition under Partial Occlusion with
  Optical Flow Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_8.html">
      <font color="black">Dynamic Facial Expression Recognition under Partial Occlusion with
  Optical Flow Reconstruction</font>
    </a>
  </h2>
  <font color="black">将来の再現性のある公正な比較の基礎を築くために、オクルージョンの生成と再構成の評価を含む新しい実験プロトコルも提案します。私たちの実験は、提案された方法が認識精度の点でギャップを大幅に削減することを示しています。閉塞状態と非閉塞状態の間で..私たちの知る限り、これは顔の表情認識のための動きを直接再構築する最初の提案です。 
[概要]新しい顔認識は依然として困難な作業ですが、部分的な顔の咬合が存在する場合の認識は依然として課題です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Seesaw Loss for Long-Tailed Instance Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_9.html">
      <font color="black">Seesaw Loss for Long-Tailed Instance Segmentation</font>
    </a>
  </h2>
  <font color="black">その結果、テールカテゴリのオブジェクトは、背景またはヘッドカテゴリとして誤って分類される可能性が高くなります。単純なエンドツーエンドのトレーニングパイプラインにより、Seesaw Lossは、クロスエントロピー損失よりも大幅に向上し、最先端の機能を実現します。ベルとホイッスルのないLVISデータセットでのパフォーマンス..異なるカテゴリ間の累積トレーニングインスタンスの比率。 
[要約]テールクラスの負のサンプルの圧倒的なスケールは、分類器の偏った学習プロセスにつながります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-23">
        <br><font color="black">2020-08-23</font>
      </time>
    </span>
</section>
<!-- paper0: UMLE: Unsupervised Multi-discriminator Network for Low Light Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_10.html">
      <font color="black">UMLE: Unsupervised Multi-discriminator Network for Low Light Enhancement</font>
    </a>
  </h2>
  <font color="black">この問題に対処するために、複数の弁別子を含むリアルタイムの教師なし生成的敵対的ネットワーク（GAN）を提案します。これらの異なる弁別器により、異なる視点からの画像の評価が可能になります。さらに、異なるチャネル特徴には異なる情報が含まれ、画像内の照明が不均一であることを考慮して、特徴融合注意モジュールを提案します。 
[概要]低照度シナリオは、視覚ベースのアプリケーションに深刻な影響を及ぼします。これらには、マルチスケール弁別器、テクスチャ弁別器、および色弁別器が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Person Re-Identification using Deep Learning Networks: A Systematic
  Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_11.html">
      <font color="black">Person Re-Identification using Deep Learning Networks: A Systematic
  Review</font>
    </a>
  </h2>
  <font color="black">いくつかの既存のre-idレビュー作業では、単一の側面からre-id手法を分析しましたが、このレビューでは、ディープアーキテクチャタイプ、一般的なRe-Idの課題（ポーズの変化、稲妻など）などの複数の深層学習の側面から多数のre-id手法を評価します。 、表示、拡大縮小、部分的または完全なオクルージョン、背景の乱雑さ）、マルチモーダルRe-Id、クロスドメインRe-Idチャレンジ、メトリック学習アプローチ、およびビデオRe-Idの貢献..最新のディープRe-ID作品の包含これは、re-idの文献に大きく貢献しています。最後に、結論と今後の方向性が含まれています。 
[要約]レビューでは、最新のディープラーニングベースのアプローチによる個人の再識別を確認します。レビューには、長年にわたって収集されたいくつかのre-idベンチマークも含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Improving the Certified Robustness of Neural Networks via Consistency
  Regularization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_12.html">
      <font color="black">Improving the Certified Robustness of Neural Networks via Consistency
  Regularization</font>
    </a>
  </h2>
  <font color="black">敵対的な例でニューラルネットワークの堅牢性を向上させるために、さまざまな防御方法が提案されています。その中で、証明可能な防御方法は、攻撃者に対して確実に堅牢なニューラルネットワークをトレーニングするのに効果的であることが実証されています。この発見に動機付けられて、誤分類された例の認定領域内のすべての例の出力確率分布を制約する、誤分類を意識した敵対的正則化（MAAR）と呼ばれる新しい防御正則化用語。このペーパーでは、誤分類された例によって引き起こされるこの不整合を調査し、新しい一貫性を追加します。誤分類された例をより有効に活用するための正則化用語。 
[概要]提案されたマールは、cifar（いくつかの最先端の方法と比較して10およびmnistデータセット）で最高の認定された堅牢性と同等の精度を備えています。誤って分類された例に対する認定された堅牢性の制約が一貫している場合、提案されたマールは大幅に改善できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: A non-alternating graph hashing algorithm for large scale image search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_13.html">
      <font color="black">A non-alternating graph hashing algorithm for large scale image search</font>
    </a>
  </h2>
  <font color="black">補助変数の存在は、計算の複雑さを増す座標降下アプローチにつながります。これらの変数を導入する必要はないと主張します。この課題を軽減するために、バイナリコードを取得する計算負荷を軽減し、それでも達成するためのさまざまな緩和アプローチが提案されています。良い解決策。 
[ABSTRACT]ハッシュは、ビッグデータに伴うコンピューティングの制限に対処するための最も効果的なアプローチの1つです。ただし、バイナリ制約のため、変数の数がデータと等しい元の空間で問題を解決する代わりに、アプリケーションは扱いにくくなります。ポイント、私たちははるかに小さなスペースで問題を解決し、このソリューションからバイナリコードを取得します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Fine-grained Attention and Feature-sharing Generative Adversarial
  Networks for Single Image Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_14.html">
      <font color="black">Fine-grained Attention and Feature-sharing Generative Adversarial
  Networks for Single Image Super-Resolution</font>
    </a>
  </h2>
  <font color="black">まず、画像を本物と偽物で区別する単一のスコアを生成する代わりに、画像の超解像のための細粒度注意生成敵対的ネットワーク（FASRGAN）と呼ばれるバリアントを提案して、各ピクセルを本物と偽物で区別します。スコアマップはHR / SR画像と同じ空間サイズを持ち、各ピクセルの再構成の難しさの程度を表すためのきめ細かい注意として機能します。FASRGANは、画像スコアと2つの出力を持つ識別器としてUnetのようなネットワークを採用しています。画像スコアマップ。 
[概要]ジェネレーターに異なるネットワークを使用する代わりに、ジェネレーターとディスクリミネーターの両方に機能共有ネットワーク（fs-srgan）を使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br><font color="black">2019-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Objective Class-based Micro-Expression Recognition through Simultaneous
  Action Unit Detection and Feature Aggregation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_15.html">
      <font color="black">Objective Class-based Micro-Expression Recognition through Simultaneous
  Action Unit Detection and Feature Aggregation</font>
    </a>
  </h2>
  <font color="black">具体的には、より効果的なAU特徴学習のために、AU検出モジュールで2つの新しい戦略を提案します。注意メカニズムとバランスの取れた検出損失関数です。さらに、単一モデルベースのマイクロエクスプレッションAU検出結果も報告します。私たちのモデルには、調整された客観的なクラスベースのAUナレッジグラフが組み込まれています。これにより、GCNはAUレベルの特徴をマイクロエクスプレッションレベルの特徴表現に集約できます。 
[概要]この論文では、客観的クラスベースのmer.itがausを同時に検出し、グラフ畳み込みネットワーク（gcn）を介してauレベルの特徴をmicro-expression-level学習に集約するための新しいディープニューラルネットワークモデルを提案します。戦略、機能は統合モデルで学習され、エラーを排除します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Style Transfer by Rigid Alignment in Neural Net Feature Space -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_16.html">
      <font color="black">Style Transfer by Rigid Alignment in Neural Net Feature Space</font>
    </a>
  </h2>
  <font color="black">この作業では、スタイルパターンをシームレスに転送し、スタイル画像のコンテンツ構造をそのまま維持する、任意のスタイル転送の効果的かつ効率的なアプローチを示します。高品質の定型化された画像を生成して比較することにより、提案されたアプローチの有効性を示します。任意のスタイルの転送のための現在の最先端技術による結果..任意のスタイルの転送は、任意のスタイルの画像から特定のコンテンツ画像にスタイルパターンを転送することを目的とするコンピュータビジョンの重要な問題です。 
[概要]これは、固定配置を使用してスタイル機能をコンテンツ機能に揃えることによって行います。これは、反対の方法を実行する既存の方法とは異なり、スタイル機能を変更することによって行います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-27">
        <br><font color="black">2019-09-27</font>
      </time>
    </span>
</section>
<!-- paper0: Interpolating Points on a Non-Uniform Grid using a Mixture of Gaussians -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_17.html">
      <font color="black">Interpolating Points on a Non-Uniform Grid using a Mixture of Gaussians</font>
    </a>
  </h2>
  <font color="black">これを行うには、既知の各ピクセルを2D正規分布として表し、各出力画像ピクセルをすべての既知のピクセルの混合からのサンプルと見なします。任意に配置されたピクセルのセットから画像を再構築する機能とは別に、これにより、ダウンストリームアプリケーションに役立つ可能性のある補間手順を介して区別します。この作業では、ガウス混合モデルに基づいて不均一な画像補間を実行するアプローチを提案します。 
[ABSTRACT]任意に配置されたピクセル値から画像を生成できる補間方法を開発します。これにより、補間手順で区別できるようになり、ダウンストリームマークに役立つ可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Control of computer pointer using hand gesture recognition in motion
  pictures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_18.html">
      <font color="black">Control of computer pointer using hand gesture recognition in motion
  pictures</font>
    </a>
  </h2>
  <font color="black">拳、手のひら、左向き、右向きの4つのクラスを含む6720の画像サンプルを含む手のデータセットが収集されます。画像は、単純な背景、さまざまな視点、光条件で15人からキャプチャされます。最後にコマンドは、カーソルをクリック、右クリック、および移動するように定義されています。 
[概要] 6720の画像サンプルを含む手のデータセットが収集されます。cnnネットワークは、ラベルを予測するためにこのデータセットでトレーニングされます。アルゴリズムの精度は91. 88％で、さまざまなバックグラウンドで使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Memory-Efficient Hierarchical Neural Architecture Search for Image
  Restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_19.html">
      <font color="black">Memory-Efficient Hierarchical Neural Architecture Search for Image
  Restoration</font>
    </a>
  </h2>
  <font color="black">実験結果は、HiNASによって発見されたアーキテクチャは、最先端の方法と比較して非常に競争力のあるパフォーマンスを達成しながら、パラメータが少なく、推論速度が速いことを示しています。外部検索スペースについては、メモリを節約するためのセル共有戦略を提案します。提案されたHiNASは、メモリと計算の両方の効率が高いです。 
[ABSTRACT] hinasは、低レベル画像の効率的なネットワークアーキテクチャを設計するシステムを提案しました。外部検索スペースでは、メモリを節約し、検索速度を高速化するセル共有戦略を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: LEUGAN:Low-Light Image Enhancement by Unsupervised Generative
  Attentional Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_20.html">
      <font color="black">LEUGAN:Low-Light Image Enhancement by Unsupervised Generative
  Attentional Networks</font>
    </a>
  </h2>
  <font color="black">実験により、提案されたアルゴリズムが最先端の方法に対して、特に画像の鮮明度とノイズ制御の観点から実際の画像に対して良好に機能することが検証されます。既存のディープネットワークベースのアルゴリズムのほとんどは、ペアワイズ画像でトレーニングされるように設計されています。具体的には、私たちのネットワークには2つの部分があります。より鋭いエッジを復元するエッジ補助モジュールと、よりリアルな色を復元する注意ガイダンスモジュールです。 
[概要]この記事では、教師なし生成ネットワークに注意を払い、低照度モジュールの拡張タスクを処理するためのガイダンスを提案します。生成された画像のエッジをより見やすくするための新しい損失関数が含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Image Reconstruction with Misaligned Structural Information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_21.html">
      <font color="black">Robust Image Reconstruction with Misaligned Structural Information</font>
    </a>
  </h2>
  <font color="black">再構築と登録を共同で実行し、それによってこのハードルを克服する変分フレームワークを提案します。過去数十年の研究により、複数のモダリティからのデータを組み合わせるための多数の数学的方法がもたらされました。したがって、提案されたフレームワークにより、共有情報を実際の条件下での複数のモダリティ。 
[概要]マルチコントラストMRI、ペットMRI、および複数の手術は、定量的および定性的に画像再構成を大幅に改善することが示されています。これらのタイプのハイパースペクトルイメージングには、材料科学におけるハイパースペクトルイメージングとマルチコントラストMRIが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-01">
        <br><font color="black">2020-04-01</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Ancient Roman Republican Coin Classification via Feature Fusion and
  Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_22.html">
      <font color="black">Deep Ancient Roman Republican Coin Classification via Feature Fusion and
  Attention</font>
    </a>
  </h2>
  <font color="black">モデルとデータセットはhttps://github.com/saeed-anwar/CoinNetで入手できます。この目的のために、コンパクトな双線形プーリング、残差グループ、および特徴注意層を採用する新しいネットワークモデルCoinNetを紹介します。また、ネットワークとその一般化機能の詳細なアブレーション研究も提供します。 
[概要]これらのコインのほとんどは、古さや保存の程度の違いにより侵食されています。共和政ローマのコインの最大かつ最も多様なモデルデータセットを収集しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-26">
        <br><font color="black">2019-08-26</font>
      </time>
    </span>
</section>
<!-- paper0: WEmbSim: A Simple yet Effective Metric for Image Captioning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_23.html">
      <font color="black">WEmbSim: A Simple yet Effective Metric for Image Captioning</font>
    </a>
  </h2>
  <font color="black">したがって、WEmbSimは、正当化される複雑なメトリックの新しいベースラインを設定すると考えています。自動画像キャプション評価の領域は、適切性と流暢さの要件を満たすことができるキャプションを生成するニーズに対処するために、依然として集中的な調査が行われています。人間の判断とシステムレベルの相関関係でSPICE、CIDEr、WMDなどの複雑な測定値を打ち負かす効果的なメトリックWEmbSimに関する研究を提案しました。 
[要約]コサイン類似度は、キャプションの単語埋め込み（mowe）の平均を使用して、監視されていないキャプション評価で驚くほど高いパフォーマンスを実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Global Convergence of Model Function Based Bregman Proximal Minimization
  Algorithms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_24.html">
      <font color="black">Global Convergence of Model Function Based Bregman Proximal Minimization
  Algorithms</font>
    </a>
  </h2>
  <font color="black">収束分析は、新しいリアプノフ関数に基づいています。提案されたMAPプロパティに基づいて、いくつかの既存のアルゴリズムを統合するモデルBPGと呼ばれるグローバル収束アルゴリズムを提案します。$を一般化するMAPプロパティを提案することにより、この問題を修正します。 L $ -smadプロパティであり、非凸非平滑複合問題の大規模なクラスにも有効です。 
[概要] $ l $ -smadプロパティは、滑らかでない関数を処理できません。これらには、関数の$やabsなどの単純な滑らかでない関数が含まれます。ただし、これらには、新しいシステムの普遍的な認識が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Hausdorff Point Convolution with Geometric Priors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_25.html">
      <font color="black">Hausdorff Point Convolution with Geometric Priors</font>
    </a>
  </h2>
  <font color="black">また、マルチスケール特徴エンコーディング用のマルチカーネルHPCを設計することにより、階層的特徴学習を実現します。入力とカーネルポイントセット間の最短距離を組み合わせるためにネットワークの重みを調整することで、タスク固有の学習を実現できます。 HPCベースのディープニューラルネットワーク（HPC-DNN）。 
[概要] hpc-dnnは、ストロングポイント畳み込みベースラインを上回り、セマンティックセグメンテーションタスクタスクのs3disで2.8％miouパフォーマンスの向上、semantickittiで1.5％のパフォーマンス向上を達成</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Overcoming False Positives in Visual Relationship Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_26.html">
      <font color="black">Towards Overcoming False Positives in Visual Relationship Detection</font>
    </a>
  </h2>
  <font color="black">BNPSは、提案を5つの明確に定義されたサブクラスに分割し、逆頻度に従ってバランスの取れたトレーニング分布を生成します。不均衡な分布の下でモデルを効果的に最適化するために、SABRAはミニバッチサンプリングにバランスの取れた負の提案サンプリング（BNPS）戦略を採用します。最適化の状況が容易になり、誤検知の数が大幅に減少します。 
[要約]トレーニングでは、関係提案の分布は非常に不均衡です。sabraは、ミニバッチサンプリングのためのバランスの取れたネガティブ提案サンプリング（bnps）戦略を開発します。sabraはsotaメソッドを大幅に上回っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: An Aggregate Method for Thorax Diseases Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_27.html">
      <font color="black">An Aggregate Method for Thorax Diseases Classification</font>
    </a>
  </h2>
  <font color="black">この論文では、損失関数のトレーニングパターンの重みは、クラス内のトレーニングパターンの数だけでなく、1つがこのトレーニングパターンをポジティブとして扱い、他のノードがそれを扱うさまざまなノードに基づいて設計されています。ネガティブとして..胸部X線画像データセットの実験結果は、この新しい重み付けスキームが分類パフォーマンスを改善し、EfficientNetからのトレーニング最適化もパフォーマンスをさらに改善することを示しています。実際の医療画像分類に見られる一般的な問題は、正のパターンが通常まれであるデータセット内の正と負のパターンの固有の不均衡。 
[概要]このシステムは、胸部疾患分類問題のための最先端のディープネットワークアーキテクチャに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-07">
        <br><font color="black">2020-08-07</font>
      </time>
    </span>
</section>
<!-- paper0: Joint super-resolution and synthesis of 1 mm isotropic MP-RAGE volumes
  from clinical MRI exams with scans of different orientation, resolution and
  contrast -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_28.html">
      <font color="black">Joint super-resolution and synthesis of 1 mm isotropic MP-RAGE volumes
  from clinical MRI exams with scans of different orientation, resolution and
  contrast</font>
    </a>
  </h2>
  <font color="black">ただし、これらのアプローチは、入力画像のコントラスト、解像度、方向に非常に敏感であるため、サイト内であっても、さまざまな臨床取得プロトコルに一般化されません。SynthSRで生成された画像を、一連の一般的なダウンストリーム分析でテストします。そして、それらが皮質下セグメンテーションとボリューム測定、画像レジストレーション（例えば、テンソルベースの形態計測）、そしていくつかの画質要件が満たされている場合は、皮質の厚さの形態計測にも確実に使用できることを示しています。CNNの最近の進歩は優れた結果を生み出しています。 MRIの超解像度およびコントラスト合成において。 
[概要]この制限により、臨床設定で毎年大きなスライス間間隔（「厚いスライス」）で取得された数百万のmriスキャンの分析が妨げられます。synthsrは、1つ以上の厚いスライススキャンを受信するcnnをトレーニングする方法です。さまざまなコントラスト、解像度、向き。高解像度のトレーニング分析を行わなくても、コントラスト、解像度、向きの任意の組み合わせでCNNをトレーニングするために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Excavating "Excavating AI": The Elephant in the Gallery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_29.html">
      <font color="black">Excavating "Excavating AI": The Elephant in the Gallery</font>
    </a>
  </h2>
  <font color="black">ケイト・クローフォードとトレバー・パグレンによる2つの美術展、「TrainingHumans」と「MakingFaces」、および付随するエッセイ「Excavating AI：機械学習トレーニングセットの画像の政治」は、社会で行われる言説に大きな影響を与えていますとマスメディアネットワーク、およびいくつかの学界..私たちの分析は、芸術やその他のコンテキストで人間のデータを使用する場合の情報に基づく同意の交渉不可能性を強調し、MLトレーニングセットの説明に関連する問題を明らかにします。しかし、批判的な精査は明らかにします。顔画像の使用に関する情報に基づく同意に関する自己矛盾したスタンス、およびMLトレーニングセットに対する批判の重大な欠陥。 
[概要]重要な精査調査調査調査トレーニングセットと人間のトレーニングセット。自白のalalalalトレーニングセットはトレーニングセットの例です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: MobileSal: Extremely Efficient RGB-D Salient Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_30.html">
      <font color="black">MobileSal: Extremely Efficient RGB-D Salient Object Detection</font>
    </a>
  </h2>
  <font color="black">さらに、効率的なマルチレベルの特徴集約のためのコンパクトピラミッドリファインメント（CPR）を提案し、明確な境界を持つ顕著なオブジェクトを導出できるようにします。問題は、モバイルネットワークは面倒なネットワークよりも特徴表現の能力が低いことです。IDRのみが採用されています。トレーニングフェーズでは、テスト中に省略されるため、計算は不要です。 
[概要]たとえば、カラー画像の深度情報は、面倒な場合に芝に関連する特徴表現を強化できることを観察しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Momentum-Contrastive Pre-Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_31.html">
      <font color="black">Adversarial Momentum-Contrastive Pre-Training</font>
    </a>
  </h2>
  <font color="black">MoCoのアイデアに基づいて、このペーパーでは、2つの動的メモリバンクを設計して、歴史的なクリーンな表現と敵対的な表現をそれぞれ維持し、長期間..一方、敵対的訓練はまったく逆です..経験的結果は、開発されたアプローチが現在の最先端の敵対的頑健性をさらに改善することを示しています。 
[要約]調査によると、敵対的な自己教師あり事前トレーニングは、バインディング表現を抽出するのに役立ちます。データ拡張に基づいて、amocは、より小さなバッチサイズとより少ないトレーニングエポックを使用できますが、より堅牢な機能を学習できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Conditional Pre-training for Transfer Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_32.html">
      <font color="black">Efficient Conditional Pre-training for Transfer Learning</font>
    </a>
  </h2>
  <font color="black">教師なし設定と教師なし設定の両方でImageNetを事前トレーニングし、ターゲットデータセットとタスクの多様なコレクションを微調整することで、手法を検証します。大規模データセットでの事前トレーニングは非常に便利ですが、最大の欠点はトレーニングコストが高いことです。 。以前の作業とは異なり、パフォーマンスに加えて、効率、適応性、柔軟性に重点を置いています。 
[概要]有用性の低いサンプルを削除するための効率的なターゲットデータセットを提案します。画像の解像度を下げると、コストとパフォーマンスのトレードオフが大きくなることがわかります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-20">
        <br><font color="black">2020-11-20</font>
      </time>
    </span>
</section>
<!-- paper0: White matter hyperintensities volume and cognition: Assessment of a deep
  learning based lesion detection and quantification algorithm on the
  Alzheimers Disease Neuroimaging Initiative -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_33.html">
      <font color="black">White matter hyperintensities volume and cognition: Assessment of a deep
  learning based lesion detection and quantification algorithm on the
  Alzheimers Disease Neuroimaging Initiative</font>
    </a>
  </h2>
  <font color="black">そのため、WMHの正確な検出と定量化は非常に重要です。被験者のより大きなコホート（n = 290）で、より大きなWMHボリュームが実行機能（P = .004）、記憶（P = .01）、および言語（P = .005）..ここでは、ディープラーニングベースのWMHセグメンテーションアルゴリズムであるStackGen-Netを使用して、ADNIからの3DFLAIRボリューム上のWMHを検出および定量化します。 
[概要]被験者のサブセットを使用し、経験豊富な神経放射線科医から手動のwmhセグメンテーションを取得して、アルゴリズムの精度を実証しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: RAP-Net: Coarse-to-Fine Multi-Organ Segmentation with Single Random
  Anatomical Prior -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_34.html">
      <font color="black">RAP-Net: Coarse-to-Fine Multi-Organ Segmentation with Single Random
  Anatomical Prior</font>
    </a>
  </h2>
  <font color="black">私たちの方法を訓練および評価するために、十分に注釈が付けられた13の臓器を備えた100人の患者ボリュームからなる臨床研究コホートが使用されます。スコア84.58％対81.69％（p &lt;0.0001）..低解像度の粗いネットワークを使用して、3Dボリュームから複数の臓器のグローバルな事前コンテキストを抽出することから始まり、その後に、粗いパイプラインから細かいパイプラインを提案します。複数の臓器に対応するモデルではなく、単一の洗練されたモデルを使用してすべての腹部臓器をセグメント化するファインフェーズ。 
[ABSTRACT]高解像度で単一臓器の精密化を実行するために使用される13のモデル。解剖学的位置と境界情報を保持するために、対応する抽出パッチとともに腹部の事前を使用しました。また、4分割交差検証を使用してアルゴリズムをテストしました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Rotation Equivariant Siamese Networks for Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_35.html">
      <font color="black">Rotation Equivariant Siamese Networks for Tracking</font>
    </a>
  </h2>
  <font color="black">回転は、視覚的なオブジェクトトラッキングで遭遇する、長く普及しているがまだ解決されていない難しい課題の1つです。SiamNetsを使用すると、教師なしでオブジェクトの向きの変化を推定できるため、相対的な2Dポーズ推定でも使用できます。 2つの人気のあるシャムアーキテクチャで、RE-SiamNetが回転の問題を非常にうまく処理し、通常のアーキテクチャよりも優れていることを示します。 
[概要]既存の深層学習ベースの追跡アルゴリズムは、本質的に並進同変であるが、回転に取り組むようには設計されていない通常のcnnを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning-Based Human Pose Estimation: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_36.html">
      <font color="black">Deep Learning-Based Human Pose Estimation: A Survey</font>
    </a>
  </h2>
  <font color="black">2014年以降の240を超える研究論文がこの調査でカバーされています。人気のあるデータセットでレビューされた方法の定量的パフォーマンス比較が要約され、議論されています。さらに、2Dおよび3Dの人間の姿勢推定データセットと評価メトリックが含まれています。 
[概要]人間-コンピュータインタラクション、モーション分析、拡張現実、仮想現実が開発されました。調査論文の目的は、最近のディープラーニングベースのソリューションの包括的なレビューを提供することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: MRDet: A Multi-Head Network for Accurate Oriented Object Detection in
  Aerial Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_37.html">
      <font color="black">MRDet: A Multi-Head Network for Accurate Oriented Object Detection in
  Aerial Images</font>
    </a>
  </h2>
  <font color="black">本論文では、任意指向領域提案ネットワーク（AO-RPN）を提案し、水平アンカーから変換された指向提案を生成します。さらに、正確な境界ボックスを取得するために、検出タスクを複数のサブタスクに分離し、マルチヘッドを提案します。それらを達成するためのネットワーク..各ヘッドは、対応するタスクに最適な機能を学習するように特別に設計されているため、ネットワークでオブジェクトを正確に検出できます。 
[概要]最近開発された多くの方法は、短期的な課題を解決しようとします。これには、追加の方向係数の推定や高密度のアンカーの配置が含まれます。これにより、モデルの複雑さとコストが高くなります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: FracTrain: Fractionally Squeezing Bit Savings Both Temporally and
  Spatially for Efficient DNN Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_38.html">
      <font color="black">FracTrain: Fractionally Squeezing Bit Savings Both Temporally and
  Spatially for Efficient DNN Training</font>
    </a>
  </h2>
  <font color="black">コードはhttps://github.com/RICE-EIC/FracTrainで入手できます。たとえば、CIFAR-10でResNet-74をトレーニングすると、FracTrainはそれぞれ77.6％と53.5％の計算コストとトレーニングレイテンシの節約を達成します。最高のSOTAベースラインと比較して、同等の（-0.07％）精度を達成します。ディープニューラルネットワーク（DNN）の最近のブレークスルーにより、オンサイト学習を備えたインテリジェントエッジデバイスに対する途方もない需要が高まり、そのようなシステムの実用化が実現しました。エッジで利用できるリソースが限られていることと、最先端の（SOTA）DNNに必要な膨大なトレーニングコストのために、依然として課題が残っています。 
[概要]低-高精度のdnnトレーニングは、コストとエネルギー効率の最も効果的なノブの1つです。fractrainは、（i）プログレッシブフラクショナルデマンドオプションのオプションオプションdnnトレーニングと大規模なフラクショナル量子化を統合します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Union-net: A deep neural network model adapted to small data sets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_39.html">
      <font color="black">Union-net: A deep neural network model adapted to small data sets</font>
    </a>
  </h2>
  <font color="black">実際のアプリケーションでは、一般に小さなデータセットを取得できます。各ユニオンモジュールは畳み込み層に相当します。モデルコードはhttps://github.com/yeaso/union-netで公開されています
[要約]このペーパーでは、ユニオンコンボリューションの概念。日常のアプリケーションシナリオで高い実用的価値があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: P4Contrast: Contrastive Learning with Pairs of Point-Pixel Pairs for
  RGB-D Scene Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_40.html">
      <font color="black">P4Contrast: Contrastive Learning with Pairs of Point-Pixel Pairs for
  RGB-D Scene Understanding</font>
    </a>
  </h2>
  <font color="black">実験は、この提案されたアプローチが、以前の事前トレーニングアプローチよりも3つの大規模RGB-Dシーン理解ベンチマーク（ScanNet、SUN RGB-D、および3RScan）で優れたパフォーマンスをもたらすことを示しています。この問題を解決するために、対照的な「点のペア-正の値には対応するRGB-Dポイントのペアが含まれ、負の値には2つのモダリティの1つが乱されているか、2つのRGB-Dポイントが対応していないペアが含まれます。このアプローチは大きな成功を収めています。画像と点群の両方の特徴抽出器を事前トレーニングするためのものですが、特に高レベルのシーンの理解を促進する目的で、マルチモーダルRGB-Dスキャンについてはほとんど調査されていません。 
[概要]有望なアプローチは、対照学習を使用して潜在空間を学習することです。これらの機能は、類似のデータサンプルでは近く、異なるデータサンプルでは遠く離れています。この提案されたアプローチは、3つの大規模なrgb-dシーン理解ベンチマークでより優れたパフォーマンスを提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Global Context Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_41.html">
      <font color="black">Global Context Networks</font>
    </a>
  </h2>
  <font color="black">結果として得られるネットワーク要素は、グローバルコンテキスト（GC）ブロックと呼ばれ、軽量な方法でグローバルコンテキストを効果的にモデル化し、バックボーンネットワークの複数のレイヤーに適用してグローバルコンテキストネットワーク（GCNet）を形成できるようにします。 2層のボトルネックによる非ローカルブロックの1層変換関数。これにより、パラメータ数がさらに大幅に削減されます。ただし、厳密な経験的分析により、非ローカルネットワークによってモデル化されたグローバルコンテキストは次のようになります。異なるクエリ位置でもほぼ同じです。 
[概要] gcnetは一般に、さまざまな認識タスクの主要なベンチマークでimnetを上回っています。実験によると、gcnetは一般にネットワークネットワークを形成しています。gcnetは世界で最も効果的なツールであることがわかりました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: EPSNet: Efficient Panoptic Segmentation Network with Cross-layer
  Attention Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_42.html">
      <font color="black">EPSNet: Efficient Panoptic Segmentation Network with Cross-layer
  Attention Fusion</font>
    </a>
  </h2>
  <font color="black">基本的に、EPSNetは、プロトタイプマスクとマスク係数の単純な線形結合に基づいてマスクを生成します。たとえば、セグメンテーションやセマンティックセグメンテーションなどの軽量ネットワークブランチは、マスク係数を予測し、プロトタイプネットワークブランチによって予測された共有プロトタイプでマスクを生成するだけで済みます。さらに、共有プロトタイプの品質を高めるために、「クロスレイヤーアテンションフュージョンモジュール」と呼ばれるモジュールを採用しています。このモジュールは、マルチスケール機能をアテンションメカニズムと統合して、相互の長距離依存関係をキャプチャします。 
[概要]現在の最先端の研究では、結論についてあまり懸念していません。共有プロトタイプの品質を向上させるために、「クロスレイヤーアテンションフュージョン」モジュールを開発しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-23">
        <br><font color="black">2020-03-23</font>
      </time>
    </span>
</section>
<!-- paper0: Model Rubik's Cube: Twisting Resolution, Depth and Width for TinyNets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_43.html">
      <font color="black">Model Rubik's Cube: Twisting Resolution, Depth and Width for TinyNets</font>
    </a>
  </h2>
  <font color="black">ネットワークの拡大とは異なり、小さなネットワークでは幅よりも解像度と奥行きの方が重要であることがわかります。たとえば、TinyNet-Eはわずか24MのFLOPで59.9％のTop-1精度を達成し、それよりも約1.9％高くなっています。 ImageNetベンチマークでの実験結果は、逆ジャイアント式を使用したEfficientNetsの小さいバージョンよりもTinyNetのパフォーマンスがはるかに優れていることを示しています。 
[概要]このペーパーは、最小のモデルサイズと望遠鏡のコストでより深いニューラルネットワークを取得するためのツイストルールを調査することを目的としています。tinynetは、逆巨大式を使用した効率的なネットの小さいバージョンよりもはるかに優れたパフォーマンスを示しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring Motion Boundaries in an End-to-End Network for Vision-based
  Parkinson's Severity Assessment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_44.html">
      <font color="black">Exploring Motion Boundaries in an End-to-End Network for Vision-based
  Parkinson's Severity Assessment</font>
    </a>
  </h2>
  <font color="black">また、モデルのパフォーマンスを向上させるために一時的な注意メカニズムを展開します。さらに、動きの境界は、より良い動きの評価のためにカメラの動きの効果を難読化するのに役立つ追加の入力モダリティとして調査されます。さまざまなデータモダリティの効果を除去します。提案されたネットワークの精度について、他の一般的なアーキテクチャと比較します。 
[概要] pdを測定するためのエンドツーエンドのディープラーニングフレームワークを提示します。また、モデルのパフォーマンスを向上させるために、膨張した反応メカニズムを展開しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-17">
        <br><font color="black">2020-12-17</font>
      </time>
    </span>
</section>
<!-- paper0: EDN: Salient Object Detection via Extremely-Downsampled Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_45.html">
      <font color="black">EDN: Salient Object Detection via Extremely-Downsampled Network</font>
    </a>
  </h2>
  <font color="black">したがって、この作業はSODの新しい考え方を刺激することが期待されます。新しいスケール相関ピラミッド畳み込み（SCPC）も、上記の極端なダウンサンプリングからオブジェクトの詳細を復元するためのエレガントなデコーダーを構築するように設計されています。広範な実験により、EDNが達成することが実証されています。 \ sリアルタイムの速度でパフォーマンスをアートします。 
[概要]改良されたネットワーク（edn）は、極端なダウンサンプリング手法を使用して、画像全体のグローバルビューを学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Appearance-Invariant 6-DoF Visual Localization using Generative
  Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_46.html">
      <font color="black">Appearance-Invariant 6-DoF Visual Localization using Generative
  Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">照明、天気、季節など、外部環境が変化した場合の新しい視覚的ローカリゼーションネットワークを提案します。場所の認識とローカリゼーションのためのさまざまな挑戦的なデータセットを使用して、視覚的ローカリゼーションネットワークを証明します。その結果は、私たちの方法が状態を上回っていることを示しています。さまざまな環境変化を伴うシナリオでの最先端の方法..特徴抽出ネットワークは、Generative Adversarial Network CycleGANに基づくエンコーダーネットワークで構成されており、さまざまな天候のペアになっていないサンプルから本質的な外観不変の特徴マップをキャプチャできます。と季節。 
[概要]視覚と変化のネットワークは、6自由度のポーズモデルに基づいています。システムは、長期的な視覚的ローカリゼーションに取り組むために基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Slender Object Detection: Diagnoses and Improvements -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_47.html">
      <font color="black">Slender Object Detection: Diagnoses and Improvements</font>
    </a>
  </h2>
  <font color="black">さらに、現在の代表的なオブジェクト検出方法に対して明確で一貫した改善を実現する機能適応戦略を提案します。主な調査結果は次のとおりです。1）ラベル割り当てにおけるアンカーの重要な役割。 2）2点表現の記述能力。 3）細い物体と通常の物体の検出を改善するための重要な戦略。したがって、この作業では、細い物体の検出の問題を体系的に研究します。 
[概要]実際のシナリオでは、細いオブジェクトが実際には非常に一般的です。ただし、これは主にcocoなどのデータセットに基づいています。これらの要因には、cocoでの18.9％のマップの単純な低下が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-17">
        <br><font color="black">2020-11-17</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Contrast Computed Tomography Healthy Kidney Atlas -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_48.html">
      <font color="black">Multi-Contrast Computed Tomography Healthy Kidney Atlas</font>
    </a>
  </h2>
  <font color="black">ただし、マルチコントラストCT用の腹部および後腹膜臓器アトラスフレームワークはありません。3次元マルチモーダル組織マップの構築は、情報統合を通じて時間的および空間的スケール全体で学際的なイノベーションを促進する機会を提供します。アトラスのリンク人口統計は、集団間の腎臓の解剖学的構造の変化のより良い理解を提供しました。 
[概要]新しい高解像度のct後腹膜アトラスは、非造影CT全体の腎臓用に特別に最適化されています。これにより、集団全体の腎臓の解剖学的構造の変化をよりよく理解できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Seed Phenotyping on Neural Networks using Domain Randomization and
  Transfer Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_49.html">
      <font color="black">Seed Phenotyping on Neural Networks using Domain Randomization and
  Transfer Learning</font>
    </a>
  </h2>
  <font color="black">このようなシナリオに取り組むために、ドメインのランダム化のアイデア、すなわち。ネットワークは、人気のあるImageNetおよびCOCOデータセットから事前にトレーニングされた重みでトレーニングされます。このような取り組みの主なボトルネックの1つは、大量のトレーニングデータの必要性です。 
[概要]画像は、最先端の状態-最先端の状態-最先端の状態-最先端の状態-最先端の状態-論争プロセスを分析するために使用されます。画像は、将来使用できるネットワークを作成するために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: SubICap: Towards Subword-informed Image Captioning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_50.html">
      <font color="black">SubICap: Towards Subword-informed Image Captioning</font>
    </a>
  </h2>
  <font color="black">サブワード言語モデリングを使用して、キャプションシステムはさまざまなメトリックスコアを改善し、トレーニング語彙のサイズはベースラインよりも約90％小さく、さまざまな最先端の単語レベルモデルです。さらに、計算の複雑さを回避するために、既存のICモデルまれな単語のアイデンティティが失われるように、頻繁な単語の適度なサイズの語彙で動作します。私たちの定量的および定性的な結果と分析は、提案されたアプローチの有効性を示しています。 
[要約]これにより、まれな単語の表現が困難になり、単語外が不可能になります。したがって、これらは困難であり、アイデンティティ単語からは不可能です。単語は、大幅に低いサブワード語彙を使用して悪用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Hateful Memes Using a Multimodal Deep Ensemble -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_51.html">
      <font color="black">Detecting Hateful Memes Using a Multimodal Deep Ensemble</font>
    </a>
  </h2>
  <font color="black">提案されたモデルは、ベースラインを大幅に上回り、3,100人以上の参加者のうちリーダーボードで5 $ ^ {th} $にランク付けされています。機械学習アルゴリズムを使用してヘイトスピーチを検出することで大きな進歩が見られましたが、重要な技術的課題は依然として残っています。パフォーマンスを人間の精度に近づけるために解決されます。最新の視覚言語トランスフォーマーアーキテクチャのいくつかを調査し、このタスクのパフォーマンスを向上させるための改善を提案します。 
[概要]最新の技術的課題のいくつかを調査します。このタスクのパフォーマンスを向上させるための改善を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: An Efficient Recurrent Adversarial Framework for Unsupervised Real-Time
  Video Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_52.html">
      <font color="black">An Efficient Recurrent Adversarial Framework for Unsupervised Real-Time
  Video Enhancement</font>
    </a>
  </h2>
  <font color="black">特に、当社のビデオエンハンサーは、毎秒35フレームを超えるFullHDビデオ（1080x1920）を拡張できます。提案された設計により、繰り返しセルがフレーム間で時空間情報を効率的に伝播し、複雑度の高いネットワークの必要性を減らすことができます。効率的なトレーニングソースドメインとターゲットドメインの共同分布を同時に学習する単一のディスクリミネーターを導入することで実現されます。 
[ABSTRACT]新しいシステムでは、ペアになっていないビデオから周期的な敵対的な方法で学習できます。ここでは、提案された回帰ユニットが採用されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Task-Adaptive Negative Class Envision for Few-Shot Open-Set Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_53.html">
      <font color="black">Task-Adaptive Negative Class Envision for Few-Shot Open-Set Recognition</font>
    </a>
  </h2>
  <font color="black">基本的に、外部メモリを使用して負のクラス表現を推定します。この論文では、少数の例を使用した新しいソースからのクエリに対して堅牢な認識システムを学習する、少数ショットの開集合認識（FSOR）の問題を研究します。未知のオープンソース..さらに、学習プロセスを強化する新しい共役エピソードトレーニング戦略を紹介します。 
[概要]限られた例から新しいクラスを迅速に学習することを目的としたショット学習はほとんどありません。open-セット認識はオープンワールドからの未知のネガティブクラスを考慮します。さらに、新しいタスクを提案します-適応ネガティブクラス構想法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Parallel-beam X-ray CT datasets of apples with internal defects and
  label balancing for machine learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CV/paper_54.html">
      <font color="black">Parallel-beam X-ray CT datasets of apples with internal defects and
  label balancing for machine learning</font>
    </a>
  </h2>
  <font color="black">これにより、データセットをテスト、トレーニング、または検証のサブセットに分割して、ラベルバイアスを排除できます。バイアスを最適化問題として定式化することでこれに取り組みます。3つのバージョンはノイズのないシミュレーションです。ガウスノイズを追加し、散乱ノイズを使用したシミュレーション。 
[概要]データセットは、データ駆動型、学習ベースの画像再構成、セグメンテーション、および後処理方法の開発とテスト用に準備されています。データセットは、実際の3d x-rayctデータとその後のボリューム再構成に基づいています。機械学習におけるラベルバイアスの影響の分析とテスト（および削除するための新しい方法の適用）に使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Deep Learning for Text Style Transfer: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_0.html">
      <font color="black">Deep Learning for Text Style Transfer: A Survey</font>
    </a>
  </h2>
  <font color="black">厳選された論文リストはhttps://github.com/zhijing-jin/Text_Style_Transfer_Surveyにあります。 2017年の最初のニューラルテキストスタイルの転送作業以来、70近くの代表的な記事を収集、要約、および議論しました。全体として、タスクの定式化、既存のデータセットとサブタスク、評価指標、および並列データと非並列データの方法について説明しました。 。 
[概要] 2017年のテキストスタイル転送作業の最初の到着以来、約70の代表的な記事を収集、詳細化、および議論しました。また、tstに関する特定の属性についての議論も提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-01">
        <br><font color="black">2020-11-01</font>
      </time>
    </span>
</section>
<!-- paper0: Recognizing Emotion Cause in Conversations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_1.html">
      <font color="black">Recognizing Emotion Cause in Conversations</font>
    </a>
  </h2>
  <font color="black">テキスト内の感情の背後にある原因を認識することは、NLPの基本的でありながら未踏の研究分野です。さらに、原因の原因に基づいてさまざまな原因タイプを定義し、2つの異なるサブタスクに対処するための強力なトランスベースベースラインを確立します。 RECCON：1）因果スパン抽出および2）因果感情含意..この目的のために、RECCONという名前の付随するデータセットとの会話で感情原因を認識するタスクを紹介します。 
[概要]データセットはrecconと呼ばれ、感情の原因を認識するテキストの一種です。www.com/ / / github ofresearchで入手できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: To what extent do human explanations of model behavior align with actual
  model behavior? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_2.html">
      <font color="black">To what extent do human explanations of model behavior align with actual
  model behavior?</font>
    </a>
  </h2>
  <font color="black">より具体的には、統合された勾配によって測定された、自然言語の人間の説明が入力単語に対するモデルの感度とどの程度整合しているかを定量化する2つの整合メトリックを定義しました。さらに、調査したモデルのベースバージョンは、人間が生成したものとの整合性が高い傾向がありました。モデルパラメータの数を増やすと、人間の説明との整合性が低下する可能性があることを示唆する、より大きな対応物よりも説明。ケーススタディとして自然言語推論（NLI）を使用して、モデルの推論決定の人間が生成した説明の程度を調査しました。モデルが実際にこれらの決定を行う方法と一致します。 
[要約]人間が生成したモデルの結論決定の説明が、モデルが実際にこれらの決定を行う方法とどの程度一致するかを調べました。モデルの人間の説明との一致は、nliでのモデルの精度によって予測されないことがわかりました。精度と位置合わせが有益であることを示唆している</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: I like fish, especially dolphins: Addressing Contradictions in Dialogue
  Modelling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_3.html">
      <font color="black">I like fish, especially dolphins: Addressing Contradictions in Dialogue
  Modelling</font>
    </a>
  </h2>
  <font color="black">結果は次のことを明らかにしています。（i）新しく収集されたデータセットは、対話ドメインをカバーすることを目的としたデータを含む既存のNLIデータよりも、対話矛盾検出タスクの監視を提供するのに特に効果的です。 （ii）構造化された発話ベースのアプローチは、構造化されていない対応するものよりも、分析と配布外の対話の両方でより堅牢で転送可能です。また、最良の矛盾検出モデルが人間の判断とよく相関し、その証拠をさらに提供することも示します。最先端の生成チャットボットの一貫性を自動的に評価および改善するための使用法。次に、矛盾検出に事前トレーニング済みのTransformerモデルを使用する構造化発話ベースのアプローチを一般的な非構造化アプローチと比較します。 
[概要]矛盾の検出に事前にトレーニングされたトランスモデルを使用する新しいシステムを、一般的な非構造化アプローチと比較します。最良の一般的な応答検出モデルは、検出とよく相関します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Improved Biomedical Word Embeddings in the Transformer Era -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_4.html">
      <font color="black">Improved Biomedical Word Embeddings in the Transformer Era</font>
    </a>
  </h2>
  <font color="black">これらの動的埋め込みには、コンテキストに応じて同音異義語と頭字語を区別できるという追加の利点があります。これまでの取り組みで開発された単語の関連性について、複数のデータセットを使用して、これらの調整された静的埋め込みの評価を行います。ダウンストリームアプリケーションと研究の取り組み：https：//github.com/bionlproc/BERT-CRel-Embeddings 
[ABSTRACT]トランスフォーマーアーキテクチャを使用して動的埋め込みを作成します。これらの埋め込みには、同音異義語と頭字語を区別できるという追加の利点があります。環境</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Sentence-Based Model Agnostic NLP Interpretability -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_5.html">
      <font color="black">Sentence-Based Model Agnostic NLP Interpretability</font>
    </a>
  </h2>
  <font color="black">文を使用することにより、変更されたテキストは分散されたままになり、問題の次元が削減されて、同等の計算の複雑さでブラックボックスへの忠実度が向上します。この選択は簡単に思えるかもしれませんが、次のような複雑な分類子を使用すると、 BERT、単語ベースのアプローチは、計算の複雑さだけでなく、分布外のサンプリングの問題も引き起こし、最終的には根拠のない説明につながります。今日、サロゲートに基づくブラックボックス自然言語処理（NLP）モデルの解釈可能性、 LIMEやSHAPのように、単語ベースのサンプリングを使用して説明を作成します。 
[概要]この論文では、単語の革新に取り組むための文の使用について説明します。この記事では、複雑な単語の使用方法について説明します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Quantifying Exposure Bias for Neural Language Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_6.html">
      <font color="black">Quantifying Exposure Bias for Neural Language Generation</font>
    </a>
  </h2>
  <font color="black">これは、ニューラル言語生成（NLG）モデルトレーニングの中心的な問題と見なされてきました。実際の設定と合成設定の両方で、LSTM /トランスフォーマーモデルの実験を行います。露出バイアスの問題は、トレーニングと生成の不一致を指します。自動回帰ニューラルネットワーク言語モデル（LM）の最大尤度推定（MLE）トレーニングで、教師の強制によって。 
[概要]この問題は、神経言語生成の中心的な問題と見なされてきました。認知言語言語生成（nlg）モデルトレーニングを軽減するために提案されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-25">
        <br><font color="black">2019-05-25</font>
      </time>
    </span>
</section>
<!-- paper0: Enriching the Transformer with Linguistic Factors for Low-Resource
  Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_7.html">
      <font color="black">Enriching the Transformer with Linguistic Factors for Low-Resource
  Machine Translation</font>
    </a>
  </h2>
  <font color="black">特に、提案された変更であるFactored Transformerは、機械翻訳システムに追加の知識を挿入する言語的要因を使用します。さまざまな種類の機能を使用するほかに、さまざまなアーキテクチャ構成の影響を調査します。 、ソーストークンを参照する言語情報などの単語機能は、特定の設定、通常は反復アーキテクチャでのニューラル機械翻訳システムの結果を改善することが知られています。 
[概要]この調査では、現在の最先端技術である変圧器を強化して、外部の知識を導入できるようにすることを提案しています。最良の構成に加えて、ベースライン変圧器よりも0.8ブルーの改善を示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-17">
        <br><font color="black">2020-04-17</font>
      </time>
    </span>
</section>
<!-- paper0: ProofWriter: Generating Implications, Proofs, and Abductive Statements
  over Natural Language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_8.html">
      <font color="black">ProofWriter: Generating Implications, Proofs, and Abductive Statements
  over Natural Language</font>
    </a>
  </h2>
  <font color="black">トランスフォーマーは、自然言語理論（自然言語で表現された論理ルール）に対する論理演繹をエミュレートし、候補の含意に真/偽のラベルを確実に割り当てることが示されています。特に、1ステップの含意ジェネレーターを繰り返すと、信頼性の高い証明が得られます。 （事後の合理化ではなく）実際のモデルの決定を表します。ただし、理論の含意を生成する能力はまだ実証されておらず、回答の証明を再構築する方法は不完全です。 
[ABSTRACT]幻想的な理論理論理論は理論で見つけることができますが、まだ示されていません。理論理論は、理論理論を証明できる1ステップの仮定ジェネレータに基づいています。これは理論理論と証明できない結論のためです。欠落している事実</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised neural adaptation model based on optimal transport for
  spoken language identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_9.html">
      <font color="black">Unsupervised neural adaptation model based on optimal transport for
  spoken language identification</font>
    </a>
  </h2>
  <font color="black">私たちのモデルでは、データセットのトレーニングとテストのために機能と分類器の両方で分布の不一致を減らすように適応を明示的に定式化します。結果は、クロスドメインテストタスクで大幅な改善が達成されたことを示しました。オリエンタル言語認識（OLR）チャレンジデータコーパスでは、トレーニングとテストのデータセットがさまざまな条件から収集されました。 
[概要]このシステムは、教師なし神経適応モデルを開発するために使用できます。スライドの分布の不一致の問題に対処するために開発できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: REM-Net: Recursive Erasure Memory Network for Commonsense Evidence
  Refinement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_10.html">
      <font color="black">REM-Net: Recursive Erasure Memory Network for Commonsense Evidence
  Refinement</font>
    </a>
  </h2>
  <font color="black">これに対処するために、REM-Netには、質問応答を説明しない低品質のエビデンスを再帰的に消去することによってエビデンスを改良するモジュールが装備されています。2つの常識的な質問応答データセット、WIQAとCosmosQAで実験を行います。結果REM-Netのパフォーマンスを実証し、洗練された証拠が説明可能であることを示します。 
[ABSTRACT] rem-netは再帰的消去メモリネットワークです。これは、証拠の品質向上に対処するためのものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: WEmbSim: A Simple yet Effective Metric for Image Captioning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_11.html">
      <font color="black">WEmbSim: A Simple yet Effective Metric for Image Captioning</font>
    </a>
  </h2>
  <font color="black">これは、SPICE、CIDEr、WMDなどの複雑な測定値を人間の判断とのシステムレベルの相関関係で打ち負かす効果的なメトリックWEmbSimに関する提案された作業に影響を与えます。したがって、WEmbSimは、正当化される複雑なメトリックの新しいベースラインを設定すると考えています。 。自動画像キャプション評価の分野は、適切性と流暢さの要件を満たすことができるキャプションを生成するニーズに対処するために、まだ集中的な研究が行われています。 
[要約]コサイン類似度は、キャプションの単語埋め込み（mowe）の平均を使用して、監視されていないキャプション評価で驚くほど高いパフォーマンスを実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Gender Bias in Multilingual Neural Machine Translation: The Architecture
  Matters -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_12.html">
      <font color="black">Gender Bias in Multilingual Neural Machine Translation: The Architecture
  Matters</font>
    </a>
  </h2>
  <font color="black">どちらの動作も、性別の偏りを緩和するのに役立ちます。ソースの埋め込みと注意のさらなる解釈可能性分析は、言語固有のケースでは、埋め込みがより多くの性別情報をエンコードし、その注意がより迂回されることを示しています。多言語ニューラルマシン翻訳アーキテクチャは主に異なります言語間でモジュールとパラメータを共有する量。 
[要約]この論文では、選択したアーキテクチャが、同じデータでトレーニングされたときに、性別バイアスの精度に影響を与えるかどうかを調査します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: A Context Aware Approach for Generating Natural Language Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_13.html">
      <font color="black">A Context Aware Approach for Generating Natural Language Attacks</font>
    </a>
  </h2>
  <font color="black">マスクされた言語モデリングと次の文の予測を共同で活用して、コンテキストを理解します。以前の文献で提案された攻撃と比較して、成功率と単語の摂動率の両方の点で大幅に優れた高品質の敵対的な例を生成できます。ブラックボックス設定で自然言語処理モデルを攻撃するという重要なタスクを研究します。 
[概要]テキスト分類と含意タスクに関するより詳細な敵対的な例を作成することを目的とした攻撃戦略を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Enhanced back-translation for low resource neural machine translation
  using self-training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_14.html">
      <font color="black">Enhanced back-translation for low resource neural machine translation
  using self-training</font>
    </a>
  </h2>
  <font color="black">この手法は、ベースラインの低リソースIWSLT&#39;14英語-ドイツ語およびIWSLT&#39;15英語-ベトナム語後方翻訳モデルをそれぞれ11.06および1.5 BLEU改善することが示されました。改善された英語-ドイツ語後方モデルによって生成された合成データを使用して、 2.7 BLEUによる標準的な逆変換を使用してトレーニングされた別の順方向モデルを上回った順方向モデル。この作業は、逆方向モデルの出力を使用して、順方向変換手法を通じてモデル自体を改善するセルフトレーニング戦略を提案します。 
[概要]システムの品質は、多くの研究で最終的なqutモデルのパフォーマンスに影響を与えることが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-04">
        <br><font color="black">2020-06-04</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-lingual Dependency Parsing as Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_15.html">
      <font color="black">Cross-lingual Dependency Parsing as Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">このようにして、トレーニングコーパスだけでなく、追加の注釈なしデータでもユニバーサル機能を継続的に抽出し、さらに改善することができます。マルチタスクとしての依存関係解析に補助タスクとして2つの事前トレーニングタスクを追加し、パフォーマンスを向上させます。さらに、クロスドメイン学習におけるセルフトレーニングの有用性に触発されて、従来のセルフトレーニングと2つの事前トレーニングタスクを組み合わせます。 
[概要]この論文では、監督なしで普遍的な特徴を抽出する事前トレーニングタスクの機能を使用します。さらに、従来の自己トレーニングと2つの事前学習タスクを組み合わせます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Co-GAT: A Co-Interactive Graph Attention Network for Joint Dialog Act
  Recognition and Sentiment Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_16.html">
      <font color="black">Co-GAT: A Co-Interactive Graph Attention Network for Joint Dialog Act
  Recognition and Sentiment Classification</font>
    </a>
  </h2>
  <font color="black">コアモジュールは、発話間接続とタスク間接続が構築され、相互に繰り返し更新される、提案された協調型グラフ相互作用レイヤーであり、2つのタイプの情報を同時に考慮することを実現します。コンテキストおよび相互作用情報からの寄与は、コンテキスト化された単語表現（BERT、Roberta、XLNet）と完全には重複しません。2つの公開データセットでの実験結果は、モデルが2つの情報ソースを正常にキャプチャし、状態を達成することを示しています。最先端のパフォーマンス。 
[概要] 2つのタスクを実行するためにco-インタラクティブグラフ注意ネットワーク（co-gat）が提案されています。彼らは、2つの相互作用情報間のリンクとして識別する必要はないと述べています。この論文では、coを提案します。 -それらを実行するためのインタラクティブなグラフ認識ネットワーク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: A Multimodal Framework for the Detection of Hateful Memes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_17.html">
      <font color="black">A Multimodal Framework for the Detection of Hateful Memes</font>
    </a>
  </h2>
  <font color="black">単純な微調整を超えて既存のマルチモーダルアプローチのパフォーマンスを改善し、とりわけ、ロバスト性を改善するためのクロス検証に基づくマルチモダリティとアンサンブル学習を促進するための対照的な例のアップサンプリングの有効性を示します。ベースのモデルであり、AUROCスコア80.53を達成し、Facebookが主催する2020 Hateful Memes Challengeのフェーズ2で4位になりました。マルチモーダルヘイトスピーチの検出は本質的に困難で未解決の問題です。ミームは、画像とテキスト、したがって、マルチモーダル推論と視覚と言語の共同理解が必要です。 
[概要]私たちは、憎むべきミームを検出するためのマルチモーダルフレームワークの開発を目指しています。また、モデルの誤分類を分析し、仮説に基づく拡張とそのパフォーマンスへの影響について説明します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Code Switching Language Model Using Monolingual Training Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_18.html">
      <font color="black">Code Switching Language Model Using Monolingual Training Data</font>
    </a>
  </h2>
  <font color="black">結果から、トレーニングで単一言語データの代替バッチを使用すると、CS言語モデルの複雑さが軽減されたと結論付けられます。単一言語データのみを使用してコードスイッチング（CS）言語モデルをトレーニングすることは、現在も進行中の研究課題です。結果RNNベースの言語モデルの出力埋め込みで平均二乗誤差（MSE）を使用して、一貫して改善されました。 
[要約]提案された方法は、コードスイッチトレーニングデータを使用した言語モデルの微調整に匹敵しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: QUACKIE: A NLP Classification Task With Ground Truth Explanations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_19.html">
      <font color="black">QUACKIE: A NLP Classification Task With Ground Truth Explanations</font>
    </a>
  </h2>
  <font color="black">これにより、解釈可能性の評価が差し迫った問題になります。NLP解釈可能性を評価するためのデータセットは複数ありますが、人間が提供するグラウンドトゥルースに依存しているため、偏りがないという疑問が生じます。この作業では、別のアプローチを採用し、質問応答データセットの流用。 
[概要]この方法を使用してベンチマークを提案し、現在の最先端の方法を幅広く評価することにより、nlpの解釈可能性に関する将来の研究の基礎を築きます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: RNN-T Models Fail to Generalize to Out-of-Domain Audio: Causes and
  Solutions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_20.html">
      <font color="black">RNN-T Models Fail to Generalize to Out-of-Domain Audio: Causes and
  Solutions</font>
    </a>
  </h2>
  <font color="black">長い形式のYouTubeテストセットで、非ストリーミングRNN-Tモデルがより短いデータセグメントでトレーニングされると、提案された組み合わせにより、単語誤り率（WER）が22.3％から14.8％に向上します。ストリーミングRNN-Tモデルが短い検索クエリでトレーニングされると、提案された手法により、YouTubeセットのWERが67.0％から25.3％に向上します。近年、オールニューラルのエンドツーエンドアプローチが最先端のアプローチを獲得しています。 -いくつかの挑戦的な自動音声認識（ASR）タスクのアート結果..トレーニング中に複数の正則化手法を組み合わせることと、動的な重複推論を使用することの2つのソリューションを提案します。 
[概要]ほとんどの既存の作業は、列車とテストデータが同じドメインから取得されるasrモデルの構築に焦点を当てています。この作業では、ストリーミングおよび非ストリーミングリカレントニューラルネットワークトランスデューサの一般化プロパティを分析します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br><font color="black">2020-05-07</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-modal Identification of State-Sponsored Propaganda on Social Media -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_21.html">
      <font color="black">Multi-modal Identification of State-Sponsored Propaganda on Social Media</font>
    </a>
  </h2>
  <font color="black">視覚的およびテキスト的コンテンツのみに基づいてプロパガンダメッセージを検出するためのマルチモデルフレームワークが提案され、3つの組織による同じ期間（同じ期間のデータのトレーニングとテスト）によるプロパガンダの検出で有望なパフォーマンスを実現します（ F1 = 0.869）およびさまざまな期間（過去のトレーニング、将来のテスト）（F1 = 0.697）。データセットは、2つの期間にわたる3つの異なる組織による宣伝で構成されています。新しいデータセットと一般的なフレームワークは強力なものを提供します。国が後援するインターネット宣伝を特定するタスクのベンチマークであり、このタスクに関する将来の作業の潜在的な道筋を指摘します。 
[概要]プロパガンダの定義があいまいなため、データのラベル付けが信頼できないため、問題は解決されていません。データセットは、2つの期間にわたる3つの異なる組織によるプロパガンダで構成されています。誤検知の予測の影響を減らすために、しきい値を次のように変更します。偽陽性率と真陽性率の関係をテストする</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Disentangling semantics in language throughs VAEs and a certain
  architectural choice -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_22.html">
      <font color="black">Disentangling semantics in language throughs VAEs and a certain
  architectural choice</font>
    </a>
  </h2>
  <font color="black">文の依存構造、およびOpen Information Extractionモデルを通過したときに生成される述語構造に対する生成中の各潜在変数の影響を調査します。対応する潜在変数を変更すると、文のこれらの要素が変更されることを示します。そして、それらを2つの文の間で交換すると、予想される部分的な意味の交換につながります。変更されたトランスフォーマーを構成要素として使用して、文を固定数の階層構造の潜在変数に\ emph {変換}するように変分自動エンコーダーをトレーニングします。 
[ABSTRACT]オートエンコーダーは文を固定数の「潜在」にスワップできます。モデルは主語、直接目的語、前置詞オブジェクトを分離できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: SubICap: Towards Subword-informed Image Captioning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_23.html">
      <font color="black">SubICap: Towards Subword-informed Image Captioning</font>
    </a>
  </h2>
  <font color="black">さらに、計算の複雑さを回避するために、既存のICモデルは、頻繁な単語の適度なサイズの語彙で動作するため、まれな単語のIDが失われます。サブワード言語モデリングを使用して、キャプションシステムはさまざまなメトリックスコアを改善し、トレーニング語彙のサイズは約ベースラインおよびさまざまな最先端の単語レベルモデルよりも90％少なくなります。これにより、大幅に低いサブワード語彙を使用してコーパス内のすべての単語を表すことができ、パラメーターの学習が向上します。 
[要約]これにより、まれな単語の表現が困難になり、単語外が不可能になります。したがって、これらは困難であり、アイデンティティ単語からは不可能です。単語は、大幅に低いサブワード語彙を使用して悪用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Hateful Memes Using a Multimodal Deep Ensemble -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_24.html">
      <font color="black">Detecting Hateful Memes Using a Multimodal Deep Ensemble</font>
    </a>
  </h2>
  <font color="black">提案されたモデルは、ベースラインを大幅に上回り、3,100人以上の参加者のうちリーダーボードで5 $ ^ {th} $にランク付けされています。機械学習アルゴリズムを使用してヘイトスピーチを検出することで大きな進歩が見られましたが、重要な技術的課題は依然として残っています。パフォーマンスを人間の精度に近づけるために解決されます。最新の視覚言語トランスフォーマーアーキテクチャのいくつかを調査し、このタスクのパフォーマンスを向上させるための改善を提案します。 
[概要]最新の技術的課題のいくつかを調査します。このタスクのパフォーマンスを向上させるための改善を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Conditional Text Generation for Harmonious Human-Machine Interaction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_25.html">
      <font color="black">Conditional Text Generation for Harmonious Human-Machine Interaction</font>
    </a>
  </h2>
  <font color="black">有望な研究分野として、多くの努力が払われていることがわかります。したがって、CTGの新しい研究動向を包括的にレビューすることを目指しています。したがって、条件付きテキスト生成（CTG）は研究のホットスポットになっています。 
[概要]研究者は、ニューラルテキスト生成の新しい分野を模索しています。彼らは、テクノロジーの開発を探求するのに長い道のりだと言います。新しいテクノロジーは、人間とのコミュニケーションに使用できる可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-08">
        <br><font color="black">2019-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: g2tmn at Constraint@AAAI2021: Exploiting CT-BERT and Ensembling Learning
  for COVID-19 Fake News Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/cs.CL/paper_26.html">
      <font color="black">g2tmn at Constraint@AAAI2021: Exploiting CT-BERT and Ensembling Learning
  for COVID-19 Fake News Detection</font>
    </a>
  </h2>
  <font color="black">使用したモデル、テキストの前処理方法、データの追加方法について説明します。したがって、コロナウイルスのパンデミックとその結果はソーシャルメディアで活発に議論されています。ただし、すべてのソーシャルメディアの投稿が真実であるとは限りません。 
[概要]コロナウイルスのパンデミックとその結果はソーシャルメディアで議論されています。それらの多くはパニックを引き起こし、人々に誤解を与える偽のニュースを広めています。特に、トランスベースのcovid-twitter-bert（ct --bert）モデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Wheel-Rail Interface Condition Estimation (W-RICE) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.AS/paper_0.html">
      <font color="black">Wheel-Rail Interface Condition Estimation (W-RICE)</font>
    </a>
  </h2>
  <font color="black">したがって、車輪とレールの相互作用に起因する騒音パターンの分析から、車輪とレールの間の接着状態を推定することが可能です。本研究では、転がり騒音を入力として使用する接着状態を推定する新しいアプローチを提案します。車輪とレールの間の表面の粗さは、ローリングノイズレベルに大きな影響を及ぼします。 
[概要]車輪とレールの境界面に第3の物体が存在することで、接着力が変化します。ローリングノイズを入力として使用する新しいアプローチが提案されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised neural adaptation model based on optimal transport for
  spoken language identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.AS/paper_1.html">
      <font color="black">Unsupervised neural adaptation model based on optimal transport for
  spoken language identification</font>
    </a>
  </h2>
  <font color="black">トレーニングデータセットとテストデータセットの両方での適応損失でトレーニングデータセットの分類損失を最小化することにより、トレーニングドメインとテストドメイン間の統計的分布の差が減少します。東洋言語認識（OLR）チャレンジデータでSLID実験を実行しました。トレーニングとテストのデータセットがさまざまな条件から収集されたコーパス。私たちの結果は、クロスドメインテストタスクで大幅な改善が達成されたことを示しました。 
[概要]このシステムは、教師なし神経適応モデルを開発するために使用できます。スライドの分布の不一致の問題に対処するために開発できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-24">
        <br><font color="black">2020-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: Code Switching Language Model Using Monolingual Training Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.AS/paper_2.html">
      <font color="black">Code Switching Language Model Using Monolingual Training Data</font>
    </a>
  </h2>
  <font color="black">両方の方法を組み合わせることにより、混乱が299.63から80.38に減少します。RNNベースの言語モデルの出力埋め込みで平均二乗誤差（MSE）を使用すると、結果が一貫して改善されました。単言語のみを使用したコードスイッチング（CS）言語モデルのトレーニングデータはまだ進行中の研究問題です。 
[要約]提案された方法は、コードスイッチトレーニングデータを使用した言語モデルの微調整に匹敵しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: RNN-T Models Fail to Generalize to Out-of-Domain Audio: Causes and
  Solutions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-25/eess.AS/paper_3.html">
      <font color="black">RNN-T Models Fail to Generalize to Out-of-Domain Audio: Causes and
  Solutions</font>
    </a>
  </h2>
  <font color="black">近年、オールニューラルのエンドツーエンドのアプローチにより、いくつかの挑戦的な自動音声認識（ASR）タスクで最先端の結果が得られています。長い形式のYouTubeテストセットで、非ストリーミングRNN-Tモデルはデータのより短いセグメントでトレーニングされ、提案された組み合わせは単語誤り率（WER）を22.3％から14.8％に改善します。ストリーミングRNN-Tモデルが短い検索クエリでトレーニングされた場合、提案された手法はYouTubeセットのWERを67.0％から25.3％に改善します。トレーニング中に複数の正則化手法を組み合わせる方法と動的な重複推論を使用する方法の2つのソリューションを提案します。 
[概要]ほとんどの既存の作業は、列車とテストデータが同じドメインから取得されるasrモデルの構築に焦点を当てています。この作業では、ストリーミングおよび非ストリーミングリカレントニューラルネットワークトランスデューサの一般化プロパティを分析します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br><font color="black">2020-05-07</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
