<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-12-04の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Phonetic Posteriorgrams based Many-to-Many Singing Voice Conversion via
  Adversarial Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.SD/paper_0.html">
      <font color="black">Phonetic Posteriorgrams based Many-to-Many Singing Voice Conversion via
  Adversarial Training</font>
    </a>
  </h2>
  <font color="black">提案されたシステムは、ジェネレータ$ G $、音声生成弁別器$ D_ {A} $、および特徴解きほぐし弁別器$ D_F $の3つのモジュールで構成されます。さらに、より堅牢で正確な歌唱変換を実現するために、解きほぐし弁別器$ D_F $エンコードされたPPGに残っているピッチと音色に関連する情報を削除することが提案されています。音色変換をより安定して制御可能にするために、スピーカーの埋め込みは、異なる音色クラスターを表すトレーニング可能なベクトルのグループの加重和にさらに分解されます。 
[概要]ジェネレーター$ g $は、特徴を並列にエンコードし、それらをターゲット波形に逆変換します。より堅牢で正確な歌唱変換を行うために、エンコードされたppgに残っているピッチと音色に関連する情報を削除するために解きほぐし合計が提案されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Individually amplified text-to-speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.SD/paper_1.html">
      <font color="black">Individually amplified text-to-speech</font>
    </a>
  </h2>
  <font color="black">平均オピニオン評点はSTOIメトリックによって適切に予測されました。テキスト読み上げ（TTS）は、受信側で難聴を補正するのではなく、ソースでの難聴を補正する機会を提供します。音声品質の主観的評価により、提案されたアルゴリズムは、高品質のオーディオにつながりました。 
[要約]音声分析は、提案されたアルゴリズムが高品質のaudio.projectにつながったことを示しています。聴覚障害のあるリスナーの音声品質を改善するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Supervised attention for speaker recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.SD/paper_2.html">
      <font color="black">Supervised attention for speaker recognition</font>
    </a>
  </h2>
  <font color="black">ただし、一部の設定では、SAPは時間平均プーリング（TAP）ベースラインと比較してパフォーマンスが低く、エンドツーエンドのトレーニングでは注意が効果的に学習されないことを意味します。最近提案された自己注意プーリング（SAP）は良好であることが示されています。いくつかの話者認識システムでのパフォーマンス..提案された方法を使用すると、コンテキストベクトルをブーストして、最も有益なフレームを選択できます。 
[概要] SAPシステムでは、コンテキストセンサーは特徴抽出器と一緒に終了するようにトレーニングされます。コンテキストプールの役割は、話者認識のために最もベースラインのフレームを選択することです。この方法は、短い発話話者を含むさまざまな実験設定で既存の方法よりも優れています。認識</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: MelGlow: Efficient Waveform Generative Network Based on
  Location-Variable Convolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.SD/paper_3.html">
      <font color="black">MelGlow: Efficient Waveform Generative Network Based on
  Location-Variable Convolution</font>
    </a>
  </h2>
  <font color="black">LJSpeechデータセットでの実験は、MelGlowが小さなモデルサイズでWaveGlowよりも優れたパフォーマンスを達成することを示しています。これにより、位置変数畳み込みの有効性と潜在的な最適化空間が検証されます。 、位置変数畳み込みは、カーネル予測子を利用して、メルスペクトルに基づいて畳み込みカーネルの複数のセットを生成します。ここで、畳み込みカーネルの各セットは、関連する波形間隔で畳み込み操作を実行するために使用されます。WaveGlowと位置変数畳み込みの組み合わせ、 MelGlowという名前の効率的なボコーダーが設計されています。 
[要約] location-variable convolutionという名前のネットワークは、波形の畳み込みをモデル化するために提案されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Cross attentive pooling for speaker verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.SD/paper_4.html">
      <font color="black">Cross attentive pooling for speaker verification</font>
    </a>
  </h2>
  <font color="black">この論文では、参照クエリペア全体のコンテキスト情報を利用して、ペアワイズマッチング問題の最も識別力のある情報を含む発話レベルの埋め込みを生成するクロスアテンティブプーリング（CAP）を提案します。実験はVoxCelebで実行されます。私たちの方法が同等のプーリング戦略よりも優れているデータセット。話者の検証は当然ペアワイズの問題ですが、話者の埋め込みを生成する既存の方法はインスタンスごとです。 
[ABSTRACT]スピーカーの埋め込みを生成するための既存の方法は疑問です。テストはvoxcelebデータセットからのデータに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-13">
        <br><font color="black">2020-08-13</font>
      </time>
    </span>
</section>
<!-- paper0: End to End ASR System with Automatic Punctuation Insertion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.SD/paper_5.html">
      <font color="black">End to End ASR System with Automatic Punctuation Insertion</font>
    </a>
  </h2>
  <font color="black">この研究では、ted.comから入手可能なトランスクリプトを使用してTEDLIUMデータセットの句読点を生成する方法を提案します。歴史的に、テキストまたは音声からテキストへのコンテキストでの自動句読点に多くの関心が寄せられてきました。音声信号から単語と句読点を同時に出力するエンドツーエンドのASRシステム。 
[概要]新しいニューラルネットワークベースのエンドツーエンドの音声認識システムに自動句読点を許可することにほとんど関心がないようです。また、音声信号から単語と句読点を同時に出力するエンドツーエンドのasrシステムを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Light-field view synthesis using convolutional block attention module -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.IV/paper_0.html">
      <font color="black">Light-field view synthesis using convolutional block attention module</font>
    </a>
  </h2>
  <font color="black">残余畳み込みブロック注意モジュール（CBAM）は、最終的な適応画像の改良に使用されます。注意モジュールは、画像の重要な特徴を学習して焦点を合わせるのに役立ち、チャネルと空間の次元に順次適用されます。3つを使用します。各ステージの順次畳み込みニューラルネットワーク。 
[概要]提案されたネットワークは、注意メカニズムを使用して、入力ステージの密な分割を使用したライトフィールド画像の新しいビューを合成します。各ステージに3つの時系列畳み込みニューラルネットワークを使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: FracBits: Mixed Precision Quantization via Fractional Bit-Widths -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.IV/paper_1.html">
      <font color="black">FracBits: Mixed Precision Quantization via Fractional Bit-Widths</font>
    </a>
  </h2>
  <font color="black">最適化中、モデル内の各レイヤー/カーネルのビット幅は、2つの連続するビット幅の小数状態にあり、徐々に調整できます。微分可能な正則化項を使用すると、量子化中にリソースの制約を満たすことができます。最適化された混合精度モデルをもたらす認識トレーニング。さらに、私たちの方法は、より良い計算コスト割り当てのためにチャネルプルーニングと自然に組み合わせることができます。 
[概要]モデルは2つの連続したビットの端数ステータスにあります-幅は徐々に調整できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-04">
        <br><font color="black">2020-07-04</font>
      </time>
    </span>
</section>
<!-- paper0: Localization of Malaria Parasites and White Blood Cells in Thick Blood
  Smears -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.IV/paper_2.html">
      <font color="black">Localization of Malaria Parasites and White Blood Cells in Thick Blood
  Smears</font>
    </a>
  </h2>
  <font color="black">厚い血液塗抹標本の画像のスライスのデータセットで、取得したデジタル画像を分析するためのモデルを構築します。厚い血液塗抹標本に適用される顕微鏡検査は、マラリア寄生虫血症を決定するための事実上の方法です。マラリア寄生虫血症を効果的に決定することは、臨床医が病気の重症度を正確に判断し、質の高い治療を提供するのを支援します。 
[要約]研究では、マラリア原虫と白血球の位置特定とカウントのためのエンドツーエンドのアプローチが提示されました。データセットのサイズが限られているため、モデルのパフォーマンスを向上させるためにデータスミアが適用されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Space-Time Correspondence as a Contrastive Random Walk -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.IV/paper_3.html">
      <font color="black">Space-Time Correspondence as a Contrastive Random Walk</font>
    </a>
  </h2>
  <font color="black">したがって、単一のパスレベルの制約が暗黙的に中間比較のチェーンを監視します。さらに、エッジドロップアウトと呼ばれる手法、およびテスト時の自己監視適応が、オブジェクト中心の対応の転送をさらに改善することを示します。適応なしで類似性メトリックとして使用される場合、学習された表現は、オブジェクト、セマンティックパーツ、およびポーズを含むラベル伝播タスクで、自己監視された最先端のパフォーマンスを上回ります。 
[要約]適応なしで類似性メトリックとして使用される場合、学習された表現は自己教師ありノードよりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-25">
        <br><font color="black">2020-06-25</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Alternating Optimization for Blind Hyperspectral Imagery
  Super-resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.IV/paper_4.html">
      <font color="black">Unsupervised Alternating Optimization for Blind Hyperspectral Imagery
  Super-resolution</font>
    </a>
  </h2>
  <font color="black">具体的には、空間領域とスペクトル領域でそれぞれ変性モデルを効果的に取得する方法を調査し、融合ベースのSR再構成モデルとの互換性を高めます。この目的のために、まず、交互最適化ベースの深いフレームワークを提案して、縮退モデルと潜在画像の再構築。これにより、縮退モデルの推定とHSIの再構築が相互に促進されます。このような問題を十分に軽減するために、監視なしのブラインドHSISR法を検討します。 
[概要]たとえば、教師なしブラインドhsi sr法を検討します。この目的のために、これらのモデルは縮退モデルを推定し、潜在関数を再構築します。新しい方法は、3つのベンチマークhsisrデータセットに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Flow-based Deformation Guidance for Unpaired Multi-Contrast MRI
  Image-to-Image Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.IV/paper_5.html">
      <font color="black">Flow-based Deformation Guidance for Unpaired Multi-Contrast MRI
  Image-to-Image Translation</font>
    </a>
  </h2>
  <font color="black">フローベースのアーキテクチャの可逆特性により、追加の損失関数なしで画像から画像への変換のサイクル整合性が保証されます。実験結果は、提案されたアプローチを使用して合成された画像が、 3つの標準データセットでの既存の深層学習ベースの方法と比較した場合の平均二乗誤差、ピーク信号対雑音比、および構造類似性指数。 HCP、MRBrainS13、およびBrats2019。 
[概要]この論文では、対になっていない画像への新しいアプローチを紹介します-これに加えて、これを使用して、対になっていない画像で1つのドメインを別のドメインに変換するための拡張にさらに制約を与えます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: A combined full-reference image quality assessment approach based on
  convolutional activation maps -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.IV/paper_6.html">
      <font color="black">A combined full-reference image quality assessment approach based on
  convolutional activation maps</font>
    </a>
  </h2>
  <font color="black">具体的には、提案された方法は、高い予測性能に到達するために少量のデータでトレーニングできることが実証されています。提案された方法の設計選択が推論される詳細なパラメータ研究も提示されます。完全参照の目標画質評価（FR-IQA）は、人間の観察者が知覚する画像の品質を、その元の参照対応物を使用して予測することです。 
[概要]私たちの最良の提案であるactmapfeatは、6つの公開されているベンチマークiqaデータベースの最新技術と比較されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-19">
        <br><font color="black">2020-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: Adaptive Partial Scanning Transmission Electron Microscopy with
  Reinforcement Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.IV/paper_7.html">
      <font color="black">Adaptive Partial Scanning Transmission Electron Microscopy with
  Reinforcement Learning</font>
    </a>
  </h2>
  <font color="black">ソースコード、事前トレーニング済みモデル、トレーニングデータは、https：//github.com/Jeffrey-Ede/adaptive-scansから公開されています。圧縮センシングは、最小限の情報損失で走査透過電子顕微鏡の電子線量とスキャン時間を減らすことができます。スキャンセグメントのサンプリング方向は、以前に観察されたスキャンセグメントに基づいて反復ニューラルネットワークによって選択されます。 
[概要]データは失われた情報を測定するために使用できますが、テストには役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: SMDS-Net: Model Guided Spectral-Spatial Network for Hyperspectral Image
  Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.IV/paper_8.html">
      <font color="black">SMDS-Net: Model Guided Spectral-Spatial Network for Hyperspectral Image
  Denoising</font>
    </a>
  </h2>
  <font color="black">その後、モデルはSMDS-Netという名前のエンドツーエンドネットワークに展開されます。その基本モジュールは、モデルのノイズ除去手順と最適化にシームレスに接続されています。広範な実験と包括的な分析により、ノイズ除去能力とメソッドの解釈可能性が確認されます。最先端のHSIノイズ除去法に対して..このモデルは、最初に観測されたHSIを低次元の直交部分空間に投影し、次に投影された画像を多次元辞書で表現します。 
[概要] hsisのハイパーレスティング画像は、ハイパースペクティングネットワークsmds-netによって作成されます。これらのモジュールは、ノイズ除去手順およびモデルの拡張とシームレスに接続されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Data-Efficient Learning: A Benchmark for COVID-19 CT Lung and
  Infection Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.IV/paper_9.html">
      <font color="black">Towards Data-Efficient Learning: A Benchmark for COVID-19 CT Lung and
  Infection Segmentation</font>
    </a>
  </h2>
  <font color="black">これらのリソースはすべて公開されており、私たちの仕事は、限られたデータで効率的なCOVID-19 CTセグメンテーションのための深層学習手法の開発を促進するための基礎を築きます。さらに、現在のCOVID-19CTセグメンテーション手法をそのまま比較することは困難です。さまざまなデータセットで開発され、さまざまな設定でトレーニングされ、さまざまな指標で評価されます。目的：COVID-19 CTスキャンでの肺と感染の正確なセグメンテーションは、患者の定量的管理において重要な役割を果たします。 
[要約]既存の研究のほとんどは、単一の機関から取得するのが難しい大規模でプライベートな注釈付きデータセットに基づいています。この論文では、70の注釈付きcovid-19のケースに基づいて肺と感染のセグメンテーションの3つのベンチマークを構築しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br><font color="black">2020-04-27</font>
      </time>
    </span>
</section>
<!-- paper0: A Single Sensor Based Multispectral Imaging Camera using a Narrow
  Spectral Band Colour Mosaic Integrated on the Monochrome CMOS Image Sensor -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.IV/paper_10.html">
      <font color="black">A Single Sensor Based Multispectral Imaging Camera using a Narrow
  Spectral Band Colour Mosaic Integrated on the Monochrome CMOS Image Sensor</font>
    </a>
  </h2>
  <font color="black">ここでは、モノクロCMOSセンサーに統合されたベイヤーパターンの狭スペクトル帯域RGBカラーモザイクを使用した単一センサーベースの3バンドマルチスペクトルカメラを示します。マルチスペクトルイメージカメラは、電磁全体の狭波長帯域の特定の波長範囲内の画像データをキャプチャします。スペクトル..狭帯域カラーモザイクは、プラズモニックカラーフィルターとヘテロ構造誘電体多層のハイブリッドの組み合わせで作られています。 
[概要]マルチスペクトルカメラは、ヒューマネクトラルカメラがキャプチャできないより多くの情報をキャプチャできます。マルチスペクトルカメラは、複数の光学系をキャプチャします。これにより、画像の同時登録の問題も発生します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Hi-UCD: A Large-scale Dataset for Urban Semantic Change Detection in
  Remote Sensing Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.IV/paper_11.html">
      <font color="black">Hi-UCD: A Large-scale Dataset for Urban Semantic Change Detection in
  Remote Sensing Imagery</font>
    </a>
  </h2>
  <font color="black">洗練された都市の変化を検出および分析するために使用できます。バイナリおよびマルチクラスの変化検出でいくつかの古典的な方法を使用してデータセットをベンチマークします。実験結果は、Hi-UCDが挑戦的でありながら有用であることを示しています。 
[概要]このデータセットは、空間解像度が0.1 mの航空写真を使用しています。3つの時相が含まれ、9つのクラスの土地被覆で意味的に注釈が付けられています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-06">
        <br><font color="black">2020-11-06</font>
      </time>
    </span>
</section>
<!-- paper0: COVID-19 CT Image Synthesis with a Conditional Generative Adversarial
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.IV/paper_12.html">
      <font color="black">COVID-19 CT Image Synthesis with a Conditional Generative Adversarial
  Network</font>
    </a>
  </h2>
  <font color="black">リアルタイム逆転写ポリメラーゼ連鎖反応（rRT-PCR）と胸部コンピューター断層撮影（CT）イメージングは、どちらもCOVID-19診断において重要な役割を果たします。最近、深層学習ベースのコンピュータービジョン法は、 X線、磁気共鳴画像、CT画像などの医療画像アプリケーション。コロナウイルス病2019（COVID-19）は、2019年12月以降急速に拡大している進行中の世界的な大流行です。
[要約] ctスキャンはcovidの重要な役割です-19診断。これは、他の最先端の画像を上回る最新の方法です。提案された方法は、さまざまな機械学習アプリケーションに有望であることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Object-Centric Image Generation from Layouts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.IV/paper_13.html">
      <font color="black">Object-Centric Image Generation from Layouts</font>
    </a>
  </h2>
  <font color="black">また、オブジェクトのインスタンス認識を強化するジェネレーターの条件付けメカニズムの変更を提案します。単一オブジェクトおよび単一ドメインの画像生成に関する最近の印象的な結果にもかかわらず、複数のオブジェクトを含む複雑なシーンの生成は依然として困難です。 Object-Centric Generative Adversarial Network（またはOC-GAN）と呼ばれるto-image-generationメソッドは、新しいシーングラフ類似性モジュール（SGSM）に依存しています。 
[概要] sgsmは、シーン内のオブジェクト間の空間的関係の表現を学習します。これらは、モデルのレイアウトの改善につながります-忠実度。これにより、以前のアプローチで複数の障害モードが追加されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-16">
        <br><font color="black">2020-03-16</font>
      </time>
    </span>
</section>
<!-- paper0: Conditional Adversarial Camera Model Anonymization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.IV/paper_14.html">
      <font color="black">Conditional Adversarial Camera Model Anonymization</font>
    </a>
  </h2>
  <font color="black">特定の写真画像をキャプチャするために使用されたカメラのモデル（モデルの帰属）は、通常、画像内に存在する高周波モデル固有のアーティファクトから推測されます。定量的な比較は、制限的な非対話型の黒でのフレームワークの有効性を示しています。ボックス設定..そのような変換を学習するための条件付き敵対的アプローチを提案します。 
[抽象]モデルの匿名化は、見かけのキャプチャモデルが変更されるなど、これらのアーティファクトを変換するプロセスです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br><font color="black">2020-02-18</font>
      </time>
    </span>
</section>
<!-- paper0: How to Exploit the Transferability of Learned Image Compression to
  Conventional Codecs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.IV/paper_15.html">
      <font color="black">How to Exploit the Transferability of Learned Image Compression to
  Conventional Codecs</font>
    </a>
  </h2>
  <font color="black">画像は、学習したフィルターによって変更され、さまざまなパフォーマンス測定値または特定のタスクに最適化されます。この目標の可能な方法として、この作業では、学習した画像コーディングを代理として使用して、画像を最適化する方法を提案および調査します。エンコード用の画像..理想的には、既存の従来のコーデックをそのままにしておく必要があります。これにより、より迅速な採用とバランスの取れた計算エンベロープへの準拠が保証されます。 
[概要]画像を最適化するための代理として画像を使用するのはこれが初めてです。この作業では、学習画像コーディングを使用して選択した画像を最適化する方法を提案および調査します。これは、の代替として使用できます。画像の代理</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Image inpainting using frequency domain priors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.IV/paper_16.html">
      <font color="black">Image inpainting using frequency domain priors</font>
    </a>
  </h2>
  <font color="black">この目的のために、ネットワークが高周波成分を選択的に再構築しながらグローバルコンテキストを学習できるようにする周波数ベースのデコンボリューションモジュールを提案します。しかし、これらの方法は依然として実際の複雑なシーンの高周波の詳細を再構築するのに苦労し、色、境界アーティファクト、歪んだパターン、ぼやけたテクスチャの不一致。公開されているデータセットCelebA、Paris Streetview、およびDTDテクスチャデータセットで提案された方法を評価し、現在の最先端の方法よりも優れていることを示します。質的および量的に画像修復技術。 
[ABSTRACT]以前の作業では、空間ドメイン情報のみを使用してニューラルネットワークをトレーニングすることにより、欠落しているピクセルを予測します。公開されているデータセットceleba、paris streetview、textureデータセットで提案された方法を評価します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: SSN: Soft Shadow Network for Image Compositing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.IV/paper_17.html">
      <font color="black">SSN: Soft Shadow Network for Image Compositing</font>
    </a>
  </h2>
  <font color="black">SSNは2Dオブジェクトマスクを入力として受け取るため、絵画やベクターアートなどの画像タイプに依存しません。SSNは、周囲閉塞予測モジュールを使用して中間周囲閉塞マップを予測します。これは、ユーザーがさらに洗練して幾何学的な手がかりを提供できます。シャドウ生成を調整します。インタラクティブなソフトシャドウネットワーク（SSN）を導入して、画像合成用の制御可能なソフトシャドウを生成します。 
[ABSTRACT] ssnは、アンビエントオクルージョン予測モジュールを組み合わせて、中間のアンビエントオクルージョンマップを予測します。これは、ユーザーがさらに洗練して、影の生成を調整するための幾何学的な手がかりを提供できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Understanding Failures of Deep Networks via Robust Feature Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_0.html">
      <font color="black">Understanding Failures of Deep Networks via Robust Feature Extraction</font>
    </a>
  </h2>
  <font color="black">ImageNetデータセットのメソッドの評価は、（i）提案されたワークフローが重要な障害モードの発見に効果的であり、（ii）視覚化技術が抽出された特徴を理解するのに役立ち、（iii）抽出された洞察がエンジニアを支援できることを示しています。エラー分析とデバッグを使用します。テストセット全体の集計スコアを報告する学習モデルの従来の評価指標は、機能やインスタンスの障害の重要で有益なパターンを明らかにするには不十分です。障害の特性評価と説明を目的とした方法を紹介し、調査します。存在または不在によってパフォーマンスが低下する視覚属性を特定します。 
[ABSTRACT]視覚的特徴の欠如をテストするために、視覚化手法を提案します。この手法は、特徴の定義をデバンキングするように設計されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: IMAGO: A family photo album dataset for a socio-historical analysis of
  the twentieth century -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_1.html">
      <font color="black">IMAGO: A family photo album dataset for a socio-historical analysis of
  the twentieth century</font>
    </a>
  </h2>
  <font color="black">私たちの知る限り、これは文学のこの道に沿って進む最初の作品です。ディープラーニングベースのアプローチに従って、IMAGOデータセットは1845年から2009年の間に撮影された写真を実験する機会を提供しました。他の情報源を使用せずに、画像の日付と社会史的背景を評価するという目標。当初の予想を超えて、このような分析は、この作業で採用されたアプローチのパフォーマンスの観点からだけでなく、そのメリットを明らかにしました。 、しかしまた、社会歴史的研究の利益のための予見可能な含意と使用の観点から。 
[概要] 2004年からボローニャ大学のリミニキャンパスで撮影された画像。これには、家族のアルバムに属する写真と家族のアルバムの写真が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-Supervised Learning for Multi-Task Scene Understanding by Neural
  Graph Consensus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_2.html">
      <font color="black">Semi-Supervised Learning for Multi-Task Scene Understanding by Neural
  Graph Consensus</font>
    </a>
  </h2>
  <font color="black">これらのパスは、特定のエッジのアンサンブルティーチャーとして機能し、信頼性の高い監視信号に強力なコンセンサスが使用されます。教師なし学習プロセスは数世代にわたって繰り返され、各エッジが「学生」になり、異なるアンサンブル「ティーチャー」の一部にもなります。 「他の学生を訓練するために..また、マルチタスクおよび半教師なし学習のための最先端の方法と比較し、優れたパフォーマンスを示します。 
[概要]システムは数世代にわたって繰り返され、各エッジが「学生」になります。たとえば、提案されたアイデアの理論的正当化を示し、大規模なデータセットで検証します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-02">
        <br><font color="black">2020-10-02</font>
      </time>
    </span>
</section>
<!-- paper0: Pre-Trained Image Processing Transformer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_3.html">
      <font color="black">Pre-Trained Image Processing Transformer</font>
    </a>
  </h2>
  <font color="black">したがって、事前にトレーニングされたモデルは、微調整後の目的のタスクで効率的に使用できます。さらに、さまざまな画像処理タスクにうまく適応するために対照学習が導入されています。IPTモデルは、マルチヘッドとマルチを使用してこれらの画像でトレーニングされます。 -尾。 
[ABSTRACT] iptは、さまざまな低レベルのベンチマークで現在の最先端の手法を上回っています。事前にトレーニングされたモデルが1つしかないため、iptは多くの低レベルのベンチマークを上回ります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Aerial Imagery Pixel-level Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_4.html">
      <font color="black">Aerial Imagery Pixel-level Segmentation</font>
    </a>
  </h2>
  <font color="black">最先端のDeepLabv3 + Xception65アーキテクチャを使用した私たちの作業は、DroneDeploy検証セットで平均70％のIOUを達成します。データの拡張、正規化、画像サイズ、損失関数に関する実験により、高性能セットアップへの洞察が得られます。空中画像セグメンテーションデータセットの場合..この結果により、現在公開されている最先端の検証セットmIOU（65％）のパフォーマンスを5％上回っています。 
[概要]最新のネットワークアーキテクチャを使用して、マルチクラス設定の航空写真でほとんど作業を行いません。ほとんど作業を行わずに、deeplabv3 xception65アーキテクチャを使用して、dronedeploymememememememememememememememememememememememememememememememememememememememememememememememememememememememememememememememememememememememememememememememememememememememememememememememememe</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Text Recognition in the Wild: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_5.html">
      <font color="black">Text Recognition in the Wild: A Survey</font>
    </a>
  </h2>
  <font color="black">要約すると、この文献レビューは、シーンテキスト認識の分野の全体像を提示しようとしています。この論文の目的は、（1）シーンテキスト認識に関連する基本的な問題と最先端技術を要約することです。 （2）新しい洞察とアイデアを紹介します。 （3）公的に利用可能なリソースの包括的なレビューを提供する。 （4）今後の作業の方向性を指摘します。関連リソースはGithubリポジトリで入手できます：https：//github.com/HCIILAB/Scene-Text-Recognition。 
[概要] githubの研究者は、シーンテキスト認識の分野に関する新しい研究を書きました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br><font color="black">2020-05-07</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal Spatio-Temporal Deep Learning Approach for Neonatal
  Postoperative Pain Assessment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_6.html">
      <font color="black">Multimodal Spatio-Temporal Deep Learning Approach for Neonatal
  Postoperative Pain Assessment</font>
    </a>
  </h2>
  <font color="black">さらに、時空間分析は時間の経過とともにより安定し、誤分類エラーを最小限に抑えるのに非常に効果的であることが証明されています。この論文では、視覚信号と音声信号を統合し、新生児の評価に使用する新しいマルチモーダル時空間アプローチを紹介します。術後の痛み..これらの結果は、提案されたアプローチが、臨床現場、ポイントオブケア検査、および家庭での完全に自動化された痛みのモニタリングへの道を開く手動評価の実行可能な代替手段として使用できることを示しています。 
[概要]これらのアプローチは単峰性であり、主に新生児の手続き型（急性）疼痛の評価に焦点を当てています。それらはしばしばミシモーダルであり、マルチモーダルマルチモーダルアプローチの評価に焦点を当てています。これらの結果は、提案されたアプローチが手動評価の実行可能な代替手段として使用できることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Relational Learning for Skill Preconditions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_7.html">
      <font color="black">Relational Learning for Skill Preconditions</font>
    </a>
  </h2>
  <font color="black">これらのペアワイズオブジェクト関係の連続表現を学習するオブジェクト関係モデルを提案します。オブジェクト関係モデルはシミュレーションで完全にトレーニングされ、学習されると、別の前提条件モデルによって使用されて、実世界のタスクのスキル前提条件が予測されます。この作業では、制約のない環境での操作スキルの前提条件モデルの学習に焦点を当てます。 
[概要]私たちのアプローチは、さまざまな形状とサイズのオブジェクト全体で、3つのタスクすべての前提条件を予測する上で大幅な改善につながることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: FracBits: Mixed Precision Quantization via Fractional Bit-Widths -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_8.html">
      <font color="black">FracBits: Mixed Precision Quantization via Fractional Bit-Widths</font>
    </a>
  </h2>
  <font color="black">ターゲット計算の制約とモデルサイズの下でエンドツーエンドの混合精度モデルを導出するための新しい学習ベースのアルゴリズムを提案します。最終モデルは、MobilenetV1 / V2、ResNet18での混合精度の以前の量子化方法と同等またはそれ以上のパフォーマンスを実現します。 ImageNetデータセットのリソース制約..微分可能な正規化項を使用すると、量子化対応トレーニング中にリソース制約を満たすことができ、最適化された混合精度モデルが得られます。 
[概要]モデルは2つの連続したビットの端数ステータスにあります-幅は徐々に調整できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-04">
        <br><font color="black">2020-07-04</font>
      </time>
    </span>
</section>
<!-- paper0: Dual Refinement Feature Pyramid Networks for Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_9.html">
      <font color="black">Dual Refinement Feature Pyramid Networks for Object Detection</font>
    </a>
  </h2>
  <font color="black">具体的には、DRFPNはSpatial Refinement Block（SRB）とChannel Refinement Block（CRB）の2つのモジュールで構成されます。SRBは隣接するレベル間のコンテキスト情報に基づいてサンプリングポイントの場所と内容を学習します。提案されたDRFPNは既存のDRFPNに簡単に接続できます。 FPNベースのモデル。 
[概要]デュアルリファインメント機能ピラミッドネットワーク（drfpn）は、既存のfpnベースのモデルに簡単にプラグインできます。コードは公開されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Localization of Malaria Parasites and White Blood Cells in Thick Blood
  Smears -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_10.html">
      <font color="black">Localization of Malaria Parasites and White Blood Cells in Thick Blood
  Smears</font>
    </a>
  </h2>
  <font color="black">厚い血液塗抹標本の画像のスライスのデータセットで、取得したデジタル画像を分析するためのモデルを構築します。ただし、寄生虫血症の手動定量化は、時間と労力を要し、かなりの訓練を受けた専門知識を必要とします。 ..データセットのサイズが限られているためにモデルのパフォーマンスを向上させるために、データ拡張が適用されました。 
[要約]研究では、マラリア原虫と白血球の位置特定とカウントのためのエンドツーエンドのアプローチが提示されました。データセットのサイズが限られているため、モデルのパフォーマンスを向上させるためにデータスミアが適用されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Dual-Branch Network with Dual-Sampling Modulated Dice Loss for Hard
  Exudate Segmentation from Colour Fundus Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_11.html">
      <font color="black">Dual-Branch Network with Dual-Sampling Modulated Dice Loss for Hard
  Exudate Segmentation from Colour Fundus Images</font>
    </a>
  </h2>
  <font color="black">詳細には、最初のブランチでは、均一なサンプラーを使用して、ダイス損失計算用の予測セグメンテーションマスクからピクセルをサンプリングします。これにより、ダイス損失により大きなハードの誤認により大きなコストが発生するため、このブランチは自然に大きなハード滲出液にバイアスされます。小さな硬い滲出液よりも滲出液..両方が別々に自分の義務を負います..2番目のブランチでは、リバランスされたサンプラーを使用して硬い滲出液ピクセルをオーバーサンプリングし、損失計算のために背景ピクセルをアンダーサンプリングします。 
[概要]この論文は、これらの問題に取り組むことを目的とし、デュアルサンプリング変調ダイス損失を備えたデュアルブランチネットワークを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Privileged Knowledge Distillation for Online Action Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_12.html">
      <font color="black">Privileged Knowledge Distillation for Online Action Detection</font>
    </a>
  </h2>
  <font color="black">将来のフレームを明示的に予測する他のOAD手法と比較して、私たちのアプローチは、予測できない不要で一貫性のない視覚コンテンツの学習を回避し、2つの人気のあるOADベンチマークであるTVSeriesとTHUMOS14で最先端の精度を実現します。特権知識蒸留（PKD）を提案しますこれは、（i）カリキュラム学習手順をスケジュールし、（ii）情報ギャップを縮小し、学習パフォーマンスを向上させるために、学生モデルに補助ノードを挿入します。このペーパーでは、オンラインアクション検出のための新しい特権ベースの学習フレームワークを紹介します。トレーニング段階でのみ観察可能な将来のフレームは、特権情報の形式と見なされます。 
[概要]この論文は、オンライン行動検出のための特権ベースのフレームワークを備えた新しい学習を提示しました。トレーニング段階でのみ観察可能な将来のフレームは、特権情報の形式と見なされます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-18">
        <br><font color="black">2020-11-18</font>
      </time>
    </span>
</section>
<!-- paper0: Make One-Shot Video Object Segmentation Efficient Again -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_13.html">
      <font color="black">Make One-Shot Video Object Segmentation Efficient Again</font>
    </a>
  </h2>
  <font color="black">最適な学習行動を実現するために、ニューロンレベルで個々の学習率を予測します。ビデオオブジェクトセグメンテーション（VOS）は、ビデオの各フレームでオブジェクトのセットをセグメント化するタスクを説明します。以前の微調整アプローチの非効率性を軽減するため、効率的なワンショットビデオオブジェクトセグメンテーション（e-OSVOS）を紹介します。 
[概要] e-osvosはオブジェクト検出タスクを切り離し、半教師あり設定でローカルオブジェクトのみを予測します。これにより、シーケンス全体の一般的なパフォーマンスの低下に対処するためのオンライン適応を実践できます。ただし、最近、vosコミュニティはそのように見なしています。テスト時間の強化と、実行不可能なテストランタイムへの影響</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Defending Multiple Adversarial Perturbations via Gated Batch
  Normalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_14.html">
      <font color="black">Towards Defending Multiple Adversarial Perturbations via Gated Batch
  Normalization</font>
    </a>
  </h2>
  <font color="black">マルチドメイン仮説に基づいて、\ emph {ゲートバッチ正規化（GBN）}を提案します。これは、複数の摂動タイプに対するロバスト性を向上させるディープニューラルネットワークの新しいビルディングブロックです。最近のいくつかの方法では、複数の$での敵対攻撃に対するモデルのロバスト性が向上しています。 \ ell_p $ボールですが、各摂動タイプに対するパフォーマンスはまだ満足のいくものではありません。次に、異なるブランチの特徴が、後続のレイヤーのドメイン不変表現として整列されます。 
[ABSTRACT]既存の敵対的防御は通常、個々の特定の摂動タイプに対するモデルの堅牢性を向上させます。これらのタイプは、さまざまなタイプの敵対的摂動に基づいています。これらには、ゲート付きサブネットワークとマルチブランチ摂動層が含まれます。これは、各bnブランチが単一摂動型の電荷</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Attributes Aware Face Generation with Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_15.html">
      <font color="black">Attributes Aware Face Generation with Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">次に、3つのスタックジェネレーターが、属性機能を入力として取得することにより、それぞれ$ 64 \ times 64 $、$ 128 \ times 128 $、および$ 256 \ times 256 $の解像度の顔画像を生成します。CelebAでの広範な実験は、両方の定性的な点でAFGANの優位性を示しています具体的には、まず、バイナリ属性ベクトルを豊富な属性特徴に変換するための2パス埋め込み層と自己注意メカニズムを提案します。 【アブストラクト】これに加えて、アフガンと呼ばれる新しい属性認識顔画像生成手法を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Space-Time Correspondence as a Contrastive Random Walk -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_16.html">
      <font color="black">Space-Time Correspondence as a Contrastive Random Walk</font>
    </a>
  </h2>
  <font color="black">さらに、エッジドロップアウトと呼ばれる手法、およびテスト時の自己監視適応により、オブジェクト中心の対応の転送がさらに改善されることを示します。したがって、単一のパスレベル制約が暗黙的に中間比較のチェーンを監視します。類似性のパスに沿って高い確率を配置するように表現を最適化します。 
[要約]適応なしで類似性メトリックとして使用される場合、学習された表現は自己教師ありノードよりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-25">
        <br><font color="black">2020-06-25</font>
      </time>
    </span>
</section>
<!-- paper0: Rel3D: A Minimally Contrastive Benchmark for Grounding Spatial Relations
  in 3D -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_17.html">
      <font color="black">Rel3D: A Minimally Contrastive Benchmark for Grounding Spatial Relations
  in 3D</font>
    </a>
  </h2>
  <font color="black">データセット内の3Dシーンは、最小限のコントラストのペアで提供されます。ペアの2つのシーンはほぼ同じですが、一方には空間関係があり、もう一方には失敗します。Rel3Dを使用すると、大規模な空間関係を予測する際の3D情報の有効性を定量化できます。人間のデータをスケーリングします。視覚入力の空間的関係（「テーブルの上のラップトップ」など）を理解することは、人間とロボットの両方にとって重要です。 
[ABSTRACT] rel3dを使用すると、大規模な人間データの空間関係を予測する際の3D情報の有効性を定量化できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: D-Unet: A Dual-encoder U-Net for Image Splicing Forgery Detection and
  Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_18.html">
      <font color="black">D-Unet: A Dual-encoder U-Net for Image Splicing Forgery Detection and
  Localization</font>
    </a>
  </h2>
  <font color="black">これらの問題を解決するために、画像スプライシング偽造検出用のデュアルエンコーダU-Net（D-Unet）と呼ばれる新しいネットワークを提案します。これは、固定エンコーダと固定エンコーダを使用します。固定エンコーダは、画像の指紋を自律的に学習します。改ざんされた領域と改ざんされていない領域。一方、固定エンコーダーは、ネットワークの学習と検出を支援する方向情報を意図的に提供します。これらの検出方法のほとんどは、ローカルパッチまたはローカルオブジェクトに焦点を当てています。 
[概要]これらの検出方法のほとんどは、ローカルパッチまたはローカルオブジェクトに焦点を当てていますが、一部の特定の画像コンテンツは、cnnベースの検出ネットワークではほとんど保持されません。これらのネットワークは、ネットワークの検出精度を向上させます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Meta-Generating Deep Attentive Metric for Few-shot Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_19.html">
      <font color="black">Meta-Generating Deep Attentive Metric for Few-shot Classification</font>
    </a>
  </h2>
  <font color="black">この調査では、タスクごとに識別可能なメトリックを生成するのに十分な柔軟性を備えた3層の深い注意深いネットワークを使用してメトリックを構築します。コードが利用可能です：https：//github.com/NWPUZhoufei/DAM ..生成の学習タスクを意識した基本学習者は、少数ショット学習（FSL）の問題に対処するための有望な方向性を証明します。 
[ABSTRACT]タスクの説明（たとえば、いくつかのラベル付きサンプル）に基づいて新しいfslタスクの特定のメトリックを適応的に生成することを学習します。提案されたメタ学習者は、クラス間サンプルペアを条件とするマルチモーダル重み分布を開発します。 4つのベンチマークfslデータセットに適合させることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: pixelNeRF: Neural Radiance Fields from One or Few Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_20.html">
      <font color="black">pixelNeRF: Neural Radiance Fields from One or Few Images</font>
    </a>
  </h2>
  <font color="black">1つまたは少数の入力画像を条件とする連続的な神経シーン表現を予測する学習フレームワークであるpixelNeRFを提案します。NeRFのボリュームレンダリングアプローチを活用して、明示的な3D監視なしで画像からモデルを直接トレーニングできます。広範な実験を実施します。ホールドアウトされたオブジェクトと見えないカテゴリ全体を使用した単一画像の新しいビュー合成タスクのShapeNetベンチマークについて。 
[概要]これにより、ネットワークを複数のシーンにまたがってトレーニングし、前のシーンを学習できます。フィードフォワード方式で新しいビュー合成を実行できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Sparse Semi-Supervised Action Recognition with Active Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_21.html">
      <font color="black">Sparse Semi-Supervised Action Recognition with Active Learning</font>
    </a>
  </h2>
  <font color="black">SESARは2つの主要なコンポーネントで構成され、最初のコンポーネントはシーケンスを再構築するエンコーダーデコーダーRNNを介してラベル付けされていないアクションシーケンスの潜在表現を学習し、2番目のコンポーネントはアクティブラーニングを実行してクラスターと分類の不確実性に基づいてラベル付けするシーケンスを選択します.. 2つのコンポーネントがスケルトンベースのアクションシーケンスで同時にトレーニングされると、それらは少数のラベル付きサンプルのみを使用したアクション認識の堅牢なシステムに対応します。SESARは、ラベルなしデータとアクティブに選択された少数のシーケンスの両方からの情報を活用します。監視されていないトレーニングとまばらに監視されているガイダンスを組み合わせたラベリング。 
[ABSTRACT]既存のメソッドは、アノテーションと誤ったラベル付けされたデータに関連する課題のためにパフォーマンスを制限しています。sesarは2つの主要部分で構成され、最初のコンポーネントは不確実なアクションシーケンスを学習します。2番目のコンポーネントはアクティブラーニングを実行して、ラベル付けされるシーケンスを選択します。クラスターと分類の不確実性について</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Implicit Pairs for Boosting Unpaired Image-to-Image Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_22.html">
      <font color="black">Implicit Pairs for Boosting Unpaired Image-to-Image Translation</font>
    </a>
  </h2>
  <font color="black">暗黙のペアの能力は、疑似ペア、つまり実際のペアを近似するだけのペアのサンプルを使用してさらに表示されます。私たちの作業では、暗黙のペアをペアになっていないセットに注入すると、2つのドメイン間のマッピングが強化されることを示します。それらの分布の互換性を改善し、いくつかの測定にわたって教師なし手法のパフォーマンスを14％以上向上させます。このような疑似ペアが合成される可能性がある画像から画像への変換問題に対する近似暗黙サンプルの効果を示します。一方向ではありますが、他の方向ではありません。 
[概要]近年、対になっていないセットからマッピングを学習する手法に注目が集まっています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-15">
        <br><font color="black">2019-04-15</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Alternating Optimization for Blind Hyperspectral Imagery
  Super-resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_23.html">
      <font color="black">Unsupervised Alternating Optimization for Blind Hyperspectral Imagery
  Super-resolution</font>
    </a>
  </h2>
  <font color="black">具体的には、空間領域とスペクトル領域でそれぞれ変性モデルを効果的に取得する方法を調査し、融合ベースのSR再構成モデルとの互換性を高めます。このような問題を十分に軽減するために、教師なしブラインドHSISR法を検討します。次に、メタ学習ベースのメカニズムをさらに提案して、ネットワークを事前トレーニングします。これにより、さまざまな複雑な縮退に適応する速度と一般化能力を効果的に向上させることができます。 
[概要]たとえば、教師なしブラインドhsi sr法を検討します。この目的のために、これらのモデルは縮退モデルを推定し、潜在関数を再構築します。新しい方法は、3つのベンチマークhsisrデータセットに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: VaB-AL: Incorporating Class Imbalance and Difficulty with Variational
  Bayes for Active Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_24.html">
      <font color="black">VaB-AL: Incorporating Class Imbalance and Difficulty with Variational
  Bayes for Active Learning</font>
    </a>
  </h2>
  <font color="black">これらの用語を実装するには、生成モデルと扱いにくい尤度推定が必要です。この方法は、データの不均衡が大きい実世界のデータセットを含む、複数の異なるデータセットの分類タスクに適用できることを示しています。最先端技術..VAEを分類器とさらに結び付け、VAEトレーニングを容易にするために、VAEへの入力として分類器の深い特徴表現を使用します。 
[概要]この目的のために変分オートエンコーダー（vae）をトレーニングします。限られたデータ予算の下で既存の方法の可能性を大幅に向上させることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-25">
        <br><font color="black">2020-03-25</font>
      </time>
    </span>
</section>
<!-- paper0: RELLIS-3D Dataset: Data, Benchmarks and Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_25.html">
      <font color="black">RELLIS-3D Dataset: Data, Benchmarks and Analysis</font>
    </a>
  </h2>
  <font color="black">セマンティックシーンの理解は、特にオフロード環境において、堅牢で安全な自律ナビゲーションに不可欠です。さらに、このデータセットで最新のディープラーニングセマンティックセグメンテーションモデルを評価します。実験結果は、RELLIS-3Dが課題を提示することを示しています。都市環境でのセグメンテーション用に設計されたアルゴリズム用。 
[概要]データはテキサスA＆M大学のレリス状態で収集されました。クラスの不均衡と環境地形に関連する既存のアルゴリズムに課題があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-17">
        <br><font color="black">2020-11-17</font>
      </time>
    </span>
</section>
<!-- paper0: Single-shot Path Integrated Panoptic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_26.html">
      <font color="black">Single-shot Path Integrated Panoptic Segmentation</font>
    </a>
  </h2>
  <font color="black">インスタンスセグメンテーションとセマンティックセグメンテーションを統合する新しいタスクであるパノプティコンセグメンテーションは、最近多くの注目を集めています。トップダウンとボトムアップの両方のアプローチの利点を利用して、SPINetという名前の私たちの方法は高い効率と精度を楽しんでいます主要なパノプティコンセグメンテーションベンチマーク：COCOとCityscapes ..パノプティコン-機能は、同じインスタンスに属し、異なるクラスのオブジェクトを区別するクラスターピクセルにガイドする補助的な問題によってより洗練されます。 
[概要]パノプティコンは、パノプティコンによって作成された統合された特徴マップです。物と物の両方の情報を提供します。パノプティコン-特徴を一度に提供し、プロジェクトを具体化します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Fixed-Point Convolutional Neural Network for Real-Time Video Processing
  in FPGA -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_27.html">
      <font color="black">Fixed-Point Convolutional Neural Network for Real-Time Video Processing
  in FPGA</font>
    </a>
  </h2>
  <font color="black">実験が示したように、提案されたニューラルネットワークは安価なFPGAでもリアルタイムビデオ処理にうまく対応します。この記事では、カメラからの画像を認識する実用的なタスクのためのニューラルネットワークアーキテクチャを提案します。これには速度の点でいくつかの利点があります。 。この記事では、既存のデータセットを別のタスクを解決するために適応させる方法も提案しました。 
[概要]この記事では、カメラからの画像を認識する実用的なタスクのためのニューラルネットワークアーキテクチャを提案しています。また、実装する既存のデータセットを適応させるための手法も提案しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-08-29">
        <br><font color="black">2018-08-29</font>
      </time>
    </span>
</section>
<!-- paper0: Inverse Visual Question Answering with Multi-Level Attentions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_28.html">
      <font color="black">Inverse Visual Question Answering with Multi-Level Attentions</font>
    </a>
  </h2>
  <font color="black">これは、一般的に使用される複数の指標の観点から最先端のパフォーマンスを示しています。VQAV1データセットで提案されたモデルを評価します。モデルでは、部分的な質問での二重注意を含む、2つのレベルの複数の注意が採用されています。エンコードステップと次の疑問詞生成ステップでの動的な注意。 
[ABSTRACT]提案されたモデルは、地域の視覚的および意味的特徴を生成します。次に、注意メカニズムを使用して、回答キューでそれらを強化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-17">
        <br><font color="black">2019-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Label Contrastive Learning for Abstract Visual Reasoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_29.html">
      <font color="black">Multi-Label Contrastive Learning for Abstract Visual Reasoning</font>
    </a>
  </h2>
  <font color="black">提案されたアプローチは、2つの最も人気のあるベンチマークデータセット（Balanced-RAVENとPGM）で評価され、両方で現在の最先端の結果よりも優れていることを示しています。システムの効率的なトレーニングのために、マルチラベルサンプルの場合のノイズコントラスト推定アルゴリズム..この認知の違いに動機付けられたこの作業は、DLとRPMを解決する人間の方法を組み合わせて、両方の世界を最大限に活用することを目的としています。 
[概要]レイヴンの漸進的行列は、最も一般的なタイプの学習問題です。人間は、解決するルールと概念の特定に取り組んでいます。これは、長いパターンベースのトレーニングと、場合によってはデータセットのバイアスの悪用によるものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: A Simple Semi-Supervised Learning Framework for Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_30.html">
      <font color="black">A Simple Semi-Supervised Learning Framework for Object Detection</font>
    </a>
  </h2>
  <font color="black">コードはhttps://github.com/google-research/ssl_detection/で入手できます。MS-COCOを使用して半監視対象オブジェクト検出のパフォーマンスを評価し、両方のMS-COCOでのSTACの有効性を示す実験プロトコルを提案します。およびVOC07 .. STACは、ラベルのない画像からローカライズされたオブジェクトの信頼性の高い疑似ラベルを展開し、強力な拡張によって一貫性を適用することでモデルを更新します。 
[概要]視覚認識のデモンストレーションの範囲は、主に画像分類タスクにあります。これは、目覚ましい進歩があったにもかかわらずです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-10">
        <br><font color="black">2020-05-10</font>
      </time>
    </span>
</section>
<!-- paper0: BERT-hLSTMs: BERT and Hierarchical LSTMs for Visual Storytelling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_31.html">
      <font color="black">BERT-hLSTMs: BERT and Hierarchical LSTMs for Visual Storytelling</font>
    </a>
  </h2>
  <font color="black">トランスフォーマーベースのBERTを使用して、文と単語の埋め込みを取得します。この問題に取り組むために、文レベルと単語レベルのセマンティクスを別々にモデル化する新しい階層型ビジュアルストーリーテリングフレームワークを提案します。実験結果は、モデルが最も優れていることを示しています。自動評価メトリックBLEUおよびCIDErの下で密接に関連するベースライン、および人間の評価による私たちの方法の有効性も示しています。 
[概要]視覚的なストーリーテリングアプローチは、単語レベルのシーケンス生成方法を使用し、文レベルの依存関係を適切に考慮していないため、一貫性に欠けています。トランスフォーマーベースのバートを使用して、文と単語の埋め込みを取得します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Auto Seg-Loss: Searching Metric Surrogates for Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_32.html">
      <font color="black">Auto Seg-Loss: Searching Metric Surrogates for Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">広く採用されているクロスエントロピー損失とその変形の成功にもかかわらず、損失関数と評価メトリック間の不整合はネットワークパフォーマンスを低下させます。特にセマンティックセグメンテーションの分野では、さまざまなシナリオに対してさまざまな評価メトリックが提案されています。 。検索スペースを正規化し、検索を効率化するために、2つの制約が導入されています。 
[概要]たとえば、さまざまな種類の損失に対して評価指標が提案されています。現在、損失関数を手動で設計するには、専門知識と重要な損失関数が必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Flow-based Deformation Guidance for Unpaired Multi-Contrast MRI
  Image-to-Image Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_33.html">
      <font color="black">Flow-based Deformation Guidance for Unpaired Multi-Contrast MRI
  Image-to-Image Translation</font>
    </a>
  </h2>
  <font color="black">フローベースのアーキテクチャの可逆特性により、追加の損失関数なしで画像から画像への変換のサイクル整合性が保証されます。連続するスライス間の時間情報を利用して、ペアになっていないドメインを別のドメインに変換するための最適化にさらに制約を与えます。ボリューム医療画像..HCP、MRBrainS13、およびBrats2019。 
[概要]この論文では、対になっていない画像への新しいアプローチを紹介します-これに加えて、これを使用して、対になっていない画像で1つのドメインを別のドメインに変換するための拡張にさらに制約を与えます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: A combined full-reference image quality assessment approach based on
  convolutional activation maps -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_34.html">
      <font color="black">A combined full-reference image quality assessment approach based on
  convolutional activation maps</font>
    </a>
  </h2>
  <font color="black">具体的には、提案手法を少ないデータ量でトレーニングして高い予測性能を実現できることを実証します。さらに、トレーニング画像の量と予測性能の関係を調べます。詳細なパラメータの研究については、提案された方法の設計上の選択が推論されます。 
[概要]私たちの最良の提案であるactmapfeatは、6つの公開されているベンチマークiqaデータベースの最新技術と比較されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-19">
        <br><font color="black">2020-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: Temporal Pyramid Network for Pedestrian Trajectory Prediction with
  Multi-Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_35.html">
      <font color="black">Temporal Pyramid Network for Pedestrian Trajectory Prediction with
  Multi-Supervision</font>
    </a>
  </h2>
  <font color="black">さらに、マルチ監視による粗い融合戦略を提案します。この論文では、スクイーズ変調と膨張変調による歩行者軌道予測のための時間ピラミッドネットワークを提案します。私たちの階層的フレームワークは、上から下へとますます豊富な時間情報。これにより、さまざまなテンポでのモーション動作をより適切にキャプチャできます。 
[概要]当社のシステムは、軌道の長距離情報と短距離情報の両方を十分に活用できます。特定の時間における歩行方向や速度などの長距離情報を同時に活用することは困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: The Resistance to Label Noise in K-NN and DNN Depends on its
  Concentration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_36.html">
      <font color="black">The Resistance to Label Noise in K-NN and DNN Depends on its
  Concentration</font>
    </a>
  </h2>
  <font color="black">最後に、開発された式がK-NNおよびDNN分類器の観測されたパフォーマンスに近接していることを経験的に示します。K最近傍法（K-NN）および深層ニューラルネットワーク（DNN）の分類パフォーマンスを調査します。ラベルノイズ..私たちの結果は、いくつかのタイプのラベルノイズに対するDNNのすでに観察された驚くべき耐性を説明するかもしれません。 
[要約] k-テスト例のnnの予測は、そのローカル近隣のトレーニング例のラベルに依存します。発見は、ラベルノイズに対するdnnの抵抗を説明します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-03-30">
        <br><font color="black">2018-03-30</font>
      </time>
    </span>
</section>
<!-- paper0: A small note on variation in segmentation annotations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_37.html">
      <font color="black">A small note on variation in segmentation annotations</font>
    </a>
  </h2>
  <font color="black">パフォーマンスが最悪のアノテーターを削除した後、残りの分散は意味的に意味があり、セル境界とセル内部のセグメンテーションを取得するために利用できることを示します。機械学習に関するワークショップで実施された小規模なクラウドソーシング実験の結果について報告します。 2020年のデンマークバイオイメージングネットワーク会議で開催されたセグメンテーション。実験の目的は、手動の注釈をグラウンドトゥルースとしてではなく、大幅に変動する可能性のある参照標準として見なすべきであることを示すことでした。 
[概要]参加者に、ミトコンドリアを3つの2Dパッチに手動でセグメント化できるように依頼しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Semantic Parsing of Freehand Sketches with Homogeneous
  Transformation, Soft-Weighted Loss, and Staged Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_38.html">
      <font color="black">Deep Semantic Parsing of Freehand Sketches with Homogeneous
  Transformation, Soft-Weighted Loss, and Staged Learning</font>
    </a>
  </h2>
  <font color="black">この論文では、フリーハンドスケッチの部分レベルの意味解析のための新しい深いフレームワークを提案します。これは、実験的に実質的な実用的メリットがあることが示されている3つの主要な貢献をします。スケッチ解析のタスクについては、ラベル付きの利用可能なデータはありません。モデルトレーニングに直接使用できるフリーハンドスケッチ。具体的には、同種変換法の一般化能力を評価するために、スケッチベースの画像検索タスクの追加実験がQMULFG-SBIRデータセットで実行されます。 
[概要]提案された方法は、ドメイン適応の問題に対処するように設計されています。実際の画像解析から3つの異なるタイプの学習が必要です。これらには、あいまいな空間とクラスの不均衡の両方に注意を向けるソフト加重損失関数が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-14">
        <br><font color="black">2019-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Self-labeled Conditional GANs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_39.html">
      <font color="black">Self-labeled Conditional GANs</font>
    </a>
  </h2>
  <font color="black">また、CIFAR10およびCIFAR100の人間のラベルでトレーニングされたクラス条件付きGANよりも優れています。この場合、きめ細かい注釈やクラスごとの多数のサンプルは利用できません。クラスタリングネットワークを標準の条件付きGANフレームワークに組み込み、ディスクリミネーターと対戦します。さらに、当社のクラスタリングネットワークは、CIFAR100クラスタリングの最先端を超えています。 
[概要]ジェネレーターは、imagenetやlsunなどの大規模データセットでかなりのマージンを持ってfidの点で無条件のガンよりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Aggregating Long-Term Context for Learning Laparoscopic and
  Robot-Assisted Surgical Workflows -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_40.html">
      <font color="black">Aggregating Long-Term Context for Learning Laparoscopic and
  Robot-Assisted Surgical Workflows</font>
    </a>
  </h2>
  <font color="black">タスク固有のネットワーク表現を活用して、十分統計量モデル（SSM）によって伝播される長期的な十分統計量を収集する新しい時間ネットワーク構造を提案します。既存および新規の最先端のセグメンテーションよりも優れた結果を示します。 2つの腹腔鏡下胆嚢摘出術データセットの手法：公開されているCholec80データセットとMGH100、より挑戦的で臨床的に意味のあるセグメントラベルを備えた新しいデータセット。 。 
[概要]完全な手術ワークフローを理解することで、ロボットは手術中のイベントで外科医を支援することができます。これには、外科医が特定のキーまたは高リスクフェーズに入ったときに警告を発することが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Adaptive Partial Scanning Transmission Electron Microscopy with
  Reinforcement Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_41.html">
      <font color="black">Adaptive Partial Scanning Transmission Electron Microscopy with
  Reinforcement Learning</font>
    </a>
  </h2>
  <font color="black">再発アクターは、スパーススキャンを完了するフィードフォワード畳み込みニューラルネットワークと連携するように強化学習によってトレーニングされます。ソースコード、事前トレーニング済みモデル、およびトレーニングデータは、https：//github.com/Jeffrey-Ede/adaptive-scansで公開されています。 。スキャンセグメントのサンプリング方向は、以前に観測されたスキャンセグメントに基づいてリカレントニューラルネットワークによって選択されます。 
[概要]データは失われた情報を測定するために使用できますが、テストには役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: Multiple Networks are More Efficient than One: Fast and Accurate Models
  via Ensembles and Cascades -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_42.html">
      <font color="black">Multiple Networks are More Efficient than One: Fast and Accurate Models
  via Ensembles and Cascades</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、大規模な計算体制では、モデルアンサンブルは、大規模な孤立モデルを使用するよりも精度を向上させるための費用効果の高い方法であることを示唆しています。また、アンサンブルをカスケードに変換することで、アンサンブルの計算コストを大幅に削減できることもわかりました。多くの場合、完全なアンサンブルの元の精度を維持しながら、さまざまなビジョンタスクおよびアーキテクチャファミリでの委員会ベースのモデルの利点を広範囲に調査します。 
[概要]新しいアーキテクチャの検索には、通常、かなりのコンピューティングリソースが必要です。大規模なプログラム体制では、モデルアンサンブルは、大規模な単独モデルを使用するよりもコスト効率の高い方法で精度を向上させます。委員会ベースのモデル、つまりアンサンブルを示します。またはモデルのカスケードは、単一のモデルと比較した場合、少ない計算でより高い精度を簡単に得ることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: SSGD: A safe and efficient method of gradient descent -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_43.html">
      <font color="black">SSGD: A safe and efficient method of gradient descent</font>
    </a>
  </h2>
  <font color="black">実験結果は、私たちのアプローチが精度と堅牢性の点で一般的な勾配降下アプローチよりも明らかに優れていることを示しています。人工知能技術の活発な開発に伴い、さまざまな工学技術アプリケーションが次々に実装されています。勾配降下法は重要な役割を果たします。シンプルな構造、優れた安定性、簡単な実装により、さまざまな最適化の問題を解決する役割を果たします。 
[概要]システムはシンプルな構造、優れた安定性、簡単な実装を備えています。データの精度を使用してアップグレードを防ぐことができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: SMDS-Net: Model Guided Spectral-Spatial Network for Hyperspectral Image
  Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_44.html">
      <font color="black">SMDS-Net: Model Guided Spectral-Spatial Network for Hyperspectral Image
  Denoising</font>
    </a>
  </h2>
  <font color="black">広範な実験と包括的な分析により、最先端のHSIノイズ除去方法に対する私たちの方法のノイズ除去能力と解釈可能性が確認されます。ディープラーニング（DL）ベースのハイパースペクトル画像（HSI）ノイズ除去アプローチは、観測されたノイズの多い画像間の非線形マッピングを直接学習します。これにより、SMDS-Netは明確な物理的意味を伝達します。つまり、HSIの低ランク性と希薄性を学習します。 
[概要] hsisのハイパーレスティング画像は、ハイパースペクティングネットワークsmds-netによって作成されます。これらのモジュールは、ノイズ除去手順およびモデルの拡張とシームレスに接続されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Federated Learning with Noisy Labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_45.html">
      <font color="black">Robust Federated Learning with Noisy Labels</font>
    </a>
  </h2>
  <font color="black">これらの重心は、各デバイスのローカルデータの中心的な機能であり、通信ラウンドごとにサーバーによって調整されます。これらの問題を解決するために、サーバーがローカルモデルと連携して、クラスを交換することで一貫した決定境界を維持する、新しいフェデレーション学習スキームを導入します。賢明な重心..その結果、ローカルモデルは一貫性のない決定境界を形成し、それらの重みは互いに大きく異なります。これは、連合学習における深刻な問題です。 
[ABSTRACT]連合学習は、サーバーがローカルモデルと連携して、クラスごとの重心を交換することにより、一貫した決定境界を維持できるようにするシステムです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: A Multi-task Contextual Atrous Residual Network for Brain Tumor
  Detection & Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_46.html">
      <font color="black">A Multi-task Contextual Atrous Residual Network for Brain Tumor
  Detection & Segmentation</font>
    </a>
  </h2>
  <font color="black">最初の目的は、アテンションゲートの役割を果たし、腫瘍との相関性が低い遠方の背景を無視しながら、脳腫瘍の周囲の領域にのみ焦点を当てる、提案されたコンテキスト脳腫瘍検出ネットワークによって実行されます。最先端のアプローチとの比較..当社の3Dアトラス残差ネットワークは、スキップ接続を使用して設計されており、深い層から浅い層への勾配を直接伝播できるため、さまざまな深さの特徴が保持され、お互いを洗練する。 
[概要]ネットワークは、フィルターの受容野を拡大するために3d atrous残余ネットワークを使用します。これらのネットワークは、異なるカーネルサイズの3datrous畳み込みを使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Sketch-Specific Data Augmentation for Freehand Sketch Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_47.html">
      <font color="black">Sketch-Specific Data Augmentation for Freehand Sketch Recognition</font>
    </a>
  </h2>
  <font color="black">品質向上に向けて、クラス内分散が小さい新しいタイプのスケッチのセットを生成するための平均ストローク再構成（MSR）アプローチを提示します。これらのソリューションは両方とも、マルチソースデータおよびスケッチの時間的手がかりから制限されていません。最後に、より多くの実験が、スケッチベースの画像検索のタスクに対する私たちのアプローチの実用的な価値を示しています。 
[概要]スケッチベースのスケッチの実践は、特定のオブジェクトデータやスケッチの時間的手がかりに制限されません。ssdaは任意の畳み込みネットワークと統合できるため、既存の方法の明確な利点があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-14">
        <br><font color="black">2019-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: AutoInt: Automatic Integration for Fast Neural Volume Rendering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_48.html">
      <font color="black">AutoInt: Automatic Integration for Fast Neural Volume Rendering</font>
    </a>
  </h2>
  <font color="black">トレーニングでは、陰的神経表現の導関数に対応する計算グラフをインスタンス化します。ただし、これらの方法を実用化する上での根本的な障害は、トレーニングおよび推論中にレンダリングされた光線に沿って必要なボリューム統合によって引き起こされる極端な計算およびメモリ要件です。 ..計算の基本定理により、これにより、ネットワークの2つの評価で任意の明確な積分を計算できます。 
[概要]数百万の光線の画像をキャプチャするためのクイックトラックフォートラックアプローチを取得するためのシンプルでシンプルでシンプルな方法。新しいモデルとして発表されましたが、すでに発表されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Co-mining: Self-Supervised Learning for Sparsely Annotated Object
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_49.html">
      <font color="black">Co-mining: Self-Supervised Learning for Sparsely Annotated Object
  Detection</font>
    </a>
  </h2>
  <font color="black">マルチビュー学習を強化し、ラベルのないインスタンスをより適切にマイニングするために、元の画像と対応する拡張画像が、それぞれシャムネットワークの2つのブランチの入力として使用されます。まばらに注釈が付けられたオブジェクト検出のほとんどの既存の方法は、ハードネガティブサンプルまたはラベルのないインスタンスを無視された領域に変換して、フォールスネガティブの干渉を減らします。実験は、アンカーベースの検出器RetinaNetとアンカーフリー検出器FCOSの2つの典型的なフレームワークを使用して、3つの異なるまばらに注釈が付けられた設定でMSCOCOデータセットで実行されます。 
[概要]レティナネットとの連携により、シャムネットワークの2つのブランチを使用して注釈が付けられた1.4％のコーリーコーリーを実現します。これらの戦略は、注釈の欠落によって引き起こされる悪影響をせいぜい軽減できるため、不十分です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Predicting Livelihood Indicators from Crowdsourced Street Level Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_50.html">
      <font color="black">Predicting Livelihood Indicators from Crowdsourced Street Level Images</font>
    </a>
  </h2>
  <font color="black">モデルにとって重要な機能とその使用方法を視覚化することで、エンドユーザー組織がモデルを理解し、安価に入手できる道路機能を使用するインデックス推定の代替アプローチを提供できます。政府やその他の大規模な組織からの主要な決定は大衆の幸福の測定についてですが、そのような測定を大規模に行うことは費用がかかり、したがって発展途上国の多くでまれです。全国的に代表的な世帯調査で収集された地上データと私たちの結果を比較することによって、インドとケニアの2つの異なる国でテストすることにより、貧困、人口、健康の指標とその拡張性を正確に予測するための私たちのアプローチ。 
[概要]公共の群衆ベースのストリートレベルの画像から主要な生計指標を予測するための、安価でスケーラブルで解釈可能なアプローチを提案します。これらには、有益なオブジェクトを検出することによって複数世帯のクラスター表現を作成する方法と、グラフベースのアプローチが含まれます。画像間の関係をキャプチャします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Part-Based Understanding of RGB-D Scans -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_51.html">
      <font color="black">Towards Part-Based Understanding of RGB-D Scans</font>
    </a>
  </h2>
  <font color="black">中間パーツグラフ表現を活用して、パーツの事前の構築だけでなく、堅牢な完了を可能にします。これを使用して、最終的なパーツマスク予測を構築します。 3Dシーンに関するレベルの推論。ただし、オブジェクトとの相互作用とその機能的理解を可能にするには、よりきめ細かい理解が必要です。私たちの実験は、パーツグラフを介してパーツの理解をパーツの事前ベースの予測に導くことは、セマンティックパーツの完了のタスクに対する代替アプローチよりも大幅に優れていることを示しています。 
[概要]実世界の3D環境のパーツベースのシーン理解のタスクを提案します。シーンのrgb-dスキャンから、オブジェクトを検出し、各オブジェクトについて、幾何学的パーツマスクへの分解を予測します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: MakeupBag: Disentangling Makeup Extraction and Application -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_52.html">
      <font color="black">MakeupBag: Disentangling Makeup Extraction and Application</font>
    </a>
  </h2>
  <font color="black">2つのタスクを絡ませている他の現在の深い方法とは対照的に、私たちはメイクの解きほぐしと顔のメイクの適用を分離可能な目的として解決します。 .MakeupBagは、現在の方法では不可能な、抽出されたメイクアップスタイルのカスタマイズとピクセル固有の変更を可能にするため、私たちのアプローチに大きな利点をもたらします。 
[概要]提案された手法は、新しいメイクスタイルを参照顔画像から別の以前に見られなかった顔写真に転送することができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Learned Initializations for Optimizing Coordinate-Based Neural
  Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_53.html">
      <font color="black">Learned Initializations for Optimizing Coordinate-Based Neural
  Representations</font>
    </a>
  </h2>
  <font color="black">2D画像の表現、CTスキャンの再構築、2D画像観察からの3D形状とシーンの復元など、さまざまなタスクでこれらの利点を探ります。座標ベースの神経表現は、離散的なアレイベースの表現の代替として大きな期待を示しています。複雑な低次元信号の場合..標準のメタ学習アルゴリズムを適用して、表現されている信号の基礎となるクラス（たとえば、顔の画像や椅子の3Dモデル）に基づいて、これらの完全に接続されたネットワークの初期重みパラメーターを学習することを提案します。 
[概要]これらの学習された初期重みを使用すると、モデル化される信号クラスよりも強力な事前分布として機能し、特定の信号の部分的な観測のみが利用可能な場合に、より一般化されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Pedestrian Trajectory Prediction using Context-Augmented Transformer
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_54.html">
      <font color="black">Pedestrian Trajectory Prediction using Context-Augmented Transformer
  Networks</font>
    </a>
  </h2>
  <font color="black">歩行者のロバストな軌道予測を提供するために、フレームワークへの入力として、過去の位置情報、エージェントの相互作用情報、およびシーンの物理的セマンティクス情報の融合に依存しました。歩行者の2つの実際のデータセットでフレームワークを評価しました。共有都市交通環境では、短期および長期の予測範囲の両方で、比較されたベースラインアプローチを上回っています。文献では、この問題は、反復ニューラルネットワーク（RNN）を使用して対処されることがよくあります。 
[概要]この問題は、リカレントニューラルネットワーク（rnns）を使用して対処されることがよくあります。この作業では、より効率的でrnnsを上回ることが課題となった変圧器ネットワークに基づくフレームワークを紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Beyond Cats and Dogs: Semi-supervised Classification of fuzzy labels
  with overclustering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_55.html">
      <font color="black">Beyond Cats and Dogs: Semi-supervised Classification of fuzzy labels
  with overclustering</font>
    </a>
  </h2>
  <font color="black">フレームワークのオーバークラスタリング機能を改善するための新しい損失を提案し、共通の画像分類データセットSTL-10で、以前の作業よりも高速でオーバークラスタリングのパフォーマンスが優れていることを示します。半教師あり分類を処理するための新しいフレームワークを提案します。そのようなファジーラベル..しかし、現実の世界では、異なる専門家が異なる意見を持っているという問題にしばしば遭遇し、ファジーラベルを生成します。 
[概要]半教師あり学習の現在の研究では、実際のデータ量が10分の1以上減少する可能性がありますが、この一連の研究では、猫や犬などの異なるクラスが使用されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Patch2Pix: Epipolar-Guided Pixel-Level Correspondences -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_56.html">
      <font color="black">Patch2Pix: Epipolar-Guided Pixel-Level Correspondences</font>
    </a>
  </h2>
  <font color="black">一致提案によって定義されたローカル領域からピクセルレベルの一致を回帰し、信頼スコアを使用して外れ値の一致を共同で拒否することにより、一致提案を洗練する新しい改良ネットワークPatch2Pixを提示します。これは、のエピポーラジオメトリと一致する対応を学習するために弱く監視されます。入力画像ペア..この作業では、検出から絞り込みの方法で対応を推定する新しい視点を提案します。最初にパッチレベルの一致提案を予測し、次にそれらを絞り込みます。さらに、学習した絞り込みを示します。再トレーニングなしで完全に監視された方法に一般化され、最先端のローカリゼーションパフォーマンスにつながります。 
[ABSTRACT]通信ネットワークは、単一のネットワーク内でこれらのステップを実行することを提案しますが、パースペクティブのボトルネックのためにマッチング解像度が低くなります。さらに、学習した改良が、再トレーニングなしで完全に監視された方法に一般化されることを示します。最先端のローカリゼーションパフォーマンスパフォーマンス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Essential Features: Reducing the Attack Surface of Adversarial
  Perturbations with Robust Content-Aware Image Preprocessing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_57.html">
      <font color="black">Essential Features: Reducing the Attack Surface of Adversarial
  Perturbations with Robust Content-Aware Image Preprocessing</font>
    </a>
  </h2>
  <font color="black">具体的には、元のオブジェクトの主なエッジの特徴をk-means減色アプローチとともに保持する適応ブラー戦略を採用して、画像をそのk個の最も代表的な色に単純化します。既存のアプローチは、のコンテンツに直交して設計される傾向があります。このアプローチは、元の画像の適切な特徴を維持しながら色を調整する機能を制限することにより、敵の攻撃面を大幅に制限します。 
[要約]本質的特徴と呼ばれる新しい技術は、画像を、摂動の影響を低減する堅牢な特徴空間に変換します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Data-Efficient Learning: A Benchmark for COVID-19 CT Lung and
  Infection Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_58.html">
      <font color="black">Towards Data-Efficient Learning: A Benchmark for COVID-19 CT Lung and
  Infection Segmentation</font>
    </a>
  </h2>
  <font color="black">さらに、現在のCOVID-19 CTセグメンテーション手法は、さまざまなデータセットで開発され、さまざまな設定でトレーニングされ、さまざまな指標で評価されているため、比較するのは困難です。これらのリソースはすべて公開されており、私たちの仕事は、限られたデータで効率的なCOVID-19CTセグメンテーションのための深層学習法の開発..結論：私たちの知る限り、この作業は、医療画像セグメンテーションのための最初のデータ効率的な学習ベンチマークと、事前にトレーニングされたモデルの最大数を示します今まで。 
[要約]既存の研究のほとんどは、単一の機関から取得するのが難しい大規模でプライベートな注釈付きデータセットに基づいています。この論文では、70の注釈付きcovid-19のケースに基づいて肺と感染のセグメンテーションの3つのベンチマークを構築しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br><font color="black">2020-04-27</font>
      </time>
    </span>
</section>
<!-- paper0: StyleSpace Analysis: Disentangled Controls for StyleGAN Image Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_59.html">
      <font color="black">StyleSpace Analysis: Disentangled Controls for StyleGAN Image Generation</font>
    </a>
  </h2>
  <font color="black">次に、スタイルチャネルの大規模なコレクションを検出する方法について説明します。各チャネルは、高度にローカライズされ、解きほぐされた方法で個別の視覚属性を制御することが示されています。最初に、チャネルごとのスタイルパラメータのスペースであるStyleSpaceを示します。これらのStyleSpaceコントロールを介した視覚的属性の操作は、以前の作品で提案されたものよりもうまく解きほぐされていることが示されています。 
[概要]最初に、styleslicaが以前の作品で調査された他の中間潜在空間よりも大幅に解きほぐされていることを示します。事前にトレーニングされた分類器または少数のサンプル画像を使用して、特定のオブジェクトを制御するスタイルチャネルを識別する簡単な方法を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Hi-UCD: A Large-scale Dataset for Urban Semantic Change Detection in
  Remote Sensing Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_60.html">
      <font color="black">Hi-UCD: A Large-scale Dataset for Urban Semantic Change Detection in
  Remote Sensing Imagery</font>
    </a>
  </h2>
  <font color="black">洗練された都市の変化を検出および分析するために使用できます。バイナリおよびマルチクラスの変化検出でいくつかの古典的な方法を使用してデータセットをベンチマークします。実験結果は、Hi-UCDが挑戦的でありながら有用であることを示しています。 
[概要]このデータセットは、空間解像度が0.1 mの航空写真を使用しています。3つの時相が含まれ、9つのクラスの土地被覆で意味的に注釈が付けられています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-06">
        <br><font color="black">2020-11-06</font>
      </time>
    </span>
</section>
<!-- paper0: COVID-19 CT Image Synthesis with a Conditional Generative Adversarial
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_61.html">
      <font color="black">COVID-19 CT Image Synthesis with a Conditional Generative Adversarial
  Network</font>
    </a>
  </h2>
  <font color="black">ただし、深層学習モデルのトレーニングには大量のデータが必要であり、COVID-19 CTデータを収集する際、病気の感染力が高いため、医療スタッフは高いリスクに直面します。胸部CTイメージングには、迅速な報告という利点があります。コスト、および肺感染の検出のための高感度.. COVID-19 CTイメージングのデータ要件を満たすために、高品質で現実的なものを効果的に生成できる条件付き生成敵ネットワークに基づくCT画像合成アプローチを提案します。深層学習ベースの医療画像タスクで使用するためのCOVID-19CT画像。 
[ABSTRACT] ctスキャンはcovid-19診断において重要な役割を果たします。これは、他の最先端の画像を上回る最新の方法です。提案された方法は、さまざまな機械学習アプリケーションに有望であることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Two-Stream CNN for Multi-Modal Age-related Macular Degeneration
  Categorization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_62.html">
      <font color="black">Learning Two-Stream CNN for Multi-Modal Age-related Macular Degeneration
  Categorization</font>
    </a>
  </h2>
  <font color="black">1,099のカラー眼底画像と1,099の異なる目から取得された1,290のOCT画像で構成される臨床データセットでの実験により、マルチモーダルAMD分類に対する提案されたソリューションの有効性が検証されます。対照的に、マルチモーダル入力が与えられた場合のAMD分類を検討します。臨床的に意味があるがほとんど未踏の方向..最終的な予測への個々のモダリティの寄与を視覚的に解釈するために、クラスアクティベーションマッピング（CAM）手法をマルチモーダルシナリオに拡張します。 
[概要]マルチモーダルamd分類の提案されたソリューションが開発されました。カラー眼底画像またはオクト画像の場合がありますが、代わりに、エンドツーエンドのマルチモーダル畳み込みニューラルネットワークを選択します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Object-Centric Image Generation from Layouts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_63.html">
      <font color="black">Object-Centric Image Generation from Layouts</font>
    </a>
  </h2>
  <font color="black">単一オブジェクトおよび単一ドメインの画像生成に関する最近の印象的な結果にもかかわらず、複数のオブジェクトを含む複雑なシーンの生成は依然として困難です。SGSMは、シーン内のオブジェクト間の空間的関係の表現を学習し、モデルのレイアウト忠実度の向上につながります。 ..画質の向上とは別に、私たちの貢献は、以前のアプローチの2つの障害モードを軽減します。（1）レイアウト内の対応する境界ボックスなしで生成される偽のオブジェクト、および（2）画像内のマージされたオブジェクトにつながるレイアウト内の重複する境界ボックス。 
[概要] sgsmは、シーン内のオブジェクト間の空間的関係の表現を学習します。これらは、モデルのレイアウトの改善につながります-忠実度。これにより、以前のアプローチで複数の障害モードが追加されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-16">
        <br><font color="black">2020-03-16</font>
      </time>
    </span>
</section>
<!-- paper0: Recovering Trajectories of Unmarked Joints in 3D Human Actions Using
  Latent Space Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_64.html">
      <font color="black">Recovering Trajectories of Unmarked Joints in 3D Human Actions Using
  Latent Space Optimization</font>
    </a>
  </h2>
  <font color="black">これは、特定の関節の位置がマークアップされないことを意味し、全身の動きのダウンストリーム分析が困難になります。マーカーなしのモーションキャプチャは大きな進歩を遂げましたが、ヘルスケア、マーカーベースのシステム、特にアクティブマーカーなどの重要なアプリケーションでは、は依然としてゴールドスタンダードと見なされています。特定のアクションの欠落している関節を人間のアクションの多様体に投影することで回復します。これは、ディープオートエンコーダーの潜在空間表現を最適化することで実現されます。 
[ABSTRACT]モーションキャプチャとkinectのデータセットは、提案された方法が欠落した関節の結果を回復するのに非常にうまく機能することを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Parallel Residual Bi-Fusion Feature Pyramid Network for Accurate
  Single-Shot Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_65.html">
      <font color="black">Parallel Residual Bi-Fusion Feature Pyramid Network for Accurate
  Single-Shot Object Detection</font>
    </a>
  </h2>
  <font color="black">より多くの層を持つより深いバックボーンが使用されると、FPの利点は弱まります。（2）連結および再編成（CORE）モジュールは、機能融合のためのボトムアップ経路を提供します。これにより、双方向融合FPが可能になります。失われた情報を下位層の特徴マップから回復します。私たちの方法は、小さなオブジェクトの検出に特に適しています。 
[概要]バイウェイト（トップダウンとボトムアップ）融合を備えた新しい並列fp構造を提案し、大小のオブジェクトを高精度で一度に検出します。方法は、プーリングシフトによる正確なローカリゼーションを維持することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: NICER: Aesthetic Image Enhancement with Humans in the Loop -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_66.html">
      <font color="black">NICER: Aesthetic Image Enhancement with Humans in the Loop</font>
    </a>
  </h2>
  <font color="black">半自動の方法では、ほとんどの場合、事前定義された編集手順を制御できます。これにより、ユーザーの創造性と明るさやコントラストなどの詳細な調整を行う能力が制限されます。したがって、この作業では、ニューラル画像の補正と拡張のルーチンを提案します（ NICER）、インタラクティブでユーザー中心の完全、半自動、または完全に手動のプロセスでの参照なしの画像強調へのニューラルネットワークベースのアプローチ。この方向でのさらなる研究を容易にするために、コードを公開します。 
[ABSTRACT]ユーザーにエンハンスメントプロセスの制御を与えないソフトウェア。ユーザーに主観的にアピールしない編集済み画像につながる可能性があります。nicerは、に基づいて美的スコアを最大化するために、画像編集パラメーターにnoを繰り返し調整します。画像のスタイルとコンテンツ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: SB-MTL: Score-based Meta Transfer-Learning for Cross-Domain Few-Shot
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_67.html">
      <font color="black">SB-MTL: Score-based Meta Transfer-Learning for Cross-Domain Few-Shot
  Learning</font>
    </a>
  </h2>
  <font color="black">まず、微調整するように設計された特定のレイヤーを備えた機能エンコーダーがあります。クロスドメイン少数ショット学習の広範な研究（BSCD-FSL）ベンチマークでモデルをテストします。これには、高度なターゲットドメインの範囲が含まれます。 miniImagenetソースドメインとのさまざまな非類似性。次に、微調整後に分類スコアを直接取得する代わりに、ソフトマックス前の分類スコアを距離空間にマッピングすることにより、スコアを座標として解釈します。 
[概要]スコアベースのメタ転送-学習（sb-mtl）と呼ばれる私たちの方法は、アドレス-学習とメタ-maml-最適化された機能エンコーダーとスコアベースのグラフニューラルネットワークを使用した学習を組み合わせたものです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Interpretable Graph Capsule Networks for Object Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_68.html">
      <font color="black">Interpretable Graph Capsule Networks for Object Recognition</font>
    </a>
  </h2>
  <font color="black">この作業では、後者について説明します。さらに、GraCapsNetsは、CapsNetsの他の利点、つまり、解きほぐされた表現とアフィン変換のロバスト性も保持します。これらの顕著性メソッドは、基礎となる分類器の特定のアーキテクチャを必要とし、その中の反復ルーティングメカニズム。 
[概要]広く使用されている顕著性手法は、主にcnnベースの分類を説明するために提案されています。これらは、アクティベーション値と対応する勾配を組み合わせて顕著性マップの説明を作成します。これらの顕著性手法は、解釈可能性の欠如を克服できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Full-Resolution Correspondence Learning for Image Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_69.html">
      <font color="black">Full-Resolution Correspondence Learning for Image Translation</font>
    </a>
  </h2>
  <font color="black">提案されたGRU支援PatchMatchは、完全に微分可能で非常に効率的です。画像変換と共同でトレーニングすると、教師なしの方法でフル解像度のセマンティック対応を確立できます。これにより、模範ベースの画像変換が容易になります。各PatchMatch反復内、ConvGRUモジュールは、より大きなコンテキストのマッチングだけでなく、過去の推定値も考慮して、現在の対応を改善するために使用されます。 
[概要]画像翻訳で完全にトレーニングされると、教師なしの方法でフル解像度のセマンティック対応を確立できます。これにより、模範ベースの画像翻訳が支援されます。実験は、パッチマッチの拡張で実行できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Conditional Adversarial Camera Model Anonymization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_70.html">
      <font color="black">Conditional Adversarial Camera Model Anonymization</font>
    </a>
  </h2>
  <font color="black">特定の写真画像をキャプチャするために使用されたカメラのモデル（モデルの帰属）は、通常、画像内に存在する高周波モデル固有のアーティファクトから推測されます。事前にトレーニングされたデュアルストリームモデルからの損失で対物レンズを補強します。アトリビューション分類子。生成ネットワークを制約して、アーティファクトの全範囲を変換します。モデルの匿名化は、見かけのキャプチャモデルが変更されるように、これらのアーティファクトを変換するプロセスです。 
[抽象]モデルの匿名化は、見かけのキャプチャモデルが変更されるなど、これらのアーティファクトを変換するプロセスです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br><font color="black">2020-02-18</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-mode Core Tensor Factorization based Low-Rankness and Its
  Applications to Tensor Completion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_71.html">
      <font color="black">Multi-mode Core Tensor Factorization based Low-Rankness and Its
  Applications to Tensor Completion</font>
    </a>
  </h2>
  <font color="black">さらに、MCTFおよびNonMCTF正則化最小化問題を研究し、問題を解決するための効果的なBSUMアルゴリズムを設計しました。ハイパースペクトル画像（HSI）ノイズ除去、ビデオ補完、MRI復元を含む一連の実験により、提案された提案の優れたパフォーマンスが確認されました。方法。これは、いくつかの既知の入力に基づいて、本質的な低ランク構造のクリーンなデータを正確に復元できる最初の方法です。 
[要約]このメトリックは、一般的なコレクションの低ランクの洞察をエンコードします。mctfは、それがどの程度効果的であるかを調べる最初の方法をエンコードします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Instance Segmentation through Reasoning about Multi-Object
  Occlusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_72.html">
      <font color="black">Robust Instance Segmentation through Reasoning about Multi-Object
  Occlusion</font>
    </a>
  </h2>
  <font color="black">生成モデルを拡張して複数のオブジェクトを含め、困難な咬合シナリオで効率的な推論を行うためのフレームワークを導入します。KITTIINSTanceデータセット（KINS）と合成咬合データセットでの実験は、マルチオブジェクトでのモデルの有効性と堅牢性を示しています。オクルージョン下のインスタンスセグメンテーション..誤ったセグメンテーションを特定し、それらを修正するためにオクルージョンの順序を推定するオクルージョン推論モジュール（ORM）を導入します。 
[概要]私たちの仕事は、結合したオクルーダーへの神経機能の活性化の体系的なモデルを学習する構成ネットワークに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: A Sheaf and Topology Approach to Generating Local Branch Numbers in
  Digital Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_73.html">
      <font color="black">A Sheaf and Topology Approach to Generating Local Branch Numbers in
  Digital Images</font>
    </a>
  </h2>
  <font color="black">この論文は、トポロジーデータ分析（TDA）と層理論を組み合わせた理論的アプローチに関するものです。また、提案された理論を適用して、デジタル画像内のローカルオブジェクトのブランチ番号を特定できることを示します。永続性図（PD）は、マルチセット形式のPHの情報。 
[概要]イーサンデータ分析は、数学とコンピュータサイエンスの分野で注目を集めています。データの形状に関係し、多くの科学分野で効果的であることが証明されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-27">
        <br><font color="black">2020-11-27</font>
      </time>
    </span>
</section>
<!-- paper0: BasicVSR: The Search for Essential Components in Video Super-Resolution
  and Beyond -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_74.html">
      <font color="black">BasicVSR: The Search for Essential Components in Video Super-Resolution
  and Beyond</font>
    </a>
  </h2>
  <font color="black">このようなゲインがどのように得られるかを説明するために体系的な分析を行い、落とし穴について説明します。さらに、情報の集約を容易にするための情報補充メカニズムと結合された伝播スキームを提示することにより、BasicVSRの拡張性を示します。は、将来のVSRアプローチの強力なベースラインとして機能します。 
[概要]これらの複雑なコンポーネントが使用されるのはこれが初めてです。これらには、速度と復元品質の点で魅力的な改善を実現する簡潔なパイプラインであるbasicvsrが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Evolutionary NAS with Gene Expression Programming of Cellular Encoding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_75.html">
      <font color="black">Evolutionary NAS with Gene Expression Programming of Cellular Encoding</font>
    </a>
  </h2>
  <font color="black">ニューラルアーキテクチャ検索（NAS）のルネッサンスは、遺伝的アルゴリズム（GA）や遺伝的プログラミング（GP）などの古典的な方法が畳み込みニューラルネットワーク（CNN）アーキテクチャに利用されているのを見てきました。実験では、SLGEの有効性がアーキテクチャの発見に示されています。 CIFAR-10およびCIFAR-100画像分類タスクでの最先端の手作りCNNアーキテクチャのパフォーマンスを向上させます。より少ないGPUリソースを使用して既存のNASメソッドで競争力のある分類エラー率を達成します。これに対処するために、新しい生成エンコーディングスキーム-$ symbolic \ linear \ generative \ encoding $（SLGE）-シンプルでありながら強力なスキームを提示します。これは、線形固定長文字列の染色体にローカルグラフ変換を埋め込み、遺伝子発現プログラミングの進化的プロセスを介して、さまざまな形状とサイズのCNNアーキテクチャを開発します。 
[ABSTRACT] gaとgpには機能の複雑さが不足しており、cnn.cnnアーキテクチャのような大規模なアーキテクチャでは十分に拡張できません。より少ないgpuリソースを使用して、既存のnasメソッドで競争力のある分類エラー率を達成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-27">
        <br><font color="black">2020-05-27</font>
      </time>
    </span>
</section>
<!-- paper0: ThumbNet: One Thumbnail Image Contains All You Need for Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_76.html">
      <font color="black">ThumbNet: One Thumbnail Image Contains All You Need for Recognition</font>
    </a>
  </h2>
  <font color="black">そうすることで、ThumbNetは、大きな画像の元の入力ネットワークと同じように小さな画像でうまく機能する推論ネットワークを学習します。CNNの入力画像にはかなりの冗長性が含まれているという事実に基づいて、本論文では、統一されたフレームワークを提案します。 、ThumbNetと呼ばれ、1つのサムネイル画像で推論できるようにすることでCNNモデルを同時に加速および圧縮します。ThumbNetを使用すると、計算とメモリの要件を大幅に削減できるサムネイル入力推論ネットワークを取得できるだけでなく、一般的な分類タスクのサムネイル画像を生成できる画像ダウンスケーラー。 
[ABSTRACT]現在の作業は主に、システムの複雑さに対するサムネットの影響を無視して、パラメータまたはイーサンで発生する計算を減らすことによってネットワークを圧縮しようとしています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-10">
        <br><font color="black">2019-04-10</font>
      </time>
    </span>
</section>
<!-- paper0: Attribute-Guided Adversarial Training for Robustness to Natural
  Perturbations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_77.html">
      <font color="black">Attribute-Guided Adversarial Training for Robustness to Natural
  Perturbations</font>
    </a>
  </h2>
  <font color="black">この偏差は正確にはわからないかもしれませんが、その広範な特性は、属性の観点から事前に指定されています。iidではない目に見えないテストドメインで堅牢性が期待されるセットアップを検討します。テストドメインからのデータにアクセスすることなく、属性空間への分類器の露出を最大化するために、新しいサンプルを生成することを学習する敵対的なトレーニングアプローチを提案します。 
[概要]小さなサンプルを生成するための敵対的学習アプローチを提案します。敵対的トレーニングは、3種類の摂動に焦点を当てています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Reliable Model Compression via Label-Preservation-Aware Loss Functions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_78.html">
      <font color="black">Reliable Model Compression via Label-Preservation-Aware Loss Functions</font>
    </a>
  </h2>
  <font color="black">これに対抗するために、教師と生徒の学習パラダイムを使用してラベルをより適切に保存するフレームワークを提示します。8つの異なる実世界のセットを使用して、複数の圧縮スキームと精度回復アルゴリズムに対するアプローチの有効性を定量的および定性的に示します。ネットワークアーキテクチャ..損失関数に対する追加の用語の役割を調査し、関連するパラメータを自動的に調整する方法を示します。 
[概要]モデル圧縮の目標は、大規模な参照ニューラルネットワークを取得し、参照と機能的に同等の、より小さく安価な圧縮ネットワークを出力することです。ただし、圧縮により、ラベルにかなりの不一致が生じる可能性があることが確認されています。参照モデルと圧縮モデルによって生成され、バイアスと信頼性の低下をもたらします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Backdoor Attacks on the DNN Interpretation System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_79.html">
      <font color="black">Backdoor Attacks on the DNN Interpretation System</font>
    </a>
  </h2>
  <font color="black">信頼できないソースによって開発されたディープラーニングモデルを展開する場合、攻撃が深刻なセキュリティ脅威となることを示します。2種類の攻撃を設計します。顕著性マップの特定の変更を強制する標的型攻撃と、上位ピクセルの重要度スコアが高い場合の非標的型攻撃です。元の顕著性マップから大幅に削減されます。さまざまな深層学習アーキテクチャの勾配ベースおよび勾配のない解釈方法に対して、提案されたバックドア攻撃の経験的評価を実行します。 
[要約]顕著性マップは、深いモデルをトレーニングするために使用される目的関数のペナルティ項に組み込まれ、モデルトレーニングへの影響はトリガーの存在を条件とします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-21">
        <br><font color="black">2020-11-21</font>
      </time>
    </span>
</section>
<!-- paper0: DeepVideoMVS: Multi-View Stereo on Video with Recurrent Spatio-Temporal
  Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_80.html">
      <font color="black">DeepVideoMVS: Multi-View Stereo on Video with Recurrent Spatio-Temporal
  Fusion</font>
    </a>
  </h2>
  <font color="black">目新しさは、タイムステップ間の視点の変化を考慮して、セルの隠れた状態を伝播することにあります。その結果、評価されたメトリックのほとんどで、既存の最先端のマルチビューステレオメソッドよりも優れています。リアルタイムのパフォーマンスを維持しながら、屋内シーンの画像を作成します。特定のタイムステップで、以前の深度予測を使用して、以前の非表示状態を現在のカメラ平面にワープします。 
[概要]私たちのアプローチのバックボーンは、実際の-メトリックエンコーダー-デコーダーです。画像のペアから計算されたコストボリュームに依存しています。目新しさは、セルの隠された状態を伝播することにあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: How to Exploit the Transferability of Learned Image Compression to
  Conventional Codecs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_81.html">
      <font color="black">How to Exploit the Transferability of Learned Image Compression to
  Conventional Codecs</font>
    </a>
  </h2>
  <font color="black">画像は、学習したフィルターによって変更され、さまざまなパフォーマンス測定値または特定のタスクに最適化されます。この目標の可能な方法として、この作業では、学習した画像コーディングを代理として使用して、画像を最適化する方法を提案および調査します。エンコード用の画像..理想的には、既存の従来のコーデックをそのままにしておく必要があります。これにより、より迅速な採用とバランスの取れた計算エンベロープへの準拠が保証されます。 
[概要]画像を最適化するための代理として画像を使用するのはこれが初めてです。この作業では、学習画像コーディングを使用して選択した画像を最適化する方法を提案および調査します。これは、の代替として使用できます。画像の代理</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Motion-based Camera Localization System in Colonoscopy Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_82.html">
      <font color="black">Motion-based Camera Localization System in Colonoscopy Videos</font>
    </a>
  </h2>
  <font color="black">本研究では、カメラのおおよその解剖学的位置を推定し、カメラが存在する解剖学的結腸セグメントを分類するカメラ位置特定システムを提案しました。推定位置インデックスに基づいて、結腸テンプレートを作成することにより解剖学的結腸セグメント分類を実行しました。結腸鏡検査の自動評価は、結腸鏡検査所見の定性的な人間の解釈に存在する主観性を考慮すると興味深いものです。 
[ABSTRACT]大腸内視鏡検査は、所見の意味とコンテキストを推測する際に考慮すべき重要な要素です。カメラのローカリゼーションシステムは、カメラの動き情報のないフレームを削除するための非情報フレーム検出から始まります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Identifying Mislabeled Data using the Area Under the Margin Ranking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_83.html">
      <font color="black">Identifying Mislabeled Data using the Area Under the Margin Ranking</font>
    </a>
  </h2>
  <font color="black">このアプローチは、合成データセットと実世界のデータセットに関する以前の作業を一貫して改善します。WebVision50分類タスクでは、この方法でトレーニングデータの17％が削除され、テストエラーが1.6％（絶対）改善されます。アルゴリズムの中心は次のとおりです。 Area Under the Margin（AUM）統計。これは、クリーンなサンプルと誤ってラベル付けされたサンプルのトレーニングダイナミクスの違いを利用します。 
[要約]簡単な手順-意図的に誤ってラベル付けされたしきい値サンプルが入力されたクラスを追加する-誤ってラベル付けされたデータを学習する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-28">
        <br><font color="black">2020-01-28</font>
      </time>
    </span>
</section>
<!-- paper0: SAFCAR: Structured Attention Fusion for Compositional Action Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_84.html">
      <font color="black">SAFCAR: Structured Attention Fusion for Compositional Action Recognition</font>
    </a>
  </h2>
  <font color="black">そのために、アクションの時系列構造をキャプチャするオブジェクト検出からの情報と、コンテキスト情報をキャプチャする視覚的な手がかりを組み合わせる、新しい構造化注意融合（SAF）自己注意メカニズムを開発およびテストします。私たちのアプローチは、現在の最先端システムよりも効果的に新しい動詞-名詞構成を認識し、いくつかのラベル付きの例から非常に効率的に目に見えないアクションカテゴリに一般化します。ただし、構成性は、活用できる構造も提供します。 
[概要]私たちのアプローチは、新しい動詞を認識することを示しています-名詞は、現在の最先端のシステムよりも効果的に断片化されています。いくつかのラベル付きの例から、目に見えないアクションカテゴリに非常に効率的に一般化されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Hyperbolic Representations for Unsupervised 3D Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_85.html">
      <font color="black">Learning Hyperbolic Representations for Unsupervised 3D Segmentation</font>
    </a>
  </h2>
  <font color="black">また、階層的なトリプレット損失とマルチスケールパッチサンプリングスキームを導入して、さまざまなレベルの粒度にまたがる関係を埋め込みます。特に注釈機能が制限されている場合や新しいカテゴリの発見が必要な場合は、複雑なボリュームデータに教師なし3Dセグメンテーションが必要です。 ..階層的なおもちゃのデータセット、BraTSの全腫瘍データセット、および極低温電子顕微鏡データで、教師なし3Dセグメンテーションに対する双曲線表現の有効性を示します。 
[概要]双曲線潜在空間と提案されたジャイロ平面畳み込み層を備えた変分オートエンコーダー（vae）を介して、教師なしセグメンテーションの3Dパッチの効果的な表現を学習することを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: 3D-NVS: A 3D Supervision Approach for Next View Selection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_86.html">
      <font color="black">3D-NVS: A 3D Supervision Approach for Next View Selection</font>
    </a>
  </h2>
  <font color="black">合成画像と実画像の詳細な実験を通じて提案された方法の有効性を示し、既存の最先端の3D再構成および次善のビュー予測技術よりも改善された再構成品質をどのように提供するかを示します。提案されたアプローチはエンドツーエンドでトレーニング可能です。そして、受動的に取得された2Dビューのペアで可能な限り最高の3D再構成品質を取得することを目指しています。次に最適なビュー選択のための分類ベースのアプローチを提示し、このタスクの監視信号をもっともらしく取得する方法を示します。 
[概要]提案されたモデルは、受動的に取得された3Dビューのペアを使用して、可能な限り最高の3D再構成品質を得ることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Feature Learning by Cross-Level Instance-Group
  Discrimination -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_87.html">
      <font color="black">Unsupervised Feature Learning by Cross-Level Instance-Group
  Discrimination</font>
    </a>
  </h2>
  <font color="black">各インスタンスの不変マッピングは、拡張ビュー内のアトラクションによって課されますが、インスタンス間の類似性は、インスタンスグループに対する一般的な反発から生じます。インスタンス間の自然な類似性は、推定されるインスタンスの区別と競合し、不安定なトレーニングとパフォーマンスの低下を引き起こします。ワイズおよびクロスビューの比較は、対照学習の正/負のサンプル比を大幅に改善し、より優れた不変マッピングを実現します。 
[概要]私たちのアイデアは、インスタンスの類似性を発見し、インスタンスのグループ化によって直接ではなく、インスタンスとローカルインスタンスグループ間のクロスレベルの識別（cld）によって、対照的な学習に統合することです。自己の新しい最先端技術に追加します。監督、世界、および転移学習のベンチマーク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-09">
        <br><font color="black">2020-08-09</font>
      </time>
    </span>
</section>
<!-- paper0: Impact of Thermal Throttling on Long-Term Visual Inference in a
  CPU-based Edge Device -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_88.html">
      <font color="black">Impact of Thermal Throttling on Long-Term Visual Inference in a
  CPU-based Edge Device</font>
    </a>
  </h2>
  <font color="black">結果は、ヒステリシスベースのアクティブ冷却がすべての場合に熱スロットリングを防止し、それによって冷却なしと比較してスループットを最大約90％向上させることを示しています。これは、アクティブ冷却を適用できない場合に周囲温度が重要なパラメータであることを示しています。研究は、安定した屋内条件下で、低コストのエッジプラットフォーム、つまりRaspberry Pi 4B（RPi4B）で実施されました。 
[概要]この調査は、コンピューターシステムで80の異なるケースを分析することによって行われました。ヒステリシスベースのアクティブ冷却により、すべてのケースで熱スロットリングが防止されました。結果は、cnnモデルとソフトウェアコンポーネントの適切な選択の重要性を強調しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Transfer Visual Effects from Videos to Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_89.html">
      <font color="black">Learning to Transfer Visual Effects from Videos to Images</font>
    </a>
  </h2>
  <font color="black">2番目の課題に対処するために、制約のないピクセル値を予測するのではなく、モデルが前のフレームから既存の画像ピクセルを移動することのみを許可します。客観的および主観的な設定でメソッドを評価し、非定型変換を受けているオブジェクトを示す興味深い定性的結果を示します。 、顔を溶かしたり、鹿を咲かせたりするなど。最初の課題に対処するために、5つの損失関数を評価します。最も有望なものは、生成されたアニメーションがソースビデオと同様のオプティカルフローとテクスチャモーションを持つことを奨励します。 
[概要]視覚効果の転送の課題には、抽出したい効果をキャプチャする方法が含まれます。また、コンテンツや芸術的なスタイルではなく、効果のみがソースビデオから入力画像に転送されるようにすることも目指しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Basis Prediction Networks for Effective Burst Denoising with Large
  Kernels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_90.html">
      <font color="black">Basis Prediction Networks for Effective Burst Denoising with Large
  Kernels</font>
    </a>
  </h2>
  <font color="black">これにより、比較的大きなノイズ除去カーネルを効果的に活用し、品質の大幅な向上（1dB PSNR以上）と最先端の方法よりも高速な実行時間を実現できます。この目的のために、新しい基底予測ネットワークを導入します。入力バーストが与えられると、画像内で共有されるグローバルベースカーネルのセットと、個々のピクセルに固有の対応する混合係数を予測します。画像のバーストは、時間と空間の両方で有意な自己類似性を示します。 
[概要]これにより、オサマビンの表現が動機付けられます。ピクセルあたりのガラスの数を制限する代わりに、予測することができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-09">
        <br><font color="black">2019-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Graph-SIM: A Graph-based Spatiotemporal Interaction Modelling for
  Pedestrian Action Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_91.html">
      <font color="black">Graph-SIM: A Graph-based Spatiotemporal Interaction Modelling for
  Pedestrian Action Prediction</font>
    </a>
  </h2>
  <font color="black">これらの課題に動機付けられて、1）横断歩道の動作を予測するための新しいグラフベースのモデルを提案します。この論文の公開時に、データセットが公開されます。都市部の自律型車両にとって最も重要でありながら挑戦的なタスクの1つ環境は、特に横断歩道で、近くの歩行者の将来の行動を予測しています。 
[概要]私たちの方法は、近くの道路利用者との歩行者の相互作用をモデル化します。新しいデータは、既存の方法と比較してさまざまな指標を10％以上改善することにより、最先端のパフォーマンスを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Prototype Trees for Interpretable Fine-grained Image Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_92.html">
      <font color="black">Neural Prototype Trees for Interpretable Fine-grained Image Recognition</font>
    </a>
  </h2>
  <font color="black">画像内のこのプロトタイプの有無によって、ノードを介したルーティングが決まります。したがって、意思決定は人間の推論に似ています。鳥の喉は赤いですか。アンサンブルとプルーニングを使用して、精度と解釈可能性のトレードオフを調整します。 
[ABSTRACT]ニューラルプロトタイプツリー（prototree）は、モデル全体を忠実に視覚化するために、解釈可能な決定木にプロトタイプを含める深層学習手法です。説明サイズを縮小し、解釈可能性を向上させるように設計されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Generalized Object Detection on Fisheye Cameras for Autonomous Driving:
  Dataset, Representations and Baseline -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_93.html">
      <font color="black">Generalized Object Detection on Fisheye Cameras for Autonomous Driving:
  Dataset, Representations and Baseline</font>
    </a>
  </h2>
  <font color="black">物体検出は、自動運転で包括的に研究された問題です。これは、自動運転シナリオの魚眼カメラでの物体検出に関する最初の詳細な研究です。また、ポリゴン頂点を取得するための曲率適応境界サンプリング方法を設計します。均一なサンプリングと比較して、相対的なmAPスコアが4.9％向上します。 
[概要]このプロジェクトは、さらなる研究を促進するために公開されました。魚眼画像でオブジェクトを検出するためのバウンディングボックス、楕円、および汎用ポリゴンが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: The Tsetlin Machine -- A Game Theoretic Bandit Driven Approach to
  Optimal Pattern Recognition with Propositional Logic -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_94.html">
      <font color="black">The Tsetlin Machine -- A Game Theoretic Bandit Driven Approach to
  Optimal Pattern Recognition with Propositional Logic</font>
    </a>
  </h2>
  <font color="black">5つのベンチマークで、Tsetlin Machineは、SVM、ディシジョンツリー、ランダムフォレスト、ナイーブベイズ分類器、ロジスティック回帰、ニューラルネットワークと比較して競争力のある精度を提供します。これは、ローカル最適化なしで、グローバル最適化のみによる学習に変換されます。メモリとしての単一の整数であり、増分および減分操作を通じて確率的環境での最適なアクションを学習します。 
[概要] tsetlinオートマトンは、命題式を使用して複雑なパターン認識の問題を解決します。これは、tsetlinオートマトンの集合で構成され、パフォーマンスを排除します。これは、神経最適化なしで、グローバルな最適化のみを学習することを意味します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-04-04">
        <br><font color="black">2018-04-04</font>
      </time>
    </span>
</section>
<!-- paper0: Image inpainting using frequency domain priors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_95.html">
      <font color="black">Image inpainting using frequency domain priors</font>
    </a>
  </h2>
  <font color="black">この目的のために、ネットワークが高周波成分を選択的に再構築しながらグローバルコンテキストを学習できるようにする周波数ベースのデコンボリューションモジュールを提案します。しかし、これらの方法は依然として実際の複雑なシーンの高周波の詳細を再構築するのに苦労し、色、境界アーティファクト、歪んだパターン、ぼやけたテクスチャの不一致。公開されているデータセットCelebA、Paris Streetview、およびDTDテクスチャデータセットで提案された方法を評価し、現在の最先端の方法よりも優れていることを示します。質的および量的に画像修復技術。 
[ABSTRACT]以前の作業では、空間ドメイン情報のみを使用してニューラルネットワークをトレーニングすることにより、欠落しているピクセルを予測します。公開されているデータセットceleba、paris streetview、textureデータセットで提案された方法を評価します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: SSN: Soft Shadow Network for Image Compositing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_96.html">
      <font color="black">SSN: Soft Shadow Network for Image Compositing</font>
    </a>
  </h2>
  <font color="black">SSNは2Dオブジェクトマスクを入力として受け取るため、絵画やベクターアートなどの画像タイプに依存しません。SSNは、周囲閉塞予測モジュールを使用して中間周囲閉塞マップを予測します。これは、ユーザーがさらに洗練して幾何学的な手がかりを提供できます。シャドウの生成を調整します。モデルがリアルなソフトシャドウをリアルタイムで生成することを示します。 
[ABSTRACT] ssnは、アンビエントオクルージョン予測モジュールを組み合わせて、中間のアンビエントオクルージョンマップを予測します。これは、ユーザーがさらに洗練して、影の生成を調整するための幾何学的な手がかりを提供できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Object-Driven Active Mapping for More Accurate Object Pose Estimation
  and Robotic Grasping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_97.html">
      <font color="black">Object-Driven Active Mapping for More Accurate Object Pose Estimation
  and Robotic Grasping</font>
    </a>
  </h2>
  <font color="black">定量的評価は、提案されたフレームワークが非常に高いマッピング精度を持っていることも示しています。オブジェクトの把握、オブジェクトの配置、拡張現実などの操作実験は、提案されたフレームワークの有効性と利点を大幅に示しています。オブジェクトをターゲットにしてポーズ推定の精度を高めるために、オブジェクトマッピングプロセスをガイドするオブジェクト駆動型の探索戦略も設計します。 
[概要]フレームワークは、同時マルチオブジェクトポーズ推定プロセスと統合されたオブジェクトスラムシステム上に構築されています。プロジェクトは、マッピングモジュールと探索戦略に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: AutoTune: Automatically Tuning Convolutional Neural Networks for
  Improved Transfer Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_98.html">
      <font color="black">AutoTune: Automatically Tuning Convolutional Neural Networks for
  Improved Transfer Learning</font>
    </a>
  </h2>
  <font color="black">ソースコードはhttps://github.com/JekyllAndHyde8999/AutoTune_CNN_TransferLearningで入手できます。提案されたAutoTuneメソッドによって得られた分類結果は、$ 95.92 \％$、$ 86.54 \％$を達成することにより、3つのデータセットで標準のベースライン転送学習メソッドよりも優れています。 、およびCalTech-101、CalTech-256、およびStanfordDogsに対してそれぞれ$ 84.67 \％$の精度。事前にトレーニングされたCNNレイヤーは、ベイジアン最適化を使用してターゲットデータからの知識で調整されます。 
[概要] caltech-101、caltech-256、caltech、256、およびスタンフォード犬はオートプシーであることが示されています。新しい方法は、ベースcnnモデルの多数のコースに基づいています。畳み込みニューラルを自動的に調整するように設計されています。より良い転移学習のためのネットワーク（cnn）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-25">
        <br><font color="black">2020-04-25</font>
      </time>
    </span>
</section>
<!-- paper0: Visualization of Supervised and Self-Supervised Neural Networks via
  Attribution Guided Factorization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_99.html">
      <font color="black">Visualization of Supervised and Self-Supervised Neural Networks via
  Attribution Guided Factorization</font>
    </a>
  </h2>
  <font color="black">アルゴリズムは、ローカル属性によって導かれる方法で、ピクセルごとのローカル影響を逆投影しますが、そうでなければ説明にバイアスをかける顕著な特徴を修正します。広範な一連の実験で、私たちの方法の能力を実証します。予測されたラベルだけでなく、クラス固有の視覚化。驚くべきことに、このメソッドは、勾配ベースのメソッドに一般的に適用されるベンチマークと、主に帰属メソッドの評価に使用されるベンチマークで最先端の結果を取得します。 
[ABSTRACT]たとえば、私たちのメソッドは、結果の名前に最も影響を与える領域を強調表示するのに効果的です。たとえば、現在、さまざまなタイプの視覚化に基づいています。このメソッドは、自己教師ありメソッドが意味情報を学習することを示すのにも成功しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Progressively Volumetrized Deep Generative Models for Data-Efficient
  Contextual Learning of MR Image Recovery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_100.html">
      <font color="black">Progressively Volumetrized Deep Generative Models for Data-Efficient
  Contextual Learning of MR Image Recovery</font>
    </a>
  </h2>
  <font color="black">ここでは、複雑な体積画像回復タスクを個々の直線次元にわたる一連のより単純な断面タスクに分解する、新しいデータ効率の高い漸進的体積化生成モデル（ProvoGAN）を紹介します。複雑性の低い断面モデルは学習行動を改善します。それでも、ボリュームの縦方向の寸法全体のコンテキスト情報を無視します。磁気共鳴イメージング（MRI）は、多数の組織コントラストの下で特定の解剖学的ボリュームをイメージングする柔軟性を提供します。 
[ABSTRACT]スキャン時間の考慮事項により、MRIデータの品質と多様性に厳しい制限が課せられます。克服するために、provoganはグローバルなコンテキストを効果的にキャプチャし、細かい構造の詳細を回復します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-27">
        <br><font color="black">2020-11-27</font>
      </time>
    </span>
</section>
<!-- paper0: Is Each Layer Non-trivial in CNN? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CV/paper_101.html">
      <font color="black">Is Each Layer Non-trivial in CNN?</font>
    </a>
  </h2>
  <font color="black">ただし、ネットワークでは各レイヤーは重要ですか？畳み込みカーネルはネットワークのコアですが、ResNetではそれらのいくつかが些細で規則的であることを示しています。実験結果をベースラインと比較し、同様または同じパフォーマンスに到達できることを示しました。 
[概要] resnetの登場により、実際に使用されるネットワークはますます深くなり、広くなっています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-09">
        <br><font color="black">2020-09-09</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: German's Next Language Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_0.html">
      <font color="black">German's Next Language Model</font>
    </a>
  </h2>
  <font color="black">トレーニング済みモデルは、研究コミュニティに公開されます。これらのモデルのトレーニングでは、評価主導型のアプローチを採用しています。結果は、データの追加とWWMの利用の両方により、モデルのパフォーマンスが向上することを示しています。既存のドイツのモデルに対してベンチマークを行うことで、これらのモデルがこれまでで最高のドイツのモデルであること。 
[概要]ベースモデルとラージサイズの両方のモデルについて、一連のドキュメントトレーニングと固有表現抽出（ner）タスク全体でsotaパフォーマンスを達成することができました。既存のモデルに対するベンチマークを使用して、これらのモデルがドイツの最高のモデルであることを示します。日付</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Question Answering over Knowledge Bases by Leveraging Semantic Parsing
  and Neuro-Symbolic Reasoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_1.html">
      <font color="black">Question Answering over Knowledge Bases by Leveraging Semantic Parsing
  and Neuro-Symbolic Reasoning</font>
    </a>
  </h2>
  <font color="black">知識ベースの質問応答（KBQA）は、自然言語処理の重要なタスクです。セマンティック解析、エンティティリンク、および関係リンク）、エンドツーエンドのトレーニングデータを必要としません。NSQAは最先端のパフォーマンスを実現します。 QALD-9およびLC-QuAD1.0で。 
[概要]新しいアプローチには、複雑な質問の理解、理由の必要性、大規模なトレーニングデータセットの欠如が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Unsupervised Neural Machine Translation with Adversarial
  Denoising Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_2.html">
      <font color="black">Robust Unsupervised Neural Machine Translation with Adversarial
  Denoising Training</font>
    </a>
  </h2>
  <font color="black">この論文では、UNMTベースのシステムのロバスト性を改善するために、初めてノイズの多いデータを明示的に考慮します。いくつかの言語ペアでの実験結果は、提案された方法がノイズの多いシナリオで従来のUNMTシステムのロバスト性を大幅に改善したことを示しています。ほとんどの研究では、UMNTは、ノイズの多いデータに対するロバスト性を考慮せずに、クリーンなデータでトレーニングされています。 
[概要] unmtシステムは、入力文の小さな摂動に敏感です。これらには、単語ノイズ、単語ノイズ、語順ノイズが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-28">
        <br><font color="black">2020-02-28</font>
      </time>
    </span>
</section>
<!-- paper0: GottBERT: a pure German Language Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_3.html">
      <font color="black">GottBERT: a pure German Language Model</font>
    </a>
  </h2>
  <font color="black">GottBERTは、fairseqを使用して元のRoBERTaモデルに関連して事前トレーニングされました。すべてのダウンストリームタスクは、ドイツのBERTのベンチマークから取得されたハイパーパラメータプリセットを使用してトレーニングされました。GottBERTは、RoBERTaBASEアーキテクチャを使用して256コアTPUポッドで正常に事前トレーニングされました。 
[概要]新しい調査によると、多言語モデルは単一言語モデルよりも劣っています。オスカーデータセットのドイツ語部分がテキストコーパスとして使用されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Do We Really Need That Many Parameters In Transformer For Extractive
  Summarization? Discourse Can Help ! -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_4.html">
      <font color="black">Do We Really Need That Many Parameters In Transformer For Extractive
  Summarization? Discourse Can Help !</font>
    </a>
  </h2>
  <font color="black">よりバランスの取れたハイパーパラメータ設定を適用すると、文レベルで8ヘッドトランスフォーマーモデルをさらに大幅に上回り、必要なパラメーターが1桁少なくなります。元のシングルヘッドトランスフォーマーモデルと比較すると、ツリーアテンションアプローチは同様のパフォーマンスに達します。アテンションコンポーネントのパラメータが大幅に削減されているにもかかわらず、EDUレベルとセンテンスレベルの両方で..ツリーの自己アテンションアプローチが抽出要約のタスクで競争力のあるROUGEスコアを達成するという経験的結果を示します。 
[ABSTRACT]新しいツリーの自己-注意はドキュメントレベルの談話情報に基づいています。これは、最近提案された「合成」フレームワークを別の軽量な代替手段で拡張します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Accurate Word Alignment Induction from Neural Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_5.html">
      <font color="black">Accurate Word Alignment Induction from Neural Machine Translation</font>
    </a>
  </h2>
  <font color="black">主なアイデアは、アライメントされるターゲットトークンが前の作業のようにデコーダー出力ではなくデコーダー入力である場合のステップでアライメントを誘導することです。Shift-Attは、Transformerのアテンションウェイトからアライメントを誘導する解釈方法です。パラメータの更新やアーキテクチャの変更は必要ありません。Shift-AETは、Transformerに緊密に統合され、対称化されたShift-Attアライメントからの監視とは別にトレーニングされた、追加のアライメントモジュールからアライメントを抽出します。 
[概要]主な位置合わせ方法shift-attは、transformer.aetの注意の重みから位置合わせを誘導する解釈方法です。aetはgizaを1.4〜4.8エアポイント上回っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: Bengali Abstractive News Summarization(BANS): A Neural Attention
  Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_6.html">
      <font color="black">Bengali Abstractive News Summarization(BANS): A Neural Attention
  Approach</font>
    </a>
  </h2>
  <font color="black">この記事では、エンコーダーデコーダーに注目したseq2seqベースの長短期記憶（LSTM）ネットワークモデルを紹介しました。また、bangla.bdnews24.com1から収集した19kを超える記事と対応する人間が書いた要約のデータセットを準備しました。これは、これまでベンガル語のニュース文書を要約するための最も広範なデータセットであり、Kaggle2で公開されています。これは、BANSの最先端のアプローチにより、人間の評価スコアの点で大幅な改善を示しました。 
[概要]過去の研究のほとんどは、抽出要約アプローチで行われています。システムは、生成された文のように、明快で人間的な単語の長いシーケンスを生成するローカル注意ベースのモデルを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Inverse Visual Question Answering with Multi-Level Attentions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_7.html">
      <font color="black">Inverse Visual Question Answering with Multi-Level Attentions</font>
    </a>
  </h2>
  <font color="black">この論文では、逆視覚的質問応答に対処するための新しい深いマルチレベル注意モデルを提案します。これは、複数の一般的に使用されるメトリックの観点から最先端のパフォーマンスを示します。提案されたモデルをVQAV1で評価します。データセット。 
[ABSTRACT]提案されたモデルは、地域の視覚的および意味的特徴を生成します。次に、注意メカニズムを使用して、回答キューでそれらを強化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-17">
        <br><font color="black">2019-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Explaining Structures Improve NLP Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_8.html">
      <font color="black">Self-Explaining Structures Improve NLP Models</font>
    </a>
  </h2>
  <font color="black">提案されたモデルには、次のメリットがあります。（1）スパンの重みにより、モデルが自己説明可能になり、解釈のために追加のプロービングモデルが不要になります。 （2）提案されたモデルは一般的であり、NLPの既存の深層学習構造に適合させることができます。 （3）各テキストスパンに関連付けられた重みは、フレーズや文などの高レベルのテキストユニットの直接的な重要度スコアを提供します。解釈可能性がパフォーマンスを犠牲にしないことを初めて示します。自己の神経モデル機能を説明すると、自己説明的な性質がなくても、対応する機能よりも優れたパフォーマンスが得られ、SST-5で59.1の新しいSOTAパフォーマンス、SNLIで92.3の新しいSOTAパフォーマンスが達成されます。このレイヤーは、各テキストスパンの情報を集約します。特定の重みに関連付けられ、それらの重み付きの組み合わせは、最終的な予測のためにsoftmax関数に送られます。 
[概要] nlpの深層学習モデルが効果的であると考えられます。このレイヤーは各テキストスパンの情報を集約し、それが特定の重みに関連付けられ、それらの重み付きの組み合わせがsalのsoftmaxモデルに供給されます。これらのモデルは次のとおりです。解釈がどれだけ機能するかを説明することはできませんが、このモデルはそれ以上のコミュニケーションを必要としません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: BERT-hLSTMs: BERT and Hierarchical LSTMs for Visual Storytelling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_9.html">
      <font color="black">BERT-hLSTMs: BERT and Hierarchical LSTMs for Visual Storytelling</font>
    </a>
  </h2>
  <font color="black">トランスフォーマーベースのBERTを使用して、文と単語の埋め込みを取得します。この問題に取り組むために、文レベルと単語レベルのセマンティクスを別々にモデル化する新しい階層型ビジュアルストーリーテリングフレームワークを提案します。次に、階層型LSTMネットワークを採用します。下部のLSTMは、画像に対応する文間の依存関係を学習するために、BERTから文のベクトル表現を入力として受け取り、上部のLSTMは、下部のLSTMからの入力を取得して、対応する単語のベクトル表現を生成します。 
[概要]視覚的なストーリーテリングアプローチは、単語レベルのシーケンス生成方法を使用し、文レベルの依存関係を適切に考慮していないため、一貫性に欠けています。トランスフォーマーベースのバートを使用して、文と単語の埋め込みを取得します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Saying No is An Art: Contextualized Fallback Responses for Unanswerable
  Dialogue Queries -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_10.html">
      <font color="black">Saying No is An Art: Contextualized Fallback Responses for Unanswerable
  Dialogue Queries</font>
    </a>
  </h2>
  <font color="black">今日のダイアログシステムは、「その質問に対する答えがわからない」や「それについてはよくわからない」などの静的で不自然な応答に依存していますが、ユーザーが状況に応じて応答を生成するニューラルアプローチを設計していますこのようなダイアログシステムは、ダイアログシステムの範囲内で応答できないドメイン外または新規のユーザークエリに応答するために、フォールバックメカニズムに依存する必要があります。依存関係の解析に対するルールの使用と、質問と応答のペアの合成データを微調整したテキストからテキストへの変換により、関連性が高く、文法的で多様な質問が生成されます。 
[概要]システムの有効性を実証するために、自動および手動の評価を実行します。自動を実行します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Federated Learning with Diversified Preference for Humor Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_11.html">
      <font color="black">Federated Learning with Diversified Preference for Humor Recognition</font>
    </a>
  </h2>
  <font color="black">したがって、特定のパッセージは、さまざまな読者によってさまざまな程度で面白いと見なすことができます。ユーモアを理解することは、人間とAIの相互作用における多くのアプリケーションでの創造的な言語モデリングにとって重要です。広範な実験は、人々のユーモアの内容を正確に認識することにおけるFedHumorの重要な利点を示しています。 9つの最先端のユーモア認識アプローチと比較して多様なユーモアの好みがあります。 
[概要]巧妙なテキスト認識でユーモアを考えることは非常に主観的である可能性があります。これにより、多様なユーモアの好みに適応できるユーモラスなテキスト認識モデルのトレーニングが可能になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Multilingual Neural RST Discourse Parsing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_12.html">
      <font color="black">Multilingual Neural RST Discourse Parsing</font>
    </a>
  </h2>
  <font color="black">実験結果は、両方の方法が限られたトレーニングデータでも効果的であり、すべてのサブタスクで言語間、ドキュメントレベルの談話解析で最先端のパフォーマンスを達成することを示しています。ただし、他の言語の解析タスク注釈付きデータが不足しているため、ドイツ語、オランダ語、ポルトガル語は依然として困難です。テキスト談話の構文解析は、自然言語での情報の流れと議論の構造を理解する上で重要な役割を果たします。 
[概要]これまでの研究は、主に英語のツリーバンクからモデルを導き出し、評価することに焦点を当てていました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Drugs4Covid: Drug-driven Knowledge Exploitation based on Scientific
  Publications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_13.html">
      <font color="black">Drugs4Covid: Drug-driven Knowledge Exploitation based on Scientific
  Publications</font>
    </a>
  </h2>
  <font color="black">薬物と疾患は、それぞれATC分類とMeSHカテゴリに従って識別されます。薬物のオープンカタログが作成され、結果は薬物ブラウザ、キーワードガイド付きテキストエクスプローラー、およびナレッジグラフを通じて公開されます。Drugs4Covidは単語を組み合わせます大規模な医学文献の薬物指向の探索を可能にするための埋め込み技術とセマンティックWebテクノロジー。 
[概要] drugs4covidは、単語埋め込み技術とセマンティックWebテクノロジーを組み合わせて、薬物関連の探索を可能にします。6万件を超える記事と2vidがコードから処理されました-19コーパスとcovidの情報</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Dual Attention Model for Citation Recommendation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_14.html">
      <font color="black">Dual Attention Model for Citation Recommendation</font>
    </a>
  </h2>
  <font color="black">本研究では、「引用推奨のための二重注意モデル（DACR）」と呼ばれる新しい埋め込みベースのニューラルネットワークを提案し、原稿の準備中に引用を推奨します。ニューラルネットワークは、3つの入力の埋め込み間の類似性を最大化するように設計されています（ローカルコンテキストの単語、セクション、構造コンテキスト）、およびコンテキストに表示されるターゲット引用..指数関数的に増加する学術論文に基づいて、包括的で適切なリソースを見つけて引用することは重要な作業になりました。 
[概要]私たちの方法は、学術論文に十分な引用を推奨するのに適しています。新しい方法は、非社会的情報の3つの次元を使用します。これらには、ローカルコンテキスト、構造コンテキスト、およびユーザーが作業しているセクションの単語が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-01">
        <br><font color="black">2020-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: CL-IMS @ DIACR-Ita: Volente o Nolente: BERT does not outperform SGNS on
  Semantic Change Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_15.html">
      <font color="black">CL-IMS @ DIACR-Ita: Volente o Nolente: BERT does not outperform SGNS on
  Semantic Change Detection</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、語彙の意味変化検出でBERT埋め込みを活用する堅牢な方法を見つけることができなかったことを示しています。SemEval-2020タスク1の英語データセットのパラメーターを調整して高性能に到達しましたが、これはイタリア語に変換されません。 DIACR-Itaデータセット.. $。72 $の精度で、時点と公式ランキングのランク5（8）の間のトークンベースのBERT埋め込みの平均ペアワイズ距離を活用します。 
[概要]トークンベースのbertembedddingsの平均ペアワイズ距離を利用します。公式ランキングで$の精度で5（8）にランク付けします。 72ドル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-14">
        <br><font color="black">2020-11-14</font>
      </time>
    </span>
</section>
<!-- paper0: Circles are like Ellipses, or Ellipses are like Circles? Measuring the
  Degree of Asymmetry of Static and Contextual Embeddings and the Implications
  to Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_16.html">
      <font color="black">Circles are like Ellipses, or Ellipses are like Circles? Measuring the
  Degree of Asymmetry of Static and Contextual Embeddings and the Implications
  to Representation Learning</font>
    </a>
  </h2>
  <font color="black">静的埋め込みとBERTなどのコンテキスト埋め込みの両方を研究します。BERTの非対称性の評価は、埋め込みの動的な性質のため、一般に困難です。したがって、BERTの条件付き確率（言語モデルとして）を多数使用して調査します。理論的に正当なベイズ非対称スコアを導出するためのウィキペディアのコンテキスト。 
[概要]埋め込みを評価する方法は、埋め込みの動的な性質のために一般的に困難です。これは、コンテキスト埋め込みが静的埋め込みよりもランダム性を示すことを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: DialogBERT: Discourse-Aware Response Generation via Learning to Recover
  and Rank Utterances -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_17.html">
      <font color="black">DialogBERT: Discourse-Aware Response Generation via Learning to Recover
  and Rank Utterances</font>
    </a>
  </h2>
  <font color="black">このようなトークンレベルのエンコーディングは、発話間の談話レベルの一貫性の調査を妨げます。3つのマルチターン会話データセットでの実験は、定量的評価の点で、私たちのアプローチがBARTやDialoGPTなどのベースラインを著しく上回っていることを示しています。 DialogBERTは、以前のPLMベースの対話モデルを強化する新しい会話応答生成モデルです。 
[要約]人間の評価は、会話のコンテキストがベースラインよりも一貫性があり、有益で、人間のような応答を生成することを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Label Enhanced Event Detection with Heterogeneous Graph Attention
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_18.html">
      <font color="black">Label Enhanced Event Detection with Heterogeneous Graph Attention
  Networks</font>
    </a>
  </h2>
  <font color="black">まず、文字とレキシコン単語間の相互作用が十分に活用されていません。イベント検出（ED）は、テキスト内の指定されたタイプのイベントトリガーのインスタンスを認識することを目的としています。具体的には、各文をグラフに変換します。ここで、文字ノードと単語ノードがあります。さまざまなタイプのエッジに接続されているため、単語と文字の間の相互作用は完全に予約されています。 
[概要]中国のキャラクターは単語の問題に悩まされています-トリガーの不一致。既存の単語は十分に活用されていませんが、活用されていません。新しいアーキテクチャはラベル拡張異種グラフ注意ネットワークと呼ばれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning Framework for Measuring the Digital Strategy of Companies
  from Earnings Calls -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_19.html">
      <font color="black">Deep Learning Framework for Measuring the Digital Strategy of Companies
  from Earnings Calls</font>
    </a>
  </h2>
  <font color="black">この調査は、企業が採用しているデジタル戦略パターンのさまざまなクラスターを理解するために、非構造化データに最先端のNLPモデルを適用した最初の調査です。テキスト分類にはTransformerベースのアーキテクチャを使用して、会話のコンテキストをよりよく理解します。私たちの調査結果は、Fortune 500の企業が、製品主導、顧客体験主導、サービス主導、効率主導の4つの異なる戦略を使用していることを示唆しています。 
[ABSTRACT]企業は、自社の戦略が期待された業績を達成しなかったと報告しています。彼らはクラスタリング分析を適用することにより、デジタル戦略パターンを適用しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-23">
        <br><font color="black">2020-10-23</font>
      </time>
    </span>
</section>
<!-- paper0: Context in Informational Bias Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_20.html">
      <font color="black">Context in Informational Bias Detection</font>
    </a>
  </h2>
  <font color="black">この論文では、英語のニュース記事における情報バイアスの4種類のコンテキストを調査します。隣接する文、記事全体、他のニュース発行者からの同じイベントに関する記事、および同じドメインからの記事（ただし、イベントが異なる可能性があります）です。イベントコンテキストを統合すると、非常に強力なベースラインよりも分類パフォーマンスが向上することがわかります。情報バイアスは、エンティティに対する読者の意見を左右する可能性のある接線、投機的、または背景情報を提供する文または句を通じて伝達されるバイアスです。 
[要約]最高の-実行するコンテキスト句は有用な情報バイアスを提供します。しかし、以前の研究では、文を超えたコンテキストの役割を調査していません。これは、情報バイアスがないためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: CUT: Controllable Unsupervised Text Simplification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_21.html">
      <font color="black">CUT: Controllable Unsupervised Text Simplification</font>
    </a>
  </h2>
  <font color="black">このアプローチは、確立されたベンチマークで競争力のあるパフォーマンスを実現します。NewselaデータセットでSARIスコアが46.88％、FKGLが3.65％です。このホワイトペーパーでは、教師なし設定で制御可能なテキストの簡略化を学習するという課題に焦点を当てます。2つの教師なしを提案します。生成されたテキストの出力の複雑さを制御するためのメカニズム、つまり、制御トークンを使用した逆変換（学習ベースのアプローチ）と単純性を意識したビーム検索（デコードベースのアプローチ）。 
[概要]これは、教師なし手法を使用しているためです。この調査では、逆変換アルゴリズムを微調整することにより、アルゴリズムが自己監視して、目的の複雑さの出力を生成することが示されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Quda: Natural Language Queries for Visual Data Analytics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_22.html">
      <font color="black">Quda: Natural Language Queries for Visual Data Analytics</font>
    </a>
  </h2>
  <font color="black">Qudaのリリースにより、データ分析と視覚化におけるV-NLIの研究開発が促進されることを願っています。3つのアプリケーションを通じてQudaの有用性を示します。この作業は、大規模なコーパスを構築する最初の試みです。分析タスクを認識するため。 
[概要] 3つのアプリケーションを通じてqudaの有用性を実証しました。これには、データ分析と視覚化を含む3つのアプリケーションが含まれます。qudaのリリースにより、v-nlisの研究開発が促進されることを願っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br><font color="black">2020-05-07</font>
      </time>
    </span>
</section>
<!-- paper0: Adapt-and-Adjust: Overcoming the Long-Tail Problem of Multilingual
  Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_23.html">
      <font color="black">Adapt-and-Adjust: Overcoming the Long-Tail Problem of Multilingual
  Speech Recognition</font>
    </a>
  </h2>
  <font color="black">A2フレームワークは、次の3つの手法でロングテールの問題を克服します。（1）事前にトレーニングされた多言語言語モデル（mBERT）を活用して、リソースの少ない言語のパフォーマンスを向上させます。 （2）最小限の追加パラメーターで、言語固有の適応と言語に依存しない適応の両方で構成されるデュアルアダプターを提案する。 （3）トレーニング中の損失にクラスの事前確率を課すか、推論中にソフトマックス出力のロジットを調整することによって、クラスの不均衡を克服します。現実世界の多言語音声認識の1つの重要な課題は、ロングテール分布の問題です。英語のようなリソースが豊富な言語には豊富なトレーニングデータがありますが、リソースの少ない言語のロングテールには限られたトレーニングデータの量が異なります。CommonVoiceコーパスでの広範な実験は、A2が従来のアプローチを大幅に上回っていることを示しています。 
[ABSTRACT]ロングテールの問題を克服するために、適応を提案し、1,000人を対象としたマルチタスク学習フレームワークを開発しました。テストでは、a2がロングテールを大幅に上回っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Disentangled Intent Representations for Zero-shot Intent
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_24.html">
      <font color="black">Learning Disentangled Intent Representations for Zero-shot Intent
  Detection</font>
    </a>
  </h2>
  <font color="black">この問題に対処するために、見えないクラスラベルを利用して解きほぐされた意図表現（DIR）を学習するクラストランスダクティブフレームワークを提案します。2）一般化された意図検出（GZSID）設定では、見えない意図を効果的に認識できません。対応するラベル名が入力発話として機能する、トレーニング段階での見えない意図を予測するモデル。 
[概要]既存のzsidシステムには、2つの制限があります。これらは、表示されているインテントと表示されていないインテントの関係をモデル化するのが得意ではありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: KEML: A Knowledge-Enriched Meta-Learning Framework for Lexical Relation
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_25.html">
      <font color="black">KEML: A Knowledge-Enriched Meta-Learning Framework for Lexical Relation
  Classification</font>
    </a>
  </h2>
  <font color="black">補助タスクの確率分布は、さまざまなタイプの語彙関係を認識するモデルの能力を高めるために定義されます。複数のデータセットでの実験は、KEMLが最先端の方法よりも優れていることを示しています。知識が豊富なメタ学習（語彙関係分類のタスクに対処するためのKEML）フレームワーク。 
[概要]概念間の語彙関係の正確な予測は困難です。keml、lkb-bert（語彙知識ベース-bert）モデルは、大規模なテキストコーパスから概念表現を学習するために提示されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-25">
        <br><font color="black">2020-02-25</font>
      </time>
    </span>
</section>
<!-- paper0: SemMT: A Semantic-based Testing Approach for Machine Translation Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_26.html">
      <font color="black">SemMT: A Semantic-based Testing Approach for Machine Translation Systems</font>
    </a>
  </h2>
  <font color="black">最後に、往復翻訳で不審な旅行を特定するための解決策について説明します。これにより、さらなる調査が明らかになる可能性があります。ただし、これらの変容関係では、元の文と翻訳された文が同じ意味（つまり、意味的類似性）を持っているかどうかは考慮されません。 .. SemMTは往復翻訳を適用し、元の文と翻訳された文の間の意味的類似性を測定します。 
[ABSTRACT]既存の方法は、翻訳結果の正確さを判断するために、主に文学的レベルまたは構文レベルで設計された変成関係に依存しています。この論文では、意味的類似性チェックに基づく機械翻訳システムの自動テストアプローチであるsemmtを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: End to End ASR System with Automatic Punctuation Insertion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_27.html">
      <font color="black">End to End ASR System with Automatic Punctuation Insertion</font>
    </a>
  </h2>
  <font color="black">この研究では、ted.comから入手可能なトランスクリプトを使用してTEDLIUMデータセットの句読点トランスクリプトを生成する方法を提案します。ただし、自動句読点を新しいニューラルネットワークベースのエンドツーエンド音声認識に組み込むことにはほとんど関心がないようです。システムは、部分的に句読点付きの英語の音声コーパスがないためです。歴史的に、テキストまたは音声からテキストへのコンテキストでの自動句読点に多くの関心が寄せられてきました。 
[概要]新しいニューラルネットワークベースのエンドツーエンドの音声認識システムに自動句読点を許可することにほとんど関心がないようです。また、音声信号から単語と句読点を同時に出力するエンドツーエンドのasrシステムを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: TURL: Table Understanding through Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/cs.CL/paper_28.html">
      <font color="black">TURL: Table Understanding through Representation Learning</font>
    </a>
  </h2>
  <font color="black">事前にトレーニングされた表現を使用したユニバーサルモデル設計は、最小限のタスク固有の微調整で幅広いタスクに適用できます。テーブルを理解するための6つの異なるタスク（関係抽出、セルなど）で構成されるベンチマークを使用してTURLを体系的に評価します。 TURLはすべてのタスクにうまく一般化され、ほとんどすべてのインスタンスで既存のメソッドを大幅に上回っていることを示しています。 
[ABSTRACT] turlは、コンフェデレーションWebテーブルにプレトレーニング/ファインリスニングモデルを導入する新しいフレームワークです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-26">
        <br><font color="black">2020-06-26</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Phonetic Posteriorgrams based Many-to-Many Singing Voice Conversion via
  Adversarial Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.AS/paper_0.html">
      <font color="black">Phonetic Posteriorgrams based Many-to-Many Singing Voice Conversion via
  Adversarial Training</font>
    </a>
  </h2>
  <font color="black">音色変換をより安定して制御可能にするために、スピーカーの埋め込みは、異なる音色クラスターを表すトレーニング可能なベクトルのグループの加重和にさらに分解されます。さらに、より堅牢で正確な歌唱変換を実現するために、解きほぐし弁別器$ D_F $が提案されます。エンコードされたPPGに残っているピッチと音色に関連する情報を削除します。さらに客観的な分析により、提案された2段階のトレーニング戦略でトレーニングされたモデルは、より滑らかでシャープなフォーマントを生成でき、より高いオーディオ品質につながることがわかります。 
[概要]ジェネレーター$ g $は、特徴を並列にエンコードし、それらをターゲット波形に逆変換します。より堅牢で正確な歌唱変換を行うために、エンコードされたppgに残っているピッチと音色に関連する情報を削除するために解きほぐし合計が提案されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Individually amplified text-to-speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.AS/paper_1.html">
      <font color="black">Individually amplified text-to-speech</font>
    </a>
  </h2>
  <font color="black">平均オピニオン評点はSTOIメトリックによって適切に予測されました。テキスト読み上げ（TTS）は、受信側で難聴を補正するのではなく、ソースでの難聴を補正する機会を提供します。転移学習は迅速な適応につながりました。生成されたスペクトルを元の音声から個別に増幅された音声に変換し、個別のTTSシステムを効率的にトレーニングする方法を提供します。 
[要約]音声分析は、提案されたアルゴリズムが高品質のaudio.projectにつながったことを示しています。聴覚障害のあるリスナーの音声品質を改善するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Supervised attention for speaker recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.AS/paper_2.html">
      <font color="black">Supervised attention for speaker recognition</font>
    </a>
  </h2>
  <font color="black">ただし、一部の設定では、SAPは時間平均プーリング（TAP）ベースラインと比較してパフォーマンスが低く、エンドツーエンドのトレーニングでは注意が効果的に学習されないことを意味します。提案された方法では、コンテキストベクトルをブーストして選択することができます。最も有益なフレーム..SAPシステムでは、コンテキストベクトルは、特徴抽出器とともにエンドツーエンドでトレーニングされます。コンテキストベクトルの役割は、話者認識のために最も識別力のあるフレームを選択することです。 
[概要] SAPシステムでは、コンテキストセンサーは特徴抽出器と一緒に終了するようにトレーニングされます。コンテキストプールの役割は、話者認識のために最もベースラインのフレームを選択することです。この方法は、短い発話話者を含むさまざまな実験設定で既存の方法よりも優れています。認識</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: MelGlow: Efficient Waveform Generative Network Based on
  Location-Variable Convolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.AS/paper_3.html">
      <font color="black">MelGlow: Efficient Waveform Generative Network Based on
  Location-Variable Convolution</font>
    </a>
  </h2>
  <font color="black">LJSpeechデータセットでの実験は、MelGlowが小さなモデルサイズでWaveGlowよりも優れたパフォーマンスを達成することを示しています。これにより、位置変数畳み込みの有効性と潜在的な最適化空間が検証されます。 、位置変数畳み込みは、カーネル予測子を利用して、メルスペクトルに基づいて畳み込みカーネルの複数のセットを生成します。ここで、畳み込みカーネルの各セットは、関連する波形間隔で畳み込み操作を実行するために使用されます。WaveGlowと位置変数畳み込みの組み合わせ、 MelGlowという名前の効率的なボコーダーが設計されています。 
[要約] location-variable convolutionという名前のネットワークは、波形の畳み込みをモデル化するために提案されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Cross attentive pooling for speaker verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.AS/paper_4.html">
      <font color="black">Cross attentive pooling for speaker verification</font>
    </a>
  </h2>
  <font color="black">この論文では、参照クエリペア全体のコンテキスト情報を利用して、ペアワイズマッチング問題の最も識別力のある情報を含む発話レベルの埋め込みを生成するクロスアテンティブプーリング（CAP）を提案します。実験はVoxCelebで実行されます。私たちの方法が同等のプーリング戦略よりも優れているデータセット。この論文の目的は、発話が「野生の」ビデオから来て、無関係な信号を含む可能性がある、テキストに依存しない話者の検証です。 
[ABSTRACT]スピーカーの埋め込みを生成するための既存の方法は疑問です。テストはvoxcelebデータセットからのデータに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-13">
        <br><font color="black">2020-08-13</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic Noise Embedding: Noise Aware Training and Adaptation for Speech
  Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.AS/paper_5.html">
      <font color="black">Dynamic Noise Embedding: Noise Aware Training and Adaptation for Speech
  Enhancement</font>
    </a>
  </h2>
  <font color="black">ノイズのみのフレームを推定するために、音声アクティビティ検出（VAD）を使用して、音声後方に最適なしきい値を適用することにより、非音声フレームを検出します。DNEは単純なニューラルネットワークによって抽出され、DNEとのSEモジュールを共同で使用できます。環境に適応するように訓練されています。ここでは、非音声フレームは、ノイズの多い信号のノイズのみのフレームと見なすことができます。 
[ABSTRACT]ノイズのみのフレーム。音声アクティビティ検出（vad）を使用して、音声後方に最適なしきい値を適用することにより、音声以外のフレームを検出します。これらの推定フレームは、動的ノイズ埋め込み（dne）と呼ばれるノイズ埋め込みを抽出するために使用されます。 seモジュールがバックグラウンドノイズの特性をキャプチャするのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: End to End ASR System with Automatic Punctuation Insertion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-04/eess.AS/paper_6.html">
      <font color="black">End to End ASR System with Automatic Punctuation Insertion</font>
    </a>
  </h2>
  <font color="black">この研究では、ted.comから入手可能なトランスクリプトを使用してTEDLIUMデータセットの句読点トランスクリプトを生成する方法を提案します。ダメラウレーベンシュタイン距離とスロットエラー率をDLev-SERに組み合わせることで、仮説テキストが次の場合の句読点エラー率の測定が可能になります。参照と完全に一致していません。歴史的に、テキストまたは音声からテキストへのコンテキストでの自動句読点に多くの関心が寄せられてきました。 
[概要]新しいニューラルネットワークベースのエンドツーエンドの音声認識システムに自動句読点を許可することにほとんど関心がないようです。また、音声信号から単語と句読点を同時に出力するエンドツーエンドのasrシステムを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
