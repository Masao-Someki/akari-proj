<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<title>Akari-2020-01-14の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
  <div class="header-logo">
    <a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
  </div>
</header>
<input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">

<div class="menubar">
<span class="bar"></span>
<span class="bar"></span>
<span class="bar"></span>
</div>

<ul>
<li><a id="home" href="../../index.html">Home</a></li>
<li><a id="about" href="../../teamAkariとは.html">About</a></li>
<li><a id="contact" href="../../contact.html">Contact</a></li>
<li><a id="contact" href="../../list/newest.html">New Papers</a></li>
<li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
</ul>

</label>
<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Unsupervised Any-to-Many Audiovisual Synthesis via Exemplar Autoencoders -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/cs.SD/paper_0.html">
      Unsupervised Any-to-Many Audiovisual Synthesis via Exemplar Autoencoders
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さまざまな合成例については、プロジェクトWebページhttps://dunbar12138.github.io/projectpage/Audiovisual/を参照することをお勧めします。既存の方法とは対照的に、提案されたアプローチは、スピーカーからわずか2〜3分の音声データを使用して、非常に短い時間で任意の多数のスピーカーに簡単に拡張できます。オーディオ信号から、またはその逆。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br>2020-01-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Differentiable Perceptual Audio Metric Learned from Just Noticeable
  Differences -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/cs.SD/paper_1.html">
      A Differentiable Perceptual Audio Metric Learned from Just Noticeable
  Differences
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、メトリックを損失関数として使用して、ニューラルネットワークをトレーニングすることにより、このメトリックを評価します。この作業では、新たに収集された注目に値する違い（JND）音声クリップのペアが同一であるかどうかを人間が注釈します。多くの音声処理タスクの評価は、時間と費用がかかる主観的な評価に依存しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br>2020-01-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/cs.SD/paper_2.html">
      PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、ニューラルネットワークが音声パターン認識の問題を解決するために適用されました。提案されたAudioSetタグ付けシステムは、最新の平均平均精度（mAP）0.439を達成し、0.392の最高の以前のシステムをアウトパフォームします。機械学習分野の重要な研究トピックであり、オーディオタグ付け、音響シーン分類、サウンドイベント検出などのいくつかのタスクが含まれます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-21">
        <br>2019-12-21
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Negative Statements Considered Useful -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/cs.CL/paper_0.html">
      Negative Statements Considered Useful
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      （i）ピアベースの統計的推論では、潜在的な否定的なステートメントを導き出すために、エンティティを関連性の高いエンティティと比較し、教師付きおよび教師なしの機能を使用してランク付けします。（ii）クエリログベースのテキスト抽出では、検索エンジンのクエリログを収集するためのパターンベースのアプローチ。ネガティブステートメントをコンパイルするための2つのアプローチを紹介します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br>2020-01-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Domain Adaptation on Reading Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/cs.CL/paper_1.html">
      Unsupervised Domain Adaptation on Reading Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最初に、強力なBERTコンテキスト表現を使用しても、あるデータセットでトレーニングされたモデルを別のターゲットデータセットに直接適用すると、パフォーマンスがまだ不十分であることを示します。特に、ソースデータセットで微調整されたBERTモデルを活用します信頼性フィルタリングを使用して、セルフトレーニング用のターゲットドメインで信頼性の高い擬似ラベル付きサンプルを生成します。一方、ドメイン全体の条件付き敵対学習により、ドメイン分布の不一致をさらに低減します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br>2019-11-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CLUENER2020: Fine-grained Name Entity Recognition for Chinese -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/cs.CL/paper_2.html">
      CLUENER2020: Fine-grained Name Entity Recognition for Chinese
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      比較のために、シーケンスラベリングタスクとしていくつかの最新のベースラインを実装し、人間のパフォーマンスとその分析を報告します。人、組織、場所などの一般的なラベルの他に、より多様なカテゴリが含まれています。現在の他の中国のNERデータセットよりも挑戦的であり、実際のアプリケーションをよりよく反映できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br>2020-01-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Structural Decompositions of Epistemic Logic Programs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/cs.CL/paper_3.html">
      Structural Decompositions of Epistemic Logic Programs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、これらの境界に準拠する完全な動的プログラミングアルゴリズムも提供します。最後に、ツリー幅を新規の依存構造に適用することで、認識論的リテラルの観点から与えられることを示します。 ELP解決手順..認識論理プログラム（ELP）は、言語内の回答セットを推論する手段を提供する標準回答セットプログラミング（ASP）の一般的な一般化です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br>2020-01-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ProphetNet: Predicting Future N-gram for Sequence-to-Sequence
  Pre-training -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/cs.CL/paper_4.html">
      ProphetNet: Predicting Future N-gram for Sequence-to-Sequence
  Pre-training
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果から、ProphetNetは、同じベーススケールの事前トレーニングデータセットを使用するモデルと比較して、抽象的要約タスクと質問生成タスクの両方で最高のパフォーマンスを達成することが示されています。ベーススケールデータセット（16GB）と大規模データセットを使用してProphetNetを事前トレーニングします（それぞれ160GB）..本論文では、ProphetNetと呼ばれる新しいシーケンス間事前トレーニングモデルを提示します。これは、将来のn-gram予測と提案されたn-ストリーム自己注意メカニズムと呼ばれる新しい自己監視対象を導入します。 ProphetNetは、従来のシーケンスツーシーケンスモデルでの1ステップ先予測の最適化の代わりに、各タイムステップで以前のコンテキストトークンに基づいて次のnトークンを同時に予測するnステップ先予測によって最適化されます。グラム予測は、モデルが将来のトークンを計画し、強いローカル相関での過剰適合を防ぐことを明示的に奨励します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br>2020-01-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Extraction and Analysis of Fictional Character Networks: A Survey -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/cs.CL/paper_5.html">
      Extraction and Analysis of Fictional Character Networks: A Survey
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      文字ネットワークは、物語から抽出されたグラフであり、頂点は文字を表し、エッジはそれらの間の相互作用に対応します。最初に、一般的な方法で抽出プロセスを説明し、物語の媒体、ネットワーク分析の目的、およびその他の要因に応じて、実際にその構成ステップがどのように実装されるかを説明します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-05">
        <br>2019-07-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Reformer: The Efficient Transformer -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/cs.CL/paper_6.html">
      Reformer: The Efficient Transformer
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果のモデルであるReformerは、Transformerモデルと同等のパフォーマンスを発揮しますが、長いシーケンスではメモリ効率が大幅に向上し、高速になります。さらに、特に長いシーケンスでは非常にコストがかかる可能性があります。さらに、標準残差の代わりに可逆残差レイヤーを使用します。これにより、$ N $回ではなく、トレーニングプロセスでアクティベーションを1回のみ保存できます。 。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br>2020-01-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural
  Architecture Search -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/cs.CL/paper_7.html">
      AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural
  Architecture Search
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      タスク指向の知識の蒸留損失を組み込んで、検索のヒントと検索制約としての効率を意識した損失を提供します。これにより、タスク適応型BERT圧縮の効率と有効性の間の適切なトレードオフが可能になります。指向のBERT圧縮では、微分可能なニューラルアーキテクチャ検索を活用して特定のタスクのBERTをタスク適応型の小さなモデルに自動的に圧縮する新しい圧縮方法AdaBERTを提案します。すなわち、すべての異なるダウンストリームタスクに対して同じ圧縮されたBERT。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br>2020-01-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-Source Domain Adaptation for Text Classification via
  DistanceNet-Bandits -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/cs.CL/paper_8.html">
      Multi-Source Domain Adaptation for Text Classification via
  DistanceNet-Bandits
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最初に、これらの距離測定のどれがサンプルを同じドメインと異なるドメインから最もよく区別できるかを示すために分析実験を行い、経験的結果と相関します。最後に、このモデルをマルチアーム複数のソースドメイン間を動的に切り替え、モデルが低リソースターゲットドメインに転送するための最適な軌道とドメインの混合を学習できるようにするバンディットコントローラー。NLPタスクのコンテキストにおけるさまざまな距離ベースの測定の研究サンプルの推定に基づいて、ドメイン間の非類似性を特徴付けます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br>2020-01-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A logic-based relational learning approach to relation extraction: The
  OntoILPER system -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/cs.CL/paper_9.html">
      A logic-based relational learning approach to relation extraction: The
  OntoILPER system
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されているリレーショナルアプローチは、いくつかの理由により、統計抽出よりもリレーション抽出に適しているようです。このような統計学習手法は、通常、例を表すための命題仮説空間に基づいています。 ..さらに、OntoILPERは、背景知識生成プロセスをガイドするドメインオントロジーを使用し、抽出された関係インスタンスを格納するために使用されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br>2020-01-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Survey on Publicly Available Sinhala Natural Language Processing Tools
  and Research -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/cs.CL/paper_10.html">
      Survey on Publicly Available Sinhala Natural Language Processing Tools
  and Research
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      しかし、さまざまな理由により、これらの試みは相互の調整と認識を欠いているように見えます。しかし、言語と経済の両方の資本の貧困のため、シンハラは自然言語処理ツールと研究の観点で、資源不足のままです。従兄弟の英語が持つ経済的駆動力も、中国語などの言語が持つ数の法則の完全な推進力もない言語..そのため、この論文をarXivにアップロードし、定期的に更新して、フィールド。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-05">
        <br>2019-06-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Joint Reasoning for Multi-Faceted Commonsense Knowledge -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/cs.CL/paper_11.html">
      Joint Reasoning for Multi-Faceted Commonsense Knowledge
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      常識知識（CSK）は、視覚的理解からチャットボットまで、さまざまなAIアプリケーションをサポートします。各概念は他の概念から分離して扱われ、プロパティの定量的測定（またはランキング）のみがステートメントが有効であるという信頼スコアです。この方法論は、いくつかの大規模なCSKコレクションに適用されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br>2020-01-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Mining customer product reviews for product development: A summarization
  process -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/cs.CL/paper_12.html">
      Mining customer product reviews for product development: A summarization
  process
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      オンラインのレビュー要約プロセスを自然言語処理で自動化するには、高度な合意に基づく人間の注釈結果が不可欠であるため、この研究は自動化の将来の研究のための資料を提供します。好みのこれらの側面を説明する言語パターンが発見され、注釈ガイドラインとして作成されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br>2020-01-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Cross-lingual, Character-Level Neural Morphological Tagging -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/cs.CL/paper_13.html">
      Cross-lingual, Character-Level Neural Morphological Tagging
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      関連する複数の言語間で共通の文字表現を学習すると、リソースの多い言語からリソースの少ない言語への知識の伝達が可能になり、精度が最大30％向上します。一般的なNLPタスクの場合でも、多くの言語では十分な監督が利用できません。形態学的タグ付けも例外ではありません。高リソース言語と低リソース言語を一緒に。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2017-08-30">
        <br>2017-08-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Computer-supported Analysis of Positive Properties, Ultrafilters and
  Modal Collapse in Variants of Gödel's Ontological Argument -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/cs.CL/paper_14.html">
      Computer-supported Analysis of Positive Properties, Ultrafilters and
  Modal Collapse in Variants of Gödel's Ontological Argument
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      G \ &quot;odelの議論のスコットのバージョンとは対照的に、アンダーソンとフィッティングによって提供された2つのバリアントは、モード崩壊を回避します。それらは大まかな読みでかなり異なって見えますが、実際に密接に関連しています。 （モーダル）ウルトラフィルターの適切に適応された概念、および正のプロパティの拡張とインテンションの慎重な区別。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-20">
        <br>2019-10-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Persuasion for Good: Towards a Personalized Persuasive Dialogue System
  for Social Good -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/cs.CL/paper_15.html">
      Persuasion for Good: Towards a Personalized Persuasive Dialogue System
  for Social Good
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      注釈に基づいて、コーパスで使用される10の説得戦略を予測するコンテキスト情報と文レベルの機能を備えたベースライン分類子を構築しました。さらに、パーソナライズされた説得プロセスの理解を深めるために、個人の人口統計と人格、道徳、価値体系、寄付に対する意欲などの心理的背景。その後、個人の背景に応じて、どのタイプの説得戦略がより多くの寄付をもたらすかを分析しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-16">
        <br>2019-06-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: LP-SparseMAP: Differentiable Relaxed Optimization for Sparse Structured
  Prediction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/cs.CL/paper_16.html">
      LP-SparseMAP: Differentiable Relaxed Optimization for Sparse Structured
  Prediction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SparseMAPは、一部のダウンストリームアプリケーションで望ましいプロパティである少数の構造の組み合わせを返します。これにより、たとえば、おおよその推論を必要とする論理制約のあるループグラフィカルモデルや因子グラフは除外されます。潜在変数または出力変数としての依存関係ツリーまたはアライメントなどの組み合わせ構造。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br>2020-01-13
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Unsupervised Any-to-Many Audiovisual Synthesis via Exemplar Autoencoders -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/eess.AS/paper_0.html">
      Unsupervised Any-to-Many Audiovisual Synthesis via Exemplar Autoencoders
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さまざまな合成例については、プロジェクトWebページhttps://dunbar12138.github.io/projectpage/Audiovisual/を参照することをお勧めします。ターゲットスピーカーの音声と特定のスタイル（感情と雰囲気）を学習するために、模範オートエンコーダを使用します。また、オーディオ信号からビデオを生成するためのアプローチの有用性を示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br>2020-01-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Visually Guided Self Supervised Learning of Speech Representations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/eess.AS/paper_1.html">
      Visually Guided Self Supervised Learning of Speech Representations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      自己教師付き表現学習は、最近、オーディオモダリティとビジュアルモダリティの両方で多くの研究関心を集めています。感情認識と音声認識の競合結果。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br>2020-01-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Differentiable Perceptual Audio Metric Learned from Just Noticeable
  Differences -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/eess.AS/paper_2.html">
      A Differentiable Perceptual Audio Metric Learned from Just Noticeable
  Differences
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      既存の損失をメトリックで単純に置き換えると、主観的なペアワイズ比較で測定されるノイズ除去の大幅な改善が得られることがわかります。 JND）では、人間がオーディオクリップのペアが同一であるかどうかに注釈を付けます。さらに、このメトリックを損失関数として使用して、ニューラルネットワークをトレーニングすることでこのメトリックを評価します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br>2020-01-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-14/eess.AS/paper_3.html">
      PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、ニューラルネットワークがオーディオパターン認識の問題を解決するために適用されました。提案されたAudioSetタグ付けシステムは、0.439の最新の平均平均精度（mAP）を達成します。オーディオパターン認識システムのパフォーマンスを制限する小さなデータセットに焦点を当てます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-21">
        <br>2019-12-21
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本日更新された論文はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br>
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
