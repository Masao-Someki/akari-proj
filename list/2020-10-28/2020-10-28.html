<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-10-28の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Deep generative factorization for speech signal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.SD/paper_0.html">
      <font color="black">Deep generative factorization for speech signal</font>
    </a>
  </h2>
  <font color="black">この論文は、新しい階乗識別正規化フローモデル（階乗DNF）に基づく音声因数分解アプローチを提示します。さまざまな情報要因が音声信号にブレンドされ、ほとんどの音声情報処理タスクの主な困難を形成します。音声コンテンツと話者特性を含む階乗ケースは、提案された階乗DNFが音声信号を因数分解する強力な機能を持ち、情報の表現と操作に関していくつかの比較モデルよりも優れていることを示しています。 
[概要]提案された階乗dnfは、音声信号を因数分解する強力な機能を備えています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Squeezing value of cross-domain labels: a decoupled scoring approach for
  speaker verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.SD/paper_1.html">
      <font color="black">Squeezing value of cross-domain labels: a decoupled scoring approach for
  speaker verification</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、最初に、クロスドメインデータを追加するだけでは、登録テストの不一致がある条件でのパフォーマンスに役立たないことを示す実証研究を紹介します。統計が一貫している場合、新しい定式化は従来のPLDAにフォールバックします。実験クロスチャネルテストの結果は、提案されたアプローチが非常に効果的であり、ドメインの不一致に対する主要な解決策であることを示しています。 
[概要]これは、登録条件とテスト条件の間の統計が一貫していないためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Universal ASR: Unifying Streaming and Non-Streaming ASR Using a Single
  Encoder-Decoder Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.SD/paper_2.html">
      <font color="black">Universal ASR: Unifying Streaming and Non-Streaming ASR Using a Single
  Encoder-Decoder Model</font>
    </a>
  </h2>
  <font color="black">ストリーミングASRモデルと非ストリーミングASRモデルを1つのシステムに統合できるユニバーサルASRと呼ばれる新しいアーキテクチャを提案します。最近、オンラインエンドツーエンドASRがますます注目を集めています。組み込みストリーミングASRモデルは、リアルタイムの認識結果を取得するための要件。非ストリーミングモデルは、パフォーマンスを向上させるために最終的な認識結果を更新できます。 
[ABSTRACT]ユニバーサルasrは、音声をすばやく正確に認識できるストリーミングモデルと非ストリーミングモデルを統合できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: ByteCover: Cover Song Identification via Multi-Loss Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.SD/paper_3.html">
      <font color="black">ByteCover: Cover Song Identification via Multi-Loss Training</font>
    </a>
  </h2>
  <font color="black">ByteCoverは従来のResNetモデルに基づいて構築されており、CSIのモデルの機能をさらに強化するために、2つの主要な改善が設計されています。2番目の改善では、BNNeckメソッドを使用して、マルチロストレーニングを可能にし、分類損失とトリプレット損失を共同で最適化することにより、カバー曲のクラス間識別とクラス内コンパクト性を同時に確保できます。一連の実験により、ByteCoverの有効性と効率が実証されました。複数のデータセット、およびDa-TACOSデータセットでは、ByteCoverは最高の競争力のあるシステムを20.9 \％上回っています。 
[概要]プロジェクトは古典的なresnetモデルに基づいて構築されています。2つの主要な改善がcsiの機能をさらに強化するように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Emotion recognition by fusing time synchronous and time asynchronous
  representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.SD/paper_4.html">
      <font color="black">Emotion recognition by fusing time synchronous and time asynchronous
  representations</font>
    </a>
  </h2>
  <font color="black">IEMOCAPデータセットの実験結果は、2分岐構造が、すべての一般的なテスト設定で4方向分類で最先端の結果を達成することを示しています。さらに、他のすべての感情に追加のクラスを組み込むことにより、最後の5 -ASR仮説を使用した方法分類システムは、より現実的な感情認識システムのプロトタイプと見なすことができます。各単語とその音響認識の間の相関関係をキャプチャするために、TSBは各入力ウィンドウフレームで音声とテキストのモダリティを組み合わせて、時間の経過とともにプールします。単一の埋め込みベクトルを形成します。 
[概要] tsbは、各入力ウィンドウフレームで音声とテキストのモダリティを組み合わせます。その後、時間の経過とともにプールを実行して単一の埋め込みを形成します。最終的な感情分類では、tsbとタブの埋め込みの両方を使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: The UPC Speaker Verification System Submitted to VoxCeleb Speaker
  Recognition Challenge 2020 (VoxSRC-20) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.SD/paper_5.html">
      <font color="black">The UPC Speaker Verification System Submitted to VoxCeleb Speaker
  Recognition Challenge 2020 (VoxSRC-20)</font>
    </a>
  </h2>
  <font color="black">ダブルブランチシャムは、トレーニング中にクロスエントロピー損失を使用してバイナリ分類を実行します。シャムネットワークには、それぞれ2つと3つのブランチがあり、各ブランチはCNNエンコーダーです。最終的な提出は3つのシステムの組み合わせです。 
[要約]最終的な提出は、3つのシステムの組み合わせです。cnnエンコーダーであるvoxへの応答です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Parallel waveform synthesis based on generative adversarial networks
  with voicing-aware conditional discriminators -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.SD/paper_6.html">
      <font color="black">Parallel waveform synthesis based on generative adversarial networks
  with voicing-aware conditional discriminators</font>
    </a>
  </h2>
  <font color="black">このフレームワークでは、弁別器のパフォーマンスを大幅に向上させることができる投影ベースの条件付け方法を採用しています。特に、FastSpeech 2ベースのテキスト読み上げフレームワーク内のスピーカーに依存しないトレーニングモデルは、平均オピニオン評点4.20、4.18を達成します。 、4.21、および4.31は、それぞれ4人の日本語話者に対して..主観的なテスト結果は、従来のParallelWaveGANおよびWaveNetシステムに対する提案された方法の優位性を示しています。 
[ABSTRACT]プロジェクションベースのコンディショニング方法は、ディスクリミネーターのパフォーマンスを大幅に向上させることができます。各ディスクリミネーターがそれぞれ特徴的な特性を学習すると、トレーニングプロセスがより効率的になり、ジェネレーターがより現実的な音声波形を生成できるようになります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Far-Field Speech Recognition with Unified Dereverberation and
  Beamforming -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.SD/paper_7.html">
      <font color="black">End-to-End Far-Field Speech Recognition with Unified Dereverberation and
  Beamforming</font>
    </a>
  </h2>
  <font color="black">上記の2つのアーキテクチャは、音声認識基準のみを使用して、完全にエンドツーエンドで最適化されています。空間化されたwsj1-2mixコーパスとREVERBの両方での実験は、提案されたモデルが残響シナリオで従来の方法よりも優れていることを示しています。別の新しいフロントエンドアーキテクチャが提案されています。これは、加重電力最小化歪みなし応答（WPD）畳み込みビームフォーマを拡張して、分離と残響除去を同時に実行します。 
[概要] 2つの新しいフロントエンドアーキテクチャが新しい論文で提案されています。これらは、音声認識基準のみを使用して、従来の方法で完全に最適化されています。2つのアーキテクチャは、認識標準を使用するように最適化されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br><font color="black">2020-05-21</font>
      </time>
    </span>
</section>
<!-- paper0: New interfaces for musical expression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.SD/paper_8.html">
      <font color="black">New interfaces for musical expression</font>
    </a>
  </h2>
  <font color="black">このワークショップでは、音楽コントローラーに関心のあるインターフェースの専門家と、新しい音楽インターフェースの開発に携わるミュージシャンや作曲家が集まります。エレクトロニクス、デジタルメディア、高度な素材、その他の技術分野の急速な進化により、音楽インターフェースの前例のない機会が開かれています。発明者とデザイナー..これらの新しいテクノロジーによってもたらされる可能性は、音楽の作曲家や演奏者にとって複雑でしばしば混乱する一連の選択肢という課題を伴います。 
[概要]代替の音楽コントローラーは、テクノロジーと音楽文化の間で進行中の対話の最先端です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Toward Speech Separation in The Pre-Cocktail Party Problem with TasTas -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.SD/paper_9.html">
      <font color="black">Toward Speech Separation in The Pre-Cocktail Party Problem with TasTas</font>
    </a>
  </h2>
  <font color="black">オンライン音声データリミックス拡張\ cite {zeghidour2020wavesplit}をトレーニングに採用すると、11.14dBのSDR改善を実現できます。このノートでは、モノラルへのエンドツーエンドアプローチにTasTas \ cite {shi2020speech}を使用することを提案します。カクテルパーティー前の問題における音声分離..公開WSJ0-5mixデータコーパスでの実験により、10.41dBのSDRが改善されました。 
[概要]公開wsj0-5mixデータコーパスでの実験の結果は10です。41dbsdrの改善。このペーパーの結果は簡単に再現できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: LaFurca: Iterative Refined Speech Separation Based on Context-Aware
  Dual-Path Parallel Bi-LSTM -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.SD/paper_10.html">
      <font color="black">LaFurca: Iterative Refined Speech Separation Based on Context-Aware
  Dual-Path Parallel Bi-LSTM</font>
    </a>
  </h2>
  <font color="black">これらのネットワークはすべて、2人の話者の混合発話を受け取り、それを2つの別々の発話にマッピングします。各発話には1人の話者の声のみが含まれます。次に、グローバルコンテキスト対応のインターイントラクロスパラレルBiLSTMを使用して、グローバルコンテキストをさらに認識します。情報..最初に、並列内BiLSTMおよび並列間BiLSTMコンポーネントを備えたデュアルパスネットワークが導入され、異なるブランチ間のパフォーマンスのサブバリアントが削減されます。 
[ABSTRACT]イントラパラレルビルストンおよびインターパラレルビルストンビルストンコンポーネントを備えたデュアルパスネットワークが導入され、パフォーマンスが大幅に低下します。ネットワークは、前のステージの分離結果を改善できるようになります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-23">
        <br><font color="black">2020-01-23</font>
      </time>
    </span>
</section>
<!-- paper0: Leveraging speaker attribute information using multi task learning for
  speaker verification and diarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.SD/paper_11.html">
      <font color="black">Leveraging speaker attribute information using multi task learning for
  speaker verification and diarization</font>
    </a>
  </h2>
  <font color="black">実験コードが公開されました。この作業では、米国最高裁判所の録音の補助変数として話者の年齢を利用し、VoxCelebで話者の国籍を使用して、マルチタスク学習設定で追加の話者属性情報を活用することにより、深い話者の埋め込みを示します。検証およびダイアリゼーションタスクのパフォーマンスを向上させることができ、補助タスクを省略した場合と比較して、最高裁判所の音声ではDERで17.8％、EERで8.9％の相対的な改善を達成できます。スピーカーの深い埋め込みは、スピーカーでスピーカーIDをエンコードするための主要な方法になりました。認識タスク。 
[ABSTRACT]埋め込みスペースは、考えられるすべてのスピーカー間のバリエーションをキャプチャする必要があります、と埋め込みスピーカーは言います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Rule-embedded network for audio-visual voice activity detection in live
  musical video streams -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.SD/paper_12.html">
      <font color="black">Rule-embedded network for audio-visual voice activity detection in live
  musical video streams</font>
    </a>
  </h2>
  <font color="black">視覚情報の助けを借りて、この論文は、モデルがターゲットの声をよりよく検出するのを助けるために視聴覚（AV）入力を融合するためのルール埋め込みネットワークを提案します。実験は次のことを示しています：1）クロスモーダル融合の助けを借りて提案されたルールでは、AVブランチの検出結果はオーディオブランチの検出結果よりも優れています。 2）バイモーダルモデルのパフォーマンスは、オーディオのみのモデルのパフォーマンスをはるかに上回っています。これは、オーディオ信号とビジュアル信号の両方を組み込むことがVADにとって非常に有益であることを示しています。クロスモーダル音楽とオーディオ信号処理により多くの注目を集めるには、フレームレベルのラベルが付いた新しいライブミュージカルビデオコーパスが導入されました。 
[概要]モデルにおけるルールの主な役割は、バイモーダル情報間の関係を調整し、視覚的表現をマスクとして使用して、非ターゲットサウンドの情報を除外することです。フレーム付きの新しいライブ音楽ビデオコーパス-レベルラベルは、クロスモーダル音楽とオーディオ信号処理により多くの注目を集めるために導入されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Contextual Tag Embeddings for Cross-Modal Alignment of Audio
  and Tags -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.SD/paper_13.html">
      <font color="black">Learning Contextual Tag Embeddings for Cross-Modal Alignment of Audio
  and Tags</font>
    </a>
  </h2>
  <font color="black">MHAはWEMの出力に参加し、オーディオに関連付けられたタグのコンテキスト表現を提供し、対照的な損失を使用してMHAの出力をAAEのエンコーダーの出力に合わせます。AAEとMHAを共同で最適化し、音声表現を評価します（つまり、自己教師あり音声表現学習は、さまざまなダウンストリームタスクに使用できる一般的な音声埋め込みを取得するための魅力的な代替手段を提供します。
[要約]一般化できるテキスト処理モデルは使用しません。トレーニング中にタグが不明です。対照的な損失を使用して、mhaの出力をaaeのエンコーダーに合わせます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: One-class learning towards generalized voice spoofing detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.SD/paper_14.html">
      <font color="black">One-class learning towards generalized voice spoofing detection</font>
    </a>
  </h2>
  <font color="black">重要なアイデアは、本物の音声表現を圧縮し、角度マージンを注入して、埋め込みスペースでのなりすまし攻撃を分離することです。私たちのシステムは、ASVspoof 2019チャレンジの評価セットで2.19％の同等のエラー率を達成し、既存のすべての単一システムを上回ります。 ..この作業では、1クラスの学習を使用して未知の論理アクセス攻撃（つまり、合成音声）を検出するためのスプーフィング防止システムを提案します。 
[ABSTRACT]システムは、1クラスの学習を使用して認証攻撃を検出できます。システムは、既存のすべての単一システムを上回る、同等のエラー率、asvspoof2019攻撃を実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Upsampling artifacts in neural audio synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.SD/paper_15.html">
      <font color="black">Upsampling artifacts in neural audio synthesis</font>
    </a>
  </h2>
  <font color="black">オーディオシンセサイザーの最近の進歩の多くは、不要なアーティファクトをもたらす可能性のあるニューラルアップサンプラーに依存しています。ここでは、オーディオ信号処理の観点からこの問題を調査することで、このギャップに対処します。次に、さまざまなニューラルアップサンプラーを比較し、最も近い隣接補間を示します。アップサンプラーは、音のアーティファクトを導入する傾向がある問題のある（ただし最先端の）転置およびサブピクセルコンボリューションの代替となります。 
[概要]コンピュータビジョンでは、アップサンプリングアーティファクトが研究されており、チェッカーボードアーティファクトとして知られています（その特徴的な視覚パターンのため）。ここでは、オーディオ信号処理の観点からこの問題を研究することにより、このギャップに対処します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Post Training Uncertainty Calibration of Deep Networks For Medical Image
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.IV/paper_0.html">
      <font color="black">Post Training Uncertainty Calibration of Deep Networks For Medical Image
  Segmentation</font>
    </a>
  </h2>
  <font color="black">すべての場合において、事後キャリブレーションはMCドロップアウトと競合します。すべての場合において、少なくとも1つの事後キャリブレーションがキャリブレーションを改善します。実装が簡単ないくつかの事後キャリブレーション方法を調査します。そのうちのいくつかは斬新です。 
[概要]十分にトレーニングされたモデルは、SD損失でトレーニングされたモデルよりも必ずしもキャリブレーションが少ないわけではありません。ただし、すべての信頼スコアは、ユーザーに貴重な情報を提供します。モンテカルロ（mc）ドロップアウトと比較されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Probabilistic Imaging: Uncertainty Quantification and Multi-modal
  Solution Characterization for Computational Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.IV/paper_1.html">
      <font color="black">Deep Probabilistic Imaging: Uncertainty Quantification and Multi-modal
  Solution Characterization for Computational Imaging</font>
    </a>
  </h2>
  <font color="black">したがって、観測データを説明する可能性のある画像の空間を特徴づけることが重要です。このアプローチでは、トレーニングデータは必要ありません。代わりに、ニューラルネットワークの重みを最適化して、特定の測定データセットに適合する画像サンプルを生成します。DeepProbabilisticImaging（DPI）は、トレーニングされていない深層生成モデルを使用して、観測されていない画像の事後分布を推定します。 
[ABSTRACT]ディープ確率イメージング（dpi）は、トレーニングされていないディープジェニュティブモデルを使用して、観測されていない画像の事後分布を推定します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: A Bayesian Filter for Multi-view 3D Multi-object Tracking with Occlusion
  Handling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.IV/paper_2.html">
      <font color="black">A Bayesian Filter for Multi-view 3D Multi-object Tracking with Occlusion
  Handling</font>
    </a>
  </h2>
  <font color="black">提案されたアルゴリズムは、最新のWILDTRACKSデータセットで評価され、新しいデータセットの非常に混雑したシーンで機能することが実証されています。3Dワールドフレームで動作し、オブジェクトの3D軌道推定を提供します。このペーパーでは、オンラインマルチを提案します。マルチカメラ構成に関係なく、単眼検出器のトレーニングのみを必要とするカメラマルチオブジェクトトラッカー。再トレーニングの労力なしでカメラのシームレスな拡張/削除を可能にします。 
[概要]提案されたアルゴリズムは、カメラ全体の検出の総数が線形的に複雑であるため、カメラの数に応じて適切にスケーリングされます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br><font color="black">2020-01-13</font>
      </time>
    </span>
</section>
<!-- paper0: Decentralized Attribution of Generative Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.IV/paper_3.html">
      <font color="black">Decentralized Attribution of Generative Models</font>
    </a>
  </h2>
  <font color="black">この結果は、MNISTとCelebAで検証されます。このホワイトペーパーでは、各モデルを本物のデータと区別できるようにするだけで証明可能な帰属を実現できる分散型帰属について説明します。既存の帰属方法は、モデルの数に関して拡張性がありません。そして、帰属可能性に関する理論的限界が欠けています。 
[概要]各モデルを本物のデータと区別できるようにするだけで帰属を達成できるという懸念があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Improved inter-scanner MS lesion segmentation by adversarial training on
  longitudinal data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.IV/paper_4.html">
      <font color="black">Improved inter-scanner MS lesion segmentation by adversarial training on
  longitudinal data</font>
    </a>
  </h2>
  <font color="black">次に、2つの病変セグメンテーションが同じスキャナータイプを使用して取得したスキャンに基づいているかどうかを予測するように弁別モデルをトレーニングし、このタスクで78％の精度を達成します。モデルのパフォーマンスは、手動の描写を含む目に見えないデータセットで評価されます。最後に、ベースモデルとディスクリミネーターは、マルチスキャナーの縦方向データで敵対的にトレーニングされ、ベースモデルのスキャナー間の一貫性が向上します。 
[ABSTRACT]病変セグメンテーションアルゴリズムは、MRIスキャナーまたはプロトコルの違いに関連する画像特性の変動の影響を受けやすく、基本モデルの精度を達成するために重要なデータについて敵対的に訓練されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br><font color="black">2020-02-03</font>
      </time>
    </span>
</section>
<!-- paper0: Triple-view Convolutional Neural Networks for COVID-19 Diagnosis with
  Chest X-ray -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.IV/paper_5.html">
      <font color="black">Triple-view Convolutional Neural Networks for COVID-19 Diagnosis with
  Chest X-ray</font>
    </a>
  </h2>
  <font color="black">コロナウイルス病2019（COVID-19）は、世界中でますます多くの人々に影響を及ぼしており、医療システムに大きなストレスを与えています。これらの問題に対処するために、単一のビューから各CXR画像を処理する従来の方法とは異なり、このペーパーではトリプルを提案します。 CXR画像を使用してCOVID-19診断のための畳み込み神経ネットワークを表示します。提案されたネットワーク構造は、人間の肺の解剖学的構造を尊重し、実際のCOVID-19の臨床診断とよく一致しています。 
[要約] covid-19は、1つの画像のみを生成するcxrスキャンです。これは、利用可能な限られたサンプルからより多くの特徴を抽出することが難しいことを意味します。これらには、左肺ビュー、右肺ビュー、および全体的な診断を含むこれらの特徴が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Spatio-Temporal Processing for Automatic Vehicle Detection in Wide-Area
  Aerial Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.IV/paper_6.html">
      <font color="black">Spatio-Temporal Processing for Automatic Vehicle Detection in Wide-Area
  Aerial Video</font>
    </a>
  </h2>
  <font color="black">全体として、提案された時空間処理スキームを使用すると、平均Fスコアが0.8以上に向上し、誤検知が平均83.8％減少します。実験的評価では、提案されたスキームが9つのアルゴリズムのそれぞれの車両検出パフォーマンスを向上させることが示されています。 7つのデータセットで評価した場合..2つのローカル空中ビデオデータセットと1つの駐車車両データセットで提案された空間処理のパフォーマンスを評価し、5つのローカル空中ビデオデータセットと1つのパブリックデータセットで提案された時空間処理スキームのパフォーマンスを評価します。 
[ABSTRACT]新しいシステムは、既存の検出アルゴリズムのしきい値処理ステップを、前景ピクセル分類のためのマルチネイバーフッドヒステリシスthresholduneに置き換えます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Micro-CT Synthesis and Inner Ear Super Resolution via Bayesian
  Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.IV/paper_7.html">
      <font color="black">Micro-CT Synthesis and Inner Ear Super Resolution via Bayesian
  Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">超解像タスクのためのサイクル整合性生成敵対的ネットワークを探索し、翻訳アプローチにベイジアン推論を装備します。さらに、側頭骨の構造を定量化するための評価メトリックを\ emph {HuMoment}導入します。公開されている内耳CTデータセットであり、最先端の深層学習ベースの方法よりも視覚的および定量的に改善されています。 
[概要]これらの画像は、臨床現場では利用できないことがよくあります。これらの画像は、視覚的および定量的な改善の状態に依存しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Hyperspectral Anomaly Change Detection Based on Auto-encoder -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.IV/paper_8.html">
      <font color="black">Hyperspectral Anomaly Change Detection Based on Auto-encoder</font>
    </a>
  </h2>
  <font color="black">公開されている「Viareggio2013」データセットでの実験結果は、従来の方法に対する効率と優位性を示しています。この論文では、オートエンコーダー（ACDA）に基づく独自のHACDアルゴリズムを提案して、非線形ソリューションを提供します。最終的な異常変化強度マップとしての2方向の2つの損失マップの最小値。 
[概要]ハイパースペクトル情報情報の変化の検出（hacd）は、マルチテンポラルハイパースペクトル画像（hsi）間の小さいが重要な異常変化を見つけるのに役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: An Adaptive Intelligence Algorithm for Undersampled Knee MRI
  Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.IV/paper_9.html">
      <font color="black">An Adaptive Intelligence Algorithm for Undersampled Knee MRI
  Reconstruction</font>
    </a>
  </h2>
  <font color="black">私たちのメソッドは、独立したチャレンジデータセットでfastMRIオーガナイザーによって評価されました。これは、メソッドの優れたパフォーマンスと幅広い適用性を示しています。チャレンジへのすべての提出は、最初は既知のグラウンドトゥルースとの類似性に基づいてランク付けされ、その後、上位4つの提出が行われました。放射線学的に評価された。 
[要約]課題は、既知の根拠との類似性に基づいていました。上位4件の提出物は放射線学的に評価されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-15">
        <br><font color="black">2020-04-15</font>
      </time>
    </span>
</section>
<!-- paper0: Impact of Spherical Coordinates Transformation Pre-processing in Deep
  Convolution Neural Networks for Brain Tumor Segmentation and Survival
  Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.IV/paper_10.html">
      <font color="black">Impact of Spherical Coordinates Transformation Pre-processing in Deep
  Convolution Neural Networks for Brain Tumor Segmentation and Survival
  Prediction</font>
    </a>
  </h2>
  <font color="black">前処理とデータ拡張は、ディープ畳み込みニューラルネットワーク（DCNN）で重要な役割を果たします。この作業では、通常のMRIボリュームと組み合わせて使用して脳の精度を向上させる前処理方法として、球面座標変換を適用しました。脳腫瘍セグメンテーション（BraTS）チャレンジ2020データセットでの腫瘍セグメンテーションと患者の全生存（OS）予測..LesionEncoderフレームワークを適用して、DCNNモデルから特徴を自動的に抽出し、検証データセットでOS予測の精度0.586を達成しました。 BraTS2020リーダーボードによると最高の結果の1つです。 
[概要]新しい方法は、dcnnに球形の空間変換データを供給することを目的としています。その後、dcnnモデルから特徴を自動的に抽出するために適用されました。腫瘍データは、brats2020リーダーボードによると最良の結果の1つです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Motion Compensated Whole-Heart Coronary Magnetic Resonance Angiography
  using Focused Navigation (fNAV) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.IV/paper_11.html">
      <font color="black">Motion Compensated Whole-Heart Coronary Magnetic Resonance Angiography
  using Focused Navigation (fNAV)</font>
    </a>
  </h2>
  <font color="black">fNAVをRSNと比較し、同じデータの呼吸分解XD-GRASP再構成と記録された再構成時間を比較しました。したがって、この作業の目標は、3Dモーション情報と非剛体内取得の両方を組み込むことにより、3DラジアルCMRAの堅牢性と品質を向上させることです。フォーカスナビゲーション（fNAV）と呼ばれるフレームワークへのデータの修正。方法：数値シミュレーションからの500のデータセット、22人の健康なボランティア、および549人の心臓病患者にfNAVを適用しました。 
[概要]数値シミュレーションからの500のデータセット、22人の健康なボランティア、および549人の心臓病患者にfnavを適用しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Sequential Learning for Cervical Spine Fracture Detection on
  Computed Tomography Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.IV/paper_12.html">
      <font color="black">Deep Sequential Learning for Cervical Spine Fracture Detection on
  Computed Tomography Imaging</font>
    </a>
  </h2>
  <font color="black">検証結果は、平衡（104陽性および104陰性症例）および不平衡（104陽性および419陰性症例）テストデータセットでそれぞれ70.92％および79.18％の分類精度を示しています。頸椎の骨折は救急医療であり、永続的な麻痺、さらには死につながる可能性があります。この論文では、CT軸方向画像の頸椎骨折の自動検出のための双方向長期短期メモリ（BLSTM）層を備えた深い畳み込み神経ネットワーク（DCNN）を提案します。 
[ABSTRACT]詳細なデータセットは、モデルのトレーニングと検証に使用されます。結果は、患者管理にとって重要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Compressing Images by Encoding Their Latent Representations with
  Relative Entropy Coding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.IV/paper_13.html">
      <font color="black">Compressing Images by Encoding Their Latent Representations with
  Relative Entropy Coding</font>
    </a>
  </h2>
  <font color="black">最近提案された「ビットバック」法は、潜在的な後部と前部の間の相対エントロピーに近いコード長で画像の潜在的表現を間接的にエンコードできます。別の方法として、新しい方法、相対エントロピーコーディング（REC）を提案します。 Cifar10、ImageNet32、およびKodakデータセットで得られた経験的結果によってサポートされている、単一画像の相対エントロピーに近いコード長で潜在表現を直接エンコードできます。さらに、以前のビットバック方法とは異なり、RECは損失のある圧縮にすぐに適用できます。 Kodakデータセットの最先端と競合します。 
[概要]これらの方法は、可逆圧縮にのみ使用できます。複数の画像を圧縮する場合にのみ公称効率を達成します。単一の画像を圧縮するには非効率的です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-02">
        <br><font color="black">2020-10-02</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: ATRW: A Benchmark for Amur Tiger Re-identification in the Wild -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_0.html">
      <font color="black">ATRW: A Benchmark for Amur Tiger Re-identification in the Wild</font>
    </a>
  </h2>
  <font color="black">ATRWには、92頭のアムールトラからの8,000を超えるビデオクリップが含まれており、バウンディングボックス、ポーズキーポイント、タイガーIDアノテーションが付いています。通常のre-IDデータセットとは対照的に、タイガーはさまざまな制約のないポーズと照明条件でキャプチャされます。論文は、新しい大規模データセットであるAmur Tiger Re-identification in the Wild（ATRW）データセットを導入することにより、ギャップを埋めようとしています。 
[概要]アムールトラの再-野生の識別（atrw）データセットには、多くのトラの写真と照明条件が含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-13">
        <br><font color="black">2019-06-13</font>
      </time>
    </span>
</section>
<!-- paper0: Memory Optimization for Deep Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_1.html">
      <font color="black">Memory Optimization for Deep Networks</font>
    </a>
  </h2>
  <font color="black">私たちのコードはhttps://github.com/utsaslab/MONeTで入手できます。同じ計算コストで、\ sysnameは現在の最先端の自動チェックポインティングフレームワークよりも1.2〜1.8倍少ないメモリを必要とします。MONeTはさまざまなPyTorchモデルの全体的なメモリ要件は3倍で、計算のオーバーヘッドは9〜16％です。 
[ABSTRACT] monetは、メモリフットプリントを最小限に抑える自動フレームワークです。monetは、以前のすべての手動調整操作よりも優れたパフォーマンスを発揮します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Modeling Extent-of-Texture Information for Ground Terrain Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_2.html">
      <font color="black">Modeling Extent-of-Texture Information for Ground Terrain Recognition</font>
    </a>
  </h2>
  <font color="black">次に、テクスチャの範囲（EoT）ガイド付きドメイン間メッセージパッシングモジュールは、テクスチャと形状の情報の範囲を、エンコードされたテクスチャと形状の情報とパッチごとに組み合わせて、知識を共有し、順序のないテクスチャのバランスを取ります。最後に、地面と地形の画像分類は、完全に接続されたレイヤーによって実行されます。さらに、バイリニアモデルは、無秩序なテクスチャ情報と順序付けられた形状情報の間のペアワイズ相関を生成します。 
[概要] `テクスチャ情報 &#39;は、パッチが相互に認識して豊富な特徴を学習するために使用されます。新しいモデルを使用して、順序のバランスを作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-17">
        <br><font color="black">2020-04-17</font>
      </time>
    </span>
</section>
<!-- paper0: CT Reconstruction with PDF: Parameter-Dependent Framework for Multiple
  Scanning Geometries and Dose Levels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_3.html">
      <font color="black">CT Reconstruction with PDF: Parameter-Dependent Framework for Multiple
  Scanning Geometries and Dose Levels</font>
    </a>
  </h2>
  <font color="black">実験は、提案された方法が特定のジオメトリと線量レベルでトレーニングされた元のネットワークと同様の競合するパフォーマンスを取得できることを示しています。これにより、複数のスキャンジオメトリと線量レベルの追加トレーニングコストを効率的に節約できます。提案されたPDFでは、ジオメトリと線量レベルはパラメータ化され、2つの多層パーセプトロン（MLP）に供給されます。深層学習に基づくCT再構成法の現在の主流は、通常、スキャンジオメトリと線量レベルを修正する必要があります。これにより、トレーニングコストが大幅に悪化し、より多くのトレーニングデータが必要になります。臨床応用。 
[概要]提案されたシステムは、複数のスキャンジオメトリと線量レベルで同時にデータをトレーニングするために使用できます。マッピングに10億ドルの費用がかかることが期待されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Feature-aware Adaptation and Density Alignment for Crowd Counting in
  Video Surveillance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_4.html">
      <font color="black">Feature-aware Adaptation and Density Alignment for Crowd Counting in
  Video Surveillance</font>
    </a>
  </h2>
  <font color="black">ただし、実世界のデータと合成画像の間のドメインギャップはモデルのパフォーマンスを低下させます。ギャップを減らすために、本論文では、合成からモデルを効果的に適応させることができるドメイン適応スタイルの群集カウント方法を提案します。特定の実世界のシーンへのデータ..これは、マルチレベルの機能認識適応（MFA）と構造化密度マップアライメント（SDA）で構成されています。 
[概要]以前の方法では、目に見えない領域にうまく一般化することはできませんが、実世界のデータと合成画像の間のギャップにより、モデルのパフォーマンスが低下します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-08">
        <br><font color="black">2019-12-08</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Exact Verification of Binarized Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_5.html">
      <font color="black">Efficient Exact Verification of Binarized Neural Networks</font>
    </a>
  </h2>
  <font color="black">Binarized Neural Networks（BNN）は同等のロバスト性を提供し、正確で大幅に効率的な検証を可能にすることを主張します。MNISTで重要な畳み込みBNNのL-inf制限の敵対的ロバスト性の最初の正確な検証結果を提示することにより、EEVの有効性を示します。およびCIFAR10データセット..ほとんどのベリファイアは実数値ネットワークで機能します。 
[概要] 2値化ニューラルネットワーク（bnns）は同等の堅牢性を提供し、正確で大幅に効率的な検証を可能にすることを主張します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br><font color="black">2020-05-07</font>
      </time>
    </span>
</section>
<!-- paper0: MMFT-BERT: Multimodal Fusion Transformer with BERT Encodings for Visual
  Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_6.html">
      <font color="black">MMFT-BERT: Multimodal Fusion Transformer with BERT Encodings for Visual
  Question Answering</font>
    </a>
  </h2>
  <font color="black">広範な実験により、私たちの方法の有効性と優位性が示されています。さらに、TVQAの分離された診断サブセットであるTVQA-Visualを提供します。これには、人間の注釈者の判断に基づく視覚（V）モダリティの知識が厳密に必要です。これによりSOTAの結果が得られます。 TVQAデータセット。 
[ABSTRACT] tvqaデータセットは、tvqaデータセットの視覚的なテスト結果を提供します。これらの質問は、モデルの動作と、超人的なパフォーマンスを防ぐために組み合わされた課題を調査するのに役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Probabilistic Imaging: Uncertainty Quantification and Multi-modal
  Solution Characterization for Computational Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_7.html">
      <font color="black">Deep Probabilistic Imaging: Uncertainty Quantification and Multi-modal
  Solution Characterization for Computational Imaging</font>
    </a>
  </h2>
  <font color="black">したがって、観測データを説明する可能性のある画像の空間を特徴づけることが重要です。このアプローチでは、トレーニングデータは必要ありません。代わりに、ニューラルネットワークの重みを最適化して、特定の測定データセットに適合する画像サンプルを生成します。DeepProbabilisticImaging（DPI）は、トレーニングされていない深層生成モデルを使用して、観測されていない画像の事後分布を推定します。 
[ABSTRACT]ディープ確率イメージング（dpi）は、トレーニングされていないディープジェニュティブモデルを使用して、観測されていない画像の事後分布を推定します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: On the Transfer of Disentangled Representations in Realistic Settings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_8.html">
      <font color="black">On the Transfer of Disentangled Representations in Realistic Settings</font>
    </a>
  </h2>
  <font color="black">1Mのシミュレーション画像と同じロボット設定の1,800を超える注釈付きの実世界画像を含む新しい高解像度データセットを紹介します。解きほぐされた表現学習を現実的な高解像度設定にスケーリングし、大規模に実施するために、新しいアーキテクチャを提案します。このデータセットの解きほぐされた表現の実証的研究..解きほぐしは、分布外（OOD）タスクのパフォーマンスの優れた予測因子であることがわかります。 
[ABSTRACT]解きほぐされた表現は、さまざまなタスクに役立つことがわかりました。しかし、それらのスケーラビリティと実際の世界への影響には疑問が残ります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Synthetic Training for Monocular Human Mesh Recovery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_9.html">
      <font color="black">Synthetic Training for Monocular Human Mesh Recovery</font>
    </a>
  </h2>
  <font color="black">さらに印象的なことに、近接ショット画像のパフォーマンスは、弱い監視のために提案されたD2S投影を使用して大幅に改善されますが、計算効率の明らかな優位性を維持します。したがって、深度差を組み込むための深度対スケール（D2S）投影を提案します。より適切な監視のために関節ごとのスケールバリアントを導出する投影関数。さらに、一般化能力を強化するために、ほとんどの既存の方法は、3Dから2Dへの投影を介して推定された3Dポーズを監視するために野生の2Dポーズデータセットを使用しました。 。 
[概要]新しい論文は、単一のrgb画像から大きなスケールの違いがある3Dメッシュを推定することを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Artificial intelligence based writer identification generates new
  evidence for the unknown scribes of the Dead Sea Scrolls exemplified by the
  Great Isaiah Scroll (1QIsaa) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_10.html">
      <font color="black">Artificial intelligence based writer identification generates new
  evidence for the unknown scribes of the Dead Sea Scrolls exemplified by the
  Great Isaiah Scroll (1QIsaa)</font>
    </a>
  </h2>
  <font color="black">明確な相転移は、列27の周りに明らかです。2つの半分の間の統計的に有意な差を考慮して、3次の事後分析が実行されました。スペースでは、原稿の前半と後半の列が、特にさまざまなデジタル古書体ツールの場合、そのような散布図の2つの異なるゾーンに配置され、それぞれがスクリプトサンプルの非常に異なる機能的側面に対応していることがわかりました。 
[要約]古書体学-古代の手書きの研究-は書記文化へのアクセスを提供することができます。これは1qisaaの偉大なイザヤの巻物によって例示されています。最後に、この巻物の一連の列のブレークポイントの新しい証拠を報告します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-end trainable network for degraded license plate detection via
  vehicle-plate relation mining -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_11.html">
      <font color="black">End-to-end trainable network for degraded license plate detection via
  vehicle-plate relation mining</font>
    </a>
  </h2>
  <font color="black">次に、ナンバープレートの四隅を回帰して斜めのナンバープレートを確実に検出することにより、ローカル領域の四辺形の境界ボックスを予測することを提案します。広範な実験により、提案された小型および斜めのナンバープレートに対する方法の有効性が検証されます。さらに、ネットワーク全体をエンドツーエンドでトレーニングできます。 
[概要]小さい-小さい-サイズの曲がったナンバープレートは検出が困難です。これらには、主に遠方のモバイルカメラが原因の小さい-サイズのプレートが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: A Bayesian Filter for Multi-view 3D Multi-object Tracking with Occlusion
  Handling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_12.html">
      <font color="black">A Bayesian Filter for Multi-view 3D Multi-object Tracking with Occlusion
  Handling</font>
    </a>
  </h2>
  <font color="black">提案されたアルゴリズムは、最新のWILDTRACKSデータセットで評価され、新しいデータセットの非常に混雑したシーンで機能することが実証されています。重要な革新は、最適なベイズマルチビューマルチオブジェクトフィルタリングに適した、忠実度が高く扱いやすい3Dオクルージョンモデルです。これは、単一のベイジアン再帰に、トラック管理、状態推定、クラッター除去、およびオクルージョン/誤検出処理のサブタスクをシームレスに統合します。このペーパーでは、単眼検出器のトレーニングのみを必要とするオンラインマルチカメラマルチオブジェクトトラッカーを提案します。マルチカメラ構成に依存しないため、再トレーニングを行わなくてもカメラをシームレスに拡張/削除できます。 
[概要]提案されたアルゴリズムは、カメラ全体の検出の総数が線形的に複雑であるため、カメラの数に応じて適切にスケーリングされます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br><font color="black">2020-01-13</font>
      </time>
    </span>
</section>
<!-- paper0: Reconfigurable Voxels: A New Representation for LiDAR-Based Point Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_13.html">
      <font color="black">Reconfigurable Voxels: A New Representation for LiDAR-Based Point Clouds</font>
    </a>
  </h2>
  <font color="black">このアプローチにより、特にスパース領域のボクセル機能の安定性が効果的に向上することが経験的にわかりました。nuScenes、Lyft、KITTIなどの複数のベンチマークでの実験結果は、この新しい表現が小さくて離れたオブジェクトの検出パフォーマンスを大幅に向上させることを示しています。 、顕著なオーバーヘッドコストを発生させることなく..この困難に取り組むために、3Dポイントクラウドから表現を構築するための新しいアプローチである再構成可能ボクセルを提案します。 
[概要]新しい方法は、目立ったオーバーヘッドコストを発生させることなく、小さくて遠くのオブジェクトの検出パフォーマンスを向上させることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: Decentralized Attribution of Generative Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_14.html">
      <font color="black">Decentralized Attribution of Generative Models</font>
    </a>
  </h2>
  <font color="black">この結果は、MNISTとCelebAで検証されます。このペーパーでは、各モデルを本物のデータと区別できるようにするだけで証明可能な帰属を実現できる分散型帰属を研究します。同じデータセットから学習した生成モデルのセットを考えると、帰属可能性は生成されたコンテンツのソースモデルを正しく識別するための公開検証サービスが存在する場合に達成されます。 
[概要]各モデルを本物のデータと区別できるようにするだけで帰属を達成できるという懸念があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: A Multi-task Two-stream Spatiotemporal Convolutional Neural Network for
  Convective Storm Nowcasting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_15.html">
      <font color="black">A Multi-task Two-stream Spatiotemporal Convolutional Neural Network for
  Convective Storm Nowcasting</font>
    </a>
  </h2>
  <font color="black">結果として得られる2ストリームの融合畳み込みニューラルネットワークでは、一部のパラメーターが1ストリームの畳み込みニューラルネットワークに入力されますが、多くのデータの特徴を学習できます。2ストリームのマルチタスク学習を1つの単一ストリームに統合します。畳み込みニューラルネットワーク..これにより、ネットワーク構造が簡素化され、必要なトレーニング時間が短縮され、分類の精度が向上します。 
[ABSTRACT]ナウキャスティングへの対流性ストームは対流性ストームです。簡潔な2ストリーム畳み込みニューラルネットワークを使用して、ナウキャスティングの空間およびスケジューリングの手がかりを抽出します。レーダーと衛星データを使用するネットワークを簡素化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Fourth-Order Nonlocal Tensor Decomposition Model for Spectral Computed
  Tomography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_16.html">
      <font color="black">Fourth-Order Nonlocal Tensor Decomposition Model for Spectral Computed
  Tomography</font>
    </a>
  </h2>
  <font color="black">この論文では、スペクトルCT画像再構成（FONT-SIR）法の4次非局所テンソル分解モデルを提案します。スペクトルコンピュータ断層撮影（CT）は、フォトンカウンティング検出器（PCD）を使用してさまざまなエネルギービンからスペクトル画像を再構成できます。次に、生成された4次テンソルユニットに対して低ランクとスパース性の分解が実行され、加重核ノルムと全変動（TV）ノルムが、それぞれ低ランクとスパース性の制約を適用するために使用されます。 
[概要]研究者は新しいフォントを提案しました-サー。彼らはシミュレーションと実際のデータセットの両方で優れた資格と定量的パフォーマンスを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: A Method of Generating Measurable Panoramic Image for Indoor Mobile
  Measurement System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_17.html">
      <font color="black">A Method of Generating Measurable Panoramic Image for Indoor Mobile
  Measurement System</font>
    </a>
  </h2>
  <font color="black">画像スティッチングでは、グラフカットベースの方法を使用して重なり合う領域の最適なシームラインを検索し、幾何学的影響を軽減し、ピラミッドマルチバンドに基づく画像ブレンディングを利用して、スティッチングライン付近の測光効果を排除します。メソッドは、データ収集プラットフォームからのデータでテストされ、満足のいくアプリケーションの見通しを示します。各ピクセルは深度値に関連付けられているため、この深度値を球形投影の半径として設計し、パノラマ画像をさらに投影できます。世界を調整し、その結果、高品質の測定可能なパノラマ画像を生成します。 
[概要] 3Dポイントと画像データの融合のために、2D高密度深度マップを作成します。信頼性の高いキャリブレーションおよび同期されたセンサーに基づいて、コンセプトを作成するためのツールを作成しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Improved inter-scanner MS lesion segmentation by adversarial training on
  longitudinal data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_18.html">
      <font color="black">Improved inter-scanner MS lesion segmentation by adversarial training on
  longitudinal data</font>
    </a>
  </h2>
  <font color="black">最後に、ベースモデルとディスクリミネーターは、マルチスキャナーの縦断的データで敵対的にトレーニングされ、ベースモデルのスキャナー間の一貫性が向上します。次に、ディスクリミネーターモデルがトレーニングされ、2つの病変セグメンテーションが同じものを使用して取得されたスキャンに基づいているかどうかが予測されます。スキャナーの種類の有無にかかわらず、このタスクで78％の精度を達成します。現在の自動病変セグメンテーションアルゴリズムは、MRIスキャナーまたはプロトコルの違いに関連する画像特性の変動の影響を受けます。 
[ABSTRACT]病変セグメンテーションアルゴリズムは、MRIスキャナーまたはプロトコルの違いに関連する画像特性の変動の影響を受けやすく、基本モデルの精度を達成するために重要なデータについて敵対的に訓練されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br><font color="black">2020-02-03</font>
      </time>
    </span>
</section>
<!-- paper0: Triple-view Convolutional Neural Networks for COVID-19 Diagnosis with
  Chest X-ray -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_19.html">
      <font color="black">Triple-view Convolutional Neural Networks for COVID-19 Diagnosis with
  Chest X-ray</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案された方法が、特により困難な3つのクラス分類タスクで最先端のパフォーマンスを達成し、広い一般性と高い柔軟性を認めることを示しています。大規模な医療CXRデータを収集するため、データの不足は別の問題です。セットは現在難しいかもしれません。コロナウイルス病2019（COVID-19）は世界中でますます多くの人々に影響を及ぼしており、医療システムに重大なストレスをもたらしています。 
[要約] covid-19は、1つの画像のみを生成するcxrスキャンです。これは、利用可能な限られたサンプルからより多くの特徴を抽出することが難しいことを意味します。これらには、左肺ビュー、右肺ビュー、および全体的な診断を含むこれらの特徴が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Semantic Visual Navigation by Watching YouTube Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_20.html">
      <font color="black">Semantic Visual Navigation by Watching YouTube Videos</font>
    </a>
  </h2>
  <font color="black">パッシブデータからのこのようなポリシー外のQ学習は、ナビゲーションの意味的なセマンティックキューを学習できることを示します。これらのキューを階層型ナビゲーションポリシーで使用すると、視覚的にリアルなシミュレーションでObjectGoalタスクの効率が向上します。最小限の直接相互作用を使用しながら、エンドツーエンドRL、動作クローニング、および従来の方法に比べて15〜83％の相対的な改善が見られます。 
[概要]このペーパーでは、YouTube動画を視聴することで、このようなセマンティックキューを学習し、新しい環境のオブジェクトにナビゲートするために活用します。この方法では、qを使用してこれらの課題に取り組みます。疑似ラベル付き遷移4倍（画像、アクション、次の画像、褒賞 ）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br><font color="black">2020-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: Down to the Last Detail: Virtual Try-on with Detail Carving -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_21.html">
      <font color="black">Down to the Last Detail: Virtual Try-on with Detail Carving</font>
    </a>
  </h2>
  <font color="black">標準データセットでの広範な実験は、提案されたフレームワークが、特に衣服の質感と顔のアイデンティティの視覚的な詳細を維持することにおいて、最先端のパフォーマンスを達成することを示しています。複数の段階のエンドツーエンドのトレーニングにより、フレームワーク全体が視覚的忠実度が大幅に向上し、細部がより豊かな結果が得られるように共同で最適化されます。衣服や顔の領域などの顕著な領域の細部をより適切に保存するために、ツリーブロック（ツリー拡張フュージョンブロック）を提案して、ジェネレータネットワーク。 
[概要]生成を空間アラインメントに分解するために、マルチステージフレームワークが提案されています。フレームワーク全体を共同で最適化して、視覚的忠実度と詳細を大幅に向上させることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-13">
        <br><font color="black">2019-12-13</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Infer Unseen Attribute-Object Compositions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_22.html">
      <font color="black">Learning to Infer Unseen Attribute-Object Compositions</font>
    </a>
  </h2>
  <font color="black">既存の手法のほとんどは、単一属性オブジェクトの構図認識に限定されており、外観が似ている構図を区別することはほとんどできません。さらに、116,099枚の画像と8,030枚の画像を含む大規模な多属性データセット（MAD）を構築します。構成カテゴリ..モデルは、画像の視覚的特徴と、単語埋め込みベクトルによって表される属性オブジェクトカテゴリラベルを潜在空間にマッピングします。 
[概要]モデルは、画像の視覚的特徴と属性（単語埋め込みシールドで表されるオブジェクトカテゴリラベル）を潜在空間にマッピングします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Structured Visual Search via Composition-aware Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_23.html">
      <font color="black">Structured Visual Search via Composition-aware Learning</font>
    </a>
  </h2>
  <font color="black">MS-COCOとHICO-DETの2つの大規模ベンチマークでの実験は、私たちのアプローチが競合する手法に対するパフォーマンスの大幅な向上につながることを示しています。モデル出力は、入力変換に関して対称的に変化するようにトレーニングされており、機密性の高い特徴空間..そうすることで、より小さな特徴空間を使用してより少ないデータから学習するため、非常に効率的な検索手法につながります。 
[概要]構造は、オブジェクトの位置とカテゴリをエンコードする2Dコンポジションの形式です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Micro-CT Synthesis and Inner Ear Super Resolution via Bayesian
  Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_24.html">
      <font color="black">Micro-CT Synthesis and Inner Ear Super Resolution via Bayesian
  Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">超解像タスクのためのサイクル整合性生成敵対的ネットワークを探索し、翻訳アプローチにベイジアン推論を装備します。さらに、マルチ評価者の視覚的評価実験を実行し、訓練を受けた専門家が提案された方法の最高品質スコアを一貫して評価することを発見しました。メソッド..エンドツーエンドの学習タスクとしてアプローチを実装すると、対になっていない翻訳タスクの不確実性を定量化し、不確実性マスクが側頭骨の構造情報を提供できることがわかります。 
[概要]これらの画像は、臨床現場では利用できないことがよくあります。これらの画像は、視覚的および定量的な改善の状態に依存しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Hyperspectral Anomaly Change Detection Based on Auto-encoder -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_25.html">
      <font color="black">Hyperspectral Anomaly Change Detection Based on Auto-encoder</font>
    </a>
  </h2>
  <font color="black">最終的に、2つの方向の2つの損失マップの最小値を最終的な異常変化強度マップとして使用します。提案されたACDAは、複雑なイメージング条件に直面したときに効果的な予測モデルを構築できます。公開された「Viareggio2013」データセットでの実験結果は従来の方法に対する効率と優位性。 
[概要]ハイパースペクトル情報情報の変化の検出（hacd）は、マルチテンポラルハイパースペクトル画像（hsi）間の小さいが重要な異常変化を見つけるのに役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: DEAL: Deep Evidential Active Learning for Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_26.html">
      <font color="black">DEAL: Deep Evidential Active Learning for Image Classification</font>
    </a>
  </h2>
  <font color="black">ラベル付けに最も有益で代表的なデータインスタンスを選択することにより、ALはモデルのより効率的な学習に貢献できます。CNNの最近のALメソッドは、ラベル付けするインスタンスの選択にさまざまなソリューションを提案します。畳み込みニューラルネットワーク（CNN）が証明されています画像分類などの監視対象のコンピュータビジョンタスクの最先端モデルになること。 
[ABSTRACT] cnnの最近のalメソッドは、ラベル付けするインスタンスを選択するためのさまざまなソリューションを提供します。ただし、このようなモデルのトレーニングと検証には、通常、大きなラベル付きデータセットが必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: An Adaptive Intelligence Algorithm for Undersampled Knee MRI
  Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_27.html">
      <font color="black">An Adaptive Intelligence Algorithm for Undersampled Knee MRI
  Reconstruction</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、独立したチャレンジデータセットでfastMRI主催者によって評価されました。ネットワークは、Facebook AIResearchとNYULangoneHealthによって組織された2019fastMRIチャレンジからの膝MRIデータセットでトレーニングされ、テストされました。これは、優れたパフォーマンスと幅広い適用性を示しています。メソッドの。 
[要約]課題は、既知の根拠との類似性に基づいていました。上位4件の提出物は放射線学的に評価されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-15">
        <br><font color="black">2020-04-15</font>
      </time>
    </span>
</section>
<!-- paper0: Impact of Spherical Coordinates Transformation Pre-processing in Deep
  Convolution Neural Networks for Brain Tumor Segmentation and Survival
  Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_28.html">
      <font color="black">Impact of Spherical Coordinates Transformation Pre-processing in Deep
  Convolution Neural Networks for Brain Tumor Segmentation and Survival
  Prediction</font>
    </a>
  </h2>
  <font color="black">この作業では、球面座標変換が前処理方法として適用され、通常のMRIボリュームと組み合わせて使用され、脳腫瘍セグメンテーション（BraTS）チャレンジ2020データセットでの脳腫瘍セグメンテーションと患者の全生存（OS）予測の精度が向上します.. LesionEncoderフレームワークが適用され、DCNNモデルから特徴が自動的に抽出され、検証データセットでOS予測の精度が0.586になりました。これは、BraTS2020リーダーボードによると最高の結果の1つです。前処理とデータ拡張プレイDeep Convolutional Neural Networks（DCNN）における重要な役割。 
[概要]新しい方法は、dcnnに球形の空間変換データを供給することを目的としています。その後、dcnnモデルから特徴を自動的に抽出するために適用されました。腫瘍データは、brats2020リーダーボードによると最良の結果の1つです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Denoising Prior Driven Deep Neural Network for Image Restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_29.html">
      <font color="black">Denoising Prior Driven Deep Neural Network for Image Restoration</font>
    </a>
  </h2>
  <font color="black">画像のノイズ除去、超解像、ぼけ除去など、いくつかのIRタスクに関する実験結果は、提案された方法が、画像のノイズ除去、ぼけ除去、超ぼけなど、いくつかのIRタスクで非常に競争力のある最先端の結果をもたらす可能性があることを示しています。解像度..自然画像のマルチスケール冗長性を活用できる畳み込みニューラルネットワーク（CNN）ベースのノイズ除去装置が提案されています。そのため、提案されたネットワークは、DNNの強力なノイズ除去機能を活用するだけでなく、観測モデル。 
[概要]ネットワークアーキテクチャは、ネットワークアーキテクチャの品質にとって依然として大きな課題です。ネットワークアーキテクチャは、ネットワークアーキテクチャによって簡単に管理できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-01-21">
        <br><font color="black">2018-01-21</font>
      </time>
    </span>
</section>
<!-- paper0: SIRI: Spatial Relation Induced Network For Spatial Description
  Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_30.html">
      <font color="black">SIRI: Spatial Relation Induced Network For Spatial Description
  Resolution</font>
    </a>
  </h2>
  <font color="black">さらに、位置情報の欠如を修正するためにグローバル位置の事前情報を導入します。これにより、グローバルな位置推論のあいまいさが生じる可能性があります。言語的特徴と視覚的特徴の両方が連結されて、ターゲットのローカリゼーションが完成します。具体的には、視覚的特徴は最初に暗黙的に相関されます。投影された潜在空間のオブジェクトレベル。次に、それらは各空間関係ワードによって抽出され、各空間関係を表すそれぞれ異なるアクティブ化された機能が生成されます。 
[ABSTRACT]視覚的特徴は、投影された潜在空間の明示的なオブジェクトレベルで相関します。それらは、各空間関係の単語によって抽出され、各通りを表す正確な場所になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Are scene graphs good enough to improve Image Captioning? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_31.html">
      <font color="black">Are scene graphs good enough to improve Image Captioning?</font>
    </a>
  </h2>
  <font color="black">さらに、予測されたシーングラフの品質は一般に非常に低いですが、高品質のシーングラフを使用すると、強力なボトムアップトップダウンベースラインと比較して最大3.3 CIDErのゲインが得られます。最後に、ノイズの程度を判断します。予測されたシーングラフでは、キャプションの品質に影響を与えます。多くの最高の画像キャプションモデルは、画像の説明を生成するために、オブジェクト検出モデルで計算されたオブジェクトの特徴のみに依存しています。 
[概要]多くのモデルはシーングラフ機能を使用し、モデルはさまざまなキャプションメトリック全体でオブジェクト検出機能のみを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-25">
        <br><font color="black">2020-09-25</font>
      </time>
    </span>
</section>
<!-- paper0: Mining Generalized Features for Detecting AI-Manipulated Fake Faces -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_32.html">
      <font color="black">Mining Generalized Features for Detecting AI-Manipulated Fake Faces</font>
    </a>
  </h2>
  <font color="black">次に、オクターブ畳み込み（OctConv）と注意ベースの融合モジュールを導入して、CDIとSIから固有の機能を効果的かつ適応的にマイニングします。最後に、操作手法のバイアスを排除してより一般化された検出を取得するアライメントモジュールを設計します。フレームワーク..この問題を解決するために、固有の機能をマイニングし、分布バイアスをさらに排除して一般化能力を向上させることに焦点を当てた新しいフレームワークを提案します。 
[概要]クロスマニピュレーション手法間の分布バイアスのため、「見えない」マニピュレーション手法の使用は依然として不十分です。提案されたフレームワークの一般化能力をさらに検証するために、フェイクアートの実験を行います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Skeletonization for Plant Root Structure Reconstruction from MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_33.html">
      <font color="black">Robust Skeletonization for Plant Root Structure Reconstruction from MRI</font>
    </a>
  </h2>
  <font color="black">22のMRIスキャンでメソッドを評価し、人間の専門家による再構成と比較します。このタスクには2段階のアプローチを提案します。最初の段階は、セマンティックルートと土壌セグメンテーションに基づいており、任意のルートボクセルから最低コストのパスを見つけます。シュートに。 
[概要]第1段階は理解不足に基づいています。第2段階では、生成された最大の完全連結成分を取得します。3Dスケルトン化を使用してグラフ構造を抽出します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Thinking in Frequency: Face Forgery Detection by Mining Frequency-aware
  Clues -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_34.html">
      <font color="black">Thinking in Frequency: Face Forgery Detection by Mining Frequency-aware
  Clues</font>
    </a>
  </h2>
  <font color="black">ただし、最近の進歩により、特に圧縮された画像やビデオでは、人間の目の知覚能力を超えて顔を偽造できるため、非常に困難です。周波数を意識した偽造パターンのマイニングは、周波数が提供するため、治療法になる可能性があります。微妙な偽造アーティファクトまたは圧縮エラーのいずれかを十分に説明できる補完的な視点..顔偽造検出に周波数を導入するために、2つの異なるが補完的な周波数認識を利用して、顔偽造ネットワーク（F3-Net）の新しい周波数を提案します。手がかり、1）周波数を意識した分解された画像コンポーネント、および2）ローカル周波数統計。2ストリームの共同学習フレームワークを介して偽造パターンを深く掘り下げます。 
[要約]提案されたf3-は、挑戦的なフェイスフォレンジックデータセットのすべての圧縮品質において、競合する最先端の手法をはるかに上回っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-18">
        <br><font color="black">2020-07-18</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-directional Feature Fusion Network for Building Damage Assessment
  from Satellite Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_35.html">
      <font color="black">Cross-directional Feature Fusion Network for Building Damage Assessment
  from Satellite Imagery</font>
    </a>
  </h2>
  <font color="black">さらに、データ拡張メソッドCutMixは、ハードクラスの課題に取り組むために利用されます。ただし、ほとんどの既存の作品は、相関関係を考慮せずに、災害前と災害後の画像を入力として使用します。 
[概要]高解像度の衛星画像は、分析のために災害前と災害後のシーンに関する豊富な情報を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Dendrite Net: A White-Box Module for Classification, Regression, and
  System Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_36.html">
      <font color="black">Dendrite Net: A White-Box Module for Classification, Regression, and
  System Identification</font>
    </a>
  </h2>
  <font color="black">第三に、MNISTおよびFASHION-MNISTデータセットにより、DDは、分類のためにCell bodyNetよりも大きなトレーニング損失の下で高いテスト精度を示したことが確認されました。DDコードはhttps://github.com/liugang1234567/Gang-neuronで入手できます。実験と結果：最初のホワイトボックスマシン学習アルゴリズムであるDDは、ブラックボックスシステムに対して優れたシステム識別パフォーマンスを示しました。 
[ABSTRACT] ddの主な概念は、出力の論理式に対応するクラスの論理関係が含まれている場合、アルゴリズムは学習後にこのクラスを認識できるということです。これは、ddがより優れた一般化機能をもたらした9つの実世界のアプリケーションによって検証されました。ニューロンのセルボディネットを模倣したmlpアーキテクチャと比較して</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br><font color="black">2020-04-08</font>
      </time>
    </span>
</section>
<!-- paper0: DISK: Learning local features with policy gradient -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_37.html">
      <font color="black">DISK: Learning local features with policy gradient</font>
    </a>
  </h2>
  <font color="black">1、3つの公開ベンチマークで最先端の結果を提供します。シンプルでありながら表現力豊かな確率モデルにより、トレーニングと推論の体制を緊密に保ちながら、最初から確実にトレーニングするのに十分な収束特性を維持できます。図に示すように、何が良いキーポイントを構成するかについて、識別力があり、一般的に保持されている仮定に挑戦しながら、非常に密に抽出されます。
[要約]システムは、強化された学習の原則を活用することによって障害を克服する新しい方法です（rl）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-24">
        <br><font color="black">2020-06-24</font>
      </time>
    </span>
</section>
<!-- paper0: UDBNET: Unsupervised Document Binarization Network via Adversarial Game -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_38.html">
      <font color="black">UDBNET: Unsupervised Document Binarization Network via Adversarial Game</font>
    </a>
  </h2>
  <font color="black">後で、クリーンな画像とその生成された劣化バージョンが、教師なしドキュメント二値化ネットワーク（UDBNet）のトレーニングに使用される疑似ペアデータを構成します。実験結果は、提案されたモデルの既存の状態よりも優れたパフォーマンスを示しています。 -広く使用されているDIBCOデータセットのアートアルゴリズム。このアプローチに従って、コンテンツ機能は同じでテキスト機能が異なる複数の画像を生成するため、ドキュメントの2値化データセットを拡大しました。 
[概要]敵対的なテクスチャ拡張ネットワーク（atanet）は、最初に、劣化した参照画像のテクスチャをクリーンな画像に重ね合わせます。共同弁別器は、udbnetに画像のパフォーマンスを向上させるように強制します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-14">
        <br><font color="black">2020-07-14</font>
      </time>
    </span>
</section>
<!-- paper0: A Simple and Efficient Registration of 3D Point Cloud and Image Data for
  Indoor Mobile Mapping System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_39.html">
      <font color="black">A Simple and Efficient Registration of 3D Point Cloud and Image Data for
  Indoor Mobile Mapping System</font>
    </a>
  </h2>
  <font color="black">初期ポーズの精度と3Dポイントと画像データの統合の適用性を向上させるために、シンプルで効率的な登録方法を開発します。その後、Canny画像エッジ検出に基づいてコストマップを作成します。3DLiDARポイントクラウドの登録マルチソースデータの組み合わせでは、光学画像を使用することが重要です。 
[ABSTRACT]ポイントフィーチャはシングルフレームライダーから抽出され、ポイントフィーチャは従来のキャニーメソッドを使用して画像から抽出されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Image-to-Image Translation via Pre-trained StyleGAN2
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_40.html">
      <font color="black">Unsupervised Image-to-Image Translation via Pre-trained StyleGAN2
  Network</font>
    </a>
  </h2>
  <font color="black">提案された方法が、最先端の作品と比較して、画質、多様性、入力画像および参照画像との意味的類似性の点で優れたパフォーマンスを達成できることを証明するために、定性的および定量的評価の両方が行われました。これには多くの計算が必要です。リソース..その後、画像とその潜在ベクトル間の変換を実現するための反転方法を提案しました。 
[概要]ターゲットドメインで新しいモデルを生成する新しいi2i変換方法を提案しました。新しい方法では、モデルモデルを使用してモデルの画像を作成します。結果の品質は低く、アーティファクトが多く含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: Ice Monitoring in Swiss Lakes from Optical Satellites and Webcams using
  Machine Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_41.html">
      <font color="black">Ice Monitoring in Swiss Lakes from Optical Satellites and Webcams using
  Machine Learning</font>
    </a>
  </h2>
  <font color="black">私たちの衛星ベースの方法では、両方のセンサーで平均交差オーバーユニオン（mIoU）スコア&gt; 93％と69％（約）が得られます。湖の氷の監視をピクセル単位のセマンティックセグメンテーション問題としてモデル化します。つまり、湖の表面の各ピクセルを分類して、空間的に明示的な氷の覆いのマップを取得します。 
[概要]レイクアイスは、地球規模の気候観測システム（gcos）の重要な気候変数に含まれています。マルチスペクトル光学衛星画像（viirsおよびmodis）とrgbウェブカメラ画像は、提案されたシステムが一貫して良好な結果をもたらすことを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Probing Contextual Language Models for Common Ground with Visual
  Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_42.html">
      <font color="black">Probing Contextual Language Models for Common Ground with Visual
  Representations</font>
    </a>
  </h2>
  <font color="black">全体として、私たちの調査結果は、言語の基礎と文脈言語モデルにおけるその具体化に関する新しい経験的洞察を導き出しました。プローブの選択性を証明する、対照実験でははるかに弱い結果が見つかりました。大規模な文脈言語モデルは最近大きな成功を収めていますが、それらの表現に何がエンコードされているかについては、まだ理解されていないことがたくさんあります。 
[概要]コンテキスト表現が参照するオブジェクトの物理的プロパティにどのように関連するかを特徴付けます。最近の多くの言語モデルが、意味的に整列された画像パッチの取得に役立つ表現を生成することを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: Pixel-based Facial Expression Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_43.html">
      <font color="black">Pixel-based Facial Expression Synthesis</font>
    </a>
  </h2>
  <font color="black">わずかに異なる分布からの画像をテストすると、GAN結果の品質が大幅に低下します。提案された方法は、数百のトレーニング画像のみを活用することで優れた一般化機能を実現します。さらに、提案されたモデルは2桁小さいため、リソースに制約のあるデバイスへの展開に適しています。 
[概要]提案手法は、数百枚のトレーニング画像のみを活用することにより、優れた一般化機能を実現しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Sequential Learning for Cervical Spine Fracture Detection on
  Computed Tomography Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_44.html">
      <font color="black">Deep Sequential Learning for Cervical Spine Fracture Detection on
  Computed Tomography Imaging</font>
    </a>
  </h2>
  <font color="black">検証結果は、平衡（104陽性および104陰性症例）および不平衡（104陽性および419陰性症例）テストデータセットでそれぞれ70.92％および79.18％の分類精度を示しています。頸椎の骨折は救急医療であり、永久的な麻痺、さらには死に至る可能性があります。コンピューター断層撮影（CT）による骨折が疑われる患者の正確な診断は、患者の管理にとって重要です。 
[ABSTRACT]詳細なデータセットは、モデルのトレーニングと検証に使用されます。結果は、患者管理にとって重要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Fit to Measure: Reasoning about Sizes for Robust Object Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_45.html">
      <font color="black">Fit to Measure: Reasoning about Sizes for Robust Object Recognition</font>
    </a>
  </h2>
  <font color="black">特に、ビジュアルインテリジェンスの認識論的要件を特定するための以前の作業に基づいて、オブジェクトの典型的なサイズの知識がオブジェクト認識システムの精度を大幅に向上させる可能性があると仮定します。この仮説を検証するために、この論文ではMLベースのアーキテクチャにオブジェクトサイズに関する知識を統合するためのアプローチ。このコンテキストでは、ロボットのビジュアルインテリジェンスを改善するための最初の前提条件は、堅牢で信頼性の高いオブジェクト認識システムを構築することです。 
[抽象]オブジェクト認識ソリューションは、伝統的に機械学習epに基づいていますが、これによりパフォーマンスが向上することが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Reconstruction of Voxels with Position- and Angle-Dependent Weightings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_46.html">
      <font color="black">Reconstruction of Voxels with Position- and Angle-Dependent Weightings</font>
    </a>
  </h2>
  <font color="black">これは再構成の基本的な制限です。この作業では、最初にシステム行列と重み付け部分の観点からこの再構成問題を定式化します。疑似逆行列を計算し、解がランク不足であるため、非常に不適切であることを示します。 
[概要]これにより、システムマトリックスが変更され、標準のフィルター処理された逆投影の使用が禁止されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: A Solution to Product detection in Densely Packed Scenes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_47.html">
      <font color="black">A Solution to Product detection in Densely Packed Scenes</font>
    </a>
  </h2>
  <font color="black">その結果、SKU-110kのテストセットで58.7 mAPが得られます。密集したシーンの本質的な特徴を把握するために、検出器のステージを分析し、パフォーマンスを制限するボトルネックを調査します。作業を変更します。カスケードR-CNNから。 
[概要]メソッドにはトリックが詰め込まれ、ハイパーキャプテンを最適化します。これは、さまざまなトリックがロードされたメソッドのメソッドの結果です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-23">
        <br><font color="black">2020-07-23</font>
      </time>
    </span>
</section>
<!-- paper0: Hard Example Generation by Texture Synthesis for Cross-domain Shape
  Similarity Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_48.html">
      <font color="black">Hard Example Generation by Texture Synthesis for Cross-domain Shape
  Similarity Learning</font>
    </a>
  </h2>
  <font color="black">ネガティブペア間の形状の違いがテクスチャギャップと絡み合っており、ネガティブペアを押しのけるのにメトリック学習が無効になっていることがわかります。画像ベースの3D形状検索（IBSR）は、特定の2D画像の対応する3D形状を大規模な3D形状データベース..3D形状モデルのテクスチャを合成すると、ハードトリプレットが作成され、2D画像の豊富なテクスチャの悪影響が抑制されるため、ネットワークは幾何学的特性の発見にさらに集中するようになります。 
[概要]一般的なルーチンは、2D画像と3D形状を埋め込みスペースにマッピングし、形状の類似性の尺度を定義（または学習）することです。この論文では、パフォーマンスの低下の原因を特定し、この問題の実用的な解決策を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-23">
        <br><font color="black">2020-10-23</font>
      </time>
    </span>
</section>
<!-- paper0: Bayesian Bits: Unifying Quantization and Pruning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_49.html">
      <font color="black">Bayesian Bits: Unifying Quantization and Pruning</font>
    </a>
  </h2>
  <font color="black">ベイジアンビットは、量子化演算の新しい分解を採用し、ビット幅を2倍にすることを順次検討します。ベイジアンビットは、学習可能な確率ゲートを導入します。これは、指定されたテンソルのビット幅を集合的に制御します。新しいビット幅ごとに、完全な精度値と以前に丸められた値が量子化されます。 
[ABSTRACT]剪定された混合精度ネットワークは、静的ビット幅の同等物よりも精度と効率のトレードオフが優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-14">
        <br><font color="black">2020-05-14</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Word Recognition using Multiple Hypotheses and Deep Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_50.html">
      <font color="black">Improving Word Recognition using Multiple Hypotheses and Deep Embeddings</font>
    </a>
  </h2>
  <font color="black">ヒンディー語の本のコレクションに対して、提案された方法を体系的に厳密に評価します。単語画像の埋め込みを使用して単語認識の精度を向上させるための新しいスキームを提案します。訓練されたテキスト認識機能を使用して、与えられた単語の画像。 
[概要]複数のテキスト理論を予測できる訓練されたテキスト認識機能を使用します。私たちの方法は、単語認識の精度に関して約10％の絶対的な改善を達成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Fast Local Attack: Generating Local Adversarial Examples for Object
  Detectors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_51.html">
      <font color="black">Fast Local Attack: Generating Local Adversarial Examples for Object
  Detectors</font>
    </a>
  </h2>
  <font color="black">私たちの方法で生成された敵対的な例は、アンカーのないオブジェクト検出器を攻撃できるだけでなく、アンカーベースのオブジェクト検出器を攻撃するために転送することもできます。その結果、計算量が少なくなり、より高いブラックボックスが実現します。攻撃と攻撃パフォーマンスの転送..ほとんどの既存の研究は、画像分類器またはアンカーベースのオブジェクト検出器の攻撃に焦点を当てていますが、それらは画像全体にグローバルな摂動を生成します。これは不要です。 
[ABSTRACT]敵対的な摂動が画像に追加されています。これにより、アンカーの非常に攻撃的な局所摂動が作成されます-フリーオブジェクト検出器</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Odometry and Mapping for Multi-LiDAR Systems with Online
  Extrinsic Calibration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_52.html">
      <font color="black">Robust Odometry and Mapping for Multi-LiDAR Systems with Online
  Extrinsic Calibration</font>
    </a>
  </h2>
  <font color="black">さらに、グローバルマップを構築し、データの不確実性をモデル化して削減する方法とともに、十分な機能を備えたポーズを最適化するマッピングアルゴリズムを開発します。提案された作業が、さまざまなマルチLiDARセットアップ用の完全で堅牢かつ拡張可能なシステムであることを示します。 ..モーションおよび外部初期化手順の後、スライディングウィンドウベースのマルチLiDARオドメトリがオンボードで実行され、オンラインキャリブレーションの改良と収束の識別によってポーズを推定します。 
[ABSTRACT]外部キャリブレーション、オドメトリ、および複数のLIDARのマッピングのためのシステム。キャリブレーションのために10個のシーケンス（全長4.60km）を分析することによって開発されたシステム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: MFIF-GAN: A New Generative Adversarial Network for Multi-Focus Image
  Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_53.html">
      <font color="black">MFIF-GAN: A New Generative Adversarial Network for Multi-Focus Image
  Fusion</font>
    </a>
  </h2>
  <font color="black">トレーニング条件の事前知識を組み合わせることにより、このネットワークは{\ alpha}マットモデルに基づく合成データセットでトレーニングされます。さらに、再構成と勾配正則化の項が損失関数で組み合わされ、境界の詳細と融合画像の品質を向上させます。ネットワークでは、注意メカニズムとしてのスクイーズおよび励起残差モジュールが採用されています。 
[ABSTRACT] mfifは、フォーカス/ dseの周りのデフォーカス拡散効果（dse）を回避するためのものです。スクイーズおよび励起残差モジュールがネットワークで採用されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-21">
        <br><font color="black">2020-09-21</font>
      </time>
    </span>
</section>
<!-- paper0: Co-attentional Transformers for Story-Based Video Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CV/paper_54.html">
      <font color="black">Co-attentional Transformers for Story-Based Video Understanding</font>
    </a>
  </h2>
  <font color="black">ただし、ビデオの物語の側面に焦点を当てているため、さまざまなキャラクター間の相互作用、およびそれらのアクションと動機についても理解する必要があります。ドラマなどの視覚的なストーリーと、ビデオの質問応答タスクでのパフォーマンスの測定。ビジョンと言語学習の最近の傾向に触発されて、ストーリーベースのビデオ理解へのアプリケーション内での視覚と言語の融合のための注意メカニズムのアプリケーションを探ります。 
[概要]ドラマなどのビジュアルストーリーに見られる長期的な依存関係をより適切にキャプチャするために、新しい共同注意トランスモデルを提案します。モデルにアプローチして、ビデオの質問応答タスクでのパフォーマンスを測定します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Autoencoding Improves Pre-trained Word Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_0.html">
      <font color="black">Autoencoding Improves Pre-trained Word Embeddings</font>
    </a>
  </h2>
  <font color="black">理論的主張を実験的に検証し、上位主成分を保持することが、追加の言語リソースやラベル付きデータへのアクセスを必要とせずに、事前にトレーニングされた単語の埋め込みを改善するのに実際に役立つことを示します。この結果は、以前の研究（Mu and Viswanath、2018）と矛盾します。事前にトレーニングされた埋め込みから上位主成分を削除することを提案しました。ただし、理論的には、この後処理ステップは、線形オートエンコーダーを適用して2乗l2再構成エラーを最小化することと同等です。 
[ABSTRACT]後処理ステップは、線形オートエンコーダーを適用することと同等です。ただし、このステップは、オートエンコーダーを適用することに相当します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-25">
        <br><font color="black">2020-10-25</font>
      </time>
    </span>
</section>
<!-- paper0: Dual Attention Model for Citation Recommendation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_1.html">
      <font color="black">Dual Attention Model for Citation Recommendation</font>
    </a>
  </h2>
  <font color="black">指数関数的に増加する学術論文に基づいて、包括的で適切なリソースを発見して引用することは重要な作業になりました。この研究では、「引用推奨のためのデュアルアテンションモデル（DACR）」と呼ばれる新しい埋め込みベースのニューラルネットワークを提案します。 「原稿の準備中に引用を推奨する。これらの欠点により、学術論文に適切な引用を推奨するには、そのような方法では不十分です。 
[概要]私たちの方法は、学術論文に十分な引用を推奨するのに適しています。新しい方法は、非社会的情報の3つの次元を使用します。これらには、ローカルコンテキスト、構造コンテキスト、およびユーザーが作業しているセクションの単語が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-01">
        <br><font color="black">2020-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: A survey of embedding models of entities and relationships for knowledge
  graph completion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_2.html">
      <font color="black">A survey of embedding models of entities and relationships for knowledge
  graph completion</font>
    </a>
  </h2>
  <font color="black">知識グラフにない関係が真である可能性が高いかどうかを予測します。ただし、知識グラフは通常不完全であるため、知識グラフの完了またはリンク予測を実行すると便利です。エンティティとその関係に関する実際の事実の知識グラフ（KG）は、さまざまな自然言語処理タスクに役立つリソースです。 
[ABSTRACT]知識グラフの完成は役立つ可能性が高いですが、関係情報は関連していないため、便利です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2017-03-23">
        <br><font color="black">2017-03-23</font>
      </time>
    </span>
</section>
<!-- paper0: Separating Argument Structure from Logical Structure in AMR -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_3.html">
      <font color="black">Separating Argument Structure from Logical Structure in AMR</font>
    </a>
  </h2>
  <font color="black">自然言語文の意味を表現するためのAMR（Abstract Meaning Representation）形式は、スコープと数量詞を処理するようには設計されていません。AMRの魅力的なコア述語-項構造は保持されます。結果のフレームワークは、談話表現理論のフレームワークと同様です。 。 
[要約]フォーマリズムは、結論を正しく予測するように設計されています。amrは、正しい予測を行うフォーマリズムを作成することを目的としています。結果として得られるフレームワークは、談話表現理論のフレームワークと似ています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-04">
        <br><font color="black">2019-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Evaluating Gender Bias in Speech Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_4.html">
      <font color="black">Evaluating Gender Bias in Speech Translation</font>
    </a>
  </h2>
  <font color="black">科学界は、多元主義を受け入れ、主要な社会集団とマイナーな社会集団を一貫して代表する必要性をますます認識しています。この論文では、音声翻訳における性差別を評価するための新しい無料のチャレンジセットであるWinoSTを紹介します。WinoSTはの音声バージョンです。 MTチャレンジセットであるWinoMTは、どちらも評価プロトコルに従って性別の正確さを測定します。 
[要約]私たちのシステムでは、性別の偏見に対処する必要があります。性別の正確さを測定するための評価とプロトコルを提供する必要があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: To BERT or Not to BERT: Comparing Task-specific and Task-agnostic
  Semi-Supervised Approaches for Sequence Tagging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_5.html">
      <font color="black">To BERT or Not to BERT: Comparing Task-specific and Task-agnostic
  Semi-Supervised Approaches for Sequence Tagging</font>
    </a>
  </h2>
  <font color="black">この作業では、ラベルなしデータを効果的に使用する方法を調査します。タスク固有の半教師ありアプローチであるクロスビュートレーニング（CVT）を調査し、ドメインおよびタスク関連の英語データを含む複数の設定でタスクに依存しないBERTと比較します。 .. BERTのようなTransformerのようなアーキテクチャを使用して、ラベルのない大量のデータを活用することは、一般的な表現を学習する効果があるため、最近人気が高まっています。これは、ダウンストリームタスク用にさらに微調整して大成功を収めることができます。はるかに軽量なモデルアーキテクチャであり、一連のシーケンスタグ付けタスクでBERTと同様のパフォーマンスを実現し、財務および環境への影響が少ないことを示しています。 
[ABSTRACT] cvtは、はるかに軽量なモデルアーキテクチャを使用しており、一連のシーケンスタグ付けタスクでbertと同様のパフォーマンスを実現し、経済的および環境への影響が少ないことを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Listener's Social Identity Matters in Personalised Response Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_6.html">
      <font color="black">Listener's Social Identity Matters in Personalised Response Generation</font>
    </a>
  </h2>
  <font color="black">さらに興味深いことに、リスナーのアイデンティティをさらにモデル化することにより、パーソナライズされた応答ジェネレータは、それ自体のアイデンティティでより優れたパフォーマンスを発揮します。また、パーソナライズされたジェネレータを構築します。しかし、語用論は、人間が自分が誰であるかだけでなく、話し方を調整することを示唆しています。だけでなく、彼らが話している人。 
[ABSTRACT]語用論は、人間が話し方を調整することを示唆しています。ソーシャル変数の典型的な例として性別を使用して、リスナーのアイデンティティがソーシャルメディアで使用される言語にどのように影響するかを調査します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Emotion recognition by fusing time synchronous and time asynchronous
  representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_7.html">
      <font color="black">Emotion recognition by fusing time synchronous and time asynchronous
  representations</font>
    </a>
  </h2>
  <font color="black">IEMOCAPデータセットの実験結果は、2分岐構造が、すべての一般的なテスト設定で4方向分類で最先端の結果を達成することを示しています。対照的に、TABは、文のテキストの埋め込みを統合することにより、発話間の情報を提供します。多数のコンテキスト発話から別の埋め込みベクトルに..さらに、他のすべての感情に追加のクラスを組み込むことにより、ASR仮説を使用した最終的な5方向分類システムは、より現実的な感情認識システムのプロトタイプと見なすことができます。 
[概要] tsbは、各入力ウィンドウフレームで音声とテキストのモダリティを組み合わせます。その後、時間の経過とともにプールを実行して単一の埋め込みを形成します。最終的な感情分類では、tsbとタブの埋め込みの両方を使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Reinforcement Learning for Neural Relation Extraction with
  Hierarchical Memory Extractor -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_8.html">
      <font color="black">Improving Reinforcement Learning for Neural Relation Extraction with
  Hierarchical Memory Extractor</font>
    </a>
  </h2>
  <font color="black">本論文では、上記の2つの問題を解決するための新しいフレームワークを提案する。さらに、階層的加重ランキング損失関数を定義してトップダウン検索処理を実装する。さらに、暗黙の関係情報を使用してRLを改善する。 
[概要]システムは、正しいデータとノイズの多いデータの両方からフィードバックを取得するように設計されています。また、データからフィードバックを取得するための新しい報酬関数も提供します。ただし、2つの無視された問題があります。以前のrlメソッドはノイズの多いデータのフィードバックを無視します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Re-evaluating phoneme frequencies -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_9.html">
      <font color="black">Re-evaluating phoneme frequencies</font>
    </a>
  </h2>
  <font color="black">最尤フレームワークを使用して、166のオーストラリア言語に対するべき法則と3つの代替分布の適合性を推測します。これらの新しい洞察を、時間の経過に伴う音素インベントリの進化に影響を与える原因プロセスの種類と比較し、その理由の潜在的な説明を特定します。 、音素変化における音素物質の重要な役割があるにもかかわらず、非常に多様な音素コンテンツを持つインベントリが音素周波数の同様の分布を共有することを期待できます。この有望な研究プログラムでの将来の作業の優先順位で締めくくります。 
[概要]これらの新しい洞察を、時間の経過に伴う音素インベントリの進化に影響を与える原因プロセスの種類と比較します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-09">
        <br><font color="black">2020-06-09</font>
      </time>
    </span>
</section>
<!-- paper0: Exploiting Vietnamese Social Media Characteristics for Textual Emotion
  Recognition in Vietnamese -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_10.html">
      <font color="black">Exploiting Vietnamese Social Media Characteristics for Textual Emotion
  Recognition in Vietnamese</font>
    </a>
  </h2>
  <font color="black">私たちの実験的評価は、ベトナムのソーシャルメディアの特性に基づく適切な前処理技術により、Multinomial Logistic Regression（MLR）が64.40％の最高のF1スコアを達成し、UITの作成者によって構築されたCNNモデルよりも4.66％大幅に改善されたことを示しています。 -VSMEC（59.74％）..この論文では、データの前処理がテキストの感情認識における機械学習方法にどのように影響するかを示すために、いくつかの実験を行います。多くの研究者は、より正確で堅牢な感情検出システムの構築を目指しています。 
[概要]実験は、ベンチマークデータセットとしてベトナムのソーシャルメディア感情コーパス（uit-vsmec）で実行されます。実験的な実験評価は、ベトナムのソーシャルネットワークに基づく適切な前処理技術を使用して、多項ロジスティック新星（mlr）が最高のf1-スコア64。40％</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-23">
        <br><font color="black">2020-09-23</font>
      </time>
    </span>
</section>
<!-- paper0: Classifying Syntactic Errors in Learner Language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_11.html">
      <font color="black">Classifying Syntactic Errors in Learner Language</font>
    </a>
  </h2>
  <font color="black">既存のエラー分類方法とは異なり、私たちの方法は言語間で適用可能であり、英語学習者とロシア語学習者の構文エラーの詳細な図を作成することで紹介します。この方法は、確立されたUniversal Dependencies構文表現スキームに基づいており、他のエラー分類システム..さらに、主要な文法エラー修正（GEC）システムの出力を分析するための方法論の有用性を示します。 
[概要]構文システムは、確立されたユニバーサル依存関係の構文表現スキームに基づいて構築されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: UPB at SemEval-2020 Task 12: Multilingual Offensive Language Detection
  on Social Media by Fine-tuning a Variety of BERT-based Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_12.html">
      <font color="black">UPB at SemEval-2020 Task 12: Multilingual Offensive Language Detection
  on Social Media by Fine-tuning a Variety of BERT-based Models</font>
    </a>
  </h2>
  <font color="black">単一言語コーパスと多言語コーパスの両方を使用して事前トレーニングされたいくつかのニューラルアーキテクチャ（つまり、BERT、mBERT、Roberta、XLM-Roberta、およびALBERT）が微調整され、データセットの複数の組み合わせを使用して比較されました。スコアリングモデルは、私たちのチームを英語、アラビア語、デンマーク語、ギリシャ語、トルコ語でそれぞれ85の21位、53の28位、39の19位、37の16位、46の10位にランク付けしたコンテストでの提出に使用されました。このペーパーでは、Offenseval 2020共有タスクのサブタスクAで採用された、Twitterで攻撃的な言語を5つの言語（英語、アラビア語、デンマーク語、ギリシャ語、トルコ語）で識別するためのTransformerベースのソリューションについて説明します。 
[ABSTRACT] cnnのfredpleitgenは、米国でTwitterで不快な言葉を特定した最初のチームでした。チームは、英語、アラビア語、デンマーク語、ギリシャ語で85の21位、53の28位、アルバート、37、46の10位にランクされました。 、およびトルコ語</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Volctrans Parallel Corpus Filtering System for WMT 2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_13.html">
      <font color="black">Volctrans Parallel Corpus Filtering System for WMT 2020</font>
    </a>
  </h2>
  <font color="black">スコアリングモジュールでは、XLMベースのスコアラーがスコアを提供し、その後に再ランク付けメカニズムとアンサンブルが続きます。km-enとps-enの場合、提出物はベースラインを3.x /2.xと2.x / 2.x上回っています。 on From Scratch / Fine-Tune条件は、すべての提出物の中で最も高い条件です。単語整列モデルに基づいて、マイニングモジュールは反復マイニング戦略を採用して潜在的な並列文を抽出します。 
[要約]このタスクでは、参加者が指定されたドキュメントペアから潜在的な並列文のペアを整列し、低品質のペアをフィルタリングできるようにスコアを付ける必要があります。スクラッチ/微調整-すべての提出物の中で最も高い条件を調整します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: It's All in the Name: A Character Based Approach To Infer Religion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_14.html">
      <font color="black">It's All in the Name: A Character Based Approach To Infer Religion</font>
    </a>
  </h2>
  <font color="black">既存の作業では、辞書ベースの方法を使用して宗教を予測するため、見えない名前を分類できません。最後に、複雑な非線形分類器の予測を説明できる層ごとの関連性伝播を使用して、畳み込みニューラルネットワークモデルの分類決定を追跡します。ブラックボックスと称される性質を回避します。個人の名前と親/配偶者の名前を組み合わせることで分類器を改善し、非常に高い精度を実現します。 
[概要]文字パターンを学習する文字ベースのモデルを使用しています。これらは、高精度で対象を簡単に分類できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: AMBERT: A Pre-trained Language Model with Multi-Grained Tokenization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_15.html">
      <font color="black">AMBERT: A Pre-trained Language Model with Multi-Grained Tokenization</font>
    </a>
  </h2>
  <font color="black">モデルのトークンは通常、英語などの言語では単語またはサブワードであり、中国語などの言語では文字であるという意味で細かく設定されています。結果は、ほとんどすべての場合でAMBERTが既存の最高のパフォーマンスモデルよりも優れていることを示しています。 、特に中国語の改善は重要です。この論文では、細粒度と粗粒度の両方のトークン化に基づいて、AMBERT（マルチグレインBERT）と呼ばれる新しい事前トレーニング済み言語モデルを提案します。 
[ABSTRACT]事前にトレーニングされた言語モデルは細かく、細かく、細かく設定されています。英語などの言語の場合、単語またはサブユニットであり、中国語の場合、ほとんどすべての場合、ambertは既存の最高のパフォーマンスモデルよりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Natural Language Processing Tasks with Human Gaze-Guided
  Neural Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_16.html">
      <font color="black">Improving Natural Language Processing Tasks with Human Gaze-Guided
  Neural Attention</font>
    </a>
  </h2>
  <font color="black">私たちの共同モデルは、Quora Question Pairsコーパスでの言い換え生成の最先端をBLEU-4で10％以上上回り、挑戦的なGoogle SentenceCompressionコーパスでの文圧縮の最先端のパフォーマンスを達成していることを示しています。 4つの異なるコーパスは、ハイブリッドTSM期間の予測が人間の視線のグラウンドトゥルースと高度に相関していることを示しています。コーパスの欠如は、自然言語処理（NLP）の神経注意メカニズムの監視信号として人間の視線データを統合する上でこれまでのところ限られた進歩です。 。 
[概要]新しいモデルは、単一の機械学習フレームワークで、読書の認知モデルと明示的な人間の視線監視を組み合わせたものです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Interpreting Attention Models with Human Visual Attention in Machine
  Reading Comprehension -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_17.html">
      <font color="black">Interpreting Attention Models with Human Visual Attention in Machine
  Reading Comprehension</font>
    </a>
  </h2>
  <font color="black">人間の注意とパフォーマンスとの類似性が高いことは、LSTMモデルとCNNモデルと有意に相関していることがわかります。この目的のために、参加者が映画のプロットを読み、事前定義された質問に回答する、新しい23人の参加者の視線追跡データセットMQA-RCを紹介します。 ..ただし、XLNetがこの困難なタスクで最高のパフォーマンスを発揮するという事実にもかかわらず、この関係がXLNetモデルには当てはまらないことを示します。 
[概要]長短期記憶（lstm）、畳み込みニューラルモデル、xlnetトランスフォーマーアーキテクチャに基づいて最先端のネットワークを比較します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Are scene graphs good enough to improve Image Captioning? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_18.html">
      <font color="black">Are scene graphs good enough to improve Image Captioning?</font>
    </a>
  </h2>
  <font color="black">さらに、予測シーングラフの品質は一般に非常に低いですが、高品質のシーングラフを使用すると、強力なボトムアップトップダウンベースラインと比較して最大3.3CIDErのゲインが得られます。多くのトップパフォーマンスの画像キャプションモデルは画像記述を生成するためにオブジェクト検出モデルで計算されたオブジェクトの特徴のみに基づいて..最後に、予測されたシーングラフのノイズがキャプションの品質にどの程度影響するかを判断します。 
[概要]多くのモデルはシーングラフ機能を使用し、モデルはさまざまなキャプションメトリック全体でオブジェクト検出機能のみを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-25">
        <br><font color="black">2020-09-25</font>
      </time>
    </span>
</section>
<!-- paper0: LXPER Index 2.0: Improving Text Readability Assessment for L2 English
  Learners in South Korea -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_19.html">
      <font color="black">LXPER Index 2.0: Improving Text Readability Assessment for L2 English
  Learners in South Korea</font>
    </a>
  </h2>
  <font color="black">ほとんどのテキストの読みやすさ評価モデルは、英語のネイティブリーダー向けに開発されており、外国英語トレーニング（ELT）カリキュラムのテキストの精度が低くなっています。CoKECテキストを使用してモデルをトレーニングし、テキストの読みやすさ評価の精度を大幅に向上させます。韓国のELTカリキュラム..各テキストには、その目標グレードレベルのラベルが付いています。 
[概要]英語は韓国のl2英語学習者のためのテキスト可読性評価モデルに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Multitask Training with Text Data for End-to-End Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_20.html">
      <font color="black">Multitask Training with Text Data for End-to-End Speech Recognition</font>
    </a>
  </h2>
  <font color="black">LibriSpeechの100時間サブセットまたは完全な960時間データセットのいずれかでトレーニングされた、提案された方法は、ベースラインに対して11％の相対的なパフォーマンスの向上をもたらし、デコード中に追加のニューラルネットワークを必要とせずに言語モデルの浅い融合に匹敵します。サンプル出力文とレアワードの単語エラー率の結果は、提案された方法が言語レベルの情報を効果的に組み込むことができることを示しています。言語レベルの情報をよりよく組み込むために、注意ベースのエンドツーエンドの音声認識モデルのためのマルチタスクトレーニング方法を提案します。 【概要】提案手法は、言語レベルの情報を効果的に組み込むことができ、音声認識、音声認識、予測のツールとして利用できる。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-lingual Machine Reading Comprehension with Language Branch
  Knowledge Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_21.html">
      <font color="black">Cross-lingual Machine Reading Comprehension with Language Branch
  Knowledge Distillation</font>
    </a>
  </h2>
  <font color="black">クロスリンガルの機械読解（CLMRC）は、アラビア語、ヒンディー語、ベトナム語などの低ソース言語の大規模な注釈付きデータセットがないため、依然として困難な問題です。言語ブランチは、1つの単一のパッセージのグループです。すべての対象言語の質問と組み合わせた言語..LBMRCに基づいて、個々の言語に堪能な複数の機械読解（MRC）モデルをトレーニングします。 
[ABSTRACT]言語ブランチマシンの読解（lbmrc）は、新しい拡張アプローチです。新しいモデルは、データノイズに対してより堅牢になる可能性があるため、モデルの言語間能力が向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: X-FACTR: Multilingual Factual Knowledge Retrieval from Pretrained
  Language Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_22.html">
      <font color="black">X-FACTR: Multilingual Factual Knowledge Retrieval from Pretrained
  Language Models</font>
    </a>
  </h2>
  <font color="black">さらに、多言語LMが知識にアクセスする能力を向上させ、いくつかのベンチマーク言語での有効性を検証するためのコードスイッチングベースの方法を提案します。ベンチマークデータとコードはhttps://x-factr.github.ioでリリースされています。 ..広範な実験結果は、利用可能なリソースが多かれ少なかれ、現在の最先端のLMがこのタスクでどの程度うまく機能するか（または不十分であるか）についての洞察を提供します。 
[ABSTRACT] lmsの事実表現能力に関する研究は英語で行われています。これらの研究は、ほぼ確実に英語で行われています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Interpretation of NLP models through input marginalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_23.html">
      <font color="black">Interpretation of NLP models through input marginalization</font>
    </a>
  </h2>
  <font color="black">この研究では、既存の解釈方法によって引き起こされた分布外の問題を提起し、解決策を提示します。各トークンを疎外することを提案します。提案された方法を使用して、感情分析と自然言語推論のためにトレーニングされたさまざまなNLPモデルを解釈します。既存の方法は各トークンを事前定義された値（つまりゼロ）に置き換えるため、結果の文はトレーニングデータの配布、誤解を招く解釈をもたらします。 
[要約]提案された方法は、新しいシステムを作成するために使用できます。それは、システムがどのように機能するかを説明するのに役立つ可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-XScience: A Large-scale Dataset for Extreme Multi-document
  Summarization of Scientific Articles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_24.html">
      <font color="black">Multi-XScience: A Large-scale Dataset for Extreme Multi-document
  Summarization of Scientific Articles</font>
    </a>
  </h2>
  <font color="black">記述統計と経験的結果--- Multi-XScienceデータセットでトレーニングされたいくつかの最先端モデルを使用--- Multi-XScienceが抽象モデルに非常に適していることを明らかにします。マルチドキュメントの要約は、大規模なデータセットはほとんど存在しません。Multi-XScienceは、挑戦的なマルチドキュメント要約タスクを導入します。要約と参照する記事に基づいて、論文の関連作業セクションを作成します。 
[ABSTRACT] multi-xscienceは、科学論文から作成された大規模なマルチドキュメント要約データセットです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Event Detection: Gate Diversity and Syntactic Importance Scoresfor Graph
  Convolution Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_25.html">
      <font color="black">Event Detection: Gate Diversity and Syntactic Importance Scoresfor Graph
  Convolution Neural Networks</font>
    </a>
  </h2>
  <font color="black">また、ゲートのコンテキストの多様性とEDのグラフとモデルの重要度スコアの一貫性を実現するための新しいメカニズムを紹介します。さらに、EDの現在のモデルでは、depenを介して取得できる単語の全体的なコンテキストの重要度スコアを活用できません。 -デンシーツリー、パフォーマンスを向上させるために..この研究では、トリガー候補からの情報に基づいて、EDのGCNモデルの隠れたベクトル内のノイズの多い情報をフィルタリングする新しいゲーティングメカニズムを提案します。 
[概要]この研究では、ノイズの多い情報をフィルタリングするための新しいゲーティングメカニズムを提案します。提案されたモデルは、2つのedデータセットでパフォーマンスの状態を実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Discovering and Interpreting Conceptual Biases in Online Communities -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_26.html">
      <font color="black">Discovering and Interpreting Conceptual Biases in Online Communities</font>
    </a>
  </h2>
  <font color="black">そのため、これらのアプローチでは、事前に定義されていない概念バイアスを見つけることができないか、見つけたバイアスを解釈して調査することが困難です。ただし、以前の調査では、事前定義された一連の概念バイアスのみを考慮して証明します（例：性別が多かれ少なかれ特定の仕事に関連しているかどうか）、または概念レベルでの意味を理解するのに役立たずに偏った単語を発見するだけかどうか..この論文は、単語にエンコードされた概念的偏見を自動的に発見して解釈するのに役立つ一般的なデータ駆動型アプローチを提案します埋め込み。 
[要約]これにより、既存のアプローチはオンラインコミュニティのバイアスを発見して解釈するのに不適切になります。そのようなコミュニティは、主流の文化とは異なるバイアスを持っている可能性があるためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Speech SIMCLR: Combining Contrastive and Reconstruction Objective for
  Self-supervised Speech Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_27.html">
      <font color="black">Speech SIMCLR: Combining Contrastive and Reconstruction Objective for
  Self-supervised Speech Representation Learning</font>
    </a>
  </h2>
  <font color="black">その目的は、潜在空間内の異なる拡張サンプル間の一致を最大化する対照損失と入力表現の再構成損失の組み合わせです。トレーニング中に、SpeechSimCLRは生の音声とそのスペクトログラムに拡張を適用します。提案された方法は音声で競争力のある結果を達成しました。感情認識と音声認識。 
[ABSTRACT]音声表現学習の新しい自己教師あり目的であるspeechsimclrは、この論文で提案されています。simclrは、音声表現に適用する新しい自己教師あり目的です。これは、最小化する対照的な損失の組み合わせの結果です。潜在空間内の異なる拡張サンプル間の一致と入力表現の再構成損失</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Probing Contextual Language Models for Common Ground with Visual
  Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_28.html">
      <font color="black">Probing Contextual Language Models for Common Ground with Visual
  Representations</font>
    </a>
  </h2>
  <font color="black">全体として、私たちの調査結果は、言語の基礎と文脈言語モデルにおけるその具体化に関する新しい経験的洞察を示しています。対照実験では、プローブの選択性を証明する、はるかに弱い結果が見つかりました。将来の進歩の余地。 
[概要]コンテキスト表現が参照するオブジェクトの物理的プロパティにどのように関連するかを特徴付けます。最近の多くの言語モデルが、意味的に整列された画像パッチの取得に役立つ表現を生成することを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: Gender Prediction Based on Vietnamese Names with Machine Learning
  Techniques -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_29.html">
      <font color="black">Gender Prediction Based on Vietnamese Names with Machine Learning
  Techniques</font>
    </a>
  </h2>
  <font color="black">その結果、私たちが達成した最高のF1スコアはLSTMモデルで最大96 \％であり、トレーニング済みモデルに基づいてWeb APIを生成します。生物学的性別は個々の人間を提示する側面の1つであるため、多くの作業が必要です。さらに、このペーパーでは、6つのマシン学習アルゴリズム（Support Vector Machine、Multinomial Naive Bayes、Bernoulli Naive Bayes、Decision Tree、Random Forrest、Logistic Regression）とディープラーニングモデル（ディープラーニングモデル）について説明します。 LSTM）ベトナムの名前の性別予測のためのfastText単語埋め込み。 
[概要]データセットは、性別に基づいて26,000を超えるフルネームで構成されています。このデータセットは、サイトの26,000を超えるフルネームに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Predict and Use Latent Patterns for Short-Text Conversation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_30.html">
      <font color="black">Predict and Use Latent Patterns for Short-Text Conversation</font>
    </a>
  </h2>
  <font color="black">この論文では、生成を導くための制御可能なセマンティクスとして、潜在的な応答や対応する分布からサンプリングされた品詞シーケンスなど、より詳細なセマンティクス形式を使用することを提案します。実験結果は、より豊富なセマンティクスが有益で多様な応答を提供できるだけでなく、流暢さと一貫性を含む応答品質の全体的なパフォーマンスを向上させます。以前のいくつかの作品は、サンプルされた潜在的な単語を制御可能なセマンティックフォームとして利用して、生成された応答を作品の周りに駆動しようとしますが、より複雑なセマンティックフォームを使用して、生成をガイドします。 
[概要]それらのほとんどは、応答を作成するためにエンコーダーとデコーダーに依存しています。それらの大部分は、応答を作成するためにエンコーダー、エンコーダー、およびデコーダーを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic Boundary Time Warping for Sub-sequence Matching with Few
  Examples -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_31.html">
      <font color="black">Dynamic Boundary Time Warping for Sub-sequence Matching with Few
  Examples</font>
    </a>
  </h2>
  <font color="black">結果は、ベースラインや以前のアプローチよりも優れているか、利用可能な例の数が少ない場合に同等の結果を達成することを示しています。この論文は、短いシーケンスのセットと同様に、長い時間シーケンスでフラグメントを見つける新しい方法を示しています。自然言語処理の分野からの2つの異なる数ショットの問題についてです。 
[概要]この方法は、動的タイムワーピング（dtw）手法に基づいています。これは、少数のショット検索に適しています。例によると、結果は、ベースラインおよび以前のアプローチよりも優れていることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Fast Interleaved Bidirectional Sequence Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_32.html">
      <font color="black">Fast Interleaved Bidirectional Sequence Generation</font>
    </a>
  </h2>
  <font color="black">2つの方向をインターリーブし、単語の位置と自己注意マスクを適応させるだけで、単方向デコードの標準アーキテクチャを双方向デコーダに簡単に変換できることを示します。シーケンス生成中の独立性の仮定は推論を高速化できますが、高度な並列生成は相互依存トークンには品質が犠牲になります。インターリーブ双方向デコーダー（IBDecoder）は、標準のTransformerのモデルの単純さとトレーニング効率を維持し、5つのマシン変換タスクと2つのドキュメント要約タスクで最大2倍のデコード速度を実現します。同等の品質の自動回帰デコードと比較して。 
[概要]デコーダーは、左から右、右から左の方向に同時にターゲットワードを生成します。これを使用して、右から右または右から左から左の方向にターゲットワードを生成するデコーダーを作成できます。 。これは、同等の品質の自己回帰デコードと比較できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Agent Reinforcement Learning as a Computational Tool for Language
  Evolution Research: Historical Context and Future Challenges -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_33.html">
      <font color="black">Multi-Agent Reinforcement Learning as a Computational Tool for Language
  Evolution Research: Historical Context and Future Challenges</font>
    </a>
  </h2>
  <font color="black">この論文の目的は、言語進化研究の歴史的文脈の中で最近のMARLの貢献を位置付け、この理論的および計算的背景から将来の研究のためのいくつかの課題を抽出することです。エージェント集団における緊急コミュニケーションの計算モデルは現在得られています。マルチエージェント強化学習（MARL）の最近の進歩による機械学習コミュニティへの関心。しかし、現在の貢献は、言語が前言語的実体からどのように出現したかを理解することを目的とした以前の理論的および計算的文献からまだ比較的切り離されています。 
[要約]言語が前言語的実体からどのように出現したかを決定するための研究が現在進行中です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-20">
        <br><font color="black">2020-02-20</font>
      </time>
    </span>
</section>
<!-- paper0: Global Sentiment Analysis Of COVID-19 Tweets Over Time -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_34.html">
      <font color="black">Global Sentiment Analysis Of COVID-19 Tweets Over Time</font>
    </a>
  </h2>
  <font color="black">いくつかの最悪の被害を受けた国で1日あたりの確認された症例数に関する情報を提供するデータセットに対して探索的データ分析も実行され、感情の変化と開始以降の症例の変化との比較が提供されました。 2020年6月までのこのパンデミック。さらに、感情分類のためにLong Short Term Memory（LSTM）やArtificial Neural Networks（ANN）などのさまざまな機械学習モデルが実装され、その精度が決定されました。さらに、コロナウイルスの影響を決定するために日常生活の中で、Work From Home（WFH）とOnline Learningに関連するツイートが削られ、時間の経過に伴う感情の変化が観察されました。 
[概要]世界中の人々が自分の意見を表明するためにソーシャルメディアを利用しています。この現象は世界を席巻しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Co-attentional Transformers for Story-Based Video Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/cs.CL/paper_35.html">
      <font color="black">Co-attentional Transformers for Story-Based Video Understanding</font>
    </a>
  </h2>
  <font color="black">キャラクター中心のビデオストーリー理解の質問を特徴とする最近導入されたDramaQAデータセットで私たちのアプローチを評価します。ただし、ビデオの物語の側面に焦点を当てているため、さまざまなキャラクター間の相互作用、およびキャラクターの行動と動機..私たちのモデルは、ベースラインモデルを全体で8パーセントポイント、すべての難易度レベルで少なくとも4.95ポイント、最大12.8パーセントポイント上回っており、DramaQAチャレンジの勝者をなんとか打ち負かしています。 
[概要]ドラマなどのビジュアルストーリーに見られる長期的な依存関係をより適切にキャプチャするために、新しい共同注意トランスモデルを提案します。モデルにアプローチして、ビデオの質問応答タスクでのパフォーマンスを測定します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Deep generative factorization for speech signal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.AS/paper_0.html">
      <font color="black">Deep generative factorization for speech signal</font>
    </a>
  </h2>
  <font color="black">この論文は、新しい階乗識別正規化フローモデル（階乗DNF）に基づく音声因数分解アプローチを提示します。さまざまな情報要因が音声信号にブレンドされ、ほとんどの音声情報処理タスクの主な困難を形成します。音声コンテンツと話者特性を含む階乗ケースは、提案された階乗DNFが音声信号を因数分解する強力な機能を持ち、情報の表現と操作に関していくつかの比較モデルよりも優れていることを示しています。 
[概要]提案された階乗dnfは、音声信号を因数分解する強力な機能を備えています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Squeezing value of cross-domain labels: a decoupled scoring approach for
  speaker verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.AS/paper_1.html">
      <font color="black">Squeezing value of cross-domain labels: a decoupled scoring approach for
  speaker verification</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、最初に、クロスドメインデータを追加するだけでは、登録とテストの不一致がある状況でのパフォーマンスに役立たないことを示す実証研究を紹介します。注意深い分析により、この印象的な結果は、登録とテストの間の一貫性のない統計によって引き起こされることが示されています。条件..一般的な知恵は、クロスドメインデータを収集し、マルチドメインPLDAモデルをトレーニングして、ドメインに依存しないスピーカーサブスペースを学習することです。 
[概要]これは、登録条件とテスト条件の間の統計が一貫していないためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Blind Sound Source Localization based on Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.AS/paper_2.html">
      <font color="black">Blind Sound Source Localization based on Deep Learning</font>
    </a>
  </h2>
  <font color="black">一方のデコーダーは残響によって引き起こされたマルチパスを解決し、もう一方のデコーダーはソースの位置を推定します。エンコーダーは入力尤度の圧縮表現を取得します。実験は、私たちの方法が複数信号分類（MUSIC）、位相のあるステアリング応答パワーよりも優れていることを示しています。残響環境での変換（SRP-PHAT）、スパースベイズ学習（SBL）、および競合する畳み込みニューラルネットワーク（CNN）アプローチ。 
[概要]各マイクで受信した音声信号の空間的特徴を抽出し、各ポイントの音源位置の尤度面として表現します。エンコーダーは入力尤度の圧縮表現を取得します。残響法は複数の信号分類（音楽）、位相変換を使用したステアリング応答パワー（srp --phat）、および残響環境でのローカル畳み込みニューラルネットワーク（cnn）アプローチ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Universal ASR: Unifying Streaming and Non-Streaming ASR Using a Single
  Encoder-Decoder Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.AS/paper_3.html">
      <font color="black">Universal ASR: Unifying Streaming and Non-Streaming ASR Using a Single
  Encoder-Decoder Model</font>
    </a>
  </h2>
  <font color="black">組み込みストリーミングASRモデルは、要件に応じてさまざまな遅延を構成してリアルタイムの認識結果を取得できますが、非ストリーミングモデルは、最終的な認識結果を更新してパフォーマンスを向上させることができます。最近、オンラインのエンドツーエンドASRが向上しました。注目が高まっています。実験結果は、Universal ASRが、音声を迅速かつ正確に認識できるストリーミングモデルと非ストリーミングモデルを統合する効率的なメカニズムを提供することを示しています。 
[ABSTRACT]ユニバーサルasrは、音声をすばやく正確に認識できるストリーミングモデルと非ストリーミングモデルを統合できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: ByteCover: Cover Song Identification via Multi-Loss Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.AS/paper_4.html">
      <font color="black">ByteCover: Cover Song Identification via Multi-Loss Training</font>
    </a>
  </h2>
  <font color="black">2番目の改善では、BNNeck法を使用してマルチロストレーニングを可能にし、分類損失とトリプレット損失を共同で最適化する方法を奨励します。これにより、カバー曲のクラス間識別とクラス内コンパクト化が実現します。 、同時に保証できます。ByteCoverは従来のResNetモデルに基づいて構築されており、CSIのモデルの機能をさらに強化するために、2つの主要な改善が設計されています。最初の改善では、インスタンスの正規化の統合を紹介します。 （IN）およびバッチ正規化（BN）により、ResNet-IBNモデルの主要コンポーネントであるIBNブロックを構築します。 
[概要]プロジェクトは古典的なresnetモデルに基づいて構築されています。2つの主要な改善がcsiの機能をさらに強化するように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Emotion recognition by fusing time synchronous and time asynchronous
  representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.AS/paper_5.html">
      <font color="black">Emotion recognition by fusing time synchronous and time asynchronous
  representations</font>
    </a>
  </h2>
  <font color="black">IEMOCAPデータセットの実験結果は、2分岐構造が、すべての一般的なテスト設定で4方向分類で最先端の結果を達成することを示しています。さらに、他のすべての感情に追加のクラスを組み込むことにより、最後の5 -ASR仮説を使用した方法分類システムは、より現実的な感情認識システムのプロトタイプと見なすことができます。対照的に、TABは、多数のコンテキスト発話からの文テキスト埋め込みを別の埋め込みベクトルに統合することにより、クロス発話情報を提供します。 
[概要] tsbは、各入力ウィンドウフレームで音声とテキストのモダリティを組み合わせます。その後、時間の経過とともにプールを実行して単一の埋め込みを形成します。最終的な感情分類では、tsbとタブの埋め込みの両方を使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: FragmentVC: Any-to-Any Voice Conversion by End-to-End Extracting and
  Fusing Fine-Grained Voice Fragments With Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.AS/paper_6.html">
      <font color="black">FragmentVC: Any-to-Any Voice Conversion by End-to-End Extracting and
  Fusing Fine-Grained Voice Fragments With Attention</font>
    </a>
  </h2>
  <font color="black">話者検証に基づく客観的評価とMOSによる主観的評価の両方で、このアプローチがAdaIN-VCやAutoVCなどのSOTAアプローチよりも優れていることが示されました。2つの異なる特徴空間の隠れた構造を2段階のトレーニングプロセスで調整することにより、FragmentVCはアテンションマップの分析で検証されたTransformerのアテンションメカニズムに基づいて、ターゲットの話者の発話からきめの細かい音声フラグメントを抽出し、それらを目的の発話に融合することができ、エンドツーエンドで実行されます。このアプローチは、コンテンツと話者情報の間のもつれを解くことを考慮せずにのみ再構成損失でトレーニングされ、並列データを必要としません。 
[ABSTRACT]音声起動音声起動音声起動音声アクションプロジェクト。音声認識を使用して、音声を失った人々のやる気を引き出すことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: The UPC Speaker Verification System Submitted to VoxCeleb Speaker
  Recognition Challenge 2020 (VoxSRC-20) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.AS/paper_7.html">
      <font color="black">The UPC Speaker Verification System Submitted to VoxCeleb Speaker
  Recognition Challenge 2020 (VoxSRC-20)</font>
    </a>
  </h2>
  <font color="black">最終的な提出は、3つのシステムの組み合わせです。VoxCeleb-1テスト、VoxSRC-20検証、およびテストセットに関するシステムの結果を提供します。System-1は、同様のiベクトルを再構築しようとする自動エンコーダベースのアプローチです。 System-2および-3は、畳み込みニューラルネットワーク（CNN）ベースのシャムアーキテクチャです。 
[要約]最終的な提出は、3つのシステムの組み合わせです。cnnエンコーダーであるvoxへの応答です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Parallel waveform synthesis based on generative adversarial networks
  with voicing-aware conditional discriminators -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.AS/paper_8.html">
      <font color="black">Parallel waveform synthesis based on generative adversarial networks
  with voicing-aware conditional discriminators</font>
    </a>
  </h2>
  <font color="black">主観的なテスト結果は、従来の並列WaveGANおよびWaveNetシステムに対する提案された方法の優位性を示しています。さらに、従来の弁別器は、有声および無声の音声をモデル化するために2つの波形弁別器に分けられます。各弁別器が高調波の特徴的な特性を学習すると、ノイズ成分はそれぞれ、敵対的なトレーニングプロセスがより効率的になり、ジェネレータがより現実的な音声波形を生成できるようになります。 
[ABSTRACT]プロジェクションベースのコンディショニング方法は、ディスクリミネーターのパフォーマンスを大幅に向上させることができます。各ディスクリミネーターがそれぞれ特徴的な特性を学習すると、トレーニングプロセスがより効率的になり、ジェネレーターがより現実的な音声波形を生成できるようになります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Far-Field Speech Recognition with Unified Dereverberation and
  Beamforming -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.AS/paper_9.html">
      <font color="black">End-to-End Far-Field Speech Recognition with Unified Dereverberation and
  Beamforming</font>
    </a>
  </h2>
  <font color="black">空間化されたwsj1-2mixコーパスとREVERBの両方での実験は、提案されたモデルが残響シナリオで従来の方法よりも優れていることを示しています。マルチソース入力を処理できる元のWPDから新しい定式化を導き出し、固有値分解を逆行列に置き換えます。バックプロパゲーションアルゴリズムをより安定させるための操作。最初に、マルチソースマスクベースの重み付き予測誤差（WPE）モジュールが、残響除去のためにフロントエンドに組み込まれます。 
[概要] 2つの新しいフロントエンドアーキテクチャが新しい論文で提案されています。これらは、音声認識基準のみを使用して、従来の方法で完全に最適化されています。2つのアーキテクチャは、認識標準を使用するように最適化されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br><font color="black">2020-05-21</font>
      </time>
    </span>
</section>
<!-- paper0: New interfaces for musical expression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.AS/paper_10.html">
      <font color="black">New interfaces for musical expression</font>
    </a>
  </h2>
  <font color="black">このワークショップでは、音楽コントローラーに関心のあるインターフェースの専門家と、新しい音楽インターフェースの開発に携わるミュージシャンや作曲家が集まります。現在、テクノロジーと音楽文化の間で進行中の対話の最先端である代替の音楽コントローラーには、過去に取り上げられた問題の多くが含まれます。 CHIミーティング..エレクトロニクス、デジタルメディア、高度な素材、およびその他の技術分野の急速な進化により、音楽インターフェースの発明者やデザイナーに前例のない機会が開かれています。 
[概要]代替の音楽コントローラーは、テクノロジーと音楽文化の間で進行中の対話の最先端です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Toward Speech Separation in The Pre-Cocktail Party Problem with TasTas -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.AS/paper_11.html">
      <font color="black">Toward Speech Separation in The Pre-Cocktail Party Problem with TasTas</font>
    </a>
  </h2>
  <font color="black">オンライン音声データリミックス拡張\ cite {zeghidour2020wavesplit}をトレーニングに採用すると、11.14dBのSDRの改善を達成できます。公開WSJ0-5mixデータコーパスでの実験の結果、10.41dBのSDRが改善されました。 https://github.com/ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separationでのDPRNN-TasNetの再実装、およびTasTasは、このDPRNN-TasNetの実装に基づいて実現されていると考えられています。この論文の結果を簡単に再現できること。 
[概要]公開wsj0-5mixデータコーパスでの実験の結果は10です。41dbsdrの改善。このペーパーの結果は簡単に再現できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: LaFurca: Iterative Refined Speech Separation Based on Context-Aware
  Dual-Path Parallel Bi-LSTM -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.AS/paper_12.html">
      <font color="black">LaFurca: Iterative Refined Speech Separation Based on Context-Aware
  Dual-Path Parallel Bi-LSTM</font>
    </a>
  </h2>
  <font color="black">デュアルパス双方向長短期記憶（BiLSTM）ブロックを備えたディープニューラルネットワークは、シーケンスモデリング、特に音声分離などで非常に効果的であることが証明されています。最初に、並列内BiLSTMおよび並列間BiLSTMコンポーネントを備えたデュアルパスネットワークを導入して、異なるブランチ間のパフォーマンスのサブ分散を削減します。次に、グローバルコンテキストアウェアなインターイントラクロスパラレルBiLSTMを使用して、グローバルコンテキスト情報。 
[ABSTRACT]イントラパラレルビルストンおよびインターパラレルビルストンビルストンコンポーネントを備えたデュアルパスネットワークが導入され、パフォーマンスが大幅に低下します。ネットワークは、前のステージの分離結果を改善できるようになります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-23">
        <br><font color="black">2020-01-23</font>
      </time>
    </span>
</section>
<!-- paper0: Acoustic echo cancellation with the dual-signal transformation LSTM
  network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.AS/paper_13.html">
      <font color="black">Acoustic echo cancellation with the dual-signal transformation LSTM
  network</font>
    </a>
  </h2>
  <font color="black">モデルは、60時間の実エコーシナリオと合成エコーシナリオでのみトレーニングされます。トレーニングセットアップには、多言語音声、データ拡張、追加のノイズ、および残響が含まれ、さまざまな実世界の条件に適切に一般化されるモデルを作成します。 ..この方法は、平均オピニオン評点（MOS）の点でAECチャレンジベースラインを0.30上回っています。 
[概要] 46lnは短いものを組み合わせます-ネットワークは学習された特徴表現を組み合わせます。この方法はaec-チャレンジベースラインを0.30上回ります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Leveraging speaker attribute information using multi task learning for
  speaker verification and diarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.AS/paper_14.html">
      <font color="black">Leveraging speaker attribute information using multi task learning for
  speaker verification and diarization</font>
    </a>
  </h2>
  <font color="black">実験コードが公開されました。この作業では、米国最高裁判所の録音の補助変数として話者の年齢を利用し、VoxCelebで話者の国籍を使用して、マルチタスク学習設定で追加の話者属性情報を活用することにより、深い話者の埋め込みを示します。検証およびダイアリゼーションタスクのパフォーマンスを向上させることができ、補助タスクを省略した場合と比較して、最高裁判所の音声ではDERで17.8％、EERで8.9％の相対的な改善を達成できます。スピーカーの深い埋め込みは、スピーカーでスピーカーIDをエンコードするための主要な方法になりました。認識タスク。 
[ABSTRACT]埋め込みスペースは、考えられるすべてのスピーカー間のバリエーションをキャプチャする必要があります、と埋め込みスピーカーは言います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Phase Aware Speech Enhancement using Realisation of Complex-valued LSTM -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.AS/paper_15.html">
      <font color="black">Phase Aware Speech Enhancement using Realisation of Complex-valued LSTM</font>
    </a>
  </h2>
  <font color="black">提案されたRCLSTMは、複素数演算を使用して複素数値シーケンスを処理するように設計されているため、CRMの実数部と虚数部の間の依存関係を保持し、それによって位相を保持します。実数ベースのマスキング方法と比較すると、提案されたRCLSTMは音声品質の知覚評価（PESQ）を含むいくつかの客観的尺度でそれらを4.3％以上改善します。ただし、FFNNは、位相推定に不可欠なシーケンシャル情報をキャプチャできません。 
[概要]複素数値フィードフォワードニューラルネットワークを使用して、位相を考慮に入れて複素比マスクを推定する試みがありました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Rule-embedded network for audio-visual voice activity detection in live
  musical video streams -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.AS/paper_16.html">
      <font color="black">Rule-embedded network for audio-visual voice activity detection in live
  musical video streams</font>
    </a>
  </h2>
  <font color="black">クロスモーダル音楽およびオーディオ信号処理により多くの注目を集めるために、フレームレベルのラベルを備えた新しいライブ音楽ビデオコーパスが導入されます。視覚情報の助けを借りて、この論文はオーディオを融合するためのルール埋め込みネットワークを提案します。モデルがターゲット音声をより適切に検出するのに役立つ視覚（AV）入力。実験は次のことを示しています。1）提案されたルールによるクロスモーダル融合の助けを借りて、AVブランチの検出結果はオーディオブランチの検出結果よりも優れています。 2）バイモーダルモデルのパフォーマンスはオーディオのみのモデルのパフォーマンスをはるかに上回っており、オーディオ信号とビジュアル信号の両方を組み込むことがVADにとって非常に有益であることを示しています。 
[概要]モデルにおけるルールの主な役割は、バイモーダル情報間の関係を調整し、視覚的表現をマスクとして使用して、非ターゲットサウンドの情報を除外することです。フレーム付きの新しいライブ音楽ビデオコーパス-レベルラベルは、クロスモーダル音楽とオーディオ信号処理により多くの注目を集めるために導入されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Contextual Tag Embeddings for Cross-Modal Alignment of Audio
  and Tags -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.AS/paper_17.html">
      <font color="black">Learning Contextual Tag Embeddings for Cross-Modal Alignment of Audio
  and Tags</font>
    </a>
  </h2>
  <font color="black">AAEとMHAを共同で最適化し、オーディオ表現を評価します（つまり、MHAはWEMの出力に参加し、オーディオに関連付けられたタグのコンテキスト表現を提供し、MHAの出力をのエンコーダーの出力に合わせます。対照的な損失を使用するAAE .. AAEのエンコーダーの出力）を、サウンド、音楽ジャンル、楽器分類の3つの異なるダウンストリームタスクで利用します。 
[概要]トレーニング中に不明なタグに一般化できるテキスト処理モデルは使用しません。対照的な損失を使用して、mhaの出力をaaeのエンコーダーに合わせます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: One-class learning towards generalized voice spoofing detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.AS/paper_18.html">
      <font color="black">One-class learning towards generalized voice spoofing detection</font>
    </a>
  </h2>
  <font color="black">重要なアイデアは、本物の音声表現を圧縮し、角度マージンを注入して、埋め込みスペースでのなりすまし攻撃を分離することです。この作業では、を使用して未知の論理アクセス攻撃（つまり、合成音声）を検出するなりすまし防止システムを提案します。 1クラスの学習..私たちのシステムは、ASVspoof 2019チャレンジの評価セットで2.19％の同等のエラー率を達成し、既存のすべての単一システムを上回っています。 
[ABSTRACT]システムは、1クラスの学習を使用して認証攻撃を検出できます。システムは、既存のすべての単一システムを上回る、同等のエラー率、asvspoof2019攻撃を実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Upsampling artifacts in neural audio synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-28/eess.AS/paper_19.html">
      <font color="black">Upsampling artifacts in neural audio synthesis</font>
    </a>
  </h2>
  <font color="black">最初に、アップサンプリングアーティファクトの主な原因が、（i）問題のあるアップサンプリング演算子によって導入されたトーンおよびフィルタリングアーティファクト、および（ii）アップサンプリング中に出現するスペクトルレプリカであることを示します。ここでは、この問題を調査することによってこのギャップに対処します。次に、オーディオ信号処理の観点を比較します。次に、さまざまなニューラルアップサンプラーを比較し、最近隣補間アップサンプラーが、トーンアーティファクトを導入する傾向がある問題のある（ただし最先端の）転置およびサブピクセル畳み込みの代替になる可能性があることを示します。 
[概要]コンピュータビジョンでは、アップサンプリングアーティファクトが研究されており、チェッカーボードアーティファクトとして知られています（その特徴的な視覚パターンのため）。ここでは、オーディオ信号処理の観点からこの問題を研究することにより、このギャップに対処します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
