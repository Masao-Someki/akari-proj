<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-11-04の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: StyleMelGAN: An Efficient High-Fidelity Adversarial Vocoder with
  Temporal Adaptive Normalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.SD/paper_0.html">
      <font color="black">StyleMelGAN: An Efficient High-Fidelity Adversarial Vocoder with
  Temporal Adaptive Normalization</font>
    </a>
  </h2>
  <font color="black">したがって、計算の複雑さを抑えて忠実度の高い音声の合成を可能にする軽量のニューラルボコーダーであるStyleMelGANを提案します。高度に並列化可能な音声生成は、CPUとGPUでリアルタイムよりも数倍高速です。MelGANとParallelWaveGANは依然として劣っています。知覚品質の。 
[概要] wavenet、waveglow、ganモデルが最良の結果を達成します。wavenetやwaveglowなどの軽量ganモデルも最良の結果を達成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Two Heads Are Better Than One: A Two-Stage Approach for Monaural Noise
  Reduction in the Complex Domain -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.SD/paper_1.html">
      <font color="black">Two Heads Are Better Than One: A Two-Stage Approach for Monaural Noise
  Reduction in the Complex Domain</font>
    </a>
  </h2>
  <font color="black">第2段階では、振幅と位相の両方のコンポーネントが調整されます。振幅と位相は2つのサブタスクに分割されます。第1段階では、振幅のみが最適化されます。 
[要約]最初の段階では、マグニチュードのみが最適化されます。実験はwsj0-si84コーパスで実行されます。結果は、提案されたアプローチが以前のベースラインを大幅に上回っていることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Small footprint Text-Independent Speaker Verification for Embedded
  Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.SD/paper_2.html">
      <font color="black">Small footprint Text-Independent Speaker Verification for Embedded
  Systems</font>
    </a>
  </h2>
  <font color="black">さらに、音響的に困難なVOiCESコーパスでモデルを評価します。5秒の長さの発話で200ミリ秒未満の遅延でRaspberry Pi3BなどのIoTシステムに典型的な小型デバイスでソリューションを実行する可能性を示します。学習パラメーターの数が25.6倍減少したのに対し、距離チャレンジからの2019VOiCESの最高スコアモデルに対して2.6パーセントポイントのEERの限定的な増加。 
[概要]モデルはvoxceleb1検証テストセットによって作成されました。モデルは実証済みの実証済みの音声に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Spectrum and Prosody Conversion for Cross-lingual Voice Conversion with
  CycleGAN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.SD/paper_3.html">
      <font color="black">Spectrum and Prosody Conversion for Cross-lingual Voice Conversion with
  CycleGAN</font>
    </a>
  </h2>
  <font color="black">クロスリンガル音声変換に関するこれまでの研究は、主にF0転送の線形変換によるスペクトル変換に焦点を当てています。CWTは、信号をさまざまな時間スケールに分解して、さまざまな時間分解能で韻律を説明する方法を提供します。実験結果は、提案されたスペクトルを示しています。 -Prosody-CycleGANフレームワークは、主観的評価においてSpectrum-CycleGANベースラインを上回っています。 
[要約]たとえば、2人の話者の並列データの必要性を排除します。これは、言語間音声変換における韻律の最初の研究です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-11">
        <br><font color="black">2020-08-11</font>
      </time>
    </span>
</section>
<!-- paper0: Improving RNN transducer with normalized jointer network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.SD/paper_4.html">
      <font color="black">Improving RNN transducer with normalized jointer network</font>
    </a>
  </h2>
  <font color="black">従来のハイブリッドASRシステムと比較して優れたパフォーマンスを示しています。また、最高のパフォーマンスを実現するために、変更されたコンフォーマーエンコーダネットワークとトランスフォーマーXL予測ネットワークでRNN-Tネットワークを強化することを提案します。AISHELL-1データセットでは、 RNN-Tシステムは、AISHELL-1のストリーミングベンチマークと非ストリーミングベンチマークで、それぞれCER 6.15 \％と5.37 \％の最先端の結果を取得します。 
[概要]従来のハイブリッドasrシステムと比較して優れたパフォーマンスを示していますが、モデルはパフォーマンスを損なうことを示しています。また、変更されたコンフォーマーエンコーダネットワークとトランスフォーマー-xl予測ネットワークを使用してrnn-tネットワークを強化することを提案します。最高のパフォーマンスを実現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: VAW-GAN for Singing Voice Conversion with Non-parallel Training Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.SD/paper_5.html">
      <font color="black">VAW-GAN for Singing Voice Conversion with Non-parallel Training Data</font>
    </a>
  </h2>
  <font color="black">エンコーダーをトレーニングして、歌手のアイデンティティと歌の韻律（F0輪郭）を音声コンテンツから解きほぐします。歌手のアイデンティティとF0を条件付けることにより、デコーダーは、目に見えないターゲットの歌手のアイデンティティを持つ出力スペクトル特徴を生成し、F0レンダリングを改善します。並列トレーニングデータ通常、歌声変換システムのトレーニングに必要ですが、実際のアプリケーションでは実用的ではありません。 
[概要]この論文では、vawに基づく歌声変換フレームワークを提案します-gan.itは歌手のアイデンティティとfsteinを使用してf0レンダリングを改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: A Two-Stage Approach to Device-Robust Acoustic Scene Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.SD/paper_6.html">
      <font color="black">A Two-Stage Approach to Device-Robust Acoustic Scene Classification</font>
    </a>
  </h2>
  <font color="black">DCASE 2020タスク1aで評価した結果は、提案されたASCシステムが開発セットで最先端の精度を達成し、CNNアンサンブルの2段階融合である最高のシステムが81.9％の平均精度を実現することを示しています。マルチデバイステストデータの中で、目に見えないデバイスで大幅な改善が得られます。さらに、ASCの新しいデータ拡張スキームも調査されます。2段階の分類器と周波数サブを実装するために、3つの異なるCNNアーキテクチャが検討されています。サンプリングスキームが調査されます。 
[ABSTRACT] cnnシステムは、2つのcnn分類器に基づくアドホックスコアの組み合わせを組み合わせます。新しいシステムは、ascの革新的なデータ拡張スキームを提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic latency speech recognition with asynchronous revision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.SD/paper_7.html">
      <font color="black">Dynamic latency speech recognition with asynchronous revision</font>
    </a>
  </h2>
  <font color="black">実験によると、非同期リビジョンの動的レイテンシモデルでは、ストリーミングモデルに比べて8 \％-14 \％の相対的な改善が見られます。推論段階では、エンコーダとデコーダの履歴状態を非同期にリビジョンして、レイテンシと精度をトレードオフできます。モデルの..トレーニングと推論の不一致を軽減するために、入力発話を順方向接続でいくつかのセグメントにランダムに分割するトレーニング手法であるセグメントクロッピングを提案します。 
[ABSTRACT]これにより、動的なレイテンシー情報を改善して取得できます。これにより、インスタントレイテンシー情報を取得できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: ShaneRun System Description to VoxCeleb Speaker Recognition Challenge
  2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.SD/paper_8.html">
      <font color="black">ShaneRun System Description to VoxCeleb Speaker Recognition Challenge
  2020</font>
    </a>
  </h2>
  <font color="black">また、エンコーダからの元の負のユークリッド距離の代わりに、テスト発話ペアのt-SNE正規化距離を使用して最適な融合を実装する簡単な方法を提供します。最終的に提出されたシステムは、固定データトラックで0.3098 minDCFと5.076％ERRを取得し、ベースラインはそれぞれ1.3％minDCFと2.2％ERRです。ResNet-34をエンコーダーとして使用して、オープンソースのvoxceleb-trainerから参照されるスピーカーの埋め込みを抽出します。 
[概要]スピーカーの埋め込みを抽出するためのエンコーダーとしてresnet-34を使用します。最終的に送信されたシステムは0.3098mindcfおよび5.076％errを取得しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Shift If You Can: Counting and Visualising Correction Operations for
  Beat Tracking Evaluation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.SD/paper_9.html">
      <font color="black">Shift If You Can: Counting and Visualising Correction Operations for
  Beat Tracking Evaluation</font>
    </a>
  </h2>
  <font color="black">注釈効率の簡単な計算について説明し、これをビート追跡システムの定性的評価に使用できる有益な視覚化と組み合わせます。この最新の要約では、ビート追跡評価の修正されたアプローチを提案します。ビート検出のシーケンスを変換して、グラウンドトゥルースアノテーションのシーケンスと比較したときによく知られているFメジャー計算を最大化するために必要な作業の条件。実装および視覚化コードをGitHubリポジトリで無料で利用できるようにします。 
[概要]ソフトウェアが作業中に変更されたのはこれが初めてです。この作業は、追加の、より大きな、許容範囲ウィンドウに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Training Wake Word Detection with Synthesized Speech Data on Confusion
  Words -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.SD/paper_10.html">
      <font color="black">Training Wake Word Detection with Synthesized Speech Data on Confusion
  Words</font>
    </a>
  </h2>
  <font color="black">実験結果は、拡張がシステムの堅牢性の向上に役立つことを示しています。紛らわしい単語は、実際のキーワードスポッティングアプリケーションでよく見られ、複雑な話し言葉や事前定義されたキーワードに似たさまざまな種類の単語が原因でパフォーマンスが大幅に低下します。さらに、マルチスピーカーのテキストから音声へのシステムによって生成された合成データでトレーニングセットを拡張することにより、混乱する単語のシナリオに関して大幅な改善を実現します。 
[概要]データ拡張システムは、拡張をトレーニングするための2つのデータ拡張セットアップに基づいています。結果は、システムの堅牢性を強化するために作成されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Problems using deep generative models for probabilistic audio source
  separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.SD/paper_11.html">
      <font color="black">Problems using deep generative models for probabilistic audio source
  separation</font>
    </a>
  </h2>
  <font color="black">深い生成モデリングの最近の進歩により、複雑なデータから事前分布を学習し、後でベイズ推定に使用できるようになりました。学習した事前分布は、識別的で極端にピークに達するか、滑らかで非識別的であることがわかります。これを定量化します。 2つのオーディオデータセットでの2種類の深層生成モデルの動作。 
[概要]これは、オーディオ信号の通信が不足していることが原因である可能性があります。ただし、オーディオソースの分離などのタスクに必要な適切なプロパティを血管が示すことができないことがわかりました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Do face masks introduce bias in speech technologies? The case of
  automated scoring of speaking proficiency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.SD/paper_12.html">
      <font color="black">Do face masks introduce bias in speech technologies? The case of
  automated scoring of speaking proficiency</font>
    </a>
  </h2>
  <font color="black">バイアスのいくつかの測定値は、2つのグループ間でスコアの違いを示しませんでした。2つのサンプルは、音響測定値の範囲全体で異なり、音声パターンにも小さいが有意な違いを示しています。ただし、これらの違いは違いにつながりません。人間または自動化された英語能力のスコア。 
[概要]顔の覆いは、信号の音響特性と音声パターンの両方に影響を与える可能性があります。ただし、わずかな違いでも、人間または自動化された英語能力のスコアに違いはありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Input-independent Attention Weights Are Expressive Enough: A Study of
  Attention in Self-supervised Audio Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.SD/paper_13.html">
      <font color="black">Input-independent Attention Weights Are Expressive Enough: A Study of
  Attention in Self-supervised Audio Transformers</font>
    </a>
  </h2>
  <font color="black">t-SNE、PCA、およびいくつかの観察の助けを借りて、自己監視オーディオトランスの注意の重みは4つの一般的なケースに分類できます。私たちのアプローチは、典型的な自己注意と同等のパフォーマンスを示していますが、両方で20％少ない時間を必要としますトレーニングと推論..この論文では、音声表現学習のためのトランスベースモデルの計算の複雑さを軽減するためのソリューションを探します。 
[ABSTRACT]トランスフォーマーベースのモデルは、10種類の注意アルゴリズムに基づいています。これらの注意アルゴリズムを使用して、自己監視方式でモデルを事前トレーニングし、特徴抽出器として扱います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-09">
        <br><font color="black">2020-06-09</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Learning unbiased registration and joint segmentation: evaluation on
  longitudinal diffusion MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.IV/paper_0.html">
      <font color="black">Learning unbiased registration and joint segmentation: evaluation on
  longitudinal diffusion MRI</font>
    </a>
  </h2>
  <font color="black">この処理バイアスは、セグメンテーションを1つのボクセルのみで変換する場合に得られるバイアスよりもさらに小さく、微妙な数値の不安定性と補間に起因する可能性があります。2を使用した脳MRIデータセットの白質路の縦断分析に関する提案手法を評価します。 3249人の3つの時点、つまり合計8045の画像。さらに、このグループごとのフレームワークは、偏りのない被験者内テンプレートを直接構築し、信頼性の高い効率的な分析を可能にすることにより、学習ベースの縦断的研究の新しい方法を導入します時空間イメージングバイオマーカーの。 
[ABSTRACT]分析は、一貫したセグメンテーションを取得するために画像をグループの平均空間にのみ登録する偏りのない学習戦略に基づいて、両方のタスクを共同で最適化する調整されたフレームワークから恩恵を受ける可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Fast High Resolution Blood Flow Estimation and Clutter Rejection via an
  Alternating Optimization Problem -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.IV/paper_1.html">
      <font color="black">Fast High Resolution Blood Flow Estimation and Clutter Rejection via an
  Alternating Optimization Problem</font>
    </a>
  </h2>
  <font color="black">\ textit {in vivo}データで実行された数値調査は、最先端の方法と比較して提案されたアプローチの効率を示しています。この論文では、超音波から高解像度のドップラー血流を推定するための計算効率の高い手法を紹介します。超音波画像シーケンス..より正確には、堅牢な主成分分析に基づくブラインドデコンボリューション法を実装する新しい高速交互最小化アルゴリズムで構成されています。 
[概要]新しい方法は、プロジェクトの堅牢な主要部分に基づくブラインドデコンボリューション法を使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Image Colorization: A Survey and Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.IV/paper_2.html">
      <font color="black">Image Colorization: A Survey and Dataset</font>
    </a>
  </h2>
  <font color="black">この記事では、ディープラーニングアルゴリズムを使用した最近の最先端のカラー化の包括的な調査を紹介し、スキップ接続、入力などの観点から基本的なブロックアーキテクチャを説明します。最近、ディープラーニング技術は特に画像のカラー化で進歩しました。既存のカラー化手法を大まかに7つのクラスに分類できます。 
[概要]画像のカラー化で特に進歩した深層学習手法。オプティマイザ、損失関数、トレーニングプロトコル、トレーニングデータなど、さまざまなさまざまな手法があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: A Predictive Visual Analytics System for Studying Neurodegenerative
  Disease based on DTI Fiber Tracts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.IV/paper_3.html">
      <font color="black">A Predictive Visual Analytics System for Studying Neurodegenerative
  Disease based on DTI Fiber Tracts</font>
    </a>
  </h2>
  <font color="black">パーキンソン病進行マーカーイニシアチブの研究データベースからの実際のデータを使用して、いくつかのケーススタディを実施します。システムのAI拡張インターフェースは、統計的特徴空間、物理的空間、およびの空間を含む、組織化された全体的な分析空間を通じてユーザーをガイドします。さまざまなグループの患者..ラベル付けされたDTI線維路データと対応する統計に基づいて患者グループを研究するためのインテリジェントな視覚分析システムを紹介します。 
[概要]ラベル付けされたdtiファイバートラクトデータと対応する統計に基づいて患者グループを研究するためのインテリジェントな視覚分析システムを紹介します。カスタム機械学習パイプラインを使用して、この大きな分析スペースを絞り込み、さまざまな範囲で実践的に調査します。リンクされた視覚化</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Generalized Wasserstein Dice Score, Distributionally Robust Deep
  Learning, and Ranger for brain tumor segmentation: BraTS 2020 challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.IV/paper_4.html">
      <font color="black">Generalized Wasserstein Dice Score, Distributionally Robust Deep
  Learning, and Ranger for brain tumor segmentation: BraTS 2020 challenge</font>
    </a>
  </h2>
  <font color="black">私たちのアンサンブルは、BraTS 2020チャレンジのセグメンテーションタスクで登録された693チームのうち4位にランクされました。一般化されたWassersteinダイス損失は、BraTSでラベル付けされた腫瘍領域の階層構造を利用できるサンプルごとの損失関数です。 Rangerは、広く使用されているAdamオプティマイザーを一般化したもので、バッチサイズが小さく、ラベルにノイズが多いため、より安定しています。 
[概要]私たちは、一般的で最先端の3d u-ネットアーキテクチャに固執しました。これらには、非標準のサンプルごとの損失関数、非標準の母集団損失関数、レンジャー付きのオプティマイザーが含まれていました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Review: Deep Learning in Electron Microscopy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.IV/paper_5.html">
      <font color="black">Review: Deep Learning in Electron Microscopy</font>
    </a>
  </h2>
  <font color="black">コンテキストとして、電子顕微鏡法における深層学習の一般的なアプリケーションを確認します。次に、ニューラルネットワークコンポーネント、一般的なアーキテクチャ、およびそれらの最適化を確認します。次に、深層学習と電子顕微鏡とのインターフェースを開始するために必要なハードウェアとソフトウェアについて説明します。 
[概要]このレビューペーパーは、知識が限られている開発者を対象とした実用的な視点を提供します。これには、電子顕微鏡などの技術の実用的な視点が含まれます。最後に、電子顕微鏡における深層学習の将来の方向性について説明します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Accelerated WGAN update strategy with loss change rate balancing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.IV/paper_6.html">
      <font color="black">Accelerated WGAN update strategy with loss change rate balancing</font>
    </a>
  </h2>
  <font color="black">この論文では、この更新戦略が精度と収束速度の点で最適ではないことを示し、WGAN損失を使用したWasserstein GAN（WGAN）およびその他のGANの新しい更新戦略を提案します（例：Generative Adversarial Networksでの弁別器の最適化） （GAN）内部トレーニングループで完了するまでは計算上禁止されており、有限のデータセットではオーバーフィットになります。提案された更新戦略は、GとDの損失変化率の比較に基づいています。提案された戦略が両方の収束を改善することを示します。速度と精度。
[要約]これに対処するための一般的な更新戦略は、kとジェネレータgの1つの拡張ステップを交互に行うことです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-28">
        <br><font color="black">2020-08-28</font>
      </time>
    </span>
</section>
<!-- paper0: Developing High Quality Training Samples for Deep Learning Based Local
  Climate Classification in Korea -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.IV/paper_7.html">
      <font color="black">Developing High Quality Training Samples for Deep Learning Based Local
  Climate Classification in Korea</font>
    </a>
  </h2>
  <font color="black">代わりに、この研究では、マルチスケール畳み込みニューラルネットワークを使用して韓国の主要都市をマッピングするカスタムLCZデータを開発しました。グローバルスケールのLCZマッピングが検討されていますが、精度の低さ、ラベルの品質の変動、またはドメイン適応の課題によって制限されています。結果は、深層学習で新しいカスタムLCZデータを使用すると、マシン学習やグローバルSo2Satデータセットの転送学習を使用した従来のコミュニティベースのLCZマッピングと比較して、より正確なLCZマップ結果を生成できることを示しました。 
[概要]都市フットプリントデータは、高解像度の都市フレームワークを提供しますが、分布、パターン、および特性に関する重要な情報が不足しています。都市ゾーンマップは調査されていますが、精度の低さ、ラベルの品質の変動、またはドメイン適応の課題によって制限されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Cognitive Biomarker Prioritization in Alzheimer's Disease using Brain
  Morphometric Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.IV/paper_8.html">
      <font color="black">Cognitive Biomarker Prioritization in Alzheimer's Disease using Brain
  Morphometric Data</font>
    </a>
  </h2>
  <font color="black">方法：新しく開発されたランク学習法PLTRを採用して、パラダイムを実装します。クロス検証とレベルアウト検証の設定で実験を行います。また、PLTRを拡張して、最も効果的な認知評価と効果の低いものをより適切に分離しますもの。 
[概要]パーソナライズされた認知評価の優先順位付けを可能にする機械学習ツールを開発します。この方法は、最も効果的な認知評価を優先順位付けリストに追加する潜在的なスコアリング関数を学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br><font color="black">2020-02-18</font>
      </time>
    </span>
</section>
<!-- paper0: Genetic U-Net: Automatically Designing Lightweight U-shaped CNN
  Architectures Using the Genetic Algorithm for Retinal Vessel Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.IV/paper_9.html">
      <font color="black">Genetic U-Net: Automatically Designing Lightweight U-shaped CNN
  Architectures Using the Genetic Algorithm for Retinal Vessel Segmentation</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案された方法が、DRIVE、CHASE \ _DB1、STAREの3つの公開データセットで既存の方法よりも優れていることを示しています。 ..この問題に対処するために、遺伝的アルゴリズム（GA）を使用して、網膜血管セグメンテーション用の軽量U字型CNNを自動的に設計するGeneticU-Netと呼ばれる新しい方法を提案します。 
[ABSTRACT] cnsは、検索スペースを駆動する遺伝的アルゴリズムに基づいています。この方法では、遺伝的アルゴリズムを使用して優れたアーキテクチャを検索します。これらは、最先端のモデルよりも軽量ですが正確です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Encoding Clinical Priori in 3D Convolutional Neural Networks for
  Prostate Cancer Detection in bpMRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.IV/paper_10.html">
      <font color="black">Encoding Clinical Priori in 3D Convolutional Neural Networks for
  Prostate Cancer Detection in bpMRI</font>
    </a>
  </h2>
  <font color="black">パフォーマンスを評価するために、800の機関トレーニング検証スキャンを使用してU-Net、U-SEResNet、UNet ++、およびAttention U-Netの3D適応をトレーニングし、放射線学的に推定された注釈と計算された事前評価を組み合わせます。200の独立したテストbpMRIスキャンの場合csPCaの組織学的に確認された描写により、臨床的先験的にエンコードする提案された方法は、患者ベースの診断（AUROCの最大8.70％の増加）および病変レベルの検出（0.1〜1.0の偽陽性の間の1.08pAUCの平均増加）を改善する強力な能力を示します患者ごとに）4つのアーキテクチャすべてにわたって..解剖学的事前情報は、U-Netアーキテクチャに基づく最先端の畳み込み神経ネットワーク（CNN）にドメイン固有の臨床知識を注入するための実行可能な媒体である可能性があると仮定します。 
[概要]前立腺がん（cspca）の空間的有病率とゾーンの区別をキャプチャする確率的母集団を紹介します。バイパラメトリックmrイメージング（bpmri）でコンピュータ支援検出（cad）を改善できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-31">
        <br><font color="black">2020-10-31</font>
      </time>
    </span>
</section>
<!-- paper0: Solving Inverse Problems with Hybrid Deep Image Priors: the challenge of
  preventing overfitting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.IV/paper_11.html">
      <font color="black">Solving Inverse Problems with Hybrid Deep Image Priors: the challenge of
  preventing overfitting</font>
    </a>
  </h2>
  <font color="black">数値結果は、ハイブリッド事前分布が過剰適合の防止に重要な役割を果たしていることを示しています。交互方向乗数法（ADMM）を使用して新しい事前分布を組み込み、さまざまな形式のADMMを試して、の内部ループによって引き起こされる余分な計算を回避します。 ADMMの手順..他の深層学習アプローチに対するDIPの主な利点は、大規模なデータセットにアクセスする必要がないことです。 
[ABSTRACT]反復回数が増えると、画像のノイズにディップがオーバーフィットします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: When We First Met: Visual-Inertial Person Localization for Co-Robot
  Rendezvous -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_0.html">
      <font color="black">When We First Met: Visual-Inertial Person Localization for Co-Robot
  Rendezvous</font>
    </a>
  </h2>
  <font color="black">私たちの実験は、提案した方法がわずか5秒のIMUデータとビデオを使用して80.7％の精度で対象者を正確に特定できることを示しています。私たちは、人の動きがである視覚慣性特徴空間を学習する方法を提案します。ビデオは、ウェアラブル慣性計測ユニット（IMU）で測定された動きに簡単に一致させることができます。人の慣性情報は、スマートフォンなどのウェアラブルデバイスで測定でき、ランデブー中に自律システムと選択的に共有できます。 
[概要]このコンセプトは、将来的にセンサーセンサーに使用される可能性があります。また、群衆の中にいる人々に会うための自動運転車としても使用される可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br><font color="black">2020-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Deformable Tetrahedral Meshes for 3D Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_1.html">
      <font color="black">Learning Deformable Tetrahedral Meshes for 3D Reconstruction</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、ノイズの多い点群から直接計算された高品質の四面体メッシュを取得し、入力として単一の画像のみを使用して高品質の3D四面体メッシュの結果を最初に紹介します。後処理は必要ありません。学習ベースの3D再構成に対応する3D形状表現は、機械学習とコンピューターグラフィックスの未解決の問題です。 
[ABSTRACT] def def deftetとして知られるdeftetは、モデルとして使用できることを示すことができました。たとえば、モデルのモデル化に使用されましたが、現在はテスト済みです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Visual Representations for Transfer Learning by Suppressing
  Texture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_2.html">
      <font color="black">Learning Visual Representations for Transfer Learning by Suppressing
  Texture</font>
    </a>
  </h2>
  <font color="black">これらの問題に対処するために、異方性拡散に基づく古典的な方法を使用して、テクスチャが抑制された画像を使用したトレーニングを強化することを提案します。この方法は、転送学習タスクに特に効果的であり、5つの標準的な転送学習データセットでパフォーマンスの向上が見られました。重要なエッジ情報を保持し、同時にテクスチャを抑制します。 
[概要]この簡単な方法は、重要なエッジ情報を保持し、同時にテクスチャを抑制するのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Rotational Rectification Network: Enabling Pedestrian Detection for
  Mobile Vision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_3.html">
      <font color="black">Rotational Rectification Network: Enabling Pedestrian Detection for
  Mobile Vision</font>
    </a>
  </h2>
  <font color="black">このような状況では、カメラの動きによって歩行者の画像が極端な角度でキャプチャされる可能性があります。回転整流ネットワークは、回転情報を空間トランスネットワークに渡す2D回転推定モジュールを使用して、画像の特徴を歪めません。問題は、CNNベースの歩行者（またはオブジェクト）検出器に挿入してカメラの回転の大幅な変化に適応できる回転整流ネットワーク（R2N）を提案することです。 
[概要]これにより、標準の歩行者検出器を使用すると、歩行者検出のパフォーマンスが低下する可能性があります。ロジャー整流ネットワークを使用すると、画像の回転が激しい場合の最先端の歩行者検出器のパフォーマンスを最大45％向上させることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2017-06-19">
        <br><font color="black">2017-06-19</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Joint Transmission-Recognition for Multi-View Cameras -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_4.html">
      <font color="black">Deep Joint Transmission-Recognition for Multi-View Cameras</font>
    </a>
  </h2>
  <font color="black">ワイヤレスカメラを使用した監視アプリケーションを動機として、エッジデバイスとして動作するマルチビューカメラによって実行されるワイヤレスチャネルを介した人物分類タスクを検討します。ワイヤレスエッジでの効率的な推論のための共同送信認識スキームを提案します。ディープニューラルネットワーク（DNN）ベースの圧縮方式で、デジタル（個別）伝送とジョイントソースチャネルコーディング（JSCC）方式が組み込まれています。 
[概要]ワイヤレスカメラはwiwi-fiデバイスとして動作します。ワイヤレス通信スキームを使用してwiwiwi-fiを開発できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Learning unbiased registration and joint segmentation: evaluation on
  longitudinal diffusion MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_5.html">
      <font color="black">Learning unbiased registration and joint segmentation: evaluation on
  longitudinal diffusion MRI</font>
    </a>
  </h2>
  <font color="black">この処理バイアスは、セグメンテーションを1つのボクセルのみで変換する場合に得られるバイアスよりもさらに小さく、これは微妙な数値の不安定性と補間に起因する可能性があります。 3249人の3つの時点、つまり合計8045枚の画像。結果は、暗黙の参照画像が入力画像の平均であることを確認します。 
[ABSTRACT]分析は、一貫したセグメンテーションを取得するために画像をグループの平均空間にのみ登録する偏りのない学習戦略に基づいて、両方のタスクを共同で最適化する調整されたフレームワークから恩恵を受ける可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: A Comprehensive Study of Class Incremental Learning Algorithms for
  Visual Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_6.html">
      <font color="black">A Comprehensive Study of Class Incremental Learning Algorithms for
  Visual Tasks</font>
    </a>
  </h2>
  <font color="black">主な実験結果は、既存のアルゴリズムのいずれも、評価されたすべての設定で最良の結果を達成しないことです。重要な違いは、過去のクラスの制限されたメモリが許可されているかどうかに特に発生します。ここでは、後者に焦点を当て、それらを共通の概念的および実験的フレームワークを提案し、次の貢献を提案します：（1）インクリメンタル学習アルゴリズムの6つの望ましいプロパティを定義し、これらのプロパティに従って分析します。（2）クラスインクリメンタル学習問題の統一された形式化を導入します。（3）提案します。データセットの数、データセットのサイズ、制限されたメモリのサイズ、増分状態の数の点で既存のものよりも徹底的な共通の評価フレームワーク、（4）過去の模範選択のための群れの有用性を調査する、（5）実験的証拠を提供する壊滅的な忘却に取り組むために知識蒸留を使用せずに競争力のあるパフォーマンスを得ることが可能であり、（6）再現を容易にすることテストされたすべてのメソッドを共通のオープンソースリポジトリに統合することによる重複性。 
[概要]このような場合に直面する主な課題は、壊滅的な忘却です。これには、新しいデータが取り込まれたときに過去のデータをアンダーフィットするニューラルネットワークの傾向が含まれます。2番目のタイプのアプローチは、深いモデルサイズを修正し、その目的が確実にすることであるメカニズムを導入します。モデルの安定性と可塑性の間の適切な妥協点</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: HyNet: Learning Local Descriptor with Hybrid Similarity Measure and
  Triplet Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_7.html">
      <font color="black">HyNet: Learning Local Descriptor with Hybrid Similarity Measure and
  Triplet Loss</font>
    </a>
  </h2>
  <font color="black">HyNetは、パッチマッチング、検証、検索を含む標準ベンチマークで以前の方法を大幅に上回り、3D再構成タスクで完全なエンドツーエンドの方法を上回っています。HyNetは、トリプレットマージン損失のハイブリッド類似性測定を導入します。記述子ノルムを制約する正則化項、およびすべての中間特徴マップと出力記述子のL2正規化を実行する新しいネットワークアーキテクチャ。私たちの観察に基づいて、最先端の新しいローカル記述子であるHyNetを提案します。結果は一致します。 
[ABSTRACT]研究は、l2正規化がトレーニング中に背中の再伝播された記述子勾配にどのように影響するかを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br><font color="black">2020-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: Kernel Two-Dimensional Ridge Regression for Subspace Clustering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_8.html">
      <font color="black">Kernel Two-Dimensional Ridge Regression for Subspace Clustering</font>
    </a>
  </h2>
  <font color="black">画像の投影係数と表現係数を同時に求めて、相互に強化し、強力なデータ表現を実現します。最近、部分空間クラスタリング手法が広く研究されています。広範な実験結果により、新しい手法の有効性が検証されています。 
[ABSTRACT]表現の学習を強化するためにニューロンとして2Dデータを使用します。提案された目的関数を解決しようとします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Wheat Crop Yield Prediction Using Deep LSTM Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_9.html">
      <font color="black">Wheat Crop Yield Prediction Using Deep LSTM Model</font>
    </a>
  </h2>
  <font color="black">インドのいくつかの州で提案されているテシル（ブロック）レベルの小麦予測に関するアプローチを評価し、既存の方法よりも50％以上優れていることを示します。また、農地、水域、都市部は収量推定の改善に役立ちます。公的に入手可能な衛星画像から作物の収量を予測するための信頼性が高く安価な方法を紹介します。 
[ABSTRACT]衛星画像を使用して、衛星画像から収穫量を予測できます。このアプローチは、成長期のステップの関連性をアイドル状態でモデル化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-supervised AU Intensity Estimation with Contrastive Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_10.html">
      <font color="black">Semi-supervised AU Intensity Estimation with Contrastive Learning</font>
    </a>
  </h2>
  <font color="black">最初の段階では、ラベルのないビデオのデータセットを使用して、対照的な学習に基づいて顔の行動のダイナミクスの強力な時空間表現を学習します。私たちの知る限り、監視されていない方法で顔の行動をモデル化するためのこのフレームワークに基づいて構築した最初の段階です。ステージは、ランダムに選択されたラベル付きフレームの別のデータセットを使用して、AU強度を推定するための時空間モデルの上にリグレッサをトレーニングします。 
[概要]私たちの方法では、キーフレームを手動で選択する必要はありません。わずか2ドルで最先端の結果を生成します。既存の方法を半ば実行します。ラベル付きフレームを慎重に選択しなくても、時間のかかる作業です。以前のアプローチではまだ必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Passport-aware Normalization for Deep Model Protection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_11.html">
      <font color="black">Passport-aware Normalization for Deep Model Protection</font>
    </a>
  </h2>
  <font color="black">したがって、ターゲットモデルの構造は変化しません。広範な実験を通じて、画像と3Dポイント認識モデルの両方でその有効性を検証します。モデルIPが誰かに盗まれた疑いがある場合にのみ、パスポート対応のプライベートブランチは所有権の確認のために追加されました。 
[概要]これらのモデルの多くは、ターゲットネットワークの変更が必要です。このモデルモデルIPは、誰かに盗まれたと考えられています。モデルモデルモデルの所有者は保護できません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: A Deep Temporal Fusion Framework for Scene Flow Using a Learnable Motion
  Model and Occlusions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_12.html">
      <font color="black">A Deep Temporal Fusion Framework for Scene Flow Using a Learnable Motion
  Model and Occlusions</font>
    </a>
  </h2>
  <font color="black">私たちの仕事は、オクルージョンの問題を克服するために、マルチフレーム設定でシーンフロー推定値を時間的に融合するための新しいデータ駆動型アプローチを提案します。2番目のステップでは、ニューラルネットワークが共通の参照フレームからの双方向シーンフロー推定値を組み合わせます、正確な推定値とオクルージョンマスクの自然な副産物を生成します。従来のデュアルフレームアプローチでは、特に車両の環境認識が大きいため、オクルージョンと視界外の動きが制限要因になります（自我- ）オブジェクトの動き。 
[ABSTRACT]モーション分析は、オクルージョンと視野外モーションが制限要因であることを示しています。しかし、代わりに、一定のモーションモデルに依存せず、データからモーションの一般的な時間的関係を学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Attention Beam: An Image Captioning Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_13.html">
      <font color="black">Attention Beam: An Image Captioning Approach</font>
    </a>
  </h2>
  <font color="black">人間にとっては簡単な作業のように見えますが、画像を理解する能力（コンピュータビジョン）が必要であり、その結果、画像の人間のような記述を生成する（自然言語理解）必要があるため、機械にとっては困難です。最近では、エンコーダ-デコーダーベースのアーキテクチャは、画像キャプションの最先端の結果を達成しています。ここでは、3つのベンチマークデータセット（Flickr8k、Flickr30k、およびFlickr30k）でより高品質のキャプションを提供するエンコーダーデコーダーベースのアーキテクチャに加えて、ビーム検索のヒューリスティックを提示します。 MSCOCO。 
[概要]エンコーダー（デコーダーベースのアーキテクチャー）は、3つのベンチマークデータセット（flickr8k、flickr30k、ms coco）でより良いキャプションを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Image Colorization: A Survey and Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_14.html">
      <font color="black">Image Colorization: A Survey and Dataset</font>
    </a>
  </h2>
  <font color="black">一般に、既存のカラー化手法を7つのクラスに大まかに分類できます。最近、ディープラーニング手法は特に画像のカラー化で進歩しました。この記事では、ディープラーニングアルゴリズムを使用した最近の最先端のカラー化の包括的な調査について説明します。スキップ接続、入力などに関する基本的なブロックアーキテクチャ。
[要約]ディープラーニング手法は、特に画像のカラー化のために進歩しました。さまざまなさまざまな手法には、オプティマイザ、損失関数、トレーニングプロトコル、トレーニングデータなどが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Relational Graph Learning on Visual and Kinematics Embeddings for
  Accurate Gesture Recognition in Robotic Surgery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_15.html">
      <font color="black">Relational Graph Learning on Visual and Kinematics Embeddings for
  Accurate Gesture Recognition in Robotic Surgery</font>
    </a>
  </h2>
  <font color="black">私たちの方法の有効性は、公開JIGSAWSデータセットの最新の結果で実証されており、縫合とノットタイピングタスクの両方で現在のユニモーダルおよびマルチモーダル方法を上回っています。ただし、既存の方法はユニモーダルのみを採用しています。モーダルデータまたはマルチモーダル表現を直接連結します。これは、視覚および運動学データに固有の有益な相関関係を十分に活用して、ジェスチャー認識の精度を高めることができません。具体的には、最初に、時間的畳み込みネットワークとLSTMユニットを使用してビデオおよび運動学シーケンスから埋め込みを抽出します。 。 
[ABSTRACT]レーザービデオとロボット運動学を記録することができ、外科的ジェスチャーを理解するための適切な知識を提供します。これは、視覚情報と運動学情報を動的に統合するマルチモーダルダーバングラフネットワークの新しいアプローチである可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Recent Advances in Understanding Adversarial Robustness of Deep Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_16.html">
      <font color="black">Recent Advances in Understanding Adversarial Robustness of Deep Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">その後、頻繁に使用されるベンチマークを調査し、理論的に証明された敵対的ロバスト性の限界について言及します。さまざまな観点から、敵対的ロバスト性。敵対的例に耐性のある高いロバスト性を備えたモデルを取得することがますます重要になっています。 
[ABSTRACT]自然サンプルの知覚できない摂動は、公正な信頼スコアで誤った予測につながる可能性があります。敵対的攻撃と堅牢性に限界を与えます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Effective Representations from Global and Local Features for
  Cross-View Gait Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_17.html">
      <font color="black">Learning Effective Representations from Global and Local Features for
  Cross-View Gait Recognition</font>
    </a>
  </h2>
  <font color="black">この目標に向けて、グローバルな視覚情報とローカルな領域の詳細の両方を活用し、グローバルおよびローカルの特徴抽出器（GLFE）を開発します。歩行認識は最も重要な生体認証技術の1つであり、多くの分野で適用されています。 GLFEモジュールは、新しく設計された複数のグローバルおよびローカル畳み込み層（GLConv）で構成され、グローバルおよびローカルの特徴を原則的にアンサンブルします。 
[ABSTRACT]歩行認識フレームワークは、人間の全体的な外観または局所領域から抽出された記述子によって各人間の歩行フレームを表します。この方法により、視覚的特徴の識別性が大幅に向上し、歩行認識データが向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Media Keyphrase Prediction: A Unified Framework with
  Multi-Modality Multi-Head Attention and Image Wordings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_18.html">
      <font color="black">Cross-Media Keyphrase Prediction: A Unified Framework with
  Multi-Modality Multi-Head Attention and Image Wordings</font>
    </a>
  </h2>
  <font color="black">Twitterから新たに収集された大規模なデータセットでの広範な実験は、私たちのモデルが従来の注意ネットワークに基づく以前の最先端技術を大幅に上回っていることを示しています。ソーシャルメディアスタイルのテキストと画像をより適切に調整するために、次のことを提案します。 -複雑なクロスメディアインタラクションをキャプチャするためのモダリティマルチヘッドアテンション（M3H-Att）。 （2）2つのモダリティを橋渡しするための、光学文字と画像属性の形式の画像表現。さらに、キーフレーズの分類と生成の出力を活用し、それらの利点を組み合わせるための統一されたフレームワークを設計します。 
[ABSTRACT]ソーシャルメディアはキーフレーズ予測としてますます人気が高まっています。これは、ユーザーが必要なものをすばやくキャプチャできるようにするためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: A spatial hue similarity measure for assessment of colourisation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_19.html">
      <font color="black">A spatial hue similarity measure for assessment of colourisation</font>
    </a>
  </h2>
  <font color="black">これらの措置は、基準グラウンドトゥルース以外のもっともらしいモードにペナルティを課します。それらがグラウンドトゥルースにピクセル距離で近い場合、それらはしばしば信じがたいモードに適切にペナルティを課すことができません。これらはピクセル差分法であるため、空間コヒーレンシを評価できません。この方法では、SOTA着色法の定性的および定量的なパフォーマンス比較が可能になり、主観的な人間の目視検査への依存が軽減されます。SSIMを彩度チャネルに適用しますが、色相チャネルのSSIMを再定式化します。空間色相類似性測定（SHSM）と呼ばれる測定に。 
[概要]システムは、視覚的に-コヒーレントな色相チャネルが空間的にペナルティを課しながらハイスコアを達成することを可能にします-インコヒーレントモード</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Representation Learning by InvariancePropagation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_20.html">
      <font color="black">Unsupervised Representation Learning by InvariancePropagation</font>
    </a>
  </h2>
  <font color="black">また、Places205とPascal VOCでの線形分類、小規模データセットでの転移学習など、他のダウンストリームタスクで最先端のパフォーマンスを実現します。その結果、ResNet-50をバックボーンとして、この方法で実現します。 ImageNet線形分類で71.3％のトップ1精度、1％ラベルのみで78.2％トップ5精度の微調整、以前の結果を上回っています。この論文では、カテゴリレベルの変動に対して不変の表現の学習に焦点を当てる不変性伝播を提案します。 、同じカテゴリの異なるインスタンスによって提供されます。 
[ABSTRACT]私たちのメソッドは、意味的に一貫したカテゴリを再帰的に検出します。同じインスタンスの異なるビューに基づいて、インスタンスへの表現の伝播を学習できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-07">
        <br><font color="black">2020-10-07</font>
      </time>
    </span>
</section>
<!-- paper0: On estimating gaze by self-attention augmented convolutions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_21.html">
      <font color="black">On estimating gaze by self-attention augmented convolutions</font>
    </a>
  </h2>
  <font color="black">私たちの実験では、MPIIFaceGazeデータセットの最先端の方法と比較して平均角度誤差が2.38％減少し、EyeDiapデータセットで2位になったことを結果が示しました。このメカニズムは、視線回帰前の顔と目の画像から導出された、より優れた、より空間を意識した特徴表現..フレームワークARes-gazeと名付けました。これは、注意を強化したResNet（ARes-14）を2つの畳み込みバックボーンとして探索します。 
[概要] wei wei weiweilは、この特定のタスクのネットワークアーキテクチャにはまだ改善の余地があると述べています。彼は、システムがフルフェイス画像で離れた領域間の依存関係を学習することで、より深いアーキテクチャよりも優れたパフォーマンスを発揮できると述べています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: The Devil is in Classification: A Simple Framework for Long-tail Object
  Detection and Instance Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_22.html">
      <font color="black">The Devil is in Classification: A Simple Framework for Long-tail Object
  Detection and Instance Segmentation</font>
    </a>
  </h2>
  <font color="black">2019 LVISチャレンジに勝った方法で..このような観察に基づいて、まず、インスタンスのセグメンテーション結果を実際に向上させるロングテール分類パフォーマンスを改善するためのさまざまな手法を検討します。具体的には、状態のパフォーマンス低下を体系的に調査します。 -最新の2段階インスタンスセグメンテーションモデル最近のロングテールLVISデータセットでR-CNNをマスクし、主な原因がオブジェクト提案の不正確な分類であることを明らかにします。 
[概要]これらのデータセットは、かなりロングテールでパフォーマンスが低下する傾向があります。これは、オブジェクト提案の分類が不正確であるためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-23">
        <br><font color="black">2020-07-23</font>
      </time>
    </span>
</section>
<!-- paper0: The Aleatoric Uncertainty Estimation Using a Separate Formulation with
  Virtual Residuals -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_23.html">
      <font color="black">The Aleatoric Uncertainty Estimation Using a Separate Formulation with
  Virtual Residuals</font>
    </a>
  </h2>
  <font color="black">シミュレーションデータによる回帰、年齢推定、深度推定の3種類の実験を行う。ターゲット推定と不確実性推定を分離することにより、信号推定と不確実性推定のバランスも制御する。提案手法が状態よりも優れていることを示す。信号と不確実性の推定のための最先端の技術。 
[要約]提案された方法は、信号と不確実性の推定のための最先端の技術よりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Learning a Generative Motion Model from Image Sequences based on a
  Latent Motion Matrix -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_24.html">
      <font color="black">Learning a Generative Motion Model from Image Sequences based on a
  Latent Motion Matrix</font>
    </a>
  </h2>
  <font color="black">この教師なし生成モデルは、事前の新しい多変量ガウス過程に従い、微分同相運動モデルにつながる時間畳み込みネットワーク内に適用されます。この方法は、償却変量推論を使用してトレーニングされた条件付き潜在変数モデルに基づいています。時空間登録のための一連の画像から確率的運動モデルを学習します。 
[ABSTRACT]私たちのモデルは、低レベルのモーションマトリックスでモーションをエンコードします。シミュレーションや補間などのさまざまなモーション分析タスクを可能にします。この方法は、条件付き潜在変数モデルに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: PV-NAS: Practical Neural Architecture Search for Video Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_25.html">
      <font color="black">PV-NAS: Practical Neural Architecture Search for Video Recognition</font>
    </a>
  </h2>
  <font color="black">本研究では、実用的なソリューション、すなわち実用的なビデオニューラルアーキテクチャ検索（PV-NAS）を提案します。PV-NASは、勾配ベースの検索方法を使用して、新しい時空間ネットワーク検索空間で非常に大規模なアーキテクチャを効率的に検索できます。 ..次善のソリューションに固執することを避けるために、検索されたモデルの十分なネットワーク多様性を促進するための新しい学習率スケジューラを提案します。ただし、ビデオ認識ネットワークの自動設計はあまり検討されていません。 
[概要]ビデオタスク用のディープニューラルネットワークは高度にカスタマイズされています。このようなネットワークの設計には、ドメインの専門家と費用のかかる試行錯誤のテストが必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: RONELD: Robust Neural Network Output Enhancement for Active Lane
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_26.html">
      <font color="black">RONELD: Robust Neural Network Output Enhancement for Active Lane
  Detection</font>
    </a>
  </h2>
  <font color="black">最初に確率マップ出力からレーンポイントを適応的に抽出し、次に曲線レーンと直線レーンを検出してから、直線レーンで加重最小二乗線形回帰を使用して、実際の画像のエッジマップの断片化に起因する壊れたレーンエッジを修正します。クロスデータセット検証テストでRONELDを使用すると、精度が2倍に向上します。これらの各モデルは、同じデータセットから取得したトレインおよびテスト入力で特にうまく機能しますが、異なる環境の見えないデータセットではパフォーマンスが大幅に低下します。 
[ABSTRACT]高速追跡トラック、およびデータデータデータを使用してアクティブレーンを最適化します。高速追跡技術は畳み込みニューラルネットワークに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-19">
        <br><font color="black">2020-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: Generalized Wasserstein Dice Score, Distributionally Robust Deep
  Learning, and Ranger for brain tumor segmentation: BraTS 2020 challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_27.html">
      <font color="black">Generalized Wasserstein Dice Score, Distributionally Robust Deep
  Learning, and Ranger for brain tumor segmentation: BraTS 2020 challenge</font>
    </a>
  </h2>
  <font color="black">私たちのアンサンブルは、BraTS 2020チャレンジのセグメンテーションタスクで登録された693チームのうち4番目にランク付けされました。一般化されたWassersteinダイス損失は、BraTSでラベル付けされた腫瘍領域の階層構造を利用できるサンプルごとの損失関数です。分布的にロバストな最適化は、トレーニングデータセット内の過小評価されたサブドメインの存在を説明する経験的リスク最小化の一般化です。 
[概要]私たちは、一般的で最先端の3d u-ネットアーキテクチャに固執しました。これらには、非標準のサンプルごとの損失関数、非標準の母集団損失関数、レンジャー付きのオプティマイザーが含まれていました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Review: Deep Learning in Electron Microscopy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_28.html">
      <font color="black">Review: Deep Learning in Electron Microscopy</font>
    </a>
  </h2>
  <font color="black">最後に、電子顕微鏡法における深層学習の将来の方向性について説明します。次に、ニューラルネットワークコンポーネント、一般的なアーキテクチャ、およびそれらの最適化を確認します。深層学習は、電子顕微鏡法を含む科学技術のほとんどの分野を変革しています。 
[概要]このレビューペーパーは、知識が限られている開発者を対象とした実用的な視点を提供します。これには、電子顕微鏡などの技術の実用的な視点が含まれます。最後に、電子顕微鏡における深層学習の将来の方向性について説明します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Continuous and Diverse Image-to-Image Translation via Signed Attribute
  Vectors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_29.html">
      <font color="black">Continuous and Diverse Image-to-Image Translation via Signed Attribute
  Vectors</font>
    </a>
  </h2>
  <font color="black">定性的結果と定量的結果の両方が、提案されたフレームワークが最先端の方法に対してより高品質の連続翻訳結果を生成することを示しています。中間結果のスムーズなシーケンスを生成すると、2つの異なるドメインのギャップが埋められ、全体のモーフィング効果が促進されます。ドメイン..特に、署名操作を利用してドメイン情報をエンコードすることにより、すべてのドメインで共有される統一された属性空間を導入し、それによって異なるドメインの属性ベクトルの補間を可能にします。 
[概要]連続翻訳の問題は十分に研究されていません。既存のi2iアプローチは連続翻訳に限定されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Accelerated WGAN update strategy with loss change rate balancing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_30.html">
      <font color="black">Accelerated WGAN update strategy with loss change rate balancing</font>
    </a>
  </h2>
  <font color="black">この論文では、この更新戦略が精度と収束速度の点で最適ではないことを示し、WGAN損失を使用したWasserstein GAN（WGAN）およびその他のGANの新しい更新戦略を提案します（たとえば、提案された更新戦略はGとDの損失変化率の比較。提案された戦略が収束速度と精度の両方を改善することを示します。WGAN-GP、Deblur GAN、および超解像度GAN）。 
[要約]これに対処するための一般的な更新戦略は、kとジェネレーターgの1つの拡張ステップを交互に行うことです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-28">
        <br><font color="black">2020-08-28</font>
      </time>
    </span>
</section>
<!-- paper0: "You eat with your eyes first": Optimizing Yelp Image Advertising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_31.html">
      <font color="black">"You eat with your eyes first": Optimizing Yelp Image Advertising</font>
    </a>
  </h2>
  <font color="black">さまざまな画像カテゴリの簡略化された星の評価を90〜98％の精度で分類し、青い空、開いた環境、多くのウィンドウを含む画像が、より高いYelpレビューと相関していることを確認します。企業のオンライン写真表現は、その成功または失敗..Yelpデータセットを前処理した後、転送学習を使用して、Yelp画像を受け入れ、星評価を予測する分類器をトレーニングします。 
[概要] yelpの画像データセットとスターベースのレビューシステムを使用します。次に、ガンをトレーニングして、非常に効果的な画像の一般的なプロパティを調査します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Distribution-aware Margin Calibration for Medical Image Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_32.html">
      <font color="black">Distribution-aware Margin Calibration for Medical Image Segmentation</font>
    </a>
  </h2>
  <font color="black">このスキームにより、実際のIoUスコアの観点からより優れたセグメンテーションパフォーマンスが保証されます。Jaccardインデックスは、Intersection-over-Union（IoUスコア）とも呼ばれ、医療画像セグメンテーションで最も重要な評価指標の1つです。その代理を最適化するために提案されているが、それらの一般化能力については保証が提供されていない。 
[要約]提案されたスコアは医学的分析の未解決の問題ですが、複数の客観的クラスにわたって平均iou（miou）スコアを直接最適化することは問題です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Infer Unseen Attribute-Object Compositions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_33.html">
      <font color="black">Learning to Infer Unseen Attribute-Object Compositions</font>
    </a>
  </h2>
  <font color="black">推論中、すべてのコンポジションの中で特定の画像特徴に最も近いコンポジションが推論結果として使用されます。次に、属性とオブジェクトのセマンティック関連付けの制約に従って、視覚的特徴と対応するラベルセマンティックの間の距離が計算されます。潜在空間の特徴..さらに、116,099の画像と8,030の構成カテゴリで大規模なマルチ属性データセット（MAD）を構築します。 
[概要]モデルは、画像の視覚的特徴と属性（単語埋め込みシールドで表されるオブジェクトカテゴリラベル）を潜在空間にマッピングします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Representations from Audio-Visual Spatial Alignment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_34.html">
      <font color="black">Learning Representations from Audio-Visual Spatial Alignment</font>
    </a>
  </h2>
  <font color="black">これらの空間的手がかりから学ぶために、360 {\ deg}ビデオと空間オーディオの対照的なオーディオビジュアル空間アラインメントを実行するようにネットワークに依頼しました。オーディオビジュアル表現学習に関する以前の作業では、ビデオレベルでの対応を活用しています。トランスアーキテクチャを使用して360 {\ deg}ビデオの空間コンテンツ全体を推論し、複数の視点からの表現を組み合わせると、空間アライメントの実行が強化されます。 
[概要]オーディオの口実作業-ビジュアル表現クリップはビデオレベルで活用します。ビジュアル表現に基づいて、ネットワークにこれらの空間的手がかりから学習するように依頼しました。提案されたビデオ口実タスクの利点は、さまざまなオーディオと視覚的なダウンストリームタスク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Memory Group Sampling Based Online Action Recognition Using Kinetic
  Skeleton Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_35.html">
      <font color="black">Memory Group Sampling Based Online Action Recognition Using Kinetic
  Skeleton Features</font>
    </a>
  </h2>
  <font color="black">オンライン行動認識は、人間中心のインテリジェントサービスにとって重要なタスクですが、人間の行動の空間的および時間的スケールの多様性と不確実性のために達成するのは依然として困難です。最後に、改良された1DCNNネットワークがトレーニングとテストに採用されています。サンプリングされたフレームからの特徴..最初に、空間的および時間的スケルトン特徴を組み合わせて、アクションの空間的および時間的情報の両方がカバーされるように、幾何学的特徴だけでなくマルチスケールモーション特徴も含むアクションを描写します。 
[概要]以前のアクションフレームと現在のアクションフレームを組み合わせるメモリグループサンプリング方法を提案します。これは、隣接するフレームが大幅に冗長であるという事実に基づいています。サンプリングメカニズムにより、長期的なコンテキスト情報も考慮されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-01">
        <br><font color="black">2020-11-01</font>
      </time>
    </span>
</section>
<!-- paper0: MACE: Model Agnostic Concept Extractor for Explaining Image
  Classification Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_36.html">
      <font color="black">MACE: Model Agnostic Concept Extractor for Explaining Image
  Classification Networks</font>
    </a>
  </h2>
  <font color="black">この作業では、MACE：Model Agnostic Concept Extractorを提案します。これは、より小さな概念を通じて畳み込みネットワークの動作を説明できます。ただし、人間は通常、画像を分析し、より小さな概念の存在を指摘することによって推論します。抽出された概念と事前トレーニング済みモデルの予測との関連性を推定します。これは、既存のアプローチにはない、個々のクラスの予測を説明するために必要な重要な側面です。 
[概要]メイスモデルは、画像の畳み込みネットワークによって生成された特徴マップを分析して、さまざまな質問で概念を抽出します。システムは、属性2の動物などのデータセットに基づいています。awa2およびplaces365</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: AViD Dataset: Anonymized Videos from Diverse Countries -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_37.html">
      <font color="black">AViD Dataset: Anonymized Videos from Diverse Countries</font>
    </a>
  </h2>
  <font color="black">既存のビデオデータセットのほとんどが、限られた数の国からのアクションビデオのみをキャプチャするように統計的にバイアスされていることを確認します。アクション認識用の新しい公開ビデオデータセットを導入します：多様な国からの匿名ビデオ（AViD）。新しいAViDデータセットは、モデルを事前トレーニングするための優れたデータセットとして機能し、以前のデータセットと同等またはそれ以上のパフォーマンスを発揮します。 
[概要]既存の動画データセットのほとんどは、限られた数の国からのアクション動画のみをキャプチャするように統計的に偏っていることを確認しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-10">
        <br><font color="black">2020-07-10</font>
      </time>
    </span>
</section>
<!-- paper0: Temporal Attention-Augmented Graph Convolutional Network for Efficient
  Skeleton-Based Human Action Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_38.html">
      <font color="black">Temporal Attention-Augmented Graph Convolutional Network for Efficient
  Skeleton-Based Human Action Recognition</font>
    </a>
  </h2>
  <font color="black">TAMを軽量GCNトポロジに組み込んで、計算の総数をさらに削減します。2つのベンチマークデータセットでの実験結果は、提案された方法がベースラインのGCNベースの方法よりも大幅に優れている一方で、計算..さらに、計算回数が最大9.6分の1で、最先端の処理と同等のパフォーマンスを発揮します。 
[ABSTRACT]最も成功したアクション認識方法は、ディープフィードフォワードネットワークを使用して、アクション内のすべてのスケルトンを処理します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-23">
        <br><font color="black">2020-10-23</font>
      </time>
    </span>
</section>
<!-- paper0: Classifier Pool Generation based on a Two-level Diversity Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_39.html">
      <font color="black">Classifier Pool Generation based on a Two-level Diversity Approach</font>
    </a>
  </h2>
  <font color="black">結果は、動的分類子選択と動的アンサンブル選択の方法を適用した場合、実験の69.4％で大幅な精度の向上を示しています。サブサンプル全体で変動性の高い複雑さの測定値が、後部プールの適応のために選択されます。進化的アルゴリズムは、複雑さと決定空間..28のデータセットと20の複製を備えた堅牢な実験プロトコルを使用して、提案された方法を評価します。 
[要約]提案された方法は、データセットのサブサンプルの数を測定するために開発されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Self-semi-supervised Learning to Learn from NoisyLabeled Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_40.html">
      <font color="black">Self-semi-supervised Learning to Learn from NoisyLabeled Data</font>
    </a>
  </h2>
  <font color="black">一方、自己半教師あり学習のますます普及している方法は、ラベルが不完全な場合にタスクに役立つことが証明されています。この目標を達成するために、一方では、多くの論文がノイズの多いラベルとクリーンなラベルを区別することに専念してきました。 DNNの一般化を高めるためのもの。「半教師あり」によって、誤ってラベル付けされたデータがラベル付けされていないデータとして検出されたと見なします。 「自己」によって、半教師あり学習を行うために自己教師あり手法を選択します。 
[ABSTRACT]ワイヤレスで分類されたデータは、高品質の人間のラベル付きデータを取得するのが困難であり、ノイズの多いラベルに対して堅牢なトレーニングモデルの活発な研究領域につながります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Faraway-Frustum: Dealing with Lidar Sparsity for 3D Object Detection
  using Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_41.html">
      <font color="black">Faraway-Frustum: Dealing with Lidar Sparsity for 3D Object Detection
  using Fusion</font>
    </a>
  </h2>
  <font color="black">KITTIデータセットでの実験は、鳥瞰図および3Dでの遠方の物体検出に関して、私たちの方法が最先端の方法よりもかなり優れていることを示しています。ただし、この距離は、高速で移動する車両ではそれほど遠くないと見なす必要があります。 ：車両は、70 mphで移動しながら、2秒以内に60メートルを移動できます。より近いオブジェクトの場合は、最先端の方法に従って、学習したポイントクラウド表現を代わりに使用します。 
[概要]遠くのオブジェクトの場合、これらのタイプのオブジェクト検出はこれらの範囲で見つけることができます。主な戦略は、オブジェクトクラスを認識するために2Dビジョンのみに依存することです。この戦略は、オブジェクトの目の検出の主な欠点を軽減します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Attention Based Instance Discriminative Learning for Person
  Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_42.html">
      <font color="black">Unsupervised Attention Based Instance Discriminative Learning for Person
  Re-Identification</font>
    </a>
  </h2>
  <font color="black">したがって、事前トレーニングなしでエンドツーエンドの方法でトレーニングされる、人の再識別のための教師なしフレームワークを提案します。提案されたフレームワークは、グループ畳み込みを組み合わせた新しい注意メカニズムを活用して、（1）空間的注意を強化します。複数のスケールと（2）トレーニング可能なパラメーターの数を59.6％削減します。Market1501およびDukeMTMC-reIDデータセットを使用して広範な分析を実行し、この方法が常に最先端の方法よりも優れていることを示します（事前の有無にかかわらず） -訓練された重み）。 
[概要]提案されたフレームワークは、グループ畳み込みを使用して空間的注意を強化します。また、トレーニング可能なパラメーターの数を59.6％削減します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Developing High Quality Training Samples for Deep Learning Based Local
  Climate Classification in Korea -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_43.html">
      <font color="black">Developing High Quality Training Samples for Deep Learning Based Local
  Climate Classification in Korea</font>
    </a>
  </h2>
  <font color="black">代わりに、この研究では、マルチスケール畳み込みニューラルネットワークを使用して韓国の主要都市をマッピングするカスタムLCZデータを開発しました。グローバルスケールのLCZマッピングが検討されていますが、精度の低さ、ラベルの品質の変動、またはドメイン適応の課題によって制限されています。結果は、深層学習で新しいカスタムLCZデータを使用すると、マシン学習やグローバルSo2Satデータセットの転送学習を使用した従来のコミュニティベースのLCZマッピングと比較して、より正確なLCZマップ結果を生成できることを示しました。 
[概要]都市フットプリントデータは、高解像度の都市フレームワークを提供しますが、分布、パターン、および特性に関する重要な情報が不足しています。都市ゾーンマップは調査されていますが、精度の低さ、ラベルの品質の変動、またはドメイン適応の課題によって制限されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Generating Unobserved Alternatives: A Case Study through
  Super-Resolution and Decompression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_44.html">
      <font color="black">Generating Unobserved Alternatives: A Case Study through
  Super-Resolution and Decompression</font>
    </a>
  </h2>
  <font color="black">この特性を持ついくつかの問題を調査し、同じ入力で複数の高品質の予測を生成できるアプローチを開発します。現在の設定に回帰法と条件付き生成モデルのいずれかを適用すると、多くの場合、単一の予測しかできないモデルになります。入力ごとに..その結果、観測された出力とは異なる高品質の出力を生成するために使用できます。 
[要約]モデルは、同じ入力が与えられた場合に複数の高品質の予測を生成できます。また、複数の高品質の予測を生成することもできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: BIGPrior: Towards Decoupling Learned Prior Hallucination and Data
  Fidelity in Image Restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_45.html">
      <font color="black">BIGPrior: Towards Decoupling Learned Prior Hallucination and Data
  Fidelity in Image Restoration</font>
    </a>
  </h2>
  <font color="black">確かに、分離されたデータの忠実度と以前の用語のピクセルごとの寄与は、提案されたフレームワークですぐに利用できます。さらに、劣化モデルの過剰適合の犠牲になるのは幻覚の部分であることがよくあります。これにより、復元での広範な採用が制限されます。アプリケーション。 
[ABSTRACT]ディープラーニング手法は、優れた復元品質を生み出すことがよくあります。事前に画像を学習しながら、観測データに忠実なネットワーク学習を行うと、元のデータと幻覚データを下流で分離することができなくなります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Content-based Analysis of the Cultural Differences between TikTok and
  Douyin -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_46.html">
      <font color="black">Content-based Analysis of the Cultural Differences between TikTok and
  Douyin</font>
    </a>
  </h2>
  <font color="black">米国と中国）..短い形式のビデオソーシャルメディアは、視聴者にダイナミックなストーリーを伝えて注目を集めることにより、従来のメディアパラダイムからシフトします。メディアのファッションや社会的特異性とともに文化の違いを表現しているという仮説は私たちの研究の主なターゲット。 
[概要]新しいソーシャルメディアネットワークは、さまざまな種類のオブジェクトを使用して独自のシーンを作成します。これらには、さまざまなラベルを表すために使用できる日常のオブジェクトのさまざまな組み合わせが含まれます。これらは、usなどのさまざまな種類のオブジェクトの例です。中国と米国では、オブジェクト検出を実行するために、コンテキスト内のマイクロソフト共通オブジェクトで事前にトレーニングされた、より高速な地域畳み込みニューラルネットワーク（より高速なr --cnn）も使用しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring DeshuffleGANs in Self-Supervised Generative Adversarial
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_47.html">
      <font color="black">Exploring DeshuffleGANs in Self-Supervised Generative Adversarial
  Networks</font>
    </a>
  </h2>
  <font color="black">デシャッフルタスクを2つの異なるGANディスクリミネーターに割り当て、両方のアーキテクチャに対するデシャッフルの効果を調査します。また、GANベンチマークで主に使用されるさまざまなデータセット（LSUN-ベッドルーム、LSUN-チャーチ、CelebA）でのDeshuffleGANのパフォーマンスを評価します。 -HQ ..最後に、損失状況に関するGANトレーニングへの自己監視タスクの貢献を示し、一部の設定では、自己監視タスクの効果が敵対的トレーニングに協力しない可能性があることを示します。 
[概要]デシャッフルガンは、壊滅的な忘却の問題なしに安定したガントレーニングを支援するために提案されています。一般化可能性のコンテキストでのデシャッフルガンのデシャッフルタスク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: CooGAN: A Memory-Efficient Framework for High-Resolution Facial
  Attribute Editing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_48.html">
      <font color="black">CooGAN: A Memory-Efficient Framework for High-Resolution Facial
  Attribute Editing</font>
    </a>
  </h2>
  <font color="black">両方のパスは、ローカルからグローバルへの一貫性の目的の下で協調的に機能します（つまり、スムーズなステッチング）。これらの問題に対処するために、HR顔画像編集用の協調GAN（CooGAN）と呼ばれるNOVELピクセル変換フレームワークを提案します。さらに、より効率的なマルチスケール特徴融合のためのより軽い選択的転送ユニットを提案し、より忠実な顔属性操作をもたらします。 
[概要]このフレームワークは、きめの細かいローカル顔パッチ生成のためのローカルパスを備えています。これには、グローバル低解像度（lr）顔構造モニタリングのためのグローバルパスが含まれます。これらには、より効率的なマルチスケール機能融合のためのより軽い選択的転送ユニットが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Better Sign Language Translation with STMC-Transformer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_49.html">
      <font color="black">Better Sign Language Translation with STMC-Transformer</font>
    </a>
  </h2>
  <font color="black">これは、GTグロス翻訳がSLTパフォーマンスの上限として機能し、グロスが手話の非効率的な表現であるという以前の主張と矛盾します。また、グロス監視に依存する現在の方法の問題を示します。ビデオからテキストへSTMC-Transformerの翻訳は、GTグロスの翻訳よりも優れています。 
[概要]翻訳システムは、手話グロスからバインドされた話し言葉を作成します。アスルでは、aslg（pc12 text text text.the video）を超えて、stmcのテキスト翻訳がgtグロスの翻訳よりも優れていることを報告します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-01">
        <br><font color="black">2020-04-01</font>
      </time>
    </span>
</section>
<!-- paper0: STC-Flow: Spatio-temporal Context-aware Optical Flow Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_50.html">
      <font color="black">STC-Flow: Spatio-temporal Context-aware Optical Flow Estimation</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案されたスキームが、SintelデータセットとKITTI 2012/2015データセットで2フレームベースの方法の最先端のパフォーマンスを達成することを示しています。具体的には、STC-Flowには3つの主要なコンテキストモジュール（ピラミッド型空間コンテキスト）が含まれています。モジュール、時間的コンテキスト相関モジュール、および反復残差コンテキストアップサンプリングモジュール。それぞれ、特徴抽出、相関、およびフロー再構築の各段階で関係を構築します。ローカルピラミッド特徴抽出とマルチレベル相関を使用した以前の光フロー推定アプローチとは異なり、空間的および時間的次元での豊富な長距離依存性をキャプチャすることにより、コンテキスト関係探索アーキテクチャを提案します。 
[要約]提案されたスキームは、「コンテキスト関係探索アーキテクチャ」を作成するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-01">
        <br><font color="black">2020-03-01</font>
      </time>
    </span>
</section>
<!-- paper0: Genetic U-Net: Automatically Designing Lightweight U-shaped CNN
  Architectures Using the Genetic Algorithm for Retinal Vessel Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_51.html">
      <font color="black">Genetic U-Net: Automatically Designing Lightweight U-shaped CNN
  Architectures Using the Genetic Algorithm for Retinal Vessel Segmentation</font>
    </a>
  </h2>
  <font color="black">さらに、提案された方法によって得られたアーキテクチャは、最先端のモデルよりも軽量ですが正確です。実験結果は、提案された方法が3つの公開データセット、DRIVE、CHASE \ _DB1、STAREの既存の方法よりも優れていることを示しています。 ..この問題に対処するために、遺伝的アルゴリズム（GA）を使用して、網膜血管セグメンテーション用の軽量U字型CNNを自動的に設計するGeneticU-Netと呼ばれる新しい方法を提案します。 
[ABSTRACT] cnsは、検索スペースを駆動する遺伝的アルゴリズムに基づいています。この方法では、遺伝的アルゴリズムを使用して優れたアーキテクチャを検索します。これらは、最先端のモデルよりも軽量ですが正確です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Joint Object Detection and Multi-Object Tracking with Graph Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_52.html">
      <font color="black">Joint Object Detection and Multi-Object Tracking with Graph Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">この作業では、グラフニューラルネットワーク（GNN）に基づく共同MOTアプローチの新しいインスタンスを提案します。MOT15/ 16/17/20データセットでの広範な実験を通じて、GNNベースの共同MOTアプローチの有効性を示します。検出タスクとMOTタスクの両方の最新のパフォーマンスを示します。その結果、勾配を逆伝播してMOTシステム全体を最適化することができず、パフォーマンスが最適化されません。 
[概要]以前の作業では、さまざまな目的でトレーニングされた検出モジュールとデータ関連付けモジュールを設計することがよくあります。重要なアイデアは、gnnsが空間ドメインと音声ドメインの両方で可変サイズのオブジェクト間の関係をモデル化できることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-23">
        <br><font color="black">2020-06-23</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Fair Cross-Domain Adaptation via Generative Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_53.html">
      <font color="black">Towards Fair Cross-Domain Adaptation via Generative Learning</font>
    </a>
  </h2>
  <font color="black">具体的には、生成機能の拡張を検討して、少数ショットのソースクラスの効果的なトレーニングデータを合成します。一方、効果的なクロスドメインアライメントは、ソースからの知識を適応させてターゲットの学習を容易にすることを目的としています。2つの大きなクロスドメインビジュアルデータセットでの実験結果は、最先端のDAアプローチと比較して、少数ショットと全体的な分類精度の両方を改善する上での提案手法の有効性。公正なクロスドメイン適応を実行し、これらの少数カテゴリのパフォーマンスを向上させるために、新しいジェネレーティブを開発します。公正なクロスドメイン分類のための数ショットクロスドメイン適応（GFCA）アルゴリズム。 
[ABSTRACT] new daは通常、実際のソースドメインがクラスごとにバランスが取れていると想定します。これは比較的類似している可能性があります。これは、ソースクラスのサイズが比較的類似しているためである可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-04">
        <br><font color="black">2020-03-04</font>
      </time>
    </span>
</section>
<!-- paper0: Encoding Clinical Priori in 3D Convolutional Neural Networks for
  Prostate Cancer Detection in bpMRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_54.html">
      <font color="black">Encoding Clinical Priori in 3D Convolutional Neural Networks for
  Prostate Cancer Detection in bpMRI</font>
    </a>
  </h2>
  <font color="black">パフォーマンスを評価するために、800の機関トレーニング検証スキャンを使用してU-Net、U-SEResNet、UNet ++、およびAttention U-Netの3D適応をトレーニングし、放射線学的に推定された注釈と計算された事前評価を組み合わせます。200の独立したテストbpMRIスキャンの場合csPCaの組織学的に確認された描写により、臨床的先験的にコード化する提案された方法は、患者ベースの診断（AUROCの最大8.70％の増加）および病変レベルの検出（0.1〜1.0の偽陽性の間の1.08pAUCの平均増加）を改善する強力な能力を示します患者ごと）4つのアーキテクチャすべてにわたって..バイパラメトリックMRイメージングでのコンピュータ支援検出（CAD）を改善するために、臨床的に重要な前立腺癌（csPCa）の空間的有病率とゾーンの区別をキャプチャする確率的母集団を導入します。 （bpMRI）。 
[概要]前立腺がん（cspca）の空間的有病率とゾーンの区別をキャプチャする確率的母集団を紹介します。バイパラメトリックmrイメージング（bpmri）でコンピュータ支援検出（cad）を改善できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-31">
        <br><font color="black">2020-10-31</font>
      </time>
    </span>
</section>
<!-- paper0: Meta Module Network for Compositional Visual Reasoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_55.html">
      <font color="black">Meta Module Network for Compositional Visual Reasoning</font>
    </a>
  </h2>
  <font color="black">このような柔軟なインスタンス化メカニズムにより、インスタンスモジュールのパラメータは中央メタモジュールから継承され、関数セットの増大と同じモデルの複雑さを維持し、より優れたスケーラビリティを約束します。実用的なより強力なNMNアーキテクチャを設計するために、提案します。関数レシピを取り込んで、動的に多様なインスタンスモジュールに変形できる新しいメタモジュールを中心としたメタモジュールネットワーク（MMN）。GQAデータセットからの見えない関数の合成実験も、MMNの強力な一般化可能性を示しています。特定の関数の
[ABSTRACT]モジュールは、複雑なタスクでより多くの関数のセットにスケールアップするときに実用的ではありません。強力なモジュールは、以前に観察されたものとの構造的類似性に基づいて簡単に表すことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-08">
        <br><font color="black">2019-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Parameter Efficient Deep Neural Networks with Bilinear Projections -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_56.html">
      <font color="black">Parameter Efficient Deep Neural Networks with Bilinear Projections</font>
    </a>
  </h2>
  <font color="black">適切な深層学習フレームワークがあれば、一般に深さまたは層の幅を増やしてより高いレベルの精度を達成することが可能です。4つのベンチマークデータセットでの実験は、提案された双線形射影を深層ニューラルネットワークに適用すると従来よりもさらに高い精度を達成できることを示しています完全なDNNは、モデルサイズを大幅に削減します。したがって、出力チャネルの数を増やすことでマッピングサイズを単純にスケールアップします。これにより、モデルの精度を維持し、さらに向上させることができます。 
[ABSTRACT] dnnsは双線形投影に置き換えられました。たとえば、このモデルでは、深度またはレイヤー幅を増やして、より高いレベルの精度を実現できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Micro Stripes Analyses for Iris Presentation Attack Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_57.html">
      <font color="black">Micro Stripes Analyses for Iris Presentation Attack Detection</font>
    </a>
  </h2>
  <font color="black">実験は5つのデータベースで示され、2つのデータベース（IIITD-WVUとノートルダム）はLivDet-2017 Irisコンペティションのものです。分類問題をより適切にモデル化するためのプレゼンテーション攻撃検出ネットワークでは、セグメント化された領域が処理されて低次元が提供されます。入力セグメントとより多くの学習サンプル..虹彩認識システムは、テクスチャードコンタクトレンズや印刷画像などのプレゼンテーション攻撃に対して脆弱です。 
[概要]システムは、虹彩提示攻撃を検出するように設計されています。拡張された正規化された虹彩テクスチャの複数のマイクロストライプを抽出する必要があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Solving Inverse Problems with Hybrid Deep Image Priors: the challenge of
  preventing overfitting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_58.html">
      <font color="black">Solving Inverse Problems with Hybrid Deep Image Priors: the challenge of
  preventing overfitting</font>
    </a>
  </h2>
  <font color="black">交互方向乗数法（ADMM）を使用して新しい事前分布を組み込み、さまざまな形式のADMMを試して、ADMMステップの内部ループによって引き起こされる余分な計算を回避します。数値結果は、ハイブリッド事前分布が重要な役割を果たすことを示しています。過剰適合の防止..論文では、過剰適合を回避するためにハイブリッドディープイメージ事前分布を使用します。 
[ABSTRACT]反復回数が増えると、画像のノイズにディップがオーバーフィットします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Out-of-Distribution Detection for Automotive Perception -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_59.html">
      <font color="black">Out-of-Distribution Detection for Automotive Perception</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、入力がOODであるかどうかを判断するためのシンプルで効果的な方法を紹介します。NNは信頼度の推定にソフトマックス正規化に依存することが多く、OODサンプルに高い信頼度が割り当てられるため、障害の検出が妨げられます。ニューラルネットワーク（NN ）は、自律走行における物体認識タスクに広く使用されています。 
[概要] out-distribution（ood）dataとして知られるトレーニングデータセットは、十分に表現されていません。これにより、oodモードに高い信頼性が割り当てられる可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Applying Deep-Learning-Based Computer Vision to Wireless Communications:
  Methodologies, Opportunities, and Challenges -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_60.html">
      <font color="black">Applying Deep-Learning-Based Computer Vision to Wireless Communications:
  Methodologies, Opportunities, and Challenges</font>
    </a>
  </h2>
  <font color="black">DLベースのCVをワイヤレス通信に適用する方法を説明するために、ミリ波（mmWave）システムでDLベースのCVを使用して、最適なミリ波多入力多出力（MIMO）ビームフォーミングを実現する例を示します。モバイルシナリオ..ただし、これまでのところ、このような作業は文献ではまれです。実験結果は、フレームワークがベースライン方式よりもはるかに高い精度を達成し、視覚データがMIMOビームフォーミングシステムのパフォーマンスを大幅に向上できることを示しています。 
[概要]この記事の主な目的は、無線通信で使用されているdlの適用に関するアイデアを紹介することです。resnetを使用して既存のシステムから将来のビームオブジェクトを予測することができます。3-実際の出力。この方法を使用して開発できます。たとえば新しいシステム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-10">
        <br><font color="black">2020-06-10</font>
      </time>
    </span>
</section>
<!-- paper0: RealHePoNet: a robust single-stage ConvNet for head pose estimation in
  the wild -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_61.html">
      <font color="black">RealHePoNet: a robust single-stage ConvNet for head pose estimation in
  the wild</font>
    </a>
  </h2>
  <font color="black">GTX 1060 GPU）..私たちのモデルは、2つのデータセットの組み合わせでトレーニングされています：「ポインティング「04」（幅広いポーズをカバーすることを目的）」と「注釈付きの野生の顔のランドマーク」（モデルの堅牢性を向上させるため）実世界の画像で使用するため）。*コードはhttps://github.com/rafabs97/headpose_finalで入手できます。*デモビデオはhttps://www.youtube.com/watch?v=2UeuXh5DjAE 
[ABSTRACT]単一の畳み込みニューラルネットワーク（convnet）モデルは、実世界での使用可能性を最大化するために、精度と可能性の速度のバランスを取ることを目的としています。結合されたデータセットの3つの異なるパーティションが定義され、トレーニング、検証、およびテストの目的で使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: VEGA: Towards an End-to-End Configurable AutoML Pipeline -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_62.html">
      <font color="black">VEGA: Towards an End-to-End Configurable AutoML Pipeline</font>
    </a>
  </h2>
  <font color="black">b）さまざまな検索アルゴリズムとタスクをサポートするために、新しいきめ細かい検索スペースとその記述言語を設計して、さまざまな検索アルゴリズムとタスクに簡単に適応できるようにします。c）深層学習フレームワークの一般的なコンポーネントを抽象化します。統合インターフェース..VEGAはhttps://github.com/huawei-noah/vegaでオープンソース化されています。 
[ABSTRACT] automlは、us.vegaで開発できるautomlシステムであり、自動データ拡張、モデル圧縮、完全トレーニングなど、automlの複数のモジュールで動作します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: In Defense of Feature Mimicking for Knowledge Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CV/paper_63.html">
      <font color="black">In Defense of Feature Mimicking for Knowledge Distillation</font>
    </a>
  </h2>
  <font color="black">教師は生徒の特徴の大きさにもっと自由を与え、生徒に特徴の方向の模倣にもっと注意を向けさせるべきだと主張します。特徴の模倣をさらに容易にするために、特徴ベクトルを大きさと方向に分解します。従来のKDよりも高い精度を実現できること。 
[ABSTRACT]従来の方法では、教師のソフトロジットを使用して学生ネットワークをトレーニングします。これは、softmaxレイヤーなしでトレーニングされた教師にも適用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Semi-Supervised Cleansing of Web Argument Corpora -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_0.html">
      <font color="black">Semi-Supervised Cleansing of Web Argument Corpora</font>
    </a>
  </h2>
  <font color="black">400kの引数テキストを持つ既存のargs.meコーパスでは、私たちのアプローチは、手動評価によると0.97の精度で、ほぼ87kの無関係な文を検出します。少ない労力で、アプローチを他のWeb引数コーパスに適合させて一般的な方法を提供できます。コーパスの品質を向上させるために..この論文では、そのような無関係なテキストを半監視された方法で検出するための精度指向のアプローチを提示します。 
[要約]このアプローチは、関連性と非関連性の基本的な語彙パターンを自動的に学習します。次に、パターンに一致する文から新しいパターンをブートストラップします。少ない労力で、アプローチを他のWeb引数コーパスに適合させることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Supervised Contrastive Learning for Pre-trained Language Model
  Fine-tuning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_1.html">
      <font color="black">Supervised Contrastive Learning for Pre-trained Language Model
  Fine-tuning</font>
    </a>
  </h2>
  <font color="black">また、新しい目的により、トレーニングデータのさまざまなレベルのノイズに対してより堅牢なモデルが得られ、ラベル付けされたタスクデータが限られている関連タスクによりよく一般化できることも示します。適切な一般化には、あるクラスの例と他のクラスの例とを対比して、微調整段階の教師あり対照学習（SCL）の目的を提案します。クロスエントロピーと組み合わせて、提案するSCL損失は、強力なRoBERTa-Largeよりも改善されます。高データと低データの両方のレジームにおけるGLUEベンチマークの複数のデータセットのベースラインであり、特殊なアーキテクチャ、あらゆる種類のデータ拡張、メモリバンク、または追加の教師なしデータを必要としません。 
[概要] scl損失は、強力なロベルタ（高2と低の両方のデータレジームにおける接着剤ベンチマークの複数のデータセットの大きなベースライン）に対する改善を提案します。モデル、メモリバンク、またはより多くの教師なしデータは必要ありません。 、またはさらに監視されていないもの</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Creating a Domain-diverse Corpus for Theory-based Argument Quality
  Assessment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_2.html">
      <font color="black">Creating a Domain-diverse Corpus for Theory-based Argument Quality
  Assessment</font>
    </a>
  </h2>
  <font color="black">引数を識別し、3つの異なるドメインに注釈タスクを適応させる方法を示します。この作業では、理論ベースのAQの最初の大規模なドメイン多様な注釈付きコーパスであるGAQCorpusについて説明します。私たちの作業は理論ベースの研究に情報を提供します。引数の注釈を付けて、計算AQ評価をサポートするためのより多様なコーパスの作成を可能にします。 
[要約]プロジェクトは、理論に基づく議論の注釈に関する研究に情報を提供します。これにより、評価をサポートするためのより多様なコーパスの作成が可能になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Warped Language Models for Noise Robust Language Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_3.html">
      <font color="black">Warped Language Models for Noise Robust Language Understanding</font>
    </a>
  </h2>
  <font color="black">WLMのトレーニング中の入力テキストの挿入とドロップの変更は、自動音声認識（ASR）エラーによるノイズのタイプに似ているため、WLMはASRノイズに対してより堅牢になる可能性があります。この作業では、ワープを紹介します。トレーニング時の入力文がMLMと同じ変更に加えて、ランダムトークンの挿入と削除という2つの追加の変更が行われる言語モデル（WLM）。計算結果を通じて、WLM上に構築された自然言語理解システムが実行することを示します。特にASRエラーが存在する場合、MLMに基づいて構築されたものと比較して優れています。 
[概要]これらの2つの変更は、mlmsの変更に加えて、文を拡張および縮小します。これらは、話し言葉の理解、特に自発的な会話音声認識ノイズに対して堅牢ではありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: QMUL-SDS @ SardiStance2020: Leveraging Network Interactions to Boost
  Performance on Stance Detection using Knowledge Graphs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_4.html">
      <font color="black">QMUL-SDS @ SardiStance2020: Leveraging Network Interactions to Boost
  Performance on Stance Detection using Knowledge Graphs</font>
    </a>
  </h2>
  <font color="black">さらなる調査により、私たちの最良の実験設定は、同じアーキテクチャとパラメータ設定で、社会的相互作用機能のみを組み込んだ後、パフォーマンスを（f-avg 0.573）から（f-avg 0.733）に向上させました-モデルのパフォーマンスに対する社会的相互作用の影響を強調しています。 。タスクAの提出はベースラインを超えませんでしたが、すべてのトレーニングツイートを使用してモデルを再トレーニングすると、タスクAのBERT多言語埋め込みを使用した双方向LSTMの使用（f-avg 0.601）につながる有望な結果が示されました。タスクの提出についてB、6位（f-avg0.709）。 
[概要]私たちの最高の実験設定は、同じアーキテクチャとイーサン設定でパフォーマンスを（f-平均0. 573）から（f-平均0. 733）に向上させました。社会的相互作用機能を組み込んだ後---社会的相互作用の影響を強調モデルのパフォーマンス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: The Gap on GAP: Tackling the Problem of Differing Data Distributions in
  Bias-Measuring Datasets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_5.html">
      <font color="black">The Gap on GAP: Tackling the Problem of Differing Data Distributions in
  Bias-Measuring Datasets</font>
    </a>
  </h2>
  <font color="black">たとえば、性別バイアス測定共参照解決データセットの女性サブセットに、代名詞と正しい候補の間の平均距離が長い文が含まれている場合、RNNベースのモデルは、長期的な依存関係のために、このサブセットでパフォーマンスが低下する可能性があります。 。重み付け方法を使用して、これらの相関に対処するために使用する必要があるテストインスタンスの重みのセットを見つけ、最近リリースされた16の共参照モデルを再評価します。ただし、収集されたデータの望ましくないパターンがそのようなテストを行う可能性があります。正しくありません。 
[概要]テストデータの同様のパターンに対処するためにテストサンプルに重みを付ける新しい方法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Small footprint Text-Independent Speaker Verification for Embedded
  Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_6.html">
      <font color="black">Small footprint Text-Independent Speaker Verification for Embedded
  Systems</font>
    </a>
  </h2>
  <font color="black">Raspberry Pi 3BなどのIoTシステムに典型的な小型デバイスで、5秒の長さの発話で200ms未満の遅延でソリューションを実行する可能性を示します。さらに、音響的に困難なVOiCESコーパスでモデルを評価します。学習パラメーターの数が25.6倍減少したのに対し、距離チャレンジからの2019VOiCESの最高スコアモデルに対して2.6パーセントポイントのEERの限定的な増加。 
[概要]モデルはvoxceleb1検証テストセットによって作成されました。モデルは実証済みの実証済みの音声に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Automated Anamnesis Summarization: BERT-based Models for Symptom
  Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_7.html">
      <font color="black">Towards Automated Anamnesis Summarization: BERT-based Models for Symptom
  Extraction</font>
    </a>
  </h2>
  <font color="black">症状の特定と症状の属性抽出の両方でモデルの有望なパフォーマンスを実証でき、単純なベースラインを大幅に上回ります。ただし、手動で作成されたメモは本質的に構造化されておらず、多くの場合不完全です。ドイツの患者の独白のデータセットを提示し、適切に作成します。実世界の実用性と実用性の制約の下で定義された情報抽出タスク。 
[概要]この問題で医師をサポートするための最新のnlp技術の可能性を調査します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Media Keyphrase Prediction: A Unified Framework with
  Multi-Modality Multi-Head Attention and Image Wordings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_8.html">
      <font color="black">Cross-Media Keyphrase Prediction: A Unified Framework with
  Multi-Modality Multi-Head Attention and Image Wordings</font>
    </a>
  </h2>
  <font color="black">それにもかかわらず、ほとんどの以前の取り組みはテキストモデリングに焦点を当てており、一致する画像に埋め込まれた豊富な機能をほとんど無視しています。Twitterから新たに収集された大規模なデータセットでの広範な実験は、私たちのモデルが従来の注意に基づいて以前の最先端技術を大幅に上回っていることを示していますネットワーク..ソーシャルメディアスタイルのテキストと画像をより適切に調整するために、次のことを提案します。（1）複雑なクロスメディアインタラクションをキャプチャするための新しいマルチモダリティマルチヘッドアテンション（M3H-Att）。 （2）2つのモダリティを橋渡しするための、光学的文字と画像属性の形式の画像表現。 
[ABSTRACT]ソーシャルメディアはキーフレーズ予測としてますます人気が高まっています。これは、ユーザーが必要なものをすばやくキャプチャできるようにするためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Layer-Wise Multi-View Learning for Neural Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_9.html">
      <font color="black">Layer-Wise Multi-View Learning for Neural Machine Translation</font>
    </a>
  </h2>
  <font color="black">別のボーナスとして、私たちの方法はネットワークアーキテクチャにとらわれず、元のモデルと同じ推論速度を維持できます。このように、最上位のエンコーダ層（プライマリビューと呼ばれる）に加えて、中間エンコーダも組み込まれています。補助ビューとしてのレイヤー..5つの変換タスクに関する広範な実験結果は、私たちのアプローチが複数の強力なベースラインに対して安定した改善をもたらすことを示しています。 
[概要]既存のソリューションは通常、ネットワークアーキテクチャの調整に依存しています。さらに、各レイヤーのオフを認識します。この問題は、中間文の冗長なビューとして認識されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: An exploration of the encoding of grammatical gender in word embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_10.html">
      <font color="black">An exploration of the encoding of grammatical gender in word embeddings</font>
    </a>
  </h2>
  <font color="black">コンテキスト化された埋め込みに関する実験結果は、埋め込みにコンテキスト情報を追加すると、分類子のパフォーマンスに悪影響を与えることを指摘しました。スウェーデン語、デンマーク語、オランダ語の埋め込みで文法的な性別がエンコードされる方法に重複があることがわかりました。研究では、名詞の文法的な性別を決定する神経分類器の精度に応じて、単語の埋め込みのさまざまなセットを比較します。 
[概要]単語の埋め込みに基づく文法的な性別の研究は、文法的な性別がどのように決定されるかについての洞察を提供します。スウェーデン語、デンマーク語、およびオランダ語の埋め込みで文法的な性別がエンコードされる方法に重複があることがわかります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: AraWEAT: Multidimensional Analysis of Biases in Arabic Word Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_11.html">
      <font color="black">AraWEAT: Multidimensional Analysis of Biases in Arabic Word Embeddings</font>
    </a>
  </h2>
  <font color="black">いくつかの次元にわたるバイアスの存在を測定します。つまり、埋め込みモデル（Skip-Gram、CBOW、およびFastText）とベクトルサイズ、テキストのタイプ（百科事典のテキスト、ニュースとユーザー生成コンテンツ）、方言（エジプト方言と。現代標準アラビア語）、および時間（さまざまな期間のコーパスの通時分析）。私たちの分析では、いくつかの興味深い発見が得られました。たとえば、アラビア語のニュースコーパスでトレーニングされた埋め込みの暗黙的な性別バイアスは、時間の経過とともに着実に増加します（2007年から2017年の間）。 ..最近の研究によると、分布語のベクトル空間は、性別や人種差別などの人間の偏見をエンコードすることがよくあります。 
[概要]アラビア語の埋め込みにおけるバイアスの広範な分析を実施します。次に、埋め込みスペースに最近導入された一連のバイアステストを適用します。これには、さまざまな埋め込みスペースと埋め込みスペースが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Investigating Catastrophic Forgetting During Continual Training for
  Neural Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_12.html">
      <font color="black">Investigating Catastrophic Forgetting During Continual Training for
  Neural Machine Translation</font>
    </a>
  </h2>
  <font color="black">調査結果の妥当性と信頼性を確保するために、さまざまな言語ペアとドメインで実験を行います。NMTモデルのモジュールに関する調査では、一部のモジュールは一般ドメインの知識と密接な関係があり、他のモジュールはドメイン適応..この問題を解決するために多くの方法が提案されていますが、この現象の原因をまだ知ることはできません。 
[概要]継続的なトレーニング中のツールの大幅な変更により、一般的にパフォーマンスが低下します-ドメイン。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Weakly- and Semi-supervised Evidence Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_13.html">
      <font color="black">Weakly- and Semi-supervised Evidence Extraction</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、わずか100の証拠注釈で大幅な利益をもたらします。ただし、実際には、裏付けとなる証拠をマークする追加の注釈は、少数のトレーニング例でのみ利用できる場合があります（利用できる場合）。多くの予測タスクでは、利害関係者は望まない予測だけでなく、人間がその正しさを検証するために使用できる証拠も裏付けています。 
[要約]証拠注釈の例は、少数のトレーニング例でのみ利用できる場合があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Spectrum and Prosody Conversion for Cross-lingual Voice Conversion with
  CycleGAN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_14.html">
      <font color="black">Spectrum and Prosody Conversion for Cross-lingual Voice Conversion with
  CycleGAN</font>
    </a>
  </h2>
  <font color="black">CWTは、信号をさまざまな時間スケールに分解して、さまざまな時間解像度で韻律を説明する方法を提供します。このようにして、任意の2つの言語の並列データと調整手法の必要性を排除します。言語間音声変換に関する以前の研究主にF0転送の線形変換によるスペクトル変換に焦点を当てています。 
[要約]たとえば、2人の話者の並列データの必要性を排除します。これは、言語間音声変換における韻律の最初の研究です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-11">
        <br><font color="black">2020-08-11</font>
      </time>
    </span>
</section>
<!-- paper0: Decoupling entrainment from consistency using deep neural networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_15.html">
      <font color="black">Decoupling entrainment from consistency using deep neural networks</font>
    </a>
  </h2>
  <font color="black">これらの結果は、ニューラルネットワークを使用してエントレインメントをモデル化することの利点を示し、会話の質と一貫性を考慮しないエントレインメント測定値との以前の関連付けを解釈する方法に関する質問を提起します。話者の最初の音声機能を予測の混乱として扱うことを提案します。後続の出力の..これらは、実際の相互作用を偽の相互作用からうまく区別します。 
[概要]一貫性を制御するエントレインメントの新しい測定値を定義します。これらの測定値は、混乱を解消するための2つの既存のニューラルアプローチに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Meta-Learning for Natural Language Understanding under Continual
  Learning Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_16.html">
      <font color="black">Meta-Learning for Natural Language Understanding under Continual
  Learning Framework</font>
    </a>
  </h2>
  <font color="black">テキストの一般的な表現を得るために複数のタスクを処理する堅牢なモデルをトレーニングする方法が開発されました。ニューラルネットワークは、さまざまな自然言語理解（NLU）タスクへの取り組みの成果で認められています。この論文では、モデルを実装します。 -NLUタスクの継続的なフレームワークの下での非依存メタ学習（MAML）およびオンライン認識メタ学習（OML）メタ目的。 
[概要]瞬間接着剤と接着剤のベンチマークでメソッドを検証します。瞬間接着剤、接着剤で結果を検証します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: DeL-haTE: A Deep Learning Tunable Ensemble for Hate Speech Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_17.html">
      <font color="black">DeL-haTE: A Deep Learning Tunable Ensemble for Hate Speech Detection</font>
    </a>
  </h2>
  <font color="black">-そしてGabなどのフリンジアウトレットのベースラインモデルの欠如..ソーシャルメディアでのオンラインヘイトスピーチは、最近急成長している問題になっています..（a）私たちは国家の強みを組み合わせたディープラーニングモデルのアンサンブルを設計します-最先端のアプローチ、（b）転送学習を活用してGabなどのラベルのないデータセットで自動ヘイトスピーチ分類を実行するチューニングファクターをこのフレームワークに組み込み、（c）弱い教師あり学習方法を開発してラベルのないデータをトレーニングするためのフレームワーク。 
[ABSTRACT]悪意のあるグループは、いくつかのメインストリーム（twitterとfacebook）とフリンジ（gab、4chan、8chanなど）にまたがる大規模なコンテンツ配信ネットワークを開発しました。これらの問題は、大規模なソーシャルメディアの最優先事項になっています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: DAGA: Data Augmentation with a Generation Approach for Low-resource
  Tagging Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_18.html">
      <font color="black">DAGA: Data Augmentation with a Generation Approach for Low-resource
  Tagging Tasks</font>
    </a>
  </h2>
  <font color="black">結果は、特に与えられたゴールドトレーニングデータが少ない場合に、私たちの方法がベースラインを一貫して上回ることができることを示しています。半教師あり設定では、与えられたラベルなしデータのみとラベルなしデータに加えて、NERタスクでメソッドを評価します。知識ベース..監視された設定では、名前付きエンティティ認識（NER）、音声部分（POS）のタグ付け、およびエンドツーエンドのターゲットベースの感情分析（E2E-TBSA）タスクに関する広範な実験を実施します。 
[概要]線形化されたラベル付き文でトレーニングされた言語モデルを使用した新しい拡張方法を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: CharBERT: Character-aware Pre-trained Language Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_19.html">
      <font color="black">CharBERT: Character-aware Pre-trained Language Model</font>
    </a>
  </h2>
  <font color="black">また、教師なし文字表現学習のためのNLM（Noisy LM）という名前の新しい事前トレーニングタスクを提案します。最初に、連続する文字表現から各トークンのコンテキストワード埋め込みを構築し、次に文字の表現とサブワード表現を融合します。新規の教師なし相互作用モジュール..この論文では、これらの問題に取り組むために、以前の方法（BERT、RoBERTaなど）を改良したCharBERTという名前の文字認識事前トレーニング済み言語モデルを提案します。 
[概要]これらのメソッドは、単語をサブワード単位に分割して脆弱にします。これらのモデルが事前トレーニングされたモデル、評価セット、およびコードを利用できるのはこれが初めてです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: New Approaches for NLU based on Information Architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_20.html">
      <font color="black">New Approaches for NLU based on Information Architecture</font>
    </a>
  </h2>
  <font color="black">さて、通常の学習プロセスに戻りましょう。まず、語彙分類について知っていたことをすべて忘れてから、結論にジャンプしましょう。上記の分類原則はすべて、語彙を人為的に分割するのではなく、構造的および機能ベースの識別です。名詞、形容詞、代名詞などにチャンクします。 
[概要]このペーパーでは、字句チャンクをデータチャンク、構造チャンク、およびポインターチャンクに再分類しました。設定された構造の違いに応じて、データチャンクはさらに属性チャンクとエンティティチャンクに分割できます。著者は、自然言語は情報がエンコードされ、情報が高度に抽象化および概念化されている方法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-24">
        <br><font color="black">2020-10-24</font>
      </time>
    </span>
</section>
<!-- paper0: Rhetoric, Logic, and Dialectic: Advancing Theory-based Argument Quality
  Assessment in Natural Language Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_21.html">
      <font color="black">Rhetoric, Logic, and Dialectic: Advancing Theory-based Argument Quality
  Assessment in Natural Language Processing</font>
    </a>
  </h2>
  <font color="black">大規模なAQアノテーションの実現可能性を示し、次元間の関係を活用することでパフォーマンスが向上することを示し、理論ベースの予測と実際のAQ評価の相乗効果を探ります。次に、理論ベースの評価に対する最初の計算アプローチを提案します。将来の作業の強力なベースラインとして役立つ可能性があります。オンラインの論争的記述の3つの多様なドメインをカバーする広範な分析を実施し、GAQCorpusを提示することでこのギャップを埋めます。最初の大規模な英語マルチドメイン（コミュニティQ＆Aフォーラム、ディベートフォーラム、レビューフォーラム） ）理論ベースのAQスコアで注釈が付けられたコーパス。 
[要約]大規模な理論に基づくコーパスが欠落している、と英語の研究者は言います。しかし、それは異なるモデルとその後の改善に焦点を当てています。これには、必要な作業量の発見が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br><font color="black">2020-06-01</font>
      </time>
    </span>
</section>
<!-- paper0: VAW-GAN for Singing Voice Conversion with Non-parallel Training Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_22.html">
      <font color="black">VAW-GAN for Singing Voice Conversion with Non-parallel Training Data</font>
    </a>
  </h2>
  <font color="black">エンコーダーをトレーニングして、歌手のアイデンティティと歌の韻律（F0輪郭）を音声コンテンツから解きほぐします。通常、歌声変換システムのトレーニングには並列トレーニングデータが必要ですが、実際のアプリケーションでは実用的ではありません。歌手のアイデンティティとF0の場合、デコーダーは、ターゲットの歌手のアイデンティティが見えない出力スペクトル特徴を生成し、F0レンダリングを改善します。 
[概要]この論文では、vawに基づく歌声変換フレームワークを提案します-gan.itは歌手のアイデンティティとfsteinを使用してf0レンダリングを改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: BioNerFlair: biomedical named entity recognition using flair embedding
  and sequence tagger -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_23.html">
      <font color="black">BioNerFlair: biomedical named entity recognition using flair embedding
  and sequence tagger</font>
    </a>
  </h2>
  <font color="black">固有表現抽出に広く使用されているのとほぼ同じ汎用アーキテクチャを備えたBioNerFlairは、以前の最先端モデルよりも優れています。結果：Flair plusGloVe埋め込みと双方向LSTMを使用して生物医学的固有表現抽出のモデルをトレーニングする方法であるBioNerFlairを紹介します。 -CRFベースのシーケンスタガー..これらのモデルは優れた結果をもたらします。ただし、計算コストが高く、他のコンテキスト文字列ベースのモデルとLSTM-CRFベースのシーケンスタガーを使用して、ドメイン固有のタスクのスコアを向上させることができます。 
[概要]科学者や研究者は、自分に関連する情報を含む記事を見つけるのに苦労しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Finding Friends and Flipping Frenemies: Automatic Paraphrase Dataset
  Augmentation Using Graph Theory -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_24.html">
      <font color="black">Finding Friends and Flipping Frenemies: Automatic Paraphrase Dataset
  Augmentation Using Graph Theory</font>
    </a>
  </h2>
  <font color="black">事前にトレーニングされたBERTモデルから開始して、これらのデータセットを使用してトレーニングされた言い換えモデルでメソッドを評価し、自動的に拡張されたトレーニングセットがより正確なモデルをもたらすことを発見します。提供された文ペアラベルから言い換えグラフを作成し、拡張された文ペアラベルを作成します。遷移性プロパティを使用して元の文のペアからラベルを直接推測することによるデータセット。ほとんどのNLPデータセットは手動でラベル付けされているため、ラベル付けに一貫性がないか、サイズが制限されています。 
[概要]データセットを改善するためのコンセプトコンセプトコンセプトを提案します。構造バランス理論を使用して、グラフ内の誤ったラベル付けの可能性を特定し、ラベルを反転します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Experiencers, Stimuli, or Targets: Which Semantic Roles Enable Machine
  Learning to Infer the Emotions? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_25.html">
      <font color="black">Experiencers, Stimuli, or Targets: Which Semantic Roles Enable Machine
  Learning to Infer the Emotions?</font>
    </a>
  </h2>
  <font color="black">人のアイデンティティは特定の感情に偏っているので、それは経験者ですか（Xは常に幸せです）。刺激と感情カテゴリの予測を共同でモデル化することは両方のサブタスクに有益であることが示されていますが、これらの意味的役割のどちらが分類子が感情を推測できるかは不明です。それは特定のターゲット（誰もがXを愛する）または刺激（ Xを行うとみんなが悲しくなります）？ 
[要約]役割の位置について考えることで、分類の決定を改善できます。これらのgの意味的役割のどれが、分類子が感情を推測できるかは不明です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_26.html">
      <font color="black">XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection</font>
    </a>
  </h2>
  <font color="black">データセットは、言語固有のBERTモデルとSVMを使用して慎重に評価され、XEDが他の同様のデータセットと同等に機能することを示します。したがって、感情分析と感情検出に役立つツールです。Plutchikのコア感情を使用して、データセットに追加の注釈を付けます。ニュートラルを使用してマルチラベルマルチクラスデータセットを作成します。多言語のきめ細かい感情データセットであるXEDを紹介します。 
[要約]データセットは、人間の注釈付きフィンランド語（25k）と英語の文（30k）、および30の追加言語の投影注釈で構成されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Paragraph-level Attention-Aware Inference for Multi-Document Neural
  Abstractive Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_27.html">
      <font color="black">Paragraph-level Attention-Aware Inference for Multi-Document Neural
  Abstractive Summarization</font>
    </a>
  </h2>
  <font color="black">最後になりましたが、注意を意識した推論には強力な普遍性があり、さまざまな階層型要約モデルに簡単に採用して、モデルのパフォーマンスを向上させることができます。注意を意識したメカニズムでバニラビーム検索を改良することにより、品質が大幅に向上します。要約の数を観察することができます。代わりに、入力に対する注意の分布は不規則であり、ソースドキュメントのコンテンツレイアウトに依存する必要があります。 
[要約]たとえば、最適な注意分布とソースの間の依存関係を学習するための注意予測モデルを構築します。ただし、さまざまな空間入力の結論に均一なパターンを簡単に採用できます。yayazは、注意-普遍性-は普遍性のしるしです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Feature Extraction of Text for Deep Learning Algorithms: Application on
  Fake News Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_28.html">
      <font color="black">Feature Extraction of Text for Deep Learning Algorithms: Application on
  Fake News Detection</font>
    </a>
  </h2>
  <font color="black">特徴抽出は、アルゴリズムをより効率的かつ正確に機能させるため、機械学習と深層学習の重要なプロセスです。この前処理方法により、データが非常にコンパクトになるだけでなく、分類器に必要な特徴も含まれます。アルファベットの頻度には、元のテキストの複雑なコンテキストや意味を理解するためのいくつかの便利な機能が含まれているようです。N-gram）。 
[ABSTRACT]新しい調査によると、アルファベットの順序に関する情報がなくても、ニュースの元のテキストのディープラーニングアルゴリズムとアルファベットの頻度を使用すると、偽のニュースと信頼できるニュースを高精度で分類できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: Modeling Event Salience in Narratives via Barthes' Cardinal Functions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_29.html">
      <font color="black">Modeling Event Salience in Narratives via Barthes' Cardinal Functions</font>
    </a>
  </h2>
  <font color="black">注釈なしでイベントの顕著性を計算するために、バルトのイベントの顕著性の定義を採用し、事前にトレーニングされた言語モデルのみを必要とするいくつかの教師なし方法を提案します。イベントの顕著性の推定は、ストーリー生成などのタスクやテキストのツールとして役立ちます。ナラトロジーとフォークロリスティックスの分析..ナラティブのイベントは顕著性が異なります。ストーリーにとって重要なものもあれば、他のものよりも重要なものもあります。 
[要約]提案された方法は物語論と民俗学で普及している</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: On Cross-Dataset Generalization in Automatic Detection of Online Abuse -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_30.html">
      <font color="black">On Cross-Dataset Generalization in Automatic Detection of Online Abuse</font>
    </a>
  </h2>
  <font color="black">クロスデータセットの一般化におけるトピックバイアスとタスク定式化バイアスを調査します。これらのトピックを削除すると、ドメイン内分類のパフォーマンスを低下させることなく、クロスデータセットの一般化が向上します。教師なしトピックモデリングとトピックのキーワードの手動検査を使用して、これらの例を識別します。 。 
[要約]実際には、トピックおよびクラス配布で設定されたトレーニングとは異なるデータにシステムが適用されます。データセット間の一般化でトピックのバイアスを調査します。教師なしトピックモデリングとトピックのキーワードの手動検査を使用して、これらの例を特定します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Word Sense Disambiguation Biases in Machine Translation for
  Model-Agnostic Adversarial Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_31.html">
      <font color="black">Detecting Word Sense Disambiguation Biases in Machine Translation for
  Model-Agnostic Adversarial Attacks</font>
    </a>
  </h2>
  <font color="black">統計データのプロパティに基づいて曖昧性解消エラーを予測する方法を紹介し、いくつかのドメインとモデルタイプでその有効性を示します。調査結果は、曖昧性解消の堅牢性がドメイン間で大幅に異なり、同じデータでトレーニングされた異なるモデルが異なる脆弱性があることを示しています。攻撃..語義の曖昧性解消は、NMTの翻訳エラーのよく知られた原因です。 
[要約]誤った曖昧性解消の選択のいくつかは、モデルの過剰によるものです-ソーステキストのより深い理解ではなく、トレーニングデータで見つかったデータセットアーティファクトへの依存</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Data-to-Text Generation with Iterative Text Editing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_32.html">
      <font color="black">Data-to-Text Generation with Iterative Text Editing</font>
    </a>
  </h2>
  <font color="black">2つの主要なデータからテキストへのデータセット（WebNLG、Cleaned E2E）でのアプローチを評価し、その警告と利点を分析します。反復的なテキスト編集に基づくデータからテキストへの生成への新しいアプローチを提示します。モデルは単純なヒューリスティックによってフィルタリングされ、既製の事前トレーニング済み言語モデルで再ランク付けされます。 
[概要]データからテキストへの生成により、文の融合に一般的なドメインデータセットを使用して、ゼロショットドメインの適応の可能性が開かれることを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Joint Entity and Relation Extraction with Set Prediction Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_33.html">
      <font color="black">Joint Entity and Relation Extraction with Set Prediction Networks</font>
    </a>
  </h2>
  <font color="black">この集合予測問題を解決するために、非自己回帰並列デコードを備えた変圧器を特徴とするネットワークを提案します。さらに、2分割マッチングを介して一意の予測を強制する集合ベースの損失も設計します。ただし、以前のseq2seqベースのモデルでは変換する必要があります。トレーニングフェーズでのシーケンスへのトリプルのセット。 
[概要]提案されたネットワークは、トリプルの最終セットをワンショットで直接出力します。これらのネットワークは、トリプルオーダーを無視し、関係タイプとエンティティに焦点を当てることにより、より正確なトレーニング信号を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: WSL-DS: Weakly Supervised Learning with Distant Supervision for Query
  Focused Multi-Document Abstractive Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_34.html">
      <font color="black">WSL-DS: Weakly Supervised Learning with Distant Supervision for Query
  Focused Multi-Document Abstractive Summarization</font>
    </a>
  </h2>
  <font color="black">次に、各単一ドキュメントで要約モデルを繰り返しトレーニングして、複数のドキュメント（つまり、長いシーケンス）でニューラル要約モデルを一度にトレーニングするときに発生する計算の複雑さの問題を軽減します。クエリフォーカスマルチドキュメント要約（QF- MDS）タスク、ドキュメントのセット、およびクエリが提供されます。ここでの目標は、指定されたクエリに基づいてこれらのドキュメントから要約を生成することです。ドキュメント理解会議（DUC）データセットの実験結果は、提案されたアプローチが新しい状態を設定することを示しています。さまざまな評価指標に関する最先端の結果。 
[概要]ラベル付けされたトレーニングデータセットの欠如は、このタスクの主要な課題です。目的は、マルチドキュメントゴールドからドキュメントセット内の各ドキュメントの弱参照要約を作成することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Appraisal Theories for Emotion Classification in Text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_35.html">
      <font color="black">Appraisal Theories for Emotion Classification in Text</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、イベントの説明における高品質の評価次元の割り当てが、個別の感情カテゴリの分類の改善につながることを示しています。したがって、自動分類アプローチでは、潜在変数としてイベントのプロパティを学習する必要があります（たとえば、不確実性と精神的または肉体的努力ヘビの遭遇に関連して恐怖につながる）。この論文では、イベントの認知的評価の理論に従って、イベントのそのような解釈を明示的にし、分類モデルにエンコードされたときの感情分類の可能性を示すことを提案します。 
[概要]このアプローチは、イベントの知覚に基づく既存の心理学理論を無視します。この感情の再構築は、主観的な感情の明示的なレポートにアクセスしなくても可能です。これらの例は、感情分類の可能性を示すことを目的としています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br><font color="black">2020-03-31</font>
      </time>
    </span>
</section>
<!-- paper0: De-Anonymizing Text by Fingerprinting Language Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_36.html">
      <font color="black">De-Anonymizing Text by Fingerprinting Language Generation</font>
    </a>
  </h2>
  <font color="black">ML開発者は、実行パスが機密入力に依存しないようにするなどの安全なコーディング手法をまだ採用していません。次に、攻撃者が適切なサイドチャネル（キャッシュアクセスなど）を介してこれらの指紋を測定することにより、入力されたテキストを推測する方法を示します。 ）、この攻撃が匿名テキストの匿名化にどのように役立つかを説明し、防御について話し合います。マシン学習システムのコンポーネントは、（まだ）セキュリティホットスポットとして認識されていません。 
[概要]安全なコーディング手法は開発者によってまだ採用されていません。この調査は、安全で安全な学習システムの保護に役立つ可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br><font color="black">2020-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: Better Sign Language Translation with STMC-Transformer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_37.html">
      <font color="black">Better Sign Language Translation with STMC-Transformer</font>
    </a>
  </h2>
  <font color="black">これは、GTグロス翻訳がSLTパフォーマンスの上限として機能し、グロスが手話の非効率的な表現であるという以前の主張と矛盾します。グロス監視に依存する現在の方法の問題も示しています。ASLG-PC12コーパスについて、16BLEU以上の増加を報告します。 
[概要]翻訳システムは、手話グロスからバインドされた話し言葉を作成します。アスルでは、aslg（pc12 text text text.the video）を超えて、stmcのテキスト翻訳がgtグロスの翻訳よりも優れていることを報告します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-01">
        <br><font color="black">2020-04-01</font>
      </time>
    </span>
</section>
<!-- paper0: CMT in TREC-COVID Round 2: Mitigating the Generalization Gaps from Web
  to Special Domain Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_38.html">
      <font color="black">CMT in TREC-COVID Round 2: Mitigating the Generalization Gaps from Web
  to Special Domain Search</font>
    </a>
  </h2>
  <font color="black">深い事前トレーニング済み言語モデル（LM）に基づくニューラルランカーは、多くの情報検索ベンチマークを改善することが示されています。システムは、ドメイン適応型事前トレーニングと数ショット学習テクノロジーを利用して、ニューラルランカーがドメインの不一致とラベル不足の問題を軽減するのに役立ちます。この論文は、特別なドメイン適応問題を軽減するための検索システムを提示します。 
[概要]当社のコードはwwwで公開されています。 github。 com / thunlp / openmatch。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Learning on the Latent Space for Diverse Dialog Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_39.html">
      <font color="black">Adversarial Learning on the Latent Space for Diverse Dialog Generation</font>
    </a>
  </h2>
  <font color="black">私たちのモデルは、最初に自動エンコードによって文の意味のある表現を学習し、次に入力クエリを応答表現にマッピングすることを学習し、それが次に応答文としてデコードされます。この論文では、生成的敵対的生成ネットワークに基づく2段階のフレームワークを提案します。条件付き応答を生成するためのネット..定量的評価と定性的評価の両方で、私たちのモデルが既存の最先端の方法よりも流暢で、関連性があり、多様な応答を生成することが示されています。 
[要約]モデルは、既存の最先端の方法よりも流暢で、関連性があり、多様な応答を生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br><font color="black">2019-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Neutralizing Gender Bias in Word Embedding with Latent Disentanglement
  and Counterfactual Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_40.html">
      <font color="black">Neutralizing Gender Bias in Word Embedding with Latent Disentanglement
  and Counterfactual Generation</font>
    </a>
  </h2>
  <font color="black">さまざまな定量的および定性的なバイアス除去実験から、私たちの方法は、単語の埋め込みのバイアス除去において、既存のバイアス除去方法よりも優れていることが示されています。 ..以前の方法は、バイアス除去のために単語の埋め込みを線形部分空間に投影しますが、適応された勾配反転層を備えたシャム自動エンコーダ構造を備えた\ textit {LatentDisentanglement}方法を導入します。 
[概要]以前の方法は、バイアス除去中に意味情報を保持する機能を示しています。新しい方法では、「潜在的な解きほぐし」方法を使用して、単語の性別情報を二重寝具に変換します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br><font color="black">2020-04-07</font>
      </time>
    </span>
</section>
<!-- paper0: Results of a Single Blind Literary Taste Test with Short Anonymized
  Novel Fragments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_41.html">
      <font color="black">Results of a Single Blind Literary Taste Test with Short Anonymized
  Novel Fragments</font>
    </a>
  </h2>
  <font color="black">48人の参加者による対照実験の参加者によるオランダ語小説の文学的評価に対するテキストの特徴の影響を測定するためのパイロット研究の結果を報告します。文学的品質の認識がテキストからどの程度導き出されるかは未解決の問題です。 -本質的要因と社会的要因..探索的分析では、評価を、社会的要因が除外されなかったリドルの大規模な読者調査からの評価、およびそれらの文学的な評価の機械学習予測と比較します。 
[要約]教師ありモデルは、文学的な質問から文学的な品質評価を予測できますが、これは社会的要因が重要でないことを証明するものではありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Code-switched Classification Exploiting Constituent Language
  Resources -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_42.html">
      <font color="black">Towards Code-switched Classification Exploiting Constituent Language
  Resources</font>
    </a>
  </h2>
  <font color="black">英語-ヒンディー語のコードスイッチング設定で、皮肉検出とヘイトスピーチ検出の2つのダウンストリームタスクの実験を実行します。コードスイッチングは、同じ音声交換内で1つの言語から別の言語への移行を示す一般的に観察される通信現象です。これらの実験では、最先端の実験と比較して、皮肉検出とヘイトスピーチ検出のF1スコアがそれぞれ22％と42.5％増加していることが示されています。 
[ABSTRACT]コード-データの可用性が限られているため、切り替えられたデータはしばしば厄介なタスクになります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: How Far Does BERT Look At:Distance-based Clustering and Analysis of
  BERT$'$s Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_43.html">
      <font color="black">How Far Does BERT Look At:Distance-based Clustering and Analysis of
  BERT$'$s Attention</font>
    </a>
  </h2>
  <font color="black">この作業では、提案された機能のセットの上に教師なしクラスタリングを行うことで、注意ヒートマップを大幅に異なるパターンに明確にクラスター化します。これは、以前の観察結果と一致します。さらに、提案された機能を使用して、さまざまな注意ヘッドを説明および調整できます。トランスフォーマーモデル..分析研究を通じて、対応する機能をさらに研究します。 
[要約]以前の研究では、注意の頭の行動のいくつかの原始的なパターンが見つかりましたが、注意のパターンに固有のより体系的な分析は依然として原始的なままです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Early Onset of Depression from Social Media Text using Learned
  Confidence Scores -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_44.html">
      <font color="black">Detecting Early Onset of Depression from Social Media Text using Learned
  Confidence Scores</font>
    </a>
  </h2>
  <font color="black">そのために、eRisk 2018データセットを調査し、トピック分析と学習した信頼スコアを活用して意思決定プロセスをガイドすることにより、最先端の技術に関して良好な結果を達成します。この作業では、早期発症を検出する方法に焦点を当てます。ソーシャルメディアのテキスト、特にRedditからのうつ病の分析。書かれたテキストからの精神的健康障害に関する計算研究は、自然言語処理と心理学の間の学際的な領域をカバーしています。 
[要約]うつ病は若年成人の2番目に多い死因です。私たちはeriskデータセットを調査し、良好な結果を達成しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: An Information Bottleneck Approach for Controlling Conciseness in
  Rationale Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_45.html">
      <font color="black">An Information Bottleneck Approach for Controlling Conciseness in
  Rationale Extraction</font>
    </a>
  </h2>
  <font color="black">IBを使用して、調整可能なスパース事前分布を通じてマスクのスパース性レベルを直接制御できる学習目標を導き出します。複雑な言語理解モデルの決定は、入力を元のテキストの関連するサブシーケンスに制限することで合理化できます。半監視設定では、適度な量の金の理論的根拠（トレーニング例の25％）が、完全な入力を使用するモデルとのギャップを埋めます。 
[要約]私たちの完全な教師なしアプローチは、文の密なバイナリマスクを予測する説明者を共同で学習します。終了-抽出された理論的根拠のみを決定するタスク予測子</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: Subword Segmentation and a Single Bridge Language Affect Zero-Shot
  Neural Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_46.html">
      <font color="black">Subword Segmentation and a Single Bridge Language Affect Zero-Shot
  Neural Machine Translation</font>
    </a>
  </h2>
  <font color="black">ただし、以前の論文では、ゼロショット翻訳の成功がまちまちであると報告されています。多言語モデルの最近の傾向は、すべての言語ペア間の並列データでトレーニングするのではなく、単一のブリッジ言語を使用することです。言語固有のサブワードセグメンテーションは、トレーニング時のサブワードコピーが少なくなり、共同でトレーニングされたセグメンテーションと比較して、ゼロショットのパフォーマンスが向上することがわかりました。 
[ABSTRACT]ゼロ-wmtデータでトレーニングされた多言語システムのショットパフォーマンス。システムの魅力を高める傾向が見られます。これにより、モデルが言語タグを無視する障害モードが発生します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Do face masks introduce bias in speech technologies? The case of
  automated scoring of speaking proficiency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_47.html">
      <font color="black">Do face masks introduce bias in speech technologies? The case of
  automated scoring of speaking proficiency</font>
    </a>
  </h2>
  <font color="black">2つのサンプルは音響測定の範囲全体で異なり、音声パターンにも小さいながらも有意な違いがあることがわかります。この論文では、英語能力の自動評価に対するフェイスマスクの着用の影響を調査します。バイアスは、2つのグループ間でスコアに差を示さなかった。 
[概要]顔の覆いは、信号の音響特性と音声パターンの両方に影響を与える可能性があります。ただし、わずかな違いでも、人間または自動化された英語能力のスコアに違いはありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Variational Autoencoder for Text Modelling with Timestep-Wise
  Regularisation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_48.html">
      <font color="black">Improving Variational Autoencoder for Text Modelling with Timestep-Wise
  Regularisation</font>
    </a>
  </h2>
  <font color="black">モデルの有効性と多様性は、言語モデリングや対話応答の生成など、さまざまなタスクで実証されています。このホワイトペーパーでは、タイムステップワイズ正則化VAE（TWR-VAE）と呼ばれる、後部を効果的に回避できるシンプルで汎用的なアーキテクチャを提案します。崩壊し、RNNベースのVAEモデルに適用できます。このような問題は、RNNベースのVAEモデルがテキストモデリングに使用される場合に特によく見られます。 
[概要]シンプルで一般的なアーキテクチャは、タイムステップと呼ばれます-賢明な正則化vae（twr-vae）。事後崩壊を効果的に回避でき、rnnベースのvaeモデルに適用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-lingual Word Embeddings beyond Zero-shot Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_49.html">
      <font color="black">Cross-lingual Word Embeddings beyond Zero-shot Machine Translation</font>
    </a>
  </h2>
  <font color="black">また、弱い翻訳転送を引き起こす多言語アーキテクチャの制限の側面について説明し、制限を緩和する方法を提案します。転送が言語間単語のみに基づいている場合の、多言語ニューラル機械翻訳モデルの見えない言語への転送可能性を調査します。埋め込み..私たちの実験結果は、翻訳知識が他の言語に弱く伝達される可能性があり、伝達可能性の程度が言語の関連性に依存することを示しています。 
[要約]移転可能性の理論は、国の関連する制限に依存します。知識の理解の欠如は、他の言語に移転する可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Input-independent Attention Weights Are Expressive Enough: A Study of
  Attention in Self-supervised Audio Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_50.html">
      <font color="black">Input-independent Attention Weights Are Expressive Enough: A Study of
  Attention in Self-supervised Audio Transformers</font>
    </a>
  </h2>
  <font color="black">t-SNE、PCA、およびいくつかの観察の助けを借りて、自己監視オーディオトランスの注意の重みは4つの一般的なケースに分類できます。これらのケースといくつかの分析に基づいて、特定の注意の重みのセットを使用できます。モデルを初期化するために..私たちのアプローチは、典型的な自己注意に匹敵するパフォーマンスを示していますが、トレーニングと推論の両方で20％少ない時間を必要とします。 
[ABSTRACT]トランスフォーマーベースのモデルは、10種類の注意アルゴリズムに基づいています。これらの注意アルゴリズムを使用して、自己監視方式でモデルを事前トレーニングし、特徴抽出器として扱います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-09">
        <br><font color="black">2020-06-09</font>
      </time>
    </span>
</section>
<!-- paper0: A Benchmark of Rule-Based and Neural Coreference Resolution in Dutch
  Novels and News -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_51.html">
      <font color="black">A Benchmark of Rule-Based and Neural Coreference Resolution in Dutch
  Novels and News</font>
    </a>
  </h2>
  <font color="black">結果は、データ駆動型システムと知識駆動型システムの相対的な強み、およびドメイン、ドキュメントの長さ、注釈スキームの影響についての洞察を提供します。ルールベース（Lee et al。、2013）とニューラルを評価します（Lee et al。、2018）2つのドメインのオランダのデータセットに関する共参照システム：文学小説とニュース/ウィキペディアのテキスト..このペーパーで使用されているコードとモデルは、https：//github.com/andreasvc/crac2020 
[ABSTRACT]で入手できます。 ]結果は、データ駆動型システムと知識駆動型システムの相対的な強みに対する洞察を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Grid Tagging Scheme for Aspect-oriented Fine-grained Opinion Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_52.html">
      <font color="black">Grid Tagging Scheme for Aspect-oriented Fine-grained Opinion Extraction</font>
    </a>
  </h2>
  <font color="black">広範な実験結果は、GTSモデルが強力なベースラインを大幅に上回り、最先端のパフォーマンスを達成することを示しています。ただし、パイプラインアプローチは、実際のシナリオではエラーの伝播と不便に悩まされがちです。GTSの実現可能性と互換性を検証するには、 CNN、BiLSTM、BERTにそれぞれ基づいて3つの異なるGTSモデルを実装し、アスペクト指向の意見ペア抽出と意見トリプレット抽出データセットで実験を行います。 
[要約]完全なafoeタスクは通常、複数のサブタスクに分割され、パイプラインで達成されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-09">
        <br><font color="black">2020-10-09</font>
      </time>
    </span>
</section>
<!-- paper0: BERT-QE: Contextualized Query Expansion for Document Re-ranking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/cs.CL/paper_53.html">
      <font color="black">BERT-QE: Contextualized Query Expansion for Document Re-ranking</font>
    </a>
  </h2>
  <font color="black">このギャップを埋めるために、BERTなどのコンテキスト化モデルをドキュメント検索タスクに適用する最近の進歩に触発されて、このペーパーでは、BERTモデルの強度を活用して、拡張に関連するドキュメントチャンクを選択する新しいクエリ拡張モデルを提案します。クエリとドキュメントで使用される言語間の不一致を軽減します。標準のTRECRobust04およびGOV2テストコレクションの評価では、提案されたBERT-QEモデルはBERT-Largeモデルを大幅に上回っています。 
[要約]提案されたbert-qeモデルはbert-ラージモデルを大幅に上回っています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: StyleMelGAN: An Efficient High-Fidelity Adversarial Vocoder with
  Temporal Adaptive Normalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.AS/paper_0.html">
      <font color="black">StyleMelGAN: An Efficient High-Fidelity Adversarial Vocoder with
  Temporal Adaptive Normalization</font>
    </a>
  </h2>
  <font color="black">したがって、計算の複雑さを抑えて忠実度の高い音声を合成できる軽量のニューラルボコーダーであるStyleMelGANを提案します。WaveNetやWaveGlowのような計算量の多いモデルが最良の結果を達成し、軽量のGANモデルなどが最適です。 StyleMelGANは、時間適応正規化を使用して、ターゲット音声の音響特性を使用して低次元ノイズベクトルのスタイルを設定します。 
[概要] wavenet、waveglow、ganモデルが最良の結果を達成します。wavenetやwaveglowなどの軽量ganモデルも最良の結果を達成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Two Heads Are Better Than One: A Two-Stage Approach for Monaural Noise
  Reduction in the Complex Domain -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.AS/paper_1.html">
      <font color="black">Two Heads Are Better Than One: A Two-Stage Approach for Monaural Noise
  Reduction in the Complex Domain</font>
    </a>
  </h2>
  <font color="black">第2段階では、振幅と位相の両方の成分が調整されます。第1段階では、振幅のみが最適化されます。これは、ノイズの多い位相を組み込んで、粗く複雑なクリーンな音声スペクトル推定を取得します。 
[要約]最初の段階では、マグニチュードのみが最適化されます。実験はwsj0-si84コーパスで実行されます。結果は、提案されたアプローチが以前のベースラインを大幅に上回っていることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Small footprint Text-Independent Speaker Verification for Embedded
  Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.AS/paper_2.html">
      <font color="black">Small footprint Text-Independent Speaker Verification for Embedded
  Systems</font>
    </a>
  </h2>
  <font color="black">学習パラメーターの数が25.6倍減少したのに対し、距離チャレンジからの2019 VOiCESの最高スコアモデルに関して2.6パーセントポイントのEERの限定的な増加を報告します。さらに、音響的にモデルを評価します。挑戦的なVOiCESコーパス..5秒の長さの発話で200ms未満の遅延で、Raspberry Pi3BなどのIoTシステムに典型的な小型デバイスでソリューションを実行する可能性を示します。 
[概要]モデルはvoxceleb1検証テストセットによって作成されました。モデルは実証済みの実証済みの音声に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Improved End-to-End Dysarthric Speech Recognition via Meta-learning
  Based Model Re-initialization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.AS/paper_3.html">
      <font color="black">Improved End-to-End Dysarthric Speech Recognition via Meta-learning
  Based Model Re-initialization</font>
    </a>
  </h2>
  <font color="black">具体的には、エンドツーエンドモデルに焦点を当て、モデルにとらわれないメタ学習（MAML）と爬虫類アルゴリズムを拡張して、さまざまな構音障害の話者への適応を繰り返しシミュレートすることにより、基本モデルをメタ更新します。ただし、通常のスピーカーと構音障害の音声データは、基本モデルの適応パフォーマンスを制限します。UASpeechデータセットの実験結果は、提案された方法を使用した最良のモデルが、微調整なしの基本モデルおよびモデルを直接微調整した場合と比較して、54.2％および7.6％の相対的な単語エラー率の削減を達成することを示しています。それぞれベースモデルから調整されており、最先端のハイブリッドDNN-HMMモデルに匹敵します。 
[概要]構音障害スピーチは、限られた構音障害スピーチを使用して微調整する有望な方法です-基本モデルを調整します。モデルは構音障害スピーチの知識を取得し、目に見えない構音障害の話者に迅速に適応する方法を学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Spectrum and Prosody Conversion for Cross-lingual Voice Conversion with
  CycleGAN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.AS/paper_4.html">
      <font color="black">Spectrum and Prosody Conversion for Cross-lingual Voice Conversion with
  CycleGAN</font>
    </a>
  </h2>
  <font color="black">F0モデリングに連続ウェーブレット変換（CWT）分解を使用することを提案します。また、スペクトルマッピングと韻律マッピング用にそれぞれ2つのCycleGANパイプラインをトレーニングすることを提案します。このようにして、任意の2つの言語の並列データの必要性を排除します。アラインメント技術。 
[要約]たとえば、2人の話者の並列データの必要性を排除します。これは、言語間音声変換における韻律の最初の研究です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-11">
        <br><font color="black">2020-08-11</font>
      </time>
    </span>
</section>
<!-- paper0: Gesticulator: A framework for semantically-aware speech-driven gesture
  generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.AS/paper_5.html">
      <font color="black">Gesticulator: A framework for semantically-aware speech-driven gesture
  generation</font>
    </a>
  </h2>
  <font color="black">任意のビートとセマンティックジェスチャを一緒に生成するように設計されたモデルを提示します。ディープラーニングベースのモデルは、入力として音声の音響表現とセマンティック表現の両方を取り、出力として関節角度回転のシーケンスとしてジェスチャを生成します。主観的および客観的評価私たちのアプローチの成功を確認します。 
[ABSTRACT]ディープ-学習ベースのモデルは、音声の音響表現と意味表現の両方を入力として受け取り、出力として関節角度回転のシーケンスとしてジェスチャーを生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-25">
        <br><font color="black">2020-01-25</font>
      </time>
    </span>
</section>
<!-- paper0: Improving RNN transducer with normalized jointer network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.AS/paper_6.html">
      <font color="black">Improving RNN transducer with normalized jointer network</font>
    </a>
  </h2>
  <font color="black">実験は、オープンな170時間のAISHELL-1と産業レベルの30000時間のマンダリン音声データセットで実施されます。さらに、RNN-Tシステムを30000時間の産業オーディオデータで十分に訓練された商用ハイブリッドシステムと比較し、9を取得します。事前トレーニングや外部言語モデルを使用しない場合の相対的な改善。この作業では、RNN-Tトレーニングの大きな勾配変動の原因を分析し、それを克服するための新しい\ textit {正規化されたジョイントネットワーク}を提案しました。 
[概要]従来のハイブリッドasrシステムと比較して優れたパフォーマンスを示していますが、モデルはパフォーマンスを損なうことを示しています。また、変更されたコンフォーマーエンコーダネットワークとトランスフォーマー-xl予測ネットワークを使用してrnn-tネットワークを強化することを提案します。最高のパフォーマンスを実現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: VAW-GAN for Singing Voice Conversion with Non-parallel Training Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.AS/paper_7.html">
      <font color="black">VAW-GAN for Singing Voice Conversion with Non-parallel Training Data</font>
    </a>
  </h2>
  <font color="black">音声コンテンツから歌手のアイデンティティと歌の韻律（F0輪郭）を解きほぐすためにエンコーダーをトレーニングします。実験結果は、提案されたフレームワークがベースラインフレームワークよりも優れたパフォーマンスを達成することを示しています。変分自動エンコーディングWasserstein生成的敵対ネットワークなどの最近のエンコーダー-デコーダー構造（VAW-GAN）は、非並列トレーニングデータを通じてマッピングを学習する効果的な方法を提供します。 
[概要]この論文では、vawに基づく歌声変換フレームワークを提案します-gan.itは歌手のアイデンティティとfsteinを使用してf0レンダリングを改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: A Two-Stage Approach to Device-Robust Acoustic Scene Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.AS/paper_8.html">
      <font color="black">A Two-Stage Approach to Device-Robust Acoustic Scene Classification</font>
    </a>
  </h2>
  <font color="black">DCASE 2020タスク1aで評価した結果は、提案されたASCシステムが開発セットで最先端の精度を達成し、CNNアンサンブルの2段階融合である最高のシステムが81.9％の平均精度を実現することを示しています。マルチデバイステストデータの中で、目に見えないデバイスで大幅な改善が得られます。2段階の分類器を実装するために3つの異なるCNNアーキテクチャが検討され、周波数サブサンプリングスキームが調査されます。デバイスの堅牢性を向上させるために、競争力のあるデータ駆動型音響シーン分類（ASC）システムの望ましい重要な機能である、完全畳み込みニューラルネットワーク（CNN）に基づく新しい2段階システムが提案されています。 
[ABSTRACT] cnnシステムは、2つのcnn分類器に基づくアドホックスコアの組み合わせを組み合わせます。新しいシステムは、ascの革新的なデータ拡張スキームを提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic latency speech recognition with asynchronous revision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.AS/paper_9.html">
      <font color="black">Dynamic latency speech recognition with asynchronous revision</font>
    </a>
  </h2>
  <font color="black">実験によると、非同期リビジョンを使用した動的レイテンシモデルでは、ストリーミングモデルに比べて8 \％〜14 \％の相対的な改善が見られます。トレーニングと推論の不一致を軽減するために、入力発話をいくつかのセグメントにランダムに分割するトレーニング手法であるセグメントトリミングを提案します。順方向接続を使用します。これにより、動的な遅延音声認識の結果が得られ、精度が大幅に向上します。 
[ABSTRACT]これにより、動的なレイテンシー情報を改善して取得できます。これにより、インスタントレイテンシー情報を取得できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: ShaneRun System Description to VoxCeleb Speaker Recognition Challenge
  2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.AS/paper_10.html">
      <font color="black">ShaneRun System Description to VoxCeleb Speaker Recognition Challenge
  2020</font>
    </a>
  </h2>
  <font color="black">また、エンコーダからの元の負のユークリッド距離の代わりに、テスト発話ペアのt-SNE正規化距離を使用して最適な融合を実装する簡単な方法を提供します。最終的に提出されたシステムは、固定データトラックで0.3098 minDCFと5.076％ERRを取得し、ベースラインはそれぞれ1.3％minDCFと2.2％ERRです。このレポートでは、ShaneRunのチームがVoxCelebスピーカー認識チャレンジ（VoxSRC）2020に提出したことを説明します。
[概要]スピーカーの埋め込みを抽出するエンコーダーとしてresnet-34を使用します。最終的に提出されたシステムは0.3098mindcfと5を取得しました。076％エラー</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: A Study of Incorporating Articulatory Movement Information in Speech
  Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.AS/paper_11.html">
      <font color="black">A Study of Incorporating Articulatory Movement Information in Speech
  Enhancement</font>
    </a>
  </h2>
  <font color="black">深層学習アルゴリズムは音声強調（SE）で大きな進歩を遂げましたが、SEのパフォーマンスは、目に見えないノイズタイプや非常に低い信号対ノイズ比（SNR）などの非常に困難な条件に対しては依然として制限されています。さらに、AAMSEは堅牢です。非常に低いSNRと目に見えないノイズタイプの条件下での結果..波形マッピングベースとスペクトルマッピングベースのSEシステムの両方の関節運動機能と音声データを3つの融合戦略と組み合わせます。 
[ABSTRACT]調音-動きseモデル（aamse）は、新しいマルチモーダルオーディオ-調音-動きseモデルです。これらの結果は、データの組み合わせに基づいており、seの全体的なパフォーマンスを向上させることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Training Wake Word Detection with Synthesized Speech Data on Confusion
  Words -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.AS/paper_12.html">
      <font color="black">Training Wake Word Detection with Synthesized Speech Data on Confusion
  Words</font>
    </a>
  </h2>
  <font color="black">さらに、マルチスピーカーテキスト読み上げシステムによって生成された合成データでトレーニングセットを拡張することにより、混乱する単語のシナリオに関する大幅な改善を実現します。このようなシナリオでのウェイクワード検出システムの堅牢性を強化するために、2つを調査します。エンドツーエンドのKWSシステムをトレーニングするためのデータ拡張セットアップ..紛らわしい単語は、実際のキーワードスポッティングアプリケーションでよく見られます。これは、複雑な話し言葉や、事前定義されたものと同じように聞こえるさまざまな種類の単語が原因で、パフォーマンスが大幅に低下します。キーワード。 
[概要]データ拡張システムは、拡張をトレーニングするための2つのデータ拡張セットアップに基づいています。結果は、システムの堅牢性を強化するために作成されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Problems using deep generative models for probabilistic audio source
  separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.AS/paper_13.html">
      <font color="black">Problems using deep generative models for probabilistic audio source
  separation</font>
    </a>
  </h2>
  <font color="black">深層生成モデリングの最近の進歩により、複雑なデータから事前分布を学習し、後でベイジアン推論に使用できるようになりました。2つのオーディオデータセットで2種類の深層生成モデルのこの動作を定量化します。ただし、分布が学習したことがわかります。オーディオ信号の深い生成モデルでは、確率論的アプローチを使用したオーディオソースの分離などのタスクに必要な適切なプロパティが示されません。 
[概要]これは、オーディオ信号の通信が不足していることが原因である可能性があります。ただし、オーディオソースの分離などのタスクに必要な適切なプロパティを血管が示すことができないことがわかりました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Do face masks introduce bias in speech technologies? The case of
  automated scoring of speaking proficiency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.AS/paper_14.html">
      <font color="black">Do face masks introduce bias in speech technologies? The case of
  automated scoring of speaking proficiency</font>
    </a>
  </h2>
  <font color="black">2つのサンプルは音響測定の範囲全体で異なり、音声パターンにも小さいながらも有意な違いが見られます。ただし、これらの違いは、人間または自動化された英語能力のスコアの違いにはなりません。バイアスのいくつかの測定2つのグループ間でスコアに差は見られませんでした。 
[概要]顔の覆いは、信号の音響特性と音声パターンの両方に影響を与える可能性があります。ただし、わずかな違いでも、人間または自動化された英語能力のスコアに違いはありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Explicit Prosodic Modelling and Deep Speaker Embedding Learning for
  Non-standard Voice Conversion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.AS/paper_15.html">
      <font color="black">Explicit Prosodic Modelling and Deep Speaker Embedding Learning for
  Non-standard Voice Conversion</font>
    </a>
  </h2>
  <font color="black">標準音声の音声変換（VC）は大幅に進歩しましたが、構音障害や第二言語（L2）音声などの非標準音声のVCは、話者を維持しながら非定型韻律を修正する必要があるため、依然として課題です。アイデンティティ..第3に、変換モデルは、音声埋め込みと標準韻律機能を入力として受け取り、スピーカーエンコーダーまたはスピーカー適応を介して学習されたターゲットDSEを条件として、変換された音声を生成します。まず、音声エンコーダーは堅牢な音声を抽出しようとします。非標準の音声からの埋め込み。 
[概要] vcシステムには、明示的な韻律モデリングとディープスピーカー埋め込み（dse）学習があります。最初に、パラリンピック音声補正機能が音素埋め込みを取り込んで、標準の音素持続時間とピッチ値を推測します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Textual Echo Cancellation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.AS/paper_16.html">
      <font color="black">Textual Echo Cancellation</font>
    </a>
  </h2>
  <font color="black">このシステムは、マイク混合信号とTTS再生のソーステキストの両方を入力として受け取り、強化されたオーディオを予測する、マルチソースアテンションを備えた新しいシーケンス間モデルを使用して実装します。この論文では、提案します。 Textual Echo Cancellation（TEC）-オーバーラップした音声録音からのText-to-Speech（TTS）再生エコーをキャンセルするためのフレームワーク。さらに、テキストシーケンスは、TTS再生の生の音響信号と比較してサイズがはるかに小さく、再生が合成される前でも、デバイスとASRサーバーにすぐに送信できます。 
[概要]このシステムは、スマートスピーカーの音声認識とユーザーエクスペリエンスを大幅に向上させることができます。音響エコーキャンセレーションなどの代替アプローチと比較して、インターネット通信と遅延を削減するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-13">
        <br><font color="black">2020-08-13</font>
      </time>
    </span>
</section>
<!-- paper0: Input-independent Attention Weights Are Expressive Enough: A Study of
  Attention in Self-supervised Audio Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-04/eess.AS/paper_17.html">
      <font color="black">Input-independent Attention Weights Are Expressive Enough: A Study of
  Attention in Self-supervised Audio Transformers</font>
    </a>
  </h2>
  <font color="black">t-SNE、PCA、およびいくつかの観察の助けを借りて、自己監視オーディオトランスの注意の重みは4つの一般的なケースに分類できます。私たちのアプローチは、典型的な自己注意と同等のパフォーマンスを示していますが、両方で20％少ない時間を必要としますトレーニングと推論..これらのケースといくつかの分析に基づいて、特定の注意の重みのセットを使用してモデルを初期化することができます。 
[ABSTRACT]トランスフォーマーベースのモデルは、10種類の注意アルゴリズムに基づいています。これらの注意アルゴリズムを使用して、自己監視方式でモデルを事前トレーニングし、特徴抽出器として扱います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-09">
        <br><font color="black">2020-06-09</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
