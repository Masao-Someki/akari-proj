<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-10-30の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: GANs & Reels: Creating Irish Music using a Generative Adversarial
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.SD/paper_0.html">
      <font color="black">GANs & Reels: Creating Irish Music using a Generative Adversarial
  Network</font>
    </a>
  </h2>
  <font color="black">この論文では、反復成分のない生成的敵対的ネットワークを使用したアルゴリズムによるメロディ生成の方法を示します。ここでは、拡張畳み込みとタワーを備えたDC-GANアーキテクチャを使用して、連続情報を空間画像情報としてキャプチャし、アイルランドの伝統的なリールなどの固定長のメロディー形式。音楽の生成は、反復ニューラルネットワークを使用して正常に実行されました。モデルは、本物の響きのメロディーの作成に役立つシーケンス情報を学習します。 
[要約]リカレントニューラルネットワークを使用して紙の生成が正常に実行されました。モデルは、本物のサウンド情報の作成に役立つ情報を学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Progressive Voice Trigger Detection: Accuracy vs Latency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.SD/paper_1.html">
      <font color="black">Progressive Voice Trigger Detection: Accuracy vs Latency</font>
    </a>
  </h2>
  <font color="black">2段階のアーキテクチャを使用して、テストセットで検出された真のトリガーのわずか3％の決定を遅らせることで、本人拒否率を66％向上させることができますが、増加はごくわずかです。レイテンシー..ただし、毎回より多くのオーディオを聞くのを待つと、レイテンシーが増加します。プログレッシブボイストリガー検出を使用すると、明確なトリガー候補をすばやく受け入れることでレイテンシーと精度をトレードオフできますが、より多くのコンテキストを待って、より多くを受け入れるかどうかを決定します。限界的な例。 
[概要]この作業の主なアイデアは、トリガーフレーズの直後に続く単語の情報を活用することです。ただし、毎回より多くの音声で聞くのを待つと、待ち時間が長くなります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervised Pre-training Reduces Label Permutation Instability of
  Speech Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.SD/paper_2.html">
      <font color="black">Self-supervised Pre-training Reduces Label Permutation Instability of
  Speech Separation</font>
    </a>
  </h2>
  <font color="black">いくつかのタイプの自己監視タスクの中で、音声強調ベースの事前トレーニングタスクは、私たちの実験で大きな効果を示しています。正しいラベル順列を安定して選択する方法は、長年の問題です。さらに、事前トレーニング時間を考慮しても、より大きなバッチサイズを使用すると、パフォーマンスを低下させることなく、トレーニングプロセス全体をさらに短くすることができます。 
[概要]この論文では、ラベルの順列を安定させるために、自己教師あり事前トレーニングを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: SNR-Based Teachers-Student Technique for Speech Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.SD/paper_3.html">
      <font color="black">SNR-Based Teachers-Student Technique for Speech Enhancement</font>
    </a>
  </h2>
  <font color="black">提案手法を評価するために、公開データセットに基づいてSNRが-20dBから20dBのデータセットを構築しました。最終的に、学生モデルは高SNRと低SNRの両方で音声強調を実行できます。次に、別の教師を選択します。トレーニングデータのSNRに従って、学生モデルのトレーニングを監視するモデル。 
[概要]この問題に対処するために、snrベースの教師-学生の技術と時間-ドメインu-ネットを統合する方法。互いに一致しない複数の小さな範囲のsnrの下で教師モデルをテストします。特定のsnr範囲内で音声強調を十分に実行する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-29">
        <br><font color="black">2020-05-29</font>
      </time>
    </span>
</section>
<!-- paper0: The ins and outs of speaker recognition: lessons from VoxSRC 2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.SD/paper_4.html">
      <font color="black">The ins and outs of speaker recognition: lessons from VoxSRC 2020</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、チャレンジへの参加から学んだ教訓を共有しています。トレーニング済みモデルは、軽量モデルとシンプルなパイプラインを使用した既存のほとんどの作業に対する改善を示しています。この目的のために、強力なモデルをトレーニングできる効率的なトレーニングフレームワークを最適化します。限られた時間とリソース。 
[概要]この作業の目標は、これらの困難な環境で記録された発話の堅牢な話者認識です。限られた時間とリソースで強力なモデルをトレーニングできる効率的なトレーニングフレームワークを最適化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: UNetGAN: A Robust Speech Enhancement Approach in Time Domain for
  Extremely Low Signal-to-noise Ratio Condition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.SD/paper_5.html">
      <font color="black">UNetGAN: A Robust Speech Enhancement Approach in Time Domain for
  Extremely Low Signal-to-noise Ratio Condition</font>
    </a>
  </h2>
  <font color="black">このアプローチは、時間領域で直接動作するジェネレーターネットワークとディスクリミネーターネットワークで構成されます。パブリックベンチマークで低SNR条件（最大-20dB）でのUNetGANのパフォーマンスを評価します。ジェネレーターネットワークはUを採用しています。 -ネットのような構造であり、そのボトルネックに拡張畳み込みを採用しています。 
[概要]ジェネレータネットワークは、au-netのような構造を採用し、ボトルネックに拡張畳み込みを採用しています。結果は、音声品質が大幅に向上することを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: DeviceTTS: A Small-Footprint, Fast, Stable Network for On-Device
  Text-to-Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.SD/paper_6.html">
      <font color="black">DeviceTTS: A Small-Footprint, Fast, Stable Network for On-Device
  Text-to-Speech</font>
    </a>
  </h2>
  <font color="black">経験はWORLDとLPCNetボコーダーで行われます。DeviceTTSは、エンコーダーとデコーダーの間のブリッジとして期間予測子を利用して、Tacotronでの単語のスキップと繰り返しの問題を回避します。私たちが知る限り、DeviceTTSは実際のアプリケーションにおけるほとんどのデバイスのニーズ。 
[ABSTRACT] devicettsは、オンデバイスデバイス用に小さなフットプリント、高速、安定したネットワークを使用します。これらには、音声品質を向上させるために使用できる「devicetts」用のネットワークが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: The IQIYI System for Voice Conversion Challenge 2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.SD/paper_7.html">
      <font color="black">The IQIYI System for Voice Conversion Challenge 2020</font>
    </a>
  </h2>
  <font color="black">その中で、私たちの最良の結果は、タスク2の類似性評価であり、ASVベースの客観的評価で2番目、主観的評価で5番目です。次に、改良された韻律タコトロンモデルによってMel特徴が計算されます。 24kのサンプリングレートのオーディオではなく16kのオーディオを使用する場合、変換結果は自然さと類似性において比較的良好です。 
[概要]競技会では、各対象話者は70文です。たとえば、24kのサンプリングレートではなく16kの音声を使用する場合、各音声は2,000文であり、変換結果は比較的良好です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Audio Embeddings with User Listening Data for Content-based
  Music Recommendation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.SD/paper_8.html">
      <font color="black">Learning Audio Embeddings with User Listening Data for Content-based
  Music Recommendation</font>
    </a>
  </h2>
  <font color="black">提案されたシステムは、数百万のユーザーとトラックでテストされたコンテンツベースの音楽レコメンデーションで最先端のパフォーマンスを生み出します。また、音楽ジャンル分類タスクの機能としてオーディオ埋め込みを抽出します。新しいトラックについては、決定できます。トラックのオーディオ埋め込みとさまざまなユーザー埋め込みの類似性をそれぞれ計算することにより、推奨するユーザーの最適なグループ。 
[概要]新しいトラックの場合、トラックの音声埋め込みとユーザー埋め込みの類似性を計算することで、推奨する最適なユーザーグループを決定できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Recent Developments on ESPnet Toolkit Boosted by Conformer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.SD/paper_9.html">
      <font color="black">Recent Developments on ESPnet Toolkit Boosted by Conformer</font>
    </a>
  </h2>
  <font color="black">この作業の目的は、通常は高いリソースを必要とする最先端の研究環境を準備する負担を軽減することにより、研究コミュニティに貢献することです。私たちの実験は、さまざまなトレーニングのヒントと、さまざまなタスクでコンフォーマーによって得られる重要なパフォーマンス上の利点を明らかにします。 ..これらの結果は競争力があり、現在の最先端のTransformerモデルよりも優れています。 
[概要]幅広いエンドツーエンドの音声処理アプリケーションの結果。これらには、自動音声認識（asr）、音声翻訳（st）、音声ヒント（ss）が含まれます。これらの結果はオープンであるか、現在のモデルよりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Sub-Band Knowledge Distillation Framework for Speech Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.SD/paper_10.html">
      <font color="black">Sub-Band Knowledge Distillation Framework for Speech Enhancement</font>
    </a>
  </h2>
  <font color="black">モデルパラメータの数と計算の複雑さを増すことなく、学生モデルのパフォーマンスがさらに向上します。次に、教師モデルの指導の下で、すべてのサブバンドで機能する一般的なサブバンド拡張モデル（学生モデル）をトレーニングします。 。これらの教師モデルは、独自のサブバンドの処理に専念しています。 
[概要]メソッドを使用して、全周波数帯域を複数のサブバンドに探索します。サブバンドごとにエリートレベルのサブバンド拡張モデルを事前トレーニングします。教師モデルのガイダンスの下で、一般的なサブバンドをトレーニングします。 -バンド。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-29">
        <br><font color="black">2020-05-29</font>
      </time>
    </span>
</section>
<!-- paper0: ACCDOA: Activity-Coupled Cartesian Direction of Arrival Representation
  for Sound Event Localization and Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.SD/paper_11.html">
      <font color="black">ACCDOA: Activity-Coupled Cartesian Direction of Arrival Representation
  for Sound Event Localization and Detection</font>
    </a>
  </h2>
  <font color="black">ACCDOA表現により、単一のターゲットでSELDタスクを解決でき、2つの利点があります。目標とモデルサイズの増加のバランスを取る必要がないことです。ACCDOAベースのSELDシステムは、最先端のSELDよりも優れたパフォーマンスを発揮します。ローカリゼーションと場所に依存する検出の観点からのシステム..ニューラルネットワーク（NN）ベースの方法は、サウンドイベントのローカリゼーションと検出（SELD）で高いパフォーマンスを示します。 
[ABSTRACT]従来のnnベースの方法では、サウンドイベントの検出に2つのブランチ、sedターゲットと到着方向（doa）ターゲットを使用します。各タスク専用の2つのネットワークを使用すると、ネットワーク表現が増加します。したがって、accdoa表現を使用すると解決できます。単一のターゲットを持つseldタスク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Playing a Part: Speaker Verification at the Movies -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.SD/paper_12.html">
      <font color="black">Playing a Part: Speaker Verification at the Movies</font>
    </a>
  </h2>
  <font color="black">話者認証と識別パフォーマンスの両方がこの新しいデータで急激に低下することを示し、ドメイン間でモデルを転送する際の課題を示しています。そして最後に（iii）単純なドメイン適応パラダイムがパフォーマンスを改善することを示しますが、まだ改善の余地があります。VoxMoviesにはさまざまな感情、アクセント、背景ノイズを伴う発話が含まれているため、インタビュースタイルとはまったく異なるドメインで構成されます。 VoxCelebなどの現在の話者認識データセットでの感情的に穏やかな発話。 （ii）多数のドメイン適応評価セットを提供し、これらの評価ペアで最先端の話者認識モデルのパフォーマンスをベンチマークします。この作業の目的は、で人気のある話者認識モデルのパフォーマンスを調査することです。映画のスピーチセグメント。俳優がキャラクターを演じるために意図的に声を偽装することがよくあります。 
[概要]約4000のムービークリップから856のIDの音声を含む、斬新でやりがいのある話者認識データセットを収集します。この新しいデータで両方の話者検証を行い、モデルをキャラクター間で転送する際の課題を示しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: FullSubNet: A Full-Band and Sub-Band Fusion Model for Real-Time
  Single-Channel Speech Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.SD/paper_13.html">
      <font color="black">FullSubNet: A Full-Band and Sub-Band Fusion Model for Real-Time
  Single-Channel Speech Enhancement</font>
    </a>
  </h2>
  <font color="black">サブバンドモデルは正反対です。その入力は、1つの周波数といくつかのコンテキスト周波数で構成されます。これらの2つのタイプのモデルには、異なる特性があります。 
[ABSTRACT]フルバンドとサブバンドは、フルバンドとノイズの多いビーコン機能を入力するモデルを指します。提案されたフルサブネットは、実際のトレーニングを使用して、2つのタイプのモデルの利点を統合します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-Supervised Speech Recognition via Graph-based Temporal
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.SD/paper_14.html">
      <font color="black">Semi-Supervised Speech Recognition via Graph-based Temporal
  Classification</font>
    </a>
  </h2>
  <font color="black">新しく提案されたグラフベースの時間分類（GTC）目標は、疑似ラベルのN-bestリストから生成されるWFSTベースの監視による自己トレーニングに適用されます。ただし、N-bestリストの代替ASR仮説ラベルなしの音声発話に対してより正確なラベルを提供し、シードASRモデルの不確実性も反映できます。このセットアップでは、GTCを使用して、CTCと同様に時間的アラインメントだけでなく、ラベルアラインメントも学習して最適な疑似-加重グラフからのラベルシーケンス。 
[概要]このアプローチの有効性は、疑似ラベルの精度に大きく依存します。ただし、それ以外の場合は、1-最良のasrマージンのみが使用されます。代わりに、Tシャツに基づくTシャツシステムから学習するために使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Emformer: Efficient Memory Transformer Based Acoustic Model For Low
  Latency Streaming Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.SD/paper_15.html">
      <font color="black">Emformer: Efficient Memory Transformer Based Acoustic Model For Low
  Latency Streaming Speech Recognition</font>
    </a>
  </h2>
  <font color="black">強力なベースライン拡張メモリトランスフォーマー（AM-TRF）と比較すると、Emformerはトレーニングのスピードアップが4.6ドル倍になり、デコードで相対リアルタイムファクター（RTF）が18ドル％減少し、テストクリーンとWERの相対WERが17ドル減少します。 test-otherで$ 9 \％$ .. Emformerは、トレーニングで並列化されたブロック処理を適用して、低遅延モデルをサポートします。平均遅延が80ミリ秒の低遅延シナリオの場合、EmformerはテストクリーンでWER $ 3.01 \％$を達成します。テストで$ 7.09 \％$-その他。 
[概要]平均レイテンシが80ミリ秒の低レイテンシシナリオの場合、emformerは$ 2. 50-クリーン、テストで$ 5. 62 /％$-その他。同じレイテンシシナリオで、emformerはwer $ 3.01を達成します。 7.999ドルとテストで$-その他</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Domain Generalization for Medical Imaging Classification with
  Linear-Dependency Regularization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_0.html">
      <font color="black">Domain Generalization for Medical Imaging Classification with
  Linear-Dependency Regularization</font>
    </a>
  </h2>
  <font color="black">特定のデバイスベンダーまたは患者集団によってキャプチャされたデータ）は、別の分布のデータに一般化できない場合があります。このペーパーでは、の分野でディープニューラルネットワークの一般化機能を改善するためのシンプルで効果的なアプローチを紹介します。医用画像分類..2つの挑戦的な医用画像分類タスクの実験結果は、私たちの方法が最先端のベースラインと比較してより優れたクロスドメイン一般化機能を達成できることを示しています。 
[概要]最近の高度なモデルでは、トレーニングに十分なデータセットにアクセスする必要があります。単純なデバイスベンダーまたは患者集団によってキャプチャされたデータは、別のディストリビューションでデータに一般化できない場合があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-27">
        <br><font color="black">2020-09-27</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Autofocus for Synthetic Aperture Sonar -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_1.html">
      <font color="black">Deep Autofocus for Synthetic Aperture Sonar</font>
    </a>
  </h2>
  <font color="black">私たちの定式化には、非反復的（したがって高速）であり、他のぼけ除去深層学習方法で頻繁に必要とされるグラウンドトゥルースフォーカス-デフォーカス画像ペアを必要としないという利点があります。私たちの結果は、ディープオートフォーカスが知覚的に同じくらい良い画像を生成できることを示していますベンチマークの反復手法ですが、計算コストが大幅に低くなります。ディープオートフォーカスと呼ばれるディープネットワークを使用して、自己監視型の位相エラー推定タスクとして問題を定式化します。 
[概要]これらのアルゴリズムは通常、反復的でメトリックです-画像のシャープネスメトリックを最適化しようとするという点に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Maximum a posteriori signal recovery for optical coherence tomography
  angiography image generation and denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_2.html">
      <font color="black">Maximum a posteriori signal recovery for optical coherence tomography
  angiography image generation and denoising</font>
    </a>
  </h2>
  <font color="black">このアルゴリズムは、確率的OCTA信号モデルと最尤推定に関する以前の研究に基づいています。結果は、ピーク信号対雑音比と構造的類似性の大幅な改善を示しています。繰り返しの光コヒーレンストモグラフィー（OCT）スキャンに基づいて、強度が変化します。時間の経過とともに観察され、OCTA画像データの計算に使用されます。 
[ABSTRACT]アルゴリズムは、繰り返される光コヒーレンストモグラフィー（oct）スキャンに基づいています。強度の変化は時間の経過とともに観察され、オクタ画像データの計算に使用されます。新しいオクタ画像生成およびノイズ除去アルゴリズムに発展する可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: An automated and multi-parametric algorithm for objective analysis of
  meibography images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_3.html">
      <font color="black">An automated and multi-parametric algorithm for objective analysis of
  meibography images</font>
    </a>
  </h2>
  <font color="black">マイボーム腺造影は、眼科医がマイボーム腺機能障害（MGD）の評価と診断を支援するために使用する非接触画像技術です。アルゴリズムの完全なアーキテクチャは、次の3つのステップに分けることができます。（1）足根結膜領域のセグメンテーション関心領域（ROI）; （2）ROI内の腺のセグメンテーションと識別。 （3）新しく定義された腺直径変形指数（DI）、腺屈曲度指数（TI）、および腺信号指数（SI）を含む定量的マルチパラメトリック分析。アルゴリズムの実現可能性は、典型的なmeibograhy画像の分析で示されます。 
[ABSTRACT]マイボグラフィー画像の人工的な適格性分析は、再現性と効率の低下につながる可能性があります。画像の客観的かつ定量的な分析のための自動化されたマルチパラメトリックアルゴリズムを開発しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Beyond cross-entropy: learning highly separable feature distributions
  for robust and accurate classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_4.html">
      <font color="black">Beyond cross-entropy: learning highly separable feature distributions
  for robust and accurate classification</font>
    </a>
  </h2>
  <font color="black">他のフレームワークとは異なり、提案された方法は、クラスが線形分離可能であるように、潜在空間内のターゲット分布への入力クラスのマッピングを学習します。ただし、深い分類器は、わずかな摂動という点で、敵対攻撃に対して非常に脆弱であることが知られています。入力の数が多いと、エラーが発生しやすくなります。敵対的な攻撃に堅牢性を提供することは、特に多数のクラスが関係する問題では、通常、精度の低下を犠牲にして行われるため、非常に困難な作業です。 
[ABSTRACT]ディープ分類器は敵対攻撃に対して非常に脆弱であることが知られていますが、入力に関連する小さな摂動は簡単にエラーにつながる可能性があります。これは、ディープロバストマルチクラス分類器をトレーニングするための新しいアプローチです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Sea-Net: Squeeze-And-Excitation Attention Net For Diabetic Retinopathy
  Grading -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_5.html">
      <font color="black">Sea-Net: Squeeze-And-Excitation Attention Net For Diabetic Retinopathy
  Grading</font>
    </a>
  </h2>
  <font color="black">この問題を軽減するために、SEA-Netと呼ばれる堅牢なDRグレーディングのための新しい深層学習アーキテクチャが提案されています。このアーキテクチャでは、空間的注意とチャネル注意が交互に実行され、相互にブーストされて、分類パフォーマンスが向上します。重症度レベル間の微妙な違いにより、従来の方法を使用して重要な特徴をキャプチャすることは困難です。網膜画像に基づく自動DRグレーディングは、治療計画に優れた診断および予後の価値を提供します。 
[概要]糖尿病性網膜症（dr）は糖尿病の合併症であり、失明につながる可能性があります。重症度レベルの微妙な違いにより、従来の方法で重要な特徴を捉えることが困難になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: What can we learn from gradients? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_6.html">
      <font color="black">What can we learn from gradients?</font>
    </a>
  </h2>
  <font color="black">入力再構成の理論的限界を調査し、出力層のノード数に関係なく、\ textbf {one}隠れノードを持つ完全に接続されたニューラルネットワークが\ textbf {single}入力画像を再構成するのに十分であることを示します。次に、この結果をサイズBのミニバッチで平均化された勾配に一般化します。畳み込みニューラルネットワークの場合、最初の畳み込み層に必要なフィルターの数は、バッチサイズBによって決定されますが、この場合は、入力幅dとフィルター後の幅$ d ^ {&#39;} $も$ h =（\ frac {d} {d ^ {&#39;}}）^ 2BC $の役割を果たします。ここで、Cは入力のチャネル番号です。 
[ABSTRACT]研究者は、隠れノードを持つ完全に接続されたニューラルネットワークはミニバッチを再構築するのに十分であると言います。完全なミニバッチは、隠れユニットの数がbを超える場合、完全に接続されたネットワークで再構築できます。たとえば、ネットワークは、出力層のノードの数に関係なく、画像を再構築できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: A Helmholtz equation solver using unsupervised learning: Application to
  transcranial ultrasound -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_7.html">
      <font color="black">A Helmholtz equation solver using unsupervised learning: Application to
  transcranial ultrasound</font>
    </a>
  </h2>
  <font color="black">ネットワークは、物理ベースの損失関数と、完全に監視されていないトレーニングを伴う理想的な音速分布のセットを使用してトレーニングされます（真のソリューションの知識は必要ありません）。リアルタイム予測へのステップとして、現在の作業では、 2Dの不均一ヘルムホルツ方程式の高速反復ソルバーは、完全に学習されたオプティマイザーを使用して開発されています。経頭蓋超音波療法は、脳障害の非侵襲的治療にますます使用されています。 
[概要]軽量ネットワークアーキテクチャは、学習された2D状態に基づいています。学習されたオプティマイザは、テストセットで優れたパフォーマンスを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: ProCAN: Progressive Growing Channel Attentive Non-Local Network for Lung
  Nodule Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_8.html">
      <font color="black">ProCAN: Progressive Growing Channel Attentive Non-Local Network for Lung
  Nodule Classification</font>
    </a>
  </h2>
  <font color="black">肺結節分類のための新しいProgressiveGrowing Channel Attentive Non-Local（ProCAN）ネットワークを提案します。さらに、提案した方法の各新しいコンポーネントの寄与と効果を分析するために、広範なアブレーション研究を実施しました。結果は、ProCANがモデルは最先端の方法を上回り、LIDC-IDRIデータセットで98.05％のAUCと95.28％の精度を達成します。 
[要約]提案された方法は、3つの異なる側面からこの課題に対処します。それは、根粒のサイズと不均一な外観の大きな変動に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Point Cloud Attribute Compression via Successive Subspace Graph
  Transform -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_9.html">
      <font color="black">Point Cloud Attribute Compression via Successive Subspace Graph
  Transform</font>
    </a>
  </h2>
  <font color="black">実験結果により、提案されたSSGT法は、以前の領域適応ハール変換（RAHT）法よりも優れたRDパフォーマンスを提供することが示されています。変換は、八分木のリーフノードからルートノードまでの大きな点群に再帰的に適用されます。表現された部分空間は、最小のものから点群全体に連続的に拡張されます。部分空間を記述し、正規化されたグラフラプラシアンに基づいてグラフフーリエ変換を定義する自己ループを備えた重み付きグラフを設計します。 
[概要]変換は、リーフノードから八分木のルートまでの大きな点群雲に適用されます。この変換は、点群グラフの作成に使用された変更に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Thermodynamic Cost of Edge Detection in Artificial Neural
  Network(ANN)-Based Processors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_10.html">
      <font color="black">Thermodynamic Cost of Edge Detection in Artificial Neural
  Network(ANN)-Based Processors</font>
    </a>
  </h2>
  <font color="black">得られた結果は、さまざまなプロセッサのタスクベースの基本的なエネルギー効率分析の比較の基礎を提供し、したがって、プロセッサのアーキテクチャレベルの記述と計算の物理学に基づく熱力学的コスト計算の研究に貢献します。セルラーアレイプロセッサ（CAP）のパフォーマンス改善を提案し、特殊用途プロセッサの消費の削減を示します。最後に、入力データ構造の結果としての消費の変化を計算し、情報のエネルギーコストに対するランダム性の影響を示します。処理。 
[ABSTRACT]人工ニューラルネットワーク（ann）ベースのann）は、エッジ検出タスクを実行するようにトレーニングされています。システムは、一般的な特定のタスク用にトレーニングされています。目的のプロセッサ。結果は、特定のタスク用にトレーニングされたannネットワークの利点を明らかにします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br><font color="black">2020-03-18</font>
      </time>
    </span>
</section>
<!-- paper0: ProxIQA: A Proxy Approach to Perceptual Optimization of Learned Image
  Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_11.html">
      <font color="black">ProxIQA: A Proxy Approach to Perceptual Optimization of Learned Image
  Compression</font>
    </a>
  </h2>
  <font color="black">この最適化フレームワークを適用して、エンドツーエンドの最適化された画像圧縮ネットワークをトレーニングする方法を実験的に示します。既存のディープ画像圧縮モデルの上に構築することで、最大31ドルのビットレート削減を示すことができます。指定された知覚品質（VMAF）レベルが与えられた場合のMSE最適化に対する％$ .. $ \ ell_p $ $（p = 1,2）$ノルムの使用は、その単純さと分析のために、ニューラルネットワークの損失の測定を主に支配してきました。プロパティ。 
[概要]実験的な25億ドルのモデルを使用して、視覚情報の損失を評価できます。これらの単純な基準は、人間の知覚と一致していません。これにより、知覚モデルを模倣するプロキシネットワークが作成されます。ネットワークの損失層</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-19">
        <br><font color="black">2019-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: Genetic U-Net: Automatically Designing Lightweight U-shaped CNN
  Architectures Using the Genetic Algorithm for Retinal Vessel Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_12.html">
      <font color="black">Genetic U-Net: Automatically Designing Lightweight U-shaped CNN
  Architectures Using the Genetic Algorithm for Retinal Vessel Segmentation</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案された方法が3つの公開データセット、DRIVE、CHASE_DB1、STAREの既存の方法よりも優れていることを示しています。さらに、提案された方法によって得られたアーキテクチャは、最先端のモデルよりも軽量ですが堅牢です。網膜血管セグメンテーションの深層学習に基づく以前の多くの研究は、U字型の畳み込み神経ネットワーク（CNN）を手動で設計することにより、有望なパフォーマンスを達成しています。 
[概要] cnnsの手動設計は遺伝的アルゴリズムに基づいています。遺伝的アルゴリズムを使用して優れたアーキテクチャを検索します。この方法は、最先端のモデルよりも軽量ですが堅牢です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Novel Digital Camera with the PCIe Interface -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_13.html">
      <font color="black">Novel Digital Camera with the PCIe Interface</font>
    </a>
  </h2>
  <font color="black">このアーキテクチャでは、画像ストリームをカメラからデータ処理ユニットに直接転送できるため、オーバーヘッドが大幅に削減され、パフォーマンスが向上します。これは、複数のイメージングデバイスからのデータストリームの処理中に特に重要です。テラビット/秒..制限は、リアルタイムで動作する制御または保護システムにとってさらに重要です。 
[概要]標準的な画像診断システムは、光学セットアップ、デジタルカメラ、フレームグラバー、画像処理CPU、およびデータ分析ツールで構成されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Identification of complex mixtures for Raman spectroscopy using a novel
  scheme based on a new multi-label deep neural network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_14.html">
      <font color="black">Identification of complex mixtures for Raman spectroscopy using a novel
  scheme based on a new multi-label deep neural network</font>
    </a>
  </h2>
  <font color="black">MDNNモデルは、パーム油中の物質から調製されたサンプルから収集されたデータを使用してトレーニング、検証、およびテストされました。提案されたモデルは、特徴抽出を加速し、グローバル平均プール層を使用して特徴グラフを拡張します。シグモイド関数は、モデルの最後のレイヤー。 
[概要]提案されたスキームは、一定のウェーブレット変換（cwt）と複雑な混合物を分類するためのディープネットワークに基づいています。マルチラベルディープニューラルネットワークモデル（mdnn）を使用して、材料を分類します。シグモイド関数は、モデルの最後のレイヤー</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: InterFaceGAN: Interpreting the Disentangled Face Representation Learned
  by GANs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_15.html">
      <font color="black">InterFaceGAN: Interpreting the Disentangled Face Representation Learned
  by GANs</font>
    </a>
  </h2>
  <font color="black">次に、異なるセマンティクス間の相関について詳細な調査を行い、部分空間射影を介してそれらをより適切に解きほぐし、属性操作をより正確に制御できるようにします。まず、GANが潜在空間のいくつかの線形部分空間でさまざまなセマンティクスを学習することを発見しました。 。これらの部分空間を特定した後、モデルを再トレーニングすることなく、対応する顔の属性を現実的に操作できます。 
[概要]最先端のガンモデルによって学習された解きほぐされた顔の表現を解釈し、潜在空間における顔のセマンティクスの特性を研究するために、インターフェースガンと呼ばれるフレームワークを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-18">
        <br><font color="black">2020-05-18</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring Generative Adversarial Networks for Image-to-Image Translation
  in STEM Simulation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_16.html">
      <font color="black">Exploring Generative Adversarial Networks for Image-to-Image Translation
  in STEM Simulation</font>
    </a>
  </h2>
  <font color="black">ディープラーニングモデルのGenerativeAdversarial Network（GAN）を使用すると、最良の結果が得られ、同じデータセットの以前の回帰モデルと同様の精度レベルで実行されることがわかります。次に、結果を回帰法の結果と比較します。その他畳み込み法などの線形イメージングモデルに基づくシミュレーション方法は、はるかに高速ですが、アプリケーションで使用するには不正確すぎます。このプロジェクトの
[ABSTRACT]データはこのgithubシミュレーションにあります。データは他のシミュレーション方法からのデータを理解するために使用できます。これらのデータは分析やデータにも使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Recurrent Neural Networks for video object detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_17.html">
      <font color="black">Recurrent Neural Networks for video object detection</font>
    </a>
  </h2>
  <font color="black">この調査では、オブジェクト検出に時間的コンテキストを含めることの利点など、比較した方法の一般的な結果を示し、ビデオオブジェクト検出ネットワークの結論とガイドラインを示しています。たとえば、自動運転など、分類を行う必要のある実際のデータを自動運転する多くのアプリケーションの場合はビデオです。異なるフレームの特徴マップを反復ユニットにフィードする機能ベースのメソッド、クラス確率を持つ境界ボックスを反復ユニットにフィードするボックスレベルのメソッド、およびフローネットワークを使用するメソッドは異なります。 
[概要]分類が必要な実際のデータはビデオです。たとえば、自動運転、実際の情報はビデオです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: A comparison of automatic multi-tissue segmentation methods of the human
  fetal brain using the FeTA Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_18.html">
      <font color="black">A comparison of automatic multi-tissue segmentation methods of the human
  fetal brain using the FeTA Dataset</font>
    </a>
  </h2>
  <font color="black">4つの研究グループが参加し、合計10のアルゴリズムを提出し、自動アルゴリズムの開発に対するデータベースの利点を実証しました。正常な胎児と先天性の胎児の両方の神経発達を完全に理解するには、発達中のヒト胎児の脳を定量的に分析することが重要です。障害..ここでは、妊娠年齢（20〜33週）の範囲にわたる50の手動でセグメント化された病理学的および非病理学的胎児磁気共鳴脳容積再構成の公開されているデータベースを7つの異なる組織カテゴリ（外部脳脊髄液、灰色物質、白質、脳室、小脳、深い灰色の物質、脳幹/脊髄）。 
[概要]これらは、この分析を容易にするために必要です。自動多組織胎児脳。これらのアルゴリズムには、セグメント化された胎児脳のオープンデータベースが必要です。これらには、理解するために人間の組織の範囲を謝罪および分析することが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Convolutional Neural Networks for Global Human Settlements Mapping from
  Sentinel-2 Satellite Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_19.html">
      <font color="black">Convolutional Neural Networks for Global Human Settlements Mapping from
  Sentinel-2 Satellite Imagery</font>
    </a>
  </h2>
  <font color="black">人間の居住地の空間的に一貫性のある最新のマップは、特にますます都市化が進む世界の時代において、都市化と持続可能性に関連するポリシーに対処するために重要です。コペルニクス地球観測プログラムのオープンで無料のSentinel-2データの可用性は提供します世界規模での人間の居住地の壁から壁へのマッピングの新しい機会。このペーパーでは、のグローバルコンポジットから10mの空間解像度で市街地を完全に自動抽出するためのディープラーニングベースのフレームワークを紹介します。 Sentinel-2画像：構築領域のピクセル単位の画像分類のための単純な畳み込みニューラルネットワークアーキテクチャに基づいたマルチニューロモデリング手法が開発されています。提案されたモデルのコア機能は、サイズ5 x5ピクセルの画像パッチです。 Sentinel-2画像からの市街地と、合計1,448,578のトレーニング可能なパラメーターと4つの2D畳み込み層と2つの平坦化された軽量トポロジーを記述するのに適していますレイヤー。グローバルSentinel-2イメージコンポジットへのモデルの展開により、2018年の参照年の市街地に関する最も詳細で完全なマップレポートが提供されます。建物のフットプリントの独立した参照データセットによる結果の検証世界中の277のサイトが、提案されたフレームワークによって生成されたビルドアップレイヤーの信頼性とモデルの堅牢性を確立しています。 
[概要]人間の地図地図地図は、建物の建物のあり方を形作るのに役立ちました。建物のプログラムは、人間よりも成功しています。13歳は建物システムの中心です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-05">
        <br><font color="black">2020-06-05</font>
      </time>
    </span>
</section>
<!-- paper0: FlatNet: Towards Photorealistic Scene Reconstruction from Lensless
  Measurements -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_20.html">
      <font color="black">FlatNet: Towards Photorealistic Scene Reconstruction from Lensless
  Measurements</font>
    </a>
  </h2>
  <font color="black">FlatNetは、2つの段階で構成されます。（1）フォワードモデル定式化内のパラメーターを学習することによって測定を中間再構成の空間にマッピングする反転段階と、（2）この中間再構成の知覚品質を向上させる知覚強化段階です。 $ \ textit {FlatNet} $と呼ばれる私たちのアプローチは、カメラのフォワードモデルの定式化が知られているマスクベースのレンズレスカメラから高品質のフォトリアリスティック画像を再構築するためのフレームワークを規定します。広範な実験を実行することにより、高品質の再構成を示します。 2つの異なるタイプのレンズレスプロトタイプを使用する実際の困難なシーンで。1つは分離可能なフォワードモデルを使用し、もう1つはより一般的な分離不可能なクロップドコンボリューションモデルを使用します。 
[概要]レンズレスカメラは、多重化された測定から画像を復元するアルゴリズムに依存しています。これらは、エスカレーションベースの再構成アプローチに基づいており、レンズレス再構成の画質が桁違いに向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Self-Supervised Methods for Medical Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_21.html">
      <font color="black">3D Self-Supervised Methods for Medical Imaging</font>
    </a>
  </h2>
  <font color="black">各タスクで、データ効率、パフォーマンス、収束速度の向上を評価します。実験では、3Dタスクを使用してモデルを事前トレーニングすると、トレーニングと比較して、より強力なセマンティック表現が得られ、ダウンストリームタスクをより正確かつ効率的に解決できることが示されています。モデルを最初から作成し、2Dスライスで事前トレーニングするまで。複数のアプリケーション分野で成功を収めた後、自己教師あり学習方法が最近注目を集めています。 
[概要]開発されたアルゴリズムは、3Dコントラスト予測コーディング、3D回転予測、3Dジグソーパズル、相対3Dパッチ位置、および3D模範ネットワークです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-06">
        <br><font color="black">2020-06-06</font>
      </time>
    </span>
</section>
<!-- paper0: A Novel Fast 3D Single Image Super-Resolution Algorithm -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_22.html">
      <font color="black">A Novel Fast 3D Single Image Super-Resolution Algorithm</font>
    </a>
  </h2>
  <font color="black">特に、提案された3Dデシメーション演算子の分解手法により、Tikhonov正則化の簡単な実装が可能になり、さらに、全変動などの他の正則化関数を考慮に入れて、最先端の計算コストを実現できます。実行された数値実験は、提案されたアプローチが既存の3D SRメソッドよりも優れていることを示しました。主な貢献は、周波数領域での基礎となる特性に基づいて、関連する間引き演算子とブラー演算子を同時に処理する元の方法にあります。 。 
[要約]提案されたアプローチにより、オペレーターは、周波数領域での基礎となる特性に基づいて、関連する間引き演算子とぼかし演算子を同時に処理できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Identifying safe intersection design through unsupervised feature
  extraction from satellite imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_23.html">
      <font color="black">Identifying safe intersection design through unsupervised feature
  extraction from satellite imagery</font>
    </a>
  </h2>
  <font color="black">これは、3方向交差点よりも4方向交差点でより頻繁なハード加速イベント（車両あたり）、T交差点での比較的低いハード減速頻度、およびラウンドアバウトでの一貫した低い平均速度を示しました。オーストラリアのテレマティクスデータセットは、インフラストラクチャ設計を運転行動にリンクしました。 6600万キロメートルの運転中にキャプチャされました。全体として、ドメイン固有の特徴抽出により、より安全な運転行動をもたらし、道路の外傷を減らす可能性のあるインフラストラクチャの改善を特定できました。 
[概要]この記事では、大国のすべてのエリアの設計を体系的に分析する最初の研究を紹介しました。これは、航空写真とディープラーニングに基づいています。オートエンコーダーは、交差点のタイプ、サイズ、サイズなど、高レベルの特徴を抽出しました。類似のデザインをクラスター化するために使用された形状、レーンマーキング、および複雑さ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Brain Tumor Segmentation Network Using Attention-based Fusion and
  Spatial Relationship Constraint -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_24.html">
      <font color="black">Brain Tumor Segmentation Network Using Attention-based Fusion and
  Spatial Relationship Constraint</font>
    </a>
  </h2>
  <font color="black">マルチモーダル脳腫瘍セグメンテーションチャレンジ2020（BraTs2020）のテストセットで私たちの方法を評価します。さらに、腫瘍のサブ領域間の空間的関係が比較的固定されているという事実に触発されました。腫瘍コアでは、腫瘍の異なるサブ領域間の関係を制約するために空間損失を提案します。具体的には、サブブランチはマルチモーダル画像から異なる腫瘍の特徴をキャプチャするために使用されますが、メインブランチでは、マルチモーダル機能を効果的に集約するための空間チャネル融合ブロック（SCFB）。 
[概要]腫瘍の複雑な外観と曖昧な輪郭は困難です。これは、腫瘍の複雑な画像と曖昧な輪郭によるものです。この方法では、0。8764、0.52、0。8243、0.773ダイススコアが達成されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: A Simple Local Minimal Intensity Prior and An Improved Algorithm for
  Blind Image Deblurring -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_25.html">
      <font color="black">A Simple Local Minimal Intensity Prior and An Improved Algorithm for
  Blind Image Deblurring</font>
    </a>
  </h2>
  <font color="black">次に、新しいアルゴリズムは、ブレ除去でPMPのスパース性を効率的に活用するように設計されています。これにより、既存のアルゴリズムでの非厳密な近似ソリューションを回避しながら、計算効率を大幅に向上させます。極端なチャネルの事前、および局所的な最大勾配の事前は、有望な効果を示しています。 
[ABSTRACT] deblur-鮮明な画像のpmpは、ぼやけた画像のpmpよりもはるかに密度が高くなります。新しい方法では、半2次分割アルゴリズムを直接使用するのではなく、pmpにスパース性を柔軟に課します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-16">
        <br><font color="black">2019-06-16</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Accurate Entropy Model with Global Reference for Image
  Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.IV/paper_26.html">
      <font color="black">Learning Accurate Entropy Model with Global Reference for Image
  Compression</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案されたモデルが業界のほとんどの最先端の方法のレート歪み性能を上回っていることを示しています。提案された方法は、デコードされた潜在性をスキャンし、次に、分布推定を支援するために最も関連性のある潜在性を見つけます。現在の潜在性..この作業の副産物は、パフォーマンスをさらに向上させる平均シフトGDNモジュールの革新です。 
[概要]以前のメソッドはハイパープライアとローカルコンテキストを組み合わせます。既存のメソッドはハイパープライアとローカルコンテキストで重要な役割を果たします。これは平均シフトgdnモジュールの革新です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-16">
        <br><font color="black">2020-10-16</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: An End to End Network Architecture for Fundamental Matrix Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_0.html">
      <font color="black">An End to End Network Architecture for Fundamental Matrix Estimation</font>
    </a>
  </h2>
  <font color="black">この論文では、ステレオ画像から直接基本行列を推定するための新しいエンドツーエンドネットワークアーキテクチャを紹介します。屋外と屋内の両方のデータセットで実施された実験は、このネットワークが従来の方法や以前の深層学習ベースの方法よりも優れていることを示していますさまざまなメトリックに対応し、パフォーマンスを大幅に向上させます。完全に機能するパイプラインを確立するために、画像内の対応の検索、異常な拒否の実行、基本行列の計算を担当するさまざまなディープニューラルネットワークがエンドツーエンドのネットワークアーキテクチャに統合されます。 
[概要] 24時間体制のネットワークアーキテクチャは、エンドツーエンドのネットワークアーキテクチャです。推定された基本行列の精度をより合理的に評価するために、視覚化結果との整合性が高い新しい評価指標を設計します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Generalization for Medical Imaging Classification with
  Linear-Dependency Regularization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_1.html">
      <font color="black">Domain Generalization for Medical Imaging Classification with
  Linear-Dependency Regularization</font>
    </a>
  </h2>
  <font color="black">医用画像のドメイン変動がある程度コンパクトであるという観察に動機付けられて、異なるドメインから収集された医療データ間で共有可能な情報をキャプチャするために、新しい線形依存正則化項を使用した変分エンコーディングを通じて代表的な特徴空間を学習することを提案します。 。この論文では、医用画像分類の分野で深部神経ネットワークの一般化能力を改善するためのシンプルで効果的なアプローチを紹介します。特定のデバイスベンダーまたは患者集団によってキャプチャされたデータは、一般化できない場合があります。別の分布のデータ。 
[概要]最近の高度なモデルでは、トレーニングに十分なデータセットにアクセスする必要があります。単純なデバイスベンダーまたは患者集団によってキャプチャされたデータは、別のディストリビューションでデータに一般化できない場合があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-27">
        <br><font color="black">2020-09-27</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Autofocus for Synthetic Aperture Sonar -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_2.html">
      <font color="black">Deep Autofocus for Synthetic Aperture Sonar</font>
    </a>
  </h2>
  <font color="black">私たちの定式化には、非反復的（したがって高速）であり、他のぼけ除去ディープラーニング方法で頻繁に必要とされるグラウンドトゥルースフォーカス-デフォーカス画像ペアを必要としないという利点があります。私たちの結果は、ディープオートフォーカスが知覚的に同じくらい良い画像を生成できることを示していますベンチマークの反復手法ですが、計算コストが大幅に低くなります。このレターでは、オートフォーカスの問題に対処するための機械学習、特に深層学習の可能性を示します。 
[概要]これらのアルゴリズムは通常、反復的でメトリックです-画像のシャープネスメトリックを最適化しようとするという点に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Minimalistic Attacks: How Little it Takes to Fool a Deep Reinforcement
  Learning Policy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_3.html">
      <font color="black">Minimalistic Attacks: How Little it Takes to Fool a Deep Reinforcement
  Learning Policy</font>
    </a>
  </h2>
  <font color="black">特に、次の3つの主要な設定を定義することにより、最小限の攻撃を調査します。（1）ブラックボックスポリシーアクセス：攻撃者はRLポリシーの入力（状態）と出力（アクション確率）にのみアクセスできます。 （2）分数状態の敵：数ピクセルのみが摂動され、極端な場合は単一ピクセルの敵です。 （3）戦術的に変化する攻撃：重要なフレームのみが戦術的に選択されて攻撃されます。3つの主要な設定に対応することで敵対攻撃を定式化し、4つの完全に訓練された状態を調べることで6つのAtariゲームでの効力を調査します。 -アートポリシー..最近の研究では、ニューラルネットワークベースのポリシーは敵対的な例によって簡単にだまされる可能性があることが明らかになっています。 
[概要]敵対者の生成に対してより制限的な見方をします。このホワイトペーパーでは、モデルの脆弱性の限界を探ります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br><font color="black">2019-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Maximum a posteriori signal recovery for optical coherence tomography
  angiography image generation and denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_4.html">
      <font color="black">Maximum a posteriori signal recovery for optical coherence tomography
  angiography image generation and denoising</font>
    </a>
  </h2>
  <font color="black">光コヒーレンストモグラフィー血管造影（OCTA）は、網膜および網膜下の血管系を画像化するための新規で臨床的に有望な画像診断法です。このアルゴリズムは、確率的OCTA信号モデルと最尤推定に関する以前の研究に基づいています。正規化のためのウェーブレット収縮は、6つの同時登録された単一のOCTAボリュームからマージされたOCTAグラウンドトゥルースボリュームと比較されました。 
[ABSTRACT]アルゴリズムは、繰り返される光コヒーレンストモグラフィー（oct）スキャンに基づいています。強度の変化は時間の経過とともに観察され、オクタ画像データの計算に使用されます。新しいオクタ画像生成およびノイズ除去アルゴリズムに発展する可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic joint damage quantification using computer vision and deep
  learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_5.html">
      <font color="black">Automatic joint damage quantification using computer vision and deep
  learning</font>
    </a>
  </h2>
  <font color="black">深層学習（DL）アルゴリズムを使用したコンピュータービジョン技術を使用して、低コストのカメラで関節損傷を正確、自律的、迅速に定量化するためのフレームワークを提案します。色のしきい値を使用した別の損傷定量化アルゴリズムを適用して、 3D再構成画像の損傷の表面積を計算します。トレーニングされたDLモデルは、オープンソース構造を使用して3D画像を再構成するために使用される一連のクエリ2D画像のピクセル単位のカラーマスキングジョイント損傷に使用されます。モーションアルゴリズムから。 
[ABSTRACT]ソフトウェアは、関節損傷のある鋸カットの画像をトレーニングするために使用されます。時間の経過に伴う損傷を評価および定量化することが重要です。結果は、フレームワークが76％のリコールと10％のエラーを達成することを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: An automated and multi-parametric algorithm for objective analysis of
  meibography images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_6.html">
      <font color="black">An automated and multi-parametric algorithm for objective analysis of
  meibography images</font>
    </a>
  </h2>
  <font color="black">アルゴリズムの完全なアーキテクチャは、次の3つのステップに分けることができます。（1）関心領域（ROI）としての足根結膜領域のセグメンテーション。 （2）ROI内の腺のセグメンテーションと識別。 （3）新しく定義された腺径変形指数（DI）、腺屈曲度指数（TI）、および腺信号指数（SI）を含む定量的マルチパラメトリック分析。Meibographyは、眼科医が支援するために使用する非接触イメージング技術です。メイボミアン腺機能障害（MGD）の評価と診断。自動アルゴリズムのパフォーマンスを評価するために、類似性指数（k）と、偽陽性率（r_P）および偽陰性率（r_N）を含むセグメンテーションエラーが計算されます。手動で定義されたグラウンドトゥルースと、15の典型的なマイボグラフィ画像のROIとメイボミアン腺の両方の自動セグメンテーションの間。 
[ABSTRACT]マイボグラフィー画像の人工的な適格性分析は、再現性と効率の低下につながる可能性があります。画像の客観的かつ定量的な分析のための自動化されたマルチパラメトリックアルゴリズムを開発しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Beyond cross-entropy: learning highly separable feature distributions
  for robust and accurate classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_7.html">
      <font color="black">Beyond cross-entropy: learning highly separable feature distributions
  for robust and accurate classification</font>
    </a>
  </h2>
  <font color="black">分布の平均値は、各クラスが他のすべてのクラスから同じ距離にあるように、シンプレックスの頂点を中心にしています。他のフレームワークとは異なり、提案された方法は、潜在的なターゲット分布への入力クラスのマッピングを学習します。クラスが線形分離可能であるような空間。ただし、深い分類器は、入力のわずかな摂動がエラーに簡単につながる可能性があるという点で、敵対的な攻撃に対して非常に脆弱であることが知られています。 
[ABSTRACT]ディープ分類器は敵対攻撃に対して非常に脆弱であることが知られていますが、入力に関連する小さな摂動は簡単にエラーにつながる可能性があります。これは、ディープロバストマルチクラス分類器をトレーニングするための新しいアプローチです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Sea-Net: Squeeze-And-Excitation Attention Net For Diabetic Retinopathy
  Grading -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_8.html">
      <font color="black">Sea-Net: Squeeze-And-Excitation Attention Net For Diabetic Retinopathy
  Grading</font>
    </a>
  </h2>
  <font color="black">この問題を軽減するために、SEA-Netと呼ばれる堅牢なDRグレーディングのための新しい深層学習アーキテクチャが提案されています。このアーキテクチャでは、空間的注意とチャネル注意が交互に実行され、相互にブーストされて、分類パフォーマンスが向上します。重大度レベル間の微妙な違いにより、従来の方法を使用して重要な機能をキャプチャすることは困難です。実験結果は、提案されたアーキテクチャの有効性を示しています。 
[概要]糖尿病性網膜症（dr）は糖尿病の合併症であり、失明につながる可能性があります。重症度レベルの微妙な違いにより、従来の方法で重要な特徴を捉えることが困難になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Financial ticket intelligent recognition system based on deep learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_9.html">
      <font color="black">Financial ticket intelligent recognition system based on deep learning</font>
    </a>
  </h2>
  <font color="black">このシステムの実用的な価値は、財務会計業務における深層学習技術に有益な試みを行う商用アプリケーションでテストされています。現在、システムは194種類の財務チケットを認識でき、自動反復最適化メカニズムを備えています。つまり、申請時間の増加に伴い、システムでサポートされるチケットの種類が増え続け、認識の精度が向上し続けることを意味します。金融チケット（または請求書、請求書など）の発行の急速な成長に直面しています。 。
[概要]財務会計システムは、財務会計士の銀行にますます負担をかける可能性があります。システムは、人々が自分の財務を理解できる必要があります。システムは、財務会計などの問題を解決するためにも使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Automodulators -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_10.html">
      <font color="black">Deep Automodulators</font>
    </a>
  </h2>
  <font color="black">オートモジュレーターは、デコーダー操作のデータフローをその統計的特性から切り離し、潜在ベクトルを使用して前者を後者によって変調します。デコーダー層の相互解きほぐしのための原理的なアプローチを使用します。焦点はランダムサンプリングにありました。対応する自動エンコーダは、実際の入力画像で動作する可能性があります。 
[概要]オートモジュレーターのバリエーションは、画像アプリケーションやその他のデータドメインの有用な構成要素になると期待しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-21">
        <br><font color="black">2019-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Collaborative Method for Incremental Learning on Classification and
  Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_11.html">
      <font color="black">Collaborative Method for Incremental Learning on Classification and
  Generation</font>
    </a>
  </h2>
  <font color="black">そのコンポーネントの1つとして、トレーニングデータと比較して多様性の高い画像を生成できる生成モデルincGANも紹介します。データ不足の厳しい環境下で、ICLASは分類と生成ネットワークを段階的にトレーニングします。ICLASは両方をトレーニングするためネットワークでは、私たちのアルゴリズムは複数回の増分クラス学習を実行できます。 
[概要]この論文では、属性共有（iclas）を使用した増分クラス学習のための新しいアルゴリズムを紹介します。多数のタスクの実験により、アルゴリズムの利点が急速に実証されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Night vision obstacle detection and avoidance based on Bio-Inspired
  Vision Sensors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_12.html">
      <font color="black">Night vision obstacle detection and avoidance based on Bio-Inspired
  Vision Sensors</font>
    </a>
  </h2>
  <font color="black">最後に、非同期適応衝突回避（AACA）アルゴリズムが適用され、効果的な回避が行われます。検出された各オブジェクトの深さは、LC-Harrisを利用して抽出された2D特徴を三角測量することによって計算されます。イベントカメラは、高ダイナミックレンジで高出力時間レートで非同期にイベントをトリガーします。最大120 $ dB $の。 
[ABSTRACT]イベントカメラは、最大120の高ダイナミックレンジで高出力時間レートで非同期にイベントをトリガーします。検出された各オブジェクトの深さは、lc-harrisを利用して抽出された2D特徴を三角測量することによって計算されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: ProCAN: Progressive Growing Channel Attentive Non-Local Network for Lung
  Nodule Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_13.html">
      <font color="black">ProCAN: Progressive Growing Channel Attentive Non-Local Network for Lung
  Nodule Classification</font>
    </a>
  </h2>
  <font color="black">提案された方法は、3つの異なる側面からこの課題に対処します。最初に、チャネルごとの注意機能を追加することにより、非ローカルネットワークを強化します。さらに、の各新しいコンポーネントの寄与と効果を分析するために、広範なアブレーション研究を実施しました。私たちの提案した方法。 
[要約]提案された方法は、3つの異なる側面からこの課題に対処します。それは、根粒のサイズと不均一な外観の大きな変動に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Point Cloud Attribute Compression via Successive Subspace Graph
  Transform -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_14.html">
      <font color="black">Point Cloud Attribute Compression via Successive Subspace Graph
  Transform</font>
    </a>
  </h2>
  <font color="black">最近提案された連続部分空間学習（SSL）の原則に触発されて、この作業で点群属性の圧縮に対処するための連続部分空間グラフ変換（SSGT）を開発します。変換はリーフノードからルートノードまでの大きな点群に適用されます。表現された部分空間が最小のものから点群全体に連続的に拡張される間、オクトツリーの再帰的に..提案されたSSGT法が以前の領域適応ハール変換（RAHT）法よりも優れたRD性能を提供することが実験結果によって示されています。 
[概要]変換は、リーフノードから八分木のルートまでの大きな点群雲に適用されます。この変換は、点群グラフの作成に使用された変更に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Cream of the Crop: Distilling Prioritized Paths For One-Shot Neural
  Architecture Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_15.html">
      <font color="black">Cream of the Crop: Distilling Prioritized Paths For One-Shot Neural
  Architecture Search</font>
    </a>
  </h2>
  <font color="black">優先パスはパフォーマンスと複雑さに応じてオンザフライで変更されるため、最終的に得られるパスは作物のクリームです。ImageNetでの実験により、このようなパス蒸留方法がハイパーネットワークの収束率とパフォーマンスも向上できることが確認されました。サブネットワークのトレーニングを後押しするように..優先パスから知識を抽出することで、サブネットワークのトレーニングを後押しすることができます。 
[概要]優先パスから知識を抽出することで、トレーニングを後押しできます。サブネットワークは、トレーニングプロセス全体を通じて、共同で学習し、互いに教えることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: SAR-NAS: Skeleton-based Action Recognition via Neural Architecture
  Searching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_16.html">
      <font color="black">SAR-NAS: Skeleton-based Action Recognition via Neural Architecture
  Searching</font>
    </a>
  </h2>
  <font color="black">挑戦的なNTURGB + DおよびKinecticsデータセットでの実験により、スケルトンベースの行動認識のためにこれまでに開発されたネットワークのほとんどがコンパクトで効率的ではない可能性が高いことが確認されました。このペーパーでは、スケルトンのニューラルネットワークアーキテクチャの自動設計の研究を紹介します。ベースの行動認識..最近開発されたDARTS（Differentiable Architecture Search）は、2つのタイプのセル上に構築された効果的なネットワークアーキテクチャを検索するために採用されています。 
[概要]スケルトンベースのネットワークを検索する提案された方法が開発されました。通常のセルと削減セルの2種類のネットワークセルを作成するために使用できます。全体的な計算と検索を削減するために、すべての操作は2Dベースです。スペース</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: ProxIQA: A Proxy Approach to Perceptual Optimization of Learned Image
  Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_17.html">
      <font color="black">ProxIQA: A Proxy Approach to Perceptual Optimization of Learned Image
  Compression</font>
    </a>
  </h2>
  <font color="black">この最適化フレームワークを適用して、エンドツーエンドの最適化された画像圧縮ネットワークをトレーニングする方法を実験的に示します。既存のディープ画像圧縮モデルの上に構築することで、最大31ドルのビットレート削減を示すことができます。指定された知覚品質（VMAF）レベルが与えられた場合のMSE最適化に対する％$ ..ここでは、定量的知覚モデルに対して画像分析ネットワークを最適化するための異なる「近位」アプローチについて説明します。 
[概要]実験的な25億ドルのモデルを使用して、視覚情報の損失を評価できます。これらの単純な基準は、人間の知覚と一致していません。これにより、知覚モデルを模倣するプロキシネットワークが作成されます。ネットワークの損失層</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-19">
        <br><font color="black">2019-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: WaveTransform: Crafting Adversarial Examples via Input Decomposition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_18.html">
      <font color="black">WaveTransform: Crafting Adversarial Examples via Input Decomposition</font>
    </a>
  </h2>
  <font color="black">複数のデータベースとCNNモデルを使用して実験を行い、提案されたWaveTransform攻撃の有効性を確立し、特定の周波数成分の重要性を分析します。提案された攻撃の堅牢性は、最近の敵対的防御アルゴリズムに対する転送可能性と復元力によっても評価されます。 。周波数スペクトルは、オブジェクト認識のためのユニークで識別可能な機能を学習する上で重要な役割を果たしてきました。 
[ABSTRACT]画像に存在する低頻度および高頻度の情報は、深層学習を含む多数の表現学習手法によって抽出され、学習可能です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Forgetting Outside the Box: Scrubbing Deep Networks of Information
  Accessible from Input-Output Observations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_19.html">
      <font color="black">Forgetting Outside the Box: Scrubbing Deep Networks of Information
  Accessible from Input-Output Observations</font>
    </a>
  </h2>
  <font color="black">提案された忘却手順には、モデルの線形化バージョンの微分方程式から導出された決定論的部分と、損失ランドスケープのジオメトリに合わせたノイズを追加することによって情報破壊を保証する確率論的部分があります。情報は、入力と出力の動作のみが観察されるブラックボックスネットワークから、忘れられたコホートに関するクエリごとに抽出できます。ニューラルタンジェントカーネルに触発されたDNNのアクティブ化と重みダイナミクス間の接続を利用して情報を計算します。アクティベーションで。 
[概要] dnn.itのアクティベーションと重みダイナミクスの関係を利用して、入力と出力の動作のみが観察されるブラックボックスネットワークから、忘れられたコホートに関する質問ごとに抽出できる情報の量を知ることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-05">
        <br><font color="black">2020-03-05</font>
      </time>
    </span>
</section>
<!-- paper0: Genetic U-Net: Automatically Designing Lightweight U-shaped CNN
  Architectures Using the Genetic Algorithm for Retinal Vessel Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_20.html">
      <font color="black">Genetic U-Net: Automatically Designing Lightweight U-shaped CNN
  Architectures Using the Genetic Algorithm for Retinal Vessel Segmentation</font>
    </a>
  </h2>
  <font color="black">ただし、これらのCNNの手動設計には時間がかかり、広範な経験的知識が必要です。この問題に対処するために、遺伝的アルゴリズム（GA）を使用して、網膜血管セグメンテーション用の軽量U字型CNNを自動的に設計する新しい方法を提案します。 Genetic U-Net ..実験結果は、提案された方法が3つの公開データセット、DRIVE、CHASE_DB1、およびSTAREの既存の方法よりも優れていることを示しています。 
[概要] cnnsの手動設計は遺伝的アルゴリズムに基づいています。遺伝的アルゴリズムを使用して優れたアーキテクチャを検索します。この方法は、最先端のモデルよりも軽量ですが堅牢です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: ContraGAN: Contrastive Learning for Conditional Image Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_21.html">
      <font color="black">ContraGAN: Contrastive Learning for Conditional Image Generation</font>
    </a>
  </h2>
  <font color="black">同時に、ジェネレーターは、信頼性を欺き、コントラスト損失が少ないリアルな画像を生成しようとします。条件付き画像生成は、クラスラベル情報を使用して多様な画像を生成するタスクです。ソフトウェアパッケージはhttps://github.comで入手できます。 / POSTECH-CVLab / PyTorch-StudioGAN。 
[ABSTRACT]コントラガンは、最先端のモデルよりも、小さなimagenetおよびimagenetデータセットで7.3％および7.7％優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-23">
        <br><font color="black">2020-06-23</font>
      </time>
    </span>
</section>
<!-- paper0: Measuring and Harnessing Transference in Multi-Task Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_22.html">
      <font color="black">Measuring and Harnessing Transference in Multi-Task Learning</font>
    </a>
  </h2>
  <font color="black">後者の場合、転移メトリックを活用する2つの方法を提案します。具体的には、タスク間の転移を定量化できる類似性指標を開発し、この量を使用して、マルチタスク学習の最適化ダイナミクスをよりよく理解し、全体を改善します。学習パフォーマンス..1つ目は、一緒にトレーニングするタスクを選択することでマクロレベルで動作し、2つ目は、各トレーニングステップでタスクの勾配を組み合わせる方法を決定することでミクロレベルで機能します。 
[概要]タスク間の転移を定量化できる類似性尺度を開発します。これは、全体的な学習パフォーマンスの向上にも役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Supervised Contrastive Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_23.html">
      <font color="black">Supervised Contrastive Learning</font>
    </a>
  </h2>
  <font color="black">教師あり対照（SupCon）損失の2つの可能なバージョンを分析し、損失の最もパフォーマンスの高い定式化を特定します。自己監視表現学習に適用される対照学習は、近年復活し、最先端のパフォーマンスにつながっています。深層画像モデルの教師なしトレーニング..他のデータセットと2つのResNetバリアントのクロスエントロピーに対して一貫したアウトパフォーマンスを示します。 
[概要]最新のバッチ対照アプローチは、トリプレット、最大マージン、nペア損失などの従来の対照損失を包含または大幅に上回っています。resnet-200では、imagenetデータセットでトップ-1の精度81.4％を達成しています-0 。このアーキテクチャで報告された最良の数を8％上回っています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-23">
        <br><font color="black">2020-04-23</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Deep Interleaved Networks with Asymmetric Co-Attention for
  Image Restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_24.html">
      <font color="black">Learning Deep Interleaved Networks with Asymmetric Co-Attention for
  Image Restoration</font>
    </a>
  </h2>
  <font color="black">このように、浅い情報は、特徴表現能力を強化するために深い代表的な特徴予測を導くことができます。この論文では、異なる状態の情報を高品質（HQ）のために組み合わせる方法を学習する深いインターリーブネットワーク（DIN）を提示します。 ）画像の再構築..このようなAsyCAは、さまざまな状態からの有益な機能を適応的に強調できるだけでなく、ネットワークの識別能力も向上させます。 
[ABSTRACT] cnnベースのモデルは通常、単一パスストリームとして実装され、最終予測のために低品質（lq）入力空間からの特徴表現を強化します。提案されたdinは、複数の相互接続されたブランチが異なる状態でインターリーブおよび融合するためのネットワークシステムに従います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Transferable Universal Adversarial Perturbations Using Generative Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_25.html">
      <font color="black">Transferable Universal Adversarial Perturbations Using Generative Models</font>
    </a>
  </h2>
  <font color="black">ディープニューラルネットワークは、敵対的な摂動に対して脆弱である傾向があり、自然画像に追加することで、それぞれのモデルを高い信頼性でだますことができます。ただし、既存のUAPは、未知のターゲットモデルに適用した場合、まだ十分に高いだまし率を欠いています。これにより、生成されたUAPを他のターゲットモデルに転送できるようになります。 
[概要]画像の存在-普遍的な敵対的摂動（uaps）としても知られる認識摂動が発見されました。これらの摂動は、さまざまなターゲットモデルに対して非常によく一般化されます。生成された非ターゲットuapを使用すると、93の平均だまし率が得られます。 。ソースモデルで36％</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding the Failure Modes of Out-of-Distribution Generalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_26.html">
      <font color="black">Understanding the Failure Modes of Out-of-Distribution Generalization</font>
    </a>
  </h2>
  <font color="black">特に、いくつかの学習しやすいタスクに関する勾配降下法でトレーニングされた線形分類器の理論的研究を通じて、2つの補完的な故障モードを明らかにします。最後に、これらの故障モードがいつ発生するかを理解するために、画像分類データセットの自然な変更を構築します。実際には..経験的研究によると、機械学習モデルは、背景などの特徴に依存していることが多く、トレーニング時間中にのみラベルと誤って相関し、テスト時間中の精度が低下する可能性があります。 
[概要]これらのモードは、疑似相関がデータに2種類のスキューを誘発する方法から生じます。また、これらのデータセットで最新のニューラルネットワークをトレーニングするときに、2つの故障モードを分離する実験を設計します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Recurrent neural circuits for contour detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_27.html">
      <font color="black">Recurrent neural circuits for contour detection</font>
    </a>
  </h2>
  <font color="black">全体として、私たちの研究は、方向傾斜錯視が、生物学的視覚システムが堅牢で効率的な輪郭検出を達成するのに役立つ神経回路の副産物であり、これらの回路を人工ニューラルネットワークに組み込むことでコンピュータービジョンを改善できることを示唆しています。この錯覚を修正すると、ガンマが大幅に減少します。 -高レベルのオブジェクト境界輪郭よりも低レベルのエッジを優先するように駆動することによるネット輪郭検出の精度..ガンマネットと呼ばれるこのアーキテクチャが、より優れたサンプル効率で輪郭検出タスクを解決することを学習することを示します。最先端のフィードフォワードネットワークでありながら、方向傾斜錯視として知られる古典的な知覚錯覚も示します。 
[概要]ガンマネットワークとして知られるガンマネットアーキテクチャは、より良いサンプル効率で輪郭検出タスクを解決することを学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: InterFaceGAN: Interpreting the Disentangled Face Representation Learned
  by GANs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_28.html">
      <font color="black">InterFaceGAN: Interpreting the Disentangled Face Representation Learned
  by GANs</font>
    </a>
  </h2>
  <font color="black">次に、異なるセマンティクス間の相関関係について詳細な調査を行い、部分空間投影を介してそれらをより適切に解きほぐし、属性操作をより正確に制御します。さらに、詳細な顔の同一性分析とレイヤーごとの分析を実行します。最後に、GAN反転アプローチを採用し、InterFaceGANによって確立された合成データに基づいてフィードフォワードモデルを明示的にトレーニングすることにより、実際の顔の編集にアプローチを適用します。 
[概要]最先端のガンモデルによって学習された解きほぐされた顔の表現を解釈し、潜在空間における顔のセマンティクスの特性を研究するために、インターフェースガンと呼ばれるフレームワークを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-18">
        <br><font color="black">2020-05-18</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic Resource-aware Corner Detection for Bio-inspired Vision Sensors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_29.html">
      <font color="black">Dynamic Resource-aware Corner Detection for Bio-inspired Vision Sensors</font>
    </a>
  </h2>
  <font color="black">提案されたアルゴリズムは、ネイバーの中から最適なコーナー候補を選択することができ、従来のハリススコアと比較して59％の平均実行時間の節約を達成します。このアルゴリズムは、3層フィルタリング-ハリスまたはTLF-ハリスアルゴリズムと呼ばれます。は、イベントのフィルタリング戦略に基づいています。その目的は、1）着信イベント、つまりノイズを意図的に排除することによって精度を高めること、および2）システムのリアルタイムパフォーマンスを改善すること、つまり、一定のスループットを維持することです。限られた精度の損失で不要なイベントを破棄することにより、1秒あたりの入力イベントの数。 
[ABSTRACT]組み込みシステムでイベントのストリームから非同期コーナーをリアルタイムで検出するアルゴリズム。これは、一部の着信イベントを意図的に排除することで精度を高めることを目的としたイベントのフィルタリング戦略に基づいています。ターンの中から最適なコーナーアルゴリズムを選択する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Black-Box Optimization of Object Detector Scales -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_30.html">
      <font color="black">Black-Box Optimization of Object Detector Scales</font>
    </a>
  </h2>
  <font color="black">Faster R-CNNで入力画像サイズと以前のボックスアンカースケールを調整することにより、mAPがPASCAL VOC 2007で2％、SSDで3％増加することを示します。回帰分析を実行して、重要なハイパーパラメーターを見つけます。調整する..自動ハイパーパラメータ最適化は、CNNベースのオブジェクト検出器ハイパーパラメータを改善するために検討されていません。 
[概要]この作業では、以前のcnnとssdを改善するためのブラックボックス拡張方法の使用を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Asynchronous Corner Tracking Algorithm based on Lifetime of Events for
  DAVIS Cameras -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_31.html">
      <font color="black">Asynchronous Corner Tracking Algorithm based on Lifetime of Events for
  DAVIS Cameras</font>
    </a>
  </h2>
  <font color="black">DAVISカメラは、人間の目を模倣する新しい視覚センサーを使用します。この論文では、DAVISカメラによってキャプチャされたイベントと強度画像の両方を使用する新しい非同期コーナー追跡方法を提案します。さらに、困難な照明シナリオで動作するアプリケーションは、イベントカメラの高いHDR、つまり、従来のカメラの60dBと比較して140dB。 
[概要]カメラの出力レートは、動的な環境で毎秒最大1,000万イベントに達する可能性があります。カメラのプロダクションフレームは、イベントの周囲5x5ピクセルのウィンドウサイズ内で、毎秒1,000万イベントに達する可能性があります。コーナーは、発生したイベントの速度と方向を計算するために使用されます-コーナー</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: YOLOpeds: Efficient Real-Time Single-Shot Pedestrian Detection for Smart
  Camera Applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_32.html">
      <font color="black">YOLOpeds: Efficient Real-Time Single-Shot Pedestrian Detection for Smart
  Camera Applications</font>
    </a>
  </h2>
  <font color="black">ただし、このような複雑なパラダイムは簡単に拡張できず、デバイス上で処理するためのリソースに制約のあるスマートカメラに従来から実装されていないため、リアルタイムの監視と堅牢性が不可欠な状況で大きな利点が得られます。アプリケーションとデバイス上のエクスペリエンスだけでなく、プライバシーとセキュリティを実現する重要な要素にもなり、ユーザーはデータをサーバーに送信して評価する必要なしにニューラルネットワークのメリットを享受できます。全体として、YOLOpedsはリアルタイムの持続的な運用を提供します。毎秒30フレーム以上で、検出率は既存の深層学習モデルを86％上回っています。 
[ABSTRACT]ディープラーニングを使用して、正確な最先端の検出器を構築できます。これらには、歩行者検出とディープラーニングが含まれます。このシステムは、プライバシーとセキュリティを実現するための重要な要素にもなります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Video Representation Using Pretext-Contrastive Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_33.html">
      <font color="black">Self-Supervised Video Representation Using Pretext-Contrastive Learning</font>
    </a>
  </h2>
  <font color="black">さらに、私たちのPCLは柔軟性があり、ほとんどすべての既存の口実タスク方法に適用できます。口実タスクのベースラインと対照的な損失のさまざまな組み合わせに基づく広範な実験により、教師あり学習ターゲットとの強い一致が確認され、有効性と一般性が実証されます。 PCLの..口実タスクと対照的な損失の組み合わせは、対応するベースラインを超えてビデオ検索と認識の両方で大幅な改善を示しました。 
[ABSTRACT]口実タスクのベースラインと対照的な損失は、彼らの自己教師あり学習目標との強い一致を証明します。また、同じ方法で現在の最先端の方法を上回ることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring Generative Adversarial Networks for Image-to-Image Translation
  in STEM Simulation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_34.html">
      <font color="black">Exploring Generative Adversarial Networks for Image-to-Image Translation
  in STEM Simulation</font>
    </a>
  </h2>
  <font color="black">ディープラーニングモデルのGenerativeAdversarial Network（GAN）を使用すると、最良の結果が得られ、同じデータセットの以前の回帰モデルと同様の精度レベルで実行されることがわかります。このプロジェクトのコードとデータは、このGitHubリポジトリにあります。 、https：//github.com/uw-cmg/GAN-STEM-Conv2MultiSlice ..次に、結果を回帰法の結果と比較します。このプロジェクトの
[ABSTRACT]データはこのgithubシミュレーションにあります。データは他のシミュレーション方法からのデータを理解するために使用できます。これらのデータは分析やデータにも使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Recurrent Neural Networks for video object detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_35.html">
      <font color="black">Recurrent Neural Networks for video object detection</font>
    </a>
  </h2>
  <font color="black">この調査では、オブジェクト検出に時間的コンテキストを含めることの利点など、比較した方法の一般的な結果を示し、ビデオオブジェクト検出ネットワークの結論とガイドラインを示しています。たとえば、自動運転など、分類を行う必要のある実際のデータを自動運転する多くのアプリケーションの場合はビデオです。異なるフレームの特徴マップを反復ユニットにフィードする機能ベースのメソッド、クラス確率を持つ境界ボックスを反復ユニットにフィードするボックスレベルのメソッド、およびフローネットワークを使用するメソッドは異なります。 
[概要]分類が必要な実際のデータはビデオです。たとえば、自動運転、実際の情報はビデオです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: A comparison of automatic multi-tissue segmentation methods of the human
  fetal brain using the FeTA Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_36.html">
      <font color="black">A comparison of automatic multi-tissue segmentation methods of the human
  fetal brain using the FeTA Dataset</font>
    </a>
  </h2>
  <font color="black">4つの研究グループが参加し、合計10のアルゴリズムを提出し、自動アルゴリズムの開発に対するデータベースの利点を示しました。ここでは、範囲全体で手動でセグメント化された50の病理学的および非病理学的胎児磁気共鳴脳ボリューム再構築の公開データベースを紹介します。妊娠年齢（20〜33週）を7つの異なる組織カテゴリー（外部脳脊髄液、灰白質、白質、脳室、小脳、深灰白質、脳幹/脊髄）に分類します。この分析を容易にするために、自動多組織胎児脳セグメンテーションアルゴリズムが必要であり、これにはセグメント化された胎児の脳のオープンデータベースが必要です。 
[概要]これらは、この分析を容易にするために必要です。自動多組織胎児脳。これらのアルゴリズムには、セグメント化された胎児脳のオープンデータベースが必要です。これらには、理解するために人間の組織の範囲を謝罪および分析することが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: RelationNet++: Bridging Visual Representations for Object Detection via
  Transformer Decoder -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_37.html">
      <font color="black">RelationNet++: Bridging Visual Representations for Object Detection via
  Transformer Decoder</font>
    </a>
  </h2>
  <font color="black">\ emph {キーサンプリング}アプローチや\ emph {共有ロケーション埋め込み}アプローチなど、デコーダモジュールの効率的な計算に向けて新しい手法が提案されています。既存のオブジェクト検出フレームワークは通常、単一フォーマットのオブジェクト/パーツ表現に基づいて構築されています。つまり、RetinaNetとFaster R-CNNのアンカー/提案長方形ボックス、FCOSとRepPointsの中心点、CornerNetのコーナーポイントです。提案されたモジュールの名前は\ emph {ブリッジ視覚表現}（BVR）です。 
[概要]これは、さまざまな表現による異種または非アニアニネットの特徴抽出によるものです。これらの例は通常、フレームワークを駆動して、分類の改善やローカリゼーションの詳細化など、さまざまな側面で適切に機能します。これらの表現を1つにまとめることは困難です。それぞれの強みを生かすための枠組み</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: A Grid-based Representation for Human Action Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_38.html">
      <font color="black">A Grid-based Representation for Human Action Recognition</font>
    </a>
  </h2>
  <font color="black">近年、HARは、特に深層学習モデルの出現により、大きな進歩を遂げました。GRAR（行動認識のためのグリッドベースの表現）メソッドは、いくつかのベンチマークデータセットでテストされ、モデルが人間の行動を正確に認識できることを示しています。 -クラスの外観の変化とオクルージョンの課題..この論文では、代表的なポーズの特徴に明確な注意を払って、アクションの最も識別力のある外観情報を新しいコンパクトなグリッド表現に効率的にエンコードする、人間の行動認識のための新しい方法を提案します。 
[ABSTRACT]私たちのgrar（アクションアピアランスのグリッドベースの表現）メソッドは、いくつかのベンチマークデータセットでテストされています。クラス内のアピアランスの変動やオクルージョンの課題にもかかわらず、モデルは人間のアクションを正確に認識できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-17">
        <br><font color="black">2020-10-17</font>
      </time>
    </span>
</section>
<!-- paper0: Convolutional Neural Networks for Global Human Settlements Mapping from
  Sentinel-2 Satellite Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_39.html">
      <font color="black">Convolutional Neural Networks for Global Human Settlements Mapping from
  Sentinel-2 Satellite Imagery</font>
    </a>
  </h2>
  <font color="black">人間の居住地の空間的に一貫性のある最新のマップは、特にますます都市化が進む世界の時代において、都市化と持続可能性に関連するポリシーに対処するために重要です。コペルニクス地球観測プログラムのオープンで無料のSentinel-2データの可用性は提供します世界規模での人間の居住地の壁から壁へのマッピングの新しい機会。このペーパーでは、のグローバルコンポジットから10mの空間解像度で市街地を完全に自動抽出するためのディープラーニングベースのフレームワークを紹介します。 Sentinel-2画像：構築領域のピクセル単位の画像分類のための単純な畳み込みニューラルネットワークアーキテクチャに基づいたマルチニューロモデリング手法が開発されています。提案されたモデルのコア機能は、サイズ5 x5ピクセルの画像パッチです。 Sentinel-2画像からの市街地と、合計1,448,578のトレーニング可能なパラメーターと4つの2D畳み込み層と2つの平坦化された軽量トポロジーを記述するのに適していますレイヤー。グローバルSentinel-2イメージコンポジットへのモデルの展開により、2018年の参照年の市街地に関する最も詳細で完全なマップレポートが提供されます。建物のフットプリントの独立した参照データセットによる結果の検証世界中の277のサイトが、提案されたフレームワークによって生成されたビルドアップレイヤーの信頼性とモデルの堅牢性を確立しています。 
[概要]人間の地図地図地図は、建物の建物のあり方を形作るのに役立ちました。建物のプログラムは、人間よりも成功しています。13歳は建物システムの中心です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-05">
        <br><font color="black">2020-06-05</font>
      </time>
    </span>
</section>
<!-- paper0: ATRW: A Benchmark for Amur Tiger Re-identification in the Wild -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_40.html">
      <font color="black">ATRW: A Benchmark for Amur Tiger Re-identification in the Wild</font>
    </a>
  </h2>
  <font color="black">ATRWには、92頭のアムールトラからの8,000を超えるビデオクリップが含まれており、バウンディングボックス、ポーズキーポイント、タイガーIDアノテーションが付いています。ただし、既存のre-IDメソッドは、ポーズのバリエーションが限られており、キャプチャ環境が制限されている人や車を主に対象としています。典型的なre-IDデータセットとは対照的に、トラは制約のないポーズと照明条件の多様なセットでキャプチャされます。 
[概要]アムールトラの再-野生の識別（atrw）データセットには、多くのトラの写真と照明条件が含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-13">
        <br><font color="black">2019-06-13</font>
      </time>
    </span>
</section>
<!-- paper0: An Overview Of 3D Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_41.html">
      <font color="black">An Overview Of 3D Object Detection</font>
    </a>
  </h2>
  <font color="black">既存の2D検出モデルを使用してRGB画像上の関心領域（ROI）をローカライズし、続いて点群でピクセルマッピング戦略を実行し、最後に最初の2D境界ボックスを3D空間に持ち上げます。歩行者などのオブジェクト、サイクリスト、またはトラフィックコーンは通常、非常にまばらなポイントで表されるため、ポイントクラウドのみを使用した検出は非常に複雑になります。最近リリースされたnuScenesデータセットを使用します---大規模なデータセットには多くのデータ形式が含まれています---トレーニングと提案されたアーキテクチャを評価します。 
[概要]このプロジェクトでは、rgbと点群データを使用してマルチクラスオブジェクト認識を実行するフレームワークを提案します。2D、3D構造の使用は、点群の複雑さのために依然として課題です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Permute, Quantize, and Fine-tune: Efficient Compression of Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_42.html">
      <font color="black">Permute, Quantize, and Fine-tune: Efficient Compression of Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">これは、点ごとの畳み込み（現代のアーキテクチャを支配する）、線形レイヤー（空間次元の概念がない）、および畳み込み（複数のフィルターが同じコードワードに圧縮される場合）に適しています。このペーパーでは、次のことを観察します。同じ関数を表現しながら、2つの隣接するレイヤーの重みを並べ替えることができます。最後に、ネットワークをより適切に圧縮し、より高い最終精度を達成するために、アニールされた量子化アルゴリズムに依存します。 
[概要]このサイクルが畳み込みフィルターに使用されるのはこれが初めてですが、一般的な解決策は未解決のままであるため、ツールを確立することは困難です。最近、さまざまなコアビジョンで最先端のネットワーク圧縮を実現しました。自然言語処理タスク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Suppressing Mislabeled Data via Grouping and Self-Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_43.html">
      <font color="black">Suppressing Mislabeled Data via Grouping and Self-Attention</font>
    </a>
  </h2>
  <font color="black">広範な実験により、AFMは、2つの挑戦的な現実世界のノイズの多いデータセットFood101NとClothing1Mで最先端の結果をもたらすことが示されています。 。ディープネットワークは、大規模なクリーンデータで優れた結果を達成しますが、ノイズの多いラベルから学習すると大幅に低下します。 
[概要]コードは注意深い機能の取り違え（afm）と呼ばれ、クリーンなサンプルに注意を払い、誤ったラベルのサンプルに注意を払うことができます。誤ったラベルのデータの影響を抑えるように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: FlatNet: Towards Photorealistic Scene Reconstruction from Lensless
  Measurements -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_44.html">
      <font color="black">FlatNet: Towards Photorealistic Scene Reconstruction from Lensless
  Measurements</font>
    </a>
  </h2>
  <font color="black">$ \ textit {FlatNet} $と呼ばれる私たちのアプローチは、カメラのフォワードモデルの定式化が知られているマスクベースのレンズレスカメラから高品質の写実的な画像を再構築するためのフレームワークを定めています。FlatNetは2つの段階で構成されます。フォワードモデル定式化内のパラメータを学習することにより、測定を中間再構成の空間にマッピングする反転段階、および（2）この中間再構成の知覚品質を改善する知覚強化段階..レンズレスイメージングは、実現に向けた潜在的なソリューションとして浮上しています。従来のカメラではかさばるレンズを避けて超小型カメラ。 
[概要]レンズレスカメラは、多重化された測定から画像を復元するアルゴリズムに依存しています。これらは、エスカレーションベースの再構成アプローチに基づいており、レンズレス再構成の画質が桁違いに向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Memory Optimization for Deep Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_45.html">
      <font color="black">Memory Optimization for Deep Networks</font>
    </a>
  </h2>
  <font color="black">私たちのコードはhttps://github.com/utsaslab/MONeTで入手できます。MONeTは、自動チェックポインティングだけでなく、以前のすべての手動調整操作よりも優れたパフォーマンスを発揮します。MONeTは、さまざまなPyTorchモデルの全体的なメモリ要件を3分の1に削減します。計算の9〜16％のオーバーヘッド。 
[ABSTRACT] monetは、以前のすべての手動で調整された操作とcheckpointing.monetよりもパフォーマンスが優れています。必要なメモリは現在の状態の1.2〜1。8分の1です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: AADS: Augmented Autonomous Driving Simulation using Data-driven
  Algorithms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_46.html">
      <font color="black">AADS: Augmented Autonomous Driving Simulation using Data-driven
  Algorithms</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、これらの問題に対処するための新しいアプローチを紹介します。拡張自動運転シミュレーション（AADS）。私たちの定式化は、シミュレートされたトラフィックフローで実世界の画像を拡張し、写真のようにリアルなシミュレーション画像とレンダリングを作成します。 ADシミュレーションと私たちは、現実世界の複雑さと多様性を仮想環境で現実的に捉えることはできないと信じています。 
[ABSTRACT]システムは、仮想環境の柔軟性と現実世界の豊かさを組み合わせて、地球上のあらゆる場所の効果的なシミュレーションを可能にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-01-23">
        <br><font color="black">2019-01-23</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Self-Supervised Methods for Medical Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_47.html">
      <font color="black">3D Self-Supervised Methods for Medical Imaging</font>
    </a>
  </h2>
  <font color="black">各タスクで、データ効率、パフォーマンス、収束速度の向上を評価します。医用画像領域からの3つのダウンストリームタスクでのメソッドの有効性を示します。i）3D MRIからの脳腫瘍セグメンテーション、ii）膵臓3D CTからの腫瘍セグメンテーション、およびiii）2D眼底画像からの糖尿病性網膜症の検出..他の研究者が適用できるようにするために、開発されたアルゴリズム（3Dバージョンと2Dバージョンの両方）の実装をオープンソースライブラリとして公開します。データセットのメソッドを拡張します。 
[概要]開発されたアルゴリズムは、3Dコントラスト予測コーディング、3D回転予測、3Dジグソーパズル、相対3Dパッチ位置、および3D模範ネットワークです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-06">
        <br><font color="black">2020-06-06</font>
      </time>
    </span>
</section>
<!-- paper0: A Novel Fast 3D Single Image Super-Resolution Algorithm -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_48.html">
      <font color="black">A Novel Fast 3D Single Image Super-Resolution Algorithm</font>
    </a>
  </h2>
  <font color="black">特に、提案された3Dデシメーション演算子の分解手法により、Tikhonov正則化の簡単な実装が可能になり、さらに、全変動などの他の正則化関数を考慮に入れて、最先端の計算コストを実現できます。アルゴリズムは大幅に削減されます。実行された数値実験は、提案されたアプローチが既存の3D SRメソッドよりも優れていることを示しました。この論文では、3D単一画像超解像度（SR）問題を解決する新しい計算効率の高い方法を紹介します。その低解像度の対応物からの高解像度のボリューム。 
[要約]提案されたアプローチにより、オペレーターは、周波数領域での基礎となる特性に基づいて、関連する間引き演算子とぼかし演算子を同時に処理できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Integration of the 3D Environment for UAV Onboard Visual Object Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_49.html">
      <font color="black">Integration of the 3D Environment for UAV Onboard Visual Object Tracking</font>
    </a>
  </h2>
  <font color="black">ターゲットの位置を画像空間ではなく3D空間で表すことにより、エゴモーション中のトラッキングを安定させ、オクルージョン、背景の乱雑さ、小規模なオブジェクトの処理を改善します。この目的のために、既存のデータセットを適合させました。視覚的なオブジェクトの追跡と3Dでの観察されたシーンの再構築のために..私たちのアプローチは、トラフィックモニタリング、ビデオ監視、およびナビゲーションに有益であると考えています。 
[概要]観測されたシーンの3D構造を検出に統合することを提案します-追跡アルゴリズムによる</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-06">
        <br><font color="black">2020-08-06</font>
      </time>
    </span>
</section>
<!-- paper0: Video based real-time positional tracker -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_50.html">
      <font color="black">Video based real-time positional tracker</font>
    </a>
  </h2>
  <font color="black">ほとんどの場合、特に屋内オブジェクトや晴天から遮られたオブジェクトに対して、既存のGPSベースのシステムよりも高い更新レートと測位精度を実現します。システムは、より広い世界に対する追跡対象の位置を返します。カメラによって形成された重なり合うマトリックスを理解することにより、これらを実世界の座標に外挿することができます。位置トラッカーは、選択したアリーナの周囲に配置された1〜n台のビデオカメラの範囲に依存します。 
[ABSTRACT]システムは、独自のシステムからの100％合成データセットでトレーニングされています。システムは、より広い世界に対する追跡対象オブジェクトの位置を返します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Free-Form Image Inpainting via Contrastive Attention Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_51.html">
      <font color="black">Free-Form Image Inpainting via Contrastive Attention Network</font>
    </a>
  </h2>
  <font color="black">さらに、復元された領域と既知の領域の両方をスムーズに組み合わせることができる、新しいデュアルアテンションフュージョンモジュール（DAF）を備えたマルチスケールデコーダーを提案します。このようにして、未知の領域が外側から内側に自然に埋められます。フル解像度の画像からコンテキストセマンティクスをエンコードし、より識別力のある表現を取得できます。 
[概要]このマルチスケールアーキテクチャは、エンコーダーによって学習された識別表現をレイヤーごとに画像にデコードするのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Speech-Image Semantic Alignment Does Not Depend on Any Prior
  Classification Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_52.html">
      <font color="black">Speech-Image Semantic Alignment Does Not Depend on Any Prior
  Classification Tasks</font>
    </a>
  </h2>
  <font color="black">さらに他では、事前に訓練されたネットワークを使用して、セマンティック埋め込みの前に音声特徴を抽出します。音声および画像ブランチのエンコーダに適切なニューラルアーキテクチャを選択し、大きなデータセットを使用すると、事前に依存することなく、競争力のある想起率を得ることができます。訓練された初期化または特徴抽出：$（speech、image）$セマンティックアラインメントと$ Speech \ rightarrow image $および$ image \ rightarrow Speech $の取得は、独自の調査に値する標準的なタスクであり、他の質問を調査することができます---たとえば、オーディオエンベッダーのサイズは、$ Speech \ rightarrow image $および$ image \ rightarrow Speech $クエリでのリコール率の損失をほとんど伴わずに大幅に削減できます。事前トレーニング済みの初期化または事前トレーニング済みの機能による「転送学習」なしで、抽出では、以前の結果は、$ Speech \ rightarrow image $および$ image \ rightarrow Speech $クエリで低いリコール率を示す傾向がありました。 
[ABSTRACT]画像信号の画像は、さまざまな機能を使用して取得するために使用されます。顎ベースの通信は、「転移学習」なしで使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: What it Thinks is Important is Important: Robustness Transfers through
  Input Gradients -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_53.html">
      <font color="black">What it Thinks is Important is Important: Robustness Transfers through
  Input Gradients</font>
    </a>
  </h2>
  <font color="black">MNIST、CIFAR-10、CIFAR-100、Tiny-ImageNetでの実験を通じて、提案された方法である入力勾配の敵対的マッチングが、さまざまなタスク間、さらにはさまざまなモデルアーキテクチャ間でロバスト性を転送できることを示します。これは、セマンティクスを直接ターゲットにすることを示しています。入力勾配の計算は、敵対的なロバスト性に向けた実行可能な方法です。このような摂動に対してロバストなモデルの学習された重みは、異なるタスク間で転送可能であることが以前にわかっていますが、これは、ソースタスクとターゲットタスクのモデルアーキテクチャが同じである場合にのみ適用されます。 
[ABSTRACT]学習質問は、モデルのサブジェクトのサブジェクトをテストするために使用できます。それらは、ゼロから堅牢にトレーニングされた強力なベースラインに近い堅牢性を得ることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-11">
        <br><font color="black">2019-12-11</font>
      </time>
    </span>
</section>
<!-- paper0: Identifying safe intersection design through unsupervised feature
  extraction from satellite imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_54.html">
      <font color="black">Identifying safe intersection design through unsupervised feature
  extraction from satellite imagery</font>
    </a>
  </h2>
  <font color="black">オーストラリアのテレマティクスデータセットは、インフラストラクチャの設計を6,600万キロメートルの運転中にキャプチャされた運転行動にリンクしました。全体として、ドメイン固有の特徴抽出により、より安全な運転行動をもたらし、道路の外傷を減らす可能性のあるインフラストラクチャの改善を特定できました。 4方向または3方向の交差点での頻繁なハード加速イベント（車両ごと）、T交差点での比較的低いハード減速頻度、およびラウンドアバウトでの一貫した低い平均速度。 
[概要]この記事では、大国のすべてのエリアの設計を体系的に分析する最初の研究を紹介しました。これは、航空写真とディープラーニングに基づいています。オートエンコーダーは、交差点のタイプ、サイズ、サイズなど、高レベルの特徴を抽出しました。類似のデザインをクラスター化するために使用された形状、レーンマーキング、および複雑さ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Passport-aware Normalization for Deep Model Protection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_55.html">
      <font color="black">Passport-aware Normalization for Deep Model Protection</font>
    </a>
  </h2>
  <font color="black">したがって、ターゲットモデルの構造変化は発生しません。広範な実験を通じて、画像と3Dポイント認識モデルの両方でその有効性を検証します。この目的のために、ほとんどの場合に一般的に適用できる新しいパスポート対応の正規化定式化を提案します。既存の正規化レイヤーであり、IP保護のために別のパスポート対応ブランチを追加するだけで済みます。 
[概要]これらのモデルの多くは、ターゲットネットワークの変更が必要です。このモデルモデルIPは、誰かに盗まれたと考えられています。モデルモデルモデルの所有者は保護できません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: RATT: Recurrent Attention to Transient Tasks for Continual Image
  Captioning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_56.html">
      <font color="black">RATT: Recurrent Attention to Transient Tasks for Continual Image
  Captioning</font>
    </a>
  </h2>
  <font color="black">そのタスクの語彙はばらばらではありません。私たちは私たちの方法を一時的なタスクへの反復的注意（RATT）と呼び、また、重みの正規化と知識の蒸留に基づく継続的な学習アプローチを再発性の継続的な学習問題に適応させる方法を示します。継続的な画像キャプションタスクで語彙の一時的な性質に明示的に対応するアプローチ-つまり、
[ABSTRACT]これまで、継続的な学習にほとんど注意が向けられていませんでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-13">
        <br><font color="black">2020-07-13</font>
      </time>
    </span>
</section>
<!-- paper0: Spherical Knowledge Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_57.html">
      <font color="black">Spherical Knowledge Distillation</font>
    </a>
  </h2>
  <font color="black">具体的には、教師と生徒のロジットを単位球に投影し、球上で効率的に知識の蒸留を実行できます。理論分析とアブレーション研究によって議論を検証します。以前のアプローチでは、単純にこの目標を達成しようとします。教師と生徒の間で転送される「ロジット監視」情報。これは、正規化されたロジットと$ l ^ 2 $ノルムの転送として後で分解できます。 
[概要]この問題の解決に加えて、球形知識蒸留（skd）を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Sparse and Continuous Attention Mechanisms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_58.html">
      <font color="black">Sparse and Continuous Attention Mechanisms</font>
    </a>
  </h2>
  <font color="black">注意ベースのテキスト分類、機械翻訳、視覚的な質問応答に関する実験は、1Dおよび2Dでの継続的な注意の使用を示しており、時間間隔とコンパクトな領域に注意を向けることができることを示しています。対照的に、有限領域では最近softmaxのまばらな代替案に取り組んでいます（たとえば、このペーパーは2つの方向で機能を拡張します：最初に、alpha-entmaxを連続ドメインに拡張し、Tsallis統計と変形した指数ファミリーとのリンクを明らかにします。
[ABSTRACT]は定期的な注意メカニズム、連続機械を支持しますmachine machine.itは、ユニバーサルユニバーサルユニバーサルアテンションのパターンに基づいています。一連の同様のことになると、アップグレードは簡単です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-12">
        <br><font color="black">2020-06-12</font>
      </time>
    </span>
</section>
<!-- paper0: Brain Tumor Segmentation Network Using Attention-based Fusion and
  Spatial Relationship Constraint -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_59.html">
      <font color="black">Brain Tumor Segmentation Network Using Attention-based Fusion and
  Spatial Relationship Constraint</font>
    </a>
  </h2>
  <font color="black">マルチモーダル脳腫瘍セグメンテーションチャレンジ2020（BraTs2020）のテストセットで私たちの方法を評価します。磁気共鳴（MR）画像から脳腫瘍を描写することは、神経膠腫の治療にとって重要です。腫瘍のサブ領域間の空間的関係は比較的固定されています。たとえば、増強腫瘍は常に腫瘍コアにあり、腫瘍の異なるサブ領域間の関係を制約するための空間的損失を提案します。 
[概要]腫瘍の複雑な外観と曖昧な輪郭は困難です。これは、腫瘍の複雑な画像と曖昧な輪郭によるものです。この方法では、0。8764、0.52、0。8243、0.773ダイススコアが達成されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: A Coarse-To-Fine (C2F) Representation for End-To-End 6-DoF Grasp
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_60.html">
      <font color="black">A Coarse-To-Fine (C2F) Representation for End-To-End 6-DoF Grasp
  Detection</font>
    </a>
  </h2>
  <font color="black">さらに、回転エラーと遷移エラーの両方を考慮した新しいAPベースのメトリックを提案し、把握検出モデルのより包括的な評価ツールにします。また、単一オブジェクトでの成功率の点で8％と40％正確です。シーンとクラッターシーンの完了率はそれぞれ..私たちの方法は、ビューと入力ポイントの数が異なる設定の中で優れた結果を示しています。 
[概要]私たちのアーキテクチャは少なくとも20倍高速です。以前の2-fアプローチよりも正確です。私たちの方法は設定で優れた結果を示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Accurate Entropy Model with Global Reference for Image
  Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_61.html">
      <font color="black">Learning Accurate Entropy Model with Global Reference for Image
  Compression</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案されたモデルが業界のほとんどの最先端の方法のレート歪み性能を上回っていることを示しています。この作業の副産物は、さらに改善する平均シフトGDNモジュールの革新です。パフォーマンス..提案された方法は、デコードされた潜在性をスキャンし、現在の潜在性の分布推定を支援するために最も関連性のある潜在性を見つけます。 
[概要]以前のメソッドはハイパープライアとローカルコンテキストを組み合わせます。既存のメソッドはハイパープライアとローカルコンテキストで重要な役割を果たします。これは平均シフトgdnモジュールの革新です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-16">
        <br><font color="black">2020-10-16</font>
      </time>
    </span>
</section>
<!-- paper0: Not All Unlabeled Data are Equal: Learning to Weight Data in
  Semi-supervised Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CV/paper_62.html">
      <font color="black">Not All Unlabeled Data are Equal: Learning to Weight Data in
  Semi-supervised Learning</font>
    </a>
  </h2>
  <font color="black">この手法が、半教師あり画像および言語分類タスクで最先端の方法よりも優れていることを示します。既存の半教師あり学習（SSL）アルゴリズムは、単一の重みを使用して、ラベル付きとラベルなしの例の損失のバランスを取ります。ラベルのないすべての例は均等に重み付けされます。代わりに、影響関数に基づくアルゴリズムを介してこれらの重みを調整します。これは、1つのトレーニング例に対するモデルの依存度の尺度です。 
[概要]影響関数の高速で効果的な測定を提案します。アプローチを効率的にするために、高速で効果的な例を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-02">
        <br><font color="black">2020-07-02</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Multiple Sclerosis Severity Classification From Clinical Text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_0.html">
      <font color="black">Multiple Sclerosis Severity Classification From Clinical Text</font>
    </a>
  </h2>
  <font color="black">多発性硬化症（MS）は慢性、炎症性、変性の神経疾患であり、専門医が拡張障害状態スケール（EDSS）を使用して監視し、神経学コンサルトノートの形式で非構造化テキストに記録します。Macro-F1を改善します。 EDSSの予測では0.12（〜0.88）、以前のWord2Vec CNNおよびルールベースのアプローチよりも機能的なサブスコアの予測では平均0.29（〜0.63）。MSBCは、すべてのメトリックおよび予測タスクで最先端のパフォーマンスを実現します。 Snorkelアンサンブルから生成されたモデルよりも優れています。 
[概要] edss測定には、全体的な「edss」スコアといくつかの機能サブスコアが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: CAPT: Contrastive Pre-Training for Learning Denoised Sequence
  Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_1.html">
      <font color="black">CAPT: Contrastive Pre-Training for Learning Denoised Sequence
  Representations</font>
    </a>
  </h2>
  <font color="black">特定のモダリティに焦点を当てたほとんどの以前の研究とは異なり、11の自然言語理解とクロスモーダルタスクに関する包括的な経験的証拠は、CAPTが言語と視覚言語の両方のタスクに適用可能であり、0.6％の絶対ゲインを含む驚くほど一貫した改善が得られることを示していますGLUEベンチマークとNLVRの0.8％絶対増分で..提案されたCAPTは、監視されていないインスタンスごとのトレーニング信号を介して、元のシーケンスとその破損したバージョンの表現間の一貫性を促進します。このようにして、トレーニング前の微調整の不一致を軽減するだけではありません。事前トレーニングのノイズによって誘発されますが、事前トレーニングされたモデルが、より効果的な文レベルの監視を介して入力のグローバルセマンティクスをより適切にキャプチャするのにも役立ちます。 
[ABSTRACT] pre-トレーニングは、このタイプのノイズのベンチマークバージョンです。これは、以前の以前のモデルが破損していて、元の入力を復元しようとしていることを示しています。ただし、モデルはさまざまなレベルのノイズで動作します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Conversation Graph: Data Augmentation, Training and Evaluation for
  Non-Deterministic Dialogue Management -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_2.html">
      <font color="black">Conversation Graph: Data Augmentation, Training and Evaluation for
  Non-Deterministic Dialogue Management</font>
    </a>
  </h2>
  <font color="black">タスク指向の対話システムは、通常、大量の高品質のトレーニングデータに依存するか、複雑な手作りのルールを必要とします。複数のアクションを同一の対話状態で有効と見なします。対話のグラフベースの表現である会話グラフ（ConvGraph）を提案します。これは、データの増強、マルチリファレンストレーニング、および非決定論的エージェントの評価に利用できます。 
[要約]データセットはサイズが制限されていることがよくあります。これらの測定にはディスカッションアクションが必要です。これらには、同一のダイアログ状態で有効な複数のアクションが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervised Pre-training Reduces Label Permutation Instability of
  Speech Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_3.html">
      <font color="black">Self-supervised Pre-training Reduces Label Permutation Instability of
  Speech Separation</font>
    </a>
  </h2>
  <font color="black">いくつかのタイプの自己監視タスクの中で、音声強調ベースの事前トレーニングタスクは、私たちの実験で大きな効果を示しています。既製の事前トレーニングモデルを使用すると、トレーニング期間を3分の1から3分の2に短縮できます。さらに、事前トレーニング時間を考慮しても、より大きなバッチサイズを使用すると、パフォーマンスを低下させることなく、トレーニングプロセス全体を短縮できます。 
[概要]この論文では、ラベルの順列を安定させるために、自己教師あり事前トレーニングを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: SNR-Based Teachers-Student Technique for Speech Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_4.html">
      <font color="black">SNR-Based Teachers-Student Technique for Speech Enhancement</font>
    </a>
  </h2>
  <font color="black">最終的に、学生モデルは高SNRと低SNRの両方で音声強調を実行できます。提案された方法を評価するために、公開データセットに基づいて-20dBから20dBの範囲のSNRを持つデータセットを構築しました。次に、別の教師を選択します。トレーニングデータのSNRに従って、学生モデルのトレーニングを監視するモデル。 
[概要]この問題に対処するために、snrベースの教師-学生の技術と時間-ドメインu-ネットを統合する方法。互いに一致しない複数の小さな範囲のsnrの下で教師モデルをテストします。特定のsnr範囲内で音声強調を十分に実行する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-29">
        <br><font color="black">2020-05-29</font>
      </time>
    </span>
</section>
<!-- paper0: Contextual BERT: Conditioning the Language Model Using a Global State -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_5.html">
      <font color="black">Contextual BERT: Conditioning the Language Model Using a Global State</font>
    </a>
  </h2>
  <font color="black">文献の他の方法との実験的比較は、私たちの方法がパーソナライズを大幅に改善することを示しています。これは、固定サイズのコンテキストで条件付けするためのグローバル状態を追加することによって、BERTアーキテクチャを進歩させる動機を与えます。BERTは人気のある言語モデルです。 -トレーニングタスクは、空白を埋めることです。つまり、残りの単語に基づいて、文からマスクされた単語を予測します。 
[概要] 2つの新しいアプローチを提示し、それらを業界のユースケースに適用します。ケースでは、特定の顧客を条件として、不足している記事でファッション衣装を完成させます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Language ID in the Wild: Unexpected Challenges on the Path to a
  Thousand-Language Web Text Corpus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_6.html">
      <font color="black">Language ID in the Wild: Unexpected Challenges on the Path to a
  Thousand-Language Web Text Corpus</font>
    </a>
  </h2>
  <font color="black">これらのエラーを軽減するために、2つのクラスの手法を提案します。ワードリストベースの調整可能な精度フィルター（約500言語でキュレーションされたリストをリリース）とトランスフォーマーベースの半教師ありLangIDモデルで、データセットの精度の中央値を5.5％から71.2に向上させます％..最大1,629の言語でLangIDモデルをトレーニングし、保持されたテストセットで同等の品質を実現しますが、これらのモデルを使用して作成されたWebクロールテキストコーパスの人間が判断したLangIDの精度は、多くの低リソースで約5％にすぎません。言語、より堅牢な評価の必要性を示唆しています。これらの手法により、500以上の言語のそれぞれで100K以上の比較的クリーンな文をカバーする初期データセットを作成し、1,000言語のWebテキストコーパスへの道を開くことができます。 
[ABSTRACT] langidは、主に文献で解決されたものとして扱われ、1,366の言語で90％を超える平均f1を達成するモデルが報告されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Predicting Themes within Complex Unstructured Texts: A Case Study on
  Safeguarding Reports -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_7.html">
      <font color="black">Predicting Themes within Complex Unstructured Texts: A Case Study on
  Safeguarding Reports</font>
    </a>
  </h2>
  <font color="black">教師あり分類アプローチを使用して、保護レポートの主要テーマを自動的に識別する問題に焦点を当てます。利用可能なレポートの量が比較的少なく、ドメイン固有の用語を使用しているため、自動化されたアプローチの適用が困難です。アプリケーションの研究少量のトレーニングデータに基づく教師あり分類の数は限られています。 
[ABSTRACT]研究は、ラベル付けされたデータが限られている複雑なタスクでも問題行動をシミュレートするディープラーニングモデルの可能性を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Unique Chinese Linguistic Phenomena -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_8.html">
      <font color="black">Unique Chinese Linguistic Phenomena</font>
    </a>
  </h2>
  <font color="black">中国語と英語の言語学の多様性は、主に形態と構文に反映されます。中国語の言語学の複雑さが操作を難しくし、英語の方法がの方法と互換性がないため、中国語のオープンリレーション抽出は十分に確立されていません。中国語..言語学は、一般性、安定性、および国籍の独自の特性を保持しており、抽出戦略の策定に影響を与えるため、関係抽出に組み込む必要があります。 
[概要]中国語のオープンリレーション抽出は、中国語の言語が複雑なため、十分に認識されていません。英語の方法は、中国語の方法と互換性がありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-23">
        <br><font color="black">2020-02-23</font>
      </time>
    </span>
</section>
<!-- paper0: May I Ask Who's Calling? Named Entity Recognition on Call Center
  Transcripts for Privacy Law Compliance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_9.html">
      <font color="black">May I Ask Who's Calling? Named Entity Recognition on Call Center
  Transcripts for Privacy Law Compliance</font>
    </a>
  </h2>
  <font color="black">新しいタイプのユーザー生成テキストであるコールセンター会話での名前付きエンティティ認識の使用を調査します。これらの会話は、自発的な音声からの問題と、ノイズの多いユーザーからの他の一般的な問題に加えて、誤った認識を含む会話型の自動音声認識に新しい問題を組み合わせます。生成されたテキスト..新しい注釈付きの独自のコーパスを使用し、カスタムのコンテキスト文字列埋め込みをトレーニングし、BiLSTM-CRFを適用して、最新の結果を新しいタスクに一致させます。 
[概要]これらの会話は、自発的発話の問題と自発的発話などの問題を組み合わせたものです。その他の一般的な問題には、テキストメッセージやテキストメッセージが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Investigating African-American Vernacular English in Transformer-Based
  Text Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_10.html">
      <font color="black">Investigating African-American Vernacular English in Transformer-Based
  Text Generation</font>
    </a>
  </h2>
  <font color="black">意図に相当する並列AAVE / SAEツイートペアのデータセットを作成することにより、AAVEテキストでのGPT-2のパフォーマンスを調査します。これにより、各ペアの構文構造とAAVEまたはSAE固有の言語を分離します。 GPT-2で生成されたAAVEおよびSAEテキストは、コンテキストの厳密さと全体的な品質を比較します。各サンプルとそのGPT-2で生成されたテキストを事前にトレーニングされた感情分類子で評価すると、AAVEテキストはSAEよりも否定的な感情の分類が多くなることがわかります。 GPT-2を使用すると、一般的に両方の肯定的な感情の発生が増加します。 
[ABSTRACT] aave textは、saeよりも否定的な感情の分類を多くします。しかし、gpt -2を使用すると、一般に、両方の肯定的な感情の発生が増加します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Rethinking Self-Attention: Towards Interpretability in Neural Parsing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_11.html">
      <font color="black">Rethinking Self-Attention: Towards Interpretability in Neural Parsing</font>
    </a>
  </h2>
  <font color="black">最近の研究は、モデル表現が予測の解釈を容易にしながら、ラベル固有の情報から利益を得ることができることを示しています。さらに、私たちのモデルは、既存の研究と比較してより少ない自己注意層を必要とします。注意メカニズムは、モデルを許可しながらNLPタスクのパフォーマンスを改善しました説明し続けるために。 
[概要]モデルに必要な自己注意レイヤーは、既存の作業よりも少なくなります。これらには、ラベル注意レイヤーが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br><font color="black">2019-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Memory Attentive Fusion: External Language Model Integration for
  Transformer-based Sequence-to-Sequence Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_12.html">
      <font color="black">Memory Attentive Fusion: External Language Model Integration for
  Transformer-based Sequence-to-Sequence Model</font>
    </a>
  </h2>
  <font color="black">したがって、大量のペアデータを準備することは難しいため、外部LMに記憶されている知識を活用してseq2seqモデルを構築することが重要です。ペアデータは基本的にseq2seqモデルのトレーニングに必要ですが、外部LMは対になっていないデータのみでトレーニングされます。このペーパーでは、外部言語モデル（LM）をTransformerベースのシーケンス間（seq2seq）モデルに統合するための新しい融合方法を紹介します。 
[ABSTRACT]融合法は、seq2seqの代わりにseq2seqモデルを使用することを提案します。対になっていないスタイルでのみトレーニングできる外部lmを作成します。提案された方法は、記憶された知識を読み取るためにマルチホップ方式でターゲット注意を繰り返す注意メカニズムを組み合わせます。 lm</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Pretrained Language Model Embryology: The Birth of ALBERT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_13.html">
      <font color="black">Pretrained Language Model Embryology: The Birth of ALBERT</font>
    </a>
  </h2>
  <font color="black">これらの調査結果は、事前トレーニング済みモデルの知識が事前トレーニング中に変化することを示唆しており、事前トレーニング手順が多いからといって、必ずしもモデルに包括的な知識が提供されるとは限りません。https：//github.comで結果を再現するためのソースコードと事前トレーニング済みモデルを提供します。 / d223302 / albert-embryology ..私たちの結果は、ALBERTが事前トレーニング中にさまざまな学習速度でさまざまな音声部分（POS）のトークンを再構築および予測することを学習することを示しています。 
[ABSTRACT] albert-事前トレーニングされた言語モデルの発生学-は事前トレーナーによって研究されました。調査結果は、ランダムに初期化されたパラメーターのセットから全能性言語モデルへのステップに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Autoregressive Knowledge Distillation through Imitation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_14.html">
      <font color="black">Autoregressive Knowledge Distillation through Imitation Learning</font>
    </a>
  </h2>
  <font color="black">翻訳や要約などの典型的な言語生成タスクでは、私たちの方法は、シーケンスレベルの知識蒸留などの他の蒸留アルゴリズムよりも一貫して優れています。私たちの方法でトレーニングされた学生モデルは、ゼロからトレーニングされたモデルよりも1.4〜4.8 BLEU / ROUGEポイント高くなります。教師モデルと比較して推論速度が最大14倍に向上します。ただし、これらの向上は推論速度を妨げるという犠牲を払っており、最先端のモデルを実際の時間に敏感なモデルに展開するのは面倒です。設定。 
[ABSTRACT] state-of thegreveモデルは、実際の時間に敏感な設定で展開できます。この方法は、露出バイアスの問題に対処するように設計されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Named Entity Recognition with Attentive Ensemble of Syntactic
  Information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_15.html">
      <font color="black">Improving Named Entity Recognition with Attentive Ensemble of Syntactic
  Information</font>
    </a>
  </h2>
  <font color="black">6つの英語と中国語のベンチマークデータセットでの実験結果は、提案されたモデルの有効性を示唆し、すべての実験データセットでの以前の研究よりも優れていることを示しています。この論文では、注意深いアンサンブルを通じてさまざまなタイプの構文情報を活用することにより、NERを改善します。提案されたキー値メモリネットワーク、構文の注意、およびそのような構文情報をそれぞれエンコード、重み付け、および集約するためのゲートメカニズム。名前付きエンティティ認識（NER）は、エンティティが以下に従って抽出される可能性のあるセンテンス構文およびセマンティックプロパティに非常に敏感です。それらがどのように使用され、実行中のテキストに配置されるか。 
[概要]新しい調査によると、提案されたモデルはうまく機能していません。新しい調査によると、新しいモデルを使用してプロパティを特定できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Is Graph Structure Necessary for Multi-hop Question Answering? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_16.html">
      <font color="black">Is Graph Structure Necessary for Multi-hop Question Answering?</font>
    </a>
  </h2>
  <font color="black">最近、テキストをグラフ構造としてモデル化し、それに対処するためにグラフニューラルネットワークを導入することは、多くのNLP研究分野でトレンドになっています。グラフ構造と隣接行列の両方がタスク関連の事前知識であり、グラフの注意力であると指摘します。自己注意の特殊なケースと見なすことができます。実験と視覚化された分析は、グラフ注意またはグラフ構造全体を自己注意またはトランスフォーマーに置き換えることができることを示しています。 
[概要]この論文では、グラフ構造がマルチホップ質問応答に必要かどうかを調査します。パターン-注意関連、または構造全体を自己に置き換えることができます-注意またはトランスフォーマー</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br><font color="black">2020-04-07</font>
      </time>
    </span>
</section>
<!-- paper0: Refining Implicit Argument Annotation for UCCA -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_17.html">
      <font color="black">Refining Implicit Argument Annotation for UCCA</font>
    </a>
  </h2>
  <font color="black">提案された暗黙の引数の分類は、暗黙の役割の解釈の理論によって推進され、6つのタイプで構成されます：直示的、一般的、ジャンルベース、タイプ識別可能、非特定、および反復セット。述語-引数構造分析は中心的なコンポーネントです。テキストの表現を意味します。UCCAEWTコーパスの一部を再検討し、リファインメントレイヤーで注釈が付けられた新しいデータセットを提供し、他のスキームとの比較分析を行うことにより、設計を例示します。 
[ABSTRACT] ucca ewtコーパスの分析は、言語理解に不確実性をもたらします。しかし、一部の引数が文で明示的に言及されていないという事実は、中央言語理解にあいまいさを引き起こします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-26">
        <br><font color="black">2020-05-26</font>
      </time>
    </span>
</section>
<!-- paper0: Lexical Simplification with Pretrained Encoders -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_18.html">
      <font color="black">Lexical Simplification with Pretrained Encoders</font>
    </a>
  </h2>
  <font color="black">最近の教師なし語彙単純化アプローチは、与えられた文に関係なく複雑な単語自体にのみ依存して候補置換を生成します。これにより、必然的に多数の偽の候補が生成されます。完全に教師なしであるにもかかわらず、実験結果は、私たちのアプローチがこれらのベースラインは、言語データベースと対訳コーパスを活用し、3つの有名なベンチマークで最新の精度ポイントを12以上上回っています。具体的には、元の文の複雑な単語をマスクして、BERTに入力して予測します。マスクされたトークン。 
[要約]新しい非スーパー化アプローチは、マスクされたトークンを予測するためにbertにフィードするために、指定された文に関係なく、複雑な単語自体にのみ依存します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-14">
        <br><font color="black">2019-07-14</font>
      </time>
    </span>
</section>
<!-- paper0: Sub-Band Knowledge Distillation Framework for Speech Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_19.html">
      <font color="black">Sub-Band Knowledge Distillation Framework for Speech Enhancement</font>
    </a>
  </h2>
  <font color="black">次に、教師モデルの指導の下で、すべてのサブバンドで機能する一般的なサブバンド拡張モデル（学生モデル）をトレーニングします。モデルパラメータの数と計算の複雑さを増やさずに、学生モデルのパフォーマンスがさらに向上します。 。これらの教師モデルは、独自のサブバンドの処理に専念しています。 
[概要]メソッドを使用して、全周波数帯域を複数のサブバンドに探索します。サブバンドごとにエリートレベルのサブバンド拡張モデルを事前トレーニングします。教師モデルのガイダンスの下で、一般的なサブバンドをトレーニングします。 -バンド。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-29">
        <br><font color="black">2020-05-29</font>
      </time>
    </span>
</section>
<!-- paper0: Uncovering Latent Biases in Text: Method and Application to Peer Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_20.html">
      <font color="black">Uncovering Latent Biases in Text: Method and Application to Peer Review</font>
    </a>
  </h2>
  <font color="black">合成データや二次データに依存する代わりに、「グラウンドトゥルース」バイアスを推測してフレームワークを評価できるアプリケーションを特定します。次に、特定戦略を形式化して、推定バイアスをサブグループメンバーシップインジケーターの可視性に因果関係を関連付けます。アイデンティティ隠蔽ポリシーの変更前後の期間から..「グラウンドトゥルース」として機能するレビュー評価にバイアスの証拠を示し、提案されたフレームワークがにアクセスすることなくレビューテキストからこれらのバイアスを正確に検出することを示しますレビューの評価。 
[概要]「説得力のある」バイアスを推測できるアプリケーションを特定します。「グラウンドトゥルース」として機能するレビュー評価にバイアスの証拠を示します。提案されたフレームワークは、レビューテキストからこれらのバイアスを正確に検出します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Unbabel's Participation in the WMT20 Metrics Shared Task -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_21.html">
      <font color="black">Unbabel's Participation in the WMT20 Metrics Shared Task</font>
    </a>
  </h2>
  <font color="black">また、セグメントレベルの予測をドキュメントレベルのスコアに変換する簡単な手法を提案します。したがって、これらのトラックでのモデルの結果を、前年度のテストセットを参照して示します。全体として、システムは以前のテストセットのすべての言語ペアは、多くの場合、新しい最先端技術を設定します。 
[概要]すべての言語ペアのトラックと、「メトリックとしてのqe」トラックに参加します。さまざまな人間が生成した品質スコアと相対ランクでトレーニングされた新しいランキングモデルで回帰するように、いくつかの推定モデルをトレーニングします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Making the Best Use of Review Summary for Sentiment Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_22.html">
      <font color="black">Making the Best Use of Review Summary for Sentiment Analysis</font>
    </a>
  </h2>
  <font color="black">多くのレビューWebサイトでは、ユーザーは完全なレビューに加えて要約を入力できます。直感的に、要約情報はレビュー感情分析に追加の利点をもたらす可能性があります。経験的な結果は、レビュー中心のモデルがユーザー作成の要約をより有効に活用できることを示しています。レビュー感情分析用であり、ユーザーの要約が自動要約システムによって生成された要約に置き換えられる場合、既存の方法と比較してより効果的です。 
[概要]多くのレビューウェブサイトでは、ユーザーは完全なレビューに加えて概要を入力できます。多くのウェブサイトでは、ユーザーはレビューの形式を入力できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-07">
        <br><font color="black">2019-11-07</font>
      </time>
    </span>
</section>
<!-- paper0: Tilde at WMT 2020: News Task Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_23.html">
      <font color="black">Tilde at WMT 2020: News Task Systems</font>
    </a>
  </h2>
  <font color="black">さらに、さまざまな並列および単一言語のデータ選択スキームと、サンプリングされた逆翻訳を実験します。最終モデルは、右から左への再ランク付けを特徴とするTransformerベースモデルとTransformerビッグモデルのアンサンブルです。提出物に従います。前年から、マリアンの機械翻訳ツールキットを使用してトレーニングする、形態学的に動機付けられたサブワードユニットベースのTransformerベースモデルとなるベースラインシステムを構築します。 
[ABSTRACT]最終モデルはトランスベースとトランスフォーマーのアンサンブルです。私たちは前年度からの提出に従います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Explainable Automated Coding of Clinical Notes using Hierarchical
  Label-wise Attention Networks and Label Embedding Initialisation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_24.html">
      <font color="black">Explainable Automated Coding of Clinical Notes using Hierarchical
  Label-wise Attention Networks and Label Embedding Initialisation</font>
    </a>
  </h2>
  <font color="black">このようなコーディングは通常、病院で手動で行われますが、自動化されて医療コーディングの効率と精度が向上する可能性があります。自動化された医療コーディングのディープラーニングに関する最近の研究により、有望なパフォーマンスが達成されました。臨床ノートの診断または手続き型コーディングは、コーディングされたものを導き出すことを目的としています。患者に関する疾患関連情報の要約。 
[概要]これらのモデルは通常、病院で手動で実行されますが、自動化することもできます。これらのモデルは、医療コーディングの効率と精度を向上させるために使用できます。ただし、これらのモデルの説明性は通常不十分であり、臨床診療のサポートに自信を持って使用できません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Dual Attention Model for Citation Recommendation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_25.html">
      <font color="black">Dual Attention Model for Citation Recommendation</font>
    </a>
  </h2>
  <font color="black">ニューラルネットワークは、3つの入力（ローカルコンテキストワード、セクション、構造コンテキスト）の埋め込みと、コンテキストに表示されるターゲット引用との類似性を最大化するように設計されています。この研究では、次のような新しい埋め込みベースのニューラルネットワークを提案します。原稿作成時に引用を推奨する「引用推奨デュアルアテンションモデル（DACR）」。たとえば、ユーザーが書いている論文のセクションを考慮せず、引用を見つける必要がある場合、それらの間の関連性ローカルコンテキスト内の単語（引用を説明するテキストスパン）、またはローカルコンテキストからの各単語の重要性。 
[概要]私たちの方法は、学術論文に十分な引用を推奨するのに適しています。新しい方法は、非社会的情報の3つの次元を使用します。これらには、ローカルコンテキスト、構造コンテキスト、およびユーザーが作業しているセクションの単語が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-01">
        <br><font color="black">2020-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: CoSimLex: A Resource for Evaluating Graded Word Similarity in Context -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_26.html">
      <font color="black">CoSimLex: A Resource for Evaluating Graded Word Similarity in Context</font>
    </a>
  </h2>
  <font color="black">タスクと評価のメトリックを定義し、データセット収集方法の概要を示し、これまでのデータセットのステータスを説明します。SimLex-999の標準のペアワイズ類似性タスクに基づいて、コンテキスト依存の類似性測定を提供します。単語の意味の離散的な違いだけでなく、意味のより微妙で段階的な変化もカバーします。また、リソースの豊富な言語（英語）だけでなく、リソースの少ない言語も多数取り上げています。このペーパーでは、このギャップを埋めることを目的とした新しいデータセットCoSimLexを構築する取り組みについて説明します。 
[ABSTRACT]メトリクスは類似性の判断に基づいていますが、文脈を無視します。語義の曖昧性解消のための標準的なタスクは文脈を考慮しますが、意味の類似性の継続的な測定を提供しません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-11">
        <br><font color="black">2019-12-11</font>
      </time>
    </span>
</section>
<!-- paper0: Sparse and Continuous Attention Mechanisms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_27.html">
      <font color="black">Sparse and Continuous Attention Mechanisms</font>
    </a>
  </h2>
  <font color="black">対照的に、有限領域の場合、softmaxのまばらな代替案に関する最近の研究があります（たとえば、この論文では、その機能を2つの方向に拡張します。最初に、alpha-entmaxを連続領域に拡張し、ツァリス統計と変形指数型分布族とのリンクを明らかにします。 ..次に、連続領域注意メカニズムを導入し、{1,2}のアルファの効率的な勾配逆伝播アルゴリズムを導出します。
[ABSTRACT]は、通常の注意メカニズム、連続機械機械machine.itを支持し、ユニバーサルユニバーサルユニバーサルのパターンに基づいています。注意。一連の同様のことになると、アップグレードは簡単です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-12">
        <br><font color="black">2020-06-12</font>
      </time>
    </span>
</section>
<!-- paper0: Named Entity Recognition for Social Media Texts with Semantic
  Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_28.html">
      <font color="black">Named Entity Recognition for Social Media Texts with Semantic
  Augmentation</font>
    </a>
  </h2>
  <font color="black">特に、大規模コーパスから拡張意味情報を取得し、その情報をエンコードおよび集約するための注意深い意味拡張モジュールとゲートモジュールをそれぞれ提案します。英語と中国語から収集された3つのベンチマークデータセットで広範な実験が実行されます。ソーシャルメディアプラットフォーム。結果は、3つのデータセットすべてにわたる以前の研究に対するアプローチの優位性を示しています。豊富なセマンティック情報が事前にトレーニングされた単語の埋め込みに暗黙的に保存されていることを考えると、セマンティック拡張の潜在的な理想的なリソースです。 
[概要] nerやソーシャルメディアなどのソーシャルメディアサイトは、ソーシャルメディアテキストのnerへのニューラルベースのアプローチを開発しました。結果は、3つのデータセットすべてにわたる以前の研究へのアプローチの利点を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-Supervised Speech Recognition via Graph-based Temporal
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_29.html">
      <font color="black">Semi-Supervised Speech Recognition via Graph-based Temporal
  Classification</font>
    </a>
  </h2>
  <font color="black">結果は、このアプローチが、スコアが関連付けられた疑似ラベルのN-bestリストを効果的に活用し、標準の疑似ラベルを大幅に上回り、ASRの結果がN-bestリストの最良の仮説であるオラクル実験に近いことを示しています。手動で選択されます。ただし、N-bestリストの代替ASR仮説は、ラベルなしの音声発話に対してより正確なラベルを提供し、シードASRモデルの不確実性を反映することもできます。新しく提案されたグラフベースの時間分類（GTC）の目的は疑似ラベルのN個のベストリストから生成されるWFSTベースの監視を使用したセルフトレーニングに適用されます。 
[概要]このアプローチの有効性は、疑似ラベルの精度に大きく依存します。ただし、それ以外の場合は、1-最良のasrマージンのみが使用されます。代わりに、Tシャツに基づくTシャツシステムから学習するために使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: "where is this relationship going?": Understanding Relationship
  Trajectories in Narrative Text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_30.html">
      <font color="black">"where is this relationship going?": Understanding Relationship
  Trajectories in Narrative Text</font>
    </a>
  </h2>
  <font color="black">これら2つのタスクを通じて人間の社会的関係の調査を容易にするために、新しいデータセットであるSocial Narrative Treeを構築します。これは、毎日のさまざまな社会的相互作用を文書化した1250のストーリーで構成されます。言語モデルを使用してベースラインパフォーマンスを確立し、精度が大幅に低下します。具体的には、Relationship Outlook PredictionMCQとResolutionPredictionMCQの2つの評価タスクを提案します。 
[ABSTRACT]社会構造は、人間関係がどのように進化するかについての豊富な常識知識を生み出すために織り交ぜられる多数の社会要素をエンコードします。結果は、モデルが複雑な人間関係を理解するために構文的および意味的信号を超えて見る必要があることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Emformer: Efficient Memory Transformer Based Acoustic Model For Low
  Latency Streaming Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_31.html">
      <font color="black">Emformer: Efficient Memory Transformer Based Acoustic Model For Low
  Latency Streaming Speech Recognition</font>
    </a>
  </h2>
  <font color="black">ベンチマークLibriSpeechデータで実験を実行します。平均レイテンシ960ミリ秒で、EmformerはテストクリーンでWER $ 2.50 \％$、テストその他で$ 5.62 \％$を取得します。Emformerはトレーニングで並列ブロック処理を適用して低をサポートします。レイテンシーモデル。 
[概要]平均レイテンシが80ミリ秒の低レイテンシシナリオの場合、emformerは$ 2. 50-クリーン、テストで$ 5. 62 /％$-その他。同じレイテンシシナリオで、emformerはwer $ 3.01を達成します。 7.999ドルとテストで$-その他</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Measuring non-trivial compositionality in emergent communication -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_32.html">
      <font color="black">Measuring non-trivial compositionality in emergent communication</font>
    </a>
  </h2>
  <font color="black">青い円）は、その構成要素の意味の共通部分に要約されます（たとえば、これらの結果は、NTCの出現のモデル化の進展を妨げる可能性のある創発的コミュニケーション研究の重要な制限を強調しています。彼らは重要な構成性を構成性の失敗として扱います。
[要約]複雑な信号（例：apple）の意味がntcを検出できない場合、プロトコルは自明ではない構成性（ntc）です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Combining Self-Training and Self-Supervised Learning for Unsupervised
  Disfluency Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/cs.CL/paper_33.html">
      <font color="black">Combining Self-Training and Self-Supervised Learning for Unsupervised
  Disfluency Detection</font>
    </a>
  </h2>
  <font color="black">一般的に使用される英語の配電盤テストセットの実験結果は、私たちのアプローチが、コンテキスト化された単語の埋め込みを使用する以前の最先端の教師ありシステムと比較して競争力のあるパフォーマンスを達成することを示しています（たとえば、この作業では、潜在的に可能性のある教師なし学習パラダイムを探索します安価で入手しやすいラベルのないテキストコーパスを使用します。BERTおよびELECTRA）。 
[要約]この問題を軽減するためのいくつかの提案がありましたが、それでも人間の注釈付きコーパスが必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: GANs & Reels: Creating Irish Music using a Generative Adversarial
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.AS/paper_0.html">
      <font color="black">GANs & Reels: Creating Irish Music using a Generative Adversarial
  Network</font>
    </a>
  </h2>
  <font color="black">この論文では、反復成分のない生成的敵対的ネットワークを使用したアルゴリズムによるメロディ生成の方法を示します。音楽生成は、モデルが本物の響きのメロディの作成に役立つシーケンス情報を学習するリカレントニューラルネットワークを使用して正常に実行されました。拡張された畳み込みとタワーを備えたDC-GANアーキテクチャを使用して、シーケンシャル情報を空間画像情報としてキャプチャし、アイルランドの伝統的なリールなどの固定長のメロディ形式で長距離の依存関係を学習します。 
[要約]リカレントニューラルネットワークを使用して紙の生成が正常に実行されました。モデルは、本物のサウンド情報の作成に役立つ情報を学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Progressive Voice Trigger Detection: Accuracy vs Latency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.AS/paper_1.html">
      <font color="black">Progressive Voice Trigger Detection: Accuracy vs Latency</font>
    </a>
  </h2>
  <font color="black">2段階のアーキテクチャを使用して、テストセットで検出された真のトリガーのわずか3％の決定を遅らせることで、本人拒否率を66％向上させることができますが、増加はごくわずかです。レイテンシー..プログレッシブボイストリガー検出により、明確なトリガー候補をすばやく受け入れることでレイテンシーと精度をトレードオフできますが、より多くのコンテキストを待って、より限界的な例を受け入れるかどうかを決定します。ただし、毎回より多くのオーディオを聞くのを待つと、待ち時間の増加。 
[概要]この作業の主なアイデアは、トリガーフレーズの直後に続く単語の情報を活用することです。ただし、毎回より多くの音声で聞くのを待つと、待ち時間が長くなります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervised Pre-training Reduces Label Permutation Instability of
  Speech Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.AS/paper_2.html">
      <font color="black">Self-supervised Pre-training Reduces Label Permutation Instability of
  Speech Separation</font>
    </a>
  </h2>
  <font color="black">いくつかのタイプの自己監視タスクの中で、音声強調ベースの事前トレーニングタスクは、実験で大きな効果を示します。この論文では、自己監視事前トレーニングを利用して、ラベルの順列を安定させます。正しいラベルの順列を安定して選択する方法長年の問題です。 
[概要]この論文では、ラベルの順列を安定させるために、自己教師あり事前トレーニングを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: SNR-Based Teachers-Student Technique for Speech Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.AS/paper_3.html">
      <font color="black">SNR-Based Teachers-Student Technique for Speech Enhancement</font>
    </a>
  </h2>
  <font color="black">提案手法を評価するために、公開データセットに基づいてSNRが-20dBから20dBのデータセットを構築しました。具体的には、この手法は複数の教師モデルと生徒モデルで構成されています。次に、さまざまな教師モデルを選択して監視します。トレーニングデータのSNRに従った学生モデルのトレーニング。 
[概要]この問題に対処するために、snrベースの教師-学生の技術と時間-ドメインu-ネットを統合する方法。互いに一致しない複数の小さな範囲のsnrの下で教師モデルをテストします。特定のsnr範囲内で音声強調を十分に実行する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-29">
        <br><font color="black">2020-05-29</font>
      </time>
    </span>
</section>
<!-- paper0: The ins and outs of speaker recognition: lessons from VoxSRC 2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.AS/paper_4.html">
      <font color="black">The ins and outs of speaker recognition: lessons from VoxSRC 2020</font>
    </a>
  </h2>
  <font color="black">人気のあるResNetアーキテクチャのバリエーションを話者認識に利用し、さまざまな損失関数とトレーニングパラメータを使用して広範な実験を実行します。Interspeech2020のVoxCeleb話者認識チャレンジ（VoxSRC）は、有名人の演奏を含む話者認識システムの挑戦的な評価を提供します映画のさまざまな部分..私たちの訓練されたモデルは、より軽いモデルと単純なパイプラインで、ほとんどの既存の作品に対する改善を示しています。 
[概要]この作業の目標は、これらの困難な環境で記録された発話の堅牢な話者認識です。限られた時間とリソースで強力なモデルをトレーニングできる効率的なトレーニングフレームワークを最適化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: UNetGAN: A Robust Speech Enhancement Approach in Time Domain for
  Extremely Low Signal-to-noise Ratio Condition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.AS/paper_5.html">
      <font color="black">UNetGAN: A Robust Speech Enhancement Approach in Time Domain for
  Extremely Low Signal-to-noise Ratio Condition</font>
    </a>
  </h2>
  <font color="black">この結果は、音声品質が大幅に向上し、SEGAN、cGAN fo SE、位相敏感スペクトル近似コスト関数を使用した双方向LSTM（PSA-BLSTM）、Short-に関するWave-U-Netなどの代表的な深層学習モデルを大幅に上回っていることを示しています。時間客観的了解度（STOI）と音声品質の知覚評価（PESQ）。非常に低い信号対雑音比（SNR）条件での音声強調は非常に困難な問題であり、以前の研究ではほとんど調査されていません。パブリックベンチマークでの低SNR条件（最大-20dB）でのUNetGAN。 
[概要]ジェネレータネットワークは、au-netのような構造を採用し、ボトルネックに拡張畳み込みを採用しています。結果は、音声品質が大幅に向上することを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: DeviceTTS: A Small-Footprint, Fast, Stable Network for On-Device
  Text-to-Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.AS/paper_6.html">
      <font color="black">DeviceTTS: A Small-Footprint, Fast, Stable Network for On-Device
  Text-to-Speech</font>
    </a>
  </h2>
  <font color="black">経験はWORLDとLPCNetボコーダーで行われます。ご存知のとおり、モデルサイズはオンデバイスTTSの重要な要素です。DeviceTTSの場合、ディープフィードフォワードシーケンシャルメモリネットワーク（DFSMN）が基本コンポーネントとして使用されます。 
[ABSTRACT] devicettsは、オンデバイスデバイス用に小さなフットプリント、高速、安定したネットワークを使用します。これらには、音声品質を向上させるために使用できる「devicetts」用のネットワークが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: The IQIYI System for Voice Conversion Challenge 2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.AS/paper_7.html">
      <font color="black">The IQIYI System for Voice Conversion Challenge 2020</font>
    </a>
  </h2>
  <font color="black">その中で、最も良い結果は、タスク2の類似性評価、ASVベースの客観的評価で2番目、主観的評価で5番目です。評価結果は、このシステムがより良い音声変換効果を達成できることを示しています。 Melの特徴は、改良されたプロソディタコトロンモデルによって計算されます。 
[概要]競技会では、各対象話者は70文です。たとえば、24kのサンプリングレートではなく16kの音声を使用する場合、各音声は2,000文であり、変換結果は比較的良好です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Audio Embeddings with User Listening Data for Content-based
  Music Recommendation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.AS/paper_8.html">
      <font color="black">Learning Audio Embeddings with User Listening Data for Content-based
  Music Recommendation</font>
    </a>
  </h2>
  <font color="black">提案されたシステムは、数百万のユーザーとトラックでテストされたコンテンツベースの音楽レコメンデーションで最先端のパフォーマンスを生み出します。ユーザーの埋め込みとユーザーの好きなトラックと嫌いなトラックからのオーディオデータを使用して、トラックごとにオーディオの埋め込みを取得できます。シャムネットワークでメトリック学習を使用します。また、音楽ジャンル分類タスクの機能としてオーディオ埋め込みを抽出します。 
[概要]新しいトラックの場合、トラックの音声埋め込みとユーザー埋め込みの類似性を計算することで、推奨する最適なユーザーグループを決定できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Recent Developments on ESPnet Toolkit Boosted by Conformer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.AS/paper_9.html">
      <font color="black">Recent Developments on ESPnet Toolkit Boosted by Conformer</font>
    </a>
  </h2>
  <font color="black">私たちの実験は、さまざまなトレーニングのヒントと、さまざまなタスクでConformerを使用して得られる重要なパフォーマンス上の利点を明らかにしています。事前にトレーニングされたモデルを使用して、上記のすべてのタスクに対してオープンソースと公開されているコーパスを使用してオールインワンレシピをリリースする準備をしています。結果は競争力があり、現在の最先端のTransformerモデルを上回っています。 
[概要]幅広いエンドツーエンドの音声処理アプリケーションの結果。これらには、自動音声認識（asr）、音声翻訳（st）、音声ヒント（ss）が含まれます。これらの結果はオープンであるか、現在のモデルよりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Sub-Band Knowledge Distillation Framework for Speech Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.AS/paper_10.html">
      <font color="black">Sub-Band Knowledge Distillation Framework for Speech Enhancement</font>
    </a>
  </h2>
  <font color="black">モデルパラメータの数と計算の複雑さを増すことなく、学生モデルのパフォーマンスがさらに向上します。これらの教師モデルは、独自のサブバンドの処理に専念しています。次に、教師モデルのガイダンスの下で、一般的なサブバンドをトレーニングします。すべてのサブバンドで機能する拡張モデル（学生モデル）。 
[概要]メソッドを使用して、全周波数帯域を複数のサブバンドに探索します。サブバンドごとにエリートレベルのサブバンド拡張モデルを事前トレーニングします。教師モデルのガイダンスの下で、一般的なサブバンドをトレーニングします。 -バンド。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-29">
        <br><font color="black">2020-05-29</font>
      </time>
    </span>
</section>
<!-- paper0: ACCDOA: Activity-Coupled Cartesian Direction of Arrival Representation
  for Sound Event Localization and Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.AS/paper_11.html">
      <font color="black">ACCDOA: Activity-Coupled Cartesian Direction of Arrival Representation
  for Sound Event Localization and Detection</font>
    </a>
  </h2>
  <font color="black">ACCDOA表現を使用すると、単一のターゲットでSELDタスクを解決でき、2つの利点があります。目的のバランスを取る必要がないこととモデルサイズの増加です。単一のネットワークでの2分岐表現では、2つの目的のバランスを取る方法を決定する必要があります。最適化中..ACCDOAベースのSELDシステムは、ローカリゼーションと場所に依存する検出の点でも、最先端のSELDシステムよりも優れたパフォーマンスを発揮しました。 
[ABSTRACT]従来のnnベースの方法では、サウンドイベントの検出に2つのブランチ、sedターゲットと到着方向（doa）ターゲットを使用します。各タスク専用の2つのネットワークを使用すると、ネットワーク表現が増加します。したがって、accdoa表現を使用すると解決できます。単一のターゲットを持つseldタスク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Playing a Part: Speaker Verification at the Movies -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.AS/paper_12.html">
      <font color="black">Playing a Part: Speaker Verification at the Movies</font>
    </a>
  </h2>
  <font color="black">VoxMoviesには、さまざまな感情、アクセント、およびバックグラウンドノイズを伴う発話が含まれているため、VoxCelebなどの現在の話者認識データセットのインタビュースタイルの感情的に穏やかな発話とはまったく異なるドメインで構成されます。 （ii）多数のドメイン適応評価セットを提供し、これらの評価ペアで最先端の話者認識モデルのパフォーマンスをベンチマークします。この新しいデータでは、話者検証と識別パフォーマンスの両方が急激に低下することを示しています。ドメイン間でモデルを転送する際の課題を示します。そして最後に（iii）単純なドメイン適応パラダイムがパフォーマンスを改善することを示しますが、まだ改善の余地があります。この作業の目標は、映画の音声セグメントで人気のある話者認識モデルのパフォーマンスを調査することです。キャラクターを演じるために彼らの声を偽装します。 
[概要]約4000のムービークリップから856のIDの音声を含む、斬新でやりがいのある話者認識データセットを収集します。この新しいデータで両方の話者検証を行い、モデルをキャラクター間で転送する際の課題を示しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: FullSubNet: A Full-Band and Sub-Band Fusion Model for Real-Time
  Single-Channel Speech Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.AS/paper_13.html">
      <font color="black">FullSubNet: A Full-Band and Sub-Band Fusion Model for Real-Time
  Single-Channel Speech Enhancement</font>
    </a>
  </h2>
  <font color="black">サブバンドモデルは正反対です。ただし、信号の定常性をモデル化し、ローカルスペクトルパターンに対応する機能がありません。フルバンドモデルは、グローバルスペクトルコンテキストと長距離クロスバンド依存関係をキャプチャできます。 
[ABSTRACT]フルバンドとサブバンドは、フルバンドとノイズの多いビーコン機能を入力するモデルを指します。提案されたフルサブネットは、実際のトレーニングを使用して、2つのタイプのモデルの利点を統合します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-Supervised Speech Recognition via Graph-based Temporal
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.AS/paper_14.html">
      <font color="black">Semi-Supervised Speech Recognition via Graph-based Temporal
  Classification</font>
    </a>
  </h2>
  <font color="black">新しく提案されたグラフベースの時間分類（GTC）目標は、WFSTベースの監視による自己トレーニングに適用されます。これは疑似ラベルのNベストリストから生成されます。結果は、このアプローチがN-を効果的に活用できることを示しています。スコアが関連付けられた疑似ラベルの最良のリスト。標準の疑似ラベルを大幅に上回り、ASRの結果は、N個の最良のリストの最良の仮説が手動で選択されるオラクル実験に近いものです。ただし、の代替ASR仮説N-bestリストは、ラベルのない音声発話に対してより正確なラベルを提供し、シードASRモデルの不確実性を反映することもできます。 
[概要]このアプローチの有効性は、疑似ラベルの精度に大きく依存します。ただし、それ以外の場合は、1-最良のasrマージンのみが使用されます。代わりに、Tシャツに基づくTシャツシステムから学習するために使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: Emformer: Efficient Memory Transformer Based Acoustic Model For Low
  Latency Streaming Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-30/eess.AS/paper_15.html">
      <font color="black">Emformer: Efficient Memory Transformer Based Acoustic Model For Low
  Latency Streaming Speech Recognition</font>
    </a>
  </h2>
  <font color="black">960ミリ秒の平均遅延の下で、Emformerはテストクリーンで$ 2.50 \％$、テストその他で$ 5.62 \％$を取得します。強力なベースライン拡張メモリトランスフォーマー（AM-TRF）と比較すると、Emformerは$ 4.6 $倍のトレーニングスピードアップを取得します。デコードでの$ 18 \％$相対リアルタイム係数（RTF）の削減と、テストクリーンでの相対WER削減$ 17 \％$、テストその他での$ 9 \％$ ..同じレイテンシとモデルのLSTMベースラインとの比較サイズ、Emformerは、test-cleanとtest-otherでそれぞれ相対的なWER削減$ 9 \％$と$ 16 \％$を取得します。 
[概要]平均レイテンシが80ミリ秒の低レイテンシシナリオの場合、emformerは$ 2. 50-クリーン、テストで$ 5. 62 /％$-その他。同じレイテンシシナリオで、emformerはwer $ 3.01を達成します。 7.999ドルとテストで$-その他</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
