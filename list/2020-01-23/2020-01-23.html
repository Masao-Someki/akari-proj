<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<title>Akari-2020-01-23の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
  <div class="header-logo">
    <a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
  </div>
</header>
<input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">

<div class="menubar">
<span class="bar"></span>
<span class="bar"></span>
<span class="bar"></span>
</div>

<ul>
<li><a id="home" href="../../index.html">Home</a></li>
<li><a id="about" href="../../teamAkariとは.html">About</a></li>
<li><a id="contact" href="../../contact.html">Contact</a></li>
<li><a id="contact" href="../../list/newest.html">New Papers</a></li>
<li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
</ul>

</label>
<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Non-Negative Matrix Factorization-Convolutional Neural Network (NMF-CNN)
  For Sound Event Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-23/cs.SD/paper_0.html">
      Non-Negative Matrix Factorization-Convolutional Neural Network (NMF-CNN)
  For Sound Event Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      検証結果を他の参加者と比較することにより、提案されたシステムは今年のタスク4チャレンジで19チーム（ベースラインシステムを含む）で8位にランクされました。そのような統合の重要なアイデアは、NMFを使用しておおよその強力なラベルを提供することですこのような統合により、ベースラインシステムと比較してより高いイベントベースのF1スコアを達成できました（評価データセット：30.39％対23.7％、検証データセット：31％対25.8％）。 
[ABSTRACT]ディープラーニングシステムは、非負行列因子分解と畳み込みニューラルネットワークを統合します。このような統合により、ベースラインシステムと比較して、f1ベースのより高いイベントを達成できました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br>2020-01-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Representation Disentanglement using Cross Domain Features
  and Adversarial Learning in Variational Autoencoder based Voice Conversion -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-23/cs.SD/paper_1.html">
      Unsupervised Representation Disentanglement using Cross Domain Features
  and Adversarial Learning in Variational Autoencoder based Voice Conversion
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本論文では、敵対的学習の概念を組み込むことにより、CDVAE-VCフレームワークを拡張し、もつれ解除の程度をさらに高め、それにより変換音声の品質と類似性を改善します。類似性スコアは、提案された方法の有効性を示しています。より具体的には、最初に生成的敵対ネットワーク（GAN）をCDVAE-VCに組み込むことの有効性を調査します。 
[要旨]成功は、より複雑な潜在表現からもたらされたと考えています。まず、cdvae-vcを使用したウイルス（gans）の有効性を調査します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br>2020-01-22
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: RETRO: Relation Retrofitting For In-Database Machine Learning on Textual
  Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-23/cs.CL/paper_0.html">
      RETRO: Relation Retrofitting For In-Database Machine Learning on Textual
  Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      どの単語が同じ列に表示されるか、または相互に関連するか。学習問題に対するさまざまなハイパーパラメータの影響を調査し、それらすべてに対して適切な設定を導き出します。機械学習（ML）タスク。 
[概要]データベース内のテキストの数値表現を学習する新しいシステムを提案します。これらには、単語の埋め込み、単語の埋め込みによってエンコードされた豊富な情報が含まれます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-28">
        <br>2019-11-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Domain Adaptation for Neural Machine Translation with
  Iterative Back Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-23/cs.CL/paper_1.html">
      Unsupervised Domain Adaptation for Neural Machine Translation with
  Iterative Back Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ドメイン内の単一言語データに反復逆翻訳（IBT）トレーニングスキームを適用します。これは、TransformerベースのNMTモデルを繰り返し使用して、オンザフライで1つの翻訳方向にドメイン内の擬似並列文のペアを作成し、それらを使用してトレーニングしますさらに、ドイツ語から英語およびルーマニア語から英語の言語ペアで利用可能な監視対象のドメイン外データがある場合、パフォーマンスをさらに強化し、最大+19.31 BLEUの改善を得ることができます。最強のベースライン、および適応されていないモデルに対する+47.69 BLEU増分。教師なしデータを使用しないドイツ語から英語への翻訳タスクの3つのドメインで評価され、この単純な手法のみ（ドメイン外の並列データなし）がすでにすべてを超えることができます以前のドメイン適応手法---最強の以前の手法よりも最大+9.48 BLEU、未適応のベースラインより最大+27.77 BLEU。 
[要約]教師データなしのドイツ語から英語への翻訳タスク、この単純な手法だけで以前のシステムをすべて超えることができます。メソッドのみ（ドメイン外の並列データなし）は既に以前のシステムを超えることができます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br>2020-01-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Neural Architecture for Person Ontology population -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-23/cs.CL/paper_2.html">
      A Neural Architecture for Person Ontology population
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、エンティティ分類と関係抽出のニューラルモデルを使用して、非構造化データから個人オントロジーグラフを自動的に生成するシステムを提示します。人工ニューラルネットワークにより、エンティティ認識、エンティティ分類、および関係抽出が改善されましたが、オントロジーは、概念間のセマンティック関係の固定セットを必要とするため、主に手動プロセスのままです。これらのタスクの新しいデータセットを導入し、結果を議論します。 
[概要]オントロジーの作成は、概念間のセマンティック関係の固定セットを必要とするため、主に手動プロセスのままです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br>2020-01-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: TLT-school: a Corpus of Non Native Children Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-23/cs.CL/paper_3.html">
      TLT-school: a Corpus of Non Native Children Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文は、英語とドイツ語の両方を学習している学生のパフォーマンスを評価するために北イタリアの学校で収集された音声発話のコーパス「TLT-school」について説明します。コーパスの一部は、特に非ネイティブの音声認識と第二言語習熟度の自動評価。発話の手動転写に使用されるガイドラインと手順、および当社が開発した自動音声認識システムによって達成された結果について詳しく説明します。 
[要旨]コーパスは、2017年と2018年に9歳から16歳までの学生から記録されました。2017年に記録されたすべての発話は、手動で書き写されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br>2020-01-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Understanding Image Captioning Models beyond Visualizing Attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-23/cs.CL/paper_4.html">
      Understanding Image Captioning Models beyond Visualizing Attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は、キャプションの各単語のピクセル単位の画像説明と言語説明を同時に提供します。実験分析は、画像キャプションの注意モデルを理解するための説明方法の強さを示します。注意よりも正確さは、第二に、画像コンテンツでサポートされていないオブジェクトの単語を識別でき、第三に、偏りを解消してモデルを改善するためのガイダンスを提供できます。 
[要約]分析は、画像キャプション注意モデルを理解するための説明方法の強さを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-04">
        <br>2020-01-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Joint Entity Extraction and Assertion Detection for Clinical Text -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-23/cs.CL/paper_5.html">
      Joint Entity Extraction and Assertion Detection for Clinical Text
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      陰性の医学的所見は臨床報告で広く見られますが、肯定的な所見からそれらを区別することは情報抽出にとって難しい課題です。このアーキテクチャは、以前のルールベースおよび機械学習ベースのシステムよりもかなり優れています。問題を解決し、エンティティと否定を一緒に抽出する新しいエンドツーエンドの神経モデルを提示します。 
[概要]条件付きソフトマックス共有デコーダーアーキテクチャは、差別化の増加の問題を克服するように設計
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-13">
        <br>2018-12-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Representation Disentanglement using Cross Domain Features
  and Adversarial Learning in Variational Autoencoder based Voice Conversion -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-23/cs.CL/paper_6.html">
      Unsupervised Representation Disentanglement using Cross Domain Features
  and Adversarial Learning in Variational Autoencoder based Voice Conversion
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、敵対的学習の概念を組み込むことにより、CDVAE-VCフレームワークを拡張し、もつれ解除の程度をさらに増加させ、それにより変換された音声の品質と類似性を改善します。ドメインVAE-VC（CDVAE-VC）フレームワークは、VAE-VCのパフォーマンスを改善するために、さまざまな特性の音響特性を利用しました。実験結果は、学習された潜在表現のもつれの程度がGANとスピーカー分類。 
[要旨]成功は、より複雑な潜在表現からもたらされたと考えています。まず、cdvae-vcを使用したウイルス（gans）の有効性を調査します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br>2020-01-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Normalization of Input-output Shared Embeddings in Text Generation
  Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-23/cs.CL/paper_7.html">
      Normalization of Input-output Shared Embeddings in Text Generation
  Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ニューラルネットワークベースのモデルは、さまざまな自然言語処理タスクの最先端のモデルでしたが、ネットワークの入力および出力ディメンションの問題は、特にテキスト生成タスク（たとえば、これらの方法はほぼ計算コストがかからず、他の埋め込み手法と組み合わせることができ、最先端のニューラルネットワークモデルに適用すると優れた効果を示します。線形代数と統計理論に基づいて、このペーパーでは、既存の入力出力の埋め込み重み共有方法は、入力/出力の重み共有埋め込みを改善する方法を提起し、その中で埋め込み重み行列の正規化の方法は最高のパフォーマンスを示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br>2020-01-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On the evolution of word usage of classical Chinese poetry -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-23/cs.CL/paper_8.html">
      On the evolution of word usage of classical Chinese poetry
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      距離行列に基づく系統解析は、異なるタイプの古典的な中国詩の進化的連鎖がそれらの年代順と一致していることを示唆しており、文字頻度には、さまざまなタイプの古典的な中国詩の間の進化的連鎖を推測するのに役立つ系統発生情報が含まれていることを示唆しています。この研究で行われた統計分析は、一般的な中国文学のデータセットを分析するために一般化することができます。そのような分析は、一般的な中国文学の進化的連鎖についての定量的洞察を提供できます。 
[ABSTRACT]古典的な中国詩の進化的連鎖に関する定量的調査は限られています。キャラクター選好の一般的なパターンの分析は、漢字の使用の減少傾向を示唆しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2015-09-10">
        <br>2015-09-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Contextualized Embeddings in Named-Entity Recognition: An Empirical
  Study on Generalization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-23/cs.CL/paper_9.html">
      Contextualized Embeddings in Named-Entity Recognition: An Empirical
  Study on Generalization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CoNLL03でトレーニングされたモデルの場合、言語モデルのコンテキスト化により、ドメイン内で最大+ 12％の相対マイクロF1スコアが最大+ 13％増加し、目に見えない言及の検出に特に有益であることがわかります。 -WNUTデータセットのドメイン。ただし、標準の英語ベンチマークは、列車の言及とテストの言及の間に非現実的な語彙の重複があるため、コンテキスト機能よりも語彙の重要性を過大評価しています。 
[ABSTRACT]これは、特に名前付きエンティティの認識において一般化に直観的に役立ちます。トレーニング中に見られなかった言及を検出することが重要です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br>2020-01-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Elephant in the Room: An Evaluation Framework for Assessing Adversarial
  Examples in NLP -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-23/cs.CL/paper_10.html">
      Elephant in the Room: An Evaluation Framework for Assessing Adversarial
  Examples in NLP
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、テキストの例の長さや入力ドメインなど、攻撃のパフォーマンスに影響を与える可能性のある複数の要因があることを学びました。本論文では、前述の特性に基づいて敵対例の品質を評価する評価フレームワークを提案します.. 5つのベンチマーク攻撃手法と自動エンコーダーに基づく代替手法を実験し、これらの手法が読みやすさとコンテンツの保存性が低い敵対的な例を生成することを発見しました。 
[ABSTRACT] 5つのベンチマーク攻撃方法と、自動エンコーダーに基づく代替アプローチで実験します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br>2020-01-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multilingual Denoising Pre-training for Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-23/cs.CL/paper_11.html">
      Multilingual Denoising Pre-training for Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      mBARTは、複数の言語で全文をノイズ除去することにより、完全なシーケンス間モデルを事前トレーニングする最初の方法です。以前のMT事前トレーニングは、エンコーダ、デコーダ、またはテキストの一部の再構築のみに焦点を当てていました。mBART初期化を追加すると、低リソースMTの最大12 BLEUポイントを含む最高リソース設定以外のすべてでパフォーマンスが向上することを実証しますまた、多くのドキュメントレベルおよび教師なしモデルの5 BLEUポイント以上。完全なモデルを事前にトレーニングすることで、タスク固有ではなく、教師あり（文レベルとドキュメントレベルの両方）および教師なし機械翻訳用に直接微調整することができます変更。 
[ABSTRACT] mbartは、多くの言語の自動エンコーダです。事前-完全なモデルをトレーニングすると、教師付きおよび教師なしの機械翻訳用に微調整できます。また、バイテキストまたはトレーニング前のコーパスにはありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br>2020-01-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ManyModalQA: Modality Disambiguation and QA over Diverse Inputs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-23/cs.CL/paper_12.html">
      ManyModalQA: Modality Disambiguation and QA over Diverse Inputs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Wikipediaをスクレイピングしてデータを収集し、クラウドソーシングを使用して質問と回答のペアを収集します。課題、ManyModalQA。エージェントは、テキスト、画像、表という3つの異なるモダリティを考慮して質問に答えなければなりません。 
[ABSTRACT]ウィキペディアをスクレイピングしてデータを収集し、クラウドソーシングを使用して質問と回答のペアを収集します。このモデルは、既存のデータセットに比べてチャレンジセットの精度が大幅に低く、質問がより曖昧であることを示唆しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br>2020-01-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: VoiceCoach: Interactive Evidence-based Training for Voice Modulation
  Skills in Public Speaking -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-23/cs.CL/paper_13.html">
      VoiceCoach: Interactive Evidence-based Training for Voice Modulation
  Skills in Public Speaking
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      多くのガイドラインが利用可能ですが、多くのガイドラインは多くの場合、特に初心者スピーカー向けに、異なる人前で話す状況に適用するのに十分実用的ではありません。音声入力が与えられると、VoiceCoachは自動的に良い音声を推奨します文構造と音声変調スキルの両方の類似性に基づくデータセットからの変調例。 
[ABSTRACT] voicecoachは、使用されるインタラクティブな証拠ベースのアプローチです。音声伝送スキルの効果的なトレーニングを促進するために使用されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br>2020-01-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ARAACOM: ARAbic Algerian Corpus for Opinion Mining -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-23/cs.CL/paper_14.html">
      ARAACOM: ARAbic Algerian Corpus for Opinion Mining
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      個人や社会が日常生活のいくつかの主題（スポーツ、政治、テレビなど）に対する気分を追跡する必要性が高まっているため、ウェブでの意見マイニングはますます魅力的なタスクになっています。アラビアのアルジェリアの新聞で意見をマイニングするためのアプローチを提案します。したがって、これを利用するには強力な手段を必要とする多くのデータが作成されます。 
[概要]現在、多くのWebサイトが少ない労力で広範囲にアクセスできます。100万人以上がデータの影響を受けていると考えられています。意見マイニングの分析は西洋言語で開発されました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br>2020-01-22
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Non-Negative Matrix Factorization-Convolutional Neural Network (NMF-CNN)
  For Sound Event Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-23/eess.AS/paper_0.html">
      Non-Negative Matrix Factorization-Convolutional Neural Network (NMF-CNN)
  For Sound Event Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このような統合の重要な考え方は、NMFを使用して弱ラベルデータに近似の強いラベルを提供することです。検証結果を他の参加者と比較することにより、提案されたシステムは19チーム（ベースラインシステムを含む）で8位にランク付けされました年のタスク4の課題。このような統合により、ベースラインシステムと比較して、より高いイベントベースのF1スコアを達成できました（評価データセット：30.39％対23.7％、検証データセット：31％対25.8％）。 
[ABSTRACT]ディープラーニングシステムは、非負行列因子分解と畳み込みニューラルネットワークを統合します。このような統合により、ベースラインシステムと比較して、f1ベースのより高いイベントを達成できました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br>2020-01-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Representation Disentanglement using Cross Domain Features
  and Adversarial Learning in Variational Autoencoder based Voice Conversion -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-23/eess.AS/paper_1.html">
      Unsupervised Representation Disentanglement using Cross Domain Features
  and Adversarial Learning in Variational Autoencoder based Voice Conversion
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、敵対的学習の概念を組み込むことにより、CDVAE-VCフレームワークを拡張し、もつれ解除の程度をさらに高め、それによって変換された音声の品質と類似性を改善します。実験結果により、学習した潜在的表現は、GANと話者分類子の両方によって強化できます。成功は、より複雑な潜在的表現からもたらされると考えました。 
[要旨]成功は、より複雑な潜在表現からもたらされたと考えています。まず、cdvae-vcを使用したウイルス（gans）の有効性を調査します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br>2020-01-22
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本日更新された論文はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br>
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
