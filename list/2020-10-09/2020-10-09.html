<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-10-09の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Classification of Speech with and without Face Mask using Acoustic
  Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.SD/paper_0.html">
      <font color="black">Classification of Speech with and without Face Mask using Acoustic
  Features</font>
    </a>
  </h2>
  <font color="black">これらの音響機能は、ComParE 2020のComParE機能、bag-of-audio-words、DeepSpectrum、およびauDeep機能の最先端のベースラインとともに使用されます。この動機で、スピーカーがフェイスマスクを着用しているかどうかを確認します。与えられたスピーチは、Computational Paralinguistics Evaluation（ComParE）2020のタスクとして含まれています。フェイスマスクの使用は、コミュニケーション中にスピーチを妨げる可能性のある要因の1つです。 
[要約]調査では、音響機能の有効性が示され、2020年のベースラインと比較したスコアレベルの融合により、テストセットでの重み付けされていない平均再現率は73. 50％になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Vrengt: A Shared Body-Machine Instrument for Music-Dance Performance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.SD/paper_1.html">
      <font color="black">Vrengt: A Shared Body-Machine Instrument for Music-Dance Performance</font>
    </a>
  </h2>
  <font color="black">最終公演では、ダンサーの腕と脚の筋肉活動をキャプチャするために2つのMyoアームバンドが使用され、呼吸の音をキャプチャするワイヤレスヘッドセットマイクが使用されました。探索では、特に焦点を当てた「時空間マトリックス」を使用しました。ソニックマイクロインタラクション..参加型デザインアプローチを使用して、ダンサーの身体表現を体系的に探索するためのツールとしてソニフィケーションを使用しました。 
[概要] vrengtの作品は、ミュージシャンとダンサーによって開発されました。音楽を探索するために「時空間マトリックス」を使用して開発されました。プロジェクトは、vrengtによって紙の論文で公開されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Investigating U-Nets with various Intermediate Blocks for
  Spectrogram-based Singing Voice Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.SD/paper_2.html">
      <font color="black">Investigating U-Nets with various Intermediate Blocks for
  Spectrogram-based Singing Voice Separation</font>
    </a>
  </h2>
  <font color="black">次に、これらのネットワークをSDRメトリックで比較します。畳み込み層と完全に接続された層で構成される特定のブロックを使用すると、MUSDBの歌声分離タスクで0.9dBの大きなマージンで最先端のSDRを実現します。 。コードとモデルはオンラインで入手できます。 
[概要]これらのブロックに基づく多くのu-net-がsvsタスクに提案されています。u-netアーキテクチャで使用できるさまざまなタイプの中間ブロックを評価および比較する既存の作業はありませんでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-02">
        <br><font color="black">2019-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Population Based Training for Data Augmentation and Regularization in
  Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.SD/paper_3.html">
      <font color="black">Population Based Training for Data Augmentation and Regularization in
  Speech Recognition</font>
    </a>
  </h2>
  <font color="black">これは、トレーニング中にこれらのハイパーパラメータを変更しないベースラインと比べて遜色なく、8％の相対的なWERの改善が見られます。LibriSpeechのテストで5.18％の単語誤り率が得られます-その他..これにより、実験の負担と計算コストが大幅に簡素化されます。そのような最適なスケジュールを見つけることの。 
[概要]人口ベースのトレーニングが便利なツールであることを示します。この方法で標本を最適化することで音声認識を実験し、ドロップアウトも行います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Texture-based Presentation Attack Detection for Automatic Speaker
  Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.SD/paper_4.html">
      <font color="black">Texture-based Presentation Attack Detection for Automatic Speaker
  Verification</font>
    </a>
  </h2>
  <font color="black">ただし、これらは基本的にアンサンブル内のシステムの相補性に依存します。これらおよびその他の利点にもかかわらず、一般的な生体認証システム、特に自動話者検証（ASV）システムは、攻撃の提示に対して脆弱である可能性があります。特に、生成モデルに基づく一般的なフィッシャーベクトル特徴空間。 
[概要]最新のasvspoof2019コンテストでは、アンサンブル分類器ベースのプレゼンテーション攻撃検出（パッド）アプローチを使用して、ほとんどの形式の攻撃を確実に検出できることが示されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Emotion Invariant Speaker Embeddings for Speaker Identification with
  Emotional Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.SD/paper_5.html">
      <font color="black">Emotion Invariant Speaker Embeddings for Speaker Identification with
  Emotional Speech</font>
    </a>
  </h2>
  <font color="black">さまざまな感情を持つ平均的な話者モデルベースのフレームワークに対して、感情不変の話者埋め込みを使用した話者識別研究の精度が2.6％向上します。したがって、結果のテスト埋め込みは感情不変になり、さまざまな感情状態間の不一致を補正します。 i-vectorベースのシステムを使用して取得したさまざまな感情を含むテスト埋め込みを感情不変空間にマッピングする抽出ネットワークを学習します。 
[ABSTRACT]音声は、さまざまな感情を持つ話者を識別するために使用できます。これらは、ニュートラルな音声を使用したさまざまな話者の一連の例に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: HLT-NUS Submission for NIST 2019 Multimedia Speaker Recognition
  Evaluation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.SD/paper_6.html">
      <font color="black">HLT-NUS Submission for NIST 2019 Multimedia Speaker Recognition
  Evaluation</font>
    </a>
  </h2>
  <font color="black">オーディオシステムはx-vectorベースのスピーカー埋め込みに基づいていますが、顔認識システムはResNetおよびInsightFaceベースの顔埋め込みに基づいています。以前のNIST SREとは対照的に、最新版はマルチメディアトラックに焦点を当てて両方のスピーカーを認識します。音声と視覚の情報..音声と視覚の入力用に別々のシステムを開発した後、2つのモダリティからのシステムをスコアレベルで融合して、それらの情報をまとめて使用しました。 
[概要]マルチメディア研究は幅広いアプリケーションに注目を集めています。話者認識も例外ではありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: D3Net: Densely connected multidilated DenseNet for music source
  separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.SD/paper_7.html">
      <font color="black">D3Net: Densely connected multidilated DenseNet for music source
  separation</font>
    </a>
  </h2>
  <font color="black">音楽ソースの分離には、オーディオ信号の長期依存性をモデル化するための大きな入力フィールドが含まれます。MUSDB18データセットの実験結果は、D3Netが6.01の平均信号対歪み比（SDR）で最先端のパフォーマンスを達成することを示しています。 dB .. D3Netには、異なる解像度を同時にモデル化するために、単一レイヤーに異なる拡張係数を持つ新しいマルチ拡張コンボリューションが含まれます。 
[ABSTRACT]新しい畳み込み畳み込みには、異なる解像度を同時にモデル化するために、単一レイヤーに異なる拡張拡張拡張畳み込み係数を持つ新しいマルチステート畳み込みが含まれます。新しい畳み込み畳み込みは、畳み込み畳み込みへの新しいアプローチです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Sound Event Localization and Detection Using Activity-Coupled Cartesian
  DOA Vector and RD3net -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.SD/paper_8.html">
      <font color="black">Sound Event Localization and Detection Using Activity-Coupled Cartesian
  DOA Vector and RD3net</font>
    </a>
  </h2>
  <font color="black">シングルステージシステムとして、SEDタスクとSELタスクの両方の単一ターゲットとしてアクティビティ結合デカルトDOAベクトル〜（ACCDOA）表現を使用する統合トレーニングフレームワークを提案します。2つのシステムを検討します。シングルステージシステムサウンドイベントのローカリゼーション〜（SEL）とサウンドイベントの検出〜（SED）を同時に解決し、最初にSEDタスクとSELタスクを個別に処理し、後でそれらの結果を組み合わせる2段階システム..DCASE2020タスクに提出されたシステム〜3 ：このレポートでは、サウンドイベントのローカリゼーションと検出（SELD）について説明します。 
[ABSTRACT]システムはsedタスクとselタスクを個別に組み合わせて動作し、後でそれらの結果を組み合わせます。サウンドイベントの場所とアクティビティを効率的に推定するために、rd3netをさらに提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-22">
        <br><font color="black">2020-06-22</font>
      </time>
    </span>
</section>
<!-- paper0: Latent linguistic embedding for cross-lingual text-to-speech and voice
  conversion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.SD/paper_9.html">
      <font color="black">Latent linguistic embedding for cross-lingual text-to-speech and voice
  conversion</font>
    </a>
  </h2>
  <font color="black">十分に訓練された英語の潜在的な言語埋め込みを使用して、Voice Conversion Challenge 2020に含まれるいくつかのドイツ語、フィンランド語、および北京語の話者用のクロスリンガルTTSおよびVCシステムを作成することにより、私たちの方法がクロスリンガルVCを作成するだけではないことを示します。話者の類似性が高いだけでなく、追加の手順を実行することなく、言語間のTTSにシームレスに使用できます。最近提案された音声クローニングシステムNAUTILUSは、転写されていない音声を使用して見えない音声をクローニングできるため、使用の実現可能性を調査します。統一されたクロスリンガルTTS / VCシステムを開発する。しかし、知覚される自然さの主観的評価は、ターゲットスピーカー間で異なるようであり、これは将来の改善の1つの側面です。 
[概要]クロスリンガルスピーチネスは、追加の手順を実行せずに使用できるシステムです。このシステムは、十分に訓練された英語の潜在的な言語埋め込みを使用して作成され、いくつかのドイツ語、フィンランド語のクロスリンガルttsおよびvcシステムを作成しました。 、およびマンダリンスピーカー</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Tatum-Level Drum Transcription Based on a Convolutional Recurrent Neural
  Network with Language Model-Based Regularized Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.SD/paper_10.html">
      <font color="black">Tatum-Level Drum Transcription Based on a Convolutional Recurrent Neural
  Network with Language Model-Based Regularized Training</font>
    </a>
  </h2>
  <font color="black">提案された方法では、データムレベルの確率的言語モデル（ゲート付き回帰ユニット（GRU）ネットワークまたは反復認識バイグラムモデル）が、ドラムスコアの広範なコレクションからトレーニングされます。このようなフレーム間での主な問題ただし、DNNは、これらのパターンの長期的な音楽的に意味のある構造をフレームレベルで学習することが難しいため、推定開始時間がシンボリックドラムスコアに表示される典型的なタタムレベルのパターンと一致しないことが多いということです。これを解決するには問題は、フレームからデータムへのDNNの正規化されたトレーニング方法を提案します。 
[概要]提案された方法は、ディープニューラルネットワーク（dnns）によって開発されました。この方法では、フレームのパターンをtatum dnnに置き換える必要があります。この方法は、ドラムの開始時間を予測するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Hierarchical Classification of Pulmonary Lesions: A Large-Scale
  Radio-Pathomics Study -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.IV/paper_0.html">
      <font color="black">Hierarchical Classification of Pulmonary Lesions: A Large-Scale
  Radio-Pathomics Study</font>
    </a>
  </h2>
  <font color="black">Pulmonary-RadPathという名前のこの遡及的データセットにより、正確な深層学習システムの開発と検証が可能になり、非侵襲的手順、つまり放射線CTスキャンで侵襲的病理ラベルを予測できます。侵襲的病理分析が肺の臨床的ゴールデンスタンダードとして機能することを考慮すると癌の診断、この研究では、癌（例、浸潤性/非浸潤性腺癌、扁平上皮癌）および非浸潤性癌を含む病理学的に確認されたラベルを含む5,134の放射線CT画像を含む大規模な放射線病理学データセットを介してラベルのあいまいさの問題を解決します癌性疾患（例、結核、ハマルトーマ）。有望な結果は、精密医療を促進する可能性を示唆しています。 
[概要]深層学習は、肺がんのコンピューター支援診断（cadx）領域で大きな成功を収めています。このデータセットは、肺-radpathという名前で、正確な深層学習システムの開発と検証を可能にします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Single-molecule orientation localization microscopy II: a performance
  comparison -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.IV/paper_1.html">
      <font color="black">Single-molecule orientation localization microscopy II: a performance
  comparison</font>
    </a>
  </h2>
  <font color="black">興味深いことに、標準的な蛍光顕微鏡への簡単な変更は、多くのイメージングシナリオで優れたパフォーマンスを示します。この作業では、複数の最先端の一般的に使用される配向局在顕微鏡法のパフォーマンスを、測定精度の基本的な限界と比較します。 ..標準的な落射蛍光顕微鏡よりも精度が向上した蛍光分子の2Dおよび3D位置と2Dおよび3D配向を測定するために、さまざまな技術が開発されています。 
[ABSTRACT]分析は、さまざまな実験条件とサンプル形状の標準的なイメージング方法を示しています。精密なイメージング方法を使用して、特定のターゲットを特定します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: SESAME: Semantic Editing of Scenes by Adding, Manipulating or Erasing
  Objects -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.IV/paper_2.html">
      <font color="black">SESAME: Semantic Editing of Scenes by Adding, Manipulating or Erasing
  Objects</font>
    </a>
  </h2>
  <font color="black">多様なデータセットのセットでモデルを評価し、（a）画像操作と（b）セマンティックラベルを条件とした画像生成の2つのタスクで最先端のパフォーマンスを報告します。これらは完全なセットを処理できません。編集操作、つまりセマンティックコンセプトの追加、操作、または削除の方法。これらの制限に対処するために、オブジェクトの追加、操作、または消去によるシーンのセマンティック編集用の新しいジェネレーターとディスクリミネーターのペアであるSESAMEを提案します。 
[概要]オブジェクトを追加、操作、または消去することでシーンをセマンティック編集するための新しいジェネレーターとディスクリミネーターのペアであるゴマを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-10">
        <br><font color="black">2020-04-10</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to synthesise the ageing brain without longitudinal data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.IV/paper_3.html">
      <font color="black">Learning to synthesise the ageing brain without longitudinal data</font>
    </a>
  </h2>
  <font color="black">コミュニティ全体によるこのような将来の研究を促進するために、私たちのコードはhttps://github.com/xiat0616/BrainAgeingで利用可能になります。私たちは、グラウンドトゥルース縦断データと事前トレーニングされた年齢を使用して、合成画像の品質とリアリズムを評価します。予測因子..敵対的な定式化により、脳の外観、年齢、AD状態の共同分布を学習し、被験者のアイデンティティを維持するという困難な問題に対処するための再構成損失を定義します。 
[ABSTRACT]私たちの方法は、年齢（連続変数変数変数）とアルツハイマー病の状態（広告、序数問題）の2つの要因を条件とする画像を合成します。2つの広く使用されているオートセットを使用していくつかのベンチマークと比較します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br><font color="black">2019-12-04</font>
      </time>
    </span>
</section>
<!-- paper0: CSTNet: A Dual-Branch Convolutional Network for Imaging of Reactive
  Flows using Chemical Species Tomography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.IV/paper_4.html">
      <font color="black">CSTNet: A Dual-Branch Convolutional Network for Imaging of Reactive
  Flows using Chemical Species Tomography</font>
    </a>
  </h2>
  <font color="black">さらに、種の濃度と温度の自然に相関する分布を自動的に学習するクロストークデコーダーを使用した画像再構成のために、デュアルブランチアーキテクチャが提案されています。測定ノイズとミリ秒レベルに対する堅牢性の点で、以前のアプローチと比較して優れたパフォーマンスが見られます。計算時間..反応性フローにおける種の濃度と温度。 
[ABSTRACT] cstnetは、cst測定とセンサーレイアウトを学習ネットワークに組み込んだ共有特徴抽出器を導入します。提案されたcstnetは、シミュレートされたデータセットと、業界ベースのセンサーを使用した実験での実際の炎からの測定データの両方で検証されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Frequency and Spatial domain based Saliency for Pigmented Skin Lesion
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.IV/paper_5.html">
      <font color="black">Frequency and Spatial domain based Saliency for Pigmented Skin Lesion
  Segmentation</font>
    </a>
  </h2>
  <font color="black">個別の融合スキームを採用して、それぞれのドメインの顕著な特徴を組み合わせます。周波数ドメインのマップは、集約された画像から生成されます。提案された方法のパフォーマンスは、PH2およびISIC2016データセットで評価されます。 
[概要]提案された方法は、周波数と空間モスで開発されました。それは、それぞれのドメインの顕著性機能を組み合わせたものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Clinically Verified Hybrid Deep Learning System for Retinal Ganglion
  Cells Aware Grading of Glaucomatous Progression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.IV/paper_6.html">
      <font color="black">Clinically Verified Hybrid Deep Learning System for Retinal Ganglion
  Cells Aware Grading of Glaucomatous Progression</font>
    </a>
  </h2>
  <font color="black">方法：提案されたフレームワークは、網膜神経線維層、内網状層を伴う神経節細胞、および神経節細胞複合領域を抽出するハイブリッド畳み込みネットワークを包含し、したがって、緑内障の対象の定量的スクリーニングを可能にします。緑内障の進行は、分析することによって簡単に監視できます。網膜神経節細胞（RGC）の変性。多くの研究者は、眼底および光コヒーレンストモグラフィースキャンからカップ対ディスク比を測定することによって緑内障をスクリーニングしました。 
[概要]緑内障の進行は、神経節細胞（rgcs）を分析することで簡単に監視できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Spatially-Variant CNN-based Point Spread Function Estimation for Blind
  Deconvolution and Depth Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.IV/paper_7.html">
      <font color="black">Spatially-Variant CNN-based Point Spread Function Estimation for Blind
  Deconvolution and Depth Estimation</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、光学セットアップに関する先験的な知識の必要性を最小限に抑えて、平坦でないオブジェクトの画像を強化するための複数の可能性を開きます。顕微鏡固有のキャリブレーションに続いて、復元されたPSFモデルパラメータが次の精度で表面深度を推定できることをさらに示します。設計されたPSFを使用する場合、2マイクロメートル以上の拡張範囲。具体的には、機器やオブジェクトを必要としない畳み込みニューラルネットワーク（CNN）を使用して、空間的に変化する点像分布関数（PSF）モデルのパラメーターを推定します。特定のキャリブレーション。 
[ABSTRACT]畳み込みニューラルネットワーク（cnn）を使用して、空間-バリアント点-広がり関数（psf）モデルのパラメーターを推定します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: MRI Banding Removal via Adversarial Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.IV/paper_8.html">
      <font color="black">MRI Banding Removal via Adversarial Training</font>
    </a>
  </h2>
  <font color="black">専門家の評価者（理事会認定の放射線科医）のグループによる強力なベースラインとのブラインド比較の結果を報告します。ここで、私たちのアプローチは、統計的に有意な詳細の損失なしに、バンディング除去で優れているとランク付けされています。サブサンプリングから再構成されたMRI画像ディープラーニング手法を使用したカルテシアンデータは、特徴的なバンディング（ストリークと呼ばれることもあります）を示すことがよくあります。これは、再構成された画像の信号対雑音比の低い領域で特に強くなります。この手法では、追加の計算を必要とせずに、バンディングの外観が大幅に減少します。または再構成時の後処理。 
[要約]研究は、人間の注釈を必要とせずにバンディング構造を使用することでペナルティを課す敵対的損失の使用を提案しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-23">
        <br><font color="black">2020-01-23</font>
      </time>
    </span>
</section>
<!-- paper0: Intensity interferometry-based 3D imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.IV/paper_9.html">
      <font color="black">Intensity interferometry-based 3D imaging</font>
    </a>
  </h2>
  <font color="black">大気散乱に対するロバスト性や外部光源を活用する自律性などの利点により、この測距アプローチは将来のアプリケーションにとって興味深いものになります。ゲートSPADテクノロジーを使用することにより、基本的な3Dシーンが妥当な測定時間で画像化されます。従来のアプローチと比較して、提案された同期フォトンカウンティングにより、より多くの光モードを使用して3Dレンジングパフォーマンスを向上させることができます。 
[概要]提案された提案された提案された量子量子量子ディスプレイは、3Dモデルに使用できます。3Dモデルには、熱光に基づく3Dデバイスが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: BVI-DVC: A Training Database for Deep Video Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.IV/paper_10.html">
      <font color="black">BVI-DVC: A Training Database for Deep Video Compression</font>
    </a>
  </h2>
  <font color="black">実験結果は、このデータベースが、同じトレーニングおよび評価構成の下で、3つの既存の（一般的に使用される）画像/ビデオトレーニングデータベースよりもコーディングゲインの点で大幅な改善をもたらすことを示しています。この論文では、新しい大規模で代表的なビデオデータベース、BVI-DVCは、CNNベースのビデオ圧縮システムをトレーニングするために提示され、空間解像度とビット深度のアップサンプリング、後処理、ループ内フィルタリングなど、従来のコーディングアーキテクチャを強化する機械学習ツールに特に重点を置いています。全体的な追加のコーディングの改善テストされたすべてのコーディングモジュールとCNNアーキテクチャに提案されたデータベースを使用することにより、PSNRの評価に基づいて最大10.3％、VMAFに基づいて8.1％になります。 
[ABSTRACT]畳み込みニューラルネットワーク（cnns）は、コンテンツカバレッジが比較的限られているデータベースでトレーニングされます。これらは、作業を改善するために使用できる新しいテクノロジーの開発によく使用されます。これには、4つの異なるプログラミングツールの新しいシステムのテストが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br><font color="black">2020-03-30</font>
      </time>
    </span>
</section>
<!-- paper0: Free annotated data for deep learning in microscopy? A hitchhiker's
  guide -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.IV/paper_11.html">
      <font color="black">Free annotated data for deep learning in microscopy? A hitchhiker's
  guide</font>
    </a>
  </h2>
  <font color="black">他の応用分野のデータセットから集めた知識を借りて、顕微鏡検査に活用することは可能ですか？注釈付きデータに対するこの要件を緩和できますか？顕微鏡検査では、多くの深層学習モデルが前提条件として採用している大規模なデータセットを取得して注釈を付けるための時間的負担とコストが、これらの方法を非現実的にしているように見えることがよくあります。 
[概要]データデータデータgitmoの提案を緩和することができます。バイオ顕微鏡法の学習ベースの方法にアクセスするために使用できますか？</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Bone Feature Segmentation in Ultrasound Spine Image with Robustness to
  Speckle and Regular Occlusion Noise -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.IV/paper_12.html">
      <font color="black">Bone Feature Segmentation in Ultrasound Spine Image with Robustness to
  Speckle and Regular Occlusion Noise</font>
    </a>
  </h2>
  <font color="black">3D超音波画像は、低コストで放射線のないリアルタイムの特性により、脊柱側弯症の診断に大きな期待を寄せています。超音波画像には、多くのスペックルと定期的な閉塞ノイズが含まれる傾向があり、専門家にとっては困難で面倒で時間がかかります。骨の特徴を見つける..この論文では、超音波脊椎ボリュームプロジェクションイメージング（VPI）画像のU-net構造に基づくロバストな骨の特徴セグメンテーション法を提案します。 
[概要]超音波診断によって脊柱側弯症にアクセスするための鍵は、骨領域を正確にセグメント化し、咬合を測定することです。骨の特徴の効果を測定するには、超音波画像検査が鍵となります。提案されたアプローチは、ダイススコアの2.3％と1％を改善します。 u-ネットモデルと比較したaucスコアの</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: A Variational Auto-Encoder Approach for Image Transmission in Wireless
  Channel -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.IV/paper_13.html">
      <font color="black">A Variational Auto-Encoder Approach for Image Transmission in Wireless
  Channel</font>
    </a>
  </h2>
  <font color="black">さらに、ネットワークの損失関数として知覚ベースのエラーメトリックを使用することにより、再構成された画像の人間の知覚品質に優れていることを試みました。私たちの調査結果は、変分オートエンコーダがオートエンコーダよりもチャネル劣化に対してロバストであることを示唆しています。この論文では、変分オートエンコーダの性能を調査し、その結果を標準オートエンコーダと比較します。 
[概要]ディープラーニング手法を使用してこれらの問題に対処するために多くの作業が行われたのはこれが初めてです。提案されたニューラルネットワークを最適化するための知覚ベースのメトリックとして構造類似性インデックス（ssim）を使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Convolutional Sequence to Sequence Model for Vertebral Compression
  Fractures Identification in CT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.IV/paper_14.html">
      <font color="black">3D Convolutional Sequence to Sequence Model for Vertebral Compression
  Fractures Identification in CT</font>
    </a>
  </h2>
  <font color="black">さまざまな表現と分類のアプローチを活用するいくつかのモデルバリアントを評価し、大規模なデータセットで検証された最先端の結果を達成するモデルのアンサンブルと患者レベルの骨折識別0.955の曲線下領域を組み合わせたフレームワークを提示します（ AUC）..システムは、脊椎のコンパクトな3D表現を統合し、脊髄検出のためのConvolutional Neural Network（CNN）と、3Dアーキテクチャをシーケンスするための新しいエンドツーエンドシーケンスを利用します。この研究では、自動主要な骨粗鬆症関連の骨折の診断されていない前兆であることが多いコンピューター断層撮影画像上で脊椎圧迫骨折を識別するためのシステム。 
[ABSTRACT]骨粗鬆症性骨折は骨粗鬆症性骨折の最も一般的な原因です。骨粗鬆症によって開発されたシステムはキックスターターで事前注文できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Compressed Sensing with Signal Averaging for Improved Sensitivity and
  Motion Artifact Reduction in Fluorine-19 MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.IV/paper_15.html">
      <font color="black">Compressed Sensing with Signal Averaging for Improved Sensitivity and
  Motion Artifact Reduction in Fluorine-19 MRI</font>
    </a>
  </h2>
  <font color="black">両方の取得-再構築戦略は、パーフルオロポリエーテルを注射したマウス（n = 2）でinvivoで検証されました。注入されたパーフルオロカーボンエマルジョン（PFC）のフッ素-19（19F）MRIは、炎症と細胞追跡の非侵襲的定量化を可能にしますが、苦しみます低い信号対雑音比と延長されたスキャン時間から..調査されたすべての雑音レベルで、取得-再構成戦略のDSCは、正規化パラメータと加速係数に強く依存していました。 
[概要]特定の比率と信号の平均化を組み合わせた19fmriパルスシーケンスにより、モーションアーチファクトに対する感度と堅牢性が向上しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-10">
        <br><font color="black">2019-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: CS-MCNet:A Video Compressive Sensing Reconstruction Network with
  Interpretable Motion Compensation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.IV/paper_16.html">
      <font color="black">CS-MCNet:A Video Compressive Sensing Reconstruction Network with
  Interpretable Motion Compensation</font>
    </a>
  </h2>
  <font color="black">さらに、フィードフォワードアーキテクチャにより、再構成はネットワークによってリアルタイムで処理でき、従来の反復法よりも最大3桁高速です。この論文では、CSと呼ばれる解釈可能な運動補償を備えたディープニューラルネットワーク-MCNetは、ビデオ圧縮センシングの高品質でリアルタイムのデコードを実現するために提案されています。アーキテクチャ全体は、アルゴリズムの展開を使用して解釈可能であり、従来のアルゴリズムに関する事前知識を転送できるという利点があります。 
[概要]この方法を使用すると、64倍の圧縮率で22dbのpsnrを達成できます。これは約4％から9％可能です。フレーム間予測をネットワークに適用して、隣接するフレームの相関情報を抽出します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Single-molecule orientation localization microscopy I: fundamental
  limits -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.IV/paper_17.html">
      <font color="black">Single-molecule orientation localization microscopy I: fundamental
  limits</font>
    </a>
  </h2>
  <font color="black">この作業では、古典的および量子推定理論を適応させ、任意の固定イメージングシステムの双極子のようなエミッターの位置と方向を測定するための可能な限り最高の精度を導き出すための数学的フレームワークを提案します。さらに、ベクトル双極子イメージングモデルは量子制限された最高のローカリゼーション精度は、スカラーモノポールモデルによって提案されたものよりも約4〜8％劣ります。全体として、考えられるすべての2Dおよび3Dローカリゼーションおよび方向測定タスクで最大精度を実現するために単一の機器を最適化することはできないと結論付けています。 
[概要]考えられるすべてのレーザー動作を測定するための最大感度限界を達成する機器を設計することは不可能であることがわかりました。しかし、全体として、考えられるすべての2Dおよび3Dの位置特定と方向付けで最大の精度を実現するために最適化できる機器はないと結論付けています。測定タスク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Regularized Compression of MRI Data: Modular Optimization of Joint
  Reconstruction and Coding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.IV/paper_18.html">
      <font color="black">Regularized Compression of MRI Data: Modular Optimization of Joint
  Reconstruction and Coding</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、モジュラー最適化構造を持ち、乗数の交互方向法（ADMM）技術と、反復的に適用されるブラックボックスモジュールとしての最先端の画像圧縮技術（BPG）を使用して実装されます。磁気共鳴イメージング（ MRI）処理チェーンは、医療診断用の画像を再構成するための生データを提供する重要な取得段階から始まります。これにより、選択した損失のある圧縮標準と互換性のある医療データ圧縮アプローチが確立されます。 
[要約]研究によると、非可逆圧縮は再構成の品質を向上させることさえできます。方法は可逆圧縮に基づいています。方法は再構成の品質を向上させるために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: A Comparative Study on Effects of Original and Pseudo Labels for Weakly
  Supervised Learning for Car Localization Problem -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_0.html">
      <font color="black">A Comparative Study on Effects of Original and Pseudo Labels for Weakly
  Supervised Learning for Car Localization Problem</font>
    </a>
  </h2>
  <font color="black">元のクラスラベルに加えて、生成されたクラスラベルは、CAMのトレーニングにも使用され、教師なし学習の例の解決策になります。実験では、最初に、弱教師ありローカリゼーションのクラスラベルがCompcarsデータセットに与える影響を分析します。提案された教師なしアプローチは、この特定のデータセットの弱教師あり方法よりも約％6優れていることを示しています。 
[ABSTRACT]クラスアクティベーションマッピング（cam）は、ローカリゼーションラベルを予測するために使用されます。実験では、まず、教師ありローカリゼーションにおけるクラスラベルのcompcarsデータセットへの影響を分析します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchical Classification of Pulmonary Lesions: A Large-Scale
  Radio-Pathomics Study -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_1.html">
      <font color="black">Hierarchical Classification of Pulmonary Lesions: A Large-Scale
  Radio-Pathomics Study</font>
    </a>
  </h2>
  <font color="black">コンピュータ断層撮影（CT）からの肺病変の診断は重要ですが、肺癌関連疾患の臨床的意思決定には困難です。侵襲的病理分析が肺癌診断の臨床的ゴールデンスタンダードとして機能することを考慮して、この研究では、ラベルのあいまいさを解決します。癌（例、浸潤性/非浸潤性腺癌、扁平上皮癌）および非癌性疾患（例、結節、ハマルトーマ）を含む病理学的に確認されたラベルを含む5,134の放射線CT画像を含む大規模な放射線病理学データセットを介して発行します。 Pulmonary-RadPathという名前の遡及的データセットにより、正確な深部学習システムの開発と検証が可能になり、非侵襲的手順、つまり放射線CTスキャンで侵襲的病理学的ラベルを予測できます。 
[概要]深層学習は、肺がんのコンピューター支援診断（cadx）領域で大きな成功を収めています。このデータセットは、肺-radpathという名前で、正確な深層学習システムの開発と検証を可能にします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Age and Gender Prediction From Face Images Using Attentional
  Convolutional Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_2.html">
      <font color="black">Age and Gender Prediction From Face Images Using Attentional
  Convolutional Network</font>
    </a>
  </h2>
  <font color="black">この作業では、注意と残差畳み込みネットワークのアンサンブルに基づいて、顔画像の性別と年齢層を高い精度で予測するための深層学習フレームワークを提案します。モデルをマルチタスク学習方式でトレーニングし、予測された性別を使用して年齢分類子の機能埋め込みを拡張し、そうすることで年齢予測の精度をさらに高めることができることを示します。注意メカニズムを使用すると、モデルが顔の重要で有益な部分に焦点を合わせることができます。より正確な予測を行うためです。 
[概要]私たちのモデルは、人気のある顔の年齢と性別のデータセットでトレーニングされています。注意メカニズムを使用して、顔の重要で有益な部分に焦点を当てることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: IRX-1D: A Simple Deep Learning Architecture for Remote Sensing
  Classifications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_3.html">
      <font color="black">IRX-1D: A Simple Deep Learning Architecture for Remote Sensing
  Classifications</font>
    </a>
  </h2>
  <font color="black">限られたトレーニングサンプルで高い分類精度を達成しているにもかかわらず、分類された画像を比較すると、すべてのデータセットで大きなトレーニングサンプルを使用してトレーニングされたモデルによって提供された分類された画像と比較すると、異なる土地被覆クラスが同じ領域に割り当てられていることがわかります。 Indiana Pinesハイパースペクトルデータセットを使用した小さなトレーニングサンプルは、異なる深層学習アーキテクチャを使用した9つの報告された作品と同等またはそれ以上のパフォーマンスを提案アーキテクチャによって示唆しています。分類精度に関する結果は、小規模トレーニングを使用したベイジアン最適化2D-CNNと比較して、提案アーキテクチャによるパフォーマンスの向上を示唆しています。サンプル。 
[概要] 4つの新しいデータセットが、小規模および大規模のトレーニングサンプルの両方で分類に使用されました。結果は、異なる深層学習アーキテクチャを使用した9つの報告された作業よりも、提案されたアーキテクチャによる同等以上のパフォーマンスを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Autoregressive Ensembles for Satellite Imagery Manipulation
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_4.html">
      <font color="black">Generative Autoregressive Ensembles for Satellite Imagery Manipulation
  Detection</font>
    </a>
  </h2>
  <font color="black">この論文では、生成的自己回帰モデルのアンサンブルを使用して、潜在的な操作を検出するために画像のピクセルの分布をモデル化します。以前に提示されたアプローチと比較して正確なローカリゼーション結果を得るために、提示されたアプローチのパフォーマンスを評価します。画像に適用される操作の性質は通常不明であり、使用される改ざん技術の事前知識を必要としない監視されていない方法が好ましい。 
[概要]画像には、農業管理、気象予測、自然災害による被害評価が含まれます。改ざん技術の事前知識を必要としない監視されていない方法が推奨されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: ALFWorld: Aligning Text and Embodied Environments for Interactive
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_5.html">
      <font color="black">ALFWorld: Aligning Text and Embodied Environments for Interactive
  Learning</font>
    </a>
  </h2>
  <font color="black">具現化されたエージェントは同じ能力を必要としますが、既存の作業は抽象的推論と具体的実行の両方に必要なインフラストラクチャをまだ提供していません。ALFWorldは、TextWorldで学習された抽象的知識が具体的で視覚的に根拠のあるものに直接対応する新しいBUTLERエージェントの作成を可能にしますアクション..バトラーのシンプルなモジュラー設計は、研究者がパイプラインのすべての部分（言語理解、計画、ナビゲーション、視覚的シーン理解など）を改善するためのモデルに集中できるように問題を考慮に入れています。 
[ABSTRACT] alfworldは、エージェントが抽象的なテキストベースのポリシーを学習し、alfredベンチマークから目標を実行できるようにするシミュレーターです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: SESAME: Semantic Editing of Scenes by Adding, Manipulating or Erasing
  Objects -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_6.html">
      <font color="black">SESAME: Semantic Editing of Scenes by Adding, Manipulating or Erasing
  Objects</font>
    </a>
  </h2>
  <font color="black">画像生成の最近の進歩により、セマンティック画像編集のための強力なツールが生まれました。セマンティクスと画像を入力として簡単に連結するディスクリミネーターを使用する以前の方法とは対照的に、SESAMEディスクリミネーターは画像と画像を独立して処理する2つの入力ストリームで構成されます。そのセマンティクスは、後者を使用して前者の結果を操作します。このセットアップでは、ユーザーが編集する領域のセマンティックラベルを提供し、ジェネレーターが対応するピクセルを合成します。 
[概要]オブジェクトを追加、操作、または消去することでシーンをセマンティック編集するための新しいジェネレーターとディスクリミネーターのペアであるゴマを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-10">
        <br><font color="black">2020-04-10</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to synthesise the ageing brain without longitudinal data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_7.html">
      <font color="black">Learning to synthesise the ageing brain without longitudinal data</font>
    </a>
  </h2>
  <font color="black">敵対的な定式化により、脳の外観、年齢、AD状態の同時分布を学習し、被験者のアイデンティティを維持するという困難な問題に対処するための再構築損失を定義します。コミュニティ全体によるこのような将来の研究を促進するために、コードはhttpsで入手できます。 ：//github.com/xiat0616/BrainAgeing ..縦方向のデータに依存せずに、被験者固有の脳の老化の軌跡をシミュレートすることを学習する、深い学習ベースの方法を提案します。 
[ABSTRACT]私たちの方法は、年齢（連続変数変数変数）とアルツハイマー病の状態（広告、序数問題）の2つの要因を条件とする画像を合成します。2つの広く使用されているオートセットを使用していくつかのベンチマークと比較します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br><font color="black">2019-12-04</font>
      </time>
    </span>
</section>
<!-- paper0: Creation and Validation of a Chest X-Ray Dataset with Eye-tracking and
  Report Dictation for AI Development -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_8.html">
      <font color="black">Creation and Validation of a Chest X-Ray Dataset with Eye-tracking and
  Report Dictation for AI Development</font>
    </a>
  </h2>
  <font color="black">さらに、疾患の分類と位置特定、自動放射線レポート生成、および人間と機械の相互作用の研究者は、これらのデータから利益を得ることができます。人工知能の研究者を支援するために、胸部X線（CXR）画像の豊富なデータセットを開発しました。次の整列されたデータが含まれています：CXR画像、転写された放射線レポートテキスト、放射線科医の口述音声および視線座標データ。 
[概要]データは視線追跡システムを使用して収集され、放射線科医は1,083cxr画像をレビューして報告しました。データは追跡システムを使用して収集されました。放射線科医は1,000cxr画像をレビューして報告します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Improve Adversarial Robustness via Weight Penalization on Classification
  Layer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_9.html">
      <font color="black">Improve Adversarial Robustness via Weight Penalization on Classification
  Layer</font>
    </a>
  </h2>
  <font color="black">複数のベンチマークデータセットでの経験的結果は、クリーンなデータの高い分類精度を維持しながら、追加の計算をあまり必要とせずに、この方法でネットワークの堅牢性を効果的に改善できることを示しています。次に、ReLUタイプの関数がアクティブ化に適していない理由を説明します。このフレームワークの下で..これらの調査結果は、既存のアプローチの限界を明らかにし、シンプルで優れたスケーラビリティを備えた、新しい軽量ペナルティの防御方法を開発することにつながります。 
[ABSTRACT]新しい方法はシンプルでスケーラビリティが優れていると研究者は言います。シンプルで効果的で、簡単に開発できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Frequency and Spatial domain based Saliency for Pigmented Skin Lesion
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_10.html">
      <font color="black">Frequency and Spatial domain based Saliency for Pigmented Skin Lesion
  Segmentation</font>
    </a>
  </h2>
  <font color="black">個別の融合スキームを採用して、それぞれのドメインの顕著な特徴を組み合わせます。実験の結果は、提案されたスキームが最先端の方法と比較してより良いセグメンテーション結果を生成することを示唆しています。周波数領域のマップは集約された画像から生成されます。 
[概要]提案された方法は、周波数と空間モスで開発されました。それは、それぞれのドメインの顕著性機能を組み合わせたものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Clinically Verified Hybrid Deep Learning System for Retinal Ganglion
  Cells Aware Grading of Glaucomatous Progression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_11.html">
      <font color="black">Clinically Verified Hybrid Deep Learning System for Retinal Ganglion
  Cells Aware Grading of Glaucomatous Progression</font>
    </a>
  </h2>
  <font color="black">方法：提案されたフレームワークは、網膜神経線維層、内網状層を伴う神経節細胞、および神経節細胞複合領域を抽出するハイブリッド畳み込みネットワークを含み、緑内障の被験者の定量的スクリーニングを可能にします。緑内障の進行は、分析することによって簡単に監視できます。網膜神経節細胞（RGC）の変性。しかし、この論文は、緑内障の病状をスクリーニングし、それらの重症度を等級分けするためのRGC萎縮に注意を払う新しい戦略を提示します。 
[概要]緑内障の進行は、神経節細胞（rgcs）を分析することで簡単に監視できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Deformable DETR: Deformable Transformers for End-to-End Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_12.html">
      <font color="black">Deformable DETR: Deformable Transformers for End-to-End Object Detection</font>
    </a>
  </h2>
  <font color="black">コードがリリースされる予定です。COCOベンチマークでの広範な実験により、私たちのアプローチの有効性が実証されています。DETRは、優れたパフォーマンスを実証しながら、オブジェクト検出で多くの手動コンポーネントの必要性を排除するために最近提案されました。 
[ABSTRACT]変形可能なdetrは、detrよりも優れたパフォーマンスを実現できます。画像の特徴マップを処理する際の注意モジュールを減らすように設計されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Deep SVBRDF Estimation on Real Materials -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_13.html">
      <font color="black">Deep SVBRDF Estimation on Real Materials</font>
    </a>
  </h2>
  <font color="black">データセットとコードはhttps://lvsn.github.io/real-svbrdfで入手できます。広範な一連の実験と新しい深層学習アーキテクチャを使用して、実際のデータの結果を改善するための2つの戦略、微調整と材料ごとの最適化手順を検討します。ただし、詳細に調べると、文学は純粋に合成データで訓練されており、多様で現実的ですが、現実世界の豊かさを表していないことがよくあります。 
[要約]新しい分析は、文献のほとんどのアプローチが純粋に合成データで訓練されていることを明らかにしています。しかし、データはしばしば現実世界の豊かさを表していない</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Spatially-Variant CNN-based Point Spread Function Estimation for Blind
  Deconvolution and Depth Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_14.html">
      <font color="black">Spatially-Variant CNN-based Point Spread Function Estimation for Blind
  Deconvolution and Depth Estimation</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、オブジェクトの回転、照明の変化、または光子ノイズに対してロバストでありながら、理想的な条件で最大0.99のピアソン相関係数の2乗で画像自体からPSFパラメータを復元します。ここでは、光の解像度を向上させる方法を示します。焦点面までの物体距離を共同で推定しながら、画像の歪みを局所的に推定することにより、そのような物体の顕微鏡画像。具体的には、畳み込み神経ネットワーク（CNN）を使用して、空間的に変化する点像分布関数（PSF）モデルのパラメーターを推定します。機器またはオブジェクト固有のキャリブレーションは必要ありません。 
[ABSTRACT]畳み込みニューラルネットワーク（cnn）を使用して、空間-バリアント点-広がり関数（psf）モデルのパラメーターを推定します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: MRI Banding Removal via Adversarial Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_15.html">
      <font color="black">MRI Banding Removal via Adversarial Training</font>
    </a>
  </h2>
  <font color="black">ディープラーニング手法を使用してサブサンプリングされたデカルトデータから再構成されたMRI画像は、特徴的なバンディング（ストリークと呼ばれることもあります）を示すことがよくあります。これは、再構成された画像の信号対雑音比の低い領域で特に強くなります。再構成時に追加の計算や後処理を必要としないバンディング。この作業では、人間の注釈を必要とせずにバンディング構造にペナルティを課す敵対的損失の使用を提案します。 
[要約]研究は、人間の注釈を必要とせずにバンディング構造を使用することでペナルティを課す敵対的損失の使用を提案しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-23">
        <br><font color="black">2020-01-23</font>
      </time>
    </span>
</section>
<!-- paper0: BGM: Building a Dynamic Guidance Map without Visual Images for
  Trajectory Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_16.html">
      <font color="black">BGM: Building a Dynamic Guidance Map without Visual Images for
  Trajectory Prediction</font>
    </a>
  </h2>
  <font color="black">実験は、BGMが2つの広く使用されているETHおよびUCYデータセットで最先端の予測精度を達成し、より複雑なシナリオを処理することを示しています。ビジュアルイメージには通常、環境の有益なコンテキストが含まれているため、エージェントの行動を予測するのに役立ちます。まず、現在に近い期間内のシーン内のすべてのエージェントのアクティビティを記録してガイダンスマップを作成し、次にそれをコンテキストCNNにフィードして、エージェントのコンテキスト機能を取得します。 
[概要]エージェントの実際の行動に対する視覚効果は驚くべきことではありません。まず、シーン内のすべてのエージェントのアクティビティをそれぞれに近い期間内に記録します。次に、それらをコンテキストcnnにフィードして、コンテキスト機能を取得します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: BVI-DVC: A Training Database for Deep Video Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_17.html">
      <font color="black">BVI-DVC: A Training Database for Deep Video Compression</font>
    </a>
  </h2>
  <font color="black">実験結果は、このデータベースが、同じトレーニングおよび評価構成の下で、3つの既存の（一般的に使用される）画像/ビデオトレーニングデータベースよりもコーディングゲインの点で大幅な改善をもたらすことを示しています。従来のアプローチと比較して、大幅に強化されたコーディングゲインを達成できます。テストされたすべてのコーディングモジュールとCNNアーキテクチャに提案されたデータベースを使用することによる全体的な追加のコーディングの改善は、PSNRの評価に基づいて最大10.3％、VMAFに基づいて8.1％です。 
[ABSTRACT]畳み込みニューラルネットワーク（cnns）は、コンテンツカバレッジが比較的限られているデータベースでトレーニングされます。これらは、作業を改善するために使用できる新しいテクノロジーの開発によく使用されます。これには、4つの異なるプログラミングツールの新しいシステムのテストが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br><font color="black">2020-03-30</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Tiered Image Segmentation forDetecting Internal Ice Layers in Radar
  Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_18.html">
      <font color="black">Deep Tiered Image Segmentation forDetecting Internal Ice Layers in Radar
  Imagery</font>
    </a>
  </h2>
  <font color="black">次に、それを極地の氷の内部層の検出に適用し、人間がラベル付けした注釈をグラウンドトゥルースとして使用した極地の氷レーダーデータの大規模なデータセットで評価します。層の数が不明であり、層が消え、再出現し、マージし、分割される可能性があるため、内部境界ははるかに困難です。この論文では、階層化されたセグメンテーション問題の一般的なクラスを解決するための新しいディープニューラルネットワークベースのモデルを提案します。 。 
[概要]地球のレーダーは、雪と氷の内部構造の観測を収集できますが、これらの観測に手動でラベルを付けるプロセスは、時間がかかり、手間がかかります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Free annotated data for deep learning in microscopy? A hitchhiker's
  guide -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_19.html">
      <font color="black">Free annotated data for deep learning in microscopy? A hitchhiker's
  guide</font>
    </a>
  </h2>
  <font color="black">顕微鏡検査では、多くの深層学習モデルが前提条件として取る大きなデータセットを取得して注釈を付ける時間の負担とコストが、これらの方法を非現実的にしているように見えることがよくあります。注釈付きデータに対するこの要件を緩和できますか。他の応用分野のデータセットから集めた知識を借りて、顕微鏡検査に活用することは可能ですか？ 
[概要]データデータデータgitmoの提案を緩和することができます。バイオ顕微鏡法の学習ベースの方法にアクセスするために使用できますか？</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: UESegNet: Context Aware Unconstrained ROI Segmentation Networks for Ear
  Biometric -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_20.html">
      <font color="black">UESegNet: Context Aware Unconstrained ROI Segmentation Networks for Ear
  Biometric</font>
    </a>
  </h2>
  <font color="black">ほとんどのデータベースでIOU0.5で100 \％の精度が達成されます。各生体認証特性の使用は問題に依存しますが、人間の耳には強力な生体認証測定として使用できる十分な識別特性があることがわかっています。 。2D側面画像で耳を見つけることは困難な作業であり、多くの既存のアプローチが大きなパフォーマンスを達成していますが、研究の大部分は制約された環境に基づいています。 
[概要]人間の耳は、強力な生体認証手段として使用できるように十分な識別特性を備えていることがわかっています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: A Unified Approach to Interpreting and Boosting Adversarial
  Transferability -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_21.html">
      <font color="black">A Unified Approach to Interpreting and Boosting Adversarial
  Transferability</font>
    </a>
  </h2>
  <font color="black">この目的のために、転送可能性を強化するいくつかの古典的な方法が、敵対的な摂動内の相互作用を本質的に減少させることを証明します。負の相関は、さまざまな入力を持つさまざまなDNNを通じてさらに検証されます。これに基づいて、攻撃プロセス中に相互作用に直接ペナルティを課すことを提案します。 、これにより、敵の転送可能性が大幅に向上します。 
[要約]敵対的な伝達可能性と敵対的な摂動内の相互作用との間の負の相関関係を証明します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: A Critique of Self-Expressive Deep Subspace Clustering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_22.html">
      <font color="black">A Critique of Self-Expressive Deep Subspace Clustering</font>
    </a>
  </h2>
  <font color="black">特に、モデルの定式化が複数の方法で不適切であることが多く、データの縮退埋め込みにつながる可能性があることを示します。これは、部分空間の和集合にまったく対応する必要はありません。このアプローチを、非線形多様体の結合、多くの研究は、ニューラルネットワークを使用して元のデータの適切なカーネル埋め込みを学習することを提案しました。これは、埋め込み空間のデータに対する自己表現損失関数によって正規化され、線形部分空間の結合を促進します。埋め込み空間のデータに対して..部分空間クラスタリングは、線形部分空間の和集合でサポートされるデータをクラスター化するように設計された監視されていないクラスタリング手法であり、各部分空間は周囲空間よりも小さい次元のクラスターを定義します。 
[概要]この問題の多くの既存の化身は、線形パルスの自己表現特性の活用に基づいています。これらには、以前のデータよりも低いデータでは適切に対処されていない潜在的な欠陥がいくつか含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Decamouflage: A Framework to Detect Image-Scaling Attacks on
  Convolutional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_23.html">
      <font color="black">Decamouflage: A Framework to Detect Image-Scaling Attacks on
  Convolutional Neural Networks</font>
    </a>
  </h2>
  <font color="black">より正確には、検証したように、1つのデータセットから決定されたしきい値は、他の異なるデータセットにも適用できます。これら3つの方法はそれぞれスタンドアロンで効率的ですが、アンサンブル方式で機能して、検出精度を向上させるだけでなく、潜在的な適応攻撃を強化します。全体として、Decamouflageは、許容可能な実行時オーバーヘッドで、ホワイトボックスとブラックボックスの両方の設定で画像スケーリング攻撃を正確に検出できます。 
[ABSTRACT] decamouflageは、許容可能なランタイムオーバーヘッドで、ホワイトボックスとブラックボックスの両方の設定で画像スケーリング攻撃を検出できます。これは、「画像スケーリング攻撃」と呼ばれる新しい攻撃の影響を検出するために使用できます。これは、幅広いコンピュータビジョンアプリケーション</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Bone Feature Segmentation in Ultrasound Spine Image with Robustness to
  Speckle and Regular Occlusion Noise -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_24.html">
      <font color="black">Bone Feature Segmentation in Ultrasound Spine Image with Robustness to
  Speckle and Regular Occlusion Noise</font>
    </a>
  </h2>
  <font color="black">提案されたセグメンテーション方法は、小規模で通常のオクルージョンノイズに対するモデルの感度を下げるために全分散損失を導入します。提案されたアプローチは、u-netモデルと比較してDiceスコアの2.3％とAUCスコアの1％を改善します。スペックルおよび通常のオクルージョンノイズに対して高いロバスト性を示します。超音波画像には、多くのスペックルおよび通常のオクルージョンノイズが含まれる傾向があり、専門家が骨の特徴を見つけるのは困難で、面倒で、時間がかかります。 
[概要]超音波診断によって脊柱側弯症にアクセスするための鍵は、骨領域を正確にセグメント化し、咬合を測定することです。骨の特徴の効果を測定するには、超音波画像検査が鍵となります。提案されたアプローチは、ダイススコアの2.3％と1％を改善します。 u-ネットモデルと比較したaucスコアの</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Watch, read and lookup: learning to spot signs from multiple supervisors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_25.html">
      <font color="black">Watch, read and lookup: learning to spot signs from multiple supervisors</font>
    </a>
  </h2>
  <font color="black">これらの3つのタスクは、ノイズコントラスト推定とマルチインスタンス学習の原則を使用して統合学習フレームワークに統合されます。さらに、孤立した手話の機械可読英国手話（BSL）辞書データセットBSLDictを提供して、このタスク..ローショットサインスポッティングベンチマークでのアプローチの有効性を検証します。 
[概要]複数のタイプの監視を使用してモデルをトレーニングします。データセット、モデル、コードはプロジェクトページで入手できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Attack and Defense on Point Sets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_26.html">
      <font color="black">Adversarial Attack and Defense on Point Sets</font>
    </a>
  </h2>
  <font color="black">特に、提案された防御方法は、防御を直接対象とする概念実証攻撃によって生成された敵対点群を検出するのにも効果的です。敵対点群からグリッドCNNおよびその逆への転送可能性をさらに分析します。安全性が重要なビジョンタスク（ADASなど）での3Dポイントクラウドデータの有用性は、研究者に3D表現とディープネットワークの堅牢性にもっと注意を払うように促します。 
[概要]攻撃および防御システムは、3Dポイントクラウドが操作されるのを防ぐように設計されています。これは許容できる3Dポイントクラウド表現です。効果的で効果的なポイントポイントポリシーを開発するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-02-28">
        <br><font color="black">2019-02-28</font>
      </time>
    </span>
</section>
<!-- paper0: Texture-based Presentation Attack Detection for Automatic Speaker
  Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_27.html">
      <font color="black">Texture-based Presentation Attack Detection for Automatic Speaker
  Verification</font>
    </a>
  </h2>
  <font color="black">ただし、これらは基本的にアンサンブル内のシステムの相補性に依存します。PADソリューションの一般化可能性を高める動機を持って、このペーパーでは、音声スペクトログラム画像の分析に適用されるテクスチャ記述子の調査について報告します。実験結果は健全性を示しています。私たちのアプローチの例：最大で100の正真正銘のプレゼンテーションのうち16が拒否されますが、100の攻撃プレゼンテーションのうち1つだけが受け入れられます。 
[概要]最新のasvspoof2019コンテストでは、アンサンブル分類器ベースのプレゼンテーション攻撃検出（パッド）アプローチを使用して、ほとんどの形式の攻撃を確実に検出できることが示されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Single-Image Camera Response Function Using Prediction Consistency and
  Gradual Refinement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_28.html">
      <font color="black">Single-Image Camera Response Function Using Prediction Consistency and
  Gradual Refinement</font>
    </a>
  </h2>
  <font color="black">パッチからの予測がより一貫している場合、それはパッチがノイズまたは劣った色の組み合わせによる影響を受けにくいことを意味し、したがって、CRF推定に対してより信頼できる可能性があります。推定するためにいくつかの方法が提案されています。単一の画像からのCRFですが、それらのほとんどは一般的な実際の画像の処理に失敗する傾向があります。これらの問題に対処するために、予測の一貫性と段階的な改良を使用した非深層学習法を導入します。 
[概要]完全に監視された深層学習に基づく最近の方法は、トレーニングデータにあるcrfsに対してのみ機能します。したがって、他の考えられるcrfsを処理できず、問題に対処するために、提供する入力ノイズのパッチに依存します。より一貫性のある予測</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Distribution-Balanced Loss for Multi-Label Classification in Long-Tailed
  Datasets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_29.html">
      <font color="black">Distribution-Balanced Loss for Multi-Label Classification in Long-Tailed
  Datasets</font>
    </a>
  </h2>
  <font color="black">分布バランス損失は、標準のバイナリクロスエントロピー損失に対する2つの重要な変更を通じて、これらの問題に対処します。1）ラベルの共起によって引き起こされる影響を考慮に入れて、重みを再調整する新しい方法、および2）負の値ネガティブラベルの過剰抑制を緩和するための許容正則化..PascalVOCとCOCOの両方での実験は、この新しい損失関数でトレーニングされたモデルが既存の方法よりも大幅なパフォーマンスの向上を達成することを示しています。分布バランス損失と呼ばれる新しい損失関数を提示します。ロングテールクラス分布を示すマルチラベル認識問題の場合。 
[概要]マルチラベル認識の問題は、2つの重要な問題があるため、多くの場合、より困難です。これらには、2つの変更による共起と、ネガティブラベルの優位性が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-19">
        <br><font color="black">2020-07-19</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Convolutional Sequence to Sequence Model for Vertebral Compression
  Fractures Identification in CT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_30.html">
      <font color="black">3D Convolutional Sequence to Sequence Model for Vertebral Compression
  Fractures Identification in CT</font>
    </a>
  </h2>
  <font color="black">このシステムは、脊髄検出用の畳み込みニューラルネットワーク（CNN）と、3Dアーキテクチャをシーケンスするための新しいエンドツーエンドシーケンスを利用して、脊椎のコンパクトな3D表現を統合します。さまざまな表現と分類アプローチを活用するいくつかのモデルバリアントを評価します。そして、大規模なデータセットで検証された最先端の結果を達成するモデルのアンサンブルと、0.955 Area Under the Curve（AUC）の患者レベルの骨折識別を組み合わせたフレームワークを提示します。この研究では、自動を提示します。主要な骨粗鬆症関連の骨折の診断されていない前兆であることが多い、コンピュータートモグラフィー画像上の脊椎圧迫骨折を識別するためのシステム。 
[ABSTRACT]骨粗鬆症性骨折は骨粗鬆症性骨折の最も一般的な原因です。骨粗鬆症によって開発されたシステムはキックスターターで事前注文できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: A Survey On Anti-Spoofing Methods For Face Recognition with RGB Cameras
  of Generic Consumer Devices -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_31.html">
      <font color="black">A Survey On Anti-Spoofing Methods For Face Recognition with RGB Cameras
  of Generic Consumer Devices</font>
    </a>
  </h2>
  <font color="black">そうすることで、フェイスPADの分野における主な課題、進化、現在の傾向を描写し、その将来の研究に関する洞察を提供します。提案された類型に従ってフェイスPADに最も影響を与えた方法の包括的なプレゼンテーションを採用します。時系列で..実験の観点から、この調査論文は、利用可能な公開データベースの要約された概要と、さまざまなPADメソッドの広範な比較実験結果を提供します。 【概要】顔提示攻撃検知（パッド）方式は、一般消費者向け機器のカメラのみが必要です。導入に最も影響を与えた方式の総合表示を採用しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: A Hybrid Approach and Unified Framework for Bibliographic Reference
  Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_32.html">
      <font color="black">A Hybrid Approach and Unified Framework for Bibliographic Reference
  Extraction</font>
    </a>
  </h2>
  <font color="black">次に、38863の参照を含む2401スキャンで画像ベースの参照検出用の大規模なデータセットをリリースします。すべて手動で個別の参照用に注釈が付けられています。この論文の貢献は3つあります。したがって、を克服できる一般的なソリューションが期待されました。以前のアプローチの制限。 
[概要]提案されたシステムは、データセットで98のap50を達成しました。deepbirdは人間の視覚に触発され、レイアウト機能を利用して科学出版物の個々の参照を識別します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-16">
        <br><font color="black">2019-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Interpretations are useful: penalizing explanations to align neural
  networks with prior knowledge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_33.html">
      <font color="black">Interpretations are useful: penalizing explanations to align neural
  networks with prior knowledge</font>
    </a>
  </h2>
  <font color="black">多くの場合、提案された説明可能な深層学習方法の連想は最初のステップで停止し、実践者にモデルへの洞察を提供しますが、それに基づいて行動する方法はありません。特に、モデルが一部の機能に誤って重要性を割り当てていることが示された場合、 CDEPは、提供された説明を直接正規化することにより、実践者がこれらのエラーを修正できるようにします。この論文では、実践者が既存の説明方法を活用して深層学習モデルの予測精度を高めることができる方法であるコンテキスト分解説明ペナルティ（CDEP）を提案します。 。 
[概要]提案された深層学習方法は最初のステップで停止し、実践者にモデルへの洞察を提供しますが、それを活用する方法はありません。これらには、一部の機能に誤って重要性が割り当てられたモデルが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-30">
        <br><font color="black">2019-09-30</font>
      </time>
    </span>
</section>
<!-- paper0: DBLFace: Domain-Based Labels for NIR-VIS Heterogeneous Face Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_34.html">
      <font color="black">DBLFace: Domain-Based Labels for NIR-VIS Heterogeneous Face Recognition</font>
    </a>
  </h2>
  <font color="black">深層学習ベースのドメイン不変特徴学習法は、近赤外線および可視（NIR-VIS）の異種顔認識で進歩しています。各ラベルは特定のドメインの画像を表します。特に、被験者ごとに2つのラベルのセット。 NIR画像用とVIS画像用の1つは、NIR-VIS顔認識モデルのトレーニングに使用されます。 
[概要]これらの方法は、クラス内の変動が大きく、トレーニング用のnir画像がないため、過剰適合する傾向があります。このモデルは、特定のドメインの画像を表します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Dense Relational Image Captioning via Multi-task Triple-Stream Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_35.html">
      <font color="black">Dense Relational Image Captioning via Multi-task Triple-Stream Networks</font>
    </a>
  </h2>
  <font color="black">リレーショナルキャプションは、オブジェクトの組み合わせ間の各関係の明示的な説明を提供します。ビジュアルシーン内のオブジェクト間の関係情報に関して複数のキャプションを生成することを目的とした新しい画像キャプションタスクである高密度リレーショナルキャプションを紹介します。このフレームワークは、両方の多様性において有利です。情報の量。関係に基づく包括的な画像理解につながります。たとえば、関係提案の生成などです。 
[概要]マルチタスクトリプルストリームネットワーク（mttsnet）を提案します。これらは、各単語の正しいキャプションと位置を共同で予測することによってトレーニングされます。提案されたモデルがより多様なキャプションを生成できることを実証しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: In the Wild: From ML Models to Pragmatic ML Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_36.html">
      <font color="black">In the Wild: From ML Models to Pragmatic ML Systems</font>
    </a>
  </h2>
  <font color="black">さらに、NEDで評価された他のすべての方法を大幅に上回る2つの新しい方法（エグザンプラチューニングと最小距離しきい値）を紹介します。野生で堅牢なインテリジェンスを実現するには、さまざまな量のデータと監視から持続的な学習を提供しながら、中断のない推論を提供する学習システムが必要です。 .. NEDは、事前定義されたトレーニングとテストフェーズ、すべてのクラスに十分な量のラベル付きデータ、クローズドワールドの仮定など、過度に強力な仮定の多くを削除しながら、以前のフレームワークの目的を自然に統合します。 
[概要]新しい学習と評価のフレームワークを紹介します-実際には（ned）。特定のレベルのデータから学習できます。nedでは、学習者はデータのストリームに直面し、新しいクラスに適応する必要があります。これらにはガイド付き、少数-ショット、継続的、および自己監視学習</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Rotation-Invariant Local-to-Global Representation Learning for 3D Point
  Cloud -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_37.html">
      <font color="black">Rotation-Invariant Local-to-Global Representation Learning for 3D Point
  Cloud</font>
    </a>
  </h2>
  <font color="black">各レベルの記述子は、3Dポイントの確率的サンプリングを介してグラフに基づくニューラルネットワークから取得されます。これは、学習した表現を入力データの変動に対してロバストにするのに効果的です。提案されたアルゴリズムは、最先端のパフォーマンスを提供します。回転増強3Dオブジェクト認識ベンチマークについて、包括的なアブレーション実験を通じてその特性をさらに分析します。さまざまな幾何学的変換、特に回転を処理するのに適した、3Dポイントクラウドデータのローカルからグローバルへの表現学習アルゴリズムを提案します。変換に関する明示的なデータ拡張なし。 
[概要]提案されたアルゴリズムは、回転のパフォーマンスを示します-拡張された3Dオブジェクト認識ベンチマーク。これは、入力オブジェクトの回転をボトムアップ方式でエンコードするネットワークに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-07">
        <br><font color="black">2020-10-07</font>
      </time>
    </span>
</section>
<!-- paper0: Visuo-Lingustic Question Answering (VLQA) Challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_38.html">
      <font color="black">Visuo-Lingustic Question Answering (VLQA) Challenge</font>
    </a>
  </h2>
  <font color="black">まず、VLQAサブセットを解決するための既存の最良の視覚言語アーキテクチャを調査し、それらが適切に推論できないことを示します。特定の画像テキストモダリティに関する共同推論を導き出し、Visuo-Linguistic質問応答をコンパイルする新しいタスクを提案します（ VLQA）質問応答設定でコーパスに挑戦します。VLQAは、視覚言語のコンテキストを推論するための優れたベンチマークになると考えています。 
[概要]データセット、コード、リーダーボードは米国で入手可能です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: DeepURL: Deep Pose Estimation Framework for Underwater Relative
  Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_39.html">
      <font color="black">DeepURL: Deep Pose Estimation Framework for Underwater Relative
  Localization</font>
    </a>
  </h2>
  <font color="black">提案手法は、単一画像からAUVの6DポーズをAUVの3Dモデルの8つのコーナーを表す2D画像キーポイントとして予測し、カメラ座標の6DポーズをRANSACベースのPnPを使用して決定します。画像変換ネットワークを使用して、レンダリングされた画像と実際の画像の間のギャップを埋め、トレーニング用の合成画像を生成します。さまざまなカメラを使用した実際の水中環境（スイミングプールと海）での実験結果は、提案された堅牢性と精度を示しています。最先端の方法での翻訳エラーと方向エラーの観点からの技術。 
[概要]画像からdへの通信ネットワークを使用して、レンダリングされた画像と実際の画像の間のギャップを埋め、トレーニング用の合成画像を生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-11">
        <br><font color="black">2020-03-11</font>
      </time>
    </span>
</section>
<!-- paper0: Are Adaptive Face Recognition Systems still Necessary? Experiments on
  the APE Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_40.html">
      <font color="black">Are Adaptive Face Recognition Systems still Necessary? Experiments on
  the APE Dataset</font>
    </a>
  </h2>
  <font color="black">さらに、これらの深い特徴をBSIFアルゴリズムを使用して抽出された手作りの特徴と比較します。実験結果は、テンプレートの更新またはランダム選択のないシステムに関して、「最適化された」自己更新方法の有効性を示しています。どちらの場合も、さまざまな評価を行います。そのような種類の機能に最も役立つものを検出するためのテンプレート更新戦略。 
[ABSTRACT] aphotoeveryday（ape）データセットを使用すると、ユーザーはクラス内のユーザーのバリエーションを長期間のキャプチャに埋め込むことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Novel-View Human Action Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_41.html">
      <font color="black">Novel-View Human Action Synthesis</font>
    </a>
  </h2>
  <font color="black">ノベルビューヒューマンアクションシンセシスは、実際の視点からのビデオを前提として、仮想の視点から体の動きを合成することを目的としています。これにより、ネットワークは前景と背景の合成タスクの学習に独立して集中できます。転送されたテクスチャをローカル、ローカルジオデシック近傍内、およびグローバルに対称セマンティックパーツ全体に伝播することによる高密度テクスチャメッシュ。 
[概要]提案された提案されたソリューションは、公開されたntu rgbdデータセットに基づいています。公開された更新されたデータセットで利用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-Supervised Learning of Multi-Object 3D Scene Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_42.html">
      <font color="black">Semi-Supervised Learning of Multi-Object 3D Scene Representations</font>
    </a>
  </h2>
  <font color="black">3D形状は、符号付き距離関数（SDF）として関数空間で連続的に表されます。これは、教師ありの方法でサンプル形状から効率的に事前トレーニングされます。反復エンコーダーは、各オブジェクトの3D形状、ポーズ、およびテクスチャの潜在的な表現を回帰します。入力RGB画像..3Dシーンレイアウトを推測する際のモデルの精度を評価し、その生成機能を示します。 
[概要]私たちのアプローチは、画像をシーンの構成オブジェクトに分解し、単一のビューからそれらの形状、ポーズ、テクスチャを推測することを学びます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: VisualNews : A Large Multi-source News Image Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_43.html">
      <font color="black">VisualNews : A Large Multi-source News Image Dataset</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、GoodNewsデータセットとVisualNewsデータセットの両方で新しい最先端の結果を達成しますが、競合する方法よりもパラメータが大幅に少なくなります。提案された方法は、視覚的機能とテキスト機能を効果的に組み合わせて、イベントやエンティティ..より具体的には、名前付きエンティティのより正確な予測を促進するために、エンティティガイドアテンションレイヤーとともにエンティティ認識モジュールを提案します。 
[概要]提案された方法は、視覚的機能と文学的機能を効果的に組み合わせて、イベントやエンティティなどのより豊富な情報を含むキャプションを生成することができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Object Detection and Pose Estimation of Unseen Objects in Color
  Images with Local Surface Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_44.html">
      <font color="black">3D Object Detection and Pose Estimation of Unseen Objects in Color
  Images with Local Surface Embeddings</font>
    </a>
  </h2>
  <font color="black">テクスチャのないCADモデルのみを必要とし、新しいオブジェクトのトレーニングフェーズを必要としない、画像内のオブジェクトの3Dポーズを検出および推定するためのアプローチを提示します。ただし、多くのポイントが同様のローカルジオメトリを持っている可能性があるため、これらの対応の多くはあいまいです。オブジェクトの表面を指す場合、この埋め込みはCADモデルから直接計算できます。画像の場所については、画像自体から予測することを学びます。 
[概要]私たちのアプローチは、堅牢な学習と3D地理を組み合わせています。これは、ローカル3D粘土の埋め込みに依存して、CADモデルを入力画像に一致させます。これにより、CADモデルの3Dポイントと2D画像のあいまいさが決まります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Rethinking PointNet Embedding for Faster and Compact Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_45.html">
      <font color="black">Rethinking PointNet Embedding for Faster and Compact Model</font>
    </a>
  </h2>
  <font color="black">通常、PointNetの埋め込み関数は、入力ポイントが入力空間の特定のローカル領域に存在するときにアクティブ化されるソフトインジケーター関数のように動作します。実験では、ガウスカーネルを使用したモデルが同等の結果を達成することを確認します。ベースラインメソッドに移行しますが、サンプルあたりの浮動小数点演算がはるかに少なく、PointNetから最大92％削減されます。さらに、ガウスカーネルもPointNetが満たす普遍的な近似定理を満たしていることを示します。 
[ABSTRACT] pointnetはセンサーを埋め込むための新しい方法ですが、ガウスカーネルによるソフトインジケーター機能を埋め込む代わりに、pointnetを含む既存の方法ではリアルタイム情報が依然として困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-31">
        <br><font color="black">2020-07-31</font>
      </time>
    </span>
</section>
<!-- paper0: Regularized Compression of MRI Data: Modular Optimization of Joint
  Reconstruction and Coding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CV/paper_46.html">
      <font color="black">Regularized Compression of MRI Data: Modular Optimization of Joint
  Reconstruction and Coding</font>
    </a>
  </h2>
  <font color="black">これにより、選択した不可逆圧縮標準と互換性のある医療データ圧縮アプローチが確立されます。この方法は、モジュラー最適化構造を持ち、乗数の交互方向法（ADMM）技術と最先端の画像圧縮技術（ブラックボックスモジュールとしてBPG）を繰り返し適用します。MagneticResonanceImaging（MRI）処理チェーンは、医療診断用の画像を再構成するための生データを提供する重要な取得段階から始まります。 
[要約]研究によると、非可逆圧縮は再構成の品質を向上させることさえできます。方法は可逆圧縮に基づいています。方法は再構成の品質を向上させるために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: TextSETTR: Label-Free Text Style Extraction and Tunable Targeted
  Restyling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_0.html">
      <font color="black">TextSETTR: Label-Free Text Style Extraction and Tunable Targeted
  Restyling</font>
    </a>
  </h2>
  <font color="black">ラベルのないAmazonレビューデータでトレーニングすると、各クラスのエグザンプラが4つしかない場合でも、結果のTextSETTRモデルは感情の転送で競争力があります。さらに、ラベルのないコモンクロールデータでトレーニングした単一のモデルが複数の次元に沿って転送できることを示します。方言、感情、形式、礼儀正しさ、感情を含みます。結果として得られる学習スタイルのベクトル空間はテキストスタイルの多くの側面をエンコードするため、他の属性を保持しながら入力テキストの特定の属性を調整する「ターゲットを絞った再スタイル化」ベクトル操作として転送を再キャストします。 
[概要]ラベルのないコモンクロールデータでトレーニングされた単一のモデルは、複数の次元に沿って転送できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Slot Alignment and Recognition for Cross-Lingual NLU -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_1.html">
      <font color="black">End-to-End Slot Alignment and Recognition for Cross-Lingual NLU</font>
    </a>
  </h2>
  <font color="black">結果は、私たちの方法がほとんどの言語で高速整列を使用する単純なラベル投影方法よりも優れており、トレーニング時間の半分だけで、より複雑で最先端の投影方法と競争力のあるパフォーマンスを達成することを示しています。クロスリンガル転送のためにターゲットスロットラベルを共同で調整および予測することを学習する新しいエンドツーエンドモデルを提案します。クロスリンガルNLUの今後の研究を継続するために、MultiATIS ++コーパスをコミュニティにリリースします。 
[概要] multiatisを紹介します-新しい多言語nlucorpus。クロスリンガルatisコーパスを9つの言語に拡張します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br><font color="black">2020-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: What Can We Do to Improve Peer Review in NLP? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_2.html">
      <font color="black">What Can We Do to Improve Peer Review in NLP?</font>
    </a>
  </h2>
  <font color="black">前進する可能性のある方法はいくつかありますが、主な難しさは、NLPコミュニティで一貫して実装するためのインセンティブとメカニズムを作成することです。ピアレビューは、会議の提出の品質を判断するための最良のツールですが、ますます偽りになっています。問題の一部は、査読者とエリアチェアが、リンゴとオレンジの比較を余儀なくされる、不十分に定義されたタスクに直面していることであると主張します。 
[概要]このツールは、リンゴとオレンジを比較するために設計されました。批評家は、明確に定義されていないタスクに直面しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Detect All Abuse! Toward Universal Abusive Language Detection Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_3.html">
      <font color="black">Detect All Abuse! Toward Universal Abusive Language Detection Models</font>
    </a>
  </h2>
  <font color="black">定量的および定性的な評価結果は、私たちのALDアルゴリズムが、虐待的な言語とさまざまなオンラインコミュニティドメインの複数の側面をカバーする7つのALDデータセット全体で6つの最先端のALDアルゴリズムに匹敵するか、それを上回っていることを示しています。虐待的な言語の複数の側面を受け入れるためのアテンションゲートフローメカニズム。この論文では、異なるドメインにわたるいくつかのタイプのALDタスクに対処できる新しい汎用ALDフレームワークであるMACASを紹介します。 
[ABSTRACT] Twitterのように、単一のドメインで単一の虐待的な言語の問題を解決することに焦点を当てたオンラインaldの以前の作品</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: ALFWorld: Aligning Text and Embodied Environments for Interactive
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_4.html">
      <font color="black">ALFWorld: Aligning Text and Embodied Environments for Interactive
  Learning</font>
    </a>
  </h2>
  <font color="black">ALFWorldは、TextWorldで学習した抽象的な知識が、具体的で視覚的に根拠のあるアクションに直接対応する新しいBUTLERエージェントの作成を可能にします。具体化されたエージェントには同じ能力が必要ですが、既存の作業では、抽象的推論と実行の両方に必要なインフラストラクチャがまだ提供されていません。具体的には..バトラーのシンプルなモジュラー設計は、研究者がパイプラインのすべての部分（言語理解、計画、ナビゲーション、視覚的シーン理解など）を改善するためのモデルに集中できるように問題を考慮に入れています。 
[ABSTRACT] alfworldは、エージェントが抽象的なテキストベースのポリシーを学習し、alfredベンチマークから目標を実行できるようにするシミュレーターです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: How do Decisions Emerge across Layers in Neural Models? Interpretation
  with Differentiable Masking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_5.html">
      <font color="black">How do Decisions Emerge across Layers in Neural Models? Interpretation
  with Differentiable Masking</font>
    </a>
  </h2>
  <font color="black">結果として得られるプルーニングは過度に積極的であり、モデルがどのように予測に到達するかを反映しません。これにより、属性ヒートマップをプロットできるだけでなく、ネットワーク層全体で決定がどのように形成されるかを分析できます。まず、予測するため、アプローチが効率的になります。検索ではなく。 
[ABSTRACT] diffmaskは、入力のサブセットに基づく単純なモデルです。テストの対応するレイヤーでネットワークが「知っている」ことを明らかにします。代わりに、予測に影響を与えることなくモデルを削除できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: Leakage-Adjusted Simulatability: Can Models Generate Non-Trivial
  Explanations of Their Behavior in Natural Language? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_6.html">
      <font color="black">Leakage-Adjusted Simulatability: Can Models Generate Non-Trivial
  Explanations of Their Behavior in Natural Language?</font>
    </a>
  </h2>
  <font color="black">（2）CoS-Eおよびe-SNLIデータセットを使用して、2つの既存の生成グラフィカルモデルと2つの新しいアプローチを評価します。私たちが導入する合理化方法の1つは、おおよそ人間レベルのLASスコアを達成します。私たちの貢献は次のとおりです。（1）NL説明を評価するためのリーク調整シミュレーション可能性（LAS）メトリックを導入します。これは、説明がオブザーバーがモデルの予測にどの程度役立つかを測定します。説明が出力を直接リークする方法を制御しながら、出力..この作業では、モデルのシミュレーション可能性の観点から説明を評価する問題に対処します。 
[概要]モデルのシミュレーション可能性の観点から説明を評価する問題に対処します。モデルを人間の観察者の代理として使用し、この選択を2人の被験者で検証します。また、紙漏れ時の不十分なラベルの説明を最適化します。ラススコアを改善する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Extracting a Knowledge Base of Mechanisms from COVID-19 Papers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_7.html">
      <font color="black">Extracting a Knowledge Base of Mechanisms from COVID-19 Papers</font>
    </a>
  </h2>
  <font color="black">科学論文の自然言語からさまざまな形のメカニズム関係を抽出する方法の使用を追求してきました。オープンで自由形式のエンティティ間のメカニズム関係を対象とした、幅広く粗粒度のスキーマを作成します。私たちのアプローチは、多様な概念にわたる一般化をサポートする表現力と幅広さ。 
[概要] covid-19および関連文献で概念を特定しようとしています。これらは、細胞プロセスから経済的影響に至るまで、活動、機能、関連性、因果関係を表しています。私たちのアプローチは、表現力と幅のバランスを取り、多様な概念にわたる一般化をサポートします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Enhancing Fine-grained Sentiment Classification Exploiting Local Context
  Embedding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_8.html">
      <font color="black">Enhancing Fine-grained Sentiment Classification Exploiting Local Context
  Embedding</font>
    </a>
  </h2>
  <font color="black">3つの一般的なデータセットでの実験結果は、ローカルコンテキストアウェアネットワークがローカルコンテキスト機能の抽出において既存のアプローチよりも優れていることを示しています。さらに、ローカルコンテキストアウェアフレームワークは多くのモデルに簡単に適応でき、他のターゲットを改善する可能性があります。レベルのタスク..しかし、以前のアプローチは、ターゲットの感情とそのローカルコンテキストの重要な関連性を無視していました。 
[概要]この論文は、ローカルコンテキストの埋め込みとローカルコンテキストの予測損失を備えたローカルコンテキスト認識ネットワーク（lca-net）を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-02">
        <br><font color="black">2020-10-02</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Recombine and Resample Data for Compositional Generalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_9.html">
      <font color="black">Learning to Recombine and Resample Data for Compositional Generalization</font>
    </a>
  </h2>
  <font color="black">ここでは、潜在的なシンボリック構造にアピールすることなく、構成の一般化の大きなカテゴリをサポートする学習データ拡張スキームのファミリーを紹介します。過去の研究では、シンボリック足場が見つかりました（たとえば、再結合および再サンプリングされた例で拡張されたデータセットで通常の神経シーケンスモデルをトレーニングする2つの言語処理問題の一般化を大幅に改善します---指示に従う（SCAN）と形態学的分析（Sigmorphon 2018）---私たちのアプローチはわずか8つの初期例から新しい構造と緊張の学習を可能にします。
[要約]私たちのアプローチデータ拡張には2つのコンポーネントがあります。これらには、元のトレーニング例の再結合と、外挿を促進するために生成された例のリサンプリングが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Infusing Disease Knowledge into BERT for Health Question Answering,
  Medical Inference and Disease Name Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_10.html">
      <font color="black">Infusing Disease Knowledge into BERT for Health Question Answering,
  Medical Inference and Disease Name Recognition</font>
    </a>
  </h2>
  <font color="black">したがって、BERTを疾患の知識と統合して、これらの重要なタスクを改善します。たとえば、消費者の健康に関する質問応答のBioBERTの精度が68.29％から72.09％に向上し、2つのデータセットで新しいSOTAの結果が観察されます。具体的には、新しい疾患知識注入トレーニング手順を作成し、BERT、BioBERT、SciBERT、ClinicalBERT、BlueBERT、ALBERTなどの一連のBERTモデルで評価します。 
[概要]これらの重要なタスクを改善するために、バートと疾患知識を統合します。これらのモデルは、ほぼすべての場合に拡張でき、疾患知識注入の実行可能性を示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural
  Language Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_11.html">
      <font color="black">IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural
  Language Understanding</font>
    </a>
  </h2>
  <font color="black">12のタスクすべてのベースラインモデルとベンチマーク評価のフレームワークをリリースしているため、誰もがシステムパフォーマンスのベンチマークを行うことができます。タスクのデータセットは、タスクの多様性を確保するためにさまざまなドメインとスタイルにあります。IndoNLUには12が含まれています。単一文の分類から、複雑さのレベルが異なるペア文シーケンスのラベル付けまで、さまざまなタスク。 
[概要]インドネシアの自然言語理解（indonlu）タスクのトレーニング、評価、ベンチマークのための最初の膨大なリソース</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-11">
        <br><font color="black">2020-09-11</font>
      </time>
    </span>
</section>
<!-- paper0: BAE: BERT-based Adversarial Examples for Text Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_12.html">
      <font color="black">BAE: BERT-based Adversarial Examples for Text Classification</font>
    </a>
  </h2>
  <font color="black">BAE、BERTマスク言語モデルからのコンテキスト摂動を使用して敵対的な例を生成するためのブラックボックス攻撃を提示します。現代のテキスト分類モデルは、敵対的な例、モデルによって誤分類される人間が識別できない元のテキストの摂動バージョンの影響を受けやすいです。 BAEは、テキストの一部をマスクし、BERT-MLMを利用してマスクされたトークンの代替を生成することにより、元のテキストのトークンを置き換えて挿入します。 
[ABSTRACT] nlpの最近の作業では、ルールベースのサブセット置換戦略を使用して敵対的な例を生成します。これらには、バートマスク言語モデルからのコンテキスト摂動を使用して敵対的な例を生成するためのブラックボックス攻撃が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-04">
        <br><font color="black">2020-04-04</font>
      </time>
    </span>
</section>
<!-- paper0: COMETA: A Corpus for Medical Entity Linking in the Social Media -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_13.html">
      <font color="black">COMETA: A Corpus for Medical Entity Linking in the Social Media</font>
    </a>
  </h2>
  <font color="black">一般言語のエンティティリンキング（EL）の進歩は進んでいますが、既存のデータセットは、素人の言語での健康用語の複雑な性質に対処できていません。文字列ベースからニューラルベースのモデルまでの20のELベースラインでのベンチマーク実験を通じて、私たちは光を当てました。 2つの挑戦的な評価シナリオの下でエンティティと概念に対して複雑な推論を実行するこれらのシステムの能力について..COMETAでの実験結果は、黄金の弾丸が存在せず、最高の主流技術でさえ、埋めるのに大きなパフォーマンスギャップがあることを示しています。ソリューションは、データのさまざまなビューを組み合わせることに依存しています。 
[概要]健康分野での国民の声を理解できるアプリケーションのニーズが高まっています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-07">
        <br><font color="black">2020-10-07</font>
      </time>
    </span>
</section>
<!-- paper0: Contract Discovery: Dataset and a Few-Shot Semantic Retrieval Challenge
  with Competitive Baselines -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_14.html">
      <font color="black">Contract Discovery: Dataset and a Few-Shot Semantic Retrieval Challenge
  with Competitive Baselines</font>
    </a>
  </h2>
  <font color="black">対照的に、言語モデルベースのソリューションは、特に教師なし微調整が適用された場合に、パフォーマンスが向上します。データセットと参照結果に加えて、法的領域に特化したLMが公開されました。アブレーション研究に加えて、質問に対処しました。利用可能な例の数に応じて、関連するテキストフラグメントの検出精度に関して。 
[概要]このタスクは、法的情報の抽出に関する従来のnliおよび共有タスクとは大幅に異なります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br><font color="black">2019-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding Clinical Trial Reports: Extracting Medical Entities and
  Their Relations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_15.html">
      <font color="black">Understanding Clinical Trial Reports: Extracting Medical Entities and
  Their Relations</font>
    </a>
  </h2>
  <font color="black">ここでは、（a）臨床試験を説明する全文記事から治療と結果を抽出すること（エンティティの識別）、および（b）後者に関して前者について報告された結果を推測すること（関係）の両方のエンドツーエンドのタスクを検討します。次に、これらの純粋なデータ駆動型ベースラインを上回る、試験結果の通常の提示方法に動機付けられた新しい方法を提案します。最後に、非営利団体を対象にモデルのフィールド評価を実行し、既存の薬剤を特定する可能性があります。エンドツーエンドの証拠抽出システムの潜在的な有用性を示して、癌のために再利用されます。 
[概要]医療専門家は、意思決定に情報を提供するために記事から手動で情報を抽出する必要があります。癌に再利用される可能性のある既存の薬を特定することを目的として、非営利団体でモデルのフィールド評価を実行します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-07">
        <br><font color="black">2020-10-07</font>
      </time>
    </span>
</section>
<!-- paper0: Discriminatively-Tuned Generative Classifiers for Robust Natural
  Language Inference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_16.html">
      <font color="black">Discriminatively-Tuned Generative Classifiers for Robust Natural
  Language Inference</font>
    </a>
  </h2>
  <font color="black">特に、「infinilogloss」と呼ばれるログ損失への単純な無制限の変更で強力な結果が得られます。私たちの実験は、GenNLIが、小さなトレーニングセットを含む、いくつかの挑戦的なNLI実験設定全体で、識別ベースラインと事前トレーニングベースラインの両方を上回っていることを示しています。ラベル分布、およびラベルノイズ..生成分類器の識別的微調整のトレーニング目標を調査し、以前の作業からの対数損失微調整に対する改善を示します。 
[ABSTRACT] gennliは、識別ベースラインと事前トレーニング済みベースラインの両方を上回っています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Long-Tail Relation Extraction with Collaborating
  Relation-Augmented Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_17.html">
      <font color="black">Improving Long-Tail Relation Extraction with Collaborating
  Relation-Augmented Attention</font>
    </a>
  </h2>
  <font color="black">間違ったラベリング問題とロングテール関係は、関係抽出における遠隔監視によって引き起こされる2つの主要な課題です。これは、間違ったラベリングの影響を最小限に抑えるために、文と関係に注意を払ってセンテンスバッグで動作します。モデルでは、階層内のリレーション間で共有されるコラボレーションリレーション機能を導入して、リレーション拡張プロセスを促進し、ロングテールリレーションのトレーニングデータのバランスを取ります。 
[ABSTRACT] long-補助アテンションネットワークに加えて、階層内のリレーション間で共有される接続リレーション機能を導入して、リレーションを促進します-プロセスを強化し、ロングテールリレーションのトレーニングデータのバランスを取ります。人気のベンチマークデータセットnytでの実験で、提案されたコーラは、以前の最先端のパフォーマンスを大幅に改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Subword Regularization for Robust Neural Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_18.html">
      <font color="black">Adversarial Subword Regularization for Robust Neural Machine Translation</font>
    </a>
  </h2>
  <font color="black">多様なサブワードセグメンテーションをニューラル機械翻訳（NMT）モデルに公開すると、NMTモデルがさまざまなサブワード候補を経験できるため、機械翻訳の堅牢性が向上することがよくあります。この論文では、トレーニング中の勾配信号が多様なサブワードセグメンテーションを公開するための代替基準..モデルベースの敵対サンプルが、NMTモデルのセグメンテーションエラーに対する感度を効果的に高め、低リソースおよびアウトドメインデータセットでのNMTモデルのパフォーマンスを向上させることを実験的に示します。 
[概要]サブワードセグメンテーションの多様化は、主に事前にトレーニングされたサブバーサリモデルに依存しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br><font color="black">2020-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: Injecting Word Information with Multi-Level Word Adapter for Chinese
  Spoken Language Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_19.html">
      <font color="black">Injecting Word Information with Multi-Level Word Adapter for Chinese
  Spoken Language Understanding</font>
    </a>
  </h2>
  <font color="black">中国のSLUに関する以前の研究では、単語情報が考慮されておらず、意図の検出とスロットの充填に有益な単語の境界を検出できませんでした。2つの中国のSLUデータセットでの実験結果は、モデルが有用な単語情報をキャプチャし、状態を達成できることを示しています。 -最先端のパフォーマンス..さらに重要なことに、ワードアダプターをBERTに接続すると、フレームワークが大幅に改善されます。これは、ワードアダプターの有効性と柔軟性を示しています。 
[概要]この論文では、中国のsluの単語情報を挿入するためのマルチレベルの単語アダプターを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Assessing Phrasal Representation and Composition in Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_20.html">
      <font color="black">Assessing Phrasal Representation and Composition in Transformers</font>
    </a>
  </h2>
  <font color="black">ディープトランスフォーマーモデルは、NLPタスクのパフォーマンスを新しい限界に押し上げ、フレーズなどの複雑な言語入力の高度な処理を示唆しています。これらのモデルのフレーズ表現は、微妙な構成の証拠がほとんどなく、単語の内容に大きく依存していることがわかります。論文では、最先端の事前訓練されたトランスフォーマーにおけるフレーズ表現の体系的な分析を提示します。 
[概要]これらのモデルがフレーズの表現をどのように処理するかについての理解は限られています。フレーズの類似性と意味の変化に関する人間の判断を活用したテストを使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: EdinburghNLP at WNUT-2020 Task 2: Leveraging Transformers with
  Generalized Augmentation for Identifying Informativeness in COVID-19 Tweets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_21.html">
      <font color="black">EdinburghNLP at WNUT-2020 Task 2: Leveraging Transformers with
  Generalized Augmentation for Identifying Informativeness in COVID-19 Tweets</font>
    </a>
  </h2>
  <font color="black">私たちの最も成功したモデルは、半教師あり実験環境で訓練されたRoBERTa、XLNet、BERTweetを含む変圧器のアンサンブルです。このため、より多くの機関がTwitter（災害救援組織および報道機関）をプログラムで監視し、したがってツイートの有益性は、大量のデータからのノイズをフィルタリングするのに役立ちます。提案されたシステムは、テストセットで0.9011のF1スコア（リーダーボードで7位）を達成し、ファストテキスト埋め込みを使用するベースラインシステムと比較してパフォーマンスが大幅に向上しています。 。 
[概要]提案されたシステムは、テストセットで0.9011の重要なf1スコアを持っています。これは、ファストテキスト埋め込みを使用するベースラインシステムと比較してパフォーマンスが大幅に向上していることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-06">
        <br><font color="black">2020-09-06</font>
      </time>
    </span>
</section>
<!-- paper0: Leveraging Discourse Rewards for Document-Level Neural Machine
  Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_22.html">
      <font color="black">Leveraging Discourse Rewards for Document-Level Neural Machine
  Translation</font>
    </a>
  </h2>
  <font color="black">4つの異なる言語ペアと3つの翻訳ドメインでの実験により、私たちのトレーニングアプローチは、他の競合アプローチよりもまとまりのある一貫性のあるドキュメント翻訳を実現できましたが、参照翻訳への忠実性を損なうことはありませんでした。Zh-の場合言語ペアでは、私たちの方法は、ランナーアップよりもLCで2.46パーセントポイント（pp）、COHで1.17 ppの改善を達成し、同時にBLEUスコアで0.63 pp、F_BERTで0.47ppを改善しました。この論文では、強化学習目標を使用して、2つの確立された談話メトリック、語彙凝集（LC）とコヒーレンス（COH）を明示的に最適化するトレーニングアプローチを提案します。 
[要約]ドキュメント内の個々の文の翻訳は、ドキュメントレベルで談話の側面を保持する必要があります。私たちの方法は、次点者よりもlcで2.46パーセントポイント、cohで1.17ppの改善を達成しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Large Product Key Memory for Pretrained Language Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_23.html">
      <font color="black">Large Product Key Memory for Pretrained Language Models</font>
    </a>
  </h2>
  <font color="black">両方がPKM拡張PLMの事前トレーニングに不可欠であり、メモリ使用率とダウンストリームパフォーマンスを向上させることを確認します。新しいメモリ使用量メトリックを定義し、このメトリックを使用して注意深く観察すると、ほとんどのメモリスロットがトレーニング中に古くなったままであることがわかります。 PKM拡張モデル..ただし、それらの経験的アプリケーションは、因果言語モデリングに限定されています。 
[ABSTRACT] plmsを使用すると、わずかなステッチでモデルの容量を効率的に増やすことで予測精度を向上させることができます。これには、メモリなしで事前トレーニングされたモデルの重みの初期化や、フィードフォワードネットワークを置き換えるのではなく追加によるpkmの拡張が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Two are Better than One: Joint Entity and Relation Extraction with
  Table-Sequence Encoders -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_24.html">
      <font color="black">Two are Better than One: Joint Entity and Relation Extraction with
  Table-Sequence Encoders</font>
    </a>
  </h2>
  <font color="black">この作業では、2つの異なるエンコーダー（テーブルエンコーダーとシーケンスエンコーダー）が表現学習プロセスで互いに役立つように設計されている、新しい{\ emテーブルシーケンスエンコーダー}を提案します。ただし、通常、それらは学習に焦点を合わせています。同じ空間内の両方のタスクに必要な情報をキャプチャするための単一のエンコーダ（通常はテーブル形式の表現を学習）。名前付きエンティティの認識と関係の抽出は、2つの重要な基本的な問題です。 
[ABSTRACT]両方のタスクを同時に解決するために共同学習アルゴリズムが提案されています。それらの多くは共同タスクをテーブルとしてキャストします-問題を埋める</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: GRADE: Automatic Graph-Enhanced Coherence Metric for Evaluating
  Open-Domain Dialogue Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_25.html">
      <font color="black">GRADE: Automatic Graph-Enhanced Coherence Metric for Evaluating
  Open-Domain Dialogue Systems</font>
    </a>
  </h2>
  <font color="black">実験結果は、私たちのGRADEが、ピアソンとスピアマンの人間の判断との相関の観点から、多様な対話モデルの測定に関して他の最先端の指標を大幅に上回っていることを示しています。トピックレベルの対話グラフを利用して、新しい評価指標を提案します。 GRADEは、自動対話評価のためのグラフ拡張表現の略です。対話の一貫性を自動的に評価することは、高品質のオープンドメイン対話システムを開発するための挑戦的ですが需要の高い能力です。 
[ABSTRACT]現在の評価指標は、対話フローのきめ細かいトピック遷移ダイナミクスを明示的に考慮せずに、表面の特徴または発話レベルのロジックのみを考慮します。グラフを表す新しい評価指標グレードを提案します。自動対話評価の表現を強化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Fuse Sentences with Transformers for Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_26.html">
      <font color="black">Learning to Fuse Sentences with Transformers for Summarization</font>
    </a>
  </h2>
  <font color="black">広範な実験を通じて、さまざまな設計の選択がTransformerのパフォーマンスに与える影響を調査します。それらは、融合によって要約文をほとんど生成しないか、要約が元の意味を保持できない原因となる誤った融合を生成する傾向があります。私たちの調査結果は、モデリングの重要性を強調しています。効果的な文の融合のための文間の対応点。 
[要約]文を融合するモデルの能力は、元の文の融合を実行する能力を強化することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Predicting Typological Features in WALS using Language Embeddings and
  Conditional Probabilities: ÚFAL Submission to the SIGTYP 2020 Shared Task -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_27.html">
      <font color="black">Predicting Typological Features in WALS using Language Embeddings and
  Conditional Probabilities: ÚFAL Submission to the SIGTYP 2020 Shared Task</font>
    </a>
  </h2>
  <font color="black">類型的特徴の予測に関するSIGTYP2020共有タスクへの提出を提示します。テストデータで70.7％の精度に達し、共有タスクで1位にランク付けされます。制約付きシステムを提出し、類型的特徴のみに基づいて予測します。 WALSデータベース。 
[概要]制約付きシステムを提出し、walsデータベースのみに基づいて類型的特徴を予測します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Shallow-to-Deep Training for Neural Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_28.html">
      <font color="black">Shallow-to-Deep Training for Neural Machine Translation</font>
    </a>
  </h2>
  <font color="black">このようにして、54層エンコーダーを使用したTransformerシステムのトレーニングに成功しました。WMT&#39;16英語-ドイツ語およびWMT&#39;14英語-フランス語翻訳タスクの実験結果は、からのトレーニングよりも$ 1.4 $ $ \ times $速いことを示しています。スクラッチし、2つのタスクで$ 30.33 $と$ 43.29 $のBLEUスコアを達成します。これは、浅いモデルを積み重ねることによって深いモデルを学習する浅いから深いトレーニング方法を開発するように促します。 
[概要]コードは初めて公開されました。変圧器システムを54層エンコーダーに置き換えることで機能します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Language-Grounded Policy in Vision-and-Language Navigation
  with Bayes' Rule -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_29.html">
      <font color="black">Generative Language-Grounded Policy in Vision-and-Language Navigation
  with Bayes' Rule</font>
    </a>
  </h2>
  <font color="black">この論文では、言語モデルを使用してすべての可能な命令の分布を計算する生成的言語ベースのポリシーを設計および調査します。実験では、提案された生成的アプローチが、特に見えない環境で、Room-2-Room（R2R）およびRoom-4-Room（R4R）データセットの識別的アプローチよりも優れていることを示します。ビジョンと言語のナビゲーション（VLN ）は、エージェントが現実的な3D環境で具体化され、指示に従ってゴールノードに到達するタスクです。 
[概要]このようなvlnエージェントを構築するには、2つの可能なアプローチがあります。これらには、識別ポリシーと識別ポリシーが含まれます。データとシステムの組み合わせにより、最先端の結果に近くなります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: BERTering RAMS: What and How Much does BERT Already Know About Event
  Arguments? -- A Study on the RAMS Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_30.html">
      <font color="black">BERTering RAMS: What and How Much does BERT Already Know About Event
  Arguments? -- A Study on the RAMS Dataset</font>
    </a>
  </h2>
  <font color="black">ゴールドの引数をランダムに生成された「臨時語」に置き換えることで敵対的なテスト例を作成するスキームであるNONCEを提案します。（Clarket al。、2019）のアテンションマップベースのプロービングフレームワークを使用すると、BERTのアテンションヘッドは控えめですがイベントの引数を見つけるチャンスをはるかに超える能力は、トレーニングやドメインの微調整がなく、プレイスの最低17.77％からアーティファクトの最高51.61％までさまざまです。クロスセンテンス引数の「ベストヘッド」を分離する手順を提案します。センテンス内引数の検出とは別に検出。 
[概要]これらのヘッドは、パフォーマンスを向上させることができ、一部の役割ではより高くなります。これらは、全体の監督の平均11％と推定されます。これらには、クロスエト引数およびその他のタスクに「最適なヘッド」が含まれます。これらには、が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Text-based RL Agents with Commonsense Knowledge: New Challenges,
  Environments and Baselines -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_31.html">
      <font color="black">Text-based RL Agents with Commonsense Knowledge: New Challenges,
  Environments and Baselines</font>
    </a>
  </h2>
  <font color="black">このような知識により、エージェントは、信じがたい行動を排除することで世界で効率的に行動し、先読み計画を実行して、現在の行動が将来の世界の状態にどのように影響するかを判断できます。TWCでの人間のパフォーマンスを推定するために、ユーザー調査を実施し、将来の改善の余地は十分にあります。TWCに常識的な知識を組み込んだエージェントは、より効率的に行動しながら、より良いパフォーマンスを発揮することを示しています。 
[ABSTRACT] textworld commonsense（twc）は、将来のrlエージェント向けの新しいゲーム環境です。特定の種類の常識知識を持つrlエージェントをトレーニングおよび評価するように設計されています。常識知識を持つエージェントは、より効率的に行動しながら、パフォーマンスが向上することを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Converting the Point of View of Messages Spoken to Virtual Assistants -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_32.html">
      <font color="black">Converting the Point of View of Messages Spoken to Virtual Assistants</font>
    </a>
  </h2>
  <font color="black">仮想アシスタントは文字通りの場合もあります。LSTM、CopyNet、T5などのニューラル機械翻訳（NMT）アプローチについても調査しました。仮想アシスタントが1人のユーザーから音声メッセージを受け取り、ポイントを変換できるシステムを設計しました。メッセージの表示を確認し、結果をターゲットユーザーに配信します。 
[概要]仮想アシスタントは、「私は彼を愛しています」というメッセージを抽出して、bobという名前のユーザーの連絡先に送信できます。仮想アシスタントは、線形テキスト分類モデル、品詞tagging.weを統合するルールベースのモデルを開発しました。別々に訓練された言語モデルを使用して、忠実さと相対的な困惑のためにブループラス流星を使用しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Knowledge-enriched, Type-constrained and Grammar-guided Question
  Generation over Knowledge Bases -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_33.html">
      <font color="black">Knowledge-enriched, Type-constrained and Grammar-guided Question
  Generation over Knowledge Bases</font>
    </a>
  </h2>
  <font color="black">さらに、文法的類似性を特徴とする新しい報酬関数は、強化学習を介して生成の豊かさと構文の正確さの両方を改善するように設計されています。具体的には、エンティティドメインと説明、および関係階層情報は、質問コンテキストを構築するために考慮されますが、条件付きコピーメカニズムは現在の単語タイプに従って質問のセマンティクスを調整するために組み込まれています。広範な実験により、提案されたモデルは、広く使用されている2つのベンチマークデータセットSimpleQuestionおよびPathQuestionで既存の方法よりも大幅に優れていることが示されています。 
[概要]革新的な知識を提案します-強化され、タイプ-制約され、文法-ktgという名前のガイドのモデル。さらに、モデルは、単純な質問や豊かさなど、既存の方法よりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-07">
        <br><font color="black">2020-10-07</font>
      </time>
    </span>
</section>
<!-- paper0: Population Based Training for Data Augmentation and Regularization in
  Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_34.html">
      <font color="black">Population Based Training for Data Augmentation and Regularization in
  Speech Recognition</font>
    </a>
  </h2>
  <font color="black">これは、トレーニングの過程でこれらのハイパーパラメータを変更しないベースラインと比べて遜色なく、8％の相対的なWERの改善があります。これにより、このような最適なスケジュールを見つけるための実験的負担と計算コストが大幅に簡素化されます。最適化の過程で、固定値を使用するよりもパフォーマンスが向上しました。 
[概要]人口ベースのトレーニングが便利なツールであることを示します。この方法で標本を最適化することで音声認識を実験し、ドロップアウトも行います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: PARADE: A New Dataset for Paraphrase Identification Requiring Computer
  Science Domain Knowledge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_35.html">
      <font color="black">PARADE: A New Dataset for Paraphrase Identification Requiring Computer
  Science Domain Knowledge</font>
    </a>
  </h2>
  <font color="black">実験によると、最先端のニューラルモデルと専門家ではない人間のアノテーターの両方がPARADEでのパフォーマンスが低いことが示されています。専門的なドメイン知識を必要とする言い換え識別のためのPARADEと呼ばれる新しいベンチマークデータセットを提示します。 -チューニングにより、0.709のF1スコアが達成されます。これは、他の言い換え識別データセットでのパフォーマンスよりもはるかに低くなります。 
[ABSTRACT]パレードには、語彙および構文レベルではほとんど重複しないが、コンピューターサイエンスドメインの知識に基づいて意味的に同等である言い換えが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: AbuseAnalyzer: Abuse Detection, Severity and Target Prediction for Gab
  Posts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_36.html">
      <font color="black">AbuseAnalyzer: Abuse Detection, Severity and Target Prediction for Gab
  Posts</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、Gabからの7601件の投稿を含む最初の種類のデータセットを紹介します。これは、虐待の存在、重大度、および虐待行為のターゲットの観点からオンライン虐待を調べます。オンラインソーシャルメディアプラットフォームの広範な人気により、情報が広まりました。より速く、それはまた、ヘイトスピーチ、不快な言葉、性的および人種差別的な意見などのようなさまざまなタイプの広範なオンライン虐待をもたらしました。また、これらのタスクに対処するシステムを提案し、虐待の存在について最大80％の精度を取得します。乱用ターゲットの予測では82％、乱用の重大度の予測では約65％。 
[概要]虐待の深刻度と標的を推定することにほとんど焦点が当てられていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-30">
        <br><font color="black">2020-09-30</font>
      </time>
    </span>
</section>
<!-- paper0: INSPIRED: Toward Sociable Recommendation Dialog Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_37.html">
      <font color="black">INSPIRED: Toward Sociable Recommendation Dialog Systems</font>
    </a>
  </h2>
  <font color="black">自動評価と人間評価の両方で、戦略を組み込んだモデルはベースラインモデルよりも優れています。したがって、映画の推薦のための1,001人の人間と人間の対話の新しいデータセットであるINSPIREDを提示し、推奨を成功させるための手段を示します。分析によると、社交的な推薦戦略は個人的な意見を共有したり、励ましでコミュニケーションしたりするなど、より頻繁に成功する推奨につながります。 
[概要]成功した推奨に基づいて推奨戦略に関連する注釈スキームを作成します。人間がコミュニケーションで推奨を行う方法をよりよく理解するために、推奨に関連する注釈システムを設計します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-29">
        <br><font color="black">2020-09-29</font>
      </time>
    </span>
</section>
<!-- paper0: DART: A Lightweight Quality-Suggestive Data-to-Text Annotation Tool -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_38.html">
      <font color="black">DART: A Lightweight Quality-Suggestive Data-to-Text Annotation Tool</font>
    </a>
  </h2>
  <font color="black">大量の構造化データに注釈を付けることで実行されたシミュレーション実験では、DARTはアクティブラーニングで必要な注釈の総数を減らし、関連するラベルをテーブルまたはツリー構造の形式で自動的に提案することが示されています。構造化データにテキストの説明でラベルを付ける一般的なタスクのための注釈ツール、Data AnnotatoR Tool（DART）。 
[概要]ツールは、大量のデータに注釈を付ける際の人間の労力を軽減するインタラクティブなアプリケーションです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: An Empirical Study on Model-agnostic Debiasing Strategies for Robust
  Natural Language Inference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_39.html">
      <font color="black">An Empirical Study on Model-agnostic Debiasing Strategies for Robust
  Natural Language Inference</font>
    </a>
  </h2>
  <font color="black">また、テキストスワップ、単語置換、言い換えなどのデータ拡張を実行し、さまざまな（すべてではありませんが）敵対的攻撃に同時に対抗する効率を証明します。次に、専門家の混合（MoE）を変更することにより、明確な既知のバイアスに対抗しようとします。アンサンブル法を使用して、複数のNLIバイアスを同時に軽減することは簡単ではなく、モデルレベルのアンサンブル法はMoEアンサンブル法よりも優れていることを示します。まず、さまざまな敵対データセットで事前トレーニングされたモデルを含む一般的なニューラルNLIモデルをベンチマークします。 
[概要]このホワイトペーパーでは、nliモデルを複数の異なる敵対的攻撃に対して堅牢にする方法を探ります。次に、専門家（moe）のアンサンブル手法を組み合わせて変更することで、異なる既知のバイアスと戦うことを試み、軽減するのは簡単ではないことを示します。同時に複数のnliバイアス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: FGN: Fusion Glyph Network for Chinese Named Entity Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_40.html">
      <font color="black">FGN: Fusion Glyph Network for Chinese Named Entity Recognition</font>
    </a>
  </h2>
  <font color="black">（2）スライディングウィンドウとスライスを使用する方法を提供します-文字のBERT表現とグリフ表現を融合するための注意。コンテキストとグリフの間の潜在的なインタラクティブな知識をキャプチャする可能性があります。実験は4つのNERデータセットで行われ、FGNがタガーとしてのLSTM-CRFは、中国のNERの新しい最先端のパフォーマンスを実現します。中国のNERは困難な作業です。 
[概要]漢字には潜在的なグリフ情報が含まれていますが、これは見過ごされがちです。この方法では、融合メカニズムにインタラクティブな情報が追加される場合もあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-15">
        <br><font color="black">2020-01-15</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Topic-Guided Conversational Recommender System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_41.html">
      <font color="black">Towards Topic-Guided Conversational Recommender System</font>
    </a>
  </h2>
  <font color="black">広範な実験により、トピック予測、アイテムの推奨、応答の生成という3つのサブタスクに対するアプローチの有効性が実証されています。TG-ReDialはhttps://github.com/RUCAIBox/TG-ReDialで入手できます。TGに基づく-ReDialでは、トピックに基づく会話による推奨のタスクを提示し、このタスクへの効果的なアプローチを提案します。 
[概要]効果的なクロタを開発するには、高品質のデータセットのサポートが不可欠です。新しいデータセットはtgに基づいています-リダイヤル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: On the Ability and Limitations of Transformers to Recognize Formal
  Languages -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_42.html">
      <font color="black">On the Ability and Limitations of Transformers to Recognize Formal
  Languages</font>
    </a>
  </h2>
  <font color="black">トランスフォーマーは、多数のNLPタスクで反復モデルに取って代わりました。実験では、トランスフォーマーはこのサブクラスでうまく機能し、学習したメカニズムは私たちの構築と強く相関していることがわかりました。おそらく驚くべきことに、LSTMとは対照的に、トランスフォーマーはのみうまく機能します。よく知られている複雑さの尺度に従って言語をより複雑にするため、パフォーマンスが低下する正規言語のサブセットで。 
[概要]異なる異なる構文プロパティをモデル化する能力の違いはほとんど不明のままです。ただし、これらはこのサブクラスでうまく機能することを示唆しており、学習したメカニズムは私たちの構築と強く相関しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-23">
        <br><font color="black">2020-09-23</font>
      </time>
    </span>
</section>
<!-- paper0: Latent linguistic embedding for cross-lingual text-to-speech and voice
  conversion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_43.html">
      <font color="black">Latent linguistic embedding for cross-lingual text-to-speech and voice
  conversion</font>
    </a>
  </h2>
  <font color="black">十分に訓練された英語の潜在的な言語埋め込みを使用して、Voice Conversion Challenge 2020に含まれるいくつかのドイツ語、フィンランド語、および北京語の話者用の言語間TTSおよびVCシステムを作成することにより、私たちの方法が言語間VCを作成するだけでなく話者の類似性が高いだけでなく、追加の手順を実行することなく、言語間のTTSにシームレスに使用できます。ただし、知覚される自然さの主観的な評価は、ターゲットスピーカー間で異なるようであり、これは将来の改善の1つの側面です。システムは、単にターゲットスピーカーの音声を複製するだけでなく、特定のフレーミングの下で元の音声よりも優れていると見なすことができる新しい音声を本質的に作成します。 
[概要]クロスリンガルスピーチネスは、追加の手順を実行せずに使用できるシステムです。このシステムは、十分に訓練された英語の潜在的な言語埋め込みを使用して作成され、いくつかのドイツ語、フィンランド語のクロスリンガルttsおよびvcシステムを作成しました。 、およびマンダリンスピーカー</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Precise Task Formalization Matters in Winograd Schema Evaluations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_44.html">
      <font color="black">Precise Task Formalization Matters in Winograd Schema Evaluations</font>
    </a>
  </h2>
  <font color="black">尊敬されている英国の常識的な推論ベンチマークであるWinogradSchema Challenge（WSC）のパフォーマンスは、最近、SuperGLUEリーダーボードでチャンスの精度から89％に急上昇しましたが、それに応じて推論能力が大幅に向上したことを裏付ける証拠は比較的少ないです。この急増の前後に使用された形式化の間を補間し、（i）複数の選択肢としてタスクをフレーミングするとパフォーマンスが2〜6ポイント向上し、（ii）事前トレーニングされた言語モデリングの再利用を含むいくつかの追加手法を見つける2つのWinogradスキーマデータセットヘッドは、ハイパーパラメータに対するモデルの極端な感度を軽減できます。将来のベンチマーク作成者には、報告された結果に対する形式化の決定の影響を最小限に抑えるために、追加の構造を課すことをお勧めします。 
[概要]改善は、データセットのユーザーによるタスク形式の最近の変更によるものです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Reducing Sentiment Bias in Language Models via Counterfactual Evaluation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_45.html">
      <font color="black">Reducing Sentiment Bias in Language Models via Counterfactual Evaluation</font>
    </a>
  </h2>
  <font color="black">正則化は、同等レベルの困惑と意味的類似性を維持しながら、公平性メトリックを改善します。公正な機械学習の文献から個人およびグループの公平性メトリックを採用することにより、感情バイアスを定量化し、2つの異なるコーパスでトレーニングされた大規模モデルを示します（ニュース記事、およびウィキペディア）はかなりのレベルのバイアスを示します。条件付けコンテキスト（たとえば、書き込みプロンプト）と言語モデルを前提として、生成されたテキストの感情が機密属性の値の変化によって影響を受けるかどうか（およびどのように）を分析します（たとえば、 、国名、職業、性別）、反事実的評価の形式を使用した条件付けのコンテキストで。 
[要約]生成されたテキストの感情が、反事実的評価の形式を使用して、条件付けコンテキストの機密属性の値の変化によって影響を受けるかどうか（およびどのように）を分析します。次に、埋め込みと感情予測を提案します-言語の正則化から派生モデルの潜在的表現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-08">
        <br><font color="black">2019-11-08</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Debiasing NLU Models from Unknown Biases -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_46.html">
      <font color="black">Towards Debiasing NLU Models from Unknown Biases</font>
    </a>
  </h2>
  <font color="black">最近提案されたバイアス除去方法は、この傾向を緩和するのに効果的であることが示されています。提案されたフレームワークは一般的であり、既存のバイアス除去方法を補完します。さらに、評価は、フレームワークを適用すると全体的な堅牢性が向上することを示唆しています。 
[ABSTRACT] debiasingは、モデルが事前に知らないうちにバイアスを使用することを防ぐ自己バイアス解除フレームワークです。これにより、これらの既存の方法は、特定のバイアスを特にターゲットにすることなく、チャレンジデータセットの改善を維持できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-25">
        <br><font color="black">2020-09-25</font>
      </time>
    </span>
</section>
<!-- paper0: MAVEN: A Massive General Domain Event Detection Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_47.html">
      <font color="black">MAVEN: A Massive General Domain Event Detection Dataset</font>
    </a>
  </h2>
  <font color="black">MAVENは、データ不足の問題を軽減し、より一般的なイベントタイプをカバーします。これらの問題を軽減するために、4,480のWikipediaドキュメント、118,732のイベント言及インスタンス、および168のイベントタイプを含むMAssive eVENt検出データセット（MAVEN）を提示します。限定イベント既存のデータセットのタイプは、一般ドメインのイベントを十分にカバーできないため、EDモデルのアプリケーションが制限されます。 
[概要]大規模なイベント検出データセット（maven）には、4、480のウィキペディアドキュメント、118、732のイベント言及インスタンス、および168のイベントタイプが含まれています。最新のモデルを再現し、Mavenの徹底的な評価を行います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br><font color="black">2020-04-28</font>
      </time>
    </span>
</section>
<!-- paper0: Dense Relational Image Captioning via Multi-task Triple-Stream Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_48.html">
      <font color="black">Dense Relational Image Captioning via Multi-task Triple-Stream Networks</font>
    </a>
  </h2>
  <font color="black">さらに、明示的なリレーショナルモジュールを使用してオブジェクトの埋め込みを調整することで、MTTSNetのパフォーマンスを向上できることがわかりました。キャプションの生成を学習するだけでなく、各単語のPOSを予測するフレームワークを適用します。この目的のために、各単語の正しいキャプションとPOSを共同で予測することによってトレーニングされる、各POSを担当する3つの反復ユニットで構成されるマルチタスクトリプルストリームネットワーク（MTTSNet）を提案します。 
[概要]マルチタスクトリプルストリームネットワーク（mttsnet）を提案します。これらは、各単語の正しいキャプションと位置を共同で予測することによってトレーニングされます。提案されたモデルがより多様なキャプションを生成できることを実証しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Don't Parse, Insert: Multilingual Semantic Parsing with Insertion Based
  Decoding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_49.html">
      <font color="black">Don't Parse, Insert: Multilingual Semantic Parsing with Insertion Based
  Decoding</font>
    </a>
  </h2>
  <font color="black">セマンティック解析は、自然言語理解システムの重要なコンポーネントの1つです。この論文では、これら2つの問題を克服するために挿入トランスフォーマーに基づく非自己回帰パーサーを提案します。このモデルは推論時に遅く、解析を生成します。 O（n）デコードステップ（nはターゲットシーケンスの長さ）。 
[概要]最先端の方法は、自己回帰シーケンスからシーケンスモデルに基づいて解析を直接生成します。この方法は、言語間転送学習設定ではうまく機能しません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: FANG: Leveraging Social Context for Fake News Detection Using Graph
  Representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_50.html">
      <font color="black">FANG: Leveraging Social Context for Fake News Detection Using Graph
  Representation</font>
    </a>
  </h2>
  <font color="black">特に、FANGは、フェイクニュース検出のタスクを大幅に改善し、トレーニングデータが限られている場合でも堅牢です。フェイクニュース検出のための新しいグラフィカルなソーシャルコンテキスト表現および学習フレームワークであるFactual News Graph（FANG）を提案します。 ..パフォーマンスを対象とした以前のコンテキストモデルとは異なり、私たちの焦点は表現学習にあります。 
[ABSTRACT] fangは、社会的文脈を忠実度の高い表現に取り込むのに優れています。これらの表現は、ニュースメディアの報道の事実を予測するなど、関連するタスクに一般化されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-18">
        <br><font color="black">2020-08-18</font>
      </time>
    </span>
</section>
<!-- paper0: A Cascade Approach to Neural Abstractive Summarization with Content
  Selection and Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_51.html">
      <font color="black">A Cascade Approach to Neural Abstractive Summarization with Content
  Selection and Fusion</font>
    </a>
  </h2>
  <font color="black">このようなシステムは、テキスト生成とともにコンテンツ選択を評価する必要があるため、要約評価にも課題をもたらしますが、後者の評価は未解決の問題のままです。最後に、ニューラルテキスト要約でカスケードパイプラインを利用する方法について説明します。そして、将来の研究のための重要な方向性に光を当てます。ニューラルテキストの要約にカスケードアーキテクチャを支持する実証的研究を提示します。 
[概要]重要なコンテンツを識別し、それらをまとまりのあるテキストにつなぎ合わせるカスケードパイプラインのパフォーマンスは、エンドシステムのエンドツーエンドのパフォーマンスに匹敵するか、それを上回っています。この調査は、米国中の研究者によって実施されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Generalizable and Explainable Dialogue Generation via Explicit Action
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_52.html">
      <font color="black">Generalizable and Explainable Dialogue Generation via Explicit Action
  Learning</font>
    </a>
  </h2>
  <font color="black">私たちが提案するアプローチは、ベンチマークマルチドメインデータセットであるMultiWOZの潜在的なアクションベースラインを上回ります。この明示的なアクション表現は、言語の構成構造を介して一般化を促進します。また、説明可能な生成プロセスを可能にします。 
[ABSTRACT]アクションアノテーションの必要性を軽減するために、潜在アクションラーニングが導入されました。この問題に対処するために、発話を単語のスパンとして表す自然言語アクションを学習することを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: On the importance of pre-training data volume for compact language
  models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_53.html">
      <font color="black">On the importance of pre-training data volume for compact language
  models</font>
    </a>
  </h2>
  <font color="black">さらに、過去の非常に少量の事前トレーニングデータでは、タスク固有のコーパスに対する中間の事前トレーニングステップでは実質的な改善が得られないことを示します。持続可能な実践に向けた取り組みとして、事前トレーニングの影響を調査します。コンパクトな言語モデルのデータ量..言語モデリングの最近の進歩により、計算量が多く、リソースを必要とする最先端のモデルが生まれました。 
[概要]調査によると、パフォーマンスの高いモデルは、わずか100MBのテキストで取得されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Visuo-Lingustic Question Answering (VLQA) Challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_54.html">
      <font color="black">Visuo-Lingustic Question Answering (VLQA) Challenge</font>
    </a>
  </h2>
  <font color="black">VLQAは、視覚言語コンテキストを推論するための優れたベンチマークになると考えています。特定の画像テキストモダリティに関する共同推論を導き出し、視覚言語質問応答（VLQA）チャレンジコーパスをコンパイルする新しいタスクを提案します。質問応答設定..最初に、VLQAサブセットを解決するために、既存の最良のビジョン言語アーキテクチャを調査し、それらが適切に推論できないことを示します。 
[概要]データセット、コード、リーダーボードは米国で入手可能です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Attention Mechanism with Query-Value Interaction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_55.html">
      <font color="black">Improving Attention Mechanism with Query-Value Interaction</font>
    </a>
  </h2>
  <font color="black">クエリとキーの相互作用と同様に、クエリと値の間にも固有の関連性があり、クエリと値の相互作用を組み込むと、クエリの特性に応じてカスタマイズされた値を学習することで出力を向上させる可能性があります。ただし、クエリと値の相互作用は既存の注意方法では無視され、最適ではない可能性があります。クエリ対応の注意値を学習し、それらを元の値および注意の重みと組み合わせて最終出力を形成できるクエリ値相互作用関数を提案します。 
[ABSTRACT]この関数は、入力クエリ、キー、および値を合計を使用して出力にマッピングする3項関数として使用できます。これらは、クエリとキーの間の相互作用に基づく注意の重みに関連しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Generating Instructions at Different Levels of Abstraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_56.html">
      <font color="black">Generating Instructions at Different Levels of Abstraction</font>
    </a>
  </h2>
  <font color="black">技術的な指示を生成するとき、さまざまな抽象化レベルで世界の複雑なオブジェクトを記述すると便利なことがよくあります。この目的のために、複雑なオブジェクトの構造をきれいにキャプチャできるAI計画の方法である階層計画の使用を紹介します。 Minecraftでさまざまな抽象化レベルで構築命令を生成する方法を示します。 
[概要] Minecraftのさまざまなレベルの管理で構築命令を生成する方法を示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-hop Inference for Question-driven Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_57.html">
      <font color="black">Multi-hop Inference for Question-driven Summarization</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案された方法が2つの非ファクトイドQAデータセット、つまりWikiHowとPubMedQAで常に最先端の方法を上回っていることを示しています。具体的には、質問との関連性と、人間を介した異なる文間の相互関係を共同でモデル化します。 -要約された回答を正当化するための重要な文をキャプチャするマルチホップ推論モジュールのようなものです。質問駆動型の要約は、ソースドキュメントを要約して、事実に反しない質問に対する簡潔で有益な回答を生成する効果的なアプローチとして最近研究されました。 
[概要]新しい方法はマルチホップ選択ジェネレーター（msg）と呼ばれ、マルチホップ推論を質問主導の質問主導の質問主導の要約に組み込み、生成された要約の正当化を提供するように設計されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: A Co-Interactive Transformer for Joint Slot Filling and Intent Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_58.html">
      <font color="black">A Co-Interactive Transformer for Joint Slot Filling and Intent Detection</font>
    </a>
  </h2>
  <font color="black">広範な実験により、モデルが相互作用の知識をうまく取り込むことが実証されています。さらに、提案された共同対話型モジュールを積み重ねて、相互作用機能で相互に段階的に強化することができます。この論文では、検討する共同対話型トランスフォーマーを提案します。 2つのタスク間の相互影響。 
[概要] 2つのタスクは密接に関連しており、一方のタスクの情報をもう一方のタスクで使用できます。ただし、これまでのアプローチでは、関連する2つのタスク間の相互影響を同時にモデル化することはできません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: What-if I ask you to explain: Explaining the effects of perturbations in
  procedural text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_59.html">
      <font color="black">What-if I ask you to explain: Explaining the effects of perturbations in
  procedural text</font>
    </a>
  </h2>
  <font color="black">説明タスクをマルチタスク学習問題としてモデル化することにより、段落からそのような説明を構築するシステムであるQUARTETを提示します。また、驚くべき副次的効果も提示します。このモデルは、ダウンストリームで絶対F1が7％向上する新しいSOTAも実現します。 QAタスク..QUARTETは、最近のプロセス理解ベンチマークのいくつかの強力なベースラインと比較して、（手順テキストの文に基づいて）より良い説明を提供します。 
[概要]雌のウサギが病気になった場合、人間はウサギの個体数への影響を簡単に説明できます。これは、エンドタスクのパフォーマンスを犠牲にして適切な説明を行う必要がないことを説明しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-04">
        <br><font color="black">2020-05-04</font>
      </time>
    </span>
</section>
<!-- paper0: Multilingual Knowledge Graph Completion via Ensemble Knowledge Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/cs.CL/paper_60.html">
      <font color="black">Multilingual Knowledge Graph Completion via Ensemble Knowledge Transfer</font>
    </a>
  </h2>
  <font color="black">5つの実世界の言語固有のKGでの実験は、KEnSが補完的な知識を効果的に識別して活用することにより、KG完了に関する最先端の方法を一貫して改善することを示しています。これは、複数の独立して維持されている知識の転送のため、非常に困難です。 KGは、アライメント情報の不足と記述された事実の不一致によって妨げられることがよくあります。既存のKG埋め込みアプローチは、主に単一のKG内の事実を学習および予測しますが、より妥当なソリューションは、複数の言語固有のKGの知識から利益を得るでしょう。 KGごとに、データの品質とカバレッジに独自の長所と制限があります。 
[概要]複数の言語-特定のkgには、データ品質とカバレッジに独自の長所と制限があります。kensは、複数の言語にまたがる学習とアンサンブル知識の伝達を埋め込むための新しい研究フレームワークです。複数の言語固有のkgの埋め込みで機能します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-07">
        <br><font color="black">2020-10-07</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Non-Parallel Voice Conversion with Augmented Classifier Star Generative
  Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.AS/paper_0.html">
      <font color="black">Non-Parallel Voice Conversion with Augmented Classifier Star Generative
  Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">第三に、変換された音声信号をリアルタイムの実装を可能にするのに十分な速さで生成でき、適度にリアルな音声を生成するために数分のトレーニング例しか必要としません。この論文では、新しく導入されたものを含む、StarGANの3つの定式化について説明します。 「AugmentedclassifierStarGAN（A-StarGAN）」と呼ばれる新しいStarGANバリアントを、非並列VCタスクで比較します。次に、単一のジェネレータネットワークを使用して複数のドメインにわたるマッピングを同時に学習できるため、利用可能なトレーニングを十分に活用できます。すべてのドメインに共通する潜在的な機能をキャプチャするために複数のドメインから収集されたデータ。 
[概要] stargan-vcは、音声ジェネレータのトレーニングに並列発話、翻訳、または時間調整手順を必要としません。リアルタイムの解釈を可能にするのに十分な速さで変換された音声信号を生成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Classification of Speech with and without Face Mask using Acoustic
  Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.AS/paper_1.html">
      <font color="black">Classification of Speech with and without Face Mask using Acoustic
  Features</font>
    </a>
  </h2>
  <font color="black">これらの音響機能は、ComParE 2020のComParE機能、bag-of-audio-words、DeepSpectrum、およびauDeep機能の最先端のベースラインとともに使用されます。この動機で、スピーカーがフェイスマスクを着用しているかどうかを確認します。与えられたスピーチは、Computational Paralinguistics Evaluation（ComParE）2020のタスクとして含まれています。調査により、音響機能の有効性が明らかになり、ComParE 2020ベースラインとのスコアレベルの融合により、テストセットでの加重平均想起率は73.50％になります。 
[要約]調査では、音響機能の有効性が示され、2020年のベースラインと比較したスコアレベルの融合により、テストセットでの重み付けされていない平均再現率は73. 50％になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Vrengt: A Shared Body-Machine Instrument for Music-Dance Performance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.AS/paper_2.html">
      <font color="black">Vrengt: A Shared Body-Machine Instrument for Music-Dance Performance</font>
    </a>
  </h2>
  <font color="black">この論文では、マルチユーザー楽器のパラダイムを振り返り、サウンドデザインのツールとしてソニフィケーションを使用して共有楽器を作成するアプローチについて説明し、楽器の演奏者の主観的な評価を振り返ります。探索では「時空間マトリックス」を使用しました。 &quot;、特に音のマイクロインタラクションに焦点を当てています。最終公演では、2つのMyoアームバンドを使用して、ダンサーの腕と脚の筋肉活動をキャプチャし、ワイヤレスヘッドセットマイクを使用して呼吸音をキャプチャしました。 
[概要] vrengtの作品は、ミュージシャンとダンサーによって開発されました。音楽を探索するために「時空間マトリックス」を使用して開発されました。プロジェクトは、vrengtによって紙の論文で公開されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Investigating U-Nets with various Intermediate Blocks for
  Spectrogram-based Singing Voice Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.AS/paper_3.html">
      <font color="black">Investigating U-Nets with various Intermediate Blocks for
  Spectrogram-based Singing Voice Separation</font>
    </a>
  </h2>
  <font color="black">これらのブロックに基づいてU-netを実装し、複雑な値のスペクトログラムでトレーニングして、大きさと位相の両方を考慮します。畳み込み層と完全に接続された層で構成される特定のブロックを使用すると、最新のSDRが実現されます。 0.9 dBの大きなマージンによるMUSDBの歌声分離タスク。この論文では、さまざまな中間スペクトログラム変換ブロックを紹介します。 
[概要]これらのブロックに基づく多くのu-net-がsvsタスクに提案されています。u-netアーキテクチャで使用できるさまざまなタイプの中間ブロックを評価および比較する既存の作業はありませんでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-02">
        <br><font color="black">2019-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Population Based Training for Data Augmentation and Regularization in
  Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.AS/paper_4.html">
      <font color="black">Population Based Training for Data Augmentation and Regularization in
  Speech Recognition</font>
    </a>
  </h2>
  <font color="black">これは、トレーニング中にこれらのハイパーパラメータを変更しないベースラインと比べて遜色なく、相対的なWERが8％向上しています。SpecAugmentをこのように最適化することで音声認識を実験し、ドロップアウトも行います。5.18％の単語誤りを取得します。 LibriSpeechのテストのレート-その他。 
[概要]人口ベースのトレーニングが便利なツールであることを示します。この方法で標本を最適化することで音声認識を実験し、ドロップアウトも行います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Texture-based Presentation Attack Detection for Automatic Speaker
  Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.AS/paper_5.html">
      <font color="black">Texture-based Presentation Attack Detection for Automatic Speaker
  Verification</font>
    </a>
  </h2>
  <font color="black">PADソリューションの一般化可能性を高める動機を持って、この論文では、音声スペクトログラム画像の分析に適用されるテクスチャ記述子の調査について報告します。特に、生成モデルに基づく一般的なフィッシャーベクトル特徴空間を提案します。 ASVSpoof 2019の競争では、アンサンブル分類器ベースのプレゼンテーション攻撃検出（PAD）アプローチを使用して、ほとんどの形式の攻撃を確実に検出できることが示されました。 
[概要]最新のasvspoof2019コンテストでは、アンサンブル分類器ベースのプレゼンテーション攻撃検出（パッド）アプローチを使用して、ほとんどの形式の攻撃を確実に検出できることが示されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Emotion Invariant Speaker Embeddings for Speaker Identification with
  Emotional Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.AS/paper_6.html">
      <font color="black">Emotion Invariant Speaker Embeddings for Speaker Identification with
  Emotional Speech</font>
    </a>
  </h2>
  <font color="black">研究は、IEMOCAPデータベースの4つの異なる感情クラスを使用して実施されます。話者の感情状態は、音声生成に大きな影響を与えることがわかり、中立状態から生じる音声とは異なる可能性があります。さまざまな感情を持つ平均的な話者モデルベースのフレームワークに対して、感情不変の話者埋め込みを使用した話者識別研究の精度。 
[ABSTRACT]音声は、さまざまな感情を持つ話者を識別するために使用できます。これらは、ニュートラルな音声を使用したさまざまな話者の一連の例に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: HLT-NUS Submission for NIST 2019 Multimedia Speaker Recognition
  Evaluation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.AS/paper_7.html">
      <font color="black">HLT-NUS Submission for NIST 2019 Multimedia Speaker Recognition
  Evaluation</font>
    </a>
  </h2>
  <font color="black">オーディオシステムはx-vectorベースの話者埋め込みに基づいていますが、顔認識システムはResNetおよびInsightFaceベースの顔埋め込みに基づいています。マルチメディア研究は幅広いアプリケーションに注目を集めており、話者認識も例外ではありません。 。音声入力と視覚入力用に別々のシステムを開発した後、2つのモダリティからのシステムをスコアレベルで融合して、それらの情報をまとめて使用しました。 
[概要]マルチメディア研究は幅広いアプリケーションに注目を集めています。話者認識も例外ではありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: D3Net: Densely connected multidilated DenseNet for music source
  separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.AS/paper_8.html">
      <font color="black">D3Net: Densely connected multidilated DenseNet for music source
  separation</font>
    </a>
  </h2>
  <font color="black">マルチ拡張畳み込みをDenseNetアーキテクチャと組み合わせることにより、D3Netは、拡張畳み込みをDenseNetに単純に組み込むときに存在するエイリアシングの問題を回避します。MUSDB18データセットの実験結果は、D3Netが平均信号で最先端のパフォーマンスを達成することを示しています。 6.01 dBの歪み比（SDR）に対する..D3Netは、異なる解像度を同時にモデル化するために、単一レイヤーに異なる拡張係数を持つ新しいマルチ拡張畳み込みを含みます。 
[ABSTRACT]新しい畳み込み畳み込みには、異なる解像度を同時にモデル化するために、単一レイヤーに異なる拡張拡張拡張畳み込み係数を持つ新しいマルチステート畳み込みが含まれます。新しい畳み込み畳み込みは、畳み込み畳み込みへの新しいアプローチです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Sound Event Localization and Detection Using Activity-Coupled Cartesian
  DOA Vector and RD3net -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.AS/paper_9.html">
      <font color="black">Sound Event Localization and Detection Using Activity-Coupled Cartesian
  DOA Vector and RD3net</font>
    </a>
  </h2>
  <font color="black">シングルステージシステムとして、SEDタスクとSELタスクの両方の単一ターゲットとしてアクティビティ結合デカルトDOAベクトル〜（ACCDOA）表現を使用する統合トレーニングフレームワークを提案します。モデルを一般化するために、3つのデータ拡張を適用します。手法：等化混合データ拡張〜（EMDA）、1次アンビソニックス〜（FOA）信号のローテーション、SpecAugmentのマルチチャネル拡張..DCASE2020タスクに提出されたシステム〜3：サウンドイベントのローカリゼーションと検出（SELD）について説明します。このレポートでは。 
[ABSTRACT]システムはsedタスクとselタスクを個別に組み合わせて動作し、後でそれらの結果を組み合わせます。サウンドイベントの場所とアクティビティを効率的に推定するために、rd3netをさらに提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-22">
        <br><font color="black">2020-06-22</font>
      </time>
    </span>
</section>
<!-- paper0: Latent linguistic embedding for cross-lingual text-to-speech and voice
  conversion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.AS/paper_10.html">
      <font color="black">Latent linguistic embedding for cross-lingual text-to-speech and voice
  conversion</font>
    </a>
  </h2>
  <font color="black">最近提案された音声複製システムNAUTILUSは、転写されていない音声を使用して見えない音声を複製できるため、統合された言語間TTS / VCシステムを開発するためにそれを使用する可能性を調査します。言語間音声生成はシナリオです。音声発話は、元々話されていなかった言語のターゲットスピーカーの声で生成されます。十分に訓練された英語の潜在的な言語埋め込みを使用して、含まれるいくつかのドイツ語、フィンランド語、およびマンダリンスピーカー用のクロスリンガルTTSおよびVCシステムを作成します。 Voice Conversion Challenge 2020では、私たちの方法が、話者の類似性が高いクロスリンガルVCを作成するだけでなく、追加の手順を実行することなく、クロスリンガルTTSにシームレスに使用できることを示しています。 
[概要]クロスリンガルスピーチネスは、追加の手順を実行せずに使用できるシステムです。このシステムは、十分に訓練された英語の潜在的な言語埋め込みを使用して作成され、いくつかのドイツ語、フィンランド語のクロスリンガルttsおよびvcシステムを作成しました。 、およびマンダリンスピーカー</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Tatum-Level Drum Transcription Based on a Convolutional Recurrent Neural
  Network with Language Model-Based Regularized Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-09/eess.AS/paper_11.html">
      <font color="black">Tatum-Level Drum Transcription Based on a Convolutional Recurrent Neural
  Network with Language Model-Based Regularized Training</font>
    </a>
  </h2>
  <font color="black">提案された方法では、データムレベルの確率的言語モデル（ゲート付き回帰ユニット（GRU）ネットワークまたは反復認識バイグラムモデル）が、ドラムスコアの広範なコレクションからトレーニングされます。このようなフレーム間での主な問題ただし、DNNは、これらのパターンの長期的な音楽的に意味のある構造をフレームレベルで学習することが難しいため、推定開始時間がシンボリックドラムスコアに表示される典型的なタタムレベルのパターンと一致しないことが多いということです。これを解決するには問題は、フレームからデータムへのDNNの正規化されたトレーニング方法を提案します。 
[概要]提案された方法は、ディープニューラルネットワーク（dnns）によって開発されました。この方法では、フレームのパターンをtatum dnnに置き換える必要があります。この方法は、ドラムの開始時間を予測するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
