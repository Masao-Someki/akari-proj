<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-09-03の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: WaveGrad: Estimating Gradients for Waveform Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.SD/paper_0.html">
      <font color="black">WaveGrad: Estimating Gradients for Waveform Generation</font>
    </a>
  </h2>
  <font color="black">WaveGradはトレーニングが簡単で、対数尤度の加重変分下限を暗黙的に最適化します。経験的な実験により、WaveGradは、より少ない連続演算で強い尤度ベースの自己回帰ベースラインに一致する高忠実度のオーディオサンプルを生成することがわかります。WaveGradは非-autoregressive、推論中に一定数の生成ステップのみを必要とします。 
[ABSTRACT] wavegradは非自己回帰であり、testimony.itの実行中に一定数の条件付きステップが必要です。トレーニングは簡単で、対数尤度の重み付き変分下限を暗黙的に最適化します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Architecture Search For Keyword Spotting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.SD/paper_1.html">
      <font color="black">Neural Architecture Search For Keyword Spotting</font>
    </a>
  </h2>
  <font color="black">Googleの音声コマンドデータセットで提案された方法を評価し、文献で一般的に報告されている12クラスの発話分類の設定で97％を超える最先端の精度を達成しました。ディープニューラルネットワークは最近人気のあるソリューションになりましたキーワードスポッティングシステムを使用すると、音声でスマートデバイスを制御できます。次に、見つかったセルを深度と幅の両方に拡大して、競争力のあるパフォーマンスを実現します。 
[ABSTRACT]許容可能なメモリフットプリントを維持しながら、音響信号から抽出された特徴に基づいてキーワードスポッティングのパフォーマンスを向上させるのに役立つ畳み込みニューラルネットワークモデルを検索します。見つかったセルは、競争力のあるパフォーマンスを実現するために深さと幅の両方で拡大されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Neural Crossbreed: Neural Based Image Metamorphosis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.IV/paper_0.html">
      <font color="black">Neural Crossbreed: Neural Based Image Metamorphosis</font>
    </a>
  </h2>
  <font color="black">目的のモーフィング値で2つの潜在ベクトルを補間して中間画像を生成する、事前トレーニング済みのBigGANを使用してモーフィング用のトレーニングデータセットを準備します。これは、事前トレーニング済みの生成モデルを使用して画像モーフィングに対処する最初の試みです。セマンティックトランスフォーメーションを学習します。実験は、ニューラルクロスブリードが従来のアプローチに関連するさまざまな制限を克服し、高品質のモーフィング画像を生成することを示しています。 
[ABSTRACT]これは、セマンティックトランスフォーメーションを学習するためにビッグデータに対処する最初の試みです。ネットワークは、形状と外観の補間を個別に処理できます。コンテンツとスタイル転送のもつれを解くことで使用でき、豊かなユーザビリティを実現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Analysis of Dilation in Children and its Impact on Iris Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.IV/paper_1.html">
      <font color="black">Analysis of Dilation in Children and its Impact on Iris Recognition</font>
    </a>
  </h2>
  <font color="black">虹彩認識のパフォーマンスは、拡張変動が存在する場合にも分析されます。成人の虹彩に関する研究では、さまざまな年齢での虹彩認識パフォーマンスに対する拡張の大きな影響が示されました。ただし、大人の結果は必ずしも子供に変換されるとは限りません。 
[ABSTRACT]拡張は年齢の要因であり、時間の経過とともに子供たちに見られます。他の研究では、虹彩の認識に大きな影響があることが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: DARWIN: A Highly Flexible Platform for Imaging Research in Radiology -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.IV/paper_2.html">
      <font color="black">DARWIN: A Highly Flexible Platform for Imaging Research in Radiology</font>
    </a>
  </h2>
  <font color="black">私たちのディープラーニングモジュールは、分類、検出、およびセグメンテーションタスクの最先端のアーキテクチャを統合します。ラジオミクスまたはディープラーニング研究実験を行うには、放射線科医または医師が必要なプログラミングスキルを把握する必要があります。コーディングの経験が限られている場合はコストがかかります。ハイパーパラメータを手動で選択したり、アルゴリズムを選択して最適なものを自動的に検索したりできます。 
[ABSTRACT] radiomicsモジュールは、1000を超える次元の特徴を抽出できます。多くのドラッグ可能な教師ありおよび教師なし機械学習モデルを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: SAR Tomography via Nonlinear Blind Scatterer Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.IV/paper_3.html">
      <font color="black">SAR Tomography via Nonlinear Blind Scatterer Separation</font>
    </a>
  </h2>
  <font color="black">レイオーバーの分離は、建物の再構成やバイオマスの推定など、多くの合成開口レーダーアプリケーションの基本となっています。提案された方法は、カーネルPCAを使用してデータの次元を人工的に増加させ、前述の制限を緩和します。レイオーバーされた散乱体の位相中心を取得する方法。計算コストのかかるトモグラフィーの反転を回避します。 
[ABSTRACT] sarトモグラフィーとして知られているプロセスは、通常、sarイメージングモデルの反転によって解決されます。このプロセスには、混合次元に沿った散乱プロファイルの取得が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: On the Structures of Representation for the Robustness of Semantic
  Segmentation to Input Corruption -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.IV/paper_4.html">
      <font color="black">On the Structures of Representation for the Robustness of Semantic
  Segmentation to Input Corruption</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、堅牢性との関係を理解するためにSoftmax、IBE、およびSigmoidを使用する最適化目標の結果として得られた構造を比較する分析を提供します。 IBE 40.3とSoftmaxベースライン37.5の両方と比較した、mIOUが42.1の重大度レベル。 
[要約]シグモイドとibeを組み合わせて堅牢性を向上させることを提案します。また、シグモイドとibeを組み合わせてタスクを向上させ、</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: GAIT: Gradient Adjusted Unsupervised Image-to-Image Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.IV/paper_5.html">
      <font color="black">GAIT: Gradient Adjusted Unsupervised Image-to-Image Translation</font>
    </a>
  </h2>
  <font color="black">画像から画像への変換（IIT）は、敵対学習の開発により最近大きく進歩しました。最近のほとんどの作業では、敵対的損失を利用して、変換された画像セットとターゲット画像セットの分布を一致させています。勾配の調整ターゲット画像のソーベル応答とソース画像の調整済みソーベル応答の間のL2ノルムである損失が利用されます。 
[要約]提案された方法は、問題を実証するために準備されたクラゲ-ヘッケルデータセットで検証されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Transform Quantization for CNN Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.IV/paper_6.html">
      <font color="black">Transform Quantization for CNN Compression</font>
    </a>
  </h2>
  <font color="black">最初に、CNN量子化のレートと歪みの理論を紹介し、レート-歪み最適化問題として最適な量子化を提起します。以前のCNN量子化技法は、重みとアクティブ化の結合統計を無視する傾向があり、特定の最適化されたCNNパフォーマンスを生成します量子化ビットレート、またはトレーニング中にのみ共同統計を考慮し、すでにトレーニングされたCNNモデルの効率的な圧縮を促進しない。変換量子化は、CNNの低ビットレート圧縮を容易にするために、単一フレームワークで量子化と次元削減（非相関）技術を統合します。変換ドメインにおける効率的な推論。 
[ABSTRACT]以前のcnn量子化技法は、重みとアクティブ化の結合統計を無視する傾向があり、特定の量子化ビットレートで準最適なcnnパフォーマンスを生成します。変換量子化は、単一フレームワークで量子化と空間削減（非相関）技法を統合し、低機能のビットレート圧縮</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Classification of stroke using Neural Networks in Electrical Impedance
  Tomography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.IV/paper_7.html">
      <font color="black">Classification of stroke using Neural Networks in Electrical Impedance
  Tomography</font>
    </a>
  </h2>
  <font color="black">}、Analysis \＆PDE 11、2018]幾何学的解釈があり、EITデータからの計算に導電率の完全な画像の計算が含まれていません。典型的なEITは、ぼやけのためにストロークEITには最適ではありません。1つの有望なアプリケーション脳卒中-EIT、または脳卒中の虚血性または出血性への分類。 
[ABSTRACT]これは、患者に電流を供給し、結果として得られる皮膚の電圧を測定することに基づいています。つまり、画像再構成方法を正則化する必要があり、通常は画像がぼやけます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-14">
        <br><font color="black">2020-04-14</font>
      </time>
    </span>
</section>
<!-- paper0: Semantic Segmentation of Neuronal Bodies in Fluorescence Microscopy
  Using a 2D+3D CNN Training Strategy with Sparsely Annotated Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.IV/paper_8.html">
      <font color="black">Semantic Segmentation of Neuronal Bodies in Fluorescence Microscopy
  Using a 2D+3D CNN Training Strategy with Sparsely Annotated Data</font>
    </a>
  </h2>
  <font color="black">スパースアノテーションのみを使用する半教師付き代替戦略は、トレーニング時間が長くなり、達成されたモデルは2D CNNと比較して容量が増える傾向にあり、同様の結果を得るにはより多くのグラウンドトゥルースデータが必要になります。一方、3D CNNは、これらの問題を克服するために、スパース2Dアノテーションでネイティブ3D CNNモデルをトレーニングするための2段階の戦略を提案します。ここで、欠落しているラベルは2D CNNモデルによって推測され、損失計算中の重み付けされた方法での手動注釈。 
[ABSTRACT] 2フェーズ戦略は、ネイティブ3d cnnモデルをトレーニングすることです。これらには、欠落したラベルがローカルモデルによって推論され、計算された損失中に重み付けされた方法で手動アノテーションと組み合わされる3dアノテーションが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-31">
        <br><font color="black">2020-08-31</font>
      </time>
    </span>
</section>
<!-- paper0: Depth Range Reduction for 3D Range Geometry Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.IV/paper_9.html">
      <font color="black">Depth Range Reduction for 3D Range Geometry Compression</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、3Dジオメトリの深度範囲を縮小して、より低いエンコーディング周波数（またはより少ない数のエンコーディング期間）を使用して2D画像内に格納できるようにする新しい方法を紹介します。このデータを効率的に保存、送信、またはストリーミングすることはより困難になります。3D範囲データを圧縮するための一般的なアプローチの1つは、通常の2D画像のカラーチャネル内でデータをエンコードすることです。 
[要約]提案された方法はスキャンの前に行われ、既存のさまざまな3d範囲形式の圧縮業界と容易に互換性があります。3d範囲データの取得がより高速で正確になるにつれて、これを効率的に保存、送信、またはストリーミングすることがより困難になりますデータ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Attention Enriched Deep Learning Model for Breast Tumor Segmentation in
  Ultrasound Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.IV/paper_10.html">
      <font color="black">Attention Enriched Deep Learning Model for Breast Tumor Segmentation in
  Ultrasound Images</font>
    </a>
  </h2>
  <font color="black">検証結果は、顕著な注意レイヤーのないモデルに比べて腫瘍セグメンテーションの精度が向上することを示しています。顕著な注意モデルは、タスク固有の知識をディープラーニングに組み込む手段を提供することにより、他の臓器の医用画像の処理における精度と堅牢性を高める可能性があります。アーキテクチャ..アプローチは、510画像のデータセットで90.5％のダイス類似係数を達成しました。 
[要約]提案されたアプローチは、注意ブロックをau-netアーキテクチャに導入します。これは、顕著性レベルが高い空間領域に優先順位を付ける機能表現を学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-20">
        <br><font color="black">2019-10-20</font>
      </time>
    </span>
</section>
<!-- paper0: SPARE3D: A Dataset for SPAtial REasoning on Three-View Line Drawings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.IV/paper_11.html">
      <font color="black">SPARE3D: A Dataset for SPAtial REasoning on Three-View Line Drawings</font>
    </a>
  </h2>
  <font color="black">これらの質問に答えるために、SPARE3Dデータセットを提示します。SPARE3Dが空間推論のための新しい問題の定式化とネットワーク設計を刺激し、インテリジェントロボットが2Dセンサーを介して3Dの世界で効果的に動作できるようにすることを願っています。認知科学と心理測定学に基づいて、SPARE3Dには、ビューの一貫性、カメラのポーズ、および形状の生成に関する3種類の2D-3D推論タスクが含まれており、難易度が高くなっています。 
[ABSTRACT] spare3dは認知科学と心理測定学に基づいています。3種類の2d-3d推論タスクが含まれており、難易度が高くなっています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br><font color="black">2020-03-31</font>
      </time>
    </span>
</section>
<!-- paper0: Application of LSTM architectures for next frame forecasting in
  Sentinel-1 images time series -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.IV/paper_12.html">
      <font color="black">Application of LSTM architectures for next frame forecasting in
  Sentinel-1 images time series</font>
    </a>
  </h2>
  <font color="black">垂下式、注ぎ込み式、de probl {\ `e} me donn {\ &#39;e}、il est n {\&#39; e} cessaire de choisir l&#39;architectureoptime .. Dans cet article、les mod {\` e} les Stack -LSTM、CNN-LSTMおよびConvLSTM sont appliqu {\ &#39;e} s {\ `a} une s {\&#39; e} rie temporelle d&#39;imagesレーダーセンチネル-1、ただし{\ &#39;e} tant de pr {\ &#39;e} dire la prochaineオカレンスdans une s {\&#39; e} quence .. Les r {\ &#39;e} sultats exp {\&#39; e} rimentaux {\ &#39;e} valu {\&#39; e} s {\ `a} l&#39;aide desはパフォーマンスRMSとRMSとMAEを実行し、tempsはtraitmentとl&#39;indexを類似します{\ &#39;e} SSIM、montrent que chacune des troisアーキテクチャはプットプロデュワールデボンr {\&#39; e} sultats en fonction des param {\ `e} tres utilis {\ &#39;e} s。 
[ABSTRACT] de nos jours、les algorithmuuuuuuuuuuuuuuuuuuuu.s.com、lstm。 et et et convlstm、lstm、lstm。 et convlstm.leしかし、 `e &#39;tant de pr` ee&#39;、 `de pr &#39;e&#39; de pr（e）quence。 `これは私が今まで見た中で最高のものではない</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Breast mass detection in digital mammography based on anchor-free
  architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.IV/paper_13.html">
      <font color="black">Breast mass detection in digital mammography based on anchor-free
  architecture</font>
    </a>
  </h2>
  <font color="black">トランケーション正規化法を導入し、適応型ヒストグラム等化と組み合わせて、乳房の質量と周囲の環境との間のコントラストを強化します。一方、小さいデータサイズによって引き起こされる過剰適合問題を解決するために、自然変形データ拡張法と修正法を提案しますデータの複雑さに基づくトレーニングデータの動的更新方法を使用して、限られたデータを効果的に利用します。最後に、転移学習を使用してトレーニングプロセスを支援し、モデルの堅牢性を大幅に向上させます。結果：INbreastデータセットでは、各画像に再現率が0.930である一方で、平均0.495の誤検知。 DDSMデータセットで、各画像に0.599の偽陽性がある場合、再現率は0.943に達します。結論：データセットINbreastとDDSMの実験結果は、提案されたBMassDNetが現在の上位ランクの方法よりも優れた検出性能を発揮できることを示しています。 
[要約]これは乳房の腫瘤の不均一性とその周囲の環境の複雑さが原因です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient, high-performance pancreatic segmentation using multi-scale
  feature extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.IV/paper_14.html">
      <font color="black">Efficient, high-performance pancreatic segmentation using multi-scale
  feature extraction</font>
    </a>
  </h2>
  <font color="black">ここでは、効率的なマルチスケール画像機能の利用により高性能を達成することに重点を置いた、高度に最適化されたニューラルネットワークベースの膵臓セグメンテーションアルゴリズムであるMoNetを紹介します。人工知能ベースの画像分析手法が臨床的適用性に到達するために、高性能の開発アルゴリズムは非常に重要です。たとえば、自然画像に基づく既存のセグメンテーションアルゴリズムは、パラメーターの使用において効率的でも、医用画像用に最適化されていません。 
[ABSTRACT]私たちは、自分がどのようになっているかを知ることができたかどうかわかりません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: W-Net: Dense Semantic Segmentation of Subcutaneous Tissue in Ultrasound
  Images by Expanding U-Net to Incorporate Ultrasound RF Waveform Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.IV/paper_15.html">
      <font color="black">W-Net: Dense Semantic Segmentation of Subcutaneous Tissue in Ultrasound
  Images by Expanding U-Net to Incorporate Ultrasound RF Waveform Data</font>
    </a>
  </h2>
  <font color="black">専門の臨床医と研修生による手でラベル付けされた画像で構成されるカスタムデータセットが実験に使用され、現在、次のカテゴリに分類されています：皮膚、脂肪、脂肪筋膜/間質、筋肉および筋膜。以前の作業とは異なり、背景クラスを使用せずに、画像内のすべてのピクセルにラベルを付けます。SubQの潜在的な用途には、形成外科、脂肪幹細胞採取、リンパ管モニタリング、特定のタイプの腫瘍の検出/治療などがあります。 
[ABSTRACT] subqは、ラベリングに使用できる新しいタイプの超音波です。形成外科、rfu.sを含みます。幹細胞モニタリング、および他の形態の腫瘍</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: 3D dynamic hand gestures recognition using the Leap Motion sensor and
  convolutional neural networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.IV/paper_16.html">
      <font color="black">3D dynamic hand gestures recognition using the Leap Motion sensor and
  convolutional neural networks</font>
    </a>
  </h2>
  <font color="black">最後の完全に接続されたレイヤーを削除し、考慮されるジェスチャークラスと同じ数のニューロンを持つ新しいレイヤーを追加することにより、人気のあるResNet-50アーキテクチャの変更バージョンが採用されています。このメソッドは、既存の参照データセットと予備に適切に適用されています。テストは、ユーザーが実行する動的ジェスチャーのリアルタイム認識のためにすでに実行されています。ジェスチャーの分類は、深い畳み込みニューラルネットワーク（CNN）を使用して実行されます。 
[要約]このメソッドは、非静的なジェスチャーを識別するために使用されます。これは、深い畳み込みニューラルネットワーク（cnn）に基づいています。このメソッドは、既存のシステムに正常に適用されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br><font color="black">2020-03-03</font>
      </time>
    </span>
</section>
<!-- paper0: SURF-SVM Based Identification and Classification of Gastrointestinal
  Diseases in Wireless Capsule Endoscopy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.IV/paper_17.html">
      <font color="black">SURF-SVM Based Identification and Classification of Gastrointestinal
  Diseases in Wireless Capsule Endoscopy</font>
    </a>
  </h2>
  <font color="black">内視鏡検査は、消化管（GIT）疾患の診断に大きく貢献します。次に、関心点で抽出された特徴を使用して、サポートベクターマシン（SVM）のトレーニングとテストを行い、画像を自動的に正常または正常に分類します。この原稿では、関心点の検出に使用される記述子は、高速化されたロバスト機能（SURF）であり、CIELAB空間色に変換された画像に含まれる色情報を使用して、より適切に処理されます。識別。 
[要約]ワイヤレスカプセル内視鏡検査は、使いやすさと効率の点でゆっくりと引き継がれています。これらの画像は、Gitの異常組織と正常組織を自動的に検出することを目的とした、効果的かつ認知的な効率的なアプローチを実装するために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Unified Generative Adversarial Networks for Controllable Image-to-Image
  Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.IV/paper_18.html">
      <font color="black">Unified Generative Adversarial Networks for Controllable Image-to-Image
  Translation</font>
    </a>
  </h2>
  <font color="black">さらに、私たちのモデルは、3つの新しい損失、つまり、色の損失、制御可能な構造に基づくサイクルの一貫性の損失、および制御可能な構造に基づく自己コンテンツ保持の損失を通じて、画像から画像へのマッピングを学習します。2つの困難な画像変換タスクの実験、つまり、手のジェスチャーからジェスチャーへの変換とクロスビュー画像の変換は、私たちのモデルが説得力のある結果を生成し、両方のタスクで他の最先端の方法よりも大幅に優れていることを示しています。また、Fr \ &#39;echet ResNet生成された画像の品質を評価する距離（FRD）。 
[要約]モデルは、制御可能な構造で条件付けされた画像を生成できます。これらには、クラスラベル、オブジェクトのキーポイント、人間の骨格、シーンのセマンティックマップが含まれます。これは、外観情報を提供できる単一の画像で構成されます。また、制御可能な構造を提供して、画像の品質</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-12">
        <br><font color="black">2019-12-12</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Neural Crossbreed: Neural Based Image Metamorphosis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_0.html">
      <font color="black">Neural Crossbreed: Neural Based Image Metamorphosis</font>
    </a>
  </h2>
  <font color="black">さらに、意味的変化の学習により、ポーズやカメラビューが大きく異なるオブジェクトを含む画像間でモーフィングを実行できるようになります。事前にトレーニングされたBigGANを使用してモーフィング用のトレーニングデータセットを準備します。目的のモーフィング値での2つの潜在ベクトル..潜在的な空間での入力画像の意味的変化を学習してモーフィング効果を作成できるフィードフォワードニューラルネットワークであるNeural Crossbreedを提案します。 
[ABSTRACT]これは、セマンティックトランスフォーメーションを学習するためにビッグデータに対処する最初の試みです。ネットワークは、形状と外観の補間を個別に処理できます。コンテンツとスタイル転送のもつれを解くことで使用でき、豊かなユーザビリティを実現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: MetaSimulator: Simulating Unknown Target Models for Query-Efficient
  Black-box Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_1.html">
      <font color="black">MetaSimulator: Simulating Unknown Target Models for Query-Efficient
  Black-box Attacks</font>
    </a>
  </h2>
  <font color="black">この目的のために、さまざまな既存のネットワークの攻撃で生成されたクエリシーケンスを収集することにより、マルチタスクの形式でトレーニングデータを構築します。ディープニューラルネットワークのセキュリティ問題を調査するために、多くの敵対的な攻撃が提案されています。 、クエリの大部分を攻撃でMetaSimulatorに転送できるため、クエリの複雑さが大幅に軽減されます。 
[ABSTRACT]ターゲットモデルは、ターゲットモデルの機能を偽造するための代替モデルです。ただし、検索の複雑さは依然として高く、防御メカニズムを導入することで、このような攻撃を簡単に防御できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Identifying Statistical Bias in Dataset Replication -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_2.html">
      <font color="black">Identifying Statistical Bias in Dataset Replication</font>
    </a>
  </h2>
  <font color="black">ImageNetデータセットの複製であるImageNet-v2を調査します。このモデルでは、データ品質の標準の人間内ループ測定を制御した後でも、モデルの精度が大幅に（11〜14％）低下します。データセットレプリケーションのバイアスを認識して回避するための具体的な推奨事項。特定された統計的バイアスを修正した後、元の$ 11.7 \％\ pm 1.0 \％$の精度低下の推定$ 3.6 \％\ pm 1.5 \％$のみが残ることを示します行方不明で。 
[ABSTRACT]私たちの研究では、データセットレプリケーションへの標準的なアプローチが統計的バイアスを導入する直観的ではないが重要な方法を提示します。特定された統計的バイアスを除外した後、推定$ 3 6.69999のみであることを示します。調査結果はwwwで公開されています。 github。 com / madrylab /データセット-分析分析分析</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-19">
        <br><font color="black">2020-05-19</font>
      </time>
    </span>
</section>
<!-- paper0: DARWIN: A Highly Flexible Platform for Imaging Research in Radiology -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_3.html">
      <font color="black">DARWIN: A Highly Flexible Platform for Imaging Research in Radiology</font>
    </a>
  </h2>
  <font color="black">DARWINは、ユーザーが実験用のカスタムパイプラインを定義する可能性も提供します。これにより、ユーザーは手動でハイパーパラメーターを選択したり、アルゴリズムを選択して最適なものを自動的に検索したりできます。当社のディープラーニングモジュールは、最先端の分類アーキテクチャを統合しています、検出、およびセグメンテーションタスク。 
[ABSTRACT] radiomicsモジュールは、1000を超える次元の特徴を抽出できます。多くのドラッグ可能な教師ありおよび教師なし機械学習モデルを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Comprehensive Semantic Segmentation on High Resolution Aerial Imagery
  for Natural Disaster Assessment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_4.html">
      <font color="black">Comprehensive Semantic Segmentation on High Resolution Aerial Imagery
  for Natural Disaster Assessment</font>
    </a>
  </h2>
  <font color="black">データセットの課題について説明し、このデータセットの最先端の方法をトレーニングして、これらの方法がどれだけ災害状況を認識できるかを評価します。この論文では、視覚認識のための大規模なハリケーンマイケルデータセットを提示します。災害シナリオで、セマンティックセグメンテーションのための最先端のディープニューラルネットワークモデルを分析します。最後に、将来の研究の課題について説明します。 
[ABSTRACT]データセットは約2000枚の高解像度の航空写真で構成されます。注釈付きの地面が含まれています-セマンティックセグメンテーションの真実データ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Retaining Image Feature Matching Performance Under Low Light Conditions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_5.html">
      <font color="black">Retaining Image Feature Matching Performance Under Low Light Conditions</font>
    </a>
  </h2>
  <font color="black">また、低照度画像強調（LLIE）アルゴリズムを適用すると、適切な特徴抽出アルゴリズムと組み合わせると、特徴マッチングがさらに向上することを示しています。低照度画像での特徴マッチングパフォーマンスを維持するための最適な設定を見つけるには、次の効果を調べます。特徴検出器の特徴許容しきい値を変更し、特徴検出の前に低光量画像エンハンスメント（LLIE）の形式で前処理を追加します。低光量画像でも、従来の手作りの特徴検出器を使用した特徴照合は依然として合理的に実行されます。しきい値パラメータを下げることによっても。 
[ABSTRACT]このホワイトペーパーでは、低照度環境での特徴検出アルゴリズムのパフォーマンスを確認します。さらに、低照度画像でも、従来の特徴検出器を使用した特徴照合は、かなり適切に機能することを確認しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: IAUnet: Global Context-Aware Feature Learning for Person
  Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_6.html">
      <font color="black">IAUnet: Global Context-Aware Feature Learning for Person
  Re-Identification</font>
    </a>
  </h2>
  <font color="black">ソースコードはhttps://github.com/blue-blue272/ImgReID-IAnet。で入手できます。ここで、空間的相互作用は、単一フレームの異なるボディパーツ間のコンテキスト依存関係を計算することを学習します。時間的相互作用は、すべてのフレームで同じボディパーツ間のコンテキスト依存関係をキャプチャします。 
[ABSTRACT]没入のブロックで世界の「ビジョン」を模倣します。これはcnnsベースのメソッドが使用しない初めての例です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Open-set Adversarial Defense -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_7.html">
      <font color="black">Open-set Adversarial Defense</font>
    </a>
  </h2>
  <font color="black">さらに、既知のクラスでトレーニングされた敵対的防御メカニズムは、オープンセットサンプルに一般化されないことを示します。 -OSAD問題の解決策として防御ネットワーク（OSDN）を設定します。 
[ABSTRACT]敵対的防御は、知覚できない敵対的摂動を伴う画像からネットワークを守ることを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Line-Circle-Square (LCS): A Multilayered Geometric Filter for Edge-Based
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_8.html">
      <font color="black">Line-Circle-Square (LCS): A Multilayered Geometric Filter for Edge-Based
  Detection</font>
    </a>
  </h2>
  <font color="black">当社のエキスパートは、幾何学的定義に基づく信頼係数の共分散に依存して、検出されたランドマークを無視、出現、比較します。提案されたフィルターは、定義された各エキスパートに検出、追跡、学習を適用して、過剰計算せずにシーンを判断するための詳細情報を抽出します。これはこのペーパーでは、オブジェクトの検出、追跡、マッピングのアプリケーションの複雑さを軽減する最先端のフィルターを紹介しています。 
[ABSTRACT] line-circle-square（lcsではない）フィルターは、大規模なデータベースを備えた移動ロボットが受信オブジェクトを処理できると主張しています。この実験は、提案されたフィルターの有効性を検出精度とリソース使用量の観点から検証します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-21">
        <br><font color="black">2020-08-21</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Feature Learning by Autoencoder and Prototypical
  Contrastive Learning for Hyperspectral Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_9.html">
      <font color="black">Unsupervised Feature Learning by Autoencoder and Prototypical
  Contrastive Learning for Hyperspectral Classification</font>
    </a>
  </h2>
  <font color="black">実験により、2つの提案されたオートエンコーダネットワークはそれ自体で優れた特徴学習能力を備えていることが証明されました。私たちが設計した対照的な学習ネットワークは、2つの特徴を組み合わせてより代表的な特徴を学習できることを証明しています。特徴抽出のための教師なし学習方法はますます増えています人気があります。さらに、私たちの方法は、ベースライン方法よりも速い特徴抽出速度を維持します。 
[ABSTRACT]人気のある対比学習法と古典的な表現学習法を組み合わせて、教師なしの特徴学習ネットワークを作成します。この手法は、ハイパースペクトル分類実験の他の比較手法を上回ります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Decentralized Source Localization Using Wireless Sensor Networks from
  Noisy Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_10.html">
      <font color="black">Decentralized Source Localization Using Wireless Sensor Networks from
  Noisy Data</font>
    </a>
  </h2>
  <font color="black">フォルトモデルの下でソースの場所を推定する2つの方法を提案します。ヒッティングセットアプローチとソースの場所の推定にFCでノイズの多いデータセットを利用する機能選択方法です。イベントのローカリゼーションには、侵入者、汚染物質のローカライズなど、多くのアプリケーションがあります。生物兵器、化学兵器、戦闘監視における敵の位置、電力系統の故障などの発生源。これらの方法は、発生源の位置を推定する上でフォールトトレラントであり、複雑でもないことを示しました。 
[ABSTRACT]フォールトモデルにより、センサーノードは誤検知または誤判断を提供できます。これらには、ソース位置の推定のためにfcでノイズの多いネットワークを使用することが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Face Image Quality Assessment: A Literature Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_11.html">
      <font color="black">Face Image Quality Assessment: A Literature Survey</font>
    </a>
  </h2>
  <font color="black">最近のアプローチの間の顕著な概念的な違いを含む、深層学習ベースの方法に向かう傾向が観察されています。画像の選択に加えて、顔の画像品質評価は、ここで説明する他のさまざまなアプリケーションシナリオでも使用できます。この調査では、顔のバイオメトリクスのフレームワークにおける顔の質の評価に関する文献の概要。たとえば、
[ABSTRACT]顔の質の評価は、他のさまざまなアプリケーションシナリオでも使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Joint Graph-based Depth Refinement and Normal Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_12.html">
      <font color="black">Joint Graph-based Depth Refinement and Normal Estimation</font>
    </a>
  </h2>
  <font color="black">奥行きの推定は、シーンの3Dジオメトリを理解する上で不可欠なコンポーネントであり、都市や屋内の設定で多数のアプリケーションがあります。 map ..このタスクを、入力の逆深度マップまでの距離を最小化するデータ忠実度項を含む最適化問題、および区分的平面解を実施する正則化として定式化します。 
[要約]提案された正則化は、各ピクセルで平面を自動的に推定するように設計されています。これにより、類似のピクセルが同じ平面に割り当てられるようになります。この方法により、視覚的および数値的に深さの改善が大幅に改善されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-03">
        <br><font color="black">2019-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Seeing wake words: Audio-visual Keyword Spotting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_13.html">
      <font color="black">Seeing wake words: Audio-visual Keyword Spotting</font>
    </a>
  </h2>
  <font color="black">最後に、（3）私たちの方法が他の言語、特にフランス語とドイツ語に一般化し、英語に事前トレーニングされたネットワークを微調整することにより、言語固有のデータが少ない英語に匹敵するパフォーマンスを達成することを示します。主な貢献は：（1）類似性マップ中間表現を使用してタスクを（i）シーケンスマッチングと（ii）パターン検出に分割し、単語がそこにあるかどうか、いつ存在するかを決定する、新しい畳み込みアーキテクチャ、KWS-Net。 （2）オーディオが利用可能な場合、視覚的なキーワードスポッティングにより、クリーンでノイズの多いオーディオ信号の両方のパフォーマンスが向上することを示しています。この方法は、トレーニングおよびテスト時に、以前の最先端の視覚的なキーワードスポッティングアーキテクチャのパフォーマンスを超えています。同じベンチマーク、および最先端のリップリーディングメソッドのベンチマークでも同じです。 
[ABSTRACT] keyメソッドはワイルドビデオに最適であり、audio.keyで重要です。key。メソッドは、video.methodでテストするためのメソッドメソッドです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: e-TLD: Event-based Framework for Dynamic Object Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_14.html">
      <font color="black">e-TLD: Event-based Framework for Dynamic Object Tracking</font>
    </a>
  </h2>
  <font color="black">一方、オブジェクトがカメラの視野に再び入ると、データ駆動型のグローバルスライディングウィンドウ検出器が、後続の追跡のためにオブジェクトを特定します。3つのモーションで5つの異なるオブジェクトのグラウンドトゥルースロケーションを使用設定、つまり平行移動、回転、6-DOF、定量測定は、さまざまなパフォーマンスの問題に関する重要な洞察を備えたイベントベースの追跡フレームワークについて報告されます。重要な新機能の1つは、追跡するイベントベースのローカルスライディングウィンドウ技術の使用です。雑然としたテクスチャ背景のシーンで確実に。 
[要約]追跡フレームワークは、オブジェクトの識別表現をオンライン学習で使用します。オブジェクトが視野に戻ったときに、オブジェクトを検出して再追跡します。これは、追跡カメラとしては初めてのことです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Exploiting Latent Codes: Interactive Fashion Product Generation, Similar
  Image Retrieval, and Cross-Category Recommendation using Variational
  Autoencoders -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_15.html">
      <font color="black">Exploiting Latent Codes: Interactive Fashion Product Generation, Similar
  Image Retrieval, and Cross-Category Recommendation using Variational
  Autoencoders</font>
    </a>
  </h2>
  <font color="black">アイウェア、フットウェア、バッグを含むファッション製品の画像データセットは、このパイプラインがeコマースの急成長業界に適用可能であることを示すのに適切であり、データマッチングの新しい方法と組み合わせた目的の製品の指定、およびVAEを使用した推奨システムをユーザーが直接操作できるようにします。この論文では、Variational Autoencoder（VAE）を使用して、ユーザーが好みに応じた属性を持つ製品を生成し、同じ製品の同様のスタイルを取得できるインタラクティブなファッション製品アプリケーションフレームワークを構築することを提案します。ファッション業界でのディープラーニングアプリケーションの台頭により、大規模なデータセットのキュレーションが進み、製品設計、画像検索、レコメンダーシステム用のアプリケーションを構築できるようになりました。 
[ABSTRACT]新しい論文で、著者はインタラクティブファッション製品アプリケーションシステムシステムシステムの作成を提案しています。彼は、システム内のデータの組み合わせを使用して製品製品アプリケーションフレームワークを作成することを提案しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning to Detect Bacterial Colonies for the Production of
  Vaccines -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_16.html">
      <font color="black">Deep Learning to Detect Bacterial Colonies for the Production of
  Vaccines</font>
    </a>
  </h2>
  <font color="black">多くの可能性を探求する必要がありますが、私たちの結果は、細菌コロニーを分離および分類するためのディープラーニングの可能性を示しています。 ..この手動のタスクは時間がかかり、エラーが発生しやすくなります。 
[ABSTRACT]オーダーメイドの損失関数を使用したマルチクラスの汎化により、許容可能な精度で病原性コロニーと非病原性コロニーを区別できることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Going beyond Free Viewpoint: Creating Animatable Volumetric Video of
  Human Performances -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_17.html">
      <font color="black">Going beyond Free Viewpoint: Creating Animatable Volumetric Video of
  Human Performances</font>
    </a>
  </h2>
  <font color="black">セマンティックエンリッチメントとジオメトリックアニメーション機能は、3Dデータに時間的一貫性を確立し、続いてパラメトリック形状適応型フルヒューマンボディモデルを使用して各フレームを自動的にリギングすることによって実現されます。ポーズ編集では、キャプチャしたデータを可能な限り活用します。キャプチャされたフレームを運動学的に変形させて、目的のポーズに合わせます。これらは、インタラクティブに組み合わされて新しい顔の表情を形成するように処理されます。 
[ABSTRACT]たとえば、キャプチャしたデータに似たアニメート可能なモデルを作成する代わりに、俳優のパフォーマンスを再アニメーション化および変更できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: On the Structures of Representation for the Robustness of Semantic
  Segmentation to Input Corruption -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_18.html">
      <font color="black">On the Structures of Representation for the Robustness of Semantic
  Segmentation to Input Corruption</font>
    </a>
  </h2>
  <font color="black">最後に、SCrIBEは、IBE 40.3とSoftmaxベースライン37.5の両方と比較して、42.1のmIOUですべての破損と重大度レベルにわたって集計された優れたセグメンテーションパフォーマンスを示すことを示しています。暗黙的背景推定（IBE）は、コストがほとんどまたはまったくないセマンティックセグメンテーションモデルの配布範囲外の入力に対する堅牢性。このホワイトペーパーでは、Softmax、IBE、およびSigmoidを使用する最適化目標の結果として学習された構造を比較する分析を提供し、それらの理解を向上させます。堅牢性との関係。 
[要約]シグモイドとibeを組み合わせて堅牢性を向上させることを提案します。また、シグモイドとibeを組み合わせてタスクを向上させ、</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Monocular 3D Detection with Geometric Constraints Embedding and
  Semi-supervised Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_19.html">
      <font color="black">Monocular 3D Detection with Geometric Constraints Embedding and
  Semi-supervised Training</font>
    </a>
  </h2>
  <font color="black">この戦略では、2つの共有ウェイトKM3D-Netのコンセンサス予測を、異なる入力増強条件とネットワーク正則化の下で同じラベルなし画像に適用します。このモデルでは、合成データ、インスタンスセグメンテーション、CADモデル、深度のないRGB画像のみが必要ですジェネレーター。KITTIでラベル付けされたデータが13 \％で、以前の完全に監視されたメソッドのほとんどを超えています。 
[ABSTRACT]オブジェクトのキーポイントを予測する完全なたたみ込みモデルを設計しました。次に、これらの推定を遠近制約と組み合わせて位置属性を削減します。さらに、ラベル付きトレーニングデータが不足している場合の効果的な半教師ありトレーニング戦略を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: GAIT: Gradient Adjusted Unsupervised Image-to-Image Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_20.html">
      <font color="black">GAIT: Gradient Adjusted Unsupervised Image-to-Image Translation</font>
    </a>
  </h2>
  <font color="black">提案された方法は、クラゲからヘッケルへのデータセットで検証されます。これは、異なる背景分布の画像を含む、言及された問題を示すために準備されています。ターゲット画像のSobel応答間のL2ノルムである勾配調整損失そして、ソース画像の調整されたSobel応答が利用されます。我々の方法が定性的および定量的にベースライン方法と比較してパフォーマンスの向上を得たことを示し、提案された方法の有効性を示しています。 
[要約]提案された方法は、問題を実証するために準備されたクラゲ-ヘッケルデータセットで検証されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Transform Quantization for CNN Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_21.html">
      <font color="black">Transform Quantization for CNN Compression</font>
    </a>
  </h2>
  <font color="black">最初に、CNN量子化のレートと歪みの理論を紹介し、最適な量子化をレート-歪み最適化問題として提起します。変換量子化は、CNNの低ビットレート圧縮を容易にするために、単一のフレームワークで量子化と次元削減（非相関）技術を統合します。変換領域での効率的な推論。この論文では、変換量子化を介して、トレーニング後の畳み込みニューラルネットワーク（CNN）の重みを圧縮します。 
[ABSTRACT]以前のcnn量子化技法は、重みとアクティブ化の結合統計を無視する傾向があり、特定の量子化ビットレートで準最適なcnnパフォーマンスを生成します。変換量子化は、単一フレームワークで量子化と空間削減（非相関）技法を統合し、低機能のビットレート圧縮</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: PCPL: Predicate-Correlation Perception Learning for Unbiased Scene Graph
  Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_22.html">
      <font color="black">PCPL: Predicate-Correlation Perception Learning for Unbiased Scene Graph
  Generation</font>
    </a>
  </h2>
  <font color="black">今日、シーングラフの生成（SGG）タスクは、主に述語注釈の分布の非常に長い尾のバイアスのために、現実的なシナリオで大幅に制限されています。ベンチマークVG150データセットでの広範な実験は、提案されたPCPLが尾クラスで著しく優れていることを示しています。以前の最先端の方法を大幅に上回っており、主要なもののパフォーマンスを十分に維持しています。このホワイトペーパーでは、述語ラベルが相互に強い相関を持っている場合、一般的なリバランス戦略（たとえば、re -サンプリングと再重み付け）は、テールデータのオーバーフィッティング（例：ベンチではなく歩道に座っている）が発生するか、元の不均一な分布による悪影響（例：さまざまなパークオン/スタンディングの集計）が発生します。オン/オンに座る）。 
[ABSTRACT]クラスの不均衡の問題に取り組むことは重要でやりがいがあります。そのため、問題に取り組むことが重要であり、課題に直面しています。主な理由は、再受信戦略が述語の頻度に敏感でありながら、関連性を知らないためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervised Learning of Detailed 3D Face Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_23.html">
      <font color="black">Self-supervised Learning of Detailed 3D Face Reconstruction</font>
    </a>
  </h2>
  <font color="black">広範な実験により、提案された方法が前の作業よりも優れていることを示しています。最初の段階では、測光損失と入力顔とレンダリングされた顔の間の顔の知覚損失を組み合わせて、3DMMベースの粗いモデルを回帰します。問題に対処するために、私たちの学習フレームワークは、従来のアプローチで計算された代理グラウンドトゥルース3Dモデルの監視を必要としません。 
[要約]私たちのアプローチは、3dmmベースのアンサンブルモデルとuv空間での変位マップを使用して3d面を表現します。代わりに、問題自体を学習中の監督として利用します。第2ステージ、入力画像と回帰面の両方3Dに展開され、画像-詳細な顔を予測する画像変換ネットワークに送信されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br><font color="black">2019-10-25</font>
      </time>
    </span>
</section>
<!-- paper0: Semantics-aware Adaptive Knowledge Distillation for Sensor-to-Vision
  Action Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_24.html">
      <font color="black">Semantics-aware Adaptive Knowledge Distillation for Sensor-to-Vision
  Action Recognition</font>
    </a>
  </h2>
  <font color="black">同じアクションの場合、ビジョンセンサー（ビデオまたは画像）とウェアラブルセンサーから学習した知識は関連していて補完的である可能性があります。複数のウェアラブルセンサーから知識を適応的に転送および抽出することにより、ビジョンセンサーモダリティ（ビデオ）でのアクション認識を強化します。SAKDNは、教師モダリティとして複数のウェアラブルセンサーを使用し、生徒モダリティとしてRGBビデオを使用します。 
[ABSTRACT] sakdnという名前のsakdnは、複数のウェアラブル-センサーを教師のウェアラブルとして使用し、rgbビデオを学生のモダリティとして使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: A perception centred self-driving system without HD Maps -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_25.html">
      <font color="black">A perception centred self-driving system without HD Maps</font>
    </a>
  </h2>
  <font color="black">提案されたライン検出サブシステムは、ディープラーニングを使用せずに最先端のパフォーマンスを実現します。提案されたシステムは、HDマップとは無関係です。 
[ABSTRACT]提案されたライン検出サブシステムは、ディープラーニングなしで最先端のパフォーマンスを実現します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Generative Model for Image Inpainting with Local Binary Pattern
  Learning and Spatial Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_26.html">
      <font color="black">Deep Generative Model for Image Inpainting with Local Binary Pattern
  Learning and Spatial Attention</font>
    </a>
  </h2>
  <font color="black">さらに、既知の領域と生成された領域の間の整合性だけでなく、生成された領域自体内の一貫性も考慮することにより、改善された空間注意メカニズムが画像修復ネットワークに統合されています。ソースコードとトレーニング済みモデルは、 https://github.com/HighwayWu/ImageInpainting .. CelebA-HQ、Places、Paris StreetViewを含む公開データセットに対する広範な実験により、定量的および定性的に。 
[ABSTRACT] u-netアーキテクチャを使用した最初のlbp学習ネットワークは、欠落した領域の構造情報を正確に予測するように設計されています。ネットワークは、最新の競合アルゴリズムよりも優れた修復結果を生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Zero-Shot Human-Object Interaction Recognition via Affordance Graphs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_27.html">
      <font color="black">Zero-Shot Human-Object Interaction Recognition via Affordance Graphs</font>
    </a>
  </h2>
  <font color="black">グラフに含まれている知識をモデルに抽出することを目的とした損失関数を提案します。また、グラフを使用して、潜在空間に局所構造を課すことによって学習表現を正則化します。いくつかのデータセット（私たちのアプローチは、アクションとオブジェクトの間のアフォーダンス関係をモデル化するグラフの形で、画像コンテンツの外部にある知識を利用します。与えられたオブジェクトに対してアクションを実行できます。 
[要旨]私たちのアプローチは、画像コンテンツの外部にある知識を利用します。いくつかのデータセットで私たちのアプローチを評価し、それが現在の最新技術よりも優れていることを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Continual Prototype Evolution: Learning Online from Non-Stationary Data
  Streams -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_28.html">
      <font color="black">Continual Prototype Evolution: Learning Online from Non-Stationary Data
  Streams</font>
    </a>
  </h2>
  <font color="black">2つの高度に不均衡なデータストリームを含む5つのベンチマークで、大幅なマージンで最先端のパフォーマンスを実現します。このような困難な設定に対抗するには、プロトタイプと最近傍ベースの分類を共有潜在スペースで集約します。プロトタイプ進化（CoPE）は、任意の時点での学習と予測を可能にします。非定常データストリームからの学習は困難な試みであることが証明されているため、現在の継続的な学習者は、バランスのとれたデータセット、データストリームの無制限の処理を想定して、問題を大幅に緩和します。サブセット、およびタスク情報の追加の可用性、場合によっては推論中にも。 
[ABSTRACT]その結果、私たちの継続的な学習者は追加のタスク情報なしでオンライン形式でデータストリームを処理し、不均衡なデータストリームに対して確実な堅牢性を示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Semantic Segmentation of Neuronal Bodies in Fluorescence Microscopy
  Using a 2D+3D CNN Training Strategy with Sparsely Annotated Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_29.html">
      <font color="black">Semantic Segmentation of Neuronal Bodies in Fluorescence Microscopy
  Using a 2D+3D CNN Training Strategy with Sparsely Annotated Data</font>
    </a>
  </h2>
  <font color="black">スパースアノテーションのみを使用する半教師あり代替戦略は、トレーニング時間が長くなり、達成されたモデルは、2D CNNと比較して容量が増える傾向にあり、同様の結果を得るにはより多くのグラウンドトゥルースデータが必要になります。3DCNNは、手動で注釈が付けられた大規模なボリュームデータが必要なため、かなりの人間の労力が必要です。人間の脳皮質の3D高解像度蛍光顕微鏡イメージングでのニューロン構造のセマンティックセグメンテーションは、ニューロンのローカリゼーションに良い結果をもたらすが、リードする二次元CNNを利用できます。不正確な表面再構成に。 
[ABSTRACT] 2フェーズ戦略は、ネイティブ3d cnnモデルをトレーニングすることです。これらには、欠落したラベルがローカルモデルによって推論され、計算された損失中に重み付けされた方法で手動アノテーションと組み合わされる3dアノテーションが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-31">
        <br><font color="black">2020-08-31</font>
      </time>
    </span>
</section>
<!-- paper0: Evaluation of Deep Convolutional Generative Adversarial Networks for
  data augmentation of chest X-ray images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_30.html">
      <font color="black">Evaluation of Deep Convolutional Generative Adversarial Networks for
  data augmentation of chest X-ray images</font>
    </a>
  </h2>
  <font color="black">医療画像データセットは、データの取得にかかる高コストと時間のかかる注釈のために、通常は不均衡です。この作業では、生成モデリング（深い畳み込み生成敵対的ネットワーク）を介して胸部X線データセットでデータ増強を実行し、元のデータとモデルの評価と同様の特性を保持する人工インスタンスは、Fr \ &#39;echet Inception of Inception（FID）スコア1.289をもたらしました。この問題に対処するために、データ増強は、位置増強技術によってトレーニングデータに対して実行されることがよくあります。スケーリング、クロッピング、フリッピング、パディング、回転、平行移動、アフィン変換、および明るさ、コントラスト、彩度、データセットサイズを増やすための色相などの色増強技術など。 
[ABSTRACT]ディープニューラルネットワークデータセットによって行われた調査では、望ましい結果が得られません。これは多くの場合、オーバーです-データを過半数クラスのサンプルに適合させます。これらの拡張手法は、データが限られているドメインで有利であるとは限りません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Intrinsic Relationship Reasoning for Small Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_31.html">
      <font color="black">Intrinsic Relationship Reasoning for Small Object Detection</font>
    </a>
  </h2>
  <font color="black">具体的には、最初に、初期の地域特徴に基づいて疎な意味関係をモデル化するセマンティックモジュールと、それぞれの位置情報と形状情報に基づいて疎な空間レイアウト関係をモデル化する空間レイアウトモジュールを構築します。オブジェクトとその関係に関するコンテキスト情報を統合するコンテキスト推論モジュールに追加します。これは、分類と回帰のために元の地域の視覚的特徴とさらに融合されます。そのため、このような固有の関係のモデリングと推論は、小さなオブジェクトの検出に役立ちます。 
[ABSTRACT]小さなオブジェクト検出モデルは、オブジェクト間の意味的および空間的なレイアウト関係を推測します。これらは、コンテキスト推論モジュールに送られ、オブジェクトとその関係に関するコンテキスト情報を組み合わせます。新しいモデルは、小さなオブジェクトの開発</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: LSMVOS: Long-Short-Term Similarity Matching for Video Object -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_32.html">
      <font color="black">LSMVOS: Long-Short-Term Similarity Matching for Video Object</font>
    </a>
  </h2>
  <font color="black">既存のアルゴリズムは、主にマッチングおよび伝搬戦略の目的に基づいています。これは、マスキングまたはオプティカルフローで以前のフレームを利用することが多いものです。このペーパーでは、新しい伝搬方法を探索し、短期マッチングモジュールを使用して以前の情報を抽出します。フレームとそれを伝播に適用し、ビデオオブジェクトセグメンテーション（LSMOVS）方式の長期短期類似性マッチングのネットワークを提案します：ピクセルレベルのマッチングと長期マッチングモジュールと短期マッチングモジュール間の相関を行うことにより、最初のフレームと前のフレーム、グローバル類似性マップとローカル類似性マップ、現在のフレームの特徴パターンと前のフレームのマスキングが取得されます。結論：このホワイトペーパーで提案されている短期マッチングモジュールは、情報を抽出するのに役立ちますマスクだけではなく、前のフレームの。 
[ABSTRACT]以前のパターン化と通信戦略はマスキングまたはオプティカルフローで以前のフレームを利用します。これは、ネットワークがオンラインの微調整なしで効率的なビデオオブジェクトセグメンテーションを実現できることを意味します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Structure-Aware Generation Network for Recipe Generation from Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_33.html">
      <font color="black">Structure-Aware Generation Network for Recipe Generation from Images</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、体系的なフレームワークにいくつかの新しいアイデアをもたらします。（1）教師なし学習アプローチを利用して、トレーニング前に文レベルのツリー構造ラベルを取得します。 （2）（1）から学習したツリー構造ラベルの監視により、画像からターゲットレシピのツリーを生成します。 （3）推論されたツリー構造をレシピ生成手順と統合する。提案されたモデルは、高品質で一貫したレシピを生成し、ベンチマークのRecipe1Mデータセットで最先端のパフォーマンスを実現できます。上記に対処するには制限、我々は構造認識生成ネットワーク（SGN）の新しいフレームワークを提案して、食品レシピ生成タスクに取り組みます。 
[ABSTRACT]コンセプトは、食品レシピ生成タスクに取り組むように設計されています。イメージキャプションタスクなどの構造に基づいています。新しいモデルは、高品質で一貫したレシピを生成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: DARTS-: Robustly Stepping out of Performance Collapse Without Indicators -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_34.html">
      <font color="black">DARTS-: Robustly Stepping out of Performance Collapse Without Indicators</font>
    </a>
  </h2>
  <font color="black">ヘッセ固有値などのさまざまなインジケーターがパフォーマンス崩壊のシグナルとして提案されており、インジケーターが事前設定されたしきい値に達したら検索を停止する必要があります。接続をスキップすると、この特権から得られる利益が多すぎて、派生モデルの崩壊を引き起こすと考えられます。 ..このペーパーでは、崩壊を解決するために、より微妙で直接的なアプローチを採用しています。 
[ABSTRACT]新しい調査によると、スキップ接続は不利な状態から簡単に回復して支配的になる可能性がある</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarially Robust Neural Architectures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_35.html">
      <font color="black">Adversarially Robust Neural Architectures</font>
    </a>
  </h2>
  <font color="black">NASフレームワークの場合、離散アーキテクチャがスーパーネットからサンプリングされると、すべてのアーキテクチャパラメータが等しく扱われます。我々は、敵対的な堅牢性、リプシッツ定数、およびアーキテクチャパラメータ間の関係を調査し、アーキテクチャパラメータに対する適切な制約がリプシッツ定数をさらにロバスト性を改善します。したがって、ネットワーク全体のリプシッツ定数を、平均と分散がアーキテクチャパラメータに関連する単変量対数正規分布を使用して近似できる、トレーニング可能な多変量対数正規分布からアーキテクチャパラメータをサンプリングすることを提案します。 
[ABSTRACT] NASフレームワークの場合、ディスクリートアーキテクチャがスーパーネットからサンプリングされると、すべてのアーキテクチャパラメータが同等に処理されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Domain Adaptation For Plant Organ Counting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_36.html">
      <font color="black">Unsupervised Domain Adaptation For Plant Organ Counting</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、オブジェクトカウントを目的とした密度マップ推定のドメイン適応のためのドメイン敵対学習手法を提案します。教師付き学習は、画像内のオブジェクトをカウントするためによく使用されますが、小さく密に配置されたオブジェクトをカウントする場合、必要な画像アノテーションの収集は煩雑です。2つの多様なオブジェクトカウントタスク（小麦の小穂、葉）の評価は、ドメインシフトのさまざまなクラスにわたってターゲットデータセットで一貫したパフォーマンスを示します：屋内から屋外への画像と種から種への適応から。 
[要約]重要な画像、または異なる植物種で使用するための、屋内植物データの注釈付きデータセットの使用。このアプローチでは、ソースデータセットとターゲットデータセットの間の完全に整列した分布を想定していません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Lunar Crater Identification in Digital Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_37.html">
      <font color="black">Lunar Crater Identification in Digital Images</font>
    </a>
  </h2>
  <font color="black">これらの手法は、合成画像と実際の画像の両方で示されています。透視投影によって形成された画像で楕円形のクレーターの縁のパターンを認識できる場合（およびできない場合）に表示されます。これらの記述子は事前に計算されている場合があります。既知のクレーターパターンの場合は、高速で認識できるように検索可能なインデックスに配置されます。 
[ABSTRACT]クレーターベースの地形相対ナビゲーションと科学的画像の自動登録の両方で、「ロストインスペース」のクレーター識別問題が一般的です。クレーターリム観測からポーズを計算するため、およびクレーターリム対応を評価するための新しい手法も開発されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Facial Geometry Recovery from a Depth View with Attention Guided
  Generative Adversarial Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_38.html">
      <font color="black">3D Facial Geometry Recovery from a Depth View with Attention Guided
  Generative Adversarial Network</font>
    </a>
  </h2>
  <font color="black">質的および量的比較の両方から、AGGANはより完全で滑らかな3D顔の形状を回復し、従来の方法よりもはるかに広い範囲の視野角を処理し、深度ビューのノイズに耐性があることがわかります。具体的には、AGGANはボクセル空間内の3D顔のジオメトリをエンコードし、注意誘導GANを使用して、不適切な2.5D深度-3Dマッピングをモデル化します。3D顔のジオメトリの一貫性を強化する複数の損失関数と、事前の顔の分布ボクセル空間のサーフェスポイントは、トレーニングプロセスをガイドするために組み込まれています。 
[ABSTRACT] agganは、顔の密な3Dボクセルグリッドを生成できます。トレーニングプロセスをガイドするために、複数の損失関数と事前の顔面ポイントの分布が組み込まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: RPT: Learning Point Set Representation for Siamese Visual Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_39.html">
      <font color="black">RPT: Learning Point Set Representation for Siamese Visual Tracking</font>
    </a>
  </h2>
  <font color="black">さらに、階層的な畳み込み層を融合することにより詳細な構造情報を取得するためのマルチレベルの集約戦略を提案します。OTB2015、VOT2018、VOT2019、GOT-10kなどのいくつかの挑戦的なベンチマークに関する広範な実験は、この方法が新しい最先端の技術を実現することを示しています20 FPSを超えて実行している間のパフォーマンス。ポイントセットは、ターゲット領域の意味的および幾何学的に重要な位置を示すようにトレーニングされており、オブジェクトの外観のより細かいローカリゼーションとモデリングを可能にします。 
[ABSTRACT]ポイントセットは、ターゲット領域の意味的および幾何学的に重要な位置を示すようにトレーニングされており、より細かいローカリゼーションとオブジェクトの外観のモデリングを可能にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-08">
        <br><font color="black">2020-08-08</font>
      </time>
    </span>
</section>
<!-- paper0: Long-Term Anticipation of Activities with Cycle Consistency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_40.html">
      <font color="black">Long-Term Anticipation of Activities with Cycle Consistency</font>
    </a>
  </h2>
  <font color="black">私たちのフレームワークは、朝食データセットと50Saladsの2つのデータセットで最先端の結果を達成します。さらに、予測された将来の過去のアクティビティを予測することにより、時間の経過に伴うサイクルの一貫性の損失を導入します。ディープラーニングメソッドの成功によりビデオでの活動を分析する際、最近、将来の活動を予測することに、より多くの注意が向けられています。 
[ABSTRACT]長期実行プログラムの長期的な知識は、将来の活動を予測できます。これらの作業は、観測されたシーケンスの意味解釈を予測タスクから切り離します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Semantically Adaptive Image-to-image Translation for Domain Adaptation
  of Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_41.html">
      <font color="black">Semantically Adaptive Image-to-image Translation for Domain Adaptation
  of Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、ストリートシーンのセマンティックセグメンテーションに対するドメイン適応の問題に取り組みます。ただし、画像のセマンティクスを利用して、変換アルゴリズムを導くこともできます。ドメインシフトは、セマンティックセグメンテーションにとって非常に困難な問題です。 
[ABSTRACT]モデルは、画像とラベルが人工的に生成される合成データで簡単にトレーニングできますが、実際の環境にデプロイするとパフォーマンスが低下します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Convolutional Nonlinear Dictionary with Cascaded Structure Filter Banks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_42.html">
      <font color="black">Convolutional Nonlinear Dictionary with Cascaded Structure Filter Banks</font>
    </a>
  </h2>
  <font color="black">結果として、設計空間の役割を議論する余地が残っています。一般的に、畳み込みニューラルネットワーク（CNN）は、画像復元アプリケーションでの実用性を示しています。ただし、既存のCNNは、原子画像（畳み込みカーネル）間の関係を考慮せずに構築されます。この研究では、カスケードフィルターバンクを使用した画像復元のための畳み込み非線形辞書（CNLD）を提案します。 
[ABSTRACT]畳み込みニューラルネットワーク（cnn）は、画像復元アプリケーションで実用性を示しました。既存の部屋の部屋の部屋の構造は、原子画像間の関係を考慮せずに構築されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Unpaired Image-to-Image Translation using Adversarial Consistency Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_43.html">
      <font color="black">Unpaired Image-to-Image Translation using Adversarial Consistency Loss</font>
    </a>
  </h2>
  <font color="black">サイクルの一貫性の喪失は、このような問題に対して広く使用されている制約です。私たちの方法は、3つのやりがいのあるタスクで最先端の結果を達成します：メガネの取り外し、男性から女性への翻訳、自撮りからアニメへの翻訳。損失は、変換された画像を特定のソース画像に変換する必要はありませんが、変換された画像がソース画像の重要な機能を保持し、上記のサイクルの一貫性の損失の欠点を克服するように促すことができます。 
[ABSTRACT]この方法は、画像から画像への変換のための新しいレベルの「一貫性の損失」に基づいています。これは、ソースがビジョンの状態を達成するために管理するのが初めての場合です。この方法は、成功も達成します画像と自撮りのマッピング結果-アニメ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-10">
        <br><font color="black">2020-03-10</font>
      </time>
    </span>
</section>
<!-- paper0: Video Captioning Using Weak Annotation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_44.html">
      <font color="black">Video Captioning Using Weak Annotation</font>
    </a>
  </h2>
  <font color="black">この目的のために、ビデオキャプションのセマンティックコンセプトとその依存関係を推論することにより、弱い注釈から細かい文章を徐々に生成するプログレッシブ視覚推論方法を提案します。コンセプト関係をモデル化するために、大きな文のコーパス..依存関係ツリーをたどって、キャプションモデルをトレーニングするための文が生成されます。 
[要約]このペーパーでは、ビデオキャプションモデルをトレーニングするために、強い注釈ではなく弱い注釈を使用することを検討します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: SPARE3D: A Dataset for SPAtial REasoning on Three-View Line Drawings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_45.html">
      <font color="black">SPARE3D: A Dataset for SPAtial REasoning on Three-View Line Drawings</font>
    </a>
  </h2>
  <font color="black">SPARE3Dが空間推論のための新しい問題の定式化とネットワーク設計を刺激し、2Dセンサーを介してインテリジェントロボットが3Dの世界で効果的に動作できるようにすることを願っています。データセットとコードはhttps://ai4ce.github.io/SPARE3D。で入手できます。空間推論は人間の知性の重要な要素です。 
[ABSTRACT] spare3dは認知科学と心理測定学に基づいています。3種類の2d-3d推論タスクが含まれており、難易度が高くなっています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br><font color="black">2020-03-31</font>
      </time>
    </span>
</section>
<!-- paper0: Overcoming Negative Transfer: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_46.html">
      <font color="black">Overcoming Negative Transfer: A Survey</font>
    </a>
  </h2>
  <font color="black">ネガティブトランスファーを克服する方法は長い間研究されており、近年ますます注目を集めています。この調査は、ネガティブトランスファーに関連する要因を分析することを試み、4つの重要な側面からネガティブトランスファーを克服する理論と進歩を要約します。品質、ターゲットデータの品質、ドメインの相違、および一般的なアルゴリズム。これにより、読者に現在の研究ステータスとアイデアへの洞察を提供できます。フィールドの方向。 
[要約]目的は、転移学習の成功が常に保証されるわけではないことを確認することです。研究はマンチェスター大学の研究者によって行われます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: ALEX: Active Learning based Enhancement of a Model's Explainability -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_47.html">
      <font color="black">ALEX: Active Learning based Enhancement of a Model's Explainability</font>
    </a>
  </h2>
  <font color="black">具体的に言えば、提案された選択関数は、分類子モデルに加えて「説明者」モデルをトレーニングし、予測されたクラスを説明するために、平均してデータの異なる部分が使用されるインスタンスを優先します。標準的なALヒューリスティックスでは、分類モデルが最も信頼性の低い予測をもたらす注釈のポイントを選択するなど、これらのヒューリスティックが人間にとってより解釈可能なモデルにつながるかどうかを確認する実証的調査はありませんでした。最初の実験は、そのようなヒューリスティックを示す有望な傾向を示しましたより効果的で説明可能なエンドツーエンドのデータ駆動型分類器の開発につながる可能性があります。 
[要約]これらのヒューリスティックが人間にとってより解釈可能なモデルにつながるかどうかを確認する研究はありませんでした</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Breast mass detection in digital mammography based on anchor-free
  architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_48.html">
      <font color="black">Breast mass detection in digital mammography based on anchor-free
  architecture</font>
    </a>
  </h2>
  <font color="black">トランケーション正規化法を導入し、適応型ヒストグラム等化と組み合わせて、乳房の質量と周囲の環境との間のコントラストを強化します。一方、小さいデータサイズによって引き起こされるオーバーフィッティング問題を解決するために、自然変形データ拡張法と修正法を提案します限られたデータを効果的に利用するために、データの複雑さに基づくトレーニングデータの動的更新方法。ただし、乳房の質量の不均一性とその周囲の環境の複雑さのため、依然として大きな課題です。方法：これらの問題に対処するには、アンカーフリーで機能ピラミッドに基づく、乳房質量検出ネットワーク（BMassDNet）と呼ばれる1段階のオブジェクト検出アーキテクチャを提案します。これにより、さまざまなサイズの乳房質量の検出が適切に適合されます。 
[要約]これは乳房の腫瘤の不均一性とその周囲の環境の複雑さが原因です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Human-Object Interactions via Functional Generalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_49.html">
      <font color="black">Detecting Human-Object Interactions via Functional Generalization</font>
    </a>
  </h2>
  <font color="black">また、私たちのアプローチは、見られるオブジェクトの設定でゼロショットHOI検出のパフォーマンスを大幅に向上させることも示しています。人間が機能的に類似したものと相互作用するという考えに基づいて、画像内の人間とオブジェクトの相互作用（HOI）を検出するアプローチを提示します。同様の方法でオブジェクトを作成します。さらに、一般的なオブジェクト検出器を使用して、モデルが一般化されて、以前には見えなかったオブジェクトを含む相互作用に対応できることをさらに示します。 
[要約]提案されたモデルはシンプルであり、効率的にデータ、人間の視覚的特徴、人間とオブジェクトの相対的な空間方向を使用します。さらに、一般的なオブジェクト検出器を使用して、以前に見えなかったオブジェクトを含む相互作用にモデルを一般化できることを実証しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-05">
        <br><font color="black">2019-04-05</font>
      </time>
    </span>
</section>
<!-- paper0: Privacy Leakage of SIFT Features via Deep Generative Model based Image
  Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_50.html">
      <font color="black">Privacy Leakage of SIFT Features via Deep Generative Model based Image
  Reconstruction</font>
    </a>
  </h2>
  <font color="black">設計された深生成モデルは2つのネットワークで構成され、最初のネットワークはSIFT機能からローカルバイナリパターン（LBP）機能に変換することで潜像の構造情報を学習しようとしますが、2番目のネットワークはによって導かれるピクセル値の再構築を目的としています学習したLBP ..私たちの結果は、SIFT座標を十分に保護できれば、プライバシー漏洩問題を大幅に回避できることを示唆しています。敵が座標ではなくSIFT記述子にのみアクセスできる場合、潜像の再構築の適度な成功は、高度に構造化された画像（たとえば、顔）で達成でき、一般的な設定では失敗します。 
[ABSTRACT]これらのローカル機能は信頼できない当事者にさらされることが多いですが、プライバシー漏洩問題は近年ますます注目されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Local-HDP: Interactive Open-Ended 3D Object Categorization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_51.html">
      <font color="black">Local-HDP: Interactive Open-Ended 3D Object Categorization</font>
    </a>
  </h2>
  <font color="black">さらに、推論方法が提案され、高速事後近似が得られます。ただし、LDAベースのアプローチの効率と精度は、手動で選択したトピックの数に依存します。対照的に、提案されたLocal-HDPは自律的に決定できます。各カテゴリのトピックの数。 
[ABSTRACT]この方法を使用すると、エージェントは独立したトピックを段階的に学習できます。これにより、時間に合わせて環境に適応できます。この方法を使用して、さまざまなトピックを段階的に学習できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Temporal Self-Ensembling Teacher for Semi-Supervised Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_52.html">
      <font color="black">Temporal Self-Ensembling Teacher for Semi-Supervised Object Detection</font>
    </a>
  </h2>
  <font color="black">以前のKDベースの方法とは異なり、時間的に進化した教師モデルを考案します。（1）教師モデルは教師と生徒の2つの役割を果たし、ラベルのない画像に対する教師の予測は生徒の予測に非常に近い場合があります。これは、生徒の上限を制限します。（2）SSODのクラスの不均衡の問題により、教師から生徒への効率的な知識の伝達が妨げられます。 
[ABSTRACT]これらの自己強調戦略は、データとモデルの多様性を向上させます。また、不均衡な画像に対する教師の予測を改善します。この方法は、ベンチマークで80. 73％と40. 52％を達成しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-13">
        <br><font color="black">2020-07-13</font>
      </time>
    </span>
</section>
<!-- paper0: Real-time 3D Facial Tracking via Cascaded Compositional Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_53.html">
      <font color="black">Real-time 3D Facial Tracking via Cascaded Compositional Learning</font>
    </a>
  </h2>
  <font color="black">出力変数のさまざまなモダリティに明示的に対処しながら、従来のブーストされたシダと比較して、フィッティングパワーの向上と学習速度の高速化を実現できます。トレーニングデータにより、実際のアプリケーションでより実用的になります。GoMBFのシーケンス（GoMBF-Cascade）をさらにカスケードして顔のモーションパラメータを後退させることにより、さまざまな野生のビデオで、最先端の方法。はるかに多くのトレーニングデータが必要か、計算が複雑になります。 
[ABSTRACT] gombfは、multipleparモデルの深い構成です。それぞれは、部分的な運動パラメータを予測するように最初にトレーニングされたブーストされたシダです。次に、一緒に連結されて、単一の強いブーストされたシダを形成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient, high-performance pancreatic segmentation using multi-scale
  feature extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_54.html">
      <font color="black">Efficient, high-performance pancreatic segmentation using multi-scale
  feature extraction</font>
    </a>
  </h2>
  <font color="black">ここでは、効率的なマルチスケール画像機能の利用により高性能を達成することに重点を置いた、高度に最適化されたニューラルネットワークベースの膵臓セグメンテーションアルゴリズムであるMoNetを紹介します。人工知能ベースの画像分析手法が臨床的適用性に到達するために、高性能の開発アルゴリズムは非常に重要です。たとえば、自然画像に基づく既存のセグメンテーションアルゴリズムは、パラメーターの使用において効率的でも、医用画像用に最適化されていません。 
[ABSTRACT]私たちは、自分がどのようになっているかを知ることができたかどうかわかりません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Lifelong Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_55.html">
      <font color="black">Lifelong Object Detection</font>
    </a>
  </h2>
  <font color="black">具体的には、正確で効率的な予測のために、代表的なオブジェクト検出器であるFaster R-CNNを検討します。このホワイトペーパーでは、新しいトレーニングクラスが順次到着し、モデルを段階的に改良して、新しいトレーニングクラスが新しい以前のトレーニングデータがない場合のオブジェクトクラス。蒸留サンプルの選択には、疑似陽性を意識したサンプリング戦略も導入されています。 
[ABSTRACT]たとえば、正確で効率的な予測のために、代表的なオブジェクト検出器である高速r-cnnを検討します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Estimating the Brittleness of AI: Safety Integrity Levels and the Need
  for Testing Out-Of-Distribution Performance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_56.html">
      <font color="black">Estimating the Brittleness of AI: Safety Integrity Levels and the Need
  for Testing Out-Of-Distribution Performance</font>
    </a>
  </h2>
  <font color="black">TEVVと認証の難しいハードルをクリアできるところまでAIを実現するために、障害が発生しやすいAIコンポーネントにもかかわらず復元力のあるシステムを設計し、OODパフォーマンスを評価および改善することに重点を置く必要があります。画像の分類と音声認識）設計範囲内でも完全に重要なシステムで通常認定されているものよりも桁違いに故障しやすい（完全に分布内のサンプリング）。この論文は、これらの基準のいずれもディープニューラルネットワークに特定のものではないことを主張しています。 
[ABSTRACT] tevvvvvvvvは、aiがどのように最適であるかを見つける方法を見つけることへの挑戦です。それを使用して、システムが特定の境界内でうまく機能し、それらの境界の外側ではうまく機能しない方法を見つけることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: W-Net: Dense Semantic Segmentation of Subcutaneous Tissue in Ultrasound
  Images by Expanding U-Net to Incorporate Ultrasound RF Waveform Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_57.html">
      <font color="black">W-Net: Dense Semantic Segmentation of Subcutaneous Tissue in Ultrasound
  Images by Expanding U-Net to Incorporate Ultrasound RF Waveform Data</font>
    </a>
  </h2>
  <font color="black">私たちの新しい\ emph {W-Net}のRF波形入力とアーキテクチャは、通常のU-NetとアテンションU-Netと比較して、mIoU精度（すべての組織クラスにわたって平均）をそれぞれ4.5 \％と4.9 \％向上させました。皮下組織（SubQ）セグメンテーションを最初の臨床目標として選択しました。これは、多様な混合組織があり、セグメント化が難しく、研究領域が少ないためです。私たちの知る限り、これは最初のディープラーニングまたはCNNでもあります。超音波生のRFデータをグレー画像とともに分析するセグメンテーションのアプローチ。 
[ABSTRACT] subqは、ラベリングに使用できる新しいタイプの超音波です。形成外科、rfu.sを含みます。幹細胞モニタリング、および他の形態の腫瘍</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: 3D dynamic hand gestures recognition using the Leap Motion sensor and
  convolutional neural networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_58.html">
      <font color="black">3D dynamic hand gestures recognition using the Leap Motion sensor and
  convolutional neural networks</font>
    </a>
  </h2>
  <font color="black">ジェスチャーを自動的に理解するためのメソッドを定義することは、多くのアプリケーションコンテキストやバーチャルリアリティアプリケーションで、より自然で使いやすい人間とコンピューターの相互作用メソッドを作成するために最も重要です。ジェスチャーの分類は、深い畳み込みニューラルを使用して実行されます。ネットワーク（CNN）。人気のResNet-50アーキテクチャの修正バージョンが採用されています。これは、最後に完全に接続されたレイヤーを削除し、考慮されるジェスチャークラスと同じ数のニューロンを持つ新しいレイヤーを追加することで得られます。 
[要約]このメソッドは、非静的なジェスチャーを識別するために使用されます。これは、深い畳み込みニューラルネットワーク（cnn）に基づいています。このメソッドは、既存のシステムに正常に適用されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br><font color="black">2020-03-03</font>
      </time>
    </span>
</section>
<!-- paper0: Perceptual Deep Neural Networks: Adversarial Robustness through Input
  Recreation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_59.html">
      <font color="black">Perceptual Deep Neural Networks: Adversarial Robustness through Input
  Recreation</font>
    </a>
  </h2>
  <font color="black">概念は数学的に形式化されており、2つのバリエーションが開発されています（1つは画像全体の修復に基づいており、もう1つはノイズのあるサイズ変更された超解像再現に基づいています）。このホワイトペーパーでは、マシンが入力を再作成し、調査する方法このような拡張された認識の利点..実験により、$ \ varphi $ DNNは攻撃の精度を大幅に低下させ、最先端の防御さえも超える可能性があることが明らかになりました。 
[要約]これは、網膜に到達する信号が表示されないためです。独自の入力も再現する知覚的なディープニューラルネットワークを提案します。これらは、攻撃の精度を大幅に低減するように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: CLOCs: Camera-LiDAR Object Candidates Fusion for 3D Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_60.html">
      <font color="black">CLOCs: Camera-LiDAR Object Candidates Fusion for 3D Object Detection</font>
    </a>
  </h2>
  <font color="black">CLOCは、2Dおよび3D検出器の非最大抑制（NMS）の前に結合された出力候補で動作し、幾何学的および意味論的な一貫性を活用して、より正確な最終3Dおよび2D検出結果を生成するようにトレーニングされています。提出時に、 CLOCは、公式のKITTIリーダーボードのすべての融合ベースのメソッドの中で最高にランク付けされています。CLOCs融合は、単一モダリティ検出器のパフォーマンスを大幅に向上させる複雑さの低いマルチモーダル融合フレームワークを提供します。 
[要約] clocsフュージョンは、マルチモダリティ検出器のパフォーマンスを大幅に向上させるマルチモーダルフュージョンフレームワークを提供します。clocsフュージョンは、3Dおよび鳥瞰図メトリックで動作します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: SeismoFlow -- Data augmentation for the class imbalance problem -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_61.html">
      <font color="black">SeismoFlow -- Data augmentation for the class imbalance problem</font>
    </a>
  </h2>
  <font color="black">これは、機械学習の課題である、いわゆるクラスの不均衡問題です。この作業では、クラスベースの不均衡に対処することを目的として、合成サンプルを作成するフローベースの生成モデルであるSeismoFlowを提案します。地震計の信号品質の分類とクラスの不均衡の両方の課題を解決する一歩前進です。 
[ABSTRACT] 5で構成されるデータセットを紹介します。223の地震記録は、良、中、悪のクラスに分散しています。この結果は、地震記録の信号品質分類とクラス不均衡のタスクを解決するための前進です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-23">
        <br><font color="black">2020-07-23</font>
      </time>
    </span>
</section>
<!-- paper0: Unified Generative Adversarial Networks for Controllable Image-to-Image
  Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_62.html">
      <font color="black">Unified Generative Adversarial Networks for Controllable Image-to-Image
  Translation</font>
    </a>
  </h2>
  <font color="black">また、生成された画像の品質を評価するために、Fr \ &#39;echet ResNet Distance（FRD）を提示します。さらに、このモデルは、3つの新しい損失、つまり色の損失、制御可能な構造ガイドサイクルを通じて画像から画像へのマッピングを学習します-一貫性の損失、および制御可能な構造に基づく自己コンテンツ保持損失..私たちの知る限り、1つのGANフレームワークをこのようなすべての制御可能な構造に基づく画像変換タスクで動作させるのは、私たちが初めてです。 
[要約]モデルは、制御可能な構造で条件付けされた画像を生成できます。これらには、クラスラベル、オブジェクトのキーポイント、人間の骨格、シーンのセマンティックマップが含まれます。これは、外観情報を提供できる単一の画像で構成されます。また、制御可能な構造を提供して、画像の品質</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-12">
        <br><font color="black">2019-12-12</font>
      </time>
    </span>
</section>
<!-- paper0: Excavating "Excavating AI": The Elephant in the Gallery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CV/paper_63.html">
      <font color="black">Excavating "Excavating AI": The Elephant in the Gallery</font>
    </a>
  </h2>
  <font color="black">Kate CrawfordとTrevor Paglenによる「Training Humans」と「Making Faces」の展覧会、およびエッセイ「Excavating AI：The politics of images in machine learning training sets」に関する批評の解説が含まれています。 
[ABSTRACT]展示「人間のトレーニング」と「顔の作成」に関する批評的な解説が含まれています。また、付随するエッセイ「AIの発掘：機械学習のトレーニングセットにおける画像の政治」についても解説しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Garain at SemEval-2020 Task 12: Sequence based Deep Learning for
  Categorizing Offensive Language in Social Media -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CL/paper_0.html">
      <font color="black">Garain at SemEval-2020 Task 12: Sequence based Deep Learning for
  Categorizing Offensive Language in Social Media</font>
    </a>
  </h2>
  <font color="black">提案されたシステムを準備するために、LSTMのようなディープラーニングネットワークとKerasのようなフレームワークを利用しました。これは、単語のバッグモデルを自動生成されたシーケンスベースの特徴と、指定されたデータセットから手動で抽出した特徴と組み合わせたものです。タスクに参加しました。 C、つまり攻撃対象の識別。タスクはさらに3つのサブタスクに分類されました。攻撃言語の識別、攻撃タイプの自動分類、および攻撃対象の識別です。 
[要約]タスクは複数の言語に分割され、データセットは言語ごとに提供されました。cnnのジムブールデンは、タスクに参加したと述べています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: A Practical Chinese Dependency Parser Based on A Large-scale Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CL/paper_1.html">
      <font color="black">A Practical Chinese Dependency Parser Based on A Large-scale Dataset</font>
    </a>
  </h2>
  <font color="black">最近、ニューラルネットワークベース（NNベース）の依存解析が大幅に進歩し、最先端の結果が得られました。2つのテストセットで実験を行います。トレーニングセットと同じ分布を持つ標準テストセットと他のソースからサンプリングされたランダムなテストセット、およびそれらのラベル付き添付ファイルスコア（LAS）は、それぞれ92.9 \％および86.9 \％です。DuCTBは、検索ログ、Chinese Newswire、さまざまなフォーラムを含む複数のソースからの約100万の注釈付き文章で構成されています談話、会話プログラム。 
[ABSTRACT]ソーシャルネットワークベース（nnベース）の依存解析が大幅に進歩しました。2つのテストセットで実験を行います。標準のtestparparparparparpar results.ductserは、約100万の注釈付き文で構成されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Defeating Author Gender Identification with Text Style Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CL/paper_2.html">
      <font color="black">Defeating Author Gender Identification with Text Style Transfer</font>
    </a>
  </h2>
  <font color="black">私たちの方法の多言語での適用性を示すために、私たちは英語とペルシャ語のコーパスの両方にこの方法を適用し、最終的に提案された性別識別モデルをそれぞれ45.6％と39.2％打ち負かし、英語の状態の類推で非常に競争力のある評価結果を得ましたアートメソッド..トークンの置換を目的とした事前トレーニング済みの単語の埋め込み、性別の交換を目的とした文字ベースのトークン分類、およびすべての提案の中で最も流暢な組み合わせを抽出するためのビーム検索アルゴリズムを進めました。最も重要な自然言語処理タスクの1つとして挙げられます。 
[要旨]私たちの方法は複数の言語で適用できます。pgで性別識別モデルを偽造することで、さまざまなモデルの成功を評価するためのトレードオフ値を決定します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: An exploratory study of L1-specific non-words -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CL/paper_3.html">
      <font color="black">An exploratory study of L1-specific non-words</font>
    </a>
  </h2>
  <font color="black">仮の結果は、L1固有の非単語が純粋にスウェーデン語のように見える非単語の後に、2番目に遅い処理が行われることを示しているようです。このホワイトペーパーでは、L1固有の非単語を調べます。異なる言語モデルで非単語を再ランク付けすると、「スウェーデン語」（パイロット調査1）の知覚された違いにつながるかどうか、およびドイツ語と英語のネイティブスピーカーの語彙の決定における反応時間が長いかどうかを調査する2つの小さなケーススタディの結果を示します。それぞれのL1固有の非単語が提示された場合のタスク（パイロット調査2）。 
[ABSTRACT]スウェーデンの話者は別の言語モデルで再ランク付けされます。別の言語モデルで非単語を再ランク付けすると、「スウェーデン語」の違いが認識されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Identifying Documents In-Scope of a Collection from Web Archives -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CL/paper_4.html">
      <font color="black">Identifying Documents In-Scope of a Collection from Web Archives</font>
    </a>
  </h2>
  <font color="black">評価は、3つの異なるWebアーカイブから作成した3つのデータセットに重点を置いています。実験結果では、ドキュメントの特定の部分（全文ではなく）のみに重点を置くBoW分類子が、3つのデータセットすべてで比較したすべての方法よりも優れていることを示しています。具体的には、機械学習モデルとディープラーニングモデルの両方と、ドキュメント全体またはドキュメントの特定の部分から抽出された「バッグオブワード」（BoW）機能と、ドキュメントの構造を取り込む構造的特徴を調べます。 
[ABSTRACT]ドキュメント全体から抽出された「bag of words」（弓）の特徴と、ドキュメントの構造をとらえる構造上の特徴</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Temporal Mental Health Dynamics on Social Media -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CL/paper_5.html">
      <font color="black">Temporal Mental Health Dynamics on Social Media</font>
    </a>
  </h2>
  <font color="black">ソーシャルメディアプラットフォームからのメンタルヘルスデータマイニングの遠隔監視のために既存の方法論を利用し、グローバルなCOVID-19パンデミック時にケーススタディとしてシステムを展開します。グローバルパンデミックへの明示的およびグローバルな現象であるクリスマスのうつ病への暗黙的の両方が文学によってサポートされています。 
[要約]戦略的意思決定に使用するメンタルヘルスのダイナミクスへの洞察を提供するシステムを提案する-意思決定</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-30">
        <br><font color="black">2020-08-30</font>
      </time>
    </span>
</section>
<!-- paper0: ASTRAL: Adversarial Trained LSTM-CNN for Named Entity Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CL/paper_6.html">
      <font color="black">ASTRAL: Adversarial Trained LSTM-CNN for Named Entity Recognition</font>
    </a>
  </h2>
  <font color="black">私たちのモデルは、CoNLL-03、OntoNotes 5.0、WNUT-17の3つのベンチマークで評価され、最先端の結果を達成しています。NERシステムは何十年にもわたって研究されてきました。最近、ディープニューラルネットワークと事前にトレーニングされた単語の埋め込みの進歩は、NERの原動力となっています。 
[ABSTRACT] nerシステムは何十年もの間研究されてきました。最近、ner systemと名付けられました。これにより、より詳細な研究が作成されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: JUNLP@SemEval-2020 Task 9:Sentiment Analysis of Hindi-English code mixed
  data using Grid Search Cross Validation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CL/paper_7.html">
      <font color="black">JUNLP@SemEval-2020 Task 9:Sentiment Analysis of Hindi-English code mixed
  data using Grid Search Cross Validation</font>
    </a>
  </h2>
  <font color="black">この作業は、SemEval-2020 Sentimixタスクへの参加として行われ、英語とヒンディー語のコードが混在する文章の感情分析に焦点を当てました。提出用のユーザー名は「sainik.mahata」、チーム名は「JUNLP」でした。この言語現象は、いくつか例を挙げると、感情分析、機械翻訳、テキスト要約などの従来のNLPドメインに大きな課題をもたらします。 
[要旨]多言語を話す人々は、主に母国語と英語を話す人に焦点を合わせています。彼らは母国語でよく知られており、英語を話す人を主人公としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-24">
        <br><font color="black">2020-07-24</font>
      </time>
    </span>
</section>
<!-- paper0: Coupling Distant Annotation and Adversarial Training for Cross-Domain
  Chinese Word Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CL/paper_8.html">
      <font color="black">Coupling Distant Annotation and Adversarial Training for Cross-Domain
  Chinese Word Segmentation</font>
    </a>
  </h2>
  <font color="black">遠方のアノテーションについては、「中国語の単語」の本質を再考し、ターゲットドメインからの監督や事前定義済みの辞書を必要としない自動遠方アノテーションメカニズムを設計します。このアプローチは、ドメイン固有の単語を効果的に探索し、ターゲットドメインの生のテキスト..敵対的なトレーニングのために、ノイズ低減とソースドメイン情報の最大利用を実行するために、文レベルのトレーニング手順を開発します。 
[ABSTRACT]このペーパーでは、クロスドメインcwsの遠方のアノテーションと敵対的なトレーニングを組み合わせることが提案されています。このアプローチは、タスクを効果的に探索し、ターゲットドメインの生のテキストに遠方のアノテーションを付けることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Automated Storytelling via Causal, Commonsense Plot Ordering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CL/paper_9.html">
      <font color="black">Automated Storytelling via Causal, Commonsense Plot Ordering</font>
    </a>
  </h2>
  <font color="black">人間と参加者のプロトコルを使用して、異なる常識推論推論と帰納的バイアスを備えたベースラインシステムに対してシステムを評価して、知覚されたストーリー品質におけるソフト因果関係の役割を決定します。この作業では、因果関係としてソフト因果関係の概念を紹介します。常識推論から推論されます。C2PO、因果関係、常識プロット順序付けを通じてこの概念を操作可能にするナラティブ生成へのアプローチを示します。 
[ABSTRACT]因果的で常識的なプロットの順序付けによってこの概念を操作可能にするシステムであるc2poを示します。人間の研究は、プロットイベント間のリンクがストーリーの知覚とプロットの一貫性を高めると考えられていることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Machine Translation System Selection from Bandit Feedback -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CL/paper_10.html">
      <font color="black">Machine Translation System Selection from Bandit Feedback</font>
    </a>
  </h2>
  <font color="black">オフライントレーニングとは対照的に、ユーザーは通常、システムの改善に使用される細かいフィードバック（正しい翻訳など）の種類を提供できません。現実の世界で機械翻訳システムを適応させることは難しい問題です。シミュレーションでバンディットラーニングテクニックを使用するユーザーのフィードバックに基づいて、特定の翻訳タスクに使用するシステムを選択するポリシーを学習します。 
[ABSTRACT]シミュレートされたユーザーフィードバックにバンディット学習技術を使用して、特定の翻訳タスクに使用するシステムを選択するポリシーを学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-22">
        <br><font color="black">2020-02-22</font>
      </time>
    </span>
</section>
<!-- paper0: Too good to be true? Predicting author profiles for abusive language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CL/paper_11.html">
      <font color="black">Too good to be true? Predicting author profiles for abusive language</font>
    </a>
  </h2>
  <font color="black">性格特性は実際の値の15％以内で予測され、年齢は10年の誤差範囲で予測され、性別は70％のケースで正しく分類されました。これらの結果は、著者のプロファイリングに関する以前の研究と比較すると不十分です。虐待的な言葉や脅威の評価のコンテキスト内でこれを適用する場合は注意が必要です。この研究では、著者の人口統計と虐待的な言葉と通常の言葉の統計的関係を調べ、性格、年齢、性別の予測実験を行います。 
[ABSTRACT]乱用言語は、予測に基づいて差異が生じるかどうかがまだテストされていない特定の言語のドメインです。研究は米国中の研究者によって行われました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Revisiting the Open-Domain Question Answering Pipeline -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/cs.CL/paper_12.html">
      <font color="black">Revisiting the Open-Domain Question Answering Pipeline</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、従来のBM25ベースの情報検索機能、RM3ベースの神経関連性フィードバック、神経ランカー、および機械読み取り理解段階を使用する新しいマルチステージパイプラインで構成されるオープンドメインQAシステムであるMindstoneについて説明します。オープンドメインQAシステムは、情報検索から始まり、コーパスからドキュメントのサブセットを選択します。これらは、マシンリーダーによって処理され、回答範囲を選択します。このペーパーでは、質問応答におけるエンドツーエンドのパフォーマンスの新しいベースラインを確立します。 Wikipedia / SQuADデータセット（EM = 58.1、F1 = 65.8）の場合、以前の最新技術（Yang et al。、2019b）を大幅に上回ります。 
[ABSTRACT] open-ドメインqaシステムは、コーパスからドキュメントのサブセットを選択するための情報検索で始まります。これらは、マシンリーダーによって処理され、回答スパンを選択します。紙は、質問回答用の新しいベースラインを確立しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Non-Parallel Voice Conversion with Augmented Classifier Star Generative
  Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.AS/paper_0.html">
      <font color="black">Non-Parallel Voice Conversion with Augmented Classifier Star Generative
  Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、新たに導入された「拡張分類子StarGAN（A-StarGAN）」という新しいStarGANバリアントを含む、StarGANの3つの定式化について説明し、それらを非並列VCタスクで比較します。 StarGANと呼ばれる生成的敵対的ネットワーク（GAN）のバリアントを使用することによる非並列音声変換（VC）の場合。第3に、リアルタイム実装を可能にするのに十分な速さで変換済み音声信号を生成でき、数分のトレーニング例しか必要ありません。適度にリアルな音声を生成します。 
[ABSTRACT] stargan-vcは、スピーチジェネレーターのトレーニングに平行した発話、翻訳、または時間調整手順を必要としません。nongan-vcと呼ばれるこのメソッドは、変換されたスピーチ信号を十分に速く生成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: WaveGrad: Estimating Gradients for Waveform Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.AS/paper_1.html">
      <font color="black">WaveGrad: Estimating Gradients for Waveform Generation</font>
    </a>
  </h2>
  <font color="black">WaveGradはトレーニングが簡単で、対数尤度の加重変分下限を暗黙的に最適化します。わずか6回の反復で高忠実度のオーディオサンプルを生成できます。WaveGradは非自己回帰であり、定数のみが必要です推論中の生成ステップの数。 
[ABSTRACT] wavegradは非自己回帰であり、testimony.itの実行中に一定数の条件付きステップが必要です。トレーニングは簡単で、対数尤度の重み付き変分下限を暗黙的に最適化します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Speaker Representation Learning using Global Context Guided Channel and
  Time-Frequency Transformations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.AS/paper_2.html">
      <font color="black">Speaker Representation Learning using Global Context Guided Channel and
  Time-Frequency Transformations</font>
    </a>
  </h2>
  <font color="black">提案されたモジュールのパフォーマンスに影響を与える可能性のあるさまざまな要因を分析するために、詳細なアブレーション研究も行われます。提案されたL2-tf-GTFC変換ブロックを使用することにより、等誤り率が4.56％から3.07％ DCFスコアの点で32.68％の削減、および相対的な27.28％の改善。グローバルコンテキスト情報を使用して、重要なチャネルを強化し、グローバルコンテキストとローカル機能間の類似性を計算することにより、顕著な時間周波数位置を再調整します。 
[ABSTRACT]軽量ブロックはcnnモデルに簡単に組み込むことができます。ベースラインresnet-ldeモデルおよびスクイーズ＆励起ブロックに比べて、スピーカーの検証パフォーマンスが大幅に向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Architecture Search For Keyword Spotting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-03/eess.AS/paper_3.html">
      <font color="black">Neural Architecture Search For Keyword Spotting</font>
    </a>
  </h2>
  <font color="black">Googleの音声コマンドデータセットで提案された方法を評価し、文献で一般的に報告されている12クラスの発話分類の設定で97％を超える最先端の精度を達成しました。事前定義されたセルサーチスペースで演算子とその接続を検索します。次に、見つかったセルを深度と幅の両方で拡大して、競争力のあるパフォーマンスを実現します。 
[ABSTRACT]許容可能なメモリフットプリントを維持しながら、音響信号から抽出された特徴に基づいてキーワードスポッティングのパフォーマンスを向上させるのに役立つ畳み込みニューラルネットワークモデルを検索します。見つかったセルは、競争力のあるパフォーマンスを実現するために深さと幅の両方で拡大されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
