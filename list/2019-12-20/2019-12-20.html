<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<title>Akari-2019-12-20の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
  <div class="header-logo">
    <a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
  </div>
</header>
<input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">

<div class="menubar">
<span class="bar"></span>
<span class="bar"></span>
<span class="bar"></span>
</div>

<ul>
<li><a id="home" href="../../index.html">Home</a></li>
<li><a id="about" href="../../teamAkariとは.html">About</a></li>
<li><a id="contact" href="../../contact.html">Contact</a></li>
<li><a id="contact" href="../../list/newest.html">New Papers</a></li>
<li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
</ul>

</label>
<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Practical applicability of deep neural networks for overlapping speaker
  separation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.SD/paper_0.html">
      Practical applicability of deep neural networks for overlapping speaker
  separation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      調査対象のディープラーニングメソッドは、ディープクラスタリングとディープアトラクタネットワークです。次に、メソッドが現実的なバックグラウンドノイズに対処する方法を調査し、これらの外乱に対処するためのいくつかの修正を提案します。 、これらが訓練された言語と共通の特徴を持っている場合。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SeER: An Explainable Deep Learning MIDI-based Hybrid Song Recommender
  System -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.SD/paper_1.html">
      SeER: An Explainable Deep Learning MIDI-based Hybrid Song Recommender
  System
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、「SeER」と呼ばれるハイブリッドディープラーニングモデルを提案します。これは、より正確なパーソナライズされたレコメンデーションを提供するために、コラボレーティブフィルター（CF）とディープラーニングシーケンスモデルを使用して曲のMIDIコンテンツをレコメンデーションします。アイテムのコールドスタートの問題を解決します。さらに、提案されたオフライン検証のテストに基づいて、パーソナライズされた説明がユーザーの好みに合ったプロパティをキャプチャしていることを示します。評価実験では、ランキング評価の観点からのアートベースラインおよびハイブリッド歌推薦システム。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-25">
        <br>2019-06-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: LSTM-TDNN with convolutional front-end for Dialect Identification in the
  2019 Multi-Genre Broadcast Challenge -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.SD/paper_2.html">
      LSTM-TDNN with convolutional front-end for Dialect Identification in the
  2019 Multi-Genre Broadcast Challenge
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、MUSANとRIRデータセットを使用して音声増強を調査し、既存のトレーニングデータの量と多様性を通常の方法で増加させます。他のコーパスを使用せずにCLSTMシステムをトレーニングします。最初の結果は、CLSTMアーキテクチャが従来のDNN xベクトル実装よりも優れていることを示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Generating Synthetic Audio Data for Attention-Based Speech Recognition
  Systems -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_0.html">
      Generating Synthetic Audio Data for Attention-Based Speech Recognition
  Systems
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      低リソース環境（LibriSpeech-100h）でのデータ増強により、強力なベースラインに対して単語誤り率（WER）で最大33％の改善を達成し、50を超える同等のOracle実験とのギャップを縮めました。 \％..同じテキストデータの言語モデル統合およびSpecAugmentのような単純なデータ拡張メソッドとメソッドを比較し、パフォーマンスの向上はほとんど独立していることを示します。ASRシステムとTTSシステムは別々に構築され、テキストのみのデータがパラメータやアーキテクチャを変更することなく、既存のエンドツーエンドASRシステムを強化するために使用できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Multi-task Learning Model for Chinese-oriented Aspect Polarity
  Classification and Aspect Term Extraction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_1.html">
      A Multi-task Learning Model for Chinese-oriented Aspect Polarity
  Classification and Aspect Term Extraction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      既存のモデルと比較して、このモデルはアスペクト用語を抽出し、アスペクト用語の極性を同期的に推定する機能を備えています。さらに、このモデルは中国語と英語の両方のコメントを同時に分析するのに効果的であり、多言語混合データセットでの実験がその可用性を証明しました。最も一般的に使用されるSemEval-2014 task4レストランおよびラップトップデータセットの実験結果は、ATEおよびAPCサブタスクの最先端のパフォーマンスよりも優れています。既存の作業のほとんどは、アスペクト用語極性推論および無視のサブタスクに焦点を当てていますアスペクト用語抽出の重要性。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-17">
        <br>2019-12-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Controllable Text-to-Image Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_2.html">
      Controllable Text-to-Image Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ベンチマークデータセットの広範な実験により、この方法が既存の最新技術よりも優れており、自然言語記述を使用して合成画像を効果的に操作できることが実証されています。コードはhttps://github.com/mrlibw/ControlGANで入手できます。損失は、画像生成に関与するランダム性を低減し、変更されたテキストに必要な特定の属性を操作者が操作することを促進するために採用されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-16">
        <br>2019-09-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Discriminative Sentence Modeling for Story Ending Prediction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_3.html">
      Discriminative Sentence Modeling for Story Ending Prediction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、SCT v1.0とv1.5の両方で、従来のモデルとBERTベースのモデルを慎重に調べ、将来の研究に役立つ可能性のある興味深い結果を示しています。StoryCloze Testデータセットの実験結果は、提案されたモデルがさまざまなシステムを大幅に上回ることを示しています提案されたモデルは、コンテキスト表現、ストーリー認識表現、および識別表現の3つのセマンティックレベルで2つの終了を識別することができます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Annotating and normalizing biomedical NEs with limited knowledge -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_4.html">
      Annotating and normalizing biomedical NEs with limited knowledge
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      名前付きエンティティ認識（NER）は、新しいドメインの言語処理の最初のステップです。共有タスク用に開発されたシステムは、類似の辞書で得られたスコアを明らかに上回る方法で収集、構造化、変更された限られた知識に基づいていますこの意味で、人間の注釈付きデータセットの全体的な品質に関する発見者の中には、このシステムによって得られた上記の「公式の」結果に疑問を投げかける人もいます（0.91 F1-score）。 2つのPharmaCoNERサブタスクの最初（0.916 F1スコア）。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CJRC: A Reliable Human-Annotated Benchmark DataSet for Chinese Judicial
  Reading Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_5.html">
      CJRC: A Reliable Human-Annotated Benchmark DataSet for Chinese Judicial
  Reading Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      BERTとBiDAFに基づく2つの強力なベースラインモデルを構築します。CJRCデータセットは、理解技術を読み取ることで要素を抽出するのに役立ちます。ただし、ドキュメントタイプとアクションの原因の多様性のため、要素タイプを完全に事前定義することは困難です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Optimal coding and the origins of Zipfian laws -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_6.html">
      Optimal coding and the origins of Zipfian laws
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最適な非特異コーディングは、単語の長さが周波数ランクの対数にほぼ比例して増加することを予測します。これは、Zipfの略語法則と一致しています。 -頻度分布..さらに、最適な非特異的コーディングに関する調査結果は、ランダムなタイピングに関する一般的な信念に挑戦しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-04">
        <br>2019-06-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Depth-Adaptive Transformer -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_7.html">
      Depth-Adaptive Transformer
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーでは、ネットワークのさまざまな段階で出力を予測できるTransformerモデルをトレーニングし、特定のシーケンスに必要な計算量を予測するさまざまな方法を調査します。同じレイヤーのセットを繰り返し適用するUniversal Transformersの動的計算とは異なり、デコーダーレイヤーの1/4未満を使用しながら、ベースラインTransformerを適切に調整します。各ステップで異なるレイヤーを適用して、計算量とモデル容量。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-22">
        <br>2019-10-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Application of Word2vec in Phoneme Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_8.html">
      Application of Word2vec in Phoneme Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      61-39音素マッピング比較テーブルを使用して、データセットの音素を逆マッピングし、さらに61個の音素トレーニングデータを生成します。音素ベクトル間の距離を大きくします。トレーニングの終わりに、修正トレーニング用のデータセットを標準データセットに置き換えます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-17">
        <br>2019-12-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Going Beneath the Surface: Evaluating Image Captioning for
  Grammaticality, Truthfulness and Diversity -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_9.html">
      Going Beneath the Surface: Evaluating Image Captioning for
  Grammaticality, Truthfulness and Diversity
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      診断評価のために構築する広範な合成データセットの既存の画像キャプションモデルを評価することにより、評価フレームワークの可能性を示します。画像キャプションのタスクのための新しい診断評価フレームワークを紹介します。生成されたキャプションの文法、真実性、および多様性（GTD）のモデル。GTD評価フレームワークを診断データセットと組み合わせて、標準の評価を補完するモデルの機能と制限に関する洞察を提供する方法を経験的に示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Identifying Adversarial Sentences by Analyzing Text Complexity -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_10.html">
      Identifying Adversarial Sentences by Analyzing Text Complexity
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、発見に関連する特徴を抽出することにより、敵対テキストを識別する方法を提案します。リスクを防ぐために敵対テキストと元のテキストの違いを調査します。人間によって書かれたテキストがより一貫性があり、流暢。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An End-to-End Dialogue State Tracking System with Machine Reading
  Comprehension and Wide & Deep Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_11.html">
      An End-to-End Dialogue State Tracking System with Machine Reading
  Comprehension and Wide & Deep Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      従来のステージワイズDSTとは異なり、ダイアログターン間のエラーの蓄積を回避するためのエンドツーエンドDSTシステムを提案します。知っている限り、MRCとWide＆DeepモデルがDSTに適用されるのは初めて実験結果は、フレームワークが、0.8652の共同目標精度と0.9835のF1スコアをタグ付けするスロットで、50％ゼロショットサービスを含むテストデータセットで優れたパフォーマンスを達成することを示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: LSTM-TDNN with convolutional front-end for Dialect Identification in the
  2019 Multi-Genre Broadcast Challenge -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_12.html">
      LSTM-TDNN with convolutional front-end for Dialect Identification in the
  2019 Multi-Genre Broadcast Challenge
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは、発話を複数の時間ストレッチまたは時間圧縮バージョンに変換し、その後、他のコーパスを使用せずにCLSTMシステムをトレーニングするために使用されます。この論文では、MUSANおよびRIRデータセットを使用して音声量を増やし、量と多様性を向上させる第2に、TSMベースの速度摂動を採用すると、不均衡なデータのパフォーマンスがわずかに向上します。最終的に、関連する話者および言語認識タスクからの証拠に沿って、従来のデータ増強手法がさらにメリットをもたらします。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards a Philological Metric through a Topological Data Analysis
  Approach -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_13.html">
      Towards a Philological Metric through a Topological Data Analysis
  Approach
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果として、文学の専門家の基準の下にある結果に到達し、Lope de Vegaの文学スタイルを、G \ &#39;ongoraのものよりもQuevedoのものに近づけます。この論文では、トポロジカルデータを使用します。これらの詩人の文学スタイルの間の距離を測るための最初のアプローチを提供する分析技術。一般に、2つの異なるストリームで文学の専門家によって分類されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Simile Recognition with Cyclic Multitask Learning and Local
  Attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_14.html">
      Neural Simile Recognition with Cyclic Multitask Learning and Local
  Attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      各サブタスクを繰り返し実行し、前のサブタスクの出力を現在のサブタスクへの追加入力として取得することで、サブタスク間の相互依存性をよりよく調査できるようにします。アートモデルと慎重に設計されたベースライン、そしてゲインはBERTを使用しても依然として顕著です。直mile認識は、直mile文を検出し、直componentsコンポーネント、つまりテナーと車両を抽出することです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Bootstrapping Generators from Noisy Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_15.html">
      Bootstrapping Generators from Noisy Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、コンテンツ固有の目的でトレーニングされたモデルが、ソフトアテンションのみに依存するバニラエンコーダデコーダを改善することを示しています。特殊なコンテンツ選択メカニズムを導入することにより、この困難なタスクに取り組んでいます。 -テキスト生成は、構造化されたデータ表現（たとえば、データベース内のファクト）と関連テキストとの間の通信の学習に関するものです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-04-17">
        <br>2018-04-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An Ensemble Method to Produce High-Quality Word Embeddings (2016) -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_16.html">
      An Ensemble Method to Produce High-Quality Word Embeddings (2016)
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      それが生成する埋め込みは、多くの単語の類似性評価で最先端のパフォーマンスを達成します。まれな単語の評価での$ \ rho = .596 $のスコア（Luong et al。、2013）は、以前の最もよく知られたシステム。GloVe（Pennington et al。、2014）とword2vec（Mikolov et al。、2013）によって生成された埋め込みを、セマンティックネットワークConceptNet（Speer and Havasi、2012 ）およびPPDB（Ganitkevitch et al。、2013）、それらの情報を大規模な多言語語彙を持つ共通の表現にマージします。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2016-04-06">
        <br>2016-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: BabyAI: A Platform to Study the Sample Efficiency of Grounded Language
  Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_17.html">
      BabyAI: A Platform to Study the Sample Efficiency of Grounded Language
  Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      現在のディープラーニングメソッドは、組成特性を持つ言語の学習に関してはまだ十分なサンプル効率ではないという強力な証拠を提示します。ベースラインの結果を報告し、ニューラルネットワークベースのトレーニングに必要な人間の関与の量を推定しますBabyAIレベルのいくつかのエージェント。BabyAIプラットフォームは、19レベルの難易度の拡張可能なスイートで構成されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-10-18">
        <br>2018-10-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-channel Reverse Dictionary Model -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_18.html">
      Multi-channel Reverse Dictionary Model
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      辞書の定義と人間が作成した説明の両方を含む英語と中国語のデータセットでモデルを評価します。予測子は、入力クエリからターゲットワードの異なる特性を識別することが期待されます。実験結果は、モデルがさらに、人間が作成した記述データセットで最も人気のある商用逆辞書システムよりも優れています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br>2019-12-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: GoodNewsEveryone: A Corpus of News Headlines Annotated with Emotions,
  Semantic Roles, and Reader Perception -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_19.html">
      GoodNewsEveryone: A Corpus of News Headlines Annotated with Emotions,
  Semantic Roles, and Reader Perception
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、構造の自動予測のタスクのベースラインを開発し、結果について議論します。クラウドソーシングを介して、主要な感情、感情経験者、テキストの合図、感情の原因とターゲットを注釈付けした5000の英語ニュースヘッドラインのデータセットをリリースすることで、このギャップを埋めます、読者の見出しの認識と感情だけでなく、感情を構造化された現象として扱っている作品は少なく、関連するデータセットと方法の欠如によって説明できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-06">
        <br>2019-12-06
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Generating Synthetic Audio Data for Attention-Based Speech Recognition
  Systems -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/eess.AS/paper_0.html">
      Generating Synthetic Audio Data for Attention-Based Speech Recognition
  Systems
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      低リソース環境（LibriSpeech-100h）でのデータ増強により、強力なベースラインに対して単語誤り率（WER）で最大33％の改善を達成し、50を超える同等のOracle実験とのギャップを縮めました。 \％..同じテキストデータの言語モデル統合とSpecAugmentのような単純なデータ拡張方法とこの方法を比較し、パフォーマンスの改善はほとんど独立していることを示します。また、最新のWERに対して最大5％の相対的なWERの改善を示しますLibriSpeech-960hのASRベースライン。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Practical applicability of deep neural networks for overlapping speaker
  separation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/eess.AS/paper_1.html">
      Practical applicability of deep neural networks for overlapping speaker
  separation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      検討するディープラーニング方法は、ディープクラスタリングとディープアトラクタネットワークです。このペーパーでは、重複する話者分離問題に対する2つのディープラーニングベースのソリューションの現実的なシナリオでの適用性を検討します。これらには、訓練された言語と共通の特徴があります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SeER: An Explainable Deep Learning MIDI-based Hybrid Song Recommender
  System -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/eess.AS/paper_2.html">
      SeER: An Explainable Deep Learning MIDI-based Hybrid Song Recommender
  System
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      予測精度の重要性とは別に、説明可能性やコールドスタート問題の解決など、他の重要な側面も重要です。この作業では、協調フィルタリング（CF）とより正確なパーソナライズされた推奨事項を提供するための推奨事項の歌のMIDIコンテンツの深層学習シーケンスモデル。アイテムのコールドスタートの問題を解決します。歌の推薦のための深層学習の進歩にもかかわらず、コンテンツに基づいたシーケンスモデルを学習することによって歌のシーケンシャルな性質を利用したものはいません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-25">
        <br>2019-06-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CNN-LSTM models for Multi-Speaker Source Separation using Bayesian Hyper
  Parameter Optimization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/eess.AS/paper_3.html">
      CNN-LSTM models for Multi-Speaker Source Separation using Bayesian Hyper
  Parameter Optimization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、ハイパーパラメーター空間で新しいポイントをサンプリングする場合、以前に評価されたポイントに非常に近い可能性があるため、追加情報をほとんど提供できません。 ..さらに、ランダムサンプリングは、パフォーマンスの低いモデルが支配的なハイパースペースエリアと同様に、有望なエリアでサンプリングする可能性があります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Application of Word2vec in Phoneme Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/eess.AS/paper_4.html">
      Application of Word2vec in Phoneme Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、音素認識モデルは、word2vecモデルを使用して、パフォーマンスを向上させるために埋め込み行列を初期化します。これにより、音素ベクトル間の距離が長くなる場合があります。さらに61個の音素トレーニングデータを生成します。トレーニングの最後に、修正トレーニング用のデータセットを標準データセットに置き換えます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-17">
        <br>2019-12-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: LSTM-TDNN with convolutional front-end for Dialect Identification in the
  2019 Multi-Genre Broadcast Challenge -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/eess.AS/paper_5.html">
      LSTM-TDNN with convolutional front-end for Dialect Identification in the
  2019 Multi-Genre Broadcast Challenge
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、MUSANとRIRデータセットを使用して音声増強を調査し、既存のトレーニングデータの量と多様性を通常の方法で増やします。結果は、CLSTMアーキテクチャが従来のDNN xベクトル実装よりも優れていることを最初に示します。タイムスケール修正（TSM）を使用して、非常に不均衡なトレーニングセットの1つの低リソース方言の集中的な増強を調査します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Continuous Speech Recognition using EEG and Video -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/eess.AS/paper_6.html">
      Continuous Speech Recognition using EEG and Video
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本稿では、脳波（EEG）機能を使用して連続視覚音声認識システムのパフォーマンスを改善できるかどうかを調査します。コネクショニスト時間分類（CTC）ベースのエンドツーエンド自動音声認識（ASR）モデルを実装しました。認識。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-16">
        <br>2019-12-16
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Murine models of renal ischaemia reperfusion injury: An opportunity for refinement using non-invasive monitoring methods -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/biorxiv.physiology/paper_0.html">
      Murine models of renal ischaemia reperfusion injury: An opportunity for refinement using non-invasive monitoring methods
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これにより、腎臓損傷モデルの改良が容易になり、前臨床モデルで見られる損傷の程度を臨床環境で見られる損傷に変換することができます。基礎となるメカニズムを理解するには、AKIおよびCKDの再現可能な小動物モデルが必要です。方法：オスBALB / cマウスは、イソフルラン麻酔下で、両側腎茎クランプ（AKI）または遅延対側腎摘出（CKD）を伴う片側腎茎クランプを受けました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Vitamin D-binding protein is required for the maintenance of α-cell function and glucagon secretion -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/biorxiv.physiology/paper_1.html">
      Vitamin D-binding protein is required for the maintenance of α-cell function and glucagon secretion
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      DBPを削除すると、より小さく過形成の細胞、Na +チャネルコンダクタンスの変化、低グルコースによる細胞活性化の障害、グルカゴン分泌速度の低下がもたらされました。 。したがって、DBPは糖尿病の病因に影響を与える細胞表現型の重要な調節因子です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: When does diet matter? The roles of larval and adult nutrition in regulating adult size traits. -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/biorxiv.physiology/paper_2.html">
      When does diet matter? The roles of larval and adult nutrition in regulating adult size traits.
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      大人の体重については、豊富な大人の食事は、両方の種類の食事の幼虫の栄養不良の悪影響を緩和しました。幼虫の食事を操作すると、大人のサイズのすべての測定値に大きな影響を与えることがわかりました。体重も成人の栄養によって変化する可能性があります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
