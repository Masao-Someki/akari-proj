<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<title>Akari-2019-12-20の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
  <div class="header-logo">
    <a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
  </div>
</header>
<input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">

<div class="menubar">
<span class="bar"></span>
<span class="bar"></span>
<span class="bar"></span>
</div>

<ul>
<li><a id="home" href="../../index.html">Home</a></li>
<li><a id="about" href="../../teamAkariとは.html">About</a></li>
<li><a id="contact" href="../../contact.html">Contact</a></li>
<li><a id="contact" href="../../list/newest.html">New Papers</a></li>
<li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
</ul>

</label>
<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Practical applicability of deep neural networks for overlapping speaker
  separation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.SD/paper_0.html">
      Practical applicability of deep neural networks for overlapping speaker
  separation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      調査対象のディープラーニングメソッドは、ディープクラスタリングとディープアトラクタネットワークです。次に、メソッドが現実的なバックグラウンドノイズに対処する方法を調査し、これらの外乱に対処するためのいくつかの修正を提案します。 、これらが訓練された言語と共通の特徴を持っている場合。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SeER: An Explainable Deep Learning MIDI-based Hybrid Song Recommender
  System -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.SD/paper_1.html">
      SeER: An Explainable Deep Learning MIDI-based Hybrid Song Recommender
  System
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      評価実験では、ランキング評価に関して最先端のベースラインおよびハイブリッド歌推薦システムと比較して有望な結果を示しています。さらに、オフライン検証のための提案されたテストに基づいて、私たちのパーソナライズされた説明はユーザーの好み..歌の推薦のための深層学習の進歩にもかかわらず、コンテンツに基づくシーケンスモデルを学習することによって歌のシーケンシャルな性質を利用したものはいません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-25">
        <br>2019-06-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: LSTM-TDNN with convolutional front-end for Dialect Identification in the
  2019 Multi-Genre Broadcast Challenge -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.SD/paper_2.html">
      LSTM-TDNN with convolutional front-end for Dialect Identification in the
  2019 Multi-Genre Broadcast Challenge
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本論文では、MUSANとRIRデータセットを使用して音声増強を調査し、既存のトレーニングデータの量と多様性を通常の方法で増やします。結果は、CLSTMアーキテクチャが従来のDNN xベクトル実装よりも優れていることを最初に示します。システムは、ASRU 2019で発表されたMGB-5 ADIチャレンジの15エントリ中2位を獲得しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Generating Synthetic Audio Data for Attention-Based Speech Recognition
  Systems -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_0.html">
      Generating Synthetic Audio Data for Attention-Based Speech Recognition
  Systems
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      低リソース環境（LibriSpeech-100h）でのデータ増強により、強力なベースラインに対して単語誤り率（WER）で最大33％の改善を達成し、50を超える同等のOracle実験とのギャップを縮めました。 \％..また、LibriSpeech-960hの最新のASRベースラインに対して最大5％の相対WERの改善を示しています。ASRおよびTTSシステムは、テキストのみのデータを使用して既存のエンドツーエンドを強化できることを示すために個別に構築されています-パラメータまたはアーキテクチャの変更を必要とせずにASRシステムを終了します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Multi-task Learning Model for Chinese-oriented Aspect Polarity
  Classification and Aspect Term Extraction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_1.html">
      A Multi-task Learning Model for Chinese-oriented Aspect Polarity
  Classification and Aspect Term Extraction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ローカルコンテキストフォーカス（LCF）メカニズムに基づいて、このペーパーでは、まず、中国語指向のアスペクトベースの感情分析、つまりLCF-ATEPCのマルチタスク学習モデルを提案します。既存のモデルと比較して、このモデルはアスペクトを抽出する機能を備えていますさらに、このモデルは中国語と英語の両方のコメントを同時に分析するのに効果的であり、多言語混合データセットの実験がその有効性を証明しました。さらに、最も一般的に使用されるSemEval-2014 task4 Restaurantの実験結果また、ラップトップデータセットは、ATEおよびAPCサブタスクでの最先端のパフォーマンスよりも優れています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-17">
        <br>2019-12-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Controllable Text-to-Image Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_2.html">
      Controllable Text-to-Image Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ベンチマークデータセットに関する広範な実験により、本手法が既存の最新技術よりも優れており、自然言語記述を使用して合成画像を効果的に操作できることが実証されています。また、単語レベルの弁別子が提案され、単語と他のコンテンツの生成に影響を与えることなく、特定の視覚属性を操作できる効果的なジェネレーターのトレーニングを促進する画像領域。 、モデルが最も関連性の高い単語に対応するサブリージョンの生成と操作に集中できるようにします。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-16">
        <br>2019-09-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Discriminative Sentence Modeling for Story Ending Prediction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_3.html">
      Discriminative Sentence Modeling for Story Ending Prediction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、SCT v1.0とv1.5の両方で、従来のモデルとBERTベースのモデルを慎重に調べ、将来の研究に役立つ可能性のある興味深い結果を示しています。StoryCloze Testデータセットの実験結果は、提案されたモデルがさまざまなシステムを大幅に上回ることを示しています提案されたモデルは、コンテキスト表現、ストーリー認識表現、および識別表現の3つのセマンティックレベルで2つの終了を識別することができます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Annotating and normalizing biomedical NEs with limited knowledge -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_4.html">
      Annotating and normalizing biomedical NEs with limited knowledge
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      共有タスクのために開発されたシステムは、限られた知識に基づいており、過去の英語の類似の辞書ベースのシステムで得られたスコアを明らかに上回る方法で収集、構造化、変更されています。人間の注釈付きデータセットの全体的な品質は、2つのPharmaCoNERサブタスクでそれぞれ2番目（0.91 F1スコア）と1番目（0.916 F1スコア）にランク付けされた、このシステムによって得られる上記の「公式」結果に疑問を投げかけます。サブドメインのNERの知識ベースの方法を回復するために、このペーパーでは、注釈ガイドラインと人間の注釈プラクティスの両方の検証と統合におけるリソースベースのシステムの重要な貢献も強調しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CJRC: A Reliable Human-Annotated Benchmark DataSet for Chinese Judicial
  Reading Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_5.html">
      CJRC: A Reliable Human-Annotated Benchmark DataSet for Chinese Judicial
  Reading Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、人間のアノテーターと比較して改善のための十分なスペースがあることを示しています。BERTとBiDAFに基づいて2つの強力なベースラインモデルを構築します。ただし、ドキュメントタイプと原因の多様性のために、エレメントタイプを完全に事前定義することは困難ですアクションの。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Optimal coding and the origins of Zipfian laws -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_6.html">
      Optimal coding and the origins of Zipfian laws
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最適な非特異コーディングは、単語の長さが周波数ランクの対数にほぼ比例して増加することを予測します。これは、Zipfの略語法則と一致しています。 -頻度分布..最後に、Zipfianの法則と他の言語法のコンパクトな理論の構築のための最適なコーディングの含意について説明します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-04">
        <br>2019-06-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Depth-Adaptive Transformer -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_7.html">
      Depth-Adaptive Transformer
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      IWSLTのドイツ語から英語への翻訳では、4分の1未満のデコーダレイヤーを使用しながら、適切に調整されたベースライントランスフォーマーの精度にアプローチします。このホワイトペーパーでは、ネットワークのさまざまな段階で出力を予測できるトランスフォーマーモデルをトレーニングし、特定のシーケンスに必要な計算量を予測するさまざまな方法を調査します。同じレイヤーのセットを繰り返し適用するユニバーサルトランスフォーマーの動的計算とは異なり、ステップごとに異なるレイヤーを適用して、計算量とモデル容量。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-22">
        <br>2019-10-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Application of Word2vec in Phoneme Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_8.html">
      Application of Word2vec in Phoneme Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、音素認識モデルは、word2vecモデルを使用して、パフォーマンスを向上させるために埋め込み行列を初期化します。これにより、音素ベクトル間の距離が長くなる場合があります。さらに61個の音素トレーニングデータを生成します。トレーニングの最後に、修正トレーニング用のデータセットを標準データセットに置き換えます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-17">
        <br>2019-12-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Going Beneath the Surface: Evaluating Image Captioning for
  Grammaticality, Truthfulness and Diversity -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_9.html">
      Going Beneath the Surface: Evaluating Image Captioning for
  Grammaticality, Truthfulness and Diversity
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      診断評価のために構築する広範囲の合成データセットの既存の画像キャプションモデルを評価することにより、評価フレームワークの可能性を示します。既存の評価指標は、候補キャプションと参照キャプションのセット間の表面類似性に焦点を当て、キャプションと基礎となる視覚的コンテンツとの間の実際の関係を確認しないでください。しかし、このタスクの評価は依然として困難な問題です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Identifying Adversarial Sentences by Analyzing Text Complexity -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_10.html">
      Identifying Adversarial Sentences by Analyzing Text Complexity
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、調査結果に関連する特徴を抽出することにより、敵対テキストを識別する方法を提案します。人間によって書かれたテキストがより一貫性があり、流fluentであることを証明します。スパム製品のレビューや偽の政治投稿などの悪意のある目的を実行するため。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An End-to-End Dialogue State Tracking System with Machine Reading
  Comprehension and Wide & Deep Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_11.html">
      An End-to-End Dialogue State Tracking System with Machine Reading
  Comprehension and Wide & Deep Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちが知る限り、MRCとWide＆DeepモデルがDST問題に完全にエンドツーエンドで適用されるのはこれが初めてです。従来のステージワイズDSTとは異なり、エンドツーエンドを提案しますダイアログターン間のエラーの蓄積を避けるためのDSTシステム。実験結果は、フレームワークが0.8652の共同目標精度と0.9835のタグ付けF1スコアの50％ゼロショットサービスを含むテストデータセットで優れたパフォーマンスを達成することを示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: LSTM-TDNN with convolutional front-end for Dialect Identification in the
  2019 Multi-Genre Broadcast Challenge -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_12.html">
      LSTM-TDNN with convolutional front-end for Dialect Identification in the
  2019 Multi-Genre Broadcast Challenge
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、MUSANとRIRデータセットを使用して音声増強を調査し、既存のトレーニングデータの量と多様性を通常の方法で増加させます。他のコーパスを使用せずにCLSTMシステムをトレーニングします。最初の結果は、CLSTMアーキテクチャが従来のDNN xベクトル実装よりも優れていることを示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards a Philological Metric through a Topological Data Analysis
  Approach -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_13.html">
      Towards a Philological Metric through a Topological Data Analysis
  Approach
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果として、文学の専門家の基準の下にある結果に到達し、Lope de Vegaの文学スタイルを、G \ &#39;ongoraのものよりもQuevedoのものに近づけます。この論文では、トポロジカルデータを使用します。これらの詩人の文学スタイル間の距離を測るための最初のアプローチを提供する分析手法。この文学的な傾向に。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Simile Recognition with Cyclic Multitask Learning and Local
  Attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_14.html">
      Neural Simile Recognition with Cyclic Multitask Learning and Local
  Attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      各サブタスクを繰り返し実行し、前のサブタスクの出力を現在のサブタスクへの追加入力として取得し、サブタスク間の相互依存性をよりよく調査できるようにします。広範な実験により、フレームワークが現在の最先端モデルおよび慎重に設計されたベースラインよりも大幅に優れていることが示されており、BERTを使用した場合の利益は依然として顕著です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Bootstrapping Generators from Noisy Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_15.html">
      Bootstrapping Generators from Noisy Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、コンテンツ固有の目的でトレーニングされたモデルが、ソフトアテンションのみに依存するバニラエンコーダーデコーダーを改良することを示しています。データとテキストのペア間の対応を発見し、エンコーダー/デコーダーアーキテクチャーのトレーニング中にこれらを使用してコンテンツ信号を強化する方法を示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-04-17">
        <br>2018-04-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An Ensemble Method to Produce High-Quality Word Embeddings (2016) -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_16.html">
      An Ensemble Method to Produce High-Quality Word Embeddings (2016)
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      まれな単語（Luong et al。、2013）の評価での$ \ rho = .596 $のスコアは、以前の最もよく知られているシステムよりも16％高くなっています。多くの単語の類似性の評価..計算セマンティクスへの現在成功しているアプローチは、単語を機械学習ベクトル空間の埋め込みとして表現することです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2016-04-06">
        <br>2016-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: BabyAI: A Platform to Study the Sample Efficiency of Grounded Language
  Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_17.html">
      BabyAI: A Platform to Study the Sample Efficiency of Grounded Language
  Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      現在のディープラーニングメソッドは、組成特性を持つ言語の学習に関してはまだ十分なサンプル効率ではないという強力な証拠を提示します。BabyAIプラットフォームは、19レベルの難易度の拡張可能なスイートで構成されています。言語指導を理解することは実用的および科学的理由の両方にとって望ましいが、現在の学習方法のデータ効率が悪いことを考えると、この目標は相当な研究努力を必要とするかもしれない。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-10-18">
        <br>2018-10-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-channel Reverse Dictionary Model -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_18.html">
      Multi-channel Reverse Dictionary Model
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      辞書の定義と人間が作成した記述の両方を含む、英語と中国語のデータセットでモデルを評価します。実験結果は、モデルが最先端のパフォーマンスを達成し、人間で最も人気のある商用逆辞書システムよりも優れていることを示します記述された記述データセット..このモデルは、センテンスエンコーダーと複数の予測子で構成されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br>2019-12-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: GoodNewsEveryone: A Corpus of News Headlines Annotated with Emotions,
  Semantic Roles, and Reader Perception -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/cs.CL/paper_19.html">
      GoodNewsEveryone: A Corpus of News Headlines Annotated with Emotions,
  Semantic Roles, and Reader Perception
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      テキストからの感情分析に関するほとんどの研究は、感情分類または感情強度回帰のタスクに焦点を当てています。最後に、構造の自動予測タスクのベースラインを開発し、結果を議論します。主要な感情、感情経験者、テキストによる手がかり、感情の原因とターゲット、および読者の見出しに対する認識と感情をクラウドソーシングで注釈付けしたニュースの見出し。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-06">
        <br>2019-12-06
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Generating Synthetic Audio Data for Attention-Based Speech Recognition
  Systems -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/eess.AS/paper_0.html">
      Generating Synthetic Audio Data for Attention-Based Speech Recognition
  Systems
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      低リソース環境（LibriSpeech-100h）でのデータ拡張により、強力なベースラインに対してワードエラー率（WER）で最大33％の改善を達成し、同等のOracle実験とのギャップを50以上削減\％.. LibriSpeech-960hでの最新のASRベースラインに対して最大5％の相対WERの改善も示しています。同じテキストデータの言語モデル統合とSpecAugmentおよびshowのような単純なデータ拡張メソッドとメソッドを比較します。パフォーマンスの改善はほとんど独立しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Practical applicability of deep neural networks for overlapping speaker
  separation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/eess.AS/paper_1.html">
      Practical applicability of deep neural networks for overlapping speaker
  separation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      検討するディープラーニング手法は、ディープクラスタリングとディープアトラクタネットワークです。まず、これらの手法が広範囲の言語に適用可能であることを示す実験を示します。重複するスピーカー分離問題の解決策。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SeER: An Explainable Deep Learning MIDI-based Hybrid Song Recommender
  System -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/eess.AS/paper_2.html">
      SeER: An Explainable Deep Learning MIDI-based Hybrid Song Recommender
  System
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      歌の推薦のためのディープラーニングの進歩にもかかわらず、コンテンツに基づくシーケンスモデルを学習することで歌のシーケンシャルな性質を利用したものはありません。この作品では、コラボレーションを使用するハイブリッドディープラーニングモデル「SeER」を提案します。より正確なパーソナライズされた推奨事項を提供するための、推奨事項のための曲のMIDIコンテンツに対するフィルタリング（CF）および深層学習シーケンスモデル。アイテムのコールドスタートの問題を解決します。推奨曲に関連する説明を生成します。予測精度の重要性の他に、説明可能性やコールドスタート問題の解決など、他の重要な側面も重要です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-25">
        <br>2019-06-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CNN-LSTM models for Multi-Speaker Source Separation using Bayesian Hyper
  Parameter Optimization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/eess.AS/paper_3.html">
      CNN-LSTM models for Multi-Speaker Source Separation using Bayesian Hyper
  Parameter Optimization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ネットワークの両方の部分にハイパーパラメータを選択する必要があり、相互に依存する可能性があります。ただし、ハイパーパラメータ空間で新しいポイントをサンプリングする場合、以前に評価したポイントに非常に近いため、追加情報がほとんどありません..この論文では、エンコーダーデコーダーCNNとLSTMを並行して使用するソース分離のための新しいネットワークを提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Application of Word2vec in Phoneme Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/eess.AS/paper_4.html">
      Application of Word2vec in Phoneme Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      トレーニングの最後に、データセットを修正トレーニング用の標準データセットに置き換えます。また、音素認識モデルはword2vecモデルを使用して、パフォーマンスを向上させるために埋め込み行列を初期化します。これにより、音素ベクトル間の距離が長くなります。このモデルでは、TIMITデータセットでPER（音素エラー率）が16.5％の最良の結果を得ることができます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-17">
        <br>2019-12-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: LSTM-TDNN with convolutional front-end for Dialect Identification in the
  2019 Multi-Genre Broadcast Challenge -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/eess.AS/paper_5.html">
      LSTM-TDNN with convolutional front-end for Dialect Identification in the
  2019 Multi-Genre Broadcast Challenge
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、MUSANとRIRデータセットを使用して、通常の方法で既存のトレーニングデータの量と多様性を高める音声増強も調査します。システムは、畳み込みおよび長期短期を使用することにより、従来のDNN xベクトルのパフォーマンスを向上させます特徴抽出のための畳み込みニューラルネットワークフロントエンドの利点と、より長い時間依存性をキャプチャするためのバックエンドリカレントニューラルの利点を組み合わせたMemory-Recurrent（CLSTM）アーキテクチャ。結果は、CLSTMアーキテクチャが従来のDNN x-vector実装。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Continuous Speech Recognition using EEG and Video -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/eess.AS/paper_6.html">
      Continuous Speech Recognition using EEG and Video
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本稿では、脳波（EEG）機能を使用して連続視覚音声認識システムのパフォーマンスを改善できるかどうかを調査します。コネクショニスト時間分類（CTC）ベースのエンドツーエンド自動音声認識（ASR）モデルを実装しました。認識。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-16">
        <br>2019-12-16
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Murine models of renal ischaemia reperfusion injury: An opportunity for refinement using non-invasive monitoring methods -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/biorxiv.physiology/paper_0.html">
      Murine models of renal ischaemia reperfusion injury: An opportunity for refinement using non-invasive monitoring methods
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果：プレクランプ麻酔時間は、R-IRI後のAKI重症度の最も重要な予測因子の1つでした。ここでは、小さなげっ歯類の腎臓機能を非侵襲的に測定する革新的な技術により、R-IRIモデルの改良が成功し、AKIからCKDへの移行を個々の動物で縦方向に監視できるようになった方法について説明します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Vitamin D-binding protein is required for the maintenance of α-cell function and glucagon secretion -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/biorxiv.physiology/paper_1.html">
      Vitamin D-binding protein is required for the maintenance of α-cell function and glucagon secretion
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      したがって、DBPは、糖尿病の病因に影響を与える、細胞表現型の重要な調節因子です。 。ビタミンD結合タンパク質（DBP）またはGCグロブリンは、循環から標的組織にビタミンD代謝産物を運びます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: When does diet matter? The roles of larval and adult nutrition in regulating adult size traits. -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-20/biorxiv.physiology/paper_2.html">
      When does diet matter? The roles of larval and adult nutrition in regulating adult size traits.
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      大人の体重については、豊富な大人の食事は、両方の種類の食事に対する幼虫の栄養不良の悪影響を軽減しました。さらに、我々の研究は、少年の栄養環境が大人の食事への反応にどのように影響するかを理解するための基礎を提供します。 2つの方法：タンパク質を食事の炭水化物含有量に変える（栄養素制限と呼ばれる）こと、および食事のカロリー密度を変えること（カロリー制限と呼ばれる）。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br>2019-12-19
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
