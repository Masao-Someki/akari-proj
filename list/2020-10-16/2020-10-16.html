<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-10-16の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: D3Net: Densely connected multidilated DenseNet for music source
  separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.SD/paper_0.html">
      <font color="black">D3Net: Densely connected multidilated DenseNet for music source
  separation</font>
    </a>
  </h2>
  <font color="black">マルチ拡張畳み込みをDenseNetアーキテクチャと組み合わせることにより、D3Netは、拡張畳み込みをDenseNetに単純に組み込むときに存在するエイリアシングの問題を回避します。音楽ソースの分離には、オーディオ信号の長期依存性をモデル化するための大きな入力フィールドが含まれます。 MUSDB18データセットの実験結果は、D3Netが6.01 dBの平均信号対歪み比（SDR）で最先端のパフォーマンスを達成することを示しています。 
[ABSTRACT]新しい畳み込み畳み込みには、異なる解像度を同時にモデル化するために、単一レイヤーに異なる拡張拡張拡張畳み込み係数を持つ新しいマルチステート畳み込みが含まれます。新しい畳み込み畳み込みは、畳み込み畳み込みへの新しいアプローチです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: A Transformer Based Pitch Sequence Autoencoder with MIDI Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.SD/paper_1.html">
      <font color="black">A Transformer Based Pitch Sequence Autoencoder with MIDI Augmentation</font>
    </a>
  </h2>
  <font color="black">過剰適合を防ぐために、洗練された損失関数が提案され、パラメーターの量が削減されます。さらに、音楽チューンの移調とMIDIシーケンスの切り捨てがデータ拡張に適用されます。この作業は、取得の問題に取り組むための新しいアプローチを提供します。音楽信号分析で一般的であり、より注目に値する小さなデータセットからの機能。 
[要約]メロディーがオートマトンまたはホモサピエンスのどちらによって作成されたかを評価するために、音の欠如が提案されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Lightweight End-to-End Speech Recognition from Raw Audio Data Using
  Sinc-Convolutions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.SD/paper_2.html">
      <font color="black">Lightweight End-to-End Speech Recognition from Raw Audio Data Using
  Sinc-Convolutions</font>
    </a>
  </h2>
  <font color="black">時間領域での％データ拡張..このために、エンドツーエンドASRシステムの低パラメーターの機械学習可能な特徴抽出として、Sinc畳み込みと深さ方向の畳み込みを統合する軽量Sinc畳み込み（LSC）を提案します。結果として得られるエンドツーエンドモデルは、時間領域でSpecAugmentを適用することによってさらに改善される、スムーズな収束動作を示します。 
[概要]私たちのモデルは、tedlium v2テストデータセットで10.7％の単語誤り率を達成します。結果として得られるlog-melフィルターバンク機能を備えたアーキテクチャは絶対1.9％ですが、モデルサイズの21％しかありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Analysis and Influence of Hierarchical Structure on Melody,
  Rhythm and Harmony in Popular Music -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.SD/paper_3.html">
      <font color="black">Automatic Analysis and Influence of Hierarchical Structure on Melody,
  Rhythm and Harmony in Popular Music</font>
    </a>
  </h2>
  <font color="black">階層のレベルが異なれば相互作用も異なり、構造階層が繰り返しや類似性の単純な概念を超えて音楽で重要な役割を果たすという証拠を提供します。フレーズが組み合わさってセクションを形成し、2レベルの階層構造を生み出します。私たちの仕事は音楽生成と音楽の評価。 
[概要]システムシステムシステムは「構造構造」を検出します。研究は音楽生成と音楽評価のための新しいアプリケーションを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: The NeteaseGames System for Voice Conversion Challenge 2020 with
  Vector-quantization Variational Autoencoder and WaveNet -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.SD/paper_4.html">
      <font color="black">The NeteaseGames System for Voice Conversion Challenge 2020 with
  Vector-quantization Variational Autoencoder and WaveNet</font>
    </a>
  </h2>
  <font color="black">ただし、システムは言語内音声変換タスクにのみ提出します。さらに、システムはいくつかの客観的評価で良好に機能します。具体的には、システムは自動自然性予測で平均3.95の自然性スコアを達成し、6位にランクされました。 ASVベースのスピーカーの類似性となりすまし対策でそれぞれ8位。 
[ABSTRACT] vq --vae --wavenetは、非並列音声変換です。話者のアイデンティティで言語形式を分離するとともに、音響機能を再構築します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Music Classification in MIDI Format based on LSTM Mdel -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.SD/paper_5.html">
      <font color="black">Music Classification in MIDI Format based on LSTM Mdel</font>
    </a>
  </h2>
  <font color="black">10分割交差検証によって評価された結果の精度は90％に達する可能性があります。私たちの仕事は、AIによって生成された音楽と人間の作曲家が異なる特性を持っていることを示しています。これは、深層学習ネットワークによって学習できます。 AIまたは人間の作曲家は、ディープラーニングネットワークによって実行できます。 
[ABSTRACT] aiと人間の作曲家は異なる特性を持っており、ディープラーニングネットワークで学習できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Muse: Multi-modal target speaker extraction with visual cues -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.SD/paper_6.html">
      <font color="black">Muse: Multi-modal target speaker extraction with visual cues</font>
    </a>
  </h2>
  <font color="black">音声と唇の動きの時間的同期が有用な手がかりであり、ターゲットスピーカーの埋め込みも同様に重要であると考えています。ターゲットスピーカーの唇の画像シーケンスのみを条件とするMuSEという名前のマルチモーダルスピーカー抽出ネットワークを提案します。抽出..参照音声は通常、話者の埋め込みとして事前登録されています。 
[ABSTRACT] museは、ターゲットスピーカーの埋め込みを抽出するための参照として視覚的な手がかりを使用します。museは、si-sdrおよびpesqに関してav-convtasnetベースラインよりも向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Dance Revolution: Long-Term Dance Generation with Music via Curriculum
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.SD/paper_7.html">
      <font color="black">Dance Revolution: Long-Term Dance Generation with Music via Curriculum
  Learning</font>
    </a>
  </h2>
  <font color="black">この論文では、音楽主導のダンス生成をシーケンス間の学習問題として形式化し、新しいseq2seqアーキテクチャを考案して、音楽機能の長いシーケンスを効率的に処理し、音楽とダンスの間のきめ細かい対応をキャプチャします。この問題ロングモーションシーケンス生成ではさらに厳しくなる。さらに、ロングモーションシーケンス生成における自己回帰モデルのエラー蓄積を軽減するカリキュラム学習戦略を提案する。これは、以前の完全ガイド付き教師強制スキームからトレーニングプロセスを穏やかに変更する。代わりに生成された動きを主に使用する、ガイドの少ない自動回帰スキームに向けたグラウンドトゥルースの動き。 
[ABSTRACT]ダンスと音楽は機械学習アーキテクチャの問題です。ただし、これはニューラルネットワークにフィードバックされる予測エラーが豊富なためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br><font color="black">2020-06-11</font>
      </time>
    </span>
</section>
<!-- paper0: Dataset artefacts in anti-spoofing systems: a case study on the ASVspoof
  2017 benchmark -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.SD/paper_8.html">
      <font color="black">Dataset artefacts in anti-spoofing systems: a case study on the ASVspoof
  2017 benchmark</font>
    </a>
  </h2>
  <font color="black">最後に、このデータセットの新しいベースラインとして機能するフレームレベルモデルと発話レベルモデルの両方について、いくつかの新しいベンチマーク結果を提供します。第3に、このデータセットの信頼性が高く堅牢なパフォーマンス推定のために、非音声セグメントと無音の前後の破棄を提案します。トレーニングおよび推論中の発話..次に、対策モデルがこれらのアーティファクトを利用して、このデータセットで成功したように見える方法を示します。 
[概要]リプレイディスクーフィング攻撃に焦点を当てたイベント。参加者は、提供されたデータセットでシステムを構築およびトレーニングしました。この記事では、データセットに固有のアーティファクトが、公開されたシステムの明らかな成功にどのように貢献しているかを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Melody Classification based on Performance Event Vector and BRNN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.SD/paper_9.html">
      <font color="black">Melody Classification based on Performance Event Vector and BRNN</font>
    </a>
  </h2>
  <font color="black">また、いくつかのハイパーパラメータの影響について説明し、評価データセットの複数の予測出力を作成しました。モデルは、開発データセットとWikifoniaデータセットで満足のいくパフォーマンスを達成しました。メロディ分類のCSMT2020データチャレンジのモデルを提案しました。 
[概要]私たちのモデルは、分類のための双方向rnnネットワークを構築しました。また、いくつかのハイパーパラメーターの効果についても説明しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Convolutional Neural Network-based Inverse Filtering Approach for
  Speech De-reverberation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.SD/paper_10.html">
      <font color="black">Deep Convolutional Neural Network-based Inverse Filtering Approach for
  Speech De-reverberation</font>
    </a>
  </h2>
  <font color="black">CNN構造のさまざまな選択肢の中で、スキップ接続を備えた完全畳み込みオートエンコーダネットワークで構成されるU-netを検討します。実験結果は、提案された方法が、以下の一般的なベンチマークアルゴリズムよりも優れた残響除去性能を提供することを示しています。さまざまな残響条件..この目的のために、残響音声信号の畳み込み伝達関数（CTF）モデルを検討します。 
[ABSTRACT]プロジェクトは、現実的な残響条件をより適切に処理することを目的としています。部屋のインパルス応答（rir）フィルターはctf分析ウィンドウよりも長くなります。提案された方法はより良い残響除去を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: CS2-Net: Deep Learning Segmentation of Curvilinear Structures in Medical
  Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.IV/paper_0.html">
      <font color="black">CS2-Net: Deep Learning Segmentation of Curvilinear Structures in Medical
  Imaging</font>
    </a>
  </h2>
  <font color="black">.... 2種類の注意モジュール（空間的注意とチャネル注意）を利用して、クラス間識別とクラス内応答性を強化し、ローカル機能をグローバルな依存関係と正規化に適応的に統合します。心血管、腎臓、目、肺、および神経学的状態。 
[概要]これらの曲線器官構造は米国で開発されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: AI-based BMI Inference from Facial Images: An Application to Weight
  Monitoring -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.IV/paper_1.html">
      <font color="black">AI-based BMI Inference from Facial Images: An Application to Weight
  Monitoring</font>
    </a>
  </h2>
  <font color="black">健康的な体重モニタリングのための自己診断画像ベースの方法は、肥満の憂慮すべき傾向に続いてますます関心を集めています。ソーシャルメディアから集められた3つの公的に利用可能なBMI注釈付き顔画像データセット、すなわちVisualBMI、VIP-Attributes、およびBollywoodの実験結果データセットは、ResNet50を使用して取得した最小平均絶対誤差（MAE）が$ 1.04 $の顔画像からのBMI推論における深層学習法の有効性を示唆しています。この分野でのさらなる研究開発を促進するために、5つのパフォーマンスを評価および比較します。さまざまなディープラーニングベースのConvolutionalNeural Network（CNN）アーキテクチャ、つまり、顔画像からのBMI推論のためのVGG19、ResNet50、DenseNet、MobileNet、およびlightCNN。 
[概要]顔画像からのボディマス指数（bmi）の結論のためのaiベースの方法を調査する学術研究はほんの一握りしか存在しません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: AMPA-Net: Optimization-Inspired Attention Neural Network for Deep
  Compressed Sensing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.IV/paper_2.html">
      <font color="black">AMPA-Net: Optimization-Inspired Attention Neural Network for Deep
  Compressed Sensing</font>
    </a>
  </h2>
  <font color="black">圧縮センシング（CS）は、限られた測定からほぼ完全な画像を再構成するため、画像処理における困難な問題です。さらに、AMP-Netの表現能力を向上させるために3つの注意ネットワークを使用するAMPA-Netを提案します。AMP -Netは、近似メッセージパッシング（AMP）アルゴリズムとニューラルネットワークの融合を実現します。 
[概要] amp-netとampa-netは4つのcs再構築ベンチマークデータセットにあります。システムはamp-ニューヨークベースのシステムによって開発されました。これを使用して、初めて新しいシステムを作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Spatial Registration Evaluation of [18F]-MK6240 PET -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.IV/paper_3.html">
      <font color="black">Spatial Registration Evaluation of [18F]-MK6240 PET</font>
    </a>
  </h2>
  <font color="black">次に、これらの各被験者のPET画像と、30の「テンプレートナイーブ」被験者のホールドアウトセットを、3つの異なる登録パラメーターと手順のセットを使用して、テンプレート画像を中間として使用して、対応するMRI画像に登録しました。一部の分子PET放射性リガンドの場合のように、画像の形状や信号強度に大きな違いがある場合は、困難な場合があります。この場合、対照被験者は頭蓋内領域内のノイズに比べて信号が比較的不足しており、ターゲット外の結合がある可能性があります。他の地域と混同され、主題によって異なる場合があります。テンプレートベースの方法は、直接登録およびMRなしの定量化の実行可能な代替手段または救済策であると結論付けます。そして、2つの画像モダリティ間の類似性に疑問がある場合に好まれるかもしれません。 
[概要] 30人のアミロイド被験者の幅広い分布から母集団固有のMRIおよびペットテンプレートを作成しました。従来の登録は既存のctベースの標準に匹敵し、テストしたすべての方法でエラーに有意差はありませんでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Design of Spatial-Spectral Filters for CT Material Decomposition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.IV/paper_4.html">
      <font color="black">Design of Spatial-Spectral Filters for CT Material Decomposition</font>
    </a>
  </h2>
  <font color="black">考えられるさまざまなSSF設計を評価するために、2つ以上の材料からの信号を区別するスペクトルCTシステムの能力を特徴付ける分離可能性インデックスと呼ばれる新しいフィッシャー情報ベースの予測画質メトリックを定義します。各スペクトルチャネルでまばらな投影データ。この予測メトリックは、システム設計最適化フレームワークを定義するために使用されます。 
[概要]新しいデバイスは、空間ミアフィルター（ssf）と呼ばれます。これは、X線源の近くに配置されたフィルター材料のタイル配列で構成されます。X線ビームの保護形状を変調するために使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Encoder-decoder semantic segmentation models for electroluminescence
  images of thin-film photovoltaic modules -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.IV/paper_5.html">
      <font color="black">Encoder-decoder semantic segmentation models for electroluminescence
  images of thin-film photovoltaic modules</font>
    </a>
  </h2>
  <font color="black">結晶シリコンモジュール）..エンコーダ-デコーダディープニューラルネットワークアーキテクチャを利用します..さらに、6000枚の画像のフルセットに最適なモデルを適用し、EL画像の自動セグメンテーションが推測できない多くの微妙な特徴を明らかにできることを示します画像の小さなサンプルを研究することから。 
[概要]ネットワークは、銅インジウムガリウムガリウムジセレニド（cigs）薄膜モジュールの6000 el画像を含むデータベースからの画像のサンプルでトレーニングおよびテストされています。これらの機能は、品質管理に拡張できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Point Cloud Rendering after Coding: Impacts on Subjective and Objective
  Quality -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.IV/paper_6.html">
      <font color="black">Point Cloud Rendering after Coding: Impacts on Subjective and Objective
  Quality</font>
    </a>
  </h2>
  <font color="black">このようなシナリオでは、点群通信システムにおけるいくつかの処理ステップの影響とパフォーマンス、特に点群コーディングソリューションに関連する品質の低下を評価することが重要です。このコンテキストでは、このペーパーの主な目的は研究することです。知覚されるユーザー品質および利用可能な客観的品質評価メトリックのパフォーマンスに対するいくつかのコーディングおよびレンダリングソリューションの影響。最近、点群は、さまざまな没入型アプリケーションの3Dビジュアルデータを表す有望な方法であることが示されています。自律走行車への拡張現実。 
[概要]点群データの知覚品質は、レンダリングソリューションに大きく依存します。主な点群評価は、最近のmpeg点群ソリューションの評価です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br><font color="black">2019-12-19</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Images through Stega Glasses -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.IV/paper_7.html">
      <font color="black">Adversarial Images through Stega Glasses</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、ステガノグラフィと敵対的な画像の関係について説明します。この猫とマウスのゲームを最先端の分類器、ステガナライザー、ステガノグラフィ埋め込みスキームでプレイします。ステガノグラフィは防御側よりも攻撃側に役立つことがわかりました。 
[ABSTRACT] ste-敵対的な敵対的な敵対者は、敵対的な摂動を見つけるのに役立ちます。stealysisは、敵対者を検出するのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Interactive Latent Interpolation on MNIST Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.IV/paper_8.html">
      <font color="black">Interactive Latent Interpolation on MNIST Dataset</font>
    </a>
  </h2>
  <font color="black">次に、ブラウザでの生成速度を.2ミリ秒に短縮する次元削減を引き続き活用する新しいWebベースのGANを提案しました。最後に、線形補間を使用して最新のUIを作成し、作業を提示しました。高速生成により、非常に高速に生成できるため、これまでに見たことのないアニメーションタイプのエフェクトを作成できます。これはWebとモバイルの両方で機能します。 
[概要]新しいWebベースのガンは、技術的な削減を利用して、ブラウザでの生成をに高速化します。 2ミリ秒。高速生成により、これまでに見たことのないアニメーションタイプのエフェクトを作成できるほど高速に生成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Relighting Networks for Image Light Source Manipulation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.IV/paper_9.html">
      <font color="black">Deep Relighting Networks for Image Light Source Manipulation</font>
    </a>
  </h2>
  <font color="black">具体的には、提案されたDRNは、2020ECCV会議の「AIM2020-Anyto one relighting Challenge」で最高のPSNRを達成しました。この論文では、単一画像の再照明タスクを定式化し、新しいDeep Relighting Network（DRN）を提案します。 3つの部分：1）深い自動エンコーダネットワークを介して主要なシーン構造を明らかにすることを目的としたシーンの再変換、2）敵対的な学習を通じて新しい光の方向からの光の効果を予測するための影の事前推定、3）再レンダリング、一次構造を再構成されたシャドウビューと組み合わせて、ターゲット光源の下で必要な推定を形成します。実験結果は、提案された方法が定性的および定量的に他の可能な方法よりも優れていることを示しています。 
[ABSTRACT]新しい方法は、より多くの情報を必要とする既存の方法を使用します。これらには、シーンの詳細な詳細画像が含まれますが、利用できない場合があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Muse: Multi-modal target speaker extraction with visual cues -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.IV/paper_10.html">
      <font color="black">Muse: Multi-modal target speaker extraction with visual cues</font>
    </a>
  </h2>
  <font color="black">ターゲットスピーカー抽出のための唇の画像シーケンスのみを条件とするMuSEという名前のマルチモーダルスピーカー抽出ネットワークを提案します。スピーカー抽出アルゴリズムは、参照音声に依存して、ターゲットスピーカーに注意を集中します。この信念に動機付けられています。 、事前登録された参照音声を必要とせずに、ターゲットスピーカーの埋め込みを抽出するための参照として視覚的な手がかりを使用する新しい手法を研究します。 
[ABSTRACT] museは、ターゲットスピーカーの埋め込みを抽出するための参照として視覚的な手がかりを使用します。museは、si-sdrおよびpesqに関してav-convtasnetベースラインよりも向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Image Reconstruction with Misaligned Structural Information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.IV/paper_11.html">
      <font color="black">Robust Image Reconstruction with Misaligned Structural Information</font>
    </a>
  </h2>
  <font color="black">再構成と登録を共同で実行し、それによってこのハードルを克服する変分フレームワークを提案します。マルチモダリティ（またはマルチチャネル）イメージングはますます重要になり、より広く利用できるようになっています。多くの場合、変分正則化として定式化されている最先端の方法は、定量的および定性的に画像再構成を大幅に改善することが示されています。 
[概要]ハイパースペクトルイメージング、ハイパースペクトルイメージング、マルチ直腸イメージングに加えて、メディックはモダリティを大幅に改善することが示されています。ハイパースペクトルイメージングは、メディックやメディックを含む複数の地域で見られます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-01">
        <br><font color="black">2020-04-01</font>
      </time>
    </span>
</section>
<!-- paper0: Combining Spectral CT Acquisition Methods for High-Sensitivity Material
  Decomposition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.IV/paper_12.html">
      <font color="black">Combining Spectral CT Acquisition Methods for High-Sensitivity Material
  Decomposition</font>
    </a>
  </h2>
  <font color="black">モデルベースの材料分解を、ヨウ素濃度が0.1〜5.0 mg / mLの水-ヨウ素ファントムに適用します。スペクトル手法のさまざまな組み合わせのバイアスノイズプロットを示し、組み合わせたアプローチによってスペクトル感度の多様性が可能になり、改善されることを示します。個別に適用される戦略と比較して低濃度のイメージング性能。このさまざまな感度を可能にするスペクトルCTテクノロジーには、ソースkVスイッチング、2層検出器、およびソース側フィルタリング（タイル化された空間スペクトルフィルターなど）が含まれます。 
[概要]イメージングシステムの感度を変調するためのいくつかのアプローチがあります。これには、高度な物理モデルを使用してこれら3つの赤外線ct戦略をシミュレートすることが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: LiteDepthwiseNet: An Extreme Lightweight Network for Hyperspectral Image
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.IV/paper_13.html">
      <font color="black">LiteDepthwiseNet: An Extreme Lightweight Network for Hyperspectral Image
  Classification</font>
    </a>
  </h2>
  <font color="black">3つのベンチマークハイパースペクトルデータセットでの実験結果は、LiteDepthwiseNetが非常に少数のパラメーターと低い計算コストで最先端のパフォーマンスを達成することを示しています。さらに、元の3D深度方向コンボリューションのReLUレイヤーとバッチ正規化レイヤーを削除します。これにより、小さなサイズのデータセットでのモデルの過適合現象が大幅に改善されます。さらに、焦点損失は、困難なサンプルや不均衡なデータに対するモデルの注意を改善するための損失関数として使用され、そのトレーニングパフォーマンスはクロスよりも大幅に優れています。エントロピー損失またはバランスの取れたクロスエントロピー損失。 
[ABSTRACT]深層学習法は、高い分類パフォーマンスを実現できます。これらには、深さ方向の畳み込み、深さ方向の畳み込み、点ごとの畳み込みが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: XPDNet for MRI Reconstruction: an Application to the fastMRI 2020 Brain
  Challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.IV/paper_14.html">
      <font color="black">XPDNet for MRI Reconstruction: an Application to the fastMRI 2020 Brain
  Challenge</font>
    </a>
  </h2>
  <font color="black">また、MRI再構成のためのディープラーニングに固有の最先端技術を採用しています。モジュール式クロスドメインニューラルネットワークXPDNetとそのMRI再構成タスクへの応用を紹介します。このアプローチは、PDHGアルゴリズムを次のように展開することにあります。ステップ間の加速スキームを学習するだけでなく。 
[概要]このアプローチは、システムを展開し、ステップ間の加速スキームを学習することで構成されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: RetiNerveNet: Using Recursive Deep Learning to Estimate Pointwise 24-2
  Visual Field Data based on Retinal Structure -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.IV/paper_15.html">
      <font color="black">RetiNerveNet: Using Recursive Deep Learning to Estimate Pointwise 24-2
  Visual Field Data based on Retinal Structure</font>
    </a>
  </h2>
  <font color="black">緑内障は、世界で不可逆的な失明の主な原因であり、7000万人以上に影響を及ぼしています。RetiNerveNetは、視神経乳頭周囲の網膜神経線維層（RNFL）の厚さから始めて、網膜神経線維の弧状の収束を追跡しようとします。個々の年齢補正された24-2SAP値を推定する。提案されたネットワークは、いくつかのベースラインと比較して、個々の視野値のより正確な推定値を取得でき、SAPのプロキシとしての有用性を示唆しています。 
[概要]このテストは、視覚障害を検出するために最も頻繁に使用されます。緑内障のため、より客観的な赤外線ドメイン光コヒーレンストモグラフィー（sdoct）からの情報を使用します。retinervenetは樹液の平均偏差を正確に予測できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Optimized Spatial-Spectral CT for Multi-Material Decomposition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.IV/paper_16.html">
      <font color="black">Optimized Spatial-Spectral CT for Multi-Material Decomposition</font>
    </a>
  </h2>
  <font color="black">フィルタタイルの次数の結果はほとんど変化を示さず、フィルタの次数が優先度の低い設計上の考慮事項であることを示しています。ただし、個々のチャネルは投影領域ではまばらです。現実的なCTジオメトリとノイズモデルを使用して各設計パラメータの影響を特徴付ける数値シミュレーションの結果を示し、実現可能性を示します。 
[ABSTRACT]モデル-ベースの反復再構成法はフィルターに対応できます。システムは最小限のデータを使用し、モデルベースのモデルの分析を使用します。システムを使用して、システムと呼ばれる新しいモデルを開発できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Attention-Network for Semantic Segmentation of High-Resolution
  Remote Sensing Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.IV/paper_17.html">
      <font color="black">Multi-Attention-Network for Semantic Segmentation of High-Resolution
  Remote Sensing Images</font>
    </a>
  </h2>
  <font color="black">線形の複雑さを備えたカーネル注意と呼ばれる新しい注意メカニズムが、注意の高い計算要求を軽減するために提案されています。リモートセンシング画像のセマンティックセグメンテーションは、土地資源管理、収量推定、および経済的評価において重要な役割を果たします。 -製品アテンションメカニズムが導入され、セマンティックセグメンテーションで広く利用されて、長距離の依存関係をモデル化しました。アテンションの時間と空間の複雑さが高いため、入力が多いアプリケーションシナリオでのアテンションの使用が妨げられます。 
[ABSTRACT]たとえば、ニューラルネットワークによって多くの情報が悪用されていますが、標準モデルにはまだいくつかの制限があります。たとえば、これらの欠点を改善するために、マルチアテンションネットワーク（manet）を提案しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Differential diagnosis and molecular stratification of gastrointestinal
  stromal tumors on CT images using a radiomics approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.IV/paper_18.html">
      <font color="black">Differential diagnosis and molecular stratification of gastrointestinal
  stromal tumors on CT images using a radiomics approach</font>
    </a>
  </h2>
  <font color="black">放射線モデルのAUCはc-KITで0.52、c-KITエクソン11で0.56、MIで0.52でした。画像、年齢、性別、場所を含むGIST対非GIST放射線モデルの平均は曲線下面積（AUC）は0.82です。3人の放射線科医のAUCはそれぞれ0.69、0.76、0.84でした。 
[ABSTRACT]ラジオミクスは、要旨を他の腹腔内腫瘍と区別するためにラジオミクスを評価することでした。それらは、要旨、pdgfra、braf変異状態、および有糸分裂指数（mi）を予測します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Across Scales & Across Dimensions: Temporal Super-Resolution using Deep
  Internal Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_0.html">
      <font color="black">Across Scales & Across Dimensions: Temporal Super-Resolution using Deep
  Internal Learning</font>
    </a>
  </h2>
  <font color="black">低フレームレートの入力ビデオから直接抽出された例でビデオ固有のCNNをトレーニングします。これにより、複雑なビデオのゼロショット時間SRが発生し、モーションブラーとモーションエイリアシングの両方が除去され、外部ビデオでトレーニングされた以前の監視方法を上回ります。データセット..また、入力ビデオの時間的ナイキスト制限を超える新しい高い時間的周波数を回復できるため、時間的フレーム補間（おそらく高度なもの）では元に戻せないモーションブラー効果とモーションエイリアシング効果の両方を解決できます。 
[ABSTRACT]真の時間的超解像（tsr）は、単なる時間的補間（フレームレートの増加）以上のものです。新しい方法では、単一のビデオシーケンス内で小さな空間の時間パッチが強く繰り返されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-19">
        <br><font color="black">2020-03-19</font>
      </time>
    </span>
</section>
<!-- paper0: MOTChallenge: A Benchmark for Single-camera Multiple Target Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_1.html">
      <font color="black">MOTChallenge: A Benchmark for Single-camera Multiple Target Tracking</font>
    </a>
  </h2>
  <font color="black">最後に、最先端のトラッカーの分類と広範なエラー分析を提供します。2014年後半に開始された単一カメラのMultiple Object Tracking（MOT）のベンチマークであるMOTChallengeを紹介し、既存および新規のデータを収集します。複数のオブジェクト追跡方法の標準化された評価のためのフレームワークを作成します。2番目と3番目のリリースでは、ラベル付きボックスの数が大幅に増加するだけでなく、歩行者以外の複数のオブジェクトクラスのラベルと、の可視性のレベルも提供されます。関心のあるすべてのオブジェクト。 
[概要]ベンチマークは、歩行者がmotコミュニティで最も研究されているオブジェクトであるため、複数の人の追跡に焦点を当てています。ラベル付きボックスの数が大幅に増加するだけでなく、歩行者以外の複数のオブジェクトクラスのラベルも提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: CS2-Net: Deep Learning Segmentation of Curvilinear Structures in Medical
  Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_2.html">
      <font color="black">CS2-Net: Deep Learning Segmentation of Curvilinear Structures in Medical
  Imaging</font>
    </a>
  </h2>
  <font color="black">医療および生物医学画像からの血管や神経線維などの曲線構造の自動検出は、多くの疾患の管理に関連する自動画像解釈の重要な初期段階です。新しい曲線構造セグメンテーションネットワーク（CS2-Net）を導入します。 、これには、曲線構造の豊富な階層表現を学習するためのエンコーダーとデコーダーの自己注意メカニズムが含まれています。心臓血管、腎臓、目、肺、および神経の状態。 
[概要]これらの曲線器官構造は米国で開発されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-Supervised Semantic Segmentation in Earth Observation: The
  MiniFrance Suite, Dataset Analysis and Multi-task Network Study -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_3.html">
      <font color="black">Semi-Supervised Semantic Segmentation in Earth Observation: The
  MiniFrance Suite, Dataset Analysis and Multi-task Network Study</font>
    </a>
  </h2>
  <font color="black">それにもかかわらず、MiniFranceの最も特徴的な品質は、半教師あり学習用に特別に設計されたこの分野で唯一のデータセットです。トレーニングパーティションにラベル付きおよびラベルなしの画像が含まれ、リアルなシナリオを再現します。MiniFranceには、前例のないプロパティがいくつかあります。それは大規模であり、2000を超える非常に高解像度の航空画像を含み、2,000億を超えるサンプル（ピクセル）を占めています。それは多様で、フランスの16の大都市圏をカバーし、さまざまな気候、さまざまな風景、都市と田舎のシーンがあります。高レベルのセマンティクスを備えた土地利用クラスを考慮すると、困難です。MiniFranceスイートである地球観測における半教師ありセマンティックセグメンテーションのための新しい大規模データセットを紹介します。 
[ABSTRACT]ミニフランスは大規模で、2000を超える非常に高解像度の航空画像を含み、2,000億を超えるサンプル（ピクセル）を占めています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed
  Gradients -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_4.html">
      <font color="black">AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed
  Gradients</font>
    </a>
  </h2>
  <font color="black">AdaBeliefの直感は、現在の勾配方向の「信念」に従ってステップサイズを適応させることです。ノイズの多い勾配の指数移動平均（EMA）を、観測された勾配の場合、次のタイムステップでの勾配の予測として表示します。予測から大きく外れているため、現在の観察結果を信用せず、小さな一歩を踏み出します。観測された勾配が予測に近い場合、それを信頼し、大きな一歩を踏み出します。さらに、Cifar10でのGANのトレーニングでは、AdaBeliefは、適切に調整されたAdamオプティマイザーと比較して、高い安定性を示し、生成されたサンプルの品質を向上させます。 。 
[ABSTRACT] adabeliefのadabeliefは、適応方法のような高速実装、sgdのような優れた一般化、トレーニングの安定性という3つの目標を達成できます。adabeliefもadabeliefと同じ精度を達成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Approximate Manifold Defense Against Multiple Adversarial Perturbations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_5.html">
      <font color="black">Approximate Manifold Defense Against Multiple Adversarial Perturbations</font>
    </a>
  </h2>
  <font color="black">さらに、トレーニングのために提案された再構築プロセスを組み込むと、RBF-CNNモデルの敵対的ロバスト性が向上します。RBF-CNNは、マイナーな敵対的摂動を軽減する再構築レイヤーも利用します。ただし、このアプローチの成功は、生成ネットワークかどうかに依存します。完全なクリーンデータ多様体をキャプチャできますが、これは複雑な入力ドメインの未解決の問題のままです。 
[概要]このアプローチにより、複数の摂動タイプに対するロバスト性を実現しながら、高価な敵対的な例を生成する必要がなくなります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-05">
        <br><font color="black">2020-04-05</font>
      </time>
    </span>
</section>
<!-- paper0: Boosting Image-based Mutual Gaze Detection using Pseudo 3D Gaze -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_6.html">
      <font color="black">Boosting Image-based Mutual Gaze Detection using Pseudo 3D Gaze</font>
    </a>
  </h2>
  <font color="black">3つの画像データセットの実験結果は、提案されたアプローチが追加の注釈なしで検出パフォーマンスを大幅に改善することを示しています。この作業は、29.2Kの画像で相互注視ラベルで注釈が付けられた33.1Kの人間のペアで構成される新しい画像データセットも導入します。相互注視ラベルから推定される疑似3D注視ラベルを使用して3D注視推定ブランチをトレーニングすることにより、追加のラベリングコストなしでパフォーマンスが向上します。 
[概要]この作業では、相互視線検出のタスクに焦点を当てます。トレーニング中に補助的な3D視線推定タスクを使用して、パフォーマンスを向上させるためのシンプルで効果的なアプローチを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Generalizing Universal Adversarial Attacks Beyond Additive Perturbations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_7.html">
      <font color="black">Generalizing Universal Adversarial Attacks Beyond Additive Perturbations</font>
    </a>
  </h2>
  <font color="black">GoogleLeNet、VGG16 / 19、ResNet101 / 152、DenseNet121を含む6つのディープニューラルネットワークモデルを使用して、CIFAR-10およびImageNetデータセットで広範な実験が行われます。ただし、普遍的な敵対的攻撃の現在の方法は、加法摂動に基づいており、次の場合に誤分類が発生します。摂動は入力画像に直接追加されます。さらに重要なことに、加法摂動と非加法摂動の両方を統合するために、GUAPと呼ばれる普遍的な敵対攻撃のための新しい統一された柔軟なフレームワークを提案します。これは加法摂動によって攻撃を開始できます。非加法摂動、または両方の組み合わせ。 
[ABSTRACT]普遍的な敵対的攻撃の現在の方法は、加法摂動に基づいています。これらは、摂動が画像に直接追加されると誤分類を引き起こします。guapは、ウェズリー摂動または両方の組み合わせによって攻撃を開始できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: THIN: THrowable Information Networks and Application for Facial
  Expression Recognition In The Wild -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_8.html">
      <font color="black">THIN: THrowable Information Networks and Application for Facial
  Expression Recognition In The Wild</font>
    </a>
  </h2>
  <font color="black">適応型の弱い予測子の重み付けを学習する差分ツリーゲートを採用しているため、弱い予測子が専門とする外因性表現空間のパーティションをモデル化します。顔の表情）。によって条件付けられた深いアンサンブルを使用する予測レイヤーを設計します。外因性の表現。 
[概要]このような外因性変数の例は、表情認識（fer）を考慮した場合のアイデンティティです。予測するような深いアンサンブルを使用する予測レイヤーを設計します。このレイヤーは、見ることができる外因性変数間の依存関係を明示的に予測します。 。それはまた、外因性の情報がスロー可能な方法で2回使用されることを予測します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: AI-based BMI Inference from Facial Images: An Application to Weight
  Monitoring -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_9.html">
      <font color="black">AI-based BMI Inference from Facial Images: An Application to Weight
  Monitoring</font>
    </a>
  </h2>
  <font color="black">ソーシャルメディアから集められた3つの公的に利用可能なBMI注釈付き顔画像データセット、すなわちVisualBMI、VIP属性、およびボリウッドデータセットに関する実験結果は、最小平均絶対誤差（MAE）の顔画像からのBMI推論における深層学習法の有効性を示唆しています。 ）ResNet50を使用して得られた$ 1.04 $ ..この分野でのさらなる研究開発を促進するために、5つの異なるディープラーニングベースのConvolutional Neural Network（CNN）アーキテクチャ、つまりVGG19、ResNet50、DenseNet、MobileNet、および顔画像からのBMI推論のためのlightCNN ..健康的な体重モニタリングのための自己診断画像ベースの方法は、肥満の憂慮すべき傾向に続いてますます関心を集めています。 
[概要]顔画像からのボディマス指数（bmi）の結論のためのaiベースの方法を調査する学術研究はほんの一握りしか存在しません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: AMPA-Net: Optimization-Inspired Attention Neural Network for Deep
  Compressed Sensing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_10.html">
      <font color="black">AMPA-Net: Optimization-Inspired Attention Neural Network for Deep
  Compressed Sensing</font>
    </a>
  </h2>
  <font color="black">AMP-Netは、近似メッセージパッシング（AMP）アルゴリズムとニューラルネットワークの融合を実現します。すべてのパラメータは自動的に学習されます。さらに、3つの注意ネットワークを使用してAMP-の表現能力を向上させるAMPA-Netを提案します。ネット。 
[概要] amp-netとampa-netは4つのcs再構築ベンチマークデータセットにあります。システムはamp-ニューヨークベースのシステムによって開発されました。これを使用して、初めて新しいシステムを作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Knowledge Graph Transfer Network for Few-Shot Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_11.html">
      <font color="black">Knowledge Graph Transfer Network for Few-Shot Recognition</font>
    </a>
  </h2>
  <font color="black">ImageNetデータセットでの広範な実験は、現在の主要な競合他社と比較して大幅なパフォーマンスの向上を示しています。具体的には、対応するカテゴリの分類子の重みで各ノードを初期化することにより、ノードの相互作用を調査するためにグラフを介してノードメッセージを適応的に伝播する伝播メカニズムが学習されます。基本カテゴリの分類器情報を新規カテゴリの分類器情報に転送します。さらに、より大規模なカテゴリ、つまり6,000カテゴリをカバーするImageNet-6Kデータセットを構築し、このデータセットでの実験により、提案されたモデルの有効性がさらに実証されます。 
[概要]新しいカテゴリは、オブジェクトの色、テクスチャ、形状、または背景コンテキストによって支配される傾向があります。したがって、異なるカテゴリ間の意味相関を組み込むことを学ぶことで、この情報転送を効果的に正規化できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br><font color="black">2019-11-21</font>
      </time>
    </span>
</section>
<!-- paper0: DynaSLAM II: Tightly-Coupled Multi-Object Tracking and SLAM -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_12.html">
      <font color="black">DynaSLAM II: Tightly-Coupled Multi-Object Tracking and SLAM</font>
    </a>
  </h2>
  <font color="black">オブジェクトの3D境界ボックスも推定され、固定された時間ウィンドウ内で大まかに最適化されます。DynaSLAMIIは、インスタンスのセマンティックセグメンテーションとORB機能を利用して、動的オブジェクトを追跡します。静的シーンと動的オブジェクトの構造は次のとおりです。新しいバンドル調整提案内で、カメラと移動エージェントの両方の軌道と共同で最適化されます。 
[ABSTRACT] dynaslam ii、ステレオおよびrgb --d構成用のビジュアルスラムシステムは、マルチオブジェクトトラッキング機能を緊密に統合します。静的シーンと動的オブジェクトの構造は、カメラと移動の両方の軌道と共同で最適化されます。エージェント</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Learning of Visual Features by Contrasting Cluster
  Assignments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_13.html">
      <font color="black">Unsupervised Learning of Visual Features by Contrasting Cluster
  Assignments</font>
    </a>
  </h2>
  <font color="black">以前の対照的な方法と比較して、私たちの方法は、大きなメモリバンクや特別な勢いのネットワークを必要としないため、メモリ効率が高くなります。私たちの方法は、大小のバッチでトレーニングでき、無制限の量のデータに拡張できます。検証します。 ResNet-50を使用したImageNetで75.3％のトップ1の精度を達成し、検討されているすべての転送タスクで監視された事前トレーニングを上回ったことによる調査結果。 
[概要]これらの対照的な方法は通常オンラインで機能し、多数の明示的なペアワイズ特徴比較に依存します。この方法は、対照的な学習のように特徴を直接比較するのではなく、クラスター割り当て間の一貫性を強化しながら、データを同時にクラスター化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br><font color="black">2020-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: NeRF++: Analyzing and Improving Neural Radiance Fields -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_14.html">
      <font color="black">NeRF++: Analyzing and Improving Neural Radiance Fields</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、この困難なシナリオでのビュー合成の忠実度を向上させます。このテクニカルレポートでは、最初に放射輝度フィールドとその潜在的なあいまいさ、つまり形状放射輝度のあいまいさについて説明し、そのようなあいまいさを回避するNeRFの成功を分析します。コードはhttpsで入手できます。 ：//github.com/Kai-46/nerfplusplus。 
[ABSTRACT] nerfは、ビュー（オードの不透明度とビューに依存するカラーボリューム）を表す多層パーセプトロン（mlps）をトレーニング画像のセットに適合させ、ボリュームレンダリング手法に基づいて新規性をサンプリングします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Respecting Domain Relations: Hypothesis Invariance for Domain
  Generalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_15.html">
      <font color="black">Respecting Domain Relations: Hypothesis Invariance for Domain
  Generalization</font>
    </a>
  </h2>
  <font color="black">いわゆる仮説不変表現（HIR）を学習することを提案します。これは、表現を整列させるのではなく、事後確率を整列させるだけで不変性の仮定を緩和します。入力分布..ドメインの一般化では、複数のラベルが付けられた非独立で非同一に分散されたソースドメインはトレーニング中に利用できますが、ターゲットドメインのデータもラベルも利用できません。 
[ABSTRACT]いわゆるドメインユニバーサルドメイン（dirs）の学習は、ドメイン一般化への一般的なアプローチです。ただし、これは、ターゲットドメインへの適切な一般化には必要ありません。パブリックドメイン一般化データセットに関する実験結果を報告します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Auto Seg-Loss: Searching Metric Surrogates for Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_16.html">
      <font color="black">Auto Seg-Loss: Searching Metric Surrogates for Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">これは、個々のメトリック用に手動で設計された既存の損失関数とは対照的です。PASCALVOCとCityscapesでの広範な実験は、私たちのアプローチの有効性を示しています。 
[ABSTRACT]失われたセグメントの検索は、個人のメトリックに役立つ場合があります。これは、個々のメトリックの既存の損失関数とは対照的です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Self-training Algorithm Based on Deep Learning for Optical
  Aerial Images Change Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_17.html">
      <font color="black">Unsupervised Self-training Algorithm Based on Deep Learning for Optical
  Aerial Images Change Detection</font>
    </a>
  </h2>
  <font color="black">最終的な変化検出結果は、訓練された学生ネットワークによって取得できます。これらの疑似ラベルを使用して、適切に設計された畳み込みニューラルネットワークを訓練します。実際のデータセットでの実験結果は、提案された方法の競争力のあるパフォーマンスを示しています。 
[概要]最終的な変更検出結果は、訓練を受けた学生ネットワークによって取得できます。アルゴリズムのプロセス全体は、手動でマークされたラベルのない教師なしプロセスです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Learn to Segment Retinal Lesions and Beyond -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_18.html">
      <font color="black">Learn to Segment Retinal Lesions and Beyond</font>
    </a>
  </h2>
  <font color="black">この大規模なデータセットでの広範な実験は、提案されたアプローチが、病変のセグメンテーション、病変の分類、DRの等級付けなどの複数のタスクで従来技術を上回っていることを示しています。最後に、DRグレーディングと結果解釈の両方のサイドアテンションブランチとしてLesion-Netを使用するマルチタスクネットワークを構築します。自動網膜スクリーニングに向けて、この論文では、ピクセルレベルの網膜病変のセグメンテーションと画像を同時に達成するよう努めています。レベルの疾患分類。 
[概要]新しい論文は、糖尿病性網膜症の文脈で3つの課題を攻撃します-dr）grading.les les、新しい一連の課題は、糖尿病性網膜症を困難にします（dr）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-25">
        <br><font color="black">2019-12-25</font>
      </time>
    </span>
</section>
<!-- paper0: LTN: Long-Term Network for Long-Term Motion Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_19.html">
      <font color="black">LTN: Long-Term Network for Long-Term Motion Prediction</font>
    </a>
  </h2>
  <font color="black">私たちの長期ネットワークは、回帰アプローチと分類アプローチの両方を統合します。したがって、この作業では、長期ネットワーク（LTN）と呼ばれる長期軌道予測の2段階のフレームワークを提示します。正確な動きを作成します。ロボットが自律ナビゲーションタスクを実行しようとする場合、歩行者や車両などの周囲のエージェントの予測は重要なタスクです。 
[ABSTRACT]長期軌道予測は長期ネットワーク（ltn）と呼ばれます。長期接続は長期ナビゲーションを予測するために使用できます。マルチモーダル軌道予測に関する以前の研究は非常にうまく機能します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Hold me tight! Influence of discriminative features on deep network
  boundaries -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_20.html">
      <font color="black">Hold me tight! Influence of discriminative features on deep network
  boundaries</font>
    </a>
  </h2>
  <font color="black">最後に、決定境界の構築がトレーニングサンプルの小さな摂動に非常に敏感であり、特定の方向の変化が直交サンプルの突然の不変性につながる可能性があることを示します。これはまさに敵対トレーニングが達成するために使用するメカニズムです。堅牢性..このフレームワークを使用して、CNNのいくつかの興味深いプロパティを明らかにします。 
[ABSTRACT]この作業では、敵対的なロバスト性の分野からツールを借ります。それらは、データセットの特徴を決定境界までのサンプルの距離まで決定する新しい視点を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-15">
        <br><font color="black">2020-02-15</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning in Diabetic Foot Ulcers Detection: A Comprehensive
  Evaluation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_21.html">
      <font color="black">Deep Learning in Diabetic Foot Ulcers Detection: A Comprehensive
  Evaluation</font>
    </a>
  </h2>
  <font color="black">最後に、さまざまな深層学習法に基づくアンサンブル法がF1-スコアを強化できるが、mAPは強化できないことを示します。この論文では、次の深層学習ベースのアルゴリズムを比較します。FasterR-CNN、FasterR-の3つのバリアントCNNとアンサンブル法。 YOLOv3; YOLOv5; EfficientDet;と新しいカスケードアテンションネットワーク..私たちは、各方法の包括的な評価を提供します。 
[概要] dfuチャレンジ（dfuc2020）は、各メソッドをトレーニングするための2,00枚の画像と2,00枚の画像の詳細なデータセットを参加者に提供します。これらには、モデルアーキテクチャの詳細な詳細な説明が含まれています。各dfuc20について、アンサンブルメソッドがさまざまな深層学習状態の結果に基づいて、f1-スコアを向上させることができますが、マップは向上させません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-07">
        <br><font color="black">2020-10-07</font>
      </time>
    </span>
</section>
<!-- paper0: A Hamiltonian Monte Carlo Method for Probabilistic Adversarial Attack
  and Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_22.html">
      <font color="black">A Hamiltonian Monte Carlo Method for Probabilistic Adversarial Attack
  and Learning</font>
    </a>
  </h2>
  <font color="black">魅力的なソリューションは、敵対的な例のソリューションスペースを探索し、それらの多様な束を生成することです。これにより、実際のシステムの堅牢性が向上し、深刻なセキュリティの脅威や脆弱性を防ぐことができます。HMCの効率を向上させるために、軌道の長さを自動的に制御する新しい体制を提案します。これにより、アルゴリズムは、さまざまな位置で検索方向に沿って適応ステップサイズで移動できます。既存の敵対的攻撃方法のほとんどは、入力に対して単一の敵対的例を作成するだけです。敵対的な例の根底にあるデータ多様性を垣間見ることができます。 
[概要]既存の敵対的攻撃方法のほとんどは、入力に対して単一の敵対的例を作成するだけです。ソリューションは、敵対的例の基礎となるデータ多様性を垣間見ることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Improved Multi-Source Domain Adaptation by Preservation of Factors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_23.html">
      <font color="black">Improved Multi-Source Domain Adaptation by Preservation of Factors</font>
    </a>
  </h2>
  <font color="black">この論文では、タスクに役立つ要素も失われる可能性があるため、これが負の転送につながる可能性があることを示します。これに対処するために、深い敵対的な教師なしDAモデルをトレーニングする方法であるFactor-Preserving DA（FP-DA）を提案します。 、マルチドメインシナリオで特定のタスク関連要因を保持できます。多くのDAアプローチは、機能表現からすべてのドメイン要因を削除してドメイン不変にしようとします。 
[概要]新しい方法は、深い敵対的な教師なしdaモデルをトレーニングすることです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Anomaly Detection with Deep Perceptual Autoencoders -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_24.html">
      <font color="black">Anomaly Detection with Deep Perceptual Autoencoders</font>
    </a>
  </h2>
  <font color="black">モデルのセットアップ中に異常な例がまったく提供されない、完全に監視されていない異常検出の非常に問題のあるステートメントを再検討します。既知のベンチマークを使用した自然画像データセット、および放射線とデジタルを含む2つの医療データセットでソリューションを評価します。病理画像..モデルのハイパーパラメータの検索を開始するためだけに、非常に少数の限定された変動性の異常を使用することにより、この非現実的な仮定を緩和することを提案します。 
[概要]新しいアプローチは、画像異常検出の新しい強力なベースラインを示唆しています。モデルのハイパーパラメータの検索を開始するためだけに、限られた変動の非常に少数の異常を使用して、非現実的な仮定を緩和することを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-23">
        <br><font color="black">2020-06-23</font>
      </time>
    </span>
</section>
<!-- paper0: Object Tracking Using Spatio-Temporal Future Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_25.html">
      <font color="black">Object Tracking Using Spatio-Temporal Future Prediction</font>
    </a>
  </h2>
  <font color="black">外観ベースのトラッカーと軌道予測を動的に切り替えるために、追跡予測がどれだけ優れているかを評価できるネットワークを採用し、評価スコアを使用して、外観ベースのトラッカーの予測と軌道ベースの予測のどちらかを選択します。 。入力ビデオでは、ターゲットオブジェクトの軌道はオブジェクトの動きだけでなくカメラの動きにも影響されるため、背景モーションモジュールはカメラの動きを推定します。これにより、オブジェクトの軌道をオブジェクトから独立させることができます。 
[ABSTRACT]私たちの軌道予測モジュールは、オブジェクトの過去の軌道に基づいて、現在および将来のフレームでのターゲットオブジェクトの位置を予測します。モーションはオブジェクトから独立させることができます。提案された方法は、新しい最先端を設定します。一般的に使用される追跡ベンチマークでのパフォーマンス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Domain Adaptation with Consistency Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_26.html">
      <font color="black">Self-Supervised Domain Adaptation with Consistency Training</font>
    </a>
  </h2>
  <font color="black">さらにガイダンスを提供するために、拡張データの特徴表現を元のデータの特徴表現と一致させるように強制します。直感的に、一貫性は表現学習に追加の制約を導入するため、学習された表現は正しい情報に焦点を合わせる可能性が高くなります。メインタスクについて..ただし、取得された特徴表現には、メインタスクに関して無関係な情報が大量に含まれている可能性があります。 
[概要]ラベルのないデータからターゲットを学習するための自己教師あり口実タスクを作成します。さらにガイダンスを提供するために、拡張データの特徴表現を元のデータの特徴表現と一致させるように強制します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Back to the Future: Cycle Encoding Prediction for Self-supervised
  Contrastive Video Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_27.html">
      <font color="black">Back to the Future: Cycle Encoding Prediction for Self-supervised
  Contrastive Video Representation Learning</font>
    </a>
  </h2>
  <font color="black">アーキテクチャ的には、基盤となるネットワーク構造は、すべてのビデオスニペットに単一の機能エンコーダーを利用し、時間的な順方向および逆方向の遷移を学習する2つの予測モジュールを追加します。このペーパーでは、CEPコンポーネントのソースコードを完全に公開します。標準データセットUCF101およびHMDB51。 
[ABSTRACT] cepは、ラベルのないビデオコンテンツの高レベルの空間的時間構造を効果的に表すことができます。自己監視信号として、cepは、保存された機能分離だけでなく、異文化を活用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: LiRaNet: End-to-End Trajectory Prediction using Spatio-Temporal Radar
  Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_28.html">
      <font color="black">LiRaNet: End-to-End Trajectory Prediction using Spatio-Temporal Radar
  Fusion</font>
    </a>
  </h2>
  <font color="black">この論文では、広く使用されているLIDARおよび高解像度（HD）マップとともにレーダーセンサー情報を利用する新しいエンドツーエンドの軌道予測方法であるLiRaNetを紹介します。自動車レーダーは豊富で補完的な情報を提供し、長距離車両を可能にします検出と瞬間的な半径方向の速度測定。ただし、レーダー測定の角度分解能が比較的低い、その希薄性、LIDARとの正確な時間同期の欠如など、LIDARとレーダー情報の融合を困難にする要因があります。 
[概要]効率的な空間-時間レーダー特徴抽出スキームを提案します。これらの課題を克服するために、予測誤差が52％減少することを示します。これには、レーダー情報の予測の大幅な低下が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-02">
        <br><font color="black">2020-10-02</font>
      </time>
    </span>
</section>
<!-- paper0: FOSS: Multi-Person Age Estimation with Focusing on Objects and Still
  Seeing Surroundings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_29.html">
      <font color="black">FOSS: Multi-Person Age Estimation with Focusing on Objects and Still
  Seeing Surroundings</font>
    </a>
  </h2>
  <font color="black">通常、このような状況は2つの別々のモデルによって解決されました。 1つは顔の領域をトリミングする顔検出器モデルで、もう1つはトリミングされた画像から推定する年齢推定モデルです。この作業では、推定する単一のモデルで複数人の年齢を検出および推定できる方法を提案します。また、顔を中心に周囲を見ながら年齢を重ねる。また、顔を片方だけ撮影した画像でトレーニングしても、モデルが複数人をうまく推定できるトレーニング方法を提案する。 
[概要]状況によっては、野生および複数の人の年齢推定が必要です。ただし、各顔の年齢を正確に特定するには、個別のモデルが必要です。提案された方法は、最先端の精度を上回るのに役立つ可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: RNN Training along Locally Optimal Trajectories via Frank-Wolfe
  Algorithm -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_30.html">
      <font color="black">RNN Training along Locally Optimal Trajectories via Frank-Wolfe
  Algorithm</font>
    </a>
  </h2>
  <font color="black">特定の条件下で、アルゴリズムが$ \ epsilon $エラーに対して$ O（1 / \ epsilon）$の劣線形収束率を持っていることを証明します。FWは暗黙的に正規化された勾配を含み、収束率が遅くなる可能性がありますが、驚くべきことに、追加のコストがあっても、全体的なトレーニングコストがバックプロパゲーションよりも低いことが経験的に観察された新しいRNNトレーニング方法。また、深いRNNアーキテクチャを実験し、効率的なトレーニングパフォーマンスを示します。 
[ABSTRACT]私たちの方法は、新しい率直なウルフ法につながります。これは、本質的に、再起動スキームを備えたsgdアルゴリズムです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: A Simple Non-i.i.d. Sampling Approach for Efficient Training and Better
  Generalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_31.html">
      <font color="black">A Simple Non-i.i.d. Sampling Approach for Efficient Training and Better
  Generalization</font>
    </a>
  </h2>
  <font color="black">さらに、おそらくもっと重要なことに、DaRサンプリング戦略を使用してImageNetの事前トレーニング済みモデルが、オブジェクト検出（+0.3 AP）、インスタンスセグメンテーション（+0.3 AP）、シーン解析（+0.5 mIoU）などのダウンストリームタスクの転送性を向上させることがわかりました。人間の姿勢の推定（+0.6 AP）。さまざまなデータセットでトレーニングコストが15％削減された場合でも、提案されたDaR戦略が予測精度を維持（および多くの場合改善）できることを実験で示します（CIFAR 10、 CIFAR 100およびImageNet）およびさまざまなバックボーンアーキテクチャ（ResNets、DenseNets、およびMobileNets）。 
[ABSTRACT]実験は、提案されたdar戦略が予測精度を維持できることを示しています。トレーニングコストは、さまざまなデータセット（cifar 100およびimagenet）で15％削減されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-11-23">
        <br><font color="black">2018-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Interpreting Multivariate Interactions in DNNs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_32.html">
      <font color="black">Interpreting Multivariate Interactions in DNNs</font>
    </a>
  </h2>
  <font color="black">実験結果は提案手法の有効性を示した。我々は様々なDNNで実験を行った。我々は各入力変数の帰属値を推論に割り当てるように設計されたシャープレイ値に基づいて相互作用の重要性を定義する。 
[ABSTRACT]相互作用は、各因子の属性値を割り当てるように設計されたシャープレイ値に基づいています。実験により、提案された方法の有効性が示されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-10">
        <br><font color="black">2020-10-10</font>
      </time>
    </span>
</section>
<!-- paper0: Does Data Augmentation Benefit from Split BatchNorms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_33.html">
      <font color="black">Does Data Augmentation Benefit from Split BatchNorms</font>
    </a>
  </h2>
  <font color="black">この作業では、この不一致を修正するために最近提案されたトレーニングパラダイムを調査します。配布されていない可能性のある、強力に拡張された画像に補助BatchNormを使用します。次に、精度と堅牢性の間の基本的なトレードオフを調査します。さまざまなBatchNormパラメーターを使用することで、モデルのパフォーマンスに対するデータ拡張の利点についてより深い洞察を得ることができます。代わりに、弱い拡張によって定義されたBatchNormパラメーターを使用して調査したところ、この方法により、CIFAR-10などの一般的な画像分類ベンチマークのパフォーマンスが大幅に向上することがわかりました。 、CIFAR-100、およびImageNet。 
[ABSTRACT]テスト結果は、この方法が一般的な画像分類ベンチマークのパフォーマンスを大幅に改善することを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: An Empirical Analysis of Visual Features for Multiple Object Tracking in
  Urban Scenes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_34.html">
      <font color="black">An Empirical Analysis of Visual Features for Multiple Object Tracking in
  Urban Scenes</font>
    </a>
  </h2>
  <font color="black">ただし、それらの一部が他より優れているかどうかは明らかではありません。いくつかのデータセットの結果は、ReIDネットワークの機能が、検出器の品質に関係なく、インスタンスを互いに区別するのに最適であることを示しています。これらの機能は、都市のシーン追跡シナリオでバウンディングボックスで囲まれたオブジェクトを識別するのにどれほど優れているか。 
[ABSTRACT] mot機能には、カラーヒストグラム、整列された勾配のヒストグラム、畳み込みニューラルネットワークからの深い機能、および再識別（reid）機能が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Encoder-decoder semantic segmentation models for electroluminescence
  images of thin-film photovoltaic modules -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_35.html">
      <font color="black">Encoder-decoder semantic segmentation models for electroluminescence
  images of thin-film photovoltaic modules</font>
    </a>
  </h2>
  <font color="black">薄膜モジュールのエレクトロルミネッセンス（EL）画像のセマンティックセグメンテーションを実行するために、ディープニューラルネットワークに基づく一連の画像セグメンテーション方法を検討します。抽出する2種類の特徴、シャント、いわゆる「液滴」を選択しました。さらに、6000枚の画像のフルセットに最適なモデルを適用し、EL画像の自動セグメンテーションにより、画像の小さなサンプルの調査からは推測できない多くの微妙な特徴を明らかにできることを示しました。 
[概要]ネットワークは、銅インジウムガリウムガリウムジセレニド（cigs）薄膜モジュールの6000 el画像を含むデータベースからの画像のサンプルでトレーニングおよびテストされています。これらの機能は、品質管理に拡張できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: CIMON: Towards High-quality Hash Codes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_36.html">
      <font color="black">CIMON: Towards High-quality Hash Codes</font>
    </a>
  </h2>
  <font color="black">さらに、ほとんどのハッシュ方法は、衝突などのハッシュコードの基本的な特性を無視します。これにより、ハッシュコードが不安定になります。まず、グローバル制約学習と類似性統計分布を使用して、信頼性の高いスムーズなガイダンスを取得します。いくつかのベンチマークデータセットは、提案された方法が、検索パフォーマンスと堅牢性の両方で、幅広い最先端の方法を一貫して上回っていることを示しています。 
[概要]ほとんどの研究は教師なしハッシュに焦点を当てていますが、事前にトレーニングされたモデルの非効率的な表現能力のため、ローカルの意味的類似性に多くの誤検出と検出漏れが導入されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: YOLOff: You Only Learn Offsets for robust 6DoF object pose estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_37.html">
      <font color="black">YOLOff: You Only Learn Offsets for robust 6DoF object pose estimation</font>
    </a>
  </h2>
  <font color="black">カメラ座標系の各キーポイントの位置を復元するために、ローカル投票を確実に実行します。標準データセットLineModでの実験は、最先端の方法よりも堅牢で正確なアプローチを示しています。ポーズ情報を抽出するには、幾何学的ステップは、レジストレーションエラーを最小化することにより、カメラ座標系の3Dポイントをワールド座標系の対応する3Dポイントと位置合わせし、ポーズを計算することで構成されます。 
[概要]単純なステップは、雑然としたシーンの単一のrgb --d画像に基づいています。ポーズ情報を抽出するための幾何学的ステップは、カメラ内の3Dポイントと世界の対応する3Dポイントを位置合わせすることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br><font color="black">2020-02-03</font>
      </time>
    </span>
</section>
<!-- paper0: PP-OCR: A Practical Ultra Lightweight OCR System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_38.html">
      <font color="black">PP-OCR: A Practical Ultra Lightweight OCR System</font>
    </a>
  </h2>
  <font color="black">一方、中国語と英語の認識のためのいくつかの事前トレーニング済みモデルがリリースされています。これには、テキスト検出器（97K画像が使用）、方向分類器（600K画像が使用）、テキスト認識機能（17.9M画像が使用）が含まれます。 。上記のモデルはすべてオープンソースであり、コードはGitHubリポジトリ（https://github.com/PaddlePaddle/PaddleOCR）で入手できます。光学文字認識（OCR）システムは、さまざまな場所で広く使用されています。オフィスオートメーション（OA）システム、ファクトリーオートメーション、オンライン教育、地図作成などのアプリケーションシナリオの例。
[要約]提案されたpp-ocrは、さまざまなテキストの外観と計算効率の要求により、依然として困難な作業です。 ppの提案されたモデルサイズは、6622の中国語文字を認識するためにわずか3.5mです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-21">
        <br><font color="black">2020-09-21</font>
      </time>
    </span>
</section>
<!-- paper0: Representation Learning via Invariant Causal Mechanisms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_39.html">
      <font color="black">Representation Learning via Invariant Causal Mechanisms</font>
    </a>
  </h2>
  <font color="black">これに基づいて、新しい自己教師あり目的である不変因果メカニズムによる表現学習（ReLIC）を提案します。これは、不変正則化によって拡張全体でプロキシターゲットの不変予測を強制し、一般化の保証を改善します。自己教師あり学習は次のように登場しました。ラベルのないデータのみを使用して表現を事前トレーニングすることにより、コストのかかる教師あり信号への依存を減らす戦略。さらに、因果関係を使用して、特定の種類の自己教師あり方法である対照学習を一般化し、これらの方法の成功に関する代替の理論的説明を提供します。 
[概要]これらの方法は、ヒューリスティックプロキシ分類タスクとデータ拡張を組み合わせたものですが、この成功についての理論的な理解は限られています。この方法は、明示的な不変性制約を通じて使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: HS-ResNet: Hierarchical-Split Block on Convolutional Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_40.html">
      <font color="black">HS-ResNet: Hierarchical-Split Block on Convolutional Neural Network</font>
    </a>
  </h2>
  <font color="black">Hierarchical-Split Blockには、1つの残りのブロック内に多くの階層的な分割および連結接続が含まれています。さらに、Hierarchical-Splitブロックは非常に柔軟で効率的であり、さまざまなアプリケーションに潜在的なネットワークアーキテクチャの大きなスペースを提供します。マルチスケール機能が見つかります。多くのビジョンタスクにとって非常に重要です。 
[概要]これはベースラインと比較され、改善が見られます。また、上位モデルのほとんどの状態を上回っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Kernel Based Progressive Distillation for Adder Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_41.html">
      <font color="black">Kernel Based Progressive Distillation for Adder Neural Networks</font>
    </a>
  </h2>
  <font color="black">最後に、グラウンドトゥルースと教師の両方からの情報に基づいて、目的のANNが段階的に学習されます。たとえば、提案されたPKKDメソッドを使用してトレーニングされたANN-50は、ImageNetデータセットで76.8 \％のトップ1精度を取得します。 ResNet-50よりも0.6 \％高くなっています。残念ながら、すべての畳み込みフィルターを加算器フィルターに置き換えると、精度が低下します。 
[ABSTRACT] annsは、システムのパフォーマンスを向上させるための新しい方法です。これは、カーネルベースの知識蒸留（pkkd）法に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Segmentation and Defect Classification of the Power Line Insulators: A
  Deep Learning-based Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_42.html">
      <font color="black">Segmentation and Defect Classification of the Power Line Insulators: A
  Deep Learning-based Approach</font>
    </a>
  </h2>
  <font color="black">したがって、この研究では、絶縁体を背景からセグメント化して、4つの異なるカテゴリ、つまり、健康、破損、焼け/腐食、およびキャップの欠落に基づいて状態を分類する2段階モデルを紹介します。ただし、既存の研究では、特定の種類の絶縁体の故障..その故障は、送電線全体の中断または広範囲にわたる停電を引き起こす可能性があります。 
[概要]提案されたアプローチは、4つの絶縁体によって開発できます。複数のタイプの障害を検出および検出するには、単純なセグメンテーションが必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-21">
        <br><font color="black">2020-09-21</font>
      </time>
    </span>
</section>
<!-- paper0: Rectifying Pseudo Label Learning via Uncertainty Estimation for Domain
  Adaptive Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_43.html">
      <font color="black">Rectifying Pseudo Label Learning via Uncertainty Estimation for Domain
  Adaptive Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">入力画像が与えられると、モデルはセマンティックセグメンテーション予測と予測の不確実性を出力します。問題を克服するために、このペーパーでは、トレーニング中に予測の不確実性を明示的に推定して、監視されていないセマンティックセグメンテーション適応の疑似ラベル学習を修正することを提案します。具体的には、予測分散を介して不確実性をモデル化し、不確実性を最適化の目的に組み込みます。 
[概要]以前のアプローチでは、通常、疑似ラベルをグラウンドトゥルースと見なしますが、代わりに、トレーニングドメインとテストドメインの不一致により、ラベルに誤った予測が含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-08">
        <br><font color="black">2020-03-08</font>
      </time>
    </span>
</section>
<!-- paper0: Spherical Knowledge Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_44.html">
      <font color="black">Spherical Knowledge Distillation</font>
    </a>
  </h2>
  <font color="black">理論的分析とアブレーション研究によって議論を検証します。具体的には、教師と生徒のロジットを単位球に投影し、球上で効率的に知識の蒸留を実行できます。ロジットの規範は実際には干渉であると主張します。 、転送プロセスの効率を損ないます。 【概要】この問題の解決に加えて、球形知識蒸留（skd）を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Constrative Person Re-identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_45.html">
      <font color="black">Unsupervised Constrative Person Re-identification</font>
    </a>
  </h2>
  <font color="black">表現学習は、教師なし人のReIDで重要な役割を果たします。具体的には、従来の対照学習戦略とは異なり、複数のポジティブと適応的にサンプリングされたネガティブを使用してコントラスト損失を定義し、より強力なアイデンティティ識別表現を備えた特徴埋め込みモデルを学習できるようにすることを提案します。 。教師なしの人ReIDは、集中的な手動注釈なしで機能し、新しい条件に適応する大きな可能性を示しているため、最近多くの注目を集めています。 
[ABSTRACT] reidは手動の注釈なしで機能し、新しい条件に適応する大きな可能性を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Interactive Latent Interpolation on MNIST Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_46.html">
      <font color="black">Interactive Latent Interpolation on MNIST Dataset</font>
    </a>
  </h2>
  <font color="black">次に、次元削減を利用してブラウザでの生成を.2ミリ秒に短縮する新しいWebベースのGANを提案しました。最後に、線形補間を使用して最新のUIを作成し、作業を提示しました。数学的な理由で機能しなくなったGANについては、後で説明します。 
[概要]新しいWebベースのガンは、技術的な削減を利用して、ブラウザでの生成をに高速化します。 2ミリ秒。高速生成により、これまでに見たことのないアニメーションタイプのエフェクトを作成できるほど高速に生成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Reproducible and Interpretable Spiculation Quantification for Lung
  Cancer Screening -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_47.html">
      <font color="black">Reproducible and Interpretable Spiculation Quantification for Lung
  Cancer Screening</font>
    </a>
  </h2>
  <font color="black">次に、結節の再現性のある半自動セグメンテーションを使用した病理学的悪性腫瘍予測のために、棘状突起の定量化測定をラジオミクスフレームワークに適用しました。公開されているLIDC-IDRIデータセットの病理学者（強いラベル）と放射線科医（弱いラベル）の評価を使用してこの機能を含む放射線モデルをトレーニングおよびテストしてから、モデルを外部で検証します。結節のスピキュレーションを定量化するための、再現性があり、解釈可能な、パラメータのない手法を開発しました。 
[概要]本研究では、面積歪みメトリックを使用してスピキュレーションを定量化するための解釈可能なツールを提案しました。これらのスコアは、単純な病理学的悪性腫瘍予測モデルによって作成されました。スピキュレーションを使用すると、以前のモデルよりも高いパフォーマンスを達成できました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-08-24">
        <br><font color="black">2018-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Relighting Networks for Image Light Source Manipulation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_48.html">
      <font color="black">Deep Relighting Networks for Image Light Source Manipulation</font>
    </a>
  </h2>
  <font color="black">この論文では、単一画像の再照明タスクを定式化し、3つの部分からなる新しいDeep Relighting Network（DRN）を提案します：1）深い自動エンコーダネットワークを通じて主要なシーン構造を明らかにすることを目的としたシーンの再変換、2）シャドウプライア推定、敵対的学習を通じて新しい光の方向からの光の影響を予測する、および3）再レンダリング、一次構造を再構築されたシャドウビューと組み合わせて、ターゲット光源の下で必要な推定を形成する。実験結果は、提案された方法は、定性的および定量的に、他の可能な方法よりも優れています。具体的には、提案されたDRNは、2020ECCV会議の「AIM2020-Anyto onerelightingchallenge」で最高のPSNRを達成しました。 
[ABSTRACT]新しい方法は、より多くの情報を必要とする既存の方法を使用します。これらには、シーンの詳細な詳細画像が含まれますが、利用できない場合があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Dance Revolution: Long-Term Dance Generation with Music via Curriculum
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_49.html">
      <font color="black">Dance Revolution: Long-Term Dance Generation with Music via Curriculum
  Learning</font>
    </a>
  </h2>
  <font color="black">この論文では、音楽駆動型ダンス生成をシーケンス間学習問題として形式化し、新しいseq2seqアーキテクチャを考案して、音楽機能の長いシーケンスを効率的に処理し、音楽とダンスの間のきめ細かい対応をキャプチャします。ロングモーションシーケンス生成における自動回帰モデルのエラー蓄積を軽減するカリキュラム学習戦略を提案します。これにより、トレーニングプロセスが、以前のグラウンドトゥルースムーブメントを使用した完全にガイドされた教師強制スキームから、主に代わりに生成された動き..この問題は、ロングモーションシーケンスの生成ではさらに深刻になります。 
[ABSTRACT]ダンスと音楽は機械学習アーキテクチャの問題です。ただし、これはニューラルネットワークにフィードバックされる予測エラーが豊富なためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br><font color="black">2020-06-11</font>
      </time>
    </span>
</section>
<!-- paper0: A Deep Drift-Diffusion Model for Image Aesthetic Score Distribution
  Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_50.html">
      <font color="black">A Deep Drift-Diffusion Model for Image Aesthetic Score Distribution
  Prediction</font>
    </a>
  </h2>
  <font color="black">さらに、さまざまな心理的プロセスもモデルによって予測できます。DDDモデルは、評価結果の従来のモデリングの代わりに、美的知覚の心理的プロセスを記述できます。ドリフトのパラメーターを回帰するために、深い畳み込みニューラルネットワークを使用します。拡散モデル。 
[概要]モデルは、モデリングの代わりに、深い美的知覚の心理的プロセスを記述することができます。モデルはシンプルですが効率的であり、美的スコア分布予測における最先端の方法よりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Image Reconstruction with Misaligned Structural Information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_51.html">
      <font color="black">Robust Image Reconstruction with Misaligned Structural Information</font>
    </a>
  </h2>
  <font color="black">これらのモデルのほとんどすべては、モダリティが完全に登録されているという仮定に依存していますが、これはほとんどの実際のアプリケーションには当てはまりません。再構成と登録を共同で実行し、それによってこのハードルを克服する変分フレームワークを提案します。マルチモダリティ（またはマルチチャネル）イメージングはますます重要になり、より広く利用できるようになっています。たとえば、
[ABSTRACT]ハイパースペクトルイメージング、ハイパースペクトルイメージング、マルチ直腸イメージングに加えて、医療従事者はモダリティを大幅に改善することが示されています。ハイパースペクトルイメージングは複数の地域で見られます。医者と医者を含む</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-01">
        <br><font color="black">2020-04-01</font>
      </time>
    </span>
</section>
<!-- paper0: Empty Cities: a Dynamic-Object-Invariant Space for Visual SLAM -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_52.html">
      <font color="black">Empty Cities: a Dynamic-Object-Invariant Space for Visual SLAM</font>
    </a>
  </h2>
  <font color="black">最初の課題は、画像のマルチクラスセマンティックセグメンテーションを学習する畳み込みネットワークを使用することで対処されます。コードはhttps://github.com/bertabescos/EmptyCities_SLAMで利用可能になりました。エンドツーを紹介します。 -ディープラーニングフレームワークを終了して、車両や歩行者などの動的コンテンツを含む都市環境の画像を、ローカリゼーションとマッピングに適した現実的な静的フレームに変換します。 
[概要]一般的な目的は、動的環境での視覚ベースのローカリゼーションおよびマッピングタスクを改善することです。これらには、動的オブジェクトの削除、静的背景の修復が含まれます。2番目の課題は、寛大な敵対モデルによって対処されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Self-training for Few-shot Transfer Across Extreme Task Differences -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_53.html">
      <font color="black">Self-training for Few-shot Transfer Across Extreme Task Differences</font>
    </a>
  </h2>
  <font color="black">従来の数ショットおよび転送学習手法は、ソースタスクとターゲットタスクの間にこのような極端な違いがあると失敗します。このホワイトペーパーでは、この極端なドメインギャップに取り組むためのシンプルで効果的なソリューションを紹介します。ターゲットドメインからのラベルなしデータ..このような大きなラベル付きデータセットが事前トレーニングに利用できない問題ドメイン（X線画像など）では、別の「ソース」問題ドメイン（例： ImageNet）。これは、目的のターゲットタスクとは大きく異なる可能性があります。 
[概要]このような大きなラベル付きデータセットが事前トレーニングに利用できない問題ドメインでは、別の「ソース」問題ドメインで事前トレーニングに頼る必要があります。これは、目的のターゲットタスクとは大きく異なる可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: LiteDepthwiseNet: An Extreme Lightweight Network for Hyperspectral Image
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_54.html">
      <font color="black">LiteDepthwiseNet: An Extreme Lightweight Network for Hyperspectral Image
  Classification</font>
    </a>
  </h2>
  <font color="black">さらに、元の3D深度方向畳み込みのReLUレイヤーとバッチ正規化レイヤーを削除します。これにより、小さなサイズのデータセットでのモデルの過剰適合現象が大幅に改善されます。3つのベンチマークハイパースペクトルデータセットでの実験結果は、LiteDepthwiseNetが最新の状態を達成することを示しています。パラメータ数が非常に少なく、計算コストが低いアートパフォーマンス。さらに、焦点損失は、困難なサンプルや不均衡なデータに対するモデルの注意を改善するための損失関数として使用され、そのトレーニングパフォーマンスはクロスよりも大幅に優れています。エントロピー損失またはバランスの取れたクロスエントロピー損失。 
[ABSTRACT]深層学習法は、高い分類パフォーマンスを実現できます。これらには、深さ方向の畳み込み、深さ方向の畳み込み、点ごとの畳み込みが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Interpretation of Swedish Sign Language using Convolutional Neural
  Networks and Transfer Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_55.html">
      <font color="black">Interpretation of Swedish Sign Language using Convolutional Neural
  Networks and Transfer Learning</font>
    </a>
  </h2>
  <font color="black">さらに、手話をユーザーフレンドリーなWebアプリケーションとして解釈するためのモデルの実装の詳細について説明します。結果は、CNNの使用が手話を解釈するための有望なアプローチであり、転移学習を使用して高いテスト精度を達成できることを示しています。小さなトレーニングデータセットを使用しているにもかかわらず..8つの研究対象と9,400の画像に基づくモデルの最終的な精度は、85％です。 
[概要]畳み込みニューラルネットワーク（cnns）を使用して、コンピューターがスウェーデン手話の兆候を解釈できるようにする</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Natural Language Rationales with Full-Stack Visual Reasoning: From
  Pixels to Semantic Frames to Commonsense Graphs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_56.html">
      <font color="black">Natural Language Rationales with Full-Stack Visual Reasoning: From
  Pixels to Semantic Frames to Commonsense Graphs</font>
    </a>
  </h2>
  <font color="black">私たちの実験は、基本的な事前訓練された言語モデルが視覚的適応の恩恵を受け、フリーテキストの合理化が複雑な視覚的テキストの推論タスクのモデル解釈可能性を補完する有望な研究の方向性であることを示しています。複雑な視覚的推論タスク：視覚的常識的推論、視覚的テキストの含意、視覚的質問への回答..正確な合理化の重要な課題は、すべてのレベルでの包括的な画像理解です。ピクセルレベルでの明示的なコンテンツだけでなく、セマンティックおよび実用的なレベル。 
[要約]いくつかの複雑な視覚的推論タスクにわたって自然言語の理論的根拠を生成することに焦点を当てた最初の研究</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Integrating Coarse Granularity Part-level Features with Supervised
  Global-level Features for Person Re-identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_57.html">
      <font color="black">Integrating Coarse Granularity Part-level Features with Supervised
  Global-level Features for Person Re-identification</font>
    </a>
  </h2>
  <font color="black">一方では、CGPNは、全体的および部分的な人物画像の両方に対して効果的な身体部分の特徴を抽出することを学習します。CGPNは、人物Re-IDの精度を高めるために2倍の利点を獲得します。特に人物Reにとって最も困難なデータセットであるCUHK03で-ID、シングルクエリモードでは、ランクを変更せずにこの方法でランク-1 / mAP = 87.1 \％/ 83.6 \％の最高の結果が得られ、現在の最良の方法を+ 7.0 \％/ + 6.7 \％上回っています。 。 
[ABSTRACT] re --idは動作が難しいことがわかりますが、これらのシナリオにはholistic03と部分的な歩行者画像の両方が含まれることがよくあります。一方、cgpnは、監視戦略を使用してより正確なグローバル特徴を抽出することを学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: XPDNet for MRI Reconstruction: an Application to the fastMRI 2020 Brain
  Challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_58.html">
      <font color="black">XPDNet for MRI Reconstruction: an Application to the fastMRI 2020 Brain
  Challenge</font>
    </a>
  </h2>
  <font color="black">モジュラークロスドメインニューラルネットワークXPDNetとそのMRI再構成タスクへの応用を紹介します。執筆時点では、このアプローチは、加速係数4で膝と脳の両方のfastMRIリーダーボードでPSNRの最高のパフォーマンスを発揮します。また、MRI再構成のためのディープラーニングに固有の最先端技術を採用しています。 
[概要]このアプローチは、システムを展開し、ステップ間の加速スキームを学習することで構成されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: RetiNerveNet: Using Recursive Deep Learning to Estimate Pointwise 24-2
  Visual Field Data based on Retinal Structure -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_59.html">
      <font color="black">RetiNerveNet: Using Recursive Deep Learning to Estimate Pointwise 24-2
  Visual Field Data based on Retinal Structure</font>
    </a>
  </h2>
  <font color="black">提案されたネットワークは、ベースラインの数と比較して、個々の視野値のより正確な推定値を取得できます。これは、SAPのプロキシとしての有用性を意味します。RetiNerveNetは、より客観的なスペクトルドメイン光コヒーレンストモグラフィー（SDOCT）からの情報を使用します。 .. RetiNerveNetは、視野周囲の網膜神経線維層（RNFL）の厚さから始めて、網膜神経線維の弧状の収束をトレースバックして、個々の年齢補正された24-2SAP値を推定しようとします。 
[概要]このテストは、視覚障害を検出するために最も頻繁に使用されます。緑内障のため、より客観的な赤外線ドメイン光コヒーレンストモグラフィー（sdoct）からの情報を使用します。retinervenetは樹液の平均偏差を正確に予測できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning Models for Predicting Wildfires from Historical
  Remote-Sensing Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_60.html">
      <font color="black">Deep Learning Models for Predicting Wildfires from Historical
  Remote-Sensing Data</font>
    </a>
  </h2>
  <font color="black">結果は、深層学習モデルが、83％のAUCで植生、天気、地形に関する集計データを使用して、火災の可能性が高い領域を正常に識別できることを示しています。野火の可能性が高い領域を識別することは、土地および森林管理の重要な要素ですと災害への備え..この予測問題は、3つの機械学習タスクとして構成されています。 
[概要] 10年近くのリモートセンシングデータと過去の火災記録を集約して山火事を予測することでデータセットを作成します。結果は、4つの異なる深層学習モデルを使用して比較および分析され、山火事の可能性が推定されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Attention-Network for Semantic Segmentation of High-Resolution
  Remote Sensing Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_61.html">
      <font color="black">Multi-Attention-Network for Semantic Segmentation of High-Resolution
  Remote Sensing Images</font>
    </a>
  </h2>
  <font color="black">注意の高い計算要求を軽減するために、線形複雑性を備えたカーネル注意と呼ばれる新しい注意メカニズムが提案されています。注意の空間の複雑さは、大きな入力を伴うアプリケーションシナリオでの注意の使用を妨げます。この論文では、これらの欠点を改善するためにマルチアテンションネットワーク（MANet）を提案しました。 
[ABSTRACT]たとえば、ニューラルネットワークによって多くの情報が悪用されていますが、標準モデルにはまだいくつかの制限があります。たとえば、これらの欠点を改善するために、マルチアテンションネットワーク（manet）を提案しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Video Anomaly Detection via Flow-based Generative Modeling
  on Appearance and Motion Latent Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_62.html">
      <font color="black">Unsupervised Video Anomaly Detection via Flow-based Generative Modeling
  on Appearance and Motion Latent Features</font>
    </a>
  </h2>
  <font color="black">異常なシーンは外観や動きによって通常のシーンと区別されるため、これまでの多くのアプローチでは、モーション情報のオプティカルフローなどの明示的な事前トレーニング済みモデルが使用されていました。これにより、ネットワークが複雑になり、事前トレーニングに依存します。監視ビデオの異常検出は、通常のシーンでの犯罪や事故などの異常なイベントを検索します。SlowFastネットワークの構造を活用し、外観（低速）と動き（高速）を通じて空間的および時間的情報に焦点を当てる暗黙的な2パスAutoEncoder（ITAE）を提案します。 ）それぞれエンコーダ。 
[概要]異常なイベントはめったに発生しません。正常なデータと異常なデータの間にクラスの不均衡の問題があります。これらのタイプのエンコーダは、トレーニングセットのビデオを再構築することにより、正常な外観と動作を学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Differential diagnosis and molecular stratification of gastrointestinal
  stromal tumors on CT images using a radiomics approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_63.html">
      <font color="black">Differential diagnosis and molecular stratification of gastrointestinal
  stromal tumors on CT images using a radiomics approach</font>
    </a>
  </h2>
  <font color="black">放射線科モデルのAUCはc-KITで0.52、c-KITエクソン11で0.56、MIで0.52でした。3人の放射線科医のAUCはそれぞれ0.69、0.76、0.84でした。GISTと非画像、年齢、性別、場所を含むGIST放射線モデルの平均曲線下面積（AUC）は0.82でした。 
[ABSTRACT]ラジオミクスは、要旨を他の腹腔内腫瘍と区別するためにラジオミクスを評価することでした。それらは、要旨、pdgfra、braf変異状態、および有糸分裂指数（mi）を予測します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: A Human Eye-based Text Color Scheme Generation Method for Image
  Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CV/paper_64.html">
      <font color="black">A Human Eye-based Text Color Scheme Generation Method for Image
  Synthesis</font>
    </a>
  </h2>
  <font color="black">これらの問題に対処するために、この論文では、物事を観察する人間の目の特性と一致する配色を生成する新しい方法を設計します。次に、生成されるテキストは、画像の同じ深さに均一に制限されます。テキストが深さを超えて表示される可能性がある現実世界の特殊なケースです。私たちの方法の有効性は、いくつかの公開データセットで検証されています。 
[概要]テキストの配色に使用される配色は、比較的固定されたカラーキーです。実際のデータセットから学習した値のペアです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Pronoun-Targeted Fine-tuning for NMT with Hybrid Losses -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_0.html">
      <font color="black">Pronoun-Targeted Fine-tuning for NMT with Hybrid Losses</font>
    </a>
  </h2>
  <font color="black">で入手可能なコード<https://github.com/ntunlp/pronoun-finetuning>..センテンスレベルモデルは、WMT14とIWSLT13De-Enテストセットの両方で0.5BLEUの改善を示していますが、コンテキストモデルは、WMT14De-Enテストセットで31.81から32BLEUに、32.10からIWSLT13 De-Enテストセットの33.13、それに対応する代名詞翻訳の改善。微調整を通じて代名詞翻訳の改善を目標とし、代名詞ベンチマークテストセットでモデルを評価します。 
[概要]細かいレベルのテストによる代名詞翻訳の改善。代名詞モデルを改善するには、結果が必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchical Poset Decoding for Compositional Generalization in Language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_1.html">
      <font color="black">Hierarchical Poset Decoding for Compositional Generalization in Language</font>
    </a>
  </h2>
  <font color="black">提案されたデコーダーを、構成の一般化を測定するために特別に設計された、大きくて現実的な自然言語の質問応答データセットである、Compositional Freebase Questions（CFQ）で評価します。注文情報にバイアスをかける。 （2）階層メカニズムにより、ポセットの高レベルの構造をキャプチャできます。出力が半順序集合（ポセット）である構造化された予測タスクとして、人間の言語理解を形式化します。 
[ABSTRACT]デコーダーアーキテクチャは、ポセット構造を適切に考慮していません。これは、構成の一般化能力が低いためであると言われています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Improvised Chatbots from Adversarial Modifications of Natural
  Language Feedback -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_2.html">
      <font color="black">Learning Improvised Chatbots from Adversarial Modifications of Natural
  Language Feedback</font>
    </a>
  </h2>
  <font color="black">これらの変更されたフィードバック応答で元のトレーニングデータを拡張すると、Personachatデータセットでの正しい応答のランク付けで元のチャットボットのパフォーマンスが69.94％から75.96％に向上することを示します。これは、元のモデルがすでに131kのサンプルでトレーニングされていることを考えると大幅に改善されています。目標は、フィードバックをユーザーの以前の発話に応答する応答に変換し、フィードバックを自然な応答と区別する識別器をだますことです。ただし、ほとんどの場合、ユーザーフィードバックには、トレーニングサンプルとしての有用性を妨げる無関係なシーケンスが含まれています。 
[概要]ほとんどの場合、ユーザーフィードバックには、トレーニングサンプルとしての有用性に不満がある無関係なシーケンスが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Better Representation for Tables by Self-Supervised Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_3.html">
      <font color="black">Learning Better Representation for Tables by Self-Supervised Tasks</font>
    </a>
  </h2>
  <font color="black">前者は、数値のサイズプロパティをテーブル表現に組み込むのに役立つ列ディメンションに取り組んでいます。これらは、コンテンツの選択と計画、および補助監視に基づく一部のメソッドに誤った監視信号を与える可能性があります。実験結果は、モデルが一緒にトレーニングされたことを示しています。これらの2つの自己監視タスクを使用すると、コンテキストの選択と計画をモデル化せずに、より顕著でよく整理された事実を含むテキストを生成できます。 
[概要]新しいアプローチは、これらに対して特別な扱いをせず、自然言語テキストの単語と見なします。これらは、コンテンツの選択と計画、および補助的な監視に基づいて、一部の方法に誤った監視信号を与える可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Calibration of Pre-trained Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_4.html">
      <font color="black">Calibration of Pre-trained Transformers</font>
    </a>
  </h2>
  <font color="black">この作業ではBERTとRoBERTaに焦点を当て、自然言語の推論、言い換えの検出、常識的な推論の3つのタスクにわたってそれらのキャリブレーションを分析します。（1）すぐに使用できる場合、事前にトレーニング済みモデルはドメイン内でキャリブレーションされ、ベースラインと比較して、ドメイン外のキャリブレーションエラーは3.5分の1になります。 （2）温度スケーリングは、ドメイン内のキャリブレーションエラーをさらに減らすのに効果的であり、ラベル平滑化を使用して経験的不確実性を意図的に増加させると、ドメイン外の事後確率をキャリブレーションするのに役立ちます。各タスクについて、ドメイン内とチャレンジアウトを検討します。 of-domain設定。モデルがより多くの例に直面する場合、不確実である必要があります。 
[概要]各タスクについて、ドメイン内での設定とドメイン外での設定を検討します。モデルは、不確実であるはずのより多くの例に直面します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-17">
        <br><font color="black">2020-03-17</font>
      </time>
    </span>
</section>
<!-- paper0: GMH: A General Multi-hop Reasoning Model for KG Completion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_5.html">
      <font color="black">GMH: A General Multi-hop Reasoning Model for KG Completion</font>
    </a>
  </h2>
  <font color="black">長距離推論には2つの重要な問題があると主張します：i）どちらのエッジを選択するか、ii）いつ検索を停止するか..この作業では、3つのモジュールで問題を解決する一般的なモデルを提案します：1）可能なパスを推定するためのローカル-グローバルナレッジモジュール、2）パスの多様なセットを探索するための差別化されたアクションドロップアウトモジュール、および3）過剰検索を回避するための適応停止検索モジュール..3つのデータセットの包括的な結果は、短距離と長距離の両方の推論シナリオでベースラインに対して大幅に改善されたモデル。 
[概要]短いシナリオと長いシナリオの両方でマルチホップ推論を理解するには長い道のりがあります。これはマルチホップ通信タスクに関する研究努力の結果です。現在のモデルは通常、短距離推論を実行します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Continual Learning for Neural Semantic Parsing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_6.html">
      <font color="black">Continual Learning for Neural Semantic Parsing</font>
    </a>
  </h2>
  <font color="black">結果として得られるパフォーマンスは、完全なデータセットでゼロからトレーニングされたモデルと同等です。古いモデルの特定の微調整手順を使用した単純なアプローチにより、のトレーニングと比較して計算コストを最大90％削減できることを示します。新しいモデル..2つの人気のあるセマンティック解析データセット、FacebookTOPとSNIPSでのアプローチの有効性を紹介します。 
[概要]古いモデルの単純なアプローチにより、新しいモデルのトレーニングと比較してコストを90％削減できることを示しました。2つの人気のあるセマンティック解析データセット、facebook top、およびsnipsに対するアプローチの有効性を示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Where's the Question? A Multi-channel Deep Convolutional Neural Network
  for Question Identification in Textual Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_7.html">
      <font color="black">Where's the Question? A Multi-channel Deep Convolutional Neural Network
  for Question Identification in Textual Data</font>
    </a>
  </h2>
  <font color="black">提案されたQuest-CNNは、透析ケア設定でのデータ入力レビューダイアログのデータセットと一般的なドメインデータセットの両方で最高のF1スコアを達成しました。これを「c-questions」と呼びます。質問文を検出するための従来のルールベースおよび学習ベースの方法のパフォーマンスを評価しました。 
[概要]新しい研究では、マルチチャネルの深いコンギショナルネットワークアーキテクチャが提案されています。quest-cnnと呼ばれ、質問ではない文から実際の質問を分離することを目的としています。これらには、近くの文で言及されている問題に関する質問が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: PublishInCovid19 at WNUT 2020 Shared Task-1: Entity Recognition in Wet
  Lab Protocols using Structured Learning Ensemble and Contextualised
  Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_8.html">
      <font color="black">PublishInCovid19 at WNUT 2020 Shared Task-1: Entity Recognition in Wet
  Lab Protocols using Structured Learning Ensemble and Contextualised
  Embeddings</font>
    </a>
  </h2>
  <font color="black">個々のモデルは、完全なデータセットのランダムなトレイン検証分割でトレーニングされます。部分一致と完全一致の観点から、それぞれ1位と2位にランク付けされました。このアプローチは2つのフェーズで構成されています。 
[ABSTRACT]第2フェーズでは、11個のbilstm-crfモデルで構成されるアンサンブルを作成します。これらのモデルは、多数決を含むさまざまなタスクでトレーニングされます。これらには、多数決と構造化学習のアンサンブルが含まれます（sle）。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Natural Language Inference Models Partially Embed Theories of
  Lexical Entailment and Negation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_9.html">
      <font color="black">Neural Natural Language Inference Models Partially Embed Theories of
  Lexical Entailment and Negation</font>
    </a>
  </h2>
  <font color="black">私たちの行動評価では、汎用NLIデータセットでトレーニングされたモデルは、否定を含むMoNLIの例では体系的に失敗しますが、MoNLIの微調整はこの失敗に対処します。プローブはこの結論と一致する証拠を生成し、介入実験はこれを強化します。モデルの因果的ダイナミクスが、MoNLIのサブセットに対するこのアルゴリズムの因果的ダイナミクスを反映していることを示しています。これは、BERTモデルがアルゴリズムレベルで字句含意と否定の理論を少なくとも部分的に組み込んでいることを示唆しています。 
[ABSTRACT] monliは、語彙含意と否定に焦点を当てた新しい自然主義データセットです。monliの調査によると、bertモデルはmonliの助けを実装することを学びました。monliモデルはmonliのmonliの使用に基づいています。機械</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: Wasserstein Distance Regularized Sequence Representation for Text
  Matching in Asymmetrical Domains -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_10.html">
      <font color="black">Wasserstein Distance Regularized Sequence Representation for Text
  Matching in Asymmetrical Domains</font>
    </a>
  </h2>
  <font color="black">WD-Matchは、基礎となるマッチングモデルとしてメソッドを使用することにより、さまざまなテキストマッチングメソッドを改善するために使用できます。非対称ドメインからのテキストをマッチングする1つのアプローチは、マッチング関数が使用される特徴ベクトルとして入力シーケンスを共通の意味空間に投影することです。簡単に定義して学習することができます。4つの公開されているベンチマークに基づく実験結果は、WD-Matchが基礎となるメソッドとベースラインを一貫して上回っていることを示しました。 
[概要]練習には、wd --matchと呼ばれる関数の使用が含まれます。関数ベースの正則化は、さまざまなドメインの機能を正則化するために定義されます。この方法は、4つの一般的なテキストマークに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: "Did you really mean what you said?" : Sarcasm Detection in
  Hindi-English Code-Mixed Data using Bilingual Word Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_11.html">
      <font color="black">"Did you really mean what you said?" : Sarcasm Detection in
  Hindi-English Code-Mixed Data using Bilingual Word Embeddings</font>
    </a>
  </h2>
  <font color="black">そのようなものの1つがソーシャルメディアテキストでの皮肉の検出です。FastTextとWord2Vecのアプローチから派生したバイリンガルの単語埋め込みを使用して、ヒンディー語と英語のコード混合ツイートでの皮肉検出の問題に対処するためのディープラーニングベースのアプローチを提案します。世界中の人々によるソーシャルメディアプラットフォームの使用により、多くの新しい興味深いNLP問題が発生しています。 
[概要]ヒンディー語での皮肉検出の問題に対処するためのディープラーニングベースのアプローチを提案します-バイリンガルの単語埋め込みを使用した英語のコード混合ツイート</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-01">
        <br><font color="black">2020-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: DialogueTRM: Exploring the Intra- and Inter-Modal Emotional Behaviors in
  the Conversation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_12.html">
      <font color="black">DialogueTRM: Exploring the Intra- and Inter-Modal Emotional Behaviors in
  the Conversation</font>
    </a>
  </h2>
  <font color="black">イントラモーダルの場合、各モダリティ内の差別化されたコンテキスト設定に従って、シーケンシャル構造とフィードフォワード構造を簡単に切り替えることができる新しい階層トランスフォーマーを構築します。したがって、イントラモーダルとインターモーダルの視点..インターモーダルの場合、ニューロンとベクトルの両方のグレイン機能の相互作用を適用して、すべてのモダリティにわたる差別化された貢献を学習する、新しいマルチグレインインタラクティブフュージョンを構成します。 
[ABSTRACT] ercのdialoguetransformerは、モーダル内およびモーダル間での明確なマルチパラル動作を調査します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Natural Language Processing Tasks with Human Gaze-Guided
  Neural Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_13.html">
      <font color="black">Improving Natural Language Processing Tasks with Human Gaze-Guided
  Neural Attention</font>
    </a>
  </h2>
  <font color="black">私たちの共同モデルは、Quora Question Pairsコーパスでの言い換え生成の最先端をBLEU-4で10％以上上回り、挑戦的なGoogle SentenceCompressionコーパスでの文圧縮の最先端のパフォーマンスを達成することを示しています。 ..さらに、タスク固有の人間の視線データを必要とせずに、特定のアップストリームNLPタスク用に設計されたネットワークのアテンションレイヤーにTSM予測を統合するための新しいジョイントモデリングアプローチを提案します。4つの異なるコーパスで、ハイブリッドを実証します。 TSM期間の予測は、人間の視線のグラウンドトゥルースと高度に相関しています。 
[概要]新しいモデルは、単一の機械学習フレームワークで、読書の認知モデルと明示的な人間の視線監視を組み合わせたものです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Response Selection for Multi-Party Conversations withDynamic Topic
  Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_14.html">
      <font color="black">Response Selection for Multi-Party Conversations withDynamic Topic
  Tracking</font>
    </a>
  </h2>
  <font color="black">また、Topic-BERTは、自己教師あり学習を使用してトピック情報をBERTに埋め込むための重要な事前トレーニングステップを提案します。DSTC-8UbuntuIRCデータセットの実験結果は、応答の選択とトピックの解きほぐしタスクのパフォーマンスを上回る最先端の結果を示しています。十分なマージンを持って既存の方法..この新しい定式化により、動的なトピックの解きほぐしと応答の選択を実行するために、一度に2つの発話のみで大規模な事前トレーニング済みモデルによる効率的なエンコーディングをサポートする新しいマルチタスク学習フレームワークを提案します。 
[概要]会話トピックの延長と遷移は現在の方法では無視されます。さらに、効率化をサポートする新しいマルチタスク学習フレームワークを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Semantic Label Smoothing for Sequence to Sequence Problems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_15.html">
      <font color="black">Semantic Label Smoothing for Sequence to Sequence Problems</font>
    </a>
  </h2>
  <font color="black">seq2seq設定の既存のアプローチのほとんどは、トークンレベルの平滑化を行うか、ターゲットシーケンスのトークンをランダムに置き換えることによって生成されたシーケンスを平滑化します。これらの作業とは異なり、このペーパーでは、\ emph {整形式}の関連シーケンスを平滑化する手法を提案します。これは、ターゲットシーケンスと十分なn-gramオーバーラップがあるだけでなく、\ emph {意味的に類似}しています。ただし、このようなメソッドをMachine Translationなどのseq2seq設定に直接拡張することは困難です。たとえば、このような大きなターゲット出力スペース問題があると、考えられるすべての出力にラベルスムージングを適用するのが困難になります。 
[ABSTRACT]このような問題のターゲット出力スペースが大きいため、すべての可能な出力にラベル平滑化を適用するのは困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Grammatical Error Correction in Low Error Density Domains: A New
  Benchmark and Analyses -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_16.html">
      <font color="black">Grammatical Error Correction in Low Error Density Domains: A New
  Benchmark and Analyses</font>
    </a>
  </h2>
  <font color="black">この背後にある要因は、システムが低エラー密度ドメインで強力な内部言語モデルに依存できないことであることを示しています。文法エラー修正（GEC）システムの評価は、主に英語の非ネイティブ学習者によって書かれたエッセイに焦点を当てています。ただし、これはGECアプリケーションの全範囲の一部にすぎません。この作業により、さまざまなトピックやジャンルに一般化するオープンドメインGECモデルの開発が容易になることを願っています。 
[概要] gecのターゲットドメインを拡大し、gecの新しいベンチマークであるcwebをリリースすることを目指しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Pretrained Language Models for Dialogue Generation with Multiple Input
  Sources -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_17.html">
      <font color="black">Pretrained Language Models for Dialogue Generation with Multiple Input
  Sources</font>
    </a>
  </h2>
  <font color="black">以前の作業は、すべての入力ソースを連結するか、さまざまな入力ソースからの情報を平均化するだけです。大規模な事前トレーニング済み言語モデルは、自然言語理解タスクで卓越したパフォーマンスを実現しました。 
[概要]この作品では、事前に訓練された言語モデルgpt2から適応された複数の入力ソースを使用した対話モデルを研究します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Deepfake Detection with Factual Structure of Text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_18.html">
      <font color="black">Neural Deepfake Detection with Factual Structure of Text</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、与えられたドキュメントの事実上の構造をエンティティグラフとして表し、グラフニューラルネットワークで文の表現を学習するためにさらに利用されます。しかし、それらは、マシンで生成されたものを区別する要因であるドキュメントの事実上の構造をキャプチャするのに苦労します。統計分析によると、人間が書いたテキスト。次に、文の表現は、予測を行うためのドキュメント表現に構成され、隣接する文間の一貫した関係が順次モデル化されます。 
[ABSTRACT]ディープフェイク検出は既存の構造に基づいています。これらの構造はグラフベースのモデルに基づいています。ネットワーク表現はドキュメントに区別して構成されます。結果は、事実上の構造が人間が書いたテキストを区別できることを示唆しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Constituency Parsing with Span Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_19.html">
      <font color="black">Improving Constituency Parsing with Span Attention</font>
    </a>
  </h2>
  <font color="black">さらに、異なる長さのカテゴリ内のn-gramに重みを付けることでモデルをさらに強化し、長い文の解析に役立つカテゴリスパンの注意を提案します。広く使用されている3つのベンチマークデータセットの実験結果は、アラビア語、中国語の解析におけるアプローチの有効性を示しています、および英語。これらすべてに対するアプローチによって最先端のパフォーマンスが得られます。構成要素の構文解析は、自然言語を理解するための基本的かつ重要なタスクであり、コンテキスト情報の適切な表現がこのタスクに役立ちます。 
[概要]解析プロセスへの寄与に応じて重み付けすることにより、スパン表現にnグラムを組み込みます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Inducing Alignment Structure with Gated Graph Attention Networks for
  Sentence Matching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_20.html">
      <font color="black">Inducing Alignment Structure with Gated Graph Attention Networks for
  Sentence Matching</font>
    </a>
  </h2>
  <font color="black">実験結果は、私たちの方法が自然言語と言い換えの識別のタスク全体で2つのデータセットで最先端のパフォーマンスを実質的に達成することを示しています。最初に、いくつかの慎重に設計された戦略を持つグラフとして文のペアを表します。私たちのモデルは意味のあるグラフ構造を学習でき、解釈性の向上に対する優位性を示しています。 
[概要]最新のアプローチでは、注意ベースのニューラルモデルを採用して、2つの文の間に単語またはフレーズレベルのアラインメントを構築します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Does Chinese BERT Encode Word Structure? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_21.html">
      <font color="black">Does Chinese BERT Encode Word Structure?</font>
    </a>
  </h2>
  <font color="black">注意の重み分布統計とプロービングタスクの両方を使用して中国語のBERTを調査し、次のことを発見しました。（1）単語情報がBERTによってキャプチャされている。 （2）単語レベルの機能は、ほとんどが中間表現レイヤーにあります。 （3）ダウンストリームタスクは、BERTの単語機能をさまざまに使用し、POSタグ付けとチャンクは単語機能に最も依存し、自然言語推論はそのような機能に最も依存しません。既存の作業では、構文、意味、および単語感覚の知識がBERTでエンコードされます。ただし、中国語などの文字ベースの言語の単語の特徴を調査した研究はほとんどありません。 
[概要] 1,000以上の単語が言語認識のために分析されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Named Entity Recognition and Relation Extraction using Enhanced Table
  Filling by Contextualized Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_22.html">
      <font color="black">Named Entity Recognition and Relation Extraction using Enhanced Table
  Filling by Contextualized Representations</font>
    </a>
  </h2>
  <font color="black">その単純さにもかかわらず、実験結果は、提案された方法がCoNLL04およびACE05英語データセットの最先端の方法よりも優れていることを示しています。また、テンソル内積を適応させて、履歴に頼ることなく、関係ラベルを一度に予測します。ベースの予測または検索戦略..また、コンテキスト集約のために複数の文が提供されている場合、提案された方法がACE05データセットの最先端のNERモデルと同等のパフォーマンスを達成することを確認します。 
[概要]提案された方法は、文脈化された単語の埋め込みに基づいています。これは、ace05データセットの最先端のモデルと同等のパフォーマンスを提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Bridging Information-Seeking Human Gaze and Machine Reading
  Comprehension -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_23.html">
      <font color="black">Bridging Information-Seeking Human Gaze and Machine Reading
  Comprehension</font>
    </a>
  </h2>
  <font color="black">この発見を動機として、読解中の人間の情報探索行動を模倣することにより、自動読解をより人間らしいものにすることを提案します。この作業では、読解中の人間の視線が与えられた読解質問にどのように条件付けられるかを分析します。この信号が機械の読解に有益であるかどうか。この目的のために、複数の選択肢の読解タスクに従事する多数の参加者を含む新しい視線追跡データセットを収集します。 
[概要]私たちは、自動読解をより人間的なものにすることを提案します-その人間の情報を模倣することによって-読解中の読解行動を求めます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-30">
        <br><font color="black">2020-09-30</font>
      </time>
    </span>
</section>
<!-- paper0: Reliable Evaluations for Natural Language Inference based on a Unified
  Cross-dataset Benchmark -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_24.html">
      <font color="black">Reliable Evaluations for Natural Language Inference based on a Unified
  Cross-dataset Benchmark</font>
    </a>
  </h2>
  <font color="black">14個のNLIデータセットを使用した新しい統合クロスデータセットベンチマークを提示し、広く使用されている9つのニューラルネットワークベースのNLIモデルと、最近提案された5つのアノテーションアーティファクトのバイアス除去方法を再評価します。信頼できる評価設定とベンチマークの欠如NLI研究の進捗状況..提案された評価スキームと実験ベースラインは、将来の信頼できるNLI研究を刺激するための基礎を提供する可能性があります。 
[要約]新しい論文は、クロスデータセット評価を使用してモデルの信頼できる一般化パフォーマンスを評価することを提案しています。提案されたデータセットは、記念日研究の基礎を提供する可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Compressive Summarization with Plausibility and Salience Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_25.html">
      <font color="black">Compressive Summarization with Plausibility and Salience Modeling</font>
    </a>
  </h2>
  <font color="black">単純な抽出-圧縮パイプラインに統合すると、私たちの方法はベンチマーク要約データセットで強力なドメイン内結果を達成し、人間の評価は、妥当性モデルが一般に文法的および事実上の削除を選択することを示しています。スパンを削除すると、文の文法性と事実性、およびスパンは、要約からの重要な情報が含まれている場合に顕著です。これらはそれぞれ、事前にトレーニングされたTransformerモデルによって判断され、もっともらしく、顕著ではない削除のみを適用できます。 
[概要]カリフォルニア大学の研究では、候補スパンの厳密な構文上の制約を緩和することが提案されています。代わりに、もっともらしく、目立たない削除を適用できます。モデルは、削除の範囲で実行でき、削除は目立たない</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Fine-Tuning Pre-trained Language Model with Weak Supervision: A
  Contrastive-Regularized Self-Training Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_26.html">
      <font color="black">Fine-Tuning Pre-trained Language Model with Weak Supervision: A
  Contrastive-Regularized Self-Training Approach</font>
    </a>
  </h2>
  <font color="black">対照的な正則化と信頼性に基づく再重み付けに支えられたこの対照的な自己トレーニングフレームワークは、エラーの伝播を効果的に抑制しながら、モデルの適合を徐々に改善できます。シーケンス、トークン、および文のペアの分類タスクの実験は、モデルが最強のベースラインを大幅に上回っていることを示しています。 6つのタスクで7つのベンチマークを実行し、完全に監視された微調整方法で競争力のあるパフォーマンスを実現します。微調整された事前トレーニング済み言語モデル（LM）は、多くの自然言語処理（NLP）タスクで大きな成功を収めますが、それでも過剰な処理が必要です。微調整段階でのラベル付きデータ。 
[概要] fine-msの問題は、ラベル付けされたデータがなく、弱い監視に基づいています。これは問題のためであり、対照的な自己トレーニングフレームワークであるコサインを開発します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: The Language of Food during the Pandemic: Hints about the Dietary
  Effects of Covid-19 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_27.html">
      <font color="black">The Language of Food during the Pandemic: Hints about the Dietary
  Effects of Covid-19</font>
    </a>
  </h2>
  <font color="black">まず、封鎖中に健康食品の言及から不健康な食品への顕著な変化があったことを観察します。米国でのパンデミック封鎖中にTwitterで食品の言語を調査し、3月15日から2か月の期間に焦点を当てます。 2020年5月15日..次に、封鎖中に投稿された食品関連のツイートを含むうつ病ハッシュタグのポイントごとの相互情報の増加と、封鎖中のうつ病ハッシュタグと不健康な食品、タバコ、アルコールとの関連性の増加を示します。 
[概要]封鎖中に公開された77万件を超えるツイートと過去5年間の同等の期間を分析します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Context-Guided BERT for Targeted Aspect-Based Sentiment Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_28.html">
      <font color="black">Context-Guided BERT for Targeted Aspect-Based Sentiment Analysis</font>
    </a>
  </h2>
  <font color="black">2つの（T）ABSAデータセットで事前トレーニングされたBERTを使用して両方のモデルをトレーニングします：SentiHoodとSemEval-2014（タスク4）。私たちの仕事は、コンテキストの事前トレーニングされた自己注意ベースの言語モデルにコンテキスト依存関係を追加することの有用性の証拠を提供します。ベースの自然言語タスク..最初に、コンテキスト認識トランスフォーマーを適応させて、コンテキストガイド付きsoftmax-attentionを使用するCG-BERTを生成します。 
[概要]コンテキストcgの2つのバリエーションを提案します-異なる状況下で注意を分散することを学ぶバート。事前に訓練された自己苦しみを持つ同様のモデルも、新しい最先端の結果を達成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Phonemer at WNUT-2020 Task 2: Sequence Classification Using COVID
  Twitter BERT and Bagging Ensemble Technique based on Plurality Voting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_29.html">
      <font color="black">Phonemer at WNUT-2020 Task 2: Sequence Classification Using COVID
  Twitter BERT and Bagging Ensemble Technique based on Plurality Voting</font>
    </a>
  </h2>
  <font color="black">最終的なアプローチでは、F1スコアが0.9037に達し、評価基準としてF1スコアを使用して全体で6位にランク付けされました。続いて、CNN、RNN、トランスフォーマーベースのモデルなどの複数の深層学習モデルを実験しました。 EMNLP WNUT-2020共有タスク2に取り組むために採用したアプローチ：有益なCOVID-19英語ツイートの特定。 
[概要]タスクは、新しいコロナウイルスに関連する英語のツイートが有益であるかどうかを自動的に識別するシステムを開発することです。最初の段階では、関連情報のみをフィルタリングしてデータセットを前処理します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-01">
        <br><font color="black">2020-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: RNNs can generate bounded hierarchical languages with optimal memory -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_30.html">
      <font color="black">RNNs can generate bounded hierarchical languages with optimal memory</font>
    </a>
  </h2>
  <font color="black">最後に、無制限の計算を使用しても、$ o（m \ log k）$の隠れユニットでは十分なアルゴリズムがないことを示します。$ O（m \ log k）$の隠れユニットを持つRNNで十分であり、指数関数的であることを証明します。明示的な構成によるメモリの削減。最もよく知られている結果は、$ O（k ^ {\ frac {m} {2}}）$メモリ（非表示の単位）を使用してこれらの言語を生成します。 
[ABSTRACT] dyckは、適切にネストされたブラケットの言語であり、dyck.dyckにあります。明示的な構造により、$ o（m）$の非表示単位を持つrnnで十分であり、メモリへの洞察が得られると説明しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Sequence Labeling vs. Clause Classification for English Emotion Stimulus
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_31.html">
      <font color="black">Sequence Labeling vs. Clause Classification for English Emotion Stimulus
  Detection</font>
    </a>
  </h2>
  <font color="black">これまでのところ、設定（3）は北京語で、（2）は英語で広く評価されていますが、比較は行われていません。これを実現するために、2つの異なるアプローチを比較可能に評価できる統合フレームワークを提案し、モデルを実装します。北京語の最先端のアプローチに触発され、異なるドメインの4つの英語データセットでテストします。私たちの結果は、句ベースとシーケンスベースの両方で、4つのデータセットのうち3つでシーケンスラベリングが優れていることを示しています。評価。 
[概要]私たちは、句の分類またはシーケンスのラベル付けが英語での感情刺激の説明に適しているかどうかに答えることを目指しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: The LL(finite) strategy for optimal LL(k) parsing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_32.html">
      <font color="black">The LL(finite) strategy for optimal LL(k) parsing</font>
    </a>
  </h2>
  <font color="black">この戦略は、入力を線形時間で解析し、非終端記号の選択肢を明確にするために必要な任意の、しかし常に最小限の先読みを使用し、実行される先読み端末スキャンの数に最適です。LL（k）の解析のためのLL（有限）解析戦略。 kを知る必要のない文法が提示されます。優先順位による文法のあいまいさの解決（入力を構文解析式の文法として効果的に解釈すること）、および述語の使用を可能にするアルゴリズムの変更が示されています。概念の証明であるオープンソースパーサージェネレーターAstirは、生成する出力にLL（有限）戦略を採用しています。 
[要約]この戦略では、最小限の先読みを使用して、非終端記号の選択肢を明確にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Task Learning for Cross-Lingual Abstractive Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_33.html">
      <font color="black">Multi-Task Learning for Cross-Lingual Abstractive Summarization</font>
    </a>
  </h2>
  <font color="black">さらに、中国語-英語およびアラビア語-英語の抽象要約で最高のROUGEスコアを達成します。一方、翻訳ペアや単言語の抽象要約データなどの既存の本物のデータをトレーニングに導入します。さらに、Transumは機械翻訳。 
[ABSTRACT]新しいメソッドtransumは、入力文の先頭に特別なトークンを付加して、ターゲットタスクを示します。実験結果は、transumが、疑似舌間要約データのみでトレーニングされたモデルよりも優れたパフォーマンスを達成することを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: DaNetQA: a yes/no Question Answering Dataset for the Russian Language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_34.html">
      <font color="black">DaNetQA: a yes/no Question Answering Dataset for the Russian Language</font>
    </a>
  </h2>
  <font color="black">タスク転送では、3つの類似した文モデリングタスクを活用します：1）言い換えのコーパス、言い換え、2）XNLIのロシア語部分を使用するNLIタスク、3）別の質問応答タスク、SberQUAD ..言語転送では英語からロシア語への翻訳と多言語言語の微調整を使用します。各質問は、Wikipediaの段落と、その段落から派生した回答とペアになっています。 
[概要]自然な「はい」または「いいえ」の質問で構成されます。タスクは、質問と段落の両方を入力として受け取ることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: NUIG-Shubhanker@Dravidian-CodeMix-FIRE2020: Sentiment Analysis of
  Code-Mixed Dravidian text using XLNet -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_35.html">
      <font color="black">NUIG-Shubhanker@Dravidian-CodeMix-FIRE2020: Sentiment Analysis of
  Code-Mixed Dravidian text using XLNet</font>
    </a>
  </h2>
  <font color="black">ソーシャルメディアは多言語社会に浸透していますが、ほとんどのメディアはコミュニケーションの優先言語として英語を使用しています。したがって、会話中に文化言語と英語を混合すると、多言語データが豊富になります。これをコード混合と呼びます。このようなデータを使用するダウンストリームNLPタスクは、複数の言語に分散しているため、セマンティックな性質があるため困難です。このような自然言語処理タスクの1つは感情分析です。このため、自動回帰XLNetモデルを使用してコードが混在するタミル語-英語およびマラヤラム-英語のデータセットに対して感情分析を実行します。 
[概要]会話中にあなたの文化的言語を英語と英語と混ぜ合わせます。データは今日の世界で利用可能です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Tokenization Repair in the Presence of Spelling Errors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_36.html">
      <font color="black">Tokenization Repair in the Presence of Spelling Errors</font>
    </a>
  </h2>
  <font color="black">与えられたテキストからすべてのスペースを削除すると（前の作業のシナリオ）、精度はそれぞれ94.5％と90.1％に低下します。トークン化の修復とスペル修正は別々の問題として扱う必要があり、扱うことができると主張します。高品質のトークン化修復の3つの主要な要素を特定します。双方向コンポーネントを使用した深い言語モデル、スペルミスのあるテキストでモデルをトレーニングすること、およびすでに存在するスペース情報を利用することです。 
[概要]この問題をスペル修正の特殊なケースと考えたくなります。さまざまなニューラルモデルと多数の強力なベースラインを調査します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Anchor & Transform: Learning Sparse Embeddings for Large Vocabularies -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_37.html">
      <font color="black">Anchor & Transform: Learning Sparse Embeddings for Large Vocabularies</font>
    </a>
  </h2>
  <font color="black">ANTはスケーラブルで柔軟性があり、エンドツーエンドでトレーニング可能です。テキスト、ユーザー、映画、URLなどの個別のオブジェクトの継続的な表現を学習することは、言語やユーザーモデリングを含む多くのアプリケーションの中心にあります。その結果、既存のメソッドは、大きな語彙サイズにスケーリングしません。 
[ABSTRACT]その結果、既存のメソッドは大きな語彙サイズにスケーリングされません。メソッドをアンカー＆トランスフォーム（ant）と呼びます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br><font color="black">2020-03-18</font>
      </time>
    </span>
</section>
<!-- paper0: Natural Language Rationales with Full-Stack Visual Reasoning: From
  Pixels to Semantic Frames to Commonsense Graphs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_38.html">
      <font color="black">Natural Language Rationales with Full-Stack Visual Reasoning: From
  Pixels to Semantic Frames to Commonsense Graphs</font>
    </a>
  </h2>
  <font color="black">私たちの実験は、基本的な事前訓練された言語モデルが視覚的適応の恩恵を受け、フリーテキストの合理化が複雑な視覚的テキストの推論タスクのモデル解釈可能性を補完する有望な研究の方向性であることを示しています。複雑な視覚的推論タスク：視覚的常識的推論、視覚的テキストの含意、視覚的質問への回答..正確な合理化の重要な課題は、すべてのレベルでの包括的な画像理解です。ピクセルレベルでの明示的なコンテンツだけでなく、セマンティックおよび実用的なレベル。 
[要約]いくつかの複雑な視覚的推論タスクにわたって自然言語の理論的根拠を生成することに焦点を当てた最初の研究</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Dataset Cartography: Mapping and Diagnosing Datasets with Training
  Dynamics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_39.html">
      <font color="black">Dataset Cartography: Mapping and Diagnosing Datasets with Training
  Dynamics</font>
    </a>
  </h2>
  <font color="black">これにより、各例について2つの直感的な測定値が得られます---真のクラスに対するモデルの信頼度と、エポック間でのこの信頼度の変動性---トレーニングの1回の実行で取得されます。 「分布外の一般化に最も貢献するモデルに関する領域。4つのデータセットにわたる実験は、これらのモデル依存の測定値が、データマップ内の3つの異なる領域を明らかにし、それぞれが顕著な特性を持っていることを示しています。 
[要約]調査：データマップの作成には、ほとんど無視されている情報源を使用しています。データ量に焦点を合わせると、データの品質を評価することが困難になったと彼は言います。しかし、マップに焦点を合わせると、堅牢なモデルにつながる可能性があると彼は言います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Bitext Mining and Translation via Self-trained Contextual
  Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_40.html">
      <font color="black">Unsupervised Bitext Mining and Translation via Self-trained Contextual
  Embeddings</font>
    </a>
  </h2>
  <font color="black">多言語BERTを使用して、最近傍検索用のソース文とターゲット文の埋め込みを作成し、自己トレーニングを介してモデルを適応させます。教師なし方法を説明して、整列されていないテキストから機械翻訳（MT）用の疑似並列コーパスを作成します。 IWSLT&#39;15の英語とベトナム語のコーパスを、疑似並列Wikipediaの文のペアで強化し、低リソースのMTタスクで1.2BLEUの改善を実現します。 
[概要]教師なしbitextマイニングがmtデータセットを拡張する効果的な方法であることを示しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Utility is in the Eye of the User: A Critique of NLP Leaderboards -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_41.html">
      <font color="black">Utility is in the Eye of the User: A Critique of NLP Leaderboards</font>
    </a>
  </h2>
  <font color="black">このフレーミングを使用して、リーダーボード（現在の形式）がNLPコミュニティ全体のプロキシとしてどのように機能しないかを形式化します。この意見書では、リーダーボードによってインセンティブが与えられるものと実際に役立つものとの相違を調査します。ミクロ経済理論のレンズ..私たちは、リーダーボードとNLPの実践者の両方を消費者として、そしてモデルから得られる利益をその有用性として組み立てます。 
[概要] adam hanley：リーダーボードとnlpプラクティショナーの両方を消費者としてフレーム化します。たとえば、非常に非効率的なモデルは、プラクティショナーにはあまり有用ではありませんが、リーダーボードには提供されません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-29">
        <br><font color="black">2020-09-29</font>
      </time>
    </span>
</section>
<!-- paper0: Discrete Word Embedding for Logical Natural Language Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_42.html">
      <font color="black">Discrete Word Embedding for Logical Natural Language Understanding</font>
    </a>
  </h2>
  <font color="black">単語の個別の埋め込みを学習するための教師なしニューラルモデルを提案します。これにより、埋め込みは、シンボリックで最先端の古典的な計画ソルバーと直接互換性があります。私たちの埋め込みは、各単語を、古典的な遷移ルールを説明する一連の提案ステートメントとして表します。 / STRIPS計画形式。 
[概要]バイナリ埋め込みは、連続形式計画ソルバーと同様のシステムをサポートします。これにより、埋め込みは、シンボリックで最先端の古典的な計画ソルバーと直接互換性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-26">
        <br><font color="black">2020-08-26</font>
      </time>
    </span>
</section>
<!-- paper0: Diverse Keyphrase Generation with Neural Unlikelihood Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_43.html">
      <font color="black">Diverse Keyphrase Generation with Neural Unlikelihood Training</font>
    </a>
  </h2>
  <font color="black">私たちのバージョンのULトレーニングは、（1）ターゲットトークンレベルで動作し、繰り返しトークンの生成を阻止します。 （2）ソーステキストから繰り返しトークンをコピーしないようにするためのコピートークンレベル。この問題を軽減するために、S2Sモデルのトレーニングにニューラル尤度（UL）目標を採用します。ニューラル自然言語生成の最近の進歩により、目覚ましい進歩が可能になりました。 F1スコアなどの品質指標の改善を通じて実証された、キーフレーズ生成のタスクについて。 
[概要]ニューラル自然言語生成の最近の進歩により、キーフレーズ生成のタスクが進歩しました。まず、キーフレーズモデルによって生成された出力に存在する情報の冗長性の程度を分析します。この問題を軽減するために、ニューラルの可能性を採用します（ul） s2sモデルのトレーニングの目的</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Dual Inference for Improving Language Understanding and Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_44.html">
      <font color="black">Dual Inference for Improving Language Understanding and Generation</font>
    </a>
  </h2>
  <font color="black">3つのベンチマークデータセットでの実験は、NLUとNLGの両方で提案された方法の有効性を示し、実用化の大きな可能性を提供します。ただし、現在のNLP領域で急成長しているモデルの規模に関しては、再トレーニングが難しい場合があります。 NLUモデル全体とNLGモデル..自然言語理解（NLU）タスクと自然言語生成（NLG）タスクは、強い二重の関係を持っています。NLUは自然言語の発話に基づいてセマンティックラベルを予測することを目的としており、NLGはその逆です。 
[概要]前の作業は主にトレーニングの二重性の活用に焦点を当てていましたが、前の作業は主にモデルのパフォーマンスを向上させることを目的としていました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: MedDG: A Large-scale Medical Consultation Dataset for Building Medical
  Dialogue System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_45.html">
      <font color="black">MedDG: A Large-scale Medical Consultation Dataset for Building Medical
  Dialogue System</font>
    </a>
  </h2>
  <font color="black">MedDGの各会話では、病気、症状、属性、テスト、および薬を含む5つの異なるカテゴリのエンティティに、追加のラベルとして注釈が付けられます。1つは次のエンティティの予測であり、もう1つは医師の応答の生成です。私たちは、MedDGという名前の12種類の一般的な胃腸疾患に関連する大規模で高品質の医療対話データセットを構築してリリースする最初の試みを行い、オンラインの健康相談コミュニティから17,000を超える会話を収集しました。 
[概要]病気、症状、属性、テスト、薬など、5種類のエンティティに、meddgの各会話で注釈が付けられます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding Neural Abstractive Summarization Models via Uncertainty -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/cs.CL/paper_46.html">
      <font color="black">Understanding Neural Abstractive Summarization Models via Uncertainty</font>
    </a>
  </h2>
  <font color="black">最後に、デコーダーの不確実性と注意の振る舞いの関係を調べて、注意がモデルでこれらの観察された効果をどのように引き起こすかを理解します。デコーダーの不確実性は、文の位置や隣接するトークンのペア間の構文上の距離などの要因にも関連し、どの要因が、モデルの次の出力トークンに対してコンテキストを特に選択的にするか。不確実性が、要約およびテキスト生成モデルをより広く分析するための有用な視点であることを示します。 
[概要]この作業では、ブラックボックスとホワイトボックスの両方の方法で要約デコーダーを分析します。モデルの予測の確率または不確実性について調査しました。不確実性は、要約モデルとテキスト生成モデルをより広く研究するための有用な視点です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: D3Net: Densely connected multidilated DenseNet for music source
  separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.AS/paper_0.html">
      <font color="black">D3Net: Densely connected multidilated DenseNet for music source
  separation</font>
    </a>
  </h2>
  <font color="black">MUSDB18データセットの実験結果は、D3Netが6.01 dBの平均信号対歪み比（SDR）で最先端のパフォーマンスを達成することを示しています。この論文では、受容場の急速な成長と単一の畳み込み層でのマルチ解像度データの同時モデリング、および密に接続された拡張DenseNet（D3Net）と呼ばれる新しいCNNアーキテクチャを提案します。D3Netには、異なる解像度をモデル化するために単一のレイヤーで異なる拡張係数を持つ新しいマルチ拡張畳み込みが含まれます。同時に。 
[ABSTRACT]新しい畳み込み畳み込みには、異なる解像度を同時にモデル化するために、単一レイヤーに異なる拡張拡張拡張畳み込み係数を持つ新しいマルチステート畳み込みが含まれます。新しい畳み込み畳み込みは、畳み込み畳み込みへの新しいアプローチです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: A Transformer Based Pitch Sequence Autoencoder with MIDI Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.AS/paper_1.html">
      <font color="black">A Transformer Based Pitch Sequence Autoencoder with MIDI Augmentation</font>
    </a>
  </h2>
  <font color="black">また、データ拡張には音楽の移調とMIDIシーケンスの切り捨てが適用されます。過剰適合を防ぐために、洗練された損失関数が提案され、パラメーターの量が削減されます。この作業は、取得の問題に取り組むための新しいアプローチを提供します。音楽信号分析で一般的であり、より注目に値する小さなデータセットからの機能。 
[要約]メロディーがオートマトンまたはホモサピエンスのどちらによって作成されたかを評価するために、音の欠如が提案されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Lightweight End-to-End Speech Recognition from Raw Audio Data Using
  Sinc-Convolutions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.AS/paper_2.html">
      <font color="black">Lightweight End-to-End Speech Recognition from Raw Audio Data Using
  Sinc-Convolutions</font>
    </a>
  </h2>
  <font color="black">多くのエンドツーエンドの自動音声認識（ASR）システムは、人間の聴覚をエミュレートするために手作りされた前処理された周波数領域機能に依然依存しています。時間領域でのデータ拡張率。結果として生じるエンドツーエンドモデルは、SpecAugmentを時間領域に適用することでさらに改善されるスムーズな収束動作を示しています。 
[概要]私たちのモデルは、tedlium v2テストデータセットで10.7％の単語誤り率を達成します。結果として得られるlog-melフィルターバンク機能を備えたアーキテクチャは絶対1.9％ですが、モデルサイズの21％しかありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Analysis and Influence of Hierarchical Structure on Melody,
  Rhythm and Harmony in Popular Music -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.AS/paper_3.html">
      <font color="black">Automatic Analysis and Influence of Hierarchical Structure on Melody,
  Rhythm and Harmony in Popular Music</font>
    </a>
  </h2>
  <font color="black">自動的に検出された階層的反復構造は、構造とコード進行、メロディーとリズムの間の重要な相互作用を明らかにします。フレーズが組み合わされてセクションを形成し、2レベルの階層構造を生成します。階層のレベルが異なると相互作用も異なり、構造階層が繰り返しや類似性の単純な概念を超えた音楽。 
[概要]システムシステムシステムは「構造構造」を検出します。研究は音楽生成と音楽評価のための新しいアプリケーションを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: The NeteaseGames System for Voice Conversion Challenge 2020 with
  Vector-quantization Variational Autoencoder and WaveNet -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.AS/paper_4.html">
      <font color="black">The NeteaseGames System for Voice Conversion Challenge 2020 with
  Vector-quantization Variational Autoencoder and WaveNet</font>
    </a>
  </h2>
  <font color="black">ただし、システムは言語内音声変換タスク用にのみ送信します。実際には、システムは、タスク1（言語内）とタスク2（言語間）の両方のVCC2020データセットを使用して開発できます。 、私たちのシステムは、いくつかの客観的な評価でうまく機能します。 
[ABSTRACT] vq --vae --wavenetは、非並列音声変換です。話者のアイデンティティで言語形式を分離するとともに、音響機能を再構築します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Music Classification in MIDI Format based on LSTM Mdel -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.AS/paper_5.html">
      <font color="black">Music Classification in MIDI Format based on LSTM Mdel</font>
    </a>
  </h2>
  <font color="black">10分割交差検証によって評価された結果の精度は90％に達する可能性があります。最初にMIDI形式の音楽サンプルを自然言語シーケンスに変換し、次にこれらのサンプルをmLSTM（乗法長短期記憶）+ロジスティック回帰によって分類しました。仕事は、AIと人間の作曲家によって生成された音楽が異なる特性を持っていることを示しています。それは深い学習ネットワークによって学ぶことができます。 
[ABSTRACT] aiと人間の作曲家は異なる特性を持っており、ディープラーニングネットワークで学習できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Muse: Multi-modal target speaker extraction with visual cues -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.AS/paper_6.html">
      <font color="black">Muse: Multi-modal target speaker extraction with visual cues</font>
    </a>
  </h2>
  <font color="black">ターゲットスピーカー抽出のための唇の画像シーケンスのみを条件とするMuSEという名前のマルチモーダルスピーカー抽出ネットワークを提案します。この信念に動機付けられて、ターゲットスピーカーの埋め込みを抽出するための参照として視覚的な手がかりを使用する新しい手法を研究します。 、事前登録された参照音声を必要とせずに..音声と唇の動きの間の時間的同期は有用な手がかりであり、ターゲットスピーカーの埋め込みも同様に重要であると考えています。 
[ABSTRACT] museは、ターゲットスピーカーの埋め込みを抽出するための参照として視覚的な手がかりを使用します。museは、si-sdrおよびpesqに関してav-convtasnetベースラインよりも向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Dance Revolution: Long-Term Dance Generation with Music via Curriculum
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.AS/paper_7.html">
      <font color="black">Dance Revolution: Long-Term Dance Generation with Music via Curriculum
  Learning</font>
    </a>
  </h2>
  <font color="black">この論文では、音楽駆動型ダンス生成をシーケンス間学習問題として形式化し、新しいseq2seqアーキテクチャを考案して、音楽機能の長いシーケンスを効率的に処理し、音楽とダンスの間のきめ細かい対応をキャプチャします。ロングモーションシーケンス生成における自動回帰モデルのエラー蓄積を軽減するカリキュラム学習戦略を提案します。これにより、トレーニングプロセスが、以前のグラウンドトゥルースムーブメントを使用した完全にガイドされた教師強制スキームから、主に代わりに生成された動き..この問題は、ロングモーションシーケンスの生成ではさらに深刻になります。 
[ABSTRACT]ダンスと音楽は機械学習アーキテクチャの問題です。ただし、これはニューラルネットワークにフィードバックされる予測エラーが豊富なためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br><font color="black">2020-06-11</font>
      </time>
    </span>
</section>
<!-- paper0: Dataset artefacts in anti-spoofing systems: a case study on the ASVspoof
  2017 benchmark -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.AS/paper_8.html">
      <font color="black">Dataset artefacts in anti-spoofing systems: a case study on the ASVspoof
  2017 benchmark</font>
    </a>
  </h2>
  <font color="black">第三に、このデータセットの信頼性が高く堅牢なパフォーマンス推定のために、トレーニングと推論中に発話の前後に非音声セグメントと無音を破棄することを提案します。最後に、フレームレベルと発話レベルの両方のモデルに対して、次のことができるいくつかの新しいベンチマーク結果を提供します。このデータセットの新しいベースラインとして機能します。これまでに60を超える研究論文がこのデータセットで公開されていますが、対策がなりすまし攻撃の検出に成功したように見える理由に答えようとしたものはありません。 
[概要]リプレイディスクーフィング攻撃に焦点を当てたイベント。参加者は、提供されたデータセットでシステムを構築およびトレーニングしました。この記事では、データセットに固有のアーティファクトが、公開されたシステムの明らかな成功にどのように貢献しているかを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Melody Classification based on Performance Event Vector and BRNN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.AS/paper_9.html">
      <font color="black">Melody Classification based on Performance Event Vector and BRNN</font>
    </a>
  </h2>
  <font color="black">このモデルは、開発データセットとWikifoniaデータセットで満足のいくパフォーマンスを達成しました。メロディ分類のCSMT2020データチャレンジのモデルを提案しました。モデルは、分類用の双方向RNNネットワークを構築するための入力シーケンスとしてパフォーマンスイベントベクトルを使用しました。 
[概要]私たちのモデルは、分類のための双方向rnnネットワークを構築しました。また、いくつかのハイパーパラメーターの効果についても説明しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Convolutional Neural Network-based Inverse Filtering Approach for
  Speech De-reverberation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-16/eess.AS/paper_10.html">
      <font color="black">Deep Convolutional Neural Network-based Inverse Filtering Approach for
  Speech De-reverberation</font>
    </a>
  </h2>
  <font color="black">CNN構造のさまざまな選択肢の中で、スキップ接続を備えた完全畳み込みオートエンコーダネットワークで構成されるU-netを検討します。提案されたフレームワークでは、CNNアーキテクチャはCTFの逆フィルタを直接推定するようにトレーニングされています。モデル..この目的のために、残響音声信号の畳み込み伝達関数（CTF）モデルを検討します。 
[ABSTRACT]プロジェクトは、現実的な残響条件をより適切に処理することを目的としています。部屋のインパルス応答（rir）フィルターはctf分析ウィンドウよりも長くなります。提案された方法はより良い残響除去を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
