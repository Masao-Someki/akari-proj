<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-02-07の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Source separation with weakly labelled data: An approach to
  computational auditory scene analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/cs.SD/paper_0.html">
      Source separation with weakly labelled data: An approach to
  computational auditory scene analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、2つのランダムに選択されたセグメントの混合物から、ターゲットセグメントのオーディオタグ付け予測を条件とするターゲットセグメントへの回帰が学習されます。ソース分離に関する以前の研究は、音声や音楽などの特定のサウンドクラスの分離に焦点を当てています。作業では、弱いラベルのデータでトレーニングされたソース分離フレームワークを提案します。 
[ABSTRACT]サウンドイベント検出システムは、ターゲットサウンドイベントを含むようなセグメントを検出するために使用されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br>2020-02-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Representation Disentanglement using Cross Domain Features
  and Adversarial Learning in Variational Autoencoder based Voice Conversion -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/cs.SD/paper_1.html">
      Unsupervised Representation Disentanglement using Cross Domain Features
  and Adversarial Learning in Variational Autoencoder based Voice Conversion
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      一方、品質および類似性スコアの観点からの主観的評価結果は、提案手法の有効性を示しています。本論文では、もつれの程度をさらに高めるために、敵対的学習の概念を組み込むことによりCDVAE-VCフレームワークを拡張します。実験結果は、学習された潜在表現のもつれ解除の程度が、GANと話者分類器の両方によって強化できることを確認しています。 
[要旨]成功は、より複雑な潜在表現からもたらされたと考えています。まず、cdvae-vcを使用したウイルス（gans）の有効性を調査します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br>2020-01-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Modeling of Individual HRTFs based on Spatial Principal Component
  Analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/cs.SD/paper_2.html">
      Modeling of Individual HRTFs based on Spatial Principal Component
  Analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      主観的な位置特定実験は、PCAと提案された方法がほとんどの条件で同様の性能を持っていることを示しています。 HRTFは、周波数と個人に依存する重みと組み合わされた空間主成分の小さなセットで表されます。 
[要旨]この論文は、空間主成分分析に基づくディープニューラルネットワークを使用した個々のhrtfモデリング方法を提示した。結果は、提案された方法とpca方法によって生成されたhrtfsが一般的な方法よりも優れていることを示す。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-21">
        <br>2019-10-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Parallel WaveGAN: A fast waveform generation model based on generative
  adversarial networks with multi-resolution spectrogram -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/cs.SD/paper_3.html">
      Parallel WaveGAN: A fast waveform generation model based on generative
  adversarial networks with multi-resolution spectrogram
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      特に、提案されているParallel WaveGANのパラメータは1.44 Mのみで、単一のGPU環境でリアルタイムの28.68倍の24 kHz音声波形を生成できます。さらに、このモデルは、コンパクトなアーキテクチャでも高忠実度の音声を生成できます。 ..知覚的リスニングテストの結果は、提案された方法が、トランスフォーマーベースの音声合成フレームワーク内で4.16平均オピニオンスコアを達成することを検証します。これは、最適な蒸留ベースのParallel WaveNetシステムと比較されます。 
[要約]提案された方法は、非自己回帰ウェーブネットを使用して、現実的な音声波形の時間-周波数分布をキャプチャします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Message Passing for Query Answering over Knowledge Graphs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/cs.CL/paper_0.html">
      Message Passing for Query Answering over Knowledge Graphs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      トレーニング中に見られないエッジに依存するクエリに応答することにより、競争力のあるパフォーマンスを得る方法を評価します。これにより、クエリの埋め込みが行われ、応答エンティティが埋め込みスペースでそれに近くなります。このタスクを解決するには、ノードが変数とエンティティに対応するクエリのグラフ表現にメッセージパッシングメカニズムを適用することを提案します。 
[ABSTRACT]埋め込みにより、ミッシングリンクやラベルなどの追加情報を予測できます。これらには、より複雑な構造を持つ回答が含まれます。これらの作品が公開されたのは初めてです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br>2020-02-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Understanding Car-Speak: Replacing Humans in Dealerships -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/cs.CL/paper_1.html">
      Understanding Car-Speak: Replacing Humans in Dealerships
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      カースピークは、車の物理的特性に関係する抽象的な言語です。したがって、彼らは理想的な車を「カースピーク」でしか記述できません。また、カースピーク言語の合理的なデータセットをキュレートすることも目指しています。 
[概要]車-ディーラーは、彼らのニーズを営業担当者に伝えます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br>2020-02-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Attractive or Faithful? Popularity-Reinforced Learning for Inspired
  Headline Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/cs.CL/paper_2.html">
      Attractive or Faithful? Popularity-Reinforced Learning for Inspired
  Headline Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      定量的および定性的実験を通じて、提案されたPORL-HGが、人間（71.03％）と予測子（少なくとも27.60％）の両方によって評価される魅力の点で、最先端の見出し生成モデルを大幅に上回ることを示します。 PORL-HGの忠実度は、最先端の世代モデルにも匹敵します。PORL-HGは、1）人気トピック注目（PTA）を使用して抽出的抽象的アーキテクチャを活用し、抽出者が魅力的な文を選択できるようにします。記事および2）アブストラクトを魅力的な文章の書き換えに導くための人気予測。オンラインメディアソースおよび公開されたニュースの急速な普及に伴い、ユーザーがニュース記事に圧倒されるため、読者をニュース記事に引き付けるための見出しがますます重要になっています。膨大な情報。 
[ABSTRACT]たとえば、私たちはインスパイアされた見出しを生成し、エフェクトの効果を持つ人気と呼ばれる新しいフレームワークを提案します。ニューヨーク大学、カリフォルニアは、有名人のようなエフェクトの使用を含む多くの同様のプロジェクトを作成しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br>2020-02-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Neural Topical Expansion Framework for Unstructured Persona-oriented
  Dialogue Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/cs.CL/paper_3.html">
      A Neural Topical Expansion Framework for Unstructured Persona-oriented
  Dialogue Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      PEEは、ペルソナ探査とペルソナエクスプロイトの2つの主要モジュールで構成されます。前者は、変分オートエンコーダ（VAE）ベースのトピックモデルを使用して、既存の対話コーパスとマイニングおよび相関させることで、事前定義されたユーザーペルソナ記述を拡張することを学習します。その結果、既存のメソッドは、ペルソナの一貫した応答を生成するときにペルソナの説明を使用できないか、不適切に使用します。 
[概要]システムは、事前定義されたユーザーペルソナの説明を、セマンティックに関連付けられたコンテンツで拡張してから、ダイアログ応答を生成することができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br>2020-02-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Irony Detection in a Multilingual Context -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/cs.CL/paper_4.html">
      Irony Detection in a Multilingual Context
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのシステムの性能を最先端のシステムと比較して、その能力を確認します。多言語の単語表現またはテキストベースの機能を使用して異なる言語で個別にトレーニングされたこれらの単一言語モデルは、皮肉な注釈付きデータのない言語。私たちは、機能ベースのモデルと、単一言語の単語表現を使用したニューラルアーキテクチャの両方を採用しています。 
[概要]調査では、多言語の単語表現を使用して、単一言語モデルが異なる言語で個別にトレーニングされていることが示されています。これらのモデルは、アイロニーの注釈付きデータがない言語でアイロニー検出の扉を開くことができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br>2020-02-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards Semantic Noise Cleansing of Categorical Data based on Semantic
  Infusion -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/cs.CL/paper_5.html">
      Towards Semantic Noise Cleansing of Categorical Data based on Semantic
  Infusion
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      後で、自動車ドメインのWebフォーラムデータセットを使用して、提案されたフレームワークの評価結果を示します。この手法に基づいて、用語のコンテキストを使用してセマンティックノイズをフィルタリングする教師なしテキスト前処理フレームワークを提案します。私たちは、セマンティックノイズをテキストの物語に寄与しない一連の用語として形式化します。 
[ABSTRACT]ストップワードの概念を超えて、セマンティックノイズを排除するために用語の妥当性を検討します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br>2020-02-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: DeFINE: DEep Factorized INput Token Embeddings for Neural Sequence
  Modeling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/cs.CL/paper_6.html">
      DeFINE: DEep Factorized INput Token Embeddings for Neural Sequence
  Modeling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      適応入力表現を含む最新の方法と比較して、この手法は、6〜20％の複雑さの低下をもたらします。このアーキテクチャでは、低次元入力の使用を可能にする斬新なスキップ接続を備えた階層構造を使用します出力層、合計パラメーターとトレーニング時間を削減しながら、既存の方法と同等以上のパフォーマンスを提供します。DeFINEは、新規または既存のシーケンスモデルに簡単に組み込むことができます。 
[概要]この作業では、comparable.itを学習するための新しいメソッドを定義します。このメソッドを使用して、深いトークン表現を効率的に学習します。新規または既存のシーケンスモデルに簡単に組み込むことができます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-27">
        <br>2019-11-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards Understanding Language through Perception in Situated
  Human-Robot Interaction: From Word Grounding to Grammar Induction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/cs.CL/paper_7.html">
      Towards Understanding Language through Perception in Situated
  Human-Robot Interaction: From Word Grounding to Grammar Induction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この短い論文で簡単に強調する難題は、言語の潜在的な文法構造を推測することです。これには、視覚、および組み合わせカテゴリー文法（CCG ）フレーズの場合。これにより、ロボットが相互作用中に人間の指示を適切に理解できるように、フレーズをグラウンディングする道が開けます。ロボットは、高度な認知機能を必要とするさまざまなタスクで人間のユーザーと広く協力しています周囲の環境を発見します。 
[要約]困難な課題は、言語の潜在的な文法構造を推測している
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-12">
        <br>2018-12-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Representation Disentanglement using Cross Domain Features
  and Adversarial Learning in Variational Autoencoder based Voice Conversion -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/cs.CL/paper_8.html">
      Unsupervised Representation Disentanglement using Cross Domain Features
  and Adversarial Learning in Variational Autoencoder based Voice Conversion
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、敵対的学習の概念を組み込むことにより、CDVAE-VCフレームワークを拡張し、解きほぐしの程度をさらに高め、それにより変換された音声の品質と類似性を改善します。表現..より具体的には、まず、生成的敵対ネットワーク（GAN）をCDVAE-VCに組み込むことの有効性を調査します。 
[要旨]成功は、より複雑な潜在表現からもたらされたと考えています。まず、cdvae-vcを使用したウイルス（gans）の有効性を調査します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br>2020-01-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Representing text as abstract images enables image classifiers to also
  simultaneously classify text -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/cs.CL/paper_9.html">
      Representing text as abstract images enables image classifiers to also
  simultaneously classify text
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      テキストベースの比較問題に適用される画像分類ネットワーク）。米国特許の発明者名の実体曖昧性解消にこの手法を適用します。新しいテキストから画像への表現方法は、他のNLP比較問題にも広く使用できます、学術出版物の曖昧性解消など、またはテキストと画像の両方のデータセットの同時分類を必要とする問題のために。 
[要約]この方法では、2つの発明者名レコード間の各ペアワイズ比較からの画像を2D RGU（積み重ね）画像表現に変換します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-19">
        <br>2019-08-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Citation Data of Czech Apex Courts -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/cs.CL/paper_10.html">
      Citation Data of Czech Apex Courts
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      データセットは、一般に公開されます。さらに、データセットは、後続の定性的および定量的分析のベースとして高品質の引用データを達成するために手動で処理されました。裁判所の決定識別子の抽出。 
[要約]データセットは、チェコの裁判所の決定のコーパスから自動的に抽出されました。データセットは、一般に公開されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br>2020-02-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multilingual acoustic word embedding models for processing zero-resource
  languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/cs.CL/paper_11.html">
      Multilingual acoustic word embedding models for processing zero-resource
  languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ここでは、複数の適切なリソースの言語からのラベル付きデータで単一の教師付き埋め込みモデルをトレーニングし、それを目に見えないゼロリソース言語に適用することを提案します。6つのターゲットゼロリソース言語で単語識別タスクを使用してテストします。リソースの豊富な7つの言語では、どちらのモデルも同様に機能し、リソースのない言語でトレーニングされた教師なしモデルよりも優れています。 
[要約] 7つの適切なリソース言語でトレーニングされた場合、両方のモデルは同様に実行し、ゼロでトレーニングされた教師なしモデルよりも優れています-リソース言語
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br>2020-02-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: HTMLPhish: Enabling Phishing Web Page Detection by Applying Deep
  Learning Techniques on HTML Analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/cs.CL/paper_12.html">
      HTMLPhish: Enabling Phishing Web Page Detection by Applying Deep
  Learning Techniques on HTML Analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、HTMLPhishは完全に言語に依存しないクライアント側の戦略であるため、テキスト言語に関係なくWebページのフィッシング検出を実行できます。具体的には、HTMLPhishはWebページのHTMLドキュメントのコンテンツを受信し、Convolutional Neural Networks （CNN）を使用して、HTMLのテキストコンテンツのセマンティック依存関係を学習します。その結果、フィッシング攻撃と戦うためのプロアクティブな手法が非常に必要になりました。 
[要旨]この戦いは、ワールドワイドウェブでのフィッシング攻撃の増加につながっています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-28">
        <br>2019-08-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Conversational Structure Aware and Context Sensitive Topic Model for
  Online Discussions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/cs.CL/paper_13.html">
      Conversational Structure Aware and Context Sensitive Topic Model for
  Online Discussions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実際のフォーラムデータセットの実験を使用して、一貫性の6つの異なる測定値とトピック割り当ての印象的な精度でトピック抽出のパフォーマンスの向上を実証します。従来のトピックモデルはオンラインディスカッションで成功が限られており、その制限を克服するために、ディスカッションスレッドを使用しますツリー構造を作成し、コメントへの返信数を定量化する「ポピュラリティ」メトリックを提案して、単語の出現頻度を拡張し、ネストされたディスカッションスレッドのノード間のトピック依存関係を特徴付ける「推移性」コンセプトを提案します。トピックとコメントへの割り当てを推測するための、人気と推移性に基づくトピックモデル（CSATM）。 
[ABSTRACT]会話構造認識トピックモデル（csatm）を構築します。人気と推移性に基づいて、トピックとコメントへの割り当てを推測します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br>2020-02-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Related Tasks can Share! A Multi-task Framework for Affective language -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/cs.CL/paper_14.html">
      Related Tasks can Share! A Multi-task Framework for Affective language
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのマルチタスクモデルは、畳み込みゲートリカレントユニット（GRU）フレームワークに基づいています。これは、さまざまな手作りの機能セットによってさらに支援されます。感情の極性を「ポジティブ」と「ネガティブ」として表現すると、通常、範囲が限定されます評価と分析により、マルチタスクフレームワークの関連タスクの共同学習は、シングルタスクフレームワークの個々のタスクよりも優れていることが示唆されています。 
[要約]理論は、マルチタスク学習フレームワークで複数のタスクの関連性を使用することです。関連タスクの学習は、シングルタスクフレームワークの個々のタスクよりも優れている場合があります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br>2020-02-06
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Source separation with weakly labelled data: An approach to
  computational auditory scene analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/eess.AS/paper_0.html">
      Source separation with weakly labelled data: An approach to
  computational auditory scene analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      訓練されたサウンドイベント検出システムは、ターゲットサウンドイベントを含む可能性が最も高いセグメントを検出するために使用されます。次に、ランダムに選択された2つのセグメントの混合から、ターゲットセグメントの..弱くラベル付けされたデータには、音声イベントの発生時間なしで、オーディオクリップのタグのみが含まれます。 
[ABSTRACT]サウンドイベント検出システムは、ターゲットサウンドイベントを含むようなセグメントを検出するために使用されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br>2020-02-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Representation Disentanglement using Cross Domain Features
  and Adversarial Learning in Variational Autoencoder based Voice Conversion -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/eess.AS/paper_1.html">
      Unsupervised Representation Disentanglement using Cross Domain Features
  and Adversarial Learning in Variational Autoencoder based Voice Conversion
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      音声変換（VC）の効果的なアプローチは、言語コンテンツを音声信号の他のコンポーネントから解きほぐすことです。次に、ドメイン敵対トレーニングの概念を検討し、話者分類器によって実現される潜在表現に明示的な制約を追加します。潜在コードに存在する話者情報を明示的に排除します。実験結果は、学習した潜在表現のもつれの程度を、GANと話者分類子の両方によって強化できることを確認します。 
[要旨]成功は、より複雑な潜在表現からもたらされたと考えています。まず、cdvae-vcを使用したウイルス（gans）の有効性を調査します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br>2020-01-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Modeling of Individual HRTFs based on Spatial Principal Component
  Analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/eess.AS/paper_2.html">
      Modeling of Individual HRTFs based on Spatial Principal Component
  Analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      主観的位置特定実験は、PCAと提案された方法がほとんどの条件で同様の性能を持っていることを示しています。客観的および主観的な実験は、提案された方法、主成分分析（PCA）方法、および一般的な方法によって生成されたHRTFを評価します。結果は、提案された方法とPCA方法によって生成されたHRTFが一般的な方法よりも優れていることを示しています。 
[要旨]この論文は、空間主成分分析に基づくディープニューラルネットワークを使用した個々のhrtfモデリング方法を提示した。結果は、提案された方法とpca方法によって生成されたhrtfsが一般的な方法よりも優れていることを示す。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-21">
        <br>2019-10-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multilingual acoustic word embedding models for processing zero-resource
  languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/eess.AS/paper_3.html">
      Multilingual acoustic word embedding models for processing zero-resource
  languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      6つのターゲットゼロリソース言語で単語弁別タスクを使用してこれらをテストします。単一のトレーニング言語で、2番目のモデルはより適切に動作しますが、パフォーマンスは特定のトレーニング-テスト言語ペアにより依存します。唯一の利用可能なリソースです。このような埋め込みは、「ゼロリソース」音声検索、インデックス作成、および検出システムで使用できます。 
[要約] 7つの適切なリソース言語でトレーニングされた場合、両方のモデルは同様に実行し、ゼロでトレーニングされた教師なしモデルよりも優れています-リソース言語
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br>2020-02-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Parallel WaveGAN: A fast waveform generation model based on generative
  adversarial networks with multi-resolution spectrogram -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/eess.AS/paper_4.html">
      Parallel WaveGAN: A fast waveform generation model based on generative
  adversarial networks with multi-resolution spectrogram
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      特に、提案されたParallel WaveGANのパラメータは1.44 Mのみであり、単一のGPU環境でリアルタイムの28.68倍の24 kHz音声波形を生成できます。知覚リスニングテストの結果は、提案手法がTransformerで4.16平均意見スコア最適な蒸留ベースの並列WaveNetシステムと比較される、テキストベースの音声合成フレームワーク。提案手法では、非自己回帰WaveNetは、多重解像度スペクトログラムと敵対的損失関数を共同で最適化することによりトレーニングされます。現実的な音声波形の時間周波数分布をキャプチャします。 
[要約]提案された方法は、非自己回帰ウェーブネットを使用して、現実的な音声波形の時間-周波数分布をキャプチャします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: The Endothelial Protein C Receptor plays an essential role in the maintenance of Pregnancy -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/biorxiv.physiology/paper_0.html">
      The Endothelial Protein C Receptor plays an essential role in the maintenance of Pregnancy
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      母体の血栓形成は疑わしい危険因子ですが、これらの合併症における血栓プロセスの役割と抗血栓治療の可能性は不明なままです。.内皮プロテインC受容体（EPCR）は、胎盤で高度に発現する抗凝固タンパク質です。母体胎児の健康管理における大きな課題です。 
[ABSTRACT]母体血栓症はリスク因子の疑いがあるが、これらの合併症および抗血栓治療の可能性における血栓症プロセスの役割は不明のままである。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br>2020-02-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Pharmacological inhibition of longevity regulator PAPP-A restrains mesenchymal stromal cell activity -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/biorxiv.physiology/paper_1.html">
      Pharmacological inhibition of longevity regulator PAPP-A restrains mesenchymal stromal cell activity
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      PAPP-A阻害は、局所IGFシグナル伝達を低下させ、複数の加齢性疾患の進行を制限し、寿命を延ばしますが、これらの多面的効果の背後にあるメカニズムは不明のままです。この効果を調べるために、間葉間質細胞（MSC）をPAPP-AのソースおよびPAPP-A抑制に対する主要なレスポンダーとして特定しました。 
[概要] pappは、igf結合タンパク質を切断することでigfの可用性を高める分泌型メタロプロテアーゼです。マウスの複数の組織でコラーゲンと細胞外マトリックス（ecm）の遺伝子発現を減少させます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br>2020-02-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Memo1 gene expression in kidney and bone is unaffected by dietary mineral load and calciotropic hormones -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-07/biorxiv.physiology/paper_2.html">
      Memo1 gene expression in kidney and bone is unaffected by dietary mineral load and calciotropic hormones
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Mediator of Cell Motility 1（MEMO1）は、FGF23シグナル伝達を含む成長因子に対する細胞応答の遍在的に発現されるモジュレーターであり、Memo1欠損マウスはFgf23またはクロトー欠損マウスモデルといくつかの表現型特性を共有します。野生型C57BL / 6Nマウスは、1,25（OH）2-ビタミンD3、副甲状腺ホルモン（PTH）、17β-エストラジオールまたは媒体で治療を受けました。 
[ABSTRACT]マウスのマウスは、memo1遺伝子の発現がカルシウム代謝刺激ホルモンによって調節されているか、食事のミネラル負荷を変化させているかをテストしました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br>2020-02-06
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
