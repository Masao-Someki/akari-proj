<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-08-13の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Improving Stability of LS-GANs for Audio and Speech Signals -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.SD/paper_0.html">
      <font color="black">Improving Stability of LS-GANs for Audio and Speech Signals</font>
    </a>
  </h2>
  <font color="black">さらに、これらのサンプルから再構成された信号は、通常のLS-GANと比較して高いS / N比を達成しました。このベクトル空間で計算された正規性からの最適化をジェネレーター最適化定式化にエンコードすると、より包括的なスペクトログラムの作成に役立つことがわかります。実験結果UrbanSound8kおよびMozillaの共通の音声データセットのサブセットでは、Fr \ &#39;echetの開始距離で測定された生成サンプルの品質が大幅に改善されています。 
[ABSTRACT]ジェネレーター拡張インカネーションは、より包括的なスペクトログラムを作成するのに役立ちます。urbansound8kおよびmozilla共通音声データセットのガンサーにより、生成されたサンプルの品質が向上しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: VAW-GAN for Singing Voice Conversion with Non-parallel Training Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.SD/paper_1.html">
      <font color="black">VAW-GAN for Singing Voice Conversion with Non-parallel Training Data</font>
    </a>
  </h2>
  <font color="black">歌唱音声変換システムのトレーニングには、通常、並列トレーニングデータが必要ですが、実際のアプリケーションでは実用的ではありません。音声コンテンツから歌手IDと歌唱韻律（F0輪郭）のもつれを解くようにエンコーダーをトレーニングします。最近のエンコーダー変分オートエンコーディングWasserstein生成的敵対ネットワーク（VAW-GAN）などのデコーダー構造は、非並列トレーニングデータを通じてマッピングを学習する効果的な方法を提供します。 
[要約]このホワイトペーパーでは、vawに基づいた歌声変換フレームワークを提案します。gan.itは歌手IDとfsteinを使用してf0レンダリングを改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Transfer Learning Approaches for Streaming End-to-End Speech Recognition
  System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.SD/paper_2.html">
      <font color="black">Transfer Learning Approaches for Streaming End-to-End Speech Recognition
  System</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、RNN-Tフレームワークの4つの異なるTL手法の比較研究を紹介します。ハイブリッドASRシステムでは、伝達学習は通常、ソース言語AMでターゲット言語音響モデル（AM）を初期化することによって行われます。伝達学習（TL）知識をソース言語からターゲット言語に転送するために、従来のハイブリッド自動音声認識（ASR）システムで広く使用されています。 
[ABSTRACT] tlは、再帰型ニューラルネットワークトランスデューサー（rnn-t）モデルなどのエンドツーエンド（e2e）asrシステムに適用できます。asrシステムは、ターゲット言語のエンコーダーと予測ネットワークをテストするために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Channel-wise Subband Input for Better Voice and Accompaniment Separation
  on High Resolution Music -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.SD/paper_3.html">
      <font color="black">Channel-wise Subband Input for Better Voice and Accompaniment Separation
  on High Resolution Music</font>
    </a>
  </h2>
  <font color="black">比較のために、スケール、アーキテクチャ、CWS設定が異なるモデルで音声と伴奏の分離（VAS）を実行します。実験では、CWS入力が多くの面で有益であることを示しています。以下に焦点を当て、musdb18hqテストセットでメソッドを評価します。 SDR、SIR、SARメトリック。 
[要約]私たちはcnnベースの高解像度mssモデルの主要な問題に対処することを目指しています。提案されたアプローチは、各サブバンドでの効果的な重み共有を可能にし、チャネル間の柔軟性を高めます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Spectrum and Prosody Conversion for Cross-lingual Voice Conversion with
  CycleGAN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.SD/paper_4.html">
      <font color="black">Spectrum and Prosody Conversion for Cross-lingual Voice Conversion with
  CycleGAN</font>
    </a>
  </h2>
  <font color="black">連続ウェーブレット変換（CWT）分解をF0モデリングに使用することを提案します。また、スペクトルマッピングと韻律マッピングの2つのCycleGANパイプラインをトレーニングすることも提案します。主観的評価のベースライン。 
[ABSTRACT]たとえば、2つのスピーカーのパラレルデータの必要性を排除します。これは、クロスリンガル音声変換における韻律の最初の研究です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-11">
        <br><font color="black">2020-08-11</font>
      </time>
    </span>
</section>
<!-- paper0: Emotion Profile Refinery for Speech Emotion Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.SD/paper_5.html">
      <font color="black">Emotion Profile Refinery for Speech Emotion Classification</font>
    </a>
  </h2>
  <font color="black">EPRメソッドは、洗練の連続した段階で動的に生成される複数の確率的クラスラベルを生成します。これにより、モデルの精度が大幅に向上します。このホワイトペーパーでは、時間を提供する感情プロファイル（EP）の使用をお勧めします。特定の発話全体に存在する感情的な手がかりの微妙なブレンドをキャプチャする一連のセグメントレベルのソフトラベル。さらに、EPを更新する反復手順である感情プロファイル精製（EPR）を提案します。 
[ABSTRACT]このラベリングの原則は、感情的な不純物を考慮してシステムパフォーマンスに課題を課します。また、epsを更新する反復手順である感情プロファイル精製（epr）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Attentron: Few-Shot Text-to-Speech Utilizing Attention-Based
  Variable-Length Embedding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.SD/paper_6.html">
      <font color="black">Attentron: Few-Shot Text-to-Speech Utilizing Attention-Based
  Variable-Length Embedding</font>
    </a>
  </h2>
  <font color="black">さらに、モデルは、任意の数の参照オーディオにスケールアウトして、合成音声の品質を向上させることができます。パーソナライゼーションの需要の高まりに対応して、スピーカーのみをクローン化する、いわゆる数ショットTTSシステムの必要性いくつかのデータが出てきています。人間の評価を含む私たちの実験によると、提案されたモデルは、話者の類似性と品質の点で、目に見えない話者の音声を生成するときに、最先端のモデルを大幅に上回っています。 
[ABSTRACT] attentronは少数です-トレーニング中に見えない話者の声を複製するショットttsモデルです。このモデルは、話者の類似性と品質の面で、見えない話者のスピーチを生成するときに、最先端のモデルを大幅に上回ります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-18">
        <br><font color="black">2020-05-18</font>
      </time>
    </span>
</section>
<!-- paper0: Mask Detection and Breath Monitoring from Speech: on Data Augmentation,
  Feature Representation and Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.SD/paper_7.html">
      <font color="black">Mask Detection and Breath Monitoring from Speech: on Data Augmentation,
  Feature Representation and Modeling</font>
    </a>
  </h2>
  <font color="black">スピーチ呼吸モニタリングタスクでは、Bi-LSTM構造に基づいてさまざまなボトルネック機能を調査します。マスク検出タスクでは、フィルターバンクエネルギー、性別認識機能、およびスピーカー認識機能を備えた深い畳み込みニューラルネットワークをトレーニングします。実験結果は、提案された方法がベースラインを上回り、それぞれ呼吸およびマスク評価セットで0.746 PCCおよび78.8％UARを達成することを示しています。 
[要約]マスク検出タスクでは、深い畳み込みニューラルネットワークをトレーニングします。システムは、データ増大スキームを使用してトレーニングデータを増やします。これらには、速度摂動、スペック、ランダム消去が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Anomaly localization by modeling perceptual features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.IV/paper_0.html">
      <font color="black">Anomaly localization by modeling perceptual features</font>
    </a>
  </h2>
  <font color="black">このFeature-Augmented VAEは、入力画像をピクセル空間で再構築するだけでなく、いくつかの異なる特徴空間でもトレーニングされます。これらは、大きな画像データセットで事前にトレーニングされた畳み込みニューラルネットワークによって計算されます。 MVTec異常検出およびローカリゼーションデータセットに関する最新の手法。変分オートエンコーダー（VAE）を使用した画像データセットの教師なし生成モデリングが、異常画像または画像内の異常領域を検出するために使用されていますが、最近の研究では、この方法は、人間の知覚と一致しない画像や領域を特定することが多く、ロバストな異常検出のための生成モデルの有用性に疑問を投げかけています。 
[要約]新しいvaeモデルは、人間の知覚に近い新しいモデルに基づいています。最近のvaeシステムで明確な改善を達成しています。また、より複雑な異常モデルを開発しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Bone Segmentation in Contrast Enhanced Whole-Body Computed Tomograph -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.IV/paper_1.html">
      <font color="black">Bone Segmentation in Contrast Enhanced Whole-Body Computed Tomograph</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、トレーニングデータのウィンドウ処理とシグモイド活性化しきい値の選択の変更に基づいて、新しい前処理技術を備えたUネットアーキテクチャの概要を説明し、低線量コントラストの強化全身CTスキャンから骨髄領域を適切にセグメント化します。メソッドは、2つの内部データセットと1つの外部テストデータセットでそれぞれ0.979、0.965、および0.934の平均ダイス係数を達成しました。骨領域のセグメンテーションにより、CTイメージングにおける診断、疾患の特徴付け、および治療モニタリングを強化できます。 
[要約]提案された方法は、2つの内部データセットと1つの外部テストデータセットで0. 979、0. 965、および0. 934の平均ダイスエントリを達成しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Large-Scale Analysis of Iliopsoas Muscle Volumes in the UK Biobank -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.IV/paper_2.html">
      <font color="black">Large-Scale Analysis of Iliopsoas Muscle Volumes in the UK Biobank</font>
    </a>
  </h2>
  <font color="black">左と右の腸腰筋の体積の間に小さいが有意な非対称性がありました。腰筋測定は、サルコペニアのマーカーと健康の予測因子として頻繁に使用されています。腸腰筋の体積は、5,000人の参加者全員で正常に測定されました。 
[要約]腸腰筋の体積は女性の被験者と比較して男性で大きかった。年齢のある男性では筋肉量の減少が加速された</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: OCMR (v1.0)--Open-Access Multi-Coil k-Space Dataset for Cardiovascular
  Magnetic Resonance Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.IV/paper_3.html">
      <font color="black">OCMR (v1.0)--Open-Access Multi-Coil k-Space Dataset for Cardiovascular
  Magnetic Resonance Imaging</font>
    </a>
  </h2>
  <font color="black">高度にアンダーサンプリングされたデータから診断品質のCMR画像を復元することは、活発な研究分野です。最近、CMRを高速化するためにいくつかのデータ取得および処理方法が提案されています。この作業では、OCMRと呼ばれるオープンアクセスデータセットを紹介します。 53の完全にサンプリングされた、212のプロスペクティブアンダーサンプリングされた心臓シネシリーズからマルチコイルk空間データを提供します。 
[ABSTRACT] mmrはocmrと呼ばれるオープンアクセスデータセットであり、53の完全侵襲性および212の前向きアンダーサンプリング心臓シネシリーズからのk空間データを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-08">
        <br><font color="black">2020-08-08</font>
      </time>
    </span>
</section>
<!-- paper0: Guided Collaborative Training for Pixel-wise Semi-Supervised Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.IV/paper_4.html">
      <font color="black">Guided Collaborative Training for Pixel-wise Semi-Supervised Learning</font>
    </a>
  </h2>
  <font color="black">セミ教師あり学習（SSL）の一般化をさまざまなピクセル単位のタスクに調査します。最初に、GCTは、新しい欠陥検出器を通じて密な出力によって引き起こされる問題に対処します。https：//github.comで利用可能なコード/ ZHKKKe / PixelSSL。 
[要約]このホワイトペーパーでは、task.gctの新しいsslフレームワークを提示し、最先端の方法よりも大幅に優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Semixup: In- and Out-of-Manifold Regularization for Deep Semi-Supervised
  Knee Osteoarthritis Severity Grading from Plain Radiographs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.IV/paper_5.html">
      <font color="black">Semixup: In- and Out-of-Manifold Regularization for Deep Semi-Supervised
  Knee Osteoarthritis Severity Grading from Plain Radiographs</font>
    </a>
  </h2>
  <font color="black">Semixupは、内挿された一貫性と一緒に、多様体の内外のサンプルを使用した一貫性の正則化に依存しています。最近の文献では、ディープラーニング手法は、ゴールドスタンダードのケルグレンローレンス（KL）グレーディングに従ってOAの重症度評価を確実に実行できることが示されていますただし、これらの方法では大量のラベル付きデータが必要になるため、取得にコストがかかります。 
[ABSTRACT]この筋骨格は、X線評価を評価する必要があります。これは通常、X線評価によって確認されます。これは、深層学習法がOA重症度評価を実行する方法を説明します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-04">
        <br><font color="black">2020-03-04</font>
      </time>
    </span>
</section>
<!-- paper0: Using convolution neural networks to learn enhanced fiber orientation
  distribution models from commercially available diffusion magnetic resonance
  imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.IV/paper_6.html">
      <font color="black">Using convolution neural networks to learn enhanced fiber orientation
  distribution models from commercially available diffusion magnetic resonance
  imaging</font>
    </a>
  </h2>
  <font color="black">CNNモデルがローカル繊維配向をどの程度うまく解決できるかを評価します。1）同じdMRI取得プロトコルを使用してデータセットをトレーニングおよびテストする場合。 2）CNNモデルのトレーニングに使用されたものとは異なるdMRI取得プロトコルでデータセットをテストする場合。および3）CNNモデルのトレーニングに使用されるよりも少ない数のdMRI勾配方向のデータセットでテストする場合。特定の取得による複雑なファイバー構成の利点を解決できる拡散磁気共鳴画像（dMRI）に基づく正確なローカルファイバー配向分布（FOD）モデリング多数の勾配方向（b-vecs）、高い最大b値（b-vals）、および複数のb値（マルチシェル）を課すプロトコル。ここでは、商業的に取得されたdMRIの改善されたFODについて学びます。 
[要約]臨床環境では取得時間に制限があり、市販のスキャナーでは堅牢なシングルシェルとdmriシーケンスを提供できない場合があります。dmriは、国立病院で神経学および神経外科のクイーンスクエアで取得されたcnnアーキテクチャとデータセットを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: The Ensemble Method for Thorax Diseases Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.IV/paper_7.html">
      <font color="black">The Ensemble Method for Thorax Diseases Classification</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、損失関数のトレーニングパターンの重みは、クラスのトレーニングパターンの数だけでなく、それらの1つがこのトレーニングパターンをポジティブとして扱い、他のノードがポジティブとして扱うさまざまなノードにも基づいて設計されています。胸部X線画像データセットの実験結果は、この新しい重み付けスキームが分類パフォーマンスを向上させることを示しています。また、EfficientNetからのトレーニング最適化がパフォーマンスをさらに向上させます。アンサンブル法を以前の調査のいくつかのパフォーマンスと比較します。提案された方法に対する公正な比較を提供するための胸部疾患分類。 
[要約]提案された方法は、胸部疾患分類問題の最先端のディープネットワークアーキテクチャに基づいています。提案された代替方法との公平な比較を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-07">
        <br><font color="black">2020-08-07</font>
      </time>
    </span>
</section>
<!-- paper0: Temporal-Coded Deep Spiking Neural Network with Easy Training and Robust
  Performance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.IV/paper_8.html">
      <font color="black">Temporal-Coded Deep Spiking Neural Network with Easy Training and Robust
  Performance</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、時間コード化されたディープSNNが、高性能でエネルギー効率の高いアプリケーションに適していることを示します。このペーパーでは、ベンチマークデータセットCIFAR10とImageNetを介してディープ時間コード化されたSNNを簡単かつ直接トレーニングできることを示します。同等のサイズとアーキテクチャのDNNの1％以内のテスト精度でテストします。SNNは実用的なニューロモーフィックハードウェアに実装する必要があることを考慮して、8、4、2ビットに量子化された重みとランダムノイズによって摂動された重みを使用してディープSNNをトレーニングします。実用的なアプリケーションでその堅牢性を実証します。 
[ABSTRACT]クローズドフォームのおかげでトレーニングはdnnと同様になります-スパイク波形ダイナミクスのソリューション</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-24">
        <br><font color="black">2019-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Vehicle-Human Interactive Behaviors in Emergency: Data Extraction from
  Traffic Accident Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.IV/paper_9.html">
      <font color="black">Vehicle-Human Interactive Behaviors in Emergency: Data Extraction from
  Traffic Accident Videos</font>
    </a>
  </h2>
  <font color="black">このギャップを埋めて関連する研究を促進するために、このペーパーでは、監視カメラとドライビングレコーダーの両方でキャプチャされた実際の事故ビデオからインタラクティブな行動データ（つまり、車両と人間の軌跡）を抽出する新しい便利な方法を提供します。リアルタイムの事故ビデオからのデータ抽出の主な課題は、記録用カメラがキャリブレーションされておらず、監視の角度が不明であることです。現在、緊急時の車と人間の相互作用行動を研究するには、大量のほとんど利用できない実際の緊急事態におけるデータセット。 
[ABSTRACT]自動運転車（avs）の既存のパブリックデータソースは、主に新しい運転シナリオまたは人間の関与のない緊急事態に焦点を当てています。データ抽出の主な課題は、カメラの記録が未調整であり、監視の角度が不明であることです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-02">
        <br><font color="black">2020-03-02</font>
      </time>
    </span>
</section>
<!-- paper0: Real-Time Cardiac Cine MRI with Residual Convolutional Recurrent Neural
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.IV/paper_10.html">
      <font color="black">Real-Time Cardiac Cine MRI with Residual Convolutional Recurrent Neural
  Network</font>
    </a>
  </h2>
  <font color="black">放射線科医の評価に基づいて、ディープラーニングモデルは圧縮センシングよりも優れたパフォーマンスを示します。ただし、リアルタイムシネマは高速の画像取得を実現するために、一般に高度にアンダーサンプリングされたデータを取得するため、MRI画像の再構成に大きな課題があります。リアルタイム心臓シネ再構成のための残差畳み込みRNN。 
[ABSTRACT]これは、ディープラーニングアプローチをカートルのリアルタイム心臓シネ再構成に適用した最初の作品です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: A Longitudinal Method for Simultaneous Whole-Brain and Lesion
  Segmentation in Multiple Sclerosis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.IV/paper_11.html">
      <font color="black">A Longitudinal Method for Simultaneous Whole-Brain and Lesion
  Segmentation in Multiple Sclerosis</font>
    </a>
  </h2>
  <font color="black">スキャナー、MRIプロトコル、または縦方向のフォローアップスキャンの回数とタイミングに関する事前の仮定を行わないため、非常に一般的に適用可能です。この論文では、縦方向の脳のMRIのセグメンテーションのための新しい方法を提案します。多発性硬化症に苦しむ患者のスキャン。この方法は、全脳と病変の同時セグメンテーションのための既存の横断的方法に基づいて構築され、縦断的スキャン間の時間的一貫性を促進するために被験者固有の潜在変数を導入します。 
[要約]提案された方法は、既存の方法で全体を同時に構築します-脳と病変のセグメンテーション。また、対象-特定の潜在変数を導入して、mriスキャン間の空間を促進します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: A survey of loss functions for semantic segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.IV/paper_12.html">
      <font color="black">A survey of loss functions for semantic segmentation</font>
    </a>
  </h2>
  <font color="black">特定の損失関数がすべてのデータセットで良好に機能し、未知の分布データセットで適切な選択肢として使用できることを示しました。画像のセグメンテーションは、医療の抜け穴を修正して支援する可能性があるため、活発な研究分野です。 mass ..コードはhttps://github.com/shruti-jadon/Semantic-Segmentation-Loss-Functionsで入手できます。 
[要約]新しいログ-coshダイス損失関数も導入しました。コードはwww。 github。 com</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-26">
        <br><font color="black">2020-06-26</font>
      </time>
    </span>
</section>
<!-- paper0: An Inter- and Intra-Band Loss for Pansharpening Convolutional Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.IV/paper_13.html">
      <font color="black">An Inter- and Intra-Band Loss for Pansharpening Convolutional Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">私たちが提案するIIB損失は、バンド間とバンド内の両方の関係を効果的に維持でき、さまざまなパンシャープンCNNに直接適用できます。シミュレートされた目的のマルチスペクトル画像。この手紙では、元のL2損失の欠点を克服するために、バンド間およびバンド内（IIB）の新しい損失を提案します。 
[ABSTRACT] pansharp2損失は、バンド間およびバンド内の両方の関係を効果的に維持できます。異なるパンシャープンCNNに直接適用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: End-To-End Convolutional Neural Network for 3D Reconstruction of Knee
  Bones From Bi-Planar X-Ray Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.IV/paper_14.html">
      <font color="black">End-To-End Convolutional Neural Network for 3D Reconstruction of Knee
  Bones From Bi-Planar X-Ray Images</font>
    </a>
  </h2>
  <font color="black">各骨の形状を統計的にモデリングする一般的なアプローチとは対照的に、私たちのディープネットワークは骨の形状の分布をトレーニング画像から直接学習します。しかし、そのような2Dスキャンから3Dモデルを取得することは非常に困難です。私たちのディープラーニングモデルは非常に効率的で、一般化し、高品質の再構成を生成します。 
[ABSTRACT]脳、脳および脳外科医の3Dモデルの取得は成功する可能性があります。現実的で現実的です現実的に、外科医外科医は病院に再びエネルギーを与えることができます。しかし、再エネルギー3Dモデルは簡単に簡単に取得できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-02">
        <br><font color="black">2020-04-02</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervised Light Field View Synthesis Using Cycle Consistency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.IV/paper_15.html">
      <font color="black">Self-supervised Light Field View Synthesis Using Cycle Consistency</font>
    </a>
  </h2>
  <font color="black">生成されたビューが入力ビューと一致するように強制する双方向マッピングを構築するために、サイクル整合性制約が使用されます。この問題に取り組むために、サイクル整合性を備えた自己監視型ライトフィールドビュー合成フレームワークを提案します。提案された方法は、堅牢性を検証するためのさまざまなデータセット、および結果は、監視付き微調整と比較して競争力のあるパフォーマンスを達成するだけでなく、特に複数の中間ビューを生成する場合に、最先端のライトフィールドビュー合成方法よりも優れていることを示しています。 
[要約]提案された方法は、高品質の自然なビデオデータセットから学習した事前知識をライトフィールドビュー合成タスクに転送することを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: More Diverse Means Better: Multimodal Deep Learning Meets Remote Sensing
  Imagery Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.IV/paper_16.html">
      <font color="black">More Diverse Means Better: Multimodal Deep Learning Meets Remote Sensing
  Imagery Classification</font>
    </a>
  </h2>
  <font color="black">この作業では、一般的なマルチモーダルディープラーニング（MDL）フレームワークを開発することにより、前述の問題のベースラインソリューションを提供します。さらに重要なことに、このフレームワークはピクセル単位の分類タスクに限定されるだけでなく、畳み込みによる空間情報モデリングにも適用できます。ニューラルネットワーク（CNN）。さらに、コードとデータセットはhttps://github.com/danfenghong/IEEE_TGRS_MDL-RSで入手でき、RSコミュニティに貢献します。 
[要約]これは、シングルモダリティが支配的な分類タスクでディープネットワークが正常に適用されているにもかかわらずです。ただし、そのパフォーマンスは、情報の多様性の制限により、細かく分類する必要がある複雑なシーンのボトルネックを満たします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: TextureWGAN: Texture Preserving WGAN with MLE Regularizer for Inverse
  Problems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.IV/paper_17.html">
      <font color="black">TextureWGAN: Texture Preserving WGAN with MLE Regularizer for Inverse
  Problems</font>
    </a>
  </h2>
  <font color="black">MSEベースのメソッドは、ベースラインイメージとCNNによって生成されたイメージ間のすべてのピクセルのユークリッド距離を最小化し、イメージテクスチャなどのピクセルの空間情報を無視します。 texture ..この論文では、逆問題のためのWasserstein GAN（WGAN）に基づく新しい方法を提案しました。 
[要約]すべての提案された方法で、最も一般的で効果的な方法は、平均二乗誤差（mse）を使用した畳み込みニューラルネットワーク（cnn）です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-11">
        <br><font color="black">2020-08-11</font>
      </time>
    </span>
</section>
<!-- paper0: Renal Cell Carcinoma Detection and Subtyping with Minimal Point-Based
  Annotation in Whole-Slide Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.IV/paper_18.html">
      <font color="black">Renal Cell Carcinoma Detection and Subtyping with Minimal Point-Based
  Annotation in Whole-Slide Images</font>
    </a>
  </h2>
  <font color="black">また、サブタイピングモデルは、WSIをテストするための診断ラベルのみでトレーニングされたモデルよりもf1スコアが12％優れています。腎細胞癌（RCC）の3つの重要なサブタイプの実験では、Min-ポイント注釈付きデータセットは、癌領域検出のためのセグメンテーション注釈付きデータセットでトレーニングされた分類子に匹敵します。このため、SSLメソッドを使用して、最小点ベースの注釈と呼ばれる新しい注釈方法で癌領域を正確に検出するフレームワークを提案しましたそして、予測された結果と革新的なハイブリッド損失を利用して、サブタイプの分類モデルをトレーニングします。 
[要約]システムはsslメソッドを使用して癌性領域を正確に検出します。次に、革新的なハイブリッド損失の予測結果を使用して、サブタイプの分類モデルをトレーニングします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Pixel-level Corrosion Detection on Metal Constructions by Fusion of Deep
  Learning Semantic and Contour Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.IV/paper_19.html">
      <font color="black">Pixel-level Corrosion Detection on Metal Constructions by Fusion of Deep
  Learning Semantic and Contour Segmentation</font>
    </a>
  </h2>
  <font color="black">CNN ..ただし、派生した最終的な画像は、構造解析とプレファブリケーションに対してまだ十分に正確ではありません。..このホワイトペーパーでは、腐食検出。精度と時間の点で優れており、他の深いモデルと比較して必要な注釈付きサンプルの数が少ないコスト、時間、安全性の向上。さらに、カラーセグメンテーションの結果を融合する新しいデータ投影スキームを採用しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: TF-NAS: Rethinking Three Search Freedoms of Latency-Constrained
  Differentiable Neural Architecture Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_0.html">
      <font color="black">TF-NAS: Rethinking Three Search Freedoms of Latency-Constrained
  Differentiable Neural Architecture Search</font>
    </a>
  </h2>
  <font color="black">深度レベルでは、シンク接続検索スペースを導入して、スキップ操作と他の候補操作の間の相互排除を確保し、アーキテクチャの冗長性を排除します。特に、検索されたTF-NAS-Aは76.9％のトップ1を取得します。正確さ、より少ないレイテンシで最先端の結果を達成します。幅レベルについては、徐々に細かい方法で正確なレイテンシ制約を達成する弾性スケーリング戦略を提案します。 
[ABSTRACT] three-freedom nas（tf-nas）は、良好な分類精度と正確なレイテンシ制約を達成するための新しい方法です。depth-levelでは、スキップと他の候補間の相互排除を確実にするためにシンクを接続します。検索時間はわずか1.8日です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Compression of Deep Learning Models for Text: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_1.html">
      <font color="black">Compression of Deep Learning Models for Text: A Survey</font>
    </a>
  </h2>
  <font color="black">一方、実際のアプリケーションでは、小さなモデルサイズ、短い応答時間、低い計算電力ワット数が要求されます。この調査では、6種類の方法（剪定、量子化、知識蒸留、パラメーター共有、テンソル分解、線形）について説明します。トランスフォーマーベースのメソッド）のようなモデルを圧縮して、実際の業界のNLPプロジェクトでの展開を可能にします。効率的で小さなモデルでアプリケーションを構築するという重大なニーズと、この分野で最近発表された大量の作業を考えると、この調査は過去数年の「NLPの深層学習」コミュニティによって行われた大量の作業を整理し、一貫したストーリーとして提示します。 
[ABSTRACT]これらのモデルを圧縮するための6種類の方法について説明します。これらのモデルは、プロジェクトの一環として再作成する必要があります。これらには、米国および米国からのデータデータの認識が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Unsupervised Crowd Counting via Regression-Detection
  Bi-knowledge Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_2.html">
      <font color="black">Towards Unsupervised Crowd Counting via Regression-Detection
  Bi-knowledge Transfer</font>
    </a>
  </h2>
  <font color="black">ソースで学習された回帰ベースおよび検出ベースのモデルとそれらの相互変換を考慮して、ターゲットで回帰検出双知識転送を伴う反復自己教師あり学習スキームを導入します。2つのモデルのデュアルソース知識は異種混合です群集分布のさまざまなモダリティをキャプチャするため、補完的です。教師なしの群集カウントは、挑戦的ではありますが、ほとんど調査されていないタスクです。 
[ABSTRACT]ラベルなしのターゲットセットで人物を検出してカウントする方法を学びます。このホワイトペーパーでは、転移学習の設定でそれを探ります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Anomaly localization by modeling perceptual features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_3.html">
      <font color="black">Anomaly localization by modeling perceptual features</font>
    </a>
  </h2>
  <font color="black">このFeature-Augmented VAEは、入力画像をピクセル空間で再構築するだけでなく、いくつかの異なる特徴空間でもトレーニングされます。これらは、大きな画像データセットで事前にトレーニングされた畳み込みニューラルネットワークによって計算されます。 MVTec異常検出およびローカリゼーションデータセットに関する最新の方法。ここで、これらの問題は異常分布の単純なモデルを持つことから明らかになると主張し、より複雑な異常モデルを表す新しいVAEベースのモデルを提案します。人間の知覚にも近いです。 
[要約]新しいvaeモデルは、人間の知覚に近い新しいモデルに基づいています。最近のvaeシステムで明確な改善を達成しています。また、より複雑な異常モデルを開発しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: HOSE-Net: Higher Order Structure Embedded Network for Scene Graph
  Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_4.html">
      <font color="black">HOSE-Net: Higher Order Structure Embedded Network for Scene Graph
  Generation</font>
    </a>
  </h2>
  <font color="black">具体的には、一連のコンテキスト埋め込みがローカルグラフベースのメッセージパッシングを介して学習され、グローバル構造ベースの分類空間にマップされます。最初に、ローカルとローカルの両方を組み込むための新しい構造対応のembedding-to-classifier（SEC）モジュールを提案します。出力空間への関係のグローバルな構造情報。広範な実験により、提案されたHOSE-NetがVisual GenomeとVRDの2つの一般的なベンチマークで最先端のパフォーマンスを実現することが示されています。 
[ABSTRACT]シーングラフの予測は、オブジェクトの検出と関係の分類に分けられます。ただし、一部の方法では、クラス内の大幅な変動と不均衡なデータ分布の問題があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Local Temperature Scaling for Probability Calibration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_5.html">
      <font color="black">Local Temperature Scaling for Probability Calibration</font>
    </a>
  </h2>
  <font color="black">COCOおよびLPBA40データセットの実験は、さまざまなメトリックに対して改善されたキャリブレーションパフォーマンスを示しています。一方、確率キャリブレーションアプローチは、実験的に観測されたエラーと確率出力を一致させることを目的として研究されていますが、主に、セマンティックではなく分類タスクに焦点を当てていますセグメンテーション..私たちのアプローチの1つの利点は、予測精度が変化しないため、ポストプロセッシングステップとしてキャリブレーションが可能になることです。 
[要約]学習ベースのキャリブレーション方法は、マルチラベルのセマンティックセグメンテーションに焦点を当てています。これは、製品の精度を変更しないため、温度ステップとしてのキャリブレーションが可能になるためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Identity-Aware Attribute Recognition via Real-Time Distributed Inference
  in Mobile Edge Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_6.html">
      <font color="black">Identity-Aware Attribute Recognition via Real-Time Distributed Inference
  in Mobile Edge Clouds</font>
    </a>
  </h2>
  <font color="black">ただし、バックホールネットワークの遅延やカメラからデータセンターへの大規模なデータ送信が非常に遅いため、データセンターの展開では、属性認識と個人の再IDのリアルタイム要件を満たすことができません。MECでの分散推論の問題も調査します。次に、不確実性のある動的MEC対応カメラネットワークを考慮して、提案された分散推論フレームワークのモジュールの分布に関する学習ベースのアルゴリズムを考案します。 
[ABSTRACT]データセンターの展開は、属性認識と人物の再確認のリアルタイム要件を満たしていません。これは、バックホールネットワークとカメラからデータセンターへの大規模なデータ送信が非常に遅れているためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: DAWN: Vehicle Detection in Adverse Weather Nature Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_7.html">
      <font color="black">DAWN: Vehicle Detection in Adverse Weather Nature Dataset</font>
    </a>
  </h2>
  <font color="black">DAWNデータセットは、実際の交通環境からの1000枚の画像のコレクションで構成され、霧、雪、雨、砂嵐の4つの気象条件に分けられます。このデータは、悪天候によって引き起こされる車両のパフォーマンスへの影響の解釈に役立ちます。検出システム。さらに、シーン理解と車両検出アルゴリズムは、特定のタイプの合成画像といくつかの実世界の画像を含むデータセットを使用して評価されることがほとんどです。 
[ABSTRACT]このデータセットには、さまざまな交通環境を示す画像が含まれています。データセットには、分析された画像で注釈が付けられています。これらのアルゴリズムが不明確な画像に対してどのように実行されるかは不明です。また、これらのアルゴリズムの進行状況はフィールドで標準化されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Branched Multi-Task Networks: Deciding What Layers To Share -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_8.html">
      <font color="black">Branched Multi-Task Networks: Deciding What Layers To Share</font>
    </a>
  </h2>
  <font color="black">特定の予算、すなわち。当然のことながら、可能なネットワーク構成の数は組み合わせで大きく、共有するレイヤーと分岐する場所を決定するのが面倒になります。このホワイトペーパーでは、これらの制限を超えて、分岐マルチタスクネットワークを自動的に構築する方法を提案します。採用したタスクの親和性を活用します。 
[ABSTRACT]これらの影響を受けるネットワークは通常、いくつかの共有レイヤーから始まります。その後、さまざまなタスクが独自のレイヤーのシーケンスに分岐します。以前の作業では、レイヤー共有のレベルを決定するためにアドホックな方法に依存していました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-05">
        <br><font color="black">2019-04-05</font>
      </time>
    </span>
</section>
<!-- paper0: Fine-grained Visual Textual Alignment for Cross-Modal Retrieval using
  Transformer Encoders -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_9.html">
      <font color="black">Fine-grained Visual Textual Alignment for Cross-Modal Retrieval using
  Transformer Encoders</font>
    </a>
  </h2>
  <font color="black">私たちは、この研究分野で最も優れた8つの方法と私たちのアプローチの有効性を比較します。ディープラーニングベースのビジュアルテキスト処理システムの進化にもかかわらず、正確なマルチモーダルマッチングは依然として難しい課題です。 TERANによって生成されたきめの細かい配置は、大規模なクロスモーダル情報検索のための効果的かつ効率的な方法の研究への道を開きます。 
[ABSTRACT] teranは、両方のモダリティの有益な豊富さを維持するために、画像と文の基になるコンポーネント、つまり、、および単語の間のきめの細かい一致を強制します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: BiHand: Recovering Hand Mesh with Multi-stage Bisected Hourglass
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_10.html">
      <font color="black">BiHand: Recovering Hand Mesh with Multi-stage Bisected Hourglass
  Networks</font>
    </a>
  </h2>
  <font color="black">BiHandの出力では、ネットワークから予測されたジョイントの回転と形状パラメーターを使用して、フルハンドメッシュが復元されます。2Dシード段階、3Dジョイントの2Dキーポイントとシルエット、3Dリフティングステージの深度マップ、ジョイントの回転と形状メッシュ生成ステージのパラメータ）を単一の順方向パスで使用します。各ステージ内で、BiHandは、ネットワークが2つの密接に関連する情報をカプセル化できるようにする新しい二等分設計を採用しています（たとえば、
[ABSTRACT]新しい研究では、新しいモデルを使用して3D位置を予測します。これは、2Dシードステージ、3Dリフティングステージ、メッシュ生成ステージを含む3つのステージに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Large-Scale Analysis of Iliopsoas Muscle Volumes in the UK Biobank -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_11.html">
      <font color="black">Large-Scale Analysis of Iliopsoas Muscle Volumes in the UK Biobank</font>
    </a>
  </h2>
  <font color="black">モデルのトレーニングと検証に90の手動注釈を使用できました。腸腰筋の筋肉量は、5,000人の参加者全員で正常に測定されました。腸腰筋の体積は、身長、BMI、年齢に有意に関連しており、筋肉量の減少が加速されていることもわかりました。年齢の男性で。 
[要約]腸腰筋の体積は女性の被験者と比較して男性で大きかった。年齢のある男性では筋肉量の減少が加速された</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic assembly of aero engine low pressure turbine shaft based on 3D
  vision measurement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_12.html">
      <font color="black">Automatic assembly of aero engine low pressure turbine shaft based on 3D
  vision measurement</font>
    </a>
  </h2>
  <font color="black">次に、前処理された2次元凸包が主要な穴位置フィーチャーをセグメント化するように構築され、セグメンテーションによって取得された取り付け面と穴位置がRANSAC法に基づいてフィッティングされます。測定アルゴリズムは、自動アセンブリテストベッドに実装されています。特定のタイプの航空エンジンの低圧タービンローター。最初に、ボルト表面のねじ山曲線がPCA投影とエッジ点群クラスタリングに基づいてセグメント化され、ハフ変換を使用して3次元ねじ山曲線にフィットします。 
[要約]タービンシャフトのドッキングプロセスにおけるシャフトホールアセンブリの姿勢の高精度測定が実現されます。設計は高度な高度な高度なコンピュータテクノロジーに基づいています。取り付け面のマッチングの最終的な測定精度は0.10mm未満です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: A Zero-Shot Sketch-based Inter-Modal Object Retrieval Scheme for Remote
  Sensing Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_13.html">
      <font color="black">A Zero-Shot Sketch-based Inter-Modal Object Retrieval Scheme for Remote
  Sensing Images</font>
    </a>
  </h2>
  <font color="black">提案されたスキームは、スケッチ表現が画像のわずかな原型である場合でも効率的に実行されます。この研究中に考案されたEarth on Canvas（EoC）と呼ばれる新しいバイモーダル画像スケッチデータセットで実験を行いました。このデータセットのマーキングは、提案されたネットワークが、リモートセンシングにおけるゼロショットスケッチベースの検索フレームワークのための他の最先端の方法よりも優れていることを示しています。 
[ABSTRACT]新しいバイモーダル画像-キャンバス上の地球と呼ばれるスケッチデータセットで実験を行いました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Guided Collaborative Training for Pixel-wise Semi-Supervised Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_14.html">
      <font color="black">Guided Collaborative Training for Pixel-wise Semi-Supervised Learning</font>
    </a>
  </h2>
  <font color="black">https://github.com/ZHKKKe/PixelSSL ..で利用可能なコード：最初に、GCTは、新しい欠陥検出器を介して密な出力によって引き起こされる問題に対処します。次に、GCTのモジュールは、2つの新しいタスク固有のプロパティに依存しない制約案。 
[要約]このホワイトペーパーでは、task.gctの新しいsslフレームワークを提示し、最先端の方法よりも大幅に優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Stable Low-rank Tensor Decomposition for Compression of Convolutional
  Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_15.html">
      <font color="black">Stable Low-rank Tensor Decomposition for Compression of Convolutional
  Neural Network</font>
    </a>
  </h2>
  <font color="black">ただし、数値最適化アルゴリズムで畳み込みテンソルをフィッティングすると、発散成分、つまり非常に大きなランク1テンソルが発生するが、互いに打ち消し合うことがよくあります。この論文は、畳み込みカーネルのテンソル分解における縮退に関する最初の研究です。このアプローチを評価します。画像分類のための人気のあるCNNアーキテクチャに基づいて、私たちの方法がはるかに低い精度低下をもたらし、一貫したパフォーマンスを提供することを示しています
[要約]この問題への簡単なアプローチは、畳み込みカーネルをその低進化カーネルで置き換えることです。これらの畳み込みカーネルは、それらを低ランクの比較で置き換えています。これらの縮退は、ニューラルネットワークの解釈不能な結果と数値の不安定性を引き起こすことがよくあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Semixup: In- and Out-of-Manifold Regularization for Deep Semi-Supervised
  Knee Osteoarthritis Severity Grading from Plain Radiographs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_16.html">
      <font color="black">Semixup: In- and Out-of-Manifold Regularization for Deep Semi-Supervised
  Knee Osteoarthritis Severity Grading from Plain Radiographs</font>
    </a>
  </h2>
  <font color="black">Semixupは、内挿された一貫性とともに、多様体の内外のサンプルを使用した一貫性の正則化に依存しています。ただし、これらの方法では、大量のラベル付きデータが必要であり、取得にコストがかかります。この研究では、Semixupアルゴリズムを提案します。ラベルなしデータを活用する半教師あり学習（SSL）アプローチ。 
[ABSTRACT]この筋骨格は、X線評価を評価する必要があります。これは通常、X線評価によって確認されます。これは、深層学習法がOA重症度評価を実行する方法を説明します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-04">
        <br><font color="black">2020-03-04</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Feature Descriptors using Camera Pose Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_17.html">
      <font color="black">Learning Feature Descriptors using Camera Pose Supervision</font>
    </a>
  </h2>
  <font color="black">生成された記述子をCAmera Pose Supervised（CAPS）記述子と呼びます。ピクセルレベルのグラウンドトゥルース対応が不要になったため、フレームワークは、はるかに大規模で多様なデータセットでトレーニングし、より優れた偏りのない記述子にできる可能性を広げています。ただし、既存の記述子学習フレームワークでは、通常、トレーニングのために特徴点間のグラウンドトゥルース対応が必要であり、大規模に取得するのは困難です。 
[ABSTRACT]記述子学習フレームワークには根拠と真実の対応が必要です。これらには、記述子を利用する新しい損失関数が含まれています。これらの記述子は、手法から学習する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br><font color="black">2020-04-28</font>
      </time>
    </span>
</section>
<!-- paper0: Look here! A parametric learning based approach to redirect visual
  attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_18.html">
      <font color="black">Look here! A parametric learning based approach to redirect visual
  attention</font>
    </a>
  </h2>
  <font color="black">既存の注意シフトアルゴリズムとは対照的に、グローバルパラメトリックアプローチは、画像のセマンティクスをより適切に保持し、典型的な生成アーティファクトを回避します。編集により、あらゆる画像サイズでインタラクティブなレートで推論が可能になり、ビデオに簡単に一般化できます。このペーパーでは、実用的なツールを紹介します。将来の画像編集パイプラインを簡素化します。 
[ABSTRACT]新しい方法は、画像領域をより魅力的にすることです。これにより、ユーザーは編集を上または下にダイヤルして編集した画像をカスタマイズできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Learn from Mistakes: Robust Optimization for Adversarial
  Noise -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_19.html">
      <font color="black">Learning to Learn from Mistakes: Robust Optimization for Adversarial
  Noise</font>
    </a>
  </h2>
  <font color="black">敵対的な例を使用してモデルを堅牢に最適化することを学習し、新しい敵対的な例を生成する必要なしに、学習した知識を新しいモデルに転送できるメタオプティマイザーをトレーニングします。最も説得力のある防御である敵対的なトレーニングには、大幅な増加が必要です。実験結果は、メタオプティマイザがさまざまなアーキテクチャおよびデータセットにわたって一貫していることを示しており、敵対的な脆弱性に自動的にパッチを適用できることを示唆しています。 
[ABSTRACT]十分に強力な敵対的システムが提案されていますが、それはまだ未解決の問題です。低データ体制で堅牢なモデルをトレーニングし、異なるモデル間で敵対的知識を転送します。オプティマイザーは、異なるアーキテクチャとデータセット全体で一貫しており、敵対的な脆弱性に自動的にパッチを適用する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Balanced Depth Completion between Dense Depth Inference and Sparse Range
  Measurements via KISS-GP -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_20.html">
      <font color="black">Balanced Depth Completion between Dense Depth Inference and Sparse Range
  Measurements via KISS-GP</font>
    </a>
  </h2>
  <font color="black">密で正確な深度マップ回復の問題を対象として、この論文では、深度推論と深度回帰の役割を分割することにより、これら2つのモダリティの融合を深度完了（DC）問題として紹介します。深層学習の最近の進歩により、単一の画像からのフル解像度。最新のMDEとガウシアンプロセス（GP）ベースの深度回帰法を利用して、スパースで深度を拡張することにより、さまざまなMDEモジュールを柔軟に処理できる一般的なソリューションを提案します。レンジ測定。 
[ABSTRACT] deep mdを使用すると、単一の画像に基づいてフル解像度で深度を推定できます。これは、高度で高度な高度なディープラーニングに基づいています。多くのロボットアプリケーションで、正確でありながら密な測定が可能です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Dense-Captioning Events in Videos: SYSU Submission to ActivityNet
  Challenge 2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_21.html">
      <font color="black">Dense-Captioning Events in Videos: SYSU Submission to ActivityNet
  Challenge 2020</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは2段階のパイプラインに従います。最初に、一時的なイベントの提案のセットを抽出します。次に、イベントレベルの時間的関係をキャプチャし、マルチモーダル情報を効果的に融合するマルチイベントキャプションモデルを提案します。このテクニカルレポートでは、ActivityNetチャレンジ2020の高密度ビデオキャプションタスクへの提出について簡単に説明します。アプローチは、テストセットで9.28 METEORスコアを達成します。 
[ABSTRACT]これは、一連の技術的な課題が提示されたのは初めてです。概念体系の概念には、将来の簡単な説明があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-21">
        <br><font color="black">2020-06-21</font>
      </time>
    </span>
</section>
<!-- paper0: Layer-wise training convolutional neural networks with smaller filters
  for human activity recognition using wearable sensors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_22.html">
      <font color="black">Layer-wise training convolutional neural networks with smaller filters
  for human activity recognition using wearable sensors</font>
    </a>
  </h2>
  <font color="black">アイデアに触発された論文では、HARにレゴフィルターを使用した軽量CNNを提案しました。フィルターはCNNを構築する際の基本単位であるため、より小さなフィルターの再設計がディープHARに適用できるかどうかをさらに調査する価値があります。畳み込みニューラルネットワーク（CNN）は、さまざまな人間活動認識（HAR）データセットに最新の最先端技術を導入しています。 
[ABSTRACT]カリフォルニア大学の研究者は、harにレゴフィルターを使用した軽量cnnを提案しました。ローカル損失関数を使用してモデルをトレーニングします。プロジェクトはアイデアに触発され、harの人間による再構築を提案しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-08">
        <br><font color="black">2020-05-08</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic Object Removal and Spatio-Temporal RGB-D Inpainting via
  Geometry-Aware Adversarial Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_23.html">
      <font color="black">Dynamic Object Removal and Spatio-Temporal RGB-D Inpainting via
  Geometry-Aware Adversarial Learning</font>
    </a>
  </h2>
  <font color="black">大まかなトポロジから細かいトポロジまで続き、以前のタイムステップからの情報を適応的に融合するためにゲート付きの再帰フィードバックメカニズムを組み込んだ、新しいジオメトリ対応のDynaFillアーキテクチャを提案します。修復する問題を画像から画像への変換タスク、モデルとしてキャストまた、影や反射など、シーン内の動的オブジェクトの存在に関連する領域を修正します。動的オブジェクトは、ローカリゼーションやマッピングなどの重要なタスクのパフォーマンスを低下させる環境のロボットの知覚に大きな影響を与えます。 
[ABSTRACT]私たちのアーキテクチャは、敵対的なトレーニングを使用して、細かいリアルなテクスチャを合成します。これらにより、注意を当てることなく、オンラインで空間的かつ一貫性のある方法で、閉塞領域の色と深度構造を幻覚化できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Online Graph Completion: Multivariate Signal Recovery in Computer Vision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_24.html">
      <font color="black">Online Graph Completion: Multivariate Signal Recovery in Computer Vision</font>
    </a>
  </h2>
  <font color="black">たとえば、マトリックス（またはテンソル）として現れるデータの部分的な測定値の順次取得では、残りのエントリの完了（または協調フィルタリング）のための新しい戦略が最近研究されたばかりです。Imgurから収集された大量の画像セット、そうでなければ分類するのが難しい画像で有望な結果が見られます。コンピュータビジョンと機械学習での「ヒューマンインザループ」パラダイムの採用は、実際のデータ取得（たとえば、人間の監督）であるさまざまなアプリケーションにつながります。そして、基礎となる推論アルゴリズムは密接に絡み合っています。 
[ABSTRACT]部分的に観測された測定値、財務上の制約、データの追加の分布または構造的側面など、多くの実際的な問題について。たとえば、追加の測定値の要求を時系列で行う必要がある「結論」アルゴリズムを調査します。大規模なセットimgurから収集した画像の中で、分類するのが難しい画像については有望な結果が得られます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: TextRay: Contour-based Geometric Modeling for Arbitrary-shaped Scene
  Text Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_25.html">
      <font color="black">TextRay: Contour-based Geometric Modeling for Arbitrary-shaped Scene
  Text Detection</font>
    </a>
  </h2>
  <font color="black">表現を効果的に学習するために、幾何加重と視覚的コンテンツの間の伝播経路を構築する集中加重トレーニング戦略とコンテンツ損失を設計します。任意形状のテキスト検出は、大きなアスペクト比、さまざまなスケール、ランダムな回転、曲線の形状。コードはhttps://github.com/LianaWang/TextRayで入手できます。 
[抽象]幾何学的モデリングは極座標系で実行されます。形状空間と単一ピースの対数の間の双方向マッピングスキームに基づいています。これらは視覚的なマッピングに基づいており、複雑な幾何学的レイアウトを統一表現に提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-11">
        <br><font color="black">2020-08-11</font>
      </time>
    </span>
</section>
<!-- paper0: The Ensemble Method for Thorax Diseases Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_26.html">
      <font color="black">The Ensemble Method for Thorax Diseases Classification</font>
    </a>
  </h2>
  <font color="black">胸部X線画像データセットの実験結果は、この新しい重み付けスキームが分類パフォーマンスを向上させること、またEfficientNetからのトレーニング最適化がパフォーマンスをさらに向上させることを示しています。このホワイトペーパーでは、損失関数のトレーニングパターンの重みは、クラス内のトレーニングパターンの数だけでなく、それらの1つがこのトレーニングパターンをポジティブとして処理し、他のノードがネガティブとして処理するさまざまなノードについてもです。実際の単語の医用画像分類で見られる一般的な問題は、ポジティブパターンが通常まれであるデータセット内のポジティブパターンとネガティブパターンの固有の不均衡。 
[要約]提案された方法は、胸部疾患分類問題の最先端のディープネットワークアーキテクチャに基づいています。提案された代替方法との公平な比較を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-07">
        <br><font color="black">2020-08-07</font>
      </time>
    </span>
</section>
<!-- paper0: ThumbNet: One Thumbnail Image Contains All You Need for Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_27.html">
      <font color="black">ThumbNet: One Thumbnail Image Contains All You Need for Recognition</font>
    </a>
  </h2>
  <font color="black">そうすることで、ThumbNetは、大きな画像の元の入力ネットワークと同じように小さな画像で同様に機能する推論ネットワークを学習します。ThumbNetを使用すると、計算とメモリの要件を大幅に削減できるサムネイル入力推論ネットワークを取得できるだけでなく、一般的な分類タスクのサムネイル画像を生成できる画像ダウンスケーラーも取得します。広範な実験により、ThumbNetの有効性が示され、ThumbNetによって学習されたサムネイル入力推論ネットワークが、元の入力ネットワークの精度を適切に維持できることが実証されています入力画像が16倍に縮小されたとき。 
[ABSTRACT]現在の作品は、ほとんどの場合、システムの複雑さに対するサムネットの影響を無視して、そのパラメーターまたはイーサンで発生する計算を削減することによってネットワークを圧縮しようとしています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-10">
        <br><font color="black">2019-04-10</font>
      </time>
    </span>
</section>
<!-- paper0: Temporal-Coded Deep Spiking Neural Network with Easy Training and Robust
  Performance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_28.html">
      <font color="black">Temporal-Coded Deep Spiking Neural Network with Easy Training and Robust
  Performance</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、同等のサイズとアーキテクチャのDNNの1％以内のテスト精度で、ベンチマークデータセットCIFAR10およびImageNetを介して、時間コード化されたディープなSNNを簡単かつ直接トレーニングできることを示します。SNNは、実用的なニューロモーフィックハードウェアでは、重みを8、4、2ビットに量子化し、ランダムノイズによって摂動された重みでディープSNNをトレーニングして、実用的なアプリケーションでの堅牢性を実証します。さらに、実装する位相ドメイン信号処理回路図を開発します。既存の作業よりもエネルギー効率が90％向上したスパイクニューロン。 
[ABSTRACT]クローズドフォームのおかげでトレーニングはdnnと同様になります-スパイク波形ダイナミクスのソリューション</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-24">
        <br><font color="black">2019-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Select Good Regions for Deblurring based on Convolutional Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_29.html">
      <font color="black">Select Good Regions for Deblurring based on Convolutional Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">最初に、ラベル付きの画像パッチを構築し、ディープニューラルネットワークをトレーニングします。次に、学習したモデルを適用して、画像のどの領域がぼかし解除に最適かを判断します。ブラインド画像のぼかし解除の目的は、1つの入力ぼかし画像から鮮明な画像を復元することです未知のブラーカーネルを使用します。ほとんどの画像のブレ除去アプローチは、事前の画像の開発に焦点を当てていますが、ブラーカーネルの推定に対する画像の詳細と構造の影響に十分な注意が払われていません。 
[要約]ぼかしカーネル推定に対する画像の詳細と構造の影響に十分な注意が払われていない。提案されたアプローチは効果的であり、画像のぼかし解除に適した領域を選択できる可能性がある</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Vehicle-Human Interactive Behaviors in Emergency: Data Extraction from
  Traffic Accident Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_30.html">
      <font color="black">Vehicle-Human Interactive Behaviors in Emergency: Data Extraction from
  Traffic Accident Videos</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーで提案するアプローチでは、画像処理を使用して、元のビデオの視点とは異なる新しい視点を取得します。現在、緊急時の車と人間の対話型行動を研究するには、実際の緊急事態で大量のデータセットが必要です。利用できません。リアルタイムの事故ビデオからデータを抽出するための主な課題は、記録用カメラがキャリブレーションされておらず、監視の角度が不明であることです。 
[ABSTRACT]自動運転車（avs）の既存のパブリックデータソースは、主に新しい運転シナリオまたは人間の関与のない緊急事態に焦点を当てています。データ抽出の主な課題は、カメラの記録が未調整であり、監視の角度が不明であることです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-02">
        <br><font color="black">2020-03-02</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Geometry Guided Neural Relighting with Flash Photography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_31.html">
      <font color="black">Towards Geometry Guided Neural Relighting with Flash Photography</font>
    </a>
  </h2>
  <font color="black">さらに、単一画像ベースのセットアップにより、データキャプチャプロセスが大幅に簡素化されます。深度マップを組み込むことにより、私たちのアプローチは、懐中電灯画像からのジオメトリに基づく画像分解を介して、新しい照明の下で現実的な高周波効果を推定し、キャストを予測できます。シャドウエンコーディング変換された深度マップからのシャドウマップ。固有の画像分解と画像の再ライティングにおける最先端の画像ベースのアプローチに対するジオメトリガイドアプローチの利点を実験的に検証し、実際のモバイルでのパフォーマンスも実証します電話の写真の例。 
[ABSTRACT]私たちのアプローチは、新しい照明の下で現実的な高周波効果を推定することができます。異なる方法では、異なる照明条件下でカラー画像を巧妙にサンプリングする必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: DXSLAM: A Robust and Efficient Visual SLAM System with Deep Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_32.html">
      <font color="black">DXSLAM: A Robust and Efficient Visual SLAM System with Deep Features</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、ディープたたみ込みニューラルネットワーク（CNN）を使用した特徴抽出をシームレスに最新のSLAMフレームワークに組み込むことができることを示しています。ローカルの特徴、グローバルな特徴、および語彙に基づいて、信頼性の高いループ閉鎖検出方法が構築されています。 Bag of Words（BoW）メソッドを使用して、ローカル機能の視覚的な語彙もトレーニングします。 
[要約]提案されたスラムシステムは、最新のcnnを使用して各画像フレームのキーポイントを検出します。これらには、キーポイント記述子が含まれますが、画像全体のグローバル記述子も含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: A Surgery of the Neural Architecture Evaluators -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_33.html">
      <font color="black">A Surgery of the Neural Architecture Evaluators</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、NAS-Bench-201ベンチマークサーチスペースでワンショットおよび予測子ベースの両方のエバリュエーターの広範な評価を実施し、さまざまな要因が評価相関およびその他のNAS指向の基準にどのように、そしてなぜ影響するかを分析します。 。一般的に使用される高速アーキテクチャエバリュエーターには、ワンショットエバリュエーター（ウェイトシェアリングとハイパーネットベースのエバリュエーターを含む）と予測子ベースのエバリュエーターがあります。コードはhttps://github.com/walkerning/aw_nasで入手できます。 
[要約] NASの主な課題は、神経構造の迅速かつ正確な評価を行うことです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-07">
        <br><font color="black">2020-08-07</font>
      </time>
    </span>
</section>
<!-- paper0: Object Detection for Graphical User Interface: Old Fashioned or Deep
  Learning or a Combination? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_34.html">
      <font color="black">Object Detection for Graphical User Interface: Old Fashioned or Deep
  Learning or a Combination?</font>
    </a>
  </h2>
  <font color="black">私たちは、50k以上のGUI画像で7つの代表的なGUI要素検出方法の最初の大規模な実証研究を実施して、これらの方法の機能、制限、および効果的な設計を理解しています。GUI画像でのグラフィカルユーザーインターフェイス（GUI）要素の検出は、ドメイン-特定のオブジェクト検出タスク..新しいGUI固有の昔ながらの非テキストGUI要素検出方法を設計します。これは、新しいトップダウンの粗から細かい戦略を採用し、GUIの成熟したディープラーニングモデルと組み合わせます。テキスト検出。25,000枚のGUI画像に対する私たちの評価は、この手法がGUI要素の検出における最先端のパフォーマンスを大幅に向上させることを示しています。 
[要約]新しいgui要素検出モデルは、guiとgui要素を検出する機能を使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervised Video Representation Learning Using Inter-intra
  Contrastive Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_35.html">
      <font color="black">Self-supervised Video Representation Learning Using Inter-intra
  Contrastive Framework</font>
    </a>
  </h2>
  <font color="black">IICフレームワークには多くの柔軟なオプションがあり、いくつかの異なる構成を使用して実験を行います。従来の自己監視手法の標準的なアプローチでは、正負のデータのペアを使用して、対照的な学習戦略でトレーニングします。評価は、ビデオの取得と学習したビデオ表現を使用したビデオ認識タスク。 
[要約]従来の自己監視手法の標準的なアプローチでは、ポジティブ-ネガティブ-ネガティブデータのペアを使用して、対照的な学習戦略でトレーニングします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-06">
        <br><font color="black">2020-08-06</font>
      </time>
    </span>
</section>
<!-- paper0: A Longitudinal Method for Simultaneous Whole-Brain and Lesion
  Segmentation in Multiple Sclerosis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_36.html">
      <font color="black">A Longitudinal Method for Simultaneous Whole-Brain and Lesion
  Segmentation in Multiple Sclerosis</font>
    </a>
  </h2>
  <font color="black">この論文では、多発性硬化症に苦しむ患者の縦脳MRIスキャンのセグメンテーションの新しい方法を提案します。この方法は、全脳と病変の同時セグメンテーションの既存の断面法に基づいており、被験者固有の潜在変数を縦方向スキャン間の時間的一貫性を促進します。これは、スキャナー、MRIプロトコル、または縦方向フォローアップスキャンの数とタイミングに関する事前の仮定を行わないため、非常に一般的に適用できます。 
[要約]提案された方法は、既存の方法で全体を同時に構築します-脳と病変のセグメンテーション。また、対象-特定の潜在変数を導入して、mriスキャン間の空間を促進します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Attention-based Fully Gated CNN-BGRU for Russian Handwritten Text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_37.html">
      <font color="black">Attention-based Fully Gated CNN-BGRU for Russian Handwritten Text</font>
    </a>
  </h2>
  <font color="black">また、Tahnの複数の出力機能と入力機能を利用して完全にゲート化されたレイヤーを提案します。この提案された作業により、より良い結果が得られます。手書きのカザフ語とロシア語データベース（HKR）でモデルを実験しました。 HKRデータセットでの最初の作業と、他のほとんどの既存のモデルに対する最先端の結果の実証。この研究では、カザフ語とロシア語でトレーニングされた注意エンコーダーデコーダーネットワークを使用して手書きテキストのタスクに取り組みます。 
[要約]私たちは、完全にゲートされたcnnに基づいた新しいディープニューラルネットワークモデルを開発します。これは、複数の双方向GRUと注意メカニズムによってサポートされています。当社の研究は、HKRデータセットに関する最初の作業です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: A survey of loss functions for semantic segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_38.html">
      <font color="black">A survey of loss functions for semantic segmentation</font>
    </a>
  </h2>
  <font color="black">特定の損失関数がすべてのデータセットで良好に機能し、unknown-distributionデータセットで適切な選択肢として使用できることを示しました。コードはhttps://github.com/shruti-jadon/Semantic-Segmentation-Loss-Functionsで入手できます。 ..このホワイトペーパーでは、画像のセグメンテーションで広く使用されているよく知られた損失関数のほとんどを要約し、それらの使用法がモデルの高速で優れた収束に役立つ場合を挙げています。 
[要約]新しいログ-coshダイス損失関数も導入しました。コードはwww。 github。 com</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-26">
        <br><font color="black">2020-06-26</font>
      </time>
    </span>
</section>
<!-- paper0: Factor Graph based 3D Multi-Object Tracking in Point Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_39.html">
      <font color="black">Factor Graph based 3D Multi-Object Tracking in Point Clouds</font>
    </a>
  </h2>
  <font color="black">代わりに、既製の3Dオブジェクト検出器の結果をガウス混合モデルとして表現します。これは因子グラフフレームワークに組み込まれています。その結果、割り当て問題は3D空間マルチオブジェクトと暗黙的かつ共同で解決されます非線形最小二乗最適化を使用した状態推定。これにより、すべての検出をすべてのオブジェクトに同時に割り当てる柔軟性が得られます。 
[要約]提案されたアルゴリズムは、オフラインおよびオンラインの追跡に適用できます。その単純さにもかかわらず、システムは堅牢で信頼性の高い追跡結果を実現します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: An Inter- and Intra-Band Loss for Pansharpening Convolutional Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_40.html">
      <font color="black">An Inter- and Intra-Band Loss for Pansharpening Convolutional Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">これらのパンシャープニングネットワークは、CNNのさまざまな特徴的な構造に焦点を当てており、それらのほとんどは、融合画像とシミュレートされた目的のマルチスペクトル画像の間のL2損失によってトレーニングされます。提案されたIIB損失は、バンド内とバンド内の両方の関係を効果的に維持でき、直接適用できます。この手紙では、元のL2損失の欠点を克服するために、新しいバンド間およびバンド内（IIB）損失を提案します。 
[ABSTRACT] pansharp2損失は、バンド間およびバンド内の両方の関係を効果的に維持できます。異なるパンシャープンCNNに直接適用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Inter-Image Communication for Weakly Supervised Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_41.html">
      <font color="black">Inter-Image Communication for Weakly Supervised Localization</font>
    </a>
  </h2>
  <font color="black">2番目の制約は、データセット全体のオブジェクトフィーチャのグローバルな整合性を学習することです。1番目の制約は、バッチ内のさまざまな画像からランダムにサンプリングされる識別ピクセル間の確率的フィーチャの整合性を学習することです。1つの画像に埋め込まれた判別情報画像間通信で相手に利益をもたらすために活用できます。 
[ABSTRACT] 2種類の制約が提案され、同じカテゴリ内のオブジェクトの特徴の一貫性を促進します。1つの画像に埋め込まれたしわが寄る情報を利用して、画像間通信で対応するものに利益をもたらすことができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: End-To-End Convolutional Neural Network for 3D Reconstruction of Knee
  Bones From Bi-Planar X-Ray Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_42.html">
      <font color="black">End-To-End Convolutional Neural Network for 3D Reconstruction of Knee
  Bones From Bi-Planar X-Ray Images</font>
    </a>
  </h2>
  <font color="black">2つの2平面X線画像から直接膝の骨を3Dで再構成するためのエンドツーエンドの畳み込みニューラルネットワーク（CNN）アプローチを提示します。各骨の形状を統計的にモデリングする一般的なアプローチとは対照的に、ネットワークは、トレーニング画像から骨の形状の分布を直接学習します。臨床的には、骨の3Dモデルをキャプチャすることは、手術計画、インプラントフィッティング、術後評価に不可欠です。 
[ABSTRACT]脳、脳および脳外科医の3Dモデルの取得は成功する可能性があります。現実的で現実的です現実的に、外科医外科医は病院に再びエネルギーを与えることができます。しかし、再エネルギー3Dモデルは簡単に簡単に取得できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-02">
        <br><font color="black">2020-04-02</font>
      </time>
    </span>
</section>
<!-- paper0: PAM:Point-wise Attention Module for 6D Object Pose Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_43.html">
      <font color="black">PAM:Point-wise Attention Module for 6D Object Pose Estimation</font>
    </a>
  </h2>
  <font color="black">GAPでは、幾何情報の重要な情報に注意を払うように設計されており、CAPはチャネル情報の重要な情報に注意を払うように設計されています。以前の方法は、詳細化プロセスで深度情報を利用するか、各データの異種アーキテクチャとして設計されました特徴を抽出するためのスペース。注意モジュールは、計算の複雑さを大幅に増加させることなく、特徴表現を効率的に作成することを示しています。 
[ABSTRACT] 6Dポーズを推定するための重要な技術は、あらゆる環境でポーズを見つけるのに十分な特徴を抽出してポーズを推定することです。これらの方法は、十分な特徴を抽出できないという制限があります。したがって、これらの方法では十分な特徴を抽出できません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Facial Expression Retargeting from Human to Avatar Made Easy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_44.html">
      <font color="black">Facial Expression Retargeting from Human to Avatar Made Easy</font>
    </a>
  </h2>
  <font color="black">具体的には、幾何学的対応を設計して、幾何学的マッチングを反映し、トリプレットデータ構造を使用して、ユーザーのアバター表現の知覚的好みを表現します。次に、幾何学的および知覚的制約によって導かれる2つの潜在空間間の対応を構築します。まず、低次元を構築します。変分オートエンコーダーで人間とアバターの表情のための潜在的なスペース。 
[ABSTRACT]従来の方法では、マーカーまたはブレンドシェイプを使用して、人間とアバターの顔の間のマッピングを作成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Image-based Portrait Engraving -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_45.html">
      <font color="black">Image-based Portrait Engraving</font>
    </a>
  </h2>
  <font color="black">顔検出を使用して、ディザマトリックスをワープし、彫刻線を顔の周りに湾曲させてスタイルを整えます。このペーパーでは、単純な画像ベースの方法について説明します。規則的なディザリングを使用して、肖像画に彫刻のスタイルを適用します。最後に、カラー彫刻へのアプローチの適用を示します。 
[ABSTRACT]顔検出は、頭の分析に基づいてマップを推定するために使用されます。この方法を使用すると、印刷線の使用は、より良いスタイルのせいです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Adaptive Semantic Segmentation Using Weak Labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_46.html">
      <font color="black">Domain Adaptive Semantic Segmentation Using Weak Labels</font>
    </a>
  </h2>
  <font color="black">弱いラベルの使用は、（i）画像レベルのターゲットアノテーションの収集がWDAで比較的安価であり、UDAでコストがかからないため、実用的であり便利です。（ii）カテゴリごとのドメインアライメントの機会が開かれます。機能の配置と疑似ラベリングの間の相互作用を可能にする弱いラベル。ドメイン適応のプロセスの両方を改善します。実験では、UDAの既存の最先端技術に関して大幅な改善を示し、新しいベンチマークを提示します。 WDA設定で。 
[要旨]弱いラベルは、教師なしドメイン画像のモデル予測に基づいて取得できます。また、新しいソックスで人間のアノテーターから取得することもできます-教師付きドメイン（wda）1997 1997</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-30">
        <br><font color="black">2020-07-30</font>
      </time>
    </span>
</section>
<!-- paper0: Open Set Recognition with Conditional Probabilistic Generative Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_47.html">
      <font color="black">Open Set Recognition with Conditional Probabilistic Generative Models</font>
    </a>
  </h2>
  <font color="black">多くのモデルバリアントについて説明し、それらの特性を研究するための包括的な実験を提供します。ディープニューラルネットワークは、幅広い視覚理解タスクにおいて画期的な成果をもたらしました。複数のベンチマークデータセットでの実験結果は、提案された方法がベースラインを大幅に上回り、新しい状態を達成していることを示しています-最先端のパフォーマンス。 
[ABSTRACT]ディープニューラルネットワークは、未知のサンプルを既知のクラスの1つとして誤って認識します。しかし、従来のネットワークは、既知の分類の識別表現を提供しません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Segment Actions from Observation and Narration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_48.html">
      <font color="black">Learning to Segment Actions from Observation and Narration</font>
    </a>
  </h2>
  <font color="black">トレーニング中にアクションラベルが知られていない、監視されていない、および監視が弱い設定に焦点を当てます。ナレーションによって導かれるタスク構造の生成セグメントモデルをビデオのアクションセグメンテーションに適用します。その単純さにもかかわらず、このモデルは以前の自然主義的な教育ビデオのデータセットで作業します。 
[ABSTRACT]私たちのモデルでは、トレーニングで使用される監督のソースを変更できます。また、タスクの構造と物語の言語の両方が大きなメリットをもたらすことがわかりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br><font color="black">2020-05-07</font>
      </time>
    </span>
</section>
<!-- paper0: Improving the Performance of Fine-Grain Image Classifiers via Generative
  Data Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_49.html">
      <font color="black">Improving the Performance of Fine-Grain Image Classifiers via Generative
  Data Augmentation</font>
    </a>
  </h2>
  <font color="black">機械学習（ML）とコンピュータービジョンツールの最近の進歩により、財務分析、医療診断、さらには国防総省などのさまざまな分野でのアプリケーションが可能になりました。この方法をサポートするために、私たちは新しい拡張方法を開発しました。は、埋め込みスペース内のターゲットオブジェクトの意味的に意味のある寸法（方向など）を操作できます。ただし、実際のユースケースでのそれらの広範な実装には、いくつかの課題があります。（1）多くのアプリケーションは高度に専門化されているため、\ emph {スパースデータ}ドメイン。 （2）MLツールはトレーニングセットの影響を受けやすく、通常、面倒で労働集約的なデータ収集とデータラベル付けプロセスが必要です。 （3）MLツールは非常に「ブラックボックス」になる可能性があり、意思決定プロセスや新しいデータが予測パフォーマンスにどのように影響する可能性があるかについて、ほとんどまたはまったく洞察をユーザーに提供しません。 
[ABSTRACT]実際の使用例における最近の開発にはいくつかの課題があります。これらのツールには労働集約的なデータ収集とデータのラベル付けプロセスが必要です。これらにはdapper gan、dapper gan、dapper ganが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Representative Graph Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_50.html">
      <font color="black">Representative Graph Neural Network</font>
    </a>
  </h2>
  <font color="black">意味のあるセグメンテーションを適用することにより、私たちのRepGraphネットワークは、3つの挑戦的なベンチマークであるADE20K、Cityscapes、およびPASCAL-Contextデータセットで最先端の方法と競合または有利に実行できます。コードが利用可能ですhttps://git.io/RepGraph。にあります。RepGraphレイヤーは柔軟で、多くのビジュアルアーキテクチャに統合し、他の操作と組み合わせることができます。 
[ABSTRACT] repgraphは、1つのノードの応答を少数の代表的なノードで調査します。repgraphレイヤーは、多くの視覚的アーキテクチャに統合するために柔軟です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Tighter risk certificates for neural networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_51.html">
      <font color="black">Tighter risk certificates for neural networks</font>
    </a>
  </h2>
  <font color="black">学習した予測子の目に見えない例で有効なリスク証明書を計算します。MNISTとCIFAR-10での実験では、トレーニング方法により、競合するテストセットエラーと非空のリスク境界が以前の結果よりもはるかに狭い値で生成されることが示されていますリスクを制限することで学習アルゴリズムをガイドするだけでなく、モデルの選択も約束することを示す文献。さらに、重み（データフリーとデータ依存の両方）とニューラルネットワークアーキテクチャに関するさまざまなタイプの事前分布を実験します。 
[ABSTRACT]ニューラルネットワークを使った実験により、私たちのトレーニング方法は、競合するテストセットエラーと非真空リスク限界を生成し、以前の結果よりもはるかに厳しい値を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-25">
        <br><font color="black">2020-07-25</font>
      </time>
    </span>
</section>
<!-- paper0: LogoDet-3K: A Large-Scale Image Dataset for Logo Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_52.html">
      <font color="black">LogoDet-3K: A Large-Scale Image Dataset for Logo Detection</font>
    </a>
  </h2>
  <font color="black">さらに、Focal損失とCIoU損失を大規模なロゴ検出のための最新のYOLOv3フレームワークに組み込んだ強力なベースラインメソッドLogo-Yoloを提案します。LogoDet-3Kデータセットは、大規模なロゴを促進するために使用されます。関連の調査およびhttps://github.com/Wangjing1551/LogoDet-3K-Dataset。で見つけることができます。このホワイトペーパーでは、3,000のロゴカテゴリを持つフルアノテーションの最大のロゴ検出データセットであるLogoDet-3Kを紹介します。 、約200,000の手動で注釈を付けたロゴオブジェクトと158,652の画像。 
[ABSTRACT] logodet-3kは完全な注釈が付いた最大のロゴ検出データセットです。3,00のロゴカテゴリ、約200,000の手動で注釈されたロゴオブジェクト、および158、652の画像があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Defending Adversarial Examples via DNN Bottleneck Reinforcement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_53.html">
      <font color="black">Defending Adversarial Examples via DNN Bottleneck Reinforcement</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、DNNボトルネック強化方式を紹介して、敵対的攻撃に対するディープニューラルネットワーク（DNN）の脆弱性を緩和します。したがって、このホワイトペーパーでは、ビジュアルクラシファイアと同じエンコーディングウェイトを共有するオートエンコーダ（AE）を共同でトレーニングすることを提案します。後者を維持しながら前者を強化することにより、それが敵対的であろうとなかろうと、冗長な情報は潜在表現から削除されるべきです。 
[ABSTRACT]これは、dnnアプリがデータのボトルネックを軽減できる初めての例です。これにより、情報を潜在的な表現にエンコードするのが容易になります。これにより、敵対的またはそうでないことを防ぐことが難しくなります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervised Light Field View Synthesis Using Cycle Consistency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_54.html">
      <font color="black">Self-supervised Light Field View Synthesis Using Cycle Consistency</font>
    </a>
  </h2>
  <font color="black">生成されたビューが入力ビューと一致するように強制する双方向マッピングを構築するために、サイクル整合性制約が使用されます。この重要な概念から派生した2つの損失関数、サイクル損失と再構成損失は、事前トレーニング済みモデルを微調整するために使用されますこの問題に取り組むために、我々は、サイクルの一貫性を備えた自己管理型ライトフィールドビュー合成フレームワークを提案します。 
[要約]提案された方法は、高品質の自然なビデオデータセットから学習した事前知識をライトフィールドビュー合成タスクに転送することを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: More Diverse Means Better: Multimodal Deep Learning Meets Remote Sensing
  Imagery Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_55.html">
      <font color="black">More Diverse Means Better: Multimodal Deep Learning Meets Remote Sensing
  Imagery Classification</font>
    </a>
  </h2>
  <font color="black">「何を」、「どこで」、「どのように」融合するかに焦点を当てることで、さまざまな融合戦略と、ディープネットワークをトレーニングしてネットワークアーキテクチャを構築する方法を示します。さらに重要なのは、フレームワークがピクセルのみに限定されていないことです。賢明な分類タスクだけでなく、畳み込みニューラルネットワーク（CNN）を使用した空間情報モデリングにも適用できます。ディープネットワークは、単一モダリティ主導の分類タスクで正常に適用されていますが、そのパフォーマンスは、細かくする必要がある複雑なシーンのボトルネックに必ず対応します。情報の多様性の制限により、分類されました。 
[要約]これは、シングルモダリティが支配的な分類タスクでディープネットワークが正常に適用されているにもかかわらずです。ただし、そのパフォーマンスは、情報の多様性の制限により、細かく分類する必要がある複雑なシーンのボトルネックを満たします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Caricature via Semantic Shape Transform -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_56.html">
      <font color="black">Learning to Caricature via Semantic Shape Transform</font>
    </a>
  </h2>
  <font color="black">大規模な写真風刺画のベンチマークデータセットに対するアプローチの有効性を、最先端の手法と比較して示します。さらに、このモデルでは、ユーザーがセマンティックマップを介して形状を操作できます。提案されたフレームワークは、顔の構造を維持しながら、視覚的に楽しい形状の誇張をレンダリングすることができます。 
[ABSTRACT]シンプルなアルゴリズムは、人物の描画の詳細な詳細マップに基づいています。これを使用して、ユーザーが形状を操作できるアルゴリズムを作成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Renal Cell Carcinoma Detection and Subtyping with Minimal Point-Based
  Annotation in Whole-Slide Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_57.html">
      <font color="black">Renal Cell Carcinoma Detection and Subtyping with Minimal Point-Based
  Annotation in Whole-Slide Images</font>
    </a>
  </h2>
  <font color="black">また、サブタイピングモデルは、WSIをテストするために、診断ラベルのみでトレーニングされたモデルよりもf1-scoreで12％優れています。このため、SSLメソッドを使用して、癌領域を正確に検出するフレームワークを提案しました。最小限のポイントベースのアノテーションを使用して、予測された結果を革新的なハイブリッド損失とともに利用して、サブタイピングの分類モデルをトレーニングします。腎細胞癌（RCC）の3つの重要なサブタイプの実験により、分類器のパフォーマンスがMin-ポイント注釈付きデータセットは、癌領域検出用のセグメンテーション注釈付きデータセットでトレーニングされた分類子に匹敵します。 
[要約]システムはsslメソッドを使用して癌性領域を正確に検出します。次に、革新的なハイブリッド損失の予測結果を使用して、サブタイプの分類モデルをトレーニングします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Pixel-level Corrosion Detection on Metal Constructions by Fusion of Deep
  Learning Semantic and Contour Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_58.html">
      <font color="black">Pixel-level Corrosion Detection on Metal Constructions by Fusion of Deep
  Learning Semantic and Contour Segmentation</font>
    </a>
  </h2>
  <font color="black">ただし、派生した最終的な画像は、構造分析やプレファブリケーションに対してまだ十分に正確ではありません。このホワイトペーパーでは、腐食検出に3つのセマンティックセグメンテーション指向の深層学習モデル（FCN、U-NetおよびMask R-CNN）を適用します精度と時間の点で優れており、必要な注釈付きサンプルの数は他のディープモデルと比較して少なくなります。金属構造物の腐食検出は、迅速、安全かつ効果的な検査のための土木工学における主要な課題です。 
[ABSTRACT]新しいイメージングアプローチは、欠陥領域の周囲に境界ボックスを配置します。これは、メンテナンスコスト、時間を削減し、安全性を向上させる革新的な建設コンセプトです。さらに、カラーセグメンテーションの結果を融合する新しいデータ投影スキームを採用</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Text as Neural Operator: Image Manipulation by Text Instruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_59.html">
      <font color="black">Text as Neural Operator: Image Manipulation by Text Instruction</font>
    </a>
  </h2>
  <font color="black">提案されたモデルは、3つのデータセットの最近のベースラインに対して良好に機能することを示します。このために、モデルは生成プロセスを分解して、場所（空間領域）と修正方法（テキストオペレーター）を適用する方法を見つけます。GANベースを提案します。この問題に取り組む方法。 
[ABSTRACT]提案されたモデルは、3つのデータセットの最近のベースラインに対して良好に機能することを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-11">
        <br><font color="black">2020-08-11</font>
      </time>
    </span>
</section>
<!-- paper0: ASAP-Net: Attention and Structure Aware Point Cloud Sequence
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_60.html">
      <font color="black">ASAP-Net: Attention and Structure Aware Point Cloud Sequence
  Segmentation</font>
    </a>
  </h2>
  <font color="black">コードはhttps://github.com/intrepidChw/ASAP-Netで入手できます。第二に、効率的な時空間相関法は、埋め込みのためにより局所的な構造を活用する一方で、時間的一貫性を適用し、計算の複雑さを軽減するために提案されます。最後に、点群シーケンスセグメンテーションのための異なるバックボーンネットワークを備えた提案されたASAPモジュールの汎化能力を示します。 。 
[要旨]空間をさらに改善します-asapと呼ばれる柔軟なモジュールを使用して時間的ポイントクラウド機能を学習します。フレーム全体の注意と構造情報を考慮します。埋め込みのためにより局所的な構造を活用する方法が提案されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: FATNN: Fast and Accurate Ternary Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_61.html">
      <font color="black">FATNN: Fast and Accurate Ternary Neural Networks</font>
    </a>
  </h2>
  <font color="black">さらに、TNNと完全な精度のネットワークとの間の精度には依然として大きなギャップがあり、実際のアプリケーションへの展開が妨げられています。これらの2つの課題に取り組むために、この作業では、最初に、いくつかの穏やかな制約の下で、三項内積は2倍削減できます。その結果、従来のTNNは、標準の2ビットモデルと比較してメモリ消費量と速度は同じですが、表現能力は劣ります。 
[要約] 3つの量子化レベルのみを使用して3値表現をエンコードするには2ビットが必要です。それでも、tnnsとフルビットネットワークの精度には大きなギャップがあり、それらの表現は妨げられます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: RAF-AU Database: In-the-Wild Facial Expressions with Subjective Emotion
  Judgement and Objective AU Annotations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_62.html">
      <font color="black">RAF-AU Database: In-the-Wild Facial Expressions with Subjective Emotion
  Judgement and Objective AU Annotations</font>
    </a>
  </h2>
  <font color="black">自動表情認識に関する作業の多くは、エクマンの基本的な感情理論に基づいて、特定の数の感情クラスとその誇張された顔の構成（通常は6つの典型的な顔の表情）を含むデータベースに依存しています。これらの感情ラベルは、野生の顔の表情は、定義済みのAUパターンだけで簡単に注釈を付けることはできません。この問題に対処するために、サインベース（つまりAU）と判断ベース（つまり、知覚される感情）のアプローチを採用したRAF-AUデータベースを開発します野生のブレンドされた表情に注釈を付けること。 
[ABSTRACT]私たちの生活の中での顔の表情は、複数の基本的な感情とブレンドすることができます。顔の表情などの最も複雑な表情は未解決の問題です。人気の機能とマルチラベルを使用して、raf-auのau認識のベースラインを提供しました学習方法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Text-Guided Neural Image Inpainting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CV/paper_63.html">
      <font color="black">Text-Guided Neural Image Inpainting</font>
    </a>
  </h2>
  <font color="black">結果分析は、生成された画像がガイダンステキストと一致し、さまざまな説明を提供することでさまざまな結果の生成を可能にすることを示唆しています。2つのオープンデータセットで実験が行われます。このようなタスクを実行するために、Text-ガイド付きデュアルアテンションインペインティングネットワーク（TDANet）。 
[要約]カリフォルニア大学の研究者は、テキストと呼ばれる新しいモデルを開発しています-ガイド付き二重注意修復ネットワーク（tdanet）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br><font color="black">2020-04-07</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Compression of Deep Learning Models for Text: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_0.html">
      <font color="black">Compression of Deep Learning Models for Text: A Survey</font>
    </a>
  </h2>
  <font color="black">一方、実際のアプリケーションでは、小さなモデルサイズ、短い応答時間、低い計算パワーワット数が要求されます。効率的で小さなモデルを使用してアプリケーションを構築するという重要なニーズと、この分野で最近発表された大量の作業を考えると、この調査は、過去数年間に「NLPのディープラーニング」コミュニティによって行われた大量の作業を整理し、それを首尾一貫した物語として提示していることを示しています。近年、自然言語処理（NLP）と情報検索（IR ）は、Recurrent Neural Networks（RNNs）、Gated Recurrent Units（GRUs）and Long Short-Term Memory（LSTMs）networksなどのディープラーニングモデル、およびトランスフォーマーからの双方向エンコーダー表現（BERT）などのトランスフォーマーベースのモデルのおかげで、大きな進歩を遂げました
[ABSTRACT]これらのモデルを圧縮するための6種類の方法について説明します。これらのモデルは、プロジェクトの一環として再作成する必要があります。これらには、米国および米国からのデータデータの認識が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: VAW-GAN for Singing Voice Conversion with Non-parallel Training Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_1.html">
      <font color="black">VAW-GAN for Singing Voice Conversion with Non-parallel Training Data</font>
    </a>
  </h2>
  <font color="black">音声コンテンツから歌手のアイデンティティと歌の韻律（F0輪郭）を解くようにエンコーダーをトレーニングします。実験結果は、提案されたフレームワークがベースラインフレームワークよりも優れたパフォーマンスを達成することを示しています。このホワイトペーパーでは、 VAW-GAN。 
[要約]このホワイトペーパーでは、vawに基づいた歌声変換フレームワークを提案します。gan.itは歌手IDとfsteinを使用してf0レンダリングを改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Transfer Learning Approaches for Streaming End-to-End Speech Recognition
  System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_2.html">
      <font color="black">Transfer Learning Approaches for Streaming End-to-End Speech Recognition
  System</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、RNN-Tフレームワークの4つの異なるTL手法の比較研究を紹介します。RNN-Tフレームワークの場合、エンコーダーと予測ネットワークの初期化モデルの選択に応じて、いくつかの転送学習戦略が存在します。ランダムに初期化されたRNN-Tモデルに対して、さまざまなTLメソッドを使用して相対ワードエラー率を17％削減。 
[ABSTRACT] tlは、再帰型ニューラルネットワークトランスデューサー（rnn-t）モデルなどのエンドツーエンド（e2e）asrシステムに適用できます。asrシステムは、ターゲット言語のエンコーダーと予測ネットワークをテストするために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: The Language Interpretability Tool: Extensible, Interactive
  Visualizations and Analysis for NLP Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_3.html">
      <font color="black">The Language Interpretability Tool: Extensible, Interactive
  Visualizations and Analysis for NLP Models</font>
    </a>
  </h2>
  <font color="black">パフォーマンスが低下するのはいつですか。 LITは、ローカルの説明、集計分析、および反事実生成を合理化されたブラウザベースのインターフェースに統合して、迅速な調査とエラー分析を可能にします。LITは活発に開発されており、コードと完全なドキュメントはhttps://github.com/pairで入手できます-コード/点灯。 
[ABSTRACT]モデルの動作に関する中心的な質問に焦点を当てます。さまざまなワークフローセットのケーススタディを含めます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Spectrum and Prosody Conversion for Cross-lingual Voice Conversion with
  CycleGAN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_4.html">
      <font color="black">Spectrum and Prosody Conversion for Cross-lingual Voice Conversion with
  CycleGAN</font>
    </a>
  </h2>
  <font color="black">F0モデリングに連続ウェーブレット変換（CWT）分解を使用することを提案します。CWTは、信号をさまざまな時間分解能で韻律を説明するさまざまな時間スケールに分解する方法を提供します。また、スペクトルと韻律の2つのCycleGANパイプラインをトレーニングすることを提案しますそれぞれマッピング。 
[ABSTRACT]たとえば、2つのスピーカーのパラレルデータの必要性を排除します。これは、クロスリンガル音声変換における韻律の最初の研究です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-11">
        <br><font color="black">2020-08-11</font>
      </time>
    </span>
</section>
<!-- paper0: GasMet: Profiling Gas Leaks in the Deployment of Solidity Smart
  Contracts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_5.html">
      <font color="black">GasMet: Profiling Gas Leaks in the Deployment of Solidity Smart
  Contracts</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、スマートコントラクトの展開およびトランザクションコストに影響を与える可能性のある20個のSolidityコードの臭い、つまり\ textit {cost smells} ..を体系的に特定します。たとえば、データ構造や使用される特定の指示-必要以上のガス消費につながる可能性があります。Ethereumでは、コンパイルされると、スマートコントラクトは、コンピューティングリソースと\ textitを提供することにより、Ethers（ビットコインのような暗号通貨）を稼ぐことができる鉱山労働者のマシンで実行されます{ガス}（Etherの場合）は、このようなコンピューティングリソースを補う実行料に相当します。 
[ABSTRACT]イーサリアムでは、スマートコントラクトは、コンピューティングリソースを提供することでエーテル（ビットコインのような暗号通貨）を獲得できるマイナーのマシンで実行されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Evaluating the Impact of Knowledge Graph Contexton Entity Disambiguation
  Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_6.html">
      <font color="black">Evaluating the Impact of Knowledge Graph Contexton Entity Disambiguation
  Models</font>
    </a>
  </h2>
  <font color="black">私たちの経験的結果は、提案されたKGコンテキストを一般化できること（Wikipediaの場合）を検証し、変圧器アーキテクチャでのKGコンテキストの提供は、バニラ変圧器モデルを含む既存のベースラインを大幅に上回っています。 ..事前トレーニング済みのTransformerモデルは、テキストからコンテキスト情報を学習していくつかのNLPタスクのパフォーマンスを向上させる最先端のアプローチとして登場しました。 
[要約]提案されたkgコンテキストはwikipediaに対して標準化できます。既存のモデルにはまだ特殊なコンテキストが必要です。これらのモデルには依然として特殊なコンテキストが必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Glushkov's construction for functional subsequential transducers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_7.html">
      <font color="black">Glushkov's construction for functional subsequential transducers</font>
    </a>
  </h2>
  <font color="black">Glushkovの構造には多くの興味深い特性がありますが、トランスデューサーに適用すると、さらに明らかになります。ここで紹介する方法とアルゴリズムは、正規表現のコンパイラーを実装するために使用されました。この記事は、機能的な後続有限状態トランスデューサー間の異常なリンクを示すことを目的としています。そしてGlushkovの建設。 
[要約]この記事は、機能的な後続有限状態トランスデューサとglushkovの構造との間の異常なリンクを示すよう努めています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Text Classification based on Multi-granularity Attention Hybrid Neural
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_8.html">
      <font color="black">Text Classification based on Multi-granularity Attention Hybrid Neural
  Network</font>
    </a>
  </h2>
  <font color="black">RNNやConvNetsなどの各ニューラルアーキテクチャには独自の長所と短所があるため、さまざまなアーキテクチャを統合すると、テキストのセマンティック表現が豊かになり、NLPタスクのパフォーマンスが向上すると想定されます。構文上の注意により重要度が計算されます下位のシンボリックレベルでの構文要素（単語や文など）の解釈と意味の注意が、上位の潜在的意味に対応する埋め込み空間次元の重要性を計算するために使用されます。構文上の注意と意味上の注意。 
[ABSTRACT]これらには、リカレントニューラルネットワーク（rnn）とたたみ込みニューラルネットワークが含まれます。convnetsにはメモリ機能がなく、同時データを順序付けられていない機能としてモデル化する必要があります。異なるアーキテクチャの統合は、セマンティックを強化できると想定されていますテキストの表現、したがってnlpタスクのパフォーマンスを向上させる</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Navigating Language Models with Synthetic Agents -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_9.html">
      <font color="black">Navigating Language Models with Synthetic Agents</font>
    </a>
  </h2>
  <font color="black">さらに、モデルがチェス盤の正確な潜在的表現を作成し、この知識を使用して法的移動の軌跡をプロットできることもわかりました。この研究では、コーパスでGPT-2のバージョンをトレーニングします歴史的なチェスゲームの概要を学習し、モデル内の単語の学習された関係をチェス盤の既知のグラウンドトゥルースと比較し、合法性とプレーの歴史的パターンを移動します。GPT-2/ GPT-3などの現代の自然言語モデル人間の信念に関する途方もない量の情報を、一貫して尋問可能な形で含みます。 
[ABSTRACT]モデルを使用した動きのパーセンテージはよく知られていることがわかります。また、これらの動きは人間のパターンと実質的に類似していることがわかります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Variance-reduced Language Pretraining via a Mask Proposal Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_10.html">
      <font color="black">Variance-reduced Language Pretraining via a Mask Proposal Network</font>
    </a>
  </h2>
  <font color="black">自然言語処理では、自己監視学習（別名、事前トレーニング）が重要です。このようにして、人間のラベル付けなしでモデルをトレーニングでき、膨大なデータを10億のパラメーターで使用できます。このホワイトペーパーでは、勾配分散減少の観点からの問題。 
[ABSTRACT]ほとんどの事前トレーニング方法では、最初に文の一部の位置をランダムにマスクしてから、モデルをトレーニングして、マスクされた位置のトークンを復元します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Distantly Supervised Relation Extraction in Federated Settings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_11.html">
      <font color="black">Distantly Supervised Relation Extraction in Federated Settings</font>
    </a>
  </h2>
  <font color="black">ただし、同じエンティティのペアを含む文が異なるプラットフォームに散在する可能性があるため、遠隔監視のラベルノイズを克服することは困難になります。このホワイトペーパーでは、連合環境で遠隔監視された関係抽出について調査します。ただし、集中型トレーニングは、 2つの問題、つまりデータバリアとプライバシー保護。これらの問題により、複数のプラットフォームからのデータを集中化することはほとんど不可能またはコストが非常に高くなります。 
[ABSTRACT]遠隔監視には、さまざまなプラットフォームからテキストを収集して1台のマシンに保存することが含まれます。ただし、モデル学習と生データへの直接アクセスの必要性を切り離す、統合学習盆地での遠隔監視を調査することは価値があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Modeling Inter-Aspect Dependencies with a Non-temporal Mechanism for
  Aspect-Based Sentiment Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_12.html">
      <font color="black">Modeling Inter-Aspect Dependencies with a Non-temporal Mechanism for
  Aspect-Based Sentiment Analysis</font>
    </a>
  </h2>
  <font color="black">SemEval 2014タスク4の2つの異なるドメインでの実験は、提案されたアプローチの有効性を示しています。さらに、ABSAタスクのよく知られたクラスの不均衡の問題に焦点を当て、適切に分類されたインスタンスに割り当てられた損失の重み付けを減らすことで対処します..この論文では、アスペクト間の依存関係をモデル化することによってABSAタスクを強化するための新しい非時間的メカニズムを提案します。 
[ABSTRACT] absaタスクのクラスの不均衡の問題に焦点を当て、適切に分類されたインスタンスに割り当てられた損失に重みを付けてダウンすることで対処します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Text Generation via Feature-Mover's Distance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_13.html">
      <font color="black">Adversarial Text Generation via Feature-Mover's Distance</font>
    </a>
  </h2>
  <font color="black">提案されたモデルは優れたパフォーマンスをもたらし、幅広い適用性と有効性を示しています。具体的には、特徴ムーバーの距離（FMD）と呼ばれる新しいメトリックを使用して、実際の文章と合成文章の潜在的な特徴の分布を照合することを検討します。この定式化により、差別的な批評家と最適化が容易な目的で、既存の方法でのモードの崩壊と脆性のトレーニングの問題を克服します。 
[要約]提案されたモデルは、テキストベースのタスクのモデルを開発するために使用できます。モデルの成功をテストするためのツールとしても使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-09-17">
        <br><font color="black">2018-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Fine-Grained Relevance Annotations for Multi-Task Document Ranking and
  Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_14.html">
      <font color="black">Fine-Grained Relevance Annotations for Multi-Task Document Ranking and
  Question Answering</font>
    </a>
  </h2>
  <font color="black">新しく作成したデータを使用して、長いドキュメント内の関連性の分布や、テキストの特定の位置に対するアノテーターの注意を調査します。この作業では、FiRA（詳細な関連性アノテーションの新しいデータセット）を紹介します。 TKLは長いドキュメントに対して最新の検索結果を示しますが、多くの関連する節を逃していることがわかります。 
[ABSTRACT]この作品では、関連性の高い細かいアノテーションの新しいデータセットであるフィラを紹介します。新しく作成したデータを使用して、長いドキュメント内の関連性の分布と、テキストの特定の位置に対するアノテーターの注意を調査します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: The Annotation Guideline of LST20 Corpus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_15.html">
      <font color="black">The Annotation Guideline of LST20 Corpus</font>
    </a>
  </h2>
  <font color="black">LST20コーパスは、前述のように5層の言語アノテーションを提供します。また、3,745のドキュメントすべてに15のニュースジャンルでアノテーションが付けられます。そのサイズに関して、このデータセットは、NLPの共同ニューラルモデルを開発するのに十分な大きさであると見なされます。 
[要約] posタグ付け、名前付きエンティティ、句の境界、文の境界が含まれます。lst4コーパスの乱雑さのスケールは、5つの言語アノテーションのレイヤーで構成されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: OCoR: An Overlapping-Aware Code Retriever -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_16.html">
      <font color="black">OCoR: An Overlapping-Aware Code Retriever</font>
    </a>
  </h2>
  <font color="black">異なる人々が使用する異なる名前の重複は、2つの異なる名前が潜在的に関連している可能性があることを示します（たとえば、「メッセージ」と「msg」）。コードの識別子と自然言語の説明の単語の重複は、コードスニペットと説明は潜在的に関連している可能性があります。さらに、OCoRのさまざまなコンポーネントのパフォーマンスを理解するのに役立ついくつかの詳細な実験も行いました。評価は、2つの確立されたデータセットに対して行われました。 
[ABSTRACT]コードの取得は、一連のコードの中で最も関連性の高いコードを検索することを目的としています。ただし、これらのアプローチでは、重要な機能をキャプチャできません。「overlaps」と呼ばれる新しいコード。2つの特別に設計されたコンポーネントを使用してオーバーラップをキャプチャします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Segment Actions from Observation and Narration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_17.html">
      <font color="black">Learning to Segment Actions from Observation and Narration</font>
    </a>
  </h2>
  <font color="black">私たちは、トレーニング中にアクションラベルが知られていない、監視されていない、または監視が弱い設定に焦点を当てています。その単純さにもかかわらず、このモデルは、自然主義的な教育用ビデオのデータセットに対する以前の作業と競合して実行されます。このモデルでは、使用する監視のソースを変更できますトレーニングでは、タスク構造とナラティブ言語の両方がセグメンテーション品質に大きな利点をもたらすことがわかりました。 
[ABSTRACT]私たちのモデルでは、トレーニングで使用される監督のソースを変更できます。また、タスクの構造と物語の言語の両方が大きなメリットをもたらすことがわかりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br><font color="black">2020-05-07</font>
      </time>
    </span>
</section>
<!-- paper0: TensorCoder: Dimension-Wise Attention via Tensor Representation for
  Natural Language Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_18.html">
      <font color="black">TensorCoder: Dimension-Wise Attention via Tensor Representation for
  Natural Language Modeling</font>
    </a>
  </h2>
  <font color="black">マスク言語モデリングとニューラル機械翻訳を含む2つのタスクでTensorCoderを検証します。このホワイトペーパーでは、新しい言語モデリングアプローチ（つまりTensorCoder）を開発できる次元単位の注意メカニズムを提案します。元のトランスフォーマーとの比較TensorCoderは、元のモデルの計算を大幅に削減するだけでなく、マスクされた言語モデリングタスク（PTBデータセット内）のパフォーマンスの向上と機械翻訳タスクの同等のパフォーマンスを実現します。 
[要旨]この注意は、シーケンスの長さに対して2次であり、長いシーケンスタスクのアプリケーションの可能性を制限します。さらに、元の$ o（n * 2d）と$ d $に基づいて、注意の複雑さを減らすことができます。頭の光学</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: A Dataset for Statutory Reasoning in Tax Law Entailment and Question
  Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_19.html">
      <font color="black">A Dataset for Statutory Reasoning in Tax Law Entailment and Question
  Answering</font>
    </a>
  </h2>
  <font color="black">機械読み取りモデルを直接適用すると、法的ドメインに微調整されているかどうかに関係なく、質問に対してすぐに使用できるパフォーマンスが低いことがわかります。これを、手作業で作成されたPrologベースのシステムと対照的に設計します。タスクを完全に解決します。これらの実験は、法定推論が今後直面する課題の議論をサポートします。これは、自然言語で指定された規範的なルールを利用できるモデルの開発に動機を与えることができる興味深い現実のタスクであると主張します。 
[ABSTRACT]自然言語のパフォーマンスを理解するためにマシンが導入されています。これには、法的ドメインのテキストコーパスと一緒にデータセットが含まれています。これを、手動で作成したプロローグベースのシステムと対比</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br><font color="black">2020-05-11</font>
      </time>
    </span>
</section>
<!-- paper0: Approaching Neural Chinese Word Segmentation as a Low-Resource Machine
  Translation Task -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_20.html">
      <font color="black">Approaching Neural Chinese Word Segmentation as a Low-Resource Machine
  Translation Task</font>
    </a>
  </h2>
  <font color="black">追加のデータなしでクローズドテスト条件下でMSRコーパスでベンチマークを行うと、このメソッドは、最新技術と同等の97.6％F1を達成します。注意してエンコーダーデコーダーモデルを構築し、正則化を含む一連の手法を調べます、データ拡張、客観的重み付け、転移学習、エンサンブル..この作業では、低リソースのニューラル機械翻訳から中国語の単語セグメンテーションまでのベストプラクティスを適用します。 
[ABSTRACT]中国の研究者は文字レベルの翻訳にラベルを付けようとしましたが、翻訳ベースのアプローチと他の方法との間には依然としてパフォーマンスのギャップがあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Text-Guided Neural Image Inpainting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/cs.CL/paper_21.html">
      <font color="black">Text-Guided Neural Image Inpainting</font>
    </a>
  </h2>
  <font color="black">既存のテキスト誘導画像生成作業とは異なり、修復モデルは、特定のテキストの意味内容と画像の残りの部分を比較し、欠落部分に埋める必要のある意味内容を見つける必要があります。結果分析は、生成された画像はガイダンステキストと一致し、さまざまな説明を提供することでさまざまな結果を生成できること。最初に、デュアルマルチモーダルアテンションメカニズムは、破損した領域に関する明示的な意味情報を抽出するように設計されています。相互注意によるテキストおよび補足画像領域。 
[要約]カリフォルニア大学の研究者は、テキストと呼ばれる新しいモデルを開発しています-ガイド付き二重注意修復ネットワーク（tdanet）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br><font color="black">2020-04-07</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Improving Stability of LS-GANs for Audio and Speech Signals -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.AS/paper_0.html">
      <font color="black">Improving Stability of LS-GANs for Audio and Speech Signals</font>
    </a>
  </h2>
  <font color="black">UrbanSound8kとMozillaの共通音声データセットのサブセットに関する実験結果は、Fr \ &#39;echetの開始距離によって測定された生成サンプルの品質にかなりの改善を示しています。さらに、これらのサンプルからの信号を再構築すると、通常のLS-GAN ..このホワイトペーパーでは、音声信号と音声信号の2D表現について、シュール分解のユニタリー空間で新しい類似性メトリックを提案することにより、生成的敵対ネットワーク（GAN）の不安定性の問題に対処します。 
[ABSTRACT]ジェネレーター拡張インカネーションは、より包括的なスペクトログラムを作成するのに役立ちます。urbansound8kおよびmozilla共通音声データセットのガンサーにより、生成されたサンプルの品質が向上しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: VAW-GAN for Singing Voice Conversion with Non-parallel Training Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.AS/paper_1.html">
      <font color="black">VAW-GAN for Singing Voice Conversion with Non-parallel Training Data</font>
    </a>
  </h2>
  <font color="black">歌声変換システムのトレーニングには、通常、並列トレーニングデータが必要ですが、実際のアプリケーションでは実用的ではありません。音声コンテンツから歌手IDと歌唱韻律（F0輪郭）のもつれを解くようにエンコーダーをトレーニングします。シンガーアイデンティティとF0の場合、デコーダーは目に見えないターゲットシンガーアイデンティティを含む出力スペクトル機能を生成し、F0レンダリングを改善します。 
[要約]このホワイトペーパーでは、vawに基づいた歌声変換フレームワークを提案します。gan.itは歌手IDとfsteinを使用してf0レンダリングを改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Transfer Learning Approaches for Streaming End-to-End Speech Recognition
  System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.AS/paper_2.html">
      <font color="black">Transfer Learning Approaches for Streaming End-to-End Speech Recognition
  System</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、RNN-Tフレームワークの4つの異なるTL手法の比較研究を紹介します。ハイブリッドASRシステムでは、伝達学習は通常、ソース言語AMでターゲット言語音響モデル（AM）を初期化することによって行われます。伝達学習（TL）知識をソース言語からターゲット言語に転送するために、従来のハイブリッド自動音声認識（ASR）システムで広く使用されています。 
[ABSTRACT] tlは、再帰型ニューラルネットワークトランスデューサー（rnn-t）モデルなどのエンドツーエンド（e2e）asrシステムに適用できます。asrシステムは、ターゲット言語のエンコーダーと予測ネットワークをテストするために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Channel-wise Subband Input for Better Voice and Accompaniment Separation
  on High Resolution Music -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.AS/paper_3.html">
      <font color="black">Channel-wise Subband Input for Better Voice and Accompaniment Separation
  on High Resolution Music</font>
    </a>
  </h2>
  <font color="black">musdb18hqテストセットでメソッドを評価し、SDR、SIR、およびSARメトリックに焦点を当てます。提案されたアプローチは、各サブバンドでの効果的な重み共有を可能にし、チャネル間の柔軟性を高めます。実験は、CWS入力が多くの面で有益であることを示しています。 
[要約]私たちはcnnベースの高解像度mssモデルの主要な問題に対処することを目指しています。提案されたアプローチは、各サブバンドでの効果的な重み共有を可能にし、チャネル間の柔軟性を高めます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Spectrum and Prosody Conversion for Cross-lingual Voice Conversion with
  CycleGAN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.AS/paper_4.html">
      <font color="black">Spectrum and Prosody Conversion for Cross-lingual Voice Conversion with
  CycleGAN</font>
    </a>
  </h2>
  <font color="black">F0モデリングに連続ウェーブレット変換（CWT）分解を使用することを提案します。また、スペクトルマッピングと韻律マッピングの2つのCycleGANパイプラインをトレーニングすることも提案します。クロスリンガル音声変換に関するこれまでの研究は、主に線形変換によるスペクトル変換に焦点を当てていますF0転送用。 
[ABSTRACT]たとえば、2つのスピーカーのパラレルデータの必要性を排除します。これは、クロスリンガル音声変換における韻律の最初の研究です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-11">
        <br><font color="black">2020-08-11</font>
      </time>
    </span>
</section>
<!-- paper0: Emotion Profile Refinery for Speech Emotion Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.AS/paper_5.html">
      <font color="black">Emotion Profile Refinery for Speech Emotion Classification</font>
    </a>
  </h2>
  <font color="black">3つのよく知られている感情コーパスの実験は、提案された方法を使用して顕著な利得を示しています。このホワイトペーパーでは、感情レベルの微妙なブレンドをキャプチャするセグメントレベルのソフトラベルの時系列を提供する感情プロファイル（EP）の使用をお勧めします。特定の発話全体に存在する手がかり。EPRメソッドは、洗練された連続的な段階で動的に生成される複数の確率的クラスラベルを生成します。これにより、モデルの精度が大幅に向上します。 
[ABSTRACT]このラベリングの原則は、感情的な不純物を考慮してシステムパフォーマンスに課題を課します。また、epsを更新する反復手順である感情プロファイル精製（epr）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Attentron: Few-Shot Text-to-Speech Utilizing Attention-Based
  Variable-Length Embedding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.AS/paper_6.html">
      <font color="black">Attentron: Few-Shot Text-to-Speech Utilizing Attention-Based
  Variable-Length Embedding</font>
    </a>
  </h2>
  <font color="black">さらに、モデルは、任意の数の参照オーディオにスケールアウトして、合成音声の品質を向上させることができます。人間の評価を含む私たちの実験によると、提案されたモデルは、生成時に最先端のモデルを大幅に上回りますこの問題に対処するために、トレーニング中に見えない話者の声を複製する、数ショットのTTSモデルであるAttentronを提案します。 
[ABSTRACT] attentronは少数です-トレーニング中に見えない話者の声を複製するショットttsモデルです。このモデルは、話者の類似性と品質の面で、見えない話者のスピーチを生成するときに、最先端のモデルを大幅に上回ります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-18">
        <br><font color="black">2020-05-18</font>
      </time>
    </span>
</section>
<!-- paper0: Mask Detection and Breath Monitoring from Speech: on Data Augmentation,
  Feature Representation and Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-13/eess.AS/paper_7.html">
      <font color="black">Mask Detection and Breath Monitoring from Speech: on Data Augmentation,
  Feature Representation and Modeling</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案された方法がベースラインを上回り、それぞれ呼吸およびマスク評価セットで0.746 PCCおよび78.8％UARを達成することを示しています。速度摂動、SpecAugment、およびランダム消去。音声呼気監視タスクでは、Bi-LSTM構造に基づいてさまざまなボトルネック機能を調査します。 
[要約]マスク検出タスクでは、深い畳み込みニューラルネットワークをトレーニングします。システムは、データ増大スキームを使用してトレーニングデータを増やします。これらには、速度摂動、スペック、ランダム消去が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
