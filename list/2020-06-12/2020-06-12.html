<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-06-12の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Telling Left from Right: Learning Spatial Correspondence between Sight
  and Sound -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.SD/paper_0.html">
      Telling Left from Right: Learning Spatial Correspondence between Sight
  and Sound
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      モデルをトレーニングして、左と右のオーディオチャネルが反転したかどうかを判断し、ビジュアルストリームとオーディオストリーム全体の空間ローカライゼーションを推論させます。空間対応を理解することで、3つのオーディオビジュアルタスクでモデルのパフォーマンスが向上することを示しています。空間オーディオキューを利用しない監視ありベースラインと自己監視ベースラインを定量的に向上させます。また、アンビソニックオーディオを使用して360度ビデオに自己管理アプローチを拡張する方法も示します。 
[ABSTRACT]ビジュアルビジュアルビジュアルストリームは、従来の方法よりも有用であると教えられています。これらには、大規模なビデオデータセット、youtube-asmr-300kが含まれます。ビジュアルオーディオは900時間を超える映像で構成されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Memory Controlled Sequential Self Attention for Sound Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.SD/paper_1.html">
      Memory Controlled Sequential Self Attention for Sound Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたメモリ制御シーケンシャルセルフアテンションの使用は、サウンドイベントトークンのフレーム間の関係を誘導する方法を提供します。URBAN-SEDデータセットでの実験は、セルフアテンション誘導SEDモデルを使用したメモリの範囲がサウンド認識パフォーマンスに及ぼす影響を示しています。 。私たちのメモリ制御自己注意モデルは、URBAN-SEDデータセットで33.92％のイベントベースのFスコアを達成し、自己注意なしでモデルによって報告された20.10％のFスコアよりも優れていることを示しています。 
[要約]ポリフォニックサウンドイベント検出（sed）のために、畳み込みリカレントニューラルネットワーク（crnn）モデルに加えて、メモリ制御の自己注意メカニズムを使用することを提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br>2020-05-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to Count Words in Fluent Speech enables Online Speech
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.SD/paper_2.html">
      Learning to Count Words in Fluent Speech enables Online Speech
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      LRS2データセットとLibriSpeechデータセットで実行された実験は、それぞれ制約なし音声と既読音声であり、オンラインシステムはオフラインのものと同等に機能し、5セグメントの動的アルゴリズム遅延があることを示しています。さらに、推定されたセグメント長が分布は強制整列で得られた語長分布に似ていますが、システムでは正確なセグメントと単語の同等性は必要ありません。Tarisは標準のトランスフォーマーと比較して無視できるオーバーヘッドをもたらしますが、入力と出力の間のローカル関係モデリングは不変を与えます設計によるシーケンスの長さ。 
[ABSTRACT]これは、米国のスピーチスピーチで使用できます。正確なシステムは正確な正確なモデルを必要としないことを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-08">
        <br>2020-06-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Bonseyes AI Pipeline -- bringing AI to you. End-to-end integration of
  data, algorithms and deployment tools -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.SD/paper_3.html">
      Bonseyes AI Pipeline -- bringing AI to you. End-to-end integration of
  data, algorithms and deployment tools
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、モジュール式AIパイプラインを統合フレームワークとして提示し、データ、アルゴリズム、およびデプロイメントツールを統合します。ただし、組み込みデバイスでのカスタムAIソリューションのトレーニングとデプロイメントには、データ、アルゴリズム、および高精度を達成するためのツール。私たちのAIパイプラインは、i）データの取り込み、ii）モデルのトレーニング、iii）デプロイメントの最適化、およびiv）IoTハブの統合という4つの主要なモジュールで構成されています。 
[ABSTRACT]ツールのさまざまな段階を相互接続し、モジュール式のエンドツーエンドの組み込みデバイス用AI製品の開発を提供できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-01-15">
        <br>2019-01-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Investigating Robustness of Adversarial Samples Detection for Automatic
  Speaker Verification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.SD/paper_4.html">
      Investigating Robustness of Adversarial Samples Detection for Automatic
  Speaker Verification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、このような攻撃を防御する方法は限られています。最近、自動話者検証（ASV）システムに対する敵対的攻撃は、ASVシステムに深刻な脅威をもたらすため、広く注目を集めています。 
[ABSTRACT]そのような攻撃を防御するための既存の方法は限られています。これらには、広告を検出するvggのようなバイナリ分類検出器が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An Objective Measure of Quality for Time-Scale Modification of Audio -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.SD/paper_5.html">
      An Objective Measure of Quality for Time-Scale Modification of Audio
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案された測定は、0.487の平均二乗平均誤差と0.865の平均ピアソン相関を達成し、主観的セッションの98パーセンタイルと82パーセンタイルにそれぞれ相当します。提案された測定は、時間スケール変更アルゴリズムを評価するために使用され、エラスティックがSolo楽器と音声信号の最高の客観的品質、Identity Phase-Locking Phase Vocoderは音楽信号の最高の客観的品質と最高の全体的な品質を提供します。タイムスケール修正（TSM）で処理されたオーディオの客観的評価は未解決の問題です。 
[ABSTRACT]時間のデータセット-処理されたラベルにスケーリングされた音声が公開されました。これは、品質の最初の客観的指標を作成するために使用されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Perceiving Music Quality with GANs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.SD/paper_6.html">
      Perceiving Music Quality with GANs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この方法は監視されておらず、劣化した素材にアクセスする必要がなく、音楽のさまざまな領域に合わせて調整できます。通常、音楽オーディオ信号の知覚品質を評価するには、変更されていないコンテンツのクリーンな参照信号が必要であり、音楽などの参照が利用できないアプリケーションを妨げます最後に、メソッドは、音楽の人間の評価と統計的に有意な相関があることが示されています。 
[要約]この方法は、音楽の人間による評価と統計的に有意な相関があることが示されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: XiaoiceSing: A High-Quality and Integrated Singing Voice Synthesis
  System -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.SD/paper_7.html">
      XiaoiceSing: A High-Quality and Integrated Singing Voice Synthesis
  System
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このドキュメントでは、XiaoiceSingを紹介します。XiaoiceSingは、スペクトル、F0、および持続時間のモデリングに統合ネットワークを採用した高品質の歌声合成システムです。 2つのA / Bテストで、提案されたF0と期間のモデリング方法は、それぞれベースラインに対して97.3％と84.3％の優先率を達成し、XiaoiceSingの圧倒的な利点を示しています。 
[要約] xiaoicesingは、歌うために提案されたシステムです-詳細。提案されたf0と期間のモデリングは、ベースラインに対して97.3％と84.3％の優先率を達成します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Dance Revolution: Long Sequence Dance Generation with Music via
  Curriculum Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.SD/paper_8.html">
      Dance Revolution: Long Sequence Dance Generation with Music via
  Curriculum Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      広範な実験は、提案されたアプローチが自動メトリックと人間の評価の両方で既存の方法を大幅に上回っていることを示しています。自己注意の受容フィールドを制限することにより、エンコーダは、二次メモリ要件をシーケンスの線形に減らすことにより、長い音楽シーケンスを効率的に処理できます。 length ..この論文では、トランスフォーマーベースの音楽エンコーダーとリカレント構造ベースのダンスデコーダーで構成される、音楽によるロングシーケンスダンス生成のための新しいseq2seqアーキテクチャを提案します。 
[ABSTRACT]この論文では、musicを使用した長いシーケンスダンス生成のための新しいseq2seqアーキテクチャを提案します。これは、トランスフォーマーベースの音楽エンコーダーとリカレント構造ベースのダンスデコーダーで構成されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Blissful Ignorance: Anti-Transfer Learning for Task Invariance -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.SD/paper_9.html">
      Blissful Ignorance: Anti-Transfer Learning for Task Invariance
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さまざまな類似性メトリクスと集計関数を使用して転移防止学習を実装しました。そのようなタスクの例としては、スタイルとコンテンツの認識、または音声からのピッチと音色などがあります。結果は、転移防止学習がすべてのテストケースで一貫して精度を向上させ、ネットワークをプッシュして、目前のタスクのより代表的な機能を学ぶことができます。 
[ABSTRACT]反転移学習は、別のタスクについて学習された学習表現を回避します。これは、新しいタスクに関連せず、誤解を招く可能性があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Transparency in Language Generation: Levels of Automation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_0.html">
      Transparency in Language Generation: Levels of Automation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちは、自動化された言語を記述するための共通の用語セットを確立するために、SAEレベルの自動化を基に言語自動化の分類法を提案します。したがって、消費者は、広告、メディアレポート、または言語の生成..提案された分類法がこの急速に進歩している分野の透明性を高められることを私たちは望んでいます。 
[ABSTRACT]会社は、言語の生産における自動化の役割に関する広告、メディアレポート、または曖昧さによって誤解を招く可能性があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Teaching Pre-Trained Models to Systematically Reason Over Implicit
  Knowledge -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_1.html">
      Teaching Pre-Trained Models to Systematically Reason Over Implicit
  Knowledge
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、暗黙の事前トレーニング済みの知識と明示的な自然言語ステートメントの両方を組み合わせて体系的な推論を確実に実行するようにLMをトレーニングできる最初のデモンストレーションを提供します。これを行うには、モデルを教えるデータセットを自動的に生成する手順を説明します新しい推論スキル、およびモデルが暗黙の分類学および世界の知識、連鎖およびカウントを含む推論を効果的に実行することを学習することを実証します。最後に、トレーニングの分布を超えて一般化する「教える」モデルを示します。複数の使用法をうまく構成します単一の例で推論スキル。 
[ABSTRACT]証拠は、大規模な事前トレーニング済み言語モデル（lms）が何らかの推論能力を獲得することを示唆していますが、この能力は制御が困難です。事前トレーニング済みlmsのパラメーターにすでにエンコードされている暗黙の知識の膨大なリザーバーを利用することが重要です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: See what I'm saying? Comparing Intelligent Personal Assistant use for
  Native and Non-Native Language Speakers -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_2.html">
      See what I'm saying? Comparing Intelligent Personal Assistant use for
  Native and Non-Native Language Speakers
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      L2スピーカーは、IPAを言語の必要性に鈍感であると見なし、対話の失敗を引き起こします。インテリジェントパーソナルアシスタント（IPA）の限られた言語カバレッジは、多くが非ネイティブ言語で対話することを意味します。十分。 
[要旨] L2ユーザー向けに言語体験を調整する必要性について説明します。言語生成の負担を軽減しながら視覚的フィードバックを強調します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Empirical Analysis of Zipf's Law, Power Law, and Lognormal Distributions
  in Medical Discharge Reports -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_3.html">
      Empirical Analysis of Zipf's Law, Power Law, and Lognormal Distributions
  in Medical Discharge Reports
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は、放電レポートが打ち切られたべき乗則と対数正規分布に最も適していることを示しています。私たちの調査結果は、放電レポートテキストのベイジアンモデリングと統計テキスト分析が、打ち切られたべき乗則と対数正規確率事前分布を使用することでメリットがあることを示唆しています。ベイジアンモデリングと統計テキスト分析は、適切な解決策を奨励するために、情報に基づく事前確率に依存します。 
[ABSTRACT]この論文では、医学的退院レポートのテキストがzipfの法則に従っているかどうかを分析しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br>2020-03-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Emora STDM: A Versatile Framework for Innovative Dialogue System
  Development -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_4.html">
      Emora STDM: A Versatile Framework for Innovative Dialogue System
  Development
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのフレームワークは、対話管理に対する2つの一般的なアプローチである状態機械と情報状態の間の相互運用性をサポートすることにより、幅広い専門知識レベルに対応します。自然言語式パッケージにより、パターンマッチング、カスタムNLPモジュール、データベースクエリをシームレスに統合できます。ユーザースタディとして、このフレームワークを学際的な学部課程に採用し、技術的背景と非技術的背景の両方を持つ学生が創造的な対話マネージャーを短期間で開発できるようにします。 
[ABSTRACT]状態マシンと情報状態はどちらも、対話管理に対する一般的なアプローチです。このフレームワークは、2つの一般的なアプローチ間の相互運用性をサポートすることにより、幅広い専門知識レベルに対応します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Tangled up in BLEU: Reevaluating the Evaluation of Automatic Machine
  Translation Evaluation Metrics -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_5.html">
      Tangled up in BLEU: Reevaluating the Evaluation of Automatic Machine
  Translation Evaluation Metrics
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、ペアワイズシステムランキングに移り、人間の判断に対する自動メトリックの下でパフォーマンス改善をしきい値処理する方法を開発します。これにより、発生したタイプIとタイプIIのエラーの定量化が可能になります。拒否された人間の違い。これらの結果は合わせて、機械翻訳におけるメトリック評価とシステムパフォーマンス評価のプロトコルの改善を示唆しています。メトリックを判断するための現在の方法は、評価に使用される翻訳、特に外れ値。これは、メトリクスの有効性について誤った確信のある結論につながることがよくあります。 
[ABSTRACT]自動指標は人間による評価のゴールドスタンダードでは機能しません。システムランキングにより、発生したタイプiとタイプIIのエラーを定量化できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Disentangled Non-Local Neural Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_6.html">
      Disentangled Non-Local Neural Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ホワイト化されたペアワイズ項は領域内の関係を学習し、単項項は顕著な境界を学習します。ただし、2つの項は非ローカルブロックで密結合されているため、それぞれの学習が妨げられます。分離された設計の有効性をCityscapesでのセマンティックセグメンテーション、ADE20KおよびPASCAL Context、COCOでのオブジェクト検出、Kineticsでのアクション認識など、さまざまなタスク。 
[ABSTRACT]非vovovovovovoブロックは絡み合っていない非vovovovovovovolutionです。2つの用語に分割できます。2つのピクセル間の関係を説明する白くされたペアワイズ項と、すべてのピクセルの顕著性を表す単項項です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SemEval-2019 Task 1: Cross-lingual Semantic Parsing with UCCA -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_7.html">
      SemEval-2019 Task 1: Cross-lingual Semantic Parsing with UCCA
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      UCCAは、意味論的表現のための言語間で適用可能なフレームワークであり、広範なタイポロジカルな作業に基づいて構築され、迅速な注釈をサポートします。UCCA解析に関するSemEval 2019共有タスクを英語、ドイツ語、フランス語で提示し、参加するシステムと結果について説明します。完全な結果は、タスクのWebサイト\ url {https://competitions.codalab.org/competitions/19160}にあります。 
[ABSTRACT]このタスクはすべての言語と設定で改善をもたらしました。uccaはセマンティックリプレゼンテーション用のクロスアラ/サイトです。広範囲なタイポロジー作業に基づいて構築されており、迅速な注釈をサポートしています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-03-06">
        <br>2019-03-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Enhanced Universal Dependency Parsing with Second-Order Inference and
  Mixture of Training Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_8.html">
      Enhanced Universal Dependency Parsing with Second-Order Inference and
  Mixture of Training Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      低リソースのタミル語コーパスでは、タミル語のトレーニングデータを他の言語と特別に混合し、タミル語のパフォーマンスを大幅に改善しました。送信要件についての誤解により、接続されていないグラフを送信しました。 \ textbf {6th}を10チーム以上にランク付けします。ただし、この問題を修正した後、システムは公式結果で\ textbf {1st}をランク付けしたチームより0.6 ELAS高くなりました。 
[要旨]私たちのシステムはグラフです-二次の可能性があるパーサーです。提出された要件に関する情報の不足を提出しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-02">
        <br>2020-06-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Performance in the Courtroom: Automated Processing and Visualization of
  Appeal Court Decisions in France -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_9.html">
      Performance in the Courtroom: Automated Processing and Visualization of
  Appeal Court Decisions in France
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、判決のネットワークでコミュニティの検出を実行し、コミュニティの機能を利用した事件の難しさを表す指標を提案します。法的制度の情報の非対称性と正義へのアクセスのギャップを減らすために、司法判断から法的指標を抽出します。 .. NLPメソッドを使用して、判決から興味深いエンティティ/データを抽出し、弁護士と判決のネットワークを構築します。 
[ABSTRACT]私たちは、弁護士の経験、勝敗率、弁護士のネットワークにおける弁護士の重要性に基づいて弁護士をランク付けする指標を提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Provenance for Linguistic Corpora Through Nanopublications -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_10.html">
      Provenance for Linguistic Corpora Through Nanopublications
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーでは、イベントの注釈が付けられたコーパスのケーススタディを使用して、このデータの新しい相互運用可能な表現をナノパブリケーションの形式で作成することにより、この問題に対処します。つまり、これらのバリエーションは、既存のコーパス間の相互運用性に影響を与えます。計算言語学の研究新しいツールと方法論のトレーニングとテストは、テキストコーパスに依存しています。 
[要約]クエリは、異なるコーパスの情報の自動相互運用性により、複数のコーパスの情報をより簡単かつ効果的に取得できることを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Stance Detection on Social Media: State of the Art and Trends -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_11.html">
      Stance Detection on Social Media: State of the Art and Trends
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、この調査では、ソーシャルメディアでのスタンス検出の新たな傾向とさまざまなアプリケーションについて調査しています。この調査では、スタンス検出に関する既存のベンチマークデータセットに関する最新の結果を報告し、最も効果的なアプローチについて説明します。この研究は、現在の既存の研究のギャップについての議論を提供し、ソーシャルメディアでのスタンス検出の可能な将来の方向性を強調することで締めくくります。 
[要約]調査はソーシャルメディアでの作業を調査します。最後に、現在の調査のギャップについて説明します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-05">
        <br>2020-06-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Monolingual Approach to Contextualized Word Embeddings for
  Mid-Resource Languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_12.html">
      A Monolingual Approach to Contextualized Word Embeddings for
  Mid-Resource Languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Common-CrawlベースのOSCARデータのノイズにもかかわらず、OSCARでトレーニングされた埋め込みは、Wikipediaでトレーニングされた単一言語埋め込みよりもはるかに優れたパフォーマンスを発揮します。特に、多言語Wikipediaベースのコンテキスト埋め込み（多言語BERT）よりも優れています。これは、ほとんど常に以前の最先端技術を構成しており、より大きく、より多様なコーパスのメリットが、多言語埋め込みアーキテクチャのクロスリンガルの利点を上回っていることを示しています。言語分類によりCommon Crawlから抽出された多言語OSCARコーパスを使用します。フィルタリングとクリーニング。いくつかの中間リソース言語の単一言語の文脈化された単語埋め込み（ELMo）をトレーニングします。 
[ABSTRACT]タグ付けと解析のタスクに関するこれらの言語のelmo埋め込み。これらは実際には、タグ付けとコンテキストにおける現在の最先端技術と同等またはそれを改善します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-hop Reading Comprehension across Documents with Path-based Graph
  Convolutional Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_13.html">
      Multi-hop Reading Comprehension across Documents with Path-based Graph
  Convolutional Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      一方、Gated-RGCNは、パスベースの推論グラフに証拠を蓄積することを提案します。これには、ドキュメント全体に伝播する情報の有用性を調整し、推論中に質問情報を追加するための新しい質問認識ゲーティングメカニズムが含まれます。WikiHopでのアプローチを評価します。データセット、および私たちのアプローチは、以前に公開されたアプローチに対して最先端の精度を達成します。人間の推論処理に触発され、サポートドキュメントからパスベースの推論グラフを作成します。 
[要約]この論文では、このマルチパスの読解問題に取り組むための新しいアプローチを提案します。このグラフは、グラフベースのアプローチとパスベースのアプローチの両方のアイデアを組み合わせることができるため、マルチホップの質問に適しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: VirTex: Learning Visual Representations from Textual Annotations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_14.html">
      VirTex: Learning Visual Representations from Textual Annotations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      VirTexは、意味的に密なキャプションを使用して視覚表現を学習する事前トレーニングアプローチを提案します。すべてのタスクで、VirTexは、ImageNetで学習した機能（監視ありまたは監視なし）と同等またはそれ以上の機能を生成します。多くのビジョンタスクへの事実上のアプローチは、ImageNetの教師付きトレーニングを通じて通常学習される、事前トレーニング済みの視覚表現から始めることです。 
[ABSTRACT]最近の方法では、教師なしの事前トレーニングを調査しました。教師付き事前トレーニングを再検討し、データを効率的に検索します。ココキャプションを最初から畳み込みネットワークをトレーニングします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: KRED: Knowledge-Aware Document Representation for News Recommendations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_15.html">
      KRED: Knowledge-Aware Document Representation for News Recommendations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、情報抽出層は、元のドキュメント表現のガイダンスの下でエンティティの埋め込みを集約し、ドキュメントベクトルを新しいものに変換します。ただし、既存のドキュメント理解モデルは、知識エンティティ（BERTなど）を考慮せずにニュース記事を表すか、特定のタイプのテキストエンコーディングモデル（DKNなど）を使用して、汎化能力と効率が損なわれるようにします。実際のニュースデータセットでの実験は、KREDがさまざまなニュース推奨アプリケーションに大きな利益をもたらすことを示しています。 
[ABSTRACT]記事は重要なメッセージを伝え、より直接的な方法でコンテンツを理解するのに役立ちます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Dynamic Fusion Network for Multi-Domain End-to-end Task-Oriented Dialog -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_16.html">
      Dynamic Fusion Network for Multi-Domain End-to-end Task-Oriented Dialog
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、すべてのドメインからのデータを効果的に使用して各ドメインのパフォーマンスを改善する方法や、目に見えないドメインの研究はほとんどありません。さらに、関連性を自動的に活用する新しいダイナミックフュージョンネットワーク（DF-Net）を提案します。ターゲットドメインと各ドメインの間。結果は、私たちのモデルがマルチドメインダイアログの既存の方法よりも優れていることを示しており、最先端の文献を提供しています。 
[ABSTRACT]ほとんどのニューラルモデルは、ナビゲーションやスケジューリングなど、特定の数のタスクドメインでのみ利用可能な大量のトレーニングデータに依存しています。ただし、すべてのドメインのデータを効果的に使用してパフォーマンスを向上させる方法に関する研究はほとんどありません各ドメインの
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-23">
        <br>2020-04-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Embed2Detect: Temporally Clustered Embedded Words for Event Detection in
  Social Media -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_17.html">
      Embed2Detect: Temporally Clustered Embedded Words for Event Detection in
  Social Media
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験から得られた結果は、私たちのアプローチがベースラインを大幅に改善したことを証明する効果的かつ効率的なイベント検出が可能であることを示しています。このホワイトペーパーでは、Embed2Detectと呼ばれる新しい方法を提案し、ソーシャルメディアのイベント検出の特徴を組み合わせて予測ベースの単語の埋め込みと階層的凝集クラスタリング..スポーツデータセットの場合、Embed2Detectは、最良に実行されたベースラインメソッドよりも30％高いF値を達成し、政治データセットの場合は36％増加しました。 
[ABSTRACT]既存のイベント検出方法のほとんどは、データ内の統計的および構文的機能にのみ焦点を当てています。これは、単語とその意味の間の関係を記述するためです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-10">
        <br>2020-06-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Augmenting Data for Sarcasm Detection with Unlabeled Conversation
  Context -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_18.html">
      Augmenting Data for Sarcasm Detection with Unlabeled Conversation
  Context
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、提案されたデータ増強技術でトレーニングされた、提案されたモデルは、FigLang2020の皮肉検出タスクに参加し、RedditとTwitterの両方のデータセットで最高のパフォーマンスを獲得し、達成しました。また、コンテキストの長さの不均衡に関する問題を軽減するために、さまざまなコンテキストの長さを効果的に処理できるようなモデルの入出力形式。会話型コンテキストを利用してトレーニング用の意味のあるサンプルを生成する、新しいデータ拡張手法CRA（Contextual Response Augmentation）を紹介します。 
[ABSTRACT]また、モデルの入力-出力形式を変更することで、不均衡なコンテキストの長さに関する問題を軽減します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Probabilistic Model with Commonsense Constraints for Pattern-based
  Temporal Fact Extraction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_19.html">
      A Probabilistic Model with Commonsense Constraints for Pattern-based
  Temporal Fact Extraction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、私たちのモデルがニュースデータから真の時間的事実を抽出する既存の方法を大幅に上回っていることを示しています。特に時間的事実のための2つの新規設計があります。（1）テキストの時間タグを含む2種類の時間信号のパターン信頼性をモデル化します。テキスト生成時間; （2）常識的な制約を観測可能な変数としてモデル化します。この作業では、生成プロセスでの事実抽出を定式化する確率的グラフィカルモデルを提案します。 
[ABSTRACT]パターンベースの情報抽出ファクトは、その効率と転送可能性で認識されています。パターンは、ファクトの信頼性を確保するために使用されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Data Manipulation: Towards Effective Instance Learning for Neural
  Dialogue Generation via Learning to Augment and Reweight -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_20.html">
      Data Manipulation: Towards Effective Instance Learning for Neural
  Dialogue Generation via Learning to Augment and Reweight
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは、対話生成モデルを最適化するためにトレーニングサンプルを操作するだけでなく、検証サンプルを使用した勾配降下法によって操作スキルを向上させることも学習します。提案されたデータ操作フレームワークは完全にデータ駆動型で学習可能です。それらのデータ駆動型神経対話モデルの。 
[要約]提案されたデータ操作フレームワークは完全にデータ駆動型で学習可能です。信頼できるサンプルに向けてデータ分布を事前に再形成するように設計されています。これにより、これらのデータ駆動型神経対話モデルの学習が妨げられます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Deep Differential System Stability -- Learning advanced computations
  from examples -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_21.html">
      Deep Differential System Stability -- Learning advanced computations
  from examples
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      システムの質的特性のほぼ完全な推定と数値の適切な近似を実現し、ニューラルネットワークが組み込みの数学的知識がなくても高度な定理と複雑な計算を学習できることを示しています。生成された大規模なデータセットに対してトランスフォーマーを使用して、学習するモデルをトレーニングします局所安定性、無限大での動作、可制御性などの微分システムの特性。例から高度な数学的計算を学ぶことができますか？ 
[ABSTRACT]優れた安定性、無限大の動作、制御可能性など、数学システムの特性を学習するモデルをトレーニングします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: XiaoiceSing: A High-Quality and Integrated Singing Voice Synthesis
  System -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_22.html">
      XiaoiceSing: A High-Quality and Integrated Singing Voice Synthesis
  System
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、XiaoiceSingが畳み込みニューラルネットワークのベースラインシステムよりも、音質が1.44 MOS、発音精度が1.18、自然度が1.38優れていることを示しています。3）各音素の継続時間の損失に加えて、すべての音素の継続時間2つのA / Bテストで、提案されたF0および持続時間モデリング方法は、ベースラインに対してそれぞれ97.3％および84.3％の優先率を達成し、XiaoiceSingの圧倒的な利点を示しています。 
[要約] xiaoicesingは、歌うために提案されたシステムです-詳細。提案されたf0と期間のモデリングは、ベースラインに対して97.3％と84.3％の優先率を達成します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Mental Workload and Language Production in Non-Native Speaker IPA
  Interaction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_23.html">
      Mental Workload and Language Production in Non-Native Speaker IPA
  Interaction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      しかし、言語の範囲とさまざまなレベルの機能により、多くのスピーカーは非ネイティブ言語を使用してIPAに取り組んでいます。私たちは、ネイティブ（L1）と非ネイティブ（L2）英語のスピーカーがスマートフォンやスマートスピーカーによるIPA。これは、非ネイティブスピーカーによって表示される言語の生産の精神的な作業負荷やパターンに影響を与える可能性があります。 
[ABSTRACT]ネイティブと非ネイティブの英語話者がスマートフォンとスマートスピーカーを使用してタスクを完了した混合-設計実験を紹介します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CycleGT: Unsupervised Graph-to-Text and Text-to-Graph Generation via
  Cycle Training -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_24.html">
      CycleGT: Unsupervised Graph-to-Text and Text-to-Graph Generation via
  Cycle Training
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CycleGTは、完全に非並列のグラフとテキストデータセットからブートストラップでき、2つのフォーム間で繰り返し逆変換でき、新しい事前トレーニング戦略を使用できる教師なしトレーニングフレームワークです。同じ量のデータでトレーニングされたモデルは、監視ありモデルと同等のパフォーマンスを達成できます。これにより、G2TおよびT2Gの分野でのデータ不足の問題を克服する効果的なアプローチとしてフレームワークが検証されます。 
[ABSTRACT]これは、テキストトレーニングによるt2gとg2tの教師なし学習への最初の試みです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-08">
        <br>2020-06-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploring Weaknesses of VQA Models through Attribution Driven Insights -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_25.html">
      Exploring Weaknesses of VQA Models through Attribution Driven Insights
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、これらの洞察を使用して、入力質問の意味の変化がごくわずかでこれらのシステムに重大な損傷を与える敵対的な攻撃を作成します。最近の研究は、視覚障害者のための視覚的な質問に答えるためにこれらのVQAモデルを効果的に適用しています。これにより、開発が強化されると考えています。視覚障害者を支援するために配備された場合、入力の起こり得る変動に対してより堅牢なシステムの。 
[ABSTRACT]これらのデータセットは人工的な設定で作成され、現実のシナリオをほとんど反映していません。これらのデータセットは、データセットに基づいたデータセットによって作成されました。これにより、過去数年間にさらに堅牢なシステムの開発が促進されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Large-Scale Adversarial Training for Vision-and-Language Representation
  Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_26.html">
      Large-Scale Adversarial Training for Vision-and-Language Representation
  Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      VILLAを現在の最高性能のV + Lモデルに適用し、視覚的質問応答、視覚的常識推論、画像テキスト検索、参照式理解、視覚的含意、NLVR2などの幅広いタスクで新しい最先端の技術を実現します..画像のピクセルとテキストトークンに敵対的な摂動を追加する代わりに、各モダリティの埋め込みスペースで敵対的なトレーニングを実行することを提案します。大規模なトレーニングを有効にするには、「無料」の敵対的なトレーニング戦略を採用し、 KLダイバージェンスに基づく正則化により、埋め込み空間の不変性を高めます。 
[ABSTRACT]別荘は別荘の芸術を含む2つのトレーニング段階で構成されます。「無料」のトレーニング戦略を採用し、それをklと組み合わせます。また、埋め込み空間での不変性を高めるためにkl-可視化を組み合わせます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ClarQ: A large-scale and diverse dataset for Clarification Question
  Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_27.html">
      ClarQ: A large-scale and diverse dataset for Clarification Question
  Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの制限を克服するために、私たちは、stackexchangeから抽出されたポストコメントタプルに基づく明確化質問の多様で大規模なデータセットの作成を支援する（自己監視に基づく）新しいブートストラップフレームワークを考案します。最初の目的は分類子の精度を高めることを目的とし、2番目の目的は再現率を高めることです。フレームワークは、ニューラルネットワークベースのアーキテクチャを使用して、明確化の質問を分類します。 
[ABSTRACT]新しいデータセットを使用して、明確化の質問を特定できます。明確化質問の生成の分野への研究を促進することを目的としています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-10">
        <br>2020-06-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The Unstoppable Rise of Computational Linguistics in Deep Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_28.html">
      The Unstoppable Rise of Computational Linguistics in Deep Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、自然言語理解タスクに適用されるニューラルネットワークの履歴をたどり、言語の性質がニューラルネットワークアーキテクチャの開発にもたらした重要な貢献を特定します。この視点は、深部の研究が直面する課題の予測につながります。自然言語を理解するためのアーキテクチャの学習。注意ベースのモデルでの変数バインディングとそのインスタンス化の重要性に焦点を当て、Transformerはシーケンスモデルではなく、誘導構造モデルであると主張します。 
[要約]可変キーの重要性とその注意-ベースのモデルでのインスタンス化に焦点を当てています。トランスはシーケンスモデルではなく、誘導-構造モデルであると主張しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br>2020-05-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Discrete Latent Variable Representations for Low-Resource Text
  Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_29.html">
      Discrete Latent Variable Representations for Low-Resource Text
  Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      テキストの深い潜在変数モデルに関する多くの作業は連続潜在変数を使用しますが、離散潜在変数は解釈可能であり、通常はスペース効率が高いため興味深いものです。低リソースのドキュメントと文の分類の機能として、学習表現のパフォーマンスを比較します。 ..興味深いことに、ハードEMの償却済みバリアントは、リソースが最も少ない状況で特に効果的であることがわかります。 
[ABSTRACT]テキストの離散潜在変数モデルを学習するいくつかのアプローチを検討します。最高のモデルは、連続した表現で以前に報告された最高の結果よりも優れています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ConfNet2Seq: Full Length Answer Generation from Spoken Questions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_30.html">
      ConfNet2Seq: Full Length Answer Generation from Spoken Questions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      音声シーケンスは、事前トレーニング済みの自動音声認識から抽出された混同ネットワークとしてコンパクトに表されます。回答範囲から質問に対する自然な回答を生成するタスクは広く研究されていますが、音声による自然な文の生成に関する研究はほとんどありませんコンテンツ..会話型およびタスク指向の対話システムは、テキストや音声などのマルチモーダルインターフェイスを介して自然な応答を使用してユーザーと対話することを目的としています。 
[ABSTRACT]目的の回答は、知識ソースによって調査された回答の形式です。これらは、口頭の質問からの完全な長さの自然な回答に基づいています。これは、グラフ入力から最良の回答までフルサイズの回答を生成する最初の試みです私たちの知識の
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-09">
        <br>2020-06-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CompLex: A New Corpus for Lexical Complexity Prediction from Likert
  Scale Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_31.html">
      CompLex: A New Corpus for Lexical Complexity Prediction from Likert
  Scale Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの論文では、語彙の複雑さを連続的に予測するための最初の英語のデータセットを提示することで、この制限に対処します。5ポイントのリッカートスケールスキームを使用して、聖書、ユーロパール、生物医学のテキストの3つのソース/ドメインからのテキストの複雑な単語に注釈を付けます。その結果、それぞれ約7人のアノテーターによって注釈が付けられた9,476文のコーパスが得られました。 
[ABSTRACT]このタスクは一般に、複雑な単語の識別（cwi）と呼ばれます。単語の欠如は、すべてのcwiデータセットに注釈が付けられているという事実のせいです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-16">
        <br>2020-03-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CoSDA-ML: Multi-Lingual Code-Switching Data Augmentation for Zero-Shot
  Cross-Lingual NLP -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_32.html">
      CoSDA-ML: Multi-Lingual Code-Switching Data Augmentation for Zero-Shot
  Cross-Lingual NLP
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      19言語での5つのタスクの実験結果は、この方法により、mBERTと比較してすべてのタスクのパフォーマンスが大幅に向上することを示しています。既存の作業と比較して、この方法はトレーニングに2か国語の文に依存せず、1つのトレーニングプロセスのみを必要とします。複数のターゲット言語。ただし、これらのモデルは、異なる言語間でサブワードのコンテキスト化された表現に一貫性がないために制限されます。 
[要約]私たちは、多言語コードを生成するデータ拡張フレームワークを提案します-データを微調整するために切り替えます-mbertを調整します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Extracting and categorising the reactions to COVID-19 by the South
  African public -- A social media study -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/cs.CL/paper_33.html">
      Extracting and categorising the reactions to COVID-19 by the South
  African public -- A social media study
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ソーシャルメディアは、災害時にディスカッショントピックを抽出するために使用できます。この調査結果は、南アフリカおよびそれ以降の災害環境におけるソーシャルメディアのさらなる研究に役立つ可能性があります。南アフリカに対するCOVID-19のパンデミックな影響により、ソーシャルメディアユーザーが関与している討論トピックとのパンデミックの対比に対応して政府によって公布された法律と規制。
[要約] covid-南アフリカへの19のパンデミックインパクト。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Memory Controlled Sequential Self Attention for Sound Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/eess.AS/paper_0.html">
      Memory Controlled Sequential Self Attention for Sound Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      URBAN-SEDデータセットでの実験は、自己注意によって誘発されたSEDモデルで、音声認識パフォーマンスに対するメモリの範囲の影響を示しています。メモリ制御された自己注意モデルが、URBANでイベントベースのFスコア33.92％を達成することを示します。 -SEDデータセット、自己注意なしでモデルによって報告されたFスコア20.10％を上回っています。各注意ヘッドが明示的な注意幅値で埋め込まれた音声を処理するマルチヘッド自己注意メカニズムで提案されたアイデアを拡張します。 
[要約]ポリフォニックサウンドイベント検出（sed）のために、畳み込みリカレントニューラルネットワーク（crnn）モデルに加えて、メモリ制御の自己注意メカニズムを使用することを提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br>2020-05-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to Count Words in Fluent Speech enables Online Speech
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/eess.AS/paper_1.html">
      Learning to Count Words in Fluent Speech enables Online Speech
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Tarisは標準のトランスフォーマーと比較してごくわずかなオーバーヘッドをもたらしますが、入力と出力の間のローカル関係モデリングは、設計によりシーケンス長に不変性を与えます。さらに、推定されたセグメント長の分布が強制アライメントで得られた語長の分布に似ていることを示します。私たちのシステムは、正確なセグメントと単語の同等性を必要としません。LRS2とLibriSpeechデータセットに対して、それぞれ制約のない音声と読み上げの音声の実験を行ったところ、オンラインのシステムはオフラインのデータと同等の性能を発揮し、動的なアルゴリズムは5セグメントの遅延。 
[ABSTRACT]これは、米国のスピーチスピーチで使用できます。正確なシステムは正確な正確なモデルを必要としないことを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-08">
        <br>2020-06-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Bonseyes AI Pipeline -- bringing AI to you. End-to-end integration of
  data, algorithms and deployment tools -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/eess.AS/paper_2.html">
      Bonseyes AI Pipeline -- bringing AI to you. End-to-end integration of
  data, algorithms and deployment tools
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、データ、アルゴリズム、およびデプロイメントツールを統合する統合フレームワークとしてモジュール式AIパイプラインを示します。次世代の組み込み情報通信技術（ICT）システムは、自律タスクを実行できる協調システムです。ただし、組み込みデバイスでのカスタムAIソリューションのトレーニングと展開には、高精度を実現するためのデータ、アルゴリズム、およびツールのきめ細かな統合が必要です。 
[ABSTRACT]ツールのさまざまな段階を相互接続し、モジュール式のエンドツーエンドの組み込みデバイス用AI製品の開発を提供できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-01-15">
        <br>2019-01-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Investigating Robustness of Adversarial Samples Detection for Automatic
  Speaker Verification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/eess.AS/paper_3.html">
      Investigating Robustness of Adversarial Samples Detection for Automatic
  Speaker Verification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      VGGのようなバイナリ分類検出器が導入され、敵対的なサンプルの検出に効果的であることが実証されています。以前のアプローチに直交するこの作業は、敵対的なデータをASVトレーニングに増強するのではなく、個別の検出ネットワークで敵対的な攻撃からASVシステムを防御することを提案します。 。既存のアプローチは主に、敵対的なデータの増大を伴うASVシステムの再トレーニングに重点を置いています。 
[ABSTRACT]そのような攻撃を防御するための既存の方法は限られています。これらには、広告を検出するvggのようなバイナリ分類検出器が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An Objective Measure of Quality for Time-Scale Modification of Audio -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/eess.AS/paper_4.html">
      An Objective Measure of Quality for Time-Scale Modification of Audio
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案された測定は、0.487の平均二乗平均誤差と0.865の平均ピアソン相関を達成し、主観的セッションの98パーセンタイルと82パーセンタイルにそれぞれ相当します。提案された測定は、時間スケール変更アルゴリズムを評価するために使用され、エラスティックがSolo楽器と音声信号の最高の客観的品質、Identity Phase-Locking Phase Vocoderは音楽信号の最高の客観的品質と最高の全体的な品質を提供します。タイムスケール修正（TSM）で処理されたオーディオの客観的評価は未解決の問題です。 
[ABSTRACT]時間のデータセット-処理されたラベルにスケーリングされた音声が公開されました。これは、品質の最初の客観的指標を作成するために使用されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Perceiving Music Quality with GANs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/eess.AS/paper_5.html">
      Perceiving Music Quality with GANs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      音楽オーディオ信号の知覚品質を評価するには、通常、変更されていないコンテンツのクリーンな参照信号が必要であり、音楽生成など、参照が利用できないアプリケーションを妨げます。この方法は監視されていないため、劣化した素材にアクセスする必要がなく、 music ..音楽ライブラリで生成的敵対的ネットワークをトレーニングし、その弁別子を知覚される音楽の品質の尺度として使用することを提案します。 
[要約]この方法は、音楽の人間による評価と統計的に有意な相関があることが示されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: XiaoiceSing: A High-Quality and Integrated Singing Voice Synthesis
  System -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/eess.AS/paper_6.html">
      XiaoiceSing: A High-Quality and Integrated Singing Voice Synthesis
  System
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、XiaoiceSingが畳み込みニューラルネットワークのベースラインシステムよりも、音質で1.44 MOS、発音精度で1.18、自然度で1.38優れていることを示しています。FastSpeechのメインアーキテクチャに従い、歌特有のデザインを提案します。 IDと位置のエンコーディング、楽譜からの機能（ノートのピッチや長さなど）も追加されます。このホワイトペーパーでは、スペクトル、F0、持続時間のモデリングに統合ネットワークを採用した高品質の歌声合成システムであるXiaoiceSingについて説明します。 
[要約] xiaoicesingは、歌うために提案されたシステムです-詳細。提案されたf0と期間のモデリングは、ベースラインに対して97.3％と84.3％の優先率を達成します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Blissful Ignorance: Anti-Transfer Learning for Task Invariance -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-12/eess.AS/paper_7.html">
      Blissful Ignorance: Anti-Transfer Learning for Task Invariance
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      標準の転移学習は、あるタスクで学習された表現が別のタスクに役立つと想定していますが、転移防止学習は、別のタスクで学習された表現の学習を回避します。 ..合計4つのデータセットを使用して、さまざまなタスクとセットアップでオーディオドメインのアプローチを評価します。さまざまな類似性メトリックと集計関数を使用して転移防止学習を実装しました。 
[ABSTRACT]反転移学習は、別のタスクについて学習された学習表現を回避します。これは、新しいタスクに関連せず、誤解を招く可能性があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本日更新された論文はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br>
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
