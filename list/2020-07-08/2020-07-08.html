<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-07-08の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Predicting Afrobeats Hit Songs Using Spotify Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.SD/paper_0.html">
      <font color="black">Predicting Afrobeats Hit Songs Using Spotify Data</font>
    </a>
  </h2>
  <font color="black">この研究は、Afrobeatsジャンルのどの曲がSpotifyリスナーの間で人気になるかを予測することを目的として、ヒットソングサイエンスの問題に取り組みました。曲は、提供されたオーディオ機能を使用して、Spotify Web APIを介して生成されました。 
[要約] 2063曲のデータセットは、spotify web apiを介して生成されました。データセットは、spotifyのソフトウェアによって生成されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Tones' Phase Coding (MTPC) of Interaural Time Difference by
  Spiking Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.SD/paper_1.html">
      <font color="black">Multi-Tones' Phase Coding (MTPC) of Interaural Time Difference by
  Spiking Neural Network</font>
    </a>
  </h2>
  <font color="black">MTPCは、畳み込みSNNと反復SNNの2つの異なるSNNアーキテクチャでパイプライン化されており、さまざまなSNNへの適用性を示しています。実験結果は、平均誤差方位角1〜3度を示し、他の生物学的精度を上回っています。音源定位のためのもっともらしいニューロモーフィックなアプローチ..このスキームは、到着の時間差を人工的に計算するのではなく、人間の聴覚定位システムの機能的構造に自然に従います。 
[ABSTRACT]このモデルのキーは、両耳間の時間差（itd）キューをスパイクパターンにエンコードするmtpcに依存しています。イベント駆動型や電力効率などのsnnの利点を際立たせています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: X-vectors: New Quantitative Biomarkers for Early Parkinson's Disease
  Detection from Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.SD/paper_2.html">
      <font color="black">X-vectors: New Quantitative Biomarkers for Early Parkinson's Disease
  Detection from Speech</font>
    </a>
  </h2>
  <font color="black">高品質のマイクと自分の電話で221人のフランス語話者（最近診断されたPD被験者と健康な対照を含む）を録音しました。より正確なモデルを持ち、起こりうる性別への影響を評価するために、男性と女性を別々に分析しました。多くの記事はパーキンソン病（PD）を検出するために音声分析を使用していますが、病気の初期段階と性別への影響に焦点を当てたものはほとんどありません。 
[ABSTRACT]最新の話者認識システム（xシールドと呼ばれる）を採用して、音声分析からpdの初期段階を検出しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Unsupervised CT Metal Artifact Learning using Attention-guided
  beta-CycleGAN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_0.html">
      <font color="black">Unsupervised CT Metal Artifact Learning using Attention-guided
  beta-CycleGAN</font>
    </a>
  </h2>
  <font color="black">提案された方法は、適切なフィーチャ空間のもつれを解くための最適な輸送理論から導出された新しいベータサイクルGANアーキテクチャに基づいています。金属アーチファクト削減（MAR）は、コンピュータ断層撮影（CT）で最も重要な研究トピックの1つです。たたみ込みブロックアテンションモジュール（CBAM）レイヤーを適切な解きほぐしパラメーターで追加すると、実験結果により、元の画像の詳細なテクスチャーを維持する、より改善されたMARを取得できることが確認されています。 
[要約]提案された方法は、小説のベータ-サイクガンアーキテクチャに基づいています。有効な機能である空間のもつれを解消するための最適なトランスポグラフィーに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: A Weakly Supervised Consistency-based Learning Method for COVID-19
  Segmentation in CT Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_1.html">
      <font color="black">A Weakly Supervised Consistency-based Learning Method for COVID-19
  Segmentation in CT Images</font>
    </a>
  </h2>
  <font color="black">このラベル付けスキームにより、アノテーターは感染しそうな領域のピクセルにラベルを付けることができます。領域をセグメント化するのに10〜15秒かかるのに対し、1〜3秒しかかかりません。コロナウイルス病2019（COVID-19）は世界中に積極的に広まり、実存的な健康危機。従来、セグメンテーションモデルは、これらのラベルのクロスエントロピー損失関数を使用して、ポイントレベルのアノテーションでトレーニングします。 
[要約]トモグラフィー（ct）画像でcovid-19を検出するシステムは、病気の重症度を定量化するのに役立ちます。ただし、ラベリング担当者は、ポイントの注釈、ct画像の感染領域ごとに1つのピクセルのみを必要とします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-04">
        <br><font color="black">2020-07-04</font>
      </time>
    </span>
</section>
<!-- paper0: A Vision-based Social Distance and Critical Density Detection System for
  COVID-19 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_2.html">
      <font color="black">A Vision-based Social Distance and Critical Density Detection System for
  COVID-19</font>
    </a>
  </h2>
  <font color="black">さらに、関心領域（ROI）の社会的密度を測定し、流入を調整することで、社会的距離違反の発生機会を減らすことができます。ここでは、4つの重要な倫理的要因を考慮した人工知能（AI）ベースのリアルタイムの社会的距離の検出と警告システムを提案します。 （1）システムがデータを記録/キャッシュしてはならない、（2）警告は個人をターゲットにしてはならない、（3）人間の監督者が検出/警告ループに入ってはならない、（4）コードはオープンソースであり、一般に公開されています。提案された方法を実際のデータセット全体でテストし、その一般性とパフォーマンスを測定しました。 
[ABSTRACT]人工知能（ai）ベースのリアルタイムの社会的距離検出および警告システム。違反が検出された場合、非侵入型の音声-視覚的警告信号が送信されますが、社会的距離の測定基準に違反した個人をターゲットにしません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: S2-cGAN: Self-Supervised Adversarial Representation Learning for Binary
  Change Detection in Multispectral Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_3.html">
      <font color="black">S2-cGAN: Self-Supervised Adversarial Representation Learning for Binary
  Change Detection in Multispectral Images</font>
    </a>
  </h2>
  <font color="black">ディープニューラルネットワークは最近、リモートセンシング（RS）におけるバイナリ変更検出（CD）の問題で有望なパフォーマンスを実証し、大量のラベル付き多時間トレーニングサンプルを必要とします。提案されたS ^ 2-cGANは、変化しない分布のみを生成するようにトレーニングされていますサンプル..既存のGANベースのメソッド（敵対的なトレーニング中に識別器を使用してジェネレーターを監視するだけ）とは異なり、S2-cGANは直接識別器の可能性を利用してバイナリCDタスクを解決します。 
[要約]提案された方法は2つのステップで構成されています：rs（s2-cgan）。これらには、敵対的なゲームを通じてサンプルの分布を学習することが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Speed-of-sound imaging by differential phase contrast with angular
  compounding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_4.html">
      <font color="black">Speed-of-sound imaging by differential phase contrast with angular
  compounding</font>
    </a>
  </h2>
  <font color="black">シグネチャのコントラストは、角度合成の方法によって増強され、画像のシャープネスの「フォーカス」制御を提供します。これにより、サンプル内の異常な内包物のオンザフライでの視覚的な位置特定が可能になります。このようなイメージングは、最終的には軟組織の病状の臨床診断に役立ちます。特に、この手法では、リアルタイムで0.5 \％程度の相対的なSoS変動を簡単に明らかにできることを示しています。
[要約]この手法では、標準パルスと同じ受信原理を使用します-エコーImaging.itは、標準の位相シフトと同じ手法を使用して並行して操作できます。これは、標準のbモードイメージングで操作すると、2dで実行できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Lossless CNN Channel Pruning via Gradient Resetting and Convolutional
  Re-parameterization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_5.html">
      <font color="black">Lossless CNN Channel Pruning via Gradient Resetting and Convolutional
  Re-parameterization</font>
    </a>
  </h2>
  <font color="black">記憶と忘却の独立性に関する神経生物学の研究に触発されて、CNNを記憶パラメータと忘却部分に再パラメータ化することを提案します。前者はパフォーマンスを維持することを学習し、後者は効率を学習します。 ImageNetで76.15 \％のトップ1の精度を持つ標準のResNet-50を43.9 \％FLOPのみの狭いものにスリム化でき、精度の低下はありません。コードとモデルはhttps://github.com/DingXiaoH/でリリースされていますResRep。 
[ABSTRACT] `filter pruning &#39;は、畳み込みニューラルネットワーク（cnn）をスリム化することを目的としています。それは、畳み込み層の幅（つまり、出力チャネルの数）を減らすことを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Learning and Reasoning with the Graph Structure Representation in
  Robotic Surgery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_6.html">
      <font color="black">Learning and Reasoning with the Graph Structure Representation in
  Robotic Surgery</font>
    </a>
  </h2>
  <font color="black">グラフシーンラベルを取得するには、ロボットシーンのセグメンテーションチャレンジ2018データセットのバウンディングボックスとインストルメントROIインタラクションに注釈を付け、ロボット手術の経験豊富な臨床専門家を使用して提案を評価します。各ノードを対応する隣接ノードに埋め込むにはノードの機能については、SageConvをさらにネットワークに組み込んでいます。ハードラベルを平滑化すると、モデルの予測が過剰になることを回避でき、最後から2番目のレイヤーによって学習された機能の表現が強化されます。 
[要旨]シーングラフを生成して、ロボット支援手術中に器具と手術対象領域（roi）の間の手術の相互作用を予測するアプローチを開発します。各ノードを対応する隣接する設計設計に埋め込むために、ネットワークにsageconvをさらに組み込みました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Plane Adjustment of Orthopedic Intraoperative Flat Panel
  Detector CT-Volumes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_7.html">
      <font color="black">Automatic Plane Adjustment of Orthopedic Intraoperative Flat Panel
  Detector CT-Volumes</font>
    </a>
  </h2>
  <font color="black">これらの領域の1つでは、1つの平面が他の2つの平面に直交していません。CNNは2つの解剖学的領域で評価されます。 。 
[ABSTRACT]ボリュームの軸整列多平面再構成（mpr）は、解剖学的に整列されたmprsと一致します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Ischemic Stroke Lesion Segmentation from Computed Tomography
  Perfusion Images by Image Synthesis and Attention-Based Deep Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_8.html">
      <font color="black">Automatic Ischemic Stroke Lesion Segmentation from Computed Tomography
  Perfusion Images by Image Synthesis and Attention-Based Deep Neural Networks</font>
    </a>
  </h2>
  <font color="black">最初に、特徴抽出器を使用して、未加工の時空間コンピュータ断層撮影（CTA）画像の低レベルと高レベルの両方のコンパクトな表現を取得します。この問題に対処するために、合成された疑似拡散拡散に基づく新しいフレームワークを提案します。灌流パラメーターマップからの加重イメージング（DWI）により、より正確なセグメンテーションのためのより良い画像品質が得られます。コンピューター断層撮影灌流（CTP）画像からの虚血性脳卒中病変セグメンテーションは、急性期治療室における脳卒中の正確な診断に重要です。 
[ABSTRACT]病変領域は疑似dwiジェネレーターによってマップされます。これは畳み込みニューラルネットワークに基づいており、それを利用するようにトレーニングされています。これらのコンポーネントが開発されたのはこれが初めてです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Image reconstruction through a multimode fiber with a simple neural
  network architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_9.html">
      <font color="black">Image reconstruction through a multimode fiber with a simple neural
  network architecture</font>
    </a>
  </h2>
  <font color="black">かなり単純なニューラルネットワークアーキテクチャである単一の隠れ層の高密度ニューラルネットワークは、画像再構成の忠実度とトレーニング時間の点で以前に使用されたCNNよりも優れていることがわかります。密集したネットワークが期間全体でCNNよりも優れたパフォーマンスを発揮するトレーニングセット。 MMFの分散は深刻な未解決の問題です。 
[要約]畳み込みニューラルネットワーク（cnns）は、高忠実度のmmf画像再構成を実行するようにトレーニングできます。ネットワークは、トレーニングセットの停止後1週間にわたって収集されたmmf画像を正確に再構成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-10">
        <br><font color="black">2020-06-10</font>
      </time>
    </span>
</section>
<!-- paper0: MetricUNet: Synergistic Image- and Voxel-Level Learning for Precise CT
  Prostate Segmentation via Online Sampling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_10.html">
      <font color="black">MetricUNet: Synergistic Image- and Voxel-Level Learning for Precise CT
  Prostate Segmentation via Online Sampling</font>
    </a>
  </h2>
  <font color="black">そして、比較は、提案された方法が合理的なマージンで最先端の方法よりも優れていることを示しています。マルチタスクネットワークでボクセル単位のサンプリングを介して、新しいオンラインメトリック学習モジュールを導入します。 -予測されたセグメンテーションで滑らかな近傍。 
[要約]提案されたネットワークには、2つのタスクに取り組むデュアルブランチアーキテクチャがあります。これらには、前立腺のセグメンテーションを生成することを目的としたボクセルネットワークと、ボクセル、メトリック学習サブネットワークが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-15">
        <br><font color="black">2020-05-15</font>
      </time>
    </span>
</section>
<!-- paper0: Instance Segmentation for Whole Slide Imaging: End-to-End or
  Detect-Then-Segment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_11.html">
      <font color="black">Instance Segmentation for Whole Slide Imaging: End-to-End or
  Detect-Then-Segment</font>
    </a>
  </h2>
  <font color="black">以前に検出された512x512の糸球体で動作するDeepLab_v3セグメンテーションフレームワークを使用した検出後セグメントパイプラインは、エンドツーエンドのマスク-RCNNパイプラインからの0.902 DSCと比較して、0.953のダイス類似係数（DSC）を達成しました。検出後セグメントパイプラインは、エンドツーエンドメソッドと比較してより優れたセグメンテーションパフォーマンスを達成しました。コンピュータービジョンでは、エンドツーエンドインスタンスセグメンテーションメソッド（たとえば、Mask-RCNN）は、検出後と比較した利点を示しています。補完的な検出とセグメンテーションタスクを同時に実行することにより、セグメントアプローチ。 
[ABSTRACT]高解像度wsiでは、単一の糸球体が元の解像度で1,00x1,00ピクセルを超えることがあります。これは、1,00x1,00ピクセルを超える単一の糸球体と比較できますが、高解像度のイメージングでは、糸球体は1,00x1、000ピクセルを超える可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Noise-Powered Disentangled Representation for Unsupervised Speckle
  Reduction of Optical Coherence Tomography Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_12.html">
      <font color="black">Noise-Powered Disentangled Representation for Unsupervised Speckle
  Reduction of Optical Coherence Tomography Images</font>
    </a>
  </h2>
  <font color="black">画像のノイズ除去にディープラーニングが適用され、有望な結果が得られていますが、十分に登録されたクリーンでノイズの多い画像ペアがないため、教師あり学習ベースのアプローチで満足できるOCT画像のノイズ除去結果を実現することは現実的ではありません。解きほぐされた表現と生成的敵対ネットワークでは、提案された方法は最初に対応するエンコーダーによってノイズの多い画像をコンテンツとノイズ空間に解きほぐします。様々な眼疾患。 
[要約]このホワイトペーパーでは、適切に登録された画像ペアに依存しない教師なしのoct画像スペックル低減アルゴリズムを提案します。それまでに、ジェネレーターを使用して、抽出されたコンテンツの特徴を持つノイズ除去されたoct画像を予測します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Self domain adapted network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_13.html">
      <font color="black">Self domain adapted network</font>
    </a>
  </h2>
  <font color="black">ただし、ターゲットドメインごとにモデルをトレーニングするのは時間がかかり、計算コストがかかります。ターゲットドメインのデータが不足している場合や、データのプライバシーのためにソースデータが利用できない場合でも、実行不可能です。ドメインのシフトは、臨床現場でディープネットワークを展開するための大きな問題です。ターゲットラベルデータがないため、ほとんどの作業は教師なしドメイン適応（UDA）に焦点を当てています。 
[ABSTRACT]（ターゲット）画像が（ソース）トレーニングデータとは異なる方法で取得すると、ネットワークパフォーマンスが大幅に低下します。現在のudaメソッドでは、画像変換（調和）またはドメイン固定機能を学習するモデルをトレーニングするために、ソースデータとターゲットデータの両方が必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: GIQA: Generated Image Quality Assessment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_14.html">
      <font color="black">GIQA: Generated Image Quality Assessment</font>
    </a>
  </h2>
  <font color="black">さまざまなデータセットで最近のさまざまなGANモデルによって生成された多数の画像を評価し、それらが人間の評価と一貫していることを実証します。さらに、生成モデルのリアリズムと多様性を個別に評価し、オンラインでハードを有効にするなど、多くのアプリケーションでGIQAを利用できます。結果を改善するためのGANのトレーニングにおけるネガティブマイニング（OHEM）。2つの視点からの3つのGIQAアルゴリズムを紹介します：学習ベースとデータベース。 
[要約]最近、トピックに対していくつかの定量的基準が浮上しましたが、それらのどれも定量的画像用に設計されていません。これには、学習ベースとデータベースが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-19">
        <br><font color="black">2020-03-19</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic lesion detection, segmentation and characterization via 3D
  multiscale morphological sifting in breast MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_15.html">
      <font color="black">Automatic lesion detection, segmentation and characterization via 3D
  multiscale morphological sifting in breast MRI</font>
    </a>
  </h2>
  <font color="black">領域候補は最後に、ランダムアンダーサンプリングブースト（RUSboost）によって病変または正常組織として、ランダムフォレストによって悪性または良性病変として分類されます。同じ乳房MRIデータセットで評価された以前に提案されたシステムと比較して、提案されたCADシステムは、乳房病変の検出と特性評価において好ましいパフォーマンスを実現します。病変のセグメンテーションの平均ダイス類似性インデックス（DSI）は0.72です。 
[ABSTRACT]提案されたCADシステムは、4Dマルチモーダル乳房MRIデータを処理できます。これらには、ユーザーの介入なしで病変検出とセグメンテーションが含まれます。提案されたシステムは、真陽性率（tpr）が3.90で3.90を達成します。 ）病変検出用</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Lung Segmentation from Chest X-rays using Variational Data Imputation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_16.html">
      <font color="black">Lung Segmentation from Chest X-rays using Variational Data Imputation</font>
    </a>
  </h2>
  <font color="black">このモデルを広範囲のデータ増強を伴う通常のCXRでトレーニングし、このモデルの有用性を実証して極端な異常を伴う症例に拡張します。肺混濁は、新規コロナウイルス病2019（COVIDを含む、多くの呼吸器疾患によって引き起こされる肺の炎症です。 -19）..この作業では、CXRからのCOVID-19の自動リスクスコアリングを目的としたパイプラインの一部として、このような異常なCXRから肺をセグメント化することに焦点を当てます。 
[ABSTRACT]心臓X-このような混濁を伴う光線は、肺の領域を認識できなくします。これにより、肺の自動画像分析を実行することが困難になります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br><font color="black">2020-05-20</font>
      </time>
    </span>
</section>
<!-- paper0: Uncertainty-Aware Blind Image Quality Assessment in the Laboratory and
  Wild -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_17.html">
      <font color="black">Uncertainty-Aware Blind Image Quality Assessment in the Laboratory and
  Wild</font>
    </a>
  </h2>
  <font color="black">6つのIQAデータベースでの広範囲な実験は、実験室および野生で画像品質を盲目的に評価する学習方法の有望さを示しています。最初に同じIQAデータベースから画像のペアをサンプリングし、各ペアの1つの画像がより高品質である確率を計算します次に、監視信号として使用します。次に、フィデリティ損失を使用して、このような多数の画像ペアでBIQAのディープニューラルネットワークを最適化します。 
[ABSTRACT]これは、実験室でシミュレーションされ、野生でキャプチャされた画像間の分布のずれによるものです。しかし、合成歪みのあるデータベースでトレーニングされたモデルは、現実的な歪みの処理に特に弱いままです。これを使用して、提案されたトレーニング戦略の普遍性を実証しました既存のbiqaモデルを改善する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br><font color="black">2020-05-28</font>
      </time>
    </span>
</section>
<!-- paper0: Context Model for Pedestrian Intention Prediction using Factored
  Latent-Dynamic Conditional Random Fields -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_18.html">
      <font color="black">Context Model for Pedestrian Intention Prediction using Factored
  Latent-Dynamic Conditional Random Fields</font>
    </a>
  </h2>
  <font color="black">FLDCRFは、データセット全体（データセットごとに$ \ sim $ 100シーケンス）のLong Short-Term Memory（LSTM）ネットワークよりも優れた同一の時系列機能を備えています。この目的のために、歩行者の意図に対する車両の相互作用の影響を紹介します。そのような車両相互作用コンテキストを含めることにより、予測時間の認識可能な進歩を示します。 
[ABSTRACT]既存のシステムは、歩行者の横断または非横断の予測を車両の前で支援します。これらのシステムは、歩行者の早期かつ正確な予測を必要とします。これらのシステムは、そのようなシステムの円滑な運用のための早期予測の必要性を述べています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-27">
        <br><font color="black">2019-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Topology Transformation with Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_19.html">
      <font color="black">3D Topology Transformation with Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">生成された3D形状は斬新でインスピレーションを与えると信じています。最後に、GANを使用せずに、3D形状を直接変換するベースラインアルゴリズムとアプローチの結果を比較します。カスタマイズされた3Dを構築する方法を説明します表現。 
[要旨] vox2voxと呼ばれる修正済みのpix2pixガンを使用して、3Dオブジェクトの体積スタイルを変換します。さらに、ガンを使用せずに、アプローチと3D形状を直接変換するベースラインアルゴリズムの結果を比較します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Segmentation of Pulmonary Opacification in Chest CT Scans of COVID-19
  Patients -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_20.html">
      <font color="black">Segmentation of Pulmonary Opacification in Chest CT Scans of COVID-19
  Patients</font>
    </a>
  </h2>
  <font color="black">データセットでトレーニングされた複数のセグメンテーションモデルに、オープンソースの実装と事前トレーニング済みの重みを提供します。この作業では、さまざまなものと関連付けられている胸部CTスキャンでの肺混濁のパターンのセグメンテーションのためのオープンソースモデルを提供します世界中のヘルスケアセンターからCOVID-19患者の663胸部CTスキャンを収集し、肺の混濁の6つの異なるパターンをセグメント化する約25,000スライスのピクセルごとのセグメンテーションラベルを作成しました。 
[要約]ある種の肺炎は、このウイルスに関連する最も一般的な症状です。当社の最良のモデルは、不透明度の交差-ユニオンスコア0. 76を達成しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: High-speed Millimeter-wave 5G/6G Image Transmission via Artificial
  Intelligence -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_21.html">
      <font color="black">High-speed Millimeter-wave 5G/6G Image Transmission via Artificial
  Intelligence</font>
    </a>
  </h2>
  <font color="black">94 GHzプロトタイプが構築され、「A」から「Z」までの文字に対して最大1桁の画像伝送速度の向上が実現されました。人工知能（AI）は、mmWave圧縮センシング（ CS）高速5G / 6G画像転送用。具体的には、3つの主要な機能を実現するために、辞書学習圧縮センシングニューラルネットワーク（DL-CSNet）を開発しました。 2）アダマール測定行列を最適化する。 3）学習された辞書ベースでロスレス画像を再構成する。 
[要約]私たちは辞書学習圧縮センシングシステムを開発しました。それは学習した辞書ベースでロスレス画像を高速化することを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Divide-and-Rule: Self-Supervised Learning for Survival Analysis in
  Colorectal Cancer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_22.html">
      <font color="black">Divide-and-Rule: Self-Supervised Learning for Survival Analysis in
  Colorectal Cancer</font>
    </a>
  </h2>
  <font color="black">次に、これらの組織病理学的パターンを使用して、複雑な組織間の相互作用を表し、臨床転帰を直接予測します。これを行うには、組織領域の表現とクラスタリングのメトリックを共同で学習する自己教師あり学習方法を提案します。それらの基礎となるパターン。私たちの方法によって得られた組織形態学的クラスターは、生存モデルのトレーニングによって評価されます。 
[ABSTRACT]がん組織領域の組織病理学的パターンの迅速な研究。これらは、複雑な組織間の相互作用を表すために使用されます。これらのパターンは、結腸直腸がんの予後の層別化を改善するために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Extracting the fundamental diagram from aerial footage -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_23.html">
      <font color="black">Extracting the fundamental diagram from aerial footage</font>
    </a>
  </h2>
  <font color="black">一般に、このシステムの動作は、道路セグメント、地域、またはネットワークの基本図によって特徴付けられます。このホワイトペーパーでは、ドローンプラットフォームから取得した空中映像から基本図を取得する革新的な方法を考案します。効率的な交通監視が行われています交通ネットワークの混雑にうまく対処するための基本的な役割。3つのフェーズのそれぞれについて開発されたアルゴリズムについて詳しく説明し、実際の設定での結果の適用性を示します。 
[ABSTRACT]輻輳は、2つの測定可能な特性、システム全体の動作に影響を与える需要とネットワーク密度と強く相関しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Light Field Image Super-Resolution Using Deformable Convolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.IV/paper_24.html">
      <font color="black">Light Field Image Super-Resolution Using Deformable Convolution</font>
    </a>
  </h2>
  <font color="black">具体的には、機能レベルの位置合わせのための角度変形可能な位置合わせモジュール（ADAM）を設計します。さらに、ベースライン調整可能なLFデータセットを開発して、さまざまな視差の下でSRパフォーマンスを評価します。ADAMに基づいて、さらに収集と提案を行いますセンタービュー機能と各サイドビュー機能の間で双方向の位置合わせを実行する分散アプローチ。 
[ABSTRACT]複数のlf画像に加えて、これらの情報をうまく組み込むことができます。これらの機能は、各ビューの機能に組み込んでエンコードできます。これは、すべてのlf画像のsr再構成の結果です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: What Gives the Answer Away? Question Answering Bias Analysis on Video QA
  Datasets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_0.html">
      <font color="black">What Gives the Answer Away? Question Answering Bias Analysis on Video QA
  Datasets</font>
    </a>
  </h2>
  <font color="black">具体的には、トレーニング中に見られたアノテーターは、モデルと推論によってより適切に予測されます。抽象的な質問は、実際の直接的な質問よりもバイアスがかかります。また、アノテーターと重複しないトレーニングテストの分割を使用すると、ビデオQAデータセット..ビデオQAデータセットの質問応答バイアスは、マルチモーダルモデルを誤ってQAアーティファクトに適合させ、モデルの一般化能力を危険にさらす可能性があります。 
[ABSTRACT]調査では、QAバイアスの強さや発生源が示されています。モデルをデバッグするための洞察が研究者に提供されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Spatial Semantic Embedding Network: Fast 3D Instance Segmentation with
  Deep Metric Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_1.html">
      <font color="black">Spatial Semantic Embedding Network: Fast 3D Instance Segmentation with
  Deep Metric Learning</font>
    </a>
  </h2>
  <font color="black">複雑な前処理または後処理を必要とする以前のアプローチとは異なり、実装はコンパクトで高速であり、競争力のあるパフォーマンスを実現し、高解像度のボクセルを持つ大規模なシーンでのスケーラビリティを維持します。オブジェクトのインスタンスを、空間情報と意味情報の両方を反映する別個のクラスターに分割します。APスコアのScanNet 3Dインスタンスセグメンテーションベンチマークで、アルゴリズムの最先端のパフォーマンスを示します。 
[ABSTRACT]これは、屋内環境の最強最強最強の再構築です。たとえば、アルゴリズムの単純なパフォーマンスを示しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised CT Metal Artifact Learning using Attention-guided
  beta-CycleGAN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_2.html">
      <font color="black">Unsupervised CT Metal Artifact Learning using Attention-guided
  beta-CycleGAN</font>
    </a>
  </h2>
  <font color="black">提案された方法は、適切なフィーチャ空間のもつれを解くための最適な輸送理論から導出された新しいベータサイクルGANアーキテクチャに基づいています。別の重要な貢献は、注意メカニズムが金属アーチファクトを効果的に削除するための重要な要素であることを示すことです。最近、有望MARの教師なし学習は機能の絡み合い解消を使用して提案されましたが、結果のネットワークアーキテクチャは複雑であり、大規模な臨床画像を処理することが困難です。 
[要約]提案された方法は、小説のベータ-サイクガンアーキテクチャに基づいています。有効な機能である空間のもつれを解消するための最適なトランスポグラフィーに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Determining Sequence of Image Processing Technique (IPT) to Detect
  Adversarial Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_3.html">
      <font color="black">Determining Sequence of Image Processing Technique (IPT) to Detect
  Adversarial Attacks</font>
    </a>
  </h2>
  <font color="black">私たちの実証実験は、このアプローチがあらゆるAIモデルの処理として効率的に使用できることを示す有望な結果を示しました。したがって、最初に、適応型攻撃手法（防御上）を含むさまざまな攻撃手法を使用して、クリーンなデータセットから敵対的なサンプルを生成しました。 。元の画像と処理された画像の「画像の違い」を使用して特徴を抽出し、分類スキームに入力して、入力サンプルが敵対的かクリーンかを判断します。 
[要約]作業は複数のデータを分析することによって開発されました-攻撃セットでテストされたセット</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-01">
        <br><font color="black">2020-07-01</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Count in the Crowd from Limited Labeled Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_4.html">
      <font color="black">Learning to Count in the Crowd from Limited Labeled Data</font>
    </a>
  </h2>
  <font color="black">具体的には、ラベル付けされていないデータの擬似グラウンドトゥルースの推定を含むガウスプロセスベースの反復学習メカニズムを提案します。これは、ネットワークのトレーニングの監視として使用されます。さらに、提案された方法を活用して、合成データセットからカウントすることを学習しながら、現実世界のデータセットに一般化することができるネットワーク（合成から現実への転送）。提案された方法は、ShanghaiTech、UCF-QNRF、WorldExpo、UCSDなどのいくつかのデータセットの削減されたデータ（半教師あり）設定で有効であることが示されています。
[要約]提案された方法は、削減されたデータ（半監視）設定</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Human Trajectory Forecasting in Crowds: A Deep Learning Perspective -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_5.html">
      <font color="black">Human Trajectory Forecasting in Crowds: A Deep Learning Perspective</font>
    </a>
  </h2>
  <font color="black">私たちの分析に基づいて、これらの社会的相互作用を効果的にキャプチャするためのシンプルでありながら強力な方法を提案します。初期の作品は、ドメイン知識に基づいてこの表現を手作りしました。社会的相互作用。 
[要約]人間の軌跡の予測を分析するための調査が行われました。これには、大規模な相互作用-中心的な状況のtrajnetが含まれていました。この方法は、現実世界と合成データセットの両方で競合ベースラインよりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Interpretability of CNN Models Using Non-Negative Concept
  Activation Vectors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_6.html">
      <font color="black">Improving Interpretability of CNN Models Using Non-Negative Concept
  Activation Vectors</font>
    </a>
  </h2>
  <font color="black">忠実度（近似モデル）と解釈可能性（人にとって意味がある）の要件に基づいて、測定を設計し、フレームワークとの整合のためのさまざまな次元削減方法を評価します。この作業では、Ghorbani et〜のACEアルゴリズムを再考します。その他、概念ベースの代替説明フレームワークを提案しています。CAVには概念レベルの情報が含まれており、クラスタリングを通じて学習できます。 
[要旨] cnns.cavsを適用する場合、この欠陥は重要な課題のままです-概念-レベル情報が含まれ、階層化によって学習できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-27">
        <br><font color="black">2020-06-27</font>
      </time>
    </span>
</section>
<!-- paper0: A Weakly Supervised Consistency-based Learning Method for COVID-19
  Segmentation in CT Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_7.html">
      <font color="black">A Weakly Supervised Consistency-based Learning Method for COVID-19
  Segmentation in CT Images</font>
    </a>
  </h2>
  <font color="black">従来、セグメンテーションモデルは、これらのラベルのクロスエントロピー損失関数を使用して、ポイントレベルのアノテーションでトレーニングします。このラベル付けスキームにより、アノテーターは、感染しそうな領域のピクセルにラベルを付けることができます。地域をセグメント化する秒数。コロナウイルス病2019（COVID-19）は世界中に積極的に広がり、実存的な健康危機を引き起こしています。 
[要約]トモグラフィー（ct）画像でcovid-19を検出するシステムは、病気の重症度を定量化するのに役立ちます。ただし、ラベリング担当者は、ポイントの注釈、ct画像の感染領域ごとに1つのピクセルのみを必要とします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-04">
        <br><font color="black">2020-07-04</font>
      </time>
    </span>
</section>
<!-- paper0: Structured (De)composable Representations Trained with Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_8.html">
      <font color="black">Structured (De)composable Representations Trained with Neural Networks</font>
    </a>
  </h2>
  <font color="black">表現は、表現をクラスと環境を表す要素に分解できる明確な構造であることを証明します。提案された手法は、エンドツーエンドのディープラーニングを使用して、入力画像と離散ラベルから構造化された合成可能な表現を学習します。表現は、クラスラベルによって与えられる分布と、環境としてモデル化されるコンテキスト情報によって与えられる分布との間の距離推定に基づいています。 
[ABSTRACT]コンセプトは、クラス全体の特徴を捉えたコンセプトの形式です。クラスラベルによって与えられたスナックとコンテキスト情報によって与えられたスナックの間の距離の推定に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: CURL: Contrastive Unsupervised Representations for Reinforcement
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_9.html">
      <font color="black">CURL: Contrastive Unsupervised Representations for Reinforcement
  Learning</font>
    </a>
  </h2>
  <font color="black">私たちのコードはオープンソースであり、https：//github.com/MishaLaskin/curl。で入手できます。CURLは、DeepMind Control SuiteとAtari Gamesの複雑なタスクで、モデルベースとモデルフリーの両方の以前のピクセルベースの方法よりも優れています。 100K環境での1.9倍および1.2倍のパフォーマンス向上と対話ステップのベンチマークをそれぞれ示しています。CURLは、対照学習を使用して生のピクセルから高レベルの機能を抽出し、抽出された機能の上にポリシー外の制御を実行します。 
[ABSTRACT] curlは、対照学習に基づいて生のピクセルから高レベルの特徴を抽出します。対照学習に基づいて、抽出された特徴に基づいてオフポリシー制御を実行します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br><font color="black">2020-04-08</font>
      </time>
    </span>
</section>
<!-- paper0: Regional Image Perturbation Reduces $L_p$ Norms of Adversarial Examples
  While Maintaining Model-to-model Transferability -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_10.html">
      <font color="black">Regional Image Perturbation Reduces $L_p$ Norms of Adversarial Examples
  While Maintaining Model-to-model Transferability</font>
    </a>
  </h2>
  <font color="black">地域の敵対的攻撃は、敵対的な摂動を生成するための複雑な方法に依存することが多いため、既知の攻撃との有効性を比較することは困難です。選択した地域によっては、これらのローカライズされた敵対的な例に必要な$ L_p $ノルムの歪みが大幅に少なくなります（$ p \ \ {0、2、\ infty \} $）と比較して、ローカルでない対応物と比較します。クロスエントロピー符号を使用した非常にシンプルな地域の敵対的摂動攻撃法を開発します。これは、敵対的な機械学習で最も一般的に使用される損失の1つです。 
[要約]研究により、複雑な方法に頼らずに効果的な地域の摂動を生成できることが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Universal Lower-Bounds on Classification Error under Adversarial Attacks
  and Random Corruption -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_11.html">
      <font color="black">Universal Lower-Bounds on Classification Error under Adversarial Attacks
  and Random Corruption</font>
    </a>
  </h2>
  <font color="black">最適な敵対的攻撃は、特定の攻撃モデルによって引き起こされる特定のバイナリコスト関数の最適なトランスポートプランであり、2部グラフの最大マッチングに基づく単純なアルゴリズムを介して計算できます。これらの境界は、データのクラス条件付き分布のジオメトリに依存しますが、特定の分類子には依存しません。（2）一般的な距離ベースの攻撃の場合、ベイズ最適誤差の明示的な下限を導出します。 
[ABSTRACT]私たちの仕事はベイの導出に焦点を当てています-分類器が特定の分類問題で発生する可能性のある最適なエラーであり、敵対的な攻撃の影響を受けます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br><font color="black">2020-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: A Vision-based Social Distance and Critical Density Detection System for
  COVID-19 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_12.html">
      <font color="black">A Vision-based Social Distance and Critical Density Detection System for
  COVID-19</font>
    </a>
  </h2>
  <font color="black">提案された方法を実際のデータセット全体でテストして、その一般性とパフォーマンスを測定しました。一方、データを記録し、測定基準に従わない個人にラベルを付けると、自由社会における個人の権利が侵害されます。アクティブな監視システム個人間の距離を検出して警告することで、致命的な病気の蔓延を遅らせることができます。 
[ABSTRACT]人工知能（ai）ベースのリアルタイムの社会的距離検出および警告システム。違反が検出された場合、非侵入型の音声-視覚的警告信号が送信されますが、社会的距離の測定基準に違反した個人をターゲットにしません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: ROAM: Random Layer Mixup for Semi-Supervised Learning in Medical Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_13.html">
      <font color="black">ROAM: Random Layer Mixup for Semi-Supervised Learning in Medical Imaging</font>
    </a>
  </h2>
  <font color="black">代わりに、\ textit {ランダムレイヤーミックスアップ}であるROAMを提案します。これにより、ランダムに選択されたスペースで補間されたデータポイントに対するネットワークの信頼性が低下します。ROAMは、これまでに見たことのないデータポイントをより多く生成します。一般化能力を適合させ、強化します。このオプションは制限されていると私たちは主張します。 
[要約]ディープラーニングメソッドは、大量の注釈付きデータに大きく依存します。これは時間がかかり、コストがかかります。ロームは、これまでにないデータポイントをより多く生成するため、過剰適合を回避し、一般化機能を強化します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-20">
        <br><font color="black">2020-03-20</font>
      </time>
    </span>
</section>
<!-- paper0: Post-Comparison Mitigation of Demographic Bias in Face Recognition Using
  Fair Score Normalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_14.html">
      <font color="black">Post-Comparison Mitigation of Demographic Bias in Face Recognition Using
  Fair Score Normalization</font>
    </a>
  </h2>
  <font color="black">性別を考慮した場合、最大82.7％です。私たちの仮説は、同様の個人を同様に扱うことにつながる正規化アプローチを設計することにより、個人の公平性の表記に基づいて構築されています。 
[ABSTRACT]以前の作品は主に偏った顔の表現の学習に焦点を当てていました。これにより、全体的な認識パフォーマンスが大幅に低下するリスクが軽減されますが、新しいシステムは偏見をより一貫して軽減します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-10">
        <br><font color="black">2020-02-10</font>
      </time>
    </span>
</section>
<!-- paper0: Contextual Encoder-Decoder Network for Visual Saliency Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_15.html">
      <font color="black">Contextual Encoder-Decoder Network for Visual Saliency Prediction</font>
    </a>
  </h2>
  <font color="black">アーキテクチャは、エンコーダー/デコーダー構造を形成し、マルチスケール機能を並行してキャプチャするために、異なる拡張レートで複数の畳み込み層を備えたモジュールを含みます。私たちのモデルは、2つの公開顕著性ベンチマークの複数の評価指標にわたって競争力のある一貫した結果を達成し、 5つのデータセットと選択された例に対する提案されたアプローチの有効性。ただし、人間の凝視マップを説明することを目的とした既存のモデルには、そのようなメカニズムが明示的に組み込まれていません。 
[要約]システムは、大規模な画像分類タスクで事前トレーニングされた畳み込みニューラルネットワークに基づいています。結果の表現をグローバルシーン情報と組み合わせて、視覚的顕著性を正確に予測します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-02-18">
        <br><font color="black">2019-02-18</font>
      </time>
    </span>
</section>
<!-- paper0: Lossless CNN Channel Pruning via Gradient Resetting and Convolutional
  Re-parameterization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_16.html">
      <font color="black">Lossless CNN Channel Pruning via Gradient Resetting and Convolutional
  Re-parameterization</font>
    </a>
  </h2>
  <font color="black">記憶と忘却の独立性に関する神経生物学の研究に触発されて、CNNを記憶パラメータと忘却部分に再パラメーター化することを提案します。 ImageNetで76.15 \％のトップ1の精度を持つ標準のResNet-50を、43.9 \％FLOPsのみで精度の低下のないより狭いものにスリム化できます。後者のペナルティグラディエントでルールを更新すると、構造化されたスパース性が実現され、再パラメーター化されたモデルをより狭いレイヤーの元のアーキテクチャに同等に変換できるようになります。 
[ABSTRACT] `filter pruning &#39;は、畳み込みニューラルネットワーク（cnn）をスリム化することを目的としています。それは、畳み込み層の幅（つまり、出力チャネルの数）を減らすことを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Learning and Reasoning with the Graph Structure Representation in
  Robotic Surgery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_17.html">
      <font color="black">Learning and Reasoning with the Graph Structure Representation in
  Robotic Surgery</font>
    </a>
  </h2>
  <font color="black">グラフシーンラベルを取得するには、ロボットシーンのセグメンテーションチャレンジ2018データセットのバウンディングボックスと機器とROIの相互作用にロボット手術の経験豊富な臨床専門家に注釈を付け、それを使用して命題を評価します。注意リンク機能を設計し、グラフの解析ネットワークと統合して、外科的相互作用を認識します。ハードラベルを平滑化すると、モデルの予測の過剰な予測を回避でき、最後から2番目のレイヤーによって学習された特徴表現を強化できます。 
[要旨]シーングラフを生成して、ロボット支援手術中に器具と手術対象領域（roi）の間の手術の相互作用を予測するアプローチを開発します。各ノードを対応する隣接する設計設計に埋め込むために、ネットワークにsageconvをさらに組み込みました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Diverse and Styled Image Captioning Using SVD-Based Mixture of Recurrent
  Experts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_18.html">
      <font color="black">Diverse and Styled Image Captioning Using SVD-Based Mixture of Recurrent
  Experts</font>
    </a>
  </h2>
  <font color="black">提案されたキャプションモデルは、追加のラベル付けを必要とせずに、多様で様式化された画像キャプションを生成できることを示しています。さらに、スタイル付きおよび多様なキャプションは、密にラベル付けされたまたはスタイル付きのデータセットでトレーニングせずに抽出されます。結果には、より良い説明も表示されますコンテンツの正確さの点で。 
[ABSTRACT]新しいトレーニングアルゴリズムによって作成された結果システムは、キャプションを組み合わせます。このモデルは、標準の事実に基づく画像キャプションデータセットに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Single Shot Video Object Detector -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_19.html">
      <font color="black">Single Shot Video Object Detector</font>
    </a>
  </h2>
  <font color="black">技術的には、SSVDはFeature Pyramid Network（FPN）をバックボーンネットワークとして使用して、マルチスケール機能を生成します。既存の機能集約方法とは異なり、SSVDは、一方でモーションを推定し、モーションパスに沿って、およびその他、2つのストリーム構造で隣接するフレームから特徴を直接サンプリングすることで特徴を幻覚化します。具体的には、シングルショットビデオオブジェクト検出器（SSVD）を提示します。これは、特徴の集約をオブジェクトの1ステージ検出器に新しく統合する新しいアーキテクチャです。ビデオでの検出。 
[ABSTRACT]シングルショットビデオオブジェクト検出器（ssvd）は、ビデオ内のオブジェクト検出のために機能を1ステージ検出器に統合する新しいアーキテクチャです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Can GAN Generated Morphs Threaten Face Recognition Systems Equally as
  Landmark Based Morphs? -- Vulnerability and Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_20.html">
      <font color="black">Can GAN Generated Morphs Threaten Face Recognition Systems Equally as
  Landmark Based Morphs? -- Vulnerability and Detection</font>
    </a>
  </h2>
  <font color="black">顔モーフィングの主な目的は、さまざまなデータ主体の顔画像を組み合わせることです（たとえば、新しく作成された2500のモーフィング顔画像のモーフィングデータセットを使用して、この作業で重要な質問を投げかけます。回答を求めて、市販のFRS（COTS）とディープラーニングベースのFRS（ArcFace）。この作業では、確立されたモーフィング攻撃検出スキームを使用して、ガン生成モーフとランドマークベースのモーフの両方の検出アプローチのベンチマークも行います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Spectral Graph-based Features for Recognition of Handwritten Characters:
  A Case Study on Handwritten Devanagari Numerals -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_21.html">
      <font color="black">Spectral Graph-based Features for Recognition of Handwritten Characters:
  A Case Study on Handwritten Devanagari Numerals</font>
    </a>
  </h2>
  <font color="black">提案された方法の有効性を裏付けるために、標準的な手書き数字のコンピュータビジョンパターン認識、インド統計研究所のコルカタデータセットの単位で大規模な実験が行われました。手書き文字に関する既存の研究は広範ですが、特徴空間における文字の効果的な表現。実験結果は、将来の研究で使用できる有望な発見を示しています。 
[要約]研究は、コルカタ、コルカタの研究者によって実行されました。これらは、手書き文字を特徴付け、効果的に表現するアプローチを提案しています。この結果は、将来の研究で使用できる有望な結果を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchical nucleation in deep neural networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_22.html">
      <font color="black">Hierarchical nucleation in deep neural networks</font>
    </a>
  </h2>
  <font color="black">このプロセスにより、出力層の確率密度にフットプリントが残り、ピークのトポグラフィーにより、カテゴリーの意味的関係を再構築できます。その後の層では、概念の意味的階層を反映する階層的な方法で密度ピークが発生します。密度単一のカテゴリーに対応するピークは、出力の近くにのみ現れ、不均一な液体の核生成プロセスに似た非常に鋭い遷移を介して現れます。 
[要約]密度とそれらがどのように生成されるかを理解することは、実用的かつ理論的に興味深いものです。この研究では、初期層が意味論的なビットを生成することがわかりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Generate Novel Domains for Domain Generalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_23.html">
      <font color="black">Learning to Generate Novel Domains for Domain Generalization</font>
    </a>
  </h2>
  <font color="black">ジェネレーターをトレーニングするために、最適なトランスポートを使用して、ソースと合成された疑似小説ドメイン間の分散のダイバージェンスをモデル化し、ダイバージェンスを最大化します。 4つのベンチマークデータセットでのアートDGメソッド。.合成データでセマンティクスが保持されることを保証するために、ジェネレータにサイクルの一貫性と分類の損失を課します。 
[ABSTRACT]利用可能なソースドメインは多くの場合、限られた多様性を示します。これにより、利用可能なトレーニングドメインの多様性が明確に増加します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Ischemic Stroke Lesion Segmentation from Computed Tomography
  Perfusion Images by Image Synthesis and Attention-Based Deep Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_24.html">
      <font color="black">Automatic Ischemic Stroke Lesion Segmentation from Computed Tomography
  Perfusion Images by Image Synthesis and Attention-Based Deep Neural Networks</font>
    </a>
  </h2>
  <font color="black">最初に、特徴抽出器を使用して、生の時空間コンピュータ断層撮影血管造影（CTA）画像の低レベルと高レベルの両方のコンパクトな表現を取得します。コンピュータ断層撮影灌流（CTP）画像からの虚血性脳卒中病変セグメンテーションは、正確な診断に重要です急性期治療室における脳卒中の発生。.より良い合成品質を達成するために、病変領域により注意を払い、高レベルのコンテキストの一貫性を促進するハイブリッド損失関数を提案します。 
[ABSTRACT]病変領域は疑似dwiジェネレーターによってマップされます。これは畳み込みニューラルネットワークに基づいており、それを利用するようにトレーニングされています。これらのコンポーネントが開発されたのはこれが初めてです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: MetricUNet: Synergistic Image- and Voxel-Level Learning for Precise CT
  Prostate Segmentation via Online Sampling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_25.html">
      <font color="black">MetricUNet: Synergistic Image- and Voxel-Level Learning for Precise CT
  Prostate Segmentation via Online Sampling</font>
    </a>
  </h2>
  <font color="black">ただし、従来のFCNは通常、クロスエントロピーまたはダイス損失によってトレーニングされ、ピクセルの予測とグラウンドトゥルースラベル間の誤差のみを個別に計算します。最近の研究におけるセマンティックセグメンテーションのアーキテクチャ。これにより、予測されたセグメンテーションで近隣が滑らかでないことがよくあります。 
[要約]提案されたネットワークには、2つのタスクに取り組むデュアルブランチアーキテクチャがあります。これらには、前立腺のセグメンテーションを生成することを目的としたボクセルネットワークと、ボクセル、メトリック学習サブネットワークが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-15">
        <br><font color="black">2020-05-15</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Model-Blind Temporal Denoisers without Ground Truths -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_26.html">
      <font color="black">Learning Model-Blind Temporal Denoisers without Ground Truths</font>
    </a>
  </h2>
  <font color="black">オンラインのノイズ除去スキームとワーピングロス正則化を使用して、時間的アライメントを改善します。照明のばらつきは、アライメントされたフレームの局所的な類似性に基づいて定量化されます。この手法は、複数のノイズ、データセット、およびネットワークアーキテクチャ。 
[ABSTRACT]新しい方法は、ビデオのノイズ除去器に直接適用すると、ノイズの過剰適合につながります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Convolutional Neural Network for Identifying Seam-Carving Forgery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_27.html">
      <font color="black">Deep Convolutional Neural Network for Identifying Seam-Carving Forgery</font>
    </a>
  </h2>
  <font color="black">低レベルの機能を学習する機能を実現するために、微妙な信号のキャプチャに特化した5種類のネットワークブロックで構成されるCNNアーキテクチャを設計しました。ベースラインと比較して、私たちの作業は、3つの観点から最先端のパフォーマンスを発揮します。クラス分類（オリジナル、シーム挿入、およびシーム除去）。作業の効果を検証するために、さまざまなCNNベースのベースラインに基づいた大規模な実験が行われました。 
[ABSTRACT]シーム-カービングアルゴリズムは、定義されたコスト関数に従って、シームと呼ばれるピクセルの接続パスを計算します。次に、繰り返し計算されるシームを削除して複製することにより、画像のサイズを調整します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-05">
        <br><font color="black">2020-07-05</font>
      </time>
    </span>
</section>
<!-- paper0: Optical Navigation in Unstructured Dynamic Railroad Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_28.html">
      <font color="black">Optical Navigation in Unstructured Dynamic Railroad Environments</font>
    </a>
  </h2>
  <font color="black">このアプローチは、高価な列車管理インフラストラクチャをSmartRail 4.0の列車のローカルインテリジェンスに置き換えるステップです。列車の運用中に時折発生する重大なオクルージョンにより、追跡が困難な反復的な領域に利用可能な観測が制限されます。この困難な環境での並進と回転のロバストな推定のための私たちのアプローチと、実際の鉄道シナリオでのアプローチの実験的検証を提供します。 
[要約]列車の動きの推定に対処する方法を提案します。このアプローチは、高価な列車管理インフラストラクチャを列車のローカルインテリジェンスに置き換えるためのステップです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: GOLD-NAS: Gradual, One-Level, Differentiable -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_29.html">
      <font color="black">GOLD-NAS: Gradual, One-Level, Differentiable</font>
    </a>
  </h2>
  <font color="black">標準の画像分類ベンチマークでは、GOLD-NASは単一の検索手順内で一連のパレート最適アーキテクチャを見つけることができます。新しい空間と検索アルゴリズムは、差別化可能なNASの検索を向上させることができると考えています。発見されたアーキテクチャのほとんどは研究されていません以前は、認識精度とモデルの複雑さの間で適切なトレードオフを実現していました。 
[要約]新しい論文では、手動で設計された制約を緩和し、100億ドルを超える候補を含むように検索スペースを拡大しています。さらに、段階的1レベル微分可能ニューラルアーキテクチャ検索と呼ばれる新しいアルゴリズムを提案しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Re-thinking Co-Salient Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_30.html">
      <font color="black">Re-thinking Co-Salient Object Detection</font>
    </a>
  </h2>
  <font color="black">最後に、CoSODの課題と今後の取り組みについて説明します。3番目に、34の最先端のアルゴリズムを包括的に要約し、そのうちの16を3つの挑戦的なCoSODデータセット（iCoSeg、CoSal2015、およびCoSOD3k）でベンチマークし、さらに詳細なレポート（つまり、グループレベル）パフォーマンス分析..私たちの研究がCoSODコミュニティの成長を強力に後押しすることを願っています
[ABSTRACT] cosodは、顕著オブジェクト検出（sod）の新興で急速に成長している拡張であり、co- images.cosodのグループで発生する顕著なオブジェクトには、3、316、高品質、精巧に選択された画像が160グループに分けられます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Location Sensitive Image Retrieval and Tagging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_31.html">
      <font color="black">Location Sensitive Image Retrieval and Tagging</font>
    </a>
  </h2>
  <font color="black">LocSensは、マルチモーダルクエリのテキスト情報と場所情報を融合して、場所の粒度のさまざまなレベルで関連画像を取得し、場所情報をうまく活用して画像のタグ付けを改善します。地球のさまざまな部分の人々が、オブジェクトと概念を異なる方法で説明しています。 LocSensは、画像、タグ、座標のトリプレットを妥当性によってランク付けすることを学習するモデルと、最終的なランク付けにおける位置の影響のバランスをとる2つのトレーニング戦略を提示します。 
[ABSTRACT] locsensは、妥当性によって画像、タグ、座標のトリプレットをランク付けすることを学習するモデルです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchical and Unsupervised Graph Representation Learning with
  Loukas's Coarsening -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_32.html">
      <font color="black">Hierarchical and Unsupervised Graph Representation Learning with
  Loukas's Coarsening</font>
    </a>
  </h2>
  <font color="black">強力な理論的保証を備えた粗大化法と相互情報の最大化を組み合わせることで、高品質の埋め込みを生成するのに十分であることを示します。分類タスクでこれらを評価し、文献の一般的なベンチマークを使用します。このアルゴリズムは、最先端のアルゴリズムと競合することを示しています。教師なしグラフ表現学習方法。 
[ABSTRACT]このメソッドはディープラーニングパイプラインにプラグインでき、バックコミュニケーションを可能にします。共通のベンチマークを使用して分類タスクで評価します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: SaADB: A Self-attention Guided ADB Network for Person Re-identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_33.html">
      <font color="black">SaADB: A Self-attention Guided ADB Network for Person Re-identification</font>
    </a>
  </h2>
  <font color="black">この論文では、最も特徴的な領域を\ textbf {適応的に}消去できる人物再IDのための新しい自己注意誘導適応型DropBlockネットワーク（SaADB）を提案します。次に、入力機能と自己注意誘導ドロップマスクは乗算されて、ドロップされた機能マップが生成されます。具体的には、SaADBはまずチャネルごとのプーリングによって自己注意マップを取得し、自己注意マップをしきい値処理することによってドロップマスクを返します。 
[ABSTRACT] bdbは、次善の結果につながる可能性がある機能を削除します。bdb-bdb-deir bdb（bdb）の機能を削除できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Instance Segmentation for Whole Slide Imaging: End-to-End or
  Detect-Then-Segment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_34.html">
      <font color="black">Instance Segmentation for Whole Slide Imaging: End-to-End or
  Detect-Then-Segment</font>
    </a>
  </h2>
  <font color="black">Detect-then-segmentパイプラインは、End-to-Endメソッドと比較してより優れたセグメンテーションパフォーマンスを達成しました。512x512解像度の以前に検出された糸球体で動作するDeepLab_v3セグメンテーションフレームワークを備えた当社の検出-then-segmentパイプラインは、0.953のダイス類似係数（DSC）を達成しました）、エンドツーエンドのMask-RCNNパイプラインからの0.902 DSCと比較します。ただし、高解像度のWSIでは、単一の糸球体自体が元の解像度で1,000x1,000ピクセルを超える可能性があり、対応する機能マップは、Mask-RCNNパイプラインを介してダウンサンプリングされます。 
[ABSTRACT]高解像度wsiでは、単一の糸球体が元の解像度で1,00x1,00ピクセルを超えることがあります。これは、1,00x1,00ピクセルを超える単一の糸球体と比較できますが、高解像度のイメージングでは、糸球体は1,00x1、000ピクセルを超える可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Are spoofs from latent fingerprints a real threat for the best
  state-of-art liveness detectors? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_35.html">
      <font color="black">Are spoofs from latent fingerprints a real threat for the best
  state-of-art liveness detectors?</font>
    </a>
  </h2>
  <font color="black">スナップショット写真を撮ることは、磁性粉によって表面に残った指紋を作成し、テープでトレースを持ち上げることよりもはるかに簡単です。これは注目すべき結果であり、以前の研究では報告されていませんでした。このために、小説を収集しました潜在的な指紋のスナップショット写真を使用して作成されたライブおよびスプーフィング画像のデータセット。 
[ABSTRACT]この種の攻撃が脅威と見なすことができる暫定的なもの。これらには、指紋活性検出器と検証システムが含まれます。最も好ましい条件でのこの攻撃のデータセット</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Interpretable End-to-end Urban Autonomous Driving with Latent Deep
  Reinforcement Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_36.html">
      <font color="black">Interpretable End-to-end Urban Autonomous Driving with Latent Deep
  Reinforcement Learning</font>
    </a>
  </h2>
  <font color="black">CARLAでシミュレートされた自動運転車との比較テストは、混雑した周辺車両による都市シナリオでの私たちの方法のパフォーマンスが、DQN、DDPG、TD3、SACなどの多くのベースラインを支配することを示しています。プロセス..潜在空間は、強化学習のサンプルの複雑さも大幅に減らします。 
[要約]統合された潜在環境モデルが導入され、進化プロセスと一緒に学習されます。潜在空間は、自動運転の導入に適応する機会も大幅に減らします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-23">
        <br><font color="black">2020-01-23</font>
      </time>
    </span>
</section>
<!-- paper0: Point Proposal Network for Reconstructing 3D Particle Endpoints with
  Sub-Pixel Precision in Liquid Argon Time Projection Chambers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_37.html">
      <font color="black">Point Proposal Network for Reconstructing 3D Particle Endpoints with
  Sub-Pixel Precision in Liquid Argon Time Projection Chambers</font>
    </a>
  </h2>
  <font color="black">ボクセル解像度が3mm /ボクセルであるPILArNetパブリックLArTPCデータサンプルをベンチマークとして使用して、このアルゴリズムは、提供された実際のポイント位置からそれぞれ3および10〜ボクセルの距離内にある3Dポイントの96.8％および97.8％を正常に予測しました。さらに、これらの予測ポイントを使用して、3Dボクセルを個々のトラックのような粒子軌道にクラスター化する簡単なアルゴリズムを示します。クラスタリングの効率、純度、および調整後のランダムインデックスはそれぞれ96％、93％、91％です。最も近い真のポイント位置の3つのボクセル内の3Dポイント、距離の中央値は0.25ボクセルであることがわかり、サブボクセルレベルの精度を実現します。 
[要約]このプロジェクトは、粒子を識別および分析するように設計されています。また、識別された関心のあるポイントのカテゴリを決定します。サブボクセルの精度を使用して、中央距離は0であることがわかります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-26">
        <br><font color="black">2020-06-26</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Trajectory Dependencies for Human Motion Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_38.html">
      <font color="black">Learning Trajectory Dependencies for Human Motion Prediction</font>
    </a>
  </h2>
  <font color="black">事前定義されたグラフ構造を使用する代わりに、新しいグラフ畳み込みネットワークを設計して、グラフの接続性を自動的に学習します。コードはhttps://github.com/wei-mao-2019/LearnTrajDepで入手できます。これにより、時間依存性の範囲（または前の作業で行ったような時間畳み込みフィルターサイズ）を手動で定義する必要がなくなります。 
[ABSTRACT]結果のrnnモデルは予測エラーの累積に悩まされ、モーション予測に望ましくない不連続性をもたらします。これにより、ネットワークは人間のポーズの範囲を超えた長期の依存関係をキャプチャできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-15">
        <br><font color="black">2019-08-15</font>
      </time>
    </span>
</section>
<!-- paper0: Counterfactual Vision-and-Language Navigation via Adversarial Path
  Sampling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_39.html">
      <font color="black">Counterfactual Vision-and-Language Navigation via Adversarial Path
  Sampling</font>
    </a>
  </h2>
  <font color="black">結果は、提案されたAPSを使用した敵対的なトレーニングプロセスが、目に見える環境と目に見えない環境の両方でVLNモデルに利益をもたらすことを示しています。低品質の拡張データの代わりに効果的な条件を検討できる敵対主導の反事実推論モデルを提案します。探査プロセスは、目に見えない環境下でさらに改善を得ることができます。 
[要約] vlnタスクは、人間による十分なナビゲーションパスを収集することが困難です-インタラクティブな環境のための注釈付きの指示。特に、ナビゲーションパフォーマンスに基づいてナビゲーターを改善するように強制する困難なパスのサンプルを学習するモデルに到達します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-17">
        <br><font color="black">2019-11-17</font>
      </time>
    </span>
</section>
<!-- paper0: NuClick: A Deep Learning Framework for Interactive Segmentation of
  Microscopy Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_40.html">
      <font color="black">NuClick: A Deep Learning Framework for Interactive Segmentation of
  Microscopy Images</font>
    </a>
  </h2>
  <font color="black">組織学および細胞学の画像の核と細胞については、各オブジェクト内の1回のクリックでNuClickが正確な注釈を生成するのに十分であることを示しています。ラベル付きデータの収集は、特にラベルが1人以上の専門家による時間のかかる分析の結果である医療画像分野では、専門家の知識を必要とすることが多いため、費用がかかります。 
[要約]この論文では、各オブジェクトの注釈の収集を高速化するためのシンプルなcnnベースのアプローチを提案します。腺などの多細胞構造の場合、波形信号を誘導信号として提供し、腺の境界をセグメント化できるようにします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-29">
        <br><font color="black">2020-05-29</font>
      </time>
    </span>
</section>
<!-- paper0: Monitoring Browsing Behavior of Customers in Retail Stores via RFID
  Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_41.html">
      <font color="black">Monitoring Browsing Behavior of Customers in Retail Stores via RFID
  Imaging</font>
    </a>
  </h2>
  <font color="black">TagSeeは、顧客が棚のアイテムを閲覧しているときに、棚の境界に沿って配置されたタグとリーダーの間に立っているという洞察に基づいています。これにより、RFID信号が通るマルチパスと両方のRSSが変更されます。リーダーが受け取るRFID信号の位相値と位相値が変化します。このホワイトペーパーでは、市販の（COTS）モノスタティックRFIDデバイスを使用することを提案します（つまり、この目的のために、多人数の画像処理であるTagSeeを提案します。モノスタティックRFIDイメージングに基づくシステムです。
[要約] tagseeは、顧客が棚のアイテムを閲覧しているときに、棚の境界に沿って配置されたタグとリーダーの間に立っているという洞察に基づいています。これらは、マルチパスを変更しますrfid信号はに沿って進み、リーダーのrss値と位相値の両方が変化を受け取ります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: RIFLE: Backpropagation in Depth for Deep Transfer Learning through
  Re-Initializing the Fully-connected LayEr -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_42.html">
      <font color="black">RIFLE: Backpropagation in Depth for Deep Transfer Learning through
  Re-Initializing the Fully-connected LayEr</font>
    </a>
  </h2>
  <font color="black">事前トレーニング済みモデルを使用してディープコンボリューションニューラルネットワーク（CNN）を微調整すると、大規模なデータセットから学習した知識をターゲットタスクに転送できます。この作業では、転送学習設定での逆伝播を深める、シンプルで効果的な戦略であるRIFLEを提案します。 、完全に調整されたレイヤーを定期的に再初期化することにより、微調整手順中にランダムなスクラッチを使用します。RIFLEは、深いCNNレイヤーの重みに意味のある更新をもたらし、低レベルの機能学習を改善しますが、ランダム化の効果は簡単に収束できます。全体的な学習手順全体。 
[ABSTRACT]ライフルは、深いCNNレイヤーの重みに意味のある更新をもたらします。ここでのバックプロパゲーションは、深い更新を小さなCNNレイヤーにもたらします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Calibrated BatchNorm: Improving Robustness Against Noisy Weights in
  Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_43.html">
      <font color="black">Calibrated BatchNorm: Improving Robustness Against Noisy Weights in
  Neural Networks</font>
    </a>
  </h2>
  <font color="black">ノイズの属性を事前に知る必要がなく、私たちのアプローチは、アナログ環境に固有の変動ノイズの下でアクティベーションの分布を調整することができます。結果は、ノイズにとらわれない堅牢なネットワークを実現し、開発を進める効果を示しています。ニューラルネットワークの分野におけるアナログコンピューティングデバイス。このホワイトペーパーでは、バッチ正規化層の統計を再計算して、推論フェーズ中に偏った分布を較正することを提案します。 
[要約]論文では、バッチ正規化層の統計を再計算して、尤度フェーズ中に偏った変動を較正することを提案しています。仮定を検証するために、定量的な実験を行い、いくつかのコンピュータービジョンタスクに方法を適用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: See, Hear, Explore: Curiosity via Audio-Visual Association -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_44.html">
      <font color="black">See, Hear, Explore: Curiosity via Audio-Visual Association</font>
    </a>
  </h2>
  <font color="black">いくつかのAtari環境とハビタット（写実的なナビゲーションシミュレーター）で結果を提示し、外部の報酬がない場合に本質的に学習エージェントをガイドするための視聴覚関連モデルを使用する利点を示します。しかし、将来の予測は本質的に難しい作業です私たちのアプローチは、複数のモダリティを利用して、より効率的な探索のためのより強力な信号を提供します。 
[要約]この方法は、人間にとって視覚と音の両方が探索において重要な役割を果たすという事実に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Rethinking Bottleneck Structure for Efficient Mobile Network Design -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_45.html">
      <font color="black">Rethinking Bottleneck Structure for Efficient Mobile Network Design</font>
    </a>
  </h2>
  <font color="black">Pascal VOC 2007テストセットでは、オブジェクト検出で0.9％のmAP改善も見られます。広範な実験により、一般的な考えとは異なり、このようなボトルネック構造は、モバイルネットワークの逆のものよりも有益であることがわかります。 2つのデザインルールを導入することによる古典的な残差ボトルネック：反転残差の学習と線形ボトルネックの使用。 
[ABSTRACT]デザインは、2つのデザインルールを導入することで従来の残差ボトルネックを変更します。反転残差の学習と線形ボトルネックの使用。imagenet分類では、反転残差ブロックをOurcテストに置き換えるだけで、分類精度を1以上に設定できます。 7 ％</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-05">
        <br><font color="black">2020-07-05</font>
      </time>
    </span>
</section>
<!-- paper0: Self domain adapted network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_46.html">
      <font color="black">Self domain adapted network</font>
    </a>
  </h2>
  <font color="black">ただし、各ターゲットドメインのモデルのトレーニングは時間がかかり、計算コストが高く、ターゲットドメインのデータが不足している場合や、データのプライバシーのためにソースデータが利用できない場合でも実行不可能です。このホワイトペーパーでは、新しい自己ドメイン適応ネットワーク（SDA-ネット）追加のデータを使用したり、UDAモデルをトレーニングしたりせずに、テスト段階で単一の被験者にすばやく適応できます。ドメインシフトは、臨床診療で深いネットワークを展開するための主要な問題です。 
[ABSTRACT]（ターゲット）画像が（ソース）トレーニングデータとは異なる方法で取得すると、ネットワークパフォーマンスが大幅に低下します。現在のudaメソッドでは、画像変換（調和）またはドメイン固定機能を学習するモデルをトレーニングするために、ソースデータとターゲットデータの両方が必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: DAM: Deliberation, Abandon and Memory Networks for Generating Detailed
  and Non-repetitive Responses in Visual Dialogue -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_47.html">
      <font color="black">DAM: Deliberation, Abandon and Memory Networks for Generating Detailed
  and Non-repetitive Responses in Visual Dialogue</font>
    </a>
  </h2>
  <font color="black">さらに、DAMは既存のビジュアルダイアログエンコーダーと柔軟に連携し、DAMの情報選択モードを制限することでエンコーダー構造に適応します。実験結果は、提案されたモデルが高品質の応答で新しい最先端のパフォーマンスを実現することを示しています。 ..各DAMモジュールは、エンコーダーから取得した応答レベルのセマンティクスと、各ワードを生成するために特別に選択されたワードレベルのセマンティクスの適応的な組み合わせを実行します。 
[ABSTRACT]ダムは、詳細で非反復的な対話を作成するために視覚的応答を必要とします。これは、視覚的応答が視覚的視覚情報に基づいている方法を説明しています。ダムは、一連の注意に基づいています-情報選択ステップに基づいています。再発審議・放棄・記憶（ダム）モジュール</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-Supervised Crowd Counting via Self-Training on Surrogate Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_48.html">
      <font color="black">Semi-Supervised Crowd Counting via Self-Training on Surrogate Tasks</font>
    </a>
  </h2>
  <font color="black">具体的には、2つの革新的なコンポーネントに基づいて構築された新規の半教師付き群衆カウント方法を提案しました。（1）一連の相互関連バイナリセグメンテーションタスクは、代理予測ターゲットとして元の密度マップ回帰タスクから導出されます。 （2）サロゲートターゲット予測子は、これらのバイナリセグメンテーションタスクの根本的な制約を完全に活用する提案されたセルフトレーニングスキームを利用することにより、ラベル付きデータとラベルなしデータの両方から学習されます。この設計の根拠は、特徴抽出器の学習がより多くなる可能性があるということです。ラベル付けされていないデータから生成された不可避のノイズの多い監督に対して信頼性が高く堅牢です。このペーパーでは、特徴学習の観点から半教師付きの群集カウント問題に取り組みます。 
[要約]提案された方法は、既存の半教師ありの群集カウント方法より優れています。群衆カウンターのネットワーク全体ではなく、一般的な特徴抽出器をトレーニングするために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: GIQA: Generated Image Quality Assessment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_49.html">
      <font color="black">GIQA: Generated Image Quality Assessment</font>
    </a>
  </h2>
  <font color="black">さらに、GIQAは、生成モデルのリアリズムと多様性を個別に評価し、GANのトレーニングでオンラインハードネガティブマイニング（OHEM）を有効にして結果を改善するなど、多くのアプリケーションで利用できます。さまざまなデータセットのGANモデルを使用して、それらが人間の評価と一致していることを示します。学習ベースとデータベースの2つの観点から、3つのGIQAアルゴリズムを紹介します。 
[要約]最近、トピックに対していくつかの定量的基準が浮上しましたが、それらのどれも定量的画像用に設計されていません。これには、学習ベースとデータベースが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-19">
        <br><font color="black">2020-03-19</font>
      </time>
    </span>
</section>
<!-- paper0: Discretization-Aware Architecture Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_50.html">
      <font color="black">Discretization-Aware Architecture Search</font>
    </a>
  </h2>
  <font color="black">操作またはエッジのいずれかで実行される離散化プロセスでは、重大な不正確さが発生するため、最終的なアーキテクチャの品質は保証されません。スーパーネットワークを目的のトポロジーの構成に向けてプッシュするための損失項を追加します。これにより、離散化による精度の損失が大幅に軽減されます。}、弱い候補を切り捨てます。 
[ABSTRACT]これらの方法は、可能なすべてのエッジと操作を使用してスーパーネットワークを最適化し、離散化によって最適なサブネットワークを決定します。操作またはエッジのいずれかで実行される離散化プロセスでは、重大な不正確さが発生します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Multimodal Representations for Unseen Activities -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_51.html">
      <font color="black">Learning Multimodal Representations for Unseen Activities</font>
    </a>
  </h2>
  <font color="black">公開されているデータセットでのテストに加えて、新しい大規模なテキスト/ビデオデータセットを導入します。また、対をなす定式化を使用して結合埋め込みスペースを改善し、ペアになっていないテキストおよびビデオデータからメリットを得られる方法を提案します。ペア化されたデータとペア化されていないデータを使用して共有埋め込みスペースを学習すると、3つの困難なタスク（i）ゼロショットアクティビティ分類、（ii）教師なしアクティビティの発見、（iii）目に見えないアクティビティキャプション、および美術。 
[ABSTRACT]ペア化されたデータとペア化されていないデータを使用して、目に見えないアクティビティをより適切にキャプチャする表現を学習する能力を示します。共有の埋め込みスペースを学習する方法は、3つの難しいタスクに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-06-21">
        <br><font color="black">2018-06-21</font>
      </time>
    </span>
</section>
<!-- paper0: Building Computationally Efficient and Well-Generalizing Person
  Re-Identification Models with Metric Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_52.html">
      <font color="black">Building Computationally Efficient and Well-Generalizing Person
  Re-Identification Models with Metric Learning</font>
    </a>
  </h2>
  <font color="black">計量学習の目的、つまりAM-Softmax損失と、いくつかの追加のトレーニングプラクティスを使用して、一般化されているが計算効率の高いモデルを構築することを提案します。最近提案されたOmni-Scale Network（OSNet）アーキテクチャをいくつかのトレーニングトリックと組み合わせて使用します3つの設定で大規模なMSMT17データセットのクロスドメイン一般化問題を引き起こす最先端の結果を得るためのアーキテクチャ調整：MSMT17-all-&gt; DukeMTMC、MSMT17-train-&gt; Market1501およびMSMT17-all-&gt; Market1501。 。このギャップの一部は、（たとえば、顔認識のデータセットと比較して）比較的小規模の個人再識別データセットが原因ですが、トレーニングの目的にも関連しています。 
[ABSTRACT] re-識別データセットは学習およびトレーニングの目標とは関係ありません。データセットはより大規模に基づいていますが、トレーニングの目標と関係があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-17">
        <br><font color="black">2020-03-17</font>
      </time>
    </span>
</section>
<!-- paper0: Real-MFF: A Large Realistic Multi-focus Image Dataset with Ground Truth -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_53.html">
      <font color="black">Real-MFF: A Large Realistic Multi-focus Image Dataset with Ground Truth</font>
    </a>
  </h2>
  <font color="black">さらに、適切なデータセットなしでマルチフォーカス画像融合のためのディープニューラルネットワークをトレーニングすることは困難です。また、説明のために、このデータセットに対して10の典型的なマルチフォーカスアルゴリズムを評価します。データセットはライトフィールドイメージによって生成されます、およびソース画像とグラウンドトゥルース画像の両方が現実的です。 
[ABSTRACT] real-mffには、対応するグラウンドトゥルースイメージを含む710ペアのソースイメージが含まれています。データセットには、建物、植物、人間、ショッピングモール、広場など、さまざまなシーンが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-28">
        <br><font color="black">2020-03-28</font>
      </time>
    </span>
</section>
<!-- paper0: STAGE: Spatio-Temporal Attention on Graph Entities for Video Action
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_54.html">
      <font color="black">STAGE: Spatio-Temporal Attention on Graph Entities for Video Action
  Detection</font>
    </a>
  </h2>
  <font color="black">さらに、複数のGPUでのエンドツーエンドの同期トレーニングを必要とする最新モデルに匹敵するパフォーマンスを実現できます。コードは、https：//github.com/aimagelab/で公開されています。 STAGE_action_detection .. AVAデータセットでテストすると、ベースラインに対して10〜16％の相対的なmAPの改善を示しています。 
[要約]ビデオ理解モジュールは、空間と時間における俳優とオブジェクト間の相互作用をエンコードできます。このタスクでは、グラフ接続の使用は前例のないものです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-09">
        <br><font color="black">2019-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic lesion detection, segmentation and characterization via 3D
  multiscale morphological sifting in breast MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_55.html">
      <font color="black">Automatic lesion detection, segmentation and characterization via 3D
  multiscale morphological sifting in breast MRI</font>
    </a>
  </h2>
  <font color="black">同じ乳房MRIデータセットで評価された以前に提案されたシステムと比較して、提案されたCADシステムは、乳房病変の検出と特性評価において好ましいパフォーマンスを達成します。4D乳房磁気共鳴画像（MRI）に関するコンピューター支援検出/診断（CAD）に関するこれまでの研究病変の検出、セグメンテーション、特徴付けを個別のタスクとして行い、通常、ユーザーは入力として2D MRIスライスまたは関心領域を手動で選択する必要があります。提案されたCADシステムは、領域候補の生成、特徴抽出、領域候補の分類という3つの主要な段階で構成されています。 
[ABSTRACT]提案されたCADシステムは、4Dマルチモーダル乳房MRIデータを処理できます。これらには、ユーザーの介入なしで病変検出とセグメンテーションが含まれます。提案されたシステムは、真陽性率（tpr）が3.90で3.90を達成します。 ）病変検出用</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Imitation Learning Approach for AI Driving Olympics Trained on
  Real-world and Simulation Data Simultaneously -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_56.html">
      <font color="black">Imitation Learning Approach for AI Driving Olympics Trained on
  Real-world and Simulation Data Simultaneously</font>
    </a>
  </h2>
  <font color="black">コンテスト中に参加者が遭遇する主な問題の1つは、シミュレーション環境で最高のパフォーマンスを得るためにトレーニングされたアルゴリズムが実際の環境では成り立たないこと、およびその逆です。この問題を克服するために、模倣学習アルゴリズムを採用し、トレーニングされたシミュレーションと実世界の両方からソースから収集されたデータセットに基づいて、モデルをすべての環境で同等に実行するように強制します。このホワイトペーパーでは、AIドライビングオリンピックコンテストでの模倣を通じてレーン追従チャレンジを解決するための勝利アプローチについて説明します。シミュレーションと実際のデータの混合セットについて学習します。 
[ABSTRACT] aiドライビングレーンレーンレーンコンペティションは2段階のコンペティションです。第1段階では、シミュレーション環境でアルゴリズムが競合します。ほとんどのアルゴリズムは特定の走行条件に合わせて調整する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: RGBT Salient Object Detection: A Large-scale Dataset and Benchmark -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_57.html">
      <font color="black">RGBT Salient Object Detection: A Large-scale Dataset and Benchmark</font>
    </a>
  </h2>
  <font color="black">％この作業は、グラウンドトゥルースアノテーション付きの空間的に配置された5000個のRGBT画像ペアを含む、VT5000という名前のそのようなRGBT画像データセットに貢献します。％さらに、VT5000データセットでRGBT顕著オブジェクト検出のさまざまなアルゴリズムの包括的な分析を実行し、いくつかの貴重な結論とRGBT顕著オブジェクト検出の潜在的な研究方向を提供します。％しかし、RGBT顕著オブジェクト検出の現在の研究は、大規模なデータセットと包括的なベンチマークの欠如によって制限されています。 
[要約] rgbt顕著オブジェクト検出の研究は、大規模なデータセットと包括的なベンチマークがないために制限されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Scribble-based Domain Adaptation via Co-segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_58.html">
      <font color="black">Scribble-based Domain Adaptation via Co-segmentation</font>
    </a>
  </h2>
  <font color="black">詳細だが時間のかかる注釈を要求する代わりに、ターゲットドメインの落書きを使用して、ドメイン適応を実行します。このホワイトペーパーでは、構造化学習と共同セグメンテーションに基づくドメイン適応の新しい定式化を紹介します。正規化された損失の導入に。 
[ABSTRACT]この作業では、新しい「不安定」な監視ありメソッドを提案します。代わりに、実際にはオプションではない可能性がある追加のデータに完全に注釈を付ける必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic memory to alleviate catastrophic forgetting in continuous
  learning settings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_59.html">
      <font color="black">Dynamic memory to alleviate catastrophic forgetting in continuous
  learning settings</font>
    </a>
  </h2>
  <font color="black">実験は、動的メモリが、これらのシフトがいつ発生するかについての明確な知識を必要とせずに、複数のデータシフトがある状況で破滅的な忘却に対抗することを示しています。メソッドは動的メモリを使用して、多様なトレーニングデータサブセットのリハーサルを容易にし、忘却を緩和します。 
[ABSTRACT] mitのソフトウェア会社は、継続学習マシンの変化のパターンを使用します。このツールは、モデルを使用してソースドメインの目に見えない変化を使用します。2つの異なるスキャナープロトコルと合成分類で取得されたルーチンの臨床ctデータに対するアプローチを評価タスク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: On The Radon-Nikodym Spectral Approach With Optimal Clustering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_60.html">
      <font color="black">On The Radon-Nikodym Spectral Approach With Optimal Clustering</font>
    </a>
  </h2>
  <font color="black">ラドンニコディムアプローチの際立った特徴は、不変グループの知識です。すべての回答は、入力ベクトル$ \ mathbf {x} $コンポーネントの非退化線形変換で比較的不変です。この問題は、ガウスを構築することで解決されますルベーグ測度の求積法..ベイジアンアプローチでは、新しい観測値は結果の確率のみを変更しますが、ラドンニコディムアプローチでは、結果の確率だけでなく、確率空間$ | \ psi ^ {
[i]} \ rangle $も新しい値で変化します観察。 
[ABSTRACT] nikodymアプローチは、radon.simpleの信条でシンプルです。シンプルでシンプルなシステムでは、事前確率と事後確率が必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-02">
        <br><font color="black">2019-06-02</font>
      </time>
    </span>
</section>
<!-- paper0: Lung Segmentation from Chest X-rays using Variational Data Imputation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_61.html">
      <font color="black">Lung Segmentation from Chest X-rays using Variational Data Imputation</font>
    </a>
  </h2>
  <font color="black">この作業では、CXRからのCOVID-19の自動リスクスコアリングを目的としたパイプラインの一部として、このような異常なCXRから肺をセグメント化することに焦点を当てます。極端な異常のある症例にまで及ぶ。肺混濁は、新しいコロナウイルス病2019（COVID-19）を含む多くの呼吸器疾患によって引き起こされる肺の炎症です。 
[ABSTRACT]心臓X-このような混濁を伴う光線は、肺の領域を認識できなくします。これにより、肺の自動画像分析を実行することが困難になります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br><font color="black">2020-05-20</font>
      </time>
    </span>
</section>
<!-- paper0: Single Storage Semi-Global Matching for Real Time Depth Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_62.html">
      <font color="black">Single Storage Semi-Global Matching for Real Time Depth Processing</font>
    </a>
  </h2>
  <font color="black">視差マップの更新レートは現実的な10.5 fpsです。MGMはSGMのバリアントです。GPUを使用した加速にはFPGAが必要です。 
[ABSTRACT]ステレオ-ビジョンシステムはfpgaに基づいています-よりグローバルなマッチング（mgm）の実装。システムは4つのパスを使用しますが、対応するピクセルの単一のブリスベンコスト値を保存</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: C2G-Net: Exploiting Morphological Properties for Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_63.html">
      <font color="black">C2G-Net: Exploiting Morphological Properties for Image Classification</font>
    </a>
  </h2>
  <font color="black">生画像でトレーニングされた従来のCNNアーキテクチャと比較して、C2G-Netは同様の予測精度を達成し、トレーニング時間は85％削減され、モデルの解釈が容易になりました。C2G-Netのパフォーマンスをテストするために、予測に多重免疫組織化学画像を使用しました大腸癌の再発リスク.. C2G-Netは、（1）セグメンテーションを使用してオブジェクトを識別してグリッド上に配置する画像圧縮アルゴリズムであるCell2Grid、および（2）10,000未満のトレーニング可能なCNNアーキテクチャであるDeepLNiNoの2つのコンポーネントで構成されます。モデルの解釈を容易にすることを目的としたパラメーター。 
[要旨] c2g -ohは、トレーニング可能なパラメーターが10,000未満の新しいcnnアーキテクチャであり、生物学的予測精度を実現しました。没入型インモデルは、トレーニング時間が85％短縮され、モデルの解釈がより簡単で、同様の予測精度を実現しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Vanishing Point Detection with Direct and Transposed Fast Hough
  Transform inside the neural network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_64.html">
      <font color="black">Vanishing Point Detection with Direct and Transposed Fast Hough
  Transform inside the neural network</font>
    </a>
  </h2>
  <font color="black">積分演算子を使用すると、ニューラルネットワークが画像内のグローバルな直線的な特徴に依存できるようになるため、消失点を検出するのに最適です。さらに、提案されたニューラルネットワークアーキテクチャは、直接投影と逆投影のプロセスを本質的に繰り返すことに注意してください。たとえば、コンピュータ断層撮影で使用されます。提案されたアーキテクチャの有効性を示すために、DVRからの画像のセットを使用し、既存の方法に対するその優位性を示します。 
[ABSTRACT]たとえば、dvrからの画像のセットを使用して、提案されたアーキテクチャの有効性を示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-04">
        <br><font color="black">2020-02-04</font>
      </time>
    </span>
</section>
<!-- paper0: Uncertainty-Aware Blind Image Quality Assessment in the Laboratory and
  Wild -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_65.html">
      <font color="black">Uncertainty-Aware Blind Image Quality Assessment in the Laboratory and
  Wild</font>
    </a>
  </h2>
  <font color="black">最初に同じIQAデータベースから画像のペアをサンプリングし、各ペアの1つの画像が監視信号として高品質である確率を計算します。次に、忠実度の損失を使用して、BIQAのディープニューラルネットワークを多数の最適化します。そのような画像のペア..また、最適化中に不確実性推定を正規化するために、ヒンジ制約を明示的に適用します。 
[ABSTRACT]これは、実験室でシミュレーションされ、野生でキャプチャされた画像間の分布のずれによるものです。しかし、合成歪みのあるデータベースでトレーニングされたモデルは、現実的な歪みの処理に特に弱いままです。これを使用して、提案されたトレーニング戦略の普遍性を実証しました既存のbiqaモデルを改善する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br><font color="black">2020-05-28</font>
      </time>
    </span>
</section>
<!-- paper0: On Class Orderings for Incremental Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_66.html">
      <font color="black">On Class Orderings for Incremental Learning</font>
    </a>
  </h2>
  <font color="black">結果は、順序がパフォーマンスとメソッドのランキングに大きな影響を与える可能性があることを示しています。データセットのさまざまな順序を計算する方法を提案します。インクリメンタル学習の評価におけるクラスの順序の影響はほとんど注目されていません。 
[ABSTRACT]順序はパフォーマンスとメソッドのランキングに大きな影響を与える可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-04">
        <br><font color="black">2020-07-04</font>
      </time>
    </span>
</section>
<!-- paper0: Soft Anchor-Point Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_67.html">
      <font color="black">Soft Anchor-Point Object Detection</font>
    </a>
  </h2>
  <font color="black">ベルとホイッスルがなければ、私たちの最高のモデルは、COCOで47.4％の単一モデルの単一スケールAPを達成できます。重要な洞察は、アンカーポイントは、機能ピラミッドレベル内およびグループ全体でグループとして共同で最適化する必要があるということです。アンカーフリーの検出方法は大きな進歩を遂げてきました。 
[要約]主要な2つのファミリであるアンカーポイント検出とキーポイント検出は、速度精度ステージの反対側にあります。ソフト加重アンカーポイントとソフト選択ピラミッドレベルを使用して、シンプルで効果的なトレーニング戦略を提案します。各ピラミッドレベル内の誤った注意の問題と、すべてのピラミッドレベルにわたる機能選択の問題に対処する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-27">
        <br><font color="black">2019-11-27</font>
      </time>
    </span>
</section>
<!-- paper0: Context Model for Pedestrian Intention Prediction using Factored
  Latent-Dynamic Conditional Random Fields -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_68.html">
      <font color="black">Context Model for Pedestrian Intention Prediction using Factored
  Latent-Dynamic Conditional Random Fields</font>
    </a>
  </h2>
  <font color="black">2つの異なるデータセットにメソッドを適用します。1つは社内で収集されたもの-NTUデータセットともう1つの公共の実際のベンチマーク-JAADデータセットです。このようなシステムでは、歩行者の交差/交差しない行動の早期かつ正確な予測が必要です。 Vehicle ..歩行者の相互作用をスムーズに処理することは、自動運転車（AV）および高度運転支援システム（ADAS）の重要な要件です。 
[ABSTRACT]既存のシステムは、歩行者の横断または非横断の予測を車両の前で支援します。これらのシステムは、歩行者の早期かつ正確な予測を必要とします。これらのシステムは、そのようなシステムの円滑な運用のための早期予測の必要性を述べています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-27">
        <br><font color="black">2019-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: SpinalNet: Deep Neural Network with Gradual Input -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_69.html">
      <font color="black">SpinalNet: Deep Neural Network with Gradual Input</font>
    </a>
  </h2>
  <font color="black">提案されているSpinalNetのスクリプトは、https：//github.com/dipuk0506/SpinalNetから入手できます。ディープニューラルネットワーク（DNN）は、多くの分野で最先端のパフォーマンスを実現しています。入力セグメンテーションにより、各隠れ層は、前の層の入力と出力の一部を受け取ることができます。 
[要約]このペーパーは、スピナルネットを提示することを目的としています。レイヤーには、ニューロンの数が少ないdnnsが含まれています。非表示レイヤーの入力ウェイト数は、従来のdnnsよりも大幅に低くなっています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Dual Mixup Regularized Learning for Adversarial Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_70.html">
      <font color="black">Dual Mixup Regularized Learning for Adversarial Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">ただし、既存の方法には2つの問題があります。4つのドメイン適応ベンチマークに関する一連の実証的研究は、私たちのアプローチが最先端の技術を達成できることを示しています。上記の問題を軽減するために、 UDAのMixup正則化学習（DMRL）メソッド。これは、分類子がサンプル間の一貫した予測を強化するのをガイドするだけでなく、潜在空間の固有の構造も豊かにします。 
[要旨] dmrlは、モデルの有効性を向上させる方法に関するエグゼクティブエキスパートです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: AnchorFace: An Anchor-based Facial Landmark Detector Across Large Poses -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_71.html">
      <font color="black">AnchorFace: An Anchor-based Facial Landmark Detector Across Large Poses</font>
    </a>
  </h2>
  <font color="black">全体的に、AnchorFaceという名前の提案されたアプローチは、4つの挑戦的なベンチマークで非常に効率的な推論速度で最先端の結果を取得します。顔のランドマークの位置特定は、人間の顔の事前定義された点を検出することを目的としており、トピックはニューラルネットワークに基づく方法の最近の開発によって急速に改善されています。各アンカーテンプレートの予測に基づいて、結果を集約して、大きなポーズによる画期的な不確実性。 
[ABSTRACT] `anchorface &#39;は、検索でトラックを追跡できると主張していますsearch.claimsは、新しいモデルを使用して検索を検索できると主張しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: HKR For Handwritten Kazakh & Russian Database -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_72.html">
      <font color="black">HKR For Handwritten Kazakh & Russian Database</font>
    </a>
  </h2>
  <font color="black">データベースは1400以上の記入済みフォームで構成されています。約63000の文、約200人の異なる作家によって作成された650000以上の記号があります。カザフ語の単語/文の％）オフライン手書き認識用。いくつかの前処理およびセグメンテーション手順がデータベースとともに開発されています。 
[要約]約63000文、200人の異なる作家によって作成された650000以上の記号がある</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Topology Transformation with Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_73.html">
      <font color="black">3D Topology Transformation with Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">生成された3D形状は斬新でインスピレーションを与えると信じています。ここでは、ジェネレーティブアドバーサリネットワーク（GAN）を使用した3Dから3Dへの新しいトポロジー変換方法を示します。特に、3Dモデルを2つの新しいボリュームトポロジに変換する方法を示します。 -3Dネットワークとギリゴロ。 
[要旨] vox2voxと呼ばれる修正済みのpix2pixガンを使用して、3Dオブジェクトの体積スタイルを変換します。さらに、ガンを使用せずに、アプローチと3D形状を直接変換するベースラインアルゴリズムの結果を比較します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: ReMOTS: Refining Multi-Object Tracking and Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_74.html">
      <font color="black">ReMOTS: Refining Multi-Object Tracking and Segmentation</font>
    </a>
  </h2>
  <font color="black">（2）隣接するフレーム間で観測を関連付けて短期トラックレットを形成します。（1）予測マスクを使用して外観エンコーダーをトレーニングします。（4）採用されている外観機能と自動的に適用されるしきい値を使用して、短期トラックレットを長期トラックレットにマージします。統計情報から得られます。 
[ABSTRACT] remotsは、データ関連付けの観点からmotsの結果を絞り込むために主に4つのステップを実行します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Model for Rotated Indoor Scenes Planning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_75.html">
      <font color="black">Adversarial Model for Rotated Indoor Scenes Planning</font>
    </a>
  </h2>
  <font color="black">シーン合成に関するこれまでの作業と比較して、提案された3つのモジュールは、自動レイアウト生成の機能を強化し、室内空間の回転中のモードの崩壊を低減します。提案されたモデルは、条件付き敵対ネットワーク、回転モジュール、モードモジュール、および回転弁別器モジュール。数値の結果は、提案されたモデルが、寝室、バスルーム、書斎、畳の部屋を含む4種類の部屋に高品質のレイアウトをもたらすことを示しています。 
[要約]提案されたモデルは、条件付き敵対的ネットワークを組み合わせたものです。回転モジュール、モードモジュール、および回転弁別器が含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-24">
        <br><font color="black">2020-06-24</font>
      </time>
    </span>
</section>
<!-- paper0: AutoAssign: Differentiable Label Assignment for Dense Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_76.html">
      <font color="black">AutoAssign: Differentiable Label Assignment for Dense Object Detection</font>
    </a>
  </h2>
  <font color="black">さらに、他のデータセットの実験、\ emph {eg。さらに、私たちの最高のモデルは52.1 \％APを達成し、既存のすべての1ステージ検出器を上回っています。MSCOCOに関する広範な実験は、この方法が他の最高のサンプリング戦略をさまざまなバックボーンで$ \ sim $ 1 \％着実に上回っていることを示しています。 
[ABSTRACT] autoassignは、各場所の予測を動的に変更することにより、ポジティブサンプルとネガティブサンプルを自動的に決定します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Segmentation of Pulmonary Opacification in Chest CT Scans of COVID-19
  Patients -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_77.html">
      <font color="black">Segmentation of Pulmonary Opacification in Chest CT Scans of COVID-19
  Patients</font>
    </a>
  </h2>
  <font color="black">この作業では、さまざまな病期と感染症の重症度と関連付けられている胸部コンピュータ断層撮影（CT）スキャンでの肺混濁のパターンのセグメンテーションにオープンソースモデルを提供します。複数のセグメンテーションにオープンソースの実装と事前トレーニング済みの重みを提供します。私たちのデータセットでトレーニングされたモデル..私たちの最高のモデルは、テストセットで不透明度Intersection-Over-Unionスコア0.76を達成し、ドメイン適応の成功を実証し、放射線科医の1.7 \％以内の混濁の量を予測します。 
[要約]ある種の肺炎は、このウイルスに関連する最も一般的な症状です。当社の最良のモデルは、不透明度の交差-ユニオンスコア0. 76を達成しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Divide-and-Rule: Self-Supervised Learning for Survival Analysis in
  Colorectal Cancer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_78.html">
      <font color="black">Divide-and-Rule: Self-Supervised Learning for Survival Analysis in
  Colorectal Cancer</font>
    </a>
  </h2>
  <font color="black">次に、これらの組織病理学的パターンを使用して、複雑な組織間の相互作用を表し、臨床転帰を直接予測します。この方法で得られた組織形態学的クラスターは、生存モデルのトレーニングによって評価されます。これを行うには、共同で組織領域の表現と、その基礎となるパターンを取得するためのクラスタリングのメトリック。 
[ABSTRACT]がん組織領域の組織病理学的パターンの迅速な研究。これらは、複雑な組織間の相互作用を表すために使用されます。これらのパターンは、結腸直腸がんの予後の層別化を改善するために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Decoupled Spatial-Temporal Attention Network for Skeleton-Based Action
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_79.html">
      <font color="black">Decoupled Spatial-Temporal Attention Network for Skeleton-Based Action
  Recognition</font>
    </a>
  </h2>
  <font color="black">人間の関節の2D / 3D座標として表される動的骨格データは、その高レベルのセマンティック情報と環境の堅牢性により、人間の行動認識のために広く研究されてきました。具体的には、骨格データの特定の要件を満たすために、3つの手法アテンションブロックを構築するために提案されています。つまり、空間時間的注意デカップリング、デカップリングされた位置エンコーディング、空間的グローバル正則化です。これは、アテンションブロックのみを含み、ジョイントの位置や相互接続を知る必要なしに、ジョイント間の空間時間依存性をモデリングできます。 。 
[ABSTRACT]以前の方法は、手作りのトラバーサルルールの設計に大きく依存しています。これには、パフォーマンスが制限されたアテンションブロックの作成が含まれます。これにより、位置を知らなくてもアテンションブロックをモデリングできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Non-image Data Classification with Convolutional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_80.html">
      <font color="black">Non-image Data Classification with Convolutional Neural Networks</font>
    </a>
  </h2>
  <font color="black">逆に、時系列データは別として、1次元ベクトルのセットとして表されるデータ例は、CNNでは使用できませんが、他の人工ニューラルネットワーク（ANN）では使用できます。データラングリングの新しい前処理方法をいくつか提案しました。 1次元のデータベクトルを2次元のグラフィカルイメージに変換し、CNNで処理するフィールド間に適切な相関を持たせます。VGNnet-16を使用してCNNで処理された変換後のデータは、正規ANNアプローチと比較して、分類精度において競争力のある結果を示します。さらなる改善の可能性が高い。 
[ABSTRACT]データの例はcnnで使用できますが、他の人工ニューラルネットワーク（anns）でも使用できます。これらには、時系列データから抽出できる1-d `行列 &#39;のセットが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Extracting the fundamental diagram from aerial footage -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_81.html">
      <font color="black">Extracting the fundamental diagram from aerial footage</font>
    </a>
  </h2>
  <font color="black">3つのフェーズのそれぞれについて開発されたアルゴリズムについて詳しく説明し、実際の設定での結果の適用性を示します。全体として、このシステムの動作は、道路セグメント、地域、またはネットワークの基本的な図によって特徴付けられます。このホワイトペーパーでは、ドローンプラットフォームから取得した空中映像から基本図を取得する革新的な方法を考案します。輻輳は、システムの全体的な動作に影響を与える2つの測定可能な特性、需要とネットワーク密度と強く相関しています。 
[ABSTRACT]輻輳は、2つの測定可能な特性、システム全体の動作に影響を与える需要とネットワーク密度と強く相関しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Pix2Vox++: Multi-scale Context-aware 3D Object Reconstruction from
  Single and Multiple Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_82.html">
      <font color="black">Pix2Vox++: Multi-scale Context-aware 3D Object Reconstruction from
  Single and Multiple Images</font>
    </a>
  </h2>
  <font color="black">これらの問題に対処するために、Pix2Vox ++という名前のシングルビューおよびマルチビュー3Dオブジェクト再構成用の新しいフレームワークを提案します。融合3Dボリュームで誤って回復されたパーツをさらに修正するために、最終出力を生成するリファイナーが採用されています。 ShapeNet、Pix3D、およびThings3Dベンチマークの実験結果は、Pix2Vox ++が、精度と効率の両方の点で、最先端の方法に対して有利に機能することを示しています。 
[ABSTRACT] shapenet、pix3d、things3dのベンチマークは、pix2vox plusが、精度と効率の両方の観点から、最先端技術に対して有利に機能することを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-22">
        <br><font color="black">2020-06-22</font>
      </time>
    </span>
</section>
<!-- paper0: Reinterpreting CTC training as iterative fitting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_83.html">
      <font color="black">Reinterpreting CTC training as iterative fitting</font>
    </a>
  </h2>
  <font color="black">これに触発されて、CTCトレーニングを変更する2つの方法を提案しました。実験は、この方法がスパイク問題をうまく解決でき、さらに、さまざまなトレーニング設定での収束が速くなることを示しています。これに加えて、CTCの再解釈は、まったく新しい視点です。他の状況で役立つ可能性があります。 
[ABSTRACT] ctc-モデルのタイプのトレーニング済みモデルは、一連のスパイクを形成する傾向があります。これらは、スパイク問題として知られる、強い予測されたブランクによって分離されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-24">
        <br><font color="black">2019-04-24</font>
      </time>
    </span>
</section>
<!-- paper0: Light Field Image Super-Resolution Using Deformable Convolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_84.html">
      <font color="black">Light Field Image Super-Resolution Using Deformable Convolution</font>
    </a>
  </h2>
  <font color="black">ただし、LF画像間の差異に起因する角度情報を組み込むことは困難です。当社のLF-DFnetは、より忠実なディテールを備えた高解像度画像を生成し、最先端の再構成精度を達成できます。.このホワイトペーパーでは、 LF画像SRの視差問題を処理するための変形可能なたたみ込みネットワーク（つまり、LF-DFnet）。 
[ABSTRACT]複数のlf画像に加えて、これらの情報をうまく組み込むことができます。これらの機能は、各ビューの機能に組み込んでエンコードできます。これは、すべてのlf画像のsr再構成の結果です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Long-term Human Motion Prediction with Scene Context -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_85.html">
      <font color="black">Long-term Human Motion Prediction with Scene Context</font>
    </a>
  </h2>
  <font color="black">単一のシーン画像と2Dポーズ履歴がある場合、この方法では、まず複数の人間のモーションゴールをサンプリングし、次に各ゴールに向かう3Dヒューマンパスを計画し、最後に各パスに続く3Dヒューマンポーズシーケンスを予測します。この作業では、新しい3シーンのコンテキストを活用してこのタスクに取り組むステージフレームワーク。合成データセットと実際のデータセットの両方で、私たちの方法は既存の方法に対して一貫した定量的および定性的な改善を示しています。 
[ABSTRACT]この作品では、シーンのコンテキストを利用してこのタスクに取り組む新しい3段階のフレームワークを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Meta Corrupted Pixels Mining for Medical Image Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_86.html">
      <font color="black">Meta Corrupted Pixels Mining for Medical Image Segmentation</font>
    </a>
  </h2>
  <font color="black">予測されたセグメンテーション結果の損失値マップを入力と見なすメタマスクネットワークは、破損したレイヤーを特定し、それらに小さな重みを割り当てることができます。この方法は、重み付けマップを自動的に推定して、すべてのピクセルの重要性を評価することを目的としていますしかし、ディープニューラルネットワークのトレーニングには、高品質のアノテーションを備えた大量のサンプルが必要です。 
[ABSTRACT]ディープニューラルネットワークには、高品質のアノテーションを備えた大量のサンプルが必要です。メソッドは、単純なメタマスクネットワークに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: LabelEnc: A New Intermediate Supervision Method for Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CV/paper_87.html">
      <font color="black">LabelEnc: A New Intermediate Supervision Method for Object Detection</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、オブジェクト検出システムのトレーニングを強化するために、LabelEncという新しい中間監視方法を提案します。次に、学習したラベルエンコーディング機能を利用して、検出バックボーンに接続された新しい補助損失を導入し、派生検出器の性能..私たちのアプローチは主に2段階のトレーニング手順を含みます。 
[ABSTRACT]新しい方法は、ラベル空間でオートエンコーダを使用します。検出バックボーンへの補助的な中間監視として機能します。この方法は、さまざまな検出システムを約2％改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: What Gives the Answer Away? Question Answering Bias Analysis on Video QA
  Datasets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CL/paper_0.html">
      <font color="black">What Gives the Answer Away? Question Answering Bias Analysis on Video QA
  Datasets</font>
    </a>
  </h2>
  <font color="black">具体的には、トレーニング中に見られたアノテーターは、モデルと推論によってより適切に予測されます。抽象的な質問は、実際の直接的な質問よりも多くのバイアスを招きます。私たちのアブレーション研究は、バイアスがアノテーターと質問のタイプから生じる可能性があることを示しています。人気のあるビデオ質問応答データセットのQAバイアスを分析し、事前学習済みの言語モデルがマルチモーダルコンテキスト情報を使用せずに37〜48％の質問に正しく回答できることを発見します。これは、5-choose-1多肢選択問題の20％ランダム推測ベースラインをはるかに超えています。 
[ABSTRACT]調査では、QAバイアスの強さや発生源が示されています。モデルをデバッグするための洞察が研究者に提供されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Structured (De)composable Representations Trained with Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CL/paper_1.html">
      <font color="black">Structured (De)composable Representations Trained with Neural Networks</font>
    </a>
  </h2>
  <font color="black">表現は、表現をクラスと環境を表す要素に分解できる明確な構造であることを証明します。提案された手法は、エンドツーエンドのディープラーニングを使用して、入力画像と離散ラベルから構造化された合成可能な表現を学習します。表現は、クラスラベルによって与えられる分布と、環境としてモデル化されるコンテキスト情報によって与えられる分布との間の距離推定に基づいています。 
[ABSTRACT]コンセプトは、クラス全体の特徴を捉えたコンセプトの形式です。クラスラベルによって与えられたスナックとコンテキスト情報によって与えられたスナックの間の距離の推定に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Continual BERT: Continual Learning for Adaptive Extractive Summarization
  of COVID-19 Literature -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CL/paper_2.html">
      <font color="black">Continual BERT: Continual Learning for Adaptive Extractive Summarization
  of COVID-19 Literature</font>
    </a>
  </h2>
  <font color="black">このモデルは、壊滅的な忘却を最小限に抑えながらコミュニティのニーズに適合しながら、オンラインで新しいデータについて継続的に学習します。そのパフォーマンスのベンチマークと手動による調査は、モデルが新しい科学文献の健全な要約を提供していることを示しています。 COVID-19に関連する圧倒的な量の新しい研究を毎日公開し、ほとんどまたはまったく注意を払わずに多くの文献を作成する。 
[ABSTRACT]このモデルは、長い論文の簡潔かつ独自の要約を提供します。ベンチマークと手動のフィッティングは、モデルが新しい科学文献の健全な要約を提供していることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Research on Annotation Rules and Recognition Algorithm Based on Phrase
  Window -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CL/paper_3.html">
      <font color="black">Research on Annotation Rules and Recognition Algorithm Based on Phrase
  Window</font>
    </a>
  </h2>
  <font color="black">対応するアルゴリズムは、画像フィールドのターゲット領域を識別するという考えに基づいており、文内のさまざまなフレーズの開始位置と終了位置を見つけ、ネストされたフレーズと文法の依存関係の同期認識を実現できます。ラベリングルールはフレーズを使用します。最小単位として、文をネスト可能な7種類のフレーズタイプに分割し、フレーズ間の文法的な依存関係をマークします。実験の結果は、ラベル付けルールが便利で使いやすく、あいまいさがないことを示しています。このアルゴリズムは、文法的にマルチグラニュラーであり、エンドツーエンドアルゴリズムよりも多様です。 
[ABSTRACT]ラベリングルールはフレーズを最小単位として使用します。7つのタイプのネスト可能なフレーズタイプに分割された文</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Proving Non-Inclusion of Büchi Automata based on Monte Carlo Sampling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CL/paper_4.html">
      <font color="black">Proving Non-Inclusion of Büchi Automata based on Monte Carlo Sampling</font>
    </a>
  </h2>
  <font color="black">広範な実験的評価により、$ \ mathsf {IMC} ^ 2 $はB \ &quot;uchi automataのインクルードに対する反例を見つけるための高速で信頼性の高い方法であることが示されています。このような数のサンプルにより、$ \ mathsf {IMC} ^ 2 $さらなるサンプリングによって$ \ mathcal {L}（\ mathcal {A}）\ not \ subseteq \ mathcal {L}（\ mathcal {B}）$を目撃する確率は、投げ縄の反例を見つける確率は$ \ epsilon $よりも大きい。これはプログラムの終了分析ではよく理解されているが、B \ &quot;uchiオートマトンの言語包含分析の場合は当てはまらない。言語の包含を証明するアルゴリズムを改善し、反例の検索は高価な補完操作に任せました。 
[要約]検証ツールの実用化を最小限に抑えるには、同時にそれらを追求することをお勧めします。これは、b.itがmatheilに対してモンテカルロモデルチェック用に開発されていることを証明するための特定のアルゴリズムを提示するためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-05">
        <br><font color="black">2020-07-05</font>
      </time>
    </span>
</section>
<!-- paper0: So What's the Plan? Mining Strategic Planning Documents -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CL/paper_5.html">
      <font color="black">So What's the Plan? Mining Strategic Planning Documents</font>
    </a>
  </h2>
  <font color="black">注釈付きテキストの量は、RuREBusからどのような洞察を得ることができるかを示すのに十分な大きさです。このペーパーでは、ロシアの戦略計画文書のコーパスであるRuREBusを紹介します。このプロジェクトは、言語テクノロジーと電子政府の両方の観点に基づいています。 
[ABSTRACT]新しいテキストコーパスを最初から作成するためのパイプラインを示しました。次のテキストは、ループイン戦略を使用してマークアップされています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-01">
        <br><font color="black">2020-07-01</font>
      </time>
    </span>
</section>
<!-- paper0: Cultural Convergence: Insights into the behavior of misinformation
  networks on Twitter -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CL/paper_6.html">
      <font color="black">Cultural Convergence: Insights into the behavior of misinformation
  networks on Twitter</font>
    </a>
  </h2>
  <font color="black">ネットワーク内のアイデアとコミュニティの誕生と進化を、時間をかけてどのように研究できるでしょうか。ネットワークマッピングを使用して、COVID-19に関連するコンテンツを作成するアカウントを検出し、次に潜在ディリクレ割り当てを使用してトピックを抽出し、中心性をブリッジしてトピックブリッジと非トピックブリッジを特定してから、各トピックとブリッジの分布を調べ、Jensen-Shannonを適用しますトピックナラティブで収束しているコミュニティを示すためのトピック分布の発散。ネットワークマッピング、トピックモデリング、中心性の橋渡し、発散からなるマルチモーダルパイプラインを使用して、COVID-19パンデミックを取り巻くTwitterデータを分析します。 
[要約]マルチモーダルパイプラインを使用して、covidを取り巻くTwitterデータを分析します-19パンデミック</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: An Emergency Medical Services Clinical Audit System driven by Named
  Entity Recognition from Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CL/paper_7.html">
      <font color="black">An Emergency Medical Services Clinical Audit System driven by Named
  Entity Recognition from Deep Learning</font>
    </a>
  </h2>
  <font color="black">3つのモデルはすべて、エンティティタイプマッチング評価で約0.981、厳密評価で約0.976のF1スコアを達成し、BiLSTM-CRFモデルは、BERTベースのモデルよりも1〜2桁軽量で高速です。非構造化救急救命士のフリーテキストレポートから臨床エンティティを確実に識別することができる名前付きエンティティ認識モデル。弱く監視されたトレーニングアプローチを採用して、文にラベルを付けました。 
[ABSTRACT]監査は、時間と手間がかかる手動の海図レビューによって実行されます。この調査で使用されたデータセットには、58、898件のラベルのない救急車の事故が含まれていました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: DAM: Deliberation, Abandon and Memory Networks for Generating Detailed
  and Non-repetitive Responses in Visual Dialogue -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CL/paper_8.html">
      <font color="black">DAM: Deliberation, Abandon and Memory Networks for Generating Detailed
  and Non-repetitive Responses in Visual Dialogue</font>
    </a>
  </h2>
  <font color="black">さらに、DAMは既存のビジュアルダイアログエンコーダーと柔軟に連携し、DAMの情報選択モードを制限することでエンコーダー構造に適応します。各DAMモジュールは、エンコーダーからキャプチャされた応答レベルのセマンティクスとワードレベルの適応的な組み合わせを実行します。各単語を生成するために特別に選択されたセマンティクス。実験結果は、提案されたモデルが高品質の応答で新しい最先端のパフォーマンスを実現することを示しています。 
[ABSTRACT]ダムは、詳細で非反復的な対話を作成するために視覚的応答を必要とします。これは、視覚的応答が視覚的視覚情報に基づいている方法を説明しています。ダムは、一連の注意に基づいています-情報選択ステップに基づいています。再発審議・放棄・記憶（ダム）モジュール</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: TriggerNER: Learning with Entity Triggers as Explanations for Named
  Entity Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CL/paper_9.html">
      <font color="black">TriggerNER: Learning with Entity Triggers as Explanations for Named
  Entity Recognition</font>
    </a>
  </h2>
  <font color="black">2つの十分に研究されたNERデータセットの14kエンティティトリガーをクラウドソーシングします。提案されたモデルであるトリガーマッチングネットワークは、タグ付けのために目に見えない文章に簡単に一般化できる、自己表現でトリガー表現とソフトマッチングモジュールを共同で学習します。従来のニューラルNERフレームワークよりもはるかに費用対効果が高いです。 
[要約]提案されたモデルであるトリガーマッチングネットワークは、文章内のオブジェクトを人々が認識できるようにすることを目的としています。コスト効果の高い方法で監督を提供することが可能です。人間が文章内のエンティティを認識する方法を説明するのに役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br><font color="black">2020-04-16</font>
      </time>
    </span>
</section>
<!-- paper0: The Go Transformer: Natural Language Modeling for Game Play -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CL/paper_10.html">
      <font color="black">The Go Transformer: Natural Language Modeling for Game Play</font>
    </a>
  </h2>
  <font color="black">ランダムゲームボードと比較して、GPT-2の微調整では、効率の良いオープニングムーブシーケンスが示され、センタープレイやサイドプレイよりもコーナープレイが優先されます。アノテーションはトレーニングデータを提供します（例：Amazons＆Connect 4/6）。結果は、言語モデリングがチャンピオンシップGoゲームのシーケンス形式とその戦略的フォーメーションの両方をキャプチャできることを示しています。 
[ABSTRACT]自然なテキストジェネレーターが句読点、間隔、句読点を生成します。テキストジェネレーターは、ゲームの視覚化とクリエイティブパターンへの入力を提供します。効率の良いオープニングムーブシーケンスを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Reflection-based Word Attribute Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CL/paper_11.html">
      <font color="black">Reflection-based Word Attribute Transfer</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案された方法が、ターゲット属性を持たない単語を変更せずに、指定された単語の単語属性を転送できることを示しています。しばしば、キング-男性+女性=クイーンなどの類推関係を表す単語の埋め込みを使用できます。性別を含む単語の属性を変更します。この作業では、このようなアナロジー操作を行わずに、リフレクションマッピングに基づいて単語属性を転送する新しい方法を提案します。 
[ABSTRACT]この作品では、王は男性であるという知識に基づいて女性を差し引きます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: A Transformer-based approach to Irony and Sarcasm detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CL/paper_12.html">
      <font color="black">A Transformer-based approach to Irony and Sarcasm detection</font>
    </a>
  </h2>
  <font color="black">以前の研究
[71]を大幅に拡張して、最近提案された事前トレーニング済みの変圧器ベースのネットワークアーキテクチャに基づくニューラルネットワーク手法を提案します。これは、反復畳み込みニューラルネットワーク（RCNN）の採用と工夫によってさらに強化されます。比喩言語（FL）は、すべてのソーシャルメディアディスカッションフォーラムおよびチャットでユビキタスに見え、感情分析の取り組みに追加の課題をもたらします。この設定により、データの前処理が最小限に抑えられます。 
[要旨]短いテキストでのflスキーマの削除は、自然言語処理（nlp）の分野ではほとんど未解決の問題です。提案された方法は、高度なディープラーニング（dl）メソッドに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-23">
        <br><font color="black">2019-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: S2ORC: The Semantic Scholar Open Research Corpus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CL/paper_13.html">
      <font color="black">S2ORC: The Semantic Scholar Open Research Corpus</font>
    </a>
  </h2>
  <font color="black">このリソースが、学術的テキストに対するテキストマイニングのためのツールとタスクの研究開発を促進することを願っています。フルテキストには、対応する紙のオブジェクトにリンクされている引用、図、表のインライン検出が自動的に検出され、注釈が付けられます。S2ORC 、私たちは何百もの学術出版社やデジタルアーカイブからの論文を1つの情報源に集約し、これまでに公開されている機械可読学術テキストの最大のコレクションを作成しています。 
[要約]コーパスは、リッチテキスト、記事、解決された書誌参照、および8の構造化された全文で構成されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-07">
        <br><font color="black">2019-11-07</font>
      </time>
    </span>
</section>
<!-- paper0: scb-mt-en-th-2020: A Large English-Thai Parallel Corpus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CL/paper_14.html">
      <font color="black">scb-mt-en-th-2020: A Large English-Thai Parallel Corpus</font>
    </a>
  </h2>
  <font color="black">私たちのモデルのパフォーマンスは、タイ語-英語のGoogle Translation API（2020年5月現在）のパフォーマンスに匹敵し、Open Parallel Corpus（OPUS）がタイ語-英語と英語-タイ語の両方の翻訳のトレーニングデータに含まれている場合、Googleよりも優れています。 。私たちは、このデータセットに基づいて機械翻訳モデルをトレーニングします。.データセット、事前トレーニング済みモデル、および私たちの作業を再現するためのソースコードは、パブリックで使用できます。 
[ABSTRACT]データセット、事前トレーニング済みモデル、および私たちの作業を再現するためのソースコードは、パブリックで使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: SUPP.AI: Finding Evidence for Supplement-Drug Interactions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CL/paper_15.html">
      <font color="black">SUPP.AI: Finding Evidence for Supplement-Drug Interactions</font>
    </a>
  </h2>
  <font color="black">ラベル付きDDIデータを使用して、RoBERTa言語モデルのコンテキスト化された単語表現を微調整し、微調整モデルを適用して、補足の相互作用を識別します。22Mの記事（P = 0.82、R = 0.58、F1 = 0.68）インタラクションが60kの場合。ユーザーがモデルによって抽出された証拠文を検索するためのSUPP.AIアプリケーションを作成します。 
[ABSTRACT]サップを紹介します。 ai、生物医学文献から抽出されたサプリメント-薬物相互作用（sdis）の証拠を閲覧するためのアプリケーション。sdi識別のためのラベル付きデータの欠如に対処するために、薬物関連相互作用を識別する密接に関連するタスクのラベルを使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-17">
        <br><font color="black">2019-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: A Frobenius Algebraic Analysis for Parasitic Gaps -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CL/paper_16.html">
      <font color="black">A Frobenius Algebraic Analysis for Parasitic Gaps</font>
    </a>
  </h2>
  <font color="black">同じ述語の引数に影響を与える寄生ギャップの場合、多態性は、主要なギャップを導入する字句項目に関連付けられます。付属物の寄生ギャップは、付属語句のヘッドの多態性型スキーマとの一般化された調整の形式として分析されます。寄生ギャップの解釈は、自然言語の構成における非線形性の表面的なケースです。 
[ABSTRACT]これらはポリモーフィックコピーの例です。これらには、付属句の先頭のポリモーフィックタイプスキーマが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br><font color="black">2020-05-12</font>
      </time>
    </span>
</section>
<!-- paper0: Educating Text Autoencoders: Latent Representation Guidance via
  Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CL/paper_17.html">
      <font color="black">Educating Text Autoencoders: Latent Representation Guidance via
  Denoising</font>
    </a>
  </h2>
  <font color="black">この単純な変更により、エンコーダーに類似のテキストを類似の潜在表現にマッピングするように促すことにより、結果のモデルの潜在空間ジオメトリがガイドされることを証明します。この問題を修正するために、元の文が摂動されたバージョンから再構築されるノイズ除去目的で敵対オートエンコーダーを増強します（DAAEと呼ばれる）。しかし、現在のモデルは、潜在的なベクトル操作を介して意味のあるテキスト操作を実行するために必要な一貫した潜在的なスペースを維持するのに苦労しています。 
[ABSTRACT]この現象の理論的説明により、大容量オートエンコーダーがシーケンスと関連する潜在表現の間の任意のマッピングを学習できることがわかります。改善策は、daae潜在空間の潜在空間構成に関するこの簡単な変更ガイドであることを証明します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-29">
        <br><font color="black">2019-05-29</font>
      </time>
    </span>
</section>
<!-- paper0: Do Transformers Need Deep Long-Range Memory -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/cs.CL/paper_18.html">
      <font color="black">Do Transformers Need Deep Long-Range Memory</font>
    </a>
  </h2>
  <font color="black">一連の介入を実行して、長距離メモリを6分の1に減らしても同等のパフォーマンスが得られ、ネットワークの下位層で注意の範囲を制限することでより良いパフォーマンスが得られることを示します。ただし、これが必要かどうかは不明です。特に言語モデリングの場合、Transformer-XL（過去のアクティベーションの長期記憶で強化されたTransformer-XL）は、よく研究されたさまざまなベンチマークで最先端であることが示されています。 
[ABSTRACT] transformer-xl-過去のアクティベーションのメモリで強化されたトランス-は最先端の技術であることが示されています。トランスは一連のよく研究されたベンチマークです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Predicting Afrobeats Hit Songs Using Spotify Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.AS/paper_0.html">
      <font color="black">Predicting Afrobeats Hit Songs Using Spotify Data</font>
    </a>
  </h2>
  <font color="black">この研究は、Afrobeatsジャンルのどの曲がSpotifyリスナーの間で人気になるかを予測することを目的として、ヒットソングサイエンスの問題に取り組みました。曲は、提供されたオーディオ機能を使用して、Spotify Web APIを介して生成されました。 
[要約] 2063曲のデータセットは、spotify web apiを介して生成されました。データセットは、spotifyのソフトウェアによって生成されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Tones' Phase Coding (MTPC) of Interaural Time Difference by
  Spiking Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.AS/paper_1.html">
      <font color="black">Multi-Tones' Phase Coding (MTPC) of Interaural Time Difference by
  Spiking Neural Network</font>
    </a>
  </h2>
  <font color="black">実験結果は、1〜3度の平均誤差方位角を示しています。これは、音源定位のための他の生物学的に妥当なニューロモーフィックアプローチの精度を上回ります。このスキームは、人工的に計算するのではなく、自然に人間の聴覚定位システムの機能構造に従います。到着の時間差.. MTPCは、畳み込みSNNと反復SNNの2つの異なるSNNアーキテクチャでパイプライン化され、さまざまなSNNへの適用性を示します。 
[ABSTRACT]このモデルのキーは、両耳間の時間差（itd）キューをスパイクパターンにエンコードするmtpcに依存しています。イベント駆動型や電力効率などのsnnの利点を際立たせています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: X-vectors: New Quantitative Biomarkers for Early Parkinson's Disease
  Detection from Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-08/eess.AS/paper_2.html">
      <font color="black">X-vectors: New Quantitative Biomarkers for Early Parkinson's Disease
  Detection from Speech</font>
    </a>
  </h2>
  <font color="black">高品質のマイクと自分の電話で221人のフランス語話者（最近診断されたPD被験者と健康な対照を含む）を録音しました。より正確なモデルを持ち、起こりうる性別への影響を評価するために、男性と女性を別々に分析しました。この結果は、両方の録音タイプ（高品質のマイクと電話）で観察されました。 
[ABSTRACT]最新の話者認識システム（xシールドと呼ばれる）を採用して、音声分析からpdの初期段階を検出しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
