<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-05-29の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Unsupervised Audio Source Separation using Generative Priors -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.SD/paper_0.html">
      Unsupervised Audio Source Separation using Generative Priors
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      計画された勾配降下最適化を使用することにより、私たちのアプローチは同時にソース固有の潜在空間を検索して、構成ソースを効率的に回復します。生成事前確率は時間領域で直接定義できます。 WaveGAN、スペクトル領域損失関数を使用して最適化すると、高品質のソース推定につながることがわかります。 
[要旨]事前に個々のソースでトレーニングする必要があり、これらの仮定が変更された場合は再トレーニングが必要です。仮定が変更された場合、プロセスには再トレーニングが必要です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Subword RNNLM Approximations for Out-Of-Vocabulary Keyword Search -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.SD/paper_1.html">
      Subword RNNLM Approximations for Out-Of-Vocabulary Keyword Search
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本稿では、従来のn-gramモデルとRNNLM近似を補間してOOV認識を改善することを提案します。さらに、サブワードユニットに適した新しいRNNLM近似法を開発します。近似をスパンし、トレーニングコーパスで元々観測されなかったn-gramも考慮します。これを解決する1つの方法は、バックオフn-gramモデルによってRNNLMを近似することです。 
[要約]初回パス認識でサブワード言語モデル（lms）を使用すると、oovワードを認識できます。ただし、サブワードn-グラムlmsでもデータのスパース性に悩まされています。このような新しい方法は、サブワード認識用に開発されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Leveraging Text Data Using Hybrid Transformer-LSTM Based End-to-End ASR
  in Transfer Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.SD/paper_2.html">
      Leveraging Text Data Using Hybrid Transformer-LSTM Based End-to-End ASR
  in Transfer Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は、制限されたラベル付きデータを使用して両方をトレーニングすると、提案されたアーキテクチャが以前のLSTMベースのアーキテクチャ
[1]よりも24.2％相対ワードエラー率（WER）だけ優れていることを示しています。さらに、転送されたモデルのLSTMデコーダーを追加のテキストデータでブーストすることにより、13.6％の相対WER削減を追加で取得します。 
[要約]マレーシアのコーパスで1.5％のテキストを含む実験を行います。これは、合計13％と比較されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Speech-to-Singing Conversion based on Boundary Equilibrium GAN -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.SD/paper_3.html">
      Speech-to-Singing Conversion based on Boundary Equilibrium GAN
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      再現性のために、コードは紙の出版時にGitHubリポジトリで公開されます。具体的には、音声入力、およびオプションでターゲットの歌唱のF0輪郭が与えられると、提案されたモデルは、漸進的に成長する歌声信号を出力として生成しますエンコーダー/デコーダーアーキテクチャと境界平衡GAN損失関数..このペーパーでは、音声信号のスペクトログラムを歌うもののスペクトログラムに変換するための生成的敵対的ネットワーク（GAN）ベースのモデルの使用を調査します。スピーチ。 
[要約]提案されたモデルは、既存の非発声レベルよりもはるかに自然な歌声を生成します。これにより、発声に対する発声の使用を削減するさまざまな方法を開発するために使用できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: DeepSonar: Towards Effective and Robust Detection of AI-Synthesized Fake
  Voices -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.SD/paper_4.html">
      DeepSonar: Towards Effective and Robust Detection of AI-Synthesized Fake
  Voices
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      目の肥えた偽の声におけるDeepSonarの高い検出率（98.1％平均精度）と低い誤警報率（0.02等しいエラー率）を裏付けるために英語と中国語の両方を含みます。この作業では、層ごとのニューロンの力を活用します。実際とAIで合成された偽の声の微妙な違いをキャプチャし、生の入力よりも明確な信号を分類子に提供できるという推測のある活性化パターン。実験は3つのデータセット（Google、Baiduなどの商用製品を含む）で行われます。 
[ABSTRACT]科学者は偽の声の新たな脅威に完全に取り組む準備ができていません。彼らはこの新たな脅威に取り組む準備ができていないと言います
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Bayesian Restoration of Audio Degraded by Low-Frequency Pulses Modeled
  via Gaussian Process -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.SD/paper_5.html">
      Bayesian Restoration of Audio Degraded by Low-Frequency Pulses Modeled
  via Gaussian Process
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文は、パルス位置を一緒に推定することができる新しいベイジアンアプローチを提案します。パルスを開始する強い不連続性の根底にあるほぼ消滅した信号を補間します。制御された実験により、提案された方法は、ユーザーの介入が大幅に少なくて済み、以前のアプローチと同様の知覚結果が得られ、次の場合にうまく機能することが示されています。自然に劣化した信号を処理します。モデルパラメータとパルスの事後分布は、マルコフチェーンモンテカルロ（MCMC）アルゴリズムによって探索されます。 
[要約]デジタル録音での抑制に対する以前のアプローチは、パルス位置の事前推定値に依存します。これは通常、ハイレート化された方法で実行されます。以前のロッドロッドロッドは古いモデルパラメーターを生成し、パルスはマルコフによって探索されます-チェーンモンテカルロ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: When Can Self-Attention Be Replaced by Feed Forward Layers? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.SD/paper_6.html">
      When Can Self-Attention Be Replaced by Feed Forward Layers?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、トランスフォーマーなどの自己注意モデルは、音声認識における再帰型ニューラルネットワークシステムと比較して競争力のある結果をもたらしました。私たちの実験は、自己注意層が音声信号を処理する方法に関する洞察を提供し、より低い自己注意層がエンコーダの入力は十分に広い範囲の入力をエンコードするため、上位層でさらにコンテキスト情報を学習する必要はありません。これを調査するために、これらの自己注意層をフィードフォワード層に置き換えます。 
[要約]音声認識実験で興味深い結果を実際に観察しました。エンコーダーの上部の自己注意レイヤーをフィードフォワードレイヤーで置き換えると、パフォーマンスが低下することはなく、わずかな利益さえあります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Subword RNNLM Approximations for Out-Of-Vocabulary Keyword Search -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_0.html">
      Subword RNNLM Approximations for Out-Of-Vocabulary Keyword Search
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、ベースライン近似を提案された方法で置き換えると、複数文字と単一文字のサブワードの両方で最高のパフォーマンスが得られます。このホワイトペーパーでは、従来のnグラムモデルとRNNLM近似を補間してOOV認識を改善することを提案します。 、サブワードユニットに適した新しいRNNLM近似方法を開発します。これは、ロングスパン近似を含む可変次数のn-gramを生成し、トレーニングコーパスで元々観測されなかったn-gramも考慮します。 
[要約]初回パス認識でサブワード言語モデル（lms）を使用すると、oovワードを認識できます。ただし、サブワードn-グラムlmsでもデータのスパース性に悩まされています。このような新しい方法は、サブワード認識用に開発されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Attention in Natural Language Processing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_1.html">
      Attention in Natural Language Processing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、自然言語処理における注意アーキテクチャの統一モデルを定義し、テキストデータのベクトル表現で動作するように設計されたものに焦点を当てます。4つの次元による注意モデルの分類法を提案します。入力、互換性関数、分布関数、入力および/または出力の多重度など。ただし、このドメインは急速に進歩しているため、注意の体系的な概要はまだありません。 
[ABSTRACT]アテンションアーキテクチャはさまざまな形式で実現されています。アテンションアーキテクチャのシステムは複数の形式で見られます。アテンションモデルで以前の情報をどのように活用できるかの例を示します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-02-04">
        <br>2019-02-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Language (Technology) is Power: A Critical Survey of "Bias" in NLP -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_2.html">
      Language (Technology) is Power: A Critical Survey of "Bias" in NLP
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの調査結果に基づいて、NLPシステムの「バイアス」を分析する作業をガイドする3つの推奨事項を提案することにより、前進の道の始まりを説明します。これらの推奨事項は、言語と社会階層間の関係のより深い認識に基づいており、研究者と実務家を励ます彼らの「バイアス」の概念化、つまり、どのようなシステムの動作が、どのような方法で、誰に、そしてなぜ有害であるか、およびこれらのステートメントの基礎となる規範的な推論を明確に表現し、そして生きているものを中心に作業を集中させる技術者とそのようなコミュニティ間の権力関係を調査し、再考しながら、NLPシステムの影響を受けるコミュニティのメンバーの経験。さらに、これらの論文で提案されている「バイアス」を測定または緩和するための定量的手法は、彼らの動機とあまり一致しておらず、 NLP以外の関連文献を利用する。 
[ABSTRACT]「バイアス」を測定または緩和するために提案されたこれらの論文の定量的手法は、彼らの動機とはあまり一致していません。これらの推奨事項は、言語と社会階層間の関係のより大きな認識に基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: $R^3$: Reverse, Retrieve, and Rank for Sarcasm Generation with
  Commonsense Knowledge -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_3.html">
      $R^3$: Reverse, Retrieve, and Rank for Sarcasm Generation with
  Commonsense Knowledge
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人間の評価によると、私たちのシステムは、34％は人間のアノテーターよりも皮肉を生成し、90％は強化ハイブリッドベースラインよりも優れた皮肉を生成します。皮肉の生成に関するこれまでの研究は主に文脈の不一致に焦点を当てていますが、価数の逆転を組み合わせると、常識知識に基づく意味的不一致は、より高品質の皮肉を生成します。非皮肉な入力文に基づく皮肉生成のための教師なしアプローチを提案します。 
[ABSTRACT]私たちの方法は、検索と編集のフレームワークを使用して、sarcasmの2つの主要な特性をインスタンス化します。価数の逆転と意味的な意味の不一致が、コンテキストとの共通の常識または世界の知識を含む可能性があります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Variational Neural Machine Translation with Normalizing Flows -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_4.html">
      Variational Neural Machine Translation with Normalizing Flows
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      残念ながら、潜在的な空間は非常に大きくなる可能性があり、トレーニング時に潜在コードが多くの変換モデルによって無視される傾向があるため、有益な潜在変数の学習は重要です。変分ニューラル機械翻訳（VNMT）は、ソースセンテンスだけでなく、いくつかの潜在確率変数にも条件付けされたターゲット翻訳の生成をモデリングします。このホワイトペーパーでは、VNMTフレームワークを最新のトランスフォーマーに適用し、より柔軟な近似を導入することを提案します正規化フローに基づく事後。 
[ABSTRACT]以前の作品は、潜在コードの配布に強い仮定を課し、デザインを選択する傾向があります。しかし、彼らは、マシン内条件と8条件外条件の両方でフレームワークの魅力的な欠如を示したと述べています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Intersectional Bias in Hate Speech and Abusive Language Datasets -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_5.html">
      Intersectional Bias in Hate Speech and Abusive Language Datasets
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は、アフリカ系アメリカ人のつぶやきが虐待的であるとラベル付けされる可能性が最大3.7倍高く、アフリカ系アメリカ人の男性のつぶやきが他のものと比べて嫌悪であるとラベル付けされる可能性が最大77％高いことを示しました。差別的発言と虐待的言語のデータセットにおける交差バイアスに関する。アルゴリズムは、ソーシャルメディアでの差別的発言と虐待的言語を検出するために広く適用されています。 
[ABSTRACT]これらのアルゴリズムのトレーニングに使用される人間の注釈が付けられた言語に偏りがあるかどうかを調査しました。人種、性別、政党識別など、Twitterでデータをテストしました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Corpus for Large-Scale Phonetic Typology -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_6.html">
      A Corpus for Large-Scale Phonetic Typology
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      コーパスを作成する方法論を説明し、現在の方法とこのデータの有用性への影響に関する警告について説明し、48の最高品質のリーディングに関する一連のケーススタディを通じて可能な研究方向を示します。コーパスとスクリプトは公開されています。 https://voxclamantisproject.github.io。で非営利目的で利用できます。ただし、現在利用できるリソースがほとんどない、または数百の言語でこのようなアラインメントを取得することは簡単ではなく、計算集約的です。 
[要約]最初の大規模コーパスは、635言語の690の読みでセグメントと推定された音素レベルのラベルを揃えました。このような観測は数百の言語に使用でき、その多くは現在利用可能なリソースがほとんどないか、まったくありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ConCET: Entity-Aware Topic Classification for Open-Domain Conversational
  Agents -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_7.html">
      ConCET: Entity-Aware Topic Classification for Open-Domain Conversational
  Agents
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、ConCETはエンティティ情報を利用して、発話表現を豊かにし、文字、単語、エンティティタイプの埋め込みを1つの表現に結合します。ただし、数百万の使用可能なエンティティを持つリッチドメインの場合、非現実的な量のラベル付きトレーニングデータが必要になります。私たちは、ConCETと提案されたトレーニング方法を、自己対話と呼ばれるオープンに利用可能な人間と人間の会話データセットで最初に広範囲に評価して、以前の最先端の方法に対するアプローチを調整します。次に、Amazon Alexa Prizeの一部として収集された、実際のユーザーとの人間と機械の会話の大規模なデータセットでConCETを評価します。 
[ABSTRACT]複雑なドメインの場合、発話は多くの場合、そのドメインを担当する単一のコンポーネントにルーティングされます。ただし、リッチドメインの場合は、表現する必要があります。このモデルでは、concetを導入します。同時エンティティ-会話型トピック分類子、エンティティ-タイプ情報と発話コンテンツ機能を組み込んだもの
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CA-EHN: Commonsense Analogy from E-HowNet -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_8.html">
      CA-EHN: Commonsense Analogy from E-HowNet
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、88Kの中国語の単語に構造化された感覚の定義と英語の翻訳で注釈を付けるオントロジーであるE-HowNetを活用して、常識的な知識を単語レベルの類推にモデル化します。実験により、CA-EHNは優れた指標として際立っている単語表現が常識的な知識をどの程度うまく埋め込んでいるかの説明です。データセットは\ url {https://github.com/ckiplab/CA-EHN}で公開されています。 
[ABSTRACT]最初の常識的な単語の類推データセットには、5、656の単語、および763の関係をカバーする90、505の類推が含まれています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-20">
        <br>2019-08-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Generating Diverse and Consistent QA pairs from Contexts with
  Information-Maximizing Hierarchical Conditional VAEs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_9.html">
      Generating Diverse and Consistent QA pairs from Contexts with
  Information-Maximizing Hierarchical Conditional VAEs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      生成されたQApairs（QAベースの評価）のみを使用してQAモデル（BERTベース）のパフォーマンスを評価するか、生成されたペアと人間のラベルが付いたペア（半教師あり学習）の両方を使用して、いくつかのベンチマークデータセットでValidourInformation MaximizingHierarchicalConditionalVariationalAutoEncoder（Info-HCVAE）を検証します）最先端のベースラインモデルに対するトレーニングの場合。結果は、モデルが両方のタスクのすべてのベースラインで印象的なパフォーマンスの向上を達成し、トレーニングに一部のデータのみを使用していることを示しています。問題に取り組む別のアプローチは、問題のコンテキストまたは大量の非構造化テキストから自動生成されたQAペアを使用することです（例
[ABSTRACT]システムは、人間ベースのqaペアの数に基づいています。自動生成されたqaペアを使用します。問題のコンテキストから、または大量の非構造化テキストから
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Adversarial Attacks and Defense on Textual Data: A Review -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_10.html">
      Adversarial Attacks and Defense on Textual Data: A Review
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      後で、この分野で前進するために克服する必要があるすべての論文と課題の興味深い発見のいくつかを指摘します。この問題は、画像と音声の分野で深く研究されています。この原稿では、攻撃手法、より包括的なアイデアを提供するためにこの問題を克服する方法に関するさまざまな防御モデル。 
[ABSTRACT]これは、モデルがノイズに弱いため、モデルの誤分類を余儀なくされることが示されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Would you Like to Talk about Sports Now? Towards Contextual Topic
  Suggestion for Open-Domain Conversational Agents -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_11.html">
      Would you Like to Talk about Sports Now? Towards Contextual Topic
  Suggestion for Open-Domain Conversational Agents
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は有望です。CTS-Seqモデルはベースラインより23％高い精度でトピックを提案し、協調フィルタリングシグナルをハイブリッドCTS-Seq-CFモデルに組み込むと、推奨精度が12％向上します。この問題を解決するには：（1）会話コンテキストをキャプチャするためのモデルベースの順次トピック提案（CTS-Seq）、（2）類似ユーザーからの以前の成功した会話をキャプチャするための協調フィルタリングベースの提案（CTS-CF）、および（3 ）会話コンテキストと協調フィルタリングの両方を組み合わせたハイブリッドアプローチ。代わりに、オープンドメインの会話に対するパーソナライズされたコンテキストトピックの提案のためのさまざまな方法を検討します。 
[ABSTRACT]アイデアは、個人的な会話型AIチャレンジに使用する必要があります。このモデルは、一連の同様の質問に基づいています。質問は、Amazon Alexa賞のctチャレンジの一部として収集された実際の会話の使用に基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Understanding Cross-Lingual Syntactic Transfer in Multilingual Recurrent
  Neural Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_12.html">
      Understanding Cross-Lingual Syntactic Transfer in Multilingual Recurrent
  Neural Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      言語モデルを関連言語に公開しても、必ずしもターゲット言語の文法知識が向上するわけではなく、字句意味変換の最適条件が構文変換に最適ではない可能性があります。多言語トレーニングは、主に字句表現スペース、またはそれは純粋に文法知識の共有を可能にしますか？現在、最新のニューラル言語モデルは、基盤となるアーキテクチャを変更することなく、複数の言語で同時に正常にトレーニングできることが確立されており、さまざまなNLPモデルを低リソース言語に簡単に適合させることができます。 
[要約]このホワイトペーパーでは、さまざまな形式のクロスリンガル転送を分析します。さまざまなモデルと調査タスクを使用して、その最も決定的な要因を探します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br>2020-03-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: HAT: Hardware-Aware Transformers for Efficient Natural Language
  Processing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_13.html">
      HAT: Hardware-Aware Transformers for Efficient Natural Language
  Processing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最初に$ \ textit {arbitrary encoding-decoder注目} $と$ \ textit {heterogeneous layer} $を使用して大きなデザインスペースを構築します。次に、デザインスペースのすべての候補をカバーする$ \ textit {SuperTransformer} $をトレーニングします。最後に、ハードウェアレイテンシ制約を使用して進化的な検索を実行し、ターゲットハードウェアでの高速実行に特化した専用の$ \ textit {SubTransformer} $を見つけます。 
[ABSTRACT] $ entra textit `supertransformer &#39;$は、デザインスペースのすべての候補をカバーします。`ウェイトシェアリングを使用して多くの$＆textit（サブトランスフォーマー）$を生成する$ ent 
[supertransformer] $をトレーニングします。私たちは見つけることができます。 」
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: User Intent Inference for Web Search and Conversational Agents -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_14.html">
      User Intent Inference for Web Search and Conversational Agents
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2番目の研究トピックでは、次の方法で、Web検索インテント予測の既存の最新手法をeコマースドメインに拡張する予定です。1）検索クエリのインテントと関連する製品カテゴリを予測する共同学習モデルを開発するそれら、2）新しい隠れたユーザーの意図の発見..これらの調査の結果を活用して、自然言語の理解、クエリのスコープ、クエリの提案、ランキングなどのさまざまなタスクのパフォーマンスを向上させ、ユーザーエクスペリエンスを充実させることができます。または、ユーザーの発話またはクエリが短く、あいまいで、コンテキストに依存する可能性があるため、ユーザーの意図を推測することは困難です。 
[ABSTRACT]検索エンジンは、検索エンジンの意図を検索するユーザーの意図を予測します。これらのモデルは、eコマースサイトの検索エンジンで利用可能な実際のクエリで評価されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Appraisal Theories for Emotion Classification in Text -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_15.html">
      Appraisal Theories for Emotion Classification in Text
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの結果は、イベントの説明における高品質の評価次元の割り当てが、個別の感情カテゴリの分類の改善につながることを示しています。自動感情カテゴリ化は、主に、事前定義されたインベントリからの感情にテキスト単位が割り当てられるテキスト分類として定式化されています。 Paul Ekman（恐怖、喜び、怒り、嫌悪感、悲しみ、驚き）またはRobert Plutchik（信頼、期待を追加）によって提案された基本的な感情クラスに続くインスタンス。この論文では、理論に従って、イベントのそのような解釈を明確にすることを提案します。イベントの認知的評価の結果、分類モデルにエンコードされたときに感情分類の可能性を示します。 
[ABSTRACT]これらのイベントの解釈は、paul ek ek ekによって提案されています。これらは、イベントの評価理論に基づいており、感情分類の可能性を示しています。悲しみの理論に従って、これらの解釈は嫌悪感を持って行う必要があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br>2020-03-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Benchmarking neural embeddings for link prediction in knowledge graphs
  under semantic and structural changes -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_16.html">
      Benchmarking neural embeddings for link prediction in knowledge graphs
  under semantic and structural changes
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、知識グラフが意味論的および構造的変化を経験する可能性がある状況での神経埋め込みの精度をベンチマークするオープンソースの評価パイプラインを提案します。リンク予測容量を知識グラフの構造。このような評価パイプラインは、頻繁に更新されることが予想される知識グラフの埋め込みの精度をシミュレートするために特に重要です。 
[ABSTRACT]たとえば、私たちは主に埋め込みを学習する革新的な方法に焦点を当ててきましたが、そのパフォーマンスと堅牢性を評価できるさまざまな方法に注意が向けられていません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-15">
        <br>2020-05-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: JointMap: Joint Query Intent Understanding For Modeling Intent
  Hierarchies in E-commerce Search -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_17.html">
      JointMap: Joint Query Intent Understanding For Modeling Intent
  Hierarchies in E-commerce Search
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーでは、ディープラーニングモデルである2つの異なる高レベルのユーザーインテントタスクを同時に学習するジョイントクエリインテント理解（JointMap）を紹介します。1）クエリのコマーシャルインテントと非コマーシャルインテントの識別、および2）一連の関連付けこれらのタスクのラベル付けされたデータセットのキュレーションはコストと時間がかかる可能性があるため、高品質のトレーニングデータセットを生成するために、アクティブな学習モデルと組み合わせて遠隔監視アプローチを提案します。 。eコマースドメインでは、クエリの理解における最近の研究は、クエリと製品カテゴリのマッピングに焦点を当てています。 
[ABSTRACT]検索クエリは、jointmapの有効性を示すために使用できます。検索クエリは、大規模な商業ウェブサイトから収集されます。結果は、意図芸術をモデル化する有望な方向を示唆しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Complex networks for event detection in heterogeneous high volume news
  streams -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_18.html">
      Complex networks for event detection in heterogeneous high volume news
  streams
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのアプローチは、自然言語処理技術を使用してニュース記事のストリームからこれらのエンティティを検出し、検出されたエンティティが記事や文の共起によってリンクされるタイムスタンプ付きの一連のネットワークを作成します。潜在的なイベントは、コミュニティを使用して特徴付けられ、区別されます名前付きエンティティと関連記事の有益な名詞句を関連付けるキーグラフの検出。このプロトタイプでは、重要なイベントを特定するために、加重ノードの次数が追跡され、変化点の検出が使用されます。 
[要約]この方法論はすでに有望な結果を生み出しており、将来的にはより多様な複雑なネットワーク分析技術を含めるように拡張される予定です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transition-based Semantic Dependency Parsing with Pointer Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_19.html">
      Transition-based Semantic Dependency Parsing with Pointer Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、BERTから抽出された深い文脈化された単語の埋め込みによりアプローチを強化します。結果のシステムは、既存のすべての遷移ベースのモデルよりも優れているだけでなく、SemEval 2015タスク18の英語データセットでこれまでの最高の完全に監視された精度にも一致します。以前の最先端のグラフベースのパーサー。ポインターネットワークで実装された遷移ベースのパーサーは、このタスクでのラベル付き構文ツリーの生成とグラフベースのモデルのパフォーマンスに優れ、依存関係の解析における新しい技術になりました。 
[要約]強力なニューラルネットワークの機能をさらにテストするために、セマンティックな依存関係の解析を実行できる移行システムを提案します。結果として得られるシステムは、2015年のSemevalタスクで最高の完全に監視された精度に一致します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-27">
        <br>2020-05-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Joint Modelling of Emotion and Abusive Language Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_20.html">
      Joint Modelling of Emotion and Abusive Language Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの方法は、実質的な成功を収めていますが、これまではコメントの言語特性とユーザーのオンラインコミュニティのモデル化にのみ焦点を当て、ユーザーの感情的な状態とこれがユーザーの言語にどのように影響するかを無視していました。このホワイトペーパーでは、 1つのタスクが他のタスクに通知することを可能にするマルチタスク学習フレームワークで実験する、感情と虐待的な言語検出の最初の共同モデル。私たちの結果は、感情的な機能を組み込むことにより、データセット全体での虐待検出パフォーマンスが大幅に向上することを示しています。 
[ABSTRACT]自然言語処理（nlp）コミュニティは、悪用を検出するためのさまざまな手法を試しました。これらには、データセット全体での悪用検出パフォーマンスの広範な改善につながる、感情的な機能の使用が含まれます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Language Models are Few-Shot Learners -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_21.html">
      Language Models are Few-Shot Learners
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      対照的に、人間は通常、いくつかの例または単純な指示から新しい言語タスクを実行できます。これは、現在のNLPシステムがまだ大部分が苦労しているものです。最後に、GPT-3は、人間の評価者が人間が書いた記事との区別が困難です。この発見とGPT-3の一般的な社会的影響について説明します。 
[ABSTRACT]言語モデルをスケールアップすると、タスクが大幅に改善されます。これは、以前のモデルアプローチとの競争力に達する場合があります。これらには、言語テスト、言語テスト、言語テストが含まれます。これらのデータセットは、モデルとのテキストインタラクションに変換できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: When Can Self-Attention Be Replaced by Feed Forward Layers? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_22.html">
      When Can Self-Attention Be Replaced by Feed Forward Layers?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これを調査するために、これらの自己注意レイヤーをフィードフォワードレイヤーに置き換えます。私たちの実験は、自己注意レイヤーが音声信号を処理する方法についての洞察を提供し、エンコーダーの低い自己注意レイヤーが十分に広いエンコードを行うという結論に導きます入力の範囲、したがって上位層でさらにコンテキスト情報を学習する必要はありません。ただし、学習されたコンテキストの範囲は、自己注意層の下位から上位に徐々に増加しますが、音響イベントは多くの場合、短時間で発生します。左から右の順序。 
[要約]音声認識実験で興味深い結果を実際に観察しました。エンコーダーの上部の自己注意レイヤーをフィードフォワードレイヤーで置き換えると、パフォーマンスが低下することはなく、わずかな利益さえあります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Contextual Dialogue Act Classification for Open-Domain Conversational
  Agents -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_23.html">
      Contextual Dialogue Act Classification for Open-Domain Conversational
  Agents
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの問題に対処するために、私たちは新しい方法であるCDAC（Contextual Dialogue Act Classifier）を提案します。これは、文脈対話行為分類のためのシンプルで効果的な深層学習アプローチです。この方法の有効性を調査するために、スイッチボードの人間と人間の対話データセット、およびそれを微調整して人間と機械の会話データの対話行動を予測し、Amazon Alexa Prize 2018競争の一部として収集しました。さらに、私たちの結果は、小規模なCDACモデルの微調整手動でラベル付けされたヒューマンマシンの会話のサンプルにより、CDACは実際のユーザーの会話における対話行動をより正確に予測できるようになり、将来の改善のための有望な方向性が示唆されます。 
[ABSTRACT] daは人間と人間の会話で広く研究されていますが、新しいオープンエージェントについては十分に調査されていません。これは、オープンドメインの人間と機械の会話にラベル付けされたデータがないことです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Lessons from reinforcement learning for biological representations of
  space -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_24.html">
      Lessons from reinforcement learning for biological representations of
  space
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このタイプの表現が、特徴ベクトルのデコードを使用して学習された位置間の補間などの幾何学的に一貫性のある空間タスクをサポートする能力をテストします。 &#39;..離れた機能が持続する）幾何学的タスクのパフォーマンスを向上させることができます。 
[ABSTRACT]「頭を中心にした」、「ハンドを中心に」、「世界をベースにした」は、脳ベースのナビゲーションの例です。このペーパーでは、高度な幾何学的整合性を持つ領域の手作りの表現を紹介します。これらの例では、空間の認識（この場合は2d）表現を避けています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-13">
        <br>2019-12-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Variational Autoencoder with Embedded Student-$t$ Mixture Model for
  Authorship Attribution -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_25.html">
      Variational Autoencoder with Embedded Student-$t$ Mixture Model for
  Authorship Attribution
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、既存のVAEは現在、潜在空間の基になる確率分布の想定されるガウス性によって課される制限にまだ拘束されています。この作業では、VAEのガウスモデルをStudent- $ t $モデルに拡張します。これにより、暗黙の確率密度のそれぞれの裾の「重さ」の独立した制御のため。 。 
[ABSTRACT]現在、既存のVaesは、潜在空間での潜在的な確率分布の仮定されたガウス性によって課される制限によって依然として拘束されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_26.html">
      A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      レビューを書くためのオピニオンマイニングにおける最近の進歩にもかかわらず、2つのデータセットに対するアプローチを評価し、ビデオとオーディオのモダリティを活用することで、テキストのみのベースラインよりもパフォーマンスが向上することを示しています。これらの追加のモダリティがビデオレビューをよりよく理解する上で鍵となる証拠を提供します。私たちのアプローチは、時間の注釈を必要とせずに文レベルで機能し、コンテンツのオーディオ、ビデオ、言語の文字起こしから派生した機能を使用します。 
[要約]私たちは、ビデオレビューからきめ細かな意見をマイニングするマルチモーダルアプローチを提案します。ビデオとオーディオのモダリティを活用すると、一貫してテキストよりもパフォーマンスが向上することを示しています-ベースラインのみ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-27">
        <br>2020-05-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning Various Length Dependence by Dual Recurrent Neural Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_27.html">
      Learning Various Length Dependence by Dual Recurrent Neural Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、提案されたDuRNNモデルが非常に長いシーケンス（5000タイムステップを超える）だけでなく、短いシーケンスも非常にうまく処理できることを示しています。多くの最新のRNNモデルと比較して、このモデルは効率的で優れていますパフォーマンス..最初の部分は、制約された完全なリカレント接続を備えたリカレントニューラルネットワークで、短期的な依存関係を順番に処理し、短期的なメモリを生成します。 
[ABSTRACT]長期依存の多くのバリアントが提案されています。これらには、デュアルリカレントニューラルネットワーク（durnn）が含まれます。これは、シーケンスの短期依存で構成され、短期記憶を生成します。ただし、提案されたモデルは、長いシーケンスと短いシーケンスを処理できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Classification of Spam Emails through Hierarchical Clustering and
  Supervised Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_28.html">
      Classification of Spam Emails through Hierarchical Clustering and
  Supervised Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、SPEMC- $ 11 $ Kを使用して、TF-IDFおよびBOWエンコーディングとNaiveベイズ、ディシジョンツリー、およびSVM分類子の組み合わせを評価しました。スパマーは、メールの人気を利用して無差別に迷惑メールを送信しています。最後に、マルチクラスのスパム分類のタスクには、（i）TF-IDFをSVMと組み合わせて最高のマイクロF1スコアパフォーマンスを実現することをお勧めします。 、$ 2.13 $ msでメールを分析します。
[ABSTRACT]最初のマルチクラスデータセットには、健康とテクノロジー、個人的な詐欺、性的なコンテンツの3種類のスパムメールが含まれます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-18">
        <br>2020-05-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CDL: Curriculum Dual Learning for Emotion-Controllable Response
  Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_29.html">
      CDL: Curriculum Dual Learning for Emotion-Controllable Response
  Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CDLは、感情とコンテンツに焦点を当てた2つの報酬を利用して、双対性を改善します。これらの問題を緩和するために、感情制御可能な応答生成を二重タスクに拡張して、感情的応答と感情的生成を生成する、Curriculum Dual Learning（CDL）という新しいフレームワークを提案します。代わりにクエリを実行します。既存の方法では、主に標準クロスエントロピー損失に正則化用語を追加することで感情表現を強化し、トレーニングプロセスに影響を与えます。 
[ABSTRACT] quelableは感情表現を改善することを目的としています。標準のクロスネバダ損失に正則化用語を徐々に追加することにより、感情学習を向上させることを目的としています。ただし、これらの質問は以前のモデルでは無視され、一貫性がさらに損なわれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br>2020-05-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Cats climb entails mammals move: preserving hyponymy in compositional
  distributional semantics -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_30.html">
      Cats climb entails mammals move: preserving hyponymy in compositional
  distributional semantics
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      数学的には、Comprはそれ自体がCPマップであり、したがって線形で一般的に非可換です。これらのルールを小さな文の含意データセットでテストし、FuzzおよびPhaserのパフォーマンスに対するいくつかの改善を確認します。Psdマトリックスは比較的学習できます与えられたベクトル空間で簡単に$ M \ otimes M ^ * $ですが、単語を構成して句や文を形成するには、より大きな空間での表現が必要です。 
[ABSTRACT]これらは、それ自体が単語の類似性だけでなく、催眠術をモデル化することを可能にします-またはpsd
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The SIGMORPHON 2020 Shared Task on Unsupervised Morphological Paradigm
  Completion -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/cs.CL/paper_31.html">
      The SIGMORPHON 2020 Shared Task on Unsupervised Morphological Paradigm
  Completion
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      4つのコンポーネントのパイプラインであるモジュラーベースラインシステムを提供しました。ここで分析を提示し、この共有タスクがこのトピックに関するさらなる研究の基礎となるようにします。提出されたシステムでのみ、最良の結果が得られました。 
[ABSTRACT]システムは、生のテキストと補題のリストを入力として受け取ります。次に、各補題のすべての活用形を生成します。9つの驚きの言語で公式に評価されました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Unsupervised Audio Source Separation using Generative Priors -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/eess.AS/paper_0.html">
      Unsupervised Audio Source Separation using Generative Priors
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは、データドリブンモデリングの最近の進歩を活用し、意味のある事前情報を通じてラベル付きデータの欠如を補うことができる監視されていない方法の必要性を強く強調しています。最先端の未決定のオーディオソース分離システムは監視されたものに依存しています時間またはスペクトル領域のいずれかで動作する注意深く調整されたニューラルネットワークアーキテクチャのエンドエンドトレーニング。WaveGANでは、最適化にスペクトル領域損失関数を使用すると、高品質のソース推定が得られることがわかります。 
[要旨]事前に個々のソースでトレーニングする必要があり、これらの仮定が変更された場合は再トレーニングが必要です。仮定が変更された場合、プロセスには再トレーニングが必要です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Subword RNNLM Approximations for Out-Of-Vocabulary Keyword Search -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/eess.AS/paper_1.html">
      Subword RNNLM Approximations for Out-Of-Vocabulary Keyword Search
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、ベースライン近似を提案された方法で置き換えると、複数文字と単一文字のサブワードの両方で最高のパフォーマンスが得られます。音声認識キーワード検索では、クエリに、音声認識のトレーニング時に観察されない語彙外（OOV）の単語が含まれる場合があります。 system .. Recurrent Neural Network（RNN）LMは、スパース性の問題を軽減しますが、初回パスの認識には適していません。 
[要約]初回パス認識でサブワード言語モデル（lms）を使用すると、oovワードを認識できます。ただし、サブワードn-グラムlmsでもデータのスパース性に悩まされています。このような新しい方法は、サブワード認識用に開発されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Leveraging Text Data Using Hybrid Transformer-LSTM Based End-to-End ASR
  in Transfer Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/eess.AS/paper_2.html">
      Leveraging Text Data Using Hybrid Transformer-LSTM Based End-to-End ASR
  in Transfer Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に重要なこととして、提案されたハイブリッドアーキテクチャは、LSTMとトランスフォーマアーキテクチャの両方と比較して、はるかに高速な推論を提供します。限られたラベル付きデータを使用してトレーニングされます。これから、リソースが豊富な別の言語からの転移学習により、さらに25.4％の相対WER削減が得られます。 
[要約]マレーシアのコーパスで1.5％のテキストを含む実験を行います。これは、合計13％と比較されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Speech-to-Singing Conversion based on Boundary Equilibrium GAN -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/eess.AS/paper_3.html">
      Speech-to-Singing Conversion based on Boundary Equilibrium GAN
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      再現性のために、コードは紙の出版時にGitHubリポジトリで公開されます。私たちの定量的および定性的分析は、提案されたモデルが既存の敵対的訓練を受けていないベースラインよりもはるかに高い自然さを持つ歌声を生成することを示しています。入力、およびオプションでターゲットの歌唱のF0輪郭、提案されたモデルは、漸進的に成長するエンコーダー/デコーダーアーキテクチャと境界平衡GAN損失関数を備えた歌唱信号を出力として生成します。 
[要約]提案されたモデルは、既存の非発声レベルよりもはるかに自然な歌声を生成します。これにより、発声に対する発声の使用を削減するさまざまな方法を開発するために使用できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: DeepSonar: Towards Effective and Robust Detection of AI-Synthesized Fake
  Voices -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/eess.AS/paper_4.html">
      DeepSonar: Towards Effective and Robust Detection of AI-Synthesized Fake
  Voices
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      目の肥えた偽の声におけるDeepSonarの高い検出率（98.1％平均精度）と低い誤警報率（0.02等しいエラー率）を裏付けるために英語と中国語の両方を含みます。この作業では、層ごとのニューロンの力を活用します。実際とAIで合成された偽の声の微妙な違いをキャプチャし、生の入力よりも明確な信号を分類器に提供できるという推測を持つアクティブ化パターン。レイヤー単位のニューロンの動作は、入力間の違いを探す重要な洞察を提供します。安全で堅牢で解釈可能なDNNを構築するために広く採用されています。 
[ABSTRACT]科学者は偽の声の新たな脅威に完全に取り組む準備ができていません。彼らはこの新たな脅威に取り組む準備ができていないと言います
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Bayesian Restoration of Audio Degraded by Low-Frequency Pulses Modeled
  via Gaussian Process -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/eess.AS/paper_5.html">
      Bayesian Restoration of Audio Degraded by Low-Frequency Pulses Modeled
  via Gaussian Process
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文は、パルス位置を一緒に推定することができる新しいベイジアンアプローチを提案します。パルスを開始する強い不連続性の根底にあるほぼ消滅した信号を補間します。また、破損した信号からの抑制を可能にする単純なガウスプロセスによってロングパルステールを推定します。機械装置で古いレコード盤や蓄音機の録音を再生するときに見られる一般的な欠陥は、相互作用によって引き起こされるかなりの低周波成分を含む長いパルスです制御された実験により、提案された方法は、ユーザーの介入が大幅に少なくて済みますが、以前のアプローチと同様の知覚結果が得られ、自然に劣化したものを扱うときにうまく機能することが示されています。シグナル。 
[要約]デジタル録音での抑制に対する以前のアプローチは、パルス位置の事前推定値に依存します。これは通常、ハイレート化された方法で実行されます。以前のロッドロッドロッドは古いモデルパラメーターを生成し、パルスはマルコフによって探索されます-チェーンモンテカルロ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: When Can Self-Attention Be Replaced by Feed Forward Layers? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/eess.AS/paper_6.html">
      When Can Self-Attention Be Replaced by Feed Forward Layers?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これを調査するために、これらの自己注意レイヤーをフィードフォワードレイヤーに置き換えます。これは質問につながります。音声認識の場合、トランスフォーマーのエンコーダーの上部の自己注意レイヤーにとってシーケンス全体のグローバルなビューは依然として重要ですか？ 。私たちの実験は、自己注意層が音声信号をどのように処理するかについての洞察を提供し、エンコーダーの下部自己注意層が十分に広い範囲の入力をエンコードするため、上部層でのさらなるコンテキスト情報の学習は不要であるという結論につながります。 
[要約]音声認識実験で興味深い結果を実際に観察しました。エンコーダーの上部の自己注意レイヤーをフィードフォワードレイヤーで置き換えると、パフォーマンスが低下することはなく、わずかな利益さえあります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Exposure to hypergravity during development leads to altered cartilage material properties and strain distribution in zebrafish. -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/biorxiv.physiology/paper_0.html">
      Exposure to hypergravity during development leads to altered cartilage material properties and strain distribution in zebrafish.
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      予測された変化した株の領域では、軟骨細胞の形態に対する局所的な変化が観察され、重力の変化が軟骨細胞の成熟に影響し、最終的には軟骨の構造と機能に変化をもたらすことを示唆しています。体と多くの組織の構造と機能に影響を与えます。しかし、顎軟骨の機械的性質の変化を観察しました。 
[要約]微小重力が筋肉と骨のホメオスタシスに及ぼす影響は十分に説明されています。これらの重力場への短時間の曝露によるこれらの影響はあまり特徴付けられていません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Proteomic Profiling of the Human Dentin Identifies Age-Related Differences in the Composition and Solubility of the Matrisome -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-29/biorxiv.physiology/paper_1.html">
      Proteomic Profiling of the Human Dentin Identifies Age-Related Differences in the Composition and Solubility of the Matrisome
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの研究は、高齢化した歯のバイオマーカーの発見と、高齢化人口の健康な歯列を維持または再生するための戦略の開発に向けた最初のステップです。対処するために、プロテオミクスを使用して、若年および高齢の成人のヒトの象牙質ECMのプロファイルを作成しました。歯..加齢は、時間の経過とともに生体内で発生する進行性の生理学的変化の結合です。 
[要約]現在のところ、象牙質ECMの組成とそれが年齢とともにどのように変化するかは不明です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br>2020-05-28
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
