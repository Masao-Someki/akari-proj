<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-08-20の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: HpRNet : Incorporating Residual Noise Modeling for Violin in a
  Variational Parametric Synthesizer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.SD/paper_0.html">
      <font color="black">HpRNet : Incorporating Residual Noise Modeling for Violin in a
  Variational Parametric Synthesizer</font>
    </a>
  </h2>
  <font color="black">持続音のスペクトル包絡線の変分符号化の過程で導出された潜在空間の観察を通じて、信号の各高調波成分と残差成分、およびそれらの相互依存性に関する洞察を取得します。この作業では、バイオリントーンのパラメトリックモデル、特に残留ボウノイズの生成モデリングにより、より自然な音質を実現します。最近では、オーディオ信号のパラメトリック表現が組み込まれ、合成された出力の音楽的な制御が容易になりました。 
[要約]オーディオ信号のパラメトリック表現が組み込まれ、生成された出力のより良い音楽制御を容易にします。より良い音楽空間を可能にするために、ノイズのパラメトリックモデルが導入されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: LIRA: Lifelong Image Restoration from Unknown Blended Distortions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_0.html">
      <font color="black">LIRA: Lifelong Image Restoration from Unknown Blended Distortions</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案されたアプローチが両方のPSNR / SSIMメトリックの混合歪み除去タスクで最先端のパフォーマンスを実現できるだけでなく、新しい復元タスクを学習しながら古い専門知識を維持できることを示しています。人間の記憶システムの成人の神経発生に触発された新しい歪みは、以前に訓練されたモデルが新しいエキスパートブランチを組み込み、学習された知識に干渉することなく継続的に新しい知識を蓄積できる神経成長戦略を開発します。最初にベースフォークジョインモデルを設計します個々の歪み除去タスクに特化した複数の事前トレーニング済みエキスパートモデルが協調的かつ適応的に機能して、混合された歪みを処理します。 
[ABSTRACT]問題の学習に加えて、ブレンドされた歪みの新しいモデルを上げます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Correcting Data Imbalance for Semi-Supervised Covid-19 Detection Using
  X-ray Chest Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_1.html">
      <font color="black">Correcting Data Imbalance for Semi-Supervised Covid-19 Detection Using
  X-ray Chest Images</font>
    </a>
  </h2>
  <font color="black">データの不均衡を修正する簡単なアプローチを提案し、損失関数の各観測値に重みを付け、表現不足のクラスに対応する観測値に高い重みを与えます。この作業では、既知の半教師ありディープラーニングアーキテクチャのパフォーマンスを評価します。非常に限られた数のラベル付き観測と非常に不均衡なラベル付きデータセットを使用するMixMatchとして。さらに、新しい高感染性疾患のコンテキストでは、データセットも非常に不均衡であり、新しい疾患の陽性症例からの観測はほとんどありません。 
[要約]胸部x線の画像分類のための深層学習の適用-covidの線画像-19人の患者が新しい診断前検出法になる可能性がある</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Detector tilt considerations in high-energy Bragg coherent diffraction
  imaging: a simulation study -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_2.html">
      <font color="black">Detector tilt considerations in high-energy Bragg coherent diffraction
  imaging: a simulation study</font>
    </a>
  </h2>
  <font color="black">このような傾斜した検出器の存在下で合成散乱体からの物理的に正確な回折シミュレーションを使用して、観測された信号の歪みの一般的な性質を定性的および定量的に分析し、画像再構成中に修正する処方を提供します。このような構成変更とその数値的対策は、従来とは異なるコヒーレント回折測定構成を実現し、将来的には新規の材料特性化実験の道を開く上で価値がある可能性があります。コヒーレント回折信号の取得中にブラッグ回折ビームに垂直。 
[ABSTRACT] bcdiの合成バージョンは、bcdiサンプリング領域の既知の理論の適応に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Enhanced MRI Reconstruction Network using Neural Architecture Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_3.html">
      <font color="black">Enhanced MRI Reconstruction Network using Neural Architecture Search</font>
    </a>
  </h2>
  <font color="black">さらに、同種アーキテクチャはネットワークの表現能力を低下させます。基本ブロックの各セルに対して、微分可能ニューラルアーキテクチャ検索（NAS）技術を使用して、密ブロックの8つのバリアントから最適な操作を自動的に選択します。作業では、残差基本ブロックの残差を使用して拡張MRI再構成ネットワークを提示します。 
[ABSTRACT] mri再構成用のカスケードネットワークアーキテクチャは広く使用されています。ネットワークが深くなると、「消失勾配」の問題が発生します。この作業では、強化されたmri再構成ネットワークを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: DONet: Dual Objective Networks for Skin Lesion Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_4.html">
      <font color="black">DONet: Dual Objective Networks for Skin Lesion Segmentation</font>
    </a>
  </h2>
  <font color="black">私たちのDONetは、2つの対称デコーダーを採用して、異なる目的に近づくための異なる予測を生成します。皮膚病変のセグメンテーションは、ダーモスコープ画像のコンピューター支援診断における重要なステップです。このように、2つのデコーダーは、一致する異なる確率マップを生成することが推奨されます。異なる最適化ターゲット、それに応じて補完的な予測になります。 
[要約]ディープラーニングベースのセマンティックセグメンテーションファクターは、皮膚病変の結果を大幅に進歩させました。過去数年間、私たちは、皮膚病変のセグメンテーションを改善するために、donetという名前のシンプルで効果的なフレームワークを提案します。2つの目的は、実際には異なる損失関数</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: A 3D Motion Vector Database for Dynamic Point Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_5.html">
      <font color="black">A 3D Motion Vector Database for Dynamic Point Clouds</font>
    </a>
  </h2>
  <font color="black">この作業の目的は、動的な点群の圧縮などのさまざまな目的に使用できる、この一般に入手可能な3Dモーションベクトルデータベースについて説明することです。点群が表す大量のデータと、連続するジオメトリの違いにより、フレーム、ポイントクラウドデータセット全体のモーションベクトルの生成には、かなりの時間と計算リソースが必要になる場合があります。このデータベースには、M = 8およびM = 16のモーションベクトルが含まれています。
[要旨]モーションポイントクラウドデータセットには、 3Dモーションポイントデータベース。モーションポイントデータセットは、すべてのフレームのデータベースを作成するために使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Blur-Attention: A boosting mechanism for non-uniform blurred image
  restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_6.html">
      <font color="black">Blur-Attention: A boosting mechanism for non-uniform blurred image
  restoration</font>
    </a>
  </h2>
  <font color="black">条件付き生成敵対フレームワークにブラーアテンションネットワークを導入することにより、エンドツーエンドのブラインドモーションのブレ除去方法、つまり単一の画像のブラーアテンションGAN（BAG）を提案します。モジュールはDenseBlockユニットで構成されています空間的に変化する複雑なぼかし特徴を効果的に抽出できるマルチプーリング機能フュージョンを備えた空間注意ユニット。複数レベルの残差接続構造を設計して、複数のぼかし注意モジュールを接続し、ぼかし注意ネットワークを形成します。 
[ABSTRACT]不鮮明-アテンションモジュールは、ソフトウェアの最適なツールとして宣伝されています。不均衡な有用な方法を正確に推定することは困難です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Stabilizing Deep Tomographic Reconstruction Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_7.html">
      <font color="black">Stabilizing Deep Tomographic Reconstruction Networks</font>
    </a>
  </h2>
  <font color="black">私たちの実験では、ACIDは3種類の不安定性をすべて排除し、前述のPNAS調査の方法に比べて画質を大幅に改善しました。ここでは、この課題に根本的に取り組むための分析、圧縮、反復ディープ（ACID）ネットワークを提案します。 ACIDは、ビッグデータでトレーニングされたディープリコンストラクションネットワーク、高度な最適化によるCS、ワークフロー全体を安定させる反復的な改良のユニークな組み合わせから生まれます。 
[ABSTRACT]不安定性には、小さな摂動による強力な出力アーティファクト、小さな特徴の検出不良、入力データの増加によるパフォーマンスの低下が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: DIRECT-Net: a unified mutual-domain material decomposition network for
  quantitative dual-energy CT imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_8.html">
      <font color="black">DIRECT-Net: a unified mutual-domain material decomposition network for
  quantitative dual-energy CT imaging</font>
    </a>
  </h2>
  <font color="black">具体的には、提案されたDIRECT-Netは相互ドメインデータに即座にアクセスでき、ノイズ低減と材料分解のためにスタックされた畳み込みニューラルネットワーク（CNN）レイヤーを利用します。サイノグラムまたはCT画像の事前情報を組み込んだ反復DECT画像再構成アルゴリズムは、は、ノイズとアーチファクトの抑制において潜在的な利点を示しましたが、計算リソースが大きくなり、再構築時間が長くなり、アルゴリズムパラメータを手作業で面倒に選択する必要がありました。別個のX線スペクトルで2セットの断層撮影測定を取得することにより、デュアルエネルギーCT （DECT）は、材料固有の定量的なイメージングを可能にします。 
[ABSTRACT]ネットワークはドメインコンピューティングアルゴリズムを使用して高品質のdectマテリアル分解を実行します。結果はdectイメージングの基礎となる物理学に基づいて数値的にシミュレーションされます。xcatデジタルファントム、ヨウ素溶液ファントム、および生物学的未来は、検証に使用されますダイレクト-ネットのパフォーマンス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Universal bounds for imaging in scattering media -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_9.html">
      <font color="black">Universal bounds for imaging in scattering media</font>
    </a>
  </h2>
  <font color="black">循環およびDMPKランダムマトリックスアンサンブルから得られた数値例を使用して、導出された境界の有効性を説明します。大きな$ N $の漸近制限では、チャネル容量の上限はバイモーダルの上限によってよく近似されていることが示されています最後に、相互情報量とチャネル容量は伝送固有値の非線形統計であることが示されていますが、中心極限定理の存在が示され、議論されています。 
[ABSTRACT]普遍的な作業は、媒体の平均透過率に基づいています。チャネル容量は、透過固有値の非線形統計であることが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-26">
        <br><font color="black">2020-02-26</font>
      </time>
    </span>
</section>
<!-- paper0: Slide-free MUSE Microscopy to H&E Histology Modality Conversion via
  Unpaired Image-to-Image Translation GAN Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_10.html">
      <font color="black">Slide-free MUSE Microscopy to H&E Histology Modality Conversion via
  Unpaired Image-to-Image Translation GAN Models</font>
    </a>
  </h2>
  <font color="black">CycleGANとGANILLAは、H＆Eスタイルを適切に転送し、MUSEコンテンツを保持する視覚的に説得力のある結果を提供しました。画像では、CycleGANが最高のパフォーマンスを発揮すると判断しました。 
[要旨]ミューズ画像は、ヘマトキシリンおよびエオシン染色（h＆e）画像に類似するように変換できます。また、ミュール色の反転がハラール変換に必要なステップである可能性があることもわかりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Blind Spot Denoising for Microscopy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_11.html">
      <font color="black">Improving Blind Spot Denoising for Microscopy</font>
    </a>
  </h2>
  <font color="black">最近、ノイズ統計についての仮定を行うことにより、自己監視法が出現しました。光学顕微鏡画像は通常回折限界であることを考慮して、この知識をノイズ除去プロセスに含めることを提案します。ここでは、ノイズを改善する新しい方法を提示します。自己管理型ノイズ除去の品質。 
[ABSTRACT]問題は多くの場合、（教師あり）深層学習に基づいて解決されます。これらの方法は、ノイズ除去される画像で直接トレーニングされます。これらの結果には、追加のペアのトレーニングデータは必要ありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Scene Text Detection with Selected Anchor -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_12.html">
      <font color="black">Scene Text Detection with Selected Anchor</font>
    </a>
  </h2>
  <font color="black">Faster RCNNのアンカーベースのRPNを置き換えることにより、AS-RPNベースのFaster RCNNは、COCO-Text、ICDAR2013、ICDAR2015、MSRA-などの標準ベンチマークで、従来の最先端のテキスト検出アプローチと同等のパフォーマンスを実現できます。単一スケールおよび単一モデル（ResNet50）テストのみを使用する場合のTD500。これにより、精度は大幅に向上しますが、計算による検索、回帰、および分類の無駄になります。シーンテキスト検出用の高密度アンカースキームを使用したオブジェクト提案手法は、高い再現率を実現します。 
[要旨]アンカーは、新しい手法で精度を向上させることができます。品質が低いことが原因である可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: On the inverse Potts functional for single-image super-resolution
  problems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_13.html">
      <font color="black">On the inverse Potts functional for single-image super-resolution
  problems</font>
    </a>
  </h2>
  <font color="black">私たちの数値結果は、超解像と勾配スパース性の組み合わせが、オブジェクトの検出とラベリングタスク（QRスキャンや土地被覆分類など）に特に役立つことを示しています。これらの結果は、標準のクラスタリングアルゴリズムと状態の分類精度を向上させることが示されています。最先端のディープアーキテクチャ
[3] .. 
[1]、
[2]とは異なり、多変量データの場合に非凸サブステップを解決するために近似グラフカットと動的プログラミング手法が使用され、提案された分割によりハードしきい値と標準の共役勾配ソルバーを使用してそれらの解を明示的に計算します。ターゲット画像の画像勾配がまばらであるという仮定に基づいて、単一画像超解像の変分モデルを検討します。 
[ABSTRACT]提案された分割により、2歳の子供が一緒に作業できるようになります。これは、複数のタイプの共役に基づいています-ユーザーデータ。単一のモデルの作成にも使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Model-Based Reconstruction for Simultaneous Multi-Slice T1 Mapping using
  Single-Shot Inversion-Recovery Radial FLASH -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_14.html">
      <font color="black">Model-Based Reconstruction for Simultaneous Multi-Slice T1 Mapping using
  Single-Shot Inversion-Recovery Radial FLASH</font>
    </a>
  </h2>
  <font color="black">方法：SMS励起は、データ取得のためにシングルショットIRラジアルフラッシュシーケンスと組み合わせられます。提案された方法の検証は、ファントムと、6人の健康な成人被験者の人間の脳と肝臓に対して行われます。以前に開発されたシングルスライスキャリブレーションなしのモデルベースの再構築はSMSに拡張され、パラメーターマップの推定とすべてのスライスからのコイル感度を単一の非線形逆問題として定式化します。 
[ABSTRACT]データ収集のためのシングルショットirディジットフラッシュシーケンスの分析。計算は、シングルショットirファンネルフラッシュシーケンスと組み合わされます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-23">
        <br><font color="black">2019-09-23</font>
      </time>
    </span>
</section>
<!-- paper0: "Name that manufacturer". Relating image acquisition bias with task
  complexity when training deep learning models: experiments on head CT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_15.html">
      <font color="black">"Name that manufacturer". Relating image acquisition bias with task
  complexity when training deep learning models: experiments on head CT</font>
    </a>
  </h2>
  <font color="black">分類とセグメンテーションの両方のタスク、具体的には2つの最先端のモデルの畳み込みニューラルネットワーク（CNN）を評価します。分類にはResNet 
[2]、セグメンテーションにはU-Net 
[3]を使用します。多かれ少なかれ微妙な病変の存在を模倣する脳データは、このバイアスが課題の難しさに関連していることも示しています。医用画像に機械学習技術を適用することへの関心が急速に高まり続けているため、モデルは臨床アプリケーション用に開発および展開されています。 
[要旨]このステップでは、さまざまな形のバイアスを認識する能力が重要です。cnnsは、イメージングスキャナーの製造元を区別する方法を学ぶことができます。このバイアスは、ニューラルネットワークとネットワークの両方のモデルパフォーマンスに大きな影響を与える可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Black Re-ID: A Head-shoulder Descriptor for the Challenging Problem of
  Person Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_16.html">
      <font color="black">Black Re-ID: A Head-shoulder Descriptor for the Challenging Problem of
  Person Re-Identification</font>
    </a>
  </h2>
  <font color="black">この問題をブラックRe-ID問題と呼びます。人物の再識別（Re-ID）は、複数のカメラでキャプチャされた一連の画像から入力人物画像を取得することを目的としています。この問題を解決するには、衣服に頼るのではなく情報、私たちは人の再IDを支援するためにヘッドショルダー機能を活用することを提案します。 
[ABSTRACT] re-idメソッドは大きな成功を収めましたが、それらのほとんどは衣服の属性の観点から特徴を抽出します。頭-肩適応型再識別ネットワーク-は、入力を学習するために提案されています。このメソッドは、モデルの一般化</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Uncertainty Analysis in SPECT Reconstruction based on Probabilistic
  Programming -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_17.html">
      <font color="black">Uncertainty Analysis in SPECT Reconstruction based on Probabilistic
  Programming</font>
    </a>
  </h2>
  <font color="black">非Uターンサンプラー（NUTS）は、不確実性を考慮してスキャンされたオブジェクトシステムを推定するために使用されます。ただし、128x128x128ボクセル以上のファントムサイズでは、再構成時間を改善する必要があります。従来の再構成アルゴリズムでは、コリメータの視野によって導入されたプロセス。 
[ABSTRACT]データの分析は、現在の作業に不確実性が含まれる可能性があることを示しています。データは、作業が分析分析に使用できることを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Axiom-based Grad-CAM: Towards Accurate Visualization and Explanation of
  CNNs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_18.html">
      <font color="black">Axiom-based Grad-CAM: Towards Accurate Visualization and Explanation of
  CNNs</font>
    </a>
  </h2>
  <font color="black">一方、専用のAxiomベースのGrad-CAM（XGrad-CAM）は、これらの公理を可能な限り満たすために提案されています。実験により、XGrad-CAMが保存と感度の点でGrad-CAMの拡張バージョンであることが示されています。特に、CNNの決定と画像領域の間の関係を発見するために、いくつかのクラスアクティベーションマッピング（CAM）メソッドが提案されています。 
[要約]コードはwwwから入手できます。 github。 com / fu0511 / xgrad-cam。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Volumetric Ambient Occlusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_19.html">
      <font color="black">Deep Volumetric Ambient Occlusion</font>
    </a>
  </h2>
  <font color="black">提案されたニューラルネットワークは、このグローバル情報の変更時にのみ実行する必要があるため、リアルタイムのボリューム相互作用をサポートします。可能な限り最高の結果を達成するために、ディープニューラルネットワークのさまざまな伝達関数表現と注入戦略を提案および分析します..直接的なボリュームレンダリングのコンテキストで、ボリュームアンビエントオクルージョンのための新しいディープラーニングベースの手法を紹介します。 
[ABSTRACT]新しいアプローチは、伝達関数を介して提供されるグローバル情報を考慮しながら、ボリュームデータセット内のボクセルごとのアンビエントオクルージョンを予測できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Controllable Backlight Dimming -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_20.html">
      <font color="black">Deep Controllable Backlight Dimming</font>
    </a>
  </h2>
  <font color="black">デュアルパネルディスプレイは、高忠実度とハイダイナミックレンジでコンテンツを再生するためにローカル調光アルゴリズムを必要とします。提案された方法は、さまざまな定量的品質メトリックを使用して、105のHDR画像のテストセットで他の6つの方法に対して評価されます。この方法では、畳み込みニューラルネットワークを使用して、表示するHDR画像を入力として使用し、バックライト値を予測します。 
[要約]デュアルパネルhdrディスプレイでhdr画像をレンダリングするための新しい方法が提案されています。モデルは制御可能な電動工具によって設計およびトレーニングされています。結果は、表示品質の向上とローカル調光の改善を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Relighting Networks for Image Light Source Manipulation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_21.html">
      <font color="black">Deep Relighting Networks for Image Light Source Manipulation</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案された方法が他の可能な方法よりも質的および量的に優れていることを示しています。具体的には、提案されたDRNは、2020 ECCV会議の「AIM2020-Any to one relighting challenge」で最高のPSNRを達成しました。光源の操作与えられた画像の編集は興味深い作業であり、写真や映画撮影などのさまざまなアプリケーションで役立ちます。 
[ABSTRACT]新しい方法は、より多くの情報を必要とする既存の方法を使用します。これらには、シーンの詳細な詳細画像が含まれ、利用できない場合があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Development of novel algorithm to visualize blood vessels on 3D
  ultrasound images during liver surgery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_22.html">
      <font color="black">Development of novel algorithm to visualize blood vessels on 3D
  ultrasound images during liver surgery</font>
    </a>
  </h2>
  <font color="black">肝臓の血管にはさまざまな形状があり、超音波画像にノイズが存在するため、ノイズと混同される可能性があります。これらの制限を克服するために、ノイズの多いBモード超音波画像の効果的な3D視覚化を提供できるボリューム視覚化のアルゴリズムは、超音波システムは用途が広く、携帯可能であり、手術室で使用できるという利点があります。 
[要約] 2D画像の代わりに3Dデータセットを使用すると、解剖学的構造の視覚化が向上します。ボリュームの視覚化により、放射線科医や外科医は大きなデータセットを確認できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Graudally Applying Weakly Supervised and Active Learning for Mass
  Detection in Breast Ultrasound Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_23.html">
      <font color="black">Graudally Applying Weakly Supervised and Active Learning for Mass
  Detection in Breast Ultrasound Images</font>
    </a>
  </h2>
  <font color="black">モデルのトレーニング後にアクティブ学習を実行すると、CorLocがさらに増加しました。実験結果では、適切に制御された重みを割り当てることにより、正確にローカライズされ分類された画像の比率である正しいローカリゼーション（CorLoc）指標が24％増加しました。 .. 2段階のオブジェクト検出モデルで、弱く注釈が付けられた画像の影響を処理するために、制御された重みを提案します。 
[ABSTRACT]オブジェクト検出モデルのトレーニングは重要な問題になります。トレーニング済みモデルを使用して、アノテーション付き画像に強力なアノテーションを安全に割り当てるためのアクティブな学習スキームも紹介します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Objective CNN Based Algorithm for SAR Despeckling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_24.html">
      <font color="black">Multi-Objective CNN Based Algorithm for SAR Despeckling</font>
    </a>
  </h2>
  <font color="black">これは、3つの異なる用語の重み付けされた組み合わせによって得られる固有の損失関数の定義によって達成されます。これらのソリューションのほとんどは、SAR画像のプロパティを含まない同様のコスト関数を持つ異なるネットワークアーキテクチャの定義に焦点を当てています。そのようなことを考慮することの重要性コスト関数のSARプロパティは、均一、不均一、および非常に不均一など、さまざまな下線が引かれたシナリオでの正しいノイズ除去と詳細保持のために重要です。 
[要約] sar画像の重要な解釈が原因で、dlテクニックの適用は簡単ではありません。これらのソリューションの多くは、sar画像のプロパティを含まない同様のコスト関数を持つ異なるネットワークアーキテクチャの定義に焦点を当てています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-16">
        <br><font color="black">2020-06-16</font>
      </time>
    </span>
</section>
<!-- paper0: DIR-DBTnet: Deep iterative reconstruction network for 3D digital breast
  tomosynthesis imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.IV/paper_25.html">
      <font color="black">DIR-DBTnet: Deep iterative reconstruction network for 3D digital breast
  tomosynthesis imaging</font>
    </a>
  </h2>
  <font color="black">結果：数値データと実験データの両方で、提案されたDIR-DBTnetは、フィルター処理された逆投影（FBP）および全変動（TV）メソッドと比較して、面内シャドウアーティファクトと面外アーティファクトを低減します。数値および実験結果の分析は、FBPおよび反復アルゴリズムよりも優れたDBTイメージングパフォーマンスを示します。アーチファクト拡散関数（ASF）、乳房密度、信号のノイズ比（SDNR）などの定量的メトリックは、画質に使用されます。評価。 
[要約] dir-dbtnetは、標準のfbp再構築アルゴリズムを展開することによって開発されました。特に、深い反復再構築ネットワークが提案されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: LIRA: Lifelong Image Restoration from Unknown Blended Distortions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_0.html">
      <font color="black">LIRA: Lifelong Image Restoration from Unknown Blended Distortions</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案されたアプローチが両方のPSNR / SSIMメトリックの混合歪み除去タスクで最先端のパフォーマンスを達成できるだけでなく、新しい専門家のタスクを学習しながら古い専門知識を維持できることを示しています。人間の記憶システムにおける成人の神経発生に触発された新しい歪みは、以前に訓練されたモデルが新しいエキスパートブランチを組み込み、学習された知識を妨げることなく継続的に新しい知識を蓄積できる神経成長戦略を開発します。この問題を緩和するために、小説を混合歪みの生涯画像復元問題。 
[ABSTRACT]問題の学習に加えて、ブレンドされた歪みの新しいモデルを上げます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Addressing Neural Network Robustness with Mixup and Targeted Labeling
  Adversarial Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_1.html">
      <font color="black">Addressing Neural Network Robustness with Mixup and Targeted Labeling
  Adversarial Training</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、Mixupの強化と、Targeted Labeling Adversarial Training（TLAT）と呼ばれる新しい敵対的なトレーニングアルゴリズムを組み合わせています。最も伝統的な一般的な破損と敵対的な例をカバーする幅広い摂動から保護する防御を構築する必要があります。ノイズ、回転、ぼかし、敵対的な例に敏感です。 
[ABSTRACT] m-tlat.itと呼ばれる新しいデータ拡張戦略を提案します。これは、広義の堅牢性に対処するように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Human Body Model Fitting by Learned Gradient Descent -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_2.html">
      <font color="black">Human Body Model Fitting by Learned Gradient Descent</font>
    </a>
  </h2>
  <font color="black">このデータから、ネットワークは、最適化がはるかに効率的に実行される有効なポーズと形状の部分空間を学習します。このアルゴリズムが高速であることを経験的に示します（平均。このアプローチでは、画像と3Dの対応を取得するのに難しいことは必要ありません。 
[ABSTRACT]システムは、数回の予測に使用できるアルゴリズムに基づいていますが、画像から3D画像などの3D対応は必要ありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: No-reference Quality Assessment with Unsupervised Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_3.html">
      <font color="black">No-reference Quality Assessment with Unsupervised Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">実験により、この方法では、軽量の畳み込みニューラルネットワークに基づいて、さまざまなソースとターゲットの設定でより高いパフォーマンスを実現できることが示されています。他のドメインのコンテンツへの適応能力が不足しています。このホワイトペーパーでは、自然シーンの品質を、光学カメラで取得されていない画像（スクリーンコンテンツ画像、SCIなど）に転送する機能を模索しています。人間の視覚システムが自然環境の知覚を通じて適応し進化したという広く受け入れられている見解。 
[ABSTRACT]一般に、品質予測モデルをnisから新しいタイプのデータに直接転送することは簡単な作業ではありません。提案された方法は、目に見えないアプリケーションの品質評価指標の学習に光を当てます-煩わしくなく、特定のコンテンツ主観的評価のコスト</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Virtual Adversarial Training in Feature Space to Improve Unsupervised
  Video Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_4.html">
      <font color="black">Virtual Adversarial Training in Feature Space to Improve Unsupervised
  Video Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">また、エントロピー最小化の不安定な動作と決定境界反復改良トレーニングをドメイン適応の教師と話し合い、同様の動作を実現する代替を提案します。仮想敵対トレーニングは最近、半教師あり学習でも多くの成功を収めています。教師なしドメイン適応として。ただし、これまではピクセル空間の入力サンプルで使用されてきましたが、特徴ベクトルに直接適用することを提案します。 
[要約]最先端のモデルは、複数の教師なしビデオドメイン適応タスクで使用されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Correcting Data Imbalance for Semi-Supervised Covid-19 Detection Using
  X-ray Chest Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_5.html">
      <font color="black">Correcting Data Imbalance for Semi-Supervised Covid-19 Detection Using
  X-ray Chest Images</font>
    </a>
  </h2>
  <font color="black">さらに、テスト済みのデータセットには、コスタリカの成人患者の胸部X線画像で構成される新しいデータセットが含まれています。さらに、新しい高感染性疾患のコンテキストでは、データセットも非常に不均衡であり、新しい疾患のポジティブケースからの観察はほとんどありません。この作業では、非常に限られた数のラベル付き観測と非常に不均衡なラベル付きデータセット。 
[要約]胸部x線の画像分類のための深層学習の適用-covidの線画像-19人の患者が新しい診断前検出法になる可能性がある</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: CosyPose: Consistent multi-view multi-object 6D pose estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_6.html">
      <font color="black">CosyPose: Consistent multi-view multi-object 6D pose estimation</font>
    </a>
  </h2>
  <font color="black">3番目に、複数のオブジェクトの仮説とビュー間のそれらの対応が与えられた場合のグローバルシーンリファインメントの方法を開発します。カメラの視点が不明な一連の入力画像によってキャプチャされたシーン内の複数の既知のオブジェクトの6Dポーズを復元する方法を紹介します。これは、すべてのビューでの再投影エラーを最小限に抑えるためにカメラとオブジェクトのポーズを調整するオブジェクトレベルのバンドル調整問題を解決することによって実現されます。 
[要旨] 6dオブジェクトの仮説を生成するために使用する単一オブジェクトの6dポーズ推定方法を提示します。このメソッドを使用して6dオブジェクトの仮説を作成します。これは、ポーズを微調整するオブジェクトレベルのバンドル調整問題を解決することによって達成されますすべてのビューでの再投影エラーを最小限に抑えるためのカメラとオブジェクトの配置</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Apply VGGNet-based deep learning model of vibration data for prediction
  model of gravity acceleration equipment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_7.html">
      <font color="black">Apply VGGNet-based deep learning model of vibration data for prediction
  model of gravity acceleration equipment</font>
    </a>
  </h2>
  <font color="black">この論文で提案された方法は、振動信号をスペクトログラムに変換し、ディープラーニングモデルを使用して分類トレーニングを実行することでした。この論文で提案された方法のパフォーマンスを評価する実験が行われました。4チャネルの加速度計が回転子であるベアリングハウジングと時間-振幅データは、サンプリングによって測定値から得られました。 
[要約]提案された方法は、振動信号をスペクトログラムに変換し、ディープラーニングモデルを使用して分類トレーニングを実行することでした</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-22">
        <br><font color="black">2020-05-22</font>
      </time>
    </span>
</section>
<!-- paper0: A Generalization of Otsu's Method and Minimum Error Thresholding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_8.html">
      <font color="black">A Generalization of Otsu's Method and Minimum Error Thresholding</font>
    </a>
  </h2>
  <font color="black">一般化ヒストグラムしきい値（GHT）を紹介します。これは、ヒストグラムベースの画像しきい値処理のためのシンプルで高速かつ効果的な手法です。GHTは、3つの古典的なしきい値処理手法を特別なケースとして包括していることを示します。大津法、最小誤差しきい値処理（MET）、および重み付けパーセンタイルしきい値処理.. GHTは、手書きのドキュメントイメージの2値化（ピクセルごとの2値化を生成するようにトレーニングされたディープニューラルネットワークを含む）の最近の課題について、すべてのアルゴリズムのパフォーマンスよりも優れているか、一致し、数十行のコードまたは大津の方法またはMETへのささいな修正として。 
[ABSTRACT] ghtは、適切な事前分布を持つガウス分布の混合の正確な最大事後推定を実行することによって機能します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-14">
        <br><font color="black">2020-07-14</font>
      </time>
    </span>
</section>
<!-- paper0: Enhanced MRI Reconstruction Network using Neural Architecture Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_9.html">
      <font color="black">Enhanced MRI Reconstruction Network using Neural Architecture Search</font>
    </a>
  </h2>
  <font color="black">さらに、同種アーキテクチャはネットワークの表現能力を低下させます。基本ブロックの各セルに対して、微分可能ニューラルアーキテクチャ検索（NAS）技術を使用して、密ブロックの8つのバリアントから最適な操作を自動的に選択します。作業では、残差基本ブロックの残差を使用して拡張MRI再構成ネットワークを提示します。 
[ABSTRACT] mri再構成用のカスケードネットワークアーキテクチャは広く使用されています。ネットワークが深くなると、「消失勾配」の問題が発生します。この作業では、強化されたmri再構成ネットワークを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Lightweight Lane Detection by Optimizing Spatial Embedding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_10.html">
      <font color="black">Towards Lightweight Lane Detection by Optimizing Spatial Embedding</font>
    </a>
  </h2>
  <font color="black">柔軟なオブジェクト形状、オクルージョン、リアルタイムアプリケーションへの適応性があるため、多くのレーン検出方法は提案なしのインスタンスセグメンテーションに依存しています。たたみ込みの長所の1つである畳み込みの並進不変性は、最適化に課題を引き起こします。 pixel embedding ..私たちの提案する方法は、中心位置特定のための後処理ステップを可能にし、エンドツーエンドの方法でクラスタリングを最適化します。 
[要約]提案された方法は、リアルタイムのシンプルさと軽量バックボーンの採用により、リアルタイムのレーン検出を可能にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: DONet: Dual Objective Networks for Skin Lesion Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_11.html">
      <font color="black">DONet: Dual Objective Networks for Skin Lesion Segmentation</font>
    </a>
  </h2>
  <font color="black">私たちのDONetは、2つの対称デコーダーを採用して、異なる目的に近づくための異なる予測を生成します。具体的には、2つの目的は実際には異なる損失関数によって定義されます。さらに、ダーモスコピック画像におけるさまざまな病変のスケールと形状の課題に対処するために、さらに反復的なコンテキストエンコーディングモジュール（RCEM）を提案して、皮膚病変間の複雑な相関関係をモデル化します。異なるスケールコンテキストの機能を効率的に統合して、より堅牢な表現を形成します。 
[要約]ディープラーニングベースのセマンティックセグメンテーションファクターは、皮膚病変の結果を大幅に進歩させました。過去数年間、私たちは、皮膚病変のセグメンテーションを改善するために、donetという名前のシンプルで効果的なフレームワークを提案します。2つの目的は、実際には異なる損失関数</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Blur-Attention: A boosting mechanism for non-uniform blurred image
  restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_12.html">
      <font color="black">Blur-Attention: A boosting mechanism for non-uniform blurred image
  restoration</font>
    </a>
  </h2>
  <font color="black">条件付き生成敵対フレームワークにブラーアテンションネットワークを導入することにより、エンドツーエンドのブラインドモーションデブラー手法、つまり単一の画像のブラーアテンションGAN（BAG）を提案します。マルチレベルの残差を設計します。複数のブラーアテンションモジュールを接続してブラーアテンションネットワークを形成するための接続構造。モジュールは、DenseBlockユニットとマルチプーリング機能フュージョンを備えた空間アテンションユニットで構成され、空間的に変化する複雑なブラー機能を効果的に抽出できます。 
[ABSTRACT]不鮮明-アテンションモジュールは、ソフトウェアの最適なツールとして宣伝されています。不均衡な有用な方法を正確に推定することは困難です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Anchor-free Small-scale Multispectral Pedestrian Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_13.html">
      <font color="black">Anchor-free Small-scale Multispectral Pedestrian Detection</font>
    </a>
  </h2>
  <font color="black">このようにして、ネットワークアーキテクチャを簡素化し、特に閉塞または低オブジェクト解像度での歩行者に対して、より高い検出パフォーマンスを実現できます。現在の最高の状態と比較して、5.68％のログ平均ミス率を達成します。挑戦的なKAISTマルチスペクトル歩行者検出ベンチマークの7.49％（25％改善）の芸術。私たちは、直接の境界ボックス予測ではなく、オブジェクトの中心とスケールに基づいて歩行者表現を学習することを目指しています。 
[ABSTRACT]これらのデータは、歩行者検出のパフォーマンスを向上させるために使用できます。これは、小規模な、または部分的に遮蔽されたケースに基づいています。結果は、小規模な歩行者の検出における私たちの方法の技術を示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Stabilizing Deep Tomographic Reconstruction Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_14.html">
      <font color="black">Stabilizing Deep Tomographic Reconstruction Networks</font>
    </a>
  </h2>
  <font color="black">ACIDの威力は、ビッグデータでトレーニングされたディープリコンストラクションネットワーク、高度な最適化によるCS、ワークフロー全体を安定させる反復改良のユニークな組み合わせに由来します。実験では、ACIDは3種類の不安定性をすべて排除し、画質を大幅に改善しました前述のPNAS研究の方法と比較して。ここでは、この課題に根本的に対処するための分析的、圧縮的、反復的深層（ACID）ネットワークを提案します。 
[ABSTRACT]不安定性には、小さな摂動による強力な出力アーティファクト、小さな特徴の検出不良、入力データの増加によるパフォーマンスの低下が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Breast Cancer Detection Using Convolutional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_15.html">
      <font color="black">Breast Cancer Detection Using Convolutional Neural Networks</font>
    </a>
  </h2>
  <font color="black">テストデータセットでのモデルのパフォーマンスは次のとおりです：検出精度91.86％、感度94.67％、AUC-ROC 92.2％。私たちのモデルは質量領域を検出し、マンモグラム（MG）画像の良性または悪性の異常に分類します。提案されたモデルでは、MG画像はさまざまな病院から局所的に収集されました。画像はガウシアンフィルター、中央値フィルター、バイラテラルフィルターなどのさまざまな前処理段階を通過し、MGの背景から乳房の領域を抽出しました画像。 
[ABSTRACT]エチオピアの診断手法は手動ですが、習得が困難です。cnnアーキテクチャは、特徴抽出段階用に設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-17">
        <br><font color="black">2020-03-17</font>
      </time>
    </span>
</section>
<!-- paper0: EASTER: Efficient and Scalable Text Recognizer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_16.html">
      <font color="black">EASTER: Efficient and Scalable Text Recognizer</font>
    </a>
  </h2>
  <font color="black">また、オフライン手書きテキスト認識タスクの現在の最良の結果に対する改善を紹介します。アーキテクチャの複数のバリエーションを実験し、最小のバリアントの1つ（深さとパラメーターごとの数）がRNNベースの複雑な選択肢と同等に機能します。 -layeredの最も深いバリアントは、RNTアーキテクチャよりもパフォーマンスが高く、IIIT-5kやSVTなどのベンチマークデータセットに十分なマージンがあります。 
[ABSTRACT]研究は、リカレントネットワークと複雑なゲートレイヤーに関連しています。これにより、ソリューション全体が複雑になり、スケーリングが困難になります。当社のモデルでは、1-d畳み込みレイヤーを使用しており、特性はありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-18">
        <br><font color="black">2020-08-18</font>
      </time>
    </span>
</section>
<!-- paper0: Robust RGB-based 6-DoF Pose Estimation without Real Pose Annotations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_17.html">
      <font color="black">Robust RGB-based 6-DoF Pose Estimation without Real Pose Annotations</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、困難な条件で、実際のポーズアノテーションを使用せずに6自由度のポーズをロバストかつ正確に推定するアプローチを紹介します。アプローチ..私たちは、LINEMODとOccludedLINEMODで最先端のパフォーマンスを実現します。実際のポーズ設定なしで、Occluded-LINEMODでのトレーニング中に実際のアノテーションに依存するメソッドよりも優れています。 
[ABSTRACT] douglas rushkoff：可能なすべてのオクルージョンを注釈付きデータでカバーするのは難しいです。実際のポーズ設定なしでlinemodとoccludedlinemodで最先端のパフォーマンスを達成すると彼は言います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Visibility-aware Multi-view Stereo Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_18.html">
      <font color="black">Visibility-aware Multi-view Stereo Network</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、マッチングの不確実性推定を介して、MVSネットワークのピクセル単位のオクルージョン情報を明示的に推論および統合します。このように、オクルージョンされたピクセルの悪影響はコストフュージョンで抑制されます。提案されたフレームワークVis-MVSNet重度のオクルージョンを伴うシーンの深度精度を向上させます。 
[ABSTRACT]提案されたフレームワークvis-mvsnetは、重度のオクルージョンがあるシーンの深度精度を大幅に改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-18">
        <br><font color="black">2020-08-18</font>
      </time>
    </span>
</section>
<!-- paper0: STAR: Sparse Trained Articulated Human Body Regressor -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_19.html">
      <font color="black">STAR: Sparse Trained Articulated Human Body Regressor</font>
    </a>
  </h2>
  <font color="black">第2に、SMPLは体型からポーズ依存の変形を考慮に入れますが、実際には、形状が異なる人々は別様に変形します。 http://star.is.tue.mpg.deの目的。 
[ABSTRACT]人気がある一方で、smplにはいくつかの制限があることを示し、smplよりも量的および質的に優れているstarを導入します。この密なポーズ-修正オフセットは、グローバルな運動学的ツリーのすべてのジョイントに関連し、疑似長距離相関を取得します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: FrankMocap: Fast Monocular 3D Hand and Body Motion Capture by Regression
  and Integration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_20.html">
      <font color="black">FrankMocap: Fast Monocular 3D Hand and Body Motion Capture by Regression
  and Integration</font>
    </a>
  </h2>
  <font color="black">FrankMocapを構築するために、全身パラメトリックモデル（SMPL-X）の手の一部を取得することにより、最先端の単眼3D「手」モーションキャプチャ方式を構築します。3D手のモーションキャプチャ出力は効率的に統合できます。単眼ボディモーションキャプチャ出力に変換し、全身モーションを生成すると、統合パラメトリックモデル構造になります。この手法は、ほぼリアルタイム（9.5 fps）で機能し、3Dボディおよびハンドモーションキャプチャ出力を統合パラメトリックモデル構造として生成します。 
[ABSTRACT] frankmocapは、3次元の手と体の両方の動きを推定できるモーションキャプチャシステムです。これは、以前のショーよりも高速（9.5 fps）で精度が高くなります。この手法は、体と手の両方の動きをキャプチャするために使用されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Remix: Rebalanced Mixup -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_21.html">
      <font color="black">Remix: Rebalanced Mixup</font>
    </a>
  </h2>
  <font color="black">実験結果により、Remixは以前の方法に比べて一貫した大幅な改善を提供することが確認されました。また、Remixを実際の大規模不均衡データセット、iNaturalist 2018で評価しました。このような最新の正則化手法を調査しましたクラス不均衡レジームの下でのMixup、Manifold MixupおよびCutMixとして、提案されたRemixが、CIFAR-10によって構築された不均衡なデータセットに対して、これらの最先端技術といくつかの再重み付けおよび再サンプリング技術を大幅に上回ることを示しました。 CIFAR-100、CINIC-10。 
[ABSTRACT]新しい手法remixは、mixupの形状を緩和します。これにより、混合係数を解きほぐすことができます。分類子は、決定の境界をプッシュすることを学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Regularized Two-Branch Proposal Networks for Weakly-Supervised Moment
  Retrieval in Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_22.html">
      <font color="black">Regularized Two-Branch Proposal Networks for Weakly-Supervised Moment
  Retrieval in Videos</font>
    </a>
  </h2>
  <font color="black">次に、共有可能な2分岐提案モジュールを設計して、強化されたストリームから肯定的な提案を生成し、抑制された提案から妥当な否定的な提案を生成して、十分な対決を行います。具体的には、まず言語認識フィルターを考案して、強化されたビデオストリームと抑制されたビデオストリームを生成します。ビデオストリーム..このホワイトペーパーでは、サンプル間とサンプル内の対立を同時に考慮するために、新しい正則化2分岐提案ネットワークを提案します。 
[ABSTRACT]弱い監視対象ストリームは、トレーニング中にビデオレベルの文の注釈のみを提供します。代わりに、これらのメソッドは、ターゲットの瞬間を論理的な負の瞬間から内部で区別できません-内部</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Regularized Flexible Activation Function Combinations for Deep Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_23.html">
      <font color="black">Regularized Flexible Activation Function Combinations for Deep Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">ディープニューラルネットワークでのアクティブ化は、非線形マッピングを達成するための基本です。これに基づいて、LSTMセルのシグモイドまたはtanhを置き換えることができる柔軟なアクティブ化関数の新しいファミリが実装され、ReLUとELUを組み合わせることによって新しいファミリが実装されます。また、事前知識としての仮定に基づく2つの新しい正則化用語が導入されています。 
[ABSTRACT]伝統的な研究は、主に特定の一連の学習タスクの固定された活性化を見つけることに焦点を当てています。研究は伝統的な研究によって行われました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-26">
        <br><font color="black">2020-07-26</font>
      </time>
    </span>
</section>
<!-- paper0: Weakly Supervised Learning with Region and Box-level Annotations for
  Salient Instance Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_24.html">
      <font color="black">Weakly Supervised Learning with Region and Box-level Annotations for
  Salient Instance Segmentation</font>
    </a>
  </h2>
  <font color="black">ピクセルレベルの正確な場所のために、各特徴インスタンスのコンテキストフィーチャーを画像内のグローバルコンテキストに拡張するグローバルフィーチャーリファイニングレイヤーが導入されています。その一方で、ラベル付け更新スキームが、提案されたフレームワークに埋め込まれ、弱い次の反復のための注釈。ベルとホイッスルなしで、私たちの提案された方法は57.13％のマスクAPを達成します。これは、完全に監視された最良の方法よりも優れており、監視の弱い顕著インスタンスセグメンテーションの新しい技術を確立します。 
[ABSTRACT]サイクリックなグローバルコンテキストsalientインスタンスセグメンテーションネットワーク（cgcnet）を提示します。これは、既存のsaliency検出データセットからのバイナリsalient領域とバウンディングボックスの組み合わせによって監視されます。ラベリング更新スキームは、提案されたフレームワークに組み込まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Detection of Backdoors in Trained Classifiers Without Access to the
  Training Set -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_25.html">
      <font color="black">Detection of Backdoors in Trained Classifiers Without Access to the
  Training Set</font>
    </a>
  </h2>
  <font color="black">ここでは、DNN画像分類器でのバックドア攻撃のトレーニング後の検出について扱います。これは、既存の作品ではほとんど考慮されていません。防御者は、毒されたトレーニングセットにはアクセスできず、トレーニングされた分類器自体にアクセスできるだけでなく、分類ドメイン..いくつかのバックドアパターン、データセット、および攻撃設定について、代替防御と比較してADアプローチをテストし、その好意を示します。これは、トレーニングされた分類子が
[ABSTRACT ]攻撃は分類精度を低下させようとせず、バックドアパターンが存在する場合は常に分類子にターゲットクラスへの分類を学習させます。知覚できないバックドア攻撃に対する純粋に監視なしの異常検出（g）防御を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-27">
        <br><font color="black">2019-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: OS2D: One-Stage One-Shot Object Detection by Matching Anchor Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_26.html">
      <font color="black">OS2D: One-Stage One-Shot Object Detection by Matching Anchor Features</font>
    </a>
  </h2>
  <font color="black">学習したローカルフィーチャの密な相関マッチングを使用して対応を見つけ、フィーチャを整列させるフィードフォワード幾何変換モデルと相関テンソルの双線形リサンプリングを使用して、整列したフィーチャの検出スコアを計算します。すべてのコンポーネントは微分可能であり、これにより、 -to-endトレーニング..私たちのコードはオンラインで利用できます：https://github.com/aosokin/os2d。 
[ABSTRACT]このメソッドは目に見えないクラスを検出できます。いくつかのベースラインを大幅に上回っています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-15">
        <br><font color="black">2020-03-15</font>
      </time>
    </span>
</section>
<!-- paper0: Spatio-temporal relationships between rainfall and convective clouds
  during Indian Monsoon through a discrete lens -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_27.html">
      <font color="black">Spatio-temporal relationships between rainfall and convective clouds
  during Indian Monsoon through a discrete lens</font>
    </a>
  </h2>
  <font color="black">毎年6月から9月に大雨を引き起こす多変数プロセスであるインドモンスーンは、空間と時間において非常に不均一です。降雨とOLRでそれぞれ8つの毎日の空間パターン、および降雨とOLRの7つの共同パターンであることがわかります。降雨とOLRの空間パターンを識別、分類、視覚化するために、マルコフ確率場に基づく統計モデルを使用して作成された、データの離散的かつ時空間的にコヒーレントな表現を使用します。 
[ABSTRACT] 2004年から2010年の間のモンスーンの降雨と発信長波放射の関係を調査します。olrは一般に降水量と強い負の相関を持っていますが、空間変動が大きいことがわかります。この特定の6月の西インドは、olr日に発生します、おそらく浅い雲から</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: SoDA: Multi-Object Tracking with Soft Data Association -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_28.html">
      <font color="black">SoDA: Multi-Object Tracking with Soft Data Association</font>
    </a>
  </h2>
  <font color="black">Waymo OpenDatasetの実験結果は、私たちのアプローチが最新の大規模データセットを活用し、ビジュアルマルチオブジェクトトラッキングの最新技術と比較して有利に機能することを示唆しています。結果の潜在空間表現により、モデルは、全体的なデータ駆動型の方法でオクルージョンを推論し、オブジェクトがオクルードされている場合でもトラックの推定値を維持できるようになります。 
[ABSTRACT]私たちのモデルは、ハードデータの関連付けを緩和できます。これにより、回復不可能なエラーが発生する可能性があります。その結果、潜在空間表現により、モデルはオクルージョンの理由を学習できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-18">
        <br><font color="black">2020-08-18</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Domain Identification for Thermal-to-Visible Face Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_29.html">
      <font color="black">Cross-Domain Identification for Thermal-to-Visible Face Recognition</font>
    </a>
  </h2>
  <font color="black">このフレームワークは、熱から可視への顔認識のための新しいクロスドメインアイデンティティおよびドメインインバリアンス損失関数を導入することによって最適化され、正確に共同登録および同期された画像の要件を緩和します。さらに、非正面の熱から可視への顔認識など、より困難なタスク。使用される機能と損失関数の両方の広範な分析を提供し、提案されたドメイン適応フレームワークを最新の機能ベースのドメイン適応モデルと比較します。さまざまな範囲、ポーズ、表情で収集された顔の画像を含む困難なデータセット。 
[要約]この論文は、新しい機能マッピングサブネットワークと既存の深い機能モデルを組み合わせた新しいドメイン適応フレームワークを提案します。これらは、変更されたネットワークアーキテクチャ（vgg16やresnet50など）に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Stereo Plane SLAM Based on Intersecting Lines -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_30.html">
      <font color="black">Stereo Plane SLAM Based on Intersecting Lines</font>
    </a>
  </h2>
  <font color="black">3D空間では、2本の交差する線がこのような平面を決定できます。平面フィーチャは、SLAMシステムのドリフトエラーを減らすための一種の安定したランドマークです。平面フィーチャは、通常、規則的な形状とストレートエッジライン。 
[ABSTRACT]論文では、ステレオイメージ用に抽出された線から平面パラメーターをltする新しい方法を提案します。ステレオマッチングを使用して、3D空間の端点と線の方向を計算し、平面を計算できます。提案されたものに追加システムでは、最新のスラムシステムと比較して、堅牢で正確な推定結果を示しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: TNT: Target-driveN Trajectory Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_31.html">
      <font color="black">TNT: Target-driveN Trajectory Prediction</font>
    </a>
  </h2>
  <font color="black">まず、環境と他のエージェントとの相互作用をエンコードすることにより、エージェントの潜在的なターゲット状態が$ T $ステップ先に予測します。TNTは、最先端の車両や歩行者の軌道予測をベンチマークします。 Argoverse Forecasting、INTERACTION、Stanford Drone、社内のPedestrian-at-Intersectionデータセットについて。TNTには、エンドツーエンドでトレーニングされる3つのステージがあります。 
[ABSTRACT]これは、ターゲット駆動型の軌跡予測（tnt）フレームワークにつながります。tntは、最初にエージェントの潜在的なターゲット状態を予測し、$ t $未来にステップします。次に、環境と他のエージェントとの相互作用を作成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Motion Capture from Internet Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_32.html">
      <font color="black">Motion Capture from Internet Videos</font>
    </a>
  </h2>
  <font color="black">したがって、我々は、単一のビデオを個別に使用する代わりに、これらのインターネットビデオを共同で分析することにより、人間の動きをキャプチャすることを提案します。この新しいタスクは、既存の方法では対応できない多くの新しい課題をもたらします。ビデオが同期されておらず、カメラの視点が不明であり、背景のシーンが異なり、人間の動きがビデオ間で完全に同じではないためです。 
[ABSTRACT]これは、人間のビデオが異なる時間インスタンスで記録された初めての例です。これらは、人間の同じモーション特性をエンコードします。これらのビデオは同期されておらず、カメラの視点は不明であり、背景シーンは異なり、人間の動き動画間でまったく同じではありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-18">
        <br><font color="black">2020-08-18</font>
      </time>
    </span>
</section>
<!-- paper0: MineNav: An Expandable Synthetic Dataset Based on Minecraft for Aircraft
  Visual Navigation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_33.html">
      <font color="black">MineNav: An Expandable Synthetic Dataset Based on Minecraft for Aircraft
  Visual Navigation</font>
    </a>
  </h2>
  <font color="black">さらに、レンダリングされた画像と実際の画像の間のデータバイアスを最小限に抑えるために使用できるシェーダーコミュニティもあります。最後に、深度予測、表面法線のデータを生成する3つのツールを提供します予測と視覚オドメトリ、ユーザーはセグメンテーションやオプティカルフロー予測などの他のビジョンタスク用のプラグインモジュールを開発することもできます。オープンソースのゲームに基づいて高品質の合成データセットを生成する簡単な方法を提案します。Minecraftにはレンダリングされた画像、深度マップが含まれます、表面法線マップ、および6自由度のカメラ軌道。 
[ABSTRACT]非常に多数の3Dオープンワールド環境があり、ユーザーは撮影に適したシーンを見つけてデータセットを構築でき、ゲーム内でシーンを構築することもできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Channel-wise Hessian Aware trace-Weighted Quantization of Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_34.html">
      <font color="black">Channel-wise Hessian Aware trace-Weighted Quantization of Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">CW-HAWQを最新の技術と比較すると、複数のネットワークでより良い結果が得られることがわかります。CW-HAWQはヘッシアントレースを使用して、アクティベーションと重み付けの異なるチャネルの相対的な感度の順序を決定します。さらに、CW- HAWQは、Deep Reinforcement Learning（DRL）Deep Deterministic Policy Gradient（DDPG）ベースのエージェントを使用して、異なる量子化ビットの最適な比率を見つけ、ヘッセ行列のトレース順序に従ってチャネルにビットを割り当てることを提案しています。 
[ABSTRACT] cw-hawqの状態数は、従来のautomlベースのミックスよりもはるかに少ない-精度の高い方法。これは、各チャネルのビットを決定する複雑さが元の方法には高すぎるため機能します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Slide-free MUSE Microscopy to H&E Histology Modality Conversion via
  Unpaired Image-to-Image Translation GAN Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_35.html">
      <font color="black">Slide-free MUSE Microscopy to H&E Histology Modality Conversion via
  Unpaired Image-to-Image Translation GAN Models</font>
    </a>
  </h2>
  <font color="black">また、MUSEの色反転はH＆Eへの正確なモダリティ変換に必要なステップである可能性があることもわかりました。実際の生成されたH＆E画像で自動化された評論家をトレーニングした結果、CycleGANが最高のパフォーマンスを発揮することを確認しました。 to-H＆Eモデルは、MUSEイメージングと従来の組織学の間の知覚上のギャップを埋めることにより、新しいスライドなしの方法の採用を改善するのに役立ちます。 
[要旨]ミューズ画像は、ヘマトキシリンおよびエオシン染色（h＆e）画像に類似するように変換できます。また、ミュール色の反転がハラール変換に必要なステップである可能性があることもわかりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Blind Spot Denoising for Microscopy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_36.html">
      <font color="black">Improving Blind Spot Denoising for Microscopy</font>
    </a>
  </h2>
  <font color="black">最近、ノイズ統計についての仮定を行うことにより、自己監視法が出現しました。ここでは、自己監視ノイズ除去の品質を改善する新しい方法を紹介します。このような方法は、ノイズ除去されるべき画像に対して直接トレーニングされます。追加のペアのトレーニングデータは必要ありません。 
[ABSTRACT]問題は多くの場合、（教師あり）深層学習に基づいて解決されます。これらの方法は、ノイズ除去される画像で直接トレーニングされます。これらの結果には、追加のペアのトレーニングデータは必要ありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Scene Text Detection with Selected Anchor -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_37.html">
      <font color="black">Scene Text Detection with Selected Anchor</font>
    </a>
  </h2>
  <font color="black">Faster RCNNのアンカーベースのRPNを置き換えることにより、AS-RPNベースのFaster RCNNは、COCO-Text、ICDAR2013、ICDAR2015、MSRA-などの標準ベンチマークで、従来の最先端のテキスト検出アプローチと同等のパフォーマンスを実現できます。単一スケールおよび単一モデル（ResNet50）テストのみを使用する場合のTD500 ..このホワイトペーパーでは、テキストの提案を抽出するために、高密度アンカーの代わりに効果的な選択アンカーを使用するアンカー選択ベースの地域提案ネットワーク（AS-RPN）を提案します。シーンテキスト検出のための高密度アンカースキームを使用した提案手法は、高い再現率を達成するために頻繁に適用されました。 
[要旨]アンカーは、新しい手法で精度を向上させることができます。品質が低いことが原因である可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Every Pixel Matters: Center-aware Feature Alignment for Domain Adaptive
  Object Detector -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_38.html">
      <font color="black">Every Pixel Matters: Center-aware Feature Alignment for Domain Adaptive
  Object Detector</font>
    </a>
  </h2>
  <font color="black">広範な実験結果を伴う多数の適応設定での方法を示し、既存の最先端のアルゴリズムに対して良好なパフォーマンスを示します。既存のソリューションとは異なり、ピクセルごとのオブジェクト性を予測することで各ピクセルを説明するドメイン適応フレームワークを提案します具体的には、提案された方法は、前景ピクセルにより注意を向けることによって中心を意識した位置合わせを実行するため、ドメイン全体でより適切な適応が実現されます。 
[ABSTRACT]ほとんどの既存の方法は、画像レベルまたはインスタンスレベルで機能の配置を採用しています。現在のソリューションには、各ピクセルを説明するドメイン適応フレームワークが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: "Name that manufacturer". Relating image acquisition bias with task
  complexity when training deep learning models: experiments on head CT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_39.html">
      <font color="black">"Name that manufacturer". Relating image acquisition bias with task
  complexity when training deep learning models: experiments on head CT</font>
    </a>
  </h2>
  <font color="black">分類とセグメンテーションの両方のタスク、具体的には2つの最先端のモデルの畳み込みニューラルネットワーク（CNN）を評価します。分類にはResNet 
[2]、セグメンテーションにはU-Net 
[3]を使用します。多かれ少なかれ微妙な病変の存在を模倣する脳データは、このバイアスが課題の難しさに関連していることも示しています。バイアスのすべての潜在的な原因を説明することは依然として困難ですが、特定の種類のバイアスを特定するための手法を開発できますそれらの影響を軽減するために。 
[要旨]このステップでは、さまざまな形のバイアスを認識する能力が重要です。cnnsは、イメージングスキャナーの製造元を区別する方法を学ぶことができます。このバイアスは、ニューラルネットワークとネットワークの両方のモデルパフォーマンスに大きな影響を与える可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Doodle to Search: Practical Zero-Shot Sketch-based Image Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_40.html">
      <font color="black">Doodle to Search: Practical Zero-Shot Sketch-based Image Retrieval</font>
    </a>
  </h2>
  <font color="black">意外なことに、モデルの縮小版を使用して既に達成できる既存のデータセットの最先端のパフォーマンスよりも、驚くほど検索パフォーマンスが優れていることを示しています。ドメイン間の相互情報をマイニングする新しい戦略は、特に設計されていますドメインのギャップを緩和するために使用します。高度に抽象的なアマチュアの人間のスケッチは、セミフォトリアリスティックであることが多い既存のデータセットに含まれるスケッチではなく、意図的にドメインギャップを最大化するために供給されます。 
[ABSTRACT]最初にコミュニティに新しいzs-sbirデータセット、quickdraw-拡張を提供します。330,000枚のスケッチと写真の204,00枚の写真が含まれます。次に、zsetを作成して、スケッチと写真を共通の埋め込みスペースに共同でモデル化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-06">
        <br><font color="black">2019-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Connectivity of Neural Networks from a Topological Perspective -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_41.html">
      <font color="black">Learning Connectivity of Neural Networks from a Topological Perspective</font>
    </a>
  </h2>
  <font color="black">さらに、接続性の分布に補助スパース制約を付加します。これにより、学習されたトポロジーが重要な接続に焦点を当てることが促進されます。ネットワークを分析用の完全なグラフに表すトポロジーの視点を提案します。ノードは機能の集約と変換を実行します。エッジは情報の流れを決定します。実験の定量的な結果は、学習された接続が、ランダム、残差、完全など、従来のルールベースのものより優れていることを反映しています。 
[要約]論文では、ニューラルネットワークの接続性の最適化を試みます。これには、接続の大きさを反映する学習可能なパラメーターをエッジにアタッチすることが含まれます。このプロセスは既存のネットワークと互換性があり、より大きな検索スペースやさまざまなタスクへの適応性を備えています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: CCA: Exploring the Possibility of Contextual Camouflage Attack on Object
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_42.html">
      <font color="black">CCA: Exploring the Possibility of Contextual Camouflage Attack on Object
  Detection</font>
    </a>
  </h2>
  <font color="black">この問題についてより深い洞察を得るために、オブジェクト検出器のパフォーマンスに影響を与えるコンテキストカモフラージュ攻撃（略してCCA）アルゴリズムを提案します。ディープニューラルネットワークベースのオブジェクト検出は、多くの現実世界のアプリケーションの基礎となっています。提案されているカモフラージュは最新のオブジェクト検出器のほとんどに有効であることが検証されています。 
[ABSTRACT]進化した検索戦略と機械学習を写真との相互作用で使用-迷彩パターンを見つけるための現実的なシミュレーション環境</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Vision-based Robotic Grasping From Object Localization, Object Pose
  Estimation to Grasp Estimation for Parallel Grippers: A Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_43.html">
      <font color="black">Vision-based Robotic Grasping From Object Localization, Object Pose
  Estimation to Grasp Estimation for Parallel Grippers: A Review</font>
    </a>
  </h2>
  <font color="black">把持推定タスクには、2D平面把持法と6DoF把持法があり、前者は一方向からの把持に制限されています。多くの物体姿勢推定法は、物体の位置特定が不要で、物体の位置特定と物体の姿勢推定を共同で行っています。論文は、ビジョンベースのロボット把持に関する包括的な調査を提示しています。 
[ABSTRACT]ビジョンベースのロボットによる把握中に、3つの主要なタスクを完了します。さらに、タスクは対象オブジェクトの領域を提供します。把握推定タスクには、2D平面把握方法と6Dof把握方法が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-16">
        <br><font color="black">2019-05-16</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Class-incremental Object Detection with Nearest Mean of
  Exemplars -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_44.html">
      <font color="black">Towards Class-incremental Object Detection with Nearest Mean of
  Exemplars</font>
    </a>
  </h2>
  <font color="black">この論文では、クラス増分オブジェクト検出（CIOD）という名前のオブジェクト検出フレームワークを提案します。最初に、従来のOpenCVカスケード分類器がオブジェクト候補ボックス生成段階で改善され、クラス増分のニーズに対応します。CIODがオブジェクト検出を分割します。 2段階に。 
[ABSTRACT] ciodはオブジェクト検出を2段階に分割します-incremental.ciodはコンセプトコンセプトコンセプト `cascade &#39;を使用して、クラスに基づいて分類子をトレーニングします-incrementalで生成されたオブジェクト候補ボックスを識別し、実際のオブジェクトボックスを抽出します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: SegCodeNet: Color-Coded Segmentation Masks for Activity Detection from
  Wearable Cameras -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_45.html">
      <font color="black">SegCodeNet: Color-Coded Segmentation Masks for Activity Detection from
  Wearable Cameras</font>
    </a>
  </h2>
  <font color="black">2つのストリーム間で優先順位を付けるストリーム単位の注意ゲーティングと、関連機能を含むビデオフレームを優先順位付けするフレーム単位の注意モジュールも含まれています。この作業では、2つのストリームネットワーク\ emph {SegCodeNetを開発しました。 }、元のRGBビデオストリームに加えて、関連オブジェクトの色分けされたセマンティックセグメンテーションマスクを含むビデオストリームを含むネットワークブランチを使用します。ウェアラブルカメラを使用してキャプチャされた一人称ビデオ（FPV）からのアクティビティ検出はアクティブですヘルスケア、法執行機関、リハビリテーションなど、多くの分野で潜在的な用途を持つ研究分野。 
[要約]最先端の方法は、オプティカルフローベースのハイブリッド技術を使用します。シングルストリームネットワークと比較して、提案された2ストリーム方法は、$ 14の絶対的な改善を実現します。 366ドル、10ドル。平均f1スコアと精度のそれぞれ324＆％$</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Black Re-ID: A Head-shoulder Descriptor for the Challenging Problem of
  Person Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_46.html">
      <font color="black">Black Re-ID: A Head-shoulder Descriptor for the Challenging Problem of
  Person Re-Identification</font>
    </a>
  </h2>
  <font color="black">入力された人物の画像が与えられた場合、アンサンブルメソッドは、画像の内側の人物が黒い服を着ている場合、より大きな重みを割り当てることにより、ヘッドショルダー機能に焦点を当てます。この問題を解決するには、服装の情報に頼るのではなく、ヘッドショルダー機能を活用して人物のRe-IDを支援します。Black-reID、Market1501、およびDukeMTMC-reIDデータセットに対する広範な評価により、私たちのモデルは、最新のRe-IDメソッドと比較して最高の結果を達成していることがわかります。黒と従来の再IDの両方の問題。 
[ABSTRACT] re-idメソッドは大きな成功を収めましたが、それらのほとんどは衣服の属性の観点から特徴を抽出します。頭-肩適応型再識別ネットワーク-は、入力を学習するために提案されています。このメソッドは、モデルの一般化</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Trailer Moments in Full-Length Movies -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_47.html">
      <font color="black">Learning Trailer Moments in Full-Length Movies</font>
    </a>
  </h2>
  <font color="black">コントラストアテンションモジュールの有効性は、パブリックベンチマークでの最先端のパフォーマンス改善によっても実証されています。映画と予告編の共同アテンションをガイダンスとして利用し、トレーラーで高度に修正されたモーメントは、無相関のモーメントよりも高いスコアが期待されるトレーニングペア。最初の映画の予告編データセットを構築し、提案された共同注意支援ランキングネットワークは、監視ありアプローチよりも優れたパフォーマンスを示します。 
[ABSTRACT]提案された共同注意支援ランキングネットワークは、監視ありアプローチよりも優れたパフォーマンスを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: CFAD: Coarse-to-Fine Action Detector for Spatiotemporal Action
  Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_48.html">
      <font color="black">CFAD: Coarse-to-Fine Action Detector for Spatiotemporal Action
  Localization</font>
    </a>
  </h2>
  <font color="black">粗モジュールの長い時間情報のパラメータ化されたモデリングは、正確な初期管推定を得るのに役立ちますが、精細モジュールは、主要なタイムスタンプのガイダンスの下で管の位置を選択的に調整します。他の方法とは異なり、提案されたCFADは、UCF101-24、UCFSports、およびJHMDB-21のアクション検出ベンチマークで、3.3倍の推論速度で競合結果を達成します。最も近い競合他社。 
[ABSTRACT] simple-to-fineアクションディテクター（cfd）は、アクションlocalinesの効率的なストリームのための新しい単純化可能なフレームワークです。このコンセプトは、フレームワーク内のsaltyモジュールと精製モジュールの2つの主要コンポーネントによって実装されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Investigating Bias and Fairness in Facial Expression Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_49.html">
      <font color="black">Investigating Bias and Fairness in Facial Expression Recognition</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、次のことを示しています。（i）データの増加により、ベースラインモデルの精度が向上しますが、これだけではバイアス効果を軽減できません。 （ii）データ拡張で強化された属性認識アプローチと複雑なアプローチの両方が、精度と公平性の点でベースラインアプローチよりも優れたパフォーマンスを発揮します。 （iii）複雑なアプローチは、人口統計学的バイアスを軽減するために最適です。 （iv）バイアス軽減戦略は、不均一な属性分布または不均衡な数のサブグループデータが存在する場合により適しています。したがって、この作業では、3つの異なるアプローチを比較することにより、顔の認識におけるバイアスと公平性の体系的な調査を行います。つまり、RAF-DBとCelebAの2つのよく知られたデータセットでのベースライン、属性認識、および複雑なアプローチです。感情の表現と顔の画像からの影響の認識は、感情の分野でよく研究されている研究問題です。顔画像と対応する表情ラベルを含む多数のデータセットを使用したコンピューティングとコンピュータービジョン。 
[ABSTRACT]データ拡張によりベースラインデータの精度が向上しますが、これだけではバイアス効果を軽減することはできません。複雑なアプローチは、人口統計学的バイアスを軽減するのに最適です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-20">
        <br><font color="black">2020-07-20</font>
      </time>
    </span>
</section>
<!-- paper0: Axiom-based Grad-CAM: Towards Accurate Visualization and Explanation of
  CNNs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_50.html">
      <font color="black">Axiom-based Grad-CAM: Towards Accurate Visualization and Explanation of
  CNNs</font>
    </a>
  </h2>
  <font color="black">一方、専用のAxiomベースのGrad-CAM（XGrad-CAM）は、これらの公理を可能な限り満たすために提案されています。実験により、XGrad-CAMは、保存と感度の点でGrad-CAMの拡張バージョンであることが示されています。合理的な視覚化にもかかわらず、明確で十分な理論的サポートの欠如は、これらの方法の主な制限です。 
[要約]コードはwwwから入手できます。 github。 com / fu0511 / xgrad-cam。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Volumetric Ambient Occlusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_51.html">
      <font color="black">Deep Volumetric Ambient Occlusion</font>
    </a>
  </h2>
  <font color="black">提案されたニューラルネットワークは、このグローバル情報の変更時にのみ実行する必要があるため、リアルタイムのボリューム相互作用をサポートします。最良の結果を達成するために、ディープニューラルネットワークのさまざまな伝達関数表現と注入戦略を提案および分析します..得られた結果に基づいて、同様のボリューム学習シナリオに適用可能な推奨事項も提供します。 
[ABSTRACT]新しいアプローチは、伝達関数を介して提供されるグローバル情報を考慮しながら、ボリュームデータセット内のボクセルごとのアンビエントオクルージョンを予測できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Face Anti-Spoofing Via Disentangled Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_52.html">
      <font color="black">Face Anti-Spoofing Via Disentangled Representation Learning</font>
    </a>
  </h2>
  <font color="black">公開ベンチマークデータセットでメソッドを評価し、広範な実験結果により、最先端の競合他社に対するメソッドの有効性が実証されています。この論文では、絡み合いのない表現学習に動機付けられ、顔のアンチの新しい視点を提案します。ライブネス機能とコンテンツ機能を画像から解きほぐすスプーフィング、およびライブネス機能は分類にさらに使用されます。最後に、解きほぐしの効果と利点を理解するのに役立ついくつかの結果をさらに視覚化します。 
[要約]畳み込みニューラルネットワーク（cnn）アーキテクチャも提案します。解体と、一般化機能を改善するための低レベルと高レベルの監視の組み合わせのプロセス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Physically-Constrained Transfer Learning through Shared Abundance Space
  for Hyperspectral Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_53.html">
      <font color="black">Physically-Constrained Transfer Learning through Shared Abundance Space
  for Hyperspectral Image Classification</font>
    </a>
  </h2>
  <font color="black">ただし、トレーニングとテストの画像が異なるドメイン（ソースドメインとターゲットドメインなど）上にある場合、取得条件が異なるために生じるスペクトルのばらつきにより、ほとんどの最先端のアプローチはパフォーマンスが低下する傾向があります。方法は、共有アバンダンススペース（PCTL-SAS）を介した物理的に制約のある転移学習と呼ばれます。ハイパースペクトル画像（HSI）分類は、最もアクティブな研究トピックの1つであり、ディープラーニングの最近の発展によって後押しされる有望な結果を達成しています。 
[ABSTRACT]画像のテストとテストはさまざまなタイプの最先端の研究に基づいています。ただし、新しい方法はさまざまなドメインでテストする必要があります。これは大幅に削減されるため、モデルをターゲットドメインに適用できますデータのラベル付けやネットワークの再トレーニングに余計な手間をかけずに</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Query Twice: Dual Mixture Attention Meta Learning for Video
  Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_54.html">
      <font color="black">Query Twice: Dual Mixture Attention Meta Learning for Video
  Summarization</font>
    </a>
  </h2>
  <font color="black">この論文では、ソフトマックスのボトルネック問題に取り組む、ビデオ要約のためのメタ学習を備えたデュアル混合注意（DMASum）モデルという新しいフレームワークを提案します。最初のクエリキーアテンションに加えて2次の変化をキャプチャできるアテンション。次に、新しいシングルフレームメタラーニングルールが導入され、トレーニングソースが限られている小さなデータセットにより一般化されます。新しい評価プロトコルを2つのパブリックデータセット、SumMe、およびTVSum ..さらに、DMASumは、ローカルキーフレームとグローバルな注意を累積的に結びつける視覚的注意と順次注意の両方を大幅に活用します。 
[ABSTRACT] softmax関数は、複雑な視覚情報または連続情報の上位表現を保持するのに苦労します。これは、softmaxボトルネック問題として知られています。dmarモデルは通常、小さな領域への単一の注意を予測します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Relighting Networks for Image Light Source Manipulation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_55.html">
      <font color="black">Deep Relighting Networks for Image Light Source Manipulation</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案された方法が他の可能な方法よりも質的および量的に優れていることを示しています。特定の画像の光源を操作することは興味深いタスクであり、写真や映画撮影などのさまざまなアプリケーションで役立ちます。特に、提案されたDRNは最高の2020 ECCV会議の「AIM2020-Any to one relighting challenge」のPSNR。 
[ABSTRACT]新しい方法は、より多くの情報を必要とする既存の方法を使用します。これらには、シーンの詳細な詳細画像が含まれ、利用できない場合があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: PatchPerPix for Instance Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_56.html">
      <font color="black">PatchPerPix for Instance Segmentation</font>
    </a>
  </h2>
  <font color="black">さまざまなデータドメインでメソッドを評価し、4つのベンチマーク、つまりISBI 2012 EMセグメンテーションベンチマーク、BBBC010 C. elegansデータセット、および2Dと3Dの蛍光顕微鏡データの新しい最先端技術を定義します。さらに、我々の方法は、複雑な形状クラスターの極端な場合を示すショウジョウバエニューロンの3D光学顕微鏡データに適用されることを示しています。私たちの方法は、インスタンスを形成するためにアセンブルする密な局所形状記述子の予測に基づいています。 
[要約]私たちの方法は、密な局所形状記述子の予測に基づいており、インスタンスを形成するためにアセンブルします。これは、学習した形状パッチで構成されるインスタンスを生成する最初の非反復的な方法です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-21">
        <br><font color="black">2020-01-21</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Cross-domain Image Classification by Distance Metric Guided
  Feature Alignment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_57.html">
      <font color="black">Unsupervised Cross-domain Image Classification by Distance Metric Guided
  Feature Alignment</font>
    </a>
  </h2>
  <font color="black">現代の技法は、ドメイン敵対的なトレーニングを使用してドメイン不変の特徴を抽出することに焦点を当てています。実験結果は、提案された方法が最新技術よりも優れ、モデルの一般化を可能にすることを示しています。クロスデバイス用の胎児超音波データセットで提案された方法を評価します。画像分類。 
[要旨]教師なしドメイン適応は、ソースドメインを使用して知識をターゲットに転送する有望な手段です。これらの手法は、ターゲットドメインの潜在表現空間の識別クラス境界を学習することを怠り、制限された適応パフォーマンスを生み出します。クロスデバイス画像分類のための胎児超音波データセット</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Reading Beyond Faces for Sparsity-Aware 4D Affect Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_58.html">
      <font color="black">Towards Reading Beyond Faces for Sparsity-Aware 4D Affect Recognition</font>
    </a>
  </h2>
  <font color="black">これは、より高い認識精度に効果的であるだけでなく、計算上も便利です。BU-4DFEデータセットで達成された広範な実験結果は、99.69の有望な精度に到達することにより、最新の方法に対する私たちの方法の重要性を示しています。 ％for 4D FER ..重要なのは、次に、スパース性を認識したディープネットワークを提示して、マルチビューでの畳み込み特徴のスパース表現を計算することです。 
[ABSTRACT]最初に、ディープラーニングのデータ制限問題に対処する新しい方法を提案します。また、3つの位置合わせされたプランから顔の筋肉の動きをキャプチャする効果的な方法を紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-08">
        <br><font color="black">2020-02-08</font>
      </time>
    </span>
</section>
<!-- paper0: Graudally Applying Weakly Supervised and Active Learning for Mass
  Detection in Breast Ultrasound Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_59.html">
      <font color="black">Graudally Applying Weakly Supervised and Active Learning for Mass
  Detection in Breast Ultrasound Images</font>
    </a>
  </h2>
  <font color="black">モデルのトレーニング後にアクティブ学習を実行すると、CorLocがさらに増加しました。実験結果では、適切に制御された重みを割り当てることにより、正確にローカライズされ分類された画像の比率である正しいローカリゼーション（CorLoc）指標が24％増加しました。 .. 2段階のオブジェクト検出モデルで、弱く注釈が付けられた画像の影響を処理するために、制御された重みを提案します。 
[ABSTRACT]オブジェクト検出モデルのトレーニングは重要な問題になります。トレーニング済みモデルを使用して、アノテーション付き画像に強力なアノテーションを安全に割り当てるためのアクティブな学習スキームも紹介します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Objective CNN Based Algorithm for SAR Despeckling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_60.html">
      <font color="black">Multi-Objective CNN Based Algorithm for SAR Despeckling</font>
    </a>
  </h2>
  <font color="black">さらに、特別に設計されたアーキテクチャが、検討されているフレームワーク内の特徴的な機能を効果的に抽出するために提案されています。リモートセンシングのディープラーニング（DL）は、今日、効果的な運用ツールになっています。変更検出、画像復元、セグメンテーションなどのアプリケーションで主に使用されています、検出、および分類。このようなSAR特性をコスト関数で考慮することの重要性は、下線が引かれたシナリオ（同種、異種、極端に異種など）での正しいノイズ除去と詳細の保持にとって重要です。 
[要約] sar画像の重要な解釈が原因で、dlテクニックの適用は簡単ではありません。これらのソリューションの多くは、sar画像のプロパティを含まない同様のコスト関数を持つ異なるネットワークアーキテクチャの定義に焦点を当てています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-16">
        <br><font color="black">2020-06-16</font>
      </time>
    </span>
</section>
<!-- paper0: A Color Elastica Model for Vector-Valued Image Regularization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_61.html">
      <font color="black">A Color Elastica Model for Vector-Valued Image Regularization</font>
    </a>
  </h2>
  <font color="black">具体的には、提案された汎関数を最小化するための演算子分割方法を示します。非線形性は、3つのベクトル値と行列値の変数を導入することで分離されます。ここでは、カラーを最小化するカラー画像のPolyakovアクションに追加を導入します。マニホールド曲率。これは、カラーイメージチャネルにラプラスベルトラミ演算子を適用することによって計算されます。 
[要約]たとえば、提案されたモデルは、画像レベルセットで動作するオイラーエラスティカを最小化するために縮小されます。提案された方法は、関連する行列の定常状態を解くために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Attribute Prototype Network for Zero-Shot Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_62.html">
      <font color="black">Attribute Prototype Network for Zero-Shot Learning</font>
    </a>
  </h2>
  <font color="black">追加の利点として、私たちのモデルは、画像内の属性の視覚的証拠を指します。局所性が拡張された画像表現が、CUBデータセットの3つのゼロショット学習ベンチマークで新しい最先端の技術を実現することを示し、画像表現の改善された属性ローカリゼーション能力を確認します。 
[ABSTRACT]コードはwwwで公開されます。ウェンジアクス。 io / apn-zsl /。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: DeepHandMesh: A Weakly-supervised Deep Encoder-Decoder Framework for
  High-fidelity Hand Mesh Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_63.html">
      <font color="black">DeepHandMesh: A Weakly-supervised Deep Encoder-Decoder Framework for
  High-fidelity Hand Mesh Modeling</font>
    </a>
  </h2>
  <font color="black">私たちの手のモデル、データセット、およびコードは、https：//mks0601.github.io/DeepHandMesh/ ..で公開されています。この研究では、まず、高忠実度のハンドメッシュ用の弱監視のディープエンコーダーデコーダーフレームワークであるDeepHandMeshを提案します。モデリング..代わりに、3Dジョイント座標やマルチビュー深度マップなどの弱い監視に依存しています。これらは、グラウンドトゥルースメッシュよりも取得が容易であり、メッシュトポロジに依存しません。 
[ABSTRACT]提案されたディープハンドメッシュは弱い-監視された方法でトレーニングされていますが、以前の完全に監視された手モデルよりもはるかに現実的な手メッシュを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Instance-Aware Graph Convolutional Network for Multi-Label
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_64.html">
      <font color="black">Instance-Aware Graph Convolutional Network for Multi-Label
  Classification</font>
    </a>
  </h2>
  <font color="black">グラフの畳み込みにおけるインスタンス認識のラベル拡散では、統計的ラベル相関のみを使用するのではなく、統計的LCMと各画像インスタンスの個別の1つを融合する画像依存ラベル相関行列（LCM）がグラフ推論用に構築されます。モデルの学習された機能にラベル認識の適応情報を注入するためのラベルについて。全体として、サブネットワークの2つの融合ブランチがフレームワークに関与しています。画像全体をモデル化するグローバルブランチと領域ベースのブランチ探索関心領域（ROI）間の依存関係。このホワイトペーパーでは、マルチラベル分類のためのインスタンス対応グラフ畳み込みニューラルネットワーク（IA-GCN）フレームワークを提案します。 
[ABSTRACT]以前の方法では、ラベル相関はデータの統計情報に基づいて計算されるため、すべてのサンプルで同じです。これにより、多くの画像間の大きな変動を処理するにはラベルのグラフが不十分になる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Open Source Iris Recognition Hardware and Software with Presentation
  Attack Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CV/paper_65.html">
      <font color="black">Open Source Iris Recognition Hardware and Software with Presentation
  Attack Detection</font>
    </a>
  </h2>
  <font color="black">パイプライン全体のハードウェア仕様とすべてのソースコードは、このホワイトペーパーとともに利用可能になります。高速かつ正確な虹彩セグメンテーション、ドメイン固有の人間にヒントを得た2値化統計画像機能（BSIF）のための軽量の画像複雑さガイド付き畳み込みネットワークを提案します。アイリステンプレートを構築し、PADの2D（アイリステクスチャ）と3D（フォトメトリックステレオベース）機能を組み合わせる。RaspberryPi 3B +では、提案されたアイリス認識は約3.2秒で実行され、提案されたPADは約4.5秒で実行されます。 
[要約]この作業の主な目的は、なりすまし耐性の虹彩認識のための低コストのベースラインを提供することです。提案されている虹彩ソフトウェアは3.2秒で構築できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Vector-quantized neural networks for acoustic unit discovery in the
  ZeroSpeech 2020 challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CL/paper_0.html">
      <font color="black">Vector-quantized neural networks for acoustic unit discovery in the
  ZeroSpeech 2020 challenge</font>
    </a>
  </h2>
  <font color="black">2番目のモデルは、ベクトル量子化とコントラスト予測コーディング（VQ-CPC）を組み合わせたものです。この課題に取り組むために2つのニューラルモデルを提案します。どちらもベクトル量子化を使用して、連続する特徴を有限のコードセットにマッピングします。2つのVQ-CPC全般的にパフォーマンスがやや高く、トレーニングが簡単で高速です。 
[ABSTRACT]これはゼロスピーチ2020チャレンジです。スピーチの明確な表現を学習することを目的としています。2つのモデルは、ダウンストリームの音声変換タスクでも競合的に実行します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-19">
        <br><font color="black">2020-05-19</font>
      </time>
    </span>
</section>
<!-- paper0: Generating Categories for Sets of Entities -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CL/paper_1.html">
      <font color="black">Generating Categories for Sets of Entities</font>
    </a>
  </h2>
  <font color="black">次に、階層内の場所が候補ごとに特定されます。ウィキペディアのカテゴリに基づいてテストコレクションを開発し、提案されたアプローチの有効性を示します。最初に、ニューラル抽象要約モデルを使用して候補カテゴリを生成します。 
[ABSTRACT]構造は、候補をランク付けして最も有望なもので識別するために使用されます。これらは、幅広い情報アクセスタスクで使用されるユニークで貴重なリソースです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Deploying Lifelong Open-Domain Dialogue Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CL/paper_2.html">
      <font color="black">Deploying Lifelong Open-Domain Dialogue Learning</font>
    </a>
  </h2>
  <font color="black">（2020）、クラウドソーシングされたデータには、自然性の欠如と実際のユースケースとの関連性の問題がありますが、静的データセットのパラダイムでは、モデルが言語の使用経験から学ぶことができません（Silver et al。、2013）。 。この作業では、ロールプレイングゲームを構築して展開します。これにより、人間のプレーヤーは、オープンドメインのファンタジーの世界にいる学習エージェントと会話します。これとは対照的に、人。 
[ABSTRACT]対照的に、人と対話することでより役立つ機械学習システムが望まれるかもしれません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-18">
        <br><font color="black">2020-08-18</font>
      </time>
    </span>
</section>
<!-- paper0: Toward Automated Quest Generation in Text-Adventure Games -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CL/paper_3.html">
      <font color="black">Toward Automated Quest Generation in Text-Adventure Games</font>
    </a>
  </h2>
  <font color="black">テキスト環境でのクエストの生成は、意味的に一貫している必要があるため、困難です。テキストアドベンチャーゲームは、通常、パズルまたはクエストとして構成され、成功するには特定のアクションを特定の順序で実行する必要があります。このペーパーでは、テキストアドベンチャーゲームで、目標に向かって進むために必要な一連のアクションとして定義されるクエストを手続き的に生成すること。 
[ABSTRACT] text-アドベンチャーゲームは通常、パズルまたはクエストとして構成されます。テキスト環境でのクエスト生成は、意味的に一貫している必要があります。特に、料理に関するクエストの生成に注目します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-13">
        <br><font color="black">2019-09-13</font>
      </time>
    </span>
</section>
<!-- paper0: FinChat: Corpus and evaluation setup for Finnish chat conversations on
  everyday topics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CL/paper_4.html">
      <font color="black">FinChat: Corpus and evaluation setup for Finnish chat conversations on
  everyday topics</font>
    </a>
  </h2>
  <font color="black">FinChatには、さまざまな年齢の人々からの7つのトピックに関するスクリプトなしの会話が含まれています。オープンドメインのチャットボットを作成するには、それらを評価するために大量の会話データと関連するベンチマークタスクが必要です。フィンランドのチャット会話コーパスFinChatを作成するための収集作業について説明します。公開しました。 
[ABSTRACT]フィンランドのチャットボット研究は、チャットボット研究の出発点を提供します。チャットボットは、さまざまな年齢の人々からの7つのトピックについて、スクリプトなしの会話を使用します。会話コーパスでトレーニングされたチャットボットモデルは、自動メトリックに基づいて正しい答えを選択するチャンスよりも優れていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Sequence Modeling Ability of Recurrent Neural Networks via
  Sememes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CL/paper_5.html">
      <font color="black">Improving Sequence Modeling Ability of Recurrent Neural Networks via
  Sememes</font>
    </a>
  </h2>
  <font color="black">評価では、PTBとWikiText-2を含むいくつかのベンチマークデータセットを言語モデリングに使用し、SNLIを自然言語推論に使用し、別の2つのデータセットを感情分析と言い換え検出に使用します。実験結果は、バニラRNNと比較して、私たちの精液組み込みモデルの明白で一貫した改善を示しています。これは、私たちの精液組み込み方法の有効性を証明しています。 
[要約] 3つの異なるseme組み込みメソッドを設計し、lstm、gru、およびそれらの双方向バリアントを含む典型的なrnnsでそれらを使用します。実験は、バニラrnnsと比較して、seme組み込みモデルの明白で一貫した改善を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-20">
        <br><font color="black">2019-10-20</font>
      </time>
    </span>
</section>
<!-- paper0: NMT-based Cross-lingual Document Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CL/paper_6.html">
      <font color="black">NMT-based Cross-lingual Document Embeddings</font>
    </a>
  </h2>
  <font color="black">クロスリンガルドキュメント分類タスクでは、新しいcNVはNVと同様に機能し、フォワードパスデコードを必要とする他の公開された研究よりも優れています。ベクトル（NTDVまたは単にNV）。新しいメソッドは制約付きNV（cNV）と呼ばれます。 
[要約]新しい方法は制約付きnv（cnv）と呼ばれます。埋め込みが同じモデルに類似していることは保証されていません。新しいトレーニング方法は、</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-07-29">
        <br><font color="black">2018-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Context-Based Quotation Recommendation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CL/paper_7.html">
      <font color="black">Context-Based Quotation Recommendation</font>
    </a>
  </h2>
  <font color="black">質的分析は、パラグラフとスパンの推奨タスクの難しさを示し、最良のBERTモデルの予測が、元のニュース記事からの真に選択された引用ではない場合でも、その予測可能性を確認します。メールやエッセイの場合、著者はさまざまなソースからの直接引用を利用することがよくあります。音声書き起こしと関連するニュース記事のコレクションで実験を行い、モデルの段落ランキングとスパン予測パフォーマンスを評価します。 
[ABSTRACT]私たちは、オープンドメインの変種として引用推奨事項に取り組みます。実験は、このタスクに関するbertベースのメソッドの強力なパフォーマンスを確認します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-17">
        <br><font color="black">2020-05-17</font>
      </time>
    </span>
</section>
<!-- paper0: Victim or Perpetrator? Analysis of Violent Characters Portrayals from
  Movie Scripts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CL/paper_8.html">
      <font color="black">Victim or Perpetrator? Analysis of Violent Characters Portrayals from
  Movie Scripts</font>
    </a>
  </h2>
  <font color="black">これまでに、映画の脚本で使用されている言語が暴力的なコンテンツの強力な指標であること、および大規模なデータセットの犠牲者や加害者としての特定の人口統計の体系的な描写があることを示した最初の例です。この作業では、その役割のためにキャストされた俳優の人口統計に基づくキャラクターの役割（すなわち、犠牲者、加害者、ナレーター）。計算方法が映画の暴力の大規模分析に役立つことを提案します。 
[ABSTRACT]開発する方法は、スクリプトのみから作成を特徴付けます。この方法は、スクリプトで使用される言語に基づいています。結果は、描写の頻度に2つの大きな違いがあることを強調しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: BabelEnconding at SemEval-2020 Task 3: Contextual Similarity as a
  Combination of Multilingualism and Language Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CL/paper_9.html">
      <font color="black">BabelEnconding at SemEval-2020 Task 3: Contextual Similarity as a
  Combination of Multilingualism and Language Models</font>
    </a>
  </h2>
  <font color="black">私たちの仮説は、追加の言語からの証拠が人間が生成したスコアとの相関関係を活用できるということです。単語のペア間のコンテキスト類似度を計算するために、翻訳および多言語モデルに依存するアプローチを提案します。BabelEncondingは両方のサブタスクに適用されました8つのタスクと言語の組み合わせのうち6つでトップ3にランクされ、3倍のスコアリングシステムでした。 
[ABSTRACT] babelencondingは両方のサブタスクに適用され、上位にランク付けされました-8つのタスク/言語の組み合わせのうち6つに3つ。最高のスコアリングシステムで3回</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: UoB at SemEval-2020 Task 12: Boosting BERT with Corpus Level Information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CL/paper_10.html">
      <font color="black">UoB at SemEval-2020 Task 12: Boosting BERT with Corpus Level Information</font>
    </a>
  </h2>
  <font color="black">ただし、いくつかのタスクでは、コーパスレベルで利用可能な情報（用語頻度-逆ドキュメント頻度（TF-IDF）など）を利用できます。サブタスクA（乱用検出）に参加し、最高パフォーマンスのチームとサブタスクB（ターゲット検出）で、44の参加チームの4つにランク付けされています。BERTなどの事前トレーニング済みの言語モデルの単語表現は、いくつかの自然言語処理タスクで非常に成功して、大幅に改善されています最先端の。 
[ABSTRACT]この情報をbertと統合することの有効性をテストします。また、実際にパフォーマンスが大幅に向上することも示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Leveraging Historical Interaction Data for Improving Conversational
  Recommender System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CL/paper_11.html">
      <font color="black">Leveraging Historical Interaction Data for Improving Conversational
  Recommender System</font>
    </a>
  </h2>
  <font color="black">私たちは2つの事前トレーニングタスクを慎重に設計して、アイテムベースと属性ベースのプリファレンス間の情報の融合を強化しています。最近、会話レコメンダーシステム（CRS）が新しく実用的な研究トピックになりました。 CRSを改善するための相互作用データ。 
[ABSTRACT]新しい方法では、事前トレーニング方法を使用して、会話データのみから効果的な嗜好表現の学習を改善します。新しい方法は、学習パフォーマンスを改善するために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: On the Relation between Quality-Diversity Evaluation and
  Distribution-Fitting Goal in Text Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CL/paper_12.html">
      <font color="black">On the Relation between Quality-Diversity Evaluation and
  Distribution-Fitting Goal in Text Generation</font>
    </a>
  </h2>
  <font color="black">パフォーマンス評価では、通常、品質と多様性のメトリックが適用されます。また、一般的に使用されるBLEU / Self-BLEUメトリックペアは、どの分岐メトリックとも一致しないため、品質/多様性メトリックペアの代わりとしてCR / NRRを提案します。テキスト生成モデルの目標は、基礎となるテキストの実際の確率分布に適合させることです。 
[ABSTRACT]パフォーマンス評価では、品質と多様性の指標が通常適用されます。標準の標準ブルー/自己ブルー指標は実際の発散指標と一致しません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-03">
        <br><font color="black">2020-07-03</font>
      </time>
    </span>
</section>
<!-- paper0: Transformer based Multilingual document Embedding model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/cs.CL/paper_13.html">
      <font color="black">Transformer based Multilingual document Embedding model</font>
    </a>
  </h2>
  <font color="black">第3に、NMT変換損失関数に新しい距離制約損失を追加します。現在の最先端の多言語ドキュメント埋め込みモデルの1つは、双方向LSTMベースの多言語ニューラル機械翻訳モデル（LASER）です。これ距離制約の喪失により、並列文の埋め込みがベクトル空間でさらに接近します。距離制約付きトレーニング済みT-LASERモデルをcT-LASERと呼びます。 
[ABSTRACT]このペーパーでは、トランスフォーマーベースのセンテンスパーエンベディングモデルであるt-laserを紹介しました。これにより、3つの改善が行われます。レーザーを使用すると、エンコーダーでの並列計算を高速化して、テキストの埋め込みを生成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Vector-quantized neural networks for acoustic unit discovery in the
  ZeroSpeech 2020 challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.AS/paper_0.html">
      <font color="black">Vector-quantized neural networks for acoustic unit discovery in the
  ZeroSpeech 2020 challenge</font>
    </a>
  </h2>
  <font color="black">アイデアは、将来の音響単位を予測することによって音声の表現を学習することです。VQ-VAEは、音声波形を再構成する前に音声を離散単位のシーケンスにエンコードします。2番目のモデルは、ベクトル量子化とコントラスト予測コーディング（VQ-CPC）を組み合わせたものです。 。 
[ABSTRACT]これはゼロスピーチ2020チャレンジです。スピーチの明確な表現を学習することを目的としています。2つのモデルは、ダウンストリームの音声変換タスクでも競合的に実行します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-19">
        <br><font color="black">2020-05-19</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Sequence Modeling Ability of Recurrent Neural Networks via
  Sememes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.AS/paper_1.html">
      <font color="black">Improving Sequence Modeling Ability of Recurrent Neural Networks via
  Sememes</font>
    </a>
  </h2>
  <font color="black">評価では、PTBとWikiText-2を含むいくつかのベンチマークデータセットを言語モデリングに使用し、SNLIを自然言語推論に使用し、別の2つのデータセットを感情分析と言い換え検出に使用します。実験結果は、バニラRNNは、私たちの精液組み込み方法の有効性を証明します。さらに、私たちは、精液組み込みモデルのロバスト性が高く、敵対的攻撃の防御において敵対的トレーニングよりも優れていることを発見しました。 
[要約] 3つの異なるseme組み込みメソッドを設計し、lstm、gru、およびそれらの双方向バリアントを含む典型的なrnnsでそれらを使用します。実験は、バニラrnnsと比較して、seme組み込みモデルの明白で一貫した改善を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-20">
        <br><font color="black">2019-10-20</font>
      </time>
    </span>
</section>
<!-- paper0: HpRNet : Incorporating Residual Noise Modeling for Violin in a
  Variational Parametric Synthesizer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.AS/paper_2.html">
      <font color="black">HpRNet : Incorporating Residual Noise Modeling for Violin in a
  Variational Parametric Synthesizer</font>
    </a>
  </h2>
  <font color="black">持続音のスペクトル包絡線の変分符号化の過程で導出された潜在空間の観察を通じて、信号の各高調波成分と残差成分、およびそれらの相互依存性に関する洞察を取得します。この作業では、バイオリントーンのパラメトリックモデル、特に残留ボウノイズの生成モデリングは、より自然な音質を実現します。オーディオ合成の生成モデルは、ここ数年で勢いを増しています。 
[要約]オーディオ信号のパラメトリック表現が組み込まれ、生成された出力のより良い音楽制御を容易にします。より良い音楽空間を可能にするために、ノイズのパラメトリックモデルが導入されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervised pre-training with acoustic configurations for replay
  spoofing detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-20/eess.AS/paper_3.html">
      <font color="black">Self-supervised pre-training with acoustic configurations for replay
  spoofing detection</font>
    </a>
  </h2>
  <font color="black">ASVspoof 2019物理アクセスデータセットに基づいて、提案された方法の有効性を2つの高性能システムを利用して検証します。具体的には、発話からセグメントのペアを選択し、ディープニューラルネットワークをトレーニングして、2つのセグメントの音響構成が同一かどうかを判断します..ここで、音響構成とは、音声の録音プロセス中に生成される環境要因を指しますが、マイクの種類、場所、周囲の騒音レベルなど、音声自体は指しません。 
[要約]提案された方法は、ベースラインアプローチより30％優れています。この結果は、提案されたシステムが基準よりも標準よりも優れていることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-22">
        <br><font color="black">2019-10-22</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
