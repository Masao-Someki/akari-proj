<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-05-22の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Coswara -- A Database of Breathing, Cough, and Voice Sounds for COVID-19
  Diagnosis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.SD/paper_0.html">
      Coswara -- A Database of Breathing, Cough, and Voice Sounds for COVID-19
  Diagnosis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これに向けて、この論文では、Coswaraと呼ばれる、咳、呼吸、声などの呼吸音のデータベースを作成（および分析）するための初期の取り組みを紹介します。パンデミックが進展しているため、データの収集と分析は、進歩.. COVID-19のパンデミックは、国、人種、宗教、経済の境界を越えた世界的な課題を提示します。 
[要約] covid、呼吸音の現在のゴールドスタンダードの方法は、有用な洞察を提供し、診断ツールの設計を可能にします。サウンドサンプルは、Webサイトアプリケーションを使用して世界中のクラウドソーシングで収集されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Conversational End-to-End TTS for Voice Agent -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.SD/paper_1.html">
      Conversational End-to-End TTS for Voice Agent
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、補助エンコーダーと会話型コンテキストエンコーダーを備え、会話中の現在の発話とそのコンテキストに関する情報も強化する、会話型コンテキスト対応のエンドツーエンドTTSアプローチを提案します。実験結果は、メソッドは、会話コンテキストに応じてより自然な韻律を生成し、発話レベルと会話レベルの両方で大幅な優先度の向上をもたらします。エンドツーエンドのニューラルTTSは、リーディングスタイルの音声合成で優れたパフォーマンスを実現しました。 
[要約]ヨーク大学の研究者は、音声エージェント用に適切に設計された会話スピーチコーパスを構築しています。提案された方法は、会話コンテキストに応じてより自然な韻律を生成します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Pitchtron: Towards audiobook generation from ordinary people's voices -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.SD/paper_2.html">
      Pitchtron: Towards audiobook generation from ordinary people's voices
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      GSTのAXYスコアは、ハードピッチトロンとソフトピッチトロンではそれぞれ2.01と1.14です。ハードピッチトロンはピッチをデコーダーへの入力として使用し、ソフトピッチトロンはピッチを韻律エンコーダへの入力として使用します。客観的および主観的な提案モデルの有効性を検証します。テスト。 
[ABSTRACT]この問題に対処するために、ハードとソフトの2つのモデルを提案します。pitchlit.pitchtronは、開発したツールキットとコーパスを使用します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Inaudible Adversarial Perturbations for Targeted Attack in Speaker
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.SD/paper_3.html">
      Inaudible Adversarial Perturbations for Targeted Attack in Speaker
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、摂動を測定するために共通のl_pノルムを使用する代わりに、元のオーディオのマスキングしきい値の下で摂動を制限します。Aishell-1コーパスでの実験により、このアプローチでは、任意の性別スピーカーターゲットに対して最大98.5％の攻撃成功率が得られることが示されています。 、リスナーに区別できない属性を保持しながら。。さらに、提案されたアプローチを音楽などの完全に無関係な波形に適用すると、効果的なスピーカーアタックも実現します。 
[要約]私たちは、周波数マスキングの心理音響学的原理に基づいて、話者認識システムに聞こえない敵対的摂動を生成することを提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Cross-lingual Multispeaker Text-to-Speech under Limited-Data Scenario -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.SD/paper_4.html">
      Cross-lingual Multispeaker Text-to-Speech under Limited-Data Scenario
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      バイリンガルデータセットを使用すると、モデルは、話している言語に関するすべての話者に対して忠実なスピーチを生成できるだけでなく、非母国語に関する単一言語の話者に対してアクセントがありながら流暢でわかりやすいスピーチを生成できます。{https：// caizexin.github.io/mlms-syn-samples/index.html} ..たとえば、北京語話者は英語を流暢に話すことができます。 
[ABSTRACT] 2つの言語は入力の同じ音素表現を共有しますが、言語属性と話者IDは、話者の埋め込みによって個別に制御されます。システムは、非ネイティブ言語に関する単一言語話者に対して、アクセントがありながら流暢でわかりやすい音声を生成できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Formant Tracking Using Dilated Convolutional Networks Through Dense
  Connection with Gating Mechanism -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.SD/paper_5.html">
      Formant Tracking Using Dilated Convolutional Networks Through Dense
  Connection with Gating Mechanism
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      第2に、各非表示レイヤーは、密な接続を介して以前のすべてのレイヤーからの出力情報を再利用しました。第3に、重要でない情報を選択的に忘れることによって勾配消失の問題を緩和するためにゲーティングメカニズムも採用しました。従来の実装に加えて、 3つの側面からのアーキテクチャ。 
[要約]このペーパーでは、フォルマント追跡のための時間的対比ネットワーク（tcn）の使用を検討しました。最初に、拡張された畳み込みの「因果的」モードをオフにして、拡張された畳み込みが将来の音声フレームを見るようにしました。重要でない情報を密かに忘れているシステムに収束することができました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Leveraging Text Data Using Hybrid Transformer-LSTM Based End-to-End ASR
  in Transfer Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.SD/paper_6.html">
      Leveraging Text Data Using Hybrid Transformer-LSTM Based End-to-End ASR
  in Transfer Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に重要なことですが、提案されたハイブリッドアーキテクチャは、LSTMおよびトランスフォーマアーキテクチャの両方と比較して推論がはるかに高速です。結果は、提案されたアーキテクチャが以前のLSTMベースのアーキテクチャ
[1]よりも24.2％相対ワードエラー率（WER）だけ優れていることを示しています。限られたラベル付きデータを使用してトレーニングされます。これから、リソースが豊富な別の言語からの転移学習により、さらに25.4％の相対WER削減が得られます。 
[要約]マレーシアのコーパスで1.5％のテキストを含む実験を行います。これは、合計13％と比較されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Training Keyword Spotting Models on Non-IID Data with Federated Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.SD/paper_7.html">
      Training Keyword Spotting Models on Non-IID Data with Federated Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、例にラベルを付ける（デバイス上のデータの可視性がゼロの場合）ために、教師と生徒のトレーニングを検討します。リソースの制約を克服するために、メモリを集中的に使用するMTRデータ拡張をSpecAugmentに置き換えます。これにより、誤った拒否率が56％削減されます。 。本番品質のキーワードスポッティングモデルは、統合学習を使用してデバイス上でトレーニングでき、中央でトレーニングされたモデルと同等の誤認および誤認率を達成できることを示しています。 
[ABSTRACT]オンデバイスデータのフィッティングに関連するアルゴリズムの制約を克服するために、アルゴリズムとハイパーパラメーター構成の徹底的な調査を実施します。例をテストするために、教師と生徒のトレーニングを調査します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ASAPP-ASR: Multistream CNN and Self-Attentive SRU for SOTA Speech
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.SD/paper_8.html">
      ASAPP-ASR: Multistream CNN and Self-Attentive SRU for SOTA Speech
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、音響モデリング用のマルチストリームCNNと言語モデリング用の自己注意型単純反復ユニット（SRU）の2つの新しいニューラルネットワークアーキテクチャを備えたLibriSpeechコーパスの最先端（SOTA）パフォーマンスを示します。 SpecAugmentデータ拡張メソッドを使用すると、テストクリーンで4％、テストその他で14％の相対ワードエラー率（WER）の改善を実現します。ハイブリッドASRフレームワークでは、マルチストリームCNN音響モデルが音声フレームの入力を処理します。各ストリームが多様性のためのユニークな拡張率を持っている複数の並列パイプラインで。 
[ABSTRACT]ハイブリッドasrフレームワークでは、マルチストリームcnn音響モデルが複数の並列パイプラインで音声フレームの入力を処理します。n-24のアートモデルを使用した最高のスコアリングにより、パフォーマンスをさらに向上させます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multistream CNN for Robust Acoustic Modeling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.SD/paper_9.html">
      Multistream CNN for Robust Acoustic Modeling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      マルチストリームCNNは、データ増強方法で訓練されており、LibriSpeechコーパスのtest-otherセットのWERを12％（相対）向上させます。提案されたアーキテクチャは、音響モデリングの堅牢性を実現するために、複数のストリームでさまざまな時間解像度に対応します。埋め込み処理における時間分解能の観点から、1D-CNNの変形であるTDNN-Fの拡張を検討します。 
[要約]提案されたアーキテクチャは、複数のストリームで異なる空間解像度に対応し、音響モデリングの堅牢性を実現します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: End-to-End Far-Field Speech Recognition with Unified Dereverberation and
  Beamforming -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.SD/paper_10.html">
      End-to-End Far-Field Speech Recognition with Unified Dereverberation and
  Beamforming
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      マルチソース入力を処理できる元のWPDから新しい定式化を導出し、固有値分解を逆行列演算に置き換えて、逆伝播アルゴリズムをより安定させます。上記の2つのアーキテクチャは完全に最適化されており、エンド方式で、音声認識基準のみを使用します。最初に、マルチソースマスクベースの重み付き予測エラー（WPE）モジュールが残響除去のためにフロントエンドに組み込まれています。 
[要約] 2つの新しいフロントエンドアーキテクチャが新しい論文で提案されています。完全に最終的に最適化されます。従来の方法で、音声認識基準のみを使用します。2つのアーキテクチャは、認識標準を使用するように最適化されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Simplified Self-Attention for Transformer-based End-to-End Speech
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.SD/paper_11.html">
      Simplified Self-Attention for Transformer-based End-to-End Speech
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      印象的な20％のパラメーター削減により、私たちのモデルは20,000時間の大規模タスクで認識性能の損失を示しません。SSANベースおよび従来のSANベースの変圧器を、公共のAISHELL-1で評価します。内部1000時間20,000時間の大規模マンダリンタスク。変圧器モデルがエンドツーエンドの音声認識に導入され、長期的な依存関係のモデル化における優れた機能により、さまざまなタスクで最先端のパフォーマンスを発揮します。 
[ABSTRACT]変圧器モデルは、aishellで20％以上の実際の削減を達成できます-1つのタスク
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An approach to Beethoven's 10th Symphony -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.SD/paper_12.html">
      An approach to Beethoven's 10th Symphony
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      出力の構造は、ネットワークのトレーニングに使用される交響曲に強く依存します。ルートヴィヒヴァンベートーベンは、第10交響曲を書いている1799年から1825年の間に交響曲を作曲しました。モデルのトレーニング後、生成された音楽を比較して分析しました。結果を含む入力データ、およびそれらを取得するために使用されるトレーニングデータに基づいて生成された出力間の差異を確立します。 
[ABSTRACT]作曲された音楽は、入力データと結果を比較することによって分析されました。また、それらを取得するために使用されたトレーニングデータに基づいて、生成された出力間の差異を確立しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Understanding the Importance of Heart Sound Segmentation for Heart
  Anomaly Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.SD/paper_13.html">
      Understanding the Importance of Heart Sound Segmentation for Heart
  Anomaly Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この研究では、心音分類の前のステップとして心音セグメンテーションの重要性を明示的に調べ、得られた洞察を適用して、異常な心音検出のためのロバストな分類器を提案します。実験結果は、セグメンテーションが異常な心音の分類における重要な役割..分野の一部の研究者は、セグメンテーションステップは不要な計算負荷であると主張していますが、他の研究者は、特徴抽出の前のステップとしてそれを採用しています。 
[要約]最初の段階では、心音をセグメント化して心音を検出します。その後、特徴が抽出されて分類が実行されます。特徴抽出がまだ開かれている前に心音をセグメント化するかどうかの質問
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Environmental Sound Classification with Parallel Temporal-spectral
  Attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.SD/paper_14.html">
      Environmental Sound Classification with Parallel Temporal-spectral
  Attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、一時的な注意メカニズムがCNNで使用され、特に音声イベントの開始時間とオフセット時間が適用されない弱くラベル付けされたデータについて、オーディオ分類に関連する時間フレームから有用な情報を取得しました。この論文では、 CNNが差別的なサウンド表現を学習するための新しい並列時間スペクトル注意メカニズム。これは、異なる時間フレームと周波数帯域の重要性をキャプチャすることにより、時間的およびスペクトル的特徴を強化します。3つの環境音分類（ESC）データセットと2つの音響データの実験シーン分類（ASC）データセットは、この方法が分類パフォーマンスを改善し、ノイズに対する堅牢性も示すことを示しています。 
[要旨] cnnのシステムはcnnを使用して、オーディオ分類に関連する時間枠から有用な情報を取得します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-14">
        <br>2019-12-14
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: SafeComp: Protocol For Certifying Cloud Computations Integrity -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_0.html">
      SafeComp: Protocol For Certifying Cloud Computations Integrity
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのプロトコルは、最も近い関連作業と比較して、証明構築の複雑さを$ O（n \ log {n}）$から$ O（n）$に減らし、同等の長さの証明書を使用して通信の複雑さを正確に1ラウンドにします。 。必ずしも信頼できない一部のリモートパーティによって実行される計算の整合性を証明する問題を定義します。この問題を特定の制約の下で解決するSafeCompと呼ばれるマルチパーティインタラクティブプロトコルを提示します。 
[要旨]この問題を解決するsafecompと呼ばれるマルチパーティのインタラクティブプロトコルを紹介します。目標は問題を解決することです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transformer Based Language Models for Similar Text Retrieval and Ranking -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_1.html">
      Transformer Based Language Models for Similar Text Retrieval and Ranking
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これを実現するには、トランスフォーマー（BERT）からの双方向エンコーダー表現を使用して、文長テキストのベクトル化表現と、ベクトル最近傍検索インデックスを作成します。バッグオブワードベースのステップを排除することにより、このアプローチでは、クエリと共通のストップワードがない場合でも、結果を正確に取得してランク付けします。類似したテキストの取得と長い自然言語クエリによるランク付けのほとんどのアプローチは、互いに共通の単語を持つクエリと応答にある程度依存しています。 
[ABSTRACT]私たちは、bertを使用してこのタスクを達成するための監視された方法と監視されていない方法の両方を示しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-10">
        <br>2020-05-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Symptom extraction from the narratives of personal experiences with
  COVID-19 on Reddit -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_2.html">
      Symptom extraction from the narratives of personal experiences with
  COVID-19 on Reddit
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      トピックモデリングと感情分析を使用して、症状の発生後の最初の14日間の個人の経験を通じてCOVID-19の議論の変化を定量化します。重要なケースに関するいくつかの会話も特定され、ほぼ一定の割合で現れました。発熱、咳、喉の痛みなどの初期症状は投稿の初めに集中していたが、呼吸の問題を示す言葉は約10日でピークに達した。 
[要約]ソーシャルメディアは、症状の各段階が患者にもたらす感情を識別できます。ソーシャルメディアアカウントは、症状が発現してから19日後に識別できます。情報は、人々が自分の経験を自己報告するときに識別できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Quality Estimation for Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_3.html">
      Unsupervised Quality Estimation for Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      不確実性の定量化の方法を採用することにより、人間による品質の判断と非常に良好な相関を達成し、最先端の監視付きQEモデルに匹敵します。このアプローチを評価するために、ブラックボックスとガラスの両方で作業を可能にする最初のデータセットを収集します-boxはQEにアプローチします。MTシステムをブラックボックスとして扱う現在のほとんどの作業とは異なり、MTシステムから翻訳の副産物として抽出できる有用な情報を探ります。 
[ABSTRACT]既存のアプローチでは、エキスパートによる注釈付きの大量のデータ、計算、トレーニングに時間が必要
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: MTSS: Learn from Multiple Domain Teachers and Become a Multi-domain
  Dialogue Expert -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_4.html">
      MTSS: Learn from Multiple Domain Teachers and Become a Multi-domain
  Dialogue Expert
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、これらのドメイン固有の教師は、ドメインの知識とポリシーを普遍的な生徒モデルに付与し、この生徒モデルをまとめてマルチドメインの対話エキスパートにします。実際の学校の教育シナリオに触発されて、私たちの方法は複数のドメイン固有の教師と普遍的な学生..実験結果は、私たちの方法がマルチドメインとシングルドメインの両方の設定でSOTAを使用して競争力のある結果に達することを示しています。 
[ABSTRACT]満足のいくポリシーを取得し、マルチドメイン設定で節のある対話状態表現の問題を回避する新しい方法を提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Automated Question Answer medical model based on Deep Learning
  Technology -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_5.html">
      Automated Question Answer medical model based on Deep Learning
  Technology
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この研究では、これらの質問に対する適切な回答を生成し、一種のデジタルドクターを作成するプロセスを自動化することによって、この問題の解決策を紹介します。さらに、この研究では、RNNのフレームワークとエンコーダー/デコーダーを使用してエンドツーエンドモデルをトレーニングし、医療/健康問題の小さなセットに対する賢明で有用な回答を生成します。 
[ABSTRACT]新しい研究は、rnnのフレームワークとエンコーダー-デコーダーを使用してエンドツーエンドモデルをトレーニングし、医療または健康問題の小さなセットに対する賢明な回答を生成します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: RuBQ: A Russian Dataset for Question Answering over Wikidata -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_6.html">
      RuBQ: A Russian Dataset for Question Answering over Wikidata
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      データは、自動フィルタリング、クラウド支援エンティティリンク、SPARQLクエリの自動生成、およびその後の社内検証を受けました。高品質のデータセットは、複雑さの異なる1,500のロシア語の質問、英語の機械翻訳、WikidataへのSPARQLクエリで構成されています、参照回答、およびロシア語のラベルが付いたエンティティを含むトリプルのWikidataサンプル。データセットの作成は、オンラインクイズからの質問と回答のペアの大規模なコレクションから始まりました。 
[ABSTRACT]データセットは、さまざまな知識の1、500のロシア語の質問で構成されています。回答には、ロシア語のラベルを持つエンティティを含むトリプルのwikidataサンプルが含まれていました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards Finite-State Morphology of Kurdish -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_7.html">
      Towards Finite-State Morphology of Kurdish
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      単語を生成および分析するための有限状態トランスデューサーに変換される形態学的ルールを抽出します。この研究の結果は、クルド語の言語生成に関する研究の実施を支援し、クルド語NLPを活用しながら言語の情報検索（IR）能力を強化します。この論文では、この種の最初の試みとして、クルド語（ソラニ方言）の形態を計算の観点から説明します。 
[要約]クルド語の文法がより高度なコンピューティングレベルに変換されました。ソラニフルをベースにした、この種の最初の試みです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Text-to-Text Pre-Training for Data-to-Text Tasks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_8.html">
      Text-to-Text Pre-Training for Data-to-Text Tasks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、モデルは完全にエンドツーエンドであり、中間の計画ステップ、非字句化、またはコピーメカニズムに依存しません。T5の事前トレーニングは、ドメイン外のテストセットの大幅な改善によって証明されているように、ストリンガーの一般化も可能にします。 。事前トレーニングがデータからテキストへのタスクにますます普及するようになるため、私たちの作業が将来の研究の有用なベースラインとして役立つことを願っています。 
[ABSTRACT] t5は、webnlg、multiwozおよびtottoベンチマークで最先端の結果を達成しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The Frankfurt Latin Lexicon: From Morphological Expansion and Word
  Embeddings to SemioGraphs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_9.html">
      The Frankfurt Latin Lexicon: From Morphological Expansion and Word
  Embeddings to SemioGraphs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このようにして、この記事では、古典的な機械学習だけでなく、知的事後修正、特に基礎となる語彙リソースのグラフ表現に基づく解釈プロセスの形での人間の計算を含む、見出し語化のより包括的な理解を主張しています。この記事では、中世ラテン語の語彙リソースであるフランクフルトラテン語辞書（FLL）を紹介します。この語彙は、ラテン語のテキストの見出し語化と見出し語の事後編集の両方に使用されます。また、 FLLの継続的なレビューと更新を目的とした限定的なクラウドソーシングプロセス。 
[要約] capitulariesコーパスは、中世ラテン語を処理するためのリファレンスとして作成されたコーパスです。単語の埋め込みを使用して、fllの拡張子を記述します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Text Matters but Speech Influences: A Computational Analysis of
  Syntactic Ambiguity Resolution -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_10.html">
      Text Matters but Speech Influences: A Computational Analysis of
  Syntactic Ambiguity Resolution
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらなる分析により、計算モデルが聴覚プロセスと言語プロセスの内部関係を反映していることを示しています。構文的に曖昧な発話の韓国語台本に記録された音声コーパスを利用して、共注意フレームワーク、つまりマルチホップ注意とクロス注意、スピーチ意図の明確化において非常に優れたパフォーマンスを示します。人間が構文のあいまいさをどのように解決するかを分析することは、言語学の分野で長い間関心のある問題でした。 
[ABSTRACT]韓国語のコミュニケーションは話し言葉の重要な問題です。話し言葉の問題を克服することが重要です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-21">
        <br>2019-10-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SentiBERT: A Transferable Transformer-Based Architecture for
  Compositional Sentiment Semantics -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_11.html">
      SentiBERT: A Transferable Transformer-Based Architecture for
  Compositional Sentiment Semantics
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      包括的な実験は、SentiBERTがフレーズレベルの感情分類で競争力のあるパフォーマンスを達成することを示しています。構成感情のセマンティクスを効果的にキャプチャするBERTのバリアントであるSentiBERTを提案します。 
[ABSTRACT]否定と対照的な関係を捉える際に、センチベールがベースラインアプローチよりも優れていることを示し、構成感情の意味をモデル化します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-08">
        <br>2020-05-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Worse WER, but Better BLEU? Leveraging Word Embedding as Intermediate in
  Multitask End-to-End Speech Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_12.html">
      Worse WER, but Better BLEU? Leveraging Word Embedding as Intermediate in
  Multitask End-to-End Speech Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      音声翻訳（ST）は、ソース言語の音声からターゲット言語のテキストへの変換を学習することを目的としています。認識デコーダの出力が正しいセマンティクスを持っているかどうかは、その正確さよりも重要であるため、マルチタスクSTを改善することを提案します。単語埋め込みを中間として使用することによるモデル。以前の作品は、マルチタスク学習がSTパフォーマンスを向上させることを示しています。この場合、認識デコーダーはソース言語のテキストを生成し、翻訳デコーダーは認識デコーダーの出力に基づいて最終的な翻訳を取得します。 。 
[ABSTRACT]研究は、マルチタスク学習がstのパフォーマンスを向上させることを示しています。認識デコーダーはソース言語のテキストを生成します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Cross-Linguistic Syntactic Evaluation of Word Prediction Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_13.html">
      Cross-Linguistic Syntactic Evaluation of Word Prediction Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      多言語BERTは、英語では高い構文精度を示しましたが、他の言語では顕著な欠陥がありました。他の構文では、一致精度は一般に、形態が豊富な言語でより高くなりました。オブジェクト関連の条項間の合意について。 
[要約]単一言語アサリの研究は、english.monolingual lstmsが、attractgram.multilingualモデルが一般的にパフォーマンスの低い単一言語モデルを使用せずに、依存関係に対して高い精度を達成したことを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br>2020-05-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: BLEURT: Learning Robust Metrics for Text Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_14.html">
      BLEURT: Learning Robust Metrics for Text Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちはBLEURTを提案します。これは、BERTに基づいて学習された評価指標であり、数千の偏ったトレーニング例で人間の判断をモデル化できます。私たちのアプローチの重要な側面は、モデルの一般化に役立つ数百万の合成例を使用する新しい事前トレーニングスキームです.. BLEURTは、WMTメトリックの共有タスクとWebNLG競争データセットの過去3年間の最先端の結果を提供します。 
[ABSTRACT]評価指標は遅れています。最も一般的な選択は人間の判断とあまり相関しない可能性があるためです。私たちのアプローチの重要な側面は、モデルの一般化に役立つ数百万の合成例を使用する新しい事前トレーニングスキームです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br>2020-04-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Textual Membership Queries -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_15.html">
      Textual Membership Queries
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このフレームワークをテキストドメインに実装し、いくつかのテキスト分類タスクでテストし、より多くのMQがラベル付けされてトレーニングセットに組み込まれると、分類子のパフォーマンスが向上することを示します。オペレーターを小さなインスタンスセット（コアセット）に適用して、新しいメンバーシップクエリのセット。このフレームワークを使用して、インスタンススペースを検索スペースと見なし、検索アルゴリズムを適用して、学習者に関連性の高い新しい例を生成します。 
[ABSTRACT]これは、文学分野でのメンバーシップクエリに関する最初の作品です。知る限りでは、クエリに参加するのはこれが初めてです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-05-11">
        <br>2018-05-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Unified MRC Framework for Named Entity Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_16.html">
      A Unified MRC Framework for Named Entity Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この定式化は、ネストされたNERのエンティティ重複問題に自然に取り組みます。異なるカテゴリの2つの重複エンティティの抽出には、2つの独立した質問に答える必要があります。たとえば、\ textsc {per}ラベルを持つエンティティの抽出は、質問への回答範囲の抽出として形式化されます。 &quot;{\ itどの人がテキストで言及されていますか？}&quot; ..ネストされたNERデータセット、つまり、それぞれ+ 1.28、+ 2.55、+ 5.44、+ 6.37の現在のSOTAモデルに比べて、パフォーマンスを大幅に向上させることができますACE04、ACE05、GENIA、KBP17、およびフラットNERデータセットのSOTA結果、つまり英語版CoNLL 2003、英語版OntoNotes 5.0、中国語版MSRA、中国語版OntoNotes 4.0ではそれぞれ+ 0.24、+ 1.95、+ 0.21、+ 1.49。 
[要約]フラットnerで最も広く使用されているバックボーンは、単一のラベルを特定のトークンに割り当てることができるだけです。nerのタスクをシーケンスのラベル付けの問題として扱うのではなく、それを機械読解（mrc）として定式化することを提案します） 仕事
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Hidden Markov Chains, Entropic Forward-Backward, and Part-Of-Speech
  Tagging -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_17.html">
      Hidden Markov Chains, Entropic Forward-Backward, and Part-Of-Speech
  Tagging
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この方法では、MEMCフレームワークと同じ方法でHMCフレームワークの機能を考慮に入れることができます。また、観点として、EFBを備えたHMCがリカレントニューラルネットワークの代わりにどのように表示されるかを指定し、アーキテクチャー。20年間、このデフォルトにより、任意の機能をエレガントに統合する最大エントロピーマルコフモデル（MEMM）から始まる他の順次モデルの開発が促進されてきました。 
[要約]隠しマルコフチェーン（hmc）モデルはmemmベースの機能を処理できます。20年前、nlpのhmcが無視されていましたが、このモデルがどのように自然言語に基づいているかは不明です。 memmベースの復元
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Top-Down Neural Architecture towards Text-Level Parsing of Discourse
  Rhetorical Structure -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_18.html">
      A Top-Down Neural Architecture towards Text-Level Parsing of Discourse
  Rhetorical Structure
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      特に、談話の解析を再帰的な分割ポイントランキングタスクとしてキャストします。この場合、分割ポイントはランクに従ってさまざまなレベルに分類され、それに関連付けられている基本的な談話ユニット（EDU）はそれに応じて配置されます。深い自然言語の理解とさまざまな下流アプリケーション、談話修辞構造（DRS）のテキストレベルの解析は、近年ますます注目を集めています。英語のRST-DTコーパスと中国語のCDTBコーパスの両方での実験により、テキストレベルのDRS解析に向けて提案されたトップダウンアプローチの優れた効果。 
[ABSTRACT]これはテキストに関する以前の研究に基づいています-レベルの談話解析です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Glyce: Glyph-vectors for Chinese Character Representations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_19.html">
      Glyce: Glyph-vectors for Chinese Character Representations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      タグ付け（NER、CWS、POS）、文のペアの分類、単一の文の分類タスク、依存関係の解析、セマンティックロールのラベル付けなど、さまざまな中国のNLPタスクに新しい最先端の結果を設定できます。たとえば、提案されたモデルは、NERのOntoNotesデータセットで80.6のF1スコア、BERTに対して+1.5を達成しています。テキスト分類のFudanコーパスで99.8 \％のほぼ完全な精度を達成します。https：//github.com/ShannonAI/glyceにあるコード。 
[ABSTRACT]さまざまな中国語のnlpタスクに新しい最先端の結果を設定できます。これらには、タグ付け、文のペアのデータ、単一の文の分類タスク、依存関係の解析、およびセマンティックロールノートが含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-01-29">
        <br>2019-01-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Fluent Response Generation for Conversational Question Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_20.html">
      Fluent Response Generation for Conversational Question Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、正確さを維持しながら流暢な文法応答応答を生成するために、SEQ2SEQ NLGアプローチ内でQA応答を配置する方法を提案します。具体的には、構文変換（ST）を開発して、質問固有の候補応答応答を生成し、 BERTベースの分類子（Devlin et al。、2019）。CoQAデータセットでテストを行うことにより、モデルのスケーラビリティをさらに示します。 
[ABSTRACT]新しいconvqaプロジェクトは、データ拡張を使用してエンドツーエンドシステムのトレーニングデータを生成します。提案されたモデルは、会話型応答の生成においてcoqaおよびquacモデルよりも優れています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: LaCulturaNonSiFerma -- Report su uso e la diffusione degli hashtag delle
  istituzioni culturali italiane durante il periodo di lockdown -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_21.html">
      LaCulturaNonSiFerma -- Report su uso e la diffusione degli hashtag delle
  istituzioni culturali italiane durante il periodo di lockdown
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このレポートは、イタリアの文化遺産機関がイタリアのCOVID-19ロックダウン期間中に文化コンテンツを宣伝および伝達するために使用する＃ハッシュタグの分析を示しています。これらのアクティビティのほとんどは、コンテンツの集計と作成に役立つ1つまたは複数の＃ハッシュタグを提示します特定のトピックに関するコミュニティ。ソーシャルメディアを使用して、ユーザーをサポートし、参加するためのいくつかの活動が提案されています。 
[ABSTRACT]イタリアの機関は、パンデミックシナリオへの適応に非常に積極的です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: MultiMWE: Building a Multi-lingual Multi-Word Expression (MWE) Parallel
  Corpora -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_22.html">
      MultiMWE: Building a Multi-lingual Multi-Word Expression (MWE) Parallel
  Corpora
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちが知っている唯一のバイリンガルMWEコーパスは、PARSEME（PARSingおよびマルチワード式）EUプロジェクトからのものです。MT実験でこれらの抽出されたバイリンガルMWEの品質を調べます。この論文では、マルチリンガルおよびルート並列コーパスから抽出したバイリンガルMWEコーパス。 
[ABSTRACT]これは、871組の英語-ドイツ語mwesの小さなコレクションです。これらのトピックは、スペクトルのルートから抽出されます。これには、mwe用語の翻訳パフォーマンスの向上が含まれます。研究者は、この無料のコーパスを独自のモデルまたは使用に使用できますそれらをモデル機能としてナレッジベースに
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Training Keyword Spotting Models on Non-IID Data with Federated Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_23.html">
      Training Keyword Spotting Models on Non-IID Data with Federated Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      リソースの制約を克服するために、メモリを集中的に使用するMTRデータの拡張をSpecAugmentに置き換えます。これにより、誤った拒否率が56％減少します。オンデバイスデータのフィッティングに関連するアルゴリズムの制約（本質的に独立しておらず、同一に分散されている）を克服するために、大規模なフェデレーションシミュレーションを使用して、最適化アルゴリズムとハイパーパラメーター構成の徹底的な実証研究を行います。 
[ABSTRACT]オンデバイスデータのフィッティングに関連するアルゴリズムの制約を克服するために、アルゴリズムとハイパーパラメーター構成の徹底的な調査を実施します。例をテストするために、教師と生徒のトレーニングを調査します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ASAPP-ASR: Multistream CNN and Self-Attentive SRU for SOTA Speech
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_24.html">
      ASAPP-ASR: Multistream CNN and Self-Attentive SRU for SOTA Speech
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SpecAugmentデータ拡張メソッドでトレーニングすると、テストクリーンで4％、テストその他で14％の相対ワードエラー率（WER）の改善が実現されます。ハイブリッドASRフレームワークでは、マルチストリームCNN音響モデルが音声の入力を処理します。複数の並列パイプライン内のフレーム。各ストリームは、多様性のために独自の拡張率を持っています。この論文では、2つの新しいニューラルネットワークアーキテクチャ、音響モデリング用のマルチストリームCNNを備えたLibriSpeechコーパスの最先端（SOTA）パフォーマンスを示します。言語モデリングのための自己注意型の単純反復ユニット（SRU）。 
[ABSTRACT]ハイブリッドasrフレームワークでは、マルチストリームcnn音響モデルが複数の並列パイプラインで音声フレームの入力を処理します。n-24のアートモデルを使用した最高のスコアリングにより、パフォーマンスをさらに向上させます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Training a code-switching language model with monolingual data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_25.html">
      Training a code-switching language model with monolingual data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたアプローチは、人工的に生成されたCSデータでCS言語モデルをトレーニングすることと同等またはそれ以上です。RNNベースの言語モデルで出力射影行列を制約および正規化することにより、異なる言語の埋め込みを互いに近づけます。教師なしのバイリンガルの単語翻訳。異なる言語の意味的に同等の単語が一緒にマッピングされているかどうかを分析します。 
[要約]提案されたアプローチは、異なる言語でトレーニングされたcs言語モデルのパフォーマンスを著しく改善します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-14">
        <br>2019-11-14
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multistream CNN for Robust Acoustic Modeling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_26.html">
      Multistream CNN for Robust Acoustic Modeling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      リアルタイムファクター（RTF）に関して、マルチストリームCNNは通常のTDNN-Fより15％優れており、これは本番システムまたはアプリケーションでの実用性も示唆しています。 LibriSpeechコーパスのその他のセットは12％（相対）。 
[要約]提案されたアーキテクチャは、複数のストリームで異なる空間解像度に対応し、音響モデリングの堅牢性を実現します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Stance Prediction and Claim Verification: An Arabic Perspective -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_27.html">
      Stance Prediction and Claim Verification: An Arabic Perspective
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      導入されたコーパスを使用して、2つの提案されたタスクの2つの機械学習ベースラインも開発します。クレーム検証とスタンス予測です。結果は、事前トレーニング中に学習された言語機能と世界知識はスタンス予測に役立ちますが、事前トレーニングから得られたそのような表現は不十分であることを示唆しています。コンテキストや証拠にアクセスせずにクレームを検証するため。コーパスの作成方法と注釈プロセスについて説明します。 
[ABSTRACT]公開されているコーパスはarabic.itで利用可能です。4、547の虚偽のクレームと3、786のペアのバージョン（クレーム、証拠）の2つの解釈があります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Beyond User Self-Reported Likert Scale Ratings: A Comparison Model for
  Automatic Dialog Evaluation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_28.html">
      Beyond User Self-Reported Likert Scale Ratings: A Comparison Model for
  Automatic Dialog Evaluation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      自動評価モデルCMADE（自動ダイアログ評価の比較モデル）も提案します。これは、自己報告されたユーザー評価をトレーニングするときに自動的にクリーンアップします。ただし、自己報告されたユーザー評価は、さまざまなユーザー間の偏りや変動に悩まされています。具体的には、まず、自己管理手法を使用してより適切なダイアログ機能の表現を学習し、次にKNNとShapleyを使用して混乱しているサンプルを削除します。 
[ABSTRACT]リッカートスコアに基づく自己評価は、Amazon Alexa賞のチャットボットなどのソーシャル会話システムで広く採用されています。この問題を緩和するために、比較タスクとしてダイアログ評価を定式化します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multipurpose Intelligent Process Automation via Conversational Assistant -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_29.html">
      Multipurpose Intelligent Process Automation via Conversational Assistant
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      転移学習（TL）メソッドを使用してシステムのいくつかのコンポーネントを再実装することにより、後者の使用法を紹介します。提案されたシステムは、2つの大きな利点をもたらします。よりインテリジェントなプロセスに焦点を当てます。このようなインテリジェントエージェントは、特定の質問に回答し、通常は自然言語で実行されるルーチンタスク（つまり、カスタマーサポート）を実行することにより、ユーザーを支援できます。 
[要旨]コミュニケーションエージェントは、自然なシステムでユーザーと対話できます。これらは自然なコミュニケーションシステムの潜在的なアプリケーションです。システムにより、トレーニングデータの欠如を利用できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-07">
        <br>2020-01-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Synthetic Error Dataset Generation Mimicking Bengali Writing Pattern -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_30.html">
      Synthetic Error Dataset Generation Mimicking Bengali Writing Pattern
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      英語のキーボードを使用してベンガル語を書いている間、ユーザーはスペルミスを犯すことがよくあります。この研究では、QWERTYレイアウトの英語キーボードを使用してベンガル語のライティングパターンを分析することにより、正しい単語から自動でスペルミスのベンガル語の単語を生成するアルゴリズムを紹介します。分析の一部として、は、最も一般的に使用されているベンガル語の単語、音声学的に類似した置換可能なクラスター、頻繁に誤入力された置換可能なクラスター、頻繁に誤入力されやすい挿入傾向のあるクラスター、およびエラーの生成中のJuktakkhar（定数文字クラスター）の処理に関するいくつかのルールのリストを形成しました。 
[ABSTRACT]自動スペルミスベンガル語の単語リストのアルゴリズムは、いくつかのエラーに基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-07">
        <br>2020-03-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Simplified Self-Attention for Transformer-based End-to-End Speech
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_31.html">
      Simplified Self-Attention for Transformer-based End-to-End Speech
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      印象的な20％のパラメーター削減により、このモデルは20,000時間の大規模タスクで認識パフォーマンスの損失を示しません。このホワイトペーパーでは、優れたパフォーマンスを維持しながらモデルの複雑さを軽減するために、簡易自己注意（SSAN）を提案します。プロジェクションレイヤーの代わりにFSMNメモリブロックを使用して、トランスフォーマーベースのエンドツーエンド音声認識用のクエリとキーベクトルを形成するレイヤー。トランスフォーマーモデルは、最先端の音声認識に導入されています。長期的な依存関係をモデル化する際の優位性により、さまざまなタスクのパフォーマンス。 
[ABSTRACT]変圧器モデルは、aishellで20％以上の実際の削減を達成できます-1つのタスク
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Domain Adaptation of Language Models for Reading
  Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_32.html">
      Unsupervised Domain Adaptation of Language Models for Reading
  Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2つ目は、LMとRCのマルチタスク学習アプローチを使用する提案モデルです。UDARC問題を解決するために、2つのドメイン適応モデルを提供します。読解（RC）は、質問応答の機能を学習するタスクですテキストソース付き。 
[ABSTRACT]これは、アウトドメインの言語モデリング（lm）機能が不足しているためです。提案されたモデルは、lmとrcのマルチタスク学習アプローチを使用しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Gradient-Based Adversarial Training on Transformer Networks for
  Detecting Check-Worthy Factual Claims -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_33.html">
      Gradient-Based Adversarial Training on Transformer Networks for
  Detecting Check-Worthy Factual Claims
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      チェックに値するクレームを検出するタスクに関して、トランスニューラルネットワークモデルでの敵対トレーニングの有効性に関する研究を提示します。その過程で、トランスフォーマモデルに敵対トレーニングを適用する方法を提案します。多くの同様のテキスト分類タスクに一般化できます。ClaimBusterデータセットとCLEF2019データセットでは、それぞれ現在の最新モデルと比較して4.70ポイントのF1スコアの改善が得られます。 
[ABSTRACT]最初の敵対的-正規化された、トランスフォーマーベースのクレームポイントモデルで、複数のベンチマークで最先端の技術を実現します。類似したテキスト分類タスクで解釈される可能性がある、敵対的トレーニングをトランスフォーマーモデルに適用する方法を提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br>2020-02-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and
  Perspective -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/cs.CL/paper_34.html">
      Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and
  Perspective
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ニューラルシンボリックコンピューティングによって示唆されているように、AIシステムの説明可能性、解釈可能性、および信頼性を向上させる必要性は、原則として原理的な方法論を要求します。いくつかのドメインでのGNNの適用、および神経シンボリックコンピューティングの現在の開発との関係。 
[要旨]ニューラルのモデルとしてのgnnsの使用を確認します-シンボリックコンピューティング。gnnsは科学的ネットワークやソーシャルネットワークで広く使用されています。他の領域でのgnnsの広範囲な使用
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-29">
        <br>2020-02-29
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Coswara -- A Database of Breathing, Cough, and Voice Sounds for COVID-19
  Diagnosis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/eess.AS/paper_0.html">
      Coswara -- A Database of Breathing, Cough, and Voice Sounds for COVID-19
  Diagnosis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これに向けて、この論文では、Coswaraと呼ばれる呼吸音、つまり咳、呼吸、声のデータベースを作成（および分析）する際の初期の取り組みについて説明します。Coswaraの分析からの洞察は、呼吸器感染症のポイントオブケア診断のためのテクノロジーソリューション。近い将来、これはCOVID-19の診断に役立ちます。COVID-19の顕著な症状には、咳や呼吸困難があります。 
[要約] covid、呼吸音の現在のゴールドスタンダードの方法は、有用な洞察を提供し、診断ツールの設計を可能にします。サウンドサンプルは、Webサイトアプリケーションを使用して世界中のクラウドソーシングで収集されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Conversational End-to-End TTS for Voice Agent -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/eess.AS/paper_1.html">
      Conversational End-to-End TTS for Voice Agent
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、会話内の現在の発話とそのコンテキストに関する情報を強化するために、補助エンコーダーと会話型コンテキストエンコーダーを備えた会話型コンテキスト対応のエンドツーエンドTTSアプローチを提案します。さらに、モデルには、フィラーや繰り返される単語などのいくつかの自発的な動作を表現する機能があり、会話型の発話スタイルがより現実的になります。この研究は、シーケンスからシーケンスへのモデリングフレームワークで音声エージェントの会話型TTSを構築することを目的としています。 
[要約]ヨーク大学の研究者は、音声エージェント用に適切に設計された会話スピーチコーパスを構築しています。提案された方法は、会話コンテキストに応じてより自然な韻律を生成します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Binaural LCMV Beamforming with Partial Noise Estimation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/eess.AS/paper_2.html">
      Binaural LCMV Beamforming with Partial Noise Estimation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      第2に、部分ノイズ推定を使用するBMVDR（BMVDR-N）は、BMVDRの出力信号とノイズのある参照マイク信号を混合し、背景ノイズのバイノーラルキューを制御できるようにします。記録された信号と実験結果を使用した実験結果知覚リスニングテストは、BLCMV-Nが干渉源（BLCMVなど）のバイノーラルキューを保持できる一方で、ノイズ低減性能とバックグラウンドノイズ（BMVDR-Nなど）のバイノーラルキュー保存とのトレードオフを可能にすることを示しています。 ）。したがって、いくつかの拡張機能が提案されています。 
[要約]バイノーラル線形制約付き最小変動（blcmv）ビームフォーマーは、ニューヨークベースのジェネレーターの目的を制御できます。ただし、干渉するキューの低減を制御できず、隣接するソースのバイノーラルキューを歪め、バックグラウンドノイズ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-10">
        <br>2019-05-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Pitchtron: Towards audiobook generation from ordinary people's voices -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/eess.AS/paper_3.html">
      Pitchtron: Towards audiobook generation from ordinary people's voices
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      GSTのAXYスコアは、ハードピッチトロンとソフトピッチトロンではそれぞれ2.01と1.14です。ハードピッチトロンはピッチをデコーダーへの入力として使用し、ソフトピッチトロンはピッチを韻律エンコーダへの入力として使用します。この問題に対処するために、2つのモデルを提案します。ハードとソフトのピッチトロン、そして私たちが開発したツールキットとコーパスをリリースします。 
[ABSTRACT]この問題に対処するために、ハードとソフトの2つのモデルを提案します。pitchlit.pitchtronは、開発したツールキットとコーパスを使用します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Inaudible Adversarial Perturbations for Targeted Attack in Speaker
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/eess.AS/paper_4.html">
      Inaudible Adversarial Perturbations for Targeted Attack in Speaker
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、摂動を測定するために一般的なl_pノルムを使用する代わりに、元のオーディオのマスキングしきい値の下で摂動を抑制します。この研究では、この弱点を利用して、x-ベクトルベースのスピーカー認識に対する標的型攻撃を実行することを目的としています。さらに、提案されたアプローチを音楽などの完全に無関係な波形に適用すると、効果的なスピーカーアタックも実現します。 
[要約]私たちは、周波数マスキングの心理音響学的原理に基づいて、話者認識システムに聞こえない敵対的摂動を生成することを提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Text Matters but Speech Influences: A Computational Analysis of
  Syntactic Ambiguity Resolution -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/eess.AS/paper_5.html">
      Text Matters but Speech Influences: A Computational Analysis of
  Syntactic Ambiguity Resolution
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらなる分析により、計算モデルが聴覚プロセスと言語プロセスの内部関係を反映していることを示しています。構文的に曖昧な発話の韓国語台本に記録された音声コーパスを利用して、共注意フレームワーク、つまりマルチホップ注意とクロス注意、明確化された発話意図で非常に優れたパフォーマンスを示します。同時に、音声言語理解（SLU）システムにとっても最も難しい問題の1つです。 
[ABSTRACT]韓国語のコミュニケーションは話し言葉の重要な問題です。話し言葉の問題を克服することが重要です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-21">
        <br>2019-10-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Cross-lingual Multispeaker Text-to-Speech under Limited-Data Scenario -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/eess.AS/paper_6.html">
      Cross-lingual Multispeaker Text-to-Speech under Limited-Data Scenario
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      バイリンガルデータセットを使用すると、モデルは、話す言語に関するすべての話者に対して忠実度の高いスピーチを生成できるだけでなく、母国語以外の言語に関する単一言語の話者に対して、アクセントがありながら流暢でわかりやすいスピーチを生成できます。たとえば、北京語スピーカーは英語を流暢に話すことができます。{https://caizexin.github.io/mlms-syn-samples/index.html}。 
[ABSTRACT] 2つの言語は入力の同じ音素表現を共有しますが、言語属性と話者IDは、話者の埋め込みによって個別に制御されます。システムは、非ネイティブ言語に関する単一言語話者に対して、アクセントがありながら流暢でわかりやすい音声を生成できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Formant Tracking Using Dilated Convolutional Networks Through Dense
  Connection with Gating Mechanism -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/eess.AS/paper_7.html">
      Formant Tracking Using Dilated Convolutional Networks Through Dense
  Connection with Gating Mechanism
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      第2に、各非表示レイヤーは、密な接続を通じて以前のすべてのレイヤーからの出力情報を再利用しました。従来の実装に加えて、アーキテクチャを3つの側面から変更しました。第3に、勾配消失の問題を緩和するためにゲーティングメカニズムも採用しました。重要でない情報を選択的に忘れることによって。 
[要約]このペーパーでは、フォルマント追跡のための時間的対比ネットワーク（tcn）の使用を検討しました。最初に、拡張された畳み込みの「因果的」モードをオフにして、拡張された畳み込みが将来の音声フレームを見るようにしました。重要でない情報を密かに忘れているシステムに収束することができました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Leveraging Text Data Using Hybrid Transformer-LSTM Based End-to-End ASR
  in Transfer Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/eess.AS/paper_8.html">
      Leveraging Text Data Using Hybrid Transformer-LSTM Based End-to-End ASR
  in Transfer Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は、制限されたラベル付きデータを使用して両方をトレーニングすると、提案されたアーキテクチャが以前のLSTMベースのアーキテクチャ
[1]よりも24.2％相対ワードエラー率（WER）だけ優れていることを示しています。 LSTMとTransformerの両方のアーキテクチャに対応します。これから、リソースが豊富な別の言語からの転移学習により、さらに25.4％の相対的なWER削減が得られます。 
[要約]マレーシアのコーパスで1.5％のテキストを含む実験を行います。これは、合計13％と比較されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Training Keyword Spotting Models on Non-IID Data with Federated Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/eess.AS/paper_9.html">
      Training Keyword Spotting Models on Non-IID Data with Federated Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      リソースの制約を克服するために、メモリを集中的に使用するMTRデータ拡張をSpecAugmentに置き換えます。これにより、偽の拒否率が56％削減されます。本番品質のキーワードスポッティングモデルは、統合学習を使用してデバイス上でトレーニングでき、同等の偽を実現できることを示しています集中的に訓練されたモデルに対する受諾率と偽棄却率。最後に、例にラベルを付ける（デバイス上のデータの可視性がゼロの場合）ために、教師と生徒の訓練を調査します。 
[ABSTRACT]オンデバイスデータのフィッティングに関連するアルゴリズムの制約を克服するために、アルゴリズムとハイパーパラメーター構成の徹底的な調査を実施します。例をテストするために、教師と生徒のトレーニングを調査します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ASAPP-ASR: Multistream CNN and Self-Attentive SRU for SOTA Speech
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/eess.AS/paper_10.html">
      ASAPP-ASR: Multistream CNN and Self-Attentive SRU for SOTA Speech
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SpecAugmentデータ拡張メソッドでトレーニングすると、テストクリーンで4％、テストその他で14％の相対ワードエラー率（WER）の改善を実現します。ハイブリッドASRフレームワークでは、マルチストリームCNN音響モデルが音声の入力を処理します。複数の並列パイプライン内のフレーム。各ストリームには多様性のための独自の拡張率があります。24層の自己注意型SRU言語モデルを使用してN-bestリスコアリングによりパフォーマンスをさらに向上させ、テストクリーンで1.75％、4.46でWERを達成します。テストその他の％。 
[ABSTRACT]ハイブリッドasrフレームワークでは、マルチストリームcnn音響モデルが複数の並列パイプラインで音声フレームの入力を処理します。n-24のアートモデルを使用した最高のスコアリングにより、パフォーマンスをさらに向上させます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multistream CNN for Robust Acoustic Modeling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/eess.AS/paper_11.html">
      Multistream CNN for Robust Acoustic Modeling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      マルチストリームCNNは、データ拡張メソッドでトレーニングされ、LibriSpeechコーパスのテストその他のセットのWERを12％（相対）改善します。埋め込み処理における時間解像度の多様性について、TDNN-Fの拡張を検討します。 1D-CNN ..各音声ストリームはより狭いTDNN-Fレイヤーをスタックします。そのTDNN-Fレイヤーは、入力音声フレームを並行して処理するときに、カーネルに固有のストリーム固有の拡張率があります。 
[要約]提案されたアーキテクチャは、複数のストリームで異なる空間解像度に対応し、音響モデリングの堅牢性を実現します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: End-to-End Far-Field Speech Recognition with Unified Dereverberation and
  Beamforming -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/eess.AS/paper_12.html">
      End-to-End Far-Field Speech Recognition with Unified Dereverberation and
  Beamforming
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      まず、マルチソースマスクベースの重み付き予測エラー（WPE）モジュールが残響除去用のフロントエンドに組み込まれています。上記の2つのアーキテクチャは、音声認識基準を使用するだけで、完全にエンドツーエンドで最適化されています。マルチソース入力を処理できる元のWPDから新しい定式化を導出し、固有値分解を行列の逆演算に置き換えて、逆伝播アルゴリズムをより安定させます。 
[要約] 2つの新しいフロントエンドアーキテクチャが新しい論文で提案されています。完全に最終的に最適化されます。従来の方法で、音声認識基準のみを使用します。2つのアーキテクチャは、認識標準を使用するように最適化されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Simplified Self-Attention for Transformer-based End-to-End Speech
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/eess.AS/paper_13.html">
      Simplified Self-Attention for Transformer-based End-to-End Speech
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      印象的な20％のパラメーター削減により、私たちのモデルは20,000時間の大規模タスクで認識パフォーマンスの損失を示しません。 AISHELL-1タスクのCER削減..私たちは、公共のAISHELL-1で、SSANベースおよび従来のSANベースのトランスフォーマーを評価します。内部の1000時間および20,000時間の大規模なマンダリンタスクです。 
[ABSTRACT]変圧器モデルは、aishellで20％以上の実際の削減を達成できます-1つのタスク
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An approach to Beethoven's 10th Symphony -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/eess.AS/paper_14.html">
      An approach to Beethoven's 10th Symphony
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ニューラルネットワークモデルは、Long Short-Therm Memory（LSTM）ニューラルネットワークに基づいて構築されています。出力の構造は、ネットワークのトレーニングに使用されるシンフォニーに強く依存します。彼の作品、この論文の目的は、シンボリックデータから彼の構成モデルのパターンを抽出する可能性を調査し、彼の最後の交響曲であるテンスを生成することです。 
[ABSTRACT]作曲された音楽は、入力データと結果を比較することによって分析されました。また、それらを取得するために使用されたトレーニングデータに基づいて、生成された出力間の差異を確立しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Understanding the Importance of Heart Sound Segmentation for Heart
  Anomaly Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/eess.AS/paper_15.html">
      Understanding the Importance of Heart Sound Segmentation for Heart
  Anomaly Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この研究では、心音分類の前のステップとして心音セグメンテーションの重要性を明確に検討し、得られた洞察を適用して、異常な心音検出のためのロバストな分類器を提案します。さらに、説明可能な緊急の必要性の認識医療分野の人工知能（AI）モデルでは、モデル解釈技術を使用して分類子によって学習された隠された表現も明らかにします。実験結果は、セグメンテーションが異常な心音分類に重要な役割を果たすことを示しています。 
[要約]最初の段階では、心音をセグメント化して心音を検出します。その後、特徴が抽出されて分類が実行されます。特徴抽出がまだ開かれている前に心音をセグメント化するかどうかの質問
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br>2020-05-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Environmental Sound Classification with Parallel Temporal-spectral
  Attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-22/eess.AS/paper_16.html">
      Environmental Sound Classification with Parallel Temporal-spectral
  Attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、一時的な注意メカニズムがCNNで使用され、特に音声イベントの開始時間とオフセット時間が適用されない弱くラベル付けされたデータについて、オーディオ分類に関連する時間フレームから有用な情報を取得しました。この論文では、 CNNが特徴的なサウンド表現を学習するための新しい並列時間スペクトル注意メカニズム。これは、異なる時間フレームと周波数帯域の重要性をキャプチャすることにより、時間特性とスペクトル特性を強化します。並列ブランチは、時間注意とスペクトル注意を適用できるように構築されています。サウンドイベントの存在なしにセグメントからの干渉を緩和するためにそれぞれ。 
[要旨] cnnのシステムはcnnを使用して、オーディオ分類に関連する時間枠から有用な情報を取得します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-14">
        <br>2019-12-14
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本日更新された論文はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br>
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
