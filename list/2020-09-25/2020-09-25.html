<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-09-25の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: The COUGHVID crowdsourcing dataset: A corpus for the study of
  large-scale cough analysis algorithms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.SD/paper_0.html">
      <font color="black">The COUGHVID crowdsourcing dataset: A corpus for the study of
  large-scale cough analysis algorithms</font>
    </a>
  </h2>
  <font color="black">COUGHVIDデータセットは、幅広い被験者の年齢、性別、地理的位置、COVID-19ステータスを表す20,000を超えるクラウドソースの咳の記録を提供します。次に、経験豊富な呼吸器科医が2,000以上の記録にラベルを付け、咳に存在する医学的異常を診断し、多数の咳音声分類タスクに使用できる、現存する最大の専門家ラベル付き咳データセットの1つです。その結果、COUGHVIDデータセットは、世界で最も緊急な健康危機に対処するためにMLモデルをトレーニングするための豊富な咳記録に貢献します。 
[要約]現在、このようなmlモデルをトレーニングするための咳音の検証済みデータベースはありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Timbre Space Representation of a Subtractive Synthesizer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.SD/paper_1.html">
      <font color="black">Timbre Space Representation of a Subtractive Synthesizer</font>
    </a>
  </h2>
  <font color="black">私たちは、さまざまな波形入力ソースとエンベロープフィルターが、音色変化の主要な手段として機能し、合成された音色の知覚に新しい音響相関を提供するという仮説を立てました。ペアワイズの非類似性評価が、オンラインのブラウザーベースの実験内で収集されました。この研究では、我々は、減算合成音の非類似性評価から幾何学的にスケーリングされた知覚音色空間を生成し、結果の次元を音響記述子のセットと相関させます。 
[ABSTRACT]合成モデルによって生成された15のサウンドのセットをキュレートします。さまざまなソース波形、周波数緩和（fm）、およびエンベロープされたカットオフ周波数を持つローパスフィルターを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Effects of Word-frequency based Pre- and Post- Processings for Audio
  Captioning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.SD/paper_2.html">
      <font color="black">Effects of Word-frequency based Pre- and Post- Processings for Audio
  Captioning</font>
    </a>
  </h2>
  <font color="black">結果は、データの増大と後処理がシステムのスコアを大幅に向上させることを示しています。次に、詳細なモジュールごとのアブレーション研究を実施して、精度を向上させるための主要な処理モジュールをさらに明確にしました。特に、データの増大とビームの混合の検索後処理では、SPIDErをそれぞれ0.8ポイントと1.6ポイント改善します。 
[ABSTRACT]システムは最高の評価スコアを受け取りましたが、パフォーマンスに最も完全に貢献した個々の要素のどれがまだ明確にされていません。次に、詳細なモジュールを実施しました。精度の向上</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Co-VeGAN: Complex-Valued Generative Adversarial Network for Compressive
  Sensing MR Image Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.IV/paper_0.html">
      <font color="black">Co-VeGAN: Complex-Valued Generative Adversarial Network for Compressive
  Sensing MR Image Reconstruction</font>
    </a>
  </h2>
  <font color="black">ほとんどの方法は、複素数値のエンティティからマグニチュードを抽出するか、またはそれらを2つの実数値のチャネルとして連結します。実数値のディープネットワークの基本的な問題に対処するには、さらに、実際に価値のあるディープラーニングベースの方法と比較して、使用するトレーニング可能なパラメーターが大幅に少なくなります。 
[ABSTRACT] cs-mr画像は、最先端のディープラーニングベースの方法を使用して分析できます。ただし、主な欠点は、複雑な値のmriデータを実際の値のエンティティとして扱うことです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-24">
        <br><font color="black">2020-02-24</font>
      </time>
    </span>
</section>
<!-- paper0: Soft Tissue Sarcoma Co-Segmentation in Combined MRI and PET/CT Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.IV/paper_1.html">
      <font color="black">Soft Tissue Sarcoma Co-Segmentation in Combined MRI and PET/CT Data</font>
    </a>
  </h2>
  <font color="black">マルチモーダル医療画像における腫瘍のセグメンテーションは、深層学習ベースの方法に向かう傾向が高まっています。しかし、それらは、腫瘍の特徴が各モダリティによって異なって強調され、腫瘍の描写に影響を与えることを考慮に入れていません。同時に同時セグメンテーションを提案しますメソッドは、モダリティ固有のエンコーダーおよびデコーダーブランチによるマルチモーダル機能学習を可能にし、リソース効率の高い密に接続された畳み込み層の使用を可能にします。 
[要約]マルチモーダル画像データを融合して、単一の画像モダリティの腫瘍成長輪郭を改善する研究。結果は、私たちのマルチモーダル共同セグメンテーションモデルが、ペットまたはmriのみを使用するモデルよりもモダリティ固有の腫瘍セグメンテーションを提供することを示しています（t1およびt2）入力としてスキャン</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-28">
        <br><font color="black">2020-08-28</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Phase Unwrapping via Deep Image Prior for Quantitative Phase
  Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.IV/paper_2.html">
      <font color="black">Robust Phase Unwrapping via Deep Image Prior for Quantitative Phase
  Imaging</font>
    </a>
  </h2>
  <font color="black">フェーズアンラッピングは、より有益な画像を復元する計算プロセスです。深い画像の事前分布の概念に触発されて、トレーニングセットを必要としないディープラーニングベースの方法を提案します。測定の一貫性を確保しながら、位相を正確にアンラップします。 
[ABSTRACT]フェーズはほとんどのイメージングシステムでラップされていますが、結果は行われていません。メソッドにはトレーニングセットは必要ありませんが、トレーニングセットは必要ありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Transfer Learning by Cascaded Network to identify and classify lung
  nodules for cancer detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.IV/paper_3.html">
      <font color="black">Transfer Learning by Cascaded Network to identify and classify lung
  nodules for cancer detection</font>
    </a>
  </h2>
  <font color="black">この研究の主な貢献は、セグメンテーションネットワークを導入することです。ここでは、パブリックデータセットでトレーニングされた最初のステージが、転移学習によってデータセットからの結節を含む画像を認識するのに役立ちます。そして、結節のセグメンテーションが向上します。結節を良性と悪性に分類する第2段階。提案されたアーキテクチャは、95.67 \％の曲線下面積値で従来の方法よりも優れています。 
[ABSTRACT] studyは、tu tu tumoursを正確にセグメント化および分類できるカスケードアーキテクチャを開発しました。これは、初期段階で腫瘍を識別するために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Residual Feature Distillation Network for Lightweight Image
  Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.IV/paper_4.html">
      <font color="black">Residual Feature Distillation Network for Lightweight Image
  Super-Resolution</font>
    </a>
  </h2>
  <font color="black">ただし、この操作が効率的なSISRモデルの設計にどのように役立つかは十分に明確ではありません。単一画像超解像（SISR）の最近の進歩により、畳み込みニューラルネットワーク（CNN）の能力が調査され、より優れたパフォーマンスが達成されました。論文では、より軽量でフレキシブルでありながら、機能的にチャネル分割操作と同等である機能蒸留接続（FDC）を提案します。 
[ABSTRACT] cnnのデータ抽出ネットワークによって新しい方法が提案されています。チャネル分割操作を使用して抽出された特徴を抽出します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Cranial Implant Prediction using Low-Resolution 3D Shape Completion and
  High-Resolution 2D Refinement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.IV/paper_5.html">
      <font color="black">Cranial Implant Prediction using Low-Resolution 3D Shape Completion and
  High-Resolution 2D Refinement</font>
    </a>
  </h2>
  <font color="black">最初のサブネットワークは、ダウンサンプリングされた欠陥のある頭蓋骨の形状を完成するように設計されています。2番目のサブネットワークは、再構築された形状をスライスごとにアップサンプリングします。さらに、3D頭蓋骨の形状全体を元の画像解像度でロードすることは、一般に利用可能なGPUでは実行できません。 
[要約]私たちの提案するソリューションは、チャレンジテストケースの高解像度3Dインプラントをダイス-スコアとハウスドルフ距離で正確に予測します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: An Attention-Guided Deep Regression Model for Landmark Detection in
  Cephalograms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.IV/paper_6.html">
      <font color="black">An Attention-Guided Deep Regression Model for Landmark Detection in
  Cephalograms</font>
    </a>
  </h2>
  <font color="black">このフレームワークでは、グローバルステージヒートマップに注意メカニズムを組み込んで、ローカルステージの推論を導き、ローカルヒートマップパッチを高解像度で後退させます。さらに、拡張探査戦略は、推論しながら堅牢性を向上させ、 -モデルの複雑さを増大させます。計算量を減らして手動で調整することで、私たちのフレームワークは最先端の結果を実現します。 
[要約]この論文では、頭部X線画像の解剖学的ランドマークを自動的に検出するためのディープラーニングベースのフレームワークを提案します。提案されたフレームワークは、2ステージのu-netに基づいており、マルチチャネルヒートマップを後退させます。ランドマーク検出。しかし、プロジェクトは推論しながら堅牢性を証明し、モデルの複雑さを増すことなく検索範囲を拡大しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-17">
        <br><font color="black">2019-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: Complex Convolutional Neural Networks for Ultrasound Image
  Reconstruction from In-Phase/Quadrature Signal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.IV/paper_7.html">
      <font color="black">Complex Convolutional Neural Networks for Ultrasound Image
  Reconstruction from In-Phase/Quadrature Signal</font>
    </a>
  </h2>
  <font color="black">私たちは、CID-NetがRFトレーニング済みCNNから取得したものと同じ画質をもたらすという実験的証拠を提供しました。つまり、3つのI / Q画像のみを使用することにより、CID-Netは、31のRF画像をコヒーレントに合成することで得られる画像と競合する高品質の画像を生成しました。最近、ID-Netと呼ばれるCNNアーキテクチャについて説明しました。 RF発散波（DW）超音波画像の再構成。この作業で、このネットワークの複雑な同等物、つまりI / Qデータで動作するDWネットワーク（CID-Net）の複雑な開始を導出しました。 
[ABSTRACT]この作業では、i / q信号から超音波画像を再構成するために複雑な畳み込みニューラルネットワーク（ccnns）を利用しました。これらは、d / wネットワーク（cid -q）の複雑な開始と呼ばれ、i / qデータで動作します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Perceptual Video Quality Prediction Emphasizing Chroma Distortions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.IV/paper_8.html">
      <font color="black">Perceptual Video Quality Prediction Emphasizing Chroma Distortions</font>
    </a>
  </h2>
  <font color="black">この問題の調査に向けて、発生する彩度の歪みの種類、輝度の歪みとの関係、およびそれらが知覚される品質にどのように影響するかを理解することが重要です。人間の観察者が見るデジタルビデオの品質の測定は、一般的な方法になっていますアダプティブビデオストリーミング、品質監視、その他のデジタルTVアプリケーションなど、多数のマルチメディアアプリケーションで使用されます。具体的には、新しい主観的なデータセットは、さまざまな量の彩度と混ざったさまざまなレベルの輝度量子化によって引き起こされる歪みによって影響を受けた合計$ 210 $ビデオで構成されています。量子化。 
[ABSTRACT]ビデオの知覚品質の測定は、圧縮によるルマとクロマの両方の歪みから生じました。新しい実験は、ビデオの知覚品質を測定するために開発されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-23">
        <br><font color="black">2020-09-23</font>
      </time>
    </span>
</section>
<!-- paper0: YOLACT++: Better Real-time Instance Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.IV/paper_9.html">
      <font color="black">YOLACT++: Better Real-time Instance Segmentation</font>
    </a>
  </h2>
  <font color="black">さらに、1つのGPUのみでトレーニングした後、この結果を取得します。また、わずかなパフォーマンスペナルティしかない標準NMSの12 ms高速ドロップインのFast NMSも提案します。これは、インスタンスのセグメント化を2つの並列に分割することで実現します。サブタスク：（1）プロトタイプマスクのセットを生成し、（2）インスタンスごとのマスク係数を予測します。 
[ABSTRACT]独自の例を「非たたみ込み」の方法で提示します。これらの例は、モデルをマスクエントリと組み合わせることによって生成されます。次に、変形可能なたたみ込みを使用して生成されます。これらには、高速マスク再スコアリング34が含まれます。 33.5 fpsのms coco上の1つのマップ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-03">
        <br><font color="black">2019-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Attention with Multiple Sources Knowledges for COVID-19 from CT Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.IV/paper_10.html">
      <font color="black">Attention with Multiple Sources Knowledges for COVID-19 from CT Images</font>
    </a>
  </h2>
  <font color="black">この手順は、システムをノイズに対してより堅牢にするだけでなく、局所的な病変領域に焦点を当てたネットワークを導きます。特に、学習したネットワークから抽出された感染領域とヒートマップは、学習プロセス中に注意メカニズムを介してグローバルイメージと統合されます。さらに、私たちの学習したネットワークガイダンスは、グレイボックスモデルの入力と出力の間の接続を理解できるため、医師に説明可能な機能を提供します。 
[要約] covid-19の早期診断は時期尚早である可能性があります。これらのアプローチは主に、新しいアーキテクチャの導入、転移学習技術、または大規模データの構築に重点を置いています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-23">
        <br><font color="black">2020-09-23</font>
      </time>
    </span>
</section>
<!-- paper0: Packet Compressed Sensing Imaging (PCSI): Robust Image Transmission over
  Noisy Channels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.IV/paper_11.html">
      <font color="black">Packet Compressed Sensing Imaging (PCSI): Robust Image Transmission over
  Noisy Channels</font>
    </a>
  </h2>
  <font color="black">コンピュータ上で画像の送信と受信を同時に行うことができ、複数のステーションから複数の画像を同時に受信できるため、「画像ネット」を作成できます。 1200ボーAFSKで送信すると、満足のいくSSTV解像度（320x240ピクセル）の画像を1〜2分で受信できます。これは、アナログSSTVの送信時間と同等です。目標は、計算上簡単な堅牢な画像送信方法を開発することです。送信（たとえば、低電力8ビットマイクロコントローラーと互換性がある）であり、パケットが失われる可能性が高い弱い信号環境に適しています。 
[ABSTRACT] goalxxは、堅牢な画像送信方法を開発することです。送信は簡単で、PCSIおよびwi-fiで利用できます。高度な高度な方法を使用できる場合があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Brain Multiplex Prediction From a Single Network for
  High-Order Connectional Gender-Specific Brain Mapping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.IV/paper_12.html">
      <font color="black">Adversarial Brain Multiplex Prediction From a Single Network for
  High-Order Connectional Gender-Specific Brain Mapping</font>
    </a>
  </h2>
  <font color="black">このようなアーキテクチャは、潜在的なソースネットワークの表現と、ソースからターゲットマルチプレックスレイヤー内への深い非線形マッピングを同時に学習します。ただし、これにより、機能ネットワークなどの単一の脳ネットワークを持つデータセットへの適用が妨げられます。 、ジオメトリックGAN（G-GAN）の初期のフィールドを利用して、（i）スキップ接続を備えたU-Netアーキテクチャを模倣したジオメトリックソースからターゲットネットワークへのトランスレータ、および（ii）条件付き弁別器を含むディープマルチプレックス予測アーキテクチャを設計します。これは、マルチプレックスソースイントラレイヤーに条件を付けることにより、予測されたターゲットイントラレイヤーを分類します。 
[要約]調査により、マルチプレックス接続は性別分類の精度を大幅に向上させることがわかりました。これらにはマルチプレックス接続が含まれ、低次と高次の両方の性別-特定のマルチプレックス接続が識別されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic identification of fossils and abiotic grains during carbonate
  microfacies analysis using deep convolutional neural networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.IV/paper_13.html">
      <font color="black">Automatic identification of fossils and abiotic grains during carbonate
  microfacies analysis using deep convolutional neural networks</font>
    </a>
  </h2>
  <font color="black">したがって、そのアプリケーションは、ルーチンの識別を行う人間の専門家による手間のかかる手間のかかる作業の多くを排除することができます。高性能のワークステーションを使用して、コンピュータービジョンで非常に効率的であることが証明されている4つの古典的なディープたたみ込みニューラルネットワーク（DCNN）を実装しました。過去数年にわたって。しかし、機械分類器はこの課題に対処するのに役立ちます。 
[要約]ペトログラファーは、化石と非生物の穀物グループを識別できます。機械分類器は、ドロマイトや黄鉄鉱などの鉱物に困難を示しました。このツールは、人間の分類器に匹敵する再現性とバイアス回避を備えた高精度を示しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Unpaired Image Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.IV/paper_14.html">
      <font color="black">Unpaired Image Denoising</font>
    </a>
  </h2>
  <font color="black">次に、クリーンなターゲットを必要とせずに、ノイズ除去ネットワークをトレーニングするためにそれを使用します。ディープニューラルネットワークがノイズの多い画像からのみノイズ除去することを学習するNoise2Voidなどの方法が登場したのはごく最近です。処理は主に教師あり学習に頼ります。 
[要約]写真のノイズ除去の方法の大半はこのルールの例外ではありませんが、実際にはノイズの多い画像に直接対応しないクリーンな画像が利用可能です。これらのクリーンな画像には完全に監視されていない有用な情報が含まれているため、改善の余地がありますメソッドは悪用しない</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: ECOVNet: An Ensemble of Deep Convolutional Neural Networks Based on
  EfficientNet to Detect COVID-19 From Chest X-rays -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.IV/paper_15.html">
      <font color="black">ECOVNet: An Ensemble of Deep Convolutional Neural Networks Based on
  EfficientNet to Detect COVID-19 From Chest X-rays</font>
    </a>
  </h2>
  <font color="black">単一のトレーニング中に作成されるモデルスナップショットの予測は、2つのアンサンブル戦略、つまりハードアンサンブルとソフトアンサンブルを通じて組み合わされ、胸部X線を分類する関連タスクの分類パフォーマンスと一般化を改善します。大きな胸部X線データセットを使用してCOVID-19を検出するための、ECOVNetというEfficientNetに基づく深い畳み込みニューラルネットワーク（CNN）の集合。最初に、オープンアクセスの大きな胸部X線コレクションが拡張され、次に、EfficientNet用のImageNet事前トレーニング済みウェイトが、トレーニング済みのカスタマイズされた微調整トップレイヤーとともに転送され、モデルスナップショットのアンサンブルが続き、COVID-19、正常、および肺炎に対応する胸部X線を分類します。 
[要約]モデルスナップショットのアンサンブルは、胸部X線をcovid-19、正常、および肺炎に基づいて分類するために作成されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: A Comprehensive Analysis of Deep Regression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_0.html">
      <font color="black">A Comprehensive Analysis of Deep Regression</font>
    </a>
  </h2>
  <font color="black">多数の深いモデルがあり、ネットワークアーキテクチャまたはデータの前処理における小さな変更と、最適化手順の確率論的な性質により、特に異なる結果が生成され、他のものを大幅に上回るメソッドをふるい分けることが非常に困難になります。 .. 4つのビジョン問題で実験を行い、パフォーマンスの中央値の信頼区間と、結果の統計的有意性（ある場合）を報告します。線形回帰の最上層を持つ畳み込みニューラルネットワーク。 
[ABSTRACT]これは、deeppar手法の最初の包括的な分析です。4つの実験により、システムは一意ではないことが示されています。ただし、ネットワークアーキテクチャの変更により、さまざまなデータの前処理手順の変動が変動します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-03-22">
        <br><font color="black">2018-03-22</font>
      </time>
    </span>
</section>
<!-- paper0: Interpreting and Boosting Dropout from a Game-Theoretic View -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_1.html">
      <font color="black">Interpreting and Boosting Dropout from a Game-Theoretic View</font>
    </a>
  </h2>
  <font color="black">したがって、ドロップアウトの有用性は相互作用を減らして過剰適合の重要性を軽減すると見なすことができます。実験結果は、相互作用の損失がドロップアウトの有用性を効果的に改善し、DNNのパフォーマンスを向上できることを示しています。さらに、このような相互作用は、ディープラーニングにおける過剰適合問題と強く関連していた。 
[ABSTRACT]ドロップアウトはドロップアウト間の相互作用の強さを抑制できます。これらの相互作用はディープラーニングの過剰適合問題に強く関連していました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Unifying data for fine-grained visual species classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_2.html">
      <font color="black">Unifying data for fine-grained visual species classification</font>
    </a>
  </h2>
  <font color="black">ここでは、さまざまな保護パートナーによるWildlife Insightsプラットフォームのデータ統合の取り組みと、それに伴う課題について概説します。次に、465の細粒種にわたって2.9Mの画像でトレーニングされた、初期の深い畳み込みニューラルネットワークモデルを提示します。人間の専門家が画像内の種を手動で分類する負荷を軽減します。コンピュータビジョンの進歩により、関心のある画像を自動的に識別して画像内の種にラベルを付けるために構築されたカスタムAIモデルで効果的なソリューションが提供されます。 
[ABSTRACT] in-enableセンサーの普及により、過去10年間で前例のないデータ量が収集されています。コンピュータービジョンの進歩により、関心のある画像を識別し、その中の種にラベルを付けるために構築されたカスタムAIモデルで効果的なソリューションを提供できるようになります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Co-VeGAN: Complex-Valued Generative Adversarial Network for Compressive
  Sensing MR Image Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_3.html">
      <font color="black">Co-VeGAN: Complex-Valued Generative Adversarial Network for Compressive
  Sensing MR Image Reconstruction</font>
    </a>
  </h2>
  <font color="black">つまり、実際に価値のあるディープネットワークの根本的な問題に対処するためです。複雑な値のデータを処理できないことから、複雑な値の生成的敵対的ネットワーク（Co-VeGAN）に基づく新しいフレームワークを提案します。さらに、実際の深い学習に基づく方法。 
[ABSTRACT] cs-mr画像は、最先端のディープラーニングベースの方法を使用して分析できます。ただし、主な欠点は、複雑な値のmriデータを実際の値のエンティティとして扱うことです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-24">
        <br><font color="black">2020-02-24</font>
      </time>
    </span>
</section>
<!-- paper0: Attribute Propagation Network for Graph Zero-shot Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_4.html">
      <font color="black">Attribute Propagation Network for Graph Zero-shot Learning</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、伝播メカニズムをトレーニングしてZSLの属性空間を最適化し、クラスのグラフ上の隣接クラスと関連クラスに基づいて各クラスのセマンティック属性を改善することを目指しています。ゼロショット学習（ZSL）の目標トレーニング中に見られなかったクラスのサンプルを分類するモデルをトレーニングすることです。伝播された属性が、さまざまなZSL設定でパフォーマンスが大幅に改善されたゼロショットクラスの分類子を生成できることを示します。 
[ABSTRACT] 2つのゼロショット学習設定と5つのベンチマークデータセットを使用したテストでは、伝播メカニズムとともにエンドツーエンドでグラフを生成するメカニズムを学習できます。伝播された属性がトレーニングクラスを生成できることを示します異なるzsl設定でパフォーマンスが大幅に向上</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Soft Tissue Sarcoma Co-Segmentation in Combined MRI and PET/CT Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_5.html">
      <font color="black">Soft Tissue Sarcoma Co-Segmentation in Combined MRI and PET/CT Data</font>
    </a>
  </h2>
  <font color="black">このギャップを埋めるために、マルチモーダル画像データを利用して各モダリティの腫瘍描写を改善するモダリティ固有の肉腫セグメンテーションモデルを開発します。ただし、腫瘍描写に影響を与える各モダリティによって腫瘍特性が異なるように強調されることは考慮されていません。 ..マルチモーダル医療画像における腫瘍のセグメンテーションは、深層学習ベースの方法に向かう傾向が高まっています。 
[要約]マルチモーダル画像データを融合して、単一の画像モダリティの腫瘍成長輪郭を改善する研究。結果は、私たちのマルチモーダル共同セグメンテーションモデルが、ペットまたはmriのみを使用するモデルよりもモダリティ固有の腫瘍セグメンテーションを提供することを示しています（t1およびt2）入力としてスキャン</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-28">
        <br><font color="black">2020-08-28</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Object Localization Using 2D Estimates for Computer Vision
  Applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_6.html">
      <font color="black">3D Object Localization Using 2D Estimates for Computer Vision
  Applications</font>
    </a>
  </h2>
  <font color="black">提案された方法は、MATLABに実装され、ポーズ推定とカメラキャリブレーションの両方で検証実験が実行されます。2D画像を使用して3Dポーズを推定する変換戦略が提示されます。ポーズ推定とカメラキャリブレーションに基づくオブジェクト位置確認の手法提示されます。 
[ABSTRACT]シンプルシンプルシンプルモデルはシンプルシンプル、シンプルシンプルモデルモデルです。シンプルシンプルマップはシンプルでシンプルシンプルからシンプルモデルです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Reconstruction of Novel Object Shapes from Single Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_7.html">
      <font color="black">3D Reconstruction of Novel Object Shapes from Single Images</font>
    </a>
  </h2>
  <font color="black">SDFNetは、既存のベースラインメソッドであるGenReおよびOccNetと比較して、見えている形状と見えていない形状で最先端のパフォーマンスを提供することを示しています。このような見えないオブジェクトのカテゴリへの一般化は、アーキテクチャ設計とトレーニングアプローチの機能です。単一画像3D形状再構成は、ディープモデルがトレーニングセットの一部ではなかった形状に一般化できるようにすることです。 
[ABSTRACT]この記事でリリースされたコードベースは、単一の画像形状再構成の方法の一貫した評価と比較を可能にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-14">
        <br><font color="black">2020-06-14</font>
      </time>
    </span>
</section>
<!-- paper0: A Gradient Flow Framework For Analyzing Network Pruning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_8.html">
      <font color="black">A Gradient Flow Framework For Analyzing Network Pruning</font>
    </a>
  </h2>
  <font color="black">最近のネットワーク剪定方法は、トレーニングの早い段階で剪定モデルに焦点を当てています。このフレームワークを使用して、剪定メジャーとモデルパラメーターの進化との関係を決定し、トレーニングの早い段階で剪定モデルに関連するいくつかの所見を確立します。ベースの剪定は、損失の減少に最も貢献しないパラメーターを削除し、結果として、マグニチュードに依存しない方法よりも速く収束するモデルになります。 （ii）損失保存ベースのプルーニングは、1次モデルの進化のダイナミクスを保持し、最小限のトレーニングを受けたモデルのプルーニングに十分に動機付けられています。 （iii）勾配ノルムベースの剪定は2次モデルの進化のダイナミクスに影響し、剪定による勾配ノルムの増加はパフォーマンスの低いモデルを生成する可能性があります。トレーニングで早期に使用する正当性がないにもかかわらず、そのような測定を使用して剪定されたモデルは驚くべき結果になります最小の精度損失。 
[要約]患者を取り除くことの影響を特定するために使用される新しい方法。これらは「剪定」モデルの欠如に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: BWCFace: Open-set Face Recognition using Body-worn Camera -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_9.html">
      <font color="black">BWCFace: Open-set Face Recognition using Body-worn Camera</font>
    </a>
  </h2>
  <font color="black">この目的のために、この作業の貢献は2つあります。（1）室内および昼光条件下で身体に装着したカメラを使用してキャプチャされた、132の被験者の合計178Kの顔の画像からなるBWCFaceと呼ばれるデータセットのコレクション、および（2）収集されたデータセットで、顔を識別するための5つの異なる損失関数と組み合わされた最新の深層学習ベースのたたみ込みニューラルネットワーク（CNN）アーキテクチャのオープンセット評価。ただし、パフォーマンスは最大99.00％ランクまで向上しました。事前トレーニング済みのCNNモデルがBWCFaceデータセットのIDのサブセットで微調整されている場合の精度。収集されたBWCFaceデータセットと事前トレーニング済み/微調整済みアルゴリズムは、この分野でのさらなる研究開発を促進するために公開されています。 
[要約]この研究の目的は、身に着けているカメラ（bwc）を使用して顔認識のギャップを埋めることです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Residual Feature Distillation Network for Lightweight Image
  Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_10.html">
      <font color="black">Residual Feature Distillation Network for Lightweight Image
  Super-Resolution</font>
    </a>
  </h2>
  <font color="black">FDCのおかげで、情報マルチ蒸留ネットワーク（IMDN）を再考し、残差機能蒸留ネットワーク（RFDN）と呼ばれる軽量で正確なSISRモデルを提案できます。しかし、この操作が効率的な設計にどのように役立つかは十分に明確ではありません。 SISRモデル..このホワイトペーパーでは、チャネル分割操作と機能的に同等でありながら、より軽量で柔軟な機能蒸留接続（FDC）を提案します。 
[ABSTRACT] cnnのデータ抽出ネットワークによって新しい方法が提案されています。チャネル分割操作を使用して抽出された特徴を抽出します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: AAA: Adaptive Aggregation of Arbitrary Online Trackers with Theoretical
  Performance Guarantee -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_11.html">
      <font color="black">AAA: Adaptive Aggregation of Arbitrary Online Trackers with Theoretical
  Performance Guarantee</font>
    </a>
  </h2>
  <font color="black">コードはhttps://github.com/songheony/AAA-journal ..で入手できます。このホワイトペーパーでは、任意の複数のオンライントラッカーを適応的に集約するオンライントラッキング方法を提案します。追跡中の最高のエキスパートは不明ですが、任意の画像シーケンスに最適なトラッカーです。 
[要約]新しい調査が追跡のためのオンライン追跡方法を提案します。提案された方法は、ベンチマークデータセットと集約されたトラッカーの大きな変動に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-19">
        <br><font color="black">2020-09-19</font>
      </time>
    </span>
</section>
<!-- paper0: Cranial Implant Prediction using Low-Resolution 3D Shape Completion and
  High-Resolution 2D Refinement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_12.html">
      <font color="black">Cranial Implant Prediction using Low-Resolution 3D Shape Completion and
  High-Resolution 2D Refinement</font>
    </a>
  </h2>
  <font color="black">最初のサブネットワークは、ダウンサンプリングされた欠陥のある頭蓋骨の形状を完成するように設計されています。3Dネットワークと2Dネットワークを階層的損失関数でエンドツーエンドで一緒にトレーニングします。2番目のサブネットワークは、再構築された形状をスライスごとにアップサンプリングします。 
[要約]私たちの提案するソリューションは、チャレンジテストケースの高解像度3Dインプラントをダイス-スコアとハウスドルフ距離で正確に予測します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-View Brain HyperConnectome AutoEncoder For Brain State
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_13.html">
      <font color="black">Multi-View Brain HyperConnectome AutoEncoder For Brain State
  Classification</font>
    </a>
  </h2>
  <font color="black">ジオメトリックディープラーニングフレームワーク内に埋め込まれたハイパーコネクトームを形式化して、特定の主題に合わせて最適化し、それによって個人ベースの学習フレームワークを設計します。次に、マルチコネクトハイパーエンコーダー脳領域（ノード）間の多対多の関係をより適切に捉えるためのハイパーグラフ畳み込み層。第2に、既存のグラフ埋め込み技術は、異種分布のマルチビューグラフデータに簡単に適合させることができません。 
[要約] roisのペア全体の接続性を維持するために新しいマッピングシステムが必要です。既存の埋め込み手法は、マルチビューグラフデータに簡単に適応できます。この方法は、最近傍アルゴリズムに基づいて各脳ビューのハイパーコネクトームを構築するように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: CLASS: Cross-Level Attention and Supervision for Salient Objects
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_14.html">
      <font color="black">CLASS: Cross-Level Attention and Supervision for Salient Objects
  Detection</font>
    </a>
  </h2>
  <font color="black">次に、顕著なオブジェクトの微細構造と境界を適切に復元できます。最初に、低レベル機能と高レベル機能のさまざまな利点を活用するために、新しい非ローカルクロスレベルアテンション（CLA）を提案します。完全な顕著なオブジェクトの区別を強化するために、長距離の機能の依存関係をキャプチャできます。 
[要約]この論文は、正確な非音のための新しいレベルレベルネットワークを提案します。これら2つの問題に対処するために、新しいレベルレベルシステムを提案します。これは、ピクセルレベル、領域レベル、およびオブジェクト-レベル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-23">
        <br><font color="black">2020-09-23</font>
      </time>
    </span>
</section>
<!-- paper0: An Attention-Guided Deep Regression Model for Landmark Detection in
  Cephalograms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_15.html">
      <font color="black">An Attention-Guided Deep Regression Model for Landmark Detection in
  Cephalograms</font>
    </a>
  </h2>
  <font color="black">このフレームワークでは、グローバルステージヒートマップに注意メカニズムを組み込んで、ローカルステージの推論を導き、ローカルヒートマップパッチを高解像度で後退させます。さらに、拡張探査戦略は、推論しながら堅牢性を向上させ、 -モデルの複雑さを増加させる。セファロメトリックトレーシング法は、通常、歯科矯正診断および治療計画で使用されます。 
[要約]この論文では、頭部X線画像の解剖学的ランドマークを自動的に検出するためのディープラーニングベースのフレームワークを提案します。提案されたフレームワークは、2ステージのu-netに基づいており、マルチチャネルヒートマップを後退させます。ランドマーク検出。しかし、プロジェクトは推論しながら堅牢性を証明し、モデルの複雑さを増すことなく検索範囲を拡大しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-17">
        <br><font color="black">2019-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: J$\hat{\text{A}}$A-Net: Joint Facial Action Unit Detection and Face
  Alignment via Adaptive Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_16.html">
      <font color="black">J$\hat{\text{A}}$A-Net: Joint Facial Action Unit Detection and Face
  Alignment via Adaptive Attention</font>
    </a>
  </h2>
  <font color="black">さらに、正確な局所的特徴を抽出するために、各AUの注意マップを適応的に調整する適応注意学習モジュールを提案します。特に、最初にマルチスケールの共有特徴を学習し、顔の位置合わせの高レベルの特徴をAUにフィードします。広範囲の実験は、私たちのフレームワークが（i）挑戦的なBP4D、DISFA、GFTおよびBP4D +ベンチマークで最先端のAU検出方法を大幅に上回っており、（ii）各AUの不規則な領域を適応的にキャプチャできることを示しています。 （iii）顔の位置合わせで競争力のあるパフォーマンスを実現し、（iv）部分的なオクルージョンや非正面のポーズでもうまく機能します。 
[ABSTRACT]ほとんどの既存のau検出機能は、2つのタスクを個別に処理します。これらは、顔の位置合わせを前処理として扱い、ランドマークを使用して各auの固定領域または注意を事前定義します。最後に、組み立てられたローカル機能が顔の位置合わせ機能と統合され、 au検出のグローバル機能</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br><font color="black">2020-03-18</font>
      </time>
    </span>
</section>
<!-- paper0: Knowledge Distillation for Multi-task Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_17.html">
      <font color="black">Knowledge Distillation for Multi-task Learning</font>
    </a>
  </h2>
  <font color="black">マルチタスク学習（MTL）は、複数のタスクを実行する単一のモデルを学習して、すべてのタスクで良好なパフォーマンスを実現し、計算コストを削減します。クロスエントロピー、ユークリッド損失）。これにより、マルチタスク学習の不均衡問題が発生します。タスク固有のネットワークはさまざまな機能をエンコードするので、小さなタスク固有のアダプターを導入して、マルチタスク機能をタスク固有の機能に投影します。 
[ABSTRACT]そのようなモデルを学習するには、難易度、大きさ、特性が異なる一連のタスクの損失を同時に最適化する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-14">
        <br><font color="black">2020-07-14</font>
      </time>
    </span>
</section>
<!-- paper0: FTN: Foreground-Guided Texture-Focused Person Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_18.html">
      <font color="black">FTN: Foreground-Guided Texture-Focused Person Re-Identification</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、Re-IDのフォアグラウンドガイダンステクスチャフォーカスネットワーク（FTN）を提案します。FTNは、無関係な背景の表現を弱め、エンドツーエンドの方法で人物に関連する属性を強調します。 3つの一般的に使用されるデータセットMarket1501、CUHK03およびMSMT17での計算効率の高い広範な実験は、提案された方法が最新の方法に対して有利に機能することを示しています。特に、TF- Dec再構築されたグラウンドトゥルースは、ガウスマスクとCFAによって生成されたアテンションマスクによって重み付けされたFTNの入力にすぎないためです。 
[ABSTRACT] ftnは、reidタスク用のセマンティックエンコーダーとコンパクトなフォアグラウンドアテンションモジュール、および再構築タスク用のテクスチャ関連デコーダー（tf-dec）で構成されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: YOLACT++: Better Real-time Instance Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_19.html">
      <font color="black">YOLACT++: Better Real-time Instance Segmentation</font>
    </a>
  </h2>
  <font color="black">単一のTitan Xpで評価されたMS COCOで競争力のある結果を達成する、リアルタイム（&gt; 30 fps）のインスタンスセグメンテーションの単純な完全たたみ込みモデルを提示します。これは、以前の最先端のアプローチよりも大幅に高速です。 。また、Fast NMSを提案します。これは、パフォーマンスがわずかに低下するだけで、標準のNMSを12 ms高速に置き換えます。インスタンスのセグメンテーションを2つの並列サブタスクに分割することでこれを実現します。（1）プロトタイプマスクのセットの生成と（ 2）インスタンスごとのマスク係数の予測。 
[ABSTRACT]独自の例を「非たたみ込み」の方法で提示します。これらの例は、モデルをマスクエントリと組み合わせることによって生成されます。次に、変形可能なたたみ込みを使用して生成されます。これらには、高速マスク再スコアリング34が含まれます。 33.5 fpsのms coco上の1つのマップ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-03">
        <br><font color="black">2019-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Frame to Single-Frame: Knowledge Distillation for 3D Object
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_20.html">
      <font color="black">Multi-Frame to Single-Frame: Knowledge Distillation for 3D Object
  Detection</font>
    </a>
  </h2>
  <font color="black">自動運転のための3Dオブジェクト検出における一般的なジレンマは、高品質で高密度の点群がトレーニング中にのみ利用可能であり、テストでは利用できないことです。次に、特徴の一貫性の正則化を使用して、モデルの同じものを疎な単一フレームの点群でトレーニングします。両方のモデルから。特に、ポイントクラウドオブジェクト検出用の2段階のトレーニングパイプラインを設計します。 
[ABSTRACT]密集した点群でオブジェクト検出モデルをトレーニングするのはこれが初めてです。トレーニング時にのみ利用可能な追加情報を使用して複数のフレームから生成されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Attention with Multiple Sources Knowledges for COVID-19 from CT Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_21.html">
      <font color="black">Attention with Multiple Sources Knowledges for COVID-19 from CT Images</font>
    </a>
  </h2>
  <font color="black">この手順は、システムをノイズに対してより堅牢にするだけでなく、局所的な病変領域に焦点を当てたネットワークを導きます。特に、学習したネットワークから抽出された感染領域とヒートマップは、学習プロセス中に注意メカニズムを介してグローバルイメージと統合されます。広範な実験は、最近のベースラインと比較して私たちのアプローチの優れたパフォーマンスを示しています。 
[要約] covid-19の早期診断は時期尚早である可能性があります。これらのアプローチは主に、新しいアーキテクチャの導入、転移学習技術、または大規模データの構築に重点を置いています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-23">
        <br><font color="black">2020-09-23</font>
      </time>
    </span>
</section>
<!-- paper0: Cloud Cover Nowcasting with Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_22.html">
      <font color="black">Cloud Cover Nowcasting with Deep Learning</font>
    </a>
  </h2>
  <font color="black">気象ランドスケープでは、従来の気象学が一般に物理モデリングに基づいているデータ外挿などの特定の手法を必要とするため、このフィールドはかなり具体的です。このホワイトペーパーでは、次のようなさまざまなアプリケーション領域がある雲カバーナウキャスティングに焦点を当てます。衛星ショットの最適化と太陽光発電の予測..複数の画像タスクに関する最近のディープラーニングの成功に続き、クラウドカバーのナウキャスティング用にMeteosat衛星画像に深い畳み込みニューラルネットワークを適用しました。 
[ABSTRACT]クラウドカバーのナウキャスティングのために、meteosat衛星画像に深い畳み込みネットワークを適用</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Scale Profiling of Brain Multigraphs by Eigen-based
  Cross-Diffusion and Heat Tracing for Brain State Profiling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_23.html">
      <font color="black">Multi-Scale Profiling of Brain Multigraphs by Eigen-based
  Cross-Diffusion and Heat Tracing for Brain State Profiling</font>
    </a>
  </h2>
  <font color="black">この研究では、スペクトルグラフ理論と拡散モデルのフィールドを相互受粉しながら、マルチグラフ脳の統合、比較、およびプロファイリングのための固有ベースの相互拡散戦略をこれまでに提案します。この研究は、形状を聞くための最初のステップを提示します。併存する神経障害のプロファイリングともつれを解くために活用できる脳マルチグラフの1つであり、それによって精密医療が進歩します。その複雑な複雑さにより、脳障害がどのように脳グラフの単一のビューだけでなく、個々のマルチグラフ表現を変えるかを理解するそして人口規模は、最終的に広範囲の脳の状態（例えば、健康な状態と無秩序な状態）のもつれを解くための脳の接続性のプロファイリングに対する最も挑戦的な障害の1つのままです。 
[ABSTRACT]これらには、マルチグラフの脳の統合、比較、およびプロファイリングの組み合わせが含まれます。これは、プロファイリングや神経障害の解明に使用できる脳マルチグラフの形状を聞くための最初のステップです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Brain Multiplex Prediction From a Single Network for
  High-Order Connectional Gender-Specific Brain Mapping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_24.html">
      <font color="black">Adversarial Brain Multiplex Prediction From a Single Network for
  High-Order Connectional Gender-Specific Brain Mapping</font>
    </a>
  </h2>
  <font color="black">このようなアーキテクチャは、潜在的なソースネットワークの表現と、ソースからターゲットマルチプレックスレイヤー内への深い非線形マッピングを同時に学習します。異なる点として、この論文では、ジオメトリックGAN（G-GAN）の初期フィールドを利用して設計します。 （i）スキップ接続を備えたU-Netアーキテクチャを模倣した幾何学的ソースからターゲットネットワークへのトランスレータ、および（ii）多重ソースイントラレイヤーの条件付けによって予測されたターゲットイントラレイヤーを分類する条件付き弁別子を含むディープマルチプレックス予測アーキテクチャ。このギャップを埋めるために、性別の違いを調査するために、ソースネットワークから脳の多重化を予測する最初の作業を提案します。 
[要約]調査により、マルチプレックス接続は性別分類の精度を大幅に向上させることがわかりました。これらにはマルチプレックス接続が含まれ、低次と高次の両方の性別-特定のマルチプレックス接続が識別されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Comparative Analysis of Polynomial and Rational Approximations of
  Hyperbolic Tangent Function for VLSI Implementation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_25.html">
      <font color="black">Comparative Analysis of Polynomial and Rational Approximations of
  Hyperbolic Tangent Function for VLSI Implementation</font>
    </a>
  </h2>
  <font color="black">tanhアクティベーション機能のさまざまな方法と実装が公開されていますが、比較研究は欠落しています。ニューラルネットワークアクセラレータのパフォーマンスとエリアターゲットを満たすには、アクティベーション機能の複雑さの低い正確なハードウェア実装が必要です。多項式と有理の方法とそれらのハードウェア実装の比較分析を示します。 
[ABSTRACT]ニューラルネットワークアクセラレータのターゲットを満たすには、人間の活性化機能が必要です。プログラムは、人間との接続などの高度なテクノロジーに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-13">
        <br><font color="black">2020-07-13</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding Fairness of Gender Classification Algorithms Across
  Gender-Race Groups -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_26.html">
      <font color="black">Understanding Fairness of Gender Classification Algorithms Across
  Gender-Race Groups</font>
    </a>
  </h2>
  <font color="black">たとえば、使用されているすべてのアルゴリズムで、黒人女性（一般に黒人種）は常に最も低い正解率を取得しました。しかし、現在まで、既存の研究の大部分はアフリカ系アメリカ人と白人のみに限定されていました。この目的は紙は、性別の人種グループにわたる性別分類アルゴリズムの異なる性能を調査することです。 
[ABSTRACT]調査では、性別と人種を超えたこのテクノロジーの公平性に疑問が投げかけられました。実験により、アーキテクチャの違いを伴うアルゴリズムは、特定の性別に対する一貫性とパフォーマンスが異なることが判明しました-人種グループ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic identification of fossils and abiotic grains during carbonate
  microfacies analysis using deep convolutional neural networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_27.html">
      <font color="black">Automatic identification of fossils and abiotic grains during carbonate
  microfacies analysis using deep convolutional neural networks</font>
    </a>
  </h2>
  <font color="black">薄片の微小相の同定に基づく岩石学分析は、堆積環境の解釈と古生態学的再構成で広く使用されています。コンピュータビジョンで非常に効率的であることが証明されている4つの古典的な深い畳み込みニューラルネットワーク（DCNN）を実装するために、高性能ワークステーションを採用しました。過去数年にわたって。骨格断片の形態学的および微細構造の多様性を区別するには、微小相における化石の形態型に関する広範な事前知識と、顕微鏡下での長いトレーニングセッションが必要です。 
[要約]ペトログラファーは、化石と非生物の穀物グループを識別できます。機械分類器は、ドロマイトや黄鉄鉱などの鉱物に困難を示しました。このツールは、人間の分類器に匹敵する再現性とバイアス回避を備えた高精度を示しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: DLBCL-Morph: Morphological features computed using deep learning for an
  annotated digital DLBCL image set -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_28.html">
      <font color="black">DLBCL-Morph: Morphological features computed using deep learning for an
  annotated digital DLBCL image set</font>
    </a>
  </h2>
  <font color="black">TMAには、DLBCLを代表する組織の領域を識別する、病理学者が注釈を付けた関心領域（ROI）が付随します。Cox比例ハザードモデルを適合させて、生存結果の予測におけるこれらの幾何学的特徴の有用性を示し、 Cインデックス（95％CI）0.635（0.574,0.691）を達成しました。この発見は、腫瘍核から計算された幾何学的特徴が予後的に重要であり、前向き研究で検証する必要があることを示唆しています。 
[要約]ディープラーニングモデルを使用してすべての腫瘍核をストレッチしました。これらの特徴は予後的に重要であることがわかりました。これは、腫瘍細胞からの幾何学的特徴の予測が予後を示唆していることを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Performance Analysis of 3D Face Alignment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_29.html">
      <font color="black">Unsupervised Performance Analysis of 3D Face Alignment</font>
    </a>
  </h2>
  <font color="black">これらの方法は最大50％の外れ値に対して堅牢であることを示し、顔の表情やオクルージョンがある場合に、未知のポーズから正面のポーズに顔をマッピングするのに適しています。データセット..しかし、この注釈プロセスは、手動でも自動でも、エラーが発生することはほとんどなく、分析に大きな偏りがあります。 
[要旨]顔画像に基づく剛体変換のロバスト推定の問題を再考します。統計的な正面顔モデルと関連するパラメトリック信頼メトリックを作成し、最終的にパフォーマンス分析に使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-14">
        <br><font color="black">2020-04-14</font>
      </time>
    </span>
</section>
<!-- paper0: How Neural Networks Extrapolate: From Feedforward to Graph Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_30.html">
      <font color="black">How Neural Networks Extrapolate: From Feedforward to Graph Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">これらの観察結果は、仮説につながります。アーキテクチャと入力表現に適切な非線形性をエンコードすると、GNNは動的プログラミング（DP）タスクで十分に外挿できます。一方、ReLU MLPは、訓練分布は十分に「多様」です。勾配降下によって訓練されたReLU MLPが原点から任意の方向に沿って線形関数にすばやく収束することから始めます。これは、ReLU MLPがほとんどの非線形タスクで十分に外挿できないことを示唆しています。 
[ABSTRACT] mlnモジュールを備えた構造化ネットワークであるgnnsは、より複雑なタスクである程度の成功を収めています。これらの研究は、ほとんどの非線形タスクではrelu mlpsが十分に外挿できないことを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Integration of the 3D Environment for On-Board UAV Visual Object
  Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_31.html">
      <font color="black">Integration of the 3D Environment for On-Board UAV Visual Object
  Tracking</font>
    </a>
  </h2>
  <font color="black">これにより、背景の乱雑さが原因のオクルージョンとアーティファクトの処理が向上します。既存のデータセットを視覚オブジェクト追跡に適合させ、観測されたシーンを3Dで再構築することにより、低高度で斜めビューのUAVからキャプチャされたプロトタイプの画像シーケンスの評価を行いました..無人航空機（UAV）からのビジュアルオブジェクトトラッキングには、オブジェクトのオクルージョンや背景の乱雑さなど、いくつかの課題があります。 
[要約]提案されたパイプラインは、ビジュアルオブジェクトトラッカーと静的環境のスパース3D再構成を組み合わせたものです。これは、背景の乱雑さによって引き起こされたオクルージョンとアーティファクトに基づいています。結果は、提案されたアプローチが、単純な視覚的手がかりとアプローチを使用した方法よりも優れていることを示しています追跡</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-06">
        <br><font color="black">2020-08-06</font>
      </time>
    </span>
</section>
<!-- paper0: Scene Graph to Image Generation with Contextualized Object Layout
  Refinement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_32.html">
      <font color="black">Scene Graph to Image Generation with Contextualized Object Layout
  Refinement</font>
    </a>
  </h2>
  <font color="black">ただし、シーングラフは指定が不十分であるため、トレーニングデータの多くのターゲット画像で同じシーングラフが発生することがよくあります。このモデルでは、オブジェクトレイアウトを徐々にアップサンプリング、リファイン、およびコンテキスト化することで、埋め込みから（中間ボックスを予測せずに）レイアウトを直接予測します。これは、画像の生成、関係の実現、オブジェクトの品質の向上につながります。 
[ABSTRACT]教師付き学習を使用して以前の作業でトレーニングされたモデル。目標は各シーングラフの正確なターゲット画像レイアウトを作成することです。この作業では、すべてのオブジェクトレイアウトを一緒に生成することにより、これらの問題を軽減する方法を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-23">
        <br><font color="black">2020-09-23</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Impute: A General Framework for Semi-supervised Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_33.html">
      <font color="black">Learning to Impute: A General Framework for Semi-supervised Learning</font>
    </a>
  </h2>
  <font color="black">最先端の半教師付き手法に簡単に組み込むことができる学習間定式化に問題を提起し、特にラベルが制限されている場合にそれらのパフォーマンスを向上させます。画像分類や顔のランドマーク検出タスクなど、分類と回帰の両方の問題。最近の半教師あり学習方法では、正規化戦略のおかげで、画像分類タスクでラベルのごく一部のみを使用しながら、教師ありと同等の結果が得られることが示されています。 
[要約]このホワイトペーパーでは、半教師あり学習により直接的なアプローチをとっています。ラベルなしのサンプルのラベルを補完する学習を提案しています。これらのラベルでトレーニングすると、ネットワークはより一般化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-22">
        <br><font color="black">2019-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: On the Detection of Digital Face Manipulation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_34.html">
      <font color="black">On the Detection of Digital Face Manipulation</font>
    </a>
  </h2>
  <font color="black">学習した注意マップでは、情報領域を強調表示して、バイナリ分類（本物の顔と偽の顔）をさらに改善し、操作された領域を視覚化します。したがって、操作された顔画像を検出し、操作された領域をローカライズすることが重要です。操作された顔の検出とローカリゼーションの研究では、さまざまなタイプの顔の偽造を含む大規模なデータベースを収集します。 
[要約]注意メカニズムを使用すると、顔の偽造品の検出と操作領域の位置特定が改善されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-03">
        <br><font color="black">2019-10-03</font>
      </time>
    </span>
</section>
<!-- paper0: SLGAN: Style- and Latent-guided Generative Adversarial Network for
  Desirable Makeup Transfer and Removal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_35.html">
      <font color="black">SLGAN: Style- and Latent-guided Generative Adversarial Network for
  Desirable Makeup Transfer and Removal</font>
    </a>
  </h2>
  <font color="black">生成的敵対的ネットワークを使用して人間の顔の写真に化粧を適用する場合に考慮すべき5つの機能があります。アイデンティティを回避するためにヒストグラムマッチングに基づいて化粧スタイルを転送できる、斬新な知覚化粧ロスとスタイル不変のデコーダを提供します。シフトの問題..残念ながら、5つすべての機能に同時に対応したものはありません。 
[ABSTRACT]私たちの提案は、顔のメイク画像を補間して固有の機能を決定できます。また、既存の方法を比較して、ユーザーが望ましいメイク構成を見つけるのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: ECOVNet: An Ensemble of Deep Convolutional Neural Networks Based on
  EfficientNet to Detect COVID-19 From Chest X-rays -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_36.html">
      <font color="black">ECOVNet: An Ensemble of Deep Convolutional Neural Networks Based on
  EfficientNet to Detect COVID-19 From Chest X-rays</font>
    </a>
  </h2>
  <font color="black">単一のトレーニング中に作成されるモデルスナップショットの予測は、2つのアンサンブル戦略、つまりハードアンサンブルとソフトアンサンブルを通じて組み合わされ、胸部X線を分類する関連タスクの分類パフォーマンスと一般化を改善します。大きな胸部X線データセットを使用してCOVID-19を検出するための、ECOVNetというEfficientNetに基づく深い畳み込みニューラルネットワーク（CNN）の集合。最初に、オープンアクセスの大きな胸部X線コレクションが拡張され、次に、EfficientNet用のImageNet事前トレーニング済みウェイトが、トレーニング済みのカスタマイズされた微調整トップレイヤーとともに転送され、モデルスナップショットのアンサンブルが続き、COVID-19、正常、および肺炎に対応する胸部X線を分類します。 
[要約]モデルスナップショットのアンサンブルは、胸部X線をcovid-19、正常、および肺炎に基づいて分類するために作成されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Local Context Attention for Salient Object Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_37.html">
      <font color="black">Local Context Attention for Salient Object Segmentation</font>
    </a>
  </h2>
  <font color="black">さらに、LCBに基づいて1ステージの粗密構造が実装され、ローカルコンテキスト記述機能が適応的に強化されます。次に、ローカルコンテキストブロック（LCB）に拡張されます。いくつかの顕著なオブジェクトセグメンテーションで包括的な実験が行われます。特に、DUTS-TEデータセットで最大0.883のFスコアと0.034 MAEを使用して、最新の方法に対する提案されたLCANetの優れたパフォーマンスを示すデータセット。 
[要約]提案されたネットワークは、明示的なローカル注意を生成するために注意相関フィルターを導入します。これは、ローカルコンテキスト記述能力に基づいています。優れたパフォーマンスは他のオブジェクトほど良くありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: MimicDet: Bridging the Gap Between One-Stage and Two-Stage Object
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_38.html">
      <font color="black">MimicDet: Bridging the Gap Between One-Stage and Two-Stage Object
  Detection</font>
    </a>
  </h2>
  <font color="black">従来の模倣方法とは異なり、MimicDetは1段および2段検出器のバックボーンを共有しており、模倣のための互換性のある機能を持つように設計された2つのヘッドに分岐します。コストはそれほど増加しないため、実用的です。大規模なネットワークをバックボーンとして採用するためです。したがって、MimicDetは、教師ネットワークの事前トレーニングなしでエンドツーエンドのトレーニングが可能です。 
[ABSTRACT] 2ステージ検出器は従来の方法よりも効率的ですが、2ステージ検出器は依然として精度をリードしています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Graph Normalization for Graph Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CV/paper_39.html">
      <font color="black">Learning Graph Normalization for Graph Neural Networks</font>
    </a>
  </h2>
  <font color="black">グラフニューラルネットワーク（GNN）はかなりの注目を集めており、グラフ構造化データを処理するための新しい有望なパラダイムとして浮上しています。GNNは通常、複数のレイヤーに積み重ねられ、各レイヤーのノード表現は、隣接するノードフィーチャの伝播と集約によって計算されます。グラフに関して。GNNは、複数のレイヤーにスタックすることにより、グラフ上のデータ間の長期的な依存関係をキャプチャして、パフォーマンスを向上させることができます。 
[ABSTRACT] gnnは通常、複数のレイヤーにスタックされ、隣接するノードの機能を伝播および集約して投影されます。複数のレイヤーでgnnを効果的にトレーニングするには、いくつかの正規化手法が必要です。この欠点に取り組むには、最適化することでグラフの正規化を学ぶことを提案します4つの異なるレベルでの正規化手法の重み付き組み合わせ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Keeping Up Appearances: Computational Modeling of Face Acts in
  Persuasion Oriented Discussions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_0.html">
      <font color="black">Keeping Up Appearances: Computational Modeling of Face Acts in
  Persuasion Oriented Discussions</font>
    </a>
  </h2>
  <font color="black">最後に、会話状態の潜在表現をモデル化して、予測される顔の行動が肯定的な会話結果の確率に及ぼす影響を分析し、以前の調査結果を裏付けるいくつかの相関関係を観察します。ブラウンとレビンソンの丁寧さ理論（1978）に基づいて、説得会話で顔の行動をモデル化するための一般化されたフレームワークを提案します。その結果、信頼できるコーディングマニュアル、注釈付きコーパス、および計算モデルが得られます。計算モデルを使用して、顔の行動を特定し、主要な会話の結果を予測できます（例
[ABSTRACT]顔のモデリングの概念は、人間の維持管理の研究の鍵です。この概念は、顔の行為がツールとしてどのように使用されるかを説明しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Adapting BERT for Word Sense Disambiguation with Gloss Selection
  Objective and Example Sentences -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_1.html">
      <font color="black">Adapting BERT for Word Sense Disambiguation with Gloss Selection
  Objective and Example Sentences</font>
    </a>
  </h2>
  <font color="black">また、WordNetの既存の例文を使用したWSDのデータ拡張手法も紹介します。提案されているトレーニング目標とデータ拡張手法を使用して、モデルは英語の全単語ベンチマークデータセットで最先端の結果を達成できます。 。BERTなどの事前トレーニング済みの言語モデルを使用したドメイン適応または転移学習は、多くの自然言語処理タスクに効果的なアプローチであることが証明されています。 
[ABSTRACT]提案されたトレーニング目標とデータ拡張手法を使用して、私たちのモデルは英語の全単語ベンチマークデータセットで結果を達成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: SentiLARE: Sentiment-Aware Language Representation Learning with
  Linguistic Knowledge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_2.html">
      <font color="black">SentiLARE: Sentiment-Aware Language Representation Learning with
  Linguistic Knowledge</font>
    </a>
  </h2>
  <font color="black">実験は、SentiLAREがさまざまな感情分析タスクで新しい最先端のパフォーマンスを取得することを示しています。まず、次の方法で、各単語の感情の極性を品詞タグで取得するコンテキスト認識感情アテンションメカニズムを提案します。 SentiWordNetにクエリを実行します。次に、ラベル対応マスク言語モデルと呼ばれる新しい事前トレーニングタスクを考案して、知識対応言語表現を構築します。 
[ABSTRACT] sentilare.itと呼ばれる新しい言語表現モデルを提案します。これは、事前にトレーニングされたモデルに、一部の音声タグと感情の極性を含む単語レベルの言語知識を導入します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-06">
        <br><font color="black">2019-11-06</font>
      </time>
    </span>
</section>
<!-- paper0: Feature Adaptation of Pre-Trained Language Models across Languages and
  Domains for Text Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_3.html">
      <font color="black">Feature Adaptation of Pre-Trained Language Models across Languages and
  Domains for Text Classification</font>
    </a>
  </h2>
  <font color="black">セルフトレーニングは、トレーニングのターゲットドメインデータの疑似ラベルを予測するUDAで広く使用されています。2つの単一言語および多言語のAmazonレビューデータセットでの実験により、CFdはクロスドメインおよびクロス言語でのセルフトレーニングのパフォーマンスを一貫して改善できることが示されています設定..セルフトレーニングのロバスト性を向上させるために、このホワイトペーパーでは、クラス認識機能自己蒸留（CFd）を提示して、PrLMから弁別特徴を学習します。PrLM機能は、特徴適応モジュールと特徴に自己蒸留されます同じクラスのより密にクラスター化されています。 
[ABSTRACT] prmsの機能を新しいドメインに適応させる方法を開発します。ラベル付きでトレーニングされたモデルをラベルなしのターゲットドメインに適応させます。ただし、予測された疑似ラベルにはノイズが含まれているため、トレーニングに悪影響を及ぼします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language
  Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_4.html">
      <font color="black">RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language
  Models</font>
    </a>
  </h2>
  <font color="black">私たちはいくつかの制御可能な生成方法を経験的に評価し、データまたは計算集約的な方法（たとえば、非毒性データの適応型事前トレーニング）が、単純なソリューション（たとえば、「悪い」単語を禁止する）よりも毒性を回避するのに効果的であることがわかります、現在の方法はありません。神経毒性変性に対してフェイルセーフです。RealToxicityPromptsを作成してリリースします。RealToxicityPromptsは、広く使用されている毒性分類子の毒性スコアと組み合わせた、英語のWebテキストの大規模なコーパスから派生した100Kの自然発生の文レベルのプロンプトのデータセットです。 ..事前トレーニング済みの神経言語モデル（LM）は、人種差別、性差別、またはその他の有毒な言語を生成する傾向があり、安全な展開を妨げます。 
[ABSTRACT]事前トレーニング済みのlmは、一見無害なプロンプトからでも有毒なテキストに退化する可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Language Generation with Multi-Hop Reasoning on Commonsense Knowledge
  Graph -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_5.html">
      <font color="black">Language Generation with Multi-Hop Reasoning on Commonsense Knowledge
  Graph</font>
    </a>
  </h2>
  <font color="black">一連のテキスト生成タスクでの生成済みの事前トレーニング済み言語モデルの成功にもかかわらず、生成中に基礎となる常識的な知識を推論する必要がある場合でも、問題が発生します。モデルが、次の3つのテキスト生成タスクの既存のベースラインを上回ることを経験的に示しています。常識に基づく推論が必要です。また、生成に根拠を提供するモデルによって推論された推論パスを使用して、動的マルチホップ推論モジュールの有効性を示します。 
[ABSTRACT]動的マルチホップテキストテキストテキストを含む事前トレーニング済みモデルを可能にするマルチホップ推論フロー（grf）を使用した生成を提案します。動的マルチホップ推論モデルの有効性も実証しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Can you tell? SSNet -- a Sagittal Stratum-inspired Neural Network
  Framework for Sentiment Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_6.html">
      <font color="black">Can you tell? SSNet -- a Sagittal Stratum-inspired Neural Network
  Framework for Sentiment Analysis</font>
    </a>
  </h2>
  <font color="black">代表的なベンチマークデータセットの実験結果と他の方法との比較1は、新しいネットワークアーキテクチャの利点を示しています。人間の脳には、皮肉を理解するのに役立つ、矢状層と呼ばれる特殊なニューロン形成さえあることがわかります。この生物学的形成を、同じテキスト上の異なるモデルの予測を組み合わせて、感情分析用の堅牢で正確かつ計算効率の高い分類子を構築するニューラルネットワークアーキテクチャを設計するためのインスピレーション。 
[ABSTRACT]人間の脳には、矢状層と呼ばれる特殊なニューロン形成さえあり、皮肉を理解するのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-23">
        <br><font color="black">2020-06-23</font>
      </time>
    </span>
</section>
<!-- paper0: Presentation and Analysis of a Multimodal Dataset for Grounded
  LanguageLearning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_7.html">
      <font color="black">Presentation and Analysis of a Multimodal Dataset for Grounded
  LanguageLearning</font>
    </a>
  </h2>
  <font color="black">これにより、ロボット工学、NLP、およびHCIの共通部分を研究する研究者は、画像、テキスト、および音声の複数のモダリティがどのように相互作用するかを調査し、これらのモダリティの固有の違いが結果に影響を与えることがわかります。この作業では、は、話し言葉または書き言葉のいずれかを使用して記述された一般的な家庭用オブジェクトのマルチモーダルデータセットであるGrounded Language Dataset（GoLD）を示します。違いを分析し、さまざまなモダリティが人間の入力からの言語学習にどのように影響するかを示す実験を示します。 
[要約]研究は、さまざまなモダリティが人間の言語学習にどのように影響するかを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Novel Keyword Extraction and Language Detection Approaches -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_8.html">
      <font color="black">Novel Keyword Extraction and Language Detection Approaches</font>
    </a>
  </h2>
  <font color="black">ファジー言語マッチングのための文字列トークン化への高速で斬新なアプローチを提案し、処理時間を83.6％短縮し、再現率は推定で3.1％向上しますが、精度は2.6％減少します。このアプローチは機能します。キーワードが複数の単語に細分化されている場合でも、文字間をスキャンする必要はありません。ファジー文字列マッチングと言語分類は、自然言語処理パイプラインの重要なツールであり、このホワイトペーパーは両方の分野で進歩をもたらします。 
[ABSTRACT]文字列のトークン化は、文字列のトークン化への高速で斬新なアプローチです。処理時間は83. 6％減少し、回収率は推定で3％向上しますが、2.6％減少します。検討する作業はありません。メタデータを使用して言語分類を強化する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Task-Oriented Dialogue as Dataflow Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_9.html">
      <font color="black">Task-Oriented Dialogue as Dataflow Synthesis</font>
    </a>
  </h2>
  <font color="black">MultiWOZデータセットに関する追加の実験により、データフロー表現により、既成のシーケンスからシーケンスへのモデルが、既存の最良のタスク固有の状態追跡モデルと一致することが可能になることが示されています。新しいデータセット、SMCalFlowを導入し、イベント、天気、場所、人など。実験では、データフローグラフとメタ計算により、これらの自然な対話における表現可能性と予測可能性が大幅に向上することが示されています。 
[ABSTRACT]私たちのグラフに基づく状態は、複雑なユーザーインテントの表現と操作を可能にします。明示的なメタ計算により、これらのインテントが学習モデルで予測しやすくなります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: AliMe KG: Domain Knowledge Graph Construction and Application in
  E-commerce -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_10.html">
      <font color="black">AliMe KG: Domain Knowledge Graph Construction and Application in
  E-commerce</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、フリーテキストからドメインナレッジグラフを構築する方法を体系的に紹介し、いくつかのアプリケーションでそのビジネス価値を実証します。AliMeKGを、ショッピングガイド、プロパティに関する質問応答、推奨理由の生成などのいくつかのオンラインビジネスシナリオに適用しました。私たちの経験では、垂直領域でのフリーテキストからの構造化された知識のマイニングは実用的であり、産業環境で大きな価値がある可能性があります。 
[ABSTRACT] alime kgは、eコマースのドメインナレッジグラフです。ユーザーの問題、関心のあるポイント（poi）、アイテム情報、および関係をキャプチャします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: CogniFNN: A Fuzzy Neural Network Framework for Cognitive Word Embedding
  Evaluation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_11.html">
      <font color="black">CogniFNN: A Fuzzy Neural Network Framework for Cognitive Word Embedding
  Evaluation</font>
    </a>
  </h2>
  <font color="black">最近の先駆的フレームワークと比較して、提案されたCogniFNNは、文脈非依存（GloVe）と文脈依存（BERT）の両方の単語埋め込みの予測誤差が小さく、ランダムに生成された単語埋め込みで高い有意比率を達成しました。実験では、 3つのモダリティ（EEG、fMRI、およびアイトラッキング）にわたる15の人間の認知データセット、および平均二乗誤差と複数の仮説テストをメトリックとして選択して、提案されたCogniFNNフレームワークを評価しました。単語の埋め込みは、意味論的表現を反映でき、埋め込み品質は、人間の自然な読書に関連する認知データソースで総合的に評価されます。 
[ABSTRACT] cognifnnは、ファジーニューラルネットワークを使用して、対応する認知データセットに対する英語の埋め込みを評価するための非線形および非定常特性を抽出する最初の試みです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Generating Commonsense Explanation by Extracting Bridge Concepts from
  Reasoning Paths -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_12.html">
      <font color="black">Generating Commonsense Explanation by Extracting Bridge Concepts from
  Reasoning Paths</font>
    </a>
  </h2>
  <font color="black">トリプルを最初にスコア付けし、サブグラフ内のパスをルーティングし、さらにトリプルレベルとコンセプトレベルの両方で監督が弱いブリッジコンセプトを選択するブリッジコンセプト抽出モデルを設計します。常識説明生成タスクとモデルは、自動評価と人間評価の両方で最先端のベースラインよりも優れています。この作業では、推論チェーンで\ textit {bridges}として機能する基本的な概念を最初に抽出し、これらを統合する方法を提案します最終的な説明を生成するための概念。 
[ABSTRACT]私たちは常識的な説明生成タスクの実験を行います。私たちのモデルは、自動評価と人間評価の両方で最先端のベースラインを上回っています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Augmentation Policy Search for Domain and Cross-Lingual
  Generalization in Reading Comprehension -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_13.html">
      <font color="black">Adversarial Augmentation Policy Search for Domain and Cross-Lingual
  Generalization in Reading Comprehension</font>
    </a>
  </h2>
  <font color="black">これらの学習されたポリシーを使用して、敵対的なトレーニングがドメイン内、ドメイン外、および言語間（ドイツ語、ロシア語、トルコ語）の一般化の大幅な改善につながる可能性があることを示します。この作業では、いくつかの効果的な敵と読解モデルを敵対的評価に対してより堅牢にするだけでなく、ソースドメインと新しいドメインおよび言語の一般化を改善することを目的とした自動化されたデータ拡張ポリシー検索メソッド。モデルの一般化。 
[ABSTRACT]敵対的に拡張されたデータセットを使用したトレーニングは、パフォーマンスによって改善されましたが、モデルの一般化に悪影響を及ぼしました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-13">
        <br><font color="black">2020-04-13</font>
      </time>
    </span>
</section>
<!-- paper0: N-LTP: A Open-source Neural Chinese Language Technology Platform with
  Pretrained Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_14.html">
      <font color="black">N-LTP: A Open-source Neural Chinese Language Technology Platform with
  Pretrained Models</font>
    </a>
  </h2>
  <font color="black">私たちの知る限り、これはすべての中国のNLPの基本的なタスクをサポートする最初のツールキットです。ソースコード、ドキュメント、および事前トレーニング済みのモデルは、https：//github.com/HIT-SCIR/ltp ..で入手できます。さらに、シングルタスクモデルがマルチタスクモデルを教える知識抽出を使用することを提案します。これにより、マルチタスクモデルがシングルタスクの教師を超えることができます。 
[ABSTRACT]マルチナレッジナレッジナレッジシステムには、すべての中国語関連タスクの共有ナレッジをキャプチャする事前トレーニング済みモデルがあります。このツールは、ユーザーが使いやすく、処理結果を直接表示できるようにする視覚化ツールも提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Causal Explanation Detection with Pyramid Salient-Aware Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_15.html">
      <font color="black">Towards Causal Explanation Detection with Pyramid Salient-Aware Network</font>
    </a>
  </h2>
  <font color="black">さらに、PSANは、トップアテンションベースの談話レベルの顕著なネットワークを介して談話の優位性を変更して、メッセージの説明的なセマンティクスを強化することができます。CEAの一般的に使用されるデータセットでの実験は、PSANが最先端のパフォーマンスよりも優れていることを示しています因果的説明検出タスクでF1値を1.8％削減する方法です。メッセージの因果的説明を検出するためにピラミッド顕著認識ネットワーク（PSAN）を設計します。 
[ABSTRACT] psanは、原因説明分析の重要なサブタスクであり、1つのメッセージに原因説明が存在するかどうかを判断します。調査によると、psanは、最先端の方法よりも、原因説明の検出でf1値が1％優れています。仕事</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Ape210K: A Large-Scale and Template-Rich Dataset of Math Word Problems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_16.html">
      <font color="black">Ape210K: A Large-Scale and Template-Rich Dataset of Math Word Problems</font>
    </a>
  </h2>
  <font color="black">私たちは、Ape210Kが数学の単語問題解決システムのベンチマークになることを期待しています。Ape210Kを解決するには、自然言語の理解だけでなく常識的な知識も必要であることが分析で示されています。 。 
[ABSTRACT]以前の作品で使用された評価データセットには、規模と多様性の点で深刻な制限があります。これは、最大の公開データセットmath23kの9倍のサイズである210kの中国の小学校レベルの数学問題で構成されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Logic2Text: High-Fidelity Natural Language Generation from Logical Forms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_17.html">
      <font color="black">Logic2Text: High-Fidelity Natural Language Generation from Logical Forms</font>
    </a>
  </h2>
  <font color="black">論理形式は、フリースキーマの多様なグラフ構造を示します。これは、モデルのセマンティクスを理解する能力に大きな課題をもたらします。テーブルが提供されているだけの場合、既存のモデルが制御可能で忠実度の高い論理生成を生成することは困難です。新しい大規模なデータセット\ textsc {Logic2Text}を提示します。基本的な論理形式とペアになっている一般的なロジックタイプを含む10,753の説明があります。 
[抽象]この作品では、制御可能で忠実な忠実な世代を取得するために、論理レベルからの世代として論理レベルnlgを定式化します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: Grounded Compositional Outputs for Adaptive Language Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_18.html">
      <font color="black">Grounded Compositional Outputs for Adaptive Language Modeling</font>
    </a>
  </h2>
  <font color="black">私たちの知る限り、結果は、トレーニング語彙に依存しないサイズの最初の単語レベルの言語モデルです。私たちの分析は、サンプル効率の向上に起因しています。私たちのモデルは、低頻度の単語に対してより正確です。は、この問題を改善するために、表面フォームに基づく合成入力の埋め込みを使用しました。 
[要旨]言語モデルのサイズはそのサイズに影響を与え、そのような適応に抵抗するものの一部です。この作業では、一歩先を行き、言語モデルの完全に構成的な出力埋め込み層を提案します。さらに情報に基づいています構造化レキシコンから（wordnet）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: AnchiBERT: A Pre-Trained Model for Ancient ChineseLanguage Understanding
  and Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_19.html">
      <font color="black">AnchiBERT: A Pre-Trained Model for Ancient ChineseLanguage Understanding
  and Generation</font>
    </a>
  </h2>
  <font color="black">より簡単に入手できる古代中国のコーパスを最大限に活用するために、大規模な古代中国のコーパスでトレーニングされたBERTのアーキテクチャに基づいた事前トレーニング済み言語モデルであるAnchiBERTをリリースします。実験結果では、 AnchiBERTは、事前トレーニングされていないモデルと同様にBERTよりも優れており、すべてのケースで最先端の結果を達成します。以前の研究では、通常、並列データに深く依存する監視モデルを使用しています。 
[ABSTRACT]古代-現代中国語の翻訳、詩のモデル、最新の状態は自然言語処理の例です。さらに、古代中国の大規模な並列データを取得することは困難です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Effects of Word-frequency based Pre- and Post- Processings for Audio
  Captioning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/cs.CL/paper_20.html">
      <font color="black">Effects of Word-frequency based Pre- and Post- Processings for Audio
  Captioning</font>
    </a>
  </h2>
  <font color="black">ここでは、それらの寄与を評価するために、最初にシステムで要素ごとのアブレーション研究を行い、各要素がどの程度効果的であるかを推定しました。音響シーンの検出と分類のタスク6（自動オーディオキャプション）に使用したシステムとイベント（DCASE）2020チャレンジは、オーディオキャプションのための3つの要素、つまりデータ増強、マルチタスク学習、および後処理を組み合わせたものです。次に、詳細なモジュールごとのアブレーション研究を実施し、精度を向上させるための主要な処理モジュールをさらに明確にしました。 
[ABSTRACT]システムは最高の評価スコアを受け取りましたが、パフォーマンスに最も完全に貢献した個々の要素のどれがまだ明確にされていません。次に、詳細なモジュールを実施しました。精度の向上</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: A New Dataset for Amateur Vocal Percussion Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.AS/paper_0.html">
      <font color="black">A New Dataset for Amateur Vocal Percussion Analysis</font>
    </a>
  </h2>
  <font color="black">この分析の最終目標は、マッピングアルゴリズムが被験者間をより一般化し、より高いパフォーマンスを達成するのに役立つことです。この研究の貢献は2つあります。特に、エミュレートされた楽器へのこれらの音声模倣の自動マッピングにより、作成者は、リズムをより速く現実的にプロトタイプ化します。 
[ABSTRACT]新しいアマチュアボーカルパーカッション（avp）データセットが導入され、ビートボクシングの経験がほとんどまたはまったくない人が、ボーカルパーカッションのタスクにどのようにアプローチするかを調査します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Data augmentation and loss normalization for deep noise suppression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.AS/paper_1.html">
      <font color="black">Data augmentation and loss normalization for deep noise suppression</font>
    </a>
  </h2>
  <font color="black">この正規化は、レベル依存の損失関数を使用すると、信号レベルが不均衡なシーケンスでのトレーニングによって引き起こされる劣化を克服することを実験で示しています。SNR値をより広い範囲に拡張するだけでなく、連続分布がトレーニングの正規化に役立つことを示していますだけでなく、スペクトルおよび動的レベルダイバーシティも強化します。ただし、レベルの強化によってトレーニングを低下させないために、シーケンスレベルの正規化を適用して、信号ベースの損失関数を変更することを提案します。 
[ABSTRACT]教師ありディープラーニングのためのデータ増強技術-ベースの音声強調。研究はデータ増強によって行われました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-14">
        <br><font color="black">2020-08-14</font>
      </time>
    </span>
</section>
<!-- paper0: The COUGHVID crowdsourcing dataset: A corpus for the study of
  large-scale cough analysis algorithms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.AS/paper_2.html">
      <font color="black">The COUGHVID crowdsourcing dataset: A corpus for the study of
  large-scale cough analysis algorithms</font>
    </a>
  </h2>
  <font color="black">その結果、COUGHVIDデータセットは、世界で最も緊急な健康危機に対処するためにMLモデルをトレーニングするための豊富な咳の記録に貢献します。次に、経験豊富な呼吸器科医が2,000以上の記録にラベルを付けて、咳に存在する医学的異常を診断し、それにより、多数の咳音声分類タスクに使用できる、現存するエキスパートラベルの付いた最大の咳データセット。COUGHVIDデータセットは、幅広い被験者の年齢、性別、地理的場所、およびCOVID-19ステータスを表す20,000以上のクラウドソーシングされた咳の記録を提供します。 
[要約]現在、このようなmlモデルをトレーニングするための咳音の検証済みデータベースはありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Timbre Space Representation of a Subtractive Synthesizer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.AS/paper_3.html">
      <font color="black">Timbre Space Representation of a Subtractive Synthesizer</font>
    </a>
  </h2>
  <font color="black">ペアワイズ非類似度の評価は、オンラインブラウザーベースの実験内で収集されました。さまざまな波形入力ソースとエンベロープフィルターが音色変化の主要な手段として機能し、合成音色の知覚に新しい音響相関を提供するという仮説を立てました。さまざまなソース波形、周波数変調（FM）、およびエンベロープされたカットオフ周波数を持つローパスフィルターを使用する合成モデルによって生成される15個のサウンドのセット。 
[ABSTRACT]合成モデルによって生成された15のサウンドのセットをキュレートします。さまざまなソース波形、周波数緩和（fm）、およびエンベロープされたカットオフ周波数を持つローパスフィルターを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Effects of Word-frequency based Pre- and Post- Processings for Audio
  Captioning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-25/eess.AS/paper_4.html">
      <font color="black">Effects of Word-frequency based Pre- and Post- Processings for Audio
  Captioning</font>
    </a>
  </h2>
  <font color="black">次に、詳細なモジュールごとのアブレーションスタディを実施して、精度を向上させるための主要な処理モジュールをさらに明確にしました。この結果は、データの増強と後処理により、システムのスコアが大幅に向上することを示しています。特に、データの混合とビームサーチの混合後処理では、SPIDErをそれぞれ0.8ポイントと1.6ポイント改善します。 
[ABSTRACT]システムは最高の評価スコアを受け取りましたが、パフォーマンスに最も完全に貢献した個々の要素のどれがまだ明確にされていません。次に、詳細なモジュールを実施しました。精度の向上</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
