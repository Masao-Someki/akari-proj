<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-12-16の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: QUARC: Quaternion Multi-Modal Fusion Architecture For Hate Speech
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.SD/paper_0.html">
      <font color="black">QUARC: Quaternion Multi-Modal Fusion Architecture For Hate Speech
  Classification</font>
    </a>
  </h2>
  <font color="black">ソーシャルメディアへのヘイトスピーチ投稿の特定のモダリティに基づくモデルは有用ではありません。むしろ、ヘイトスピーチを分類しながら画像とテキストの両方を考慮するマルチモーダル融合モデルのようなモデルが必要です。テキスト-画像融合モデルは高度にパラメータ化されているため、モダリティのペアごとに追加の融合コンポーネントを持つクォータニオンニューラルネットワークベースのモデルを提案します。モデルは、ヘイトスピーチ分類のためにMMHS150KTwitterデータセットでテストされます。 
[概要]テキスト-画像融合モデルは大幅にペアリングされているため、クォータニオンニューラルネットワークベースのモデルを提案します。このモデルは、パラメーターが約75％削減され、ストレージスペースとトレーニング時間にメリットがあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: A novel dataset for the identification of computer generated melodies in
  the CSMT challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.SD/paper_1.html">
      <font color="black">A novel dataset for the identification of computer generated melodies in
  the CSMT challenge</font>
    </a>
  </h2>
  <font color="black">データセットの目的は、生成されたメロディーの特徴を学習することにより、コンピューターで生成されたメロディーを区別できるかどうかを調べることです。データセットは、開発データセットと評価データセットの2つの部分で構成されます。 Conference on Sound and Music Technology（CSMT）が主催するデータチャレンジが紹介されています。 
[概要] csmtデータチャレンジでは、参加者はメロディーの一部がコンピューターによって生成されたものか、人間によって作成されたものかを識別する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: A fully recurrent feature extraction for single channel speech
  enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.SD/paper_2.html">
      <font color="black">A fully recurrent feature extraction for single channel speech
  enhancement</font>
    </a>
  </h2>
  <font color="black">この目的のために、特徴抽出CNNレイヤーに再通貨係数を追加して、単一チャネル音声強調のための堅牢なコンテキスト認識特徴抽出戦略を導入します。バニラCNNモジュールを使用した強化モデルに対して評価した場合、目に見えないノイズ条件で、提案されたモデル特徴抽出レイヤーでの再通貨化により、最大1.5 dBのセグメントSNR（SSNR）ゲインが生成され、平均意見スコアスケールで主観的品質が0.4向上し、最適化されるパラメーターが25％削減されました。示されているように、再通貨を追加すると、抽出された特徴レベルでノイズ属性のローカル統計がキャプチャされるため、提案されたモデルは、非常にノイズの多い条件でも音声キューを区別するのに効果的です。 
[要約]この主張は、cnnの話し言葉の話し言葉の地域からのデータの欠如に基づいています。ただし、このモデルは、非常に騒がしい状況でも音声の手がかりを区別するのに効果的であることが示唆されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-09">
        <br><font color="black">2020-06-09</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Medical Deep Learning -- A systematic Meta-Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/eess.IV/paper_0.html">
      <font color="black">Medical Deep Learning -- A systematic Meta-Review</font>
    </a>
  </h2>
  <font color="black">患者データは、病院などの臨床センターで収集されるだけでなく、ほんの数例を挙げると、一般開業医、モバイルヘルスケアアプリ、またはオンラインWebサイトによって収集されるデータにも関連しています。大量の患者記録とデータの収集、および個別化された治療への傾向により、健康情報の自動化された信頼性の高い処理と分析に対する大きなニーズがあります。この傾向は、過去数年間に新しい大規模な研究努力をもたらしました。 
[概要]ディープラーニングアルゴリズムは、画像処理や分析のように、カッティングメッド手法よりも優れたパフォーマンスを発揮しました。オブジェクト認識やゲームなど、ディープラーニングが人間よりも優れたパフォーマンスを発揮する場合もあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Remote Sensing Image Scene Classification with Deep Neural Networks in
  JPEG 2000 Compressed Domain -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/eess.IV/paper_1.html">
      <font color="black">Remote Sensing Image Scene Classification with Deep Neural Networks in
  JPEG 2000 Compressed Domain</font>
    </a>
  </h2>
  <font color="black">したがって、提案されたアプローチは、エンドツーエンドのトレーニング可能な統合ニューラルネットワークでJPEG 2000圧縮アルゴリズムで与えられた多重解像度パラダイムをモデル化します。これは、最も粗い解像度のウェーブレットサブバンドに関連付けられたコードストリームを入力として取得して、より細かい解像度に近づけることによって実現されます。いくつかの転置された畳み込み層を使用するサブバンド..次に、一連の畳み込み層は、近似されたウェーブレットサブバンドの高レベルのセマンティックコンテンツをモデル化します。 
[ABSTRACT]ディープニューラルネットワークを使用する既存のシーン分類アプローチでは、画像を完全に解凍する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-20">
        <br><font color="black">2020-06-20</font>
      </time>
    </span>
</section>
<!-- paper0: Canopy Density Estimation in Perennial Horticulture Crops Using 3D
  Spinning Lidar SLAM -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/eess.IV/paper_2.html">
      <font color="black">Canopy Density Estimation in Perennial Horticulture Crops Using 3D
  Spinning Lidar SLAM</font>
    </a>
  </h2>
  <font color="black">AgScan3Dデータは、Continuous-Time SLAMアルゴリズムによって、グローバルに登録された3Dレイクラウドに処理されます。グローバルレイクラウドは、季節内およびシーズン全体でブドウ園のスナップショットを複数回比較できる正規のデータ形式（デジタルツイン）です。季節..コードとフィールドのデータセットはhttps://github.com/csiro-robotics/agscan3dで入手できます。 
[概要]グローバルレイクラウドはデジタルツインであり、シーズン内およびシーズン間でブドウ園のスナップショットを複数回比較できます。このデジタルツインの組み合わせにより、成長期および年間からブドウ園全体を分析および比較できます。年</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-30">
        <br><font color="black">2020-07-30</font>
      </time>
    </span>
</section>
<!-- paper0: Frozen-to-Paraffin: Categorization of Histological Frozen Sections by
  the Aid of Paraffin Sections and Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/eess.IV/paper_3.html">
      <font color="black">Frozen-to-Paraffin: Categorization of Histological Frozen Sections by
  the Aid of Paraffin Sections and Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">さらに、凍結からパラフィンへの変換が分類スコアの最適化に役立つかどうかを調査しました。最後に、少量のトレーニングデータを処理し、分類の精度をさらに高めるための特定のデータ拡張戦略を提案します。ただし、パラフィン切片と比較して、凍結切片の品質は通常低く、誤分類の割合が高くなります。 
[要約]これにより、外科医は介入中に組織学的所見を待って、組織学的結果に基づいて術中を行うことができました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Effect of the regularization hyperparameter on deep learning-based
  segmentation in LGE-MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/eess.IV/paper_4.html">
      <font color="black">Effect of the regularization hyperparameter on deep learning-based
  segmentation in LGE-MRI</font>
    </a>
  </h2>
  <font color="black">ここでは、任意のL2正則化値を使用して、さまざまな深層学習ベースのセグメンテーションネットワークを作成します。この作業では、L2正則化ハイパーパラメーターの任意の選択が深層学習ベースのセグメンテーションの結果にどの程度影響するかを示すことを目的としています。また、著者は、他の深層学習ハイパーパラメーターの手動調整または調整を採用して、90％の検証精度を達成する前にすべてのエポックの10％に達した場合にのみ実行します。 
[概要]これらは、さまざまな深層学習ベースのセグメンテーションネットワークを作成するために使用できます。これらは、l2正則化の長さに対する高血圧の例です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: WDNet: Watermark-Decomposition Network for Visible Watermark Removal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/eess.IV/paper_5.html">
      <font color="black">WDNet: Watermark-Decomposition Network for Visible Watermark Removal</font>
    </a>
  </h2>
  <font color="black">公開グレースケールデータセットLVWおよびCLWDでの広範な実験は、提案されたWDNetが精度と効率の両方で最先端のアプローチよりも優れていることを一貫して示しています。現在の除去方法は通常、画像から画像への変換技術を活用しています。コードとCLWDデータセットは、https：//github.com/MRUIL/WDNetで公開されています。 
[概要]色付き透かし除去データセットの空白を埋めるために、clwdと呼ばれる大規模なデータセットを構築します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-14">
        <br><font color="black">2020-12-14</font>
      </time>
    </span>
</section>
<!-- paper0: Triage of Potential COVID-19 Patients from Chest X-ray Images using
  Hierarchical Convolutional Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/eess.IV/paper_6.html">
      <font color="black">Triage of Potential COVID-19 Patients from Chest X-ray Images using
  Hierarchical Convolutional Networks</font>
    </a>
  </h2>
  <font color="black">実験結果は、HCNアーキテクチャが既存の研究と比較してより良い結果を達成できることを示しています。COVIDNetからの畳み込み層の使用により、CXRモダリティに関連する表現の抽出が保証されます。提案された方法は潜在的なCOVID-19を正確にトリアージできます。テスト負荷を共有し、テスト容量を増やすためのCXR画像を介した患者。 
[ABSTRACT] covidnetが畳み込みネットワーク（hcn）を使用して、さまざまな機能とともにデータを自然に拡張します。covidnetから畳み込み層を使用すると、cxrに関連する表現を確実に抽出できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-01">
        <br><font color="black">2020-11-01</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding Catastrophic Overfitting in Single-step Adversarial
  Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/eess.IV/paper_7.html">
      <font color="black">Understanding Catastrophic Overfitting in Single-step Adversarial
  Training</font>
    </a>
  </h2>
  <font color="black">この論文では、壊滅的な過剰適合が、最大の摂動を伴う敵対的な例のみを使用するシングルステップの敵対的トレーニングの特性と非常に密接に関連しており、敵対的な方向のすべての敵対的な例ではなく、決定境界の歪みと高度に湾曲した損失面..高速の敵対的トレーニングは堅牢性と効率の両方を示しましたが、「壊滅的な過剰適合」の問題が観察されました。この観察に基づいて、壊滅的な過剰適合を防ぐだけでなく、シングルステップの敵対的訓練では、マルチステップの敵対的攻撃を防ぐことは難しいという信念。 
[概要]簡単な方法は、壊滅的な過剰適合を防ぐことができます。また、単一ステップの敵対的トレーニングで多段階の敵対的攻撃を防ぐことは難しいという信念を無効にします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Medical Deep Learning -- A systematic Meta-Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_0.html">
      <font color="black">Medical Deep Learning -- A systematic Meta-Review</font>
    </a>
  </h2>
  <font color="black">この開発が大きな可能性を示しているもう1つの分野は、医療分野です。大量の患者記録とデータの収集、および個別化された治療への傾向により、健康の自動化された信頼性の高い処理と分析が強く求められています。情報..一般に、特定の病状を含む医療画像の分析など、特定の医療シナリオに焦点を当てています。 
[概要]ディープラーニングアルゴリズムは、画像処理や分析のように、カッティングメッド手法よりも優れたパフォーマンスを発揮しました。オブジェクト認識やゲームなど、ディープラーニングが人間よりも優れたパフォーマンスを発揮する場合もあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Clustering of Electromagnetic Showers and Particle Interactions with
  Graph Neural Networks in Liquid Argon Time Projection Chambers Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_1.html">
      <font color="black">Clustering of Electromagnetic Showers and Particle Interactions with
  Graph Neural Networks in Liquid Argon Time Projection Chambers Data</font>
    </a>
  </h2>
  <font color="black">液体アルゴンタイムプロジェクションチェンバー（LArTPC）は、敏感なボリューム内の荷電粒子の高解像度画像を生成する検出器のクラスです。グラフニューラルネットワーク（GNN）は、任意の空間に埋め込まれたオブジェクト間の相関関係を見つけるために近年開発されました。相対的なシャワーエネルギーの解像度は$（4.1 + 1.4 / \ sqrt {E（\ text {GeV}）}）\、\％$で、シャワーの方向の解像度は$（2.1 / \ sqrt {E（\ text { GeV}）}）^ {\ circ} $。 
[概要]電子メールは、相互作用の粒子を検出するために電子メールを使用できることを示しています。電子メールは、電子メールが現在および将来のニュートリノ物理学プログラムにとって重要であることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-02">
        <br><font color="black">2020-07-02</font>
      </time>
    </span>
</section>
<!-- paper0: NAPA: Neural Art Human Pose Amplifier -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_2.html">
      <font color="black">NAPA: Neural Art Human Pose Amplifier</font>
    </a>
  </h2>
  <font color="black">導入された機能を分析するために、広範な言及研究を実行します。最後に、モデルを実際の人間のデータセットに一般化し、一般的なポーズモデルとしての可能性を示します。また、スタイルごとのトレーニングとエンドツーエンドを比較し、スタイルの転送とポーズの回帰の間のトレードオフをほのめかします。 
[概要]芸術的な画像で人間の姿勢の推定をターゲットにします。任意のスタイル転送用に277のスタイルセットを収集し、芸術的な281の画像テストセットを構築します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Object-based attention for spatio-temporal reasoning: Outperforming
  neuro-symbolic models with flexible distributed architectures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_3.html">
      <font color="black">Object-based attention for spatio-temporal reasoning: Outperforming
  neuro-symbolic models with flexible distributed architectures</font>
    </a>
  </h2>
  <font color="black">私たちのモデルは、自己注意と学習された「ソフトな」オブジェクト中心の表現、およびBERTスタイルの半教師あり予測損失の両方を批判的に利用します。ニューラルネットワークは、さまざまな知覚タスクで成功を収めていますが、多くの場合、これらのドメインでの最初の実験では、論理エンジンと言語パーサーをニューラル知覚フロントエンドと結合する神経シンボリックアプローチが、完全に学習された分散型よりも大幅に優れていることがわかりました。ネットワーク、上記の論文をサポートするために取られた発見。 
[概要] 2つの新しいタスクドメイン、clevrerとcaterは、知覚ではなく、オブジェクト間の空間-量子相互作用のコンテキストで推論に焦点を当てるために開発されました。研究は、適切な誘導性を備えた完全に学習されたニューラルネットワークを示していますバイアスは、以前のすべての認知モデルよりも大幅に優れたパフォーマンスを発揮します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: PaMIR: Parametric Model-Conditioned Implicit Representation for
  Image-based Human Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_4.html">
      <font color="black">PaMIR: Parametric Model-Conditioned Implicit Representation for
  Image-based Human Reconstruction</font>
    </a>
  </h2>
  <font color="black">PaMIRベースの再構築フレームワークでは、パラメトリックモデルのセマンティック機能を使用して自由形式のディープ陰関数を正規化するための新しいディープニューラルネットワークが提案されています。これにより、挑戦的なポーズやさまざまな衣服のトポロジのシナリオでの一般化能力が向上します。最後に、パラメトリックモデルの推定精度を向上させ、パラメトリックモデルと陰関数の間の一貫性を高めるためのボディリファレンス最適化手法を提案します。単一の画像から3D人間を正確かつロバストにモデリングすることは非常に困難であり、そのための鍵です。不適切な問題は、人間のモデルの3D表現です。 
[ABSTRACT]パラメトリックモデル-条件付き陰的表現（パミール）は、パラメトリックボディモデルを自由に組み合わせます-ディープディープディープインジェクションを形成します。3Dモデルを含む通常の3Dモデルの制限を克服するように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Image Inpainting Guided by Coherence Priors of Semantics and Textures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_5.html">
      <font color="black">Image Inpainting Guided by Coherence Priors of Semantics and Textures</font>
    </a>
  </h2>
  <font color="black">Semantic-Wise Attention Propagation（SWAP）モジュールは、非局所的なセマンティックコヒーレンスを探索することにより、スケール全体で完成した画像テクスチャを洗練するために考案されました。これにより、テクスチャの混同が効果的に軽減されます。具体的には、最初にマルチスケールジョイント最適化フレームワークを採用します。コヒーレンスの優先順位をモデル化し、それに応じて画像の修復とセマンティックセグメンテーションを粗い方法から細かい方法でインターリーブ的に最適化します。また、全体的な構造と詳細なテクスチャの観点から、セマンティクスと修復された画像の間の一貫性を制約する2つのコヒーレンス損失を提案します。 。 
[要約]これは、テクスチャが不明瞭で変化しているためです。コヒーレンスの損失により、セマンティック画像と修復された画像の間の一貫性が制約されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Class-incremental Learning with Rectified Feature-Graph Preservation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_6.html">
      <font color="black">Class-incremental Learning with Rectified Feature-Graph Preservation</font>
    </a>
  </h2>
  <font color="black">それらの長所と短所への洞察は、古い知識の保存のための加重ユークリッド正則化を動機付けます。CIFAR-100とImageNetデータセットの両方での実験結果は、私たちの方法が分類エラーを減らし、壊滅的な忘却を容易にするという点で最先端のアプローチよりも優れていることを示しています、および異なるクラス間で均等にバランスの取れた精度を奨励します。私たちのプロジェクトページはhttps://github.com/yhchen12101/FGP-ICLにあります。 
[概要]私たちのプロジェクトページはwwwです。 github。 com / yhchen12101 / fgp-icl</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Improving Spatiotemporal Action Recognition in Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_7.html">
      <font color="black">Towards Improving Spatiotemporal Action Recognition in Videos</font>
    </a>
  </h2>
  <font color="black">YOWOの変更を適用するために、2つの中規模のデータセットを検討します。人気のある共同注釈付きヒューマンモーションデータベース（J-HMDB-21）と、カーネギーメロン大学を拠点とするスタートアップAgotが提供するレストランのビデオ映像のプライベートデータセットです。 AI ..具体的には、損失関数を変更することにより、YOWOを改善し、ビデオの不均衡なクラスの問題に対処するための4つの新しいアプローチを提案します。後者は、小さなオブジェクトと不均衡なデータクラスを使用した動きの速いアクションを含み、タスクを作成します。アクションローカリゼーションのより挑戦的な。 
[概要]アクション検出の精度を高め、計算時間を短縮するために、その構造を変更することを目指しています。これらには、2つの中程度のサイズのヨーバランスのデータセット-人気のあるジョイント-注釈付きの人間の動きのデータベース（j-hmdb-21）とのプライベートデータセットが含まれますカーネギーメロン大学が提供するレストランのビデオ映像-ベースのスタートアップ、agot。 ai</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Aggregative Self-Supervised Feature Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_8.html">
      <font color="black">Aggregative Self-Supervised Feature Learning</font>
    </a>
  </h2>
  <font color="black">空間コンテキスト集約SSLでは、2つのアドホックプロキシタスクを空間コンテキスト補完性と統合し、グローバルコンテキスト機能とローカルコンテキスト機能をそれぞれモデル化するヒューリスティックSSLメソッドを提供します。最後に、自己集約SSLでは、自己補完することを提案します。線形中心のカーネルアラインメントメトリックに基づく補助損失関数を備えた既存のプロキシタスク。これにより、手元のプロキシタスクから学習した機能によってカバーされていない場所の探索が明示的に促進され、モデリング機能がさらに強化されます。次に、原理的なフレームワークを提案します。さまざまなタスク間の機能の相補性を活用することを目的とした、統一された表現を形成するためのマルチタスクの集約的な自己監視学習。 
[ABSTRACT] salは、教師あり信号を定義するプロキシタスクです。sslで最も重要な部分は、学習の力を制御するプロキシタスクです。この点で、さまざまな形式の相補性の観点からグループ化する3つの戦略を提案します。自己監視学習機能の堅牢性</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-14">
        <br><font color="black">2020-12-14</font>
      </time>
    </span>
</section>
<!-- paper0: Representing Ambiguity in Registration Problems with Conditional
  Invertible Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_9.html">
      <font color="black">Representing Ambiguity in Registration Problems with Conditional
  Invertible Neural Networks</font>
    </a>
  </h2>
  <font color="black">この制限に取り組むために、登録方法論のコアコンポーネントとして可逆ニューラルネットワーク（INN）のアプリケーションを検討します。この作業の仮説は、提案されたアプローチがそのようなあいまいな登録問題の複数のソリューションを識別できるということです。最初の実現可能性調査では、脊椎CTボリュームをX線画像に登録することにより、2D3D登録設定のアプローチをテストします。 
[要約]提案されたフレームワークでは、旅館は、登録問題の可能な解決策を表すことにより、ネットワーク出力として点推定を超えることを可能にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: FlowMOT: 3D Multi-Object Tracking by Scene Flow Association -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_10.html">
      <font color="black">FlowMOT: 3D Multi-Object Tracking by Scene Flow Association</font>
    </a>
  </h2>
  <font color="black">さらに、フィルターベースの方法が失敗する可能性のあるさまざまな速度のシーンで着実に作業できます。次に、ハンガリーのアルゴリズムを使用してID伝播戦略との最適なマッチング関係を生成し、追跡タスクを完了します。これらの欠点を軽減するには、 FlowMOTという名前のLiDARベースの3DMOTフレームワークを提案します。これは、ポイントごとのモーション情報を従来のマッチングアルゴリズムに統合し、データ関連付けの堅牢性を強化します。 
[ABSTRACT]ハンガリーベースのシステムはより良い結果を達成できますが、最適なハイパーパラメータを提供することは困難です。代わりに、従来の方法では、完全に完全なハイパーパラメータを取得することは困難ですが、達成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-14">
        <br><font color="black">2020-12-14</font>
      </time>
    </span>
</section>
<!-- paper0: Dilated-Scale-Aware Attention ConvNet For Multi-Class Object Counting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_11.html">
      <font color="black">Dilated-Scale-Aware Attention ConvNet For Multi-Class Object Counting</font>
    </a>
  </h2>
  <font color="black">実際のシーンには複数のオブジェクトのカテゴリがあることに注意してください。この論文では、ポイントレベルの注釈に基づくシンプルで効率的なカウントネットワークを提案します。マルチクラスのオブジェクトカウントは、オブジェクトカウントタスクの適用範囲を拡大します。 
[概要]この論文では、ポイントレベルの注釈に基づくシンプルで効率的なカウントネットワークを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervised learning through the eyes of a child -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_12.html">
      <font color="black">Self-supervised learning through the eyes of a child</font>
    </a>
  </h2>
  <font color="black">この論文では、私たちの目標は、現代の自己教師あり深層学習手法と、3人の幼児の視点から記録された最近の縦断的で自己中心的なビデオデータセットを利用することによって、そのような進歩を正確に達成することです（Sullivan et al。、2020）。誕生すると、子供たちは自分の周りの世界について意味のある期待を抱きます。この基本的な質問に完全に一般的に取り組むことは現在実行不可能ですが、高レベルの視覚カテゴリの開発など、より狭く定義された領域で実際の進歩を遂げることを期待できます。データ収集技術の改善と深層学習の最近の進歩のおかげです。 
[概要]私たちの目標は、最新の自己教師あり深層学習手法と3人の幼児の視点から記録された最近のビデオデータセットを使用して進歩を達成することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-31">
        <br><font color="black">2020-07-31</font>
      </time>
    </span>
</section>
<!-- paper0: Improved Image Matting via Real-time User Clicks and Uncertainty
  Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_13.html">
      <font color="black">Improved Image Matting via Real-time User Clicks and Uncertainty
  Estimation</font>
    </a>
  </h2>
  <font color="black">計算バジェットに基づいて、ユーザーは不確実性ガイダンスで改善するローカルパーツの数を選択できます。この目的のために、このペーパーでは、トライマップがなく、あいまいさを排除するために数回のユーザークリック操作のみを必要とする改善されたディープイメージマットフレームワークを提案します。 ..実際、前景の選択は主観的な手順であり、ユーザーの意図によって異なります。 
[概要]ほとんどの既存のマット方法では、ユーザーが指定したトライマップを補助入力として使用して、優れたアルファマットを生成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: RGPNet: A Real-Time General Purpose Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_14.html">
      <font color="black">RGPNet: A Real-Time General Purpose Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">私たちの実験は、RGPNetが最先端の非リアルタイムの重いモデルに匹敵する精度でリアルタイムにセグメンテーション結果を生成できることを示しています。また、より深い層からより浅い層への勾配の流れを促進します。アダプターエンコーダーとデコーダーの間の分散表現の複数のレベルからの抽象的な概念を保存および改良するのに役立ちます。 
[ABSTRACT] rgpnetはデコーダーとアダプターで構成されています。 adapter.itは、より深い層からより浅い層への流れにも役立ちます。..rgpnetは、再生の別のシステムにも役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-03">
        <br><font color="black">2019-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Fast 3D Image Moments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_15.html">
      <font color="black">Fast 3D Image Moments</font>
    </a>
  </h2>
  <font color="black">3Dボリュームのいくつかの2D投影画像が生成されます。これらの2Dモーメントは、3Dボリュームモーメントを導出するために使用されます。アルゴリズムは、これらの2D画像から2Dモーメントのセットを計算します。 
[概要]このアプローチは、処理時間の短縮を実証しました。これは、3Dオブジェクトのモーメントの計算にも役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: SPOC learner's final grade prediction based on a novel sampling batch
  normalization embedded neural network method -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_16.html">
      <font color="black">SPOC learner's final grade prediction based on a novel sampling batch
  normalization embedded neural network method</font>
    </a>
  </h2>
  <font color="black">次に、バッチ正規化（BN）修正レイヤーを完全に接続されたニューラルネットワークに埋め込んで、データの不均衡な問題を解決します。他の3つの深層学習方法を使用した実験結果は、提案された方法の優位性を示しています。この問題を解決するために、サンプリングバッチ正規化埋め込み深層ニューラルネットワーク（SBNEDNN）法を本論文で開発した。 
[概要]スポックの学習者の最終学年は一般的に不均衡です。これらの焦点は予測モデルのトレーニングにあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Experimental design for MRI by greedy policy search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_17.html">
      <font color="black">Experimental design for MRI by greedy policy search</font>
    </a>
  </h2>
  <font color="black">非欲張り目的の勾配推定値の分散が大きいことに起因するこの現象の部分的な説明を提供し、この分散が非欲張りモデルのポリシーを個々のMR画像に適応させるのを妨げることを実験的に検証します。この適応性が重要であることを経験的に示します。サブサンプリング設計の改善に..予期せぬことに、私たちの実験は、目的の単純な欲張り近似が、より一般的な非欲張りアプローチとほぼ同等の解につながることを示しています。 
[要約]サブサンプリング設計を改善するために、これらのサブサンプリング戦略は主にヒューリスティックに依存しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-30">
        <br><font color="black">2020-10-30</font>
      </time>
    </span>
</section>
<!-- paper0: Hypothesis Disparity Regularized Mutual Information Maximization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_18.html">
      <font color="black">Hypothesis Disparity Regularized Mutual Information Maximization</font>
    </a>
  </h2>
  <font color="black">仮説伝達学習（HTL）と教師なしドメイン適応（UDA）を統合するための取り組みとして、ソースドメインからの知識が伝達される、教師なし仮説伝達に取り組むための仮説視差正則化相互情報最大化〜（HDMI）アプローチを提案します。仮説のみを介して、教師なしの方法でターゲットドメインに適応します。相互情報の最大化、HDMIを通じてラベルのないターゲットドメインに適応しながら、各仮説の制約のない最適化とは対照的に、異なる仮説間の重要な関係をより有効に活用します。ターゲット仮説を調整する仮説視差正則化を組み込んで、より適切なターゲット表現を共同で学習しながら、より適切に調整された予測の不確実性を備えたより転送可能なソース知識を維持します。HDMIは、HTLのコンテキストでUDAのベンチマークデータセットで最先端の適応パフォーマンスを実現します。 、アクセスする必要なし■適応中のソースデータ。 
[概要] divised zaraは、情報ベースのサイトをテストするシステムを開発しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_19.html">
      <font color="black">FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation</font>
    </a>
  </h2>
  <font color="black">その単純さのために、提案された方法は、現在の最も正確な方法と比較して384倍、8倍補間で現在の最速の方法と比較して23倍、推論速度を改善します。ただし、オプティカルフローに依存する方法は、オクルージョンと複雑な非線形のモデル化に失敗することがよくあります。ビデオから直接モーションを作成し、リアルタイム展開に適さない追加のボトルネックを導入します。アプローチの大部分は、ビデオの隣接フレーム間の双方向オプティカルフローを計算し、適切なワーピングアルゴリズムを実行して出力フレームを生成することにより、ビデオフレーム補間の問題を解決します。 
[ABSTRACT]メソッドはオプティカルフローに依存しているため、ビデオから直接オクルージョンや複雑な非線形モーションをモデル化できないことがよくあります。これらは、リアルタイム展開に適さない余分なボトルネックを作成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Seeing Behind Objects for 3D Multi-Object Tracking in RGB-D Sequences -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_20.html">
      <font color="black">Seeing Behind Objects for 3D Multi-Object Tracking in RGB-D Sequences</font>
    </a>
  </h2>
  <font color="black">RGB-Dフレームのシーケンスから、各フレーム内のオブジェクトを検出し、それらの完全なオブジェクトジオメトリと、正規空間への密な対応マッピングを予測する方法を学びます。合成および実世界のRGB-Dデータの両方での実験は、動的オブジェクト追跡で最先端のパフォーマンスを実現します。これにより、各フレーム内のオブジェクトの6DoFポーズと、フレーム間の対応を導き出し、RGB-Dシーケンス全体で堅牢なオブジェクト追跡を提供できます。 
[概要]オブジェクトの完成は追跡に大きく役立ち、平均モタで$ 6.5- $の改善を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Point-Level Temporal Action Localization: Bridging Fully-supervised
  Proposals to Weakly-supervised Losses -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_21.html">
      <font color="black">Point-Level Temporal Action Localization: Bridging Fully-supervised
  Proposals to Weakly-supervised Losses</font>
    </a>
  </h2>
  <font color="black">ポイントレベルの時間的アクションローカリゼーション（PTAL）は、アクションインスタンスごとに1つのタイムスタンプアノテーションのみを使用して、トリミングされていないビデオのアクションをローカライズすることを目的としています。THUMOS14、BEOID、およびGTEAでの実験により、提案された方法の有効性が定量的および定性的に検証され、私たちの方法は、最先端の方法よりも優れています。私たちの知る限り、これは、ポイントレベルの設定に完全に監視されたパラダイムを活用する最初の作業です。 
[ABSTRACT]既存の方法では、フレームレベルの予測ベイスンを採用して、まばらな単一フレームのラベルから学習します。このペーパーでは、ポイントレベルのアノテーションの提案ベースの予測ベイスンを調査します。ポイントレベルのアノテーションには、より制約のあるソリューションの利点があります。隣接するフレーム間のスペースと一貫した予測</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Face Hallucination Using Split-Attention in Split-Attention Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_22.html">
      <font color="black">Face Hallucination Using Split-Attention in Split-Attention Network</font>
    </a>
  </h2>
  <font color="black">次に、外部-内部分割注意グループは、顔の構造情報を安定させるためにマルチパス機能を微調整するための機能間相互作用を提供します。この論文では、内部チャネル機能と外部を融合する分割注意ネットワーク（SISN）の分割注意を提案します。顔の構造情報を探索するための（クロス）マルチパス機能..最近、注意メカニズムが、内部特徴マップの相関を探索するための畳み込みニューラルネットワーク（CNN）ベースの超解像度（SR）タスクに適用されました。 
[ABSTRACT]スプリットアテンションアテンションブロックは、顔のローカル詳細の忠実度を維持します。スプリットアテンションブロックは、顔のローカル情報を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-22">
        <br><font color="black">2020-10-22</font>
      </time>
    </span>
</section>
<!-- paper0: FMODetect: Robust Detection and Trajectory Estimation of Fast Moving
  Objects -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_23.html">
      <font color="black">FMODetect: Robust Detection and Trajectory Estimation of Fast Moving
  Objects</font>
    </a>
  </h2>
  <font color="black">デブラッティングなどの他の方法と比較して、推論は数桁高速であり、リアルタイムの高速移動オブジェクトの検出や大規模なビデオコレクションでの検索などのアプリケーションが可能です。提案された方法は、最初にすべての高速移動オブジェクトを切り捨てられたものとして検出します。軌道までの距離関数..続いて、検出された各オブジェクトのマットおよびフィッティングネットワークは、オブジェクトの軌道と背景のないぼやけた外観を推定します。 
[概要]たとえば、ブレ除去とブレ除去では、問題をマットとブレ除去に分割し、別々に解決します。この方法は、軌道推定とシャープな外観の再構築の点で優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Latent Implicit Conditional Optimization when Learning from
  Small Sample -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_24.html">
      <font color="black">Generative Latent Implicit Conditional Optimization when Learning from
  Small Sample</font>
    </a>
  </h2>
  <font color="black">実際、グリコは、クラスごとにわずか5〜10の例を使用して、すべてのクラスの完全に新しいサンプルを合成することを学習します。そのようなクラスは、事前に課すことなく、わずか10のクラスです。 CIFAR-10、CIFAR-100、およびCUB-200から取得した小さなサンプルでトレーニングした場合、最先端技術と比較して画像分類を改善します。次に、GLICOを使用して、分類器をトレーニングしながら小さなトレーニングセットを拡張します。小さなサンプル。 
[概要]グリコは、クラスごとに完全に新しいサンプルを合成することを学習します。提案された方法は、学習した潜在空間を潜在空間にサンプリングします。次に、トレーニングされたジェネレーターを使用して新しい例を生成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br><font color="black">2020-03-31</font>
      </time>
    </span>
</section>
<!-- paper0: Robots Understanding Contextual Information in Human-Centered
  Environments using Weakly Supervised Mask Data Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_25.html">
      <font color="black">Robots Understanding Contextual Information in Human-Centered
  Environments using Weakly Supervised Mask Data Distillation</font>
    </a>
  </h2>
  <font color="black">私たちが提案するアーキテクチャは、コストの制約を満たす前景ピクセルが最も少ないPSLを自動的に検索する新しいマスクリファインメントシステムを使用します。ただし、これらの方法では、取得に時間がかかり、時間がかかる大量の人間がラベル付けしたデータが必要です。比較Naive、GrabCut、およびPyramidメソッドを使用すると、ラベルとセグメンテーションの品質が大幅に向上することがわかりました。 
[ABSTRACT] wesupermaddは、学習した画像機能を使用してpslsを具体的に生成します。これらには、人間中心の環境でのロボットナビゲーションタスクで一般的なものが含まれます。これにより、手作りのヒューリスティックルールが不要になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: FAWA: Fast Adversarial Watermark Attack on Optical Character Recognition
  (OCR) Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_26.html">
      <font color="black">FAWA: Fast Adversarial Watermark Attack on Optical Character Recognition
  (OCR) Systems</font>
    </a>
  </h2>
  <font color="black">ほとんどの既存の敵対的攻撃によって生成される敵対的例は不自然であり、背景をひどく汚染します。摂動を透かしとして偽装することにより、結果として生じる敵対的画像を人間の目に自然に見せ、完全な攻撃成功率を達成できます。この問題に対処するには、ホワイトボックス方式でシーケンスベースのOCRモデルに対する高速敵対的透かし攻撃（FAWA）を提案します。 
[概要]自然な外観に加えて、ファワは平均で60％少ない摂動と78％少ない反復で100％の攻撃成功率を達成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Cluster, Split, Fuse, and Update: Meta-Learning for Open Compound Domain
  Adaptive Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_27.html">
      <font color="black">Cluster, Split, Fuse, and Update: Meta-Learning for Open Compound Domain
  Adaptive Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">その後、メタラーナーをデプロイして、スタイルコードを条件として、サブターゲットドメイン固有の予測を融合する方法を学習します。次に、さまざまなサブターゲットドメインを独立したブランチに分割し、バッチ正規化パラメーターを学習して、それらを独立して処理します。 ..最初に、監視されていない方法で抽出された画像スタイルによって、ターゲットドメインを複数のサブターゲットドメインにクラスター化します。 
[概要]この作業では、セマンティックセグメンテーションのためのocdaへの原理的なメタ学習ベースのアプローチmocdaを提案します。これは、メタ学習者がサブドメイン固有の予測を融合するために展開され、スタイルに基づいているという事実に基づいています。 code.weは、合成から実際の知識への伝達ベンチマークデータセットに関する広範な実験によって、アプローチの利点を検証します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Noise as a Resource for Learning in Knowledge Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_28.html">
      <font color="black">Noise as a Resource for Learning in Knowledge Distillation</font>
    </a>
  </h2>
  <font color="black">そうすることで、ディープニューラルネットワークの一般的な課題を対象とする3つの異なる方法を提案します。コンパクトモデルとラージモデル間のパフォーマンスギャップの最小化（Fickle Teacher）、高性能コンパクトな敵対的にロバストなモデルのトレーニング（Soft Randomization）、およびトレーニングモデルです。ラベルノイズの下で効率的に（乱雑なコラボレーション）。ノイズはコンピューティングシステムでは一般に迷惑と見なされますが、神経科学の多くの研究では、脳が確率的推論などの計算を実行できるようにすることで、神経系のノイズのいくつかの利点が示されています。刺激に関する追加情報を運ぶだけでなく、協調学習フレームワークのさまざまなレベルで建設的なノイズを注入することで、モデルを効果的にトレーニングし、学生モデルの望ましい特性を抽出できることを経験的に示しています。 
[ABSTRACT]ノイズはディープニューラルネットワークのパフォーマンスを向上させることが示されています。協調学習フレームワークのさまざまなレベルで建設的なノイズを注入することで、モデルを効果的にトレーニングし、学生モデルで結果を抽出できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-11">
        <br><font color="black">2019-10-11</font>
      </time>
    </span>
</section>
<!-- paper0: Remote Sensing Image Scene Classification with Deep Neural Networks in
  JPEG 2000 Compressed Domain -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_29.html">
      <font color="black">Remote Sensing Image Scene Classification with Deep Neural Networks in
  JPEG 2000 Compressed Domain</font>
    </a>
  </h2>
  <font color="black">次に、一連の畳み込み層が、近似ウェーブレットサブバンドの高レベルのセマンティックコンテンツをモデル化します。したがって、提案されたアプローチは、エンドツーエンドのトレーニング可能な統合ニューラルネットワークでJPEG2000圧縮アルゴリズムで与えられた多重解像度パラダイムをモデル化します。 ..これは、最も粗い解像度のウェーブレットサブバンドに関連付けられたコードストリームを入力として取得し、いくつかの転置された畳み込み層を使用して、より細かい解像度のサブバンドを近似することによって実現されます。 
[ABSTRACT]ディープニューラルネットワークを使用する既存のシーン分類アプローチでは、画像を完全に解凍する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-20">
        <br><font color="black">2020-06-20</font>
      </time>
    </span>
</section>
<!-- paper0: Frozen-to-Paraffin: Categorization of Histological Frozen Sections by
  the Aid of Paraffin Sections and Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_30.html">
      <font color="black">Frozen-to-Paraffin: Categorization of Histological Frozen Sections by
  the Aid of Paraffin Sections and Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">最後に、少量のトレーニングデータを処理し、分類の精度をさらに高めるための特定のデータ拡張戦略を提案します。さらに、凍結からパラフィンへの変換が分類スコアの最適化に役立つかどうかを調査しました。パラフィン切片と比較して、凍結切片の品質は通常低く、誤分類の割合が高くなります。 
[要約]これにより、外科医は介入中に組織学的所見を待って、組織学的結果に基づいて術中を行うことができました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Deep N-ary Error Correcting Output Codes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_31.html">
      <font color="black">Deep N-ary Error Correcting Output Codes</font>
    </a>
  </h2>
  <font color="black">ディープラーニングベースの学習者によるN-aryECOCのトレーニングを容易にするために、ディープN-ary ECOCのパラメーター共有アーキテクチャの3つの異なるバリアントをさらに提案します。ディープデータに依存しないアンサンブル手法。具体的には、従来のECOCとその一般的な拡張N-ary ECOCは、元のマルチクラス分類問題を一連の独立したより単純な分類サブ問題に分解します。 
[ABSTRACT] deep n-ary ecocは単純ではありませんが、基礎学習者のトレーニングに高い費用がかかるため、文献で十分に活用されています。画像とテキストの両方の分類タスクについて、さまざまなディープニューラルネットワークアーキテクチャでバックボーンを変更して実験を行います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Objective, Probabilistic, and Generalized Noise Level Dependent
  Classifications of sets of more or less 2D Periodic Images into Plane
  Symmetry Groups -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_32.html">
      <font color="black">Objective, Probabilistic, and Generalized Noise Level Dependent
  Classifications of sets of more or less 2D Periodic Images into Plane
  Symmetry Groups</font>
    </a>
  </h2>
  <font color="black">金谷健一の幾何学的赤池情報量基準と関連する幾何学的赤池重みによって可能になる平面対称群分類への新しいアプローチを示します。後者の機能は、ノイズの少ない画像データとより正確な処理アルゴリズムが利用可能になったときに結晶対称分類を更新できることを意味します。さらに、コンピュータビジョンコミュニティは、より強力で計算効率の高いフーリエ空間法ではなく、直接空間法を使用してそのような分類を行う傾向があります。 
[概要]これらの分類は通常、判断のために任意のしきい値に依存する主観的な方法で両方のコミュニティによって行われます。これは、これらの方法が適切に機能するには、によって分析された画像に一般的に存在するよりも多くの周期的なユニットセルモチーフの繰り返しが必要なためです。コンピュータビジョンコミュニティ。私たちのアプローチは、逆格子空間で作業することの利点を活用し、結晶学的対称性の階層的性質を処理するのに非常に適しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Phase Retrieval with Holography and Untrained Priors: Tackling the
  Challenges of Low-Photon Nanoscale Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_33.html">
      <font color="black">Phase Retrieval with Holography and Untrained Priors: Tackling the
  Challenges of Low-Photon Nanoscale Imaging</font>
    </a>
  </h2>
  <font color="black">ホログラフィックCDIは、ウイルス、タンパク質、結晶などのイメージング標本が低光子測定を必要とするナノスケールで重要になります。この作業では、これらの課題に適応したホログラフィック位相回復のためのデータセットフリーの深層学習フレームワークを紹介します。 
[ABSTRACT]ホログラフィは、対象の標本に隣接して配置された参照オブジェクトを含みます。このデータは、ポアソンショットノイズによって非常に破損し、多くの場合、共振がありません。新しい方法に加えて、新しい方法を導入する必要があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-14">
        <br><font color="black">2020-12-14</font>
      </time>
    </span>
</section>
<!-- paper0: Blur Invariant Kernel-Adaptive Network for Single Image Blind deblurring -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_34.html">
      <font color="black">Blur Invariant Kernel-Adaptive Network for Single Image Blind deblurring</font>
    </a>
  </h2>
  <font color="black">カーネルを効率的に使用するために、ぼけた画像とぼけたカーネルの両方からの特徴を低次元空間にエンコードし、それらを同時にデコードして適切に合成された特徴表現を取得するカーネル適応AEブロックを提案します。続いて、ぼけ除去ネットワークを提案します。推定されたブラーカーネルを使用して鮮明な画像を復元します。さまざまなガウスブラーカーネルを使用して、REDS、GOPRO、およびFlickr2Kデータセットでモデルを評価します。 
[ABSTRACT]私たちのモデルは、2つの連続するタスクに分割することにより、ブレ除去の問題を解決します。カーネルを提案します-ぼやけた画像とぼやけたカーネルの両方からの特徴を低レベル空間にエンコードする適応型aeブロック</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Domain Adaptation from Synthetic to Real Images for
  Anchorless Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_35.html">
      <font color="black">Unsupervised Domain Adaptation from Synthetic to Real Images for
  Anchorless Object Detection</font>
    </a>
  </h2>
  <font color="black">コードは次の場所にあります：https：//github.com/scheckmedia/centernet-uda ..アンカーレス検出器のアーキテクチャを利用して、2つのUDAメソッド、つまり、エントロピー最小化と最大二乗損失を調整することを提案します。セグメンテーションからオブジェクト検出まで..私たちの仕事では、合成画像を含むドメイン適応問題に、最新のアンカーレスアーキテクチャの1つであるCenterNetを使用します。 
[ABSTRACT]アンカーレス検出器は、物体検出の分野でますます注目を集めています。それらの結果は、提案された方法がマップネットを69％に増やすことができることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: A Comprehensive Study of Class Incremental Learning Algorithms for
  Visual Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_36.html">
      <font color="black">A Comprehensive Study of Class Incremental Learning Algorithms for
  Visual Tasks</font>
    </a>
  </h2>
  <font color="black">最初のタイプのアルゴリズムは徹底的に比較されましたが、これは固定サイズモデルを利用する方法には当てはまりません。ここでは、後者に焦点を当て、それらを共通の概念的および実験的フレームワークに配置し、次の貢献を提案します。 ）インクリメンタル学習アルゴリズムの6つの望ましいプロパティを定義し、これらのプロパティに従って分析します。（2）クラスインクリメンタル学習問題の統一された形式化を導入します。（3）既存の評価フレームワークよりも徹底的な共通の評価フレームワークを提案します。データセットの数、データセットのサイズ、制限されたメモリのサイズ、および増分状態の数、（4）過去の模範選択のための群集の有用性の調査、（5）知識を使用せずに競争力のあるパフォーマンスを得ることが可能であるという実験的証拠を提供する壊滅的な忘却に取り組むための蒸留、および（6）テストされたすべてのメソッドを共通のオープンソースリポジトリに統合することにより、再現性を促進します。新しいデータに直面したときに能力を向上させる人工知能の能力は、人工知能における未解決の課題です。 
[概要]このような場合に直面する主な課題は、壊滅的な忘却です。これには、新しいデータが取り込まれたときに過去のデータをアンダーフィットするニューラルネットワークの傾向が含まれます。2番目のタイプのアプローチは、深いモデルサイズを修正し、その目的が確実にすることであるメカニズムを導入します。モデルの安定性と可塑性の間の適切な妥協点</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Enhance Multimodal Transformer With External Label And In-Domain
  Pretrain: Hateful Meme Challenge Winning Solution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_37.html">
      <font color="black">Enhance Multimodal Transformer With External Label And In-Domain
  Pretrain: Hateful Meme Challenge Winning Solution</font>
    </a>
  </h2>
  <font color="black">嫌いなミーム検出は、最近発表された新しい研究分野であり、ミームの視覚的、言語的理解と、タスクを適切に実行するための背景知識の両方が必要です。この技術レポートは、Hateful Meme Detection Challenge2020の最初の解決策をまとめたものです。この問題に取り組むために最先端の視覚言語変換器を拡張します。レポートの最後に、現在の方法論を改善するための欠点と考えられる方向性も指摘します。 
[概要]嫌なミーム検出チャレンジ2020は、この問題に取り組むことを目的としています。問題に取り組むための可能な方向の状態を拡張します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring Vicinal Risk Minimization for Lightweight Out-of-Distribution
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_38.html">
      <font color="black">Exploring Vicinal Risk Minimization for Lightweight Out-of-Distribution
  Detection</font>
    </a>
  </h2>
  <font color="black">私たちの検出方法は、OoDサンプルを分類するための補助クラスを導入します。これにより、エッジデバイスでのOoD検出の展開が容易になり、OoD検出器のトレーニングで使用するためのVicinal RiskMinimizationの理解が広がります。既存のOoD検出器にはかなりのメモリと計算があります。オーバーヘッドがあるため、VRMを活用して、耳に聞こえないOoD検出器を開発します。 
[概要]このペーパーでは、ビシナルリスク最小化のプロパティがより優れたフード検出器のトレーニングに役立つかどうかを調査します。既存のフード検出器にはかなりのメモリと計算オーバーヘッドがあるため、vrmを活用して最小限の耳に聞こえるフード検出器を開発します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Human Pose Estimation by Learning Deeply Aggregated
  Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_39.html">
      <font color="black">Efficient Human Pose Estimation by Learning Deeply Aggregated
  Representations</font>
    </a>
  </h2>
  <font color="black">これにより、最終的な融合表現で効果的な情報を最大化できます。ほとんどの既存のモデルは、主に異なる空間サイズの特徴からマルチスケール情報を探索します。具体的には、直交注意ブロック（OAB）と2次融合ユニット（SFU）を提案します。 。 
[概要]単一のピラミッドネットワークは、さらに豊富なマルチスケール情報を含む深く集約された表現を生成できる可能性があります。oabとsfuの助けを借りて、単一のピラミッドネットワークは深く集約された表現を生成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-13">
        <br><font color="black">2020-12-13</font>
      </time>
    </span>
</section>
<!-- paper0: Semantic-Guided Representation Enhancement for Self-supervised Monocular
  Trained Depth Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_40.html">
      <font color="black">Semantic-Guided Representation Enhancement for Self-supervised Monocular
  Trained Depth Estimation</font>
    </a>
  </h2>
  <font color="black">このフレームワークに基づいて、セマンティックエッジにあるポイントベースの特徴をサンプリングし、個々のセマンティックガイドエッジ強調モジュール（SEEM）にフィードすることで、ローカル特徴表現を強化します。SEEMは、チャレンジングで深度推定を促進するために特別に設計されています。セマンティックボーダー..広範な実験により、セマンティックカテゴリボーダーや薄いオブジェクトなどの困難な画像領域で非常に正確な深度をキャプチャする方法の明確な優位性が検証されます。この論文では、セマンティックガイドによる深度表現の強調を提案することでこの問題に対処します。豊富なコンテキスト情報を活用することにより、ローカルとグローバルの両方の深度特徴表現を促進する方法。 
[概要]これは、深度表現能力が限られているためです。ただし、通常、境界領域や薄い構造のオブジェクトに表示すると低下します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Canny-VO: Visual Odometry with RGB-D Cameras based on Geometric 3D-2D
  Edge Alignment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_41.html">
      <font color="black">Canny-VO: Visual Odometry with RGB-D Cameras based on Geometric 3D-2D
  Edge Alignment</font>
    </a>
  </h2>
  <font color="black">これにより、データからモデルへの登録、双一次内挿、劣勾配計算など、より計算量の多いパラダイムが不要になります。エッジ登録で一般的に使用される距離変換の2つの代替案として、近似最近傍フィールドと方向付け最近傍フィールドが提案されます。 。公開SLAMベンチマークシーケンスの広範な評価は、最先端のパフォーマンスと、古典的なユークリッド距離フィールドに対する利点を示しています。 
[ABSTRACT]距離変換の2つの置換が提案されています。これにより、モデル登録、双一次内挿、劣勾配計算など、より計算量の多いデータの解釈が不要になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Modal Deep Clustering: Unsupervised Partitioning of Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_42.html">
      <font color="black">Multi-Modal Deep Clustering: Unsupervised Partitioning of Images</font>
    </a>
  </h2>
  <font color="black">マルチモーダルディープクラスタリング（MMDC）は、画像の埋め込みをガウス混合モデル分布からサンプリングされたターゲットポイントに合わせるように、ディープネットワークをトレーニングします。実験結果は、MMDCが6つの挑戦的なベンチマークで最先端のパフォーマンスを達成または上回ることを示しています。 ..クラスターの割り当ては、画像埋め込みの混合コンポーネントの関連付けによって決定されます。 
[ABSTRACT]教師なしシステムによって開発された教師なしクラスタリングフレームワーク。追加の処理なしで画像の直接クラスター割り当てを提供します。これにより、ネットワークはより意味のあるタスクを学習するようになります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-05">
        <br><font color="black">2019-12-05</font>
      </time>
    </span>
</section>
<!-- paper0: Geometry Enhancements from Visual Content: Going Beyond Ground Truth -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_43.html">
      <font color="black">Geometry Enhancements from Visual Content: Going Beyond Ground Truth</font>
    </a>
  </h2>
  <font color="black">この作品は、画像から高周波パターンを抽出し、それらを幾何学的特徴として再挿入する新しい循環アーキテクチャを提示します。この手順により、一方では細部をキャプチャし、忠実である低コストの深度センサーの解像度を向上させることができます。スキャンされたグラウンドトゥルース。深さの超解像度タスクと、視覚的に魅力的で強化された生成3Dモデルの最新の結果を示します。 
[概要]これにより、低コストの深度センサーの解像度を向上させることができます。これにより、詳細をキャプチャし、スキャンされたグラウンドトゥルースに忠実になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Online Class-Incremental Continual Learning with Adversarial Shapley
  Value -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_44.html">
      <font color="black">Online Class-Incremental Continual Learning with Adversarial Shapley
  Value</font>
    </a>
  </h2>
  <font color="black">全体として、提案されたASERメソッドは、さまざまなデータセットでの最先端のリプレイベースの継続的な学習メソッドと比較して、競争力のある、または改善されたパフォーマンスを提供することがわかります。このペーパーでは、特にオンラインクラスインクリメンタル設定に焦点を当てます。モデルがオンラインデータストリームから継続的に新しいクラスを学習する必要がある場合。この目的のために、以前に観察されたクラスの潜在的な決定境界を保持する能力に従ってメモリデータサンプルをスコアリングする新しいAdversarial Shapley値スコアリング方法を提供します（維持するため）学習中の現在のクラスの潜在的な決定境界を妨害しながら（新しいクラス境界の可塑性と最適な学習を促進するために）、安定性を学習し、忘れないようにします。 
[要約]再生するバッファリングされた画像を選択するための最良の方法は、まだ未解決の質問です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-31">
        <br><font color="black">2020-08-31</font>
      </time>
    </span>
</section>
<!-- paper0: SSD-GAN: Measuring the Realness in the Spatial and Spectral Domains -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_45.html">
      <font color="black">SSD-GAN: Measuring the Realness in the Spatial and Spectral Domains</font>
    </a>
  </h2>
  <font color="black">提案された方法は一般的であり、過度のコストをかけずにほとんどの既存のGANフレームワークに簡単に統合できます。強化されたディスクリミネーターにより、SSD-GANのジェネレーターは、実際のデータの高周波コンテンツを学習し、正確な詳細を生成することが推奨されます。標準GANの弁別器に高周波が欠落しているという問題があることを観察し、ネットワークアーキテクチャで採用されているダウンサンプリング層に起因することを明らかにしました。 
[概要] ssd-ganのジェネレーターは、実際のデータの高周波コンテンツを学習し、正確な詳細を生成することをお勧めします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Capsule Attention for Multimodal EEG and EOG Spatiotemporal
  Representation Learning with Application to Driver Vigilance Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_46.html">
      <font color="black">Capsule Attention for Multimodal EEG and EOG Spatiotemporal
  Representation Learning with Application to Driver Vigilance Estimation</font>
    </a>
  </h2>
  <font color="black">ドライバーの警戒の推定は、輸送の安全性にとって重要なタスクです。学習した表現の識別能力をよりよく調査するために、動的ルーティングの反復回数やその他のパラメーターを含む、提案されたカプセル注意メカニズムの効果を研究します。学習したマルチモーダル表現の最も顕著な部分に焦点を当てるシステムでは、深い長期短期記憶（LSTM）ネットワークに続くカプセル注意メカニズムで構成されるアーキテクチャを提案します。 
[概要]システムは、深く長い短期記憶ネットワークに続くカプセル注意メカニズムで構成されるアーキテクチャを提案します。学習された表現の識別能力をよりよく調査するために、提案されたカプセル注意システムの効果を調べます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-17">
        <br><font color="black">2019-12-17</font>
      </time>
    </span>
</section>
<!-- paper0: Research on All-content Text Recognition Method for Financial Ticket
  Image -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_47.html">
      <font color="black">Research on All-content Text Recognition Method for Financial Ticket
  Image</font>
    </a>
  </h2>
  <font color="black">実験結果によると、この方法の平均認識精度は、文字シーケンスで91.75 \％、チケット全体で87 \％です。漢字認識の特性によると、このフレームワークには2段階の情報抽出方法が含まれています。漢字認識の速度を向上させることができます。さらに、金融チケット文字認識フレームワーク（FTCRF）を提案します。 
[概要]従来の手動請求書償還および財務会計システムは、財務会計士により多くの負担をもたらします。この方法は、認識精度とリコール率が高く、財務テキスト検出の実際の要件を満たすことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Domain Grouping and Alignment for Domain Adaptive Semantic
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_48.html">
      <font color="black">Cross-Domain Grouping and Alignment for Domain Adaptive Semantic
  Segmentation</font>
    </a>
  </h2>
  <font color="black">ソースドメインでの正確なセグメンテーション機能を忘れずにドメインアラインメントを最大化することを目的として、ドメイン間でサンプルをクラスター化するために、特にクラスター間のセマンティックの一貫性と直交性を促進するための2つの損失関数を示します。以前の方法の他の制限であるクラスの不均衡の問題を解決するために..ディープコンボリューションニューラルネットワーク（CNN）内のソースドメインとターゲットドメイン全体でセマンティックセグメンテーションネットワークを適応させる既存の手法は、の2つのドメインからのすべてのサンプルを処理します。グローバルまたはカテゴリを意識した方法。 
[ABSTRACT]私たちの方法は一貫して適応パフォーマンスを向上させ、さまざまなドメイン適応設定で最先端のパフォーマンスを上回ります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Weakly Supervised Learning with Region and Box-level Annotations for
  Salient Instance Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_49.html">
      <font color="black">Weakly Supervised Learning with Region and Box-level Annotations for
  Salient Instance Segmentation</font>
    </a>
  </h2>
  <font color="black">正確なピクセルレベルの位置については、各顕著なインスタンスのコンテキスト機能を画像内のグローバルコンテキストに拡張するグローバル機能リファインレイヤーが導入されています。顕著なインスタンスのセグメンテーションは、顕著性検出領域で広く注目された新しい挑戦的なタスクです。実験結果は、弱く監視された注釈によってトレーニングされた提案されたエンドツーエンドネットワークが、既存の完全に監視された顕著なインスタンスセグメンテーション方法と競合する可能性があることを示しています。 
[概要]循環グローバルコンテキスト顕著なインスタンスセグメンテーションネットワーク（cgcnet）を提示します。これは、既存の顕著性検出データセットからのバイナリ顕著な領域と境界ボックスの組み合わせによって監視されます。ラベリング更新スキームは、提案されたフレームワークに組み込まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Effect of the regularization hyperparameter on deep learning-based
  segmentation in LGE-MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_50.html">
      <font color="black">Effect of the regularization hyperparameter on deep learning-based
  segmentation in LGE-MRI</font>
    </a>
  </h2>
  <font color="black">この作業では、著者は、L2正則化ハイパーパラメーターの任意の選択がLGE-MRIでの深層学習ベースのセグメンテーションの結果にどの程度影響するかを示すことを目的としています。また、著者は他の手動調整または調整を採用しています。深層学習ハイパーパラメータ。90％の検証精度を達成する前にすべてのエポックの10％に達した場合にのみ実行されます。ここでは、任意のL2正則化値を使用して、さまざまな深層学習ベースのセグメンテーションネットワークを作成します。 
[概要]これらは、さまざまな深層学習ベースのセグメンテーションネットワークを作成するために使用できます。これらは、l2正則化の長さに対する高血圧の例です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: GTA: Global Temporal Attention for Video Action Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_51.html">
      <font color="black">GTA: Global Temporal Attention for Video Action Understanding</font>
    </a>
  </h2>
  <font color="black">インスタンス固有の注意マトリックスを計算する従来の自己注意とは異なり、GTAは、安定した時間構造を学習してさまざまなサンプル間で一般化することを目的としたグローバル注意マトリックスをランダムに初期化します。より良い時間的モデリングのために機能の相互作用を活用します。グローバル時間的注意（GTA）を導入します。これは、分離された方法で空間的注意に加えてグローバルな時間的注意を実行します。 
[概要]この論文では、自己についてのより深い理解を求めます-ビデオの視覚的モデリングに対する注意。空間的注意の上にグローバルな空間的注意を分離して実行するグローバル時間的注意（gta）を紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: FCFR-Net: Feature Fusion based Coarse-to-Fine Residual Learning for
  Monocular Depth Completion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_52.html">
      <font color="black">FCFR-Net: Feature Fusion based Coarse-to-Fine Residual Learning for
  Monocular Depth Completion</font>
    </a>
  </h2>
  <font color="black">まず、単純なCNNフレームワークによって粗密深度マップを取得します。特に、粗い段階から細かい段階では、チャネルシャッフル抽出操作を使用して、カラー画像と粗い深度マップ、およびエネルギーからより代表的な特徴を抽出します。ベースの融合操作は、チャネルシャッフル操作によって取得されたこれらの機能を効果的に融合するために利用され、より正確で洗練された深度マップにつながります。深度補完は、対応するカラー画像を入力として、疎深度マップから高密度深度マップを復元することを目的としています。 
[ABSTRACT]最近のアプローチは、主に深さの完了を1段階のエンドツーエンドの役に立たないタスクとして定式化し、密な深度マップに直接アプローチします。この問題に対処するために、新しいエンドツーエンドの残差学習フレームワークを提案します。このタイプの学習タスクの結果としてのプロセス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: HeadGAN: Video-and-Audio-Driven Talking Head Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_53.html">
      <font color="black">HeadGAN: Video-and-Audio-Driven Talking Head Synthesis</font>
    </a>
  </h2>
  <font color="black">単一の参照画像を使用して話す頭の合成の問題を解決する最近の試みは、有望な結果を示しています。ジェネレータへの補完的な入力としてオーディオ機能を利用することにより、口の動きの妥当性を改善します。新しい再現アプローチであるHeadGANを提案します。これは、3D顔表現の合成を条件付けます。これは、任意の運転ビデオから抽出して、任意のソースの顔の形状に適合させることができます。 
[概要]ジェネレーターへの補完的な入力としてオーディオ機能を利用することにより、口の動きの妥当性を改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Decoupled Self Attention for Accurate One Stage Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_54.html">
      <font color="black">Decoupled Self Attention for Accurate One Stage Object Detection</font>
    </a>
  </h2>
  <font color="black">FPNとサブタスクのヘッドネットワークの間に位置するため、さまざまなタスクのFPN融合特徴に基づいてグローバル特徴を個別に抽出するために使用されます。オブジェクト検出データセットの規模は画像認識データセットImageNetの規模よりも小さいため、転送学習にはディープラーニングオブジェクト検出モデルの基本的なトレーニング方法になります。これにより、ImageNetデータセットでオブジェクト検出モデルのバックボーンネットワークを事前トレーニングして、分類およびローカリゼーションサブタスクの特徴を抽出します。実験結果はDSAモジュールの有効性を示しています。 
[概要]分類タスクはオブジェクトの顕著な領域の特徴に焦点を合わせます。一方、位置特定タスクはローカリゼーションタスクに使用される特徴に焦点を合わせます。オブジェクト検出のパフォーマンスを効果的に向上させることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-14">
        <br><font color="black">2020-12-14</font>
      </time>
    </span>
</section>
<!-- paper0: Panoptic Image Annotation with a Collaborative Assistant -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_55.html">
      <font color="black">Panoptic Image Annotation with a Collaborative Assistant</font>
    </a>
  </h2>
  <font color="black">アシスタントは、画像の他の部分に独自に注釈を付けることでこの信号にインテリジェントに反応し、アノテーターが必要とする作業量を削減します。シミュレーションと人間のアノテーターの両方で、COCOパノラマデータセットに対して徹底的な実験を行います。アクションアノテーターによって実行されることは、強力なコンテキストシグナルとして機能します。 
[概要]アノテーターは、事前定義されたセグメントのプールを使用して画像に注釈を付けることができます。アシスタントは、画像の他の部分に独自に注釈を付けることでこの信号にインテリジェントに反応し、アノテーターが必要とする作業量を削減します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-17">
        <br><font color="black">2019-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: mDALU: Multi-Source Domain Adaptation and Label Unification with Partial
  Datasets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_56.html">
      <font color="black">mDALU: Multi-Source Domain Adaptation and Label Unification with Partial
  Datasets</font>
    </a>
  </h2>
  <font color="black">画像分類、2Dセマンティック画像セグメンテーション、およびジョイント2D-3Dセマンティックセグメンテーションの3つの異なるタスクでメソッドを検証します。このペーパーでは、このタスクをマルチソースドメイン適応およびラベル統合（mDALU）問題として扱い、新しいメソッドを提案します。前者では、部分的な知識が複数のソースドメインからターゲットドメインに転送され、そこで融合されます。 
[概要]課題は、さまざまなタイプの新しいデータモダリティに対するものです。さらに、既存のメソッドを新しいドメインに一般化するために使用する必要があります。このタスクは、マルチソースドメインの適応とラベルの統合です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: docExtractor: An off-the-shelf historical document element extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_57.html">
      <font color="black">docExtractor: An off-the-shelf historical document element extraction</font>
    </a>
  </h2>
  <font color="black">さらに、歴史的文書のイラストセグメンテーションの微調整専用のIlluHisDocと呼ばれる新しい公開データセットを紹介します。特定のデータセットを微調整せずに得られたパフォーマンスは、アプリケーション、特にデジタルヒューマニティーズにとって重要であると主張します。私たちが取り組む行レベルのページセグメンテーションは、汎用要素抽出エンジンに最も関連性があります。豊富な合成ドキュメントの高速ジェネレーターに依存し、完全に畳み込みのネットワークを設計します。これは、検出ベースのアプローチよりも一般化することを示しています。 。 
[概要]さまざまなデータセットにわたって、既成のシステムとして高品質のパフォーマンスを提供することを実証しました。豊富な合成ドキュメントの高速ジェネレーターに依存し、完全なコンセットを設計します。これは、検出よりも一般化することを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Geometric Surface Image Prediction for Image Recognition Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_58.html">
      <font color="black">Geometric Surface Image Prediction for Image Recognition Enhancement</font>
    </a>
  </h2>
  <font color="black">表面画像はカラー画像から予測されます。そのために、幾何学的表面画像とそのカラー写真は、最初にGenerative Adversarial Networks（GAN）モデルでトレーニングされます。お守り認識のケーススタディの評価は、予測された幾何学的表面画像は、さまざまな照明条件下での対応するカラー画像よりも曖昧さが少なく、画像認識タスクを支援するために効果的に使用できます。 
[ABSTRACT]条件は、モデルまたは精巧なモデルをトレーニングするために必要です。オブジェクトを認識するためには、異なるタスクからのいくつかの画像が必要です。次に、トレーニングされたジェネレータモデルを使用して、幾何学的表面画像を予測します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Teach me to segment with mixed supervision: Confident students become
  masters -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_59.html">
      <font color="black">Teach me to segment with mixed supervision: Confident students become
  masters</font>
    </a>
  </h2>
  <font color="black">ディープセグメンテーションニューラルネットワークは、ピクセル単位のセグメンテーションを備えた大規模なトレーニングデータセットを必要としますが、実際に取得するにはコストがかかります。さらに興味深いことに、分類における最近の観察と一致して、監視を減らしてトレーニングされたブランチが教師よりも大幅に優れていることを示します。ラベル付けされたピクセルの標準的なクロスエントロピーと組み合わせて、私たちの新しい定式化は2つの重要な用語を統合します。（i）監視されていない画像に対して定義されたシャノンエントロピー損失。これにより、下部ブランチでの自信のある学生の予測が促進されます。 （ii）Kullback-Leibler（KL）ダイバージェンス。これは、強力に監視されたブランチによって生成された予測から監視されていないブランチに知識を転送し、エントロピー（学生の信頼）項をガイドして自明な解決策を回避します。 
[要約]詳細な監視により、この問題を軽減できます。データのごく一部に完全な同義の注釈が含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: NUTA: Non-uniform Temporal Aggregation for Action Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_60.html">
      <font color="black">NUTA: Non-uniform Temporal Aggregation for Action Recognition</font>
    </a>
  </h2>
  <font color="black">私たちのモデルは、広く使用されている4つの大規模な行動認識データセット（Kinetics400、Kinetics700、Something-something V2、Charades）で最先端のパフォーマンスを実現しています。不均一時間集約（NUTA）と呼ばれる方法を提案します。 ）、有益な時間セグメントからのみ機能を集約します。また、NUTA機能を従来の均一にサンプリングされたビデオ機能と時間的に位置合わせできる同期方法を導入し、ローカル機能とクリップレベル機能の両方を組み合わせることができます。 
[概要]提案されたnutaメソッドは、入力クリップからのデータに基づいています。このメソッドは、ビデオの4つの異なる部分を測定することを目的としています。また、提案されたメソッドがビデオクリップの最も関連性の高い部分を選択する方法を示す視覚化も含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: NeuralQAAD: An Efficient Differentiable Framework for High Resolution
  Point Cloud Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_61.html">
      <font color="black">NeuralQAAD: An Efficient Differentiable Framework for High Resolution
  Point Cloud Compression</font>
    </a>
  </h2>
  <font color="black">高解像度の点群でEMDを評価するのは難しいため、EMDのスケーラブルで高速でありながら信頼性の高い上限として、kdツリー（EM-kD）に基づく分割統治アプローチを提案します。QAPを解決します。勾配降下法と並行して..Skullsは、NeuralQAADの実装とともに公開する、頭蓋骨CTスキャンの新しいデータセットです。 
[概要]私たちのアーキテクチャは、以前の作業よりもはるかに効率的にパラメータを使用します。2次割り当てポイントに基づく新しいトレーニング手順とアーキテクチャを組み合わせます。この手順は代理損失として機能し、より表現力豊かな土工距離（emd）を最小限に抑えることができます。点群でも</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Large Scale Holistic Video Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_62.html">
      <font color="black">Large Scale Holistic Video Understanding</font>
    </a>
  </h2>
  <font color="black">HVUは、シーン、オブジェクト、アクション、イベント、属性、および概念のカテゴリで定義されたセマンティックな側面を含み、現実世界のシナリオを自然にキャプチャします。実験を通じて、全体論的表現学習が補完的であり、重要な役割を果たすことができるという考えを検証します。多くの実際のアプリケーションを可能にする役割..HVUには、3142を超えるラベルにまたがるトレーニング、検証、およびテストセット用の900万の注釈を含む、合計で約572,000のビデオが含まれています。 
[ABSTRACT] hvuは、マルチラベルおよびマルチタスクビデオの理解に焦点を当てたセマンティック分類で構成されています。これらには、動的シーンでの複数のセマンティックな側面の発見が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-25">
        <br><font color="black">2019-04-25</font>
      </time>
    </span>
</section>
<!-- paper0: Fitting the Search Space of Weight-sharing NAS with Graph Convolutional
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_63.html">
      <font color="black">Fitting the Search Space of Weight-sharing NAS with Graph Convolutional
  Networks</font>
    </a>
  </h2>
  <font color="black">これらの方法は、計算コストの点で大きな利点がありますが、個別のトレーニングプロセスを実行しない限り、サンプリングされたサブネットワークが正確に推定される保証はありません。サンプリングされたサブネットワークのパフォーマンスに合うようにグラフ畳み込みネットワークをトレーニングすることで、この問題を軽減します。 -ランダムエラーの影響が最小限になるようにネットワーク..それを加速するために、研究者は、最初にスーパーネットワークをトレーニングして異なる演算子間で計算を再利用する重み共有方法を提案しました。これにより、指数関数的に多くのサブネットワークをサンプリングして効率的に評価できます。 。 
[概要]調査では、接続を再利用するためにスーパーネットワークを最初にトレーニングする重み共有方法が提案されています。これには、サンプリングして効率的に評価できるネットワークの再生成が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-17">
        <br><font color="black">2020-04-17</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Invisible People -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_64.html">
      <font color="black">Detecting Invisible People</font>
    </a>
  </h2>
  <font color="black">このパフォーマンス低下の多くを回復するために、2つの重要なイノベーションを紹介します。現在の検出および追跡システムのパフォーマンスがこのタスクで劇的に低下することを示します。ただし、具体化されたロボットエージェント（自動運転車など）でのオンライン追跡には、基本的にオブジェクトが必要です。永続性。これは、隠されたオブジェクトが再表示される前にそれらについて推論する機能です。 
[概要]ベンチマークの追跡を目的とし、目に見えないオブジェクトを検出するタスクの新しい指標を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Classification of Smoking and Calling using Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_65.html">
      <font color="black">Classification of Smoking and Calling using Deep Learning</font>
    </a>
  </h2>
  <font color="black">2014年以降、非常に深い畳み込みニューラルネットワークが提案され、あらゆる種類の競技会のチャンピオンにとってなくてはならない武器になりました。深層学習に基づく明るさの向上は、他の有用なトレーニングトリックとともにこの分類タスクの分類を改善するために実装されています。このレポートでは、事前トレーニングされた開始V3を変更することにより、喫煙と呼び出しの分類を実行するパイプラインが導入されています。 
[概要]レポートでは、喫煙と通話の分類を実行するパイプラインが導入されています。質と量の結果に基づいて、バイアスの少ないサンプルを使用したこのパイプラインは実用的であり、高精度で有用であると結論付けることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic Anchor Learning for Arbitrary-Oriented Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_66.html">
      <font color="black">Dynamic Anchor Learning for Arbitrary-Oriented Object Detection</font>
    </a>
  </h2>
  <font color="black">コードとモデルはhttps://github.com/ming71/DALで入手できます。このようにして、検出器は高品質のアンカーを動的に選択して正確なオブジェクト検出を実現し、分類と回帰の相違を軽減します。 。新たに導入されたDALにより、水平方向のプリセットアンカーが少ないだけで、任意の方向のオブジェクトに対して優れた検出パフォーマンスを実現します。 
[概要]この方法では、高品質のアンカーを簡単に選択して、正確なオブジェクト検出を実現できます。トレーニングの正と負の候補を特定するために使用されています。これにより、分類の信頼性とローカリゼーションの精度に矛盾が生じます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-08">
        <br><font color="black">2020-12-08</font>
      </time>
    </span>
</section>
<!-- paper0: Object-Centric Neural Scene Rendering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_67.html">
      <font color="black">Object-Centric Neural Scene Rendering</font>
    </a>
  </h2>
  <font color="black">これにより、オブジェクトやライトが移動する場合でも、再トレーニングなしでシーンをレンダリングできます。NeRFのようにシーンの放射輝度フィールドを学習する代わりに、オブジェクトごとの光輸送をモデル化する表現であるオブジェクト中心のニューラル散乱関数（OSF）を学習することを提案します。照明とビューに依存するニューラルネットワークを暗黙的に使用します。NeRFはリアルな画像を合成しますが、静的なシーンのみをモデル化し、特定のイメージング条件に密接に関連しています。 
[ABSTRACT]私たちの仕事は、神経放射輝度モデル（nerfs）に基づいています。これにより、オブジェクトやライトが移動した場合でも、再トレーニングなしで散乱関数を使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: WDNet: Watermark-Decomposition Network for Visible Watermark Removal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_68.html">
      <font color="black">WDNet: Watermark-Decomposition Network for Visible Watermark Removal</font>
    </a>
  </h2>
  <font color="black">目に見える透かしは、著作権の所有権を保護するために画像で広く使用されています。公開グレースケールデータセットLVWおよびCLWDでの広範な実験は、提案されたWDNetが精度と効率の両方で最先端のアプローチよりも優れていることを一貫して示しています。分解定式化により、WDNetは、透かしを単に削除するのではなく、画像から透かしを分離することができます。 
[概要]色付き透かし除去データセットの空白を埋めるために、clwdと呼ばれる大規模なデータセットを構築します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-14">
        <br><font color="black">2020-12-14</font>
      </time>
    </span>
</section>
<!-- paper0: Triage of Potential COVID-19 Patients from Chest X-ray Images using
  Hierarchical Convolutional Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_69.html">
      <font color="black">Triage of Potential COVID-19 Patients from Chest X-ray Images using
  Hierarchical Convolutional Networks</font>
    </a>
  </h2>
  <font color="black">また、認識パフォーマンスを向上させるために、マルチクラス問題をバイナリ分類にエンコードするためのECOCの使用を提案します。COVIDNetからの畳み込み層の使用により、CXRモダリティに関連する表現の抽出が保証されます。実験結果は、HCNアーキテクチャが既存の研究と比較してより良い結果を達成します。 
[ABSTRACT] covidnetが畳み込みネットワーク（hcn）を使用して、さまざまな機能とともにデータを自然に拡張します。covidnetから畳み込み層を使用すると、cxrに関連する表現を確実に抽出できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-01">
        <br><font color="black">2020-11-01</font>
      </time>
    </span>
</section>
<!-- paper0: FINED: Fast Inference Network for Edge Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_70.html">
      <font color="black">FINED: Fast Inference Network for Edge Detection</font>
    </a>
  </h2>
  <font color="black">私たちの実験は、私たちのシステムがほぼ同じモデル（パラメーター）サイズで現在のすべてのエッジ検出器よりも優れていることを示しています。ディープラーニングテクノロジーは、エッジ検出の精度を大幅に向上させます。ただし、一般的なニューラルネットワーク設計ではモデルの複雑さが非常に高くなります。これは実際の使用を妨げます。 
[概要]ディープラーニングテクノロジーにより、エッジ検出の精度が大幅に向上します。ただし、エッジ検出の可能性が高いネットワークを提案します。モデルの複雑さをさらに軽減しながら、同じレベルの精度を維持できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: KOALAnet: Blind Super-Resolution using Kernel-Oriented Adaptive Local
  Adjustment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_71.html">
      <font color="black">KOALAnet: Blind Super-Resolution using Kernel-Oriented Adaptive Local
  Adjustment</font>
    </a>
  </h2>
  <font color="black">本論文では、空間的に変化するぼけ特性に適応するために空間的に変化する劣化と復元のカーネルを共同で学習する、KOALAnetと呼ばれるSR機能のカーネル指向適応局所調整（KOALA）に基づく新しいブラインドSRフレームワークを提案します。実像で..ブラインド超解像度（SR）法は、未知の劣化を含む低解像度画像から高品質の高解像度画像を生成することを目的としています。さらに、提案されたKOALAnetは、焦点の合った領域と焦点の合っていない領域が混在する画像を効果的に処理することにより、過度にシャープ化されていない意図的なぼかしのある芸術的な写真に対して最も自然な結果を生み出すことを示しています。 
[概要]提案されたコアラは、焦点が合っている領域と焦点が合っていない領域が混在する画像を効果的に処理することにより、意図的なぼかしのある芸術的な写真に対して最も自然な結果を生成します。提案されたコアラネットは、ぼかしを解いて削除し、そのままにしておきます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Factorization Methods Using a Gaussian/Uniform Mixture Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_72.html">
      <font color="black">Robust Factorization Methods Using a Gaussian/Uniform Mixture Model</font>
    </a>
  </h2>
  <font color="black">また、私たちのアプローチをM推定器を使用する因数分解法と比較します。さらに、そのようなフレームワークを反復パースペクティブ因数分解スキームにさらに組み込む方法を示します。アルゴリズムを検証するために多数の実験を実行します。それらを既存のものと比較してください。 
[概要]ガウス/均一混合モデルとそれに関連するemアルゴリズムを紹介します。任意のアフィン因数分解法で機能し、外れ値に対してロバストにするロバストな手法を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Layout of Custom-size Furniture through Multiple-domain Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_73.html">
      <font color="black">Deep Layout of Custom-size Furniture through Multiple-domain Learning</font>
    </a>
  </h2>
  <font color="black">私たちの数値結果は、提案されたモデルが最先端のモデルと比較してカスタムサイズの家具のより高品質なレイアウトを生み出すことを示しています。この論文では、カスタムサイズの家具レイアウトを生成するためのマルチドメインモデルを提案します。インテリアシーン..プロのデザイナーによる$ 710,700 $のデザインを含む実際のインテリアレイアウトデータセットで実験を行います。 
[概要]提案されたモデルは、プロのインテリアデザイナーをサポートすることを目的としています。このモデルは、室内のカスタムサイズの家具の自動レイアウト機能を強化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: CosSGD: Nonlinear Quantization for Communication-efficient Federated
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_74.html">
      <font color="black">CosSGD: Nonlinear Quantization for Communication-efficient Federated
  Learning</font>
    </a>
  </h2>
  <font color="black">この作業では、圧縮確率的勾配降下法の非線形量子化を提案します。これは、連合学習で簡単に利用できます。MNIST、CIFAR-10、およびBraTSデータセットを使用して、画像分類と脳腫瘍のセマンティックセグメンテーションについて広範な実験を行います。最先端の有効性と印象的な通信効率..フェデレーション学習は、これらのクライアントのローカルデータを中央サーバーに転送することなく、クライアント間の学習を容易にします。 
[概要]システムは、通信コストを最大3桁大幅に削減します。連合学習法の成功にもかかわらず、改善が必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Practical Auto-Calibration for Spatial Scene-Understanding from
  Crowdsourced Dashcamera Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_75.html">
      <font color="black">Practical Auto-Calibration for Spatial Scene-Understanding from
  Crowdsourced Dashcamera Videos</font>
    </a>
  </h2>
  <font color="black">ただし、このようなカメラに対応する固有のパラメータは不明であるか、時間の経過とともに変化することがよくあります。それでも、前方および平面ナビゲーションは再構成のあいまいさを伴う重要なモーションシーケンスをもたらすため、ダッシュボードカメラの自動キャリブレーションは困難です。完全な視覚シーケンスの構造再構成何万もの画像が含まれている可能性もあり、計算上は不可能です。 
[ABSTRACT]クラウドソーシング動画を使用して知覚モジュールを作成できます。これらはクラウドソーシング動画からのクラウドソーシング動画に基づいています。このシステムはクラウドソーシング動画に役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Masksembles for Uncertainty Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_76.html">
      <font color="black">Masksembles for Uncertainty Estimation</font>
    </a>
  </h2>
  <font color="black">MC-dropoutのようにネットワークの一部をランダムにドロップする代わりに、Masksembleは、個々のモデル間の相関を変更できるようにパラメーター化された固定数のバイナリマスクに依存します。両方の利点を組み合わせるために、Masksemblesを導入します。 ..これにより、わずかなコストでEnsemblesと同等のパフォーマンスを備えたシンプルで実装が容易なメソッドが実現します。 
[ABSTRACT]ディープアンサンブルは、不確実性を生成するための最良の方法の1つと考えられていますが、トレーニングと評価に非常に費用がかかります。両方の利点を組み合わせるために、マスクサンブルを導入します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Fine-Grained Vehicle Perception via 3D Part-Guided Visual Data
  Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_77.html">
      <font color="black">Fine-Grained Vehicle Perception via 3D Part-Guided Visual Data
  Augmentation</font>
    </a>
  </h2>
  <font color="black">さらに、GitHubですべてのソースコード、データセット、トレーニング済みモデルをリリースする予定です。まず、データ不足に対処するために、動的パーツを備えた3Dカーモデルを車両に適合させることにより、効果的なトレーニングデータ生成プロセスを提案します。実際の画像で、次に人と車の相互作用シナリオを再構築します。実験は、視覚データの拡張を備えたトレーニング済みネットワークが、2D検出とインスタンスセグメンテーションの精度の点で他のベースラインを大幅に上回っていることを示しています。 
[概要]この論文では、視覚データの拡張に関する2つの重要な問題を解決することで、自動運転のこの重要な問題に対処します。これにより、位置合わせされた3Dパーツを使用して実際の画像を直接編集できるようになり、堅牢なディープニューラルを学習するための効果的なトレーニングデータ生成が可能になります。ネットワーク（dnns）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Artificial Dummies for Urban Dataset Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CV/paper_78.html">
      <font color="black">Artificial Dummies for Urban Dataset Augmentation</font>
    </a>
  </h2>
  <font color="black">これは、ポーズ、外観、およびターゲットの背景シーンを解きほぐして制御するデータジェネレーター（DummyNetと呼ばれる）を使用して実現されます。最初に、人を含む都市シーンの制御された合成のための拡張方法について説明します。最後に、DummyNetによって生成されたデータが、さまざまなデータセット全体で、また限られた量のトレーニングデータしか利用できない夜間の状況などの困難な状況で、いくつかの既存の人物検出器のパフォーマンスを向上させることを示します。 
[ABSTRACT]既存のデータベースの検出器は、任意のポーズで、任意の外観で、さまざまな背景シーンに埋め込まれた人物画像を作成できます。提案されたジェネレータは、前景の人物のセグメンテーションとその構成を考慮した新しいネットワークアーキテクチャと関連する損失に依存しています。背景シーンに</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Traditional IR rivals neural models on the MS~MARCO Document Ranking
  Leaderboard -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_0.html">
      <font color="black">Traditional IR rivals neural models on the MS~MARCO Document Ranking
  Leaderboard</font>
    </a>
  </h2>
  <font color="black">結果を再現するためのソフトウェアとデータを提供します。ほとんどのBERTベースのモデルより劣りますが、再ランク付けに大規模な事前トレーニング済みTransformerモデルを使用した2つの提出を含む、いくつかのニューラル実行（およびすべての非ニューラル実行）を上回りました。 ..この短いドキュメントでは、MS MARCOドキュメントランキングリーダーボード（2020-12-06）で0.298に等しいMRR @ 100を達成した従来のIRシステムについて説明します。 
[ABSTRACT] mrrは、いくつかのニューラルラン（およびすべての非ニューラルラン）をなんとか完成させました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Object-based attention for spatio-temporal reasoning: Outperforming
  neuro-symbolic models with flexible distributed architectures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_1.html">
      <font color="black">Object-based attention for spatio-temporal reasoning: Outperforming
  neuro-symbolic models with flexible distributed architectures</font>
    </a>
  </h2>
  <font color="black">これらのドメインでの最初の実験では、論理エンジンと言語パーサーをニューラル知覚フロントエンドと結合するニューロシンボリックアプローチが、完全に学習された分散ネットワークよりも大幅に優れていることがわかりました。これは、上記の論文をサポートするために行われた発見です。これらの結果は、これらのデータセットを含む以前の研究によって提示された神経記号論に反論し、神経ネットワークが実際に物理的イベントの原因となる動的構造について効果的に推論することを学ぶことができるという証拠を提供します。これらの柔軟なバイアスにより、モデルは利用可能なラベル付きデータの60％未満を使用する、以前のニューロシンボリックな最先端。 
[概要] 2つの新しいタスクドメイン、clevrerとcaterは、知覚ではなく、オブジェクト間の空間-量子相互作用のコンテキストで推論に焦点を当てるために開発されました。研究は、適切な誘導性を備えた完全に学習されたニューラルネットワークを示していますバイアスは、以前のすべての認知モデルよりも大幅に優れたパフォーマンスを発揮します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Writing Polishment with Simile: Task, Dataset and A Neural Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_2.html">
      <font color="black">Writing Polishment with Simile: Task, Dataset and A Neural Approach</font>
    </a>
  </h2>
  <font color="black">私たちのモデルは、最初に直喩の補間が行われるべき場所を特定し、次に場所固有の直喩を生成します。人間の作家は、平文の適切な場所に適切な直喩を補間して、文章を生き生きとさせることがよくあります。したがって、2段階のLocate＆Genモデルを設計します。トランスアーキテクチャに基づいています。 
[概要]新しい作業には、トランスフォーマーアーキテクチャに基づく2段階の位置特定と生成モデルが含まれます。これらには、コンテキスト付きの500万の直喩を含む中国の直喩（cs）データセットが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Check Contract Inconsistencies -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_3.html">
      <font color="black">Learning to Check Contract Inconsistencies</font>
    </a>
  </h2>
  <font color="black">実世界のデータセットで実施された実験は、CIC問題で94.05％のバランスの取れた精度と90.90％のF1スコアで私たちの方法の有望なパフォーマンスを示しています。この問題に対処する従来の方法は、主に手動の契約レビューに依存しています。 -集中的でコストがかかる..この作業では、新しい契約不整合チェック（CIC）問題を定式化し、ペアワイズブランク解決（PBR）と呼ばれるエンドツーエンドのフレームワークを設計して、CIC問題を高精度で解決します。 。 
[概要]多くのシナリオで、契約はプリコンパイルされた形式で空白で埋められます。これにより、契約の不整合が発生し、契約の法的有効性が損なわれる可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: *-CFQ: Analyzing the Scalability of Machine Learning on a Compositional
  Task -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_4.html">
      <font color="black">*-CFQ: Analyzing the Scalability of Machine Learning on a Compositional
  Task</font>
    </a>
  </h2>
  <font color="black">このスイートを使用して、固定計算コストの条件下でトレーニングサイズの増加から利益を得るトランスフォーマーの能力を調査する一連の実験を実施します。構成の一般化がすべてのトレーニングサイズで課題のままであることを示し、自然言語は一貫して高いエラー率につながりますが、トレーニングデータの増加によって部分的にのみ相殺されます。さらに、関連ドメインからの追加のトレーニングデータはデータが不足している状況での精度を向上させますが、この向上は限定的であり、距離が離れるにつれて低下することを示します。関連ドメインからターゲットドメインへの増加。 
[概要]固定コンピューティングコストの条件下でトレーニングサイズの増加から利益を得るモデルの能力。調査によると、関連するドメインからのトレーニングデータを増やすと、データマークの状況での精度が向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Generation of complex database queries and API calls from natural
  language utterances -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_5.html">
      <font color="black">Generation of complex database queries and API calls from natural
  language utterances</font>
    </a>
  </h2>
  <font color="black">他の質問については、テンプレートベースのアプローチを使用するか、クエリピースを予測してクエリを構築できますが、シーケンス間モデルよりも高い精度です。トレーニングデータセットの質問と同様の質問の場合、複雑なクエリが生成されます。高精度で..この方法は、小さなデータセットを使用して機能します。 
[ABSTRACT]長期モデルは、質問生成の問題をインテント分類とスロット充填セットに変換できます。トレーニングデータセットの質問と同様の質問の場合、高精度で複雑なクエリを生成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Enriched Annotations for Tumor Attribute Classification from Pathology
  Reports with Limited Labeled Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_6.html">
      <font color="black">Enriched Annotations for Tumor Attribute Classification from Pathology
  Reports with Limited Labeled Data</font>
    </a>
  </h2>
  <font color="black">精密医療はヘルスケアに革命を起こす可能性がありますが、患者のデータの多くは構造化されていないフリーテキストに閉じ込められており、効果的な個別治療の研究と提供が制限されています。以前の研究ではドキュメントレベルのラベルにのみ注釈が付けられていましたが、さらにアノテーターに質問します最終的なラベルに関連する行または潜在的に行を強調表示するように依頼することで、従来のラベルを充実させます。これにより、ドキュメントごとに必要な注釈時間が20％増加します。結果は、32、64、癌ごとに128、および186のラベル付きドキュメント、SLAは、私たちが行った比較の大部分で同等またはそれ以上のmicro-f1およびmacro-f1スコアを達成するために、最先端の方法としてラベル付きドキュメントの半分の数しか必要としません。 
[要約]情報抽出用の注釈付きデータセットは、高品質の注釈に必要な高度な専門知識のために、多くの場合、困難で費用がかかります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Contrastive Triple Extraction with Generative Transformer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_7.html">
      <font color="black">Contrastive Triple Extraction with Generative Transformer</font>
    </a>
  </h2>
  <font color="black">さらに、モデルのパフォーマンスをさらに向上させる2つのメカニズム（バッチごとの動的注意マスキングとトリプルごとのキャリブレーション）を導入します。3つのデータセット（NYT、WebNLG、MIE）での実験結果は、私たちのアプローチがより優れていることを示しています。ベースラインよりもパフォーマンスが優れています。生成トリプル抽出は、長期的な依存関係をキャプチャして不忠実なトリプルを生成するのに苦労する可能性があるため、生成トランスを使用した対照的なトリプル抽出という新しいモデルを紹介します。 
[概要]この論文では、シーケンス生成のトリプル抽出タスクを再検討します。これらには、エンコーダー-デコーダーベースの生成用の単一の共有トランスモジュールが含まれます。モデルのパフォーマンスをさらに向上させるための2つのメカニズムを紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: FILTER: An Enhanced Fusion Method for Cross-lingual Language
  Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_8.html">
      <font color="black">FILTER: An Enhanced Fusion Method for Cross-lingual Language
  Understanding</font>
    </a>
  </h2>
  <font color="black">推論中、モデルはターゲット言語でのテキスト入力とソース言語での翻訳に基づいて予測を行います。この論文では、XLM微調整の入力として言語間データを取得する拡張融合方法であるFILTERを提案します。 mBERT、Unicoder、XLMなどの大規模なクロスリンガル言語モデル（LM）は、クロスリンガル表現学習で大きな成功を収めています。 
[概要]クロスリンガル転送タスクに加えて、ほとんどの既存の方法は、lmの微調整に単一言語入力のみを使用します。これらの作業がクロスリンガル転送プロセスで使用されるのはこれが初めてです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Modeling Homophone Noise for Robust Neural Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_9.html">
      <font color="black">Modeling Homophone Noise for Robust Neural Machine Translation</font>
    </a>
  </h2>
  <font color="black">検出器は、テキスト文の潜在的な同音異義語エラーを識別し、それらを音節に変換して混合シーケンスを形成し、それを音節対応NMTに送ります。中国語-&gt;英語の翻訳に関する広範な実験は、提案された方法がベースラインを大幅に上回っているだけではないことを示しています。同音異義語ノイズのあるノイズの多いテストセットで、クリーンテキストの大幅な改善も実現します。この論文では、堅牢なニューラルマシントランスレーション（NMT）フレームワークを提案します。 
[概要]フレームワークは、同音異義語のノイズ検出器と音節で構成されています-同音異義語のエラーを認識するモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Aspect Sentiment Analysis with Latent Sentiment-Aspect Attribution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_10.html">
      <font color="black">Multi-Aspect Sentiment Analysis with Latent Sentiment-Aspect Attribution</font>
    </a>
  </h2>
  <font color="black">ホテルレビューデータセットとビールレビューデータセットでの実験により、SAAMは対応する基本モデルよりも感情分析のパフォーマンスを向上させることができました。さらに、フレームワークが文レベルのスコアをドキュメントレベルのスコアに直感的に組み合わせる方法により、以下を提供できます。データへのより深い洞察（例えば、半監視された文のアスペクトラベリング）。SAAMは、従来のニューラルネットワーク上で動作し、マルチアスペクトの感情分類と感情回帰の問題に対処するように設計されています。 
[ABSTRACT] saamは、従来のニューラルネットワーク上で動作し、マルチアプリケーションの問題に対処するように設計されています-感情レベルとsquits.saamは、cnnとrnnを使用した一連の実験で詳しく説明されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Ensemble Distillation Approaches for Grammatical Error Correction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_11.html">
      <font color="black">Ensemble Distillation Approaches for Grammatical Error Correction</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、これら両方の蒸留アプローチをシーケンス予測タスクである文法エラー訂正（GEC）に適用する方法について説明します。これは、学習者に非常に役立つフィードバックを提供できるため、言語学習タスクの重要なアプリケーション領域です。 、単語の文法的修正の予測は、単語の入力シーケンスと生成された出力履歴の両方に大きく依存するため、蒸留について調査された標準タスクよりも困難です。 
[概要]これは言語学習タスクの重要なアプリケーション領域です。学習者に非常に役立つフィードバックを提供できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Relation-Aware Neighborhood Matching Model for Entity Alignment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_12.html">
      <font color="black">Relation-Aware Neighborhood Matching Model for Entity Alignment</font>
    </a>
  </h2>
  <font color="black">近傍を照合するときに近傍ノードを比較するだけでなく、接続された関係から有用な情報を探索することも試みます。3つの実世界のデータセットでの実験結果は、提案されたモデルRNMが最先端の方法よりも優れていることを示しています。 、既存の方法では、エンティティの配置と関係の配置の間の積極的な相互作用にあまり注意が払われていませんでした。 
[概要]以前の研究では、エンティティの位置合わせにkgの構造情報を使用してエンティティの埋め込みに焦点を当てていました。複数の研究者が、エンティティの位置合わせを強化するために、隣接するノードをペアで比較しようとしました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: A Response Retrieval Approach for Dialogue Using a Multi-Attentive
  Transformer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_13.html">
      <font color="black">A Response Retrieval Approach for Dialogue Using a Multi-Attentive
  Transformer</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、ユーザーからの要求とユーザーが参照している製品に対するエージェントの応答を調整する、マルチアテンシブ構造のトランスフォーマーに基づくニューラルアーキテクチャを利用しています。SIMMCファッションデータセットの最終実験は私たちのアプローチは、主催者によって定義されたすべての検索メトリックで2番目に良いスコアを達成します。このペーパーでは、Dialogue System Technology Challenge（DSTC9）の第9版の作業を紹介します。 
[ABSTRACT]私たちのソリューションはトラック番号4に対応しています：シミュレートされたインタラクティブチャット。私たちのアシスタントは、応答候補のプールから最も適切な応答応答を取得するタスクを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: QUARC: Quaternion Multi-Modal Fusion Architecture For Hate Speech
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_14.html">
      <font color="black">QUARC: Quaternion Multi-Modal Fusion Architecture For Hate Speech
  Classification</font>
    </a>
  </h2>
  <font color="black">このモデルは、パラメーターがほぼ75％削減され、実際のモデルと比較してパフォーマンスの点で同等でありながら、ストレージスペースとトレーニング時間の点でもメリットがあります。テキストと画像の融合モデルは高度にパラメーター化されているため、提案します。モダリティの各ペアに追加の融合コンポーネントを持つクォータニオンニューラルネットワークベースのモデル。モデルは、ヘイトスピーチ分類のためにMMHS150KTwitterデータセットでテストされます。 
[概要]テキスト-画像融合モデルは大幅にペアリングされているため、クォータニオンニューラルネットワークベースのモデルを提案します。このモデルは、パラメーターが約75％削減され、ストレージスペースとトレーニング時間にメリットがあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Enhance Multimodal Transformer With External Label And In-Domain
  Pretrain: Hateful Meme Challenge Winning Solution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_15.html">
      <font color="black">Enhance Multimodal Transformer With External Label And In-Domain
  Pretrain: Hateful Meme Challenge Winning Solution</font>
    </a>
  </h2>
  <font color="black">レポートの最後に、現在の方法論を改善するための欠点と考えられる方向性も指摘します。嫌なミーム検出は、ミームの視覚的、言語的理解と実行するための背景知識の両方を必要とする最近発表された新しい研究分野です。このテクニカルレポートは、この問題に取り組むために最先端の視覚言語トランスフォーマーを拡張する、Hateful Meme Detection Challenge2020の最初のソリューションをまとめたものです。 
[概要]嫌なミーム検出チャレンジ2020は、この問題に取り組むことを目的としています。問題に取り組むための可能な方向の状態を拡張します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Nested Named Entity Recognition with Partially-Observed TreeCRFs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_16.html">
      <font color="black">Nested Named Entity Recognition with Partially-Observed TreeCRFs</font>
    </a>
  </h2>
  <font color="black">ただし、広く使用されているシーケンスラベリングフレームワークは、ネストされた構造を持つエンティティを検出するのが困難です。TreeCRFを使用すると、観測ノードと潜在ノードを共同でモデル化する統一された方法を実現できます。具体的には、すべてのラベル付きエンティティスパンを観測ノードとして表示します。構成ツリー、および潜在ノードとしての他のスパン。 
[概要]広く使用されているシーケンスラベリングフレームワークは、ネストされた構造を持つエンティティを検出するのが困難です。ラベル付けされたすべてのエンティティスパンを構成ツリー内の観測ノードとして表示し、他のスパンを潜在ノードとして表示します。システムは、内部アルゴリズムのバリアントに基づいています。 、ノードごとに異なる仮定をサポートします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Learning from History: Modeling Temporal Knowledge Graphs with
  Sequential Copy-Generation Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_17.html">
      <font color="black">Learning from History: Modeling Temporal Knowledge Graphs with
  Sequential Copy-Generation Networks</font>
    </a>
  </h2>
  <font color="black">CyGNetは、エンティティの語彙全体から将来の事実を予測できるだけでなく、繰り返して事実を識別し、それに応じて過去の既知の事実を参照してそのような将来の事実を予測することもできます。この目的のために、新しい表現学習を提案します。新しい時間認識コピー生成メカニズムに基づく時間知識グラフ、つまりCyGNetのモデル。大規模な知識グラフは、タイムラインに沿ったエンティティの動的な関係または相互作用をモデル化する時間的事実を格納するために成長することがよくあります。 
[要約]モデルは、履歴に表示される既知の事実から多くを学習する可能性があります。cygnetは、エンティティの語彙全体から将来の事実を予測できます。また、繰り返しで事実を識別し、既知の事実を参照してそのような将来の事実を正確に予測できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Profiling Gas Leaks in Solidity Smart Contracts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_18.html">
      <font color="black">Profiling Gas Leaks in Solidity Smart Contracts</font>
    </a>
  </h2>
  <font color="black">私たちのスイートのメトリックは、最適化が必要なソースコードセグメントをより簡単に特定するために使用できます。不適切な設計の選択は、必要以上にガス消費量を増やす可能性があります。ただし、スマートコントラクトの展開と実行のコストは、実行された実装の選択によって異なります。開発者による。 
[概要] 34人の参加者を対象とした調査では、2,186のスマートコントラクトがスマートコントラクトのコストにリンクしていることがわかりました。この調査では、提案された指標が展開コストと直接関連していることが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: The Gap on GAP: Tackling the Problem of Differing Data Distributions in
  Bias-Measuring Datasets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_19.html">
      <font color="black">The Gap on GAP: Tackling the Problem of Differing Data Distributions in
  Bias-Measuring Datasets</font>
    </a>
  </h2>
  <font color="black">ただし、収集されたデータの望ましくないパターンにより、このようなテストが不正確になる可能性があります。バイアスモデルを検出できる診断データセットは、自然言語処理内のバイアス削減の重要な前提条件です。共参照解決のためのGAPデータセットの方法を示します。 
[ABSTRACT]テストデータの同様のパターンに対処するためにテストサンプルに重みを付ける新しい方法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Clustering from Distributions over Topics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_20.html">
      <font color="black">Efficient Clustering from Distributions over Topics</font>
    </a>
  </h2>
  <font color="black">結果は、私たちのアプローチが効率の点で他の分析手法よりも優れている（&gt; 0.5）ことを示唆しています。ただし、この種の教師なし手法は依然として高い時間コストがかかります。このアプローチは、ドメイン内の同様のドキュメントを識別するときに有望な結果を得ることが証明されています。科学出版物の。 
[概要]これは、ページの小さいページを識別する方法を見つけるために使用できます。これは、問題を解決するための以前の試みと比較されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Incorporating Pragmatic Reasoning Communication into Emergent Language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_21.html">
      <font color="black">Incorporating Pragmatic Reasoning Communication into Emergent Language</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、より自然で、正確で、堅牢で、きめが細かく、簡潔な発話を得るための侵入の重要性に光を当てています。それらの組み合わせが言語学で探求されていることを考えると、短期間の相互推論を組み合わせた計算モデルを提案します-長期的な言語の発話を伴うベースの語用論..エージェントコミュニケーションの参照ゲームとStarcraftIIでこれを調査し、経験的および理論的にさまざまな種類の相互推論語用論モデルの相対的なメリットを評価します。 
[ABSTRACT]語用論は、科学的に異なり、異なるという事実に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-07">
        <br><font color="black">2020-06-07</font>
      </time>
    </span>
</section>
<!-- paper0: Keyword-Guided Neural Conversational Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_22.html">
      <font color="black">Keyword-Guided Neural Conversational Model</font>
    </a>
  </h2>
  <font color="black">この論文では、人間の会話は常識に基づいていると仮定し、キーワード遷移と応答検索の両方に外部常識知識グラフ（CKG）を活用できるキーワード誘導ニューラル会話モデルを提案します。この問題に取り組むための主要なパラダイムは1）次のターンのキーワード分類子をトレーニングし、2）キーワード拡張応答検索モデルをトレーニングします。さらに、セルフプレイと人間の評価の両方で、モデルがよりスムーズなキーワード遷移で応答を生成し、ターゲットキーワードよりも速く到達することが示されています。競争力のあるベースライン。 
[ABSTRACT]キーワード分類は、次のターンのキーワードモデルのトレーニングと評価のデータセットに基づいています。これらは人間の注釈なしで会話から直接抽出されるため、ノイズが多く、会話の目標が低くなります。これは、推奨などの問題に取り組むために使用できます。と心理療法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Theoretical Knowledge Graph Reasoning via Ending Anchored Rules -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_23.html">
      <font color="black">Theoretical Knowledge Graph Reasoning via Ending Anchored Rules</font>
    </a>
  </h2>
  <font color="black">結果は、EARDictモデルが、WN18RRで96.6％のHits @ 10スコアを達成するなど、知識グラフ補完の2つの大きなデータセットですべてのベンチマークモデルを大幅に上回っていることを示しています。私たちの理論は、トリプルが正しい理由またはそうでない理由を説明する正確な理由を提供します。知識グラフから正確で具体的なルールを見つけることは、多くのダウンストリームタスクのパフォーマンスを向上させ、自然言語処理の研究トピックにアプローチする新しい方法を提供することさえできる重要な課題と見なされています。 
[概要] eardictモデルからの新しい調査は、必要な情報量の証拠を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: CARE: Commonsense-Aware Emotional Response Generation with Latent
  Concepts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/cs.CL/paper_24.html">
      <font color="black">CARE: Commonsense-Aware Emotional Response Generation with Latent
  Concepts</font>
    </a>
  </h2>
  <font color="black">合理性と感情は人間の2つの基本要素です。具体的には、最初に、入力メッセージと目的の感情が与えられた場合の応答の常識を意識した感情的な潜在概念を学習および構築するためのフレームワークを提案します。仮説をテストするために、1つに焦点を当てます。合理性の基本的な側面、すなわち常識、そして常識を意識した感情的反応生成のための新しいモデルであるCAREを提案します。 
[概要]合理性と感情の概念は、aiの主要なマイルストーンの1つです。この論文では、合理性と感情を会話エージェントに組み合わせると、応答品質が向上する可能性があると仮定します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: F0-based Gammatone Filtering for Intelligibility Gain of Acoustic Noisy
  Signals -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/eess.AS/paper_0.html">
      <font color="black">F0-based Gammatone Filtering for Intelligibility Gain of Acoustic Noisy
  Signals</font>
    </a>
  </h2>
  <font color="black">さらに、PESQおよびWSSの客観的スコアは、提案された手法が興味深い品質改善も提供することを示しています。実験結果は、提案されたスキームが、競合するアプローチと比較した場合、表現力豊かな音声了解度の向上につながることを示しています。提案されたGTFF0ソリューションと2つのベースライン手法非定常度が異なる4つのバックグラウンドノイズを考慮して調べます。 
[概要]音声の高調波成分を検出するために一連のガンマトーンフィルターが採用されています。提案されたスキームは、競合するアプローチと比較した場合、表現力豊かな音声了解度の向上につながります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: QUARC: Quaternion Multi-Modal Fusion Architecture For Hate Speech
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/eess.AS/paper_1.html">
      <font color="black">QUARC: Quaternion Multi-Modal Fusion Architecture For Hate Speech
  Classification</font>
    </a>
  </h2>
  <font color="black">モデルは、ヘイトスピーチ分類のためにMMHS150K Twitterデータセットでテストされます。テキスト-画像融合モデルは高度にパラメータ化されているため、モダリティのペアごとに追加の融合コンポーネントを持つクォータニオンニューラルネットワークベースのモデルを提案します。パラメータが75％削減され、実際の対応物と比較してパフォーマンスの点で同等でありながら、ストレージスペースとトレーニング時間の点でもメリットがあります。 
[概要]テキスト-画像融合モデルは大幅にペアリングされているため、クォータニオンニューラルネットワークベースのモデルを提案します。このモデルは、パラメーターが約75％削減され、ストレージスペースとトレーニング時間にメリットがあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: A novel dataset for the identification of computer generated melodies in
  the CSMT challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/eess.AS/paper_2.html">
      <font color="black">A novel dataset for the identification of computer generated melodies in
  the CSMT challenge</font>
    </a>
  </h2>
  <font color="black">データセットの目的は、生成されたメロディーの特徴を学習することにより、コンピューターで生成されたメロディーを区別できるかどうかを調べることです。この論文では、音と音楽技術に関する会議（CSMT）が主催するデータチャレンジに使用されるデータセットを紹介します。 .. CSMTデータチャレンジでは、参加者は、特定のメロディーがコンピューターによって生成されたものか、人間によって作成されたものかを識別する必要があります。 
[概要] csmtデータチャレンジでは、参加者はメロディーの一部がコンピューターによって生成されたものか、人間によって作成されたものかを識別する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Bayesian Learning of LF-MMI Trained Time Delay Neural Networks for
  Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/eess.AS/paper_3.html">
      <font color="black">Bayesian Learning of LF-MMI Trained Time Delay Neural Networks for
  Speech Recognition</font>
    </a>
  </h2>
  <font color="black">ただし、それらは本質的に過剰適合する傾向があり、限られたトレーニングデータを使用すると一般化パフォーマンスが低下します。識別トレーニング手法は、自動音声認識システムの最先端のパフォーマンスを定義します。いくつかのベイジアン学習ベースのTDNNバリアントシステムが提案されています。重みパラメーターと非表示のアクティブ化関数の選択、または非表示のレイヤー出力に関する不確実性をモデル化します。 
[ABSTRACT]識別ベースのtdnnバリアントシステムは、重み条件と隠れた活性化関数の選択、または隠れたレイヤー出力の不確実性をモデル化するために提案されています。これらのシステムは、直接重みを微調整してベースラインシステムを上回りました。 &#39;</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-08">
        <br><font color="black">2020-12-08</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Speech Verification Spoofing Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/eess.AS/paper_4.html">
      <font color="black">Automatic Speech Verification Spoofing Detection</font>
    </a>
  </h2>
  <font color="black">自動音声検証（ASV）は、声に基づいて個人の身元を判断するテクノロジーです。これを念頭に置いて、ASVSpoof 2019コンテストの設定に従って、堅牢で効率的な潜在的な対策を開発します。2つの指標、EERおよびt-DCFは、システム評価に使用されます。 
[概要]最高のシステムセキュリティ基準を目指す必要があります。システム評価には、eerとt --dcfの2つのメトリックが使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: A fully recurrent feature extraction for single channel speech
  enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/eess.AS/paper_5.html">
      <font color="black">A fully recurrent feature extraction for single channel speech
  enhancement</font>
    </a>
  </h2>
  <font color="black">バニラCNNモジュールを使用した拡張モデルに対して評価した場合、目に見えないノイズ条件で、特徴抽出レイヤーに再現性がある提案されたモデルは、最大1.5 dBのセグメントSNR（SSNR）ゲインを生成し、平均で主観的品質が0.4向上しました。最適化されるパラメータが25％削減される一方で、オピニオンスコアスケール。畳み込みニューラルネットワーク（CNN）モジュールは、ハイエンドの音声強調ニューラルモデルを構築するために広く使用されています。示されているように、再通貨を追加すると、ローカル統計がキャプチャされます。抽出された特徴レベルでのノイズ属性の分析、したがって、提案されたモデルは、非常にノイズの多い条件でも音声キューを区別するのに効果的です。 
[要約]この主張は、cnnの話し言葉の話し言葉の地域からのデータの欠如に基づいています。ただし、このモデルは、非常に騒がしい状況でも音声の手がかりを区別するのに効果的であることが示唆されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-09">
        <br><font color="black">2020-06-09</font>
      </time>
    </span>
</section>
<!-- paper0: Visual-speech Synthesis of Exaggerated Corrective Feedback -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-16/eess.AS/paper_6.html">
      <font color="black">Visual-speech Synthesis of Exaggerated Corrective Feedback</font>
    </a>
  </h2>
  <font color="black">音声の誇張は、Tacotronに基づく強調音声生成ニューラルネットワークによって実現されますが、視覚の誇張は、ADC Viseme Blendingによって実現されます。つまり、動きの振幅を増やし、電話の持続時間を延長し、色のコントラストを強化します。ユーザーの調査によると、誇張されたフィードバックは学習者の発音の識別と発音の改善を支援する点で、誇張されていないバージョンよりも優れています。第2言語（L2）の学習者が誤発音をより適切に識別できるように、より識別力のあるフィードバックを提供するために、コンピューター支援発音での誇張された視覚音声フィードバックの方法を提案します。トレーニング（CAPT）。 
[概要]視覚的な誇張は、adc visemeブレンディングによって実現されます。視覚的な誇張は、強調音声生成によって行われます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-12">
        <br><font color="black">2020-09-12</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
