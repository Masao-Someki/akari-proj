<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-09-23の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: wav2vec 2.0: A Framework for Self-Supervised Learning of Speech
  Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.SD/paper_0.html">
      <font color="black">wav2vec 2.0: A Framework for Self-Supervised Learning of Speech
  Representations</font>
    </a>
  </h2>
  <font color="black">わずか10分のラベル付きデータを使用し、53k時間のラベルなしデータを事前トレーニングすると、Librispeechのノイズの多い/クリーンなテストセットで5.2 / 8.6 WERが達成されます。ラベル付きデータの量を1時間に減らすと、wav2vec 2.0は以前のパフォーマンスよりも優れています。ラベル付きデータを100分の1に減らしながら、100時間のサブセットで最先端の技術を使用しています。音声オーディオのみから強力な表現を学習し、その後、書き起こされた音声を微調整することで、最高の半教師ありの方法より優れたパフォーマンスを発揮概念的にはより単純です。 
[要旨] wav2vec 2。 0は、潜在空間での音声入力をマスクします。それは、共同で学習される3r表現の量子化に対して定義された対照的なタスクを解決します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-20">
        <br><font color="black">2020-06-20</font>
      </time>
    </span>
</section>
<!-- paper0: A Crowdsourced Open-Source Kazakh Speech Corpus and Initial Speech
  Recognition Baseline -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.SD/paper_1.html">
      <font color="black">A Crowdsourced Open-Source Kazakh Speech Corpus and Initial Speech
  Recognition Baseline</font>
    </a>
  </h2>
  <font color="black">高品質を確保するために、カザフ語のネイティブスピーカーによって慎重に検査されました。このホワイトペーパーでは、最初にデータ収集と事前処理の手順を説明し、次にデータベース仕様の説明を行います。実験結果は、音声と筆記録の品質が有望であることを示しています。 。 
[要約]カザフ語スピーチコーパス（ksc）には、154,000を超える発話が含まれています。これは、さまざまなカザフ語スピーチおよび言語処理アプリケーションを進めるために開発された、公的に利用可能な最大のデータベースです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Learning of Speech 2D Feature-Trajectory for Prosthetic Hands -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.SD/paper_2.html">
      <font color="black">End-to-End Learning of Speech 2D Feature-Trajectory for Prosthetic Hands</font>
    </a>
  </h2>
  <font color="black">ネットワークは、TensorFlowバックエンドを備えたKerasライブラリを備えたPythonで書かれています。このホワイトペーパーでは、音声の2D機能を義手用の軌跡に直接マッピングするエンドツーエンドの畳み込みニューラルネットワーク（CNN）を提案します。 NVIDIA Jetson TX2開発者キットのCNN。 
[要旨]音声コマンドは、義手をマルチモーダルに制御する上で不可欠な要素です。自動音声認識システムには、人間の音声をテキストにマッピングする方法が学習されます。従来の音声のパフォーマンス-制御された義手はまだ不十分です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Learning a Lie Algebra from Unlabeled Data Pairs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.SD/paper_3.html">
      <font color="black">Learning a Lie Algebra from Unlabeled Data Pairs</font>
    </a>
  </h2>
  <font color="black">重要なことに、パラメータ$ t_i \ in \ mathbb {R} $の値は、データペア$（\ boldsymbol {x} _i、\ boldsymbol {y} _i）$間で変化する可能性があり、事前に知る必要はありません。たとえば、ピッチ、強度ダイナミクス、および演奏テクニックの解きほぐしは、音楽情報の検索では依然として難しい作業です。球体の回転には、よく知られている対称グループ（$ \ mathrm {SO}（3）$）がありますが、同じことは、変動の多くの現実の要因については言えません。 
[ABSTRACT]近年、剛体運動を超えてグループを嘘に陥るディープラーニングの一般化により、球体の表面上のパターンなどの明示的な対称性を持つデータセット上にコンネットを構築できるようになりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-19">
        <br><font color="black">2020-09-19</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Speech Recognition and Disfluency Removal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.SD/paper_4.html">
      <font color="black">End-to-End Speech Recognition and Disfluency Removal</font>
    </a>
  </h2>
  <font color="black">ディスフルエンシー検出は通常、自動音声認識（ASR）システムとダウンストリームタスクの間の中間ステップです。また、統合されたASRモデルとディスフルエンシーモデルを評価するために使用できる2つの新しいメトリックを提案します。このペーパーの結果は、エンドツーエンドの音声認識と将来の流暢性の除去のタスクに関するさらなる研究のベンチマーク。 
[ABSTRACT]新しい論文は、流暢性の除去のためのモデルのタスクを調査することを目的としています。また、asrシステムと流暢さの検出を調査することを目的としています。調査結果は、さらなる研究のベンチマークとして役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Sequential View Synthesis with Transformer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.IV/paper_0.html">
      <font color="black">Sequential View Synthesis with Transformer</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、ニューラルレンダリングによる新規ビュー合成の問題に対処します。ここでは、他の視点からの特定の入力画像セットに基づいて、任意のカメラポーズで新規ビューを予測します。最後に、さまざまなモデルでモデルを評価しますデータセットに挑戦し、モデルが一貫した予測を提供するだけでなく、微調整のための再トレーニングも必要としないことを実証します。次に、学習した表現に基づいて、ターゲットビューを含む画像シーケンスを予測するためにシーケンシャルレンダリングデコーダーを導入します。 
[要約]提案されたトランスフォーマーベースの問題ネットワーク（t-gqn）は、2つの新しい概念を追加することでニューラル-レンダリング方法を拡張します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: Design of Efficient Deep Learning models for Determining Road Surface
  Condition from Roadside Camera Images and Weather Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.IV/paper_1.html">
      <font color="black">Design of Efficient Deep Learning models for Determining Road Surface
  Condition from Roadside Camera Images and Weather Data</font>
    </a>
  </h2>
  <font color="black">ただし、オンタリオ州全体で500を超えるカメラが画像を収集するため、目視検査はリソース集約型の活動になり、特に吹雪の期間中はスケーリングが困難になります。さらに、体系的なアブレーション実験に従って、以前に公開されたディープラーニングモデルを適用し、パラメータは、元のパラメータ数と比較して約1.3％であり、気象変数からの観測値を統合することで、モデルは視界不良条件下でRSCをより適切に確認できます。複数のディープラーニングモデルを使用して、路側カメラの画像と気象からRSCを自動的に決定変数、問題に対処するために同様の方法が使用された以前の研究を拡張します。 
[ABSTRACT]路面状態（rsc）は、道路に優先順位を付け、耕すなどの清掃作業を割り当てるために使用されます。500台を超えるカメラの場合、目視検査はリソース集約型のアクティビティになり、スケーリングが困難になります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Referenceless Rate-Distortion Modeling with Learning from Bitstream and
  Pixel Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.IV/paper_2.html">
      <font color="black">Referenceless Rate-Distortion Modeling with Learning from Bitstream and
  Pixel Features</font>
    </a>
  </h2>
  <font color="black">大規模な実験により、提案された方法により、サンプルのビットレート推定エラーの割合が、最新技術と比較して平均で10％以内に24.60％減少することが示されています。これにより、柔軟性と適用性に関する最新のコーデックのグローバルレート制御パラダイムが改善されます。具体的には、R-QP関係曲線を、コーシーベースの分布から導出されたロバストな2次R-QPモデリング関数として説明します。 
[ABSTRACT]参照なしの予測ベースの方法は、マルチパスコーディングと比較して実用的な利点を示します。ただし、予測の忠実度を向上させるために、ディープラーニングアルゴリズムを利用してビットレートを推定する新しい方法を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-18">
        <br><font color="black">2020-09-18</font>
      </time>
    </span>
</section>
<!-- paper0: Michelson Holography: Dual-SLM Holography with Camera-in-the-loop
  Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.IV/paper_3.html">
      <font color="black">Michelson Holography: Dual-SLM Holography with Camera-in-the-loop
  Optimization</font>
    </a>
  </h2>
  <font color="black">私たちは、新しいカメラインザループホログラフィテクニックを使用してこのシステムを較正し、最先端のホログラフィック2D画質を実証します。マイケルソンホログラフィ（MH）を導入します。これは、新たなホログラフィックの画質を最適化するホログラフィックディスプレイテクノロジーです。 2つの空間光変調器を使用するMHは、破壊的な干渉を利用して、観測された画像を破壊する非回折光を光学的にキャンセルすることができます。 
[ABSTRACT] 2つの空間光modlogを使用すると、mhは損傷を利用できます。これは、画像を破壊する非回折光をキャンセルするように機能します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-19">
        <br><font color="black">2020-09-19</font>
      </time>
    </span>
</section>
<!-- paper0: Semantic Workflows and Machine Learning for the Assessment of Carbon
  Storage by Urban Trees -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.IV/paper_4.html">
      <font color="black">Semantic Workflows and Machine Learning for the Assessment of Carbon
  Storage by Urban Trees</font>
    </a>
  </h2>
  <font color="black">科学ワークフローシステムは、実験の再現性、来歴のキャプチャ、ソフトウェアの再利用性、知識の共有など、これらの問題に対処するために比類のない利点を提供します。私たちの知る限り、これはガイドラインに従ってアフリカの地域の炭素貯蔵量を推定する最初の研究です気候変動に関する政府間パネル（IPCC）の意見です。ただし、気候科学の研究では、複数の分野のデータ、ソフトウェア、実験的アプローチの間の複雑な相互運用性の問題に対処する必要があります。 
[ABSTRACT]気候科学の研究では、しばしば気候科学の複雑な利点に対処する必要があります。気候科学は、しばしば気候科学の問題です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: CA-Net: Comprehensive Attention Convolutional Neural Networks for
  Explainable Medical Image Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.IV/paper_5.html">
      <font color="black">CA-Net: Comprehensive Attention Convolutional Neural Networks for
  Explainable Medical Image Segmentation</font>
    </a>
  </h2>
  <font color="black">ただし、セグメンテーションターゲットの位置、形状、スケールに大きな変動があり、既存のCNNの説明が不十分で、臨床的決定への適用が制限されている複雑な条件は依然として課題です。畳み込みニューラルネットワーク（CNN）は、自動医療画像セグメンテーションのための最新のパフォーマンス。この作業では、CNNアーキテクチャで複数の注意を広範囲に使用し、より正確で説明可能な医療画像セグメンテーションのための包括的な注意ベースのCNN（CA-Net）を提案します。最も重要な空間位置、チャネル、およびスケールを同時に認識します。 
[ABSTRACT]畳み込みニューラルネットワーク（cnns）は、自動医用画像セグメンテーションの扱いが複雑です。より正確で説明可能な医療処置のために包括的な注意ベースのcnn（ca-net）を提案します。既存のネットワークよりもはるかに優れた説明可能性があると言います注意の重みマップを視覚化することにより</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Interactive Multi-Dimension Modulation with Dynamic Controllable
  Residual Learning for Image Restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.IV/paper_6.html">
      <font color="black">Interactive Multi-Dimension Modulation with Dynamic Controllable
  Residual Learning for Image Restoration</font>
    </a>
  </h2>
  <font color="black">さらに、ベータ分布に基づいて新しいデータサンプリング戦略を提案し、さまざまな低下のタイプとレベルのバランスをとります。以前の1次元（SD）変調と比較して、MDは複数の低下を適応的に処理し、さまざまな低下の不均衡学習問題を軽減するように設定されています..具体的には、従来の残差接続に制御変数を追加して、入力と残差の加重加算を可能にします。 
[ABSTRACT]新しい問題の設定は多次元（md）栽培と呼ばれます。これは、複数の劣化タイプとレベルにわたって出力効果を変調することを目的としています。これらには、異なる条件ネットワークからの画像の削除が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-11">
        <br><font color="black">2019-12-11</font>
      </time>
    </span>
</section>
<!-- paper0: Constrained Non-Linear Phase Retrieval for Single Distance X-ray Phase
  Contrast Tomography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.IV/paper_7.html">
      <font color="black">Constrained Non-Linear Phase Retrieval for Single Distance X-ray Phase
  Contrast Tomography</font>
    </a>
  </h2>
  <font color="black">ただし、この線形近似では、近似の条件に違反すると、アーティファクトやぼやけが発生することがよくあります。XPCTを使用して画像化されたオブジェクトを再構築するには、まず位相検索アルゴリズムを使用して、X線位相投影（2D投影）を推定します各ビューでの屈折率の減少。NLPRを一般的な線形位相回復（LPR）アプローチと比較し、NLPRがより高い定量的精度でよりシャープな再構成を実現することを示します。 
[ABSTRACT] xpctを使用して画像化されたオブジェクトを再構築するには、まず位相検索アルゴリズムを使用して、屈折率の減少の2d投影であるX線位相投影を推定します。実際には、位相再構築は、線形逆問題</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: The Use of AI for Thermal Emotion Recognition: A Review of Problems and
  Limitations in Standard Design and Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.IV/paper_8.html">
      <font color="black">The Use of AI for Thermal Emotion Recognition: A Review of Problems and
  Limitations in Standard Design and Data</font>
    </a>
  </h2>
  <font color="black">しかし、熱画像は、顔認識の誤用に悩まされているRGBを介して、コンピュータビジョンに半匿名のモダリティを提供することも提案しています。私たちの動機は、熱FERの最近の進歩を紹介し、会話について刺激することです。現在のデータセットの制限。しかし、人間中心のAIタスクのソースとして熱画像を採用することへの移行は容易ではなく、複数の人口統計にわたる高忠実度データソースの可用性と徹底的な検証に依存しています。 
[要約]熱画像の採用への移行は容易ではなく、高忠実度データセクターの可用性に依存しています。これは、人間のAIタスクのソースとして熱画像を採用するための最初のステップです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Early Exit or Not: Resource-Efficient Blind Quality Enhancement for
  Compressed Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.IV/paper_9.html">
      <font color="black">Early Exit or Not: Resource-Efficient Blind Quality Enhancement for
  Compressed Images</font>
    </a>
  </h2>
  <font color="black">具体的には、私たちのアプローチは、ダイナミックディープニューラルネットワーク（DNN）を介して圧縮画像の品質を盲目的に段階的に向上させます。DNNには早期終了戦略が組み込まれています。強化された画像の品質。その結果、わずかなアーティファクトはより単純で高速なプロセスで削除でき、厳しいアーティファクトはさらに複雑なプロセスでさらに削除できます。 
[要約]このホワイトペーパーでは、リソース効率の高いブラインド品質向上（rbqe）モデルを提案します。具体的には、私たちのアプローチは、強化された画像の評価品質に応じて、強化を自動的に終了または続行することを決定できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br><font color="black">2020-06-30</font>
      </time>
    </span>
</section>
<!-- paper0: Classification of COVID-19 in CT Scans using Multi-Source Transfer
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.IV/paper_10.html">
      <font color="black">Classification of COVID-19 in CT Scans using Multi-Source Transfer
  Learning</font>
    </a>
  </h2>
  <font color="black">利用可能なCOVID-19 CTデータが本質的に不足しているため、これらの研究努力は転移学習の使用を余儀なくされました。私たちの最高のパフォーマンスモデルは、0.893の精度と0.897の再現スコアを達成し、そのベースラインを上回りました。 9.3％でスコアをリコールします。マルチソースの微調整アプローチにより、モデルはImageNetで微調整されたベースラインモデルを上回りました。 
[要約]リサーチは、ct scans。からのcovid-19のたたみ込みニューラルネットワーク（cnns）でのコンピュータービジョンの使用を調査しました。19歳の人の背後にある主な理由は、信頼性の欠如とrt-pcrテストの欠如によるものです。感染率が高いのは信頼性が低いためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Detection Of Concrete Cracks using Dual-channel Deep Convolutional
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.IV/paper_11.html">
      <font color="black">Detection Of Concrete Cracks using Dual-channel Deep Convolutional
  Network</font>
    </a>
  </h2>
  <font color="black">この論文では、256 x 256ピクセル解像度のこれらの画像でトレーニングされたディープCNNから始めて、問題を特定することでモデルを徐々に最適化しました。研究の過程で、コンクリート亀裂のある3200のラベル付き画像のデータベースでクラックのコントラスト、照明条件、方向、深刻度が非常に変動する場所で作成されました。ランダムなズーム、回転、強度のスケーリングなどの無人の動画と互換性のある変動と劣化を考慮した拡張データセットを使用します。アブレーション研究では、現実的な状況でコンクリート亀裂を見つける際の堅牢性だけでなく、高精度（〜92.25％）を示すデュアルチャネルディープCNNを設計しました。 
[ABSTRACT]プロジェクトは、コンクリートのひび割れを含む3200枚の画像のデータベースを使用して作成されました。現実的な状況でコンクリートのひび割れを見つける際に高い精度を示しています-</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning based NAS Score and Fibrosis Stage Prediction from CT and
  Pathology Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.IV/paper_12.html">
      <font color="black">Deep Learning based NAS Score and Fibrosis Stage Prediction from CT and
  Pathology Data</font>
    </a>
  </h2>
  <font color="black">また、CTとH \＆Eで染色された病理データからの情報を組み合わせて、両方のタイプのデータが利用可能な場合に、NASスコアと線維化ステージ予測のパフォーマンスを向上させる方法も示します。これは、コンピューターの病理学者を支援するのに非常に役立ちます。を利用した診断プロセス。非アルコール性脂肪肝疾患（NAFLD）は、世界の人口でますます流行している。 
[ABSTRACT] nafld（nafld）はnafld（nash）とその後の肝障害を引き起こす可能性があります。適切なタイミングで診断せずに、nafldはnafldをリードできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: AdderSR: Towards Energy Efficient Image Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.IV/paper_13.html">
      <font color="black">AdderSR: Towards Energy Efficient Image Super-Resolution</font>
    </a>
  </h2>
  <font color="black">そのために、加算器操作とIDマッピングの関係を徹底的に分析し、ショートカットを挿入して、加算器ネットワークを使用してSRモデルのパフォーマンスを向上させます。具体的には、加算器操作では、画像処理に不可欠なIDマッピングを簡単に学習できません。タスク..次に、機能の分布を調整し、詳細を調整するための学習可能な電源アクティベーションを開発します。 
[ABSTRACT]たとえば、addernetはaddernetを使用して出力機能を計算し、大量のエネルギー消費を回避します。addernetは、写真認識ではなく、added機能を使用して追加機能を計算します。addernetは、cnnベースラインと同等の成功を収めることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-18">
        <br><font color="black">2020-09-18</font>
      </time>
    </span>
</section>
<!-- paper0: Single Image Super-Resolution for Domain-Specific Ultra-Low Bandwidth
  Image Transmission -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.IV/paper_14.html">
      <font color="black">Single Image Super-Resolution for Domain-Specific Ultra-Low Bandwidth
  Image Transmission</font>
    </a>
  </h2>
  <font color="black">私たちは、再構成された画像の品質と、実際の使用例におけるそのような方法の見通しを調査することを目的としています。次に、ニューラルネットワークをトレーニングして、アップサンプリングを実行し、元の画像を再構成します。 
[ABSTRACT]これにより、このようなチャネルは使用できなくなったり、効率が悪くなったりします。これは、長年の釣りで得られた大規模で多様なデータセットで調査されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-09">
        <br><font color="black">2020-09-09</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Discriminative Segmentation Tracking Using Dual Memory Banks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_0.html">
      <font color="black">Discriminative Segmentation Tracking Using Dual Memory Banks</font>
    </a>
  </h2>
  <font color="black">ベルとホイッスルなしで、私たちのシンプルでありながら効果的な追跡アーキテクチャは、VOT2016、VOT2018、VOT2019、GOT-10K、およびTrackingNetベンチマークに新しい最先端の技術を設定し、特にVOT2016で0.535と0.506のEAOを達成しますVOT2018 ..既存のテンプレートベースのトラッカーは通常、境界ボックスを使用して各フレームのターゲットをローカライズするため、ピクセル単位の表現の学習とターゲットの複雑で非剛体の変換の処理が制限されます。デュアルメモリバンク、つまり、外観メモリバンクと空間メモリバンクを備えた、新しい識別セグメンテーション追跡アーキテクチャ。 
[ABSTRACT]外観メモリバンクは、空間的および地域的な非局所的類似性を使用して、外観マスクを現在のフレームに伝播します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-21">
        <br><font color="black">2020-09-21</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Image Labels On-the-fly for Training Robust Classification
  Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_1.html">
      <font color="black">Learning Image Labels On-the-fly for Training Robust Classification
  Models</font>
    </a>
  </h2>
  <font color="black">一方、NLPアルゴリズムに基づく自動アノテーション手法は、臨床システムで広く利用可能なこれらの画像の既存の診断レポートに依存して、合理的な代替手段として最近有望であることが示されています。アノテーションの差異（同じデータに複数回ラベルを付けることによる）と、医用画像分析などの重要なアプリケーションへの影響。メタトレーニングベースのラベルサンプリングモジュールは、追加のバックを通して最も学習するモデルに利益をもたらすラベルに参加するように設計されています伝播プロセス。 
[ABSTRACT]このプロセスは、通常は専門的なトレーニングと特定のドメインでの専門知識を必要とするすでに退屈な注釈作業に余分な負担を追加します。代わりに、注意-オン-ラベルの概念が導入され、より優れたラベルセットをサンプリングします-これらはトレーニングとしてデータ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Face Models for Example-Based Visual Speech Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_2.html">
      <font color="black">Neural Face Models for Example-Based Visual Speech Synthesis</font>
    </a>
  </h2>
  <font color="black">私たちは、口形素クエリシーケンスに基づいてスイス-ドイツ語手話の口を合成することにより、このアプローチの有効性を示しています。ただし、例に基づくアプローチの2つの困難は、高いメモリ要件と、アーティファクトのない、現実的なモーション間の遷移の作成です。サンプル..このデータは、新しいモーションシーケンスを作成するためにループまたは連結できる短いモーションサンプルに分割されます。 
[要約]キャプチャされたデータに基づいて、顔のパフォーマンスをシームレスに連結するために使用される顔の表情の神経表現を学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: PP-OCR: A Practical Ultra Lightweight OCR System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_3.html">
      <font color="black">PP-OCR: A Practical Ultra Lightweight OCR System</font>
    </a>
  </h2>
  <font color="black">上記のすべてのモデルはオープンソースであり、コードはGitHubリポジトリ（https://github.com/PaddlePaddle/PaddleOCRなど）で利用できます。モデルの機能を強化するか、モデルサイズ..実際のデータに対応するアブレーション実験も提供されます。 
[要約]提案されたpp-ocrは、さまざまなテキストの外観と計算効率の要求により、依然として困難なタスクです。提案されたppのモデルサイズは、6622漢字を認識するためにわずか3.5 mです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-21">
        <br><font color="black">2020-09-21</font>
      </time>
    </span>
</section>
<!-- paper0: Sequential View Synthesis with Transformer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_4.html">
      <font color="black">Sequential View Synthesis with Transformer</font>
    </a>
  </h2>
  <font color="black">最後に、さまざまな困難なデータセットでモデルを評価し、モデルが一貫した予測を提供するだけでなく、微調整のために再トレーニングを必要としないことを示します。このペーパーでは、提案されたトランスフォーマーベースの生成クエリネットワーク（T-GQN） 2つの新しい概念を追加することによるニューラルレンダリング手法。2番目に、学習した表現に基づいて、ターゲットビューを含む画像シーケンスを予測する順次レンダリングデコーダーを導入します。 
[要約]提案されたトランスフォーマーベースの問題ネットワーク（t-gqn）は、2つの新しい概念を追加することでニューラル-レンダリング方法を拡張します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: Compositional Few-Shot Recognition with Primitive Discovery and
  Enhancing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_5.html">
      <font color="black">Compositional Few-Shot Recognition with Primitive Discovery and
  Enhancing</font>
    </a>
  </h2>
  <font color="black">プリミティブ発見とプリミティブ強化..少数ショット学習（FSL）は、いくつかのトレーニングサンプルしか与えられていない新しいクラスを認識することを目的としていますが、それでもディープラーニングには大きな課題が残っています。プリミティブ発見では、オブジェクトパーツに関連するプリミティブの学習に焦点を当てます。画像分割の順序からの自己監視、余分な手間のかかる注釈を回避し、セマンティックギャップの影響を軽減します。 
[ABSTRACT] fslは、重要なプリミティブで構成されるフィーチャ表現を学習することを目的としています。これは、2つのパーツと共同でトレーニングされます。プリミティブの発見では、画像分割の順序からの自己監視によるオブジェクトパーツに関連するプリミティブの学習に焦点を当てます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br><font color="black">2020-05-12</font>
      </time>
    </span>
</section>
<!-- paper0: Geometry-Aware Segmentation of Remote Sensing Images via Implicit Height
  Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_6.html">
      <font color="black">Geometry-Aware Segmentation of Remote Sensing Images via Implicit Height
  Estimation</font>
    </a>
  </h2>
  <font color="black">セマンティックラベリングに単一ストリームエンコーダーデコーダーネットワークを使用する代わりに、高さマップを予測する別のデコーダーブランチを設計し、DSM画像をサイド監視として使用して、この新しく設計されたデコーダーブランチをトレーニングします。このようにして、モデルはモデル入力としてDSMを必要とせず、トレーニング中に役立つ3D幾何学的情報の恩恵を受けます。さらに、高さデコーダブランチからの3D幾何学的特徴とセマンティックセグメンテーションからの2Dコンテキスト特徴を融合する新しい幾何学対応畳み込みモジュールを開発します。ブランチ。 
[ABSTRACT]以前の方法はほとんど3D標高情報を採用しています。代わりに、新しいモデルはモデル入力としてdsmを必要としません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-10">
        <br><font color="black">2020-06-10</font>
      </time>
    </span>
</section>
<!-- paper0: Performance Indicator in Multilinear Compressive Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_7.html">
      <font color="black">Performance Indicator in Multilinear Compressive Learning</font>
    </a>
  </h2>
  <font color="black">最近、多次元信号を扱うときのセンシングと学習のステップを効率的に最適化するために、Multilinear Compressive Learning（MCL）フレームワークが提案されました。一般に圧縮学習、特にMCLでは、圧縮センシングデバイスによってキャプチャされた圧縮測定の数が、ストレージの要件または伝送の帯域幅要件を特徴付けます。テンソル。 
[ABSTRACT]この数値は、mcl system.mclの再構成エラーの学習パフォーマンスを完全に特徴付けるものではないため、優れた指標として機能できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Stochastic Neighbor Embedding with Gaussian and Student-t Distributions:
  Tutorial and Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_8.html">
      <font color="black">Stochastic Neighbor Embedding with Gaussian and Student-t Distributions:
  Tutorial and Survey</font>
    </a>
  </h2>
  <font color="black">このチュートリアルと調査論文では、SNE、対称SNE、t-SNE（またはコーシーSNE）、および一般的な自由度を持つt-SNEについて説明します。SNEでは、すべての点が他のすべての点の隣接点と見なされますある程度の確率で、この確率は埋め込み空間に保存されるように試みられます。これらのメソッドのサンプル外の拡張と加速についても説明します。 
[ABSTRACT] sneでは、すべての点が他のすべての点の隣接点であると見なされます。この確率は、埋め込み空間で保存されるように試行されます。ただし、t-sneはスチューデント-tとガウス分布を使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: OpenREALM: Real-time Mapping for Unmanned Aerial Vehicles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_9.html">
      <font color="black">OpenREALM: Real-time Mapping for Unmanned Aerial Vehicles</font>
    </a>
  </h2>
  <font color="black">すべてのモードで、結果のマップの漸進的な進行状況をオペレーターが地上でライブで見ることができます。取得された最新の表面情報は、さまざまなUAVアプリケーションにプッシュされます。さらに、 UAVはデータの地理参照に使用されます。 
[ABSTRACT]カメラに接続されたカメラは、関心のある対象領域の高解像度画像をキャプチャするために使用されます。カメラは、関心のある領域を識別してデータをマッピングするために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Design of Efficient Deep Learning models for Determining Road Surface
  Condition from Roadside Camera Images and Weather Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_10.html">
      <font color="black">Design of Efficient Deep Learning models for Determining Road Surface
  Condition from Roadside Camera Images and Weather Data</font>
    </a>
  </h2>
  <font color="black">さらに、体系的なアブレーション実験に従って、以前に公開されたディープラーニングモデルを適合させ、パラメーターの数を元のパラメーター数と比較して約1.3％に減らし、気象変数からの観測を統合することにより、モデルは視界不良時にRSCをより正確に確認できます条件..このホワイトペーパーでは、道路維持管理の効率向上に焦点を当てた調査結果を示しています。複数のディープラーニングモデルを使用して、路側のカメラ画像と気象変数からRSCを自動的に決定し、同様の方法が使用された以前の調査を拡張しています。問題に対処します。 
[ABSTRACT]路面状態（rsc）は、道路に優先順位を付け、耕すなどの清掃作業を割り当てるために使用されます。500台を超えるカメラの場合、目視検査はリソース集約型のアクティビティになり、スケーリングが困難になります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: What Do You See? Evaluation of Explainable Artificial Intelligence (XAI)
  Interpretability through Neural Backdoors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_11.html">
      <font color="black">What Do You See? Evaluation of Explainable Artificial Intelligence (XAI)
  Interpretability through Neural Backdoors</font>
    </a>
  </h2>
  <font color="black">バックドアトリガーは意図的な誤分類の原因となる最も重要な機能であるため、堅牢なXAIメソッドは、推論時にその存在を明らかにする必要があります。説明可能なAI（XAI）メソッドは、ディープニューラルネットワークがハイライトするモデル顕著性説明を通じて入力を予測する方法を解釈するために提案されています特定のターゲットに決定を下すために重要と見なされた入力の部分。XAIメソッドが生成する説明を体系的に評価するための3つの補完的なメトリックを導入し、7つの最新のモデルフリーおよびモデル固有のポストホックを評価します。色、形、質感、場所、サイズを使用して特別に細工されたトリガーでトロイの木馬化された36のモデルによる方法。 
[ABSTRACT]重要な観察結果は、トリガーが説明の根本的な真実を提供することです。これにより、サルシー法で特定された領域が出力にどのように関連しているか</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Personalized Speech2Video with 3D Skeleton Regularization and Expressive
  Body Poses -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_12.html">
      <font color="black">Personalized Speech2Video with 3D Skeleton Regularization and Expressive
  Body Poses</font>
    </a>
  </h2>
  <font color="black">モーションの詳細を含む写実的で高解像度のビデオを作成するために、条件付きGANにパーツアテンションメカニズムを挿入することを提案します。私たちのアプローチを検証するために、さまざまなトピックのさまざまなドキュメントを読んでいる1人の男性モデルと1人の女性モデルからの20の高品質ビデオのデータセットを収集します。 
[ABSTRACT]スケルトンの動きは、リカレントニューラルネットワーク（rnn）を使用して生成されます。次に、条件付き多関節3 dネットワーク（gan）を介して出力ビデオを合成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-17">
        <br><font color="black">2020-07-17</font>
      </time>
    </span>
</section>
<!-- paper0: Semantic Workflows and Machine Learning for the Assessment of Carbon
  Storage by Urban Trees -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_13.html">
      <font color="black">Semantic Workflows and Machine Learning for the Assessment of Carbon
  Storage by Urban Trees</font>
    </a>
  </h2>
  <font color="black">科学ワークフローシステムは、実験の再現性、来歴のキャプチャ、ソフトウェアの再利用性、知識の共有など、これらの問題に対処するために比類のない利点を提供します。私たちの知る限り、これはガイドラインに従ってアフリカの地域の炭素貯蔵量を推定する最初の研究です気候変動に関する政府間パネル（IPCC）から。気候科学は地球の気温の変化の原因と結果の両方を理解するために重要であり、決定的な政策立案のために不可欠になっています。 
[ABSTRACT]気候科学の研究では、しばしば気候科学の複雑な利点に対処する必要があります。気候科学は、しばしば気候科学の問題です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: MonoClothCap: Towards Temporally Coherent Clothing Capture from
  Monocular RGB Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_14.html">
      <font color="black">MonoClothCap: Towards Temporally Coherent Clothing Capture from
  Monocular RGB Video</font>
    </a>
  </h2>
  <font color="black">変形トラッキングのドリフトを最小限に抑えるために、衣服の可視テクスチャ領域を順次拡大するUVテクスチャ成長法を開発します。広範な定量的実験により、衣服の体位誤差や表面再構成誤差などのメトリックに対する本手法の有効性が実証されています。 。差別化可能なレンダラーを利用して、シルエットとテクスチャの両方の違いを最小限に抑えることにより、キャプチャした形状を入力フレームに揃えます。 
[ABSTRACT]この方法では、事前にスキャンされたパーソナライズされたメッシュテンプレートは必要ありません。さまざまな課題から衣服のキャプチャ結果が成功したことを実証しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Deep N-ary Error Correcting Output Codes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_15.html">
      <font color="black">Deep N-ary Error Correcting Output Codes</font>
    </a>
  </h2>
  <font color="black">さらに、ディープN-ary ECOCに関する広範なアブレーション研究は、他のディープデータに依存しないアンサンブル法よりも優れたパフォーマンスを示します。ディープラーニングベースの学習者によるN-ary ECOCのトレーニングを容易にするために、パラメーター共有アーキテクチャの3つの異なるバリアントをさらに提案します。アンサンブル学習は、一連の基本分類子を集約することにより、マルチクラス分類のパフォーマンスを一貫して向上させます。 
[ABSTRACT]ディープn ary ecocは簡単ではなく、ベース学習者のトレーニングに高い費用がかかるため、文献では十分に活用されています。画像とテキストの両方の分類タスクに対して、異なるディープニューラルネットワークアーキテクチャでバックボーンを変化させて実験を行います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Spatial-Temporal Block and LSTM Network for Pedestrian Trajectories
  Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_16.html">
      <font color="black">Spatial-Temporal Block and LSTM Network for Pedestrian Trajectories
  Prediction</font>
    </a>
  </h2>
  <font color="black">2つの公開データセットに関する実験結果。シーン内の各歩行者はノードと見なされ、グラフの埋め込みによって各ノードとその近傍の関係を取得できます。複数の可能な将来の軌跡を効果的に予測するために、ネットワークを柔軟にするために時空間たたみ込みブロックをさらに導入します。 
[要約]この論文では、新しいlstmベースのアルゴリズムを提案します。問題は、社会的勢力と乱雑なシーンが原因です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Conditional Sequential Modulation for Efficient Global Image Retouching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_17.html">
      <font color="black">Conditional Sequential Modulation for Efficient Global Image Retouching</font>
    </a>
  </h2>
  <font color="black">CSRNetは、ベースネットワークと条件ネットワークで構成されます。このペーパーでは、一般的に使用されるレタッチ操作を調査し、これらのピクセルに依存しない操作が多層パーセプトロン（MLP）によって近似または定式化できることを数学的に見つけます。露出オーバー/露出不足、コントラストの低下、不調和な彩度などの写真の欠陥に苦しむ画像の美的視覚品質を向上させることを目的としています。 
[要約]基本ネットワークは、患者を個別に処理するmlpのように動作します。条件ネットワークは、入力画像のグローバルな特徴を抽出します。これは、この分析に基づいており、非常に軽量なフレームワーク-条件付きレタッチネットワーク（csrnet）-効率的なグローバル画像レタッチのため</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: CA-Net: Comprehensive Attention Convolutional Neural Networks for
  Explainable Medical Image Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_18.html">
      <font color="black">CA-Net: Comprehensive Attention Convolutional Neural Networks for
  Explainable Medical Image Segmentation</font>
    </a>
  </h2>
  <font color="black">正確な医用画像セグメンテーションは、疾患の診断と治療計画に不可欠です。この作業では、CNNアーキテクチャで複数の注意を広範囲に使用し、より正確で説明可能な医用画像のための包括的な注意ベースのCNN（CA-Net）を提案します最も重要な空間位置、チャネル、およびスケールを同時に認識するセグメンテーション。たたみ込みニューラルネットワーク（CNN）は、自動医療画像セグメンテーションのための最先端のパフォーマンスを実現しています。 
[ABSTRACT]畳み込みニューラルネットワーク（cnns）は、自動医用画像セグメンテーションの扱いが複雑です。より正確で説明可能な医療処置のために包括的な注意ベースのcnn（ca-net）を提案します。既存のネットワークよりもはるかに優れた説明可能性があると言います注意の重みマップを視覚化することにより</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Interactive Multi-Dimension Modulation with Dynamic Controllable
  Residual Learning for Image Restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_19.html">
      <font color="black">Interactive Multi-Dimension Modulation with Dynamic Controllable
  Residual Learning for Image Restoration</font>
    </a>
  </h2>
  <font color="black">具体的には、従来の残差接続に制御変数を追加して、入力と残差の加重加算を可能にします。広範な実験により、提案されたCResMDがSDとMDの両方の変調タスクで優れたパフォーマンスを達成することが示されています。復元レベルを決定する制御係数を調整する。 
[ABSTRACT]新しい問題の設定は多次元（md）栽培と呼ばれます。これは、複数の劣化タイプとレベルにわたって出力効果を変調することを目的としています。これらには、異なる条件ネットワークからの画像の削除が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-11">
        <br><font color="black">2019-12-11</font>
      </time>
    </span>
</section>
<!-- paper0: Tailoring: encoding inductive biases by optimizing unsupervised
  objectives at prediction time -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_20.html">
      <font color="black">Tailoring: encoding inductive biases by optimizing unsupervised
  objectives at prediction time</font>
    </a>
  </h2>
  <font color="black">この作業では、両方の問題を解決します。最初に、トランスダクティブ学習からインスピレーションを得て、入力を受け取った後、予測を行う前に、教師なしの目的でモデルを微調整できることに注意してください。CNNから注意メカニズム、エンコーディングニューラルネットワークへの誘導バイアスは、機械学習の改善の実りあるソースです。モデルを各入力にカスタマイズするため、このプロセスを調整と呼びます。 
[要約]調整とメタ調整の利点が理論的に説明されています。これらは、より適切な表現を学習する新しい方法で実証されています。これらは、損失関数に追加の項を追加することにより、ネットワークがより良い表現を学習するのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: TSV Extrusion Morphology Classification Using Deep Convolutional Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_21.html">
      <font color="black">TSV Extrusion Morphology Classification Using Deep Convolutional Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">TSV押し出し形態分類アプリケーション用に、ネットワークの複雑度が異なる4つのCNNアーキテクチャが実装およびトレーニングされています。得られた結果は、最適化された複雑度、ドロップアウト、およびデータ拡張を備えたCNNモデルが、人間の専門家に匹敵する分類精度を達成できることを示しています。 、白色光干渉法（WLI）技術を使用して、押し出されたTSVの表面プロファイルを取得します。 
[ABSTRACT] cnnは、wli.itから取得した未加工データを使用するプログラムを開発しました。54x54ピクセルのtsv画像が含まれ、ラベルが付けられ、3つの曲がったクラスにリストされます。データの拡張とドロップアウトのアプローチは、過適合と過適合のバランスを実現するために使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Keep off the Grass: Permissible Driving Routes from Radar with Weak
  Audio Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_22.html">
      <font color="black">Keep off the Grass: Permissible Driving Routes from Radar with Weak
  Audio Supervision</font>
    </a>
  </h2>
  <font color="black">モバイルロボットの屋外での信頼性の高い展開には、特定の環境で許容可能な運転ルートを確実に特定する必要があります。したがって、ロボットの下の地形タイプを予測できる音声ベースの分類子によるレーダーベースの分類子のトレーニングを弱く監視します。 。オドメトリ、GPS、およびオーディオ分類子からのテレインラベルを組み合わせることにより、レーダースキャンのラベル付けに使用される環境内のロボットのテレインラベル付けされた軌道を構築できます。 
[ABSTRACT] fmcwスキャンレーダーに基づく知覚システムは、環境条件に関係なく、代替センサーよりも長い範囲で完全なパフォーマンスを維持します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br><font color="black">2020-05-11</font>
      </time>
    </span>
</section>
<!-- paper0: Heuristic Rank Selection with Progressively Searching Tensor Ring
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_23.html">
      <font color="black">Heuristic Rank Selection with Progressively Searching Tensor Ring
  Network</font>
    </a>
  </h2>
  <font color="black">PSTRNは、進化フェーズと進行フェーズを介して、関心領域にすばやく収束し、優れたパフォーマンスを獲得できます。一方、ランクを選択するためのヒューリスティックな方法はなく、適切なランクを見つけるための列挙方法は非常に時間がかかります。したがって、上記の現象に基づいて、プログレッシブ検索テンソルリングネットワーク検索（PSTRN）という新しいプログレッシブ遺伝的アルゴリズムを提案します。これは、最適なランクを正確かつ効率的に見つけることができます。 
[ABSTRACT] pstrnは関心領域にすばやく収束し、優れたパフォーマンスを獲得できます。ただし、この方法はパブリックベンチマークで検証されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Learning a Lie Algebra from Unlabeled Data Pairs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_24.html">
      <font color="black">Learning a Lie Algebra from Unlabeled Data Pairs</font>
    </a>
  </h2>
  <font color="black">重要なことに、パラメータ$ t_i \ in \ mathbb {R} $の値は、データペア$（\ boldsymbol {x} _i、\ boldsymbol {y} _i）$間で変化する可能性があり、事前に知る必要はありません。重要なアイデアは、すべてのターゲット$ \ boldsymbol {y} _i $をマトリックスで近似することです-$ \ boldsymbol {\ widetilde {y}} _ i = \ boldsymbol {\ phi}（t_i）\ boldsymbol {の形式のベクトル積x} _i $。ここで、行列$ \ boldsymbol {\ phi}（t_i）$は、$ \ mathrm {GL} _n（\ mathbb {R}）$の1パラメータサブグループに属しています。たとえば、ピッチ、インテンシティダイナミクス、および演奏テクニックは、音楽情報の検索において依然として難しい課題です。 
[ABSTRACT]近年、剛体運動を超えてグループを嘘に陥るディープラーニングの一般化により、球体の表面上のパターンなどの明示的な対称性を持つデータセット上にコンネットを構築できるようになりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-19">
        <br><font color="black">2020-09-19</font>
      </time>
    </span>
</section>
<!-- paper0: The Use of AI for Thermal Emotion Recognition: A Review of Problems and
  Limitations in Standard Design and Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_25.html">
      <font color="black">The Use of AI for Thermal Emotion Recognition: A Review of Problems and
  Limitations in Standard Design and Data</font>
    </a>
  </h2>
  <font color="black">熱生理学の研究は90年代後半から続けられています。しかし、人間中心のAIタスクのソースとして熱画像を採用することへの移行は容易ではなく、複数の人口統計にわたる高忠実度データソースの可用性と徹底した検証に依存しています。この研究は、医学、心理学、機械学習、光学、感情コンピューティングの交差点にあります。 
[要約]熱画像の採用への移行は容易ではなく、高忠実度データセクターの可用性に依存しています。これは、人間のAIタスクのソースとして熱画像を採用するための最初のステップです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Clustering of Electromagnetic Showers and Particle Interactions with
  Graph Neural Networks in Liquid Argon Time Projection Chambers Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_26.html">
      <font color="black">Clustering of Electromagnetic Showers and Particle Interactions with
  Graph Neural Networks in Liquid Argon Time Projection Chambers Data</font>
    </a>
  </h2>
  <font color="black">電磁（EM）アクティビティは通常、従来のアルゴリズムを使用して効率的に組み立てることが難しい、さまざまな形態と方向の空間的に分離されたフラグメントを示します。次に、最適化されたアルゴリズムは、粒子インスタンスを相互作用にクラスタリングする関連タスクに適用され、平均ARIが99.2％になります。 $ \ sim \ mathcal {O}（1）\、m ^ {-3} $の相互作用密度の場合、これは$（4.1 + 1.4 / \ sqrt {E（\ text {GeV }）}）\、\％$およびシャワー方向の解像度は$（2.1 / \ sqrt {E（\ text {GeV}）}）^ {\ circ} $です。 
[要約]アルゴンネットのパブリックlartpcシミュレーションデータセットによって画像が取得されました。アルゴリズムは97.8％のシャワークラスタリング精度を実現します。次に、粒子を相互作用にクラスタリングする関連タスクに適用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-02">
        <br><font color="black">2020-07-02</font>
      </time>
    </span>
</section>
<!-- paper0: Whole page recognition of historical handwriting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_27.html">
      <font color="black">Whole page recognition of historical handwriting</font>
    </a>
  </h2>
  <font color="black">ハンドヘルドまたは組み込みデバイスに展開できるモデルのタイプとサイズに集中します。テキストのローカリゼーションとセグメンテーションなしのページ全体の推論アプローチは競争力があると結論付けます。このために、エンドツーエンドを調査します手書きのページを取り、その全文を転記するテキストのローカリゼーションなしの推論アプローチ。 
[要約]調査により、より多くのユーザーが情報を検索できることが示されています。このアプローチを「iamフル」と呼び、「iamフリー」であると言います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Early Exit or Not: Resource-Efficient Blind Quality Enhancement for
  Compressed Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_28.html">
      <font color="black">Early Exit or Not: Resource-Efficient Blind Quality Enhancement for
  Compressed Images</font>
    </a>
  </h2>
  <font color="black">具体的には、私たちのアプローチは、ダイナミックディープニューラルネットワーク（DNN）を介して、圧縮画像の品質を盲目的に段階的に向上させます。DNNには、早期終了戦略が組み込まれています。次に、評価された方法に従って、強化を自動的に終了または続行するかを決定できます。強化された画像の品質。さらに、実際には、圧縮された画像の品質は不明であり、既存のアプローチではブラインド品質の強化に適したモデルを選択することは困難です。 
[要約]このホワイトペーパーでは、リソース効率の高いブラインド品質向上（rbqe）モデルを提案します。具体的には、私たちのアプローチは、強化された画像の評価品質に応じて、強化を自動的に終了または続行することを決定できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br><font color="black">2020-06-30</font>
      </time>
    </span>
</section>
<!-- paper0: PennSyn2Real: Training Object Recognition Models without Human Labeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_29.html">
      <font color="black">PennSyn2Real: Training Object Recognition Models without Human Labeling</font>
    </a>
  </h2>
  <font color="black">このフレームワークは設定が簡単で、幅広いオブジェクトに適用できるため、合成データと実際のデータの間のギャップが小さくなります。当社のデータ生成フレームワークは、クロマキーイング、つまりモーショントラッキングシステムを備えた成熟した映画撮影技術をブートストラップし、オブジェクトの向きとライティングが制御されている、アーティファクトのない、キュレーションされた注釈付きの画像。合成データでトレーニングされたCNNは、セマンティックセグメンテーションとオブジェクト検出設定の両方で、実際のデータでトレーニングされたものと同等のパフォーマンスを発揮します。 
[ABSTRACT] pennsyn2real-20種類以上のマイクロ航空機（mav）の4万枚以上の4k画像を含む合成データセット。これを使用して、mav検出および分類システムシステムシステム用の任意の数のトレーニング画像を生成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Classification of COVID-19 in CT Scans using Multi-Source Transfer
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_30.html">
      <font color="black">Classification of COVID-19 in CT Scans using Multi-Source Transfer
  Learning</font>
    </a>
  </h2>
  <font color="black">私たちの最高のパフォーマンスモデルは、0.893の精度と0.897のリコールスコアを達成し、ベースラインのリコールスコアを9.3％上回ることができました。利用可能なCOVID-19 CTデータが本質的に不足しているため、これらの研究努力は、転移学習の使用..マルチソースの微調整アプローチにより、モデルはImageNetで微調整されたベースラインモデルを上回りました。 
[要約]リサーチは、ct scans。からのcovid-19のたたみ込みニューラルネットワーク（cnns）でのコンピュータービジョンの使用を調査しました。19歳の人の背後にある主な理由は、信頼性の欠如とrt-pcrテストの欠如によるものです。感染率が高いのは信頼性が低いためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Detection Of Concrete Cracks using Dual-channel Deep Convolutional
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_31.html">
      <font color="black">Detection Of Concrete Cracks using Dual-channel Deep Convolutional
  Network</font>
    </a>
  </h2>
  <font color="black">この論文では、256 x 256ピクセル解像度のこれらの画像でトレーニングされたディープCNNから始めて、問題を特定することでモデルを徐々に最適化しました。研究の過程で、コンクリート亀裂のある3200のラベル付き画像のデータベースでクラックのコントラスト、照明条件、方向、深刻度が非常に変動する場所で作成されました。モデルはパフォーマンスに基づいてテストされ、機能マップを使用して分析されています。これにより、デュアルチャネル構造の重要性が確立されます。 。 
[ABSTRACT]プロジェクトは、コンクリートのひび割れを含む3200枚の画像のデータベースを使用して作成されました。現実的な状況でコンクリートのひび割れを見つける際に高い精度を示しています-</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: ALICE: Active Learning with Contrastive Natural Language Explanations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_32.html">
      <font color="black">ALICE: Active Learning with Contrastive Natural Language Explanations</font>
    </a>
  </h2>
  <font color="black">対照的な説明を組み込むことで、モデルは40〜100％多いトレーニングデータでトレーニングされたベースラインモデルよりも優れています。ALICEはまずアクティブラーニングを使用して、最も有益なラベルクラスのペアを選択し、専門家から対照的な自然言語の説明を引き出します。 。従来のアノテーションプロセスは、低帯域幅のヒューマンマシンコミュニケーションインターフェイス（分類ラベル）を使用しており、それぞれが数ビットの情報しか提供していません。 
[ABSTRACT]多数の通信データポイントに注釈を付けるとコストがかかります。トレーニング方法を使用してデータ効率を向上させます。aliceは、これらの説明からセマンティック選択パーサーを使用して知識を学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: SAMOT: Switcher-Aware Multi-Object Tracking and Still Another MOT
  Measure -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_33.html">
      <font color="black">SAMOT: Switcher-Aware Multi-Object Tracking and Still Another MOT
  Measure</font>
    </a>
  </h2>
  <font color="black">広範な実験により、本手法がすべての指標で競争力のある結果を達成することが示されています。最後に、提案されたフレームワークは、従来の手法と提案された新しい指標の両方でテストされます。SCGは、競合グラフを作成して作業することにより、1つのフレーム内の空間スイッチャーを排除します。最適な部分グラフを取り出します。 
[要約]新しいレポートは、マルチオブジェクトトラッキングの新しいシステムを提案します。このコンセプトは、新しいアイデンティティメジャーに基づいています。新しいオブジェクトを識別するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning based NAS Score and Fibrosis Stage Prediction from CT and
  Pathology Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_34.html">
      <font color="black">Deep Learning based NAS Score and Fibrosis Stage Prediction from CT and
  Pathology Data</font>
    </a>
  </h2>
  <font color="black">NAFLDの診断と治療は、NAFLD活動スコア（NAS）と肝線維症の段階に依存します。これらは通常、病理医による肝生検から評価されます。非アルコール性脂肪肝疾患（NAFLD）は、世界の人口でますます流行しています。 。適切なタイミングで診断を行わないと、NAFLDは非アルコール性脂肪性肝炎（NASH）とそれに続く肝障害を引き起こす可能性があります。 
[ABSTRACT] nafld（nafld）はnafld（nash）とその後の肝障害を引き起こす可能性があります。適切なタイミングで診断せずに、nafldはnafldをリードできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Beyond Triplet Loss: Person Re-identification with Fine-grained
  Difference-aware Pairwise Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_35.html">
      <font color="black">Beyond Triplet Loss: Person Re-identification with Fine-grained
  Difference-aware Pairwise Loss</font>
    </a>
  </h2>
  <font color="black">Person Re-IDentification（ReID）は、複数のカメラのさまざまな視点から人物を再特定することを目的としています。提案された損失は一般的なもので、プラグインとして使用して、トリプレット損失を置き換え、さまざまなタイプの最新の状態を大幅に強化できます。アートアプローチ..しかし、ほとんどの最先端のReIDアプローチは、通常3重項損失によって駆動され、大きな外観の違いを区別することに重点を置いているため、きめの細かい機能を効果的に学習できません。 
[要約]提案された損失は、多くの一般的な損失関数を大幅に上回っています。これにより、データ効率も大幅に向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: AdderSR: Towards Energy Efficient Image Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_36.html">
      <font color="black">AdderSR: Towards Energy Efficient Image Super-Resolution</font>
    </a>
  </h2>
  <font color="black">次に、特徴の分布を調整して詳細を調整するための学習可能な電源アクティベーションを開発します。ただし、計算が異なるため、大規模な画像分類でのAdderNetの成功を画像の超解像タスクに直接継承することは非常に困難です。パラダイム..いくつかのベンチマークモデルとデータセットで行われた実験は、AdderNetを使用した画像超解像モデルが、エネルギー消費を約2 $ \ times $削減して、CNNベースラインと同等のパフォーマンスと視覚的品質を達成できることを示しています。 
[ABSTRACT]たとえば、addernetはaddernetを使用して出力機能を計算し、大量のエネルギー消費を回避します。addernetは、写真認識ではなく、added機能を使用して追加機能を計算します。addernetは、cnnベースラインと同等の成功を収めることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-18">
        <br><font color="black">2020-09-18</font>
      </time>
    </span>
</section>
<!-- paper0: Frame-wise Cross-modal Match for Video Moment Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_37.html">
      <font color="black">Frame-wise Cross-modal Match for Video Moment Retrieval</font>
    </a>
  </h2>
  <font color="black">ビデオモーメントの取得は、指定された自然言語クエリのビデオでゴールデンモーメントを取得することを目標としています。このアプローチによってある程度の進歩は達成されていますが、これらの方法では、クエリとビデオフレーム間のクロスモーダルな相互作用が十分にキャプチャされていません。 ..この論文では、2つのモダリティ間の相互作用モデリングに基づいて時間的境界を予測する注意深いクロスモーダル関連性マッチング（ACRM）モデルを提案します。 
[ABSTRACT]これらのビデオがビデオストリームで検出されたのはこれが初めてです。ただし、これらの方法では、検索フレームとビデオフレーム間のクロスモーダルインタラクションが十分にキャプチャされていないとします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: A Generative Adversarial Approach with Residual Learning for Dust and
  Scratches Artifacts Removal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_38.html">
      <font color="black">A Generative Adversarial Approach with Residual Learning for Dust and
  Scratches Artifacts Removal</font>
    </a>
  </h2>
  <font color="black">具体的には、残差学習を利用して、トレーニングプロセスを高速化し、ノイズ除去のパフォーマンスを向上させます。最後に、最先端の方法とソフトウェアアプリケーションを大幅に上回り、優れた結果を提供します。レタッチにより、写真の見た目は魅力的ですが、カジュアルな写真家の多くは、専門的な方法で操作する専門知識を欠いています。 
[要約]フォトレタッチの最も難しいタスクの一部は、ほこりや傷のアーティファクトの除去です。最近の研究では、従来の方法と比較して、さまざまな自動画像処理タスクで良好な結果が得られることが証明されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Dehaze from Realistic Scene with A Fast Physics-based
  Dehazing Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_39.html">
      <font color="black">Learning to Dehaze from Realistic Scene with A Fast Physics-based
  Dehazing Network</font>
    </a>
  </h2>
  <font color="black">ただし、高品質の深度を持つ大規模なデータセットはほとんどが屋内であり、屋外の深度マップは不正確であるため、合成データセットと実際のぼんやりとした画像の間にはまだギャップがあります。このホワイトペーパーでは、既存のデータセットを新しい大規模な高精細（HD）3Dムービーからの実際の屋外シーンを含む多様な曇り除去データセット。最近の学習ベースの方法では、かすんだ画像のペアとクリーンなグラウンドトゥルースリファレンスを含むデータセットが必要ですが、実際のシーンで正確なグラウンドトゥルースをキャプチャすることは一般に不可能です。 
[ABSTRACT]信頼性の高いパフォーマンスを備えた新しい曇り除去方法は、自動運転などの多くのアプリケーションで非常に正確です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-18">
        <br><font color="black">2020-04-18</font>
      </time>
    </span>
</section>
<!-- paper0: Synthetic Training for Accurate 3D Human Pose and Shape Estimation in
  the Wild -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_40.html">
      <font color="black">Synthetic Training for Accurate 3D Human Pose and Shape Estimation in
  the Wild</font>
    </a>
  </h2>
  <font color="black">STRAPSがSSP-3Dの他の最先端の方法よりも形状予測精度の面で優れていることを示しますが、ポーズ中心のデータセットとメトリックの最先端との競争力を維持しています。キーポイント検出とセグメンテーションCNNによってテスト時に予測される、合成トレーニング入力とノイズのある実際の入力との間のデータの増大と破損をトレーニング中に使用します。これは主に、野生のトレーニングの不足によるものであることをお勧めします多様で正確な体形ラベルのあるデータ。 
[ABSTRACT]実際の正確なポーズと形状の合成トレーニングが提案されています。システムは、シルエットや2Dジョイントなどのプロキシ表現を利用しています。システムは、合成トレーニングデータでトレーニングされ、データ不足を克服しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-21">
        <br><font color="black">2020-09-21</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Learning of Non-Rigid Residual Flow and Ego-Motion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_41.html">
      <font color="black">Self-Supervised Learning of Non-Rigid Residual Flow and Ego-Motion</font>
    </a>
  </h2>
  <font color="black">さらに、点群シーケンスの時間的一貫性プロパティに基づいて、監視対象フレームワークを自己監視信号で拡張します。点群のペアからの相対的な剛体変換と、それに続く反復改良を学習することを提案します。現在のほとんどシーンフローメソッドは、3Dモーションの静的コンポーネントと動的コンポーネントを区別することなく、シーンフローをポイントごとの並進ベクトルとしてモデル化することを選択します。 
[要約]この作業では、動的3Dシーンの非剛体残差フローと自我モーションフローの同時推定によるシーンフロー学習の終了方法の代替方法を示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Point Cloud Semantic Segmentation by Learning 3D Object
  Proposal Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_42.html">
      <font color="black">Improving Point Cloud Semantic Segmentation by Learning 3D Object
  Proposal Generation</font>
    </a>
  </h2>
  <font color="black">さらに、DASSを使用して既存の2ステージ検出器の高再現率提案を生成するパイプラインを提供し、追加の監視信号を使用して3D方向推定機能を改善できることを示します。SemanticKITTIおよびKITTIオブジェクトデータセットの広範な実験により、DASS高精度のBEV検出結果を維持しながら、画像FOVで幾何学的に類似したクラスの3Dセマンティックセグメンテーション結果を最大37.8％IoU改善できます。補助3Dオブジェクトからのローカリゼーション機能を明示的に活用する、検出対応3Dセマンティックセグメンテーション（DASS）フレームワークを提案します。検出タスク。 
[要旨] ossは、幾何学的に類似したクラスの3Dセマンティックセグメンテーション結果を最大37まで改善できます。画像fovの8％iou</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Segmentation of Photovoltaic Module Cells in Electroluminescence Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_43.html">
      <font color="black">Segmentation of Photovoltaic Module Cells in Electroluminescence Images</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、94.47％の中央加重Jaccardインデックスと97.54％の$ F_1 $スコアでこのタスクをロバストに解決します。どちらも、自動的にセグメント化された太陽電池マスクとグラウンドトゥルースソーラーセルマスクの非常に高い類似性を示しています。アルゴリズムの重要なステップは、垂線型制約を利用して、レンズキャリブレーションの観点からセグメンテーション問題を定式化します。これにより、大量のデータに対する制御された研究により、時間の経過に伴うモジュールの劣化の影響を理解できます。 
[要約]提案された方法は、太陽電池モジュールのデータセットに基づいています。これには、さまざまな欠陥のある合計408個の太陽電池が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-06-18">
        <br><font color="black">2018-06-18</font>
      </time>
    </span>
</section>
<!-- paper0: An embedded deep learning system for augmented reality in firefighting
  applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_44.html">
      <font color="black">An embedded deep learning system for augmented reality in firefighting
  applications</font>
    </a>
  </h2>
  <font color="black">私たちは、消防士の個人用保護具（PPE）に組み込まれたカメラからストリーミングされたデータを利用して熱、RGBカラー、深度画像をキャプチャし、すでに開発されたディープラーニングモデルを展開して入力データを分析できる、組み込みプロトタイプシステムを設計および構築しましたリアルタイム..組み込みシステムは、ワイヤレスストリーミングを介して処理された画像を分析して返します。リモートで表示して、分析された入力の結果を視覚化し、消防士の注意をオブジェクトのオブジェクトに引き付ける拡張現実プラットフォームを使用して、消防士に中継することができます。煙や炎を通して見えないドアや窓などの関心。状況認識（つまり、現場での現在の状態や活動に関する知識）を維持することは、火災環境の安全で成功したナビゲーションに必要な正確な意思決定にとって重要です。消防士によって。 
[ABSTRACT]組み込みシステムは、ワイヤレスストリーミングを介して処理された画像を分析して返します。リモートで表示し、拡張現実プラットフォームを使用して消防士に中継することができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Curriculum Learning with Diversity for Supervised Computer Vision Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_45.html">
      <font color="black">Curriculum Learning with Diversity for Supervised Computer Vision Tasks</font>
    </a>
  </h2>
  <font color="black">トレーニング中に多様性を確保し、訪問頻度の低いクラスの要素を優先します。カリキュラムの学習手法は、従来のランダムトレーニングを難易度の高い戦略に置き換えることで、自動モデルの精度を向上させるための実行可能なソリューションです。 Pascal VOC 2007とCityscapesデータセットでオブジェクト検出とインスタンスセグメンテーション実験を行い、ランダムにトレーニングされたベースラインと標準のカリキュラムアプローチの両方を超えます。 
[ABSTRACT]標準のカリキュラムテクノロジーは自動的に改善された戦略を提供しません。しかし、それはデータ分布や提案されたモデルなどの複数の要素によって制約されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: ParSeNet: A Parametric Surface Fitting Network for 3D Point Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_46.html">
      <font color="black">ParSeNet: A Parametric Surface Fitting Network for 3D Point Clouds</font>
    </a>
  </h2>
  <font color="black">これは、以前の作業よりもはるかに豊富なプリミティブのクラスを処理し、より忠実にサーフェスを表現できるようにします。ソースコードは、https：//hippogriff.github.io/parsenet。で公開されています。分析および学習ベースの代替案に対する当社のアプローチ。 
[ABSTRACT] parsenetは、大規模な人工の3D形状のデータセットでトレーニングされます。形状分解のための高レベルの意味論的優先順位を取得します。また、表面の反復可能でロバストなパラメーター化を生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-26">
        <br><font color="black">2020-03-26</font>
      </time>
    </span>
</section>
<!-- paper0: Visual Methods for Sign Language Recognition: A Modality-Based Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_47.html">
      <font color="black">Visual Methods for Sign Language Recognition: A Modality-Based Review</font>
    </a>
  </h2>
  <font color="black">この論文は、手話の視覚的理解を範囲として人間の行動認識に関する文献をレビューすることを目的としています。分析された方法は、主に、利用されるさまざまな種類の単峰型入力、それらの相対的なマルチモーダルの組み合わせ、パイプラインの手順に従って整理されます。各セクションでは、関連するデータセットとアプローチを詳細に比較して、手話関連サービスの作成に適した、まだオープンな貢献経路を区別します。 
[要約]人間の行動認識における最近の進歩は、gpuの上昇を利用しています-大量のデータからの学習</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: MFIF-GAN: A New Generative Adversarial Network for Multi-Focus Image
  Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_48.html">
      <font color="black">MFIF-GAN: A New Generative Adversarial Network for Multi-Focus Image
  Fusion</font>
    </a>
  </h2>
  <font color="black">注意メカニズムとしてスクイーズおよび励起残余ネットワーク（SE-ResNet）モジュールがネットワークで採用されています。このホワイトペーパーでは、MFIF-GANと呼ばれる新しい生成敵対的ネットワークを提示し、マルチフォーカス画像をフォーカスマップに変換して取得します。全焦点画像をさらに.. MFIFの研究動向の1つは、焦点/焦点外れ境界（FDB）の周りの焦点外れ拡散効果（DSE）を解決することです。 
[ABSTRACT] mfifは、焦点の周りの焦点ぼけの広がり効果（dse）を解決します-焦点ぼけ境界（fdb）。焦点と焦点ぼけ境界がネットワークで使用されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-21">
        <br><font color="black">2020-09-21</font>
      </time>
    </span>
</section>
<!-- paper0: Single Image Super-Resolution for Domain-Specific Ultra-Low Bandwidth
  Image Transmission -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_49.html">
      <font color="black">Single Image Super-Resolution for Domain-Specific Ultra-Low Bandwidth
  Image Transmission</font>
    </a>
  </h2>
  <font color="black">私たちは、再構成された画像の品質と、実際の使用例におけるそのような方法の見通しを調査することを目的としています。次に、ニューラルネットワークをトレーニングして、アップサンプリングを実行し、元の画像を再構成します。 
[ABSTRACT]これにより、このようなチャネルは使用できなくなったり、効率が悪くなったりします。これは、長年の釣りで得られた大規模で多様なデータセットで調査されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-09">
        <br><font color="black">2020-09-09</font>
      </time>
    </span>
</section>
<!-- paper0: ROAM: Random Layer Mixup for Semi-Supervised Learning in Medical Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CV/paper_50.html">
      <font color="black">ROAM: Random Layer Mixup for Semi-Supervised Learning in Medical Imaging</font>
    </a>
  </h2>
  <font color="black">ROAMはこれまでにないデータポイントをより多く生成するため、過剰適合を回避し、汎化能力を強化します。このオプションは制限されていると私たちは主張します。ROAMは完全に監視された状態で最先端の（SOTA）結果を達成します（89.5 \％）および半教師あり（87.0 \％）の設定では、脳全体のセグメンテーションでそれぞれ最大2.40 \％および16.50 \％の相対的な改善が見られます。 
[要約]深い学習方法は、大量の注釈付きデータに大きく依存します。これには時間がかかり、コストがかかります。ロームは、これまでにないデータポイントを生成するため、過剰適合を回避し、汎化機能を強化します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-20">
        <br><font color="black">2020-03-20</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: SUMBT+LaRL: End-to-end Neural Task-oriented Dialog System with
  Reinforcement Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_0.html">
      <font color="black">SUMBT+LaRL: End-to-end Neural Task-oriented Dialog System with
  Reinforcement Learning</font>
    </a>
  </h2>
  <font color="black">エンドツーエンドの対話システムに強化学習の新しい成功基準を提案するだけでなく、成功基準と評価方法に応じて異なる結果の側面に関する実験的分析を提供します。SUMBT+は、ユーザーの行動と対話の信念の状態を推定します、およびLaRLは潜在的なシステムアクションスペースをモデル化し、推定されたコンテキストに基づいて応答を生成します。その結果、私たちのモデルは、コーパスベースの評価で85.4％の新しい最先端の成功率と、81.40の同等の成功率を達成しましたDSTC8チャレンジによって提供されるシミュレーターベースの評価の％。 
[要約]このペーパーでは、エンドツーエンドのトレーニング可能なニューラルダイアログシステムを提案します。sumntlarlと呼ばれ、システムは微調整されているため、ダイアログの成功率が大幅に向上します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Reinforcement Learning for On-line Dialogue State Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_1.html">
      <font color="black">Deep Reinforcement Learning for On-line Dialogue State Tracking</font>
    </a>
  </h2>
  <font color="black">DSTとポリシーの両方の共同トレーニングにより、パフォーマンスをさらに向上させることができます。実験により、オンラインDST最適化により、事前定義されたポリシーを使用する柔軟性を維持しながら、対話マネージャーのパフォーマンスを効果的に向上できることがわかります。オンラインDST最適化のための学習（DRL）フレームワークが提案されています。 
[ABSTRACT]これは、オンライン音声対話システム用のdrlフレームワークのdstモジュールを最適化する最初の取り組みです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Translation of Programming Languages -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_2.html">
      <font color="black">Unsupervised Translation of Programming Languages</font>
    </a>
  </h2>
  <font color="black">また、852個の並列関数で構成されるテストセットをビルドしてリリースし、翻訳の正確さを確認する単体テストも提供しています。残念ながら、結果として得られる翻訳は読みやすさに欠けることが多く、ターゲット言語の規則を順守できず、手動で変更する必要があります。正常に動作します。.ニューラルモデルは、自然言語翻訳のコンテキストではルールベースのモデルよりも大幅に優れていますが、このドメインでは並列データが不足しているため、トランスコンパイルへの適用は制限されています。 
[ABSTRACT]トランスコンパイラーは主に相互運用性のために使用され、廃止または非推奨の言語で記述されたコードベースを移植します。これらは通常、ソースコードに適用される手作りの書き換えルールに依存します。 -費用のかかる翻訳修正</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-05">
        <br><font color="black">2020-06-05</font>
      </time>
    </span>
</section>
<!-- paper0: Chart-based Zero-shot Constituency Parsing on Multiple Languages -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_3.html">
      <font color="black">Chart-based Zero-shot Constituency Parsing on Multiple Languages</font>
    </a>
  </h2>
  <font color="black">さらに、英語以外の言語を調べることにより、ゼロショット解析アプリケーションの範囲を広げます。最後に、多言語PLMをゼロショット解析フレームワークに導入し、9つの言語の文に対して妥当な解析を生成できることを確認します。具体的には、まず、このアプローチがそれぞれの単一言語PLMを備えた言語に適用できることを示します。 
[ABSTRACT]新しい論文は、新しいチャートベースの方法と効果的なアンサンブル手法を組み合わせて使用し、英語のptbで他の教師なしパーサーに匹敵するパフォーマンスを実現します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br><font color="black">2020-04-08</font>
      </time>
    </span>
</section>
<!-- paper0: wav2vec 2.0: A Framework for Self-Supervised Learning of Speech
  Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_4.html">
      <font color="black">wav2vec 2.0: A Framework for Self-Supervised Learning of Speech
  Representations</font>
    </a>
  </h2>
  <font color="black">wav2vec 2.0は、潜在空間での音声入力をマスクし、共同学習される潜在表現の量子化で定義された対照的なタスクを解決します。ラベル付きデータを10分だけ使用し、ラベルなしデータを53k時間事前トレーニングすると、5.2 / 8.6 Librispeechのノイズの多い/クリーンなテストセットでのWER ..ラベル付きデータの量を1時間に減らすと、wav2vec 2.0は100時間サブセットのラベル付きデータを使用しながら、従来の100時間サブセットのパフォーマンスよりも優れています。 
[要旨] wav2vec 2。 0は、潜在空間での音声入力をマスクします。それは、共同で学習される3r表現の量子化に対して定義された対照的なタスクを解決します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-20">
        <br><font color="black">2020-06-20</font>
      </time>
    </span>
</section>
<!-- paper0: A Crowdsourced Open-Source Kazakh Speech Corpus and Initial Speech
  Recognition Baseline -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_5.html">
      <font color="black">A Crowdsourced Open-Source Kazakh Speech Corpus and Initial Speech
  Recognition Baseline</font>
    </a>
  </h2>
  <font color="black">高品質を保証するために、カザフ語のネイティブスピーカーによって慎重に検査されました。このホワイトペーパーでは、最初にデータ収集と推測の手順を説明し、次にデータベースの仕様を説明します。カザフ語スピーチコーパス（KSC）には、約335時間の筆記さまざまな地域、年齢層、性別の参加者が話す154,000以上の発話からなる音声。 
[要約]カザフ語スピーチコーパス（ksc）には、154,000を超える発話が含まれています。これは、さまざまなカザフ語スピーチおよび言語処理アプリケーションを進めるために開発された、公的に利用可能な最大のデータベースです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Constructing interval variables via faceted Rasch measurement and
  multitask deep learning: a hate speech application -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_6.html">
      <font color="black">Constructing interval variables via faceted Rasch measurement and
  multitask deep learning: a hate speech application</font>
    </a>
  </h2>
  <font color="black">ターゲット結果の理論化されたコンポーネントの評価は、ニューラルネットワークの内部概念学習の教師付き順序変数として使用されます。YouTube、Twitter、Redditから供給され、ラベルが付けられた50,000のソーシャルメディアコメントのデータセットでこの新しい方法を示しますヘイトスピーチから反スピーチまでの連続スペクトルを測定するために、11,000人の米国を拠点とするAmazon Mechanical Turkワーカー。ターゲットの構成、この場合はヘイトスピーチを、通常の調査項目としてラベル付けされた複数の構成要素に分解します。 
[ABSTRACT]対象の構成要素、この場合はヘイトスピーチを、通常の調査項目としてラベル付けされた複数の構成要素に分解します。当社の方法は、人間のラベラーの調査解釈バイアスを推定し、生成された連続測定への影響を排除します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: GRACE: Gradient Harmonized and Cascaded Labeling for Aspect-based
  Sentiment Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_7.html">
      <font color="black">GRACE: Gradient Harmonized and Cascaded Labeling for Aspect-based
  Sentiment Analysis</font>
    </a>
  </h2>
  <font color="black">極性シーケンスは、生成されたアスペクト項ラベルに依存するように設計されています。これらの問題を解決するために、GRadient hArmonizedおよびCascadEdラベリングモデル（GRACE）を提案します。実験結果は、提案されたモデルが複数のベンチマークデータセットで一貫性の改善を達成し、状態を生成することを示しています-最先端の結果。 
[要約]提案されたモデルは、複数のベンチマークデータセットで一貫性の向上を達成し、最先端の結果を生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Event Coreference Resolution via a Multi-loss Neural Network without
  Using Argument Information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_8.html">
      <font color="black">Event Coreference Resolution via a Multi-loss Neural Network without
  Using Argument Information</font>
    </a>
  </h2>
  <font color="black">したがって、イベント引数の抽出から伝播されるエラーを減らし、コンテキスト情報を効果的に使用するために、ドキュメント内のイベントの相互参照解決タスクを実行して大きなパフォーマンスを達成するために引数情報を必要としないマルチロスニューラルネットワークモデルを提案します最新のメソッドよりも..イベント相互参照解決（ECR）は自然言語処理（NLP）の重要なタスクであり、このタスクへの既存のアプローチのほとんどすべてがイベント引数情報に依存しています。言及にはイベントのすべての引数が含まれており、引数情報は、イベントが実際のテキストでイベントの相互参照を検出する引数を持っているというモデルを混乱させる可能性があります。 
[ABSTRACT]引数argument argumentの重要な例。ただし、これらのメソッドは「コンテキスト」の影響を受ける傾向があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Logical foundations for hybrid type-logical grammars -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_9.html">
      <font color="black">Logical foundations for hybrid type-logical grammars</font>
    </a>
  </h2>
  <font color="black">ハイブリッド型論理文法の論理的基礎を明らかにすることに加えて、現在の研究は、非連想バージョンや構造ルールと単項モードを組み込んだマルチモーダルバージョンなど、元のシステムのバリアントと拡張への道を開きます。 。このホワイトペーパーでは、ハイブリッド型論理文法、つまりLambek文法とLambda文法を組み合わせた論理の証明論的側面について説明します。正規化や部分式のプロパティなど、計算のいくつかの基本的なプロパティを証明し、シーケントと証明の両方を示します。ハイブリッド型論理文法のネット計算。 
[ABSTRACT]正規化やサブ数式プロパティなど、数式のいくつかの基本プロパティを証明します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Causal Explanation Detection with Pyramid Salient-Aware Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_10.html">
      <font color="black">Towards Causal Explanation Detection with Pyramid Salient-Aware Network</font>
    </a>
  </h2>
  <font color="black">PSANは、キーワードに含まれる談話の顕著なセマンティクスを下部のグラフベースの単語レベルの顕著なネットワークでキャプチャすることにより、因果的説明の検出を支援できます。原因説明分析（CEA）は、毎日のイベントの背後にある理由を理解するのに役立ちます。メッセージの一貫性を理解するのに非常に役立ちます。さらに、PSANは、トップアテンションベースの談話レベルの顕著なネットワークを介して談話の優位性を変更して、メッセージの説明的なセマンティクスを強化できます。 
[要約] psanは、タスクに関する1.8の「因果的説明の検出」により、最先端の方法よりも優れています。調査は、ceaのデータセットに基づいていました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Speech Recognition and Disfluency Removal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_11.html">
      <font color="black">End-to-End Speech Recognition and Disfluency Removal</font>
    </a>
  </h2>
  <font color="black">エンドツーエンドのモデルが流暢な筆記録を直接生成することを学習することを示します。ただし、それらのパフォーマンスは、ASRシステムとディスフルエンシー検出モデルで構成されるベースラインパイプラインアプローチよりも少し悪いです。ディスフルエンシー検出は、通常、自動音声認識（ASR）システムとダウンストリームタスクの間の中間ステップです。統合されたASRモデルとディスフルエンシーモデルの評価に使用できる新しいメトリック。 
[ABSTRACT]新しい論文は、流暢性の除去のためのモデルのタスクを調査することを目的としています。また、asrシステムと流暢さの検出を調査することを目的としています。調査結果は、さらなる研究のベンチマークとして役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Glushkov's construction for functional subsequential transducers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_12.html">
      <font color="black">Glushkov's construction for functional subsequential transducers</font>
    </a>
  </h2>
  <font color="black">生成されたオートマトンは非常にコンパクトです。元の式の（入力アルファベットからの）シンボルごとに1つの状態と、シンボルの範囲ごとに1つのトランジションのみが含まれているためです。オートマトン評価中..この記事では、このアルゴリズムの可能な拡張と最適化の無駄な範囲を示すよう努めています。 
[ABSTRACT]この記事では、可能な拡張の無駄な範囲を示すよう努めています。オートマトンには、元の式の各シンボルに対して1つの状態のみが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Global-to-Local Neural Networks for Document-Level Relation Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_13.html">
      <font color="black">Global-to-Local Neural Networks for Document-Level Relation Extraction</font>
    </a>
  </h2>
  <font color="black">エンティティグローバル表現はドキュメント内のすべてのエンティティの意味情報をモデル化し、エンティティローカル表現は特定のエンティティの複数の言及のコンテキスト情報を集約し、コンテキスト関係表現は他の関係のトピック情報をエンコードします。実験結果は、このモデルが優れたパフォーマンスを達成することを示していますドキュメントレベルのREの2つのパブリックデータセットについて。長距離のエンティティ間の関係を抽出し、複数の言及がある場合に特に効果的です。 
[ABSTRACT]システムでは、ドキュメント全体にわたってエンティティと言及についての複雑な推論が必要です。これは、長距離のエンティティ間の関係を抽出し、複数の言及がある場合に特に効果的です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: ALICE: Active Learning with Contrastive Natural Language Explanations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_14.html">
      <font color="black">ALICE: Active Learning with Contrastive Natural Language Explanations</font>
    </a>
  </h2>
  <font color="black">アリスを鳥類分類と社会的関係分類の2つの視覚認識タスクに適用しました。アリスは、アクティブラーニングを使用して、最も有益なラベルクラスのペアを選択し、専門家から対照的な自然言語の説明を引き出すことを学習します。最後に、抽出された学習モデルの構造を動的に変更することによる知識。 
[ABSTRACT]多数の通信データポイントに注釈を付けるとコストがかかります。トレーニング方法を使用してデータ効率を向上させます。aliceは、これらの説明からセマンティック選択パーサーを使用して知識を学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Context-theoretic Semantics for Natural Language: an Algebraic Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_15.html">
      <font color="black">Context-theoretic Semantics for Natural Language: an Algebraic Framework</font>
    </a>
  </h2>
  <font color="black">コンテキスト理論はフレームワークの実装です。実装では、文字列は、理論的分析から推定された特性を持つベクトルとして表されます。この仮定に基づいて、単語のベクトル表現は、フィールド上の代数の要素と見なすことができることを示すことができます。単語の意味を表すためのベクトル空間の基礎となる格子構造があります。ラティスの部分的な順序付けを意味間の含意を記述するものとして解釈します。 
[要約]単語列の意味は、コーパスモデル内で発生する環境を表すコロンであると想定されます。理論的分析は、意味がコンテキストによって決定されると想定しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Beat the AI: Investigating Adversarial Human Annotation for Reading
  Comprehension -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_16.html">
      <font color="black">Beat the AI: Investigating Adversarial Human Annotation for Reading
  Comprehension</font>
    </a>
  </h2>
  <font color="black">敵対的に収集されたサンプルに関するトレーニングは、敵対的に収集されたデータセットへの強力な一般化につながるが、ますます強力なインザループモデルによりパフォーマンスが低下することがわかります。設定、アノテーションループ内の段階的に強力なモデルで合計36,000のサンプルを収集します。さらに、強力なモデルは、実質的に弱いループ内モデルで収集されたデータセットからも学習できることがわかります。 
[ABSTRACT]これにより、敵対効果の再現性などの質問を調査できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-02">
        <br><font color="black">2020-02-02</font>
      </time>
    </span>
</section>
<!-- paper0: Vector Projection Network for Few-shot Slot Tagging in Natural Language
  Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_17.html">
      <font color="black">Vector Projection Network for Few-shot Slot Tagging in Natural Language
  Understanding</font>
    </a>
  </h2>
  <font color="black">特に、ベンチマークSNIPSとNERの5ショット設定では、私たちのメソッドは最強の数ショット学習ベースラインよりもF $ _1 $スコアでそれぞれ$ 6.30 $および$ 13.79 $ポイントを上回っています。対照的な実験は、提案されたベクトル投影がベースの類似性メトリックは、他のバリアントを大幅に上回ります。基本的に、このアプローチは、適応バイアスを持つ正規化線形モデルと同等です。 
[ABSTRACT]新しい研究は、数ショットスロットのタグ付けのための新しいシステムを提案します。それは、単語としての各ターゲットラベル上の文脈的な単語の埋め込みの予測を悪用します-ラベルの類似性</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-21">
        <br><font color="black">2020-09-21</font>
      </time>
    </span>
</section>
<!-- paper0: Dual Learning for Dialogue State Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_18.html">
      <font color="black">Dual Learning for Dialogue State Tracking</font>
    </a>
  </h2>
  <font color="black">これをプライマルトラッカーエージェントをデュアルDSTと呼びます。デュアル学習フレームワークには、プライマルトラッカーエージェント（発話から状態ジェネレータ）とデュアル発話ジェネレータエージェント（状態から発話ジェネレータ）の2つのエージェントがあります。 ..従来の教師あり学習フレームワークと比較して、二重学習は、ラベル付けされたデータなしで、再構成エラーと報酬信号を介して両方のエージェントを繰り返し更新できます。 
[要約]デュアルラーニングは、ラベル付けされたデータなしで、再構成エラーと報酬信号を介して両方のエージェントを繰り返し更新できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: AutoRC: Improving BERT Based Relation Classification Models via
  Architecture Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_19.html">
      <font color="black">AutoRC: Improving BERT Based Relation Classification Models via
  Architecture Search</font>
    </a>
  </h2>
  <font color="black">この作業では、BERTベースのRCモデルの包括的な検索スペースを設計し、ニューラルアーキテクチャ検索（NAS）手法を使用して、上記の設計の選択肢を自動的に発見します。アブレーション研究は、検索スペースの設計の必要性と検索の有効性を示していますmethod .. 7つのベンチマークRCタスクでの実験は、この方法が、BERTベースのベースラインRCモデルよりも優れたアーキテクチャを見つけるのに効率的かつ効果的であることを示しています。 
[ABSTRACT]エンティティスパンの識別には複数の選択肢があります。これは、関係タイプを分類するのに役立つ機能を手動で決定することが難しいためです。調査により、この方法がより優れたアーキテクチャを見つけるのに効率的かつ効果的であることが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: PodSumm -- Podcast Audio Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_20.html">
      <font color="black">PodSumm -- Podcast Audio Summarization</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、データセットでROUGE-F（1/2 / L）スコア0.63 / 0.53 / 0.63を達成します。このタスクのデータセットの欠如に動機付けられて、内部データセットをキュレートし、データ拡張のための効果的なスキームを見つけます。アノテーターから要約を収集するためのプロトコルを設計します。このホワイトペーパーでは、テキストドメインからのガイダンスを介して、ポッドキャストの要約を自動的に作成する方法を示します。 
[ABSTRACT]リスナーは、ポッドキャストクリエイターが提供するエピソードのテキスト説明に依存することが多い</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Distributed Structured Actor-Critic Reinforcement Learning for Universal
  Dialogue Management -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_21.html">
      <font color="black">Distributed Structured Actor-Critic Reinforcement Learning for Universal
  Dialogue Management</font>
    </a>
  </h2>
  <font color="black">逐次システム意思決定プロセスは、部分的に観察可能なマルコフ意思決定プロセス（POMDP）に抽象化できます。タスク指向の音声対話システム（SDS）は、特定のタスク（ホテルの予約など）を達成する人間のユーザーを支援することを目的としています。この作業では、ユーザーに応答するダイアログアクションを選択するポリシーの考案にのみ焦点を当てます。 
[ABSTRACT]対話管理はsdsの中核部分です。ユーザーに応答することを決定するポリシーを作成する方法があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Structured Hierarchical Dialogue Policy with Graph Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_22.html">
      <font color="black">Structured Hierarchical Dialogue Policy with Graph Neural Networks</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、グラフニューラルネットワーク（GNN）の柔軟性を利用して、これらの問題に対処します。複数の場所でのレストラン予約などの複合タスクのダイアログポリシートレーニングは、実用的に重要で挑戦的な問題です。学習（HDRL）メソッドは、複合タスクで優れたパフォーマンスを実現しています。 
[ABSTRACT]レストランの構造をモデル化するための新しいコムネットが提案されています。インタラクティブプロジェクトのネットワークを開発するために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Let's Stop Incorrect Comparisons in End-to-end Relation Extraction! -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_23.html">
      <font color="black">Let's Stop Incorrect Comparisons in End-to-end Relation Extraction!</font>
    </a>
  </h2>
  <font color="black">このメタ分析は、評価設定とデータセット統計の両方のレポートで厳密性の必要性を強調し、エンドツーエンドREで評価設定を統一することを求めます。次に、小規模な実証研究を提案して、最も一般的な間違いと評価は、ACE05での最終的なREパフォーマンスを約5％過大評価することにつながります。記事は、以前の作業と比較して信頼性の低いパフォーマンスを示しています。 
[ABSTRACT]最初に、公開された論文で無効な比較のパターンを特定します。それらは、それらの伝染を回避するためにそれらを記述します。また、この機会を利用して、最近の2つの進展のアブレーションを研究します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: An Empirical Study on Neural Keyphrase Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_24.html">
      <font color="black">An Empirical Study on Neural Keyphrase Generation</font>
    </a>
  </h2>
  <font color="black">この研究が、キーフレーズ生成タスクを取り巻く不確実性のいくつかを明らかにし、このトピックに関する将来の研究を促進するのに役立つことを願っています。キーフレーズ生成タスクのモデルパフォーマンスは、深層学習の進化とともに大幅に向上しました。この経験的研究では、広範な実験結果を提供し、キーフレーズ生成モデルのパフォーマンスに影響を与える最も重要な要因を分析することにより、このギャップ。 
[要約]キーフレーズ生成タスクのモデルパフォーマンスは、深層学習の進化とともに大幅に向上しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: A Study in Improving BLEU Reference Coverage with Diverse Automatic
  Paraphrasing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_25.html">
      <font color="black">A Study in Improving BLEU Reference Coverage with Diverse Automatic
  Paraphrasing</font>
    </a>
  </h2>
  <font color="black">ただし、これらの言い換えが、評価されるMT出力に最も関連するスペースの部分を具体的に対象とする場合、より良い結果が得られることも示します。WMT19メトリックタスクの英語への方向に関する実験（両方で）システムと文のレベル）は、言い換えの参照を使用すると一般にBLEUが改善されることを示しています。そうすると、より多様性が向上します。さらに、人間の言い換えを使用しても、利益はわずかに留まり、BLEUが正しく活用する能力に固有の制限があることを示唆しています。複数の参照。 
[要約]言い換えは、有効な翻訳のスペースをより適切にカバーできます。ただし、妥当性はそれほど重要ではないように思われます。強力なサンプリングアプローチの高い結果は、文レベルのブルーで使用した場合に人間の言い換えを上回ります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: A Deep Learning Approach to Geographical Candidate Selection through
  Toponym Matching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_26.html">
      <font color="black">A Deep Learning Approach to Geographical Candidate Selection through
  Toponym Matching</font>
    </a>
  </h2>
  <font color="black">さまざまな困難なシナリオ（言語間や地域の違い、OCRエラーなど）をカバーする、いくつかの新しい現実的なデータセットに基づいて、固有の音韻一致評価を実行します。候補の選択は、参照できる潜在的なエンティティを識別するタスクです既存のデータセットと、19世紀の英語のOCRテキストの手動で注釈を付けた新しいリソースの両方で、トポニム解決のダウンストリームタスクのコンテキストでの候補選択のパフォーマンスを報告します。 
[ABSTRACT]この論文では、最先端のニューラルネットワークアーキテクチャを使用した、トポニムマッチングによる候補選択のための柔軟な深層学習手法を紹介します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: CREDIT: Coarse-to-Fine Sequence Generation for Dialogue State Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_27.html">
      <font color="black">CREDIT: Coarse-to-Fine Sequence Generation for Dialogue State Tracking</font>
    </a>
  </h2>
  <font color="black">対話システムでは、対話状態トラッカーは、対話履歴全体に基づいて、現在の対話状態のコンパクトな表現を正確に見つけることを目的としています。マークされた言語シーケンスである構造化状態表現を利用して、さらに微調整できますポリシー勾配法を使用して自然言語メトリックを最適化することにより、事前にトレーニングされたモデル（教師あり学習による）。すべての生成状態追跡メソッドと同様に、CREDITはすべての可能なスロット値を列挙する事前定義されたダイアログオントロジーに依存しません。 
[ABSTRACT]新しい論文では、シーケンス生成問題として構造化状態表現とキャストダイアログ状態追跡を採用しています。構造に基づいて、自然言語メトリックを最適化することにより、事前トレーニング済みモデルを正確に最適化できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: CodeBLEU: a Method for Automatic Evaluation of Code Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_28.html">
      <font color="black">CodeBLEU: a Method for Automatic Evaluation of Code Synthesis</font>
    </a>
  </h2>
  <font color="black">CodeBLEUと、テキストからコードへの変換、コード変換、およびコードの改良という3つのコード合成タスクでプログラマーによって割り当てられた品質スコア間の相関係数を評価することにより、実験を行います。これは、n-gramのBLEUの強度を吸収します。抽象構文ツリー（AST）を介してコード構文を照合し、データフローを介してコードセマンティクスをさらに注入します。実験結果は、提案されたCodeBLEUが、BLEUや精度と比較して、プログラマーが割り当てたスコアとの相関性を向上できることを示しています。 
[ABSTRACT] bleuはもともと自然言語を評価するために設計されています。完全な精度は厳しすぎるため、さまざまな出力を過小評価します。実験結果は、提案されたcodebleuがbleuや精度と比較してより良い相関を達成できることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: SQuARE: Semantics-based Question Answering and Reasoning Engine -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/cs.CL/paper_29.html">
      <font color="black">SQuARE: Semantics-based Question Answering and Reasoning Engine</font>
    </a>
  </h2>
  <font color="black">SQuAREは、高精度を維持しながら回答の説明を生成することもできます。私たちのアプローチは、純粋に（常識）推論に基づいています。VerbNetプリミティブをセマンティック代数として使用し、部分ツリーに基づく新規アルゴリズムを使用して、このフレームワークのアプリケーションを示しますテキスト内の知識を表す回答セットプログラムを生成するマッチング。 
[ABSTRACT]理解機能はテキストをその常識的な意味にマッピングします。質問は同じフレームワークを使用してasp質問に変換されます。これにより、高精度を維持しながら回答の説明が生成されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: wav2vec 2.0: A Framework for Self-Supervised Learning of Speech
  Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.AS/paper_0.html">
      <font color="black">wav2vec 2.0: A Framework for Self-Supervised Learning of Speech
  Representations</font>
    </a>
  </h2>
  <font color="black">わずか10分のラベル付きデータを使用し、53k時間のラベルなしデータを事前トレーニングすると、Librispeechのノイズの多い/クリーンなテストセットで5.2 / 8.6 WERが達成されます。ラベル付きデータの量を1時間に減らすと、wav2vec 2.0は以前のパフォーマンスよりも優れています。ラベル付きデータを100分の1に減らしながら、100時間のサブセットで最先端の技術を使用します。wav2vec2.0は、潜在空間の音声入力をマスクし、共同学習される潜在表現の量子化で定義された対照的なタスクを解決します。 
[要旨] wav2vec 2。 0は、潜在空間での音声入力をマスクします。それは、共同で学習される3r表現の量子化に対して定義された対照的なタスクを解決します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-20">
        <br><font color="black">2020-06-20</font>
      </time>
    </span>
</section>
<!-- paper0: Personalized Speech2Video with 3D Skeleton Regularization and Expressive
  Body Poses -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.AS/paper_1.html">
      <font color="black">Personalized Speech2Video with 3D Skeleton Regularization and Expressive
  Body Poses</font>
    </a>
  </h2>
  <font color="black">モーションの詳細を含む写実的で高解像度のビデオを作成するために、条件付きGANにパーツアテンションメカニズムを挿入することを提案します。スケルトンの動きを現実的で表現力豊かにするために、3Dの人間の骨格の知識と学習した個人の音声の象徴的なジェスチャーの辞書を、パイプラインの学習とテストの両方の生成プロセスに埋め込みます。彼ら自身の差別。 
[ABSTRACT]スケルトンの動きは、リカレントニューラルネットワーク（rnn）を使用して生成されます。次に、条件付き多関節3 dネットワーク（gan）を介して出力ビデオを合成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-17">
        <br><font color="black">2020-07-17</font>
      </time>
    </span>
</section>
<!-- paper0: A Crowdsourced Open-Source Kazakh Speech Corpus and Initial Speech
  Recognition Baseline -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.AS/paper_2.html">
      <font color="black">A Crowdsourced Open-Source Kazakh Speech Corpus and Initial Speech
  Recognition Baseline</font>
    </a>
  </h2>
  <font color="black">高品質を確保するために、ネイティブのカザフ語話者によって注意深く検査されました。カザフ語のオープンソース音声コーパスを提示します。KSCは、さまざまなカザフ語の音声および言語処理アプリケーションを進めるために開発された最大の公開データベースです。 
[要約]カザフ語スピーチコーパス（ksc）には、154,000を超える発話が含まれています。これは、さまざまなカザフ語スピーチおよび言語処理アプリケーションを進めるために開発された、公的に利用可能な最大のデータベースです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: TinySpeech: Attention Condensers for Deep Speech Recognition Neural
  Networks on Edge Devices -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.AS/paper_3.html">
      <font color="black">TinySpeech: Attention Condensers for Deep Speech Recognition Neural
  Networks on Edge Devices</font>
    </a>
  </h2>
  <font color="black">これらの結果は、デバイス上の音声認識用の非常に効率的なディープニューラルネットワークを構築するためのアテンションコンデンサーの有効性を示すだけでなく、エッジでディープラーニングを加速し、幅広いTinyMLアプリケーションに力を与える可能性を明らかにします。限られた語彙の音声認識のためのGoogle Speech Commandsベンチマークデータセットは、TinySpeechネットワークが大幅に低いアーキテクチャの複雑さ（$ 507 \ times $少ないパラメーター）および低い計算の複雑さ（$ 48 \ times $少ない乗算-加算操作）を達成したことを示しました。以前の作業と比較して..その有効性を説明するために、特にマイクロコントローラーの操作の制約で特別に調整された、機械駆動の設計探索戦略を使用して、デバイス上の音声認識用に調整された注意コンデンサーで構成されるTinySpeech、低精度のディープニューラルネットワークを紹介します。 。 
[要約]音声認識用のディープニューラルネットワークは依然として課題です。これは主にメモリとコンピューティングリソースの不足が原因です。しかし、音声認識の広範な使用は依然として課題です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Learning of Speech 2D Feature-Trajectory for Prosthetic Hands -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.AS/paper_4.html">
      <font color="black">End-to-End Learning of Speech 2D Feature-Trajectory for Prosthetic Hands</font>
    </a>
  </h2>
  <font color="black">汎用グラフィックスプロセッシングユニット（GPGPU）の最近の進歩により、インテリジェントデバイスでディープニューラルネットワークをリアルタイムで実行できるようになりました。このCNNでの実験では、実行時間0.119および20ミリ秒の二乗平均平方根誤差により、対応する軌道出力が生成されます。音声入力データに..音声コマンドは、義手のマルチモーダル制御の重要な部分です。 
[要旨]音声コマンドは、義手をマルチモーダルに制御する上で不可欠な要素です。自動音声認識システムには、人間の音声をテキストにマッピングする方法が学習されます。従来の音声のパフォーマンス-制御された義手はまだ不十分です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Speech Recognition and Disfluency Removal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-23/eess.AS/paper_5.html">
      <font color="black">End-to-End Speech Recognition and Disfluency Removal</font>
    </a>
  </h2>
  <font color="black">個別の流暢性検出モデルに依存せずに、流暢な発話を流暢な筆記録に直接マップするようにASRモデルをトレーニングできるかどうかを具体的に検討します。このホワイトペーパーの調査結果は、最終的なタスクのさらなる研究のベンチマークとして役立ちます。エンドツーエンドの音声認識と将来の流暢さの除去。エンドツーエンドのモデルが流暢な筆記録を直接生成することを学習することを示します。ただし、それらのパフォーマンスは、ASRシステムとディスフルエンシー検出モデルで構成されるベースラインパイプラインアプローチよりもわずかに劣ります。 
[ABSTRACT]新しい論文は、流暢性の除去のためのモデルのタスクを調査することを目的としています。また、asrシステムと流暢さの検出を調査することを目的としています。調査結果は、さらなる研究のベンチマークとして役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
