<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-03-27の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Speech Quality Factors for Traditional and Neural-Based Low Bit Rate
  Vocoders -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-27/cs.SD/paper_0.html">
      Speech Quality Factors for Traditional and Neural-Based Low Bit Rate
  Vocoders
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      主観的品質評価の結果は、既存の完全参照音声品質測定基準と十分に相関していません。公的に入手可能なデータベースから取得した音声サンプルのいくつかのパフォーマンス測定基準を主観的スコアと比較しました。低ビットレートで。 
[要約]公に利用可能なデータベースからの音声データの分析は、人々のスコアと比較されました。結果は、音声品質を正確に予測するための新しいメトリックを開発するために使用される音声信号の側面への貴重な洞察を提供します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-26">
        <br>2020-03-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Non-parallel Voice Conversion System with WaveNet Vocoder and Collapsed
  Speech Suppression -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-27/cs.SD/paper_1.html">
      Non-parallel Voice Conversion System with WaveNet Vocoder and Collapsed
  Speech Suppression
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、LPCDCによって引き起こされる悪影響を緩和するために、LPCDCが問題のあるセグメントにのみ適用され、品質の損失を短期間に制限することを保証するために、折りたたみ音声セグメント検出器（CSSD）を提案します。問題に取り組むために、従来のボコーダーで生成された音声を参照音声として使用して、線形予測符号化分布制約（LPCDC）を導出し、折りたたまれた音声の問題を回避します。この論文では、単純な非並列音声変換（VC）システムをWaveNet（WN）ボコーダーと提案された折りたたみ音声抑制技術。 
[ABSTRACT] wnは、忠実度の高い音声波形を作成するためのボコーダーです。これにより、折りたたみ音声の問題を含む折りたたみ音声システムが作成されます。提案された方法は、以前の非平行制限の音声品質をさらに改善します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-26">
        <br>2020-03-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: In defence of metric learning for speaker recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-27/cs.SD/paper_2.html">
      In defence of metric learning for speaker recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、VoxCelebデータセットでの話者認識に関する最新の損失関数の広範な評価を示します。バニラのトリプレット損失でも、分類ベースの損失と比較して競争力のあるパフォーマンスを示し、角度メトリック学習目標で訓練されたものを示します最先端の方法よりも優れています。このペーパーの目的は、目に見えない話者の「オープンセット」話者認識です。この場合、理想的な埋め込みにより、クラス内の小さな発話レベルの表現に情報を凝縮できます。 （同じスピーカー）と大きなクラス間（異なるスピーカー）の距離。 
[要約]バニラのトリプレット損失でさえ、分類ベースの損失と比較して競争力のあるパフォーマンスを示すことを実証しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-26">
        <br>2020-03-26
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: A Label Proportions Estimation Technique for Adversarial Domain
  Adaptation in Text Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-27/cs.CL/paper_0.html">
      A Label Proportions Estimation Technique for Adversarial Domain
  Adaptation in Text Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この研究では、ラベルシフトによるテキスト分類の教師なしドメイン適応に焦点を当て、ラベル比率推定（DAN-LPE）フレームワークを使用したドメイン敵対ネットワークを導入します。実験により、DAN-LPEがターゲットラベル分布の良好な推定を達成し、分類シフトのパフォーマンスを向上させるためにラベルシフトを削減します。場合によっては、ラベルシフトが大きくなり、DANNがドメイン不変の機能を学習できないことがあります。 
[ABSTRACT]ドメイン-敵対的なニューラルネットワーク（dann）とそのバリアントが最近広く使用されていますが、この問題に対して有望なラベル結果が得られています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-16">
        <br>2020-03-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Hybrid Attention-Based Transformer Block Model for Distant Supervision
  Relation Extraction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-27/cs.CL/paper_1.html">
      Hybrid Attention-Based Transformer Block Model for Distant Supervision
  Relation Extraction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、より簡潔な文レベルの注意メカニズムを採用してバッグ表現を構成し、各文の有効な情報を組み込んでバッグを効果的に表現することを目指しています。データセットの手動ラベル付けを回避するために、遠隔監視関係抽出（DSRE）が広く使用されています使用、ナレッジベースを利用してデータセットに自動的に注釈を付けることを目的としています。公開データセットNew York Times（NYT）の実験結果は、提案されたアプローチが評価データセットの最新のアルゴリズムよりも優れており、有効性を検証できます。 DSREタスクのモデルの例です。 
[ABSTRACT]メイン抽出は自然言語処理（nlp）の基本的なタスクです。これは、テキストに基づいてエンティティ間の意味関係を抽出することを目的としています。このメソッドは、根本的な強力なタスクのために誤ったラベル付けに大きく苦しんでいます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-10">
        <br>2020-03-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Boosting Factual Correctness of Abstractive Summarization with Knowledge
  Graph -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-27/cs.CL/paper_2.html">
      Boosting Factual Correctness of Abstractive Summarization with Knowledge
  Graph
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、知識の融合によって要約の事実の正確さを高めることを提案します。記事から事実関係を抽出しました。実証結果は、FASumが、独立して訓練された事実の正しさ評価者と人間の評価の両方のもとで、最新の抽象要約システムと比較してはるかに高い事実の正しさで要約を生成することを示しています。 
[要約]要約と元のテキストの不一致により、その適用性にさまざまな懸念が生じています。このモデルでは、知識情報を要約生成プロセスに有機的に統合できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-19">
        <br>2020-03-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Vector logic and counterfactuals -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-27/cs.CL/paper_3.html">
      Vector logic and counterfactuals
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この結果は、この手順が複雑な領域に投影された不確実な評価を生成することを示しています。この事実の理由は、この事実に反する命題のこの表現が、2つの複素数によってそれぞれ重み付けされた2つの反対の真理値の重ね合わせである評価を生成することです共役係数..この基本的な表現の後、与えられた反事実の妥当性の判断により、実ベクトル「true」または「false」で表される受け入れまたは拒否に向けて決定をシフトすることができ、このシフトを象徴的に表すことができますもう一度、否定の2つの平方根を適用します。 
[ABSTRACT] counterfactualsは、否定の平方根の1つ、複雑な行列を含む暗黙の行列を前処理しているように見える複雑な行列演算子です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br>2020-03-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Visual Grounding in Video for Unsupervised Word Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-27/cs.CL/paper_4.html">
      Visual Grounding in Video for Unsupervised Word Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この共有埋め込みを前提として、（i）言語間で単語、特に「視覚的」単語をマッピングできることを示します。 （ii）共有埋め込みは、既存の教師なしテキストベースの単語翻訳技術に適切な初期化を提供し、提案されたハイブリッドビジュアルテキストマッピングアルゴリズムMUVEの基礎を形成します。 （iii）私たちのアプローチは、テキストベースのメソッドの欠点に対処することで優れたパフォーマンスを実現します-より堅牢で、共通性の低いデータセットを処理し、低リソース言語に適用できます。この視覚的な世界でのグラウンディングには、これらのすべての言語間のギャップを埋めます。これらの方法を使用して、英語からフランス語、韓国語、日本語に単語を翻訳します。すべて平行コーパスはなく、単に物事をしながら話している人々の多くのビデオを見るだけです。 
[要約]重要なアイデアは、2つの言語間で共通の視覚表現を確立することです。それは、母国語でナレーションされたペアになっていない動画から埋め込みを学ぶことです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-11">
        <br>2020-03-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Common-Knowledge Concept Recognition for SEVA -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-27/cs.CL/paper_5.html">
      Common-Knowledge Concept Recognition for SEVA
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      問題は、名前付きエンティティ抽出と同様のトークン分類タスクとして定式化されます。ドメインエキスパートとテキスト処理メソッドの助けを借りて、シーケンスモデルをトレーニングするためのラベル付けスキームを慎重に定義することにより、単語レベルで注釈が付けられたデータセットを構築します。システムエンジニアリングの概念を認識します。システムエンジニアの仮想アシスタント（SEVA）の共通概念認識システムを構築します。これは、関係の抽出、ナレッジグラフの構築、質問への回答などのダウンストリームタスクに使用できます。 
[ABSTRACT]事前にトレーニングされた言語モデルを使用し、ラベル付けされたシステムで細かくラベル付けします。これらの抽出された概念を使用して簡単なナレッジグラフが作成されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-26">
        <br>2020-03-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards Making the Most of BERT in Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-27/cs.CL/paper_6.html">
      Towards Making the Most of BERT in Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      機械翻訳の実験では、WMT14の英語とドイツ語のペアで最大3 BLEUスコアの\ methodの向上が示され、これは以前の最先端の事前トレーニング支援NMTを1.4 BLEUスコアだけ上回っています。この作業では、事前トレーニング済みのLMを神経機械翻訳（NMT）に統合するための鍵となる協調トレーニングフレームワーク（\ method）を紹介します。GPT-2とBERTは、さまざまな上で事前トレーニング済みの言語モデル（LM）を使用することの有効性を示しています自然言語処理タスク。 
[要約]提案されたcnmtは3つの手法で構成されています。nhtモデルが事前にトレーニングされた知識を保持できるようにするための漸近蒸留
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-15">
        <br>2019-08-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: TLDR: Token Loss Dynamic Reweighting for Reducing Repetitive Utterance
  Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-27/cs.CL/paper_7.html">
      TLDR: Token Loss Dynamic Reweighting for Reducing Repetitive Utterance
  Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ハードトークンには高い重みを使用し、イージートークンには低い重みを使用することで、NLGモデルは個々のトークンを異なるペースで学習できます。ただし、この方法は変換器などの他のモデルに一般化されません。自然言語生成（NLG）モデルは繰り返し発声する傾向があります。 
[ABSTRACT]モデルアーキテクチャの影響を最初に調査します。例として、個々のトークン損失に微分可能な重みを適用するトークン損失動的再重み付け（tldr）を学習します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-26">
        <br>2020-03-26
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Speech Quality Factors for Traditional and Neural-Based Low Bit Rate
  Vocoders -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-27/eess.AS/paper_0.html">
      Speech Quality Factors for Traditional and Neural-Based Low Bit Rate
  Vocoders
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      主観的な品質評価の結果は、既存の完全な参照音声品質メトリックと十分に相関していません。この研究は、低ビットレートで音声をコーディングするためのさまざまなアルゴリズムのパフォーマンスを比較しています。この結果は、使用される音声信号の側面に関する貴重な洞察を提供します。生成モデルベースのコーダーから音声品質を正確に予測する新しいメトリックを開発する。 
[要約]公に利用可能なデータベースからの音声データの分析は、人々のスコアと比較されました。結果は、音声品質を正確に予測するための新しいメトリックを開発するために使用される音声信号の側面への貴重な洞察を提供します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-26">
        <br>2020-03-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Monaural Speech Enhancement Using Deep Multi-Branch Residual Network
  with 1-D Causal Dilated Convolutions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-27/eess.AS/paper_1.html">
      Monaural Speech Enhancement Using Deep Multi-Branch Residual Network
  with 1-D Causal Dilated Convolutions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      MB-ResNetはスプリット変換集約設計を利用しており、低い計算量で強力な表現力を得ることが期待されています。広範な実験的調査により、MB-ResNetsは残余の長期短期メモリネットワーク（ResLSTM）を上回ることが示されています。優れたパラメーター効率を提供しながら、音声明瞭度と品質の観点で残差または密な集約を採用するCNNネットワーク。長期短期記憶（LSTM）モデルは、その高い計算の複雑さと爆発/消失勾配問題によって制限されます。 
[ABSTRACT]マルチブランチ残差ネットワーク（mb-resnet）の長期的な改善は、長期的な効果をキャプチャする能力によって制限されます。たたみ込みニューラルネットワーク（cnn）、resnetの組み合わせは、受容野を拡張し、非常に長期間の時間的コンテキスト情報のキャプチャ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-27">
        <br>2019-12-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Non-parallel Voice Conversion System with WaveNet Vocoder and Collapsed
  Speech Suppression -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-27/eess.AS/paper_2.html">
      Non-parallel Voice Conversion System with WaveNet Vocoder and Collapsed
  Speech Suppression
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この問題に取り組むために、従来のボコーダーで生成された音声を参照音声として使用して、線形予測符号化分布制約（LPCDC）を導出し、音声の崩壊問題を回避します。さらに、LPCDCによって導入される悪影響を軽減するために、 LPCDCが問題のあるセグメントにのみ適用され、品質の損失を短期間に制限することを保証するための折りたたみ音声セグメント検出器（CSSD）。このホワイトペーパーでは、シンプルな非並列音声変換（VC）システムをWaveNet（WN）ボコーダーと提案された折りたたみ音声抑制技術。 
[ABSTRACT] wnは、忠実度の高い音声波形を作成するためのボコーダーです。これにより、折りたたみ音声の問題を含む折りたたみ音声システムが作成されます。提案された方法は、以前の非平行制限の音声品質をさらに改善します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-26">
        <br>2020-03-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: In defence of metric learning for speaker recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-27/eess.AS/paper_3.html">
      In defence of metric learning for speaker recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      バニラのトリプレット損失でさえ、分類ベースの損失と比較して競争力のあるパフォーマンスを示し、角度メトリック学習目的で訓練されたものは、最先端の方法よりも優れていることを示しています。このホワイトペーパーでは、最新のVoxCelebデータセットでの話者認識の損失関数。話者認識の一般的な信念は、分類目的で訓練されたネットワークがメトリック学習方法よりも優れていることです。 
[要約]バニラのトリプレット損失でさえ、分類ベースの損失と比較して競争力のあるパフォーマンスを示すことを実証しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-26">
        <br>2020-03-26
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Photoperiod-dependent developmental reprogramming of the transcriptional response to seawater entry in Atlantic salmon (Salmo salar) -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-27/biorxiv.physiology/paper_0.html">
      Photoperiod-dependent developmental reprogramming of the transcriptional response to seawater entry in Atlantic salmon (Salmo salar)
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      一定の光量（LL）で飼育された魚と比較して、短い日長（SP）への曝露はSWの浸透圧低下を劇的に損ない、鰓遺伝子発現における糖質コルチコイド関連の広範な変化と関連していました。細胞張性または細胞内カルシウムレベルの急性変化に関連する経路がSWの準備で重要性が低下するため、SPLL魚のNFATを介した応答の場合生涯を通じてLLで飼育された魚の反応プロファイルは、LLに戻る前にSPに8週間曝露された魚（SPLL）の反応プロファイルとはかなり異なります。 
[要約] swに遭遇する前の日長依存性準備変化とswへの曝露によって刺激された活性化変化の両方が関与します。光周期履歴の主な影響は、swに対するll順応魚の処理応答で観察されました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-26">
        <br>2020-03-26
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
