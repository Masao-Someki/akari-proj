<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-09-29の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      <font color="black"></font>
    </a>
  </h2>
  <font color="black">本日更新された論文はありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br><font color="black"></font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: A Study on Lip Localization Techniques used for Lip reading from a Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/eess.IV/paper_0.html">
      <font color="black">A Study on Lip Localization Techniques used for Lip reading from a Video</font>
    </a>
  </h2>
  <font color="black">読唇術は、通信システムにノイズの有無にかかわらず、音声がないか低い場合の自動音声認識に役立ちます。最初にビデオ入力の最初のフレームで唇を見つけ、次のフレームで唇を追跡します。最初のステップで得られたピクセルポイントを使用し、最後に追跡された唇モデルを対応する一致する文字に変換して視覚情報を提供します。読唇術のプロセスでは、通常、次のステップが使用されます。 
[ABSTRACT]唇のローカリゼーションは、唇を読み取るために必要な基本的な手順です。唇のローカリゼーションには、ビデオ入力から視覚情報を抽出することが含まれます。次の手順が一般的に使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: High-throughput molecular imaging via deep learning enabled Raman
  spectroscopy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/eess.IV/paper_1.html">
      <font color="black">High-throughput molecular imaging via deep learning enabled Raman
  spectroscopy</font>
    </a>
  </h2>
  <font color="black">これらのアプローチを組み合わせることで、最大160倍のラマンイメージングの高速化を実現し、1分未満で高解像度、高信号対雑音比の細胞イメージングを可能にします。DeepeRは、多数の高スループットラマン分光法を可能にする基盤を提供します。と分子イメージングアプリケーション全体の生物医学..最初に、最先端のラマンフィルタリング法に比べて平均二乗誤差が9倍改善された、深い学習による低信号対雑音比のラマン分子シグネチャのノイズ除去と再構築を実行します。 
[概要]ディープラーニングにより、150万を超えるスペクトル（400時間の取得）を備えたハイパースペクトルラマン画像の大規模なデータセットでトレーニングされたラマン分光法が可能になりました。ハイパースペクトル画像の堅牢な2〜4倍の超解像のためのニューラルネットワークを開発しています。モードモードモデレーションでのスローモーションとそれを使用してスロースローを可能にする-分子情報が収集される場所を確認する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Deep EvoGraphNet Architecture For Time-Dependent Brain Graph Data
  Synthesis From a Single Timepoint -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/eess.IV/paper_2.html">
      <font color="black">Deep EvoGraphNet Architecture For Time-Dependent Brain Graph Data
  Synthesis From a Single Timepoint</font>
    </a>
  </h2>
  <font color="black">私たちのEvoGraphNetコードはhttp://github.com/basiralab/EvoGraphNetで入手できます。実際、単一の時点から時間の経過とともに出現および進化する縦方向（つまり、時間依存）の脳の接続障害を予測することは、非常に早い段階で障害のある患者..したがって、各ジェネレーターの出力を後続の入力として設定することにより、次の予測される各時点を取得します。これにより、最後に1つの時点のみを使用して特定の数の時点を予測できます。 -ファッションを終わらせる。 
[ABSTRACT]脳グラフの進化モデルは、文献ではほとんど見過ごされています。単一の時点を使用して、最小の脳グラフ進化予測エラーを達成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial shape perturbations on 3D point clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/eess.IV/paper_3.html">
      <font color="black">Adversarial shape perturbations on 3D point clouds</font>
    </a>
  </h2>
  <font color="black">3Dニューラルネットワークをどのように利用できるかを理解するために必要な、攻撃者の観点から堅牢なモデルを作成する問題を検討します。3Dポイントクラウド分類を攻撃するための3つの可能な形状攻撃を調査し、それらのいくつかができることを示します。以前に提案された点除去防御のような前処理ステップに対しても効果的です。ロボット工学、ドローン制御、自動運転の視覚タスクの深層学習で3Dデータがますます利用されるにつれて、堅牢なニューラルネットワークをトレーニングすることの重要性が高まります。 
[概要] 3Dデータ型を攻撃する2つのカテゴリを調査します。1つは3D点群で、形状情報を記述します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-16">
        <br><font color="black">2019-08-16</font>
      </time>
    </span>
</section>
<!-- paper0: Offline versus Online Triplet Mining based on Extreme Distances of
  Histopathology Patches -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/eess.IV/paper_4.html">
      <font color="black">Offline versus Online Triplet Mining based on Extreme Distances of
  Histopathology Patches</font>
    </a>
  </h2>
  <font color="black">また、極端な距離に基づいたオンラインアプローチを調査し、データパターンに基づいてオフラインとオンラインマイニングのパフォーマンスを包括的に比較し、オフラインマイニングを大きなミニバッチサイズのオンラインマイニングの扱いやすい一般化として説明します。多くの作品は選択のみに焦点を当てていますがオンラインのトリプレット（バッチ単位）では、オフラインでトレーニングする前に、極端な距離と隣接パッチの影響も調査します。オフラインとオンラインのマイニングアプローチは、ResNet-18などの特定のアーキテクチャで同等のパフォーマンスを発揮することがわかりました。この研究。 
[概要]オフラインマイニングとオンラインマイニングの埋め込み距離の観点から極端なケースの影響を分析します。これらには、イージーポジティブ、バッチセミハード、バッチミニハード、バッチハードが含まれます。さまざまな極端な距離を含むさまざまなケースが有望です。特にオンラインアプローチでは</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-04">
        <br><font color="black">2020-07-04</font>
      </time>
    </span>
</section>
<!-- paper0: Trainable Structure Tensors for Autonomous Baggage Threat Detection
  Under Extreme Occlusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/eess.IV/paper_5.html">
      <font color="black">Trainable Structure Tensors for Autonomous Baggage Threat Detection
  Under Extreme Occlusion</font>
    </a>
  </h2>
  <font color="black">提案されたフレームワークは、4つの公開されているX線データセットで厳密にテストされており、平均平均精度スコアの点で最先端のフレームワークよりも優れています。さらに、私たちの知る限り、これは唯一のフレームワークです。これは、4つの異なるタイプのX線スキャナーから得られたグレースケールスキャンとカラースキャンの組み合わせで厳密にテストされています。多くの研究者が、手荷物X線スキャンからこれらの脅威を認識するためのコンピューター支援スクリーニングシステムを開発しました。 
[概要]新しいインスタンス検出器は、トレーニング可能な構造スキームを使用して、閉塞および乱雑な密輸品の輪郭を強調します。これは、4種類のX線スキャナーから取得したグレーとカラースキャンの組み合わせで厳密にテストされた唯一のフレームワークです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: A Foreground-background Parallel Compression with Residual Encoding for
  Surveillance Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/eess.IV/paper_6.html">
      <font color="black">A Foreground-background Parallel Compression with Residual Encoding for
  Surveillance Video</font>
    </a>
  </h2>
  <font color="black">デコード側では、前景と背景の合成とフレーム品質の向上を実現するために、粗いものから細かいものまでの2段階モジュールが適用されます。本論文では、前景を抽出して圧縮するビデオ圧縮方法を提案します。実験結果は、HECVデータセットで同じPSNR（36 dB）を達成するために、提案された方法が従来のアルゴリズムH.265よりも69.5％少ないbpp（ピクセルあたりのビット数）を必要とすることを示しています。 
[概要]提案された方法は、従来のアルゴリズムhよりも69.5％少ないbpp（ピクセルあたりのビット数）を必要とします。 hecvデータセットで同じpsnr（36 db）を実現するには265</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-18">
        <br><font color="black">2020-01-18</font>
      </time>
    </span>
</section>
<!-- paper0: Automated Pancreas Segmentation Using Multi-institutional Collaborative
  Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/eess.IV/paper_7.html">
      <font color="black">Automated Pancreas Segmentation Using Multi-institutional Collaborative
  Deep Learning</font>
    </a>
  </h2>
  <font color="black">ディープラーニングベースの方法のパフォーマンスは、トレーニングに使用されるデータセットの数に大きく依存します。ただし、写真画像とは異なり、技術的、法的、プライバシー上の問題が多数あるため、医療画像を収集するための集中型データベースを生成することは困難です。医用画像分析分野のデータを増やすための努力がなされてきた。 
[ABSTRACT]調査によると、フェデレーション学習モデルはスタンドアロントレーニングよりも一般化可能性が高いことが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Cuid: A new study of perceived image quality and its subjective
  assessment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/eess.IV/paper_8.html">
      <font color="black">Cuid: A new study of perceived image quality and its subjective
  assessment</font>
    </a>
  </h2>
  <font color="black">この論文では、制御された実験室環境で主観的評価が収集された画質知覚の新しい研究を提示します。したがって、視覚信号の歪みに対する人間の行動反応を忠実に反映する制御された知覚実験で信頼できる主観的データを取得することが重要です。 。画質評価（IQA）の研究は、主に人間の視覚に関する知識が不完全なため、限られたままです。 
[概要]人間の被験者は高度なiqaアルゴリズムの開発につながりました。人間の被験者によるデジタル証拠は開発の基礎として機能します。データベースはキャリブレーションと検証を容易にするために公開されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: AI Progress in Skin Lesion Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/eess.IV/paper_9.html">
      <font color="black">AI Progress in Skin Lesion Analysis</font>
    </a>
  </h2>
  <font color="black">特にローショット学習の問題については、ベースラインアルゴリズムと比較した場合に、ローショットで正常に低下し、それでも良好に機能する皮膚分析アルゴリズムを報告します。クラスごとにわずか10のトレーニングエグザンプラを使用すると、ベースラインDLアルゴリズムのパフォーマンスが大幅に低下します。 、56.41％の精度で、偶然に近いのに対し、最高のパフォーマンスのローショットアルゴリズムでは、83.33％の精度が得られます。これらの問題の解決は、非常に望ましい要件からさまざまです。描写のために。これは、類似したタイプの病変を明確にし、改善された診断を実行するのに役立つか、AIバイアス除去の場合のように、皮膚病変分析のためにクリニックで公正なAI技術の展開を可能にするために必要です。 
[概要] aiの重要な課題について説明します。ローショット学習は、トレーニング画像が不足している分類に対処することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: A Content Driven Resource Allocation Scheme for Video Transmission in
  Vehicular Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/eess.IV/paper_10.html">
      <font color="black">A Content Driven Resource Allocation Scheme for Video Transmission in
  Vehicular Networks</font>
    </a>
  </h2>
  <font color="black">提案されたリソース割り当てスキームは、コンテンツ分析のパフォーマンスに関連するコンテンツ品質（QoC）の最大化に基づいています。QoCベースの評価モデルが最初に提案されます。次に、リソース割り当て問題が解決可能なものに変換されます。凸最適化問題。 
[概要]提案されたリソース割り当てスキームは、コンテンツ分析のパフォーマンスに関連するコンピュータの品質を最大化することに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Segmentation and Analysis of a Sketched Truss Frame Using Morphological
  Image Processing Techniques -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/eess.IV/paper_11.html">
      <font color="black">Segmentation and Analysis of a Sketched Truss Frame Using Morphological
  Image Processing Techniques</font>
    </a>
  </h2>
  <font color="black">このフレームワークのさらなる開発は、構造のモデル化と分析の方法に革命をもたらす可能性があります。このペーパーは、一枚の紙に描かれた手描きまたはコンピューター生成のトラスフレームの分析を自動化する方法論の開発に専念しています。 、形態学的画像処理技術を使用して、手でスケッチしたトラスコンポーネントのセグメンテーション手法に焦点を当て、トラスのリアルタイム分析を提供します。 
[概要]このペーパーでは、構造システムの効率を迅速に評価するために、画像処理を使用した構造解析の自動化の可能性に焦点を当てています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Medical Image Segmentation Using Deep Learning: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/eess.IV/paper_12.html">
      <font color="black">Medical Image Segmentation Using Deep Learning: A Survey</font>
    </a>
  </h2>
  <font color="black">教師あり学習アプローチでは、バックボーンネットワークの選択、ネットワークブロックの設計、損失関数の改善の3つの側面で文献を分析します。この論文は2つの独自の貢献をしています。深層学習は医療画像のセグメンテーションに広く使用されています。また、この分野での深層学習の成功を記録した多数の論文が発表されています。 
[概要]医療画像のセグメンテーションを調べるために使用される深層学習手法。これらには、損失関数の成功などの深層学習手法が含まれていました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Texture Memory-Augmented Deep Patch-Based Image Inpainting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/eess.IV/paper_13.html">
      <font color="black">Texture Memory-Augmented Deep Patch-Based Image Inpainting</font>
    </a>
  </h2>
  <font color="black">提案された方法は、3つの挑戦的な画像ベンチマーク、つまりPlaces、CelebA-HQ、およびParis Street-Viewデータセットで、定性的および定量的に優れたパフォーマンスを示します。それにもかかわらず、結果には、周囲の領域に似た忠実でシャープな詳細が欠けていることがよくあります。さらに、高品質のパッチ合成を促進するために、パッチ配布損失を導入します。一方、
[ABSTRACT]ディープネットワークは、大きな領域を完成させる上で有望な結果を示します。新しいディープインペインティングフレームワークにより、マスクされていない領域から抽出されたパッチサンプルのテクスチャメモリによってテクスチャ生成をガイドできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Mixture of Spectral Generative Adversarial Networks for Imbalanced
  Hyperspectral Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/eess.IV/paper_14.html">
      <font color="black">Mixture of Spectral Generative Adversarial Networks for Imbalanced
  Hyperspectral Image Classification</font>
    </a>
  </h2>
  <font color="black">ジェネレータネットワークは、分類器のパフォーマンスを向上させるためにデータ拡張を実行します。MGSGANは、少数派クラスに対する多数派の不均衡比が高い場合でも、少数派クラスを生成できます。提案された方法は、2つのハイパースペクトル画像データセットを通じて検証され、状態と比較されています。実際のデータ分布に対応する2つのクラス不均衡設定の下での最先端の方法。 
[概要]提案された方法は、2つのハイパースペクトル画像データセットを通じて検証されました。実際のデータ分布に対応するネットワーク不均衡設定と比較されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Light Field Image Super-Resolution Using Deformable Convolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/eess.IV/paper_15.html">
      <font color="black">Light Field Image Super-Resolution Using Deformable Convolution</font>
    </a>
  </h2>
  <font color="black">ADAMに基づいて、センタービュー機能と各サイドビュー機能の間で双方向アライメントを実行するための収集と分散のアプローチをさらに提案します。この論文では、変形可能な畳み込みネットワーク（つまり、LF-DFnet）を提案します。 LF画像SRの視差問題を処理します。ライトフィールド（LF）カメラは、複数の視点からシーンを記録できるため、画像の超解像（SR）に有益な角度情報を導入できます。 
[概要]私たちのアプローチを使用すると、角度情報を適切に組み込み、各ビューの特徴にエンコードすることができます。これらの特徴は、すべてのlf画像のsr再構成に役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Super-Resolution Ultrasound Localization Microscopy Based on a High
  Frame-rate Clinical Ultrasound Scanner: An In-human Feasibility Study -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/eess.IV/paper_16.html">
      <font color="black">Super-Resolution Ultrasound Localization Microscopy Based on a High
  Frame-rate Clinical Ultrasound Scanner: An In-human Feasibility Study</font>
    </a>
  </h2>
  <font color="black">微妙な形態学的および血行力学的情報は、シングルブレスホールドおよびフリーハンドスキャンで取得されたデータで実証されました。invivoでの深部組織の微小血管変化の非侵襲的検出は、臨床診断および幅広い病態の評価に重要な情報を提供します。 。現在、臨床超音波スキャナーでのULMの臨床的有用性は、長いデータ取得時間や低イメージングフレームレートに関連する追跡性能の低下などの技術的制限によって妨げられています。 
[ABSTRACT] in-高フレームレート（hfr）の臨床超音波スキャナーでの人間のulmは、短い取得時間を使用して超解像微小血管イメージングを実現します。これらには、サブピクセルモーションレジストレーション、mbシグナル、およびカルマンフィルターを含む高度な処理技術が含まれていました。 -ベースの追跡</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Cloud Removal for Remote Sensing Imagery via Spatial Attention
  Generative Adversarial Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/eess.IV/paper_17.html">
      <font color="black">Cloud Removal for Remote Sensing Imagery via Spatial Attention
  Generative Adversarial Network</font>
    </a>
  </h2>
  <font color="black">高解像度リモートセンシング衛星画像の雲を除去することは、それを分析する前に不可欠な前処理ステップです。このタスクを解決するために生成的敵対ネットワークを採用し、リモートセンシング画像の雲除去タスクに空間的注意メカニズムを導入し、提案します。人間の視覚メカニズムを模倣し、ローカルからグローバルへの空間的注意でクラウド領域を認識して焦点を合わせる、空間的注意生成敵対ネットワーク（SpA GAN）という名前のモデル。これにより、これらの領域の情報回復が強化され、より高品質のクラウドレス画像が生成されます。 ....ただし、リモートセンシング画像は、必然的に気候、特に雲の影響を受けます。 
[概要]リモートセンシング画像のクラウドを削除するためのニューラルネットワークの使用はまだ比較的小さい</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Concentrated Multi-Grained Multi-Attention Network for Video Based
  Person Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_0.html">
      <font color="black">Concentrated Multi-Grained Multi-Attention Network for Video Based
  Person Re-Identification</font>
    </a>
  </h2>
  <font color="black">ビデオベースの再識別（Re-ID）タスクでは、オクルージョンは依然として深刻な問題であり、成功率に大きな影響を与えます。ただし、注意メカニズムには、最終的な表現に十分な識別情報を抽出する機能がまだありません。ビデオから..この論文では、2つのマルチアテンションモジュールがマルチスケール中間機能の処理を通じてマルチグレイン情報を抽出するように設計されている集中マルチグレインマルチアテンションネットワーク（CMMANet）を提案します。 
[概要]注意メカニズムは、多数の既存の方法によって閉塞問題を解決するのに役立つことが証明されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: RAF-AU Database: In-the-Wild Facial Expressions with Subjective Emotion
  Judgement and Objective AU Annotations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_1.html">
      <font color="black">RAF-AU Database: In-the-Wild Facial Expressions with Subjective Emotion
  Judgement and Objective AU Annotations</font>
    </a>
  </h2>
  <font color="black">自動表情認識に関する作業の多くは、エクマンの基本的な感情理論に基づいて、特定の数の感情クラスとその誇張された顔の構成（通常は6つの典型的な顔の表情）を含むデータベースに依存しています。この問題に対処するために、RAF-を開発します。野生のブレンドされた表情に注釈を付けるために、サインベース（つまりAU）と判断ベース（つまり知覚された感情）のアプローチを採用するAUデータベース。しかし、最近の研究では、人間の生活の表情をブレンドできることが明らかになっています。複数の基本的な感情を持っています。 
[概要]私たちの人間の生活の表情は、複数の基本的な感情とブレンドできます。顔の表情など、最も複雑な表情はまだ未解決の質問です。人気のある機能とマルチラベルを使用して、raf-auでのau認識のベースラインを提供しました。学習方法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Content-based Propagation of User Markings for Interactive Segmentation
  of Patterned Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_2.html">
      <font color="black">Content-based Propagation of User Markings for Interactive Segmentation
  of Patterned Images</font>
    </a>
  </h2>
  <font color="black">リアルタイムのフィードバックのおかげで、ユーザーは現在の結果に応じて戦略的に新しいマーキングを配置できます。私たちの方法の重要な要素は、画像コンテンツをエンコードするグラフです。画像とボリュームの効率的で簡単なセグメンテーションは非常に実用的です重要性。 
[概要]これがピクセル分類によるセグメンテーションへの非常に効率的なアプローチになる方法を示しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-09-06">
        <br><font color="black">2018-09-06</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Adapt Multi-View Stereo by Self-Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_3.html">
      <font color="black">Learning to Adapt Multi-View Stereo by Self-Supervision</font>
    </a>
  </h2>
  <font color="black">私たちの評価は、提案された適応方法が新しいドメインで自己教師ありマルチビューステレオ再構成を学習するのに効果的であることを示しています。モデルに依存しないメタ学習（MAML）を使用して、ベースパラメータをトレーニングします。自己教師ありトレーニングを通じて新しいドメインでステレオを表示します。新しいターゲットドメインへの適応性を向上させるために、深いニューラルネットワークをトレーニングするマルチビューステレオの適応学習アプローチを提案します。 
[概要]マルチビューステレオ再構成の学習は、環境が変化する傾向があり、さまざまなドメインに確実に一般化する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Scalable Transfer Learning with Expert Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_4.html">
      <font color="black">Scalable Transfer Learning with Expert Models</font>
    </a>
  </h2>
  <font color="black">この戦略は、転送中に事前トレーニングデータを再検討しないため、新しいタスクへの転送プロセスをスケーリングします。したがって、ターゲットタスクごとに追加の計算をほとんど必要とせず、2〜3桁のスピードアップが得られます。競合するアプローチと比較して..2つの異なるデータソースでアプローチを評価し、両方のケースで20を超える多様なビジョンタスクのベースラインを上回っていることを示しています。 
[概要]既存のラベル構造を活用して、さまざまな専門家をトレーニングします。つまり、ターゲットタスクごとに追加の計算をほとんど必要とせず、2〜3桁の速度向上が実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-end Recurrent Multi-Object Tracking and Trajectory Prediction
  with Relational Reasoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_5.html">
      <font color="black">End-to-end Recurrent Multi-Object Tracking and Trajectory Prediction
  with Relational Reasoning</font>
    </a>
  </h2>
  <font color="black">いくつかの関係推論アーキテクチャを調査し、順列不変モデルが非順列不変の代替案よりも優れていることを示します。また、理論的にはユニバーサル関数近似器であるにもかかわらず、DeepSetsのような単一の順列不変演算を使用するアーキテクチャはそれにもかかわらず多頭の注意に基づくより複雑なアーキテクチャよりも優れています。現代のオブジェクト追跡アプローチの大部分は、オブジェクト間の相互作用をモデル化していません。 
[概要]オブジェクト間の相互作用や関係の理解を含むシステム全体は、クラス順列です。これらのアーキテクチャは、多面的な注意に基づくより複雑なアーキテクチャよりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-12">
        <br><font color="black">2019-07-12</font>
      </time>
    </span>
</section>
<!-- paper0: High-throughput molecular imaging via deep learning enabled Raman
  spectroscopy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_6.html">
      <font color="black">High-throughput molecular imaging via deep learning enabled Raman
  spectroscopy</font>
    </a>
  </h2>
  <font color="black">これらのアプローチを組み合わせることで、最大160倍のラマンイメージングの高速化を実現し、1分以内に高解像度で高信号対雑音比のセルラーイメージングを可能にします。まず、低信号対雑音比のラマンのノイズ除去と再構築を実行します。ディープラーニングによる分子シグネチャー。最先端のラマンフィルタリング法に比べて平均二乗誤差が9倍向上しています。ラマン分光法により、前例のない分子コントラストを備えた非破壊のラベルフリーイメージングが可能になりますが、データ取得が遅いため制限があります。ハイスループットイメージングアプリケーションを大幅に防止します。 
[概要]ディープラーニングにより、150万を超えるスペクトル（400時間の取得）を備えたハイパースペクトルラマン画像の大規模なデータセットでトレーニングされたラマン分光法が可能になりました。ハイパースペクトル画像の堅牢な2〜4倍の超解像のためのニューラルネットワークを開発しています。モードモードモデレーションでのスローモーションとそれを使用してスロースローを可能にする-分子情報が収集される場所を確認する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Interventional Few-Shot Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_7.html">
      <font color="black">Interventional Few-Shot Learning</font>
    </a>
  </h2>
  <font color="black">IFSLの貢献は、既存の微調整およびメタ学習ベースのFSL手法と直交しているため、IFSLはそれらすべてを改善し、\で新しい1/5ショットの最先端技術を実現できることは注目に値します。 textit {mini} ImageNet、\ textit {tiered} ImageNet、およびクロスドメインCUB ..具体的には、バックドア調整に基づいて3つの効果的なIFSLアルゴリズム実装を開発します。これは、本質的に、多発学習のSCMに対する因果的介入です。因果関係の観点から見たFSLの上限..コードはhttps://github.com/yue-zhongqi/ifslでリリースされています。 
[概要]バックドア調整に基づいて3つの効果的なifslアルゴリズムを開発します。これは本質的に多くのscmに対する因果的介入です-ショット学習</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Deep EvoGraphNet Architecture For Time-Dependent Brain Graph Data
  Synthesis From a Single Timepoint -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_8.html">
      <font color="black">Deep EvoGraphNet Architecture For Time-Dependent Brain Graph Data
  Synthesis From a Single Timepoint</font>
    </a>
  </h2>
  <font color="black">ここでは、単一の時点から時間依存の脳グラフの進化を予測するための、最初のエンドツーエンドの幾何学的深層学習を利用したグラフ生成敵対的ネットワーク（gGAN）であるEvoGraphNetを提案します。実際、縦方向（つまり、時間-依存）単一の時点から時間の経過とともに出現および進化する脳の接続障害は、非常に早い段階で障害のある患者のための個別の治療を設計するのに役立ちます。したがって、各ジェネレータの出力をその入力として設定することにより、次の予測される各時点を取得します。エンドツーエンドの方法で単一の時点のみを使用して、指定された数の時点を予測できるようにする後継。 
[ABSTRACT]脳グラフの進化モデルは、文献ではほとんど見過ごされています。単一の時点を使用して、最小の脳グラフ進化予測エラーを達成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Flexible Example-based Image Enhancement with Task Adaptive Global
  Feature Self-Guided Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_9.html">
      <font color="black">Flexible Example-based Image Enhancement with Task Adaptive Global
  Feature Self-Guided Network</font>
    </a>
  </h2>
  <font color="black">1対多および多対1の画像マッピングを学習できる最初の実用的なマルチタスク画像強調ネットワークを提案します。私たちのネットワークは、最近提案されたSGNアーキテクチャに基づいており、グローバルな機能とスタイルを組み込むことを目的とした変更が加えられています。適応..さらに、モデルは、共有表現を利用することにより、複数のマッピングを同時に学習する際にさらに高いパフォーマンスを実現します。 
[概要]単一の拡張マッピングの学習において、モデルが現在のパフォーマンスを上回っていることを示します。ネットワークは、最近提案されたsgnアーキテクチャに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br><font color="black">2020-05-13</font>
      </time>
    </span>
</section>
<!-- paper0: Dendrite Net: A White-Box Module for Classification, Regression, and
  System Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_10.html">
      <font color="black">Dendrite Net: A White-Box Module for Classification, Regression, and
  System Identification</font>
    </a>
  </h2>
  <font color="black">第三に、MINISTおよびFASHION-MINISTデータセットにより、DDは、分類のためにCell body Netよりも大きなトレーニング損失の下で高いテスト精度を示したことが確認されました。モジュールの数は、DDの論理式容量を効果的に調整できるため、過剰適合を回避し、優れた一般化機能を備えたモデルを簡単に取得できます。最後に、$ MATLAB $と$ PyTorch $（$ Python $）で繰り返し実験を行ったところ、エポックとフォワードプロパゲーションの両方でDDがCell bodyNetよりも高速であることがわかりました。 
[ABSTRACT] ddの主な概念は、出力の論理式に対応するクラスの論理関係が含まれている場合、アルゴリズムは学習後にこのクラスを認識できるということです。実験は、ddがより良い一般化をもたらした9つの実世界のアプリケーションによって最初に検証されました。ニューロンの細胞体ネットを模倣したmlpアーキテクチャと比較した機能</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br><font color="black">2020-04-08</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial shape perturbations on 3D point clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_11.html">
      <font color="black">Adversarial shape perturbations on 3D point clouds</font>
    </a>
  </h2>
  <font color="black">ロボット工学、ドローン制御、自動運転のビジョンタスクの深層学習で3Dデータがますます利用されるにつれて、堅牢なニューラルネットワークをトレーニングすることの重要性が高まります。攻撃者の観点から堅牢なモデルを作成する問題を検討します。 3Dニューラルネットワークをどのように活用できるかを理解する。一般的に使用される3Dデータタイプの1つは、形状情報を記述する3Dポイントクラウドです。 
[概要] 3Dデータ型を攻撃する2つのカテゴリを調査します。1つは3D点群で、形状情報を記述します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-16">
        <br><font color="black">2019-08-16</font>
      </time>
    </span>
</section>
<!-- paper0: Offline versus Online Triplet Mining based on Extreme Distances of
  Histopathology Patches -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_12.html">
      <font color="black">Offline versus Online Triplet Mining based on Extreme Distances of
  Histopathology Patches</font>
    </a>
  </h2>
  <font color="black">この調査では、オフラインとオンラインのマイニングアプローチは、ResNet-18などの特定のアーキテクチャで同等のパフォーマンスを発揮することがわかりました。また、極端な距離に基づいてオンラインアプローチを調査し、データパターンに基づいてオフラインとオンラインのマイニングパフォーマンスを包括的に比較します。オフラインマイニングを、ミニバッチサイズが大きいオンラインマイニングの扱いやすい一般化として説明します。100,000パッチを含む結腸直腸癌（CRC）組織病理学データセットに対するオフラインおよびオンライントリプレットマイニングの効果を分析します。 
[概要]オフラインマイニングとオンラインマイニングの埋め込み距離の観点から極端なケースの影響を分析します。これらには、イージーポジティブ、バッチセミハード、バッチミニハード、バッチハードが含まれます。さまざまな極端な距離を含むさまざまなケースが有望です。特にオンラインアプローチでは</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-04">
        <br><font color="black">2020-07-04</font>
      </time>
    </span>
</section>
<!-- paper0: Morphing Attack Detection -- Database, Evaluation Platform and
  Benchmarking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_13.html">
      <font color="black">Morphing Attack Detection -- Database, Evaluation Platform and
  Benchmarking</font>
    </a>
  </h2>
  <font color="black">既存のMADアルゴリズムに挑戦するために、モーフィングされた画像は、貢献する画像から作成された慎重な主題の事前選択であり、モーフィングアーティファクトを削除するためにさらに後処理されます。この作業では、進歩を促進するための新しい隔離されたデータセットを提示します。より一般化するために、見えないデータでアルゴリズムをテストできるMADの例。さらに、隔離されたデータでアルゴリズムをテストするための新しいオンライン評価プラットフォームを紹介します。 
[概要]最近の作業の進歩の数にもかかわらず、深刻な未解決の問題に注意します。これらには、時代遅れのベンチマーク、一般化可能性の課題、および不適切に対処されている年齢、性別、民族性への考慮事項が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br><font color="black">2020-06-11</font>
      </time>
    </span>
</section>
<!-- paper0: Trainable Structure Tensors for Autonomous Baggage Threat Detection
  Under Extreme Occlusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_14.html">
      <font color="black">Trainable Structure Tensors for Autonomous Baggage Threat Detection
  Under Extreme Occlusion</font>
    </a>
  </h2>
  <font color="black">提案されたフレームワークは、4つの公開されているX線データセットで厳密にテストされており、平均平均精度スコアの点で最先端のフレームワークよりも優れています。さらに、私たちの知る限り、これは唯一のフレームワークです。これは、4つの異なるタイプのX線スキャナーから取得したグレースケールスキャンとカラースキャンの組み合わせで厳密にテストされています。ただし、これらのフレームワークはすべて、極端な閉塞下での密輸品の認識に制限があります。 
[概要]新しいインスタンス検出器は、トレーニング可能な構造スキームを使用して、閉塞および乱雑な密輸品の輪郭を強調します。これは、4種類のX線スキャナーから取得したグレーとカラースキャンの組み合わせで厳密にテストされた唯一のフレームワークです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: A Foreground-background Parallel Compression with Residual Encoding for
  Surveillance Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_15.html">
      <font color="black">A Foreground-background Parallel Compression with Residual Encoding for
  Surveillance Video</font>
    </a>
  </h2>
  <font color="black">H.264やH.265などの従来のビデオ圧縮アルゴリズムは、監視ビデオの低情報密度特性を十分に活用していません。適応型の背景更新と補間により、複数の隣接するフレーム間で背景情報を共有することにより、圧縮率が大幅に向上します。モジュール..実験結果は、HECVデータセットで同じPSNR（36 dB）を達成するために、提案された方法が従来のアルゴリズムH.265よりも69.5％少ないbpp（ビット/ピクセル）を必要とすることを示しています。 
[概要]提案された方法は、従来のアルゴリズムhよりも69.5％少ないbpp（ピクセルあたりのビット数）を必要とします。 hecvデータセットで同じpsnr（36 db）を実現するには265</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-18">
        <br><font color="black">2020-01-18</font>
      </time>
    </span>
</section>
<!-- paper0: Extending the Morphological Hit-or-Miss Transform to Deep Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_16.html">
      <font color="black">Extending the Morphological Hit-or-Miss Transform to Deep Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">最後に、定性的なヒットおよびミスフィルターの視覚化が単一の形態学的レイヤーに関連して提供されます。私たちの分析は、畳み込みが実際には、フィルターの違いの意味解釈を通じてヒットミス変換のように機能することを示しています。定量的実験は、合成およびベンチマークで提供されます。データは、直接エンコーディングのヒットオアミス変換が、オブジェクトと一致する学習された形状の解釈性を向上させるのに対し、形態学的にインスピレーションを得た一般化された畳み込みがより高い分類精度をもたらすことを示しています。 
[概要]ターゲットパターンに応答する方法がわからない理由を説明します。これは、ドントケア（dnc）を表現するための最も重要な方法です。これは、nであるseの特定の領域にとって重要です。ターゲットの検出には関係ありませんが、代わりに、ベンチマークデータで従来の畳み込みよりも優れた拡張機能を導入します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br><font color="black">2019-12-04</font>
      </time>
    </span>
</section>
<!-- paper0: Automated Pancreas Segmentation Using Multi-institutional Collaborative
  Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_17.html">
      <font color="black">Automated Pancreas Segmentation Using Multi-institutional Collaborative
  Deep Learning</font>
    </a>
  </h2>
  <font color="black">医用画像解析分野のデータを増やすために多くの努力が払われてきました。しかし、写真画像とは異なり、技術的、法的、プライバシーの問題が多いため、医用画像を収集するための集中データベースを生成することは困難です。フェデレーション学習とローカルトレーニングのみで得られたセグメンテーションモデル。 
[ABSTRACT]調査によると、フェデレーション学習モデルはスタンドアロントレーニングよりも一般化可能性が高いことが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: PhishGAN: Data Augmentation and Identification of Homoglpyh Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_18.html">
      <font color="black">PhishGAN: Data Augmentation and Identification of Homoglpyh Attacks</font>
    </a>
  </h2>
  <font color="black">ここでは、条件付きの生成的敵対的ネットワーク（GAN）であるPhishGANを使用して、非ホモグリフ入力テキスト画像を条件とする象形文字の画像を生成する方法を示します。 「| inkedin.com」を「linkedin.com」と間違え、その過程で、偽のWebサイトに個人情報を漏らします。 
[概要]攻撃を難読化するためのpunycodeの使用により、被害者はフィッシングの影響を受けやすくなります。これは、公開されているデータセットがないため、より高度な機械学習モデルのトレーニングを妨げるためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-24">
        <br><font color="black">2020-06-24</font>
      </time>
    </span>
</section>
<!-- paper0: Student Engagement Detection Using Emotion Analysis, Eye Tracking and
  Head Movement with Machine Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_19.html">
      <font color="black">Student Engagement Detection Using Emotion Analysis, Eye Tracking and
  Head Movement with Machine Learning</font>
    </a>
  </h2>
  <font color="black">システムは典型的なeラーニングシナリオでテストされ、その結果は、学生が「非常に従事している」、「名目上従事している」、「まったく従事していない」各期間を正しく識別することを示しています。提供された情報のみを使用します。ラップトップコンピュータに存在する典型的な組み込みのウェブカメラによって、リアルタイムで動作するように設計されました。一般に距離学習、特にeラーニングの増加に伴い、学生の関与は非常に重要であり、教師、研究者、政策立案者の両方にとって最大の課題の1つです。 
[ABSTRACT]学生のエンゲージメントレベルを検出するシステムを使用して集中度インデックスを作成します。結果は、学生と最高スコアの学生も集中度インデックスが高いことを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-18">
        <br><font color="black">2019-09-18</font>
      </time>
    </span>
</section>
<!-- paper0: Video Face Recognition System: RetinaFace-mnet-faster and Secondary
  Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_20.html">
      <font color="black">Video Face Recognition System: RetinaFace-mnet-faster and Secondary
  Search</font>
    </a>
  </h2>
  <font color="black">私たちの方法は大規模なデータセットに適しており、実験結果は、私たちの方法が単一フレーム検出の暴力的な検索よりも82％速いことを示しています。私たちの実験結果は、RetinaFace-mnet-より高速で、640 * 480の解像度でTesla P40とシングルスレッドはそれぞれ16.7％と70.2％の速度を向上させます。最後に、パフォーマンスを向上させるためにHNSWを使用してセカンダリ検索メカニズムを設計します。 
[概要]顔認識は複雑な環境では困難です。これらの複雑な領域にはさまざまな方法が必要です。これらには、3D画像、網膜面、網膜面が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Image-Based Sorghum Head Counting When You Only Look Once -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_21.html">
      <font color="black">Image-Based Sorghum Head Counting When You Only Look Once</font>
    </a>
  </h2>
  <font color="black">これらの洞察は、ベースラインモデルを上回り、サンプル外の平均平均精度0.95を達成する深層学習モデルの開発につながりました。デジタル農業の現代の傾向は、作物の品質評価と収量推定のための人工知能へのシフトを見てきました。 ..私たちのアプローチには、ソルガム画像の主要な構造要素を特定し、パフォーマンスに大きく貢献するパラメーター調整されたアンカーボックスの選択を動機付けた新しい探索的分析が含まれます。 
[概要]デジタル分析を使用して、空中ドローン画像からソルガムヘッドを識別およびカウントできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Cuid: A new study of perceived image quality and its subjective
  assessment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_22.html">
      <font color="black">Cuid: A new study of perceived image quality and its subjective
  assessment</font>
    </a>
  </h2>
  <font color="black">この論文では、制御された実験室環境で主観的評価が収集された画質知覚の新しい研究を提示します。したがって、視覚信号の歪みに対する人間の行動反応を忠実に反映する制御された知覚実験で信頼できる主観的データを取得することが重要です。 。さまざまなカテゴリの画像とさまざまなタイプおよびレベルの歪みの組み合わせによって、品質の知覚がどのように影響を受けるかを調査します。 
[概要]人間の被験者は高度なiqaアルゴリズムの開発につながりました。人間の被験者によるデジタル証拠は開発の基礎として機能します。データベースはキャリブレーションと検証を容易にするために公開されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Segmentation and Analysis of a Sketched Truss Frame Using Morphological
  Image Processing Techniques -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_23.html">
      <font color="black">Segmentation and Analysis of a Sketched Truss Frame Using Morphological
  Image Processing Techniques</font>
    </a>
  </h2>
  <font color="black">このフレームワークのさらなる開発は、構造のモデル化と分析の方法に革命をもたらす可能性があります。このペーパーでは、構造システムの効率を迅速に評価するために画像処理を使用した構造分析の自動化の可能性に焦点を当てます。構造モデリングに含まれる最も時間のかかる手順は、分析を提供するために構造のジオメトリを定義することです。 
[概要]このペーパーでは、構造システムの効率を迅速に評価するために、画像処理を使用した構造解析の自動化の可能性に焦点を当てています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Medical Image Segmentation Using Deep Learning: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_24.html">
      <font color="black">Medical Image Segmentation Using Deep Learning: A Survey</font>
    </a>
  </h2>
  <font color="black">教師あり学習アプローチについては、バックボーンネットワークの選択、ネットワークブロックの設計、損失関数の改善という3つの側面で文献を分析します。弱教師あり学習アプローチについては、データ拡張、転送学習、およびインタラクティブセグメンテーション、個別に..既存の調査と比較して、この調査は以前とは非常に異なる方法で文献を分類し、読者が関連する理論的根拠を理解するのに便利であり、深層学習アプローチに基づく医療画像セグメンテーションの適切な改善を考えるように導きます。 
[概要]医療画像のセグメンテーションを調べるために使用される深層学習手法。これらには、損失関数の成功などの深層学習手法が含まれていました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Cloud Cover Nowcasting with Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_25.html">
      <font color="black">Cloud Cover Nowcasting with Deep Learning</font>
    </a>
  </h2>
  <font color="black">この論文では、衛星ショットの最適化や太陽光発電エネルギー生産予測などのさまざまなアプリケーション分野を持つ雲量ナウキャスティングに焦点を当てます。選択したすべてのアーキテクチャは、永続性よりも大幅に改善され、有名なU-NetはAROME物理モデルを上回っています。 Nowcastingは、最大数時間の短期間の天気予報を目的とした気象学の分野です。 
[概要]雲量のナウキャスティングのために、メテオサット衛星画像に深い畳み込みネットワークを適用しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: PERF-Net: Pose Empowered RGB-Flow Net -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_26.html">
      <font color="black">PERF-Net: Pose Empowered RGB-Flow Net</font>
    </a>
  </h2>
  <font color="black">人間のポーズがRGBピクセル値によって完全に決定されることを考えると、一見、この追加のストリームは冗長に見えるかもしれませんが、この単純で柔軟な追加が補完的なゲインを提供できることを（おそらく驚くべきことに）示しています。ビデオアクション認識の文献は、最先端のパフォーマンスを達成するために2つのストリームモデル（空間入力ストリームと時間入力ストリームを組み合わせる）が必要であることを示しています。この洞察を使用して、PERF-Net（Poseの略）と名付けた新しいモデルを提案します。この新しいポーズストリームを標準のRGBおよびフローベースの入力ストリームと蒸留技術を介して組み合わせたエンパワードRGB-フローネット）は、私たちのモデルが多くの人間の行動認識において最先端を大幅に上回っていることを示していますデータセットは、フローやポーズを推論時に明示的に計算する必要はありません。 
[ABSTRACT] perf --netと名付けた新しいモデルは、この新しいポーズストリームを標準のrgbおよびフローベースの入力ストリームと組み合わせます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Rotated Binary Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_27.html">
      <font color="black">Rotated Binary Neural Network</font>
    </a>
  </h2>
  <font color="black">大きな回転行列の学習の複雑さを回避するために、2つの小さな回転行列を学習する2回転式をさらに紹介します。この論文では、初めて、量子化誤差に対する角度バイアスの影響を調査し、次に完全精度の重みベクトルとその2値化バージョンの間の角度調整を考慮する回転バイナリニューラルネットワーク（RBNN）を導入します。各トレーニングエポックの開始時に、完全精度の重みベクトルをそのバイナリベクトルに回転することを提案します。角度バイアスを減らすため。 
[ABSTRACT]バイナリモデルはgithubで入手できます。ノルムギャップの補正以前の作品は、角度バイアスにほとんど触れずにギャップを補正することに焦点を当てていました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Blur Invariant Kernel-Adaptive Network for Single Image Blind deblurring -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_28.html">
      <font color="black">Blur Invariant Kernel-Adaptive Network for Single Image Blind deblurring</font>
    </a>
  </h2>
  <font color="black">カーネルを効率的に使用するために、ぼけた画像とぼけカーネルの両方からの特徴を低次元空間にエンコードし、それらを同時にデコードして適切に合成された特徴表現を取得する、カーネル適応型AEブロックを提案します。ネットワークはのぼけパターンを学習します。入力画像と、画像固有のブラーカーネルの推定値を生成するためのトレーニング。ブラーカーネルに関する情報を利用する、新しいブラインドの単一画像のブレ除去方法を紹介します。 
[ABSTRACT]私たちのモデルは、ブレ除去の問題を2つの連続するタスクに分割することで解決します。カーネルを提案します。これは、ぼやけた画像とぼやけたカーネルの両方の特徴を低レベルの空間にエンコードする適応型aeブロックです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Stop: A Simple yet Effective Approach to Urban
  Vision-Language Navigation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_29.html">
      <font color="black">Learning to Stop: A Simple yet Effective Approach to Urban
  Vision-Language Navigation</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、挑戦的な都市VLNデータセットのタッチダウンで新しい最先端技術を実現し、距離編集（SED）で重み付けされた成功でベースラインを6.89％（絶対的な改善）上回っています。既存の方法では、STOPアクションを他のアクションと同等に扱います。その結果、エージェントは目的地が正しいパス上にある場合でも、目的地で停止できないことがよくあります。ビジョンと言語のナビゲーション（VLN）は、エージェントが言語の指示に従ってナビゲートすることを学習する自然な言語の接地タスクです。実世界の環境で指定された宛先に。 
[概要]重要な課題は、正しい動作を認識して停止することです。停止するには、新しい言語モジュールが役立つ場合があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Amodal 3D Reconstruction for Robotic Manipulation via Stability and
  Connectivity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_30.html">
      <font color="black">Amodal 3D Reconstruction for Robotic Manipulation via Stability and
  Connectivity</font>
    </a>
  </h2>
  <font color="black">コードはgithub.com/wagnew3/ARMで入手できます。ARMは、（1）オブジェクトの形状よりも前に安定性、（2）前に接続性、（3）マルチチャネル入力を導入するアモーダル3D再構成システムを提案します。オブジェクトのグループ間の関係を推論できる表現。学習ベースの3Dオブジェクト再構成により、3Dオブジェクトモデルのシングルショットまたは数ショットの推定が可能になります。 
[ABSTRACT]モデルベースの方法は、新しいオブジェクトやシーンに迅速に適応できます。これらのシステムは、物理的リアリズムの低い再構成を生成します。オブジェクトの物理的特性よりも優先して、再構成の品質が向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Memory Based Attentive Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_31.html">
      <font color="black">Memory Based Attentive Fusion</font>
    </a>
  </h2>
  <font color="black">ユニモーダルエンコーダからの特徴入力は、注意深い構成と変換によって融合され、その後、結果として得られるメモリ派生特徴とレイヤー入力が単純に融合されます。融合レイヤー内に、の長期依存性を含む特徴を格納する明示的なメモリブロックを導入します。融合データ..この論文では、現在の機能と長期的な依存関係の両方をデータに組み込むことでモードを融合し、モデルが時間の経過に伴うモードの相対的な重要性を理解できるようにする、新しいメモリベースの注意深い融合レイヤーを紹介します。 
[ABSTRACT]最先端の方法のほとんどは、ベースのストリームを独立して処理するナイーブフュージョンを使用し、結合することで潜在的な長期依存関係を無視します。これには、フュージョンデータの長期依存関係を含むフィーチャを格納するフュージョンレイヤーに新しいメモリブロックを作成することが含まれます。 .mbafレイヤーは、さまざまなモダリティとネットワークにわたって一般化して、融合を強化し、パフォーマンスを向上させることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Distribution Matching for Crowd Counting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_32.html">
      <font color="black">Distribution Matching for Crowd Counting</font>
    </a>
  </h2>
  <font color="black">DM-Countでは、Optimal Transport（OT）を使用して、正規化された予測密度マップと正規化されたグラウンドトゥルース密度マップの間の類似性を測定します。OT計算を安定させるために、モデルに全変動損失を含めます。 DM-Countの一般化誤差限界は、ガウス平滑化法のそれよりも厳密です。 
[要約]平均絶対誤差に関して、dm-カウントは、2つの大規模なカウントデータセット、ucf-qnrfおよびnwpuで、以前の最先端の方法を大幅に上回っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: The Elements of End-to-end Deep Face Recognition: A Survey of Recent
  Advances -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_33.html">
      <font color="black">The Elements of End-to-end Deep Face Recognition: A Survey of Recent
  Advances</font>
    </a>
  </h2>
  <font color="black">最後に、顔表現の段階で、認識のために前処理された顔から識別機能が抽出されます。3つの要素はすべて、深い畳み込みニューラルネットワークによって実現されます。顔認識は、で最も基本的で長年のトピックの1つです。コンピュータビジョンコミュニティ。 
[概要]深い顔認識は目覚ましい進歩を遂げ、実際のアプリケーションで広く使用されています。システム全体は通常、顔検出、顔前処理、顔表現の3つの主要要素で構築されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Visual Steering for One-Shot Deep Neural Network Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_34.html">
      <font color="black">Visual Steering for One-Shot Deep Neural Network Synthesis</font>
    </a>
  </h2>
  <font color="black">この手法を反復的に適用することで、アナリストは特定のアプリケーションで最高のパフォーマンスを発揮するニューラルネットワークアーキテクチャに収束できます。この問題に対処するために、ニューラルネットワークアーキテクチャの最適化のタスクをグラフ空間探索として定式化します。ショットアーキテクチャ検索手法..このアプローチでは、すべての候補アーキテクチャのスーパーグラフがワンショットでトレーニングされ、最適なニューラルネットワークがサブグラフとして識別されます。 
[概要]ニューラルネットワークアーキテクチャ検索の完全自動化技術の能力は、人間の専門家のドメイン知識がなければ制限されます。これにより、ネットワークアーキテクチャ空間から学ぶ必要があります。すべての候補アーキテクチャのスーパーグラフが1つでトレーニングされます。ショットと最適なネットワークはサブグラフとして識別されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Sparse-data based 3D surface reconstruction with vector matching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_35.html">
      <font color="black">Sparse-data based 3D surface reconstruction with vector matching</font>
    </a>
  </h2>
  <font color="black">拡張ラグランジュに基づく高速アルゴリズムも提案されています。数値実験は、合成および実世界のデジタルマップの両方の詳細な特徴と複雑な構造を持つ表面を再構築する際のモデルとアルゴリズムの有効性を示しています。一次および二次の全変動正規化器と組み合わせた通常のベクトルマッチングを使用するという考えに基づく提案。 
[概要]新しいモデルによって新しいモデルが提案されました。これは、合成および実世界の数のデータを使用するという考えに基づいています。モデルには、デジタルマップの詳細な機能と複雑な構造があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Texture Memory-Augmented Deep Patch-Based Image Inpainting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_36.html">
      <font color="black">Texture Memory-Augmented Deep Patch-Based Image Inpainting</font>
    </a>
  </h2>
  <font color="black">それにもかかわらず、結果は周囲の領域に似た忠実でシャープな詳細を欠いていることがよくあります。さらに、高品質のパッチ合成を促進するためにパッチ分布損失を導入します。提案された方法は、3つの挑戦的な画像ベンチマークで定性的および定量的に優れたパフォーマンスを示します。つまり、Places、CelebA-HQ、およびParisStreet-Viewデータセットです。一方、
[ABSTRACT]ディープネットワークは、大きな領域を完成させる上で有望な結果を示します。新しいディープインペインティングフレームワークにより、マスクされていない領域から抽出されたパッチサンプルのテクスチャメモリによってテクスチャ生成をガイドできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: EvolGAN: Evolutionary Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_37.html">
      <font color="black">EvolGAN: Evolutionary Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">人間の評価者は、猫用に83.7pc、FashionGen用に74pc、馬用に70.4pc、アートワーク用に69.2pcの頻度で新しいバージョンの画像を好み、顔のすでに優れたGANを少し改善しました。新しい方法は生成につながります元のジェネレーターの多様性を維持しながら、大幅に高品質の画像を作成します。このアプローチは、あらゆる品質スコアラーとGANジェネレーターに適用されます。 
[概要]新しい方法は、より多くの広告の到着につながります。このアプローチは、すべての品質スコアラーとガンジェネレーターに適用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: NITI: Training Integer Neural Networks Using Integer-only Arithmetic -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_38.html">
      <font color="black">NITI: Training Integer Neural Networks Using Integer-only Arithmetic</font>
    </a>
  </h2>
  <font color="black">これにより、すべての浮動小数点実装に匹敵するトレーニング結果が得られます。ImageNetでは、8ビットデータパスを使用した重みの累積に16ビット整数が必要です。外部ランダム数生成の必要性を排除する疑似確率的丸めスキームが提案されています。より広い中間結果から低精度のストレージへの変換を容易にします。 
[概要]これは、高いダイナミックレンジと数値精度の両方が最新のトレーニングアルゴリズムの成功の中心であるためです。これらはトレーニング結果の増加によるものです。代わりに、既存の既存のシステムで16世紀の精度を達成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Interpretable Detail-Fidelity Attention Network for Single Image
  Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_39.html">
      <font color="black">Interpretable Detail-Fidelity Attention Network for Single Image
  Super-Resolution</font>
    </a>
  </h2>
  <font color="black">特徴表現と非線形マッピングのためのディープCNNの強力な機能の恩恵を受けて、ディープラーニングベースの方法は単一画像の超解像で優れたパフォーマンスを達成しました。この意図を追求することを目的として、解決すべき2つの困難な問題があります。 ）スムースとディテールの多様な特性に適応する適切な演算子を学習します。 （2）低周波数のスムージングを保持し、高周波数の詳細を再構築するモデルの機能を向上させます。コードはhttps://github.com/YuanfeiHuang/DeFiANで入手できます。 
[概要]ほとんどの既存のsrメソッドは、最初は視覚認識用に設計されたネットワークの大容量に依存していますが、超解像の最初の意図を考慮することはめったにありません。それらを解決するために、目的を持って解釈可能な詳細を提案します。これらのスムーソンと詳細を分割して処理します-そして-学習方法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Long-Tailed Classification by Keeping the Good and Removing the Bad
  Momentum Causal Effect -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_40.html">
      <font color="black">Long-Tailed Classification by Keeping the Good and Removing the Bad
  Momentum Causal Effect</font>
    </a>
  </h2>
  <font color="black">特に、トレーニングでは因果的介入を使用し、推論では反事実的推論を使用して、「良い」を維持しながら「悪い」を削除します。一方、その誘発された仲介は、表現学習と頭の予測にも役立ちます。既存の方法は、基本的な理論を欠いている再重み付け/再サンプリングヒューリスティックに主に基づいています。 
[ABSTRACT] long-tailed分類は、大規模な深層学習の鍵です。この論文では、因果的結論のフレームワークを確立します。理論は、直接的な因果効果にリンクされている事実に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: RRPN++: Guidance Towards More Accurate Scene Text Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_41.html">
      <font color="black">RRPN++: Guidance Towards More Accurate Scene Text Detection</font>
    </a>
  </h2>
  <font color="black">RRPNは、優れたシーンテキスト検出アプローチの1つですが、手動で設計されたアンカーと粗い提案の改良により、パフォーマンスはまだ完璧にはほど遠いです。さらに、認識ブランチは、提案を再スコアリングし、結合フィルタリング戦略によって誤検知の提案を排除するのにも役立ちます。 ..推論段階では、検出ブランチは提案の絞り込みを出力し、認識ブランチは絞り込みテキスト領域のトランスクリプトを予測します。 
[概要]この論文では、$ pnベースのモデルの可能性をいくつかの改善によって活用するためにrrpnを提案します。開発に基づいて、検出ブランチと認識ブランチが組み込まれ、モデルのパフォーマンスと効率が低下します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-scale Receptive Fields Graph Attention Network for Point Cloud
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_42.html">
      <font color="black">Multi-scale Receptive Fields Graph Attention Network for Point Cloud
  Classification</font>
    </a>
  </h2>
  <font color="black">この論文では、点群分類のためのマルチスケール受容野グラフ注意ネットワーク（MRFGATにちなんで名付けられた）を提案します。提案されたMRFGATアーキテクチャはModelNet10およびModelNet40データセットでテストされ、結果はそれが最先端を達成することを示しています。形状分類タスクのパフォーマンス..ポイントクラウドのローカルの細かい機能に焦点を当て、チャネルアフィニティに基づいてマルチアテンションモジュールを適用することにより、ネットワークの学習された機能マップは、ポイントクラウドの豊富な機能情報を適切にキャプチャできます。 
[ABSTRACT]ポイントネットアーキテクチャは、ローカルポイントクラウド上で直接形状フィーチャを効率的に学習でき、良好なパフォーマンスを実現しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Driver Drowsiness Classification Based on Eye Blink and Head Movement
  Features Using the k-NN Algorithm -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_43.html">
      <font color="black">Driver Drowsiness Classification Based on Eye Blink and Head Movement
  Features Using the k-NN Algorithm</font>
    </a>
  </h2>
  <font color="black">その大規模なデータセットに基づいて、ドライバーの状態分類のためのk最近傍アルゴリズムに基づく特徴選択方法を開発および評価しました。したがって、この作業の目的は、ドライバーの信号を使用して車両のドライバーの眠気検出を拡張することです。監視カメラ..この目的のために、運転免許証の点滅動作と頭の動きに関連する35の特徴が運転シミュレーターの実験で抽出されます。 
[概要]この作業の目的は、ドライバー監視カメラの信号を使用して、車両のドライバーの眠気検知を拡張することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: AIM 2020 Challenge on Video Temporal Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_44.html">
      <font color="black">AIM 2020 Challenge on Video Temporal Super-Resolution</font>
    </a>
  </h2>
  <font color="black">コンテストには68人の登録参加者がおり、最終テストフェーズでは5チーム（1チームが撤退）が参加しました。現実世界で現実的でやりがいのあるダイナミクスをシミュレートするために、トレーニングと評価を目的としたハンドヘルドカメラ。優勝チームは、拡張された2次ビデオ補間法を提案し、VTSRタスクで最先端を実現します。 
[概要]コンテストには68人の登録参加者がおり、最終テストフェーズでは5チームが参加しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Kernel Based Progressive Distillation for Adder Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_45.html">
      <font color="black">Kernel Based Progressive Distillation for Adder Neural Networks</font>
    </a>
  </h2>
  <font color="black">たとえば、提案されたPKKDメソッドを使用してトレーニングされたANN-50は、ImageNetデータセットで76.8 \％のトップ1精度を取得します。これは、ResNet-50よりも0.6 \％高くなります。畳み込みニューラルネットワーク（CNN）と同じアーキテクチャが同時に初期化され、教師ネットワークとしてトレーニングされます。ANNとCNNの機能と重みは、精度の低下を排除するために新しいスペースに変換されます。ここでの主な理由は、$ \ ell_1 $ -normを使用したANNの最適化の難しさです。 、逆伝播の勾配の推定が不正確です。 
[ABSTRACT] annsは、システムのパフォーマンスを向上させるための新しい方法です。カーネルベースの知識蒸留（pkkd）法に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Light Field Image Super-Resolution Using Deformable Convolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_46.html">
      <font color="black">Light Field Image Super-Resolution Using Deformable Convolution</font>
    </a>
  </h2>
  <font color="black">ライトフィールド（LF）カメラは、複数の視点からシーンを記録できるため、画像の超解像（SR）に有益な角度情報を導入できます。さらに、ベースライン調整可能なLFデータセットを開発して、さまざまな視差変動の下でSRのパフォーマンスを評価します。本論文では、LF画像SRの視差問題を処理するために変形可能な畳み込みネットワーク（すなわち、LF-DFnet）を提案する。 
[概要]私たちのアプローチを使用すると、角度情報を適切に組み込み、各ビューの特徴にエンコードすることができます。これらの特徴は、すべてのlf画像のsr再構成に役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Event-based Action Recognition Using Timestamp Image Encoding Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_47.html">
      <font color="black">Event-based Action Recognition Using Timestamp Image Encoding Network</font>
    </a>
  </h2>
  <font color="black">本研究では、イベントデータのエンコードされた時空間画像を入力として取り、アクションラベルを出力する2Dネットワークをエンコードするタイムスタンプ画像を提案します。イベントデータの時空間情報を適切にエンコードして使用することが重要です。データから学習するための標準的なコンピュータービジョンツール。イベントカメラは、消費電力が少ない非同期の高周波ビジョンセンサーであり、人間の行動認識タスクに適しています。 
[ABSTRACT]このメソッドは、ベンチマークと同じレベルのパフォーマンスを達成できます。また、ジェスチャ認識でsotaの結果を達成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Cloud Removal for Remote Sensing Imagery via Spatial Attention
  Generative Adversarial Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CV/paper_48.html">
      <font color="black">Cloud Removal for Remote Sensing Imagery via Spatial Attention
  Generative Adversarial Network</font>
    </a>
  </h2>
  <font color="black">このタスクを解決するために生成的敵対的ネットワークを採用し、リモートセンシング画像クラウド除去タスクに空間的注意メカニズムを導入し、人間の視覚的メカニズムを模倣し、認識して焦点を合わせる空間的注意生成的敵対的ネットワーク（SpA GAN）というモデルを提案します。ローカルからグローバルへの空間的注意を払ったクラウドエリア。これにより、これらのエリアの情報回復が強化され、より高品質のクラウドレス画像が生成されます。ただし、リモートセンシング画像は、気候、特に雲の影響を必然的に受けます。高解像度のリモートセンシング衛星画像は、それを分析する前に不可欠な前処理ステップです。 
[概要]リモートセンシング画像のクラウドを削除するためのニューラルネットワークの使用はまだ比較的小さい</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Presentation and Analysis of a Multimodal Dataset for Grounded Language
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_0.html">
      <font color="black">Presentation and Analysis of a Multimodal Dataset for Grounded Language
  Learning</font>
    </a>
  </h2>
  <font color="black">これにより、ロボット工学、NLP、HCIの共通部分を研究する研究者は、画像、テキスト、音声の複数のモダリティがどのように相互作用するかをよりよく調査し、これらのモダリティの言語の違いが結果に影響を与えることを示すことができます。さまざまなモダリティが人間の入力からの言語学習にどのように影響するかを示す実験を提示します。この作業では、話し言葉または書き言葉のいずれかを使用して人々によって記述された一般的な家庭用オブジェクトのマルチモーダルデータセットであるGrounded Language Dataset（GoLD）を提示します。 
[要約]研究は、さまざまなモダリティが人間からの言語学習にどのように影響するかを示しています-</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Graph-based Multi-hop Reasoning for Long Text Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_1.html">
      <font color="black">Graph-based Multi-hop Reasoning for Long Text Generation</font>
    </a>
  </h2>
  <font color="black">推論されたパスに基づいて、文実現モジュールは完全な文を生成します。GPT-2）および知識強化モデル。ストーリー生成、レビュー生成、製品記述生成を含む3つの代表的なタスクで実験を行います。 
[ABSTRACT] mrgは、文間の意味依存関係を学習することを目的としています。mrgは、提案されたモデルがどのように機能するかを理解するための説明ビューを提供するスケルトン文を明示的に推測します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Transformers with Latent Depth -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_2.html">
      <font color="black">Deep Transformers with Latent Depth</font>
    </a>
  </h2>
  <font color="black">WMTの英語-ドイツ語の機械翻訳とマスクされた言語モデリングタスクを評価します。このタスクは、より深いトランスフォーマーをトレーニングするための既存のアプローチよりも優れています。レイヤー選択の事後分布を学習することにより、使用するレイヤーを自動的に学習する確率的フレームワークを提示します。 .. 100層）。 
[概要]これはこのフレームワークの拡張であり、多言語マシン選択のために1つの共有トランスフォーマーネットワークをトレーニングする新しい方法を提案します。これには、モデル容量の削減や言語言語の理解の許可が含まれます。ただし、これらのタスクの多くは依然としてオープンチャレンジ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Generative latent neural models for automatic word alignment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_3.html">
      <font color="black">Generative latent neural models for automatic word alignment</font>
    </a>
  </h2>
  <font color="black">単語の配置は、並列文ペアの単語間の翻訳対応を識別し、たとえば、二か国語辞書の学習、統計的機械翻訳システムのトレーニング、または品質推定の実行に使用されます。これらの手法は、Giza ++と比較して競争力のある結果をもたらすことができることを示します。そして、2つの言語ペアの強力なニューラルネットワークアラインメントシステムに..この論文では、単語アラインメントのタスクのためにこれらのモデルを研究し、バニラ変分オートエンコーダのいくつかの進化を提案および評価します。 
[ABSTRACT]オートエンコーダーは、教師なし方法で潜在表現を学習するためにさまざまな自然言語処理で使用されてきました。これらの手法は、ギザや2つの言語ペアの強力なニューラルネットワークアライメントシステムと比較して、競争力のある結果を生み出すことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Reactive Supervision: A New Method for Collecting Sarcasm Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_4.html">
      <font color="black">Reactive Supervision: A New Method for Collecting Sarcasm Data</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、他の感情コンピューティングドメインに適応できるため、新しい研究の機会が開かれます。皮肉検出は感情コンピューティングの重要なタスクであり、大量のラベル付きデータを必要とします。リアクティブ監視、これを利用する新しいデータ収集方法を紹介します。既存のデータ収集技術の制限を克服するためのオンライン会話のダイナミクス。 
[概要]新しい方法は生産性研究を前進させることが期待されています。データセットは情報を事前注文するために利用可能になります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Incomplete Utterance Rewriting as Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_5.html">
      <font color="black">Incomplete Utterance Rewriting as Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">この論文では、それをセマンティックセグメンテーションタスクとして定式化する斬新で広範なアプローチを提示します。さらに、私たちのアプローチは、推論における標準的なアプローチよりも4倍高速です。ローカル情報とグローバル情報の両方をキャプチャできるという利点は、私たちのアプローチは、いくつかの公開データセットで最先端のパフォーマンスを実現します。 
[ABSTRACT]以前の作品は通常、機械翻訳タスクとして形作られています。最初から生成するのではなく、そのような化身は編集操作を導入します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Fancy Man Lauches Zippo at WNUT 2020 Shared Task-1: A Bert Case Model
  for Wet Lab Entity Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_6.html">
      <font color="black">Fancy Man Lauches Zippo at WNUT 2020 Shared Task-1: A Bert Case Model
  for Wet Lab Entity Extraction</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、WNUT 2020共有タスク-1：ウェットラボエンティティ抽出に関するチームワークを紹介します。これは、BiLSTM CRFモデルやウェットラボエンティティ抽出を完了するために使用できるバートケースモデルなど、いくつかのモデルで調査を実施しました。自動またはラボ手順を実行するステップを指定するプロトコルを機械可読形式に半自動で変換することは、生物学的研究に大きなメリットをもたらします。これらのノイズが多く、密度が高く、ドメイン固有のラボプロトコル処理は、深層学習の開発にますます関心を集めています。 
[概要]主にラボプロトコルのパフォーマンスの違いについて説明しました。また、特定のラボ科目のパフォーマンスの違いについても説明しました。ディープラーニングがどのように行われるかも確認できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: TransModality: An End2End Fusion Method with Transformer for Multimodal
  Sentiment Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_7.html">
      <font color="black">TransModality: An End2End Fusion Method with Transformer for Multimodal
  Sentiment Analysis</font>
    </a>
  </h2>
  <font color="black">モダリティ間の変換は、話者の発話のより良い共同表現に寄与すると想定しています。複数のマルチモーダルデータセット（CMU-MOSI、MELD、IEMOCAP）でモデルを検証します。さまざまな融合方法が提案されていますが、エンドを採用しているものはほとんどありません。 -モダリティ間の微妙な相関関係をマイニングするためのエンドツーエンドの翻訳モデル。 
[概要]マルチモーダル感情分析のタスクに対処するために、新しい融合方法であるトランスモダリティを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Reducing Quantity Hallucinations in Abstractive Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_8.html">
      <font color="black">Reducing Quantity Hallucinations in Abstractive Summarization</font>
    </a>
  </h2>
  <font color="black">抽象的要約が幻覚の対象となることはよく知られています---元のテキストでサポートされていない資料を含みます..最新のモデルによって生成された抽象的要約のビーム価値で、 -数量項が元のテキストでサポートされている要約をランク付けします。実験結果は、このようなランク付けされた要約のROUGEスコアは、ランク付けされていない要約よりも精度が高く、リコールで同等の損失がないことを示しています。より高いF $ _1 $で。 
[ABSTRACT]ビーム内で-抽象的要約の価値があり、ランクアップするために-元のテキストでサポートされている数量用語でそれらの要約をランク付けします。結果は、前者に対する人々の好みを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: MinTL: Minimalist Transfer Learning for Task-Oriented Dialogue Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_9.html">
      <font color="black">MinTL: Minimalist Transfer Learning for Task-Oriented Dialogue Systems</font>
    </a>
  </h2>
  <font color="black">広範な実験により、1）当社のシステムは、エンドツーエンドの応答生成に関して新しい最先端の結果を確立します。2）MinTLベースのシステムは、低リソース設定でベースライン方式よりも堅牢であり、競争力を実現します。 20 \％のトレーニングデータのみで結果が得られ、3）Levは推論効率を大幅に向上させます。コピーメカニズムを使用して古いダイアログ状態を新しいダイアログ状態に「引き継ぐ」以前のアプローチとは異なり、Levenshteinの信念スパン（Lev）を導入します。 、最小の生成長で効率的な対話状態追跡を可能にします。この論文では、タスク指向対話システムのシステム設計プロセスを簡素化し、注釈付きデータへの過度の依存を軽減するために、ミニマリスト転送学習（MinTL）を提案します。 
[ABSTRACT] mintlは、事前にトレーニングされたseq2seqモデルをプラグアンドプレイし、対話状態の追跡を共同で学習できるシステムです。このシステムは、t5とbartに基づいており、t5、bartで終わります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-25">
        <br><font color="black">2020-09-25</font>
      </time>
    </span>
</section>
<!-- paper0: Comparison Between Traditional Machine Learning Models And Neural
  Network Models For Vietnamese Hate Speech Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_10.html">
      <font color="black">Comparison Between Traditional Machine Learning Models And Neural
  Network Models For Vietnamese Hate Speech Detection</font>
    </a>
  </h2>
  <font color="black">VLSP-ソーシャルネットワークでのヘイトスピーチ検出に関する共有タスクは、コメントがクリーンかどうかを検出するための多くの提案されたアプローチを示しました。したがって、ベトナム語のソーシャルネットワークでのユーザーのコメントに関する大規模なデータセットでの従来の機械学習とディープラーニングを比較します。 F1スコアでの精度を比較して、各モデルの長所と短所を見つけ、従来の機械学習モデルとディープニューラルモデルでそれぞれ精度が最も高い2つのモデルを選択します。次に、これら2つのモデルを比較します。混同行列を参照し、各モデルの長所と短所を考慮して、適切なラベルを予測します。 
[概要]ベトナムでは、攻撃や嫌がらせの脅威がオンラインユーザーに悪影響を及ぼしますが、問題についてはさらに調査が必要です。これらのモデルは、混同行列に言及することで適切なラベルを予測できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-31">
        <br><font color="black">2020-01-31</font>
      </time>
    </span>
</section>
<!-- paper0: Twitter Corpus of the #BlackLivesMatter Movement And Counter Protests:
  2013 to 2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_11.html">
      <font color="black">Twitter Corpus of the #BlackLivesMatter Movement And Counter Protests:
  2013 to 2020</font>
    </a>
  </h2>
  <font color="black">BlackLivesMatter、AllLivesMatter、BlueLivesMatterのいずれかのキーワードを含む1,000万人のユーザーからの4,180万件のツイートのデータセットを紹介します。＃AllLivesMatterや#BlueLivesMatterなどの同様のハッシュタグがBLMの動きに対抗するように見えました。 -計算社会科学、通信、政治科学、自然言語処理、機械学習の分野での研究を促進するために、大規模なデータセットを調達します。 
[概要]この運動はメディアや政治的注目を集めています。アマド・アーバリー、ブレオナ・テイラー、ジョージ・フロイドの殺害に続いて、2020年にジェイコブ・ブレイクが撃たれました。同様のハッシュタグが、＃alllivesmatterや＃bluelivesmatter</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Navigating Language Models with Synthetic Agents -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_12.html">
      <font color="black">Navigating Language Models with Synthetic Agents</font>
    </a>
  </h2>
  <font color="black">この研究では、歴史的なチェスゲームのコーパスでGPT-2のバージョンをトレーニングし、テキスト文字列を使用してコンテキストと方向を作成し、合成エージェントのクラスターをモデルに「起動」します。に含まれる軌跡を比較します。エージェント/モデルによって生成されたテキストをチェス盤の既知のグラウンドトゥルースと比較し、合法性を動かし、遊びの歴史的パターンを比較します。GPT-2/ GPT-3などの現代の自然言語モデルには、膨大な量の情報が含まれています。一貫してテスト可能な形での人間の信念について。 
[概要]モデルはチェス盤の正確な潜在的表現を作成します。この知識を使用して、全面的な合法的な動きの軌跡をプロットすることが可能です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Functions to Study the Benefit of Multitask Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_13.html">
      <font color="black">Learning Functions to Study the Benefit of Multitask Learning</font>
    </a>
  </h2>
  <font color="black">MTLの場合、タスク数（T）、タスクあたりのサンプル数（n）、および調整された相互情報量（AMI）によって測定されたタスクの関連性に対してモデルのパフォーマンスを調査します。 MTLモデルは存在しますが、タスクの関連性やバランスの取れたデータセットの使用などの強力な仮定に依存しています。これらの混合結果は、MTLモデルのパフォーマンスに影響を与える要因を研究する動機になります。 
[ABSTRACT] mtlモデルは、関連する一連のタスクを共同で最適化するようにトレーニングされています。これらの混合結果は、mtlモデルのパフォーマンスに影響を与える要因を研究する動機になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-09">
        <br><font color="black">2020-06-09</font>
      </time>
    </span>
</section>
<!-- paper0: Knowledge-Aware Procedural Text Understanding with Multi-Stage Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_14.html">
      <font color="black">Knowledge-Aware Procedural Text Understanding with Multi-Stage Training</font>
    </a>
  </h2>
  <font color="black">最近のアプローチはかなりの進歩を遂げましたが、人間のパフォーマンスには大きく遅れをとっています。2つの手続き型テキストデータセット、ProParaとRecipesの実験結果は、提案された方法の有効性を検証します。この方法では、モデルがさまざまなベースラインとの比較..常識的な推論の難しさとデータの不足という2つの課題は、未解決のままです。 
[概要]外部の知識源を使用してこれらの問題を解決する、新しい知識を意識した手続き型テキスト理解（コアラ）モデルを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: A Simple and Efficient Ensemble Classifier Combining Multiple Neural
  Network Models on Social Media Datasets in Vietnamese -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_15.html">
      <font color="black">A Simple and Efficient Ensemble Classifier Combining Multiple Neural
  Network Models on Social Media Datasets in Vietnamese</font>
    </a>
  </h2>
  <font color="black">私たちの単一モデルは、各データセットで肯定的な結果に達します。この分野では、多くの言語でさまざまな研究がありますが、ベトナム語に限定されています。私たちの実験では、特定の各データセットの分類タスクに適したモデルを見つけます。 
[概要]この調査は、ソーシャルメディア上のベトナム語のテキストを3つの異なるベトナム語ベンチマークデータセットから分類することを目的としています。これらには、3つのデータセットすべてで最高のパフォーマンスが含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Visual Exploration and Knowledge Discovery from Biomedical Dark Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_16.html">
      <font color="black">Visual Exploration and Knowledge Discovery from Biomedical Dark Data</font>
    </a>
  </h2>
  <font color="black">この分析研究により、圧倒的な量の情報を分析する問題を克服し、そのような大量のデータを処理および調査する際の人間の認識と知覚の制限を軽減するための潜在的なソリューションを提供することを目指しています。自然言語処理ベースのパイプラインを採用しています。生物医学の暗いデータから知識を発見するために..しかし、そのほとんどは構造に欠けており、簡単に分類して通常のデータベースにインポートすることはできません。 
[概要]このタイプのデータは、「ダークデータ」と呼ばれることがよくあります。これらのタイプの情報は、ダークデータとしてラベル付けされることがよくあります。これらの情報は、主なキーであるさまざまな情報視覚化手法を使用した洞察を調査および理解するために使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Baselines for Word Alignment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_17.html">
      <font color="black">Neural Baselines for Word Alignment</font>
    </a>
  </h2>
  <font color="black">また、モデルが克服するベースラインの典型的なアラインメントエラーを分析して、形態学的に豊富な言語に対するこれらの新しいモデルの利点と制限を説明します。この作業では、4つの言語の教師なし単語アラインメントのニューラルモデルを調査し、包括的に評価します。ペア、ニューラルモデルのいくつかのバリアントを対比します。ほとんどの設定で、IBM-1のニューラルバージョンと隠れマルコフモデルが、個別のモデルよりも大幅に優れていることを示します。 
[概要]ほとんどの設定で、ニューラルネットワークが優先されるマシンであることを示します。自然言語処理のほとんどの領域では、これらのモデルが実際に優先されるシステムです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: SPARTA: Efficient Open-Domain Question Answering via Sparse Transformer
  Matching Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_18.html">
      <font color="black">SPARTA: Efficient Open-Domain Question Answering via Sparse Transformer
  Matching Retrieval</font>
    </a>
  </h2>
  <font color="black">結果として得られる表現は、高価な近似ベクトル検索を必要とせず、高密度の対応物よりも優れたパフォーマンスをもたらすスケーラブルなニューラル検索を可能にします。SPARTAは、両方の英語のさまざまなオープンドメイン質問応答タスクにわたって新しい最先端の結果を実現します。オープンSQuAD、Natural Question、CMRCなどを含む中国のデータセット。分析により、提案された方法が人間が解釈できる表現を作成し、パフォーマンスと効率の間のトレードオフを柔軟に制御できることも確認されます。 
[ABSTRACT] spartaは、転置インデックスとして効率的に実装できるスパース表現を学習します。これにより、オープンドメインの質問回答と11の検索パフォーマンス回答が可能になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Type B Reflexivization as an Unambiguous Testbed for Multilingual
  Multi-Task Gender Bias -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_19.html">
      <font color="black">Type B Reflexivization as an Unambiguous Testbed for Multilingual
  Multi-Task Gender Bias</font>
    </a>
  </h2>
  <font color="black">すべてのタスク言語の組み合わせで性別バイアスの証拠を見つけ、モデルバイアスを全国労働市場統計と相関させます。代わりに、相互参照の読み取りには性別のない代名詞が必要であり、性別のある所有的な代名詞は反反射的です。 4つの言語と4つのNLPタスクにまたがり、この現象のみに焦点を当てた、多言語、マルチタスクのチャレンジデータセット。 
[要約]性別による偏見は、明確に間違ったモデル予測につながる可能性があります。これらの言語では、「医師がマスクを外した」の直接翻訳は、相互参照の読みとばらばらの読みの間で曖昧ではありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Computer Assisted Translation with Neural Quality Estimation and
  Automatic Post-Editing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_20.html">
      <font color="black">Computer Assisted Translation with Neural Quality Estimation and
  Automatic Post-Editing</font>
    </a>
  </h2>
  <font color="black">人間の翻訳者の行動を模倣するために、品質推定、生成後編集、アトミック操作後編集の3つの効率的な委任モジュールを設計し、それらに基づいて階層モデルを構築します。また、認定翻訳者が大幅に迅速化できることを確認します。人間の評価における私たちのモデルを使用した編集後の処理..WMT2017 APE共有タスクからの英語-ドイツ語データセットを使用してこのアプローチを検証し、実験結果で最先端のパフォーマンスを実現できます。 
[概要]機械翻訳システムと人間の翻訳者の間のギャップは、投稿編集によって手動で埋める必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-19">
        <br><font color="black">2020-09-19</font>
      </time>
    </span>
</section>
<!-- paper0: Pchatbot: A Large-Scale Dataset for Personalized Chatbot -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_21.html">
      <font color="black">Pchatbot: A Large-Scale Dataset for Personalized Chatbot</font>
    </a>
  </h2>
  <font color="black">予備的な実験的研究では、Pchatbotでトレーニングされたパーソナライズされたチャットボットモデルが、対応するアドホックチャットボットモデルよりも優れていることが示されています。このホワイトペーパーでは、WeiboフォーラムとJudicalフォーラムからそれぞれ収集された2つのサブセットを含む大規模なダイアログデータセットであるPchatbotを紹介します。ユーザーの過去の会話の可用性に依存するパーソナライズされた対話モデルの開発を可能にします。 
[概要] pchatbotの規模は既存のデータセットよりも大幅に大きいため、データ駆動型モデルにメリットがある可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: What Disease does this Patient Have? A Large-scale Open Domain Question
  Answering Dataset from Medical Exams -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_22.html">
      <font color="black">What Disease does this Patient Have? A Large-scale Open Domain Question
  Answering Dataset from Medical Exams</font>
    </a>
  </h2>
  <font color="black">MedQAは既存のOpenQAシステムに大きな課題を提示し、将来的にNLPコミュニティからはるかに強力なOpenQAモデルを促進するためのプラットフォームとして機能することを期待しています。英語、簡体字中国語、繁体字中国語の3つの言語をカバーしています。 3つの言語のそれぞれ12,723、34,251、および14,123の質問が含まれています。ドキュメントリトリーバーと機械理解モデルを順次組み合わせることにより、ルールベースのニューラルメソッドと一般的なニューラルメソッドの両方を実装します。 
[概要]医学的問題を解決するための最初の自由形式の多肢選択式openqaデータセットmedqaは、専門の医療委員会試験から収集されました。データセットには、3つのルールベースの一般的なニューラルメソッドが含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Mitigating Gender Bias for Neural Dialogue Generation with Adversarial
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_23.html">
      <font color="black">Mitigating Gender Bias for Neural Dialogue Generation with Adversarial
  Learning</font>
    </a>
  </h2>
  <font color="black">ただし、対話モデルに性別ごとに同様の応答を生成させる可能性があるため、対話システムに直接適用することはできません。これにより、生成される応答の多様性が大幅に低下し、対話モデルのパフォーマンスが大幅に低下します。特に、彼らは人々の性別の偏見を反映する反応を生み出すことができます。 
[ABSTRACT]人間の会話データで訓練された対話システムは偏っています。彼らは、フレームワークが対話モデルの性差別を減らすと言います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Towards an Argument Mining Pipeline Transforming Texts to Argument
  Graphs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/cs.CL/paper_24.html">
      <font color="black">Towards an Argument Mining Pipeline Transforming Texts to Argument
  Graphs</font>
    </a>
  </h2>
  <font color="black">このペーパーは、自然言語テキストからの議論情報のコンポーネントとそれらの関係の自動抽出を対象としています。パイプラインの実装はGitHubで公開されています。生成された議論グラフは、議論の余地のあるテキスト。 
[概要]完全な議論構造を提供するシステムの欠如に対処します。また、既存のベンチマーク議論構造に基づいて結果を評価するための新しい方法を紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-08">
        <br><font color="black">2020-06-08</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Siamese Capsule Network for End-to-End Speaker Recognition In The Wild -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-29/eess.AS/paper_0.html">
      <font color="black">Siamese Capsule Network for End-to-End Speaker Recognition In The Wild</font>
    </a>
  </h2>
  <font color="black">モデルに対して一連の実験と最新のソリューションとの比較を行い、モデルが他のすべてのモデルよりも大幅に少ないトレーニングデータを使用してパフォーマンスを向上させていることを示しています。埋め込みを使用することで最高のパフォーマンスが達成されることを示しています。フロントエンドの機能集約モジュールから直接取得し、動的ルーティングを使用してそれらをより高いカプセルに渡します。実際の話者検証のためのエンドツーエンドのディープモデルを提案します。 
[概要]私たちのモデルは、シンパフォーマンスシステムを使用して埋め込みを抽出します。また、さまざまなスピーカー埋め込みの影響を調査するために追加の実験を実行します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
