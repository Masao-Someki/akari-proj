<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-10-15の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Towards Resistant Audio Adversarial Examples -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.SD/paper_0.html">
      <font color="black">Towards Resistant Audio Adversarial Examples</font>
    </a>
  </h2>
  <font color="black">生成プロセスの欠陥により、最先端の敵対的な例の生成方法が、ターゲット音声認識システム（Mozilla Deepspeechなど）でのビニング操作のために過剰適合を引き起こすことがわかりました。現実的な無線設定での編集距離の経験的比較によるアプローチ。私たちのアプローチは、無線攻撃に向けた重要な一歩を示しています。 
[ABSTRACT]敵対的な例の方法では、ビニング操作が原因で過剰適合が発生します。現実的な地上波設定で編集距離を比較することにより、アプローチによる大幅な改善を確認します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Exploiting Spectral Augmentation for Code-Switched Spoken Language
  Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.SD/paper_1.html">
      <font color="black">Exploiting Spectral Augmentation for Code-Switched Spoken Language
  Identification</font>
    </a>
  </h2>
  <font color="black">これにより、インドの文脈では音声LIDタスクが非常に困難になります。インドの言語の文脈でかなりの数のLIDシステムが実装されていますが、そのようなシステムのほとんどは、組織内で収集された小規模の音声データを使用しています。私たちは、英語とコードを組み合わせた3つのインド言語（Gujarati、Telugu、およびTamil）で音声LIDを実行します。 
[概要]マイクロソフトのスピーキングリッドチャレンジは、マイクロソフトリサーチチームによって音声リッドチャレンジとして開催されました。チャレンジには、音声信号に存在する言語を識別する機能が含まれます。これらには、その州の公用語、ヒンディー語、英語が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Hear her Fear: Data Sonification for Sensitizing Society on Crime
  Against Women in India -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.SD/paper_2.html">
      <font color="black">Hear her Fear: Data Sonification for Sensitizing Society on Crime
  Against Women in India</font>
    </a>
  </h2>
  <font color="black">ユーザーフレンドリーなインターフェースは、順次および比較データソニフィケーションの複数のオプションで開発されています。インドの州の女性に対する犯罪に関する機密データとの没入型エンゲージメントを提供するデータソニフィケーションの可能性を探ります。インターフェースを通じて、ユーザーは評価できますまたは、さまざまな州、年、または犯罪カテゴリの女性に対する犯罪の程度を比較します。 
[概要] 35〜5つのインドの州をカバーする9つの犯罪カテゴリのデータは国の記録から取得されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-29">
        <br><font color="black">2020-09-29</font>
      </time>
    </span>
</section>
<!-- paper0: A variational autoencoder for music generation controlled by tonal
  tension -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.SD/paper_3.html">
      <font color="black">A variational autoencoder for music generation controlled by tonal
  tension</font>
    </a>
  </h2>
  <font color="black">ユーザー入力または潜在空間からの直接サンプリングのいずれかから生じるシード音楽フラグメントが与えられると、モデルは、トーン張力が変更されたこの元のシードフラグメントのバリエーションを生成できます。スパイラルアレイ張力理論に基づく2つのトーン張力測定を組み込みます。変分オートエンコーダモデルに変換します。これにより、生成されたピース全体の音の張力の方向と、音の張力の全体的なレベルを制御できます。 
[概要]これにより、生成されたピース全体の色調張力の方向と、全体的な色調張力のレベルを制御できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Robotic Pouring using Audition and Haptics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.SD/paper_4.html">
      <font color="black">Robust Robotic Pouring using Audition and Haptics</font>
    </a>
  </h2>
  <font color="black">MP-Netは、自己収集されたマルチモーダル注入データセットでトレーニングされます。代わりに、オーディションと触覚の両方の入力を条件として液体の高さを確実に予測できるマルチモーダル注入ネットワーク（MP-Net）を提案します。このデータセットには300台のロボットが含まれています。 3種類のターゲットコンテナの音声および力/トルク測定値を使用して録音を流し込みます。 
[概要]ビジョンベースの方法は、閉塞状態で失敗することがよくあります。代わりに、オーディオベースの方法は、ノイズの多い環境ではうまく機能しません。ネットワークトレーニングの結果とロボット実験は、mp-netがノイズやタスクと環境の変化に対して堅牢であることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-29">
        <br><font color="black">2020-02-29</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: 3D Segmentation Networks for Excessive Numbers of Classes: Distinct Bone
  Segmentation in Upper Bodies -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.IV/paper_0.html">
      <font color="black">3D Segmentation Networks for Excessive Numbers of Classes: Distinct Bone
  Segmentation in Upper Bodies</font>
    </a>
  </h2>
  <font color="black">このため、ほとんどの確立された方法を直接適応させることはできません。ディープラーニング方法を使用した3Dデータの完全に監視されたセグメンテーションは、多くのタスクで広く研究されていますが、通常は少数のクラスのみを区別するように制限されています。 CTスキャンからエンドツーエンドで学習した方法で、100を超える個別の骨を同時に自動的にセグメント化することにより、この方法の堅牢性を示します。 
[概要]外科的介入の計画と医療専門家の教育のための視覚化ツールに情報を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Practical Deep Raw Image Denoising on Mobile Devices -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.IV/paper_1.html">
      <font color="black">Practical Deep Raw Image Denoising on Mobile Devices</font>
    </a>
  </h2>
  <font color="black">私たちが提案するモバイルフレンドリーなノイズ除去モデルは、Qualcomm Snapdragon 855チップセットでメガピクセルあたり約70ミリ秒で動作し、2019年にリリースされたいくつかのフラッグシップスマートフォンのナイトショット機能の基礎となっています。私たちの重要な洞察は2つあります。センサーのノイズレベルを推定すると、合成センサー固有のデータでトレーニングされた小さなネットワークは、一般的なデータでトレーニングされた大きなネットワークよりもパフォーマンスが優れている可能性があります。 （2）異なるISO設定での大きなノイズレベルの変動は、新しいk-Sigma変換によって除去でき、小さなネットワークで広範囲のノイズレベルを効率的に処理できます。この作業では、軽量で効率的な提案を行います。主流のモバイルデバイス上でスムーズに動作し、高品質のノイズ除去結果を生成するニューラルネットワークベースの生画像ノイズ除去装置。 
[概要]提案されたモバイルフレンドリーなノイズ除去モデルは、クアルコムのキンギョソウ855チップセットでメガピクセルあたり約70ミリ秒で動作します。これは、2019年にリリースされたいくつかのフラッグシップスマートフォンのナイトショット機能の基礎です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Morphological Reconstruction Improves Microvessel Mapping in
  Super-Resolution Ultrasound -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.IV/paper_2.html">
      <font color="black">Morphological Reconstruction Improves Microvessel Mapping in
  Super-Resolution Ultrasound</font>
    </a>
  </h2>
  <font color="black">具体的には、フレームごとに検出されるピークの数が4倍に増加し、処理に100ミリ秒のオーダーが必要であり、付加的な電子ノイズ（CEUS画像で3.6 dB CNRまで）に対して堅牢です。この方法は計算上です。効率的で、したがって大規模なデータセットにスケーラブルであるため、微小血管の構造と機能のイメージングにおけるSR-USの能力が増強される可能性があります。この方法をSRフレームワークに統合することにより、CEUSと比較して空間分解能が6倍向上することを示します。 、ニワトリ胚微小血管の画像化。 
[概要]この方法は、超高速造影剤から抽出できます-強化された超音波。画像ごとに数百のマイクロバブルピークを抽出できます（312-by --180zation）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-19">
        <br><font color="black">2020-09-19</font>
      </time>
    </span>
</section>
<!-- paper0: A Pathologist-Annotated Dataset for Validating Artificial Intelligence:
  A Project Description and Pilot Study -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.IV/paper_3.html">
      <font color="black">A Pathologist-Annotated Dataset for Validating Artificial Intelligence:
  A Project Description and Pilot Study</font>
    </a>
  </h2>
  <font color="black">ワークフローは、ROIタイプ、ROIがsTILの密度を推定するのに適切かどうかの決定、および適切な場合はそのROIのsTIL密度値を収集します。目的：この作業では、検証データセットを作成するためのコラボレーションを提示します。スライド画像全体（WSI）を処理するアルゴリズムの病理学者の注釈の一覧。最終的には、データセット、統計手法、および学んだ教訓を共有する予定です。 
[概要]アルゴリズムのパフォーマンスのデータ収集と評価に重点を置いています。病理医の画像をクラウドソーシングするためのトレーニング資料とワークフローを作成しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: PP-LinkNet: Improving Semantic Segmentation of High Resolution Satellite
  Imagery with Multi-stage Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.IV/paper_4.html">
      <font color="black">PP-LinkNet: Improving Semantic Segmentation of High Resolution Satellite
  Imagery with Multi-stage Training</font>
    </a>
  </h2>
  <font color="black">最近、ディープニューラルネットワークの適用による画像セグメンテーションの改善により、大規模な高解像度衛星画像から道路セグメントを抽出するという有望な結果が示されました。道路ネットワークのマッピングは、現在、費用と労力の両方がかかります。この論文では、提案します。クラウドソースのOpenStreetMap（OSM）データから自動的に（人的労力なしで）取得されたノイズの多い疑似グラウンドトゥルースマスクを活用する、衛星画像のセマンティックセグメンテーションの堅牢性を向上させる2段階の転送学習手法。 
[概要]道路網のマッピングは現在、費用と労力の両方がかかります。改善には、業界グレードのアプリケーションのモデルを構築するために必要なラベル付きトレーニングデータの欠如が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Low-rank Convex/Sparse Thermal Matrix Approximation for Infrared-based
  Diagnostic System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.IV/paper_5.html">
      <font color="black">Low-rank Convex/Sparse Thermal Matrix Approximation for Infrared-based
  Diagnostic System</font>
    </a>
  </h2>
  <font color="black">これらの方法は、主成分サーモグラフィ（PCT）とスパースPCTの利点を継承しますが、非負の制約でスパースPCTの負のベースに取り組み、データの処理でクラスタリング特性を示します。これらの方法の実用性と効率は、実験によって実証されています。 3つの標本（異なる深さとサイズの欠陥）での表面下欠陥検出の結果と、乳癌スクリーニングデータセットで乳房異常を区別するための熱的不均一性の維持（74.1％、75.8％、および77.8％の精度）。アクティブサーモグラフィとパッシブサーモグラフィは2つです。診断評価のために表面下の欠陥につながる不均一な熱パターンを測定するために広く使用されている効率的な手法。 
[概要]これらの方法は、乳房の異常を区別するために、表面下の欠陥を検出し、熱を維持するために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient and high accuracy 3-D OCT angiography motion correction in
  pathology -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.IV/paper_6.html">
      <font color="black">Efficient and high accuracy 3-D OCT angiography motion correction in
  pathology</font>
    </a>
  </h2>
  <font color="black">さらに、高度に並列化された実装と短い実行時間のために設計されており、高密度または広視野スキャンでも臨床ルーチンに統合できます。この方法を使用して、最先端の軸方向性能を達成し、両方で大幅な進歩を示します特に病理学的サブグループにおける横方向の協調と歪みの補正..広範囲の病理学と健康の両方を含む17人の被験者の204の体積スキャンに基づく大規模な定量的評価において、臨床的に関連する特徴に関連するメトリックを使用してアルゴリズムを評価しましたコントロール。 
[概要]これは、主に血管造影血管造影や血管造影血管などの繊維構造の特徴を調整する最初のアプローチです。特定の構造や層がセグメント化されていないため、このアプローチは設計上、病理学的運動に対してロバストです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Ground-truth resting-state signal provides data-driven estimation and
  correction for scanner distortion of fMRI time-series dynamics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.IV/paper_7.html">
      <font color="black">Ground-truth resting-state signal provides data-driven estimation and
  correction for scanner distortion of fMRI time-series dynamics</font>
    </a>
  </h2>
  <font color="black">重要なことに、CNNの時間的ノイズ除去がST-SNR&gt; 1をプッシュすることを観察しました。4つのスキャナーから取得した動的ファントムデータは、スキャナーの不安定性の乗法性ノイズの寄与が全ノイズの約6〜18％であることを示しました。動的ファントムを使用して、定量化しました。グラウンドトゥルース時系列をその測定されたfMRIデータと比較することによるボクセルワイズノイズ。 
[ABSTRACT] fmriのファントムは、安静時の脳と同等の動的信号を提供できます。センサーは、ボクセル全体の8〜19％で、スキャナー間で直接比較できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-14">
        <br><font color="black">2020-04-14</font>
      </time>
    </span>
</section>
<!-- paper0: Differential diagnosis and molecular stratification of gastrointestinal
  stromal tumors on CT images using a radiomics approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.IV/paper_8.html">
      <font color="black">Differential diagnosis and molecular stratification of gastrointestinal
  stromal tumors on CT images using a radiomics approach</font>
    </a>
  </h2>
  <font color="black">3人の放射線科医のAUCはそれぞれ0.69、0.76、0.84でした。画像、年齢、性別、場所を含むGISTと非GISTの放射線科モデルの平均曲線下面積（AUC）は0.82でした。放射線モデルのAUCは、\ textit {c-KIT}で0.52、\ textit {c-KIT}エクソン11で0.56、MIで0.52でした。 
[ABSTRACT]ラジオミクスは、要点を他の腹腔内腫瘍と区別するためにラジオミクスを評価することであり、要点では、要点と画像、年齢、性別、場所を含むラジオミクスモデルの平均曲線下面積（auc）が0. 82</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Interpretation of 3D CNNs for Brain MRI Data Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.IV/paper_9.html">
      <font color="black">Interpretation of 3D CNNs for Brain MRI Data Classification</font>
    </a>
  </h2>
  <font color="black">最近の研究では、特定の脳領域の形態学的差異が畳み込みニューラルネットワーク（CNN）を使用してMRIで検出できることが示されています。ただし、既存のモデルの解釈は関心領域に基づいており、ボクセルに拡張することはできません。画像全体の賢明な画像解釈..現在の作業では、若い健康な被験者の大規模なオープンソースデータセットでの分類タスクを検討します-男性と女性の間の脳の違いの調査。 
[ABSTRACT]ニューラルネットワークは、大規模な前処理なしでフル6データを処理できます。モデルの変更は、関心領域に基づいています。この論文では、性差に関する以前の調査結果を拡張しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-20">
        <br><font color="black">2020-06-20</font>
      </time>
    </span>
</section>
<!-- paper0: Fast meningioma segmentation in T1-weighted MRI volumes using a
  lightweight 3D deep learning architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.IV/paper_10.html">
      <font color="black">Fast meningioma segmentation in T1-weighted MRI volumes using a
  lightweight 3D deep learning architecture</font>
    </a>
  </h2>
  <font color="black">全体として、混合精度トレーニングを使用すると、軽量PLS-Netアーキテクチャを使用して比較的短時間で競合セグメンテーションモデルをトレーニングすることができました。2つの異なる3Dニューラルネットワークアーキテクチャを研究しました。（i）単純なエンコーダ- 3D U-Netに類似したデコーダー、および（ii）軽量マルチスケールアーキテクチャ（PLS-Net）。モデルは、検出精度、セグメンテーション精度、およびトレーニング/推論速度の観点から評価されました。 
[概要]外来診療所では、外科的に治療された髄膜腫と未治療の髄膜腫の両方が多数続いた。モデルは、検出精度、セグメンテーション精度、および病院向けのトレーニングの観点から評価された。最大の髄膜腫で最高の精度が達成された。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Exploiting wavelength diversity for high resolution time-of-flight 3D
  imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.IV/paper_11.html">
      <font color="black">Exploiting wavelength diversity for high resolution time-of-flight 3D
  imaging</font>
    </a>
  </h2>
  <font color="black">最先端の飛行時間（ToF）ベースの3Dセンサーは、横方向と深さの解像度が低いという問題があります。他の連続波振幅変調ToF原理とは異なり、私たちのアプローチは、巨視的な干渉表面測定に波長多様性を利用します。粗いまたは鏡面のオブジェクト..この原則に基づいて、3つの異なるセンサーアーキテクチャを活用して、プロトタイプセンサーの3つの異なる実施形態を紹介します。 
[概要]新しいシステムは、最大35マイクロメートルの深度精度とネイティブセンサーでの点群密度（状態の解像度）、tofカメラ（最大数メガピクセル）を使用して、実世界のオブジェクトの3D測定を使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Deep S$^3$PR: Simultaneous Source Separation and Phase Retrieval Using
  Deep Generative Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.IV/paper_12.html">
      <font color="black">Deep S$^3$PR: Simultaneous Source Separation and Phase Retrieval Using
  Deep Generative Models</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、ソース分離と位相回復（S $ ^ 3 $ PR）の同時問題を紹介して解決します。一般に、S $ ^ 3 $ PRは非常に劣決定で、凸面ではなく、解決が困難です。S$ ^ 3 $ PRは、顕微鏡法、無線通信、散乱媒体を介したイメージングなど、位相を測定するのが難しい複数の独立したコヒーレントソースがある多くのアプリケーションドメインで重要ですが、ほとんど解決されていない問題です。 
[概要] s $ 1b 3 $ prは、顕微鏡法、無線通信、散乱媒体を介したイメージングなど、多くのアプリケーションドメインで重要ですが、ほとんど解決されていない問題です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-14">
        <br><font color="black">2020-02-14</font>
      </time>
    </span>
</section>
<!-- paper0: Identification of images of COVID-19 from Chest X-rays using Deep
  Learning: Comparing COGNEX VisionPro Deep Learning 1.0 Software with Open
  Source Convolutional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.IV/paper_13.html">
      <font color="black">Identification of images of COVID-19 from Chest X-rays using Deep
  Learning: Comparing COGNEX VisionPro Deep Learning 1.0 Software with Open
  Source Convolutional Neural Networks</font>
    </a>
  </h2>
  <font color="black">たとえば、ウォータールー大学はダーウィンAIとともに、ディープラーニングモデルCOVID-Netを設計し、13,975枚の画像で構成されるCOVIDxというデータセットを作成しました。この危機の間に多くの企業や教育機関が集まり、さまざまなディープを作成しました。胸部ラジオグラフィー画像からのCOVID-19の効果的な診断のための学習モデル..結果は、COVID-Netおよびオープンソースコミュニティからの他のさまざまな最先端のディープラーニングモデルの結果と比較されます。 
[概要]ウォータールー大学は、ダーウィンaiとともに、深層学習モデルcovid-netを設計し、covidxというデータセットを作成しました。結果は、オープンソースコミュニティの深層学習モデルの結果と比較されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-03">
        <br><font color="black">2020-08-03</font>
      </time>
    </span>
</section>
<!-- paper0: Fader Networks for domain adaptation on fMRI: ABIDE-II study -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.IV/paper_14.html">
      <font color="black">Fader Networks for domain adaptation on fMRI: ABIDE-II study</font>
    </a>
  </h2>
  <font color="black">3D畳み込みオートエンコーダーを使用して、ドメインに関係のない潜在空間画像表現を構築し、この方法を示して、ABIDEデータに対する既存のアプローチよりも優れています。それでも、ABIDE内の異なるスキャンサイト間でのモデルの転送可能性の問題があります。ABIDEは最大のオープンです。 fMRIデータと完全な表現型の説明の両方を含むソース自閉症スペクトル障害データベース。 
[概要]データは、データを分析することによって広範囲に調査されました。データは、機能的接続性分析とディープラーニングに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: AMPA-Net: Optimization-Inspired Attention Neural Network for Deep
  Compressed Sensing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.IV/paper_15.html">
      <font color="black">AMPA-Net: Optimization-Inspired Attention Neural Network for Deep
  Compressed Sensing</font>
    </a>
  </h2>
  <font color="black">AMP-Netは、近似メッセージパッシング（AMP）アルゴリズムとニューラルネットワークの融合を実現します。そのすべてのパラメーターは自動的に学習されます。圧縮センシング（CS）は、ほぼ完全な画像をから再構築するため、画像処理における困難な問題です。限られた測定。 
[概要] amp-netとampa-netは4つのcs再構築ベンチマークデータセットにあります。システムはamp-ニューヨークベースのシステムによって開発されました。これを使用して、初めて新しいシステムを作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Shift in Computer Vision models for MRI data analysis: An
  Overview -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.IV/paper_16.html">
      <font color="black">Domain Shift in Computer Vision models for MRI data analysis: An
  Overview</font>
    </a>
  </h2>
  <font color="black">この調査で説明するアルゴリズムには、高度なデータ処理、モデルアーキテクチャの強化、機能トレーニング、ドメイン不変の潜在空間での予測が含まれます。自動エンコードニューラルネットワークのアプリケーションとそのドメイン不変のバリエーションについては、調査で詳しく説明します。コンピュータービジョン手法は、医療画像分析で優れたパフォーマンスを示しています。 
[概要]現在、臨床で使用されているアプリケーションがいくつかあります。それらは、異なるソースまたは取得ドメインからのデータへのモデルの転送性が低いです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: 3D Segmentation Networks for Excessive Numbers of Classes: Distinct Bone
  Segmentation in Upper Bodies -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_0.html">
      <font color="black">3D Segmentation Networks for Excessive Numbers of Classes: Distinct Bone
  Segmentation in Upper Bodies</font>
    </a>
  </h2>
  <font color="black">このため、ほとんどの確立された方法を直接適応させることはできません。このホワイトペーパーでは、3Dセグメンテーションネットワークを多ラベル設定でトレーニングする複雑さについて説明し、ネットワークアーキテクチャ、損失関数、およびデータ拡張に必要な変更を示します。その結果、CTスキャンからエンドツーエンドで学習した方法で100を超える異なる骨を同時に自動的にセグメント化することにより、この方法の堅牢性を実証します。 
[概要]外科的介入の計画と医療専門家の教育のための視覚化ツールに情報を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: 4Seasons: A Cross-Season Dataset for Multi-Weather SLAM in Autonomous
  Driving -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_1.html">
      <font color="black">4Seasons: A Cross-Season Dataset for Multi-Weather SLAM in Autonomous
  Driving</font>
    </a>
  </h2>
  <font color="black">直接ステレオ視覚慣性オドメトリとRTK-GNSSの融合から得られた最大センチメートルの精度でグローバルに一貫した参照ポーズを提供します。完全なデータセットはhttps://www.4seasons-dataset.comで入手できます。データさまざまなシナリオで、昼と夜を含むさまざまな気象条件と照明の下で収集されました。 
[概要] 9つの異なる環境で350km以上の記録を収集することができました。これは、視覚オドメトリ、グローバルな場所の認識、およびマップベースの再ローカリゼーション追跡に関する研究を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Back to the Future: Cycle Encoding Prediction for Self-supervised
  Contrastive Video Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_2.html">
      <font color="black">Back to the Future: Cycle Encoding Prediction for Self-supervised
  Contrastive Video Representation Learning</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、CEPコンポーネントのソースコードを完全に公開しています。標準データセットUCF101およびHMDB51の大幅に改善された結果を報告します。CEPは、閉じた前後および後方前方の時間ループの概念が存在する潜在空間を構築します。ほぼ保存されています。 
[ABSTRACT] cepは、ラベルのないビデオコンテンツの高レベルの空間時間構造を効果的に表すことができます。自己監視信号として、cepは自己監視信号としてフォワードを活用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Propagation Rules for Attribution Map Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_3.html">
      <font color="black">Learning Propagation Rules for Attribution Map Generation</font>
    </a>
  </h2>
  <font color="black">次に、マスクされた入力画像がモデルに再度入力され、元の画像と組み合わせたときにガイダンスとして使用できる新しい出力が取得されます。5つのデータセットと6つのネットワークアーキテクチャで示されているように、提案された方法では、アートの結果と、よりクリーンで視覚的にもっともらしいアトリビューションマップを提供します。導入された学習可能なモジュールは、高次の差分サポートを備えた任意の自動卒業フレームワークの下でトレーニングできます。 
[概要]これらの方法は、情報量の少ない高周波成分に敏感です。さまざまなモデルやサンプルへの適応性に欠けています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Compositional Video Synthesis with Action Graphs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_4.html">
      <font color="black">Compositional Video Synthesis with Action Graphs</font>
    </a>
  </h2>
  <font color="black">AG2Vidは、CATERおよびSomething-Somethingデータセットで評価され、他のベースラインを上回ります。現在のビデオ生成モデルは、そのようなビデオを生成する能力が制限されています。最後に、アクショングラフを使用してアクションの新しい構成を生成する方法を示します。 
[ABSTRACT]現在のビデオ生成モデルは、そのようなビデオを生成する機能に制限があります。ag2vidモデルは、外観と位置の特徴を解きほぐします。アクショングラフは、アクションの新しい構成を作成するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-27">
        <br><font color="black">2020-06-27</font>
      </time>
    </span>
</section>
<!-- paper0: MFPP: Morphological Fragmental Perturbation Pyramid for Black-Box Model
  Explanations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_5.html">
      <font color="black">MFPP: Morphological Fragmental Perturbation Pyramid for Black-Box Model
  Explanations</font>
    </a>
  </h2>
  <font color="black">ディープニューラルネットワーク（DNN）は最近、医療診断や自動運転など、多くの高度で多様なタスクに適用され、使用されています。MFPP方式では、入力画像をマルチスケールフラグメントに分割し、フラグメントをランダムにマスクします。ブラックボックスモデルの予測結果に対する各ピクセルの重要性を示す顕著性マップを生成するための摂動として。既存の入力サンプリング摂動法と比較して、ピラミッド構造フラグメントがより効果的であることが証明されています。 
[概要]ブラックボックススキームは、dnn.mfppの原因となる入力領域を識別できます。以前の入力サンプリング摂動法と比較されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-04">
        <br><font color="black">2020-06-04</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-class segmentation under severe class imbalance: A case study in
  roof damage assessment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_6.html">
      <font color="black">Multi-class segmentation under severe class imbalance: A case study in
  roof damage assessment</font>
    </a>
  </h2>
  <font color="black">この問題を軽減することを目的とした4つの異なる手法を提案します。屋根の損傷の分類とオーバーヘッド画像からのセグメンテーションのタスクは、固有の課題を提示します。この作業では、強いクラスの不均衡によってもたらされる課題に対処することを選択します。 
[概要]これは、データをネットワークにフィードする新しいプロジェクトの作業です。このプロジェクトは、強いクラスの不均衡によってもたらされる課題に取り組むことを目的としています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Data Augmentation for Meta-Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_7.html">
      <font color="black">Data Augmentation for Meta-Learning</font>
    </a>
  </h2>
  <font color="black">メタ学習パイプラインを体系的に分析し、画像レベルとクラスレベルの両方でデータ拡張を統合できる明確な方法を調査します。データ拡張を使用して、クラスごとに利用可能な画像の数を増やす方法を調査します。また、まったく新しいクラスを生成します。従来の画像分類器は、画像のミニバッチをランダムにサンプリングすることによってトレーニングされます。 
[ABSTRACT]データ拡張を使用して、クラスごとに使用可能な画像の数を増やすことができますが、まったく新しいクラスを生成することもできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Reconstruction of Quantitative Susceptibility Maps from Phase of
  Susceptibility Weighted Imaging with Cross-Connected Ψ-Net -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_8.html">
      <font color="black">Reconstruction of Quantitative Susceptibility Maps from Phase of
  Susceptibility Weighted Imaging with Cross-Connected Ψ-Net</font>
    </a>
  </h2>
  <font color="black">特別に設計された拡張相互作用ブロックがこのブランチの各レベルに埋め込まれ、受容野を拡大して、より広い空間範囲の位相画像からより多くの感受性情報をキャプチャします。人間のデータセットでの実験結果は、C {\ Psi} -Netを示しています。他のQSM再構成アルゴリズムよりも優れたパフォーマンスをタスクで実現します。この作業では、感受性加重イメージング（SWI）で生成されたハイパスフィルター処理された位相データの新しい値を調査し、エンドツーエンドのクロスを開発することを提案します。 -接続された{\ Psi} -Net（C {\ Psi} -Net）は、追加の前処理なしで、SWIのこれらの位相データから直接QSMを再構築します。 
[概要]既存のqsm再構成法では、一般に複雑な位相データが必要です。これは、新しいシステムからのデータの分析に基づいています。クロス接続は、多重解像度機能融合スキームを作成するためにブランチ間で使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: Vision-Aided Radio: User Identity Match in Radio and Video Domains Using
  Machine Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_9.html">
      <font color="black">Vision-Aided Radio: User Identity Match in Radio and Video Domains Using
  Machine Learning</font>
    </a>
  </h2>
  <font color="black">これは、通信におけるコンピュータビジョンツールの実用化に不可欠なステップです。5Gは、増大するデータトラフィックとさまざまなサービスの需要を明確にサポートすることにより、通信技術業界の重要なイネーブラーおよび主要なインフラストラクチャプロバイダーとなるように設計されています。要件..したがって、視覚ドメインと無線ドメインの両方からの情報を照合するためのフレームワークを提案します。 
[概要]ディープラーニングとコンピュータービジョンツールを使用すると、視覚データからの情報でネットワークの環境意識を高めることができます。ただし、ネットワークには、視覚システムと無線システムの両方でユーザーのIDを照合するメカニズムが必要です。これらのツールがネットワークに接続できるネットワークの開発に使用されるように設計されたのはこれが初めてです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: MS$^2$L: Multi-Task Self-Supervised Learning for Skeleton Based Action
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_10.html">
      <font color="black">MS$^2$L: Multi-Task Self-Supervised Learning for Skeleton Based Action
  Recognition</font>
    </a>
  </h2>
  <font color="black">対照学習によって特徴空間をさらに規則化します。そして、行動認識に重要な時間的パターンは、ジグソーパズルを解くことによって学習されます。代わりに、複数のタスクを統合して、より一般的な表現を自己教師ありで学習することを提案します。 
[概要]モーション予測、ジグソーパズル認識、コントラスト学習を統合し、さまざまな側面からスケルトンの特徴を学習します。モーション予測とジグソーパズルは、ジグソーパズルを解くことで学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: Practical Deep Raw Image Denoising on Mobile Devices -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_11.html">
      <font color="black">Practical Deep Raw Image Denoising on Mobile Devices</font>
    </a>
  </h2>
  <font color="black">この作業では、主流のモバイルデバイスでスムーズに動作し、高品質のノイズ除去結果を生成する、軽量で効率的なニューラルネットワークベースの生画像ノイズ除去装置を提案します。重要な洞察は2つあります。（1）センサーノイズの測定と推定によるレベルでは、合成センサー固有のデータでトレーニングされた小さなネットワークは、一般的なデータでトレーニングされた大きなネットワークよりもパフォーマンスが優れている可能性があります。 （2）さまざまなISO設定での大きなノイズレベルの変動は、新しいk-Sigma変換によって除去でき、小さなネットワークで広範囲のノイズレベルを効率的に処理できます。ディープラーニングベースの画像ノイズ除去アプローチは、近年、多くの公開ベンチマークデータセットで普及しています。 
[概要]提案されたモバイルフレンドリーなノイズ除去モデルは、クアルコムのキンギョソウ855チップセットでメガピクセルあたり約70ミリ秒で動作します。これは、2019年にリリースされたいくつかのフラッグシップスマートフォンのナイトショット機能の基礎です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: A New Distributional Ranking Loss With Uncertainty: Illustrated in
  Relative Depth Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_12.html">
      <font color="black">A New Distributional Ranking Loss With Uncertainty: Illustrated in
  Relative Depth Estimation</font>
    </a>
  </h2>
  <font color="black">モデルをトレーニングするために、新しいランキング損失である分布損失を提案します。これは、遠いピクセルの深さが近いピクセルの深さよりも大きくなる確率を高めようとします。単一の画像からの相対的な深さ推定の問題に対する新しいアプローチを提案します。 ..見積もりに自信を持って、多くのベースラインに対して最先端の結果を達成します。 
[ABSTRACT]私たちのアプローチにより、モデルは標準偏差の形で推定の信頼度を出力できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Stereo Plane SLAM Based on Intersecting Lines -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_13.html">
      <font color="black">Stereo Plane SLAM Based on Intersecting Lines</font>
    </a>
  </h2>
  <font color="black">3D空間では、2本の交差する線でそのような平面を決定できます。平面の特徴は通常、規則的な形状と直線のエッジラインを持つ人工のオブジェクトと構造の表面に存在します。ステレオマッチングにより、端点と線を計算します。 3D空間での方向、次に2本の交差する線からの平面。 
[概要]この論文では、平面パラメータを計算する新しい方法を提案します。これらは微視的な形状形状に基づいています。3D空間では、2本の交差する線がそのような平面を決定できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Coarse and fine-grained automatic cropping deep convolutional neural
  network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_14.html">
      <font color="black">Coarse and fine-grained automatic cropping deep convolutional neural
  network</font>
    </a>
  </h2>
  <font color="black">この論文では、畳み込みニューラルネットワークのより効率的で正確な圧縮加速を実現できる粗粒度の自動プルーニングアルゴリズムを提案します。まず、畳み込みニューラルネットワークの中間特徴マップをクラスター化して、粗粒度クリッピング後のネットワーク構造を取得します。 、次に、粒子群最適化アルゴリズムを使用して、構造を繰り返し検索および最適化します。最後に、最適なネットワーク調整部分構造が取得されます。 
[概要]この論文は、きめ細かい自動プルーニングアルゴリズムを提案します。畳み込みニューラルネットワークのより効率的で正確な圧縮加速を実現できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Synergetic Reconstruction from 2D Pose and 3D Motion for Wide-Space
  Multi-Person Video Motion Capture in the Wild -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_15.html">
      <font color="black">Synergetic Reconstruction from 2D Pose and 3D Motion for Wide-Space
  Multi-Person Video Motion Capture in the Wild</font>
    </a>
  </h2>
  <font color="black">さまざまなデータセットと実際のスポーツ分野を使用して提案された方法を評価しました。多くの研究がマーカーレスモーションキャプチャを調査しましたが、この技術は実際のスポーツやコンサートには適用されていません。これは3Dモーションから2Dポーズへのフィードバックであり、ビデオモーションキャプチャの全体的なパフォーマンスに対する相乗効果。 
[概要]この方法は、空間時間精度で新しい方法を予測します。人間の骨格モデルに基づいて3Dフィルタリングを予測します。この方法は、広い空間および複数人の環境の複数のカメラで見ることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-16">
        <br><font color="black">2020-01-16</font>
      </time>
    </span>
</section>
<!-- paper0: VICTR: Visual Information Captured Text Representation for Text-to-Image
  Multimodal Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_16.html">
      <font color="black">VICTR: Visual Information Captured Text Representation for Text-to-Image
  Multimodal Tasks</font>
    </a>
  </h2>
  <font color="black">テキスト表現は、単語レベルと文レベルの埋め込みで集約され、視覚的な文脈上の単語と文の両方の表現を生成します。最初に、テキストの説明を初期入力として使用し、依存関係の解析を実行して構文構造を抽出し、意味の側面を分析します。シーングラフを抽出するために、オブジェクトの量を含めます。テキストから画像へのマルチモーダルタスク、特定のテキストの説明から画像を生成/取得することは、視覚的にリアルな画像を完全に説明するために生のテキストの説明が非常に限られた情報をカバーするため、非常に困難なタスクです。 。 
[概要]テキストから画像へのマルチモーダルタスクの新しい視覚的コンテキストテキスト表現を提案します。victr.itは、テキスト入力からオブジェクトの豊富な視覚的意味情報をキャプチャします。抽出されたオブジェクト、主題、および関係をシーングラフでトレーニングします。対応する幾何学的関係情報</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-07">
        <br><font color="black">2020-10-07</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Ensembles for Low-Data Transfer Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_17.html">
      <font color="black">Deep Ensembles for Low-Data Transfer Learning</font>
    </a>
  </h2>
  <font color="black">19の異なるダウンストリームタスク（ビジュアルタスク適応ベンチマーク）の強力なベースラインと一緒に評価すると、2,000を超える事前トレーニング済みモデルから選択した場合でも、はるかに低い推論予算で最先端のパフォーマンスを実現します。事前トレーニング自体の性質が多様性のパフォーマンスの源であり、ダウンストリームデータセットの事前トレーニングモデルのサブセットを効率的に識別する実用的なアルゴリズムを提案します。低データ体制では、適切な監視付きトレーニングを行うことは困難です。ゼロからモデル。 
[ABSTRACT]テクニックテクニックは、モデルをより簡単に作成するために使用されるように設計されています。このメソッドは、モデルを提案するためのシンプルでシンプルなシンプルです。しかし、これはテクノロジーの使用よりもはるかに効果的であると彼は主張します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Manifold-Net: Using Manifold Learning for Point Cloud Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_18.html">
      <font color="black">Manifold-Net: Using Manifold Learning for Point Cloud Classification</font>
    </a>
  </h2>
  <font color="black">次に、点群の性質を低次元空間で取得し、元の3次元（3D）空間の特徴と連結した後、特徴表現の機能と分類ネットワークのパフォーマンスの両方を向上させることができます。最先端のベースラインよりも優れたパフォーマンスを得ることができます。2つの多様な学習モジュールを提案します。1つは局所線形埋め込みアルゴリズムに基づいており、もう1つはニューラルネットワークに基づく非線形投影法です。建築。 
[概要]この紙は、点群の特徴を埋め込むために使用できます。点群分析の93％の位置に基づいています。結果は、提案された表面の位置に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Global Self-Attention Networks for Image Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_19.html">
      <font color="black">Global Self-Attention Networks for Image Recognition</font>
    </a>
  </h2>
  <font color="black">このモジュールの出力は、2つのレイヤーの出力の合計です。最近、コンピュータービジョンの一連の作業により、自己注意を使用したさまざまな画像およびビデオの理解タスクで有望な結果が示されました。提案されたGSAモジュールに基づいて、畳み込みの代わりにGSAモジュールを使用してピクセルの相互作用をモデル化する新しいスタンドアロンのグローバルアテンションベースのディープネットワークを紹介します。 
[概要]これらの作品は、深いネットワークの後の段階で低解像度の機能マップにのみ注意を適用するか、各レイヤーの受容野を小さなローカル領域に制限します。このモジュールは、2つの並列レイヤーで構成されています：コンテンツアテンションネットワークコンテンツとコンピュータビジョンに応答する位置的注意レイヤーのみに基づいてピクセルに注意を向けます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Just Pick a Sign: Optimizing Deep Multitask Models with Gradient Sign
  Dropout -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_20.html">
      <font color="black">Just Pick a Sign: Optimizing Deep Multitask Models with Gradient Sign
  Dropout</font>
    </a>
  </h2>
  <font color="black">一貫性のレベルに基づいてアクティベーションレイヤーで勾配をサンプリングする確率的マスキング手順であるGradientSign Dropout（GradDrop）を紹介します。ただし、これらの複数の更新は、モデルを矛盾する方向に引っ張ることによって最適なトレーニングを妨げる可能性があります。GradDropを示します。従来のマルチタスクおよび転送学習設定内の最先端のマルチロス手法よりも優れており、GradDropが最適なマルチロストレーニングと勾配確率の間のリンクを明らかにする方法について説明します。 
[ABSTRACT] graddropは、あらゆるディープネットアクティベーションで使用できるシンプルなディープレイヤーです。ネットワークネットワークネットワークシステムは、改善レベルを変更できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Monitoring War Destruction from Space: A Machine Learning Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_21.html">
      <font color="black">Monitoring War Destruction from Space: A Machine Learning Approach</font>
    </a>
  </h2>
  <font color="black">この記事では、ディープラーニング技術とデータ拡張を組み合わせてトレーニングサンプルを拡張することで、高解像度衛星画像の破壊を測定する自動化された方法を紹介します。このアプローチにより、前例のない範囲、解像度、頻度で破壊データを生成できます。画像-データの制限を決定的に緩和することができます。この方法をシリアの内戦に適用し、全国の主要都市での被害の進展を再構築します。 
[概要]データの欠如は、メディア報道、人道的救援活動、人権監視、復興イニシアチブ、および暴力的紛争の学術研究に厳しい制限を課します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: Hold me tight! Influence of discriminative features on deep network
  boundaries -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_22.html">
      <font color="black">Hold me tight! Influence of discriminative features on deep network
  boundaries</font>
    </a>
  </h2>
  <font color="black">具体的には、ニューラルネットワークが非識別特徴に対して高い不変性を示すことを厳密に確認し、DNNの決定境界は、分類器がそれらをまとめるいくつかの特徴でトレーニングされている場合にのみ存在できることを示します。このフレームワークを使用します。 CNNのいくつかの興味深い特性を明らかにするために..最後に、決定境界の構築がトレーニングサンプルの小さな摂動に非常に敏感であり、特定の方向の変化が直交サンプルの突然の不変性につながる可能性があることを示します。 
[ABSTRACT]この作業では、敵対的なロバスト性の分野からツールを借ります。それらは、データセットの特徴を決定境界までのサンプルの距離まで決定する新しい視点を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-15">
        <br><font color="black">2020-02-15</font>
      </time>
    </span>
</section>
<!-- paper0: WeightAlign: Normalizing Activations by Weight Alignment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_23.html">
      <font color="black">WeightAlign: Normalizing Activations by Weight Alignment</font>
    </a>
  </h2>
  <font color="black">WeightAlignを提示します。これは、フィルター内で計算された平均およびスケーリングされた標準導出によって重みを正規化し、サンプル統計を計算せずにアクティブ化を正規化します。提案された方法は、バッチサイズに依存せず、幅広いバッチサイズにわたって安定しています。 。CIFAR-10、CIFAR-100、ImageNetでの分類、PASCAL VOC 2012でのセマンティックセグメンテーション、およびOffice-31でのドメイン適応について、これらの利点を実験的に示します。 
[ABSTRACT] small-インスタンスノルム、レイヤーノルム、グループノルムなどのバッチソリューションは、単一のサンプルでも分析できるチャネル統計を使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Better Patch Stitching for Parametric Surface Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_24.html">
      <font color="black">Better Patch Stitching for Parametric Surface Reconstruction</font>
    </a>
  </h2>
  <font color="black">ただし、アトラス表現には1つの大きな欠点があります。個々のマッピングの一貫性が保証されていないため、再構築された形状またはギザギザの表面領域に穴ができます。ステッチングエラー..最初の項は表面法線を利用し、個々のマッピング内およびマッピング全体で推定されたときに、それらが局所的に一貫していることを要求します。 
[ABSTRACT]最新の作品は、ターゲットの形状を複数のマッピングのアトラスとして表しており、オブジェクトのパーツを密接にエンコードできます。ローカルマッピングのグローバルな一貫性を明示的に促進するアプローチを紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Tailoring: encoding inductive biases by optimizing unsupervised
  objectives at prediction time -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_25.html">
      <font color="black">Tailoring: encoding inductive biases by optimizing unsupervised
  objectives at prediction time</font>
    </a>
  </h2>
  <font color="black">次に、ネストされた最適化（メタ学習の最適化と同様）を定式化し、調整損失に適応した後、タスク損失で適切に実行されるようにモデルをトレーニングします。ただし、トレーニングデータで最小化されているため、通常のタスク損失と同じ一般化ギャップ..モデルを各入力に合わせてカスタマイズするため、このプロセス調整と呼びます。 
[概要]仕立てとメタ仕立ての利点を理論的に説明します。これらは、より良い表現に適応する新しい方法で示されます。ただし、ネットワークは、私たちが関心を持っているものとは異なる目的を最適化しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: JUMPS: Joints Upsampling Method for Pose Sequences -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_26.html">
      <font color="black">JUMPS: Joints Upsampling Method for Pose Sequences</font>
    </a>
  </h2>
  <font color="black">私たちの方法を使用して2Dposeシーケンスを後処理すると、キャラクターの動きをより豊かに表現できます。生成的敵対的ネットワーク（GAN）とエンコーダーを組み合わせた深い生成モデルに基づいています。人間のポーズ推定は、監視に役立つ低レベルのタスクです。人間の行動認識、およびシーンの理解全般。 
[概要] 2Dポーズ推定で関節の数を増やし、閉塞または欠落した関節を回復するためのジャンプと呼ばれる新しい方法を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-02">
        <br><font color="black">2020-07-02</font>
      </time>
    </span>
</section>
<!-- paper0: Semantic Flow-guided Motion Removal Method for Robust Mapping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_27.html">
      <font color="black">Semantic Flow-guided Motion Removal Method for Robust Mapping</font>
    </a>
  </h2>
  <font color="black">以前の作品とは異なり、画像シーケンスから直接移動オブジェクトやモーション領域を予測することはありません。次に、K-meansを使用して、インスタンスセグメンテーションマスクを使用してモーション領域マスクを微調整しました。このように、モーション領域に属するキーポイント後の計算では無視されます。 【概要】本論文では、意味情報とオプティカルフローを活用して運動領域を抽出する新しい運動除去法を提案した。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Relative Depth Estimation as a Ranking Problem -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_28.html">
      <font color="black">Relative Depth Estimation as a Ranking Problem</font>
    </a>
  </h2>
  <font color="black">ランキング問題として、単一画像問題からの相対深度推定の定式化を提示します。このように問題を再定式化することにより、ランキング問題に関する文献を活用し、既存の知識を適用してより良い結果を得ることができました。この目的のために、我々は、相対的な深さ推定問題に、ランキング文献から借用したリストごとのランキング損失、加重ListMLEを導入しました。 
[ABSTRACT]また、より良い結果を達成するために、私たちの方法がより強力なピクセル深度ランキング精度を考慮した新しいメトリックをもたらしました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Ferrograph image classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_29.html">
      <font color="black">Ferrograph image classification</font>
    </a>
  </h2>
  <font color="black">フェログラフ画像データセットとミニCIFAR-10データセットで実験を行いました。実験結果は、提案されたモデルがベースラインと比較して2つのデータセットの精度をそれぞれ9％と20％改善できることを示しています。摩耗粒子サイズの大きな変化範囲に挑戦し、摩耗粒子のマルチスケール表現を得るためにマルチスケール特徴抽出ブロックを提案しました。 
[概要]提案されたモデルは、ベースラインと比較して、2つのデータセットの精度をそれぞれ9％と20％向上させることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: FC-DCNN: A densely connected neural network for stereo estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_30.html">
      <font color="black">FC-DCNN: A densely connected neural network for stereo estimation</font>
    </a>
  </h2>
  <font color="black">その後、不整合を取り除いた視差画像に分水界の前景と背景のセグメンテーションを使用します。結果を改善するために、セミグローバルマッチングや条件付き確率場などの時間とメモリ効率の悪いコスト集計方法を使用する代わりに、フィルタリング技術、すなわちメディアンフィルターとガイド付きフィルター..ステレオ推定のための新しい軽量ネットワークを提案します。 
[概要]私たちのネットワークは、完全に畳み込みの密に接続されたニューラルネットワーク（fc-dcnn）で構成されています。ネットワークは、修正された画像間のマッチングコストを分析する半畳み込みネットワークに基づいています。このネットワークを使用して、一貫性のない値を取り除きます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: A spatial model checker in GPU (extended version) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_31.html">
      <font color="black">A spatial model checker in GPU (extended version)</font>
    </a>
  </h2>
  <font color="black">新しいGPUベースバージョンのvoxlogicaを紹介し、その実装、スケーラビリティ、およびアプリケーションについて説明します。単純な論理仕様による脳腫瘍のセグメンテーションの既存のベンチマークの分析は、最先端の精度に達しました。ツールvoxlogicaは、計算イメージングアルゴリズムITKの最先端のライブラリを、空間ロジックモデルチェックによって提供される宣言仕様と最適化された実行の組み合わせとマージします。 
[概要]既存のベンチマークの分析は、アプリケーションの新しい状態に達しました。テストは単純な推論に基づいていました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: PP-LinkNet: Improving Semantic Segmentation of High Resolution Satellite
  Imagery with Multi-stage Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_32.html">
      <font color="black">PP-LinkNet: Improving Semantic Segmentation of High Resolution Satellite
  Imagery with Multi-stage Training</font>
    </a>
  </h2>
  <font color="black">本論文では、クラウドソースのOpenStreetMap（OSM）データから自動的に（人的労力なしで）取得されたノイズの多い疑似グラウンドトゥルースマスクを活用する、衛星画像のセマンティックセグメンテーションのロバスト性を向上させる2段階の転送学習手法を提案します。ピラミッドプーリング-LinkNet（PP-LinkNet）、焦点損失、ポリ学習率、およびコンテキストモジュールを使用するセグメンテーション用の改良されたディープニューラルネットワーク。最近、ディープニューラルネットワークの適用による画像セグメンテーションの改善は、抽出において有望な結果を示しています。大規模な高解像度衛星画像からの道路セグメント。 
[概要]道路網のマッピングは現在、費用と労力の両方がかかります。改善には、業界グレードのアプリケーションのモデルを構築するために必要なラベル付きトレーニングデータの欠如が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Low-rank Convex/Sparse Thermal Matrix Approximation for Infrared-based
  Diagnostic System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_33.html">
      <font color="black">Low-rank Convex/Sparse Thermal Matrix Approximation for Infrared-based
  Diagnostic System</font>
    </a>
  </h2>
  <font color="black">これらの方法は、主成分サーモグラフィ（PCT）とスパースPCTの利点を継承しますが、非負の制約でスパースPCTの負のベースに取り組み、データの処理でクラスタリング特性を示します。これらの方法の実用性と効率は、実験によって実証されています。 3つの標本（異なる深さとサイズの欠陥）での表面下欠陥検出の結果と、乳癌スクリーニングデータセットで乳房異常を区別するための熱的不均一性の維持（74.1％、75.8％、および77.8％の精度）。アクティブサーモグラフィとパッシブサーモグラフィは2つです。診断評価のために表面下の欠陥につながる不均一な熱パターンを測定するために広く使用されている効率的な手法。 
[概要]これらの方法は、乳房の異常を区別するために、表面下の欠陥を検出し、熱を維持するために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Ranking for Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_34.html">
      <font color="black">Self-Supervised Ranking for Representation Learning</font>
    </a>
  </h2>
  <font color="black">S2R2と呼ばれる新しいフレームワークにより、ビューのペアで計算された人気のある対照学習フレームワークで、ローカルの目的と比較してグローバルな目的を計算できます。自己監視表現学習の新しいフレームワークを、ランダムな画像セットからの多数のランダムビューでの画像検索コンテキスト。原則として、ランク付け基準を使用することにより、オブジェクト中心のキュレートされたデータセット（ImageNetなど）への依存を排除します。 
[概要]画像のランダムビューは、他の画像よりも参照ビューの近くにランク付けされると予想されます。したがって、多数の正負のサンプルを生成し、ランク付け損失項を計算します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning from Small Amount of Medical Data with Noisy Labels: A
  Meta-Learning Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_35.html">
      <font color="black">Deep Learning from Small Amount of Medical Data with Noisy Labels: A
  Meta-Learning Approach</font>
    </a>
  </h2>
  <font color="black">提案されたソリューションを未熟児網膜症（ROP）データセットでテストし、ラベルノイズが68％と非常に高くなりました。その結果、適切に処理されない場合、ラベルノイズはパフォーマンスを大幅に低下させます。データの複雑さと専門家の意見の対立です。 
[ABSTRACT]コンピュータシステムは、適切にトレーニングするために正しくラベル付けされた大きなデータセットを必要としますが、これは医療アプリケーションでは取得が困難です。提案されたアルゴリズムは、ノイズの多いラベルが存在する場合の分類アルゴリズムのパフォーマンスを大幅に向上させます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Optimal Filter Pruning with Balanced Performance and Pruning
  Speed -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_36.html">
      <font color="black">Towards Optimal Filter Pruning with Balanced Performance and Pruning
  Speed</font>
    </a>
  </h2>
  <font color="black">ネットワークは、時間のかかるプルーニング再トレーニングの反復なしに、レイヤーごとの方法でプルーニングされます。包括的な実験は、私たちの方法が多くの最先端のアプローチよりも優れていることを示しています。ネットワーク全体の事前定義されたプルーニング率が与えられた場合、高速収束速度で対応する損失変動しきい値を見つける方法も紹介します。 
[概要]提案された剪定方法は、一般的なアーキテクチャに広く適用されています。最終的な微調整を除いて、追加のトレーニングは必要ありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Clusterable Visual Features for Zero-Shot Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_37.html">
      <font color="black">Learning Clusterable Visual Features for Zero-Shot Recognition</font>
    </a>
  </h2>
  <font color="black">SUN、CUB、およびAWA2データセットでの実験では、以前の最先端のZSL結果に比べて大幅な改善が見られます。機能ジェネレーターとして条件付き変分自動エンコーダー（CVAE）を使用して、元の機能を補助的な分類損失によって監視される新しい特徴空間。クラスター化可能な視覚的特徴は、CVAEの再構築により適しているだけでなく、分類の精度を向上させる分離性も高くなっています。 
[概要]論文では、zsl問題のクラスター化可能な機能を学習することを提案しています。これらの機能を使用して、データをテストするための分類器をトレーニングできます。クラスター化可能性をさらに高めるために、プロジェクトの損失を使用して機能を微調整します。ガウスノイズを導入してさらに拡大</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-07">
        <br><font color="black">2020-10-07</font>
      </time>
    </span>
</section>
<!-- paper0: Vokenization: Improving Language Understanding with Contextualized,
  Visual-Grounded Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_38.html">
      <font color="black">Vokenization: Improving Language Understanding with Contextualized,
  Visual-Grounded Supervision</font>
    </a>
  </h2>
  <font color="black">https://github.com/airsplay/vokenizationで公開されているコードと事前トレーニング済みモデル。この探索を妨げる主な理由は、視覚的に根拠のある言語データセットと純粋な言語のコーパスの間の大きさと分布の大きな相違であることがわかります。これらのコンテキストで生成されたボーケンでトレーニングされた、視覚的に監視された言語モデルは、自己よりも一貫した改善を示しています。 GLUE、SQuAD、SWAGなどの複数の純粋な言語タスクの監視対象の代替。 
[概要]視覚的に監視された言語モデルの概念は、既存の言語事前トレーニングフレームワークに基づいています。マルチモーダルアライメントを言語のみに外挿する「発声」と呼ばれる手法を開発します。データのみ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Privacy-Preserving Object Detection & Localization Using Distributed
  Machine Learning: A Case Study of Infant Eyeblink Conditioning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_39.html">
      <font color="black">Privacy-Preserving Object Detection & Localization Using Distributed
  Machine Learning: A Case Study of Infant Eyeblink Conditioning</font>
    </a>
  </h2>
  <font color="black">分散機械学習は、プライバシー、計算のスケーラビリティ、帯域幅容量により、人気のあるモデルトレーニング方法になりつつあります。分散学習を使用すると、画像データを他のノードに送信せずにモデルをトレーニングできます。この作業では、スケーラブルな分散トレーニングについて説明します。オブジェクト検出で一般的に使用される2つのアルゴリズムのバージョン。 
[ABSTRACT]ソフトウェアはシステムの精度を保護するために使用されています。これらのモデルは他のノードに画像データを送信せずにトレーニングできます。アトランタベースのシステムは現在開発中です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Rethinking Bottleneck Structure for Efficient Mobile Network Design -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_40.html">
      <font color="black">Rethinking Bottleneck Structure for Efficient Mobile Network Design</font>
    </a>
  </h2>
  <font color="black">ImageNet分類では、パラメーターや計算を増やすことなく、反転した残差ブロックを砂時計ブロックに置き換えるだけで、分類の精度をMobileNetV2よりも1.7％以上向上させることができます。PascalVOC2007テストセットでは、0.9もあることがわかります。オブジェクト検出における％mAPの改善..この論文では、このような設計変更の必要性を再考し、情報の損失や勾配の混乱のリスクをもたらす可能性があることを発見しました。 
[概要]設計は、2つの設計ルールを導入することにより、従来の残差ボトルネックを変更します。反転残差の学習と線形ボトルネックの使用。イメージネット分類では、逆残差ブロックをourcテストに置き換えるだけで、分類精度を1以上に設定できます。 7 ％</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-05">
        <br><font color="black">2020-07-05</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient and high accuracy 3-D OCT angiography motion correction in
  pathology -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_41.html">
      <font color="black">Efficient and high accuracy 3-D OCT angiography motion correction in
  pathology</font>
    </a>
  </h2>
  <font color="black">広範囲の病状と健康な対照の両方を含む17人の被験者の204の体積スキャンに基づく大規模な定量的評価で、臨床的に関連する特徴に関連するメトリックを使用してアルゴリズムを評価しました。この方法を使用して、最先端のアートアキシャルパフォーマンスは、特に病理学的サブグループにおいて、横方向の協調と歪み補正の両方で大幅な進歩を示しています。さらに、高度に並列化された実装と短い実行時間のために設計されており、高密度または広視野の臨床ルーチンに統合できますスキャンします。 
[概要]これは、主に血管造影血管造影や血管造影血管などの繊維構造の特徴を調整する最初のアプローチです。特定の構造や層がセグメント化されていないため、このアプローチは設計上、病理学的運動に対してロバストです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: OLALA: Object-Level Active Learning Based Layout Annotation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_42.html">
      <font color="black">OLALA: Object-Level Active Learning Based Layout Annotation</font>
    </a>
  </h2>
  <font color="black">しかし、オブジェクト検出のアクティブラーニングは通常、オブジェクトレベルではなく、画像レベルで実行されます。これは、アノテーターがラベル付けする画像内の最もあいまいなオブジェクト予測領域のみを選択し、アノテーションバジェットの使用を最適化します。 https://github.com/lolipopshock/Detectron2_ALで入手できます。 
[概要]オブジェクト検出のためのアクティブラーニングは、通常、オブジェクトレベルではなく、画像レベルで実行されます。オブジェクトスコアリング方法は、オブジェクトカテゴリと場所の両方を考慮してオブジェクト予測の最適な使用法を推定します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Attn-HybridNet: Improving Discriminability of Hybrid Features with
  Attention Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_43.html">
      <font color="black">Attn-HybridNet: Improving Discriminability of Hybrid Features with
  Attention Fusion</font>
    </a>
  </h2>
  <font color="black">次に、PCANetとTFNetによって取得された情報が特徴的で重要であるが、個別に不十分であることを示します。TFNetは、データの空間構造から特徴を抽出します（これをマニューシャビューと呼びます）。まず、主要なコンポーネント。情報を列ベクトル（統合ビューと呼びます）に変換することで情報を取得します。これにより、データ内の空間情報が失われます。 
[ABSTRACT] pcanetは、principalfnetや空間プーリングなどの基本的な操作で構成されていますが、主要なコンポーネントを含む2つの基本的な問題があります。また、自然画像の空間統計に対応できません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Differential diagnosis and molecular stratification of gastrointestinal
  stromal tumors on CT images using a radiomics approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_44.html">
      <font color="black">Differential diagnosis and molecular stratification of gastrointestinal
  stromal tumors on CT images using a radiomics approach</font>
    </a>
  </h2>
  <font color="black">3人の放射線科医のAUCはそれぞれ0.69、0.76、0.84でした。画像、年齢、性別、場所を含むGISTと非GISTの放射線科モデルの平均曲線下面積（AUC）は0.82でした。他の腹腔内腫瘍からの消化管間質腫瘍（GIST）およびGIST分子分析は、治療計画に必要ですが、その希少性のために困難です。 
[ABSTRACT]ラジオミクスは、要点を他の腹腔内腫瘍と区別するためにラジオミクスを評価することであり、要点では、要点と画像、年齢、性別、場所を含むラジオミクスモデルの平均曲線下面積（auc）が0. 82</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Object-Centric Learning with Slot Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_45.html">
      <font color="black">Object-Centric Learning with Slot Attention</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、畳み込みニューラルネットワークの出力などの知覚表現とインターフェイスし、スロットと呼ばれるタスク依存の抽象表現のセットを生成するアーキテクチャコンポーネントであるSlotAttentionモジュールを紹介します。SlotAttentionを経験的に示します。教師なしオブジェクト発見および教師付きプロパティ予測タスクでトレーニングされたときに、見えない構成への一般化を可能にするオブジェクト中心の表現を抽出できます。複雑なシーンのオブジェクト中心の表現を学習することは、低レベルの知覚的特徴から効率的な抽象的な推論を可能にするための有望なステップです。 
[概要]これは、自然の風景の構成表現に関する情報が不足しているためです。多くの例では、自然のタスクの構成表現をキャプチャしていません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-26">
        <br><font color="black">2020-06-26</font>
      </time>
    </span>
</section>
<!-- paper0: Interpretation of 3D CNNs for Brain MRI Data Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_46.html">
      <font color="black">Interpretation of 3D CNNs for Brain MRI Data Classification</font>
    </a>
  </h2>
  <font color="black">最近の研究では、特定の脳領域の形態学的差異が畳み込みニューラルネットワーク（CNN）を使用してMRIで検出できることが示されています。現在の研究では、若者の大規模なオープンソースデータセットでの分類タスクを検討します。健康な被験者-男性と女性の脳の違いの調査。ただし、既存のモデルの解釈は関心のある領域に基づいており、画像全体のボクセル単位の画像解釈に拡張することはできません。 
[ABSTRACT]ニューラルネットワークは、大規模な前処理なしでフル6データを処理できます。モデルの変更は、関心領域に基づいています。この論文では、性差に関する以前の調査結果を拡張しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-20">
        <br><font color="black">2020-06-20</font>
      </time>
    </span>
</section>
<!-- paper0: Atlas: End-to-End 3D Scene Reconstruction from Posed Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_47.html">
      <font color="black">Atlas: End-to-End 3D Scene Reconstruction from Posed Images</font>
    </a>
  </h2>
  <font color="black">このアプローチは、最先端のベースライン（ディープマルチビューステレオとそれに続く従来のTSDFフュージョン）を定量的および定性的に大幅に上回るScannetデータセットで評価されます。さらに、3Dモデルのセマンティックセグメンテーションは、大幅な計算なしで取得されます。 。以前の作業ではRGB入力のみで問題を試みていないため、3Dセマンティックセグメンテーションを深度センサーを使用する以前の方法と比較します。 
[ABSTRACT]再構築の従来の方法は、シーンの完全な3Dモデルを推定する前に、深度マップのより近い表現に依存しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-23">
        <br><font color="black">2020-03-23</font>
      </time>
    </span>
</section>
<!-- paper0: Implicit Rank-Minimizing Autoencoder -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_48.html">
      <font color="black">Implicit Rank-Minimizing Autoencoder</font>
    </a>
  </h2>
  <font color="black">エンコーダーとデコーダーの間に多数の追加の線形レイヤーを挿入することにより、システムは低い有効次元の表現を自発的に学習します。暗黙的ランク最小化オートエンコーダー（IRMAE）と呼ばれるモデルは、単純で決定論的であり、コンパクトな潜在空間を学習します。 ..この作業では、コードの共分散行列のランクは、多層線形ネットワークでの勾配降下学習が最小ランクの解につながるという事実に依存することにより、暗黙的に最小化されます。 
[ABSTRACT]「線形層」と呼ばれるモデルは単純で決定論的であり、コンパクトな潜在空間を学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-01">
        <br><font color="black">2020-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: Rotation Averaging with Attention Graph Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_49.html">
      <font color="black">Rotation Averaging with Attention Graph Neural Networks</font>
    </a>
  </h2>
  <font color="black">その結果、ネットワークはより高速で堅牢になり、以前のニューラルアプローチよりも少ないサンプルでトレーニングできるため、最終的には従来の反復アルゴリズムよりも精度と推論時間が優れています。この方法では、すべての観測値を使用し、を使用して外れ値の影響を抑制します。ネットワーク設計内の加重平均化と注意メカニズム..この論文では、ノイズと外れ値の存在下で回転平均化をロバストに実行できる単一ステージグラフニューラルネットワークを提案します。 
[要約]実際には、仮定は実際のデータセットに必ずしもうまく適合しない。平均化ネットワークは不十分な初期化に敏感であった</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Fast meningioma segmentation in T1-weighted MRI volumes using a
  lightweight 3D deep learning architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_50.html">
      <font color="black">Fast meningioma segmentation in T1-weighted MRI volumes using a
  lightweight 3D deep learning architecture</font>
    </a>
  </h2>
  <font color="black">さらに、さまざまなトレーニングスキームの影響を調査しました。検証研究では、ノルウェーのトロンハイムにあるセントオラフ大学病院の698個のT1強調MRボリュームを使用しました。T1強調MRIボリュームでの自動で一貫した髄膜腫セグメンテーションと対応する体積評価は、診断、治療計画、および腫瘍増殖評価に役立ちます。 
[概要]外来診療所では、外科的に治療された髄膜腫と未治療の髄膜腫の両方が多数続いた。モデルは、検出精度、セグメンテーション精度、および病院向けのトレーニングの観点から評価された。最大の髄膜腫で最高の精度が達成された。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Visual Identification of Individual Holstein-Friesian Cattle via Deep
  Metric Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_51.html">
      <font color="black">Visual Identification of Individual Holstein-Friesian Cattle via Deep
  Metric Learning</font>
    </a>
  </h2>
  <font color="black">SoftMaxベースの相互トリプレット損失を使用して、識別の問題に対処し、固定された群れのパラダイムに対して技術を詳細に評価することを提案します。既存のアプローチは、さまざまなメンテナンス要件を持つマーキング、タグ、またはウェアラブルに依存していますが、完全に手を提示します-オープンな群れの設定でのオーバーヘッドイメージングからの個々の動物の自動検出、位置特定、および識別のためのオフメソッド。ホルスタイン-フリージアン牛は、チューリングの反応拡散系から生じるものと視覚的に類似した、個々に特徴的な黒と白のコートパターンを示します。 
[概要]システムトレーニング中に隠された牛を特定して再特定する必要があります。この作業により、個々のドイツの農業の生体認証を自動化できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-16">
        <br><font color="black">2020-06-16</font>
      </time>
    </span>
</section>
<!-- paper0: GreedyFool: An Imperceptible Black-box Adversarial Example Attack
  against Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_52.html">
      <font color="black">GreedyFool: An Imperceptible Black-box Adversarial Example Attack
  against Neural Networks</font>
    </a>
  </h2>
  <font color="black">十分な知覚不能性を実現するために、HVSについて多くの調査を開始し、丁度可知歪み（JND）、Weber-Fechnerの法則、テクスチャマスキング、チャネル変調を考慮した統合メトリックを設計します。これは、良性の例と敵対的な例の間の知覚距離..この論文では、GreedyFoolという名前の新しいブラックボックスの敵対的な例の攻撃を提案します。これは、微分進化と貪欲な近似に基づいて敵対的な例を合成します。ディープニューラルネットワーク（DNN）敵対的な例と呼ばれる適切に設計された入力サンプルに対して本質的に脆弱です。 
[ABSTRACT]新しい作品は、人間の視覚系を十分に考慮していない摂動にペナルティを課すために単純なメトリックを活用することにより、敵対的な例を統合します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Reducing Drift in Structure From Motion Using Extended Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_53.html">
      <font color="black">Reducing Drift in Structure From Motion Using Extended Features</font>
    </a>
  </h2>
  <font color="black">私たちの構造的特徴は、窓の整列した列や平面的な建物のファサードなど、長距離の人工構造物を含むシーンのドリフトを大幅に減らすことができます。さらに、これらの制約のドリフトを減らす機能の分析を評価することによって提供します合成データセット上で..モーションアルゴリズムからの最先端のグローバル構造に追加の制約としてこれらの機能を追加し、追加された制約により、長くて低いフィールドのような特にドリフトが発生しやすいシーケンスの再構築が可能になることを示します-慣性測定なしでビデオを表示します。 
[概要]この論文では、平面や消失点などの拡張された構造的特徴を使用して、スケールと位置のドリフトを劇的に削減する方法を紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Anisotropy Directions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_54.html">
      <font color="black">Neural Anisotropy Directions</font>
    </a>
  </h2>
  <font color="black">いくつかのCNNアーキテクチャのNADを識別し、その方向性誘導バイアスを明らかにする効率的な方法を提供します。次に、アーキテクチャの方向性誘導バイアスをカプセル化するベクトルを神経異方性方向（NAD）として定義します。そのために開始します。非常に単純な問題に焦点を当てることによって、つまり、線形に分離可能な分布のクラスを分類し、分布の識別機能の方向に応じて、多くの最先端の深い畳み込みニューラルネットワーク（CNN）がこの単純なタスクを解決するのは驚くほど困難です。 
[概要] cnnsが単純なアーキテクチャを解決したのはこれが初めてです。これらのシステムは、ネットワークの設定をカプセル化して、特定の機能に基づいてデータを分離します。また、cifar-10データセットの場合、nadsが使用される機能を特徴づけることも示しています。異なるクラスを区別するためのcnnsによる</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br><font color="black">2020-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: A Vector-based Representation to Enhance Head Pose Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_55.html">
      <font color="black">A Vector-based Representation to Enhance Head Pose Estimation</font>
    </a>
  </h2>
  <font color="black">実験は、ベクトルベースの注釈方法が大きなポーズ角度の予測エラーを効果的に減らすことができることを示しています。特にプロファイルビューの場合、MAEが実際の動作を反映しない可能性があることを示しています。2。
[要約]現在の頭の姿勢の推定は機能しますが、これらの注釈には両方とも不連続性の問題があります。これにより、ニューラルネットワークトレーニングでパフォーマンスの問題が発生する可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Fader Networks for domain adaptation on fMRI: ABIDE-II study -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_56.html">
      <font color="black">Fader Networks for domain adaptation on fMRI: ABIDE-II study</font>
    </a>
  </h2>
  <font color="black">3D畳み込みオートエンコーダーを使用して、ドメインに関係のない潜在空間画像表現を構築し、この方法を示して、ABIDEデータに対する既存のアプローチよりも優れています。ABIDEは、fMRIデータと完全な表現型記述の両方を備えた最大のオープンソース自閉症スペクトル障害データベースです。 ABIDE内の異なるスキャンサイト間でのモデルの転送可能性の問題は依然としてあります。 
[概要]データは、データを分析することによって広範囲に調査されました。データは、機能的接続性分析とディープラーニングに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: TAM: Temporal Adaptive Module for Video Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_57.html">
      <font color="black">TAM: Temporal Adaptive Module for Video Recognition</font>
    </a>
  </h2>
  <font color="black">Kinetics-400およびSomething-Somethingデータセットに関する広範な実験は、TAMが他の時間モデリング手法よりも一貫して優れており、同様の複雑さの下で最先端のパフォーマンスを達成することを示しています。TAMは原理的なモジュールであり、非常に小さな追加の計算コストで強力なビデオアーキテクチャ（TANet）を生成する2D CNN ..重要度マップはローカルの時間ウィンドウで学習され、短期的な情報をキャプチャします。一方、集計の重みは、に焦点を当てたグローバルビューから生成されます。長期的な構造。 
[ABSTRACT] tamは、ビデオ固有のostrooper ostration osを作成するための新しいOSです。独自のロケーションマップに基づいて、ビデオ固有のoslastを作成するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-14">
        <br><font color="black">2020-05-14</font>
      </time>
    </span>
</section>
<!-- paper0: AMPA-Net: Optimization-Inspired Attention Neural Network for Deep
  Compressed Sensing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_58.html">
      <font color="black">AMPA-Net: Optimization-Inspired Attention Neural Network for Deep
  Compressed Sensing</font>
    </a>
  </h2>
  <font color="black">AMP-Netは、近似メッセージパッシング（AMP）アルゴリズムとニューラルネットワークの融合を実現します。圧縮センシング（CS）は、限られた測定からほぼ完全な画像を再構築するため、画像処理における困難な問題です。さらに、 3つのアテンションネットワークを使用してAMP-Netの表現能力を向上させるAMPA-Net。 
[概要] amp-netとampa-netは4つのcs再構築ベンチマークデータセットにあります。システムはamp-ニューヨークベースのシステムによって開発されました。これを使用して、初めて新しいシステムを作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Semantic Segmentation for Partially Occluded Apple Trees Based on Deep
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_59.html">
      <font color="black">Semantic Segmentation for Partially Occluded Apple Trees Based on Deep
  Learning</font>
    </a>
  </h2>
  <font color="black">果樹の剪定と間伐には、果樹とその枝の高解像度セグメンテーションを提供できる強力なビジョンシステムが必要です。モデルのパフォーマンスを評価するために、バイナリ精度、平均IoU、境界F1スコア、および閉塞枝リコールが使用されました。 U-Netは、現在のメトリックで他の2つのモデルよりも優れています。 
[ABSTRACT]オクルージョン難易度インデックスと深度難易度インデックスは、オクルージョン情報を回復するために必要です。これは、オクルージョン情報を回復するためのより具体的なメトリックの必要性を強調しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Development of Open Informal Dataset Affecting Autonomous Driving -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_60.html">
      <font color="black">Development of Open Informal Dataset Affecting Autonomous Driving</font>
    </a>
  </h2>
  <font color="black">最後に、歩行者や道路に存在するさまざまなオブジェクトの10万枚の画像、警察と交通安全担当者の20万枚の画像、警察と交通安全担当者の5,000枚の画像、および5,000枚の画像データからなるデータセットが収集および構築されました。非構造化動的データは、天候、時間、交通状況などのさまざまな環境で収集され、警察および安全担当者への追加の受信コールが収集されました。このドキュメントは、オブジェクトおよび非構造化動的データを収集するための手順と方法を記述したドキュメントです。自走式車両の物体認識技術開発の道筋であり、データの収集方法、注釈データ、物体分類基準、データ処理方法の概要を説明しています。 
[概要]データは、天気、時間、交通状況など、さまざまな環境で収集されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Shift in Computer Vision models for MRI data analysis: An
  Overview -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_61.html">
      <font color="black">Domain Shift in Computer Vision models for MRI data analysis: An
  Overview</font>
    </a>
  </h2>
  <font color="black">自動エンコーディングニューラルネットワークのアプリケーションとそのドメイン不変のバリエーションは、調査で詳細に説明されています。現在の作業では、機械学習とコンピュータビジョンでドメインシフトの問題に取り組むために使用される方法の概要を説明します。この調査で説明するアルゴリズムには、高度なデータ処理が含まれます。 、モデルアーキテクチャの強化と特徴的なトレーニング、およびドメイン不変の潜在空間での予測。 
[概要]現在、臨床で使用されているアプリケーションがいくつかあります。それらは、異なるソースまたは取得ドメインからのデータへのモデルの転送性が低いです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Adaptive-Attentive Geolocalization from few queries: a hybrid approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_62.html">
      <font color="black">Adaptive-Attentive Geolocalization from few queries: a hybrid approach</font>
    </a>
  </h2>
  <font color="black">クエリとギャラリーが異なるビジュアルドメインに属している場合に、ラベル付きギャラリーに対して特定のクエリ画像をジオローカライズすることを目的とする、クロスドメインの視覚的な場所認識のタスクに対処します。この方法では、次のことが可能です。 2桁少ないターゲットドメイン画像を使用しながら、現在の最先端技術を上回るパフォーマンスを実現します。論文が承認されると、コードとデータセットがリリースされます。 
[概要]少数のラベルのないターゲットドメイン画像を使用して、ターゲットの分布について学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Identifying Wrongly Predicted Samples: A Method for Active Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CV/paper_63.html">
      <font color="black">Identifying Wrongly Predicted Samples: A Method for Active Learning</font>
    </a>
  </h2>
  <font color="black">私たちの方法は単純で、モデルにとらわれず、最初から再トレーニングする必要なしに現在のモデルのステータスに依存します。さらに、非常に効率的で類似性に基づく解釈を提供する基準の近似を示します。 -最先端の結果と、誤って予測されたサンプルを特定する際のより良いレート。 
[概要]この作業では、不確実性を超えたシンプルなサンプル学習ツールを提案します。それまでに、モデルモデルシステムは非常に効率的で類似性に基づく解釈を提供するように設計されています。また、最先端の結果などを示します。誤って予測されたサンプルを特定する割合</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: No Rumours Please! A Multi-Indic-Lingual Approach for COVID Fake-Tweet
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_0.html">
      <font color="black">No Rumours Please! A Multi-Indic-Lingual Approach for COVID Fake-Tweet
  Detection</font>
    </a>
  </h2>
  <font color="black">
[概要] covidに関する偽のニュースを検出するアプローチを提案します-19早い段階で、英語以外の複数のインド語のツイートなどのソーシャルメディアから</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Annotationsaurus: A Searchable Directory of Annotation Tools -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_1.html">
      <font color="black">Annotationsaurus: A Searchable Directory of Annotation Tools</font>
    </a>
  </h2>
  <font color="black">
[概要]注釈ツールは注釈ツール注釈ツールによって作成されました。現在93個のツールを含むWebページツールのリストを作成しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Text Classification Using Label Names Only: A Language Model
  Self-Training Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_2.html">
      <font color="black">Text Classification Using Label Names Only: A Language Model
  Self-Training Approach</font>
    </a>
  </h2>
  <font color="black">
[ABSTRACT]人間は、ラベル付けされた例を見なくても分類を実行できます。私たちのモデルは、4つのベンチマークデータセットで約90％の精度を達成しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: On the Frailty of Universal POS Tags for Neural UD Parsers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_3.html">
      <font color="black">On the Frailty of Universal POS Tags for Neural UD Parsers</font>
    </a>
  </h2>
  <font color="black">
[ABSTRACT] uposタグの分析は、ゴールドタグを使用するとパフォーマンスが非線形に向上することを示しており、ある種の例外を示唆しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Self-supervised Pre-training via a Fully-Explored Masked
  Language Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_4.html">
      <font color="black">Improving Self-supervised Pre-training via a Fully-Explored Masked
  Language Model</font>
    </a>
  </h2>
  <font color="black">
[ABSTRACT]モデルは、cvmでランダムにサンプリングされたマスクは、望ましくない大きな勾配につながると主張しています。したがって、十分に検討されたマスキング戦略を提案します。これには、テキストシーケンスが特定の数の非オーバーラップセグメントに分割されることが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: Catching Attention with Automatic Pull Quote Selection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_5.html">
      <font color="black">Catching Attention with Automatic Pull Quote Selection</font>
    </a>
  </h2>
  <font color="black">この作業を再現するためのコードは、https：//github.com/tannerbohn/AutomaticPullQuoteSelectionで入手できます。人間による評価は、このタスクの独自性と選択モデルの適合性もサポートします。読者を引き付ける方法についての理解を深めるために、私たちは提唱します。自動引用符選択の新しいタスク。 
[ABSTRACT]引用符は、読者の形を捉えるために特別に設計された記事のコンポーネントです。記事から選択されたテキストのスパンで読者を引き付けるように設計されており、より目立つプレゼンテーションが提供されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-27">
        <br><font color="black">2020-05-27</font>
      </time>
    </span>
</section>
<!-- paper0: AutoADR: Automatic Model Design for Ad Relevance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_6.html">
      <font color="black">AutoADR: Automatic Model Design for Ad Relevance</font>
    </a>
  </h2>
  <font color="black">
[ABSTRACT] automlはアーキテクチャ設計に新たな光を当てましたが、事前にトレーニングされた言語モデルと統合する方法は未解決のままです。これらの事前にトレーニングされたモデルはメモリとコンピューティングを集中的に使用し、広告関連性などの産業用オンラインシステムへの展開を妨げています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Sentiment Analysis based Multi-person Multi-criteria Decision Making
  Methodology using Natural Language Processing and Deep Learning for Smarter
  Decision Aid. Case study of restaurant choice using TripAdvisor reviews -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_7.html">
      <font color="black">Sentiment Analysis based Multi-person Multi-criteria Decision Making
  Methodology using Natural Language Processing and Deep Learning for Smarter
  Decision Aid. Case study of restaurant choice using TripAdvisor reviews</font>
    </a>
  </h2>
  <font color="black">
[概要]感情分析を使用すると、意思決定モデルで自然言語での専門家の評価を検討できるようになると主張しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-31">
        <br><font color="black">2020-07-31</font>
      </time>
    </span>
</section>
<!-- paper0: Grounded Language Learning Fast and Slow -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_8.html">
      <font color="black">Grounded Language Learning Fast and Slow</font>
    </a>
  </h2>
  <font color="black">
[要約]研究は、都市のエージェントが同様のワンショット単語学習を示すことができることを示しています。それは、単語「dax」のエピソード知識内の短期をシームレスに統合します。結果は、ディープニューラルネットワークがメタ学習を活用できることも示しています。エピソード記憶と明示的にマルチモーダルな環境</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Chinese Lexical Simplification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_9.html">
      <font color="black">Chinese Lexical Simplification</font>
    </a>
  </h2>
  <font color="black">
[概要]中国語の語彙単純化（cls）タスクの調査作業はありません。私たちの知る限り、これはclsタスクの最初の調査です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Dissecting the components and factors of Neural Text Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_10.html">
      <font color="black">Dissecting the components and factors of Neural Text Generation</font>
    </a>
  </h2>
  <font color="black">
[概要]私たちは、命令法の自然言語へのアナロジーを提示します。学習体制、事前トレーニング、モデリングアプローチ、デコード、および主要な課題への課題を提示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Improvised Chatbots from Adversarial Modifications of Natural
  Language Feedback -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_11.html">
      <font color="black">Learning Improvised Chatbots from Adversarial Modifications of Natural
  Language Feedback</font>
    </a>
  </h2>
  <font color="black">これらの変更されたフィードバック応答で元のトレーニングデータを拡張すると、Personachatデータセットでの正しい応答のランク付けで元のチャットボットのパフォーマンスが69.94％から75.96％に向上することを示します。これは、元のモデルがすでに131kのサンプルでトレーニングされていることを考えると大幅な改善です。ほとんどの場合、ユーザーフィードバックには、トレーニングサンプルとしての有用性を妨げる無関係なシーケンスが含まれています。この作業では、ノイズの多いフィードバックを会話内のもっともらしい自然な応答に変換する生成的敵対モデルを提案します。 
[概要]ほとんどの場合、ユーザーフィードバックには、トレーニングサンプルとしての有用性に不満がある無関係なシーケンスが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Re-evaluating Evaluation in Text Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_12.html">
      <font color="black">Re-evaluating Evaluation in Text Summarization</font>
    </a>
  </h2>
  <font color="black">
[概要]古いデータセットの評価は、必ずしも最新のデータセットに当てはまるとは限りません。20年近くの間、ほとんどの要約論文ではルージュが標準的な評価でした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Program Enhanced Fact Verification with Verbalization and Graph
  Attention Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_13.html">
      <font color="black">Program Enhanced Fact Verification with Verbalization and Graph
  Attention Network</font>
    </a>
  </h2>
  <font color="black">
[要約]提案されたシステムは、さまざまな証拠のソースを融合するように設計されています。これには、プログラムが含まれます-強化された言語化とグラフ注意ネットワーク（progvgat）。提案されたフレームワークは、ベンチマークデータセットタブファクトで74％の精度を達成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Relation Extraction from Language Models using Constrained
  Cloze Completion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_14.html">
      <font color="black">Unsupervised Relation Extraction from Language Models using Constrained
  Cloze Completion</font>
    </a>
  </h2>
  <font color="black">
[ABSTRACT] re-flexは、教師なし関係の抽出を実行するために、事前にトレーニングされた言語モデルに対して制約付きのクローズ完了を実行する単純なフレームワークです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Summarize, Outline, and Elaborate: Long-Text Generation via Hierarchical
  Supervision from Extractive Summaries -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_15.html">
      <font color="black">Summarize, Outline, and Elaborate: Long-Text Generation via Hierarchical
  Supervision from Extractive Summaries</font>
    </a>
  </h2>
  <font color="black">長いテキストの生成は依然として課題です。要約請求の労力を要するプロセスを回避するために、セグメントを再構築するために最も有益な部分を選択することにより、監視されていない方法でセグメントの要約を抽出する{\ it再構築}戦略を提案します。提案された生成システムには、次のメリットがあります。（1）要約は、テキスト生成の高レベルのガイダンスを提供し、個々の単語予測の極小値を回避します。 （2）高レベルの談話依存関係は、要約間の条件付き依存関係に取り込まれ、要約拡張プロセス中に保持されます。さらに、（3）コンテキストを簡潔な要約として表すことにより、大幅に多くのコンテキストを考慮することができます。そのSOEは、収束速度が速く、品質が大幅に向上した長いテキストを生成します。 
[概要]長いテキストは、ローカルの単語予測の作業に基づいていません。新世代のシステムは、最高の時間を作成することができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-Supervised Bilingual Lexicon Induction with Two-way Interaction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_16.html">
      <font color="black">Semi-Supervised Bilingual Lexicon Induction with Two-way Interaction</font>
    </a>
  </h2>
  <font color="black">
[概要]注釈付きデータと注釈なしデータの間で知識を転送する2つの方法を設計します。それぞれ、事前の最適な転送と超党派の辞書の更新という名前が付けられています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Weight Squeezing: Reparameterization for Compression and Fast Inference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_17.html">
      <font color="black">Weight Squeezing: Reparameterization for Compression and Fast Inference</font>
    </a>
  </h2>
  <font color="black">
[概要]事前にトレーニングされた教師モデルから知識の伝達を実行します。次に、モデルの精度を大幅に損なうことなく、その重みからより小さな学生モデルの重みへのマッピングを学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Geometry matters: Exploring language examples at the decision boundary -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_18.html">
      <font color="black">Geometry matters: Exploring language examples at the decision boundary</font>
    </a>
  </h2>
  <font color="black">他のデータセットの難しい例を探索するためのツールを含め、使用されるすべてのコードが公開されます。このペーパーでは、情報幾何学のツールを使用して、NLPの例の難しさを定量化する理論的な方法を提案します。アプローチはシンプルで、アーキテクチャに依存せず、他のデータセットに簡単に拡張できます。 
[概要]これらの例の概念は単純で、アーキテクチャは他のツールでも簡単に利用できます。2つの人気のあるnlpアーキテクチャの難しい例を探ります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: InfoBERT: Improving Robustness of Language Models from An Information
  Theoretic Perspective -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_19.html">
      <font color="black">InfoBERT: Improving Robustness of Language Models from An Information
  Theoretic Perspective</font>
    </a>
  </h2>
  <font color="black">
[ABSTRACT] infobertには、トレーニング用の2つの相互情報量ベースのモデルがあります。これらには、入力と特徴表現の間のノイズの多い相互情報量を抑制するレギュラライザーが含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Memformer: The Memory-Augmented Transformer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_20.html">
      <font color="black">Memformer: The Memory-Augmented Transformer</font>
    </a>
  </h2>
  <font color="black">
[ABSTRACT] remedyの新しいメモリメモリの再生-メモリ要件が大幅に削減された時間の経過に伴う通信</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Pair the Dots: Jointly Examining Training History and Test Stimuli for
  Model Interpretability -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_21.html">
      <font color="black">Pair the Dots: Jointly Examining Training History and Test Stimuli for
  Model Interpretability</font>
    </a>
  </h2>
  <font color="black">
[概要]提案手法は、神経モデルの決定を明確に説明します。テスト例の取得や履歴の修正に役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Pagsusuri ng RNN-based Transfer Learning Technique sa Low-Resource
  Language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_22.html">
      <font color="black">Pagsusuri ng RNN-based Transfer Learning Technique sa Low-Resource
  Language</font>
    </a>
  </h2>
  <font color="black">
[概要]転移学習（tl）技術の使用は、貧しい人々の不足を軽減します-リソース設定</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Are Some Words Worth More than Others? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_23.html">
      <font color="black">Are Some Words Worth More than Others?</font>
    </a>
  </h2>
  <font color="black">
[概要]モデルのパフォーマンスは、高頻度の単語と低頻度の単語の間で大きく異なる可能性があり、実際には障害モードにつながる可能性があります。提案されたメトリックを使用して2つの主要な英語モデルを評価し、アプローチによってパフォーマンスの違いが明らかになることを示します。モデル間</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: Exploiting Spectral Augmentation for Code-Switched Spoken Language
  Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_24.html">
      <font color="black">Exploiting Spectral Augmentation for Code-Switched Spoken Language
  Identification</font>
    </a>
  </h2>
  <font color="black">
[概要]マイクロソフトのスピーキングリッドチャレンジは、マイクロソフトリサーチチームによって音声リッドチャレンジとして開催されました。チャレンジには、音声信号に存在する言語を識別する機能が含まれます。これらには、その州の公用語、ヒンディー語、英語が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Length-Adaptive Transformer: Train Once with Length Drop, Use Anytime
  with Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_25.html">
      <font color="black">Length-Adaptive Transformer: Train Once with Length Drop, Use Anytime
  with Search</font>
    </a>
  </h2>
  <font color="black">SQuAD 1.1、MNLI-m、SST-2などのさまざまなセットアップで優れた精度と効率のトレードオフを示すことにより、提案されたアプローチの有用性を経験的に検証します。このホワイトペーパーでは、PoWER-BERTを拡張してこの問題に対処します。これを行うために、ドロップアウトの構造バリアントであるLengthDropを使用してトランスフォーマーをトレーニングします。これは、各レイヤーでシーケンスの長さを確率的に決定します。 
[概要]提案された拡張機能により、長さ-適応コストと呼ばれる大規模なトランスフォーマーを一度トレーニングできます。これにより、シーケンスがレイヤーを通過するときにシーケンスの長さが徐々に短くなるパワー-バートを使用できなくなります。可能性のシナリオごとに個別のモデルをトレーニングする必要があることを示唆しています-その個別のコンピューティング予算</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Vokenization: Improving Language Understanding with Contextualized,
  Visual-Grounded Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_26.html">
      <font color="black">Vokenization: Improving Language Understanding with Contextualized,
  Visual-Grounded Supervision</font>
    </a>
  </h2>
  <font color="black">
[概要]視覚的に監視された言語モデルの概念は、既存の言語事前トレーニングフレームワークに基づいています。マルチモーダルアライメントを言語のみに外挿する「発声」と呼ばれる手法を開発します。データのみ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: A Self-supervised Representation Learning of Sentence Structure for
  Authorship Attribution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_27.html">
      <font color="black">A Self-supervised Representation Learning of Sentence Structure for
  Authorship Attribution</font>
    </a>
  </h2>
  <font color="black">
[要約]これらの研究は、文の構文構造の明示的な情報を調査するように私たちを動機づけました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Word Representations for Tunisian Sentiment Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_28.html">
      <font color="black">Learning Word Representations for Tunisian Sentiment Analysis</font>
    </a>
  </h2>
  <font color="black">手作りの機能を一切使用せずに、公開されている2つのデータセットでの実験結果は、他の言語と同等のパフォーマンスを示しました。これにより、オンラインの意見を調査および認識するプロセスに追加の課題が生じます。このペーパーでは、さまざまなものの重要性を調査します。教師なし単語表現（word2vec、BERT）と、畳み込みニューラルネットワークと双方向の長短期記憶の使用を調査します。 
[概要]この論文では、ソーシャルメディアで使用されるチュニジア方言のtun分析に焦点を当てます。最近では、ディープニューラルネットワークがこのタスク、特に英語で広く使用されています。手作りの機能を一切使用せずに、実験結果他の言語と同等のパフォーマンスを示した</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: MulDE: Multi-teacher Knowledge Distillation for Low-dimensional
  Knowledge Graph Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_29.html">
      <font color="black">MulDE: Multi-teacher Knowledge Distillation for Low-dimensional
  Knowledge Graph Embeddings</font>
    </a>
  </h2>
  <font color="black">蒸留された32次元モデルは、いくつかの一般的に使用されるデータセットでのいくつかの最先端（SotA）高次元メソッドと比較して非常に競争力があります。ただし、最近のKGEモデルは、ベクトル次元を過度に増やすことによってパフォーマンスを向上させる傾向があります。これは莫大なトレーニングコストを引き起こし、実際のアプリケーションでのストレージを節約します。新しい反復蒸留戦略の下で、MulDEモデルはトレーニングエポックと学生のパフォーマンスに応じて適応的にソフトラベルを生成します。 
[概要]新しい調査によると、ムルデ川は知識蒸留の枠組みを効果的に改善できることが示されています。教師として複数の致命的でないkgeモデルを使用しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: The EOS Decision and Length Extrapolation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_30.html">
      <font color="black">The EOS Decision and Length Extrapolation</font>
    </a>
  </h2>
  <font color="black">
[概要]この作業では、見過ごされがちなモデリング決定の長さの外挿への影響を調べます。たとえば、トレーニング時に見られる長さの10倍の長さに十分に外挿すると、eosはeosよりも大幅に優れていることがわかりました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Supervised Joint-Event-Extraction with Heterogeneous Information
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_31.html">
      <font color="black">Cross-Supervised Joint-Event-Extraction with Heterogeneous Information
  Networks</font>
    </a>
  </h2>
  <font color="black">さらに、接続されたエンティティとトリガーは自然に異種情報ネットワーク（HIN）を形成するため、特定のコーパスのメタパスに沿った潜在的なパターンを活用して、提案された方法のパフォーマンスをさらに向上させます。非構造化された実世界のコーパスからの構造情報（つまり、エンティティまたはイベントのトリガー）は、自然言語処理においてますます多くの研究の注目を集めています。経験的な結果と分析は、私たちのアプローチが最新の方法よりも優れていることを示しています。エンティティとトリガーの両方の抽出。 
[ABSTRACT]以前の作品は、エンティティとトリガー間の密な共起関係に完全に対処しておらず、この重要な情報を失い、抽出パフォーマンスを低下させます。これらには、相互の型分布やクロスなどのこれらの要因が含まれます。監視対象メカニズム（csm）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Recipes for Safety in Open-domain Chatbots -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_32.html">
      <font color="black">Recipes for Safety in Open-domain Chatbots</font>
    </a>
  </h2>
  <font color="black">
[概要]これらの問題を軽減するためにさまざまな方法を調査します。これらの方法を比較する実験を行い、新しい技術が内部にあることを発見します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Simplify the Usage of Lexicon in Chinese NER -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_33.html">
      <font color="black">Simplify the Usage of Lexicon in Chinese NER</font>
    </a>
  </h2>
  <font color="black">
[ABSTRACT] nerモデルは、いくつかの公開された中国のnerデータセットで新しいベンチマーク結果を達成しました。これにより、リアルタイムのner応答が必要な多くの工業地域でのアプリケーションが制限されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-16">
        <br><font color="black">2019-08-16</font>
      </time>
    </span>
</section>
<!-- paper0: Assessing Phrasal Representation and Composition in Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_34.html">
      <font color="black">Assessing Phrasal Representation and Composition in Transformers</font>
    </a>
  </h2>
  <font color="black">
[概要]これらのモデルがフレーズの表現をどのように処理するかについての理解は限られています。フレーズの類似性と意味の変化に関する人間の判断を活用したテストを使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: A Relaxed Matching Procedure for Unsupervised BLI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_35.html">
      <font color="black">A Relaxed Matching Procedure for Unsupervised BLI</font>
    </a>
  </h2>
  <font color="black">
[概要] 2つの言語間のより正確なマッチングを見つけるためのリラックスしたマッチング手順を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Semantically-Aligned Universal Tree-Structured Solver for Math Word
  Problems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_36.html">
      <font color="black">Semantically-Aligned Universal Tree-Structured Solver for Math Word
  Problems</font>
    </a>
  </h2>
  <font color="black">
[ABSTRACT]ユニバーサル式ツリー（uet）は、さまざまな参加者の方程式を表現する最初の試みを行います。新しいチャレンジ数学文章題データセット（hmwp）は、3種類のmwps（art）で構成されます。新しいモデルは、さまざまな種類の `mwps &#39;</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Subjective Question Answering: Deciphering the inner workings of
  Transformers in the realm of subjectivity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_37.html">
      <font color="black">Subjective Question Answering: Deciphering the inner workings of
  Transformers in the realm of subjectivity</font>
    </a>
  </h2>
  <font color="black">
[ABSTRACT] subjqaは、主観的な意見を求める質問を含む最初のqaデータセットです。この論文の主な目的は、変圧器ベースのアーキテクチャの内部動作を調査することでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-02">
        <br><font color="black">2020-06-02</font>
      </time>
    </span>
</section>
<!-- paper0: fugashi, a Tool for Tokenizing Japanese in Python -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_38.html">
      <font color="black">fugashi, a Tool for Tokenizing Japanese in Python</font>
    </a>
  </h2>
  <font color="black">
[ABSTRACT]日本語はスペースなしで書かれており、トークン化は簡単ではありません。これは英語のドキュメントが不足しているにもかかわらずです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Controlling the Interaction Between Generation and Inference in
  Semi-Supervised Variational Autoencoders Using Importance Weighting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_39.html">
      <font color="black">Controlling the Interaction Between Generation and Inference in
  Semi-Supervised Variational Autoencoders Using Importance Weighting</font>
    </a>
  </h2>
  <font color="black">
[概要]教師なし `vaes &#39;の追加は正則化として説明されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: An Investigation on Different Underlying Quantization Schemes for
  Pre-trained Language Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_40.html">
      <font color="black">An Investigation on Different Underlying Quantization Schemes for
  Pre-trained Language Models</font>
    </a>
  </h2>
  <font color="black">
[概要]これらのモデルの適用は、サイズが原因で制限されています。ほとんどの研究は、量子化スキームとしてバート量子化に適合した一次線形クラスタリングに焦点を当てています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Modeling Preconditions in Text with a Crowd-sourced Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_41.html">
      <font color="black">Modeling Preconditions in Text with a Crowd-sourced Dataset</font>
    </a>
  </h2>
  <font color="black">
[概要]これは、テキストに基づいた大規模なラベル付きデータが不足しているためです。この新しいコーパスの前に、2つのチャレンジタスクも導入します。これらには、イベントの言及のペアに対して定義された標準の分類タスクであるann annannotaが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Summarizing Text on Any Aspects: A Knowledge-Informed Weakly-Supervised
  Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_42.html">
      <font color="black">Summarizing Text on Any Aspects: A Knowledge-Informed Weakly-Supervised
  Approach</font>
    </a>
  </h2>
  <font color="black">
[概要]以前の研究では、通常、事前に定義された小さな一連の側面を想定しています。他の多様なトピックを要約する代わりに、新しいシステムが開発されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Google Crowdsourced Speech Corpora and Related Open-Source Resources for
  Low-Resource Languages and Dialects: An Overview -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_43.html">
      <font color="black">Google Crowdsourced Speech Corpora and Related Open-Source Resources for
  Low-Resource Languages and Dialects: An Overview</font>
    </a>
  </h2>
  <font color="black">
[概要]テキスト読み上げ認識を構築するための38のデータセットをリリースしました。データセットは、南アジア、東南アジア、アフリカ、ヨーロッパ、南アメリカの言語と方言向けに設計されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: DA-Transformer: Distance-aware Transformer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_44.html">
      <font color="black">DA-Transformer: Distance-aware Transformer</font>
    </a>
  </h2>
  <font color="black">
[ABSTRACT] da-トランスフォーマーは、多くのタスクのパフォーマンスを効果的に向上させることができます。また、バニラトランスフォーマーとそのいくつかのバージョンよりもパフォーマンスを向上させることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Databases -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_45.html">
      <font color="black">Neural Databases</font>
    </a>
  </h2>
  <font color="black">
[概要]事前定義されたスキーマのないデータベースシステムであるneuraldbについて説明します。各演算子に入力する適切なファクトのセットを作成する方法を学習するアルゴリズムについて説明します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Medical Code Assignment with Gated Convolution and Note-Code Interaction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_46.html">
      <font color="black">Medical Code Assignment with Gated Convolution and Note-Code Interaction</font>
    </a>
  </h2>
  <font color="black">
[概要]医療メモは通常長く、医療コードスペースが大きいです。医療メモの情報を完全にエンコードおよびキャプチャしないため、これらの方法は依然として効果的ではありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: BioMegatron: Larger Biomedical Domain Language Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_47.html">
      <font color="black">BioMegatron: Larger Biomedical Domain Language Model</font>
    </a>
  </h2>
  <font color="black">
[概要]多くの作品は各ドメインに影響を与える要因を研究していませんvid.yet、ほとんどの作品は理由を研究していません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: A Graph Representation of Semi-structured Data for Web Question
  Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_48.html">
      <font color="black">A Graph Representation of Semi-structured Data for Web Question
  Answering</font>
    </a>
  </h2>
  <font color="black">
[概要]ウェブテーブルとリストの概念は新しい論文で開発されています。それは商用エンジンからの情報の欠如に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Modeling Protagonist Emotions for Emotion-Aware Storytelling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/cs.CL/paper_49.html">
      <font color="black">Modeling Protagonist Emotions for Emotion-Aware Storytelling</font>
    </a>
  </h2>
  <font color="black">
[概要]この論文では、主人公の感情の軌跡をモデル化する最初の研究を紹介します。私たちのモデルには、感情の監視（emosup）モデルと2つの感情強化（emorl）モデルが含まれます。これらのモデルは、次のストーリーの生成に非常に優れています。ストーリーの質を犠牲にすることなく、ベースラインの方法と比較して望ましい感情の弧</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Towards Resistant Audio Adversarial Examples -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.AS/paper_0.html">
      <font color="black">Towards Resistant Audio Adversarial Examples</font>
    </a>
  </h2>
  <font color="black">
[ABSTRACT]敵対的な例のメソッドは、ビニング操作のために過剰適合を引き起こします。現実的な地上波設定で編集距離を比較することにより、アプローチによる大幅な改善を確認します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring Universal Speech Attributes for Speaker Verification with an
  Improved Cross-stitch Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.AS/paper_1.html">
      <font color="black">Exploring Universal Speech Attributes for Speaker Verification with an
  Improved Cross-stitch Network</font>
    </a>
  </h2>
  <font color="black">
[ABSTRACT]音響モデリング用の新しい音声属性（nsa）ユニットは、結合されたtri-sau状態によって作成されます。コア-コアの共通条件5（cc5）およびnistsre10評価セットの10秒-10秒テストで実施された実験</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Exploiting Spectral Augmentation for Code-Switched Spoken Language
  Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.AS/paper_2.html">
      <font color="black">Exploiting Spectral Augmentation for Code-Switched Spoken Language
  Identification</font>
    </a>
  </h2>
  <font color="black">
[概要]マイクロソフトのスピーキングリッドチャレンジは、マイクロソフトリサーチチームによって音声リッドチャレンジとして組織されました。チャレンジには、音声信号に存在する言語を識別する機能が含まれます。これらには、その州の公用語、ヒンディー語、英語が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Hear her Fear: Data Sonification for Sensitizing Society on Crime
  Against Women in India -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.AS/paper_3.html">
      <font color="black">Hear her Fear: Data Sonification for Sensitizing Society on Crime
  Against Women in India</font>
    </a>
  </h2>
  <font color="black">
[概要] 35〜5つのインドの州をカバーする9つの犯罪カテゴリのデータは国の記録から取得されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-29">
        <br><font color="black">2020-09-29</font>
      </time>
    </span>
</section>
<!-- paper0: A variational autoencoder for music generation controlled by tonal
  tension -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.AS/paper_4.html">
      <font color="black">A variational autoencoder for music generation controlled by tonal
  tension</font>
    </a>
  </h2>
  <font color="black">
[概要]これにより、生成されたピース全体の色調張力の方向と、全体的な色調張力のレベルを制御できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Robotic Pouring using Audition and Haptics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-15/eess.AS/paper_5.html">
      <font color="black">Robust Robotic Pouring using Audition and Haptics</font>
    </a>
  </h2>
  <font color="black">
[概要]ビジョンベースの方法は、閉塞状態で失敗することがよくあります。代わりに、オーディオベースの方法は、ノイズの多い環境ではうまく機能しません。ネットワークトレーニングの結果とロボット実験は、mp-netがノイズやタスクと環境の変化に対して堅牢であることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-29">
        <br><font color="black">2020-02-29</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
