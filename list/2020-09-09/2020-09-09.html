<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-09-09の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Semi-supervised Neural Chord Estimation Based on a Variational
  Autoencoder with Latent Chord Labels and Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.SD/paper_0.html">
      <font color="black">Semi-supervised Neural Chord Estimation Based on a Variational
  Autoencoder with Latent Chord Labels and Features</font>
    </a>
  </h2>
  <font color="black">これらの3つのモデルは変分オートエンコーダーを形成し、半教師付き方法で共同でトレーニングできます。具体的には、離散ラベルと連続特徴（潜在変数）からクロマベクトル（観測変数）の生成プロセスを表す深い生成モデルを公式化します。 ）、それぞれ自己遷移と標準ガウス分布を優先するマルコフモデルに従うと想定されています。追加の非注釈付きデータを使用した半教師あり学習は、パフォーマンスをさらに向上させることができます。 
[要旨]エースへの典型的なアプローチは、注釈付きの音楽信号のみを使用して、教師付きの方法で深い分類モデルをトレーニングすることです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-14">
        <br><font color="black">2020-05-14</font>
      </time>
    </span>
</section>
<!-- paper0: Predictions of Subjective Ratings and Spoofing Assessments of Voice
  Conversion Challenge 2020 Submissions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.SD/paper_1.html">
      <font color="black">Predictions of Subjective Ratings and Spoofing Assessments of Voice
  Conversion Challenge 2020 Submissions</font>
    </a>
  </h2>
  <font color="black">音声変換チャレンジ2020は、その旗艦の下での第3版であり、言語内半並列および言語間音声変換（VC）を促進します。さらに、提出されたシステムでスプーフィング評価を実行し、潜在的に示すVCメソッドの一部を特定しました高いセキュリティリスク..これらの客観的測定のそれぞれは、さまざまな側面に沿ってVC出力を評価します。 
[要約]課題の提出の主な評価は、群集ベースのリスニングテストによって行われましたが、提出されたシステムの客観的評価も行いました。この調査では、自動話者検証（asv）を使用して5種類の客観的評価を検討しました。ニューラルスピーカーの埋め込み、なりすまし対策、予測平均意見スコア（mos）、および自動音声認識（asr）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: A Convolutional Deep Markov Model for Unsupervised Speech Representation
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.SD/paper_2.html">
      <font color="black">A Convolutional Deep Markov Model for Unsupervised Speech Representation
  Learning</font>
    </a>
  </h2>
  <font color="black">大規模音声データセット（LibriSpeech）でトレーニングすると、ConvDMMは、ウォールストリートジャーナルデータセットでの線形電話分類および認識に関する複数の自己監視機能抽出方法を大幅に上回る機能を生成します。さらに、ConvDMMは自己監視方法を補完することがわかりました。 Wav2VecやPASEのように、いずれかの方法のみで達成された結果を改善します。この教師なしモデルは、ブラックボックス変分推論を使用してトレーニングされます。 
[要約] lvmsは、潜在的な構造が信号から抽出された情報を形成する直観的な確率論的解釈を認めます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-03">
        <br><font color="black">2020-06-03</font>
      </time>
    </span>
</section>
<!-- paper0: AutoKWS: Keyword Spotting with Differentiable Architecture Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.SD/paper_3.html">
      <font color="black">AutoKWS: Keyword Spotting with Differentiable Architecture Search</font>
    </a>
  </h2>
  <font color="black">スマートオーディオデバイスは、常時オンの軽量キーワードスポッティングプログラムによってゲート制御され、消費電力を削減します。このホワイトペーパーでは、微分可能ニューラルアーキテクチャ検索の最近の進歩を活用して、より効率的なネットワークを発見することを提案します。 Google Speech Command Dataset v1で1精度。 
[要旨]見つかったモデルは97.2％のトップに到達-Google音声コマンドデータセットv1で1の精度</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Automatic Segmentation and Visualization of Choroid in OCT with
  Knowledge Infused Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/eess.IV/paper_0.html">
      <font color="black">Automatic Segmentation and Visualization of Choroid in OCT with
  Knowledge Infused Deep Learning</font>
    </a>
  </h2>
  <font color="black">脈絡膜セグメンテーションのためのバイオマーカーを注入したグローバルからローカルへのネットワークを提案します。また、脈絡膜セグメンテーションにおけるグローバルからローカルへの戦略を設計します。グローバルモジュールは、すべての網膜層と脈絡膜層を同時にセグメント化して過剰適合を抑制し、グローバル構造情報を提供し、ローカルモジュールを使用して、バイオマーカー注入でセグメンテーションを調整します。実験により、セグメンテーションとシャドウ除去タスクの両方で既存のメソッドよりもメソッドが優れていることが示されています。 
[要旨]光コヒーレンストモグラフィー（oct）は、脈絡膜の視覚化と定量化に有利です。脈絡膜の視覚化は、網膜内部の表面のセグメント化による血管の影によって妨げられます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br><font color="black">2020-02-06</font>
      </time>
    </span>
</section>
<!-- paper0: Lung Cancer Tumor Region Segmentation Using Recurrent 3D-DenseUNet -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/eess.IV/paper_1.html">
      <font color="black">Lung Cancer Tumor Region Segmentation Using Recurrent 3D-DenseUNet</font>
    </a>
  </h2>
  <font color="black">提案されたネットワークは、0.7228の平均ダイススコアで他の最先端の3Dセグメンテーションアーキテクチャよりも優れています。続いて、ネットワーク予測に加えて形態学的操作を行い、腫瘍性と非腫瘍性の画像スライスをより適切に区別します。これにより、しきい値ベースのアプローチよりも有望です。 
[要約]提案されたネットワークの再発3d-densunetは、ct scansからのボリューム肺腫瘍セグメンテーション用の新しい深層学習ベースのアーキテクチャです。300患者のnsclc-radiomicsデータセットに基づいて、再発3dが提案されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-05">
        <br><font color="black">2018-12-05</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Change Detection in Satellite Images with Generative
  Adversarial Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/eess.IV/paper_2.html">
      <font color="black">Unsupervised Change Detection in Satellite Images with Generative
  Adversarial Network</font>
    </a>
  </h2>
  <font color="black">ただし、グラウンドトゥルースがないため、教師なしタスクでの深層学習モデルのパフォーマンスを評価または保証することが難しくなります。未登録のペアの影響を軽減し、深層学習構造をより有効に活用するために、以下に基づく新しい変更検出手順を提案します。特別なニューラルネットワークアーキテクチャ---生成的敵対的ネットワーク（GAN）。GAN機能は、視覚的特徴を含むハイパーベクトルを与えるのではなく、現実的な画像を生成するため、生成された画像を判断することでGANモデルを簡単に評価できます。他のディープラーニングベースの方法と比較して、この方法は未登録の画像の問題にあまり敏感ではなく、ほとんどのディープラーニング構造。さまざまなシーンを含む合成画像と実際のデータに関する実験結果このホワイトペーパーでは、GANモデルが、提案された拡張戦略を利用してトレーニングセットを作成し、設計された目的関数を最適化することにより、一対の画像でトレーニングできることを示します。 
[ABSTRACT]未登録画像の変更を検出するためにディープラーニングが導入されています。衛星画像に非常に注目度の高い画像を提供できる</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: An optimal mode selection algorithm for scalable video coding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/eess.IV/paper_3.html">
      <font color="black">An optimal mode selection algorithm for scalable video coding</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、ピクセルの向きに基づいて提案された最適モード選択アルゴリズムにより、時間の節約、PSNR、およびコーディング効率が向上します。スケーラブルビデオコーディング（SVC）は、その柔軟な伝送により、以前の高度なビデオコーディング（AVC）から拡張されています。提案されたアルゴリズムは、標準のH.264 JSVMリファレンスソフトウェアと比較され、57.44％の時間節約、PSNRで0.43 dBの増分、ビットレートで0.23％の圧縮であることがわかりました。 
[ABSTRACT] svcはavcよりも柔軟でスケーラブルですが、計算の決定はavc.traditional hよりも複雑です。 264アルゴリズムは時間の節約、psnrで0. 43 dbの増分、ビットレートで0. 23％の圧縮を実現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic detection of acute ischemic stroke using non-contrast computed
  tomography and two-stage deep learning model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/eess.IV/paper_4.html">
      <font color="black">Automatic detection of acute ischemic stroke using non-contrast computed
  tomography and two-stage deep learning model</font>
    </a>
  </h2>
  <font color="black">背景と目的：2段階の深層学習モデルを含む自動急性虚血性脳卒中関連（AIS）検出システムの開発と評価を目指しました。次に、2段階モデルがテストセットでAIS検出プロセスを実行しました。検出モデルの結果を評価するために、委員会の認定を受けた放射線科医は、検出モデルを使用した場合と使用しない場合のテストセットヘッドCT画像も評価しました。 
[要約] 2つの異なる画像診断機関からの238ケースを含めました。テストセットには、2,000のテストセット、2種類のテストが含まれています。結果は、テストシステムの結果に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: Wasserstein GANs for MR Imaging: from Paired to Unpaired Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/eess.IV/paper_5.html">
      <font color="black">Wasserstein GANs for MR Imaging: from Paired to Unpaired Training</font>
    </a>
  </h2>
  <font color="black">さらに、私たちの敵対的なトレーニングスキームは、ピクセル単位の損失を伴うペアのトレーニングスキームと比較して（エキスパートの放射線技師によって評価されるように）より良い画質を達成できます。また、弁別器は、質のスコアリングを行う評論家の役割を果たす多層CNNでもあります。 Wasserstein距離に基づいて再構成された画像。ジェネレーターは、展開されたニューラルネットワーク（畳み込み層とデータ整合性レイヤーのカスケード）です。 
[ABSTRACT]再構成ネットワークの不対敵対トレーニング。ジェネレータは、展開されたニューラルネットワーク-たたみ込み層とデータ整合性層のカスケード</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-15">
        <br><font color="black">2019-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting anomalous crop development with multispectral and SAR time
  series using unsupervised outlier detection at the parcel-level: application
  to wheat and rapeseed crops -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/eess.IV/paper_6.html">
      <font color="black">Detecting anomalous crop development with multispectral and SAR time
  series using unsupervised outlier detection at the parcel-level: application
  to wheat and rapeseed crops</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、考慮された機能や使用された異常値検出アルゴリズムなど、作物モニタリングの異常値検出結果の関連性に影響を与える可能性のあるさまざまな要因を分析します。このホワイトペーパーでは、区画レベルで異常作物の発生を検出するための一般的なアプローチを提案します。教師なし外れ値検出技術。提案された方法は、ボース（フランス）にある菜種および小麦の作物で検証されています。 
[要約]提案された方法は、フランス、フランスの菜種と小麦の作物で検証されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-17">
        <br><font color="black">2020-04-17</font>
      </time>
    </span>
</section>
<!-- paper0: A Residual Solver and Its Unfolding Neural Network for Total Variation
  Regularized Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/eess.IV/paper_7.html">
      <font color="black">A Residual Solver and Its Unfolding Neural Network for Total Variation
  Regularized Models</font>
    </a>
  </h2>
  <font color="black">最後に、提案されたアルゴリズムとニューラルネットワークの両方がいくつかの問題にうまく適用され、画像の平滑化、ノイズ除去、生物医学画像の再構成など、その有効性と効率が実証されています。ネットワークは一般的であり、他の総変動正則化モデルを解決するために適用できます。 
[ABSTRACT]新しいシステムは「残差ソルバー」と呼ばれます。他の総変動正則化モデルに適用できます。提案されたネットワークは監視されておらず、システムの「拡張バージョン」と見なすことができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: Convolution Neural Networks for diagnosing colon and lung cancer
  histopathological images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/eess.IV/paper_8.html">
      <font color="black">Convolution Neural Networks for diagnosing colon and lung cancer
  histopathological images</font>
    </a>
  </h2>
  <font color="black">同様のモデルを使用して、腺癌と結腸の良性を分類しました。各クラスの5000画像を含むLC25000データセットから合計2500のデジタル画像を取得しました。肺癌と結腸癌は、成人の死亡率と罹患率の主な原因の1つです。 
[要約]浅いニューラルネットワークアーキテクチャを使用して、組織病理学的スライドを肺の良性に分類しました。肺と結腸でそれぞれ97％と96％を超える診断精度が記録されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding Compositional Structures in Art Historical Images using
  Pose and Gaze Priors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/eess.IV/paper_9.html">
      <font color="black">Understanding Compositional Structures in Art Historical Images using
  Pose and Gaze Priors</font>
    </a>
  </h2>
  <font color="black">イコニックと呼ばれる彼の作品の中でマックスイムダールは、20世紀の他の著名な美術史家とともに、画像の構造的構成の美的および意味論的な重要性を強調しました。マックスイムダールの先駆的な作品に触発された私たちのアプローチは、画像構成：（a）アートワークのアクション領域とアクションラインの検出。 （b）前景と背景のポーズベースのセグメンテーション。コンピュータービジョンテクニックを使用してこれらの構造を自動的に生成する（1）は、多くの時間を節約することにより、美術史家が高度な分析を行うのに役立ちます。巨大な画像リポジトリへの概要とアクセスを提供し、（2）機械による人工画像の理解に向けた重要なステップも提供します。 
[ABSTRACT]この作業では、im機械学習技術の既存の状態を使用してこのプロセスを自動化しようとします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Region Comparison Network for Interpretable Few-shot Image
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_0.html">
      <font color="black">Region Comparison Network for Interpretable Few-shot Image
  Classification</font>
    </a>
  </h2>
  <font color="black">さらに、領域活性化マッピング（RAM）という名前の視覚化戦略を提示して、ネットワーク内の中間変数を視覚化することにより、私たちの方法が何を学んだかを直感的に説明します。ただし、モデルの解釈可能性を明示的に考慮することはめったにありません。トレーニング段階..そのため、この作業では、領域比較ネットワーク（RCN）という名前のメトリック学習ベースの方法を提案します。これは、ニューラルネットワークと同様に少数ショット学習がどのように機能するかを明らかにし、特定の領域を見つけることができます。クエリとサポートセットから取得した画像で互いに関連しています。 
[ABSTRACT]領域比較ネットワーク（rcn）と呼ばれる新しい方法は、大規模ニューラルネットワークのように少数ショット学習がどのように機能するかを明らかにできます。また、検索からの画像で互いに関連する特定の領域を見つけることもできますとサポートセット</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: Hybrid Tensor Decomposition in Neural Network Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_1.html">
      <font color="black">Hybrid Tensor Decomposition in Neural Network Compression</font>
    </a>
  </h2>
  <font color="black">後者は最も広く使用されている分解法であり、HTのバリアントであるため、ウェイトマトリックスと畳み込みカーネルをHTとTTの両方の形式に変換します。後者は、ニューラルネットワーク圧縮のハイブリッドテンソル分解の見通しを明らかにします。この現象に基づいて、TTとHTを組み合わせて畳み込み部分と完全に接続された部分を別々に圧縮し、畳み込みニューラルネットワーク（CNN）でTTまたはHT形式のみを使用するよりも高い精度を実現するハイブリッドテンソル分解の戦略を提案します。 
[要約]モデルのサイズが大きくなるため、dnnsの現在の需要が高まっています。dnnsを使用して、ニューラルネットワーク圧縮の新しいシステムを開発できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-29">
        <br><font color="black">2020-06-29</font>
      </time>
    </span>
</section>
<!-- paper0: Explanation of Unintended Radiated Emission Classification via LIME -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_2.html">
      <font color="black">Explanation of Unintended Radiated Emission Classification via LIME</font>
    </a>
  </h2>
  <font color="black">同じ親データ分布からの非常に類似したデータセットでトレーニングされた分類子のアンサンブルを使用して、識別に役立つデバイス出力の特徴のロバストセットを回復することができました。この分類子にLIMEを適用し、同じデバイスの多くの分類で結果を集計することで、分類を行うために使用される周波数帯域を決定することが可能でした。電気システムの信号処理により、これらのエミッションの発生源を特定できます。 
[ABSTRACT] Flaming Moesと呼ばれるデータセットには、家電からの意図しない放射が含まれます。これには、resnet-18画像分類アーキテクチャの適用に基づくニューラルネットワークが含まれます。この分類子にlimeを使用して、同じデバイスの多くの分類で結果を集計します。分類を行うために使用される周波数帯域を決定することが可能でした</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-04">
        <br><font color="black">2020-09-04</font>
      </time>
    </span>
</section>
<!-- paper0: TanhSoft -- a family of activation functions combining Tanh and Softplus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_3.html">
      <font color="black">TanhSoft -- a family of activation functions combining Tanh and Softplus</font>
    </a>
  </h2>
  <font color="black">たとえば、ReLUをxtanh（0.6e ^ x）に置き換えると、CIFAR-10の上位1の分類精度がDenseNet-169で0.46％、Inception-v3で0.7％向上し、tanh（0.87x）ln（1 + e ^ x）CIFAR-100のトップ1の分類精度は、DenseNet-169の場合は1.24％、SimpleNetモデルの場合は2.57％向上します。この作業では、4つの未決定のハイパーパラメーターを備えた、新しい活性化関数のファミリー、つまりTanhSoftを提案しますフォームtanh（{\ alpha} x + {\ beta} e ^ {{\ gamma} x}）ln（{\ delta} + e ^ x）を調整し、これらのハイパーパラメータを調整して、いくつかを上回ることが示されているアクティベーション関数を取得しますよく知られているアクティベーション関数。ここ数年、新しいアクティベーション関数の構築に関心が高まり、学習が向上しています。 
[ABSTRACT]理論では、特定の特定の特定の機能を事前注文できます。これらには、alphaeterやhyper Activation機能などのアクティベーション機能が含まれます。これらは、新しいアクティベーション機能の開発に使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic detection of acute ischemic stroke using non-contrast computed
  tomography and two-stage deep learning model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_4.html">
      <font color="black">Automatic detection of acute ischemic stroke using non-contrast computed
  tomography and two-stage deep learning model</font>
    </a>
  </h2>
  <font color="black">ソフトウェア検出結果がある場合とない場合の放射線科医の感度を、McNemarテストを使用して比較しました。検出モデルの結果を評価するために、認定された放射線科医は、検出モデルを使用して、または使用せずにテストセットヘッドのCT画像も評価しました。その後、2段階の深層学習検出モデルが、You Only Look Once v3モデルとVisual Geometry Group 16分類モデルを使用してトレーニングセットから構築されました。 
[要約] 2つの異なる画像診断機関からの238ケースを含めました。テストセットには、2,000のテストセット、2種類のテストが含まれています。結果は、テストシステムの結果に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: Convolutional Neural Networks for Automatic Detection of Artifacts from
  Independent Components Represented in Scalp Topographies of EEG Signals -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_5.html">
      <font color="black">Convolutional Neural Networks for Automatic Detection of Artifacts from
  Independent Components Represented in Scalp Topographies of EEG Signals</font>
    </a>
  </h2>
  <font color="black">これまで、脳波のゴールドスタンダードであるICトポプロット分析は、人間の専門家が視覚的に実施していたため、自動高速応答脳波では使用できませんでした。リアルタイムではありませんが、提案されたフレームワークは十分に効率的です。高速応答脳波ベースの脳コンピューターインターフェイス（BCI）で使用され、ICに基づく他の自動方式よりも高速です。脳波計（EEG）は、頭皮に配置されたセンサーを使用してリアルタイムで電気的脳活動を測定します。 
[要約]これまで、ic topoplot分析（egのゴールドスタンダード）は視覚的に人間の専門家によって実行されていたため、自動高速応答ネットワークでは使用できません。この方法は、32,000カロリーで使用するのに十分な効率があり、 icsに基づく他の自動メソッドよりも高速</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Analyzing Semantic Robustness of Deep Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_6.html">
      <font color="black">Towards Analyzing Semantic Robustness of Deep Neural Networks</font>
    </a>
  </h2>
  <font color="black">これらのセマンティックマップの生成は、セマンティックスペースの次元にうまく対応できないため、DNNのロバストな領域を検出するボトムアップアプローチを開発します。これを実現するために、ネットワークのロバストなセマンティック領域を見つける問題を最適化として定式化します。積分境界と、領域境界の更新方向の式を作成します。意味空間におけるDNNロバスト性の理論的に根拠のある分析を提案します。 
[要旨] dnnのグローバルな動作をセマンティックマップとして視覚化することにより、さまざまなdnnのセマンティックロバスト性を分析し、一部のdnnの興味深い動作を観察します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-09">
        <br><font color="black">2019-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: DeepSign: Deep On-Line Signature Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_7.html">
      <font color="black">DeepSign: Deep On-Line Signature Verification</font>
    </a>
  </h2>
  <font color="black">公開データの欠如に加えて、通常はさまざまなデータベースや実験プロトコルが検討されるため、提案された新しいアプローチの改善を評価することは容易ではありません。提案されたTA-RNNシステムは、最新技術より優れており、2.0未満でも結果を達成しています。熟練した偽造詐欺師とユーザーごとに1つのトレーニングシグネチャを考慮した場合の％EER。過去数年間、ディープラーニングは息をのむようなテクノロジーになり、伝統的な手作りのアプローチだけでなく、多くの異なるタスクに対する人間さえも克服しました。 
[要約]オンライン署名検証のためのディープラーニングテクニックが提案されています。提案されているta-rnnシステムは、最新の技術より優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-24">
        <br><font color="black">2020-02-24</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Scale Recovery for Monocular Depth and Egomotion
  Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_8.html">
      <font color="black">Self-Supervised Scale Recovery for Monocular Depth and Egomotion
  Estimation</font>
    </a>
  </h2>
  <font color="black">この論文では、既知のカメラの高さと推定されるカメラの高さとの間の一貫性を強制し、メトリック（スケーリングされた）深度とエゴモーション予測を生成する、新しい\ textit {scale recovery loss}を提示します。単眼画像によるエゴモーションニューラルネットワークはよく研究されており、最先端の正確性を実証しています。 。 
[要約]深度とエゴモーションの推定値は、未知のスケールまでしか知られていません。この方法は、他のスケール回復手法と競合します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: Synthesize then Compare: Detecting Failures and Anomalies for Semantic
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_9.html">
      <font color="black">Synthesize then Compare: Detecting Failures and Anomalies for Semantic
  Segmentation</font>
    </a>
  </h2>
  <font color="black">}、都市景観のAUPRエラー6％、MSDの膵腫瘍セグメンテーションのピアソン相関7％、StreetHazards異常セグメンテーションのAUPR 20％。最初のモジュールは、セグメンテーションレイアウトマップから合成画像を生成する画像合成モジュールです。もう1つは比較モジュールで、合成画像と入力画像の違いを計算します。3つの挑戦的なデータセットでフレームワークを検証し、最新の技術を大幅に改善して\ emph {ie 
[ABSTRACT ]このホワイトペーパーでは、障害と異常検出を体系的に調査します。これら2つの関連する問題に対処するために、2つのモジュールで構成される統合フレームワークを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br><font color="black">2020-03-18</font>
      </time>
    </span>
</section>
<!-- paper0: Collaborative Attention Network for Person Re-identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_10.html">
      <font color="black">Collaborative Attention Network for Person Re-identification</font>
    </a>
  </h2>
  <font color="black">次に、隣接するスライスから機能の組み合わせを自動的に学習するCollaborative Attention Network（CAN）を紹介します。Market-1501、DukeMTMC-ReID、CUHK03などの広く使用されているいくつかのパブリックデータセットの実験結果は、提案された方法が多くの既存の状態よりも優れていることを証明しています特に、提案されたマルチブランチ構造を使用して、最初にグローバル機能を異なるスケールで複数のローカルスライスに分離します。 
[ABSTRACT]作品は、ローカルパターンを収集しようとする一連の作品に基づいています。個々のフィーチャの組み合わせが含まれています。これは、グローバルフィーチャを複数のローカルスライスに分離できることを意味します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-29">
        <br><font color="black">2019-11-29</font>
      </time>
    </span>
</section>
<!-- paper0: Wasserstein GANs for MR Imaging: from Paired to Unpaired Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_11.html">
      <font color="black">Wasserstein GANs for MR Imaging: from Paired to Unpaired Training</font>
    </a>
  </h2>
  <font color="black">ジェネレーターは、展開されたニューラルネットワーク（畳み込み層とデータ整合性レイヤーのカスケード）です。さらに、私たちの敵対的なトレーニングスキームは、ピクセル単位の損失を伴うペアのトレーニングスキームと比較して（エキスパートの放射線科医による評価で）より良い画質を達成できます。弁別器は、Wasserstein距離に基づいて再構成された画像の品質を評価する評論家の役割を果たす多層CNNでもあります。 
[ABSTRACT]再構成ネットワークの不対敵対トレーニング。ジェネレータは、展開されたニューラルネットワーク-たたみ込み層とデータ整合性層のカスケード</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-15">
        <br><font color="black">2019-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Discernible Image Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_12.html">
      <font color="black">Discernible Image Compression</font>
    </a>
  </h2>
  <font color="black">したがって、圧縮画像は後続のタスクで識別可能であり、この方法を識別可能な画像圧縮（DIC）と呼びます。たとえば、DICによる圧縮画像のmAP値は、従来の方法による圧縮画像を使用する場合よりも約0.6％高くなります。結果として得られる圧縮ネットワークは、高画質の画像を生成し、機能ドメインで一貫した認識を維持できるため、これらの画像は事前トレーニング済みの機械学習モデルで十分に認識できます。 
[要旨]新しい方法を使用して、元の画像と圧縮画像の特徴を抽出し、それらを類似させることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-17">
        <br><font color="black">2020-02-17</font>
      </time>
    </span>
</section>
<!-- paper0: Solving the Blind Perspective-n-Point Problem End-To-End With Robust
  Differentiable Geometric Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_13.html">
      <font color="black">Solving the Blind Perspective-n-Point Problem End-To-End With Robust
  Differentiable Geometric Optimization</font>
    </a>
  </h2>
  <font color="black">代わりに、ブラインドPnP問題を効率的かつグローバルに解決するために、つまりポーズの事前計算を必要とせずに、最初の完全なエンドツーエンドのトレーニング可能なネットワークを提案します。提案されたアプローチは、合成データと実際のデータの他の方法を大幅に上回ります。 Sinkhorn、RANSAC、PnPアルゴリズムなどのエンドツーエンドの学習フレームワークに幾何モデルのフィッティングを組み込むために、最適化問題を区別するための最近の結果の使用。 
[要約]ポーズと対応を同時に解決することは非常に困難です。既存のアプローチでは、ノイズの多い対応が提供されるか、適切なポーズを事前に利用できるか、または問題のサイズが小さいと想定しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding and Exploiting Dependent Variables with Deep Metric
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_14.html">
      <font color="black">Understanding and Exploiting Dependent Variables with Deep Metric
  Learning</font>
    </a>
  </h2>
  <font color="black">これらの関係に基づいて、これらの顕著なバックグラウンド変数に関する以前の情報は、クラスタリングアルゴリズムを使用して分類パフォーマンスを向上させることにより、DMLアプローチの推論段階で活用できます。各クエリごとのDML表現の分布を観察する視覚化ツールの使用を通じて以前の情報が利用可能な変数、分類タスクへの各変数の影響をよりよく理解することができます。このペーパーは、データの品質と多様性を維持するためのオンライン管理戦略と、 DMLアプローチ。 
[要旨]このペーパーでは、任意の分類問題の顕著な特徴が場所によって異なる状況で、dmlのマッピング要素がどのように利用されるかを探ります。これらには、dml表現の分布を観察するための視覚化ツールを使用するためのこれらの孤立したナビゲーションツールが含まれます事前情報が入手可能な各受刑者</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: A Genetic Feature Selection Based Two-stream Neural Network for Anger
  Veracity Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_15.html">
      <font color="black">A Genetic Feature Selection Based Two-stream Neural Network for Anger
  Veracity Recognition</font>
    </a>
  </h2>
  <font color="black">次に、選択した機能を使用して、単純な完全に接続されたニューラルワークと2ストリームニューラルネットワークをトレーニングします。結果は、2ストリームアーキテクチャが瞳孔反応時に93.58％の精度で有望な認識結果を達成できることを示していますこの論文では、観察者の瞳孔データを用いて、計算手法により怒りの信憑性を認識できるかどうかを検証することを目的としています。 
[ABSTRACT] 2-ストリームアーキテクチャは、両目からの瞳孔反応が利用可能な場合、93。58％の精度で有望な認識結果を達成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-06">
        <br><font color="black">2020-09-06</font>
      </time>
    </span>
</section>
<!-- paper0: LaSOT: A High-quality Large-scale Single Object Tracking Benchmark -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_16.html">
      <font color="black">LaSOT: A High-quality Large-scale Single Object Tracking Benchmark</font>
    </a>
  </h2>
  <font color="black">LaSOTの平均ビデオ長は約2,500フレームです。各ビデオには、ターゲットが消えたり再出現したりするなど、実際のビデオ映像に存在するさまざまな課題が含まれています。LaSOTのリリースにおける私たちの目標は、専用の高品質プラットフォームを提供することですトラッカーのトレーニングと評価の両方に使用できます。視覚的な外観と自然言語の密接な関係を利用するために、LaSOTの各ビデオの言語仕様を提供しています。 
[要旨]高品質の大規模な単一オブジェクト追跡のベンチマークであるラソトを紹介します。これには、境界ボックスで注釈が付けられた一連のビデオが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Accurate Pixel-wise Object Tracking by Attention Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_17.html">
      <font color="black">Towards Accurate Pixel-wise Object Tracking by Attention Retrieval</font>
    </a>
  </h2>
  <font color="black">最初に、開始フレームにグラウンドトゥルースマスクを使用してルックアップテーブル（LUT）を作成し、次にLUTを取得して空間制約のアテンションマップを取得します。このアプローチにより、新しい最先端の最近のピクセル単位のオブジェクトトラッキングベンチマークVOT2020（40 fpsで実行中）。さらに、バックボーン機能をフィルターする予測マスクを再利用することにより、バックグラウンドクラッターの影響をさらに弱めるために、マルチ解像度マルチステージセグメンテーションネットワーク（MMS）を導入します。 
[ABSTRACT]私たちは、バックボーン機能にソフトな空間制約を実行するための注意検索ネットワーク（arn）を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-06">
        <br><font color="black">2020-08-06</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Machine Learning in Image Classification: A Survey Towards
  the Defender's Perspective -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_18.html">
      <font color="black">Adversarial Machine Learning in Image Classification: A Survey Towards
  the Defender's Perspective</font>
    </a>
  </h2>
  <font color="black">ディープラーニングアルゴリズムは、画像分類の最先端のパフォーマンスを実現し、生体認証システムや自動運転車などのセキュリティが重要なアプリケーションでも使用されています。しかし、最近の研究でこれらのアルゴリズムが示されています。人間の能力を超えることさえあり得、敵対的な例に対して脆弱です。それにもかかわらず、効率的な防御メカニズムを考案することは困難な作業であることが証明されています。 
[要旨]考案論文は、防御策を考案および評価することによって作成されました。また、研究者が考慮すべきガイダンスも提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: A Residual Solver and Its Unfolding Neural Network for Total Variation
  Regularized Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_19.html">
      <font color="black">A Residual Solver and Its Unfolding Neural Network for Total Variation
  Regularized Models</font>
    </a>
  </h2>
  <font color="black">最後に、提案されたアルゴリズムとニューラルネットワークの両方がいくつかの問題にうまく適用され、画像の平滑化、ノイズ除去、生物医学的画像再構成などの効果と効率が実証されています。理論的には、アルゴリズムの勾配フィールドの一意性を証明しています。分析後以前の方法では、勾配領域でモデルを暗黙的に解く、Residual Solverという名前の新しい反復アルゴリズムを開発しました。 
[ABSTRACT]新しいシステムは「残差ソルバー」と呼ばれます。他の総変動正則化モデルに適用できます。提案されたネットワークは監視されておらず、システムの「拡張バージョン」と見なすことができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: Disentangled Non-Local Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_20.html">
      <font color="black">Disentangled Non-Local Neural Networks</font>
    </a>
  </h2>
  <font color="black">また、単独でトレーニングされた2つの用語は、異なる視覚的な手がかりをモデル化する傾向があることもわかります。ただし、2つの用語は非ローカルブロックで密結合されているため、それぞれの学習は妨げられます。白色化されたペアワイズ用語は領域内の関係を学習し、単項用語は顕著な境界を学習します。 
[ABSTRACT]非vovovovovovoブロックは絡み合っていない非vovovovovovovolutionです。2つの用語に分割できます。2つのピクセル間の関係を説明する白色のペアワイズ項と、すべてのピクセルの顕著性を表す単項項です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br><font color="black">2020-06-11</font>
      </time>
    </span>
</section>
<!-- paper0: Convolution Neural Networks for diagnosing colon and lung cancer
  histopathological images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_21.html">
      <font color="black">Convolution Neural Networks for diagnosing colon and lung cancer
  histopathological images</font>
    </a>
  </h2>
  <font color="black">同様のモデルを使用して、腺癌と結腸の良性を分類しました。本研究の目的は、デジタルの評価により、畳み込みニューラルネットワークを使用して、肺の扁平上皮癌と腺癌、および結腸の腺癌を診断するためのコンピューター支援診断システムを提案することです。これらの癌の病理画像。浅いニューラルネットワークアーキテクチャを使用して、組織病理学的スライドを扁平上皮癌、腺癌、および肺の良性に分類しました。 
[要約]浅いニューラルネットワークアーキテクチャを使用して、組織病理学的スライドを肺の良性に分類しました。肺と結腸でそれぞれ97％と96％を超える診断精度が記録されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: Visual Object Tracking by Segmentation with Graph Convolutional Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_22.html">
      <font color="black">Visual Object Tracking by Segmentation with Graph Convolutional Network</font>
    </a>
  </h2>
  <font color="black">まず、ターゲットオブジェクトのセグメンテーションのための空間的および時間的一貫性制約の両方を活用するための効果的なエンドツーエンドの方法を提供します。提案されたモデルを最適化するための効果的なアルゴリズムが開発されました。セグメンテーションベースの追跡は、コンピュータービジョンで活発に研究されていますそしてマルチメディア。 
[要約]提案されたgcn方法は、スーパーピクセルベースのオブジェクトセグメンテーションをトラッキングに組み合わせます。スーパーピクセル表現とラベリングに混合表現と識別機能を使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-05">
        <br><font color="black">2020-09-05</font>
      </time>
    </span>
</section>
<!-- paper0: Fast and Accurate Image Super Resolution by Deep CNN with Skip
  Connection and Network in Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_23.html">
      <font color="black">Fast and Accurate Image Super Resolution by Deep CNN with Skip
  Connection and Network in Network</font>
    </a>
  </h2>
  <font color="black">Network in Networkと呼ばれる並列化された1x1 CNNは、画像の再構成にも使用されます。DeepCNNは最近、単一画像の超解像で大きな再構成パフォーマンスを発揮することを示しています。DeepCNNとSkip接続レイヤーの組み合わせローカル領域とグローバル領域の両方の画像特徴の特徴抽出器として使用されます。 
[要約]深い再構成は、単一画像の超解像で大きな再構成パフォーマンスを発揮することを示しています。現在、深いモデルはより大きな計算を必要とし、モバイル、タブレット、IoTなどのネットワークエッジデバイスには適していません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2017-07-18">
        <br><font color="black">2017-07-18</font>
      </time>
    </span>
</section>
<!-- paper0: SoccerDB: A Large-Scale Database for Comprehensive Video Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_24.html">
      <font color="black">SoccerDB: A Large-Scale Database for Comprehensive Video Understanding</font>
    </a>
  </h2>
  <font color="black">サッカーゲームは明確に定義されたルールの下でプレイされ、研究者が研究するには複雑で興味をそそるので、サッカービデオはビデオ理解のための完璧な研究オブジェクトとして役立ちます。SoccerDBのリリースは、包括的なビデオ理解に関する研究を大幅に前進させると信じています。データベースには、702,096の境界ボックス、37,709の重要なイベントラベルと時間境界、17,115のハイライトアノテーション（オブジェクト検出、アクション認識、時間的アクションのローカライズ、ハイライト検出タスク）が含まれています。 
[ABSTRACT] soccerdb.itという名前の新しいサッカービデオデータベースを提案します。これには、346の高品質サッカーゲームの71,9ビデオセグメントが含まれます。これは、包括的なスポーツビデオアクションの最大のデータベースです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-10">
        <br><font color="black">2019-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-domain semantic segmentation with pyramidal fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_25.html">
      <font color="black">Multi-domain semantic segmentation with pyramidal fusion</font>
    </a>
  </h2>
  <font color="black">私たちのモデルは、RVCセマンティックセグメンテーションチャレンジとWildDash 2リーダーボードで1位にランク付けされます。これは、log-sum-prob損失によるカスタムの後方ステップを実装し、人口統計をフリーズする前に小さな作物を使用することで達成されます。ハード認識問題の最適化を安定させ、batchnorm統計の円滑な進化を促進するために、大きなバッチでトレーニングするよう努めます。 
[要約]コンテストでは、3つの異なるドメインの7つのベンチマークに同じモデルを提出する必要があります。シングルレベル193-テクニカルソフトマックス出力に基づいています。これを行うには、log-sum-prob損失によるカスタムの後方ステップを実装し、人口統計を凍結する前に小さな作物を使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Obtaining Faithful Interpretations from Compositional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_26.html">
      <font color="black">Obtaining Faithful Interpretations from Compositional Neural Networks</font>
    </a>
  </h2>
  <font color="black">これを修正するために、補助監視を使用してモデルをトレーニングし、精度を最小限に抑えて、はるかに優れた忠実性をもたらすモジュールアーキテクチャの特定の選択肢を提案します。この作業では、上のNMNの中間出力の体系的な評価を提案し、実施しますNLVR2とDROP、複数の推論ステップの作成を必要とする2つのデータセット。中間出力が予想出力と異なることがわかり、ネットワーク構造がモデルの動作を忠実に説明していないことがわかります。 
[ABSTRACT]ネットワーク構造はモデルの動作を忠実に説明するものではありません。ただし、以前の研究では、この構造がモデルの動作の「忠実な説明」を提供することを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-02">
        <br><font color="black">2020-05-02</font>
      </time>
    </span>
</section>
<!-- paper0: Inducing Optimal Attribute Representations for Conditional GANs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_27.html">
      <font color="black">Inducing Optimal Attribute Representations for Conditional GANs</font>
    </a>
  </h2>
  <font color="black">GANにとって意味のある条件は、ターゲットドメイン合成データの性質をより柔軟に制御します。挑戦的な顔属性操作データセット、CelebA、LFWA、およびRaFDに関する当社の広範な定性的および定量的評価は、当社のメソッドによって強化されたcGANが優れていることを示していますターゲット属性の認識率とPSNRやSSIMなどの品質指標の両方の点で、対応するものや他の条件付け方法と比較して、大幅なマージンで。グラフの畳み込みネットワークを備えた新しいエンドツーエンドの学習フレームワークを提案します。ジェネレーターで条件付けする属性表現を学習します。 
[要約]そのような表現の主な欠点は、ターゲットカテゴリの高次の意味情報をエンコードできないことです。これらの表現は、高次の意味情報では学習できません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-13">
        <br><font color="black">2020-03-13</font>
      </time>
    </span>
</section>
<!-- paper0: Few-Shot Hyperspectral Image Classification With Unknown Classes Using
  Multitask Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_28.html">
      <font color="black">Few-Shot Hyperspectral Image Classification With Unknown Classes Using
  Multitask Deep Learning</font>
    </a>
  </h2>
  <font color="black">再構築されたデータは元のデータと比較されます。再構築に失敗したものは、ラベルがないために潜在的な特徴で十分に表現されていないという仮定に基づいて、不明と見なされます。多くの場合、分類システムが構築されると、新しいクラスが見落とされます。しきい値は、未知のクラスと既知のクラスを分離するように定義されています少数ショットおよび多数ショットのシナリオについて、極値理論に基づく2つの戦略を提案します。 
[要約]提案された方法は、実際のハイパースペクトル画像でテストされました。これらには最先端の結果が含まれており、全体的な精度は4.94％低くなっています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: Intraoperative Liver Surface Completion with Graph Convolutional VAE -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_29.html">
      <font color="black">Intraoperative Liver Surface Completion with Graph Convolutional VAE</font>
    </a>
  </h2>
  <font color="black">この最適化の効果は、最初に生成された形状の漸進的な非剛体変形です。推論時に、モデルの生成部分は最適化手順に埋め込まれ、潜伏表現が反復的に更新されて術中と一致するモデルが生成されます部分的な点群..この作業では、外科的腹腔鏡手術中に得られた臓器の部分的な点群を前提として、幾何学的深層学習に基づいて肝臓の表面全体を予測する方法を提案します。 
[ABSTRACT]私たちは、データセットの制限されたサイズを補正するために、周波数領域の形状をランダムに摂動させる新しいデータ拡張技術を導入します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: Learning more expressive joint distributions in multimodal variational
  methods -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_30.html">
      <font color="black">Learning more expressive joint distributions in multimodal variational
  methods</font>
    </a>
  </h2>
  <font color="black">それは、単純なパラメトリック分布で後部関節を近似し、その後、より複雑な分布に変換します。いくつかの実験を通じて、このようなさまざまなコンピュータービジョンタスクの変分推論に基づく最新のマルチモーダル法でモデルが改善することを示しますカラー化、エッジとマスクの検出、弱く監視された学習など。モデルのコードはhttps://github.com/SashoNedelkoski/BPFDMVMで公開されています。 
[要約]モデルのコードはwwwで公開されています。 github。 com</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding Compositional Structures in Art Historical Images using
  Pose and Gaze Priors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_31.html">
      <font color="black">Understanding Compositional Structures in Art Historical Images using
  Pose and Gaze Priors</font>
    </a>
  </h2>
  <font color="black">マックスイムダールの先駆的な作品に触発された私たちのアプローチは、画像合成の2つの中心的なテーマに焦点を当てています。（a）アートワークのアクション領域とアクションラインの検出。 （b）前景と背景のポーズベースのセグメンテーション。コンピュータービジョンテクニックを使用してこれらの構造を自動的に生成する（1）は、多くの時間を節約することにより、美術史家が高度な分析を行うのに役立ちます。概要と巨大な画像リポジトリへのアクセスを提供し、（2）機械による人工画像の理解に向けた重要なステップも提供します。この作業では、既存の最先端の機械学習手法を使用してこのプロセスを自動化します。いかなる形のトレーニングも必要ありません。 
[ABSTRACT]この作業では、im機械学習技術の既存の状態を使用してこのプロセスを自動化しようとします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: Imbalanced Continual Learning with Partitioning Reservoir Sampling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_32.html">
      <font color="black">Imbalanced Continual Learning with Partitioning Reservoir Sampling</font>
    </a>
  </h2>
  <font color="black">私たちは、2つの独立して解決された問題であるCatastropic Forgettingとロングテールラベルの配布に共同で取り組みます。最初に、テールの少数概念の破壊的忘却の新しい課題を実証的に示します。次に、COCOseqとNUS-WIDEseqの2つのベンチマークデータセットをキュレートします。 、タスク内およびタスク間の不均衡の研究を可能にします。データの連続ストリームからの継続的な学習は、機械学習の研究にとって重要な課題です。 
[ABSTRACT]多くのマルチラベルデータセットで予期せぬ逆境を特定します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: Perceptual Deep Neural Networks: Adversarial Robustness through Input
  Recreation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CV/paper_33.html">
      <font color="black">Perceptual Deep Neural Networks: Adversarial Robustness through Input
  Recreation</font>
    </a>
  </h2>
  <font color="black">これは、脊椎動物の死角も同様に、視覚的ロバスト性の前兆である可能性があることを示唆しています。したがって、$ \ varphi $ DNNsは、入力のレクリエーションが生物学的ネットワークと同様の人工ニューラルネットワークに大きなメリットをもたらし、重要性に光を当てることを明らかにします盲点の認識と、人工知能におけるロバストな認識のための知覚モデルの領域の開始。実験により、$ \ varphi $ DNNは攻撃の精度を大幅に低下させ、テストの87％で最先端の防御を超える可能性があることが判明他の前処理タイプの防御とのみ比較した場合の、敵対的なトレーニングのバリエーションと100％のテスト。 
[要旨]網膜に到達する信号が表示されないため、人々の知覚は機械とは根本的に異なります。さらに処理する前に自分の入力を再生成する知覚的なディープニューラルネットワークを提案します。これらは攻撃の精度を大幅に低下させる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: kk2018 at SemEval-2020 Task 9: Adversarial Training for Code-Mixing
  Sentiment Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CL/paper_0.html">
      <font color="black">kk2018 at SemEval-2020 Task 9: Adversarial Training for Code-Mixing
  Sentiment Classification</font>
    </a>
  </h2>
  <font color="black">さらに、多言語モデルを使用した敵対的トレーニングは、SemEval-2020タスク9ヒンディー語-英語感情分類競争の1位を達成するために使用されます。異なる言語のグループ間のコミュニケーションの増加に伴い、この現象はますます人気があります。この作業では、最先端の単一言語モデルERNIEからのドメイン転送学習がコード混合データセットでテストされ、驚くべきことに、強力なベースラインが達成されます。 
[ABSTRACT]言語グループでの言語の人気が高まっています。これは、異なる言語のグループ間の言語コミュニケーションが原因です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: Leam: An Interactive System for In-situ Visual Text Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CL/paper_1.html">
      <font color="black">Leam: An Interactive System for In-situ Visual Text Analysis</font>
    </a>
  </h2>
  <font color="black">Leamは、テキスト分析ワークフローを実行するためのインタラクティブなユーザーインターフェイス、複数のアトミックおよび複合データタイプを管理するための新しいデータモデル、テキスト分析のさまざまな段階を表すさまざまな操作のセットをキャプチャし、システムのさまざまなコンポーネント間の調整を可能にする表現代数を備えています、データ、コード、視覚化を含みます。既存のテキスト分析システムは通常これらの段階のサブセットに対応しており、データの異質性、来歴、ワークフローの再利用性と再現性、および確立されたプラクティスとの互換性に関連する課題に対処できないことがよくあります。これらの課題から派生した設計上の考慮事項として、計算ノートブック、スプレッドシート、視覚化ツールの利点を組み合わせることにより、テキスト分析プロセスを単一の連続体として扱うシステムであるLeamを提案します。 
[ABSTRACT]テキストデータ分析は、データのクリーニングから視覚化まで、複数のステージにまたがる多様なワークフローを備えた反復的な非線形プロセスです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: A Simple Global Neural Discourse Parser -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CL/paper_2.html">
      <font color="black">A Simple Global Neural Discourse Parser</font>
    </a>
  </h2>
  <font color="black">計算の課題を克服するために、ツリー内のノードに割り当てられたラベルとその子を分割する分割ポイントの間の独立性の仮定を提案します。これにより、解読が容易になります。このモデルは、グローバルパーサーの中で最高のパフォーマンスを実現することを実証的に実証しています、および学習されたスパン表現のみを使用して、最先端の貪欲なパーサーに匹敵するパフォーマンス。談話の構文解析は、手動で設計された機能を備えた貪欲なパーサーが大部分を占めますが、グローバルな構文解析は、その計算費用のためまれです。 
[ABSTRACT]シンプルなチャート-ベースのニューラルディスコースパーサーは学習されたスパンに基づいています。手動で複雑化した機能は必要なく、学習スパンのみに基づいています。モデルはグローバルパーサーの中で最高のパフォーマンスを達成しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Jointly Encoding Word Confusion Network and Dialogue Context with BERT
  for Spoken Language Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CL/paper_3.html">
      <font color="black">Jointly Encoding Word Confusion Network and Dialogue Context with BERT
  for Spoken Language Understanding</font>
    </a>
  </h2>
  <font color="black">音声言語理解（SLU）は、仮説を自動音声認識（ASR）から構造化された意味表現に変換します。このホワイトペーパーでは、新しいBERTベースのSLUモデル（WCN-BERT SLU）が、WCNと対話コンテキストを一緒にエンコードするために提案されています。この問題に対処するために、ワードコンフュージョンネットワーク（WCN）を使用して、SLUの入力をエンコードしました。これには、1-bestまたはn-best仮説リストよりも豊富な情報が含まれています。 
[ABSTRACT] asrmarkエラーは、後続のsluモジュールのパフォーマンスを大幅に低下させる可能性があります。これらはシステムへの変更の例です。これには、ダイアログコンテキストの最後のシステム動作の削除が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-24">
        <br><font color="black">2020-05-24</font>
      </time>
    </span>
</section>
<!-- paper0: ERNIE at SemEval-2020 Task 10: Learning Word Emphasis Selection by
  Pre-trained Language Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CL/paper_4.html">
      <font color="black">ERNIE at SemEval-2020 Task 10: Learning Word Emphasis Selection by
  Pre-trained Language Model</font>
    </a>
  </h2>
  <font color="black">ポイントワイズ回帰損失と最終的なM atchmメトリックにより近いペアワイズランキングロスを組み合わせて、モデルを微調整します。調査の結果、次のモデルがこのタスクで優れたパフォーマンスを達成していることがわかりました。ERNIE2.0、XLM- ROBERTA、ROBERTA、ALBERT ..また、追加の機能エンジニアリングとデータ拡張がパフォーマンスの向上に役立つこともわかりました。 
[ABSTRACT]自動設計の提案として最も重要な単語を見つけるように求められます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: A Convolutional Deep Markov Model for Unsupervised Speech Representation
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CL/paper_5.html">
      <font color="black">A Convolutional Deep Markov Model for Unsupervised Speech Representation
  Learning</font>
    </a>
  </h2>
  <font color="black">さらに、ConvDMMは、Wav2VecやPASEなどの自己監視手法を補完し、いずれかの手法のみで達成された結果を改善することを発見しました。確率的潜在変数モデル（LVM）は、からの言語表現学習のための自己監視学習アプローチの代替手段を提供します。スピーチ..大規模なスピーチデータセット（LibriSpeech）でトレーニングすると、ConvDMMは、ウォールストリートジャーナルデータセットでの線形電話分類および認識に関する複数の自己監視機能抽出方法を大幅に上回る機能を生成します。 
[要約] lvmsは、潜在的な構造が信号から抽出された情報を形成する直観的な確率論的解釈を認めます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-03">
        <br><font color="black">2020-06-03</font>
      </time>
    </span>
</section>
<!-- paper0: Disentangled Non-Local Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CL/paper_6.html">
      <font color="black">Disentangled Non-Local Neural Networks</font>
    </a>
  </h2>
  <font color="black">ホワイト化されたペアワイズ用語はリージョン内の関係を学習し、単項用語は顕著な境界を学習します。Cityscapesのセマンティックセグメンテーション、ADE20KおよびPASCALコンテキスト、COCOでのオブジェクト検出、アクション認識などのさまざまなタスクでの分離設計の有効性を示しますこれらの調査結果に基づいて、我々は、2つの用語が両方の用語の学習を容易にするために分離されている、もつれていない非ローカルブロックを提示します。 
[ABSTRACT]非vovovovovovoブロックは絡み合っていない非vovovovovovovolutionです。2つの用語に分割できます。2つのピクセル間の関係を説明する白色のペアワイズ項と、すべてのピクセルの顕著性を表す単項項です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br><font color="black">2020-06-11</font>
      </time>
    </span>
</section>
<!-- paper0: LynyrdSkynyrd at WNUT-2020 Task 2: Semi-Supervised Learning for
  Identification of Informative COVID-19 English Tweets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CL/paper_7.html">
      <font color="black">LynyrdSkynyrd at WNUT-2020 Task 2: Semi-Supervised Learning for
  Identification of Informative COVID-19 English Tweets</font>
    </a>
  </h2>
  <font color="black">私たちの最高のパフォーマンスモデルは、提供された検証セットで0.9179、ブラインドテストセットで0.8805のF1スコアを達成します。さらに、疑似ラベル付けを使用して、パンデミックでリリースされたラベルなしTwitterデータを組み込みます。従来の機能ベースの分類子と、事前にトレーニングされた言語モデルの最近の進歩の両方を活用して、ツイートから構文、意味、およびコンテキストの機能をキャプチャするさまざまな機械学習方法。 
[要旨]私たちのシステムはさまざまな機械学習手法を組み合わせたものです。19人の異なる同僚を採用してツイートをキャプチャしています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: Simple is Better! Lightweight Data Augmentation for Low Resource Slot
  Filling and Intent Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CL/paper_8.html">
      <font color="black">Simple is Better! Lightweight Data Augmentation for Low Resource Slot
  Filling and Intent Classification</font>
    </a>
  </h2>
  <font color="black">軽量拡張は、単語スパンと文レベルの操作を伴う一連の拡張メソッドであり、データ不足の問題を軽減することを示しています。さらに、軽量拡張は、事前トレーニング済みのLMベースのモデルと組み合わせると、BERTベースのジョイントを改善するため、有益です。インテントおよびスロット充填モデル..かなり大きなドメイン内トレーニングデータが利用可能な場合、ニューラルベースのモデルは、スロット充填およびインテント分類で卓越したパフォーマンスを実現しました。 
[ABSTRACT]軽量の拡張により、atisおよびsnipsデータセットのスロット充填でパフォーマンスが大幅に向上します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: Obtaining Faithful Interpretations from Compositional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CL/paper_9.html">
      <font color="black">Obtaining Faithful Interpretations from Compositional Neural Networks</font>
    </a>
  </h2>
  <font color="black">これを修正するために、補助監視を使用してモデルをトレーニングし、精度を最小限に抑えて、はるかに優れた忠実性をもたらすモジュールアーキテクチャの特定の選択肢を提案します。この作業では、上のNMNの中間出力の体系的な評価を提案し、実施しますNLVR2とDROPは、複数の推論ステップを構成する必要がある2つのデータセットです。ニューラルモジュールネットワーク（NMN）は、構成性をモデル化するための一般的なアプローチです。問題の構成構造を反映しながら、言語とビジョンの問題に適用すると、高精度を実現します。ネットワークアーキテクチャ。 
[ABSTRACT]ネットワーク構造はモデルの動作を忠実に説明するものではありません。ただし、以前の研究では、この構造がモデルの動作の「忠実な説明」を提供することを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-02">
        <br><font color="black">2020-05-02</font>
      </time>
    </span>
</section>
<!-- paper0: Negative Statements Considered Useful -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CL/paper_10.html">
      <font color="black">Negative Statements Considered Useful</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、成立しない顕著なステートメントを明示的に述べる場合について説明します。さまざまなデータセットを使用した実験結果は、このメソッドが注目すべき否定的なステートメントを効果的に発見できることを示しており、外部研究では、エンティティの要約に対するその有用性が強調されています。このような無効なステートメントが豊富にある場合、それらをコンパイルするためのあらゆる努力は、顕著性によるランキングに対処する必要があります。 
[ABSTRACT]すべての人気のトリンは肯定のみをキャプチャし、kb.negativeステートメントに格納されていないステートメントに対してスタンスをとらないことは、質問応答の制限を克服するのに役立ち、多くの場合、エンティティの有益な要約に貢献できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br><font color="black">2020-01-13</font>
      </time>
    </span>
</section>
<!-- paper0: PoWER-BERT: Accelerating BERT Inference via Progressive Word-vector
  Elimination -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/cs.CL/paper_11.html">
      <font color="black">PoWER-BERT: Accelerating BERT Inference via Progressive Word-vector
  Elimination</font>
    </a>
  </h2>
  <font color="black">PoWER-BERTは、従来の方法と比較して、精度と推論時間のトレードオフが大幅に改善されていることを示しています。この方法では、ALBERTに適用すると、推論時間が最大6.8倍短縮され、精度が1％未満の損失になるBERTの高度に圧縮されたバージョン。標準のGLUEベンチマークでの実験は、PoWER-BERTがBERTに比べて推論時間を最大4.5倍短縮し、1％未満の精度の損失を実現していることを示しています。 
[要旨] bertと呼ばれるパワーにより、従来の方法と比較して、精度と時間のトレードオフが大幅に改善される</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-24">
        <br><font color="black">2020-01-24</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Semi-supervised Neural Chord Estimation Based on a Variational
  Autoencoder with Latent Chord Labels and Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/eess.AS/paper_0.html">
      <font color="black">Semi-supervised Neural Chord Estimation Based on a Variational
  Autoencoder with Latent Chord Labels and Features</font>
    </a>
  </h2>
  <font color="black">追加の非注釈付きデータを使用した半教師あり学習は、パフォーマンスをさらに向上させることができます。具体的には、離散ラベルと連続特徴（潜在変数）からクロマベクトル（観測変数）の生成プロセスを表す深生成モデルを公式化します。自己遷移と標準ガウス分布をそれぞれ好むマルコフモデルに従うと仮定されます。実験結果は、コードラベルの前のマルコフとクロマベクトルの生成モデルに基づく分類モデルの正規化により、パフォーマンスが向上したことを示しています。監視された状態でもACEの。 
[要旨]エースへの典型的なアプローチは、注釈付きの音楽信号のみを使用して、教師付きの方法で深い分類モデルをトレーニングすることです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-14">
        <br><font color="black">2020-05-14</font>
      </time>
    </span>
</section>
<!-- paper0: Predictions of Subjective Ratings and Spoofing Assessments of Voice
  Conversion Challenge 2020 Submissions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/eess.AS/paper_1.html">
      <font color="black">Predictions of Subjective Ratings and Spoofing Assessments of Voice
  Conversion Challenge 2020 Submissions</font>
    </a>
  </h2>
  <font color="black">音声変換チャレンジ2020は、その旗艦の下での第3版であり、言語内の準並列およびクロス言語の音声変換（VC）を促進します。これらの各客観的指標は、さまざまな側面に沿ってVC出力を評価します。これらの相関関係がASV、ニューラルスピーカーの埋め込み、およびASRの主観的結果を伴う客観的評価は高く、主観的テスト結果の予測により影響を与えます。 
[要約]課題の提出の主な評価は、群集ベースのリスニングテストによって行われましたが、提出されたシステムの客観的評価も行いました。この調査では、自動話者検証（asv）を使用して5種類の客観的評価を検討しました。ニューラルスピーカーの埋め込み、なりすまし対策、予測平均意見スコア（mos）、および自動音声認識（asr）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: ID-Conditioned Auto-Encoder for Unsupervised Anomaly Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/eess.AS/paper_2.html">
      <font color="black">ID-Conditioned Auto-Encoder for Unsupervised Anomaly Detection</font>
    </a>
  </h2>
  <font color="black">DCASE 2020チャレンジタスク2のToyADMOSおよびMIMIIデータセットでメソッドを評価します。C2AEとは異なり、このアプローチでは分類サブタスクを省略し、学習プロセスを1回の実行に減らします。定数を修正することで、学習プロセスをさらに簡略化します。一致しないラベルのターゲットとしてのベクトル。 
[要約]私たちの方法は、オープンセット認識用に設計されたクラス条件付きオートエンコーダー（c2ae）の適応です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-10">
        <br><font color="black">2020-07-10</font>
      </time>
    </span>
</section>
<!-- paper0: A Convolutional Deep Markov Model for Unsupervised Speech Representation
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/eess.AS/paper_3.html">
      <font color="black">A Convolutional Deep Markov Model for Unsupervised Speech Representation
  Learning</font>
    </a>
  </h2>
  <font color="black">この教師なしモデルは、ブラックボックス変分推論を使用してトレーニングされます。大規模な音声データセット（LibriSpeech）でトレーニングすると、ConvDMMは、ウォールストリートジャーナルデータセットでの線形電話分類および認識に関する複数の自己教師付き特徴抽出方法を大幅に上回る機能を生成します。さらに、ConvDMMは、Wav2VecやPASEなどの自己監視方式を補完し、いずれかの方式のみで達成された結果を改善することを発見しました。 
[要約] lvmsは、潜在的な構造が信号から抽出された情報を形成する直観的な確率論的解釈を認めます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-03">
        <br><font color="black">2020-06-03</font>
      </time>
    </span>
</section>
<!-- paper0: AutoKWS: Keyword Spotting with Differentiable Architecture Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-09/eess.AS/paper_4.html">
      <font color="black">AutoKWS: Keyword Spotting with Differentiable Architecture Search</font>
    </a>
  </h2>
  <font color="black">深度単位の分離畳み込み、時間畳み込み、およびLSTMが構築単位として採用される、エンドツーエンドのニューラルネットワークを開発するために多くの努力が払われてきました。この論文では、微分可能なニューラルアーキテクチャ検索の最近の進歩を活用して発見することを提案します。より効率的なネットワークです。ただし、正確で高速な応答性を実現するために、高精度と低レイテンシの両方を備えたモデルを設計することは困難です。 
[要旨]見つかったモデルは97.2％のトップに到達-Google音声コマンドデータセットv1で1の精度</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
