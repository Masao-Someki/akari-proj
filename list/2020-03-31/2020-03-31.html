<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-03-31の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: GPVAD: Towards noise robust voice activity detection via weakly
  supervised sound event detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/cs.SD/paper_0.html">
      GPVAD: Towards noise robust voice activity detection via weakly
  supervised sound event detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      データの要求がはるかに少ない場合でも、単純なバイナリクリップレベルのGPV-Bモデルは、実際のシナリオでVAD-Cに匹敵するパフォーマンスを達成できます。2つのGPVADモデルとCRNNベースの標準VADモデル（VAD -C）3つの異なる評価プロトコル（クリーン、合成ノイズ、実際）。このような教師ありVADトレーニングの1つの考えられるボトルネックは、クリーントレーニングデータとフレームレベルのラベルの要件です。 
[要旨]データとフレームレベルのラベルを消去するには、世界で最も監視されているVADトレーニングが必要です。2つのフレームワークを提案します。1つはgpv -fからフルで、すべての可能なクリップと1つのバイナリ（gpv-b）を生成し、分割のみを行います。スピーチとノイズ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-27">
        <br>2020-03-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Audiogmenter: a MATLAB Toolbox for Audio Data Augmentation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/cs.SD/paper_1.html">
      Audiogmenter: a MATLAB Toolbox for Audio Data Augmentation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      生のオーディオデータ用に15種類、スペクトログラム用に8種類のオーグメンテーションアルゴリズムを提供しています。オーディオデータのオーグメンテーションは、ディープニューラルネットワークをトレーニングしてオーディオ分類タスクを解決するための重要なステップです。ライブラリは自由に利用できます。 
[ABSTRACT] audiogmenterは、matgmenterの新しいオーディオデータ拡張ライブラリです。複数の拡張技術を効率的に実装し、その有用性は文献で広く証明されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-11">
        <br>2019-12-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Deep Residual Neural Networks for Image in Speech Steganography -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/cs.SD/paper_2.html">
      Deep Residual Neural Networks for Image in Speech Steganography
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これを達成するために、3つのニューラルネットワークをトレーニングします。キャリアでメッセージを非表示にするエンコーディングネットワーク、キャリアからメッセージを再構築するデコードネットワーク、再構築されたメッセージをさらに改善するための追加のイメージエンハンサーネットワーク。提案されたアルゴリズムの将来の改善についても説明します。知覚的な損失なしに有限長の音声セグメント内にソースRGB画像メッセージを隠す学習ベースの手法。 
[要約]ディープラーニングベースの技術が知覚的な損失なしに画像メッセージを隠すために提案されています。キャリアを変更することなく、秘密のメッセージ内の情報の損失を最小限に抑えて行われます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br>2020-03-30
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: AliCoCo: Alibaba E-commerce Cognitive Concept Net -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/cs.CL/paper_0.html">
      AliCoCo: Alibaba E-commerce Cognitive Concept Net
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本稿では、世界最大の中国の電子商取引プラットフォームであるアリババで実施されている「AliCoCo」という大規模な電子商取引認知概念ネットの構築を提案します。しかし、電子商取引におけるユーザーのニーズはまだ十分に定義されておらず、既存のオントロジーのどれも、普遍的なユーザーが理解するのに十分な深さと幅を持っていません。その間のセマンティックギャップは、ショッピングエクスペリエンスのインテリジェント化を妨げます。 
[ABSTRACT] e-co-commerceでユーザーのニーズを正式に定義し、それをネットのノードとして概念化します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br>2020-03-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: AraBERT: Transformer-based Model for Arabic Language Understanding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/cs.CL/paper_1.html">
      AraBERT: Transformer-based Model for Arabic Language Understanding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、BERTが英語に対して行ったのと同じ成功を達成するために、特にアラビア語に対してBERTを事前トレーニングしました。最近、トランスフォーマーベースのモデルの急増により、言語固有のBERTベースのモデルが非常に大規模なコーパスで事前トレーニングされていれば、言語理解が非常に効率的です。このようなモデルは、新しい標準を設定し、ほとんどのNLPタスクで最先端の結果を達成することができました。 
[ABSTRACT]アラビア語言語の言語処理は、取り組むのが非常に難しいことが証明されています。arabertモデルは、新しい標準を設定し、事前トレーニング済みの結果を達成できました。Googleの多言語bertと比較したarabertのパフォーマンス
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-28">
        <br>2020-02-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: QRMine: A python package for triangulation in Grounded Theory -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/cs.CL/paper_2.html">
      QRMine: A python package for triangulation in Grounded Theory
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      QRMineを使用すると、研究者は最小限の労力でデータに対してこれらの方法を使用できます。三角測量は、さまざまなタイプのデータを組み合わせるプロセスです。MLは、テキストインタビュートランスクリプトからの調査結果を裏付けるために、数値データから洞察を導き出すのを容易にします。 
[ABSTRACT] gtは、定量的および数値的なデータを使用し、コーディングまたはタグ付けのさまざまな段階に従います。triangulationは、さまざまなタイプのデータを組み合わせるプロセスです。triangulationは、研究者がPythonパッケージインデックスからqrmineをインストールするのに役立ちます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br>2020-03-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Comprehensive Named Entity Recognition on CORD-19 with Distant or Weak
  Supervision -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/cs.CL/paper_3.html">
      Comprehensive Named Entity Recognition on CORD-19 with Distant or Weak
  Supervision
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、このデータセットが生物医学的側面と社会的側面の両方でCOVID-19の研究に洞察をもたらすことを願っています。このデータセットがテキストマイニングコミュニティのダウンストリームアプリケーションの構築に役立つことを願っています。 4つのソースからの結果：（1）Spacyの18の一般エンティティタイプの事前トレーニング済みNERモデル、（2）SciSpacyの18の生物医学エンティティタイプの事前トレーニング済みNERモデル、（3）の知識ベース（KB）ガイド付きNERモデル127の生物医学エンティティタイプと遠隔監視NERメソッド、および（4）8つの新しいエンティティタイプ（特にCOVID-19の研究に関連）のシードガイド付きNERモデルと弱監視NERメソッド。 
[ABSTRACT]このデータセットがテキストマイニングコミュニティに役立つことを願っています。さまざまな方法を開くことが可能です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-27">
        <br>2020-03-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Knowledge Graph Alignment using String Edit Distance -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/cs.CL/paper_4.html">
      Knowledge Graph Alignment using String Edit Distance
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、エンティティ間のタイプ情報を活用し、任意のアリティの関係間の類似性を見つけることができる文字列編集距離に基づく新しい知識グラフの配置手法を提案します。文字列編集距離
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-13">
        <br>2020-03-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Corpus of Controlled Opinionated and Knowledgeable Movie Discussions
  for Training Neural Conversation Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/cs.CL/paper_5.html">
      A Corpus of Controlled Opinionated and Knowledgeable Movie Discussions
  for Training Neural Conversation Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      非目標指向の対話用の完全にデータ駆動型のチャットボットは、想定されるバックグラウンドパーソナリティや事実の知識などのパラメーターの制御が一般的に困難であることから、ターン全体で一貫性のない動作に悩まされることが知られています。このプロセスにより、注釈の追加レイヤーも提供されます。これは、モデルのトレーニングに役立つ可能性があります。この理由の1つは、ラベル付けされたデータが比較的不足していることです。そこから、対話の振る舞いとともにパーソナリティの一貫性と事実の使用法を学習できます。 
[ABSTRACT]私たちは、人格の一貫性と事実の使用が対話の振る舞いと一緒に学ぶことができるデータをチェックアウトします。私たちは、参加者が与えられた事実と意見のプロファイルを遵守するように対話に徹底的にラベルを付け、この点で一般的な品質を見つけますは高い
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br>2020-03-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Collective Embedding-based Entity Alignment via Adaptive Features -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/cs.CL/paper_6.html">
      Collective Embedding-based Entity Alignment via Adaptive Features
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      EAの集合的な決定を行うために、EAを従来の安定したマッチング問題として定式化します。この問題は、遅延受け入れアルゴリズムによってさらに効果的に解決されます。 -アートソリューション、および実証結果はその有効性と優位性を検証します。このギャップを埋めるために、私たちは集団的EAフレームワークを提案します。 
[要旨]まず、構造的、意味的、文字列の信号を含む3つの代表的な機能を採用します。EAを満たすために、現在のソリューションではエンティティを個別に扱い、エンティティ間の相互依存性を考慮に入れていません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br>2019-12-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Investigating Language Impact in Bilingual Approaches for Computational
  Language Documentation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/cs.CL/paper_7.html">
      Investigating Language Impact in Bilingual Approaches for Computational
  Language Documentation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの結果は、翻訳のための言語の選択が単語セグメンテーションのパフォーマンスに影響を及ぼし、異なるレキシコンが異なるアラインメントされた翻訳を使用して学習されることを強調しています。（2018）。最後に、この論文は、境界手がかりを組み合わせて、バイリンガルの単語セグメンテーションのためのハイブリッドアプローチを提案しますGodard et al。からの注意深い単語セグメンテーションニューラルモデルでノンパラメトリックベイジアンモデル（Goldwater et al。、2009a）から抽出。 
[要約]マス多言語音声コーパスを使用して、56の対訳ペアを作成します。この結果は、ニューラルモデルの入力表現に手がかりを組み込むと、作業が増えることを示唆しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br>2020-03-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Empirical Analysis of Zipf's Law, Power Law, and Lognormal Distributions
  in Medical Discharge Reports -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/cs.CL/paper_8.html">
      Empirical Analysis of Zipf's Law, Power Law, and Lognormal Distributions
  in Medical Discharge Reports
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は、放電レポートが打ち切られたべき乗則と対数正規分布に最も適していることを示しています。ベイジアンモデリングと統計テキスト分析は、情報に基づく事前確率に基づいて適切なソリューションを促進します。データへの法則分布、および代替分布（対数正規、指数、拡大指数、打ち切りべき乗則）がデータに優れているかどうかをテストしました。 
[要約]医学的退院レポートのテキストがzipfの法則に従うかどうかを分析します。zipfの法則は、単語の頻度が離散べき法則の分布に従う言語の一般的に想定される統計的特性です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br>2020-03-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Attend to the beginning: A study on using bidirectional attention for
  extractive summarization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/cs.CL/paper_9.html">
      Attend to the beginning: A study on using bidirectional attention for
  extractive summarization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      評価は、双方向の注意を使用して導入文に注意を払うと、より一般的な形式のテキストデータに適用した場合でも、抽出要約モデルのパフォーマンスが向上することを示しました。さらに、この仮説が他の一般的な形式のテキストデータに拡張可能かどうかを調査しました。以降、要約手法では、このような違いを利用し、ディスカッションデータの構造的性質から利益を得ることができるモデルを作成する必要があります。 
[ABSTRACT]分析は、一般的な情報をどのように活用すべきかを示しています。これは、一般的な機密データの最初の数文に注意を払うことで、テキストの早い段階で重要な情報を紹介する傾向があるためであると言います
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-09">
        <br>2020-02-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Making Metadata Fit for Next Generation Language Technology Platforms:
  The Metadata Schema of the European Language Grid -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/cs.CL/paper_10.html">
      Making Metadata Fit for Next Generation Language Technology Platforms:
  The Metadata Schema of the European Language Grid
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ）、および関連エンティティ（たとえば、組織、プロジェクト、サポートドキュメントなど）です。このスキーマは、ヨーロッパの業界関連言語テクノロジの主要なハブおよび市場になることを目的とするEuropean Language Gridプラットフォームを強化します。このホワイトペーパーでは、言語リソースとテクノロジ（処理と生成のサービスとツール、モデル、コーパス、用語リストなど）の説明に対応する豊富なメタデータスキーマであるELG-SHAREを紹介します。
[要約]関連する設定で、メタデータがこのようなデジタル資産の管理、共有、使用のための主要コンポーネント。この設定では、追跡はこれらのデジタル資産の管理、共有、使用を容易にする重要な要素です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br>2020-03-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: European Language Grid: An Overview -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/cs.CL/paper_11.html">
      European Language Grid: An Overview
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ELGはスケーラブルなクラウドプラットフォームであり、統合された方法で、実行中のツールやサービス、データセットやリソースなど、ヨーロッパのすべての言語で数百の商用および非商用のLTにアクセスできます。ビジネスは何百もの中小企業と少数の大規模プレーヤーによって支配されています。多くは世界クラスであり、テクノロジーはグローバルプレーヤーよりも優れています。 
[ABSTRACT]ヨーロッパのltビジネスは、何百もの中小企業と少数の大規模なプレーヤーによって支配されています。24のナショナルコンピテンスセンターとヨーロッパのlt council（elg）により、elgは何百もの商用、非商用、非言語対応の言語へのアクセスを提供します。また、アウトリーチと調整のために、32の国家コンピテンスセンター（nccs）とeu委員会（elc）を設置します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br>2020-03-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning Contextualized Sentence Representations for Document-Level
  Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/cs.CL/paper_12.html">
      Learning Contextualized Sentence Representations for Document-Level
  Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      中国語-英語および英語-ドイツ語の翻訳の実験では、どちらの方法でも、ドキュメントレベルの強力なTransformerベースラインよりも翻訳品質を大幅に向上できることが示されています。NMTモデルを適用してソースコンテキストを予測することで、モデルに「コンテキスト化された」ソースを学習させたいソース側のドキュメントレベルの依存関係をキャプチャする文の表現。さらに、このような文脈化された文の埋め込みをNMTに学習および統合する2つの異なる方法を提案します。NMTモデルをソースコンテキスト予測モデルと事前に共同でトレーニングする共同トレーニング方法-大規模なモノリンガルドキュメントコーパスでソースコンテキスト予測モデルを事前トレーニングし、NMTモデルで微調整するトレーニングと微調整の方法。 
[要旨]文間の依存関係をモデル化する新しいフレームワークを提案します。ニューラル機械翻訳をトレーニングすることにより、ソース文にターゲットの文脈化された文の埋め込みを学習できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br>2020-03-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: InterBERT: Vision-and-Language Interaction for Multi-modal Pretraining -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/cs.CL/paper_13.html">
      InterBERT: Vision-and-Language Interaction for Multi-modal Pretraining
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      マスクセグメントモデリング（MSM）、マスク領域モデリング（MRM）、イメージテキストマッチング（ITM）を含む3つの事前トレーニングタスクでモデルを事前トレーニングします。一連のビジョンと言語のダウンストリームタスクでモデルを微調整します。単一ストリームの相互作用モジュールは複数のモダリティの情報を効果的に処理でき、上部の2ストリームモジュールは各モダリティの独立性を維持してパフォーマンスを回避しますシングルモーダルタスクでのダウングレード..私たちは、中国最大の電子商取引プラットフォームであるモバイル淘宝網からの3.1M画像-テキストペアの提案されたデータセットで中国InterBERTを事前トレーニングします。 
[要約]マルチモーダル事前トレーニングは、最初の中国マルチモーダル事前トレーニング済みモデルです。中国モデルは、異なるモダリティの情報フロー間の相互作用をモデル化できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br>2020-03-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: How human judgment impairs automated deception detection performance -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/cs.CL/paper_14.html">
      How human judgment impairs automated deception detection performance
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      背景：詐欺の検出はセキュリティの専門家にとって一般的な問題です。ハイブリッド調整条件は、検出のパフォーマンスを欺くことはありませんでした。それらは、完全にそれを無効にするか（ハイブリッド無効条件）、または特定の境界内で調整することができます（ハイブリッド調整条件） 。 
[要約]データは、どちらのハイブリッド条件でも、人間の判断が意味のある貢献を加えなかったことを示唆しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br>2020-03-30
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: GPVAD: Towards noise robust voice activity detection via weakly
  supervised sound event detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/eess.AS/paper_0.html">
      GPVAD: Towards noise robust voice activity detection via weakly
  supervised sound event detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      データの要求がはるかに少ない場合でも、単純なバイナリクリップレベルのGPV-Bモデルは、実際のシナリオでVAD-Cに匹敵するパフォーマンスを達成できます。2つのGPVADモデルとCRNNベースの標準VADモデル（VAD -C）3つの異なる評価プロトコル（クリーン、合成ノイズ、リアル）。従来の音声アクティビティ検出（VAD）メソッドは、クリーンで制御されたシナリオでうまく機能し、実際のアプリケーションではパフォーマンスが大幅に低下します。 
[要旨]データとフレームレベルのラベルを消去するには、世界で最も監視されているVADトレーニングが必要です。2つのフレームワークを提案します。1つはgpv -fからフルで、すべての可能なクリップと1つのバイナリ（gpv-b）を生成し、分割のみを行います。スピーチとノイズ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-27">
        <br>2020-03-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Reducing the Latency of End-to-End Streaming Speech Recognition Models
  with a Scout Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/eess.AS/paper_1.html">
      Reducing the Latency of End-to-End Streaming Speech Recognition Models
  with a Scout Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのモデルは、Librispeechのテストクリーンデータセットとテストその他データセットでわずか6億3900万秒の遅延で最高のパフォーマンス（2.7 / 6.4 WER）を達成します。注意ベースのトランスフォーマーモデルは、音声認識（SR）の有望な結果を達成しました。このペーパーでは、スカウトネットワークと認識ネットワークで構成される、変圧器モデルの新しい低遅延ストリーミングアプローチを提案します。 
[ABSTRACT]スカウトネットワークは、将来のフレームを確認せずに単語の境界全体を検出します。モデルは通常、認識の精度を維持するためにかなりのレイテンシが発生します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-23">
        <br>2020-03-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Audiogmenter: a MATLAB Toolbox for Audio Data Augmentation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/eess.AS/paper_2.html">
      Audiogmenter: a MATLAB Toolbox for Audio Data Augmentation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちは、その有用性が文献で広く証明されているいくつかの拡張技術を効率的に実装しました。ツールボックスとそのドキュメントは、https：//github.com/LorisNanni/Audiogmenter ..からダウンロードできます。生のオーディオデータ用に15種類の拡張アルゴリズムとスペクトログラムは8。 
[ABSTRACT] audiogmenterは、matgmenterの新しいオーディオデータ拡張ライブラリです。複数の拡張技術を効率的に実装し、その有用性は文献で広く証明されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-11">
        <br>2019-12-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Deep Residual Neural Networks for Image in Speech Steganography -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/eess.AS/paper_3.html">
      Deep Residual Neural Networks for Image in Speech Steganography
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      知覚的損失なしに有限長音声セグメント内にソースRGB画像メッセージを隠すディープラーニングベースの手法を提案します。また、提案されたアルゴリズムの将来の改善についても説明します。これを達成するために、3つのニューラルネットワークをトレーニングします。キャリアにメッセージを隠すためのエンコーディングネットワーク、キャリアからメッセージを再構築するためのデコーディングネットワーク、および再構築されたメッセージをさらに改善するための追加のイメージエンハンサーネットワーク。 
[要約]ディープラーニングベースの技術が知覚的な損失なしに画像メッセージを隠すために提案されています。キャリアを変更することなく、秘密のメッセージ内の情報の損失を最小限に抑えて行われます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br>2020-03-30
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Body temperature maintenance acclimates in a winter-tenacious songbird -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-31/biorxiv.physiology/paper_0.html">
      Body temperature maintenance acclimates in a winter-tenacious songbird
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      冷順応鳥は、体温調節を改善するために、発熱（サミット代謝率の増加）と熱保存（コンダクタンスの減少）の両方に関連する特性を調整しました。対照的に、コンダクタンスへの変化は、9週間の寒冷曝露後にのみ発生しました。鳥が熱的手がかりに応答して体温調節戦略を調整する能力を示し、鳥が複数の応答を組み合わせて環境の特定の要求を満たすことができることを明らかにします。 
[要約]体温を維持する機能は実験中に改善され続けましたが、この改善の根底にあるメカニズムは時間とともに変化しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br>2020-03-30
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
