<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-02-05の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Acoustic anomaly detection via latent regularized gaussian mixture
  generative adversarial networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.SD/paper_0.html">
      Acoustic anomaly detection via latent regularized gaussian mixture
  generative adversarial networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験は、我々のモデルが以前の方法に対して明確な優位性を持ち、DCASEデータセットで最先端の結果を達成することを示しています。さらに、トレーニング目的であらゆる種類の異常または未知のサンプルを収集することは非現実的で時間がかかります。検出は、異常な音響信号と正常な音響信号を区別することを目的としています。 
[要約]半教師あり学習フレームワークの下で提案されるガウス混合は不明
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-04">
        <br>2020-02-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Audio-Visual Calibration with Polynomial Regression for 2-D Projection
  Using SVD-PHAT -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.SD/paper_1.html">
      Audio-Visual Calibration with Polynomial Regression for 2-D Projection
  Using SVD-PHAT
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      低コストのマイクアレイと市販のカメラを使用して、多項式回帰が非線形カメラの歪みを効率的に処理できること、およびリアルタイム処理用に最近提案された音源定位方法SVD-PHATを示します。本論文では、音響画像を生成して光学画像の上に重ねることにより、カメラの視野をアレイマイクの聴覚領域で空間的に較正する簡単な2次元法を提案します。 
[概要]低コストのマイクフィールドとカメラのアレイを使用して、音響が非線形カメラの歪みを効率的に処理できることを示します。リアルタイム処理のための最近提案された音源定位法svd-phatは、このタスクに適合
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-04">
        <br>2020-02-04
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Towards Graph Representation Learning in Emergent Communication -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.CL/paper_0.html">
      Towards Graph Representation Learning in Emergent Communication
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      出現した通信プロトコルが堅牢であること、エージェントがゲームの変動の真の要因を明らかにすること、トレーニング中に遭遇するサンプルを超えて一般化することを学習することを示します。画像ベースの参照ゲームによって動機付けられ、複雑さの度合いが異なるグラフ参照ゲームを提案し、言語の出現と協力の観点から望ましい特性を示す強力なベースラインモデルを提供します。 。 
[要約]コミュニケーションをとるために、エンティティの複雑な表現を単一の単語または文にフラット化します。言語の出現と協力に関して望ましい特性を示す強力なベースラインモデルを提供します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-24">
        <br>2020-01-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Semantics-aware BERT for Language Understanding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.CL/paper_1.html">
      Semantics-aware BERT for Language Understanding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SemBERTは、BERT前駆体の便利な使いやすさを、タスク固有の大幅な変更なしに、微調整する方法で維持します。新しい最先端技術を取得するか、10の読解および言語推論タスクの結果を大幅に改善します。言語表現に豊富なセマンティクスを提供できる構造化セマンティック情報を組み込むことを検討してください。 
[要約]既存の言語表現モデルにはelmo、gpt、およびbertが含まれます。文字や単語の埋め込みなどの10個の定義のみを利用します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-05">
        <br>2019-09-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CoVoST: A Diverse Multilingual Speech-To-Text Translation Corpus -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.CL/paper_2.html">
      CoVoST: A Diverse Multilingual Speech-To-Text Translation Corpus
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、CCライセンスの下でTatoebaから派生した追加の評価データも提供します。データセット作成方法を説明し、データの品質の経験的証拠を提供します。CoVoSTはCC0ライセンスの下でリリースされ、無料で使用できます。 
[ABSTRACT]英語をソース言語とする言語ペア、非常に特定のドメインを含む、またはリソースが少ない
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-04">
        <br>2020-02-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Fake News Detection by means of Uncertainty Weighted Causal Graphs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.CL/paper_3.html">
      Fake News Detection by means of Uncertainty Weighted Causal Graphs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      現在のシステムでは、コンテキストに依存せずにこの情報を分類できる自動手順を設計するのは複雑であるため、このタスクの実行が困難になります。ソーシャルネットワークなどの新しい情報チャネルでは、必ずしも信頼に値するとは限らないニュースを人々が共有できるため、社会は情報消費の変化を実験しています。 
[要約]情報を偽物として検出および分類できるシステムを設計することが望ましい。このシステムは、重み付けされた因果グラフに基づく分類器を使用して取得できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-04">
        <br>2020-02-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Visual Concept-Metaconcept Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.CL/paper_4.html">
      Visual Concept-Metaconcept Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      赤と緑がオブジェクトの同じ特性を表すことを知って、立方体と球体もオブジェクトの同じ特性を表すという事実に一般化します。どちらもオブジェクトの形状を分類するためです。視覚入力からの緑;紫の立方体のほんの数例から、それらの形ではなく立方体の色相に似た紫の新しい色を理解することができます。 
[要約]画像と関連する質問からの概念とメタ概念の共同学習のための視覚概念-メタ概念学習者（vcml）を提案します。視覚表現は、目に見えない財産間の関係を予測するための基礎的な手がかりを提供します限られた、ノイズの多い、さらには偏ったデータ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-04">
        <br>2020-02-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Dynamic Knowledge Routing Network For Target-Guided Open-Domain
  Conversation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.CL/paper_5.html">
      Dynamic Knowledge Routing Network For Target-Guided Open-Domain
  Conversation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      より正確なキーワード予測の助けを借りて、私たちのキーワード拡張応答検索モジュールは、より良い検索パフォーマンスとより意味のある会話を達成することができます。次の談話の次のトピックの予測。これにより、移行の滑らかさが悪くなり、成功率が低くなります。 
[要約]既存の方法は、主に候補トピック間の意味的知識関係を考慮せずに、単一の対話または単純なターゲット-ガイド付き戦略に依存します。これらには、候補レベルのキーワード間の学習および知識関係によるスムーズな会話遷移が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-04">
        <br>2020-02-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Compositional Languages Emerge in a Neural Iterated Learning Model -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.CL/paper_6.html">
      Compositional Languages Emerge in a Neural Iterated Learning Model
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      NILの確率モデルと、構成言語の利点が存在する理由の説明を提供します。実際、これらの言語は、トレーニング中にニューラルエージェントに学習速度の利点を提供し、NILによって段階的に増幅できます。相互作用する神経エージェントに適用されると、より構造化されたタイプの言語の出現を促進する効果的な神経反復学習（NIL）アルゴリズム。 
[ABSTRACT] composedalは言語の自然な性質であり、言語ゲームの神経エージェントによって作成される通信プロトコルに現れることが期待される場合があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-04">
        <br>2020-02-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Iterative Data Programming for Expanding Text Classification Corpora -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.CL/paper_7.html">
      Iterative Data Programming for Expanding Text Classification Corpora
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      反復データプログラミング手法は、より多くのラベル付きデータがヒューマンインループで確認されるため、新しい弱モデルを改善します。実際のテキスト分類タスクでは、多くのラベル付きトレーニングサンプルが必要です。最小限の監督で近傍ベースの弱いモデルを生成することにより、テキストデータセットを増強する方法。 
[概要]これは、機械教育、特にデータプログラミングツールの最新のイノベーションです。これは、弱関数（ラベリング関数とも呼ばれる）の構築と、アンサンブル学習手法によるノイズ除去を含みます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-04">
        <br>2020-02-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Path-Based Contextualization of Knowledge Graphs for Textual Entailment -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.CL/paper_8.html">
      Path-Based Contextualization of Knowledge Graphs for Textual Entailment
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      コストをカスタマイズした外部ナレッジグラフでパスを見つけ、pとhを接続する最も関連性の高いサブグラフを構築することに方法論の基礎を置いています。サブグラフを生成するパス選択メカニズムは、ノイズを削減するだけでなく、大きなナレッジグラフから意味のある情報を取得することを示します。このペーパーでは、ナレッジグラフのコンテキスト化の問題、つまり特定のNLPタスクを紹介します。 、特定のナレッジグラフから意味のある関連するサブグラフを抽出する問題。私たちの評価では、エンティティに関する情報とエンティティ間の関係を使用すると、純粋にテキストベースのシステムのパフォーマンスが向上することがわかります。 
[要旨]この論文の場合の課題は文学的含意問題であり、文脈は例の関連サブグラフです。私たちの研究は、エンティティに関する情報とエンティティ間の関係を改善することを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-05">
        <br>2019-11-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploring Structural Inductive Biases in Emergent Communication -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.CL/paper_9.html">
      Exploring Structural Inductive Biases in Emergent Communication
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      地形の類似性と一般化によって測定された入力概念の組成的理解の出現に対する構造的誘導バイアス（単語、シーケンス、グラフ）の効果を、見慣れた特性の目に見えない組み合わせと比較します。データは、出現した通信プロトコルの構成性に影響を与えることがわかった。したがって、マルチエージェント通信におけるさまざまな構造上の優先事項を調査し、新しいグラフ参照ゲームを提案する。 
[要旨]創発的コミュニケーションの最近の研究では、人工的なエージェントが協力的な参照ゲームをプレイすることで体系的に構成された言語を開発する傾向について議論しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-04">
        <br>2020-02-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Semantic Search of Memes on Twitter -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.CL/paper_10.html">
      Semantic Search of Memes on Twitter
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      評価された方法のいくつかは効果的ですが、まだ改善の余地があります。また、テキストクエリを使用してデータセットからミームを取得するためのシステムを実装できる方法を提案します。チリのTwitterユーザーから収集されたミームのデータセット。専門家グループが注釈を付けました。 
[概要]この論文では、画像を自動的にミームとして分類するいくつかの方法を提案し、比較しています。チリのツイッターユーザーから収集されたミームの大規模なデータセットを使用して、
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-04">
        <br>2020-02-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Text Matters but Speech Influences: A Computational Analysis of
  Syntactic Ambiguity Resolution -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.CL/paper_11.html">
      Text Matters but Speech Influences: A Computational Analysis of
  Syntactic Ambiguity Resolution
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人間がどのように構文のあいまいさを解決するかを分析することは、言語学の分野で長い間関心のある問題でした。注意、スピーチの意図を明確にする際に著しく優れたパフォーマンスを示します。さらなる分析により、計算モデルが聴覚プロセスと言語プロセスの間の内部関係を反映していることを実証します。 
[概要]韓国語のコミュニケーションは話し言葉の重要な問題です。話し言葉の問題を克服することは重要です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-21">
        <br>2019-10-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On the interaction between supervision and self-play in emergent
  communication -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.CL/paper_12.html">
      On the interaction between supervision and self-play in emergent
  communication
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      その後、2つの環境での教師あり学習から始まるさまざまなS2Pスケジュールを経験的に調査します。シンボリック入力を使用したLewisシグナルゲームと、自然言語記述を使用した画像ベースの参照ゲームです。単一エージェント方式を超えるパフォーマンス。自然言語を使用するように人工エージェントを教えるための有望なアプローチには、ヒューマンインザループトレーニングの使用が含まれます。 
[ABSTRACT] researchは、現在の機械学習手法がデータ制御されすぎていることを示唆しています。researchは、システムがデータ制御されすぎて最初から訓練できないことを示唆しています。researchは、言語を最初から出現させるのは良くないことも示唆しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-04">
        <br>2020-02-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On Stochastic Automata over Monoids -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.CL/paper_13.html">
      On Stochastic Automata over Monoids
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      モノイド上の確率的オートマトンによって受け入れられる言語のクロージャ特性が調査されます。モノイド上の確率的オートマトンによって受け入れられる言語のクロージャ特性が調査されます。 
[ABSTRACT]拡張仮説は、無料モノイドの正当な普遍的性質を置き換えます。その鍵は、モノイドとモノイドの間の通勤財産です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-04">
        <br>2020-02-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: From Topic Networks to Distributed Cognitive Maps: Zipfian Topic
  Universes in the Area of Volunteered Geographic Information -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.CL/paper_14.html">
      From Topic Networks to Distributed Cognitive Maps: Zipfian Topic
  Universes in the Area of Volunteered Geographic Information
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このようにして、結論は次のとおりです。場所は、互いに近いかどうかに関係なく、トピック宇宙の同様のサブネットワークにまたがる近隣の場所にあります。この研究は、地理的場所（特にこの目的のために、いわゆるトピックネットワークの助けを借りて、都市または地域のレベルの場所を指すテキストをモデル化するボランティア地理情報（VGI）を探索します。 
[ABSTRACT]私たちは、ボランティアの地理情報（vgi）を探索して、いわゆるトピックネットワークの助けを借りて、都市または地域のレベルで場所を示すテキストをモデル化します。著者の基礎となるコミュニティ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-04">
        <br>2020-02-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ERNIE-GEN: An Enhanced Multi-Flow Pre-training and Fine-tuning Framework
  for Natural Language Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.CL/paper_15.html">
      ERNIE-GEN: An Enhanced Multi-Flow Pre-training and Fine-tuning Framework
  for Natural Language Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      既存の事前トレーニング方法とは異なり、ERNIE-GENはマルチグラニュラリティターゲットサンプリングを組み込んで事前トレーニングデータを構築し、エンコーダとデコーダ間の相関を強化します。生成を人間の書き込みパターンにより近づけるために、このフレームワークでは、単語ごとに予測するのではなく、意味的に完全なスパンを連続して予測するようにモデルをトレーニングするスパン生成フロー。抽象的要約（GigawordおよびCNN / DailyMail）、質問生成（SQuAD）、対話生成（Persona-Chat）、生成的質問応答（CoQA）など、さまざまな言語生成タスク。 
[要約] ernie-genは、強化されたマルチフローシーケンスで、トレーニング前と微調整済みのタスクをシーケンスします。システムは、トレーニングと結論の間の矛盾を、充填生成メカニズムとノイズ認識生成メソッドメソッドでブリッジします。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-26">
        <br>2020-01-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Variational Template Machine for Data-to-Text Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.CL/paper_16.html">
      Variational Template Machine for Data-to-Text Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このようなテンプレートを学習することは、多くの場合大きなペアを必要とするため、法外です。 <table, description>コーパスはめったに利用できません。さまざまなドメインからのデータセットの実験により、VTMは優れた流encyさと品質を維持しながら、より多様に生成できることが示されています。生成する新しい方法である変分テンプレートマシン（VTM）を提案しますデータ表からのテキスト記述。 
[概要]このシステムは、さまざまな異なるドメインのデータセットに基づいています。流andさと品質を維持しながら、より多様に生成できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-04">
        <br>2020-02-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Syntactically Look-Ahead Attention Network for Sentence Compression -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.CL/paper_17.html">
      Syntactically Look-Ahead Attention Network for Sentence Compression
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      したがって、通常、将来のタイムステップでデコードされるデコードされた単語と見えない単語の関係を明示的にキャプチャすることはできません。SLAHANは、より長い文の要約パフォーマンスも改善しました。 。 
[要約] seq2seq（seq2seq）ベースのモデルでは、デコーダーは単語を保持または削除することを決定します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-04">
        <br>2020-02-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Arabic Diacritic Recovery Using a Feature-Rich biLSTM Model -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.CL/paper_18.html">
      Arabic Diacritic Recovery Using a Feature-Rich biLSTM Model
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      アラビア語のテキストを書く場合、通常は発音区別符号（短母音）は省略され、読者は単語を正しく発音するためにそれらを再導入する必要があります。このモデルは、CWエラー率（CWER）2.86 \そして、現代標準アラビア語（MSA）の3.7％のCEエラー率（CEER）と2.2％のCWERおよび古典アラビア語（CA）の2.5％のCEER。 MSAとCAでそれぞれ6.0％と4.3％です。 
[ABSTRACT]アラビア語の発音区別符号には2つのタイプがあります。コア-単語の発音区別符号（cw）とcw.theは、語尾の末尾（ce）です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-04">
        <br>2020-02-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Plague Dot Text: Text mining and annotation of outbreak reports of the
  Third Plague Pandemic (1894-1952) -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/cs.CL/paper_19.html">
      Plague Dot Text: Text mining and annotation of outbreak reports of the
  Third Plague Pandemic (1894-1952)
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      構造化されたコーパスは、Solrを介して利用できるようになり、たとえば概念の識別に特化した将来の研究のために、コレクション全体で検索と分析が可能になります。 （OCR）テキストキャプチャを改善する方法、物語を構成し、レポート内の関連エンティティを特定するためのアプローチ。人口の疾患を管理するモデルの設計は、一般に過去の発生から収集された情報とデータに基づいています。 
[要旨]これらの物語の問題は、通常、一貫した構造または強力な慣習の欠如であり、大規模なコーパスでの正式な分析を禁止しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-04">
        <br>2020-02-04
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Acoustic anomaly detection via latent regularized gaussian mixture
  generative adversarial networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/eess.AS/paper_0.html">
      Acoustic anomaly detection via latent regularized gaussian mixture
  generative adversarial networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験は、我々のモデルが以前の方法に対して明確な優位性を持ち、DCASEデータセットで最新の結果を達成することを示しています。クラス不均衡の問題と異常なインスタンスの欠如に苦しんでいます。正常なものからの異常な音響信号。 
[要約]半教師あり学習フレームワークの下で提案されるガウス混合は不明
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-04">
        <br>2020-02-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Zero-Shot Multi-Speaker Text-To-Speech with State-of-the-art Neural
  Speaker Embeddings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/eess.AS/paper_1.html">
      Zero-Shot Multi-Speaker Text-To-Speech with State-of-the-art Neural
  Speaker Embeddings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      角度のソフトマックス損失を伴う学習可能な辞書エンコーディングベースの話者埋め込みは、話者検証タスクでのxベクトルと同等のエラー率を改善できます。また、これらの埋め込みは、エンドツーエンドの音声合成で新しいスピーカーへのゼロショット適応に使用すると、目に見えないスピーカーのスピーカーの類似性と自然さを改善します。トレーニング中に見られるスピーカーについては、見えないスピーカーへのゼロショット適応のギャップが残っています。エンドツーエンドのテキスト音声合成のマルチスピーカーモデリングを調査し、さまざまなタイプの状態の影響を調査します。見えない話者に対する話者の類似性に関する最新の神経話者埋め込み。 
[ABSTRACT]埋め込みエラーは、埋め込みの不足に起因する可能性があります。たとえば、目に見えないスピーカーの埋め込みを見つけることができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-23">
        <br>2019-10-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Text Matters but Speech Influences: A Computational Analysis of
  Syntactic Ambiguity Resolution -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/eess.AS/paper_2.html">
      Text Matters but Speech Influences: A Computational Analysis of
  Syntactic Ambiguity Resolution
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      構文的に曖昧な発話の韓国語のスクリプトに記録された音声コーパスを利用して、共同注意フレームワーク、すなわちマルチホップ注意と相互注意が、音声意図の曖昧さを取り除く際に著しく優れたパフォーマンスを示すことを明らかにしました。モデルは聴覚プロセスと言語プロセスの内部関係を反映します。構文のあいまいさが韻律とセマンティクスに関する問題と絡み合っているため、音声意図識別への計算アプローチは、人間の言語処理メカニズムの観察から恩恵を受けることが期待されます。 
[概要]韓国語のコミュニケーションは話し言葉の重要な問題です。話し言葉の問題を克服することは重要です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-21">
        <br>2019-10-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Audio-Visual Calibration with Polynomial Regression for 2-D Projection
  Using SVD-PHAT -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-05/eess.AS/paper_3.html">
      Audio-Visual Calibration with Polynomial Regression for 2-D Projection
  Using SVD-PHAT
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      低コストのマイクアレイと市販のカメラを使用して、多項式回帰が非線形カメラの歪みを効率的に処理できること、およびリアルタイム処理用に最近提案された音源定位方法SVD-PHATを示します。本論文では、音響画像を生成して光学画像の上に重ねることにより、カメラの視野をアレイマイクの聴覚領域で空間的に較正する簡単な2次元法を提案します。 
[概要]低コストのマイクフィールドとカメラのアレイを使用して、音響が非線形カメラの歪みを効率的に処理できることを示します。リアルタイム処理のための最近提案された音源定位法svd-phatは、このタスクに適合
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-04">
        <br>2020-02-04
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本日更新された論文はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br>
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
