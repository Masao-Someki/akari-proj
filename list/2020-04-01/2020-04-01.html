<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-04-01の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: A Recursive Network with Dynamic Attention for Monaural Speech
  Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/cs.SD/paper_0.html">
      A Recursive Network with Dynamic Attention for Monaural Speech
  Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      その結果、より柔軟でより良い推定を得ることができます。人は、複雑な環境下で音声に動的な注意を向ける傾向があります。主要なノイズ低減ネットワークとは別に、注意を適応的に生成する分離されたサブネットワークを設計します主要ネットワーク全体の情報フローを制御するための配布。 
[要約]音声強調の概念を使用して、音声強調の新しいシステムを作成できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-29">
        <br>2020-03-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ASR is all you need: cross-modal distillation for lip reading -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/cs.SD/paper_1.html">
      ASR is all you need: cross-modal distillation for lip reading
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは、大規模なオーディオのみのコーパスでトレーニングされた自動音声認識（ASR）モデルから抽出することで実現します。私たちの貢献は4つあります。（i）リップトレーニングにグラウンドトゥルーストランスクリプションは必要ないことを示します。読書システム; （ii）ラベル付けされていないビデオデータの任意の量を活用してパフォーマンスを向上させる方法を示します。 （iii）蒸留によりトレーニングが大幅にスピードアップすることを示します。 （iv）公開されているデータのみをトレーニングするために、挑戦的なLRS2およびLRS3データセットで最新の結果を取得します。ConnectionistTemporal Classification（CTC）とフレームを組み合わせたクロスモーダル蒸留法を使用します。 -wiseクロスエントロピー損失。 
[ABSTRACT]大規模なオーディオ-コーパスのみでトレーニングされた自動音声認識（asr）モデルから抽出
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-28">
        <br>2019-11-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Characterizing Speech Adversarial Examples Using Self-Attention U-Net
  Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/cs.SD/paper_2.html">
      Characterizing Speech Adversarial Examples Using Self-Attention U-Net
  Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ワードエラー率（WER）のASRメトリックは、勾配に基づく摂動の下では2.22 $ \％$の絶対減少があり、進化的に最適化された摂動の下では2.03 $ \％$の絶対減少があることを示しています。敵対的なトレーニングを備えた拡張モデルは、回復力のあるASRシステムをさらに安全にすることができます。最近の研究では、敵対的な例がディープニューラルネットワーク（DNN）ベースの音声認識システムに対するユビキタス脅威として強調されています。この作業では、U-Netベースの注意モデルを提示します、U-Net $ _ {At} $、敵対的な音声信号を強化するため。 
[ABSTRACT]敵対的な音声信号を強化するためにau-netベースの注意モデルを提示します。注意ネットワークによって学習された機能は、dnnベースのasrモデルの堅牢性を強化できることがわかります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br>2020-03-31
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: SPARQA: Skeleton-based Semantic Parsing for Complex Questions over
  Knowledge Bases -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/cs.CL/paper_0.html">
      SPARQA: Skeleton-based Semantic Parsing for Complex Questions over
  Knowledge Bases
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのアプローチは、いくつかのデータセットで有望なパフォーマンスを示しています。さらに、質問の構造を知識ベースの構造に合わせるために、私たちのマルチストラテジー手法は、文レベルと単語レベルのセマンティクスを組み合わせています。この専用の粗粒度形式BERTベースの解析アルゴリズムは、ダウンストリームの細粒度セマンティック解析の精度を向上させるのに役立ちます。 
[ABSTRACT]既存の質問の多くは、依存関係のような構文解析に依存しています。既存のメソッドの多くは、単純なスケルトン文法に依存しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br>2020-03-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Inherent Dependency Displacement Bias of Transition-Based Algorithms -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/cs.CL/paper_1.html">
      Inherent Dependency Displacement Bias of Transition-Based Algorithms
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      アルゴリズム固有の分布とツリーバンクの変位分布との類似性は、そのツリーバンクでのアルゴリズムの解析パフォーマンスと明確に相関していることを示しています。依存関係変位のアルゴリズム。構文関係の距離と方向の両方を定量化します。依存関係変位のより離散的な分析では、意味のある相関関係が生じないことを示す結果も得られます。 
[要約]アルゴリズムの固有の依存関係変位分布の類似性は、そのツリーバンクでのアルゴリズムの解析パフォーマンスと明らかに相関しています。ユニバーサル依存関係ツリーバンクの主文の長さには、非常に有意で実質的な相関があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br>2020-03-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Procedural Reading Comprehension with Attribute-Aware Context Flow -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/cs.CL/paper_2.html">
      Procedural Reading Comprehension with Attribute-Aware Context Flow
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、私たちのモデルは、ProParaとnpn-cookingという2つの手続き型読解データセットで最先端の結果を実現します。事前トレーニング済みの言語モデルを活用して、モデルはエンティティの属性とその遷移の同時予測により、テキストのエンティティ対応および属性対応の表現を取得します。このモデルは、以前および以下についてエンコードされた情報を活用する手続き型テキストのコンテキストエンコーディングを動的に取得します。テキストのスパンとして、または事前定義されたクラスのセットから識別できる特定の属性の遷移を予測する現在の状態。 
[ABSTRACT]手続き型読解のアルゴリズムを導入します。テキストは、プロセスをエンティティの遷移のシーケンスとして表す形式に変換されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br>2020-03-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On the Integration of LinguisticFeatures into Statistical and Neural
  Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/cs.CL/paper_3.html">
      On the Integration of LinguisticFeatures into Statistical and Neural
  Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      過度の一般化または「アルゴリズムバイアス」を神経MTの潜在的な欠点として特定し、それを残りの言語問題の多くに関連付けます。しかし、いくつかの問題は残っており、他の問題は浮上しています。自動翻訳のために欠けている言語情報を特定しますより正確な翻訳を作成し、既存のパイプラインに追加機能を統合するシステム。 
[ABSTRACT]研究により、多くの点で神経mtが統計mtを上回っていることがわかりました。これらの主張は、翻訳に関連するすべての側面の完全な分析ではサポートされていないことがよくあります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br>2020-03-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Distant Supervision and Noisy Label Learning for Low Resource Named
  Entity Recognition: A Study on Hausa and Yorùbá -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/cs.CL/paper_4.html">
      Distant Supervision and Noisy Label Learning for Low Resource Named
  Entity Recognition: A Study on Hausa and Yorùbá
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、いくつかの開発途上国で広く使用されている2つの言語であるHausaとYor \ `ub \ &#39;aの名前付きエンティティ認識を実行します。さまざまな埋め込みアプローチを評価し、現実的な低レベルで遠隔監視をうまく活用できることを示します分類子のパフォーマンスを2倍以上にできるリソースのシナリオ。これらの手法は、リソースの多い設定でうまく機能することが示されていますが、リソースの少ないシナリオでのパフォーマンスを調査したいと思います。 
[ABSTRACT]これらの手法は、高リソースの設定でうまく機能することが示されています。ただし、低モデルのシナリオでそれらがどのように機能するかを調査したい
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br>2020-03-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Low Resource Neural Machine Translation: A Benchmark for Five African
  Languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/cs.CL/paper_5.html">
      Low Resource Neural Machine Translation: A Benchmark for Five African
  Languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ベースラインの単一言語ペアのNMTモデルを半教師あり学習、転移学習、および多言語モデリングと比較する私たちの評価では、En-LRL方向とLRL-En方向の両方で大幅なパフォーマンスの改善が見られます。各モデルの一般化機能を示すために、また、マルチドメインテストセットの結果も報告します。平均BLEUスコアに関して、多言語アプローチでは、10の翻訳方向のうち6つで最大+5ポイントの最大のゲインが示されます。 
[要約]スタディはen-lrlおよびlrl-en方向の改善を示しています。マルチドメインテストセットの結果も示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br>2020-03-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Large-scale Pretraining for Visual Dialog: A Simple State-of-the-Art
  Baseline -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/cs.CL/paper_6.html">
      Large-scale Pretraining for Visual Dialog: A Simple State-of-the-Art
  Baseline
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの最高の単一モデルは、以前に公開された作業（モデルアンサンブルを含む）よりもNDCGとMRRで絶対1％以上優れています。これは、密であることが原因である2つの主要なメトリック（NDCGとMRR）間のトレードオフを強調しています注釈は、質問に対する元の真実の回答とうまく相関していません。私たちのモデルは、概念キャプションと視覚的質問応答データセットで事前トレーニングされ、VisDialで微調整されています。 
[ABSTRACT]これに先立ち、関連するビジョン-言語データセットの事前トレーニングを活用するアプローチを提示します。私たちのモデルは、概念的なキャプションと視覚的な質問応答データセットに事前トレーニングされ、visdialで微調整されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-05">
        <br>2019-12-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday
  Tasks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/cs.CL/paper_7.html">
      ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday
  Tasks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ALFREDタスクは、シーケンスの長さ、アクションスペース、言語の点で、既存のビジョンと言語のタスクデータセットよりも複雑です。最近の具体化されたビジョンと言語のタスクに基づくベースラインモデルは、ALFREDでうまく機能しないことを示し、このベンチマークと革新的なグラウンディングされた視覚言語理解モデルを開発するための重要な余地があります。 
[ABSTRACT] alfredには、元に戻せない状態変化を伴う、長くて構成的なタスクが含まれます。これらのディレクティブには、「マグカップを洗い流してコーヒーメーカーに入れる」が含まれています。シーケンスの長さ、アクションスペース、および言語の点でより複雑です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-03">
        <br>2019-12-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Appraisal Theories for Emotion Classification in Text -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/cs.CL/paper_8.html">
      Appraisal Theories for Emotion Classification in Text
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの結果は、イベントの説明における高品質の評価次元の割り当てが、離散的な感情カテゴリの分類の改善につながることを示しています。したがって、自動分類アプローチでは、イベントの特性を潜在変数として学習する必要があります（たとえば、この論文では、イベントの認知的評価の理論に従い、イベントのそのような解釈を明確にし、分類モデルにエンコードされたときに感情分類の可能性を示すことを提案します。 
[ABSTRACT]これらのイベントの解釈は、paul ek ek ekによって提案されています。これらはイベントの評価理論に基づいており、感情分類の可能性を示しています。悲しみの理論に従って、これらの解釈は嫌悪感を持って行う必要があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br>2020-03-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: MULTEXT-East -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/cs.CL/paper_9.html">
      MULTEXT-East
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      並列コーパス、George Orwellによる小説 &quot;1984&quot;は文で整列され、手作業で検証された形態統語的記述と補題が含まれています。このデータセットは広範囲に文書化されており、研究目的で自由に利用できます。リソースはXMLで均一にエンコードされ、テキストエンコーディングイニシアチブガイドライン、TEI P5、および16言語をカバー：ブルガリア語、クロアチア語、チェコ語、英語、エストニア語、ハンガリー語、マケドニア語、ペルシア語、ポーランド語、レジアン語、ルーマニア語、ロシア語、セルビア語、スロバキア語、スロベニア語、ウクライナ語。 
[要約]マルチテキスト-東のデータセットには、ワシベースの形態統語仕様、形態統語語彙、および注釈付き多言語コーパスが含まれます。リソースには、ブルガリア語、チェコ語、英語、エストニア語、ハンガリー語、スロバキア語、ウクライナ語の16言語が含まれます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br>2020-03-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Characterizing Speech Adversarial Examples Using Self-Attention U-Net
  Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/cs.CL/paper_10.html">
      Characterizing Speech Adversarial Examples Using Self-Attention U-Net
  Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近の研究では、敵対的な例がディープニューラルネットワーク（DNN）ベースの音声認識システムに対するユビキタス脅威として強調されています。この作業では、敵対関係を強化するU-Netベースの注意モデルU-Net $ _ {At} $を提示します。音声信号..私たちの実験は、提案されたU-Net $ _ {At} $が音声品質（PESQ）の知覚評価を1.13から2.78に、音声伝送インデックス（STI）を0.65から0.75に改善し、短期的な客観的了解度を示しています。 （STOI）0.83から0.96まで、敵対的な音声サンプルを使用した音声強調のタスク。 
[ABSTRACT]敵対的な音声信号を強化するためにau-netベースの注意モデルを提示します。注意ネットワークによって学習された機能は、dnnベースのasrモデルの堅牢性を強化できることがわかります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br>2020-03-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Understanding Cross-Lingual Syntactic Transfer in Multilingual Recurrent
  Neural Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/cs.CL/paper_11.html">
      Understanding Cross-Lingual Syntactic Transfer in Multilingual Recurrent
  Neural Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      言語モデルを関連言語に公開しても、ターゲット言語の文法知識が必ずしも向上するわけではなく、字句意味変換の最適条件が構文変換に最適でない場合があります。多言語トレーニングは、主に字句表現スペース、または純粋に文法的な知識の共有も可能にしますか？現在、最新のニューラル言語モデルは、基盤となるアーキテクチャを変更することなく、複数の言語で同時に正常にトレーニングできることが確立されており、さまざまなNLPモデルを低リソース言語に簡単に適合させることができます。 
[要約]このホワイトペーパーでは、さまざまな形式のクロスリンガル転送を分析します。さまざまなモデルとプロービングタスクを使用して、その最も決定的な要因を探します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br>2020-03-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Evaluating Amharic Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/cs.CL/paper_12.html">
      Evaluating Amharic Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      BLEUスコアの結果は、アムハラ語の翻訳の結果は有望であるがまだ低いことを示しています。このホワイトペーパーでは、アムハラ語のMTシステムの品質を自動的に評価するためのデータセットを開発して共有します。このデータセットがアムハラ語MTシステムを評価するためのベンチマークとして、学界と産業界の両方の研究コミュニティ。 
[ABSTRACT]多くの低リソース言語では、mtはまだ活発に研究されています。amharicmtはamharic mtシステムを評価するためのベンチマークです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br>2020-03-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Graph Enhanced Representation Learning for News Recommendation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/cs.CL/paper_13.html">
      Graph Enhanced Representation Learning for News Recommendation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ニュース表現の場合、最初にトランスフォーマーアーキテクチャを利用して、ニュースセマンティック表現を構築します。オンラインニュースの急増に伴い、オンラインニュースプラットフォームでは、ユーザーが興味深い情報を見つけるのに役立つパーソナライズされたニュースの推奨がますます重要になります。ここで、ニュースの推奨方法を提案します。グラフ設定で関連性をモデル化することにより、ユーザーとニュースの表現学習を強化できます。 
[ABSTRACT]既存のニュース推奨方法は、ニュースとの直接のやり取りから正確なニュース表現を構築することにより、パーソナライゼーションを実現します。グラフ表現ネットワークを介して、ニュース表現とグラフ内の重要なニュースの情報を組み合わせます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br>2020-03-31
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Monaural Speech Enhancement Using Deep Multi-Branch Residual Network
  with 1-D Causal Dilated Convolutions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/eess.AS/paper_0.html">
      Monaural Speech Enhancement Using Deep Multi-Branch Residual Network
  with 1-D Causal Dilated Convolutions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      MB-ResNetは、低い計算複雑度で強力な表現力を得ることが期待される分割変換集計設計を利用します。長い短期記憶（LSTM）モデルは、その高い計算複雑度と爆発/消失勾配問題によって制限されます..私たちの広範な実験的調査は、MB-ResNetsが、優れたパラメータ効率を提供しながら、音声明瞭度と品質の点で、残余または高密度の集約を採用する残余の長期短期メモリネットワーク（ResLSTM）およびCNNネットワークよりも優れていることを示唆しています。 
[ABSTRACT]マルチブランチ残差ネットワーク（mb-resnet）の長期的な改善は、長期的な効果を取り込む能力によって制限されます。たたみ込みニューラルネットワーク（cnn）、resnetの組み合わせは、受容野を拡張し、非常に長期間の時間的コンテキスト情報のキャプチャ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-27">
        <br>2019-12-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Recursive Network with Dynamic Attention for Monaural Speech
  Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/eess.AS/paper_1.html">
      A Recursive Network with Dynamic Attention for Monaural Speech
  Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      その結果、より柔軟でより良い推定値を得ることができます。主要なノイズ低減ネットワークとは別に、主要なネットワーク全体の情報フローを制御する注意分布を適応的に生成する分離されたサブネットワークを設計します。 TIMITコーパスに関する実験。 
[要約]音声強調の概念を使用して、音声強調の新しいシステムを作成できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-29">
        <br>2020-03-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ASR is all you need: cross-modal distillation for lip reading -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/eess.AS/paper_2.html">
      ASR is all you need: cross-modal distillation for lip reading
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの貢献は4つあります。（i）リップリードシステムをトレーニングするためにグラウンドトゥルーストランスクリプションは必要ないことを示します。 （ii）ラベル付けされていないビデオデータの任意の量を活用してパフォーマンスを向上させる方法を示します。 （iii）蒸留によりトレーニングが大幅にスピードアップすることを示します。 （iv）公開されているデータのみをトレーニングするために、挑戦的なLRS2およびLRS3データセットに関する最新の結果を取得します。ConnectionistTemporal Classification（CTC）とフレームを組み合わせたクロスモーダル蒸留法を使用します。 -wise cross-entropy loss ..これは、大規模なオーディオのみのコーパスでトレーニングされた自動音声認識（ASR）モデルから抽出することで実現します。 
[ABSTRACT]大規模なオーディオ-コーパスのみでトレーニングされた自動音声認識（asr）モデルから抽出
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-28">
        <br>2019-11-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Characterizing Speech Adversarial Examples Using Self-Attention U-Net
  Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/eess.AS/paper_3.html">
      Characterizing Speech Adversarial Examples Using Self-Attention U-Net
  Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近の研究では、ディープニューラルネットワーク（DNN）ベースの音声認識システムに対するユビキタスな脅威として敵対的な例が強調されています。敵対的な音声攻撃を伴う自動音声認識（ASR）タスクの実験を行います。具体的には、解釈可能なモデルによるモデルのパフォーマンスを評価します音声認識メトリックスと、拡張された敵対的トレーニングによるモデルのパフォーマンスについて話し合います。 
[ABSTRACT]敵対的な音声信号を強化するためにau-netベースの注意モデルを提示します。注意ネットワークによって学習された機能は、dnnベースのasrモデルの堅牢性を強化できることがわかります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br>2020-03-31
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Lipid Droplets in Brown Adipose Tissue Are Dispensable for Cold-Induced Thermogenesis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/biorxiv.physiology/paper_0.html">
      Lipid Droplets in Brown Adipose Tissue Are Dispensable for Cold-Induced Thermogenesis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      TGの欠如に対する明らかな適応として、BA-DGAT KOマウスの褐色脂肪細胞は、循環するグルコースと脂肪酸、および蓄えられたグリコーゲンを利用して熱発生を促進しているようです。したがって、驚くべきことに、BATのTGはその機能に不可欠ではありません。他の燃料源を利用するための改造を通じて一部。茶色の脂肪細胞は、多眼脂肪滴（LD）にトリグリセリド（TG）として代謝エネルギーを蓄えます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br>2020-03-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Induction of hyperandrogenism and insulin resistance differentially modulates ferroptosis in uterine and placental tissues of pregnant rats -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-01/biorxiv.physiology/paper_1.html">
      Induction of hyperandrogenism and insulin resistance differentially modulates ferroptosis in uterine and placental tissues of pregnant rats
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      DHTとINSに同時に曝露された子宮では、フェロトーシス関連ミトコンドリアの形態の重要な特徴である電子密度の高いクリステを伴う収縮したミトコンドリア、ならびにフェロトーシスの誘導に関与するミトコンドリアエンコード遺伝子Dpp4の発現の増加も観察されました..コントロールと比較して、DHTとINSへの同時曝露がGpx4とグルタチオン（GSH）のレベルの低下、GSH +グルタチオンジスルフィド（GSSG）とマロンジアルデヒド（MDA）の増加、フェロトーシス関連遺伝子の異常発現につながることを発見しました（ Acsl4、Tfrc、Slc7a11、およびGclc）は、鉄の沈着を増加させ、妊娠子宮でのERK / p38 / JNKリン酸化を活性化しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br>2020-03-31
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
