<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-12-02の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Performing with a Mobile Computer System for Vibraphone -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.SD/paper_0.html">
      <font color="black">Performing with a Mobile Computer System for Vibraphone</font>
    </a>
  </h2>
  <font color="black">このプロセスはビデオ録画で文書化され、民族誌的手法を使用して分析されました。モバイルコンピュータの音楽セットアップは、セットアップする時間とスペースがほとんどないパフォーマンス状況や、パフォーマンスクラスやワークショップでエレガントで便利であることが証明されました。モバイルシステムは実験を奨励し、使用されたプラットフォームはより広い聴衆との共有を可能にしました。 
[概要]このプロジェクトは、iphone、rjdj、純粋なデータ、自家製のピックアップシステムを使用して、コンピューター要素をパーカッションデュオのスイートであるnordligvinterにもたらすシステムに触発されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: The Zero Resource Speech Benchmark 2021: Metrics and baselines for
  unsupervised spoken language modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.SD/paper_1.html">
      <font color="black">The Zero Resource Speech Benchmark 2021: Metrics and baselines for
  unsupervised spoken language modeling</font>
    </a>
  </h2>
  <font color="black">新しい教師なしタスクである音声言語モデリングを紹介します。ラベルのない生の音声信号からの言語表現の学習と、ゼロリソーススピーチベンチマーク2021：の品質を調査する4つのブラックボックスのゼロショットメトリックのスイートです。音声学、レキシコン、構文、セマンティクスの4つの言語レベルで学習されたモデル。言語モデルは、学習された表現のクラスター化から派生した疑似テキストに基づいて学習します。また、テキストベースの「トップライン」と比較してパフォーマンスが低下します。同じデータでトレーニングされたシステムは、より洗練されたエンドツーエンドモデルによって探索されるスペースを示します。 
[概要]教師なしシステムのリストが言語レベルの混合で提示されました。プロジェクトは、4つのメトリックすべてで偶然の学習よりも優れており、音声言語モデリングの実現可能性を示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Perceptual Quality of Drum Transcription with the Expanded
  Groove MIDI Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.SD/paper_2.html">
      <font color="black">Improving Perceptual Quality of Drum Transcription with the Expanded
  Groove MIDI Dataset</font>
    </a>
  </h2>
  <font color="black">リスニングテストを通じて、精度やFメジャースコアなどの標準的な分類子メトリックは、生成された出力の知覚品質と完全に一致しないため、ダウンストリームタスクのパフォーマンスのプロキシとしては不十分であると主張します。ExpandedGrooveMIDIを紹介します。データセット（E-GMD）、43のドラムキットからの444時間のオーディオを含む自動ドラム転写（ADT）データセットであり、同様のデータセットよりも1桁大きく、人間が実行する速度アノテーションを備えた最初のデータセットです。 E-GMDは、表現のダイナミクス（速度）を予測することでダウンストリーム生成で使用する分類器を最適化し、分類メトリックで同様の結果が得られたにもかかわらず、知覚品質が向上した出力を生成することをリスニングテストで示します。 
[概要] e-gmdを使用して、ダウンストリームで使用する分類器を最適化します。これを使用して、表現力を予測し、リスニングテストで、知覚品質が向上した出力を生成することを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-01">
        <br><font color="black">2020-04-01</font>
      </time>
    </span>
</section>
<!-- paper0: Strike on Stage: a percussion and media performance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.SD/paper_3.html">
      <font color="black">Strike on Stage: a percussion and media performance</font>
    </a>
  </h2>
  <font color="black">大きな投影面がパフォーマーの真後ろに配置され、コンピュータービジョンシステムがパフォーマーの動きを追跡します。このペーパーでは、2010年にパーカッショニストとメディアアーティストChi-Hsiaによって開発および実行されたインターフェイスと対応するオーディオビジュアルパフォーマンス作品であるStrike onStageについて説明します。 LaiとCharlesMartin .. Strike on Stageのコンセプトは、コンピューターのビジュアルとサウンドを即興のパーカッションパフォーマンスに統合することです。 
[概要]ステージでのストライキのコンセプトは、コンピューターのビジュアルとサウンドを即興のパーカッションパフォーマンスに統合することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Ad-hoc Beamforming Based on Speaker Extraction for Target-Dependent
  Speech Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.SD/paper_4.html">
      <font color="black">Deep Ad-hoc Beamforming Based on Speaker Extraction for Target-Dependent
  Speech Separation</font>
    </a>
  </h2>
  <font color="black">アルゴリズムには3つのコンポーネントが含まれています。最初に、話者抽出に基づく教師ありチャネル選択フレームワークを提案します。ここでは、ターゲット音声の推定発話レベルSNRがチャネル選択の基礎として使用されます。アドホックマイクアレイのため複数の話者が離れた場所にいて独立して話すことができるような広い領域をカバーする可能性があります。混合音声からターゲット話者を抽出することを目的としたターゲット依存の音声分離は、アドホックアレイ内の特定の話者を抽出およびトレースするために重要です。 。 
[概要]アドホックマイクアレイは、混合音声からターゲットスピーカーを抽出することを目的としています。アドホックアレイ内の特定のスピーカーを抽出してトレースするために重要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Convolutive Transfer Function Invariant SDR training criteria for
  Multi-Channel Reverberant Speech Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.SD/paper_5.html">
      <font color="black">Convolutive Transfer Function Invariant SDR training criteria for
  Multi-Channel Reverberant Speech Separation</font>
    </a>
  </h2>
  <font color="black">これはよく知られている評価指標（BSS Eval）ですが、これまでトレーニングの目的として使用されたことはありません。時間領域のトレーニング基準は、単一チャネルの非残響音声混合物の分離に非常に効果的であることが証明されています。ここでは、ニューラルネットワークでサポートされているマルチチャネルソース分離を時間領域トレーニング目的関数と組み合わせることを提案します。 
[概要] librispeechベースの残響混合物でのパフォーマンスを実証しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: MTM Dataset for Joint Representation Learning among Sheet Music, Lyrics,
  and Musical Audio? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.SD/paper_6.html">
      <font color="black">MTM Dataset for Joint Representation Learning among Sheet Music, Lyrics,
  and Musical Audio?</font>
    </a>
  </h2>
  <font color="black">MTMデータセットコレクションの目標は、音符を楽譜と音楽オーディオに拡張することで制約を克服し、データセットを使用してマルチモーダル音楽データ全体の共同表現を学習できるように、音符と音節のきめ細かい配置を構築することです。 3つ以上のモダリティを含む大規模なデータセットの可用性が限られているため、3つのモダリティ間のクロスモーダル検索のジョイント表現の学習は制限されています。ジョイントを学習するためにグループによって作成された音楽Ternary Modalities Dataset（MTMデータセット）を紹介します。 3種類のクロスモーダル検索を含む、音楽情報検索（MIR）における3つのモダリティの音楽間の表現。 
[概要] mtmデータセットは、事前にトレーニングされたモデルによって構築された3つのモダリティを提供します。データセットと使用例はwwwで入手できます。 github。 com</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: A Unified Deep Speaker Embedding Framework for Mixed-Bandwidth Speech
  Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.SD/paper_7.html">
      <font color="black">A Unified Deep Speaker Embedding Framework for Mixed-Bandwidth Speech
  Data</font>
    </a>
  </h2>
  <font color="black">狭帯域スペクトログラムを広帯域スペクトログラムのサブイメージと見なし、画像分類の方法で混合帯域幅データの共同モデリング問題に取り組みます。この観点から、さまざまなトレーニングの下でいくつかの混合帯域幅共同トレーニング戦略を詳しく説明します。テストデータシナリオ..VoxCeleb1データセットで広範な実験的研究を実施します。 
[概要]提案されたシステムは、単一のスピーカー埋め込みモデルで混合帯域幅データを処理できる可能性があります。提案されたアプローチの有効性は、sitwおよびnist sre2016データセットによって検証されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Tracking Ensemble Performance on Touch-Screens with Gesture
  Classification and Transition Matrices -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.SD/paper_8.html">
      <font color="black">Tracking Ensemble Performance on Touch-Screens with Gesture
  Classification and Transition Matrices</font>
    </a>
  </h2>
  <font color="black">システムについて説明し、相互検証、プロファイリング、コンサートの経験を通じて評価します。システムは、ランダムフォレスト分類子を使用して、タッチスクリーンジェスチャと遷移マトリックス統計を抽出します。アンサンブル全体で結果のジェスチャ状態シーケンスを分析します。出演者の。 
[概要]システムはランダムフォレスト分類器を使用して、タッチスクリーンジェスチャと遷移行列統計を抽出します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: NHSS: A Speech and Singing Parallel Database -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.SD/paper_9.html">
      <font color="black">NHSS: A Speech and Singing Parallel Database</font>
    </a>
  </h2>
  <font color="black">この論文では、データベースの設計方法論について説明し、音声と歌声の特性の類似点と非類似点を分析し、これらの特性間の関係に対処して相互に変換するためのいくつかの戦略を提供します。NHSSデータベースのオーディオ録音10人の歌手が歌って話した100曲に対応し、合計7時間の音声データが得られます。このデータベースは、英語のポップソングの歌声の録音で構成されています。これは、歌手が読んだ曲の歌詞の音声版です。自然な読み方、および手動で準備された発話レベルと単語レベルの注釈。 
[概要] nhssデータベースの歌と録音の録音には合計7時間の音声データが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-artform performance using networked interfaces: Last Man to Die's
  Vital LMTD -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.SD/paper_10.html">
      <font color="black">Cross-artform performance using networked interfaces: Last Man to Die's
  Vital LMTD</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、コンピュータービジョンサーフェスとネットワーク化された心拍センサーの芸術的な動機と設計、および最初の主要な作品であるVital LMTDのマウントの経験について説明します。2009年、クロスアートフォームグループのLast Man toDieが一連のパフォーマンスを発表しました。新しいインターフェースとネットワーク化されたパフォーマンスを使用して、メンバーの3つのアートフォーム（俳優、ハンナコーミック、ビジュアルアーティスト、ベンジャミンフォースター、パーカッショニスト、チャールズマーティン）を統合します。 
[概要]この論文では、コンピュータービジョンサーフェスやハートビートセンサーの設計など、その芸術的な動機について説明しています。また、最初の主要な作業である重要なlmtdのマウントの経験についても概説しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: On hallucinations in tomographic image reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.IV/paper_0.html">
      <font color="black">On hallucinations in tomographic image reconstruction</font>
    </a>
  </h2>
  <font color="black">不正確な事前情報は、再構成された画像で誤った構造が幻覚を起こす可能性があり、それが医用画像で深刻な懸念の原因となります。 ..提案された形式の下でのさまざまな再構成方法の動作は、数値研究の助けを借りて説明されています。 
[概要]これらの問題は通常、求められているオブジェクトの事前知識を使用して正規化されます。深いネットワークと、外部にあるデータに一般化する能力はまだ調査中です。これらの深いネットワークによって学習された以前の情報の分析はまだ検討中です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: CycleGAN without checkerboard artifacts for counter-forensics of
  fake-image detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.IV/paper_1.html">
      <font color="black">CycleGAN without checkerboard artifacts for counter-forensics of
  fake-image detection</font>
    </a>
  </h2>
  <font color="black">ほとんどの最先端の偽造検出方法は、画像にDNNを使用して生成されたチェッカーボードアーティファクトが含まれていることを前提としています。したがって、偽のメイジ検出方法のカウンターフォレンジックのために、チェッカーボードアーティファクトのない新しいCycleGANを初めて提案します。 、チェッカーボードアーティファクトのないGANの例として..画像操作ツールやGenerative Adversarial Networks（GAN）などの深い画像合成技術の最近の急速な進歩により、偽の画像が簡単に生成されるため、操作された画像の検出が緊急の問題になっています。 
[概要]画像操作ツールと深い画像合成技術の最近の進歩により、偽の画像が簡単に生成されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: An Attention Mechanism with Multiple Knowledge Sources for COVID-19
  Detection from CT Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.IV/paper_2.html">
      <font color="black">An Attention Mechanism with Multiple Knowledge Sources for COVID-19
  Detection from CT Images</font>
    </a>
  </h2>
  <font color="black">具体的には、学習されたネットワークから抽出された感染領域とヒートマップは、学習プロセス中に注意メカニズムを介してグローバル画像と統合されます。この手順により、システムがノイズに対してより堅牢になるだけでなく、局所的な病変領域に焦点を当てたネットワークがガイドされます。広範な実験は、最近のベースラインと比較して、私たちのアプローチの優れたパフォーマンスを示しています。 
[概要] covid-19の早期診断は時期尚早である可能性があります。これらのアプローチは主に、新しいアーキテクチャの導入、学習手法の伝達、または大規模データの構築に焦点を当てています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-23">
        <br><font color="black">2020-09-23</font>
      </time>
    </span>
</section>
<!-- paper0: Overcoming the limitations of patch-based learning to detect cancer in
  whole slide images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.IV/paper_3.html">
      <font color="black">Overcoming the limitations of patch-based learning to detect cancer in
  whole slide images</font>
    </a>
  </h2>
  <font color="black">多くのデータセットは、データキュレーションバイアスに悩まされる可能性のある画像パッチで構成されています。他のデータセットはスライドレベル全体でのみラベル付けされ、画像全体に注釈がない場合、最終決定が正しい限り、誤ったローカル予測がマスクされる可能性があります。このペーパーでは、パッチまたはスライドレベルの分類と方法の違いについて概説します。スライド全体で癌を正確に特定またはセグメント化する必要があり、両方のケースでベストプラクティスが異なることを実験的に検証します。ネオアジュバント療法後の乳癌WSIにバイナリ癌検出ネットワークを適用して、癌の範囲の概要を示す腫瘍床を見つけます。 、スライド全体にわたって感度と精度を必要とするタスク。 
[概要]画像の削除は、より臨床的に関連性のあるレベルレベルレベルのワークフローでは良好なパフォーマンスに変換されない場合があります。これらの画像の多くは、詳細とコンテキストの両方をキャプチャするために複数のスケールで撮影する必要があり、極端なクラスの不均衡が存在する可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Deep Video Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.IV/paper_4.html">
      <font color="black">Unsupervised Deep Video Denoising</font>
    </a>
  </h2>
  <font color="black">ディープ畳み込みニューラルネットワーク（CNN）は、現在、ビデオのノイズ除去において最先端のパフォーマンスを実現しています。蛍光顕微鏡および電子顕微鏡データの実験は、グラウンドトゥルースクリーンデータが一般的にないイメージングモダリティに対するアプローチの可能性を示しています。利用可能です。ただし、顕微鏡などの多くのアプリケーションでは、ノイズのないビデオは利用できません。 
[概要]ネットワークは通常、監視付きでトレーニングされ、ネットワーク出力とグラウンド間のエラーを最小限に抑えます-真実のクリーンなビデオ。これはこれらのケースに対処するためのものであり、教師なし静止画像ノイズ除去の最近の進歩に基づいて、教師なしディープビデオノイズ除去装置を開発しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Advances in Crystallographic Image Processing for Scanning Probe
  Microscopy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.IV/paper_5.html">
      <font color="black">Advances in Crystallographic Image Processing for Scanning Probe
  Microscopy</font>
    </a>
  </h2>
  <font color="black">科学界では、SPMチップが顕微鏡の操作中に形状や微細構造を変化させ、それによって記録された画像を体系的に難読化できるという事実も認められています。この本の章では、結晶画像処理の進歩について概説します（技術の説明が2010年にこの本シリーズで最初に公開されて以来発生した走査型プローブ顕微鏡（SPM）用のCIP）。CIPは、そのような画像の不鮮明な情報の多くを復元します。 
[概要]多かれ少なかれ規則的な2d周期配列のあらゆる種類の実験画像の信号対雑音比が大幅に向上します。cipおよび技術は記録装置のタイプに依存しません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-26">
        <br><font color="black">2020-11-26</font>
      </time>
    </span>
</section>
<!-- paper0: Hi-UCD: A Large-scale Dataset for Urban Semantic Change Detection in
  Remote Sensing Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.IV/paper_6.html">
      <font color="black">Hi-UCD: A Large-scale Dataset for Urban Semantic Change Detection in
  Remote Sensing Imagery</font>
    </a>
  </h2>
  <font color="black">バイナリおよびマルチクラスの変更検出でいくつかの古典的な方法を使用してデータセットをベンチマークします。実験結果は、Hi-UCDが挑戦的でありながら有用であることを示しています。都市拡大の加速に伴い、都市変更検出（UCD）は、効果的なアプローチは、動的な都市分析のための地理空間オブジェクトに関する変更情報を提供できます。 
[概要]このデータセットは、空間解像度が0.1 mの航空写真を使用しています。3つの時相が含まれ、9つのクラスの土地被覆で意味的に注釈が付けられています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-06">
        <br><font color="black">2020-11-06</font>
      </time>
    </span>
</section>
<!-- paper0: Analysis on viewing angle of holographic image reconstructed from
  digital Fourier hologram in holographic display -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.IV/paper_7.html">
      <font color="black">Analysis on viewing angle of holographic image reconstructed from
  digital Fourier hologram in holographic display</font>
    </a>
  </h2>
  <font color="black">開口数（NA）を強化したデジタルフーリエホログラムから再構成したホログラフィック画像の視野角を分析します。強化NAデジタルホログラムは、ホログラムピクセルの回折角よりも大きい角度で画像を再構成します。数値シミュレーションと光学ホログラフィック画像の視野角のこの解釈を検証するために実験が行われます。 
[概要]再構成画像の視野角はデジタルホログラムのnaに依存します。naはホログラムサイズの焦点距離によって決定されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: High-resolution single-shot phase-shifting interference microscopy using
  deep neural network for quantitative phase imaging of biological samples -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.IV/paper_8.html">
      <font color="black">High-resolution single-shot phase-shifting interference microscopy using
  deep neural network for quantitative phase imaging of biological samples</font>
    </a>
  </h2>
  <font color="black">ネットワークのトレーニングは、光導波路とMG63骨肉腫細胞の2つの異なるサンプルで実行されます。ここでは、フィルター処理されたWL-PSIMとディープニューラルネットワーク（DNN）を使用した正確な位相測定のためのシングルショット位相シフト干渉法を紹介します。 ..さらに、WL-PSI + DNNフレームワークのパフォーマンスは、構造類似性指数測定（SSIM）値と、ネットワークで生成され、実験的にキャプチャされた干渉計の位相マップ比較によって検証されます。 
[概要]この方法は、1つのキャプチャされたインターフェログラムから4つの位相ガイドフレームを生成するようにdnnをトレーニングすることによって組み込まれます。dnnは、1つのキャプチャされたインターフェログラムから4つの位相ガイド3フレームを生成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Decomposition, Compression, and Synthesis (DCS)-based Video Coding: A
  Neural Exploration via Resolution-Adaptive Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.IV/paper_9.html">
      <font color="black">Decomposition, Compression, and Synthesis (DCS)-based Video Coding: A
  Neural Exploration via Resolution-Adaptive Learning</font>
    </a>
  </h2>
  <font color="black">解像度適応型合成では、TMF上に動き補償ネットワーク（MCN）が考案され、非局所テクスチャ転送ネットワーク（NL-TTN）を使用して対応するSTFと共同で処理される時間的動きの特徴を効率的に整列および集約し、空間をより適切に増強します。詳細。これにより、圧縮と解像度のリサンプリングノイズを効果的に軽減し、レート歪み効率を向上させることができます。さらに、最先端の方法とアブレーション研究との実験的比較を行って、の効率と一般化をさらに報告します。 DCSアルゴリズム、将来のビデオコーディングの有望な方向性を約束します。このような「分解、圧縮、合成（DCS）」ベースのスキームはコーデックに依存せず、現在、平均$ \ upperx $ 1 dBPSNRゲインまたは$ \ upperx $ 25％BDレート節約を例示しています。 、リファレンスソフトウェアを使用したHEVCアンカーに対して。 
[ABSTRACT]「分解、圧縮、ネットワーク」のネイティブ部分は、ネイティブ部分に触発されました。この作業は、単純に適用、リキュービックリサンプリング、および圧縮のnelです。これは、composition.methodに関連する合成部分に焦点を当てています。構成部分に注意を向けるために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Navigator-Free Submillimeter Diffusion Imaging using Multishot-encoded
  Simultaneous Multi-slice (MUSIUM) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.IV/paper_10.html">
      <font color="black">Navigator-Free Submillimeter Diffusion Imaging using Multishot-encoded
  Simultaneous Multi-slice (MUSIUM)</font>
    </a>
  </h2>
  <font color="black">超高解像度（0.86 mm等方性解像度）、全脳カバレッジ、および約12.5分の取得時間のdMRIが達成され、皮質および白質領域の詳細な構造が明らかになりました。まとめると、MUSIUMイメージングはサブミリメートル拡散イメージングを達成するための有望なアプローチです。臨床的に実行可能なスキャン時間内の3TMRスキャナーで..この作業では、3T MRスキャナーでナビゲーターフリーのマルチショットエンコード同時マルチスライス（MUSIUM）イメージングアプローチを開発し、SNRの向上、低RF電力、ピーク振幅を実現しました。スラブ境界アーティファクトがないこと。 
[概要]プロジェクトは、強化されたsnr、低rf電力、およびピーク持続時間を達成するために3,000米ドル（博物館）によって開発されました。博物館のイメージングは、動きによる影響を最小限に抑えました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Feature Fusion via Dual-resolution Compressive Measurement Matrix
  Analysis For Spectral Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.IV/paper_11.html">
      <font color="black">Feature Fusion via Dual-resolution Compressive Measurement Matrix
  Analysis For Spectral Image Classification</font>
    </a>
  </h2>
  <font color="black">ただし、これらの手法では、符号化開口パターンに埋め込まれた情報を使用して測定を並べ替える特徴抽出手順が必要です。CSIアーキテクチャはスペクトル画像の関連情報をコンパクトにキャプチャするため、圧縮サンプルから分類特徴を抽出するさまざまな方法が最近提案されています。融合問題を解決するために、乗算器の交互方向法の加速バリアント（accelerated-ADMM）に基づくアルゴリズムについて説明します。 
[要約]この論文では、スペクトル画像分類のために、デュアル解像度の圧縮測定から直接特徴を融合する方法を提案します。提案されたアプローチは、実験室でキャプチャされた3つのビーム画像と一連の圧縮形式で評価されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Crowd-Sourced Road Quality Mapping in the Developing World -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.IV/paper_12.html">
      <font color="black">Crowd-Sourced Road Quality Mapping in the Developing World</font>
    </a>
  </h2>
  <font color="black">道路の品質を評価し、ドメイン間でのディープラーニングベースの方法の移転可能性における主要な課題と機会を特定できる新しいクラウドソーシングアプローチを提示します。マッピングは、文書化が不十分で道路の量が不均衡な発展途上国で特に差し迫った課題を提示します。建設は今後数十年で行われると予想されます。道路の地理的分布とその品質の最新のマッピングは、土地利用計画から荒野保全に至るまでの影響の大きいアプリケーションで不可欠です。 
[ABSTRACT]開発途上国では道路インフラが整備されています。今後数十年で道路建設が行われると予想されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Adversarial Networks for Spatio-temporal Data: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.IV/paper_13.html">
      <font color="black">Generative Adversarial Networks for Spatio-temporal Data: A Survey</font>
    </a>
  </h2>
  <font color="black">時空間データで人気のあるGANアーキテクチャと、GANを使用した時空間アプリケーションのパフォーマンスを評価するための一般的な方法を要約します。コンピュータビジョンでのGANに関するいくつかのレビューが提示されましたが、空間に関連する実用的なアプリケーションと課題に取り組むことを検討した人は誰もいません。 -時間的データ..最後に、この分野に関心のある研究者に利益をもたらすことを期待して、将来の方向性を指摘します。 
[ABSTRACT] ganベースの手法は、軌道予測、イベント生成、時系列データ補完などのアプリケーションに有望であることが示されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-18">
        <br><font color="black">2020-08-18</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Globally Optimal Relative Pose Estimation with Gravity Prior -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_0.html">
      <font color="black">Globally Optimal Relative Pose Estimation with Gravity Prior</font>
    </a>
  </h2>
  <font color="black">合計50000の画像ペア..また、回転の1次近似を使用して高速ソルバーが提案されます。エピポーラ制約に基づいて、最適化問題を2つの未知数のみを持つ2つの多項式の解法に変換します。 
[概要]提案されたモデルは、4つの実世界のデータセットの状態-ofus（im）モデルと比較されます。4つのデータセットのモデルの数と比較されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: LPMNet: Latent Part Modification and Generation for 3D Point Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_1.html">
      <font color="black">LPMNet: Latent Part Modification and Generation for 3D Point Clouds</font>
    </a>
  </h2>
  <font color="black">実験は、さまざまなオブジェクトカテゴリとさまざまなポイント数で提案された方法の堅牢性を示しています。この全体論的アプローチは、パーツ表現を学習するためのパーツベースのトレーニングを必要とせず、標準の再構成損失以外に余分な損失を導入しません。 GANやVAEなどの生成モデルを統合することで新しいモデルを生成でき、セグメンテーションモジュールを統合することで注釈のない点群を処理できます。 
[概要]このメソッドは、zativeモデルを統合することで新しいモデルを生成できます。セグメンテーションモジュールを統合することで、注釈のない点群を処理できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-08">
        <br><font color="black">2020-08-08</font>
      </time>
    </span>
</section>
<!-- paper0: Point2Skeleton: Learning Skeletal Representations from Point Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_2.html">
      <font color="black">Point2Skeleton: Learning Skeletal Representations from Point Clouds</font>
    </a>
  </h2>
  <font color="black">まず、幾何学的変換を学習して骨格点のセットを予測し、次に骨格点の接続性を分析して骨格メッシュ構造を形成します。広範な評価と比較により、この方法が優れたパフォーマンスと堅牢性を備えていることがわかります。重要なアイデアは、元の入力ポイントの固有の幾何学的およびトポロジー的性質をキャプチャするための内側軸変換（MAT）の洞察。 
[概要]最初に幾何学的変換を学習して一連の骨格点を予測します。次に、骨格点の接続性を分析して骨格メッシュ構造を形成します。新しい方法は、より顕著な骨格表現を生成することを目的としています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Ultra-low bitrate video conferencing using deep image animation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_3.html">
      <font color="black">Ultra-low bitrate video conferencing using deep image animation</font>
    </a>
  </h2>
  <font color="black">利用可能な帯域幅が極端に制限されている場合の現在のビデオ圧縮パラダイムの欠点に対処するために、ディープニューラルネットワークを使用してモーション情報をキーポイント変位としてエンコードし、デコーダー側でビデオ信号を再構築するモデルベースのアプローチを採用しています。品質評価実験は、提案されたアプローチがHEVCと比較して80％以上の同じ視覚品質の平均ビットレート削減を提供することを示しています。この作業では、ビデオ会議アプリケーションの超低ビットレートビデオ圧縮のための新しい深層学習アプローチを提案します。 
[概要]提案されたアプローチは、hevcと比較して80％以上の同じ視覚品質の平均ビットレート削減を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: LiDAR-based Panoptic Segmentation via Dynamic Shifting Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_4.html">
      <font color="black">LiDAR-based Panoptic Segmentation via Dynamic Shifting Network</font>
    </a>
  </h2>
  <font color="black">ただし、既存の作業では、いずれかのオブジェクトの解析に重点が置かれています（たとえば、自動運転の急速な進歩に伴い、センシングシステムにさらに包括的な3D知覚を装備することが重要になります。特に、DS-Netには3つの魅力的な特性があります。1）強力バックボーンデザイン。 
[概要]動的シフトネットワーク（ds-net）は、点群領域で効果的なパノラマセグメンテーションフレームワークとして機能します。主なツールは、クラウドクラウドクラウドコンピューティングに基づく動的シフトです。これを使用して、間の不一致に対処できます。セマンティックおよびインスタンスの予測</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Mitigating Face Recognition Bias via Group Adaptive Classifier -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_5.html">
      <font color="black">Mitigating Face Recognition Bias via Group Adaptive Classifier</font>
    </a>
  </h2>
  <font color="black">導入された自動適応戦略は、人口統計適応パラメータ間の非類似度を繰り返し計算することにより、特定のレイヤーに適応を適用するかどうかを決定します。提案されたグループ適応分類器は、人口統計属性に基づいて、適応畳み込みカーネルと顔の注意メカニズムを使用してバイアスを軽減します。適応モジュールは、識別のために異なる顔の領域をアクティブ化するように、各人口統計グループのカーネルマスクとチャネルごとの注意マップで構成され、人口統計に関連するより識別力のある機能につながります。 
[概要]人口統計グループ間の平均クラス内距離のギャップを緩和するために、新しいデバイアス損失関数が提案されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-13">
        <br><font color="black">2020-06-13</font>
      </time>
    </span>
</section>
<!-- paper0: A Unified Structure for Efficient RGB and RGB-D Salient Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_6.html">
      <font color="black">A Unified Structure for Efficient RGB and RGB-D Salient Object Detection</font>
    </a>
  </h2>
  <font color="black">CRACEモジュールを備えたシンプルな統合機能ピラミッドネットワーク（FPN）のような構造は、顕著性と境界のマルチレベルの監視の下で結果を伝達および改善します。実験結果は、私たちの方法が両方で他の最先端の方法よりも優れていることを示していますさまざまなデータセットで、ほとんどのメトリックの観点から、RGBおよびRGB-DSODタスク。提案された構造はシンプルでありながら効果的です。 RGBと深度の豊富なコンテキスト情報を適切に抽出し、提案された構造によって効率的に融合することができます。 
[概要]提案されたクレースモジュールは、2つ（crgbの場合）または3つ（rgb-d sodの場合）を受け取り、適切に融合します。統合された構造は、特別に設計する必要があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Sim2Real for Self-Supervised Monocular Depth and Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_7.html">
      <font color="black">Sim2Real for Self-Supervised Monocular Depth and Segmentation</font>
    </a>
  </h2>
  <font color="black">シミュレーションドメインでペアのグラウンドトゥルースデータのみを使用することで、このアーキテクチャは深度マップやセグメンテーションマップなどの知覚タスクを生成する可能性があります。共有潜在空間と補助デコーダーを備えたツインVAEベースのアーキテクチャが実ドメインでペアのグラウンドトゥルースデータを必要とせずにsim2realギャップを埋めます。ドメイン適応の最近の進歩は、共有潜在空間の仮定がシミュレーションと実ドメイン間のギャップを埋めるのに役立ち、シミュレーションドメインから実ドメインへのネットワークの予測機能。 
[ABSTRACT]シミュレーション空間でトレーニングされたネットワークは、実ドメインの画像に適用すると適切に機能しません。ネットワークは、渦巻いた実データを必要とせずにsim2realギャップを埋めることができる必要があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Low Bandwidth Video-Chat Compression using Deep Generative Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_8.html">
      <font color="black">Low Bandwidth Video-Chat Compression using Deep Generative Models</font>
    </a>
  </h2>
  <font color="black">このアプローチにより、現在利用可能な代替手段よりも1桁低い、毎秒数キロビットでのビデオ通話が可能になります。さらに、SPADEブロックを活用して、目や唇などの重要な領域の結果を改善します。モバイル対応を設計します。 Siarohinらの一次アニメーションモデルに基づくアーキテクチャ。 
[概要]ネットワークはスマートフォンにワイヤレスで接続するように設計されています。これらのネットワークはリアルタイムで表示できるネットワーク上に構築されています。ネットワークを約3MBに圧縮し、iPhone8でモデルやビデオを使用できるようにします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Manifold Transformation for Dimension Reduction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_9.html">
      <font color="black">Deep Manifold Transformation for Dimension Reduction</font>
    </a>
  </h2>
  <font color="black">継続戦略は、マニフォールド学習アルゴリズムで一般的な極小問題に対処するためにトレーニング中に適用されます。このような学習済みDMTネットワークは、目に見えないデータに一般化できますが、従来のマニフォールド学習方法では、トレーニングデータの埋め込みのみが提供されます。広範な実験、比較、およびアブレーション研究は、DMTがUMAPやt-SNE、およびその他の主要なマニフォールドベースのNLDRメソッドよりも優れた結果を提供できることを示しています。 
[概要]システムは、データ内の対象のパターンまたは多様体を、より低い空間潜在空間の領域に変換します。下部になると、umapやt-sne、およびその他の主要な織りに基づくよりも優れた結果を提供できます。 nldrメソッド</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Input Bias in Rectified Gradients and Modified Saliency Maps -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_10.html">
      <font color="black">Input Bias in Rectified Gradients and Modified Saliency Maps</font>
    </a>
  </h2>
  <font color="black">したがって、一連の顕著性メソッドは、分類または潜在的な概念に大きな影響を与える入力特徴を識別する直感的な方法を提供します。スケーリングされた画像でも、入力バイアスはカラースペクトルの人工的なポイントの周りに存在します。特定の場合には視覚的に一貫しています。 、Rectified Gradientsおよびその他の変更された顕著性マップは、入力機能の不適切な使用のために、強い入力バイアス（たとえば、RGB空間の明るさ）を導入します。 
[概要]顕著性マップはさまざまな顕著性機能に依存しています。顕著性マップへの変更が「ノイズ除去」に導入されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Enabling Fingerprint Presentation Attacks: Fake Fingerprint Fabrication
  Techniques and Recognition Performance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_11.html">
      <font color="black">Enabling Fingerprint Presentation Attacks: Fake Fingerprint Fabrication
  Techniques and Recognition Performance</font>
    </a>
  </h2>
  <font color="black">この作業では、偽の指紋表現を使用したプレゼンテーション攻撃に対する感受性に関して、光学、光学マルチスペクトル、パッシブ容量性、アクティブ容量性、熱を含む、さまざまなセンシング技術に基づいた5つの異なる市販の指紋スキャナーを評価します。偽の表現を作成するために、ワックス、キャスト、ラテックス、シリコーン、さまざまな種類の接着剤、ウィンドウの色、モデリングクレイなどを含め、テストおよび評価されます。定量的評価には、偽の表現からキャプチャされたサンプルの指紋品質の評価が含まれます。対応する実際の指紋に対する偽の表現の達成された一致スコアが偽の表現の有効性を示す比較実験と同様に。 
[概要]プレゼンテーション攻撃検出テクノロジーは、指紋スキャナーデバイスに直接統合されることがよくありますが、多くの指紋スキャナーは、物理的な偽の指紋表現を使用したプレゼンテーション攻撃の影響を受けやすくなっています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Robust and Accurate Object Velocity Detection by Stereo Camera for
  Autonomous Driving -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_12.html">
      <font color="black">Robust and Accurate Object Velocity Detection by Stereo Camera for
  Autonomous Driving</font>
    </a>
  </h2>
  <font color="black">自動車メーカーSUBARUが20年以上にわたって収集した大規模なデータセットをもとに、カメラで物体の速度を正確に検出する手法を開発しました。評価は、測定装置と定量的に可能なテストコースを用いて行いました。開発したステレオカメラを実車に搭載することで過酷な環境を再現する。提案手法は、複数のステレオ視差画像を融合するハイダイナミックレンジ（HDR）検出手法、単眼とステレオの結果を融合する融合手法の3つの手法で構成されている。認識、および新しい速度計算方法。 
[概要]提案された方法は、融合システムとしてレーダーを使用することを含みます。現在、それを使用するためにレーダーを使用することはまだ一般的です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Generating Unobserved Alternatives -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_13.html">
      <font color="black">Generating Unobserved Alternatives</font>
    </a>
  </h2>
  <font color="black">その結果、観測された出力とは異なる高品質の出力を生成するために使用できます。複数の予測が正しいと見なすことができる問題を検討しますが、監視として与えられるのはそのうちの1つだけです。回帰法と現在の設定に対する条件付き生成モデルは、多くの場合、入力ごとに1つの予測しかできないモデルになります。 
[要約]モデルは、同じ入力が与えられた場合に複数の高品質の予測を生成できます。また、複数の高品質の予測を生成することもできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Robustness Out of the Box: Compositional Representations Naturally
  Defend Against Black-Box Patch Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_14.html">
      <font color="black">Robustness Out of the Box: Compositional Representations Naturally
  Defend Against Black-Box Patch Attacks</font>
    </a>
  </h2>
  <font color="black">第二に、自然閉塞に対する生来のロバスト性につながるパーツベースの表現を持つ構成的ディープネットワークは、敵対的なトレーニングなしで、PASCAL3D +およびドイツの交通標識認識ベンチマークに対するパッチ攻撃に対してロバストであることがわかります。さらに、構成的ロバスト性モデルは、敵対的に訓練された標準モデルよりも大幅に優れています。パーツベースの微調整を導入することでこの制限を克服し、きめ細かい認識を向上させます。 
[ABSTRACT]敵対的トレーニングはパッチ攻撃に対する効果が限られていますが、構成モデルの堅牢性は敵対的モデルの堅牢性を上回っています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Multiclass non-Adversarial Image Synthesis, with Application to
  Classification from Very Small Sample -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_15.html">
      <font color="black">Multiclass non-Adversarial Image Synthesis, with Application to
  Classification from Very Small Sample</font>
    </a>
  </h2>
  <font color="black">この作業では、新しい非敵対的生成手法である潜在空間のクラスター最適化（COLA）を紹介します。これは、GANの制限の一部を克服し、トレーニングデータが不足している場合にGANを上回ります。完全なデータレジームでは、この手法は次のようになります。監視なしで多様なマルチクラス画像を生成でき、画質と多様性の点で以前の非敵対的方法を上回ります。ラベル付き画像の小さなサンプルのみがトレーニングに利用可能であり、アクセスできない小規模データ体制では追加のラベルなしデータにより、私たちの結果は、同じ量のデータでトレーニングされた最先端のGANモデルを上回ります。 
[ABSTRACT]新しい方法は、監視なしで多様なマルチクラス画像を生成することができます。完全なデータ体制では、小規模なサンプル分類タスクで最先端のパフォーマンスを上回ります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Unpaired Image-to-Image Translation via Latent Energy Transport -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_16.html">
      <font color="black">Unpaired Image-to-Image Translation via Latent Energy Transport</font>
    </a>
  </h2>
  <font color="black">この単純化されたソリューションは、片側のペアリングされていない画像変換設定の効率も大幅に向上させます。私たちの知る限り、このモデルは、1024 $ \ times $ 1024の解像度のペアリングされていない画像変換に最初に適用できます。論文では、このタスクのために事前にトレーニングされたオートエンコーダの潜在空間にエネルギーベースのモデル（EBM）を展開することを提案します。 
[概要]潜在的なebmは、コンテンツコードを保持しながら、ソーススタイルコードをターゲットスタイルコードに転送することを違法に学習する可能性があります。これは、既存の画像翻訳方法よりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: How to fine-tune deep neural networks in few-shot learning? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_17.html">
      <font color="black">How to fine-tune deep neural networks in few-shot learning?</font>
    </a>
  </h2>
  <font color="black">したがって、本論文では実験的比較を通じて深層モデルを微調整する方法を研究する。さらに、モデルの重みを分析して微調整法の実現可能性を検証する。深層モデルの微調整は簡単であり、効果的な数ショットの学習方法。 
[概要]少数の-ショット学習が少数のトレーニングサンプルで新しいタスクに一般化できることが証明されています。微調整-実験的比較を通じて深層学習モデルを調整します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: CycleGAN without checkerboard artifacts for counter-forensics of
  fake-image detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_18.html">
      <font color="black">CycleGAN without checkerboard artifacts for counter-forensics of
  fake-image detection</font>
    </a>
  </h2>
  <font color="black">ほとんどの最先端の偽造検出方法は、画像にDNNを使用して生成された市松模様のアーティファクトが含まれていることを前提としています。 、チェッカーボードアーティファクトのないGANの例として..この論文では、偽の画像検出のカウンターフォレンジックのためのチェッカーボードアーティファクトのない新しいCycleGANを提案します。 
[概要]画像操作ツールと深い画像合成技術の最近の進歩により、偽の画像が簡単に生成されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Benchmarking Image Retrieval for Visual Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_19.html">
      <font color="black">Benchmarking Image Retrieval for Visual Localization</font>
    </a>
  </h2>
  <font color="black">これは、ローカリゼーションタスク用に特別に設計された検索アプローチの必要性を示しています。このペーパーでは、複数の視覚的ローカリゼーションタスクの画像検索の役割を理解することに焦点を当てています。自律走行や拡張現実など。 
[概要]この論文は、複数の視覚的ローカリゼーションタスクのローカリゼーションの役割に焦点を当てています。古典的なランドマーク検索/認識タスクの検索パフォーマンスは、すべてではなく一部のタスクでのみローカリゼーションパフォーマンスに相関することを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Semantic Segmentation By Dense Fusion Network On Blurred VHR
  Remote Sensing Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_20.html">
      <font color="black">Robust Semantic Segmentation By Dense Fusion Network On Blurred VHR
  Remote Sensing Images</font>
    </a>
  </h2>
  <font color="black">この論文では、NIR、RGB、DSMなどのマルチモダリティデータを使用して、ぼやけた、または部分的に損傷したVHRリモートセンシング画像のセグメンテーションの堅牢性を高めることを提案します。影、天候の乱れ、手ぶれなど、この問題を大きく引き起こすいくつかの要因特にRGB画像のみを使用する場合は困難です。カスケードされた高密度エンコーダ-デコーダネットワークとSELayerベースの融合および組み立て技術を提案することにより、提案されたRobustDenseNetは、最先端と比較して、画質が低下しているときに安定したパフォーマンスを実現します。セマンティックセグメンテーションモデル。 
[概要]提案されたロバストデンスネットは、画質が低下しているときに安定した使用を実現します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-03-07">
        <br><font color="black">2019-03-07</font>
      </time>
    </span>
</section>
<!-- paper0: Lossy Event Compression based on Image-derived Quad Trees and Poisson
  Disk Sampling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_21.html">
      <font color="black">Lossy Event Compression based on Image-derived Quad Trees and Poisson
  Disk Sampling</font>
    </a>
  </h2>
  <font color="black">平均して、私たちのアルゴリズムは、最先端技術と比較して6倍以上の圧縮を達成します。この問題に対処するために、隣接する強度画像から導出された四分木（QT）セグメンテーションマップに基づく新しいイベント圧縮アルゴリズムを提案します。イベントのエンコードステップでは、イベントは最初に時間の経過とともに集約され、極性ベースのイベントヒストグラムが形成されます。 
[概要]イベント圧縮アルゴリズムのパフォーマンスは、満足のいく実用的なものとはほど遠いものです。たとえば、パフォーマンスはパフォーマンスの同等化と同等です。問題は、イベントが熱変動のみをエンコードするため、空間マップが不足しているためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-03">
        <br><font color="black">2020-05-03</font>
      </time>
    </span>
</section>
<!-- paper0: An Attention Mechanism with Multiple Knowledge Sources for COVID-19
  Detection from CT Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_22.html">
      <font color="black">An Attention Mechanism with Multiple Knowledge Sources for COVID-19
  Detection from CT Images</font>
    </a>
  </h2>
  <font color="black">この手順により、システムがノイズに対してより堅牢になるだけでなく、局所的な病変領域に焦点を当てたネットワークがガイドされます。具体的には、学習されたネットワークから抽出された感染領域とヒートマップが、学習プロセス中に注意メカニズムを介してグローバル画像と統合されます。最近、CTスキャンに基づくCOVID-19診断にディープネットワークを利用する取り組みが増えています。 
[概要] covid-19の早期診断は時期尚早である可能性があります。これらのアプローチは主に、新しいアーキテクチャの導入、学習手法の伝達、または大規模データの構築に焦点を当てています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-23">
        <br><font color="black">2020-09-23</font>
      </time>
    </span>
</section>
<!-- paper0: Demographic Influences on Contemporary Art with Unsupervised Style
  Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_23.html">
      <font color="black">Demographic Influences on Contemporary Art with Unsupervised Style
  Embeddings</font>
    </a>
  </h2>
  <font color="black">contempArtは、絵画やデッサンのコレクション、Instagramのソーシャルコネクションに基づく詳細なグラフネットワーク、および追加の社会人口統計情報です。キャリアの初期にはすべて442人のアーティストに愛着を持っていました。視覚的なスタイルと社会的近接性、性別、国籍との間に関連性は見られません。教師なしスタイルの画像の埋め込みを生成するのに適した3つの方法を評価します。それらを残りのデータと相関させます。 
[ABSTRACT]現代アートワークの新しいデータセットであるcontempartは、contempartとcontempartのコラボレーションです。contempartは、現代アートワークのみのマルチモーダルデータセットです。データセットは、世界中のデータを含むネットワークからのデータに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-30">
        <br><font color="black">2020-09-30</font>
      </time>
    </span>
</section>
<!-- paper0: Revisiting Unsupervised Meta-Learning: Amplifying or Compensating for
  the Characteristics of Few-Shot Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_24.html">
      <font color="black">Revisiting Unsupervised Meta-Learning: Amplifying or Compensating for
  the Characteristics of Few-Shot Tasks</font>
    </a>
  </h2>
  <font color="black">変更されたベースラインに基づいて、UMLモデルをトレーニングするときに、タスクの特性をさらに増幅または補正します。最初に、混合埋め込みを組み込んで、数ショットのタスクの難易度を上げます。次に、タスク固有の埋め込み変換を利用します。タスク間の特定のプロパティを処理し、バニラ埋め込みへの一般化機能を維持します。 
[ABSTRACT]埋め込みの誘導バイアスは、十分なラベルの付いた例が設定された基本クラスから学習されます。次に、新しいクラスを使用した少数のショットタスクに一般化します。少数のショットの学習ベンチマークでの実験は、アプローチが以前のumlメソッドよりも4〜10優れていることを証明します。 ％パフォーマンスギャップ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Pre-Trained Image Processing Transformer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_25.html">
      <font color="black">Pre-Trained Image Processing Transformer</font>
    </a>
  </h2>
  <font color="black">IPTモデルは、マルチヘッドとマルチテールを使用してこれらの画像でトレーニングされます。さらに、さまざまな画像処理タスクにうまく適応するために対照学習が導入されています。最新のハードウェアの計算能力が大幅に向上するにつれて、事前トレーニングが行われます。大規模なデータセットで学習された深層学習モデル（\ eg、BERT、GPT-3）は、従来の方法よりも効果的であることが示されています。 
[ABSTRACT] iptは、さまざまな低レベルのベンチマークで現在の最先端の手法を上回っています。事前にトレーニングされたモデルが1つしかないため、iptは新しいタイプのベンチマークを上回ります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Overcoming the limitations of patch-based learning to detect cancer in
  whole slide images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_26.html">
      <font color="black">Overcoming the limitations of patch-based learning to detect cancer in
  whole slide images</font>
    </a>
  </h2>
  <font color="black">術前補助療法後の乳がんWSIにバイナリがん検出ネットワークを適用して、がんの範囲の概要を示す腫瘍床を見つけます。これは、スライド全体で感度と精度が必要なタスクです。多くのデータセットは、データキュレーションに苦しむ可能性のある画像パッチで構成されています。バイアス;他のデータセットはスライドレベル全体でのみラベル付けされ、画像全体に注釈がない場合、最終決定が正しい限り、誤ったローカル予測がマスクされる可能性があります。ただし、メソッドがチャレンジタスクで高いスコアを獲得したとしても、この成功は、より臨床的に関連性のあるワークフローでの良好なパフォーマンスにつながるとは限りません。 
[概要]画像の削除は、より臨床的に関連性のあるレベルレベルレベルのワークフローでは良好なパフォーマンスに変換されない場合があります。これらの画像の多くは、詳細とコンテキストの両方をキャプチャするために複数のスケールで撮影する必要があり、極端なクラスの不均衡が存在する可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Deep Video Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_27.html">
      <font color="black">Unsupervised Deep Video Denoising</font>
    </a>
  </h2>
  <font color="black">蛍光顕微鏡および電子顕微鏡データの実験は、グラウンドトゥルースクリーンデータが一般的に利用できないイメージングモダリティに対する私たちのアプローチの可能性を示しています。さらに、訓練されたCNNがビデオノイズ除去を実行するために使用するメカニズムを研究します。単一の短いノイズの多いビデオシーケンスでのみトレーニングされた場合でも、ベンチマークデータセットで現在の最先端の監視された方法と競争力を持って実行することが示されています。 
[概要]ネットワークは通常、監視付きでトレーニングされ、ネットワーク出力とグラウンド間のエラーを最小限に抑えます-真実のクリーンなビデオ。これはこれらのケースに対処するためのものであり、教師なし静止画像ノイズ除去の最近の進歩に基づいて、教師なしディープビデオノイズ除去装置を開発しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Invariant Representation Learning for Infant Pose Estimation with Small
  Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_28.html">
      <font color="black">Invariant Representation Learning for Infant Pose Estimation with Small
  Data</font>
    </a>
  </h2>
  <font color="black">私たちのFiDIPモデルは、幼児の姿勢推定のための最先端の人間の姿勢推定モデルよりも優れており、平均平均精度（AP）は90.1と高いことを示しました。幼児の動きの分析は、初期の発達において非常に重要なトピックです。研究..これらの知識を微調整されたドメイン適応幼児ポーズ（FiDIP）推定モデルに徐々に転送するための多段階トレーニング戦略を紹介します。 
[ABSTRACT]モデルのパフォーマンスは、独特の動きをする幼児など、新しい被写体やポーズを含むアプリケーションでは大幅に低下します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Automated Quality Assessment of Hand Washing Using Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_29.html">
      <font color="black">Automated Quality Assessment of Hand Washing Using Deep Learning</font>
    </a>
  </h2>
  <font color="black">最後に、ニューラルネットワークを使用して、医療専門家向けの自動品質管理とリアルタイムフィードバック用の携帯電話アプリケーションを構築する方法について説明します。大規模な（2000以上のビデオ）実世界の一部でニューラルネットワークをトレーニングします。さまざまな洗浄動作でラベル付けされたデータセット..予備的な結果は、タスクにMobileNetV2やXceptionなどの事前トレーニング済みニューラルネットワークモデルを使用すると、さまざまな洗浄動作の認識で64％を超える精度を達成できることを示しています。 
[概要]大規模な（2000本のビデオ）実世界のラベル付けされた動きの一部でニューラルネットワークをトレーニングし、さまざまな洗浄動作を行います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Disentangling Label Distribution for Long-tailed Visual Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_30.html">
      <font color="black">Disentangling Label Distribution for Long-tailed Visual Recognition</font>
    </a>
  </h2>
  <font color="black">この方法は、ベンチマークデータセットの最先端の方法を上回っていますが、トレーニングフェーズでモデル予測からソースラベルの分布を直接解くことにより、さらに改善できます。このようなプロトコルは、ターゲットも長い可能性があるため、実用性に疑問があります。 -tailed ..したがって、ターゲットとソースのラベル分布が異なるラベルシフト問題として、ロングテール視覚認識を定式化します。 
[概要]ラベルシフトの問題は、ソースソースラベル分布とモデル予測の間の絡み合いです。ドンスカーの最適な境界に基づくラベル分布のもつれを解く（lade）損失-バラダン表現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Structured Context Enhancement Network for Mouse Pose Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_31.html">
      <font color="black">Structured Context Enhancement Network for Mouse Pose Estimation</font>
    </a>
  </h2>
  <font color="black">次に、CMLSモジュールは、マルチレベル情報を生成することにより、提案されたSCMと砂時計ネットワークを共同でトレーニングするように設計されます。これにより、ネットワーク全体の堅牢性が向上します。この論文では、新しい砂時計ネットワークベースのモデル、つまりグラフィカルモデルを提案します。 2つの効果的なモジュール、すなわち構造化コンテキストミキサー（SCM）とカスケードマルチレベル監視モジュール（CMLS）が設計されているベースの構造化コンテキスト拡張ネットワーク（GM-SCENet）。ただし、深層学習ベースの方法は、マウスまたはその他の分野で有望な進歩を遂げています。動物のポーズの推定では、複雑なシナリオ（オクルージョン、目に見えないキーポイント、異常なポーズなど）を適切に処理できません。 【概要】マウス本体の変形性が高い場合、マウス本体のキーポイントを正確に特定することは大きな課題です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Open Source 3-D Filament Diameter Sensor for Recycling, Winding and
  Additive Manufacturing Machines -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_32.html">
      <font color="black">Open Source 3-D Filament Diameter Sensor for Recycling, Winding and
  Additive Manufacturing Machines</font>
    </a>
  </h2>
  <font color="black">開発された方法は、製造コミュニティのためのプラスチックリサイクル技術のより大きな可用性を保証し、複合材料の作成の成長を刺激します。リサイクルされた3Dプリンターフィラメントの直径の多軸光学制御のためのモジュラーシステムは、分析を可能にします処理されたフィラメントの表面構造、スプールの全長に沿った測定の履歴を保存し、欠陥のある領域をマークします。分散リサイクルおよび積層造形でプラスチック廃棄物を3D印刷フィラメントにアップサイクリングするという課題を克服します。システム、この研究では、リサイクルおよび巻線機用のオープンソースの3Dフィラメント直径センサーを設計、構築、テスト、および検証します。 
[概要]直径センサーは、さまざまな種類のポリマー（プラのabs）、さまざまなプラスチックの供給源、および透明なプラスチックを含むさまざまな色でテストされました。その結果、システムにより、ユーザーはより正確な直径測定のために、さらにはリサイクルされたフィラメント表面の詳細な分析</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Discover Multi-Class Attentional Regions for Multi-Label
  Image Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_33.html">
      <font color="black">Learning to Discover Multi-Class Attentional Regions for Multi-Label
  Image Recognition</font>
    </a>
  </h2>
  <font color="black">さらに、提案された方法の有効性は、グローバルプーリング戦略、入力サイズ、ネットワークアーキテクチャなどのさまざまな要因の下で広く実証されています。私たちの方法は、手頃な計算コストとパラメータのない領域でマルチクラスオブジェクトを効率的かつ効果的に認識できます。ローカリゼーションモジュール..グローバルストリームとローカルストリームの間のギャップを埋めるために、注意領域の数をできるだけ少なくし、これらの領域の多様性をできるだけ高く保つことを目的としたマルチクラス注意領域モジュールを提案します。 
[ABSTRACT]シンプルな注意領域モジュールは、注意領域の数をできるだけ少なくすることを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-03">
        <br><font color="black">2020-07-03</font>
      </time>
    </span>
</section>
<!-- paper0: Hi-UCD: A Large-scale Dataset for Urban Semantic Change Detection in
  Remote Sensing Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_34.html">
      <font color="black">Hi-UCD: A Large-scale Dataset for Urban Semantic Change Detection in
  Remote Sensing Imagery</font>
    </a>
  </h2>
  <font color="black">実験結果は、Hi-UCDが挑戦的でありながら有用であることを示しています。バイナリおよびマルチクラスの変化検出におけるいくつかの古典的な方法を使用して、データセットのベンチマークを行います。 3つの時間フェーズを含み、地上オブジェクトの変化の方向を取得するために、9つのクラスの土地被覆で意味的に注釈が付けられています。 
[概要]このデータセットは、空間解像度が0.1 mの航空写真を使用しています。3つの時相が含まれ、9つのクラスの土地被覆で意味的に注釈が付けられています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-06">
        <br><font color="black">2020-11-06</font>
      </time>
    </span>
</section>
<!-- paper0: Dual Pixel Exploration: Simultaneous Depth Estimation and Image
  Restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_35.html">
      <font color="black">Dual Pixel Exploration: Simultaneous Depth Estimation and Image
  Restoration</font>
    </a>
  </h2>
  <font color="black">学習のための大量のデータの要件を満たすために、既存のRGBDデータセットからDPペアを使用してデータセットを作成できる最初のDPイメージシミュレーターを提案します。これらの調査により、エンドツーエンドのDDDNet（ DPベースの深度とデブラーネットワーク）を共同で深度を推定し、画像を復元します。いくつかの作品は、DPペアをステレオペアとして扱うことにより、深度/逆深度を推定します。 
[概要]いくつかの作品は、dpペアをステレオペアとして扱うことで深度を推定します。ただし、トレーニングで深度推定を正規化するために、リブラー損失を定義します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Diverse Temporal Aggregation and Depthwise Spatiotemporal Factorization
  for Efficient Video Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_36.html">
      <font color="black">Diverse Temporal Aggregation and Depthwise Spatiotemporal Factorization
  for Efficient Video Classification</font>
    </a>
  </h2>
  <font color="black">カーネル因数分解とチャネル因数分解に触発されて、D（2 + 1）Dという名前の深さ方向の時空間因数分解モジュールも設計します。これは、ネットワークをより軽量で効率的にするために、3Dの深さ方向の畳み込みを2つの空間的および時間的な深さ方向の畳み込みに分解します。それらの間のギャップを埋めるために、VoV3Dと呼ばれる効率的な時間モデリング3Dアーキテクチャを提案します。これは、時間ワンショット集約（T-OSA）モジュールと深さ方向に因数分解されたコンポーネントD（2 + 1）Dで構成されます。 T-OSAは、異なる時間受容野を持つ時間的特徴を集約することによって特徴階層を構築するように考案されています。時間的モデリングの効率と有効性のおかげで、VoV3D-Lは6分の1のモデルパラメータと16分の1の計算を持ち、現在の状態を上回っています。 -Something-SomethingとKinetics-400の両方での最先端の時間モデリング手法。 
[概要] vov 3dに触発されたアーキテクチャは、不均衡な3dにはあまり関心がありません。この方法は、vov3dネットワークの開発に使用できます。osososは、ネットワークモデル「osos」および「os」ワイヤレスネットワークを使用できます。モデル容量を持つvov3d</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: UPFlow: Upsampling Pyramid for Unsupervised Optical Flow Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_37.html">
      <font color="black">UPFlow: Upsampling Pyramid for Unsupervised Optical Flow Learning</font>
    </a>
  </h2>
  <font color="black">特に、KITTI2012ではEPE = 1.4、KITTI2015ではF1 = 9.38％を達成しており、これは従来の方法をそれぞれ22.2％と15.7％上回っています。さらに、ピラミッド蒸留損失を提案します。疑似ラベルとして最も細かいフローを抽出することにより、中間レベルの監視を追加します。ピラミッドネットワークのアップサンプリングと学習を改善することにより、光フロー推定のための監視されていない学習アプローチを提示します。 
[概要]問題に取り組むために、自己監視型アップサンプルモジュールを設計します。この方法は、教師なしオプティカルフロー学習に最高のパフォーマンスを提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Generalize Unseen Domains via Memory-based Multi-Source
  Meta-Learning for Person Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_38.html">
      <font color="black">Learning to Generalize Unseen Domains via Memory-based Multi-Source
  Meta-Learning for Person Re-Identification</font>
    </a>
  </h2>
  <font color="black">具体的には、メタ学習戦略を導入して、ドメイン一般化のトレインテストプロセスをシミュレートし、より一般化可能なモデルを学習します。パラメトリック分類器によって引き起こされる不安定なメタ最適化を克服するために、非メモリベースの識別損失を提案します。 -パラメトリックでメタ学習と調和します。パブリックプライバシーのため、新しいドメインデータに常にアクセスできるとは限らず、これらの方法の適用範囲が制限されます。 
[概要]データにアクセスして、限られたドメイン向けに新しいモデルをトレーニングする必要があるのはこれが初めてです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: An improved helmet detection method for YOLOv3 on an unbalanced dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_39.html">
      <font color="black">An improved helmet detection method for YOLOv3 on an unbalanced dataset</font>
    </a>
  </h2>
  <font color="black">効率的な前処理により、YOLOv3の信頼水準は、YOLOv3の認識速度を変更することなく、一般に0.01〜0.02向上します。また、処理された画像は、効果的な特徴融合により、画像のローカリゼーションにおいても優れたパフォーマンスを発揮します。生産における認識速度と精度の要件..YOLOv3ターゲット検出アルゴリズムは、その高速性と高精度のために業界で広く使用されていますが、不均衡なデータセットの精度低下など、いくつかの制限があります。YOLOv3ターゲット検出アルゴリズムは、データセットを前処理し、YOLOv3ターゲット検出アルゴリズムを改善するためのガウスファジーデータ拡張アプローチに基づいています。 
[概要] yolov3ターゲット検出アルゴリズムはガウスシステムに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: BOTD: Bold Outline Text Detector -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_40.html">
      <font color="black">BOTD: Bold Outline Text Detector</font>
    </a>
  </h2>
  <font color="black">具体的には、BOTDは最初にテキストインスタンスごとにセンターマスク（CM）を生成します。これにより、粘着テキストを簡単に区別できます。テキストマスクをCMとPMDに分割することにより、任意の形状のテキストインスタンスのアウトラインを予測するだけで取得できます。そのCMとPMD ..最近、任意の形状のテキスト検出がますます検索の注目を集めています。 
[ABSTRACT] botdのf-メジャーは80.1％、ctw1500、52 fpsです。これは、任意の後処理プロセスがほとんどない、新しい1段階の検出フレームワークです。検出速度が遅く、後処理が複雑で、テキストの貼り付けがあります問題はまだ実際のアプリケーションの制限です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Farthest sampling segmentation of triangulated surfaces -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_41.html">
      <font color="black">Farthest sampling segmentation of triangulated surfaces</font>
    </a>
  </h2>
  <font color="black">さらに、サイズ$ k $を大きくすると、$ W ^ k $の行間の近接関係は、対応する$ W $の行間の近接を忠実に反映する傾向があることが示されます。提案された方法は他のセグメンテーションよりも計算コストが低くなります。アルゴリズムは、$ W $の少数の列のみを計算し、$ W $または$ W $の部分行列の固有分解を必要としないためです。列によって生成された空間への$ W $の正射影を証明します。 $ W ^ k $の正射影は、$ W ^ k $の列を$ W $のサンプルとして使用してNystr \ &quot;omの方法で計算された$ k $固有ベクトルによって生成された空間への$ W $の正射影と一致します。
[要約]提案された方法は、他のセグメンテーションアルゴリズムよりも人為的に安価です。$ w $または$の部分行列の固有分解を必要としません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: SOrT-ing VQA Models : Contrastive Gradient Learning for Improved
  Consistency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_42.html">
      <font color="black">SOrT-ing VQA Models : Contrastive Gradient Learning for Improved
  Consistency</font>
    </a>
  </h2>
  <font color="black">これに対処するために、最初に勾配ベースの解釈可能性アプローチを提示して、画像上の推論質問と最も強く相関する質問を決定し、これを使用して、推論に答えるのに必要な関連サブ質問を識別する能力についてVQAモデルを評価します。質問..SOrTが既存のベースラインよりも最大6.5％ポイントだけモデルの一貫性を改善すると同時に、視覚的根拠も改善することを示します。視覚的質問回答（VQA）の最近の研究により、最先端のモデルの一貫性が失われていることが明らかになりました。世界の理解-彼らは正しく推論を必要とする一見難しい質問に答えますが、より単純な関連するサブ質問は間違っています。 
[ABSTRACT] sub-質問vqaでは、モデルに「一貫性のない」質問をランク付けする必要があります。sub-質問は、画像内の低レベルの視覚的概念に関連します。sub-質問-qaは、モデルが同じ主題でよりランク付けする必要があることを意味します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-20">
        <br><font color="black">2020-10-20</font>
      </time>
    </span>
</section>
<!-- paper0: Rethinking Positive Aggregation and Propagation of Gradients in
  Gradient-based Saliency Methods -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_43.html">
      <font color="black">Rethinking Positive Aggregation and Propagation of Gradients in
  Gradient-based Saliency Methods</font>
    </a>
  </h2>
  <font color="black">この作業では、勾配情報を処理するための2つのアプローチ、つまり正の集約と正の伝播がこれらの方法を破ることを経験的に示します。LRP、RectGrad、ガイド付き逆伝播などの勾配情報を逆伝播する方法については、破壊的な効果を示します。正の勾配情報を排他的に伝播することの..顕著性メソッドは、その予測のための入力要素の重要性を示すことによって、神経ネットワークの予測を解釈します。 
[要約]人気のある顕著性メソッドのファミリーは、そのような情報を利用します。顕著性メソッドは、予測された出力に影響されません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Disentangled Latent Factors from Paired Data in Cross-Modal
  Retrieval: An Implicit Identifiable VAE Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_44.html">
      <font color="black">Learning Disentangled Latent Factors from Paired Data in Cross-Modal
  Retrieval: An Implicit Identifiable VAE Approach</font>
    </a>
  </h2>
  <font color="black">最近の識別可能なVAE（IVAE）モデルから動機付けられて、クエリモダリティデータを条件付け補助入力として組み込むように変更します。これにより、モデルの真のパラメーターが特定の規則性条件下で識別できることを証明できます。両方のモダリティのデータは複雑で構造化されており、高次元（画像やテキストなど）であるため、Variational Autoencoder（VAE）などの従来のディープオートエンコーディング潜在変数モデルでは、正確なデコーダートレーニングや現実的なトレーニングが困難になることがよくあります。合成..クロスモーダル検索でペアのバイモーダルデータ間で共有される根本的な解きほぐされた潜在因子を学習する問題を扱います。 
[概要]私たちのモデルは、要因を正確に特定し、従来のエンコーダー-デコーダー正則化モデルを大幅に上回っています。私たちのモデルは、要因を十分に特定し、従来のモデル-デコーダー正則化を大幅に上回っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Confluence: A Robust Non-IoU Alternative to Non-Maxima Suppression in
  Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_45.html">
      <font color="black">Confluence: A Robust Non-IoU Alternative to Non-Maxima Suppression in
  Object Detection</font>
    </a>
  </h2>
  <font color="black">Confluenceは、MSCOCOとPASCALVOC 2007の両方のデータセットを使用して、RetinaNet、YOLOv3、Mask-RCNNで実験的に検証されています。マンハッタン距離。クラスター内の他のすべての境界ボックスに最も近い境界ボックスを選択し、非常にコンフルエントな隣接ボックスを削除します。 
[要約]提案されたシステムは、せっかちな境界ボックスとは根本的に異なる理論的原則に基づいています。それは、貪欲な把握とその変形に対する事実の異なる原則に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: GLEAN: Generative Latent Bank for Large-Factor Image Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_46.html">
      <font color="black">GLEAN: Generative Latent Bank for Large-Factor Image Super-Resolution</font>
    </a>
  </h2>
  <font color="black">バンクを切り替えると、猫、建物、人間の顔、車など、さまざまなカテゴリの画像を処理できます。GLEANは、多重解像度スキップ接続を備えたシンプルなエンコーダ-バンク-デコーダアーキテクチャに簡単に組み込むことができます。事前にトレーニングされたGenerativeAdversarial Networks（GAN）、たとえばStyleGANを潜在的なバンクとして使用して、大因子画像の超解像度（SR）の復元品質を向上できることを示します。 
[ABSTRACT]私たちの方法であるgenustive潜在銀行（glean）は、豊富で多様な事前情報を直接活用することにより、既存の慣行を超えています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: A New Action Recognition Framework for Video Highlights Summarization in
  Sporting Events -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_47.html">
      <font color="black">A New Action Recognition Framework for Video Highlights Summarization in
  Sporting Events</font>
    </a>
  </h2>
  <font color="black">以前のシステムと比較して、私たちの方法論は精度にいくつかの利点を示しています。この研究は、スポーツ分野でのビデオ要約の潜在的なアプリケーションを拡張し、一致分析システムの開発を容易にする新しいクリッピングシステムとして役立つ可能性があります。この研究では、2つの古典的なオープンソース構造、つまりYOLO-v3とOpenPoseに基づく3レベルの予測アルゴリズムを使用して、スポーツビデオストリームを自動的にクリップする高精度のフレームワークを紹介します。 
[要約]調査によると、スポーツビデオトレーニングデータの適度なソースを使用することで、私たちの方法はスポーツ活動のハイライトクリッピングを正確に実行できます。以前の調査は成功していますが、方法は依然として懸念事項です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-level Knowledge Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_48.html">
      <font color="black">Multi-level Knowledge Distillation</font>
    </a>
  </h2>
  <font color="black">これらの異なるレベルの知識は、1種類の監視信号だけでは効果的にキャプチャできません。最近、対照的な損失ベースの知識蒸留が提案され、学生は同じ画像を近くで異なるマッピングすることにより、教師のインスタンス識別知識を学習できます。表現空間のはるか遠くにある画像..知識の蒸留は、モデルの圧縮と加速のための重要な手法になっています。 
[概要]従来の知識蒸留アプローチは、教師から生徒のネットワークに知識を伝達することを目的としていますが、これらの方法はすべて、教師の知識がマルチレベル、卵、個人、ギャビー、カテゴリレベルであることを無視しています。これらには、klの最小化が含まれます。それらの確率的出力間の相違</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: 6.7ms on Mobile with over 78% ImageNet Accuracy: Unified Network Pruning
  and Architecture Search for Beyond Real-Time Mobile Acceleration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_49.html">
      <font color="black">6.7ms on Mobile with over 78% ImageNet Accuracy: Unified Network Pruning
  and Architecture Search for Beyond Real-Time Mobile Acceleration</font>
    </a>
  </h2>
  <font color="black">大規模な検索スペースに対処するために、高速評価とベイズ最適化による強化学習に基づくメタモデリング手順を提案し、代表的なNASフレームワークに匹敵するトレーニングエポックの総数を確保します。この作業では、最初に（i）を提案します。さまざまなDNNレイヤーに適用可能なきめ細かい構造化プルーニングの一般的なカテゴリ、および（ii）モデル圧縮とNASのギャップを埋めるさまざまなDNNとさまざまなプルーニングスキームをサポートする包括的なコンパイラ自動コード生成フレームワーク。この目標に向けた以前の方法は、モデル圧縮やネットワークアーキテクチャ検索（NAS）を含め、主に独立して実行され、モバイルアクセラレーションで必須のコンパイラレベルの最適化を十分に考慮していません。 
[概要]これらには、モデル圧縮とネットワークアーキテクチャ検索（nas）が含まれます。事前評価は主に独立して実行されます。さらに、形成に役立つドキュメントであるnpasを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Whitening for Self-Supervised Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_50.html">
      <font color="black">Whitening for Self-Supervised Representation Learning</font>
    </a>
  </h2>
  <font color="black">ホワイトニングMSE（W-MSE）損失は、特別なヒューリスティックを必要とせず（たとえば、ネガティブは必要ないため、同じイメージインスタンスから複数のポジティブペアを抽出できます。追加のネットワーク）、概念的に単純です。 
[概要]ホワイトニング操作は、バッチサンプルに「散乱」効果をもたらします。これにより、すべてのサンプルが1点に崩壊する縮退解が回避されます。w-mseは、一般的な、より複雑な自己監視法に関して競合します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-13">
        <br><font color="black">2020-07-13</font>
      </time>
    </span>
</section>
<!-- paper0: Monocular 3D Object Detection with Sequential Feature Association and
  Depth Hint Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_51.html">
      <font color="black">Monocular 3D Object Detection with Sequential Feature Association and
  Depth Hint Augmentation</font>
    </a>
  </h2>
  <font color="black">深度事前評価、事後最適化、またはその他の改良モジュールを利用せずに、当社のネットワークは、適切な実行速度を維持しながら、最先端の方法に対して競争力を発揮します。深度推定のヒントとして特性化された深度パターンを提供するために、専用の深度ヒントモジュールは、深さヒントと呼ばれる行ごとの特徴を生成するように設計されており、ビンごとの方法で明示的に監視されます。トレーニング段階では、回帰出力が均一にエンコードされ、損失のもつれを解くことができます。 
[要約]この作業では、単眼の3Dオブジェクト検出のタスクに対処するために、fadnetという名前のキーポイントベースのネットワークが提示されます。この作業のもう1つの貢献は、深度ヒント拡張の戦略です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Part Discovery via Feature Alignment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_52.html">
      <font color="black">Unsupervised Part Discovery via Feature Alignment</font>
    </a>
  </h2>
  <font color="black">ニューラルネットワークの特徴は迷惑変数に対してほとんど不変であり、同じオブジェクトカテゴリの画像間の変動の主な残りの原因はオブジェクトのポーズであるという特性を利用します。この論文では、教師なしの方法でオブジェクトの部分を発見することを目指しています。 、グラウンドトゥルース部分またはキーポイント注釈なし..個々の部分の観点からオブジェクトを理解することは重要です。これにより、オブジェクトの幾何学的構造を正確に理解でき、オブジェクトが新しいポーズまたは下で見られたときのオブジェクト認識が向上します。部分的な閉塞。 
[概要]大規模なデータセット内のパーツの手動注釈は、時間と費用がかかります。同じクラスの同じポーズのオブジェクトは、同じ空間位置にパーツを配置する必要があるという信念に基づいています。簡単な方法は簡単で高速です。 、フィードフォワードニューラルネットワーク以外の追加モジュールやオーバーヘッドなし</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: RAFT-3D: Scene Flow using Rigid-Motion Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_53.html">
      <font color="black">RAFT-3D: Scene Flow using Rigid-Motion Embeddings</font>
    </a>
  </h2>
  <font color="black">リジッドモーション埋め込みに不可欠なのは、埋め込みの幾何学的一貫性を強化する微分可能なレイヤーであるDense-SE3です。実験では、RAFT-3Dが最先端のパフォーマンスを実現することが示されています。シーンフローの問題に対処します。ステレオまたはRGB-Dビデオフレームのペアで、ピクセル単位の3Dモーションを推定します。 
[概要]シーンフローの新しいディープアーキテクチャであるraft-3dを導入します。システムは、ピクセルを2Dオブジェクトにソフトにグループ化することを表すリジッド埋め込みを使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-stage Attention ResU-Net for Semantic Segmentation of
  Fine-Resolution Remote Sensing Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_54.html">
      <font color="black">Multi-stage Attention ResU-Net for Semantic Segmentation of
  Fine-Resolution Remote Sensing Images</font>
    </a>
  </h2>
  <font color="black">このような成長は、大規模な入力を伴うアプリケーションシナリオでの注意メカニズムの使用を大幅に妨げます。このような設計により、注意メカニズムとディープネットワーク間の組み込みがはるかに柔軟で用途が広くなります。Vaihingenデータセットで実施された実験により、私たちのMAResU-Net。 
[要約]この手紙では、この問題に対処するための線形注意メカニズム（lam）を提案します。これは、ドット積の注意とほぼ同等です。提案されたlamに基づいて、生のu-netのスキップ接続を再因数分解します。意味言語のための多段階のmaresu--net（maresu）を設計します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-29">
        <br><font color="black">2020-11-29</font>
      </time>
    </span>
</section>
<!-- paper0: A Stitching Algorithm for Automated Surface Inspection of Rotationally
  Symmetric Components -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_55.html">
      <font color="black">A Stitching Algorithm for Automated Surface Inspection of Rotationally
  Symmetric Components</font>
    </a>
  </h2>
  <font color="black">深層学習ベースの検出アルゴリズムを簡単に実装して、回転対称部品の故障検出と状態監視のための完全なパイプラインを生成できます。ステッチングアルゴリズムの評価には、メトリックが使用されます。すでに使用されているテスト手順によって補完されています。したがって、開発されたプロセスにより、たとえば、多くの個別の画像を表示することなく、状態監視が可能になります。 
[ABSTRACT]プロセスパイプラインは、機能を使用します-ビデオファイルから現実を作成するために開発されたアルゴリズム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning Models for Predicting Wildfires from Historical
  Remote-Sensing Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_56.html">
      <font color="black">Deep Learning Models for Predicting Wildfires from Historical
  Remote-Sensing Data</font>
    </a>
  </h2>
  <font color="black">結果は、深層学習モデルが、83％のAUCで植生、天気、地形に関する集計データを使用して、火災の可能性が高い領域を正常に識別できることを示しています。10年近くのリモートセンシングデータと履歴データを集計してデータセットを作成します。野火を予測するための火災記録..野火の可能性が高い地域を特定することは、土地と森林の管理および災害への備えの重要な要素です。 
[概要] 10年近くのリモートセンシングデータと過去の火災記録を集約して山火事を予測することでデータセットを作成します。結果は、4つの異なる深層学習モデルを使用して比較および分析され、山火事の可能性が推定されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Truly shift-invariant convolutional neural networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_57.html">
      <font color="black">Truly shift-invariant convolutional neural networks</font>
    </a>
  </h2>
  <font color="black">これらの課題に対処するために、畳み込みニューラルネットワークが精度を損なうことなくシフト下で分類パフォーマンスの100％の一貫性を達成できるようにする、単純なサブサンプリングスキームである適応多相サンプリング（APS）を提案します。 CNNの出力は、入力のわずかなシフトで大幅に変化する可能性があります。ダウンサンプリング（ストライド）レイヤーの存在によって引き起こされる問題です。APSを使用すると、ネットワークはトレーニング前でもシフトに対して完全な一貫性を示し、畳み込みニューラルネットワークを作成する最初のアプローチになります。ネットワークは本当に不変にシフトします。 
[概要]畳み込みニューラルネットワークを真にシフトバインディングにするのはこれが初めてです。apsを使用すると、トレーニング前でもネットワークはシフトに対して完全な一貫性を示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-28">
        <br><font color="black">2020-11-28</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Guided Weakly Supervised Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_58.html">
      <font color="black">3D Guided Weakly Supervised Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">2D-3Dセマンティクス（2D-3D-S）データセットのサブセットにバウンディングボックスで手動でラベルを付け、2D-3D推論モジュールを導入して、正確なピクセル単位のセグメント提案マスクを生成します。ピクセル単位のクリーンな注釈が必要です。取得するのに手間と費用がかかる完全に監視されたセマンティックセグメンテーション。次に、オブジェクト性確率を持つポイントクラウドを2D画像に投影し、その後、セマンティックセグメンテーションネットワークをトレーニングするための疑似ラベルとして扱われるセグメント提案を取得するための改良ステップが続きます。 。 
[概要]新しい論文では、部分的に監視された2Dセマンティックセグメンテーションモデルを提案します。これらは、高度なセンサーで取得するのがはるかに簡単な、利用可能な3D情報を含む境界ボックスラベルです。最初にオブジェクトの点群を生成し、オブジェクトの確率を計算します各ポイントのスコア</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Fast Class-wise Updating for Online Hashing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_59.html">
      <font color="black">Fast Class-wise Updating for Online Hashing</font>
    </a>
  </h2>
  <font color="black">高速なオンライン適応性を実現するために、バイナリコード学習を分解するクラスごとの更新方法が開発され、代わりにクラスごとの方法でハッシュ関数が更新されます。これにより、大量のトレーニングバッチの負担に十分に対処できます。オンラインハッシュの高速クラスワイズ更新（FCOH）と呼ばれる、新しい監視付きオンラインハッシュスキームを提案して、新しい効率的な内部製品操作を導入することにより、上記の2つの課題に対処します。オンライン効率をさらに達成するために、セミリラクゼーション最適化。さまざまなバイナリ制約を個別に処理することにより、オンライントレーニングを加速します。 
[ABSTRACT]高速クラス-オンラインハッシュ（fcoh）の賢明な更新は、斬新で効率的な内積演算を導入することによって課題に対処するために提案されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Minimal Solutions for Panoramic Stitching Given Gravity Prior -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_60.html">
      <font color="black">Minimal Solutions for Panoramic Stitching Given Gravity Prior</font>
    </a>
  </h2>
  <font color="black">精度と処理時間の両方の点で最先端の性能を上回っていることを示しています。これを使用すると、カメラのy軸を位置合わせするか、すでに位置合わせされていると見なして、相対的な向きを減らすことができます。 〜1-DOF（自由度）。この仮定を利用して、光学中心が一致する、つまり純粋な回転を受けるカメラによって撮影された画像のパノラマ画像スティッチングに対する新しい最小ソリューションを提案します。 
[概要] imu-imu-または整列点-は重力を測定できます。imusは重力の方向を測定するために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Inaccurate Supervision of Neural Networks with Incorrect Labels:
  Application to Epilepsy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_61.html">
      <font color="black">Inaccurate Supervision of Neural Networks with Incorrect Labels:
  Application to Epilepsy</font>
    </a>
  </h2>
  <font color="black">フレーム間相互相関行列を計算して、患者のパッティングを示す反復的な動きを示すパターンを分離しました。この作業では、発作検出のコンテキストでニューラルネットワークを使用したビデオ処理の複数の弱い監視戦略について説明します。この問題に対処するために、臨床ルーチン中に取得した新生児の連続ビデオ録画から、アーティファクトの例（新生児のパッティング）を自動的に検出しました。 
[概要]私たちの仕事は、緩くラベル付けされた時系列からより正確なモデルを構築するための洞察を提供します。彼らは、パッティング検出の場合、そのようなネットワークが精度を犠牲にすることなく、より高い想起を達成できることを発見しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-28">
        <br><font color="black">2020-11-28</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-modal registration using point clouds and graph-matching in the
  context of correlative microscopies -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_62.html">
      <font color="black">Cross-modal registration using point clouds and graph-matching in the
  context of correlative microscopies</font>
    </a>
  </h2>
  <font color="black">この論文では、グラフ構築とグラフマッチングに基づく点群の登録方法を提示し、その方法を反復的な最も近い点ベースの方法と比較します。生物学者は、登録に使用される画像コンテンツを選択して、未知の構造..生物学者が選択したコンテンツから作成した点群に基づくアプローチを提案します。 
[要約]相関顕微鏡法ワークフローのさまざまなステップで登録が必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-view Depth Estimation using Epipolar Spatio-Temporal Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_63.html">
      <font color="black">Multi-view Depth Estimation using Epipolar Spatio-Temporal Networks</font>
    </a>
  </h2>
  <font color="black">さらに、最近のMixture-of-Expertsモデルに触発された計算コストを削減するために、2Dコンテキスト情報と3D視差キューを別々に学習する2Dコンテキスト認識ネットワークと3Dマッチングネットワークで構成されるコンパクトなハイブリッドネットワークを設計します。この方法は、新しいエピポーラ時空間（EST）トランスフォーマーを使用して、幾何学的および時間的相関を複数の推定深度マップと明示的に関連付けることにより、時間的にコヒーレントな深度推定結果を実現します。は、知覚、再構築、ロボットナビゲーションなどのさまざまなアプリケーションで重要なタスクです。 
[ABSTRACT]私たちの方法は通常のコスト削減技術を実現しますが、フレーム間の強力な幾何学的および3Dの一貫性は考慮されていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-26">
        <br><font color="black">2020-11-26</font>
      </time>
    </span>
</section>
<!-- paper0: Emotion Detection using Image Processing in Python -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_64.html">
      <font color="black">Emotion Detection using Image Processing in Python</font>
    </a>
  </h2>
  <font color="black">この研究は、この手順が実行可能であり、有効な結果を生み出すことを証明しています。スキャンされた画像（テストデータセット）はトレーニングデータセットと比較されているため、感情が予測されます。この論文の目的は、画像を分析できるシステムを開発することです。人の表情を予測します。 
[概要]これらの式は、ライブフィードまたはメモリ内で利用可能な既存の画像から派生させることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Boosting the Performance of Semi-Supervised Learning with Unsupervised
  Clustering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_65.html">
      <font color="black">Boosting the Performance of Semi-Supervised Learning with Unsupervised
  Clustering</font>
    </a>
  </h2>
  <font color="black">自己監視で頻繁に使用される手作りの口実タスクとは対照的に、クラスタリングフェーズでは、同じ分類ネットワークを利用して、主要なタスクを緩和し、ラベルからの情報を過剰適合せずに伝播しようとします。画像の回転を分類する自己監視技術は、教師なし学習フェーズで組み込まれ、トレーニングを安定させます。いくつかの最先端のSSLアルゴリズムを強化し、結果を大幅に改善し、さまざまな標準で実行時間を短縮する方法の有効性を示します。各タスクでクラスごとに4つのラベルのみを使用し、CIFAR-10で92.6％、SVHNで96.9％の精度を含む、半教師ありベンチマーク。 
[概要]このペーパーでは、トレーニング中にエポック全体でラベルを完全に無視すると、パフォーマンスが大幅に向上することを示します。プライマリ分類タスクは、ラベルなしデータとほとんど注釈なしデータの両方に公開されますが、セカンダリタスクはデータをクラスター化しようとします。ラベルなし</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Decomposition, Compression, and Synthesis (DCS)-based Video Coding: A
  Neural Exploration via Resolution-Adaptive Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_66.html">
      <font color="black">Decomposition, Compression, and Synthesis (DCS)-based Video Coding: A
  Neural Exploration via Resolution-Adaptive Learning</font>
    </a>
  </h2>
  <font color="black">さらに、最先端の方法とアブレーション研究との実験的比較を実施して、DCSアルゴリズムの効率と一般化をさらに報告し、将来のビデオコーディングの有望な方向性を約束します。解像度適応合成の場合、モーション補正ネットワーク（MCN）はTMFで考案され、非ローカルテクスチャ転送ネットワーク（NL-TTN）を使用して、対応するSTFと共同で処理される時間的モーション機能を効率的に整列および集約し、空間の詳細をより適切に拡張します。これにより、圧縮と解像度のリサンプリングが行われます。ノイズは、レート歪み効率を向上させることで効果的に軽減できます。この作業では、分解にバイキュービックリサンプリングを適用し、圧縮にHEVC準拠のアルゴリズムを適用し、合成部分に焦点を当てます。 
[ABSTRACT]「分解、圧縮、ネットワーク」のネイティブ部分は、ネイティブ部分に触発されました。この作業は、単純に適用、リキュービックリサンプリング、および圧縮のnelです。これは、composition.methodに関連する合成部分に焦点を当てています。構成部分に注意を向けるために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Weakly-Supervised Arbitrary-Shaped Text Detection with
  Expectation-Maximization Algorithm -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_67.html">
      <font color="black">Weakly-Supervised Arbitrary-Shaped Text Detection with
  Expectation-Maximization Algorithm</font>
    </a>
  </h2>
  <font color="black">一方、弱教師あり学習を組み込むのに適した輪郭ベースの任意形状のテキスト検出器を提案します。3つの任意形状のテキストベンチマーク（CTW1500、Total-Text、ICDAR-ArT）での広範な実験により、（1） 10％の強く注釈が付けられたデータと90％の弱く注釈が付けられたデータのみを使用して、私たちの方法は最先端の方法と同等のパフォーマンスをもたらします。（2）100％強く注釈が付けられたデータでは、私たちの方法は3つのベンチマークすべてで既存の方法よりも優れています。任意の形のテキスト検出は、コンピュータービジョンにおける重要で挑戦的なタスクです。 
[概要]ほとんどの既存の方法では、教師ありトレーニング用のポリゴンレベルのテキスト領域ラベルを生成するために大量のデータラベル付けが必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Counting People by Estimating People Flows -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_68.html">
      <font color="black">Counting People by Estimating People Flows</font>
    </a>
  </h2>
  <font color="black">また、空間的および時間的方法の両方で人々の保全制約を活用することで、はるかに少ない注釈でアクティブラーニング設定で深い群集カウントモデルをトレーニングできることを示します。これにより、数の保全をエンコードするはるかに強力な制約を課すことができます混雑したシーンで人を数えるための最新の方法は、個々の画像の人の密度を推定するために深いネットワークに依存しています。 
[概要]これにより、人にはるかに強い制約を課すことができます。これは、人が人の流れとオプティカルフローの相関関係を利用して、結果をさらに改善できることを意味します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Navigating the GAN Parameter Space for Semantic Image Editing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_69.html">
      <font color="black">Navigating the GAN Parameter Space for Semantic Image Editing</font>
    </a>
  </h2>
  <font color="black">生成的敵対的ネットワーク（GAN）は現在、視覚編集に不可欠なツールであり、画像から画像への変換および画像復元パイプラインの標準コンポーネントです。いくつかの簡単な方法で、この空間を探索し、多数の重要なセマンティック操作の優れたソースである解釈可能な方向。コードとモデルをリリースし、GANベースの画像編集にさらに取り組むための便利なツールとして役立つことを願っています。 
[ABSTRACT]ガンは、制御可能な生成に特に役立ちます。これらの潜在的なスペースには、解釈可能な方向が幅広く含まれています。これらは、セマンティック編集操作に最適です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-27">
        <br><font color="black">2020-11-27</font>
      </time>
    </span>
</section>
<!-- paper0: Frequency Domain Image Translation: More Photo-realistic, Better
  Identity-preserving -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_70.html">
      <font color="black">Frequency Domain Image Translation: More Photo-realistic, Better
  Identity-preserving</font>
    </a>
  </h2>
  <font color="black">度数分布を2つの側面から調整します。a）画像の度数分布を局所的に制限するための空間レベルの制限。 b）画像間のグローバルな一貫性を強化するためのスペクトルレベルの調整..画像から画像への変換は、特定のスタイルの画像を別のスタイルに変換することを目的としています。入力画像を高周波および低周波の情報に変換することで、この目標を達成します。 、それぞれコンテンツとスタイルに対応します。 
[要約]提案されたアプローチは、さまざまな最先端の画像翻訳モデルに加えて、一貫して大幅な改善につながります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-27">
        <br><font color="black">2020-11-27</font>
      </time>
    </span>
</section>
<!-- paper0: We are More than Our Joints: Predicting how 3D Bodies Move -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_71.html">
      <font color="black">We are More than Our Joints: Predicting how 3D Bodies Move</font>
    </a>
  </h2>
  <font color="black">したがって、人間の動きの予測の問題は、点群の予測と見なすことができます。研究目的のコードはhttps://yz-cnsdqz.github.io/MOJO/MOJO.htmlにあります。 3Dジョイントは、スパースポイントクラウドと見なすことができることに注意してください。 
[概要]人身売買の概念は、人身売買、hci、グラフィックスに多くの用途があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: DeFMO: Deblurring and Shape Recovery of Fast Moving Objects -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_72.html">
      <font color="black">DeFMO: Deblurring and Shape Recovery of Fast Moving Objects</font>
    </a>
  </h2>
  <font color="black">DeFMOは最先端の性能を上回り、高品質の時間的超解像フレームを生成します。このような場合、古典的な方法、または人間でさえ、オブジェクトの外観と動きを回復することはできません。提案されたDeFMO方法は、複合体でトレーニングされます。合成データセットですが、いくつかのデータセットからの実際のデータでうまく機能します。 
[概要]提案されたdefmoメソッドは、複雑な合成データセットでトレーニングされています。複数のデータセットからの実世界のデータでうまく機能します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Improving the Transferability of Adversarial Examples with the Adam
  Optimizer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_73.html">
      <font color="black">Improving the Transferability of Adversarial Examples with the Adam
  Optimizer</font>
    </a>
  </h2>
  <font color="black">ImageNetでの広範な実験により、提案された方法は既存の反復法よりも高い攻撃成功率を提供することが示されました。畳み込みニューラルネットワークは画像認識タスクで人間を上回りましたが、敵対的な例からの攻撃に対して脆弱なままです。したがって、この研究は改善された方法を組み合わせたものです。反復勾配ベースの攻撃方法を使用したアダム勾配降下アルゴリズム。 
[概要]ブラックボックス環境では、敵対的攻撃の成功率はさらに改善される必要があります。次に、ニューラルネットワークを改善するためにadam反復高速勾配攻撃法が使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: HORAE: an annotated dataset of books of hours -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_74.html">
      <font color="black">HORAE: an annotated dataset of books of hours</font>
    </a>
  </h2>
  <font color="black">この論文では、中世後期の裕福な一般の人々が所有し使用している手書きの祈祷書の一種である、時間の本からの注釈付きページの新しいデータセットを紹介します。コーパスは自由に研究に利用できます。コーパスが収集され、手動で注釈が付けられた後、テキスト行の検出とゾーンの検出および入力のための最先端のシステムの評価が示されます。 
[概要]データセットは、ヨーロッパの宗教的考え方の進化に関する歴史的研究を実施するために作成されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Facetwise Mesh Refinement for Multi-View Stereo -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_75.html">
      <font color="black">Facetwise Mesh Refinement for Multi-View Stereo</font>
    </a>
  </h2>
  <font color="black">選択したカメラペアのみを使用して、各ファセットにリファインメントステップを適用します。このペーパーでは、この方法を拡張して、ドロネー三角形分割を直接推論することにより、非多様体頂点をプリエンプティブに修正し、ほとんどの頂点分割を回避します。問題を処理します。メッシュラベリングプロセスとして、各ラベルはカメラペアに対応します。 
[概要]カメラペアの選択の問題は、メッシュのすべての表示部分を調整するために各カメラペアを使用する最先端の方法とは異なります。代わりに、各ファセットに対して、強制する最適なペアを選択します。全体的な可視性とカバレッジの両方</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: RaP-Net: A Region-wise and Point-wise Weighting Network to Extract
  Robust Keypoints for Indoor Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_76.html">
      <font color="black">RaP-Net: A Region-wise and Point-wise Weighting Network to Extract
  Robust Keypoints for Indoor Localization</font>
    </a>
  </h2>
  <font color="black">コードとデータはhttps://github.com/ivipsourcecode/RaP-Netで入手できます。また、このネットワークをトレーニングするために、新しいデータセットOpenLORIS-Locationを構築します。実験結果は、提案されたRaP-NetがOpenLORIS-Locationデータセットは、屋内ローカリゼーション用の既存のCNNベースのキーポイント抽出アルゴリズムを大幅に上回っています。 
[概要]新しいネットワークラップ-ネットは地域ベースの予測子を使用してネットワークを作成します。データセットには、ロケーションラベル付きの1553枚の屋内画像が含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: fairfaceGAN: Fairness-aware Facial Image-to-Image Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_77.html">
      <font color="black">fairfaceGAN: Fairness-aware Facial Image-to-Image Translation</font>
    </a>
  </h2>
  <font color="black">さらに、保護された属性がどの程度保持されているかを測定する新しい公平性メトリック、つまりFrechet Protected Attribute Distance（FPAD）を提案します。さらに、FairFaceGANが既存の方法と比較して競争力のある結果を示す画像変換パフォーマンスも評価します。公平性の程度を評価するために、CelebAデータセットに対して2種類の実験を実行します。 
[ABSTRACT] fairfaceganは、2つの別個の潜在性を持つ公正な表現を学習できます。1つは翻訳するターゲット属性に関連し、もう1つはそれらに関連しません。fairfaceganモデルは、ターゲットサブジェクトの編集中に保護された属性の不要な翻訳も防止します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: SRG-Net: Unsupervised Segmentation for Terracotta Warrior Point Cloud
  with 3D Pointwise CNN methods -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_78.html">
      <font color="black">SRG-Net: Unsupervised Segmentation for Terracotta Warrior Point Cloud
  with 3D Pointwise CNN methods</font>
    </a>
  </h2>
  <font color="black">最後に、SRG-Netと呼ばれる改良方法を使用してSRGアルゴリズムと改良されたCNNを組み合わせて、テラコッタ戦士のセグメンテーションタスクを実行します。最初に、カスタマイズされたシード領域成長アルゴリズムを提案して、点群を粗くセグメント化します。 3D点群の特性をよりよく理解するために、監視されたセグメンテーションと監視されていない再構成ネットワークを提示します。 
[概要]テラコッタ戦士の3D点群を使用した教師なし部分セグメンテーションのシード-領域-成長cnn（srg-net）を提示します。教師ありセグメンテーションおよび再構築ネットワークを提示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Weakly-supervised Object Localization for Few-shot Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_79.html">
      <font color="black">Weakly-supervised Object Localization for Few-shot Learning</font>
    </a>
  </h2>
  <font color="black">この論文では、弱教師ありオブジェクトのローカリゼーションを実現するための自己注意ベースの補完モジュール（SACモジュール）を提案し、さらに重要なことに、少数ショット分類のための識別可能な深い記述子を選択するためのアクティブ化されたマスクを生成します。メソッドは、キーオブジェクトをより間隔を置いてローカライズできます。広範な実験により、さまざまな設定でのベンチマークデータセット、特にきめ細かい数ショットのタスクで、メソッドが最先端のメソッドよりも優れていることが示されています。 
[概要]ローカリゼーションは、一般的な分類と低データ体制でのきめ細かい分類の両方に重要な識別領域を直接提供するため、効率的なアプローチであると主張します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-02">
        <br><font color="black">2020-03-02</font>
      </time>
    </span>
</section>
<!-- paper0: Just Ask: Learning to Answer Questions from Millions of Narrated Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_80.html">
      <font color="black">Just Ask: Learning to Answer Questions from Millions of Narrated Videos</font>
    </a>
  </h2>
  <font color="black">このデータセット内の多様な回答のオープンボキャブラリーを処理するために、ビデオ質問マルチモーダルトランスフォーマーと回答埋め込みの間の対照的な損失に基づくトレーニング手順を提案します。コードとデータセットはhttps：/で公開されます。 /www.di.ens.fr/willow/research/just-ask/ ..さらに、ターゲットデータセットでモデルを微調整すると、MSRVTT-QA、MSVD-QA、ActivityNet-QAの最新技術よりも大幅に優れていることを示します。 
[要約]ただし、ビデオの質問と回答の手動注釈は、疑わしく、費用がかかります。文字起こしされたビデオナレーションから質問と回答のペアを自動的に生成することを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: SS-IL: Separated Softmax for Incremental Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_81.html">
      <font color="black">SS-IL: Separated Softmax for Incremental Learning</font>
    </a>
  </h2>
  <font color="black">スコアの再スケーリングやバランスの取れた微調整など、追加の後処理によってこのようなスコアバイアスを修正する方法がいくつか提案されていますが、このようなバイアスの根本原因に関する体系的な分析は行われていません。SS-も示しています。 ILは、他のベースラインで行われるような追加の後処理ステップなしで、はるかにバランスの取れた予測を行います。そのために、すべての新旧のクラスの出力スコアを組み合わせてソフトマックス確率を計算することが、バイアスをかけ、新しいCILメソッドであるインクリメンタル学習用のSeparated Softmax（SS-IL）を提案します。 
[要約]問題の主な課題は、壊滅的な忘却です。模範的なメモリベースのcilメソッドの場合、忘却は一般に予測スコアのバイアスによって引き起こされることが一般的に知られています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br><font color="black">2020-03-31</font>
      </time>
    </span>
</section>
<!-- paper0: Fully Convolutional Networks for Panoptic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_82.html">
      <font color="black">Fully Convolutional Networks for Panoptic Segmentation</font>
    </a>
  </h2>
  <font color="black">ローカリゼーションまたはインスタンス分離のための追加のボックスがない場合、提案されたアプローチは、単一スケール入力のCOCO、Cityscapes、およびMapillary Vistasデータセットで高効率の以前のボックスベースの無料モデルよりも優れています。 github.com/yanwei-li/PanopticFCN ..このペーパーでは、Panoptic FCNと呼ばれる、パノプティックセグメンテーションのための概念的にシンプルで強力かつ効率的なフレームワークを紹介します。 
[概要]私たちのアプローチは、統一された完全畳み込みパイプラインで前景のものを表現および予測することを目的としています。私たちは、すべてのものと背景のものを表現、マッピング、および予測することを目指しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-Supervised Noisy Student Pre-training on EfficientNet Architectures
  for Plant Pathology Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_83.html">
      <font color="black">Semi-Supervised Noisy Student Pre-training on EfficientNet Architectures
  for Plant Pathology Classification</font>
    </a>
  </h2>
  <font color="black">最後に、半教師ありノイズのある学生トレーニングの最先端のアイデアをEfficientNetに導入し、精度と収束率の両方を大幅に改善します。さらに、新しいEfficientNetモデルの使用を検討し、 0.962までの精度。タスクで0.945スコアを達成するために、VGG16、ResNet101、DenseNet161などの標準ベンチマークモデルの使用を検討します。 
[要約]レポートでは、シングルネットの画像を使用して分類の問題を調査します。これらのモデルは、0のテストスコアを達成します。962。最終的なアンサンブルされたノイズの多い学生モデルは、タスクで非常にうまく機能します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Crowd-Sourced Road Quality Mapping in the Developing World -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_84.html">
      <font color="black">Crowd-Sourced Road Quality Mapping in the Developing World</font>
    </a>
  </h2>
  <font color="black">道路の地理的分布とその品質の最新のマッピングは、土地利用計画から荒野の保全に至るまで、影響の大きいアプリケーションで不可欠です。道路ネットワークは、国のインフラストラクチャの最も重要なコンポーネントの1つです。特に、文書化が不十分で、今後数十年で不均衡な量の道路建設が発生すると予想される開発途上国での差し迫った課題。 
[ABSTRACT]開発途上国では道路インフラが整備されています。今後数十年で道路建設が行われると予想されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: DUT: Learning Video Stabilization by Simply Watching Unstable Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_85.html">
      <font color="black">DUT: Learning Video Stabilization by Simply Watching Unstable Videos</font>
    </a>
  </h2>
  <font color="black">この論文では、深い教師なし軌道ベースの安定化フレームワーク（DUT）を提案します。一方、以前の深いビデオスタビライザーは、明示的な軌道推定なしに、教師ありの方法で安定したビデオを直接生成します。これは、堅牢ですが、制御性が低く、適切なペアです。データを取得するのは困難です。教師なしトレーニングでは、動きの連続性の性質と、安定化前後のキーポイントとグリッド頂点の一貫性の両方を活用します。 
[ABSTRACT]制御可能で堅牢なスタビライザーを構築するために、dutは不安定なビデオを安定化する最初の試みを行います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: One-Pixel Attack Deceives Automatic Detection of Breast Cancer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_86.html">
      <font color="black">One-Pixel Attack Deceives Automatic Detection of Breast Cancer</font>
    </a>
  </h2>
  <font color="black">攻撃はサイバーセキュリティの観点から脅威をもたらします。1ピクセルの方法は、やる気のある攻撃者による攻撃ベクトルとして使用できます。この研究では、実際の腫瘍データセットを使用した実際のシナリオで1ピクセルの攻撃を示します。この記事では、スライド画像全体に有糸分裂が含まれるかどうかを予測する最先端の機械学習モデルが、入力画像の1つのピクセルを変更するだけでだまされる可能性があることを示します。 
[概要] 1つ-実際の腫瘍データセットを使用した実際のシナリオで実証されたピクセル攻撃</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Boosting CNN-based primary quantization matrix estimation of double JPEG
  images via a classification-like architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_87.html">
      <font color="black">Boosting CNN-based primary quantization matrix estimation of double JPEG
  images via a classification-like architecture</font>
    </a>
  </h2>
  <font color="black">結果は、統計分析と深層学習回帰に基づく最先端の方法と比較して、提案された手法の有効性を確認します。この論文では、推定を解決するために類似分類CNNアーキテクチャの使用を提案します。量子化係数の整数性を利用し、トレーニングに適切な損失関数を使用します。これは、推定の精度と平均二乗誤差の両方を考慮に入れます。アライメントに関して、一般的な操作条件下で機能するメソッドの機能。 2番目の圧縮グリッドと1番目の圧縮の1つ、および前者と2番目の圧縮のJPEG品質の組み合わせは、これらの情報が事前に不明である実際のアプリケーションに非常に関連しています。 
[ABSTRACT]ディープラーニングは、パフォーマンスの高い推定量を設計するために利用されています。この方法は、特定の状況で機能します。標準の相関問題として推定を解決するためのモデルのトレーニングに使用されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Co-Training with Task Decomposition for Semi-Supervised Domain
  Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CV/paper_88.html">
      <font color="black">Deep Co-Training with Task Decomposition for Semi-Supervised Domain
  Adaptation</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチをタスク分解を伴うディープコトレーニング（DeCoTa）と呼びます。半教師ありドメイン適応（SSDA）は、モデルをラベル付きのソースドメインから、ラベルのないデータと小さなセットのラベル付けされたデータが提供されます。これらの2つのサブタスクは非常に異なる分類器を生成し、したがって、2つの分類器が信頼性の高い予測を交換して繰り返し「互いに教える」という確立された共同トレーニングフレームワークに自然に適合することを示します。両方の分類器は、ターゲットドメインで優れています。 
[要約] ssdaタスクを2つのサブタスクに分解します。ターゲットドメインの半教師あり学習（ssl）タスクと教師なしドメインの適応（uda）.decotaは、いくつかのデータセットで注目を集める結果を達成し、従来技術を上回りました。ドメインネットで注目すべき4％のマージン</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-24">
        <br><font color="black">2020-07-24</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Towards a Unified Framework for Emotion Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_0.html">
      <font color="black">Towards a Unified Framework for Emotion Analysis</font>
    </a>
  </h2>
  <font color="black">さまざまなタスク（文レベル、単語レベル、ラベルからラベルへのマッピング）、ドメイン（自然言語とそのレジスター）、およびラベル形式（極性など）にわたる感情分析を一般化するモジュラーエンコーダーデコーダーアーキテクチャであるEmoCoderを紹介します。クラス、基本的な感情、および感情的な次元）。14のデータセットでの実験は、EmoCoderが感情の解釈可能な言語に依存しない表現を学習し、最先端のモデルのシームレスな吸収を可能にし、テストされた場合でも強力な予測品質を維持することを示していますドメインとラベル形式の目に見えない組み合わせ。 
[ABSTRACT] emocoderは、解釈可能な言語、感情の独立した表現を学習します。最先端のモデルをシームレスに吸収し、強力な予測品質を維持します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Neural language models for text classification in evidence-based
  medicine -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_1.html">
      <font color="black">Neural language models for text classification in evidence-based
  medicine</font>
    </a>
  </h2>
  <font color="black">この記事では、EBMを実施する世界で最も活発な財団の1つであるEpistemonikosをサポートする科学論文を分類するための応用研究プロジェクトの結果を報告します。XLNetニューラル言語モデルに基づいて、いくつかの方法と最良の方法をテストします。現在のアプローチを平均F1スコアで93 \％改善し、COVID-19研究論文を手動でキュレートすることを志願する医師から貴重な時間を節約します。人工知能はこの状況で重要な役割を果たすことができます。 
[要約] xlnetニューラル言語モデルに基づく最良のものは、現在のアプローチを平均f1スコアで93％改善します。これにより、covidのキュレーションを志願する医師から貴重な時間を節約できます-19の研究記事を手動で</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Denoising Pre-Training and Data Augmentation Strategies for Enhanced RDF
  Verbalization with Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_2.html">
      <font color="black">Denoising Pre-Training and Data Augmentation Strategies for Enhanced RDF
  Verbalization with Transformers</font>
    </a>
  </h2>
  <font color="black">私たちの実験結果は、標準トレーニングと比較して、表示されたカテゴリ、表示されていないエンティティ、および表示されていないカテゴリのBLEUスコアがそれぞれ3.73％、126.05％、88.16％の最小相対増加を示しています。Transformerモデルを使用して、拡張データからの事前トレーニングを活用することを提案します。データ拡張戦略を使用します。ただし、その抽象的な表現により、人間が解釈するのは困難です。 
[要約] webnlgチャレンジは、自動化されたrdfからテキストへの生成を促進することを目的としています。調査によると、相対的な最小増加は3.73％です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: The Zero Resource Speech Benchmark 2021: Metrics and baselines for
  unsupervised spoken language modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_3.html">
      <font color="black">The Zero Resource Speech Benchmark 2021: Metrics and baselines for
  unsupervised spoken language modeling</font>
    </a>
  </h2>
  <font color="black">言語モデルは、学習した表現のクラスタリングから派生した疑似テキストに基づいて学習します。また、同じデータでトレーニングされたテキストベースの「トップライン」システムと比較してパフォーマンスが低下し、より洗練された目的で探索されるスペースが示されます。 -to-endモデル..この単純なパイプラインは、4つのメトリックすべてで偶然よりも優れたパフォーマンスを示し、生の音声からの話し言葉モデリングの実現可能性を示しています。 
[概要]教師なしシステムのリストが言語レベルの混合で提示されました。プロジェクトは、4つのメトリックすべてで偶然の学習よりも優れており、音声言語モデリングの実現可能性を示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Learning from Context or Names? An Empirical Study on Neural Relation
  Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_4.html">
      <font color="black">Learning from Context or Names? An Empirical Study on Neural Relation
  Extraction</font>
    </a>
  </h2>
  <font color="black">すべてのコードとデータセットはhttps://github.com/thunlp/RE-Context-or-Namesでリリースされています。この目的のために、テキスト内の2つの主要な情報ソース（テキストコンテキストとエンティティの言及）の影響を実験的に調査します（名前）..分析に基づいて、エンティティのロートな暗記や言及での表面的な手がかりの使用を避けながら、テキストのコンテキストとタイプ情報の両方をより深く理解するために、REのエンティティマスクされた対照的な事前トレーニングフレームワークを提案します。 
[概要]どのタイプの情報が既存の再モデルに影響を与えて意思決定を行うか、またはこれらのモデルのパフォーマンスをさらに向上させる方法を明確に理解していません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Meta-Embeddings for Natural Language Inference and Semantic Similarity
  tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_5.html">
      <font color="black">Meta-Embeddings for Natural Language Inference and Semantic Similarity
  tasks</font>
    </a>
  </h2>
  <font color="black">この論文では、いくつかの最先端（SOTA）モデルから派生したメタ埋め込みを使用して、分類、意味的関連性、テキストの類似性などの主流のNLPタスクに効率的に取り組むことを提案します。メタ埋め込み学習は、事前にトレーニングされた入力単語埋め込みの特定のセットからの単一単語の埋め込み..現在の主な問題は、さまざまなNLPタスクに多数の選択肢があることです。 
[概要]過去20年間にわたって、すべての主要なnlpタスクを解決するための1つのモデルを考案するための研究が行われています。メタ埋め込みは、いくつかの個別の表現の力を利用することにより、いくつかのnlpタスクに使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Ad-hoc Beamforming Based on Speaker Extraction for Target-Dependent
  Speech Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_6.html">
      <font color="black">Deep Ad-hoc Beamforming Based on Speaker Extraction for Target-Dependent
  Speech Separation</font>
    </a>
  </h2>
  <font color="black">アルゴリズムには3つのコンポーネントが含まれています。まず、話者抽出に基づく教師ありチャネル選択フレームワークを提案します。ここでは、ターゲット音声の推定発話レベルSNRがチャネル選択の基礎として使用されます。 WSJ0-アドホックコーパス。 
[概要]アドホックマイクアレイは、混合音声からターゲットスピーカーを抽出することを目的としています。アドホックアレイ内の特定のスピーカーを抽出してトレースするために重要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: A Human Evaluation of AMR-to-English Generation Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_7.html">
      <font color="black">A Human Evaluation of AMR-to-English Generation Systems</font>
    </a>
  </h2>
  <font color="black">これらのシステムの相対的な品質と、結果を自動メトリックの結果と比較する方法について説明します。メトリックはシステム全体のランク付けにほぼ成功していますが、人間の判断を収集することで、より微妙な比較が可能になります。また、これらによって発生する一般的なエラーを分析します。システム..抽象意味表現（AMR）から英語テキストを生成するための最新のシステムは、自然言語生成に問題があることが知られているBLEUなどの自動メトリックを使用してのみ評価されています。 
[概要]最近のいくつかのamr生成システムについて、新しい人間による評価の結果が示されています。これらのシステムは、これらのシステムによって発生したエラーを追跡するために使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-14">
        <br><font color="black">2020-04-14</font>
      </time>
    </span>
</section>
<!-- paper0: Automated Source Code Generation and Auto-completion Using Deep
  Learning: Comparing and Discussing Current Language-Model-Related Approaches -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_8.html">
      <font color="black">Automated Source Code Generation and Auto-completion Using Deep
  Learning: Comparing and Discussing Current Language-Model-Related Approaches</font>
    </a>
  </h2>
  <font color="black">ディープラーニング対応の8言語モデルアプローチの人気が高まっていることを考慮して、プログラミングコードに基づいて言語モデルを作成および使用するためにさまざまなディープラーニングアーキテクチャを比較する経験的な論文が不足していることを検出しました。近年、ディープラーニングの使用言語モデルで多くの注目を集めました。結果を考慮して、各アプローチのさまざまな長所と短所、および言語モデルを評価したり実際のプログラミングコンテキストに適用したりするために見つけたギャップについて説明します。 
[概要]一部の研究プロジェクトでは、人間として解釈できるテキストを生成できると主張しています-書き込み、多くのアプリケーション分野で新しい可能性を可能にします。これらの研究では、転送を使用しながら、awd-lstms、awd-qrnns、transformerなどのさまざまなニューラルネットワークアーキテクチャを比較しています学習</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: DART: A Lightweight Quality-Suggestive Data-to-Text Annotation Tool -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_9.html">
      <font color="black">DART: A Lightweight Quality-Suggestive Data-to-Text Annotation Tool</font>
    </a>
  </h2>
  <font color="black">大量の構造化データに注釈を付けることで実行されたシミュレーション実験では、DARTはアクティブラーニングで必要な注釈の総数を減らし、関連するラベルを自動的に提案することが示されています。軽量の注釈ツールであるData AnnotatoR Tool（DART）を紹介します。構造化データにテキストの説明をラベル付けする一般的なタスク用。テーブルまたはツリー構造の形式で。 
[概要]ツールは、大量のデータに注釈を付ける際の人間の労力を軽減するインタラクティブなアプリケーションです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: CPM: A Large-scale Generative Chinese Pre-trained Language Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_10.html">
      <font color="black">CPM: A Large-scale Generative Chinese Pre-trained Language Model</font>
    </a>
  </h2>
  <font color="black">コードとパラメーターはhttps://github.com/TsinghuaAI/CPM-Generateで入手できます。ただし、GPT-3のトレーニングコーパスは主に英語であるため、GPT-3を適用して中国語のNLPタスクに対処することは依然として困難です。パラメータは公開されていません。広範な実験により、CPMは、数ショット（ゼロショットでも）学習の設定で多くのNLPタスクで強力なパフォーマンスを達成することが示されています。 
[概要]中国語の事前トレーニング済み言語モデル（cpm）は中国語のトレーニングデータを使用します。中国語の言語モデルには60億の質問と570GBのトレーニングデータがあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Mutual Information Constraints for Monte-Carlo Objectives -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_11.html">
      <font color="black">Mutual Information Constraints for Monte-Carlo Objectives</font>
    </a>
  </h2>
  <font color="black">これらの2つの研究ストランド、特にモンテカルロの目的のより狭い範囲と、観測変数と潜在変数の間の相互情報量に対する制約を織り交ぜます。したがって、真の後方からのカルバックライブラー発散の推定値を構築します。目的で使用されるサンプルをリサイクルすることにより、事前に、大幅に改善されたレート歪みと後方崩壊なしで連続および離散潜在のモデルをトレーニングします。変分オートエンコーダとしてトレーニングされる密度モデルの一般的な障害モードは、依存せずにデータをモデル化することです。それらの潜在変数は、これらの変数を役に立たなくします。 
[要約]相互情報量の範囲全体で結論を評価することをお勧めします。両方のモデルは別々に研究されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: SeMantic AnsweR Type prediction task (SMART) at ISWC 2020 Semantic Web
  Challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_12.html">
      <font color="black">SeMantic AnsweR Type prediction task (SMART) at ISWC 2020 Semantic Web
  Challenge</font>
    </a>
  </h2>
  <font color="black">より具体的には、自然言語での質問を考えると、SMARTチャレンジのタスクは、ターゲットオントロジー（DBpediaやWikidataなど）を使用して回答タイプを予測することです。質問タイプと回答タイプの予測は、ナレッジベースの質問で重要な役割を果たすことができます。正しいクエリを生成したり、回答候補をランク付けしたりするのに役立つ洞察を提供する応答システム。毎年、国際セマンティックWeb会議は、特定の問題領域で最先端のソリューションを前進させるコンテストを確立するための一連のセマンティックWebチャレンジを受け入れます。 
[要約]セマンティック回答タイプ予測タスクはiswc2020チャレンジの一部でした。スマートチャレンジは、ターゲットオントロジーを使用して回答タイプを予測することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: SOrT-ing VQA Models : Contrastive Gradient Learning for Improved
  Consistency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_13.html">
      <font color="black">SOrT-ing VQA Models : Contrastive Gradient Learning for Improved
  Consistency</font>
    </a>
  </h2>
  <font color="black">これに対処するために、最初に勾配ベースの解釈可能性アプローチを提示して、画像上の推論質問と最も強く相関する質問を決定し、これを使用して、推論に答えるのに必要な関連サブ質問を識別する能力についてVQAモデルを評価します。質問..SOrTが既存のベースラインよりも最大6.5％ポイントだけモデルの一貫性を改善すると同時に、視覚的根拠も改善することを示します。視覚的質問回答（VQA）の最近の研究により、最先端のモデルの一貫性が失われていることが明らかになりました。世界の理解-彼らは正しく推論を必要とする一見難しい質問に答えますが、より単純な関連するサブ質問は間違っています。 
[ABSTRACT] sub-質問vqaでは、モデルに「一貫性のない」質問をランク付けする必要があります。sub-質問は、画像内の低レベルの視覚的概念に関連します。sub-質問-qaは、モデルが同じ主題でよりランク付けする必要があることを意味します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-20">
        <br><font color="black">2020-10-20</font>
      </time>
    </span>
</section>
<!-- paper0: ClimaText: A Dataset for Climate Change Topic Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_14.html">
      <font color="black">ClimaText: A Dataset for Climate Change Topic Detection</font>
    </a>
  </h2>
  <font color="black">ただし、気候変動は複雑で動きが速く、多くの場合あいまいなトピックであり、人気のあるテキストベースのAIタスクのリソースが不足しているため、このプロセスの自動化は課題です。BERT\ cite {devlin2018bert}のようなコンテキストベースのアルゴリズムは、多くの些細なケースに加えて、さまざまな複雑で暗黙的なトピックパターンがあります。したがって、この作業がこのトピックに関するさらなる研究の良い出発点として役立つことを願っています。 
[ABSTRACT]気候変動は、コンテンツのフィルタリングと電子情報開示にとって重要なタスクです。したがって、一般的なキーワードベースのモデルは、このような複雑で進化するタスクには不十分であることがわかります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: The NetHack Learning Environment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_15.html">
      <font color="black">The NetHack Learning Environment</font>
    </a>
  </h2>
  <font color="black">NLEはhttps://github.com/facebookresearch/nleでオープンソースです。NLEとそのタスクスイートを既存の代替案と比較し、RLエージェントの堅牢性と体系的な一般化をテストするための理想的な媒体である理由について説明します。分散型DeepRLベースラインとRandomNetwork Distillation探索を使用し、環境でトレーニングされたさまざまなエージェントの定性分析を使用して、ゲームの初期段階での経験的な成功を示します。 
[概要]既存のrl環境は十分に複雑であるか、高速シミュレーションに基づいています。ただし、オープンになることはめったにありませんが、nethackは複雑すぎて、探索、計画、スキル習得、言語などの問題に関する研究を推進できないと主張しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-24">
        <br><font color="black">2020-06-24</font>
      </time>
    </span>
</section>
<!-- paper0: Introducing Inter-Relatedness between Wikipedia Articles in Explicit
  Semantic Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_16.html">
      <font color="black">Introducing Inter-Relatedness between Wikipedia Articles in Explicit
  Semantic Analysis</font>
    </a>
  </h2>
  <font color="black">ウィキペディアコーパスのいくつかの小さなサブセットで仮説をテストし、提案された方法論がほとんどの場合スピアマンの順位相関係数を含むパフォーマンス測定の適切な改善につながることを示します。特に、無向グラフを使用して、ノードを記事としてこの知識を表します。 2つの記事間の相互関係としてのエッジ..明示的セマンティック分析（ESA）は、ウィキペディアにある記事など、概念の空間でテキストをベクトルとして表すために使用される手法です。 
[概要]ウィキペディアとウィキペディアの相互関係の知識を組み込む方法を提案します。この方法は、esaを使用して人間の埋め込みを形成する後続の記事のパフォーマンスを向上させるためにレトロフィットと呼ばれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic coding of students' writing via Contrastive Representation
  Learning in the Wasserstein space -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_17.html">
      <font color="black">Automatic coding of students' writing via Contrastive Representation
  Learning in the Wasserstein space</font>
    </a>
  </h2>
  <font color="black">最終的に、自然言語処理（NLP）の機械学習（ML）は、学習科学の研究者が現在可能であるよりもはるかに大規模な定性的研究を実施するのを支援する可能性を秘めていると結論付けます。まず、学部生からの一連のラボレポートから始めます。議論の構造の複雑さ、証拠の範囲、結論の注意とニュアンスを考慮した4レベルのスキームによってスコア付けされた生物学コース。このラベル付けされたデータのセットを使用して、人気のある自然言語モデリング処理パイプライン、つまり、単語のベクトル表現、別名単語の埋め込み、それに続く状態空間モデルとして言語生成をキャプチャするためのLong Short Term Memory（LSTM）モデルは、高い二次加重カッパ（QWK）予測スコアでスコアを定量的にキャプチャできます。 、新しい対照的な学習設定を介してトレーニングされた場合。 
[概要]これらは短期間の研究ですが、予測することは困難です。データ分析は、学生が研究で使用するために重要です。データデータ分析は分析に役立つ可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-26">
        <br><font color="black">2020-11-26</font>
      </time>
    </span>
</section>
<!-- paper0: Extracting Synonyms from Bilingual Dictionaries -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_18.html">
      <font color="black">Extracting Synonyms from Bilingual Dictionaries</font>
    </a>
  </h2>
  <font color="black">元のシンセットと抽出されたシンセットを比較して、アラビア語と英語のシンセット抽出でそれぞれ82.3％と82.1％のFメジャーを取得しました。次に、アルゴリズムを適用してこれらのシンセットを再構築しました。評価では、最初にシンセットを変換しました。アラビア語のWordNetを翻訳ペアに変換します（つまり、ワードセンスメンバーシップを失います）。 
[要約]このアルゴリズムの初期評価は、アラビア語の抽出で有望な結果を示しています-英語のバイリンガルリット</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Learning as Abduction: Trainable Natural Logic Theorem Prover for
  Natural Language Inference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_19.html">
      <font color="black">Learning as Abduction: Trainable Natural Logic Theorem Prover for
  Natural Language Inference</font>
    </a>
  </h2>
  <font color="black">得られた結果は、論理ベースのシステムの中で最先端技術と競合します。自然言語のタブロー定理証明器に学習方法を実装し、SICKデータセットの定理証明器のパフォーマンスを1.4％向上させることを示します。依然として高精度（&gt; 94％）を維持します。言い換えると、語彙関係の助けを借りて文レベルの推論関係を証明する代わりに、語彙関係は文レベルの推論関係を考慮に入れて証明されます。 
[概要]自然言語のタブローマニュアルに学習方法を実装します。高精度を維持しながら、病気のデータセットでの方法のパフォーマンスを1.4％向上させます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: High Quality Real-Time Structured Debate Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_20.html">
      <font color="black">High Quality Real-Time Structured Debate Generation</font>
    </a>
  </h2>
  <font color="black">各引数にメタデータが関連付けられたツリー構造のディベートの大規模なコーパスを活用します。私たちの結果は、スタイル、コンテンツによって評価されるように、人間に近い品質で複雑なトピックに関するディベートをリアルタイムで生成できることを示しています。 、および競争力のある人間の討論を判断するために使用される戦略メトリック..文埋め込みモデルに依存しないもっともらしい討論を生成するためのフレームワークを開発します。 
[概要]高レベルの構造と文法を適用しながら、ディベートを生成するためのディベートツリーとパスを定義します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: A Unified Deep Speaker Embedding Framework for Mixed-Bandwidth Speech
  Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_21.html">
      <font color="black">A Unified Deep Speaker Embedding Framework for Mixed-Bandwidth Speech
  Data</font>
    </a>
  </h2>
  <font color="black">狭帯域スペクトログラムを広帯域スペクトログラムのサブイメージと見なし、画像分類の方法で混合帯域幅データの共同モデリング問題に取り組みます。VoxCeleb1データセットについて広範な実験的研究を行います。この観点から、詳細に説明します。さまざまなトレーニングおよびテストデータシナリオでのいくつかの混合帯域幅共同トレーニング戦略。 
[概要]提案されたシステムは、単一のスピーカー埋め込みモデルで混合帯域幅データを処理できる可能性があります。提案されたアプローチの有効性は、sitwおよびnist sre2016データセットによって検証されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: CLIMATE-FEVER: A Dataset for Verification of Real-World Climate Claims -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_22.html">
      <font color="black">CLIMATE-FEVER: A Dataset for Verification of Real-World Climate Claims</font>
    </a>
  </h2>
  <font color="black">人工的に設計されたクレームの最大のデータセットであるFEVER 
[1]の方法論を、インターネットから収集された実際のクレームに適合させます。フィーバー}フレームワークは、一般的な自然言語理解に貴重な課題を提供すると信じています。私たちの仕事が、気候科学とAIコミュニティによる新たな刺激的な長期共同努力の始まりとなることを願っています。 
[概要]私たちは、気候の証拠となるサポートを取得するためのアルゴリズムの改善に関する作業を促進および奨励することを目指しています-特定の主張。私たちの作業が、気候科学およびAIコミュニティによる人工的な挑戦の始まりとなることを願っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Intrinsic analysis for dual word embedding space models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_23.html">
      <font color="black">Intrinsic analysis for dual word embedding space models</font>
    </a>
  </h2>
  <font color="black">この論文では、これらすべてのバリエーションを考慮して、この質問に答えようとしています。最近の単語埋め込み手法は、過去のアトミック表現やスパース表現から離れて、連続ベクトル空間で単語を表現します。特にデュアルを検討すると、さらに1つのバリエーションが現れます。 1つではなく2つの単語の埋め込みを出力として生成する埋め込みスペース手法。 
[概要]最近の手法では、さらに複数の種類の埋め込みを作成できます。これらには、埋め込みディメンションの評価評価、コンテキストウィンドウのサイズ、トレーニング方法が含まれます。最後のword2vecレポートは、3つのタスクのうち2つでデフォルト以外のモデルが優先されることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Statistical patterns of word frequency suggesting the probabilistic
  nature of human languages -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_24.html">
      <font color="black">Statistical patterns of word frequency suggesting the probabilistic
  nature of human languages</font>
    </a>
  </h2>
  <font color="black">本研究は、本物の言語データに基づいて、言語学的普遍性、通時的ドリフト、言語変動などの重要な言語的問題が、パロールの確率と頻度パターンに変換できることを確認しました。これらの調査結果は、人間の言語が確率的である可能性があることを示唆しています。システムは本質的に、そしてその統計は人間の言語の固有の特性を作る可能性があります。伝統的な言語理論は主に言語を厳格な規則で構成される正式なシステムと見なしてきました。 
[抽象]言語は形式的システムよりも確率的システムである可能性があります。調査によると、言語は形式的システムよりも確率的です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: An Enhanced Knowledge Injection Model for Commonsense Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_25.html">
      <font color="black">An Enhanced Knowledge Injection Model for Commonsense Generation</font>
    </a>
  </h2>
  <font color="black">2つの追加モジュール、つまり位置インジケーターとスケーリングモジュールを、プロトタイプモデリング用の事前トレーニング済みエンコーダーデコーダーモデルに統合して、知識注入手順を強化します。CommonGenベンチマークで実験を行い、実験結果は、この方法でパフォーマンスが大幅に向上することを示しています。すべてのメトリック..常識的な生成は、提供された一連の概念に基づいて、もっともらしい日常のシナリオの説明を生成することを目的としています。 
[概要] commongenベンチマークで実験を行います。結果は、私たちの方法がパフォーマンスを大幅に改善することを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: EdgeBERT: Optimizing On-Chip Inference for Multi-Task NLP -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_26.html">
      <font color="black">EdgeBERT: Optimizing On-Chip Inference for Multi-Task NLP</font>
    </a>
  </h2>
  <font color="black">さらに、常時オンおよび中間エッジコンピューティング設定でこれらのアルゴリズムの利点を最大化するために、共有可能なマルチタスク埋め込みパラメーターの浮動小数点ビットエンコーディングが高密度の不揮発性に格納されるスケーラブルなハードウェアアーキテクチャを専門としています。メモリ..ALBERTベースラインと比較して、1）エントロピー-のキャリブレーションされた組み合わせを採用することにより、いくつかのGLUEベンチマークで精度の低下が1％-pt未満で、それぞれ最大2.4倍および13.4倍の推論レイテンシとメモリ節約を達成します。ベースの早期停止、2）適応型アテンションスパン、3）移動とマグニチュードのプルーニング、4）浮動小数点の量子化..全体として、EdgeBERTは、5.2倍、157倍低いエネルギーでNLPワークロードの完全なオンチップ推論アクセラレーションを可能にします。 Nvidia Jetson TegraX2モバイルGPUでの最適化されていないアクセラレータとCUDAの適応。 
[概要]最大2.4倍と13.4倍の想定レイテンシとメモリ節約をそれぞれ達成し、いくつかの接着剤ベンチマークで精度が1％未満低下します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-28">
        <br><font color="black">2020-11-28</font>
      </time>
    </span>
</section>
<!-- paper0: BAN-ABSA: An Aspect-Based Sentiment Analysis dataset for Bengali and
  it's baseline evaluation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_27.html">
      <font color="black">BAN-ABSA: An Aspect-Based Sentiment Analysis dataset for Bengali and
  it's baseline evaluation</font>
    </a>
  </h2>
  <font color="black">この論文では、高品質の手動で注釈を付けたベンガル語データセット、BAN-ABSAを提示します。これは、3人のネイティブベンガル語話者によってアスペクトとそれに関連する感情で注釈が付けられています。さらに、深層学習モデルに焦点を当てたベースライン評価を実施しました。 、アスペクト項抽出で78.75％の精度、感情分類で71.08％の精度を達成しました。データセットは、いくつかの有名なベンガルニュースポータルから収集された9,009の一意のコメントからの2,619ポジティブ、4,721ネガティブ、および1,669ニュートラルデータサンプルで構成されています。 
[概要]データセットは、いくつかの有名なベンガルニュースポータルから収集された9,09のユニークなコメントからの2、619のポジティブ、4、721のネガティブ、および1、669のニュートラルデータサンプルで構成されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Just Ask: Learning to Answer Questions from Millions of Narrated Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_28.html">
      <font color="black">Just Ask: Learning to Answer Questions from Millions of Narrated Videos</font>
    </a>
  </h2>
  <font color="black">この作業では、手動の注釈を避け、すぐに利用できる何百万ものナレーション付きビデオからビデオ質問応答（VideoQA）を学習することを提案します。このデータセット内の多様な回答のオープンボキャブラリーを処理するために、対照的なトレーニング手順を提案します。ビデオ質問マルチモーダルトランスフォーマーと回答の埋め込みの間の損失。さらに、ターゲットデータセットでモデルを微調整すると、MSRVTT-QA、MSVD-QA、およびActivityNet-QAの最新技術よりも大幅に優れていることを示します。 
[要約]ただし、ビデオの質問と回答の手動注釈は、疑わしく、費用がかかります。文字起こしされたビデオナレーションから質問と回答のペアを自動的に生成することを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Modifying Memories in Transformer Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/cs.CL/paper_29.html">
      <font color="black">Modifying Memories in Transformer Models</font>
    </a>
  </h2>
  <font color="black">トランスフォーマーの記憶と一般化を改善するタスクは広く研究されていますが、トランスフォーマーに特定の古い事実を忘れさせ、新しい事実を記憶させる方法はよく知られていません。これは、トランスフォーマーモデルの重要なコンポーネントの発見につながります。知識の変更に効果的です。特に、Transformerベースの言語モデルは、膨大な量のパラメーターで事実の知識をエンコードする優れた機能を備えていることが示されています。 
[ABSTRACT]トランスフォーマーベースの言語モデルは、膨大な量のパラメーターの重要な事実知識において優れた機能を備えていることが示されています。事実を含むトランスフォーマーベースの言語モデルの作業は、さまざまなトレーニングフェーズが暗記に向けて果たす役割についての洞察を提供します。と知識の変更</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Performing with a Mobile Computer System for Vibraphone -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.AS/paper_0.html">
      <font color="black">Performing with a Mobile Computer System for Vibraphone</font>
    </a>
  </h2>
  <font color="black">目的は、ラップトップコンピューターを使用することが難しいソロやアンサンブルの演奏状況にコンピューター音楽を浸透させるモバイルデバイスを使用して、軽量でコンパクトで柔軟なシステムを開発することでした。このプロセスはビデオ録画で文書化され、民族誌的手法を使用して分析されました。 ..シンプルなモバイルシステムは実験を促進し、使用されたプラットフォームはより広い聴衆との共有を可能にしました。 
[概要]このプロジェクトは、iphone、rjdj、純粋なデータ、自家製のピックアップシステムを使用して、コンピューター要素をパーカッションデュオのスイートであるnordligvinterにもたらすシステムに触発されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: The Zero Resource Speech Benchmark 2021: Metrics and baselines for
  unsupervised spoken language modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.AS/paper_1.html">
      <font color="black">The Zero Resource Speech Benchmark 2021: Metrics and baselines for
  unsupervised spoken language modeling</font>
    </a>
  </h2>
  <font color="black">言語モデルは、学習した表現のクラスタリングから派生した疑似テキストに基づいて学習します。また、同じデータでトレーニングされたテキストベースの「トップライン」システムと比較してパフォーマンスが低下し、より洗練された目的で探索されるスペースが示されます。 -to-endモデル..新しい監視されていないタスクである音声言語モデリングを紹介します。ラベルのない生のオーディオ信号からの言語表現の学習と、Zero Resource Speech Benchmark 2021：4つのブラックボックスのスイート、ゼロ-音声、レキシコン、構文、セマンティクスの4つの言語レベルで学習モデルの品質を調査するショットメトリック。 
[概要]教師なしシステムのリストが言語レベルの混合で提示されました。プロジェクトは、4つのメトリックすべてで偶然の学習よりも優れており、音声言語モデリングの実現可能性を示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Strike on Stage: a percussion and media performance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.AS/paper_2.html">
      <font color="black">Strike on Stage: a percussion and media performance</font>
    </a>
  </h2>
  <font color="black">大きな投影面がパフォーマーの真後ろに配置され、コンピュータービジョンシステムがパフォーマーの動きを追跡します。このペーパーでは、2010年にパーカッショニストとメディアアーティストChi-Hsiaによって開発および実行されたインターフェイスと対応するオーディオビジュアルパフォーマンス作品であるStrike onStageについて説明します。ライとチャールズ・マーティン..セットアップにより、コンピューターの視覚化と超音波処理を直接応答し、パフォーマーのジェスチャーと統合することができます。 
[概要]ステージでのストライキのコンセプトは、コンピューターのビジュアルとサウンドを即興のパーカッションパフォーマンスに統合することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Ad-hoc Beamforming Based on Speaker Extraction for Target-Dependent
  Speech Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.AS/paper_3.html">
      <font color="black">Deep Ad-hoc Beamforming Based on Speaker Extraction for Target-Dependent
  Speech Separation</font>
    </a>
  </h2>
  <font color="black">次に、選択したチャネルを深層学習ベースのMVDRアルゴリズムに適用します。ここでは、選択した各チャネルに単一チャネルの話者抽出アルゴリズムを適用して、ターゲット音声のマスクを推定します。アルゴリズムには3つのコンポーネントが含まれます。最近の研究ディープラーニングを備えたアドホックマイクアレイでは、特に音声の強調と分離において多くの注目が集まっています。 
[概要]アドホックマイクアレイは、混合音声からターゲットスピーカーを抽出することを目的としています。アドホックアレイ内の特定のスピーカーを抽出してトレースするために重要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Convolutive Transfer Function Invariant SDR training criteria for
  Multi-Channel Reverberant Speech Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.AS/paper_4.html">
      <font color="black">Convolutive Transfer Function Invariant SDR training criteria for
  Multi-Channel Reverberant Speech Separation</font>
    </a>
  </h2>
  <font color="black">これはよく知られている評価指標（BSS Eval）ですが、これまでトレーニング目標として使用されたことはありません。ここでは、ニューラルネットワークでサポートされるマルチチャネルソース分離を時間領域トレーニング目標関数と組み合わせることを提案します。このタスクでは、提案されたシステムは、単一ソースの非残響入力、つまりLibriSpeech test_cleanで得られたエラー率に、わずか1.2パーセントの差で近づきます。したがって、従来の順列不変トレーニングベースのシステムやスケール不変のような代替目的を上回ります。信号対歪み比が大幅に向上。 
[概要] librispeechベースの残響混合物でのパフォーマンスを実証しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: MTM Dataset for Joint Representation Learning among Sheet Music, Lyrics,
  and Musical Audio? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.AS/paper_5.html">
      <font color="black">MTM Dataset for Joint Representation Learning among Sheet Music, Lyrics,
  and Musical Audio?</font>
    </a>
  </h2>
  <font color="black">MTMデータセットコレクションの目標は、音符を楽譜と音楽オーディオに拡張することで制約を克服し、データセットを使用してマルチモーダル音楽データ全体の共同表現を学習できるように、音符と音節のきめ細かい配置を構築することです。データセットと使用例はhttps://github.com/MorningBooks/MTM-Datasetで入手できます。このペーパーでは、データセットとその構築方法について説明し、クロスモーダル検索タスクのいくつかのベースラインを評価します。 
[概要] mtmデータセットは、事前にトレーニングされたモデルによって構築された3つのモダリティを提供します。データセットと使用例はwwwで入手できます。 github。 com</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: A Unified Deep Speaker Embedding Framework for Mixed-Bandwidth Speech
  Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.AS/paper_6.html">
      <font color="black">A Unified Deep Speaker Embedding Framework for Mixed-Bandwidth Speech
  Data</font>
    </a>
  </h2>
  <font color="black">狭帯域スペクトログラムを広帯域スペクトログラムのサブイメージと見なし、画像分類の方法で混合帯域幅データの共同モデリング問題に取り組みます。この観点から、さまざまなトレーニングの下でいくつかの混合帯域幅共同トレーニング戦略を詳しく説明します。テストデータシナリオ..提案されたシステムは、追加のダウンサンプリング、アップサンプリング、帯域幅拡張、またはパディング操作なしで、単一スピーカー埋め込みモデルで混合帯域幅音声データを柔軟に処理できます。 
[概要]提案されたシステムは、単一のスピーカー埋め込みモデルで混合帯域幅データを処理できる可能性があります。提案されたアプローチの有効性は、sitwおよびnist sre2016データセットによって検証されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Tracking Ensemble Performance on Touch-Screens with Gesture
  Classification and Transition Matrices -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.AS/paper_7.html">
      <font color="black">Tracking Ensemble Performance on Touch-Screens with Gesture
  Classification and Transition Matrices</font>
    </a>
  </h2>
  <font color="black">システムはランダムフォレスト分類子を使用して、タッチスクリーンジェスチャと遷移行列統計を抽出します。システムについて説明し、クロス検証とプロファイリング、およびコンサートエクスペリエンスを通じて評価します。アンサンブルパフォーマンスを追跡するための新しいインターフェイスを提示および評価します。タッチスクリーンで。 
[概要]システムはランダムフォレスト分類器を使用して、タッチスクリーンジェスチャと遷移行列統計を抽出します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: NHSS: A Speech and Singing Parallel Database -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.AS/paper_8.html">
      <font color="black">NHSS: A Speech and Singing Parallel Database</font>
    </a>
  </h2>
  <font color="black">このデータベースは、英語のポップソングの歌声の録音、歌手が自然な読み方で読んだ曲の歌詞の音声版、および手動で作成された発話レベルと単語レベルの注釈で構成されています。NHSSの音声録音データベースは10人の歌手が歌って話した100曲に対応し、合計7時間の音声データになります。男性5人と女性5人の歌手がいて、それぞれ10曲の歌詞を歌って読んでいます。 
[概要] nhssデータベースの歌と録音の録音には合計7時間の音声データが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-artform performance using networked interfaces: Last Man to Die's
  Vital LMTD -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-02/eess.AS/paper_9.html">
      <font color="black">Cross-artform performance using networked interfaces: Last Man to Die's
  Vital LMTD</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、コンピュータービジョンサーフェスとネットワーク化された心拍センサーの芸術的な動機と設計、および最初の主要な作品であるVital LMTDのマウントの経験について説明します。2009年、クロスアートフォームグループのLast Man toDieが一連のパフォーマンスを発表しました。新しいインターフェースとネットワーク化されたパフォーマンスを使用して、メンバーの3つのアートフォーム（俳優、ハンナコーミック、ビジュアルアーティスト、ベンジャミンフォースター、パーカッショニスト、チャールズマーティン）を統合します。 
[概要]この論文では、コンピュータービジョンサーフェスやハートビートセンサーの設計など、その芸術的な動機について説明しています。また、最初の主要な作業である重要なlmtdのマウントの経験についても概説しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
