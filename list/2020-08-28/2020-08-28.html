<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-08-28の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Iterative Pseudo-Labeling for Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.SD/paper_0.html">
      <font color="black">Iterative Pseudo-Labeling for Speech Recognition</font>
    </a>
  </h2>
  <font color="black">また、さまざまなコーパスでトレーニングされた言語モデルがIPLで追加のテキストを効果的に利用できることを確認します。次に、両方の標準のLibrispeechテストセットで最先端の単語エラー率を達成することにより、IPLの有効性を示します。低リソース設定。IPLの主要コンポーネントである、言語モデルを使用したデコードとデータ拡張を研究します。 
[ABSTRACT]反復擬似ラベリング（ipl）は半教師付きアルゴリズムです。言語モデルとデータ拡張を使用してシステムを作成します。システムは追加のテキストを効果的に利用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-19">
        <br><font color="black">2020-05-19</font>
      </time>
    </span>
</section>
<!-- paper0: Device-Robust Acoustic Scene Classification Based on Two-Stage
  Categorization and Data Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.SD/paper_1.html">
      <font color="black">Device-Robust Acoustic Scene Classification Based on Two-Stage
  Categorization and Data Augmentation</font>
    </a>
  </h2>
  <font color="black">コードが利用可能です：https://github.com/MihawkHu/DCASE2020_task1 ..タスク1bでは、量子化手法を活用して、2つの最高精度の3クラスCNNベースのアーキテクチャの複雑さを軽減します。4つの異なるCNNベースのアーキテクチャは、2ステージの分類器を実装するために探索され、いくつかのデータ拡張手法も調査されます。 
[ABSTRACT]タスク1は、複数のデバイスで記録されたオーディオ信号のascを含みます。10の異なる細かいクラスがタスク1に含まれています。4つの異なるcnnベースのアーキテクチャが、2ステージの分類器を実装するために検討されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Speaker Re-identification with Speaker Dependent Speech Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.SD/paper_2.html">
      <font color="black">Speaker Re-identification with Speaker Dependent Speech Enhancement</font>
    </a>
  </h2>
  <font color="black">最近の研究は、音声強調の適応がさらなる利益につながる可能性があることを示しています。ここでは、音声強調方法により、従来からパフォーマンスの向上が可能になりました。音響環境。 
[ABSTRACT]スピーチの強化により、従来よりパフォーマンスの向上が可能になりました。これらには、強化されたスピーチの強化と話者認識が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-15">
        <br><font color="black">2020-05-15</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring British Accents: Modeling the Trap-Bath Split with Functional
  Data Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.SD/paper_3.html">
      <font color="black">Exploring British Accents: Modeling the Trap-Bath Split with Functional
  Data Analysis</font>
    </a>
  </h2>
  <font color="black">2番目の目的は、イギリスのアクセントの地理的変化を視覚化することです。特に、「クラス」のような単語の「a」の母音は、北と南では異なって発音されます。イギリスには、さまざまな独特のアクセントがあります。言語学に興味があります。 
[要約]最初の目的は、典型的な北部と南部の母音の違いをモデル化することです。訓練されたモデルを使用してbncの話者のアクセントを予測します。次に、石鹸膜の平滑化を使用して、これらの予測の地理的パターンをモデル化します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Weakly Supervised Training of Hierarchical Attention Networks for
  Speaker Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.SD/paper_4.html">
      <font color="black">Weakly Supervised Training of Hierarchical Attention Networks for
  Speaker Identification</font>
    </a>
  </h2>
  <font color="black">グローバル情報は最終的にセグメントレベルのモジュールから収集され、分類子を介して話者を予測します。結果は、妥当なセグメンテーションにより識別パフォーマンスがわずかに向上することを示しています。 
[要約]音声ストリームと機能はフラグメントにセグメント化されます。フレームはターゲットスピーカーに接続されていると考えられます。これは、これがエンコーダーの欠如によるものであることを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-15">
        <br><font color="black">2020-05-15</font>
      </time>
    </span>
</section>
<!-- paper0: Estimating Uniqueness of Human Voice UsingI-Vector Representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.SD/paper_5.html">
      <font color="black">Estimating Uniqueness of Human Voice UsingI-Vector Representation</font>
    </a>
  </h2>
  <font color="black">このデータを使用して、スピーカーの数、スピーカーごとのサンプル数、スピーカー内の変動のさまざまなレベルなど、いくつかの要因が推定にどのように影響するかを分析しました。次に、iのエントロピーを評価する、より適切な一意性測定を導入します。 -ベクトルは話者レベルの変動を考慮に入れています。特に、i-ベクトル要素の離散化が必ずしも話者認識パフォーマンスの低下を引き起こすわけではないと判断しました。 
[要旨]比較およびコントラストの一意性測定では、さまざまな生体認証モダリティを検討することが提案されています。i-行列要素の離散化では13への減少は発生しないことがわかりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: DrumGAN: Synthesis of Drum Sounds With Timbral Feature Conditioning
  Using Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.SD/paper_6.html">
      <font color="black">DrumGAN: Synthesis of Drum Sounds With Timbral Feature Conditioning
  Using Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">ドラムサウンドの合成作成（ドラムマシンなど）は、通常、アナログまたはデジタル合成を使用して実行され、ミュージシャンがさまざまなパラメーターを変更して目的の音色を作成できるようにします。通常、このようなパラメーターはサウンドの低レベルの機能を制御し、多くの場合、音楽的意味または知覚的対応..このホワイトペーパーでは、Generative Adversarial Networkをドラムサウンドのオーディオ合成のタスクに適用します。 
[ABSTRACT]合成パラメータは、サウンドの低レベルの機能を制御します。多くの場合、音楽的な意味や知覚的な対応はありません。この新しいディレクティブにより、高レベルの機能を学習して合成プロセスを制御できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Exploiting Temporal Attention Features for Effective Denoising in Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.IV/paper_0.html">
      <font color="black">Exploiting Temporal Attention Features for Effective Denoising in Videos</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーで使用するアテンションブロックは、ソフトアテンションを使用してフィルターをランク付けし、トレーニングを向上させます。提案された方法は、2ステージパイプラインの一部としてビデオフレームの時間的および空間的次元を利用します。Spatioという名前のアーキテクチャの各ステージ-TemporalNetworkは、チャネル単位の注意メカニズムを使用して、エンコーダー信号をデコーダー側に転送します。 
[要約]この方法は、ビデオフレームの時間的側面に基づいています。ビデオに適用される画像ノイズ除去アプローチは、ちらつきを引き起こします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Direct Adversarial Training for GANs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.IV/paper_1.html">
      <font color="black">Direct Adversarial Training for GANs</font>
    </a>
  </h2>
  <font color="black">同時に、この直接的な敵対トレーニングは、弁別器のリプシッツ定数を制限し、ジェネレーターの収束を加速できることを証明します。生成的敵対的ネットワーク（GAN）は、ディスクリミネーターとジェネレーターを共同で最適化することにより、画像生成の最も一般的なモデルです。このため、GANの直接敵対トレーニング手法を提案します。 
[ABSTRACT]そのため、ガン向けの直接敵対的トレーニング方法を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Cloze Test Helps: Effective Video Anomaly Detection via Learning to
  Complete Video Events -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.IV/paper_2.html">
      <font color="black">Cloze Test Helps: Effective Video Anomaly Detection via Learning to
  Complete Video Events</font>
    </a>
  </h2>
  <font color="black">言語学習で頻繁に使用されるクローズテストに触発され、私たちは上記のギャップを埋めるためにビデオイベント完了（VEC）という新しいVADソリューションを提案します。ただし、既存の方法は通常、再構成またはフレーム予測ルーチンに従います。このような視覚的凝固テストを構築するには、STCの特定のパッチを消去して、不完全なイベント（IE）を生成します。 
[ABSTRACT] dnnは、不足しているパッチを推測することにより、IEから元のビデオイベントを復元することを学習します。異なるタイプのIEとモダリティを使用する2つのアンサンブル戦略は、VADパフォーマンスを高めるために一般的に使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Mixed Noise Removal with Pareto Prior -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.IV/paper_3.html">
      <font color="black">Mixed Noise Removal with Pareto Prior</font>
    </a>
  </h2>
  <font color="black">既存の方法は、重み行列を導入することでINの影響を補償することを目標としていますが、これは適切なアプリオリが欠けているため正確に推定することが困難です。 （IN）は本質的ですが、挑戦的な問題です。特に、ピクセルの比較的小さな部分がINで汚染されていると想定されます。 
[ABSTRACT]衝動的な妨害の存在がノイズの分布を引き起こします。これにより、従来のawgnデノイザーのパフォーマンスが最終的に低下します。この問題に対処するには、パレート分布を重み付け行列のアプリオリとして利用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Compensation Tracker: Data Association Method for Lost Object -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.IV/paper_4.html">
      <font color="black">Compensation Tracker: Data Association Method for Lost Object</font>
    </a>
  </h2>
  <font color="black">これは、提案された方法がモデルの追跡パフォーマンスを効果的に改善できることを示しています。特に、高密度シナリオの2020データセットでは、マルチオブジェクト追跡の精度が66％に達しました。実験により、このホワイトペーパーで設計された補正トラッカーを使用した後、 、評価指標はMOTチャレンジデータセットでさまざまな程度で改善されています。 
[要約]新しい論文は、molmanフィルターと予測修正に基づいた補正トラッカーを開発しました。これは、密な方向のデータセットのデータセットに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Moderately supervised learning: definition and framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.IV/paper_5.html">
      <font color="black">Moderately supervised learning: definition and framework</font>
    </a>
  </h2>
  <font color="black">ただし、さまざまなFSLタスクのソリューションは、特定のグラウンドトゥルースラベルが常に学習可能であるわけではなく、特定のグラウンドトゥルースラベルから学習可能なターゲットへのターゲット変換が、最終的なFSLソリューションのパフォーマンスに大きな影響を与える可能性があることを示しています。特定のグラウンドトゥルースラベルから学習可能なターゲットへのターゲット変換のプロパティ、FSLカテゴリの粗さは、一部の特定のFSLタスクの最適なソリューションの構築に重要である可能性がある詳細を隠します。教師あり学習（SL）は、驚くべき成功を収めています。多くの人工知能アプリケーションで。 
[ABSTRACT] fslはおおまかに完全に教師あり学習（fsl）と定義され、wslではなく弱教師あり学習）.fslはfslと呼ばれ、指定された地面からのターゲット変換のプロパティに基づいています。fslカテゴリの粗さ特定のfslタスクに最適なソリューションを構築するために重要な可能性がある詳細を隠します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: DMD: A Large-Scale Multi-Modal Driver Monitoring Dataset for Attention
  and Alertness Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.IV/paper_6.html">
      <font color="black">DMD: A Large-Scale Multi-Modal Driver Monitoring Dataset for Attention
  and Alertness Analysis</font>
    </a>
  </h2>
  <font color="black">DMDの使用法は、DLトレーニングプロセスで使用するために準備された、13の気晴らし活動を含むdBehaviourMDデータセットのサブセットを抽出することによって示されています。DMDがより広範囲であることを示す既存の同様のデータセットとの比較が含まれています。多様で多目的..このペーパーでは、ドライバーモニタリングデータセット（DMD）を紹介します。これは、実際のシミュレーションシナリオとシミュレーションされた運転シナリオ（注意散漫、視線割り当て、眠気、ハンドル操作とコンテキストデータ）を含む広範なデータセットです。 37人のドライバーの顔、体、手をキャプチャする3台のカメラからのRGB、深度、IRビデオの数時間。 
[ABSTRACT]図示されたデータセットの欠如は、dms development.dmdの進行のボトルネックです。dmdは、より広範で、多様で、マルチドリンクです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Edge and Identity Preserving Network for Face Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.IV/paper_7.html">
      <font color="black">Edge and Identity Preserving Network for Face Super-Resolution</font>
    </a>
  </h2>
  <font color="black">顔の超解像は、ビデオ監視や識別システムなどのセキュリティの問題に不可欠な要素になっていますが、顔のコンポーネントの歪みが問題を克服するための主な障害となっています。具体的には、エッジブロックは知覚的なエッジ情報を抽出し、元のエッジに連結します。複数のスケールでの機能マップ..これらの方法では、追加のラベル、長いトレーニング時間、およびより大きな計算メモリが必要です。 
[ABSTRACT] lceメソッドは、明るさと色のコンポーネントを分割することで、色情報の依存性を減らします。また、複数のドメイン（rgbとyuv）の超解像（sr）と高解像度（hr）の画像の違いをネットワークに反映できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Random Style Transfer based Domain Generalization Networks Integrating
  Shape and Spatial Information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.IV/paper_8.html">
      <font color="black">Random Style Transfer based Domain Generalization Networks Integrating
  Shape and Spatial Information</font>
    </a>
  </h2>
  <font color="black">深層学習（DL）ベースのモデルは、医用画像のセグメンテーションで優れたパフォーマンスを示しています。モデルは、教師付きセグメンテーションと教師なしスタイルの翻訳目的を同時に最適化することにより、半教師付きの方法でトレーニングできます。40で提案されたフレームワークを評価しました。 M \＆Ms challenge2020の被験者であり、未知のベンダーやセンターからのデータのセグメンテーションで有望なパフォーマンスを獲得しました。 
[ABSTRACT]モデルは、教師ありセクションと教師なしスタイルの翻訳目標を同時に最適化することにより、半教師付き方法でトレーニングできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: A multi-channel framework for joint reconstruction of multi-contrast
  parallel MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.IV/paper_9.html">
      <font color="black">A multi-channel framework for joint reconstruction of multi-contrast
  parallel MRI</font>
    </a>
  </h2>
  <font color="black">重要性：圧縮センシング、マルチコントラスト、パラレルイメージングは個別に十分に開発されていますが、3つの組み合わせは十分に研究されておらず、そのような設定での等方性の潜在的な利点ははるかに劣っています。結果：他のよく知られているものと比較最先端の方法により、画質が大幅に改善され、コントラスト固有の詳細が他のコントラストに漏れることなく維持されます。このホワイトペーパーでは、新しい等方性マルチチャネルイメージレギュラライザを導入し、その完全な可能性を実現しています。圧縮マルチコントラストマルチコイルMRIへの統合。 
[ABSTRACT]新しい方法は、マルチコントラストパラレルmriの実行可能なオプションです。これは、新しい等方性マルチチャネルイメージレギュラライザーによって開発されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-07">
        <br><font color="black">2020-06-07</font>
      </time>
    </span>
</section>
<!-- paper0: Crossing-Domain Generative Adversarial Networks for Unsupervised
  Multi-Domain Image-to-Image Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.IV/paper_10.html">
      <font color="black">Crossing-Domain Generative Adversarial Networks for Unsupervised
  Multi-Domain Image-to-Image Translation</font>
    </a>
  </h2>
  <font color="black">n個のドメイン間で画像を変換する必要がある場合、2つのドメイン間でトレーニングを実行すると、トレーニングの複雑さが二次的に増加します。フレームワークの副産物は、必要なため、計算時間と計算リソースの削減です。最先端の作品で行われているように、ペアでドメインをトレーニングするよりも短い時間です。私たちのフレームワークは、最先端の手法と比較して、多くの画像間タスクで競合する結果を示しています。 
[ABSTRACT]一度に2つのドメインのデータのみを使用してトレーニングすると、他のドメインのメリットが得られ、より有用な機能の抽出が妨げられます。ドメインの副産物は、計算時間と計算リソースの削減です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Lymph Node Gross Tumor Volume Detection and Segmentation via
  Distance-based Gating using 3D CT/PET Imaging in Radiotherapy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.IV/paper_11.html">
      <font color="black">Lymph Node Gross Tumor Volume Detection and Segmentation via
  Distance-based Gating using 3D CT/PET Imaging in Radiotherapy</font>
    </a>
  </h2>
  <font color="black">人間の観察者は感度が低い傾向があるため（文献で報告されているように、経験豊富な放射線腫瘍医の場合は約$ 80 \％$）、$ 20 \％$の精度で$ 82.5 \％$の最高達成GTVLNリコールは臨床的に関連し、価値があります。新規のマルチブランチセグメンテーション別ネットワークは、各ブランチが1つのGTVLNカテゴリ機能の学習に特化してトレーニングされ、マルチブランチからの出力が推論で融合されます。イメージングは最も重要な臨床課題です。 
[ABSTRACT]放射線療法では、これらは必須リンパ節総腫瘍体積（gtvln）と呼ばれます。この作業では、放射線腫瘍医が実施する高レベルの推論プロトコルをシミュレーションおよび簡略化するための効果的な距離ベースのゲーティングアプローチを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: TResNet: High Performance GPU-Dedicated Architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.IV/paper_12.html">
      <font color="black">TResNet: High Performance GPU-Dedicated Architecture</font>
    </a>
  </h2>
  <font color="black">最初に、FLOPs最適化によって引き起こされるボトルネックを示し、説明します。次に、GPU構造と資産をより有効に活用する代替設計を提案します。ResNet50と同様のGPUスループットを持つTResNetモデルを使用すると、ImageNetで80.8のトップ1の精度に達します。 
[ABSTRACT] vanilla resnet50は通常、最近の競合他社よりも大幅に高速です。スループットが向上します-精度のトレードオフ。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br><font color="black">2020-03-30</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised MRI Super-Resolution using Deep External Learning and
  Guided Residual Dense Network with Multimodal Image Priors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.IV/paper_13.html">
      <font color="black">Unsupervised MRI Super-Resolution using Deep External Learning and
  Guided Residual Dense Network with Multimodal Image Priors</font>
    </a>
  </h2>
  <font color="black">この論文では、人体解剖学の簡単な事前知識に基づいた教師なしSISR手法を提案します。この手法ではトレーニングにHR画像は必要ありません。高解像度（HR）と低解像度（LR）の画像のペアを使用して、深層学習モデル（マッピング関数）をトレーニングします。これらの手法は医療画像にも適用されています。超解像（SR）。 
[ABSTRACT]高技術（hr）および低解像度（lr）画像は、深層学習モデル（マッピング関数）をトレーニングするために使用されます。これらの技術には、医療画像が含まれ、医療画像にはいくつかのユニークな特性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Recurrent Model for Individualized Prediction of Alzheimer's
  Disease Progression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.IV/paper_14.html">
      <font color="black">Deep Recurrent Model for Individualized Prediction of Alzheimer's
  Disease Progression</font>
    </a>
  </h2>
  <font color="black">そのような不利な状況に関して、我々はそれらの欠損値を推定する二次問題を定義し、時系列データに固有の時間的および多変量関係を考慮に入れて体系的な方法でそれに取り組みます。アルツハイマー病（AD）は、認知症の主な原因であり、治療や利用可能な薬がない、数年にわたるゆっくりとした進行を特徴とします。これまでの研究の多くは断面分析を考慮していましたが、より最近の研究では、縦断的または進行性のADの診断と予後に焦点を当てています疾患進行モデリング（DPM）の方法で時系列データ。 
[ABSTRACT]この場合、欠損データを推定するという二次的な問題を定義し、体系的に取り組みます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br><font color="black">2020-05-06</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Visual Question Answering on Image Sets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_0.html">
      <font color="black">Visual Question Answering on Image Sets</font>
    </a>
  </h2>
  <font color="black">自然言語の質問と一連の画像を入力として受け取り、画像の内容に基づいて質問に回答することを目的としています。一般的に研究されている単一の質問を一般化する画像セット視覚質問応答（ISVQA）のタスクを紹介します。マルチ画像設定に対する画像VQA問題。質問と回答の分布、質問のタイプ、データセットのバイアス、質問画像の依存関係など、2つのデータセットのプロパティを分析します。 
[概要] 2つのisvqaデータセット-屋内と屋外のシーンを紹介します。実際の質問は、画像の内容に基づいて質問に回答するために使用されます。また、isvqaの新しい研究課題を調査するための新しいベースラインモデルを構築します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Webly Supervised Image Classification with Self-Contained Confidence -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_1.html">
      <font color="black">Webly Supervised Image Classification with Self-Contained Confidence</font>
    </a>
  </h2>
  <font color="black">Webラベルまたは疑似ラベルの正確さは通常、Webサンプルごとにケースバイケースであるので、$ \ mathcal {L} _s $と$ \ mathcal {L} _w $の間のバランスを調整することが望ましい信頼性予測におけるディープニューラルネットワーク（DNN）の機能に触発されて、WSL設定のモデルの不確実性を適応させることにより自己完結型信頼性（SCC）を導入し、それを使用して$ \ mathcal {L } _s $と$ \ mathcal {L} _w $ ..この問題を緩和するために、最近の作品では、自己ラベル付き教師付き損失$ \ mathcal {L} _s $がWeb教師付き損失$ \ mathcal {L} _wと一緒に利用されています$。 
[ABSTRACT]ウェブラベルは、画像分類モデルのパフォーマンスの向上を妨げます。ウェブベースのウェブベースのウェブラベルは、事前注文のユーザーが利用できます。これは、信頼性予測におけるディープニューラルネットワーク（dnns）の機能に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: A Self-Reasoning Framework for Anomaly Detection Using Video-Level
  Labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_2.html">
      <font color="black">A Self-Reasoning Framework for Anomaly Detection Using Video-Level
  Labels</font>
    </a>
  </h2>
  <font color="black">より具体的には、異常にラベル付けされたビデオには、実際には短時間だけ異常が含まれ、残りのビデオフレームは正常である可能性があります。自己推論ベースのトレーニングを実行するには、時空間のバイナリクラスタリングを使用して疑似ラベルを生成します。異常なビデオのラベルに存在するノイズを軽減するのに役立つビデオ機能。提案されたフレームワークは、UCF犯罪、ShanghaiTech、UCSD Ped2を含む、公開されている現実の異常検出データセットで評価されています。 
[ABSTRACT] shanghai.itの異常検出フレームワークは、ビデオのみを使用して自己推論の方法でトレーニングされたディープニューラルネットワークに基づいています-レベルラベル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning for 2D grapevine bud detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_3.html">
      <font color="black">Deep Learning for 2D grapevine bud detection</font>
    </a>
  </h2>
  <font color="black">そのパフォーマンスを検証するために、このアーキテクチャは、検出タスクで芽の検出のための強力なメソッド、パッチ分類子メソッドを使用したスキャンウィンドウと比較され、検出の3つの側面（セグメンテーション、対応識別、およびローカリゼーション）に対する改善が示されています。 FCN-MNのこれらの結果は、変数の芽数、芽の面積、および節間長の十分に正確な測定値を生成し、実用的なセットアップでの良好なパフォーマンスを示唆します。アーキテクチャ（FCN-MN）。 
[要約]ブドウのつぼみを検出するためのコンピューター手法は、完全畳み込みネットワークモバイルネットアーキテクチャ（fcn-mn）に基づいています。現在のアプローチでは、検出精度が$ 95. 6＆$、検出再現率が$ 93. 6および$ 89. 1</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Exploiting Temporal Attention Features for Effective Denoising in Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_4.html">
      <font color="black">Exploiting Temporal Attention Features for Effective Denoising in Videos</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーで使用するアテンションブロックは、ソフトアテンションを使用してフィルターをランク付けし、トレーニングを向上させます。ビデオ処理パイプラインの基本的なタスク。 
[要約]この方法は、ビデオフレームの時間的側面に基づいています。ビデオに適用される画像ノイズ除去アプローチは、ちらつきを引き起こします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Direct Adversarial Training for GANs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_5.html">
      <font color="black">Direct Adversarial Training for GANs</font>
    </a>
  </h2>
  <font color="black">生成的敵対的ネットワーク（GAN）は、弁別器と生成器を共同で最適化することによる画像生成の最も人気のあるモデルです。このホワイトペーパーでは、生成器が訓練プロセス中に弁別器の敵対的な例を生成する可能性があることを分析しました。 GANs ..同時に、この直接的な敵対的トレーニングが弁別子のリプシッツ定数を制限し、ジェネレーターの収束を加速できることを証明します。 
[ABSTRACT]そのため、ガン向けの直接敵対的トレーニング方法を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Cloze Test Helps: Effective Video Anomaly Detection via Learning to
  Complete Video Events -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_6.html">
      <font color="black">Cloze Test Helps: Effective Video Anomaly Detection via Learning to
  Complete Video Events</font>
    </a>
  </h2>
  <font color="black">（2）それらには、高レベルのセマンティクスと時間的コンテキスト情報を利用するための十分な能力がありません。正規化された時空間キューブ（STC）は、ビデオイベントとして各RoIから構築され、VECの基礎を築き、基本的な処理として機能します。ユニットは、2つのギャップに悩まされています。（1）ビデオ活動を正確かつ包括的にローカライズすることはできません。 
[ABSTRACT] dnnは、不足しているパッチを推測することにより、IEから元のビデオイベントを復元することを学習します。異なるタイプのIEとモダリティを使用する2つのアンサンブル戦略は、VADパフォーマンスを高めるために一般的に使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Inner Eye Canthus Localization for Human Body Temperature Screening -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_7.html">
      <font color="black">Inner Eye Canthus Localization for Human Body Temperature Screening</font>
    </a>
  </h2>
  <font color="black">次に、眼球に対応する小さな領域を手動で選択することにより、追加の注釈でデータセットを強化します。次に、3D Morphable Face Model（3DMM）を使用してスパース2D-3Dポイント対応を計算します。ただし、このような手動注釈は通常、目、鼻、口などの顔のパーツを特定するために考案されており、眼の眼球領域を特定するために特別に調整されていません。 
[ABSTRACT]さらに、注釈付きのランドマークを使用して元のデータセットを充実させ、3dmmを変形して画像に投影します。データは一般公開されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: A Benchmark for Inpainting of Clothing Images with Irregular Holes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_8.html">
      <font color="black">A Benchmark for Inpainting of Clothing Images with Irregular Holes</font>
    </a>
  </h2>
  <font color="black">実験は、拡張部分畳み込み（DPConv）が他のインペインティング戦略と比較して定量的インペインティングのパフォーマンスを向上させることを示しています。特に、マスクサイズがイメージの20％以上の場合に、パフォーマンスが向上します。\ keywords {イメージインペインティング、ファッションイメージの理解、拡張された畳み込み、部分的な畳み込み。さらに、マスク更新ステップを効率的に導出する部分畳み込みの拡張バージョンの使用を紹介し、提案された方法が完全に透明なマスクを形成するために必要な層数を削減することを経験的に示します。 
[ABSTRACT]衣服の画像の修復はまだ十分に検討されていません。たとえば、部分的な描画の拡張バージョンの使用を紹介します。提案された方法は、完全に透明なマスクを形成するために必要なレイヤー数を削減します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Lightweight Lane Detection by Optimizing Spatial Embedding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_9.html">
      <font color="black">Towards Lightweight Lane Detection by Optimizing Spatial Embedding</font>
    </a>
  </h2>
  <font color="black">想定される強みの1つである畳み込みの並進不変性は、ピクセルの埋め込みを最適化する上で課題を引き起こします。この提案された方法は、中心位置特定のための後処理ステップを可能にし、エンドツーエンドの方法でクラスタリングを最適化します。.提案された方法後処理の簡素化と軽量バックボーンの採用により、リアルタイムのレーン検出を可能にします。 
[要約]提案された方法は、リアルタイムのシンプルさと軽量バックボーンの採用により、リアルタイムのレーン検出を可能にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Instance Adaptive Self-Training for Unsupervised Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_10.html">
      <font color="black">Instance Adaptive Self-Training for Unsupervised Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">&#39;GTA5 to Cityscapes&#39;と &#39;SYNTHIA to Cityscapes&#39;の実験は、最先端の方法と比較して私たちのアプローチの優れたパフォーマンスを実証しています。メソッドでは、スケーラビリティとパフォーマンスのバランスをとることが困難です。 
[ABSTRACT]教師なしドメインアプローチの教師なしパフォーマンスは、この問題を解決しようとします。最近の方法では、スケーラビリティとパフォーマンスのバランスをとることが困難です。たとえば、インスタンス適応型セレクターを使用して新しい疑似ラベル生成戦略を開発します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Mixed Noise Removal with Pareto Prior -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_11.html">
      <font color="black">Mixed Noise Removal with Pareto Prior</font>
    </a>
  </h2>
  <font color="black">特に、ピクセルの比較的小さな部分はINで汚染されていると想定され、小さな値の重みがあり、ペナルティが科されます。既存の方法は、重み行列を導入することでINの影響を補償することを目標としていますが、この現象は、タイプ1のパレート分布によって適切に説明できます。
[要約]衝動的な外乱の存在がノイズの分布を引き起こします。これにより、従来のawgnデノイザーのパフォーマンスが最終的に低下します。この問題に対処するため、加重行列のアプリオリとしてパレート分布を利用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Compensation Tracker: Data Association Method for Lost Object -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_12.html">
      <font color="black">Compensation Tracker: Data Association Method for Lost Object</font>
    </a>
  </h2>
  <font color="black">これは、提案された方法がモデルの追跡パフォーマンスを効果的に改善できることを示しています。実験では、このホワイトペーパーで設計された補正トラッカーを使用した後、評価指標がMOTチャレンジデータセットのさまざまな程度で改善されたことを示しています。特に、マルチ高密度シナリオの2020データセットでは、オブジェクト追跡の精度が66％に達しました。 
[要約]新しい論文は、molmanフィルターと予測修正に基づいた補正トラッカーを開発しました。これは、密な方向のデータセットのデータセットに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Surgical Instrument Segmentation via Anchor Generation and
  Semantic Diffusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_13.html">
      <font color="black">Unsupervised Surgical Instrument Segmentation via Anchor Generation and
  Semantic Diffusion</font>
    </a>
  </h2>
  <font color="black">2017 MICCAI EndoVis Robotic Instrument Segmentation Challengeデータセットのバイナリインストゥルメントセグメンテーションタスクの実験では、提案された方法は、単一の手動アノテーションを使用せずに0.71 IoUおよび0.81 Diceスコアを達成します。これは、手術ツールの教師なし学習の可能性を示すことが約束されています。セグメンテーション..私たちのモデルをトレーニングするために、まず粗い手がかりを融合することにより、器具と背景組織の疑似ラベルとしてそれぞれアンカーを生成します。このタスクに関する既存の作業は、面倒な大量のラベル付きデータの監視に大きく依存しています。高価な人間の努力。 
[要約] 2017年のマイカイエンドビスロボット装置のセグメンテーションチャレンジデータセットの提案された方法は、単一の手動アノテーションを使用せずに0. 71 iouおよび0. 81のサイコロスコアを達成するための単純な方法を使用します。手術器具のセグメンテーション</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: A Flexible Selection Scheme for Minimum-Effort Transfer Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_14.html">
      <font color="black">A Flexible Selection Scheme for Minimum-Effort Transfer Learning</font>
    </a>
  </h2>
  <font color="black">層）ネットワークを調整することができ、最も有望なものが自動的に選択されます。結局のところ、一般的な方法とは対照的に、最後に完全に接続されたユニットではなく、多くの中間または初期のユニットを調整するのが最善です。フレックスチューニングによって正確に検出されるドメインシフトシナリオ。この方法を実用的に魅力的なものにするために、2つの軽量で高速な選択手順を提案します。 
[ABSTRACT]ネットワークを調整することができ、最も視覚的なタスクが自動的に選択されます。これは、トレーニングソースほどクリーンではないためです。これは、トレーニングフォームほどクリーンではない実際のデータで発生します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: SegFix: Model-Agnostic Boundary Refinement for Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_15.html">
      <font color="black">SegFix: Model-Agnostic Boundary Refinement for Segmentation</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、セグメンテーションモデルの事前情報を必要とせず、ほぼリアルタイムの速度を実現します。境界ピクセルから内部ピクセルへの方向を学習することで対応を構築します。コードはhttps://github.comで入手できます。 /openseg-group/openseg.pytorch。 
[ABSTRACT]元の-信頼性の低い境界ピクセル予測を置き換えることをお勧めします。境界ピクセルから離れて内部ピクセルへの方向を学習することで、対応を構築します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Dual Distinct Classifiers for Unsupervised Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_16.html">
      <font color="black">Adversarial Dual Distinct Classifiers for Unsupervised Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">具体的には、ドメイン不変の特徴ジェネレーターを利用して、ソースドメインとターゲットデータを潜在的な共通空間に埋め込み、特徴的なクロスドメインアライメントのガイダンスを行います。しかし、それらのほとんどは、異なるドメインの特徴分布と一致させようとしています。さまざまなクラスにまたがるタスク固有の意思決定の境界を検討します。いくつかのクロスドメインビジュアルベンチマークでの広範な実験結果は、他の最先端のUDAと比較することでモデルの有効性を証明します。 
[ABSTRACT]従来のudaは、ディープアドバタリアルネットワークを通じてドメイン関連の機能を抽出することに集中しています。これらの機能のほとんどは、ラベル付けされていないだけでなく、クロスドメインのビジュアルベンチマークです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Robust Clustering by Contrastive Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_17.html">
      <font color="black">Deep Robust Clustering by Contrastive Learning</font>
    </a>
  </h2>
  <font color="black">既存の方法とは異なり、DRCは、意味的クラスタリングの割り当てと表現機能の両方の2つの視点からディープクラスタリングを調べます。これにより、クラス間多様性を増加させ、クラス内多様性を同時に減少させることができます。さらに、あらゆる最大化を可能にする一般的なフレームワークを要約しました。相互情報と対比学習の間の内部関係を調査することにより、相互情報を対照的損失を最小化します。この欠点に対処するために、Deep Robust Clustering（DRC）を提案しました。 
[ABSTRACT] drcは2つの視点からディープクラスタリングを調べます。これにより、クラス間の多様性が増加し、同時にクラス内の多様性が減少する可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-07">
        <br><font color="black">2020-08-07</font>
      </time>
    </span>
</section>
<!-- paper0: Traces of Class/Cross-Class Structure Pervade Deep Learning Spectra -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_18.html">
      <font color="black">Traces of Class/Cross-Class Structure Pervade Deep Learning Spectra</font>
    </a>
  </h2>
  <font color="black">クロスクラス構造の重要性は、次の3つの方法で説明されています。（i）多項ロジスティック回帰のコンテキストで、フィッシャー情報行列のスペクトルの異常値とバルクの比率が誤分類を予測できることを証明します。 （ii）クラス識別情報を直交化しながら、ネットワークがクラス識別情報をクラス可変性から徐々に深める方法を示します。 （iii）ディープネットをトレーニングするためのよく知られている2次最適化アルゴリズムであるKFACへの修正を提案します。これらには、スペクトルの外れ値「スパイク」、エッジの向こう側に見られる小さいが明確な連続分布「バンプ」が含まれます。 「主要なバルク」の..多くの研究者は最近、経験的なスペクトル分析を現代の深層学習分類器の研究に適用しました。 
[ABSTRACT]重要な正式なクラス/クラス間の構造を特定して説明します。これは、ディープネットスペクトルで観察される多くの視覚的に印象的な機能の起源にあります。これらには、次のものが含まれます。漁師情報マトリックス」</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-View Fusion of Sensor Data for Improved Perception and Prediction
  in Autonomous Driving -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_19.html">
      <font color="black">Multi-View Fusion of Sensor Data for Improved Perception and Prediction
  in Autonomous Driving</font>
    </a>
  </h2>
  <font color="black">融合された機能は、さらに処理されて、単一のエンドツーエンドのトレーニング可能なネットワーク内で、最終的な検出と軌跡を出力します。提案されたアプローチは、以下によって収集された独自の大規模な実世界データに関する最新技術を改善します。自動運転車両の群れ、および公共のnuScenesデータセット上。ネイティブの非量子化表現で未加工のLiDAR情報を使用する追加のLiDAR Range-View（RV）機能でBEVネットワークを拡張します。 
[ABSTRACT]私たちの方法は、最新の鳥瞰図（bev）ネットワークに基づいて構築されています。これは、過去のLIDARデータのシーケンスからボクセル化された機能を融合します。LIDARとカメラのrv融合は、簡単な方法で実行されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Adaptation Through Task Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_20.html">
      <font color="black">Domain Adaptation Through Task Distillation</font>
    </a>
  </h2>
  <font color="black">ただし、シミュレーションと実際のビジュアルエクスペリエンスは大幅に異なるため、この転送は困難です。ディープネットワークは、正確に注釈が付けられた何百万もの画像を食い込み、複雑で強力な表現を構築します。これらの認識データセットを使用して、転送元と転送先ドメインをリンクしますタスク蒸留フレームワークにおけるそれらの間のモデル。 
[ABSTRACT]画像認識などの特定のタスクでは、データセットが豊富です。これらは、ソースとターゲットのドメインをリンクして、タスク蒸留フレームワークでそれらの間でモデルを転送するために使用されます。標準ドメインで有望な結果が表示されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Surgical Skill Assessment on In-Vivo Clinical Data via the Clearness of
  Operating Field -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_21.html">
      <font color="black">Surgical Skill Assessment on In-Vivo Clinical Data via the Clearness of
  Operating Field</font>
    </a>
  </h2>
  <font color="black">ニューラルネットワークは、教師あり回帰損失と教師なしランク損失で共同でトレーニングされます。次に、ニューラルネットワークに基づく客観的で自動化されたフレームワークが提案され、COFのプロキシを通じて外科的スキルを予測します。このデータセットの分析から、手術野（COF）は、全体的なスキルとの強い相関とアノテーター間の高い一貫性を考慮して、全体的な外科的スキルの優れたプロキシとして識別されます。 
[要約]手術野（cof）の明確さは、全体的な外科的スキルの優れた代用として識別されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-task deep CNN model for no-reference image quality assessment on
  smartphone camera photos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_22.html">
      <font color="black">Multi-task deep CNN model for no-reference image quality assessment on
  smartphone camera photos</font>
    </a>
  </h2>
  <font color="black">畳み込み層の共有モデルパラメーターを使用すると、学習されたフィーチャーマップはシーンに関連し、パフォーマンスを向上させることができます。スマートフォンは、今日のモバイルソーシャルネットワーク時代で最も成功した家電製品です。評価結果は、比較されたSROCCパフォーマンスの向上を示しています。従来のNR-IQAメソッドと単一タスクのCNNベースのモデルに。 
[ABSTRACT]スマートフォンのカメラの品質と画像の後処理機能は、消費者の購入決定に影響を与える主要な要素です。以前のcnnベースのnr-iqaアプローチの拡張として、シーンタイプのマルチタスクディープcnnモデルを提案します補助タスクとしての検出</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Moderately supervised learning: definition and framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_23.html">
      <font color="black">Moderately supervised learning: definition and framework</font>
    </a>
  </h2>
  <font color="black">教師あり学習（SL）は、多数の人工知能アプリケーションで顕著な成功を収めています。特定のグラウンドトゥルースラベルから学習可能なターゲットへのターゲット変換の特性を考慮せずに、FSLカテゴリの粗さは、構築に重要ないくつかの詳細を隠します特定のFSLタスクに最適なソリューション。したがって、これらの詳細を明らかにすることが望ましいです。 
[ABSTRACT] fslはおおまかに完全に教師あり学習（fsl）と定義され、wslではなく弱教師あり学習）.fslはfslと呼ばれ、指定された地面からのターゲット変換のプロパティに基づいています。fslカテゴリの粗さ特定のfslタスクに最適なソリューションを構築するために重要な可能性がある詳細を隠します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: CenterHMR: a Bottom-up Single-shot Method for Multi-person 3D Mesh
  Recovery from a Single Image -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_24.html">
      <font color="black">CenterHMR: a Bottom-up Single-shot Method for Multi-person 3D Mesh
  Recovery from a Single Image</font>
    </a>
  </h2>
  <font color="black">代わりに、この論文では、新しいボトムアップのシングルショット法であるセンターベースのヒューマンメッシュリカバリネットワーク（CenterHMR）を紹介します。 、これにより、オクルージョン下でのロバスト性が向上します。たとえば、分離できない混雑したケースから複数人の3Dメッシュを推定することは困難です。 
[ABSTRACT]さらに、各人の3Dメッシュ結果は、目に見える身体部分を中心とした特徴から推定され、オクルージョン下でのロバスト性が向上します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Graph Structure of Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_25.html">
      <font color="black">Graph Structure of Neural Networks</font>
    </a>
  </h2>
  <font color="black">ここでは、ニューラルネットワークのグラフ構造が予測パフォーマンスにどのように影響するかを体系的に調査します。このために、ニューラルネットワーク計算のレイヤーがメッセージ交換のラウンドに対応するリレーショナルグラフと呼ばれるニューラルネットワークの新しいグラフベースの表現を開発します。グラフの構造。この表現を使用して、次のことを示します。（1）リレーショナルグラフの「スイートスポット」により、予測性能が大幅に向上したニューラルネットワークにつながる。 （2）ニューラルネットワークのパフォーマンスは、クラスタリング係数とその関係グラフの平均パス長のほぼ滑らかな関数です。 （3）私たちの調査結果は、多くの異なるタスクとデータセットにわたって一貫しています。 （4）スイートスポットを効率的に特定できます。 （5）最高性能のニューラルネットワークは、実際の生物学的ニューラルネットワークと驚くほど似たグラフ構造を持っています。 
[ABSTRACT]私たちの仕事は、ニューラルアーキテクチャの設計とニューラルネットワークの一般的な理解のための新しい方法を開きます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-13">
        <br><font color="black">2020-07-13</font>
      </time>
    </span>
</section>
<!-- paper0: DeepFake Detection Based on the Discrepancy Between the Face and its
  Context -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_26.html">
      <font color="black">DeepFake Detection Based on the Discrepancy Between the Face and its
  Context</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチには2つのネットワークが含まれます：（i）厳格なセマンティックセグメンテーションによって囲まれた顔領域を考慮する顔識別ネットワーク、および（ii）顔のコンテキスト（髪、耳、首など）を考慮するコンテキスト認識ネットワーク。このメソッドは、顔操作検出のFaceForensics ++、Celeb-DF-v2、およびDFDCベンチマークで最先端の結果を達成し、目に見えないメソッドによって生成された偽物を検出するために一般化さえします。 
[ABSTRACT] deepfakeなどのフェイススワッピングテクニックは不一致を検出できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: learn2learn: A Library for Meta-Learning Research -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_27.html">
      <font color="black">learn2learn: A Library for Meta-Learning Research</font>
    </a>
  </h2>
  <font color="black">メタラーニング研究者は、経験的研究で2つの基本的な問題に直面しています。プロトタイピングと再現性です。learn2learnは、広範囲のメタラーニング手法（例：メタ降下、メタ強化学習、少数ショット）に共通する低レベルのルーチンを提供します。学習）、アルゴリズムとベンチマークの標準化されたインターフェイスをそれらの上に構築します。 
[ABSTRACT]新しいアルゴリズムのプロトタイプを作成するときに、研究者は間違いを犯しがちです。つまり、ソフトウェアの実装に膨大な時間を費やしています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Fingerprint Feature Extraction by Combining Texture, Minutiae, and
  Frequency Spectrum Using Multi-Task CNN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_28.html">
      <font color="black">Fingerprint Feature Extraction by Combining Texture, Minutiae, and
  Frequency Spectrum Using Multi-Task CNN</font>
    </a>
  </h2>
  <font color="black">FVC2004 DB1とDB2を使用した一連の実験を通じて、提案された方法は、市販の指紋照合ソフトウェアや従来の方法と比較して、指紋照合で効率的なパフォーマンスを発揮することを示しました。また、以下を考慮した新しいデータ拡張方法を提案します。トレーニングでは、いくつかの指紋クラスを含むパブリックデータセットのみを使用するため、指紋画像の特性はトレーニング中に画像の数を増やします。テクスチャ、特徴点、および周波数スペクトルから指紋の特徴を抽出するための新しいCNNベースの方法を提案します。 。 
[ABSTRACT]私たちは、テクスチャ、特徴点、および周波数スペクトルから指紋の特徴を抽出するための新しい実証済みの方法を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Attentive One-Dimensional Heatmap Regression for Facial Landmark
  Detection and Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_29.html">
      <font color="black">Attentive One-Dimensional Heatmap Regression for Facial Landmark
  Detection and Tracking</font>
    </a>
  </h2>
  <font color="black">これに対処するために、顔のランドマークの位置特定のための新しい注意深い1次元ヒートマップ回帰法を提案します。空間複雑さがはるかに低いため、提案された方法は、GPUメモリが限られているにもかかわらず、高解像度1Dヒートマップを出力でき、量子化エラーを大幅に軽減します。 、x座標とy座標の周辺分布を表す1Dヒートマップの2つのグループを予測します。 
[要約] 1dヒートマップは、現在のヒートマップ53メソッドと比較して、空間の複雑さを大幅に軽減します。これらの1dヒートマップは、x座標とy座標に存在する正確な正確なパターンを予測します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-05">
        <br><font color="black">2020-04-05</font>
      </time>
    </span>
</section>
<!-- paper0: DMD: A Large-Scale Multi-Modal Driver Monitoring Dataset for Attention
  and Alertness Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_30.html">
      <font color="black">DMD: A Large-Scale Multi-Modal Driver Monitoring Dataset for Attention
  and Alertness Analysis</font>
    </a>
  </h2>
  <font color="black">DMDの使用法は、DLトレーニングプロセスで使用するために準備された、13の注意散漫アクティビティを含む、dBehaviourMDデータセットのサブセットを抽出することによって示されます。ビジョンは、ドライバーモニタリングシステム（DMS）の最もリッチで最も費用対効果の高いテクノロジーです。 、特に最近のディープラーニング（DL）メソッドの成功後。このホワイトペーパーでは、ドライバーモニタリングデータセット（DMD）を紹介します。これは、実際のシミュレーションシナリオとシミュレーションされた運転シナリオ（注意散漫、視線割り当て、眠気、ハンドル）を含む広範なデータセットです。 37名のドライバーの顔、体、手をキャプチャする3台のカメラからのRGB、深度、およびIRビデオの41時間の相互作用およびコンテキストデータ。 
[ABSTRACT]図示されたデータセットの欠如は、dms development.dmdの進行のボトルネックです。dmdは、より広範で、多様で、マルチドリンクです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Edge and Identity Preserving Network for Face Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_31.html">
      <font color="black">Edge and Identity Preserving Network for Face Super-Resolution</font>
    </a>
  </h2>
  <font color="black">具体的には、エッジブロックは知覚エッジ情報を抽出し、それを元の特徴マップに複数のスケールで連結します。さらに、超解像画像の識別を維持するために同一性損失関数を定義します。ローカルおよびグローバルな構造情報。 
[ABSTRACT] lceメソッドは、明るさと色のコンポーネントを分割することで、色情報の依存性を減らします。また、複数のドメイン（rgbとyuv）の超解像（sr）と高解像度（hr）の画像の違いをネットワークに反映できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: MetaDistiller: Network Self-Boosting via Meta-Learned Top-Down
  Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_32.html">
      <font color="black">MetaDistiller: Network Self-Boosting via Meta-Learned Top-Down
  Distillation</font>
    </a>
  </h2>
  <font color="black">MetaDistillerの一般化可能性を示すために、さまざまなネットワークアーキテクチャをテストします。モデルの中間機能マップから学習したソフトターゲットを利用して、最先端のネットワークと比較して、ネットワークのセルフブーストを改善できます。 。2つのデータセットの実験結果は、この方法の有効性を強く示しています。 
[ABSTRACT] distististististististististististististististististististististististististifiedは、不安定なモデルです。ただし、時間やその他の要因で依然として高い需要があります。ラベルジェネレーターを使用して、フィーチャーマッパーをトップダウン方式で融合することで作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Minimal Adversarial Examples for Deep Learning on 3D Point Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_33.html">
      <font color="black">Minimal Adversarial Examples for Deep Learning on 3D Point Clouds</font>
    </a>
  </h2>
  <font color="black">実験結果は、この方法が、80％の攻撃成功率で最先端のパフォーマンスを達成しながら、わずか4 \％のポイントしか操作しないことを示しています。例の知覚可能性を考慮し、ポイント操作の最小レベルを確保しながら、ベースのネットワーク。提案された方法は一般的であり、さまざまな攻撃戦略で実現できます。 
[要約]提案された方法は一般的であり、さまざまな攻撃で実現できます。点群分類は攻撃に対してより脆弱です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: One Shot 3D Photography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_34.html">
      <font color="black">One Shot 3D Photography</font>
    </a>
  </h2>
  <font color="black">LDIで直接モバイルデバイス用に最適化された修復ネットワークを使用して、視差領域のカラーテクスチャと構造も直接合成します。3D写真はシングルショットでキャプチャされ、モバイルデバイスで直接処理されます。当社のシステムを検証し、新しいコンポーネントを現在の最先端技術と比較するための広範な定量的評価。 
[ABSTRACT]方法は、視差を表示する新しい写真に基づいています。結果の深度は、レイヤー化された深度画像に持ち上げられます。さらに、結果をメッシュベースの表現に変換します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Beyond Synthetic Noise: Deep Learning on Controlled Noisy Labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_35.html">
      <font color="black">Beyond Synthetic Noise: Deep Learning on Controlled Noisy Labels</font>
    </a>
  </h2>
  <font color="black">データセットと2つのパブリックベンチマーク（CIFARとWebVision）でこのメソッドが最良の結果を達成することを示します。ノイズの多いデータに対して制御された実験を実行することは、ノイズレベル全体のディープラーニングを理解する上で不可欠です。このペーパーは3つの貢献をします。 
[ABSTRACT]以前の研究では、制御された合成ラベルノイズに関するディープラーニングのみを検討しました。最初に、Webからの制御された現実世界のラベルノイズの最初のベンチマークを確立します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br><font color="black">2019-11-21</font>
      </time>
    </span>
</section>
<!-- paper0: Random Style Transfer based Domain Generalization Networks Integrating
  Shape and Spatial Information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_36.html">
      <font color="black">Random Style Transfer based Domain Generalization Networks Integrating
  Shape and Spatial Information</font>
    </a>
  </h2>
  <font color="black">モデルは、教師付きセグメンテーションと教師なしスタイルの翻訳目的を同時に最適化することにより、半教師付き方法でトレーニングできます。さらに、フレームワークは、2つの正則化用語を導入することにより、ターゲットの前に空間情報と形状を組み込みます。 M \＆Ms challenge2020の40の主題に関するフレームワークを使用して、未知のベンダーやセンターからのデータのセグメンテーションで有望なパフォーマンスを獲得しました。 
[ABSTRACT]モデルは、教師ありセクションと教師なしスタイルの翻訳目標を同時に最適化することにより、半教師付き方法でトレーニングできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Propensity-to-Pay: Machine Learning for Estimating Prediction
  Uncertainty -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_37.html">
      <font color="black">Propensity-to-Pay: Machine Learning for Estimating Prediction
  Uncertainty</font>
    </a>
  </h2>
  <font color="black">予測が正しくないと、リソース割り当てが非効率になり、脆弱な顧客がプロアクティブに識別されない可能性があります。この調査では、さまざまなコンテキストを考慮して予測の不確実性を推定する機械学習モデルの能力を調査します。4つのファミリの機械学習アルゴリズムの7つのモデルについて調査します彼らの小説の活用。 
[ABSTRACT]機械学習技術を使用してモデルを構築し、顧客の傾向を正確に予測して支払うことができます。これにより、エネルギー料金を支払う能力が低下する可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: On Information Plane Analyses of Neural Network Classifiers -- A Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_38.html">
      <font color="black">On Information Plane Analyses of Neural Network Classifiers -- A Review</font>
    </a>
  </h2>
  <font color="black">具体的には、フィードフォワードニューラルネットワークでも、データ処理の不等式は相互情報量の推定を保持する必要がないと主張します。同様に、潜在表現とターゲット間の相互情報量が増加するフィッティングフェーズが必要です（しかし、十分な分類パフォーマンスを得るためには、相互情報推定の詳細によっては、このようなフィッティングフェーズを情報プレーンに表示する必要はありません。この洞察により、情報プレーンに新たな正当性が与えられます。 
[要約]情報プレーンで視覚化された圧縮は、必ずしも情報-理論的ではなく、潜在表現の幾何学的圧縮と互換性があることを私たちの調査は示唆しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-21">
        <br><font color="black">2020-03-21</font>
      </time>
    </span>
</section>
<!-- paper0: Reducing Drift in Structure from Motion using Extended Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_39.html">
      <font color="black">Reducing Drift in Structure from Motion using Extended Features</font>
    </a>
  </h2>
  <font color="black">私たちの構造上の特徴は、窓の整列された列や平面的な建物のファサードなど、長期にわたる人工構造物を含むシーンのドリフトを大幅に減らすことができます。さらに、これらの制約のドリフト低減機能の分析を提供します。合成データセット上。低周波数の長距離エラー（ドリフト）は、動きからの3D構造における固有の問題であり、シーンの合理的な再構築を妨げることがよくあります。 
[要約]このホワイトペーパーでは、平面や消失点などの拡張された構造的特徴を使用して、スケールと位置のドリフトを劇的に減らす方法を紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: A multi-channel framework for joint reconstruction of multi-contrast
  parallel MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_40.html">
      <font color="black">A multi-channel framework for joint reconstruction of multi-contrast
  parallel MRI</font>
    </a>
  </h2>
  <font color="black">重要性：圧縮センシング、マルチコントラスト、パラレルイメージングは個別に十分に開発されていますが、3つの組み合わせは十分に研究されておらず、そのような設定内での等方性の潜在的な利点ははるかに少ないです。結論：新しい方法は堅牢高速マルチコントラストパラレルMRIの臨床プロトコルの実行可能なオプション。結果：他のよく知られている最先端の方法と比較して、画質が大幅に向上し、コントラスト固有の詳細が他のコントラストに漏れることなく保持されます。 
[ABSTRACT]新しい方法は、マルチコントラストパラレルmriの実行可能なオプションです。これは、新しい等方性マルチチャネルイメージレギュラライザーによって開発されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-07">
        <br><font color="black">2020-06-07</font>
      </time>
    </span>
</section>
<!-- paper0: EfficientFCN: Holistically-guided Decoding for Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_41.html">
      <font color="black">EfficientFCN: Holistically-guided Decoding for Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">PASCALコンテキスト、PASCAL VOC、ADE20Kに関する広範な実験により、提案されたEfficientFCNの有効性が検証されます。このホワイトペーパーでは、拡張された畳み込みのない共通のImageNet事前トレーニング済みネットワークをバックボーンとするEfficientFCNを提案します。全体的なガイド付きデコーダーはエンコーダーからマルチスケール機能を介して高解像度のセマンティックリッチ機能マップを取得するために導入されました。 
[要約]拡張された完全たたみ込みネットワーク（dilatedfcn）に基づくアルゴリズム。パフォーマンスと効率のバランスをとるために、エンコーダーからのマルチレベルの機能マップを組み合わせて空間情報を徐々に回復するエンコーダー-デコーダー構造があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Pose-Guided High-Resolution Appearance Transfer via Progressive Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_42.html">
      <font color="black">Pose-Guided High-Resolution Appearance Transfer via Progressive Training</font>
    </a>
  </h2>
  <font color="black">Human3.6Mデータセット、DeepFashionデータセット、およびYouTubeから収集されたデータセットに関する広範な実験結果は、私たちのモデルが高品質の画像を生成することを示しており、人々間の衣服の移動やポーズガイドされた人間のビデオなどの有用なアプリケーションでさらに利用できます。生成..我々は、リファレンスとターゲットの人物の画像を与えられ、前例のない画像解像度（1024 * 1024）でターゲットポーズに特定のリファレンスアピアランスを転送するための新しいポーズガイドアピアランス転送ネットワークを提案します。アーキテクチャは、複数のスケールで入力画像に固有の参照の外観を学習できます。 
[ABSTRACT]人間の外見を理解する能力が失われる可能性があります。人間のイメージに外見がどのように与えられるかを学習できます。システムを使用して、システムが機能しないことを確認できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Crossing-Domain Generative Adversarial Networks for Unsupervised
  Multi-Domain Image-to-Image Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_43.html">
      <font color="black">Crossing-Domain Generative Adversarial Networks for Unsupervised
  Multi-Domain Image-to-Image Translation</font>
    </a>
  </h2>
  <font color="black">n個のドメインにまたがって画像を変換する必要がある場合、2つのドメインごとにトレーニングを実行すると、トレーニングの複雑さが2次式で増加します。提案されているフレームワークは、一対のエンコーダと、高い学習を行う一対のGANで構成されています。フレームワークの副産物は、さまざまなドメインにまたがるさまざまなドメイン全体のレベルの機能です。フレームワークの副産物は、最新の状態で行われるようにドメインをペアでトレーニングするよりも短時間で済むためです。 -アート作品。 
[ABSTRACT]一度に2つのドメインのデータのみを使用してトレーニングすると、他のドメインのメリットが得られ、より有用な機能の抽出が妨げられます。ドメインの副産物は、計算時間と計算リソースの削減です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: SpatialFlow: Bridging All Tasks for Panoptic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_44.html">
      <font color="black">SpatialFlow: Bridging All Tasks for Panoptic Segmentation</font>
    </a>
  </h2>
  <font color="black">フローは、オブジェクトの空間コンテキストをボックス回帰タスクから他のオブジェクトに配信することにより、パノラマのセグメンテーションのすべてのサブタスクをブリッジできます。 SpatialFlow ..オブジェクトの場所は、画像シーン内のすべてのものに関連しているため、パノラマのセグメンテーションの基本です。 
[要約]このホワイトペーパーでは、この目的を達成するためのオブジェクトコンテキストフローを提案します。これらには、サブタスクでオブジェクトの空間情報を適切に適応させるための4つの並列サブネットワークが含まれます。これらのネットワークがネットワークの情報</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-19">
        <br><font color="black">2019-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: Lymph Node Gross Tumor Volume Detection and Segmentation via
  Distance-based Gating using 3D CT/PET Imaging in Radiotherapy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_45.html">
      <font color="black">Lymph Node Gross Tumor Volume Detection and Segmentation via
  Distance-based Gating using 3D CT/PET Imaging in Radiotherapy</font>
    </a>
  </h2>
  <font color="black">3Dマルチモダリティイメージングから疑わしい癌転移リンパ節を検出、特定、およびセグメント化することは、臨床的に最も重要な課題です。20％の精度で82.5 \％$の達成された最高のGTVLNリコールは、臨床的に関連し、人間の観察者が傾向があるため価値がありますこれは、感度が低いことです（文献で報告されているように、経験豊富な放射線腫瘍医の場合は約$ 80 \％$）。これは、外観、サイズ、およびその他のLN特性の分布が重複しているものの、各カテゴリが異なる可能性があるという観察に基づいています。 
[ABSTRACT]放射線療法では、これらは必須リンパ節総腫瘍体積（gtvln）と呼ばれます。この作業では、放射線腫瘍医が実施する高レベルの推論プロトコルをシミュレーションおよび簡略化するための効果的な距離ベースのゲーティングアプローチを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: TResNet: High Performance GPU-Dedicated Architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_46.html">
      <font color="black">TResNet: High Performance GPU-Dedicated Architecture</font>
    </a>
  </h2>
  <font color="black">ResNet50と同様のGPUスループットを持つTResNetモデルを使用して、ImageNetで80.8トップ1の精度に達します。この作業では、GPUトレーニングと推論を維持しながら、ニューラルネットワークの精度を高めることを目的とした一連のアーキテクチャ変更を紹介します。効率..次に、GPU構造とアセットをより有効に活用する代替設計を提案します。 
[ABSTRACT] vanilla resnet50は通常、最近の競合他社よりも大幅に高速です。スループットが向上します-精度のトレードオフ。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br><font color="black">2020-03-30</font>
      </time>
    </span>
</section>
<!-- paper0: Transfer Learning for Protein Structure Classification at Low Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_47.html">
      <font color="black">Transfer Learning for Protein Structure Classification at Low Resolution</font>
    </a>
  </h2>
  <font color="black">入力表現が分類パフォーマンスに及ぼす影響を調査し、側鎖情報がきめの細かい構造予測に必要でない可能性があることを示しています。したがって、高速で低コストのタンパク質構造分類の概念実証を低コストで提供します。最後に、高解像度、低解像度、NMRで決定された構造が共通の特徴空間に生息していることを確認し、単一画像のスーパー解決。 
[ABSTRACT]研究者は、タンパク質の立体構造を視覚化できる必要があります。これは、高価で時間のかかる分析方法に依存しているためです。これにより、構造と機能を予測する方法が説明されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-11">
        <br><font color="black">2020-08-11</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised MRI Super-Resolution using Deep External Learning and
  Guided Residual Dense Network with Multimodal Image Priors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_48.html">
      <font color="black">Unsupervised MRI Super-Resolution using Deep External Learning and
  Guided Residual Dense Network with Multimodal Image Priors</font>
    </a>
  </h2>
  <font color="black">これらの手法は、医用画像の超解像（SR）にも適用されています。このホワイトペーパーでは、人体解剖学の簡単な事前知識に基づいた教師なしSISR手法を提案します。この手法では、トレーニングにHR画像は必要ありません。深層学習手法により、自然な画像を使用した最先端の単一画像超解像（SISR）が実現しました。 
[ABSTRACT]高技術（hr）および低解像度（lr）画像は、深層学習モデル（マッピング関数）をトレーニングするために使用されます。これらの技術には、医療画像が含まれ、医療画像にはいくつかのユニークな特性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Condition Invariant Features for Retrieval-Based Localization
  from 1M Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_49.html">
      <font color="black">Learning Condition Invariant Features for Retrieval-Based Localization
  from 1M Images</font>
    </a>
  </h2>
  <font color="black">困難なOxford RobotCar夜間条件では、この方法は、5m以内の定位精度で24.4％よく知られているトリプレット損失を上回ります。論文では、100万以上の画像を含むOxford RobotCarを含む3つの異なるベンチマークデータセットでいくつかのローカリゼーション手法をトレーニングおよび評価しています。 
[ABSTRACT]大規模なデータセットの異なる損失関数間の比較が不十分です。これは、アルゴリズムのトレーニングの複雑さが高いためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Recurrent Model for Individualized Prediction of Alzheimer's
  Disease Progression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_50.html">
      <font color="black">Deep Recurrent Model for Individualized Prediction of Alzheimer's
  Disease Progression</font>
    </a>
  </h2>
  <font color="black">これまでの研究の多くは断面分析を考慮していましたが、より最近の研究では、疾患進行モデリング（DPM）の方法で縦断的または時系列データを使用したADの診断と予後に焦点を当てています。TADPOLEチャレンジコホートに関する実験では、さまざまなメトリクスのパフォーマンスを測定し、その方法を文献の競合する方法と比較しました。具体的には、（i）欠損値補完、（ii）表現型測定の予測、（iii）の4つの問題に共同で取り組む深いリカレントネットワークを提案します。認知スコアの軌跡推定、および（iv）縦断的バイオマーカーに基づく被験者の臨床状態予測。 
[ABSTRACT]この場合、欠損データを推定するという二次的な問題を定義し、体系的に取り組みます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br><font color="black">2020-05-06</font>
      </time>
    </span>
</section>
<!-- paper0: Meta-Learning with Shared Amortized Variational Inference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_51.html">
      <font color="black">Meta-Learning with Shared Amortized Variational Inference</font>
    </a>
  </h2>
  <font color="black">我々は、miniImageNet、CIFAR-FS、およびFC100データセットでのアプローチを評価し、以前の研究に対するその利点を示す結果を提示します。以前の研究では、モンテカルロ近似に依存して、条件付きの事前崩壊がディラックデルタ関数になっていることを示しています。モデルパラメータが潜在変数として扱われる、経験的ベイズメタ学習モデル用の新しい償却変分推論スキームを提案します。 
[要約]以前のモデルに対する事前分布は限られたトレーニングデータに基づいています。事後はラベル付きサポートと検索データの両方を利用しますが、条件付き事前分布はラベル付きサポートモデルのみに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Bifurcated backbone strategy for RGB-D salient object detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_52.html">
      <font color="black">Bifurcated backbone strategy for RGB-D salient object detection</font>
    </a>
  </h2>
  <font color="black">広範な実験は、BBS-Netが5つの評価基準の下で8つの挑戦的なデータセットで18のSOTAモデルよりも大幅に優れていることを示しており、私たちのアプローチの優位性を示しています（$ \ sim 4 \％$ S-measure $ vs. $の上位ランクモデル： DMRA-iccv2019）..このホワイトペーパーでは、RGB-D顕著オブジェクト検出の固有のマルチモーダルおよびマルチレベルの性質を活用して、新しいカスケードされた改良ネットワークを考案します。さらに、一般化機能に関する包括的な分析を提供します。さまざまなRGB-Dデータセットを使用して、将来の研究のための強力なトレーニングセットを提供します。 
[要旨] rgb-d顕著オブジェクト検出のマルチモーダルおよびマルチレベルの性質が悪用されました。新しいシステムは、深度拡張モジュール（dem）を使用して、チャネルおよび空間ビューから有益な深度キューを発掘します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Adaptively-Accumulated Knowledge Transfer for Partial Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_53.html">
      <font color="black">Adaptively-Accumulated Knowledge Transfer for Partial Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">具体的には、適応的に蓄積されたメカニズムを調査して、最も信頼できるターゲットサンプルとそれに対応するソースカテゴリを徐々にフィルターで除外し、2つのドメイン間でより多くの知識を持つポジティブ転送を促進します。さらに、プロトタイプ分類器とマルチレイヤーで構成されるデュアルの異なる分類器アーキテクチャパーセプトロン分類器は、さまざまな視点からドメイン全体の固有のデータ分散知識を取得するために構築されています。いくつかの部分的なドメイン適応ベンチマークに関する包括的な実験は、最新のPDAメソッドと比較して、提案されたモデルの有効性を示します。 
[ABSTRACT]ほとんどの従来のドメイン適応（da）の取り組みは、ドメインサイズの機能の学習に重点を置いています。代わりに、2つのカテゴリにまたがる関連カテゴリを調整するために、適応的に蓄積された知識伝達フレームワークを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Attribute-guided image generation from layout -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_54.html">
      <font color="black">Attribute-guided image generation from layout</font>
    </a>
  </h2>
  <font color="black">出力は、要求されたオブジェクトが目的の場所にあり、所定の属性を持つ生成された画像です。いくつかの損失が協調して働き、正確で一貫性のある多様な画像生成を促進します。この制限に対処するために、新しい画像生成方法を提案します。インスタンスレベルの属性コントロール。 
[ABSTRACT]画像は私たちのカテゴリからのデータに基づいています-ガイド付きの厳格なモデルです。これらは、マップする必要がある多くの特性があることを示しています。結果の画像は、より高い解像度、オブジェクト分類の精度と一貫性を持っています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: A survey on applications of augmented, mixed andvirtual reality for
  nature and environment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_55.html">
      <font color="black">A survey on applications of augmented, mixed andvirtual reality for
  nature and environment</font>
    </a>
  </h2>
  <font color="black">拡張現実（AR）、仮想現実（VR）、複合現実（MR）は、魅力的で豊かな体験を提供できるため、大きな可能性を秘めた技術です。選択された論文を参照しながら、各カテゴリのアプリケーションについて説明します。このホワイトペーパーでは、環境に利益をもたらす、または環境問題に関する意識を高めることができる既存のAR / VR / MRアプリケーションを発見して分類することを目的とした調査の結果を示します。 
[ABSTRACT] ar / vr / mrアプリケーションは、医療、製造、エンターテイメントなどの業界で急速に増加しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: How semantic and geometric information mutually reinforce each other in
  ToF object localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CV/paper_56.html">
      <font color="black">How semantic and geometric information mutually reinforce each other in
  ToF object localization</font>
    </a>
  </h2>
  <font color="black">1つ目は、生の深度と強度の画像を入力として使用して、フロアピクセルをセグメント化し、そこからカメラの外部パラメーターを推定します。2つ目のCNNは、対象オブジェクトのセグメント化を担当します。 CNN。 
[要旨]私たちの方法では、2つのcnnを使用しています。 2番目のcnnは、関心のあるオブジェクトのセグメント化を担当します。キャリブレーションとローカリゼーションの精度は、従来のcnnアーキテクチャと比較して大幅に向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Iterative Pseudo-Labeling for Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CL/paper_0.html">
      <font color="black">Iterative Pseudo-Labeling for Speech Recognition</font>
    </a>
  </h2>
  <font color="black">次に、標準と低リソースの両方の設定でLibrispeechテストセットで最先端の単語エラー率を達成することにより、IPLの有効性を実証します。特に、IPLは両方を使用して各反復で既存のモデルを微調整しますラベル付けされたデータとラベル付けされていないデータのサブセット。IPLの主要コンポーネントである言語モデルとデータ拡張によるデコード。 
[ABSTRACT]反復擬似ラベリング（ipl）は半教師付きアルゴリズムです。言語モデルとデータ拡張を使用してシステムを作成します。システムは追加のテキストを効果的に利用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-19">
        <br><font color="black">2020-05-19</font>
      </time>
    </span>
</section>
<!-- paper0: AMBERT: A Pre-trained Language Model with Multi-Grained Tokenization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CL/paper_1.html">
      <font color="black">AMBERT: A Pre-trained Language Model with Multi-Grained Tokenization</font>
    </a>
  </h2>
  <font color="black">この論文では、細粒度と粗粒度の両方のトークン化に基づいて、AMBERT（マルチグレインBERT）と呼ばれる新しい事前トレーニング済み言語モデルを提案します。たとえば、英語では、マルチ自然な字句単位を形成し、したがって粗粒度のトークン化を使用する単語表現も合理的であるように見えます。モデルのトークンは、通常、英語などの言語では単語またはサブワードであり、中国語のような言語の場合、これらは文字です。 
[ABSTRACT]事前トレーニング済みの言語モデルは細かい-ベルト付きで細かい-粒子があります。英語などの言語の場合、これらは単語またはサブユニットであり、chinese.ambertの場合、ほとんどすべての場合で既存の最高のパフォーマンスモデルより優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Opinion-aware Answer Generation for Review-driven Question Answering in
  E-Commerce -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CL/paper_2.html">
      <font color="black">Opinion-aware Answer Generation for Review-driven Question Answering in
  E-Commerce</font>
    </a>
  </h2>
  <font color="black">次に、マルチビューポインタージェネレーターネットワークを使用して、特定の製品関連の質問に対する意見を意識した回答を生成します。このホワイトペーパーでは、統合モデルを使用して回答の生成と意見のマイニングタスクを共同で学習することにより、意見を意識した回答の生成に取り組みます。 ..製品関連の質問応答（QA）は、eコマースで重要ですが、やりがいのあるタスクです。 
[ABSTRACT]豊富な回答ベースのQAは、さまざまな製品レビューに基づいてユーザーが投稿した質問に即座に応答することを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Speaker Re-identification with Speaker Dependent Speech Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CL/paper_3.html">
      <font color="black">Speaker Re-identification with Speaker Dependent Speech Enhancement</font>
    </a>
  </h2>
  <font color="black">最初のステップでは、話者埋め込みベクトルが生成されます。これは、2番目のステップで使用して、音声品質を向上させ、話者を再識別します。この論文では、音声強調と話者認識をカスケードする新しいアプローチを紹介します。スピーチエンハンスメントを採用することでさらなる利益が得られることを示しています。 
[ABSTRACT]スピーチの強化により、従来よりパフォーマンスの向上が可能になりました。これらには、強化されたスピーチの強化と話者認識が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-15">
        <br><font color="black">2020-05-15</font>
      </time>
    </span>
</section>
<!-- paper0: CoAID: COVID-19 Healthcare Misinformation Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CL/paper_4.html">
      <font color="black">CoAID: COVID-19 Healthcare Misinformation Dataset</font>
    </a>
  </h2>
  <font color="black">CoAIDには、3,235のニュース、294,692の関連ユーザーエンゲージメント、COVID-19に関する851のソーシャルプラットフォームの投稿、グラウンドトゥルースラベルが含まれます。データセットは、https：//github.com/cuilimeng/CoAID .. COVID-19ウイルスとして入手できます。残念ながら、COVID-19に関連する誤った情報も作成され、山火事のように広がります。 
[ABSTRACT] covid-19のヘルスケアの誤ったデータセットが虚偽のニュースにリンクされています。これらには、ユーザーのソーシャルエンゲージメントとともに、ウェブサイトやソーシャルプラットフォーム上の偽のニュースが含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-22">
        <br><font color="black">2020-05-22</font>
      </time>
    </span>
</section>
<!-- paper0: Entity and Evidence Guided Relation Extraction for DocRED -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CL/paper_5.html">
      <font color="black">Entity and Evidence Guided Relation Extraction for DocRED</font>
    </a>
  </h2>
  <font color="black">最初に、エンティティガイド付きシーケンスを事前トレーニング済みの言語モデルへの入力として導入します（たとえば、第2に、証拠予測の追加機能として内部注意確率を使用して、事前トレーニング済みの言語モデルの微調整をガイドします。アプローチは、事前トレーニング済みの言語モデルがエンティティとサポート/証拠文に焦点を当てることを奨励します。これらのエンティティガイド付きシーケンスは、事前トレーニング済みの言語モデル（LM）がエンティティに関連するドキュメントの領域に焦点を当てるのに役立ちます。
[要約]新しいアプローチでは、事前にトレーニングされた言語モデルがエンティティに焦点を当てることを奨励しています。私たちのアプローチは、パブリックリーダーボードで最先端の結果を達成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Relation Extraction with Self-determined Graph Convolutional Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CL/paper_6.html">
      <font color="black">Relation Extraction with Self-determined Graph Convolutional Network</font>
    </a>
  </h2>
  <font color="black">私たちの実験は、SGCNが依存関係解析ツールを使用してグラフを構築する従来のGCNよりも優れていることを示しています。次に、自己決定グラフはGCNを使用してエンコードされています。TACREDデータセットでモデルをテストし、アートの結果。 
[ABSTRACT]グラフたたみ込みネットワーク（gcn）を使用して、事前に作成されたグラフをエンコードします。この方法では、言語ツールを使用してテキストのグラフを作成します。その後、言語ツールを使用するのではなく、新しいモデルを作成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-02">
        <br><font color="black">2020-08-02</font>
      </time>
    </span>
</section>
<!-- paper0: LTP: A New Active Learning Strategy for CRF-Based Named Entity
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CL/paper_7.html">
      <font color="black">LTP: A New Active Learning Strategy for CRF-Based Named Entity
  Recognition</font>
    </a>
  </h2>
  <font color="black">次に、いくつかの戦略は、モデルに侵入し、サンプル選択のための追加情報を生成するために変更する必要があります。これにより、開発者のワークロードが増加し、モデルのトレーニング/予測時間が増加します。このホワイトペーパーでは、まず、従来のアクティブラーニングを調べます。いくつかの典型的なデータセットの名前付きエンティティ認識で広く使用されているBiLstm-CRFの特定のケースでの戦略。LTPは、長いシーケンスを優先せず、モデルに侵入する必要がないシンプルで強力な戦略です。 
[ABSTRACT]実際のアプリケーションでは、既存の不確実性を発見しました-ベースの能動学習戦略には2つの欠点があります。これらの戦略は、モデルに侵入し、サンプル選択のための追加情報を生成するために変更する必要があります。これにより、開発者のワークロードが増加し、トレーニングが増加しモデルの予測時間</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-08">
        <br><font color="black">2020-01-08</font>
      </time>
    </span>
</section>
<!-- paper0: Weakly Supervised Training of Hierarchical Attention Networks for
  Speaker Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CL/paper_8.html">
      <font color="black">Weakly Supervised Training of Hierarchical Attention Networks for
  Speaker Identification</font>
    </a>
  </h2>
  <font color="black">グローバル情報は最終的にセグメントレベルモジュールから収集され、分類子を介して話者を予測します。2つのベースラインを比較すると、得られた結果は、提案されたアプローチがより優れたパフォーマンスを達成できることを示しています。注意を払ったフレームレベルエンコーダーは機能を学習し、ターゲットを強調表示します関連するフレームをローカルで、フラグメントベースの埋め込みを出力します。 
[要約]音声ストリームと機能はフラグメントにセグメント化されます。フレームはターゲットスピーカーに接続されていると考えられます。これは、これがエンコーダーの欠如によるものであることを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-15">
        <br><font color="black">2020-05-15</font>
      </time>
    </span>
</section>
<!-- paper0: Inno at SemEval-2020 Task 11: Leveraging Pure Transformer for
  Multi-Class Propaganda Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CL/paper_9.html">
      <font color="black">Inno at SemEval-2020 Task 11: Leveraging Pure Transformer for
  Multi-Class Propaganda Detection</font>
    </a>
  </h2>
  <font color="black">このペーパーは、SEMEVAL 2020タスク11「ニュース記事でのプロパガンダ手法の検出」に対するチーム「イノ」のソリューションを提示します。プロパガンダ手法を相互に区別する能力について、最適化された学習スキームで純粋なトランスフォーマーベースのモデルをテストしました..私たちのモデルは、検証セットとテストセットに応じて全体として0.6および0.58のF1スコアを示し、両方のセットの各クラスでゼロ以外のF1スコアを示しました。 
[要約] 2番目のサブタスクの目標は、ニュース記事のデータセットで18のプロパガンダ手法のうち11を分類することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-26">
        <br><font color="black">2020-08-26</font>
      </time>
    </span>
</section>
<!-- paper0: A Survey of Evaluation Metrics Used for NLG Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CL/paper_10.html">
      <font color="black">A Survey of Evaluation Metrics Used for NLG Systems</font>
    </a>
  </h2>
  <font color="black">また、さまざまなメトリックについて詳しく説明し、それらの主要な貢献を強調します。さらに、さまざまな評価メトリックが、事前に決定されたヒューリスティックベースの数式の使用からトレーニング済みのトランスフォーマモデルに移行しました。ディープラーニングは、最新の技術をいくつかの既存のNLGタスクだけでなく、研究者が画像のキャプションなどの新しいNLGタスクを探索するのも容易になりました。 
[要約]ディープラーニングにより、いくつかの既存のnlgタスクで最先端の技術が推進されましたが、研究者はイメージキャプションなどの新しいnlgタスクを探索することもできました。これにより、2014年以降に提案された評価指標の数が急速に増加しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Adaptable Filtering using Hierarchical Embeddings for Chinese Spell
  Check -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CL/paper_11.html">
      <font color="black">Adaptable Filtering using Hierarchical Embeddings for Chinese Spell
  Check</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、2014年と2015年の中国語のスペル修正ベークオフデータセットのスペルエラー修正に新しいSOTA結果を確立します。階層化された文字埋め込みを活用して混乱セットを適応させるスケーラブルなアプローチを提案し、（1）混乱セットを手作りする必要をなくします。 （2）めったに発生しないエラーに関連するスパース性の問題を解決します。英語などの他の言語と比較して、中国語のスペルエラーを検出して修正することは、文字数が多い（最大100k）ため、より困難です。 
[ABSTRACT]中国語でスペルミスを検出して修正するのはより困難です。しかし、ほとんどの混乱セットは修正されているため、新しく進化するエラーパターンは含まれていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Speech Summarisation: A Scoping Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CL/paper_12.html">
      <font color="black">Automatic Speech Summarisation: A Scoping Review</font>
    </a>
  </h2>
  <font color="black">また、これらのさまざまな方法と音声機能の長所と短所についても説明します。全体として、監視ありの方法（例：監視付きの方法では、手動で注釈を付けたトレーニングデータが必要になるため、コストがかかる可能性があるため、監視なしの方法に関心が高まりました。
[要約]文献検索および抽出された音声機能の使用、方法、範囲、およびトレーニングコーパスから発見された153のセットから合計110の論文</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Reinforcement Learning Based Graph-to-Sequence Model for Natural
  Question Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CL/paper_13.html">
      <font color="black">Reinforcement Learning Based Graph-to-Sequence Model for Natural
  Question Generation</font>
    </a>
  </h2>
  <font color="black">私たちのモデルは、パッセージを埋め込むための新しい双方向ゲーテッドグラフニューラルネットワークベースのエンコーダーを備えたGraph2Seqジェネレーター、およびクロスエントロピーとRL損失の両方を組み合わせた混合目的を備えたハイブリッドエバリュエーターで構成され、構文的および意味的に有効なテキストの生成を保証します。私たちのモデルはエンドツーエンドのトレーニングが可能であり、標準のSQuADベンチマークに対して大幅なマージンで既存の方法よりも優れた新しい最先端のスコアを達成します。また、回答情報をに組み込むための効果的なディープアライメントネットワークを導入します。単語レベルと文脈レベルの両方でのパッセージ。 
[概要]モデルは、graph2seqジェネレーター-パッセージを埋め込む新しい双方向ゲートグラフニューラルネットワークベースのエンコーダーで構成されます。混合目的を持つハイブリッドエバリュエーターは、クロスネバダとrlの損失を組み合わせて、構文的および意味的に有効なテキストの生成を保証します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-14">
        <br><font color="black">2019-08-14</font>
      </time>
    </span>
</section>
<!-- paper0: Uralic Language Identification (ULI) 2020 shared task dataset and the
  Wanca 2017 corpus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CL/paper_14.html">
      <font color="black">Uralic Language Identification (ULI) 2020 shared task dataset and the
  Wanca 2017 corpus</font>
    </a>
  </h2>
  <font color="black">ULI 2020データセットを使用して実施されたベースライン言語識別実験も提供します。この記事では、ウラル言語識別（ULI）2020共有タスクを使用するために、インターネットからクロールされたテキストのWanca 2017コーパスを紹介します。 ULIデータセットと、Wanca 2017コーパスとライプツィヒコーパスコレクションのさまざまな言語のテキストを使用してULIデータセットが構築された方法について説明します。 
[要約] uliデータセットは、2017年のwancaコーパスと、ライプツィヒコーパスコレクションのさまざまな言語のテキストを使用して作成されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: GREEK-BERT: The Greeks visiting Sesame Street -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CL/paper_15.html">
      <font color="black">GREEK-BERT: The Greeks visiting Sesame Street</font>
    </a>
  </h2>
  <font color="black">3つのNLPタスク、つまり品詞タグ付け、名前付きエンティティ認識、自然言語推論でそのパフォーマンスを評価し、最先端のパフォーマンスを取得します。最も重要なのは、GREEK-BERTとトレーニングの両方を行うことです。公開されているコードと、GREEK-BERTをダウンストリームNLPタスク用に微調整する方法を示すコード。2つのベンチマークで、GREEK-BERTは2つの多言語トランスフォーマーベースモデル（M-BERT、XLM-R）よりも優れています。事前にトレーニングされた単語の埋め込みで動作するより浅い神経ベースラインと同様に、大幅なマージン（5％-10％）。 
[ABSTRACT]これらのモデルは主にリソースに適用されています-豊富な英語。ただし、これらのモデルは主に現在の言語に使用されています。これらのモデルには、一部のbertと、ギリシャ語-bertを微調整する方法を示すコードが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Query Focused Multi-document Summarisation of Biomedical Texts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CL/paper_16.html">
      <font color="black">Query Focused Multi-document Summarisation of Biomedical Texts</font>
    </a>
  </h2>
  <font color="black">BERTとBioBERT、シャムアーキテクチャ、強化学習を使用してバリアントを実験します。このペーパーでは、2020年のBioASQチャレンジ（BioASQ8b）のタスクBフェーズBに対するマッコーリー大学とオーストラリア国立大学の参加について説明します。シャムアーキテクチャを使用するバリアントまたはBioBERTは結果を改善しませんでした。 
[ABSTRACT]単語の埋め込みを取得するためにbertを使用したときに最良の結果が観察されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Improvement of a dedicated model for open domain persona-aware dialogue
  generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CL/paper_17.html">
      <font color="black">Improvement of a dedicated model for open domain persona-aware dialogue
  generation</font>
    </a>
  </h2>
  <font color="black">実験のソースコードは、https：//github.com/ghosthamlet/personaからオープンソース化されています。そのため、ロングシーケンス処理用のトランスフォーマアーキテクチャのアーキテクチャと注意メカニズムの多くの改善については、このホワイトペーパーでは説明しません。 
[ABSTRACT]データセットは複数回の短い対話です。単一の処理シーケンスの合計長は105トークン以下です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Relation/Entity-Centric Reading Comprehension -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/cs.CL/paper_18.html">
      <font color="black">Relation/Entity-Centric Reading Comprehension</font>
    </a>
  </h2>
  <font color="black">自然言語のセマンティクスを表すために通常使用されるため、エンティティと関係に焦点を当てます。人間の言語を理解するマシンの構築は、人工知能における最もとらえどころのない、長年にわたる課題の1つです。より具体的には、質問に焦点を当てます読解力を測定するように設計された解答タスク。 
[ABSTRACT]エンティティと関係に焦点を当てます。これらは通常、自然言語の有効性を表すために使用されるためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Iterative Pseudo-Labeling for Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.AS/paper_0.html">
      <font color="black">Iterative Pseudo-Labeling for Speech Recognition</font>
    </a>
  </h2>
  <font color="black">最後に、Librispeechトレーニングトランスクリプションと重複しない新しい大きなドメイン内テキストコーパスをリリースして、低リソースの半教師付きASRの研究を促進します。次に、標準と低リソースの両方の環境でLibrispeechテストセットで最先端の単語エラー率を達成することにより、IPLの有効性を示します。また、さまざまなコーパスでトレーニングされた言語モデルがIPL追加のテキストを効果的に利用できます。 
[ABSTRACT]反復擬似ラベリング（ipl）は半教師付きアルゴリズムです。言語モデルとデータ拡張を使用してシステムを作成します。システムは追加のテキストを効果的に利用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-19">
        <br><font color="black">2020-05-19</font>
      </time>
    </span>
</section>
<!-- paper0: Device-Robust Acoustic Scene Classification Based on Two-Stage
  Categorization and Data Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.AS/paper_1.html">
      <font color="black">Device-Robust Acoustic Scene Classification Based on Two-Stage
  Categorization and Data Augmentation</font>
    </a>
  </h2>
  <font color="black">コードが利用可能です：https://github.com/MihawkHu/DCASE2020_task1 ..タスク1a開発データセットでは、最高の単一分類子とデータ拡張を使用して76.9 \％のASC精度が達成されます。タスク1aについては、 2つの畳み込みニューラルネットワーク（CNN）のアドホックスコアの組み合わせを活用し、音響入力を3つのクラス、次にそれぞれ10のクラスに従って分類する新しい2ステージASCシステム。 
[ABSTRACT]タスク1は、複数のデバイスで記録されたオーディオ信号のascを含みます。10の異なる細かいクラスがタスク1に含まれています。4つの異なるcnnベースのアーキテクチャが、2ステージの分類器を実装するために検討されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic Noise Embedding: Noise Aware Training and Adaptation for Speech
  Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.AS/paper_2.html">
      <font color="black">Dynamic Noise Embedding: Noise Aware Training and Adaptation for Speech
  Enhancement</font>
    </a>
  </h2>
  <font color="black">ここで、非音声フレームは、ノイズの多い信号のノイズのみのフレームと見なすことができます。DNEは単純なニューラルネットワークによって抽出され、DNEを備えたSEモジュールは、環境に適応するように共同でトレーニングできます。ノイズ情報は、このホワイトペーパーで重点的に取り上げる音声強調（SE）を含む音声アプリケーションでのノイズ認識トレーニングに非常に重要です。 
[ABSTRACT]ノイズ-フレームのみ。音声アクティビティ検出（vad）を使用します。これらの推定フレームは、ノイズの埋め込みを抽出するために使用されます。dneは、seモジュールがノイズ特性をキャプチャするのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Listener-Position and Orientation Dependency of Auditory Perception in
  an Enclosed Space: Elicitation of Salient Attributes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.AS/paper_3.html">
      <font color="black">Listener-Position and Orientation Dependency of Auditory Perception in
  an Enclosed Space: Elicitation of Salient Attributes</font>
    </a>
  </h2>
  <font color="black">これらには、ASW（見かけの音源の幅）やLEV（聞き手の包絡線）などの従来の属性が含まれていましたが、PRL（知覚される残響のラウドネス）、ARW（見かけの残響の幅）、およびリバーブの方向などの新しい属性が特定され、これらはサブ属性であると仮定されています。 -LEV（listen envelopment）の属性。10の顕著な知覚属性が実験室実験から得られたデータから識別されました。.この論文は、聴取者の位置と頭の向きに応じた顕著な聴覚属性の知覚に関して行われた主観的研究を提示します。密閉空間。 
[要約]ラボの実験から得られたデータから10の顕著な知覚属性が特定されました。コンサートホールでのリスナーの位置と頭の向きの10の異なる組み合わせが顕著属性として識別されました。顕著な属性には、リバーブの明るさや音色などの音色特性が含まれますエコー輝度</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Speaker Re-identification with Speaker Dependent Speech Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.AS/paper_4.html">
      <font color="black">Speaker Re-identification with Speaker Dependent Speech Enhancement</font>
    </a>
  </h2>
  <font color="black">ここで、音声強調方法は、伝統的にパフォーマンスの向上を可能にしました。最近の研究は、音声強調の適応がさらなる利益につながる可能性があることを示しています。得られた結果は、話者依存音声強調を使用する提案されたアプローチが、さまざまなノイズ条件での2つのベースライン。 
[ABSTRACT]スピーチの強化により、従来よりパフォーマンスの向上が可能になりました。これらには、強化されたスピーチの強化と話者認識が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-15">
        <br><font color="black">2020-05-15</font>
      </time>
    </span>
</section>
<!-- paper0: A Perceptually-Motivated Approach for Low-Complexity, Real-Time
  Enhancement of Fullband Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.AS/paper_5.html">
      <font color="black">A Perceptually-Motivated Approach for Low-Complexity, Real-Time
  Enhancement of Fullband Speech</font>
    </a>
  </h2>
  <font color="black">この作業では、PercepNetを提案します。これは、スペクトルエンベロープと音声の周期性に焦点を当てることにより、音声の人間の知覚に依存する効率的なアプローチです。フルバンド（48 kHz）音声の高品質でリアルタイムの強化を示しますCPUコアの5％未満です。過去数年間、ディープラーニングに基づく音声強調方法は、スペクトル減算およびスペクトル推定に基づく従来の方法を大幅に上回っています。 
[ABSTRACT]これらの新しいテクニックの多くは、ショートに直接作用します-sttraに基づく学習。これにより、注目度の高いパフォーマンスが得られます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring British Accents: Modeling the Trap-Bath Split with Functional
  Data Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.AS/paper_6.html">
      <font color="black">Exploring British Accents: Modeling the Trap-Bath Split with Functional
  Data Analysis</font>
    </a>
  </h2>
  <font color="black">特に、「クラス」のような単語の「a」の母音は、北と南では発音が異なります。イギリスには、言語学に関心のあるさまざまな独特のアクセントが含まれています。2番目の目的は、地理的変動を視覚化することですイギリスのアクセントの。 
[要約]最初の目的は、典型的な北部と南部の母音の違いをモデル化することです。訓練されたモデルを使用してbncの話者のアクセントを予測します。次に、石鹸膜の平滑化を使用して、これらの予測の地理的パターンをモデル化します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Weakly Supervised Training of Hierarchical Attention Networks for
  Speaker Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.AS/paper_7.html">
      <font color="black">Weakly Supervised Training of Hierarchical Attention Networks for
  Speaker Identification</font>
    </a>
  </h2>
  <font color="black">結果は、妥当なセグメンテーションにより識別パフォーマンスがわずかに向上することを示しています。グローバルレベルの情報がセグメントレベルモジュールから最終的に収集され、分類子を介して話者を予測します。スピーカーをターゲットに。 
[要約]音声ストリームと機能はフラグメントにセグメント化されます。フレームはターゲットスピーカーに接続されていると考えられます。これは、これがエンコーダーの欠如によるものであることを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-15">
        <br><font color="black">2020-05-15</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-end Music-mixed Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.AS/paper_8.html">
      <font color="black">End-to-end Music-mixed Speech Recognition</font>
    </a>
  </h2>
  <font color="black">多種多様な日本のアニメーションのバックグラウンドミュージックを混合した音声データを使用したASR実験により、手法を評価しました。分離スピーカーネットワークとしてConv-TasNetを使用し、マルチスピーカーソース分離の最先端のパフォーマンスを実現しました、波形領域の音声と音楽の混合から音声信号を抽出します。時間領域の分離方法は、周波数領域の分離方法よりも優れており、入力混合信号の位相情報を単純なカスケードとジョイントトレーニングの両方で再利用します。設定。 
[ABSTRACT]時間とドメインのソース分離に基づいてバックグラウンドミュージックでasrを改善する方法を提案します。また、両方を使用して、事前トレーニングされたconv-tasnetフロントエンドと注意ベースのasrバックエンドの共同微調整を提案します分離とasrの目的</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Estimating Uniqueness of Human Voice UsingI-Vector Representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.AS/paper_9.html">
      <font color="black">Estimating Uniqueness of Human Voice UsingI-Vector Representation</font>
    </a>
  </h2>
  <font color="black">このデータを使用して、スピーカーの数、スピーカーごとのサンプル数、スピーカー内の変動のさまざまなレベルなどのいくつかの要因が推定にどのように影響するかを分析しました。結果から、i-Vectorベースの表現によって提供される一意性の度合いが43-制限された設定で52ビット。ただし、変動の少ない変動では、量子化の粗さに応じて、推定値が13〜20ビットレベルに大幅に減少します。次に、スピーカーレベルの変動を考慮しながら、i-ベクトルのエントロピーを評価する、より適切な一意性測定を導入します。 
[要旨]比較およびコントラストの一意性測定では、さまざまな生体認証モダリティを検討することが提案されています。i-行列要素の離散化では13への減少は発生しないことがわかりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: DrumGAN: Synthesis of Drum Sounds With Timbral Feature Conditioning
  Using Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.AS/paper_10.html">
      <font color="black">DrumGAN: Synthesis of Drum Sounds With Timbral Feature Conditioning
  Using Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、Generative Adversarial Networkをドラムサウンドのオーディオ合成のタスクに適用します。実験は、キック、スネア、シンバルサウンドの大規模なコレクションで実行されます。ドラムサウンドの合成作成（例：ドラム内）マシン）は通常、アナログまたはデジタル合成を使用して実行され、ミュージシャンがさまざまなパラメータを変更して目的の音色をスカルプトできるようにします。 
[ABSTRACT]合成パラメータは、サウンドの低レベルの機能を制御します。多くの場合、音楽的な意味や知覚的な対応はありません。この新しいディレクティブにより、高レベルの機能を学習して合成プロセスを制御できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Gesticulator: A framework for semantically-aware speech-driven gesture
  generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.AS/paper_11.html">
      <font color="black">Gesticulator: A framework for semantically-aware speech-driven gesture
  generation</font>
    </a>
  </h2>
  <font color="black">任意のビートとセマンティックジェスチャーを一緒に生成するように設計されたモデルを提示します。現在のエンドツーエンドの共同スピーチジェスチャー生成システムは、音声を表現するために単一のモダリティを使用します。音声またはテキストのいずれかです。入力としての音声の意味表現、および出力としての関節角度回転のシーケンスとしてジェスチャーを生成します。 
[ABSTRACT] deep-学習に基づくモデルは、音声の音響表現と意味表現の両方を入力として受け取り、一連の関節角度回転としてジェスチャーを出力として生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-25">
        <br><font color="black">2020-01-25</font>
      </time>
    </span>
</section>
<!-- paper0: Length- and Noise-aware Training Techniques for Short-utterance Speaker
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-28/eess.AS/paper_12.html">
      <font color="black">Length- and Noise-aware Training Techniques for Short-utterance Speaker
  Recognition</font>
    </a>
  </h2>
  <font color="black">この作業は、主に短期間のテスト発話（1〜8秒）の改善に焦点を当てています。さらに、この作業では、新しい自己注意メカニズムについて説明します。また、長期間のタスクに関する改善された結果も示します。 
[ABSTRACT]ディープニューラルネットワークは、ノイズと残響の影響に効果的に対処する能力を示します。これにより、遠距離の話者認識システムにとって魅力的です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
