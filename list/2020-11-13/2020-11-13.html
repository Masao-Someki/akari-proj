<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-11-13の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Learning a Lie Algebra from Unlabeled Data Pairs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.SD/paper_0.html">
      <font color="black">Learning a Lie Algebra from Unlabeled Data Pairs</font>
    </a>
  </h2>
  <font color="black">重要なことに、パラメータ$ t_i \ in \ mathbb {R} $の値は、データペア$（\ boldsymbol {x} _i、\ boldsymbol {y} _i）$間で変わる可能性があり、事前に知る必要はありません。たとえば、ピッチの解きほぐし、強弱法、および演奏技術は、音楽情報検索において依然として困難な作業です。球上の回転には、よく知られている対称グループ（$ \ mathrm {SO}（3）$）がありますが、変動性の多くの現実世界の要因についても同じことは言えません。 
[概要]近年、剛体運動を超えてグループをリーするディープラーニングの一般化により、球の表面上のパターンなど、明示的に対称なデータセット上にconvnetを構築できるようになりました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-19">
        <br><font color="black">2020-09-19</font>
      </time>
    </span>
</section>
<!-- paper0: Using IPA-Based Tacotron for Data Efficient Cross-Lingual Speaker
  Adaptation and Pronunciation Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.SD/paper_1.html">
      <font color="black">Using IPA-Based Tacotron for Data Efficient Cross-Lingual Speaker
  Adaptation and Pronunciation Enhancement</font>
    </a>
  </h2>
  <font color="black">転送されたモデルを主観的および客観的な方法で評価します。この論文では、Tacotronモデルに小さな変更を適用することで、同じ言語または異なる言語の新しい話者の既存のTTSモデルをわずか20で転送できることを示します。数分のデータ..この目的のために、最初に言語に依存しない入力を備えたベースラインの多言語タコトロンを紹介し、次に、事前にトレーニングされたスピーカーエンコーダーやコード切り替え技術を利用せずに、スピーカー適応のさまざまなシナリオで転送学習がどのように行われるかを示します。 
[概要]最初に、言語を使用したベースラインの新しいスピーカーを紹介します-agitical input。次に、事前にトレーニングされたスピーカーエンコーダーを利用せずに、スピーカー適応のさまざまなシナリオで転送学習がどのように行われるかを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Evaluating the Intelligibility Benefits of Neural Speech Enrichment for
  Listeners with Normal Hearing and Hearing Impairment using the Greek Harvard
  Corpus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.SD/paper_2.html">
      <font color="black">Evaluating the Intelligibility Benefits of Neural Speech Enrichment for
  Listeners with Normal Hearing and Hearing Impairment using the Greek Harvard
  Corpus</font>
    </a>
  </h2>
  <font color="black">この作業では、最近設計されたギリシャのハーバードスタイルのコーパスを使用して、WaveNetベースのSSDRC（wSSDRC）と呼ばれるスペクトルシェーピングとダイナミックレンジ圧縮（SSDRC）に基づくニューラルベースの音声了解度ブースターを評価します。wSSDRCは正常にテストされました。過去の英語の資料と話者の場合..通常の聴覚（NH）と聴覚障害（HI）の両方のリスナーが、音声受信しきい値（SRT）に一致するリスナー固有のSNRで音声整形ノイズ（SSN）の下でモデルを評価しました。変更されていない音声の50％が理解できます。 
[概要]コーパスは、ハーバード/スカイラの文の形式に従って開発されました。ギリシャ語のリスナーに対して、神経音声強調モデルを適用し、パフォーマンスの向上を調べる機会を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: DESNet: A Multi-channel Network for Simultaneous Speech Dereverberation,
  Enhancement and Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.SD/paper_3.html">
      <font color="black">DESNet: A Multi-channel Network for Simultaneous Speech Dereverberation,
  Enhancement and Separation</font>
    </a>
  </h2>
  <font color="black">さらに、新しいディープコンプレックス畳み込みリカレントネットワーク（DCCRN）が音声アンミキシングの構造として使用され、ニューラルネットワークベースの加重予測誤差（WPE）が音声の残響除去のために事前にカスケードされます。実験によると、非残響の場合、提案されたDESNetは、音声強調と分離においてDCCRNとほとんどの最先端の構造を上回りますが、デリバーブシナリオでは、DESNetはカスケードされたWPE-DCCRNネットワークよりも改善されています。この論文では、次のマルチチャネルネットワークを提案します。同時音声残響除去、強調および分離（DESNet）。 
[概要]提案された変更に加えて、マルチチャネル機能の注意技術を採用します。また、ネットワークのトレーニングのための段階的なsnr戦略と損失を紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-04">
        <br><font color="black">2020-11-04</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchical Prosody Modeling for Non-Autoregressive Speech Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.SD/paper_4.html">
      <font color="black">Hierarchical Prosody Modeling for Non-Autoregressive Speech Synthesis</font>
    </a>
  </h2>
  <font color="black">提案された方法は、客観的および主観的な評価において、音質と韻律の自然さの点で他の競合他社よりも優れています。TTSモデルに韻律の特徴を明示的に提供することにより、合成された発話のスタイルを制御できます。ただし、自然で合理的な韻律を予測する推論時に挑戦的です。 
[概要]この作品では、さまざまな韻律の下での非自己回帰モデルの動作を分析しました-モデリング設定。韻律機能を提供することに加えて、平坦化された音声のスタイルを制御できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Neural Lyrics and Melody Composition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.SD/paper_5.html">
      <font color="black">Automatic Neural Lyrics and Melody Composition</font>
    </a>
  </h2>
  <font color="black">歌詞、単語、文のレベルで解析された歌詞とメロディのペアのデータセットの大規模なセットでトレーニングされた歌詞からベクトル（lyric2vec）モデルは、大規模な埋め込みモデルであり、人気のある英語の曲のリカレントニューラルネットワークなどのデータ駆動型モデルをトレーニングできます。 AutoNLMCは、歌詞ジェネレーター、歌詞エンコーダー、およびエンドツーエンドでトレーニングされたメロディーデコーダーで構成されるエンコーダーデコーダーシーケンシャルリカレントニューラルネットワークモデルです。提案されている作詞作曲システムである自動ニューラル歌詞およびメロディー構成（AutoNLMC）は、人工ニューラルネットワークを使用した自動作詞作曲の全プロセス。 
[概要]提案された作詞作曲システム、自動ニューラル歌詞とメロディー構成（autonlmc）は、作詞作曲自動データのプロセス全体を設定する試みです。このシステムは、自動ニューラルネットワークによって設計されたシステムのモデルです。一致するメロディーを生成するプロの歌詞ライター</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: The CUHK-TUDELFT System for The SLT 2021 Children Speech Recognition
  Challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.SD/paper_6.html">
      <font color="black">The CUHK-TUDELFT System for The SLT 2021 Children Speech Recognition
  Challenge</font>
    </a>
  </h2>
  <font color="black">私たちのシステムは、指定されたテストセットで20.1％、全体で10番目に配置された公式評価セットで23.6％の文字エラー率（CER）を達成しました。データ前処理の手順、背景、およびコースシステム開発の概要を説明します。実験結果の分析、およびE2EとDNN-HMMハイブリッドシステムの比較について詳しく説明します。 
[概要]私たちのアプローチは、共同ctc-注意の終わり-から-th（e2e）の音声認識フレームワークの使用、伝達学習、データ拡張、およびさまざまな言語モデルの開発を組み合わせたものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Accelerated calibrationless parallel transmit mapping using joint
  transmit and receive low-rank tensor completion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.IV/paper_0.html">
      <font color="black">Accelerated calibrationless parallel transmit mapping using joint
  transmit and receive low-rank tensor completion</font>
    </a>
  </h2>
  <font color="black">これらの方法には、（i）受信感度と送信感度の積を使用する仮想コイル、（ii）すべての送信モードの受信コイル全体に低ランク構造を適用するジョイント受信コイル、および（iii）送信低ランク（TxLR）が含まれます。受信モードと送信モードの両方に同時に低ランク構造を使用します。結果：仮想コイル法は、ノイズレベルまたは加速率が2を超えると故障し、RMSエラーが0.1を超えます。それぞれのパフォーマンスをさまざまなノイズレベルで調査します。 8チャンネル並列送信7Tシステムでのさまざまな加速率。 
[概要]共同送信への3つの異なるアプローチ-受信感度システムは4の加速係数までうまく機能しました。結果はキャリブレーションなしの並列イメージング方法を使用して再構築できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised MR Motion Artifact Deep Learning using Outlier-Rejecting
  Bootstrap Aggregation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.IV/paper_1.html">
      <font color="black">Unsupervised MR Motion Artifact Deep Learning using Outlier-Rejecting
  Bootstrap Aggregation</font>
    </a>
  </h2>
  <font color="black">最近、MRモーションアーティファクト補正のための深層学習アプローチが広く研究されています。たとえば、Gd-EOB-DTPAで強化されたMRの急性一過性呼吸困難による一過性重度モーション（TSM）は、ペアデータ生成の制御とモデル化が困難です。さらに、潜在的なバイアスからアーチファクトのない画像への平滑化に対処するために、ネットワークは、最適なトランスポート駆動のcycleGANを使用して監視されていない方法でトレーニングされます。 
[要約]たとえば、新しい方法は標準化されたテストに適用できます。これは非常に成功しており、既存の最先端の深層学習方法を上回っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient in-situ image and video compression through probabilistic
  image representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.IV/paper_2.html">
      <font color="black">Efficient in-situ image and video compression through probabilistic
  image representation</font>
    </a>
  </h2>
  <font color="black">適応再帰分割（CARP）による圧縮と呼ばれる多次元画像圧縮のこのような方法を紹介します。2D静止画像、実際のYouTubeビデオ、監視ビデオなどのさまざまなデータセットを使用した広範な数値実験により、CARPが州を支配していることが示されています。 -最先端の画像/ビデオ圧縮アプローチ--- JPEG、JPEG2000、BPG、MPEG4、HEVC、およびニューラルネットワークベースの方法を含む---これらのさまざまな画像タイプのすべて、およびほぼすべての個々の画像といくつかの方法でのビデオ..CARPは、画像の再帰的パーティションでベイジアン確率モデルから推測された画像ピクセルの最適な順列を使用して、その有効な次元を減らし、情報を保持する簡潔な表現を実現します。 
[ABSTRACT]効果的な圧縮方法には、主要なローカル詳細を保持しながら、幅広い圧縮率での高い再構成品質が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-11">
        <br><font color="black">2019-12-11</font>
      </time>
    </span>
</section>
<!-- paper0: Cross Layer Optimization and Distributed Reinforcement Learning Approach
  for Tile-Based 360 Degree Wireless Video Streaming -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.IV/paper_3.html">
      <font color="black">Cross Layer Optimization and Distributed Reinforcement Learning Approach
  for Tile-Based 360 Degree Wireless Video Streaming</font>
    </a>
  </h2>
  <font color="black">物理層のサブ問題を低複雑度で最適に解決できることを証明し、複数の独立したエージェントの並列トレーニングを活用してアプリケーション層のサブ問題を解決するために、アクタークリティカルな深層強化学習（DRL）を提案します。高品質の360度をワイヤレスでストリーミングビデオは依然として挑戦的な問題です。広範な実験により、私たちのスキームの堅牢性が明らかになり、いくつかのベースラインアルゴリズムと比較してパフォーマンスが大幅に向上することが実証されています。 
[概要]各ユーザーのqoeを最大化することとユーザー間の公平性を確保することの間のトレードオフのバランスをとるqoeメトリックを最適化します。物理層のサブ問題を低複雑度で最適に解決できることを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: GloFlow: Global Image Alignment for Creation of Whole Slide Images for
  Pathology from Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.IV/paper_4.html">
      <font color="black">GloFlow: Global Image Alignment for Creation of Whole Slide Images for
  Pathology from Video</font>
    </a>
  </h2>
  <font color="black">オプティカルフローベースの画像レジストレーションを使用してスライド画像全体を作成する2段階の方法であるGloFlowを提案します。これは、計算上扱いやすいグラフプルーニングアプローチを使用したグローバルアラインメントです。修正されたステッチを生成するために..病理学への深層学習の適用は、病理学スライドのデジタル全スライド画像の存在を前提としています。 
[概要]最初の段階では、オプティカルフロー予測子をトレーニングして、連続するビデオフレーム間のペアワイズ変換を予測します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Labelling imaging datasets on the basis of neuroradiology reports: a
  validation study -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.IV/paper_5.html">
      <font color="black">Labelling imaging datasets on the basis of neuroradiology reports: a
  validation study</font>
    </a>
  </h2>
  <font color="black">レポートのみからの画像に対する正常vs異常）は非常に正確です。この作業では、専用の深層学習ベースの神経放射線レポートを作成するプロジェクトの一環として、5000を超えるMRI神経放射線レポートにラベルを付けた神経放射線学者のチームの経験を利用します。分類器..自然言語処理（NLP）は、コンピュータービジョンアプリケーション用の病院規模の神経放射線学磁気共鳴画像法（MRI）データセットのラベリングを自動化する手段として有望です。 
[要約]しかし、これまで、このアプローチの有効性について徹底的な調査は行われていません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Cognitive Biomarker Prioritization in Alzheimer's Disease using Brain
  Morphometric Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.IV/paper_6.html">
      <font color="black">Cognitive Biomarker Prioritization in Alzheimer's Disease using Brain
  Morphometric Data</font>
    </a>
  </h2>
  <font color="black">また、PLTRを拡張して、最も効果的な認知評価と効果の低い認知評価をより適切に分離します。方法：新しく開発されたランク学習アプローチPLTRを適応させて、パラダイムを実装します。最優先の認知バイオマーカーは、促進する大きな可能性を秘めています。個別診断、疾患のサブタイピング、そして最終的にはADにおける精密医療。 
[概要]パーソナライズされた認知評価の優先順位付けを可能にする機械学習ツールを開発します。メソッドは、最も効果的な認知評価を優先順位付けリストの一番上にプッシュする潜在的なスコアリング関数を学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br><font color="black">2020-02-18</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Multimodal Image Registration with Adaptative Gradient
  Guidance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.IV/paper_7.html">
      <font color="black">Unsupervised Multimodal Image Registration with Adaptative Gradient
  Guidance</font>
    </a>
  </h2>
  <font color="black">この論文では、（i）登録される元の画像ペア、（ii）対応する勾配強度マップの両方から推定された変形フィールドを活用し、提案されたものと適応的に融合する、新しいマルチモーダルレジストレーションフレームワークを提案します。ゲート融合モジュール..2つの臨床的に取得されたCT-MRIデータセットの実験結果は、提案されたアプローチの有効性を示しています。ただし、既存の方法の推定変形場は、登録される画像ペアに完全に依存しています。 
[概要]教師なし学習ベースの方法は、飛行可能な画像レジストレーションの精度と効率よりも有望なパフォーマンスを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Limited-view Photoacoustic Imaging Reconstruction With Dual Domain
  Inputs Under Mutual Information Constraint -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.IV/paper_8.html">
      <font color="black">Limited-view Photoacoustic Imaging Reconstruction With Dual Domain
  Inputs Under Mutual Information Constraint</font>
    </a>
  </h2>
  <font color="black">制限付きビューPAイメージング再構成問題を解決するために、時間領域と周波数領域の両方の再構成アルゴリズムを使用して、遅延和（DAS）画像入力とk空間画像入力を取得することを提案します。従来の画像再構成アルゴリズムでは、限られた視野の組織はアーチファクトと情報損失を引き起こし、医師の誤診や診断の失敗を引き起こす可能性があります。光音響効果に基づいて、光音響トモグラフィーは近年非常に急速に発展しており、前臨床および臨床研究の両方にとって重要なイメージングツールになっています。 
[概要]生体組織の周囲に十分な超音波トランスデューサーを配置すると、パットは深い浸透と高い画像コントラストを提供できます。限られた視野の組織はアーチファクトと情報損失を引き起こし、医師の誤診や診断ミスを引き起こす可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Shared Prior Learning of Energy-Based Models for Image Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.IV/paper_9.html">
      <font color="black">Shared Prior Learning of Energy-Based Models for Image Reconstruction</font>
    </a>
  </h2>
  <font color="black">勾配流のいくつかの時間離散化スキームを導き出し、モスコ収束の観点からそれらの一貫性を検証します。多数の数値実験で、提案された方法がさまざまな画像再構成アプリケーションに対して最先端の結果を生成することを示します。トレーニングに利用できるグラウンドトゥルース画像はありません。最後に、共有事前学習では、前述の両方の最適制御問題が、正規化装置の共有学習パラメーターと同時に最適化され、監視されていない画像再構成がさらに強化されます。 
[ABSTRACT]エネルギーベースの学習では、学習されたデータ忠実度項とデータ駆動型正則化で構成されるエネルギー汎関数のパラメーターが平均場最適制御問題にマッピングされます。提案された方法は、最新の結果を生成します。さまざまな画像再構成アプリケーション</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Conquering the CNN Over-Parameterization Dilemma: A Volterra Filtering
  Approach for Action Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.IV/paper_10.html">
      <font color="black">Conquering the CNN Over-Parameterization Dilemma: A Volterra Filtering
  Approach for Action Recognition</font>
    </a>
  </h2>
  <font color="black">このアーキテクチャは、データの遅延入力サンプル間の相互作用の形で制御された非線形性を導入します。Volterraフィルタリングのカスケード実装を提案して、同じ分類タスクを実行するために必要なパラメータの数を大幅に削減します。従来のニューラルネットワーク..提案されたアプローチは、アクション認識のためにUCF-101およびHMDB-51データセットで評価され、最先端のCNNアプローチよりも優れていることが示されています。 
[概要]畳み込みニューラルネットワークの複雑さを軽減するために、ボルテッラフィルター（インスピレーションを得たネットワークアーキテクチャ）を提案します。これは、このネットワークのさまざまなパフォーマンスをキャプチャするさまざまなネットワークを示す方法を説明しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-21">
        <br><font color="black">2019-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: A scoping review of transfer learning research on medical image analysis
  using ImageNet -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.IV/paper_11.html">
      <font color="black">A scoping review of transfer learning research on medical image analysis
  using ImageNet</font>
    </a>
  </h2>
  <font color="black">2人の研究者が独立して記事をレビューし、適格性を判断し、事前に定義された研究プロトコルに従ってデータを抽出しました。結果：8,421件の記事をスクリーニングした後、102件が選択基準を満たしました。乳房関連研究で最も一般的に使用されたのは開始モデルでした（50 ％）、VGGNetは目（44％）、皮膚（50％）、歯（57％）の研究で一般的でした。 
[要約] 2人の研究者が独立して記事をレビューし、適格性を判断し、事前に定義された研究プロトコルに従ってデータを抽出しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br><font color="black">2020-04-27</font>
      </time>
    </span>
</section>
<!-- paper0: Tele-operative Robotic Lung Ultrasound Scanning Platform for Triage of
  COVID-19 Patients -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.IV/paper_12.html">
      <font color="black">Tele-operative Robotic Lung Ultrasound Scanning Platform for Triage of
  COVID-19 Patients</font>
    </a>
  </h2>
  <font color="black">新規の重症急性呼吸器症候群コロナウイルス2（SARS-CoV-2）は、壮大な割合のパンデミックになり、世界中の医療システムを準備するための世界的な対応が最も重要です。2次元（2D）遠隔手術ロボットプラットフォームCOVID-19感染患者に対してLUSを実施することは、大きな利益となる可能性があります。さらに、2D画像の最適化と全体的な精度の比較とともに、3人の健康な被験者で初めての適用、実現可能性、安全性が検証されました。 
[概要]肺超音波（lus）は、19人の感染患者を診断するための迅速な非侵襲的イメージングツールとして登場しました。ウイルスの拡散の緩和が最も重要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-23">
        <br><font color="black">2020-10-23</font>
      </time>
    </span>
</section>
<!-- paper0: Generative and Discriminative Learning for Distorted Image Restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.IV/paper_13.html">
      <font color="black">Generative and Discriminative Learning for Distorted Image Restoration</font>
    </a>
  </h2>
  <font color="black">このタスクを調査するために利用できるデータセットまたはベンチマークがないため、CelebAデータセットに基づく前方歪みマッピングによってDistorted Face Dataset（DFD）を作成します。提案されたベンチマークとアプリケーションの広範な実験的評価は、私たちの方法が効果的な方法であることを示しています歪んだ画像の復元のために..次に、第2段階の生成ネットワークは、知覚品質をさらに最適化します。 
[ABSTRACT]液化フィルターと液化フィルターは幻滅を分配しました。彼らは、歪んだ画像の正しい反りと完成を得るのは難しいと言います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Image analysis for Alzheimer's disease prediction: Embracing
  pathological hallmarks for model architecture design -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.IV/paper_14.html">
      <font color="black">Image analysis for Alzheimer's disease prediction: Embracing
  pathological hallmarks for model architecture design</font>
    </a>
  </h2>
  <font color="black">これは、パッチベースの高解像度3D-CNNとグローバルなトポロジー機能を組み合わせたニューラルネットワークアーキテクチャに基づいており、マルチスケールの脳組織の接続性を評価します。従来、これらの変化とADとの関係は個別に調査されます。 -グローバルアプローチは、認知的に正常な被験者とAD患者の分類で平均精度スコア$ 0.95 \ pm0.03 $（有病率$ \約55 \％$）で競争力のある結果に達しました。 
[概要]心臓の変化と脳の接続性の喪失は、高解像度の構造的磁気共鳴画像法によって検出できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Decomposing Normal and Abnormal Features of Medical Images for
  Content-based Image Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.IV/paper_15.html">
      <font color="black">Decomposing Normal and Abnormal Features of Medical Images for
  Content-based Image Retrieval</font>
    </a>
  </h2>
  <font color="black">これらの潜在コードを使用して、医用画像の正常または異常な特徴に焦点を当てて類似性検索を示します。医用画像は、構成性と見なされる正常な特徴と異常な特徴に分解できます。この考えに基づいて、医用画像を2つの個別の潜在コードに分解するエンコーダ-デコーダネットワーク：正常な解剖学的コードと異常な解剖学的コード。 
[ABSTRACT]エンコーダー-デコーダーネットワークを使用して、医用画像を2つの潜在的なコードに分解できます。これらには正常な解剖学的構造と異常な解剖学的コードが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: CheXphotogenic: Generalization of Deep Learning Models for Chest X-ray
  Interpretation to Photos of Chest X-rays -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.IV/paper_16.html">
      <font color="black">CheXphotogenic: Generalization of Deep Learning Models for Chest X-ray
  Interpretation to Photos of Chest X-rays</font>
    </a>
  </h2>
  <font color="black">胸部X線写真に適用すると、いくつかのモデルでパフォーマンスが低下することがわかりましたが、この低下があっても、一部のモデルは放射線科医と同等のパフォーマンスを示しました。さまざまなモデルトレーニング手順がモデルにどのように影響するかを理解するために、さらに調査を行うことができます。胸部X線写真への一般化..すべてのモデルは異なるグループによって開発され、CheXpertチャレンジに提出され、さらに調整することなくCheXphotoデータセット内のX線のスマートフォン写真に再適用されました。 
[概要] X線写真に対する胸部X線アルゴリズムのパフォーマンスは十分に調査されていません。これらのモデルはさまざまな診断グループによって開発され、chexpertチャレンジに提出されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: An Aggregate Method for Thorax Diseases Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.IV/paper_17.html">
      <font color="black">An Aggregate Method for Thorax Diseases Classification</font>
    </a>
  </h2>
  <font color="black">胸部X線画像データセットの実験結果は、この新しい重み付けスキームが分類パフォーマンスを改善し、EfficientNetからのトレーニング最適化もパフォーマンスをさらに改善することを示しています。この論文では、損失関数のトレーニングパターンの重みはに基づいて設計されています。クラス内のトレーニングパターンの数だけでなく、1つがこのトレーニングパターンをポジティブとして扱い、他のノードがネガティブとして扱うさまざまなノードでも。さらに、ニューラルネットワークを使用した複数のクラスの分類では、トレーニングパターンは、1つの出力ノードでは正のパターンとして扱われ、残りのすべての出力ノードでは負のパターンとして扱われます。 
[概要]このシステムは、胸部疾患分類問題のための最先端のディープネットワークアーキテクチャに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-07">
        <br><font color="black">2020-08-07</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Bi-tuning of Pre-trained Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_0.html">
      <font color="black">Bi-tuning of Pre-trained Representations</font>
    </a>
  </h2>
  <font color="black">疑問が生じます：微調整を促進するためにデータの固有の構造を完全に調査する方法は？このホワイトペーパーでは、教師あり学習と教師なしの両方の事前トレーニング済み表現をダウンストリームタスクに微調整するための一般的な学習フレームワークであるBi-tuningを提案します。ディープラーニングコミュニティでは、最初にディープニューラルネットワークを事前トレーニングするのが一般的です。大規模なデータセットを作成してから、事前にトレーニングされたモデルを特定のダウンストリームタスクに合わせて微調整します。 
[概要]表現を学習するための事前トレーニングアプローチは、目覚ましい進歩を遂げました。事前トレーニング方法は、それぞれ、ラベルの識別知識とデータの固有の構造を活用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Sketch-Based Modeling: Tips and Tricks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_1.html">
      <font color="black">Deep Sketch-Based Modeling: Tips and Tricks</font>
    </a>
  </h2>
  <font color="black">そうすることで、いくつかの重要な洞察を導き出します。（i）スパース性は通常、前景と背景の誤った予測をもたらします。（ii）人間のスタイルの多様性は、考慮されない場合、非常に貧弱な一般化特性につながる可能性があります。最後に（iii）専用のスケッチインターフェイスを使用しない限り、スケッチが固定視点の視点に一致することは期待できません。近年、深い画像ベースのモデリングが大きな注目を集めていますが、スケッチベースのモデリングの並行問題には最後に、代表的なディープシングルイメージモデリングソリューションのセットを比較し、特定された重要な違いを考慮してスケッチ入力に取り組むためにそれらのパフォーマンスをどのように改善できるかを示します。 
[概要]新しいプロジェクトは、スケッチと画像入力の主な違いを特定するために使用されます。問題に対処するための一連の異なる方法を作成するために使用できます。プロジェクトは、代替モデルとしても使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: PoseNet3D: Learning Temporally Consistent 3D Human Pose via Knowledge
  Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_2.html">
      <font color="black">PoseNet3D: Learning Temporally Consistent 3D Human Pose via Knowledge
  Distillation</font>
    </a>
  </h2>
  <font color="black">教師ネットワークは、SMPL表現で3Dポーズを予測する学生ネットワークに知識を抽出します。2D関節から3D人間のポーズを復元することは、非常に制約のない問題です。最後に、教師ネットワークと学生ネットワークの両方が最終的に共同で微調整されます。 -時間的、自己無撞着、敵対的損失を使用したエンドツーエンドの方法で、個々のネットワークの精度を向上させます。 
[概要]最初に、トレーニングに2Dポーズのみを使用して、3Dスケルトンを生成する教師ネットワークをトレーニングします。教師と生徒のネットワークは、時間的、自己一貫性、敵対的損失を使用して、エンドツーエンドの方法で共同で微調整され、改善されます。個々のネットワークの精度</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-07">
        <br><font color="black">2020-03-07</font>
      </time>
    </span>
</section>
<!-- paper0: Learning a Lie Algebra from Unlabeled Data Pairs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_3.html">
      <font color="black">Learning a Lie Algebra from Unlabeled Data Pairs</font>
    </a>
  </h2>
  <font color="black">球上の回転にはよく知られている対称群（$ \ mathrm {SO}（3）$）がありますが、実際の変動要因の多くについては同じことが言えません。重要なのは、パラメーター$ t_i \の値です。 \ mathbb {R} $は、データペア$（\ boldsymbol {x} _i、\ boldsymbol {y} _i）$間で変更される可能性があり、事前に知る必要はありません。ただし、このアプローチの1つの制限は必要です。 convnetをトレーニングする前に、目的の不変性プロパティの基礎となるLieグループを明示的に定義します。 
[概要]近年、剛体運動を超えてグループをリーするディープラーニングの一般化により、球の表面上のパターンなど、明示的に対称なデータセット上にconvnetを構築できるようになりました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-19">
        <br><font color="black">2020-09-19</font>
      </time>
    </span>
</section>
<!-- paper0: PoseTrackReID: Dataset Description -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_4.html">
      <font color="black">PoseTrackReID: Dataset Description</font>
    </a>
  </h2>
  <font color="black">さらに、このデータセットは、マルチフレームの人物re-IDに関する現在の最先端の方法の優れたベンチマークを提供します。そのため、マルチパーソンのポーズ追跡とビデオ用の大規模なデータセットであるPoseTrackReIDを紹介します。ベースの人物の再ID ..特に監視などの現実のシナリオには、人間の群衆や障害物による多くのオクルージョンが含まれています。 
[ABSTRACT] re-idは、複数人のポーズ追跡などの他のタスクに役立ちます。人間の再識別と複数人のポーズ追跡の間のギャップを埋めたいと考えています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Dense Visual Correspondences in Simulation to Smooth and Fold
  Real Fabrics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_5.html">
      <font color="black">Learning Dense Visual Correspondences in Simulation to Smooth and Fold
  Real Fabrics</font>
    </a>
  </h2>
  <font color="black">ロボットによるファブリックの操作は、無限の次元構成空間、自己閉塞、およびファブリックの複雑なダイナミクスのために困難です。これにより、複数の物理的なロボットシステムでの幅広いマルチステップファブリックスムージングおよびフォールディングタスクを堅牢に模倣できます。結果として得られるポリシーは、2つの異なるロボットシステムであるdaVinci外科用ロボットとABBYuMiでの10のファブリック操作タスク全体で80.3％の平均タスク成功率を達成します。 
[要約]結果として得られるポリシーは、10のファブリック操作タスクにわたって複雑な成功率を達成します。これを使用して、無限のさまざまな異なるタスクを軽減できます。結果は、新しいファブリック構成に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-28">
        <br><font color="black">2020-03-28</font>
      </time>
    </span>
</section>
<!-- paper0: MonoComb: A Sparse-to-Dense Combination Approach for Monocular Scene
  Flow -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_6.html">
      <font color="black">MonoComb: A Sparse-to-Dense Combination Approach for Monocular Scene
  Flow</font>
    </a>
  </h2>
  <font color="black">より多様でより多くのセンサーの使用に向けた自動車アプリケーションの進行中の傾向とは対照的に、この作業は、単眼カメラのセットアップの下で複雑なシーンフローの問題を解決しようとします。この目的に向けて、単一画像深度推定、オプティカルフロー、および疎から高密度への補間における最新の成果を活用し、単一のセンサーを使用して高密度シーンフローを計算するための単眼組み合わせアプローチ（MonoComb）を提案します。 
[概要]これらのセンサーを使用すると、他のどのシステムよりも複雑になります。たとえば、単一のセンサーを使用したワイヤレスの使用が含まれます。monocombは、オプティカルフローを使用して、再構築された3D位置を時間の経過とともに関連付けます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised MR Motion Artifact Deep Learning using Outlier-Rejecting
  Bootstrap Aggregation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_7.html">
      <font color="black">Unsupervised MR Motion Artifact Deep Learning using Outlier-Rejecting
  Bootstrap Aggregation</font>
    </a>
  </h2>
  <font color="black">最近、MRモーションアーティファクト補正のための深層学習アプローチが広く研究されています。さらに、潜在的なバイアスからアーティファクトのない画像への平滑化に対処するために、ネットワークは、最適なトランスポート駆動サイクルGANを使用して教師なし方法でトレーニングされます。トレーニングステップではアーティファクトのない画像のみが必要なため、ペアのデータは必要ありません。 
[要約]たとえば、新しい方法は標準化されたテストに適用できます。これは非常に成功しており、既存の最先端の深層学習方法を上回っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Scribble-Supervised Semantic Segmentation by Random Walk on Neural
  Representation and Self-Supervision on Neural Eigenspace -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_8.html">
      <font color="black">Scribble-Supervised Semantic Segmentation by Random Walk on Neural
  Representation and Self-Supervision on Neural Eigenspace</font>
    </a>
  </h2>
  <font color="black">この作業は、補助情報やその他の中間操作なしで、落書きラベルによって直接監視されるセマンティックセグメンテーションを実現することを目的としています。落書き監視セグメンテーションセグメンテーションは、高品質の注釈なしでその有望なパフォーマンスのために最近大きな注目を集めています。画像の主要部分の一貫性を保つために、固有空間に自己監視を適用します。 
[概要]ネットワークに埋め込まれたランダムウォークは、ランダムに縮小し、画像オブジェクトに落書きをドロップするデータセットをシミュレートするのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: PLACE: Proximity Learning of Articulation and Contact in 3D Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_9.html">
      <font color="black">PLACE: Proximity Learning of Articulation and Contact in 3D Environments</font>
    </a>
  </h2>
  <font color="black">具体的には、シーンメッシュ上の一連の基底点を前提として、条件付き変分オートエンコーダを利用して、基底点から人体表面までの最小距離を合成します。そのために、PLACE（人体とその周囲の3Dシーンとの間の近接性を明示的にモデル化する3D環境でのアーティキュレーションと接触の近接学習）。コードとモデルは、https：//sanweiliti.github.io/PLACE/PLACEで調査できます。 .html。 
[ABSTRACT]人間モデルとパラメトリック人間モデルを使用してシーンを表現します。これらには、人間が身体を介して世界と相互作用する3D世界が含まれます-シーン接触。場所という名前の方法により、現実的かつ現実的になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: GAN Memory with No Forgetting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_10.html">
      <font color="black">GAN Memory with No Forgetting</font>
    </a>
  </h2>
  <font color="black">したがって、生涯学習によって動機付けられるGANメモリは、それ自体が、前のタスクからの情報の転送と変調を介した生涯学習の形式によって表されます。したがって、行儀の良い上で順次スタイルの変調を行うことを提案します。基本GANモデル、転送された基本知識から同時に恩恵を受けながら、順次ターゲット生成モデルを形成します。コードはhttps://github.com/MiaoyunZhao/GANmemory_LifelongLearningで入手できます。 
[概要]生涯学習でデータセットのストリームを記憶できる生涯学習用のガンメモリを提案します。これは、データセットの1つを記憶できる学習タイプに基づいています。ガンメモリは、記憶するようにプログラムできます。人の記憶。これは、このタイプの記憶の前兆である可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-13">
        <br><font color="black">2020-06-13</font>
      </time>
    </span>
</section>
<!-- paper0: Supervised Multimodal Bitransformers for Classifying Images and Text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_11.html">
      <font color="black">Supervised Multimodal Bitransformers for Classifying Images and Text</font>
    </a>
  </h2>
  <font color="black">BERTなどの自己監視型双方向トランスモデルは、さまざまなテキスト分類タスクの劇的な改善につながりました。テキストエンコーダと画像エンコーダからの情報を融合し、最先端のパフォーマンスを実現する教師ありマルチモーダルバイトランスモデルを紹介します。さまざまなマルチモーダル分類ベンチマークタスクで、マルチモーダルパフォーマンスを測定するために特別に設計されたハードテストセットを含む、強力なベースラインを上回っています。しかし、現代のデジタル世界はますますマルチモーダルになり、テキスト情報には画像などの他のモダリティが伴うことがよくあります。 
[概要]現代のデジタル世界はますますマルチモーダルになっていますが、よりマルチモーダルです。情報の使用には、画像などの他の要因が伴うことがよくあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-06">
        <br><font color="black">2019-09-06</font>
      </time>
    </span>
</section>
<!-- paper0: Universal Embeddings for Spatio-Temporal Tagging of Self-Driving Logs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_12.html">
      <font color="black">Universal Embeddings for Spatio-Temporal Tagging of Self-Driving Logs</font>
    </a>
  </h2>
  <font color="black">車両と歩行者の密度、各アクターのアクション、各アクターの速度、アクター間の相互作用、およびアクターのトポロジに関連する15の属性を含む、新しい大規模な自動運転データセットSDVScenesでのアプローチの有効性を示します。ロードマップ..重要なことに、埋め込みは時空間を認識し、モデルが時空間タグ値を自然に出力できるようにします。たとえば、前の歩行者密度を計算するために、値を任意の領域にプールできます。 SDV、または車が4方向の交差点で別の車をブロックしているかどうかを判断します。 
[概要]私たちのアプローチは、すべてのタグの普遍的な埋め込みを学習し、限られたデータで効率的なタグ付けと新しい属性のより迅速な学習を可能にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Unimodal Cyclic Regularization for Training Multimodal Image
  Registration Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_13.html">
      <font color="black">Unimodal Cyclic Regularization for Training Multimodal Image
  Registration Networks</font>
    </a>
  </h2>
  <font color="black">教師なしマルチモーダル画像レジストレーションフレームワークの損失関数には、類似性測定と正則化のメトリックという2つの項があります。腹部CT-MRレジストレーションの実験では、提案された方法は、特にひどく変形した場合に、従来の正則化方法よりも優れた結果をもたらします。局所領域..ただし、正則化の用語については、ほとんどの既存のマルチモーダルレジストレーションアプローチは、推定された変形場に人工的な特性を課すために、依然として手作りの式を使用しています。 
[概要]深層学習の時代に、研究者は類似性メトリックを自動的に学習するための多くのアプローチを提案しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: RIFE: Real-Time Intermediate Flow Estimation for Video Frame
  Interpolation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_14.html">
      <font color="black">RIFE: Real-Time Intermediate Flow Estimation for Video Frame
  Interpolation</font>
    </a>
  </h2>
  <font color="black">次に、推定された中間フローに従って入力フレームをワープし、融合プロセスを使用して最終結果を計算します。提案された漏れ蒸留に基づいて、RIFEをエンドツーエンドでトレーニングし、優れたパフォーマンスを実現できます。実験により、RIFEは既存のフローベースのVFIメソッドよりも大幅に高速で、いくつかのベンチマークで最先端のインデックスを実現します。 
[概要]ほとんどの既存の方法では、最初にバイワーオプティカルを推定し、次にそれらを組み合わせて中間フローを推定します。次に、推定された中間モデルに従って入力フレームをワープします。そのプロセスを使用して、結果を推定するための融合プロセスを作成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Adding Knowledge to Unsupervised Algorithms for the Recognition of
  Intent -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_15.html">
      <font color="black">Adding Knowledge to Unsupervised Algorithms for the Recognition of
  Intent</font>
    </a>
  </h2>
  <font color="black">導出されたアルゴリズムをテストするために、抽象的な幾何学的アニメーションから、意図的および非意図的なアクションを実行するエージェントのリアルなビデオまで、3つの専用データセットを構築しました。この基本的な知識の追加が、単純な監視されていないアルゴリズムにどのようにつながるかを示します。これらの実験データセットは、トレーニングデータがなくても、アルゴリズムがアクションが意図的であるかどうかを認識できることを示しています。 
[概要]アルゴリズムは、その3D運動学に基づいて、シーン内のエージェントの動作が意図的であるか非意図的であるかを推測できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Online Knowledge Distillation via Multi-branch Diversity Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_16.html">
      <font color="black">Online Knowledge Distillation via Multi-branch Diversity Enhancement</font>
    </a>
  </h2>
  <font color="black">知識の蒸留は、面倒な教師モデルから軽量の学生モデルに知識を転送するための効果的な方法です。機能融合モジュール（FFM）を導入します。これは、に含まれる豊富なセマンティック情報を統合することにより、ネットワークの注意メカニズムのパフォーマンスを向上させます。複数の学生モデルの最後のブロック..結果は、私たちの方法がこれらのデータセットで最先端のパフォーマンスを達成していることを示しています。 
[ABSTRACT]蒸留では、複数の学生モデルのアンサンブルされた予測結果をソフトターゲットとして使用して、各学生モデルをトレーニングします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-02">
        <br><font color="black">2020-10-02</font>
      </time>
    </span>
</section>
<!-- paper0: Automated Model Compression by Jointly Applied Pruning and Quantization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_17.html">
      <font color="black">Automated Model Compression by Jointly Applied Pruning and Quantization</font>
    </a>
  </h2>
  <font color="black">混合精度が許可されている場合、AJPQはモデルサイズを5倍に縮小でき、分類タスクでMobileNetの上位5つの精度が1.06％低下するだけです。プルーニングプロセスは、0ビットのチャネルごとの量子化と見なすことができます。 AJPQは、階層アーキテクチャで設計されています。レイヤーコントローラーがレイヤーのスパース性を制御し、チャネルコントローラーが各カーネルのビット幅を決定します。 
[ABSTRACT]剪定と量子化は最適ではないソリューションにつながる可能性があります。この統合により、圧縮パイプラインが簡素化され、サイズが回避されます。ajpqは、モデルサイズを5倍、2倍に縮小するように設計されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: On the Existence of a Projective Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_18.html">
      <font color="black">On the Existence of a Projective Reconstruction</font>
    </a>
  </h2>
  <font color="black">このノートでは、射影再構成の存在とエピポーラ制約を満たす基本行列の存在との関係を研究します。 
[概要]このノートでは、外科的再建の存在と存在の関係を研究します。エピポーラ制約を満たす基本行列もあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2016-08-19">
        <br><font color="black">2016-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Pseudo-Rehearsal for Continual Learning with Normalizing Flows -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_19.html">
      <font color="black">Pseudo-Rehearsal for Continual Learning with Normalizing Flows</font>
    </a>
  </h2>
  <font color="black">単一のNFをタスクに条件付けておくと、メモリのオーバーヘッドが一定に保たれることを示します。生成モデルは、ネットワークの内部埋め込みでトレーニングされた、確率的で可逆的なニューラルネットワークである正規化フロー（NF）で構成されます。この論文では、正規化と生成ベースのリハーサルアプローチの長所を組み合わせた新しい方法を提案します。 
[ABSTRACT]メソッドは正則化と体系的な順序リハーサルソースを組み合わせます。メソッドはタスクでトレーニングされた単一のnfを置き換えることを含み、メモリオーバーヘッドが一定のままであることを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-05">
        <br><font color="black">2020-07-05</font>
      </time>
    </span>
</section>
<!-- paper0: Monitoring the Impact of Wildfires on Tree Species with Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_20.html">
      <font color="black">Monitoring the Impact of Wildfires on Tree Species with Deep Learning</font>
    </a>
  </h2>
  <font color="black">樹種ラベルは、針葉樹、広葉樹、低木、ReforestedTree、および不毛の土地の5つの土地被覆クラスの手動で描かれた地図から生成されます。森林構成の変化と樹種への野火の影響の追跡。モデルは、野火によって被害を受けた地域、樹種の変化、および焼失地域のリバウンドを正確に描写します。 
[概要]深層学習モデルは、山火事の前後の4つのバンドの航空写真から土地被覆を分類するようにカスタマイズされています。モデルは2009年から2018年までのデータの3つの山火事に適用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-04">
        <br><font color="black">2020-11-04</font>
      </time>
    </span>
</section>
<!-- paper0: GloFlow: Global Image Alignment for Creation of Whole Slide Images for
  Pathology from Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_21.html">
      <font color="black">GloFlow: Global Image Alignment for Creation of Whole Slide Images for
  Pathology from Video</font>
    </a>
  </h2>
  <font color="black">病理学への深層学習の適用は、病理学スライドのデジタル全スライド画像の存在を前提としています。第2段階では、この近似ステッチを使用して近傍グラフを作成し、修正されたステッチを生成します。のビデオスキャンのシミュレートされたデータセットWSIは、私たちの方法がスライドステッチングへの既知のアプローチよりも優れており、スライドスキャナーによって生成されたものに似たWSIをステッチすることを発見しました。 
[概要]最初の段階では、オプティカルフロー予測子をトレーニングして、連続するビデオフレーム間のペアワイズ変換を予測します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Star Domain as Primitive Representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_22.html">
      <font color="black">Neural Star Domain as Primitive Representation</font>
    </a>
  </h2>
  <font color="black">NSDが星状領域の普遍近似であり、倹約的で意味論的であるだけでなく、暗黙的および明示的な形状表現でもあることを示します。この問題を解決するために、プリミティブを学習するニューラルスタードメイン（NSD）という名前の新しいプリミティブ表現を提案します。星状領域の形状..複数のプリミティブを使用してターゲット形状を再構築する場合、プリミティブを単一の形状であるかのように扱い、集合的なボリュームや表面などの形状の基本プロパティの結合に即座にアクセスできることが望ましいです。 
[概要]新しい3D表現は神経星状領域（nsd）と呼ばれ、星状領域の原始形状を学習します。私たちのアプローチが画像再構成タスクの既存の方法よりも優れていることを示しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Labelling imaging datasets on the basis of neuroradiology reports: a
  validation study -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_23.html">
      <font color="black">Labelling imaging datasets on the basis of neuroradiology reports: a
  validation study</font>
    </a>
  </h2>
  <font color="black">レポートのみからの画像に対する正常vs異常）は非常に正確です。この作業では、専用の深層学習ベースの神経放射線レポートを作成するプロジェクトの一環として、5000を超えるMRI神経放射線レポートにラベルを付けた神経放射線学者のチームの経験を利用します。分類子..ただし、バイナリラベルとは対照的に、より詳細なラベル付けの精度はカテゴリに依存するため、この不一致の理由を強調します。 
[要約]しかし、これまで、このアプローチの有効性について徹底的な調査は行われていません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Human-Object Interaction with Mixed Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_24.html">
      <font color="black">Detecting Human-Object Interaction with Mixed Supervision</font>
    </a>
  </h2>
  <font color="black">言い換えると、このタスクでは、トレーニングのために強力な監督が必要ですが、調達は困難です。ほとんどの弱く監督された学習方法では、データが利用可能な場合、強力な監督でデータを活用することはできません。実際、HOI検出におけるこの2つのパラダイムの素朴な組み合わせは、相互に貢献することができません。強力な注釈と弱い注釈を混合して使用することにより、多くの完全に監視された方法に近いか、それよりも優れたパフォーマンスを発揮します。 
[ABSTRACT] hoiトリプレットでは、人間とオブジェクトの境界ボックスと、タスクを完了するためのそれらの間のアクションが必要です。strong-教師あり学習。画像に特定のホイトリプレットが存在するが、正確な位置は不明</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Multimodal Image Registration with Adaptative Gradient
  Guidance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_25.html">
      <font color="black">Unsupervised Multimodal Image Registration with Adaptative Gradient
  Guidance</font>
    </a>
  </h2>
  <font color="black">この論文では、（i）登録される元の画像ペア、（ii）対応する勾配強度マップの両方から推定された変形フィールドを活用し、提案されたものと適応的に融合する、新しいマルチモーダルレジストレーションフレームワークを提案します。ゲート融合モジュール..最近、監視されていない学習ベースの方法は、変形可能な画像レジストレーションの精度と効率よりも有望なパフォーマンスを示しています。2つの臨床的に取得されたCT-MRIデータセットの実験結果は、提案されたアプローチの有効性を示しています。 
[概要]教師なし学習ベースの方法は、飛行可能な画像レジストレーションの精度と効率よりも有望なパフォーマンスを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Keep It Real: a Window to Real Reality in Virtual Reality -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_26.html">
      <font color="black">Keep It Real: a Window to Real Reality in Virtual Reality</font>
    </a>
  </h2>
  <font color="black">このシステムは、ユーザーが実際の存在を仮想空間に引き込むことができるリアルタイムレンダリングフレームワークです。このような遠近法で正確な表現をサポートするために、特徴検出と対応マッチングのためのコンピュータービジョンアルゴリズムを実装しました。仮想現実（VR）環境における新しい相互作用パラダイム。これは、仮想表面に投影された仮想ミラーまたはウィンドウで構成され、現実世界を反映するミラーまたはウィンドウの正しいパースペクティブジオメトリを表します。 
[概要]この手法は、さまざまな動画、ライブストリーミングアプリ、拡張現実および仮想現実の設定に適用できます。これらは、インタラクティブで没入型のユーザーエクスペリエンスを提供できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br><font color="black">2020-04-21</font>
      </time>
    </span>
</section>
<!-- paper0: Shared Prior Learning of Energy-Based Models for Image Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_27.html">
      <font color="black">Shared Prior Learning of Energy-Based Models for Image Reconstruction</font>
    </a>
  </h2>
  <font color="black">勾配流のいくつかの時間離散化スキームを導き出し、モスコ収束の観点からそれらの一貫性を検証します。多数の数値実験で、提案された方法がさまざまな画像再構成アプリケーションに対して最先端の結果を生成することを示します。トレーニングに利用できるグラウンドトゥルース画像はありません。最後に、共有事前学習では、前述の両方の最適制御問題が、正規化装置の共有学習パラメーターと同時に最適化され、監視されていない画像再構成がさらに強化されます。 
[ABSTRACT]エネルギーベースの学習では、学習されたデータ忠実度項とデータ駆動型正則化で構成されるエネルギー汎関数のパラメーターが平均場最適制御問題にマッピングされます。提案された方法は、最新の結果を生成します。さまざまな画像再構成アプリケーション</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Model Accuracy for Imbalanced Image Classification Tasks by
  Adding a Final Batch Normalization Layer: An Empirical Study -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_28.html">
      <font color="black">Improving Model Accuracy for Imbalanced Image Classification Tasks by
  Adding a Final Batch Normalization Layer: An Empirical Study</font>
    </a>
  </h2>
  <font color="black">つまり、予測を行う際に十分な自信がない場合でも、ネットワークのパフォーマンスが向上する可能性があります。ソフトマックス出力がDLモデルの不確実性の良い尺度ではない理由についての別の議論につながります。同時に、DLは実際には少数派クラスよりも多数派を支持し、その結果、対象となる初期段階の兆候の不正確な検出に悩まされます。特定の植物タイプから健康なサンプルと不健康なサンプルをランダムかつ不均一に選択してトレーニングセットを形成することにより、基本実験をResNet34およびVGG19アーキテクチャの微調整と見なし、健康な画像と不健康な画像のバランスの取れたデータセットでモデルのパフォーマンスをテストします。 
[ABSTRACT]ディープラーニング（dl）は、その強力な検出機能のために非常に必要です。このような問題で少数派クラスの高いf1テストスコアを予測することは困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Data augmentation instead of explicit regularization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_29.html">
      <font color="black">Data augmentation instead of explicit regularization</font>
    </a>
  </h2>
  <font color="black">ほとんどの機械学習モデルとは異なり、現代の深層人工ニューラルネットワークには通常、正則化に寄与する複数のコンポーネントが含まれています。結果を考慮して、計算リソース、したがって炭素排出量と焦点を節約するために、重みの減衰とドロップアウトなしでニューラルネットワークを最適化することをお勧めします。パフォーマンスと堅牢性を向上させるためのデータ拡張とその他の誘導バイアスの詳細。次に、データ拡張と重みの減衰およびドロップアウトを対比します。 
[概要]これらの手法と明示的な正則化を提供する他の要素との相互作用はまだ十分に理解されていません。詳細な調査によると、データ拡張のみでトレーニングされた視覚オブジェクト分類モデルは、重みの減衰とドロップアウトでもトレーニングされたモデルと同じかそれ以上のパフォーマンスを達成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-06-11">
        <br><font color="black">2018-06-11</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial symmetric GANs: bridging adversarial samples and adversarial
  networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_30.html">
      <font color="black">Adversarial symmetric GANs: bridging adversarial samples and adversarial
  networks</font>
    </a>
  </h2>
  <font color="black">AS-GANの有効性は、さまざまなネットワークアーキテクチャを備えたCIFAR-10、CelebA、およびLSUNでの画像生成で検証されます。敵対的サンプルと敵対的ネットワークのブリッジングは、敵対的ネットワークをさらに開発するための新しいアプローチを提供します。は敵対的摂動に対して非常に脆弱であり、弁別器によって与えられる勾配には、情報を提供しない敵対的ノイズが含まれているため、ジェネレーターは実際のサンプルのパターンをキャッチできません。 
[概要]これは、トレーニングの安定性を向上させるために提案された多くのトレーニング戦略にもかかわらずです。しかし、この問題はこの問題の課題として残っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-20">
        <br><font color="black">2019-12-20</font>
      </time>
    </span>
</section>
<!-- paper0: Decoupled Appearance and Motion Learning for Efficient Anomaly Detection
  in Surveillance Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_31.html">
      <font color="black">Decoupled Appearance and Motion Learning for Efficient Anomaly Detection
  in Surveillance Video</font>
    </a>
  </h2>
  <font color="black">以前の作業とは対照的に、異常メトリックとして潜在コード予測を使用します。これは、照明や気象条件の変化に対する精度と堅牢性の両方の点で、さまざまなベンチマークデータセットでの再構築ベースおよびフレーム予測ベースの方法よりも優れていることを示します。このベースラインから逸脱するものはすべて、下流でさらに分析するために異常としてフラグが立てられます。 
[ABSTRACT]カメラごとに個別のアルゴリズムを展開できます。外観と動きに関連する機能のベースラインモデルを時間の経過とともに学習します。これは、さまざまなベンチマークデータセットでの再構成ベースおよびフレーム予測ベースの方法よりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Video Semantic Segmentation with Distortion-Aware Feature Correction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_32.html">
      <font color="black">Video Semantic Segmentation with Distortion-Aware Feature Correction</font>
    </a>
  </h2>
  <font color="black">歪みマップのガイダンスの恩恵を受けて、歪み領域で伝播された特徴を補正するための特徴補正モジュール（FCM）を提案しました。具体的には、まず、歪みパターンを特徴から画像空間に転送し、効果的な歪みマップ予測を実行することを提案します。この論文では、この問題を軽減するために歪みを意識した特徴補正を提案します。これにより、歪んだ伝搬特徴を修正することでビデオセグメンテーションのパフォーマンスが向上します。 
[概要]オプティカルフロー推定は必然的に不正確になり、伝播された特徴が歪む原因になります。この方法は、低価格でビデオセマンティックセグメンテーションの精度を大幅に向上させることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br><font color="black">2020-06-18</font>
      </time>
    </span>
</section>
<!-- paper0: SS-CAM: Smoothed Score-CAM for Sharper Visual Feature Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_33.html">
      <font color="black">SS-CAM: Smoothed Score-CAM for Sharper Visual Feature Localization</font>
    </a>
  </h2>
  <font color="black">本論文では、Score-CAMの上に構築され、スムーズな操作を通じて画像内のオブジェクト特徴の集中ローカリゼーションを生成するSS-CAMと呼ばれる視覚的シャープネスの観点から強化された視覚的説明を紹介します。忠実度とローカリゼーションタスクの両方でScore-CAMよりも優れたILSVRC2012検証データセット。ディープコンボリューショナルニューラルネットワークの基礎となるメカニズムの解釈は、ハイリスクでのアプリケーションにより、ディープラーニングの分野における研究の重要な側面になっています。環境。 
[概要]ブラックボックスアーキテクチャを説明するために適用された多くの方法があります。これらには、重要なデータセットよりも優れたilsvrcなどの剖検が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-25">
        <br><font color="black">2020-06-25</font>
      </time>
    </span>
</section>
<!-- paper0: Conquering the CNN Over-Parameterization Dilemma: A Volterra Filtering
  Approach for Action Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_34.html">
      <font color="black">Conquering the CNN Over-Parameterization Dilemma: A Volterra Filtering
  Approach for Action Recognition</font>
    </a>
  </h2>
  <font color="black">このVolterraニューラルネットワーク（VNN）の効率的な並列実装と、その卓越したパフォーマンスを示しながら、比較的単純で扱いやすい構造を維持します。提案されたアプローチは、アクション認識のためにUCF-101およびHMDB-51データセットで評価されます。最先端のCNNアプローチよりも優れていることが示されています。機械学習（ML）での推論の重要性により、ML、特にディープラーニングで爆発的な数の異なる提案が行われています。 
[概要]畳み込みニューラルネットワークの複雑さを軽減するために、ボルテッラフィルター（インスピレーションを得たネットワークアーキテクチャ）を提案します。これは、このネットワークのさまざまなパフォーマンスをキャプチャするさまざまなネットワークを示す方法を説明しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-21">
        <br><font color="black">2019-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: DSAM: A Distance Shrinking with Angular Marginalizing Loss for High
  Performance Vehicle Re-identificatio -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_35.html">
      <font color="black">DSAM: A Distance Shrinking with Angular Marginalizing Loss for High
  Performance Vehicle Re-identificatio</font>
    </a>
  </h2>
  <font color="black">実験結果は、DSAM損失がPKU-VD1-LargeデータセットでSoftMax損失を大幅に強化することを示しています：mAPで10.41％、cmc1で5.29％、cmc5で4.60％。車両再識別（ReID）はコンピュータビジョンにおける重要でありながら挑戦的な問題。具体的には、元のフィーチャスペースで同じクラスのサンプル間の距離をローカルに縮小し、フィーチャ角度スペースで異なるクラスのサンプルを遠ざけます。 
[概要] dsam損失関数は、元のフィーチャ空間で同じクラスのサンプル間の距離をローカルに縮小します。異なるクラスのサンプルをフィーチャの角度空間で遠くに保持します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: A scoping review of transfer learning research on medical image analysis
  using ImageNet -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_36.html">
      <font color="black">A scoping review of transfer learning research on medical image analysis
  using ImageNet</font>
    </a>
  </h2>
  <font color="black">データ増強は、微調整TL研究の72％に対して、特徴抽出TL研究の15％で実行されました。また、医療画像分析に関するTL研究に存在するいくつかの重大な研究ギャップを特定しました。結果：8,421のスクリーニング後記事、102は選択基準を満たしました。 
[要約] 2人の研究者が独立して記事をレビューし、適格性を判断し、事前に定義された研究プロトコルに従ってデータを抽出しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br><font color="black">2020-04-27</font>
      </time>
    </span>
</section>
<!-- paper0: Continual Learning for Affective Computing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_37.html">
      <font color="black">Continual Learning for Affective Computing</font>
    </a>
  </h2>
  <font color="black">ユーザーごとに表現が異なるため、これらのモデルは、表現を適切にキャプチャして感情状態をモデル化するために、各個人に合わせてパーソナライズする必要があります。実際のアプリケーションでは、感情知覚モデルが表現の個人差に敏感である必要があります。この作業では、パーソナライズされた感情知覚を開発するためのパラダイムとして、感情コンピューティングのための継続的学習（CL）の使用を提案します。 
[要約]感情コンピューティングのための継続的学習（cl）の使用は、パーソナライズされた感情知覚を開発するために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-10">
        <br><font color="black">2020-06-10</font>
      </time>
    </span>
</section>
<!-- paper0: VCE: Variational Convertor-Encoder for One-Shot Generalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_38.html">
      <font color="black">VCE: Variational Convertor-Encoder for One-Shot Generalization</font>
    </a>
  </h2>
  <font color="black">変分コンバーター-エンコーダー（VCE）は、画像をさまざまなスタイルに変換します。ワンショット一般化の問題と、追加のトレーニングなしではこれまで見られなかった新しいタスクへの転送について、この新しいアーキテクチャを紹介します。トレーニングでは順次推論アルゴリズムは必要ありません。同じプロパティを持つ2つのサンプルがエンコーダに入力されます。次に、エンコーダのノイズの多い出力からそれらの1つを処理するためにコンバータが必要です。最後に、ノイズはさまざまな変換規則を表し、新しい画像を変換するために使用されます。 
[ABSTRACT]変分オートエンコーダー（vae）は、グラフィックを生成する代わりに変換する新しい方法です。新しい方法は、より多様で多様な画像を作成するように設計されています。ワンショットで使用されますここをクリック</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: 3D-OES: Viewpoint-Invariant Object-Factorized Environment Simulators -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_39.html">
      <font color="black">3D-OES: Viewpoint-Invariant Object-Factorized Environment Simulators</font>
    </a>
  </h2>
  <font color="black">モデルのシミュレーションは、ニューラルレンダラーによって任意の視点から2D画像ビューにデコードできます。これにより、潜在的な3Dシミュレーション空間の解釈が容易になります。これにより、モデルは3Dオブジェクトの特徴を「移動」するだけで、将来のシーンを予測できます。累積オブジェクトモーション予測に基づいています。さらに、シミュレーションでのみトレーニングされたモデルをモデルベースの制御に適用して、実際のロボット設定で混乱した状態でオブジェクトを目的の場所にプッシュすることにより、学習したダイナミクスのシミュレーションから実際への転送を示します
[ABSTRACT] 3d 3dでのモデルの視点の変化を示します。モデルは、表現された画像に基づいてオブジェクトの特徴を操作するパターンニューラルネットワークに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Same Object, Different Grasps: Data and Semantic Knowledge for
  Task-Oriented Grasping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_40.html">
      <font color="black">Same Object, Different Grasps: Data and Semantic Knowledge for
  Task-Oriented Grasping</font>
    </a>
  </h2>
  <font color="black">オブジェクトとタスクの両方の点でより多様で、以前のデータセットよりも1桁大きいTaskGraspデータセットを使用して、これらの懸念に対処します。データのこの新しい幅と多様性を利用して、を使用するGCNGraspフレームワークを提示します。新しいオブジェクトインスタンス、クラス、さらには新しいタスクに一般化するためにナレッジグラフにエンコードされたオブジェクトとタスクのセマンティック知識。私たちのフレームワークは、セマンティックを使用しないベースラインメソッドと比較して、保留設定で約12％の大幅な改善を示しています。 。 
[概要]データセットには25万のタスクが含まれています-56のタスクと191のオブジェクトのギア付き把握。意味を使用しないベースラインメソッドと比較して、ホールドアウト設定で約12％の大幅な改善を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Reinforcement Learning with Videos: Combining Offline Observations with
  Interaction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_41.html">
      <font color="black">Reinforcement Learning with Videos: Combining Offline Observations with
  Interaction</font>
    </a>
  </h2>
  <font color="black">RLVは、人間が収集した経験とロボットが収集したデータを組み合わせて、ポリシーと価値の機能を学習します。その結果、ロボットが広く一般化するために必要な十分に多様な経験を収集することは困難です。これらの課題に対処するために、私たちは提案します。ビデオによる強化学習（RLV）のフレームワーク。 
[概要]たとえば、ロボットは経験から経験についてもっと学ぶことができます。これらは広く一般化するために必要ですが、収集するのは困難です。概念はrlvと呼ばれ、ビデオを使用して挑戦的なビジョンベースのスキルを学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Fit2Form: 3D Generative Model for Robot Gripper Form Design -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_42.html">
      <font color="black">Fit2Form: 3D Generative Model for Robot Gripper Form Design</font>
    </a>
  </h2>
  <font color="black">次に、このフィットネスネットワークは、ターゲット把持オブジェクトの3D指形状のペアを生成する3D生成ネットワークを監視します。ロボットのエンドエフェクタの3D形状は、その機能と全体的なパフォーマンスを決定する上で重要な役割を果たします。 https://youtu.be/utKHP3qb1bgにあります。 
[概要]この作業の目標は、機械学習アルゴリズムを使用して、タスクの設計を自動化することです-特定のグリッパーフィンガー</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Tele-operative Robotic Lung Ultrasound Scanning Platform for Triage of
  COVID-19 Patients -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_43.html">
      <font color="black">Tele-operative Robotic Lung Ultrasound Scanning Platform for Triage of
  COVID-19 Patients</font>
    </a>
  </h2>
  <font color="black">COVID-19感染患者のためにLUSを実行できる2次元（2D）遠隔手術ロボットプラットフォームは、大きな利益をもたらす可能性があります。LUSを取り巻く懸念には、感染患者と医療提供者、比較的少数の医師と超音波検査技師の格差が含まれます。 LUSを実行でき、最も重要なこととして、患者とオペレーターの間の実質的な物理的接触の要件により、感染のリスクが高まります。新規の重症急性呼吸器症候群コロナウイルス2（SARS-CoV-2）は、壮大な割合のパンデミックになりました。世界中の医療システムを準備するためのグローバルな対応が最も重要です。 
[概要]肺超音波（lus）は、19人の感染患者を診断するための迅速な非侵襲的イメージングツールとして登場しました。ウイルスの拡散の緩和が最も重要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-23">
        <br><font color="black">2020-10-23</font>
      </time>
    </span>
</section>
<!-- paper0: Pretraining boosts out-of-domain robustness for pose estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_44.html">
      <font color="black">Pretraining boosts out-of-domain robustness for pose estimation</font>
    </a>
  </h2>
  <font color="black">「ドメイン内」と「ドメイン外」（見えない馬）の両方のベンチマークを可能にする30頭の馬のデータセットを開発しました。これは、現在の人間の姿勢推定ベンチマークが直接対処していない堅牢性の重要なテストです。ネットワークはポーズ推定のための非常に効果的なツールです。さらに、より良いImageNetモデルが動物種全体でよりよく一般化することを示します。 
[概要]「ドメイン内」と「ドメイン外」の両方のベンチマークを可能にする30頭の馬のデータセットを開発しました。これは、現在の人間の姿勢推定ベンチマークが直接対応していない堅牢性の重要なテストです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-24">
        <br><font color="black">2019-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: A Review of Uncertainty Quantification in Deep Learning: Techniques,
  Applications and Challenges -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_45.html">
      <font color="black">A Review of Uncertainty Quantification in Deep Learning: Techniques,
  Applications and Challenges</font>
    </a>
  </h2>
  <font color="black">最後に、UQ手法が直面する基礎研究の課題に簡単に焦点を当て、この分野での今後の研究の方向性について説明します。さらに、強化学習（RL）におけるこれらの手法の適用についても調査します。この点に関して、研究者はさまざまな提案を行っています。 UQ手法と、コンピュータービジョン（例：自動運転車や物体検出）、画像処理（例：画像復元）、医療画像分析（例：医療画像の分類とセグメンテーション）、自然などのさまざまなアプリケーションでのパフォーマンスを調査しました。言語処理（テキスト分類、ソーシャルメディアテキスト、共生リスクスコアリングなど）、バイオインフォマティクスなど。この研究では、深層学習で使用されるUQ手法の最近の進歩をレビューします。 
[概要]研究者は、科学と工学におけるさまざまな実世界のアプリケーションを解決するために、さまざまなuqメソッドを提案しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Image Anomaly Detection by Aggregating Deep Pyramidal Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_46.html">
      <font color="black">Image Anomaly Detection by Aggregating Deep Pyramidal Representations</font>
    </a>
  </h2>
  <font color="black">実験結果は、MNIST、FMNIST、および最近のMVTec異常検出データセットで優れた精度を示しています。異常は、ネットワークが入力を再構築できないことによって検出できます。産業システムでの欠陥製品の検出から医療画像までの範囲です。 
[概要]この論文では、複数のピラミッドレベルを持つディープニューラルネットワークを使用して、さまざまなスケールで画像の特徴を分析する画像異常検出に焦点を当てています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Generative and Discriminative Learning for Distorted Image Restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_47.html">
      <font color="black">Generative and Discriminative Learning for Distorted Image Restoration</font>
    </a>
  </h2>
  <font color="black">次に、第2段階の生成ネットワークは、知覚品質をさらに最適化します。このタスクを調査するための利用可能なデータセットまたはベンチマークがないため、CelebAデータセットに基づく前方歪みマッピングによってDistorted Face Dataset（DFD）を作成します。このメソッドはタスクを分解します。修正段階と改良段階に。 
[ABSTRACT]液化フィルターと液化フィルターは幻滅を分配しました。彼らは、歪んだ画像の正しい反りと完成を得るのは難しいと言います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Generalization in Biosignal Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_48.html">
      <font color="black">Domain Generalization in Biosignal Classification</font>
    </a>
  </h2>
  <font color="black">結論：生体信号データの固有の時間的性質によって引き起こされる複雑さを認識し、この研究で提案された2段階の方法は、ドメインの一般化のプロセス全体を効果的に簡素化すると同時に、見えないドメインと採用された基本ドメインで良好な結果を示します。 ：提案されたドメイン一般化方法は、既知の基本ドメインのセットを使用して見えないドメインを表し、その後、分類子融合を使用して見えないドメインを分類します。結果：提案された分類子融合方法は、4つの完全に見えないドメインで最大16％の精度向上を達成します。 
[概要]提案されたドメイン一般化方法は、トレーニング中に見えないドメインからのデータにアクセスできます。この方法は、4つの完全に見えないドメインで最大16％の精度向上を達成しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Segment Dynamic Objects using SLAM Outliers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_49.html">
      <font color="black">Learning to Segment Dynamic Objects using SLAM Outliers</font>
    </a>
  </h2>
  <font color="black">コンセンサスインバージョンは、SLAMに重大な障害を引き起こす可能性があるため、SLAMにとっては困難です。SLAMの堅牢性を評価するための新しいステレオデータセットと新しいメトリックも提案します。データセットには、コンセンサスインバージョンが含まれています。静的な背景に。 
[概要]動的オブジェクトの機能を削除し、スラムが影響を受けないようにします。この方法では、トレーニングに動的オブジェクトごとに1つの単眼シーケンスのみが必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: A Transfer Learning Framework for Anomaly Detection Using Model of
  Normality -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_50.html">
      <font color="black">A Transfer Learning Framework for Anomaly Detection Using Model of
  Normality</font>
    </a>
  </h2>
  <font color="black">さらに、フレームワークは複雑さが低く、計算要件が緩和されています。CNNは、他の異常検出手法がこれらの特徴に適用される深い特徴抽出器として使用できます。この論文では、この問題に取り組み、動作を設定するための明確な方法を提案します。 -検出精度を向上させるポイント決定しきい値。 
[ABSTRACT] cnnは、他の異常検出手法がこれらの特徴に適用される深層特徴抽出器として使用できます。その結果、モデルと定義された正規性モデルの間で同様の測定を適用することにより、異常を検出できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: StrObe: Streaming Object Detection from LiDAR Packets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_51.html">
      <font color="black">StrObe: Streaming Object Detection from LiDAR Packets</font>
    </a>
  </h2>
  <font color="black">StrObeは以前のパケットからの計算を再利用し、新しい証拠が入ってくると、メモリとして機能するシーンの潜在的な空間表現を繰り返し更新し、正確な低遅延の知覚をもたらします。ロボットアプリケーションは最小限の反応時間を必要とするため、これは課題をもたらします。 、セーフティクリティカルな状況が発生した場合に操作を迅速に計画できるようにします。ポイントはパケットのストリームとして放出され、それぞれが360 {\ deg}カバレッジのセクターをカバーします。 
[ABSTRACT]システムはレーザーを使用して回転ベースからシーンをスキャンスキャンスキャンします。フルスイープが構築されると、世界の状態を反映しません。出力が生成されるまでに、正確に反映されなくなります。 state.inこのペーパーでは、完全なスイープが構築されるのを待たずに、LIDARパケットを取り込み、検出ストリームを放出することで遅延を最小限に抑える新しいアプローチであるストロボを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Gaussian RAM: Lightweight Image Classification via Stochastic
  Retina-Inspired Glimpse and Reinforcement Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_52.html">
      <font color="black">Gaussian RAM: Lightweight Image Classification via Stochastic
  Retina-Inspired Glimpse and Reinforcement Learning</font>
    </a>
  </h2>
  <font color="black">生物学的視覚認識プロセスに大きく影響を受けたモデルは、ガウス分布で網膜の確率的位置を模倣します。両方の幅が128にサイズ変更された大規模な乱雑なMNIST、大規模なCIFAR-10、および大規模なCIFAR-100データセットでモデルを評価します。画像分類に関するこれまでの研究は、リアルタイムの操作やモデルの圧縮ではなく、主にネットワークのパフォーマンスに焦点を当てていました。 
[概要]深層反復視覚注意モデルは、画像全体を入力として使用する従来のcnn（畳み込みニューラルネットワーク）よりも優れたネットワークに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: SVAM: Saliency-guided Visual Attention Modeling by Autonomous Underwater
  Robots -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_53.html">
      <font color="black">SVAM: Saliency-guided Visual Attention Modeling by Autonomous Underwater
  Robots</font>
    </a>
  </h2>
  <font color="black">この論文では、自律型水中ロボットで使用するための顕著性誘導視覚注意モデリング（SVAM）への全体的なアプローチを示します。また、さまざまな水中シーンと水体のテスト画像、および画像を含むいくつかの海洋試験のデータによって、その一般化パフォーマンスを検証します。ボトムアップブランチは、大まかな、しかし適度に正確な顕著性推定を高速で実行しますが、より深いトップダウンブランチは、顕著なオブジェクトのきめ細かいローカリゼーションを提供する残差リファインメントモジュール（RRM）を組み込んでいます。 
[ABSTRACT] svam-ローカリゼーションは、自然の水中画像で効果的な顕著なオブジェクト検出（sod）のための深い視覚的特徴を提供する提案されたモデルです。プロジェクトは、水中sodに対するその有効性を示すベンチマークデータセットに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Domain Adaptation for Visual Navigation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_54.html">
      <font color="black">Unsupervised Domain Adaptation for Visual Navigation</font>
    </a>
  </h2>
  <font color="black">ビジュアルナビゲーションメソッドの進歩により、生のRGB画像から意味のある表現を学習し、構造的および意味論的推論を含むさまざまなタスクを実行できるインテリジェントな具体化されたナビゲーションエージェントが生まれました。さらに、学習したナビゲーションポリシーを転送するためにこのメソッドを使用できることを示します。シミュレーションで実世界に..私たちの方法は、変換がナビゲーションポリシーによって学習された表現と一致するように、ターゲットドメインの画像をソースドメインに変換します。 
[概要]本論文では、視覚ナビゲーションのための教師なしドメイン適応法を提案する。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Decomposing Normal and Abnormal Features of Medical Images for
  Content-based Image Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_55.html">
      <font color="black">Decomposing Normal and Abnormal Features of Medical Images for
  Content-based Image Retrieval</font>
    </a>
  </h2>
  <font color="black">これらの潜在コードを使用して、医用画像の正常または異常な特徴に焦点を当てて類似性検索を示します。このアイデアに基づいて、医用画像を2つの個別の潜在コードに分解するエンコーダ-デコーダネットワークを提案します。通常の解剖学的コードおよび異常な解剖学的コード..医用画像は、正常な特徴と異常な特徴に分解することができ、これは構成性と見なされます。 
[ABSTRACT]エンコーダー-デコーダーネットワークを使用して、医用画像を2つの潜在的なコードに分解できます。これらには正常な解剖学的構造と異常な解剖学的コードが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: CheXphotogenic: Generalization of Deep Learning Models for Chest X-ray
  Interpretation to Photos of Chest X-rays -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_56.html">
      <font color="black">CheXphotogenic: Generalization of Deep Learning Models for Chest X-ray
  Interpretation to Photos of Chest X-rays</font>
    </a>
  </h2>
  <font color="black">胸部X線写真に適用すると、いくつかのモデルのパフォーマンスが低下することがわかりましたが、この低下があっても、一部のモデルは放射線科医と同等のパフォーマンスを示しました。すべてのモデルは異なるグループによって開発され、CheXpertチャレンジに提出されました。 CheXphotoデータセット内のX線のスマートフォン写真にさらに調整せずに再適用しました。さまざまなモデルトレーニング手順が胸部X線写真へのモデルの一般化にどのように影響するかを理解するためにさらに調査を行うことができます。 
[概要] X線写真に対する胸部X線アルゴリズムのパフォーマンスは十分に調査されていません。これらのモデルはさまざまな診断グループによって開発され、chexpertチャレンジに提出されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: A deep Q-Learning based Path Planning and Navigation System for
  Firefighting Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_57.html">
      <font color="black">A deep Q-Learning based Path Planning and Navigation System for
  Firefighting Environments</font>
    </a>
  </h2>
  <font color="black">エージェントは、環境に対するアクションごとに、一連の報酬とペナルティに基づくディープQ学習アルゴリズムでトレーニングされます。ライブファイアは、動的で急速に変化する環境を作成し、ディープラーニングと人工知能の方法論に価値のある課題を提示します。消防士が状況認識を維持し、これらの壊滅的なイベントに取り組む際の重要な決定に必要な重要な機能を追跡および中継する際に、シーンの理解を支援します。経験の再生を活用して学習プロセスを加速し、人間由来の経験でエージェントの学習を強化します。 。 
[概要]ストレスによる見当識障害や不安の影響を受けない、深いq学習ベースのエージェントを提案します。このコンセプトは、実際の火災環境で観察および保存された事実に基づいて、ナビゲーションの明確な決定を作成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Content-based Image Retrieval and the Semantic Gap in the Deep Learning
  Era -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_58.html">
      <font color="black">Content-based Image Retrieval and the Semantic Gap in the Deep Learning
  Era</font>
    </a>
  </h2>
  <font color="black">この質問に答えるために、最初にインスタンス検索の最も関連性のあるマイルストーンの概要を簡単に説明します。ただし、セマンティクスは重要な役割を果たしません。コンテンツベースの画像検索は、過去10年間、特にクエリ画像に表示されているのと同じオブジェクトの画像を取得するタスク。 
[概要]このシナリオはインスタンスまたはオブジェクトの取得と呼ばれ、画像間できめの細かい視覚パターンを一致させる必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Measuring Human and Economic Activity from Satellite Imagery to Support
  City-Scale Decision-Making during COVID-19 Pandemic -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_59.html">
      <font color="black">Measuring Human and Economic Activity from Satellite Imagery to Support
  City-Scale Decision-Making during COVID-19 Pandemic</font>
    </a>
  </h2>
  <font color="black">経済活動は社会的行動に影響を与え、衛星画像に署名を残して自動的に検出および分類できます。このCNNアンサンブルフレームワークは、衛星画像のオブジェクト検出の最先端ベンチマークである米国国防総省xViewチャレンジで3位にランクされました。また、COVID-19の発生前後のさまざまなサイトの実際の例の結果を示して、さまざまな測定可能な指標を示します。 
[概要]経済活動は社会的行動に影響を与え、分類可能な衛星画像に署名を残します。このシステムを使用して、それに基づいて経済指標を自動的に計算し、分類することができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br><font color="black">2020-04-16</font>
      </time>
    </span>
</section>
<!-- paper0: An Aggregate Method for Thorax Diseases Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CV/paper_60.html">
      <font color="black">An Aggregate Method for Thorax Diseases Classification</font>
    </a>
  </h2>
  <font color="black">胸部X線画像データセットの実験結果は、この新しい重み付けスキームが分類パフォーマンスを改善し、EfficientNetからのトレーニング最適化もパフォーマンスをさらに改善することを示しています。この論文では、損失関数のトレーニングパターンの重みはに基づいて設計されています。クラス内のトレーニングパターンの数だけでなく、1つがこのトレーニングパターンをポジティブとして扱い、他のノードがネガティブとして扱うさまざまなノードでも..ディープネットワークトレーニングのための重み計算アルゴリズムの組み合わせアプローチを提案します。胸部疾患分類問題のための最先端のディープネットワークアーキテクチャからのトレーニングの最適化。 
[概要]このシステムは、胸部疾患分類問題のための最先端のディープネットワークアーキテクチャに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-07">
        <br><font color="black">2020-08-07</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: The Role of the Crowd in Countering Misinformation: A Case Study of the
  COVID-19 Infodemic -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_0.html">
      <font color="black">The Role of the Crowd in Countering Misinformation: A Case Study of the
  COVID-19 Infodemic</font>
    </a>
  </h2>
  <font color="black">さらに重要なことに、群衆がツイートに反論する方法に対照的な違いがあり、一部のツイートは意見のように見えますが、他のツイートには評判の高い情報源へのリンクなどの具体的な証拠が含まれています。この作業では、虚偽の主張のデータセットをキュレートし、私たちの仕事は、一部のユーザーがソーシャルプラットフォームで誤った情報に有機的に対抗する方法と、専門的なファクトチェックを拡大する上でユーザーが果たす役割についての洞察を提供します。これらの洞察は、ツールやメカニズムの開発につながる可能性があります。誤った情報と戦う際に関係する市民に力を与えることができます。 
[要約]誤った情報が表示されるプラットフォームのユーザーである関係者は、事実の普及、つまり情報の確認と誤った情報の拡散への対抗において重要な役割を果たすことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Enabling Interactive Transcription in an Indigenous Community -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_1.html">
      <font color="black">Enabling Interactive Transcription in an Indigenous Community</font>
    </a>
  </h2>
  <font color="black">音声文字変換の初期段階で、利用可能なデータが堅牢なASRシステムをトレーニングするには不十分な場合、音声コレクションの音声文字変換をブートストラップするために、少数の孤立した単語の音声文字変換を利用できることを示します。 。パイロット実験とともに、音声用語の検出とヒューマンインザループを組み合わせた新しい文字起こしワークフローを提案します。この作業は、これまでに少数の用語しか特定されていないほぼゼロのリソースシナリオに基づいています。 2つの危険にさらされた言語を含みます。 
[要約]作業はほぼゼロに基づいています-リソースシナリオでは、いくつかの用語しか特定されていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: The Gap on GAP: Tackling the Problem of Differing Data Distributions in
  Bias-Measuring Datasets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_2.html">
      <font color="black">The Gap on GAP: Tackling the Problem of Differing Data Distributions in
  Bias-Measuring Datasets</font>
    </a>
  </h2>
  <font color="black">共参照解決のためのGAPデータセットの方法を示します。バイアスモデルを検出できる診断データセットは、自然言語処理内のバイアス削減の重要な前提条件です。ただし、収集されたデータの望ましくないパターンにより、このようなテストが不正確になる可能性があります。 
[概要]テストデータの同様のパターンに対処するためにテストサンプルに重みを付ける新しい方法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Supervised Multimodal Bitransformers for Classifying Images and Text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_3.html">
      <font color="black">Supervised Multimodal Bitransformers for Classifying Images and Text</font>
    </a>
  </h2>
  <font color="black">BERTなどの自己監視型双方向トランスモデルは、さまざまなテキスト分類タスクの劇的な改善につながりました。テキストエンコーダと画像エンコーダからの情報を融合し、最先端のパフォーマンスを実現する教師ありマルチモーダルバイトランスモデルを紹介します。さまざまなマルチモーダル分類ベンチマークタスクで、マルチモーダルパフォーマンスを測定するために特別に設計されたハードテストセットを含む、強力なベースラインを上回っています。しかし、現代のデジタル世界はますますマルチモーダルになり、テキスト情報には画像などの他のモダリティが伴うことがよくあります。 
[概要]現代のデジタル世界はますますマルチモーダルになっていますが、よりマルチモーダルです。情報の使用には、画像などの他の要因が伴うことがよくあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-06">
        <br><font color="black">2019-09-06</font>
      </time>
    </span>
</section>
<!-- paper0: Exploiting Cross-Dialectal Gold Syntax for Low-Resource Historical
  Languages: Towards a Generic Parser for Pre-Modern Slavic -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_4.html">
      <font color="black">Exploiting Cross-Dialectal Gold Syntax for Low-Resource Historical
  Languages: Towards a Generic Parser for Pre-Modern Slavic</font>
    </a>
  </h2>
  <font color="black">一般的な前近代のスラブ語パーサーと2つの特殊なパーサー（1つは東スラブ語用、もう1つは南スラブ語用）は、共同音声部分（POS）タグ付けのニューラルネットワークモデルであるjPTDP（Nguyen＆Verspoor 2018）を使用してトレーニングされます古代教会スラヴ語（OCS）を含む多くのUniversal Dependency（UD）ツリーバンクで有望な結果を示した依存関係の解析。これらの実験により、両方のOCSで新しい最先端技術が得られます（83.79 \％ラベルなし添付スコア（UAS）および78.43 \％ラベル付きアタッチメントスコア（LAS））およびOld East Slavic（OES）（85.7 \％UASおよび80.16 \％LAS）..初期のスラブ依存関係解析に関する以前の実験について、特にその能力に関して説明します。さまざまなオルソグラフィック、地域、スタイルの特徴に取り組むため。 
[要約] pre-現代のスラブの品種は低リソースの歴史的言語として扱われます。研究はデータ損失を克服し、問題を特定するために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Antibody Watch: Text Mining Antibody Specificity from the Literature -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_5.html">
      <font color="black">Antibody Watch: Text Mining Antibody Specificity from the Literature</font>
    </a>
  </h2>
  <font color="black">抽出されたアラートを使用して、問題のある抗体のサポートステートメントを含む「AntibodyWatch」ナレッジベースを構築できます。2番目のタスクは、これらのスニペットのそれぞれを、スニペットに記載されている1つ以上の抗体にリンクすることです。タンパク質やその他の抗原の発現をテストします。 
[ABSTRACT]研究者は、文献で報告されている抗体の特異性に関する記述を抽出することにより、問題のある抗体のユーザーへのアラートを自動的に生成する可能性を調査しました。結果は、問題のある抗体に関する信頼できる知識ベースを構築することが可能であることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Towards A Sentiment Analyzer for Low-Resource Languages -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_6.html">
      <font color="black">Towards A Sentiment Analyzer for Low-Resource Languages</font>
    </a>
  </h2>
  <font color="black">ハッシュタグを使用してTwitterから一連のデータを取得し、ツイートからユーザーのポジティブまたはネガティブな感情をさらに分析および調査します。この調査では、ラピッドマイナーツールを使用してTwitterデータを生成し、K-NearestのNaiveBayesを比較します。 Twitterデータの感情を分類するためのネイバー、ディシジョンツリー、およびマルチレイヤーパーセプトロンの分類方法。この実験には、全体で200のラベル付きデータがあります。 
[要約]ハッシュタグは、ツイートからのユーザーのポジティブまたはネガティブな感情を分析するために使用されます。この実験には、全体で200のラベル付きデータがあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: ConvBERT: Improving BERT with Span-based Dynamic Convolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_7.html">
      <font color="black">ConvBERT: Improving BERT with Span-based Dynamic Convolution</font>
    </a>
  </h2>
  <font color="black">実験により、ConvBERTは、さまざまなダウンストリームタスクでBERTとそのバリアントを大幅に上回り、トレーニングコストが低く、モデルパラメータが少ないことが示されています。したがって、これらの自己注意ヘッドを置き換えてローカル依存関係を直接モデル化する、新しいスパンベースの動的畳み込みを提案します。新規の畳み込みヘッドは、残りの自己注意ヘッドとともに、グローバルおよびローカルのコンテキスト学習の両方でより効率的な新しい混合注意ブロックを形成します。 
[概要]私たちは、自然なオランダのオランダのオランダ人に混合注意設計を装備し、変換モデルを構築します。このモデルは、グローバルな自己畳み込みブロックに基づいています。ただし、ニューヨークベースのモデルの合計容量は86.4接着剤です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-06">
        <br><font color="black">2020-08-06</font>
      </time>
    </span>
</section>
<!-- paper0: Linguistically-Informed Transformations (LIT): A Method for
  Automatically Generating Contrast Sets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_8.html">
      <font color="black">Linguistically-Informed Transformations (LIT): A Method for
  Automatically Generating Contrast Sets</font>
    </a>
  </h2>
  <font color="black">さらに、元のデータのパフォーマンスに影響を与えることなく、LITを適用してトレーニングデータを拡張することにより、コントラストセットでのモデルのパフォーマンスを向上させます。この作業では、コントラストを自動的に生成する言語情報変換（LIT）メソッドを提案します。実践者が関心のある言語現象を探索し、さまざまな現象を構成できるようにするセット。SNLIとMNLIで私たちの方法を実験すると、現在の事前トレーニング済み言語モデルは、十分な言語知識を含んでいると主張されていますが、自動生成されたコントラストセットに苦労していることがわかります。 
[概要]このメソッドはsnliとmnliで開発されました。これは、既存の事前トレーニング済み言語モデルがシステムで苦労していることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-16">
        <br><font color="black">2020-10-16</font>
      </time>
    </span>
</section>
<!-- paper0: Identifying Depressive Symptoms from Tweets: Figurative Language Enabled
  Multitask Learning Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_9.html">
      <font color="black">Identifying Depressive Symptoms from Tweets: Figurative Language Enabled
  Multitask Learning Framework</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、比喩的な使用法をモデル化することで、うつ病の症状を区別するためのモデルの堅牢性と信頼性を明らかに向上させることができることを示しています。比喩的な使用法は効果的な表現に貢献します。この研究は、患者の健康に関する質問-9（Patient Health Questionnaire-9（ PHQ-9）これは臨床診療で日常的に使用されています。 
[概要]ツイートの280文字の制限により、発話でのクリエイティブなアーティファクトの使用が促進されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: A Parallel Evaluation Data Set of Software Documentation with Document
  Structure Annotation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_10.html">
      <font color="black">A Parallel Evaluation Data Set of Software Documentation with Document
  Structure Annotation</font>
    </a>
  </h2>
  <font color="black">データセットは、英語からヒンディー語、インドネシア語、マレー語、タイ語の言語ペアで構成されているため、リソースの少ない多くの言語ペアのテストカバレッジも向上します。起源と作成、特殊性と特性に関する洞察を提供します。データセットと機械翻訳の結果..プレーンな並列テキストで構成されるほとんどの評価データセットとは異なり、このデータセットのセグメントには、ドキュメントコンテキストの構造情報を説明する追加のメタデータが付属しています。 
[概要]機械翻訳システムを調整および評価する可能性を提供します。より幅広い評価シナリオの可用性を高めます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-11">
        <br><font color="black">2020-08-11</font>
      </time>
    </span>
</section>
<!-- paper0: A multi-layer approach to disinformation detection on Twitter -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_11.html">
      <font color="black">A multi-layer approach to disinformation detection on Twitter</font>
    </a>
  </h2>
  <font color="black">また、国に依存しないように見える2つのニュースドメインの共有パターンの違いを強調します。文法、構文、スタイル）。Twitter拡散ネットワークの多層表現を採用し、各層についてセットを計算します。共有プロセスのさまざまな側面を定量化するグローバルネットワーク機能の概要。 
[要約]この手法は、ニュースコンテンツに見られる複数レベルの複雑さを回避することができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-28">
        <br><font color="black">2020-02-28</font>
      </time>
    </span>
</section>
<!-- paper0: DisenE: Disentangling Knowledge Graph Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_12.html">
      <font color="black">DisenE: Disentangling Knowledge Graph Embeddings</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案されたDisenEがKGEの解釈可能性に対処するための視点を調査し、リンク予測タスクのパフォーマンスを改善する効果的な方法であることが証明されていることを示しています。エンティティと関係を低に埋め込むことを目的とした知識グラフ埋め込み（KGE）次元ベクトルは、最近広く注目されています。特に、モデルが特定の関係に従ってエンティティ埋め込みの関連コンポーネントに明示的に焦点を合わせることができる注意ベースのメカニズムを導入します。 
[概要]新しい研究は主にブラックボックス神経モデルに基づいています。これにより、学習した表現を解釈することが困難になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: SigmaLaw-ABSA: Dataset for Aspect-Based Sentiment Analysis in Legal
  Opinion Texts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_13.html">
      <font color="black">SigmaLaw-ABSA: Dataset for Aspect-Based Sentiment Analysis in Legal
  Opinion Texts</font>
    </a>
  </h2>
  <font color="black">私たちの知る限り、リーガルオピニオンテキストのアスペクト（パーティ）ベースの感情分析に公開されているデータセットはありません。この調査では、研究者の支援を目的とした手動で注釈を付けたリーガルオピニオンテキストデータセット（SigmaLaw-ABSA）を紹介します。法的な領域でのABSAタスクの場合..SigmaLaw-ABSAは、人間の裁判官によって注釈が付けられた英語の法的な意見のテキストで構成されています。 
[要約]広範囲のドメインで公開されているデータセットの数は、通常、absaの分野で研究を行う研究者のニーズを満たします。法的なドメインのabsaの研究で公開されているデータセットを作成するには、いくつかを紹介します。データセット上のいくつかの既存の深層学習ベースのシステムのパフォーマンスに関する結果</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Natural Language Processing to Detect Cognitive Concerns in Electronic
  Health Records Using Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_14.html">
      <font color="black">Natural Language Processing to Detect Cognitive Concerns in Electronic
  Health Records Using Deep Learning</font>
    </a>
  </h2>
  <font color="black">ただし、認知機能障害に関する情報は、医療記録内の構造化されていない臨床医のメモによく見られますが、専門家による手動レビューには時間がかかり、エラーが発生しやすいことがよくあります。注意ベースの深層学習モデルは、ベースラインモデルやその他の単純なモデルよりも優れています。これらのメモのマイニングは、評価から利益を得るか、専門家のケアに紹介される可能性のある認知的懸念を持つ患者にラベルを付ける潜在的な機会を提供します。 
[要約]認知機能障害に関する情報は、医療記録内の構造化されていないメモによく見られます。専門家による手動レビューには時間がかかり、エラーが発生しやすいことがよくあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Incorporating a Local Translation Mechanism into Non-autoregressive
  Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_15.html">
      <font color="black">Incorporating a Local Translation Mechanism into Non-autoregressive
  Translation</font>
    </a>
  </h2>
  <font color="black">5つの翻訳タスクの経験的結果は、CMLMと比較して、私たちの方法がより少ないデコード反復で同等以上のパフォーマンスを達成し、2.5倍のスピードアップをもたらすことを示しています。さらなる分析は、私たちの方法が繰り返される翻訳を減らし、より長い文でより良いパフォーマンスを示すことを示しています。トークンを1つだけではなく、各ターゲットのデコード位置で、自己回帰的な方法でトークンの短いシーケンスを予測します。 
[ABSTRACT] latを条件付きマスク言語モデルに統合し、同様に反復自己回帰を採用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Constructing A Multi-hop QA Dataset for Comprehensive Evaluation of
  Reasoning Steps -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_16.html">
      <font color="black">Constructing A Multi-hop QA Dataset for Comprehensive Evaluation of
  Reasoning Steps</font>
    </a>
  </h2>
  <font color="black">実験を通じて、データセットがマルチホップモデルにとって挑戦的であり、マルチホップ推論が必要であることを確認します。データセットでは、マルチホップ質問の推論パスを含む証拠情報を紹介します。慎重に設計します。マルチホップステップと質問の品質を保証する質問と回答のペアを生成するときのパイプラインとテンプレートのセット。 
[要約]以前のデータセットは、質問から回答までの推論プロセスの完全な説明を提供していません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Summarization of Open-Domain Podcast Episodes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_17.html">
      <font color="black">Automatic Summarization of Open-Domain Podcast Episodes</font>
    </a>
  </h2>
  <font color="black">私たちの最高のシステムは、NIST評価者によって判断された1.559の品質評価を達成します---作成者の説明よりも0.268（+ 21％）の絶対的な増加です。ポッドキャスト要約タスクで競争力のある結果を達成する抽象要約の実装の詳細を示します。 TREC 2020 ..私たちの結果は、トランスクリプトから重要なセグメントを識別して、抽象的な要約への入力として使用することが、長い文書を要約するのに有利であることを示唆しています。 
[概要]重要な情報を収集する簡潔な文学的要約は、ユーザーがポッドキャストを聞くかどうかを決定するために重要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: World Trade Center responders in their own words: Predicting PTSD
  symptom trajectories with AI-based language analyses of interviews -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_18.html">
      <font color="black">World Trade Center responders in their own words: Predicting PTSD
  symptom trajectories with AI-based language analyses of interviews</font>
    </a>
  </h2>
  <font color="black">将来の研究では、このアプリケーションを他のトラウマ曝露や他の人口統計グループ、特に少数派にまで拡大する必要があります。PTSD症状の重症度は、インタビュー後最大7年間、PTSDチェックリスト（PCL）を使用して縦方向に測定されました。AIベースの指標言語的および対人的スタイルの辞書ベースの測定とともに、うつ病、不安、神経症、および外傷について計算されました。 
[ABSTRACT]人工知能（ai）モデルは、自然言語で精神病理学を検出することを約束しますが、主にソーシャルメディアを使用して評価されています。これは、ptsdの理解におけるaiの価値を実証する最初の研究です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Theoretical Knowledge Graph Reasoning via Ending Anchored Rules -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_19.html">
      <font color="black">Theoretical Knowledge Graph Reasoning via Ending Anchored Rules</font>
    </a>
  </h2>
  <font color="black">結果は、EARDictモデルが、WN18RRで80.38パーセントのHits @ 10スコアを含む、ベンチマーク知識グラフ完了タスクで新しい最先端のパフォーマンスを達成することを示しています。知識グラフから正確で具体的なルールを発見することは、不可欠な課題と見なされます。 、これにより、多くのダウンストリームタスクのパフォーマンスが向上し、自然言語処理の研究トピックにアプローチする新しい方法が提供されます。私たちの理論は、トリプルが正しい理由またはそうでない理由に答える正確な理由を提供します。 
[概要]新しい研究は新しい研究チームによって実施されました。それは知識グラフ推論の基礎理論を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Fairness and Robustness in Invariant Learning: A Case Study in Toxicity
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_20.html">
      <font color="black">Fairness and Robustness in Invariant Learning: A Case Study in Toxicity
  Classification</font>
    </a>
  </h2>
  <font color="black">インターネットコメントの毒性を公正に予測するタスクに、因果的発見に触発された方法を使用して堅牢な予測子を見つけるドメイン一般化アルゴリズムである不変リスク最小化（IRM）を適用します。IRMがより優れた配布外精度を達成することを示します。経験的リスク最小化（ERM）手法よりも公平性が高く、IRMを実際に適用するときに発生する問題と、このシナリオでIRMが効果的である可能性が高い条件の両方を分析します。この作業がどの程度堅牢であるかについてのさらなる研究を刺激することを願っています。機械学習法は、アルゴリズムの公平性に関連しています。 
[概要]ロバストなmlのアルゴリズムを使用して、分類器の公平性を改善できるかどうかを調査します。irmがシナリオでより公平で効果的かつ効果的に使用することを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Author's Sentiment Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_21.html">
      <font color="black">Author's Sentiment Prediction</font>
    </a>
  </h2>
  <font color="black">エンティティ感情分析の課題として、5.3kのドキュメントと3.2kの一意のエンティティをカバーする38kの段落を含むこのデータセットをリリースします。複数の強力なベースラインのベンチマークは、これが難しい分類タスクであることを示しています。段落レベルの決定を行い、それらを集約します。ドキュメント全体も効果がありません。 
[要約]データセットには、タスクのよりきめ細かいエンティティを提供するための段落注釈も含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: An Interpretable End-to-end Fine-tuning Approach for Long Clinical Text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_22.html">
      <font color="black">An Interpretable End-to-end Fine-tuning Approach for Long Clinical Text</font>
    </a>
  </h2>
  <font color="black">SnipBERTは、メモ全体を使用する代わりに、重要なスニペットを識別し、それらを階層的に切り捨てられたBERTベースのモデルにフィードします。経験的に、SnipBERTは、3つのタスクにわたって予測パフォーマンスが大幅に向上するだけでなく、モデルのように解釈可能性も向上します。予測につながった重要なテキストを特定します。この作業では、SnipBERTと呼ばれる新しい微調整アプローチを提案します。 
[ABSTRACT] snipbertは、bertベースのモデルを使用して、臨床情報の抽出とテキスト分類を行います。モデルは、予測につながった重要なテキストを識別できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Inference-only sub-character decomposition improves translation of
  unseen logographic characters -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_23.html">
      <font color="black">Inference-only sub-character decomposition improves translation of
  unseen logographic characters</font>
    </a>
  </h2>
  <font color="black">言語ペアとドメインごとに、すべてのソースセンテンスに少なくとも1つの表語文字が含まれるテストセットを作成します。ただし、このアプローチには完全な再トレーニングが含まれ、非表語文字への表語文字の翻訳の有効性は十分に検討されていません。 。見えない文字についてのみ、推論前の分解に基づく簡単な代替手段を提供します。 
[概要]これには、トレーニングおよびテスト文のサブ文字分解が含まれます。この方法は、既存のイデオグラフのサブ文字分解に基づいています。言語に害を及ぼすことが多く、一貫性のない結果が得られます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Analyzing Neural Discourse Coherence Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_24.html">
      <font color="black">Analyzing Neural Discourse Coherence Models</font>
    </a>
  </h2>
  <font color="black">この作業では、現在のコヒーレンスモデルが談話組織に関係するテキストの側面をどの程度うまくキャプチャできるかを体系的に調査します。最後に、データセットを研究者が談話コヒーレンスモデルをテストするために使用するリソースとして公開します。さらに談話を調査します。スペースを埋め込み、コヒーレンスの表現にエンコードされている知識を調べます。 
[概要]コヒーレンスを損なうさまざまな変更の2つのデータセットを考案します。談話の変更に対するモデルの感度をテストします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Intent Mining from past conversations for Conversational Agent -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_25.html">
      <font color="black">Intent Mining from past conversations for Conversational Agent</font>
    </a>
  </h2>
  <font color="black">さらに、意図を持って数百から数千の会話にラベルを付けるコストは、時間と労力のかかる仕事です。システムは会話システムの意図モデルを構築するために開発されていますが、このフレームワークは短いテキストのクラスタリングやラベル付けフレームワークとして..このペーパーでは、4つの主要なステップを含む意図発見フレームワークを提示します。事前にトレーニングされたドメインに依存しないDialog Act Classifier（データ抽出）を使用した会話からのテキスト発話の抽出、類似したユーザー発話の自動クラスタリング（クラスタリング）、インテントラベルを使用したクラスターの手動注釈（ラベリング）、およびクラスターにマップされていない前のステップの発話へのインテントラベルの伝播（ラベル伝播）。生の会話から意図的なトレーニングデータを生成します。 
[ABSTRACT]インテントモデルは、文学的発話とインテントラベルのペアのコレクションを使用して、教師あり設定でトレーニングされます。インテントで数百から数千の会話にラベルを付けるコストは、時間と労力を要する作業です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-22">
        <br><font color="black">2020-05-22</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-lingual and Multilingual Spoken Term Detection for Low-Resource
  Indian Languages -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_26.html">
      <font color="black">Cross-lingual and Multilingual Spoken Term Detection for Low-Resource
  Indian Languages</font>
    </a>
  </h2>
  <font color="black">音声用語検出（STD）は、テキストまたは音声入力のいずれかをクエリとして指定して、音声内の単語またはフレーズを検索するタスクです。この作業では、最先端のヒンディー語、タミル語、テルグ語のASRシステムを使用します。 -言語的には、リソースの少ない10のインド言語での語彙音声用語検出用。STDの標準メトリックである平均用語加重値（MTWV）を報告し、ターゲット言語と音声的に類似した言語で構築されたASRシステムの精度が高いことを示します。ただし、緩和された電話照合アルゴリズムを使用することにより、異なる言語の高いMTWVスコアを取得することもできます。 
[概要]新しい調査によると、言語で構築されたasrシステムの方が精度が高いことが示されています。リラックスした電話照合アルゴリズムを使用することで、異なる言語に対して高レベルのタスクを取得できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Supervised Contrastive Learning for Pre-trained Language Model
  Fine-tuning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_27.html">
      <font color="black">Supervised Contrastive Learning for Pre-trained Language Model
  Fine-tuning</font>
    </a>
  </h2>
  <font color="black">優れた一般化には、あるクラスの例間の類似性をキャプチャし、それらを他のクラスの例と対比する必要があるという直感に基づいて、微調整段階の教師あり対照学習（SCL）目標を提案します。トレーニングデータのさまざまなレベルのノイズに対してより堅牢なモデルにつながり、ラベル付けされたタスクデータが制限された関連タスクによりよく一般化できます。クロスエントロピーと組み合わせることで、提案するSCL損失は、強力なRoBERTa-Largeよりも改善されます。高データと低データの両方のレジームにおけるGLUEベンチマークの複数のデータセットのベースラインであり、特殊なアーキテクチャ、あらゆる種類のデータ拡張、メモリバンク、または追加の教師なしデータを必要としません。 
[概要] scl損失は、強力なロベルタ（高2と低の両方のデータレジームにおける接着剤ベンチマークの複数のデータセットの大きなベースライン）に対する改善を提案します。モデル、メモリバンク、またはより多くの教師なしデータは必要ありません。 、またはさらに監視されていないもの</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Neural Lyrics and Melody Composition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_28.html">
      <font color="black">Automatic Neural Lyrics and Melody Composition</font>
    </a>
  </h2>
  <font color="black">この論文では、人間のコミュニティがオリジナルの歌詞と生成された歌詞に適したメロディーを発見できるようにする、アルゴリズムによる作詞作曲プロセスの最も困難な側面に対処する手法を提案します。歌詞、単語、文のレベルで解析された歌詞とメロディのペアのデータセットのセットは大規模な埋め込みモデルであり、人気のある英語の曲のリカレントニューラルネットワークなどのデータ駆動型モデルをトレーニングできます。エンドツーエンドでトレーニングされた歌詞ジェネレーター、歌詞エンコーダー、メロディーデコーダーの
[概要]提案された作詞作曲システム、自動ニューラル歌詞とメロディー構成（autonlmc）は、作詞作曲自動データのプロセス全体を設定する試みです。このシステムは、自動ニューラルネットワークによって設計されたシステムのモデルです。一致するメロディーを生成するプロの歌詞ライター</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Augmenting BERT Carefully with Underrepresented Linguistic Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_29.html">
      <font color="black">Augmenting BERT Carefully with Underrepresented Linguistic Features</font>
    </a>
  </h2>
  <font color="black">ただし、以前の調査では、モデルに追加情報を追加することで、さまざまなタスクでのBERTのパフォーマンスを向上させることが可能であることが示されています。トランスフォーマーからの微調整された双方向エンコーダー表現（BERT）ベースのシーケンス分類モデルは、アルツハイマー病の検出に効果的であることが証明されています（ AD）人間のスピーチのトランスクリプトから..この作業では、BERTのさまざまな層で十分に表されていないが、AD検出タスクにとって重要な言語情報を識別するためのイントロスペクション手法としてプロービングタスクを使用します。 
[要約]調査によると、モデルに追加情報を追加することで、バートのパフォーマンスを向上させることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Biomedical Named Entity Recognition at Scale -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_30.html">
      <font color="black">Biomedical Named Entity Recognition at Scale</font>
    </a>
  </h2>
  <font color="black">Apache Sparkの上にBi-LSTM-CNN-Charディープラーニングアーキテクチャを再実装し、BERTのような重いコンテキスト埋め込みを使用せずに、7つの公開生物医学ベンチマークで新しい最先端の結果を取得する単一のトレーニング可能なNERモデルを提示します。さらに、このモデルは、オープンソースのSparkNLPライブラリの一部としてプロダクショングレードのコードベース内で無料で利用できます。任意のSparkクラスターでトレーニングと推論のためにスケールアップできます。 Python、R、Scala、Javaなどの一般的なプログラミング言語用のGPUサポートとライブラリがあります。コードを変更せずに他の人間の言語をサポートするように拡張できます。これには、BC4CHEMDを93.72％（4.1％ゲイン）に、Species800を80.91％（4.6％ゲイン）に、JNLPBAを81.29％（5.2％ゲイン）に改善することが含まれます。 
[ABSTRACT] nerは、臨床ノートやレポートから意味のあるチャンクを抽出する上で重要な役割を果たします。これらは、スティント、隔離、識別解除などのJavaタスクに送られます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Overview of the Ninth Dialog System Technology Challenge: DSTC9 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_31.html">
      <font color="black">Overview of the Ninth Dialog System Technology Challenge: DSTC9</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、タスクの定義、提供されたデータセット、ベースライン、および各トラックの評価設定について説明します。ダイアログのインタラクティブな評価、および4 ..提出されたシステムの結果を要約して、最新の状態の全体的な傾向を強調します。タスクのための最先端のテクノロジー。 
[概要] dstcのこのエディションは、ダイアログシステムの4つの異なるタスクにエンドツーストのダイアログテクノロジーを適用することに焦点を当てています。また、提出されたシステムの結果を要約して、状態-s-とテクノロジーの全体的な傾向を強調します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Domain Sentiment Classification with Contrastive Learning and
  Mutual Information Maximization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_32.html">
      <font color="black">Cross-Domain Sentiment Classification with Contrastive Learning and
  Mutual Information Maximization</font>
    </a>
  </h2>
  <font color="black">さらに、MIMはモデルの予測の比較的バランスの取れた分布を維持し、ターゲットドメインのクラス間のマージンを拡大します。私たちの知る限り、CLIMは自然言語処理（NLP）に対照学習を採用した最初の企業です。ドメイン間でのタスク..ターゲットドメインのラベルが不足しているため、CLとは別に相互情報最大化（MIM）を導入して、最終的な予測を最適にサポートする機能を活用します。 
[要約] clim：相互情報量を最大化する学習方法が提案されています。これは、クロスドメイン感情分類におけるclの可能性を調査することです。これは、最終予測を最もよくサポートする機能を活用するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-30">
        <br><font color="black">2020-10-30</font>
      </time>
    </span>
</section>
<!-- paper0: Biomedical Information Extraction for Disease Gene Prioritization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/cs.CL/paper_33.html">
      <font color="black">Biomedical Information Extraction for Disease Gene Prioritization</font>
    </a>
  </h2>
  <font color="black">確立された構造化ソースからのPPIがすでに含まれているにもかかわらず、独自のIEベースの抽出をグラフに追加することで、医薬品開発に向けた重要なステップであるhit @ 30の相対的な増加が20％増加する、新しい疾患と遺伝子の関連性を予測できることを示します。未治療の疾患の標的..テキストから生物学的関係を抽出する生物医学情報抽出（IE）パイプラインを紹介し、名前付きエンティティ認識（NER）や関係抽出（RE）などのコンポーネントが現状を上回っていることを示します。 art in BioNLP ..それを数千万のPubMedアブストラクトに適用して、タンパク質間相互作用（PPI）を抽出し、これらの抽出を、主要な構造化PPIデータベースであるSTRINGから抽出されたPPIをすでに含む生物医学知識グラフに拡張します。 
[ABSTRACT]タンパク質間相互作用（ppis）の抽出に適用します。抽出された抽出抽出物は、将来的に使用される可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Using IPA-Based Tacotron for Data Efficient Cross-Lingual Speaker
  Adaptation and Pronunciation Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.AS/paper_0.html">
      <font color="black">Using IPA-Based Tacotron for Data Efficient Cross-Lingual Speaker
  Adaptation and Pronunciation Enhancement</font>
    </a>
  </h2>
  <font color="black">転送されたモデルを主観的および客観的な方法で評価します。最近のニューラルテキスト読み上げ（TTS）モデルは、十分なデータが利用可能な場合に非常に良好に機能することが示されています。この目的のために、最初にベースライン多言語を導入します。言語に依存しない入力を備えたTacotronは、事前にトレーニングされたスピーカーエンコーダーやコードスイッチング技術を利用せずに、スピーカー適応のさまざまなシナリオで転送学習がどのように行われるかを示します。 
[概要]最初に、言語を使用したベースラインの新しいスピーカーを紹介します-agitical input。次に、事前にトレーニングされたスピーカーエンコーダーを利用せずに、スピーカー適応のさまざまなシナリオで転送学習がどのように行われるかを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Evaluating the Intelligibility Benefits of Neural Speech Enrichment for
  Listeners with Normal Hearing and Hearing Impairment using the Greek Harvard
  Corpus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.AS/paper_1.html">
      <font color="black">Evaluating the Intelligibility Benefits of Neural Speech Enrichment for
  Listeners with Normal Hearing and Hearing Impairment using the Greek Harvard
  Corpus</font>
    </a>
  </h2>
  <font color="black">通常の聴覚（NH）と聴覚障害（HI）の両方のリスナーが、音声受信しきい値（SRT）に一致するリスナー固有のSNRで音声整形ノイズ（SSN）の下でモデルを評価しました。これは、変更されていない音声の50％が理解できるポイントです。 wSSDRCは、過去に英語の資料と話者のテストに成功しました。分析統計によると、wSSDRCモデルは、単純な未処理の音声と比較して、NHで39％、HIで38％の了解度の中央値を向上させました。 
[概要]コーパスは、ハーバード/スカイラの文の形式に従って開発されました。ギリシャ語のリスナーに対して、神経音声強調モデルを適用し、パフォーマンスの向上を調べる機会を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: DESNet: A Multi-channel Network for Simultaneous Speech Dereverberation,
  Enhancement and Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.AS/paper_2.html">
      <font color="black">DESNet: A Multi-channel Network for Simultaneous Speech Dereverberation,
  Enhancement and Separation</font>
    </a>
  </h2>
  <font color="black">さらに、新しいディープコンプレックス畳み込みリカレントネットワーク（DCCRN）が音声アンミキシングの構造として使用され、ニューラルネットワークベースの加重予測誤差（WPE）が音声の残響除去のために事前にカスケードされます。実験によると、非残響の場合、提案されたDESNetは、音声強調と分離においてDCCRNとほとんどの最先端の構造を上回りますが、デリバーブシナリオでは、DESNetはカスケードWPE-DCCRNネットワークよりも改善されています。勾配伝播とジョイント最適化を可能にするために、マルチチャネル機能の選択メカニズム。これは元々、エンドツーエンドのアンミキシング、固定ビームフォーミングおよび抽出（E2E-UFE）構造で提案されています。 
[概要]提案された変更に加えて、マルチチャネル機能の注意技術を採用します。また、ネットワークのトレーニングのための段階的なsnr戦略と損失を紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-04">
        <br><font color="black">2020-11-04</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchical Prosody Modeling for Non-Autoregressive Speech Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.AS/paper_3.html">
      <font color="black">Hierarchical Prosody Modeling for Non-Autoregressive Speech Synthesis</font>
    </a>
  </h2>
  <font color="black">提案された方法は、客観的および主観的な評価において、オーディオ品質と韻律の自然さの点で他の競合他社よりも優れています。ただし、推論時に自然で合理的な韻律を予測することは困難です。韻律モデリングは、現代のテキストから音声への不可欠なコンポーネントです（ TTS）フレームワーク。 
[概要]この作品では、さまざまな韻律の下での非自己回帰モデルの動作を分析しました-モデリング設定。韻律機能を提供することに加えて、平坦化された音声のスタイルを制御できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Neural Lyrics and Melody Composition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.AS/paper_4.html">
      <font color="black">Automatic Neural Lyrics and Melody Composition</font>
    </a>
  </h2>
  <font color="black">AutoNLMCは、エンドツーエンドでトレーニングされた歌詞ジェネレーター、歌詞エンコーダー、メロディーデコーダーで構成されるエンコーダーデコーダーシーケンシャルリカレントニューラルネットワークモデルです。歌詞とメロディーのペアデータセットの大規模なセットでトレーニングされた歌詞からベクトル（lyric2vec）モデル歌詞、単語、文のレベルで解析される大規模な埋め込みモデルにより、人気のある英語の曲のリカレントニューラルネットワークなどのデータ駆動型モデルをトレーニングできます。この論文では、アルゴリズムによる作詞作成プロセスの最も困難な側面に対処する手法を提案します。これにより、人間のコミュニティはオリジナルの歌詞と、生成された歌詞に適したメロディーを見つけることができます。 
[概要]提案された作詞作曲システム、自動ニューラル歌詞とメロディー構成（autonlmc）は、作詞作曲自動データのプロセス全体を設定する試みです。このシステムは、自動ニューラルネットワークによって設計されたシステムのモデルです。一致するメロディーを生成するプロの歌詞ライター</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: The CUHK-TUDELFT System for The SLT 2021 Children Speech Recognition
  Challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-13/eess.AS/paper_5.html">
      <font color="black">The CUHK-TUDELFT System for The SLT 2021 Children Speech Recognition
  Challenge</font>
    </a>
  </h2>
  <font color="black">私たちのシステムは、指定されたテストセットで20.1％、全体で10番目に配置された公式評価セットで23.6％の文字エラー率（CER）を達成しました。データ前処理の手順、背景、およびコースシステム開発の概要について説明します。私たちのアプローチは、CTCアテンションエンドツーエンド（E2E）音声認識フレームワークの使用、転送学習、データ拡張、およびさまざまな言語モデルの開発を組み合わせたものです。 
[概要]私たちのアプローチは、共同ctc-注意の終わり-から-th（e2e）の音声認識フレームワークの使用、伝達学習、データ拡張、およびさまざまな言語モデルの開発を組み合わせたものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
