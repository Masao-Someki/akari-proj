<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-07-28の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Neural Architecture Search for Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.SD/paper_0.html">
      <font color="black">Neural Architecture Search for Speech Recognition</font>
    </a>
  </h2>
  <font color="black">300時間の配電盤の会話型電話音声認識タスクで実施された実験は、NASの自動構成TDNN-Fシステムが、手動のエキスパート構成を使用して、ベースラインのLF-MMIトレーニング済みTDNN-Fシステムを常に上回っていることを示唆しています。そして、28％の相対的なモデルサイズの縮小が得られました。これらには、格子のないMMI（LF-MMI）トレーニングにおけるアーキテクチャの重みとTDNNパラメータの推定を完全に統合する標準DARTSメソッドが含まれます。候補アーキテクチャ間の混乱を軽減するGumbel-Softmax DARTS。保持されたデータを使用してアーキテクチャの重みの過剰適合を回避するパイプライン化されたDARTS。パフォーマンスとシステムの複雑さの間のトレードオフを調整するためにリソースの制約をさらに組み込んだペナルティドDARTS。 
[要約]さまざまなニューラルアーキテクチャ検索（nas）メソッドを使用して、2つのハイパー（状態のパフォーマンスとモデルの複雑さに大きく影響するパラメーター）を学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-17">
        <br><font color="black">2020-07-17</font>
      </time>
    </span>
</section>
<!-- paper0: Target-Speaker Voice Activity Detection: a Novel Approach for
  Multi-Speaker Diarization in a Dinner Party Scenario -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.SD/paper_1.html">
      <font color="black">Target-Speaker Voice Activity Detection: a Novel Approach for
  Multi-Speaker Diarization in a Dinner Party Scenario</font>
    </a>
  </h2>
  <font color="black">また、シングルチャネルTS-VADモデルから抽出された非表示表現の上に単純な注意メカニズムを使用して、TS-VADアプローチをマルチマイクケースに拡張します。強力なクラスタリングから始めて、I-ベクトルを反復的に推定できます。ベースのダイアライゼーション..バイナリ分類出力層のセットは、各スピーカーのアクティビティを生成します。 
[ABSTRACT]広く使用されているケースベースのダイアライゼーションは、自律発話の欠如に基づいています。これは、重複発話を処理する能力が限られているためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-14">
        <br><font color="black">2020-05-14</font>
      </time>
    </span>
</section>
<!-- paper0: Analysis of Emotional Content in Indian Political Speeches -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.SD/paper_2.html">
      <font color="black">Analysis of Emotional Content in Indian Political Speeches</font>
    </a>
  </h2>
  <font color="black">注意ベースのCNN + LSTMネットワークを使用して、政治家のスピーチに存在する感情的な内容を調査します。このように、インドの政治シナリオにおける政治家のスピーチの感情的な内容の分析を提示します。スピーチの感情的な内容にはパワーがあります心に影響を与える。 
[ABSTRACT]注意ベースのCNN LSTMネットワークを使用して、政治家のスピーチに存在する感情的なコンテンツを調査します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Foreground-Background Ambient Sound Scene Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.SD/paper_3.html">
      <font color="black">Foreground-Background Ambient Sound Scene Separation</font>
    </a>
  </h2>
  <font color="black">私たちの実験的調査結果は、提案されたアプローチの一般化能力を示しています。適切な機能の正規化スキームと、バックグラウンド統計をキャプチャするオプションの補助ネットワークを備えたディープラーニングベースの分離フレームワークを提案し、さまざまな種類を処理する能力を調査します周囲のサウンドシーンで遭遇するサウンドクラスの例。トレーニングではほとんど見られません。通常、アンビエントサウンドシーンは、やや静止した背景の上に発生する複数の短いイベントで構成されます。 
[ABSTRACT] desedおよびaudiosetデータセットデータセットデータセットから分離されたサウンドを使用して、シングル-チャネルフォアグラウンド-バックグラウンドミックスを作成します。これらは、さまざまな異なるサウンドクラスの例です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br><font color="black">2020-05-11</font>
      </time>
    </span>
</section>
<!-- paper0: Hide and Speak: Towards Deep Neural Networks for Speech Steganography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.SD/paper_4.html">
      <font color="black">Hide and Speak: Towards Deep Neural Networks for Speech Steganography</font>
    </a>
  </h2>
  <font color="black">最後に、さまざまなチャネル歪みの下でモデルを評価しました。さらに、提案されたアプローチは、複数のデコーダーまたは単一の条件付きデコーダーを使用して単一のキャリアで複数のメッセージを隠すために適用できることを示しました。ビジョンのために提案されたステガノグラフィーモデルが音声にはあまり適さず、ネットワーク内の微分可能な層として短時間フーリエ変換と逆短時間フーリエ変換を含む新しいモデルを提案し、ネットワーク出力に重要な制約を課します。 
[要約]提案されたアプローチは、複数のデコーダーまたは単一の条件付きデコーダーを使用して単一のキャリアで複数のメッセージを隠すために適用できます。実験は、キャリアへの変更は人間のリスナーには気付かれず、デコードされたメッセージは非常にわかりやすいことを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-02-07">
        <br><font color="black">2019-02-07</font>
      </time>
    </span>
</section>
<!-- paper0: Joint NN-Supported Multichannel Reduction of Acoustic Echo,
  Reverberation and Noise -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.SD/paper_5.html">
      <font color="black">Joint NN-Supported Multichannel Reduction of Acoustic Echo,
  Reverberation and Noise</font>
    </a>
  </h2>
  <font color="black">提案されたアプローチは、個々のアプローチのカスケード、およびターゲット信号と残差信号のスペクトルモデルに依存しないジョイント削減アプローチの全体的な歪みに関して優れています。音響エコー、残響、ノイズの実際の録音でシステムを評価しますさまざまな状況でスマートスピーカーを使用して取得します。すべてのフィルターを更新するために、反復ブロック座標上昇アルゴリズムを開発します。 
[ABSTRACT]線形エコーキャンセレーションと残響除去後のターゲット信号と残差信号をモデル化することを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br><font color="black">2019-11-20</font>
      </time>
    </span>
</section>
<!-- paper0: Self Attentive Multi Layer Aggregation with Feature Recalibration and
  Normalization for End to End Speaker Verification System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.SD/paper_6.html">
      <font color="black">Self Attentive Multi Layer Aggregation with Feature Recalibration and
  Normalization for End to End Speaker Verification System</font>
    </a>
  </h2>
  <font color="black">モデルパラメーターの数を減らすために、チャネル幅とレイヤー深度をスケーリングしたResNetがベースラインとして使用されます。次に、完全に接続されたレイヤーと非線形アクティブ化関数を使用して、集合体フィーチャーにフィーチャー再キャリブレーションレイヤーが適用されます。トレーニングの変動性を制御するために、自己注意メカニズムが適用され、ドロップアウトの正規化とバッチの正規化を使用して多層集約を実行します。 
[ABSTRACT]ショートカット接続により、スピーカーの埋め込みの表現力が向上します。そのため、エンドツーエンドのエンドツーエンドのスピーカー検証システム用の自己注意深い多層集合体を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: On the Use of Audio Fingerprinting Features for Speech Enhancement with
  Generative Adversarial Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.SD/paper_7.html">
      <font color="black">On the Use of Audio Fingerprinting Features for Speech Enhancement with
  Generative Adversarial Network</font>
    </a>
  </h2>
  <font color="black">MFCCはコンパクトな表現を提供しますが、各メルスケールサブバンドのエネルギーのダイナミクスと分布を無視します。この作業では、ジェネレーティブアドバーサリネットワーク（GAN）に基づく音声強調システムが実装され、オーディオの組み合わせでテストされますMFCCおよび正規化スペクトルサブバンドセントロイド（NSSC）から取得したFingerPrinting（AFP）機能。NSSCは音声フォルマントの位置をキャプチャし、重要な方法でMFCCを補完します。 
[ABSTRACT]時間-周波数領域の機能は、多くのアプローチで推奨されます。これらには、短期テオドール変換（stft）とメル周波数ケプストラルブレッシング（mfcc）が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: MCSAE: Masked Cross Self-Attentive Encoding for Speaker Embedding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.SD/paper_8.html">
      <font color="black">MCSAE: Masked Cross Self-Attentive Encoding for Speaker Embedding</font>
    </a>
  </h2>
  <font color="black">MCSAEでは、クロスセルフアテンションモジュールは、各入力フィーチャの相互依存性をトレーニングします。これは、高レベルレイヤーと低レベルレイヤーの両方のフィーチャーに焦点を当てています。マルチレイヤー集約に基づいて、各残差レイヤーの出力フィーチャが使用されますMCSAEの場合。 
[ABSTRACT]これはマルチレイヤの集約に基づいています。各残余レイヤの出力機能はmcsaeに使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-28">
        <br><font color="black">2020-01-28</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Robust Vision Using Retro Reflective Markers for Remote Handling in ITER -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.IV/paper_0.html">
      <font color="black">Robust Vision Using Retro Reflective Markers for Remote Handling in ITER</font>
    </a>
  </h2>
  <font color="black">レトロリフレクティブマーカーベースのトラッキングは、ITERでのリモート処理操作の主要なイネーブラーになる可能性があると結論付けます。 ..この作業では、表面に取り付けられたマーカーを使用して、平面ターゲット、つまりカセットロックシステムのナックルの姿勢を推定する、3Dノードの再帰反射マーカーベースのバージョンを開発します。 
[ABSTRACT] 3Dノードは、アイインハンドカメラシステムを使用した微調整タスク中にリモート環境から重要な情報を抽出し、仮想現実ベースのリモート処理プラットフォームの背後にあるモデルを更新するハードウェア/ソフトウェアモジュールです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-24">
        <br><font color="black">2020-07-24</font>
      </time>
    </span>
</section>
<!-- paper0: Solving Linear Inverse Problems Using the Prior Implicit in a Denoiser -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.IV/paper_1.html">
      <font color="black">Solving Linear Inverse Problems Using the Prior Implicit in a Denoiser</font>
    </a>
  </h2>
  <font color="black">同じアルゴリズムを使用して、ブレ除去、超解像、修復、圧縮センシングのための高品質のソリューションを生成し、複数のアプリケーションでこの転移学習の一般的な形式を示します。この事実を使用して、確率的な粗密の勾配を開発します。ブラインド（つまり、未知のノイズレベル）最小二乗ノイズ除去を実行するようにトレーニングされたCNN内に埋め込まれた暗黙の事前分布から高確率サンプルを描画するための上昇手順。制約付きサンプリングへのこのアルゴリズムの一般化は、追加のトレーニングなしで、線形逆問題を解決します。 
[要約]ディープニューラルネットワークは、ノイズ除去などの問題に対する最先端のソリューションを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: MMDF: Mobile Microscopy Deep Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.IV/paper_2.html">
      <font color="black">MMDF: Mobile Microscopy Deep Framework</font>
    </a>
  </h2>
  <font color="black">選択したアプローチを実装し、そのパフォーマンスを従来のコンピュータービジョン技術と比較しました。現在の研究では、ディープラーニングの画像処理技術を適用しました（焦点が合っている/焦点が合っていない分類、画像のぼかしとノイズ除去、マルチフォーカス画像）融合）モバイル顕微鏡から得られたデータに..すべてのタスクの重要な作業の概要が提示され、最も適切なアプローチが強調表示されました。 
[ABSTRACT]モバイル顕微鏡データはモバイル顕微鏡から取得されました。結果はコンピュータービジョン技術と比較されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Image-driven discriminative and generative machine learning algorithms
  for establishing microstructure-processing relationships -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.IV/paper_3.html">
      <font color="black">Image-driven discriminative and generative machine learning algorithms
  for establishing microstructure-processing relationships</font>
    </a>
  </h2>
  <font color="black">私たちが新たに開発した微細構造表現は画像データを適切に説明しており、異なるフェーズの面積率を利用する従来のアプローチは、272の画像の比較的小さな不均衡な元のデータセットを使用して複数のクラスを区別するには不十分です。私たちの仕事は、定量的微細構造分析、および冶金プロセス設計研究に典型的な限られたデータセットでの微細構造処理関係の開発。このような限られたデータセットを補足する生成法の適用性を調査するために、生成的敵対的ネットワークは、人工的な微細構造画像を生成するように訓練されました。 
[要約]二元合金は現在核燃料として開発中です。画像認識、md、および微細構造を処理条件にリンクする予測機能を構築するための改善された機械学習アプローチの開発を目的として研究されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Test-Time Adaptable Neural Networks for Robust Medical Image
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.IV/paper_4.html">
      <font color="black">Test-Time Adaptable Neural Networks for Robust Medical Image
  Segmentation</font>
    </a>
  </h2>
  <font color="black">私たちのコードは次の場所にあります：\ url {https://github.com/neerakara/test-time-adaptable-neural-networks-for-domain-generalization ..深いCNNのアーキテクチャにとらわれず、2番目のサブネットワークでは、提案された設計を任意のセグメンテーションネットワークで利用して、イメージングスキャナーとプロトコルのバリエーションに対する堅牢性を高めることができます。特定のスキャナーとプロトコル設定からの注釈付き画像で構成されるトレーニングデータセットを使用して、これらの両方のサブネットワークをトレーニングします。 
[要約]提案された設計は、スキャナーモデルやプロトコルなどの取得の詳細に関するトレーニング画像とテスト画像の不一致に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning Methods for Solving Linear Inverse Problems: Research
  Directions and Paradigms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.IV/paper_5.html">
      <font color="black">Deep Learning Methods for Solving Linear Inverse Problems: Research
  Directions and Paradigms</font>
    </a>
  </h2>
  <font color="black">今日、ディープラーニングの急速な発展により、線形逆問題を解くための新鮮な視点が提供され、さまざまな適切に設計されたネットワークアーキテクチャにより、多くのアプリケーションで最先端のパフォーマンスが得られます。解決するために無数の試みが行われてきました。さまざまなアプリケーションでの線形逆問題のさまざまなバリアント..線形逆問題は、さまざまな科学分野の発展の基本です。 
[要約]さまざまな線形逆問題を解決するために複数の試みが行われました。このホワイトペーパーでは、ディープラーニングの開発の進捗状況を包括的に調査します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Split Computing for Complex Object Detectors: Challenges and Preliminary
  Results -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.IV/paper_6.html">
      <font color="black">Split Computing for Complex Object Detectors: Challenges and Preliminary
  Results</font>
    </a>
  </h2>
  <font color="black">レイヤーごとのテンソルサイズとモデルサイズの観点からオブジェクト検出器を広範囲に分析し、単純な分割計算方法では推論時間が短縮されないことを示しています。知る限り、これはそのような小さなボトルネックを注入する最初の研究ですオブジェクト検出器を使用して、分割コンピューティングアプローチの可能性を明らかにします。ただし、提案されているすべての分割コンピューティングアプローチは、画像分類タスクに焦点を当てており、ほとんどは、実際のシナリオから離れた小さなデータセットで評価されます。 
[ABSTRACT]モバイルとエッジコンピューティングは、多くの場合、総受付時間の点で最良のオプションです。ただし、分割コンピューティング方式で短距離を実現できるシナリオがいくつかあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Automated Detection and Forecasting of COVID-19 using Deep Learning
  Techniques: A Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.IV/paper_7.html">
      <font color="black">Automated Detection and Forecasting of COVID-19 using Deep Learning
  Techniques: A Review</font>
    </a>
  </h2>
  <font color="black">これらの医療画像からCOVID-19を特定することは、時間がかかり、要求が厳しく、人為的エラーが発生しやすいため、非常に困難です。したがって、人工知能（AI）手法を使用して、一貫した高性能を得ることができます。 COVID-19診断のためのDL技術の適用と肺の自動セグメンテーションに関する研究の完全な調査が議論され、X線とCT画像を使用した研究に集中しています。 
[ABSTRACT] covid-19は、中型サイズのコーティングされたウイルスで、一本鎖のRNAを持っています。X線とct）の画像モダリティは、迅速かつ正確な医療診断を得るために広く使用されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Differentiable model-based adaptive optics with transmitted and
  reflected light -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.IV/paper_8.html">
      <font color="black">Differentiable model-based adaptive optics with transmitted and
  reflected light</font>
    </a>
  </h2>
  <font color="black">学習には、可能性のある広範囲の収差をカバーするデータセットが必要ですが、これはより強く散乱するサンプルでは制限となり、イメージングプロセスに関する以前の情報を利用しません。機械学習は、逆を学習することにより、このような条件下でイメージングを改善する新しい方法を提供します。収差のモデル..収差は、多くの状況で光学系を制限します。たとえば、生体組織でイメージングする場合などです。 
[ABSTRACT]機械学習は、収差の逆モデルを学習することにより、このような条件下でのイメージングを改善する新しい方法を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Point-to-set distance functions for weakly supervised segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.IV/paper_9.html">
      <font color="black">Point-to-set distance functions for weakly supervised segmentation</font>
    </a>
  </h2>
  <font color="black">オブジェクトサイズ情報は、多くの一般画像および医用画像を含むデータセットからの境界ボックスからのオブジェクトセグメンテーションを可能にすることが知られていますが、アプリケーションが単一の例の場合でも、データが間接測定を表すイメージングサイエンスにまで及ぶことを示します。投影ベースのポイントからセットへの距離関数を介して実装されたネットワーク出力の制約を介してそのような情報を含める新しいアルゴリズム。ピクセルレベルのマスクまたは部分的注釈がセマンティックセグメンテーションのニューラルネットワークのトレーニングに使用できない場合、境界ボックスまたはイメージタグの形式で上位レベルの情報を使用します。 
[ABSTRACT]マスクなしでトレーニングする直接的な方法は、地面のオブジェクトまたはクラスのサイズに関する事前知識を使用することです。新しいタイプの距離アルゴリズムは、常に同じ関数形の導関数を持ち、神経機能を回避します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: EfficientDet: Scalable and Efficient Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.IV/paper_10.html">
      <font color="black">EfficientDet: Scalable and Efficient Object Detection</font>
    </a>
  </h2>
  <font color="black">まず、簡単で高速なマルチスケール機能融合を可能にする重み付き双方向機能ピラミッドネットワーク（BiFPN）を提案します。次に、すべてのバックボーン、フィーチャネットワーク、ボックス/クラス予測ネットワークの解像度、深度、幅を同時に均一にスケーリングする複合スケーリング方法を提案します。特に、単一モデルと単一スケールの場合、EfficientDet -D7は、77Mパラメーターと410B FLOPを備えたCOCO test-devで最先端の55.1 APを実現し、以前の検出器よりも4倍から9倍小さく、13倍から42倍少ないFLOPを使用します。コードはhttps：// githubで入手できます。 .com / google / automl / tree / master / efficientdet。 
[ABSTRACT] efficientdetと呼ばれる新しい範囲のオブジェクト検出器は、幅広いリソース制約にわたって、従来技術よりもずっと優れた効率を一貫して達成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br><font color="black">2019-11-20</font>
      </time>
    </span>
</section>
<!-- paper0: XCAT-GAN for Synthesizing 3D Consistent Labeled Cardiac MR Images on
  Anatomically Variable XCAT Phantoms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.IV/paper_11.html">
      <font color="black">XCAT-GAN for Synthesizing 3D Consistent Labeled Cardiac MR Images on
  Anatomically Variable XCAT Phantoms</font>
    </a>
  </h2>
  <font color="black">4クラスの手法は、心臓の注釈のみに依存しています。一方、8クラステクニックは、心臓周囲の臓器の予測された複数組織ラベルマップを採用し、条件付き画像合成により優れたガイダンスを提供します。したがって、訓練されたネットワークは、組織固有のテクスチャを新しいラベルマップに正確に転送します。結果は、トレーニング中に実際の画像のわずか20％（40ボリューム）が見られる場合でも、合成CMR画像を追加することでセグメンテーションパフォーマンスが維持されることを示しています。 
[ABSTRACT]この手法は、意味的に一貫したマスクに基づく画像生成に依存しています。4クラスと8クラスのxcat-gansは、この手法に基づいています。両方の手法で、条件付きxcat-ganを、対応するlabels。実際のデータを拡張するための合成画像の利用の改善は、最大28％のハウズドルフ距離の短縮と最大5％のサイコロスコアの増加により明らかです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient resource management in UAVs for Visual Assistance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.IV/paper_12.html">
      <font color="black">Efficient resource management in UAVs for Visual Assistance</font>
    </a>
  </h2>
  <font color="black">このプロジェクトでは、飛行時間に影響を与えたり、これらのモデルのレイテンシや精度を変更したりすることなく、リアルタイムシナリオでUAVハードウェアのオブジェクト追跡やオブジェクト検出などの一般的な画像処理タスクを最適化する新しい方法について説明します。世界中の農業、軍事、災害管理、航空写真のための無人航空機（UAV）の使用。視覚支援タスクにUAVをリアルタイムで使用する上での主要な課題の1つは、これらのタスクのメモリ使用量と電力消費を管理することです。 UAVのローエンドプロセッサボードで実行するのは計算集約的で困難です。 
[ABSTRACT] UAVを視覚的支援にリアルタイムで使用することは無人です。これらは、UAVオブジェクトのローエンドプロセッサボードで実行することは困難です。これは、コンピュータビジョンのディープラーニングモデルにもかかわらず</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-11">
        <br><font color="black">2020-07-11</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Learning Pose-invariant 3D Object Reconstruction from Single-view Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_0.html">
      <font color="black">Learning Pose-invariant 3D Object Reconstruction from Single-view Images</font>
    </a>
  </h2>
  <font color="black">結果として、再構成された形状は入力ポーズに応じて変化し、精度が低くなります。2D画像を使用して3D形状を再構成することを学ぶことは、高価な3Dデータを必要としないという利点を持つ活発な研究トピックです。視点、およびポーズの解きほぐされたコンパクトな形状空間を学習するための効果的な敵対ドメイン混同法を提案します。 
[要約]主な困難は、単一ビューの画像によって提供できる制約が不十分であることです。これにより、学習された形状空間での姿勢のもつれの問題が発生します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-03">
        <br><font color="black">2020-04-03</font>
      </time>
    </span>
</section>
<!-- paper0: Contraction Mapping of Feature Norms for Classifier Learning on the Data
  with Different Quality -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_1.html">
      <font color="black">Contraction Mapping of Feature Norms for Classifier Learning on the Data
  with Different Quality</font>
    </a>
  </h2>
  <font color="black">この発見に基づいて、品質に応じてトレーニング画像の特徴ノルムの範囲を圧縮する収縮マッピング関数を提案し、この縮小マッピング関数をソフトマックス損失またはその拡張に組み込んで、新しい学習目標を生成します。このような問題を無視して、低品質のデータの正しい分類を解決することは困難です。人気のあるソフトマックス損失とその最近の拡張により、深層学習ベースの画像分類で大きな成功を収めています。 
[要約]ニューヨーク大学の研究者によって研究が行われました。彼らは、さまざまなアプリケーションとさまざまなディープニューラルネットワークに関する注意深い実験を通じて、画像の特徴ノルムとその品質の間に正の相関があることを発見しました。提案されたアプローチは、質の異なるデータを学習する問題に効果的に対処する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: PP-YOLO: An Effective and Efficient Implementation of Object Detector -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_2.html">
      <font color="black">PP-YOLO: An Effective and Efficient Implementation of Object Detector</font>
    </a>
  </h2>
  <font color="black">主に、モデルパラメーターとFLOPの数をほとんど増加させないさまざまな既存のトリックを組み合わせて、速度がほとんど変わらないようにしながら、検出器の精度を可能な限り向上させるという目標を達成しようとします。YOLOv3は広く実際に使用して、YOLOv3に基づく新しいオブジェクト検出器を開発します。このホワイトペーパーの目的は、新しい検出モデルを提案するのではなく、実際のアプリケーションシナリオに直接適用できる比較的バランスの取れた有効性と効率のオブジェクト検出器を実装することです。 
[要約]このペーパーの目標は、新しいアプリケーションシナリオに直接適用できる、比較的バランスの取れた有効性と効率を備えたオブジェクト検出器を実装することです。pp-yoloは、有効性（45. 2％マップ）と効率（ 72.9 fps）、efficientdetやyolov4などの既存の最先端検出器を超える</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-23">
        <br><font color="black">2020-07-23</font>
      </time>
    </span>
</section>
<!-- paper0: Feature visualization of Raman spectrum analysis with deep convolutional
  neural network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_3.html">
      <font color="black">Feature visualization of Raman spectrum analysis with deep convolutional
  neural network</font>
    </a>
  </h2>
  <font color="black">ゼロに近い重み値が、ベースライン補正に使用されているように見えるバックグラウンドレベル領域で取得されます。共通成分抽出は、数値混合アミノ酸スペクトルの評価によって確認されます。この提案された方法は、次のようなアプリケーションに潜在的に適しています。トレーニングされたモデルの検証、スペクトル分析のための化合物サンプルからの共通コンポーネント抽出の信頼性を確保します。 
[ABSTRACT]抽出された領域に対する畳み込みフィルターのサイズと数の影響を調査します。ラマン-ローレンツスペクトルを使用してピーク信号が抽出されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Backdoor Attacks and Countermeasures on Deep Learning: A Comprehensive
  Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_4.html">
      <font color="black">Backdoor Attacks and Countermeasures on Deep Learning: A Comprehensive
  Review</font>
    </a>
  </h2>
  <font color="black">対策は4つの一般的なクラスに分類されます。ブラインドバックドアの削除、オフラインバックドアの検査、オンラインバックドアの検査、ポストバックドアの削除です。したがって、対策をレビューし、それらの長所と短所を比較して分析します。場合によっては、攻撃者は適応型攻撃で既存の防御をインテリジェントにバイパスします。 
[要旨]対策は広く分類され、6つのカテゴリに形式化されています。ブラインドバックドアの削除、オフラインバックドアの検査、オンラインバックドアの検査、ポストバックドアの削除を含みます。全体的に、防御に関する研究は攻撃の背後にあり、単一の攻撃はありませんあらゆるタイプのバックドア攻撃を防ぐことができる防御</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-21">
        <br><font color="black">2020-07-21</font>
      </time>
    </span>
</section>
<!-- paper0: Two-Level Residual Distillation based Triple Network for Incremental
  Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_5.html">
      <font color="black">Two-Level Residual Distillation based Triple Network for Incremental
  Object Detection</font>
    </a>
  </h2>
  <font color="black">この論文では、Faster R-CNNに基づく新しいインクリメンタルオブジェクト検出器を提案し、古いデータを使用せずに新しいオブジェクトクラスから継続的に学習します。古いクラスと新しいクラスの特徴の識別をよりよく維持するために、残差モデルは、 VOC2007とCOCOに関する広範な実験が行われ、その結果は、提案された方法が新しいクラスのオブジェクトを段階的に検出することを効果的に学習できることを示しており、この状況では壊滅的な忘却の問題が軽減されます。 
[ABSTRACT]モデルは、古いモデルと残余モデルがアシスタントとして機能するトリプルネットワークです。これにより、モデルは以前の学習クラスを忘れずに新しいデータで学習できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: K-Shot Contrastive Learning of Visual Features with Multiple Instance
  Augmentations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_6.html">
      <font color="black">K-Shot Contrastive Learning of Visual Features with Multiple Instance
  Augmentations</font>
    </a>
  </h2>
  <font color="black">これにより、特別なワンショットケースと見なすことができる既存の対比学習が一般化されます。特に、インスタンスごとに、インスタンスサブスペースが構築され、$ K $ショット増大の変動の重要な要素がどのようになり得るかの構成をモデル化します結合されて、拡張のバリアントが形成されます。クエリが与えられた後、クエリをサブスペースに射影してインスタンスの最も関連性の高いバリアントを取得し、正のインスタンスクラスを予測します。 
[ABSTRACT]固有値分解は、カスタマイズを構成するために実行できます。一連の異なるタイプの魅力的な魅力的な例を開発するために使用できます。インスタンス間の識別の利点を組み合わせることを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Top-Related Meta-Learning Method for Few-Shot Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_7.html">
      <font color="black">Top-Related Meta-Learning Method for Few-Shot Detection</font>
    </a>
  </h2>
  <font color="black">ただし、より多くのコストが必要です。少数ショット検出では、多くのメタ学習手法が提案されています。TCLは、真ラベルクラスの分類スコアと最も類似するクラスの分類スコアを利用して、少数ショットの検出パフォーマンスを向上させます。クラス。 
[ABSTRACT]以前のほとんどの方法には、2つの主な問題があります。少数ショットのクラスでは、imが強いことと分類が悪いことです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-14">
        <br><font color="black">2020-07-14</font>
      </time>
    </span>
</section>
<!-- paper0: Decomposed Generation Networks with Structure Prediction for Recipe
  Generation from Food Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_8.html">
      <font color="black">Decomposed Generation Networks with Structure Prediction for Recipe
  Generation from Food Images</font>
    </a>
  </h2>
  <font color="black">挑戦的な大規模なRecipe1Mデータセットでの広範な実験により、提案されたモデルDGNの有効性が検証され、最先端の結果よりもパフォーマンスが向上します。通常、キャプションに1つの文がある画像キャプションタスクとは異なり、調理手順は複数の文を含み、明確な構造を持っています。具体的には、各調理手順をいくつかのフェーズに分割し、各フェーズに異なるサブジェネレータを割り当てます。 
[ABSTRACT]構造は画像のキャプション作成タスクとは異なります。これらには調理の説明が含まれ、明らかな構造があります。提案されたモデルdgnは、最新の結果よりもパフォーマンスを向上させます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Research Progress of Convolutional Neural Network and its Application in
  Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_9.html">
      <font color="black">Research Progress of Convolutional Neural Network and its Application in
  Object Detection</font>
    </a>
  </h2>
  <font color="black">コンピューターのパフォーマンスの向上とデータ量の増加に伴い、畳み込みニューラルネットワーク（CNN）に基づくオブジェクト検出は、オブジェクト検出の主要なアルゴリズムになりました。この論文では、畳み込みニューラルネットワークの研究の進展とオブジェクト検出におけるそれらのアプリケーションを要約します。 、オブジェクト検出に畳み込みニューラルネットワークを適用する特定のアイデアと方法の分析と議論に焦点を当て、現在の欠陥と将来の開発方向を指摘します。 
[要約]この論文は、畳み込みニューラルネットワークの研究の進歩とオブジェクト検出におけるその応用に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Prediction for Joint Instance and Semantic Segmentation of Point
  Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_10.html">
      <font color="black">Self-Prediction for Joint Instance and Semantic Segmentation of Point
  Clouds</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、PointNet ++のみをバックボーンネットワークとして使用する場合に、S3DISの最新のインスタンスセグメンテーション結果と、S3DISおよびShapeNetの最新の比較されたセマンティックセグメンテーション結果を実現します。さらに、一般的な関連フレームワーク私たちの自己予測スキームを備えたは、インスタンスとセマンティックセグメンテーションを同時に強化するように設計されています。インスタンスとセマンティックの表現を組み合わせて、自己予測を実行します。 / geometric / shape情報を使用して、セグメンテーションの特徴的な機能を学習します。 
[ABSTRACT]私たちの方法は、より良いセグメンテーションのためにポイント関係の探索を強化するように設計されています。これは、ユーザーが1つのサブセットのラベルを予測できるグラフネットワークに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Privacy Preserving Visual SLAM -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_11.html">
      <font color="black">Privacy Preserving Visual SLAM</font>
    </a>
  </h2>
  <font color="black">これは、カメラポーズを推定し、混合線と点群を使用してバンドル調整をリアルタイムで実行するために解決する重要な問題です。合成データと実際のデータを使用した実験結果は、当社のVisual SLAMフレームワークが、意図したプライバシーを保護するフォーメーションと実際のラインクラウドマップを使用した時間パフォーマンス。この研究では、カメラのポーズを推定し、リアルタイムでラインクラウドとポイントクラウドが混在するバンドル調整を実行するためのプライバシー保護型ビジュアルSLAMフレームワークを提案します。 
[要約]以前の研究では、単一の画像または再構成ポイントクラウドのラインクラウドマップを使用してカメラポーズを推定するローカリゼーション手法を提案していますが、認知効率に対応していないため、ビデオシーケンスに直接関連していません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-20">
        <br><font color="black">2020-07-20</font>
      </time>
    </span>
</section>
<!-- paper0: Image-driven discriminative and generative machine learning algorithms
  for establishing microstructure-processing relationships -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_12.html">
      <font color="black">Image-driven discriminative and generative machine learning algorithms
  for establishing microstructure-processing relationships</font>
    </a>
  </h2>
  <font color="black">私たちが新たに開発した微細構造表現は画像データを適切に説明しており、異なるフェーズの面積率を利用する従来のアプローチは、272の画像の比較的小さな不均衡な元のデータセットを使用して複数のクラスを区別するには不十分です。私たちの仕事は、定量的微細構造分析、および冶金プロセス設計研究に典型的な限られたデータセットでの微細構造処理関係の開発。このような限られたデータセットを補足する生成法の適用性を調査するために、生成的敵対的ネットワークは、人工的な微細構造画像を生成するように訓練されました。 
[要約]二元合金は現在核燃料として開発中です。画像認識、md、および微細構造を処理条件にリンクする予測機能を構築するための改善された機械学習アプローチの開発を目的として研究されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Test-Time Adaptable Neural Networks for Robust Medical Image
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_13.html">
      <font color="black">Test-Time Adaptable Neural Networks for Robust Medical Image
  Segmentation</font>
    </a>
  </h2>
  <font color="black">コードは、\ url {https://github.com/neerakara/test-time-adaptable-neural-networks-for-domain-generalization。で入手できます。これらのサブネットワークは、次のトレーニングデータセットを使用してトレーニングします。特定のスキャナーとプロトコル設定からの注釈付きの画像。このような暗黙の事前を妥当な解剖学的セグメンテーションラベルでモデル化するために、独立して訓練されたノイズ除去オートエンコーダ（DAE）を採用しています。 
[要約]提案された設計は、スキャナーモデルやプロトコルなどの取得の詳細に関するトレーニング画像とテスト画像の不一致に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: Few-shot Knowledge Transfer for Fine-grained Cartoon Face Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_14.html">
      <font color="black">Few-shot Knowledge Transfer for Fine-grained Cartoon Face Generation</font>
    </a>
  </h2>
  <font color="black">次に、他のグループの新しいサンプルが与えられたら、新しいグループごとにグループ固有のブランチを作成して基本モデルを拡張します。これらのグループの漫画の顔は同様のスタイルを共有しますが、さまざまなグループの外観には特定の特性がまだあり、最初に、（十分なデータで構成される）基本グループの基本翻訳モデルがトレーニングされます。 
[ABSTRACT]このタスクは、グループ間で知識を伝達し、グループを学ぶ方法です-いくつかのサンプルのみで特定の特性</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Distillation Guided Residual Learning for Binary Convolutional Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_15.html">
      <font color="black">Distillation Guided Residual Learning for Binary Convolutional Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">また、ブロックごとの蒸留損失の最適化を容易にするためにバイナリ畳み込みブロックアーキテクチャを更新する動機にもなります。具体的には、軽量ショートカットブランチが各バイナリ畳み込みブロックに挿入され、各ブロックの残差を補完します。そのスクイーズと-相互作用（SI）構造。このショートカットブランチは、パラメーターの一部（たとえば、10 \％のオーバーヘッド）を導入しますが、残差を効果的に補完します。 
[ABSTRACT]ショートカット分岐が各ポイントに挿入され、各ブロックの残差を補完します。利点は、bcnnとfcnnのプレート間の実質的な補完に削減されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-10">
        <br><font color="black">2020-07-10</font>
      </time>
    </span>
</section>
<!-- paper0: NOH-NMS: Improving Pedestrian Detection by Nearby Objects Hallucination -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_16.html">
      <font color="black">NOH-NMS: Improving Pedestrian Detection by Nearby Objects Hallucination</font>
    </a>
  </h2>
  <font color="black">Greedy-NMSと比較して、私たちの方法は、最先端技術として、$ 3.9 \％$ AP、$ 5.1 \％$ Recall、および$ 0.8 \％$ $ \ text {MR} ^ {-2} $改善されていますCrowdHumanで$ 89.0 \％$ APと$ 92.9 \％$ Recall、およびそれぞれ$ 43.9 \％$ $ \ text {MR} ^ {-2} $です。ただし、NMSでの以前の研究では、この要素は考慮されていません。貪欲なNMSは本質的にジレンマを引き起こします。NMSのしきい値が低いと再現率が低くなり、しきい値が高いと偽陽性が多くなる可能性があります。 
[要約]歩行者の検出では、証拠が不足しているため、問題はより深刻です。これは、人々が思い出す可能性が高いという多くの証拠があるためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: ALF: Autoencoder-based Low-rank Filter-sharing for Efficient
  Convolutional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_17.html">
      <font color="black">ALF: Autoencoder-based Low-rank Filter-sharing for Efficient
  Convolutional Neural Networks</font>
    </a>
  </h2>
  <font color="black">最先端のたたみ込みニューラルネットワークのハードウェア要件と組み込みアプリケーションを制約する限られたリソースのギャップを埋めることは、ディープラーニング研究における次の大きな課題です。私たちの実験では、ALFはネットワークの70 \％の削減を示しましたパラメータ、操作で61 \％、実行時間で41 \％、精度の損失を最小限に抑えます。このホワイトペーパーでは、オートエンコーダベースの低ランクフィルター共有技術（ALF）を提案します。 
[ABSTRACT]量子ネットワークは通常、リソースに制約のある環境での展開が困難です。ほとんどの既存の技術には、ドメインの専門知識が必要であるか、不規則なスパース表現になります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Reconstructing NBA Players -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_18.html">
      <font color="black">Reconstructing NBA Players</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチの鍵は、NBAプレーヤーの可動でスキンのあるモデルを作成するための新しい方法、およびメッシュ（NBA2K19ビデオゲームから派生）の大規模なデータベースを作成することです。これは、研究コミュニティにリリースするものです。バスケットボールゲームのドメインは特にこれらの課題のすべてを示しているため、挑戦的です。私たちは、体の形状を再構築するための最先端の単一画像手法に対する大幅な改善を実証しています。 
[ABSTRACT]ボディモデルは、困難なボディポーズ、衣服のモデリング、セルフオクルージョンにより、依然としてエラーに悩まされています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: ShadingNet: Image Intrinsics by Fine-Grained Shading Decomposition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_19.html">
      <font color="black">ShadingNet: Image Intrinsics by Fine-Grained Shading Decomposition</font>
    </a>
  </h2>
  <font color="black">したがって、本稿では、シェーディングコンポーネントを直接（照明）および間接シェーディング（周囲の光と影）サブコンポーネントに分解することを提案します。細かい動作を行うエンドツーエンドの深い畳み込みニューラルネットワーク（ShadingNet）を提案します。細かいシェーディングモデルを利用した特殊な融合とリファインメントユニットを使用した粗密な方法。屋外の自然環境のシーンレベルの合成画像の大規模なデータセットには、細かい固有の画像グラウンドトゥルースが提供されます。 
[ABSTRACT]シェーディングプロセスは一般にスムーズですが、これらの方法は失敗する可能性があります。目的は、強い測光効果と反射率の変化を区別することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-09">
        <br><font color="black">2019-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Part-Aware Data Augmentation for 3D Object Detection in Point Cloud -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_20.html">
      <font color="black">Part-Aware Data Augmentation for 3D Object Detection in Point Cloud</font>
    </a>
  </h2>
  <font color="black">PA-AUGはオブジェクトをパーティションに分割し、5つの新しい拡張方法を各局所領域に確率的に適用します。3Dラベルは2Dラベルよりも洗練された豊富な構造情報を持っているため、より多様で効果的なデータ拡張が可能です。データ拡張は大きく貢献しています画像認識タスクのパフォーマンスを向上させるために、そして多くの関連する研究が行われてきました。 
[ABSTRACT] pa-augは、3dラベルの豊富な情報をより適切に利用して、3dオブジェクト検出器のパフォーマンスを向上させることができます。これは、既存の点群データの拡張方法と互換性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Split Computing for Complex Object Detectors: Challenges and Preliminary
  Results -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_21.html">
      <font color="black">Split Computing for Complex Object Detectors: Challenges and Preliminary
  Results</font>
    </a>
  </h2>
  <font color="black">レイヤーごとのテンソルサイズとモデルサイズの観点からオブジェクト検出器を広範囲に分析し、単純なスプリットコンピューティング手法は推論時間を短縮しないことを示しています。実際のシナリオからはほど遠い小さなデータセットで評価されます。この研究で使用されているソースコードとトレーニング済みモデルの重みは、https：//github.com/yoshitomo-matsubara/hnd-ghnd-object-detectorsで入手できます。 
[ABSTRACT]モバイルとエッジコンピューティングは、多くの場合、総受付時間の点で最良のオプションです。ただし、分割コンピューティング方式で短距離を実現できるシナリオがいくつかあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Human-Object Interactions with Action Co-occurrence Priors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_22.html">
      <font color="black">Detecting Human-Object Interactions with Action Co-occurrence Priors</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチの有用性は実験的に実証されており、私たちのアプローチのパフォーマンスは、2つの主要なHOI検出ベンチマークデータセット、HICO-DetおよびV-COCOの両方で最先端の方法を超えています。人間における一般的な問題-オブジェクト相互作用（HOI）検出タスクは、多数のHOIクラスにラベルが付けられた例の数が少ないため、結果がロングテール分布のトレーニングセットになることです。この問題に対処するために、自然な相関と反相関が存在することがわかります人間とオブジェクトの相互作用の中で。 
[要約]このホワイトペーパーでは、相関をアクション共起マーカーとしてモデル化します。これらは、事前学習を学習し、それらを活用してより効果的なトレーニングを行うために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-17">
        <br><font color="black">2020-07-17</font>
      </time>
    </span>
</section>
<!-- paper0: Rethinking Generative Zero-Shot Learning: An Ensemble Learning
  Perspective for Recognising Visual Patches -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_23.html">
      <font color="black">Rethinking Generative Zero-Shot Learning: An Ensemble Learning
  Perspective for Recognising Visual Patches</font>
    </a>
  </h2>
  <font color="black">しかし、現実の世界では、特徴の識別力を定量化し、直接活用して、精度を向上させ、計算の複雑さを軽減できます。プロセスは、複数の専門家生成を使用して、事前定義されたローカルパッチのセットのノイズの多いテキスト記述から識別的な視覚特徴を生成することから始まります。モデル..投票戦略は、分類子から出力される確率分布を平均化します。一部のパッチは他よりも識別力があるため、識別ベースの注意メカニズムは、各パッチに応じて重み付けするのに役立ちます。 
[要約]マルチパッチ「mpgan」は、ローカルパッチ機能を統合し、未確認のクラスに新しい投票戦略でラベルを付ける新しい概念です。未確認クラスの各パッチから合成された機能は、さまざまな教師付き分類子の集合を構築するために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Appearance-Preserving 3D Convolution for Video-based Person
  Re-identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_24.html">
      <font color="black">Appearance-Preserving 3D Convolution for Video-based Person
  Re-identification</font>
    </a>
  </h2>
  <font color="black">元の3Dたたみ込みカーネルをAP3Dに置き換えるだけで、AP3Dを既存の3D ConvNetと簡単に組み合わせることができます。この場合、3Dたたみ込みは人物のビデオクリップの外観表現を破壊する可能性があるため、ReIDに有害です。広範な実験により、ビデオベースのReIDに対するAP3Dの有効性と、広く使用されている3つのデータセットの結果は、最先端技術を上回っています。 
[ABSTRACT]人のビデオクリップの外観表現を使用するap3dは、最先端の技術に有害です。広く使用されている3つのデータセットの結果は、最新の技術を上回っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: YOLOpeds: Efficient Real-Time Single-Shot Pedestrian Detection for Smart
  Camera Applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_25.html">
      <font color="black">YOLOpeds: Efficient Real-Time Single-Shot Pedestrian Detection for Smart
  Camera Applications</font>
    </a>
  </h2>
  <font color="black">特に、この作業の貢献は次のとおりです。1）マルチスケール機能操作を組み合わせた効率的なバックボーン、2）ローカリゼーションを改善するためのより精巧な損失関数、3）検出のためのアンカーレスアプローチ、YOLOpedsと呼ばれる提案されたアプローチ320x320画像のPETS2009監視データセットを使用して評価されます。歩行者検出は、これらすべてのアプリケーションで重要な役割を果たし、ディープラーニングを使用して、最新の正確な検出器を構築できます。効率的なニューラルネットワークは、モバイルアプリケーションだけでなく、オンデバイスエクスペリエンスだけでなく、プライバシーとセキュリティの重要な要素にもなるため、ユーザーはデータをサーバーに送信して評価する必要がなく、ニューラルネットワークのメリットを享受できます。 
[要約]ディープラーニングは、正確な状態を構築するために使用できます-最先端の検出器。これらには、歩行者の検出とディープラーニングが含まれます。システムは、プライバシーとセキュリティの主要な実現要素にもなります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Ladybird: Quasi-Monte Carlo Sampling for Deep Implicit Field Based 3D
  Reconstruction with Symmetry -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_26.html">
      <font color="black">Ladybird: Quasi-Monte Carlo Sampling for Deep Implicit Field Based 3D
  Reconstruction with Symmetry</font>
    </a>
  </h2>
  <font color="black">次に、オブジェクトの反射対称性に基づいて、ローカルオクルージョンによるローカルオクルージョンの問題を軽減するフュージョンフュージョン手法を提案します。提案されたシステムLadybirdは、以下から高品質の3Dオブジェクト再構成を作成できます。単一の入力画像..最遠点サンプリングアルゴリズムに基づいて、理論的には一般化のパフォーマンスを向上させ、SGDベースの最適化アルゴリズムの高速収束を実現するサンプリングスキームを提案します。 
[ABSTRACT]我々は理論的により一般化のパフォーマンスを促進するサンプリング方式を提案します。最遠点サンプリングアルゴリズムに基づいて、system.ladybirdは高品質の3Dオブジェクト再構成を作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Dual Distribution Alignment Network for Generalizable Person
  Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_27.html">
      <font color="black">Dual Distribution Alignment Network for Generalizable Person
  Re-Identification</font>
    </a>
  </h2>
  <font color="black">このようなアラインメントは、デュアルレベルの制約、つまりドメインごとの敵対的な特徴の学習とアイデンティティごとの類似性の強化によって行われます。定量的な結果は、提案されたDDANがさまざまなソースドメインの分布をうまく調整でき、すべてのパフォーマンスを大幅に上回る既存のドメイン汎化アプローチ。大規模なドメイン汎化再ID（DG再ID）ベンチマークでDDANを評価します。 
[ABSTRACT] dual distribution alignment network（ddan）は、ドメインミックスに画像を調整するのに役立つソフトウェアの一種です。これらのタイプの画像がdg networkによって識別されたのは初めてです。これらの変更は、既存のdgに基づいています `ドメイン &#39;は、重要なデータセットのバリエーションによって悪用されることが多い</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: NAMF: A Non-local Adaptive Mean Filter for Salt-and-Pepper Noise Removal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_28.html">
      <font color="black">NAMF: A Non-local Adaptive Mean Filter for Salt-and-Pepper Noise Removal</font>
    </a>
  </h2>
  <font color="black">広範な実験結果は、NAMFがSAPノイズのすべてのレベルで画像を復元するための品質の面で優れたパフォーマンスを得ることができることを示しています。このホワイトペーパーでは、ソルトアンドペッパーを削除するための非ローカル適応平均フィルター（NAMF）と呼ばれる新しいアルゴリズム破損した画像からの（SAP）ノイズが表示されます。適応型サイズの効率的なウィンドウ検出器を使用してノイズを検出します。ノイズのあるピクセルは、隣接するピクセルの組み合わせで置き換えられます。最後に、SAPノイズベースの非ローカルノイズの多いピクセルの強度値を再構築するための平均フィルター。 
[ABSTRACT] sapノイズベースの非ローカル平均フィルターは、ノイズのあるピクセルの量を再構築します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-17">
        <br><font color="black">2019-10-17</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Bounding-Box Free Panoptic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_29.html">
      <font color="black">Towards Bounding-Box Free Panoptic Segmentation</font>
    </a>
  </h2>
  <font color="black">CityscapesとMicrosoft COCOデータセットで提案なしの方法をベンチマークし、COCOデータセットで既存の非提案ベースの方法よりも優れている他のMoEベースのアプローチで競争力のあるパフォーマンスを示します。私たちのアプローチは、 Mixture-of-Expert（MoE）アプローチを使用してインスタンスラベルの予測をガイドするための、セマンティックセグメンテーションネットワークと、マスクR-CNNなどのバウンディングボックスの提案に基づく計算コストの高いインスタンスセグメンテーションネットワークの組み合わせ。小さなインスタンスの場合、境界の信頼性が低い場合、BBFNetは、ハフ投票とそれに続く平均シフトによってインスタンスの中心を予測し、小さなオブジェクトを確実に検出します。 
[ABSTRACT]提案のベンチマーク-都市の景観とMicrosoft cocoデータセットでの無料の方法。既存の提案に基づいていない方法よりも優れた他の萌えベースのアプローチで競争力のあるパフォーマンスを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br><font color="black">2020-02-18</font>
      </time>
    </span>
</section>
<!-- paper0: Point-to-set distance functions for weakly supervised segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_30.html">
      <font color="black">Point-to-set distance functions for weakly supervised segmentation</font>
    </a>
  </h2>
  <font color="black">ハイパースペクトルタイムラプスイメージング、破損した画像でのオブジェクトセグメンテーション、空中地質リモートセンシングデータからの地下帯水層マッピングのデータを使用します。セマンティックセグメンテーションのニューラルネットワークのトレーニングにピクセルレベルのマスクまたは部分的なアノテーションが利用できない場合、境界ボックスまたはイメージタグの形式でより高レベルの情報を使用することが可能です。イメージングサイエンスでは、多くのアプリケーションにオブジェクトバックグラウンド構造がなく、境界ボックスは使用できません。 
[ABSTRACT]マスクなしでトレーニングする直接的な方法は、地面のオブジェクトまたはクラスのサイズに関する事前知識を使用することです。新しいタイプの距離アルゴリズムは、常に同じ関数形の導関数を持ち、神経機能を回避します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: REXUP: I REason, I EXtract, I UPdate with Structured Compositional
  Reasoning for Visual Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_31.html">
      <font color="black">REXUP: I REason, I EXtract, I UPdate with Structured Compositional
  Reasoning for Visual Question Answering</font>
    </a>
  </h2>
  <font color="black">GQAデータセットでREXUPを定量的および定性的に評価し、広範なアブレーション研究を実施してREXUPの有効性の背後にある理由を調査します。最高のモデルは、検証セットで92.7％、73.1％を実現する貴重な最先端技術を大幅に上回っています。 test-dev set。について。この論文では、視覚的な構造を意識したテキスト情報を明示する深い推論VQAモデルを提案し、段階的な推論プロセスのキャプチャと写真内の複雑なオブジェクト関係の検出にうまく機能します。 -現実的な画像。 
[ABSTRACT]当社の最良のモデルは、最先端の貴重な性能を大幅に上回っており、検証セットで92. 7％、テストで73. 1％優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: MFPP: Morphological Fragmental Perturbation Pyramid for Black-Box Model
  Explanations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_32.html">
      <font color="black">MFPP: Morphological Fragmental Perturbation Pyramid for Black-Box Model
  Explanations</font>
    </a>
  </h2>
  <font color="black">MFPPメソッドでは、入力画像をマルチスケールフラグメントに分割し、フラグメントを摂動としてランダムにマスクして、ブラックボックスモデルの予測結果の各ピクセルの有意性を示す顕著性マップを生成します。既存のモデルと比較入力サンプリング摂動法では、ピラミッド構造フラグメントがより効果的であることが証明されています。このホワイトペーパーでは、説明可能なAI問題を解決する新しい形態素断片摂動ピラミッド（MFPP）法を提案します。 
[ABSTRACT] mfppは、dnnの内部アーキテクチャを理解していなくても、dnnを担当する入力領域を特定できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-04">
        <br><font color="black">2020-06-04</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Match Distributions for Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_33.html">
      <font color="black">Learning to Match Distributions for Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、マッチング損失に関する手作りの事前分布に依存せずにクロスドメイン分布マッチングを自動的に学習するためのLearning to Match（L2M）を提案します。パブリックデータセットでの実験は、SOTAメソッドに対するL2Mの優位性を実証します。L2Mは一般的なフレームワークです。タスクに依存しない、人間が設計したマッチング機能を統合します。 
[ABSTRACT]クロスドメインのジョイント分布を直接一致させることは困難です。既存の方法では、mmdや敵対などの事前定義された距離を使用して、限界分布または条件付き分布の相違を減らす傾向があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-17">
        <br><font color="black">2020-07-17</font>
      </time>
    </span>
</section>
<!-- paper0: EfficientDet: Scalable and Efficient Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_34.html">
      <font color="black">EfficientDet: Scalable and Efficient Object Detection</font>
    </a>
  </h2>
  <font color="black">まず、簡単で高速なマルチスケール機能融合を可能にする重み付き双方向機能ピラミッドネットワーク（BiFPN）を提案します。次に、すべてのバックボーン、フィーチャネットワーク、ボックス/クラス予測ネットワークの解像度、深度、幅を同時に均一にスケーリングする複合スケーリング方法を提案します。特に、単一モデルと単一スケールの場合、EfficientDet -D7は、COCO test-devで最新の55.1 APを77Mパラメーターと410B FLOPで実現し、以前の検出器よりも4倍から9倍小さく、FLOPSを13倍から42倍少なくしています。これらの最適化と優れたバックボーンに基づいて、は、EfficientDetと呼ばれるオブジェクト検出器の新しいファミリを開発しました。これは、広範囲のリソース制約にわたって従来技術よりもずっと優れた効率を一貫して達成します。 
[ABSTRACT] efficientdetと呼ばれる新しい範囲のオブジェクト検出器は、幅広いリソース制約にわたって、従来技術よりもずっと優れた効率を一貫して達成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br><font color="black">2019-11-20</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Point Cloud Descriptors in Hand-crafted and Deep Learning Age:
  State-of-the-Art -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_35.html">
      <font color="black">3D Point Cloud Descriptors in Hand-crafted and Deep Learning Age:
  State-of-the-Art</font>
    </a>
  </h2>
  <font color="black">最後に、3D点群記述子の抽出の将来の研究の方向性を提示します。安価な3Dデータ収集デバイスの導入により、3D点群の幅広い可用性と人気が約束され、新規3Dの効果的な抽出により注目が集まっています。近年の3Dコンピュータビジョンタスクの効率を正確にするための点群記述子。このホワイトペーパーでは、既存の3D点群記述子の包括的で洞察に富んだ調査を行います。 
[要約]これらの方法は、記述子の進歩に応じて2つのカテゴリに分類できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-02-07">
        <br><font color="black">2018-02-07</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Robust Learning with Different Label Noise Distributions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_36.html">
      <font color="black">Towards Robust Learning with Different Label Noise Distributions</font>
    </a>
  </h2>
  <font color="black">きれいなサンプルは、通常、小さな損失トリックを使用して識別されます。次に、SSLが2回適用されます。1回はクリーンノイズの検出を改善するために、もう1回は最終モデルのトレーニングのために適用されます。 。 
[ABSTRACT]ノイズの多いラベルを破棄しても、半教師あり学習（ssl）の設定で悪用される可能性があります。clean-ノイズの多い送信を2回適用して、1回でクリーンでノイズの多い検出を改善し、もう一度最終モデルをトレーニングすることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br><font color="black">2019-12-18</font>
      </time>
    </span>
</section>
<!-- paper0: Suppress and Balance: A Simple Gated Network for Salient Object
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_37.html">
      <font color="black">Suppress and Balance: A Simple Gated Network for Salient Object
  Detection</font>
    </a>
  </h2>
  <font color="black">新しいゲート付きデュアルブランチ構造を設計して、さまざまなレベルの機能間の連携を構築し、ネットワーク全体の識別性を向上させます。デュアルブランチの設計により、顕著性マップの詳細をさらに復元できます。さらに、さまざまなスケールの顕著なオブジェクトを正確にローカライズするために提案された「フォールド」操作（Fold-ASPP）に基づいたアストロ空間ピラミッドプーリング。 
[ABSTRACT]プールに加えて、顕著性マップの詳細をさらに復元できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Task-oriented Disentangled Representations for Unsupervised
  Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_38.html">
      <font color="black">Learning Task-oriented Disentangled Representations for Unsupervised
  Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">この欠点は、ドメイン間でラベルが共有されない複雑なオープンセットタスクでのUDAの柔軟性を制限します。複雑なオープンセットシナリオ（検索タスク）および実験的ベンチマーク（分類タスク）での実験は、提案された方法が豊富な複雑な情報をキャプチャすることを示していますドメイン不変表現を学習することにより、トレーニングデータとテストデータの分布間の不一致を解消するために多くの努力が払われてきました。 
[要約]提案された方法は、複雑な情報を取り込み、オープンセットシナリオで優れたパフォーマンスを実現します。これらの2つのコンポーネントは、タスクのグループによって正規化されます。ドメイン全体の特定の目的関数です。ただし、学習された表現は通常、タスクを誘発するものではなく、 uda、そして複雑なオープンセットのシナリオでうまく機能する柔軟性がない</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: XCAT-GAN for Synthesizing 3D Consistent Labeled Cardiac MR Images on
  Anatomically Variable XCAT Phantoms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_39.html">
      <font color="black">XCAT-GAN for Synthesizing 3D Consistent Labeled Cardiac MR Images on
  Anatomically Variable XCAT Phantoms</font>
    </a>
  </h2>
  <font color="black">生成的敵対的ネットワーク（GAN）は、高忠実度の画像を合成することにより、有望なデータエンリッチメントソリューションを提供しています。4クラスの手法は、心臓の注釈のみに依存しています。一方、8クラスの手法では、心臓周囲の臓器の予測された複数組織ラベルマップを採用し、条件付き画像合成により優れたガイダンスを提供します。さらに、実際のデータを増強するための合成画像の利用における改善は、ハウスドルフ距離は最大28％、ダイススコアは最大5％増加し、すべての次元でグラウンドトゥルースとの類似性が高いことを示しています。 
[ABSTRACT]この手法は、意味的に一貫したマスクに基づく画像生成に依存しています。4クラスと8クラスのxcat-gansは、この手法に基づいています。両方の手法で、条件付きxcat-ganを、対応するlabels。実際のデータを拡張するための合成画像の利用の改善は、最大28％のハウズドルフ距離の短縮と最大5％のサイコロスコアの増加により明らかです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient resource management in UAVs for Visual Assistance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_40.html">
      <font color="black">Efficient resource management in UAVs for Visual Assistance</font>
    </a>
  </h2>
  <font color="black">一般的に、カメラが取り付けられたUAVの使用は、実際のシナリオでの幅広いアプリケーションにより、増加しています。しかし、ほとんどの評価モデルは、ハイエンドのCPUとGPUで行われています。関心が高まっています。世界中の農業、軍事、災害管理、航空写真のための無人航空機（UAV）の使用。 
[ABSTRACT] UAVを視覚的支援にリアルタイムで使用することは無人です。これらは、UAVオブジェクトのローエンドプロセッサボードで実行することは困難です。これは、コンピュータビジョンのディープラーニングモデルにもかかわらず</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-11">
        <br><font color="black">2020-07-11</font>
      </time>
    </span>
</section>
<!-- paper0: Online Meta-Learning for Multi-Source and Semi-Supervised Domain
  Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_41.html">
      <font color="black">Online Meta-Learning for Multi-Source and Semi-Supervised Domain
  Adaptation</font>
    </a>
  </h2>
  <font color="black">ドメイン適応（DA）は、ラベルの付いたソースデータセットのモデルを適応させて、ラベルのないデータまたは部分的にラベルの付いたデータのみが利用可能なターゲットデータセットで適切に機能するようにする局所的な問題です。既存のDAアルゴリズムの初期条件をメタ学習することによるパフォーマンス。したがって、計算的に扱いやすく、DAパフォーマンスの向上に実質的に効果的なオンラインの最短パスメタ学習フレームワークを提案します。 
[ABSTRACT]これは、より広く検討されている数ショットのメタ可能パフォーマンスの設定と比較して挑戦的です。msdaと監視されていないドメインの両方のデータセット、および半監視されたドメインの適応を提示します。クラシック（dann）と最近（ mcdおよびmme）msdaおよびssdaの手法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Vertex Mixup: Toward Better Adversarially Robust
  Generalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_42.html">
      <font color="black">Adversarial Vertex Mixup: Toward Better Adversarially Robust
  Generalization</font>
    </a>
  </h2>
  <font color="black">これらの理論的な結果を考慮して、AFO問題の解決策としてソフトラベリングを提示します。敵対的な例により、ニューラルネットワークは高い信頼度で誤った出力を生成します。敵対的に堅牢な一般化を改善するため。 
[ABSTRACT]敵対的訓練は敵対的例に対する防御の最も効果的な形式の1つですが、敵対的訓練と敵対的訓練の精度の間に大きなギャップが存在します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-05">
        <br><font color="black">2020-03-05</font>
      </time>
    </span>
</section>
<!-- paper0: ZSCRGAN: A GAN-based Expectation Maximization Model for Zero-Shot
  Retrieval of Images from Textual Descriptions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_43.html">
      <font color="black">ZSCRGAN: A GAN-based Expectation Maximization Model for Zero-Shot
  Retrieval of Images from Textual Descriptions</font>
    </a>
  </h2>
  <font color="black">複数のベンチマークデータセットでの実験により、提案されたモデルは、いくつかの最先端のゼロショットテキストから画像検索モデル、および検索に適切に使用されるゼロショット分類およびハッシュモデルよりも優れた性能を発揮することが示されています。クエリとして、私たちのモデルはゼロショット設定で関連画像を取得できます。提案されたモデルは、期待値最大化フレームワークを使用してトレーニングされます。 
[ABSTRACT]提案されたモデルは、期待値-最大化フレームワークを使用してトレーニングされます。ゼロショットテキストのセットに基づいています。これらのモデルは、ショットシステムを使用してトレーニングされます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-23">
        <br><font color="black">2020-07-23</font>
      </time>
    </span>
</section>
<!-- paper0: Representation Learning with Video Deep InfoMax -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CV/paper_44.html">
      <font color="black">Representation Learning with Video Deep InfoMax</font>
    </a>
  </h2>
  <font color="black">自然レートシーケンスと時間的にダウンサンプリングされたシーケンスの両方からビューを描画すると、よりコストのかかる大規模スケールトランスモデルを使用する従来の最先端の方法と一致またはそれを上回る速度論トレーニング済みアクション認識タスクで結果が得られることがわかります。 。また、UCF-101データセットのみでトレーニングする場合、データの拡大と微調整の方法の効果を確認し、SoTAを大幅に達成します。DeepInfoMax（DIM）は、ディープネットワークの内部構造を利用して、このようなビューを構築し、画像内の小さなパッチに依存するローカルフィーチャーと画像全体に依存するグローバルフィーチャーとの間に予測タスクを形成します。 
[ABSTRACT]最も効果的なセルフパーパー学習方法には、予測技術が含まれます。これらには、データのさまざまなビューに基づく予測タスクが含まれます。これらには、ビデオディープコンピューターと呼ばれる方法が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for
  Abstractive Text Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CL/paper_0.html">
      <font color="black">A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for
  Abstractive Text Summarization</font>
    </a>
  </h2>
  <font color="black">経験的結果は、抽象的要約における提案された方法の優位性を示しています。Gigaword、DUC-2004、およびLCSTSデータセットに対して、最先端の方法を使用して実験的評価を実行します。単語レベルのアラインメントである私たちのアプローチは、バイアスされた確率生成メカニズムを介して、生成された要約の一貫性、多様性、および有益性を改善できます。 
[要約]研究に加えて、私たちのアプローチは、生成された要約の一貫性、多様性、および情報提供性を向上させることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-05-09">
        <br><font color="black">2018-05-09</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Architecture Search for Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CL/paper_1.html">
      <font color="black">Neural Architecture Search for Speech Recognition</font>
    </a>
  </h2>
  <font color="black">最大1.0％の絶対単語誤り率の削減と28％の相対モデルサイズの削減が得られました。これらには、格子重みのないMMI（LF-MMI）トレーニングにおけるアーキテクチャの重みとTDNNパラメータの推定を完全に統合する標準DARTSメソッドが含まれます。候補アーキテクチャ間の混乱を軽減するGumbel-Softmax DARTS。保持されたデータを使用してアーキテクチャの重みの過剰適合を回避するパイプライン化されたDARTS。さらに、リソースの制約を組み込んでパフォーマンスとシステムの複雑さのトレードオフを調整するペナルティドDARTS。このホワイトペーパーでは、さまざまなニューラルアーキテクチャ検索（NAS）手法を使用して、パフォーマンスに大きな影響を与える2つのハイパーパラメータを自動的に学習します。最先端の因数分解時間遅延ニューラルネットワーク（TDNN-F）音響モデルのモデルの複雑さ：i）左右のスプライシングコンテキストオフセット。 ii）各隠れ層でのボトルネック線形投影の次元。 
[要約]さまざまなニューラルアーキテクチャ検索（nas）メソッドを使用して、2つのハイパー（状態のパフォーマンスとモデルの複雑さに大きく影響するパラメーター）を学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-17">
        <br><font color="black">2020-07-17</font>
      </time>
    </span>
</section>
<!-- paper0: Target-Speaker Voice Activity Detection: a Novel Approach for
  Multi-Speaker Diarization in a Dinner Party Scenario -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CL/paper_2.html">
      <font color="black">Target-Speaker Voice Activity Detection: a Novel Approach for
  Multi-Speaker Diarization in a Dinner Party Scenario</font>
    </a>
  </h2>
  <font color="black">また、シングルチャネルTS-VADモデルから抽出された非表示表現の上に単純な注意メカニズムを使用して、TS-VADアプローチをマルチマイクケースに拡張します。TS-VADモデルは、従来の音声機能（MFCCなど）に沿って入力として各スピーカーのi-ベクトルを使用します。CHiME-6のセグメント化されていないデータの実験は、TS-VADが、ベースラインのx-ベクトルベースのシステムよりも優れた最先端の結果を達成し、ダイアライゼーションエラー率が30％を超えることを示しています。 （DER）abs。 
[ABSTRACT]広く使用されているケースベースのダイアライゼーションは、自律発話の欠如に基づいています。これは、重複発話を処理する能力が限られているためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-14">
        <br><font color="black">2020-05-14</font>
      </time>
    </span>
</section>
<!-- paper0: NAYEL at SemEval-2020 Task 12: TF/IDF-Based Approach for Automatic
  Offensive Language Detection in Arabic Tweets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CL/paper_3.html">
      <font color="black">NAYEL at SemEval-2020 Task 12: TF/IDF-Based Approach for Automatic
  Offensive Language Detection in Arabic Tweets</font>
    </a>
  </h2>
  <font color="black">提案されたシステムは、アラビア語ツイートの攻撃的な言語を自動的に識別することを目的としています。モデルでは、開発セットとテストセットでそれぞれ84.20％、81.82％のf1スコアが報告されました。最適化アルゴリズムとして確率的勾配降下法（SGD）を使用した線形分類器を実装。 
[要約]提案されたシステムは、アラビア語のつぶやきで攻撃的な言語を自動的に識別することを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Towards an Automated SOAP Note: Classifying Utterances from Medical
  Conversations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CL/paper_4.html">
      <font color="black">Towards an Automated SOAP Note: Classifying Utterances from Medical
  Conversations</font>
    </a>
  </h2>
  <font color="black">医療会話の人間とASRの書き起こしと対応する機械学習の最適化されたSOAPノートを含むデータセットの詳細を提供します。次に、既存のディープラーニングアーキテクチャを前述の2つのタスクに適用する体系的な分析を提示します。結果は、単語と発話レベルのコンテキストの両方を取り込む階層的な方法でコンテキストをモデリングすると、両方の分類タスクが大幅に改善されます。 
[ABSTRACT]自動音声認識と自然言語ケアの最近の進歩は潜在的なソリューションを提供しますが、ベンチマーク研究の厳密な定量的ベースラインが欠けています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-17">
        <br><font color="black">2020-07-17</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Domain Adaptation on Reading Comprehension -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CL/paper_5.html">
      <font color="black">Unsupervised Domain Adaptation on Reading Comprehension</font>
    </a>
  </h2>
  <font color="black">これを解決するために、新しい条件付き敵対自己学習法（CASe）を提供します。具体的には、このアプローチでは、ソースデータセットで微調整されたBERTモデルと信頼フィルターを活用して、ターゲットドメインで信頼できる疑似ラベル付きサンプルを生成します。一方、ドメイン間の条件付き敵対的学習により、ドメインの分布の不一致をさらに減らします。 
[ABSTRACT]最初に、強力なbertコンテキスト表現を使用しても、パフォーマンスがまだ不十分であることを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br><font color="black">2019-11-13</font>
      </time>
    </span>
</section>
<!-- paper0: Public Sentiment Toward Solar Energy: Opinion Mining of Twitter Using a
  Transformer-Based Language Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CL/paper_6.html">
      <font color="black">Public Sentiment Toward Solar Energy: Opinion Mining of Twitter Using a
  Transformer-Based Language Model</font>
    </a>
  </h2>
  <font color="black">調査期間中、米国北東部地域は、米国南部地域よりも太陽エネルギーに対する肯定的な感情を示しています。日射量は、州全体の太陽感情の変動と相関していません。1月下旬から7月上旬の期間中の71,262件のツイートの分析2020年には、国民の感情は州によって大きく異なります。 
[ABSTRACT]米国の太陽エネルギーに対する世論はポジティブであることがわかります。太陽光線は市場の方針と特に相関していません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: SummEval: Re-evaluating Summarization Evaluation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CL/paper_7.html">
      <font color="black">SummEval: Re-evaluating Summarization Evaluation</font>
    </a>
  </h2>
  <font color="black">テキスト要約の評価指標に関する包括的な最新の研究の欠如と、評価プロトコルに関するコンセンサスの欠如は、進行を阻害し続けています。5つの側面に沿った要約評価方法の既存の欠点に対処します。1）再評価します12ニューラル集計モデルの出力とエキスパートおよびクラウドソーシングのヒューマンアノテーションを使用した包括的で一貫した方法での自動評価指標、2）前述の自動評価指標を使用して23の最近の集計モデルを一貫してベンチマーク、3）生成された集計の最大のコレクションを収集CNN / DailyMailニュースデータセットでトレーニングされたモデルによって、それを統一された形式で共有します。4）広範な自動メトリック全体で要約モデルを評価するための拡張可能な統一されたAPIを提供するツールキットを実装および共有します。5）組み立てて、モデルタイプの観点から、最大かつ最も多様な人間の判断のコレクションを共有する専門家の裁判官とクラウドソースワーカーの両方が注釈を付けた、CNN / Daily Mailデータセットのモデル生成の要約。この作業が、テキスト要約のためのより完全な評価プロトコルの促進と、より適切に相関する評価指標の開発における事前調査に役立つことを願っています人間の判断で。 
[ABSTRACT] 5次元に沿った要約評価方法の既存の欠点に対処します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-24">
        <br><font color="black">2020-07-24</font>
      </time>
    </span>
</section>
<!-- paper0: Advances of Transformer-Based Models for News Headline Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CL/paper_8.html">
      <font color="black">Advances of Transformer-Based Models for News Headline Generation</font>
    </a>
  </h2>
  <font color="black">BertSumAbsは、フレーズベースの注意トランスフォーマーとCopyNetによって達成された以前の最高スコアよりも平均でそれぞれ2.9ポイントと2.0ポイントずつROUGEを増加させます。トランスフォーマーアーキテクチャに基づく事前トレーニング済み言語モデルが、感情分析、質問など、NLPの多くの領域で最近のブレークスルーの理由です回答、名前付きエンティティの認識..このペーパーでは、そのタスクのために2つの事前トレーニング済みのTransformerベースのモデル（mBARTとBertSumAbs）を微調整し、ロシアのニュースのRIAおよびLentaデータセットで新しい最先端の結果を達成します。 
[ABSTRACT]事前学習済みの変圧器ベースのモデルは微調整です。事前学習済みのモデルに合わせて調整します。また、ロシアのニュースのriaおよびlentaデータセットで新しい最先端の結果を実現します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: No One is Perfect: Analysing the Performance of Question Answering
  Components over the DBpedia Knowledge Graph -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CL/paper_9.html">
      <font color="black">No One is Perfect: Analysing the Performance of Question Answering
  Components over the DBpedia Knowledge Graph</font>
    </a>
  </h2>
  <font color="black">この記事では、2010年以降、リサーチコミュニティによってリリースされたDBpediaナレッジグラフの29の利用可能なQAコンポーネントの動作を分析およびマイクロ評価します。ナレッジグラフに対する質問応答（QA）は、大規模なナレッジグラフの利用可能性の増加とユーザーインタラクションのための質問応答の重要性の増加フィールド用。 
[ABSTRACT] dbpediaは、この設定で最も一般的に使用されるナレッジグラフです。ほとんどのアプローチは、現在、一連のコンポーネントを接続する処理ステップのパイプラインを使用しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-09-26">
        <br><font color="black">2018-09-26</font>
      </time>
    </span>
</section>
<!-- paper0: An Effective Domain Adaptive Post-Training Method for BERT in Response
  Selection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CL/paper_10.html">
      <font color="black">An Effective Domain Adaptive Post-Training Method for BERT in Response
  Selection</font>
    </a>
  </h2>
  <font color="black">ドメイン固有のコーパス（Ubuntu Corpusなど）のポストトレーニングは、モデルが一般的なコーパス（英語のWikipediaなど）に表示されない文脈化された表現と単語をトレーニングするのに役立ちます。実験結果は、私たちのアプローチが新しい状態を実現することを示しています。 2つの応答選択ベンチマーク（つまり、Ubuntu Corpus V1、Advising Corpus）のパフォーマンスは、R @ 1で5.9％および6％向上しました。BERTはさまざまなNLPタスクに容易に採用され、各タスクの以前のベースラインよりも優れていますが、タスクコーパスが特定のドメインに集中しすぎている場合、まだ制限があります。 
[ABSTRACT]ドメインのポストトレーニング-特定のコーパスは、モデルが一般的なコーパスに表示されない文脈化された表現と単語をトレーニングするのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-13">
        <br><font color="black">2019-08-13</font>
      </time>
    </span>
</section>
<!-- paper0: Word Representation for Rhythms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CL/paper_11.html">
      <font color="black">Word Representation for Rhythms</font>
    </a>
  </h2>
  <font color="black">1034個のノッティンガムデータセットを使用して、サイズが450（制御トークンなし）のリズム単語辞書が生成されます。この論文では、リズムパターンの単語表現戦略を提案します。このモデルでは、全体的な音楽構造を見つけ、さまざまなメーターをクラスター化できます。 
[ABSTRACT]サイズが450のリズム単語辞書（制御トークンなし）を作成</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-21">
        <br><font color="black">2020-07-21</font>
      </time>
    </span>
</section>
<!-- paper0: Bayesian Subspace HMM for the Zerospeech 2020 Challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CL/paper_12.html">
      <font color="black">Bayesian Subspace HMM for the Zerospeech 2020 Challenge</font>
    </a>
  </h2>
  <font color="black">私たちのシステムは、非常に低いユニットビットレートを維持しながら、人間が評価した文字エラー率のベースラインと比較して優れています。SHMMは、トレーニングされるパラメータ空間全体の低次元サブスペースにパラメータが存在するように制約されたHMMとして各ユニットをモデル化します。私たちのシステムでは、単位の発見にベイズ部分空間隠れマルコフモデル（SHMM）を使用しています。 
[ABSTRACT]私たちのシステムは、人間が評価した文字エラー率のベースラインと比較して好意的です。ユニットの発見には、隠れマルコフモデル（shmm）も使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-19">
        <br><font color="black">2020-05-19</font>
      </time>
    </span>
</section>
<!-- paper0: Falcon 2.0: An Entity and Relation Linking Tool over Wikidata -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CL/paper_13.html">
      <font color="black">Falcon 2.0: An Entity and Relation Linking Tool over Wikidata</font>
    </a>
  </h2>
  <font color="black">また、技術的な専門知識がなくても実行できるオンラインAPIのデモも行います。候補者はWikidataの国際化リソース識別子（IRI）で表されます。WikidataでのFalcon 2.0のパフォーマンスを経験的に調査し、すべてのパフォーマンスを上回ると結論付けました。既存のベースライン。 
[要旨]テキスト内の知識をwikidata.falcon 2にリンクするためのツールは限られています。0は公開されており、コミュニティで再利用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-24">
        <br><font color="black">2019-12-24</font>
      </time>
    </span>
</section>
<!-- paper0: ZSCRGAN: A GAN-based Expectation Maximization Model for Zero-Shot
  Retrieval of Images from Textual Descriptions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/cs.CL/paper_14.html">
      <font color="black">ZSCRGAN: A GAN-based Expectation Maximization Model for Zero-Shot
  Retrieval of Images from Textual Descriptions</font>
    </a>
  </h2>
  <font color="black">複数のベンチマークデータセットでの実験により、提案されたモデルは、いくつかの最先端のゼロショットテキストから画像検索モデル、および検索に適切に使用されるゼロショット分類およびハッシュモデルよりも優れた性能を発揮することが示されています。クエリとして、私たちのモデルはゼロショット設定で関連画像を取得できます。提案されたモデルは、期待値最大化フレームワークを使用してトレーニングされます。 
[ABSTRACT]提案されたモデルは、期待値-最大化フレームワークを使用してトレーニングされます。ゼロショットテキストのセットに基づいています。これらのモデルは、ショットシステムを使用してトレーニングされます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-23">
        <br><font color="black">2020-07-23</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Evaluating the reliability of acoustic speech embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.AS/paper_0.html">
      <font color="black">Evaluating the reliability of acoustic speech embeddings</font>
    </a>
  </h2>
  <font color="black">そのような埋め込みの評価に現在使用されているメトリックのより詳細な分析が必要です。次に、ABXとMAPを使用して、新しいダウンストリームタスクのパフォーマンスを予測します。つまり、特定のコーパスの音声セグメントの周波数の教師なし推定です。ただし、言語間や埋め込み方法の細かい違いには、かなりの不一致が見られます。 
[ABSTRACT]現在5つの言語で17の埋め込み方法があります。これらには、abx識別と平均平均精度（マップ）が含まれます。5つの言語で2つの一般的なメトリックを比較します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Architecture Search for Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.AS/paper_1.html">
      <font color="black">Neural Architecture Search for Speech Recognition</font>
    </a>
  </h2>
  <font color="black">候補となるアーキテクチャ間でのパラメータ共有は、最大$ 7 ^ {28} $までのTDNNシステムを効率的に検索するためにも使用されました。300時間の交換機の会話型電話音声認識タスクで行われた実験は、NASが一貫して自動構成されたTDNN-Fシステムを示唆しています手動のエキスパート構成を使用して、ベースラインのLF-MMIトレーニング済みTDNN-Fシステムより優れています。最大1.0％の絶対単語エラー率の削減と28％の相対モデルサイズの削減が得られました。 
[要約]さまざまなニューラルアーキテクチャ検索（nas）メソッドを使用して、2つのハイパー（状態のパフォーマンスとモデルの複雑さに大きく影響するパラメーター）を学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-17">
        <br><font color="black">2020-07-17</font>
      </time>
    </span>
</section>
<!-- paper0: Target-Speaker Voice Activity Detection: a Novel Approach for
  Multi-Speaker Diarization in a Dinner Party Scenario -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.AS/paper_2.html">
      <font color="black">Target-Speaker Voice Activity Detection: a Novel Approach for
  Multi-Speaker Diarization in a Dinner Party Scenario</font>
    </a>
  </h2>
  <font color="black">また、シングルチャネルTS-VADモデルから抽出された非表示表現の上に単純な注意メカニズムを使用して、TS-VADアプローチをマルチマイクケースに拡張します。CHiME-6のセグメント化されていないデータの実験では、TS-VADが達成することが示されています。最先端の結果は、ベースラインのx-ベクトルベースのシステムよりも30％以上高いダイアライゼーションエラーレート（DER）を上回っています。 
[ABSTRACT]広く使用されているケースベースのダイアライゼーションは、自律発話の欠如に基づいています。これは、重複発話を処理する能力が限られているためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-14">
        <br><font color="black">2020-05-14</font>
      </time>
    </span>
</section>
<!-- paper0: Analysis of Emotional Content in Indian Political Speeches -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.AS/paper_3.html">
      <font color="black">Analysis of Emotional Content in Indian Political Speeches</font>
    </a>
  </h2>
  <font color="black">人前で話すには感情が重要な役割を果たします。注意力に基づくCNN + LSTMネットワークを使用して、政治家のスピーチに存在する感情的な内容を調査します。このように、インドの政治シナリオにおける政治家のスピーチの感情的な内容の分析を提示します。 。 
[ABSTRACT]注意ベースのCNN LSTMネットワークを使用して、政治家のスピーチに存在する感情的なコンテンツを調査します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Receptive-Field Regularized CNNs for Music Classification and Tagging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.AS/paper_4.html">
      <font color="black">Receptive-Field Regularized CNNs for Music Classification and Tagging</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、適切に設計された正則化戦略に基づいて、ResNetのような深いアーキテクチャを音楽関連のタスクに対して競争力のあるものにする原理的な方法を紹介します。 MIRではめったに使用されません。この主な理由の1つは、これから説明するように、音楽ドメインでより深いCNNが一般化されていないことです。 
[ABSTRACT] mirフィールドは依然として、古典的なvggベースのcnnアーキテクチャバリアントによって支配されています。これらには、注意などのより複雑なモジュール、および大規模なデータセットの事前トレーニングが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: From Sound Representation to Model Robustness -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.AS/paper_5.html">
      <font color="black">From Sound Representation to Model Robustness</font>
    </a>
  </h2>
  <font color="black">ResNet-18は、認識精度の点で他の密な深層学習分類器（つまり、GoogLeNetおよびAlexNet）よりも優れているだけでなく、敵対的な例を他の犠牲者分類器にかなり転送しています。この3つの2D表現ドメインとの関係を調査しました。一般に、3つのベンチマーク環境サウンドデータセットでオーディオ信号を表すために使用されます。敵対者によって割り当てられた平均予算と攻撃のコストのバランスで、6つの強力な敵対的攻撃に対する高い認識精度とモデルの堅牢性の反比例の関係に気づきます。 
[ABSTRACT] mfcc、短時間テオドール変換（stft）、および連続ウェーブレット学習（dwt）は、2D表現空間で環境音信号を変調します。18種類の広告主は、このモデルの攻撃がmfccおよびstft表現よりも比較的コストがかかることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Foreground-Background Ambient Sound Scene Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.AS/paper_6.html">
      <font color="black">Foreground-Background Ambient Sound Scene Separation</font>
    </a>
  </h2>
  <font color="black">私たちの実験的調査結果は、提案されたアプローチの一般化能力を示しています。適切な機能の正規化スキームと、バックグラウンド統計をキャプチャするオプションの補助ネットワークを備えたディープラーニングベースの分離フレームワークを提案し、さまざまな種類を処理する能力を調査しますトレーニングではほとんど見られない、アンビエントサウンドシーンで遭遇するサウンドクラスのセットです。これを行うには、DESEDおよびAudiosetデータセットからの孤立したサウンドを使用してシングルチャネルのフォアグラウンドとバックグラウンドの混合を作成し、さまざまなS / N比で見られる、または見られないサウンドクラス。 
[ABSTRACT] desedおよびaudiosetデータセットデータセットデータセットから分離されたサウンドを使用して、シングル-チャネルフォアグラウンド-バックグラウンドミックスを作成します。これらは、さまざまな異なるサウンドクラスの例です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br><font color="black">2020-05-11</font>
      </time>
    </span>
</section>
<!-- paper0: Hide and Speak: Towards Deep Neural Networks for Speech Steganography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.AS/paper_7.html">
      <font color="black">Hide and Speak: Towards Deep Neural Networks for Speech Steganography</font>
    </a>
  </h2>
  <font color="black">さらに、提案されたアプローチは、複数のデコーダーまたは単一の条件付きデコーダーを使用して単一のキャリアで複数のメッセージを隠すために適用できることを示しました。ビジョン用に提案されたステガノグラフィモデルは音声にはあまり適していないことを示し、次のような新しいモデルを提案しました。短時間フーリエ変換と逆短時間フーリエ変換は、ネットワーク内の微分可能なレイヤーとして機能するため、ネットワーク出力に重要な制約が課せられます。定性的実験では、キャリアへの変更は人間のリスナーには認識されず、デコードされたメッセージは非常にわかりやすいです。 
[要約]提案されたアプローチは、複数のデコーダーまたは単一の条件付きデコーダーを使用して単一のキャリアで複数のメッセージを隠すために適用できます。実験は、キャリアへの変更は人間のリスナーには気付かれず、デコードされたメッセージは非常にわかりやすいことを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-02-07">
        <br><font color="black">2019-02-07</font>
      </time>
    </span>
</section>
<!-- paper0: Joint NN-Supported Multichannel Reduction of Acoustic Echo,
  Reverberation and Noise -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.AS/paper_8.html">
      <font color="black">Joint NN-Supported Multichannel Reduction of Acoustic Echo,
  Reverberation and Noise</font>
    </a>
  </h2>
  <font color="black">反復ブロック座標上昇アルゴリズムを開発して、すべてのフィルターを更新します。これらのフィルターは相互に作用するため、一緒に最適化する必要があります。スマートスピーカーで取得した音響エコー、残響、ノイズの実際の録音でシステムを評価しますさまざまな状況で。 
[ABSTRACT]線形エコーキャンセレーションと残響除去後のターゲット信号と残差信号をモデル化することを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br><font color="black">2019-11-20</font>
      </time>
    </span>
</section>
<!-- paper0: Noisy Agents: Self-supervised Exploration by Predicting Auditory Events -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.AS/paper_9.html">
      <font color="black">Noisy Agents: Self-supervised Exploration by Predicting Auditory Events</font>
    </a>
  </h2>
  <font color="black">Atariゲームの実験結果は、新しい固有の動機がいくつかの最先端のベースラインを大幅に上回ることを示しています。次に、ニューラルネットワークをトレーニングして、聴覚イベントを予測し、予測エラーを固有の報酬として使用してRL探索をガイドします。オブジェクト付き）。 
[ABSTRACT]エージェントが音響データを収集し、kを使用できるようにします-基礎となる聴覚イベントのクラスターを発見する手段</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Self Attentive Multi Layer Aggregation with Feature Recalibration and
  Normalization for End to End Speaker Verification System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.AS/paper_10.html">
      <font color="black">Self Attentive Multi Layer Aggregation with Feature Recalibration and
  Normalization for End to End Speaker Verification System</font>
    </a>
  </h2>
  <font color="black">VoxCeleb1評価データセットを使用した実験結果は、提案された方法のパフォーマンスが最先端のモデルのパフォーマンスに匹敵することを示しました（VoxCeleb1およびVoxCeleb2トレーニングデータセットをそれぞれ使用して、4.95％および2.86％の同等のエラー率）。次に、完全に接続されたレイヤーと非線形アクティベーション関数を使用して、フィーチャーの再キャリブレーションレイヤーが集約されたフィーチャーに適用されます。トレーニングの変動性を制御するために、自己注意メカニズムが適用され、ドロップアウト正則化とマルチレイヤー集約を実行します。バッチ正規化。 
[ABSTRACT]ショートカット接続により、スピーカーの埋め込みの表現力が向上します。そのため、エンドツーエンドのエンドツーエンドのスピーカー検証システム用の自己注意深い多層集合体を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: On the Use of Audio Fingerprinting Features for Speech Enhancement with
  Generative Adversarial Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.AS/paper_11.html">
      <font color="black">On the Use of Audio Fingerprinting Features for Speech Enhancement with
  Generative Adversarial Network</font>
    </a>
  </h2>
  <font color="black">この作業では、Generative Adversarial Network（GAN）に基づく音声強調システムが実装され、MFCCから取得したAudio FingerPrinting（AFP）機能と正規化スペクトルサブバンドセントロイド（NSSC）の組み合わせでテストされます。NSSCは場所をキャプチャします。スピーチフォルマントの重要な方法でMFCCを補完します。MFCCはコンパクトな表現を提供しますが、各メルスケールサブバンドのエネルギーのダイナミクスと分布を無視します。 
[ABSTRACT]時間-周波数領域の機能は、多くのアプローチで推奨されます。これらには、短期テオドール変換（stft）とメル周波数ケプストラルブレッシング（mfcc）が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: MCSAE: Masked Cross Self-Attentive Encoding for Speaker Embedding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.AS/paper_12.html">
      <font color="black">MCSAE: Masked Cross Self-Attentive Encoding for Speaker Embedding</font>
    </a>
  </h2>
  <font color="black">MCSAEでは、クロス自己注意モジュールは、各入力機能の相互依存性をトレーニングします。ランダムマスキング正則化モジュールは、過適合問題を防ぐためにも適用されます。一般に、自己注意メカニズムは、スピーカー埋め込みエンコーディングに適用されています。 
[ABSTRACT]これはマルチレイヤの集約に基づいています。各残余レイヤの出力機能はmcsaeに使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-28">
        <br><font color="black">2020-01-28</font>
      </time>
    </span>
</section>
<!-- paper0: Bayesian Subspace HMM for the Zerospeech 2020 Challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.AS/paper_13.html">
      <font color="black">Bayesian Subspace HMM for the Zerospeech 2020 Challenge</font>
    </a>
  </h2>
  <font color="black">SHMMは、各ユニットをHMMとしてモデル化します。そのパラメーターは、音声変動をモデル化するようにトレーニングされた全パラメーター空間の低次元サブスペースに配置されるように制約されます。システムは、人間が評価した文字エラー率のベースラインと比較しながら、ユニットビットレートが大幅に低下します。このペーパーでは、参加者が注釈なし音声から潜在表現を発見し、それらの表現を使用して合成品質をプロキシメトリックとして使用し、音声合成を実行する必要があるZerospeech 2020チャレンジへの提出について説明します。ユニット品質のため。 
[ABSTRACT]私たちのシステムは、人間が評価した文字エラー率のベースラインと比較して好意的です。ユニットの発見には、隠れマルコフモデル（shmm）も使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-19">
        <br><font color="black">2020-05-19</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Contrastive Learning for Unsupervised Phoneme
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-28/eess.AS/paper_14.html">
      <font color="black">Self-Supervised Contrastive Learning for Unsupervised Phoneme
  Segmentation</font>
    </a>
  </h2>
  <font color="black">テスト時に、ピーク検出アルゴリズムがモデル出力に適用され、最終的な境界が生成されます。結果は、このアプローチがベースラインモデルを上回り、両方のデータセットで最先端のパフォーマンスに到達することを示唆しています。教師なし音素境界検出のタスクのための教師付き表現学習モデル。 
[ABSTRACT]モデルは、生の波形を直接操作する畳み込みニューラルネットワークです。これは、モデルの出力に適用され、最終的な境界を生成するピーク検出アルゴリズムです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
