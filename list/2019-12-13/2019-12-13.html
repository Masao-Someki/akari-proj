<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<title>Akari-2019-12-13の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
  <div class="header-logo">
    <a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
  </div>
</header>
<input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">

<div class="menubar">
<span class="bar"></span>
<span class="bar"></span>
<span class="bar"></span>
</div>

<ul>
<li><a id="home" href="../../index.html">Home</a></li>
<li><a id="about" href="../../teamAkariとは.html">About</a></li>
<li><a id="contact" href="../../contact.html">Contact</a></li>
<li><a id="contact" href="../../list/newest.html">New Papers</a></li>
<li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
</ul>

</label>
<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Listen to Look: Action Recognition by Previewing Audio -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/cs.SD/paper_0.html">
      Listen to Look: Action Recognition by Previewing Audio
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、ImgAud2Vidに基づいて、トリムされていないビデオの有用な瞬間を繰り返し選択し、効率的なビデオレベル認識のための長期的な時間的冗長性を削減する、注意に基づく長期短期メモリネットワークであるImgAud-Skimmingをさらに提案します.4つの広範な実験アクション認識データセットは、本方法が認識精度と速度の両方の面で最先端を達成することを示しています。最初に、より軽いモダリティから抽出することによりクリップレベルの特徴を幻覚化するImgAud2Vidフレームワークを考案します---単一フレームそして、それに付随する音声---効率的なクリップレベル認識のための短期的な時間的冗長性の削減。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-10">
        <br>2019-12-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Singing Synthesis: with a little help from my attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/cs.SD/paper_1.html">
      Singing Synthesis: with a little help from my attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、継続時間モデリングを完全に省くと、生成されるスペクトログラムに時折不安定性が導入されることがわかります。このモデルは、歌唱合成フィールドにうまく適用できることを示しています。文献のほとんどのモデルよりもビブラート、音符および音韻の長さ。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-12">
        <br>2019-12-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On Neural Phone Recognition of Mixed-Source ECoG Signals -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/cs.SD/paper_2.html">
      On Neural Phone Recognition of Mixed-Source ECoG Signals
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、音響信号と神経信号間の転写ミスマッチの可能性を考慮することにより、NSRシステムのパフォーマンスを改善しました。実験結果は、混合ソースシナリオでテストした場合のNSRシステムパフォーマンスの相対的な低下が、自動音声認識（ASR）..このペーパーでは、フラットスタートテクニックの代わりに初期化に手動アライメントを使用することにより、最近公開されたフレームワークのパフォーマンスを大幅に強化しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-12">
        <br>2019-12-12
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Towards Lingua Franca Named Entity Recognition with BERT -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/cs.CL/paper_0.html">
      Towards Lingua Franca Named Entity Recognition with BERT
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      初期モデルを改善するために、マルチタスク学習や部分勾配更新などの正則化戦略の使用を検討します。さらに、3つのCoNLL言語でゼロショットの最先端を実現する、目に見えない言語でも合理的に実行します。このペーパーでは、多言語BERTに基づいて単一の名前付きエンティティ認識モデルを調査します。このモデルは、多くの言語で同時にトレーニングされ、1つの言語のみでトレーニングされたモデルよりも正確にこれらの言語をデコードできます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SMArT: Training Shallow Memory-aware Transformers for Robotic
  Explainability -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/cs.CL/paper_1.html">
      SMArT: Training Shallow Memory-aware Transformers for Robotic
  Explainability
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本論文では、計算要求を制限しながら、言語生成に関する最新のパフォーマンスを提供できる完全に注意深いキャプションアルゴリズムを提案します。さらに、画像領域の新しいメモリ認識エンコーディングを組み込んでいます。キャプションの品質という点では最新技術であり、計算の要求が軽減されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-07">
        <br>2019-10-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Prediction Uncertainty Estimation for Hate Speech Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/cs.CL/paper_2.html">
      Prediction Uncertainty Estimation for Hate Speech Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      予測の不確実性を効率的に推定できるディープニューラルネットワークの適応を提案することにより、このギャップを埋めます。通常、予測の信頼性はテキスト分類で扱われません。異なるテキスト埋め込み方法を使用してアプローチを評価します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-16">
        <br>2019-09-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Controllable Unsupervised Text Attribute Transfer via Editing Entangled
  Latent Representation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/cs.CL/paper_3.html">
      Controllable Unsupervised Text Attribute Transfer via Editing Entangled
  Latent Representation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      上記の問題に対処するために、属性分類子に基づいて属性をモデリングするプロセスを潜在的な表現の最小限の編集に置き換える、より柔軟な教師なしテキスト属性転送フレームワークを提案します。データセット..具体的には、離散テキストのもつれた潜在表現を学習するトランスフォーマーベースのオートエンコーダーを最初に提案し、次に属性転送タスクを最適化問題に変換し、Fast-Gradient-Iterative-Modificationアルゴリズムを提案して、ターゲット属性に適合するまでの潜在表現。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-30">
        <br>2019-05-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Text as Environment: A Deep Reinforcement Learning Text Readability
  Assessment Model -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/cs.CL/paper_4.html">
      Text as Environment: A Deep Reinforcement Learning Text Readability
  Assessment Model
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたアプローチの主な貢献は、特徴抽出の自動化、テキストの可読性評価タスクの言語依存性の緩和、および可読性の評価に必要なテキストの最小部分を見つけることによるテキストの効率的な使用です。評価では、テキストの意味のあるプロパティを特定し、機能を適切な読みやすさレベルに正しく変換する必要があります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-12">
        <br>2019-12-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Abstractive Text Summarization and Fake News Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/cs.CL/paper_5.html">
      Neural Abstractive Text Summarization and Fake News Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、作業の拡張として、テキスト要約モデルを、分類前のニュース記事が要約され、元のニューステキストのみを使用して分類と比較される偽のニュース検出タスクの特徴抽出機能として適用します。この作業では、注意を払ったLSTMエンコーダーデコーダー、ポインタージェネレーターネットワーク、カバレッジメカニズム、トランスフォーマーなどのさまざまなモデルを探索することにより、抽象テキストの要約を研究します。キーワード：LSTM、エンコーダーデコンダー、抽象テキスト要約、ポインター-ジェネレーター、カバレッジメカニズム、トランスフォーマー、偽のニュース検出
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-03-24">
        <br>2019-03-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The Benefits of Close-Domain Fine-Tuning for Table Detection in Document
  Images -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/cs.CL/paper_6.html">
      The Benefits of Close-Domain Fine-Tuning for Table Detection in Document
  Images
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このドキュメントでは、より近いドメインからの微調整を採用する方が有益であることを示します。ドキュメント内のテーブルの正しいローカリゼーションは、構造の決定と内容の抽出に役立ちます。したがって、テーブルの検出はテーブルを理解するための重要なステップです。ただし、自然画像とドキュメント画像の間にはあいまいな関係しかなく、ソースタスクとターゲットタスクの間に密接な関係がある場合は微調整が効果的です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-12">
        <br>2019-12-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Singing Synthesis: with a little help from my attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/cs.CL/paper_7.html">
      Singing Synthesis: with a little help from my attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、デュレーションモデリングを完全に省くと、生成されるスペクトログラムに時折不安定性が生じることがわかります。埋め込みには、音符、デュレーション、および各音で発音される音素に関するスコアにエンコードされた情報が含まれます。文献のほとんどのモデルよりも、F0パターン、ビブラート、音符および音素の長さなどの音声機能のモデリング。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-12">
        <br>2019-12-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Personalized Patent Claim Generation and Measurement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/cs.CL/paper_8.html">
      Personalized Patent Claim Generation and Measurement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このような特許請求の生成は、ディープラーニング分野での最近の転移学習、特に最先端のTransformerベースのモデルを活用しています。トレーニングデータは発明者中心で、USPTOが提供するInventors Endpoint APIから取得します。特許クレームの生成は、「拡張された発明」の方法です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-07">
        <br>2019-12-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Extending Machine Language Models toward Human-Level Language
  Understanding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/cs.CL/paper_9.html">
      Extending Machine Language Models toward Human-Level Language
  Understanding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人間の言語処理は、機械システムのように徐々に学習するディープニューラルネットワークのような学習システムや、新しい情報の迅速な学習をサポートする高速学習システムなど、補完的な学習システムを活用します。物理的および社会的世界のオブジェクトと状況、および将来の機械言語モデルを取得、表現、および通信するためのシステムは、そのようなシステムをエミュレートする必要があります。言語理解。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-12">
        <br>2019-12-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Automatically Neutralizing Subjective Bias in Text -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/cs.CL/paper_10.html">
      Automatically Neutralizing Subjective Bias in Text
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、タスクに2つの強力なエンコーダーデコーダーベースラインを提案します。この種のバイアスは、集団の信頼を損ない、社会的対立を促進します。また、バイアス言語の最初の並列コーパスも提供します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Automatic Spanish Translation of the SQuAD Dataset for Multilingual
  Question Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/cs.CL/paper_11.html">
      Automatic Spanish Translation of the SQuAD Dataset for Multilingual
  Question Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、最近提案されたクロスリンガル抽出QAのMLQAおよびXQuADベンチマークを使用してQAモデルを評価しました。結果として、ほぼ100％のデータが元の英語版に含まれる合成的に生成されたSQuAD-es v1.1コーパス実験結果は、モデルがスペイン語の68.1 F1ポイントという最新の価値を達成する以前のMultilingual-BERTベースラインよりも優れていることを実験結果が示しています。 MLQAコーパスおよびスペイン語XQuADコーパスの77.6 F1および61.8完全一致ポイント。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-11">
        <br>2019-12-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Interpretability of Word Embeddings by Generating Definition
  and Usage -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/cs.CL/paper_12.html">
      Improving Interpretability of Word Embeddings by Generating Definition
  and Usage
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、これらの埋め込みによってキャプチャされた語彙のセマンティクスは、密なベクトル表現のために解釈が困難です。アプローチを検証するために、各エントリが単語、コンテキスト、例文、対応する定義を含むOxford-2019データセットを構築します。単語ベクトルの解釈可能性を改善するために、定義モデリングタスクを調査し、より合理的で理解可能なコンテキスト依存の定義を生成するための新しいフレームワーク（Semantics-Generator）を提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-12">
        <br>2019-12-12
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Listen to Look: Action Recognition by Previewing Audio -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/eess.AS/paper_0.html">
      Listen to Look: Action Recognition by Previewing Audio
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      4つのアクション認識データセットに関する広範な実験により、本手法が認識の精度と速度の両方の観点から最先端を達成することが実証されています。 -単一のフレームとそれに付随する音声---効率的なクリップレベル認識のための短期的な時間的冗長性の削減。ビデオデータのdel濫に直面して、今日の高価なクリップレベル分類器はますます非実用的です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-10">
        <br>2019-12-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Singing Synthesis: with a little help from my attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/eess.AS/paper_1.html">
      Singing Synthesis: with a little help from my attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、期間モデリングを完全に省くと、生成されるスペクトログラムに時折不安定性が導入されることがわかります。自己回帰WaveNetをニューラルボコーダーとして使用し、シーケンスツーシーケンスアーキテクチャによって生成されるメルスペクトログラムを合成します。音声と歌唱データの組み合わせ。私たちのモデルは、歌唱合成分野に注意をうまく適用できることを示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-12">
        <br>2019-12-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On Neural Phone Recognition of Mixed-Source ECoG Signals -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/eess.AS/paper_2.html">
      On Neural Phone Recognition of Mixed-Source ECoG Signals
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、音響信号と神経信号の転写ミスマッチの可能性を考慮することにより、NSRシステムのパフォーマンスを向上させました。 ..実験結果は、混合ソースシナリオでテストした場合のNSRシステムパフォーマンスの相対的な低下が、自動音声認識（ASR）のそれよりも大幅に低いことを示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-12">
        <br>2019-12-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Speech-driven facial animation using polynomial fusion of features -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/eess.AS/paper_3.html">
      Speech-driven facial animation using polynomial fusion of features
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちは、ビデオ品質、視聴覚同期、まばたきの生成に関する一連のメトリックで評価された生成ビデオの実験を通じて、このアプローチの適合性を実証します。音声駆動の顔面アニメーションには、音声信号を使用して話している顔のリアルなビデオを生成します。顔の合成に対する最近の深層学習のアプローチは、低次元の表現を抽出してそれらを連結し、その後に連結されたベクトルのデコードステップが必要です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-12">
        <br>2019-12-12
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Larval thermal characteristics of multiple ixodid ticks underlie their range dynamics -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-13/biorxiv.physiology/paper_0.html">
      Larval thermal characteristics of multiple ixodid ticks underlie their range dynamics
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      高温生存率は41〜47 {℃}で、Rhipicephalus sanguineusが最高の致死上限を持ちました。Ixodesscapularisは低温と高温の両方で最低の生存率を示しました。温度は地理的制限によりダニの個体数に影響を与える主な要因です。さまざまな種の範囲。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-12">
        <br>2019-12-12
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
