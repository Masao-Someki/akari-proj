<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-05-14の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Flowtron: an Autoregressive Flow-based Generative Network for
  Text-to-Speech Synthesis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.SD/paper_0.html">
      Flowtron: an Autoregressive Flow-based Generative Network for
  Text-to-Speech Synthesis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Flowtronは、音声合成の多くの側面（ピッチ、トーン、スピーチレート、ケイデンス、アクセント）を制御するために操作できる潜在空間へのデータの可逆マッピングを学習します。コードと事前トレーニング済みモデルは、https：で公開されます。 //github.com/NVIDIA/flowtron。さらに、音声の変化の制御、サンプル間の補間、およびトレーニング中に見られたおよび見られなかった話者間のスタイル転送に関する結果を提供します。 
[ABSTRACT] flowgreはiafから洞察を借用し、高品質で表現力豊かなメルの予約注文に利用できるtacotron.itを改良しました-spectrovid
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Discriminative Multi-modality Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.SD/paper_1.html">
      Discriminative Multi-modality Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      視覚モダリティを組み合わせた後、ASRはマルチモダリティ音声認識（MSR）にアップグレードされます。このホワイトペーパーでは、2段階の音声認識モデルを提案します。LRS3-TEDおよびLRWデータセットで大規模な実験を行いました。 
[要約]視覚モダリティを組み合わせた後、asrはマルチモダリティ音声認識（msr）にアップグレードされます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Mixture of Inference Networks for VAE-based Audio-visual Speech
  Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.SD/paper_2.html">
      Mixture of Inference Networks for VAE-based Audio-visual Speech
  Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、音声強調中に、視覚データを使用して潜在変数が初期化されるため、ノイズの多い音声スペクトログラムを使用する場合よりも堅牢な初期化が提供されます。変分推論アプローチが提案されたVAEをトレーニングするために導出されます。スピーカーの唇の画像、提供スピーチに関する有用で補足的な情報。 
[要約]提案された音声-視覚的vaeモデルを使用して、潜在変数の事後を推測できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-23">
        <br>2019-12-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.SD/paper_3.html">
      Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      我々はCycleGANネットワークを提案し、敵対的およびサイクル一貫性損失を使用して前方および逆マッピングを同時に学習することにより、非並列トレーニングデータから最適な疑似ペアを見つけます。感情的な音声変換は、スペクトルと韻律を変換して音声の感情パターンを変更することを目的としています、話者のアイデンティティと言語的内容を維持しながら。F0を10の時間スケールに分解するための連続ウェーブレット変換（CWT）の使用も検討します。これは、効果的なF0変換のために、異なる時間解像度での音声韻律を表します。 
[ABSTRACT]多くの研究では、異なる線形パターン間の並列音声データが必要です。これらの研究では、イントネーションの重要な側面であるf0が必要です。ただし、ウェーブレット変換を使用してf0をモデル化する方が適切であると考えています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-01">
        <br>2020-02-01
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Psychometric Analysis and Coupling of Emotions Between State Bulletins
  and Twitter in India during COVID-19 Infodemic -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_0.html">
      Psychometric Analysis and Coupling of Emotions Between State Bulletins
  and Twitter in India during COVID-19 Infodemic
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      誤った情報の緩和に積極的に関与している政策立案者やコミュニケーターに潜在的に関連するさらなる洞察についても議論します。この研究では、COVID-19インフォデミックとCOVID-19に関連する公式速報との心理測定的影響およびカップリングを分析します。インドの国家および州レベル。.ソーシャルメディアは最大の情報源であるため、情報流行を管理するには、誤った情報を軽減するだけでなく、情報に起因する心理的パターンを早期に理解する必要があります。 
[要約] Twitterだけでも、キュレートされたイベントページの使用率が45％急増しました。これらのソースを心理学-感情の言語学的レンズで調べます。その後、時間-健康の進化-関連する感情をキャプチャできました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: End-to-end Semantics-based Summary Quality Assessment for
  Single-document Summarization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_1.html">
      End-to-end Semantics-based Summary Quality Assessment for
  Single-document Summarization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたアプローチは、ゴールドスタンダードのデータセットで非常に有望な結果を示し、将来の要約研究にその大きな可能性を示唆しています。したがって、単語の意味的な類似性を活用して要約品質評価のための新しいエンドツーエンドのメトリックシステムを導入します。ディープラーニングの文..フレームワークでトレーニングされたモデルは、参照サマリーを必要とせずに、入力ドキュメントに対してサマリーを直接評価できます。 
[ABSTRACT] rougeは参照サマリーなしで機能する可能性があり、多くの場合、取得するのが高価または不可能です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br>2020-05-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Reasoning with Latent Structure Refinement for Document-Level Relation
  Extraction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_2.html">
      Reasoning with Latent Structure Refinement for Document-Level Relation
  Extraction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、私たちのモデルは、大規模なドキュメントレベルのデータセット（DocRED）で59.05のF1スコアを達成し、以前の結果を大幅に改善し、CDRおよびGDAデータセットに新しい最先端の結果をもたらします。既存のアプローチでは、非構造化テキストから構文ツリー、共参照、またはヒューリスティックに基づいて静的なドキュメントレベルのグラフを作成し、依存関係をモデル化します。さらに、モデルがマルチホップ推論の関連情報を段階的に集約できるようにする改良戦略を開発します。 
[ABSTRACT]モデルはドキュメント内の主要な協力情報を取り込むことができます。しかし、それは効果的な協力協力がいかに必要であるかという課題のままです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br>2020-05-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The Unstoppable Rise of Computational Linguistics in Deep Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_3.html">
      The Unstoppable Rise of Computational Linguistics in Deep Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この視点は、自然言語理解のためのディープラーニングアーキテクチャの研究が直面する課題の予測につながります。注意に基づくモデルにおける変数バインディングとそのインスタンス化の重要性に焦点を当て、Transformerはシーケンスモデルではなく、誘導モデルであると主張します。構造モデル..このホワイトペーパーでは、自然言語理解タスクに適用されるニューラルネットワークの履歴を追跡し、ニューラルネットワークアーキテクチャの開発に言語の性質がもたらした重要な貢献を特定します。 
[ABSTRACT]変数キーの重要性とそのインスタンス化に注目します-ベースのモデル。トランスはシーケンスモデルではなく、誘導-構造モデルであると主張します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br>2020-05-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Controlled Crowdsourcing for High-Quality QA-SRL Annotation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_4.html">
      Controlled Crowdsourcing for High-Quality QA-SRL Annotation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      質問回答型のセマンティックロールラベル（QA-SRL）は、SRLの魅力的でオープンで自然なフレーバーとして提案されました。このプロトコルをQA-SRLに適用すると、大幅にカバレッジの高い高品質のアノテーションが生成され、新しいゴールド評価データセット..最近、クラウドソーシングによる大規模なQA-SRLコーパスと訓練されたパーサーがリリースされました。 
[要約]大規模なクラウドソーシングされた新しいテキストとトレーニングされたパーサーがリリースされました。新しいを作成するために、複雑なセマンティックアノテーション用の改良されたクラウドソーシングプロトコルを提示します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-08">
        <br>2019-11-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Large Scale Multi-Actor Generative Dialog Modeling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_5.html">
      Large Scale Multi-Actor Generative Dialog Modeling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、過去の参照会話を条件付けして俳優のペルソナでの多回転会話を確率論的にモデル化する拡張および微調整されたGPT-2言語モデルであるジェネレーティブカンバセーションコントロールモデルを紹介します。ターゲットアクターの以前の会話での条件付けによる生成..モデルスケールの増加は、リアリズム（31％から37％への優先度）、スタイルマッチング（31％から37％への優先度）の観点からモデルサンプルの優先度を保持されたターゲット分布に測定する人間の評価に同様の改善をもたらしました。 37％〜42％）、文法とコンテンツの品質（29％〜42％）、会話の一貫性（32％〜40％）。 
[ABSTRACT]チャットボットは、ユーザーとの多様で魅力的な会話を生み出すことを目的としています。ただし、会話では一貫性のない性格またはすべてのユーザーの平均的な性格のいずれかを示します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br>2020-05-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Screenplay Quality Assessment: Can We Predict Who Gets Nominated? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_6.html">
      Screenplay Quality Assessment: Can We Predict Who Gets Nominated?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      （2）業界の意見とナラトロジーに基づいて、ドメイン固有の機能を抽出して一般的な分類手法に統合します。2つの課題に直面します（1）スクリプトは他のドキュメントデータセットよりもはるかに長い（2）指定されたスクリプトは制限されているため、収集..私たちの仕事は、脚本分析における将来の仕事のための新しいアプローチを提供します。 
[要約]制作の初期段階であるスクリプトの選択を支援するツールを構築することは、非常に有益です。2つのアプローチでこれに対処します。私たちは、主要な映画賞でのスクリプトの推薦を予測することとしてタスクを定義します。ピア-認識されたスクリプトは成功する可能性が高いはずです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br>2020-05-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Flowtron: an Autoregressive Flow-based Generative Network for
  Text-to-Speech Synthesis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_7.html">
      Flowtron: an Autoregressive Flow-based Generative Network for
  Text-to-Speech Synthesis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、音声変化の制御、サンプル間の補間、トレーニング中に見られたスピーカーと見られなかったスピーカー間のスタイル転送の結果を提供します。平均オピニオンスコア（MOS）は、Flowtronが最新のTTSモデルと音声品質.. Flowtronは、音声合成の多くの側面（ピッチ、トーン、音声速度、リズム、アクセント）を制御するために操作できる潜在空間へのデータの可逆マッピングを学習します。 
[ABSTRACT] flowgreはiafから洞察を借用し、高品質で表現力豊かなメルの予約注文に利用できるtacotron.itを改良しました-spectrovid
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: INFOTABS: Inference on Tables as Semi-structured Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_8.html">
      INFOTABS: Inference on Tables as Semi-structured Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、半構造化された表形式のテキストが遍在していることを観察します。それらを理解するには、テキストの断片の意味を理解するだけでなく、それらの間の暗黙的な関係も必要です。実験により、人間のアノテーターは表と仮説のペア間の関係に同意するものの、いくつかの標準的なモデリング戦略はタスクで失敗し、テーブルについての推論は難しいモデリングの課題をもたらす可能性があります。私たちの分析は、構内の半構造化されたマルチドメインおよび異種の性質が複雑で多面的な推論を認めていることを示しています。 
[ABSTRACT]私たちの分析は、私たちのデータが、私たちが情報についてどのように推論するかを理解するためのテストグラウンドとして証明できることを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br>2020-05-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Document Modeling with Graph Attention Networks for Multi-grained
  Machine Reading Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_9.html">
      Document Modeling with Graph Attention Networks for Multi-grained
  Machine Reading Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このベンチマークでの既存のメソッドの有効性にもかかわらず、依存関係を無視しながらトレーニング中にこれらの2つのサブタスクを個別に処理します。このようにして、2つの詳細な回答間の依存関係をモデル化して、互いの証拠を提供できます。この問題に対処するため、ドキュメント、パラグラフ、センテンス、トークンというさまざまなレベルの粒度である階層的な性質でドキュメントをモデル化することに焦点を当てた、新しいマルチグレインの機械読解フレームワークを紹介します。 
[ABSTRACT]このベンチマークで新しいベンチマークが開発されました。ベンチマークでの既存のメソッドの有効性にもかかわらず、これらの2つのサブタスクは個別に処理されます。これらの2つのサブタスクは、依存関係を無視しながらトレーニング中に個別に処理されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SpellGCN: Incorporating Phonological and Visual Similarities into
  Language Models for Chinese Spelling Check -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_10.html">
      SpellGCN: Incorporating Phonological and Visual Similarities into
  Language Models for Chinese Spelling Check
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、類似性の知識は外部入力リソースまたはヒューリスティックルールのいずれかです。これらの分類子は、BERTなどの別のネットワークによって抽出された表現に適用され、ネットワーク全体をエンドツーエンドでトレーニングできるようにします。論文は、音韻的および視覚的類似性の知識を、特殊なグラフ畳み込みネットワーク（SpellGCN）を介してCSCの言語モデルに組み込むことを提案しています。 
[ABSTRACT]例には、スペルの類似性の知識と音韻の知識が含まれます。これらは、bertなどの別のネットワークによって抽出された表現に適用されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-26">
        <br>2020-04-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: BIOMRC: A Dataset for Biomedical Machine Reading Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_11.html">
      BIOMRC: A Dataset for Biomedical Machine Reading Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      新しいデータセットを3つの異なるサイズで利用できるようにし、コードをリリースし、リーダーボードを提供します。非専門家の人間のパフォーマンスも、BIOREADと比較して新しいデータセットで高く、生物医学の専門家はさらに優れています。ヒューリスティックは新しいデータセットではうまく機能せず、BIOREADでテストされた2つのニューラルMRCモデルのパフォーマンスはBIOMRCではるかに優れています。これは、新しいデータセットのノイズが少ないか、少なくともそのタスクの実行可能性が高いことを示しています。 
[ABSTRACT] bioreadのbioreadデータセットは、新しいデータセットでは単純なヒューリスティックがうまく機能しないことを示しています。bioreadでテストされた2つの神経mrcモデルは、biomrcではるかによく機能します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br>2020-05-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Discriminative Multi-modality Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_12.html">
      Discriminative Multi-modality Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ビジョンは、音声ソロ認識（ASR）の補完的なモダリティとして、特にソロオーディオモダリティのパフォーマンスが大幅に低下するノイズの多い環境でよく使用されます。視覚モダリティを組み合わせた後、ASRはマルチモダリティ音声認識（MSR）にアップグレードされます。 。最初の段階では、対象の声が唇の動きの対応する視覚情報の助けを借りて背景のノイズから分離され、モデルが明確に「聞こえる」ようになります。 
[要約]視覚モダリティを組み合わせた後、asrはマルチモダリティ音声認識（msr）にアップグレードされます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards Hate Speech Detection at Large via Deep Generative Modeling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_13.html">
      Towards Hate Speech Detection at Large via Deep Generative Modeling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、ディープラーニング（DL）ベースのソリューションが、数千のヘイトスピーチシーケンスの適度なサイズのトレーニングデータセットを使用して、ヘイトスピーチを自動検出するために提案されています。データ駆動型のアプローチであるため、DLが他のDL列車のデータセットのサイズと多様性のスケールアップが達成されるときはいつでもメソッド。悪意のある音声の検出には、オンライン投稿とツイートの監視のための高性能コンピューティング、疑わしい投稿またはツイートの毎日のスクリーニングのための数千人の専門家など、圧倒的なリソースが必要です。 
[ABSTRACT]ヘイトスピーチの検出には、オンライン投稿とツイートのモニタリングに高性能コンピューティングが必要です。疑わしい投稿またはツイートの毎日のスクリーニングには何千人もの人間の専門家が行います。これらの手法は特定のデータセットに対して適切に機能しますが、新しいヘイトスピーチのシーケンスを検出する機能は限られており、調査されていません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br>2020-05-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Guiding Variational Response Generator to Exploit Persona -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_14.html">
      Guiding Variational Response Generator to Exploit Persona
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、提案された方法論がペルソナ対応の応答生成のパフォーマンスを著しく改善できることを示しており、測定基準は結果を評価するのに合理的です。この論文では、人間の会話のパーソナリティ関連の特性を変分応答ジェネレータに採用することを提案しています。ペルソナ対応の応答と関連する応答の両方を生成する方向に最適化を導くために、損失関数に採用された2つの新しい正則化条件を使用して特定の条件付き変分オートエンコーダーに基づくディープモデルを設計することによって。さまざまなパフォーマンスを合理的に評価するペルソナモデリングアプローチでは、このペーパーはさらに、異なる視点からの3つの直接的なペルソナ指向のメトリックを示します。 
[要旨]個人情報は、ユーザーの埋め込みの形でニューラルネットワークに組み込まれる傾向があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-06">
        <br>2019-11-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Mitigating Gender Bias Amplification in Distribution by Posterior
  Regularization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_15.html">
      Mitigating Gender Bias Amplification in Distribution by Posterior
  Regularization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、分布の観点から性別バイアス増幅の問題を調査し、ラベル上の予測確率分布の観点からバイアスが増幅されることを示します。パフォーマンスの損失がほとんどないため、この方法では、分布のバイアス増幅をほとんど除去できます。ただし、それらの分析はモデルの上位の予測に対してのみ行われます。 
[ABSTRACT]研究は、偏ったコミュニケーションは問題ではないことを示しています。しかし、彼らは、分析がモデルのトップの予測に対してのみ行われることを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br>2020-05-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Sanskrit Segmentation Revisited -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_16.html">
      Sanskrit Segmentation Revisited
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのうち、サンスクリットヘリテージエンジンのG \ &#39;erard Huetのリーダーは、入力テキストを分析し、単語パラメーター（iic、ifc、Pr、Substなどのフェーズ、およびsandhi（または遷移）など）に基づいてセグメント化します。次の単語の最初の部分を含む単語の終わり。ただし、セグメンテーションでは、フェーズで形成された単語が形態学的に有効であるかどうかを決定する以外に使用されません。フェーズとその分析は、構文解析器。 
[ABSTRACT]ツールは、言語言語languageの変換を支援するために使用されます。ライティングライティングライティングは、コンテキストで使用できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br>2020-05-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Introducing the VoicePrivacy Initiative -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_17.html">
      Introducing the VoicePrivacy Initiative
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      VoicePrivacyイニシアチブは、関心のあるタスクと評価方法を定義するための新しいコミュニティを集め、一連の課題を通じてソリューションをベンチマークすることにより、音声技術のプライバシー保護ツールの開発を促進することを目的としています。また、攻撃モデルと関連する客観的および主観的な評価指標..このホワイトペーパーでは、VoicePrivacy 2020チャレンジのために選択された音声匿名化タスクを定式化し、システムの開発と評価に使用されるデータセットについて説明します。 
[ABSTRACT] voiceprivacyソリューションイニシアチブは、ベンチマークソリューションソリューションによって作成されました。タスクは、voiceprivacy 2020シリーズ用に選択されました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-04">
        <br>2020-05-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Parallel Corpus Filtering via Pre-trained Language Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_18.html">
      Parallel Corpus Filtering via Pre-trained Language Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      WMT 2018 Parallel Corpus Filtering共有タスク、および独自のWebクロールされた日中並列コーパスで提案された方法を評価します。設定すると、このメソッドは上位1の監視ありメソッドと同等のパフォーマンスを実現します。 
[ABSTRACT]ウェブの多言語機能を活用して文の並列性を測定します。ドメインフィルターとしてgpt言語モデルを使用して、データドメインのバランスを取ります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br>2020-05-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Polysynthetic Language Modelling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_19.html">
      Neural Polysynthetic Language Modelling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      文献では、フィンランド語やトルコ語などの言語は、一般的なモデリングの仮定に挑戦する複雑さの極端な例として取り上げられています。しかし、世界のすべての言語を考えると、フィンランド語とトルコ語は平均的なケースに近いです。自然言語処理の研究一般に、英語やその他の広く使用されている言語でうまく機能するアプローチは「言語にとらわれない」ものであると想定しています。 
[ABSTRACT]高リソース言語では、共通のアプローチは、永続的に-共通のルートの異なるバリアントを完全に独立した単語タイプとして扱うことです。現在、保持されない期待はありません。しかし、世界中のすべての言語、フィンランド語、トルコ語は平均的なケースに近い
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br>2020-05-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Response-Anticipated Memory for On-Demand Knowledge Integration in
  Response Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_20.html">
      Response-Anticipated Memory for On-Demand Knowledge Integration in
  Response Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      教師は外部ドキュメント、コンテキスト、グラウンドトゥルースレスポンスを与えられ、3つの情報源からレスポンスを意識したドキュメントメモリを構築する方法を学習します。これは、教師と生徒のフレームワークを使用して達成されます。最初の2つのソースから応答が予想されるドキュメントメモリを構築し、メモリ作成に関する教師の洞察を作成します。 
[要約]このペーパーでは、予想されるいくつかの応答を念頭に置いてドキュメントメモリを作成することを提案します。教師には、外部ドキュメント、コンテキスト、グラウンドトゥルース応答が与えられ、応答の作成方法を学習します-認識ドキュメント3つの情報源からの記憶
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br>2020-05-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to Customize Model Structures for Few-shot Dialogue Generation
  Tasks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_21.html">
      Learning to Customize Model Structures for Few-shot Dialogue Generation
  Tasks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのアプローチでは、各対話モデルは共有モジュール、ゲーティングモジュール、プライベートモジュールで構成されています。最初の2つのモジュールはすべてのタスクで共有され、3番目のモジュールは異なるネットワーク構造に区別して、対応するタスク..この論文では、少数ショット設定でタスクごとに独自の対話モデルをカスタマイズできるアルゴリズムを提案します。 
[要約]このペーパーでは、少数ショット設定で各タスクに固有の対話モデルをカスタマイズできるアルゴリズムを提案します。最初の2つのモジュールはすべてのタスクで共有され、3番目のモジュールは異なるネットワークに区別してキャプチャします対応するタスクの特性
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-31">
        <br>2019-10-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Diversifying Dialogue Generation with Non-Conversational Text -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_22.html">
      Diversifying Dialogue Generation with Non-Conversational Text
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      フォーラムのコメント、イディオム、書籍の抜粋など、複数のソースから大規模な非会話型コーパスを収集します。このホワイトペーパーでは、非会話型テキストを活用して対話生成を多様化する新しい視点を提案します。さらに、トレーニングパラダイムを提示します。これらのテキストを反復的な逆翻訳を介して効果的に組み込む。 
[ABSTRACT]さらに、反復的な逆翻訳を介してテキストを効果的に組み込むためのトレーニングモデルを提示します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-09">
        <br>2020-05-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to Perform Role-Filler Binding with Schematic Knowledge -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_23.html">
      Learning to Perform Role-Filler Binding with Schematic Knowledge
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      以前の研究では、役割とフィラーが何であるかを明示的に伝えられた場合、またはトレーニング中にフィラーが見られた場合に、モデルがこの機能を学習できることがわかりました。この研究では、任意のフィラーを呼び出すことができる場合、モデルを役割とフィラーのバインディングを実行できると定義します。これらの組み合わせがトレーニング中に見られる相関に違反している場合でも、指定された役割に対応します。任意のフィラーに対してこれらのバインディングを実行できます。「Alice」、「tea」、または「Bob」の名前を聞いたことがない場合でも、この文は理解できます&quot; 前。 
[要約]スキーマ理論は、この情報を「スキーマ」と呼ばれる精神的なフレームワークに整理することを示唆しています。これらの精神的なフレームワークは「分裂」と呼ばれ、世界の構造に関する私たちの知識を表しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-02-24">
        <br>2019-02-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: jiant: A Software Toolkit for Research on General-Purpose Text
  Understanding Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_24.html">
      jiant: A Software Toolkit for Research on General-Purpose Text
  Understanding Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      jiantは、BERTやRoBERTaなど、さまざまなタスクとモデルで公開されたパフォーマンスを再現することを示しています。jiantは、https：//jiant.info。で入手できます。jiantは、マルチタスクを実行し、英語のNLUタスク。 
[ABSTRACT] jiantは、bertやrobertaなど、さまざまなタスクやモデルで公開されたパフォーマンスを再現することを示しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-04">
        <br>2020-03-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Machine Reading Comprehension: The Role of Contextualized Language
  Models and Beyond -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_25.html">
      Machine Reading Comprehension: The Role of Contextualized Language
  Models and Beyond
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのトピックについて、フルビューの分類と新しい分類法を提案します。ディープニューラルネットワークのバーストとコンテキスト化言語モデル（CLM）の進化により、MRCの研究は2つの重要なブレークスルーを経験しました。機械読解（MRC）自然言語処理（NLP）の長年の目標である人間の言語を読み取って理解するように機械を教えることを目的としています。 
[ABSTRACT] mrcの研究は2つの重要な突破口を経験しました。mrcはエジンバラ大学の教授の発案によるものです。mrcの研究は主要な突破口として説明されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br>2020-05-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_26.html">
      Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CycleGANネットワークを提案し、敵対的損失とサイクル整合性損失を使用してフォワードマッピングとインバースマッピングを同時に学習することにより、非並列トレーニングデータから最適な疑似ペアを見つけます。また、F0を10に分解するための連続ウェーブレット変換（CWT）の使用についても研究します。効果的なF0変換のための、異なる時間解像度での音声韻律を表す時間スケール。感情的な音声変換は、話者のアイデンティティと言語的内容を維持しながら、スペクトルと韻律を変換して音声の感情パターンを変更することを目的としています。 
[ABSTRACT]多くの研究では、異なる線形パターン間の並列音声データが必要です。これらの研究では、イントネーションの重要な側面であるf0が必要です。ただし、ウェーブレット変換を使用してf0をモデル化する方が適切であると考えています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-01">
        <br>2020-02-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Quda: Natural Language Queries for Visual Data Analytics -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_27.html">
      Quda: Natural Language Queries for Visual Data Analytics
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      自由形式のユーザークエリに対して効果的な設計決定を行うプロトタイプを作成して、V-NLIを構築する際のQudaの有用性を示します。V-NLIが自由形式の自然言語を理解できるように、Qudaと呼ばれる新しいデータセットを提示します。学習ベースのアプローチは、V-NLIの可能性を示しており、さまざまなNLPタスクで最先端のパフォーマンスに達しています。 
[ABSTRACT] qudaは、学術出版物に記載されている設計タスクを分析することにより、視覚化コミュニティのさまざまなアプリケーションに有益です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Dense-Caption Matching and Frame-Selection Gating for Temporal
  Localization in VideoQA -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/cs.CL/paper_28.html">
      Dense-Caption Matching and Frame-Selection Gating for Temporal
  Localization in VideoQA
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、単語、オブジェクト、フレームレベルの視覚化研究もいくつか紹介します。モデルの各コンポーネントが大幅な改善をもたらし、モデル全体が最先端のパフォーマンスを発揮する、困難なTVQAデータセットでモデルを評価します。マージンが大きい（74.09％対70.52％）。この論文では、マルチモーダル入力ソースを効果的に統合し、時間的に関連する情報を見つけて質問に答えるビデオ質問応答モデルを提案します。 
[要約]最初に高密度の画像キャプションを使用してオブジェクトとその詳細な顕著領域とアクションを識別します。これにより、モデルは質問に答えるための有用な追加情報を提供します。また、いくつかの単語、オブジェクト、フレームレベルの視覚化研究
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br>2020-05-13
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Towards Fast and Accurate Streaming End-to-End ASR -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/eess.AS/paper_0.html">
      Towards Fast and Accurate Streaming End-to-End ASR
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最初のパスのレイテンシは直接改善されませんでしたが、WERの大幅な削減により、WERとレイテンシを交換する余地が増えました。 ASR ..最小ワードエラーレート（MWER）トレーニングテクニックをさらに適用することにより、音声検索テストセットで8.0％の相対ワードエラーレート（WER）の削減と130ミリ秒の90パーセンタイルレイテンシの削減を達成しました。 
[要約]たとえば、ストリーミングe2eモデルとしての再帰型ニューラルネットワークトランスデューサー（rnn-t）は、オンデバイスとして期待できる可能性を示しています。追加のアーリーペナルティとレイトペナルティでmweモデルを拡張することにより、e2eモデルのレイテンシを削減することを提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-24">
        <br>2020-04-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Flowtron: an Autoregressive Flow-based Generative Network for
  Text-to-Speech Synthesis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/eess.AS/paper_1.html">
      Flowtron: an Autoregressive Flow-based Generative Network for
  Text-to-Speech Synthesis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      平均オピニオンスコア（MOS）は、Flowtronが音声品質の面で最新のTTSモデルと一致することを示しています。この論文では、Flowtron：制御付きテキスト音声合成用の自己回帰フローベースの生成ネットワークを提案します。 Flowtronは、音声のバリエーションとスタイルの転送を超えています。Flowtronは、音声合成の多くの側面（ピッチ、トーン、スピーチレート、ケイデンス、アクセント）を制御するために操作できる潜在空間へのデータの可逆マッピングを学習します。 
[ABSTRACT] flowgreはiafから洞察を借用し、高品質で表現力豊かなメルの予約注文に利用できるtacotron.itを改良しました-spectrovid
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Discriminative Multi-modality Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/eess.AS/paper_2.html">
      Discriminative Multi-modality Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、2段階の音声認識モデルを提案します。ビジョンは、音声ソロ認識（ASR）の補完モダリティとして、特にソロオーディオモダリティのパフォーマンスが大幅に低下するノイズの多い環境でよく使用されます。視覚モダリティを組み合わせた後、ASRはマルチモダリティ音声認識（MSR）にアップグレードされます。 
[要約]視覚モダリティを組み合わせた後、asrはマルチモダリティ音声認識（msr）にアップグレードされます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Mixture of Inference Networks for VAE-based Audio-visual Speech
  Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/eess.AS/paper_3.html">
      Mixture of Inference Networks for VAE-based Audio-visual Speech
  Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、音声強調中に、視覚データを使用して潜在変数が初期化されるため、ノイズの多い音声スペクトログラムを使用する場合よりも堅牢な初期化が提供されます。変分推論アプローチが提案されたVAEをトレーニングするために導出されます。スピーカーの唇の画像、提供スピーチに関する有用で補足的な情報。 
[要約]提案された音声-視覚的vaeモデルを使用して、潜在変数の事後を推測できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-23">
        <br>2019-12-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-14/eess.AS/paper_4.html">
      Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CycleGANネットワークを提案し、敵対的損失とサイクル整合性損失を使用してフォワードマッピングとインバースマッピングを同時に学習することにより、非並列トレーニングデータから最適な疑似ペアを見つけます。効果的なF0変換のために、異なる時間解像度での音声韻律を記述する時間スケール。F0は本質的に階層的であるイントネーションの重要な側面であるため、ウェーブレット変換を使用して異なる時間スケールでF0をモデル化する方が適切であると考えます。 。 
[ABSTRACT]多くの研究では、異なる線形パターン間の並列音声データが必要です。これらの研究では、イントネーションの重要な側面であるf0が必要です。ただし、ウェーブレット変換を使用してf0をモデル化する方が適切であると考えています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-01">
        <br>2020-02-01
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本日更新された論文はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br>
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
