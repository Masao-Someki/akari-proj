<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<title>Akari-2019-11-26の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
  <div class="header-logo">
    <a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
  </div>
</header>
<input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">

<div class="menubar">
<span class="bar"></span>
<span class="bar"></span>
<span class="bar"></span>
</div>

<ul>
<li><a id="home" href="../../index.html">Home</a></li>
<li><a id="about" href="../../teamAkariとは.html">About</a></li>
<li><a id="contact" href="../../contact.html">Contact</a></li>
<li><a id="contact" href="../../list/newest.html">New Papers</a></li>
<li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
</ul>

</label>
<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Unsupervised Feature Learning for Environmental Sound Classification
  Using Weighted Cycle-Consistent Generative Adversarial Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.SD/paper_0.html">
      Unsupervised Feature Learning for Environmental Sound Classification
  Using Weighted Cycle-Consistent Generative Adversarial Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      コードブックは、高速化された堅牢な特徴検出器（SURF）およびK-Means ++アルゴリズムを使用してDWTスペクトログラムをコーディングすることによって構築されます。オーディオ信号は、離散ウェーブレット変換（DWT）を使用して2D表現に変換されます。 4つのベンチマーク環境音データセット（ESC-10、ESC-50、UrbanSound8k、およびDCASE-2017）は、提案された分類手法が、スコープ内の最先端の分類器よりも優れていることを示しています。 AlexNetおよびGoogLeNetのように、データセットに応じて3.51％〜14.34％の分類率を改善します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-08">
        <br>2019-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Narrow-band Deep Filtering for Multichannel Speech Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.SD/paper_1.html">
      Narrow-band Deep Filtering for Multichannel Speech Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたディープフィルターは、異なる時間的および空間的特性を活用することで、音声とノイズを区別できます。音声は非定常で空間的にコヒーレントですが、ノイズは比較的静止しており、チャネル間で弱く相関しています。提案された方法は狭帯域と呼ばれます帯域ディープフィルタリング。この選択は、従来の広帯域音声強調方法とは対照的です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Robust Approach for Securing Audio Classification Against Adversarial
  Attacks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.SD/paper_2.html">
      A Robust Approach for Securing Audio Classification Against Adversarial
  Attacks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、オーディオ信号とその2D表現の両方に影響を与える可能性のあるいくつかの強力な攻撃を最初にレビューし、最も一般的な機械学習モデル、つまりディープラーニングモデルと2Dオーディオ表現でトレーニングされたサポートベクターマシン（SVM）の弾力性を評価しますいくつかの最新の敵対攻撃に対する短時間フーリエ変換（STFT）、離散ウェーブレット変換（DWT）、およびクロスリカレントプロット（CRP）。3つの環境音データセットに関する実験結果は、提案されたアプローチの競争力を示しています。強力な敵対攻撃に対する精度と堅牢性の両方の観点から、ディープニューラルネットワーク。これらのすべての手順は、精度と回復力の適切なトレードオフを提供するオーディオ分類の新しいアプローチになります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-24">
        <br>2019-04-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Invertible DNN-based nonlinear time-frequency transform for speech
  enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.SD/paper_3.html">
      Invertible DNN-based nonlinear time-frequency transform for speech
  enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、学習した変換には通常の信号処理に重要な特性がない場合があります。通常のDNNベースの音声強調では、TF変換、通常は短時間フーリエ変換〜（STFT）を使用し、DNNを使用してTFマスクを推定します。可逆深層ニューラルネットワーク〜（DNN）に基づく訓練可能な時間周波数〜（TF）変換を用いたエンドツーエンドの音声強調法を提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: VOICe: A Sound Event Detection Dataset For Generalizable Domain
  Adaptation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.SD/paper_4.html">
      VOICe: A Sound Event Detection Dataset For Generalizable Domain
  Adaptation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      VOICeはオンラインで無料で入手できます（https://doi.org/10.5281/zenodo.3514950）。.VOICeは、3つの異なるサウンドイベント（「赤ちゃんの泣き声」、「ガラスの破れ」、「銃声」）の混合物で構成されています。音響シーンの3つの異なるカテゴリ（車両、屋外、屋内）にオーバーインポーズ。さらに、敵対者に基づくトレーニング手法を使用して、VOICeのドメイン適応手法のパフォーマンスを評価します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-16">
        <br>2019-11-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Mixup-breakdown: a consistency training method for improving
  generalization of speech separation models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.SD/paper_5.html">
      Mixup-breakdown: a consistency training method for improving
  generalization of speech separation models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ラベルのない入力を「分解」する教師モデルを学習し、推定分離を補間して、より有用な疑似「ミックスアップ」入出力ペアを生成します。このペアでは、学生モデルの学習に整合性正規化を適用できます。結果は、MBT SI-SNRiの相対的な改善が最大13.77％で、いくつかの強力なベースラインを大幅に上回っています。この実験では、見えない干渉音声、ノイズ、音楽など、不一致の度合いが上昇するさまざまな条件下でMBTを評価し、MBTの一般化機能を状態と比較します最先端の教師付き学習およびSSLアプローチ。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-28">
        <br>2019-10-28
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Unsupervised Domain Adaptation of Language Models for Reading
  Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_0.html">
      Unsupervised Domain Adaptation of Language Models for Reading
  Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      UDARCタスクにより、モデルはソースドメインで教師付きRCトレーニングデータを使用し、ターゲットドメインでラベルなしパッセージのみを使用できます。モデルは、ドメイン適応なしでモデルよりも優れていました。 LMおよびRCの。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: hauWE: Hausa Words Embedding for Natural Language Processing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_1.html">
      hauWE: Hausa Words Embedding for Natural Language Processing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      hauWE CBoWの88.7％およびhauWE SGの79.3％の予測精度は、Bojanowski et al。を大きく上回りました。モデルを比較するために、ランダムに選択された30個のHausa単語と最も類似する10個の単語を予測するために使用されました..hauWE（Hausa Words Embedding） 、以前の唯一のモデルよりも大きくて優れており、NLPタスクでより便利になります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SWift -- A SignWriting improved fast transcriber -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_2.html">
      SWift -- A SignWriting improved fast transcriber
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SWiftは、ろうコミュニティを情報通信技術（ICT）から遠ざける「電子的」障壁を打破することを目的としています。ガイド付きの手順により、構成プロセスが容易になります.. SWift（SignWriting改善された高速転写）、高度なSignWriting（SW）を使用したコンピューター支援の書き込みおよび転写用のエディター。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Financial Event Extraction Using Wikipedia-Based Weak Supervision -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_3.html">
      Financial Event Extraction Using Wikipedia-Based Weak Supervision
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業はこの後者のアプローチに沿っており、関連するウィキペディアのセクションを活用して経済的出来事を説明する文章の弱いラベルを抽出します。トレーニングデータに記載されていない企業に関連する経済イベントを抽出するために使用できます。テキストからの金融イベントおよび経済イベントの抽出は、以前は主にルールベースの方法を使用して行われました。テクニック。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unlearn Dataset Bias in Natural Language Inference by Fitting the
  Residual -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_4.html">
      Unlearn Dataset Bias in Natural Language Inference by Fitting the
  Residual
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最初に、データセットバイアスに関連することが知られている機能のみを使用するバイアスモデルを学習します。バイアスされたモデルの残差に対して、バイアスされた特徴だけではうまく予測できない例に焦点を当てます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-28">
        <br>2019-08-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Conversational implicatures in English dialogue: Annotated dataset -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_5.html">
      Conversational implicatures in English dialogue: Annotated dataset
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの含意された意味は会話の含意です。.発言は含意で手動で注釈されます。.発言は、TOEFL（外国語としての英語のテスト）のような英語テストの聞き取りセクションから書き写すことによって収集されます。 IMSDb（インターネットムービースクリプトデータベース）で利用可能。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Women, politics and Twitter: Using machine learning to change the
  discourse -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_6.html">
      Women, politics and Twitter: Using machine learning to change the
  discourse
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、ParityBOTの影響の分析で、$ 2019 $アルバータ州選挙と$ 2019 $カナダ連邦選挙の両方で介入中に収集されたデータから引き出します。この論文の主な貢献は、定量的で憎悪なツイートを分類し対応するスケーラブルなモデルです質的評価..政治的意思決定に多様な意見を含めることにより、民主的な制度が強化されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Korean-to-Chinese Machine Translation using Chinese Character as Pivot
  Clue -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_7.html">
      Korean-to-Chinese Machine Translation using Chinese Character as Pivot
  Clue
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      韓国語から中国語への翻訳に関する実験結果は、提案された方法を使用したモデルが、ベースラインモデルと比較して最大1.5 BLEUポイントまで翻訳品質を改善することを示しています。語彙の点で多くの共通点があります。対応する中国語の文字に変換できる中韓語は、韓国語の語彙全体の50以上を占めています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Causal Inference Method for Reducing Gender Bias in Word Embedding
  Relations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_8.html">
      A Causal Inference Method for Reducing Gender Bias in Word Embedding
  Relations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの方法は、ジェンダーデバイアスタスク、語彙レベルおよび文レベルの評価タスク、およびダウンストリームの相互参照解決タスクに関する最新の結果を達成します。性別の方向に関連する性別の偏りを減らし、単語埋め込み関係で示される性別の偏りを減らすことができません。単語の埋め込みは、さまざまなタスクの経験的パフォーマンスを高めるため、自然言語処理に不可欠になっています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Real or Fake? Learning to Discriminate Machine from Human Generated Text -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_9.html">
      Real or Fake? Learning to Discriminate Machine from Human Generated Text
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、これらはテキストシーケンスのモデルに正常に適用されていません。そして、自己回帰モデルによって生成されたテキストから実際のテキストを区別するように訓練されています..エネルギーベースのモデル（EBM）、別名
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-07">
        <br>2019-06-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Discovering topics with neural topic models built from PLSA assumptions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_10.html">
      Discovering topics with neural topic models built from PLSA assumptions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、複雑さの測定基準を考慮すると、実施された評価ベンチマークは、トピックモデルがトピック検出タスクに対処するために古典的に使用される潜在ディリクレ割り当て（LDA）モデルよりも優れていることを示しています。本稿では、テキストコーパスでの教師なしトピック発見のモデルを提示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Corpus Wide Argument Mining -- a Working Solution -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_11.html">
      Corpus Wide Argument Mining -- a Working Solution
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ここでは、最初のエンドツーエンドの高精度、コーパス全体の引数マイニングシステムを紹介します。このスキームは、データの固有のラベルバイアスに対処し、高精度を得るために手動ラベル付けが必要なサンプル空間の領域を特定します。一流の候補者の間で。この一連の研究は中程度の成功をもたらしましたが、実際のシステムでは限られた用途しかありません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to Reuse Translations: Guiding Neural Machine Translation with
  Examples -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_12.html">
      Learning to Reuse Translations: Guiding Neural Machine Translation with
  Examples
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験により、ノイズマスクエンコーダーモデルにより、NMTは低ファジーマッチスコア（FMS）の例から有用な情報を学習できる一方で、補助デコーダーモデルは高FMSの例に適していることがわかります。機械翻訳（NMT）を使用して、ターゲット予測で同様の例の以前の翻訳を再利用します。2つのモデルを最新のTransformerで定義および実装します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards robust word embeddings for noisy texts -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_13.html">
      Towards robust word embeddings for noisy texts
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの新しい埋め込みは、標準的なテキストでの良好なパフォーマンスを維持しながら、幅広い評価タスクのノイズの多いテキストで最新のパフォーマンスよりも優れています。標準的なテキストでのパフォーマンスを維持しています。ソーシャルメディアからのツイートや他の種類の非標準的な文章の形式のノイズの多いテキストによってもたらされる困難を無視します。私たちの知る限り、これは単語埋め込みでこのタイプのノイズの多いテキストを扱う最初の明示的なアプローチです。語彙外の単語のサポートを超えるレベル。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: FLATM: A Fuzzy Logic Approach Topic Model for Medical Documents -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_14.html">
      FLATM: A Fuzzy Logic Approach Topic Model for Medical Documents
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果として、関連するドキュメントを見つけることはより困難になりました。ドキュメント分類とドキュメントモデリングを介して実行された評価指標は、モデルがLDAよりも優れたパフォーマンスを発揮することを示しています。 。モデルを評価するために、医療文書の2つのテキストデータセットを試します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Outbound Translation User Interface Ptakopet: A Pilot Study -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_15.html">
      Outbound Translation User Interface Ptakopet: A Pilot Study
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Ptakop \ v {e} tの助けを借りて、彼らが話さない言語（ドイツ語）で質問を作成することを目的とした（チェコ語）人間の注釈者の実験をフォローアップします。 3つの実世界のユースケース（ITサポートとのコミュニケーション、管理上の問題の説明、百科事典的な質問）に焦点を当て、アウトバウンド翻訳タスクに直面したときにユーザーが取るさまざまな戦略について洞察を得ます。 MTシステムを評価しますが、少なくとも中程度の品質のMTシステムでは、ユーザーにとって非常にうまく機能することが評価されています。インターネットユーザーが外国語でテキストを作成しなければならないことは珍しくありません。また、翻訳の品質を確認できません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The JDDC Corpus: A Large-Scale Multi-Turn Chinese Dialogue Dataset for
  E-commerce Customer Service -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_16.html">
      The JDDC Corpus: A Large-Scale Multi-Turn Chinese Dialogue Dataset for
  E-commerce Customer Service
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このデータセットは、人間同士の会話のいくつかの特性、例えば、コンテキスト間の目標駆動型および長期依存を反映しています。そして、JDDCが効果的なテストベッドとして機能し、対話タスクの基礎研究の発展に役立つことを願っています。意図情報と3つの十分に注釈が付けられたチャレンジセットも提供されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-22">
        <br>2019-11-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Habitat: A Platform for Embodied AI Research -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_17.html">
      Habitat: A Platform for Embodied AI Research
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、Habitatの構成は次のとおりです。（i）Habitat-Sim：構成可能なエージェント、センサー、および汎用3Dデータセット処理を備えた柔軟で高性能な3Dシミュレーター。Habitat-Simは高速です。Matterport3Dからシーンをレンダリングするとき、毎秒数千フレーム（fps）でシングルスレッドを実行し、1つのGPUで10,000 fpsを超えるマルチプロセスに達することができます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-02">
        <br>2019-04-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning by Abstraction: The Neural State Machine -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_18.html">
      Learning by Abstraction: The Neural State Machine
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      VQA-CPとGQAのモデルを評価します。2つの最近のVQAデータセットで、構成性、多段階推論、多様な推論スキルを含み、両方のケースで最先端の結果を達成します。モデルを説明するさらなる実験を提供します。概念の新規構成、回答分布の変化、見えない言語構造など、複数の次元にわたる強力な一般化能力。アプローチの質と有効性を実証します。生の感覚と密接に相互作用するように設計されたほとんどのニューラルアーキテクチャとは対照的データの代わりに、視覚的および言語的モダリティの両方をセマンティックコンセプトベースの表現に変換することにより、モデルは抽象的な潜在空間で動作し、それにより透明性とモジュール性の向上を実現します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-09">
        <br>2019-07-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Filling Conversation Ellipsis for Better Social Dialog Understanding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_19.html">
      Filling Conversation Ellipsis for Better Social Dialog Understanding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      省略記号の現象は、社会的な会話でよく見られます。具体的には、エンドツーエンドポインターネットワークモデルを使用して省略記号を解決するために、ユーザーの発話を最初に完了します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Non-autoregressive Transformer by Position Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_20.html">
      Non-autoregressive Transformer by Position Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、PNATが機械翻訳および言い換え生成タスクで最高の結果を達成し、いくつかの強力なベースラインを上回ることを示しています。この研究では、潜在的な変数として位置をテキスト生成プロセスに組み込むPNATを提案します。生成された単語の位置をモデル化します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CAIL2019-SCM: A Dataset of Similar Case Matching in Legal Domain -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_21.html">
      CAIL2019-SCM: A Dataset of Similar Case Matching in Legal Domain
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CAIL2019-SCMは類似のケースの検出に焦点を当てており、参加者はトリプレットで2つのケースがより類似していることを確認する必要があります。研究者がこのタスクをよりよく理解できるように、いくつかのベースラインも実装しています.CAIL2019-SCMには8,964のトリプレットが含まれています中国最高人民法院が発行しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: End-to-End Trainable Non-Collaborative Dialog System -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_22.html">
      End-to-End Trainable Non-Collaborative Dialog System
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのモデルは、生成プロセスを導く中間文表現としてインテントとセマンティックスロットを利用します。エンドツーエンドのタスク指向ダイアログモデルは、ユーザーがシステムと協調して所定のタスクを完了する協調タスクで有望なパフォーマンスを達成しました。 2019）、多様なコヒーレント応答を生成するためのエンドツーエンドのニューラルネットワークモデルを提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Chinese Spelling Error Detection Using a Fusion Lattice LSTM -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_23.html">
      Chinese Spelling Error Detection Using a Fusion Lattice LSTM
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      既存の方法に加えて、文字または単語の情報のみを採用し、文字、単語、pinyin1情報を融合することのプラスの効果を無視します。 -fusion入力..このモデルは、エンドツーエンドのフレームワークを利用してプロセス全体としてエラーを検出し、文字、単語、およびピンイン情報を動的に統合します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Who did They Respond to? Conversation Structure Modeling using Masked
  Hierarchical Transformer -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_24.html">
      Who did They Respond to? Conversation Structure Modeling using Masked
  Hierarchical Transformer
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、Redditプラットフォームからの新しい大規模なコーパスの実験も報告し、このデータセットをリリースします。 、祖先の流れを導く新しいマスキングメカニズムを設計し、トランスフォーマモデルを活用してすべての祖先を集約し、親の発話を予測します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: JParaCrawl: A Large Scale Web-Based English-Japanese Parallel Corpus -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/cs.CL/paper_25.html">
      JParaCrawl: A Large Scale Web-Based English-Japanese Parallel Corpus
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      事前トレーニングと微調整のアプローチは、初期状態からモデルトレーニングを上回るか、同等のパフォーマンスを達成し、トレーニングコストを大幅に削減しました。JParaCrawlと呼ばれる収集されたコーパスは、870万文のペアを蓄積しました。トレーニング済みのモデルは、研究目的でオンラインで無料で入手できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Sound event detection via dilated convolutional recurrent neural
  networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/eess.AS/paper_0.html">
      Sound event detection via dilated convolutional recurrent neural
  networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ベースラインCRNNの分類子と比較して、拡張CRNNの分類子は、F1スコアで最大1.9％、6.3％、2.5％の増加、エラー率（ER）で最大1.7％、4.1％、3.9％の減少を取得します。 、TUT-SED Synthetic 2016、TUT Sound Event 2016、TUT Sound Event 2017の公的に利用可能なオーディオコーパスそれぞれについて。CRNNに拡張された受容フィールドを提供する拡張操作の有効性を調査し、長い時間のコンテキストをキャプチャしますCRNNのパラメーターの量を増やすことなく..畳み込みリカレントニューラルネットワーク（CRNN）は、サウンドイベント検出（SED）の最先端のパフォーマンスを達成しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Feature Learning for Environmental Sound Classification
  Using Weighted Cycle-Consistent Generative Adversarial Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/eess.AS/paper_1.html">
      Unsupervised Feature Learning for Environmental Sound Classification
  Using Weighted Cycle-Consistent Generative Adversarial Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      コードブックは、高速化された堅牢な特徴検出器（SURF）とK-Means ++アルゴリズムを使用してDWTスペクトログラムをコーディングすることによって構築されます。4つのベンチマーク環境サウンドデータセット（ESC-10、ESC-50、UrbanSound8k、およびDCASE- 2017）は、提案された分類アプローチが、AlexNetやGoogLeNetなどの高度で密な畳み込みニューラルネットワークを含む、スコープ内の最先端の分類器よりも優れていることを示し、3.51％から14.34％の間で分類率を改善しました。データセット..オーディオ信号は、離散ウェーブレット変換（DWT）を使用して2D表現に変換されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-08">
        <br>2019-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Narrow-band Deep Filtering for Multichannel Speech Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/eess.AS/paper_2.html">
      Narrow-band Deep Filtering for Multichannel Speech Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されているディープフィルターは、異なる時間的および空間的特性を活用することにより、音声とノイズを区別できます。音声は非定常で空間的にコヒーレントですが、ノイズは比較的静止しており、チャネル間で弱い相関があります。この選択は、従来のワイドとは対照的です提案されたモデルの顕著な特徴は、同一のパラメータを持つ同じLSTMアーキテクチャが周波数ビン全体でトレーニングされることです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Robust Approach for Securing Audio Classification Against Adversarial
  Attacks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/eess.AS/paper_3.html">
      A Robust Approach for Securing Audio Classification Against Adversarial
  Attacks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、オーディオ信号とその2D表現の両方に影響を与える可能性のあるいくつかの強力な攻撃を最初にレビューし、最も一般的な機械学習モデル、つまりディープラーニングモデルと2Dオーディオ表現でトレーニングされたサポートベクターマシン（SVM）の弾力性を評価しますいくつかの最新の敵対攻撃に対する短時間フーリエ変換（STFT）、離散ウェーブレット変換（DWT）、およびクロスリカレントプロット（CRP）。3つの環境音データセットに関する実験結果は、提案されたアプローチの競争力を示しています。次に、強力な敵対攻撃に対する精度と堅牢性の両方の観点から、ディープニューラルネットワークについて説明します。次に、オーディオ信号の前処理済みDWT表現とSVMに基づいて敵対攻撃からオーディオシステムを保護する新しいアプローチを提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-24">
        <br>2019-04-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Invertible DNN-based nonlinear time-frequency transform for speech
  enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/eess.AS/paper_4.html">
      Invertible DNN-based nonlinear time-frequency transform for speech
  enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      しかし、学習された変換は通常の信号処理に重要な特性を持たない可能性があります。可逆非線形TF変換はDNNによって構築され、得られた変換がフィルターバンクを完全に再構築するようにデータから学習されます。可逆深層ニューラルネットワーク〜（DNN）に基づく訓練可能な時間周波数〜（TF）変換による強化方法。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: VOICe: A Sound Event Detection Dataset For Generalizable Domain
  Adaptation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/eess.AS/paper_5.html">
      VOICe: A Sound Event Detection Dataset For Generalizable Domain
  Adaptation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      VOICeは、3つの異なるサウンドイベント（「赤ちゃんの泣き声」、「ガラス破壊」、「銃声」）の混合物で構成され、車両、屋外、屋内の3つの異なるカテゴリの音響シーンに過度に課されます。オンラインで入手できます（https://doi.org/10.5281/zenodo.3514950）。さらに、敵対者ベースのトレーニング方法を使用して、VOICeでのドメイン適応方法のパフォーマンスを評価します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-16">
        <br>2019-11-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Mixup-breakdown: a consistency training method for improving
  generalization of speech separation models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/eess.AS/paper_6.html">
      Mixup-breakdown: a consistency training method for improving
  generalization of speech separation models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は、MBTがいくつかの強力なベースラインを大幅に上回っており、相対的なSI-SNRiの改善が最大で13.77％であることを示しています。一貫性の正則化が学生モデルの学習に適用できる出力ペア。この実験では、目に見えない干渉音声、ノイズ、音楽など、ミスマッチの昇順でさまざまな条件下でMBTを評価し、MBTの一般化機能を状態と比較します。最先端の教師あり学習およびSSLアプローチ。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-28">
        <br>2019-10-28
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Agrin promotes coordinated therapeutic processes leading to improved cardiac repair in pigs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/biorxiv.physiology/paper_0.html">
      Agrin promotes coordinated therapeutic processes leading to improved cardiac repair in pigs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最初に、梗塞を起こしたブタ心臓への組換えヒトアグリン（rhAgrin）の局所（順行）送達が、効率的かつ臨床的に関連する方法で患部を標的にできることを実証します。 ）タンパク質アグリンは、成体マウスのMI後の心臓再生を促進します。rhAgrinの単回投与は、MIの28日後に、心機能、梗塞サイズ、線維症、および有害なリモデリングパラメータの有意な改善をもたらしました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Differences in in vitro responses of the hypothalamo-pituitary-gonadal hormonal axis between low and high egg producing turkey hens -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/biorxiv.physiology/paper_1.html">
      Differences in in vitro responses of the hypothalamo-pituitary-gonadal hormonal axis between low and high egg producing turkey hens
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      LEPHおよびHEPHの脳下垂体および卵胞細胞は、HPG軸を刺激または阻害するためにin vitroホルモン処理を受け、続いてHPG軸遺伝子のmRNAレベルの発現分析およびステロイドホルモン産生のラジオイムノアッセイが行われました。下垂体細胞での遺伝子発現および卵胞細胞でのステロイドホルモン産生。HEPHは刺激に対してより大きな正の反応を示します。HEPHの下垂体細胞は排卵刺激に関連する遺伝子の上方制御を示し、LEPH細胞は遺伝子の上方制御を示しました排卵の抑制と関連付けられる。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Tuning of feedforward control enables stable muscle force length dynamics after loss of autogenic proprioceptive feedback -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-26/biorxiv.physiology/paper_2.html">
      Tuning of feedforward control enables stable muscle force length dynamics after loss of autogenic proprioceptive feedback
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      再神経支配および無傷の筋肉は、同様の力長ダイナミクスを示し、ランニング障害物の地形を安定させるために作業が急速に変化します。鳥の足首の運動学および生体内の筋肉ダイナミクスを、再神経支配のLGおよび無傷のLGと比較しました。失われた固有受容を補償するための活性化段階のフィードフォワード調整と一致する活性化。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br>2019-11-25
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
