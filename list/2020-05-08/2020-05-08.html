<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-05-08の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Improved RawNet with Feature Map Scaling for Text-independent Speaker
  Verification using Raw Waveforms -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.SD/paper_0.html">
      Improved RawNet with Feature Map Scaling for Text-independent Speaker
  Verification using Raw Waveforms
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      スケールベクトルを使用して、特徴マップを乗法的、加算的、またはその両方でスケーリングすることを提案します。VoxCeleb1-EおよびVoxCeleb-Hプロトコルを使用して得られた拡張評価結果は、既存の最先端システムをわずかに上回っています。 VoxCeleb1評価データセットは、提案された方法の有効性を示しており、最高のパフォーマンスを発揮するシステムは、元のRawNetと比較して同等のエラー率を半分に減らします。 
[要約]提案されたシステムは、シグモイド非線形関数を採用したスケールセンサーを使用します。これは、フィーチャマップを乗法的に、加法的に、またはその両方をスケーリングするために使用できます。最高のパフォーマンスのシステムは、元のローネットと比較して同等のエラー率を半分に減らします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-01">
        <br>2020-04-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: When Hearing Defers to Touch -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.SD/paper_1.html">
      When Hearing Defers to Touch
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この主張は、弱い刺激に対する感度の比較に基づいています。特に、タッチは、小さい低速のオブジェクトの検出において、聴覚よりも効果的であることがわかります。結果は、弱い刺激を検出するタッチと聴覚の能力は、感知されたオブジェクトのサイズだけでなく、その振動の周波数にも。 
[ABSTRACT]この主張は、触覚と弱い刺激の比較に基づいています。触覚は、小さくて遅い物体の検出において、聴覚よりも効果的であることがわかります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ContextNet: Improving Convolutional Neural Networks for Automatic Speech
  Recognition with Global Context -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.SD/paper_2.html">
      ContextNet: Improving Convolutional Neural Networks for Automatic Speech
  Recognition with Global Context
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      広く使用されているLibriSpeechベンチマークで、ContextNetが外部言語モデル（LM）なしで2.1 \％/ 4.6 \％、LM付きで1.9 \％/ 4.1 \％、2.9 \％/ 7.0の単語誤り率（WER）を達成することを示します\％クリーン/ノイズの多いLibriSpeechテストセットでパラメーターが10Mのみの場合。これは、以前に公開された2.0 \％/ 4.6 \％とLM、3.9 \％/ 11.3 \％と20Mのパラメーターの比較です。提案されたContextNetモデルは、はるかに大きな内部データセットでも検証されます。 
[ABSTRACT]新しい論文では、このギャップを埋め、新しいcnn-rnn-トランスデューサアーキテクチャでそれを超える方法を研究しています。さらに、コンテキストネットの幅をスケーリングするシンプルなスケーリング方法を提案し、優れたトレードオフを実現しています。計算と精度
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Crop Aggregating for short utterances speaker verification using raw
  waveforms -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.SD/paper_3.html">
      Crop Aggregating for short utterances speaker verification using raw
  waveforms
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案手法は、入力発話をいくつかの短い発話に分割し、セグメント化された入力から抽出されたセグメント埋め込みを集約して話者埋め込みを構成します。この論文では、短い発話に対する話者検証の性能劣化を補償する方法を提案します。 「作物集約」と呼ばれます。話者検証システムに関するほとんどの研究は、十分な音声情報で構成される長時間の発話に焦点を当てています。 
[ABSTRACT]短い時間の発話は、音声情報がないために劣化することが知られています。これは、長い発話と比較して発音情報がないためです。提案された方法は、アンサンブルベースの設計を使用して、安定性と精度を改善しています話者認証システムの
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Continuous speech separation: dataset and analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.SD/paper_4.html">
      Continuous speech separation: dataset and analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは、テストされたアルゴリズムの実際の関連性を評価することを困難にするだけでなく、実際のシナリオに容易に適用できるシステムの開発を妨げることになると私たちは考えています。このデータセットを使用することにより、最近提案されたスピーカー独立したCSSアルゴリズムが調査されます。この方向での研究を促進するために、データセットと評価スクリプトが利用可能です。 
[ABSTRACT]アルゴリズムは、信号対歪み比または同様のパフォーマンスメトリックに基づいて評価されます。さらに、信号ベースのメトリックは、自動音声認識（asr）精度と非常に弱い相関を持っています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br>2020-01-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The Perceptimatic English Benchmark for Speech Perception Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.SD/paper_5.html">
      The Perceptimatic English Benchmark for Speech Perception Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      電話の弁別がいくつかのタイプのモデルと相関していることを示し、実験的刺激で音響距離の簡単に計算できる基準を求める研究者に推奨を与えます。標準の英語音声認識装置であるDeepSpeechは、英語よりも英語の音素弁別に特化していることを示します。人間に与えられた決定タスクでのエラーが低くても、リスナーとその行動との相関は不十分です。これらは、読み上げコーパスから直接抽出され、統計音響モデル（で使用されるものなど）の評価に適しています。自動音声認識）は、典型的な音声データセットでトレーニングされています。 
[ABSTRACT]ベンチマークは、abx刺激と91人のアメリカ英語-話すリスナーの応答で構成されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Cotatron: Transcription-Guided Speech Encoder for Any-to-Many Voice
  Conversion without Parallel Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.SD/paper_6.html">
      Cotatron: Transcription-Guided Speech Encoder for Any-to-Many Voice
  Conversion without Parallel Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      当社のシステムは、トレーニング中に見えないスピーカーからの音声を変換し、ASRを利用して、最小限のパフォーマンスの低下で転写を自動化することもできます。音声変換システムをトレーニングして、Cotatron機能で音声を再構築します。 Phonetic Posteriorgram（PPG）について。.CotatronはマルチスピーカーTTSアーキテクチャに基づいており、従来のTTSデータセットでトレーニングできます。 
[要旨] cotatronはマルチスピーカーttsアーキテクチャに基づいています。従来のttsデータセットでトレーニングできます。事前トレーニング済みモデルのコードは間もなく利用可能になります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: JASS: Japanese-specific Sequence to Sequence Pre-training for Neural
  Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_0.html">
      JASS: Japanese-specific Sequence to Sequence Pre-training for Neural
  Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      JASSは、BMSSS（文節MASS）とBRSS（文節リオーダリングシーケンストゥシーケンス）の事前トレーニングであり、bunsetsusと呼ばれる日本語の言語単位に焦点を当てています。 JASSは、MASSによって提供される結果よりも優れていなくても競争力のある結果を提供できます。このために、日本語をソースとするNMTのMASSの新しい事前トレーニングの代替として、JASS、日本固有のシーケンス間を提案します。目標とする言語。 
[ABSTRACT]低シーケンスcbtは通常、転移学習によって対処されます。構文アナライザを使用して取得された言語情報は考慮されません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Where is Linked Data in Question Answering over Linked Data? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_1.html">
      Where is Linked Data in Question Answering over Linked Data?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この目的のために、セマンティックWebの利点を活用してAI完全な質問応答を実現するための新しい評価設定の作成を提案します。「ナレッジベースによる質問応答」と「リンクされたデータに対する質問応答」は現在2つあると主張します。 Linked Dataへの対処を明示的に宣言しているにもかかわらず、同じ問題のインスタンスがあります。クラウドの他の部分への外部リンクを悪用したり、共通のスキーマを共有したりするデータセットに対する質問応答を評価する既存の方法がないことを指摘します。 
[要旨]質問応答を評価するための既存の方法がないことを指摘します。何が起こったのかを知ることができないはずです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The Sensitivity of Language Models and Humans to Winograd Schema
  Perturbations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_2.html">
      The Sensitivity of Language Models and Humans to Winograd Schema
  Perturbations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、大規模なタスク固有のデータセットを微調整することで、これらの問題の解決策が得られることを示します。大規模な事前トレーニング済み言語モデルは、広く採用されているWinograd Schema Challengeの最近のパフォーマンス改善の主な原動力です常識推論能力のテスト..私たちの結果は、人間と言語モデルの興味深い違いを強調しています。言語モデルは、人間よりも数字や性別の変化や同義語の置換に対して敏感であり、人間は予測においてより安定していて一貫性があり、はるかに高い絶対的なパフォーマンス、および関連性のあるインスタンスよりも関連性のないインスタンスでパフォーマンスが向上します。 
[ABSTRACT]新しい診断データセットは、人間がより頻繁に正しいことを示しています。モデルは、人間の理解に最小限の影響を与えるウィノグラードの例の言語的摂動に敏感です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-04">
        <br>2020-05-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Measuring Social Bias in Knowledge Graph Embeddings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_3.html">
      Measuring Social Bias in Knowledge Graph Embeddings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      グラフの埋め込みがますます利用されるようになると、そのようなバイアスの存在を理解し、その影響を軽減するための措置を講じることが重要であることをお勧めします。たとえば、グラフの埋め込みは、男性は銀行家であり、女性は女性である可能性が高いという情報をエンコードします私たちは、知識グラフの埋め込みにおける社会的バイアスに関する最初の研究を提示し、そのようなバイアスを測定するのに適した新しいメトリックを提案します。 
[ABSTRACT] wikidataとfreebaseはwikidataとfreebeddingで実験を行いました。単語の埋め込みと同様に、職業に関連する有害な社会的偏見は、性別、宗教、民族性、国籍に関して埋め込みにエンコードされています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-05">
        <br>2019-12-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improved RawNet with Feature Map Scaling for Text-independent Speaker
  Verification using Raw Waveforms -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_4.html">
      Improved RawNet with Feature Map Scaling for Text-independent Speaker
  Verification using Raw Waveforms
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      VoxCeleb1-EおよびVoxCeleb-Hプロトコルを使用して得られた拡張評価結果は、既存の最先端システムをわずかに上回っています。スケールベクトルを使用して、特徴マップを乗法的、加算的、またはその両方でスケーリングすることを提案します。この研究では、さまざまな方法を使用して機能マップをスケーリングすることにより、RawNetを改善しています。 
[要約]提案されたシステムは、シグモイド非線形関数を採用したスケールセンサーを使用します。これは、フィーチャマップを乗法的に、加法的に、またはその両方をスケーリングするために使用できます。最高のパフォーマンスのシステムは、元のローネットと比較して同等のエラー率を半分に減らします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-01">
        <br>2020-04-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: YANG2UML: Bijective Transformation and Simplification of YANG to UML -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_5.html">
      YANG2UML: Bijective Transformation and Simplification of YANG to UML
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このプロセスをサポートするために、このホワイトペーパーでは、YANGデータモデルを最適化および簡略化して、管理と実装（特にインターフェイスの実装）に関する複雑さを軽減するための新しいアプローチを紹介します。NETCONFと組み合わせて、YANGは、は、実質的にすべてのネットワーク構成プロトコルをサポートする関連データ構造を定義します。YANG自体は意味的に豊富な言語であり、関連する主題に慣れるために、他の専門家や開発者を巻き込んでサポートするために視覚化されることがよくあります。毎日の仕事（YANGを利用するアプリケーションの作成）。 
[ABSTRACT]陽自体は意味的に豊富な言語です。他の専門家、開発者を巻き込み、彼らの仕事によってそれらをサポートするために視覚化されることがよくあります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Domain Adaptation on Reading Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_6.html">
      Unsupervised Domain Adaptation on Reading Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、私たちのアプローチは、ソースデータセットで微調整されたBERTモデルを信頼フィルタリングとともに活用して、セルフトレーニング用のターゲットドメインで信頼できる疑似ラベル付きサンプルを生成します。これを解決するために、新しい条件付き敵対セルフトレーニングを提供します。方法（CASe）。一方、ドメイン間の条件付き敵対学習によって、ドメインの分布の不一致をさらに減らします。 
[ABSTRACT]最初に、強力なbertコンテキスト表現を使用しても、パフォーマンスがまだ不十分であることを示します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br>2019-11-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On Exposure Bias, Hallucination and Domain Shift in Neural Machine
  Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_7.html">
      On Exposure Bias, Hallucination and Domain Shift in Neural Machine
  Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの結果は、露出バイアスを減らす方法に新しい正当性を提供します。ドメイン内テストセットのパフォーマンスを向上させなくても、ドメインシフトに対するモデルの堅牢性を向上させることができます。また、露出バイアスをビーム検索問題に関連付けます。この論文では、曝露バイアスをNMTの別のよく知られた問題、つまりドメインシフトの下で幻覚を生成する傾向に関連付けます。 
[要約]研究は、曝露バイアスが幻覚を部分的に非難していることを示しています。最小限のリスクのトレーニングでトレーニングすると、これを緩和できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ContextNet: Improving Convolutional Neural Networks for Automatic Speech
  Recognition with Global Context -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_8.html">
      ContextNet: Improving Convolutional Neural Networks for Automatic Speech
  Recognition with Global Context
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      広く使用されているLibriSpeechベンチマークで、ContextNetが外部言語モデル（LM）なしで2.1 \％/ 4.6 \％、LM付きで1.9 \％/ 4.1 \％、2.9 \％/ 7.0の単語誤り率（WER）を達成することを示します\％クリーン/ノイズの多いLibriSpeechテストセットで10Mのパラメーターのみを使用します。提案されたContextNetモデルの優位性は、より大きな内部データセットでも検証されます。ContextNetは、グローバルコンテキスト情報を畳み込みレイヤーに組み込む完全畳み込みエンコーダーを備えています。圧迫と興奮のモジュール。 
[ABSTRACT]新しい論文では、このギャップを埋め、新しいcnn-rnn-トランスデューサアーキテクチャでそれを超える方法を研究しています。さらに、コンテキストネットの幅をスケーリングするシンプルなスケーリング方法を提案し、優れたトレードオフを実現しています。計算と精度
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Nakdan: Professional Hebrew Diacritizer -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_9.html">
      Nakdan: Professional Hebrew Diacritizer
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このシステムは、最先端のダイアクリタイズの精度を提供するだけでなく、自動出力の手動編集および修正のためのインターフェースもサポートしており、ヘブライ語テキストの科学版の準備に特に役立ついくつかの機能を備えています。すべてhttp://nakdanpro.dicta.org.il。で使用します。このシステムは、モダンヘブライ語、ラビニックヘブライ語、詩的ヘブライ語をサポートしています。 
[ABSTRACT]システムは、現代のヘブライ語、ラビのヘブライ語、創造的なテキストをサポートしています。システムは、辞書をサポートしています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning Robust Models for e-Commerce Product Search -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_10.html">
      Learning Robust Models for e-Commerce Product Search
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実際のサンプルと生成されたサンプルを交互に使用するクロスエントロピー損失に潜在変数を導入することにより、モデルをエンドツーエンドでトレーニングします。問題を軽減するには、ラベル付きの大規模なデータセットが必要であり、取得に費用と時間がかかります。 。ライブ検索トラフィックでは、私たちのモデルは複数の国で大幅に改善されています。 
[ABSTRACT]ミスマッチを効果的に分類することを学習する、深いエンドツーエンドモデルを開発します。このモデルは、ハードミスマッチの例を作成して分類子を改善します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: 2kenize: Tying Subword Sequences for Chinese Script Conversion -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_11.html">
      2kenize: Tying Subword Sequences for Chinese Script Conversion
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案された方法は、以前の漢字変換アプローチを6ポイントの精度で上回っています。エラー分析により、この方法の特定の強みは、コード混合および名前付きエンティティの処理にあることがわかりました。簡体字中国語から繁体字中国語への文字変換は、中国のNLP。 
[ABSTRACT]中国語モデルは、サブワードセグメンテーション、2つの言語モデル、およびサブワードシーケンス間の変換方法に基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Adaptive Dialog Policy Learning with Hindsight and User Modeling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_12.html">
      Adaptive Dialog Policy Learning with Hindsight and User Modeling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ダイアログポリシーの学習の効率を向上させることを目的として、シミュレーションLHUA（Hindsight、ユーザーモデリング、および適応による学習）を開発しました。これにより、ダイアログエージェントは、シミュレーションユーザーと実際のユーザーの両方から後知恵で適応的に学習できるようになります。シミュレーションと後知恵は、対話エージェントにそれぞれより多くの経験とより多くの（肯定的な）強化を提供します。実験結果は、成功率と政策の質において、LHUAがシミュレーションなし、適応なし、および後知恵の対応。 
[ABSTRACT]効率の集中の使用は後知恵の後知恵です。これは、ネットワークが初めて改善できたときに提供します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Does Multi-Encoder Help? A Case Study on Context-Aware Neural Machine
  Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_13.html">
      Does Multi-Encoder Help? A Case Study on Context-Aware Neural Machine
  Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのエンコーダーのトレーニングにノイズおよび/またはよく調整されたドロップアウトのセットアップを導入するいくつかの方法を比較します。また、ノイズの生成とドロップアウトを注意深く使用することにより、IWSLT Fr-Enタスクに新しい最先端の技術を確立しますメソッド驚くべきことに、コンテキストエンコーダーは周囲の文をエンコードするだけでなく、ノイズジェネレーターとしても動作します。 
[ABSTRACT]これにより、マルチエンコーダではない本当のメリット-コンテキスト内のエンコーダ-認識翻訳を再考できます。一部の改善は、堅牢なトレーニングからもたらされます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Tale of Two Perplexities: Sensitivity of Neural Language Models to
  Lexical Retrieval Deficits in Dementia of the Alzheimer's Type -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_14.html">
      A Tale of Two Perplexities: Sensitivity of Neural Language Models to
  Lexical Retrieval Deficits in Dementia of the Alzheimer's Type
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、このアプローチが効果的である理由についてはほとんど知られていないため、最も広く使用されている筆記録の評価セット（DementiaBank）でケース/コントロールのマッチングが欠如しているため、これらのアプローチが本当に診断的であるか、敏感であるかは不明です他の変数に..近年、認知症の患者によって生成された誘発された音声サンプルと健康なコントロールからのそれらを区別するための計算方法の使用への関心が高まっています。字句頻度に関連付けられ、制御と認知症のLMの補間から生じる混合モデルは、トランスクリプトテキストのみでトレーニングされたモデルの現在の最先端技術を改善します。 
[要旨]目に見えない筆記録の診断分類のための単一の機能が、最先端のパフォーマンスを生み出すことが示されています。これらの筆記録を使用して、語彙の頻度を操作することにより、進行性の意味的痴呆をシミュレートしました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The Cascade Transformer: an Application for Efficient Answer Sentence
  Selection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_15.html">
      The Cascade Transformer: an Application for Efficient Answer Sentence
  Selection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最新のトランスフォーマーモデルと比較すると、2つの英語の質問応答データセットで測定されるように、私たちのアプローチは精度にほとんど影響を与えずに計算を37％削減します。推論中のバッチスループットを改善する手法にはほとんど注意が払われていません。各ランカーは、バッチ内の候補のサブセットをプルーニングするために使用されるため、推論時のスループットが劇的に向上します。 
[ABSTRACT] transformerは、モデルをランカーのカスケードに適合させるためのシンプルで効果的な手法です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning Implicit Text Generation via Feature Matching -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_16.html">
      Learning Implicit Text Generation via Feature Matching
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの実験結果は、英語の3つの異なる生成タスク（無条件テキスト生成、クラス条件付きテキスト生成、および教師なしテキストスタイル転送）に対する提案されたメソッドSeqGFMNの有効性を示しています。生成とテキストスタイルの転送。生成的特徴マッチングネットワーク（GFMN）は、事前トレーニング済みのニューラルネットワークからの特徴に対してモーメントマッチングを実行することにより、画像の暗黙的な生成的モデルをトレーニングするためのアプローチです。 
[ABSTRACT] seqgfmnは安定しており、テキスト生成とテキストスタイル転送のためのさまざまな敵対的アプローチをトレーニングし、優れたパフォーマンスを発揮します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The Perceptimatic English Benchmark for Speech Perception Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_17.html">
      The Perceptimatic English Benchmark for Speech Perception Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      電話の弁別がいくつかのタイプのモデルと相関していることを示し、実験的刺激に対する音響距離の標準を簡単に計算することを求める研究者に推奨事項を提供します。多数の英語とフランス語の音素コントラストの刺激テスト弁別。ベンチマークは、 ABX刺激と、91人のアメリカ英語を話すリスナーの応答。 
[ABSTRACT]ベンチマークは、abx刺激と91人のアメリカ英語-話すリスナーの応答で構成されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Global Locality in Biomedical Relation and Event Extraction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_18.html">
      Global Locality in Biomedical Relation and Event Extraction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      テキスト内のすべての言及ペア間の関係を同時に予測するために、関係とイベント抽出の両方へのアプローチを提案します。最も優れたモデルには、マルチヘッド注意と畳み込みのセットが含まれます。関連する要素間の依存関係を強化する機能に注目し、複数の注意ヘッドによって抽出された機能間の相互作用をモデル化します。 BioCreative 2017の共有タスク。 
[ABSTRACT]調査によると、私たちのアプローチは、bionlp 2009、2011、2013およびbiocreative 2017の最新技術を上回っています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-11">
        <br>2019-09-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Cross-Lingual Semantic Role Labeling with High-Quality Translated
  Training Corpus -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_19.html">
      Cross-Lingual Semantic Role Labeling with High-Quality Translated
  Training Corpus
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Universal Proposition Bankの実験結果は、翻訳ベースの方法が非常に効果的であり、自動疑似データセットがターゲット言語のSRLパフォーマンスを大幅に改善できることを示しています。このホワイトペーパーでは、コーパス翻訳に基づいて、ソースのゴールドスタンダードSRLアノテーションからのターゲット言語の品質トレーニングデータセット。研究の多くの取り組みは、自然言語の理解に重要な意味的役割ラベル（SRL）に費やされています。 
[要約]普遍的な命題は、問題に対処するための1つの有望な方法です。モデルの転送と注釈の投影の助けを借りて、大きな進歩を達成しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-14">
        <br>2020-04-14
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Self-Attention with Cross-Lingual Position Representation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_20.html">
      Self-Attention with Cross-Lingual Position Representation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      WMT&#39;14 English $ \ Rightarrow $ German、WAT&#39;17 Japanese $ \ Rightarrow $ English、およびWMT&#39;17 Chinese $ \ Leftrightarrow $ English翻訳タスクの実験結果は、私たちのアプローチが強いベースラインよりも翻訳品質を大幅かつ一貫して向上させることを示しています。機械翻訳では、ソースとターゲットの文のPEは個別にモデル化されます。広範な分析により、パフォーマンスの向上はクロスリンガル情報から得られることが確認されています。 
[ABSTRACT]これは、異なる言語での語順の相違が原因です。これは、sansがバイリンガルウェッジを学ぶことを奨励するテキストメッセージに基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Quda: Natural Language Queries for Visual Data Analytics -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_21.html">
      Quda: Natural Language Queries for Visual Data Analytics
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      V-NLIが自由形式の自然言語を理解できるように、Qudaと呼ばれる新しいデータセットを提示します。自由形式のユーザークエリに対して効果的な設計決定を行うプロトタイプを作成することにより、V-NLIの構築におけるQudaの有用性を示します。私たちのデータセットには、複雑な人間の言語を解析するための最先端の技術の導入を支援する10の低レベル分析タスクで注釈が付けられた14; 035の多様なユーザークエリが含まれています。 
[ABSTRACT] qudaは、学術出版物に記載されている設計タスクを分析することにより、視覚化コミュニティのさまざまなアプリケーションに有益です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The Danish Gigaword Project -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_22.html">
      The Danish Gigaword Project
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーでは、デンマーク語のギガワードプロジェクトについて説明します。このプロジェクトは、自由に利用できる10億語のコーパス言語のコーパスを作成することを目的としています。しかし、技術的な観点から、デンマーク語は比較的注目されておらず、その結果、デンマーク語のコーパスが広くないか広範にカバーされていないため、デンマーク語のテクノロジーを開発するのは困難です。デンマーク語は、技術と科学の伝統を持つ国であるデンマークで主に話されている北ドイツ語/スカンジナビア語です。革新。 
[ABSTRACT]デンマーク語のテクノロジーの開発が困難な理由の1つは、大規模または広義の言葉が欠けているためです-デンマーク語のコーパスの言葉
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: RNN-T Models Fail to Generalize to Out-of-Domain Audio: Causes and
  Solutions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_23.html">
      RNN-T Models Fail to Generalize to Out-of-Domain Audio: Causes and
  Solutions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これにより、不一致ドメインでの一般化特性が低下します。たとえば、短いセグメントでトレーニングされたエンドツーエンドモデルは、長い発話で評価するとパフォーマンスが低下します。近年、全ニューラルエンドツーエンドアプローチでは、 -いくつかの挑戦的な自動音声認識（ASR）タスクに関する最新の結果..長い形式のYouTubeテストセットで、非ストリーミングRNN-Tモデルがより短いデータセグメントでトレーニングされている場合、提案された組み合わせは単語の誤り率を改善します（WER）22.3％から14.8％;ストリーミングRNN-Tモデルが短い検索クエリでトレーニングされると、提案された手法により、YouTubeセットのWERが67.0％から25.3％に向上します。 
[ABSTRACT]既存のほとんどの作業は、トレーニングデータとテストデータが同じドメインから取得されるasrモデルの構築に焦点を当てています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: DramaQA: Character-Centered Video Story Understanding with Hierarchical
  QA -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_24.html">
      DramaQA: Character-Centered Video Story Understanding with Hierarchical
  QA
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのデータセットはテレビドラマ「Another Miss Oh」に基づいて構築されており、23,928のさまざまな長さのビデオクリップからの16,191 QAペアが含まれ、各QAペアは4つの難易度レベルの1つに属しています。2）ローカルコヒーレンスをモデル化する文字中心のビデオアノテーションさらに、ビデオの理解度を評価するための理論的な測定基準はありません。 
[ABSTRACT]データセットはテレビドラマ「別のミスOH」に基づいて構築されています。23、928のさまざまな長さのビデオクリップからの16、191 qaペアが含まれています。デュアルモデルを含む217のビデオクリップを分析できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Fine-Grained Analysis of Cross-Linguistic Syntactic Divergences -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_25.html">
      Fine-Grained Analysis of Cross-Linguistic Syntactic Divergences
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、5つの言語でParallel UDコーパスの手動で単語を並べたサブセットである小説のデータセットを提示し、それを使用して詳細なコーパス研究を実行します。パフォーマンスの説明に役立つことを示すことにより、結果の分析の有用性を示しますクロスリンガルパーサーのパターン..異なる言語の構文が収束および分岐するパターンは、クロスリンガル転送に関する作業を通知するためによく使用されます。 
[ABSTRACT]言語ペア全体のさまざまなコーパスの相違の有病率を定量化するための研究はほとんど行われていません。我々のフレームワークは、言語間の相違の詳細な図を提供し、以前のアプローチを一般化し、完全な自動化に役立ちます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Recurrent Neural Network Language Models Always Learn English-Like
  Relative Clause Attachment -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_26.html">
      Recurrent Neural Network Language Models Always Learn English-Like
  Relative Clause Attachment
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      したがって、スペイン語でトレーニングされたモデルは、比較可能な人間のような好みを取得できませんが、英語モデルは人間のような構文の好みを取得するように見えるかもしれません。典型的な言語モデルのユースケース）と（言語モデルのトレーニングデータを生成する）プロダクションは、必要な言語バイアスがトレーニング信号にまったくありません。英語とスペイン語のモデルパフォーマンスを比較して、RNN LMの非言語バイアスが英語では構文構造と有利に重なり、スペイン語ではないことを示します。 
[要約]英語とスペイン語のモデルパフォーマンスを比較して、rnn lmsの非言語的バイアスが英語では構文構造と有利にオーバーラップするが、スペイン語ではないことを示す
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br>2020-05-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: MISA: Modality-Invariant and -Specific Representations for Multimodal
  Sentiment Analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/cs.CL/paper_27.html">
      MISA: Modality-Invariant and -Specific Representations for Multimodal
  Sentiment Analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      各モダリティを2つの異なる部分空間に投影する新しいフレームワークMISAを提案します。ここでも、モデルは強力なベースラインよりも優れており、MISAを有用なマルチモーダルフレームワークとして確立しています。これらの表現は、マルチモーダルデータの全体的なビューを提供します。タスクの予測につながる融合に使用されます。 
[要約]論文では、効果的なモダリティ表現の学習を目指しています。これらの表現は、タスク予測につながる融合に使用されるマルチモーダルデータの全体像を提供します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Improved RawNet with Feature Map Scaling for Text-independent Speaker
  Verification using Raw Waveforms -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/eess.AS/paper_0.html">
      Improved RawNet with Feature Map Scaling for Text-independent Speaker
  Verification using Raw Waveforms
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは、特定の機能マップ内のフィルターの数に等しい次元を持つベクトルを指します。VoxCeleb1評価データセットに対して実行された実験は、提案された方法の有効性を実証し、最高のパフォーマンスのシステムは、同等のエラー率をオリジナルのRawNet ..さらに、最初の畳み込み層をSincNetのsinc畳み込み層に置き換えることを検討します。 
[要約]提案されたシステムは、シグモイド非線形関数を採用したスケールセンサーを使用します。これは、フィーチャマップを乗法的に、加法的に、またはその両方をスケーリングするために使用できます。最高のパフォーマンスのシステムは、元のローネットと比較して同等のエラー率を半分に減らします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-01">
        <br>2020-04-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ContextNet: Improving Convolutional Neural Networks for Automatic Speech
  Recognition with Global Context -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/eess.AS/paper_1.html">
      ContextNet: Improving Convolutional Neural Networks for Automatic Speech
  Recognition with Global Context
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      広く使用されているLibriSpeechベンチマークで、ContextNetが外部言語モデル（LM）なしで2.1 \％/ 4.6 \％、LM付きで1.9 \％/ 4.1 \％、2.9 \％/ 7.0の単語誤り率（WER）を達成することを示します\％クリーン/ノイズの多いLibriSpeechテストセットでパラメーターが10Mのみの場合。これは、以前に公開された2.0 \％/ 4.6 \％とLM、3.9 \％/ 11.3 \％と20Mのパラメーターの比較です。提案されたContextNetモデルは、はるかに大きな内部データセットでも検証されます。 
[ABSTRACT]新しい論文では、このギャップを埋め、新しいcnn-rnn-トランスデューサアーキテクチャでそれを超える方法を研究しています。さらに、コンテキストネットの幅をスケーリングするシンプルなスケーリング方法を提案し、優れたトレードオフを実現しています。計算と精度
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Crop Aggregating for short utterances speaker verification using raw
  waveforms -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/eess.AS/paper_2.html">
      Crop Aggregating for short utterances speaker verification using raw
  waveforms
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案された方法は、入力発話をいくつかの短い発話に分割し、セグメント化された入力から抽出されたセグメント埋め込みを集約して話者埋め込みを構成します。次に、この方法は、セグメント埋め込みと集約された話者埋め込みを同時にトレーニングします。提案された方法は、スピーカー検証システムの安定性と精度を向上させるアンサンブルベースの設計。 
[ABSTRACT]短い時間の発話は、音声情報がないために劣化することが知られています。これは、長い発話と比較して発音情報がないためです。提案された方法は、アンサンブルベースの設計を使用して、安定性と精度を改善しています話者認証システムの
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Continuous speech separation: dataset and analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/eess.AS/paper_3.html">
      Continuous speech separation: dataset and analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは、テストされたアルゴリズムの実際の関連性を評価することを困難にするだけでなく、研究者が実際のシナリオに容易に適用できるシステムの開発を妨げると考えています。このホワイトペーパーでは、連続音声分離（CSS）を次のように定義します。さまざまな程度で\ emph {部分的に}重複している複数の発話を含む\ textit {continuous}オーディオストリームから一連の重複しない音声信号を生成するタスク。このデータセットを使用して、最近提案されたいくつかの側面話者に依存しないCSSアルゴリズムが調査されます。 
[ABSTRACT]アルゴリズムは、信号対歪み比または同様のパフォーマンスメトリックに基づいて評価されます。さらに、信号ベースのメトリックは、自動音声認識（asr）精度と非常に弱い相関を持っています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br>2020-01-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Scyclone: High-Quality and Parallel-Data-Free Voice Conversion Using
  Spectrogram and Cycle-Consistent Adversarial Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/eess.AS/paper_4.html">
      Scyclone: High-Quality and Parallel-Data-Free Voice Conversion Using
  Spectrogram and Cycle-Consistent Adversarial Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Scycloneでは、ボコーダーパラメーターの代わりに線形スペクトログラムが変換機能として使用されます。これにより、基本周波数と有声/無声パラメーターの抽出エラーによる品質の低下が回避されます。完全に対になっていないトレーニングデータを使用した主観的な実験では、サイクロンが既存の最先端の並列データフリーVC技術の1つであるCycleGAN-VC2。ソースとターゲットのスピーカーのスペクトログラムは、変更されたCycleGANネットワークによってモデル化され、波形は、単一のシンプルなWaveRNNを使用して再構築されます。ガウス確率密度関数。 
[ABSTRACT] cycleganベースのスペクトログラム変換は、音声の自然さを改善するために使用されます。新しいボコーダーで認識可能な変更を認識して再作成します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The Perceptimatic English Benchmark for Speech Perception Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/eess.AS/paper_5.html">
      The Perceptimatic English Benchmark for Speech Perception Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      標準の英語音声認識機能であるDeepSpeechは、英語のリスナーよりも英語の音素識別に特化しており、人間に与えられた決定タスクでのエラーが低くても、動作との相関性が低いことを示しています。これらは直接抽出されます。読み上げ音声のコーパスから、典型的な音声データセットでトレーニングされた統計的音響モデル（自動音声認識で使用されるものなど）の評価に適したものにします。電話の識別がいくつかのタイプのモデルと相関していることを示し、研究者に推奨します実験的刺激の音響距離の簡単に計算された基準を求める。 
[ABSTRACT]ベンチマークは、abx刺激と91人のアメリカ英語-話すリスナーの応答で構成されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: RNN-T Models Fail to Generalize to Out-of-Domain Audio: Causes and
  Solutions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/eess.AS/paper_6.html">
      RNN-T Models Fail to Generalize to Out-of-Domain Audio: Causes and
  Solutions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、ほとんどの既存の作業は、トレーニングデータとテストデータが同じドメインから取得されるASRモデルの構築に重点を置いています。これにより、不一致ドメインでの汎化特性が低くなります。長い発話について..長い形式のYouTubeテストセットで、非ストリーミングRNN-Tモデルが短いデータセグメントでトレーニングされている場合、提案された組み合わせにより、単語エラー率（WER）が22.3％から14.8％に向上します。ストリーミングRNN-Tモデルが短い検索クエリでトレーニングされると、提案された手法により、YouTubeセットのWERが67.0％から25.3％に向上します。 
[ABSTRACT]既存のほとんどの作業は、トレーニングデータとテストデータが同じドメインから取得されるasrモデルの構築に焦点を当てています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Cotatron: Transcription-Guided Speech Encoder for Any-to-Many Voice
  Conversion without Parallel Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/eess.AS/paper_7.html">
      Cotatron: Transcription-Guided Speech Encoder for Any-to-Many Voice
  Conversion without Parallel Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのシステムは、トレーニング中に見えないスピーカーからの音声を変換し、ASRを利用して、最小限のパフォーマンスの低下で文字起こしを自動化することもできます。事前トレーニング済みモデルを使用したコードは間もなく利用可能になります。音声変換システムをトレーニングして、Cotatron機能を使用して音声を再構成します。これは、Phonetic Posteriorgram（PPG）に基づく以前の方法と同様です。 
[要旨] cotatronはマルチスピーカーttsアーキテクチャに基づいています。従来のttsデータセットでトレーニングできます。事前トレーニング済みモデルのコードは間もなく利用可能になります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: AutoSpeech: Neural Architecture Search for Speaker Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/eess.AS/paper_8.html">
      AutoSpeech: Neural Architecture Search for Speaker Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最終的な話者認識モデルは、標準スキームを通じて派生CNNモデルをトレーニングすることによって取得できます。結果は、提案されたアプローチからの派生CNNアーキテクチャが、VGG-M、ResNet-18、およびResNet-に基づく現在の話者認識システムを大幅に上回ることを示しています。モデルの複雑さを低減しながら、34のバックボーン。提案されたアプローチを評価するために、VoxCeleb1データセットを使用して話者識別タスクと話者検証タスクの両方で実験を行います。 
[ABSTRACT]スピーカーの構築とスピーカーの検証の両方で実験を行います。このモデルは、画像分類用に最初に提案されたバックボーンに基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Mutli-task Learning with Alignment Loss for Far-field Small-Footprint
  Keyword Spotting -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/eess.AS/paper_9.html">
      Mutli-task Learning with Alignment Loss for Far-field Small-Footprint
  Keyword Spotting
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、提案手法が接話音声のパフォーマンスを維持し、遠方界のテストセットで大幅な改善を実現することを示しています。この論文では、遠方界シナリオでの小さなフットプリントのキーワードスポッティングのタスクに焦点を当てます。 。私たちのベースラインシステムは、遠距離発話と接話音声の両方のプールされたデータでトレーニングされた畳み込みニューラルネットワークに基づいて構築されています。 
[要約]システムは、音声アプリケーションのパフォーマンスを向上させるために使用されます。異なる形式のデータから学習した埋め込み機能の間に不一致が発生します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Evidence for a behaviourally measurable perseverance trait -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/biorxiv.physiology/paper_0.html">
      Evidence for a behaviourally measurable perseverance trait
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      前のタスクに飽きて、etaの2乗範囲= 0〜0.096）。一緒に、2因子ソリューションは、パフォーマンスの全分散の37.3％を構成する共通分散の原因です。パフォーマンス時間。 
[ABSTRACT]タスクのパフォーマンスは2つのperseoraverance要因を形成しました。これらの要因は「物理的、特性」および「精神的」忍耐力として説明されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Lack of Kcnn4 improves mucociliary clearance in muco-obstructive lung disease. -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/biorxiv.physiology/paper_1.html">
      Lack of Kcnn4 improves mucociliary clearance in muco-obstructive lung disease.
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      したがって、遺伝子組み換えマウスモデルのMCCにおけるKCa3.1の役割を解明することを目的としました。しかし、気道上皮機能におけるその役割は完全には理解されていません。癒着、好中球浸潤および気腫。 
[要旨]粘液と呼吸は適切なmccの中心であり、mccはナトリウム（na）の吸収と陰イオンの分泌によって決定的に調節されます。重要なのは、カルシウム活性化カリウム（k）チャネルkcaです。 ３。 1. this削除は粘液の量を変更しなかったが粘液閉塞性肺疾患を軽減しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Validity of the Lumen(R) hand-held metabolic device to measure fuel utilization in healthy young adults -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-08/biorxiv.physiology/paper_2.html">
      Validity of the Lumen(R) hand-held metabolic device to measure fuel utilization in healthy young adults
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      アプローチ：健康的な参加者（n = 33;年齢：23.1 +-3.9年）の代謝燃料使用量は、ゴールドスタンダードの代謝カートからの呼吸交換率（RER）値と、Lumenデバイスからの％CO2を介して評価されました。回帰分析とBland-Altmanプロットは、異なる単位の性質に起因する固定バイアスを使用して、2つの測定値の間の一致（平均バイアス= 3.505、一致の限界= 2.784-4.226）を明らかにしました。測定は、2つの条件で安静時に行われ、空腹時、および代謝燃料の変化を測定するために150グラムのグルコースを消費した後。 
[ABSTRACT]代謝カートは、代謝燃料の使用状況を評価するために、生成された二酸化炭素と呼気から消費された酸素を測定します（炭水化物と脂肪）
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
