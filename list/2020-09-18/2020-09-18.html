<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-09-18の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Online Speaker Diarization with Relation Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.SD/paper_0.html">
      <font color="black">Online Speaker Diarization with Relation Network</font>
    </a>
  </h2>
  <font color="black">RenoSDの最も印象的な機能は、話者IDの関連付けにメタ学習戦略を採用していることです。特に、関係ネットワークは、データ主導の方法で遠距離メトリックを学習することを学習し、単純なフォワードパスを通じて与えられた2つのセグメントは同じスピーカーに属します。複数の独立して最適化されたモジュールで構成される従来のdiariztionシステムとは異なり、RenoSDは単一のディープニューラルネットワークを使用して、音声アクティビティ検出（VAD）、埋め込み抽出、およびスピーカーアイデンティティの関連付けを実装します。 
[要約]提案されたrenosdシステムは、単一のディープニューラルネットワークを使用して、音声-アクティビティ-検出と話者IDの関連付けを組み合わせます。2つの特定のセグメントが同じ話者に属しているかどうかを、単純な転送パスで判断できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Utterance-level Intent Recognition from Keywords -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.SD/paper_1.html">
      <font color="black">Utterance-level Intent Recognition from Keywords</font>
    </a>
  </h2>
  <font color="black">発話レベルの意図分類のアプローチは、単一の固定キーフレーズではなく、発話内の一連のキーワードに基づいています。キーワードシーケンスは、4つのタイプの入力機能に変換されます。つまり、個々の意図に対して音響、電話、word2vecおよびspeech2vecです。学習し、融合した意思決定を行います。キーフレーズの表現を使用した新しい手法が、車載ヒューマンマシンコミュニケーションを含むさまざまなドメインでノイズに強い意図分類に成功したことを示しています。 
[要約]発話レベルのインテント分類のアプローチは、単一の固定キーフレーズではなく一連のキーワードに基づいています。システムは、単一のキーフレーズではなく、発話で4つのキーワードを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Temporally Guided Music-to-Body-Movement Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.SD/paper_2.html">
      <font color="black">Temporally Guided Music-to-Body-Movement Generation</font>
    </a>
  </h2>
  <font color="black">デコーダーには、右側の動作とお辞儀の攻撃のタイミングを強調するための洗練されたネットワークとお辞儀攻撃の推論メカニズムが付属しています。私たちの知る限り、この作品は、3Dバイオリニストの体の動きを生成する最初の試みを表しています。音楽の身体の動きの主要な機能..自己注意モデルの最適化を容易にするために、ビート追跡を適用して、トレーニング例の効果的なサイズと境界を決定します。 
[要約]これは3-dヴァイオリニストの体の動きを生成する最初の試みです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Review: Deep Learning in Electron Microscopy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/eess.IV/paper_0.html">
      <font color="black">Review: Deep Learning in Electron Microscopy</font>
    </a>
  </h2>
  <font color="black">コンテキストについては、電子顕微鏡でのディープラーニングの一般的なアプリケーションを確認します。ディープラーニングは、電子顕微鏡を含む科学技術のほとんどの領域を変革しています。次に、ニューラルネットワークコンポーネント、一般的なアーキテクチャ、およびそれらの最適化を確認します。 
[ABSTRACT]このレビューペーパーは、知識が限られている開発者を対象とした実用的な視点を提供します。これには、電子顕微鏡などの技術の実用的な視点が含まれます。最後に、電子顕微鏡のディープラーニングの将来の方向性について説明します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Face Mask Detection using Transfer Learning of InceptionV3 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/eess.IV/paper_1.html">
      <font color="black">Face Mask Detection using Transfer Learning of InceptionV3</font>
    </a>
  </h2>
  <font color="black">モデルは、トレーニング中に99.9％、テスト中に100％の精度を達成することにより、他の最近提案されたアプローチよりも優れていました。コロナウイルスの拡散に対する保護のために、世界保健機関（WHO）からいくつかのガイドラインが発行されました。転移学習モデルは、マスクを着用していない人を識別するプロセスを自動化するために提案されています。 
[要約]いくつかのガイドラインが世界保健機関によって発行されました（100％）。提案されたモデルは、共同創設者の共同創設者をシミュレートして作成されています。モデルを使用して、より良いトレーニングとテストのためにデータをテストできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Microtubule Tracking in Electron Microscopy Volumes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/eess.IV/paper_2.html">
      <font color="black">Microtubule Tracking in Electron Microscopy Volumes</font>
    </a>
  </h2>
  <font color="black">微小管の軌跡は、微小管構造の生物学的事前計算を組み込んだ制約付き最適化問題を解くことによって候補グラフのノードとエッジを選択することで見つかります。このために、3桁のスピードアップをもたらす新しい整数線形計画法を提示します。先行技術と比較して、マグニチュードと精度が53％増加します（ショウジョウバエ神経組織の3つの1.2 x 4 x 4 $ \ mu $ mボリュームで評価されます）。ブロックごとに最適化問題を解決するスキームも提案します分散追跡を可能にし、非常に大きな電子顕微鏡ボリュームを処理するために必要な方法。 
[要約]まず、微小管に属している可能性が高いボクセルを特定します。これらは、候補グラフのノードとエッジを選択することで見つかりました。これが、この方法で初めて特定されたものです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: A 1d convolutional network for leaf and time series classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/eess.IV/paper_3.html">
      <font color="black">A 1d convolutional network for leaf and time series classification</font>
    </a>
  </h2>
  <font color="black">提案されたネットワークは、単純な1d入力を採用し、一般に、1次元の時系列を変更せずにエンドツーエンドで分類するなど、他のタスクに適用できます。一部のベンチマークデータセットでの実験では、このアーキテクチャが同等以上の分類精度を提供できることを示しています一部の既存の方法よりも優れています。.特徴抽出器として、ほぼ線形の分離可能な特徴を生成するため、サポートベクターマシンなどの他の分類子と一緒に使用して、より良いパフォーマンスを提供できます。 
[ABSTRACT]このネットワークベースの分類子は2つの方向で分析されます。分類子として、単純な重心輪郭距離曲線を単一の特徴として使用します。通常、複数の抽出された特徴を必要とする最新の方法で同等のパフォーマンスを実現できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-28">
        <br><font color="black">2019-06-28</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Stage CNN Architecture for Face Mask Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/eess.IV/paper_4.html">
      <font color="black">Multi-Stage CNN Architecture for Face Mask Detection</font>
    </a>
  </h2>
  <font color="black">ここにテクノロジーが鍵を握っています。私たちのシステムは、マスクされた顔とマスクされていない顔を検出できるデュアルステージの畳み込みニューラルネットワーク（CNN）アーキテクチャで構成され、プリインストールされたCCTVカメラと統合できます。ただし、手動で追跡することはできません。このポリシーの実装。 
[要約]世界がパンデミックから回復するにつれ、すべての個人の間で不安の波があります。ただし、このポリシーの実施を手動で追跡することは現実的ではありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: An Algorithm to Attack Neural Network Encoder-based Out-Of-Distribution
  Sample Detector -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/eess.IV/paper_5.html">
      <font color="black">An Algorithm to Attack Neural Network Encoder-based Out-Of-Distribution
  Sample Detector</font>
    </a>
  </h2>
  <font color="black">また、グロー尤度ベースのOOD検出も効果がないことを示しています。最後に、OOD検出のパフォーマンスが保証された簡単な理論的ソリューションを示します。Out-Of-Distribution（OOD）サンプルは、トレーニングセットの分布に従っていません。 、したがって、OODサンプルの予測クラスラベルは無意味になります。 
[ABSTRACT]パフォーマンスは、トレーニング済みモデルへの入力がトレーニングサンプルに類似している場合にのみ保証されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Arbitrary Video Style Transfer via Multi-Channel Correlation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/eess.IV/paper_6.html">
      <font color="black">Arbitrary Video Style Transfer via Multi-Channel Correlation</font>
    </a>
  </h2>
  <font color="black">複雑な光の条件下でのMCCNetのパフォーマンスをさらに改善するために、トレーニング中の照明損失も導入します。このために、見本のようなスタイルの機能と入力コンテンツを融合するようにトレーニングできるマルチチャネル修正ネットワーク（MCCNet）を提案します入力ビデオの一貫性を自然に維持しながら効率的なスタイル転送を行うための機能。MCCによって生成される出力は、鮮やかなスタイルテクスチャの画像にさらにデコードできる目的のスタイルパターンを含む機能です。 
[ABSTRACT]これは、従来の画像スタイルのスタイルスタイル転送と比較されます。コンテンツ空間との類似性に基づいてスタイル機能を再配置および融合することを学習する機能スペースで直接機能します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Single Frame Deblurring with Laplacian Filters -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/eess.IV/paper_7.html">
      <font color="black">Single Frame Deblurring with Laplacian Filters</font>
    </a>
  </h2>
  <font color="black">提案された方法は、客観的および主観的に測定された画質の大幅な改善を示しています。ベンチマークデータセットで最先端のDNN方法を使用して提案されたソリューションを評価しました。ベースラインアーキテクチャとして。 
[要約]このペーパーでは、ラプラシアンフィルターを使用したシングルフレームブラインドデブラーソリューションを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: High-dimensional Dense Residual Convolutional Neural Network for Light
  Field Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/eess.IV/paper_8.html">
      <font color="black">High-dimensional Dense Residual Convolutional Neural Network for Light
  Field Reconstruction</font>
    </a>
  </h2>
  <font color="black">これにより、モデルは複数の隣接するビューにエンコードされたジオメトリ情報をキャプチャする機能を学習できます。実現可能なネットワークをトレーニングするために、機能マップのビューのグループに基づく新しい正規化操作を提案し、段階的な損失関数を設計します。そして、パフォーマンスをさらに改善するためのマルチレンジトレーニング戦略を開発します。評価は、実際のシーン、合成データ、顕微鏡のライトフィールドを含む多数のライトフィールドデータセットに対して行われます。 
[ABSTRACT]多くの現在のアプローチは、視差の手がかりを必要とするか、一連の異なるアプローチに基づいてネットワークを復元します。これらには、2段階の復元に基づく学習フレームワークと学習フレームワークが含まれます。テストは、実世界を含む多数のライトフィールドデータセットで行われますシーン、合成データ、顕微鏡のライトフィールド</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-03">
        <br><font color="black">2019-10-03</font>
      </time>
    </span>
</section>
<!-- paper0: Deploying machine learning to assist digital humanitarians: making image
  annotation in OpenStreetMap more efficient -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/eess.IV/paper_9.html">
      <font color="black">Deploying machine learning to assist digital humanitarians: making image
  annotation in OpenStreetMap more efficient</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、人間とコンピューターの相互作用アプローチを探索し、OSMでボランティアの作業をサポートおよび最適化するためのインタラクティブな方法を提案します。シミュレーション結果と実際のユーザーアノテーションの修正による実験結果は、提案された方法が大幅にOSMのボランティアが検証/修正する必要があるデータの数。ユーザーは、いくつかの反復中に選択されたタイルの注釈を検証/修正して、新しい注釈付きデータでモデルを改善するよう求められます。 
[ABSTRACT]田舎の建物の地図は、田舎のコンピュータを自動的に更新するほど正確ではありません。提案された方法は、人道的地図作成プロジェクトに利益をもたらす可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Temporally Guided Music-to-Body-Movement Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/eess.IV/paper_10.html">
      <font color="black">Temporally Guided Music-to-Body-Movement Generation</font>
    </a>
  </h2>
  <font color="black">客観的評価と主観的評価の両方から、提案されたモデルが最新の方法よりも優れていることがわかります。私たちの知る限り、この作品は、音楽の主要な特徴を考慮した3Dバイオリニストの体の動きを生成する最初の試みを表していますMovement ..このペーパーでは、音楽オーディオから仮想バイオリニストの3Dスケルトンの動きを生成するニューラルネットワークモデルを紹介します。 
[要約]これは3-dヴァイオリニストの体の動きを生成する最初の試みです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Robust Cross-View Gait Recognition with Evidence: A Discriminant Gait
  GAN (DiGGAN) Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_0.html">
      <font color="black">Robust Cross-View Gait Recognition with Evidence: A Discriminant Gait
  GAN (DiGGAN) Approach</font>
    </a>
  </h2>
  <font color="black">ただし、歩行は、衣服、歩行速度、カメラの視野角などの多くの共変量の要因の影響を受けるため、堅牢な自動歩行認識システムを開発することは非常に困難です。歩行認識に関する既存の作業は、満足のいくパフォーマンスを提供するには十分ではありません。さらに、証拠を考慮した作品はほとんどありません-機械学習ベースの認識/認証アプリケーションで重要な要求と見なされている、決定の信頼性を明らかにする実証可能な情報。 
[ABSTRACT]歩容は簡単に収集でき、cctvカメラを介して非侵入型で個人を識別するために使用できます。全体的な歩容の外観を大幅に変える可能性があるため、視野角の大きな変化が最も困難な要素と見なされています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-11-26">
        <br><font color="black">2018-11-26</font>
      </time>
    </span>
</section>
<!-- paper0: Diversity Helps: Unsupervised Few-shot Learning via Distribution
  Shift-based Data Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_1.html">
      <font color="black">Diversity Helps: Unsupervised Few-shot Learning via Distribution
  Shift-based Data Augmentation</font>
    </a>
  </h2>
  <font color="black">ソースコードはhttps://github.com/WonderSeven/ULDA。で入手できます。重要なのは、拡張ベースの口実の数ショットタスクにおける分布の多様性の価値と重要性を強調することです。少数ショットモデルがより堅牢な機能表現を学習できるようにします。少数ショット学習は、近年広く調査されている、いくつかのトレーニング例しか利用できない場合に新しい概念を学習することを目的としています。 
[ABSTRACT]教師なし数-分布シフトによるショット学習-ベースのデータ増大（ulda）。データ増大を使用する場合、構築された各口実数ショットタスク内の分布多様性に注意を払います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-13">
        <br><font color="black">2020-04-13</font>
      </time>
    </span>
</section>
<!-- paper0: Novel View Synthesis from Single Images via Point Cloud Transformation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_2.html">
      <font color="black">Novel View Synthesis from Single Images via Point Cloud Transformation</font>
    </a>
  </h2>
  <font color="black">ソースコードとデータはhttps://lhoangan.github.io/pc4novis/。で入手できます。入力ビューとターゲットビュー間でフォワードワーピングとバックワードワーピングを使用することで、ネットワークを監視せずにエンドツーエンドでトレーニングできますdepth ..新規のビュー合成の明示的な3D形状として点群を使用する利点は、3D ShapeNetベンチマークで実験的に検証されています。 
[要旨]点群を自由に回転させて目的のビューにしてから、新しい画像に投影できます。点群は、予測されたピクセル-深度マップを使用して取得されます。点群を使用する利点は、3Dシェイプネットベンチマークで実験的に検証されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Review: Deep Learning in Electron Microscopy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_3.html">
      <font color="black">Review: Deep Learning in Electron Microscopy</font>
    </a>
  </h2>
  <font color="black">次に、ニューラルネットワークコンポーネント、一般的なアーキテクチャ、およびそれらの最適化を確認します。コンテキストについては、電子顕微鏡法でのディープラーニングの一般的なアプリケーションを確認します。次に、電子顕微鏡とのディープラーニングとインターフェースを開始するために必要なハードウェアとソフトウェアについて説明します。 
[ABSTRACT]このレビューペーパーは、知識が限られている開発者を対象とした実用的な視点を提供します。これには、電子顕微鏡などの技術の実用的な視点が含まれます。最後に、電子顕微鏡のディープラーニングの将来の方向性について説明します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: DLBCL-Morph: Morphological features computed using deep learning for an
  annotated digital DLBCL image set -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_4.html">
      <font color="black">DLBCL-Morph: Morphological features computed using deep learning for an
  annotated digital DLBCL image set</font>
    </a>
  </h2>
  <font color="black">TMAには、DLBCLを代表する組織の領域を識別する、病理学者が注釈を付けた関心領域（ROI）が付随します。Cox比例ハザードモデルを適合させて、生存結果の予測におけるこれらの幾何学的特徴の有用性を示し、 Cインデックス（95％CI）0.635（0.574,0.691）を達成しました。深層学習モデルを使用してROI内のすべての腫瘍核をセグメント化し、セグメント化された核ごとにいくつかの幾何学的特徴を計算しました。 
[要約]ディープラーニングモデルを使用してすべての腫瘍核をストレッチしました。これらの特徴は予後的に重要であることがわかりました。これは、腫瘍細胞からの幾何学的特徴の予測が予後を示唆していることを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Face Mask Detection using Transfer Learning of InceptionV3 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_5.html">
      <font color="black">Face Mask Detection using Transfer Learning of InceptionV3</font>
    </a>
  </h2>
  <font color="black">モデルのトレーニングとテストを改善するために、データの限られた可用性に対処するために画像拡張技術が採用されています。モデルは、トレーニング中に99.9％、テスト中に100％の精度を達成することにより、他の最近提案されたアプローチよりも優れています。提案されたモデルは事前トレーニング済みの最先端のディープラーニングモデルであるInceptionV3を微調整することにより構築されます。 
[要約]いくつかのガイドラインが世界保健機関によって発行されました（100％）。提案されたモデルは、共同創設者の共同創設者をシミュレートして作成されています。モデルを使用して、より良いトレーニングとテストのためにデータをテストできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: On the well-posedness of uncalibrated photometric stereo under general
  lighting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_6.html">
      <font color="black">On the well-posedness of uncalibrated photometric stereo under general
  lighting</font>
    </a>
  </h2>
  <font color="black">まず、正投影積分可能性の制約により、すでに推測されていたが証明されていない大まかな凹凸のあいまいさまで、解の一意性が保証されます。2つの重要な理論結果が確立されます。 -透視投影での問題の2乗ソリューションが提供され、合成データの数値シミュレーションにより、調査結果を経験的に検証できます。 
[ABSTRACT] 2つの重要な理論上の結果が確立されています。ただし、この問題の原因となった状態は不明です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-17">
        <br><font color="black">2019-11-17</font>
      </time>
    </span>
</section>
<!-- paper0: Video based real-time positional tracker -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_7.html">
      <font color="black">Video based real-time positional tracker</font>
    </a>
  </h2>
  <font color="black">ほとんどの場合、特に屋内オブジェクトや晴天から遮られたオブジェクトに対して、既存のどのGPSベースのシステムよりも高い更新レートと位置精度を実現します。位置を追跡するための入力としてビデオを使用するシステムを提案します。システムは、周囲の環境に対するオブジェクトのリアルタイムでの相対位置を計算します。システムは、カメラによって形成された重なり合うマトリックスを理解することにより、追跡されたオブジェクトのより広い世界に対する位置を返します。したがって、これらは実際の座標に外挿できます。 
[ABSTRACT]システムは、独自のsystem.systemからの100％合成データセットでトレーニングされます。システムは、より広い世界に対する追跡されたオブジェクトの位置を返します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Radar-Camera Sensor Fusion for Joint Object Detection and Distance
  Estimation in Autonomous Vehicles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_8.html">
      <font color="black">Radar-Camera Sensor Fusion for Joint Object Detection and Distance
  Estimation in Autonomous Vehicles</font>
    </a>
  </h2>
  <font color="black">レーダーベースの提案は、修正された地域提案ネットワーク（RPN）によって生成された画像ベースの提案と組み合わされます。RPRネットワークは、レーダー情報と画像機能マップの両方を使用して、正確なオブジェクト提案と距離推定を生成します。RPNには距離があります。生成されたすべての提案の距離を推定するための回帰層。 
[要約]提案されたアーキテクチャは、ミドルフュージョンアプローチを使用して、レーダーポイントクラウドとRGB画像を融合します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: A Linked Aggregate Code for Processing Faces (Revised Version) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_9.html">
      <font color="black">A Linked Aggregate Code for Processing Faces (Revised Version)</font>
    </a>
  </h2>
  <font color="black">混合カテゴリタスクのLAC類似度の次元構造は、いくつかの心理的にもっともらしい特徴を表示しましたが、モデルと人間の類似性判断の違いも強調しました。この結果は、LACベースの類似度が、さらなるモデリングの出発点になる可能性があることを示唆しています。顔の知覚におけるバイアスの発達の研究を含む、より高い視覚領域における顔の表現の研究。人間の判断は、LACモデルでは共有されない人種的な知覚のバイアスを示した。 
[要約]顔の表現モデルは、顔をカバーするモデルに対する集計の一次視覚皮質（v1）細胞応答を使用します。知覚可能なカテゴリの顔が使用された場合、見かけの性別や人種などの次元はトレーニングなしでモデルから出現しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic Edge Weights in Graph Neural Networks for 3D Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_10.html">
      <font color="black">Dynamic Edge Weights in Graph Neural Networks for 3D Object Detection</font>
    </a>
  </h2>
  <font color="black">マスクされた注意は暗黙的にすべてのノードの根本的な近傍グラフ構造を説明し、コストのかかる行列演算の必要性も排除するため、パフォーマンスを損なうことなく検出精度を向上させます。しかし、最近の研究では、グラフニューラルネットワーク（GNN）の利用を実証しています3Dオブジェクト検出への有望なアプローチとして。最初に、距離を意識したダウンサンプリングスキームを採用します。これにより、アルゴリズムのパフォーマンスが向上するだけでなく、センサーから離れていてもオブジェクトの最大の幾何学的特徴が保持されます。 
[ABSTRACT] 3Dオブジェクト検出アルゴリズムのほとんどは、ボクセルグリッドまたは鳥瞰図（bev）を使用した3d点群の処理に焦点を当てています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Counterfactual Generation and Fairness Evaluation Using Adversarially
  Learned Inference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_11.html">
      <font color="black">Counterfactual Generation and Fairness Evaluation Using Adversarially
  Learned Inference</font>
    </a>
  </h2>
  <font color="black">既知の因果関係グラフ構造を敵対学習推論（ALI）の条件付きバリアントに組み込むことで反事実を生成する方法を示します。意味のあるものにするために、生成された摂動は、因果モデルによって暗示される制約を満たす必要があります。アプリケーションとして、顔の魅力を予測する分類子の公平性バイアスを評価するための、CelebA画像から生成された反事実。 
[要旨]反事実に加えて、これらの例は、機械学習モデルの説明可能性と公平性を評価するのに役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Vax-a-Net: Training-time Defence Against Adversarial Patch Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_12.html">
      <font color="black">Vax-a-Net: Training-time Defence Against Adversarial Patch Attacks</font>
    </a>
  </h2>
  <font color="black">APAは、視覚的に明白なローカル領域（パッチ）を画像に挿入して、誤分類を引き起こします。APAで使用するパッチを合成することを同時に学習しながら、事前トレーニング済みのパッチを適応させるためにこれらの攻撃を利用する条件付きの生成的敵対的ネットワーク（GAN）アーキテクチャを導入します。それらに対する感受性を減らすためにCNNを対象とします。既存のAPAを防ぐためにこの保護の転送可能性を実証し、いくつかの最新のCNNアーキテクチャ全体でその有効性を示します。 
[ABSTRACT] apasは、視覚的に明白な局所領域（パッチ）を画像に挿入して、誤分類を引き起こします。このアプローチにより、回復力が事前トレーニング済みモデルに適応できるようになります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Frivolous Units: Wider Networks Are Not Really That Wide -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_13.html">
      <font color="black">Frivolous Units: Wider Networks Are Not Really That Wide</font>
    </a>
  </h2>
  <font color="black">ネットワークの幅が大きくなると増殖する2つの異なるタイプの「軽薄な」ユニットを識別します。出力に大きな変更を加えることなくネットワークからドロップできるプルーナブルユニットと、他のアクティビティの線形結合として表現できる冗長ユニットです。正確さを損なうことなく幅の増加を促進するものをよりよく理解するために、私たちは尋ねます：幅が増加するときにネットワークがそれらの効果的な複雑さを制御するユニットレベルのメカニズムはありますか？。もしそうなら、これらはアーキテクチャ、データセット、およびトレーニングパラメータにどのように依存しますか？ 
[ABSTRACT]生物学に触発された研究は、単位レベルでの表現を理解することです。それは、神経メカニズムのより詳細で直感的な解釈を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-10">
        <br><font color="black">2019-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Runtime Deep Model Multiplexing for Reduced Latency and Energy
  Consumption Inference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_14.html">
      <font color="black">Runtime Deep Model Multiplexing for Reduced Latency and Energy
  Consumption Inference</font>
    </a>
  </h2>
  <font color="black">さらに、入力を容易にするために小さなモデルが選択されるため、クラウドプロバイダーのコンピューティングリソースが2.85倍節約されます。したがって、モバイルユーザーは、ローカル処理だけでなく、クラウドサーバーでホストされる正確なモデルからも恩恵を受けます。 ..たとえば、ラベルを正しく予測できるモデルがない場合、入力は最も難しいと見なされます。 
[ABSTRACT]モバイルデバイスは、提案されたアルゴリズムを使用して、ハード入力をクラウドにオフロードして、簡単なものをローカルに推論できます。このプロジェクトでは、モバイルのモデルの精度が8.52％向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-14">
        <br><font color="black">2020-01-14</font>
      </time>
    </span>
</section>
<!-- paper0: Genetic Neural Architecture Search for automatic assessment of human
  sperm images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_15.html">
      <font color="black">Genetic Neural Architecture Search for automatic assessment of human
  sperm images</font>
    </a>
  </h2>
  <font color="black">私たちの実験では、GeNASが見つけた最良のニューラルアーキテクチャは、液胞、頭部、および先体の異常検出でそれぞれ91.66％、77.33％、77.66％の精度に達しています。この目的のために、 MHSMAデータセットには、不妊症の患者235人から収集された1,540の精子画像が含まれています。さらに、他の提案された方法はバランスのとれたデータセットで評価されていますが、GeNASはフィールドで一般的なノイズの多い低品質の不均衡なデータセット用に構築されています医用画像。 
[ABSTRACT] genasはメタコントローラーとして機能する遺伝的アルゴリズムです。単純な畳み込みニューラルネットワークアーキテクチャの検索空間を探索します。genasは、ノイズが多く、低品質で、不均衡なデータセット用に特別に構築されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-20">
        <br><font color="black">2019-09-20</font>
      </time>
    </span>
</section>
<!-- paper0: Population Mapping in Informal Settlements with High-Resolution
  Satellite Imagery and Equitable Ground-Truth -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_16.html">
      <font color="black">Population Mapping in Informal Settlements with High-Resolution
  Satellite Imagery and Equitable Ground-Truth</font>
    </a>
  </h2>
  <font color="black">私たちの調査結果は、一般的なベンチマークモデルを実際のタスクに転送することの難しさを強調しています。グリッド化された人口推定モデルを提案し、柔軟でカスタマイズ可能な空間分解能を実現します。私たちは、地域社会と協力して収集された公平なグラウンドトゥルースデータを利用しています。トレーニングとコミュニティマッピングを通じて、地元住民は独自のドメイン知識を提供すると同時に、データの管理を維持します。 
[要約]正確な人口推定は、政府当局やNgoの、たとえば医療緊急事態による効率的なリソース割り当てのための重要な要素です。私たちは共通の根拠を示すことを提案し、今後のステップを提案します。3つの実験サイトでパイプラインをテストしますナイジェリア、事前トレーニング済みの微調整ビジョンネットワークを使用してデータスパース性を克服</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Large Norms of CNN Layers Do Not Hurt Adversarial Robustness -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_17.html">
      <font color="black">Large Norms of CNN Layers Do Not Hurt Adversarial Robustness</font>
    </a>
  </h2>
  <font color="black">さらに、3つの異なる敵対訓練フレームワークで訓練されたCNNの層のノルムを計算し、敵対的にロバストなCNNは、敵対的にロバストな対応物よりも同等またはそれ以上の規範を持っていることを確認します。堅牢な分類子はニューラルネットワークで実現でき、敵対的に堅牢なニューラルネットワークは任意に大きなリプシッツ定数を持つことができます。これらの理由により、CNNレイヤーの小さなノルムの強制は、敵対的な堅牢性の実現に効果的でも必要でもありません。 
[ABSTRACT] `norm decay &#39;メソッドは、cnn decayのノルムを効果的に減らすことができます。しかし、それらが敵のロバスト性をわずかに損なう可能性があることを発見して驚いています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Multidimensional Scaling, Sammon Mapping, and Isomap: Tutorial and
  Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_18.html">
      <font color="black">Multidimensional Scaling, Sammon Mapping, and Isomap: Tutorial and
  Survey</font>
    </a>
  </h2>
  <font color="black">次に、Sammonマッピング、Isomap、およびカーネルIsomapについて説明します。SammonマッピングおよびIsomapは、それぞれメトリックMDSおよびカーネルクラシカルMDSの特殊なケースと見なすことができます。ここでは、MDSの上記のすべてのカテゴリについて説明します。 
[ABSTRACT]このチュートリアルと調査用紙では、mds.sammonマッピングの理論、isomap、およびカーネルisomapについて説明します。次に、nystromのアナロジーとランドマークmdsとランドマークisomapの使用法をビッグデータ埋め込みに導入します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Microtubule Tracking in Electron Microscopy Volumes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_19.html">
      <font color="black">Microtubule Tracking in Electron Microscopy Volumes</font>
    </a>
  </h2>
  <font color="black">このために、従来の技術（3つの1.2 x 4 x 4 $ \ mu $ mボリュームで評価）と比較して3桁のスピードアップと精度の53％の向上をもたらす新しい整数線形計画法の公式を提示します。ショウジョウバエの神経組織）。最後に、微小管追跡用のベンチマークデータセットをリリースします。ここでは、トレーニング、テスト、および検証に使用され、30 x 1000 x 1000の8つのボクセルブロック（1.2 x 4 x 4 $ \ mu $ m）で構成されています。 CREMIデータセット（https://github.com/nilsec/micron）の高密度の注釈付き微小管。ブロックごとに最適化問題を解決するためのスキームも提案します。これにより、分散追跡が可能になり、非常に処理する必要があります。大きな電子顕微鏡ボリューム。 
[要約]まず、微小管に属している可能性が高いボクセルを特定します。これらは、候補グラフのノードとエッジを選択することで見つかりました。これが、この方法で初めて特定されたものです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: A 1d convolutional network for leaf and time series classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_20.html">
      <font color="black">A 1d convolutional network for leaf and time series classification</font>
    </a>
  </h2>
  <font color="black">特徴抽出器として、ほぼ線形の分離可能な特徴を生成するため、サポートベクターマシンなどの他の分類子と一緒に使用して、より良いパフォーマンスを提供できます。提案されたネットワークは、単純な1d入力を採用し、一般に1次元の分類などの他のタスクに適用できます。変更なしのエンドツーエンド形式の時系列。このネットワークベースの分類子は、2つの方向で分析されます。 
[ABSTRACT]このネットワークベースの分類子は2つの方向で分析されます。分類子として、単純な重心輪郭距離曲線を単一の特徴として使用します。通常、複数の抽出された特徴を必要とする最新の方法で同等のパフォーマンスを実現できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-28">
        <br><font color="black">2019-06-28</font>
      </time>
    </span>
</section>
<!-- paper0: StarNet: towards Weakly Supervised Few-Shot Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_21.html">
      <font color="black">StarNet: towards Weakly Supervised Few-Shot Object Detection</font>
    </a>
  </h2>
  <font color="black">さらに、StarNetは、オブジェクト周辺のクロップが少ない、少数ショット分類ベンチマークで大幅な向上を示しています（オブジェクトのローカライズが重要です）。少数ショット検出器であるため、StarNetは事前トレーニング中に境界ボックスの注釈を必要としません。また、新規クラスの適応にも使用できません。このため、ベースラインを大幅に改善する、弱く監視された少数ショットオブジェクト検出（WS-FSOD）のこれまで未踏で困難なタスクに適用できます。 
[ABSTRACT]バックボーンは、イメージレベルのラベルのみを使用してメタトレーニングされています。したがって、これまで未探索だった少数ショットオブジェクト検出（ws-fsod）のタスクに適用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-15">
        <br><font color="black">2020-03-15</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Gender-Neutral Face Descriptors for Mitigating Bias in Face
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_22.html">
      <font color="black">Towards Gender-Neutral Face Descriptors for Mitigating Bias in Face
  Recognition</font>
    </a>
  </h2>
  <font color="black">その結果、妥当な認識パフォーマンスを維持しながら、顔認証における性別バイアスを減らすこともできます..（b。） 
[ABSTRACT]記述子はプライバシーの漏洩の影響を受けやすくなります。記述子は、記述子をプライバシーの漏洩に対して脆弱にします。agendaは、顔の記述子の性別の予測可能性を大幅に低下させます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-14">
        <br><font color="black">2020-06-14</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Stage CNN Architecture for Face Mask Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_23.html">
      <font color="black">Multi-Stage CNN Architecture for Face Mask Detection</font>
    </a>
  </h2>
  <font color="black">研究により、フェイスマスクを着用すると、ウイルス感染のリスクが大幅に軽減されるだけでなく、保護感も得られることが証明されています。当社のシステムは、マスクされた顔とマスクされていない顔を検出できるデュアルステージの畳み込みニューラルネットワーク（CNN）アーキテクチャで構成されています。プリインストールされたCCTVカメラと統合されています。ただし、このポリシーの実装を手動で追跡することはできません。 
[要約]世界がパンデミックから回復するにつれ、すべての個人の間で不安の波があります。ただし、このポリシーの実施を手動で追跡することは現実的ではありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: An Algorithm to Attack Neural Network Encoder-based Out-Of-Distribution
  Sample Detector -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_24.html">
      <font color="black">An Algorithm to Attack Neural Network Encoder-based Out-Of-Distribution
  Sample Detector</font>
    </a>
  </h2>
  <font color="black">最後に、OOD検出のパフォーマンスが保証された簡単な理論的ソリューションを紹介します。また、グロー尤度ベースのOOD検出も効果がないことを示します。この分析は、COVID-19 CTデータセットを含む5つのオープンデータセットで示されています。 
[ABSTRACT]パフォーマンスは、トレーニング済みモデルへの入力がトレーニングサンプルに類似している場合にのみ保証されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Tropical time series, iterated-sums signatures and quasisymmetric
  functions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_25.html">
      <font color="black">Tropical time series, iterated-sums signatures and quasisymmetric
  functions</font>
    </a>
  </h2>
  <font color="black">時系列からの特徴の原理的な抽出の必要性に基づいて、すべての可換半環に対して反復和シグネチャを導入します。熱帯半環の場合が中心であり、（実価値がある）既存の署名タイプのオブジェクトを使用して簡単に利用できない時系列。 
[ABSTRACT]反復型の導入-可換性のある半リング上のシグネチャを合計します。これにより、（実際の）時系列の機能に簡単にアクセスできなくなります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: AAG: Self-Supervised Representation Learning by Auxiliary Augmentation
  with GNT-Xent Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_26.html">
      <font color="black">AAG: Self-Supervised Representation Learning by Auxiliary Augmentation
  with GNT-Xent Loss</font>
    </a>
  </h2>
  <font color="black">主流の自己教師あり学習法として、拡張ベースの対比学習は、手動による注釈が不足しているさまざまなコンピュータビジョンタスクで大きな成功を収めています。結果は、AIFがCIFAR10、CIFAR100、およびSVHNの以前の最先端の方法よりも優れていることを示しています。 
[ABSTRACT]主流の自己監視学習方法として、拡張ベースの方法は、手動の注釈がないさまざまなコンピュータービジョンタスクで大きな成功を収めています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Collaborative Training between Region Proposal Localization and
  Classi?cation for Domain Adaptive Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_27.html">
      <font color="black">Collaborative Training between Region Proposal Localization and
  Classi?cation for Domain Adaptive Object Detection</font>
    </a>
  </h2>
  <font color="black">さらに、信頼性の低いサンプルは、RPNとRPCの間の不一致計算とミニマックス最適化に使用されます。RPNとRPCの一貫性と違いを詳しく調べ、RPNとRPCを個別に扱い、信頼性の高い出力を相互のガイダンスとして活用します。もう一方をトレーニングします。リージョン分類子は望ましいパフォーマンスを示しますが、RPNの高品質な提案がないと制限されますが、バックボーンネットワークでの単純な調整はRPN適応には十分効果的ではありません。 
[ABSTRACT]ラベルなしのデータセットに適用された事前トレーニング済みの検出器は、データセットの分布の違いに常に悩まされています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Image Composition with Auxiliary Illumination -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_28.html">
      <font color="black">Adversarial Image Composition with Auxiliary Illumination</font>
    </a>
  </h2>
  <font color="black">ローカルの調和とグローバルの調和を橋渡しして、それらの共同最適化を効果的に実現する、差別化可能な空間変換モジュールが設計されています。前景オブジェクトと背景画像の間の不整合に対処することは、高忠実度の画像合成において困難な作業です。論文では、合成画像に前景オブジェクトが投影する潜在的な影を考慮してリアルな画像合成を実現する敵対画像合成ネット（AIC-Net）を提案します。 
[ABSTRACT]提案されたaic-netは、質的および量的に優れたコンポジションパフォーマンスを実現します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Collective Learning: Learning Optimal Inputs and Weights Jointly in
  Deep Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_29.html">
      <font color="black">Deep Collective Learning: Learning Optimal Inputs and Weights Jointly in
  Deep Neural Networks</font>
    </a>
  </h2>
  <font color="black">この論文では、与えられたタスクに対してDNNの重みとDNNへの入力を同時に学習することを目的とした{\ em deep collective learning}のパラダイムを提案します。ディープラーニングとコンピュータビジョンの文献では、視覚データが学習タスクのエンドツーエンドのディープニューラルネットワーク（DNN）に入力されるとき、常に手動で設計されたコーディングスキーム（たとえば、RGB画像は各チャネルで0〜255の範囲の整数として表されます）で表されます。 。そのため、コンピュータービジョンにおける深層学習のソリューションとして、ルックアップビジョンネットワーク（Lookup-VNet）を提案します。 
[ABSTRACT]集団学習は手動で行われていますが、自然言語で広く使用されています。コンピュータビジョンで研究されたことはほとんどありません、とアンドリューウェイバーグ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: S2SD: Simultaneous Similarity-based Self-Distillation for Deep Metric
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_30.html">
      <font color="black">S2SD: Simultaneous Similarity-based Self-Distillation for Deep Metric
  Learning</font>
    </a>
  </h2>
  <font color="black">https://github.com/MLforHealth/S2SD ..で利用可能なコード。S2SDは、DMLを拡張し、補助的な高次元の埋め込みと機能スペースからの知識抽出により、テスト時間のコストを維持しながら、トレーニング中に補完的なコンテキストを活用し、トレーニング時間..ただし、汎化能力は、埋め込み空間の次元に応じて変化することがわかっています。 
[ABSTRACT] s2sd-同時類似性-ベースの自己-蒸留。s2sdでは、再現率が最大7％向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Modeling human visual search: A combined Bayesian searcher and saliency
  map approach for eye movement guidance in natural scenes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_31.html">
      <font color="black">Modeling human visual search: A combined Bayesian searcher and saliency
  map approach for eye movement guidance in natural scenes</font>
    </a>
  </h2>
  <font color="black">このアプローチは、凝視ランクとスキャンパスの類似性の関数として見つかるターゲットのパーセンテージの両方で、スキャンパス全体で人間に非常に似た動作を導き、一連の目の動き全体を再現します。ボトムアップの第一印象をモデル化するのに適していますが、トップダウンのタスク情報が重要な場合はスキャンパスを説明するには不十分です。ここでは、事前情報として顕著性マップによって導かれる視覚検索の統一ベイジアンモデルを提案します。 
[要旨]顕著性モデルは凝視位置を予測するのに役立ちましたが、時間に関する情報を提供していません-固視のシーケンス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Omni-supervised Facial Expression Recognition: A Simple Baseline -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_32.html">
      <font color="black">Omni-supervised Facial Expression Recognition: A Simple Baseline</font>
    </a>
  </h2>
  <font color="black">この作業が強固なベースラインとして役立ち、FERの将来の研究を容易にするのに役立つことを願っています。このホワイトペーパーでは、全知教師付き学習を活用して表情認識（FER）のパフォーマンスを向上させることを目標としています。特徴ベースの類似性比較を行うことにより、顔のプールから信頼性の高いサンプルを選択するために、少数のラベル付きサンプルが採用されています。 
[ABSTRACT] ferアプローチは通常、限られた数のサンプルを使用してモデルをトレーニングすることにより、制御された環境で顔の表情を認識することを目的としています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-18">
        <br><font color="black">2020-05-18</font>
      </time>
    </span>
</section>
<!-- paper0: Holistic Filter Pruning for Efficient Deep Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_33.html">
      <font color="black">Holistic Filter Pruning for Efficient Deep Neural Networks</font>
    </a>
  </h2>
  <font color="black">各順方向パスの後で、現在のモデルの複雑さが計算され、目的のターゲットサイズと比較されます。勾配降下により、目的のターゲットサイズが満たされるように個々のレイヤーに剪定バジェットを割り当てるグローバルソリューションを見つけることができます。フィルタープルーニングによって達成されるスパース性は、重みとアクティブ化のテンソルサイズを直接削減するため、複雑さを減らすのに特に効果的です。 
[ABSTRACT]「ホリスティックフィルタープルーニング」（hfp）を提案します。これは、実装が簡単な一般的なdnnトレーニングの新しいアプローチです。パラメーターと乗算の両方の数に対して正確なプルーニングレートを指定できます。個々のレイヤーに剪定予算を割り当てることがわかります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic Regions Graph Neural Networks for Spatio-Temporal Reasoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_34.html">
      <font color="black">Dynamic Regions Graph Neural Networks for Spatio-Temporal Reasoning</font>
    </a>
  </h2>
  <font color="black">私たちのモデルは、インスタンスの相互作用を含むビデオ分類タスクで優れた結果を達成します。現在の作業では、外部オブジェクト検出器または固定領域を使用してグラフノードに対応する特徴を抽出し、明示的なオブジェクトなしで各ノードに関連付けられた領域を動的に生成するモジュールを提案していますレベルの監視..局所性の仮定を利用して空間に明確に局所化されたノードを作成する方法を提案することにより、インスタンス間の関係のモデリングに焦点を当てています。 
[ABSTRACT]配置の仮定を利用して、空間に明確に局所化されたノードを作成する方法を提案しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: MultAV: Multiplicative Adversarial Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_35.html">
      <font color="black">MultAV: Multiplicative Adversarial Videos</font>
    </a>
  </h2>
  <font color="black">さらに、レシオバウンドと呼ばれる新しい敵対的制約によるLpノルム攻撃だけでなく、物理的に実現可能なさまざまな種類の攻撃にも一般化できます。MultAVは、追加の対応物に対してさまざまなノイズ分布を持ち、抵抗に合わせた防御方法に挑戦します。相加的攻撃..敵対的な機械学習研究の大部分は、相加的な脅威モデルに焦点を当てており、入力データに敵対的な摂動を追加します。 
[ABSTRACT]ビデオドメインで調査された脅威モデルはほんの一握りです。multavには、additiveltavモデルとは異なるノイズ分布があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Arbitrary Video Style Transfer via Multi-Channel Correlation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_36.html">
      <font color="black">Arbitrary Video Style Transfer via Multi-Channel Correlation</font>
    </a>
  </h2>
  <font color="black">複雑な光の条件下でのMCCNetのパフォーマンスをさらに改善するために、トレーニング中の照明損失も導入します。このために、見本のようなスタイルの機能と入力コンテンツを融合するようにトレーニングできるマルチチャネル修正ネットワーク（MCCNet）を提案します入力ビデオの一貫性を自然に維持しながら効率的なスタイル転送を実現する機能。具体的には、MCCNetはスタイルとコンテンツドメインの機能空間に直接作用し、コンテンツ機能との類似性に基づいてスタイル機能の再配置と融合を学習します。 
[ABSTRACT]これは、従来の画像スタイルのスタイルスタイル転送と比較されます。コンテンツ空間との類似性に基づいてスタイル機能を再配置および融合することを学習する機能スペースで直接機能します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Semantic Analysis on Point Clouds via Auxiliary Supervision of
  Local Geometric Priors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_37.html">
      <font color="black">Improving Semantic Analysis on Point Clouds via Auxiliary Supervision of
  Local Geometric Priors</font>
    </a>
  </h2>
  <font color="black">点群分析のための既存のディープラーニングアルゴリズムは、主にローカルジオメトリのグローバル構成からの教師あり学習による意味的パターンの発見に関係しています。バックボーンベースラインやその他の最先端の手法よりも優れたパフォーマンスを実現します。これらは、人気のあるベンチマークの実験で検証されています。この論文は、意味解析を改善するためのユニークなマルチタスク幾何学習ネットワークを提案する最初の試みです。ローカル形状プロパティを使用した補助的な幾何学学習により、点群自体から物理計算を介して自己監視信号として生成するか、特権情報として提供できます。 
[ABSTRACT]提案された幾何学的自己監視および特権学習アルゴリズムは、バックボーンベースラインより優れたパフォーマンスを実現できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-14">
        <br><font color="black">2020-01-14</font>
      </time>
    </span>
</section>
<!-- paper0: Single Frame Deblurring with Laplacian Filters -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_38.html">
      <font color="black">Single Frame Deblurring with Laplacian Filters</font>
    </a>
  </h2>
  <font color="black">問題の不適切な性質により、ブラインド単一画像のブレ除去は何十年にもわたる課題でした。利用された残差密ネットワークは超解像タスクでその強みを証明しているため、ベースラインアーキテクチャとして選択しました。客観的および主観的に測定された画質の改善。 
[要約]このペーパーでは、ラプラシアンフィルターを使用したシングルフレームブラインドデブラーソリューションを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Momentum Uncertainty Hashing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_39.html">
      <font color="black">Deep Momentum Uncertainty Hashing</font>
    </a>
  </h2>
  <font color="black">これは、対応する入力画像に対するハッシュネットワークの不確実性を具体化します。一方、ハッシュコードのすべてのビットの平均不一致は、\ emph {画像レベルの不確実性}と見なすことができます。各ビットの不一致は、そのビットのおおよその出力へのハッシュネットワーク。 
[要約]この論文では、ハッシングの新しい深い運動量の不確実性を提案します。明示的に、ハッシングネットワークの出力とモーメンタムの出力の不一致をモデル化します-更新されたネットワーク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Word Segmentation from Unconstrained Handwritten Bangla Document Images
  using Distance Transform -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_40.html">
      <font color="black">Word Segmentation from Unconstrained Handwritten Bangla Document Images
  using Distance Transform</font>
    </a>
  </h2>
  <font color="black">人気のある距離変換（DT）アルゴリズムは、単語画像の外側の境界を見つけるために適用されます。満足のいく結果は、提案された方法の堅牢性を確認する91.88％のセグメンテーション精度で達成されます。提案された手法は、ランダムな50でテストされます。 CMATERdb1.1.1データベースから取得した画像。 
[要約]提案された手法は、cmaterdb1から取得した50のランダムな画像でテスト</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: A Privacy-Preserving-Oriented DNN Pruning and Mobile Acceleration
  Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_41.html">
      <font color="black">A Privacy-Preserving-Oriented DNN Pruning and Mobile Acceleration
  Framework</font>
    </a>
  </h2>
  <font color="black">提案されたフレームワークを使用すると、ユーザーは非専門家の時間のかかるプルーニングプロセスを回避し、圧縮モデルから直接メリットを得ることができます。実験結果は、提案されたフレームワークが3つの最先端のエンドツーエンドDNNフレームワーク、つまり、 TensorFlow-Lite、TVM、およびMNN、それぞれ最大4.2X、2.5X、および2.0Xのスピードアップ、データのプライバシーを維持しながら、精度の損失はほとんどありません。提案されたフレームワークのアルゴリズムレベルでは、体系的な重みの剪定乗算器の交互方向法（ADMM）に基づく手法は、ランダムに生成された合成データを使用して、各レイヤーのパターンベースのプルーニング問題を反復的に解決するように設計されています。 
[要約]提案されたフレームワークは、乗数の継続方向法（admm）に基づく体系的な重み剪定手法です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-13">
        <br><font color="black">2020-03-13</font>
      </time>
    </span>
</section>
<!-- paper0: Multiple Exemplars-based Hallucinationfor Face Super-resolution and
  Editing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_42.html">
      <font color="black">Multiple Exemplars-based Hallucinationfor Face Super-resolution and
  Editing</font>
    </a>
  </h2>
  <font color="black">これらは、出力を調整するときにニューラルネットワークを導きます。ユーザー調査が行われ、CelebAデータセットの実際の画像と超解像画像をほとんど区別できないことが示されています。複数のサンプルは、単一のサンプルよりもうまく機能します。 
[ABSTRACT]低解像度の入力に高周波情報が欠落しており、画像コンテンツに関する事前の知識に基づいて幻覚をかける必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Approximate k-NN Graph Construction: a Generic Online Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_43.html">
      <font color="black">Approximate k-NN Graph Construction: a Generic Online Approach</font>
    </a>
  </h2>
  <font color="black">一方、構築されたk最近傍グラフは、k最近傍検索をサポートするために使用されます。一方、近似k最近傍グラフの構築は、検索タスクとして扱われます。各サンプルとそのk -nearest Neighborsは、作成中のグラフ上で最近隣探索を順次実行することにより、k-nearest Neighborグラフに結合されます。 
[ABSTRACT]グラフはオンラインで構築されており、既存のほとんどのソリューションでは不可能です。さまざまなタイプのデータをさまざまなサイズ、さまざまなディメンション、さまざまな指標で測定します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-04-09">
        <br><font color="black">2018-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: Low-Rank Matrix Recovery from Noisy via an MDL Framework-based Atomic
  Norm -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_44.html">
      <font color="black">Low-Rank Matrix Recovery from Noisy via an MDL Framework-based Atomic
  Norm</font>
    </a>
  </h2>
  <font color="black">最初に、原子ノルムを使用して低ランクとスパースの項のすべての候補原子を見つけます。次に、低ランクとスパース行列の適切な原子をそれぞれ選択するために、モデルの記述長を最小化します。合成データと実際のセンシングアプリケーション（ハイダイナミックレンジイメージング、バックグラウンドモデリング、シャドウとスペキュラリティの削除）に関する実験結果は、提案された方法の有効性、堅牢性、および効率を示しています。スパースノイズ/異常値はますます関心を集めています。 
[ABSTRACT]低-密な外れ値のランクとシャドウは不明です。これらには最小記述長（mdl）の原則が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: High-precision target positioning system for unmanned vehicles based on
  binocular vision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_45.html">
      <font color="black">High-precision target positioning system for unmanned vehicles based on
  binocular vision</font>
    </a>
  </h2>
  <font color="black">これに関連して、本論文では、両眼視に基づく高精度無人車両目標位置決めシステムを提案します。システムの効果を検証するために、本論文では、さまざまな姿勢でのシリンダーの出力結果の精度と計算時間を収集します。 ..実験データは、システムの位置精度が0.61〜1.17mmで、角度精度が1.95〜5.13 {\ deg}であることを示しています。これにより、より高い精度の位置決め効果を実現できます。 
[ABSTRACT]システムは、領域ベースのステレオマッチングアルゴリズムを使用して、位置と姿勢の特徴の分析に基づいて、視差マップを取得します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Back to Event Basics: Self-Supervised Learning of Image Reconstruction
  for Event Cameras via Photometric Constancy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_46.html">
      <font color="black">Back to Event Basics: Self-Supervised Learning of Image Reconstruction
  for Event Cameras via Photometric Constancy</font>
    </a>
  </h2>
  <font color="black">それにもかかわらず、正確なグラウンドトゥルースはシミュレーションでのみ利用できるため、これらの方法は現実のギャップの影響を受け、一般化可能性を確保するために、トレーニングデータセットは慎重に設計する必要があります。イベントカメラは、非同期でサンプリングする新しいビジョンセンサーです。低レイテンシと高時間分解能を備えた明るさの増分。この作業では、自己監視学習の観点から、初めて、再構成問題に取り組みます。 
[要約]ニューヨーク大学の研究者が初めてモデルを特定しました。プロジェクトは説明責任の欠如に基づいていると言います。複数のフレームで問題を追跡するために使用されることが期待されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Trajectory Poisson multi-Bernoulli filters -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_47.html">
      <font color="black">Trajectory Poisson multi-Bernoulli filters</font>
    </a>
  </h2>
  <font color="black">開発されたフィルターは、軌道PMBMフィルターに代わる計算量の少ない代替策であり、ポアソン出生モデルを使用して軌道のセットに閉形式の再帰を提供し、以前のマルチターゲット追跡アルゴリズムよりも優れていることが示されています。この論文では、2つの軌道ポアソンマルチマルチターゲットトラッキング用のベルヌーイ（TPMB）フィルター：1つは各タイムステップでの生存軌跡のセットを推定し、もう1つは各タイムステップでの生存軌跡と死んだ軌跡を含むすべての軌跡のセットを推定します。フィルターはフィルタリングの再帰を通じて、対応する軌道のセットでポアソンマルチベルヌーイ（PMB）密度を伝播することについて。 
[ABSTRACT]開発されたフィルターは、フィルタリングの再帰を通じて対応する一連の軌道上でポアソンマルチベルヌーイ（pmb）密度を伝播することに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-28">
        <br><font color="black">2020-03-28</font>
      </time>
    </span>
</section>
<!-- paper0: High-dimensional Dense Residual Convolutional Neural Network for Light
  Field Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_48.html">
      <font color="black">High-dimensional Dense Residual Convolutional Neural Network for Light
  Field Reconstruction</font>
    </a>
  </h2>
  <font color="black">このような幾何学的特徴は、オクルージョン領域の近くで変化し、前景オブジェクトの境界を示します。このような方法は、非ランバート面またはオクルージョンでは困難です。対照的に、ライトフィールド超解像（LFSR）をテンソル復元として公式化し、学習フレームワークを開発します4次元（4D）畳み込みによる2段階の復元に基づいています。 
[ABSTRACT]多くの現在のアプローチは、視差の手がかりを必要とするか、一連の異なるアプローチに基づいてネットワークを復元します。これらには、2段階の復元に基づく学習フレームワークと学習フレームワークが含まれます。テストは、実世界を含む多数のライトフィールドデータセットで行われますシーン、合成データ、顕微鏡のライトフィールド</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-03">
        <br><font color="black">2019-10-03</font>
      </time>
    </span>
</section>
<!-- paper0: Label Smoothing and Adversarial Robustness -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_49.html">
      <font color="black">Label Smoothing and Adversarial Robustness</font>
    </a>
  </h2>
  <font color="black">ラベルのスムージングによって生成される堅牢性は、その防御効果が不安定であり、自然に訓練されたモデルから転送された攻撃を防御できないという事実に基づいて不完全であることを示します。微妙な堅牢性の根底にある理由を理解するために、ラベル間の関係を調査します平滑化と敵対的な堅牢性。ラベルの平滑化でトレーニングされたネットワークの特性に関する理論的分析と、さまざまな攻撃下でのそのパフォーマンスの実験による検証。 
[ABSTRACT]研究者は、cifarでラベルの平滑化を使用してトレーニングされたネットワークを調査しました。10。モデルを使用して、そのパフォーマンスをテストできることがわかりました。モデルの「堅牢性」をテストすることが有用であるとのことです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Domain-Agnostic Few-Shot Classification by Learning Disparate Modulators -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_50.html">
      <font color="black">Domain-Agnostic Few-Shot Classification by Learning Disparate Modulators</font>
    </a>
  </h2>
  <font color="black">このフレームワークにより、プールは、ドメイン不変の有益な機能を失うことなく、表現の多様性を持つことができます。多様なドメインにわたるさまざまなデータセットの実験を通じて、提案されたアルゴリズムの有効性を検証します。少数ショット学習の研究は、メタの助けにより急速に進歩しましたが-学習、それらのほとんどはすべてのメタトレーニングとメタテストの例は単一のドメインからのものであると想定していたため、その実用的な有用性はまだ限られています。 
[ABSTRACT]少数ショット分類のためのシンプルで効果的な方法が必要です。提案されたアルゴリズムはすべてのタイプのテストに基づいています。プロジェクトの有効性をテストするために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-11">
        <br><font color="black">2019-09-11</font>
      </time>
    </span>
</section>
<!-- paper0: DanceIt: Music-inspired Dancing Video Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_51.html">
      <font color="black">DanceIt: Music-inspired Dancing Video Synthesis</font>
    </a>
  </h2>
  <font color="black">最後に、処理されたポーズシーケンスを使用して、イマジネーションモジュールでリアルなダンスビデオを合成します。実験結果と主観評価により、提案されたアプローチは、音楽を入力して有望なダンスビデオを生成する機能を実行できることがわかります。音楽から選択されたそのようなポーズシーケンスただし、通常は不連続です。 
[ABSTRACT]提案されたシステムはダンス動画に焦点を当てています。これらの動画は音楽のコンテンツと機能に一致しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: ShapeAssembly: Learning to Generate Programs for 3D Shape Structure
  Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_52.html">
      <font color="black">ShapeAssembly: Learning to Generate Programs for 3D Shape Structure
  Synthesis</font>
    </a>
  </h2>
  <font color="black">アプリケーションとして、私たちは生成モデルと微分可能プログラムインタープリターを使用して、形状プログラムを推測し、点群などの非構造化ジオメトリに適合させます。ShapeAssemblyプログラムは、直方体部分のプロキシを宣言し、それらを互いに階層的かつ対称的に接続することで形状を構築します。ファッション..その関数は自由変数でパラメーター化されているため、1つのプログラム構造で関連する形状のファミリーをキャプチャできます。 
[ABSTRACT] shapeassemblyプログラムは、直方体部分を難しいと宣言することによって形状を構築します。次に、それらを時系列的かつ対称的な方法で相互に接続します。これらの構造はよりスムーズな補間を作成し、作成が困難です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: LDNet: End-to-End Lane Detection Approach usinga Dynamic Vision Sensor -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_53.html">
      <font color="black">LDNet: End-to-End Lane Detection Approach usinga Dynamic Vision Sensor</font>
    </a>
  </h2>
  <font color="black">レーン検出タスクにRGBカメラを使用すると、照明の変化、太陽光のグレア、モーションブラーが発生しやすくなり、レーン検出方法のパフォーマンスが制限されます。この作業では、ダイナミックビジョンセンサー（LDNet）を使用したレーン検出が提案されています。 、これは、アトラス空間ピラミッドプーリングブロックに続いて、レーン検出タスクでの誤予測を予測および削減するための注意誘導デコーダーを備えたエンコーダー/デコーダー方式で設計されています。実験結果は、$ 5.54 \％$および$ 5.03の大幅な改善を示しています。マルチクラスレーン検出タスクとバイナリクラスレーン検出タスクの$ F1 $スコアの\％$。 
[要旨] rgbカメラを使用した従来の車線検出方法が提案されています。これらには、手作りまたは深層学習ベースの機能が含まれます。このデコーダーは、車線検出ステップの必要性を排除します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Deploying machine learning to assist digital humanitarians: making image
  annotation in OpenStreetMap more efficient -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_54.html">
      <font color="black">Deploying machine learning to assist digital humanitarians: making image
  annotation in OpenStreetMap more efficient</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、人間とコンピューターの相互作用のアプローチを探索し、OSMでボランティアの作業をサポートおよび最適化するためのインタラクティブな方法を提案します。ただし、OpenStreetMap（OSM）などのオープンマッピングサービスにおける農村の建物の注釈付きデータの量と量このような検出のための正確なモデルのトレーニングには十分ではありません。シミュレーション結果と実際のユーザーアノテーションの修正による実験結果は、提案された方法がOSMのボランティアが検証/修正する必要があるデータの量を大幅に削減することを示しています。 
[ABSTRACT]田舎の建物の地図は、田舎のコンピュータを自動的に更新するほど正確ではありません。提案された方法は、人道的地図作成プロジェクトに利益をもたらす可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: SLGAN: Style- and Latent-guided Generative Adversarial Network for
  Desirable Makeup Transfer and Removal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_55.html">
      <font color="black">SLGAN: Style- and Latent-guided Generative Adversarial Network for
  Desirable Makeup Transfer and Removal</font>
    </a>
  </h2>
  <font color="black">主に生成的敵対的ネットワーク（GAN）を使用して、いくつかの関連研究が提案されています。私たちの実験では、SLGANが最新の方法より優れているか、同等であることを示しています。新しい、知覚的な化粧損失を提供します。アイデンティティシフトの問題を回避するために、ヒストグラムマッチングに基づいてメイクアップスタイルを転送できるスタイル不変のデコーダー。 
[ABSTRACT]私たちの提案は、顔のメイク画像を補間して固有の機能を決定できます。また、既存の方法を比較して、ユーザーが望ましいメイク構成を見つけるのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: A Multimodal Memes Classification: A Survey and Open Research Issues -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_56.html">
      <font color="black">A Multimodal Memes Classification: A Survey and Open Research Issues</font>
    </a>
  </h2>
  <font color="black">最近、この問題は研究者や実務家の注目を集めています。自然言語処理（NLP）でのBERTの成功後、研究者はミーム分類、画像キャプション、視覚質問応答（VQA）などの視覚言語（VL）マルチモーダル問題に傾倒しました）、その他多数。VLの問題に関する初期および次世代の作業について説明します。 
[ABSTRACT]ミームは、ジョーク、皮肉、やる気などの形で、ソーシャルメディアプラットフォームで主に広まっています。これは、他のvlデータセットで大幅に実行された最先端の方法が原因であり、ミームの分類に失敗する傾向があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Learning a Deep Part-based Representation by Preserving Data
  Distribution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_57.html">
      <font color="black">Learning a Deep Part-based Representation by Preserving Data
  Distribution</font>
    </a>
  </h2>
  <font color="black">この論文では、データ分布を保存することにより、深い部分に基づく表現を学習することができ、新しいアルゴリズムは分布保存ネットワーク埋め込み（DPNE）と呼ばれます。一方、各データクラスターの固有の構造はクラス内サンプルの分布によって記述されます。DPNEでは、最初に$ k $最近傍カーネル密度推定を使用して元の高次元データの分布を推定する必要があります。次に、上記の分布。 
[ABSTRACT] dpneでは、$ k $-最近傍カーネル密度推定を使用して元のデータの分布を推定する必要があります。次に、上記の分布を尊重する部分ベースの表現を探します。新しい低コスト表現は、オリジナルのハイセックスデータスペースに埋め込まれた構造</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Modeling 3D Shapes by Reinforcement Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_58.html">
      <font color="black">Modeling 3D Shapes by Reinforcement Learning</font>
    </a>
  </h2>
  <font color="black">モデリングエージェントを効果的にトレーニングするために、ヒューリスティックポリシー、模倣学習、強化学習を組み合わせた新しいトレーニングアルゴリズムを導入します。このようなアーティストベースのモデリングに触発され、3Dモデリングポリシーを学習するRLに基づく2ステップのニューラルフレームワークを提案します。 。私たちの実験は、エージェントが規則的な構造認識メッシュモデルを作成するための適切なポリシーを学習できることを示しています。これは、提案されたRLフレームワークの実現可能性と有効性を示しています。 
[要約]モデラーは通常、一連のプリミティブを使用してメッシュモデルを作成します。ターゲットシェイプを3Dに解析する方法を学び、メッシュを編集します。詳細なマッピングを作成するために、エージェントは適切なポリシーを学習して、規則的な構造を作成します-対応メッシュモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-27">
        <br><font color="black">2020-03-27</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_59.html">
      <font color="black">Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News</font>
    </a>
  </h2>
  <font color="black">既存のアプローチはニューラルの偽のニュースから身を守るために提案されてきましたが、それらは一般的に記事がテキストとメタデータ（タイトルや著者など）しか持たないという非常に限られた設定に制限されています。視覚的意味の不整合を検出することに基づいた比較的効果的なアプローチを提供します。これは、効果的な防御の第一線として機能し、機械が生成する偽情報から守るための将来の作業の有用なリファレンスになります。または一般の人口を欺くことは主要な社会問題です。 
[ABSTRACT]画像、動画、自然言語モデルの急速な進歩により、効果的な防御メカニズムの必要性が高まっています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Document Structure Extraction using Prior based High Resolution
  Hierarchical Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_60.html">
      <font color="black">Document Structure Extraction using Prior based High Resolution
  Hierarchical Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">アブレーション手法と低解像度のバリエーションとの比較を通じて、ストリップベースのネットワークアーキテクチャの有効性を確立する実験を行います。さらに、ネットワークの機能を実証するために、1種類のドキュメント（フォーム）のみでトレーニングし、最新の状態を実現します他の一般的なドキュメントデータセットに対する最新の結果。新しい人間注釈付きフォームデータセットを紹介し、階層構造を抽出する際に、このデータセットのさまざまなセグメンテーションベースラインよりも本手法が大幅に優れていることを示します。 
[要約]紙とドキュメントのフォームを最新のhtmlベースのフォームに自動変換するために、アドビのaemフォームでこの方法が使用されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-27">
        <br><font color="black">2019-11-27</font>
      </time>
    </span>
</section>
<!-- paper0: MoPro: Webly Supervised Learning with Momentum Prototypes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_61.html">
      <font color="black">MoPro: Webly Supervised Learning with Momentum Prototypes</font>
    </a>
  </h2>
  <font color="black">また、MoProは、事前トレーニング済みのモデルを下流の画像分類および検出タスクに転送すると、優れたパフォーマンスを発揮します。MoProは、弱くラベル付けされたノイズの多いデータセットであるWebVisionで最先端のパフォーマンスを実現します。さらに、MoProは、分布シフト。 
[ABSTRACT] 3Dラベル付きのノイズデータセットであるmotrained moproは、webvision.motrainedモデルでトレーニングされていないパフォーマンスを実現します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet
  without Tricks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_62.html">
      <font color="black">MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet
  without Tricks</font>
    </a>
  </h2>
  <font color="black">私たちのコードとモデルは、https：//github.com/szq0214/MEAL-V2。で入手できます。このような単純なフレームワークは、次のような一般的に使用される手法を使用せずに、最先端の結果を達成できることを示しています。 1）アーキテクチャの変更。 2）ImageNetを超えた外部トレーニングデータ。 3）autoaug / randaug; 4）コサイン学習率; 5）ミックスアップ/カットミックストレーニング; 6）ラベル平滑化;このペーパーでは、トリックなしでImageNetのバニラResNet-50を80％+トップ1の精度に上げることができるシンプルで効果的なアプローチを紹介します。 
[ABSTRACT] autonetによると、提案された食事に基づいた方法が可能です。メソッドは以前の状態を超えることができます-同じネットワーク構造の下で驚くべきマージンで最先端の</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning Approaches to Classification of Production Technology for
  19th Century Books -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_63.html">
      <font color="black">Deep Learning Approaches to Classification of Production Technology for
  19th Century Books</font>
    </a>
  </h2>
  <font color="black">生産技術に基づいて画像を分類することを目的とした分類実験を報告します。19世紀の児童書に関する研究は、コンピュータシステムによってサポートできます。文化研究は、知識の普及プロセスと社会的および技術的実践の理解に専念しています。本業界。 
[ABSTRACT] 19世紀の本のイラストの技術は、木または銅の彫刻からリソグラフィーへの移行を特徴としていました。人間にとっても困難なパフォーマンスタスクの場合、分類品質は約70％にすぎません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Image Retrieval for Structure-from-Motion via Graph Convolutional
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_64.html">
      <font color="black">Image Retrieval for Structure-from-Motion via Graph Convolutional
  Network</font>
    </a>
  </h2>
  <font color="black">さらに、提案されたアプローチは、最新の照合可能な検索方法と比較して、再構成の精度と完全性を犠牲にすることなく、無駄な照合を大幅に削減します。入力データとしてクエリ画像を囲むサブグラフを作成することにより、学習可能なGCNを採用します。サブグラフ内のノードがクエリ写真と重複する領域を持っているかどうかを利用します。重要なアイデアは、クエリ画像の周りの特徴空間のローカルコンテキストに、この画像とその近傍との一致可能な関係に関する豊富な情報が含まれていることです。 
[要約]新しい方法はグラフ畳み込みネットワーク（gcn）に基づいています。冗長性なしで一致を生成するように機能します、と研究者は言います。彼らは何が起こったかを調べるのに時間の無駄だと言っています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Online Alternate Generator against Adversarial Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_65.html">
      <font color="black">Online Alternate Generator against Adversarial Attacks</font>
    </a>
  </h2>
  <font color="black">提案された方法は、敵のノイズを削除または破壊する代わりに、入力画像の別の画像を最初からオンラインで合成することで機能します。攻撃者が悪用する事前学習済みパラメーターを回避するために、推論段階でジェネレーターと合成画像を交互に更新します。実験結果提案されている防御的なスキームと方法が、一連の最先端の防御モデルよりもグレーボックスの敵対的攻撃に対して優れていることを示しています。 
[ABSTRACT]オンライン代替ジェネレーターは、ターゲットネットワークのパラメーターにアクセスまたは変更する必要はありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Few-Shot Unsupervised Continual Learning through Meta-Examples -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_66.html">
      <font color="black">Few-Shot Unsupervised Continual Learning through Meta-Examples</font>
    </a>
  </h2>
  <font color="black">少数ショット学習ベンチマークの実験結果は、監視ありの場合と比較しても競争力のあるパフォーマンスを示しています。私たちは、破滅的な忘却を同時に軽減し、新しいタスク（一般化されたものも含む）への一般化を優先するメタ学習スキームを活用します。メタ最適化中に機能の再利用を促進するために、自己注意メカニズムを使用して達成された集約表現を利用して単一の内部ループを活用します。 
[ABSTRACT]既存のディープラーニングソリューションの多くは、アプリケーションの範囲が限られています。これらには、集約された表現を利用する単一のインナーラボが含まれます。これらの結果は、学習の再利用を促進し、再利用を促進するために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Identify Physical Parameters from Video Using Differentiable
  Physics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_67.html">
      <font color="black">Learning to Identify Physical Parameters from Video Using Differentiable
  Physics</font>
    </a>
  </h2>
  <font color="black">私たちの実験のシミュレーションシナリオは、物体の押し出し、スライド、衝突を含み、物理特性の可観測性も分析します。実験では、ネットワークが画像をエンコードし、動画から質量や摩擦などの物理特性を特定できることを示しています。シミュレートされたシナリオでのアクションシーケンス。ネットワークをトレーニングし、物理的特性を識別するために、教師ありおよび教師ありの学習方法を提案します。 
[ABSTRACT]ビデオ予測モデルは、シーンからエンコードされてデコードされて画像に戻されるビデオの潜在表現を学習することがよくあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Rethinking Softmax with Cross-Entropy: Neural Network Classifier as
  Mutual Information Estimator -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_68.html">
      <font color="black">Rethinking Softmax with Cross-Entropy: Neural Network Classifier as
  Mutual Information Estimator</font>
    </a>
  </h2>
  <font color="black">このために、情報の違いに基づいて特定のラベルに最も関連する入力画像の領域を強調表示するinfoCAM、有益なクラスアクティベーションマップを提案します。合成データセットと実際のデータセットの実験を通じて、ソフトマックスクロスエントロピーは相互情報を概算できます。アクティベーションマップは、入力画像内のターゲットオブジェクトの位置を特定するのに役立ちます。 
[ABSTRACT]画像分類に適用すると、この関係はネットワーク構造を変更せずに入力画像とラベル間のポイントごとの相互情報を設定するのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br><font color="black">2019-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: POMP: Pomcp-based Online Motion Planning for active visual search in
  indoor environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_69.html">
      <font color="black">POMP: Pomcp-based Online Motion Planning for active visual search in
  indoor environments</font>
    </a>
  </h2>
  <font color="black">環境のフロアマップの情報、通常は入手可能な情報、またはアプリオリな単一の探索実行から簡単に抽出できる情報のみが必要です。強化学習の現在の最新技術とは異なり、POMPは大規模で高価なものを必要としません。 （時間と計算で）ラベル付けされたデータなので、中小規模の実際のシナリオでAVSを解決するのに非常に俊敏です。これにより、手元にある既知のシナリオを反復し、環境を探索してオブジェクトを検索することで、次の動きを決定できます同時に。 
[ABSTRACT] pompメソッドは、エージェントの現在のポーズの入力として使用します。タスクは、エージェントをターゲットオブジェクトに近づける次の動きを計画することです。これにより、既知の問題を反復することにより、次の問題を決定できます手元のシナリオ、環境の探索とオブジェクトの検索を同時に行う</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Model-based approach for analyzing prevalence of nuclear cataracts in
  elderly residents -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_70.html">
      <font color="black">Model-based approach for analyzing prevalence of nuclear cataracts in
  elderly residents</font>
    </a>
  </h2>
  <font color="black">核白内障の位置と一致するレンズの中央と後部周辺の温度はより高くなりました。核白内障の有病率と計算された累積熱線量との間に強い相関（調整されたR2&gt; 0.85）が観察されましたlens ..熱帯地域の高齢者を考慮するために体温調節反応モデルが拡張されました。 
[要約]核の白内障の有病率は、熱帯地域の高齢者の方が密接に関連しているよりも高い。周囲条件への曝露による水晶体の温度上昇は、50〜60歳の被験者で理論的に定量化された。水晶体の経時変化アジアの5つの都市のさまざまな気象条件の気温が計算されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Crossing You in Style: Cross-modal Style Transfer from Music to Visual
  Arts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_71.html">
      <font color="black">Crossing You in Style: Cross-modal Style Transfer from Music to Visual
  Arts</font>
    </a>
  </h2>
  <font color="black">音楽からビジュアルへのスタイルの転送は、創造性の実践において挑戦的でありながら重要なクロスモーダル学習問題です。実験は、数十年ごとにリストされた西洋音楽の録音や絵画を含む新しくコンパイルされたデータセットであるWikiArt-IMSLPで行われます。このネットワークは画像転送方法と統合され、スタイル転送プロセスを実行します。 
[ABSTRACT]音楽視覚化ネットワークは、エンコーダー-ジェネレーターアーキテクチャを使用して、音楽データから画像ベースの音楽表現を生成します。ネットワークは、西洋音楽の録音と絵画の新しいデータセットに基づいており、数十年ごとにリストされています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Phase Correlation for End-to-End Heterogeneous Sensor Measurements
  Matching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_72.html">
      <font color="black">Deep Phase Correlation for End-to-End Heterogeneous Sensor Measurements
  Matching</font>
    </a>
  </h2>
  <font color="black">シミュレーションデータと、衛星または空中ロボットによって取得された不均一なセンサー画像と空中画像で構成されるAero-Ground Datasetの両方でシステムを評価します。結果は、本手法が不均一なセンサー測定値と一致し、従来の比較のパフォーマンスより優れていることを示しています。位相相関と他の学習ベースの方法..また、以前のいくつかの方法で徹底的な評価を排除し、効率を向上させます。 
[ABSTRACT]結果は、私たちの方法が異種センサー測定値に一致できることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-21">
        <br><font color="black">2020-08-21</font>
      </time>
    </span>
</section>
<!-- paper0: Noisy Concurrent Training for Efficient Learning under Label Noise -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_73.html">
      <font color="black">Noisy Concurrent Training for Efficient Learning under Label Noise</font>
    </a>
  </h2>
  <font color="black">NCTはまた、後の段階での記憶を回避するためにターゲットの変動性を徐々に増加させます。 DNNでの暗記と一般化の抑止力としての各バッチのトレーニングサンプルの例。ディープニューラルネットワーク（DNN）は、ラベルノイズの下では効果的に学習できず、一般化パフォーマンスに影響を与えるランダムラベルを記憶することが示されています。 
[ABSTRACT] dnsは、ノイズの多いラベルを記憶する前に、最初に単純なパターンの学習を優先する傾向があります。トレーニングが進むにつれて、2つのモデルはコンセンサスにますます依存するようになります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Decision-based Universal Adversarial Attack -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_74.html">
      <font color="black">Decision-based Universal Adversarial Attack</font>
    </a>
  </h2>
  <font color="black">単一の摂動は、最も自然な画像を分類子によって誤って分類される可能性があります。さらに、上部の畳み込み層はストライプに敏感であるため、直交行列に基づくストライプのようなテクスチャーを持つ単一の摂動を生成する敵を設計することを目指しています。データ、提案された敵は、最終的に推定されたラベルのみに基づいて摂動を計算しますが、モデル全体だけでなく、さまざまなビジョンタスクにまたがる優れた転送可能性が実現されています。 
[ABSTRACT]現在の普遍的な敵対的な攻撃方法は、代用モデルを使用して摂動を生成し、次に摂動したモデルに摂動を適用します。この目的のために、効率的な意思決定ベースの普遍的な攻撃（duattack）を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: A Fourier Perspective on Model Robustness in Computer Vision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CV/paper_75.html">
      <font color="black">A Fourier Perspective on Model Robustness in Computer Vision</font>
    </a>
  </h2>
  <font color="black">これは、データ拡張を介してこれらのトレードオフを緩和する1つの方法は、より多様な拡張のセットを使用することであることを示唆しています。低周波領域で。データの増強は、ロバスト性を改善するために一般的に使用されるアプローチですが、ロバストネスのゲインは、通常、破損タイプ全体で均一ではありません。 
[ABSTRACT]高速追跡データ拡張は、改善に一般的に使用されるアプローチです。ただし、結果は通常、破損タイプ全体で均一ではありません。これらのトレードオフが発生する時期と理由を理解することは、それらを軽減するための重要なステップです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-21">
        <br><font color="black">2019-06-21</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Modeling Task Effects on Meaning Representation in the Brain via
  Zero-Shot MEG Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_0.html">
      <font color="black">Modeling Task Effects on Meaning Representation in the Brain via
  Zero-Shot MEG Prediction</font>
    </a>
  </h2>
  <font color="black">改善は、参加者が最初に単語を確認してから475〜550ミリ秒後に発生します。これは、単語のセマンティック処理の終了時間と見なされる時間に対応します。これらの結果は、単語のセマンティック処理の終了のみがタスク依存であることを示唆しています。 、および将来の研究に課題を提起し、タスクと刺激の関数として以前のタスク効果の新しい仮説を定式化します。異なるセマンティックタスクを実行しながら同じ単語を読む被験者の脳活動は、タスク間で異なることが示されています。 
[要約]異なるセマンティックタスクを実行しながら同じ単語を読む被験者の脳の活動は、タスク間で異なることが示されています。具体的な名詞についての質問に答えるタスクを課された参加者の脳磁図（meg）の脳の記録の研究</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: DSC IIT-ISM at SemEval-2020 Task 6: Boosting BERT with Dependencies for
  Definition Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_1.html">
      <font color="black">DSC IIT-ISM at SemEval-2020 Task 6: Boosting BERT with Dependencies for
  Definition Extraction</font>
    </a>
  </h2>
  <font color="black">私たちの提案するモデルは、BERTよりも優れた結果を生成し、文が定義を含むかどうかを分類する共有タスク（サブタスク1）であるDeftEval（SemEval 2020のタスク6）で微調整された言語モデルでBERTに匹敵する結果を達成します。定義抽出時のトランスフォーマーからの双方向エンコーダー表現（BERT）のパフォーマンス。さらに、依存関係をモデルに組み込むために、BERTとテキストレベルグラフ畳み込みネットワークの結合モデルを提案します。 
[ABSTRACT]さらに、バートとテキストレベルのグラフのたたみ込みネットワークの結合モデルを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Transformer-based Large Scale Language Representations using
  Hardware-friendly Block Structured Pruning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_2.html">
      <font color="black">Efficient Transformer-based Large Scale Language Representations using
  Hardware-friendly Block Structured Pruning</font>
    </a>
  </h2>
  <font color="black">一般言語理解評価（GLUE）ベンチマークタスクのさまざまなモデル（BERT、RoBERTa、およびDistilBERT）の実験結果は、特定のタスクで精度の低下がゼロまたはわずかで、最大5.0倍を達成することを示しています。この作業では、ハードウェアに適したブロック構造の剪定を使用して、効率的なトランスフォーマーベースの大規模言語表現を提案します。大幅に削減された重みのストレージと計算に加えて、提案されたアプローチは高い圧縮率を実現します。 
[ABSTRACT]ハードウェアプラットフォームでの限られた重量のストレージと速度は、特にエッジコンピューティングの時代において、事前トレーニング済みモデルを提供しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Meta-Learning for Few-Shot Natural Language
  Classification Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_3.html">
      <font color="black">Self-Supervised Meta-Learning for Few-Shot Natural Language
  Classification Tasks</font>
    </a>
  </h2>
  <font color="black">最近のメタ学習フレームワークを使用して、このタスクの分布についてトランスモデルをメタトレーニングします。これは、クローズスタイルの目的を使用して達成されますが、非表示にするトークンのみを収集することで、マルチクラス分類タスクを個別に作成します。少数の語彙用語。ただし、標準的なメタ学習手法では、一般化するために多くのトレーニングタスクが必要です。残念ながら、そのような監視対象タスクの多様なセットを見つけることは通常困難です。 
[要約]この論文では、ラベルなしテキストから大規模でリッチなメタ学習タスク分布を生成するための自己管理アプローチを提案しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Fully 8-bit Integer Inference for the Transformer Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_4.html">
      <font color="black">Towards Fully 8-bit Integer Inference for the Transformer Model</font>
    </a>
  </h2>
  <font color="black">必要に応じて逆量子化が採用され、ネットワークがより効率的になります。この作業では、トランスフォーマーアーキテクチャの原理的な変更後、整数トランスフォーマーと呼ばれる（ほぼ）完全に8ビットの整数推論アルゴリズムであるスケール伝播が可能であることを示します。 WMT16 En &lt;-&gt; Ro、WMT14 En &lt;-&gt; De、En-&gt; Frの変換タスク、およびWikiText-103言語モデリングタスクの実験では、完全に8ビットのトランスフォーマシステムが、浮動小数点ベースラインですが、必要なメモリフットプリントはほぼ4分の1です。 
[要旨]以前のシステムは、特定の機能については依然として浮動小数点に依存しています。これは、ネットワークをより効率的にするために使用できました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: g2pM: A Neural Grapheme-to-Phoneme Conversion Package for Mandarin
  Chinese Based on a New Open Benchmark Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_5.html">
      <font color="black">g2pM: A Neural Grapheme-to-Phoneme Conversion Package for Mandarin
  Chinese Based on a New Open Benchmark Dataset</font>
    </a>
  </h2>
  <font color="black">これらに動機付けされて、この研究では、中国のポリフォンの曖昧性解消のための99,000以上の文で構成される新しいベンチマークデータセットを紹介します。これに対処するために多くの学術的取り組みが行われていますが、標準のベンチマークとして機能するオープンなデータセットはありませんこれまでの公平な比較のために。シンプルなニューラルネットワークモデルをトレーニングし、他の既存のG2Pシステムよりも優れていることを確認します。 
[要約]報告されたシステムのほとんどは、中国語のテキストを中国語に変換したい研究者や実務家に採用するのが難しい</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br><font color="black">2020-04-07</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding Effects of Editing Tweets for News Sharing by Media
  Accounts through a Causal Inference Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_6.html">
      <font color="black">Understanding Effects of Editing Tweets for News Sharing by Media
  Accounts through a Causal Inference Framework</font>
    </a>
  </h2>
  <font color="black">さまざまな編集スタイルの影響を理解するために、メディアアウトレットは私たちの使いやすいツールを単独で適用することができます。より広いオーディエンスにリーチし、ニュース記事へのトラフィックを最適化するために、メディアアウトレットは通常、ソーシャルメディアアカウントを実行し、コンテンツをショートと共有しますテキストの要約..視聴者の関与におけるソーシャルメディア共有のニュースヘッドライン編集の影響を推定するために、因果推論手法とディープラーニングを組み込んだ体系的な分析を示します。傾向スコアマッチングを使用すると、類似したニュース記事が異なるスタイルで共有されている事実に反するケースと比較して、編集スタイルの潜在的な（不利な）利点を推定できます。 
[ABSTRACT]研究コミュニティは、どのような編集戦略が視聴者の関与を促進するのに効果的であるかについて十分なレベルの理解を持っていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Phenotyping of Clinical Notes with Improved Document Classification
  Models Using Contextualized Neural Language Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_7.html">
      <font color="black">Phenotyping of Clinical Notes with Improved Document Classification
  Models Using Contextualized Neural Language Models</font>
    </a>
  </h2>
  <font color="black">これらのアーキテクチャは、2つの表現型タイピングタスクで既存の最先端の方法と競合するか、またはそれを上回ることがわかります。したがって、臨床ノートのBERT表現のみに依存する表現型タイピングをモデリングするためのいくつかのアーキテクチャを探索し、手動エンジニアリングの必要性を排除します。臨床記録には、喫煙状況や心臓疾患の存在など、患者の健康状態の広範な記録が含まれています。 
[ABSTRACT]既存の調査により、重要なシステムであるが、多くの場合、ルールによるハンドエンジニアリングが必要</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-30">
        <br><font color="black">2019-10-30</font>
      </time>
    </span>
</section>
<!-- paper0: What if we had no Wikipedia? Domain-independent Term Extraction from a
  Large News Corpus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_8.html">
      <font color="black">What if we had no Wikipedia? Domain-independent Term Extraction from a
  Large News Corpus</font>
    </a>
  </h2>
  <font color="black">そのための5つのステップのパイプラインを提案し、5つすべてのベースライン結果、およびそれらのベンチマークに関連するデータセットを提供します。私たちの作業は、ドメイン固有の自動用語抽出問題に新たな光を投げかけます。 -独立した亜種です。過去20年間で最も印象的な人間の努力の1つは、ウィキペディアである無料でアクセス可能な形式での人間の知識の収集と分類です。 
[ABSTRACT]私たちは、大規模なニュースコーパスでそのような「wiki-価値のある」用語を特定することを目指しています。これは、実際のWikipediaエントリに依存しない、または最小限の依存関係で実行できます。問題の知識はドメイン固有の自動用語抽出問題</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervised pre-training and contrastive representation learning for
  multiple-choice video QA -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_9.html">
      <font color="black">Self-supervised pre-training and contrastive representation learning for
  multiple-choice video QA</font>
    </a>
  </h2>
  <font color="black">ビデオ質問応答（ビデオQA）では、与えられた質問に答えるために、ビデオと言語の両方のモダリティをきめ細かく理解する必要があります。メインステージでの対照的な学習のために、グラウンドトゥルースの回答に対応する入力にマスキングノイズを追加します。残りの部分を負のサンプルとして扱いながら、グラウンドトゥルースの回答の元の入力を正のサンプルと見なします。また、詳細な分析を通じてアプローチを検証します。 
[要約]このホワイトペーパーでは、多肢選択式のビデオ質問応答用の新しいトレーニングスキームを提案します。これらには、補助学習としてメインステージでの自己管理型コントラスト学習が含まれます。さらに、に対応する入力にマスキングノイズを追加します地面-真実の答え、残りを負のサンプルとして扱う</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Leverage Unlabeled Data for Abstractive Speech Summarization with
  Self-Supervised Learning and Back-Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_10.html">
      <font color="black">Leverage Unlabeled Data for Abstractive Speech Summarization with
  Self-Supervised Learning and Back-Summarization</font>
    </a>
  </h2>
  <font color="black">レポートは専門的に記述され、適切にフォーマットされているため、前処理は簡単です。このコンテキストでは、2つのアプローチを使用して、この膨大な量の非整列データを活用する方法を研究します。 -デコーダーモデル; （ii）逆要約生成された文字起こしに単一のレポートを合わせるために、レポートを与えられた文字起こしを予測することを学習することにより、要約プロセスを逆転させ、さらなるトレーニングのためにこの合成データセットを使用する
[要旨]フランスの会議の要約タスクには、会議の音声録音の自動マーカーに基づいてレポートが予測されるレポートが含まれます。一方、非常に大量の調整されていない手動の手動手動トレーニング、特に対応する入力のないレポートにアクセスできます。結果は両方の目的で以前のベースラインと一致しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-30">
        <br><font color="black">2020-07-30</font>
      </time>
    </span>
</section>
<!-- paper0: Fast and Accurate Sequence Labeling with Approximate Inference Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_11.html">
      <font color="black">Fast and Accurate Sequence Labeling with Approximate Inference Network</font>
    </a>
  </h2>
  <font color="black">このアルゴリズムに基づいて、ニューラルCRFモデルのエンコーダーと接続してエンドツーエンドのネットワークを形成できる近似推論ネットワークを設計します。これにより、並列化が可能になり、トレーニングと予測が高速化されます。ランダムフィールド（CRF）モデルは、最も広く使用されているニューラルシーケンスのラベリングアプローチの1つです。経験的な結果は、提案されたアプローチが、従来のCRFアプローチと比較して、長い文と競争力のある精度でデコード速度を12.7倍向上させることを示しています。 。 
[ABSTRACT] CRFモデルは正確な確率的アルゴリズムに基づいています。これらのアルゴリズムは通常、モデルのトレーニング段階と予測段階で適用されます。実験結果は、モデルが12倍の改善であることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-modal Summarization for Video-containing Documents -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_12.html">
      <font color="black">Multi-modal Summarization for Video-containing Documents</font>
    </a>
  </h2>
  <font color="black">包括的な実験は、提案されたモデルがマルチモーダル要約に有益であり、既存の方法よりも優れていることを示しています。したがって、ドキュメントとそれに関連するビデオから要約する新しいマルチモーダル要約タスクを提案します。ほとんどの既存のマルチモーダル要約は機能します。ただし、ビデオではなく画像から抽出された視覚的な補完機能を使用しているため、豊富な情報が失われています。 
[ABSTRACT]ただし、既存のマルチモーダル要約作業のほとんどは、ビデオではなく画像から抽出された視覚的な補完機能を使用しています。代わりに、バイホップの注意やブリッジを強化するための後期融合メカニズムなどの効果的な戦略を備えたベースライン一般モデルも構築しています異なるモダリティ間のギャップ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: ISCAS at SemEval-2020 Task 5: Pre-trained Transformers for
  Counterfactual Statement Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_13.html">
      <font color="black">ISCAS at SemEval-2020 Task 5: Pre-trained Transformers for
  Counterfactual Statement Modeling</font>
    </a>
  </h2>
  <font color="black">2つのサブシステムはどちらも評価で3位を達成しました。2番目のサブタスクでは、先行および結果抽出をクエリベースの質問応答問題として定式化します。当社のシステムはhttps://github.com/casnlu/ISCASで公開されています。 -SemEval2020Task5。 
[ABSTRACT]サブタスクは事前トレーニング済みのトランスフォーマーに基づいています。2番目のサブタスクでは、前件と結果の抽出を定式化します。サブタスクは質問ベースの質問回答問題です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Neural Event Coreference Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_14.html">
      <font color="black">End-to-End Neural Event Coreference Resolution</font>
    </a>
  </h2>
  <font color="black">さらに、イベントの言及は非常に多様化しており、イベントの相互参照は長距離の意味依存の決定によって複雑に管理されているため、E3Cニューラルネットワークではタイプガイドイベントの相互参照メカニズムがさらに提案されています。 2つの標準データセットでの最先端のパフォーマンス。従来のイベント相互参照システムは、通常、パイプラインフレームワークと手作りの機能に依存しており、エラー伝播の問題に直面し、汎化能力が低いことがよくあります。 
[ABSTRACT] e3cニューラルネットワークは、イベント検出とイベント共参照解決タスクを共同でモデル化し、生のテキストから自動的に特徴を抽出する方法を学ぶことができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Grounded Adaptation for Zero-shot Executable Semantic Parsing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_15.html">
      <font color="black">Grounded Adaptation for Zero-shot Executable Semantic Parsing</font>
    </a>
  </h2>
  <font color="black">私たちの分析は、GAZPがトレーニング環境でのデータ拡張より優れており、GAZP合成データの量に応じてパフォーマンスが向上し、サイクルの一貫性が適応の成功の中心であるということを示しています。新しいデータベーススキーマ）..発話とSQLクエリ）新しい次に、パーサーを適応させるために、サイクルの一貫した例を選択します。 
[ABSTRACT] gazpを使用すると、ユーザーはサイクルに適応できます-パーサーを適応させる一貫した例.gazpは、データのフォームと実行の精度のシミュレーションを改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Recurrent Interaction Network for Jointly Extracting Entities and
  Classifying Relations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_16.html">
      <font color="black">Recurrent Interaction Network for Jointly Extracting Entities and
  Classifying Relations</font>
    </a>
  </h2>
  <font color="black">2つの実世界のデータセットに関する実証研究により、提案されたモデルの優位性が確認されています。ただし、このようなアプローチでは、2つのタスク間の明示的な相互作用を学習して、個々のタスクのパフォーマンスを向上させることができません。マルチタスクを使用するアイデアエンティティと関係の共同抽出に対処するための学習アプローチは、エンティティ認識タスクと関係分類タスクの間の関連性によって動機付けられます。 
[ABSTRACT]問題に対処するための既存の方法は、共有ネットワークを介して2つのタスク間の相互作用を学習し、共有情報はタスクに渡されます-予測のための特定のネットワーク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: A Probabilistic End-To-End Task-Oriented Dialog Model with Latent Belief
  States towards Semi-Supervised Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_17.html">
      <font color="black">A Probabilistic End-To-End Task-Oriented Dialog Model with Latent Belief
  States towards Semi-Supervised Learning</font>
    </a>
  </h2>
  <font color="black">驚くべきことに、MultiWOZでのパフォーマンスの損失なしに、注釈の要求を50％に減らすことができます。信念状態が離散潜在変数として表され、システム応答と共同でモデル化される、潜在信念状態（LABES）モデルと呼ばれる確率的対話モデルを提案します。与えられたユーザー入力..構造化された信念状態は、タスク指向のダイアログシステムでのユーザーの目標の追跡とデータベースクエリにとって非常に重要です。 
[ABSTRACT]潜在的信念状態（labes）モデルを使用すると、ユーザーの発話について詳しく知ることができます。これは、「潜在的信念」と呼ばれる確率的対話モデルと呼ばれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: RDF2Vec Light -- A Lightweight Approach for Knowledge Graph Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_18.html">
      <font color="black">RDF2Vec Light -- A Lightweight Approach for Knowledge Graph Embeddings</font>
    </a>
  </h2>
  <font color="black">すべてのノードとエッジ..私たちの方法では、ランタイムが大幅に低下し、ハードウェア要件が大幅に削減されたため、以前はそのような埋め込みが不可能であったシナリオで、非常に大きなナレッジグラフの埋め込みを適用できます。ただし、ほとんどのダウンストリームアプリケーションシナリオでは、概念の小さなサブセットが実際に重要です。 
[ABSTRACT]現在のアプローチは完全なナレッジグラフの埋め込みに焦点を当てています。これらには非常に大きなナレッジグラフの埋め込みが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Generating Label Cohesive and Well-Formed Adversarial Claims -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_19.html">
      <font color="black">Generating Label Cohesive and Well-Formed Adversarial Claims</font>
    </a>
  </h2>
  <font color="black">ここでは、グラウンドトゥルースの意味を保持し、意味的に有効であるファクトチェックシステムに対して敵対的な攻撃を生成する方法を調査します。ファクトチェックモデルのターゲットクラスの損失と補助自然言語推論モデルの含意クラスの損失。ただし、ファクトチェックなどの推論タスクでは、これらのトリガーが挿入されたインスタンスの意味を誤って逆にすることがよくあります。 class.butこのような攻撃は意味的に無意味なインジケーターを生成します。ユニバーサルトリガーの生成に使用されるホットフリップ攻撃アルゴリズムを拡張しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: A Computational Approach to Understanding Empathy Expressed in
  Text-Based Mental Health Support -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_20.html">
      <font color="black">A Computational Approach to Understanding Empathy Expressed in
  Text-Based Mental Health Support</font>
    </a>
  </h2>
  <font color="black">共感は、メンタルヘルスのサポートを成功させるために不可欠です。テキストベースの会話で共感のコミュニケーションを特徴付けるための、理論に基づいた新しい統一フレームワークを開発します。実験により、私たちのアプローチが共感的な会話を効果的に識別できることが実証されています。 
[ABSTRACT]共感の測定は、主に対面の設定で行われています。調査は、私たちのアプローチが共感的な会話を効果的に識別できることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: GraphCodeBERT: Pre-training Code Representations with Data Flow -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_21.html">
      <font color="black">GraphCodeBERT: Pre-training Code Representations with Data Flow</font>
    </a>
  </h2>
  <font color="black">結果は、コード構造と新しく導入された事前トレーニングタスクがGraphCodeBERTを改善し、4つのダウンストリームタスクで最先端のパフォーマンスを達成できることを示しています。プログラミング言語の事前トレーニングモデルであるGraphCodeBERTを提示します。 code ..このようなセマンティックレベルの構造はきちんとしていて、ASTの不必要に深い階層をもたらさず、その特性によりモデルがより効率的になります。 
[ABSTRACT]既存のモデルは、コードスニペットを一連のトークンと見なします。ただし、既存のモデルは、コードの構文レベルの構造を取りません。これらには、セマンティックコードである事前トレーニング段階が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Multi^2OIE: Multilingual Open Information Extraction based on Multi-Head
  Attention with BERT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_22.html">
      <font color="black">Multi^2OIE: Multilingual Open Information Extraction based on Multi-Head
  Attention with BERT</font>
    </a>
  </h2>
  <font color="black">2つの言語（スペイン語とポルトガル語）に導入された新しいベンチマークデータセットの実験結果は、ターゲット言語のトレーニングデータがなくても、モデルが他の多言語システムよりも優れていることを示しています。以前に使用されていた、マルチヘッドアテンションを備えた双方向の長期短期メモリアーキテクチャ。Multi^ 2OIEは、Re-OIE2016とCaRBの2つのベンチマーク評価データセットで、高い計算効率で既存のシーケンスラベリングシステムより優れています。 
[ABSTRACT]モデルがシーケンスであることを証明できる必要があります-効果的で効果的な議論の方法を備えたラベル付けシステム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Named entity recognition in chemical patents using ensemble of
  contextual language models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_23.html">
      <font color="black">Named entity recognition in chemical patents using ensemble of
  contextual language models</font>
    </a>
  </h2>
  <font color="black">多数決アンサンブルアプローチに基づく私たちの最高のモデルは、92.30％の正確なF1スコアと96.24％のリラックスしたF1スコアを実現します。特許..私たちは、新しいアンサンブルモデルを提案するために、一般的で専門的なコーパスでトレーニングされたトランスフォーマアーキテクチャを評価します。 
[ABSTRACT]ケミンインフォマティクスの別のメルボルン大学の課題の研究者は、化学特許の反応情報を抽出するための言語モデルの有効性を評価しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-24">
        <br><font color="black">2020-07-24</font>
      </time>
    </span>
</section>
<!-- paper0: Code-switching pre-training for neural machine translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_24.html">
      <font color="black">Code-switching pre-training for neural machine translation</font>
    </a>
  </h2>
  <font color="black">このようにして、CSPは、ソースとターゲットの単一言語コーパスから抽出されたクロスリンガルアラインメント情報を最大限に活用することにより、NMTモデルを事前トレーニングできます。このホワイトペーパーでは、コードスイッチングと呼ばれる新しい事前トレーニング方法を提案します。ニューラル機械翻訳（NMT）の事前トレーニング（略してCSP）。.CSPは、エンコーダーデコーダーフレームワークを採用しています。そのエンコーダーはコード混合文を入力として受け取り、デコーダーは入力文の置き換えられたフラグメントを予測します。 
[ABSTRACT]提案されたcspは、ソース文の一部の単語をターゲット言語の翻訳語でランダムに置き換えます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: An information theoretic view on selecting linguistic probes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_25.html">
      <font color="black">An information theoretic view on selecting linguistic probes</font>
    </a>
  </h2>
  <font color="black">（2020）チャレンジド..この二分法が有効な情報であることが理論的に示されています。.さらに、2つの論文、* control task *（Hewitt and Liang、2019）および*によって提案された優れたプローブを構築および選択する方法が見つかりました。制御関数*（Pimentel et al。、2020）は同等です-それらのアプローチのエラーは同一です（モジュロの無関係な用語）。 
[ABSTRACT]内部表現から教師付き分類を実行するために診断分類子を割り当てる一般的なアプローチがあります。ただし、一部の研究では、診断分類自体のパフォーマンスが不十分であることが示されています。この二分法は有効な情報であることを示しています-理論上</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: A Multimodal Memes Classification: A Survey and Open Research Issues -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_26.html">
      <font color="black">A Multimodal Memes Classification: A Survey and Open Research Issues</font>
    </a>
  </h2>
  <font color="black">最後に、いくつかの未解決の研究の問題と課題を特定して明確にします。それは、ジョーク、皮肉、やる気などの形で、ソーシャルメディアプラットフォームで主に広がっています。他のVLで大幅に実行された最先端の方法データセット、ミーム分類に失敗する傾向があります。 
[ABSTRACT]ミームは、ジョーク、皮肉、やる気などの形で、ソーシャルメディアプラットフォームで主に広まっています。これは、他のvlデータセットで大幅に実行された最先端の方法が原因であり、ミームの分類に失敗する傾向があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_27.html">
      <font color="black">Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News</font>
    </a>
  </h2>
  <font color="black">攻撃者が利用できる潜在的な弱点を特定するために、4種類の生成された記事で構成されるNeuralNewsデータセットを作成し、このデータセットに基づいて一連の人間のユーザー調査実験を行います。このホワイトペーパーでは、より現実的な画像とキャプションも含む機械で生成されたニュースを防御するという困難なタスク。画像、ビデオ、および自然言語生成モデルの急速な進歩は、この状況をさらに悪化させ、効果的な防御メカニズムの必要性を強めています。 
[ABSTRACT]画像、動画、自然言語モデルの急速な進歩により、効果的な防御メカニズムの必要性が高まっています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: More Embeddings, Better Sequence Labelers? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_28.html">
      <font color="black">More Embeddings, Better Sequence Labelers?</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、18のデータセットと8つの言語の3つのタスクで広範な実験を行い、さまざまな埋め込み連結によるシーケンスのラベル付けの精度を調査し、3つの観察を行います。（1）より多くの埋め込みバリアントを連結すると、リッチリソースとクロスの精度が向上します。 -ドメイン設定と低リソース設定のいくつかの条件。 （2）追加のコンテキストサブワードの埋め込みとコンテキスト文字の埋め込みを連結すると、非常に低いリソースの設定で精度が低下します。 （3）（1）の結論に基づいて、追加の同様のコンテキスト埋め込みを連結しても、それ以上の改善にはつながりません。最近の研究では、非コンテキスト埋め込みよりもシーケンスラベラーの精度を大幅に向上させるコンテキスト埋め込みのファミリーが提案されています。結論は、人々がさまざまな設定でより強力なシーケンスラベラーを構築するのに役立ちます。 
[ABSTRACT]埋め込みは以前考えられていたよりも一般的ですが、これが改善できるかどうかについての即時の結論はありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: On the Transferability of Minimal Prediction Preserving Inputs in
  Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_29.html">
      <font color="black">On the Transferability of Minimal Prediction Preserving Inputs in
  Question Answering</font>
    </a>
  </h2>
  <font color="black">ランダムトレーニングシード、モデルアーキテクチャ、事前トレーニング、およびトレーニングドメインに対するMPPIの複雑な不変性を発見しました。これらの結果は、MPPIの解釈可能性がこれらのモデルの一般化能力を特徴付けるには不十分であることを示唆しています。最近の研究（Feng et al。、2018）神経モデルで高い信頼性と精度をもたらす、解釈不能な短い入力フラグメントの存在を確立します。 
[ABSTRACT]ランダムトレーニングシード、モデルアーキテクチャ、事前トレーニング、トレーニングドメインへの複雑な不変性を発見しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: A Deep Learning Approach to Geographical Candidate Selection through
  Toponym Matching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_30.html">
      <font color="black">A Deep Learning Approach to Geographical Candidate Selection through
  Toponym Matching</font>
    </a>
  </h2>
  <font color="black">さまざまな困難なシナリオ（言語間や地域の違い、OCRエラーなど）をカバーする、いくつかの新しい現実的なデータセットに基づいて、固有の音韻一致評価を実行します。候補の選択は、参照できる潜在的なエンティティを識別するタスクです以前に認識されたトポニムによって..エンティティの解決）、特に騒々しいまたは非標準のテキストで。 
[ABSTRACT]この論文では、最先端のニューラルネットワークアーキテクチャを使用した、トポニムマッチングによる候補選択のための柔軟な深層学習手法を紹介します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Evaluating Interactive Summarization: an Expansion-Based Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_31.html">
      <font color="black">Evaluating Interactive Summarization: an Expansion-Based Framework</font>
    </a>
  </h2>
  <font color="black">この目的のために開発したベースライン実装を評価および比較することにより、フレームワークの使用法を示します。これは、ベンチマークの一部として機能します。ユーザーがマルチドキュメントサマライザを操作できるようにすることは、サマリ結果の改善とカスタマイズに向けた有望な方向です。インタラクティブな要約のためのさまざまなアイデアが以前の研究で提案されましたが、これらのソリューションは非常に分岐しており、比類がありません。 
[要旨]ベンチマークの一部として機能する見込みのある目的のために開発したアカウントを評価および比較することにより、フレームワークの使用を実証しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: FewJoint: A Few-shot Learning Benchmark for Joint Language Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_32.html">
      <font color="black">FewJoint: A Few-shot Learning Benchmark for Joint Language Understanding</font>
    </a>
  </h2>
  <font color="black">実験のセットアップを容易にする互換性のあるFSLプラットフォームも提供します。このホワイトペーパーでは、NLPの新しいFew-Shot LearningベンチマークであるFewJointを示します。私たちのベンチマークは、構造予測とマルチタスク依存問題をさらにカバーする、数ショットの共同対話言語理解を紹介します。 
[要約]自然言語処理（nlp）でのfslの進行が非常に遅い</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Compositional and Lexical Semantics in RoBERTa, BERT and DistilBERT: A
  Case Study on CoQA -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_33.html">
      <font color="black">Compositional and Lexical Semantics in RoBERTa, BERT and DistilBERT: A
  Case Study on CoQA</font>
    </a>
  </h2>
  <font color="black">体系的なエラー分析を通じて、微調整されたRoBERTa、BERT、およびDistilBERTモデルの問題のある領域を特定します-基本的な算術（句の数え上げ）、合成セマンティクス（否定とセマンティックロールのラベル付け）、および語彙セマンティクス（驚きと反意）。この論文では、会話型質問応答（CoQA）タスクのコンテキストで言語モデルによって説明される言語現象のタイプ。拡張モデルのアンサンブルは、F1スコア全体で2.2〜2.7ポイント、F1スコアで最大42.1ポイントのブーストをもたらします。最も難しい質問クラス。 
[要約]結果は、roberta、bert、およびditilbertの間の構成情報および語彙情報を表す能力の違いを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: AMR Similarity Metrics from Principles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/cs.CL/paper_34.html">
      <font color="black">AMR Similarity Metrics from Principles</font>
    </a>
  </h2>
  <font color="black">たとえば、それは識別不能ルールのアイデンティティに適合せず、制御するのが難しいバイアスを導入します。 iii）私たちは、非常にわずかな意味の逸脱にのみより好意的であり、確立されたすべての基準の達成を目標とする新しいメトリックS $ ^ 2 $ matchを提案します。翻訳メトリックブルー（Papineni et al。、2002）。変数の配置を削除することで計算効率を向上させます。抽象意味表現（AMR）グラフを比較するために、さまざまなメトリックが提案されています。 
[ABSTRACT]新しい意味は、メトリックを意味する2つのメトリックに基づいています。これは、ファクトsmatchとsembleuに基づいています。たとえば、私たちはその適合性を評価し、その利点を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-29">
        <br><font color="black">2020-01-29</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Online Speaker Diarization with Relation Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/eess.AS/paper_0.html">
      <font color="black">Online Speaker Diarization with Relation Network</font>
    </a>
  </h2>
  <font color="black">RenoSDの最も印象的な機能は、話者IDの関連付けにメタ学習戦略を採用していることです。AMIおよびCALLHOMEデータセットの実験結果は、提案されたRenoSDシステムが最新のxベクトルベースラインに対して一貫した改善を達成していることを示しています。 ..特に、関係ネットワークは、データ主導の方法で遠距離メトリックを学習することを学習し、単純なフォワードパスを介して、指定された2つのセグメントが同じ話者に属しているかどうかを判断できます。 
[要約]提案されたrenosdシステムは、単一のディープニューラルネットワークを使用して、音声-アクティビティ-検出と話者IDの関連付けを組み合わせます。2つの特定のセグメントが同じ話者に属しているかどうかを、単純な転送パスで判断できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Silent Speech Interfaces for Speech Restoration: A Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/eess.AS/paper_1.html">
      <font color="black">Silent Speech Interfaces for Speech Restoration: A Review</font>
    </a>
  </h2>
  <font color="black">障害に応じて、一部のセンシング手法は他の手法よりも音声関連情報のキャプチャに適している場合があります。したがって、このホワイトペーパーで説明するように、SSIを実際の世界に昇格させる前に、今後の研究で多くの課題に取り組む必要があります。アプリケーション..このレビューでは、サイレントスピーチインターフェイス（SSI）研究の状況をまとめています。 
[ABSTRACT] ssisは、サイレントコミュニケーションを可能にするさまざまな生体信号を使用できます。これらには、神経活動の電気生理学的記録、声道の動きの筋電図（emg）記録が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-04">
        <br><font color="black">2020-09-04</font>
      </time>
    </span>
</section>
<!-- paper0: Utterance-level Intent Recognition from Keywords -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/eess.AS/paper_2.html">
      <font color="black">Utterance-level Intent Recognition from Keywords</font>
    </a>
  </h2>
  <font color="black">キーワードシーケンスは、4つのタイプの入力機能に変換されます。つまり、音響、電話、word2vec、speech2vecで、個々の意図学習とその後の意思決定の融合です。発話レベルの意図分類のアプローチは、代わりに発話内のキーワードのシーケンスに基づいています。ウェイクインテントが検出された場合、後で電力コストのかかるASRがトリガーされます。 
[要約]発話レベルのインテント分類のアプローチは、単一の固定キーフレーズではなく一連のキーワードに基づいています。システムは、単一のキーフレーズではなく、発話で4つのキーワードを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Temporally Guided Music-to-Body-Movement Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-18/eess.AS/paper_3.html">
      <font color="black">Temporally Guided Music-to-Body-Movement Generation</font>
    </a>
  </h2>
  <font color="black">デコーダーには、右側の動作とお辞儀の攻撃のタイミングを強調するために、洗練されたネットワークとお辞儀攻撃の推論メカニズムが付属しています。客観的評価と主観的評価の両方により、提案されたモデルが最新の方法よりも優れていることがわかります。私たちの知る限りでは、この作品は、音楽の体の動きの主要な機能を考慮した3次元バイオリニストの体の動きを生成する最初の試みを表しています。 
[要約]これは3-dヴァイオリニストの体の動きを生成する最初の試みです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
