<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-12-23の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Adjust-free adversarial example generation in speech recognition using
  evolutionary multi-objective optimization under black-box condition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.SD/paper_0.html">
      <font color="black">Adjust-free adversarial example generation in speech recognition using
  evolutionary multi-objective optimization under black-box condition</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案された方法が、タイミングラグに対して十分にロバストであり、攻撃者がターゲットスピーチに対してそれを再生するタイミングを取る必要がない、調整のない敵対的な例を首尾よく生成したことを示した。この論文は、ブラックボックス敵対者を提案する。自動音声認識システムへの攻撃方法..この論文で提案された方法は、ブラックボックスシナリオの下でロバストな敵対的な例を生成することを可能にする進化的多目的最適化（EMO）を採用しています。 
[概要]一部の研究では、音声認識のためにニューラルネットワークを攻撃しようとしましたが、これらの方法では、ターゲット音声とのタイミングラグに対する敵対的な例の堅牢性は考慮されていませんでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: On the effectiveness of signal decomposition, feature extraction and
  selection on lung sound classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.SD/paper_1.html">
      <font color="black">On the effectiveness of signal decomposition, feature extraction and
  selection on lung sound classification</font>
    </a>
  </h2>
  <font color="black">Mel周波数ケプストラム係数とともに高次の統計的およびスペクトル的特徴がクラシエに供給されると、kNN分類器で最高のパフォーマンスが得られ、最高の精度が得られることがわかります。Kaggleからダウンロードされたオープンソースデータセット。さまざまな品質の胸部聴診を使用して、さまざまな分解と特徴抽出の組み合わせを使用した結果を決定します。経験的モード分解、アンサンブル経験的モード分解、離散ウェーブレット変換などの分解方法が、主要コンポーネントなどのいくつかの特徴抽出手法とともに使用されます。分析と自動エンコーダー。特定のタスクに対してさまざまな分類子がどのように実行されるかを調べます。 
[概要]肺音は非水平ですが、通常ほど正常ではありません。これらは肺音と呼ばれ、肺音と互換性がありません。これらのタイプの分析は、さまざまな分解を使用した結果を決定するために使用されます。特徴選択方法の組み合わせを使用すると、分類器の精度に悪影響を与えることなく、入力特徴の数を大幅に減らすことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Meta Sampling for Multilingual Low-Resource Speech
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.SD/paper_2.html">
      <font color="black">Adversarial Meta Sampling for Multilingual Low-Resource Speech
  Recognition</font>
    </a>
  </h2>
  <font color="black">低リソースのターゲット言語データではASRモデルを適切にトレーニングできないため、低リソースの自動音声認識（ASR）は困難です。具体的には、各ソース言語について、クエリの損失が大きい場合、そのタスクが適切でないことを意味します。量と難易度の観点からASRモデルをトレーニングするためにサンプリングされるため、追加の学習のためにより頻繁にサンプリングする必要があります。MML-ASRでタスクをサンプリングする場合、AMSは各ソース言語のタスクサンプリング確率を適応的に決定します。 
[要約]各ソース言語について、質問の損失が大きい場合、そのタスクは、量と難易度の観点からasrモデルをトレーニングするために十分にサンプリングされていないことを意味します。mml-asrのリソースは学習状況をマスターできるため、予測できます。各言語の良好なタスクサンプリング確率</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Deep learning-based virtual refocusing of images using an engineered
  point-spread function -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.IV/paper_0.html">
      <font color="black">Deep learning-based virtual refocusing of images using an engineered
  point-spread function</font>
    </a>
  </h2>
  <font color="black">このアプローチは、空間分解能や体積イメージングスループットなどのイメージングパフォーマンスを向上させるために設計されたPSFを利用するローカリゼーション顕微鏡技術のためのディープラーニング対応の画像再構成法を開発するために適用できます。DH-PSFエンジニアリングでこのW-Netモデルを使用して、蛍光顕微鏡のDOFを約20倍に拡張します。カスケードニューラルネットワークとダブルヘリックス点像分布関数（DH-PSF）によって可能になる拡張フィールド深度（DOF）での仮想画像リフォーカス方法を紹介します。 
[概要] w-netと呼ばれるこのネットワークモデルは、2つのカスケードされたジェネレーターとディスクリミネーターのネットワークペアで構成されています。ネットワークモデルは、「w-fs」と呼ばれるネットワークモデルに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Objective Evaluation of Deep Uncertainty Predictions for COVID-19
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.IV/paper_1.html">
      <font color="black">Objective Evaluation of Deep Uncertainty Predictions for COVID-19
  Detection</font>
    </a>
  </h2>
  <font color="black">したがって、不確実性の定量化方法は、高い不確実性の推定値でリスクのある予測にフラグを立てることができます。包括的な実験を通じて、CXR画像に関連するネットワークは、ImageNetなどの自然画像データセットで事前トレーニングされたネットワークよりも優れていることが示されています。定性的および定量的評価でも、予測の不確実性の推定値は、正しい予測よりも誤った予測の方が統計的に高くなります。 
[概要]不確実性混同行列の定量化の概念が提案されています。不確実性推定の客観的評価のための新しいパフォーマンスメトリックが導入されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: So you think you can DAS? A viewpoint on delay-and-sum beamforming -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.IV/paper_2.html">
      <font color="black">So you think you can DAS? A viewpoint on delay-and-sum beamforming</font>
    </a>
  </h2>
  <font color="black">トランスデューサー要素の指向性からf値を決定し、遅延信号の位相分散から音速を決定することをお勧めします。特に、画質におけるf値と音速の重要性について説明します。物理的な観点から値を設定するための1つのソリューションを提案します。invitroまたはinvivoでDASを使用してビームフォーミングする場合、これらのパラメーターを最適化して、賢明に使用し、画像の劣化を防ぐことをお勧めします。 
[ABSTRACT]システムはシンプルでリアルタイムアプリケーションと互換性があります。トランスデューサー要素の指向性からf値を決定できます。遅延信号の位相分散から音速を決定できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-23">
        <br><font color="black">2020-07-23</font>
      </time>
    </span>
</section>
<!-- paper0: A Tiny CNN Architecture for Medical Face Mask Detection for
  Resource-Constrained Endpoints -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.IV/paper_3.html">
      <font color="black">A Tiny CNN Architecture for Medical Face Mask Detection for
  Resource-Constrained Endpoints</font>
    </a>
  </h2>
  <font color="black">モデルの展開には、480MhzでクロックされたARMCortex-M7マイクロコントローラーとわずか496KBのフレームバッファーRAMを備えた小さな開発ボードが使用されました。公共の場所でのフェイスマスクの使用を監視することは、手動であるため課題でした。監視は安全ではない可能性があります。世界は、新しいコロナウイルス（COVID-19）の急速な普及により、これまでで最も危険なパンデミックの1つを経験しています。 
[概要]世界保健機関によると、コロナウイルスの感染を阻止する最も効果的な方法は、医療用フェイスマスクを着用することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Nonlocal Co-occurrence for Image Downscaling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.IV/paper_4.html">
      <font color="black">Nonlocal Co-occurrence for Image Downscaling</font>
    </a>
  </h2>
  <font color="black">提案された方法は、入力画像に存在した高周波構造をダウンスケールされた画像に保存することができます。この共起学習は、画像全体で近傍ベースの方法で実行されます。提案された方法の有効性を示します。さまざまなダウンスケーリング係数でダウンスケールされた多数の画像に対する広範な実験によるアプローチ。 
[概要]最近、カーネルベースの畳み込みフィルターを使用して効率的な画像ダウンスケーリングアルゴリズムを開発できることが実証されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Point Cloud Quality Assessment: Large-scale Dataset Construction and
  Learning-based No-Reference Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.IV/paper_5.html">
      <font color="black">Point Cloud Quality Assessment: Large-scale Dataset Construction and
  Learning-based No-Reference Approach</font>
    </a>
  </h2>
  <font color="black">さらに、ポイントクラウド形式の特徴的な特性により、ブラインドイメージ品質評価（IQA）メソッドを直接適用してポイントクラウドの品質スコアを予測することは不可能です。結果は、提案されたネットワークが信頼できるパフォーマンスを持っていることを示しています。この作業で提示されるデータセットはhttp://smt.sjtu.edu.cnで公開されています。 
[概要]点群データの欠如は、nr-pcqa技術の開発を制限します。この論文では、大規模なpcqaデータセットを確立します。データセットには、104個の参照点群と24,000個を超える点群が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: A Feasibility study for Deep learning based automated brain tumor
  segmentation using Magnetic Resonance Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.IV/paper_6.html">
      <font color="black">A Feasibility study for Deep learning based automated brain tumor
  segmentation using Magnetic Resonance Images</font>
    </a>
  </h2>
  <font color="black">提案された腫瘍セグメンテーションアーキテクチャの全体的なパフォーマンスは、精度、境界変位エラー（BDE）、ダイススコア、信頼区間などの客観的な品質パラメータを使用して分析されました。出力に基づいて、プレウィットと呼ばれる典型的なエッジ検出アルゴリズムが腫瘍セグメンテーションタスクに使用されました。この研究では、脳腫瘍のMR画像分類と腫瘍の位置特定のために、ディープコンボリューションニューラルネットワーク（CNN）ベースの分類ネットワークとFasterRCNNベースの位置特定ネットワークが開発されました。 
[ABSTRACT]研究は、モデル展開の実際の要件と実際的な課題を評価するために臨床部門に展開されます。結果は、データが脳からのデータに基づいているという事実に基づいています。神経科医は、高精度セグメンテーションとしてのモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Adaptive Partial Scanning Transmission Electron Microscopy with
  Reinforcement Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.IV/paper_7.html">
      <font color="black">Adaptive Partial Scanning Transmission Electron Microscopy with
  Reinforcement Learning</font>
    </a>
  </h2>
  <font color="black">圧縮センシングは、最小限の情報損失で走査透過電子顕微鏡の電子線量とスキャン時間を短縮できます。再発神経ネットワークは、スパーススキャンを完了するフィードフォワード畳み込み神経ネットワークと連携するように強化学習によってトレーニングされます。スキャンセグメントのサンプリング方向が選択されます。以前に観察されたスキャンセグメントに基づく反復神経ネットワークによる。 
[概要]リカレントニューラルネットワークは、スパーススキャンを完了したフィードフォワード畳み込みニューラルネットワークと連携するようにコンポーネント学習によってトレーニングされます。リカレント脳脳ネットワークは、ウェズリーウェズリーウェズリースヌーザーによってトレーニングされ、協力するようにトレーニングされます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: Prediction of Chronic Kidney Disease Using Deep Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.IV/paper_8.html">
      <font color="black">Prediction of Chronic Kidney Disease Using Deep Neural Network</font>
    </a>
  </h2>
  <font color="black">Bade General Hospitalから、データセットとして10個の属性を持つ400人の患者の記録を取得しました。結果から、2つの属性が明らかになりました。クレアチニンと重炭酸塩は、CKDの予測に最も大きな影響を及ぼします。ナイジェリアのヨベ州の地方自治体であるBadeは、CKDの蔓延により、開業医の注目を集めています。 
[概要]慢性腎臓病（pgd）とその症状は軽度で段階的であり、何年もの間見過ごされがちですが、最近実現するだけです。この病気を達成するための技術的アプローチはまだ達成されていません。dnnモデルを使用して不在または患者におけるckdの存在</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Virtual Source Synthetic Aperture for Accurate Lateral Displacement
  Estimation in Ultrasound Elastography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.IV/paper_9.html">
      <font color="black">Virtual Source Synthetic Aperture for Accurate Lateral Displacement
  Estimation in Ultrasound Elastography</font>
    </a>
  </h2>
  <font color="black">仮想光源合成開口（VSSA）イメージングは、焦点を合わせた送信データに合成開口ビームフォーミングを実装して、SAと同じ横方向の解像度を維持しながら、被写界深度のSAの制限を克服する手法です。シミュレーションと実験結果は、横方向の変位..さまざまな超音波イメージング技術の中で、合成開口（SA）は他の技術よりも横方向の解像度が優れていますが、被写界深度のイメージングに制限があるため、超音波エラストグラフィーには一般的に使用されていません。 
[ABSTRACT]合成放棄（sa）は、他のものよりも横方向の解像度が優れています。被写界深度をキャプチャすることによる制限のため、超音波エラストグラフィには一般的に使用されていません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-19">
        <br><font color="black">2020-12-19</font>
      </time>
    </span>
</section>
<!-- paper0: HDR Denoising and Deblurring by Learning Spatio-temporal Distortion
  Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.IV/paper_10.html">
      <font color="black">HDR Denoising and Deblurring by Learning Spatio-temporal Distortion
  Models</font>
    </a>
  </h2>
  <font color="black">まず、代わりに別の関数を学習します。CLEAN-&gt; DISTORTEDは、相関ピクセルノイズ、行と列のノイズ、および少数のCLEANセンサー読み取り値からのモーションブラーを含むサンプルを生成します。残念ながら、DISTORTEDセンサー読み取り値のキャプチャは時間がかかる;また、CLEAN HDRビデオも不足しています。異なるピクセルで異なる低ダイナミックレンジ（LDR）情報を記録するデュアル露出センサーから、シャープでノイズのないハイダイナミックレンジ（HDR）ビデオを再構築しようとしています。列：奇数の列は、露出が低く、シャープであるがノイズの多い情報を提供します。列でさえ、ノイズが少なく、露出が高く、モーションブラーのあるデータでこれを補完します。 
[概要]以前のldrの作業では、クリーンな画像と歪んだ画像のペアによって監視され、ブレ除去とノイズ除去（歪んだ-クリーン）を学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Cloud removal in remote sensing images using generative adversarial
  networks and SAR-to-optical image translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.IV/paper_11.html">
      <font color="black">Cloud removal in remote sensing images using generative adversarial
  networks and SAR-to-optical image translation</font>
    </a>
  </h2>
  <font color="black">雲が厚くなるにつれて、雲を除去するプロセスはより困難になります。1つ目はSAR画像を光学画像に変換し、2つ目は以前のGANの変換画像を使用して雲を除去します。また、拡張残留開始ブロック（DRIB）を提案します。ジェネレータネットワークでバニラUネットの代わりに、L1損失関数に加えて構造類似性指数測定（SSIM）を使用します。 
[ABSTRACT]衛星画像の用途が広いため、雲の除去が注目されています。そのような場合、再構築にsarなどの補助画像を使用するのが一般的です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Complementary Time-Frequency Domain Networks for Dynamic Parallel MR
  Image Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.IV/paper_12.html">
      <font color="black">Complementary Time-Frequency Domain Networks for Dynamic Parallel MR
  Image Reconstruction</font>
    </a>
  </h2>
  <font color="black">目的：補完的なドメインから時空間相関を同時に活用する補完的な時間周波数ドメインネットワークを学習することにより、高速で高品質の動的マルチコイルMR再構築のための新しい深層学習ベースのアプローチを紹介します。この方法は効果的かつ堅牢に再構築できます。高度にアンダーサンプリングされた動的マルチコイルデータ（$ 16 \ times $と$ 24 \ times $でそれぞれ15秒と10秒のスキャン時間を生成）からの高品質画像と高速再構成速度（2.8秒）。提案されたモデルは、取得したデータにも一般化できます。別のスキャナーと、トレーニングセットでは見られなかった病状のデータから。 
[ABSTRACT]テクニックは、use-redundanciesを使用して画像を復元することを学習する多変数ネットワークに組み込まれています。ディープニューラルネットワークを使用して、異なる時間周波数領域から15スキャンを開発する利点を示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: ENSURE: Ensemble Stein's Unbiased Risk Estimator for Unsupervised
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.IV/paper_13.html">
      <font color="black">ENSURE: Ensemble Stein's Unbiased Risk Estimator for Unsupervised
  Learning</font>
    </a>
  </h2>
  <font color="black">私たちの予備的な実験結果は、提案されたENSUREアプローチが教師あり学習および最近の教師なし学習方法に匹敵する再構成品質を与えることを示しています。は、展開されたネットワークの画像ノイズ除去ステップの平均二乗誤差（MSE）推定値として、スタインの教師なしリスク推定器（SURE）を利用しました。 
[概要]それぞれが異なるサンプリングパターンで取得された画像のアンサンブルを使用するネットワークは、mseに非常に似ている可能性があります。高解像度や動的イメージングなど、いくつかのアプリケーションで画像をテストすることは困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-20">
        <br><font color="black">2020-10-20</font>
      </time>
    </span>
</section>
<!-- paper0: Brain Atlas Guided Attention U-Net for White Matter Hyperintensity
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.IV/paper_14.html">
      <font color="black">Brain Atlas Guided Attention U-Net for White Matter Hyperintensity
  Segmentation</font>
    </a>
  </h2>
  <font color="black">白質高信号（WMH）は、脳MRIにおける脳小血管疾患（cSVD）の最も一般的な症状です。この論文では、FLAIR画像のみを活用する新しい脳地図誘導注意U-Net（BAGAU-Net）を提案します。空間的に登録された白質（WM）脳地図を使用して、競争力のあるWMHセグメンテーションパフォーマンスを実現します。可用性：https：//github.com/Ericzhang1/BAGAU-Net 
[ABSTRACT] csvdの負担とその負荷を判断するには、不十分なwmhセグメンテーションアルゴリズムが重要です臨床的影響.t1-加重画像は通常、急性脳卒中の患者のために取得される標準的な臨床スキャンの一部ではありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-19">
        <br><font color="black">2020-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: Modeling Deep Learning Based Privacy Attacks on Physical Mail -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.IV/paper_15.html">
      <font color="black">Modeling Deep Learning Based Privacy Attacks on Physical Mail</font>
    </a>
  </h2>
  <font color="black">最後に、私たちの定式化とモデルにより、物理的なメールに対するディープラーニングベースのプライバシー攻撃に対抗できる封筒を設計できます。メールのプライバシー保護は、通常の紙の封筒は私たちが考えるほど安全ではないため、封筒内の隠されたコンテンツへの不正アクセスを防ぐことを目的としています。 ..まず、物理的なメールコンテンツに対するディープラーニングベースのプライバシー攻撃を、カメラでキャプチャしたエンベロープの前面画像から非表示のコンテンツへのマッピングを学習するものとしてモデル化し、次に、遠近法変換、画像の曇り除去、およびNeural-STE（See-Through-Envelope）という名前のディープコンボリューションニューラルネットワークを使用したノイズ除去。 
[概要]ディープラーニングモデル、ディープラーニングは簡単に復元できます。ディープラーニングモデル。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient and Visualizable Convolutional Neural Networks for COVID-19
  Classification Using Chest CT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.IV/paper_16.html">
      <font color="black">Efficient and Visualizable Convolutional Neural Networks for COVID-19
  Classification Using Chest CT</font>
    </a>
  </h2>
  <font color="black">症例が急速に増加しているため、深層学習が有望な診断手法として浮上しています。EfficientNet-B5は、精度0.9931 +/- 0.0021、F1スコア0.9931 +/- 0.0020、感度0.9952 +/-の最良のモデルとして識別されています。 0.0020、および0.9912 +/- 0.0048の特異度。中間アクティベーションマップと勾配加重クラスアクティベーションマッピングは、人工知能の有望なユースケースを示唆する、地上クラスの不透明度と統合に対するモデルの認識の人間が解釈できる証拠を提供します。支援された放射線ツール。 
[要約]この論文では、covid-19診断のための40の異なる畳み込みニューラルネットワークアーキテクチャを評価および比較しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Limitation of Acyclic Oriented Graphs Matching as Cell Tracking Accuracy
  Measure when Evaluating Mitosis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.IV/paper_17.html">
      <font color="black">Limitation of Acyclic Oriented Graphs Matching as Cell Tracking Accuracy
  Measure when Evaluating Mitosis</font>
    </a>
  </h2>
  <font color="black">この論文では、シミュレーションと実際の細胞追跡データの両方を使用して、AOGMで有糸分裂を評価することの限界を示します。したがって、非周期的指向グラフマッチング（AOGM）は、直接使用するのではなく、細胞追跡の事実上の標準評価指標として使用されています。複数オブジェクト追跡精度（MOTA）、IDスイッチ（IDS）、ID F1スコア（IDF1）などのコンピュータービジョンの評価指標。コンピュータービジョンのマルチオブジェクト追跡（MOT）と生物医学画像分析の細胞追跡は2つの類似した研究分野。その共通の目的は、インスタンスレベルのオブジェクトの検出/セグメンテーションを実現し、そのようなオブジェクトを異なるビデオフレーム間で関連付けることです。 
[ABSTRACT]細胞追跡は、通常motタスクの標準ではない有糸分裂（細胞分裂）の検出も目的としています。これら2つのタスクは、異なる細胞追跡方法を使用して開発されました。目的は、motではなくmot（mot）を追跡することでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Inferring Point Cloud Quality via Graph Similarity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.IV/paper_18.html">
      <font color="black">Inferring Point Cloud Quality via Graph Similarity</font>
    </a>
  </h2>
  <font color="black">人間の視覚システムは高空間周波数成分（等高線、エッジなど）に敏感であり、個々の点群ではなく局所的な構造変化に重きを置いているという事実に動機付けられて、最初に参照点群をリサンプリングして幾何学的キーポイントを抽出しますオブジェクトスケルトンを形成するためのジオメトリ情報。次に、参照点群と歪んだ点群の両方について、これらのキーポイントを中心とするローカルグラフを作成し、その後、同じローカルグラフ内の他のすべてのポイントと中心のキーポイントの間で導出される色のグラデーションモーメント（たとえば、0番目、1番目、2番目）をまとめて集計します。重要な特徴の類似性（別名、局所的な重要性）の測定。最終的な類似性インデックスは、すべてのカラーチャネルにわたってローカルグラフの有意性をプールし、すべてのグラフにわたって平均化することによって取得されます。アブレーション研究は、GraphSIMがその主要なモジュールとパラメーターを調べることにより、一貫したパフォーマンスでさまざまなシナリオに一般化されることをさらに示しています。 GraphSIM-ジオメトリと色の障害が重ね合わされた点群の主観的な品質を正確に予測するための客観的な指標。 
[概要]最初に、参照点群情報をリサンプリングしてオブジェクトスケルトンを形成することにより、幾何学的キーポイントを抽出します。次に、参照点群と歪んだ点群の両方について、これらのキーポイントを中心とするローカルグラフを作成します。最終的な類似性インデックスは、ローカルグラフの有意性をプールすることによって取得されます。すべてのカラーチャネルにわたって、すべてのカラーにわたって平均化することによって</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-31">
        <br><font color="black">2020-05-31</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Non-Rigid Neural Radiance Fields: Reconstruction and Novel View
  Synthesis of a Deforming Scene from Monocular Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_0.html">
      <font color="black">Non-Rigid Neural Radiance Fields: Reconstruction and Novel View
  Synthesis of a Deforming Scene from Monocular Video</font>
    </a>
  </h2>
  <font color="black">読者に定性的な結果を得るために補足ビデオを見るように促します。特に、消費者向けカメラが短くて単純なシーンの説得力のあるバレットタイムビデオを合成するのに十分であることを示します。さらに、結果の表現は対応推定を可能にします。ビューと時間にわたって、シーンの各ポイントの剛性スコアを提供します。 
[ABSTRACT] non-rigid nerf（nr-nerf）は、変形するオブジェクトのrgb画像を入力として取得します。次に、シーンを再構築できるデザインと外観の表現を学習します。nerfは、単眼ビデオからblatormingオブジェクトの写真も取得します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Multiple Instance Segmentation in Brachial Plexus Ultrasound Image Using
  BPMSegNet -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_1.html">
      <font color="black">Multiple Instance Segmentation in Brachial Plexus Ultrasound Image Using
  BPMSegNet</font>
    </a>
  </h2>
  <font color="black">BPMSegNetには3つの新しいモジュールがあります。提案されたBPMSegNetは、構築された超音波腕神経叢データセット（UBPD）で実験を行うことによって評価されます。最初は、さまざまなスケールでコントラスト特徴を計算する空間ローカルコントラスト特徴です。 
[ABSTRACT]超音波画像の神経識別は、局所麻酔のパフォーマンスを改善するための重要なステップです。提案されたbpmsegnetは、構築された超音波腕神経叢データセット（ubpd）で実験を行うことによって評価されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Dual-encoder Bidirectional Generative Adversarial Networks for Anomaly
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_2.html">
      <font color="black">Dual-encoder Bidirectional Generative Adversarial Networks for Anomaly
  Detection</font>
    </a>
  </h2>
  <font color="black">現在のアプローチは、ジェネレーターとディスクリミネーターネットワークと同時にトレーニングされる双方向GANアーキテクチャーでデュアルエンコーダーを使用することによって開発されています。メソッドがサンプルデータの十分な情報を保持しない場合、悪いサイクルの一貫性が発生すると想定します。脳磁気共鳴イメージング異常検出システムへの適用を含む、公的に利用可能なデータセットに私たちの方法を適用する実験が報告されています。 
[概要]提案された方法は、双方向ガンが正常なサンプルと異常なサンプルの間に大きな違いがあるサンプルを再現できない可能性がある悪いサイクルの一貫性を減らすことを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Deep learning-based virtual refocusing of images using an engineered
  point-spread function -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_3.html">
      <font color="black">Deep learning-based virtual refocusing of images using an engineered
  point-spread function</font>
    </a>
  </h2>
  <font color="black">このアプローチは、空間分解能や体積イメージングスループットなどのイメージングパフォーマンスを向上させるために設計されたPSFを利用するローカリゼーション顕微鏡技術のためのディープラーニング対応の画像再構成法を開発するために適用できます。DH-PSFエンジニアリングでこのW-Netモデルを使用して、蛍光顕微鏡のDOFを約20倍に拡張します。カスケードニューラルネットワークとダブルヘリックス点像分布関数（DH-PSF）によって可能になる拡張フィールド深度（DOF）での仮想画像リフォーカス方法を紹介します。 
[概要] w-netと呼ばれるこのネットワークモデルは、2つのカスケードされたジェネレーターとディスクリミネーターのネットワークペアで構成されています。ネットワークモデルは、「w-fs」と呼ばれるネットワークモデルに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Objective Evaluation of Deep Uncertainty Predictions for COVID-19
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_4.html">
      <font color="black">Objective Evaluation of Deep Uncertainty Predictions for COVID-19
  Detection</font>
    </a>
  </h2>
  <font color="black">包括的な実験を通じて、CXR画像に関連するネットワークは、ImageNetなどの自然画像データセットで事前トレーニングされたネットワークよりも優れていることが示されています。したがって、不確実性の定量化方法は、リスクの高い予測に高い不確実性の推定値を示すことができます。DNN予測に関連する不確実性の定量化は医療現場での信頼できる展開の前提条件。 
[概要]不確実性混同行列の定量化の概念が提案されています。不確実性推定の客観的評価のための新しいパフォーマンスメトリックが導入されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Latent Feature Representation via Unsupervised Learning for Pattern
  Discovery in Massive Electron Microscopy Image Volumes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_5.html">
      <font color="black">Latent Feature Representation via Unsupervised Learning for Pattern
  Discovery in Massive Electron Microscopy Image Volumes</font>
    </a>
  </h2>
  <font color="black">また、学習空間でのデータのクラスタリングが生物学的に意味のある区別と相関することも示します。学習した表現がクエリを有効にする能力を例で示し、科学者がデータの興味深いパターンに気付いた場合にそれらを提示できるようにします。パターンが一致する他の場所で..監視された方法を使用して、関心のある既知のパターンを予測および識別することができますが、データの規模により、事前に知られていないパターンをマイニングおよび分析することは困難です。 
[概要]データセットの意味的類似性をキャプチャする潜在表現を学習するための教師なし深層学習アプローチを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Unadversarial Examples: Designing Objects for Robust Vision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_6.html">
      <font color="black">Unadversarial Examples: Designing Objects for Robust Vision</font>
    </a>
  </h2>
  <font color="black">私たちのコードはhttps://git.io/unadversarialにあります。このフレームワークは、入力摂動に対する最新の機械学習アルゴリズムの感度を利用して、「堅牢なオブジェクト」、つまり、自信を持って検出されるように明示的に最適化されたオブジェクトを設計します。または分類されます。標準的なベンチマークから（シミュレーション内の）ロボット工学、実際の実験に至るまで、さまざまなビジョンベースのタスクに対するフレームワークの有効性を示します。 
[概要]ビジョンモデルのパフォーマンスと堅牢性を大幅に向上させることができるフレームワークを開発します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Power-SLIC: Diagram-based superpixel generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_7.html">
      <font color="black">Power-SLIC: Diagram-based superpixel generation</font>
    </a>
  </h2>
  <font color="black">速度の点では、Power-SLICはSLICと競合します。BSDS500データセットでは、Power-SLICは、コンパクトさと境界の精度の点で他の最先端のアルゴリズムよりも優れており、境界の順守は最も堅牢です。さまざまなレベルのガウスノイズ..スーパーピクセルの規則性を改善することを目的として、Power-SLICと呼ばれるダイアグラムベースのスーパーピクセル生成方法を提案します。 
[ABSTRACT]境界の順守、速度、および規則性は、スーパーピクセルの一般的に重要な基準です。スーパーピクセルに加えて、スーパーピクセルは他の最先端のアルゴリズムよりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Geometric robust descriptor for 3D point cloud -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_8.html">
      <font color="black">Geometric robust descriptor for 3D point cloud</font>
    </a>
  </h2>
  <font color="black">法線ベクトルの符号問題を回避するために、接平面に関して対称なカーネル点分布を使用します。この論文では、回転ロバストおよび密度ロバスト記述子を作成するための新しい局所特徴生成方法を提示します。カーネルは各ポイントの周りに配置され、ポイントの法線に配置されます。 
[ABSTRACT]ポイントクラウドは、3Dレジストレーションでの対応の検索やローカル領域のセグメント化など、多くのアプリケーションで使用されますが、ポイントのスパース性、回転したポイントクラウドなどの問題があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Weaponizing Unicodes with Deep Learning -- Identifying Homoglyphs with
  Weakly Labeled Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_9.html">
      <font color="black">Weaponizing Unicodes with Deep Learning -- Identifying Homoglyphs with
  Weakly Labeled Data</font>
    </a>
  </h2>
  <font color="black">ソースコードと予測されるホモグリフのリストがGithubにアップロードされます：https：//github.com/PerryXDeng/weaponizing_unicode。私たちのモデルは、ペアワイズホモグリフ識別の正規化圧縮距離アプローチを大幅に上回り、平均精度0.97を達成しています。私たちのアプローチは、ほとんどの文字がホモグリフではないという事実から生じる弱いラベルを独自に利用しています。 
[概要]ホモグリフ（特に以前に発見されていないもの）を識別する攻撃者の能力を理解することが重要です。私たちのアプローチは、ほとんどの文字がホモグリフではないという事実から生じる弱いラベルを独自に利用しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-09">
        <br><font color="black">2020-10-09</font>
      </time>
    </span>
</section>
<!-- paper0: Human Action Recognition from Various Data Modalities: A Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_10.html">
      <font color="black">Human Action Recognition from Various Data Modalities: A Review</font>
    </a>
  </h2>
  <font color="black">具体的には、単一データモダリティの手作りの機能ベースと深層学習ベースの両方の方法を確認し、融合ベースのフレームワークや共同学習ベースのアプローチなど、複数のモダリティに基づく方法も確認します。 、この分野で潜在的に重要な研究の方向性について説明します。その結果、多くの既存の研究が、さまざまなモダリティを使用してHARのさまざまなタイプのアプローチを調査しようと試みました。 
[概要]人間の行動は、さまざまなデータモダリティを使用して表すことができます。これらには、rgb、スケルトン、深度、赤外線シーケンス、点群が含まれます。これは、有用でありながら明確な情報のさまざまなソースをエンコードします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Image-based plant disease diagonasis with unsupervised anomaly detection
  based on reconstructability of colors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_11.html">
      <font color="black">Image-based plant disease diagonasis with unsupervised anomaly detection
  based on reconstructability of colors</font>
    </a>
  </h2>
  <font color="black">「異常検出」と呼ばれるデータマイニング手法には、分類器のトレーニングにまれなサンプルを必要としない教師なしアプローチが含まれます。深層学習に基づく教師あり画像分類器は、植物の病気を特定するための強力なツールですが、大量のデータセットが必要です。この研究で提案された方法は、植物画像の色の再構成可能性に焦点を当てています。 
[概要]データマイニングには、健全なサンプルを必要としない教師なしアプローチが含まれます。「異常検出」と呼ばれるデータマイニング手法には、教師なしアプローチが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-29">
        <br><font color="black">2020-11-29</font>
      </time>
    </span>
</section>
<!-- paper0: Stochastic Segmentation Networks: Modelling Spatially Correlated
  Aleatoric Uncertainty -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_12.html">
      <font color="black">Stochastic Segmentation Networks: Modelling Spatially Correlated
  Aleatoric Uncertainty</font>
    </a>
  </h2>
  <font color="black">ピクセル単位の推定値を生成するアプローチとは対照的に、SSNはラベルマップ全体の同時分布をモデル化するため、単一の画像に対して複数の空間的にコヒーレントな仮説を生成できます。肺結節を含む実際の医療データのセグメンテーションでメソッドをテストしました。 2DCTおよび3DマルチモーダルMRIスキャンの脳腫瘍..SSNは、あいまいな画像の相関不確実性をモデル化するための最先端の性能を上回り、はるかに単純で、柔軟性があり、効率的です。 
[ABSTRACT]確率的セグメンテーションネットワーク（ssns）は、任意の画像セグメンテーションネットワークアーキテクチャで偶然性の不確実性をモデル化するための効率的な確率的手法です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-10">
        <br><font color="black">2020-06-10</font>
      </time>
    </span>
</section>
<!-- paper0: A Tiny CNN Architecture for Medical Face Mask Detection for
  Resource-Constrained Endpoints -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_13.html">
      <font color="black">A Tiny CNN Architecture for Medical Face Mask Detection for
  Resource-Constrained Endpoints</font>
    </a>
  </h2>
  <font color="black">モデルの展開には、480MhzでクロックされたARMCortex-M7マイクロコントローラーとわずか496KBのフレームバッファーRAMを備えた小さな開発ボードが使用されました。世界はこれまでで最も危険なパンデミックの1つを経験しています。新規コロナウイルス（COVID-19）の急速な普及。提案されたモデルは、量子化後138 KBであり、30FPSの推論速度で実行されます。 
[概要]世界保健機関によると、コロナウイルスの感染を阻止する最も効果的な方法は、医療用フェイスマスクを着用することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal Research in Vision and Language: A Review of Current and
  Emerging Trends -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_14.html">
      <font color="black">Multimodal Research in Vision and Language: A Review of Current and
  Emerging Trends</font>
    </a>
  </h2>
  <font color="black">この調査では、VisLangの研究における最近の文献を引き付ける主要な傾向を特定し、この分野が向かっている方向を明らかにしようとしています。タスクの定式化におけるそのアプリケーションと、意味認識とコンテンツ生成に関連するさまざまな問題を解決する方法についても見ていきます。タスク固有の傾向に加えて、それらの評価戦略と今後の課題に対処します。 
[概要]これにより、ビジョンと言語の分野の交差点での研究への関心が高まりました。タスクの具体化におけるそのアプリケーションと、セマンティック知覚とコンテンツ生成に関連するさまざまな問題を解決する方法について説明します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-19">
        <br><font color="black">2020-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: Image to Bengali Caption Generation Using Deep CNN and Bidirectional
  Gated Recurrent Unit -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_15.html">
      <font color="black">Image to Bengali Caption Generation Using Deep CNN and Bidirectional
  Gated Recurrent Unit</font>
    </a>
  </h2>
  <font color="black">BLEU-1、BLEU-2、BLEU-3、BLEU-4を取得し、Meteorはそれぞれ42.6、27.95、23、66、16.41、28.7です。これは、多くの視覚障害者の日常生活にも役立ちます。キャプションを生成するためのデコーダーとしてのデータセットの画像の双方向ゲート付き回帰ユニット（BGRU）レイヤーの分析、分類、および注釈付けのためのエンコーダーとしてのInceptonV3image埋め込みモデルと呼ばれる事前トレーニング済みのディープ畳み込みニューラルネットワーク（DCNN）。 
[概要]この言語は地球上で7番目に話されている言語です。研究は言語の壁を打ち破り、お互いの視点をよりよく理解する可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: SERV-CT: A disparity dataset from CT for validation of endoscopic 3D
  reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_16.html">
      <font color="black">SERV-CT: A disparity dataset from CT for validation of endoscopic 3D
  reconstruction</font>
    </a>
  </h2>
  <font color="black">内視鏡の向きを手動で立体視に合わせました。2つの{\ it ex vivo}小さなブタの完全な胴体の死体を内視鏡の視野内に配置し、内視鏡とターゲットの解剖学的構造の両方をCTスキャンで確認しました。参照データセット内視鏡画像の大部分とさまざまな組織タイプをカバーする、対応するキャリブレーション、視差、深度、およびオクルージョンを備えた内視鏡画像ペアが含まれます。 
[概要]ステレオ-内視鏡再構成検証データセットはct（serv-ct）に基づいていました。ctスキャンはスキャンのビュー内に配置されました。スキャンスキャンスキャンは手動でステレオスコピックビューに位置合わせされました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Boosting Image-based Mutual Gaze Detection using Pseudo 3D Gaze -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_17.html">
      <font color="black">Boosting Image-based Mutual Gaze Detection using Pseudo 3D Gaze</font>
    </a>
  </h2>
  <font color="black">3つの画像データセットの実験結果は、提案されたアプローチが追加の注釈なしで検出パフォーマンスを大幅に改善することを示しています。この作業は、29.2Kの画像で相互注視ラベルで注釈が付けられた33.1Kの人間のペアで構成される新しい画像データセットも導入します。相互注視ラベルから推定される疑似3D注視ラベルを使用して3D注視推定ブランチをトレーニングすることにより、追加のラベリングコストなしでパフォーマンスが向上します。 
[概要]この作業では、相互視線検出のタスクに焦点を当てます。トレーニングフェーズで補助的な3D視線推定タスクを使用して、パフォーマンスを向上させるためのシンプルで効果的なアプローチを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Progressive One-shot Human Parsing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_18.html">
      <font color="black">Progressive One-shot Human Parsing</font>
    </a>
  </h2>
  <font color="black">POPNetは、Attention GuidanceModuleとNearestCentroid Moduleという名前の2つの協調的なメトリック学習モジュールで構成されています。これらは、基本クラスの代表的なプロトタイプを学習し、テスト中に見えないクラスに機能をすばやく転送して、テストのバイアスを減らします。さらに、POPNetはプログレッシブヒューマン解析を採用しています。粗い粒度で親クラスの学習知識を組み込んで、細かい粒度で子孫クラスを認識し、それによって小さなサイズの問題を処理できるフレームワーク。ソースコードはhttps://github.com/Charleshhy/Oneにあります。 -ショット-人間-解析。 
[概要]この論文では、ワンショットヒューマンパーシングという新しい問題を考案します。これには、ヒューマンを単一の参照例で定義された参照クラスのオープンセットに解析する必要があります。popnetはプログレッシブヒューマンパーシングフレームワークを使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Analysis of Dimensional Influence of Convolutional Neural Networks for
  Histopathological Cancer Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_19.html">
      <font color="black">Analysis of Dimensional Influence of Convolutional Neural Networks for
  Histopathological Cancer Classification</font>
    </a>
  </h2>
  <font color="black">解像度スケーリングは、入力画像の次元を増やすことによって実行され、複合スケーリングには、幅、深さ、および解像度スケーリングのハイブリッドの組み合わせが含まれます。この調査は、タスクのベースラインモデルの複合スケーリングによってCNNモデルのパフォーマンスが向上することを示しています。組織病理学的癌分類の概要..ベースラインモデルの複合スケーリングにより、幅、深さ、解像度の3つの次元すべてがスケーリングされるため、複合スケーリングで最高のパフォーマンスが得られます。 
[概要] cnnアーキテクチャは、幅、深さ、解像度、およびこれらすべての組み合わせを含む複数の次元でスケーリングされます。ベースラインモデルの複合スケーリングにより、3つの次元すべてが保証されます：膨らみ、深さ、解像度がスケーリングされ、最高のパフォーマンスが得られます。複合スケーリング</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-08">
        <br><font color="black">2020-11-08</font>
      </time>
    </span>
</section>
<!-- paper0: FracBNN: Accurate and FPGA-Efficient Binary Neural Networks with
  Fractional Activations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_20.html">
      <font color="black">FracBNN: Accurate and FPGA-Efficient Binary Neural Networks with
  Fractional Activations</font>
    </a>
  </h2>
  <font color="black">組み込みFPGAデバイスでは、FracBNNはリアルタイム画像分類の機能を示します。FracBNNは、同じモデルサイズを使用しながら、トップ1の精度が2.4％向上し、最近導入されたBNNモデルよりも優れています。入力をさらに2値化します。新しい温度計エンコーディングを使用したレイヤー。 
[ABSTRACT] fracbnnは、組み込みFPGA（xilinx ultra96v2）で動作します。これは、最近導入されたbnnモデルよりも優れており、トップ1の精度が2.4％向上しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: FcaNet: Frequency Channel Attention Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_21.html">
      <font color="black">FcaNet: Frequency Channel Attention Networks</font>
    </a>
  </h2>
  <font color="black">周波数分析に基づいて、従来のGAPが周波数領域での特徴分解の特殊なケースであることを数学的に証明します。既存のチャネルアテンションメソッド内にメソッドを実装するために、計算で1行のコードのみを変更できます。その証拠として、周波数領域でのチャネル注意メカニズムの前処理を自然に一般化し、新しいマルチスペクトルチャネル注意を備えたFcaNetを提案します。 
[概要]コードとモデルは、年末までに公開される可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Gradient Surgery for Multi-Task Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_22.html">
      <font color="black">Gradient Surgery for Multi-Task Learning</font>
    </a>
  </h2>
  <font color="black">一連の挑戦的なマルチタスク教師ありおよびマルチタスクRL問題では、このアプローチは効率とパフォーマンスの大幅な向上につながります。タスクの勾配を他の勾配の法線平面に投影する勾配手術の形式を提案します。勾配が矛盾するタスク..深層学習および深層強化学習（RL）システムは、画像分類、ゲームプレイ、ロボット制御などの分野で印象的な結果を示していますが、データ効率は依然として大きな課題です。 
[ABSTRACT]マルチタスク学習は、複数のタスク間で構造を共有するための有望なアプローチとして浮上していますが、マルチタスク学習の理由は完全には理解されていません。システムの条件は不明です。これはモデルであり、組み合わせることができます。パフォーマンスを向上させるために以前に提案されたマルチタスクアーキテクチャを使用</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-19">
        <br><font color="black">2020-01-19</font>
      </time>
    </span>
</section>
<!-- paper0: A Feasibility study for Deep learning based automated brain tumor
  segmentation using Magnetic Resonance Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_23.html">
      <font color="black">A Feasibility study for Deep learning based automated brain tumor
  segmentation using Magnetic Resonance Images</font>
    </a>
  </h2>
  <font color="black">提案された腫瘍セグメンテーションアーキテクチャの全体的なパフォーマンスは、精度、境界変位エラー（BDE）、ダイススコア、信頼区間などの客観的な品質パラメータを使用して分析されました。セグメント化された出力の信頼水準は、それと同様の範囲であることが観察されました。専門家の..深層学習アルゴリズムは、医療画像分析、解釈、およびセグメンテーションにおける人工知能の研究の急速な加速を説明しており、医学のさまざまなサブ分野にわたる多くの潜在的なアプリケーションがあります。 
[ABSTRACT]研究は、モデル展開の実際の要件と実際的な課題を評価するために臨床部門に展開されます。結果は、データが脳からのデータに基づいているという事実に基づいています。神経科医は、高精度セグメンテーションとしてのモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Adaptive Partial Scanning Transmission Electron Microscopy with
  Reinforcement Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_24.html">
      <font color="black">Adaptive Partial Scanning Transmission Electron Microscopy with
  Reinforcement Learning</font>
    </a>
  </h2>
  <font color="black">ソースコード、事前トレーニング済みモデル、トレーニングデータは、https：//github.com/Jeffrey-Ede/adaptive-scansから公開されています。リカレントニューラルネットワークは、スパーススキャンを完了するフィードフォワード畳み込みニューラルネットワークと連携するように強化学習によってトレーニングされます。したがって、スキャンパスを標本にピースごとに適応させる連続スパーススキャンシステムのプロトタイプを提示します。 
[概要]リカレントニューラルネットワークは、スパーススキャンを完了したフィードフォワード畳み込みニューラルネットワークと連携するようにコンポーネント学習によってトレーニングされます。リカレント脳脳ネットワークは、ウェズリーウェズリーウェズリースヌーザーによってトレーニングされ、協力するようにトレーニングされます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: A Self-Training Approach for Point-Supervised Object Detection and
  Counting in Crowds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_25.html">
      <font color="black">A Self-Training Approach for Point-Supervised Object Detection and
  Counting in Crowds</font>
    </a>
  </h2>
  <font color="black">さらに、非常に混雑したシーンに対処するために、検出器の表現能力を向上させる効果的なデコード方法を提案します。この論文では、ポイントレベルの注釈のみでトレーニングされる典型的なオブジェクト検出器を可能にする新しいセルフトレーニングアプローチを提案します。オブジェクトは、混雑したオブジェクトの中心点とサイズの両方を推定するためにポイントでラベル付けされます。一方、検出器の能力がますます向上するように、初期の疑似オブジェクトサイズを継続的にリファインする信頼性と順序を意識したリファインメントスキームを提案します。群集内のオブジェクトを同時に検出してカウントします。 
[概要]新しい方法を使用して、初期の疑似オブジェクトサイズを調整できます。これにより、検出器が群集内のオブジェクトを予測およびカウントできるようになります。ただし、これは新しいシステムへの第一歩となる可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-25">
        <br><font color="black">2020-07-25</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Disentangled Semantic Representation for Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_26.html">
      <font color="black">Learning Disentangled Semantic Representation for Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">上記の仮定の下で、データの背後にあるセマンティック潜在変数とドメイン潜在変数を再構築するために変分オートエンコーダーを採用します。ドメイン適応は重要ですが挑戦的なタスクです。絡み合った特徴空間での以前の取り組みとは異なり、データの潜在的な解きほぐされた意味表現（DSR）でドメイン不変の意味情報を抽出します。 
[要約]既存のドメイン適応方法のほとんどは、セマンティック潜在変数を絡み合わせて特徴空間上のドメインサイズの表現を抽出するのに苦労しています。さらに、再構築された潜在変数のこれら2つのセットを解きほぐすためにデュアル敵対的ネットワークを考案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Deep correction of breathing-related artifacts in real-time
  MR-thermometry -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_27.html">
      <font color="black">Deep correction of breathing-related artifacts in real-time
  MR-thermometry</font>
    </a>
  </h2>
  <font color="black">リアルタイムMRイメージングは、解剖学的情報と同時にオンザフライの温度マップを提供できるため、熱療法のモニタリングに臨床的に適応されています。その後の温熱療法では、最近のマグニチュード画像がCNNの入力として使用されます。現在の温度マップのオンライン補正を生成するためのモデル。設計されたCNNの入力は最新のマグニチュード画像であり、動きの代理は必要ありません。 
[ABSTRACT]温度アーチファクトが呼吸および生理学的運動によって誘発されるため、移動するターゲットの温度測定は依然として困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: GuidedStyle: Attribute Knowledge Guided Style Manipulation for Semantic
  Face Editing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_28.html">
      <font color="black">GuidedStyle: Attribute Knowledge Guided Style Manipulation for Semantic
  Face Editing</font>
    </a>
  </h2>
  <font color="black">さらに、StyleGANジェネレーターのアテンションメカニズムで、スタイル操作用の単一レイヤーを適応的に選択できます。その結果、このメソッドでは、笑顔、眼鏡、性別、口ひげ、髪の色など、さまざまな属性に沿って解きほぐされた制御可能な編集を実行できます。 ..さらに、私たちのモデルは、さまざまなタイプの実際の芸術的な顔の編集にも適用できることを示し、強力な一般化能力を示しています。 
[概要] styleganジェネレーターのアテンションメカニズムが単一のレイヤーを適応的に選択できるようにします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Do We Really Need Scene-specific Pose Encoders? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_29.html">
      <font color="black">Do We Really Need Scene-specific Pose Encoders?</font>
    </a>
  </h2>
  <font color="black">仮説をテストするために、いくつかの完全に接続されたレイヤーの浅いアーキテクチャを採用し、一般的な画像検索モデルから事前に計算されたエンコーディングでトレーニングします。視覚的ポーズ回帰モデルは、単一のフォワードパスでクエリ画像からカメラポーズを推定します。 ..これらのエンコーディングは、カメラポーズを回帰するのに十分であるだけでなく、完全に接続された分岐アーキテクチャに提供された場合、トレーニングされたモデルが競争力のある結果を達成し、現在の\ textit {最新技術を超えることさえできることがわかります。 }場合によってはリグレッサーをポーズします。 
[ABSTRACT]モデルは、深い畳み込みネットワークを使用して画像からポーズをとることを学習します。これらのネットワークは、シーンごとにトレーニングされ、回帰するようにトレーニングされます。モデルは、競争力のある結果を達成し、現在のポーズリグレッサーを超えることもできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Prediction of Chronic Kidney Disease Using Deep Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_30.html">
      <font color="black">Prediction of Chronic Kidney Disease Using Deep Neural Network</font>
    </a>
  </h2>
  <font color="black">Bade General Hospitalから、データセットとして10属性の400人の患者の記録を取得しました。ナイジェリアのヨベ州の地方自治体であるBadeは、CKDの蔓延により、開業医の注目を集めています。私たちが摂取する物質や要素のために流行しています。 
[概要]慢性腎臓病（pgd）とその症状は軽度で段階的であり、何年もの間見過ごされがちですが、最近実現するだけです。この病気を達成するための技術的アプローチはまだ達成されていません。dnnモデルを使用して不在または患者におけるckdの存在</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Underwater image filtering: methods, datasets and evaluation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_31.html">
      <font color="black">Underwater image filtering: methods, datasets and evaluation</font>
    </a>
  </h2>
  <font color="black">最後に、主観的テストや品質評価手段などの評価戦略について説明します。この調査を、最先端の水中をホストするプラットフォーム（https://puiqe.eecs.qmul.ac.uk/）で補完します。フィルタリング方法と比較を容易にします。水中画像フィルタリングは、水中画像でキャプチャされたオブジェクトの外観を復元または強化することを目的としています。 
[概要]劣化の程度は、水の種類、物体とカメラの間の距離、物体が存在する水面下の深さによって異なります。復元方法は実際の劣化を補正しますが、強調方法は知覚される画質を向上させます。またはコンピュータビジョンアルゴリズムのパフォーマンス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Graph and Temporal Convolutional Networks for 3D Multi-person Pose
  Estimation in Monocular Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_32.html">
      <font color="black">Graph and Temporal Convolutional Networks for 3D Multi-person Pose
  Estimation in Monocular Videos</font>
    </a>
  </h2>
  <font color="black">3Dポーズ推定をさらに洗練するために、時間畳み込みネットワーク（TCN）を使用して、時間的および人間のダイナミクスの制約を適用します。また、骨の接続をモデル化し、人間の関節を超えてより多くの情報を提供する人間の骨のGCNを導入します。最後に、複数の人物の3D人間のポーズを推定するために、カメラパラメータを必要とせずにカメラ中心の3Dポーズを推定するルートTCNを提案します。 
[概要] 2つのgcnは連携して、人間の関節gcnを推定します。これらは、2Dポーズ推定器の信頼スコアを使用してポーズ推定結果を改善する有向グラフに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Time-Travel Rephotography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_33.html">
      <font color="black">Time-Travel Rephotography</font>
    </a>
  </h2>
  <font color="black">現在の最先端の復元フィルターとの比較は、さまざまな重要な歴史上の人々に大幅な改善と説得力のある結果を示しています。ノイズ除去、色付け、超解像などの独立した操作を適用する従来の画像復元フィルターとは異なり、StyleGAN2フレームワークを活用しています。古い写真を現代の高解像度写真の空間に投影し、統一されたフレームワークでこれらすべての効果を実現します。多くの歴史上の人々は、初期の制限によって歪められた古い、色あせた白黒写真でのみキャプチャされます。カメラと時間の経過。 
[概要]このプロセスは、古い写真と昔ながらの画像に基づいています。最新のカメラを使用して、有名な被写体を再撮影します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Noticing Motion Patterns: Temporal CNN with a Novel Convolution Operator
  for Human Trajectory Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_34.html">
      <font color="black">Noticing Motion Patterns: Temporal CNN with a Novel Convolution Operator
  for Human Trajectory Prediction</font>
    </a>
  </h2>
  <font color="black">ここではSocialPattern Extraction Convolution（Social-PEC）として知られる、シーケンシャル軌道データのパターンを学習、検出、抽出するための畳み込みニューラルネットワークベースのアプローチを提案します。さらに重要なことに、提案されたアプローチは、以前の使用におけるあいまいさを明らかにします。意思決定プロセスを直感的に説明する方法を提示するプーリング層。人間の軌道予測問題で実行された一連の実験は、モデルが最新技術と同等に機能し、場合によっては優れていることを示しています。 
[要約]人間の軌道予測に関する一連の実験は、私たちのモデルが最先端技術と同等に機能し、何らかの方法で優れていることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-02">
        <br><font color="black">2020-07-02</font>
      </time>
    </span>
</section>
<!-- paper0: HDR Denoising and Deblurring by Learning Spatio-temporal Distortion
  Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_35.html">
      <font color="black">HDR Denoising and Deblurring by Learning Spatio-temporal Distortion
  Models</font>
    </a>
  </h2>
  <font color="black">残念ながら、歪んだセンサーの読み取り値のキャプチャには時間がかかります。また、CLEAN HDRビデオが不足しています。まず、代わりに別の関数を学習します。CLEAN-&gt; DISTORTEDは、相関するピクセルノイズ、行と列のノイズ、および少数からのモーションブラーを含むサンプルを生成します。 CLEANセンサーの読み取り値の概要..異なるピクセル列に異なる低ダイナミックレンジ（LDR）情報を記録するデュアル露出センサーから、シャープでノイズのないハイダイナミックレンジ（HDR）ビデオを再構築しようとしています。奇数列は低-露出、シャープ、しかしノイズの多い情報。列でさえ、ノイズが少なく、露出が高く、モーションブラーのあるデータでこれを補完します。 
[概要]以前のldrの作業では、クリーンな画像と歪んだ画像のペアによって監視され、ブレ除去とノイズ除去（歪んだ-クリーン）を学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Cloud removal in remote sensing images using generative adversarial
  networks and SAR-to-optical image translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_36.html">
      <font color="black">Cloud removal in remote sensing images using generative adversarial
  networks and SAR-to-optical image translation</font>
    </a>
  </h2>
  <font color="black">この研究では、2つの生成的敵対的ネットワーク（GAN）を使用して問題の解決を試みます。雲が厚くなるにつれて、雲を除去するプロセスはより困難になります。そのような場合、近赤外線や合成などの補助画像を使用します。再構成用の開口レーダー（SAR）が一般的です。 
[ABSTRACT]衛星画像の用途が広いため、雲の除去が注目されています。そのような場合、再構築にsarなどの補助画像を使用するのが一般的です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: ENSURE: Ensemble Stein's Unbiased Risk Estimator for Unsupervised
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_37.html">
      <font color="black">ENSURE: Ensemble Stein's Unbiased Risk Estimator for Unsupervised
  Learning</font>
    </a>
  </h2>
  <font color="black">私たちの予備実験結果は、提案されたENSUREアプローチが、教師あり学習および最近の教師なし学習方法に匹敵する再構成品質を与えることを示しています。特に、それぞれが異なるサンプリングパターンで取得された画像のアンサンブルを使用してネットワークをトレーニングできることを示します。 MSEを近似します。画像再構成の以前の研究では、展開されたネットワークの画像ノイズ除去ステップの平均二乗誤差（MSE）推定値として、スタインの教師なしリスク推定器（SURE）を利用しました。 
[概要]それぞれが異なるサンプリングパターンで取得された画像のアンサンブルを使用するネットワークは、mseに非常に似ている可能性があります。高解像度や動的イメージングなど、いくつかのアプリケーションで画像をテストすることは困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-20">
        <br><font color="black">2020-10-20</font>
      </time>
    </span>
</section>
<!-- paper0: Brain Atlas Guided Attention U-Net for White Matter Hyperintensity
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_38.html">
      <font color="black">Brain Atlas Guided Attention U-Net for White Matter Hyperintensity
  Segmentation</font>
    </a>
  </h2>
  <font color="black">白質高信号（WMH）は、脳MRIでの脳小血管疾患（cSVD）の最も一般的な症状です。具体的には、2つの新しい接続メカニズム、つまりマルチ入力注意モジュール（MAM）を備えたデュアルパスセグメンテーションモデルを設計しました。正確な結果を得るために2つのパスからの情報を融合するアテンションフュージョンモジュール（AFM）。2つの公開されているデータセットでの実験は、提案されたBAGAU-Netの有効性を示しています。 
[要約]不適切なwmhセグメンテーションアルゴリズムは、csvdの負担とその臨床的影響を判断するために重要です。t1-加重画像は通常、急性脳卒中の患者のために取得される標準的な臨床スキャンの一部ではありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-19">
        <br><font color="black">2020-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Point-to-Keypoint Voting Network for 6D Pose Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_39.html">
      <font color="black">3D Point-to-Keypoint Voting Network for 6D Pose Estimation</font>
    </a>
  </h2>
  <font color="black">キーポイントを指す方向ベクトルがCNNによって予測された後、RANSAC投票を使用して3Dキーポイントの座標を計算し、最小二乗法によってポーズ変換を簡単に取得できます。ポイントごとの密な特徴の埋め込みを採用します。剛体の構造情報を最大限に活用する3Dキーポイントに投票します。さらに、ポイントの空間次元サンプリング戦略が採用されているため、この方法は小さなトレーニングセットで優れたパフォーマンスを実現します。 
[概要] 3Dキーポイントの3D構造特性に基づくrgb-dデータからの6Dポーズ推定のフレームワークを提案します。提案された方法は2つのベンチマークデータセットで検証されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Performance Analysis of Optimizers for Plant Disease Classification with
  Convolutional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_40.html">
      <font color="black">Performance Analysis of Optimizers for Plant Disease Classification with
  Convolutional Neural Networks</font>
    </a>
  </h2>
  <font color="black">この論文は、衛星、ドローンベース、またはモバイルベースの画像を利用してディープラーニング手法を使用して植物の病気を予測し、先取りできることを証明する研究分析に焦点を当てています。これにより、作物の不作や農業の損失が減少します。 ＆病気はインドの農業に固有のものであり、生産性の15〜25％の年間損失につながり、莫大な経済的損失をもたらします。この研究で使用されるさまざまなオプティマイザーには、RMSprop、Adam、AMSgradが含まれます。 
[要約]研究は、アダムオプティマイザーを使用して最高のパフォーマンスが達成されることを示しています。これは、植物病害の結果の分析に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-08">
        <br><font color="black">2020-11-08</font>
      </time>
    </span>
</section>
<!-- paper0: Predicting Online Video Advertising Effects with Multimodal Deep
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_41.html">
      <font color="black">Predicting Online Video Advertising Effects with Multimodal Deep
  Learning</font>
    </a>
  </h2>
  <font color="black">特に、2種類のメタデータ、つまりカテゴリカルと連続は適切に分離され、正規化されます。実験結果は、私たちのアプローチがベースライン（0.487）から大幅に改善された0.695もの高い相関係数を達成できることを示しています。 。トレーニングデータがあまり豊富ではないため、タスクで重要な過剰適合を回避するために、追加の正規化レイヤーが挿入されます。 
[概要]論文では、オンライン動画広告のマルチモーダルな性質を利用して効果を正確に予測するための最適化されたフレームワークを示しました。動画、テキスト、メタデータの機能が調査に含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: FaceDet3D: Facial Expressions with 3D Geometric Detail Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_42.html">
      <font color="black">FaceDet3D: Facial Expressions with 3D Geometric Detail Prediction</font>
    </a>
  </h2>
  <font color="black">プロジェクトのWebサイトは次のとおりです：http：//shahrukhathar.github.io/2020/12/14/FaceDet3D.html。顔の詳細は頂点ディスプレイスメントマップとして表され、ニューラルレンダラーによって使用されて、任意の単一画像の新しい画像を任意の表現とビューでフォトリアリスティックにレンダリングします。この作業では、最初のFaceDet3Dを紹介します。 -単一の画像から-任意のターゲット表現と一致する幾何学的な顔の詳細を生成する種類の方法。 
[ABSTRACT] facedet3dは、単一の画像から、任意のターゲット表現と一致する幾何学的な顔の詳細を生成する最初の種類です。この作業では、作成されたfaceet3dなどの最初の種類のメソッドであるfacedet3dを紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-14">
        <br><font color="black">2020-12-14</font>
      </time>
    </span>
</section>
<!-- paper0: Subject-independent Human Pose Image Construction with Commodity Wi-Fi -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_43.html">
      <font color="black">Subject-independent Human Pose Image Construction with Commodity Wi-Fi</font>
    </a>
  </h2>
  <font color="black">また、DINNをトレーニングするための新しいトレーニング方法を提案し、ドメイン敵対的アプローチと比較して再トレーニングのオーバーヘッドがありません。ただし、新しい科目、つまりトレーニングに参加していない科目に関しては、パフォーマンスが低下します。サンプル..次に、ドメインに依存しないニューラルネットワーク（DINN）を設計して、被験者に依存しない特徴を抽出し、それらをきめの細かい人間のポーズ画像に変換します。 
[概要]既存の論文は、以前のトレーニングサンプルに含まれる被験者の画像を作成するときに良好な結果を達成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Adaptive Exploitation of Pre-trained Deep Convolutional Neural Networks
  for Robust Visual Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_44.html">
      <font color="black">Adaptive Exploitation of Pre-trained Deep Convolutional Neural Networks
  for Robust Visual Tracking</font>
    </a>
  </h2>
  <font color="black">まず、このペーパーでは、4つの一般的に使用されるCNNモデルの包括的な分析を提供して、各モデルの最適な特徴マップを決定します。私たちの知る限り、これらの方法はすべて、シーン属性を考慮せずに固定数の畳み込み特徴マップを使用します（例： 、オクルージョン、変形、および高速モーション）を追跡中に発生する可能性があります。前提条件として、このペーパーでは、さまざまなトポロジのCNNモデルを活用できる方法に基づいた適応型識別相関フィルター（DCF）を提案します。 
[概要]異なるモデルを選択し、それらの特徴マップのさまざまな組み合わせを活用する効果はまだ完全には比較されていません。提案された方法は、ビデオ特性に関するビジュアルトラッカーの精度と堅牢性を向上させるために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-29">
        <br><font color="black">2020-08-29</font>
      </time>
    </span>
</section>
<!-- paper0: Modeling Deep Learning Based Privacy Attacks on Physical Mail -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_45.html">
      <font color="black">Modeling Deep Learning Based Privacy Attacks on Physical Mail</font>
    </a>
  </h2>
  <font color="black">最後に、私たちの定式化とモデルにより、物理的なメールに対するディープラーニングベースのプライバシー攻撃に対抗できる封筒を設計できます。メールのプライバシー保護は、通常の紙の封筒は私たちが考えるほど安全ではないため、封筒内の隠されたコンテンツへの不正アクセスを防ぐことを目的としています。 ..テクスチャや画像構造など、隠されたコンテンツの詳細を明確に復元できることを実験的に示します。 
[概要]ディープラーニングモデル、ディープラーニングは簡単に復元できます。ディープラーニングモデル。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient and Visualizable Convolutional Neural Networks for COVID-19
  Classification Using Chest CT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_46.html">
      <font color="black">Efficient and Visualizable Convolutional Neural Networks for COVID-19
  Classification Using Chest CT</font>
    </a>
  </h2>
  <font color="black">EfficientNet-B5は、精度0.9931 +/- 0.0021、F1スコア0.9931 +/- 0.0020、感度0.9952 +/- 0.0020、特異度0.9912 +/- 0.0048の最良のモデルとして識別されます。ただし、さまざまなタイプのデータと取得プロセスで得られた結果を比較することは簡単ではないため、COVID-19患者を特徴付ける最も正確なモデルは困難です。中間活性化マップと勾配加重クラス活性化マッピングは、モデルの地面の認識の人間が解釈できる証拠を提供します-クラスの不透明性と統合。人工知能を利用した放射線ツールの有望なユースケースを示唆しています。 
[要約]この論文では、covid-19診断のための40の異なる畳み込みニューラルネットワークアーキテクチャを評価および比較しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Residual Matrix Product State for Machine Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_47.html">
      <font color="black">Residual Matrix Product State for Machine Learning</font>
    </a>
  </h2>
  <font color="black">ResMPSは、そのレイヤーが「非表示」の特徴を出力（分類など）にマッピングするネットワークとして扱うことができ、レイヤーの変分パラメーターはサンプルの特徴（画像のピクセルなど）の関数です。ResMPS非線形アクティベーションおよびドロップアウトレイヤーを自然に組み込むことができ、効率、安定性、および表現力に関して最先端のTNモデルよりも優れています。これは、レイヤーがフィードフォワードでマッピングされるNNとは本質的に異なります。出力への機能。 
[ABSTRACT]量子ネットワーク（nn）モデルはnnですが、それでもかなりの精度のギャップがあります。ただし、tnと古典的なmlの洗練されたアートモデルの間にはまだかなりのギャップがあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: A Hybrid VDV Model for Automatic Diagnosis of Pneumothorax using
  Class-Imbalanced Chest X-rays Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_48.html">
      <font color="black">A Hybrid VDV Model for Automatic Diagnosis of Pneumothorax using
  Class-Imbalanced Chest X-rays Dataset</font>
    </a>
  </h2>
  <font color="black">データセットのサブセットのアンサンブル）は他のアプローチよりも優れています。提案されたフレームワークは、SIIM ACR気胸データセットとNIH胸部X線データセットのランダムサンプル（RS-NIH）でテストされます。RS-NIHの場合、得られた結果は比較して高くなります。以前の文献の結果とは異なりますが、最初のデータセットについては、このデータセットが気胸分類に以前に使用されていないため、直接比較することはできません。 
[要約]現在まで、利用可能な医用画像データセットのほとんどには、クラス-不均衡issue.mainとデータ-アンサンブルがあり、固定特徴抽出器としてvgg16、vgg-19、densenet-121を含む3つの畳み込みニューラルネットワーク（cnn）を使用しています。最初のデータセットの場合、85。17％のリコール、86.0％のレシーバー動作特性曲線（auc）の下の領域が達成されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Towards an Automatic System for Extracting Planar Orientations from
  Software Generated Point Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_49.html">
      <font color="black">Towards an Automatic System for Extracting Planar Orientations from
  Software Generated Point Clouds</font>
    </a>
  </h2>
  <font color="black">SfMタイプの手法は、データの忠実度の極端なレベルを犠牲にしながら、より多様な環境条件でのコストと使いやすさの分野で利点を提供します。ポイントクラウドノイズは、マハラノビス距離の実装を使用して軽減されます。一般に、これらの測定値は、基本的な機器を使用して手動で収集されます。 ;通常、手作業で地図に記録されたコンパス/傾斜計とバックボード。 
[概要]一般的に、これらの測定値は基本的な機器を使用して手動で収集されます。これらには、手作業で地図に記録されたコンパス、傾斜計、バックボードが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Multiscale Feature Learning for Overlapping Chromosome
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_50.html">
      <font color="black">Adversarial Multiscale Feature Learning for Overlapping Chromosome
  Segmentation</font>
    </a>
  </h2>
  <font color="black">染色体のストリップ形状により、画像化時に互いに重なりやすくなり、その後の分析の精度に大きく影響します。次に、条件付き生成敵対的ネットワーク（cGAN）を使用して、元の画像と同様の画像を生成します。トレーニングの安定性は、最小二乗GAN目標を適用することによって強化されます。この問題に対処するために、この論文では、重複する染色体セグメンテーションの精度と適応性を改善するための敵対的マルチスケール特徴学習フレームワークを提示します。 
[ABSTRACT]画像に基づく自動染色体核型分析は、分析の効率と精度を向上させるために日常的に使用されています。代わりに、システムは、ジェネレーターとして高密度スキップ接続を備えたネストされたu字型ネットワークなどのマルチスケール機能を活用するために使用されます。マルチスケール機能を活用して、染色体画像の最適な表現を探索する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Limitation of Acyclic Oriented Graphs Matching as Cell Tracking Accuracy
  Measure when Evaluating Mitosis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_51.html">
      <font color="black">Limitation of Acyclic Oriented Graphs Matching as Cell Tracking Accuracy
  Measure when Evaluating Mitosis</font>
    </a>
  </h2>
  <font color="black">この論文では、シミュレーションと実際の細胞追跡データの両方を使用して、AOGMで有糸分裂を評価することの限界を示します。したがって、非周期的指向グラフマッチング（AOGM）は、直接使用するのではなく、細胞追跡の事実上の標準評価指標として使用されています。複数オブジェクト追跡精度（MOTA）、IDスイッチ（IDS）、ID F1スコア（IDF1）などのコンピュータービジョンの評価指標。ただし、実験に基づいて、AOGMが常に期待どおりに機能するとは限らないことがわかりました。有糸分裂イベント。 
[ABSTRACT]細胞追跡は、通常motタスクの標準ではない有糸分裂（細胞分裂）の検出も目的としています。これら2つのタスクは、異なる細胞追跡方法を使用して開発されました。目的は、motではなくmot（mot）を追跡することでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Training Convolutional Neural Networks With Hebbian Principal Component
  Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_52.html">
      <font color="black">Training Convolutional Neural Networks With Hebbian Principal Component
  Analysis</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、これらの結果に基づいて、前の作業で使用したヘッブの勝者がすべてを取る（HWTA）戦略の代わりに、非線形ヘッブ主成分分析（HPCA）学習ルールを使用して、これらの設定でのヘッブ学習をさらに改善します。特に、HPCAルールは、CIFAR-10画像データセットから関連する特徴を抽出するために畳み込みニューラルネットワークをトレーニングするために使用されます。たとえば、ヘッブ学習は、事前にトレーニングされた深部ニューラルネットワークの上位層を再トレーニングするのに効果的です。 、
[ABSTRACT]ヘッブ学習で同等の精度を達成することで、ニューラルネットワークの下位層または上位層のトレーニングに使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: YolactEdge: Real-time Instance Segmentation on the Edge (Jetson AGX
  Xavier: 30 FPS, RTX 2080 Ti: 170 FPS) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_53.html">
      <font color="black">YolactEdge: Real-time Instance Segmentation on the Edge (Jetson AGX
  Xavier: 30 FPS, RTX 2080 Ti: 170 FPS)</font>
    </a>
  </h2>
  <font color="black">これを実現するために、最先端の画像ベースのリアルタイム手法YOLACTに2つの改善を加えます。（1）速度と精度を慎重にトレードオフしながらTensorRTを最適化すること、および（2）活用する新しい機能ワーピングモジュールビデオの時間的冗長性..また、設計の選択とモジュールを分析するためにアブレーション研究を実施します。YouTubeVISおよびMS COCOデータセットでの実験は、YolactEdgeが競合するマスクを生成しながら既存のリアルタイムメソッドよりも3〜5倍高速になることを示しています。ボックス検出精度。 
[概要] yolactedgeは、jetson agxxavierで最大30.8 fps（およびrtx 2080tiで172.7 fps）で実行され、resnet-550x550イメージで101バックボーン</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: This is not the Texture you are looking for! Introducing Novel
  Counterfactual Explanations for Non-Experts using Generative Adversarial
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_54.html">
      <font color="black">This is not the Texture you are looking for! Introducing Novel
  Counterfactual Explanations for Non-Experts using Generative Adversarial
  Learning</font>
    </a>
  </h2>
  <font color="black">逆に、反事実的説明システムは、分類器が異なる予測を行うように入力画像を変更することによって、反事実的推論を可能にしようとします。私たちの結果は、私たちのアプローチがメンタルモデル、説明の満足度、信頼に関して大幅に良い結果につながることを示しています、感情、および顕著性マップで動作する2つの最先端システム、つまりLIMEとLRPよりも自己効率的です。この作業では、敵対的な画像から-への画像に基づいて、そのような反事実的な画像の説明を生成する新しいアプローチを提示します。画像翻訳技術。 
[ABSTRACT]反事実的説明システムは、敵対的な画像から画像への翻訳技術に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: PC-RGNN: Point Cloud Completion and Graph Neural Network for 3D Object
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CV/paper_55.html">
      <font color="black">PC-RGNN: Point Cloud Completion and Graph Neural Network for 3D Object
  Detection</font>
    </a>
  </h2>
  <font color="black">一方、グラフニューラルネットワークモジュールが設計されており、ローカルグローバルアテンションメカニズムとマルチスケールグラフベースのコンテキスト集約を通じてポイント間の関係を包括的にキャプチャし、エンコードされた機能を大幅に強化します。KITTIベンチマークでの広範な実験提案されたアプローチは、以前の最先端のベースラインを大幅に上回り、その有効性を強調しています。一方で、ポイントクラウド補完モジュールを導入して、密なポイントとビュー全体の高品質な提案を元の状態で復元します。保存された構造。 
[概要] pc-rgnnの概念が新しい論文で提案されています。開発中のパターンニューラルネットワークモジュールに従います。概念をどれだけ効果的に開発できるかを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-18">
        <br><font color="black">2020-12-18</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Semi-Supervised Disentangled Framework for Transferable Named Entity
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_0.html">
      <font color="black">Semi-Supervised Disentangled Framework for Transferable Named Entity
  Recognition</font>
    </a>
  </h2>
  <font color="black">（2）意味情報などのドメイン固有の情報をモデルに統合して、NERのパフォーマンスを向上させます。ただし、NERモデルが広く使用されているにもかかわらず、大規模なラベル付きデータセットが必要であるため、大きな負担がかかります。ドメイン固有およびドメイン不変の潜在変数は、3つの相互情報正規化項を使用して解きほぐされます。つまり、ドメイン固有の潜在変数と元の埋め込みの間の相互情報を最大化し、ドメイン間の相互情報を最大化します。不変の潜在変数と元の埋め込み、およびドメイン固有とドメイン不変の潜在変数間の相互情報を最小化します。 
[概要]クロスドメインナーモデルには、依然として大規模なラベル付きデータセットが必要ですが、有望なデータセットが必要であり、手動の注釈により大きな負担がかかります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Event-Driven Query Expansion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_1.html">
      <font color="black">Event-Driven Query Expansion</font>
    </a>
  </h2>
  <font color="black">候補を特定するために、新しいメカニズムを利用して、単語とイベントを同じベクトル空間に同時に埋め込みます。イベントを活用する提案された方法は、さまざまなニュースワイヤーの最先端の方法と比較して、クエリ拡張のパフォーマンスを大幅に向上させることを示します。 TRECデータセット..最初にそれに関連するイベントを検出することにより、イベント関連のクエリを拡張する方法を提案します。 
[概要]イベントを活用して関連情報の向上を図ります。イベントを活用して検索タスクをターゲットとする新しい方法を作成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Adaptation of NMT models for English-Hindi Machine Translation
  Task at AdapMT ICON 2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_2.html">
      <font color="black">Domain Adaptation of NMT models for English-Hindi Machine Translation
  Task at AdapMT ICON 2020</font>
    </a>
  </h2>
  <font color="black">BLEUスコアに基づいて、英語-ヒンディー語の機械翻訳タスクに対する2つの一般的なNMTモデル、つまりLSTMとTransformerアーキテクチャの有効性を評価しました。ドメイン適応には微調整と混合ドメインデータアプローチが使用されます。これらをトレーニングします。モデルは主にドメイン外データを使用し、ドメイン内データセットの特性に基づいた単純なドメイン適応手法を採用しています。 
[概要]英語の2つの人気モデルの有効性を調べました-ブルースコアに基づくヒンディー語の機械翻訳タスク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Dual Paraphrasing for Two-stage Semantic Parsing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_3.html">
      <font color="black">Unsupervised Dual Paraphrasing for Two-stage Semantic Parsing</font>
    </a>
  </h2>
  <font color="black">ダウンストリームのナイーブセマンティックパーサーは、中間出力を受け入れ、ターゲットの論理形式を返します。ベンチマークでの実験結果OvernightとGeoGrannoは、フレームワークが効果的であり、教師ありトレーニングと互換性があることを示しています。教師なしパラフレーズモデル。 
[概要]最初の段階では、教師なし言い換えモデルを使用して、ラベルのない自然言語の発話を聖書の発話に変換します。トレーニングプロセス全体は、事前トレーニングとサイクル学習の2つのフェーズに分かれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-27">
        <br><font color="black">2020-05-27</font>
      </time>
    </span>
</section>
<!-- paper0: Hopfield Networks is All You Need -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_4.html">
      <font color="black">Hopfield Networks is All You Need</font>
    </a>
  </h2>
  <font color="black">これらのホップフィールド層は、完全接続、畳み込み、またはリカレントネットワークを超えて、ディープラーニングの新しい方法を可能にし、プーリング、メモリ、関連付け、および注意メカニズムを提供します。新しい更新ルールは、トランスフォーマーで使用される注意メカニズムと同等です。同等性により、トランスモデルのヘッドの特性評価が可能になります。 
[ABSTRACT]新しいホップフィールドネットワークは、1回の更新で指数関数的に保存し、パターンを取得できます。新しい更新ルールは、transformers.layersで使用されるアテンションメカニズムと同等です。2つのドラッグデザインデータセットの最新技術を改善しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Acronym Identification and Disambiguation shared tasksfor Scientific
  Document Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_5.html">
      <font color="black">Acronym Identification and Disambiguation shared tasksfor Scientific
  Document Understanding</font>
    </a>
  </h2>
  <font color="black">2つの共有タスクにはそれぞれ52人と43人の参加者が集まりました。このペーパーでは、2つの共有タスクとそれぞれの主要な参加システムを確認します。この方向で研究を進めるために、頭字語の識別とそれぞれAI @ SDUおよびAD @ SDUという名前の科学文書における頭字語の明確化。 
[概要] ai @sduとad @ sduの研究者は、科学的な形で頭字語の識別と頭字語の明確化のタスクを共有しています。目的は、この方向で研究を進めることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Generating (Factual?) Narrative Summaries of RCTs: Experiments with
  Neural Multi-Document Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_6.html">
      <font color="black">Generating (Factual?) Narrative Summaries of RCTs: Experiments with
  Neural Multi-Document Summarization</font>
    </a>
  </h2>
  <font color="black">複数の試験報告から物語の生物医学的証拠の要約を自動的に生成する問題を検討します。これらの戦略により、生成された要約の事実の正確性が適度に向上することがわかります。以前に実施された系統的レビューから、関連する記事の要約の要約を現代の神経モデルで評価します。コクラン共同計画のメンバーによる、レビュー要約の著者の結論セクションをターゲットとして使用。 
[要約]コクラン共同計画のメンバーによって以前に実施された系統的レビューからの関連記事サンプルの抽象的要約のために、最新の神経モデルを評価します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Adjust-free adversarial example generation in speech recognition using
  evolutionary multi-objective optimization under black-box condition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_7.html">
      <font color="black">Adjust-free adversarial example generation in speech recognition using
  evolutionary multi-objective optimization under black-box condition</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案された方法が、タイミングラグに対して十分にロバストであり、攻撃者がターゲットスピーチに対してそれを再生するタイミングを取る必要がないように、調整のない敵対的な例を首尾よく生成したことを示した。ブラックボックスシナリオの下でロバストな敵対的例を生成することを可能にする多目的最適化（EMO）。この論文は、自動音声認識システムへのブラックボックス敵対的攻撃方法を提案します。 
[概要]一部の研究では、音声認識のためにニューラルネットワークを攻撃しようとしましたが、これらの方法では、ターゲット音声とのタイミングラグに対する敵対的な例の堅牢性は考慮されていませんでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: Discovering New Intents with Deep Aligned Clustering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_8.html">
      <font color="black">Discovering New Intents with Deep Aligned Clustering</font>
    </a>
  </h2>
  <font color="black">（コードはhttps://github.com/hanleizhang/DeepAligned-Clusteringで入手できます）。最初に、いくつかのラベル付きの既知の意図サンプルを事前知識として活用してモデルを事前トレーニングします。次に、k-meansを実行して、疑似ラベルとしてクラスター割り当てを生成します。 
[概要]この作業では、限られた既知のインテントデータを使用して新しいインテントを発見するための効果的な方法（ディープアラインクラスタリング）を提案します。k-は、クラスター割り当てを疑似ラベルとして生成することを意味します。テスト中に、整列された疑似ラベルの監督下での意図表現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Recognizing Emotion Cause in Conversations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_9.html">
      <font color="black">Recognizing Emotion Cause in Conversations</font>
    </a>
  </h2>
  <font color="black">さらに、原因の原因に基づいてさまざまな原因タイプを定義し、RECCONの2つの異なるサブタスクに対処するための強力なトランスフォーマーベースのベースラインを確立します：1）因果スパン抽出と2）因果感情含意..感情の背後にある原因の認識テキストは、NLPの基本的でありながら未踏の研究分野です。この目的のために、RECCONという名前の付随するデータセットとの会話で感情の原因を認識するタスクを紹介します。 
[概要]データセットはrecconと呼ばれ、感情の原因を認識するテキストの一種です。www.com/ / / github ofresearchで入手できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: TextDecepter: Hard Label Black Box Attack on Text Classifiers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_10.html">
      <font color="black">TextDecepter: Hard Label Black Box Attack on Text Classifiers</font>
    </a>
  </h2>
  <font color="black">これらの敵対的な例の生成は、モデルをより堅牢にするのに役立ち、これらのモデルの基礎となる意思決定への洞察を与えてくれます。近年、テキストアプリケーションに対する敵対的な例の作成に関する研究が増えています。攻撃シナリオは、感情分析や有毒コンテンツの検出など、セキュリティに敏感なアプリケーションに使用されている実際のブラックボックスモデルに適用されます。 
[要約]これらの敵対的な例の生成は、モデルをより堅牢にするのに役立ちます。これにより、これらのモデルの使用に関する洞察が得られます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-16">
        <br><font color="black">2020-08-16</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal Research in Vision and Language: A Review of Current and
  Emerging Trends -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_11.html">
      <font color="black">Multimodal Research in Vision and Language: A Review of Current and
  Emerging Trends</font>
    </a>
  </h2>
  <font color="black">この調査では、VisLangの研究における最近の文献を引き付ける主要な傾向を特定し、この分野が向かっている方向を明らかにしようとしています。タスクの定式化におけるそのアプリケーションと、意味認識とコンテンツ生成に関連するさまざまな問題を解決する方法についても見ていきます。タスク固有の傾向に加えて、それらの評価戦略と今後の課題に対処します。 
[概要]これにより、ビジョンと言語の分野の交差点での研究への関心が高まりました。タスクの具体化におけるそのアプリケーションと、セマンティック知覚とコンテンツ生成に関連するさまざまな問題を解決する方法について説明します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-19">
        <br><font color="black">2020-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: Applying wav2vec2.0 to Speech Recognition in various low-resource
  languages -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_12.html">
      <font color="black">Applying wav2vec2.0 to Speech Recognition in various low-resource
  languages</font>
    </a>
  </h2>
  <font color="black">言語に対する普遍性を検証するために、リリースされた事前トレーニング済みモデルを適用して、さまざまな話し言葉での低リソースの音声認識タスクを解決します。音声ドメインでは、wav2vec2.0はその強力な表現能力と超低の実現可能性を示し始めます。 Librispeechコーパスでのリソース音声認識..これらの言語の中で、英語は52.4 \％まで向上します。 
[概要]これらのモデルは、ラベルのない大量のデータで事前にトレーニングされています。ダウンストリームのタスクに効果的に適用できます。このモデルは、実際の会話シナリオや英語以外の言語ではテストされていません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Uncertainty and Surprisal Jointly Deliver the Punchline: Exploiting
  Incongruity-Based Features for Humor Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_13.html">
      <font color="black">Uncertainty and Surprisal Jointly Deliver the Punchline: Exploiting
  Incongruity-Based Features for Humor Recognition</font>
    </a>
  </h2>
  <font color="black">ますます強力な言語モデルにより、セットアップをオチとともにGPT-2言語モデルにフィードし、ジョークの不確実性と驚きの値を計算することができました。ジョークを2つの異なるコンポーネントに分解します。 SemEval 2021 Task 7データセットで実験を行うことにより、これら2つの機能には、既存のベースラインと比較して、ジョークと非ジョークを区別する機能が優れていることがわかりました。 
[概要]一部の既存の作業では、ユーモアを理解するために実際のジョークメカニズムを調べていません。これらの2つの機能は、既存のベースラインと比較して、ジョークと非ジョークを区別する機能が優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: A Hierarchical Reasoning Graph Neural Network for The Automatic Scoring
  of Answer Transcriptions in Video Job Interviews -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_14.html">
      <font color="black">A Hierarchical Reasoning Graph Neural Network for The Automatic Scoring
  of Answer Transcriptions in Video Job Interviews</font>
    </a>
  </h2>
  <font color="black">これらのグラフに基づいて、セマンティックレベルの推論グラフ注意ネットワークを使用して、現在のQAセッションの相互作用状態をモデル化します。自動音声認識（ASR）から、テキストの特徴に基づいて候補者の能力を自動的にスコアリングするタスクに対処します。 ）非同期ビデオ就職面接（AVI）での転記。具体的には、質問と回答の間の文の依存関係情報をキャプチャするために、文レベルのリレーショナルグラフニューラルネットワークを構築します。 
[概要]重要な課題は、質問と回答の間に依存関係を構築し、各質問と回答（qa）のペアに対してセマンティックレベルの相互作用を実行する方法です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Graph-Evolving Meta-Learning for Low-Resource Medical Dialogue
  Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_15.html">
      <font color="black">Graph-Evolving Meta-Learning for Low-Resource Medical Dialogue
  Generation</font>
    </a>
  </h2>
  <font color="black">CMDDデータセットと新しく収集されたChunyuデータセットに関する広範な実験結果は、最先端のアプローチに対するアプローチの優位性を証明しています。この問題に対処するために、より自然で実用的なパラダイム、つまり低リソースを提案します。診断経験をソース疾患からターゲット疾患に転送し、適応のための少数のデータを使用できる医療対話生成。さらに重要なことに、GEMLは、疾患症状グラフを動的に進化させることにより、疾患症状が抱える現実の課題にもうまく対処します。各疾患の相関関係は、より多くの診断症例とともに変化または進化する可能性があります。 
[ABSTRACT] gemlは、インタラクティブな知識-敏感な知識グラフを作成できます。これは、常識的な知識グラフに基づいて、以前の病気を特徴づける-症状の関係</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-Supervised Low-Resource Style Transfer of Indonesian Informal to
  Formal Language with Iterative Forward-Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_16.html">
      <font color="black">Semi-Supervised Low-Resource Style Transfer of Indonesian Informal to
  Formal Language with Iterative Forward-Translation</font>
    </a>
  </h2>
  <font color="black">非公式から正式なインドネシア語へのスタイル転送を実行するためのいくつかの戦略をベンチマークします。調査結果は、スタイル転送に機械翻訳モデルを活用するための有望なステップを示しています。また、人工的な前方翻訳データでトレーニングセットを強化することも検討しています。 
[概要]現在利用可能なインドネシア語のnlpモデルは、通常、標準的なインドネシア語を念頭に置いて開発されています。非公式のインドネシア語とその正式な対応物の住所文の新しいデータセットを構築します。また、人工的な前方翻訳データを使用してトレーニングセットを拡張することも検討しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-06">
        <br><font color="black">2020-11-06</font>
      </time>
    </span>
</section>
<!-- paper0: Pre-Training a Language Model Without Human Language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_17.html">
      <font color="black">Pre-Training a Language Model Without Human Language</font>
    </a>
  </h2>
  <font color="black">驚いたことに、特定の非人間言語データでの事前トレーニングにより、GLUEのパフォーマンスが別の非英語言語で事前トレーニングされたパフォーマンスに近くなることがわかりました。このホワイトペーパーでは、事前トレーニングデータの本質的な性質を調査します。ダウンストリームのパフォーマンスの微調整に貢献します。また、構造化データの事前トレーニングによって、モデルが自然言語のダウンストリームタスクに転送できる能力を獲得できるとは限らないこともわかりました。 
[概要]さまざまなトランスフォーマーをトレーニングします-いくつかのコーパスでマスクされた言語モデルに基づいています。微調整します-接着剤ベンチマークでそれらの言語タスクを調整します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Meta Sampling for Multilingual Low-Resource Speech
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_18.html">
      <font color="black">Adversarial Meta Sampling for Multilingual Low-Resource Speech
  Recognition</font>
    </a>
  </h2>
  <font color="black">低リソースのターゲット言語データではASRモデルを適切にトレーニングできないため、低リソースの自動音声認識（ASR）は困難です。この問題を解決するために、メタ学習は各ソース言語のASRを多くの小さなASRタスクとメタに定式化します。さまざまなソース言語からのすべてのタスクでモデルの初期化を学習し、見えないターゲット言語での高速適応にアクセスします。最後に、2つの多言語データセットでの実験結果は、MML-ASRにAMSを適用するとパフォーマンスが大幅に向上することを示し、AMSの適用性も示しています。他の低リソースの音声タスクと転移学習ASRアプローチ。 
[要約]各ソース言語について、質問の損失が大きい場合、そのタスクは、量と難易度の観点からasrモデルをトレーニングするために十分にサンプリングされていないことを意味します。mml-asrのリソースは学習状況をマスターできるため、予測できます。各言語の良好なタスクサンプリング確率</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Undivided Attention: Are Intermediate Layers Necessary for BERT? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_19.html">
      <font color="black">Undivided Attention: Are Intermediate Layers Necessary for BERT?</font>
    </a>
  </h2>
  <font color="black">中間層の数を減らし、BERT-Baseのアーキテクチャを変更すると、モデルのパラメーターの数とトレーニング時間を減らしながら、ダウンストリームタスクの微調整精度の損失を最小限に抑えることができることを示します。ただし、これらの中間層を含めることは、文献にはありません。さらに、中央カーネルアラインメント（CKA）類似性メトリックとプロービング分類器を使用して、中間層の削除が学習した自己注意表現にほとんど影響を与えないことを示します。 
[概要]すべてのbertベースのアーキテクチャには、基本的な構築コンポーネントとして、自己注意ブロックとそれに続く中間層のブロックがあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Few-Shot Text Generation with Pattern-Exploiting Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_20.html">
      <font color="black">Few-Shot Text Generation with Pattern-Exploiting Training</font>
    </a>
  </h2>
  <font color="black">いくつかのテキスト要約と見出し生成データセットで、提案されたPETのバリアントは、数ショットの設定で強力なベースラインに対して一貫した改善を提供します。例からの勾配ベースの学習と組み合わせた場合のテキスト分類タスクの範囲..この論文では、基礎となるアイデアがテキスト生成タスクにも適用できることを示します。最近提案された少数のパターン活用トレーニング（PET）を適応させます。テキスト生成タスクで生成言語モデルを微調整するためのショットアプローチ。 
[概要]最近提案された数ショットのアプローチであるパターン活用トレーニング（ペット）を、テキスト生成タスクで一般的な言語モデルを微調整するために適応させます。テキストメッセージは数ショットのアプローチですが、テキストメッセージにも適用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: KQA Pro: A Large-Scale Dataset with Interpretable Programs and Accurate
  SPARQLs for Complex Question Answering over Knowledge Base -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_21.html">
      <font color="black">KQA Pro: A Large-Scale Dataset with Interpretable Programs and Accurate
  SPARQLs for Complex Question Answering over Knowledge Base</font>
    </a>
  </h2>
  <font color="black">少数のテンプレートを使用して質問、対応するSPARQL、およびプログラムを生成する構成戦略を提案し、生成された質問をクラウドソーシングによって自然言語の質問（NLQ）に言い換えて、約12万の多様なインスタンスを生成します。マシンがさまざまなケース、つまりQA監視のみ、または中間のSPARQL /プログラム監視で複雑な質問に答えることを学習できるかどうかを評価します。QAペアのみから学習した最先端のKBQAメソッドのパフォーマンスは非常に低いことがわかります。私たちのデータセットでは、私たちの質問が以前のデータセットよりも難しいことを意味します。 
[抽象]質問はテンプレートによって生成され、多様性が低下するか、小規模になります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Retrieve Entity-Aware Knowledge and Generate Responses with
  Copy Mechanism for Task-Oriented Dialogue Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_22.html">
      <font color="black">Learning to Retrieve Entity-Aware Knowledge and Generate Responses with
  Copy Mechanism for Task-Oriented Dialogue Systems</font>
    </a>
  </h2>
  <font color="black">サブタスク3では、潜在変数を使用してダイアログ履歴と選択した知識をより適切にエンコードし、コピーメカニズムと組み合わせて応答を生成します。一方、生成タスクで知識をさらに活用するために、モデルの最終出力に対していくつかの有用な後処理戦略が実行されます。 ..サブタスク1および2の場合、ドメインやエンティティなどの大まかな情報を使用して、知識の使用を強化します。 
[概要]この課題は3つのサブタスクに分けることができます。サブタスクには知識が含まれます-ターン検出と他の方法を求めます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: An Online Multilingual Hate speech Recognition System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_23.html">
      <font color="black">An Online Multilingual Hate speech Recognition System</font>
    </a>
  </h2>
  <font color="black">ベースラインモデルを作成し、さまざまな最適化手法を使用してモデルのパフォーマンススコアを向上させます。英語とヒンディー語の2つの言語での多言語モデルの競争力のあるパフォーマンスを証明し、ほとんどの単一言語モデルと同等またはそれ以上のパフォーマンスを実現します。過去20年間のインターネットとソーシャルメディアの使用は、人間の相互作用を変えました。 
[概要]これは多くの肯定的な結果をもたらしましたが、同時にリスクと害をもたらしました。これらは、憎悪やどちらでもないなどの人間の行動の例です。私たちは、効果的な指標でページを識別してスコアリングするツールを作成します。ほぼリアルタイム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: g2tmn at Constraint@AAAI2021: Exploiting CT-BERT and Ensembling Learning
  for COVID-19 Fake News Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_24.html">
      <font color="black">g2tmn at Constraint@AAAI2021: Exploiting CT-BERT and Ensembling Learning
  for COVID-19 Fake News Detection</font>
    </a>
  </h2>
  <font color="black">使用したモデル、テキストの前処理方法、データの追加方法について説明します。ただし、すべてのソーシャルメディアの投稿が真実であるとは限りません。特に、COVID-Twitter-BERT（CT）に基づくトランスフォーマーベースのアンサンブルを使用したアプローチを提案します。 -BERT）。 
[概要]コロナウイルスのパンデミックとその結果はソーシャルメディアで議論されています。それらの多くは、パニックを引き起こし、人々に誤解を与える偽のニュースを広めています。特に、covidに基づくトランスベースのアンサンブルを使用したアプローチを提案します-twitter-bert（ ct-bert）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Improved Biomedical Word Embeddings in the Transformer Era -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/cs.CL/paper_25.html">
      <font color="black">Improved Biomedical Word Embeddings in the Transformer Era</font>
    </a>
  </h2>
  <font color="black">概念と用語を選択的に選別することなく（以前の取り組みで追求されたように）、静的埋め込みのこれまでで最も徹底的な評価を提供し、全体的なパフォーマンスが明らかに向上したと考えています。単語の複数のデータセットを使用して、これらの調整された静的埋め込みの評価を行います。と以前の取り組みによって開発された概念の関連性..私たちは、ダウンストリームのアプリケーションや研究活動のために公共で使用するための埋め込みを提供します：https：//github.com/bionlproc/BERT-CRel-Embeddings 
[ABSTRACT]複数のデータセットを使用して埋め込みの評価を行います。以前の取り組みによって開発された単語と概念の関連性のために。私たちは、ダウンストリームのアプリケーションまたは研究の取り組みのために公共の使用のために埋め込みを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Adjust-free adversarial example generation in speech recognition using
  evolutionary multi-objective optimization under black-box condition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.AS/paper_0.html">
      <font color="black">Adjust-free adversarial example generation in speech recognition using
  evolutionary multi-objective optimization under black-box condition</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案された方法が、タイミングラグに対して十分にロバストであり、攻撃者がターゲットスピーチに対してそれを再生するタイミングを取る必要がない、調整のない敵対的な例を首尾よく生成したことを示した。この論文は、ブラックボックス敵対者を提案する。自動音声認識システムへの攻撃方法..この論文で提案された方法は、ブラックボックスシナリオの下でロバストな敵対的な例を生成することを可能にする進化的多目的最適化（EMO）を採用しています。 
[概要]一部の研究では、音声認識のためにニューラルネットワークを攻撃しようとしましたが、これらの方法では、ターゲット音声とのタイミングラグに対する敵対的な例の堅牢性は考慮されていませんでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-21">
        <br><font color="black">2020-12-21</font>
      </time>
    </span>
</section>
<!-- paper0: On the effectiveness of signal decomposition, feature extraction and
  selection on lung sound classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.AS/paper_1.html">
      <font color="black">On the effectiveness of signal decomposition, feature extraction and
  selection on lung sound classification</font>
    </a>
  </h2>
  <font color="black">Mel周波数ケプストラム係数とともに高次の統計的およびスペクトル的特徴がクラシエに供給されると、kNN分類器で最高のパフォーマンスが得られ、最高の精度が得られることがわかります。Kaggleからダウンロードされたオープンソースデータセット。さまざまな品質の胸部聴診を使用して、さまざまな分解と特徴抽出の組み合わせを使用した結果を決定します。経験的モード分解、アンサンブル経験的モード分解、離散ウェーブレット変換などの分解方法が、主要コンポーネントなどのいくつかの特徴抽出手法とともに使用されます。分析と自動エンコーダー。特定のタスクに対してさまざまな分類子がどのように実行されるかを調べます。 
[概要]肺音は非水平ですが、通常ほど正常ではありません。これらは肺音と呼ばれ、肺音と互換性がありません。これらのタイプの分析は、さまざまな分解を使用した結果を決定するために使用されます。特徴選択方法の組み合わせを使用すると、分類器の精度に悪影響を与えることなく、入力特徴の数を大幅に減らすことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Meta Sampling for Multilingual Low-Resource Speech
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-23/eess.AS/paper_2.html">
      <font color="black">Adversarial Meta Sampling for Multilingual Low-Resource Speech
  Recognition</font>
    </a>
  </h2>
  <font color="black">最後に、2つの多言語データセットでの実験結果は、MML-ASRにAMSを適用するとパフォーマンスが大幅に向上することを示し、他の低リソース音声タスクおよび転移学習ASRアプローチへのAMSの適用性も示しています。この問題を解決するために、メタラーニング各ソース言語のASRを多くの小さなASRタスクに定式化し、さまざまなソース言語からのすべてのタスクでモデルの初期化をメタ学習して、見えないターゲット言語での高速適応にアクセスします。したがって、学習したタスクサンプリングポリシーは、各言語の学習状況をマスターできます。したがって、より効果的な学習のために、各言語の適切なタスクサンプリング確率を予測します。 
[要約]各ソース言語について、質問の損失が大きい場合、そのタスクは、量と難易度の観点からasrモデルをトレーニングするために十分にサンプリングされていないことを意味します。mml-asrのリソースは学習状況をマスターできるため、予測できます。各言語の良好なタスクサンプリング確率</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
