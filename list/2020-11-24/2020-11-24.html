<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-11-24の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: AVGZSLNet: Audio-Visual Generalized Zero-Shot Learning by Reconstructing
  Label Features from Multi-Modal Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.SD/paper_0.html">
      <font color="black">AVGZSLNet: Audio-Visual Generalized Zero-Shot Learning by Reconstructing
  Label Features from Multi-Modal Embeddings</font>
    </a>
  </h2>
  <font color="black">これは、オーディオとビデオの埋め込みをクラスラベルのテキスト埋め込みに近づけるのに役立ちます。同じクラスの埋め込みを近づけ、マルチモーダル設定で異なるクラスの埋め込みを押しのけるのに役立ちます。この論文では、提案します。マルチモーダル設定での一般化されたゼロショット学習のための新しいアプローチ。テスト中には、トレーニング中には見られない新しいクラスのオーディオ/ビデオがあります。 
[概要]ゼロショット学習の手段として、テキスト埋め込みの意味的関連性を使用します。オーディオとビデオの埋め込みを対応するクラスラベルのテキスト機能スペースに合わせます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-27">
        <br><font color="black">2020-05-27</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-end Silent Speech Recognition with Acoustic Sensing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.SD/paper_1.html">
      <font color="black">End-to-end Silent Speech Recognition with Acoustic Sensing</font>
    </a>
  </h2>
  <font color="black">限られた語彙（54文）での評価結果は、話者や環境に依存しない設定で8.4％、目に見えない文のテストで8.1％の単語誤り率をもたらします。また、エンドツーエンドの認識フレームワークを提案します。 CNNと注意ベースのエンコーダ-デコーダネットワークを組み合わせます。これらの反射の抽出された位相特徴は、音声を認識するために深層学習ネットワークに供給されます。 
[概要]聞こえない音響信号を使用して、人々が話すときの唇の動きをキャプチャするサイレント音声インターフェイスを紹介します。これらの反射の抽出された位相特徴は、音声を認識するために深層学習ネットワークに送られます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Discriminative Neural Clustering for Speaker Diarisation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.SD/paper_2.html">
      <font color="black">Discriminative Neural Clustering for Speaker Diarisation</font>
    </a>
  </h2>
  <font color="black">AMIの実験結果は、DNCがスペクトルクラスタリングと比較して29.4％のスピーカーエラー率（SER）の削減を達成することを示しています。従来の教師なしクラスタリングアルゴリズムと比較して、DNCは類似性尺度の明示的な定義を必要とせずにトレーニングデータからクラスタリングパターンを学習します。 .Transformerアーキテクチャに基づくDNCの実装は、困難なAMIデータセットを使用したスピーカーのダイアリゼーションタスクで効果的であることが示されています。 
[ABSTRACT] dncは、類似性測度の明示的な定義を必要とせずに、トレーニングデータからクラスタリングパターンを学習します。データの不足は、8月のトランスモデルをトレーニングするための重要な問題です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-22">
        <br><font color="black">2019-10-22</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Sparse Inpainting with Smoothed Particle Hydrodynamics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.IV/paper_0.html">
      <font color="black">Sparse Inpainting with Smoothed Particle Hydrodynamics</font>
    </a>
  </h2>
  <font color="black">この空間最適化に加えて、結果をさらに改善するためにデータ値の最適化も実装されます。従来のガウス平滑化カーネルとは別に、ランダムマスクと空間最適化マスクの両方で他のカーネルのパフォーマンスを評価します。その素朴な定式化であるSPH手法では、定数関数を再現することすらできません。アプローチを変更して、定数関数と線形関数を再現できる近似を取得します。 
[概要]この作業の主な目標は、Smoothed Particle Hydrorod（sph）手法を使用して、スパース分布画像サンプルのセットから修復プロセスを実行することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Lossless CNN Channel Pruning via Decoupling Remembering and Forgetting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.IV/paper_1.html">
      <font color="black">Lossless CNN Channel Pruning via Decoupling Remembering and Forgetting</font>
    </a>
  </h2>
  <font color="black">このような方法論は、ResRepを、パラメーターにペナルティを適用して構造化されたスパース性を生成する従来の学習ベースのプルーニングパラダイムと区別します。これにより、記憶に不可欠なパラメーターが抑制される可能性があります。ロスレスチャネルプルーニングの新しい方法であるResRepを提案します（別名。前者では通常のSGDを使用して再パラメーター化されたモデルをトレーニングしますが、後者ではペナルティ勾配を使用した新しい更新ルールを使用して、構造化されたスパース性を実現し、再パラメーター化されたモデルをより狭いレイヤーを持つ元のアーキテクチャに同等に変換できるようにします。
[要約] 「フィルタープルーニング」は、畳み込みニューラルネットワーク（cnn）をスリム化することを目的としています。これにより、畳み込みレイヤーの幅（出力チャネルの数）が削減されます。メソッドは、標準のresnetをスリム化します-50、イメージネットで76. 15％の精度でより狭いものにわずか45％のフロップで、精度の低下はありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Industrial object, machine part and defect recognition towards fully
  automated industrial monitoring employing deep learning. The case of
  multilevel VGG19 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.IV/paper_2.html">
      <font color="black">Industrial object, machine part and defect recognition towards fully
  automated industrial monitoring employing deep learning. The case of
  multilevel VGG19</font>
    </a>
  </h2>
  <font color="black">Virtual Geometry Group（VGG）ネットワークの最近の成功に動機付けられて、マルチパスVGG19と呼ばれるその修正バージョンを提案します。これにより、ローカルおよびグローバルな特徴抽出が可能になり、追加の特徴は連結によって融合されます。研究では、パターン認識のための特殊なモデルの開発を目的として、欠陥材料と産業用ツールまたはエンジン部品を含む6つの公開されている産業関連データセットを採用しました。DeepLearningは進歩していますが、リアルタイムのオブジェクト検出やその他のタスクが可能です。欠陥検出と産業物体認識のために特別に設計された畳み込みニューラルネットワークの有効性についてはほとんど調査されていません。 
[概要]全自動生産工程では、機械部品の監視が必須です。実験はニューヨーク大学の研究者が実施しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Global Voxel Transformer Networks for Augmented Microscopy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.IV/paper_3.html">
      <font color="black">Global Voxel Transformer Networks for Augmented Microscopy</font>
    </a>
  </h2>
  <font color="black">提案された方法を、さまざまな設定で3つの異なる拡張顕微鏡タスクの既存のデータセットに適用します。GVTNetは、畳み込みのようなローカルオペレーターではなく、グローバル情報を集約できるグローバルボクセルトランスフォーマーオペレーター（GVTO）上に構築されます。深い学習により、拡張顕微鏡法で目覚ましい成功を収め、高価な顕微鏡ハードウェアやサンプル前処理技術を使用せずに高品質の顕微鏡画像を取得できるようになりました。 
[概要]拡張顕微鏡法の深層学習モデルは、ほとんどがu-netベースのニューラルネットワークです。これは、パフォーマンスを制限する特定の欠点を共有することを意味します。gvtnetsは、グローバルボクセルトランスフォーマー演算子（gvtos）に基づいて構築されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic deep heterogeneous quantization of Deep Neural Networks for
  ultra low-area, low-latency inference on the edge at particle colliders -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.IV/paper_4.html">
      <font color="black">Automatic deep heterogeneous quantization of Deep Neural Networks for
  ultra low-area, low-latency inference on the edge at particle colliders</font>
    </a>
  </h2>
  <font color="black">FPGAハードウェアに実装すると、ナノ秒の推論とリソース消費量が50ドル削減されます。レイヤーごと、パラメーターごとのタイプの自動量子化手順により、さまざまな量子化器からのサンプリング、モデルのエネルギー消費量とサイズがモデルサイズを制限する手法は量子化です。つまり、
[ABSTRACT]は、最小エネルギー、高サンプリング、およびチップ上での完全自動展開のために、ディープニューラルネットワークモデルの最適に不均一に量子化されたバージョンを設計するための新しい方法です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Detection and Classification of Tick-borne Skin Lesions using
  Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.IV/paper_5.html">
      <font color="black">Automatic Detection and Classification of Tick-borne Skin Lesions using
  Deep Learning</font>
    </a>
  </h2>
  <font color="black">ダニ媒介性皮膚病変を検出するためにさまざまな畳み込みニューラルネットワークモデルを使用することによって..世界中で、ダニはさまざまな細菌性、ウイルス性、寄生虫性疾患を伝播する原因です..Googleから画像を取得することでデータ入力を拡大しましたこれがトレーニングデータを多様化し、皮膚病変検出の精度を向上させるかどうかをテストするための7つの異なる言語。 
[概要]ライム病の症例は過去10年間で劇的に増加しています。この病気の50症例は私たちだけで報告されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: High Fidelity Interactive Video Segmentation Using Tensor Decomposition
  Boundary Loss Convolutional Tessellations and Context Aware Skip Connections -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.IV/paper_6.html">
      <font color="black">High Fidelity Interactive Video Segmentation Using Tensor Decomposition
  Boundary Loss Convolutional Tessellations and Context Aware Skip Connections</font>
    </a>
  </h2>
  <font color="black">実験を通じて、高解像度ビデオデータを使用したインタラクティブセグメンテーションタスクのベースラインモデルに対するモデルの精度の向上を示します。ピクセルレベルのセグメンテーション結果を向上させるために、境界損失関数を導入します。ビデオデータの時間的コヒーレンスを改善するために、モデルに時間的画像情報を含めます。主に2つの方法で、モデル内でこの一貫した高品位の忠実度を効率的に維持します。（1）統計的に原理的なテンソル分解手順を使用してハイパーカラムフィーチャの数と（2）畳み込みテッセレーション手法を使用して、これらのフィーチャをネイティブ解像度でレンダリングします。 
[概要]ベンチマークビデオセグメンテーションデータセット、vfxセグメンテーションデータセットも紹介します。これには27,000を超える高解像度ビデオフレームが含まれます。vfxセグメンテーションデータセットには、グリーンスクリーンや対応するハンドクラフトを含むさまざまな合成シーンを含む27、046を超える高解像度モデルが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: StressNet: Detecting Stress in Thermal Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.IV/paper_7.html">
      <font color="black">StressNet: Detecting Stress in Thermal Videos</font>
    </a>
  </h2>
  <font color="black">ストレスまたはストレスなし）..再構築されたISTI信号は、個人のストレス状態を検出および分類するためにストレス検出モデルに送られます（つまり、詳細な評価は、StressNetが95％の精度で推定ISTI信号を達成し、平均でストレスを検出することを示しています精度0.842。
[要約]提案されたネットワーク-`ストレスネット &#39;-はハイブリッド放出表現モデルを特徴とします。これは、ネットワークが95％の精度でストレスを検出できることを示しています。ストレスネットはストレス状態の監視に使用されることが期待されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-18">
        <br><font color="black">2020-11-18</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-task Learning for Human Settlement Extent Regression and Local
  Climate Zone Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.IV/paper_8.html">
      <font color="black">Multi-task Learning for Human Settlement Extent Regression and Local
  Climate Zone Classification</font>
    </a>
  </h2>
  <font color="black">この手紙では、マルチタスク学習（MTL）の概念がHSE回帰とLCZ分類に初めて導入されました。さらに、精度を高めるために、LCZ分類の前にHSE予測を活用することを提案します。フレームワークが両方のタスクに競争力のあるソリューションを提供できること。 
[概要]都市マッピング用の気候サイズのシステムを提案します。これには、共有機能の学習と重み付け戦略のための都市ネットワークが含まれます。このシステムは、世界中の13都市のセンチネルデータで広範囲にテストされました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Multi-Scale Photo Exposure Correction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.IV/paper_9.html">
      <font color="black">Learning Multi-Scale Photo Exposure Correction</font>
    </a>
  </h2>
  <font color="black">したがって、エンドツーエンドの方法でトレーニング可能な、粗いものから細かいものへのディープニューラルネットワーク（DNN）モデルを提案します。これは、各サブ問題に個別に対処します。露出補正問題を2つの主要なサブ問題として定式化します。 （i）カラーエンハンスメントと（ii）ディテールエンハンスメント..私たちの方法は、露出不足の画像で既存の最先端の方法と同等の結果を達成し、露出過度のエラーに悩まされている画像に大幅な改善をもたらします。 
[概要]これまでの作業は、主に露出不足の画像または一般的な画像の強調に焦点を当てています。これらには、色の強調と詳細の強調が含まれます。ソリューションの重要な側面は、24,00を超える画像の新しいデータセットです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-25">
        <br><font color="black">2020-03-25</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Hidden Markov Models from Aggregate Observations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.IV/paper_10.html">
      <font color="black">Learning Hidden Markov Models from Aggregate Observations</font>
    </a>
  </h2>
  <font color="black">私たちのアルゴリズムの有効性は、さまざまなデータセットで実証されています。この論文では、集計観測から時間的に均一な隠れマルコフモデルのパラメータを推定するためのアルゴリズムを提案します。さらに、学習フレームワークは自然に標準のバウムになります。 -単一の個人に対応する観測値が記録される場合のウェルチ学習アルゴリズム。 
[概要]これは、各タイムステップでの個体数の母集団レベルのカウントのみが利用可能であり、そこから個々の隠れマルコフモデルを学習しようとする場合です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Attention-Network for Semantic Segmentation of Fine Resolution
  Remote Sensing Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.IV/paper_11.html">
      <font color="black">Multi-Attention-Network for Semantic Segmentation of Fine Resolution
  Remote Sensing Images</font>
    </a>
  </h2>
  <font color="black">まず、U-Netなどのエンコーダ-デコーダアーキテクチャの場合、マルチスケール機能を利用すると、情報が十分に活用されなくなり、低レベルの機能と高レベルの機能が、改良なしで直接連結されます。カーネルの新しい注意メカニズム注意の大きな計算要求を軽減するために、線形の複雑さを伴う注意が提案されます。第3に、ドット製品の注意メカニズムが導入され、長距離依存性をモデル化するためのセマンティックセグメンテーションに利用されていますが、注意の大きな時間と空間の要求が妨げられます。大規模な入力を伴うアプリケーションシナリオでの注意の実際の使用法。 
[概要]セマンティックセグメンテーションの精度は、深い畳み込みニューラルネットワークによって大幅に向上しました。ただし、標準モデルにはいくつかの制限があります。たとえば、これには、各セマンティッククラスに関連付けられた次善の特徴表現が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Adaptation based COVID-19 CT Lung Infections Segmentation Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.IV/paper_12.html">
      <font color="black">Domain Adaptation based COVID-19 CT Lung Infections Segmentation Network</font>
    </a>
  </h2>
  <font color="black">コンピュータ断層撮影（CT）からの肺感染症の自動セグメンテーションは診断のための効果的な方法になりました。コロナウイルス病（COVID-19肺炎）は急速に広がり、世界的な流行になり、公衆衛生と経済に大きな影響を与えました。 ..実験結果は、提案されたネットワークがベースラインおよび最先端の方法を大幅に上回っていることを示しています。 
[概要]肺感染症の自動セグメンテーションは診断にとって非常に重要になっています。感染症のリスクが高いためデータの収集が難しく、注釈を付けるのが面倒です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Uncertainty Modelling in Deep Neural Networks for Image Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.IV/paper_13.html">
      <font color="black">Uncertainty Modelling in Deep Neural Networks for Image Data</font>
    </a>
  </h2>
  <font color="black">最後に、分類のための人気のある画像データセットでの方法の効率を示します。ディープニューラルネットワークは、広範囲のタスクで印象的なパフォーマンスを最近達成した強力なブラックボックス予測子です。NNにツールを装備するための多くの努力がありましたがモンテカルロドロップアウトなどの不確実性の推定。これまでの方法のほとんどは、3種類のモデル、データ、または分布の不確実性のうちの1つにのみ焦点を当てています。 
[概要]システムにいくつかのツールを装備して、予測が不確かな場合に通知することができます。これは、自動運転車の制御、医療画像分析、財務見積もりなど、エラーのコストが高いアプリケーションにとって重要です。または法的分野</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-17">
        <br><font color="black">2020-11-17</font>
      </time>
    </span>
</section>
<!-- paper0: Transfer Learning for Oral Cancer Detection using Microscopic Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.IV/paper_14.html">
      <font color="black">Transfer Learning for Oral Cancer Detection using Microscopic Images</font>
    </a>
  </h2>
  <font color="black">アブレーション研究は、このタスクの微調整によるデータ拡張技術の追加の利点を示しています。ディープラーニング技術は、口腔がん細胞のパターンを検出し、その早期発見に役立ちます。単純な畳み込みニューラルネットワークのベースラインと比較した方法。 
[概要]ディープラーニング技術は、口腔がん細胞のパターンを検出できます。病気の早期発見に役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Impact of Spherical Coordinates Transformation Pre-processing in Deep
  Convolution Neural Networks for Brain Tumor Segmentation and Survival
  Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.IV/paper_15.html">
      <font color="black">Impact of Spherical Coordinates Transformation Pre-processing in Deep
  Convolution Neural Networks for Brain Tumor Segmentation and Survival
  Prediction</font>
    </a>
  </h2>
  <font color="black">この作業では、球面座標変換が前処理方法として適用され、通常のMRIボリュームと組み合わせて使用され、脳腫瘍セグメンテーション（BraTS）チャレンジ2020データセットでの脳腫瘍セグメンテーションと患者の全生存（OS）予測の精度が向上します。 ..前処理とデータ拡張はDeepConvolutional Neural Networks（DCNN）で重要な役割を果たします。その後、LesionEncoderフレームワークを適用して、DCNNモデルから特徴を自動的に抽出し、検証データセットでOS予測の精度0.586を達成しました。 BraTS2020リーダーボードによると最高の結果の1つです。 
[概要]新しい方法は、球形の空間変換データをdcnnに供給することを目的としています。その後、dcnnモデルから特徴を自動的に抽出するために適用されました。腫瘍データは、brats2020リーダーボードによると最良の結果の1つです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Complex-valued Iris Recognition Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_0.html">
      <font color="black">Complex-valued Iris Recognition Network</font>
    </a>
  </h2>
  <font color="black">この作業の結果は、複雑なガボールフィルターがテクスチャモデリングに使用される他のドメインにも適用できる可能性があります。3つのベンチマークデータセット（ND-CrossSensor-2013、CASIA-Iris-Thousand、UBIRIS.v2）で実施された実験は、虹彩認識のタスクに対する提案されたネットワークの利点..提案された複雑な値の虹彩認識ネットワークと、古典的なIrisCodeの生成に使用されるガボールウェーブレットとの強い対応を示します。ただし、提案された方法は、虹彩認識に合わせて調整された自動複素数値特徴学習を可能にします。 
[ABSTRACT]虹彩認識は、その確率的内容をより適切に表現するために、虹彩テクスチャからの位相と持続時間の両方の情報の抽出に依存します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Characterization of Industrial Smoke Plumes from Remote Sensing Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_1.html">
      <font color="black">Characterization of Industrial Smoke Plumes from Remote Sensing Data</font>
    </a>
  </h2>
  <font color="black">モデルのパフォーマンスは、表面オブジェクトとの時折の混乱、半透明の煙を識別できないこと、RGBのみの画像に基づいて煙を適切に識別する人間の制限によってほとんど制限されます。モデルは自然の雲を正しく無視し、それらの画像に焦点を合わせますエアロゾルと水蒸気からのスペクトル吸収に関連するチャネルにより、煙の位置特定が可能になります。この位置特定機能を活用し、データのラベル付きサブサンプルでU-Netセグメンテーションモデルをトレーニングして、交差点オーバーを実現します。 -ユニオン（IoU）メトリックは0.608で、煙のプルームを検出するための全体的な精度は94.0％です。私たちのモデルは、平均して、画像内の煙で覆われた領域を5.6％以内で再現できます。 
[概要]修正されたresnet-50を使用すると、さまざまなサイズの煙のプルームを94. 3％の精度で検出できます。モデルは画像内の煙で覆われた領域を5.6％以内で再現できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Pyramid Point: A Multi-Level Focusing Network for Revisiting Feature
  Layers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_2.html">
      <font color="black">Pyramid Point: A Multi-Level Focusing Network for Revisiting Feature
  Layers</font>
    </a>
  </h2>
  <font color="black">このFKP変換により、機能の品質が向上し、カーネル出力を動的に重み付けできます。順序付けされていないポイントセットからオブジェクトカテゴリの多様なグループを学習する方法を示します。これらのFKP変換は、RecurrentFKPボトルネックブロックの中心部分です。 、エンコーダのバックボーンを構成します。 
[概要]従来の「u」形状の代わりに、密なピラミッド構造を使用するピラミッドポイントネットワークを提案します。また、アブレーション研究を実行して、fkpconvの各要素の正の効果を示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-17">
        <br><font color="black">2020-11-17</font>
      </time>
    </span>
</section>
<!-- paper0: Building a Parallel Universe Image Synthesis from Land Cover Maps and
  Auxiliary Raster Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_3.html">
      <font color="black">Building a Parallel Universe Image Synthesis from Land Cover Maps and
  Auxiliary Raster Data</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、対応するデータセットでトレーニングすると、中解像度（10m）と高解像度（1m）の画像を正常に合成します。土地被覆マップと補助情報のデータ融合の利点を、結合に対する平均交差、ピクセル精度、および-トレーニング済みのU-Netセグメンテーションモデル..SPADEとは対照的に、これらの正規化レイヤーは、補助ラスターデータの情報コンテンツを最大限に活用するために、エンコーダーとデコーダーで構成される本格的なジェネレーターアーキテクチャに適用されます。 
[ABSTRACT]私たちの方法は、空間適応正規化レイヤーによる両方の入力を融合します。これは、スペードセマンティック画像合成として以前に公開されたさまざまなレイヤーの使用に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Registration for Self-Occluded Objects in Context -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_4.html">
      <font color="black">3D Registration for Self-Occluded Objects in Context</font>
    </a>
  </h2>
  <font color="black">私たちの実験は、最先端の従来の学習ベースの3D登録方法に対する私たちのアプローチの優位性を証明しています。さらに、時間効率とメモリ効率の両方を備えたオンザフライレンダリングベースのトレーニング戦略を開発します。 ..私たちの方法は、インスタンスセグメンテーションモジュールとそれに続くポーズ推定モジュールで構成されています。 
[概要]このシナリオの課題には、ほとんどの測定値がオブジェクトの周囲のコンテキストを表す外れ値であるという事実が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Lossless CNN Channel Pruning via Decoupling Remembering and Forgetting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_5.html">
      <font color="black">Lossless CNN Channel Pruning via Decoupling Remembering and Forgetting</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、ImageNetで76.15％の精度を持つ標準のResNet-50を、わずか45％のフロップで精度の低下がない狭いものにスリム化します。これは、このような高い圧縮率でロスレスプルーニングを実現した最初の方法です。 ..ロスレスチャネルプルーニングの新しい方法であるResRepを提案します（別名。このような方法は、ResRepを、パラメーターにペナルティを適用して構造化されたスパース性を生成する従来の学習ベースのプルーニングパラダイムと区別します。これにより、記憶に不可欠なパラメーターが抑制される場合があります。 
[ABSTRACT] `filter pruning &#39;は、畳み込みニューラルネットワーク（cnn）をスリム化することを目的としています。これにより、畳み込みレイヤーの幅（出力チャネルの数）が削減されます。メソッドは、標準のresnetをスリム化します-50、イメージネットで15％の精度フロップが45％で、精度の低下がない、より狭いもの</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Liquid Warping GAN with Attention: A Unified Framework for Human Image
  Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_6.html">
      <font color="black">Liquid Warping GAN with Attention: A Unified Framework for Human Image
  Synthesis</font>
    </a>
  </h2>
  <font color="black">さらに、提案された方法は、複数のソースからのより柔軟なワーピングをサポートできます。既存のタスク固有の方法は、主に2Dキーポイントを使用して人体構造を推定します。また、新しいデータセット、つまりiPERデータセットを構築して人間の動きの模倣、外観の転送、および新しいビューの合成。 
[ABSTRACT]モデルは、トレーニングが完了すると、これらすべてのタスクを処理するために使用できます。ただし、位置情報を表現するだけで、人のパーソナライズされた形状を特徴付けたり、手足の回転をモデル化したりすることはできません。目に見えないソース画像、1つまたはいくつか-ショットの敵対的学習が適用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-18">
        <br><font color="black">2020-11-18</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Agnostic Learning for Unbiased Authentication -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_7.html">
      <font color="black">Domain Agnostic Learning for Unbiased Authentication</font>
    </a>
  </h2>
  <font color="black">通常、ドメインアノテーションが提供され、すべてのドメインがクラスを共有していることを前提としています。次に、クラス依存スペースとクラス非依存スペースの両方でドメインの違いを排除して、排除の堅牢性を向上させます。ドメインの違いをモデル化して排除するのが困難になる可能性があります。 。 
[概要]本稿では、ドメインラベルなしでドメインの違いを排除するドメイン認識手法を提案します。これらのドメインに徹底的に注釈を付けることは不可能です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-11">
        <br><font color="black">2020-10-11</font>
      </time>
    </span>
</section>
<!-- paper0: Everybody Sign Now: Translating Spoken Language to Photo Realistic Sign
  Language Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_8.html">
      <font color="black">Everybody Sign Now: Translating Spoken Language to Photo Realistic Sign
  Language Video</font>
    </a>
  </h2>
  <font color="black">次に、ポーズ条件付き人間合成モデルを導入して、骨格ポーズシーケンスからフォトリアリスティックな手話ビデオを生成します。ろうコミュニティに真に理解され受け入れられるためには、自動手話制作（SLP）システムが写真を生成する必要があります。現実的な署名者..放送映像から抽出された8つの異なる手話通訳者のデータセットを使用して、SignGANが定量的測定基準および人間の知覚研究のすべてのベースライン方法を大幅に上回っていることを示します。 
[概要]混合密度ネットワークを備えたトランスアーキテクチャを採用して、話し言葉から骨格ポーズへの翻訳を処理します。サインビデオは、書かれたテキストから直接翻訳して作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-19">
        <br><font color="black">2020-11-19</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchically Decoupled Spatial-Temporal Contrast for Self-supervised
  Video Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_9.html">
      <font color="black">Hierarchically Decoupled Spatial-Temporal Contrast for Self-supervised
  Video Representation Learning</font>
    </a>
  </h2>
  <font color="black">コードと事前トレーニング済みの重みをリリースします。特に、この方法では、正則化として拡張を操作することにより、対照学習に基づいて空間的および時間的特徴を個別にキャプチャし、複合対照に向けて最適化することで、このようなプロキシタスクを階層的に解決するようにネットワークに指示します。損失..監視された学習におけるそれらの有効性に動機付けられて、我々は最初に、監視されていないビデオ学習の文脈に時空間特徴学習デカップリングと階層的学習を導入します。 
[概要]最初に、教師なしビデオ学習のコンテキストに空間的-時間的特徴学習デカップリングを導入します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: MEG: Multi-Evidence GNN for Multimodal Semantic Forensics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_10.html">
      <font color="black">MEG: Multi-Evidence GNN for Multimodal Semantic Forensics</font>
    </a>
  </h2>
  <font color="black">最近の研究では、問題を画像の転用と呼んでいます。デジタルで操作されていない画像は、キャプションや場所などの付随するマルチモーダルメタデータによって意味的に誤って表現されています。既存の方法は、単一の証拠の使用に限定されています（取得済み）パッケージ）、複数の証拠の使用による潜在的なパフォーマンスの向上を無視します。モデルのスケーラビリティとパフォーマンスを既存の方法と比較します。 
[概要]問題の設定には、マルチモーダルセマンティックフォレンジックを実行して、関連する可能性のあるテキストの参照データセットを証拠として使用して検索パッケージを取得するアルゴリズムが必要です。新しいモデルは、取得した複数のパッケージを証拠として使用し、証拠の数に応じて拡張可能です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: AVGZSLNet: Audio-Visual Generalized Zero-Shot Learning by Reconstructing
  Label Features from Multi-Modal Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_11.html">
      <font color="black">AVGZSLNet: Audio-Visual Generalized Zero-Shot Learning by Reconstructing
  Label Features from Multi-Modal Embeddings</font>
    </a>
  </h2>
  <font color="black">この論文では、マルチモーダル設定での一般化されたゼロショット学習のための新しいアプローチを提案します。テスト中は、トレーニング中には見られない新しいクラスのオーディオ/ビデオがあります。これは、オーディオとビデオの埋め込みを移動するのに役立ちます。クラスラベルのテキスト埋め込みに近づけます。これは、同じクラスの埋め込みを近づけ、マルチモーダル設定で異なるクラスの埋め込みを押しのけるのに役立ちます。 
[概要]ゼロショット学習の手段として、テキスト埋め込みの意味的関連性を使用します。オーディオとビデオの埋め込みを対応するクラスラベルのテキスト機能スペースに合わせます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-27">
        <br><font color="black">2020-05-27</font>
      </time>
    </span>
</section>
<!-- paper0: Industrial object, machine part and defect recognition towards fully
  automated industrial monitoring employing deep learning. The case of
  multilevel VGG19 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_12.html">
      <font color="black">Industrial object, machine part and defect recognition towards fully
  automated industrial monitoring employing deep learning. The case of
  multilevel VGG19</font>
    </a>
  </h2>
  <font color="black">Virtual Geometry Group（VGG）ネットワークの最近の成功に動機付けられて、マルチパスVGG19と呼ばれるその修正バージョンを提案します。これにより、ローカルおよびグローバルな特徴抽出が可能になり、追加の特徴は連結によって融合されます。調査では、パターン認識のための特殊なモデルの開発を目的として、欠陥材料と産業用ツールまたはエンジン部品を含む6つの公開されている産業関連データセットを採用しました。分類の改善は6.95％でした。 
[概要]全自動生産工程では、機械部品の監視が必須です。実験はニューヨーク大学の研究者が実施しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Attentional-GCNN: Adaptive Pedestrian Trajectory Prediction towards
  Generic Autonomous Vehicle Use Cases -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_13.html">
      <font color="black">Attentional-GCNN: Adaptive Pedestrian Trajectory Prediction towards
  Generic Autonomous Vehicle Use Cases</font>
    </a>
  </h2>
  <font color="black">これらは通常、車両の観点から実際の使用法を表すものではなく、搭載センサーが遮られている場合、不確実性の限界を過小評価する可能性があります。ただし、ほとんどの既存のアプローチでは、生成モデルの繰り返しサンプリングによってのみ不確実性を推定できます。多数のデータセットでの実験を通じて、提案された方法が、高速の推定速度で10％の平均変位誤差（ADE）と12％の最終変位誤差（FDE）によって最先端の改善を達成することを示します。 
[概要]最新の予測モデルは、空中写真を使用して群衆の完全な可観測性を想定するデータセットでトレーニングされています。これらは、実際の使用からのデータセットに基づいています。システムがどれほど効果的であるかを示す必要があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Ranking Neural Checkpoints -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_14.html">
      <font color="black">Ranking Neural Checkpoints</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、チェックポイントによって抽出された特徴の線形分離可能性が転送可能性の強力な指標であることを示唆しています。これらの測定値は一般的であり、チェックポイントがどのデータセットでどのように事前トレーニングされているかを知らなくても、さまざまな出力タイプのチェックポイントに適用されます。 
[概要] dnnsを使用して、さまざまなソースから多くのチェックポイントを収集できます。これらは、実験で最高のパフォーマンスを生み出す新しいランキング指標nlarapに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Learnable Boundary Guided Adversarial Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_15.html">
      <font color="black">Learnable Boundary Guided Adversarial Training</font>
    </a>
  </h2>
  <font color="black">以前の敵対的トレーニングは、自然データの精度を犠牲にしてモデルの堅牢性を高めます。}、敵対的ロジットペアリング（ALP）およびTRADES、パフォーマンスはさらに強化されます。}、一般化可能な分類子境界。 
[要約]この論文では、私たちの目標は自然な精度の破壊を減らすことです。「ロバスト」のモデルのモデルをガイドします。$ cal（m）**** log log log）と$＃よく認識された `モデル &#39;.weはbgatを学習可能な境界ガイド付き敵対数トレーニングに一般化します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Global Voxel Transformer Networks for Augmented Microscopy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_16.html">
      <font color="black">Global Voxel Transformer Networks for Augmented Microscopy</font>
    </a>
  </h2>
  <font color="black">提案された方法を、さまざまな設定で3つの異なる拡張顕微鏡タスクの既存のデータセットに適用します。この作業では、現在のU-の固有の制限を克服する拡張顕微鏡用の高度な深層学習ツールであるグローバルボクセルトランスフォーマーネットワーク（GVTNet）を紹介します。ネットベースのモデルであり、パフォーマンスの向上を実現します。GVTNetは、畳み込みのようなローカルオペレーターではなく、グローバル情報を集約できるグローバルボクセルトランスフォーマーオペレーター（GVTO）に基づいて構築されています。 
[概要]拡張顕微鏡法の深層学習モデルは、ほとんどがu-netベースのニューラルネットワークです。これは、パフォーマンスを制限する特定の欠点を共有することを意味します。gvtnetsは、グローバルボクセルトランスフォーマー演算子（gvtos）に基づいて構築されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Natural Graph Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_17.html">
      <font color="black">Natural Graph Networks</font>
    </a>
  </h2>
  <font color="black">同変メッセージネットワークのパラメーター化を使用するグラフ上の自然ネットワークの実用的なインスタンス化を1つ示し、いくつかのベンチマークで良好なパフォーマンスを実現します。ここでは、同変の代わりに、より一般的な自然の概念でグラフネットワークが十分であることを示します。 -定義され、より大きなクラスのグラフネットワークを開きます。グローバルおよびローカルの自然グラフネットワークを定義します。後者は、従来のメッセージパッシンググラフニューラルネットワークと同じくらいスケーラブルでありながら、より柔軟性があります。 
[概要]グラフネットワークはネットワーク順列と同変でなければなりません。ネットワーク上の同変はネットワーク上で同変であってはなりません。ここでは、グローバルおよびローカルの自然グラフネットワークを定義します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: MUST-GAN: Multi-level Statistics Transfer for Self-driven Person Image
  Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_18.html">
      <font color="black">MUST-GAN: Multi-level Statistics Transfer for Self-driven Person Image
  Generation</font>
    </a>
  </h2>
  <font color="black">DeepFashionデータセットの実験結果は、最先端の監視ありおよび監視なしの方法と比較した場合の方法の優位性を示しています。私たちのアプローチでは、人物の外観とポーズのプロパティを柔軟に操作して、ポーズの転送と服のスタイルの転送タスクを実行できます。それらをポーズガイドジェネレータに転送して、外観とポーズを再融合します。 
[ABSTRACT]モデルは、人物画像から外観の特徴を解きほぐして転送し、それらをポーズの特徴とマージして、ソースの人物画像自体を再構築します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-18">
        <br><font color="black">2020-11-18</font>
      </time>
    </span>
</section>
<!-- paper0: YOdar: Uncertainty-based Sensor Fusion for Vehicle Detection with Camera
  and Radar Sensors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_19.html">
      <font color="black">YOdar: Uncertainty-based Sensor Fusion for Vehicle Detection with Camera
  and Radar Sensors</font>
    </a>
  </h2>
  <font color="black">私たちの実験では、YOLOv3オブジェクト検出ネットワークをカスタマイズされた$ 1D $レーダーセグメンテーションネットワークと組み合わせ、nuScenesデータセットでメソッドを評価します。予測されたオブジェクトごとに、収集された情報は勾配ブーストメソッドによって後処理され、ジョイントが生成されます。両方のネットワークの予測..この作業では、カメラとレーダーのデータとセンサーを融合するための不確実性に基づく方法を提示します。 
[概要]カメラデータに基づく物体検出ネットワークの機能が潜在的に障害のある夜のシーンに焦点を当てます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-07">
        <br><font color="black">2020-10-07</font>
      </time>
    </span>
</section>
<!-- paper0: BiOpt: Bi-Level Optimization for Few-Shot Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_20.html">
      <font color="black">BiOpt: Bi-Level Optimization for Few-Shot Segmentation</font>
    </a>
  </h2>
  <font color="black">この論文では、帰納的設定の下でクエリ画像からクラスプロトタイプを計算することに成功するバイレベル最適化（BiOpt）を提案します。少数ショットセグメンテーションは、サポート画像が不足している新しいクラスのオブジェクトをセグメント化することを目的とした挑戦的なタスクです。 。各タスクで、内部ループはクエリ画像から最適化されたプロトタイプを学習することを目的としています。 
[要約]生体組織診断のシステムは、2つのネストされたループに分解されます：内側と外側のループ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: SCGAN: Saliency Map-guided Colorization with Generative Adversarial
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_21.html">
      <font color="black">SCGAN: Saliency Map-guided Colorization with Generative Adversarial
  Network</font>
    </a>
  </h2>
  <font color="black">さらに、新しい顕著性マップベースのガイダンス方法を提案します。さらに、視覚認識パフォーマンスを強化するために、生成された色付けマップと顕著性マップにそれぞれ2つの階層弁別器を使用します。色付けデコーダーのブランチを使用して予測します。プロキシターゲットとしての顕著性マップ。 
[概要]提案されたシステムは、最先端技術よりも多くのデータでトレーニングできます。完全に自動化された顕著性マップを作成するために使用できます。プロジェクトは、プロキシターゲットとしても使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Synthetic to Real Transfer for Localization and Navigational
  Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_22.html">
      <font color="black">Learning Synthetic to Real Transfer for Localization and Navigational
  Tasks</font>
    </a>
  </h2>
  <font color="black">iGibsonシミュレーターは、フォトリアリスティックなテクスチャと物理エンジンで選ばれています。ナビゲーションパイプラインを設計するには、4つの主要な課題が発生します。環境、ローカリゼーション、ナビゲーション、および計画..ローカルポリシーは、ROSナビゲーションスタックで収集されたエキスパートの軌跡からの動作のクローン作成でトレーニングされます。 
[概要]ナビゲーションは複数の分野の交差点にあり、コンピュータービジョン、ロボット工学、制御のアイデアを組み合わせています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-20">
        <br><font color="black">2020-11-20</font>
      </time>
    </span>
</section>
<!-- paper0: When and Why Test-Time Augmentation Works -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_23.html">
      <font color="black">When and Why Test-Time Augmentation Works</font>
    </a>
  </h2>
  <font color="black">さまざまなモデル、データセット、および拡張のセットにわたる実験は、私たちの方法が既存のアプローチに対して一貫した改善を提供することを示しています。私たちの分析は、トレーニングデータの性質と量、モデルアーキテクチャ、および拡張ポリシーがすべて重要であることを示唆しています。 TTAによって精度が大幅に向上した場合でも、多くの正しい予測が誤った予測に変わる可能性があることがわかりました。 
[ABSTRACT] test-time augmentationは、テストを集約する学習ベースの方法です-time augmentations.researchは、テスト時間の増強により、予測が不整合から不正確に、またはその逆に変化することを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Action Concept Grounding Network for Semantically-Consistent Video
  Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_24.html">
      <font color="black">Action Concept Grounding Network for Semantically-Consistent Video
  Generation</font>
    </a>
  </h2>
  <font color="black">追加の視覚化はhttps://iclr-acgn.github.io/ACGN/で見つけることができます。私たちの方法は、2つの新しく設計された合成データセット、CLEVR-Building-BlocksとSapien-Kitchenで評価され、実験は、与えられた異なるアクションを示していますラベルを使用すると、ACGNは命令を正しく条件付け、境界ボックスを必要とせずに対応する将来のフレームを生成できます。さらに、トレーニング済みモデルが同時アクションの分布外予測を行い、新しいオブジェクトカテゴリにすばやく適応し、学習したものを活用できることを示します。オブジェクト検出の機能。 
[要約]セマンティックアクションのタスク-条件付きビデオ予測。これは、アクション認識の逆問題と見なすことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning Analysis and Age Prediction from Shoeprints -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_25.html">
      <font color="black">Deep Learning Analysis and Age Prediction from Shoeprints</font>
    </a>
  </h2>
  <font color="black">結果は、被験者の40.23％が5歳以内に予測誤差を持ち、性別分類の予測精度が86.07％に達したことを示しています。興味深いことに、年齢に関連する特徴は、主に左右の足跡の非対称の違いにあります。 7〜80歳の被験者の100,000の足跡を収集し、そのデータを使用して、年齢に関連するパターンを分析し、年齢を予測するための深層学習エンドツーエンドモデルShoeNetを開発しました。 
[ABSTRACT] shoenetモデルは、スキップメカニズムを使用してさまざまな畳み込みニューラルネットワークモデルを統合し、年齢に関連する特徴を抽出します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-07">
        <br><font color="black">2020-11-07</font>
      </time>
    </span>
</section>
<!-- paper0: V3H: Incomplete Multi-view Clustering via View Variation and View
  Heredity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_26.html">
      <font color="black">V3H: Incomplete Multi-view Clustering via View Variation and View
  Heredity</font>
    </a>
  </h2>
  <font color="black">次に、クラスターインジケーターマトリックスに基づいてさまざまなビューを調整することにより、V3Hはさまざまなビューからの一意の情報を統合して、クラスタリングのパフォーマンスを向上させます。さらに重要なことに、V3Hは、一貫性のある情報を同時に学習するためのクラスタリングアルゴリズムに遺伝学を導入する最初の作業を提示します。不完全なマルチビューデータからの一意の情報。最後に、遺伝行列に基づく調整可能な低ランク表現の助けを借りて、V3Hは、基になる真のデータ構造を回復し、大きな不完全性の影響を減らします。 
[ABSTRACT]以前の方法では、異なるビュー間の一貫した情報のみを学習し、各ビューの一意の情報を無視します。v3h次に、各vvv 3chを、対応するビューのバリエーションマトリックスと遺伝マトリックスに分解します。次に、調整可能な低ランク表現、v3hは、基になる真のデータ構造を回復して、大きな不完全性の影響を軽減します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Cancer image classification based on DenseNet model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_27.html">
      <font color="black">Cancer image classification based on DenseNet model</font>
    </a>
  </h2>
  <font color="black">さらに、データ増強実験を実施し、トレーニングおよび検証プロセス中の処理されたバッチと損失値の関係を研究しました。本論文では、転移性癌を効果的に特定できる、DenseNetブロックに基づく新しい転移性癌画像分類モデルを提案します。より大きなデジタル病理学スキャンから取られた小さな画像パッチで..データセットは、Kaggleコンペティションによって提供されたPatchCamelyon（PCam）ベンチマークデータセットのわずかに変更されたバージョンであり、転移検出の臨床的に関連するタスクを単純なバイナリ画像分類にパックします仕事。 
[概要]画像は、病気の分類と検出を容易にするための有望な戦略を開発しましたが、コストを削減します。patchcamelyonデータセットはわずかに変更されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: StressNet: Detecting Stress in Thermal Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_28.html">
      <font color="black">StressNet: Detecting Stress in Thermal Videos</font>
    </a>
  </h2>
  <font color="black">再構築されたISTI信号は、個人のストレス状態を検出および分類するためにストレス検出モデルに送られます（つまり、ソースコードはGithubで入手できます。詳細な評価は、StressNetが95％の精度で推定ISTI信号を達成し、ストレスを検出することを示しています。 
[ABSTRACT]提案されたネットワーク-`stressnet&#39;-はハイブリッド放出表現モデルを特徴としています。これは、ネットワークが95％の精度でストレスを検出できることを示しています。stressnetはストレス状態の監視に使用されることが期待されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-18">
        <br><font color="black">2020-11-18</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Refinement Network for Human Motion Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_29.html">
      <font color="black">Adversarial Refinement Network for Human Motion Prediction</font>
    </a>
  </h2>
  <font color="black">人間の動きの予測は、限られた人間の動きを入力として与えることにより、将来の3D骨格シーケンスを予測することを目的としています。具体的には、カスケードされた改良ネットワークの入力として、過去の動きシーケンスと粗い予測の両方を使用して、洗練された人間の動きを予測し、敵対的エラーの増大..トレーニング中に、さまざまな被験者間の敵対的メカニズムを通じて学習することにより、意図的にエラー分布を導入します。 
[概要]リカレントニューラルネットワークとフィードフォワードディープネットワークの2つの一般的な方法では、スローモーションの傾向を予測できますが、手足の動きなどの動きの詳細が失われる可能性があります。3つの標準ベンチマークデータセットで広範な実験を行います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Lesion Harvester: Iteratively Mining Unlabeled Lesions and Hard-Negative
  Examples at Scale -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_30.html">
      <font color="black">Lesion Harvester: Iteratively Mining Unlabeled Lesions and Hard-Negative
  Examples at Scale</font>
    </a>
  </h2>
  <font color="black">機械学習アルゴリズムのトレーニングに必要な大規模な医用画像データの取得は、専門家主導の注釈コストが法外に高いため、しばしば手に負えません。これを行うために、高感度の病変提案ジェネレーターと非常に選択的な病変提案分類子をチェーンします。 。私たちのアプローチの利点を示すために、収集した病変でトレーニングされた病変検出器が、元のアノテーションでのみトレーニングされた同じバリアントを大幅に上回り、平均精度が7％から10％向上することを示します。 
[ABSTRACT]病院のアーカイブから抽出された深部データセットがこの問題に対処し始めました。これらのデータセットは、欠落している注釈を分析するためによく使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-21">
        <br><font color="black">2020-01-21</font>
      </time>
    </span>
</section>
<!-- paper0: A Learning-based Optimization Algorithm:Image Registration Optimizer
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_31.html">
      <font color="black">A Learning-based Optimization Algorithm:Image Registration Optimizer
  Network</font>
    </a>
  </h2>
  <font color="black">IRONは、同様のメトリック値で構成される3Dテンソル（9x9x9）によってトレーニングされます。次に、テンソルのラベルは、初期パラメーターからグローバルな最適パラメーターを指すベクトルです。特別なアーキテクチャにより、IRONは次のことができます。初期化のグローバル最適値を直接予測します。 
[概要]画像レジストレーションオプティマイザネットワーク（iron）という名前のアルゴリズムが提案されています。1回の反復後にグローバル最適値を予測できます。特別なアーキテクチャにより、ironは初期化に対して正確に正確なを示すことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning for Automatic Quality Grading of Mangoes: Methods and
  Insights -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_32.html">
      <font color="black">Deep Learning for Automatic Quality Grading of Mangoes: Methods and
  Insights</font>
    </a>
  </h2>
  <font color="black">これらの洞察は、複雑な深層学習のブラックボックスを簡潔で意味のある形で垣間見ることができ、信頼を育みます。また、実際のユースケースで人間に提示して、評価結果を確認することもできます。これを改善するために、このペーパーでは、さまざまな畳み込みニューラルネットワーク（CNN）、コンピュータービジョンで実証済みの深層学習テクノロジー。この作業では、ImageNetの事前トレーニング済みの重みを利用して転移学習も採用されています。 
[概要]これらのモデルには、畳み込みオートエンコーダー-分類器（convae-clfs）が含まれます。これらは、分類タスクにおけるマルチタスク学習の主張された利点に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Image Clustering with Tensor Kernels and Unsupervised Companion
  Objectives -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_33.html">
      <font color="black">Deep Image Clustering with Tensor Kernels and Unsupervised Companion
  Objectives</font>
    </a>
  </h2>
  <font color="black">提案されたDTKCモデルのパフォーマンスを徹底的に評価するために、いくつかの実験が行われます。ネットワーク全体で一貫したクラスター構造を奨励すると、入力空間でこれらのクラスターが非線形に見える場合でも、意味のあるクラスターに導く可能性があります。クラスター構造は、個別の損失関数がネットワーク内のレイヤーに接続されている、教師なしコンパニオン目標のアイデアを通じて実施されます。 
[概要]提案された深層プロジェクトは、畳み込みニューラルネットワーク（cnn）で構成され、畳み込みニューラルネットワークの提案されたプロセスを通じて共通のクラスター構造を反映するようにトレーニングされます。プロジェクトは畳み込み「畳み込み」に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-20">
        <br><font color="black">2020-01-20</font>
      </time>
    </span>
</section>
<!-- paper0: The Selectivity and Competition of the Mind's Eye in Visual Perception -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_34.html">
      <font color="black">The Selectivity and Competition of the Mind's Eye in Visual Perception</font>
    </a>
  </h2>
  <font color="black">これらの要素が脳内の高レベル領域の情報の流れと選択性を説明するのに役立つことを示します。私たちの仕事では、横方向とトップダウンのフィードバックを組み込んだ新しい計算モデルを作成することにより、知覚の神経メカニズムの理解を進めます。階層的競争の形態..しかし、一次視覚システムが情報を脳の正しいより高いレベルに向けるメカニズムは現在不明です。 
[概要]紡錘状回顔領域（ffa）領域は、顔以外のオブジェクトの上に顔が見えると、選択的にアクティブになることが知られています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Multi-Scale Photo Exposure Correction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_35.html">
      <font color="black">Learning Multi-Scale Photo Exposure Correction</font>
    </a>
  </h2>
  <font color="black">したがって、エンドツーエンドの方法でトレーニング可能な、粗いものから細かいものへのディープニューラルネットワーク（DNN）モデルを提案します。これは、各サブ問題に個別に対処します。露出補正問題を2つの主要なサブ問題として定式化します。 （i）カラーエンハンスメントと（ii）ディテールエンハンスメント..私たちの方法は、露出不足の画像で既存の最先端の方法と同等の結果を達成し、露出過度のエラーに悩まされている画像に大幅な改善をもたらします。 
[概要]これまでの作業は、主に露出不足の画像または一般的な画像の強調に焦点を当てています。これらには、色の強調と詳細の強調が含まれます。ソリューションの重要な側面は、24,00を超える画像の新しいデータセットです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-25">
        <br><font color="black">2020-03-25</font>
      </time>
    </span>
</section>
<!-- paper0: Group Whitening: Balancing Learning Efficiency and Representational
  Capacity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_36.html">
      <font color="black">Group Whitening: Balancing Learning Efficiency and Representational
  Capacity</font>
    </a>
  </h2>
  <font color="black">さらに、正規化によって機能に課せられた制約を分析し、モデルの表現能力の観点から、バッチサイズ（グループ番号）がバッチ（グループ）正規化ネットワークのパフォーマンスにどのように影響するかを示します。この分析は、適用するための理論的ガイダンスを提供します。実際のGW ..このペーパーでは、グループホワイトニング（GW）を提案します。これは、ホワイトニング操作の利点を活用し、ミニバッチ内の正規化の欠点を回避します。 
[概要]モデルの学習効率を改善するbnの利点は、ホワイトニングを使用することでさらに改善できます。19億ドルのgwをモデルに適用し、イメージネットとココのベンチマークで実験を行うことを提案しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: NeuralAnnot: Neural Annotator for in-the-wild Expressive 3D Human Pose
  and Mesh Training Sets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_37.html">
      <font color="black">NeuralAnnot: Neural Annotator for in-the-wild Expressive 3D Human Pose
  and Mesh Training Sets</font>
    </a>
  </h2>
  <font color="black">NeuralAnnotは、ターゲットの野生のデータセットからの2D監視と、GT 3Dポーズを使用した補助データセットからの3D監視によって、多数のサンプルでトレーニングされます。NeuralAnnotがはるかに優れた3D疑似GTを生成することを示します。最適化ベースの方法よりも実行時間がはるかに短く、新しく取得したトレーニングセットにより、パフォーマンスが大幅に向上します。ただし、フレームワークは2D監視のみを使用して各サンプルで最適化されるため、実行時間が長く、不良なものが生成されることがよくあります。仕方。 
[概要] 3D 3D人間ポーズとメッシュトレーニングセットで構築することを学習するニューラルアノテーターであるneuralannotを紹介します。新しく取得したトレーニングセットは、パフォーマンスを大幅に向上させます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Geometry-Inspired Top-k Adversarial Perturbations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_38.html">
      <font color="black">Geometry-Inspired Top-k Adversarial Perturbations</font>
    </a>
  </h2>
  <font color="black">他の敵対的な例の作成手法と比較することにより、その有効性と効率を評価します。さらに、この方法に基づいて、Top- $ k $ユニバーサル敵対的摂動、真のクラスがトップに存在しない原因となる画像にとらわれない小さな摂動を提案します。 -データセット内のほとんどの入力の$ k $予測。既存の敵対的摂動の主なターゲットは、主に、正しいTop-1予測クラスを誤ったクラスに変更することです。これは、Top- $ k $予測を変更することを意図していません。 
[要約]既存の敵対的摂動の主なターゲットは、主に正しいトップを変更することに限定されています-1つの予測クラスを誤ったクラスで変更します。これはトップを変更することを意図していません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-28">
        <br><font color="black">2020-06-28</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Transferable Adversarial Attack against Deep Face Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_39.html">
      <font color="black">Towards Transferable Adversarial Attack against Deep Face Recognition</font>
    </a>
  </h2>
  <font color="black">最後に、DFANetをLFWデータベースに適用することで、クエリなしで4つの商用APIを攻撃できる新しい敵対顔ペアのセットを生成します。次に、機能レベルの敵対的な例の転送可能性をさらに向上させるために、ドロップアウトであるDFANetを提案します。畳み込み層で使用されるベースの方法。代理モデルの多様性を高め、アンサンブルのような効果を得ることができます。さまざまなトレーニングデータベース、損失関数、ネットワークアーキテクチャを使用した最先端の顔モデルに関する広範な実験により、メソッドは、既存の攻撃メソッドの転送可能性を大幅に向上させることができます。 
[ABSTRACT]深い畳み込みニューラルネットワークは、敵対的例に対して脆弱であることがわかっています。この作業では、最初に転送可能な敵対的攻撃の特性を調査します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-13">
        <br><font color="black">2020-04-13</font>
      </time>
    </span>
</section>
<!-- paper0: Discriminative Neural Clustering for Speaker Diarisation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_40.html">
      <font color="black">Discriminative Neural Clustering for Speaker Diarisation</font>
    </a>
  </h2>
  <font color="black">本論文では、教師ありシーケンス学習問題として、最大数のクラスターを用いたデータクラスタリングを定式化する識別ニューラルクラスタリング（DNC）を提案する。AMIの実験結果は、DNCがスピーカーエラー率（SER）の低減を達成することを示している。 ）スペクトルクラスタリングに対して29.4％..したがって、この論文では、サブシーケンスランダム化、入力ベクトルランダム化、およびL2正規化スピーカー埋め込みの入力シーケンス全体を回転させることによって新しいデータサンプルを生成するDiaconis拡張の3つのデータ拡張スキームを提案します。 。 
[ABSTRACT] dncは、類似性測度の明示的な定義を必要とせずに、トレーニングデータからクラスタリングパターンを学習します。データの不足は、8月のトランスモデルをトレーニングするための重要な問題です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-22">
        <br><font color="black">2019-10-22</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Attention-Network for Semantic Segmentation of Fine Resolution
  Remote Sensing Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_41.html">
      <font color="black">Multi-Attention-Network for Semantic Segmentation of Fine Resolution
  Remote Sensing Images</font>
    </a>
  </h2>
  <font color="black">注意の大きな計算要求を軽減するために、線形の複雑さを伴うカーネル注意の新しい注意メカニズムが提案されます。第2に、特徴マップの長距離依存性が十分に調査されておらず、各セマンティッククラスに関連付けられた最適ではない特徴表現が生じます。ドットプロダクトアテンションメカニズムが導入され、セマンティックセグメンテーションで利用されて長距離の依存関係をモデル化したとしても、アテンションの時間とスペースの需要が大きいため、大規模な入力を伴うアプリケーションシナリオでのアテンションの実際の使用が妨げられます。 
[概要]セマンティックセグメンテーションの精度は、深い畳み込みニューラルネットワークによって大幅に向上しました。ただし、標準モデルにはいくつかの制限があります。たとえば、これには、各セマンティッククラスに関連付けられた次善の特徴表現が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Imbalance Robust Softmax for Deep Embeeding Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_42.html">
      <font color="black">Imbalance Robust Softmax for Deep Embeeding Learning</font>
    </a>
  </h2>
  <font color="black">この作業では、IR-Softmaxのフレームワークの下で2つの識別ソフトマックス（A-SoftmaxとAM-Softmax）を明示的に再定式化します。近年、1つの研究の焦点は、識別深い埋め込み学習によって開集合問題を解決することです。顔認識（FR）と個人の再識別（re-ID）の分野で。FRデータベース（LFW、MegaFace）とre-IDデータベース（Market-1501、Duke）、およびIR-Softmaxで広範な実験を行っています。多くの最先端の方法よりも優れています。 
[概要]顔認識（fr）と人物の再識別（re --id）の分野での深層埋め込み学習。ただし、データの不均衡が最小のパフォーマンスに影響を与える理由と方法を調査した研究はほとんどありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: CoKe: Localized Contrastive Learning for Robust Keypoint Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_43.html">
      <font color="black">CoKe: Localized Contrastive Learning for Robust Keypoint Detection</font>
    </a>
  </h2>
  <font color="black">キーポイント検出への今日の最も一般的なアプローチは、すべてのキーポイントの全体的な表現を学習することを目的とした非常に複雑なネットワークアーキテクチャを含みます。表現学習の観点から問題を調べることによってこれが可能であることを示します。私たちの実験は、CoKeが状態を達成することを示しています-すべてのキーポイントを総合的に表すアプローチ（Stacked Hourglass Networks、MSS-Net）や、詳細な3Dオブジェクトジオメトリ（StarMap）によって監視されるアプローチと比較した、最先端の結果。 
[ABSTRACT]キーポイント表現は、標準のバックボーンアーキテクチャの問題です。これらには、特徴抽出器のトレーニング中にキーポイント表現を計算するためのクラッターバンクと運動量の更新が含まれます。コークスは堅牢で、オブジェクトが部分的に遮られ、関連するパフォーマンスを大幅に上回っている場合に非常によく機能します。さまざまなデータセットに取り組む</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-29">
        <br><font color="black">2020-09-29</font>
      </time>
    </span>
</section>
<!-- paper0: MonoClothCap: Towards Temporally Coherent Clothing Capture from
  Monocular RGB Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_44.html">
      <font color="black">MonoClothCap: Towards Temporally Coherent Clothing Capture from
  Monocular RGB Video</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、単眼ビデオから身体と衣服の時間的にコヒーレントな再構成を生成します。変形追跡のドリフトを最小限に抑えるために、衣服の可視テクスチャ領域を順次拡張するUVテクスチャ成長方法を開発します。広範な定量的実験により、衣服の体のポーズエラーや表面再構成エラーなどの測定基準に関する方法。 
[概要]この方法では、事前にスキャンされたパーソナライズされたメッシュテンプレートは必要ありません。さまざまな課題から、衣服のキャプチャが成功することを実証しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Structure-Aware Completion of Photogrammetric Meshes in Urban Road
  Environment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_45.html">
      <font color="black">Structure-Aware Completion of Photogrammetric Meshes in Urban Road
  Environment</font>
    </a>
  </h2>
  <font color="black">空中斜め画像から得られた写真測量メッシュモデルは、都市の再構築に広く使用されています。車両領域は、標準的なオブジェクト検出アプローチによってマスクされます。実験的評価と分析は、異なるセンサーと地上サンプル距離でキャプチャされた3つのデータセットに対して実行されます。 
[ABSTRACT]写真測量メッシュにも深刻なテクスチャの問題があります。提案された方法は、車両を取り外した後、非常にリアルなメッシュを作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Application of Facial Recognition using Convolutional Neural Networks
  for Entry Access Control -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_46.html">
      <font color="black">Application of Facial Recognition using Convolutional Neural Networks
  for Entry Access Control</font>
    </a>
  </h2>
  <font color="black">事前トレーニング済みのモデルは、WoodNetよりも大幅に高速に適合し、一般化が進んでいるようです。ただし、これらの結果にはいくつかの注意点があります。ビデオからの画像抽出と画像拡張技術は、データセットの作成に役立ちました。 
[概要]著者を認識するためのモデルのトレーニングを支援するために、1億5000万を超える画像を含むデータセットが作成されました。結果は、データセット内の個人を高精度で分類する2つのモデルです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: ROME: Robustifying Memory-Efficient NAS via Topology Disentanglement and
  Gradients Accumulation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_47.html">
      <font color="black">ROME: Robustifying Memory-Efficient NAS via Topology Disentanglement and
  Gradients Accumulation</font>
    </a>
  </h2>
  <font color="black">具体的には、1）検索および評価段階でトポロジを一貫させるために、トポロジをアーキテクチャの操作から解きほぐすための個別のパラメータを使用します。このホワイトペーパーでは、パフォーマンスの崩壊の問題を掘り下げ、RObustifyingMemoryと呼ばれる新しいアルゴリズムを提案します。効率的なNAS（ROME）..このようにして、干渉なしに接続と操作を個別にサンプリングできます。 2）サンプリングの不公平と分散を割り引くために、重みの更新に公平なサンプリングを実施し、アーキテクチャパラメータに勾配累積メカニズムを適用します。 
[概要]検索と評価の段階では、アーキテクチャの操作からサティスを解きほぐすためのさまざまなパラメータが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Legacy Photo Editing with Learned Noise Prior -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_48.html">
      <font color="black">Legacy Photo Editing with Learned Noise Prior</font>
    </a>
  </h2>
  <font color="black">ウェブページ\ href {https://github.com/zhaoyuzhi/Legacy-Photo-Editing-with-Learned-Noise-Prior}{https://github.com/zhaoyuzhi/Legacy-Photo-Editing-with-をご覧ください。コードと提案されたLPデータセットのLearned-Noise-Prior}。また、事前にノイズを学習するための大規模なレガシー写真データセットを作成します。事前に学習したノイズを使用して、クリーンな画像を劣化させることにより、有効なトレーニングペアを簡単に構築できます。 
[概要]ペアになっていない画像を使用してrealzhi写真のノイズ分布をシミュレートするノイズ事前学習者ネガンがあります。結果は、それが最高の知覚品質を達成することを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Transfer of Pose Estimation Regression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_49.html">
      <font color="black">Adversarial Transfer of Pose Estimation Regression</font>
    </a>
  </h2>
  <font color="black">シーン不変の画像表現を学習するための深い適応ネットワークを開発し、敵対的学習を使用してモデル転送用のそのような表現を生成します。自己教師あり学習でネットワークを充実させ、適応性理論を使用してシーン不変の表現の存在を検証します。与えられた2つのシーンの画像..視覚的位置特定におけるカメラポーズ推定の問題に対処します。 
[概要]データセットシフトが一般化への重要な障壁であることを特定します。シーンを学習するための深い適応ネットワークを開発し、敵対的学習を使用してモデル転送用のそのような表現を生成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-20">
        <br><font color="black">2020-06-20</font>
      </time>
    </span>
</section>
<!-- paper0: GreedyFool: Multi-Factor Imperceptibility and Its Application to
  Designing Black-box Adversarial Example Attack -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_50.html">
      <font color="black">GreedyFool: Multi-Factor Imperceptibility and Its Application to
  Designing Black-box Adversarial Example Attack</font>
    </a>
  </h2>
  <font color="black">十分な知覚不能性を実現するために、HVSについて多くの調査を開始し、丁度可知歪み（JND）、ウェーバー-フェクナーの法則、テクスチャマスキング、チャネル変調を考慮した統合メトリックを設計します。これは、良性の例と敵対的な例の間の知覚距離..この論文では、GreedyFoolという名前の新しいブラックボックスの敵対的な例の攻撃を提案します。これは、微分進化と貪欲な近似に基づいて敵対的な例を合成します。ディープニューラルネットワーク（DNN）敵対的な例と呼ばれる適切に設計された入力サンプルに対して本質的に脆弱です。 
[ABSTRACT]新作は、人間の視覚系を十分に考慮していない摂動にペナルティを課すために単純なメトリックを活用することにより、敵対的な例を統合します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: An off-the-grid approach to multi-compartment magnetic resonance
  fingerprinting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_51.html">
      <font color="black">An off-the-grid approach to multi-compartment magnetic resonance
  fingerprinting</font>
    </a>
  </h2>
  <font color="black">これらの問題を克服するために、連続（非離散）ブロッホ応答モデルを使用したスパース近似のためのスパースグループラッソ正則化の拡張概念を備えたオフグリッドアプローチを提案します。さらに、非線形および非分析ブロッホ応答はニューラルネットワークによって近似され、提案されたアルゴリズムを通じて勾配の効率的なバックプロパゲーションを可能にします。シミュレートされた生体内の健康な脳MRFデータでテストされ、ベースラインマルチコンパートメントMRF法と比較して提案されたスキームの有効性を示します。 
[ABSTRACT]提案されたシステムは、これらの問題を克服するのに役立つ可能性があります。これらには、ボクセル内のワイヤレス混合応答が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: CoMatch: Semi-supervised Learning with Contrastive Graph Regularization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_52.html">
      <font color="black">CoMatch: Semi-supervised Learning with Contrastive Graph Regularization</font>
    </a>
  </h2>
  <font color="black">CoMatchは、複数のデータセットで最先端のパフォーマンスを実現します。自己監視型の事前トレーニングにより、精度はさらに67.1％に向上します。ラベルが1％のImageNetでは、CoMatchはトップ1の精度66.0％を達成し、パフォーマンスを上回ります。 12.6％のFixMatch。 
[概要]新しい半教師あり学習方法であるcomatchを提案します。これは、支配的なアプローチを統合し、それらの制限に対処します。2つの表現は、制約のために相互作用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: GAN-Leaks: A Taxonomy of Membership Inference Attacks against Generative
  Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_53.html">
      <font color="black">GAN-Leaks: A Taxonomy of Membership Inference Attacks against Generative
  Models</font>
    </a>
  </h2>
  <font color="black">ディープラーニングは、識別モデルから生成モデルに至るまで、圧倒的な成功を収めています。モデルタイプとトレーニング構成、3つの異なるアプリケーションシナリオ（画像、医療データ、位置データ）で。具体的には、メンバーシップの最初の分類法を示します。既存の攻撃だけでなく、新しい攻撃も含む推論攻撃。 
[ABSTRACT]ディープジェニュティブモデルは、新しいレベルのパフォーマンスを獲得することができました。幅広い設定でインスタンス化できる最初の汎用攻撃モデルを提案します。包括的な実験的研究により、攻撃パフォーマンスの体系的な分析を補完します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-09">
        <br><font color="black">2019-09-09</font>
      </time>
    </span>
</section>
<!-- paper0: Uncertainty Modelling in Deep Neural Networks for Image Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_54.html">
      <font color="black">Uncertainty Modelling in Deep Neural Networks for Image Data</font>
    </a>
  </h2>
  <font color="black">最後に、分類のための一般的な画像データセットでの方法の効率を示します。DNNの予測の不確実性の定量化は、困難でありながら進行中の問題です。ディープニューラルネットワークは、最近、幅広いスペクトルで印象的なパフォーマンスを達成した強力なブラックボックス予測子です。タスクの。 
[概要]システムにいくつかのツールを装備して、予測が不確かな場合に通知することができます。これは、自動運転車の制御、医療画像分析、財務見積もりなど、エラーのコストが高いアプリケーションにとって重要です。または法的分野</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-17">
        <br><font color="black">2020-11-17</font>
      </time>
    </span>
</section>
<!-- paper0: Graph Attention Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_55.html">
      <font color="black">Graph Attention Tracking</font>
    </a>
  </h2>
  <font color="black">シャムネットワークベースのトラッカーは、類似性マッチング問題として視覚追跡タスクを定式化します。完全2部グラフを使用して、ターゲットと検索領域の間のパーツ間の対応を確立し、グラフ注意メカニズムを適用して、テンプレート機能から検索機能へ..この論文では、上記の問題を解決するために、一般的なオブジェクト追跡のための単純なターゲット認識シャムグラフ注意ネットワークを提案します。 
[概要]提案されたsiamgatは、類似性を追跡するターゲットベースのネットワークです。ターゲットブランチと検索ブランチ間の相互相関を使用します。ターゲットと検索領域のグローバルマッチングも、ターゲット構造とパーツレベルの情報をほとんど無視します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: GENESIS: Generative Scene Inference and Sampling with Object-Centric
  Latent Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_56.html">
      <font color="black">GENESIS: Generative Scene Inference and Sampling with Object-Centric
  Latent Representations</font>
    </a>
  </h2>
  <font color="black">GENESISは、償却された方法で順次推論されるか、自己回帰の事前変数からサンプリングされたオブジェクト中心の潜在変数のセットからデコードされた画像上の空間GMMをパラメーター化します。ここでは、3Dの最初のオブジェクト中心の生成モデルであるGENESISを紹介します。シーンコンポーネント間の関係をキャプチャすることにより、シーンの分解と生成の両方が可能なビジュアルシーン。ただし、それらの基礎となる生成プロセスは、コンポーネントの相互作用を考慮していません。 
[概要]これは最初のツールです。3Dビジュアルシーンの空間アクションモデルです。genesisは、シーンコンポーネント間の関係をキャプチャすることにより、シーンの分解と生成の両方を行うことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-30">
        <br><font color="black">2019-07-30</font>
      </time>
    </span>
</section>
<!-- paper0: Impact of Spherical Coordinates Transformation Pre-processing in Deep
  Convolution Neural Networks for Brain Tumor Segmentation and Survival
  Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_57.html">
      <font color="black">Impact of Spherical Coordinates Transformation Pre-processing in Deep
  Convolution Neural Networks for Brain Tumor Segmentation and Survival
  Prediction</font>
    </a>
  </h2>
  <font color="black">この作業では、球面座標変換が前処理方法として適用され、通常のMRIボリュームと組み合わせて使用され、脳腫瘍セグメンテーション（BraTS）チャレンジ2020データセットでの脳腫瘍セグメンテーションと患者の全生存（OS）予測の精度が向上します。 ..前処理とデータ拡張はDeepConvolutional Neural Networks（DCNN）で重要な役割を果たします。その後、LesionEncoderフレームワークを適用して、DCNNモデルから特徴を自動的に抽出し、検証データセットでOS予測の精度0.586を達成しました。 BraTS2020リーダーボードによると最高の結果の1つです。 
[概要]新しい方法は、球形の空間変換データをdcnnに供給することを目的としています。その後、dcnnモデルから特徴を自動的に抽出するために適用されました。腫瘍データは、brats2020リーダーボードによると最良の結果の1つです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Uncovering the Bias in Facial Expressions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_58.html">
      <font color="black">Uncovering the Bias in Facial Expressions</font>
    </a>
  </h2>
  <font color="black">アクションユニット分類用のニューラルネットワークをトレーニングし、その精度に基づいて定量的に、ヒートマップに基づいて定性的にパフォーマンスを分析します。この特定のタスクを考慮して、私たちの研究は、特に性別と肌の色に関連するバイアスに関する透明性を提供することを目的としています。このようなタスクの例は、顔の画像内のアクションユニットと呼ばれる個別の顔の表情の検出です。 
[概要]人工ニューラルネットワークの深いアーキテクチャと豊富な利用可能なデータにより、かなり複雑な関係を記述することができます。ただし、性別と肌の色のバイアスのみから生じる分類パフォーマンスの低下について結論付けることができます。そのため、次のように説明します。検出されたバイアスを回避する方法に関する提案</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: A comparative study of semi- and self-supervised semantic segmentation
  of biomedical microscopy data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_59.html">
      <font color="black">A comparative study of semi- and self-supervised semantic segmentation
  of biomedical microscopy data</font>
    </a>
  </h2>
  <font color="black">これらのラベル付きデータセットは、生物医学分野で取得するのが難しいことがよくあります。2つの半教師ありおよび自己監視画像分類方法を採用し、生物医学顕微鏡画像のセマンティックセグメンテーションのパフォーマンスを分析します。ただし、これらのネットワークは通常、教師ありでトレーニングされます。大量のラベル付きトレーニングデータが必要です。 
[ABSTRACT]ネットワークは通常、監視ありの方法でトレーニングされ、データが必要です。これらのネットワークは通常、データを取得するために分析されるようにトレーニングされています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Puzzle-AE: Novelty Detection in Images through Solving Puzzles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CV/paper_60.html">
      <font color="black">Puzzle-AE: Novelty Detection in Images through Solving Puzzles</font>
    </a>
  </h2>
  <font color="black">ただし、ショートカットソリューションは、ジグソーパズルを含むSSLタスクの大きな課題です。オートエンコーダは、多くの異常検出方法の重要な部分として、複雑なデータセットの通常のデータに対する柔軟性に欠けています。効果的な自動として敵対的な堅牢なトレーニングを提案します。ショートカットの削除。 
[ABSTRACT] u-codeはこの目的に効果的であることが証明されていますが、他のaeベースのフレームワークと同様の再構成エラーを使用してトレーニングした場合、トレーニングデータに適合しません。提案されたフレームワークは安定していて、高速で、データ効率が高く、原則のない早期停止は必要ありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-29">
        <br><font color="black">2020-08-29</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Everybody Sign Now: Translating Spoken Language to Photo Realistic Sign
  Language Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CL/paper_0.html">
      <font color="black">Everybody Sign Now: Translating Spoken Language to Photo Realistic Sign
  Language Video</font>
    </a>
  </h2>
  <font color="black">次に、ポーズ条件付き人間合成モデルを導入して、骨格ポーズシーケンスから写実的な手話ビデオを生成します。さらに、合成された手の画像の品質を大幅に向上させる、新しいキーポイントベースの損失関数を提案します。モーションブラーによって引き起こされる問題を回避するためのキーポイントスペース。聴覚障害者のコミュニティが真に理解して受け入れられるためには、自動手話制作（SLP）システムが写実的な署名者を生成する必要があります。 
[概要]混合密度ネットワークを備えたトランスアーキテクチャを採用して、話し言葉から骨格ポーズへの翻訳を処理します。サインビデオは、書かれたテキストから直接翻訳して作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-19">
        <br><font color="black">2020-11-19</font>
      </time>
    </span>
</section>
<!-- paper0: Graph-based Modeling of Online Communities for Fake News Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CL/paper_1.html">
      <font color="black">Graph-based Modeling of Online Communities for Fake News Detection</font>
    </a>
  </h2>
  <font color="black">提案されたフレームワークは、1）配布されるコンテンツの性質、2）ユーザーのコンテンツ共有動作、および3）それらのユーザーのソーシャルネットワークに関する情報を集約します。私たちは、フレームワークが既存のテキストよりも大幅に改善されることを経験的に示しています。ベースの技術と2つの異なるドメインからのフェイクニュースデータセットで最先端の結果を達成します。この作業では、グラフニューラルネットワーク（GNN）に基づいて、新しいソーシャルコンテキスト対応のフェイクニュース検出フレームワークSAFERを提案します。 。 
[ABSTRACT]既存の調査では、オンライン投稿の配布における構造、スタイル、コンテンツ、およびパターンをモデル化しています。この調査では、グラフニューラルネットワーク（gnns）に基づいて、より安全な、新しいソーシャルコンテキストを認識したフェイクニュース検出フレームワークを提案しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-14">
        <br><font color="black">2020-08-14</font>
      </time>
    </span>
</section>
<!-- paper0: EasyTransfer -- A Simple and Scalable Deep Transfer Learning Platform
  for NLP Applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CL/paper_2.html">
      <font color="black">EasyTransfer -- A Simple and Scalable Deep Transfer Learning Platform
  for NLP Applications</font>
    </a>
  </h2>
  <font color="black">また、AppZooの主流NLPアプリケーション用のさまざまなSOTAモデルを統合し、主流TLアルゴリズムもサポートします。EasyTransferは、事前トレーニング済み言語モデル（PLM）やマルチモダリティモデルなど、主流の事前トレーニング済みModelZooをサポートします。実世界のデータセットは、EasyTransferが最先端のパフォーマンスを備えたオンライン制作に適していることを示しています。 
[概要] easytransferプラットフォームは、nlpアプリケーション用のディープtlアルゴリズムの開発を容易にするように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-18">
        <br><font color="black">2020-11-18</font>
      </time>
    </span>
</section>
<!-- paper0: KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language
  Representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CL/paper_3.html">
      <font color="black">KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language
  Representation</font>
    </a>
  </h2>
  <font color="black">この論文では、知識の埋め込みと事前トレーニングされた言語表現（KEPLER）の統合モデルを提案します。これは、事実に基づく知識をPLMに統合するだけでなく、強力なPLMを使用して効果的なテキスト拡張KEを生成できます。 https://github.com/THU-KEG/KEPLERから入手できます。実験結果は、KEPLERがさまざまなNLPタスクで最先端のパフォーマンスを達成し、KGリンクの誘導KEモデルとしても非常にうまく機能することを示しています。予測。 
[ABSTRACT]知識の埋め込み（ke）は、有益なエンティティの埋め込みで機能します。ただし、従来のkeモデルでは、豊富な文学情報を十分に活用できません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br><font color="black">2019-11-13</font>
      </time>
    </span>
</section>
<!-- paper0: Evaluating Input Representation for Language Identification in
  Hindi-English Code Mixed Text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CL/paper_4.html">
      <font color="black">Evaluating Input Representation for Language Identification in
  Hindi-English Code Mixed Text</font>
    </a>
  </h2>
  <font color="black">監視された設定では、文の各単語に関連付けられた言語ラベルがあります。言語識別のタスクはトークン分類タスクとして定式化されます。LSTMモデルとともにサブ単語表現が最良の結果をもたらすことを示します。 
[概要]コード-混合テキストは複数の言語で書かれたテキストで構成されます。人々はそのようなテキストを処理する傾向があり、現在の自然言語処理技術では不十分です。監視された設定では、文の各単語に関連する言語ラベルがあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: SPEECH-COCO: 600k Visually Grounded Spoken Captions Aligned to MSCOCO
  Data Set -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CL/paper_5.html">
      <font color="black">SPEECH-COCO: 600k Visually Grounded Spoken Captions Aligned to MSCOCO
  Data Set</font>
    </a>
  </h2>
  <font color="black">このようなコーパスは、テキストの代わりに音声入力または音声出力を含む言語と視覚（LaVi）タスクに使用できます。データセットはZenodoで入手できます：https：//zenodo.org/record/4282267。この論文は、音声が画像とテキストに追加されるMSCOCOデータセットの拡張を提示します。 
[要約]音声キャプションは、テキスト読み上げ（tts）合成を使用して生成されます。これにより、616、767の音声キャプション（600時間以上）が生成されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2017-07-26">
        <br><font color="black">2017-07-26</font>
      </time>
    </span>
</section>
<!-- paper0: Discriminative Neural Clustering for Speaker Diarisation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CL/paper_6.html">
      <font color="black">Discriminative Neural Clustering for Speaker Diarisation</font>
    </a>
  </h2>
  <font color="black">AMIの実験結果は、DNCがスペクトルクラスタリングと比較して29.4％のスピーカーエラー率（SER）の削減を達成することを示しています。Transformerアーキテクチャに基づくDNCの実装は、挑戦的なAMIデータセットを使用したスピーカーダイアリゼーションタスクで効果的であることが示されています。 ..したがって、この論文では、サブシーケンスランダム化、入力ベクトルランダム化、およびL2正規化スピーカー埋め込みの入力シーケンス全体を回転させることによって新しいデータサンプルを生成するDiaconis拡張の3つのデータ拡張スキームを提案します。 
[ABSTRACT] dncは、類似性測度の明示的な定義を必要とせずに、トレーニングデータからクラスタリングパターンを学習します。データの不足は、8月のトランスモデルをトレーニングするための重要な問題です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-22">
        <br><font color="black">2019-10-22</font>
      </time>
    </span>
</section>
<!-- paper0: Sequential Targeting: an incremental learning approach for data
  imbalance in text classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/cs.CL/paper_7.html">
      <font color="black">Sequential Targeting: an incremental learning approach for data
  imbalance in text classification</font>
    </a>
  </h2>
  <font color="black">テキストデータの不均衡に対処する一方で、ほとんどの方法は、データの数値表現でサンプリング方法を利用します。これにより、表現の効果の効率が制限されます。これは通常、支配的であるために多数派グループへのバイアスを促進する学習者につながります。プロパティ..したがって、不均衡なデータセットを処理する方法は、分布の偏りを軽減し、特にテキスト分類において、過小評価されているデータを十分に活用するために重要です。 
[ABSTRACT]不均衡なデータセットを処理する方法は、分布の偏りを軽減し、表現されていないデータを十分に活用するために重要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-20">
        <br><font color="black">2020-11-20</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: AVGZSLNet: Audio-Visual Generalized Zero-Shot Learning by Reconstructing
  Label Features from Multi-Modal Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.AS/paper_0.html">
      <font color="black">AVGZSLNet: Audio-Visual Generalized Zero-Shot Learning by Reconstructing
  Label Features from Multi-Modal Embeddings</font>
    </a>
  </h2>
  <font color="black">この論文では、マルチモーダル設定での一般化されたゼロショット学習のための新しいアプローチを提案します。ここでは、トレーニング中には見られない、テスト中のオーディオ/ビデオの新しいクラスがあります。クラスラベルのテキスト埋め込みに近い..私たちのアプローチは、クロスモーダルデコーダーと複合トリプレット損失を使用します。 
[概要]ゼロショット学習の手段として、テキスト埋め込みの意味的関連性を使用します。オーディオとビデオの埋め込みを対応するクラスラベルのテキスト機能スペースに合わせます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-27">
        <br><font color="black">2020-05-27</font>
      </time>
    </span>
</section>
<!-- paper0: Acoustic echo cancellation with the dual-signal transformation LSTM
  network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.AS/paper_1.html">
      <font color="black">Acoustic echo cancellation with the dual-signal transformation LSTM
  network</font>
    </a>
  </h2>
  <font color="black">トレーニングのセットアップには、多言語音声、データ拡張、追加のノイズ、および残響が含まれ、さまざまな実世界の条件に十分に一般化するモデルを作成します。この方法は、平均オピニオンに関してAECチャレンジベースラインを0.30上回っています。スコア（MOS）..モデルは、60〜hの実際のエコーシナリオと合成エコーシナリオでのみトレーニングされます。 
[概要] 46lnは短いものを組み合わせます-ネットワークは学習された特徴表現を組み合わせます。この方法はaec-チャレンジベースラインを0.30上回ります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Using Synthetic Audio to Improve The Recognition of Out-Of-Vocabulary
  Words in End-To-End ASR Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.AS/paper_2.html">
      <font color="black">Using Synthetic Audio to Improve The Recognition of Out-Of-Vocabulary
  Words in End-To-End ASR Systems</font>
    </a>
  </h2>
  <font color="black">これにより、テストセット全体で劣化することなく、OOV単語を含む発話の相対単語誤り率（WER）が57％削減されます。さまざまな正則化手法が検討され、両方の元のトレーニングでRNN-Tを微調整することで最高のパフォーマンスが達成されます。エンコーダーに適用された弾性重み統合（EWC）を使用したデータおよび追加の合成データ..これらの追加のオーディオテキストペアを使用することにより、OOVワードでのリカレントニューラルネットワークトランスデューサー（RNN-T）の認識精度を向上させ、非OOVワードでのパフォーマンス。 
[概要]これらのモデルでは、トレーニング資料で表されるドメインと単語に対して高精度のasrが可能ですが、トレーニング中にほとんどまたはまったく表されない単語を認識するのは困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Speech Command Recognition in Computationally Constrained Environments
  with a Quadratic Self-organized Operational Layer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.AS/paper_3.html">
      <font color="black">Speech Command Recognition in Computationally Constrained Environments
  with a Quadratic Self-organized Operational Layer</font>
    </a>
  </h2>
  <font color="black">したがって、組み込みデバイスに結果の分類器を実装できるようにするには、これらの複雑なモデルを絞るか、より効率的な軽量モデルを使用する必要があります。採用された方法は、テイラー展開と2次形式のアイデアを借用して入力層と非表示層の両方の特徴のより良い表現。このより豊富な表現は、Google音声コマンド（GSC）および合成音声コマンド（SSC）データセットでの広範な実験によって示されるように、認識精度の向上をもたらします。 
[概要]必要な認識モデルは通常、ディープラーニングの方法に従います。これらは、メモリとエネルギーを大量に消費する複雑なネットワークです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-end Silent Speech Recognition with Acoustic Sensing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.AS/paper_4.html">
      <font color="black">End-to-end Silent Speech Recognition with Acoustic Sensing</font>
    </a>
  </h2>
  <font color="black">また、CNNと注意ベースのエンコーダ-デコーダネットワークを組み合わせたエンドツーエンドの認識フレームワークを提案します。限られた語彙（54文）での評価結果は、話者に依存しない環境で8.4％の単語誤り率をもたらします。 -独立した設定、および目に見えない文のテストの場合は8.1％。これらの反射の抽出された位相特徴は、音声を認識するために深層学習ネットワークに供給されます。 
[概要]聞こえない音響信号を使用して、人々が話すときの唇の動きをキャプチャするサイレント音声インターフェイスを紹介します。これらの反射の抽出された位相特徴は、音声を認識するために深層学習ネットワークに送られます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Discriminative Neural Clustering for Speaker Diarisation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.AS/paper_5.html">
      <font color="black">Discriminative Neural Clustering for Speaker Diarisation</font>
    </a>
  </h2>
  <font color="black">AMIの実験結果は、DNCがスペクトルクラスタリングと比較して29.4％のスピーカーエラー率（SER）の削減を達成することを示しています。AMIには個々の入力シーケンスとして147の完全な会議しか含まれていないため、データ不足はTransformerモデルをトレーニングするための重要な問題です。 DNC ..この論文では、監視されたシーケンス間学習問題として、クラスターの最大数でデータクラスタリングを定式化するDiscriminative Neural Clustering（DNC）を提案します。 
[ABSTRACT] dncは、類似性測度の明示的な定義を必要とせずに、トレーニングデータからクラスタリングパターンを学習します。データの不足は、8月のトランスモデルをトレーニングするための重要な問題です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-22">
        <br><font color="black">2019-10-22</font>
      </time>
    </span>
</section>
<!-- paper0: The Zero Resource Speech Benchmark 2021: Metrics and baselines for
  unsupervised spoken language modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-24/eess.AS/paper_6.html">
      <font color="black">The Zero Resource Speech Benchmark 2021: Metrics and baselines for
  unsupervised spoken language modeling</font>
    </a>
  </h2>
  <font color="black">また、同じデータでトレーニングされたテキストベースの「トップライン」システムと比較してパフォーマンスが低下し、より洗練されたエンドツーエンドモデルによって探索されるスペースが示されます。新しい監視されていないタスクである音声言語モデリングを紹介します。学習ゼロリソーススピーチベンチマーク2021とともに、ラベルのない生のオーディオ信号からの言語表現の組み合わせ：音声学、レキシコン、構文の4つの言語レベルで学習されたモデルの品質を調査する4つのブラックボックスのゼロショットメトリックのスイートこの単純なパイプラインは、4つのメトリックすべてで偶然よりも優れたパフォーマンスを示し、生の音声からの話し言葉のモデリングの実現可能性を示しています。 
[概要]教師なしシステムのリストが言語レベルの混合で提示されました。プロジェクトは、4つのメトリックすべてで偶然の学習よりも優れており、音声言語モデリングの実現可能性を示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
