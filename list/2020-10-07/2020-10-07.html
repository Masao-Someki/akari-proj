<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-10-07の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Speech Paralinguistic Approach for Detecting Dementia Using Gated
  Convolutional Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.SD/paper_0.html">
      <font color="black">Speech Paralinguistic Approach for Detecting Dementia Using Gated
  Convolutional Neural Network</font>
    </a>
  </h2>
  <font color="black">PROMPTデータベースでは、4秒の音声データを使用すると74.7％の精度が得られ、患者のすべての音声データを使用すると80.8％に向上します。さらに、3つのクラスの分類問題でこの方法を評価します。軽度認知障害（MCI）クラスを含め、40秒の音声データで60.6％の精度を達成しました。この方法では、平均114秒の音声データを使用してピットコーパスで73.1％の精度が得られます。 
[概要]私たちの方法では、平均114秒の音声データを使用して、ピットコーパスで73.1％の精度が得られます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br><font color="black">2020-04-16</font>
      </time>
    </span>
</section>
<!-- paper0: Independent Vector Analysis with Deep Neural Network Source Priors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.SD/paper_1.html">
      <font color="black">Independent Vector Analysis with Deep Neural Network Source Priors</font>
    </a>
  </h2>
  <font color="black">実験結果は、結果として得られるニューラルネットワーク密度の事前分布が、オンライン実装の収束速度とバッチ実装の信号対干渉比（SIR）において、以前のニューラルネットワーク密度の事前分布を一貫して上回っていることを示唆しています。ここで、導関数を効率的に推定できることを初めて示します。特定のプロキシ分離関連のパフォーマンスインデックスを最適化することによる、ディープニューラルネットワーク（DNN）などのユニバーサル近似器による音声密度の評価。この論文では、例示的なアプリケーションとして複雑な音声混合分離を使用した独立ベクトル分析（IVA）の密度優先順位を研究します。 
[概要] ivaの既存のソースプライアのほとんどは、スピーチの細かい構造をキャプチャするには単純すぎます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-23">
        <br><font color="black">2020-08-23</font>
      </time>
    </span>
</section>
<!-- paper0: Pay Attention to the cough: Early Diagnosis of COVID-19 using
  Interpretable Symptoms Embeddings with Cough Sound Signal Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.SD/paper_2.html">
      <font color="black">Pay Attention to the cough: Early Diagnosis of COVID-19 using
  Interpretable Symptoms Embeddings with Cough Sound Signal Processing</font>
    </a>
  </h2>
  <font color="black">実験の結果は、モデルが、95.04 $ \ pm $ 0.18％および96.83 $ \ pmのより高い特異性と精度で、COVID-19患者の咳といくつかのタイプの非COVID-19咳を区別するためのより優れた堅牢な機能埋め込みをキャプチャすることを示しています解釈可能性を維持しながら、それぞれ0.18％ドル..これらの制限を克服するために、咳音の特徴と症状のメタデータに基づいて、解釈可能でCOVID-19診断AIフレームワークが考案および開発されています。執筆時点では、特定の抗ウイルス薬はありません。または、感染の伝播と拡大を制御するためにワクチンが推奨されます。 
[概要]提案されたフレームワークのパフォーマンスは、医療データセットを使用して評価されました。4つの咳クラスを持つ150人の患者からの328の咳音</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: The Sequence-to-Sequence Baseline for the Voice Conversion Challenge
  2020: Cascading ASR and TTS -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.SD/paper_3.html">
      <font color="black">The Sequence-to-Sequence Baseline for the Voice Conversion Challenge
  2020: Cascading ASR and TTS</font>
    </a>
  </h2>
  <font color="black">オープンソースのエンドツーエンド音声処理ツールキットであるESPnetと、コミュニティが提供する多くの適切に構成された事前トレーニング済みモデルを利用して、シーケンスツーシーケンス（seq2seq）フレームワークの下でこの方法を再検討します。実装が行われます。オープンソース：https：//github.com/espnet/espnet/tree/master/egs/vcc20 ..このペーパーでは、音声変換チャレンジ（VCC）2020のシーケンス間（seq2seq）ベースラインシステムを紹介します。 
[概要]音声変換への素朴なアプローチを検討します。これは、最初に自動音声認識モデルを使用して音声を転写することです。次に、このメソッドを使用して、text2seqによるtext-to-speechを使用してtext2seqモデルを作成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: AGIF: An Adaptive Graph-Interactive Framework for Joint Multiple Intent
  Detection and Slot Filling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.SD/paper_4.html">
      <font color="black">AGIF: An Adaptive Graph-Interactive Framework for Joint Multiple Intent
  Detection and Slot Filling</font>
    </a>
  </h2>
  <font color="black">3つのマルチインテントデータセットでの実験結果は、フレームワークが大幅な改善を実現し、最先端のパフォーマンスを実現していることを示しています。さらに、フレームワークは2つのシングルインテントデータセットで新しい最先端のパフォーマンスを実現しています。このような相互作用レイヤーは、各トークンに適応的に適用されます。これには、関連するインテント情報を自動的に抽出し、トークンレベルのスロット予測のためのきめ細かいインテント情報の統合を行うという利点があります。 
[概要]ほとんどの話し言葉理解（slu）モデルは、主に単一のインテント状態に焦点を当てています-または単にすべてのトークンの全体的なインテントコンテキストツールを組み込んでいます。さらに、私たちのフレームワークは、2つの単一のインテントデータセットで新しい最先端のパフォーマンスを実現します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br><font color="black">2020-04-21</font>
      </time>
    </span>
</section>
<!-- paper0: The Academia Sinica Systems of Voice Conversion for VCC2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.SD/paper_5.html">
      <font color="black">The Academia Sinica Systems of Voice Conversion for VCC2020</font>
    </a>
  </h2>
  <font color="black">評価では、リスニングテストにより、システムがVCC2020チャレンジで良好に機能することが示されました。タスク2では、ベクトル量子化変分オートエンコーダー（VQVAE）によって抽出された教師なし音声記号を使用しました。タスク1では、国際音声記号を使用しました。 TTSモデルの入力としてのアルファベット（IPA）。 
[ABSTRACT]両方のタスクで、カスケードされたasrtts構造に従いました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Textual Supervision for Visually Grounded Spoken Language Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.SD/paper_6.html">
      <font color="black">Textual Supervision for Visually Grounded Spoken Language Understanding</font>
    </a>
  </h2>
  <font color="black">さまざまな戦略を比較すると、十分なテキストが利用できる場合にパイプラインアプローチの方が効果的であることがわかります。リソースの少ない言語を念頭に置いて、文字起こしの代わりに翻訳を効果的に使用できることも示していますが、同様の結果を得るにはより多くのデータが必要です。 。最近の研究では、トレーニング時に文字起こしが利用可能であれば、これらのモデルを改善できることが示されています。 
[概要]これは、トレーニングが困難なリソースが少ない場合に役立ちます。ただし、エンドツーエンドのアプローチが従来のパイプラインベースのアプローチとどのように比較されるかは明確ではありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: A Unified Deep Learning Framework for Short-Duration Speaker
  Verification in Adverse Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.SD/paper_7.html">
      <font color="black">A Unified Deep Learning Framework for Short-Duration Speaker
  Verification in Adverse Environments</font>
    </a>
  </h2>
  <font color="black">結果は、提案された方法が困難な条件でのSVに効果的であり、ベースラインのiベクトルおよびディープスピーカー埋め込みシステムよりも優れたパフォーマンスを発揮することを示しています。音響歪み（つまり、ノイズと残響）に対するロバスト性をさらに向上させるために、マスキングベースの音声強調（SE）法..私たちの知る限り、これは深層学習フレームワークでこれら3つのモデルを組み合わせた最初の作業です。 
[概要] svシステムは、特にノイズの多い残響のある環境で、短い音声セグメントに適している必要があります。sv、vad、seモデルを統合されたディープラーニングフレームワークに組み合わせます。ノイズによって破損している韓国語の埋め込みデータセットで実験を行います。と残響</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Motion-Excited Sampler: Video Adversarial Attack with Sparked Prior -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.IV/paper_0.html">
      <font color="black">Motion-Excited Sampler: Video Adversarial Attack with Sparked Prior</font>
    </a>
  </h2>
  <font color="black">スパークされた事前情報はフレーム相関を強調し、相対運動を介してビデオダイナミクスを利用します。4つのベンチマークデータセットでの広範な実験結果は、提案された方法の有効性を検証します。勾配推定でスパークされた事前情報を使用することにより、さまざまなビデオ分類モデルを攻撃できます。クエリ数が少なくなります。 
[概要]これらの作品が敵対的攻撃に失敗したのはこれが初めてです。これには、勾配推定でスパークされた事前情報を使用することが含まれ、クエリ数を減らしてさまざまなビデオ分類モデルを攻撃することができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-17">
        <br><font color="black">2020-03-17</font>
      </time>
    </span>
</section>
<!-- paper0: Parallax Motion Effect Generation Through Instance Segmentation And
  Depth Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.IV/paper_1.html">
      <font color="black">Parallax Motion Effect Generation Through Instance Segmentation And
  Depth Estimation</font>
    </a>
  </h2>
  <font color="black">実験結果と視覚品質評価は、マスクR-CNNまたはFBNetネットワーク（インスタンスセグメンテーション）と組み合わせたPyD-Netネットワーク（深度推定）が良好な視覚品質で視差運動効果を生成できることを示しています。この論文では、最先端のインスタンスセグメンテーションと深度推定アプローチを利用して、単一の画像から視差運動効果を生成します。この作業では、視差運動の効率と品質の間のトレードオフを調査するために、そのようなアルゴリズムとの比較も示します。インスタンスのセグメンテーションと深度推定を同時に推定できるマルチタスク学習ネットワークを考慮した効果。 
[概要]運動視差推定は、この目的を達成するための有望な手法です。これは、30年の仮想環境でのユーザーエクスペリエンスを向上させることです。これを使用して、面積と深度を推定するネットワークを開発できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Downscaling Attacks: What You See is Not What You Get -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.IV/paper_2.html">
      <font color="black">Downscaling Attacks: What You See is Not What You Get</font>
    </a>
  </h2>
  <font color="black">通常、コンピュータビジョンシステムの前処理に必要な部分である画像のサイズ変更は、攻撃に対して脆弱です。これらの攻撃と防御は、機械学習における入力サニタイズの役割を確立するのに役立ちます。画像は、次のように作成できることを示します。マシンビジョンスケールでは、他のスケールとは画像が完全に異なります。 
[概要]これらの攻撃と防御は、機械学習における入力サニタイズの役割を確立するのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: The Bures Metric for Taming Mode Collapse in Generative Adversarial
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.IV/paper_3.html">
      <font color="black">The Bures Metric for Taming Mode Collapse in Generative Adversarial
  Networks</font>
    </a>
  </h2>
  <font color="black">ダイバーシティマッチングにより、モードの崩壊が大幅に減少し、サンプルの品質にプラスの効果があることがわかります。ブレ距離の計算は、共分散とカーネル行列の観点から、特徴空間またはカーネル空間のいずれかで便利に実行できます。モデルは、確率分布全体からサンプリングできません。 
[概要]本物と偽物のデータの最後の層を使用して、本物と偽物のデータの確率の分布を調査します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-16">
        <br><font color="black">2020-06-16</font>
      </time>
    </span>
</section>
<!-- paper0: COVIDomaly: A Deep Convolutional Autoencoder Approach for Detecting
  Early Cases of COVID-19 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.IV/paper_4.html">
      <font color="black">COVIDomaly: A Deep Convolutional Autoencoder Approach for Detecting
  Early Cases of COVID-19</font>
    </a>
  </h2>
  <font color="black">ただし、COVID-19などの特定のパンデミックの発生時には、影響を受けるケースが堅牢な検出のためにモデルをトレーニングするための十分なデータがない可能性があります。したがって、教師あり分類は、時間がかかるため、この問題には不適切です。感染者のデータを大量に収集すると、人命が失われ、予防的介入が遅れる可能性があります。COVID-19の特定のケースでは、感染患者の胸部X線撮影画像が特徴的な異常を示すことがいくつかの研究で示されています。 
[概要] 3,300万件以上の確定症例と100万人以上の死亡があります。パンデミックは、パンデミックを完全に封じ込めるにはまだ長い道のりです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Vec2Instance: Parameterization for Deep Instance Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.IV/paper_5.html">
      <font color="black">Vec2Instance: Parameterization for Deep Instance Segmentation</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチの合計ピクセル単位の精度は89 \％であり、最先端のマスクRCNN（91 \％）の精度に近いです。Vec2Instanceは、インスタンスのパラメーター化のフレームワークを提供し、畳み込みニューラルネットワークが効率的に推定できるようにします。重心の周りのインスタンスの複雑な形状..深層学習の現在の進歩により、オブジェクトの分類、ローカリゼーション、セマンティックセグメンテーション、インスタンスのセグメンテーションなどのコンピュータービジョンタスクで人間レベルの精度がもたらされています。 
[ABSTRACT] vec2instanceは、新しいディープパラトロールニューラルネットワークアーキテクチャです。たとえば、セグメンテーションなどのvec2instanceは、衛星画像で使用できます。この調査で開発されたコードは、vec2instancegithubリポジトリで入手できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: ASDN: A Deep Convolutional Network for Arbitrary Scale Image
  Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.IV/paper_6.html">
      <font color="black">ASDN: A Deep Convolutional Network for Arbitrary Scale Image
  Super-Resolution</font>
    </a>
  </h2>
  <font color="black">小規模（1〜2）のSRの場合、画像は、事前に計算されたラプラシアンピラミッドレベルのスパースセットからの補間によって構築されます。大規模のSRは、小規模からの再帰によって計算されるため、計算コストが大幅に削減されます。畳み込みニューラルネットワークは、超解像（SR）のピーク信号対雑音比を大幅に改善しました。 
[ABSTRACT]完全な比較のために、さまざまなベンチマークを使用して、固定スケールおよび任意のスケールの実験が実行されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Saliency is a Possible Red Herring When Diagnosing Poor Generalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.IV/paper_7.html">
      <font color="black">Saliency is a Possible Red Herring When Diagnosing Poor Generalization</font>
    </a>
  </h2>
  <font color="black">これは顕著性マップを使用して視覚的に診断できるとよく考えられます。一般化が不十分なことは、クラスを表す真の画像特徴ではなく、トレーニング分布にのみ存在する偽相関画像特徴を使用してターゲット変数を予測することを学習するモデルの1つの症状です。 ..このようなマスクが利用可能なトレーニング画像で、関心領域の外側にある可能性のある気を散らす特徴を無視するようにネットワークをトレーニングすることにより、このような補助ラベルを利用する複数の方法を研究します。 
[概要]これは顕著性マップを使用して視覚的に診断できるとよく考えられます。人間の専門家のマスクを使用した画像は、予測を行うための関連情報を含む画像の領域を示すことができます。これらの結果は、一般化不良の根本原因がそうではない可能性があることを示唆しています。常に空間的に定義される</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-01">
        <br><font color="black">2019-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: Detection of Ship Wakes in SAR Imagery Using Cauchy Regularisation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.IV/paper_8.html">
      <font color="black">Detection of Ship Wakes in SAR Imagery Using Cauchy Regularisation</font>
    </a>
  </h2>
  <font color="black">ベイズ法であるMoreau-Yoshidaunadjusted Langevinアルゴリズム（MYULA）は、計算効率が高く、ロバストであり、負の対数事後分布を最小化することにより、変換領域の画像を推定します。Cauchy事前ベースアプローチの検出精度は86.7％であり、6つのCOSMO-SkyMed画像での実験によって実証されています。この論文では、線形特徴が強化されたSAR画像のラドン変換を取得するためのスパース正規化に基づく革新的な船後流検出方法を提案します。 
[概要]コーシー事前分布のコスト関数が提案されていますが、それがどの程度効果的であるかは不明です。システムの吐き気は86.7％、吐き気率は86.7％です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-12">
        <br><font color="black">2020-02-12</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal brain tumor classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.IV/paper_9.html">
      <font color="black">Multimodal brain tumor classification</font>
    </a>
  </h2>
  <font color="black">検証）バランスの取れた精度、カッパおよびf1が0.913、0.897、および0.951（それぞれ。相互検証を報告します（それぞれ0.91、0.90および0.94）。
[要約]放射線画像は、癌診断の有効性についてより多くの知識をもたらすはずです。 。スライド画像全体の強力で一般的なモジュール式の学習方法が含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: autoTICI: Automatic Brain Tissue Reperfusion Scoring on 2D DSA Images of
  Acute Ischemic Stroke Patients -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.IV/paper_10.html">
      <font color="black">autoTICI: Automatic Brain Tissue Reperfusion Scoring on 2D DSA Images of
  Acute Ischemic Stroke Patients</font>
    </a>
  </h2>
  <font color="black">MINIP画像では、血管、灌流、背景のピクセルがセグメント化されています。AUCスコアは二分されたeTICIに対して0.90です。この作業では、自動および定量的なTICIスコアリング方法であるautoTICIを紹介します。 
[概要]この作業では、自動および定量的なticiスコアリング方法であるautoticiを紹介します。これは血管内治療後の技術的アウトカム指標として使用されます（evt）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-03">
        <br><font color="black">2020-10-03</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Synthetic Augmentation using Label-to-Image Translation for
  Nuclei Image Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.IV/paper_11.html">
      <font color="black">Generative Synthetic Augmentation using Label-to-Image Translation for
  Nuclei Image Segmentation</font>
    </a>
  </h2>
  <font color="black">提案された合成増強手順が精度を向上させることを計算して報告します。医用画像診断では、セマンティックセグメンテーションを使用した病理画像分析がデジタル病理学の分野としての効率的なスクリーニングに重要になります。まさにこの論文は腫瘍の核の染色スライドを扱います。 。 
[概要]エッジ構造を持つセマンティックラベルから実際の画像へのマッピングである、ラベルから画像への変換を使用した合成拡張を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br><font color="black">2020-04-21</font>
      </time>
    </span>
</section>
<!-- paper0: Histopathological Stain Transfer using Style Transfer Network with
  Adversarial Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.IV/paper_12.html">
      <font color="black">Histopathological Stain Transfer using Style Transfer Network with
  Adversarial Loss</font>
    </a>
  </h2>
  <font color="black">この作業では、敵対的損失と組み合わせた高速ニューラルスタイル転送を使用した染色正規化問題の新しいアプローチを提示します。単一のラボおよび/またはスキャナーから取得した組織病理学的画像でトレーニングされた深層学習モデルは、取得した画像の推論パフォーマンスが低くなります異なる染色プロトコルを使用した別のスキャナー/ラボから..この染色について深層学習モデルをトレーニングし、対応する染色転送ジェネレーターネットワークを使用して残りの画像を転送しました。 
[概要]この染色について深層学習モデルをトレーニングしました。残りの画像は、対応する染色転送ジェネレータネットワークを使用して転送されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Unified Supervised-Unsupervised (SUPER) Learning for X-ray CT Image
  Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.IV/paper_13.html">
      <font color="black">Unified Supervised-Unsupervised (SUPER) Learning for X-ray CT Image
  Reconstruction</font>
    </a>
  </h2>
  <font color="black">提案されたトレーニングアルゴリズムは、2レベルの教師ありトレーニング最適化問題の近似スキームでもあり、下位レベルのMBIR問題のネットワークベースの正則化は上位レベルの再構成損失を使用して最適化されます。この作業では、統合された教師ありトレーニングを提案します。 -X線コンピューター断層撮影（CT）画像再構成のための非教師あり（SUPER）学習フレームワーク..数値と視覚の両方の結果は、スタンドアロンの教師あり学習ベースの方法、反復MBIR法、およびSUPERのバリエーションに対する提案された統合SUPER法の優位性を示していますアブレーション研究によって得られた。 
[概要]提案された方法は、教師なし学習と教師なし学習の両方を組み合わせたものであり、どちらにも長所と短所があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: A Generalized Framework for Analytic Regularization of Uniform Cubic
  B-spline Displacement Fields -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.IV/paper_14.html">
      <font color="black">A Generalized Framework for Analytic Regularization of Uniform Cubic
  B-spline Displacement Fields</font>
    </a>
  </h2>
  <font color="black">また、解析ソリューションが有限差分ベースの数値実装よりも大幅に高速（最大2桁）で実行されることを示すベンチマーク結果も提供します。正規化ペナルティは通常、変位ベクトルフィールドの導関数の関数であり、次のようになります。解析的または数値的に計算されます。登録変換として3次Bスプラインを使用して、拡散、曲率、線形弾性、3次、および全変位の5つの異なる正規化子をサポートする一般化された数学的フレームワークを開発します。 
[概要]これらの画像の実現は、実際には数学的に効率的な分析フレームワークです。精度の観点から、それぞれを数値の対応物と比較することにより、アプローチを説明します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: CORE: Color Regression for Multiple Colors Fashion Garments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_0.html">
      <font color="black">CORE: Color Regression for Multiple Colors Fashion Garments</font>
    </a>
  </h2>
  <font color="black">複数の色の衣服の作業をさらに拡張します。第1段階では、メインの個別の色名を検出しながら画像の照明を補正します。第2段階では、色名の注意（検出された色に依存）とオブジェクトの注意（衣料品カテゴリ）、最後に画像ピクセルのRGB値に空間プーリングを重み付けします。 
[概要]各ファッションアイテムに連続カラーパレットのラベルが付いたデータセットを収集します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Video Anomaly Detection Using Pre-Trained Deep Convolutional Neural Nets
  and Context Mining -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_1.html">
      <font color="black">Video Anomaly Detection Using Pre-Trained Deep Convolutional Neural Nets
  and Context Mining</font>
    </a>
  </h2>
  <font color="black">さらに、高レベルの機能からコンテキストプロパティを導出して、ビデオ異常検出方法のパフォーマンスをさらに向上させます。これらの深層学習方法は、非常に複雑な大規模なトレーニングデータを使用します。異常検出は、インテリジェント監視システムにとって非常に重要です。悪意のあるアクティビティをタイムリーに検出します。 
[概要]ディープラーニング手法を使用した多くのビデオ異常検出アプローチは、固定シナリオの単一カメラビデオストリームに焦点を当てています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Motion-Excited Sampler: Video Adversarial Attack with Sparked Prior -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_2.html">
      <font color="black">Motion-Excited Sampler: Video Adversarial Attack with Sparked Prior</font>
    </a>
  </h2>
  <font color="black">4つのベンチマークデータセットでの広範な実験結果は、提案された方法の有効性を検証します。この論文では、ビデオフレーム間の固有の動きパターンと地域の相対運動を利用してビデオモデルを攻撃することを目指しています。少ないクエリ数でさまざまなビデオ分類モデルを攻撃できます。 
[概要]これらの作品が敵対的攻撃に失敗したのはこれが初めてです。これには、勾配推定でスパークされた事前情報を使用することが含まれ、クエリ数を減らしてさまざまなビデオ分類モデルを攻撃することができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-17">
        <br><font color="black">2020-03-17</font>
      </time>
    </span>
</section>
<!-- paper0: The Effectiveness of Memory Replay in Large Scale Continual Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_3.html">
      <font color="black">The Effectiveness of Memory Replay in Large Scale Continual Learning</font>
    </a>
  </h2>
  <font color="black">生のアクティベーションマップを保存するとメモリと計算コストが劇的に増加する可能性があることを考慮して、レイヤーアクティベーションの圧縮表現をリプレイバッファに保存する圧縮アクティベーションリプレイ手法を提案します。ただし、メモリが少ないERではパフォーマンスの低下が見られます。多様なタスクセットと標準の共通データセット（Split-CIFARおよびSplit-miniImageNet）を使用した大規模なタスクノミーベンチマークの両方での実験は、提案された方法の有効性を示しています。 
[ABSTRACT]バニラエクスペリエンスリプレイ（er）は、そのシンプルさにもかかわらず、パフォーマンスとスケーラビリティの両方の点で依然として非常に競争力があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervised Exposure Trajectory Recovery for Dynamic Blur Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_4.html">
      <font color="black">Self-supervised Exposure Trajectory Recovery for Dynamic Blur Estimation</font>
    </a>
  </h2>
  <font color="black">相対的な動きの軌跡を記録してぼやけた画像に含まれる動き情報を表し、動的なぼけの原因を説明する露出軌跡を定義します。モーションオフセットと呼ばれる新しいぼけ表現をピクセル単位でモデル化するために提案します。複数の時点での潜在的な鮮明な画像の変位。ただし、ぼやけた画像に含まれる動き情報は、次の理由により、まだ十分に調査および正確に定式化されていません。（i）ぼやけた動きのグラウンドトゥルースを取得するのが難しい。 （ii）時間的順序は暴露中に破壊されます。 （iii）動き推定は非常に不適切です。 
[ABSTRACT]動的ブラーは、シャープなコンテンツの相対的な動きで表すことができます。カメラの露出の原理を再検討することにより、新しいブラー表現が提案されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Assisted Probe Positioning for Ultrasound Guided Radiotherapy Using
  Image Sequence Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_5.html">
      <font color="black">Assisted Probe Positioning for Ultrasound Guided Radiotherapy Using
  Image Sequence Classification</font>
    </a>
  </h2>
  <font color="black">最初のセットは、クラスを使用して視野に見える関連する前立腺の解剖学的構造を識別します：前立腺の外側、前立腺周辺、前立腺中心..このようなアルゴリズムは、効果的な患者のセットアップ中のリアルタイムフィードバック..2番目のセットでは、プローブと前立腺の中心をクラス（左に移動、右に移動、停止）で位置合わせするために、プローブの角度調整を推奨しています。 
[ABSTRACT]マルチ入力マルチタスクアルゴリズムを使用して、光学的に追跡された超音波プローブからの空間座標データを、リカレントニューラルネットワークを使用して画像分類器と組み合わせて、2セットの予測をリアルタイムで生成します。2番目のセットは推奨します。プローブと前立腺中心の間の位置合わせを達成するためのプローブ角度調整</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Video Saliency Detection with Domain Adaptation using Hierarchical
  Gradient Reversal Layers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_6.html">
      <font color="black">Video Saliency Detection with Domain Adaptation using Hierarchical
  Gradient Reversal Layers</font>
    </a>
  </h2>
  <font color="black">また、モデルのエンコーダーから抽出された階層的特徴を、複数のスケールでの勾配反転に基づくドメイン適応アプローチと組み合わせて、トレーニング中に注釈が提供されないデータセットの一般化機能を改善します。標準ベンチマークでの実験結果つまり、DHF1K、Hollywood2、およびUCF Sportsは、提案されたモデルが、教師あり顕著性予測のほとんどのメトリックで最先端の方法よりも優れていることを示しています。この作業では、マルチを使用するビデオ顕著性検出のための3D完全畳み込みアーキテクチャを提案します。 -さまざまな抽象化レベルで抽出された特徴を使用して生成された中間マップ（目立ちやすさマップと呼ばれる）のヘッド監視。 
[概要]モデルは単一のエンコーダーを使用し、さまざまなレベルで抽出された特徴が複数のデコーダーに渡されます。標準ベンチマークでの実験結果は、提案されたモデルが教師あり顕著性予測のほとんどのメトリックでsp状態の方法よりも優れていることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-02">
        <br><font color="black">2020-10-02</font>
      </time>
    </span>
</section>
<!-- paper0: 3D-Aided Data Augmentation for Robust Face Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_7.html">
      <font color="black">3D-Aided Data Augmentation for Robust Face Understanding</font>
    </a>
  </h2>
  <font color="black">この目的のために、幾何学的に正確な顔のランドマーク、属性、およびアイデンティティ情報にそれぞれ関連付けられた3D顔モデリングを通じて、異なる照明条件で複数の視点からリアルな3D拡張画像を生成する方法を提案します。データ拡張はデータの絞り込みに非常に効果的です。特にグラウンドトゥルースラベルを取得するのが困難で費用がかかるタスクの場合、ギャップと人間の注釈のコストの削減。したがって、これらの場合にデータ拡張を実行することが望ましいでしょう。 
[概要]提案された3Dデータ拡張方法は、複数のベンチマークで最先端技術を達成しながら、さまざまな顔理解タスクのパフォーマンスと堅牢性を大幅に向上させます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-03">
        <br><font color="black">2020-10-03</font>
      </time>
    </span>
</section>
<!-- paper0: RMM: A Recursive Mental Model for Dialog Navigation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_8.html">
      <font color="black">RMM: A Recursive Mental Model for Dialog Navigation</font>
    </a>
  </h2>
  <font color="black">RMMにより、新しい環境へのより良い一般化が可能になることを示します。ガイドエージェントは、ナビゲーションエージェントをモデル化して、回答を生成するために必要なナビゲーションステップをシミュレートします。目標に向けて進行状況エージェントを使用して、直接の強化学習報酬信号として使用します。ナビゲーションアクションだけでなく、質問と回答の生成の両方も通知します。 
[ABSTRACT]心の理論に従って、再帰的メンタルモデル（rmm）を提案します。ガイドエージェントは、ナビゲーションエージェントをモデル化して、回答を生成するために必要なナビゲーションステップをシミュレートします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-02">
        <br><font color="black">2020-05-02</font>
      </time>
    </span>
</section>
<!-- paper0: PODNet: Pooled Outputs Distillation for Small-Tasks Incremental Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_9.html">
      <font color="black">PODNet: Pooled Outputs Distillation for Small-Tasks Incremental Learning</font>
    </a>
  </h2>
  <font color="black">PODNetを3つのデータセット（CIFAR100、ImageNet100、ImageNet1000）の3つの最先端モデルと比較して、これらの革新を徹底的に検証します。PODNetは、モデル全体に適用される効率的な空間ベースの蒸留損失で既存の芸術を革新し、クラスごとに複数のプロキシベクトルで構成される表現。コードはhttps://github.com/arthurdouillard/incremental_learning.pytorchで入手できます。ニューヨーク大学のエンジニアは、学習に苦労しているpodnetを提案しています。学習のためのツールとして使用するように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br><font color="black">2020-04-28</font>
      </time>
    </span>
</section>
<!-- paper0: High Speed Event Camera TRacking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_10.html">
      <font color="black">High Speed Event Camera TRacking</font>
    </a>
  </h2>
  <font color="black">この方法には、非常に高速な外れ値除去を使用して、イベントを投影された線分と照合するための堅牢なメカニズムが含まれています。嘘理論的な意味で..この作業では、このセンシング技術の限界を探り、10のスループットで25.8gを超えるダイナミクスで6自由度の動きを推定できる超高速追跡アルゴリズムを提示します。 kHz、1秒あたり100万を超えるイベントを処理します。 
[概要]システムは、カメラの動きや物体の動きを追跡することができます。エラーを使用します-嘘で設計された状態カルマンフィルター-理論的な意味で</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Support-set bottlenecks for video-text representation learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_11.html">
      <font color="black">Support-set bottlenecks for video-text representation learning</font>
    </a>
  </h2>
  <font color="black">私たちの提案する方法は、MSR-VTT、VATEX、ActivityNetで、ビデオからテキストへの検索とテキストからビデオへの検索で他の方法よりも大幅に優れています。この論文では、生成モデルを活用してこれを軽減する新しい方法を提案します。これらの関連サンプルを自然にプッシュするには：各サンプルのキャプションは、他のサポートサンプルの視覚的表現の重み付けされた組み合わせとして再構築する必要があります。この最後の動作は厳密すぎて、意味的に関連するサンプルに対しても異なる表現を強制します。たとえば、視覚的に類似した動画や、同じ描写されたアクションを共有する動画などです。 
[概要]この最後の動作は厳密すぎて、意味的に関連するサンプルに対しても異なる表現を強制します。この単純なモデルにより、表現が過度に特殊化されないようになり、データセット全体で再利用可能になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Training Deep Neural Networks for Wireless Sensor Networks Using Loosely
  and Weakly Labeled Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_12.html">
      <font color="black">Training Deep Neural Networks for Wireless Sensor Networks Using Loosely
  and Weakly Labeled Images</font>
    </a>
  </h2>
  <font color="black">ターゲットドメインは、新しいターゲットカテゴリがあり、焦点が合っていない、解像度が低い、照明が低い、撮影角度が低い低品質の画像で構成されているため、ソースドメインとは大きく異なります。カテゴリレベルの平均誤差目に見えない不均衡なターゲットドメインで41.12％減少しました。トレーニングされたネットワークでは、予測ごとに約7M（ResNet-20は約41M）の乗算があり、デジタルシグナルプロセッサチップがでリアルタイム認識を実行できるほど小さいです。私たちのWSN。 
[概要]最小限の労力で効率的なネットワークをトレーニングするために、費用対効果の高いドメイン一般化（cedg）アルゴリズムが提案されています。ターゲットドメインはパラメータから分離され、モデルのテストとテストにのみ使用されます。ターゲットドメインのサイズは約7mです（ターゲット）そして、デジタルシグナルプロセッサチップがwsnでリアルタイム認識を実行できるように十分に小さい</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Robust Multilevel Semantic Cross-Modal Hashing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_13.html">
      <font color="black">Deep Robust Multilevel Semantic Cross-Modal Hashing</font>
    </a>
  </h2>
  <font color="black">このために、情報コーディング理論分析に基づいてこの値の有効範囲を示し、上記の目標をマージン適応トリプレット損失に具体化します。さらに、複数のハッシュコードを融合して疑似コードを導入し、めったに探索しません。 -見られたセマンティクス、類似性情報の希薄性の問題を軽減します。3つのベンチマークでの実験は、導出された境界の有効性を示し、私たちの方法は最先端のパフォーマンスを達成します。 
[概要]共同ハミング空間にデータを埋め込む方法では、モーダルディスカルパンシーとノイズが大きくなるため、誤ったコードが生成されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-07">
        <br><font color="black">2020-02-07</font>
      </time>
    </span>
</section>
<!-- paper0: Parallax Motion Effect Generation Through Instance Segmentation And
  Depth Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_14.html">
      <font color="black">Parallax Motion Effect Generation Through Instance Segmentation And
  Depth Estimation</font>
    </a>
  </h2>
  <font color="black">実験結果と視覚的品質評価は、マスクR-CNNまたはFBNetネットワーク（インスタンスセグメンテーション）と組み合わせたPyD-Netネットワーク（深度推定）が良好な視覚的品質で視差運動効果を生成できることを示しています。この論文では、最先端のインスタンスセグメンテーションと深度推定アプローチを利用して、単一の画像から視差運動効果を生成します。ステレオビジョンは、このテクノロジーが開発のために提供する無数の機会とアプリケーションのために、コンピュータービジョンで成長しているトピックです。仮想および拡張現実アプリケーションなどの最新のソリューション。 
[概要]運動視差推定は、この目的を達成するための有望な手法です。これは、30年の仮想環境でのユーザーエクスペリエンスを向上させることです。これを使用して、面積と深度を推定するネットワークを開発できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Learning of State Estimation for Manipulating Deformable
  Linear Objects -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_15.html">
      <font color="black">Self-Supervised Learning of State Estimation for Manipulating Deformable
  Linear Objects</font>
    </a>
  </h2>
  <font color="black">これは、幅広い視覚的外観にわたって一般化できる新しい自己監視学習目標によって達成されます。これは、視覚的な違いへの一般化が保証されていないピクセル空間または潜在空間で学習されるダイナミクスとは対照的です。状態空間のダイナミクスは、1つの設定で学習し、他の視覚的に異なる設定で直接使用できます。 
[概要]私たちは、高価な注釈を必要とせずに、実際の画像でロープ状態推定の自己教師ありトレーニングを実証した最初の企業です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-14">
        <br><font color="black">2019-11-14</font>
      </time>
    </span>
</section>
<!-- paper0: Robust and Generalizable Visual Representation Learning via Random
  Convolutions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_16.html">
      <font color="black">Robust and Generalizable Visual Representation Learning via Random
  Convolutions</font>
    </a>
  </h2>
  <font color="black">ランダムな畳み込みはほぼ形状を保持し、局所的なテクスチャを歪める可能性があります。さまざまなコンピュータビジョンタスクでは成功しますが、ディープニューラルネットワークは、テクスチャスタイルの変化や人間が頑強な小さな摂動に対して脆弱であることが示されています。 PACSのスケッチドメインとImageNet-Sketchに一般化するシナリオでは、私たちの方法は最先端の方法を大幅に上回っています。 
[概要]たとえば、ランダムな畳み込みは、同様のグローバル形状でランダムなローカルテクスチャを持つ無数の新しいドメインを作成します。この方法は、ドメイン一般化ベンチマークのパフォーマンスを一貫して向上させ、imagenetにスケーラブルです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-25">
        <br><font color="black">2020-07-25</font>
      </time>
    </span>
</section>
<!-- paper0: Discovering Parametric Activation Functions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_17.html">
      <font color="black">Discovering Parametric Activation Functions</font>
    </a>
  </h2>
  <font color="black">ただし、新しい活性化関数の利点は一貫性がなく、タスクに依存しているため、正規化線形ユニット（ReLU）が依然として最も一般的に使用されています。CIFAR-100画像分類データセットで3つの異なるニューラルネットワークアーキテクチャを使用した実験では、アプローチは効果的です。さまざまなアーキテクチャの一般的なアクティベーション機能と特殊な機能の両方を検出し、ReLUやその他の最近提案されたアクティベーション機能よりも大幅に精度を一貫して向上させます。 
[ABSTRACT]進化的検索は、関数の一般的な形式を検出するために使用されます。さまざまなアーキテクチャの一般的なアクティブ化関数と特殊な関数の両方を検出します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-05">
        <br><font color="black">2020-06-05</font>
      </time>
    </span>
</section>
<!-- paper0: General Purpose (GenP) Bioimage Ensemble of Handcrafted and Learned
  Features with Data Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_18.html">
      <font color="black">General Purpose (GenP) Bioimage Ensemble of Handcrafted and Learned
  Features with Data Augmentation</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、さまざまなバイオイメージ分類問題のセットで評価されます。各手作り記述子は、異なるサポートベクターマシン（SVM）をトレーニングするために使用され、異なるSVMはCNNのアンサンブルと組み合わされます。この作業では、ローカル機能、高密度サンプリング機能、および深層学習アプローチを組み合わせることでパフォーマンスを向上させる新しい汎用（GenP）アンサンブル。 
[概要]提案されたgenpバイオイメージアンサンブルは、ローカル機能、高密度サンプリング機能、ディープラーニングアプローチを組み合わせることでパフォーマンスを向上させます。新しいgenpバイオイメージパフォーマンスは、異なるサポートマシンのトレーニングに使用でき、異なるsvmはのアンサンブルと組み合わされます。 cnns</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-17">
        <br><font color="black">2019-04-17</font>
      </time>
    </span>
</section>
<!-- paper0: Downscaling Attacks: What You See is Not What You Get -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_19.html">
      <font color="black">Downscaling Attacks: What You See is Not What You Get</font>
    </a>
  </h2>
  <font color="black">これらの攻撃と防御は、機械学習における入力サニタイズの役割を確立するのに役立ちます。マシンビジョンスケールと他のスケールで画像が完全に異なるように画像を作成できることを示します。画像のサイズ変更（通常はコンピュータビジョンシステムの前処理に必要な部分は、攻撃に対して脆弱です。 
[概要]これらの攻撃と防御は、機械学習における入力サニタイズの役割を確立するのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Visualizing Color-wise Saliency of Black-Box Image Classification Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_20.html">
      <font color="black">Visualizing Color-wise Saliency of Black-Box Image Classification Models</font>
    </a>
  </h2>
  <font color="black">MC-RISEを実装し、2つのデータセット（GTSRBとImageNet）を使用して評価し、画像分類結果を解釈するための既存の手法と比較した方法の有効性を示します。MC-RISE（Multi-Color RISE）を提案します。説明で色情報を考慮に入れるためのRISEの拡張。私たちの方法は、元のRISEのように特定の画像の各ピクセルの顕著性を示すだけでなく、各ピクセルの色成分の重要性を示します。色情報を含む顕著性マップは、特に色情報が重要なドメイン（交通標識認識など）で役立ちます。 
[ABSTRACT]ディープラーニングを含む高度な方法は、解釈が難しいことがよくあります。これは、各ピクセルの色部分の重要性を説明する、顕著性マップと呼ばれるヒートマップによる分類結果を説明します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: LETI: Latency Estimation Tool and Investigation of Neural Networks
  inference on Mobile GPU -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_21.html">
      <font color="black">LETI: Latency Estimation Tool and Investigation of Neural Networks
  inference on Mobile GPU</font>
    </a>
  </h2>
  <font color="black">必要な実験はわずかです。LETIはニューラルアーキテクチャの検索や大規模なレイテンシ評価に役立つツールであると考えています。この作業では、モバイルGPUでのレイテンシ近似をデータおよびハードウェア固有の問題と見なします。 
[ABSTRACT]研究コミュニティは、モバイルcpuの結論を最終的に予測するために、遅延計算にすべての可能なレイヤーのルックアップテーブルを使用します。主な目標は、ニューラルネットワークの可能性を調査（leti）するための便利な遅延推定ツールを構築することです。プロジェクトはgithubで入手できます。 com</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: MetaDetect: Uncertainty Quantification and Prediction Quality Estimates
  for Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_22.html">
      <font color="black">MetaDetect: Uncertainty Quantification and Prediction Quality Estimates
  for Object Detection</font>
    </a>
  </h2>
  <font color="black">メタ分類では、最大98.92％の分類精度と最大99.93％のAUROCが得られます。これらの結果は、他のネットワークのオブジェクト性スコアや他のベースラインアプローチと比較して大幅な改善をもたらします。したがって、より信頼性の高い不確実性と品質の推定値が得られます。グラウンドトゥルースがない場合は特に興味深い。 
[概要]予測の信頼性、したがって信頼できる不確実性が最も重要です。これらの推定値は、構造化データセットの形式で一連の透過的なメトリックを入力として受け取る後処理モデルによって学習されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-04">
        <br><font color="black">2020-10-04</font>
      </time>
    </span>
</section>
<!-- paper0: Unfolding the Alternating Optimization for Blind Super Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_23.html">
      <font color="black">Unfolding the Alternating Optimization for Blind Super Resolution</font>
    </a>
  </h2>
  <font color="black">このように、\ textit {Estimator}は、LR画像とSR画像の両方からの情報を利用して、ブラーカーネルの推定を容易にします。合成データセットと実世界の画像に関する広範な実験により、モデルが現状を大幅に上回ることができることが示されています。 -芸術的な方法で、はるかに高速で視覚的に好ましい結果を生成します。ソースコードはhttps://github.com/greatlog/DAN.gitで入手できます。 
[概要] 2ステップのソリューションには、2つの独立してトレーニングされたモデルが含まれますが、これらは互いに十分に互換性がない可能性があります。最初のステップでは、lr画像からの限られた情報しか利用できないため、高精度のぼやけたモデルを予測することは困難です。これら2つの畳み込みモデル低解像度の解像度を含むニューラルモジュールは、推定されたostrollableモデルに置き換えることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Iterative Methods for Computing Eigenvectors of Nonlinear Operators -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_24.html">
      <font color="black">Iterative Methods for Computing Eigenvectors of Nonlinear Operators</font>
    </a>
  </h2>
  <font color="black">最後に、結果を数値的に評価する方法と、古典的なアルゴリズムと深いネットワークに基づくアルゴリズムの両方の非線形デノイザーの事前情報に関連するいくつかの例と洞察を示します。この章では、非線形固有値問題を解くためのいくつかの反復法を検討します。 ..解く正規固有問題は$ T（u）= \ lambda u $です。ここで、$ T：\ R ^ n \ to \ R ^ n $はいくつかの有界非線形演算子です。 
[概要]これらは変分画像で発生します-処理、グラフ分割、分類。固有値問題の他の変種についても説明します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: COVIDomaly: A Deep Convolutional Autoencoder Approach for Detecting
  Early Cases of COVID-19 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_25.html">
      <font color="black">COVIDomaly: A Deep Convolutional Autoencoder Approach for Detecting
  Early Cases of COVID-19</font>
    </a>
  </h2>
  <font color="black">2020年9月の時点で、COVID-19のパンデミックは、世界の人々の健康と福祉を荒廃させ続けています。このパンデミックは、目に見えない病気の治療だけでなく、保健機関の緊急時の準備について深刻な問題を提起しました。また、その初期症状を特定する際にも.. 3回の相互検証を実行した後、2つの設定でそれぞれ0.7652と0.6902のプールされたROC-AUCを取得します。 
[概要] 3,300万件以上の確定症例と100万人以上の死亡があります。パンデミックは、パンデミックを完全に封じ込めるにはまだ長い道のりです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: The 1st Tiny Object Detection Challenge:Methods and Results -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_26.html">
      <font color="black">The 1st Tiny Object Detection Challenge:Methods and Results</font>
    </a>
  </h2>
  <font color="black">第1回小さな物体検出（TOD）チャレンジは、現在、小さな人物の検出に焦点を当てて、広い視野を持つ画像内の小さな物体を検出するための斬新で正確な方法を開発する研究を奨励することを目的としています。上位3つの方法の簡単な紹介を含む最初のTODチャレンジ。TODチャレンジに関心のある研究者のために提出リーダーボードが再開されます。ベンチマークデータセットおよびその他の情報は、https：//github.com/ucas-vgにあります。 / TinyBenchmark。 
[ABSTRACT] tinypersonデータセットがtodチャレンジに使用され、公開されました。世界中から約36の参加チームが最初のtodチャレンジに参加しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Vec2Instance: Parameterization for Deep Instance Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_27.html">
      <font color="black">Vec2Instance: Parameterization for Deep Instance Segmentation</font>
    </a>
  </h2>
  <font color="black">さらに、衛星画像から建物のフットプリントを抽出するための新しい方法の有用性を示します。私たちのアプローチの合計ピクセル単位の精度は89 \％であり、最先端のマスクRCNN（91 \％）..深層学習の現在の進歩は、オブジェクト分類、ローカリゼーション、セマンティックセグメンテーション、インスタンスセグメンテーションなどのコンピュータービジョンタスクにおける人間レベルの精度につながっています。 
[ABSTRACT] vec2instanceは、新しいディープパラトロールニューラルネットワークアーキテクチャです。たとえば、セグメンテーションなどのvec2instanceは、衛星画像で使用できます。この調査で開発されたコードは、vec2instancegithubリポジトリで入手できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Arbitrary Style Transfer using Graph Instance Normalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_28.html">
      <font color="black">Arbitrary Style Transfer using Graph Instance Normalization</font>
    </a>
  </h2>
  <font color="black">ただし、各インスタンスの特徴統計を計算すると、特徴間の固有の関係が無視されるため、個々のトレーニングデータセットに適合しながらグローバルスタイルを学習することは困難です。このアルゴリズムは、間で共有される同様の情報を考慮に入れることで、スタイル転送アプローチをより堅牢にします。インスタンス..さらに、この単純なモジュールは、画像から画像への変換やドメイン適応などの他のタスクにも適用できます。 
[ABSTRACT]アダプティブインスタンス正規化（adain）は、ソース画像を白くし、ターゲット画像の関係を適用します。ただし、特徴の平均と変動を正規化するためにも使用されます。単純なモジュールは、画像などの他のタスクにも魅力的です。 to-スタイルの翻訳またはドメインの適応</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: ASDN: A Deep Convolutional Network for Arbitrary Scale Image
  Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_29.html">
      <font color="black">ASDN: A Deep Convolutional Network for Arbitrary Scale Image
  Super-Resolution</font>
    </a>
  </h2>
  <font color="black">小規模（1〜2）のSRの場合、画像は、事前に計算されたラプラシアンピラミッドレベルのスパースセットからの補間によって構築されます。任意のスケールSRのより計算効率の高いモデルを取得するために、このペーパーではラプラシアンピラミッド法を使用して再構築します。ラプラシアン周波数表現の高周波画像の詳細を使用した任意のスケールの高解像度（HR）画像。深い畳み込みニューラルネットワークにより、SuperResolution（SR）のピーク信号対雑音比が大幅に改善されました。 
[ABSTRACT]完全な比較のために、さまざまなベンチマークを使用して、固定スケールおよび任意のスケールの実験が実行されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Compressing Deep Convolutional Neural Networks by Stacking
  Low-dimensional Binary Convolution Filters -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_30.html">
      <font color="black">Compressing Deep Convolutional Neural Networks by Stacking
  Low-dimensional Binary Convolution Filters</font>
    </a>
  </h2>
  <font color="black">この制限に対処するために、低次元のバイナリ畳み込みフィルターを積み重ねることによってディープCNNモデルを圧縮する新しい方法を提案します。実験結果は、提案した方法が同等の精度を維持しながら、既存の方法よりもはるかに高い圧縮率を達成することを示しました。低次元のバイナリ畳み込みフィルターの数は、特定の畳み込み層のすべてのフィルターで共有されます。 
[ABSTRACT]ディープcnnモデルは、メモリに制約のあるデバイスで使用できます。ただし、既存のバイナリモデルの圧縮率は32低下します。提案された方法は、分割畳み込みフィルターを使用して効率的にトレーニングできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: PCAL: A Privacy-preserving Intelligent Credit Risk Modeling Framework
  Based on Adversarial Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_31.html">
      <font color="black">PCAL: A Privacy-preserving Intelligent Credit Risk Modeling Framework
  Based on Adversarial Learning</font>
    </a>
  </h2>
  <font color="black">PCALは、プライバシーリスクの損失とユーティリティ指向の損失を（繰り返し）比較検討することにより、ターゲット予測タスクのパフォーマンスに重要なユーティリティ情報を維持しながら、元のデータセット内の個人情報をマスクすることを目的としています。ユーティリティとプライバシー保護の両方の観点からのシェルフオプション。結果は、PCALがユーザーデータから効果的でプライバシーのない表現を学習できることを示しており、信用リスク分析のためのプライバシー保護マシン学習に向けた強固な基盤を提供します。 
[概要]この論文は、プライバシーのフレームワークを提案しています-敵対的学習（pcal）に基づく信用リスクモデリングの節約。プライバシー保護を含む、データデータデータの安全性の懸念に対処することを目的としています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Explaining image classifiers by removing input features using generative
  models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_32.html">
      <font color="black">Explaining image classifiers by removing input features using generative
  models</font>
    </a>
  </h2>
  <font color="black">私たちの調査結果は、ImageNetデータセットとPlaces365データセットの両方、および分類子とインペインターの2つの異なるペアで一貫していました。提案された変更により、（1）真のデータ分布の下でより妥当な反事実サンプルを生成する3つの方法すべてが改善されました。 （2）オブジェクトのローカリゼーション、削除、および顕著性のメトリックの3つのメトリックに従ってより正確になります。 （3）ハイパーパラメータの変更に対してより堅牢です。代わりに、生成インペインタを3つの代表的なアトリビューションメソッドに統合して、入力機能を削除することを提案します。 
[概要]提案された変更により、3つの方法すべてが改善され、反事実的なサンプルが作成されました。これらには、ぼかし、ノイズの追加、またはグレーアウトが含まれ、非現実的なアウトサンプルが生成されることがよくあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-09">
        <br><font color="black">2019-10-09</font>
      </time>
    </span>
</section>
<!-- paper0: MoVie: Revisiting Modulated Convolutions for Visual Counting and Beyond -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_33.html">
      <font color="black">MoVie: Revisiting Modulated Convolutions for Visual Counting and Beyond</font>
    </a>
  </h2>
  <font color="black">最後に、MoVieなどの変調された畳み込みが、カウントを超えてタスクを推論するための一般的なメカニズムとして機能できるという証拠を示します。特に、MoVieは暗黙的かつ全体的に推論し、推論中に1回のフォワードパスのみが必要です。質問またはカテゴリ）。 
[ABSTRACT] prior-一般的なオブジェクトを数えるためのココのような難しいベンチマークの技術。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-24">
        <br><font color="black">2020-04-24</font>
      </time>
    </span>
</section>
<!-- paper0: NCP-VAE: Variational Autoencoders with Noise Contrastive Priors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_34.html">
      <font color="black">NCP-VAE: Variational Autoencoders with Noise Contrastive Priors</font>
    </a>
  </h2>
  <font color="black">ノイズコントラスト推定によって再重み付け係数をトレーニングし、それを多くの潜在変数グループを持つ階層VAEに一般化します。ただし、特にサンプルが事前確率からテンパリングなしで取得された場合、高品質の画像を生成するのに苦労します。この問題では、ベースの事前分布と再重み付け係数の積によって定義されるエネルギーベースの事前分布を提案します。これは、ベースを集合体の後方に近づけるように設計されています。 
[ABSTRACT]事前分布の下で高密度の潜在空間内の領域は、エンコードされた画像に対応しません。提案されたノイズの対照的な事前分布は、最先端技術の全体的なパフォーマンスを大幅に改善します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Perceptual Deep Neural Networks: Adversarial Robustness through Input
  Recreation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_35.html">
      <font color="black">Perceptual Deep Neural Networks: Adversarial Robustness through Input
  Recreation</font>
    </a>
  </h2>
  <font color="black">概念は数学的に形式化され、2つのバリエーションが開発されます（1つは画像全体の修復に基づいており、もう1つはノイズの多いサイズ変更された超解像レクリエーションに基づいています）。したがって、$ \ varphi $ DNNは、入力レクリエーションが人工に大きな利点があることを示しています生物学的ネットワークと同様のニューラルネットワークは、入力を意図的に破壊することの重要性に光を当てるだけでなく、人工知能での堅牢な認識のためにGANとオートエンコーダに基づく知覚モデルの領域を開拓します。修復に基づく$ \ varphi $ DNNが示されています。同様の低い攻撃精度を維持しながら、より大きな画像サイズに適切にスケーリングする。一方、最先端技術は最大3倍悪化します。 
[ABSTRACT]人間の知覚も、網膜に到達する信号が表示されないため、機械とは根本的に異なります。さらに処理する前に独自の入力を再作成する知覚ディープニューラルネットワーク（$ varphi $ dnn）を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Saliency is a Possible Red Herring When Diagnosing Poor Generalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_36.html">
      <font color="black">Saliency is a Possible Red Herring When Diagnosing Poor Generalization</font>
    </a>
  </h2>
  <font color="black">驚くべきことに、これらの方法は共変量シフトの存在下で一般化パフォーマンスを改善しますが、人間の専門家が重要とラベル付けした特徴に対する顕著性の修正と一般化パフォーマンスの間に強い対応はありません。これが正しいかどうかを調査します。結果は、不十分な一般化の根本原因が常に空間的に定義されているとは限らないことを示唆しており、「帰属の優先順位」としてのマスクの有用性、および説明可能な予測の顕著性について疑問を投げかけています。 
[概要]これは顕著性マップを使用して視覚的に診断できるとよく考えられます。人間の専門家のマスクを使用した画像は、予測を行うための関連情報を含む画像の領域を示すことができます。これらの結果は、一般化不良の根本原因がそうではない可能性があることを示唆しています。常に空間的に定義される</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-01">
        <br><font color="black">2019-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: A Method for Tumor Treating Fields Fast Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_37.html">
      <font color="black">A Method for Tumor Treating Fields Fast Estimation</font>
    </a>
  </h2>
  <font color="black">腫瘍治療フィールド（TTFields）は、特定の種類の癌に対するFDA承認の治療法であり、患者の寿命を大幅に延ばします。これらの結果は、いくつかのパラメーターに基づくTTFieldsの高速推定が可能であることを示唆しています。ただし、これらの計算は通常、有限要素法を使用して実行されます。時間がかかる要素法または同様のアプローチ。 
[概要]腫瘍内のttfieldの強度は、治療結果と関連していました。これには、強度が大きいほど、患者が生き残る可能性が高くなることが含まれます。この方法では、シミュレーションフレームワークでttfieldを複数回計算する必要があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Denoising Diffusion Implicit Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_38.html">
      <font color="black">Denoising Diffusion Implicit Models</font>
    </a>
  </h2>
  <font color="black">ノイズ除去拡散確率モデル（DDPM）は、敵対的なトレーニングなしで高品質の画像生成を実現しましたが、サンプルを生成するために多くのステップでマルコフ連鎖をシミュレートする必要があります。 DDPMと比較して実時間の点で倍$速く、計算とサンプル品質のトレードオフを可能にし、潜在空間で直接意味のある画像補間を実行できます。マルコフ以外の拡散プロセスのクラスを構築します。同じトレーニング目標に対応しますが、その逆のプロセスをサンプリングする方がはるかに高速です。 
[ABSTRACT] ddpmsは、反復pimpediaiaiaiaiaiaiaiaiaiaiaiaiaiaiaiaiaのクラスであり、テストまでたどることができます。msnbc222222222222222のクラスを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Collaboratively boosting data-driven deep learning and knowledge-guided
  ontological reasoning for semantic segmentation of remote sensing imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_39.html">
      <font color="black">Collaboratively boosting data-driven deep learning and knowledge-guided
  ontological reasoning for semantic segmentation of remote sensing imagery</font>
    </a>
  </h2>
  <font color="black">DSSNの前述の重大な制限を改善するために、このペーパーでは、データ駆動型深層学習モジュールと知識誘導型オントロジー推論モジュールを反復的に組み合わせるための協調的ブースティングフレームワーク（CBF）を提案します。対照的に、人間は優れた推論能力を備えています。人間が基本的なRSドメインの知識を習得した場合にのみ、RS画像を確実に解釈できます。文献では、オントロジーモデリングと推論は、人間のドメイン知識を模倣して使用するための理想的な方法ですが、それでもほとんど調査されておらず、 RSドメインで採用。 
[概要] dataf手法として、dssnはエンドツーエンドメカニズムでトレーニングできます。低レベルと中レベルのキューを使用して画像を理解することはできますが、高レベルの可能性はありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: AutoHAS: Efficient Hyperparameter and Architecture Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_40.html">
      <font color="black">AutoHAS: Efficient Hyperparameter and Architecture Search</font>
    </a>
  </h2>
  <font color="black">実験結果によると、AutoHASは、高度に最適化された最先端のResNet / EfficientNetモデルで最大0.8％、最適化されていないモデルで最大11％ImageNetの精度を向上させることができます。このような一般化における重要な課題は次のとおりです。 ENASとDARTSは、個別のアーキテクチャの選択を最適化するように設計されていますが、ハイパーパラメータの選択は連続的であることがよくあります。AutoHASは、効率的なアーキテクチャ検索、ENASとDARTSの概念をハイパーパラメータ検索に一般化するため、単一のトレーニングで両方を共同で最適化できます。 
[ABSTRACT] autohasは、効率的なアーキテクチャ検索、enas、dartsの概念をハイパーパラメータ検索に一般化するため、1回のトレーニングで両方を共同で最適化できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-05">
        <br><font color="black">2020-06-05</font>
      </time>
    </span>
</section>
<!-- paper0: Representation learning from videos in-the-wild: An object-centric
  approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_41.html">
      <font color="black">Representation learning from videos in-the-wild: An object-centric
  approach</font>
    </a>
  </h2>
  <font color="black">特に、18/19のすべての数ショット学習タスクと8/8の既成の一般化タスクでベースラインを上回ります。最後に、いくつかのアブレーションスタディを実行し、事前トレーニングされたオブジェクト検出器がパフォーマンスに与える影響を分析します。この一連のタスク全体で..既成のオブジェクト検出器からの監視あり損失と、各ビデオに存在するビデオショットフレームオブジェクト階層から自然に発生する自己監視損失を組み合わせます。 
[概要]ビデオからの教師あり損失-ショット-フレーム-オブジェクト階層を組み合わせます。また、18/19のいくつかのショット学習タスクすべてでベースラインを上回ります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Universal Domain Adaptation through Self Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_42.html">
      <font color="black">Universal Domain Adaptation through Self Supervision</font>
    </a>
  </h2>
  <font color="black">DANCEは、2つの斬新なアイデアを組み合わせています。まず、ターゲットを区別する特徴を学習するためにソースカテゴリに完全に依存することはできないため、自己監視方式でターゲットドメインの構造を学習するための新しい近隣クラスタリング手法を提案します。従来、メソッドはすべてのソースカテゴリがターゲットドメインに存在することを前提としています。次に、エントロピーベースの特徴の位置合わせと拒否を使用して、ターゲットの特徴をソースに位置合わせするか、エントロピーに基づいて未知のカテゴリとして拒否します。 
[概要]ドメイン適応型近隣クラスタリングと呼ばれる、任意のカテゴリシフトを処理できる新しいドメイン適応型フレームワークを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br><font color="black">2020-02-19</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Reinforcement Learning with Mixed Convolutional Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_43.html">
      <font color="black">Deep Reinforcement Learning with Mixed Convolutional Network</font>
    </a>
  </h2>
  <font color="black">データセットは、ジムで手動でゲームをプレイすることによって生成され、データ拡張方法を使用してデータセットを以前の4倍に拡張します。トレーニング後、このモデルは道路の特徴の境界を自動的に検出し、人間のようにロボットを駆動できます。また、各画像の真の速度、4つのABSセンサー、ステアリングホイールの位置、ジャイロスコープを読み取り、センサー入力と画像入力を組み合わせて混合モデルを設計しました。 
[概要] openaiジムで模倣学習を使用してcarracing-v0を再生します。新しいモデルは、システム全体の最大パフォーマンスを獲得します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-01">
        <br><font color="black">2020-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal brain tumor classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_44.html">
      <font color="black">Multimodal brain tumor classification</font>
    </a>
  </h2>
  <font color="black">実験は、2020年のComputational Precision Medicineチャレンジで、3クラスの不均衡な分類タスクで前向きに実施されます。相互検証を報告します（それぞれ0.91、0.90、0.94）。 
[概要]放射線画像は、がん診断の有効性についてより多くの知識をもたらすはずです。それらには、スライド画像全体の強力で一般的なモジュール式の学習方法が含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Fast and Differentiable Message Passing on Pairwise Markov Random Fields -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_45.html">
      <font color="black">Fast and Differentiable Message Passing on Pairwise Markov Random Fields</font>
    </a>
  </h2>
  <font color="black">この作業では、2つの高速で微分可能なメッセージパッシングアルゴリズム、つまり、反復セミグローバルマッチングリビジョン（ISGMR）と並列ツリー再重み付けメッセージパッシング（TRWP）を紹介します。これらは、大規模な並列処理を利用することでGPU上で大幅に高速化されます。 、当社のCUDA実装はPyTorchGPU実装よりもそれぞれ少なくとも$ 7 $および$ 700 $倍高速であり、メッセージパッシングによる効率的なエンドツーエンド学習を可能にします。具体的には、ISGMRは標準の反復および改訂バージョンです。最適化の有効性が向上した一般的なペアワイズMRF用のSGM。TRWPは、最適化を高速化するためのシーケンシャルTRW（TRWS）の高度な並列バージョンです。 
[ABSTRACT] mrfは、一般的なペアワイズmruの標準sgmのアップグレードです。mrfは、パーティとmrf全体の手作りバージョンです。これは、差別化と差別化のためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br><font color="black">2019-10-24</font>
      </time>
    </span>
</section>
<!-- paper0: autoTICI: Automatic Brain Tissue Reperfusion Scoring on 2D DSA Images of
  Acute Ischemic Stroke Patients -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_46.html">
      <font color="black">autoTICI: Automatic Brain Tissue Reperfusion Scoring on 2D DSA Images of
  Acute Ischemic Stroke Patients</font>
    </a>
  </h2>
  <font color="black">既存のTICIスコアは、目視検査に基づいて粗い序数グレードで定義され、観察者間および観察者内の変動につながります。AUCスコアは二分されたeTICIに関して0.90です。ネットワークには、シーケンスレベルのラベル依存関係も組み込まれています。状態遷移行列。 
[概要]この作業では、自動および定量的なticiスコアリング方法であるautoticiを紹介します。これは血管内治療後の技術的アウトカム指標として使用されます（evt）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-03">
        <br><font color="black">2020-10-03</font>
      </time>
    </span>
</section>
<!-- paper0: Histopathological Stain Transfer using Style Transfer Network with
  Adversarial Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_47.html">
      <font color="black">Histopathological Stain Transfer using Style Transfer Network with
  Adversarial Loss</font>
    </a>
  </h2>
  <font color="black">実験は、このアプローチが良好な視覚品質で染色正規化を正常に実行でき、染色正規化を適用しない場合と比較してより良い推論性能を提供することを示唆しています。この作業では、高速ニューラルスタイル転送と組み合わせた染色正規化問題の新しいアプローチを提示します。敵対的損失..また、高解像度ネットワーク（HRNet）に基づく新しい染色転写ジェネレータネットワークを提案します。これは、トレーニング時間が少なくて済み、参照染色とテスト染色のペアのトレーニング画像がほとんどなく、優れた一般化を実現します。 
[概要]この染色について深層学習モデルをトレーニングしました。残りの画像は、対応する染色転送ジェネレータネットワークを使用して転送されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: How Convolutional Neural Network Architecture Biases Learned Opponency
  and Colour Tuning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_48.html">
      <font color="black">How Convolutional Neural Network Architecture Biases Learned Opponency
  and Colour Tuning</font>
    </a>
  </h2>
  <font color="black">さらに、トレーニングされたCNNの色相感度曲線を取得する方法を開発します。これにより、カラーチューニングデータからの低レベルの結果を補完する高レベルの洞察が可能になります。さまざまな深さとボトルネック幅を持つCNNの範囲に対してこれらの分類を実行します。私たちの重要な発見は、ボトルネックのあるネットワークが強力な機能組織を示していることです。ボトルネック層のほぼすべてのセルが空間的にも色の反対側にもなり、ボトルネックに続く層のセルは非敵対的になります。 
[要約]研究は、ボトルネックのあるネットワークが複雑な非線形カラーシステムを学習することを示しています。ネットワークを使用して、空間的および色の反対性の観点からセルを分類できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: AE-Netv2: Optimization of Image Fusion Efficiency and Network
  Architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_49.html">
      <font color="black">AE-Netv2: Optimization of Image Fusion Efficiency and Network
  Architecture</font>
    </a>
  </h2>
  <font color="black">最後に、さまざまな画像融合タスクの共通性と特性を調査します。これは、画像融合の分野における人間の脳の継続的な学習特性に関するさらなる研究の研究基盤を提供します。次に、画像融合に対するプーリング層の影響を調査します。タスクを実行し、プーリングレイヤーを使用した画像融合方法を提案します。ディープラーニングに基づいてテストされたすべての方法の中で、AE-Netv2はより高速で、モデルサイズが小さく、堅牢性が優れています。 
[概要] ae-netv2は人間の脳の認知メカニズムに基づいています。状態と比較されています-gtx2070で100fpsの速度です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Finding the Evidence: Localization-aware Answer Prediction for Text
  Visual Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_50.html">
      <font color="black">Finding the Evidence: Localization-aware Answer Prediction for Text
  Visual Question Answering</font>
    </a>
  </h2>
  <font color="black">私たちのLaAP-Netは、質問に対する回答を生成するだけでなく、生成された回答の証拠として境界ボックスを予測します。さらに、ローカリゼーションタスクを容易にするために、マルチモーダルフュージョンのコンテキスト強化OCR表現（COR）が提案されます。提案されたLaAP-Netは、テキストVQAタスクの3つのベンチマークデータセットに対する既存のアプローチを大幅に上回っています。 
[要約]テキストベースの視覚的な質問応答（text vqa）タスクは、画像内のテキストを読む必要がある視覚的な質問に焦点を当てています。テキストの位置情報は十分に活用されておらず、生成された回答の証拠が不足しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Equivalent Classification Mapping for Weakly Supervised Temporal Action
  Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_51.html">
      <font color="black">Equivalent Classification Mapping for Weakly Supervised Temporal Action
  Localization</font>
    </a>
  </h2>
  <font color="black">これにより、新しい等価分類マッピング（ECM）メカニズムが実現します。この目的のために、理想的な分類子は両方のパイプラインを機能させることができます。これら2つのパイプラインの分類子は異なる方法で使用されますが、それらが果たす役割はまったく同じです。 -特定の機能を分類して、対応するアクションカテゴリを識別します。 
[概要]以前のメソッドは、分類パイプラインごとに2つのローカリゼーションに分類できます。これらには、分類前パイプラインと分類後パイプラインが含まれます。この目的のために、理想的な分類子は両方のパイプラインを機能させることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-18">
        <br><font color="black">2020-08-18</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Visual-Semantic Embeddings for Reporting Abnormal Findings on
  Chest X-rays -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_52.html">
      <font color="black">Learning Visual-Semantic Embeddings for Reporting Abnormal Findings on
  Chest X-rays</font>
    </a>
  </h2>
  <font color="black">この作業では、放射線画像の異常所見の報告に焦点を当てています。完全な放射線レポートのトレーニングの代わりに、教師なしクラスタリングと最小限のルールでレポートをグループ化することに加えて、レポートから異常な所見を特定する方法を提案します。私たちの方法が異常な所見を取得でき、両方で既存の生成モデルよりも優れていることを示します臨床的正確性とテキスト生成メトリック..タスクをクロスモーダル検索として定式化し、条件付き視覚-セマンティック埋め込みを提案して、画像ときめ細かい異常所見を共同埋め込みスペースに配置します。 
[概要]レポートに関する既存の作業では、エンコーダー-デコーダーネットワークをトレーニングして完全なレポートを生成することがよくあります。完全なレポートをトレーニングする代わりに、レポートから異常な結果を特定する方法を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: SAFENet: Self-Supervised Monocular Depth Estimation with Semantic-Aware
  Feature Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_53.html">
      <font color="black">SAFENet: Self-Supervised Monocular Depth Estimation with Semantic-Aware
  Feature Extraction</font>
    </a>
  </h2>
  <font color="black">私たちの重要なアイデアは、意味知識と幾何学的知識を統合する意味認識深度機能を活用することです。したがって、深さ機能の表現に意味認識を組み込むためのマルチタスク学習スキームを導入します。この論文では、SAFENetを提案します。セマンティック情報を活用して、測光損失の制限を克服するように設計されています。 
[ABSTRACT]測光損失は、入力画像フレームを照合することにより、深度予測の自己監視を提供できます。グラウンドトゥルース深度マップの代わりに、測光損失は自己監視を提供する必要があります。この方法は、さまざまな情報を使用して測光損失の制限を克服する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Microscopic fine-grained instance classification through deep attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_54.html">
      <font color="black">Microscopic fine-grained instance classification through deep attention</font>
    </a>
  </h2>
  <font color="black">限られたサンプルでの顕微鏡画像データのきめ細かい分類は、コンピュータビジョンと生物医学イメージングの未解決の問題です。第2に、グローバルな構造的特徴とローカルインスタンスの特徴が融合されて、最終的な画像レベルの分類が行われます。 -最先端のトレーニング可能なディープネットワークにより、2つの個別のきめ細かいマルチインスタンス生物医学画像分類タスクが実現します。ベンチマーク乳がん組織学データセットと新しい真菌種菌学データセットです。 
[ABSTRACT]ディープラーニングベースのビジョンシステムは、主に多数の低解像度画像を処理します。ブリッジアテンションモジュールは、追加の注釈や領域の提案なしに、高解像度で複数の主要なインスタンスに焦点を当てることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: RANP: Resource Aware Neuron Pruning at Initialization for 3D CNNs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_55.html">
      <font color="black">RANP: Resource Aware Neuron Pruning at Initialization for 3D CNNs</font>
    </a>
  </h2>
  <font color="black">具体的には、損失関数に対する感度に基づいて各ニューロンの重要度スコアを取得することが中心的なアイデアです。ShapeNetおよびBraTS&#39;18でも広く使用されている3D-UNetsを使用して、3Dセマンティックセグメンテーションに対するプルーニング方法の有効性を示します。 UCF101データセットでのMobileNetV2およびI3Dを使用したビデオ分類の場合と同様に、このニューロンの重要性は、FLOPまたはメモリに関連するニューロンリソースの消費量に応じて再重み付けされます。 
[概要]この作業では、初期化時に3d cnnを高スパース性レベルにプルーニングするリソース認識ニューロンプルーニング（ranp）アルゴリズムを紹介します。フロップまたはメモリに基づくニューロンアプリケーションは、アプリのアプリによって再重み付けされます。このニューロンアプリケーション潜在的な潜在的な開発に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Comprehensive Online Network Pruning via Learnable Scaling Factors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_56.html">
      <font color="black">Comprehensive Online Network Pruning via Learnable Scaling Factors</font>
    </a>
  </h2>
  <font color="black">私たちの方法では、ベンチマークデータセットで評価したときに、精度を著しく損なうことなく70％から90％の圧縮率が得られました。ディープニューラルネットワークアーキテクチャを展開する際の主な課題の1つは、推論時間に悪影響を与えるサイズです。メモリ要件..幅方向と深さ方向の両方のプルーニングを実行できる包括的なプルーニング戦略を提案します。 
[ABSTRACT]深いcnnsは、比率に基づいてフィルターを削除することで、幅を剪定できます。つまり、深さ------別のレイヤーやブロックに切り替えることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Probing Text Models for Common Ground with Visual Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_57.html">
      <font color="black">Probing Text Models for Common Ground with Visual Representations</font>
    </a>
  </h2>
  <font color="black">言語と視覚的表現が意図的に一致しない対照実験では、はるかに弱い結果が観察されます。さらに、実験でテキストコンテキストの影響を調べ、たとえば、形容詞を伴う名詞がより正確な検索につながることを発見します。 、私たちの調査結果は、言語の基礎に関する新しい経験的洞察を示し、いくつかの物理的特性が訓練された言語モデルによってキャプチャされていることを示唆し、将来の進歩のための大きな余地を強調しています。 
[要約]私たちの調査結果は、言語の基礎に関する新しい洞察を導き出し、いくつかの物理的特性が訓練された言語モデルによってキャプチャされていることを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: Shot in the Dark: Few-Shot Learning with No Base-Class Labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_58.html">
      <font color="black">Shot in the Dark: Few-Shot Learning with No Base-Class Labels</font>
    </a>
  </h2>
  <font color="black">しかし、それは真空中では行われません。この作業では、そのような誘導バイアスを開発するためにラベルは必要ないこと、および自己教師あり学習が少数ショット学習に強力な誘導バイアスを提供できることを示します。新規クラスのラベルのない例が利用できる場合は、トランスダクティブ設定として知られています。 
[ABSTRACT]誘導バイアスは、新しいクラスのより統計的に効率的な学習を可能にします。これは、そのようなバイアスを学習するためのラベルなしデータに基本クラスの例だけでなく、新しいクラスの例も含まれている場合に特に効果的です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Transferable Recognition-Aware Image Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_59.html">
      <font color="black">Transferable Recognition-Aware Image Processing</font>
    </a>
  </h2>
  <font color="black">私たちの簡単な方法で、強力な転送可能性と最小限の画質損失で大幅な精度の向上を達成できます。コードはhttps://github.com/liuzhuang13/Transferable_RAで入手できます。この作業では、マシンの解釈可能性を改善するための簡単なアプローチを提案します。処理された画像の分析：画像処理ネットワーク上で直接、または中間変換モデルを介して認識損失を最適化します。 
[概要]画像は検索エンジンやレコメンデーションシステムによって不適切に処理される可能性があります。これは望ましくない場合があります。たとえば、画像が誤って解釈されます。データにより、人間が消費する可能性が高くなります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-21">
        <br><font color="black">2019-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Joint COCO and Mapillary Workshop at ICCV 2019: COCO Instance
  Segmentation Challenge Track -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_60.html">
      <font color="black">Joint COCO and Mapillary Workshop at ICCV 2019: COCO Instance
  Segmentation Challenge Track</font>
    </a>
  </h2>
  <font color="black">COCO-2019検出/インスタンスセグメンテーションtest-devデータセットでは、システムは61.0 / 53.1 mAPを達成し、2018年の受賞結果をそれぞれ5.0 /4.2上回っています。COCOチャレンジ2019と2020で最高の結果を達成しています。このレポートでは、オブジェクト検出/インスタンスセグメンテーションシステムであるMegDetV2を紹介します。これは、最初にインスタンスを検出し、次にセグメンテーションを取得するために2パス方式で機能します。 
[概要]ベースラインシステムは、主にrpnと呼ばれる新しい設計のrpnに基づいて構築されています。coco/ 2018で最高の結果を達成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: DeepFakesON-Phys: DeepFakes Detection based on Heart Rate Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CV/paper_61.html">
      <font color="black">DeepFakesON-Phys: DeepFakes Detection based on Heart Rate Estimation</font>
    </a>
  </h2>
  <font color="black">DeepFakesON-Physという名前の提案された偽の検出器は、畳み込み注意ネットワーク（CAN）を使用します。これは、ビデオフレームから空間的および時間的情報を抽出し、両方のソースを分析および組み合わせて、偽のビデオをより適切に検出します。測定..この検出アプローチは、この分野の最新の公開データベースであるCeleb-DFおよびDFDCを使用して実験的に評価されています。 
[ABSTRACT]ディープフェイク動画は心拍数の変化を検出するために使用されます。最新の公開データベースと呼ばれ、これらの動画は検出できます。この方法は実験的に評価されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-01">
        <br><font color="black">2020-10-01</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Automatic Extraction of Rules Governing Morphological Agreement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_0.html">
      <font color="black">Automatic Extraction of Rules Governing Morphological Agreement</font>
    </a>
  </h2>
  <font color="black">対象言語に専門家の注釈がなくても、クロスリンガル転送を使用して、フレームワークは、大量のゴールドスタンダードの注釈付きデータで作成されたものとほぼ同等の文法仕様を抽出します。フレームワークは、に含まれるすべての言語に適用されます。 Universal Dependenciesプロジェクトは、有望な結果をもたらします。私たちは、世界の多くの言語の文法の中核にある形態統語論的現象である合意を記述するルールの抽出に焦点を当てています。 
[要約]文法規則を抽出するための言語間転送の使用。これは、金を見つけることと同等です-標準の注釈付きデータ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-02">
        <br><font color="black">2020-10-02</font>
      </time>
    </span>
</section>
<!-- paper0: SlotRefine: A Fast Non-Autoregressive Model for Joint Intent Detection
  and Slot Filling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_1.html">
      <font color="black">SlotRefine: A Fast Non-Autoregressive Model for Joint Intent Detection
  and Slot Filling</font>
    </a>
  </h2>
  <font color="black">さらに、非自己回帰モデルの条件付き独立性によって引き起こされる非協調スロット問題を処理するための新しい2パス反復メカニズムを設計します。詳細な分析により、1）事前トレーニングスキームによってモデルがさらに強化される可能性があります。 2）2パスメカニズムは、実際に調整されていないスロットを修正します。スロットの充填と意図の検出は、音声言語理解（SLU）システムの2つの主要なタスクです。 
[概要]私たちのモデルは、デコードを高速化しながら、スロット充填タスクで以前のモデルを大幅に上回っています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-View Attention Networks for Visual Dialog -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_2.html">
      <font color="black">Multi-View Attention Networks for Visual Dialog</font>
    </a>
  </h2>
  <font color="black">具体的には、エージェントは1）質問の意味的意図を決定し、2）異種のモダリティ入力間で質問関連のテキストおよび視覚的コンテンツを調整する必要があります。視覚的対話は、一連の質問を視覚的に行う挑戦的な視覚言語タスクです。 VisDial v1.0データセットの実験結果は、提案されたモデルの有効性を示しています。これは、すべての評価指標に関して、以前の最先端の方法を上回っています。 
[概要]本稿では、マルチビュー注意質問質問質問、質問、ダイアログ履歴、画像を提案します。ビジュアルダイアログの特定の特定の質問を理解する必要があります。プラス、さまざまなタイプの主題の高レベルの理解提案されたモデルは、すべての評価指標に関して、以前の最先端の方法よりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br><font color="black">2020-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: Swiss Parliaments Corpus, an Automatically Aligned Swiss German Speech
  to Standard German Text Corpus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_3.html">
      <font color="black">Swiss Parliaments Corpus, an Automatically Aligned Swiss German Speech
  to Standard German Text Corpus</font>
    </a>
  </h2>
  <font color="black">生データの65％をセンテンスレベルのオーディオテキストペアに変換すると、293時間のトレーニングデータが得られます。手動アライメントと比較すると、平均IoUは0.8401、センテンスリコールは0.9491です。この手順では、スイス議会コーパスを作成しました。これは、スイスドイツ語のスピーチを標準ドイツ語テキストコーパスに自動的に揃えたものです。 
[要約]平均iouは0.9271にさらに改善できますが、文のリコールが0になります。生データの4881.65％が文レベルの音声テキストのペアに変換され、293時間のトレーニングが行われます。データ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Please Mind the Root: Decoding Arborescences for Dependency Parsing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_4.html">
      <font color="black">Please Mind the Root: Decoding Arborescences for Dependency Parsing</font>
    </a>
  </h2>
  <font color="black">Universal Dependency Treebankからの多くの言語での最先端のパーサーの出力を分析しました。これらのパーサーは、制約に違反するツリーには低い確率を割り当てる必要があることを学習できますが、当然のことながらそうする能力はありません。トレーニングセットのサイズが小さくなるにつれてグレードが上がります。実際、私たちが観察する最悪の制約違反率は24％です。以前の研究では、制約を適用するための非効率的なアルゴリズムが提案されており、デコードランタイムにnの係数が追加されます。 Gabow and Tarjan（1984）によるアルゴリズムを依存関係の解析に適合させます。これにより、元のランタイムを損なうことなく制約が満たされます。 
[ABSTRACT]以前の作業では、制約を適用するための非効率的なアルゴリズムが提案されていました。これにより、デコードランタイムに係数nが追加されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Keep CALM and Explore: Language Models for Action Generation in
  Text-based Games -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_5.html">
      <font color="black">Keep CALM and Explore: Language Models for Action Generation in
  Text-based Games</font>
    </a>
  </h2>
  <font color="black">驚いたことに、これらのゲームの半分で、CALMは、グラウンドトゥルースの許容可能なアクションにアクセスできる他のモデルと競合するか、それよりも優れています。私たちの方法では、以前の最先端モデルよりも平均ゲームスコアが69％向上しています。 ..コードとデータはhttps://github.com/princeton-nlp/calm-textgameで入手できます。 
[ABSTRACT]モーション言語モデル（calm）は、各ゲーム状態でアクション候補のコンパクトなセットを生成することです。この方法では、平均ゲームスコアが69％向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Second-Order NLP Adversarial Examples -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_6.html">
      <font color="black">Second-Order NLP Adversarial Examples</font>
    </a>
  </h2>
  <font color="black">私たちの調査結果は、そのような2次の例が存在することを示していますが、通常、最先端のモデルの1次の敵対的な例よりも一般的ではありません。NLPの敵対的な例の生成方法は、言語モデルや文エンコーダーなどのモデルに依存して決定します。潜在的な敵対的な例が有効である場合..これらの敵対的な例は、攻撃されたモデルの欠陥ではなく、有効性を決定するモデルの欠陥である可能性があると主張します。 
[要約]これらの敵対的な例は、攻撃されたモデルの欠陥ではなく、妥当性を決定するモデルのエラーである可能性があると主張します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Filtering Noisy Dialogue Corpora by Connectivity and Content Relatedness -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_7.html">
      <font color="black">Filtering Noisy Dialogue Corpora by Connectivity and Content Relatedness</font>
    </a>
  </h2>
  <font color="black">提案手法でフィルタリングしたトレーニングデータが応答生成における神経対話エージェントの品質を向上させることを実験的に確認した。本論文では、接続性と関連性の観点から発話ペアの品質をスコアリングする方法を提案する。それは、対話の質に関する人間の判断と比較的良好な相関関係があります。 
[ABSTRACT]データセットに無視できない数が含まれていることが報告されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br><font color="black">2020-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: An Empirical Study of Tokenization Strategies for Various Korean NLP
  Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_8.html">
      <font color="black">An Empirical Study of Tokenization Strategies for Various Korean NLP
  Tasks</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、「韓国のNLPタスクに最適なトークン化戦略は何ですか？」という主要なリサーチクエスチョンに答えるために、いくつかのトークン化戦略をテストします。実験結果は、形態学的セグメンテーションとそれに続くBPEのハイブリッドアプローチが、韓国語から英語への機械翻訳、およびKorNLI、KorSTS、NSMC、PAWS-Xなどの自然言語理解タスクで最適に機能することを示しています。例外として、KorQuADの場合、 SQuADの韓国語拡張であるBPEセグメンテーションが最も効果的であることがわかりました。 
[ABSTRACT]トークンを定義するタイミングは、モデルのパフォーマンスにおいて決定的な役割を果たします。トークンは、テキストのコンテキスト情報を埋め込むアトミックユニットとして機能します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic Semantic Matching and Aggregation Network for Few-shot Intent
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_9.html">
      <font color="black">Dynamic Semantic Matching and Aggregation Network for Few-shot Intent
  Detection</font>
    </a>
  </h2>
  <font color="black">利用可能な注釈付き発話が不足しているため、少数ショットの意図検出は困難です。コードとデータは公開されています。また、すべてのクラスの共同ラベルスペースでの分類を考慮した、より困難な評価設定を提案します。 
[ABSTRACT]私たちの方法は、ラベル付きインスタンスとラベルなしインスタンスの両方の表現を強化するための包括的なマッチング測定を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Attention is Not Only a Weight: Analyzing Transformers with Vector Norms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_10.html">
      <font color="black">Attention is Not Only a Weight: Analyzing Transformers with Vector Norms</font>
    </a>
  </h2>
  <font color="black">これらの調査結果は、トランスフォーマーの内部動作への洞察を提供します。BERTおよびトランスフォーマーベースのニューラル機械翻訳システムの標準ベースの分析の調査結果には、次のものが含まれます。（i）以前の研究とは異なり、BERTは特別なトークンにあまり注意を払っていません。 、および（ii）Transformerの注意メカニズムから合理的な単語の配置を抽出できます。この論文は、注意の重みだけが注意の出力を決定する2つの要因の1つにすぎないことを示し、2番目の要因を組み込んだ規範ベースの分析を提案します。 、変換された入力ベクトルのノルム。 
[要約]トランスフォーマーの主要な言語能力を調査するために、注意が広く研究されています。私たちの規範の発見-バートとトランスフォーマーに基づく分析-ベースのニューラル機械翻訳システム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br><font color="black">2020-04-21</font>
      </time>
    </span>
</section>
<!-- paper0: Does the Objective Matter? Comparing Training Objectives for Pronoun
  Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_11.html">
      <font color="black">Does the Objective Matter? Comparing Training Objectives for Pronoun
  Resolution</font>
    </a>
  </h2>
  <font color="black">この作業では、目的の4つのカテゴリを表す4つのモデルのパフォーマンスとシードごとの安定性を公正に比較します。実験では、シーケンスランキングの目的がドメイン内で最高のパフォーマンスを発揮し、セマンティックの目的は候補と代名詞の間の類似性は、ドメイン外で最高のパフォーマンスを発揮します。また、シーケンスランキングを使用して、モデルのシードごとの不安定性を観察します。これは、他の目的が使用されている場合には当てはまりません。 
[ABSTRACT]これらの作業で使用されるテストデータセットと事前にトレーニングされた言語モデルにより、トレーニングの目的の選択が重要かどうかが不明確になります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: CoRefi: A Crowd Sourcing Suite for Coreference Annotation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_12.html">
      <font color="black">CoRefi: A Crowd Sourcing Suite for Coreference Annotation</font>
    </a>
  </h2>
  <font color="black">CoRefiはオープンソースであり、人気のあるクラウドソーシングプラットフォームを含む、あらゆるWebサイトに直接埋め込まれます。CoRefiは、コアの共参照アノテーションツールを超えて、タスクのガイド付きオンボーディングとレビューフェーズの新しいアルゴリズムを提供します。CoRefiデモ：aka.ms/ corefiビデオツアー：aka.ms/corefivideo Githubリポジトリ：https：//github.com/aribornstein/corefi 
[ABSTRACT] corefiは、Webベースの共参照アノテーションスイートです。クラウドソーシング用のアノテーションスイートを提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: COD3S: Diverse Generation with Discrete Semantic Signatures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_13.html">
      <font color="black">COD3S: Diverse Generation with Discrete Semantic Signatures</font>
    </a>
  </h2>
  <font color="black">私たちの2段階のアプローチは、ハミング距離が意味テキストの類似性の人間の判断と高度に相関する局所性鋭敏型ハッシュ（LSH）ベースの意味文コードで生成を調整することによって出力の多様性を改善します。一般的に適用可能ですが、因果生成にCOD3Sを適用します。 、提案のもっともらしい原因または結果を予測するタスク..自動および人間による評価を通じて、私たちの方法を使用して生成された応答が、タスクのパフォーマンスを低下させることなく、改善された多様性を示すことを示します。 
[ABSTRACT] seq2seqモデルは通常、意味的および構文的に多様な文のセットを生成します。私たちの方法は人間の応答に基づいています。cod3sを論理ハミングに適用します。これは、命題のもっともらしい原因または結果を予測するタスクです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Context Modeling with Evidence Filter for Multiple Choice Question
  Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_14.html">
      <font color="black">Context Modeling with Evidence Filter for Multiple Choice Question
  Answering</font>
    </a>
  </h2>
  <font color="black">課題に対処するために、証拠フィルタリングと呼ばれるシンプルで効果的なアプローチを提案し、さまざまなオプションに関してエンコードされたコンテキスト間の関係をまとめてモデル化し、証拠文を強調表示して無関係な文を除外する可能性があります。 OpenbookQAでの広範な実験を通じて、私たちのアプローチの人間の努力を比較すると、提案されたアプローチは、同じバックボーンとより多くのトレーニングデータを使用するモデルよりも優れていることがわかります。また、パラメータ分析は、アプローチの解釈可能性も示しています。OpenbookQAデータセットでは、コンテキスト内の文が相互に独立しているため、「証拠」を抽出する要件が特に重要です。 
[概要] mcqaの主な課題は、正解をサポートする特定のコンテキストから「証拠」を抽出することです。人間の労力を効果的に削減することに加えて、提案されたアプローチが同じバックボーンなどを使用するモデルよりも優れていることを示します。トレーニングデータ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Analyzing Individual Neurons in Pre-trained Language Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_15.html">
      <font color="black">Analyzing Individual Neurons in Pre-trained Language Models</font>
    </a>
  </h2>
  <font color="black">たとえば、XLNetのニューロンは、BERTや他のニューロンと比較して、プロパティを予測するときに、よりローカライズされてばらばらであることがわかりました。形態）構文を予測する高レベルのタスクと比較して、より少ないニューロンにローカライズされています。私たちの研究はまた、興味深いクロスアーキテクチャの比較を明らかにしています。 
[概要]この研究では、特定の言語現象についてどのように学習したかも明らかになっています。ニューロンは他のニューロンよりも目立つことがわかりました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: CIRCE at SemEval-2020 Task 1: Ensembling Context-Free and
  Context-Dependent Word Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_16.html">
      <font color="black">CIRCE at SemEval-2020 Task 1: Ensembling Context-Free and
  Context-Dependent Word Representations</font>
    </a>
  </h2>
  <font color="black">主な調査結果は、（1）文脈自由単語表現が強力で堅牢なベースラインであり、（2）文分類目標を使用して、有用な文脈依存単語表現を取得できること、および（3）これらの表現を組み合わせると一部のパフォーマンスが向上することです。このペーパーでは、チームUG Student Internから渡されたSemEval-2020タスク1：監視されていない字句意味変化検出（サブタスク2）への勝利の貢献について説明します。コンテキストに基づいて予測を行うアンサンブルモデルを提示します。 -自由で文脈依存の単語表現。 
[概要]データデータに基づいて予測を行うアンサンブルモデルを紹介します。これらは、データデータデータの変更を含むパフォーマンスパフォーマンスに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: RMM: A Recursive Mental Model for Dialog Navigation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_17.html">
      <font color="black">RMM: A Recursive Mental Model for Dialog Navigation</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、指示に従うだけでなく、1人のエージェントがナビゲートして2番目のガイドエージェントが回答する質問をする2エージェントタスクを紹介します。エージェントが目標に向けて行った進捗状況を強化学習報酬信号として使用して、直接通知します。ナビゲーションアクションだけでなく、質問と回答の生成も行います。RMMにより、新しい環境へのより良い一般化が可能になることを示します。 
[ABSTRACT]心の理論に従って、再帰的メンタルモデル（rmm）を提案します。ガイドエージェントは、ナビゲーションエージェントをモデル化して、回答を生成するために必要なナビゲーションステップをシミュレートします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-02">
        <br><font color="black">2020-05-02</font>
      </time>
    </span>
</section>
<!-- paper0: UNQOVERing Stereotyping Biases via Underspecified Questions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_18.html">
      <font color="black">UNQOVERing Stereotyping Biases via Underspecified Questions</font>
    </a>
  </h2>
  <font color="black">私たちの広範な研究は、（1）微調整の有無にかかわらず、これらすべてのモデルがこれらのクラスで顕著なステレオタイプバイアスを持っていることを明らかにしています。 （2）モデルが大きいほど、バイアスが高くなることがよくあります。 （3）バイアスに対する微調整の効果は、データセットとモデルサイズによって大きく異なります。2つのQAデータセットでトレーニングされた5つのトランスフォーマーベースのQAモデルと、その基礎となる言語モデルを調査します。ケーススタディとして、このメトリックを使用して、ステレオタイプの4つの重要なクラス（性別、国籍、民族性、および宗教）を分析します。 
[概要] unqoverを提示します。これは、特定されていない質問を通じてバイアスを調査および定量化するためのより大きなスケールです。misを分離する形式を使用します。2つのデータセットでトレーニングされた5つのトランスフォーマーベースのqaモデルに質問します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Speech Synthesis for Estonian -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_19.html">
      <font color="black">Neural Speech Synthesis for Estonian</font>
    </a>
  </h2>
  <font color="black">（2）神経音声合成用のソフトウェアとモデルがオープンソース（MITライセンス）でリリースされています。https：//koodivaramu.eesti.ee/tartunlp/text-to-speechで入手可能です。（3）評価を実行しました。新しいモデルを他の既存のソリューションと比較しました（EKIのHMMベースのHTSモデル、http：//www.eki.ee/heli/、およびhttps://translate.google.comからアクセスできるエストニア語のGoogleの音声合成） 。 
[概要]レポートは、大学の研究結果を説明しています。プロジェクトの結果を説明しています。プロジェクトの結果は、エストニア語で公開されています。6人のスピーカーから合計92.4時間のデータが収集され、公開されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Knowledge Empowered Structured Neural Net for End-to-End Event
  Temporal Relation Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_20.html">
      <font color="black">Domain Knowledge Empowered Structured Neural Net for End-to-End Event
  Temporal Relation Extraction</font>
    </a>
  </h2>
  <font color="black">Lagrangian Relaxationを介して制約付き推論問題を解決し、それをエンドツーエンドのイベント時間関係抽出タスクに適用します。以前のシステムは、ディープラーニングと事前トレーニング済みの言語モデルを活用してタスクのパフォーマンスを向上させます。実験結果は、フレームワークを示しています。ニュースおよび臨床領域で広く使用されている2つのデータセットで、統計的に有意なベースラインニューラルネットワークモデルを改善できます。 
[概要]以前のシステムでは、ディープラーニングと事前にトレーニングされた言語モデルを使用して、タスクのパフォーマンスを向上させます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Experience Grounds Language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_21.html">
      <font color="black">Experience Grounds Language</font>
    </a>
  </h2>
  <font color="black">大規模なテキストのみのコーパスでトレーニングされた表現学習アプローチの現在の成功には、コミュニケーションのより深い問題に対処するために、言語のより広い物理的および社会的文脈に関する研究の並行した伝統が必要であると私たちは考えます。言語をそれが説明する物理的世界およびそれが促進する社会的相互作用に関連付けることに失敗する。自然言語処理は多様な分野であり、その開発全体の進歩は、新しい表現理論、モデリング技術、データ収集パラダイム、およびタスクから来ている。 
[ABSTRACT]言語処理は多様な分野ですが、成功する社会的コミュニケーションは世界の共有された経験に依存しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br><font color="black">2020-04-21</font>
      </time>
    </span>
</section>
<!-- paper0: BERT Knows Punta Cana is not just beautiful, it's gorgeous: Ranking
  Scalar Adjectives with Contextualised Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_22.html">
      <font color="black">BERT Knows Punta Cana is not just beautiful, it's gorgeous: Ranking
  Scalar Adjectives with Contextualised Representations</font>
    </a>
  </h2>
  <font color="black">スカラー形容詞の強度検出に対する新しいBERTベースのアプローチを提案します。私たちの結果は、BERTがスカラー形容詞のセマンティクスに関する豊富な知識をエンコードし、静的な埋め込みや専用のアクセス権を持つ以前のモデルよりも優れた品質の強度ランキングを提供できることを示しています。リソース..私たちは、本質的に、ゴールドスタンダードのデータセットと、間接的な質問回答タスクの両方でモデルを評価します。 
[ABSTRACT]コンテキスト化された表現から直接派生したシールドによって強度をモデル化します。スカラー拡張を正常にランク付けできることを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Meta Lifelong-Learning with Limited Memory -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_23.html">
      <font color="black">Efficient Meta Lifelong-Learning with Limited Memory</font>
    </a>
  </h2>
  <font color="black">ただし、実験の後半で示すように、3つの重大な障害があります。（1）良好なパフォーマンスを実現するために非現実的に大きなメモリモジュールが必要、（2）負の転送に悩まされる、（3）テスト例ごとに複数のローカル適応ステップが必要推論速度が大幅に遅くなります。さらに、この方法が壊滅的な忘却と負の転送の両方を同時に軽減することを示します。サンプル効率を達成するために、この方法は、局所適応のためのより良い初期化を学習する方法でモデルをトレーニングします。 
[ABSTRACT]最先端の生涯言語学習方法は、過去の例を否定的な記憶に保存し、トレーニング時と結論時の両方で再生します。テキスト分類と質問応答ベンチマークに関する実験は、フレームワークの有効性を実証しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Knowing What You Know: Calibrating Dialogue Belief State Distributions
  via Ensembles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_24.html">
      <font color="black">Knowing What You Know: Calibrating Dialogue Belief State Distributions
  via Ensembles</font>
    </a>
  </h2>
  <font color="black">一方、信念トラッカーは、可能な対話状態の分布を維持します。結果として得られる対話信念トラッカーは、精度の点でも以前の対話信念追跡モデルよりも優れています。この作業では、キャリブレーションにおける最先端のパフォーマンスを示します。モデルのキャリブレーションされたアンサンブルを使用するマルチドメイン対話信念トラッカー用。 
[ABSTRACT]ダイアログ状態トラッカーは、現在の実行で55％をわずかに超える精度を達成します-ベンチマークに。ほぼ毎秒のダイアログターンで、誤ったダイアログ状態に完全な信頼を置きます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: On the Sub-Layer Functionalities of Transformer Decoder -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_25.html">
      <font color="black">On the Sub-Layer Functionalities of Transformer Decoder</font>
    </a>
  </h2>
  <font color="black">この作業では、Transformerベースのデコーダーがソース言語とターゲット言語からの情報をどのように活用するかを研究します。ユニバーサルプローブタスクを開発して、各デコーダーレイヤーの各モジュールを介して情報がどのように伝播されるかを評価します。分析により、デコーダーがいつどこにあるかについての洞察が得られます。さまざまなソースを活用します。これらの洞察に基づいて、各Transformerデコーダーレイヤーの残りのフィードフォワードモジュールを、パフォーマンスの低下を最小限に抑えてドロップできることを示します。これにより、計算とパラメーターの数が大幅に削減され、その結果、トレーニングと推論速度の両方。 
[ABSTRACT]デコーダーは、ソース（エンコーダーからの言語テキストとターゲット）の両方を調査することにより、出力トークンを予測する必要があります。言語の言及。デコーダーは、パフォーマンスの低下を最小限に抑えて削除できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: UnifiedQA: Crossing Format Boundaries With a Single QA System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_26.html">
      <font color="black">UnifiedQA: Crossing Format Boundaries With a Single QA System</font>
    </a>
  </h2>
  <font color="black">最後に、この事前トレーニング済みのQAモデルを特殊なモデルに微調整するだけで、6つのデータセットに新しい最先端技術がもたらされ、UnifiedQAがQAシステムを構築するための強力な出発点として確立されます。UnifiedQAは、以前の9つの異なるモデルと同等のパフォーマンスを発揮します。個々のデータセット自体でトレーニングされています。これにより、フォーマットに特化したモデルが生まれ、QAコミュニティで暗黙の分割が行われるようになりました。 
[ABSTRACT] unifiedqaは、4つの異なる形式にまたがる17のqaデータセット全体で驚くほどうまく機能する事前トレーニング済みモデルです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-02">
        <br><font color="black">2020-05-02</font>
      </time>
    </span>
</section>
<!-- paper0: Evaluating the Calibration of Knowledge Graph Embeddings for Trustworthy
  Link Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_27.html">
      <font color="black">Evaluating the Calibration of Knowledge Graph Embeddings for Trustworthy
  Link Prediction</font>
    </a>
  </h2>
  <font color="black">ここでは、既存のキャリブレーション手法がOWAではCWAよりもはるかに効果が低いことを示し、この不一致の説明を提供します。知識グラフ埋め込み（KGE）モデルによって行われた予測の信頼性についてはほとんど知られていません。標準の閉世界仮説（CWA）での評価では、知識グラフにまだ含まれていない予測トリプルは偽と見なされ、既存のキャリブレーション手法がこの一般的ではあるが狭い仮定の下でKGEに有効であることを示しています。 
[概要] kgeモデルのキャリブレーションは、信頼スコアを出力する方法の例です。キャリブレーションされたモデルは、予測されたナレッジグラフトリプルの正確さに基づいています。これらのキャリブレーション手法は、kgeのキャリブレーションの有用性を動機付けるために必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-02">
        <br><font color="black">2020-04-02</font>
      </time>
    </span>
</section>
<!-- paper0: Semantically Driven Sentence Fusion: Modeling and Evaluation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_28.html">
      <font color="black">Semantically Driven Sentence Fusion: Modeling and Evaluation</font>
    </a>
  </h2>
  <font color="black">この方法を大規模なデータセットに適用し、モデルのトレーニングと評価の両方に拡張データセットを使用します。実験では、最先端のモデルに対するアプローチの改善を強調しています。を使用して意味表現の学習を改善するには複数の参照、マルチタスクフレームワークの下で補助談話分類タスクでモデルを充実させます。 
[ABSTRACT]グラウンドトゥルースソリューションが自動的に複数の参照に拡張されるアプローチを提示します。複数の参照を使用した意味表現の学習を改善するために、マルチタスクフレームワークの下で補助談話分類タスクでモデルを強化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Simple and Effective Few-Shot Named Entity Recognition with Structured
  Nearest Neighbor Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_29.html">
      <font color="black">Simple and Effective Few-Shot Named Entity Recognition with Structured
  Nearest Neighbor Learning</font>
    </a>
  </h2>
  <font color="black">構造化デコードと最近傍学習を組み合わせる方法が、標準の数ショットNER評価タスクで最先端のパフォーマンスを達成し、F1スコアを以前のメタよりも$ 6 \％$から$ 16 \％$絶対ポイント改善することを示します。学習ベースのシステム..最近傍学習と構造化推論に基づく単純な数ショットの名前付きエンティティ認識（NER）システムを提示します。いくつかのテストドメインにわたって、この特徴空間の最近傍分類器がはるかに効果的であることを示します。標準のメタ学習アプローチよりも。 
[概要]私たちのシステムは、ソースポイントでトレーニングされた教師ありモデルを使用します。さらに、安価で効果的な方法を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: On the Sparsity of Neural Machine Translation Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_30.html">
      <font color="black">On the Sparsity of Neural Machine Translation Models</font>
    </a>
  </h2>
  <font color="black">最新のニューラル機械翻訳（NMT）モデルは多数のパラメーターを使用するため、パラメーターが大幅に過剰になり、通常は計算リソースが十分に活用されません。実験と分析は、さまざまなデータセットとNMTアーキテクチャで体系的に実行されます。これに対応して問題は、冗長パラメータを再利用してパフォーマンスを向上させることができるかどうかを実験的に調査することです。 
[概要]冗長パラメータを再利用してパフォーマンスを向上できるかどうかを調査します。これらのモデルが活性化され、ベースラインモデルが最大0.8ブルーポイント改善されたのはこれが初めてです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Aspect Sentiment Classification with Aspect-Specific Opinion Spans -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_31.html">
      <font color="black">Aspect Sentiment Classification with Aspect-Specific Opinion Spans</font>
    </a>
  </h2>
  <font color="black">ただし、これらの作業では、意見スパン全体をキャプチャできないか、可変長の意見スパンをキャプチャできません。4つのデータセットでの実験結果は、提案されたモデルの有効性を示しており、分析により、モデルがアスペクト固有の意見スパンをキャプチャします。このような設計により、モデルはアスペクト固有の意見スパンを抽出し、抽出された意見の特徴を活用して感情の極性を評価できます。 
[ABSTRACT]以前の注意ベースのモデルは、アスペクトの現実を使用して分類のための意見の特徴を抽出することを強調しています。これらは、意見のスパンを抽出した4つのデータセットに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Synthesizer: Rethinking Self-Attention in Transformer Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_32.html">
      <font color="black">Synthesizer: Rethinking Self-Attention in Transformer Models</font>
    </a>
  </h2>
  <font color="black">ドット積の注意で構成すると、シンセサイザーは常にトランスフォーマーよりも優れていることがわかります。この目的のために、トークンとトークンの相互作用なしで合成注意の重みを学習するモデルである\ textsc {Synthesizer}を提案します。トランスフォーマーモデルのパフォーマンスに対するドット積ベースの自己注意メカニズムの影響。 
[ABSTRACT]カリフォルニア大学の研究者が実験を行ったところ、シンプルなシンセが非常に競争力のあるパフォーマンスを発揮することがわかりました。また、モデルに代わって追加のメカニズムも実行しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-02">
        <br><font color="black">2020-05-02</font>
      </time>
    </span>
</section>
<!-- paper0: Reproducible Science with LaTeX -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_33.html">
      <font color="black">Reproducible Science with LaTeX</font>
    </a>
  </h2>
  <font color="black">また、ドキュメントのコンパイル時にシェルスクリプトを呼び出すことにより、システム設定情報を紙に含める方法も示します。LaTeXベースの科学ノートブックへの提案されたアプローチでは、ユーザーはコンパイル時に任意のプログラミング言語またはコマンドラインプログラムを簡単に呼び出すことができます。 LaTeXドキュメント、書き込みプロセスでお気に入りのLaTeXエディターを使用します。必要なLaTeXセットアップ、新しいPythonパッケージ、および定義されたプリアンブルについて詳しく説明し、R、Julia、およびMatLabを使用して既存の研究を再現する実例を示します。提案された手順を説明するため。 
[概要]プログラミングツールをラテックス書き込みツールに統合して、再現性のある研究の作成を容易にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-04">
        <br><font color="black">2020-10-04</font>
      </time>
    </span>
</section>
<!-- paper0: Translation Artifacts in Cross-lingual Transfer Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_34.html">
      <font color="black">Translation Artifacts in Cross-lingual Transfer Learning</font>
    </a>
  </h2>
  <font color="black">得られた洞察に基づいて、翻訳テストとゼロショットアプローチのXNLIの最先端技術を、それぞれ4.3ポイントと2.8ポイント改善します。たとえば、自然言語の推論では、前提を翻訳し、仮説は独立して、現在のモデルが非常に敏感であるそれらの間の語彙の重複を減らすことができます。人間と機械の両方の翻訳は、言語間の伝達学習において中心的な役割を果たします。多くの多言語データセットは、専門の翻訳サービスを通じて、機械を使用して作成されています。テストセットまたはトレーニングセットのいずれかを翻訳するための翻訳は、広く使用されている転送手法です。 
[概要]このホワイトペーパーでは、このような翻訳プロセスによって、既存のクロスリンガルモデルに顕著な影響を与える微妙なアーティファクトが発生する可能性があることを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: Exploiting Unsupervised Data for Emotion Recognition in Conversations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_35.html">
      <font color="black">Exploiting Unsupervised Data for Emotion Recognition in Conversations</font>
    </a>
  </h2>
  <font color="black">次に、ConvComタスクで基本的なCOntext-Dependent Encoder（Pre-CODE）を事前トレーニングします。最後に、ERCのデータセットでPre-CODEを微調整します。文レベルのテキスト分類問題とは異なり、 ERCタスクで使用できる監視対象データは限られているため、モデルが最大の効果を発揮できなくなる可能性があります。 
[概要]会話のマスクされたコンテキストを埋めるために正しい答えを選択しようとする会話完了（convcom）タスクを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-02">
        <br><font color="black">2020-10-02</font>
      </time>
    </span>
</section>
<!-- paper0: Visually Grounded Continual Learning of Compositional Phrases -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_36.html">
      <font color="black">Visually Grounded Continual Learning of Compositional Phrases</font>
    </a>
  </h2>
  <font color="black">今後の作業をガイドするために、さらにアブレーションと分析を行います。このタスクでは、モデルは、オブジェクトの分布が変化するペアの画像キャプションストリームでトレーニングされます。 VisCOLLの研究を容易にするために、COCOシフトとFlickrシフトの2つのデータセットを構築し、さまざまな継続学習方法を使用してベンチマークを行います。 
[ABSTRACT] viscollは、視覚的に根拠のある言語学習タスクであり、ストリーミングビジュアルシーンからのオブジェクトフレーズの継続的な取得をシミュレートします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-02">
        <br><font color="black">2020-05-02</font>
      </time>
    </span>
</section>
<!-- paper0: CoDEx: A Comprehensive Knowledge Graph Completion Benchmark -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_37.html">
      <font color="black">CoDEx: A Comprehensive Knowledge Graph Completion Benchmark</font>
    </a>
  </h2>
  <font color="black">次に、5つの広範囲に調整された埋め込みモデルのCoDExでのベースラインリンク予測とトリプル分類の結果を報告します。最初に、論理関係パターンの観点から各CoDExデータセットを分析します。最後に、CoDExを人気のあるFB15K-237ナレッジグラフの完成と区別します。 CoDExがより多様で解釈可能なコンテンツをカバーし、より困難なリンク予測ベンチマークであることを示すことによるデータセット。 
[ABSTRACT]コーデックスは、3つのナレッジグラフ、エンティティと関係の多言語記述、および数万のハードネガティブトリプルで構成されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: LOGAN: Local Group Bias Detection by Clustering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_38.html">
      <font color="black">LOGAN: Local Group Bias Detection by Clustering</font>
    </a>
  </h2>
  <font color="black">このような局所バイアスを分析・検出するために、クラスタリングに基づく新しいバイアス検出手法であるLOGANを提案します。機械学習手法は自然言語処理（NLP）で広く使用されています。実際、異なるグループ間で同様の集約パフォーマンスを持つモデルデータ全体で、ローカルリージョンのインスタンスで異なる動作をする可能性があります。 
[概要]機械学習モデルは、データの社会的バイアスを継承および増幅することがよくあります。毒性分類およびオブジェクト分類タスクの実験では、ローガンがローカル領域のバイアスを識別することが示されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Sparse Parallel Training of Hierarchical Dirichlet Process Topic Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_39.html">
      <font color="black">Sparse Parallel Training of Hierarchical Dirichlet Process Topic Models</font>
    </a>
  </h2>
  <font color="black">4日以内に単一のマルチコアマシンを使用して、8mのドキュメントと768mのトークンを備えた有名なコーパス（PubMed）でメソッドのベンチマークを行います。潜在的ディリクレの割り当てなどの確率的トピックモデルのノンパラメトリック拡張をより大きなものにスケーリングするデータセット、開業医はますます並列および分散システムに依存しています。このサンプラーは、自然言語に見られるスパース性の利用可能なすべてのソースを利用します。これは、計算を効率化するための重要な方法です。 
[概要]この作業では、データを研究します-社会的ディリクレデータの並列トレーニング。データベースのデータベースのデータは自然言語で見つかりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-06">
        <br><font color="black">2019-06-06</font>
      </time>
    </span>
</section>
<!-- paper0: Scene Graph Modification Based on Natural Language Commands -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_40.html">
      <font color="black">Scene Graph Modification Based on Natural Language Commands</font>
    </a>
  </h2>
  <font color="black">グラフベースのスパーストランスフォーマーとクロスアテンション情報融合に基づく新しいモデルは、機械翻訳とグラフ生成の文献から採用された以前のシステムよりも優れています。グラフやパースツリーなどの構造化表現は、多くの自然言語処理システムで重要な役割を果たします。この新しい問題の将来の研究を奨励するために、私たちの大規模なグラフ修正データセットを研究コミュニティに提供します。 
[概要]マルチターンユーザーの進歩により、複雑なシステムが改善されました。新しい情報源が与えられた場合、これらの構造を制御および更新する必要があります。これは、システムが更新方法を学習する必要があるグラフ変更の新しい問題です。新しいユーザーのコマンドが与えられた既存のシーングラフ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Poison Attacks against Text Datasets with Conditional Adversarially
  Regularized Autoencoder -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_41.html">
      <font color="black">Poison Attacks against Text Datasets with Conditional Adversarially
  Regularized Autoencoder</font>
    </a>
  </h2>
  <font color="black">私たちの中毒攻撃は、条件付きの敵対的に正則化されたオートエンコーダー（CARA）を利用して、潜在空間への毒注入によって中毒トレーニングサンプルを生成します。より具体的には、NLPモデルに対する「バックドア中毒」攻撃を示します。このペーパーは、自然言語推論における致命的な脆弱性を示しています。 （NLI）およびテキスト分類システム。 
[概要]自然学習システムに対する「バックドア中毒」攻撃を提示します。私たちの実験は、昼寝モデルが大きなセキュリティリスクに直面していることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Do Explicit Alignments Robustly Improve Multilingual Encoders? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_42.html">
      <font color="black">Do Explicit Alignments Robustly Improve Multilingual Encoders?</font>
    </a>
  </h2>
  <font color="black">ただし、単語レベルのアラインメントは最適ではないことが多く、そのようなbitextは多くの言語で利用できません。さらに、より優れた基礎となるモデルを使用することによる利点は、アラインメントトレーニングのメリットを上回ります。この論文では、このような信号をより有効に活用し、これらの以前のアラインメント方法を、アラインメントされたデータのノイズの多いソース（OPUSコレクションのランダムにサンプリングされた100万ペアのサブセット）に適合できるかどうかを調べます。 
[概要]明示的なアライメント目標の新しいパターンは、これらの表現をさらに改善することが示されています。これらは、europamalやmultiunなどのbitextに基づいています。ただし、新しい方法は、アライメントされたデータのノイズの多いソースに適合させることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Lingual Text Classification with Minimal Resources by Transferring
  a Sparse Teacher -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_43.html">
      <font color="black">Cross-Lingual Text Classification with Minimal Resources by Transferring
  a Sparse Teacher</font>
    </a>
  </h2>
  <font color="black">次に、CLTSは、ラベルのないターゲットドキュメントのシードワードのコンテキストも活用し、教師よりも優れた、より強力な学生を繰り返しトレーニングします。この作業では、「弱い」を生成する言語横断的な教師と学生の方法であるCLTSを提案します。少数の単語翻訳の形で、最小限の言語間リソースを使用したターゲット言語での監視。最後に、CLTSは、少数の単語翻訳を使用して、リソースの少ない言語で新たに発生するタスクに対処します。 
[ABSTRACT] cltsは、最も重要なタスクである特定のシードワードのみを使用し、翻訳されたシードワードに基づいて教師分類子を初期化します。これはシンプルで、18の強力な言語で驚くほど効果的です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Graph-to-Tree Neural Networks for Learning Structured Input-Output
  Translation with Applications to Semantic Parsing and Math Word Problem -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_44.html">
      <font color="black">Graph-to-Tree Neural Networks for Learning Structured Input-Output
  Translation with Applications to Semantic Parsing and Math Word Problem</font>
    </a>
  </h2>
  <font color="black">私たちの広範な実験は、Graph2Treeモデルがこれらのタスクで他の最先端モデルのパフォーマンスよりも優れているか一致していることを示しています。この論文では、新しいGraph-to-Treeニューラルネットワーク、つまりグラフで構成されるGraph2Treeを紹介します。エンコーダーと階層ツリーデコーダー。拡張されたグラフ構造の入力をエンコードし、ツリー構造の出力をデコードします。有名なSeq2Seq手法とその多数のバリエーションにより、ニューラルマシンの変換、セマンティック解析、数学ワードなどの多くのタスクで優れたパフォーマンスが実現します。問題解決。 
[概要]これらのモデルは、重要な構造情報を無視して、パフォーマンスタスクのみをシーケンスと見なします。デコード用の構造オブジェクトではなく、出力オブジェクトを処理するだけです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br><font color="black">2020-04-07</font>
      </time>
    </span>
</section>
<!-- paper0: Universal Natural Language Processing with Limited Annotations: Try
  Few-shot Textual Entailment as a Start -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_45.html">
      <font color="black">Universal Natural Language Processing with Limited Annotations: Try
  Few-shot Textual Entailment as a Start</font>
    </a>
  </h2>
  <font color="black">（ii）NLPタスクをテキスト含意に変換する価値があるのはいつですか。このようなNLP問題の統一ソルバーとして、テキスト含意を取り上げます。このタスクの豊富な注釈を取得できれば、変換は不要であると主張します。 
[要約]新しい研究は、事前に訓練された文学的含意システムが、ほんの一握りのドメイン固有の例で、ドメイン間でどれほどうまく一般化するかを示していますか？</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: An Imitation Game for Learning Semantic Parsers from User Interaction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_46.html">
      <font color="black">An Imitation Game for Learning Semantic Parsers from User Interaction</font>
    </a>
  </h2>
  <font color="black">デモンストレーションのスパース性に対抗するために、デモンストレーションされた状態と信頼できる予測を混合することによって新しいデータセットを繰り返し収集し、データセット集約方式でセマンティックパーサーを再トレーニングする新しい注釈効率の高い模倣学習アルゴリズムを提案します（Ross et al。、2011） ..コスト限界の理論的分析を提供し、テキストからSQLへの問題での有望なパフォーマンスを経験的に示します。セマンティックパーサーは、その不確実性を内省し、不確実な場合はユーザーのデモンストレーションを促す必要があります。 
[概要] 2011年に、ユーザーから直接セマンティックパーサーを学習するための代替のヒューマンインループメソッドを提案します。そうすることで、ユーザーの動作を模倣し、自律的に改善を続けることもできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-02">
        <br><font color="black">2020-05-02</font>
      </time>
    </span>
</section>
<!-- paper0: Regularizing Dialogue Generation by Imitating Implicit Scenarios -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_47.html">
      <font color="black">Regularizing Dialogue Generation by Imitating Implicit Scenarios</font>
    </a>
  </h2>
  <font color="black">広範な評価は、私たちのアプローチが多様性と関連性に関する最先端のベースラインを大幅に上回り、シナリオ固有の知識を表現していることを示しています。さらに重要なことに、会話シナリオは、模倣学習フレームワークを使用してさらに内部化されます。シナリオベースの対話モデルから階層的な監視信号に含まれるシナリオ知識を転送することによって、将来の会話へのアクセスが効果的に正規化されないため、実際の推論では将来の会話は必要ありません。人間の対話はシナリオベースであり、適切な応答は一般的に関連しています。特定のシナリオに伴う潜在的なコンテキストの知識に。 
[概要]シナリオの観点から、寛大な対話システムの改善を提案します。対話の履歴と将来の会話が考慮されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: SelfORE: Self-supervised Relational Feature Learning for Open Relation
  Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_48.html">
      <font color="black">SelfORE: Self-supervised Relational Feature Learning for Open Relation
  Extraction</font>
    </a>
  </h2>
  <font color="black">この作業では、SelfOREという名前の自己監視フレームワークを提案しました。これは、コンテキスト化されたリレーショナル機能の適応クラスタリングに大規模な事前トレーニング済み言語モデルを活用することで弱い自己監視信号を活用し、関係分類でコンテキスト化された機能を改善することで自己監視信号をブートストラップします。 .. 3つのデータセットの実験結果は、競合するベースラインと比較した場合の、オープンドメイン関係抽出におけるSelfOREの有効性と堅牢性を示しています。オープン関係抽出は、自然言語文からオープンドメイン関係の事実を抽出するタスクです。 
[ABSTRACT]既存の作品は、ヒューリスティックまたは遠方の教師あり注釈を利用して、事前定義された関係に対して教師あり分類子をトレーニングします。これらには、影響力の欠如に基づくselfpspspspsが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: Joint Turn and Dialogue level User Satisfaction Estimation on
  Multi-Domain Conversations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_49.html">
      <font color="black">Joint Turn and Dialogue level User Satisfaction Estimation on
  Multi-Domain Conversations</font>
    </a>
  </h2>
  <font color="black">28のAlexaドメイン、2つのダイアログシステム、および3つのユーザーグループからサンプリングされたダイアログで、共同ダイアログレベルの満足度推定モデルは、線形相関で最大27％（0.43-&gt; 0.70）および7％（0.63-&gt; 0.70）の改善を達成しました。ベースラインのディープニューラルネットとベンチマークの勾配ブースティング回帰モデルをそれぞれ上回るパフォーマンス。提案されたBiLSTMベースのディープニューラルネットモデルは、推定されたダイアログレベルの評価に対する各ターンの寄与を自動的に評価し、時間依存性を暗黙的にエンコードし、手作りの必要性を排除します。機能..ダイアログレベルの品質推定は、データ駆動型のダイアログ管理を最適化するために不可欠です。 
[概要]アイデアは注釈スキームに基づいています。ユーザーは注釈システムを持っている可能性が高いです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Are Words Commensurate with Actions? Quantifying Commitment to a Cause
  from Online Public Messaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_50.html">
      <font color="black">Are Words Commensurate with Actions? Quantifying Commitment to a Cause
  from Online Public Messaging</font>
    </a>
  </h2>
  <font color="black">次に、そのようなメッセージの量を、エンティティのアクションに基づく外部評価と比較します（たとえば、環境に関する政治家の投票記録、または環境非営利団体からの企業の評価）。企業や政治家などの公的エンティティはますますオンラインで使用しています。その構成員と直接通信するためのソーシャルネットワーク..この論文では、原因に対するコミットメントレベルに従ってメッセージを分類するためのテキスト分類アプローチを提示します。 
[概要]パブリックメッセージングは、環境や公衆衛生など、特定の原因や問題に対応することを目的としていることがよくあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Coreferential Reasoning Learning for Language Representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_51.html">
      <font color="black">Coreferential Reasoning Learning for Language Representation</font>
    </a>
  </h2>
  <font color="black">このペーパーのソースコードと実験の詳細は、https：//github.com/thunlp/CorefBERTから入手できます。この問題に対処するために、コンテキスト内の相互関係をキャプチャできる新しい言語表現モデルであるCorefBERTを紹介します。 BERTなどの言語表現モデルは、プレーンテキストからコンテキストセマンティック情報を効果的にキャプチャでき、適切な微調整を行うことで、多くのダウンストリームNLPタスクで有望な結果を達成することが証明されています。 
[概要]ほとんどの既存の言語表現モデルは、共参照を処理できませんでした</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-15">
        <br><font color="black">2020-04-15</font>
      </time>
    </span>
</section>
<!-- paper0: ERFit: Entropic Regression Fit Matlab Package, for Data-Driven System
  Identification of Underlying Dynamic Equations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_52.html">
      <font color="black">ERFit: Entropic Regression Fit Matlab Package, for Data-Driven System
  Identification of Underlying Dynamic Equations</font>
    </a>
  </h2>
  <font color="black">この作業では、エントロピー回帰法を使用したスパースシステム同定用のMATLABパッケージであるエントロピー回帰ソフトウェアパッケージ（ERFit）を開発しました。データ駆動型スパースシステム同定は、科学および工学における幅広い問題の一般的なフレームワークになります。 。これは、応用機械学習と人工知能アルゴリズムにおいてますます重要になっている問題です。 
[概要]コードは最小限の監視で、幅広いオプションが必要です。高度な機械学習で重要性が増している問題です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: PolicyQA: A Reading Comprehension Dataset for Privacy Policies -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_53.html">
      <font color="black">PolicyQA: A Reading Comprehension Dataset for Privacy Policies</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、115のWebサイトプライバシーポリシーの既存のコーパスからキュレーションされた25,017の読解スタイルの例を含むデータセットであるPolicyQAを紹介します。2つの既存のニューラルQAモデルを評価し、厳密な分析を実行して、PolicyQAが提供する利点と課題を明らかにします。 。プライバシーポリシーのドキュメントは長く、冗長です。 
[要約]質問応答（qa）システムは、ユーザーが関連性のある重要な情報を見つけるのに役立ちます。policyqaは、幅広いプライバシー慣行のために書かれた714の人間の注釈付き質問を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Identifying Spurious Correlations for Robust Text Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_54.html">
      <font color="black">Identifying Spurious Correlations for Robust Text Classification</font>
    </a>
  </h2>
  <font color="black">これを教師あり分類問題として扱い、処理効果推定量から導出された特徴を使用して、疑似相関を「本物の」相関と区別します。4つのデータセット（感情分類と毒性検出）での実験は、このアプローチを使用して特徴選択を通知することも疑似相関の影響を受けるサンプルの最悪の場合の精度の向上によって測定される、より堅牢な分類。これらの特徴の一般的な性質とその小さな次元のために、このアプローチは限られたトレーニング例でもうまく機能することがわかります。単語分類子を新しいドメインに転送することが可能です。 
[概要]テキスト分類における疑似相関と本物の相関を区別する方法を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Hierarchical Concept Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_55.html">
      <font color="black">Unsupervised Hierarchical Concept Learning</font>
    </a>
  </h2>
  <font color="black">UNHCLEがチェスと料理のドメインからのデータセットを使用して意味のある階層を発見する方法を経験的に示します。最後に、料理とチェスの自然言語で拡張されたデモンストレーションデータを使用して、UNHCLEが概念の意味のある言語ラベルを学習する方法を示します。環境にアクセスできない概念は、これらの発見された概念間の関係（または階層）を発見しません。 
[ABSTRACT] unhcleはトランスフォーマーです。unhcleと呼ばれる概念のアナロジーに基づいています。デモデータから教師なしの方法で概念の階層を抽出します。unhcleは、デモデータを使用して概念の意味のある言語ラベルを学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: More Bang for Your Buck: Natural Perturbation for Robust Question
  Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_56.html">
      <font color="black">More Bang for Your Buck: Natural Perturbation for Robust Question
  Answering</font>
    </a>
  </h2>
  <font color="black">この現象の影響を評価するために、最近の質問応答データセット（BoolQ）を検討し、摂動コスト比、既存の質問を摂動する相対コストと新しい質問を作成するコストの関数としてのアプローチの利点を調べます。スクラッチ..最近のモデルは多くのNLPデータセットで人間レベルのスコアを達成していますが、入力の小さな変化にかなり敏感であることがわかります。ローカル摂動には、書き出すよりも作成が比較的簡単（したがって安価）であるという利点があります。まったく新しい例。 
[概要]私たちのアプローチでは、まったく新しい例のトレーニングセットを作成します。次に、例の摂動を最小限に抑えることを提案します。このようなモデルは、より高い堅牢性とより優れた一般化を示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Instance Multi-Label Learning Networks for Aspect-Category
  Sentiment Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_57.html">
      <font color="black">Multi-Instance Multi-Label Learning Networks for Aspect-Category
  Sentiment Analysis</font>
    </a>
  </h2>
  <font color="black">これらの方法は、文で言及されているアスペクトカテゴリの感情が、文のアスペクトカテゴリを示す単語の感情の集合であり、最適ではないパフォーマンスにつながるという事実を無視します。文、AC-MIMLLNは最初にインスタンスの感情を予測し、次にアスペクトカテゴリのキーインスタンスを見つけ、最後にキーインスタンスの感情を集約することによってアスペクトカテゴリに対する文の感情を取得します。この論文では、マルチを提案します。 -アスペクトカテゴリ感情分析のためのインスタンスマルチラベル学習ネットワーク（AC-MIMLLN）。これは、文をバッグとして、単語をインスタンスとして、アスペクトカテゴリを示す単語をアスペクトカテゴリの主要インスタンスとして扱います。 
[ABSTRACT]以前のほとんどの方法では、最初にアスペクトカテゴリ（アスペクトカテゴリの特定の文表現）を生成し、次に特定のカテゴリの感情を予測します。次に、これらを使用して、ac-カテゴリ感情分析（ac-）と呼ばれるマルチラベル学習ネットワークを作成します。 mimlln）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Will I Sound Like Me? Improving Persona Consistency in Dialogues through
  Pragmatic Self-Consciousness -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_58.html">
      <font color="black">Will I Sound Like Me? Improving Persona Consistency in Dialogues through
  Pragmatic Self-Consciousness</font>
    </a>
  </h2>
  <font color="black">ただし、そのような追加のラベルとトレーニングは要求が厳しい場合があります。さらに、対話のペルソナを超えてコンテキストの一貫性を向上させるために一般化できることを示します。対話NLI（Welleck et al。、2019）およびPersonaChat（Zhang et al。 。、2018）データセットは、私たちのアプローチが矛盾を減らし、既存の対話モデルの一貫性を改善することを示しています。 
[ABSTRACT]合理的な発話行為のフレームワークに基づく私たちのアプローチは、対話エージェントに矛盾を発することを控えるように強制することができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-13">
        <br><font color="black">2020-04-13</font>
      </time>
    </span>
</section>
<!-- paper0: Don't Use English Dev: On the Zero-Shot Cross-Lingual Evaluation of
  Contextual Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_59.html">
      <font color="black">Don't Use English Dev: On the Zero-Shot Cross-Lingual Evaluation of
  Contextual Embeddings</font>
    </a>
  </h2>
  <font color="black">これらの再現性の問題は、事前にトレーニングされた埋め込みが異なる他のタスク（XLM-Rを使用したMLQAなど）にも存在します。この上限を報告すると、任意に悪いチェックポイントを回避することで結果の一貫性が高まります。ゼロショットと一緒にオラクルスコアを提供することをお勧めします。結果：英語のデータを使用して微調整しますが、ターゲット開発者が設定されたチェックポイントを選択します。 
[概要] mbertzeroの結果-ショットの精度は、4つの論文でmldoc追跡タスクで17ポイントも異なります。これは、電子メールで利用できるデータの量を見つけるのが困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Fact Correction in Abstractive Text Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_60.html">
      <font color="black">Multi-Fact Correction in Abstractive Text Summarization</font>
    </a>
  </h2>
  <font color="black">事前にトレーニングされたニューラル抽象要約システムは、少なくともROUGEの観点から、ニュース要約のパフォーマンスに関する抽出戦略を支配してきました。実験によると、自動メトリックと人間による評価..抽象要約モデルによって生成された要約の構文構造を保持しながら、ソーステキスト。 
[ABSTRACT]システム-生成された抽象的な要約は、事実の不一致の落とし穴に直面することがよくあります。ソーステキストに対処するために、事実の不一致のポイントはありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Stepwise Extractive Summarization and Planning with Structured
  Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_61.html">
      <font color="black">Stepwise Extractive Summarization and Planning with Structured
  Transformers</font>
    </a>
  </h2>
  <font color="black">構造化トランスフォーマー（HiBERTと拡張トランスフォーマー）を使用した抽出要約のためのエンコーダー中心の段階的モデルを提案します。テストする2つの構造化トランスフォーマーの中で、段階的拡張トランスフォーマーは両方のデータセットで最高のパフォーマンスを提供し、これらの課題の新しい基準を設定します。モデルは、長い入力の構造をモデル化するのに効率的であるだけでなく、タスク固有の冗長性を意識したモデリングに依存しないため、さまざまなタスクの汎用抽出コンテンツプランナーになります。 
[要約]以前に生成された要約を補助サブ構造として構造化トランスフォーマーに抽出することにより、段階的な要約を可能にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Incorporating Behavioral Hypotheses for Query Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_62.html">
      <font color="black">Incorporating Behavioral Hypotheses for Query Generation</font>
    </a>
  </h2>
  <font color="black">私たちの実験結果は、提案されたアプローチが、最近のBARTモデルと比較して、上位$ k $の単語誤り率とバートF1スコアの大幅な改善につながることを示しています。ユーザー入力は、クエリやクリックなどのさまざまな形式で提供され、それぞれが意味する可能性があります。対応する行動パターンを介してチャネル化されたさまざまなセマンティック信号。このペーパーでは、クエリ生成の仮説としてこれらの行動バイアスを誘発します。ここでは、選択した任意の仮説を集約するために、汎用のエンコーダーデコーダートランスフォーマーフレームワークが提示されます。 
[要約]このタスクは通常、条件付き生成の問題として提起されます。一般的なエンコーダー-デコーダートランスフレームワークを使用して、選択した任意の仮説を集約します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Position-Aware Tagging for Aspect Sentiment Triplet Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_63.html">
      <font color="black">Position-Aware Tagging for Aspect Sentiment Triplet Extraction</font>
    </a>
  </h2>
  <font color="black">この作業では、トリプレットを共同で抽出できる新しい位置認識タグ付けスキームを備えた最初のエンドツーエンドモデルを提案します。また、モデルの有効性と堅牢性を調査するために広範な実験を行いました。トリプレット内の3つの要素は互いに高度に関連しているため、シーケンスタグ付けアプローチを使用してそのようなトリプレットを抽出するためのジョイントモデルを構築する動機になります。 
[要約]研究努力は主にパイプラインアプローチを使用して問題を解決します。これらのアプローチはトリプレット抽出プロセスをいくつかの段階に分割します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-task Learning for Multilingual Neural Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_64.html">
      <font color="black">Multi-task Learning for Multilingual Neural Machine Translation</font>
    </a>
  </h2>
  <font color="black">また、bitextトレーニングデータを使用しない言語ペアのゼロショットセットアップで提案されたアプローチの有効性を示します。提案されたアプローチは、高リソース言語と低リソース言語の両方の翻訳品質を大きなマージンで効果的に改善できることを示します。個々のバイリンガルモデルよりも大幅に優れた結果を達成します。さらに、NMTとクロスリンガルトランスファー学習NLUタスクの両方の事前トレーニングアプローチに対するMTLの有効性を示します。提案されたアプローチは、単一のタスクでトレーニングされた大規模なモデルよりも優れています。 
[概要]提案されたマルチタスク学習（mtl）フレームワークは、bitextデータの翻訳タスクと単言語データの2つのノイズ除去タスクを使用してモデルをトレーニングします。提案されたアプローチは、高リソース言語と低リソース言語の両方の翻訳品質を効果的に向上させることができます。マージンが大きい</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: On the Role of Supervision in Unsupervised Constituency Parsing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_65.html">
      <font color="black">On the Role of Supervision in Unsupervised Constituency Parsing</font>
    </a>
  </h2>
  <font color="black">1,700の例でトレーニングする場合、またはトレーニングに50の例、開発に5の例のみを使用する場合でも、このような数ショットの解析アプローチは、教師なし解析方法すべてを大幅に上回ることができます。少数のショットの解析は、次の方法でさらに改善できます。単純なデータ拡張方法と自己トレーニング..アクセスする同じラベル付きの例で既存の教師付き解析モデル（Kitaev and Klein、2018）をトレーニングすることにより、強力なベースラインを導入します。 
[概要]教師なし解析に関する今後の作業のために2つのプロトコルを提案します。これらには、単純なデータ拡張方法と構成要素が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Feature Adaptation of Pre-Trained Language Models across Languages and
  Domains with Robust Self-Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_66.html">
      <font color="black">Feature Adaptation of Pre-Trained Language Models across Languages and
  Domains with Robust Self-Training</font>
    </a>
  </h2>
  <font color="black">自己トレーニングは、トレーニングのターゲットドメインデータ上の疑似ラベルを予測するUDAに広く使用されています。ただし、予測される疑似ラベルには必然的にノイズが含まれ、堅牢なモデルのトレーニングに悪影響を及ぼします。自己トレーニングの堅牢性を向上させるには、この論文では、PrLMから識別機能を学習するためのクラス認識機能自己蒸留（CFd）を紹介します。ここでは、PrLM機能が機能適応モジュールに自己蒸留され、同じクラスの機能がより緊密にクラスター化されます。 
[概要] prlmsの機能を新しいドメインに適応させる方法を開発します。ラベル付きでトレーニングされたモデルをラベルなしのターゲットドメインに適応させます。ただし、予測される疑似ラベルには必然的にノイズが含まれ、トレーニングに悪影響を及ぼします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: AdapterHub: A Framework for Adapting Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_67.html">
      <font color="black">AdapterHub: A Framework for Adapting Transformers</font>
    </a>
  </h2>
  <font color="black">アダプターのダウンロード、共有、およびトレーニングは、トレーニングスクリプトと特殊なインフラストラクチャへの最小限の変更を使用して、可能な限りシームレスに行われます。アダプター（事前にトレーニングされたモデルの各レイヤー内に挿入された小さな学習済みボトルネックレイヤー）は、完全に回避することでこの問題を改善します。モデル全体の微調整..AdapterHubを提案します。これは、さまざまなタスクや言語用に事前にトレーニングされたアダプターの動的な「ステッチイン」を可能にするフレームワークです。 
[概要]フレームワークは、人気のあるハグフェイストランスフォーマーライブラリの上に構築されています。これにより、最先端のモデルを簡単かつ迅速に適応させることができます。これらには、bert、roberta、xlmなどの最先端のモデルが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-15">
        <br><font color="black">2020-07-15</font>
      </time>
    </span>
</section>
<!-- paper0: MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_68.html">
      <font color="black">MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer</font>
    </a>
  </h2>
  <font color="black">MAD-Xは、固有表現抽出と因果的常識推論において、類型的に多様な言語の代表的なセット間での言語間転送において最先端技術を上回り、質問応答で競争力のある結果を達成します。アダプターベースのMAD-Xを提案します。モジュラー言語とタスク表現を学習することにより、任意のタスクと言語への高い移植性とパラメーター効率の高い転送を可能にするフレームワーク。コードとアダプターはAdapterHub.mlで入手できます。
[要約]転送パフォーマンスは、このような低リソース言語で最も弱いです。 。これらの低-事前トレーニング中には見えないリソースと言語が利用可能です。システムはadapterhubで利用可能です。 ml言語</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Metaphor Interpretation Using Word Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_69.html">
      <font color="black">Automatic Metaphor Interpretation Using Word Embeddings</font>
    </a>
  </h2>
  <font color="black">単語連想規範（手がかりに対する一般的な人間の応答）から派生した候補の追加を検討します。最後に、クラスタリングアルゴリズムにより、意味的に関連する重複が削除され、他の候補の解釈がより高いランクになります。ランク付け手順では、候補の解釈と比喩コンポーネントの類似性が考慮されます。 、セマンティックベクトル空間で測定されます。 
[概要]私たちのシステムは、「時は金なり」などの名目上の比喩を処理します。注釈付きの比喩のリストを使用して評価しました。候補は、トピックと車両のコロケーションから抽出されます（「お金」）。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: A Multi-Task Incremental Learning Framework with Category Name Embedding
  for Aspect-Category Sentiment Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_70.html">
      <font color="black">A Multi-Task Incremental Learning Framework with Category Name Embedding
  for Aspect-Category Sentiment Analysis</font>
    </a>
  </h2>
  <font color="black">私たちのモデルは、2つの（T）ACSAベンチマークデータセットで最先端を達成しました。アスペクトカテゴリ感情分析（ACSA）とターゲットアスペクトカテゴリ感情分析（TACSA）を含む（T）ACSAタスクは、感情を特定することを目的としています。事前定義されたカテゴリの極性..（T）ACSAの実際のアプリケーションには、新しいカテゴリの増分学習が必要です。 
[ABSTRACT]（t）acsaの実際のアプリケーションには、新しいカテゴリの増分学習が必要です。この論文では、カテゴリ名埋め込みネットワーク（cne --net）を提案しました。カテゴリカテゴリカテゴリを設定します。これにより、カテゴリカテゴリが弱まります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: ToTTo: A Controlled Table-To-Text Generation Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_71.html">
      <font color="black">ToTTo: A Controlled Table-To-Text Generation Dataset</font>
    </a>
  </h2>
  <font color="black">データセットと注釈プロセスの体系的な分析、およびいくつかの最先端のベースラインによって達成された結果を示します。ToTToは、オープンドメインの英語の表からテキストへのデータセットであり、120,000を超えるトレーニング例を提案します。制御された生成タスク：Wikipediaテーブルと強調表示されたテーブルセルのセットを指定して、1文の説明を生成します。通常は流暢ですが、既存のメソッドは、テーブルでサポートされていないフレーズを注釈することが多く、このデータセットが有用であることを示唆しています。高精度の条件付きテキスト生成のための研究ベンチマーク。 
[概要]アノテーターが既存のウィキペディアの文を直接修正するデータセット構築プロセスを紹介します。既存のメソッドは、テーブルでサポートされていないフレーズを幻覚化することがよくあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br><font color="black">2020-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: TORQUE: A Reading Comprehension Dataset of Temporal Ordering Questions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_72.html">
      <font color="black">TORQUE: A Reading Comprehension Dataset of Temporal Ordering Questions</font>
    </a>
  </h2>
  <font color="black">結果は、RoBERTa-largeがTORQUEのテストセットで51％の完全一致スコアを達成し、人間のパフォーマンスより約30％遅れていることを示しています。TORQUEは、人間の21kのニューススニペット3.2kに基づいて構築された新しい英語の読解ベンチマークです。時間的関係を問う生成された質問。ただし、現在の機械読解ベンチマークには、時間的現象をテストする質問がほとんどないため、これらのベンチマークでトレーニングされたシステムには、「
[何らかのイベント]の前後に何が起こったのか」などの質問に答える能力がありません。 
[概要]コンピューター読解ベンチマークには質問に答える能力がありません。現在の機械読解ベンチマークベンチマークにはほとんど質問がありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: COSMIC: COmmonSense knowledge for eMotion Identification in
  Conversations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_73.html">
      <font color="black">COSMIC: COmmonSense knowledge for eMotion Identification in
  Conversations</font>
    </a>
  </h2>
  <font color="black">現在の最先端の方法では、コンテキストの伝播、感情シフトの検出、および関連する感情クラスの区別が困難になることがよくあります。精神状態、イベント、因果関係などの常識のさまざまな要素を組み込んだ新しいフレームワークであるCOSMICを提案します。関係を構築し、それらに基づいて会話に参加している対話者間の相互作用を学習します。私たちのコードはhttps://github.com/declare-lab/conv-emotionで入手できます。 
[概要]私たちは、さまざまなタイプの常識に対処する新しいフレームワークである宇宙を提案します。これらには、精神状態、イベント、および因果関係が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Dissecting Span Identification Tasks with Performance Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_74.html">
      <font color="black">Dissecting Span Identification Tasks with Performance Prediction</font>
    </a>
  </h2>
  <font color="black">パフォーマンス予測を介してスパンIDタスクを分析し、ニューラルアーキテクチャがさまざまなタスクでどの程度うまく機能するかを推定します。たとえば、スパン頻度はLSTMにとって特に重要であり、CRFは、スパンの頻度が低く、境界が明確でない場合に役立ちます。貢献は次のとおりです。（a）パフォーマンス予測に情報を提供できるスパンIDタスクの主要なプロパティを特定します。 （b）英語のデータに対して大規模な実験を行い、アーキテクチャの選択をサポートできる、見えないスパンIDタスクのパフォーマンスを予測するモデルを構築します。 （c）、メタモデルのパラメーターを調査し、モデルとタスクのプロパティがどのように相互作用してスパンIDのパフォーマンスに影響を与えるかについての新しい洞察をもたらします。 
[概要]パフォーマンス予測に情報を提供できるスパンIDタスクの主要なプロパティを特定します。メタモデルのパラメーターを調査し、スパンID接続がスパンIDパフォーマンスにどのように影響するかについての新しい洞察を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: If beam search is the answer, what was the question? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_75.html">
      <font color="black">If beam search is the answer, what was the question?</font>
    </a>
  </h2>
  <font color="black">これは、MAPの目的だけでは、テキストで必要なプロパティを表現できないことを意味します。これは、質問に値します。ビーム検索が答えである場合、質問は何でしたか。モデルだけでは高い確率が妥当性を示さない理由についての洞察を得るために、ビーム検索を異なるデコード目的の正確なソリューションとしてフレーム化します。非常に驚くべきことに、ニューラル言語ジェネレータの正確な最大事後（MAP）デコードは頻繁につながります。低品質の結果。 
[概要]異なるデコード目的の正確な解決策としてビーム検索をフレーム化します。私たちの目的は、モデルだけで高い確率が適切性を示さない理由についての洞察を得ることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: The Sequence-to-Sequence Baseline for the Voice Conversion Challenge
  2020: Cascading ASR and TTS -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_76.html">
      <font color="black">The Sequence-to-Sequence Baseline for the Voice Conversion Challenge
  2020: Cascading ASR and TTS</font>
    </a>
  </h2>
  <font color="black">実装は、https：//github.com/espnet/espnet/tree/master/egs/vcc20でオープンソース化されています。このペーパーでは、音声変換チャレンジのシーケンス間（seq2seq）ベースラインシステムを紹介します（ VCC）2020 ..オープンソースのエンドツーエンド音声処理ツールキットであるESPnetと、コミュニティが提供する多くの適切に構成された事前トレーニング済みモデルを利用して、シーケンス間（seq2seq）フレームワークの下でこの方法を再検討します。 
[概要]音声変換への素朴なアプローチを検討します。これは、最初に自動音声認識モデルを使用して音声を転写することです。次に、このメソッドを使用して、text2seqによるテキスト読み上げを使用してtext2seqモデルを作成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Discern: Discourse-Aware Entailment Reasoning Network for Conversational
  Machine Reading -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_77.html">
      <font color="black">Discern: Discourse-Aware Entailment Reasoning Network for Conversational
  Machine Reading</font>
    </a>
  </h2>
  <font color="black">文書の解釈とダイアログの理解は、会話型の機械読解の2つの主要な課題です。学習したEDUと含意表現に基づいて、最初の質問の最終決定「はい/いいえ/無関係」にユーザーに返信するか、フォローを生成します。 -詳細を問い合わせるための質問..ShARCベンチマーク（ブラインド、ホールドアウトテストセット）での実験では、Discernが意思決定で78.3％のマクロ平均精度と64.0BLEU1で最先端の結果を達成していることが示されています。フォローアップ質問の生成。 
[要約]識別は談話-認識識別-含意推論ネットワークです。接続を強化し、理解を高めるように設計されています。含意表現の学習に基づいて、ユーザーに最終決定「はい/いいえ/無関係」を返信します。最初の質問</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Conditional Neural Generation using Sub-Aspect Functions for Extractive
  News Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_78.html">
      <font color="black">Conditional Neural Generation using Sub-Aspect Functions for Extractive
  News Summarization</font>
    </a>
  </h2>
  <font color="black">重要性、多様性、位置）。これらのサブアスペクト関数は、サマリー生成中にどのサブアスペクトに焦点を合わせるかを決定するための一連の制御コードによって規制されます。最小の位置バイアスで抽出されたサマリーは、位置設定を利用した標準モデル。 
[ABSTRACT]論文では、要約を制御できるニューラルフレームワークを提案します。これらのサブアスペクト機能は、一連の制御コードによって制御されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br><font color="black">2020-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: Tackling the Low-resource Challenge for Canonical Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_79.html">
      <font color="black">Tackling the Low-resource Challenge for Canonical Segmentation</font>
    </a>
  </h2>
  <font color="black">したがって、標準的なセグメンテーションは、低リソース言語にとって依然として困難なタスクであると結論付けます。高リソース言語のドイツ語、英語、およびインドネシア語のシミュレートされた低リソース設定でのモデルパフォーマンスを、真の新しいデータセットでの実験と比較します。低リソース言語のPopolucaとTepehua ..低リソースの設定では、新しいアプローチは、すべての言語で既存のアプローチよりも最大11.4％の精度で優れていることがわかります。 
[概要]テペワ語とlstmを含む、タスクの2つの新しいモデルを調査します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Ignore: Long Document Coreference with Bounded Memory Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_80.html">
      <font color="black">Learning to Ignore: Long Document Coreference with Bounded Memory Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">すべてのエンティティをメモリに保持する必要はないと主張し、一度に少数の限られた数のエンティティのみを追跡するメモリ拡張ニューラルネットワークを提案します。これにより、ドキュメントの長さの線形ランタイムが保証されます。（a）このモデルは、OntoNotesおよびLitBankでメモリと計算の要件が高いモデルとの競争力を維持し、（b）モデルは、ルールベースの戦略を簡単に上回る効率的なメモリ管理戦略を学習します。現在のモデルのメモリとランタイムの要件。 
[要約]エンティティのグローバル表現のみを使用して行われた調査は、実用的な利点を示していますが、すべてのエンティティをメモリに保持する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Intrinsic Probing through Dimension Selection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_81.html">
      <font color="black">Intrinsic Probing through Dimension Selection</font>
    </a>
  </h2>
  <font color="black">次に、fastTextとBERTを調べて、36の言語にわたるさまざまな形態構文属性を探します。最新のNLPシステムのほとんどは、さまざまなタスクで驚くほど高いパフォーマンスを実現する、事前にトレーニングされたコンテキスト表現を利用しています。ほとんどの属性は、 fastTextがBERTよりも言語構造を集中させているニューロンはほとんどありません。 
[概要]表現に関する豊富な研究が生まれました。分解可能な多変量ガウスプローブを提案します。これにより、単語埋め込みの言語情報が分散しているか、焦点が合っているかを判断できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: SupMMD: A Sentence Importance Model for Extractive Summarization using
  Maximum Mean Discrepancy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_82.html">
      <font color="black">SupMMD: A Sentence Importance Model for Extractive Summarization using
  Maximum Mean Discrepancy</font>
    </a>
  </h2>
  <font color="black">SupMMDは、顕著性のための教師あり学習とカバレッジと多様性のための教師なし学習の両方を組み合わせたものです。DUC-2004とTAC-の現在の最先端技術を満たすか上回ることにより、一般的な要約タスクと更新要約タスクの両方でSupMMDの有効性を示します。 2009年のデータセット..さらに、複数の情報ソース（テキスト機能や知識ベースの概念など）間の類似性を利用するために、複数のカーネル学習を適応させます。 
[ABSTRACT] supmmdは、顕著性のための複数の教師あり学習と、カバレッジと多様性のための教師なし知識を組み合わせたものです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Inference For Neural Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_83.html">
      <font color="black">Efficient Inference For Neural Machine Translation</font>
    </a>
  </h2>
  <font color="black">大型トランスフォーマーモデルは、ニューラル機械翻訳で最先端の結果を達成し、この分野で標準となっています。さまざまなアプローチを積み重ね、デコーダーの自己注意を単純化された反復ユニットに置き換えることの組み合わせを実証する実証研究を実施します。ディープエンコーダーとシャローデコーダーアーキテクチャを採用し、マルチヘッドアテンションプルーニングを使用すると、CPUとGPUでそれぞれ最大109％と84％の速度向上を実現し、BLEUに関して同じ翻訳品質を維持しながら、パラメーターの数を25％削減できます。この作業では、翻訳品質を犠牲にすることなく推論速度を最適化するための既知の手法の最適な組み合わせを探します。 
[概要]この作業では、既知の手法を完璧に組み合わせて最適化速度を最適化する方法を探します。この方法は、いくつかの既知の手法に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Reusing a Pretrained Language Model on Languages with Limited Corpora
  for Unsupervised NMT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_84.html">
      <font color="black">Reusing a Pretrained Language Model on Languages with Limited Corpora
  for Unsupervised NMT</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチであるRE-LMは、英語-マケドニア語（En-Mk）および英語-アルバニア語（En-Sq）の競合するクロスリンガル事前トレーニングモデル（XLM）を上回り、4つの翻訳方向すべてで+ 8.3BLEUポイントを超えます。 。したがって、新しい語彙拡張方法を提案します。事前にトレーニングされたLMを再利用するには、新しい言語を考慮して、事前定義された語彙を変更する必要があります。 
[概要] 1つの言語で利用できるデータが限られている場合、ただし、この方法では翻訳が不十分になります。単一言語のlmは問題ありません。両方の言語で調整され、新しい言語のテストに使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: SubjQA: A Dataset for Subjectivity and Review Comprehension -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_85.html">
      <font color="black">SubjQA: A Dataset for Subjectivity and Review Comprehension</font>
    </a>
  </h2>
  <font color="black">以前の作業の分析と比較対照し、最近開発されたNLPアーキテクチャを使用した場合でも、主観性に関する調査結果が保持されることを確認します。それにもかかわらず、質問応答など、そのようなデータが広まっている状況では主観性は調査されていません（ QA）..主観性とQAパフォーマンスの間の相互作用はより複雑ですが、主観性もQAの場合に重要な機能であることがわかります。 
[概要]顧客のレビューに基づいて、主観性の注釈を含む英語のqaデータセット（subjqa）をリリースします。主観性とqaの間の相互作用はより複雑ですが、主観性もqaの場合の重要な機能です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br><font color="black">2020-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: AGIF: An Adaptive Graph-Interactive Framework for Joint Multiple Intent
  Detection and Slot Filling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_86.html">
      <font color="black">AGIF: An Adaptive Graph-Interactive Framework for Joint Multiple Intent
  Detection and Slot Filling</font>
    </a>
  </h2>
  <font color="black">このようなインタラクションレイヤーは各トークンに適応的に適用され、関連するインテント情報を自動的に抽出し、トークンレベルのスロット予測のためのきめ細かいインテント情報統合を行うという利点があります。この論文では、アダプティブグラフを提案します。共同の複数インテント検出とスロット充填のためのインタラクティブフレームワーク（AGIF）。インテントスロットグラフインタラクションレイヤーを導入して、スロットとインテント間の強い相関関係をモデル化します。実際のシナリオでは、ユーザーは通常、同じ中に複数のインテントを持っています。発話。 
[概要]ほとんどの話し言葉理解（slu）モデルは、主に単一のインテント状態に焦点を当てています-または単にすべてのトークンの全体的なインテントコンテキストツールを組み込んでいます。さらに、私たちのフレームワークは、2つの単一のインテントデータセットで新しい最先端のパフォーマンスを実現します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br><font color="black">2020-04-21</font>
      </time>
    </span>
</section>
<!-- paper0: Help! Need Advice on Identifying Advice -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_87.html">
      <font color="black">Help! Need Advice on Identifying Advice</font>
    </a>
  </h2>
  <font color="black">コメント：EMNLP 2020で発表される予定です。事前にトレーニングされた言語モデルはルールベースのシステムよりも優れたアドバイスを取得できる一方で、アドバイスの特定は困難であり、将来の研究の方向性を特定することを示す予備モデルを提示します。アドバイス談話で豊かな言語現象を明らかにします。 
[概要] 2つのredditアドバイスフォーラムからの英語のデータセットを提示します。事前にトレーニングされた言語モデルはルールベースのシステムよりも優れたアドバイスをキャプチャできるが、アドバイスIDは難しいことを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: QADiscourse -- Discourse Relations as QA Pairs: Representation,
  Crowdsourcing and Baselines -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_88.html">
      <font color="black">QADiscourse -- Discourse Relations as QA Pairs: Representation,
  Crowdsourcing and Baselines</font>
    </a>
  </h2>
  <font color="black">最近、文のさまざまな意味的側面が表現され、質問と回答（QA）のペアを介してクラウドソーシングされています。談話関係は、2つの命題が互いにどのように関連しているかを説明し、それらを自動的に識別することは自然言語理解の不可欠な部分です。 ..ただし、談話関係に注釈を付けるには、通常、専門家の注釈者が必要です。 
[要約]議論はスペイン語に注釈を付けることの欠如に基づいています。主題を特定するには、パラリンピックの専門家の注釈者が必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: T3: Tree-Autoencoder Constrained Adversarial Text Generation for
  Targeted Attack -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_89.html">
      <font color="black">T3: Tree-Autoencoder Constrained Adversarial Text Generation for
  Targeted Attack</font>
    </a>
  </h2>
  <font color="black">特に、離散テキストデータを連続表現空間に埋め込むツリーベースのオートエンコーダを提案し、その上で敵対的摂動を最適化します。大きな懸念が生じましたが、このような敵対的攻撃を利用してNLPモデルの堅牢性を推定できます。次に、新しいツリーベースのデコーダーを適用して、生成されたテキストの構文の正確さを正規化し、文（T3（Sent））または単語（T3（Word））レベルで操作します。 
[ABSTRACT]敵対的攻撃を使用して、nlpモデルの堅牢性を推定できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-22">
        <br><font color="black">2019-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Data Augmentation for Commonsense Reasoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_90.html">
      <font color="black">Generative Data Augmentation for Commonsense Reasoning</font>
    </a>
  </h2>
  <font color="black">私たちの分析は、G-DAUG ^ Cが流暢なトレーニング例の多様なセットを生成し、その選択とトレーニングアプローチがパフォーマンスにとって重要であることを示しています。複数の常識的な推論ベンチマークを使用した実験では、G-DAUG ^ Cは一貫して既存のデータ拡張方法を上回っています。逆翻訳に基づいて、WinoGrande、CODAH、およびCommonsenseQAに新しい最先端技術を確立します。G-DAUG^ Cを調査します。これは、より正確で堅牢な学習を実現することを目的とした新しい生成データ拡張方法です。低リソース設定。 
[概要]私たちのアプローチは、事前にトレーニングされた言語モデルを使用して合成例を生成します。g-daug* c-拡張トレーニングも拡張されます-分布の一般化</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-24">
        <br><font color="black">2020-04-24</font>
      </time>
    </span>
</section>
<!-- paper0: Universal Dependencies according to BERT: both more specific and more
  general -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_91.html">
      <font color="black">Universal Dependencies according to BERT: both more specific and more
  general</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、以前の作業よりも大幅に一貫性のある依存関係ツリーを生成し、BERTの構文抽象化をよりよく説明していることを示しています。 to-one ..関係の識別と構文木の構築の方法を提案します。 
[概要]以前の作業では、個々のバートヘッドが特定の依存関係タイプをエンコードする傾向があることが示されていました。最小限の監視で正常に適用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: Minimize Exposure Bias of Seq2Seq Models in Joint Entity and Relation
  Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_92.html">
      <font color="black">Minimize Exposure Bias of Seq2Seq Models in Joint Entity and Relation
  Extraction</font>
    </a>
  </h2>
  <font color="black">トリプレット内のデコード長を3に制限し、トリプレット間の順序を削除することにより、露出バイアスの影響を最小限に抑えるための新しいシーケンスから順序なしマルチツリー（Seq2UMTree）モデルを提案します。ただし、Seq2Seqは順序付けられていないトリプレットであり、エラーの蓄積に関連する長いデコード長が含まれます。実験では、最先端のSeq2Seqモデルが両方のデータセットに適合しているのに対し、Seq2UMTreeは大幅に優れた一般化を示しています。 
[ABSTRACT]以前の作業では、トリプレットシーケンスシーケンスのシーケンスからシーケンス（seq2seq）モデルを活用します。これらは露出バイアスを導入し、モデルが頻繁なラベルの組み合わせに適合しすぎて、一般化が悪化する可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Embedding Words in Non-Vector Space with Unsupervised Graph Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_93.html">
      <font color="black">Embedding Words in Non-Vector Space with Unsupervised Graph Learning</font>
    </a>
  </h2>
  <font color="black">微分可能な重み付きグラフの形式でデータの表現を学習する最近の方法を採用し、それを使用してGloVeトレーニングアルゴリズムを変更します。分析により、学習したグラフの構造は階層的であり、WordNetの構造と類似していることがわかります。は非常に重要であり、異なるローカルトポロジのサブグラフが含まれています。グラフベースの表現が、単語の類似性と類推タスクでベクトルベースの方法よりも大幅に優れていることを示します。 
[ABSTRACT]単語は潜在構造を持つグラフを形成し、この構造は単語の埋め込みによって明らかにされる必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Attackable Sentences in Arguments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_94.html">
      <font color="black">Detecting Attackable Sentences in Arguments</font>
    </a>
  </h2>
  <font color="black">これらの調査結果に基づいて、機械学習モデルが引数内の攻撃可能な文を自動的に検出できることを示します。これは、いくつかのベースラインよりも大幅に優れており、一般の人々にも匹敵します。引数内の攻撃の推進理由を分析し、文の関連する特性を特定します。文の攻撃可能性は、文の内容、提案タイプ、およびトーンに関するこれらの特性の多くに関連付けられており、外部の知識ソースが攻撃可能性に関する有用な情報を提供できます。 
[概要]文の攻撃性がこれらの特性の多くに関連していることを示します。外部の知識ソースは、攻撃性に関する有用な情報を提供できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchical Graph Network for Multi-hop Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_95.html">
      <font color="black">Hierarchical Graph Network for Multi-hop Question Answering</font>
    </a>
  </h2>
  <font color="black">HotpotQAベンチマークでの実験は、提案されたモデルが既存のマルチホップQAアプローチを上回り、新しい最先端技術を実現することを示しています。この階層グラフが与えられると、初期ノード表現はグラフ伝播によって更新され、マルチホップ推論はトラバースによって実行されます。後続の各サブタスク（たとえば、段落選択、ファクト抽出のサポート、回答予測）のグラフエッジを介して。異種ノードを統合された統合グラフに織り込むことにより、ノードの粒度のこの階層的な差別化により、HGNはさまざまな質問回答サブタスクをサポートできます。同時にタスク。 
[概要]質問、段落、文、エンティティに答えるのに役立つニューヨークベースのシステムが作成されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-09">
        <br><font color="black">2019-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: LEGAL-BERT: The Muppets straight out of Law School -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_96.html">
      <font color="black">LEGAL-BERT: The Muppets straight out of Law School</font>
    </a>
  </h2>
  <font color="black">また、ダウンストリームタスクを微調整する際に、より広いハイパーパラメータ検索スペースを提案し、法的なNLP研究、計算法、および法的な技術アプリケーションを支援することを目的としたBERTモデルのファミリであるLEGAL-BERTをリリースします。 ）元のBERTをそのまま使用し、（b）ドメイン固有のコーパスで追加の事前トレーニングによってBERTを適応させ、（c）ドメイン固有のコーパスでBERTを最初から事前トレーニングします。事前トレーニングと微調整については、しばしば盲目的に行われますが、法的な領域で常にうまく一般化されるとは限りません。 
[概要]その適応ガイドラインに関する調査は限られています。既存のガイドラインは、法的な領域で常にうまく一般化されるとは限りません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: A Novel Challenge Set for Hebrew Morphological Disambiguation and
  Diacritics Restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_97.html">
      <font color="black">A Novel Challenge Set for Hebrew Morphological Disambiguation and
  Diacritics Restoration</font>
    </a>
  </h2>
  <font color="black">新しいデータセットを活用して、21語すべてで新しい最先端技術を実現し、全体の平均F1スコアを0.67から0.95に向上させます。ヘブライ語の同綴異義語（この種の最初のもの）にチャレンジセットを提供します。 21のヘブライ語同綴異義語の各分析の実質的な証明が含まれています。この論文では、ヘブライ語の不均衡な形態学的曖昧さの問題に対処します。 
[要約]この論文では、ヘブライ語における不均衡な経営の曖昧さの問題に取り組んでいます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Investigating African-American Vernacular English in Transformer-Based
  Text Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_98.html">
      <font color="black">Investigating African-American Vernacular English in Transformer-Based
  Text Generation</font>
    </a>
  </h2>
  <font color="black">さらに、GPT-2で生成されたAAVEおよびSAEテキストの人間による評価を実施して、コンテキストの厳密さと全体的な品質を比較します。インテントと同等の並列AAVE / SAEツイートペアのデータセットを作成することにより、AAVEテキストでのGPT-2のパフォーマンスを調査します。 、それにより、各ペアの構文構造とAAVEまたはSAE固有の言語を分離します。ソーシャルメディアの成長により、伝統的に口頭でのみ使用されてきたアフリカ系アメリカ人英語（AAVE）の書面による使用が促進されました。 
[ABSTRACT] aave textは、saeよりも否定的な感情の分類を増やします。しかし、gpt -2を使用すると、一般に、両方の肯定的な感情の発生が増加します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Converting the Point of View of Messages Spoken to Virtual Assistants -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_99.html">
      <font color="black">Converting the Point of View of Messages Spoken to Virtual Assistants</font>
    </a>
  </h2>
  <font color="black">また、LSTM、CopyNet、T5などのニューラル機械翻訳（NMT）アプローチについても調査しました。CopyNetのパラメーターもT5の37分の1です。自然性と忠実度の両方を自動的に測定するために5つの指標を検討し、BLEUplusを使用することにしました。自然性のために個別にトレーニングされた言語モデル（GPT）を使用して、忠実さと相対的な困惑のためのMETEOR。 
[概要]仮想アシスタントは、「私は彼を愛しています」というメッセージを抽出して、bobという名前のユーザーの連絡先に送信できます。仮想アシスタントは、線形テキスト分類モデル、品詞tagging.weを統合するルールベースのモデルを開発しました。別々に訓練された言語モデルを使用して、忠実さと相対的な困惑のためにブループラス流星を使用しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: On the Interplay Between Fine-tuning and Sentence-level Probing for
  Linguistic Knowledge in Pre-trained Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_100.html">
      <font color="black">On the Interplay Between Fine-tuning and Sentence-level Probing for
  Linguistic Knowledge in Pre-trained Transformers</font>
    </a>
  </h2>
  <font color="black">一部のプロービングタスクでは、微調整によって精度が大幅に変化することがわかりました。これは、微調整によって、事前にトレーニングされたモデルから言語知識が導入または削除されることを示唆している可能性があります。調査結果に基づいて、正と負の両方の効果があると主張します。プロービングの微調整には注意深い解釈が必要です。同時に、プロービングは、事前にトレーニングされたモデルによって取得された言語知識を調査する方法として登場しました。 
[ABSTRACT]微調整により、一部のプロービングタスクの精度が大幅に変化します。これは、事前にトレーニングされたモデルから言語知識を追加または削除することを示唆しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Collaborative Agents with Rule Guidance for Knowledge Graph
  Reasoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_101.html">
      <font color="black">Learning Collaborative Agents with Rule Guidance for Knowledge Graph
  Reasoning</font>
    </a>
  </h2>
  <font color="black">別のアプローチは、従来のシンボリック手法（ルール誘導など）を使用することです。これは、優れたパフォーマンスを実現しますが、シンボリック表現の制限のために一般化するのが難しい場合があります。ウォークベースのモデルは、ナレッジグラフ（KG）の推論で利点を示しています。解釈可能な決定を提供しながら適切なパフォーマンスを達成することによって..ベンチマークデータセットでの実験は、RuleGuiderが解釈可能性を失うことなく歩行ベースのモデルのパフォーマンスを改善することを示しています。 
[ABSTRACT] ruleguiderは、歩行ベースのエージェントに報酬の監視を提供するために使用されます。ただし、報酬信号の欠如は、歩行ベースのモデルをガイドするのに十分ではありません。ruleguiderは、歩行ベースのエージェントに報酬の監視を提供するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: Robustness and Reliability of Gender Bias Assessment in WordEmbeddings:
  The Role of Base Pairs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_102.html">
      <font color="black">Robustness and Reliability of Gender Bias Assessment in WordEmbeddings:
  The Role of Base Pairs</font>
    </a>
  </h2>
  <font color="black">これらの性別ペアへの依存には強い制限があることを示します。それらに基づくバイアス測定は堅牢ではなく、現実世界のバイアスの一般的なタイプを識別できませんが、それらを利用するアナロジーはバイアスの不適切な指標です。埋め込みは性別による偏見を示す可能性があり、これを定量化するためにさまざまな方法が提案されています。特に、「男性はコンピュータープログラマーに対して、女性は主婦に対して」というよく知られたアナロジーは、社会的偏見ではなく単語の類似性によるものです。 
[概要]この方法は、データから継承された社会的ステレオタイプをキャプチャします。バイアスを測定し、バイアスされたアナロジーを抽出するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Fast semantic parsing with well-typedness guarantees -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_103.html">
      <font color="black">Fast semantic parsing with well-typedness guarantees</font>
    </a>
  </h2>
  <font color="black">精度を維持または改善しながら、適切な型指定を保証し、解析速度を最大3桁向上させる、AM依存解析用のA *パーサーと遷移ベースのパーサーについて説明します。AM依存解析は言語的に原理的なニューラルの方法です。複数のグラフバンク間で高精度のセマンティック解析。セマンティックバレンシーをモデル化するタイプシステムに依存しますが、既存のパーサーを遅くします。 
[ABSTRACT]セマンティックバレントをモデル化する型システムに依存していますが、既存のパーサーを遅くします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Semantic Evaluation for Text-to-SQL with Distilled Test Suites -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_104.html">
      <font color="black">Semantic Evaluation for Text-to-SQL with Distilled Test Suites</font>
    </a>
  </h2>
  <font color="black">対照的に、現在のSpiderメトリックは、平均2.5％、最悪の場合8.1％の偽陰性率につながり、テストスイートの精度が必要であることを示しています。提案された方法を使用して、Spiderリーダーボードに提出された21のモデルを評価します。 100の例で私たちの方法が常に正しいことを手動で確認します。私たちの実装は、11のText-to-SQLデータセット用の蒸留されたテストスイートとともに公開されています。 
[概要]提案された方法を使用して、スパイダーリーダーボードに提出された21のモデルを評価し、100の例で私たちの方法が常に正しいことを手動で確認します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: DaNetQA: a yes/no Question Answering Dataset for the Russian Language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_105.html">
      <font color="black">DaNetQA: a yes/no Question Answering Dataset for the Russian Language</font>
    </a>
  </h2>
  <font color="black">タスク転送では、3つの類似した文モデリングタスクを活用します：1）言い換えのコーパス、言い換え、2）XNLIのロシア語部分を使用するNLIタスク、3）別の質問応答タスク、SberQUAD ..各質問はペアになっています。ウィキペディアのパラグラフとそのパラグラフから派生した回答を使用して、バイナリ出力を生成します。 
[概要]自然な「はい」または「いいえ」の質問で構成されます。タスクは、質問と段落の両方を入力として受け取ることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Attention Is All You Need for Chinese Word Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_106.html">
      <font color="black">Attention Is All You Need for Chinese Word Segmentation</font>
    </a>
  </h2>
  <font color="black">実験結果は、最高のセグメンテーション速度で、提案されたモデルが厳密なクローズドテスト設定の観点から強力なベースラインに対して新しい最先端または同等のパフォーマンスを達成することを示しています。私たちのモデルはSIGHANBakeoffベンチマークデータセットで評価されます。効果的なエンコーダー設計であるため、モデルはスコアリングにユニグラム機能を使用するだけで済みます。 
[概要]私たちのモデルは、注意のみのスタックエンコーダーと十分に軽いデコーダーで構成されています。さらに、よりスムーズなトレーニングのための2つの高速道路接続</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-31">
        <br><font color="black">2019-10-31</font>
      </time>
    </span>
</section>
<!-- paper0: Joint Semantics and Data-Driven Path Representation for Knowledge Graph
  Inference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_107.html">
      <font color="black">Joint Semantics and Data-Driven Path Representation for Knowledge Graph
  Inference</font>
    </a>
  </h2>
  <font color="black">より具体的には、ホーンルールを注入して、透過的で説明可能なパス構成手順によって凝縮パスを取得します。提案されたモデルは、リンク予測とパスクエリ応答タスクの2つのクラスのタスクで評価されます。さらに、一部のメソッドはリレーショナルのみを考慮します。パスに含まれるエンティティとリレーション間の異質性を無視するか、無視します。これにより、パスの豊富なセマンティクスを適切にキャプチャできなくなります。 
[ABSTRACT]パスベースの推論モデルは、kgの純粋なトリプル以外のパスで多くの情報を活用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Mask Generator: Learning to Generate Adaptive Word Maskings for
  Language Model Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_108.html">
      <font color="black">Neural Mask Generator: Learning to Generate Adaptive Word Maskings for
  Language Model Adaptation</font>
    </a>
  </h2>
  <font color="black">最適な適応マスキングを自動的に学習することにより、言語モデルとしてBERTとDistilBERTを使用して、いくつかの質問応答とテキスト分類データセットでニューラルマスクジェネレーター（NMG）を検証します。これは、ルールベースのマスキング戦略よりも優れています。具体的には、質問応答を学習します。 、ターゲット言語モデルのさらなる事前トレーニングに生成されたマスクを使用することで、見えないテキストのタスクパフォーマンスを向上させることができるように、マスキングポリシーを学習する新しい強化学習ベースのフレームワークを提示します。 
[概要]テキストメッセージで、単語の相対的な重要性を考慮できるトランスフォーマーベースのポリシーネットワークを提案します。システムは、人々がそれを使用する可能性が高いという事実に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Induced Curriculum Learning in Self-Supervised Neural Machine
  Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_109.html">
      <font color="black">Self-Induced Curriculum Learning in Self-Supervised Neural Machine
  Translation</font>
    </a>
  </h2>
  <font color="black">そのように言われずに、モデルが（i）複雑さおよび（ii）タスク関連性の増加するサンプルを（iii）ノイズ除去カリキュラムの実行と組み合わせて自己選択する方法を示します。ガニングフォグの読みやすさの指標であるSSNMTは、高校生に適したWikipediaデータからの抽出と学習を開始し、1年生の学部生に適したコンテンツにすばやく移行します。両方のシステム内部表現タイプの相互監視信号のダイナミクスを観察します。抽出と翻訳のパフォーマンスに不可欠です。 
[ABSTRACT]トレーニング中にssnmtモデルが行うサンプリング選択の詳細な分析</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br><font color="black">2020-04-07</font>
      </time>
    </span>
</section>
<!-- paper0: On the Branching Bias of Syntax Extracted from Pre-trained Language
  Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_110.html">
      <font color="black">On the Branching Bias of Syntax Extracted from Pre-trained Language
  Models</font>
    </a>
  </h2>
  <font color="black">事前にトレーニングされた言語モデルからConstituencyツリーを抽出することに多くの努力が注がれ、多くの場合、機能の定義と解析の2つの段階で進行します。実験によると、いくつかの既存の作業は分岐バイアスを示し、これら3つの要素の実装によっては分岐バイアスが発生する可能性があります。 ..この作業では、言語モデルと抽出方法の両方に依存しない、言語とその逆言語のパフォーマンスギャップを比較することにより、分岐バイアスを定量的に測定することを提案します。 
[概要]この種のメソッドは、分岐バイアスの問題に悩まされる可能性があります。これにより、バイアスがかかっているのと同じ分岐を持つ言語でのパフォーマンスが膨らみます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: GRUEN for Evaluating Linguistic Quality of Generated Text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_111.html">
      <font color="black">GRUEN for Evaluating Linguistic Quality of Generated Text</font>
    </a>
  </h2>
  <font color="black">入力として人間の参照を必要とするほとんどの既存の評価メトリックとは異なり、GRUENは参照がなく、システム出力のみを必要とします。生成されたテキストの文法性、非冗長性、焦点、構造、および一貫性を評価するためにGRUENを提案することにより、このギャップを埋めます。 。4つの言語生成タスクにわたる7つのデータセットでの実験は、提案されたメトリックが人間の判断と高度に相関していることを示しています。 
[概要]メトリクスは、システムの文法的な品質の側面にほぼ排他的に焦点を当てています。例として、教師なしで、決定論的で、さまざまなタスクに適応できる必要があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: The Multilingual Amazon Reviews Corpus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_112.html">
      <font color="black">The Multilingual Amazon Reviews Corpus</font>
    </a>
  </h2>
  <font color="black">言語ごとに、トレーニング、開発、テストセットにそれぞれ200,000、5,000、5,000のレビューがあります。データセットの各レコードには、レビューテキスト、レビュータイトル、星評価、匿名のレビュー担当者ID、匿名化された製品ID、および粗粒度の製品カテゴリ（「本」、「アプライアンス」など）。 MAEは評価の序数の性質を説明するため、このタスクでは分類精度の代わりに平均絶対誤差（MAE）を使用することを提案します。 
[概要]コーパスには、英語、日本語、ドイツ語、フランス語、スペイン語、中国語のレビューが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Pretrained Language Model Embryology: The Birth of ALBERT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_113.html">
      <font color="black">Pretrained Language Model Embryology: The Birth of ALBERT</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、ALBERTが事前トレーニング中にさまざまな学習速度でさまざまな品詞（POS）のトークンを再構築および予測することを学習することを示しています。https：//github.com/d223302/で結果を再現するためのソースコードと事前トレーニング済みモデルを提供します。 albert-embryology ..これらの調査結果は、事前トレーニング済みモデルの知識が事前トレーニング中に変化することを示唆しており、事前トレーニングのステップが多いからといって、必ずしもモデルに包括的な知識が提供されるとは限りません。 
[ABSTRACT] albert-事前訓練された言語モデルの発生学-は事前訓練者によって研究されました。調査結果は、ランダムに初期化されたパラメータのセットから全能性言語モデルへのステップに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: AutoETER: Automated Entity Type Representation for Knowledge Graph
  Embedding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_114.html">
      <font color="black">AutoETER: Automated Entity Type Representation for Knowledge Graph
  Embedding</font>
    </a>
  </h2>
  <font color="black">4つのデータセットでの実験は、リンク予測タスクの最先端のベースラインと比較して、モデルの優れたパフォーマンスを示しています。タイプクラスタリングの視覚化により、タイプの埋め込みの説明が明確になり、モデルの有効性が検証されます。最近の進歩知識グラフ埋め込み（KGE）では、連続ベクトル空間でエンティティと関係を表現できます。任意のKGの型情報を調べるために、自動エンティティTypE表現（AutoETER）を使用して新しいKGEフレームワークを開発します。これは、の潜在的な型埋め込みを学習します。各関係を、関係を意識した投影メカニズムを備えた2つのエンティティのタイプ間の変換操作と見なすことにより、各エンティティ。 
[ABSTRACT]従来のkgeモデルは、各関係を2つのエンティティのタイプ間の変換操作と見なすことにより、各エンティティの潜在的なタイプの埋め込みを学習できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-25">
        <br><font color="black">2020-09-25</font>
      </time>
    </span>
</section>
<!-- paper0: Data Rejuvenation: Exploiting Inactive Training Examples for Neural
  Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_115.html">
      <font color="black">Data Rejuvenation: Exploiting Inactive Training Examples for Neural
  Machine Translation</font>
    </a>
  </h2>
  <font color="black">WMT14英語-ドイツ語および英語-フランス語データセットの実験結果は、提案されたデータの若返りが一貫して、いくつかの強力なNMTモデルのパフォーマンスを大幅に改善することを示しています。次に、アクティブな例で若返りモデルをトレーニングします。これは、ラベルの付け直しに使用されます。順方向翻訳を伴う非アクティブな例..提案されたフレームワークは、3つのフェーズで構成されています。 
[概要]大規模データの複雑なパターンと潜在的なノイズにより、トレーニングモデルが困難になります。データのこれらの複雑なパターンは、トレーニングが困難であることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient One-Pass End-to-End Entity Linking for Questions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_116.html">
      <font color="black">Efficient One-Pass End-to-End Entity Linking for Questions</font>
    </a>
  </h2>
  <font color="black">コードとデータはhttps://github.com/facebookresearch/BLINK/tree/master/elqで入手できます。推論時間が非常に速い（単一CPUで1.57例/秒）ため、ELQはダウンストリームの質問応答システムに役立ちます。概念実証実験では、ELQを使用するとGraphRetrieverのダウンストリームQAパフォーマンスが大幅に向上することを示しています。 （arXiv：1911.03868）。 
[ABSTRACT] elqは、それぞれ12.7％と19.6％f1の大幅なマージンで、以前の最先端技術を上回っています。概念実証実験では、elqを使用するとgraphretriechのダウンストリームqaパフォーマンスが大幅に向上することを示しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: HybridQA: A Dataset of Multi-Hop Question Answering over Tabular and
  Textual Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_117.html">
      <font color="black">HybridQA: A Dataset of Multi-Hop Question Answering over Tabular and
  Textual Data</font>
    </a>
  </h2>
  <font color="black">質問は、表形式の情報とテキスト情報の両方を集約するように設計されています。つまり、どちらの形式もないと、質問に答えられなくなります。2）テキストのみのモデル。ただし、ハイブリッドモデルのスコアは依然として人間のパフォーマンスよりはるかに遅れています。 
[概要]質問は、ウィキペディアの表と、表のエンティティにリンクされた複数の自由形式のコーパスに沿っています。結果は、さまざまな種類の情報の分析に基づいています。これにより、深刻なハイブリッドが発生する可能性があります。基準</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-15">
        <br><font color="black">2020-04-15</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Coalgebras in Stylometry -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_118.html">
      <font color="black">Towards Coalgebras in Stylometry</font>
    </a>
  </h2>
  <font color="black">著者、ジャンルなど）。さらに、ポイントの動作距離は、多項式時間アルゴリズムで近似できます。テキストの構文動作は、コンテキストによって大きく異なる可能性があります（たとえば、
[ABSTRACT] coalgebrasを使用して形式化する与えられたテキストの構文的特徴を確率的遷移システムに埋め込むことによる行動の概念</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: UDapter: Language Adaptation for Truly Universal Dependency Parsing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_119.html">
      <font color="black">UDapter: Language Adaptation for Truly Universal Dependency Parsing</font>
    </a>
  </h2>
  <font color="black">結果として得られるパーサーUDapterは、高リソース言語と低リソース（ゼロショット）言語の両方で、強力な単一言語および多言語のベースラインを上回り、提案された適応アプローチの成功を示しています。詳細な分析により、ソフトパラメーターが示されています。類型的特徴を介した共有は、この成功の鍵です。これに対処するために、コンテキストパラメータの生成とアダプタモジュールに基づく新しい多言語タスク適応アプローチを提案します。 
[概要]このアプローチにより、言語間でモデルパラメータを共有しながら、言語の埋め込みを介してアダプタを学習できます。結果として得られるパーサー、udapterは、高リソース言語と低リソース（ゼロショット）言語の両方で、強力な単一言語および多言語のベースラインを上回ります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br><font color="black">2020-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: Iterative Domain-Repaired Back-Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_120.html">
      <font color="black">Iterative Domain-Repaired Back-Translation</font>
    </a>
  </h2>
  <font color="black">この目的のために、単一言語の文を往復翻訳することによってDRモデルトレーニングに対応するデータを構築し、次に、ペアのDRモデルとNMTモデルを共同で最適化する統合トレーニングフレームワークを設計します。特定のドメイン間およびからのNMTモデルの適応に関する実験一般的なドメインから特定のドメインへのアプローチは、提案されたアプローチの有効性を示しており、未適応モデルおよび逆変換よりも平均して15.79および4.47 BLEUの改善を達成しています。ただし、合成並列データは、不完全なドメイン外によって生成されるため、非常にノイズが多くなります。システムの結果、ドメイン適応のパフォーマンスが低下します。 
[概要]新しい戦略は、バック翻訳方式を使用したドメイン単一言語データを活用しています。合成バイリンガルデータの翻訳を改良するために、ドメイン修復（dr）モデルを導入する新しいシステムを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Finding the Evidence: Localization-aware Answer Prediction for Text
  Visual Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_121.html">
      <font color="black">Finding the Evidence: Localization-aware Answer Prediction for Text
  Visual Question Answering</font>
    </a>
  </h2>
  <font color="black">LaAP-Netは、質問に対する回答を生成するだけでなく、生成された回答の証拠としてバウンディングボックスを予測します。提案されたLaAP-Netは、テキストVQAタスクの3つのベンチマークデータセットに対する既存のアプローチを大幅に上回っています。 、ローカリゼーションタスクを容易にするために、マルチモーダル融合のためのコンテキスト強化OCR表現（COR）が提案されています。 
[要約]テキストベースの視覚的な質問応答（text vqa）タスクは、画像内のテキストを読む必要がある視覚的な質問に焦点を当てています。テキストの位置情報は十分に活用されておらず、生成された回答の証拠が不足しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: DLGNet-Task: An End-to-end Neural Network Framework for Modeling
  Multi-turn Multi-domain Task-Oriented Dialogue -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_122.html">
      <font color="black">DLGNet-Task: An End-to-end Neural Network Framework for Modeling
  Multi-turn Multi-domain Task-Oriented Dialogue</font>
    </a>
  </h2>
  <font color="black">オープンドメインシステムコンポーネントを追加のTODシステムモジュールとして扱うことで、DLGNet-Taskは、自然言語理解（NLU）、状態追跡、アクションポリシーなど、既存のモジュラーアプローチのすべての機能ブロックの入力と出力の同時分布を学習できます。この論文では、新しいフレームワークであるDLGNet-Taskを紹介します。これは、DLGNetやGPT-2 / 3などの自動回帰トランスネットワークを使用してユーザータスクを完了する統合タスク指向の対話システムです。マルチターンマルチドメイン会話で..私たちのフレームワークは、モジュラーアプローチの制御可能で検証可能で説明可能な出力と、エンドツーエンドシステムの低い開発、展開、および保守コストを享受しています。 
[概要]これにより、合理化された国の終わりから国への対話システムのマルチターンマルチドメイン対話生成機能を採用することが困難になりました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-04">
        <br><font color="black">2020-10-04</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Visual-Semantic Embeddings for Reporting Abnormal Findings on
  Chest X-rays -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_123.html">
      <font color="black">Learning Visual-Semantic Embeddings for Reporting Abnormal Findings on
  Chest X-rays</font>
    </a>
  </h2>
  <font color="black">ただし、そのようなモデルはデータバイアス（例：ラベルの不均衡）の影響を受け、テキスト生成モデル（例：繰り返し）に固有の一般的な問題に直面します。私たちの方法が異常な結果を取得でき、両方の臨床で既存の生成モデルよりも優れていることを示します正確性とテキスト生成メトリック..この作業では、放射線画像の異常な所見の報告に焦点を当てます。完全な放射線レポートのトレーニングの代わりに、教師なしクラスタリングと最小限のルールでレポートをグループ化することに加えて、レポートから異常な所見を特定する方法を提案します。 
[概要]レポートに関する既存の作業では、エンコーダー-デコーダーネットワークをトレーニングして完全なレポートを生成することがよくあります。完全なレポートをトレーニングする代わりに、レポートから異常な結果を特定する方法を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Extracting Implicitly Asserted Propositions in Argumentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_124.html">
      <font color="black">Extracting Implicitly Asserted Propositions in Argumentation</font>
    </a>
  </h2>
  <font color="black">2016年の米国大統領選挙討論会とオンライン解説のコーパスでモデルを評価することにより、計算モデルの有効性と限界を示します。ただし、ほとんどの議論マイニングシステムと計算言語学の研究は、議論で暗黙的に主張された提案にほとんど注意を払っていません。これらの修辞ツールは通常、議論に関連する提案をかなり暗黙的に主張するため、それらの真の意味を理解することは、特定の議論を適切に理解するための鍵となります。 
[概要]修辞ツールの使用は、特定の議論を正しく理解するための鍵です。この研究は、議論のマイニングに関する将来の研究に役立つ可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Look at the First Sentence: Position Bias in Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_125.html">
      <font color="black">Look at the First Sentence: Position Bias in Question Answering</font>
    </a>
  </h2>
  <font color="black">まず、BiDAFやBERTなどの一般的な抽出QAモデルでこの位置バイアスを説明し、位置バイアスがBERTの各レイヤーをどのように伝播するかを徹底的に調べます。位置バイアスなしで位置情報を安全に配信するために、エントロピーを含むさまざまなバイアス除去方法でモデルをトレーニングします。正則化とバイアスアンサンブル..多くの抽出質問回答モデルは、回答の開始位置と終了位置を予測するようにトレーニングされています。 
[ABSTRACT]位置が偽の位置の手がかりを学習し、異なる位置で答えを与えることができないため、答えを予測するqaモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: Textual Supervision for Visually Grounded Spoken Language Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_126.html">
      <font color="black">Textual Supervision for Visually Grounded Spoken Language Understanding</font>
    </a>
  </h2>
  <font color="black">リソースの少ない言語を念頭に置いて、文字起こしの代わりに翻訳を効果的に使用できることも示しますが、同様の結果を得るにはより多くのデータが必要です。さまざまな戦略を比較すると、十分なテキストが利用できる場合にパイプラインアプローチの方がうまく機能することがわかります。 。ただし、文字起こしにアクセスできる場合、エンドツーエンドのアプローチが従来のパイプラインベースのアプローチとどのように比較されるかは明確ではありません。 
[概要]これは、トレーニングが困難なリソースが少ない場合に役立ちます。ただし、エンドツーエンドのアプローチが従来のパイプラインベースのアプローチとどのように比較されるかは明確ではありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Explaining The Efficacy of Counterfactually-Augmented Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_127.html">
      <font color="black">Explaining The Efficacy of Counterfactually-Augmented Data</font>
    </a>
  </h2>
  <font color="black">重要なことに、指示は、該当するラベルを反転するために必要のない編集を禁止しています。この作業は、因果的思考、介入としての編集のキャスト、および結果を評価するための人間の理解に依存していますが、根底にある因果モデルは明確ではなく、根底にある原則もありません。ドメイン外評価で観察された改善。トレーニングデータのスプリアスパターンへの依存度が低い機械学習モデルを作成する試みにおいて、研究者は最近、反事実的に拡張されたデータセットを生成するためのヒューマンインザループプロセスを提案しました。 
[ABSTRACT]人間は、（与えられた）反事実ラベルを適用するようにテキストを修正する必要があります。拡張データは、意味的に無関係な単語への依存度が低く、ドメイン外でより一般化することが示されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Grammatical Error Correction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_128.html">
      <font color="black">Adversarial Grammatical Error Correction</font>
    </a>
  </h2>
  <font color="black">弁別子は文ペア分類モデルであり、文法的に正しくない正しい文の特定のペアを文法的修正の品質で判断するように訓練されています。FCE、CoNLL-14、およびBEA-19データセットの実験結果は、Adversarial-GECがNMTベースのベースラインと比較して競争力のあるGEC品質を実現します。並列テキストでディスクリミネーターとジェネレーターの両方を事前トレーニングし、ポリシーグラジエントメソッドを使用してそれらをさらに微調整します。文法的に正しくないテキスト。 
[概要]ジェネレーター、トランスフォーマーモデルは、文法的に正しくない文を与えられた文法的に正しい文を生成するように訓練されています。ジェネレーターは、文法的に正しい単語を与えられた文法的に正しい単語を作成するように訓練されたトランスフォーマーマシンです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Probing Text Models for Common Ground with Visual Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_129.html">
      <font color="black">Probing Text Models for Common Ground with Visual Representations</font>
    </a>
  </h2>
  <font color="black">言語と視覚的表現が意図的に一致しない制御実験では、はるかに弱い結果が観察されます。大規模な言語モデルは最近大きな成功を収めていますが、それらの表現にエンコードされているものについてはまだ理解されていないことがたくさんあります。たとえば、形容詞を伴う名詞がより正確な検索につながることを発見した、私たちの実験におけるテキストコンテキストの影響。 
[要約]私たちの調査結果は、言語の基礎に関する新しい洞察を導き出し、いくつかの物理的特性が訓練された言語モデルによってキャプチャされていることを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Discovery of Implicit Gender Bias -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_130.html">
      <font color="black">Unsupervised Discovery of Implicit Gender Bias</font>
    </a>
  </h2>
  <font color="black">私たちの分析は、女性の政治家に向けられた偏ったコメントがどのように混合批判を含んでいるかを示していますが、他の女性の公的人物に向けられたコメントは外見と性化に焦点を当てています。私たちはコメントレベルで女性に対する性的偏見を特定するために監督されていないアプローチを取り、バイアスが含まれている可能性が高い表面テキスト..社会での普及にもかかわらず、主にこの領域での人間の判断が信頼できない可能性があるため、社会的バイアスを特定することは困難です。 
[概要]コメントレベルで女性に対する性差別を特定するために教師なしアプローチを採用しています。私たちの方法では、傾向マッチングと敵対的学習を通じて混乱の影響を軽減します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-17">
        <br><font color="black">2020-04-17</font>
      </time>
    </span>
</section>
<!-- paper0: SUMBT+LaRL: End-to-end Neural Task-oriented Dialog System with
  Reinforcement Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_131.html">
      <font color="black">SUMBT+LaRL: End-to-end Neural Task-oriented Dialog System with
  Reinforcement Learning</font>
    </a>
  </h2>
  <font color="black">SUMBT +は、ユーザーの行動とダイアログの信念の状態を推定し、LaRLは潜在的なシステムのアクション空間をモデル化し、推定されたコンテキストを前提として応答を生成します。エンドツーエンドのダイアログシステムと同様に強化学習の新しい成功基準を提案します。成功基準と評価方法に応じて異なる結果の側面に関する実験的分析を提供します。その結果、私たちのモデルは、コーパスベースの評価で85.4％の新しい最先端の成功率、および81.40の同等の成功率を達成しました。 DSTC8チャレンジによって提供されるシミュレータベースの評価の％。 
[概要] sumbtとlarlは別々に事前トレーニングされ、システム全体が微調整されます。調整すると、ダイアログの成功率が大幅に向上します。新しいシステムは、コーパスベースの評価で85.4％の成功率を達成し、同等の成功率は81です。 .dstc8チャレンジによって提供されるシミュレーターで40％</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Compressing Language Models using Doped Kronecker Products -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_132.html">
      <font color="black">Compressing Language Models using Doped Kronecker Products</font>
    </a>
  </h2>
  <font color="black">より正式には、事前定義されたKP構造の上に非常にスパースなオーバーレイマトリックスを追加するプロセスであるドーピングを提案します。サイズ25 MB x 25x、1.4のLSTMレイヤーを使用した大規模な言語モデルの圧縮を示す実験結果を示します。パープレキシティスコアの％損失..この圧縮方法をドープクロネッカー製品圧縮と呼びます。 
[ABSTRACT] kpは、大規模な自然言語処理タスクに適用されます。ただし、存在する場合、精度が大幅に低下します。これは、co行列ドロップアウト正則化と呼ばれる新しい方法によるものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-24">
        <br><font color="black">2020-01-24</font>
      </time>
    </span>
</section>
<!-- paper0: Modeling Preconditions in Text with a Crowd-sourced Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_133.html">
      <font color="black">Modeling Preconditions in Text with a Crowd-sourced Dataset</font>
    </a>
  </h2>
  <font color="black">両方のタスクを評価すると、今日の大規模な言語モデル（LM）でも、前提条件のモデリングが難しいことがわかります。このペーパーでは、ニュースワイヤーのイベントペア間の\ emph {前提条件}のクラウドソースアノテーションであるPeKoを紹介します。テキスト注釈..私たちの生成結果は、PeKoでLMを微調整すると、生のテキストや時間的に順序付けられたコーパスでトレーニングした場合よりも、より良い条件付き関係が得られることを示しています。 
[概要]新しいコーパスは、前提条件のモデル化を目的とした2つのチャレンジタスクを導入します。これらには、優先順位付け、前提条件の識別、および前提条件の生成が含まれます。これは、前提条件の知識がlmベースの表現だけでは簡単にアクセスできないことを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Analyzing Redundancy in Pretrained Transformer Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_134.html">
      <font color="black">Analyzing Redundancy in Pretrained Transformer Models</font>
    </a>
  </h2>
  <font color="black">私たちの分析に基づいて、元のニューロンの最大10％を使用しながら、97％のパフォーマンスを維持する、効率的な機能ベースの転送学習手順を提示します。この論文では、次の概念を定義することにより、これらの制限の原因を研究します。冗長性。一般的な冗長性とタスク固有の冗長性の2つのクラスに分類されます。2つの一般的な事前トレーニング済みモデル、BERTとXLNetを分析し、表現レベルとよりきめ細かいニューロンレベルでどれだけの冗長性を示すかを調べます。 。 
[ABSTRACT]冗長性は、冗長性と呼ばれる冗長性に基づいています。冗長性は、冗長性と冗長性の一般的な例です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br><font color="black">2020-04-08</font>
      </time>
    </span>
</section>
<!-- paper0: ProtoQA: A Question Answering Dataset for Prototypical Common-Sense
  Reasoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_135.html">
      <font color="black">ProtoQA: A Question Answering Dataset for Prototypical Common-Sense
  Reasoning</font>
    </a>
  </h2>
  <font color="black">このような質問には複数の正解があり、状況によっては他の質問よりも一般的です。複数の競合ベースラインモデルを提示した後でも、人間のパフォーマンスはすべての評価指標でモデルスコアを上回り、意味のあるギャップがあり、挑戦的な性質をサポートしていることがわかりますまた、モデルが回答のランク付けされたリストを出力する必要がある生成的評価タスクを提案します。理想的には、質問のすべての典型的な回答をカバーします。 
[概要]隠された評価セットは、100人の群衆から各質問への回答を収集することによって作成されます-労働者。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-02">
        <br><font color="black">2020-05-02</font>
      </time>
    </span>
</section>
<!-- paper0: An Exploration of Arbitrary-Order Sequence Labeling via Energy-Based
  Inference Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_136.html">
      <font color="black">An Exploration of Arbitrary-Order Sequence Labeling via Energy-Based
  Inference Networks</font>
    </a>
  </h2>
  <font color="black">また、ノイズの多いデータ条件に役立つ高次エネルギーを見つけます。このようなモデルでのトレーニングと推論の難しさに対処するために、エネルギーベースの推論ネットワークの学習フレームワーク（Tu and Gimpel、2018）を使用します。この作業では、ラベルシーケンス全体を考慮するいくつかを含む、シーケンスラベリングのラベル間の複雑な依存関係をキャプチャするためのいくつかの高次エネルギー項を提案します。 
[要約]研究者はますますこれらの問題に深い表現学習を適用していますが、これらのアプローチの構造化されたコンポーネントは通常単純です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Guiding Attention for Self-Supervised Learning with Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_137.html">
      <font color="black">Guiding Attention for Self-Supervised Learning with Transformers</font>
    </a>
  </h2>
  <font color="black">驚いたことに、注意ヘッドの言語特性は必ずしも言語モデリングのパフォーマンスと相関していないこともわかりました。この論文では、双方向トランスフォーマーを使用した効率的な自己教師あり学習を可能にするシンプルで効果的な手法を提案します。実際の事前トレーニングの目的にとらわれず、モデルの収束が速くなり、ベースラインと比較してダウンストリームタスクのパフォーマンスが向上し、リソースの少ない設定で最先端の結果が得られます。 
[要約]私たちのアプローチは、訓練されたモデルの自己注意パターンが非言語的規則性の大部分を含むことを示す簡単な研究によって動機付けられています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: LIMIT-BERT : Linguistic Informed Multi-Task BERT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_138.html">
      <font color="black">LIMIT-BERT : Linguistic Informed Multi-Task BERT</font>
    </a>
  </h2>
  <font color="black">その結果、LIMIT-BERTは言語タスクのパフォーマンスを向上させるだけでなく、正則化効果と言語情報の恩恵を受けて、新しいタスクやドメインへの適応を支援するより一般的な表現につながります。さらに、LIMIT-BERTは言語マスク戦略を採用しています。構文/セマンティックフレーズに対応するすべてのトークンをマスクするセマンティックフレーズマスキング..最近のマルチタスクディープニューラルネットワーク（MT-DNN）（Liu et al。、2019）とは異なり、LIMIT-BERTは言語的に動機付けられており、 BERT学習コーパスと同じように大量の言語タスクデータを提供する半監視方式での学習。 
[概要]バートは言語的に動機付けられており、半教師あり制限で学習しています。バート学習コーパスと同じように、大量の言語情報を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-31">
        <br><font color="black">2019-10-31</font>
      </time>
    </span>
</section>
<!-- paper0: StyleDGPT: Stylized Response Generation with Pre-trained Language Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_139.html">
      <font color="black">StyleDGPT: Stylized Response Generation with Pre-trained Language Models</font>
    </a>
  </h2>
  <font color="black">希望するスタイルに従って応答を生成することは、オープンドメインの対話システムのアプリケーションを拡張する大きな可能性を秘めていますが、トレーニング用の並列データが不足しているために控えています。 2つの公開データセットを使用した包括的な経験的研究は、スタイルの一貫性とコンテキストの一貫性の両方の点で、私たちのモデルが最先端の方法を大幅に上回っていることを示しています。 
[ABSTRACT]スタイルの一貫性とデータの欠如は、言語スキルがどのように必要かを学ぶための鍵です。これらのタイプの言語モデルは、さまざまな自然言語タスクにブレークスルーをもたらしました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: PRover: Proof Generation for Interpretable Reasoning over Rules -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_140.html">
      <font color="black">PRover: Proof Generation for Interpretable Reasoning over Rules</font>
    </a>
  </h2>
  <font color="black">第三に、PROVERは、トレーニングデータの40％のみを使用して、98％のほぼ完全なQA精度を取得します。合成、手書き、および人間が言い換えたルールベースで実験を行い、QAと証明生成の有望な結果を示します。一般化のパフォーマンス..私たちのコードとモデルはhttps://github.com/swarnaHub/PRoverで公開されています
[ABSTRACT]モデルは、証明グラフに対応するノードとエッジを予測することを学習します。テスト結果は、qaと証明生成の強力な一般化を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: A Unified Deep Learning Framework for Short-Duration Speaker
  Verification in Adverse Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/cs.CL/paper_141.html">
      <font color="black">A Unified Deep Learning Framework for Short-Duration Speaker
  Verification in Adverse Environments</font>
    </a>
  </h2>
  <font color="black">私たちの知る限り、これは深層学習フレームワークでこれら3つのモデルを組み合わせた最初の作業です。音響歪み（つまり、ノイズと残響）に対するロバスト性をさらに向上させるために、マスキングベースの音声強調（SE）を適用します。方法..同時に、SVシステムに対する要件が高まっています。特にノイズが多く残響の多い環境では、短い音声セグメントに対して堅牢である必要があります。 
[概要] svシステムは、特にノイズの多い残響のある環境で、短い音声セグメントに適している必要があります。sv、vad、seモデルを統合されたディープラーニングフレームワークに組み合わせます。ノイズによって破損している韓国語の埋め込みデータセットで実験を行います。と残響</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Speech Paralinguistic Approach for Detecting Dementia Using Gated
  Convolutional Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.AS/paper_0.html">
      <font color="black">Speech Paralinguistic Approach for Detecting Dementia Using Gated
  Convolutional Neural Network</font>
    </a>
  </h2>
  <font color="black">PROMPTデータベースでは、4秒の音声データを使用すると74.7％の精度が得られ、患者のすべての音声データを使用すると80.8％に向上します。さらに、3つのクラスの分類問題でこの方法を評価します。軽度認知障害（MCI）クラスを含め、40秒の音声データで60.6％の精度を達成しました。この方法では、平均114秒の音声データを使用してピットコーパスで73.1％の精度が得られます。 
[概要]私たちの方法では、平均114秒の音声データを使用して、ピットコーパスで73.1％の精度が得られます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br><font color="black">2020-04-16</font>
      </time>
    </span>
</section>
<!-- paper0: Independent Vector Analysis with Deep Neural Network Source Priors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.AS/paper_1.html">
      <font color="black">Independent Vector Analysis with Deep Neural Network Source Priors</font>
    </a>
  </h2>
  <font color="black">この論文では、畳み込み音声混合分離を例示的なアプリケーションとして使用して、独立ベクトル解析（IVA）の密度事前分布を研究します。ここで、深部ニューラルネットワークのようなユニバーサル近似器を使用して音声密度の導関数を効率的に推定できることを初めて示します（ DNN）特定のプロキシ分離関連のパフォーマンスインデックスを最適化することによって..IVAのほとんどの既存のソース事前分布は、スピーチの微細構造をキャプチャするには単純すぎます。 
[概要] ivaの既存のソースプライアのほとんどは、スピーチの細かい構造をキャプチャするには単純すぎます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-23">
        <br><font color="black">2020-08-23</font>
      </time>
    </span>
</section>
<!-- paper0: Pay Attention to the cough: Early Diagnosis of COVID-19 using
  Interpretable Symptoms Embeddings with Cough Sound Signal Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.AS/paper_2.html">
      <font color="black">Pay Attention to the cough: Early Diagnosis of COVID-19 using
  Interpretable Symptoms Embeddings with Cough Sound Signal Processing</font>
    </a>
  </h2>
  <font color="black">実験の結果は、モデルがCOVID-19患者の咳と、95.04 $ \ pm $ 0.18％および96.83 $ \ pmのより高い特異性と精度で、いくつかのタイプの非COVID-19咳を区別するためのより優れた堅牢な機能の埋め込みをキャプチャすることを示しています。解釈可能性を維持しながら、それぞれ0.18％ドル。これを書いている時点では、感染の伝播と拡散を制御するための特定の抗ウイルス薬やワクチンは推奨されていません。解釈可能なCOVID-19診断AIフレームワークは、以下に基づいて考案および開発されています。咳は、これらの制限を克服するための機能と症状のメタデータを鳴らします。 
[概要]提案されたフレームワークのパフォーマンスは、医療データセットを使用して評価されました。4つの咳クラスを持つ150人の患者からの328の咳音</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: The Sequence-to-Sequence Baseline for the Voice Conversion Challenge
  2020: Cascading ASR and TTS -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.AS/paper_3.html">
      <font color="black">The Sequence-to-Sequence Baseline for the Voice Conversion Challenge
  2020: Cascading ASR and TTS</font>
    </a>
  </h2>
  <font color="black">実装は次の場所でオープンソースになっています：https：//github.com/espnet/espnet/tree/master/egs/vcc20 .. ESPnetを利用して、シーケンス間（seq2seq）フレームワークの下でこのメソッドを再検討します。オープンソースのエンドツーエンド音声処理ツールキット、およびコミュニティによって提供される多くの適切に構成された事前トレーニング済みモデル。このペーパーでは、音声変換チャレンジ（VCC）2020のシーケンス間（seq2seq）ベースラインシステムを紹介します。 
[概要]音声変換への素朴なアプローチを検討します。これは、最初に自動音声認識モデルを使用して音声を転記することです。次に、このメソッドを使用して、text2seqによるtext-to-speechを使用してtext2seqモデルを作成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: AGIF: An Adaptive Graph-Interactive Framework for Joint Multiple Intent
  Detection and Slot Filling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.AS/paper_4.html">
      <font color="black">AGIF: An Adaptive Graph-Interactive Framework for Joint Multiple Intent
  Detection and Slot Filling</font>
    </a>
  </h2>
  <font color="black">この論文では、共同の複数インテント検出とスロット充填のための適応グラフ-インタラクティブフレームワーク（AGIF）を提案します。ここでは、インテント-スロットグラフ相互作用レイヤーを導入して、スロットとインテント間の強い相関をモデル化します。このような相互作用レイヤーは各トークンに適応的に適用されます。これには、関連するインテント情報を自動的に抽出し、トークンレベルのスロット予測のためのきめ細かいインテント情報の統合を行うという利点があります。さらに、フレームワークは新しい最先端を実現します。 2つのシングルインテントデータセットでのパフォーマンス。 
[概要]ほとんどの話し言葉理解（slu）モデルは、主に単一のインテント状態に焦点を当てています-または単にすべてのトークンの全体的なインテントコンテキストツールを組み込んでいます。さらに、私たちのフレームワークは、2つの単一のインテントデータセットで新しい最先端のパフォーマンスを実現します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br><font color="black">2020-04-21</font>
      </time>
    </span>
</section>
<!-- paper0: The Academia Sinica Systems of Voice Conversion for VCC2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.AS/paper_5.html">
      <font color="black">The Academia Sinica Systems of Voice Conversion for VCC2020</font>
    </a>
  </h2>
  <font color="black">評価では、リスニングテストにより、システムがVCC2020チャレンジで良好に機能することが示されました。タスク1では、TTSモデルの入力として国際音声記号（IPA）を使用しました。タスク2では、監視されていない音声記号を使用しました。ベクトル量子化変分オートエンコーダー（VQVAE）によって抽出されます。 
[ABSTRACT]両方のタスクで、カスケードされたasrtts構造に従いました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Textual Supervision for Visually Grounded Spoken Language Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.AS/paper_6.html">
      <font color="black">Textual Supervision for Visually Grounded Spoken Language Understanding</font>
    </a>
  </h2>
  <font color="black">さまざまな戦略を比較すると、十分なテキストが利用できる場合にパイプラインアプローチの方が効果的であることがわかります。リソースの少ない言語を念頭に置いて、文字起こしの代わりに翻訳を効果的に使用できることも示していますが、同様の結果を得るにはより多くのデータが必要です。 。最近の研究では、トレーニング時に文字起こしが利用可能であれば、これらのモデルを改善できることが示されています。 
[概要]これは、トレーニングが困難なリソースが少ない場合に役立ちます。ただし、エンドツーエンドのアプローチが従来のパイプラインベースのアプローチとどのように比較されるかは明確ではありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: A Unified Deep Learning Framework for Short-Duration Speaker
  Verification in Adverse Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-07/eess.AS/paper_7.html">
      <font color="black">A Unified Deep Learning Framework for Short-Duration Speaker
  Verification in Adverse Environments</font>
    </a>
  </h2>
  <font color="black">結果は、提案された方法が困難な条件でのSVに効果的であり、ベースラインiベクトルおよびディープスピーカー埋め込みシステムよりも優れたパフォーマンスを発揮することを示しています。私たちの知る限り、これはこれら3つのモデルをディープで組み合わせた最初の作業です。学習フレームワーク..ノイズの多い残響のある環境で短い音声セグメントを処理するためのFPMベースのMSAを紹介します。 
[概要] svシステムは、特にノイズの多い残響のある環境で、短い音声セグメントに適している必要があります。sv、vad、seモデルを統合されたディープラーニングフレームワークに組み合わせます。ノイズによって破損している韓国語の埋め込みデータセットで実験を行います。と残響</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
