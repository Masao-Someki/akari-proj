<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<title>Akari-2019-12-25の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
  <div class="header-logo">
    <a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
  </div>
</header>
<input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">

<div class="menubar">
<span class="bar"></span>
<span class="bar"></span>
<span class="bar"></span>
</div>

<ul>
<li><a id="home" href="../../index.html">Home</a></li>
<li><a id="about" href="../../teamAkariとは.html">About</a></li>
<li><a id="contact" href="../../contact.html">Contact</a></li>
<li><a id="contact" href="../../list/newest.html">New Papers</a></li>
<li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
</ul>

</label>
<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Audio-Visual Embodied Navigation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-25/cs.SD/paper_0.html">
      Audio-Visual Embodied Navigation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      複雑な、音響的、視覚的にリアルな3D環境向けのオーディオビジュアルナビゲーションを導入します。視覚と聴覚の両方により、エージェントはオーディオベースのターゲットへのナビゲーションを学習する必要があります。具現化されたエージェントは耳が聞こえません-環境の視覚的知覚のみに制限されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-24">
        <br>2019-12-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Audio-based automatic mating success prediction of giant pandas -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-25/cs.SD/paper_1.html">
      Audio-based automatic mating success prediction of giant pandas
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、オーディオセグメントから音響特徴を抽出し、その特徴をディープニューラルネットワークに送り込み、交配を成功または失敗に分類します。過去9年間に収集されたデータセットの評価実験により有望な結果が得られ、ジャイアントパンダの繁殖を支援する音声ベースの自動交配成功予測方法の可能性が証明されました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-24">
        <br>2019-12-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving EEG based Continuous Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-25/cs.SD/paper_2.html">
      Improving EEG based Continuous Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CTCモデルのエンコーダーでリカレントレイヤーの重みをランダムな重みではなく、より意味のある重みで初期化する手法を導入し、外部言語モデルを使用してデコード時のビーム検索を改善します。この論文では、脳波（EEG）特徴に基づく連続音声認識（CSR）システムのパフォーマンスを改善するためのさまざまな手法を紹介します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-24">
        <br>2019-11-24
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: FALCON 2.0: An Entity and Relation Linking framework over Wikidata -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-25/cs.CL/paper_0.html">
      FALCON 2.0: An Entity and Relation Linking framework over Wikidata
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Falcon 2.0は、英語の形態の基本原則（N-GramタイリングやN-Gram分割など）と、学習した知識グラフから得られたラベルアラインメントの背景知識を使用して出力として返します。結果のエンティティと関係リソースはDBpediaまたはWikidataナレッジグラフのいずれかです。Falcon2.0でWikidataのみを使用して影響を経験的に調査し、知識グラフに依存しない、つまりFalcon 2.0のパフォーマンスと動作は影響を受けません。背景知識として使用される知識グラフ。Falcon2.0は公開されており、コミュニティで再利用できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-24">
        <br>2019-12-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: KnowIT VQA: Answering Knowledge-Based Questions about Videos -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-25/cs.CL/paper_1.html">
      KnowIT VQA: Answering Knowledge-Based Questions about Videos
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このデータセットは、視覚的、テキスト的、時間的一貫性の推論と知識ベースの質問を組み合わせたものであり、シリーズの視聴から得られる経験が必要です。主な調査結果は次のとおりです。ビデオのVQA、および（ii）KnowIT VQAのパフォーマンスは依然として人間の精度よりもかなり遅れており、現在のビデオモデリングの制限を研究するための有用性を示しています。人気のシットコムについて。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-23">
        <br>2019-10-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Abstractive Text Summarization with History Aggregation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-25/cs.CL/paper_2.html">
      Improving Abstractive Text Summarization with History Aggregation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      経験的に、集約メカニズムをTransformerモデルに適用し、CNN / DailyMailデータセットで実験して、ROUGEメトリックのいくつかの強力なベースラインモデルと比較して、より高品質のサマリーを実現します。このモデルでは、履歴情報を確認して、エンコーダがより多くのメモリ容量を保持できるようにします。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-24">
        <br>2019-12-24
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Audio-Visual Embodied Navigation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-25/eess.AS/paper_0.html">
      Audio-Visual Embodied Navigation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      世界を動き回るのは当然のことながら多感覚体験ですが、今日の具体化されたエージェントは耳が聞こえません-環境の視覚的認識のみに制限されています。私たちの結果は、オーディオが3D空間の具体化された視覚ナビゲーションに大いに役立つことを示しています。エージェントは、音声ベースのターゲットへのナビゲートを学習する必要があります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-24">
        <br>2019-12-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Audio-based automatic mating success prediction of giant pandas -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-25/eess.AS/paper_1.html">
      Audio-based automatic mating success prediction of giant pandas
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      交尾中に記録された交尾中のジャイアントパンダのオーディオシーケンスを考えると、まずジャイアントパンダの声でセグメントを切り取り、その大きさと長さを正規化します。次に、オーディオセグメントから音響特徴を抽出し、その特徴を交配を成功または失敗に分類するディープニューラルネットワーク。過去9年間に収集されたデータセットに対する評価実験により有望な結果が得られ、ジャイアントパンダの繁殖を支援するオーディオベースの自動交配成功予測方法の可能性が証明されました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-24">
        <br>2019-12-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Continuous Speech Recognition using EEG and Video -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-25/eess.AS/paper_2.html">
      Continuous Speech Recognition using EEG and Video
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      EEG機能は、連続的な視覚音声認識システムのパフォーマンスを向上させるのに役立つことを示しています。認識を実行するための時間分類（CTC）ベースのエンドツーエンド自動音声認識（ASR）モデル。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-16">
        <br>2019-12-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving EEG based Continuous Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-25/eess.AS/paper_3.html">
      Improving EEG based Continuous Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CTCモデルのエンコーダーでリカレントレイヤーの重みをランダムな重みではなく、より意味のある重みで初期化する手法を紹介し、外部言語モデルを使用して、デコード時のビーム検索を改善します。脳波（EEG）機能に基づく連続音声認識（CSR）システムのパフォーマンスを改善するためのさまざまな手法を紹介します。コネクショニスト時間分類（CTC）ベースの自動音声認識（ASR）システムが認識を実行するために実装されました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-24">
        <br>2019-11-24
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本日更新された論文はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br>
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
