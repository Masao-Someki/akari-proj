<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<title>Akari-2019-12-25の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
  <div class="header-logo">
    <a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
  </div>
</header>
<input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">

<div class="menubar">
<span class="bar"></span>
<span class="bar"></span>
<span class="bar"></span>
</div>

<ul>
<li><a id="home" href="../../index.html">Home</a></li>
<li><a id="about" href="../../teamAkariとは.html">About</a></li>
<li><a id="contact" href="../../contact.html">Contact</a></li>
<li><a id="contact" href="../../list/newest.html">New Papers</a></li>
<li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
</ul>

</label>
<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Audio-Visual Embodied Navigation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-25/cs.SD/paper_0.html">
      Audio-Visual Embodied Navigation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      視覚と聴覚の両方により、エージェントは音声ベースのターゲットへのナビゲートを学習する必要があります。複雑で、音響的および視覚的にリアルな3D環境向けの視聴覚ナビゲーションを導入します。具現化されたエージェントは耳が聞こえません-環境の視覚的知覚のみに制限されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-24">
        <br>2019-12-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Audio-based automatic mating success prediction of giant pandas -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-25/cs.SD/paper_1.html">
      Audio-based automatic mating success prediction of giant pandas
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、オーディオセグメントから音響特性を抽出し、その特性をディープニューラルネットワークに送り込み、交配を成功または失敗に分類します。過去9年間に収集されたデータセットに対する評価実験により、有望な結果が得られ、オーディオの可能性ジャイアントパンダの繁殖を支援するための自動交配成功予測手法..サイレント動物として定型化されたジャイアントパンダは、繁殖期に有意に多くの声を発します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-24">
        <br>2019-12-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving EEG based Continuous Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-25/cs.SD/paper_2.html">
      Improving EEG based Continuous Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、本論文では、EEG特徴から調音特徴を予測する問題を研究します。CTCモデルのエンコーダーでリカレントレイヤーの重みをランダムな重みではなく、より意味のある重みで初期化する手法を導入し、デコード時間中のビーム検索を改善するための外部言語モデル。コネクショニスト時間分類（CTC）ベースの自動音声認識（ASR）システムが認識を実行するために実装されました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-24">
        <br>2019-11-24
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: FALCON 2.0: An Entity and Relation Linking framework over Wikidata -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-25/cs.CL/paper_0.html">
      FALCON 2.0: An Entity and Relation Linking framework over Wikidata
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Falcon 2.0は公開されており、コミュニティで再利用できます。Falcon2.0の入力は、英語の短い自然言語のテキストです。グラム分割）および学習された知識グラフから得られたラベルアラインメントの背景知識が出力として返されます。結果のエンティティと関係リソースは、DBpediaまたはWikidataナレッジグラフにあります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-24">
        <br>2019-12-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: KnowIT VQA: Answering Knowledge-Based Questions about Videos -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-25/cs.CL/paper_1.html">
      KnowIT VQA: Answering Knowledge-Based Questions about Videos
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      主な調査結果は次のとおりです。（i）知識を組み込むことでビデオのVQAに顕著な改善がもたらされ、（ii）KnowIT VQAのパフォーマンスは依然として人間の精度よりかなり遅れており、現在のビデオモデリングの制限を研究するための有用性が示されています。視覚的、テキスト的、時間的コヒーレンス推論と知識ベースの質問、シリーズを視聴して得られる経験が必要です。知識ベースとビデオ質問応答を融合することにより、新しいビデオ理解タスクを提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-23">
        <br>2019-10-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Abstractive Text Summarization with History Aggregation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-25/cs.CL/paper_2.html">
      Improving Abstractive Text Summarization with History Aggregation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      高品質の要約システムは通常、強力なエンコーダーに依存します。強力なエンコーダーは、長い入力テキストから重要な情報を絞り込み、デコーダーがエンコーダーのメモリから重要な要約を生成できるようにします。 、Transformerモデルに集計メカニズムを適用し、CNN / DailyMailデータセットで実験して、ROUGEメトリックのいくつかの強力なベースラインモデルと比較して、より高品質のサマリーを実現します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-24">
        <br>2019-12-24
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Audio-Visual Embodied Navigation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-25/eess.AS/paper_0.html">
      Audio-Visual Embodied Navigation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの結果は、オーディオが3D空間での視覚ナビゲーションに大きなメリットをもたらすことを示しています。複雑で、音響的および視覚的にリアルな3D環境のオーディオビジュアルナビゲーションを導入します。環境に対する視覚的な認識のみに制限されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-24">
        <br>2019-12-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Audio-based automatic mating success prediction of giant pandas -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-25/eess.AS/paper_1.html">
      Audio-based automatic mating success prediction of giant pandas
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      過去9年間に収集されたデータセットの評価実験により有望な結果が得られ、ジャイアントパンダの繁殖を支援するオーディオベースの自動交配成功予測方法の可能性が証明されました。その後、オーディオセグメントから音響特性を抽出し、その特性を提案されたディープニューラルネットワークでは、畳み込み層に続いて双方向ゲートリカレントユニットを使用して、音声の特徴を抽出し、注意メカニズムを適用して、ネットワークが最も関連する特徴に焦点を当てるようにします。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-24">
        <br>2019-12-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Continuous Speech Recognition using EEG and Video -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-25/eess.AS/paper_2.html">
      Continuous Speech Recognition using EEG and Video
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、脳波（EEG）機能を使用して連続視覚音声認識システムのパフォーマンスを改善できるかどうかを調査します。この結果は、EEG機能が連続視覚音声認識システムのパフォーマンス向上に役立つことを示しています。認識を実行するための時間分類（CTC）ベースのエンドツーエンド自動音声認識（ASR）モデル。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-16">
        <br>2019-12-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving EEG based Continuous Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-25/eess.AS/paper_3.html">
      Improving EEG based Continuous Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CTCモデルのエンコーダーでリカレントレイヤーの重みをランダムな重みではなく、より意味のある重みで初期化する手法を導入し、外部言語モデルを使用してデコード時のビーム検索を改善します。この論文では、脳波（EEG）特徴に基づく連続音声認識（CSR）システムのパフォーマンスを改善するためのさまざまな手法を紹介します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-24">
        <br>2019-11-24
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本日更新された論文はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br>
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
