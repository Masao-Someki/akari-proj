<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<title>Akari-2019-12-19の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
  <div class="header-logo">
    <a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
  </div>
</header>
<input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">

<div class="menubar">
<span class="bar"></span>
<span class="bar"></span>
<span class="bar"></span>
</div>

<ul>
<li><a id="home" href="../../index.html">Home</a></li>
<li><a id="about" href="../../teamAkariとは.html">About</a></li>
<li><a id="contact" href="../../contact.html">Contact</a></li>
<li><a id="contact" href="../../list/newest.html">New Papers</a></li>
<li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
</ul>

</label>
<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Detecting Adversarial Attacks On Audio-Visual Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-19/cs.SD/paper_0.html">
      Detecting Adversarial Attacks On Audio-Visual Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      視聴覚相関のプロキシとして同期信頼スコアを使用し、それに基づいて敵の攻撃を検出できます。GRIDおよびLRWデータセットでトレーニングされた2つの視聴覚音声認識モデルに最近の敵の攻撃を適用します。提案されたアプローチがそのような攻撃を検出するための効果的な方法であることを示しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br>2019-12-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Ene-to-end training of time domain audio separation and recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-19/cs.SD/paper_1.html">
      Ene-to-end training of time domain audio separation and recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの実験では、WSJ0-2mixで11.0％の単語誤り率を示し、ジョイントタイムドメインモデルが、これまでに提案されたカスケードDNN-HMMおよびモノリシックE2E周波数ドメインシステムを大幅に改善できることを示しています。 -スピーカーの音声分離により、マルチスピーカー音声認識へのエンドツーエンド（E2E）アプローチの開発が促進されました。この作業を展望し、設計スペースの複雑さを説明するために、シングルチャネルマルチ-話者認識システム。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br>2019-12-18
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: MALA: Cross-Domain Dialogue Generation with Action Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-19/cs.CL/paper_0.html">
      MALA: Cross-Domain Dialogue Generation with Action Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      マルチドメインデータセット、SMDおよびMultiWOZを使用した実験は、提案されたモデルがタスク完了と言語品質の両方の点でベースラインモデルより一貫した改善を達成することを示しています..このようなアクション学習アプローチは、言語面の多様性に影響しやすく、影響を与える可能性がありますタスクの完了と言語の品質。この問題に対処するために、対話の進行に対する発話の効果を区別することにより意味的潜在行動を学習する多段階適応潜在行動学習（MALA）を提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br>2019-12-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Survey on Document-level Machine Translation: Methods and Evaluation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-19/cs.CL/paper_1.html">
      A Survey on Document-level Machine Translation: Methods and Evaluation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これに加えて、この領域の改善を説明するために導入された評価戦略もカバーします。統計的機械翻訳（SMT）の文献について話すときは、翻訳の改善を試みた作品に焦点を当てます。特定の談話現象、ニューラル機械翻訳（NMT）では、より広いコンテキストを明示的に使用する作業に焦点を当てます。このペーパーの目的は、以前のドキュメントレベルの機械翻訳の分野で行われた主要な作業を強調することです。そして、神経革命の後、研究者が私たちがどこから出発し、どの方向に向かっているのかを認識できるようにします。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br>2019-12-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CoSimLex: A Resource for Evaluating Graded Word Similarity in Context -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-19/cs.CL/paper_2.html">
      CoSimLex: A Resource for Evaluating Graded Word Similarity in Context
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、このギャップを埋めることを目的とした新しいデータセットCoSimLexを構築する取り組みについて説明します。最先端の自然言語処理ツールは、コンテキスト依存の単語埋め込みに基づいて構築されていますが、これらの表現を評価する直接的な方法は現在存在しません。標準組み込みの本質的な評価のためのタスクとデータセットは、類似性の判断に基づいていますが、コンテキストは無視します。単語の意味の曖昧性を解消するための標準的なタスクでは、コンテキストが考慮されますが、意味の類似性の継続的な測定は提供されません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-11">
        <br>2019-12-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Curriculum Learning Strategies for IR: An Empirical Study on
  Conversation Response Ranking -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-19/cs.CL/paper_3.html">
      Curriculum Learning Strategies for IR: An Empirical Study on
  Conversation Response Ranking
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この目的のために、会話応答ランキングのタスクに頼ります。会話履歴に基づいて応答をランク付けします。課題（1）に対処するために、スコアリング関数を調べて、異なる入力スペースに基づいて会話の難易度を測定します。両方の課題に対処し、カリキュラム学習がニューラルランキングモデルに有益かどうかを判断するには、大規模なデータセットと、幅広い実験を実行できる検索タスクが必要です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br>2019-12-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-channel Reverse Dictionary Model -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-19/cs.CL/paper_4.html">
      Multi-channel Reverse Dictionary Model
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      辞書の定義と人間が作成した記述の両方を含む英語と中国語のデータセットでモデルを評価します。この作業のすべてのコードとデータは、https：//github.com/thunlp/MultiRDで取得できます。実験結果は、このモデルは最先端のパフォーマンスを実現し、人間が作成した記述データセットで最も人気のある商用逆辞書システムよりも優れています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br>2019-12-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Generating summaries tailored to target characteristics -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-19/cs.CL/paper_5.html">
      Generating summaries tailored to target characteristics
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この目的で、テキスト要約のタスクに関連するこれらの特性に関する分類を提供します。1つは生成する必要のあるコンテンツに焦点を当て、2つ目は出力要約の文体的な側面に焦点を当てます。シーケンスからシーケンスへの要約フレームワークにさまざまなクラスの特性を組み込むための適切な方法について。トピック、読みやすさ、および単純さを組み込む実験は、提案された処方の実行可能性を示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br>2019-12-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Graph-based Model for Joint Chinese Word Segmentation and Dependency
  Parsing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-19/cs.CL/paper_6.html">
      A Graph-based Model for Joint Chinese Word Segmentation and Dependency
  Parsing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      以前の遷移ベースのジョイントモデルとは異なり、提案されたモデルはより簡潔であり、機能エンジニアリングの労力が少なくなります。コードはhttps://github.com/fastnlp/JointCwsParserで公開されています。したがって、単語のセグメンテーションは依存関係の解析の前提条件。これにより、依存関係の解析はエラーの伝播に悩まされ、文字レベルの事前トレーニング済み言語モデル（BERTなど）を直接使用できなくなります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-09">
        <br>2019-04-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Semantic integration of disease-specific knowledge -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-19/cs.CL/paper_7.html">
      Semantic integration of disease-specific knowledge
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      例示的なクエリの結果が表示され、自動的に生成されたセマンティックグラフとして知識を統合およびアクセスするこのアプローチの可能性を調査します。提案されたアプローチは、3つの異なるケーススタディに適用されます。知識が利用可能であり、1つのまれな疾患であるデュシェンヌ型筋ジストロフィーについては、知識が豊富でなく見つけるのが困難です。結果：疾患固有のセマンティックグラフは、特定の概念およびこれらの概念の個々の側面に関連するリソースに簡単にアクセスできる、概念関係および属性の形式で。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br>2019-12-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Collective Embedding-based Entity Alignment via Adaptive Features -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-19/cs.CL/paper_8.html">
      Collective Embedding-based Entity Alignment via Adaptive Features
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最初に、異種KGのエンティティ間の類似性のさまざまな側面をキャプチャするために、構造、セマンティック、および文字列信号という3つの代表的な機能を使用します。適応的特徴融合メカニズムを備えた集合的埋め込みベースのEAフレームワーク。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br>2019-12-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Systematic quantitative analyses reveal the folk-zoological knowledge
  embedded in folktales -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-19/cs.CL/paper_9.html">
      Systematic quantitative analyses reveal the folk-zoological knowledge
  embedded in folktales
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの結果は、動物のキャラクターと物語の中で起こることの組み合わせが実世界の関係を表すという仮説と一致した。我々の分析は、最初に、捕食者と被食者の関係が民話内の共生動物のペアに頻繁に現れることを示唆した。 、ネコとネズミまたはオオカミとブタ）、および2番目に、動物間の敵対的行動を説明する「欺ception」のモチーフは、「野生および家畜」および「野生動物」で他のタイプよりも比較的高いように見えました。 「欺ception」のモチーフは、捕食者と被食者の関係に対応して、ペアでより頻繁に現れました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-09">
        <br>2019-07-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive
  Summarization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-19/cs.CL/paper_10.html">
      PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive
  Summarization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験により、ROUGEスコアで測定された12のすべてのダウンストリームデータセットで最先端のパフォーマンスが達成されていることが実証されました。さらに、多様なドメインにわたる体系的な評価が不足しています。科学、物語、指示、電子メール、特許、および法案。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br>2019-12-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards an automatic recognition of mixed languages: The
  Ukrainian-Russian hybrid language Surzhyk -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-19/cs.CL/paper_11.html">
      Towards an automatic recognition of mixed languages: The
  Ukrainian-Russian hybrid language Surzhyk
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、プログラミング言語Rのツールで作成された例ベースのルールを採用することで、ウクライナ語とロシア語のハイブリッド言語であるSurzhykの要素を特定する最初の試みを提案します。 ）キエフ地域でデル・ガウディオ（2010）によって登録されたスルジクの音声サンプルの分析と書面コーパスの作成。 2）Surzhykパターンの識別とその実装に関する特定のルールの作成。 3）コードのテストと有効性の分析。言語の干渉は、より多くの言語が接触している今日の多言語社会で一般的であり、グローバルな最終結果としてハイブリッド言語の作成につながります。計算言語学の分野で、自動識別とさらなる精緻化の問題が明らかになったことを公式に認められていること。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br>2019-12-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Incremental Sense Weight Training for the Interpretation of
  Contextualized Word Embeddings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-19/cs.CL/paper_12.html">
      Incremental Sense Weight Training for the Interpretation of
  Contextualized Word Embeddings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの結果は、マスクされた単語の埋め込みはパフォーマンスを損なうことなく、3％改善できることを示しています。WSDの強力なベースラインを確立するために、いくつかのKNNアプローチが実験されました。マスクされた単語の埋め込みを単語の意味の曖昧性除去タスク（WSD）に適用し、そのパフォーマンスを元の埋め込みによって達成されたパフォーマンスと比較します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-05">
        <br>2019-11-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Uncovering Relations for Marketing Knowledge Representation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-19/cs.CL/paper_13.html">
      Uncovering Relations for Marketing Knowledge Representation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、エンティティと関係の識別を必要とするコーパスからのマーケティング知識グラフの作成に焦点を当てます。マーケティング知識の2つの広い側面-表現と推論-から、この論文は前者に焦点を当てています。データやモデルとやり取りできる自動化されたマーケティング知識ベース。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br>2019-12-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Ene-to-end training of time domain audio separation and recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-19/cs.CL/paper_14.html">
      Ene-to-end training of time domain audio separation and recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの実験は、WSJ0-2mixで11.0％の単語誤り率を示し、共同時間領域モデルが、これまでに提案されたカスケードDNN-HMMおよびモノリシックE2E周波数領域システムを大幅に改善できることを示します。 E2E音声認識機能を備えた畳み込み時間領域オーディオ分離ネットワーク（Conv-TasNet）に基づくモジュールと、複数のGPUに分散するか、畳み込みフロントエンドの切り捨てられた逆伝搬を近似することにより、そのようなモデルを共同でトレーニングする方法。単一チャネルのマルチスピーカー音声分離への関心の高まりは、マルチスピーカー音声認識へのエンドツーエンド（E2E）アプローチの開発に火をつけました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br>2019-12-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: DMRM: A Dual-channel Multi-hop Reasoning Model for Visual Dialog -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-19/cs.CL/paper_15.html">
      DMRM: A Dual-channel Multi-hop Reasoning Model for Visual Dialog
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      従来のモデルは通常、シングルホップ推論またはシングルチャネル推論を利用して、この複雑なマルチモーダル推論タスクを処理しますが、これは直観的には不十分です。 -および各チャンネルのマルチホップ推論プロセスによる画像認識ダイアログ履歴機能。視覚ダイアログは、画像に基づいた人間との会話にAIエージェントが関与することを必要とするビジョン言語タスクです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br>2019-12-18
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Detecting Adversarial Attacks On Audio-Visual Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-19/eess.AS/paper_0.html">
      Detecting Adversarial Attacks On Audio-Visual Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、特にマルチモーダルドメインでの敵対的検出方法に関する研究は非常に限られています。GRIDおよびLRWデータセットで訓練された2つの視聴覚音声認識モデルに最近の敵対的攻撃を適用します。学習モデル。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br>2019-12-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Ene-to-end training of time domain audio separation and recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-19/eess.AS/paper_1.html">
      Ene-to-end training of time domain audio separation and recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの実験は、WSJ0-2mixで11.0％の単語誤り率を示し、共同時間領域モデルがこれまでに提案されたカスケードDNN-HMMおよびモノリシックE2E周波数領域システムを大幅に改善できることを示しています。 E2E音声認識機能を備えた畳み込み時間領域音声分離ネットワーク（Conv-TasNet）に基づくモジュールと、複数のGPUに分散するか、畳み込みフロントエンドの切り捨てられた逆伝搬を近似することにより、このようなモデルを共同でトレーニングする方法。この作業を視点に入れて、デザインスペースの複雑さを説明し、単一チャネルのマルチスピーカー認識システムの簡潔な概要を示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br>2019-12-18
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本日更新された論文はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br>
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
