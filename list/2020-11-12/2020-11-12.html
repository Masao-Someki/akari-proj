<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-11-12の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: End-to-End Bengali Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.SD/paper_0.html">
      <font color="black">End-to-End Bengali Speech Recognition</font>
    </a>
  </h2>
  <font color="black">2つのCNNブロック、2層ブロックAと4層ブロックBを提案します。最初の層は7x3カーネルで構成され、後続の層は3x3カーネルのみで構成されます。公開されているラージベンガルASRトレーニングデータセットを使用して、ベンチマークを行います。ベンガル語のASRタスクでさまざまな複雑さと深さの7つのディープニューラルネットワーク構成のパフォーマンスを評価します。この作業では、CTCベースのCNN-RNNネットワーク、著名なディープラーニングベースのエンドツーエンド自動音声認識技術を適用します。ベンガル語のASRタスクに。 
[概要]ベンガル語の研究とリソースはほとんどなく、その間にあります。これらには、音声ベースの音声ベースのオサマビンの広範な使用が含まれます。ただし、研究は成功していません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-21">
        <br><font color="black">2020-09-21</font>
      </time>
    </span>
</section>
<!-- paper0: WaDeNet: Wavelet Decomposition based CNN for Speech Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.SD/paper_1.html">
      <font color="black">WaDeNet: Wavelet Decomposition based CNN for Speech Processing</font>
    </a>
  </h2>
  <font color="black">WaDeNetは、非侵襲的感情認識などのモバイルヘルスアプリケーションの音声を含むデータセットで現在の最先端技術を上回っています。これにより、WaDeNetはスペクトルの特徴からエンドツーエンドで学習できるため、特徴抽出の必要性が軽減されます。音声処理システムに現在存在する後続のモジュール。モバイル音声処理のエンドツーエンドモデルであるWaDeNetを提案します。 
[ABSTRACT] wadenetは、モバイル音響用の音声を含むデータセットで現在の最先端技術を上回っています。現在、wadenetは、同様のアーキテクチャを備えた単純なcnnsよりもはるかに軽量です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Surrogate Source Model Learning for Determined Source Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.SD/paper_2.html">
      <font color="black">Surrogate Source Model Learning for Determined Source Separation</font>
    </a>
  </h2>
  <font color="black">ISSは、複雑さが低く、行列の反転がないため、このタスクに適しています。実験では、ベースラインの方法と比較して、スケール不変の信号対歪み（SDR）比と単語誤り率の点で大幅な改善が見られます。トレーニングが行われます。 2つのスピーカーの混合で、SDRとコヒーレンスの2つの損失を実験します。 
[要約]深い音声の事前分布は、メジャー化-最小化（auxiva）に基づく分析と互換性がありませんが、必要な代理関数を導出することは容易ではなく、常に可能ではありません。代わりに、issの複数の反復を通じて正確な分離損失を逆伝播します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Sound Synthesis, Propagation, and Rendering: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.SD/paper_3.html">
      <font color="black">Sound Synthesis, Propagation, and Rendering: A Survey</font>
    </a>
  </h2>
  <font color="black">私たちの知る限り、これはコンピュータグラフィックスの分野における音響研究の包括的な要約を提供する最初の試みです。この論文は、仮想現実、ゲーム、マルチメディア、コンピュータにおける音響シミュレーションに関する研究の概要を示しています。支援設計..さらに、最新の深層学習ベースのサウンドシミュレーションアプローチを示します。 
[ABSTRACT]サウンドは、サウンドグラフィックや空間サイズなどの重要な手がかりを提供できます。さらに、サウンドのレンダリング方法を確認します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Time Delay Neural Network for Speech Enhancement with Full Data
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.SD/paper_4.html">
      <font color="black">Deep Time Delay Neural Network for Speech Enhancement with Full Data
  Learning</font>
    </a>
  </h2>
  <font color="black">ただし、RNNのモデルの複雑さと推論時間のコストは、ディープフィードフォワードニューラルネットワーク（DNN）よりもはるかに高くなります。リカレントニューラルネットワーク（RNN）は、近年、音声強化に関して大幅な改善を示しています。したがって、すべてのトレーニングデータを使用して、拡張モデルをトレーニングできます。 
[概要]この論文では、完全なデータ学習による音声強調のための深層時間遅延ニューラルネットワーク（tdnn）を提案します。tdnnはフィードフォワード構造を保持するため、グッドウィンコストは標準のdnnに匹敵しますが、モデルの複雑さを使用して強化されたモデルをトレーニングするだけでなく、データを無音にするためにクリーン-から-クリーンとノイズ-もトレーニングします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Recognizing More Emotions with Less Data Using Self-supervised Transfer
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.SD/paper_5.html">
      <font color="black">Recognizing More Emotions with Less Data Using Self-supervised Transfer
  Learning</font>
    </a>
  </h2>
  <font color="black">完全なIEMOCAPデータセットでトレーニングすると、73.9％の重み付けされていない精度（UA）の新しい最先端技術に到達します。この方法では、より一般的な自己トレーニングモデルから抽出された事前トレーニング済み音声表現に含まれる知識を活用します。 wav2vecモデルなど、人間の注釈を必要としない教師ありタスク。トレーニングデータが少ない場合でも有望な結果を得ることができる、音声感情認識のための新しい伝達学習方法を提案します。 
[概要]トレーニングデータのサイズを変更することで、アプローチの利点に関する詳細な洞察を提供しました。音響と言語マークの知識を組み合わせることで、結果を大幅に改善できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Recurrent Deep Stacking Networks for Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.SD/paper_6.html">
      <font color="black">Recurrent Deep Stacking Networks for Speech Recognition</font>
    </a>
  </h2>
  <font color="black">これら2つのモデルの主なアイデアは、音素レベルの情報を音響モデルに追加し、音響モデルを音響モデルと音素レベルのNグラムモデルの組み合わせに変換することです。実験により、RDSNとBPsnが大幅に改善できることが示されました。従来のDNNを超えるパフォーマンス..この論文では、RDSNのより効率的でありながら同等の代替品であるBi-Pass Stacking Network（BPSN）も提案しました。 
[概要]新しい調査によると、rdsnとbpsnはパフォーマンスを大幅に向上させることができます。新しい調査では、rdsn、バイパススタッキングネットワーク（bpsn）のより効率的な代替案が示唆されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2016-12-14">
        <br><font color="black">2016-12-14</font>
      </time>
    </span>
</section>
<!-- paper0: Incorporating Language Level Information into Acoustic Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.SD/paper_7.html">
      <font color="black">Incorporating Language Level Information into Acoustic Models</font>
    </a>
  </h2>
  <font color="black">2種類のコンテキスト情報、コンテキストを処理する2つの方法、言語レベルの情報を組み込む2つの方法など、RDLNの複数のバリエーションが検討されました。RDLNは、自動音声認識（ASR）システム全体を微調整するための可能な方法を提供しました。この論文は、言語レベルの情報を音響モデルに組み込むことができる、新しいディープリカレントニューラルネットワークのクラスを提案しました。 
[概要]これらのネットワークはリカレントディープランゲージネットワーク（rdlns）と呼ばれます。複数のネットワークがコンテキストとして考慮されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2016-12-14">
        <br><font color="black">2016-12-14</font>
      </time>
    </span>
</section>
<!-- paper0: Quasi-Periodic WaveNet: An Autoregressive Raw Waveform Generative Model
  with Pitch-dependent Dilated Convolution Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.SD/paper_8.html">
      <font color="black">Quasi-Periodic WaveNet: An Autoregressive Raw Waveform Generative Model
  with Pitch-dependent Dilated Convolution Neural Network</font>
    </a>
  </h2>
  <font color="black">次に、カスケードネットワーク構造を利用して、音声などの準周期信号の長期依存性と短期依存性を同時にモデル化します。この問題に対処するために、2つの新しい設計のQPNetを提案します。まず、PDCNNコンポーネントを適用します。与えられた補助F0機能に従ってWNのネットワークアーキテクチャを動的に変更します。 
[ABSTRACT]ピッチベースのモデルwnは、忠実度の高いオーディオ波形生成を実現します。f0機能が周期的である場合、オーディオ信号の周期的成分を生成することは困難です。シングルトーン正弦波および音声生成のパフォーマンスが評価されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-11">
        <br><font color="black">2020-07-11</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: LittleYOLO-SPP: A Delicate Real-Time Vehicle Detection Algorithm -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_0.html">
      <font color="black">LittleYOLO-SPP: A Delicate Real-Time Vehicle Detection Algorithm</font>
    </a>
  </h2>
  <font color="black">既存のリアルタイム車両検出は精度と速度に欠けています。この研究では、YOLOv3-tinyネットワークに基づくディープニューラルネットワークLittleYOLO-SPPの軽量モデルを提案して、車両をリアルタイムで効果的に検出します。リアルタイムシステム車両の盗難や道路交通違反などの犯罪行為中に、車両を高精度で検出して特定する必要があります。 
[概要] yolov3-小さなオブジェクトネットワークは、特徴抽出ネットワークを変更して車両検出の速度と精度を向上させることで改善されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Classification of COVID-19 in Chest CT Images using Convolutional
  Support Vector Machines -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_1.html">
      <font color="black">Classification of COVID-19 in Chest CT Images using Convolutional
  Support Vector Machines</font>
    </a>
  </h2>
  <font color="black">結論：提案された方法は他の方法よりも効果的です。CSVM法のパフォーマンスを評価するために、データセットはトレーニング（％75）とテスト（％25）の2つの部分に分けられます。事前トレーニングされた畳み込みニューラルネットワークとは異なります。転移学習法でトレーニングされたネットワーク（CNN）であるCSVMモデルはスクラッチとしてトレーニングされます。 
[概要] wuvidウイルスはcovidを検出する遺伝的手法であり、19例が高性能です。この手法は他の手法よりも効果的です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_2.html">
      <font color="black">ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language</font>
    </a>
  </h2>
  <font color="black">自然言語記述を使用したRGB-Dスキャンでの3Dオブジェクトローカリゼーションのタスクを紹介します。800のScanNetシーンからの11,046オブジェクトの51,583の記述を含むScanReferデータセットも紹介します。このタスクに対処するために、融合を学習するScanReferを提案します。 3Dオブジェクトの提案とエンコードされた文の埋め込みからの記述子。 
[ABSTRACT] scanreferは、オブジェクトのローカリゼーションを実行する最初の大規模な取り組みです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br><font color="black">2019-12-18</font>
      </time>
    </span>
</section>
<!-- paper0: Noise Conscious Training of Non Local Neural Network powered by Self
  Attentive Spectral Normalized Markovian Patch GAN for Low Dose CT Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_3.html">
      <font color="black">Noise Conscious Training of Non Local Neural Network powered by Self
  Attentive Spectral Normalized Markovian Patch GAN for Low Dose CT Denoising</font>
    </a>
  </h2>
  <font color="black">次に、CTノイズの非定常性の問題に移行し、LDCTノイズ除去のための新しいノイズ認識平均二乗誤差損失を導入しました。医療現場でのコンピューター断層撮影（CT）イメージングの使用の爆発的な増加により、患者に関連する放射線量..提案されたモジュールは、ノイズ除去を大幅に強化するのに役立ちました。 
[概要]ディープラーニングベースの手法が、低線量ct（ldct）ノイズ除去の主要な方法として登場しました。これは、放射線量の減少とノイズおよびアーチファクトの増加によるもので、スキャンの解釈可能性を低下させます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: DR-GAN: Conditional Generative Adversarial Network for Fine-Grained
  Lesion Synthesis on Diabetic Retinopathy Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_4.html">
      <font color="black">DR-GAN: Conditional Generative Adversarial Network for Fine-Grained
  Lesion Synthesis on Diabetic Retinopathy Images</font>
    </a>
  </h2>
  <font color="black">ランダムフリッピングやローテーションなどの一般的なデータ拡張方法では、多様性の高いデータを生成できません。したがって、大規模に生成されたデータを使用して、DRグレーディングおよび病変セグメンテーションモデルをトレーニングするためのより意味のある拡張を行うことができます。ただし、グレーディングモデルの最適化強力な一般化可能性を持たせるには、バランスの取れた大量のトレーニングデータが必要であり、特に重大度の高いレベルでは収集が困難です。 
[概要]国際プロトコルに従って5つの重大度レベルに格付けできます。したがって、大規模に生成されたデータを使用して、dr格付けおよび病変セグメンテーションモデルをトレーニングできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-10">
        <br><font color="black">2019-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: FPGA: Fast Patch-Free Global Learning Framework for Fully End-to-End
  Hyperspectral Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_5.html">
      <font color="black">FPGA: Fast Patch-Free Global Learning Framework for Fully End-to-End
  Hyperspectral Image Classification</font>
    </a>
  </h2>
  <font color="black">3つの公開ベンチマークデータセットを使用して得られた実験結果は、FPGAフレームワークがHSI分類の速度と精度の両方でパッチベースのフレームワークより優れていることを示唆しています。FCNアーキテクチャのより良い設計のために、完全にエンドツーであるFreeNet HSI分類のためのエンドネットワークは、グローバル空間情報の活用を最大化し、スペクトル注意ベースのエンコーダーと軽量デコーダーを介してパフォーマンスを向上させるために提案されています。ただし、HSI分類のためにエンコーダーデコーダーベースのFCNを直接利用することは困難です。限られたトレーニングサンプルによって引き起こされる勾配の多様性が不十分なため、常に収束に失敗するためです。 
[概要]現在の深層学習戦略は、パッチベースの学習フレームワークに基づいています。これらには、高速パッチフリーのグローバル学習（fpga）フレームワークが含まれます。hsi分類にエンコーダーデコーダーベースのfcnを直接利用することは困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial images for the primate brain -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_6.html">
      <font color="black">Adversarial images for the primate brain</font>
    </a>
  </h2>
  <font color="black">驚くべきことに、同じ画像が行動レベルでサルと人間をだましました。これらの敵対的な画像は、ターゲットカテゴリと同様のニューロン応答を誘発しました。これらの結果は、コンピュータと霊長類の視覚の類似性に関する基本的な仮定に挑戦し、ニューロン活動のモデルが霊長類の視覚的行動を選択的に指示します。 
[概要]霊長類の視覚をだますために敵対的な画像を設計することにより、この仮定を評価しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Dense U-net for super-resolution with shuffle pooling layer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_7.html">
      <font color="black">Dense U-net for super-resolution with shuffle pooling layer</font>
    </a>
  </h2>
  <font color="black">コードはオンラインで入手できます。提案された方法は、3つのベンチマークデータセット（SET14、BSD300、ICDAR2003）で以前の最先端技術よりも優れた精度を実現します。次に、シャッフルプーリングと呼ばれる新しいプーリング戦略が設計されています。超解像タスクのための高密度U-Net。 
[ABSTRACT]研究者は超解像で大きな進歩を遂げました。最初に、高密度ブロックを備えた修正されたuネットが、sisrに提案されます。知覚損失と情報損失を解決するために混合損失関数が提案されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Chinese Landscape Painting Creation Using Generative
  Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_8.html">
      <font color="black">End-to-End Chinese Landscape Painting Creation Using Generative
  Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">242人のビジュアルチューリングテストの調査によると、SAPGANの絵画は、55％の頻度で人間のアートワークと間違えられており、ベースラインGANの絵画を大幅に上回っています。 。私たちの仕事は、真に機械オリジナルのアート世代の基礎を築きます。 
[ABSTRACT] gan（sapgan）は、条件付き入力なしで中国の風景画を生成する最初のモデルです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Distorted image restoration using stacked adversarial network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_9.html">
      <font color="black">Distorted image restoration using stacked adversarial network</font>
    </a>
  </h2>
  <font color="black">探索を妨げる利用可能なベンチマークがないため、CelebAデータセットに基づいて歪みマッピングを再構築することにより、歪みのある顔のデータセットを提供します。提案されたベンチマークの方法を定量的および定性的に評価し、検証のために実世界に適用します。また、合成データを生成するための新しい方法を紹介します。 
[ABSTRACT]液化フィルターは歪んだ画像を復元するのが難しい作業です。ツールは歪んだ画像を復元するのに役立つように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Noise2Sim -- Similarity-based Self-Learning for Image Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_10.html">
      <font color="black">Noise2Sim -- Similarity-based Self-Learning for Image Denoising</font>
    </a>
  </h2>
  <font color="black">具体的には、Noise2Simは画像パッチの自己類似性を活用し、類似パッチの中心ピクセル間のマッピングを学習して、自己無撞着な画像ノイズ除去を行います。ラベル付き画像をバイパスするために、Noise2Voidメソッドは単一のノイズの多い画像でのみ周囲からマスクされたピクセルを予測します。広範な実験により、一般的なベンチマークデータセットでのNoise2NoiseおよびNoise2Voidに対するNoise2Simの優位性が実証されています。 
[ABSTRACT] noise2simはnlmです-画像のノイズ除去のためのインスピレーションを得た自己学習方法です。これはペアノイズ-クリーンな画像をペアノイズ、収集しやすいノイズ画像に置き換えることができるという事実に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-06">
        <br><font color="black">2020-11-06</font>
      </time>
    </span>
</section>
<!-- paper0: Cryo-RALib -- a modular library for accelerating alignment in cryo-EM -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_11.html">
      <font color="black">Cryo-RALib -- a modular library for accelerating alignment in cryo-EM</font>
    </a>
  </h2>
  <font color="black">TaiWan Computing Cloudコンテナのベンチマークであるこの実装は、計算を1桁高速化できます。ライブラリには、最先端の分類アルゴリズムを高速化するために広く使用できる、参照なしの配置と複数参照の配置の両方が含まれています。ただし、人気のあるGPUで高速化されたベイジアンアプローチは、3Dの改良に成功することが示されています。 
[概要] 2019年の最初の構造-ncovスパイク三量体は、ワクチン開発に重要な医学的洞察を提供する、cryo-emを使用して3月に公開されました。データ特性には、強いノイズ、巨大な寸法、大きなサンプルサイズ、未知の方向での高い不均一性が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Tattoo tomography: Freehand 3D photoacoustic image reconstruction with
  an optical pattern -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_12.html">
      <font color="black">Tattoo tomography: Freehand 3D photoacoustic image reconstruction with
  an optical pattern</font>
    </a>
  </h2>
  <font color="black">このパターンは、その断層画像がパターンの座標系に対するプローブポーズの回復を可能にするように設計されています。方法：この論文では、PATデータの3D再構成への新しいアプローチを提示します（Tattooトモグラフィー）。 ）外部追跡システムを必要とせず、臨床ワークフローにスムーズに統合できます。これは、画像取得前に関心領域に配置された光学パターンに基づいています。 
[概要]従来適用されていた2dプローブによって提供される限られた視野（fov）。これは、関心領域に配置された光学パターンに基づいています。これにより、取得した一連のpa画像を共通のグローバル座標に復元できます。システム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: ForestNet: Classifying Drivers of Deforestation in Indonesia using Deep
  Learning on Satellite Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_13.html">
      <font color="black">ForestNet: Classifying Drivers of Deforestation in Indonesia using Deep
  Learning on Satellite Imagery</font>
    </a>
  </h2>
  <font color="black">データセットを使用してモデルをトレーニングおよび検証し、ForestNetが他の標準的なドライバー分類アプローチよりも大幅に優れていることを示します。森林破壊につながるプロセスの特性評価は、対象となる森林保全および管理ポリシーの開発と実装にとって重要です。将来をサポートするために森林破壊ドライバー分類への自動化されたアプローチに関する研究、この研究でキュレートされたデータセットは、https：//stanfordmlgroup.github.io/projects/forestnetで公開されています。 
[概要]インドネシアの原生林喪失のドライバーを分類するために、フォレストネットと呼ばれる深層学習モデルが使用されています。専門家の通訳からドライバーの注釈が提供されます。データセットはstanfordmlgroupで公開されています。 github。 io /プロジェクト/フォレストネット。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Invertible CNN-Based Super Resolution with Downsampling Awareness -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_14.html">
      <font color="black">Invertible CNN-Based Super Resolution with Downsampling Awareness</font>
    </a>
  </h2>
  <font color="black">微分可能な演算子がニューラルネットワークの最終出力層として適用され、ダウンサンプリングされた出力を2D平均ダウンサンプリングの下で低解像度の入力データと一致させます。ここでは、「ダウンサンプリング対応」の超解像ネットワークの方法が提案されています。この演算子を最先端の深層学習ベースの超解像スキームの選択に追加すると、ほとんどの一般的な画像超解像ベンチマークデータセットのトレーニング時間と全体的なパフォーマンスが向上することが実証されています。 
[概要]「ダウンサンプリング対応」超解像ネットワークの手法を提案。このシステムは、医療スキャン、降水レーダー、グリッド数値シミュレーション、衛星イメージャ、その他多くのソースによって生成されたデータに適用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Skin disease diagnosis with deep learning: a review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_15.html">
      <font color="black">Skin disease diagnosis with deep learning: a review</font>
    </a>
  </h2>
  <font color="black">ディープラーニングの人気を考えると、この分野には大きな課題が残っており、将来的に探求できる機会もあります。最後に、記事を要約します。この記事の重要な部分として、関連する文献を確認します。特定のタスクに応じたいくつかの側面からの皮膚病診断のための深層学習方法。 
[ABSTRACT]ディープラーニングは皮膚病の診断の実装を可能にします。新しい技術にはディープラーニングと可能な将来の研究が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: LIFI: Towards Linguistically Informed Frame Interpolation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_16.html">
      <font color="black">LIFI: Towards Linguistically Informed Frame Interpolation</font>
    </a>
  </h2>
  <font color="black">また、音声理解のコンピュータービジョンビデオ生成モデルをテストするために、いくつかのデータセットをリリースします。また、従来の非言語メトリックで高いパフォーマンスを示しているにもかかわらず、コンピュータービジョンモデルが音声の忠実な補間を正確に生成できない例を提供します。特に音声ビデオの補間の問題を対象とした、言語情報に基づいた新しいメトリックのセットを提供します。 
[概要]音声理解のコンピュータービジョンビデオ生成モデルをテストするためのいくつかのデータセットもリリースします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-30">
        <br><font color="black">2020-10-30</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Domain Adaptive Object Detection: a Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_17.html">
      <font color="black">Deep Domain Adaptive Object Detection: a Survey</font>
    </a>
  </h2>
  <font color="black">次に、ディープドメイン適応検出器は5つのカテゴリに分類され、各カテゴリの代表的な方法の詳細な説明が提供されます。最初に、ディープドメイン適応の基本概念を簡単に紹介します。これらの方法は通常、大量のラベル付きトレーニングデータを想定しています。が利用可能であり、トレーニングデータとテストデータは同じ分布から取得されます。 
[ABSTRACT]ディープドメイン適応オブジェクト検出（ddaod）は、上記の課題に対処するための新しい学習ツールとして登場しました。最初に、ディープドメイン適応の基本概念を簡単に紹介します。最後に、将来の研究動向に関する洞察を示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-17">
        <br><font color="black">2020-02-17</font>
      </time>
    </span>
</section>
<!-- paper0: A Generalized Gaussian Extension to the Rician Distribution for SAR
  Image Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_18.html">
      <font color="black">A Generalized Gaussian Extension to the Rician Distribution for SAR
  Image Modeling</font>
    </a>
  </h2>
  <font color="black">提案された統計モデルは、複雑なSAR信号の振幅をモデル化するためのライス分布に基づいており、その同相成分と直交成分は一般化されたガウス分布であると想定されます。実験分析では、GG-ライスモデルは次のようになります。 $ \ mathcal {K} $、Weibull、Gamma、Lognormalなどの最先端の統計モデルと比較して、さまざまな周波数帯域とシーンの振幅と強度のSAR画像を調査しました。適切なモデル、Kullback-Leibler発散による統計的有意性分析、およびKolmogorov-Smirnov統計が実行されます。 
[概要]サリカの特徴はモデリアニアの画像に不可欠です。これらは一連の異なるタイプのデータに基づいています。これらのモデルには、2,000ドル（2,000ドル）のモデルが含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
</section>
<!-- paper0: Hi-UCD: A Large-scale Dataset for Urban Semantic Change Detection in
  Remote Sensing Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_19.html">
      <font color="black">Hi-UCD: A Large-scale Dataset for Urban Semantic Change Detection in
  Remote Sensing Imagery</font>
    </a>
  </h2>
  <font color="black">都市拡大の加速に伴い、重要かつ効果的なアプローチとして、都市変化検出（UCD）は、動的な都市分析のための地理空間オブジェクトに関する変化情報を提供できます。バイナリおよびマルチのいくつかの古典的な方法を使用してデータセットをベンチマークします。 -クラス変更の検出..洗練された都市の変更を検出および分析するために使用できます。 
[概要]このデータセットは、空間解像度が0.1 mの航空写真を使用しています。3つの時相が含まれ、9つのクラスの土地被覆で意味的に注釈が付けられています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-06">
        <br><font color="black">2020-11-06</font>
      </time>
    </span>
</section>
<!-- paper0: COVIDGR dataset and COVID-SDNet methodology for predicting COVID-19
  based on Chest X-Ray images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_20.html">
      <font color="black">COVIDGR dataset and COVID-SDNet methodology for predicting COVID-19
  based on Chest X-Ray images</font>
    </a>
  </h2>
  <font color="black">COVIDGR-1.0と重大度レベルのラベルは、このリンクhttps://dasci.es/es/transferencia/open-data/covidgr/から科学コミュニティで入手できます。このペーパーは3つあります。（i）わかりやすく説明します。最新のCOVID-19分類モデルによって達成された高感度、（ii）スペインのグラナダにあるHospital Universitario Cl \ &#39;inico San Cecilioとの緊密な協力の下で、COVIDGR-1.0を構築しました。これは、すべてのレベルの重症度、陽性RT-PCRによる正常から、軽度、中等度から重度。深部学習神経ネットワークは、COVID-19トリアージシステムを構築し、COVID-19患者、特に重症度の低い患者を検出する大きな可能性を秘めています。 
[要約] ct（ct）スキャナーとrt-pcrテストは、ほとんどの医療センターでは利用できません。しかし、多くの場合、cxr画像は、臨床医が意思決定を行うのを支援するための最も時間と費用効果の高いツールになります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-02">
        <br><font color="black">2020-06-02</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Open-World Reliability Assessment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_21.html">
      <font color="black">Automatic Open-World Reliability Assessment</font>
    </a>
  </h2>
  <font color="black">したがって、標準分類器またはオープンセット分類器のいずれについても、世界がいつ変化し、OOD入力が増加するとシステムの信頼性が低下するかを判断できることが重要です。したがって、これらの分類器の信頼性評価は、人間のオペレーターが行う必要があります。ネットワークは100％正確ではないため、より複雑になり、いくつかの障害が予想されます。このプロセスを自動化するために、ここでは、オープンワールドの認識信頼性問題を形式化し、この新しい問題に対処するための複数の自動信頼性評価ポリシーを提案します。報告されたスコア/確率データの分布。 
[ABSTRACT]システムは自動的にood画像を拒否する必要があります。そうしないと、既知のクラスの上にマッピングされます。ただし、softmaxとopen-set分類子はoodデータの頻度に依存します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-modal, multi-task, multi-attention (M3) deep learning detection of
  reticular pseudodrusen: towards automated and accessible classification of
  age-related macular degeneration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_22.html">
      <font color="black">Multi-modal, multi-task, multi-attention (M3) deep learning detection of
  reticular pseudodrusen: towards automated and accessible classification of
  age-related macular degeneration</font>
    </a>
  </h2>
  <font color="black">CFPでのM3パフォーマンスは、人間の網膜専門家よりも大幅に優れていました（中央値F1スコア0.644対0.350）。外部検証（オランダのロッテルダム研究）は、CFPのみで高精度を示しました（AUROC 0.965）。M3フレームワークも正確に検出されました。地理的萎縮と色素異常（それぞれAUROC 0.909と0.912）は、その一般化可能性を示しています。 
[概要] rpd検出に関する疑似サイズの `m3 &#39;ディープラーニングフレームワーク。これには、multi --rpd、multi --task（さまざまなタスクのトレーニング）、およびmulti --attention（libyan）操作が含まれます。これらにはmulti --modal（からの検出主要な画像モダリティ）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Application of Compromising Evolution in Multi-objective Image Error
  Concealment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_23.html">
      <font color="black">Application of Compromising Evolution in Multi-objective Image Error
  Concealment</font>
    </a>
  </h2>
  <font color="black">このような欠点を取り除くために、このレポートでは、妥協の概念を利用して単純な遺伝的アルゴリズムを変更する妥協進化法を提案します。多数の多目的最適化問題が、同時に最適化される多数の適応度関数で発生します。相互の好みは本質的に知られていない。シミュレーション結果は、画像エラー隠蔽のケーススタディで多目的最適化を解決する提案された方法の力を示している。 
[概要]現在の戦略では、画像強調などの複雑な領域でのこれらの問題に対するパレート最適解を作成できない可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: An ensemble-based approach by fine-tuning the deep transfer learning
  models to classify pneumonia from chest X-ray images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_24.html">
      <font color="black">An ensemble-based approach by fine-tuning the deep transfer learning
  models to classify pneumonia from chest X-ray images</font>
    </a>
  </h2>
  <font color="black">この作業では、ニューラルネットワークのトレーニング時間を短縮し、汎化誤差を最小限に抑えることができる転移学習の使用を提案します。肺炎は、肺に感染するウイルス、細菌、または真菌によって引き起こされ、診断されない場合、致命的であり、呼吸不全につながる..肺炎を正確に分類するために、InceptionResNet、MobileNetV2、Xception、DenseNet201、ResNet152V2などの最先端の深層学習モデルをトレーニングおよび微調整しました。 
[概要]米国では毎年25万人以上が肺炎と診断されています。5万人がこの病気で亡くなっています。肺炎を正確に分類するために肺を訓練し、微調整しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: A Unified Framework for Compressive Video Recovery from Coded Exposure
  Techniques -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.IV/paper_25.html">
      <font color="black">A Unified Framework for Compressive Video Recovery from Coded Exposure
  Techniques</font>
    </a>
  </h2>
  <font color="black">学習ベースのフレームワークは、シフトバリアント畳み込み層とそれに続く完全畳み込みディープニューラルネットワークで構成されます。提案された統合フレームワークは、3つのセンシング技術すべてで最先端の再構成を実現します。取得のためにいくつかのコード化された露出技術が提案されています。低帯域幅での高フレームレートビデオ。 
[概要] 1回の露光で2つの圧縮測定値を取得するために、コード化された2バケットカメラが提案されています。これは、1つの測定値しか取得できない以前に提案されたコード化された露光技術とは異なります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: LittleYOLO-SPP: A Delicate Real-Time Vehicle Detection Algorithm -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_0.html">
      <font color="black">LittleYOLO-SPP: A Delicate Real-Time Vehicle Detection Algorithm</font>
    </a>
  </h2>
  <font color="black">提案されたネットワークは、ネットワークに空間ピラミッドプーリングを組み込んでいます。これは、ネットワーク学習機能を強化するために特徴を連結するためのさまざまなスケールのプーリングレイヤーで構成されています。オクルージョンのある複雑なシーンでの車両の検出も非常に困難です。YOLOv3-小さなオブジェクトの検出ネットワークは、特徴抽出ネットワークを変更して車両検出の速度と精度を向上させることで改善されています。 
[概要] yolov3-小さなオブジェクトネットワークは、特徴抽出ネットワークを変更して車両検出の速度と精度を向上させることで改善されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Simultaneous lesion and neuroanatomy segmentation in Multiple Sclerosis
  using deep neural networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_1.html">
      <font color="black">Simultaneous lesion and neuroanatomy segmentation in Multiple Sclerosis
  using deep neural networks</font>
    </a>
  </h2>
  <font color="black">Freesurferから派生した弱い解剖学的ラベルを追加してトレーニングすると、3D Unetのパフォーマンスが低下し、DeepSCANネットのパフォーマンスが向上しました。2016年のMSSEGトレーニングで2つの最先端の完全畳み込みCNNアーキテクチャをトレーニングしました。 7人の独立した人間の評価者によって注釈が付けられたデータセット：3D Unetのリファレンス実装、および最近提案された3D-to-2Dアーキテクチャ（DeepSCAN）。両方のアーキテクチャは、単一センターのデータでトレーニングしてテストしたときにパフォーマンスの低下を示しました。 MSSEGデータセット。 
[概要]新しい論文では、畳み込みニューラルネットワーク（cnns）に基づくセグメンテーションソリューションを検討しています。これらは、マルチモーダルmrイメージングで病変と灰白質構造の高速で信頼性の高いセグメンテーションを提供する他の方法に基づいています。パフォーマンスも比較しました。自由に利用できる参照方法を使用して、病変と解剖学的ラベルの両方を予測するディープスキャンネットワークが最高でした-調査したネットワークのパフォーマンス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-01-22">
        <br><font color="black">2019-01-22</font>
      </time>
    </span>
</section>
<!-- paper0: Classification of COVID-19 in Chest CT Images using Convolutional
  Support Vector Machines -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_2.html">
      <font color="black">Classification of COVID-19 in Chest CT Images using Convolutional
  Support Vector Machines</font>
    </a>
  </h2>
  <font color="black">結果：事前トレーニング済みのCNNネットワークとCSVMモデルのパフォーマンスを評価すると、CSVM（7x7、3x3、1x1）モデルは、94.03％ACC、96.09％SEN、92.01％SPE、92.19％PRE、94.10％F1で最高のパフォーマンスを示します。 -スコア、88.15％MCCおよび88.07％カッパメトリック値..伝達学習法でトレーニングされた事前トレーニング済み畳み込みニューラルネットワーク（CNN）とは異なり、CSVMモデルはスクラッチとしてトレーニングされます。提案されたメソッドは畳み込みサポートとして定義されます。 Vector Machine（CSVM）であり、Computed Tomography（CT）画像を自動的に分類できます。 
[概要] wuvidウイルスはcovidを検出する遺伝的手法であり、19例が高性能です。この手法は他の手法よりも効果的です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Position-based Scaled Gradient for Model Quantization and Pruning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_3.html">
      <font color="black">Position-based Scaled Gradient for Model Quantization and Pruning</font>
    </a>
  </h2>
  <font color="black">重みベクトルの位置に応じて勾配をスケーリングして圧縮しやすいようにする位置ベースのスケーリング勾配（PSG）を提案します。これにより、非圧縮モードまたは圧縮モードのいずれかとしてモデルを多目的に展開できます。リソースの可用性に応じて..次に、重みベクトルの正規化子として機能するPSGが、量子化やプルーニングなどのモデル圧縮ドメインに適していることを経験的に示します。 
[概要]提案されたgdは、反転可能な関数を介して元の重み空間をワープすることによって作成された、ワープされた重み空間のgdに相当します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-22">
        <br><font color="black">2020-05-22</font>
      </time>
    </span>
</section>
<!-- paper0: A Data Set and a Convolutional Model for Iconography Classification in
  Paintings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_4.html">
      <font color="black">A Data Set and a Convolutional Model for Iconography Classification in
  Paintings</font>
    </a>
  </h2>
  <font color="black">提案された分類器は、キリスト教の宗教画の聖人を識別するタスクで優れたパフォーマンス（71.17％の精度、70.89％のリコール、70.25％のF1スコア、72.73％の平均精度）を達成します。特徴..結果の定性的分析は、CNNが各聖人の表現を特徴付ける伝統的な象徴的なモチーフに焦点を当て、正しい識別を達成するためにそのようなヒントを利用することを示しています..アートのアイコングラフィーは、アートワークの視覚的内容を研究して決定する分野ですそれらのモチーフとテーマ、そしてこれらが表現される方法を特徴づけるために。 
[ABSTRACT]図像学はさまざまな目的で活発な研究の対象となっています。アーティストや芸術作品全体の影響の研究も研究の一部です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Adaptive Local Structure Consistency based Heterogeneous Remote Sensing
  Change Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_5.html">
      <font color="black">Adaptive Local Structure Consistency based Heterogeneous Remote Sensing
  Change Detection</font>
    </a>
  </h2>
  <font color="black">異種リモートセンシング画像の変化検出は、自然災害に起因する緊急事態のリモートセンシングにおいて重要かつ挑戦的なトピックです。異種データの漏洩を回避するために、ピクセル単位の変化画像は、グラフ投影によって同じ画像ドメインで計算されます。この課題に対処するために、このレターの異種画像間の適応ローカル構造整合性（ALSC）に基づく監視されていない変更検出方法を検討します。これは、1つの画像ドメイン内の各パッチのローカル構造を表す適応グラフを作成し、このグラフを変化レベルを測定するための他の画像ドメイン。 
[概要]これは、異種センサーのイメージングメカニズムが異なるため、画像を直接比較することは困難です。このローカル構造の一貫性は、異種画像が同じ地上オブジェクトの同じ構造情報を共有するという事実を利用しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-29">
        <br><font color="black">2020-08-29</font>
      </time>
    </span>
</section>
<!-- paper0: Scribble-Supervised Semantic Segmentation by Random Walk on Neural
  Representation and Self-Supervision on Neural Eigenspa -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_6.html">
      <font color="black">Scribble-Supervised Semantic Segmentation by Random Walk on Neural
  Representation and Self-Supervision on Neural Eigenspa</font>
    </a>
  </h2>
  <font color="black">結果は、提案された方法の優位性を示しており、一部のフルラベルの監視対象の方法にも匹敵します。一般的な落書きデータセットを比較することに加えて、ランダムに縮小し、画像オブジェクトに落書きをドロップする変更されたデータセットの実験も行います。 ..さらに、確率的遷移行列が与えられた場合、画像の主要部分の一貫性を保つために、その固有空間に自己監視を適用します。 
[概要]ネットワークに埋め込まれたランダムウォークは、ランダムに縮小し、画像オブジェクトに落書きをドロップするデータセットをシミュレートするのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_7.html">
      <font color="black">ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language</font>
    </a>
  </h2>
  <font color="black">また、800のScanNetシーンからの11,046オブジェクトの51,583の説明を含むScanReferデータセットを紹介します。このタスクに対処するために、3Dオブジェクトの提案とエンコードされた文の埋め込みから融合記述子を学習するScanReferを提案します。入力として、点群を想定します。スキャンされた3Dシーンと、指定されたターゲットオブジェクトの自由形式の説明。 
[ABSTRACT] scanreferは、オブジェクトのローカリゼーションを実行する最初の大規模な取り組みです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br><font color="black">2019-12-18</font>
      </time>
    </span>
</section>
<!-- paper0: Learning RGB-D Feature Embeddings for Unseen Object Instance
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_8.html">
      <font color="black">Learning RGB-D Feature Embeddings for Unseen Object Instance
  Segmentation</font>
    </a>
  </h2>
  <font color="black">新しい2段階のクラスタリングアルゴリズムにより、セグメンテーションの精度がさらに向上します。雑然としたシーンで見えないオブジェクトをセグメント化することは、ロボットが新しい環境でタスクを実行するために習得する必要のある重要なスキルです。学習した機能の埋め込みにより、平均シフトクラスタリングアルゴリズムを適用して、見えないオブジェクトを検出およびセグメント化できます。 
[概要]合成データからrgb-d特徴の埋め込みを学習するには、新しい関数が必要です。これは、シフトクラスタリングアルゴリズムを適用して、見えないオブジェクトを検出およびセグメント化できることを意味します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-30">
        <br><font color="black">2020-07-30</font>
      </time>
    </span>
</section>
<!-- paper0: A Benchmark for Studying Diabetic Retinopathy: Segmentation, Grading,
  and Transferability -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_9.html">
      <font color="black">A Benchmark for Studying Diabetic Retinopathy: Segmentation, Grading,
  and Transferability</font>
    </a>
  </h2>
  <font color="black">DR病変のセグメンテーション; 2 ..この問題に対処するために、2,842枚の画像（FGADR）を含む大規模な細粒度の注釈付きDRデータセットを構築します。提案されたデータセットにより、DR診断に関する広範な研究が可能になります。 
[概要]この病気は、高血糖が網膜の大血管に損傷を与える場合に発生します。現在のほとんどのdr診断システムは、眼科医にとって満足のいくパフォーマンスまたは解釈可能性を達成していません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-22">
        <br><font color="black">2020-08-22</font>
      </time>
    </span>
</section>
<!-- paper0: FAT: Training Neural Networks for Reliable Inference Under Hardware
  Faults -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_10.html">
      <font color="black">FAT: Training Neural Networks for Reliable Inference Under Hardware
  Faults</font>
    </a>
  </h2>
  <font color="black">これは、CIFAR10、GTSRB、SVHN、ImageNetなどの多数の分類タスクで検証されています。機能安全を実現するためのハードウェアコストを削減するには、DNNの固有の機能を活用できるドメイン固有のソリューションを検討することが不可欠です。一般的なフォールトトレランスは、システムに冗長性を追加することで実現できます。これにより、全体的な計算要求がさらに悪化し、電力とパフォーマンスの要件を満たすことが困難になります。 
[概要] deepnetnetnetnetシステムシステムシステムは不十分であることが判明しました。システムに冗長性を追加することでフォールトトレランスを実現できると述べています。これにより、全体的なコンピューティング要求がさらに悪化し、電力とパフォーマンスの要件を満たすことが困難になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Noise Conscious Training of Non Local Neural Network powered by Self
  Attentive Spectral Normalized Markovian Patch GAN for Low Dose CT Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_11.html">
      <font color="black">Noise Conscious Training of Non Local Neural Network powered by Self
  Attentive Spectral Normalized Markovian Patch GAN for Low Dose CT Denoising</font>
    </a>
  </h2>
  <font color="black">ただし、放射線量を減らすと、ノイズとアーチファクトが増加し、スキャンの解釈可能性が低下します。ただし、いくつかの一般的なボトルネックが依然として存在し、ディープラーニングベースの手法で最高のパフォーマンスを提供できません。その結果、高度な画像再構成アルゴリズム低線量CTの診断性能を改善することは、研究者の間の主要な関心事として生じました。これは、問題の不適切さのために挑戦的です。 
[概要]ディープラーニングベースの手法が、低線量ct（ldct）ノイズ除去の主要な方法として登場しました。これは、放射線量の減少とノイズおよびアーチファクトの増加によるもので、スキャンの解釈可能性を低下させます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: DR-GAN: Conditional Generative Adversarial Network for Fine-Grained
  Lesion Synthesis on Diabetic Retinopathy Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_12.html">
      <font color="black">DR-GAN: Conditional Generative Adversarial Network for Fine-Grained
  Lesion Synthesis on Diabetic Retinopathy Images</font>
    </a>
  </h2>
  <font color="black">提案された網膜ジェネレータは、構造マスクと病変マスク、および潜在的な次数付き空間からサンプリングされた適応次数付きベクトルを条件とします。これは、合成された次数付きの重大度を制御するために採用できます。ランダムな反転や回転など、一般的なデータ拡張方法ではできません。多様性の高いデータを生成します。したがって、大規模に生成されたデータを使用して、DRグレーディングおよび病変セグメンテーションモデルをトレーニングするためのより意味のある拡張を行うことができます。 
[概要]国際プロトコルに従って5つの重大度レベルに格付けできます。したがって、大規模に生成されたデータを使用して、dr格付けおよび病変セグメンテーションモデルをトレーニングできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-10">
        <br><font color="black">2019-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: FPGA: Fast Patch-Free Global Learning Framework for Fully End-to-End
  Hyperspectral Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_13.html">
      <font color="black">FPGA: Fast Patch-Free Global Learning Framework for Fully End-to-End
  Hyperspectral Image Classification</font>
    </a>
  </h2>
  <font color="black">FPGAでは、エンコーダ-デコーダベースのFCNを使用して、画像全体を処理することでグローバルな空間情報を検討します。これにより、高速な推論が可能になります。したがって、これらの方法はローカル学習方法であり、計算コストが高くなります。限られたトレーニングサンプルによって引き起こされる不十分な多様な勾配のために常に収束に失敗するため、HSI分類にエンコーダ-デコーダベースのFCNを直接利用することは困難です。 
[概要]現在の深層学習戦略は、パッチベースの学習フレームワークに基づいています。これらには、高速パッチフリーのグローバル学習（fpga）フレームワークが含まれます。hsi分類にエンコーダーデコーダーベースのfcnを直接利用することは困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic Plane Convolutional Occupancy Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_14.html">
      <font color="black">Dynamic Plane Convolutional Occupancy Networks</font>
    </a>
  </h2>
  <font color="black">さらに、学習した動的平面の分布に関する興味深い観察結果も提供します。入力ノイズのある点群は、複数の2D動的平面に投影されるポイントごとの特徴にエンコードされます。暗黙の神経表現を使用した学習ベースの3D再構成は有望です。オブジェクトレベルだけでなく、より複雑なシーンでも進行します。 
[概要]完全に接続されたネットワークは、オブジェクトまたはシーンの形状を最もよく表す平面パラメータを予測することを学習します。この方法は、シェイプネット内の方向付けされていない点群からの表面再構成で優れたパフォーマンスを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Where to drive: free space detection with one fisheye camera -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_15.html">
      <font color="black">Where to drive: free space detection with one fisheye camera</font>
    </a>
  </h2>
  <font color="black">結果は、合成魚眼画像が深層学習のコンテキストで使用できることを示しています。自動運転の分野での開発は、画像処理および機械学習方法の分野でのこれまでにない新しい開発と密接に関連しています。この合成トレーニングデータが評価されます。さまざまな深層学習ネットワークアーキテクチャの空き領域検出のアプリケーション用。 
[ABSTRACT]合成トレーニングデータはunity3dに基づいています。これは、さまざまな深層学習ネットワークアーキテクチャの空き領域検出のアプリケーションに使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Optimized Loss Functions for Object detection and Application on
  Nighttime Vehicle Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_16.html">
      <font color="black">Optimized Loss Functions for Object detection and Application on
  Nighttime Vehicle Detection</font>
    </a>
  </h2>
  <font color="black">最後に、夜間の車両検出のための十分な実験が2つのデータセットで行われました。さらに、MIoUという名前の新しいローカリゼーション損失が、予測ボックスとターゲットボックスの間にマハラノビス距離を組み込むことによって提案されます。これにより、DIoU損失の勾配の不一致の問題が排除されます。ローカリゼーションの精度を向上させます。この論文では、分類とローカリゼーションを同時に行うために、2つの損失関数の両方を最適化します。 
[概要]この論文では、分類とローカリゼーションの両方の損失関数を同時に最適化します。この方法は、陽性サンプルのローカリゼーション精度を向上させるために使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial images for the primate brain -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_17.html">
      <font color="black">Adversarial images for the primate brain</font>
    </a>
  </h2>
  <font color="black">これらの敵対的な画像は、ターゲットカテゴリと同様のニューロン応答を誘発しました。驚くべきことに、同じ画像が行動レベルでサルと人間をだましました。霊長類の視覚は、そのような敵対的な画像に対してロバストであると考えられています。 
[概要]霊長類の視覚をだますために敵対的な画像を設計することにより、この仮定を評価しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Training with Ensemble Consensus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_18.html">
      <font color="black">Robust Training with Ensemble Consensus</font>
    </a>
  </h2>
  <font color="black">ラベルノイズが存在する場合のこのような記憶の問題に対処します。ディープニューラルネットワークは記憶された特徴の近傍に一般化できないという事実から、ノイズの多い例では、特定の摂動下でネットワーク上で一貫して小さな損失が発生しないと仮定します。提案されたLECの中で、LTECは、ノイズの多いMNIST、CIFAR-10、およびCIFAR-100での現在の最先端の方法を効率的に上回っています。 
[ABSTRACT]新しいトレーニング方法は、ノイズの多い例への過剰適合を防ぐことができます。アンサンブル損失を伴う学習と呼ばれる、この方法が提案されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-22">
        <br><font color="black">2019-10-22</font>
      </time>
    </span>
</section>
<!-- paper0: Dense U-net for super-resolution with shuffle pooling layer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_19.html">
      <font color="black">Dense U-net for super-resolution with shuffle pooling layer</font>
    </a>
  </h2>
  <font color="black">コードはオンラインで入手できます。提案された方法は、3つのベンチマークデータセット（SET14、BSD300、ICDAR2003）で以前の最先端技術よりも優れた精度を実現します。制約のない環境での単一画像超解像（SISR）は、さまざまな理由から困難です。イルミネーション、オクルージョン、複雑な環境。 
[ABSTRACT]研究者は超解像で大きな進歩を遂げました。最初に、高密度ブロックを備えた修正されたuネットが、sisrに提案されます。知覚損失と情報損失を解決するために混合損失関数が提案されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Zero-Pair Image to Image Translation using Domain Conditional
  Normalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_20.html">
      <font color="black">Zero-Pair Image to Image Translation using Domain Conditional
  Normalization</font>
    </a>
  </h2>
  <font color="black">この論文では、ゼロペアの画像から画像への変換のためのドメイン条件付き正規化（DCN）に基づくアプローチを提案します。つまり、ペアのトレーニングデータが利用できないが、それぞれが3番目のドメインとペアのトレーニングデータを持つ2つのドメイン間で変換します。 ..コードはhttps://github.com/samarthshukla/dcnで入手できます。提案されたアプローチは、はるかに少ないパラメータを使用しながら、比較された方法よりも定性的および定量的に改善されます。 
[要約]提案された提案は、エンコーダーを備えた単一のジェネレーターに基づいています-DCベースのコード。提案されたアプローチは、ペア全体でそれぞれの資格が向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Chinese Landscape Painting Creation Using Generative
  Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_21.html">
      <font color="black">End-to-End Chinese Landscape Painting Creation Using Generative
  Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">242人のビジュアルチューリングテストの調査によると、SAPGANの絵画は55％の頻度で人間のアートワークと間違えられており、ベースラインGANの絵画を大幅に上回っています。 ：エッジマップの生成用のSketchGAN、および後続のエッジからペイントへの変換用のPaintGAN。 
[ABSTRACT] gan（sapgan）は、条件付き入力なしで中国の風景画を生成する最初のモデルです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Distorted image restoration using stacked adversarial network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_22.html">
      <font color="black">Distorted image restoration using stacked adversarial network</font>
    </a>
  </h2>
  <font color="black">主に特定の単一変形のために設計された既存の方法とは異なり、この論文は、マルチタイプおよびマルチスケールの歪み画像の適切なワープを求めることを特徴とする自動歪み画像復元を目的としています。合成データを生成するための新しい方法も紹介します。歪みの一般的な手法です。 
[ABSTRACT]液化フィルターは歪んだ画像を復元するのが難しい作業です。ツールは歪んだ画像を復元するのに役立つように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: DeepSim: Semantic similarity metrics for learned image registration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_23.html">
      <font color="black">DeepSim: Semantic similarity metrics for learned image registration</font>
    </a>
  </h2>
  <font color="black">私たちのセマンティックアプローチは、学習ベースの登録モデルの最適化を推進するデータセット固有の機能を学習します。複数の画像モダリティおよびアプリケーションにわたる既存の教師なしおよび教師ありの方法と比較して、常に高い登録精度と最先端の収束よりも高速な収束を実現します。学習されたノイズに対する不変性により、低品質の画像でよりスムーズな変換が可能になります。画像登録の意味的類似性メトリックを提案します。 
[ABSTRACT]既存のメトリックは強度値の調整に焦点を合わせており、低強度のコントラストまたはノイズで問題が発生します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: EvidentialMix: Learning with Combined Open-set and Closed-set Noisy
  Labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_24.html">
      <font color="black">EvidentialMix: Learning with Combined Open-set and Closed-set Noisy
  Labels</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、私たちの方法が以前の最先端の方法よりも優れた分類結果と優れた特徴表現を生成することを示しています。この作業では、開集合と閉集合を組み合わせたノイズの多いラベル問題の新しい変形を研究します。ノイズの多いラベル、およびこの設定でのトレーニングアルゴリズムのパフォーマンスを評価するためのベンチマーク評価を導入します。このフィールドでは、2種類のラベルノイズの下でのトレーニングモデルに焦点を当てることでこの問題に対処しました。1）一部のトレーニングサンプルが存在する閉集合ノイズ既知の真のクラス以外のトレーニングラベルに誤って注釈が付けられている。 2）オープンセットノイズ。トレーニングセットには、既知のトレーニングラベルのセットに（厳密には）含まれていない真のクラスを持つサンプルが含まれます。 
[概要]コードには、ノイズの多いラベルの問題の新しいスケールが含まれています。オープンセットとクローズドションのノイズの多いラベルが組み合わされています。これらには、トレーニング手法のパフォーマンスを評価するためのベンチマーク評価が含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Age Gap Reducer-GAN for Recognizing Age-Separated Faces -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_25.html">
      <font color="black">Age Gap Reducer-GAN for Recognizing Age-Separated Faces</font>
    </a>
  </h2>
  <font color="black">提案された生成的敵対的ネットワークアルゴリズムは、顔の年齢推定と年齢別の顔の検証を組み合わせた統合フレームワークです。このアプローチの重要なアイデアは、被験者の性別と対象年齢に基づいて入力画像を調整することにより、時間の経過に伴う年齢の変化を学習することです。顔を進行させる必要のあるグループ..本論文では、年齢の進行によって引き起こされる時間的変動と顔を照合するための新しいアルゴリズムを提案します。 
[概要]提案されたアルゴリズムは、顔の年齢推定と年齢別の顔の検証を組み合わせた統合フレームワークです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Learned Equivariant Rendering without Transformation Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_26.html">
      <font color="black">Learned Equivariant Rendering without Transformation Supervision</font>
    </a>
  </h2>
  <font color="black">MNISTを背景とともに移動した結果を示します。トレーニング後、シーンをリアルタイムで操作およびレンダリングして、オブジェクト、変換、および背景の目に見えない組み合わせを作成できます。ビデオからシーン表現を学習するための自己監視フレームワークを提案します。オブジェクトと背景に自動的に描画されます。 
[ABSTRACT]私たちの方法は、移動するオブジェクトがフレーム間での変換に関して同変であり、背景が一定であることに依存しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Noise2Sim -- Similarity-based Self-Learning for Image Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_27.html">
      <font color="black">Noise2Sim -- Similarity-based Self-Learning for Image Denoising</font>
    </a>
  </h2>
  <font color="black">この課題に対処するために、Noise2Noiseメソッドは、ペアのノイズクリーン画像を収集しやすいペアのノイズノイズ画像に置き換えることができるという事実に基づいています。ノイズ除去メソッドの背後にある重要なアイデアは、平均/平均化操作を実行することです。ローカルまたは非ローカル..ラベル付けされた画像をバイパスするために、Noise2Voidメソッドは、単一のノイズの多い画像でのみ、周囲からマスクされたピクセルを予測します。 
[ABSTRACT] noise2simはnlmです-画像のノイズ除去のためのインスピレーションを得た自己学習方法です。これはペアノイズ-クリーンな画像をペアノイズ、収集しやすいノイズ画像に置き換えることができるという事実に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-06">
        <br><font color="black">2020-11-06</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-supervised Sparse Representation with Graph Regularization for
  Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_28.html">
      <font color="black">Semi-supervised Sparse Representation with Graph Regularization for
  Image Classification</font>
    </a>
  </h2>
  <font color="black">構築されたグラフは、ラベル付きデータとラベルなしデータの両方に含まれる構造情報を抽出できます。ただし、ラベル付き画像は、特定の画像分類タスクに対して依然として非常に制限されています。したがって、対応する最適化問題を解決するための効率的なアルゴリズムが開発されています。 
[概要]十分なラベル付き画像で満足のいくパフォーマンスを実現できる方法が多数あります。代わりに、ラベルなし画像が多数用意されており、簡単に入手できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Intentonomy: a Dataset and Study towards Human Intent Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_29.html">
      <font color="black">Intentonomy: a Dataset and Study towards Human Intent Understanding</font>
    </a>
  </h2>
  <font color="black">次に、一般的に使用される視覚情報、つまりオブジェクトとコンテキストが人間の動機の理解に寄与するかどうか、またどの程度貢献するかを体系的に調査します。調査結果に基づいて、オブジェクトとコンテキストのクラスに参加することの効果を定量化するためのさらなる調査を行います。インテント分類器をトレーニングする際のハッシュタグ形式のテキスト情報も同様です。この目標に向けて、日常のさまざまなシーンをカバーする14Kの画像で構成されるインテントデータセットIntentonomyを紹介します。 
[概要]ソーシャルメディア画像の背後にある意図は研究者によって研究されています。彼らは視覚情報がどのように意図の範囲を促進できるかを分析することを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Tattoo tomography: Freehand 3D photoacoustic image reconstruction with
  an optical pattern -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_30.html">
      <font color="black">Tattoo tomography: Freehand 3D photoacoustic image reconstruction with
  an optical pattern</font>
    </a>
  </h2>
  <font color="black">このパターンは、その断層画像がパターンの座標系に対するプローブポーズの回復を可能にするように設計されています。方法：この論文では、PATデータの3D再構成への新しいアプローチを提示します（Tattooトモグラフィー）。 ）外部追跡システムを必要とせず、臨床ワークフローにスムーズに統合できます。これは、画像取得前に関心領域に配置された光学パターンに基づいています。 
[概要]従来適用されていた2dプローブによって提供される限られた視野（fov）。これは、関心領域に配置された光学パターンに基づいています。これにより、取得した一連のpa画像を共通のグローバル座標に復元できます。システム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: ForestNet: Classifying Drivers of Deforestation in Indonesia using Deep
  Learning on Satellite Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_31.html">
      <font color="black">ForestNet: Classifying Drivers of Deforestation in Indonesia using Deep
  Learning on Satellite Imagery</font>
    </a>
  </h2>
  <font color="black">データセットを使用してモデルをトレーニングおよび検証し、ForestNetが他の標準的なドライバー分類アプローチよりも大幅に優れていることを示します。森林破壊ドライバー分類への自動化アプローチに関する将来の研究をサポートするために、この調査でキュレーションされたデータセットはhttps：/で公開されています。 /stanfordmlgroup.github.io/projects/forestnet ..森林破壊につながるプロセスを特徴づけることは、対象を絞った森林保全および管理ポリシーの開発と実施にとって重要です。 
[概要]インドネシアの原生林喪失のドライバーを分類するために、フォレストネットと呼ばれる深層学習モデルが使用されています。専門家の通訳からドライバーの注釈が提供されます。データセットはstanfordmlgroupで公開されています。 github。 io /プロジェクト/フォレストネット。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervised Segmentation via Background Inpainting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_32.html">
      <font color="black">Self-supervised Segmentation via Background Inpainting</font>
    </a>
  </h2>
  <font color="black">データに注釈を付けるのに法外な費用がかかる場合にこれに対処するために、移動する可能性のあるカメラによってキャプチャされた単一の画像を処理できる自己監視検出およびセグメンテーションアプローチを導入します。アプローチの中心は、オブジェクトのセグメンテーションと背景の再構築がリンクされたタスク、および構造化されたシーンの場合、背景領域は周囲から再合成できますが、移動するオブジェクトを表す領域は再合成できません。この直感を自己監視損失関数にエンコードし、提案ベースのトレーニングに利用します。セグメンテーションネットワーク。 
[概要]私たちの方法は、移動する可能性のあるカメラによってキャプチャされた単一の画像で機能します。この直感を自己監視損失関数にエンコードします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: An HVS-Oriented Saliency Map Prediction Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_33.html">
      <font color="black">An HVS-Oriented Saliency Map Prediction Modeling</font>
    </a>
  </h2>
  <font color="black">この論文は、人間の低レベル視覚野機能に触発された新しい顕著性予測アーキテクチャを提案します。視覚的注意は、外界を選択して理解するための最も重要な特性の1つです。これは一般に視覚的注意予測または視覚的顕著性マップとして知られています。 
[要約]提案されたモデルの結果は、他の最先端の顕著性予測モデルと比較した評価であり、視覚的顕著性予測の達成されたパフォーマンスです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-08">
        <br><font color="black">2020-11-08</font>
      </time>
    </span>
</section>
<!-- paper0: Invertible CNN-Based Super Resolution with Downsampling Awareness -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_34.html">
      <font color="black">Invertible CNN-Based Super Resolution with Downsampling Awareness</font>
    </a>
  </h2>
  <font color="black">この画像のパフォーマンスの向上に加えて、この方法は物理科学に潜在的に広く重大な影響を及ぼします。ここでは、「ダウンサンプリング対応」の超解像ネットワークの方法を提案します。微分可能な演算子をの最終出力層として適用します。ダウンサンプリングされた出力を2D平均ダウンサンプリングの下で低解像度の入力データと一致させるニューラルネットワーク。 
[概要]「ダウンサンプリング対応」超解像ネットワークの手法を提案。このシステムは、医療スキャン、降水レーダー、グリッド数値シミュレーション、衛星イメージャ、その他多くのソースによって生成されたデータに適用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Transformers for One-Shot Visual Imitation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_35.html">
      <font color="black">Transformers for One-Shot Visual Imitation</font>
    </a>
  </h2>
  <font color="black">さらに、デモンストレーションは、形態と外観が異なるエージェントからのものである可能性があります（たとえば、制御とは別に、デモンストレーターとロボットドメイン間の不一致に起因する問題があります。ただし、これらの手法を拡張して、テスト時間中に単一の肯定的な例を処理します。 
[ABSTRACT]ニューラルネットワークは、別のエージェントからのコンテキストビデオが与えられた場合に、グラウンドトゥルースロボットのアクションを模倣するようにトレーニングされています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Skin disease diagnosis with deep learning: a review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_36.html">
      <font color="black">Skin disease diagnosis with deep learning: a review</font>
    </a>
  </h2>
  <font color="black">この論文では、深層学習法とその皮膚疾患診断への応用についてレビューします。最後に、記事を要約します。次に、深層学習の概念を紹介し、人気のある深層学習アーキテクチャを確認します。 
[ABSTRACT]ディープラーニングは皮膚病の診断の実装を可能にします。新しい技術にはディープラーニングと可能な将来の研究が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: GDN: A Coarse-To-Fine (C2F) Representation for End-To-End 6-DoF Grasp
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_37.html">
      <font color="black">GDN: A Coarse-To-Fine (C2F) Representation for End-To-End 6-DoF Grasp
  Detection</font>
    </a>
  </h2>
  <font color="black">さらに、回転誤差と遷移誤差の両方を考慮した新しいAPベースのメトリックを提案し、把持検出モデルのより包括的な評価ツールにします。エンドツーエンドの把持検出ネットワークである把持検出ネットワーク（GDN）を提案しました。新しい粗から細（C2F）把握表現設計と協力して、ポイントクラウドに基づいて多様で正確な6-DoF把握を検出します。複数の把握候補をサンプリングして評価する以前の2段階アプローチと比較して、私たちのアーキテクチャは少なくとも20倍速くなります。 
[概要]私たちのアーキテクチャは少なくとも20倍高速です。以前の2-fアプローチよりも正確です。私たちの方法は設定で優れた結果を示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Object Detection from a Single Fisheye Image Without a Single Fisheye
  Training Image -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_38.html">
      <font color="black">3D Object Detection from a Single Fisheye Image Without a Single Fisheye
  Training Image</font>
    </a>
  </h2>
  <font color="black">既存の単眼3Dオブジェクト検出方法は、直線透視画像で実証されており、魚眼カメラで取得したような代替投影の画像では失敗します。また、実際の魚眼画像の内部データセットで実験します。この作業では、その方法を示します。魚眼トレーニングデータを使用せずに、魚眼カメラからの画像内の3Dオブジェクトを検出するために、直線画像のみでトレーニングされた既存の単眼3Dオブジェクト検出モデルを使用します。 
[概要]魚眼画像でのオブジェクト検出に関するこれまでの研究は、そのような画像の3D 3Dデータセットに焦点を当てていました。既存のメソッドは、ターゲットの非直線投影でトレーニングしますが、直線画像でのみトレーニングします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-08">
        <br><font color="black">2020-03-08</font>
      </time>
    </span>
</section>
<!-- paper0: LIFI: Towards Linguistically Informed Frame Interpolation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_39.html">
      <font color="black">LIFI: Towards Linguistically Informed Frame Interpolation</font>
    </a>
  </h2>
  <font color="black">また、音声理解のコンピュータービジョンビデオ生成モデルをテストするために、いくつかのデータセットをリリースします。この動機により、音声ビデオ補間の問題を特に対象とした、言語情報に基づく新しいメトリックのセットを提供します。このようなコンテンツは、今日、主要な形式を形成しています。オンライン通信の。 
[概要]音声理解のコンピュータービジョンビデオ生成モデルをテストするためのいくつかのデータセットもリリースします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-30">
        <br><font color="black">2020-10-30</font>
      </time>
    </span>
</section>
<!-- paper0: A Hybrid Approach for 6DoF Pose Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_40.html">
      <font color="black">A Hybrid Approach for 6DoF Pose Estimation</font>
    </a>
  </h2>
  <font color="black">このハイブリッドアプローチは、CNNを使用して高度に非構造化されたデータをフィルタリングし、クラッターをカットする、最高の学習アプローチと従来のアプローチ、および堅牢なポーズ推定のための実証済みの収束を備えたローカル幾何学的アプローチを活用します。このメソッドは、BOPコアデータセットで評価されます。ベースライン法を大幅に上回り、BOP 2020チャレンジで最も高速な方法です。最先端の深層学習ベースのインスタンス検出器を使用してオブジェクトインスタンスをセグメント化する、剛体オブジェクトの6DoFポーズ推定の方法を提案します。 RGB画像に続いて、オブジェクトのポーズを復元するためのポイントペアベースの投票方法。 
[概要]この方法は、オブジェクトを大幅に超えるデータデータセットに基づいています。これは、bop2020ポイントで最も高速な方法です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Transferred Fusion Learning using Skipped Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_41.html">
      <font color="black">Transferred Fusion Learning using Skipped Networks</font>
    </a>
  </h2>
  <font color="black">ネットワークが相互に学習する学生アーキテクチャを導入することにより、転移学習のプロセスを増幅する新しいメカニズムを提案します。転移学習やゼロショット学習などのいくつかの方法は、既存のモデルを再利用したり、既存のモデルを拡張して改善を実現したりするのに役立ちます。オブジェクト認識のタスクでのパフォーマンス..関心のあるエンティティの識別は、どのインテリジェントシステムでも顕著です。 
[概要]認識能力が向上すると、モデルの視覚知能が向上します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Domain Adaptive Object Detection: a Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_42.html">
      <font color="black">Deep Domain Adaptive Object Detection: a Survey</font>
    </a>
  </h2>
  <font color="black">第二に、ディープドメイン適応検出器は5つのカテゴリに分類され、各カテゴリの代表的な方法の詳細な説明が提供されます。この論文は、ディープドメイン適応オブジェクト検出アプローチの最先端の進歩をレビューすることを目的としています。 2つの仮定が実際に常に当てはまるとは限りません。 
[ABSTRACT]ディープドメイン適応オブジェクト検出（ddaod）は、上記の課題に対処するための新しい学習ツールとして登場しました。最初に、ディープドメイン適応の基本概念を簡単に紹介します。最後に、将来の研究動向に関する洞察を示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-17">
        <br><font color="black">2020-02-17</font>
      </time>
    </span>
</section>
<!-- paper0: Finding Relevant Flood Images on Twitter using Content-based Filters -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_43.html">
      <font color="black">Finding Relevant Flood Images on Twitter using Content-based Filters</font>
    </a>
  </h2>
  <font color="black">洪水などの自然災害をタイムリーに分析すると、センサーが粗く分散したり、センサーが故障したりするため、データが限られていることがよくあります。2つの主要な洪水イベントのケーススタディで、2つの異なるアプローチとさまざまな機能のパフォーマンスを評価します。フィルタは、ツイートに存在するテキスト情報に依存する代わりに、画像の内容を直接分析します。 
[概要]イベントの画像は、ツイッターなどのソーシャルメディアプラットフォームにアップロードされました。素材に依存するのではなく、フィルターがツイートの画像コンテンツを分析します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: DeepI2I: Enabling Deep Hierarchical Image-to-Image Translation by
  Transferring from GANs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_44.html">
      <font color="black">DeepI2I: Enabling Deep Hierarchical Image-to-Image Translation by
  Transferring from GANs</font>
    </a>
  </h2>
  <font color="black">知識の伝達を適用すると、エンコーダーとジェネレーターの間のアライメントの問題が発生します。さらに、伝達学習により、特に小さなデータセットの場合、I2Iシステムのパフォーマンスが大幅に向上することを定性的および定量的に示します。小さなデータセットで深いI2Iモデルのトレーニングを可能にするため。 、事前に訓練されたGANから知識を伝達する新しい伝達学習方法を提案します。 
[概要]たとえば、deepi2iと呼ばれる新しいdeep-in-resolutionメソッドを提案します。このメソッドはデータセットに基づいていますが、パフォーマンスが劣ります。これは、小さなデータセットでのdeepi2iモデルのトレーニングを可能にするために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: NL-LinkNet: Toward Lighter but More Accurate Road Extraction with
  Non-Local Operations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_45.html">
      <font color="black">NL-LinkNet: Toward Lighter but More Accurate Road Extraction with
  Non-Local Operations</font>
    </a>
  </h2>
  <font color="black">さらに、NL-LinkNetは、DeepGlobeチャレンジの勝者であるD-LinkNetを打ち負かし、パラメーターが43 \％少なく、1秒あたりのギガ浮動小数点演算（GFLOP）が少なく、トレーニングの収束時間が短くなっています。ベースラインモデルの非ローカルブロックの適切な使用法。詳細には、CRFリファインメントなどの後処理のない単一モデルは、公式のDeepGlobeチャレンジで公開されている他の最先端のアンサンブルモデルよりも優れたパフォーマンスを示しました。 
[概要]新しいチャレンジチャレンジチャレンジは、抵抗力のないローカルブロックを備えた効率的な非ローカルリンクネットを提案します。このプロジェクトは、公式のディープネットチャレンジに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-22">
        <br><font color="black">2019-08-22</font>
      </time>
    </span>
</section>
<!-- paper0: GRCNN: Graph Recognition Convolutional Neural Network for Synthesizing
  Programs from Flow Charts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_46.html">
      <font color="black">GRCNN: Graph Recognition Convolutional Neural Network for Synthesizing
  Programs from Flow Charts</font>
    </a>
  </h2>
  <font color="black">プログラムを合成するのに平均して約60ミリ秒かかります。実験によると、プログラムを合成するための正解率は66.4％であり、エッジとノードを認識するための正解率はそれぞれ94.1％と67.9％です。そこで、画像からグラフ構造を認識するGRCNNと呼ばれる深いニューラルネットワークを提案します。 【アブストラクト】本論文では、正確で直感的な仕様となるグラフ構造からプログラムを合成するシステムを提案する。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: DASNet: Dual attentive fully convolutional siamese networks for change
  detection of high resolution satellite images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_47.html">
      <font color="black">DASNet: Dual attentive fully convolutional siamese networks for change
  detection of high resolution satellite images</font>
    </a>
  </h2>
  <font color="black">疑似変化に対する現在の方法の抵抗の欠如を克服するために、本論文では、新しい方法、すなわち、高解像度画像の変化検出のためのデュアルアテンシブ完全畳み込みシャムネットワーク（DASNet）を提案する。しかし、利用可能な方法主に多時期リモートセンシング画像間の差異情報に焦点を当て、疑似変化情報に対するロバスト性に欠けます。さらに、不均衡なサンプルは変化検出における深刻な問題です。つまり、
[ABSTRACT]研究の目的は関心のある変化情報を特定することです。新しい方法は、主に複数の変更間の差異情報に焦点を当てています。これは、新しい方法がないためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-07">
        <br><font color="black">2020-03-07</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Learning of Dense Visual Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_48.html">
      <font color="black">Unsupervised Learning of Dense Visual Representations</font>
    </a>
  </h2>
  <font color="black">VADeRは、ローカルフィーチャをさまざまな表示条件で一定に保つことにより、ピクセル単位の表現を学習します。具体的には、これはピクセルレベルの対照学習によって実現されます。マッチングフィーチャ（つまり、異なるビューでシーンの同じ場所を記述するフィーチャ）は次のようになります。一致しない機能は分離する必要がありますが、埋め込みスペースで閉じます。私たちの方法は、複数の密な予測タスクでImageNetの教師あり事前トレーニング（および強力な教師なしベースライン）よりも優れています。 
[概要]私たちの方法は、複数の密な予測タスクでimagenetの教師あり事前トレーニングよりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Survey on 3D face reconstruction from uncalibrated images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_49.html">
      <font color="black">Survey on 3D face reconstruction from uncalibrated images</font>
    </a>
  </h2>
  <font color="black">その結果、キャリブレーションされていない2D画像から3D顔を再構築するシステムの開発に多大な努力が費やされました。さらに、事前知識としての統計的3D顔モデルの関連性を考慮して、構築手順を説明し、公開されている3D顔モデル..統計モデルフィッティング、測光、深層学習の3つの主要な戦略を考慮し、それぞれを個別にレビューして、事前知識を追加するために使用される手法に基づいて提案手法の分類を示します。 
[概要] 3d-2d顔再構成の問題が悪い-これは、ソリューションのスペースを制限するために事前の知識が必要であることを意味します。これらの手法には、統計モデルのフィッティング、光度計、深層学習が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Attention: Attention with Linear Complexities -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_50.html">
      <font color="black">Efficient Attention: Attention with Linear Complexities</font>
    </a>
  </h2>
  <font color="black">ただし、メモリと計算のコストは入力サイズに応じて2次関数的に増加します。効率的なアテンションモジュールにより、MS-COCO 2017のオブジェクト検出器とインスタンスセグメンターのパフォーマンスが大幅に向上しました。 
[ABSTRACT]アテンションメカニズムはドット-製品アテンションと同等ですが、メモリとコンピューティングのコストが大幅に少なくなります。リソース効率により、コストが高いためドット-シーンアテンションの使用が禁止されている複雑なモデルへのアテンションが民主化されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-04">
        <br><font color="black">2018-12-04</font>
      </time>
    </span>
</section>
<!-- paper0: Labeling of Multilingual Breast MRI Reports -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_51.html">
      <font color="black">Labeling of Multilingual Breast MRI Reports</font>
    </a>
  </h2>
  <font color="black">私たちの提案する方法は、臨床現場で直面する実際的な課題を克服し、従来のアプローチと比較して、医療レポートからラベルを抽出する際のパフォーマンスが向上することを示しています。ただし、医療レポートの大部分は、正規化されていない形式で保存され、訓練を受けた人間のアノテーター（通常は医師）は、各ケースを手動で評価してラベルを付ける必要があるため、費用と時間のかかる手順になります。この作業では、LAMBRと呼ばれるカスタムビルドの言語表現を使用して多言語乳房MRIレポート分類子を開発するためのフレームワークを示します。 
[概要]データセットには、大きなラベル付きフォーマットを作成するために抽出できる貴重な情報が含まれています。データセットは、臨床ツールの開発に必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Hi-UCD: A Large-scale Dataset for Urban Semantic Change Detection in
  Remote Sensing Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_52.html">
      <font color="black">Hi-UCD: A Large-scale Dataset for Urban Semantic Change Detection in
  Remote Sensing Imagery</font>
    </a>
  </h2>
  <font color="black">洗練された都市の変化を検出および分析するために使用できます。実験結果は、Hi-UCDが挑戦的でありながら有用であることを示しています。バイナリおよびマルチクラスの変化検出でいくつかの古典的な方法を使用してデータセットをベンチマークします。 
[概要]このデータセットは、空間解像度が0.1 mの航空写真を使用しています。3つの時相が含まれ、9つのクラスの土地被覆で意味的に注釈が付けられています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-06">
        <br><font color="black">2020-11-06</font>
      </time>
    </span>
</section>
<!-- paper0: An Adversarial Objective for Scalable Exploration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_53.html">
      <font color="black">An Adversarial Objective for Scalable Exploration</font>
    </a>
  </h2>
  <font color="black">シミュレートされた環境での主要なモデルベースの探索戦略に対する敵対的好奇心アプローチの計算が制限されるにつれて、徐々に増加する利点を示します。弁別ネットワークによって与えられるスコアを最小化する敵対的好奇心方法でこれらのスケーラビリティの問題に対処します。敵対的な好奇心の方法が、ドメイン転送問題のサンプル効率と予測パフォーマンスを向上させるロボット操作予測計画パイプラインに拡張する能力。 
[ABSTRACT]既存のモデルベースの好奇心手法は、多くの予測へのスケーリングに苦労するアプローチで相対的な不確実性に目を向けます。この弁別子は、予測モデルと共同で最適化され、予測を考慮した結果となる観測とアクションのシーケンスをサンプリングするアクティブラーニングアプローチを可能にします。最も現実的でない</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-13">
        <br><font color="black">2020-03-13</font>
      </time>
    </span>
</section>
<!-- paper0: COVIDGR dataset and COVID-SDNet methodology for predicting COVID-19
  based on Chest X-Ray images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_54.html">
      <font color="black">COVIDGR dataset and COVID-SDNet methodology for predicting COVID-19
  based on Chest X-Ray images</font>
    </a>
  </h2>
  <font color="black">この論文は3つあります：（i）最新のCOVID-19分類モデルによって達成された高感度をわかりやすく説明します。（ii）スペインのグラナダにあるHospital Universitario Cl \ &#39;inico San Cecilioと緊密に協力して、COVIDGRを構築しました- 1.0、陽性RT-PCRによる正常、軽度、中等度から重度まで、すべてのレベルの重症度を含む均質でバランスの取れたデータベース。深部学習神経ネットワークは、COVID-19トライアージュシステムを構築し、COVID-19患者を検出する大きな可能性を秘めています。 、特に重症度の低い患者.. COVIDGR-1.0と重症度レベルのラベルは、このリンクhttps://dasci.es/es/transferencia/open-data/covidgr/から科学界で入手できます。 
[要約] ct（ct）スキャナーとrt-pcrテストは、ほとんどの医療センターでは利用できません。しかし、多くの場合、cxr画像は、臨床医が意思決定を行うのを支援するための最も時間と費用効果の高いツールになります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-02">
        <br><font color="black">2020-06-02</font>
      </time>
    </span>
</section>
<!-- paper0: Invariant Deep Compressible Covariance Pooling for Aerial Scene
  Categorization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_55.html">
      <font color="black">Invariant Deep Compressible Covariance Pooling for Aerial Scene
  Categorization</font>
    </a>
  </h2>
  <font color="black">識別的で不変の特徴表現を学習することは、視覚的な画像分類の鍵です。D4グループなど、複数の交絡直交行列で構成される有限変換グループに従って入力画像を変換することを検討します。簡単な表現でトレーニングされた線形分類器は、また、不変性に取り憑かれています。 
[概要]この記事では、空中状態の分類におけるこの悲惨な変動を解決するために、新しいトークンの深い圧縮性共分散プーリング（idccp）を提案します。シャムスタイルのネットワークを採用して、グループ構造を表現空間に転送します。群作用の下で大丈夫な自明表現。表現の識別力をさらに向上させるために、表現をラミレスに拡張して特徴の次元を減らします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Open-World Reliability Assessment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_56.html">
      <font color="black">Automatic Open-World Reliability Assessment</font>
    </a>
  </h2>
  <font color="black">したがって、標準分類器またはオープンセット分類器のいずれについても、世界がいつ変化し、OOD入力が増えるとシステムの信頼性が低下するかを判断できることが重要です。ただし、オープンセット分類器の最適な精度はOODの頻度に依存します。データ..ただし、運用中はラベルがないため、直接精度を評価することはできません。 
[ABSTRACT]システムは自動的にood画像を拒否する必要があります。そうしないと、既知のクラスの上にマッピングされます。ただし、softmaxとopen-set分類子はoodデータの頻度に依存します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-modal, multi-task, multi-attention (M3) deep learning detection of
  reticular pseudodrusen: towards automated and accessible classification of
  age-related macular degeneration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_57.html">
      <font color="black">Multi-modal, multi-task, multi-attention (M3) deep learning detection of
  reticular pseudodrusen: towards automated and accessible classification of
  age-related macular degeneration</font>
    </a>
  </h2>
  <font color="black">RPD検出のパフォーマンスは、最先端の深層学習モデルおよび13人の眼科医と比較されました。他の2つのAMD機能（地図状萎縮と色素異常）の検出性能も評価されました。加齢性黄斑変性症（AMD）の重要な機能である客観的網状偽ドルーゼン（RPD）は、標準的な色眼底の人間の専門家によってほとんど検出されていません。写真（CFP）であり、通常、眼底自家蛍光（FAF）などの高度な画像診断法が必要です。結果RPD検出の場合、M3は、CFPのみ、FAFのみ、およびその両方で、レシーバー動作特性（AUROC）0.832、0.931、および0.933の下で面積を達成しました。それぞれ。 
[概要] rpd検出に関する疑似サイズの `m3 &#39;ディープラーニングフレームワーク。これには、multi --rpd、multi --task（さまざまなタスクのトレーニング）、およびmulti --attention（libyan）操作が含まれます。これらにはmulti --modal（からの検出主要な画像モダリティ）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: A Benchmark and Evaluation of Non-Rigid Structure from Motion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_58.html">
      <font color="black">A Benchmark and Evaluation of Non-Rigid Structure from Motion</font>
    </a>
  </h2>
  <font color="black">ここでは、この目的のために作成されたデータセットを提示することでこの問題に対処します。このデータセットは公開されており、以前の最先端技術よりもかなり大きくなっています。非剛体構造運動（NRSfM）は、長年の中心的な問題です。シーンが動的であるときに複数の画像から3D情報を取得するには、コンピュータビジョンとそのソリューションが必要です。この新しい公開データセットと評価プロトコルは、この困難な分野でのさらなる開発のためのベンチマークツールを提供します。 
[概要]この新しい公開データセットと評価プロトコルは、この困難な分野でのさらなる開発のためのベンチマークツールを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-01-25">
        <br><font color="black">2018-01-25</font>
      </time>
    </span>
</section>
<!-- paper0: A CNN-based Feature Space for Semi-supervised Incremental Learning in
  Assisted Living Applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_59.html">
      <font color="black">A CNN-based Feature Space for Semi-supervised Incremental Learning in
  Assisted Living Applications</font>
    </a>
  </h2>
  <font color="black">この論文では、アシスティッド・リビングの文脈でこの問題に関心を持っています。畳み込みニューラルネットワーク（CNN）は、その一般化能力を超える外観の変化のオブジェクト（新しいインスタンス）に直面することがあります。これには、CNNを組み込む必要があります。新しい知識、つまり段階的に学習する。 
[概要]トレーニングデータセットから得られた特徴空間を使用して、cnnで適切に認識できなかった問題のある画像に自動的にラベルを付けて、アイデアを活用することを提案します。結果として得られる半教師あり増分学習プロセスにより、新しいの分類精度が向上します。インスタンスが40％</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Discovering of Interpretable Features for Reinforcement
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_60.html">
      <font color="black">Self-Supervised Discovering of Interpretable Features for Reinforcement
  Learning</font>
    </a>
  </h2>
  <font color="black">具体的には、自己監視解釈可能ネットワーク（SSINet）を使用して、タスク関連情報を強調表示するためのきめ細かい注意マスクを作成します。これは、エージェントの決定のほとんどの証拠となります。いくつかのAtari 2600ゲームでも、この方法を検証および評価します。挑戦的な自動運転カーシミュレーター環境であるダッキータウンとして..しかし、エージェントの意思決定プロセスは一般的に透過的ではありません。 
[要約]いくつかの方法は視覚ベースのrlを解釈しようとしましたが、ほとんどはエージェントの行動の詳細な説明がありません。この方法は、エージェントがどのように決定を下すかについての証拠を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-16">
        <br><font color="black">2020-03-16</font>
      </time>
    </span>
</section>
<!-- paper0: Attention Beam: An Image Captioning Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_61.html">
      <font color="black">Attention Beam: An Image Captioning Approach</font>
    </a>
  </h2>
  <font color="black">最近、エンコーダ-デコーダベースのアーキテクチャは、画像キャプションの最先端の結果を達成しています。画像キャプションの目的は、特定の画像のテキスト記述を生成することです。ここでは、ビーム検索のヒューリスティックを提示します。 Flickr8k、Flickr30k、MS COCOの3つのベンチマークデータセットでより高品質のキャプションを提供する、エンコーダ-デコーダベースのアーキテクチャのトップ。 
[概要]エンコーダー（デコーダーベースのアーキテクチャー）は、3つのベンチマークデータセット（flickr8k、flickr30k、ms coco）でより良いキャプションを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Progressive Spatio-Temporal Graph Convolutional Network for
  Skeleton-Based Human Action Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_62.html">
      <font color="black">Progressive Spatio-Temporal Graph Convolutional Network for
  Skeleton-Based Human Action Recognition</font>
    </a>
  </h2>
  <font color="black">スケルトンベースの人間の行動認識のために広く使用されている2つのデータセットに関する実験結果は、提案された方法が、計算の複雑さがはるかに低い最先端の方法と比較して、競争力のある、またはさらに優れた分類性能を持っていることを示しています。プログレッシブ方式で時空間グラフ畳み込みネットワークのコンパクトで問題固有のトポロジを自動的に見つける方法。グラフ畳み込みネットワーク（GCN）は、スケルトンのシーケンスが次のようにモデル化されるスケルトンベースの人間の行動認識で非常に成功しています。グラフ。 
[要約]提案された方法は、はるかに低コストの最先端の方法と比較して、競争力のある、またはさらに優れた分類性能を備えています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Learning from THEODORE: A Synthetic Omnidirectional Top-View Indoor
  Dataset for Deep Transfer Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_63.html">
      <font color="black">Learning from THEODORE: A Synthetic Omnidirectional Top-View Indoor
  Dataset for Deep Transfer Learning</font>
    </a>
  </h2>
  <font color="black">合成データセットを全方位画像の最先端の実世界データセットと比較します。この目的のために、リビングルーム、さまざまな人間のキャラクター、インテリアテクスチャの3D仮想環境を作成します。MSCOCOの重みに基づいて、データセットは、オブジェクト検出用のCNNの微調整に最適です。 
[ABSTRACT]巨大サイズのインタラクティブデータセットには、14クラスの魚眼画像が含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Skeleton-based Relational Reasoning for Group Activity Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_64.html">
      <font color="black">Skeleton-based Relational Reasoning for Group Activity Analysis</font>
    </a>
  </h2>
  <font color="black">次に、個人の個別の関係が注意メカニズムによってマージされます。これにより、グループの活動を区別するためにより関連性の高いものがより重要になります。バレーボール）。関節の関係に加えて、個人と関連オブジェクトの間のこれまで未踏の関係も実験します（たとえば、
[ABSTRACT]提案されたメソッドgirnを使用すると、2つのオブジェクト間の関係を記述する複数の関係タイプが別々のモジュールから推測されます。バレーボールデータセットでそれらのメソッドを評価し、最先端の競争力のある結果を取得します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: An ensemble-based approach by fine-tuning the deep transfer learning
  models to classify pneumonia from chest X-ray images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_65.html">
      <font color="black">An ensemble-based approach by fine-tuning the deep transfer learning
  models to classify pneumonia from chest X-ray images</font>
    </a>
  </h2>
  <font color="black">この作業では、ニューラルネットワークのトレーニング時間を短縮し、汎化誤差を最小限に抑えることができる転移学習の使用を提案します。その後、これらのモデルの加重平均アンサンブルを作成し、98.46％のテスト精度、98.38％の精度を達成しました。 99.53％のリコール、98.96％のf1スコア..肺炎を正確に分類するために、InceptionResNet、MobileNetV2、Xception、DenseNet201、ResNet152V2などの最先端の深層学習モデルをトレーニングおよび微調整しました。 
[概要]米国では毎年25万人以上が肺炎と診断されています。5万人がこの病気で亡くなっています。肺炎を正確に分類するために肺を訓練し、微調整しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: A Unified Framework for Compressive Video Recovery from Coded Exposure
  Techniques -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CV/paper_66.html">
      <font color="black">A Unified Framework for Compressive Video Recovery from Coded Exposure
  Techniques</font>
    </a>
  </h2>
  <font color="black">私たちの学習ベースのフレームワークは、シフトバリアント畳み込み層とそれに続く完全畳み込みディープニューラルネットワークで構成されています。提案された統合フレームワークは、3つのセンシング技術すべてで最先端の再構成を実現します。効果的なビデオリカバリでは、定量的または定性的に2つの測定の明確な利点をまだ認識していません。 
[概要] 1回の露光で2つの圧縮測定値を取得するために、コード化された2バケットカメラが提案されています。これは、1つの測定値しか取得できない以前に提案されたコード化された露光技術とは異なります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Morphological Disambiguation from Stemming Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_0.html">
      <font color="black">Morphological Disambiguation from Stemming Data</font>
    </a>
  </h2>
  <font color="black">形態素が豊富な言語であるルワンダ語には、現在、自動形態素解析用のツールがありません。機能エンジニアリングとフィードフォワードニューラルネットワークベースの分類器を使用して、約89％の非コンテキスト化された曖昧性解消の精度を達成します。形態素解析と曖昧性解消は重要なタスクであり、形態素的に豊富な言語の自然言語処理における重要な前処理ステップ。 
[概要]新しい研究によると、語幹の語尾変化特性と形態素相関ルールが、明確化のための最も識別力のある特徴であることが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: ValNorm Quantifies Semantics to Reveal Consistent Valence Biases Across
  Languages and Over Centuries -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_1.html">
      <font color="black">ValNorm Quantifies Semantics to Reveal Consistent Valence Biases Across
  Languages and Over Centuries</font>
    </a>
  </h2>
  <font color="black">単語埋め込みにおける人間のようなバイアスを定量化する方法を拡張することにより、ValNormを紹介します。これは、新しい単語埋め込み固有の評価タスクであり、単語の価数（不快感/不快感）の感情的な意味を高精度で測定する方法です。特にバイアスを測定する場合、価数基準と単語埋め込みの精度を評価するために使用できます。私たちの結果は、この単語セットの価数の関連付けが過去2世紀の広く共有された関連付けを表すことを示しています。 
[概要]社会的バイアスは社会的バイアスを検出および定量化できます。埋め込みは英語と英語の埋め込みに基づいています。私たちの方法は一貫して高い精度を実現します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-06">
        <br><font color="black">2020-06-06</font>
      </time>
    </span>
</section>
<!-- paper0: Personal-ITY: A Novel YouTube-based Corpus for Personality Prediction in
  Italian -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_2.html">
      <font color="black">Personal-ITY: A Novel YouTube-based Corpus for Personality Prediction in
  Italian</font>
    </a>
  </h2>
  <font color="black">将来の作業のベースラインとして役立つPersonal-ITYの予備実験について報告し、一部のタイプが他のタイプよりも予測しやすいことを示し、クロスデータセット予測の特典について説明します。パーソナリティ予測の新しいコーパスを提示します。イタリア語で、以前に利用可能なリソースと比較してより多くの著者と異なるジャンルが含まれています。コーパスは、遠方の監督を利用して構築され、YouTubeのコメントにMyers-Briggs Type Indicator（MBTI）ラベルを割り当て、さまざまなものに役立ちます。実験。 
[概要]コーパスは、遠隔監視を利用して構築され、マイヤーズを割り当てます-ブリッグスタイプインジケーター（mbti）ラベルをYouTubeのコメントに割り当てます。さまざまな実験に役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Overview of CAPITEL Shared Tasks at IberLEF 2020: Named Entity
  Recognition and Universal Dependencies Parsing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_3.html">
      <font color="black">Overview of CAPITEL Shared Tasks at IberLEF 2020: Named Entity
  Recognition and Universal Dependencies Parsing</font>
    </a>
  </h2>
  <font color="black">CAPITEL-EVALは、2つのサブタスクで構成されていました。（1）名前付きエンティティの認識と分類、および（2）ユニバーサル依存関係の解析。このタスクに関するデータ、結果、および詳細情報は、sites.google.com / view / capitel2020 ..にあります。どちらのソースデータも、newswireドメインのスペイン語記事のコレクションである新たに注釈が付けられたコーパスCAPITELでした。 
[概要]合計7チームがcapitel-evalに参加し、すべてのサブタスクで13回の実行が送信されました。結果は月末に発表されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Parameter Norm Growth During Training of Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_4.html">
      <font color="black">Parameter Norm Growth During Training of Transformers</font>
    </a>
  </h2>
  <font color="black">事前トレーニングされたT5が、飽和した活性化関数を持つ半離散化ネットワークに近似することを示します。経験的に、T5の事前トレーニングよりもノルムが継続的に増加することを示します（Raffel et al。、2019）。これは、時間の経過とともにトレーニングの精度を上げることで、ノルムが可能になることを意味します。を増やす。 
[要約]トレーニングルーチンの誘導バイアスのためにネットワークが正常に学習したという証拠が浮上しています。通常、gd.gdの一部のバリアントは、トレーニングとともに増加するしきい値まで因子の線量を増加させます-精度を設定します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-19">
        <br><font color="black">2020-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: Spoken Language Interaction with Robots: Research Issues and
  Recommendations, Report from the NSF Future Directions Workshop -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_5.html">
      <font color="black">Spoken Language Interaction with Robots: Research Issues and
  Recommendations, Report from the NSF Future Directions Workshop</font>
    </a>
  </h2>
  <font color="black">第6に、ロボットは複雑な環境で動作するため、音声コンポーネントは、ロボットがオブジェクト、場所、ノイズ源、ユーザー、およびその他の人間について知っていることの豊富で効率的な表現にアクセスする必要があります。第8に、より多くの研究に加えて、より多くのことが必要です。共有可能なソフトウェアモジュールと内部インターフェース、安価なハードウェア、ベースラインシステム、多様なコーパスなどのインフラストラクチャとリソースに取り組みます。次に、言語使用の社会的およびインタラクティブな側面のより良いモデルが必要です。 
[概要]調査：必要な科学的および工学的進歩を特定します。これには、音声テクノロジーとユーザーエクスペリエンスデザインの新しい課題への対処が含まれます。堅牢性のために、ロボットにはユーザーとのより高い帯域幅の通信が必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_6.html">
      <font color="black">ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language</font>
    </a>
  </h2>
  <font color="black">また、800のScanNetシーンからの11,046オブジェクトの51,583の説明を含むScanReferデータセットを紹介します。このタスクに対処するために、3Dオブジェクトの提案とエンコードされた文の埋め込みから融合記述子を学習するScanReferを提案します。ScanReferは最初の大規模な取り組みです。自然言語表現を介してオブジェクトのローカリゼーションを3Dで直接実行します。 
[ABSTRACT] scanreferは、オブジェクトのローカリゼーションを実行する最初の大規模な取り組みです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br><font color="black">2019-12-18</font>
      </time>
    </span>
</section>
<!-- paper0: Simultaneous Speech-to-Speech Translation System with Neural Incremental
  ASR, MT, and TTS -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_7.html">
      <font color="black">Simultaneous Speech-to-Speech Translation System with Neural Incremental
  ASR, MT, and TTS</font>
    </a>
  </h2>
  <font color="black">この論文では、新しく開発された同時ニューラル音声から音声への翻訳システムとその評価を紹介します。システムのEar-Voice Spanでの全体的な遅延と、モジュールレベルのパフォーマンスとともに話す遅延を調査しました。システムは3つの完全な構成で構成されています。 -自動音声認識（ASR）、機械翻訳（MT）、およびテキストから音声への合成（TTS）用のインクリメンタルニューラル処理モジュール。 
[概要]システムは3つの完全にインクリメンタルな神経処理モジュールで構成されています。システムは3つの高度に高度に制御されたスピーキングシステムで構成されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Intent Mining from past conversations for Conversational Agent -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_8.html">
      <font color="black">Intent Mining from past conversations for Conversational Agent</font>
    </a>
  </h2>
  <font color="black">このシステムは会話型システムのインテントモデルを構築するために開発されていますが、このフレームワークは短いテキストのクラスタリングやラベリングフレームワークとしても使用できます。さまざまなインテントのトレーニングデータを実質的かつ広範囲に収集することは、ボット構築プロセス..チャットボットは、24時間サポートを提供し、顧客エンゲージメントを高めるためにますます展開されています。 
[ABSTRACT]インテントモデルは、文学的発話とインテントラベルのペアのコレクションを使用して、教師あり設定でトレーニングされます。インテントで数百から数千の会話にラベルを付けるコストは、時間と労力を要する作業です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-22">
        <br><font color="black">2020-05-22</font>
      </time>
    </span>
</section>
<!-- paper0: E-commerce Query-based Generation based on User Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_9.html">
      <font color="black">E-commerce Query-based Generation based on User Review</font>
    </a>
  </h2>
  <font color="black">ユーザーの質問やターゲットの感情の極性を考慮して、関心のある側面を抽出し、以前の関連するユーザーレビューを要約する回答を生成します。具体的には、モデルはエンコード中に入力レビューとターゲットの側面の間で注意を払い、レビューの評価とデコード中の入力コンテキスト..モデルのパフォーマンスを向上させ、トレーニング中の収束を加速するために、事前にトレーニングされた補助評価分類器も組み込まれています。 【概要】以前のユーザーからのレビューをもとに、ユーザーの質問への回答を作成する新システムを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Situated Data, Situated Systems: A Methodology to Engage with Power
  Relations in Natural Language Processing Research -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_10.html">
      <font color="black">Situated Data, Situated Systems: A Methodology to Engage with Power
  Relations in Natural Language Processing Research</font>
    </a>
  </h2>
  <font color="black">また、偏ったテキストの定義、偏ったNLPシステムの影響についての議論、アーカイブメタデータ記述の研究でバイアスを意識した方法論をどのように実行しているかを示すケーススタディも提供します。NLPの研究が社会的文脈で偏見に関与することはめったにありません。 、バイアスを軽減する能力を制限します。研究者は行動、技術的方法、および文書化の実践を推奨していますが、バイアスに関する批判的な考察を技術的NLP方法と統合する方法論は存在しません。 
[要約]新しい研究は、私たちが研究のためのシステムに貢献していることを示しています。また、私たちは偏見があることを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: IGSQL: Database Schema Interaction Graph Based Neural Model for
  Context-Dependent Text-to-SQL Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_11.html">
      <font color="black">IGSQL: Database Schema Interaction Graph Based Neural Model for
  Context-Dependent Text-to-SQL Generation</font>
    </a>
  </h2>
  <font color="black">2つの大規模で複雑なコンテキスト依存のクロスドメインテキストからSQLへのデータセットであるベンチマークSParCおよびCoSQLデータセットでモデルを評価します。この作業では、エンコーダーを使用してユーザー入力の履歴情報をキャプチャすることに加えて、提案します。データベーススキーマアイテムの履歴情報を利用するデータベーススキーマ相互作用グラフエンコーダー。私たちのモデルは、以前の最先端モデルを大幅に上回り、2つのデータセットで新しい最先端の結果を実現します。 
[ABSTRACT]コンテキストに依存するテキスト-to-text-text-to-textnessの以前のモデルは、ユーザーの対話にのみ焦点を当てています。デコードフェーズでは、さまざまな語彙の重要性を評価し、mlの予測を行うゲートメカニズムを導入します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: NIT COVID-19 at WNUT-2020 Task 2: Deep Learning Model RoBERTa for
  Identify Informative COVID-19 English Tweets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_12.html">
      <font color="black">NIT COVID-19 at WNUT-2020 Task 2: Deep Learning Model RoBERTa for
  Identify Informative COVID-19 English Tweets</font>
    </a>
  </h2>
  <font color="black">共有タスクWNUT2020 Task2の提案されたモデルによって達成されたパフォーマンスは、F1スコアメトリックで89.14％です。これらの有益なツイートは、回復、確認、疑わしい、および死亡のケースに関する情報と、ケースの場所または旅行履歴を提供します。 ..このペーパーは、WNUT-2020Task2で特定された有益なCOVID-19英語ツイートのためにNIT_COVID-19チームによって提出されたモデルを提示します。 
[要約]提案されたタスクは、英語のツイートが有益であるかどうかを自動的に識別する問題に対処します-</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: CalibreNet: Calibration Networks for Multilingual Sequence Labeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_13.html">
      <font color="black">CalibreNet: Calibration Networks for Multilingual Sequence Labeling</font>
    </a>
  </h2>
  <font color="black">2つのクロスリンガルベンチマークデータセットでの実験は、提案されたアプローチがゼロショットクロスリンガルNERおよびMRCタスクでSOTA結果を達成することを示しています。低リソース言語でのトレーニングデータの欠如は、固有表現抽出などのシーケンスラベリングタスクに大きな課題を提示します（NER）と機械読解（MRC）。1つの大きな障害は、予測された回答の境界のエラーです。 
[要約]問題は、予測された回答の境界のエラーです。mrmrmr。氏。氏。 。これらは、最初の回答を作成するための最初のステップです。最初のステップでは、既存のシーケンスラベリング方法をベースモデルとして採用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Audrey: A Personalized Open-Domain Conversational Bot -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_14.html">
      <font color="black">Audrey: A Personalized Open-Domain Conversational Bot</font>
    </a>
  </h2>
  <font color="black">オードリーは、感情検出や個人理解モジュールなどの社会的認識モデルから構築されており、ユーザーの興味や欲求をより深く理解します。自然言語理解の進歩により、最近のチャットボットは情報レベルでの対話に成功しています。会話インテリジェンス人は、情報、個人、および関係のレベルに従事する必要があります。 
[概要]ミシガン大学がオードリーをアレクサ賞のグランドチャレンジに提出3.顧客の個性と感情に導かれた興味に基づく会話を通じて顧客を引き付けることを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: The Impact of Text Presentation on Translator Performance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_15.html">
      <font color="black">The Impact of Text Presentation on Translator Performance</font>
    </a>
  </h2>
  <font color="black">私たちの調査結果は、CATツールの設計におけるベストプラクティスに直接的な影響を及ぼします。文ごとの表示により、セグメント化されていないテキストと比較して、より高速なテキストの再現と文内のエラーの識別が可能になり、ソースセンテンスとターゲットセンテンスは、並べて配置する場合に比べてテキストの複製を高速化します。広く使用されているコンピュータ支援翻訳（CAT）ツールは、ドキュメントをセンテンスなどのセグメントに分割し、スプレッドシートのように並べて配置します。見る。 
[要約]猫に感染した文の最初のテストは、セグメント化されていないテキストを提示すると最高の精度が得られることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: An Investigation of Potential Function Designs for Neural CRF -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_16.html">
      <font color="black">An Investigation of Potential Function Designs for Neural CRF</font>
    </a>
  </h2>
  <font color="black">ニューラルリニアチェーンCRFモデルは、シーケンスラベリングに最も広く使用されているアプローチの1つです。私たちの広範な実験は、2つの隣接するラベルと2つの隣接する単語のベクトル表現に基づく分解された四線形ポテンシャル関数が一貫して最高のパフォーマンスを達成することを示しています。この論文では、放出関数と遷移関数を統合するだけでなく、文脈上の単語の表現を入力として明示的に受け取る、ニューラルCRFモデルの一連のますます表現力のある潜在的な関数を調査します。 
[要約]ニューラルcrfモデルの表現力が増す一連の潜在的な関数。これらには放出関数と遷移関数が含まれますが、隣接する単語の表現も入力として使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Meemi: A Simple Method for Post-processing and Integrating Cross-lingual
  Word Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_17.html">
      <font color="black">Meemi: A Simple Method for Post-processing and Integrating Cross-lingual
  Word Embeddings</font>
    </a>
  </h2>
  <font color="black">単語の埋め込みは、自然言語処理の実践者のツールセットの標準リソースになっています。私たちのアプローチは、単一言語空間の統合と単一言語空間自体の品質の両方を改善することを示しています。この追加の変換は非直交、それはまた、単一言語空間の構造に影響を与えます。 
[ABSTRACT]クロスリンガル埋め込みは、2つ以上の言語からの単語埋め込みが統合される多言語スペースを定義します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-16">
        <br><font color="black">2019-10-16</font>
      </time>
    </span>
</section>
<!-- paper0: Labeling of Multilingual Breast MRI Reports -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_18.html">
      <font color="black">Labeling of Multilingual Breast MRI Reports</font>
    </a>
  </h2>
  <font color="black">私たちの提案する方法は、臨床現場で直面する実際的な課題を克服し、従来のアプローチと比較して、医療レポートからラベルを抽出する際のパフォーマンスが向上することを示しています。医療レポートは、臨床試験を通じて患者の状態を記録するための不可欠な媒体です。貴重な情報が含まれています。これを抽出して、臨床ツールの開発に必要な大きなラベル付きデータセットを生成できます。 
[概要]データセットには、大きなラベル付きフォーマットを作成するために抽出できる貴重な情報が含まれています。データセットは、臨床ツールの開発に必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: DocBank: A Benchmark Dataset for Document Layout Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_19.html">
      <font color="black">DocBank: A Benchmark Dataset for Document Layout Analysis</font>
    </a>
  </h2>
  <font color="black">実験結果は、DocBankでトレーニングされたモデルがさまざまなドキュメントのレイアウト情報を正確に認識することを示しています。DocBankを使用すると、さまざまなモダリティのモデルを公平に比較でき、マルチモーダルアプローチがさらに調査され、ドキュメントレイアウト分析のパフォーマンスが向上します。 DocBankデータセットは、\ url {https://github.com/doc-analysis/DocBank}で公開されています。 
[要約]視覚的情報と文学的情報の両方を含むデータセットの分析はまだ不十分です。さらに、レポートは、弱い監督によるシンプルで効果的な方法に依存しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br><font color="black">2020-06-01</font>
      </time>
    </span>
</section>
<!-- paper0: Brain2Word: Decoding Brain Activity for Language Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_20.html">
      <font color="black">Brain2Word: Decoding Brain Activity for Language Generation</font>
    </a>
  </h2>
  <font color="black">これはより現実的な設定であると主張し、見えない被験者からのfMRIデータをデコードできるモデルを提示します。この作業では、fMRIスキャンを直接分類し、固定語彙内の対応する単語にマッピングすることを提案します。既存の作業では、これまでに見られなかった被験者からのスキャンを評価します。 
[概要]科学者は、fmriスキャンをデコードして、被験者が読んでいる単語の埋め込みに変換できると述べています。ただし、正確な刺激を回復する能力が制限されています。モデルは5を達成します。22％トップ-1以上のセットアップ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Assessment of text coherence based on the cohesion estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_21.html">
      <font color="black">Assessment of text coherence based on the cohesion estimation</font>
    </a>
  </h2>
  <font color="black">さらに、異なる言語に適用できるため、この方法の有効性を英語、中国語、アラビア語のテキストのセットで調べます。この論文では、凝集推定に基づくグラフベースのコヒーレンス推定方法を提案します。 ..私たちの方法は、グラフベースのアプローチを使用して、ユーザーに評価プロセスの理解を提供します。 
[概要]私たちの方法は、グラフベースのアプローチを使用して、ユーザーに英語の評価プロセスの理解を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Recurrent Deep Stacking Networks for Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_22.html">
      <font color="black">Recurrent Deep Stacking Networks for Speech Recognition</font>
    </a>
  </h2>
  <font color="black">これら2つのモデルの主なアイデアは、音素レベルの情報を音響モデルに追加し、音響モデルを音響モデルと音素レベルのNグラムモデルの組み合わせに変換することです。実験により、RDSNとBPsnが大幅に改善できることが示されました。従来のDNNを超えるパフォーマンス。このペーパーでは、ロバストな自動音声認識（ASR）タスクにリカレントディープスタッキングネットワーク（RDSN）を適用する作業について説明しました。 
[概要]新しい調査によると、rdsnとbpsnはパフォーマンスを大幅に向上させることができます。新しい調査では、rdsn、バイパススタッキングネットワーク（bpsn）のより効率的な代替案が示唆されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2016-12-14">
        <br><font color="black">2016-12-14</font>
      </time>
    </span>
</section>
<!-- paper0: Incorporating Language Level Information into Acoustic Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_23.html">
      <font color="black">Incorporating Language Level Information into Acoustic Models</font>
    </a>
  </h2>
  <font color="black">2種類のコンテキスト情報、コンテキストを処理する2つの方法、言語レベルの情報を組み込む2つの方法など、RDLNの複数のバリエーションが検討されました。RDLNは、自動音声認識（ASR）システム全体を微調整するための可能な方法を提供しました。この論文は、言語レベルの情報を音響モデルに組み込むことができる、新しいディープリカレントニューラルネットワークのクラスを提案しました。 
[概要]これらのネットワークはリカレントディープランゲージネットワーク（rdlns）と呼ばれます。複数のネットワークがコンテキストとして考慮されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2016-12-14">
        <br><font color="black">2016-12-14</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient End-to-End Speech Recognition Using Performers in Conformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_24.html">
      <font color="black">Efficient End-to-End Speech Recognition Using Performers in Conformers</font>
    </a>
  </h2>
  <font color="black">ほとんどの以前の研究は、モデルサイズを縮小することによって効率を改善します。提案された注意ベースの効率的なエンドツーエンド音声認識モデルは、1000万のパラメータと線形計算の複雑さを備えたLibriSpeechコーパスで競争力のあるパフォーマンスをもたらします。提案されたモデルも以前よりも優れていますワードエラー率が比較的20％軽量なエンドツーエンドモデル。 
[概要]提案されたモデルは、以前の軽量モデルよりもパフォーマンスが高く、単語誤り率が比較的20％高くなっています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: On End-to-end Multi-channel Time Domain Speech Separation in Reverberant
  Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_25.html">
      <font color="black">On End-to-end Multi-channel Time Domain Speech Separation in Reverberant
  Environments</font>
    </a>
  </h2>
  <font color="black">提案されたシステムに前処理として残響除去を適用すると、クリーンで残響のあるデータでトレーニングされた音響モデルを使用して、WERをさらに29％削減できます。空間的特徴抽出に対する残響の影響を減らすために、残響除去の前処理方法が分離性能をさらに改善するために適用されます。wsj0-2mixデータセットの空間化バージョンは、提案されたシステムを評価するためにシミュレートされています。 
[概要] wsj0の空間化バージョン-2berationデータセットは、提案されたシステムを評価するためにシミュレートされました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Beneath the Tip of the Iceberg: Current Challenges and New Directions in
  Sentiment Analysis Research -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_26.html">
      <font color="black">Beneath the Tip of the Iceberg: Current Challenges and New Directions in
  Sentiment Analysis Research</font>
    </a>
  </h2>
  <font color="black">現在の関連性の原因となる重要な飛躍を分析します。さらに、多くの見落とされた未回答の質問をカバーするこのフィールドの可能なコースをグラフ化しようとします。特定のサブタスク（感情の極性分類など）とデータセットの飽和を考慮して、この分野が成熟に達したという根本的な認識があります。 
[ABSTRACT]センチメントは、マーケティング、リスク管理、極性、および政治に広く行き渡っています。マーケティングやリスク管理などのさまざまな分野で幅広い商用アプリケーションがあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: Rule-Based Approach for Party-Based SentimentAnalysis in Legal Opinion
  Texts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_27.html">
      <font color="black">Rule-Based Approach for Party-Based SentimentAnalysis in Legal Opinion
  Texts</font>
    </a>
  </h2>
  <font color="black">以前の訴訟に関連する意見や議論を詳しく説明する文書は、リーガルオピニオンテキストとして知られています。パーティーベースの感情分析は、リーガルテキストの各訴訟当事者に関する意見値を特定することにより、自動化システムで重要な役割を果たします。したがって、法的な意見のテキストから情報を抽出するプロセスを自動化する方法があれば、それらの個人に多くの利便性を提供します。 
[概要]弁護士や法務官は、必要な情報を入手するために時間を費やす必要があります。当事者ベースの感情分析は、システムで重要な役割を果たします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Multilingual Irony Detection with Dependency Syntax and Neural Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_28.html">
      <font color="black">Multilingual Irony Detection with Dependency Syntax and Neural Models</font>
    </a>
  </h2>
  <font color="black">3つの異なる実験設定が提供されます。最初に、古典的な機械学習分類子と組み合わせたさまざまな構文依存性ベースの機能を検討します。3番目の設定では、依存関係ベースの構文機能を多言語BERTアーキテクチャに組み合わせます。 
[概要]構文知識からの貢献に焦点を当て、ソーシャルサイトに注釈が付けられている言語リソースを活用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Diversity Aware Relevance Learning for Argument Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_29.html">
      <font color="black">Diversity Aware Relevance Learning for Argument Search</font>
    </a>
  </h2>
  <font color="black">私たちの経験的評価は、私たちのアプローチが、必要なデータが少なくても、引数検索タスクの大幅な改善につながることを示しています。それを超えて、重複を明示的に識別しようとするのではなく、クエリの多様な側面をカバーすることを目的としています。クラスタリングを介して重複を削除することに依存していますが、選択した施設がすべての側面をカバーしていることを直接保証するものではありません。 
[ABSTRACT]新しい作業により、引数検索の問題に対する新しいマルチステップアプローチが導入されました。これには、クレームと前提の間の明示的なマッピングに依存することが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-04">
        <br><font color="black">2020-11-04</font>
      </time>
    </span>
</section>
<!-- paper0: The Role of the Crowd in Countering Misinformation: A Case Study of the
  COVID-19 Infodemic -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/cs.CL/paper_30.html">
      <font color="black">The Role of the Crowd in Countering Misinformation: A Case Study of the
  COVID-19 Infodemic</font>
    </a>
  </h2>
  <font color="black">私たちの仕事は、一部のユーザーがソーシャルプラットフォームで誤った情報に有機的に対抗する方法と、専門的なファクトチェックを拡大する上でユーザーが果たす役割についての洞察を提供します。これらの洞察は、関係する市民が誤った情報と戦う力を与えることができるツールとメカニズムの開発につながる可能性があります。誤った情報が表示されるプラットフォームのユーザーである市民（つまり、群衆）は、ファクトチェック情報の普及と誤った情報の拡散に対抗する上で重要な役割を果たすことができます。さらに重要なことに、群衆の方法に対照的な違いがあります。ツイートに反論し、意見のように見えるツイートもあれば、評判の高い情報源へのリンクなどの具体的な証拠が含まれているツイートもあります。 
[要約]関係する市民の群衆は、事実を広める上で重要な役割を果たすことができます-情報をチェックし、誤った情報の拡散に対抗します。私たちは分類器を訓練して、主張と33、413の反論の議論のデータセットを作成します。群衆がツイートに反論する方法、一部のツイートは意見のように見える一方で、他のツイートには評判の高い情報源へのリンクなどの具体的な証拠が含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: End-to-End Bengali Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.AS/paper_0.html">
      <font color="black">End-to-End Bengali Speech Recognition</font>
    </a>
  </h2>
  <font color="black">2つのCNNブロック、2層ブロックAと4層ブロックBを提案します。最初の層は、7x3カーネルで構成され、後続の層は3x3カーネルのみで構成されます。この作業では、CTCベースのCNN-RNNネットワークを適用します。ベンガルASRタスクに対する卓越したディープラーニングベースのエンドツーエンド自動音声認識技術。公開されているラージベンガルASRトレーニングデータセットを使用して、さまざまな複雑さと深さの7つのディープニューラルネットワーク構成のパフォーマンスをベンチマークおよび評価します。ベンガル語のASRタスクについて。 
[概要]ベンガル語の研究とリソースはほとんどなく、その間にあります。これらには、音声ベースの音声ベースのオサマビンの広範な使用が含まれます。ただし、研究は成功していません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-21">
        <br><font color="black">2020-09-21</font>
      </time>
    </span>
</section>
<!-- paper0: Low-resource expressive text-to-speech using data augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.AS/paper_1.html">
      <font color="black">Low-resource expressive text-to-speech using data augmentation</font>
    </a>
  </h2>
  <font color="black">提案されたアプローチを2つのスタイル（ニュースキャスターと会話型）、さまざまなスピーカー、およびシングルスピーカーモデルとマルチスピーカーモデルの両方で示し、アプローチの堅牢性を示します。最後に、そのモデルを微調整して品質をさらに向上させます。最近のニューラルテキスト読み上げ（TTS）システムは非常に優れたパフォーマンスを発揮しますが、通常、目的の話し方の読み方からかなりの量の録音を必要とします。 
[要約]提案された変更は、拡張されていないモデルに比べて大幅な改善をもたらすと専門家は言います。彼らは、改善は合成音声の知覚された側面をはるかに超えて話者に改善をもたらすと言います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Surrogate Source Model Learning for Determined Source Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.AS/paper_2.html">
      <font color="black">Surrogate Source Model Learning for Determined Source Separation</font>
    </a>
  </h2>
  <font color="black">ISSは、複雑さが低く、行列の反転がないため、このタスクに適しています。SDRの損失は反復の収束を最速にし、コヒーレンスは単語誤り率（WER）を最低にします。の代理関数を学習することを提案します。決定されたブラインド音声分離のためのユニバーサル音声優先順位。 
[要約]深い音声の事前分布は、メジャー化-最小化（auxiva）に基づく分析と互換性がありませんが、必要な代理関数を導出することは容易ではなく、常に可能ではありません。代わりに、issの複数の反復を通じて正確な分離損失を逆伝播します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: FastSVC: Fast Cross-Domain Singing Voice Conversion with Feature-wise
  Linear Modulation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.AS/paper_3.html">
      <font color="black">FastSVC: Fast Cross-Domain Singing Voice Conversion with Feature-wise
  Linear Modulation</font>
    </a>
  </h2>
  <font color="black">FastSVCシステムの推論速度は、GPUおよびCPUのベースラインシステムよりもそれぞれ3倍および70倍高速です。さらに、提案されたFastSVCシステムは、望ましいクロスリンガル歌唱変換パフォーマンスを実現します。波形ジェネレーターは、多重解像度を使用して便利にトレーニングできます。解像度のスペクトル損失と敵対的な損失。 
[概要] fastsvcはコンフォーマーベースの音素認識機能を使用してシステムを抽出します。fastsvcはコンフォーマーベースの音素認識機能を使用します。fastsvcは提案された言語システムです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Neural Architecture Search for End-to-end Speech Recognition
  via Straight-Through Gradients -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.AS/paper_4.html">
      <font color="black">Efficient Neural Architecture Search for End-to-end Speech Recognition
  via Straight-Through Gradients</font>
    </a>
  </h2>
  <font color="black">次に、ST-NASをエンドツーエンドのASRに正常に適用します。ST勾配を使用してサブグラフのサンプリングをサポートすることは、DARTSおよびSNASを超えた効率的なNASを実現するためのコア要素です。基本的に、ST-NASはSNASからの損失を使用します。ただし、STを使用して離散変数を介して勾配を逆伝播し、損失を最適化します。これはProxylessNASでは明らかにされていません。 
[ABSTRACT] st --nasは、shy --through（st）gradientを使用する効率的なnasメソッドです。stベースのメソッドは、サブグラフのサンプリングをサポートするためにstベースのメソッドを使用します。stベースのstメソッドは、nas効率の重要なコンポーネントです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Time Delay Neural Network for Speech Enhancement with Full Data
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.AS/paper_5.html">
      <font color="black">Deep Time Delay Neural Network for Speech Enhancement with Full Data
  Learning</font>
    </a>
  </h2>
  <font color="black">TDNNは、モジュール式のインクリメンタル設計を利用して、長距離の時間的コンテキストをキャプチャする優れた可能性を秘めています。トレーニングデータを最大限に活用するために、音声強調のための完全なデータ学習方法を提案します。さらに、TDNNはフィードを保持します-その推論コストが標準のDNNに匹敵するように前方構造。 
[概要]この論文では、完全なデータ学習による音声強調のための深層時間遅延ニューラルネットワーク（tdnn）を提案します。tdnnはフィードフォワード構造を保持するため、グッドウィンコストは標準のdnnに匹敵しますが、モデルの複雑さを使用して強化されたモデルをトレーニングするだけでなく、データを無音にするためにクリーン-から-クリーンとノイズ-もトレーニングします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Recognizing More Emotions with Less Data Using Self-supervised Transfer
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.AS/paper_6.html">
      <font color="black">Recognizing More Emotions with Less Data Using Self-supervised Transfer
  Learning</font>
    </a>
  </h2>
  <font color="black">完全なIEMOCAPデータセットでトレーニングすると、73.9％の重み付けされていない精度（UA）の新しい最先端技術に到達します。注意ベースのリカレントニューラルを介して、事前にトレーニングされた音響表現をBERTモデルのセマンティック表現に合わせます。ネットワーク..パフォーマンスを、音声感情認識（SER）研究コミュニティの間で十分にベンチマークされたデータセットであるIEMOCAPデータセットの他の一般的な方法と比較します。 
[概要]トレーニングデータのサイズを変更することで、アプローチの利点に関する詳細な洞察を提供しました。音響と言語マークの知識を組み合わせることで、結果を大幅に改善できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Quasi-Periodic WaveNet: An Autoregressive Raw Waveform Generative Model
  with Pitch-dependent Dilated Convolution Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.AS/paper_7.html">
      <font color="black">Quasi-Periodic WaveNet: An Autoregressive Raw Waveform Generative Model
  with Pitch-dependent Dilated Convolution Neural Network</font>
    </a>
  </h2>
  <font color="black">次に、カスケードネットワーク構造を利用して、音声などの準周期信号の長期依存性と短期依存性を同時にモデル化します。ただし、純粋なデータ駆動型の性質とオーディオ信号に関する事前知識の欠如により、ピッチが低下します。 WNの可制御性..この問題に対処するために、2つの新しい設計のQPNetが提案されています。 
[ABSTRACT]ピッチベースのモデルwnは、忠実度の高いオーディオ波形生成を実現します。f0機能が周期的である場合、オーディオ信号の周期的成分を生成することは困難です。シングルトーン正弦波および音声生成のパフォーマンスが評価されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-11">
        <br><font color="black">2020-07-11</font>
      </time>
    </span>
</section>
<!-- paper0: On End-to-end Multi-channel Time Domain Speech Separation in Reverberant
  Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-12/eess.AS/paper_8.html">
      <font color="black">On End-to-end Multi-channel Time Domain Speech Separation in Reverberant
  Environments</font>
    </a>
  </h2>
  <font color="black">この論文では、残響環境におけるマルチチャネル時間領域音声分離の新しい方法を紹介します。提案されたシステムに前処理として残響除去を適用すると、クリーンで残響のあるデータでトレーニングされた音響モデルを使用して、WERをさらに29％削減できます。空間的特徴抽出に対する残響の影響を低減するために、残響除去前処理法を適用して、分離性能をさらに改善しました。 
[概要] wsj0の空間化バージョン-2berationデータセットは、提案されたシステムを評価するためにシミュレートされました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
