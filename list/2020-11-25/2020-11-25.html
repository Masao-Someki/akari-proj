<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-11-25の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: A Novel Multimodal Music Genre Classifier using Hierarchical Attention
  and Convolutional Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.SD/paper_0.html">
      <font color="black">A Novel Multimodal Music Genre Classifier using Hierarchical Attention
  and Convolutional Neural Network</font>
    </a>
  </h2>
  <font color="black">音楽ジャンルの分類は、現在の音楽情報検索（MIR）研究に関するトレンドトピックの1つです。次に、結果の融合特徴ベクトルに基づいて音楽トラックを分類します。スペクトログラム用にCNNベースの特徴抽出機能を実装しました。音響機能と、歌詞用のHierarchical AttentionNetworkベースの機能抽出機能を組み込むため。 
[概要]以来、ジャンルの依存関係はオーディオプロファイルに限定されています。対応する曲の歌詞として提供されている文学コンテンツも利用しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Whole-Word Segmental Speech Recognition with Acoustic Word Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.SD/paper_1.html">
      <font color="black">Whole-Word Segmental Speech Recognition with Acoustic Word Embeddings</font>
    </a>
  </h2>
  <font color="black">最終モデルは、以前のA2Wモデルよりも改善されています。さらに、書かれた単語ラベルの共同トレーニングされた音響単語埋め込み（AWE）および音響的に接地された単語埋め込み（AGWE）による事前トレーニングの使用を調査します。単語エラー率がわかります。 AWEを使用して音響セグメント表現を事前トレーニングすることにより、大幅に削減できます。また、AGWEを使用して単語予測層を事前トレーニングすることにより、追加の（より小さな）ゲインを取得できます。 
[概要]特徴サイズのモデルは、セグメントの埋め込みを使用してマッピングされます。これらのモデルは、セグメントモデルの埋め込みに基づいています。さらに、音響セグメント表現を畏敬の念を持って事前トレーニングします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-01">
        <br><font color="black">2020-07-01</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Decoder DPRNN: High Accuracy Source Counting and Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.SD/paper_2.html">
      <font color="black">Multi-Decoder DPRNN: High Accuracy Source Counting and Separation</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、スピーカーの数を数える点で最先端を上回り、再構成された信号の品質で競争力を維持していることを示します。モデルを超えて、スピーカーの数を変えて音源分離を評価する方法に関する測定基準も提案します。最大5人の話者が混在するWSJ0-mixデータセットでアプローチを評価します。 
[概要]スピーカーの数を変えて音源分離を評価する方法に関する測定基準も提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Imperio: Robust Over-the-Air Adversarial Examples for Automatic Speech
  Recognition Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.SD/paper_3.html">
      <font color="black">Imperio: Robust Over-the-Air Adversarial Examples for Automatic Speech
  Recognition Systems</font>
    </a>
  </h2>
  <font color="black">公開されているいくつかの無線の敵対的な例は、3つのカテゴリのいずれかに分類されます。これらは、手作りの例であるか、目立つため、コンテンツに注意を向けると、人間のリスナーがターゲットの文字起こしを簡単に認識できるか、攻撃が行われる部屋であるため、他の部屋に転送することはできません。したがって、部屋の特性に関する事前の知識は必要ありません。このホワイトペーパーでは、一般的な敵対的な例を生成する最初のアルゴリズムを示します。特定の環境に適合していない空中攻撃。 
[概要]これらの例は、部屋でプレイすると成功しません。部屋ベースの敵対的攻撃をより成功させるために使用できます。代わりに、部屋のインパルス応答（rirs）を使用して任意の部屋の特性を説明します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-05">
        <br><font color="black">2019-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Count Words in Fluent Speech enables Online Speech
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.SD/paper_4.html">
      <font color="black">Learning to Count Words in Fluent Speech enables Online Speech
  Recognition</font>
    </a>
  </h2>
  <font color="black">英語と北京語の音声のLRS2、LibriSpeech、およびAishell-1データセットで実行された実験は、5セグメントの動的アルゴリズム遅延がある場合、オンラインシステムがオフラインシステムと同等のパフォーマンスを発揮することを示しています。さらに、推定セグメント長分布を示します。私たちのシステムは正確なセグメント間の同等性を必要としませんが、強制整列で得られた単語の長さの分布に似ています。累積単語合計を使用して音声を動的にセグメント化し、単語への熱心なデコードを可能にします。 
[概要]これらのモデルが音声を制御できるようにする必要があるのはこれが初めてです。システムは2つの間の正確さを必要としないと彼らは言います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-08">
        <br><font color="black">2020-06-08</font>
      </time>
    </span>
</section>
<!-- paper0: DiffWave: A Versatile Diffusion Model for Audio Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.SD/paper_5.html">
      <font color="black">DiffWave: A Versatile Diffusion Model for Audio Synthesis</font>
    </a>
  </h2>
  <font color="black">データ尤度の変分限界のバリアントを最適化することにより、効率的にトレーニングされます。DiffWaveは、音声品質（MOS：4.44対4.43）の点で、強力なWaveNetボコーダーと一致し、桁違いに高速に合成されることを示します。さまざまな自動評価および人間による評価からのオーディオ品質とサンプルの多様性の点で、困難な無条件生成タスクにおいて、自動回帰およびGANベースの波形モデルを大幅に上回っています。 
[概要]モデルは非自己回帰であり、合成時に一定のステップ数でマルコフ連鎖を介してホワイトノイズ信号を構造化された波形に変換します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-21">
        <br><font color="black">2020-09-21</font>
      </time>
    </span>
</section>
<!-- paper0: Synth2Aug: Cross-domain speaker recognition with TTS synthesized speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.SD/paper_6.html">
      <font color="black">Synth2Aug: Cross-domain speaker recognition with TTS synthesized speech</font>
    </a>
  </h2>
  <font color="black">さらに、TTS合成に使用されるさまざまなタイプのテキストトランスクリプトの有効性を調査します。近年、音声認識のデータ拡張手法としてText-To-Speech（TTS）が使用され、トレーニングデータの不十分さを補っています。 。結果は、ターゲットドメインのテキストコンテンツを一致させることが良い習慣であることを示唆しており、それが不可能な場合は、十分に大きな語彙を持つトランスクリプトが推奨されます。 
[概要]話者認識をサポートする音声合成のためのマルチスピーカーttsシステムの使用を検討します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: How Far Are We from Robust Voice Conversion: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.SD/paper_7.html">
      <font color="black">How Far Are We from Robust Voice Conversion: A Survey</font>
    </a>
  </h2>
  <font color="black">すべてのVCモデルは目に見えないデータに悩まされていますが、AdaIN-VCは比較的堅牢です。また、共同でトレーニングされたスピーカー埋め込みは、スピーカー識別でトレーニングされたモデルよりも音声変換に適しています。また、交換など、これらのモデルを変更しました。スピーカーの埋め込みのパフォーマンスをさらに向上させるために。 
[概要]論文では、既知のvcモデルの堅牢性について詳細に研究しました。共同でトレーニングされた埋め込みは、話者識別でトレーニングされたモデルよりも音声変換に適しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: SimTreeLS: Simulating aerial and terrestrial laser scans of trees -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.IV/paper_0.html">
      <font color="black">SimTreeLS: Simulating aerial and terrestrial laser scans of trees</font>
    </a>
  </h2>
  <font color="black">シミュレーションでは、材料の分類がポイントごとに保持されるため、葉と木質が完全に認識され、シミュレーション後のラベル付けに先立って、一意の識別子によって個々のツリーが分離されます。SimTreeLSは、公開されているライブラリに基づいて構築されたオープンソースリソースとして利用できます。特に農林業の分野で、地上および空中レーザースキャンを使用して樹木をデジタル化するための多数の新しいアプリケーションがあります。 
[ABSTRACT] LIDARポイントクラウドの解釈は、ますます手作業でラベル付けされたデータに依存しています。これにより、手続き型で生成されたデータを無限に提供できます。これらは、データ処理技術の開発や機械学習アルゴリズムのトレーニングに使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Single-frame far-field diffractive imaging with randomized illumination -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.IV/paper_1.html">
      <font color="black">Single-frame far-field diffractive imaging with randomized illumination</font>
    </a>
  </h2>
  <font color="black">したがって、RPIは、時間分解能と信頼性が重要であるが、数十ナノメートルの空間分解能で十分な場合に、定量的X線位相イメージングに魅力的なモダリティを提供します。これらの利点を実現するには、プローブ形成の開口数に関連する分解能の限界光学系が課せられます。次に、定量的な振幅および位相画像が、結果として得られる遠視野回折パターンから再構築されます。 
[概要] rpiでは、サンプルは構造化されたプローブフィールドによって照らされます。サンプルの一般的なフィーチャサイズよりも小さいスペックルが含まれます。結果として得られる方法では、近接フィールド光学系は必要ありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Alleviating Class-wise Gradient Imbalance for Pulmonary Airway
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.IV/paper_2.html">
      <font color="black">Alleviating Class-wise Gradient Imbalance for Pulmonary Airway
  Segmentation</font>
    </a>
  </h2>
  <font color="black">バックプロパゲーション中に、クラスの不均衡が局所的であるときに前景勾配と背景勾配の比率が小さい場合、前景勾配はそれらの近傍によって侵食される可能性があります。この問題を軽減するために、グループ監視と対応するWingsNetを使用して提供します。浅い層のトレーニングを強化するための補完的な勾配フロー。このプロセスは、最上層から最下層への勾配フローに含まれるノイズ情報を累積的に増加させ、CNNの小さな構造の学習を制限します。 
[概要]これは、末梢気管支のサイズが小さく、空間分布が分散しているためです。これは、前景領域と背景領域の間の深刻なクラスの不均衡によって妨げられます。cnnの拡張法は、気道構造をより正確に予測できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Weakly- and Semi-Supervised Probabilistic Segmentation and
  Quantification of Ultrasound Needle-Reverberation Artifacts to Allow Better
  AI Understanding of Tissue Beneath Needles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.IV/paper_3.html">
      <font color="black">Weakly- and Semi-Supervised Probabilistic Segmentation and
  Quantification of Ultrasound Needle-Reverberation Artifacts to Allow Better
  AI Understanding of Tissue Beneath Needles</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、アーチファクト強度の強度減衰をモデル化し、人間のラベリングエラーを最小限に抑えるように設計されています。他のセグメンテーションアルゴリズムと比較して、アプローチの適用可能性を示します。針の残響アーチファクトは、特定が難しく、さまざまなピクセルに影響を与える可能性があります。さまざまな程度の値。 
[概要]結果として生じる残響アーティファクトは、識別が難しい場合があります。これは、さまざまなピクセル値にさまざまな程度で影響を与える可能性があります。私たちの方法は、最先端のアーティファクトと一致します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Multiscale Sparsifying Transform Learning for Image Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.IV/paper_4.html">
      <font color="black">Multiscale Sparsifying Transform Learning for Image Denoising</font>
    </a>
  </h2>
  <font color="black">最後に、詳細サブバンドのノイズ除去の必要性を排除します。次に、安価な融合手法であるウェーブレットサブバンドミキシングを使用してこの方法を大幅に強化し、シングルスケール法とマルチスケール法の結果を組み合わせることができることを示します。提案されたマルチスケール手法は、ノイズが比較的弱い場合でも、ベースラインに対する優位性を維持します。 
[概要]提案されたマルチスケール手法は驚くほどシングルスケールであり、画像のマルチスケールの性質を無視します。この単純化により、ベースラインに対して競争力のあるパフォーマンスを備えた効率的なマルチスケールノイズ除去手法が実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-25">
        <br><font color="black">2020-03-25</font>
      </time>
    </span>
</section>
<!-- paper0: Segmentation of the cortical plate in fetal brain MRI with a topological
  loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.IV/paper_5.html">
      <font color="black">Segmentation of the cortical plate in fetal brain MRI with a topological
  loss</font>
    </a>
  </h2>
  <font color="black">妊娠21週から38週までの18の胎児脳地図でこの方法を定量的に評価し、ベースライン法と比較して、すべての在胎週数でこの方法の重要な利点を示しています。さらに、ランダムに選択された130人の3人の異なる専門家による定性的評価26の臨床MRIからのスライスは、MR再構成の品質とは無関係に私たちの方法のアウトパフォーマンスを証明します。この論文では、追加の損失関数として、の形態的一貫性を強化するためのトポロジー制約の統合を初めて提案します。胎児の皮質板の深い学習ベースのセグメンテーション。 
[概要] 18の胎児脳地図で私たちの方法を定量的に評価します。ベースラインの方法と比較して、すべての在胎週数を通して私たちの方法の重要な利点を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-23">
        <br><font color="black">2020-10-23</font>
      </time>
    </span>
</section>
<!-- paper0: Mini-DDSM: Mammography-based Automatic Age Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.IV/paper_6.html">
      <font color="black">Mini-DDSM: Mammography-based Automatic Age Estimation</font>
    </a>
  </h2>
  <font color="black">年齢属性を持つ公開マンモグラフィデータセットがないため、Webクローラーを使用して、公開データセットからサムネイルマンモグラフィ画像とその年齢フィールドをダウンロードします。マンモグラフィ検診用デジタルデータベース..残念ながら、このデータセットの元の画像は、壊れたソフトウェアでしか取得できません。しかし、私たちの知る限り、年齢推定のためのマンモグラムに関する研究は行われていません。 
[概要]この研究の目的は、マンモグラム画像から年齢を再分類するためのaiベースのモデルを考案することです。マンモグラム画像は、壊れたソフトウェアによってのみ取得できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-01">
        <br><font color="black">2020-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Many-to-Many Image-to-Image Translation Across Multiple
  Domains -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.IV/paper_7.html">
      <font color="black">Unsupervised Many-to-Many Image-to-Image Translation Across Multiple
  Domains</font>
    </a>
  </h2>
  <font color="black">1つ目は、複数のドメイン間で画像を効果的かつ同時に変換するために、1つのドメイン共有エンコーダーと複数のドメイン専用デコーダーを備えた多対多アーキテクチャの提案です。画質を向上させるために、効果的な多対多を提案します。監視されていないマルチドメイン画像から画像への変換のためのマッピングフレームワーク。2つ目は、生成をさらに改善するために1対1のマッピングから拡張された2つの提案された制約です。 
[概要] 2種類の教師なしマルチドメイン画像から画像への変換が提案されています。これらは、画像を効果的かつ同時に変換するための、1つのドメインのみを備えた多対多アーキテクチャの共有エンコーダです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-28">
        <br><font color="black">2019-11-28</font>
      </time>
    </span>
</section>
<!-- paper0: Infrared small target detection based on isotropic constraint under
  complex background -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.IV/paper_8.html">
      <font color="black">Infrared small target detection based on isotropic constraint under
  complex background</font>
    </a>
  </h2>
  <font color="black">まず、MGDを介して疑わしい領域を取得し、次に元の画像のヘッセ行列の固有値を計算して、各領域の等方性パラメータを取得します。最後に、これらの領域が等方性制約条件を満たさない場合は抑制されます。提案された方法は、信号対クラッタ比ゲイン（SCRG）および受信機動作特性（ROC）曲線の点で、いくつかの一般的な方法よりも効果的で優れています。 
[ABSTRACT]小さなターゲットは、高コントラストと等方性の2つの特性を持つと見なされます。これらの領域の領域は等方性制約条件を満たしていません。これらの領域は同じ条件を満たしていないため抑制されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Blind deblurring for microscopic pathology images using deep learning
  networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.IV/paper_9.html">
      <font color="black">Blind deblurring for microscopic pathology images using deep learning
  networks</font>
    </a>
  </h2>
  <font color="black">次に、2つのエンコーダ-デコーダネットワークをトレーニングし、単独で、または組み合わせて使用して、入力画像のぼけを除去します。さまざまなタイプの病理標本でアプローチをテストし、画像のぼけ補正とそれに続くAIの診断結果の改善で優れたパフォーマンスを発揮します。アルゴリズム..これはエンドツーエンドのアプローチであり、従来のブラインドデコンボリューション方法のように波形のアーティファクトを導入しません。 
[概要]このアプローチでは、最初にディープブラー分類器をトレーニングして画像のブラータイプを識別します。これはエンドツーエンドのアプローチであり、従来のブラインドデコンボリューション法のように波形のアーティファクトを導入しません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: PRNU Estimation from Encoded Videos Using Block-Based Weighting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.IV/paper_10.html">
      <font color="black">PRNU Estimation from Encoded Videos Using Block-Based Weighting</font>
    </a>
  </h2>
  <font color="black">この目的のために、エンコーディングブロックタイプ、量子化強度、レート歪み値などのブロックレベルのパラメータを利用するいくつかのPRNU重み付けスキームが提案され、比較されます。ビデオは常に圧縮形式で保存されるため、対処する能力エンコーディングの破壊的な影響は、信頼できる帰属の中心です。ビデオからイメージングセンサーの光応答不均一性（PRNU）を推定することは、カメライメージングパイプラインのいくつかの処理ステップによって作成される複雑さのために困難な作業です。 
[要約]ビデオコーディングは、その不可逆性のため、prnu推定を最も混乱させるものの1つです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-18">
        <br><font color="black">2020-08-18</font>
      </time>
    </span>
</section>
<!-- paper0: Good and Bad Boundaries in Ultrasound Compounding: Preserving Anatomic
  Boundaries While Suppressing Artifacts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.IV/paper_11.html">
      <font color="black">Good and Bad Boundaries in Ultrasound Compounding: Preserving Anatomic
  Boundaries While Suppressing Artifacts</font>
    </a>
  </h2>
  <font color="black">この作業では、超音波のさまざまな視点から重複するピクセルを合成する新しいアルゴリズムを確立します。重複するピクセル値を組み合わせます。現在の一般的な方法では、有用な明るい領域または暗い領域を必然的に抑制または完全に除外し、潜在的に導入します。新しいアーティファクト。 
[ABSTRACT]超音波画像はプローブの方向と音波が通過する経路に依存するため、複合化のための単一の理想的な表現はありません。現在の一般的な方法は、必然的に有用な領域を抑制または完全に除外し、新しいアーティファクトを導入する可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Ultrasound Confidence Maps of Intensity and Structure Based on Directed
  Acyclic Graphs and Artifact Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.IV/paper_12.html">
      <font color="black">Ultrasound Confidence Maps of Intensity and Structure Based on Directed
  Acyclic Graphs and Artifact Models</font>
    </a>
  </h2>
  <font color="black">私たちの新しい信頼性アルゴリズムは、超音波イメージングの音響物理的特性に基づく有向非巡回グラフを使用してピクセル値を分析します。私たちのアプローチの独自の機能を示し、影検出および画像合成タスクの以前の信頼性測定アルゴリズムと比較します。個々のピクセル値の確実性を評価しようとしない限り、アーティファクトは画像分析アルゴリズムを混乱させる可能性があります。 
[概要]これらのアーティファクトは、画像分析手法を混乱させる可能性があります。これらは、影-検出および画像-複合タスクの測定アルゴリズムにおける以前の信頼度と比較されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Provably robust blind source separation of linear-quadratic
  near-separable mixtures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.IV/paper_13.html">
      <font color="black">Provably robust blind source separation of linear-quadratic
  near-separable mixtures</font>
    </a>
  </h2>
  <font color="black">BF後処理がある場合とない場合のSNPALQが現実的な数値実験に関連することを示します。SNPAスキームの反復に沿ってLQモデルに固有の積項を明示的にモデル化することにより、混合の非線形寄与が軽減され、分離が改善されます。品質..SNPALQによって抽出されたスプリアス（混合）サンプルを破棄できるため、その適用範囲が広がります。 
[概要]データセット内のサンプルとしてソースを表示する必要がある分離可能性の仮定の下でこの問題に取り組むために、2つの証明可能な堅牢で分析的に扱いやすいアルゴリズムを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Discovering Hidden Physics Behind Transport Dynamics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.IV/paper_14.html">
      <font color="black">Discovering Hidden Physics Behind Transport Dynamics</font>
    </a>
  </h2>
  <font color="black">移流拡散モデルを組み込んだ2Dと3Dの画像時系列間のオートエンコーダ構造に基づく学習フレームワーク（YETI）を提案します。識別可能性を支援するために、事前トレーニングを可能にする移流拡散シミュレータを開発します。速度および拡散テンソル場を使用した監視学習によるモデルの分析..これらの速度および拡散テンソル場を直接学習する代わりに、非圧縮性の流れと対称的な正の半確定拡散場を保証する表現を導入し、これらの表現の追加の利点を推定精度の向上。 
[概要]私たちの目標は、移流の基礎となる物理学を推定することです-ジェラード方程式。移流-ジェラード方程式、「速度と耐性」フィールドとして表されます。これには、脳卒中患者を特定する方法の学習が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Cream of the Crop: Distilling Prioritized Paths For One-Shot Neural
  Architecture Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_0.html">
      <font color="black">Cream of the Crop: Distilling Prioritized Paths For One-Shot Neural
  Architecture Search</font>
    </a>
  </h2>
  <font color="black">トレーニング中に優れたパフォーマンスを発揮するアーキテクチャ候補を指す優先パスの概念を紹介します。ImageNetでの実験により、このようなパス蒸留方法がハイパーネットワークの収束率とパフォーマンスを向上させ、サブネットワークのトレーニングを強化できることが確認されました。中心的な考え方は、サブネットワークがトレーニングプロセス全体を通じて共同で学習し、互いに教え合うことができ、個々のモデルの収束を促進することを目的としています。 
[概要]ハイパーネットワークは、トレーニングプロセス全体を通じて共同で学習し、互いに教えることができます。優先パスから知識を抽出することで、サブネットワークのトレーニングを促進できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-29">
        <br><font color="black">2020-10-29</font>
      </time>
    </span>
</section>
<!-- paper0: On the Texture Bias for Few-Shot CNN Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_1.html">
      <font color="black">On the Texture Bias for Few-Shot CNN Segmentation</font>
    </a>
  </h2>
  <font color="black">これにより、変更された特徴マップのセットが生成されます。その高周波成分は、空間領域のガウス分布のさまざまな標準偏差値で減少します。コードは、https：//github.com/rezazad68/fewshot-segmentationで入手できます。 。これは、形状コンポーネントに対してより強い優先度を持つ人間の視覚野の知覚バイアスとは対照的です。 
[概要]コードは、視覚認識におけるテクスチャの偏りを排除するように設計されています。たとえば、概念を作成するように設計されています。コードは、コードのコードコードで利用可能です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br><font color="black">2020-03-09</font>
      </time>
    </span>
</section>
<!-- paper0: Spatiotemporal Imaging with Diffeomorphic Optimal Transportation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_2.html">
      <font color="black">Spatiotemporal Imaging with Diffeomorphic Optimal Transportation</font>
    </a>
  </h2>
  <font color="black">最終的に、前の作業で提示したフレームワークに従って、ODE制約を使用して提案されたモデルを取得します。具体的には、最初にBenamou--Brenier式を使用して、質量保存画像のフロー間の最適な輸送コストを特徴付け、速度を制限します。生成された変形流が微分同相であることを保証するために、許容可能なヒルベルト空間への場。我々は、ジョイント画像の再構成と運動推定のための微分同相最適輸送を伴う変分モデルを提案する。 
[概要]提案されたモデルは、ワッサースタイン距離をベナモウ-ブレニエ公式で組み立てたものです。最終的に、オード制約バージョンのモーションをadaに取得します。現在のモデルはいくつかの潜在的なモデルに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Exemplar VAE: Linking Generative Models, Nearest Neighbor Retrieval, and
  Data Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_3.html">
      <font color="black">Exemplar VAE: Linking Generative Models, Nearest Neighbor Retrieval, and
  Data Augmentation</font>
    </a>
  </h2>
  <font color="black">Exemplar VAEは、Parzenウィンドウ推定量に基づく潜在空間にノンパラメトリック事前分布を持つVAEの変形です。実験は、密度推定と表現学習に対するExemplar VAEの有効性を示しています。重要なことに、順列にExemplarVAEを使用した生成データ拡張。不変MNISTとファッションMNISTは、分類誤差を1.17％から0.69％に、8.56％から8.16％に減らします。 
[ABSTRACT]潜在空間での近傍探索を使用して模範的なvaeトレーニングを高速化する方法として、検索拡張トレーニング（ラット）を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: HoHoNet: 360 Indoor Holistic Understanding with Latent Horizontal
  Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_4.html">
      <font color="black">HoHoNet: 360 Indoor Holistic Understanding with Latent Horizontal
  Features</font>
    </a>
  </h2>
  <font color="black">HoHoNetは2つの重要な側面で進歩しています。HoHoNetも正確です。次に、列ごとの出力形状の制約を緩和し、LHFeatからのピクセルごとの密度の高い予測を可能にする新しい地平線から密度へのモジュールを提案します。 
[概要]コンパクトなlhfeatは、垂直方向に沿ってフィーチャを平坦化します。深いアーキテクチャは、精度が向上し、より高速に実行されるように設計されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: MonoRec: Semi-Supervised Dense Reconstruction in Dynamic Environments
  from a Single Moving Camera -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_5.html">
      <font color="black">MonoRec: Semi-Supervised Dense Reconstruction in Dynamic Environments
  from a Single Moving Camera</font>
    </a>
  </h2>
  <font color="black">さらに、LiDAR深度値を必要としない半教師あり損失定式化を使用した新しい多段階トレーニングスキームを提示します。この論文では、単一から深度マップを予測する半教師あり単眼高密度再構成アーキテクチャであるMonoRecを提案します。動的環境での移動カメラ..シーン内の動的オブジェクトを処理するために、コストボリュームにエンコードされた測光の不整合を利用して移動オブジェクトマスクを予測するMaskModuleを導入します。 
[ABSTRACT] monorecは、予測されたマスクを活用することで、静的オブジェクトと移動オブジェクトの両方の正確な深度を予測できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Is a Green Screen Really Necessary for Real-Time Human Matting? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_6.html">
      <font color="black">Is a Green Screen Really Necessary for Real-Time Human Matting?</font>
    </a>
  </h2>
  <font color="black">MODNetは、エンドツーエンドスタイルで簡単にトレーニングできます。さらに、トライマップフリーの方法は通常、実際にはドメインシフトの問題に悩まされるため、（1）サブ目的の一貫性に基づく自己監視戦略を導入します。 MODNetを実際のデータに適合させ、（2）MODNetをビデオヒューマンマットに適用するときに結果を滑らかにする1フレームの遅延トリック。さらに重要なことに、私たちの方法は毎日の写真やビデオで驚くべき結果を達成します。 
[概要] modnetの設計は、人間の障害者との戦闘に対抗するように設計されています。人間の開発者が利用できる「ann ann ann wims」を選択するように設計されています。modnetは、新しい人間スタイルの人間スタイルの人間プロジェクトで利用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: SimTreeLS: Simulating aerial and terrestrial laser scans of trees -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_7.html">
      <font color="black">SimTreeLS: Simulating aerial and terrestrial laser scans of trees</font>
    </a>
  </h2>
  <font color="black">シミュレーションでは、材料の分類がポイントごとに保持されるため、葉と木質が完全に認識され、シミュレーション後のラベル付けに先立って、一意の識別子によって個々の木が分離されます。特に、地上および空中レーザースキャンを使用して木をデジタル化するための新しいアプリケーションが多数あります。農業と林業の分野で..SimTreeLSは、公開されているライブラリに基づいて構築されたオープンソースリソースとして利用できます。 
[ABSTRACT] LIDARポイントクラウドの解釈は、ますます手作業でラベル付けされたデータに依存しています。これにより、手続き型で生成されたデータを無限に提供できます。これらは、データ処理技術の開発や機械学習アルゴリズムのトレーニングに使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Where Does It End? -- Reasoning About Hidden Surfaces by Object
  Intersection Constraints -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_8.html">
      <font color="black">Where Does It End? -- Reasoning About Hidden Surfaces by Object
  Intersection Constraints</font>
    </a>
  </h2>
  <font color="black">実験では、実際の動的シーンデータセットと合成動的シーンデータセットに対するアプローチを示します。オブジェクトレベルの動的SLAMフロントエンドは、シーン内の動的オブジェクトを検出、セグメント化、追跡、およびマッピングします。また、メソッドの形状完成性能を定量的に評価します。 
[要約]この論文では、交差点の制約から隠れた形状情報を推測する、小惑星ベースの3D動的シーン再構成へのcoセクションを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: An analysis of the transfer learning of convolutional neural networks
  for artistic images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_9.html">
      <font color="black">An analysis of the transfer learning of convolutional neural networks
  for artistic images</font>
    </a>
  </h2>
  <font color="black">これらの分析は、転送学習手順のいくつかのバリエーションで実行されます。巨大な自然画像データセットからの転送学習、ディープニューラルネットワークの微調整、および対応する事前トレーニング済みネットワークの使用は、事実上、アート分析アプリケーションの中核になっています。最後に、中規模の芸術的データセットを含む二重の微調整により、タスクが変更された場合でも、より小さなデータセットの分類を改善できることを示しました。 
[概要]転移学習の効果はまだよくわかっていませんが、転移データがどのように機能するかを想像することは依然として困難です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Initial Pose-graph Generation for Global SfM -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_10.html">
      <font color="black">Efficient Initial Pose-graph Generation for Global SfM</font>
    </a>
  </h2>
  <font color="black">パスからの相対的なポーズが与えられると、記述子ベースの特徴マッチングは、既知のエピポーラジオメトリを利用して「軽量」になります。RANSACが適用されるときにPROSACベースのサンプリングを高速化するために、対応を順序付ける3番目の方法を提案します。以前の推定からのそれらのインライア確率..グローバルStructure-from-Motionアルゴリズムの初期ポーズグラフ生成を高速化する方法を提案します。 
[概要]画像のグローバルな類似性とポーズの品質（グラフのエッジ）を考慮して、*トラバーサルのヒューリスティックを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: KShapeNet: Riemannian network on Kendall shape space for Skeleton based
  Action Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_11.html">
      <font color="black">KShapeNet: Riemannian network on Kendall shape space for Skeleton based
  Action Recognition</font>
    </a>
  </h2>
  <font color="black">2つの大規模なスケルトンデータセット、つまりNTU-RGB + DとNTU-RGB + D 120の評価により、提案されたアプローチが既存の幾何学的深層学習手法よりも優れており、最近公開されたアプローチと競合することが証明されました。スケルトンシーケンスが最初にモデル化されます。ケンダルの形状空間上の軌道として、線形接線空間にマッピングされます。ディープラーニングアーキテクチャは、ほとんどのコンピュータービジョンタスクで成功しますが、基礎となるユークリッド構造を持つデータ用に設計されました。これは、前処理されたデータが存在する可能性があるため、通常は実行されません。非線形空間で。 
[概要]スケルトンベースの行動認識のために、シンプルでシンプルなアプローチが提案されています。これを使用して、高度な高度なテクノロジーの形式を開発できます。結果は、ディープラーニングアーキテクチャに送られます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: FKAConv: Feature-Kernel Alignment for Point Cloud Convolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_12.html">
      <font color="black">FKAConv: Feature-Kernel Alignment for Point Cloud Convolution</font>
    </a>
  </h2>
  <font color="black">最後に、畳み込みとサンプリング戦略を使用して、時間とメモリを効率的にしながら、分類とセマンティックセグメンテーションのベンチマークで競争力のある結果を示します。ポイントクラウド処理の最近の最先端の方法は、ポイント畳み込みの概念に基づいています。いくつかのアプローチが提案されています。また、ジオメトリのないカーネルの重みの推定と、特徴の空間サポートへのそれらの配置を分離する、独自の畳み込みバリアントを提案します。 
[概要]この論文では、ポイント畳み込み法をどのように開発したかを説明します。ポイントサンプリングは、効果的かつ高速なポイントサンプリング戦略です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: Insights From A Large-Scale Database of Material Depictions In Paintings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_13.html">
      <font color="black">Insights From A Large-Scale Database of Material Depictions In Paintings</font>
    </a>
  </h2>
  <font color="black">また、自然シーンでの物体認識用に設計されたモデルであるFasterRCNNは、絵画の素材の検出にすばやく再利用できることもわかりました。次に、絵画から学ぶことは、意図されたニューラルネットワークに有益である可能性があることを示します。自然画像で使用されます。特に、インタラクティブなセグメンテーションツールを使用して、絵画内のポリゴンセグメントにきれいに注釈を付けることができます。これは、手作業で行うには時間がかかる作業です。 
[概要]絵画から学ぶことは、自然画像での使用を目的とした神経ネットワークにとって有益な場合があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Computational efficient deep neural network with differential attention
  maps for facial action unit detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_14.html">
      <font color="black">Computational efficient deep neural network with differential attention
  maps for facial action unit detection</font>
    </a>
  </h2>
  <font color="black">この論文では、計算効率の高いエンドツーエンドトレーニングディープニューラルネットワーク（CEDNN）モデルと差分画像に基づく空間注意マップを提案します。空間注意マップを追加した後、結果は最先端のAU検出方法よりも優れています。 。機能マップは、ターゲットタスクに関連する部分に焦点を当てる傾向があります。 
[概要]提案されたcesnnは、さまざまな結果に基づいています。これは、disfaおよびckデータセットでの従来の深層学習方法よりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Revisiting Batch Normalization for Training Low-latency Deep Spiking
  Neural Networks from Scratch -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_15.html">
      <font color="black">Revisiting Batch Normalization for Training Low-latency Deep Spiking
  Neural Networks from Scratch</font>
    </a>
  </h2>
  <font color="black">SNNでのこのトレーニングの問題に対処するために、バッチ正規化を再検討し、時間による時間バッチ正規化（BNTT）手法を提案します。以前の作業とは異なり、提案されたBNTTは、時間軸に沿ってBNTTレイヤーのパラメーターを分離して時間ダイナミクスをキャプチャします。スパイクの数..CIFAR-10、CIFAR-100、Tiny-ImageNet、およびイベント駆動型DVS-CIFAR10データセットで実験を行います。 
[概要]高精度と低遅延のsnnを最初からトレーニングすると、スパイキングニューロンの微分不可能な性質に悩まされます。アドレスアドレスにアドレス指定します。bnttは、一時的なsnnのトレーニングには効果がないと見なします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: CLAWS: Clustering Assisted Weakly Supervised Learning with Normalcy
  Suppression for Anomalous Event Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_16.html">
      <font color="black">CLAWS: Clustering Assisted Weakly Supervised Learning with Normalcy
  Suppression for Anomalous Event Detection</font>
    </a>
  </h2>
  <font color="black">提案された方法は、UCF CrimeおよびShanghaiTechデータセットでそれぞれ83.03％および89.67％のフレームレベルのAUCパフォーマンスを取得し、既存の最先端のアルゴリズムよりも優れていることを示しています。この作業では、弱く監視された異常を提案します。 1）バッチ間の相関を減らすためのランダムバッチベースのトレーニング手順、2）1つのトレーニングバッチで利用可能な全体的な情報を考慮に入れることによってビデオの正常領域の異常スコアを最小化するための正常性抑制メカニズムを含む多様な貢献をする検出方法、および3）クラスタリング距離ベースの損失は、ラベルノイズの軽減に貢献し、モデルに明確な正常および異常クラスターを生成するように促すことで、より良い異常表現を生成します。ビデオレベルのラベルを介して実際の異常イベントを検出する方法を学ぶことは、ラベルのノイズだけでなく、異常のまれな発生のために挑戦的なタスク。 
[概要]この方法は、上海のau auによって提案されました。これには、バッチ間の相関を減らすためのランダムなバッチベースのトレーニング手順が含まれます。この方法を使用して、より良い異常表現を作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Alleviating Class-wise Gradient Imbalance for Pulmonary Airway
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_17.html">
      <font color="black">Alleviating Class-wise Gradient Imbalance for Pulmonary Airway
  Segmentation</font>
    </a>
  </h2>
  <font color="black">バックプロパゲーション中に、クラスの不均衡が局所的であるときに前景勾配と背景勾配の比率が小さい場合、前景勾配はそれらの近傍によって侵食される可能性があります。この問題を軽減するために、グループ監視と対応するWingsNetを使用して提供します。浅い層のトレーニングを強化するための補完的な勾配フロー。このプロセスは、最上層から最下層への勾配フローに含まれるノイズ情報を累積的に増加させ、CNNの小さな構造の学習を制限します。 
[概要]これは、末梢気管支のサイズが小さく、空間分布が分散しているためです。これは、前景領域と背景領域の間の深刻なクラスの不均衡によって妨げられます。cnnの拡張法は、気道構造をより正確に予測できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Achieving Sample-Efficient and Online-Training-Safe Deep Reinforcement
  Learning with Base Controllers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_18.html">
      <font color="black">Achieving Sample-Efficient and Online-Training-Safe Deep Reinforcement
  Learning with Base Controllers</font>
    </a>
  </h2>
  <font color="black">Deep Deterministic Policy Gradients（DDPG）に基づいて構築されたこのアルゴリズムは、コントローラーを探索、Q値推定、およびポリシー更新の段階に組み込みます。実際のロボットタスクでのDeep Reinforcement Learning（DRL）アルゴリズムの適用は多くの課題に直面します。 。一方、報酬の設定がまばらであると、探索が非効率になり、物理ロボットを使用した探索はコストが高く、安全ではありません。 
[概要]この論文では、挑戦的な密集した報酬段階を学習する方法を提案します。彼らは、私たちの方法が、既存の産業用ロボット操作システムを活用して、より柔軟でインテリジェントなコントローラーを構築する可能性を秘めていると述べています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Weakly- and Semi-Supervised Probabilistic Segmentation and
  Quantification of Ultrasound Needle-Reverberation Artifacts to Allow Better
  AI Understanding of Tissue Beneath Needles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_19.html">
      <font color="black">Weakly- and Semi-Supervised Probabilistic Segmentation and
  Quantification of Ultrasound Needle-Reverberation Artifacts to Allow Better
  AI Understanding of Tissue Beneath Needles</font>
    </a>
  </h2>
  <font color="black">他のセグメンテーションアルゴリズムと比較して、アプローチの適用可能性を示します。私たちの方法は、残響間のアーティファクトのないパッチから残響を区別し、アーティファクトの強度低下をモデル化することができます。このような効果は挑戦的です。医療画像分析のための既存のコンピュータビジョンアルゴリズム用。 
[概要]結果として生じる残響アーティファクトは、識別が難しい場合があります。これは、さまざまなピクセル値にさまざまな程度で影響を与える可能性があります。私たちの方法は、最先端のアーティファクトと一致します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: RobustPointSet: A Dataset for Benchmarking Robustness of Point Cloud
  Classifiers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_20.html">
      <font color="black">RobustPointSet: A Dataset for Benchmarking Robustness of Point Cloud
  Classifiers</font>
    </a>
  </h2>
  <font color="black">データ拡張により、モデルは「以前に見られた」入力変換に対してロバストになりますが、1）これは推論中の見えない変換では機能しないことを示し、2）データ拡張により、モデルの変換に対する固有のロバスト性を分析することが困難になります。これらのデータセットでトレーニングされたものは、トレーニング時に「見えない」変換を含むデータが提示されると、解釈不能で直感的でない方法で失敗します。この目的のために、ポイントクラウド分類モデル（データ拡張とは無関係）のロバスト性分析のために公開されているデータセットを作成します。 \ textbf {RobustPointSet}と呼ばれる入力変換。 
[概要]データセットは、解釈不能で直感的でない方法で失敗します。これらのデータセットには、列車の時間に「見えない」観測値を含むデータが含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Scale Progressive Fusion Learning for Depth Map Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_21.html">
      <font color="black">Multi-Scale Progressive Fusion Learning for Depth Map Super-Resolution</font>
    </a>
  </h2>
  <font color="black">広範な実験により、提案した方法は、定性的および定量的に最先端の方法に対して改善された結果をもたらすことが示されています。これらの困難に取り組むために、この作業では、デプスマップSRのマルチスケールプログレッシブフュージョンネットワークを提案します。異なるドメインの階層的特徴を統合するための漸近構造..低解像度（LR）深度マップとそれに関連する高解像度（HR）カラー画像を前提として、2つの異なるブランチを利用してマルチスケールの特徴学習を実現します。 
[概要]デプスマップの超解像に関する主な問題は、明らかなギザギザのエッジと細部の過度の損失があることです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Camera Convolutional Color Constancy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_22.html">
      <font color="black">Cross-Camera Convolutional Color Constancy</font>
    </a>
  </h2>
  <font color="black">通常、観測されていないカメラからのテストセット画像のスペクトル特性に依存しないように設計されている以前のクロスカメラ色恒常性モデルとは異なり、C5はトランスダクティブ推論のレンズを通してこの問題にアプローチします。追加のラベルなし画像がモデルへの入力として提供されます。テスト時に、モデルが推論中にテストセットカメラのスペクトルプロパティに合わせてキャリブレーションできるようにします。C5は、複数のデータセットでカメラ間の色の恒常性について最先端の精度を実現し、評価が高速です（ GPUまたはCPUで画像ごとにそれぞれ約7ミリ秒と約90ミリ秒）、必要なメモリはほとんどなく（約2 MB）、したがって、モバイル写真のキャリブレーション不要の自動ホワイトバランスの問題に対する実用的なソリューションです。複数のカメラからの画像でトレーニングされた学習ベースの方法である「クロスカメラコンボリューショナルカラーコンスタンシー」（C5）を紹介します。これは、トレーニング中に以前は見られなかった新しいカメラによってキャプチャされた生の画像からシーンの照明色を正確に推定します。 ng。 
[ABSTRACT] c5は、畳み込み色の恒常性（ccc）アプローチの拡張のようなハイパーネットワークです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: SelfAugment: Automatic Augmentation Policies for Self-Supervised
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_23.html">
      <font color="black">SelfAugment: Automatic Augmentation Policies for Self-Supervised
  Learning</font>
    </a>
  </h2>
  <font color="black">何百もの拡張ポリシー、トレーニング設定、ネットワークアーキテクチャにわたってこの相関関係を確立し、監視あり評価を使用せずに拡張ポリシーを自動的かつ効率的に選択するアルゴリズム（SelfAugment）を提供します。この監視あり評価は、トレーニングプロセスの重要な側面をガイドするために使用されます。データ拡張ポリシーの選択など。ただし、実際にラベルが含まれていない実際のデータでは、教師あり評価を通じて教師なしトレーニングプロセスをガイドすることはできません（たとえば、医療などのプライバシーに配慮した分野の場合など）。イメージング）。 
[概要]この教師あり評価は、トレーニングプロセスの重要な側面をガイドするために使用されます。これらには、徹底的な教師あり評価を使用して決定された学習ポリシーが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Is First Person Vision Challenging for Object Tracking? The TREK-100
  Benchmark Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_24.html">
      <font color="black">Is First Person Vision Challenging for Object Tracking? The TREK-100
  Benchmark Dataset</font>
    </a>
  </h2>
  <font color="black">ギャップを埋めるために、このペーパーでは、FPVでの視覚オブジェクト追跡の最初のベンチマークデータセットであるTREK-100を紹介します。一方、コンピュータービジョンの文献で利用可能な視覚追跡ソリューションは、最後にパフォーマンスを大幅に向上させました。多種多様なターゲットオブジェクトと追跡シナリオの年数..データセットとともに、最高の最新のビジュアルトラッカーの中で30のパフォーマンスの広範な分析を提示します。 
[概要]データセットは、60kの境界ボックス、17のシーケンス属性、13のアクション動詞属性、29のターゲットオブジェクト属性で高密度に注釈が付けられた100のビデオシーケンスで構成されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Born Identity Network: Multi-way Counterfactual Map Generation to
  Explain a Classifier's Decision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_25.html">
      <font color="black">Born Identity Network: Multi-way Counterfactual Map Generation to
  Explain a Classifier's Decision</font>
    </a>
  </h2>
  <font color="black">MNIST、3D形状、およびADNIデータセットの定性的、定量的分析で提案されたBINを検証し、さまざまなアブレーション研究からの方法の理解可能性と忠実度を示しています。反事実マップは、入力サンプルをターゲットラベルとして分類するように変換します。 、これは、人間が反事実的思考を通じて知識を処理する方法に似ています。たとえば、反事実的マップは、疾患と診断される可能性のある正常な脳画像から仮想的な異常を特定できます。 
[ABSTRACT]生まれたアイデンティティネットワーク（bin）は、多方向の反事実マップを作成するための事後アプローチです。反事実マップジェネレーターとターゲットアトリビューションネットワークは、反事実マップジェネレーターとターゲットアトリケーションネットワークの2つのコアコンポーネントで構成されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-20">
        <br><font color="black">2020-11-20</font>
      </time>
    </span>
</section>
<!-- paper0: On Adversarial Robustness: A Neural Architecture Search perspective -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_26.html">
      <font color="black">On Adversarial Robustness: A Neural Architecture Search perspective</font>
    </a>
  </h2>
  <font color="black">さまざまな手作りのNASベースのアーキテクチャを実験して経験的に..私たちの結果は、アンサンブルなどの方法でニューラルネットワークトポロジの力を活用することが、敵対的なトレーニングなしで敵対的な堅牢性を実現するための優れた方法であることを示しています。堅牢性の向上に役立ちます。敵対的な堅牢性を向上させるための1つの有望な方向性は未踏です。つまり、ニューラルネットワークアーキテクチャの複雑なトポロジです。 
[概要]現代の深層学習アーキテクチャの敵対的ロバスト性を改善するための新しい手法が提案されています。sota精度で人気のあるnasは、無料の追加として敵対的精度を提供できます。また、トレードの計算に使用できるメトリックを紹介します。 -クリーンな精度と敵対的な堅牢性の間でオフ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Generation of Continuous Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_27.html">
      <font color="black">Adversarial Generation of Continuous Images</font>
    </a>
  </h2>
  <font color="black">提案されたアーキテクチャ設計により、連続画像ジェネレータのパフォーマンスが6〜40倍向上し、LSUNベッドルーム256x256では6.27、FFHQ 1024x1024では16.32のFIDスコアに達し、連続画像GANとピクセルベースのGANの間のギャップが大幅に減少します。画像生成にINRを適応させることは、MNISTのようなデータセットに限定され、複雑な実世界のデータにスケーリングしません。それとは別に、すぐに使える超解像度など、INRベースのデコーダーのいくつかのエキサイティングなプロパティを調査します。画像空間補間、低解像度画像の高速推論、画像境界の外側を外挿する機能、および強力な幾何学的事前分布。 
[ABSTRACT] inrq、2D画像は暗黙的に16歳として表されます。これは、（x、y）に基づいてrgbピクセル値を予測します。以前のinrsの適応の試みは、データセットのようにmnistに限定されていました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Recurrent Multi-view Alignment Network for Unsupervised Surface
  Registration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_28.html">
      <font color="black">Recurrent Multi-view Alignment Network for Unsupervised Surface
  Registration</font>
    </a>
  </h2>
  <font color="black">次に、投影されたマルチビュー2D深度画像の3D形状の類似性を測定する微分可能損失関数を導入して、グラウンドトゥルースの監視なしで完全なフレームワークをエンドツーエンドでトレーニングできるようにします。 -いくつかの剛体変換のポイントごとの組み合わせによる剛体変換..いくつかの異なるデータセットでの広範な実験は、提案された方法が以前の最先端技術を大幅に上回っていることを示しています。 
[要約]このホワイトペーパーでは、これら2つの課題を同時に解決します。この表現により、ソリューションスペースが適切に制約されます。これにより、繰り返しフレームワークを使用してメソッドを繰り返し解決できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: PLOP: Learning without Forgetting for Continual Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_29.html">
      <font color="black">PLOP: Learning without Forgetting for Continual Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">バックグラウンドシフトを処理し、古いクラスの壊滅的な忘却を回避するために古いモデルによって予測されたクラス。さらに、バックグラウンドwrtのエントロピーベースの疑似ラベル付けを設計します。ディープラーニングアプローチは、今日、セマンティックセグメンテーションなどのコンピュータービジョンタスクに取り組むために広く使用されており、大規模なデータセットとかなりの計算能力を必要とします。 
[概要]セマンティックセグメンテーション（css）の継続的な学習は新しいトレンドです。新しいクラスを追加して古いモデルを更新することで構成されます。この問題は、各ステップで前の反復の古いクラスが崩壊する傾向があるcssでさらに悪化します。バックグラウンドに</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Model-Enhanced Human Motion Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_30.html">
      <font color="black">Generative Model-Enhanced Human Motion Prediction</font>
    </a>
  </h2>
  <font color="black">人間の動きの予測子は、OoDの課題を念頭に置いて構築する必要があり、多様な識別アーキテクチャを極端な分布シフトに強化するための拡張可能な一般的なフレームワークを提供することをお勧めします。現在の最先端の識別モデルに適用すると、提案されたアプローチは、分布内のパフォーマンスを犠牲にすることなくOoDの堅牢性を向上させ、モデルの解釈可能性を理論的に促進できます。人間の動きを予測するタスクは、アクションの自然な不均一性と構成性によって複雑になり、分布外までの分布シフトに対する堅牢性が必要になります。 （OoD）。 
[概要] human3。 6mおよびcmuのモーションキャプチャデータセットは、human3に基づいています。 6m。これらには、頭の中でのフードチャレンジと人間の動きの新しいモデルが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: The Interpretable Dictionary in Sparse Coding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_31.html">
      <font color="black">The Interpretable Dictionary in Sparse Coding</font>
    </a>
  </h2>
  <font color="black">スパースコーディングモデルを、同じデータでトレーニングされた同等のフィードフォワード畳み込みオートエンコーダーと比較対照します。結果は、学習したスパースコーディング辞書と内部アクティベーション表現の解釈において、定性的および定量的な利点を示しています。スパースコーディングによって学習されたものは、より簡単に理解でき、これらの要素のアクティブ化により、選択的な特徴出力が作成されます。 
[概要]私たちの研究は、同じデータを使用してトレーニングされたアンが、標準の深層学習モデルよりも解釈しやすいモデルを提供することを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: EM-Fusion: Dynamic Object-Level SLAM with Probabilistic Data Association -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_32.html">
      <font color="black">EM-Fusion: Dynamic Object-Level SLAM with Probabilistic Data Association</font>
    </a>
  </h2>
  <font color="black">私たちの主な目新しさは、データの関連付けとオクルージョン処理の戦略に自然につながる確率論的定式化です。実験で私たちのアプローチを分析し、堅牢性と精度の点で私たちのアプローチが最先端の方法と比べて遜色がないことを示します。 。ただし、移動するオブジェクトの表現と追跡は、ロボット工学や拡張現実でのアプリケーションに大きな可能性を秘めています。 
[概要]ローカルボリューム符号付き距離関数（sdf）マップで剛体オブジェクトを表現し、rgb --d画像とsdf表現の直接アライメントとしてマルチオブジェクトトラッキングを定式化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-26">
        <br><font color="black">2019-04-26</font>
      </time>
    </span>
</section>
<!-- paper0: LiDAR-based Panoptic Segmentation via Dynamic Shifting Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_33.html">
      <font color="black">LiDAR-based Panoptic Segmentation via Dynamic Shifting Network</font>
    </a>
  </h2>
  <font color="black">特に、DS-Netには3つの魅力的な特性があります。1）強力なバックボーン設計。BFSやDBSCANなどの一般的に使用されるクラスタリングアルゴリズムでは、点群分布が不均一でインスタンスサイズが異なる複雑な自動運転シーンを処理できないことがわかります。 。2）複雑な点分布の動的シフト。 
[概要]動的シフトネットワーク（ds-net）は、ポイントクラウドレルムで効果的なパノラマセグメンテーションフレームワークとして機能します。メインツールは、クラウドクラウドクラウドコンピューティングに基づく動的シフトです。これを使用して、間の不一致に対処できます。セマンティックおよびインスタンスの予測</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Variational Monocular Depth Estimation for Reliability Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_34.html">
      <font color="black">Variational Monocular Depth Estimation for Reliability Prediction</font>
    </a>
  </h2>
  <font color="black">ただし、自動運転車やロボットなどのアプリケーションでこのような推定深度画像を使用する場合は、各ピクセル位置での推定深度を一様に信じる必要があります。この論文では、単眼深度推定の変分モデルを理論的に定式化して予測します。推定深度画像の信頼性..一部のピクセルで推定深度がより大きな間違いを犯す可能性があるため、これはタスクの実行で致命的なエラーにつながる可能性があります。 
[ABSTRACT]以前の作業により、深度推定の精度が向上しました。これにより、タスクの実行時に致命的なエラーが発生する可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Legacy Photo Editing with Learned Noise Prior -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_35.html">
      <font color="black">Legacy Photo Editing with Learned Noise Prior</font>
    </a>
  </h2>
  <font color="black">また、ノイズを事前に学習するための大規模なレガシー写真データセットを作成します。https：//github.com/zhaoyuzhi/Legacy-Photo-Editing-with-Learned-Noise-コードと提案されたLPデータセットの事前。これらを解決するには問題については、ペアになっていない画像を使用して実際のレガシー写真のノイズ分布をシミュレートするために、ノイズの事前学習者NEGANを提案します。 
[概要]ペアになっていない画像を使用して実際のレガシー写真のノイズ分布をシミュレートするノイズ事前学習者ネガンがあります。結果は、それが最高の知覚品質を達成することを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Benchmarking Image Retrieval for Visual Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_36.html">
      <font color="black">Benchmarking Image Retrieval for Visual Localization</font>
    </a>
  </h2>
  <font color="black">これらのタスクには最先端の画像検索アルゴリズムを使用するのが一般的です。ただし、視覚的なローカリゼーションのコンテキストでは、視点の変更に対する堅牢性は必ずしも望ましいとは限りません。これは、ローカリゼーション用に特別に設計された検索アプローチの必要性を示しています。タスク。 
[概要]この論文は、複数の視覚的ローカリゼーションタスクのローカリゼーションの役割に焦点を当てています。古典的なランドマーク検索/認識タスクの検索パフォーマンスは、すべてではなく一部のタスクでのみローカリゼーションパフォーマンスに相関することを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Benchmarking Inference Performance of Deep Learning Models on Analog
  Devices -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_37.html">
      <font color="black">Benchmarking Inference Performance of Deep Learning Models on Analog
  Devices</font>
    </a>
  </h2>
  <font color="black">ただし、パフォーマンスは、モデルの設計哲学、モデルの詳細な構造、正確な機械学習タスク、およびデータセットによっても影響を受けます。この研究では、訓練された人気のある深層学習の推論パフォーマンスの体系的な評価アナログデバイスに展開された画像分類のモデルが実行され、推論中にトレーニングされたモデルの重みに加法性ホワイトガウスノイズが追加されました。ただし、デバイスのアナログの性質と関連する多くのノイズ源により、このようなデバイスにデプロイされた、トレーニング済みの深層学習モデルの重みの値。 
[概要]深層学習モデルは、vggなどの設計の冗長性が高く、一般にノイズに対してより堅牢です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: FP-NAS: Fast Probabilistic Neural Architecture Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_38.html">
      <font color="black">FP-NAS: Fast Probabilistic Neural Architecture Search</font>
    </a>
  </h2>
  <font color="black">単純な蒸留を備えたFP-NAS-L2モデルは、高度なインプレース蒸留を備えたBigNAS-XLよりも優れており、FLOPSが少ない0.7％の精度です。さらに、多変量空間で高速に検索するために、アーキテクチャパラメータの数を1桁以上減らすことができる、最初の因数分解された分布。このメソッドをFast Probabilistic NAS（FP-NAS）と呼びます。それでも、多くのアーキテクチャをサンプリングする必要があるため、検索に計算コストがかかります。広大なスペースで。 
[ABSTRACT] fp --nasを使用すると、巨大なfbnetv2スペースをより広く拡張できます。split-アテンションブロックを追加し、分割数を検索できるようにする一方で、特に新しい方法で大きなモデルを検索します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-22">
        <br><font color="black">2020-11-22</font>
      </time>
    </span>
</section>
<!-- paper0: VIGOR: Cross-View Image Geo-localization beyond One-to-one Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_39.html">
      <font color="black">VIGOR: Cross-View Image Geo-localization beyond One-to-one Retrieval</font>
    </a>
  </h2>
  <font color="black">私たちのデータセットとコードは公開されます。クエリと参照画像は完全に整列されたペアではなく、1つのクエリ位置をカバーする複数の参照画像が存在する可能性があるため、この仮定は既存のデータセットの1対1の取得設定を破ります。既存の最先端の方法のベンチマークを行い、クエリを大まかな方法でローカライズするための新しいエンドツーエンドのフレームワークを提案します。 
[概要]以前の作品では、関心のある領域が都市規模のデータセットに集中していました。これは、検索画像が関心のある領域で任意である可能性があるというより現実的な仮定に基づいています。これらの観察は、この現実的な設定と既存のデータセット</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Geography-Aware Self-Supervised Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_40.html">
      <font color="black">Geography-Aware Self-Supervised Learning</font>
    </a>
  </h2>
  <font color="black">時間の経過とともに空間的に整列した画像を活用して、対照的な学習と地理的位置で時間的ポジティブペアを構築し、プレテキストタスクを設計します。ギャップを埋めるために、リモートセンシングデータの時空間構造を活用する新しいトレーニング方法を提案します。提案された方法が、画像分類、オブジェクト検出、リモートセンシングおよびその他のジオタグ付き画像データセットのセマンティックセグメンテーションに関する対照学習と監視学習の間のギャップを埋めることを示します
[要約]提案手法は、自己満足と監視学習の間のギャップを埋めます。これらには対照が含まれます。 、監視された学習、およびセマンティック情報</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-19">
        <br><font color="black">2020-11-19</font>
      </time>
    </span>
</section>
<!-- paper0: A Hierarchical Multi-Modal Encoder for Moment Localization in Video
  Corpus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_41.html">
      <font color="black">A Hierarchical Multi-Modal Encoder for Moment Localization in Video
  Corpus</font>
    </a>
  </h2>
  <font color="black">顕著な課題は、ビデオの表現が時間領域のさまざまなレベルの粒度を説明する必要があることです。ActivityNetキャプションおよびTVRデータセットのビデオコーパスでのモーメントローカリゼーションに関するモデルを評価するために、広範な実験を実施します。この問題に取り組むために、粗粒度のクリップレベルと細粒度のフレームレベルの両方でビデオをエンコードして、複数のサブタスク、つまりビデオ検索、セグメントの時間的ローカリゼーションに基づいてさまざまなスケールで情報を抽出するHierArchical Multi-Modal EncodeR（HAMMER）を提案します。マスクされた言語モデリング。 
[ABSTRACT] gran granは、グラニュラービデオエンコーダー（ハンマー）の発案によるものです。これは、細粒度のクリップレベルと細粒度のフレームレベルの両方でビデオをエンコードします。これは、ビデオの取得とその後の検索を含む複数のサブタスクに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-18">
        <br><font color="black">2020-11-18</font>
      </time>
    </span>
</section>
<!-- paper0: Multiscale Sparsifying Transform Learning for Image Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_42.html">
      <font color="black">Multiscale Sparsifying Transform Learning for Image Denoising</font>
    </a>
  </h2>
  <font color="black">合成辞書学習やスパース化変換学習などのデータ駆動型スパース法は、画像のノイズ除去に効果的であることが証明されています。ただし、これらの方法は本質的にシングルスケールであり、画像のマルチスケールの性質を無視します。最後に、詳細サブバンドのノイズ除去の必要性。 
[概要]提案されたマルチスケール手法は驚くほどシングルスケールであり、画像のマルチスケールの性質を無視します。この単純化により、ベースラインに対して競争力のあるパフォーマンスを備えた効率的なマルチスケールノイズ除去手法が実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-25">
        <br><font color="black">2020-03-25</font>
      </time>
    </span>
</section>
<!-- paper0: Incorporating Learnable Membrane Time Constant to Enhance Learning of
  Spiking Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_43.html">
      <font color="black">Incorporating Learnable Membrane Time Constant to Enhance Learning of
  Spiking Neural Networks</font>
    </a>
  </h2>
  <font color="black">この論文では、膜関連パラメータが脳領域間で異なるという観察からインスピレーションを得て、シナプスの重みだけでなく、SNNの膜時定数も学習できるトレーニングアルゴリズムを提案します。スパイキングニューラルネットワーク（ SNN）は、時間的情報処理能力、低消費電力、および高い生物学的妥当性により、大きな研究関心を集めています。さらに、SNNのプーリング方法を再評価し、最大プーリングがSNNのフィッティング能力を向上させることができることを発見しました。一時的なタスクだけでなく、計算コストを削減します。 
[ABSTRACT]ニューヨークを拠点とする研究によると、snnの注目度の高い学習アルゴリズムは依然として困難ですが、脳のニューロンの信頼性は依然として課題です。提案された方法に加えて、新しい方法を開発するために使用できます。システム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-11">
        <br><font color="black">2020-07-11</font>
      </time>
    </span>
</section>
<!-- paper0: BubbleNets: Learning to Select the Guidance Frame in Video Object
  Segmentation by Deep Sorting Frames -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_44.html">
      <font color="black">BubbleNets: Learning to Select the Guidance Frame in Video Object
  Segmentation by Deep Sorting Frames</font>
    </a>
  </h2>
  <font color="black">これは、既存のデータセットから膨大な量のトレーニング例を変換できるパフォーマンスベースの損失関数を使用してフレームの選択を学習する新しいディープソーティングネットワークであるBubbleNetsを導入することで実現します。BubbleNetsを使用すると、11を達成できます。基礎となるセグメンテーション方法を変更せずに、DAVISベンチマークでのセグメンテーションパフォーマンスの相対的な改善率。半監視付きビデオオブジェクトセグメンテーションは、近年、実際のやりがいのあるビデオで大きな進歩を遂げました。 
[概要]セグメンテーション方法の現在のモデルは、最初のフレームに単一の注釈を付けてビデオ内のオブジェクトをセグメント化することです。davisベンチマークでセグメンテーションパフォーマンスを11％相対的に向上させることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-03-28">
        <br><font color="black">2019-03-28</font>
      </time>
    </span>
</section>
<!-- paper0: SpinNet: Learning a General Surface Descriptor for 3D Point Cloud
  Registration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_45.html">
      <font color="black">SpinNet: Learning a General Surface Descriptor for 3D Point Cloud
  Registration</font>
    </a>
  </h2>
  <font color="black">空間ポイントトランスフォーマーは、入力ローカルサーフェスを注意深く設計された円筒空間にマッピングするために最初に導入され、SO（2）同変表現によるエンドツーエンドの最適化を可能にします。このペーパーでは、新しいが概念的に単純なニューラルを紹介します。 SpinNetと呼ばれるアーキテクチャは、回転的に不変でありながら、正確な登録を可能にするのに十分な情報を提供します。さらに重要なことに、さまざまなセンサーモダリティを持つ目に見えないシナリオ全体で最高の一般化機能を備えています。 
[概要]入力ローカルサーフェスを十分に設計された円筒形空間にマッピングするために、最初に空間ポイントトランスフォーマーが導入されました。これにより、（2）同変表現を使用したエンドツーエンドの配置が可能になります。コードは次のURLで入手できます。 www。 github。 com / qingyonghu / spinnet。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Equivariant Maps for Hierarchical Structures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_46.html">
      <font color="black">Equivariant Maps for Hierarchical Structures</font>
    </a>
  </h2>
  <font color="black">階層構造の対称性がビルディングブロックの対称性の「花輪積」であることを観察し、ビルディングブロックの同変線形レイヤーの直感的な組み合わせを使用して階層の同変写像を表現します。これの有効性を示すためにモデル設計へのアプローチでは、ポイントクラウドデータのセマンティックセグメンテーションへの適用を検討します。ポイントクラウドをボクセル化することにより、データに変換と並べ替えの対称性の階層を課し、Semantic3Dに関する最新情報を報告します。 S3DISおよびvKITTIには、実世界で最大のポイントクラウドベンチマークがいくつか含まれています。 
[概要]多くの実用的な構造は単純なビルディングブロックの階層であるため、これは重要な問題です。いくつかの例には、セットのシーケンス、構造の対称性、または多重解像度画像が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-05">
        <br><font color="black">2020-06-05</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Sample the Most Useful Training Patches from Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_47.html">
      <font color="black">Learning to Sample the Most Useful Training Patches from Images</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、手動またはランダムな選択ではなく、画像から最も有用なパッチを選択して新しいトレーニングセットを構築することを学習する、PatchNetと呼ばれるデータ駆動型アプローチを紹介します。デモザイキングなどの一部の画像復元タスクでは、学習するのに難しいトレーニングサンプルが必要です。効果的なモデル..その驚くべき効果に加えて、PatchNetはトレーニング中にのみ適用されるため、リソースに優しいため、推論中に追加の計算コストを必要としません。 
[概要]シンプルなアイデアは、大規模なデータセットから最も有益なサンプルを自動的に選択します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Segmentation of the cortical plate in fetal brain MRI with a topological
  loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_48.html">
      <font color="black">Segmentation of the cortical plate in fetal brain MRI with a topological
  loss</font>
    </a>
  </h2>
  <font color="black">さらに、26の臨床MRIからランダムに選択された130のスライスに対する3人の異なる専門家による定性的評価は、MR再構成の品質とは無関係に私たちの方法のアウトパフォーマンスを証明します。胎児の皮質板は、子宮の発達の初期を通して劇的な形態変化を受けます。磁気共鳴（MR）イメージングを使用して..この論文では、胎児皮質プレートの深部学習ベースのセグメンテーションの形態学的一貫性を強化するために、追加の損失関数として、トポロジカル制約の統合を初めて提案します。 
[概要] 18の胎児脳地図で私たちの方法を定量的に評価します。ベースラインの方法と比較して、すべての在胎週数を通して私たちの方法の重要な利点を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-23">
        <br><font color="black">2020-10-23</font>
      </time>
    </span>
</section>
<!-- paper0: Localization Uncertainty Estimation for Anchor-Free Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_49.html">
      <font color="black">Localization Uncertainty Estimation for Anchor-Free Object Detection</font>
    </a>
  </h2>
  <font color="black">1）位置（中心点）やスケール（幅、高さ）などのさまざまな特性を持つオブジェクトプロパティに基づいて不確実性をモデル化します。ディラックのデルタ分布はガウス分布として正確に表されていないため、つまり、任意の$ \ mu $および$ \ Sigma $ ..この目的のために、モデルの仕様ミスの問題を軽減する可能性損失にIoUを重み付けすることによって不確実性を測定するために、新しい不確実性損失、負の電力対数尤度損失を設計します。 
[概要]アンカーベースの物体検出のための以前の不確実性推定方法には3つの特徴があります。それらは同様の特性を持つボックスオフセットの4つの方向に基づいています。これにより、不確実な点をキャプチャし、範囲内の定量値を提供できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-28">
        <br><font color="black">2020-06-28</font>
      </time>
    </span>
</section>
<!-- paper0: Group Whitening: Balancing Learning Efficiency and Representational
  Capacity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_50.html">
      <font color="black">Group Whitening: Balancing Learning Efficiency and Representational
  Capacity</font>
    </a>
  </h2>
  <font color="black">この分析は、GWを実際に適用するための理論的ガイダンスを提供します。最後に、提案されたGWをResNetおよびResNeXtアーキテクチャに適用し、ImageNetおよびCOCOベンチマークで実験を行います。このペーパーでは、グループホワイトニング（GW）を提案します。ホワイトニング操作を行い、ミニバッチ内の正規化の欠点を回避します。 
[概要]モデルの学習効率を改善するbnの利点は、ホワイトニングを使用することでさらに改善できます。19億ドルのgwをモデルに適用し、イメージネットとココのベンチマークで実験を行うことを提案しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Large Norms of CNN Layers Do Not Hurt Adversarial Robustness -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_51.html">
      <font color="black">Large Norms of CNN Layers Do Not Hurt Adversarial Robustness</font>
    </a>
  </h2>
  <font color="black">さらに、3つの異なる敵対的トレーニングフレームワークでトレーニングされたCNNのレイヤーのノルムを計算し、敵対的にロバストなCNNは、非敵対的にロバストなCNNと同等またはそれ以上のノルムを持っていることを発見します。畳み込みニューラルネットワーク（CNN）のLipschitzプロパティ以降敵対的ロバスト性に関連すると広く考えられているため、2Dマルチチャネル畳み込み層の$ \ ell_1 $ノルムと$ \ ell_ \ infty $ノルムを理論的に特徴付け、正確な$ \ ell_1 $ノルムと$ \を計算する効率的な方法を提供します。 ell_ \ infty $ノルム..さらに、穏やかな仮定の下で、敵対的にロバストな分類器がニューラルネットワークで達成でき、敵対的にロバストなニューラルネットワークが任意に大きなリプシッツ定数を持つことができることを証明します。 
[概要]「ノルム減衰」法は、cnn減衰のノルムを効果的に減らすことができます。しかし、敵対者の頑健性をわずかに損なう可能性があることに驚いています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Processing-In-Memory Neural Networks via Noise-Aware
  Normalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_52.html">
      <font color="black">Robust Processing-In-Memory Neural Networks via Noise-Aware
  Normalization</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、シンプルで実装が簡単で、さまざまなノイズ設定に一般的であり、モデルを再トレーニングする必要はありません。固有ノイズを軽減する以前の作業は、ノイズモデルの知識を前提としており、それに応じてニューラルネットワークを再トレーニングする必要がありました。重要な観察結果は、パフォーマンスの低下は、ノイズによって引き起こされるネットワークアクティベーションの分布シフトによるものであるということです。 
[ABSTRACT] pimアクセラレータは、物理コンポーネントに固有のノイズに悩まされることが多く、ニューラルネットワークモデルがデジタルハードウェアと同じパフォーマンスを達成することを困難にします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Do You Live a Healthy Life? Analyzing Lifestyle by Visual Life Logging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_53.html">
      <font color="black">Do You Live a Healthy Life? Analyzing Lifestyle by Visual Life Logging</font>
    </a>
  </h2>
  <font color="black">現在のライフログ/自己中心的なデータセットとは対照的に、私たちのデータセットはライフスタイル分析に適しています。画像は短い間隔で撮影され、短期間の活動をキャプチャするためです。さらに、朝から晩まで継続的に画像を撮影し、ユーザーが行ったすべての活動を記録します。この作業では、ライフスタイル分析の問題を調査し、ライフスタイル分析用の視覚的なライフログデータセット（VLDLA）を構築します。データセットに基づいて、各フレームでユーザーアクティビティを分類し、時間の経過とともに変化し、アクティビティに関連付けられているユーザーの3つの潜在的な流暢さを使用して、ユーザーのライフスタイルの健康度を測定します。 
[概要] vldlaには、ウェアラブルカメラで3秒ごとに7日間キャプチャされた画像が含まれています。データセットはライフスタイル分析に適していないため、コンピュータビジョンの分野でのライフスタイル分析に関する研究はありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Persistent Mixture Model Networks for Few-Shot Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_54.html">
      <font color="black">Persistent Mixture Model Networks for Few-Shot Image Classification</font>
    </a>
  </h2>
  <font color="black">このターゲットネットワークは、トレーニングを安定させながらパフォーマンスを向上させるために、混合コンポーネントにインスタンスを一貫して割り当てるために使用されます。4つの標準データセットと4つのバックボーンでの広範な実験により、共同表現/混合学習アプローチの有効性が実証されます。 。PMMトレーニングアルゴリズムは、1）初期トレーニングと2）プログレッシブフォローの2つの主要な段階で構成されています。 
[ABSTRACT]私たちの方法は、エンドツーエンドの方法でデータ表現と共同で各基本クラスの混合モデルを学習します。最初に、多成分混合の初期推定は、以下の組み合わせを使用して基本ドメインの各クラスについて学習されます。 2つの損失関数</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: DomainMix: Learning Generalizable Person Re-Identification Without Human
  Annotations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_55.html">
      <font color="black">DomainMix: Learning Generalizable Person Re-Identification Without Human
  Annotations</font>
    </a>
  </h2>
  <font color="black">ただし、大規模なトレーニングデータのラベル付けには、非常に費用と時間がかかります。具体的には、効果的な人物再識別トレーニングのために大規模な合成データを生成する最近の作業から着想を得て、提案された方法は、ラベル付けされた合成データから教師なしドメイン適応を最初に適用します。ラベルのない実世界のデータに変換して疑似ラベルを生成します。ただし、それらの間には依然として大きなドメインギャップが存在します。 
[概要]提案された方法は、目に見えないドメインでうまく一般化することができます。それは、ドメイン関連とドメイン識別の間の敵対的な学習を作成し、その間、人の再識別のための判別機能を学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: MicroNet: Towards Image Recognition with Extremely Low FLOPs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_56.html">
      <font color="black">MicroNet: Towards Image Recognition with Extremely Low FLOPs</font>
    </a>
  </h2>
  <font color="black">2つの設計原則に基づいて非常に低いFLOPを処理します。（a）ノードの接続性を下げることでネットワーク幅の縮小を回避し、（b）レイヤーごとにより複雑な非線形性を導入することでネットワーク深度の縮小を補正します。 、チャネル数と入力/出力接続の間の良好なトレードオフのために、ポイントワイズとデプスワイズの両方の畳み込みを低ランク行列に因数分解するマイクロファクター化畳み込みを提案します。融合は、パラメーターが入力に適応するため動的です。 
[概要]これらのローフロップは、2つの設計原則に基づいています。ノードの接続性を下げることにより、ネットワーク幅の縮小を回避することが含まれます。これらには、ポイントごとにより複雑な非回転を追加することが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Augmented Lagrangian Adversarial Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_57.html">
      <font color="black">Augmented Lagrangian Adversarial Attacks</font>
    </a>
  </h2>
  <font color="black">3つのデータセットといくつかのモデルで攻撃を最先端の方法と比較し、計算の複雑さが同等またはそれ以下の競争力のあるパフォーマンスを一貫して取得します。敵対的な攻撃アルゴリズムは、実際には遅い、またはそれ以上のペナルティ方法によって支配されます。考慮される距離の特性に合わせて大幅に調整された、効率的な距離カスタマイズされた方法。パフォーマンスに決定的な影響を与えるいくつかの重要なアルゴリズムの変更をもたらします。 
[ABSTRACT]攻撃は、広範囲の距離で簡単に使用できます-カスタマイズされたアルゴリズム。最小限の摂動の敵対的特性を生成するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Mini-DDSM: Mammography-based Automatic Age Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_58.html">
      <font color="black">Mini-DDSM: Mammography-based Automatic Age Estimation</font>
    </a>
  </h2>
  <font color="black">提案された作業の利点をさらに検証するために、別の独立したデータセットでロジスティックおよび線形回帰モデルを実行しました。残念ながら、このデータセットの元の画像は、壊れたソフトウェアでしか取得できません。公開マンモグラフィーデータが不足しているため年齢属性を持つセットでは、Webクローラーを使用して、公開データセットからサムネイルマンモグラフィック画像とその年齢フィールドをダウンロードします。マンモグラフィ検診用のデジタルデータベース。 
[概要]この研究の目的は、マンモグラム画像から年齢を再分類するためのaiベースのモデルを考案することです。マンモグラム画像は、壊れたソフトウェアによってのみ取得できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-01">
        <br><font color="black">2020-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: Temporal Action Detection with Multi-level Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_59.html">
      <font color="black">Temporal Action Detection with Multi-level Supervision</font>
    </a>
  </h2>
  <font color="black">次に、弱くラベル付けされたデータをSSADに組み込み、3つのレベルの監視を備えたOmni-supervised Action Detection（OSAD）を提案します。THUMOS14とActivityNet1.2で作成したデータ分割について、SSADとOSADのベースラインに対して広範囲にベンチマークを行います。提案されたUFAおよびIBメソッドの有効性。アクション情報を保持しながら非アクションフレームのシーン情報を抑制する情報ボトルネック（IB）は、OSADベースラインで付随するアクションコンテキストの混乱の問題を克服するのに役立つように設計されています。 
[概要]アクション検出モデルをトレーニングするためのunad-ibデータの導入は、アノテーションコストの削減に役立つ可能性があります。ssadベースラインでのアクションの不完全性の主なエラーを軽減するために、教師なし前景注意（ufa）モジュールをさらに設計します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Refinement Network for Human Motion Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_60.html">
      <font color="black">Adversarial Refinement Network for Human Motion Prediction</font>
    </a>
  </h2>
  <font color="black">具体的には、カスケードリファインメントネットワークの入力として履歴モーションシーケンスと粗い予測の両方を使用して、洗練された人間の動きを予測し、敵対的なエラー増大によってリファインメントネットワークを強化します。さまざまな主題間で..テストでは、カスケードされた改良ネットワークにより、粗い予測子からの予測誤差が軽減され、より細かい予測が確実に行われます。 
[概要]リカレントニューラルネットワークとフィードフォワードディープネットワークの2つの一般的な方法では、スローモーションの傾向を予測できますが、手足の動きなどの動きの詳細が失われる可能性があります。3つの標準ベンチマークデータセットで広範な実験を行います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: SegBlocks: Block-Based Dynamic Resolution Networks for Real-Time
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_61.html">
      <font color="black">SegBlocks: Block-Based Dynamic Resolution Networks for Real-Time
  Segmentation</font>
    </a>
  </h2>
  <font color="black">最も重要なのは、新しいBlockPadモジュールが、既存のメソッドが影響するブロック境界での機能の不連続性を防ぎ、メモリ消費を制御できることです。たとえば、このメソッドは、SwiftNet-RN18の浮動小数点演算の数を60％削減し、増加させます。 CityscapesのmIoU精度はわずか0.3％低下し、推論速度は50％低下します。CityscapesとMapillary Vistasのセマンティックセグメンテーションに関する実験では、画像を動的に処理すると、同様の複雑さの静的ベースラインと比較して、複雑さのトレードオフに対して精度が向上することが示されています。 
[概要]私たちのポイントは、画像をブロックに分割し、操作の数とメモリ消費量をダウンサンプリングします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: RIN: Textured Human Model Recovery and Imitation with a Single Image -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_62.html">
      <font color="black">RIN: Textured Human Model Recovery and Imitation with a Single Image</font>
    </a>
  </h2>
  <font color="black">この論文では、単一の画像からテクスチャ3Dモデルを再構築し、生成されたモデルで被写体を模倣するための新しいボリュームベースのフレームワークであるRINを提案します。人間の模倣は、人間のポーズを解きほぐすGANの機能によって推進され、最近話題になっています。ボディコンテンツ..しかし、最新の手法では3D情報に焦点を当てることはほとんどなく、自己閉塞を回避するために、大量の入力画像が必要になります。 
[ABSTRACT]人間の質感に加えて、au-画像-前面のように-背面への翻訳ネットワークを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Comparisons among different stochastic selection of activation layers
  for convolutional neural networks for healthcare -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_63.html">
      <font color="black">Comparisons among different stochastic selection of activation layers
  for convolutional neural networks for healthcare</font>
    </a>
  </h2>
  <font color="black">いくつかの中小規模の生物医学画像データセットでネットワークをテストしました。ベースラインとして、ReLUアクティベーションのみを使用するニューラルネットワークのアンサンブルを使用しました。次のアクティベーションから選択します：ReLU、リークReLU、パラメトリックReLU、 ELU、Adaptive Piecewice Linear Unit、S-Shaped ReLU、Swish、Mish、Mexican Linear Unit、Gaussian Linear Unit、Parametric Deformable Linear Unit、Soft Root Sign（SRS）など。 
[概要]すべての実験のマットネットはgithubsnanniによって共有されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Task dependent Deep LDA pruning of neural networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_64.html">
      <font color="black">Task dependent Deep LDA pruning of neural networks</font>
    </a>
  </h2>
  <font color="black">SqueezeNet、MobileNet）..このホワイトペーパーでは、Fisherの線形判別分析（LDA）に基づくタスク依存のディーププルーニングフレームワークを導入することで、この問題に対処します。汎用オブジェクト（ImageNet、CIFAR100）およびドメインのデータセットに関する実験結果特定のタスク（Adience、およびLFWA）は、最先端のプルーニングアプローチおよび固定コンパクトネット（
[ABSTRACT]など）に対するフレームワークの優れたパフォーマンスを示しています。このアプローチは、畳み込み、完全接続、およびモジュールベースのディープネットワークに適用できます。構造。すべての場合において、事前決定空間とクロスレイヤーデコンボ依存性に見られるニューロンの影響の高い無相関化を活用します。これは、このタイプの剪定への長期的アプローチの最初のステップです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-03-21">
        <br><font color="black">2018-03-21</font>
      </time>
    </span>
</section>
<!-- paper0: A Sliced Wasserstein Loss for Neural Texture Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_65.html">
      <font color="black">A Sliced Wasserstein Loss for Neural Texture Synthesis</font>
    </a>
  </h2>
  <font color="black">VGG-19）..根本的な数学的問題は、特徴空間内の2つの分布間の距離の測定です。私たちの目標は、その代わりにスライスされたワッサースタイン距離を促進することです。 
[要約]グラム行列の損失は、この問題の遍在するアナロジーですが、いくつかの欠点があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-12">
        <br><font color="black">2020-06-12</font>
      </time>
    </span>
</section>
<!-- paper0: Multiscale Deep Equilibrium Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_66.html">
      <font color="black">Multiscale Deep Equilibrium Models</font>
    </a>
  </h2>
  <font color="black">どちらの設定でも、MDEQは、最近の競合するコンピュータービジョンモデルのパフォーマンスに匹敵するか、それを超えることができます。このようなパフォーマンスとスケールが暗黙の深層学習アプローチによって初めて達成されました。これらの同時に学習されるマルチ解像度機能により、トレーニングが可能になります。単一のMDEQを使用して画像分類とセマンティックセグメンテーションの両方を実行するなど、さまざまなタスクと損失関数のセットに関する単一のモデル。2つの大規模なビジョンタスクでのこのアプローチの有効性を示します。ImageNet分類とセマンティックセグメンテーションCityscapesデータセットからの高解像度画像。 
[ABSTRACT] mdeqは、複数の機能解像度のポイントを同時に解決して逆伝播できるmdeqです。mdeqはインジェクションを使用して、$ o（1）$メモリ消費のみを必要とする中間状態の保存を回避します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
</section>
<!-- paper0: Self-adapting confidence estimation for stereo -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_67.html">
      <font color="black">Self-adapting confidence estimation for stereo</font>
    </a>
  </h2>
  <font color="black">この戦略により、非公開のステレオ知覚方法を備えた民生用および産業用デバイスを含むあらゆるステレオシステムとのシームレスな統合だけでなく、その自己適応機能により、フィールドでのすぐに使用可能な展開が可能になります。 ..さまざまな標準データセットを使用した徹底的な実験結果は、私たちの主張を裏付けており、私たちのソリューションが、ステレオシステムの正確な信頼性推定のオンライン学習をエンドユーザーに要求することなく初めて可能にする方法を示しています。最近、多くのコンピュータビジョンタスクに広がっており、信頼性推定の分野ではほとんど考慮されていません。 
[ABSTRACT]自己ステレオ学習は最近多くのコンピュータービジョンタスクに広がっていますが、信頼推定の分野ではほとんど考慮されていません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-14">
        <br><font color="black">2020-08-14</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Many-to-Many Image-to-Image Translation Across Multiple
  Domains -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_68.html">
      <font color="black">Unsupervised Many-to-Many Image-to-Image Translation Across Multiple
  Domains</font>
    </a>
  </h2>
  <font color="black">教師なしマルチドメイン画像から画像への変換は、ラベル付けされたデータなしで複数のドメイン間で画像を合成することを目的としています。これは、1対1の画像マッピングよりも一般的で複雑です。この方法には2つの重要な側面があります。ドメインでは、それらの翻訳結果が期待されないか、モデルが崩壊することさえあります。 
[概要] 2種類の教師なしマルチドメイン画像から画像への変換が提案されています。これらは、画像を効果的かつ同時に変換するための、1つのドメインのみを備えた多対多アーキテクチャの共有エンコーダです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-28">
        <br><font color="black">2019-11-28</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Stage CNN-Based Monocular 3D Vehicle Localization and Orientation
  Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_69.html">
      <font color="black">Multi-Stage CNN-Based Monocular 3D Vehicle Localization and Orientation
  Estimation</font>
    </a>
  </h2>
  <font color="black">モデルは最初に鳥瞰図の標高マップを作成してシーン内のオブジェクトの深さを推定し、それを使用してオブジェクトの3D境界ボックスを推定します。構文データセットとKIITIの2つの主要なデータセットでトレーニングと評価を行いました。データセット..提案されたモデルには、バックエンドネットワークとして事前にトレーニングされたResNet-50ネットワークと、さらに3つのブランチがあります。 
[概要]提案されたモデルには、バーズアイと呼ばれる事前トレーニング済みのモデルがあります。2つの主要なデータセットに基づいて構築できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Refining Semantic Segmentation with Superpixel by Transparent
  Initialization and Sparse Encoder -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_70.html">
      <font color="black">Refining Semantic Segmentation with Superpixel by Transparent
  Initialization and Sparse Encoder</font>
    </a>
  </h2>
  <font color="black">スパース行列演算を備えたスパースエンコーダは、メモリ要件と計算の複雑さの両方を大幅に削減します。一方、各スーパーピクセルの一貫したピクセルラベルは、ロジットの一貫性によって保証されます。深い学習はセマンティックセグメンテーションのパフォーマンスを大幅に向上させますが、その成功は主に正確なエッジのないオブジェクトの中央領域。 
[ABSTRACT] tiは、事前トレーニングされたネットワークの学習パラメータの効果を保持することを提案しています。スーパーピクセルは、オブジェクトエッジを保持するための一般的で効果的な補助です。ただし、各スーパーピクセルの学習ピクセルラベルは、ロジットの一貫性によって保証されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-09">
        <br><font color="black">2020-10-09</font>
      </time>
    </span>
</section>
<!-- paper0: Active Deep Densely Connected Convolutional Network for Hyperspectral
  Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_71.html">
      <font color="black">Active Deep Densely Connected Convolutional Network for Hyperspectral
  Image Classification</font>
    </a>
  </h2>
  <font color="black">次に、追加のネットワークを使用して、ラベルのないサンプルを提案し、深く密に接続された畳み込みネットワークが間違ったラベルを生成する可能性が高いことを示唆します。分類精度..したがって、提案された方法はエンドツーエンドのフレームワークです。 
[概要]ディープラーニングはハイパースペクトル画像分類コストにリンクされていますが、ディープラーニングの成功は多数のラベル付きサンプルに起因しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: A Tunable Robust Pruning Framework Through Dynamic Network Rewiring of
  DNNs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_72.html">
      <font color="black">A Tunable Robust Pruning Framework Through Dynamic Network Rewiring of
  DNNs</font>
    </a>
  </h2>
  <font color="black">DNRのメリットを評価するために、CIFAR-10、CIFAR-100ではVGG16とResNet-18、Tiny-ImageNetではVGG16の2つの広く受け入れられているモデルを使用して実験を行いました。さらに、実験ではDNRが一貫して示されています。最先端の代替手段で達成できるものよりもクリーンで敵対的な画像分類パフォーマンスが優れた圧縮モデルを見つけます。ベースラインの非圧縮モデルと比較して、DNRはすべてのデータセットで20倍を超える圧縮を提供し、クリーンまたは敵対的なものを大幅に低下させることはありません。分類精度。 
[概要]提案されたdnrメソッドは、超高モデル圧縮と堅牢な敵対的トレーニングをマージするハイブリッド損失関数を組み合わせます。dnrは、クリーンまたは敵対的分類の精度を大幅に低下させることなく、すべてのデータセットで20倍を超える圧縮を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: How Trustworthy are the Existing Performance Evaluations for Basic
  Vision Tasks? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_73.html">
      <font color="black">How Trustworthy are the Existing Performance Evaluations for Basic
  Vision Tasks?</font>
    </a>
  </h2>
  <font color="black">現在の基準によるアルゴリズムのランキングは、パラメータの選択によって変動します。この作業は、基準の信頼性の概念を提唱します。これには、（i）信頼性のパラメーターに対する堅牢性、（ii）健全性テストにおけるコンテキストの意味、および（iii）メトリックプロパティなどの数学的要件との整合性が必要です。代替基準についても検討します。形状のセットのメトリックを使用し、これらの要件に対してそれらを評価して、信頼できる基準を見つけます。 
[要約]特定の特定の基準の評価を信頼できるかどうかを検証する手段すらありません。例は、信頼性が基準の標準標準ではないことを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-08">
        <br><font color="black">2020-08-08</font>
      </time>
    </span>
</section>
<!-- paper0: Infrared small target detection based on isotropic constraint under
  complex background -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_74.html">
      <font color="black">Infrared small target detection based on isotropic constraint under
  complex background</font>
    </a>
  </h2>
  <font color="black">実験は、提案された方法が信号対クラッター比ゲイン（SCRG）および受信者動作特性（ROC）曲線の点でいくつかの一般的な方法よりも効果的で優れていることを示しています。最初に疑わしい領域がMGDを介して取得され、次に元の画像のヘッセ行列の固有値を計算して、各領域の等方性パラメーターを取得します。複雑な背景の下での小さなターゲットの検出は、システムアルゴリズムの開発において非常に困難な作業です。 
[ABSTRACT]小さなターゲットは、高コントラストと等方性の2つの特性を持つと見なされます。これらの領域の領域は等方性制約条件を満たしていません。これらの領域は同じ条件を満たしていないため抑制されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Fair Knowledge Transfer for Imbalanced Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_75.html">
      <font color="black">Towards Fair Knowledge Transfer for Imbalanced Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">このような3つの戦略は、公平性の問題とドメインシフトの課題に対処するために、統一されたフレームワークに定式化されます。ベンチマークは、既存の最先端のDAモデルと比較することにより、提案されたモデルの有効性を検証しました。特に、全体的な精度に関して、2つのベンチマークでモデルが20％以上大幅に向上しています。 
[概要]既存のdaアルゴリズムは、主にドメインの調整による実践的な知識の伝達に焦点を当てています。代わりに、セットアップにおける公平性の課題に対処することを目的としています。これらには、二重の異なる分類子とドメイン間の問題の問題が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-23">
        <br><font color="black">2020-10-23</font>
      </time>
    </span>
</section>
<!-- paper0: Task-agnostic Unsupervised Out-of-Distribution Detection Using Kernel
  Density Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_76.html">
      <font color="black">Task-agnostic Unsupervised Out-of-Distribution Detection Using Kernel
  Density Estimation</font>
    </a>
  </h2>
  <font color="black">分類を超えて一般的に適用可能な方法を試みても、同様のパフォーマンスは得られませんでした。テスト時に、テストサンプルのpdfを評価し、結果のチャネルごとのスコアをロジスティック回帰と組み合わせて、サンプルがOODであることを示す最終的な信頼スコアを作成します。 。特徴マップへのKDEの直接適用は、それらの高次元性によって妨げられるため、単一の高次元モデルではなく、チャネルごとに周辺化されたKDEモデルのセットを使用します。 
[概要]提案された方法は、クラスラベルに関する情報の不足に基づいています。ただし、分類タスクに限定されています。分類ネットワークのツールとして使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br><font color="black">2020-06-18</font>
      </time>
    </span>
</section>
<!-- paper0: Dissecting Image Crops -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_77.html">
      <font color="black">Dissecting Image Crops</font>
    </a>
  </h2>
  <font color="black">コードはhttps://github.com/basilevh/dissecting-image-cropsで入手できます。私たちの目的は空間作物の基本的な影響を分析することですが、画像の検出など、私たちの作業には多くの実際的な影響もあります。操作とニューラルネットワークの研究者にショートカット学習のより良い理解を提供します。写真家はまた、画像の美学とシーンの構成に関連する他の手がかりを残します。 
[概要]画像はロンドンの写真家バシロフによって撮影されました。彼らは現在、空間作物の基本的な影響を分析しようとしています。しかし、私たちの仕事には多くの実際的な影響もあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: No-reference Screen Content Image Quality Assessment with Unsupervised
  Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_78.html">
      <font color="black">No-reference Screen Content Image Quality Assessment with Unsupervised
  Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">特に、ランク付けの特徴空間を段階的に補完的かつ明示的に正規化する3種類の損失を紹介します。一般に、品質予測モデルをNIから新しい種類のコンテンツに直接転送することは簡単な作業ではありません。劇的に異なる統計的特性を保持する（すなわち、SCI）。特徴識別能力の強化に関して、分類器を修正し、ソースドメイン（NI）だけでなくターゲットドメイン（SCI）の予測能力を改善するためのセンターベースの損失を提案します。 。 
[概要]自然画像の豊富な主観的評価を活用したscis.itの参照品質評価方法に基づかない最初の教師なしドメイン適応（nis）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Constraint Based Refinement of Optical Flow -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_79.html">
      <font color="black">Constraint Based Refinement of Optical Flow</font>
    </a>
  </h2>
  <font color="black">分離されたシステムの半群の理論を使用して、私たちのプロセスが発散と渦度の空間特性を保持することを示します。さらに、私たちのシステムの特別な特徴は、コーシー・リーマン演算子による対角化とそれを変換する可能性です。カールと流れの発散の拡散過程に..連続性モデルへのこの近さは、修正された拡張ラグランジュ法によって理論的に正当化され、数値的に検証されます。 
[概要]システムは、2次正則化による最小化問題として開発されました。2次正則化による最小化問題として設計されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Imperceptible Universal Attacks on Texture Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_80.html">
      <font color="black">Towards Imperceptible Universal Attacks on Texture Recognition</font>
    </a>
  </h2>
  <font color="black">人間の知覚は局所的な視覚周波数特性の影響を受けるという事実に基づいて、周波数領域で普遍的な摂動を計算するための周波数調整された普遍的な攻撃方法を提案します。ディープニューラルネットワーク（DNN）は画像の影響を受けやすいことが示されていますが-自然な画像分類問題に対する無関心な敵対的攻撃、DNNベースのテクスチャ認識に対するそのような攻撃の影響はまだ調査されていません。また、私たちのアプローチが防御モデルに対する攻撃の堅牢性とデータセット間の転送可能性を改善できることも示しています。テクスチャ認識の問題。 
[概要]提案された方法は、まだ知覚できない摂動を生成する可能性があります。これは、既存のユニバーサル攻撃手法と比較されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Facial Emotion Recognition with Noisy Multi-task Annotations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_81.html">
      <font color="black">Facial Emotion Recognition with Noisy Multi-task Annotations</font>
    </a>
  </h2>
  <font color="black">コードはhttps://github.com/sanweiliti/noisyFERで入手できます。私たちの定式化では、新しい方法を利用して、統一された敵対的学習ゲームで感情予測と同時分布学習を可能にします。広範な実験研究全体での評価提案された新しい問題の実際の設定、およびCIFAR-10とラベル付けされた合成ノイズまたはRAFとAffectNetとラベル付けされた実用的なノイズマルチタスクのいずれかでの最先端の競合メソッドに対する提案されたメソッドの明らかな優位性。 
[概要]人間の顔認識モデルはしばしば非常にノイズが多い。顔の表情の注釈はしばしばノイズが多い。新しい方法はタスクを使用してより信頼性の高い相関関係を学習する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-19">
        <br><font color="black">2020-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: Blind deblurring for microscopic pathology images using deep learning
  networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_82.html">
      <font color="black">Blind deblurring for microscopic pathology images using deep learning
  networks</font>
    </a>
  </h2>
  <font color="black">この論文では、顕微鏡画像の焦点ぼけとモーションブラーを軽減し、ブラーの種類、ブラーの程度、病理学的な汚れを事前に知らなくても、詳細を取得してより鮮明でクリーンな画像を出力できるディープラーニングベースのアプローチを示します。次に、2つのエンコーダ-デコーダネットワークがトレーニングされ、単独で、または組み合わせて使用されて、入力画像のブレが除去されます。このアプローチでは、最初に深層学習分類器がトレーニングされ、画像のぼけタイプが識別されます。 
[概要]このアプローチでは、最初にディープブラー分類器をトレーニングして画像のブラータイプを識別します。これはエンドツーエンドのアプローチであり、従来のブラインドデコンボリューション法のように波形のアーティファクトを導入しません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Discovery of DisentangledManifolds in GANs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_83.html">
      <font color="black">Unsupervised Discovery of DisentangledManifolds in GANs</font>
    </a>
  </h2>
  <font color="black">発見された方向ベクトルは、さまざまな異なる属性に視覚的に対応しているため、属性の編集が可能です。提案されたフレームワークの有効性を幅広いデータセットで示します。さらに、重心損失関数を適用して一貫性と滑らかさを向上させます。さまざまな方向を横断しながら。 
[概要]以前のものから変換を学ぶことを提案します。幅広いデータセットを通じて提案されたフレームワークの有効性を実証しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: SEA: Sentence Encoder Assembly for Video Retrieval by Textual Queries -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_84.html">
      <font color="black">SEA: Sentence Encoder Assembly for Video Retrieval by Textual Queries</font>
    </a>
  </h2>
  <font color="black">AVSの成功は、クエリ文とビデオの両方を意味的類似性計算のための共通スペースにエンコードするクロスモーダル表現学習に依存しています。これにより、SEAはAVSにとって魅力的なソリューションとなり、新しい文エンコーダーを収集することでタスクを継続的に進めることができます。さらに、SEAは非常に簡単に実装できます。 
[概要]既知のavsの成功は、クロスモーダル表現学習に依存します。検索文とビデオの両方を意味的類似性のために共通のスペースにエンコードします。この方法は、エンコーダーアセンブリと呼ばれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Boundary-sensitive Pre-training for Temporal Localization in Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_85.html">
      <font color="black">Boundary-sensitive Pre-training for Temporal Localization in Videos</font>
    </a>
  </h2>
  <font color="black">合成された境界を使用すると、境界タイプを分類することでBSPを簡単に実行できます。広範な実験により、提案されたBSPは、既存のアクション分類ベースの事前トレーニングの対応物よりも優れており、補完的であり、新しい最先端のパフォーマンスを実現します。いくつかの時間的ローカリゼーションタスクについて..この論文では、初めて、新しい境界に敏感な口実（BSP）タスクを導入することにより、時間的ローカリゼーションのためのモデル事前トレーニングを調査します。 
[概要]これらのタスク用に開発された既存のモデルの多くは、一般的なビデオアクション分類タスクで事前トレーニングされています。これにより、ダウンストリームのローカリゼーションタスクよりも優れたビデオ表現の学習が可能になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-21">
        <br><font color="black">2020-11-21</font>
      </time>
    </span>
</section>
<!-- paper0: UKPGAN: Unsupervised KeyPoint GANeration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_86.html">
      <font color="black">UKPGAN: Unsupervised KeyPoint GANeration</font>
    </a>
  </h2>
  <font color="black">私たちのコードはhttps://github.com/qq456cvb/UKPGANで入手できます。さらに、UKPGANは、任意のポーズ変形の下で、剛体または非剛体SMPL人体のいずれかに適用できることを示します。これに基づいて、提案します。 UKPGANは、元のオブジェクトの形状を再構築できるようにキーポイントが検出される、監視されていない3Dキーポイント検出器です。 
[ABSTRACT] ukpganは、教師なし3Dキーポイント検出器です。キーポイントは、元のオブジェクトの形状を再構築できるように検出されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Good and Bad Boundaries in Ultrasound Compounding: Preserving Anatomic
  Boundaries While Suppressing Artifacts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_87.html">
      <font color="black">Good and Bad Boundaries in Ultrasound Compounding: Preserving Anatomic
  Boundaries While Suppressing Artifacts</font>
    </a>
  </h2>
  <font color="black">結合）重複するピクセル値..この作業では、超音波のさまざまな視点から重複するピクセルを合成する新しいアルゴリズムを確立します。以前のアルゴリズムと比較してアルゴリズムを評価し、アプローチが保存するだけではないことを示します。明るい部分と暗い部分の両方の詳細ですが、アーティファクトを増幅するのではなく、いくらか抑制します。 
[ABSTRACT]超音波画像はプローブの方向と音波が通過する経路に依存するため、複合化のための単一の理想的な表現はありません。現在の一般的な方法は、必然的に有用な領域を抑制または完全に除外し、新しいアーティファクトを導入する可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: SXL: Spatially explicit learning of geographic processes with auxiliary
  tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_88.html">
      <font color="black">SXL: Spatially explicit learning of geographic processes with auxiliary
  tasks</font>
    </a>
  </h2>
  <font color="black">さらに、Moran&#39;s Iを複数の解像度に拡張して、さまざまな空間粒度およびさまざまな距離スケールで効果をキャプチャすることを提案します。Moran&#39;s I埋め込みは、任意の空間、数値入力に対して簡単に構築でき、このアプローチは任意のネットワークアーキテクチャで使用できます。 、私たちの実験で示されているように、一貫してパフォーマンスを向上させます。生成モデリングタスクと予測モデリングタスクの両方で実世界の地理空間データを使用した実験を使用して、ニューラルネットワークをトレーニングするこの方法の優位性を示します。 
[概要]ローカルモランのsiをトレーニングプロセスに組み込み、モデルを「ナッジ」して、ローカル自己回帰効果の方向と大きさを学習します。実世界の地理空間データを使用した実験を使用してニューラルネットワークをトレーニングするこの方法の利点を示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br><font color="black">2020-06-18</font>
      </time>
    </span>
</section>
<!-- paper0: GIRAFFE: Representing Scenes as Compositional Generative Neural Feature
  Fields -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_89.html">
      <font color="black">GIRAFFE: Representing Scenes as Compositional Generative Neural Feature
  Fields</font>
    </a>
  </h2>
  <font color="black">シーンを構成生成ニューラル機能フィールドとして表すと、追加の監視なしで、構造化されていない画像コレクションとポーズのない画像コレクションから学習しながら、背景から1つまたは複数のオブジェクト、および個々のオブジェクトの形状と外観を解きほぐすことができます。生成モデルへの3Dシーン表現は、より制御可能な画像合成につながります。さらに、シーンの構成的性質を考慮している作品はごくわずかです。 
[ABSTRACT]モデルを使用すると、非構造化およびポーズなしの画像コレクションから学習しながら、1つまたは複数のオブジェクトを背景から解きほぐし、個々のオブジェクトの形状や外観を解きほぐすことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Ultrasound Confidence Maps of Intensity and Structure Based on Directed
  Acyclic Graphs and Artifact Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_90.html">
      <font color="black">Ultrasound Confidence Maps of Intensity and Structure Based on Directed
  Acyclic Graphs and Artifact Models</font>
    </a>
  </h2>
  <font color="black">超音波イメージングは改善されていますが、減衰、シャドウイング、回折、スペックルなど、モデル化が難しい固有のアーティファクトに悩まされ続けています。当社の新しい信頼性アルゴリズムは、の音響物理特性に基づく有向非周期グラフを使用してピクセル値を分析します。超音波イメージング..私たちは、私たちのアプローチのユニークな機能を実証し、それをシャドウ検出および画像合成タスクのための以前の信頼性測定アルゴリズムと比較します。 
[概要]これらのアーティファクトは、画像分析手法を混乱させる可能性があります。これらは、影-検出および画像-複合タスクの測定アルゴリズムにおける以前の信頼度と比較されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Revisiting Pixel-Wise Supervision for Face Anti-Spoofing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_91.html">
      <font color="black">Revisiting Pixel-Wise Supervision for Face Anti-Spoofing</font>
    </a>
  </h2>
  <font color="black">最近、FASタスクに対してピクセル単位の監視が提案され、よりきめ細かいピクセル/パッチレベルの手がかりを提供することを目的としています。5つのFASベンチマークデータセットで広範な実験が行われ、ベルやホイッスルなしで、提案されたピラミッドが示されています。監視は、既存のピクセル単位の監視フレームワークを超えてパフォーマンスを向上させるだけでなく、モデルの解釈可能性を向上させることもできます（つまり、PAのパッチレベルの位置をより合理的に特定する）。顔のなりすまし防止（FAS）は、セキュリティ保護において重要な役割を果たします。プレゼンテーション攻撃（PA）からの顔認識システム。 
[概要]たとえば、未知の攻撃を検出するための堅牢なアルゴリズムを開発する必要があります。これらには、マルチスケールの空間コンテキストからローカルの詳細とグローバルな意味の両方を学習するために深いモデルをガイドする新しいピラミッド監視が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Features Guidance Network for partial-to-partial point cloud
  registration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_92.html">
      <font color="black">Multi-Features Guidance Network for partial-to-partial point cloud
  registration</font>
    </a>
  </h2>
  <font color="black">実験結果は、計算効率を維持しながら、ネットワークが現在の最先端技術を上回っていることを示しています。対応信頼性計算モジュールでは、特徴一致行列と座標一致行列の間の矛盾する関係に基づいて、各対応は、不一致または不一致のポイントの影響を減らすことができます。前の作業とは異なり、形状の特徴と空間座標を利用して、対応検索を個別にガイドし、一致結果を融合して最終的な一致行列を取得します。 
[ABSTRACT]提案されたネットワークには、キーポイントの特徴抽出、対応検索、およびsvdの4つの部分が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Structure-Aware Completion of Photogrammetric Meshes in Urban Road
  Environment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_93.html">
      <font color="black">Structure-Aware Completion of Photogrammetric Meshes in Urban Road
  Environment</font>
    </a>
  </h2>
  <font color="black">車両領域は、標準的な物体検出アプローチによってマスクされます。実験的評価と分析は、異なるセンサーと地上サンプル距離でキャプチャされた3つのデータセットに対して実行されます。データセットとコードはvrlab.org.cn/~hanhu/projects/meshで入手できます。 
[ABSTRACT]写真測量メッシュにも深刻なテクスチャの問題があります。提案された方法は、車両を取り外した後、非常にリアルなメッシュを作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: CAFE-GAN: Arbitrary Face Attribute Editing with Complementary Attention
  Feature -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_94.html">
      <font color="black">CAFE-GAN: Arbitrary Face Attribute Editing with Complementary Attention
  Feature</font>
    </a>
  </h2>
  <font color="black">Generative Adversarial Network（GAN）を使用した顔属性編集に焦点を当てたマルチドメイン転送問題のいくつかの作業があります。さらに、属性の空間情報を利用するためのジェネレータのトレーニングに役立つ補完的な機能マッチングを紹介します。CAFE変換する顔の領域を、ターゲット属性と補完的な属性の両方を考慮して識別します。これらの属性は、入力された顔画像に存在しないものとして定義されます。 
[概要]プロジェクトは、特徴的なドメインと見なされる一連の属性の問題に基づいています。これらの作品はいくつかの成功を報告していますが、顔の領域に意図しない変更をもたらします-つまり、ジェネレータは指定された属性に関係のない領域を変更します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: GMOT-40: A Benchmark for Generic Multiple Object Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_95.html">
      <font color="black">GMOT-40: A Benchmark for Generic Multiple Object Tracking</font>
    </a>
  </h2>
  <font color="black">最初に、GMOT-40と名付けられた最初の公開GMOTデータセットを構築します。これには、10のオブジェクトカテゴリに均等に分散された40の注意深く注釈が付けられたシーケンスが含まれます。さらに、追跡アルゴリズムのさまざまな特性を評価するために2つの追跡プロトコルが採用されています。ターゲットに関する事前情報をほとんど必要としないMultipleObject Tracking（GMOT）は、ほとんど調査されていません。 
[概要]この論文では、3つの側面でgmotの研究を後押しするために貢献します。最初に、motアルゴリズムと提案されたベースラインを含むgmot-40の徹底的な評価を行います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Canonical Voting: Towards Robust Oriented Bounding Box Detection in 3D
  Scenes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_96.html">
      <font color="black">Canonical Voting: Towards Robust Oriented Bounding Box Detection in 3D
  Scenes</font>
    </a>
  </h2>
  <font color="black">回転分類が根本的に難しいため、オフセットと方向の予測はどちらも正確ではありません。ボックスの方向は正規の投票スキームによって生成されますが、LCCとボックスのスケールのみが回帰されます。この作業では、直接オフセットをローカルカノニカルに解きほぐします。座標（LCC）、ボックススケール、およびボックスの向き。 
[ABSTRACT]現在の最先端の方法を使用して直接オフセットを回帰しました。作業では、直接オフセットをローカルの聖書座標に解きほぐします。lcc-認識バック-投影チェックアルゴリズムが境界ボックスを切り取ります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Discovering Hidden Physics Behind Transport Dynamics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CV/paper_97.html">
      <font color="black">Discovering Hidden Physics Behind Transport Dynamics</font>
    </a>
  </h2>
  <font color="black">移流拡散モデルを組み込んだ2Dと3Dの画像時系列間のオートエンコーダ構造に基づく学習フレームワーク（YETI）を提案します。識別可能性を支援するために、事前トレーニングを可能にする移流拡散シミュレータを開発します。速度および拡散テンソル場を使用した監視学習によるモデルの解析..輸送プロセスは遍在しています。 
[概要]私たちの目標は、移流の基礎となる物理学を推定することです-ジェラード方程式。移流-ジェラード方程式、「速度と耐性」フィールドとして表されます。これには、脳卒中患者を特定する方法の学習が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Whole-Word Segmental Speech Recognition with Acoustic Word Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_0.html">
      <font color="black">Whole-Word Segmental Speech Recognition with Acoustic Word Embeddings</font>
    </a>
  </h2>
  <font color="black">セグメントモデルは、仮説のスコアがフレームの可変長セグメント全体に基づくシーケンス予測モデルです。パスの数は語彙サイズに比例するため、このようなモデルは計算が困難です。これは、使用する場合よりも桁違いに大きくなる可能性があります。電話のようなサブワードユニット..私たちの最終モデルは、以前のA2Wモデルよりも改善されています。 
[概要]特徴サイズのモデルは、セグメントの埋め込みを使用してマッピングされます。これらのモデルは、セグメントモデルの埋め込みに基づいています。さらに、音響セグメント表現を畏敬の念を持って事前トレーニングします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-01">
        <br><font color="black">2020-07-01</font>
      </time>
    </span>
</section>
<!-- paper0: Fuzzy Stochastic Timed Petri Nets for Causal properties representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_1.html">
      <font color="black">Fuzzy Stochastic Timed Petri Nets for Causal properties representation</font>
    </a>
  </h2>
  <font color="black">因果関係は、優先順位（原因が効果に先行する）、並行性（多くの場合、効果が2つ以上の原因によって同時に引き起こされる）、循環性（原因が効果を引き起こし、効果が原因を強化する）、および不正確さ（原因の存在は効果に有利に働きますが、必ずしもそれを引き起こすわけではありません）。因果シナリオをグラフィカルに表現するために使用される一般的な方法は、ニューロン、真理値表、因果ベイジアンネットワーク、認知地図、およびペトリネットです。グラフィカルモデルは、前述のプロパティの一部を個別に表すことができますが、それらすべてを不明瞭に説明しようとはしません。 
[概要]調査によると、オブジェクト間の接続が最も強力なツールです。これらには、オブジェクト間のリンクを表す画像が含まれます。また、時間、共起、ループ、不正確さを表すファジー確率ペトリネットも紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Dual Supervision Framework for Relation Extraction with Distant
  Supervision and Human Annotation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_2.html">
      <font color="black">Dual Supervision Framework for Relation Extraction with Distant
  Supervision and Human Annotation</font>
    </a>
  </h2>
  <font color="black">さらに、追加のネットワークを活用して、コンテキスト情報を考慮してラベリングバイアスを適応的に評価します。2つの別々の予測ネットワークHA-NetとDS-Netを使用して、人間の注釈と遠隔監視によってそれぞれラベルを予測し、遠隔監視の誤ったラベル付けによる精度..関係抽出（RE）は、知識ベースの構築や質問への回答などの実際のアプリケーションで重要であるため、広く研究されてきました。 
[ABSTRACT] reは、2種類のデータを使用して、reモデルをトレーニングし、精度を向上させます。ただし、2つのデータを組み合わせるだけでは、監視が低下する可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: GLGE: A New General Language Generation Evaluation Benchmark -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_3.html">
      <font color="black">GLGE: A New General Language Generation Evaluation Benchmark</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、8つの言語生成タスクにわたるNLGモデルの一般化機能を評価するための新しいマルチタスクベンチマークであるGeneral Language Generation Evaluation（GLGE）を紹介します。これにより、モデルのパフォーマンスを包括的に比較するための24のサブタスクが導入されます。 、タスクの難易度の観点から3つのサブタスク（GLGE-Easy、GLGE-Medium、およびGLGE-Hard）を引き続き設計します。 
[概要]ベンチマークは、新しい自然言語生成（nlg）モデルを考慮せずに、主にさまざまな自然言語理解タスクに焦点を当てています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Text Classification by Jointly Learning to Cluster and Align -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_4.html">
      <font color="black">Neural Text Classification by Jointly Learning to Cluster and Align</font>
    </a>
  </h2>
  <font color="black">提案された方法は、単語クラスタリングの重心とクラスタリングトークンの配置を共同で学習し、複数のベンチマークデータセットで最先端の結果を達成し、提案されたクラスタートークンの配置メカニズムがテキスト分類に実際に有利であることを証明します。分散テキストクラスタリングは、意味的に有益な表現を提供します。そして、各単語とセマンティッククラスタリング重心の間の関連性をキャプチャします。特に、私たちの定性分析は、提案されたモデルによって学習されたテキスト表現が私たちの直感とよく一致していることを顕著に示しています。 
[ABSTRACT]ライター：ニューラルテキストクラスタリングアプローチをテキスト分類タスクに拡張します。提案されたモデルによって学習されたテキスト表現は、私たちの直感とよく一致していると彼らは言います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: A Pattern-mining Driven Study on Differences of Newspapers in Expressing
  Temporal Information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_5.html">
      <font color="black">A Pattern-mining Driven Study on Differences of Newspapers in Expressing
  Temporal Information</font>
    </a>
  </h2>
  <font color="black">TKSアルゴリズムは、シーケンスからスキップグラムパターンをマイニングするために使用されます。これらのパターンを使用して、4つの新聞の署名が取得されます。署名が新聞を一意に特徴付けるようにするために、参照パターンを削除して署名を修正します。 
[概要]調査によると、新聞は情報の表現方法が異なります。署名と改訂された署名のパターンの数が削除されます。これには、さまざまな種類の情報タグが含まれます。このデータは、パターンの量を分析するために使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Unequal Representations: Analyzing Intersectional Biases in Word
  Embeddings Using Representational Similarity Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_6.html">
      <font color="black">Unequal Representations: Analyzing Intersectional Biases in Word
  Embeddings Using Representational Similarity Analysis</font>
    </a>
  </h2>
  <font color="black">これらの埋め込みは、黒人女性を白人女性よりも女性らしくなく、黒人男性よりも黒人ではないことを示しています。この発見は、複数のアイデンティティカテゴリ（人種や性別など）が互いに重なっていると主張する交差性理論と一致しています。個々のカテゴリーで共有されない独自の差別モードを作成するために。具体的には、黒人女性に対する交差バイアスの証拠について、文脈化された埋め込みと文脈化されていない埋め込みを調査します。 
[要約]私たちは、黒人女性に対する偏見の証拠について埋め込みを調査します。この発見は、複数のアイデンティティカテゴリが互いに重なり合っていると主張する交差性理論と一致しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Domain-Transferable Method for Named Entity Recognition Task -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_7.html">
      <font color="black">Domain-Transferable Method for Named Entity Recognition Task</font>
    </a>
  </h2>
  <font color="black">固有表現抽出（NER）は、自然言語処理と情報抽出の分野における基本的なタスクです。NERは、スタンドアロンツールとして、または質問応答、ダイアログアシスタント、ナレッジグラフなどのさまざまなアプリケーションの必須コンポーネントとして広く使用されています。開発..人間の努力なしに監督が得られ、神経モデルが互いに学ぶことができると仮定します。 
[ABSTRACT] nerは、質問応答やダイアログアシスタントなど、さまざまなアプリケーションのツールまたは必須コンポーネントとして広く使用されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Tight Integrated End-to-End Training for Cascaded Speech Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_8.html">
      <font color="black">Tight Integrated End-to-End Training for Cascaded Speech Translation</font>
    </a>
  </h2>
  <font color="black">この作業では、学習したパラメーターを無視せずに、ASRモデルとMTモデルのすべてのパラメーターを一緒に最適化することにより、カスケードコンポーネント全体を単一のエンドツーエンドのトレーニング可能なモデルに折りたたむ可能性を探ります。これは、再正規化されたソースワードを事後確率で渡す緊密に統合された方法です。ワンホットベクトルの代わりにソフト決定として分布し、バックプロパゲーションを可能にします。中間表現を使用し、エンドツーエンドのトレーニング可能性を維持するために、以前の研究では、認識器の非表示ベクトルをに渡すことにより、2段階モデルを使用することを提案しました。 MTモデルのデコーダーであり、MTエンコーダーを無視します。 
[要約]モデルは、ブルーで最大1.8％、ターで2.0％までカスケードモデルよりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: An Online Multilingual Hate speech Recognition System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_9.html">
      <font color="black">An Online Multilingual Hate speech Recognition System</font>
    </a>
  </h2>
  <font color="black">この調査では、公開されている6つのデータセットを1つの同種のデータセットに組み合わせて分析し、虐待的、憎悪的、またはどちらでもない3つのクラスに分類します。過去20年間で、インターネットとソーシャルメディアの使用が指数関数的に増加しました。人間の相互作用の変化..ベースラインモデルを作成し、さまざまな最適化手法を使用してモデルのパフォーマンススコアを向上させます。 
[概要]これは多くの肯定的な結果をもたらしましたが、同時にリスクと害をもたらしました。これらは、憎悪やどちらでもないなどの人間の行動の例です。私たちは、効果的な指標でページを識別してスコアリングするツールを作成します。ほぼリアルタイム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: A Hierarchical Multi-Modal Encoder for Moment Localization in Video
  Corpus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_10.html">
      <font color="black">A Hierarchical Multi-Modal Encoder for Moment Localization in Video
  Corpus</font>
    </a>
  </h2>
  <font color="black">顕著な課題は、ビデオの表現が時間領域のさまざまなレベルの粒度を説明する必要があることです。この問題に取り組むために、両方の粗いクリップでビデオをエンコードするHierArchical Multi-Modal EncodeR（HAMMER）を提案します。レベルときめ細かいフレームレベルにより、複数のサブタスク、つまり、ビデオ検索、セグメント時間ローカリゼーション、マスクされた言語モデリングに基づいてさまざまなスケールで情報を抽出します。ActivityNetのビデオコーパスでモーメントローカリゼーションに関するモデルを評価するために、広範な実験を実施します。キャプションとTVRデータセット。 
[ABSTRACT] gran granは、グラニュラービデオエンコーダー（ハンマー）の発案によるものです。これは、細粒度のクリップレベルと細粒度のフレームレベルの両方でビデオをエンコードします。これは、ビデオの取得とその後の検索を含む複数のサブタスクに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-18">
        <br><font color="black">2020-11-18</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Empathetic Dialogue Generation over Multi-type Knowledge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_11.html">
      <font color="black">Towards Empathetic Dialogue Generation over Multi-type Knowledge</font>
    </a>
  </h2>
  <font color="black">共感能力を備えたマシンが文脈一貫性のある応答を提供できるようにすることは、意味レベルと感情レベルの両方で重要です。まず、2つのタイプの知識と共同で対話することによって対話履歴を充実させ、感情的なコンテキストグラフを作成します。知識を意識したコンテキストエンコーダーを入力して、感情的なコンテキスト表現を学習し、感情的な信号を抽出します。これは、応答で表現される感情を予測するための前提条件です。 
[要約]この問題に対処するために、共感的な対話生成のタスクが提案されています。マルチタイプの知識を活用することを提案します。 e、常識知識と感情レキシコン、感情を明示的に理解して表現します。感情を予測するための前提条件である、感情的なコンテキスト表現を学習し、感情的な信号を抽出するためのマルチタイプの知識認識コンテキストエンコーダを導入します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-21">
        <br><font color="black">2020-09-21</font>
      </time>
    </span>
</section>
<!-- paper0: Do Language Embeddings Capture Scales? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_12.html">
      <font color="black">Do Language Embeddings Capture Scales?</font>
    </a>
  </h2>
  <font color="black">事前トレーニングと計算におけるコンテキスト情報を、パフォーマンスに影響を与える2つの重要な要因として特定し、数値を正規化する簡単な方法が結果に大きな影響を与える可能性があることを示します。このコンテキストでまだ研究されていない知識の1つの形式は次のとおりです。オブジェクトのスカラーの大きさに関する情報..事前トレーニング済み言語モデル（LM）は、重要な言語、常識、および事実に関する知識を持っていることが示されています。 
[概要]事前トレーニングと計算能力を2つの重要な要素として特定します。数値をバインドする簡単な方法は、結果に大きな影響を与える可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-11">
        <br><font color="black">2020-10-11</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-lingual Emotion Intensity Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_13.html">
      <font color="black">Cross-lingual Emotion Intensity Prediction</font>
    </a>
  </h2>
  <font color="black">結果は、このデータでは、並列データの要件が低い方法が、より多くの並列データを使用する方法よりも驚くほど優れていることを示しています。これは、詳細なエラー分析を通じて説明します。たとえば、マシン変換など、6つの言語間アプローチを比較します。数百万の並列文から完全に監視されていないものまで、並列データの要件が異なるさまざまな言語間の埋め込み。このトピックに関するこれまでのほとんどの作業は英語のテキストに集中していましたが、他の言語もきめ細かい感情分類の恩恵を受けます。できれば、新しい言語ごとに英語で利用可能な注釈付きデータの量を再作成する必要はありません。 
[要約]結果は、このデータでは、並列データの要件が低い回線は、より多くの並列データを使用する方法よりも驚くほど優れたパフォーマンスを発揮することを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br><font color="black">2020-04-08</font>
      </time>
    </span>
</section>
<!-- paper0: Acoustic span embeddings for multilingual query-by-example search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_14.html">
      <font color="black">Acoustic span embeddings for multilingual query-by-example search</font>
    </a>
  </h2>
  <font color="black">この作業では、AWEトレーニングを単語のスパンに一般化し、音響スパン埋め込み（ASE）を生成し、複数の見えない言語で任意の長さのクエリを使用してASEをQbEに適用する方法を検討します。アクセスできる一般的に使用される設定を検討します。目に見えないテスト言語とは異なる他の言語（この場合はいくつかの低リソース言語）のラベル付きデータに..QUESST 2015 QbEタスクでのアプローチを評価し、多言語ASEベースの検索がDTWベースよりもはるかに高速であることを発見しました。このタスクで以前に公開された最高の結果を検索し、それを上回ります。 
[概要]低リソース設定またはゼロリソース設定では、qbe検索は、動的タイムワープに基づくアプローチで対処されることがよくあります。畏敬の念に基づく以前の作業ベースのqbe検索は、主に英語のデータと単一の単語のクエリに焦点を当てていました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: DiffWave: A Versatile Diffusion Model for Audio Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_15.html">
      <font color="black">DiffWave: A Versatile Diffusion Model for Audio Synthesis</font>
    </a>
  </h2>
  <font color="black">これは、データ尤度の変分限界のバリアントを最適化することによって効率的にトレーニングされます。特に、さまざまな自動および人間による評価からのオーディオ品質とサンプルの多様性の点で、困難な無条件生成タスクで自己回帰およびGANベースの波形モデルを大幅に上回ります。 .. DiffWaveは、メルスペクトログラムを条件とするニューラルボコーディング、クラス条件付き生成、無条件生成など、さまざまな波形生成タスクで忠実度の高いオーディオを生成します。 
[概要]モデルは非自己回帰であり、合成時に一定のステップ数でマルコフ連鎖を介してホワイトノイズ信号を構造化された波形に変換します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-21">
        <br><font color="black">2020-09-21</font>
      </time>
    </span>
</section>
<!-- paper0: Suicidal Ideation and Mental Disorder Detection with Attentive Relation
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_16.html">
      <font color="black">Suicidal Ideation and Mental Disorder Detection with Attentive Relation
  Networks</font>
    </a>
  </h2>
  <font color="black">メンタルヘルスは現代社会において重要な問題です。精神障害は、効果的な治療なしに自殺念慮に変わることがあります。関係モジュールには、より重要な関係機能に優先順位を付けるための注意メカニズムがさらに装備されています。ただし、自殺念慮と他の精神障害の分類は、非常に類似しているため、困難な作業です。言語の使用法と感情的な極性のパターン。 
[要約]ソーシャルコンテンツからの精神障害と自殺念慮は、効果的な社会的介入のための潜在的な方法を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br><font color="black">2020-04-16</font>
      </time>
    </span>
</section>
<!-- paper0: Two-Way Neural Machine Translation: A Proof of Concept for Bidirectional
  Translation Modeling using a Two-Dimensional Grid -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_17.html">
      <font color="black">Two-Way Neural Machine Translation: A Proof of Concept for Bidirectional
  Translation Modeling using a Two-Dimensional Grid</font>
    </a>
  </h2>
  <font color="black">2つのモデルを個別にトレーニングする代わりに、私たちのアプローチでは、単一のネットワークが共同で両方向への翻訳を学習することを推奨しています。WMT2018ドイツ語$ \ leftrightarrow $英語およびトルコ語$ \ leftrightarrow $英語翻訳タスクの実験は、提案されたモデルが可能であることを示しています。優れた翻訳品質を生み出し、研究を指揮するのに十分な可能性を秘めています。ただし、単一のモデルを使用して、ソースからターゲットへの翻訳とターゲットからソースへの翻訳の両方で、双方向の翻訳に最適な効果を得るのは簡単ではありません。 。 
[概要]研究者は、双方向翻訳のための単一のシステムを構築することを提案しました。彼らは、単一のモデルが優れた翻訳品質を生成できると言います。提案されたモデルは、優れた品質を生成でき、研究を指揮するのに十分な可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Highway Transformer: Self-Gating Enhanced Self-Attentive Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_18.html">
      <font color="black">Highway Transformer: Self-Gating Enhanced Self-Attentive Networks</font>
    </a>
  </h2>
  <font color="black">補助的なコンテンツベースのSDUゲートは、スキップされた接続を介した変調された潜在的な埋め込みの情報フローを可能にし、勾配降下アルゴリズムによる収束速度の明確なマージンをもたらします。自己注意メカニズムは、印象的な最先端（SOTA ）さまざまな場所にあるすべてのグローバルコンテキストに注意を向けることで、多頭ドット積の注目を集め、さまざまなシーケンス学習タスクを進めます。コンテキストベースのトランスフォーマーモジュールを支援するゲーティングメカニズムの役割を明らかにする可能性があります。特に浅い層のSDUゲートは、最適化プロセス中に最適ではないポイントに向かってステップするために、より速くプッシュする可能性があります。 
[概要]内部の意味上の重要性を補充するためにlstm-スタイルのゲートユニットを組み込んだゲートコンポーネント自己依存ユニット（sdu）。ゲートメカニズムはコンテキストを支援する可能性があります-主要なトランスモジュール</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-17">
        <br><font color="black">2020-04-17</font>
      </time>
    </span>
</section>
<!-- paper0: Picking BERT's Brain: Probing for Linguistic Dependencies in
  Contextualized Embeddings Using Representational Similarity Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_19.html">
      <font color="black">Picking BERT's Brain: Probing for Linguistic Dependencies in
  Contextualized Embeddings Using Representational Similarity Analysis</font>
    </a>
  </h2>
  <font color="black">これらの結果は、コンテキストのどの側面が言語の表現にエンコードされているかについての仮説を判断するアプローチの能力を示しています。すべての場合において、BERTのコンテキスト化された埋め込みは、調査中の言語依存関係を反映し、BERTはこれらの依存関係を言語的に目立たないコントロールをエンコードするよりも高度です。そのような表現によってコンテキストのどの側面がキャプチャされますか？ 
[要約]動詞の埋め込みが動詞の主語をエンコードする程度を調査します。完全な文の表現は、文の主語をエンコードします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: A Robotic Dating Coaching System Leveraging Online Communities Posts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_20.html">
      <font color="black">A Robotic Dating Coaching System Leveraging Online Communities Posts</font>
    </a>
  </h2>
  <font color="black">結果は、参加者がロボットが役立つというよりも面白いと考えながら、ロボットがデートコーチになる可能性があると考えたことを示しています。97人の参加者がロボットと会話するために参加し、30人がロボットを評価しました。対話モジュールを備えたデートコーチングロボット。 【概要】オンラインコミュニティを活用したロボットデートコーチングシステムを開発。20名の参加者が参加してロボットと会話。30名がロボットを評価</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Tackling Domain-Specific Winograd Schemas with Knowledge-Based Reasoning
  and Machine Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_21.html">
      <font color="black">Tackling Domain-Specific Winograd Schemas with Knowledge-Based Reasoning
  and Machine Learning</font>
    </a>
  </h2>
  <font color="black">機械学習手法として、トランスフォーマーからの双方向エンコーダー表現（BERT）
[Kocijan et al。、2019]を使用しました。次に、Sharmaの手法に基づく意味役割を使用した高度な知識ベースの推論手法を開発します。 
[2019] ..第三に、知識ベースの推論と機械学習を組み合わせたアンサンブル手法を提案します。これは、実験で最高のパフォーマンスを示します。 
[概要]この論文では、4つの方法でwscへの取り組みに貢献します。彼らは、知識ベースの推論と機械学習を組み合わせたアンサンブルタスクを提案し、実験で最高のパフォーマンスを示します。また、「堅牢な」精度測定を提案します。 trichelairと2018のそれを変更する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Gender bias in magazines oriented to men and women: a computational
  approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_22.html">
      <font color="black">Gender bias in magazines oriented to men and women: a computational
  approach</font>
    </a>
  </h2>
  <font color="black">また、2015年以降、フェミニズムに関連する単語、特に2018年には中絶という単語の使用が大幅に増加していることを示しています。この調査では、女性向けの雑誌と男性向けの雑誌の内容を比較します。同じ編集グループによって10年以上（2008年から2018年）制作されました。文化的製品は、個々の価値観と行動を獲得するための情報源です。 
[概要] 2012年、星占いに関連するコンテンツが増加し、時間の経過とともに開いたままの新しいギャップが生成されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Argument from Old Man's View: Assessing Social Bias in Argumentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_23.html">
      <font color="black">Argument from Old Man's View: Assessing Social Bias in Argumentation</font>
    </a>
  </h2>
  <font color="black">結果は、テストされたすべてのディベートコーパスに不均衡で偏ったデータが含まれていることを示唆しています。主にヨーロッパ系アメリカ人の名前を持つ男性を支持しています。特に、ポータル固有のコーパスで単語埋め込みモデルをトレーニングし、既存のWEATを使用してバイアスを体系的に評価します。単語の埋め込みにおけるバイアスを測定するためのメトリック..単語の同時発生分析では、バイアスの原因を調査します。 
[概要]この論文では、大規模な英語のディベートポータルにおける社会的バイアスの存在を研究します。次に、単語の共起分析を使用して、バイアスの原因を評価し、バイアスの原因を評価します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Online Versus Offline NMT Quality: An In-depth Analysis on
  English-German and German-English -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_24.html">
      <font color="black">Online Versus Offline NMT Quality: An In-depth Analysis on
  English-German and German-English</font>
    </a>
  </h2>
  <font color="black">2017）が検討されます。2018）および注意ベースのTransformer（Vaswani et al ..両方のアーキテクチャについて、英語-ドイツ語およびドイツ語-英語で慎重に設計された人間による評価を通じて、オンラインデコードの制約が翻訳品質に与える影響を調査します言語ペア。後者は特に待ち時間の制約に敏感です。
[概要]オンライン設定に移行すると、各モデルの長所と短所を特定できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br><font color="black">2020-06-01</font>
      </time>
    </span>
</section>
<!-- paper0: OpenTapioca: Lightweight Entity Linking for Wikidata -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_25.html">
      <font color="black">OpenTapioca: Lightweight Entity Linking for Wikidata</font>
    </a>
  </h2>
  <font color="black">私たちのモデルは、トレーニング、実行、ウィキデータとのリアルタイムの同期を維持するために軽量です。ウィキデータからのみトレーニングできるシンプルな名前付きエンティティリンキングシステムを提案します。これは、このタスクに対するこのデータソースの長所と短所を示しています。また、他のシステムと比較するための簡単に再現可能なベースラインを提供します。 
[概要]将来のシステムの可能性をテストできる必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-19">
        <br><font color="black">2019-04-19</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Document Event Coreference Resolution Beyond Corpus-Tailored
  Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_26.html">
      <font color="black">Cross-Document Event Coreference Resolution Beyond Corpus-Tailored
  Systems</font>
    </a>
  </h2>
  <font color="black">将来、コーパスに合わせたCDCRシステムを超える方法についての推奨事項で締めくくります。最も重要なのは、複数のCDCRコーパスでの評価が強く必要であることです。この問題に取り組むために、3つのCDCRコーパスを含む統一された評価設定を定義します。 ECB +、Gun Violence Corpus、Football Coreference Corpus（分析を可能にするためにトークンレベルで注釈を付け直します）。コーパスに依存しない機能ベースのシステムを、ECB +用に開発された最近のニューラルシステムと比較します。 
[ABSTRACT] cdcrは、ダウンストリームのマルチpアプリケーションに利益をもたらすことを目的としています。しかし、コーパスとモデル開発の最近の進歩にもかかわらず、cdcrの適用による改善はまだ示されていません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Generating Intelligible Plumitifs Descriptions: Use Case Application
  with Ethical Considerations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/cs.CL/paper_27.html">
      <font color="black">Generating Intelligible Plumitifs Descriptions: Use Case Application
  with Ethical Considerations</font>
    </a>
  </h2>
  <font color="black">言うまでもなく、これらの機密文書を大規模に読み取り可能にして利用できるようにすることで、倫理的な考慮事項が高まります。このホワイトペーパーで取り上げる正当な懸念事項です。当事者の身元、事件の管理を担当する管轄、および性質に関する情報そして、前述のコースは、plumitifsを通じて利用できます。それらは、公的にアクセス可能ですが、ほとんど理解できません。それらは略語を使用して書かれており、カナダ刑法の規定を参照しているため、推論が困難です。 
[概要]一般にアクセス可能ですが、ほとんど理解できません。略語を使用し、カナダの刑法の規定を参照して書かれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: A Novel Multimodal Music Genre Classifier using Hierarchical Attention
  and Convolutional Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.AS/paper_0.html">
      <font color="black">A Novel Multimodal Music Genre Classifier using Hierarchical Attention
  and Convolutional Neural Network</font>
    </a>
  </h2>
  <font color="black">次に、結果の融合特徴ベクトルに基づいて音楽トラックを分類します。音響特徴を組み込むためにスペクトログラム用のCNNベースの特徴抽出器と、歌詞用の階層的注意ネットワークベースの特徴抽出器を実装しました。音楽ジャンルの分類は次のとおりです。現在の音楽情報検索（MIR）研究に関するトレンドトピックの1つ。 
[概要]以来、ジャンルの依存関係はオーディオプロファイルに限定されています。対応する曲の歌詞として提供されている文学コンテンツも利用しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Whole-Word Segmental Speech Recognition with Acoustic Word Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.AS/paper_1.html">
      <font color="black">Whole-Word Segmental Speech Recognition with Acoustic Word Embeddings</font>
    </a>
  </h2>
  <font color="black">さらに、共同でトレーニングされた音響単語埋め込み（AWE）と書かれた単語ラベルの音響的に接地された単語埋め込み（AGWE）による事前トレーニングの使用を調査します。最終モデルは、以前のA2Wモデルよりも改善されています。単語エラー率がわかります。 AWEを使用して音響セグメント表現を事前トレーニングすることにより、大幅に削減できます。また、AGWEを使用して単語予測レイヤーを事前トレーニングすることにより、追加の（より小さな）ゲインを取得できます。 
[概要]特徴サイズのモデルは、セグメントの埋め込みを使用してマッピングされます。これらのモデルは、セグメントモデルの埋め込みに基づいています。さらに、音響セグメント表現を畏敬の念を持って事前トレーニングします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-01">
        <br><font color="black">2020-07-01</font>
      </time>
    </span>
</section>
<!-- paper0: TFGAN: Time and Frequency Domain Based Generative Adversarial Network
  for High-fidelity Speech Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.AS/paper_2.html">
      <font color="black">TFGAN: Time and Frequency Domain Based Generative Adversarial Network
  for High-fidelity Speech Synthesis</font>
    </a>
  </h2>
  <font color="black">一方では、時間領域だけでなく、より一貫性の保証を提供するために、周波数領域で合成波形からグラウンドトゥルース波形を区別することを提案します。他方、従来の周波数領域のSTFT損失アプローチまたは機能マップとは対照的に弁別器による波形学習の損失について、ジェネレータが波形を直接キャプチャするように促す一連の時間領域損失を提案します。私たちの実験では、TFGANは、音声合成の下で自動回帰ボコーダと同等の平均意見スコア（MOS）を達成する能力を示しています。環境。 
[ABSTRACT]ベースのジェネレーターは、波形生成プロセスを高速かつ安定させます。時間領域と周波数領域の両方で敵対的に学習しているtfganは、新しいボコーダーモデルを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Decoder DPRNN: High Accuracy Source Counting and Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.AS/paper_3.html">
      <font color="black">Multi-Decoder DPRNN: High Accuracy Source Counting and Separation</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、スピーカーの数を数える点で最先端を上回り、再構築された信号の品質で競争力を維持していることを示しています。具体的には、グラウンドトゥルースのスピーカーの数が多かれ少なかれ、品質を評価する方法に関する問題を解決しました。モデルによって予測されたもの..最大5人の話者の混合物を使用して、WSJ0-mixデータセットに対するアプローチを評価します。 
[概要]スピーカーの数を変えて音源分離を評価する方法に関する測定基準も提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Imperio: Robust Over-the-Air Adversarial Examples for Automatic Speech
  Recognition Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.AS/paper_4.html">
      <font color="black">Imperio: Robust Over-the-Air Adversarial Examples for Automatic Speech
  Recognition Systems</font>
    </a>
  </h2>
  <font color="black">公開されているいくつかの無線の敵対的な例は、3つのカテゴリのいずれかに分類されます。これらは、手作りの例であるか、目立つため、コンテンツに注意を向けると、人間のリスナーがターゲットの文字起こしを簡単に認識できるか、または攻撃が行われる部屋であるため、他の部屋に転送することはできません。さらに、私たちのアルゴリズムでは、音響心理学的手法を利用して、元の音声信号の変化を人間の聴覚のしきい値未満に隠すことができます。したがって、部屋に関する事前の知識はありません。特性が必要です。 
[概要]これらの例は、部屋でプレイすると成功しません。部屋ベースの敵対的攻撃をより成功させるために使用できます。代わりに、部屋のインパルス応答（rirs）を使用して任意の部屋の特性を説明します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-05">
        <br><font color="black">2019-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Count Words in Fluent Speech enables Online Speech
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.AS/paper_5.html">
      <font color="black">Learning to Count Words in Fluent Speech enables Online Speech
  Recognition</font>
    </a>
  </h2>
  <font color="black">英語と北京語の音声のLRS2、LibriSpeech、およびAishell-1データセットで実行された実験は、5セグメントの動的アルゴリズム遅延がある場合、オンラインシステムがオフラインシステムと同等のパフォーマンスを発揮することを示しています。累積単語合計を使用して音声を動的にセグメント化します。タリスは、標準のトランスフォーマーと比較して無視できるオーバーヘッドを導入しますが、入力と出力の間のローカル関係モデリングは、設計によりシーケンス長に不変性を与えます。 
[概要]これらのモデルが音声を制御できるようにする必要があるのはこれが初めてです。システムは2つの間の正確さを必要としないと彼らは言います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-08">
        <br><font color="black">2020-06-08</font>
      </time>
    </span>
</section>
<!-- paper0: Integration of variational autoencoder and spatial clustering for
  adaptive multi-channel neural speech separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.AS/paper_6.html">
      <font color="black">Integration of variational autoencoder and spatial clustering for
  adaptive multi-channel neural speech separation</font>
    </a>
  </h2>
  <font color="black">私たちのモデルは、ガウス混合モデル（DOLPHIN）に基づく以前の階乗モデルを大幅に上回り、順列不変トレーニングと空間クラスタリングの統合に匹敵するパフォーマンスを示し、新しいノイズ条件に簡単に適応できることを実験的に示します。モデルのノイズ部分のみを変更する必要があるため、新しいノイズ条件に適応する場合に有利です。そうすることで、ニューラルネットワークのモデリング能力を活用できると同時に、構造化モデルを維持できます。 
[ABSTRACT]メソッドは、新しいノイズ条件に適応するときに有利です。ただし、モデルのノイズ部分のみを変更する必要があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: DiffWave: A Versatile Diffusion Model for Audio Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.AS/paper_7.html">
      <font color="black">DiffWave: A Versatile Diffusion Model for Audio Synthesis</font>
    </a>
  </h2>
  <font color="black">DiffWaveは、音声品質（MOS：4.44対4.43）の点で強力なWaveNetボコーダーと一致し、桁違いに高速に合成することを示します。データ尤度の変分限界のバリアントを最適化することにより、効率的にトレーニングされます。DiffWaveは高い-メルスペクトログラムを条件とするニューラルボコーダー、クラス条件付き生成、無条件生成など、さまざまな波形生成タスクでの忠実度の高いオーディオ。 
[概要]モデルは非自己回帰であり、合成時に一定のステップ数でマルコフ連鎖を介してホワイトノイズ信号を構造化された波形に変換します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-21">
        <br><font color="black">2020-09-21</font>
      </time>
    </span>
</section>
<!-- paper0: A light transformer for speech-to-intent applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.AS/paper_8.html">
      <font color="black">A light transformer for speech-to-intent applications</font>
    </a>
  </h2>
  <font color="black">本論文では、モデルサイズの縮小と効率の向上を目的として、簡略化された相対位置エンコーディングを使用した光トランス構造を提案します。ただし、音声の変動の原因が多いため、十分にトレーニングされたシステムでは別の言語や音声障害のあるユーザーなどの他の条件への転送。困難な音声条件を持つ3つのデータセットでの実験結果は、元のモデルサイズとトレーニング時間の半分で、既存のシステムや他の最先端モデルよりも優れたアプローチであることを証明しています。 
[概要]ライトトランスフォーマーは、既存のユーザー向けの代替音声エンコーダーとして機能します-教えられたマルチタスクsluシステム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Synth2Aug: Cross-domain speaker recognition with TTS synthesized speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.AS/paper_9.html">
      <font color="black">Synth2Aug: Cross-domain speaker recognition with TTS synthesized speech</font>
    </a>
  </h2>
  <font color="black">さらに、TTS合成に使用されるさまざまなタイプのテキストトランスクリプトの有効性を調査します。近年、音声認識のデータ拡張手法としてText-To-Speech（TTS）が使用され、トレーニングデータの不十分さを補っています。 。結果は、ターゲットドメインのテキストコンテンツを一致させることが良い習慣であることを示唆しており、それが不可能な場合は、十分に大きな語彙を持つトランスクリプトが推奨されます。 
[概要]話者認識をサポートする音声合成のためのマルチスピーカーttsシステムの使用を検討します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Zero-Shot Audio Classification via Semantic Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.AS/paper_10.html">
      <font color="black">Zero-Shot Audio Classification via Semantic Embeddings</font>
    </a>
  </h2>
  <font color="black">異なる言語モデルで生成されたラベル/文の埋め込みを連結することにより、分類パフォーマンスが向上します。この論文では、テキストラベルと音声クラスの文の説明から抽出されたセマンティック埋め込みを介した音声分類のゼロショット学習を研究します。結果はさらに改善されます。 
[概要]私たちの目標は、利用可能なトレーニングサンプルがなく、セマンティックサイド情報のみを持つサウンドクラスのオーディオインスタンスを認識できる分類器を取得することです。vggishを使用して、オーディオクリップから深い音響埋め込みを抽出し、事前にトレーニングされた言語モデル（ word2vec、glove、sound classes）を使用して、いずれかのラベル埋め込みを生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: How Far Are We from Robust Voice Conversion: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-25/eess.AS/paper_11.html">
      <font color="black">How Far Are We from Robust Voice Conversion: A Survey</font>
    </a>
  </h2>
  <font color="black">すべてのVCモデルは目に見えないデータに悩まされていますが、AdaIN-VCは比較的堅牢です。また、共同でトレーニングされたスピーカー埋め込みは、スピーカー識別でトレーニングされたものよりも音声変換に適しています。音声変換テクノロジーは近年大幅に改善されています。ディープラーニングの助けを借りて、しかし、さまざまな条件で自然な響きの発話を生成するそれらの能力は不明なままです。 
[概要]論文では、既知のvcモデルの堅牢性について詳細に研究しました。共同でトレーニングされた埋め込みは、話者識別でトレーニングされたモデルよりも音声変換に適しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
