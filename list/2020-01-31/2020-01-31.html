<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<title>Akari-2020-01-31の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
  <div class="header-logo">
    <a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
  </div>
</header>
<input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">

<div class="menubar">
<span class="bar"></span>
<span class="bar"></span>
<span class="bar"></span>
</div>

<ul>
<li><a id="home" href="../../index.html">Home</a></li>
<li><a id="about" href="../../teamAkariとは.html">About</a></li>
<li><a id="contact" href="../../contact.html">Contact</a></li>
<li><a id="contact" href="../../list/newest.html">New Papers</a></li>
<li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
</ul>

</label>
<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Sound field reconstruction in rooms: inpainting meets superresolution -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/cs.SD/paper_0.html">
      Sound field reconstruction in rooms: inpainting meets superresolution
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      特に、提示されたアプローチは、限られた数の音場圧力の大きさの任意の離散測定値を使用して、この場を計算の複雑さの低い空間内の離散点の高解像度グリッドに外挿します。この方法は、3次元の音場の測定から部屋の2次元平面を再構築することに焦点を当てています。データセットは、数千の一般的な長方形の部屋にわたるグリーン関数の数値シミュレーションから構築されます。 
[概要]この方法は、シミュレートされたデータのみでトレーニングされた部分畳み込みを使用したau-net-ニューラルネットワークに基づいています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br>2020-01-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Robust Estimation of Hypernasality in Dysarthria with Acoustic Model
  Likelihood Features -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/cs.SD/paper_1.html">
      Robust Estimation of Hypernasality in Dysarthria with Acoustic Model
  Likelihood Features
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      有声音の場合、ハイパー鼻音は低周波数に追加の共鳴を導入し、無声音の場合、鼻腔から空気が逃げるために調音の精度が低下します。工学的特徴は、しばしば鼻音に関連する複雑な音響パターンをキャプチャできません。機械学習に基づくと、トレーニング対象の小さな疾患固有の音声データセットに過剰適合する傾向があります。ハイパー鼻音性は、多くの運動音声障害に共通する特徴的な症状です。 
[概要]鼻音は低周波数に追加の共振を導入します。鼻音に基づいて、鼻腔から空気が漏れるために調音の精度が低下します。これらの機能は、1つの病気からの鼻音の鼻音を訓練する場合でも一般化されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-26">
        <br>2019-11-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Continuous speech separation: dataset and analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/cs.SD/paper_2.html">
      Continuous speech separation: dataset and analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これにより、テストされたアルゴリズムの実用的な関連性を評価するのが難しくなるだけでなく、研究者が実際のシナリオに容易に適用できるシステムを開発することも妨げられると考えています。独立したCSSアルゴリズムが調査されます。LibriCSSと呼ばれる新しい実際の記録されたデータセットは、コーパスの発話を連結して会話をシミュレートし、遠距離マイクでオーディオリプレイをキャプチャすることによってLibriSpeechから派生します。 
[概要]アルゴリズムは、信号対歪み比または同様のパフォーマンスメトリックに基づいて評価されます。さらに、信号ベースのメトリックは、自動音声認識（asr）精度と非常に弱い相関関係を持ちます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br>2020-01-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Conditioning Autoencoder Latent Spaces for Real-Time Timbre
  Interpolation and Synthesis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/cs.SD/paper_3.html">
      Conditioning Autoencoder Latent Spaces for Real-Time Timbre
  Interpolation and Synthesis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのネットワークのパフォーマンスを測定し、このクロマコンディショニングベクトルの使用から生じる潜在的な埋め込みを特徴付けます。Pythonでのオープンソースのリアルタイム音色合成アルゴリズムの概要を説明し、共有します。入力増強と潜在空間条件付けの両方で使用するクロマ特徴ベクトル。 
[ABSTRACT] autoencoderのボトルネックは、さまざまなアクティベーション関数がどのように多くを生成するかを示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br>2020-01-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On Loss Functions for Supervised Monaural Time-Domain Speech Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/cs.SD/paper_4.html">
      On Loss Functions for Supervised Monaural Time-Domain Speech Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      多くの深層学習ベースの音声強調アルゴリズムは、予測音声信号とターゲット音声信号の間の変換領域で平均二乗誤差（MSE）を最小化するように設計されています。最初に、受信機がさらに、損失関数が時間領域の深層学習ベースの音声強調システムの新しいクラスに与える影響についてはほとんど知られていません。 
[概要]スケールに基づく損失関数-ode信号-歪み比（si-sdr）は、一般的な音声強調評価指標の範囲全体で一般的なパフォーマンスを実現します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-03">
        <br>2019-09-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: BUT Opensat 2019 Speech Recognition System -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/cs.SD/paper_5.html">
      BUT Opensat 2019 Speech Recognition System
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      論文では、低リソース言語と公共安全通信などの2つのドメインカテゴリでOpenSAT評価のために提出されたBUT自動音声認識（ASR）システムについて説明します。そして、高レベルのノイズ..合理的に良好なパフォーマンスを得るために、データ増強プロセスは避けられませんでした。 
[概要]最初のトレーニングデータは不足していたため、挑戦的でした。さまざまなアーキテクチャと多言語アプローチが採用されました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br>2020-01-30
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Lost in Embedding Space: Explaining Cross-Lingual Task Performance with
  Eigenvalue Divergence -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/cs.CL/paper_0.html">
      Lost in Embedding Space: Explaining Cross-Lingual Task Performance with
  Eigenvalue Divergence
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、EVDは類型的に駆動される言語距離測定を補完する情報をキャプチャすることを実証します。1）埋め込みベースのEVD距離から得られる言語類似性スコアは、異なる言語間タスクで観察されるパフォーマンスに強く関連することを実証します2） EVDは、他の標準的な埋め込みベースの言語距離測定よりも優れており、同時に計算が扱いやすく、解釈が容易です。言語間NLPタスクのパフォーマンスは、手元の言語の（非）類似性の影響を受けます。前の研究は、二言語辞書誘導（BLI）の期待される成功と、単一言語の埋め込みスペース間の（近似）同型性の仮定との間に関連があることを示唆しています。 
[概要]言語の類似性とタスクのパフォーマンスの相関に焦点を当てた研究。数千の言語ペアと4つの異なるタスク（bli、機械翻訳、解析、posタグ付け）をカバー
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br>2020-01-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Parameter Space Factorization for Zero-Shot Learning across Tasks and
  Languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/cs.CL/paper_1.html">
      Parameter Space Factorization for Zero-Shot Learning across Tasks and
  Languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      たとえば、ベトナム語の名前付きエンティティ認識（NER）およびウォロフの品詞（POS）タグ付けのトレーニングデータが与えられた場合、モデルはウォロフのNERの正確な予測を実行できます。特に、類型的に多様な4つの大陸と11の家族からの33の言語のサンプル。最新のゼロショットのクロスリンガル転送方法と同等以上の結果が得られることを示しています。最強のベースラインと比較して、POSタグ付けで4.49ポイント、NERで7.73ポイント平均してパフォーマンスが向上します。変分推論により、見られたタスク言語の組み合わせからのデータに基づいて、潜在変数の事後を推測します。 
[ABSTRACT]組み合わせは、各言語および各タスクの潜在変数に因数分解できます。これにより、予測時に見えない組み合わせのゼロショット分類が可能になります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br>2020-01-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Text-to-SQL Generation for Question Answering on Electronic Medical
  Records -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/cs.CL/paper_2.html">
      Text-to-SQL Generation for Question Answering on Electronic Medical
  Records
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、用語の略語と質問での入力ミスの可能性が広範に使用されると、対応するSQLクエリを正確に生成するための追加の課題が生じます。質問からSQLへの生成方法は、最初にデータベースに関する特定の質問のSQLクエリを予測し、次にデータベースでクエリを実行することにより、この問題に対処します。 
[概要]新しい研究はマンチェスター大学によって実施されました。このドメインに固有の学習モデルのデータセットに基づいています。これらの課題は、さまざまなタイプの質問に対する新しいシステムを作成するために開発されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-28">
        <br>2019-07-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Adversarial Training for Aspect-Based Sentiment Analysis with BERT -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/cs.CL/paper_3.html">
      Adversarial Training for Aspect-Based Sentiment Analysis with BERT
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      （2014）、Xu等によって提案された訓練後BERT（BERT-PT）言語モデル。アブレーション研究により訓練後BERTの結果を改善した後、BERT Adversarial Training（BAT）と呼ばれる新しいアーキテクチャを提案します。感情分析におけるアスペクト抽出とアスペクト感情分類の2つの主要なタスクに関するABSA ..（2019）の敵対的トレーニングを活用する。 
[要約]これらの例は実際の文ではありませんが、ニューラルネットワークをより堅牢にする正則化手法として機能することが示されています。これらのタスクを使用した後、敵対者トレーニングを利用するためのバート敵対トレーニング（bat）と呼ばれる新しいアーキテクチャを提案アブサで
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br>2020-01-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Do We Need Word Order Information for Cross-lingual Sequence Labeling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/cs.CL/paper_4.html">
      Do We Need Word Order Information for Cross-lingual Sequence Labeling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      対話の自然言語理解、品詞タグ付け、および名前付きエンティティ認識タスクに関する実験結果は、語順情報を削除することで、ベースラインモデルよりも優れたゼロショットのクロスリンガルパフォーマンスを達成できることを示しています。私たちのモデルは入力シーケンスの単語順序情報をエンコードせず、各トークンの予測はシーケンス全体の注意に基づいています。 
[要約]クロスリンガルモデルは、ソース言語の語順に適合します。当社のモデルは、入力シーケンスの語順情報をエンコードしません。各トークンの予測は、シーケンス全体の注意に基づいています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br>2020-01-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Harnessing Code Switching to Transcend the Linguistic Barrier -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/cs.CL/paper_5.html">
      Harnessing Code Switching to Transcend the Linguistic Barrier
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本論文では、最小限の監督を必要とするポリグロット埋め込みベースの手法を活用して、サンプルコード混合ドキュメントへの体系的なアプローチを提供します。コードミキシング（またはコードスイッチング）は、言語的に多様なユーザーによって生成されるソーシャルメディアコンテンツで見られる一般的な現象です。ベース..プルワマのテロ攻撃によって引き起こされた2019年のインドとパキスタンの紛争の文脈において、我々は人間の幸福のためにコードミキシングを利用する未開拓の可能性を実証します。英語のドキュメントでは、コードが混在したドキュメントが、リソースは少ないが広く使用されている言語であるローマ字ヒンディー語で書かれた\ emph {hope speech}コンテンツを取得するブリッジとして利用されます。 
[ABSTRACT]調査によると、インド亜大陸では、ソーシャルメディアの投稿のかなりの部分がコードの切り替えを示しています。コードが混在したドキュメントは、リソースは少ないが広く使用されている言語で書かれたコンテンツを取得するためのブリッジとして使用されています。人間の健康のためにコードミキシングを活用する可能性
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br>2020-01-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Introducing the diagrammatic mode -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/cs.CL/paper_6.html">
      Introducing the diagrammatic mode
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近の2つの図コーパスを使用して提案されたアプローチを示し、マルチモーダルアプローチがダイアグラム表現の経験的分析をサポートする方法を示します。特にダイアグラム構成要素の特定とその相互関係の説明に役立ちます。自然言語、さまざまな形態のグラフィックス、矢印、線、その他の表現リソースなどの図式要素を一貫した組織に統合するための図式表現。この記事では、仮表現と呼ばれるものの説明をスケッチすることにより、図式表現へのマルチモーダルな視点を提案しますダイアグラムモード。 
[要約]私たちは、マルチモダリティ理論の観点から図式表現を検討します。この概念は、自然言語と他の形式のグラフィックスを組み合わせた形式と見なします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br>2020-01-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Don't Parse, Generate! A Sequence to Sequence Architecture for
  Task-Oriented Semantic Parsing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/cs.CL/paper_7.html">
      Don't Parse, Generate! A Sequence to Sequence Architecture for
  Task-Oriented Semantic Parsing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、実験により、3つの公開データセット（ATIS、SNIPS、Facebook TOP）で最先端のパフォーマンスを達成し、以前のシステムと比べて完全一致の精度が3.3％から7.7％向上していることが示されています。 Sequence to SequenceモデルとPointer Generator Networkに基づく統合アーキテクチャは、単純なクエリと複雑なクエリの両方を処理します。他の作業とは異なり、このアプローチはセマンティック解析スキーマに制限を課しません。 
[ABSTRACT] googleのソフトウェアは「単純な」クエリの解析に使用されています。解析ツリーとして表現できる質問が必要です。さらに、このアプローチではセマンティッククエリに制限を課していません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br>2020-01-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Wikipedia2Vec: An Efficient Toolkit for Learning and Visualizing the
  Embeddings of Words and Entities from Wikipedia -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/cs.CL/paper_8.html">
      Wikipedia2Vec: An Efficient Toolkit for Learning and Visualizing the
  Embeddings of Words and Entities from Wikipedia
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの実験では、私たちのツールは、KOREエンティティ関連データセットで最先端の結果を達成し、さまざまな標準ベンチマークデータセットで競争力のある結果を達成しました。さらに、私たちのツールは、さまざまな最近の研究で重要なコンポーネントとして使用されています。提案されたツールを使用すると、Wikipediaダンプファイルを引数として1つのコマンドを発行することで、ユーザーは埋め込みを効率的に学習できます。 
[ABSTRACT] wikipedia2vecは、ioから単語やエンティティの埋め込みを学習するための12年前のツールです。このツールを使用すると、ユーザーは埋め込みを視覚化して探索できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-15">
        <br>2018-12-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Data Mining in Clinical Trial Text: Transformers for Classification and
  Question Answering Tasks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/cs.CL/paper_9.html">
      Data Mining in Clinical Trial Text: Transformers for Classification and
  Question Answering Tasks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      主な焦点は、人口、介入、比較、および結果（PICO）フレームワークによって特徴付けられる情報ですが、データ抽出はこれらの分野に限定されません。興味のあるテキストには、英語および多言語コンテキストでの臨床試験の要約が含まれます。トランスフォーマーに基づいたニューラルネットワークアーキテクチャは、転移学習の能力と、このアーキテクチャのコンテキストに応じた単語の埋め込みと自己注意メカニズムの使用によってもたらされた、普遍的な読解などの下流の自然言語処理タスクのパフォーマンスの向上を示しています。 
[ABSTRACT] researchは、Augmentationによって重要なトレーニングにどのように取り組むかを示します。これらのモデルは、高いf1スコアを達成し、データマイニングをサポートするためにトランスベースの分類方法を適用する可能性を示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br>2020-01-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Brand Intelligence Analytics -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/cs.CL/paper_10.html">
      Brand Intelligence Analytics
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのオンラインニュース記事は、共起する単語のネットワークに変換され、ソーシャルネットワーク分析とテキストマイニングの方法とツールを組み合わせて分析されました。SBSBIの機能をよりよく説明するために、2020年米国民主党大統領予備選挙..ビッグデータの力を活用することは、ブランドマネージャーが消費者の認識のパターンと傾向を明らかにし、ブランドと望ましいトピックとの肯定的または否定的な関連を監視する機会を表します。 
[概要]ブランドインテリジェンスアプリ、またはsbs biは、ブランドの重要性を評価し、データの分析を通じてブランド分析を提供するように設計されています。イベントレジストリデータベースから50,000を超えるオンライン記事をダウンロードしました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br>2020-01-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: LowResourceEval-2019: a shared task on morphological analysis for
  low-resource languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/cs.CL/paper_11.html">
      LowResourceEval-2019: a shared task on morphological analysis for
  low-resource languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さまざまな形式の言語コーパスがCONLL-U形式に変換されました。この記事では、共有タスク用に準備されたデータセットについて説明し、参加者のソリューションの分析を行います。タスクには、形態素解析、単語形式生成、形態素セグメンテーションが含まれます。 
[概要]問題の言語については、小さなサイズのコーパスのみが利用可能です。ユニバーサル形式により、データセットは他の言語コーパスに匹敵します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br>2020-01-30
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Sound field reconstruction in rooms: inpainting meets superresolution -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/eess.AS/paper_0.html">
      Sound field reconstruction in rooms: inpainting meets superresolution
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      特に、提示されたアプローチでは、限られた数の音場圧力の大きさの任意の離散測定値を使用して、このフィールドを低い計算複雑度で空間内の離散ポイントの高解像度グリッドに外挿します。数千の一般的な長方形の部屋にまたがるグリーン関数の数値シミュレーションから。この方法は、シミュレートされたデータのみで訓練された部分畳み込みを持つU-netのようなニューラルネットワークに基づいています。シミュレートされたデータのみでトレーニングされた部分畳み込みを備えたニューラルネットワークのような
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br>2020-01-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Robust Estimation of Hypernasality in Dysarthria with Acoustic Model
  Likelihood Features -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/eess.AS/paper_1.html">
      Robust Estimation of Hypernasality in Dysarthria with Acoustic Model
  Likelihood Features
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの音響モデルから導出された機能が鼻腔発話に固有であることを実証するために、さまざまな構音障害でそれらを評価します。工学機能は、しばしば鼻鼻腔に関連する複雑な音響パターンをキャプチャできません。それらが訓練される小さな疾患特有の音声データセット。.過鼻症は多くの運動音声障害に共通する特徴的な症状です。 
[概要]鼻音は低周波数に追加の共振を導入します。鼻音に基づいて、鼻腔から空気が漏れるために調音の精度が低下します。これらの機能は、1つの病気からの鼻音の鼻音を訓練する場合でも一般化されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-26">
        <br>2019-11-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Continuous speech separation: dataset and analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/eess.AS/paper_2.html">
      Continuous speech separation: dataset and analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このデータセットを使用して、最近提案された話者に依存しないCSSアルゴリズムのいくつかの側面を調査します。この論文では、連続音声分離（CSS）を、\ textit { \ emph {部分的に}程度の異なる複数の発話を含む連続的な音声ストリーム。データセットと評価スクリプトは、この方向の研究を促進するために利用可能です。 
[概要]アルゴリズムは、信号対歪み比または同様のパフォーマンスメトリックに基づいて評価されます。さらに、信号ベースのメトリックは、自動音声認識（asr）精度と非常に弱い相関関係を持ちます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br>2020-01-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Conditioning Autoencoder Latent Spaces for Real-Time Timbre
  Interpolation and Synthesis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/eess.AS/paper_3.html">
      Conditioning Autoencoder Latent Spaces for Real-Time Timbre
  Interpolation and Synthesis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのネットワークのパフォーマンスを測定し、このクロマコンディショニングベクトルの使用から生じる潜在的な埋め込みを特徴付けます。オートエンコーダのボトルネックで使用されるさまざまなアクティベーション関数がトレーニングコーパスの埋め込みをどのように分散するかを示します。 Pythonの音色合成アルゴリズムの概要と共有。 
[ABSTRACT] autoencoderのボトルネックは、さまざまなアクティベーション関数がどのように多くを生成するかを示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br>2020-01-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On Loss Functions for Supervised Monaural Time-Domain Speech Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/eess.AS/paper_4.html">
      On Loss Functions for Supervised Monaural Time-Domain Speech Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、特定の状況では完全に失敗する可能性があるため、波形マッチングパフォーマンスメトリックは注意して使用する必要があることがわかりました。多くの深層学習ベースの音声強調アルゴリズムは、変換ドメインの平均二乗誤差（MSE）を最小化するように設計されています予測された音声信号とターゲット音声信号。最初に、受信者が人間の聴覚システムである場合、知覚的にインスパイアされた損失関数が有利である可能性があることを示します。 
[概要]スケールに基づく損失関数-ode信号-歪み比（si-sdr）は、一般的な音声強調評価指標の範囲全体で一般的なパフォーマンスを実現します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-03">
        <br>2019-09-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: BUT Opensat 2019 Speech Recognition System -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-01-31/eess.AS/paper_5.html">
      BUT Opensat 2019 Speech Recognition System
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      データ増強プロセスは、かなり良いパフォーマンスを得るために避けられませんでした。最初のトレーニングデータが不足しているため課題が多かったため、さまざまなアーキテクチャと多言語アプローチが採用されました。ストレスと高レベルの騒音下。 
[概要]最初のトレーニングデータは不足していたため、挑戦的でした。さまざまなアーキテクチャと多言語アプローチが採用されました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br>2020-01-30
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
