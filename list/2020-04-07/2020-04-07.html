<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-04-07の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Simultaneous Denoising and Dereverberation Using Deep Embedding Features -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.SD/paper_0.html">
      Simultaneous Denoising and Dereverberation Using Deep Embedding Features
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの埋め込み機能は、無響音声と残差残響信号から生成されます。提案された方法は、ノイズ除去と残響除去の2つの段階を含みます。実験結果は、提案された方法が、特に低SNRでWPEおよびBLSTMベースラインよりも優れていることを示しています。調子。 
[ABSTRACT] dcは、音声分離の最先端の方法です。埋め込み学習とk-クラスタリングを含みます。これは、特徴的な特徴である、必要な信号の推定赤外線マスキングパターンを表すことができます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Listen and Fill in the Missing Letters: Non-Autoregressive Transformer
  for Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.SD/paper_1.html">
      Listen and Fill in the Missing Letters: Non-Autoregressive Transformer
  for Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ネットワークは、マスクされていないコンテキストと入力音声の両方を考慮して、これらのマスクトークンに対応するトークンを予測する必要があります。例として、最も簡単な予測から最も困難な予測までの新しいデコード戦略を提案します。 、すべてのマスクトークンから開始し、ネットワークは部分的な結果に基づいて欠落しているトークンを繰り返し予測します。 
[ABSTRACT]提案された方法は、自己回帰autoregressiveとして提案されています。自動回帰などの自己回帰モデルで使用できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br>2019-11-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.SD/paper_2.html">
      Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      我々はCycleGANネットワークを提案し、敵対的およびサイクル一貫性損失を使用して前方および逆マッピングを同時に学習することにより、非並列トレーニングデータから最適な疑似ペアを見つけます。 、話者のアイデンティティと言語的内容を維持しながら。F0を10の時間スケールに分解するための連続ウェーブレット変換（CWT）の使用も検討します。これは、効果的なF0変換のために、異なる時間解像度での音声韻律を表します。 
[ABSTRACT]多くの研究では、異なる線形パターン間の並列音声データが必要です。これらの研究では、イントネーションの主要な側面であるf0が必要です。ただし、ウェーブレット変換を使用してf0をモデル化する方が適切であると考えています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-01">
        <br>2020-02-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: AI4COVID-19: AI Enabled Preliminary Diagnosis for COVID-19 from Cough
  Samples via an App -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.SD/paper_3.html">
      AI4COVID-19: AI Enabled Preliminary Diagnosis for COVID-19 from Cough
  Samples via an App
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人類が現在進行中のCOVID-19パンデミックに対する戦争において、大規模なテストができないことはアキレのかかとになりました。AI4COVID-19アプリは、被験者の2秒間の咳の録音を必要とします。AI4COVID-19は、臨床テストと競合するように設計されていません。 
[要約]テストは、ai4covid-19という名前のモバイルアプリを介して大規模に展開できます。アプリはクラウドで実行されているAIエンジンを使用し、アプリは1分以内に予備診断を返します。これにより、covid-19は咳だけからの診断になります。非常に困難な問題
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-02">
        <br>2020-04-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: WaveTTS: Tacotron-based TTS with Joint Time-Frequency Domain Loss -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.SD/paper_4.html">
      WaveTTS: Tacotron-based TTS with Joint Time-Frequency Domain Loss
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      WaveTTSは、音響機能と結果の音声波形の両方の品質を保証します。実験結果は、提案されたフレームワークがベースラインを上回り、高品質の合成音声を実現することを示しています。損失関数は通常、周波数領域の音響機能に対してのみ計算されるため、これは、生成された時間領域波形の品質を直接制御しません。 
[要約] wavettsとして知られているタコトロンには2つの損失関数があります。これらには、時間領域損失が含まれます。これは、自然の特徴と生成された特徴の間のメルスケールの音響特徴の損失を測定します。これは、時間と周波数の結合領域を持つタコトロンの最初の実装です損失
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-02">
        <br>2020-02-02
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Selective Attention Based Graph Convolutional Networks for Aspect-Level
  Sentiment Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_0.html">
      Selective Attention Based Graph Convolutional Networks for Aspect-Level
  Sentiment Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SemEval 2014タスク4データセットで実験を行います。ただし、場合によっては、依存関係ツリーの2ホップ以内で重要なコンテキストワードに到達できないことがあります。したがって、選択的注意に基づくGCNブロック（SA-GCN）を設計して、最も重要なコンテキストワード、そしてこれらの情報をアスペクト用語表現に直接集約します。 
[ABSTRACT]最新のアプローチでは、注意メカニズムを使用して、コンテキストとコンテキスト用語の間の相互作用をキャプチャしています。これは、最も重要な用語である単語を見つけるために選択的注意ベースのgcnブロック（sa-gcn）を設計しているためです。現在の状態-アート-
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: BERT in Negotiations: Early Prediction of Buyer-Seller Negotiation
  Outcomes -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_1.html">
      BERT in Negotiations: Early Prediction of Buyer-Seller Negotiation
  Outcomes
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの結果は、単に交渉を実現する方法ではなく、自然言語を交渉計画に組み込む必要があることを示唆しています。この目的のために、データ主導の観点から交渉における自然言語の役割を理解することを目指しています。ネゴシエーションが完了する前に、ネゴシエーションの結果を予測しようとします。このようなフレームワークを直接使用して、自動ネゴシエーションエージェントをトレーニングするためのフィードバックを取得できます。 
[ABSTRACT]システムはケースの70％以上で10％以内を正しく予測できます。自動交渉エージェントのトレーニングのフィードバックを得るために直接使用できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Keyphrase Rubric Relationship Classification in Complex
  Assignments -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_2.html">
      Unsupervised Keyphrase Rubric Relationship Classification in Complex
  Assignments
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この研究では、教師あり手法と教師なし手法の両方を分析し、教師付き手法が教師なし手法およびトピックモデリング手法よりも優れていることを確認します。ただし、教師付き手法によるデータ制限は、0.48 F1-Scoreの最大結果を生成し、教師なし手法は0.31 F1-Scoreの最良の結果を生成します。 。完全なスケールでは、レビューが不完全で詳細が不足しているため、再グレードリクエストが高くなります。このため、割り当ての内容をスコアリングルーブリックに自動的に関連付けるため、この作業では、キーフレーズ-ルーブリック関係の分類に関する非常に最初の作業を示します。 
[要旨]内容をルーブリックに関連付け、「重要な問題」として解決するよう試みます。レビュー結果は不完全であり、詳細を欠いているため、再グレードリクエストが高くなります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-03">
        <br>2020-04-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SelfORE: Self-supervised Relational Feature Learning for Open Relation
  Extraction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_3.html">
      SelfORE: Self-supervised Relational Feature Learning for Open Relation
  Extraction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、SelfOREという名前の自己監視フレームワークを提案しました。これは、コンテキスト付き関係機能の適応型クラスタリングに大規模な事前学習済み言語モデルを活用して弱い自己監視信号を活用し、関係分類のコンテキスト化機能を改善することで自己監視信号をブートストラップします。 ..ソースコードはhttps://github.com/THU-BPM/SelfORE ..で入手できます。3つのデータセットの実験結果は、競合するベースラインと比較した場合の、オープンドメイン関係抽出におけるSelfOREの有効性と堅牢性を示しています。 
[ABSTRACT]既存の作品は、ヒューリスティックまたは遠隔-教師付きアノテーションを使用して、事前定義された関係に対して教師付き分類子をトレーニングします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Grounded Conversation Generation as Guided Traverses in Commonsense
  Knowledge Graphs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_4.html">
      Grounded Conversation Generation as Guided Traverses in Commonsense
  Knowledge Graphs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Reddit会話の実験は、70％少ないパラメーターを使用しながら、以前の知識認識会話モデルおよびGPT-2ベースのモデルに対するConceptFlowの有効性を実証し、明示的な会話構造のモデリングの利点を確認します。会話をコンセプトスペースに固定することにより、ConceptFlowは潜在的な会話を表します常識的な関係に沿って概念空間をトラバースするフロー。このペーパーでは、常識知識グラフを活用して会話フローを明示的にモデル化する新しい会話生成モデルConceptFlowを紹介します。 
[ABSTRACT] conceptflowは、ユーザーが会話フローをモデル化できる新しい会話生成モデルです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-07">
        <br>2019-11-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Online influence, offline violence: Language Use on YouTube surrounding
  the 'Unite the Right' rally -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_5.html">
      Online influence, offline violence: Language Use on YouTube surrounding
  the 'Unite the Right' rally
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ほとんどの変更はラリー自体の言及に関連していますが、オルタナティブグループもYouTubeチャンネルのプロモーションの増加を示しています。社会運動理論は、ラリーに関するメディアの注目とパブリックディスコースがalt-rightに影響を与えた可能性があることを示唆していますが、これは私たちは、2つのグループ間のトピックの違いを観察します。たとえば、「オルタナティブインフルエンサー」は、プログレッシブチャネルよりもますます大きく、人種や自由な発言に関連するトピックについて話し合います。 
[要約]社会運動理論は、集会に関するメディアの注目と公共の言説がオルタナティブ権に影響を与えた可能性があることを示唆しています。しかし、これはまだ分析されていないことが研究で示されています。研究は社会運動研究によって公開されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-30">
        <br>2019-08-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An analysis of the utility of explicit negative examples to improve the
  syntactic abilities of neural language models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_6.html">
      An analysis of the utility of explicit negative examples to improve the
  syntactic abilities of neural language models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの発見の1つは、RNNのオブジェクト相対条項の難しさです。構文を含むトレーニング文の補強は多少は役立ちますが、精度は主語相対条項のレベルに達していません。私たちの成功の鍵は、追加の正しい単語と正しくない単語の対数尤度間のマージン損失。 
[ABSTRACT]私たちの方法は、神経モデルの真のアーキテクチャ上の制限を分析するためのツールになり得ますが、直接認知的に魅力的ではありませんが、複雑な構造を探索する方法になる可能性があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_7.html">
      Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CycleGANネットワークを提案し、敵対的およびサイクル整合性損失を使用してフォワードマッピングとインバースマッピングを同時に学習することにより、非並列トレーニングデータから最適な疑似ペアを見つけます。また、F0を10に分解するための連続ウェーブレット変換（CWT）の使用についても研究します。効果的なF0変換のために、さまざまな時間分解能での音声韻律を表す時間スケール。多くの研究では、さまざまな感情パターン間の並行音声データが必要ですが、実際の生活では実用的ではありません。 
[ABSTRACT]多くの研究では、異なる線形パターン間の並列音声データが必要です。これらの研究では、イントネーションの主要な側面であるf0が必要です。ただし、ウェーブレット変換を使用してf0をモデル化する方が適切であると考えています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-01">
        <br>2020-02-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: WaveTTS: Tacotron-based TTS with Joint Time-Frequency Domain Loss -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_8.html">
      WaveTTS: Tacotron-based TTS with Joint Time-Frequency Domain Loss
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、提案されたフレームワークがベースラインを上回り、高品質の合成音声を実現することを示しています。WaveTTSは、音響機能と結果の音声波形の両方の品質を保証します。このようなフレームワークは通常、文字シーケンスを周波数にマッピングする機能予測ネットワークで構成されます-ドメインの音響機能、それに続く波形再構成アルゴリズム、または音響機能から時間ドメインの波形を生成する神経ボコーダー。 
[要約] wavettsとして知られているタコトロンには2つの損失関数があります。これらには、時間領域損失が含まれます。これは、自然の特徴と生成された特徴の間のメルスケールの音響特徴の損失を測定します。これは、時間と周波数の結合領域を持つタコトロンの最初の実装です損失
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-02">
        <br>2020-02-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Countering Language Drift with Seeded Iterated Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_9.html">
      Countering Language Drift with Seeded Iterated Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      インタラクティブなトレーニングステップでエージェントを微調整し、最後の反復からシードされ、最新の微調整されたモデルを模倣するようにトレーニングされた新しいエージェントで定期的に置き換えます。反復学習は、外部の構文制約や意味論的知識を必要としないため、価値のあるタスクにとらわれない微調整プロトコル。まず、ルイスゲームの反復学習について説明します。 
[要約]このペーパーでは、反復学習を使用して言語のドリフトをなくすための一般的なアプローチを提案します。反復テキストは外部構文制約も意味論的知識も必要としないため、貴重なタスクになります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-28">
        <br>2020-03-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Dictionary-based Data Augmentation for Cross-Domain Neural Machine
  Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_10.html">
      Dictionary-based Data Augmentation for Cross-Domain Neural Machine
  Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案された方法は、逆変換ベースのIND微調整NMTモデルのパフォーマンスをさらに改善することもできます。この改善は、DDAによって生成された拡張ドメインカバレッジに関連しています。生成された疑似INDデータを使用して、一般的なドメインでトレーニングされたベースライン。 
[ABSTRACT]これらの方法には、ドメイン情報のギャップに関連する問題があります。これにより、低頻度で語彙が不足し、翻訳エラーが発生します。改善は、ddaによって生成される拡張ドメインカバレッジに関連しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to Recover Reasoning Chains for Multi-Hop Question Answering
  via Cooperative Games -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_11.html">
      Learning to Recover Reasoning Chains for Multi-Hop Question Answering
  via Cooperative Games
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、提案されたアプローチの有効性を示しています。弱く監視された信号、つまり質問と回答のペアから推論チェーンを回復する学習の新しい問題を提案します。評価のために、2つのマルチホップQAに基づいてベンチマークを作成しましたデータセット、HotpotQAおよびMedHop;そして後者のために手でラベル付けされた推論チェーン。 
[ABSTRACT]この問題に対処するための協力的なゲームアプローチを提案します。証拠のパッセージがどのように選択され、選択されたパッセージがどのように接続されているかを処理します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Applying Cyclical Learning Rate to Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_12.html">
      Applying Cyclical Learning Rate to Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      したがって、私たちの作業では、適切なオプティマイザーとそれに付随する学習率ポリシーを選択することの重要性を認識し、同時に、使いやすい学習率ポリシーのさらなる研究を促進したいと考えています。慎重に設計された実験から、オプティマイザの選択と関連する周期的学習率のポリシーがパフォーマンスに大きな影響を与える可能性があることを示しています。ディープラーニングネットワークのトレーニングでは、オプティマイザと関連する学習率は多くの場合、あまり考えずに、または最小限のチューニングで使用されます。テストデータセットで一般化することもできる、損失関数の質の高い最小値への高速収束を確実にするために重要です。 
[要約]トレーニングを使用して、トランスフォーマーをベースにしたニューラルネットワークをニューラル機械翻訳にトレーニングできます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Hierarchical Fine-Tuning Approach Based on Joint Embedding of Words
  and Parent Categories for Hierarchical Multi-label Text Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_13.html">
      A Hierarchical Fine-Tuning Approach Based on Joint Embedding of Words
  and Parent Categories for Hierarchical Multi-label Text Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      上位レベルでのテキスト分類結果が下位レベルでの分類に寄与するように、微調整技術をOrdered Neural LSTM（ONLSTM）ニューラルネットワークに適用します。このホワイトペーパーでは、階層的微調整ディープラーニングを紹介します。 HMTCのアプローチ..実社会における多くの重要な分類問題は、多数のカテゴリで構成されています。 
[要約] hypeマルチラベルテキスト分類（hmtc）は、密接に関連するカテゴリの大規模なセットよりも高い精度を持っています。結果は、この論文で提案された方法が、最先端の分類アプローチよりもはるかに低い計算コストで優れていることを示しています。高い解釈可能性の維持
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Sparse Text Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_14.html">
      Sparse Text Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これにより、トレーニング条件とテスト条件の間に不一致が生じます。結果は、流暢さと一貫性、反復回数の削減、および人間のテキストに近いnグラムの多様性の点で好ましいパフォーマンスを持つテキストジェネレータです。モデルを評価するために、疎または切り捨てられた分布を比較するために調整された3つの新しいメトリック：$ \ epsilon $ -perplexity、sparsemaxスコア、およびJensen-Shannonダイバージェンス。 
[ABSTRACT]これは、これらのモデルが修正されたsoftmaxからのサンプリングを必要とする初めての例です。縮退したテキストを回避するために、サンプリングが必要です。これは、最近のentmax変換に基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Distinguish Confusing Law Articles for Legal Judgment Prediction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_15.html">
      Distinguish Confusing Law Articles for Legal Judgment Prediction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      紛らわしい料金を区別するために、私たちは、紛らわしい法律の記事間の微妙な違いを自動的に学び、事実の説明から効果的な識別機能を注意深く抽出するために学んだ違いを十分に活用する新しい注意メカニズムを設計する新しいグラフニューラルネットワークを提案します。データセットは、LADANの優位性を示しています。法的判決予測（LJP）は、その事実を説明するテキストが与えられた場合、裁判の判決結果を自動的に予測するタスクであり、司法支援システムと公共サービスに大きな展望があります。 
[ABSTRACT]同様の法律記事に関連する訴訟は、しばしば誤って判断されます。ljpのタスクを修正するために、エンドツーエンドモデル、ladanを提示します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: PONE: A Novel Automatic Evaluation Metric for Open-Domain Generative
  Dialogue Systems -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_16.html">
      PONE: A Novel Automatic Evaluation Metric for Open-Domain Generative
  Dialogue Systems
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      広範な実験により、提案された評価方法が最新の学習ベースの評価方法よりも大幅に優れており、平均相関が13.18％向上しています。さらに、提案された方法と状態のコードが公開されています。最新のベースライン..このホワイトペーパーでは、最初に、同じ実験設定ですべての種類の自動評価指標を体系的に測定し、どの種類が最適かを確認します。 
[ABSTRACT]学習ベースのメトリックは、オープンドメインの対話型システムの最も効果的な評価メトリックであることを示しています。poneと呼ばれる新しい方法は、拡張されたポジティブサンプルとネガティブネガティブサンプルを使用することにより、人間の判断との相関を大幅に改善できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Relational Memory-based Embedding Model for Triple Classification and
  Search Personalization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_17.html">
      A Relational Memory-based Embedding Model for Triple Classification and
  Search Personalization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      その結果、R-MeNはこれらの3つの返されたベクトルを畳み込みニューラルネットワークベースのデコーダーに送り、トリプルのスカラースコアを生成します。R-MeNは、各トリプルを、トランスフォーマーを使用してメモリと繰り返し相互作用する3つの入力ベクトルのシーケンスと見なします。自己注意メカニズム。実験結果は、提案されたR-MeNが検索パーソナライゼーションタスクのSEARCH17、およびトリプル分類タスクのWN11とFB13で最新の結果を取得することを示しています。 
[要約] r-menという名前の新しいモデルは、関係トリプルの潜在的な依存関係をエンコードすることを目的としています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-13">
        <br>2019-07-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Fine-Grained Sentiment Dataset for Norwegian -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_18.html">
      A Fine-Grained Sentiment Dataset for Norwegian
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、今後の実験の予備ベンチマークとして意図された、データセットの最初の実験結果も報告します。ここでは、この注釈の取り組みの詳細な説明を示します。NoReC_fineは、ノルウェー語での細かい感情分析用のデータセットであり、極地表現、ターゲットおよび意見の保持者に関して。 
[ABSTRACT]基礎となるテキストは、複数のニュースソースを含む専門家が作成したレビューのコーパスから取得されます。開発された注釈ガイドラインの概要を例とともに示します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-28">
        <br>2019-11-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: LSTM-based Whisper Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_19.html">
      LSTM-based Whisper Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      LSTM事後者の軌跡を調べることにより、発話レベルの分類のための複数の推論アプローチを比較します。さらに、ささやき音声に固有の信号特性に基づいて一連の機能を設計し、ささやきを通常の音声からさらに分離する効果を評価します。 。提案されたシステムは、log-filterbankエネルギー（LFBE）音響特性でトレーニングされた長短記憶（LSTM）ニューラルネットワークで構成されています。 
[ABSTRACT]提案されたシステムは、log-filterbankエネルギー（lfbe）音響特性でトレーニングされた長期-短期記憶（lstm）ニューラルネットワークで構成されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-09-20">
        <br>2018-09-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Bootstrapping a Crosslingual Semantic Parser -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_20.html">
      Bootstrapping a Crosslingual Semantic Parser
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      新しいバージョンのATISとドイツ語と中国語のOvernightの実験結果は、MTが複数のMTエンジンによる言い換えで補強された場合、正確な解析のためにMTが新しい言語でトレーニングデータを概算できることを示しています。機械翻訳がトレーニングデータの適切な代用かどうかを評価します。 、およびこれを拡張して、英語、言い換え、および多言語BERTなどのリソースとの共同トレーニングを使用してブートストラップを調査します。意味解析のためのデータセットは、英語以外の言語をほとんど考慮しません。 
[ABSTRACT]新しい研究によると、mtは最小限の注釈で新しい言語と複数のドメインに適応できることが示されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression
  of Pre-Trained Transformers -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_21.html">
      MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression
  of Pre-Trained Transformers
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、教師の最後のトランスフォーマ層の自己注意モジュールを抽出することを提案します。これは、生徒にとって効果的で柔軟です。特に、SQuAD 2.0で99％以上の精度を維持し、50％を使用していくつかのGLUEベンチマークタスクを維持します。トランスフォーマーのパラメーターと教師モデルの計算。小さなモデル（学生）は、大規模なモデル（教師）のトランスフォーマーネットワークで重要な役割を果たす自己注意モジュールを深く模倣することによってトレーニングされます。 
[ABSTRACT]モデルは、ラージモデル（教師）の自己注意モジュールを深く模倣することによってトレーニングされます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-25">
        <br>2020-02-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Grayscale Data Construction and Multi-Level Ranking Objective for
  Dialogue Response Selection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_22.html">
      Grayscale Data Construction and Multi-Level Ranking Objective for
  Dialogue Response Selection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2つのベンチマークデータセットの実験結果は、新しいトレーニング戦略により、さまざまな評価指標の点で既存の最先端のマッチングモデルよりもパフォーマンスが大幅に向上することを示しています。グレースケールトレーニングデータを最大限に活用するには、マルチレベルのトレーニングを提案しますランク付け戦略..グレースケールラベルでトレーニングデータを自動的に構築することを提案します。 
[ABSTRACT]新しいトレーニング戦略により、既存の状態よりもパフォーマンスが大幅に向上します-さまざまな評価指標の点で最先端のマッチングモデル
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to Summarize Passages: Mining Passage-Summary Pairs from
  Wikipedia Revision Histories -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_23.html">
      Learning to Summarize Passages: Mining Passage-Summary Pairs from
  Wikipedia Revision Histories
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      品質分析は、データセットがパッセージ要約のためのトレーニングおよび検証セットとして使用できることを約束していることを示しています。提案されたデータセットでのさまざまな要約システムのパフォーマンスを検証および分析します。このホワイトペーパーでは、 Wikipediaページの改訂履歴をマイニングしてパッセージからサマリーデータセットを自動的に構築します。 
[要約]データセットは、パッセージの要約のためのトレーニングおよび検証セットとして使用できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: At Which Level Should We Extract? An Empirical Study on Extractive
  Document Summarization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_24.html">
      At Which Level Should We Extract? An Empirical Study on Extractive
  Document Summarization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      広範な実験と分析により、サブセンテンス単位の抽出は、自動評価と人間評価の両方の評価の下で全文抽出と比較して競争的に実行されることが示されています。サブセンテンシャル情報を活用してそれらを抽出する神経抽出モデルが提示されています。対応するConstituency構文解析ツリーでサブセンテンス単位を抽出することを提案します。 
[ABSTRACT]以前の作品は、情報レベルの内容を文レベルで識別することによってこのタスクを実行します。ただし、完全な文を抽出する場合、不必要で冗長な問題があることを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Data Manipulation: Towards Effective Instance Learning for Neural
  Dialogue Generation via Learning to Augment and Reweight -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_25.html">
      Data Manipulation: Towards Effective Instance Learning for Neural
  Dialogue Generation via Learning to Augment and Reweight
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      現在の最先端の神経対話モデルは、データ駆動型パラダイムに従って人間の会話から学習します。したがって、効果的な対話学習には、より信頼性の高い学習サンプルだけでなく、ノイズの多いサンプルも必要です。提案されたデータ操作に注意してください。フレームワークは完全にデータ駆動型で学習可能です。 
[ABSTRACT]提案されたデータ操作フレームワークは、信頼性の高いサンプルに向けてデータ分布を積極的に再形成できます。これにより、これらのデータの学習を妨げる神経対話モデル
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Directions in Abusive Language Training Data: Garbage In, Garbage Out -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_26.html">
      Directions in Abusive Language Training Data: Garbage In, Garbage Out
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      虐待的なオンラインコンテンツのデータ駆動型の分析と検出は、多くの異なるタスク、現象、コンテキスト、および方法論をカバーしています。この知識の集まりは、この複雑で非常に多様なデータを扱う実務家に証拠に基づく推奨を提供する統合につながります。乱用言語データをカタログ化するためのオープンウェブサイトと併せて、乱用言語データセットの作成とコンテンツを体系的にレビューします。 
[要約]このペーパーでは、言語コミュニケーションの効果を探ります。これらのタイプは、乱用言語データをカタログ化するためのオープンなWebサイトに基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-03">
        <br>2020-04-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Negative Training for Neural Dialogue Response Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_27.html">
      Negative Training for Neural Dialogue Response Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの実験では、ネガティブトレーニングが悪意のある応答のヒット率を大幅に低下させるか、頻繁な応答を抑制し、応答の多様性を向上させることが示されています。モデルを微調整するための負のトレーニング信号..この作業では、このような動作を最小限に抑えるための「負のトレーニング」という名前のフレームワークを提案します。 
[ABSTRACT]科学者は、否定的なトレーニングが悪意のある応答のヒット率を大幅に低下させる可能性があることを示しています。これらには、応答の多様性を改善するための推奨応答の奨励が含まれます。結果は実験で明らかになりました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-03-06">
        <br>2019-03-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Shallow Discourse Annotation for Chinese TED Talks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_28.html">
      Shallow Discourse Annotation for Chinese TED Talks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      現在、このリソースは、書面のテキストではなく、計画された音声のモノローグの談話レベルのプロパティに注釈を付けるという点でユニークです。注釈者間の合意の調査では、注釈スキームが非常に信頼できる結果を達成できることが示されています。言語関連のプロパティで注釈されたテキストコーパス言語技術の開発のための重要なリソースです。 
[要約]話し合いには、ペンの談話ツリーバンクのスタイルの談話関係が注釈として付けられ、英語には存在しない中国語のテキストのプロパティに適合
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br>2020-03-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Building a Norwegian Lexical Resource for Medical Entity Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_29.html">
      Building a Norwegian Lexical Resource for Medical Entity Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      キーワードとサフィックスに基づくこの自動辞書エントリマッピングの背後にある方法論について説明し、ドメインエキスパートによってサブセットに対して実行された手動評価の結果を示します。マッピングの80％は正しかったです。リソースは、大規模な医療からの情報をマージしますデータベース、および77,000を超える一意のエントリが含まれています。これには、ノルウェーの医学辞書から自動的にマッピングされた用語が含まれます。 
[ABSTRACT]このリソースは、大規模な医療データベースの情報を統合します。77,000を超える一意のエントリが含まれています。これには、ノルウェーの医療辞書から自動的にマッピングされた用語が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multiple Generative Models Ensemble for Knowledge-Driven Proactive
  Human-Computer Dialogue Agent -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/cs.CL/paper_30.html">
      Multiple Generative Models Ensemble for Knowledge-Driven Proactive
  Human-Computer Dialogue Agent
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ランクベースのアンサンブルアプローチがパフォーマンスを向上させるために開発されました。結果は、DuConvデータセットで、ベースラインに対して平均して、F1スコアおよびBLEUの条件が単一モデルで明らかに改善されたことを示しています。複数のシーケンスシーケンスモデルを使用して、データ拡張技術とバリアントエンコーダー/デコーダー構造の設計の助けを借りて、エンドツーエンドのマルチターンプロアクティブダイアログ生成エージェントを確立しました。 
[ABSTRACT]ランクに基づくアンサンブルアプローチは、パフォーマンスを向上させるために開発されました。モデルは、パフォーマンスを改善するために開発されました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-08">
        <br>2019-07-08
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Simultaneous Denoising and Dereverberation Using Deep Embedding Features -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/eess.AS/paper_0.html">
      Simultaneous Denoising and Dereverberation Using Deep Embedding Features
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ノイズ除去の段階では、DCネットワークを利用して、ノイズのないディープエンベディング機能を抽出します。提案した方法は、ノイズ除去と残響除去の2つの段階で構成されています。ディープクラスタリング（DC）に基づくディープエンベディング機能を使用した残響除去。 
[ABSTRACT] dcは、音声分離の最先端の方法です。埋め込み学習とk-クラスタリングを含みます。これは、特徴的な特徴である、必要な信号の推定赤外線マスキングパターンを表すことができます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Listen and Fill in the Missing Letters: Non-Autoregressive Transformer
  for Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/eess.AS/paper_1.html">
      Listen and Fill in the Missing Letters: Non-Autoregressive Transformer
  for Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      推論中、すべてのマスクトークンから開始し、ネットワークは部分的な結果に基づいて欠落しているトークンを反復的に予測します。このフレームワークは、従来の左から右を含むさまざまなデコード戦略をサポートできます。 
[ABSTRACT]提案された方法は、自己回帰autoregressiveとして提案されています。自動回帰などの自己回帰モデルで使用できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br>2019-11-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/eess.AS/paper_2.html">
      Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CycleGANネットワークを提案し、敵対的損失とサイクル整合性損失を使用してフォワードマッピングとインバースマッピングを同時に学習することにより、非並列トレーニングデータから最適な疑似ペアを見つけます。効果的なF0変換のための、異なる時間解像度での音声韻律を表す時間スケール。感情的な音声変換は、話者のアイデンティティと言語的内容を維持しながら、スペクトルと韻律を変換して音声の感情パターンを変更することを目的としています。 
[ABSTRACT]多くの研究では、異なる線形パターン間の並列音声データが必要です。これらの研究では、イントネーションの主要な側面であるf0が必要です。ただし、ウェーブレット変換を使用してf0をモデル化する方が適切であると考えています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-01">
        <br>2020-02-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: AI4COVID-19: AI Enabled Preliminary Diagnosis for COVID-19 from Cough
  Samples via an App -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/eess.AS/paper_3.html">
      AI4COVID-19: AI Enabled Preliminary Diagnosis for COVID-19 from Cough
  Samples via an App
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      残念ながら、咳は20を超えるCOVID-19に関連しない病状の一般的な症状です。AI4COVID-19は、臨床試験と競合するように設計されていません。クラウドで実行されているAIエンジンを介して咳のサンプルを分析することにより、アプリは戻ります1分以内の予備診断。 
[要約]テストは、ai4covid-19という名前のモバイルアプリを介して大規模に展開できます。アプリはクラウドで実行されているAIエンジンを使用し、アプリは1分以内に予備診断を返します。これにより、covid-19は咳だけからの診断になります。非常に困難な問題
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-02">
        <br>2020-04-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: WaveTTS: Tacotron-based TTS with Joint Time-Frequency Domain Loss -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/eess.AS/paper_4.html">
      WaveTTS: Tacotron-based TTS with Joint Time-Frequency Domain Loss
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、提案されたフレームワークがベースラインを上回り、高品質の合成音声を実現することを示しています。WaveTTSは、音響機能の品質と結果の音声波形の両方を保証します。通常、損失関数は周波数領域の音響機能に対してのみ計算されるため、これは、生成された時間領域波形の品質を直接制御しません。 
[要約] wavettsとして知られているタコトロンには2つの損失関数があります。これらには、時間領域損失が含まれます。これは、自然の特徴と生成された特徴の間のメルスケールの音響特徴の損失を測定します。これは、時間と周波数の結合領域を持つタコトロンの最初の実装です損失
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-02">
        <br>2020-02-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Deep Multilayer Perceptrons for Dimensional Speech Emotion Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/eess.AS/paper_5.html">
      Deep Multilayer Perceptrons for Dimensional Speech Emotion Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーでは、計算要件の制限に取り組むために、深い層と小さな入力サイズを備えた従来の多層パーセプトロン（MLP）を提案します。深いMLPは、IEMOCAPおよびMSP-IMPROVコーパスのスピーカー依存シナリオとスピーカー非依存シナリオの両方で最高のパフォーマンスを示しました。結果は、提案されたディープMLPが、同じ数のレイヤーとパラメーターの値で、最新のディープラーニングアーキテクチャ、つまりLSTMとCNNを上回ったことを示しています。 
[ABSTRACT] deep mlpは、iemocapとmsp-即興コーパスのスピーカー-依存シナリオとスピーカー-独立シナリオの両方で最高のパフォーマンスを示しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Meta-Learning for Short Utterance Speaker Recognition with Imbalance
  Length Pairs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/eess.AS/paper_6.html">
      Meta-Learning for Short Utterance Speaker Recognition with Imbalance
  Length Pairs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これら2つの学習スキームを組み合わせることにより、VoxCelebデータセットでの短い発声（1〜2秒）に関する標準の教師あり学習フレームワークで学習した既存の最先端のスピーカー検証モデルよりも、モデルの方が優れています。話者の識別。これにより、既存のアプローチよりも大幅に向上します。ただし、特定のエピソードのクラスのみを最適化するだけでは、データセット全体の他のクラスの識別的な埋め込みを学習するには不十分であるため、サポートセットとクエリの両方をさらに分類します。よく区別された埋め込みスペースを学習するために、トレーニングセットのクラス全体に対して設定します。 
[ABSTRACT]既存の話者認識システムを使用して、テスト被験者をテストすることができます。ショートなどの短い発声のテスト被験者は簡単に識別できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Vocoder-Based Speech Synthesis from Silent Videos -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/eess.AS/paper_7.html">
      Vocoder-Based Speech Synthesis from Silent Videos
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      音声再構成のパフォーマンスを向上させるために、モデルはマルチタスク学習方式でテキスト情報を予測するようにトレーニングされており、同時にリアルタイムで音声を再構成して認識することができます。推定された音声品質と了解度の結果は、効果を示しています既存のビデオから音声へのアプローチよりも優れた方法を示します。システムは、生のビデオフレームから音響特徴へのマッピング関数を学習し、ボコーダー合成アルゴリズムで音声を再構築します。 
[ABSTRACT]ビデオシーケンスのオーディオの欠如が低音声明瞭度を決定します。システムは生のビデオフレームから音響機能へのマッピング関数を学習します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A bio-inspired geometric model for sound reconstruction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/eess.AS/paper_8.html">
      A bio-inspired geometric model for sound reconstruction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、そのような画像はハイゼンベルググループで持ち上げられ、ウィルソン・コーワン差分積分方程式を介して再構築されます。ただし、時間の役割や対称性のグループが異なるため、根本的な相違点があります。アルゴリズム劣化した音を短時間のフーリエ変換を介して時間周波数領域の「イメージ」に変換します。 
[要約]この研究の目的は、聴覚皮質の機能アーキテクチャに基づいた音響再構成の数学モデルを提案することです（a1）
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Is aggression costly? Acute aggressive behavior increases oxidative stress independently of testosterone -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-07/biorxiv.physiology/paper_0.html">
      Is aggression costly? Acute aggressive behavior increases oxidative stress independently of testosterone
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      酸化ストレスが攻撃の生理学的コストを表す可能性があることを考慮して、急性攻撃行動が酸化ストレスを増加させる可能性があるという仮説をテストし、潜在的なメディエーターとしてのテストステロンの役割を評価しました。攻撃行動の20分後、両性の酸化ストレスのレベルが高かった対照の個人よりもレベルが高い。しかし、男性ではなく女性でのみ、より積極的になると抗酸化能が低下する。 
[要約]これは、野生の脊椎動物で急性攻撃的行動がテストステロンとは無関係に酸化ストレスを発生させることができるという最初の実験的証拠です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
