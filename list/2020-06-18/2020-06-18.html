<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-06-18の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Visual Attention for Musical Instrument Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.SD/paper_0.html">
      Visual Attention for Musical Instrument Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このプロジェクトでは、弱めにラベル付けされたデータを使用した楽器認識のパフォーマンスを向上させるために、音色-時間的感覚での注意メカニズムの使用をさらに検討します。最初のアプローチは、スライドに注意メカニズムを適用します。 -ウィンドウパラダイム。最終的な予測を生成するために集計する前に、各時間-時間的「インスタンス」に基づく予測に注意の重みが与えられます。このタスクへの2つのアプローチが検討されています。 
[ABSTRACT]このタスクへの2つの異なるアプローチが検討されました。1つの理論は、いくつかの「部分的な垣間見る」に基づいています。他の作品は、楽器の認識パフォーマンスを改善する上でのピッチと音色の役割を示唆しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br>2020-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Adversarial representation learning for private speech generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.SD/paper_1.html">
      Adversarial representation learning for private speech generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      新しいデータを生成することで性別などの機密情報を非表示にできることを示し、実用性と現実性を維持するために敵対的にトレーニングします。モデルは2つのステップでトレーニングされます。最初にスペクトログラムドメインで機密情報をフィルタリングし、次に新しいデータを生成します。フィルターされたものから独立したプライベート情報。モデルは、メルスペクトログラムを入力として受け取るU-Net CNNに基づいています。 
[ABSTRACT]データ内の機密情報を非表示にすることを学習するモデルをトレーニングします。モデルは、メル-スペクトログラムを入力として取るau-net cnnに基づいています。新しいデータを生成することにより、性別などの機密情報を非表示にすることが可能です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-16">
        <br>2020-06-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Comparing Representations for Audio Synthesis Using Generative
  Adversarial Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.SD/paper_2.html">
      Comparing Representations for Audio Synthesis Using Generative
  Adversarial Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      アーキテクチャはベンチマークのProgressive Growing Wasserstein GANに従います。モデルの特徴抽出、トレーニング、評価のコードはオンラインで入手できます。生成モデルを評価するための標準メトリックを使用して、生成されたマテリアルを定量的に評価し、トレーニング時間とサンプリング時間を比較します。 
[要旨] nsynthデータセットのサブセットで実験を行います。実験は完全に無条件の方法で実行します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-16">
        <br>2020-06-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ExSampling: a system for the real-time ensemble performance of
  field-recorded environmental sounds -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.SD/paper_3.html">
      ExSampling: a system for the real-time ensemble performance of
  field-recorded environmental sounds
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ディープラーニングによるAbleton Liveトラックへの自動サウンドマッピングにより、フィールドレコーディングをリアルタイムパフォーマンスに適用し、サウンドレコーダー、作曲家、パフォーマー間の相互作用を作成できます。ExSamplingを提案します。フィールド録音でサンプリングされた環境音のリアルタイムの音楽演奏。 
[ABSTRACT]ディープラーニングにより、フィールドレコーディングをリアルタイムパフォーマンスに適用し、サウンドレコーダー、作曲家、パフォーマー間の相互作用を作成できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br>2020-06-17
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Fine-grained Sentiment Controlled Text Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_0.html">
      Fine-grained Sentiment Controlled Text Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、このようなアプローチでは、属性の変化の度合いをより細かく制御できません。DE-VAEは、適切な可逆変換ネットワークを絡み合っていない感情空間から目的の絡み合いに学習することでコンテンツを維持しながら、属性としての感情のより良い制御を実現します。表現..制御されたテキスト生成のこれらの問題に対処するために、このホワイトペーパーでは、DE-VAEを提案します。これは、情報が豊富なエンタングル表現と属性固有のエンタングル解除表現の両方を異なる階層でキャプチャする階層フレームワークです。 
[ABSTRACT] de-vaeは、さまざまな階層で、情報が豊富なからみあい表現と属性固有のからみあい表現の両方をキャプチャします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br>2020-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Contrastive Learning for Weakly Supervised Phrase Grounding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_1.html">
      Contrastive Learning for Weakly Supervised Phrase Grounding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ネガでトレーニングすると、トレーニングデータからランダムにサンプリングされたネガよりも正確に$ \ sim10 \％$の正確なゲインが得られます。フレーズの接地は、画像領域とキャプションワードの関連付けの問題であり、視覚言語タスクの重要なコンポーネントです。 。画像とキャプションの単語間の相互情報の下限を最大化するために単語領域の注意を最適化することで、フレーズの基礎を学習できることを示します。 
[ABSTRACT]フレーズの基礎は、画像とキャプションワード間の相互情報の下限を最大化するために単語領域の注意を最適化することで学習できます。重要なアイデアは、言語モデルのガイド付き単語置換を通じて学習するための効果的なネガティブキャプションを構築することです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br>2020-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An Exploratory Study of Argumentative Writing by Young Students: A
  Transformer-based Approach -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_2.html">
      An Exploratory Study of Argumentative Writing by Young Students: A
  Transformer-based Approach
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      代わりに、大学の課題からの批評エッセイの大規模なコーパスで微調整されたトランスフォーマーベースのアーキテクチャー（BERTなど）は、はるかに優れています（F1スコアが20％以上向上）。詳細なドメイン知識を利用して特定する語彙および談話機能大学の課題に対する批判は存在しますが、若い学生のデータではうまく機能しません。システムのさまざまな構成のパフォーマンスを分析すると、子供の文章は、論拠のあるエッセイの標準的な談話構造を示さないものの、基本的なローカルより成熟したライターによる順次構造。 
[ABSTRACT]大学の学生は、推論の欠陥を特定して説明することに焦点を合わせて、プロンプトで提示された議論を批判するように求められました。詳細なドメイン知識を利用して大学の課題に対する批評を特定する語彙と談話の機能
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br>2020-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Automatically Ranked Russian Paraphrase Corpus for Text Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_3.html">
      Automatically Ranked Russian Paraphrase Corpus for Text Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの研究では、問題の解決策を提案します。新しい公的に利用可能な見出し言い換えコーパス（ParaPhraser Plus）を収集、ランク付け、評価し、Universal Transformerアーキテクチャを使用して、自動的にランク付けされたコーパスを手動で評価するテキスト生成実験を実行します。サイズ制限のために、これらのデータセットはエンドツーエンドのテキスト生成ソリューションにはほとんど適用できません。一方、言い換え生成には大量のトレーニングデータが必要です。 
[ABSTRACT]データは、ロシアのログインシステムの数に基づいています。これらは、標準、標準、標準、言い換え、コーパス、パラパラグに利用できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br>2020-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Tweet-based Dataset for Company-Level Stock Return Prediction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_4.html">
      A Tweet-based Dataset for Company-Level Stock Return Prediction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      データセット、スクリプト、モデルは、https：//github.com/ImperialNLP/stockreturnpred。で公開されています。また、さまざまなタイプの機能を使用する標準の機械学習アルゴリズムとマルチビュー学習ベースのアプローチを使用したベースラインも提供しています。 。私たちのデータセットは、英語のTwitterからの862、231のラベル付きインスタンスで構成され、85、176のラベル付きインスタンスのクリーンなサブセットをコミュニティにリリースします。 
[ABSTRACT]このデータセットでは、1日間、2日間、3日間、7日間の株価収益率に対するツイートベースの影響を分析できます。また、機械学習アルゴリズムとマルチビュー学習ベースのアプローチを使用してベースラインを提供します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br>2020-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Building Low-Resource NER Models Using Non-Speaker Annotation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_5.html">
      Building Low-Resource NER Models Using Non-Speaker Annotation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      NSの結果は、最新のコンテキスト表現に基づいて構築されたクロスリンガルメソッドと一貫して同等またはそれ以上であり、追加の努力でさらに優れたパフォーマンスを発揮する可能性があります。インドネシア語を使用して、注意深く制御されたアノテーション実験で不慣れな言語にアノテーションを付けるために、30人の参加者を募集します。ロシア語、およびターゲット言語としてのヒンディー語。私たちの結果は、非スピーカーアノテーターを使用すると、流暢なスピーカーのパフォーマンスに近づく、または匹敵する結果が得られることを示しています。 
[ABSTRACT]結果は一貫して同等またはそれ以上のクロスリンガルメソッドです。結果は、追加の労力でさらにパフォーマンスを向上させる可能性があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br>2020-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: VATEX: A Large-Scale, High-Quality Multilingual Dataset for
  Video-and-Language Research -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_6.html">
      VATEX: A Large-Scale, High-Quality Multilingual Dataset for
  Video-and-Language Research
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、他のビデオと言語の研究にVATEXを使用する可能性について説明します。VATEXデータセットでの広範な実験により、最初に、統合多言語モデルでは、ビデオの英語と中国語の両方の説明をより効率的に生成できないことがわかりますだけでなく、単一言語モデルよりもパフォーマンスが向上します。新しい大規模な多言語ビデオ記述データセット、VATEXを提示します。これには、41,250以上のビデオと825,000のキャプションが英語と中国語で含まれています。 
[ABSTRACT]また、vatexに基づくビデオと言語の研究について2つの用語を紹介します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-06">
        <br>2019-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Modeling subjective assessments of guilt in newspaper crime narratives -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_7.html">
      Modeling subjective assessments of guilt in newspaper crime narratives
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      したがって、SuspectGuiltは、言語の選択が主観的な罪悪感の判断にどのように影響するかについての豊富な画像を提供します。犯罪の報告は、広く知られている形式のジャーナリズムであり、国民の認識や社会政策を形作る力があります。これらのモデルは、テキストレベルの評価とスパンレベルの注釈から、ジャンルの事前トレーニングと共同監督の恩恵を受けることを示しています。 
[要約]犯罪報告の力と疑わしい新聞の使用は、犯罪行為の社会的影響に対処するためのツールとして使用される可能性があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br>2020-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ktrain: A Low-Code Library for Augmented Machine Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_8.html">
      ktrain: A Low-Code Library for Augmented Machine Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      機械学習をよりアクセスしやすく、適用しやすくする低コードのPythonライブラリであるktrainを紹介します。テキストデータ（テキスト分類、シーケンスタグ付け、オープンドメイン質問応答など）、ビジョンデータ（たとえば、画像分類）、およびグラフデータ（ノード分類、リンク予測など）の場合、ktrainはシンプルな統合インターフェースを提供し、わずか3または4つの「コマンド」またはコード行で幅広いタスクをすばやく解決できます。 TensorFlowおよび他の多くのライブラリ（トランスフォーマー、scikit-learn、stellargraphなど）のラッパーであり、洗練された最先端の機械学習モデルを両方の初心者が簡単に構築、トレーニング、検査、デプロイできるように設計されていますそして経験豊富な開業医。 
[ABSTRACT]洗練された最先端の機械学習モデルをシンプルにするように設計されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-19">
        <br>2020-04-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Causality Extraction based on Self-Attentive BiLSTM-CRF with Transferred
  Embeddings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_9.html">
      Causality Extraction based on Self-Attentive BiLSTM-CRF with Transferred
  Embeddings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      公開データセットでメソッドを評価し、実験結果は、ベースラインと比較して、このメソッドが大幅かつ一貫した改善を達成していることを示しています。データ不足の問題に対処するために、Flair埋め込みとも呼ばれるコンテキスト文字列埋め込みを転送します。タスクの大規模なコーパス。さらに、因果関係抽出のパフォーマンスを向上させるために、マルチヘッドの自己注意メカニズムをSCITEに導入して、因果関係のある単語間の依存関係を学習します。 
[要旨] bilstm-crfモデルをバックボーンとする神経因果性抽出器を提案します。候補因果ペアを抽出してそれらの関係を個別に特定することなく、原因と結果を直接抽出できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-16">
        <br>2019-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On the Learnability of Concepts: With Applications to Comparing Word
  Embedding Algorithms -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_10.html">
      On the Learnability of Concepts: With Applications to Comparing Word
  Embedding Algorithms
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最初にこの方法を使用して、事前学習済みの単語の埋め込みに関する概念の学習可能性を測定します。この概念を使用して、特定の概念の学習可能性を分析します。特定の概念の学習可能性を分析します。次に、固定コーパスとハイパーパラメータを使用したさまざまな埋め込みアルゴリズムの相対的なメリットを比較するために、仮説検定とROC曲線に基づいて、概念の学習可能性の統計分析を開発します。 
[要約]この概念を使用して、特定の概念の学習可能性を分析します。これらは、辞書内の各単語に関連付けられた座標です。これには、固定コーパスを使用した埋め込みアルゴリズムが含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br>2020-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Canonicalizing Open Knowledge Bases with Multi-Layered Meta-Graph Neural
  Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_11.html">
      Canonicalizing Open Knowledge Bases with Multi-Layered Meta-Graph Neural
  Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2種類の情報を多層グラフとして表現します。構造情報は、文、リレーショナルフレーズ、および名詞句のレイヤーにわたるリンクを形成します。意味情報は、各層の重み付けされた層内リンクを形成します。.多層ニューラルグラフ構造を通じて名詞句と関係句の表現を集約するグラフニューラルネットワークモデルを提案します。OpenKnowledgeの名詞句と関係句多くの場合、ベースは正規ではなく、冗長で曖昧な事実につながります。 
[ABSTRACT]この概念は、フレーズを分析することによって作成されました。これらには、どのタプルからの構造情報、どの文、および意味情報が含まれていました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br>2020-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving unsupervised neural aspect extraction for online discussions
  using out-of-domain classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_12.html">
      Improving unsupervised neural aspect extraction for online discussions
  using out-of-domain classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、データの準備中に、ドメイン内である可能性が低い文をフィルターで除外し、残りの文でニューラルモデルをトレーニングします。確率論的分類子をトレーニングして、ドメイン外のテキスト（外部データセット）と-domain texts（target dataset）..トピックの一貫性に対するセンテンスフィルタリングのプラスの効果は、フィルタリングされていないテキストでトレーニングされたアスペクト抽出モデルと比較して示されます。 
[ABSTRACT]アバエとドメイン内のテキストを区別するために確率的分類子をトレーニングします。トピックの一貫性に対するセンテンスフィルタリングのプラスの効果は、フィルタリングされていないテキストでトレーニングされたタスク抽出モデルと比較して示されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br>2020-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: De-Anonymizing Text by Fingerprinting Language Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_13.html">
      De-Anonymizing Text by Fingerprinting Language Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実行パスが機密入力に依存しないようにするなどの安全なコーディング手法は、ML開発者によってまだ採用されていません。次に、適切なサイドチャネル（キャッシュアクセスなど）を介してこれらのフィンガープリントを測定することにより、攻撃者が入力されたテキストを推測する方法を示します回）、この攻撃が匿名テキストの匿名化にどのように役立つかを説明し、防御について議論します。次のようなアプリケーションで使用される、核抽出（テキスト生成の一般的なアプローチ）を調査することで、MLシステムのコードセキュリティの研究を開始します。自動補完---ユーザーが入力したテキストを無意識のうちにリークします。 
[ABSTRACT]安全なコーディング手法はまだ開発者によって採用されていません。この研究は安全な安全な学習システムの保護に役立つ可能性があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br>2020-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploiting Review Neighbors for Contextualized Helpfulness Prediction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_14.html">
      Exploiting Review Neighbors for Contextualized Helpfulness Prediction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      （3）レビューの最近傍5つまでを同等に検討すると、通常は弱いですが許容できる予測結果が生成されます。広範な実験により、NAPの有効性と現在のレビューに対する連続した近隣の影響が確認されます。レビューごとに、NAPは3つのタイプのネイバー選択：その先行、後続、および周囲のネイバー。 
[要約]ほとんどの研究は、レビューの有用性は自己制御的であると想定しています。しかし、大多数の研究は、有用なツールが自己制御的であるとは想定していません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br>2020-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Iterative Edit-Based Unsupervised Sentence Simplification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_15.html">
      Iterative Edit-Based Unsupervised Sentence Simplification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      NewselaおよびWikiLargeデータセットでの実験は、私たちのアプローチが最先端の教師付きアプローチとほぼ同じくらい効果的であることを示しています。次に、複雑な文に対して単語レベルおよびフレーズレベルの編集を繰り返し実行します。以前のアプローチと比較して、モデル並列トレーニングセットは必要ありませんが、より制御可能で解釈可能です。 
[要約]私たちのモデルは、流暢さ、単純さ、および意味を含むスコアリング関数によって導かれます。スーパーセント。私たちのモデルは、並列トレーニングセットを必要としませんが、より制御可能で解釈可能です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br>2020-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CO-Search: COVID-19 Information Retrieval with Semantic Search, Question
  Answering, and Abstractive Summarization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_16.html">
      CO-Search: COVID-19 Information Retrieval with Semantic Search, Question
  Answering, and Abstractive Summarization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ランカーはマルチホップの質問応答モジュールで構成され、マルチパラグラフの抽象サマライザがレトリーバーのスコアを調整します。COVID-19グローバルパンデミックにより、病気を理解、追跡、緩和する国際的な取り組みが行われ、科学分野全体にわたるCOVID-19およびSARS-CoV-2関連の出版物の重要なコーパス。CO-Searchは、いくつかの主要なメトリックにわたって、第1ラウンドと第2ラウンドのデータセットで最高のパフォーマンスを取得します：正規化された割引累積ゲイン、精度、平均平均精度、およびバイナリ設定。 
[要約] 2020年5月の時点で、covidを通じて128,000のコロナウイルス関連の出版物が収集されました-19のオープンな研究データセットの課題
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br>2020-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Hybrid Natural Language Generation System Integrating Rules and Deep
  Learning Algorithms -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_17.html">
      A Hybrid Natural Language Generation System Integrating Rules and Deep
  Learning Algorithms
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーでは、ルールベースのアプローチと最新のディープラーニングアルゴリズムの両方のメリットを組み合わせた、強化された自然言語生成システムを提案し、生成されたテキストコンテンツが俊敏な人間のライティングスタイルとそのコンテンツロジックを示すことができる程度までパフォーマンスを向上させます。高度に制御可能です。自然言語処理のパフォーマンスを包括的かつ正確に測定するために、HMCUと呼ばれる新しいアプローチも考えられます。 
[ABSTRACT]自然言語処理のパフォーマンスを測定するために開発された新しいシステム。新しいシステムには、hmlabと呼ばれる新しいアプローチも含まれています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br>2020-06-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SEEK: Segmented Embedding of Knowledge Graphs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_18.html">
      SEEK: Segmented Embedding of Knowledge Graphs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ソースコードとデータは\ url {https://github.com/Wentao-Xu/SEEK}にあります。スコアリング関数の一般的でエレガントな設計により、フレームワークは多くの有名な既存のメソッドを組み込むことができます。特別なケースとして。さらに、公開ベンチマークでの広範な実験は、私たちのフレームワークの効率と効果を実証しています。 
[ABSTRACT]ナレッジグラフの埋め込みのための既存の方法では、モデルの複雑さとモデルの表現力の間でgitmoのトレードオフを作成できません。新しいフレームワークはスコアリング関数の設計に焦点を当て、2つの重要な特性を強調します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-02">
        <br>2020-05-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Conversational Neuro-Symbolic Commonsense Reasoning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_19.html">
      Conversational Neuro-Symbolic Commonsense Reasoning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このタスクのベンチマークデータセットをリリースします。これは、人間から収集され、常識的な仮定で注釈が付けられています。このようなif-then-becauseコマンドは、ユーザーが会話型エージェントに指示するときに特に重要です。たとえば、コマンド「私は仕事に遅れたくないので私を早く起こしてください」話者は、交通のスローダウンを引き起こすのに十分に雪が降らなければならないという暗黙の仮定を推測するためにリスナーの常識的な推論に依存します。 
[ABSTRACT]新しい常識推論ベンチマークを提案します。このツールは、自然言語コマンドが暗示する常識の推定を明らかにするためのものです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br>2020-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Mucko: Multi-Layer Cross-Modal Knowledge Reasoning for Fact-based Visual
  Question Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_20.html">
      Mucko: Multi-Layer Cross-Modal Knowledge Reasoning for Fact-based Visual
  Question Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      多層グラフ表現に加えて、モダリティ対応の異種グラフ畳み込みネットワークを提案し、特定の質問に最も関連するさまざまな層から証拠をキャプチャします。このプロセスを複数回スタックすることにより、モデルは反復推論を実行し、予測しますすべての質問指向の証拠を分析することによる最適な答え。コードはhttps://github.com/astro-zihao/muckoで入手できます。 
[要約]視覚的、意味的、および事実上の機能にはfvqaソリューションが必要です。これらは、各モーダルからの証拠を決定するマルチモーダルグラフの畳み込みに基づいています。これにより、新しいタスクが作成されます-fihタスクの最先端のパフォーマンス
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-16">
        <br>2020-06-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: $R^3$: Reverse, Retrieve, and Rank for Sarcasm Generation with
  Commonsense Knowledge -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/cs.CL/paper_21.html">
      $R^3$: Reverse, Retrieve, and Rank for Sarcasm Generation with
  Commonsense Knowledge
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      皮肉の生成に関するこれまでの研究は、主に文脈の不一致に焦点を当てていますが、常識的な知識に基づいて価数の逆転と意味の不一致を組み合わせると、より質の高い皮肉が生成されることを示しています。人間の評価によると、私たちのシステムは、人間の注釈者よりも皮肉を生成するのが34％です。 、および強化されたハイブリッドベースラインよりも90％優れています。この手法では、検索と編集のフレームワークを使用して、皮肉の2つの主要な特性をインスタンス化します：共有の常識または世界の知識を含む可能性のあるコンテキストとの価数の逆転と意味の不一致スピーカーとリスナーの間。 
[ABSTRACT]私たちの方法は、検索と編集のフレームワークを使用して、sarcasmの2つの主要な特性をインスタンス化します。価数の逆転とセマンティックのコンテキストの不一致には、話し手と聞き手の共通の常識または世界の知識が含まれます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Visual Attention for Musical Instrument Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/eess.AS/paper_0.html">
      Visual Attention for Musical Instrument Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このプロジェクトでは、弱めにラベル付けされたデータを使用した楽器認識のパフォーマンスを向上させるために、音色-時間的感覚での注意メカニズムの使用をさらに検討します。最初のアプローチは、スライドに注意メカニズムを適用します。 -ウィンドウパラダイム。各時間-時間的「インスタンス」に基づく予測は、最終的な予測を生成するために集約する前に注意の重みが与えられます。2番目のアプローチは、ネットワークがパーツのみに対応する視覚的注意の反復モデルに基づいています。限られた数の「垣間見る」を考慮して、スペクトログラムの次の点に注意してどこに注意を向けるかを決定します。 
[ABSTRACT]このタスクへの2つの異なるアプローチが検討されました。1つの理論は、いくつかの「部分的な垣間見る」に基づいています。他の作品は、楽器の認識パフォーマンスを改善する上でのピッチと音色の役割を示唆しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br>2020-06-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Adversarial representation learning for private speech generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/eess.AS/paper_1.html">
      Adversarial representation learning for private speech generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      モデルは2つのステップでトレーニングされます。最初にスペクトログラムドメインの機密情報をフィルター処理し、次にフィルター処理された情報とは無関係に新しいプライベート情報を生成します。組織、企業、国全体のさまざまな設定でデータが収集されます。 、ユーザーのプライバシーの需要が高まっています。この作業では、音声データの特定の機密属性を難読化することを学習する生成的敵対的ネットワーク（GAN）に基づくモデルを提示します。 
[ABSTRACT]データ内の機密情報を非表示にすることを学習するモデルをトレーニングします。モデルは、メル-スペクトログラムを入力として取るau-net cnnに基づいています。新しいデータを生成することにより、性別などの機密情報を非表示にすることが可能です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-16">
        <br>2020-06-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Comparing Representations for Audio Synthesis Using Generative
  Adversarial Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/eess.AS/paper_2.html">
      Comparing Representations for Audio Synthesis Using Generative
  Adversarial Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      アーキテクチャはベンチマークProgressive Growing Wasserstein GANに従います。完全に無条件の方法で実験を実行し、ピッチ情報でネットワークを調整します。生成モデルを評価するための標準メトリックを使用して、生成された材料を定量的に評価し、比較します。トレーニングとサンプリング時間。 
[要旨] nsynthデータセットのサブセットで実験を行います。実験は完全に無条件の方法で実行します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-16">
        <br>2020-06-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ExSampling: a system for the real-time ensemble performance of
  field-recorded environmental sounds -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/eess.AS/paper_3.html">
      ExSampling: a system for the real-time ensemble performance of
  field-recorded environmental sounds
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ディープラーニングによるAbleton Liveトラックへの自動サウンドマッピングにより、フィールドレコーディングをリアルタイムパフォーマンスに適用し、サウンドレコーダー、作曲家、パフォーマー間の相互作用を作成できます。ExSamplingを提案します。フィールド録音でサンプリングされた環境音のリアルタイムの音楽演奏。 
[ABSTRACT]ディープラーニングにより、フィールドレコーディングをリアルタイムパフォーマンスに適用し、サウンドレコーダー、作曲家、パフォーマー間の相互作用を作成できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br>2020-06-17
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Mast cells participate in the development of diastolic dysfunction in diabetic obese mice -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-18/biorxiv.physiology/paper_0.html">
      Mast cells participate in the development of diastolic dysfunction in diabetic obese mice
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結論：マスト細胞は、心臓微小血管疾患と拡張機能障害の発症に重要な役割を果たします。合理的：駆出率の保持（HFpEF）による心不全は、疫学的問題として増大しています。これらのマウスでは、拡張末期圧（EDP）が上昇しています。拡張機能障害の兆候は、血管漏出、内皮細胞の活性化、白血球の浸潤に関連しています。 
[要約]科学者は拡張機能障害のモデルとしてレプチン受容体欠損（leprdb / db）雌マウスを使用
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br>2020-06-17
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
