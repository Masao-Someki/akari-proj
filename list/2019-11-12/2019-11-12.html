<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<title>Akari-2019-11-12の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
  <div class="header-logo">
    <a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
  </div>
</header>
<input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">

<div class="menubar">
<span class="bar"></span>
<span class="bar"></span>
<span class="bar"></span>
</div>

<ul>
<li><a id="home" href="../../index.html">Home</a></li>
<li><a id="about" href="../../teamAkariとは.html">About</a></li>
<li><a id="contact" href="../../contact.html">Contact</a></li>
<li><a id="contact" href="../../list/newest.html">New Papers</a></li>
<li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
</ul>

</label>
<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Learning with Learned Loss Function: Speech Enhancement with Quality-Net
  to Improve Perceptual Evaluation of Speech Quality -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.SD/paper_0.html">
      Learning with Learned Loss Function: Speech Enhancement with Quality-Net
  to Improve Perceptual Evaluation of Speech Quality
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、学習したサロゲート関数がPESQスコア（MSE損失でトレーニングされた結果と比較して0.18ポイントの増加）をさらに高め、音声明瞭度を維持するように強化モデルを導くことができることを示します。近似化されたPESQ関数を備えた強化モデルは、微分可能であり、トレーニングデータから学習されます。人間の知覚に関連する目的関数を利用して音声強化モデルをトレーニングすることは、最近人気のトピックになりました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-06">
        <br>2019-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Diversity by Phonetics and its Application in Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.SD/paper_1.html">
      Diversity by Phonetics and its Application in Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      言語ペアとデータセット全体で大幅かつ一貫した改善を達成します：中タスクIWSLT&#39;17ではフランス語-英語、ドイツ語-英語、中国語-英語、大タスクWMT&#39;18バイオではフランス語-英語、最大4 BLEUポイント最新技術。音声符号化は私たちの貢献の最初の部分であり、2番目はこの改善の理由を理解することを目的とする理論です。私たちはこれをサポートする仮説の経験的幾何学的検証を実施します圧倒的な証拠を取得します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Hierarchical Latent Vector Model for Learning Long-Term Structure in
  Music -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.SD/paper_2.html">
      A Hierarchical Latent Vector Model for Learning Long-Term Structure in
  Music
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このアーキテクチャを音符のモデリングシーケンスに適用すると、「フラット」ベースラインモデルよりも劇的に優れたサンプリング、補間、再構成のパフォーマンスを発揮することがわかります。この問題に対処するため、階層デコーダーの使用を提案します。入力のサブシーケンスの埋め込みと、これらの埋め込みを使用して各サブシーケンスを個別に生成します。「MusicVAE」の実装は、http：//g.co/magenta/musicvae-codeでオンラインで入手できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-03-13">
        <br>2018-03-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Training for Deep Speech Source Separation with
  Kullback-Leibler Divergence Based Probabilistic Loss Function -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.SD/paper_3.html">
      Unsupervised Training for Deep Speech Source Separation with
  Kullback-Leibler Divergence Based Probabilistic Loss Function
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      音声ソースの分離は、分離エラーへの過剰適合を回避するために確率的な方法で実行されます。マイク入力信号の統計モデルとして、残響および背景ノイズサブモデルを含む時変空間共分散行列（SCM）モデルを採用します。残響と背景ノイズに対するロバスト性を実現するために。複数の中間変数があるため、単一の中間変数を評価する損失関数は適用できません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Visualizing and Understanding Self-attention based Music Tagging -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.SD/paper_4.html">
      Visualizing and Understanding Self-attention based Music Tagging
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      パフォーマンスだけでなく、より良い解釈性を促進することもできます。最近、私たちは自己注意に基づく音楽タグ付けモデルを提案しました。音楽情報検索における従来のディープアーキテクチャのほとんどとは異なります。画像として、提案された自己注意ベースのモデルは、音楽を個々のオーディオイベントの時間シーケンスと見なそうとしました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Data Efficient Direct Speech-to-Text Translation with Modality Agnostic
  Meta-Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.SD/paper_5.html">
      Data Efficient Direct Speech-to-Text Translation with Modality Agnostic
  Meta-Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      多言語音声翻訳コーパス（MuST-C）からの英語-ドイツ語（En-De）および英語-フランス語（En-Fr）言語ペアのSTタスクに対して提案されたメタ学習アプローチを評価します。メタ学習フェーズで、モデルのパラメーターは、膨大な量の音声転写（例：英語ASR）およびテキスト翻訳（例：英語-ドイツ語MT）にさらされています。これまでの研究では、上記の難しさを克服する転送学習アプローチの使用が提案されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: BP-Transformer: Modelling Long-Range Context via Binary Partitioning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_0.html">
      BP-Transformer: Modelling Long-Range Context via Binary Partitioning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      BPTは、計算の複雑さとモデルの容量のバランスが取れています。スパースアテンション用のコード、ハイパーパラメーター、CUDAカーネルはPyTorchで使用できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Attending to Entities for Better Text Understanding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_1.html">
      Attending to Entities for Better Text Understanding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、表面レベルのキューが十分でない複雑で長距離の推論を必要とするタスクでは、事前に訓練されたモデルと人間のパフォーマンスの間に大きなギャップがまだあります.. Strubell et al .. 2017）最終タスクの中で、そのようなモデルは最新の結果を達成し、人間のパフォーマンスに近づいています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Interactive Matching Network for Multi-Turn Response Selection in
  Retrieval-Based Chatbots -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_2.html">
      Interactive Matching Network for Multi-Turn Response Selection in
  Retrieval-Based Chatbots
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      4つのパブリックデータセットでの実験は、IMNがすべてのメトリックでベースラインモデルよりも優れていることを示し、新しい最先端のパフォーマンスを達成し、マルチターン応答選択のドメイン間の互換性を実証します。階層的に文をエンコードし、アテンションメカニズムと集約することにより、より記述的な表現を生成することができるように設計されています。最後に、マルチターンコンテキスト全体と応答候補間の双方向の相互作用を計算して、それらの間の一致情報を導き出します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-01-07">
        <br>2019-01-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Sequence-to-Set Semantic Tagging: End-to-End Multi-label Prediction
  using Neural Attention for Complex Query Reformulation and Automated Text
  Categorization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_3.html">
      Sequence-to-Set Semantic Tagging: End-to-End Multi-label Prediction
  using Neural Attention for Complex Query Reformulation and Automated Text
  Categorization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、現在のコンテキストで意味のある候補概念間の隠された関連付けは、単一のドキュメント内ではなく、コレクション内に、代替の字句形式を介して存在する場合があります。 UMLSのようなオントロジーなどの事実ベースまたはルールベースの知識ソースで発生するエンティティまたは標準的な概念形式を明示的に参照していない、生物医学文献を含む証拠ベースの医学（EBM）などのクエリシナリオ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to Order Sub-questions for Complex Question Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_4.html">
      Learning to Order Sub-questions for Complex Question Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      既存の作業はこの戦略に従っていますが、これらのサブ質問の回答順序を最適化しようとはしていません。この論文では、動的に決定するポリシーを学習できる複雑な質問に答える新しい強化学習（RL）アプローチを提案します推論の各段階でどのサブ質問に回答する必要があります。その結果、サブ質問は任意の順序で回答され、検索スペースが大きくなり、回答を見逃すリスクが高くなります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Text classification with pixel embedding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_5.html">
      Text classification with pixel embedding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      つまり、3次元カーネルを単語シーケンス上でスライドさせるたびに、畳み込みは$ n $単語画像をカバーし、スカラーを出力します。畳み込みカーネルサイズの最初の2次元は、単語画像のサイズに等しく、カーネルサイズの最後の次元は$ n $です。具体的には、3次元のテキストテンソルに3次元の畳み込みカーネルを適用します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Diversity by Phonetics and its Application in Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_6.html">
      Diversity by Phonetics and its Application in Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      仮説の実証的な幾何学的検証を実施して、圧倒的な証拠を得ます。仮説は、音声符号化が意味的に多様な文の違いを強調する手順を符号化するため、NMTに役立つと述べています。機械翻訳（NMT）。これにより、トレーニングとテスト中に、入力とともに音声エンコードとそのようなエンコードのバリアントが提供されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: DialogAct2Vec: Towards End-to-End Dialogue Agent by Multi-Task
  Representation Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_7.html">
      DialogAct2Vec: Towards End-to-End Dialogue Agent by Multi-Task
  Representation Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このモデルでは、システム設計への介入に手作業がほとんど必要ありません。マルチタスク学習により、表現学習の有効性が大幅に向上することがわかります。たとえば、システム設計中のルール定義とデータラベリングは、手作業が非常に多く、 to-sequenceメソッドは、片側の発話情報のみをモデル化します。レストラン予約用のパブリックデータセットに関する広範な実験により、提案された方法は、行為予測タスクと発話予測の両方の最新のベースラインに対する大幅な改善につながることが示されています仕事。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Word Sense Disambiguation using Knowledge-based Word Similarity -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_8.html">
      Word Sense Disambiguation using Knowledge-based Word Similarity
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2つ目の方法は、単語ベクトル表現の類似性に基づいてあいまいな単語を分析するために、テキストから文脈上の単語を抽出する方法を提案します。自然言語処理では、単語の意味の曖昧性解消（WSD）は、特定のコンテキストで正しい単語の意味を識別することに関する未解決の問題です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: What the Vec? Towards Probabilistically Grounded Embeddings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_9.html">
      What the Vec? Towards Probabilistically Grounded Embeddings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、W2Vは最近、いくつかの主要なアルゴリズムを支えるグラフ埋め込みの分野で採用されています。それらの埋め込みは広く使用されており、さまざまな自然言語処理タスクで良好に機能します。適切な投影の下で低次元の単語埋め込みにエンコードされている類似性や言い換えなどの単語の関係。W2VとGloVeの埋め込みが機能する理由を理論的に説明します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-05-30">
        <br>2018-05-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Align, Mask and Select: A Simple Method for Incorporating Commonsense
  Knowledge into Language Representation Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_10.html">
      Align, Mask and Select: A Simple Method for Incorporating Commonsense
  Knowledge into Language Representation Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      データセットは、提案された &quot;align、mask、and select&quot;（AMS）メソッドにより自動的に作成されます。さまざまな自然言語処理（NLP）タスクのパフォーマンスを一貫して改善するために微調整できます。ただし、既存の事前学習済み言語表現モデルでは、常識的な知識やその他の知識を明示的に組み込むことはほとんどありません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-19">
        <br>2019-08-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Meta Answering for Machine Reading -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_11.html">
      Meta Answering for Machine Reading
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      同様に、単純なマシンメタアンサーは環境よりも優れており、Natural Questionsデータセットの精度と再現性の両方を向上させます。回答の周りのテキストをほんの少しだけ使用することで、人間はマシンリーダーより優れて再現性を向上させることができます。フレームワークを調査しますメタ質問応答システムがブラックボックス環境と相互作用する、実世界の情報探索問題に触発された機械読み取り用。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Are Girls Neko or Shōjo? Cross-Lingual Alignment of Non-Isomorphic
  Embeddings with Iterative Normalization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_12.html">
      Are Girls Neko or Shōjo? Cross-Lingual Alignment of Non-Isomorphic
  Embeddings with Iterative Normalization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      非同型ペアの場合、私たちの方法（反復正規化）は、（1）個々の単語ベクトルが単位長であり、（2）各言語の平均ベクトルがゼロであることを同時に実施することにより、単一言語の埋め込みを変換して直交整列を容易にします。埋め込み（CLWE）は多くの多言語自然言語処理システムの根底にあり、多くの場合、事前に訓練された単一言語埋め込みの直交変換を介しています。ただし、直交マッピングは埋め込みが自然に同型の言語ペアでのみ機能します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-04">
        <br>2019-06-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Deep Contextualized Self-training for Low Resource Dependency Parsing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_13.html">
      Deep Contextualized Self-training for Low Resource Dependency Parsing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      低リソースのドメイン内およびクロスドメイン設定の両方で、複数の言語で実験を実施し、DCSTが従来のセルフトレーニングおよび最近の半教師ありトレーニング方法よりも大幅に優れていることを実証します。パーサーを独自の出力でトレーニングすることにより、この注釈のボトルネックを軽減するトレーニングアルゴリズムこれらのモデルは、ゲーティングメカニズムを通じてベースパーサーを使用します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: RaKUn: Rank-based Keyword extraction via Unsupervised learning and Meta
  vertex aggregation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_14.html">
      RaKUn: Rank-based Keyword extraction via Unsupervised learning and Meta
  vertex aggregation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      メタ頂点（既存の頂点の集合体）と体系的な冗長フィルターを導入すると、提案された方法は、14の異なるデータセットでのキーワード抽出タスクの最新技術と同等の性能を発揮します。ドキュメントの視覚化に使用します。特定のテキストから派生したグラフに適用されるグラフ理論的尺度である負荷中心性を使用して、キーワードを効率的に識別およびランク付けする方法を検討します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-15">
        <br>2019-07-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A neural joint model for Vietnamese word segmentation, POS tagging and
  dependency parsing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_15.html">
      A neural joint model for Vietnamese word segmentation, POS tagging and
  dependency parsing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      特に、私たちのモデルは、BISTグラフベースの依存性パーサー（KiperwasserとGoldberg、2016）を、単語のセグメンテーションとPOSタグ付けのためにBiLSTM-CRFベースのニューラルレイヤー（Huang et al。、2015）で拡張します。結果は、我々の共同モデルが最先端の、または競争力のあるパフォーマンスを獲得することを示しています。我々は、ベトナム語の共同単語セグメンテーション、品詞（POS）タグ付け、および依存性解析のための最初のマルチタスク学習モデルを提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-30">
        <br>2018-12-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Keep it Consistent: Topic-Aware Storytelling from an Image Stream via
  Iterative Multi-agent Communication -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_16.html">
      Keep it Consistent: Topic-Aware Storytelling from an Image Stream via
  Iterative Multi-agent Communication
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ビジュアルストーリーテリングは、一連の画像から物語の段落を自動的に生成することを目的としています。2つの生成タスクを結合するために、トピック記述ジェネレーターとストーリージェネレーターを2つのエージェントと見なし、同時に学習するマルチエージェント通信フレームワークを提案します反復更新メカニズムを介します。その後、トピックの説明のガイダンスを使用してストーリーが構築されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Zero-shot Cross-lingual Dialogue Systems with Transferable Latent
  Variables -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_17.html">
      Zero-shot Cross-lingual Dialogue Systems with Transferable Latent
  Variables
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、実験結果は、使用する外部リソースがはるかに少ないにもかかわらず、現在の最先端モデルと比較して、モデルが自然言語理解タスク（つまり、意図検出とスロット充填）の適応パフォーマンスを向上させることを示しています。ゼロショットシナリオ。この課題に取り組むために、最初に非常に少数の並列単語ペアのセットを使用して、整列した言語間の単語レベルの表現を調整します。多言語タスク指向のダイアログシステムに対する急増する要求にもかかわらずAlexa、Google Home）、多言語または多言語シナリオで行われた研究は少なくなっています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Wasserstein distances for evaluating cross-lingual embeddings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_18.html">
      Wasserstein distances for evaluating cross-lingual embeddings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      バイリンガルの語彙帰納法などの従来の埋め込みの評価方法と比較して、このアプローチの利点について議論します。これらの問題でワッサーシュタイン距離を使用すると、いくつかの強力なベースラインよりも優れており、現状と同等のパフォーマンスを発揮することが示唆されますアートモデル。Wasserstein距離のファミリを使用して、言語間のドキュメント検索および言語間のドキュメント分類の問題を解決する方法を示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Comprehensive Exploration on WikiSQL with Table-Aware Word
  Contextualization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_19.html">
      A Comprehensive Exploration on WikiSQL with Table-Aware Word
  Contextualization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      特に、モデルのパフォーマンスがWikiSQLの上限に近いことを示しています。評価エラーの大部分は誤った注釈によるものであり、モデルの実行精度はすでに人間のパフォーマンスを1.3％超えています。 seq2seqデコーダーを使用したBERTはタスクのパフォーマンスを低下させ、このような事前学習済みの大きなモデルを使用する場合は注意深い設計の重要性を示していることに注意してください。将来のNL2SQLデータセットとモデル。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-02-04">
        <br>2019-02-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A hybrid text normalization system using multi-head self-attention for
  mandarin -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_20.html">
      A hybrid text normalization system using multi-head self-attention for
  mandarin
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      全体的に、システムのパフォーマンスは文レベルで1.5％以上改善され、さらに改善される可能性があります。このペーパーには、データセットの不均衡なパターン分布に対処するさまざまな試みも含まれています。最近の研究からの神経モデルによって動機付けられており、私たちの内部ニュースコーパスでより良いパフォーマンスを持っています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: EntEval: A Holistic Evaluation Benchmark for Entity Representations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_21.html">
      EntEval: A Holistic Evaluation Benchmark for Entity Representations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、EntEvalを提案します。エンティティタイピング、エンティティ類似性、エンティティ関係予測、エンティティの曖昧性解消など、エンティティの非自明な理解を必要とするさまざまなタスクのテストスイートです。最先端の事前学習済み言語モデルであり、複数のEntEvalタスクの強力なベースラインを改善することを示しています。それらの重要性にもかかわらず、エンティティ表現の全体的な品質を評価する標準ベンチマークはありません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-31">
        <br>2019-08-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: NegBERT: A Transfer Learning Approach for Negation Detection and Scope
  Resolution -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_22.html">
      NegBERT: A Transfer Learning Approach for Negation Detection and Scope
  Resolution
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      NegBERTと呼ばれるこのモデルは、Sherlockデータセットで92.36、BioScope Abstractsで94.53、BioScope Full Papersで91.24、SFUデータセットで89.94のスコープ解決でトークンレベルF1スコアを達成し、以前の状態を上回る長年にわたって、この問題に対処するために、単純なルールベースのシステム、機械学習分類器、条件付きランダムフィールドモデル、CNN、さらに最近ではBiLSTMなど、複数のアプローチが検討されてきました。言語、およびテキストからの情報抽出の主要コンポーネント。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Leveraging Dependency Forest for Neural Medical Relation Extraction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_23.html">
      Leveraging Dependency Forest for Neural Medical Relation Extraction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このタスクでは、依存関係構文が重要な機能のソースとして認識されています。フォレストには多くの可能な決定が含まれているため、リコールは高くなりますが、1ベスト出力に比べてノイズが多くなります。精度が比較的低いため、有用性が低下しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Decompressing Knowledge Graph Representations for Link Prediction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_24.html">
      Decompressing Knowledge Graph Representations for Link Prediction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、エンティティと関係の埋め込みは、まず関数を解凍することにより、より表現力豊かで堅牢な空間に解凍され、次に知識グラフ埋め込みモデルがこの新しい機能空間でトレーニングされます。さらに、DeComと比較して、埋め込みが明示的に増加することも示します特に、RESCAL + DeComは、すべての評価指標にわたってFB15k-237ベンチマークで最先端のパフォーマンスを達成します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer
  Sentence Selection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_25.html">
      TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer
  Sentence Selection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのアプローチは、2つの有名なベンチマークであるWikiQAとTREC-QAで最先端を確立し、MAPスコアはそれぞれ92％と94.3％を達成しました。これは、過去最高の83.4％と87.5％を大きく上回り、最近の作業.. TANDAは、より安定した堅牢なモデルを生成し、最適なハイパーパラメーターを選択するために必要な労力を削減することを経験的に示しています。 。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Data Efficient Direct Speech-to-Text Translation with Modality Agnostic
  Meta-Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_26.html">
      Data Efficient Direct Speech-to-Text Translation with Modality Agnostic
  Meta-Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      以前の研究では、上記の困難を克服するために転送学習アプローチの使用が提案されています。ただし、STタスクの大量の並列データの収集は、ASRおよびMTタスクと比較して困難です。ただし、これらのモデルのパラメーターは個別に更新されます次の最適なソリューションにつながる可能性のある各タスクの。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A unified sequence-to-sequence front-end model for Mandarin
  text-to-speech synthesis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/cs.CL/paper_27.html">
      A unified sequence-to-sequence front-end model for Mandarin
  text-to-speech synthesis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、TacotronとWaveRNNで統合フロントエンドを実装して、マンダリンTTSシステムを構築しました。それによる合成音声は、パイプラインベースのフロントエンド（4.37）と人間の録音（4.49）に匹敵するMOS（4.38）を取得しました）..この論文では、生のテキストを直接言語機能に変換するマンダリンTTSの統一されたシーケンス間フロントエンドモデルを提案しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Learning with Learned Loss Function: Speech Enhancement with Quality-Net
  to Improve Perceptual Evaluation of Speech Quality -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/eess.AS/paper_0.html">
      Learning with Learned Loss Function: Speech Enhancement with Quality-Net
  to Improve Perceptual Evaluation of Speech Quality
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、学習したサロゲート関数が強化モデルを導き、PESQスコアをさらに向上させ（MSE損失でトレーニングした結果と比較して0.18ポイント増加）、音声明瞭度を維持できることを示しています。知覚に関連するメトリックは、音声品質（PESQ）の知覚評価であり、人間によって評価された品質スコアと高い相関関係を提供することが証明されています。この研究では、近似PESQ関数を使用して拡張モデルを最適化することを提案します、これは微分可能であり、トレーニングデータから学習されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-06">
        <br>2019-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Diversity by Phonetics and its Application in Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/eess.AS/paper_1.html">
      Diversity by Phonetics and its Application in Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      言語ペアとデータセット全体で大幅かつ一貫した改善を達成します：中タスクIWSLT&#39;17ではフランス語-英語、ドイツ語-英語、中国語-英語、大タスクWMT&#39;18バイオではフランス語-英語、最大4 BLEUポイント最先端技術。圧倒的な証拠を得るために、仮説の経験的幾何学的検証を実施します。その後、3番目の貢献として、理論に基づいて、仮説の学習中に活用する人工的なメカニズムを開発します。 （および検証済み）効果音声学。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Hierarchical Latent Vector Model for Learning Long-Term Structure in
  Music -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/eess.AS/paper_2.html">
      A Hierarchical Latent Vector Model for Learning Long-Term Structure in
  Music
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このアーキテクチャを音符のシーケンスのモデリングに適用すると、「フラット」ベースラインモデルよりも劇的に優れたサンプリング、補間、再構成パフォーマンスを示すことがわかります。この構造により、モデルは潜在コードを利用して、 「これは、再発するVAEの問題のままです。.「MusicVAE」の実装は、http：//g.co/magenta/musicvae-codeでオンラインで入手できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-03-13">
        <br>2018-03-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Training for Deep Speech Source Separation with
  Kullback-Leibler Divergence Based Probabilistic Loss Function -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/eess.AS/paper_3.html">
      Unsupervised Training for Deep Speech Source Separation with
  Kullback-Leibler Divergence Based Probabilistic Loss Function
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      マイク入力信号の統計モデルとして、残響とバックグラウンドノイズのサブモデルを含む時変空間共分散行列（SCM）モデルを採用し、残響とバックグラウンドノイズに対する堅牢性を実現しています。複数の中間変数があるため、損失単一の中間変数を評価する関数は適用されません。この論文では、クリーンな信号が利用できない条件下で訓練されるディープニューラルネットワーク（DNN）によるマルチチャネル音声ソース分離を提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Feedback Recurrent AutoEncoder -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/eess.AS/paper_4.html">
      Feedback Recurrent AutoEncoder
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、潜在空間に学習済みの事前分布を追加し、エントロピーコーダーを使用することにより、さらに低い可変ビットレートを実現できることを示します。音声スペクトログラム圧縮におけるその有効性を実証します。強力なニューラルボコーダーは、低い固定ビットレートで高品質の音声波形を生成できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Visualizing and Understanding Self-attention based Music Tagging -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/eess.AS/paper_5.html">
      Visualizing and Understanding Self-attention based Music Tagging
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、私たちは自己注意に基づく音楽タグ付けモデルを提案しました。パフォーマンスだけでなく、より良い解釈を容易にすることもできます。音楽情報検索における従来のディープアーキテクチャのほとんどとは異なります。画像として、提案された自己注意ベースのモデルは、音楽を個々のオーディオイベントの時間シーケンスと見なそうとしました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Data Efficient Direct Speech-to-Text Translation with Modality Agnostic
  Meta-Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/eess.AS/paper_6.html">
      Data Efficient Direct Speech-to-Text Translation with Modality Agnostic
  Meta-Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、STタスクの大量の並列データを収集することは、ASRおよびMTタスクと比較して困難です。以前の研究では、上記の困難を克服するための転送学習アプローチの使用が提案されています。次の最適なソリューションにつながる可能性のある各タスクの。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Sleep time, social jetlag and intelligence: biology or work timing? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/biorxiv.physiology/paper_0.html">
      Sleep time, social jetlag and intelligence: biology or work timing?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      クロノタイプに違いは見られず、就業日の高IQ者の遅い睡眠タイミングは、遅い就業時間によって完全に説明されました。就業日中の習慣的な睡眠タイミングと休業日、就業時間との関連を調査しました私たちの結果は、より高いIQを持つ人々のより遅い睡眠のタイミングは生理学的な違いによるのではなく、より遅いまたはより柔軟な仕事のスケジュールによることを示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Stress-induced myonectin improves glucose homeostasis by inhibiting glycemic response to HPA axis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-12/biorxiv.physiology/paper_1.html">
      Stress-induced myonectin improves glucose homeostasis by inhibiting glycemic response to HPA axis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      生体内でのMynの過剰発現は、EPIへの血糖応答を鈍化させる代わりに耐糖能を改善し、インスリン感受性を高めます。ストレスはEPIへの血糖およびグリセロール応答を減衰させますが、脂肪組織におけるEPIへの脂肪分解応答を高めます。 HPA軸に対する血糖および代謝反応を再調整するミオカインを誘導し、したがって耐糖能異常および肥満の進行を防ぎます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
