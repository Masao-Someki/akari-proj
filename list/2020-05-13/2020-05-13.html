<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-05-13の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: The IOA System for Deep Noise Suppression Challenge using a Framework
  Combining Dynamic Attention and Recursive Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.SD/paper_0.html">
      The IOA System for Deep Noise Suppression Challenge using a Framework
  Combining Dynamic Attention and Recursive Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最終的なブラインドテストセットの場合、提出されたシステムの平均MOS改善は、noreverb、reverb、realrecの各カテゴリーで、それぞれ0.49、0.24、0.36です。推定結果を段階的に絞り込むために、再帰学習、タイプメモリメカニズムを使用して複数の段階で情報を悪化させるトレーニングプロトコルの例です。このテクニカルレポートは、Deep Noise Suppression Challengeに提出されたシステムについて説明し、非リアルタイムトラックの結果を示します。 
[要約]結果は、メモリメカニズムを使用して複数の段階で情報を悪化させるトレーニングプロトコルのタイプに基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: MultiQT: Multimodal Learning for Real-Time Question Tracking in Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.SD/paper_1.html">
      MultiQT: Multimodal Learning for Real-Time Question Tracking in Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は、マルチモーダル学習で同様の改善パターンが観察される医療症状の検出に一般化されます。英語の緊急医療サービスへの通話中に、音声で質問にリアルタイムでラベルを付けるという困難で実践的なタスクに対処します。緊急コールテイカーのための意思決定支援システム。私たちの結果は、不快なノイズと限られた量のトレーニングデータの下で、テキストまたはオーディオのみと比較した場合、2つのモダリティから共同学習することの大きな利点を示しています。 
[要約]音声から学習するための新しいマルチモーダルアプローチを提案します。2つのモダリティから共同で学習することで、大きな成果が得られたことを結果が示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-02">
        <br>2020-05-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-Task Network for Noise-Robust Keyword Spotting and Speaker
  Verification using CTC-based Soft VAD and Global Query Attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.SD/paper_2.html">
      Multi-Task Network for Noise-Robust Keyword Spotting and Speaker
  Verification using CTC-based Soft VAD and Global Query Attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、可視化の例とアブレーション実験の結果も示します。次に、特徴ベクトルの集約に使用して、識別的な埋め込みを生成します。マルチタスクネットワークは、ノイズの多い環境などの困難な条件でのパフォーマンス向上を目的として、サブネットワークを緊密に結合します、オープン語彙KWS、およびコネクショニスト時間的分類（CTC）ベースのソフト音声アクティビティ検出（VAD）とグローバルクエリアテンションの新しい手法を導入することにより、短期間のSV。 
[要約] kwsおよびsvチャレンジチャレンジチャレンジを実行するネットワークが提案されています。ネットワークは連携して、オープン言語の言語languageを完全に利用します。これは、4.9％および26を示しています。両方のタスクのベースライン
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-08">
        <br>2020-05-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Creative Quantum Computing: Inverse FFT, Sound Synthesis, Adaptive
  Sequencing and Musical Composition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.SD/paper_3.html">
      Creative Quantum Computing: Inverse FFT, Sound Synthesis, Adaptive
  Sequencing and Musical Composition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Zenoと呼ばれる構成は、実際の実際のアプリケーションを説明するために提示されています。量子コンピューティングは、原子物理学の原理に基づいて構築された代替コンピューティングテクノロジーとして浮上しています。芸術と創造的なアプリケーションに向かって、音楽は私たちの出発点です。 
[ABSTRACT]量子コンピューティングには、主に研究室に限定された専門知識が必要です。この章では、この点を改善することを目的とした研究を紹介します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: FeatherWave: An efficient high-fidelity neural vocoder with multi-band
  linear prediction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.SD/paper_4.html">
      FeatherWave: An efficient high-fidelity neural vocoder with multi-band
  linear prediction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、主観的なリスニングテストでは、FeatherWaveがLPCNetよりも高品質の音声を生成できることを示しています。マルチバンド方式により、モデルは複数の音声サンプルを同時に1ステップで生成できます。実験では、24 kHzの高音を生成できます。 -忠実度の高いオーディオは、単一のCPUでのリアルタイムより9倍速く、LPCNetボコーダーよりもはるかに高速です。 
[ABSTRACT] wavernnアーキテクチャで音声信号の線形予測特性を使用するlpcnetは、リアルタイムよりも速い速度で高品質の音声を生成できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Discriminative Multi-modality Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.SD/paper_5.html">
      Discriminative Multi-modality Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      第2段階では、音声モダリティと視覚モダリティを組み合わせて、MSRサブネットワークによる音声の理解を深め、認識率をさらに向上させます。この論文では、2段階の音声認識モデルを提案します。ビジョンはよく使用されます。オーディオ音声認識（ASR）の補完モダリティとして、特にソロオーディオモダリティのパフォーマンスが大幅に低下するノイズの多い環境で。 
[要約]視覚モダリティを組み合わせた後、asrはマルチモダリティ音声認識（msr）にアップグレードされます。最初の段階では、対象の声は、唇の動きの対応する視覚情報の助けを借りて、背景のノイズから分離され、モデルが理解しますはっきり
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: AdaDurIAN: Few-shot Adaptation for Neural Text-to-Speech with DurIAN -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.SD/paper_6.html">
      AdaDurIAN: Few-shot Adaptation for Neural Text-to-Speech with DurIAN
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この問題に対処するために、改良されたDurIANベースの平均モデルをトレーニングすることでAdaDurIANを紹介し、それをさまざまな話者にまたがる共有の話者に依存しないコンテンツエンコーダーを使用した少数ショット学習に活用します。 （MOS）の自然さと話者の類似性のより多くの好み..私たちの実験におけるいくつかの数ショット学習タスクは、AdaDurIANがベースラインのエンドツーエンドシステムを大幅に上回っていることを示しています。 
[ABSTRACT] adadurianはテキストの共有バージョンよりも優れたパフォーマンスを発揮できます-音声認識のマージンが大幅に増加します。adadurianは、少ないデータで対話ダイアログを上回るパフォーマンスを発揮できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Flowtron: an Autoregressive Flow-based Generative Network for
  Text-to-Speech Synthesis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.SD/paper_7.html">
      Flowtron: an Autoregressive Flow-based Generative Network for
  Text-to-Speech Synthesis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Flowtronは、高品質で表現力のあるメルスペクトログラム合成を提供するために、IAFから洞察を借り、Tacotronを刷新します。さらに、トレーニング中に見られる、見えないスピーカー間の音声変化、サンプル間の補間、スタイル転送の制御に関する結果を提供します。平均オピニオンスコア（MOS）は、Flowtronが音声品質の面で最新のTTSモデルと一致することを示しています。 
[ABSTRACT] flowtronはiafから洞察を借用し、高品質で表現力豊かなメル-スペクトログラム合成を提供するために使用されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: DiscreTalk: Text-to-Speech as a Machine Translation Problem -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.SD/paper_8.html">
      DiscreTalk: Text-to-Speech as a Machine Translation Problem
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      VQ-VAEモデルは、音声波形から離散シンボルのシーケンスへのマッピング関数を学習し、Transformer-NMTモデルは、特定の入力テキストからこの離散シンボルシーケンスを推定するようにトレーニングされます。JSUTコーパスを使用した実験的評価では、提案された方法は、自然に非自己回帰ニューラルボコーダーを使用して従来のTransformer-TTSモデルよりも優れており、VQ-VAEモデルの再構築に匹敵するパフォーマンスを実現します。ニューラル機械翻訳（NMT）に基づく音声（E2E-TTS）モデル。 
[要約]提案されたモデルは、非自己回帰センサー量子化変分オートエンコーダー（vq-vae）モデルと自己回帰トランスフォーマー-nhtモデルで構成されます。新しいモデルは、完全に訓練された方法でこのようなマッピングを学習できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: WinoWhy: A Deep Diagnosis of Essential Commonsense Knowledge for
  Answering Winograd Schema Challenge -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_0.html">
      WinoWhy: A Deep Diagnosis of Essential Commonsense Knowledge for
  Answering Winograd Schema Challenge
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      WinoWhyとすべてのコードは次の場所で入手できます。現在のWSCモデルが常識を理解できるのか、それともデータセットの統計的バイアスに基づいてWSCの質問を単純に解決できるのかを調査するために、収集された理由を活用してWinoWhyと呼ばれる新しいタスクを開発します。すべてのWSC質問の間違った理由。 
[ABSTRACT] winowhyと呼ばれる新しいタスクでは、すべてのwsc質問について、モデルをもっともらしい理由と非常に似ているが間違った理由から区別する必要があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Tale of a Probe and a Parser -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_1.html">
      A Tale of a Probe and a Parser
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは疑問を投げかけます：どのメトリックを優先するべきですか？英語で11.1ポイント）。構造プローブは、解析文献では検証されていない斬新なデザインであり、その正確な利点はすぐには明らかではありません。 
[ABSTRACT]研究者は「プローブ」をトレーニングしています-監視モデル。モデルの出力から言語構造を抽出するように設計されています。構造プローブは、解析文献で検証されていない新しいデザインを持っています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-04">
        <br>2020-05-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: COVID-19Base: A knowledgebase to explore biomedical entities related to
  COVID-19 -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_2.html">
      COVID-19Base: A knowledgebase to explore biomedical entities related to
  COVID-19
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの知る限りでは、これは、COVID-19に特化した最初のナレッジベースであり、関連するさまざまな生物医学エンティティを文献マイニングを通じて統合します。 -19Baseは、研究コミュニティがCOVID-19の治療的処置の可能な方法を発見するのに役立ちます。私たちは、ヒト遺伝子、ヒトmiRNA、ヒトlncRNA、疾患、タンパク質データバンク、薬物、および薬物側を含む7つのトピック固有の辞書を検討しましたCOVID-19に関連するすべての科学的証拠を採掘するために統合されています。 
[要約]私たちは、自動化された文献マイニングおよびラベル付けシステムを使用して、19に対する薬物の有効性を測定しました。研究コミュニティは、covidの治療のための可能な方法を発見しました19
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Empowering Active Learning to Jointly Optimize System and User Demands -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_3.html">
      Empowering Active Learning to Jointly Optimize System and User Demands
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実際のユーザーからのデータを使用して複数の学習戦略とユーザータイプを評価し、代替手法がエンドユーザーにとって不適切な演習の多くにつながる場合、私たちの共同アプローチが両方の目的をよりよく満たすことを発見しました。このホワイトペーパーでは、共同で最適化する新しいアクティブな学習アプローチを提案します。アクティブな学習システム（効果的にトレーニング）とユーザー（有用なインスタンスを受け取る）の見かけ上相反する目的特定のユーザーに対する演習。ユーザーは自分のスキルに一致する演習のみを受け取る必要があります。 
[ABSTRACT]システムは、特定のユーザーに対するエクササイズの適切性を予測するために迅速に学習する必要がありますが、ユーザーは自分のスキルに一致するエクササイズのみを受け取る必要があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-09">
        <br>2020-05-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: MultiQT: Multimodal Learning for Real-Time Question Tracking in Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_4.html">
      MultiQT: Multimodal Learning for Real-Time Question Tracking in Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      英語での緊急医療サービスへの電話中にリアルタイムで音声で質問にラベルを付けるという挑戦的で実践的なタスクに対処します。これは、緊急電話応対者向けの幅広い意思決定支援システムに組み込まれています。私たちの結果は、有害なノイズと限られた量のトレーニングデータの下で、テキストまたはオーディオのみと比較した場合の2つのモダリティ。結果は、マルチモーダル学習で同様の改善パターンが観察される医療症状の検出に一般化します。 
[要約]音声から学習するための新しいマルチモーダルアプローチを提案します。2つのモダリティから共同で学習することで、大きな成果が得られたことを結果が示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-02">
        <br>2020-05-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Word2Vec: Optimal Hyper-Parameters and Their Impact on NLP Downstream
  Tasks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_5.html">
      Word2Vec: Optimal Hyper-Parameters and Their Impact on NLP Downstream
  Tasks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      下流のタスクは、通常、最良のモデルはタスク固有であり、高いアナロジースコアは必ずしもF1スコアと正の相関があるとは限らず、同じことがデータのみに焦点を当てている場合にも当てはまります。時間、エネルギー、環境を節約するための倫理的配慮がなされている場合、その後、適度に小さいコーパスでも同じように、場合によってはさらに優れた結果が得られる可能性があります。それらをリリース済みの事前トレーニング済みの元のword2vecモデルと比較します。 
[要約]同様のインスピレーションが新しいディープニューラルネットワークの埋め込みにあります。ただし、この作業の目的は、ハイパーの最適な組み合わせを示し、パラメーターが存在し、さまざまな組み合わせを評価することです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-23">
        <br>2020-03-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning and Evaluating Emotion Lexicons for 91 Languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_6.html">
      Learning and Evaluating Emotion Lexicons for 91 Languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのアプローチは、ソース言語感情辞書、バイリンガルの単語翻訳モデル、ターゲット言語埋め込みモデルのみを必要とします。しかし、手動でキュレーションされた辞書は、ごく一部の言語でのみ利用可能であり、世界のほとんどの言語にはそのような貴重なリソースがありません。これらの91言語の要件を満たし、表現力豊かな高カバレッジレキシコンを生成できます。このレキシコンは、それぞれ10万以上の語彙エントリを持つ8つの感情変数で構成されています。 
[ABSTRACT]レキシコンは少数の言語でのみ使用できます。ここでは、任意のターゲット言語の感情モデルを作成する方法を紹介します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SKEP: Sentiment Knowledge Enhanced Pre-training for Sentiment Analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_7.html">
      SKEP: Sentiment Knowledge Enhanced Pre-training for Sentiment Analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      3種類の感情タスクの実験は、SKEPが強力な事前トレーニングベースラインを大幅に上回り、ほとんどのテストデータセットで新しい最先端の結果を達成することを示しています。特に、アスペクトと感情のペアの予測は、ペア内の単語間の依存関係をキャプチャすることを目的としたマルチラベル分類。https：//github.com/baidu/Sentaでコードをリリースします。 
[ABSTRACT]感情分析は、従来の感情分析アプローチで使用されていました。ただし、事前トレーニングのプロセスでは、感情知識は無視されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Detecting Multiword Expression Type Helps Lexical Complexity Assessment -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_8.html">
      Detecting Multiword Expression Type Helps Lexical Complexity Assessment
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、ネイティブリーダーと非ネイティブリーダーにとって最も問題となる式のタイプを調査します。この作業では、YimamらのComplex Word Identification Shared Task 2018データセットに再度アノテーションを付けます。MWEアノテーション付きデータセットをリリースしますこのペーパーでは、このデータセットはテキスト簡略化コミュニティにとって貴重なリソースであると考えています。 
[ABSTRACT] mwesの語彙の複雑さに関する研究は、まだ十分に調査されていない領域です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Reassessing Claims of Human Parity and Super-Human Performance in
  Machine Translation at WMT 2019 -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_9.html">
      Reassessing Claims of Human Parity and Super-Human Performance in
  Machine Translation at WMT 2019
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、これらの問題を考慮に入れて修正された評価を行います。私たちの結果は、WMT 2019で行われた人間の平等の主張と超人的なパフォーマンスは、英語からドイツ語の人間の平等の主張を除いて、反駁されるべきであることを示しています。調査結果に基づいて、機械翻訳における人間の同等性の将来の評価のために、一連の推奨事項と未解決の質問を提示します。 
[ABSTRACT] wmt 2019のwmt 2019での共有タスクの人間の評価における3つの潜在的な問題を特定します。利用可能な文章間コンテキストの量の制限、評価者の翻訳能力の制限、参照翻訳の使用が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neighborhood Matching Network for Entity Alignment -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_10.html">
      Neighborhood Matching Network for Entity Alignment
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、クロスグラフ近傍マッチングモジュールを採用して、特定のエンティティペアの近傍差を共同でエンコードします。このような戦略により、NMNは、アライメントタスクに悪影響を与えるノイズの多い近傍を無視しながら、マッチング指向のエンティティ表現を効率的に構築できます。 NMNはエンティティ間の類似性を推定して、トポロジー構造と近隣の違いの両方を取得します。 
[ABSTRACT]異質性の課題は構造的異質性です。2つの革新的なコンポーネントを提供することで、表現をより適切に学習できます。エンティティは、より厳しいケースで近隣の類似性を簡単に推定できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Prta: A System to Support the Analysis of Propaganda Techniques in the
  News -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_11.html">
      Prta: A System to Support the Analysis of Propaganda Techniques in the
  News
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Prta（Propaganda Persuasion Techniques Analyzer）を使用すると、プロパガンダテクニックが発生するスパンを強調表示して定期的にクロールされた記事を探索し、プロパガンダテクニックの使用に基づいて比較することができます。専用のインターフェースまたはAPIを介したテキストまたはURL。システムはさらに、全体的および経時的に、または時間間隔、キーワード、および/または政治に基づいてユーザーが指定したフィルタリング基準に従って、そのような技術の使用に関する統計を報告します。メディアの向き。 
[ABSTRACT]調査は事実の確認と偽情報の検出に重点を置いています。このシステムはオンラインで無料で利用できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Do not let the history haunt you -- Mitigating Compounding Errors in
  Conversational Question Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_12.html">
      Do not let the history haunt you -- Mitigating Compounding Errors in
  Conversational Question Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、この現象の重大度を質問タイプ、会話の長さ、ドメインタイプの関数として分析します。このホワイトペーパーでは、テスト時に以前に予測された回答を使用すると複合エラーが発生し、CoQAシステムのパフォーマンスが大幅に低下することがわかりました..この問題を解決するために、トレーニング中にターゲットの回答とモデル予測を動的に選択するサンプリング戦略を提案し、テスト時の状況を厳密にシミュレーションします。 
[要約] coqaモデルは、前の質問に対する人間-書面-真実の答えにアクセスできません。これにより、モデルは以前に予測された独自の答えに依存できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-Task Network for Noise-Robust Keyword Spotting and Speaker
  Verification using CTC-based Soft VAD and Global Query Attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_13.html">
      Multi-Task Network for Noise-Robust Keyword Spotting and Speaker
  Verification using CTC-based Soft VAD and Global Query Attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、特徴ベクトルの集約に使用され、弁別的な埋め込みが生成されます。提案されたアプローチでは、両方のタスクのベースラインと比較して、等しいエラーレート（EER）が4.06％と26.71％向上しています。フレームレベルの音響情報とスピーカー情報音声レベルで生成された重みと統合されているため、単語レベルのグローバル表現を形成します。 
[要約] kwsおよびsvチャレンジチャレンジチャレンジを実行するネットワークが提案されています。ネットワークは連携して、オープン言語の言語languageを完全に利用します。これは、4.9％および26を示しています。両方のタスクのベースライン
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-08">
        <br>2020-05-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Generalized Entropy Regularization or: There's Nothing Special about
  Label Smoothing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_14.html">
      Generalized Entropy Regularization or: There's Nothing Special about
  Label Smoothing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、ラベルの平滑化では、出力分布のスパース性、言語生成モデルでは望ましくない特性が許容されないことがわかります。そのため、代わりに他のエントロピー正則化方法を使用することをお勧めします。これには、特殊なケースとしてラベルスムージングが含まれ、それを使用して、モデルのエントロピーと言語生成タスクでのパフォーマンスとの関係をよりよく理解します。このクラスの手法は、ラベルスムージングの1つであり、関連性があります。エントロピー正則化。 
[要約]プロファイリングの前に、自信過剰は予測が過剰適合の一般的な兆候である
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-02">
        <br>2020-05-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Intersectional Bias in Hate Speech and Abusive Language Datasets -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_15.html">
      Intersectional Bias in Hate Speech and Abusive Language Datasets
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この研究は、ヘイトスピーチと虐待的言語のデータセットにおける相互バイアスに関する最初の体系的な証拠を提供します。結果は、アフリカ系アメリカ人のツイートが虐待的であるとラベル付けされる可能性が最大3.7倍高く、アフリカ系アメリカ人の男性のツイートが最大77％であることを示しました他と比較して憎悪的であると分類される可能性が高い。アルゴリズムは、ソーシャルメディアでの差別的発言や虐待的な言葉を検出するために広く適用されています。 
[ABSTRACT]これらのアルゴリズムのトレーニングに使用される人間の注釈が付けられた言語に偏りがあるかどうかを調査しました。人種、性別、政党識別など、Twitterでデータをテストしました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Frobenius Algebraic Analysis for Parasitic Gaps -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_16.html">
      A Frobenius Algebraic Analysis for Parasitic Gaps
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      同じ述語の引数に影響を与える寄生ギャップの場合、多態性は、主要なギャップを導入する語彙項目に関連付けられます。タイプロジカルおよび組み合わせの両方の伝統における既存のカテゴリー分析は、構文コピーの明示的な形式に依存しています。構造制御モダリティで拡張されたLambek微積分の観点から定式化されています。 
[ABSTRACT]これらはポリモーフィックコピーの例です。これらには、付属句の先頭のポリモーフィックタイプスキーマが含まれています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Discriminative Multi-modality Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_17.html">
      Discriminative Multi-modality Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      視覚モダリティを組み合わせた後、ASRはマルチモダリティ音声認識（MSR）にアップグレードされます。ビジョンは、特に音声音声認識（ASR）の補完モダリティとして、特にソロオーディオモダリティのパフォーマンスが大幅に低下するノイズの多い環境で使用されます。本論文では、2段階の音声認識モデルを提案する。 
[要約]視覚モダリティを組み合わせた後、asrはマルチモダリティ音声認識（msr）にアップグレードされます。最初の段階では、対象の声は、唇の動きの対応する視覚情報の助けを借りて、背景のノイズから分離され、モデルが理解しますはっきり
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Simultaneous paraphrasing and translation by fine-tuning Transformer
  models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_18.html">
      Simultaneous paraphrasing and translation by fine-tuning Transformer
  models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このシステムは、ハンガリー語（加重マクロF1スコアで27％の絶対的改善）およびポルトガル語（33％の絶対的改善）の言語のベースラインを大幅に上回っています。 ACL 2020向けのニューラル生成と翻訳（WNGT）に関する第4回ワークショップ。最終的なシステムは、事前トレーニング済みの翻訳モデルを活用し、オーバーサンプリング戦略と組み合わせたTransformerアーキテクチャを使用して、競争力のあるパフォーマンスを実現します。 
[ABSTRACT]最終的なシステムは、トランスアーキテクチャと競争力のあるパフォーマンスを達成するための取り組みを使用しています。結果は結果の結果です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On the Robustness of Language Encoders against Grammatical Errors -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_19.html">
      On the Robustness of Language Encoders against Grammatical Errors
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      自然な文法エラーに直面した場合、事前トレーニング済みの言語エンコーダー（ELMo、BERT、およびRoBERTa）の動作を診断するために徹底的な調査を実施します。結果は、テストされたすべてのモデルのパフォーマンスが影響を受けることを確認しますが、影響の程度は異なります。モデルの振る舞いを解釈するために、文法的文やエラーの位置を特定する能力を明らかにするために、言語的受容性タスクをさらに設計します。 
[要旨] elm以外のスピーカーから実際の文法エラーを収集します。攻撃を実行して、クリーンなテキストデータでこれらのエラーをシミュレートします。結果は、テストされたすべてのモデルのパフォーマンスが影響を受けることを確認します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Review of Text Style Transfer Based on Deep Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_20.html">
      Review of Text Style Transfer Based on Deep Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、テキストスタイル転送モデルの既存の特性を要約し、ディープラーニングに基づくテキストスタイル転送モデルの将来の開発傾向を分析および予測します。この記事では、ディープラーニングに基づくテキストスタイル転送モデルに関する研究をまとめます。近年、主要な研究の方向性と進歩を要約、分析、比較しています。近年、自然言語処理の研究では、テキストスタイルの転送が注目を集めています。 
[ABSTRACT]テキストスタイルの転送は、自然言語の状況でホットな問題になりつつあります。さらに、この記事では、自然言語の研究に使用される公開データセットと評価指標も紹介します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Dynamic Memory Induction Networks for Few-Shot Text Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_21.html">
      Dynamic Memory Induction Networks for Few-Shot Text Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      詳細な分析は、各コンポーネントの有効性を示すためにさらに実行されます。この論文では、少数ショットのテキスト分類のための動的メモリ誘導ネットワーク（DMIN）を提案します。提案されたモデルは、miniRCV1とODICで新しい最先端の結果を達成しますデータセット、最高のパフォーマンス（精度）を2〜4％向上させます。 
[ABSTRACT]モデルはminircv1とodicデータセットの新しいデータセット結果を提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: One Size Does Not Fit All: Generating and Evaluating Variable Number of
  Keyphrases -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_22.html">
      One Size Does Not Fit All: Generating and Evaluating Variable Number of
  Keyphrases
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      以前の評価指標と新しい評価指標の両方で、モデルはすべてのデータセットの強力なベースラインを上回っています。さらに、変数番号の生成に合わせて調整された2つの評価指標を提案します。異なるテキストは本来、異なる数のキーフレーズに対応するものとします。 
[ABSTRACT]このdesideratumは、既存の神経キーフレーズ生成モデルから大幅に欠落しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-10-11">
        <br>2018-10-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Psychometric Analysis and Coupling of Emotions Between State Bulletins
  and Twitter in India during COVID-19 Infodemic -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_23.html">
      Psychometric Analysis and Coupling of Emotions Between State Bulletins
  and Twitter in India during COVID-19 Infodemic
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      COVID-19のインフォデミックはパンデミック自体よりも速く広がっており、情報の波に乗った誤った情報が人々の健康とガバナンスシステムへの主要な脅威となっています。COVID-19の危機の間に、Twitterだけで使用率が45％急増しました。 2020年3月6日以降、キュレーションされたイベントページとダイレクトメッセージングの使用量が30％増加しています。これら2つの情報源を、心理言語学的な感情のレンズで調べ、2つの情報の範囲と結合を定量化しました。 
[要約]ソーシャルメディアは最大の情報源ですが、誤報を軽減し、それに起因する心理的パターンを早期に理解する必要があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: AdaDurIAN: Few-shot Adaptation for Neural Text-to-Speech with DurIAN -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_24.html">
      AdaDurIAN: Few-shot Adaptation for Neural Text-to-Speech with DurIAN
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この問題に対処するために、改良されたDurIANベースの平均モデルをトレーニングしてAdaDurIANを導入し、それをさまざまなスピーカー間で共有されるスピーカー非依存コンテンツエンコーダーを使用した少数ショット学習に活用します。主観的評価は、AdaDurIANがより高い平均意見スコアをもたらすことも示しています自然な（MOS）話者の類似性のより多くの好み。さらに、AdaDurIANを感情伝達タスクに適用し、その有望なパフォーマンスを実証します。 
[ABSTRACT] adadurianはテキストの共有バージョンよりも優れたパフォーマンスを発揮できます-音声認識のマージンが大幅に増加します。adadurianは、少ないデータで対話ダイアログを上回るパフォーマンスを発揮できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Every Document Owns Its Structure: Inductive Text Classification via
  Graph Neural Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_25.html">
      Every Document Owns Its Structure: Inductive Text Classification via
  Graph Neural Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      4つのベンチマークデータセットでの広範な実験は、この手法が最先端のテキスト分類手法よりも優れていることを示しています。最後に、単語ノードは、ドキュメントの埋め込みとして集計されます。最初に、各ドキュメントの個々のグラフを作成し、GNNを使用して学習します。そのローカル構造に基づいたきめの細かい単語表現。これにより、新しいドキュメントの目に見えない単語の埋め込みも効果的に作成できます。 
[ABSTRACT]新しい言語の作品は、各ドキュメント内のコンテキストの単語の関係をキャプチャしたり、新しい単語のgnnの学習を満たすことができません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-22">
        <br>2020-04-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Semantic Scaffolds for Pseudocode-to-Code Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_26.html">
      Semantic Scaffolds for Pseudocode-to-Code Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、目に見えない問題に対してテストした場合、11の候補だけが以前の最良のアプローチの上位3000のパフォーマンスに到達する必要があり、効率の大幅な向上を示しています。疑似コードからコードを生成するために、階層検索方法をSPoCデータセットに適用します。 、行レベルの自然言語の疑似コードアノテーションが与えられ、実行ベースのテストケースを満たすプログラムを生成することを目的としています。推論中にセマンティックスキャフォールドを使用することにより、前の状態よりもトップ100の精度が10％向上します。 -最先端の。 
[ABSTRACT]最高の精度で10％の絶対的な改善を実現-検索データを使用する以前の最先端技術に対して100の精度、検索スペースのより良いカバレッジを実現
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Synchronous Bidirectional Learning for Multilingual Lip Reading -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_27.html">
      Synchronous Bidirectional Learning for Multilingual Lip Reading
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      まず、多言語設定のモデリング単位として音素を導入します。したがって、多言語ターゲットの学習は、音素の予測に改善をもたらすはずです。同様の音素は、常に同様の視覚パターンにつながります。 
[要約]この論文では、多言語の読唇の相乗効果に焦点を当てています。すべての言語の唇の動きは類似したパターンを共有しています。唇の動きは、異なる言語間で共有される各音素の量と多様性を増加させます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-08">
        <br>2020-05-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Framework for Hierarchical Multilingual Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_28.html">
      A Framework for Hierarchical Multilingual Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      41言語のデータセットに対する徹底的な実験により、特に豊富なリソースセットが利用可能な類型的に関連するファミリを使用して低リソース言語のパフォーマンスを改善する場合に、提案されたフレームワークの有効性が実証されます。このホワイトペーパーでは、類型言語ファミリーツリーを利用して多言語機械翻訳戦略を構築するための階層的フレームワークを提示し、相互に異なる言語を組み込むことによる悪影響を回避しながら、類似言語間の転送を可能にします。多言語機械翻訳は最近転移学習を介して低リソース言語の機械翻訳のパフォーマンスを向上させる可能性を考えると、人気が高まっています。 
[ABSTRACT] 41言語のデータセットでの調査により、提案されたフレームワークの有効性が実証されました。調査は、システムの成功が特定の言語グループでの実験に限定されていることを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Flowtron: an Autoregressive Flow-based Generative Network for
  Text-to-Speech Synthesis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_29.html">
      Flowtron: an Autoregressive Flow-based Generative Network for
  Text-to-Speech Synthesis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      平均オピニオンスコア（MOS）は、Flowtronが最新のTTSモデルと音声品質の点で一致していることを示しています。コードおよび事前トレーニング済みモデルは、https：//github.com/NVIDIA/flowtronで公開されます。 。 Flowtronは、音声合成の多くの側面（ピッチ、トーン、スピーチレート、ケイデンス、アクセント）を制御するために操作できる潜在空間へのデータの可逆マッピングを学習します。 
[ABSTRACT] flowtronはiafから洞察を借用し、高品質で表現力豊かなメル-スペクトログラム合成を提供するために使用されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: DiscreTalk: Text-to-Speech as a Machine Translation Problem -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_30.html">
      DiscreTalk: Text-to-Speech as a Machine Translation Problem
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      JSUTコーパスを使用した実験的評価は、提案された方法が自然に非自己回帰ニューラルボコーダーを使用して従来のTransformer-TTSモデルを上回り、VQ-VAEモデルの再構築に匹敵するパフォーマンスを達成することを示しています。VQ-VAEモデルからこのようなマッピングは完全にデータ駆動型の方法で学習できます。従来のE2E-TTSモデルで必要な特徴抽出のハイパーパラメータを考慮する必要はありません。VQ-VAEモデルは、音声波形からそして、Transformer-NMTモデルは、特定の入力テキストからこの離散シンボルシーケンスを推定するようにトレーニングされます。 
[要約]提案されたモデルは、非自己回帰センサー量子化変分オートエンコーダー（vq-vae）モデルと自己回帰トランスフォーマー-nhtモデルで構成されます。新しいモデルは、完全に訓練された方法でこのようなマッピングを学習できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The Safari of Update Structures: Visiting the Lens and Quantum
  Enclosures -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_31.html">
      The Safari of Update Structures: Visiting the Lens and Quantum
  Enclosures
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      したがって、更新構造は代数オブジェクトの厳密により一般的なクラスを形成するため、この作業は基本的に興味があります。これを使いこなすことで、個別に研究された数学的構造間の新しい関係を明らかにすることが約束されます。 2つを一致させるために必要な追加の仮定を正確に示して、オブザーバブルです。最近導入された更新構造の概念に基づいて、非常に適切に動作するレンズの一般化であることを示します。つまり、厳密なデカルトカテゴリの更新構造とvwbレンズのサブセット。 
[ABSTRACT]焦点を短剣-特別な可換フロベニーリングからシフトします。その際、相互作用する（co）マグマ（co）モジュールのペアに焦点を当てます。これは、理論の無垢さがmodule.tamuminiに関連していることを示しています。これらの構造は、それらがマグマのコマグマに関連していないことを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br>2020-05-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SentiBERT: A Transferable Transformer-Based Architecture for
  Compositional Sentiment Semantics -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_32.html">
      SentiBERT: A Transferable Transformer-Based Architecture for
  Compositional Sentiment Semantics
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      包括的な実験は、SentiBERTがフレーズレベルの感情分類で競争力のあるパフォーマンスを達成することを示しています。さらに、SentiBERTを理解するためにアブレーション研究と設計の視覚化方法を実施しています。否定と対照的な関係をキャプチャし、モデル化する際に、SentiBERTがベースラインアプローチより優れていることを示しています。構成感情のセマンティクス。 
[ABSTRACT]否定と対照的な関係を捉える上で、センチベルトがベースラインアプローチより優れていることを示し、構成感情の意味をモデル化します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-08">
        <br>2020-05-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploiting Syntactic Structure for Better Language Modeling: A Syntactic
  Distance Approach -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_33.html">
      Exploiting Syntactic Structure for Better Language Modeling: A Syntactic
  Distance Approach
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Penn TreebankおよびChinese Treebankデータセットの実験結果は、グラウンドトゥルースパースツリーが追加のトレーニング信号として提供される場合、モデルがより低い混乱度を達成し、より良い品質でツリーを誘導できることを示しています。このホワイトペーパーでは、マルチタスクの目的、つまり、モデルは単語とグラウンドトゥルースパースツリーを「構文距離」と呼ばれる形式で同時に予測します。この場合、これらの2つの別々の目的間の情報は同じ中間表現を共有します。神経言語モデルへの移行は、難しい課題です。 
[ABSTRACT]ペンツリーバンクと中国のデータセットの研究者は、グラウンドトゥルースパースツリーが追加のトレーニング信号として提供されると、モデルはより低い混乱度を達成し、より良い品質でツリーを誘導できることを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Report on the 2020 Sarcasm Detection Shared Task -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_34.html">
      A Report on the 2020 Sarcasm Detection Shared Task
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーでは、ACL 2020での第2回比喩言語処理ワークショップ（FigLang2020）の一環として実施した皮肉検出に関する共有タスクについて報告します。皮肉および皮肉検出などの比喩言語分析は、過去10年間で人気のあるNLPタスク。このような問題への計算アプローチに取り組むコミュニティが成長しているため、ベンチマーク調査を実施して現在の最先端技術を分析し、この分野の進展を促進することが不可欠です。 
[ABSTRACT]米国でベンチマーク調査が開発されています。問題を検出する方法を調査することが重要です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Document Modeling with Graph Attention Networks for Multi-grained
  Machine Reading Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/cs.CL/paper_35.html">
      Document Modeling with Graph Attention Networks for Multi-grained
  Machine Reading Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Natural Questionsは、長い解答（通常は段落）と短い解答（長い解答内の1つ以上のエンティティ）の2つの粒度の解答を備えた、新しい難解な機械読解ベンチマークです。長い解答と短い解答を抽出できます。それぞれ、段落レベルの表現とトークンレベルの表現から。このようにして、2つの詳細な回答間の依存関係をモデル化して、互いの証拠を提供できます。 
[ABSTRACT]このベンチマークで新しいベンチマークが開発されました。ベンチマークでの既存のメソッドの有効性にもかかわらず、これらの2つのサブタスクは個別に処理されます。これらの2つのサブタスクは、依存関係を無視しながらトレーニング中に個別に処理されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: TalkNet: Fully-Convolutional Non-Autoregressive Speech Synthesis Model -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/eess.AS/paper_0.html">
      TalkNet: Fully-Convolutional Non-Autoregressive Speech Synthesis Model
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2番目のネットワークは、展開されたテキストからメルスペクトログラムを生成します。明示的な継続時間予測により、単語のスキップと繰り返しがなくなります。非自己回帰アーキテクチャにより、高速なトレーニングと推論が可能になります。 
[ABSTRACT]事前学習済みの接続論的分類（ctc）ベースの音声認識モデルを使用して、書記素持続時間をトレーニングデータセットに追加します。単語の品質は、自動回帰モデルとほぼ一致します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The IOA System for Deep Noise Suppression Challenge using a Framework
  Combining Dynamic Attention and Recursive Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/eess.AS/paper_1.html">
      The IOA System for Deep Noise Suppression Challenge using a Framework
  Combining Dynamic Attention and Recursive Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最終的なブラインドテストセットの場合、提出されたシステムの平均MOS改善は、noreverb、reverb、realrecの各カテゴリでそれぞれ0.49、0.24、0.36です。このテクニカルレポートは、ディープノイズ抑制チャレンジに提出されたシステムについて説明しています。非リアルタイムトラックの結果を示します。アテンションジェネレーターネットワークは、ノイズ低減ネットワークの機能分布を動的に制御するように設計されています。 
[要約]結果は、メモリメカニズムを使用して複数の段階で情報を悪化させるトレーニングプロトコルのタイプに基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: MultiQT: Multimodal Learning for Real-Time Question Tracking in Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/eess.AS/paper_2.html">
      MultiQT: Multimodal Learning for Real-Time Question Tracking in Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの結果は、有害なノイズと限られた量のトレーニングデータの下で、テキストまたはオーディオのみと比較した場合、2つのモダリティから共同で学習することの大きな利点を示しています。私たちのモデルは、音声とその独自のテキスト表現を、2つの別々のモダリティまたはビューとして、ストリーミングオーディオから学習し、自動音声認識を介してそのノイズの多いテキストにテキストを変換します。結果は一般的に、マルチモーダル学習による同様の改善パターンを観察する医療症状の検出に一般化します。 
[要約]音声から学習するための新しいマルチモーダルアプローチを提案します。2つのモダリティから共同で学習することで、大きな成果が得られたことを結果が示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-02">
        <br>2020-05-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-Task Network for Noise-Robust Keyword Spotting and Speaker
  Verification using CTC-based Soft VAD and Global Query Attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/eess.AS/paper_3.html">
      Multi-Task Network for Noise-Robust Keyword Spotting and Speaker
  Verification using CTC-based Soft VAD and Global Query Attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      マルチタスクネットワークは、コネクショニストの時間的分類（CTC）ベースのソフトな音声アクティビティ検出（CTC）ベースの新しい手法を導入することにより、ノイズの多い環境、オープン語彙KWS、短時間のSVなどの困難な条件でのパフォーマンス向上を目的としたサブネットワークを緊密に組み合わせVAD）とグローバルクエリアテンション..次に、特徴ベクトルの集約に使用されて、差別的な埋め込みを生成します。.フレームレベルの音響およびスピーカー情報は、音声レベルで生成された重みと統合され、単語レベルのグローバル表現を形成します。 
[要約] kwsおよびsvチャレンジチャレンジチャレンジを実行するネットワークが提案されています。ネットワークは連携して、オープン言語の言語languageを完全に利用します。これは、4.9％および26を示しています。両方のタスクのベースライン
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-08">
        <br>2020-05-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Creative Quantum Computing: Inverse FFT, Sound Synthesis, Adaptive
  Sequencing and Musical Composition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/eess.AS/paper_4.html">
      Creative Quantum Computing: Inverse FFT, Sound Synthesis, Adaptive
  Sequencing and Musical Composition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Zenoと呼ばれる構成は、実際の実際のアプリケーションを示すために提示されています。この章では、このシナリオの改善を目的とした研究を紹介します。この章では、量子情報処理が逆高速フーリエ変換（FFT）サウンドシンセサイザを制御する初期結果について報告します。適応的な音楽シーケンサー。 
[ABSTRACT]量子コンピューティングには、主に研究室に限定された専門知識が必要です。この章では、この点を改善することを目的とした研究を紹介します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: FeatherWave: An efficient high-fidelity neural vocoder with multi-band
  linear prediction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/eess.AS/paper_5.html">
      FeatherWave: An efficient high-fidelity neural vocoder with multi-band
  linear prediction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      マルチバンド方式により、モデルは1つのステップで複数の音声サンプルを並行して生成できます。さらに、主観的なリスニングテストでは、FeatherWaveがLPCNetよりも優れた品質の音声を生成できることが示されています。実験では、24 kHzの高さを生成できます。 -忠実度の高いオーディオは、単一のCPUでのリアルタイムより9倍速く、LPCNetボコーダーよりもはるかに高速です。 
[ABSTRACT] wavernnアーキテクチャで音声信号の線形予測特性を使用するlpcnetは、リアルタイムよりも速い速度で高品質の音声を生成できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Discriminative Multi-modality Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/eess.AS/paper_6.html">
      Discriminative Multi-modality Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      視覚モダリティを組み合わせた後、ASRはマルチモダリティ音声認識（MSR）にアップグレードされます。ビジョンは、特に音声音声認識（ASR）の補完モダリティとして、特にソロオーディオモダリティのパフォーマンスが大幅に低下するノイズの多い環境で使用されます。本論文では、2段階の音声認識モデルを提案する。 
[要約]視覚モダリティを組み合わせた後、asrはマルチモダリティ音声認識（msr）にアップグレードされます。最初の段階では、対象の声は、唇の動きの対応する視覚情報の助けを借りて、背景のノイズから分離され、モデルが理解しますはっきり
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: AdaDurIAN: Few-shot Adaptation for Neural Text-to-Speech with DurIAN -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/eess.AS/paper_7.html">
      AdaDurIAN: Few-shot Adaptation for Neural Text-to-Speech with DurIAN
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      主観評価は、AdaDurIANが自然さのより高い平均オピニオンスコア（MOS）と話者の類似性のより多くの好みをもたらすことも示しています。この問題に対処するために、改良されたDurIANベースの平均モデルをトレーニングすることによってAdaDurIANを導入し、それを少数ショット学習に活用します異なるスピーカー間で共有される、スピーカーに依存しないコンテンツエンコーダーを使用します。この実験のいくつかの数ショット学習タスクは、AdaDurIANがベースラインエンドツーエンドシステムを大幅に上回っていることを示しています。 
[ABSTRACT] adadurianはテキストの共有バージョンよりも優れたパフォーマンスを発揮できます-音声認識のマージンが大幅に増加します。adadurianは、少ないデータで対話ダイアログを上回るパフォーマンスを発揮できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Flowtron: an Autoregressive Flow-based Generative Network for
  Text-to-Speech Synthesis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/eess.AS/paper_8.html">
      Flowtron: an Autoregressive Flow-based Generative Network for
  Text-to-Speech Synthesis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの平均意見スコア（MOS）は、Flowtronが最新のTTSモデルと音声品質の点で一致していることを示しています。Flowtronは、トレーニングデータの可能性を最大化することによって最適化され、トレーニングがシンプルで安定しています。Flowtronは、音声合成の多くの側面（ピッチ、トーン、スピーチレート、ケイデンス、アクセント）を制御するために操作できる潜在空間へのデータの可逆マッピング。 
[ABSTRACT] flowtronはiafから洞察を借用し、高品質で表現力豊かなメル-スペクトログラム合成を提供するために使用されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: DiscreTalk: Text-to-Speech as a Machine Translation Problem -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/eess.AS/paper_9.html">
      DiscreTalk: Text-to-Speech as a Machine Translation Problem
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      JSUTコーパスを使用した実験的評価は、提案された方法が自然に非自己回帰ニューラルボコーダーを使用して従来のTransformer-TTSモデルよりも優れており、VQ-VAEモデルの再構築に匹敵するパフォーマンスを達成していることを示しています。シンボルの場合、NMTおよび自動音声認識（ASR）で開発されたさまざまな手法（ビーム検索、サブワードユニット、言語モデルとの融合など）を使用できます。さらに、予測機能の過度の平滑化問題を回避できます。 TTSの一般的な問題。 
[要約]提案されたモデルは、非自己回帰センサー量子化変分オートエンコーダー（vq-vae）モデルと自己回帰トランスフォーマー-nhtモデルで構成されます。新しいモデルは、完全に訓練された方法でこのようなマッピングを学習できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Gut microbiota impairs insulin clearance during obesity -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/biorxiv.physiology/paper_0.html">
      Gut microbiota impairs insulin clearance during obesity
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      5つの細菌分類群は、インスリンクリアランスの分散の&gt; 90％を予測しました。微生物の小さなクラスターが、インスリンクリアランスの欠陥、肥満と2型糖尿病の進行を緩和するためのターゲットになる可能性があります。肥満時のインスリンクリアランスの変化のトリガー正しく定義されていません。 
[要約]インスリン分泌の増加とインスリンクリアランスの低下は、高インスリン血症の一因となる可能性があります。経口抗生物質は、高脂肪食（hfd）を12週間以上与えられたマウスのインスリンクリアランスの障害を軽減しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Effects of long-term in vivo micro-CT imaging on hallmarks of osteopenia and frailty in aging mice -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-13/biorxiv.physiology/paper_1.html">
      Effects of long-term in vivo micro-CT imaging on hallmarks of osteopenia and frailty in aging mice
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      静的な形態計測パラメーターで観察されたグループ間の違いは、動的な形態計測パラメーターではそれほど顕著ではありませんでした。 、早期老化モデル（PolgA（D257A / D257A））を使用して、これらの効果が遺伝子型間で異なるかどうかを評価しました。 
[ABSTRACT] mriイメージングは加齢研究に適用できます。加齢に伴い、取り扱いや麻酔などの外部刺激に対する脆弱性や感受性が高まるため、看護を使用できる範囲は不明のままです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
