<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-12-10の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: DeepTalk: Vocal Style Encoding for Speaker Recognition and Speech
  Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.SD/paper_0.html">
      <font color="black">DeepTalk: Vocal Style Encoding for Speaker Recognition and Speech
  Synthesis</font>
    </a>
  </h2>
  <font color="black">DeepTalkを最先端の生理学的音声機能ベースの話者認識システムと組み合わせることにより、話者認識パフォーマンスがさらに向上します。また、DeepTalkメソッドを現在の最先端の音声合成装置に統合して合成を生成します。スピーチ..さらに、DeepTalkベースの合成スピーチは、話者認識のコンテキストでは実際のスピーチとほとんど区別がつかないことが示されています。 
[要約] deeptalkメソッドは、複数の困難なデータセットにわたって、最先端の生理学的音声特性に基づく話者認識システムよりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Conjugate Mixture Models for Clustering Multimodal Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.SD/paper_1.html">
      <font color="black">Conjugate Mixture Models for Clustering Multimodal Data</font>
    </a>
  </h2>
  <font color="black">問題を尤度最大化タスクとして定式化し、関連する共役期待値最大化アルゴリズムを導出します。提案されたアルゴリズムの収束特性を徹底的に調査します。これらのモデルは、観測されていないパラメーター空間（オブジェクト）間でしばしば利用可能な明示的な変換を利用します。 ）および各観測空間（センサー）。 
[要約]このようなアプローチの主な難しさは、単峰性クラスタリングが相互に一貫していることを保証することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: SongMASS: Automatic Song Writing with Pre-training and Alignment
  Constraint -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.SD/paper_2.html">
      <font color="black">SongMASS: Automatic Song Writing with Pre-training and Alignment
  Constraint</font>
    </a>
  </h2>
  <font color="black">この論文では、上記の課題に対処するためにSongMASSを提案します。これは、マスクされたシーケンスからシーケンス（MASS）の事前トレーニングと、歌詞からメロディーおよびメロディーから歌詞の生成のための注意ベースのアライメントモデリングを活用します。機械で曲（歌詞やメロディー）を作成します。これは、学界と業界の両方で興味深いトピックです。具体的には、1）元の文レベルのMASS事前トレーニングを曲レベルに拡張して、長いコンテキスト情報をより適切にキャプチャします。音楽、およびモダリティ（歌詞またはメロディー）ごとに個別のエンコーダーとデコーダーを使用します。 2）トレーニング中に文レベルの注意マスクとトークンレベルの注意制約を活用して、歌詞とメロディーの整合性を強化します。 
[概要]自動作詞作曲では、歌詞からメロディーの生成とメロディーが2つの重要なタスクです。歌詞とメロディーのペアデータは限られており、2つのタスクの生成品質に影響します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Convex Regularization Behind Neural Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/eess.IV/paper_0.html">
      <font color="black">Convex Regularization Behind Neural Reconstruction</font>
    </a>
  </h2>
  <font color="black">ただし、ニューラルネットワークの非凸で不透明な性質は、医用画像などの高感度アプリケーションでの有用性を妨げます。特に、重み減衰正則化を使用してニューラルネットワークをトレーニングすると、パスのスパース性が誘発され、予測は断片的な線形フィルタリングになります。ネットワークは、逆問題で高解像度画像を再構築するための途方もない可能性を示しています。 
[概要]アトラスネットワークは、最適なトレーニングと予測を提供します。また、ナビゲーションとナビゲーションの予防接種も提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Diverse R-PPG: Camera-Based Heart Rate Estimation for Diverse Subject
  Skin-Tones and Scenes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/eess.IV/paper_1.html">
      <font color="black">Diverse R-PPG: Camera-Based Heart Rate Estimation for Diverse Subject
  Skin-Tones and Scenes</font>
    </a>
  </h2>
  <font color="black">最初の遠隔医療に焦点を当てたリモートバイタルサインデータセットであるVITALデータセットを作成することで、メソッドのパフォーマンスを評価します。このメソッドは、照明の変化、影、鏡面ハイライトによるエラーを減らし、肌の色や設定全体に偏りのないパフォーマンスの向上をもたらします。医学的に包括的な非接触HRセンシング技術を、すべての肌の色調の患者にとって実行可能な現実にするための段階。報告されたデータで、より暗い肌の色調でのパフォーマンスを向上させる新しい物理駆動アルゴリズムを提示します。 
[概要]報告されたデータで、より暗い肌の色調でのパフォーマンスを向上させる、新しい物理学主導のアルゴリズムを紹介します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-24">
        <br><font color="black">2020-10-24</font>
      </time>
    </span>
</section>
<!-- paper0: Non-interferometric accurate phase imaging via a linear-convergence
  iterative optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/eess.IV/paper_2.html">
      <font color="black">Non-interferometric accurate phase imaging via a linear-convergence
  iterative optimization</font>
    </a>
  </h2>
  <font color="black">さらに、その近似解を正確な解に変えるための効率的な反復最適化戦略が開発されています。反復の線形収束特性により、大量の反復を必要とせずに高精度の位相回復が達成されます。提案されたの実現可能性と精度メソッドは、数値シミュレーションとさまざまな位相オブジェクトの実験の両方によって検証されます。 
[概要]高度な方法は、タイプ4fの光学構成に基づいています。これを使用して、オブジェクトの正確な位相を作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br><font color="black">2020-05-12</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Data Augmentation for Vehicle Detection in Aerial Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/eess.IV/paper_3.html">
      <font color="black">Generative Data Augmentation for Vehicle Detection in Aerial Images</font>
    </a>
  </h2>
  <font color="black">提案手法は、異なる発電機と統合できるという意味で一般的である。本論文では、航空画像における車両検出性能の向上に焦点を当て、境界ボックス注釈よりも特別な監視を必要としない生成増強手法を提案する。トレーニングデータセット内の車両オブジェクトの数..実験では、この方法をPluralisticおよびDeepFillと統合すると、平均精度がそれぞれ最大25.2％および25.7％向上することが示されています。 
[概要]提案された方法は、検出器をより多くのインスタンスでトレーニングできるようにすることで、車両検出のパフォーマンスを向上させます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Multiscale Phase Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/eess.IV/paper_4.html">
      <font color="black">Multiscale Phase Retrieval</font>
    </a>
  </h2>
  <font color="black">これらの戦略は、新しい統合フォトニック、プラズモン、および/またはメタマテリアルデバイスを使用して構築されるような干渉計のネットワークを使用したグループテストに依存しています。対照的に、位相回復は、コヒーレントまたは部分的にコヒーレントなフィールドを直接測定するセンサーと理論的に一致しています。事前の仮定..コヒーレント波動場の特性評価はレーザー、X線、および電子イメージングに不可欠ですが、センサーはフィールド自体ではなく、フィールドの2乗の大きさを測定します。 
[ABSTRACT]レーザーイメージングを使用して、フィールドを特徴付けることができます。たとえば、ホログラフィーまたは位相回復を使用する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: A signal detection model for quantifying over-regularization in
  non-linear image reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/eess.IV/paper_5.html">
      <font color="black">A signal detection model for quantifying over-regularization in
  non-linear image reconstruction</font>
    </a>
  </h2>
  <font color="black">2つのメトリックを組み合わせて使用すると、非線形画像再構成を使用する場合にCTアルゴリズムと構成パラメータを決定するための有用な処方箋が得られる可能性があります。このようなメトリックを使用すると、画像..構成は、取得される投影の数が異なります。 
[概要]非線形画像再構成の評価に使用されるメトリックの大部分は、何らかの形式のグローバル画像忠実度に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-07">
        <br><font color="black">2020-10-07</font>
      </time>
    </span>
</section>
<!-- paper0: Machine Learning for Cataract Classification and Grading on Ophthalmic
  Imaging Modalities: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/eess.IV/paper_6.html">
      <font color="black">Machine Learning for Cataract Classification and Grading on Ophthalmic
  Imaging Modalities: A Survey</font>
    </a>
  </h2>
  <font color="black">さらに、機械学習技術に基づく自動白内障の分類とグレーディングのいくつかの課題について説明し、将来の研究のためにこれらの課題に対する可能な解決策を提示します。このペーパーでは、眼科に基づく白内障の分類とグレーディングのための機械学習の最近の進歩を包括的に調査します。画像..このペーパーはまた、メリットと制限の両方の既存の作品への洞察を提供します。 
[ABSTRACT]研究者は、白内障の自動分類と評価のための人工知能技術を開発しました。これは、臨床医が白内障を時間内に予防および治療するのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Improved Lite Audio-Visual Speech Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/eess.IV/paper_7.html">
      <font color="black">Improved Lite Audio-Visual Speech Enhancement</font>
    </a>
  </h2>
  <font color="black">提案されたシステムは改良型LAVSE（iLAVSE）と呼ばれ、畳み込みリカレントニューラルネットワークアーキテクチャをコアAVSEモデルとして使用します。従来のAVSEシステムと比較して、LAVSEはオンライン計算が少なくて済み、顔データのユーザープライバシー問題を適度に解決します。ビデオデータセットを使用して、台湾マンダリンスピーチでiLAVSEを評価します。 
[ABSTRACT] lavseはライトオーディオ-視覚音声強調（lavse）アルゴリズムです。この研究では、3つの実用的な問題に対処するためにlavseを拡張します。結果は、ilaveが実際のシナリオに適していることも確認しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-30">
        <br><font color="black">2020-08-30</font>
      </time>
    </span>
</section>
<!-- paper0: ROSE: A Retinal OCT-Angiography Vessel Segmentation Dataset and New
  Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/eess.IV/paper_8.html">
      <font color="black">ROSE: A Retinal OCT-Angiography Vessel Segmentation Dataset and New
  Model</font>
    </a>
  </h2>
  <font color="black">実験結果は、SCF-Netが従来の方法や他の深層学習方法よりもOCT-Aで優れた血管セグメンテーションパフォーマンスをもたらすことを示しています。第3に、最先端の血管セグメンテーションモデルと提案されたROSEデータセットのSCF-Net ..ただし、OCT-Aでの網膜血管の自動セグメンテーションは、多くの眼関連疾患の理解における重要性にもかかわらず、毛細血管の視認性の低さや血管の複雑さの高さなどのさまざまな課題のために十分に研究されていません。 。 
[概要]網膜画像解析の分野で初めて、専用の網膜oct-セグメンテーションデータセット（バラ）を構築します。これは、中心線-レベルまたはピクセルレベルのいずれかで、229a-血管のある画像-注釈-で構成されます。これは、毛細血管の視認性が低い、血管が複雑であるなどのさまざまな課題によるものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-10">
        <br><font color="black">2020-07-10</font>
      </time>
    </span>
</section>
<!-- paper0: Modeling and Enhancing Low-quality Retinal Fundus Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/eess.IV/paper_9.html">
      <font color="black">Modeling and Enhancing Low-quality Retinal Fundus Images</font>
    </a>
  </h2>
  <font color="black">次に、劣化モデルに基づいて、臨床的観察と分析のために解剖学的網膜構造と病理学的特性を維持しながら、グローバルな劣化要因を抑制する臨床指向の眼底増強ネットワーク（cofe-Net）が提案されます。眼底イメージングのビームと網膜の構造、これに対処するために自然画像強調法を直接利用することはできません。さらに、眼底補正法が網膜血管セグメンテーションや光学ディスク/カップなどの医療画像分析アプリケーションに役立つことも示しています。検出。 
[概要]さまざまな経験を持つオペレーターが撮影した眼底画像は、品質に大きなばらつきがありますが、眼底画像の特殊な光ビームと網膜の構造により、自然画像強調法を直接使用してこれに対処できます。目的の眼底増強ネットワーク（cofe-net）は、グローバルな劣化要因を抑制するために提案されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br><font color="black">2020-05-12</font>
      </time>
    </span>
</section>
<!-- paper0: AIDE: Annotation-efficient deep learning for automatic medical image
  segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/eess.IV/paper_10.html">
      <font color="black">AIDE: Annotation-efficient deep learning for automatic medical image
  segmentation</font>
    </a>
  </h2>
  <font color="black">3つの医療センターからの872人の患者の11,852枚の乳房画像を含む3つの臨床データセットについて、AIDEは、完全に監視されたカウンターパートによって生成されたものに匹敵するセグメンテーションマップと、10％のトレーニング注釈のみを利用する独立した放射線科医の手動注釈を一貫して生成します。注釈効率の高いディープラーニング（AIDE）は、画像の内容をより適切に調査することにより、低品質の注釈を段階的に修正します。正確な画像セグメンテーションは、疾患の診断や治療計画などの医療画像アプリケーションにとって非常に重要です$ ^ {1-4} $。 
[概要]ディープラーニング手法は通常、高品質の手動注釈付きのトレーニングデータセットに依存しています。これらは、医用画像では利用できないことがよくあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Complementary Capabilities of Photoacoustic Imaging to Existing Optical
  Ocular Imaging Techniques -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/eess.IV/paper_11.html">
      <font color="black">Complementary Capabilities of Photoacoustic Imaging to Existing Optical
  Ocular Imaging Techniques</font>
    </a>
  </h2>
  <font color="black">この章では、眼底写真、SLO、およびOCTの概要を説明し、次の主要な眼球イメージングモダリティとしての光音響イメージングの可能性について説明します。 
[概要]この章では、次の主要な眼球イメージングモダリティとしての光音響ポテンシャルについて説明します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Automated Scoring of Nuclear Pleomorphism Spectrum with
  Pathologist-level Performance in Breast Cancer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/eess.IV/paper_12.html">
      <font color="black">Automated Scoring of Nuclear Pleomorphism Spectrum with
  Pathologist-level Performance in Breast Cancer</font>
    </a>
  </h2>
  <font color="black">複数の実験で、完全に自動化されたアプローチにより、選択した関心領域とスライド画像全体で、それぞれ10人と4人の病理医と比較して、最高の病理医レベルのパフォーマンスを達成できました。核多形性の程度を連続体と見なします。腫瘍形態の変化の連続スペクトル..核多形性は、尿細管分化および有糸分裂カウントとともに、3層乳がんの等級付けの構成要素の1つである核形態の変化の程度です。 
[要約]腫瘍形態の変化の連続スペクトル。また、ベースラインとしての正常な上皮の追加の陰謀を動機付けます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Red Blood Cell Segmentation with Overlapping Cell Separation and
  Classification on Imbalanced Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/eess.IV/paper_13.html">
      <font color="black">Red Blood Cell Segmentation with Overlapping Cell Separation and
  Classification on Imbalanced Dataset</font>
    </a>
  </h2>
  <font color="black">血液塗抹標本画像での自動赤血球分類は、血液専門医がRBCラボの結果を分析するのに時間とコストを削減するのに役立ちます。重複する細胞分離に焦点を当て、セグメンテーションプロセスでは最初に楕円を推定して赤血球を表します。精度は20血液塗抹標本で0.889です。画像。 
[概要]この方法は、凹点を検出して楕円を見つけます。次に、有向楕円フィッティングを使用してセルデータの拡張を見つけます。この方法を使用して、セルのオーバーラップとデータの不均衡の問題に取り組むことが望まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: JointsGait:A model-based Gait Recognition Method based on Gait Graph
  Convolutional Networks and Joints Relationship Pyramid Mapping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/eess.IV/paper_14.html">
      <font color="black">JointsGait:A model-based Gait Recognition Method based on Gait Graph
  Convolutional Networks and Joints Relationship Pyramid Mapping</font>
    </a>
  </h2>
  <font color="black">第二に、関節関係ピラミッドマッピング（JRPM）は、人がさまざまなスケールで歩いているときの人間の関節の関係に応じて、生物学的利点を備えた識別可能な特徴空間に時空間歩行特徴をマッピングするために提案されています。は、遠くから認識できるという利点があり、公共のセキュリティで広く使用できます。以前のアプローチとは異なり、JointsGaitはまず、外的要因による干渉が少ない歩行グラフ畳み込みネットワークを使用して、2D関節から時空間特徴を抽出しました。 
[ABSTRACT]新しいモデルベースの歩行認識方法jointsgaitは、2D人体関節から歩行情報を抽出するために提案されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br><font color="black">2020-04-27</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Driving Behavior Explanation with Multi-level Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_0.html">
      <font color="black">Driving Behavior Explanation with Multi-level Fusion</font>
    </a>
  </h2>
  <font color="black">マルチモーダルフュージョンの文献における最近の進歩を活用して、BEEFは、高レベルの意思決定機能と中レベルの知覚機能の間の相関関係をモデル化するように注意深く設計されています。軌道予測モデルの概要..私たちのアプローチの柔軟性と効率は、HDDとBDD-Xデータセットでの広範な実験で検証されています。 
[ABSTRACT] beefは、複数のレベルから機能を融合することを学習します、とadam scott.fusionは自動運転モデルの開発に基づいていると言います。システムの融合は、hddとbddの実験で検証されます-x</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Scene Text Detection with Scribble Lines -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_1.html">
      <font color="black">Scene Text Detection with Scribble Lines</font>
    </a>
  </h2>
  <font color="black">いくつかのベンチマークでの実験は、提案された方法が弱いラベリング方法と元のポリゴンベースのラベリング方法の間のパフォーマンスギャップを埋め、さらに優れたパフォーマンスを示すことを示しています。さらに、落書きを使用するために弱く監視されたシーンテキスト検出フレームワークが提案されます。テキスト検出用の行..これは、さまざまな形状のテキストの一般的なラベル付け方法であり、低いラベル付けコストが必要です。 
[ABSTRACT]ベンチマークは、テキスト検出のためにポリゴンではなく落書き線でテキストに注釈を付けるために提案されています。この方法は、より単純な注釈でパフォーマンスを向上させるために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: vLPD-Net: A Registration-aided Domain Adaptation Network for 3D Point
  Cloud Based Place Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_2.html">
      <font color="black">vLPD-Net: A Registration-aided Domain Adaptation Network for 3D Point
  Cloud Based Place Recognition</font>
    </a>
  </h2>
  <font color="black">ただし、実世界での登録と場所認識モデルのトレーニングのために高品質の点群データとグラウンドトゥルースを取得するには、時間と労力がかかります。構造認識登録ネットワークが導入され、幾何学的特性から特徴を学習し、メトリック学習には、マッチングレートベースのトリプレット損失が含まれます。モデルは、GTA-Vを介した新しい仮想LiDARデータセットを通じて、さまざまな気象条件と日中条件でトレーニングされ、ドメインの適応は、ローカルとグローバルを調整することによって実世界のドメインに実装されます。特徴。 
[概要]サイトを意識した登録ネットワークとドメイン適応の影響を修正するために大規模な調査が行われました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Kinematics-Guided Reinforcement Learning for Object-Aware 3D Ego-Pose
  Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_3.html">
      <font color="black">Kinematics-Guided Reinforcement Learning for Object-Aware 3D Ego-Pose
  Estimation</font>
    </a>
  </h2>
  <font color="black">また、ドリフトを修正し、推定された人間とオブジェクトの相互作用を改善するための微調整ステップを構築します。制御された設定と野生の設定の両方での実験は、私たちの方法がオブジェクト条件付き3Dエゴポーズシーケンスを正常に抽出できることを示しています。は物理法則と一致しています。これは、エゴセントリックビデオからオブジェクト（椅子、ボックス、障害物など）との物理的に有効な3D全身相互作用シーケンスを推定する最初の作業です。 
[概要]目的は、3Dシーンのコンテキストを組み込み、ポーズ推定の品質を向上させることです。これは、自己中心的なビデオからのオブジェクトとの物理的に有効な3D全身相互作用シーケンスを推定する最初の作業です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Convex Regularization Behind Neural Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_4.html">
      <font color="black">Convex Regularization Behind Neural Reconstruction</font>
    </a>
  </h2>
  <font color="black">ただし、ニューラルネットワークの非凸で不透明な性質は、医用画像などの高感度アプリケーションでの有用性を妨げます。ニューラルネットワークは、逆問題で高解像度画像を再構築するための大きな可能性を示しています。特に、ニューラルネットワークのトレーニングを意味します。重み減衰規則化を使用すると、パスのスパース性が誘発されますが、予測はピースワイズ線形フィルタリングです。 
[概要]アトラスネットワークは、最適なトレーニングと予測を提供します。また、ナビゲーションとナビゲーションの予防接種も提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: E3D: Event-Based 3D Shape Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_5.html">
      <font color="black">E3D: Event-Based 3D Shape Reconstruction</font>
    </a>
  </h2>
  <font color="black">移動するイベントカメラからの出力は、時空間勾配のまばらなポイントセットであり、主にシーン/オブジェクトのエッジと輪郭をスケッチします。最初に、イベントフレームのスタックを変換するためのイベントからシルエット（E2S）ニューラルネットワークモジュールを紹介します。対応するシルエットに、カメラポーズ回帰用の追加のニューラルブランチを使用します。イベントカメラ、高ダイナミックレンジを可能にしながら大幅に低い電力、遅延、データコストのセンサーを使用して3D再構成にアプローチします。 
[概要]現在の3Dモデルは、rgb、rgb --d、LIDARセンサーに基づいています。これらには、イベントフレームのスタックを対応するシルエットに変換する3dおよびe2sニューラルネットワークモジュールが含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Independently Recurrent Neural Network (IndRNN) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_6.html">
      <font color="black">Deep Independently Recurrent Neural Network (IndRNN)</font>
    </a>
  </h2>
  <font color="black">基本的なスタック型IndRNN、残留IndRNN、密に接続されたIndRNNなど、さまざまなより深いIndRNNアーキテクチャが調査されました。これらはすべて、既存のRNNよりもはるかに深くなる可能性があります。さらに、IndRNNは各タイムステップでの計算を減らし、10を超える可能性があります。一般的に使用される長短期記憶（LSTM）よりも2倍高速です。これらの問題に対処するために、このペーパーでは、アダマール積として定式化されたリカレント接続を備えた新しいタイプのRNNを提案します。これは、独立リカレントニューラルネットワーク（IndRNN）と呼ばれます。同じ層のニューロンは互いに独立しており、層を越えて接続されています。 
[ABSTRACT] indrnnは、リカレント接続を持つrnnsの一種です。これらには、同じレイヤー内のニューロンが互いに独立しており、レイヤー間で接続されています。これは、indrnnがreluなどの非飽和活性化関数で動作し、まだ消えている可能性があるためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-11">
        <br><font color="black">2019-10-11</font>
      </time>
    </span>
</section>
<!-- paper0: Structure-Consistent Weakly Supervised Salient Object Detection with
  Local Saliency Coherence -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_7.html">
      <font color="black">Structure-Consistent Weakly Supervised Salient Object Detection with
  Local Saliency Coherence</font>
    </a>
  </h2>
  <font color="black">一貫性のある顕著性マップが入力と同じ画像の異なるスケールで予測されることを保証する自己無撞着メカニズムとして顕著性構造の一貫性損失を設計します。これは、モデルの一般化能力を強化するための正則化手法と見なすことができます。詳細な顕著な領域を提供する場合、完全なオブジェクト構造を持つ統合された顕著な領域を予測するために、画像の特徴とピクセル距離に基づいてラベルをラベルのない領域に伝播するローカルコヒーレンス損失を提案します。ECSSDデータセットの場合：F_ \ beta = 0.8995、 E_ \ xi = 0.9079およびMAE = 0.0489 $）、このタスクの以前の最良の方法よりも、Fメジャーで4.60 \％、Eメジャーで2.05 \％、MAEで1.88 \％の平均ゲインがあります。 
[概要]弱い教師ありと完全教師ありの顕著なオブジェクト検出方法の間のパフォーマンスのギャップは非常に大きいです。完全なオブジェクトとの統合された顕著な領域を予測するために、画像の特徴とピクセル距離に基づいてラベルをラベルなし領域に伝播するローカルコヒーレンス損失を提案します。構造</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-08">
        <br><font color="black">2020-12-08</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Denoising of Flash and No-Flash Pairs for Photography in Low-Light
  Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_8.html">
      <font color="black">Deep Denoising of Flash and No-Flash Pairs for Photography in Low-Light
  Environments</font>
    </a>
  </h2>
  <font color="black">特に、私たちの方法は、ノイズがなく、フラッシュ画像に見られる鋭い影や強い鏡面ハイライトのない正確な周囲色を含む画像を生成します。私たちのネットワークは、平滑化された画像を組み合わせることにより、高品質の画像を生成することを効果的に学習することを示しますフラッシュ入力から抽出された高周波アルベドの詳細を使用した、フラッシュなしの画像からのシーンの周囲の外観の推定。当社のネットワークは、ゲインマップとカーネルのフィールドを出力します。後者は、画像ごとの要素を線形混合することによって取得されます。低ランクのカーネルベース。 
[概要]私たちの方法は、シーンの高品質なレンダリングを作成することです。最初にカーネルフィールドをフラッシュなしの画像に適用します。次に、結果にゲインマップを掛けて、最終的な出力を作成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Simple is not Easy: A Simple Strong Baseline for TextVQA and TextCaps -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_9.html">
      <font color="black">Simple is not Easy: A Simple Strong Baseline for TextVQA and TextCaps</font>
    </a>
  </h2>
  <font color="black">それをテキストベースの画像キャプションに転送すると、TextCaps Challenge 2020の勝者も上回ります。この論文では、単純な注意メカニズムが、ベルやホイッスルなしで同じまたはさらに優れた仕事をすることができると主張します。このメカニズムの下で、 OCRトークン機能を個別の視覚的および言語的注意ブランチに分割し、それらを人気のあるTransformerデコーダーに送信して、回答またはキャプションを生成するだけです。 
[概要] 2つのタスク（テキストベースの視覚的な質問応答と画像のキャプション、既存のビジョンからのテキスト拡張-言語アプリケーション）が急速に普及しています。シンプルなプレゼンテーションメカニズムでも同じことができ、ベルやホイッスルなしでさらに優れた仕事をすることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Gradient Flow with Unrolled Highway Expectation Maximization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_10.html">
      <font color="black">Improving Gradient Flow with Unrolled Highway Expectation Maximization</font>
    </a>
  </h2>
  <font color="black">HEMNetは、展開されたアーキテクチャの深さに沿ってスケーリングされたスキップ接続または高速道路を備えているため、バックプロパゲーション中の勾配フローが改善され、標準の展開されたEMと比較して、追加の計算とメモリのコストはごくわずかです。ただし、バックボーンネットワークを区別してトレーニングすることは困難です。勾配消失問題が発生しやすいため、EM反復を逆伝播することによって..モデルベースの機械学習手法をディープニューラルアーキテクチャに統合することで、ディープニューラルネットの表現力とモデルベースの手法の機能の両方を活用できます。ドメイン固有の知識。 
[ABSTRACT]システムは、モデルのモデルの展開された反復で構成されます。hemnetは、ユタベースのモデルの展開された拡張で構成されます。これは、バックボーンニューラルネットワークと共同でトレーニングされた展開されたレイヤーワイズ構造の結果です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Decoupled Classification Refinement: Hard False Positive Suppression for
  Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_11.html">
      <font color="black">Decoupled Classification Refinement: Hard False Positive Suppression for
  Object Detection</font>
    </a>
  </h2>
  <font color="black">分類ネットワークの初期段階に配置されたROIプーリングを使用して、DCRに適応受容野を適用します。シンプルで効果的で広く適用可能な分離分類精製（DCR）ネットワークによって検出器分類力の可能性を示します。特に、DCRは、ローカリゼーションネットワーク（ベース検出器）と並行して別個の分類ネットワークを配置します。 
[概要] 3つの要因があると推測します：特徴学習の目標が一致しないため、共有特徴表現が最適ではありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-10-05">
        <br><font color="black">2018-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Data Augmentation for Vehicle Detection in Aerial Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_12.html">
      <font color="black">Generative Data Augmentation for Vehicle Detection in Aerial Images</font>
    </a>
  </h2>
  <font color="black">提案された方法は、異なるジェネレーターと統合できるという意味で一般的です。実験は、この方法がPluralisticおよびDeepFillと統合された場合、平均精度をそれぞれ最大25.2％および25.7％向上させることを示しています。空中画像での車両検出性能の向上に焦点を当て、トレーニングデータセット内の車両オブジェクトの境界ボックス注釈よりも追加の監視を必要としない生成的増強方法を提案します。 
[概要]提案された方法は、検出器をより多くのインスタンスでトレーニングできるようにすることで、車両検出のパフォーマンスを向上させます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Video Deblurring by Fitting to Test Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_13.html">
      <font color="black">Video Deblurring by Fitting to Test Data</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、ビデオからシャープなフレームをヒューリスティックに選択し、これらのシャープなフレームで畳み込みニューラルネットワークをトレーニングします。実際のビデオデータで実施された実験は、モデルが最先端のビデオよりもクリアでシャープなビデオを再構築できることを示しています。ブレ除去アプローチ..内部学習方法として、私たちのアプローチには、トレーニングデータとテストデータの間にドメインギャップがありません。これは、既存のビデオブレ除去アプローチにとって問題となる問題です。 
[概要]私たちのモデルは、最新のビデオブレ除去アプローチよりも鮮明でシャープなビデオを再構築できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Kernel Anomalous Change Detection for Remote Sensing Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_14.html">
      <font color="black">Kernel Anomalous Change Detection for Remote Sensing Imagery</font>
    </a>
  </h2>
  <font color="black">アルゴリズムの実装と、実際のシナリオでの自然な異常な変化のデータベースを提供しますhttp://isp.uv.es/kacd.html ..普及した問題とACDの問題の両方で導入されたカーネルメソッドのパフォーマンスを示します。さまざまな解像度（AVIRIS、Sentinel-2、WorldView-2、Quickbird）を使用したマルチスペクトルおよびハイパースペクトル画像の実際の変更とシミュレートされた変更。線形定式化と比較して検出精度の点で優れたパフォーマンスが達成され、検出精度が向上し、誤検出が減少します。 -アラーム率。 
[ABSTRACT]これには、方法論が利用できる多くのアプリケーションがあります。特に、ガウス分布とアマッドコンター（ec）分布を利用するアルゴリズムに焦点を当てています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: AMVNet: Assertion-based Multi-View Fusion Network for LiDAR Semantic
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_15.html">
      <font color="black">AMVNet: Assertion-based Multi-View Fusion Network for LiDAR Semantic
  Segmentation</font>
    </a>
  </h2>
  <font color="black">計算リソースとメモリリソースが限られていることが多い自動運転車..広範な実験により、AMVNetはSemanticKITTIとnuScenesの両方のベンチマークデータセットで最先端の結果を達成し、私たちのアプローチはクラススコアを組み合わせるベースライン方法よりも優れていることが示されていますこのようなアプローチは、ロボットシステムにとって望ましいものです。たとえば、
[ABSTRACT] amvnetの達成状態-amvnetのセマンティックキットおよびnuscenesデータセット</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Annotation-Free Evaluation of Cross-Lingual Image Captioning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_16.html">
      <font color="black">Towards Annotation-Free Evaluation of Cross-Lingual Image Captioning</font>
    </a>
  </h2>
  <font color="black">参照がゼロであるためより困難な2番目のシナリオについては、CMedRelを提案して、CLinRelで使用されるのと同じ視覚的特徴空間で生成されたキャプションと画像コンテンツ間のクロスメディア関連性を計算します。WMDRelはモデルで生成されたキャプションと、Word Moverの距離を使用した英語参照の機械翻訳との間の意味的関連性。両方のキャプションを深い視覚的特徴空間に投影することにより、CLinRelは視覚指向の言語間関連性の尺度です。 
[要約]参照が利用可能な最初のシナリオでは、2つのメトリックを提案します。wmdrelとclinrelは、視覚的-客観的クロス-言語的関連性の測定値を測定します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Recurrence-free unconstrained handwritten text recognition using gated
  fully convolutional network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_17.html">
      <font color="black">Recurrence-free unconstrained handwritten text recognition using gated
  fully convolutional network</font>
    </a>
  </h2>
  <font color="black">私たちのモデルはCTC損失でトレーニングされ、RIMESデータセットとIAMデータセットの両方で競争力のある結果を示しています。このペーパーでは、よく知られているCNN + LSTMアーキテクチャの再発のない代替であるゲート付き完全畳み込みネットワークアーキテクチャを紹介します。これらのコンポーネントの主な欠点は、関連するパラメーターの数が多いことと、トレーニングおよび予測中にそれらが順次実行されることです。 
[概要] lstmセルを使用する代わりの主な方法は、畳み込み層を多用することで長期記憶喪失を補うことです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: UniT: Unified Knowledge Transfer for Any-shot Object Detection and
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_18.html">
      <font color="black">UniT: Unified Knowledge Transfer for Any-shot Object Detection and
  Segmentation</font>
    </a>
  </h2>
  <font color="black">この分類法は、アルゴリズム設計を大部分サイロ化しています。オブジェクトの検出とセグメンテーションの方法は、トレーニングのために大規模なインスタンスレベルの注釈に依存しています。これは、収集が困難で時間のかかるものです。さまざまな設定でパフォーマンスの向上を示します。 
[概要]ベーススケールスケールの場合、モデルは弱いものから完全に監視されたものまでアノタを学習します。これらのツールを使用すると、モデルは単純なモデルの使用から学習します。これらのツールを使用して、さまざまな種類の監視を作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-12">
        <br><font color="black">2020-06-12</font>
      </time>
    </span>
</section>
<!-- paper0: DS-Net: Dynamic Spatiotemporal Network for Video Salient Object
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_19.html">
      <font color="black">DS-Net: Dynamic Spatiotemporal Network for Video Salient Object
  Detection</font>
    </a>
  </h2>
  <font color="black">また、トップダウンのクロスアテンションアグリゲーション（CAA）プロシージャは、時空間フィーチャの動的な補完的アグリゲーションを容易にするように設計されています。動的ウェイトジェネレータ（DWG）は、対応する顕著性ブランチの信頼性を自動的に学習するように設計されています。ベンチマークVOS、DAVIS、FBMS、SegTrack-v2、およびViSalは、提案された方法が最先端のアルゴリズムよりも優れたパフォーマンスを実現することを示しています。 
[ABSTRACT]システムはオプティカルフローを使用して空間情報を抽出しますが、カメラの動きや顕著なオブジェクトの部分的な動きのために、顕著性の役割を検出できないことがよくあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Better Object Detection in Scale Variation with Adaptive Feature
  Selection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_20.html">
      <font color="black">Towards Better Object Detection in Scale Variation with Adaptive Feature
  Selection</font>
    </a>
  </h2>
  <font color="black">これは、マイナークラスのパフォーマンスを向上させるために重要です。ほぼ無料の推論オーバーヘッドを導入しながら、特徴的なピラミッド構造を持つ検出器のパフォーマンスを大幅に向上させます。さらに、クラス認識サンプリングメカニズム（CASM）が提案されています。各クラスの統計的特性に基づいて、各トレーニング画像に対するサンプリング比を再重み付けすることにより、クラスの不均衡の問題に取り組みます。 
[要約]コードは、米国で99999999999999999999999999999999999999999999に利用できます。これは、米国ベースのチャネルで利用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-06">
        <br><font color="black">2020-12-06</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Activation Functions: A new paradigm for understanding Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_21.html">
      <font color="black">Learning Activation Functions: A new paradigm for understanding Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">SLAFは、最適な活性化関数の適切な近似に役立つ事前定義された基本要素の加重和として与えられます。活性化関数の領域での研究の範囲は限られており、最適化の容易さや一般化の質の向上を中心としています。ニューラルネットワーク（NN）の。これらの基本要素の係数により、連続関数（従来のすべての活性化からなる）の空間全体を検索できます。 
[概要]トレーニング中に学習される「自己学習可能な活性化関数」（slaf）を提案します。これらは定義されていますが、ネットワークの助けを借りて重み付けされています。slnnsがリプシッツ連続活性化を使用して任意のニューラルネットワークをデートできることを証明します。それらの容量を強調する任意のエラー</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-23">
        <br><font color="black">2019-06-23</font>
      </time>
    </span>
</section>
<!-- paper0: Hateful Memes Detection via Complementary Visual and Linguistic Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_22.html">
      <font color="black">Hateful Memes Detection via Complementary Visual and Linguistic Networks</font>
    </a>
  </h2>
  <font color="black">モーダル情報をさらに統合するために、Hateful Memes Challenge2020で補完的な視覚的および言語的ネットワークに基づく候補解を調査します。コードはhttps://github.com/webYFDT/hatefulで入手できます。言語の埋め込みはで構成されています。 3つのコンポーネント、つまり、文の単語の埋め込み、位置の埋め込み、および対応するSpacyの埋め込み（Sembedding）。これは、Spacyによって抽出された語彙によって表されるシンボルです。 
[概要]事前にトレーニングされた分類器とオブジェクト検出器を使用して、入力から社会的関心（e）のコンテキスト機能と領域を取得します。視覚的埋め込みの位置表現の融合は、modingの主な課題です。嫌なミーム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: PhysCap: Physically Plausible Monocular 3D Motion Capture in Real Time -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_23.html">
      <font color="black">PhysCap: Physically Plausible Monocular 3D Motion Capture in Real Time</font>
    </a>
  </h2>
  <font color="black">ビデオはhttp://gvv.mpi-inf.mpg.de/projects/PhysCapで入手できます。単色カメラからのマーカーのない3Dヒューマンモーションキャプチャは、大きな進歩を遂げました。私たちの方法は、物理的に妥当で時間的に安定したグローバル3Dヒューマンモーションを、物理的に妥当でない姿勢、床への侵入、フットスケートなしで、リアルタイムおよび一般的にビデオからキャプチャします。シーン。 
[概要]ビデオは25fpsでシングルカラーカメラによってキャプチャされました。これは、物理的にもっともらしい、リアルタイムのマーカーの最初のアルゴリズムを示しています-人間の少ない3Dモーションキャプチャ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-20">
        <br><font color="black">2020-08-20</font>
      </time>
    </span>
</section>
<!-- paper0: Conjugate Mixture Models for Clustering Multimodal Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_24.html">
      <font color="black">Conjugate Mixture Models for Clustering Multimodal Data</font>
    </a>
  </h2>
  <font color="black">問題を尤度最大化タスクとして定式化し、関連する共役期待値最大化アルゴリズムを導出します。一貫したモデル選択基準が提案されます。提案されたアルゴリズムの収束特性が徹底的に調査されます。 
[要約]このようなアプローチの主な難しさは、単峰性クラスタリングが相互に一貫していることを保証することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Machine Learning for Cataract Classification and Grading on Ophthalmic
  Imaging Modalities: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_25.html">
      <font color="black">Machine Learning for Cataract Classification and Grading on Ophthalmic
  Imaging Modalities: A Survey</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、メリットと制限の両方の既存の作業についての洞察も提供します。さらに、機械学習技術に基づく自動白内障の分類とグレーディングのいくつかの課題について説明し、将来の研究のためにこれらの課題に対する可能な解決策を提示します。白内障の分類と眼の画像に基づく等級付けのための機械学習の最近の進歩の調査。 
[ABSTRACT]研究者は、白内障の自動分類と評価のための人工知能技術を開発しました。これは、臨床医が白内障を時間内に予防および治療するのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Tactile Object Pose Estimation from the First Touch with Geometric
  Contact Rendering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_26.html">
      <font color="black">Tactile Object Pose Estimation from the First Touch with Geometric
  Contact Rendering</font>
    </a>
  </h2>
  <font color="black">また、ポーズ分布を推論し、他の知覚システムまたは複数の接触から来る追加のポーズ制約を含めることもできます。私たちのアプローチは、異なるオブジェクトポーズから生じる可能性のある接触形状を説明するためにポーズ分布を回帰しながら、特徴的な触覚観察から高精度のポーズ推定を提供します。 ..ウェブサイト：http：//mcube.mit.edu/research/tactile_loc_first_touch.html 
[ABSTRACT]たとえば、オブジェクトを作成します-実際の触覚観察から接触形状へのag theoマップ。これは、それが可能であるという事実に基づいています。単一の触覚観察からオブジェクトをローカライズします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-supervised Active Learning for Instance Segmentation via Scoring
  Predictions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_27.html">
      <font color="black">Semi-supervised Active Learning for Instance Segmentation via Scoring
  Predictions</font>
    </a>
  </h2>
  <font color="black">さらに、上記のTSPを半教師ありで使用するプログレッシブ疑似ラベリング体制を考案し、ラベル付きデータとラベルなしデータの両方を活用して、インスタンスのセグメンテーションのパフォーマンスを最大化しながら、ラベル付けの労力を最小限に抑えることができます。具体的には、トリプレットという名前の不確実性サンプリング戦略を提示します。クラス、バウンディングボックス、マスクからの手がかりをランク付けするサンプルを明示的に組み込むためのスコアリング予測（TSP）。医療画像データセットの結果は、提案された方法が意味のある方法で利用可能なデータからの知識の具体化をもたらすことを示しています。 
[概要]提案された方法は、クラス、境界ボックス、およびマスクからの手がかりをランク付けするサンプルを組み込むように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Pruning Filter in Filter -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_28.html">
      <font color="black">Pruning Filter in Filter</font>
    </a>
  </h2>
  <font color="black">具体的には、フィルター$ F \ in \ mathbb {R} ^ {C \ times K \ times K} $を$ K \ times K $ストライプとして扱います。つまり、$ 1 \ times 1 $フィルター$ \ in \ mathbb {R } ^ {C} $次に、フィルター全体ではなくストライプを剪定することで、ハードウェアに配慮しながら、従来のFPよりも細かい粒度を実現できます。両方の方法の強度を収束させるために、フィルター内のフィルターを剪定することを提案します。 。このメソッドをSWP（\ emph {Stripe-Wise Pruning}）と呼びます。 
[概要]剪定は、フィルター剪定（fp）と重み剪定（wp）の2つのカテゴリに分類できます。特に、単一のフィルターの設計を取り除くために、フィルター内のフィルターを剪定することを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-30">
        <br><font color="black">2020-09-30</font>
      </time>
    </span>
</section>
<!-- paper0: ROSE: A Retinal OCT-Angiography Vessel Segmentation Dataset and New
  Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_29.html">
      <font color="black">ROSE: A Retinal OCT-Angiography Vessel Segmentation Dataset and New
  Model</font>
    </a>
  </h2>
  <font color="black">実験結果は、SCF-Netが従来の方法や他の深層学習方法よりもOCT-Aで優れた血管セグメンテーションパフォーマンスをもたらすことを示しています。第3に、最先端の血管セグメンテーションモデルと提案されたROSEデータセットのSCF-Net ..ただし、OCT-Aでの網膜血管の自動セグメンテーションは、多くの眼関連疾患の理解における重要性にもかかわらず、毛細血管の視認性の低さや血管の複雑さの高さなどのさまざまな課題のために十分に研究されていません。 。 
[概要]網膜画像解析の分野で初めて、専用の網膜oct-セグメンテーションデータセット（バラ）を構築します。これは、中心線-レベルまたはピクセルレベルのいずれかで、229a-血管のある画像-注釈-で構成されます。これは、毛細血管の視認性が低い、血管が複雑であるなどのさまざまな課題によるものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-10">
        <br><font color="black">2020-07-10</font>
      </time>
    </span>
</section>
<!-- paper0: Modeling and Enhancing Low-quality Retinal Fundus Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_30.html">
      <font color="black">Modeling and Enhancing Low-quality Retinal Fundus Images</font>
    </a>
  </h2>
  <font color="black">ただし、さまざまなレベルの経験を持つオペレーターによってキャプチャされた眼底画像は、品質に大きなばらつきがあります。合成画像と実画像の両方での実験は、私たちのアルゴリズムが網膜の詳細を失うことなく低品質の眼底画像を効果的に修正することを示しています。検眼鏡イメージングシステムを分析し、不均一な照明、画像のぼやけ、アーチファクトなど、主要な低品質要因の信頼できる劣化をシミュレートします。 
[概要]さまざまな経験を持つオペレーターが撮影した眼底画像は、品質に大きなばらつきがありますが、眼底画像の特殊な光ビームと網膜の構造により、自然画像強調法を直接使用してこれに対処できます。目的の眼底増強ネットワーク（cofe-net）は、グローバルな劣化要因を抑制するために提案されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br><font color="black">2020-05-12</font>
      </time>
    </span>
</section>
<!-- paper0: Discovering Clinically Meaningful Shape Features for the Analysis of
  Tumor Pathology Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_31.html">
      <font color="black">Discovering Clinically Meaningful Shape Features for the Analysis of
  Tumor Pathology Images</font>
    </a>
  </h2>
  <font color="black">これらの記述子の特徴が、全国肺スクリーニング試験（n = 143）の肺腺癌患者の患者生存転帰とどのように関連しているかを示しました。さらに、記述子ベースの予後モデルが開発され、The CancerGenomeの独立した患者コホートで検証されました。アトラスプログラムプログラム（n = 318）。特定された各腫瘍領域から、その形状、形状、およびトポロジーを定量化する30の明確に定義された記述子を抽出しました。 
[要約]プロセスは、組織学的詳細を高解像度でキャプチャする新しい画像を生成します。これらの記述子は、その形状、地理、および信頼性を定量化します。これらの記述子ベースの予後モデルは、独立した患者コホートで開発および検証されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Video Object Segmentation with Episodic Graph Memory Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_32.html">
      <font color="black">Video Object Segmentation with Episodic Graph Memory Networks</font>
    </a>
  </h2>
  <font color="black">構造化された外部メモリ設計により、視覚情報が限られている場合でも、モデルで新しい知識を包括的にマイニングしてすばやく保存できます。また、微分可能なメモリコントローラは、有用な表現をメモリに保存するための抽象的な方法と、後でこれらの表現を予測に使用する方法をゆっくりと学習します。 、勾配降下法を介して..さらに、学習可能なコントローラーが組み込まれているため、メモリの読み取りと書き込みが容易になり、固定メモリスケールが維持されます。さらに、提案されたグラフメモリネットワークは、きちんとした、しかし原理的なフレームワークを生成します。 -ショットおよびゼロショットのビデオオブジェクトセグメンテーションタスク。 
[概要]提案されたグラフメモリネットワークは、ネットワークの新しいパターンメモリネットワークに対応するように設計されています。ネットワークは、ワンショットおよびゼロショットのビデオオブジェクトセグメンテーションタスクによって適切に一般化できる便利なモデルを提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-14">
        <br><font color="black">2020-07-14</font>
      </time>
    </span>
</section>
<!-- paper0: Batch Group Normalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_33.html">
      <font color="black">Batch Group Normalization</font>
    </a>
  </h2>
  <font color="black">正規化は効果的なソリューションの1つです。DeepConvolutionalNeuralNetworks（DCNN）は、トレーニングが困難で時間がかかります。以前の正規化方法の中で、バッチ正規化（BN）は、中規模および大規模のバッチサイズで良好に機能し、複数のビジョンタスクがありますが、バッチサイズが小さいとパフォーマンスが大幅に低下します。 
[概要]この論文では、bnが非常に大きなバッチサイズで飽和することがわかりました。これには、ワーカーごとに128の画像、つまりgpuが含まれ、bnの劣化は、ノイズの多い統計計算または混乱した統計計算によって引き起こされることが示唆されます。したがって、異なるバッチサイズに対して、大きなバッチ統計も混乱したバッチ統計も提供しません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-04">
        <br><font color="black">2020-12-04</font>
      </time>
    </span>
</section>
<!-- paper0: Improving the Fairness of Deep Generative Models without Retraining -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_34.html">
      <font color="black">Improving the Fairness of Deep Generative Models without Retraining</font>
    </a>
  </h2>
  <font color="black">GAN解釈の最近の作業を利用して、ターゲット属性に対応する潜在空間の方向を識別し、出力画像全体でバランスの取れた属性分布を持つ潜在コードのセットを操作します。実験は、私たちの方法がの公平性を大幅に改善できることを示しています。画像生成、定量的および定性的の両方で潜在的なベースラインを上回ります。潜在コードセットの分布に適合するガウス混合モデル（GMM）を学習します。これは、より公平な属性分布を持つ画像を生成するための潜在コードのサンプリングをサポートします。 
[概要]再トレーニングなしで事前トレーニングされたガンモデルの画像生成の公平性を向上させるためのシンプルで効果的な方法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Positional Encoding as Spatial Inductive Bias in GANs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_35.html">
      <font color="black">Positional Encoding as Spatial Inductive Bias in GANs</font>
    </a>
  </h2>
  <font color="black">DCGANやPGGANなどの他の生成アーキテクチャでも同じ現象が見られます。より良い空間誘導バイアスを提供するために、代替の位置エンコーディングを調査し、その効果を分析します。より柔軟な位置エンコーディングに明示的に基づいて、新しいマルチトレーニング戦略をスケーリングし、最先端の無条件ジェネレーターStyleGAN2でその有効性を実証します。 
[概要]このようなジェネレーターが、空間的にだけでグローバル構造をキャプチャする方法を知りたいと考えています。 iid。 ..これは、そのような機能の大部分が、ジェネレータでゼロパディングを使用する場合の暗黙的な位置認識によってもたらされることを示すために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: AIDE: Annotation-efficient deep learning for automatic medical image
  segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_36.html">
      <font color="black">AIDE: Annotation-efficient deep learning for automatic medical image
  segmentation</font>
    </a>
  </h2>
  <font color="black">3つの医療センターからの872人の患者の11,852枚の乳房画像を含む3つの臨床データセットについて、AIDEは、完全に監視されたカウンターパートによって生成されたものに匹敵するセグメンテーションマップと、10％のトレーニング注釈のみを利用する独立した放射線科医の手動注釈を一貫して生成します。注釈効率の高いディープラーニング（AIDE）は、画像の内容をより適切に調査することにより、低品質の注釈を段階的に修正します。正確な画像セグメンテーションは、疾患の診断や治療計画などの医療画像アプリケーションにとって非常に重要です$ ^ {1-4} $。 
[概要]ディープラーニング手法は通常、高品質の手動注釈付きのトレーニングデータセットに依存しています。これらは、医用画像では利用できないことがよくあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Two-phase Pseudo Label Densification for Self-training based Domain
  Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_37.html">
      <font color="black">Two-phase Pseudo Label Densification for Self-training based Domain
  Adaptation</font>
    </a>
  </h2>
  <font color="black">第2段階では、信頼度に基づく簡単な分類を実行します。ただし、信頼できる予測のみが疑似ラベルとして使用されるため、既存の自己トレーニングアプローチでは、実際には必然的にスパース疑似ラベルが生成されます。この問題に取り組むために、TPLDと呼ばれる新しい2フェーズ疑似ラベル高密度化フレームワークを提案します。 
[概要]自己トレーニングスキームには、ターゲットデータのハード処理が含まれます。ターゲット疑似ラベルが生成され、ネットワークが再トレーニングされます。結果としてトレーニングが不足すると、信号が最適ではなく、エラーが発生しやすいモデルになるため、これは重要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: A Deep Learning Bidirectional Temporal Tracking Algorithm for Automated
  Blood Cell Counting from Non-invasive Capillaroscopy Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_38.html">
      <font color="black">A Deep Learning Bidirectional Temporal Tracking Algorithm for Automated
  Blood Cell Counting from Non-invasive Capillaroscopy Videos</font>
    </a>
  </h2>
  <font color="black">提案されたモデルは、他のベースライントラッカーよりも優れており、テストビデオで65.57％の複数オブジェクト追跡精度と73.95％のID F1スコアを達成しています。CycleTrackは、2つの単純なオンライン追跡モデルSORTとCenterTrackを組み合わせ、毛細血管血球の流れの機能に合わせて調整されています。血球は、連続するフレーム間の2つの反対の時間方向（順方向および逆方向の追跡）の変位ベクトルによって追跡されます。 
[概要]人間の血球追跡に加えて、ビデオの自動処理のためのソリューションがあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-26">
        <br><font color="black">2020-11-26</font>
      </time>
    </span>
</section>
<!-- paper0: Lipschitz Regularized CycleGAN for Improving Semantic Robustness in
  Unpaired Image-to-image Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_39.html">
      <font color="black">Lipschitz Regularized CycleGAN for Improving Semantic Robustness in
  Unpaired Image-to-image Translation</font>
    </a>
  </h2>
  <font color="black">この論文では、セマンティックのロバスト性を改善し、セマンティックフリッピングの問題を軽減するための新しいアプローチであるリプシッツ正則化CycleGANを提案しました。複数の一般的なデータセットでアプローチを評価し、いくつかの既存のGANベースの方法と比較します。結果は、セマンティックフリッピングが少ない堅牢な変換を生成するという私たちのアプローチの有効性と利点を示唆しています。 
[概要]これは、ソースドメインとターゲットドメイン間のセマンティック統計の違いによるものであると主張します。ジェネレータにペナルティガンサイクルサイクル損失を追加しました。これにより、セマンティックに一貫した変換が促進されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Explanation-Guided Training for Cross-Domain Few-Shot Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_40.html">
      <font color="black">Explanation-Guided Training for Cross-Domain Few-Shot Classification</font>
    </a>
  </h2>
  <font color="black">クロスドメイン少数ショット分類タスク（CD-FSC）は、少数ショット分類と、データセットによって表されるドメイン全体を一般化する要件を組み合わせます。次に、機能を動的に見つけて強調する、モデルに依存しない説明ガイド付きトレーニング戦略を開発します。これは予測にとって重要です。まず、FSCモデルの予測を説明するために、レイヤーごとの関連性伝播（LRP）メソッドを調整します。 
[概要]システムは、fscモデルの予測に適用されたときに既存の説明方法から得られた説明スコアを組み合わせます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-17">
        <br><font color="black">2020-07-17</font>
      </time>
    </span>
</section>
<!-- paper0: Progressive Network Grafting for Few-Shot Knowledge Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_41.html">
      <font color="black">Progressive Network Grafting for Few-Shot Knowledge Distillation</font>
    </a>
  </h2>
  <font color="black">最初のステップでは、生徒のブロックを1つずつ教師に移植し、他の教師のブロックのパラメータと絡み合った移植されたブロックのパラメータを学習します。実験により、ラベルのないサンプルをいくつか使用するだけで、満足のいく結果が得られることがわかります。 CIFAR10、CIFAR100、およびILSVRC-2012の結果。ソースコードはhttps://github.com/zju-vipa/NetGraftで入手できます。 
[ABSTRACT]蒸留は蒸留の結果であり、知識の伝達を実現するために大量のラベル付きデータが必要です。2番目のステップでは、トレーニングを受けた生徒のブロックが段階的に接続され、教師のネットワークに一緒に移植され、学習した生徒のブロックが適応できるようになります。 ciub10とciju100では、私たちのパフォーマンスは知識蒸留スキームのパフォーマンスと同等です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: SnapMix: Semantically Proportional Mixing for Augmenting Fine-grained
  Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_42.html">
      <font color="black">SnapMix: Semantically Proportional Mixing for Augmenting Fine-grained
  Data</font>
    </a>
  </h2>
  <font color="black">実験によると、私たちの方法は、さまざまなデータセットおよびさまざまなネットワーク深度で既存の混合ベースのアプローチを一貫して上回っています。さらに、提案されたSnapMixは、中間レベルの機能を組み込むことにより、トップレベルのパフォーマンスを実現し、堅実なベースラインとして機能する可能性を示しています。きめの細かい認識のために..きめの細かい画像の主な識別情報は通常微妙な領域にあるため、この線に沿った方法では、きめの細かい認識でラベルノイズが大きくなりがちです。 
[ABSTRACT]最近のメソッドは、snapmixと呼ばれる新しいメソッドの作成に効果的であることが証明されています。このメソッドは、クラスアクティベーションマップを使用して、きめ細かいデータを拡張する際のラベルノイズを低減します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: One-Vote Veto: A Self-Training Strategy for Low-Shot Learning of a
  Task-Invariant Embedding to Diagnose Glaucoma -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_43.html">
      <font color="black">One-Vote Veto: A Self-Training Strategy for Low-Shot Learning of a
  Task-Invariant Embedding to Diagnose Glaucoma</font>
    </a>
  </h2>
  <font color="black">ソースコードと事前トレーニング済みモデルは、公開時に公開されます。それでも、CNNは通常、トレーニング用に大量の適切にラベル付けされたデータを必要とします。これは、特に疾患がまれで、専門家はコストがかかります。ラベルなしトレーニングデータの自己予測と対照的予測の両方を考慮に入れることにより、OVVセルフトレーニングは事前トレーニングされたMTTNNを微調整するための追加の疑似ラベルを提供します。 
[ABSTRACT] cnnは通常、トレーニングのために大量の適切にラベル付けされたデータを必要としますが、これは多くの生物医学画像分類アプリケーションでは利用できない場合があります。これらには、剖検、自己トレーニングされたmttnnが含まれ、事前トレーニングされたmttnnを微調整するための疑似ラベルを提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: BSN++: Complementary Boundary Regressor with Scale-Balanced Relation
  Modeling for Temporal Action Proposal Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_44.html">
      <font color="black">BSN++: Complementary Boundary Regressor with Scale-Balanced Relation
  Modeling for Temporal Action Proposal Generation</font>
    </a>
  </h2>
  <font color="black">2つの人気のあるベンチマークであるActivityNet-1.3とTHUMOS14で広範な実験が行われ、BSN ++が最先端のパフォーマンスを達成していることを示しています。次に、以前の方法で無視された提案と提案の関係を説明するために、提案を考案します。位置とチャネルの観点から2つの自己注意モジュールを含む関係ブロック。この論文では、時間的提案生成のために補完的な境界回帰子と関係モデリングを活用する新しいフレームワークであるBSN ++を提示します。 
[ABSTRACT]現在の方法では、境界の場所にノイズが多く、提案の取得に使用される信頼スコアの品質が低いことがよくあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Have convolutions already made recurrence obsolete for unconstrained
  handwritten text recognition ? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_45.html">
      <font color="black">Have convolutions already made recurrence obsolete for unconstrained
  handwritten text recognition ?</font>
    </a>
  </h2>
  <font color="black">最近、ゲートメカニズムを備えた完全畳み込みネットワークなどの無再発アーキテクチャが、競争力のある結果を達成するための1つの可能な代替案として提案されました。この論文では、畳み込みアーキテクチャを調査し、CNN + BLSTMベースラインと比較します。実験的研究を提案します。 RIMESデータセットを使用したオフライン手書き認識タスクのさまざまなアーキテクチャ、および印刷されたグリッドであるノートブックの背景で画像を拡張することで構成される修正バージョンについて。 
[概要]これらの昨年、リカレントネットワークと長短期記憶ネットワークはその分野で最先端のパフォーマンスを達成しました。これらの研究はそれを最先端のパフォーマンスにしました。これは直接的な効果があります。そのようなアーキテクチャのトレーニング時間に、またニューラルトレーニング時間に直接的な影響を与える</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Group-Wise Semantic Mining for Weakly Supervised Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_46.html">
      <font color="black">Group-Wise Semantic Mining for Weakly Supervised Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">特に、グループごとのセマンティックマイニング用のグラフニューラルネットワーク（GNN）を考案します。この場合、入力画像はグラフノードとして表され、画像のペア間の基本的な関係は、効率的な共注意メカニズムによって特徴付けられます。ネットワークは、反復メッセージパッシングによってエンドツーエンドでトレーニング可能であり、画像全体にインタラクションキューを伝播して、パフォーマンスを段階的に向上させます。人気のあるPASCAL VOC 2012およびCOCOベンチマークで実験を行い、モデルは最新の状態を生成します。アートパフォーマンス。 
[ABSTRACT] wsssは、画像のグループ内のセマンティック依存関係を明示的にモデル化する新しいグループ賢明な学習タスクです。モデルが過度の注意を払うのを防ぐために、グラフドロップアウトレイヤーをさらに提案し、モデルがより正確に学習することを奨励します。完全なオブジェクト応答</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Strong but Simple Baseline with Dual-Granularity Triplet Loss for
  Visible-Thermal Person Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_47.html">
      <font color="black">Strong but Simple Baseline with Dual-Granularity Triplet Loss for
  Visible-Thermal Person Re-Identification</font>
    </a>
  </h2>
  <font color="black">RegDBおよびSYSU-MM01データセットでの実験では、グローバル機能のみを使用すると、デュアルグラニュラリティトリプレット損失によってVT-ReIDのパフォーマンスが大幅に向上することが示されています。センターベースの損失が導入された場合、クラスのコンパクト性と粗粒度レベルからのクラス間識別..この手紙では、可視熱人の再識別（VT-ReID）のための概念的に単純で効果的な二重粒度トリプレット損失を提案します。 
[ABSTRACT] reidモデルは、常にサンプルベースのトリプレット損失と細粒度レベルからのID損失でトレーニングされます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Rectifier Neural Network with a Dual-Pathway Architecture for Image
  Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_48.html">
      <font color="black">Rectifier Neural Network with a Dual-Pathway Architecture for Image
  Denoising</font>
    </a>
  </h2>
  <font color="black">実験結果は、特にノイズが小さい場合に、モデルが優れたパフォーマンスをより速く達成することを示しています。最近、tanh活性化関数に基づくディープニューラルネットワークは、画像のノイズ除去において優れたパワーを示しました。同じネットワークアーキテクチャの下での画像ノイズ除去のための活性化関数。 
[概要]同じ隠れ層で入力と出力の重みが逆になっている2つの整流器ニューロンを組み合わせることにより、デュアルパスウェイ整流器ニューラルネットワークを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2016-09-10">
        <br><font color="black">2016-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Skillearn: Machine Learning Inspired by Humans' Learning Skills -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_49.html">
      <font color="black">Skillearn: Machine Learning Inspired by Humans' Learning Skills</font>
    </a>
  </h2>
  <font color="black">具体的には、これらのスキルを形式化し、それらを活用してより優れた機械学習（ML）モデルをトレーニングすることを目指しています。この目標を達成するために、一般的なフレームワークであるSkillearnを開発します。これは、人間の学習スキルを数学的に表現して使用するための原則的な方法を提供します。 MLモデルのトレーニングを改善するための正式に表現されたスキル..2つのケーススタディでは、Skillearnを適用して、テストに合格することによる学習とインターリーブ学習という2つの人間の学習スキルを形式化し、形式化されたスキルを使用して神経アーキテクチャ検索を改善します。 
[概要]これらのスキルを形式化し、それらを活用して、より優れた機械学習（ml）モデルをトレーニングすることを目指しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Facial Landmark Detection by Multi-order Multi-constraint Deep
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_50.html">
      <font color="black">Robust Facial Landmark Detection by Multi-order Multi-constraint Deep
  Networks</font>
    </a>
  </h2>
  <font color="black">提案されたMMDNが、より正確な境界適応型ランドマークヒートマップを生成し、ポーズの変化が大きく、オクルージョンが大きい顔の予測ランドマークに対する形状制約を効果的に強化できることを示すのは興味深いことです。具体的には、暗黙的な多次相関ジオメトリ対応（IMCG） ）モデルは、より識別力のある表現のために多次空間相関と多次チャネル相関を導入するために提案されています。挑戦的なベンチマークデータセットでの実験結果は、最先端の顔のランドマーク検出方法に対するMMDNの優位性を示しています。 
[概要]この論文では、より強力な特徴相関と形状制約学習のためのマルチ制約ディープネットワーク（mmdn）を提案します。これらには、グローバルな形状制約を強化するための明示的な確率ベースの境界適応相関（epbr）メソッドが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Automated Scoring of Nuclear Pleomorphism Spectrum with
  Pathologist-level Performance in Breast Cancer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_51.html">
      <font color="black">Automated Scoring of Nuclear Pleomorphism Spectrum with
  Pathologist-level Performance in Breast Cancer</font>
    </a>
  </h2>
  <font color="black">複数の実験で、完全に自動化されたアプローチにより、選択した関心領域とスライド画像全体で、それぞれ10人と4人の病理医と比較して、最高の病理医レベルのパフォーマンスを達成できました。核多形性は、核形態の変化の程度です。尿細管分化および有糸分裂カウントとともに、3層乳がんグレーディングのコンポーネントの1つ。ネットワークを従来の3つに制約することなく、複数の病理医の集合的な知識から、多種多様な腫瘍領域に関する深層学習ネットワークをトレーニングします。 -カテゴリ分類。 
[要約]腫瘍形態の変化の連続スペクトル。また、ベースラインとしての正常な上皮の追加の陰謀を動機付けます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Unsupervised Image Anomaly Detection: An Information Theoretic
  Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_52.html">
      <font color="black">Deep Unsupervised Image Anomaly Detection: An Information Theoretic
  Framework</font>
    </a>
  </h2>
  <font color="black">広範な実験により、提案されたフレームワークは、複数のベンチマークデータセットでいくつかの最先端技術を大幅に上回っていることが実証されています。代理タスクベースの方法は、最近、教師なし画像異常検出に大きな期待を寄せています。教師なしで最適化するために、正規データと異常データの分布が潜在空間で分離可能であるという仮定の下で、その下限は、相互情報とエントロピーの間のトレードオフを重み付けする関数と見なすことができることを示します。 
[ABSTRACT]教師なし画像用のシステムが初めて開発されましたが、トレーニング中に異常なデータが提供されない教師なし設定では直接最適化できません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervised Human Detection and Segmentation via Multi-view
  Consensus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_53.html">
      <font color="black">Self-supervised Human Detection and Segmentation via Multi-view
  Consensus</font>
    </a>
  </h2>
  <font color="black">複雑なシーンでの前景オブジェクトの自己監視検出とセグメンテーションは、完全に監視された対応物がドメイン固有のアプリケーションで十分な精度を提供するために過度に大量の注釈付きデータを必要とするため、注目を集めています。このようにして、提案の同時分布を学習します。複数のビューにわたって..推論時に、私たちの方法は単一のRGB画像で動作します。 
[概要]既存の自己監視アプローチは、主に外観と動きに関する制限的な仮定に依存しているため、非常に動的なアクティビティを描写したり、カメラの動きを伴うシーンでの使用が妨げられます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Generalizable Pedestrian Detection: The Elephant In The Room -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_54.html">
      <font color="black">Generalizable Pedestrian Detection: The Elephant In The Room</font>
    </a>
  </h2>
  <font color="black">まず、それらの設計（たとえば、この調査を通じて、既存の最先端の歩行者検出器は、同じデータセットでトレーニングおよびテストした場合は非常に優れたパフォーマンスを発揮しますが、データセット間の評価では一般化が不十分であることがわかります。この傾向の2つの理由があります。
[ABSTRACT]歩行者のいない汎用オブジェクト検出器（設計に合わせた適応）は、既存の最先端の歩行者検出器と比較してはるかに一般化されています。ただし、この傾向には2つの理由があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-19">
        <br><font color="black">2020-03-19</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Detect Objects with a 1 Megapixel Event Camera -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_55.html">
      <font color="black">Learning to Detect Objects with a 1 Megapixel Event Camera</font>
    </a>
  </h2>
  <font color="black">イベントカメラは、高い時間精度、低いデータレート、および高いダイナミックレンジで視覚情報をエンコードします。このペーパーでは、イベントベースのオブジェクト検出タスクのコンテキストでこれらすべての問題に対処します。データセットには14以上が含まれています。自動車のシナリオでの1メガピクセルのイベントカメラの時間記録と、高頻度でラベル付けされた、車、歩行者、および二輪車の25Mバウンディングボックス。 
[概要]このパフォーマンスギャップの主な理由は、フレームカメラと比較してイベントセンサーの空間解像度が低いことです。大規模なトレーニングデータセットの欠如は、イベントベースの処理のための十分に確立されたディープラーニングアーキテクチャの欠如です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Machine Learning for Glacier Monitoring in the Hindu Kush Himalaya -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_56.html">
      <font color="black">Machine Learning for Glacier Monitoring in the Hindu Kush Himalaya</font>
    </a>
  </h2>
  <font color="black">すぐに利用できるリモートセンシングデータを利用して、衛星画像からきれいな氷と破片で覆われた氷河の両方を識別して輪郭を描くモデルを作成します。私たちのアプローチは、衛星画像からの半自動マッピングに基づいています。氷河マッピングは、 hkh地域。 
[概要]気候変動は、生計が氷河生態系の健全性に依存している個人にリスクをもたらします。また、データを公開し、専門家がモデルの予測を視覚化して修正できるWebツールを開発しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Contrastive Transformation for Self-supervised Correspondence Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_57.html">
      <font color="black">Contrastive Transformation for Self-supervised Correspondence Learning</font>
    </a>
  </h2>
  <font color="black">ビデオ内レベルとビデオ間レベルの間の変換の一貫性を強制することにより、きめ細かい対応の関連付けが十分に保持され、インスタンスレベルの機能の識別が効果的に強化されます。ビデオ内学習は、単一のビデオ内のフレーム間で画像コンテンツを変換します。フレームペアワイズアフィニティを介して..私たちの方法は、完全に監視されたアフィニティ表現（ResNetなど）を上回り、特定のタスク用に設計された最近の完全に監視されたアルゴリズム（VOTやVOSなど）に対して競合的に実行されることにも言及する価値があります。 ）。 
[概要]私たちの画像は、信頼性の高い対応推定のために、ビデオ内およびビデオ間表現の関連付けを同時に考慮します。この方法は、最近の自己監視対応方法よりも優れたパフォーマンスを発揮するためにこの方法を使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Context-Aware Graph Convolution Network for Target Re-identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_58.html">
      <font color="black">Context-Aware Graph Convolution Network for Target Re-identification</font>
    </a>
  </h2>
  <font color="black">このようにして、グラフ推論中に他の簡単なサンプルの中でコンテキスト情報フローを使用してハードサンプルに対処できます。具体的には、効果的なハードギャラリーサンプラーを採用して、妥当なグラフサイズを維持しながら、ポジティブサンプルの高い再現率を取得します。計算の複雑さが低いトレーニングプロセスでの不均衡な問題を弱めます。プローブ-ギャラリーとギャラリー-ギャラリーの関係。したがって、情報が限られているか誤解を招く可能性があるため、ハードサンプルは十分に解決されない場合があります。 
[概要]これらの提案には、コンテンツの類似性の学習が含まれます。これらには、計算の複雑さが低いトレーニングプロセスでの不均衡な問題を弱めることができるハードギャラリーサンプラーが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-08">
        <br><font color="black">2020-12-08</font>
      </time>
    </span>
</section>
<!-- paper0: Physics-Guided Spoof Trace Disentanglement for Generic Face
  Anti-Spoofing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_59.html">
      <font color="black">Physics-Guided Spoof Trace Disentanglement for Generic Face
  Anti-Spoofing</font>
    </a>
  </h2>
  <font color="black">物理的特性に基づいて、なりすましの生成は、付加的なプロセスと修復プロセスの組み合わせとして表されます。付加的なプロセスは、余分なパターン（モアレパターンなど）を導入するなりすまし材料としてスプーフィングを説明します。 。ソースコードと事前トレーニング済みモデルは、公開時に公開されます。 
[概要]アンチスプーフィングモデルは、スプーフィング面をスプーフィングトレースと実際の対応物に解きほぐすように設計されています。新しいモデルは、3つの付加コンポーネントと1つの修復コンポーネントに基づいており、さまざまな周波数帯域のトレースを表します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: JANUS: Benchmarking Commercial and Open-Source Cloud and Edge Platforms
  for Object and Anomaly Detection Workloads -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_60.html">
      <font color="black">JANUS: Benchmarking Commercial and Open-Source Cloud and Edge Platforms
  for Object and Anomaly Detection Workloads</font>
    </a>
  </h2>
  <font color="black">さらに、Amazon Rekognition、Google Vision、Azure Cognitive Servicesなどの独自のディープラーニングオブジェクト検出パッケージの長所と短所を見て、FasterRなどのオープンソースで調整可能なソリューションと対比します。 -CNN（FRCNN）..これらのワークロードは、センサーデータの異常検出などの計算量が少ない場合もあれば、ドローンから取得したビデオフィードからのオブジェクト検出などの計算量が多い場合もあります。低電力のエッジデバイスで実行する場合、レイテンシーは最大49分の1になります。 
[概要] aws iot greengrassは、他のすべてのクラウドソリューションと比較して少なくとも2分の1のレイテンシーと1.25分の1のコストを実現します。レイテンシーはGoogleのレイテンシーで最大49分の1です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: MorphNet: One-Shot Face Synthesis GAN for Detecting Recognition Bias -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_61.html">
      <font color="black">MorphNet: One-Shot Face Synthesis GAN for Detecting Recognition Bias</font>
    </a>
  </h2>
  <font color="black">シミュレーターは、最初に3Dモーフィング可能なモデルを提供された画像に適合させ、目的の頭のポーズと顔の表情のコントロールを適用してから、モデルを画像にレンダリングします。顔の小さなデータセットを新しいポーズと表情で拡張することにより、認識パフォーマンスが向上することを示します。次に、元の画像とレンダリングされたモーフィング可能なモデルを条件とする条件付きGenerative Adversarial Network（GAN）を使用して、新しい顔の表情と元の人物の画像を生成します。頭のポーズ。 
[概要]シミュレーターシティは、最初に3Dモーフィング可能なモデルを提供された画像に適合させます。目的の頭のポーズと表情のコントロールを適用してから、モデルを画像にレンダリングします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: ESAD: End-to-end Deep Semi-supervised Anomaly Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_62.html">
      <font color="black">ESAD: End-to-end Deep Semi-supervised Anomaly Detection</font>
    </a>
  </h2>
  <font color="black">2つの要因を同時に最適化する際の矛盾を解決するために、相互情報量の最適化に焦点を当てた最初のエンコーダーとエントロピーの最適化に焦点を当てた2番目のエンコーダーを備えた新しいエンコーダー-デコーダー-エンコーダー構造を提案します。この方法は、医療診断やいくつかの古典的な異常検出ベンチマークなど、複数のベンチマークデータセットでいくつかの最先端技術を大幅に上回っています。2つのエンコーダーは、潜在的な表現に一貫した制約を加えて同様のエンコーディングを共有するように強制されます。 
[要約]新しい関数はklを測定します-医療データと異常データの間の相違</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: UnrealPerson: An Adaptive Pipeline towards Costless Person
  Re-identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_63.html">
      <font color="black">UnrealPerson: An Adaptive Pipeline towards Costless Person
  Re-identification</font>
    </a>
  </h2>
  <font color="black">その基本的な部分は、高品質で制御可能な分布から合成画像を生成できるシステムです。個人再識別（ReID）の主な難しさは、注釈付きデータの収集と、異なるドメイン間でのモデルの転送にあります。このペーパーでは、UnrealPersonを紹介します。 、非現実的な画像データを最大限に活用して、トレーニング段階と展開段階の両方でコストを削減する新しいパイプライン。 
[ABSTRACT] unrealpersonは、非現実的な画像データを最大限に活用して、トレーニング段階と展開段階の両方でコストを削減する新しいパイプラインです。この方法は、msmt17に直接転送すると、38.5％のランク-1の精度を達成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-08">
        <br><font color="black">2020-12-08</font>
      </time>
    </span>
</section>
<!-- paper0: A Topological Filter for Learning with Label Noise -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_64.html">
      <font color="black">A Topological Filter for Learning with Label Noise</font>
    </a>
  </h2>
  <font color="black">経験的結果は、私たちの方法が最先端技術を上回り、幅広いノイズタイプとレベルに対してロバストであることを示しています。理論的には、このトポロジカルアプローチが高い確率でクリーンなデータを収集することが保証されていることを証明します。この問題について、本論文では、ラベルノイズをフィルタリングするための新しい方法を提案します。 
[概要]ラベルノイズをフィルタリングするための新しい方法を提案します。クリーンなデータのほとんどを収集し、高品質のモデルをトレーニングすることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Red Blood Cell Segmentation with Overlapping Cell Separation and
  Classification on Imbalanced Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_65.html">
      <font color="black">Red Blood Cell Segmentation with Overlapping Cell Separation and
  Classification on Imbalanced Dataset</font>
    </a>
  </h2>
  <font color="black">20個の血液塗抹標本画像の精度は0.889です。重複する細胞分離に焦点を当て、セグメンテーションプロセスでは最初に楕円を推定して赤血球を表します。分類にはバランスの取れたトレーニングデータセットが必要です。 
[概要]この方法は、凹点を検出して楕円を見つけます。次に、有向楕円フィッティングを使用してセルデータの拡張を見つけます。この方法を使用して、セルのオーバーラップとデータの不均衡の問題に取り組むことが望まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: A Comprehensive Study of Class Incremental Learning Algorithms for
  Visual Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_66.html">
      <font color="black">A Comprehensive Study of Class Incremental Learning Algorithms for
  Visual Tasks</font>
    </a>
  </h2>
  <font color="black">過去のクラスの制限された記憶が許可されるかどうかにかかわらず、特に重要な違いが生じます。ここでは、後者に焦点を当て、それらを共通の概念的および実験的フレームワークに配置し、次の貢献を提案します。（1）増分学習の6つの望ましい特性を定義するアルゴリズムとこれらの特性に従ってそれらを分析し、（2）クラス増分学習問題の統一された形式化を導入し、（3）データセットの数、データセットのサイズの点で既存のものより徹底的な共通の評価フレームワークを提案します。制限された記憶のサイズと増分状態の数、（4）過去の模範選択のための群れの有用性を調査する、（5）壊滅的な忘却に取り組むために知識蒸留を使用せずに競争力のあるパフォーマンスを得ることが可能であるという実験的証拠を提供する、（6 ）テストされたすべてのメソッドを共通のオープンソースリポジトリに統合することにより、再現性を促進します。最初のアプローチグループは、忘れられた問題に取り組みます。新しい知識に対応するために、深いモデルの容量を増やすことによって。 
[概要]このような場合に直面する主な課題は、壊滅的な忘却です。これには、新しいデータが取り込まれたときにニューラルネットワークが過去のデータをアンダーフィットする傾向が含まれます。2番目のタイプのアプローチは、深いモデルサイズを修正し、その目的がモデルの安定性と可塑性の間の適切な妥協点</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Siamese Basis Function Networks for Defect Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_67.html">
      <font color="black">Siamese Basis Function Networks for Defect Classification</font>
    </a>
  </h2>
  <font color="black">このアプローチを使用して、作成者はシャムカーネル内にある種のクラス認識を作成しました。次に、カーネルは、データセット内の他の画像から中心を区別できるようにエンコーディングを生成するようにトレーニングされます。基本的なアイデアは分類することです。類似性スコアを使用した比較による。 
[概要]シャムカーネルは基底関数ネットワークで使用されます。次に、データセット内の他の画像から中心を区別する方法でソロモンを生成するようにトレーニングされます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: JointsGait:A model-based Gait Recognition Method based on Gait Graph
  Convolutional Networks and Joints Relationship Pyramid Mapping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_68.html">
      <font color="black">JointsGait:A model-based Gait Recognition Method based on Gait Graph
  Convolutional Networks and Joints Relationship Pyramid Mapping</font>
    </a>
  </h2>
  <font color="black">第二に、関節関係ピラミッドマッピング（JRPM）は、人がさまざまなスケールで歩いているときの人間の関節の関係に応じて、生物学的利点を備えた識別可能な特徴空間に時空間歩行特徴をマッピングするために提案されています。は、遠くから認識できるという利点があり、公共のセキュリティで広く使用できます。以前のアプローチとは異なり、JointsGaitはまず、外的要因による干渉が少ない歩行グラフ畳み込みネットワークを使用して、2D関節から時空間特徴を抽出しました。 
[ABSTRACT]新しいモデルベースの歩行認識方法jointsgaitは、2D人体関節から歩行情報を抽出するために提案されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br><font color="black">2020-04-27</font>
      </time>
    </span>
</section>
<!-- paper0: Batch Normalization Biases Residual Blocks Towards the Identity Function
  in Deep Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_69.html">
      <font color="black">Batch Normalization Biases Residual Blocks Towards the Identity Function
  in Deep Networks</font>
    </a>
  </h2>
  <font color="black">また、残余ネットワークの詳細な実証研究を提供します。これにより、バッチ正規化ネットワークはより大きな学習率でトレーニングできますが、この効果は特定の計算レジームでのみ有益であり、バッチサイズが小さい場合は最小限のメリットしかありません。バッチ正規化は、初期化時に、ネットワーク深度の平方根のオーダーの正規化係数によって、スキップ接続に比べて残りのブランチをダウンスケールするため、この重要な利点が生じることを示します。この洞察を使用して、単純な初期化スキームを開発します。正規化せずに深い残余ネットワークをトレーニングできます。 
[概要]ネットワーク深度の平方根のオーダーの正規化係数を使用して、正規化せずに特定のネットワークをトレーニングできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-24">
        <br><font color="black">2020-02-24</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Lesion Tracker: Monitoring Lesions in 4D Longitudinal Imaging
  Studies -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_70.html">
      <font color="black">Deep Lesion Tracker: Monitoring Lesions in 4D Longitudinal Imaging
  Studies</font>
    </a>
  </h2>
  <font color="black">DLTは、100件の縦断的研究の外部臨床テストセットでも一般化され、88％の精度を達成します。最後に、DLTを自動腫瘍モニタリングワークフローにプラグインすると、病変治療反応の評価で85％の精度が得られます。手動入力の精度よりも0.46％低い。この作業では、外観ベースと解剖学的ベースの両方の信号を使用する深層学習アプローチである深部病変トラッカー（DLT）を紹介します。 
[概要] esaesaベースesaベースesaベースesaベースesaベースesaスタイルの研究は、現在「病変手術」のシステムをテストしていることを発表しました。まもなく米国の病院で利用できるようになる可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Rigid and Articulated Point Registration with Expectation Conditional
  Maximization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_71.html">
      <font color="black">Rigid and Articulated Point Registration with Expectation Conditional
  Maximization</font>
    </a>
  </h2>
  <font color="black">最尤法を採用して、革新的なEMのようなアルゴリズム、つまりポイント登録の期待条件付き最大化（ECMPR）アルゴリズムを導入します。厳密な登録を関節式登録に拡張します。関連する結果を推定の観点から詳細に分析します。登録パラメータ、および半明確な正の緩和に基づいて回転および並進パラメータを推定するための最適な方法を提案します。 
[要約]アルゴリズムにより、混合モデルコンポーネントに関連する共分散行列を使用できます。等方性共分散法よりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: MiniSeg: An Extremely Minimum Network for Efficient COVID-19
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_72.html">
      <font color="black">MiniSeg: An Extremely Minimum Network for Efficient COVID-19
  Segmentation</font>
    </a>
  </h2>
  <font color="black">さらに、MiniSegを従来の方法と比較するための包括的なCOVID-19セグメンテーションベンチマークを構築します。上記の問題に対処するために、効率的なCOVID-19セグメンテーションのための軽量ディープラーニングモデルであるMiniSegを提案します。 / testと低い計算コストもCOVID-19スクリーニングシステムの迅速な展開と開発に必要ですが、従来の深層学習法は通常計算集約的です。 
[概要] covid-19感染ctエリアセグメンテーションが大きな注目を集めています。迅速な展開には迅速なトレーニングとテストも必要です。minisegには、軽量モデルを含むいくつかの重要な長所があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br><font color="black">2020-04-21</font>
      </time>
    </span>
</section>
<!-- paper0: Removing Class Imbalance using Polarity-GAN: An Uncertainty Sampling
  Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_73.html">
      <font color="black">Removing Class Imbalance using Polarity-GAN: An Uncertainty Sampling
  Approach</font>
    </a>
  </h2>
  <font color="black">さらに、分類器Cとの敵対的ゲームの競合は、Gによって学習された条件付き分布をそれぞれのクラスの周辺に押し出し、クラスの不均衡の問題を補償します。実験的証拠は、この初期化がネットワークの安定したトレーニングをもたらすことを示しています。 、ジェネレーターGが最小-最大ゲームで弁別子Dと競合する場合、元のネットワークに分類器ネットワークをさらに追加することを提案します。 
[要約]合成オーバーサンプリングなどの対策は、深層学習モデルによって処理される複雑なデータでは限られた成功しか収めていません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Generating Out of Distribution Adversarial Attack using Latent Space
  Poisoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CV/paper_74.html">
      <font color="black">Generating Out of Distribution Adversarial Attack using Latent Space
  Poisoning</font>
    </a>
  </h2>
  <font color="black">勾配ベースの攻撃とは対照的に、潜在空間ポイズニングは、分類器の傾向を利用して、トレーニングデータセットの独立した同一の分布をモデル化し、分布サンプルから生成することによってそれをだまします。MNIST、SVHN、およびCelebAデータセットに関する経験的結果生成された敵対的な例が、証明可能な堅牢な防御メカニズムを使用して設計された堅牢なl_0、l_2、l_infノルム分類器を簡単にだますことができることを検証します。従来の敵対的な攻撃は、ネットワークからの勾配によって生成された摂動に依存します。ネットワークに対応します。 
[ABSTRACT]敵対的な画像がターゲットラベルに誤って分類されます。データは画像の固有の構造を改ざんするために使用されます。その結果、データをモデル化するためにもつれを解いたオートエンコーダをトレーニングします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Label Confusion Learning to Enhance Text Classification Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_0.html">
      <font color="black">Label Confusion Learning to Enhance Text Classification Models</font>
    </a>
  </h2>
  <font color="black">5つのテキスト分類ベンチマークデータセットでの広範な実験により、広く使用されているいくつかの深層学習分類モデルに対するLCMの有効性が明らかになりました。この論文では、現在人気のあるテキスト分類モデルの拡張コンポーネントとして、新しいラベル混同モデル（LCM）を提案します。実験では、LCMが混乱したデータセットやノイズの多いデータセットに特に役立ち、ラベルスムージング法よりも優れていることも確認されています。 
[概要] 1つ-ホット表現は、インスタンスとラベルの関係を適切に反映していない可能性があります。これは、ラベルが完全に独立していないことが多く、インスタンスが実際に発生する可能性があるためです。lcmは、ラベルの混乱を学習して、ラベル間の意味の重複をキャプチャできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Infinite use of finite means: Zero-Shot Generalization using
  Compositional Emergent Protocols -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_1.html">
      <font color="black">Infinite use of finite means: Zero-Shot Generalization using
  Compositional Emergent Protocols</font>
    </a>
  </h2>
  <font color="black">明示的な報酬の量を減らして複雑なタスクを習得するように私たちを駆り立てるのは、これと同じ本質的な衝動です。人間の言語は、無限の思考の配列を表現するために有限の手段を利用するシステムとして説明されています。これらの報酬をトレーニングエージェントで活用して、外部からのフィードバックがない場合に構成性を誘導する方法。 
[要約]たとえば、緊急のコミュニケーションで構成性をどのように誘発するか？明示的な報酬の量を減らして複雑なタスクを習得するように駆り立てるのは、これと同じ本質的な衝動です..これは、構成性を誘発するエージェントのトレーニングにおける同じ本質的な衝動です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Document-Level Relation Extraction with Adaptive Thresholding and
  Localized Context Pooling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_2.html">
      <font color="black">Document-Level Relation Extraction with Adaptive Thresholding and
  Localized Context Pooling</font>
    </a>
  </h2>
  <font color="black">ATLOP（Adaptive Thresholding and Localized cOntext Pooling）モデルは63.4のF1スコアを達成し、CDRとGDAの両方で既存のモデルを大幅に上回っています。1つのドキュメントには通常複数のエンティティペアが含まれ、1つのエンティティペアは関連付けられたドキュメントで複数回発生しますローカライズされたコンテキストプーリングは、事前にトレーニングされた言語モデルから直接注意を移し、関係を決定するのに役立つ関連コンテキストを見つけます。 
[要約]適応しきい値処理は、マルチラベル分類のグローバルしきい値を学習可能なエンティティに置き換えます-依存しきい値</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: From Bag of Sentences to Document: Distantly Supervised Relation
  Extraction via Machine Reading Comprehension -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_3.html">
      <font color="black">From Bag of Sentences to Document: Distantly Supervised Relation
  Extraction via Machine Reading Comprehension</font>
    </a>
  </h2>
  <font color="black">実験は、私たちの方法が新しい最先端のDSパフォーマンスを達成することを示しています。エンティティに関するすべての文をドキュメントとして再編成し、リレーション固有の質問でドキュメントをクエリしてリレーションを抽出することにより、ドキュメントベースのDSパラダイムは次のことができます。すべてのセンテンスレベル、インターセンテンスレベル、およびエンティティレベルの証拠を同時にエンコードして活用します。ただし、バッグベースのパラダイムでは、関係抽出にインターセンテンスレベルとエンティティレベルの証拠を活用できません。それらのノイズ除去アルゴリズムは、多くの場合、特殊で複雑です。 
[ABSTRACT]遠隔監視は、mrcモデルを効果的にトレーニングできる新しいdsシステムです。dsloss（遠隔監視損失）と呼ばれ、新しいモデルのトレーニングに使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-08">
        <br><font color="black">2020-12-08</font>
      </time>
    </span>
</section>
<!-- paper0: The Depth-to-Width Interplay in Self-Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_4.html">
      <font color="black">The Depth-to-Width Interplay in Self-Attention</font>
    </a>
  </h2>
  <font color="black">理論的に予測された動作を明確に明らかにする深さ6〜48のネットワークで体系的な経験的アブレーションを実施し、特定の自己注意ネットワークサイズに対する最適な深さから幅への割り当てに関する明示的な定量的提案を提供します。ガイドラインは深さを解明します- GPT3のスケール（そのサイズには深すぎる）までのサイズの自己注意ネットワークにおける幅と幅のトレードオフ、およびそれを超えると、1兆パラメータの自己注意ネットワークに最適な30Kの前例のない幅をマークします..自然言語処理のフロンティアを急速に押し上げている自己注意アーキテクチャは、驚くべき深さ非効率的な動作を示しています。以前の研究では、内部表現（ネットワーク幅）を増やすことは、自己注意の数を増やすことと同じくらい有用であることが示されています。レイヤー（ネットワークの深さ）。 
[概要] 1兆を超えるイーサン言語モデルへの競争は、自己注目を高めるための詳細な詳細なガイドラインを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-22">
        <br><font color="black">2020-06-22</font>
      </time>
    </span>
</section>
<!-- paper0: CiwGAN and fiwGAN: Encoding information in acoustic data to model
  lexical learning with Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_5.html">
      <font color="black">CiwGAN and fiwGAN: Encoding information in acoustic data to model
  lexical learning with Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">ディープニューラルネットワークは、人間の音声の単語に対応する情報を生の音響データにどのようにエンコードできますか？このペーパーでは、生の音響入力からの教師なし語彙学習をモデル化するための2つのニューラルネットワークアーキテクチャ、ciwGAN（Categorical InfoWaveGAN）とfiwGAN（Featural InfoWaveGAN）を提案します。これらは、オーディオデータのディープ畳み込みGANアーキテクチャ（WaveGAN; arXiv：1705.07904）と情報理論を組み合わせたものです。 GANの拡張-InfoGAN（arXiv：1606.03657）、およびより高いレベルの分類と同時に特徴学習をモデル化でき、字句項目の非常に低次元のベクトル表現を可能にする新しい潜在空間構造を提案します。字句学習は次のようにモデル化されます。深いニューラルネットワークにデータを出力させ、その音響出力から一意の情報を取得できるようにするアーキテクチャから生まれました。 
[概要]ネットワークは、オーディオデータに深い畳み込みganアーキテクチャを使用します。これらには、gan --infoganの情報理論的拡張が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-04">
        <br><font color="black">2020-06-04</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Explaining Structures Improve NLP Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_6.html">
      <font color="black">Self-Explaining Structures Improve NLP Models</font>
    </a>
  </h2>
  <font color="black">解釈可能性がパフォーマンスを犠牲にしないことを初めて示しました。自己説明機能のニューラルモデルは、自己説明性のない対応するものよりも優れたパフォーマンスを取得し、SST-5で59.1の新しいSOTAパフォーマンスを達成します。 SNLIでの92.3の新しいSOTAパフォーマンス。提案されたモデルには、次のメリットがあります。（1）スパンの重みにより、モデルが自己説明可能になり、解釈のために追加のプロービングモデルが不要になります。 （2）提案されたモデルは一般的であり、NLPの既存の深層学習構造に適合させることができます。 （3）各テキストスパンに関連付けられた重みは、フレーズや文などの高レベルのテキストユニットの直接的な重要度スコアを提供します。このレイヤーは、特定の重みに関連付けられた各テキストスパンの情報と、それらの重み付きの組み合わせを集約します。最終予測のためにsoftmax関数に供給されます。 
[ABSTRACT] nlpの深層学習モデルが効果的であると考えられます。このレイヤーは、各テキストスパンの情報を集約し、特定の重みに関連付けられ、それらの重み付きの組み合わせがsalのsoftmaxモデルに送られます。これらのモデルは次のとおりです。どのくらいの解釈が機能するかを説明することはできませんが、このモデルはより多くのコミュニケーションを必要としません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Transfer learning and subword sampling for asymmetric-resource
  one-to-many neural translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_7.html">
      <font color="black">Transfer learning and subword sampling for asymmetric-resource
  one-to-many neural translation</font>
    </a>
  </h2>
  <font color="black">実験は、特にスケジュールされたマルチタスク学習、ノイズ除去オートエンコーダ、およびサブワードサンプリングに対してプラスの効果を示しています。英語からエストニア語（低リソース）およびフィンランド語（高リソース）、英語の3つの人為的に制限された翻訳タスクでさまざまな方法をテストします。スロバキアとチェコ語、英語からデンマーク語とスウェーデン語、そして1つの現実世界のタスク、ノルウェー語から北サミとフィンランド語へ。低リソース言語のニューラルマシン翻訳を改善するためのいくつかのアプローチがあります。単言語データを活用できます。事前トレーニングまたはデータ拡張を介して;関連する言語ペアの並列コーパスは、多言語モデルでのパラメーター共有または転移学習を介して使用できます。サブワードのセグメンテーションと正則化の手法を適用して、語彙の高いカバレッジを確保できます。 
[概要]これらのアプローチは、非対称の-リソース1-から-多くの翻訳タスクのコンテキストで見ることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br><font color="black">2020-04-08</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning Models for Multilingual Hate Speech Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_8.html">
      <font color="black">Deep Learning Models for Multilingual Hate Speech Detection</font>
    </a>
  </h2>
  <font color="black">コードと実験設定をhttps://github.com/punyajoy/DE-LIMITで他の研究者に公開しました。これらのモデルは、将来の多言語ヘイトスピーチ検出タスクの優れたベースラインとしても機能する可能性があります。ヘイトスピーチ検出は英語という1つの言語でしか利用できないほとんどのデータセットに関する困難な問題。 
[概要]研究者は、多言語のヘイトスピーチの大規模な分析を実施しました。これらのモデルは、将来のヘイトスピーチ検出タスクの優れたベースラインとしても機能する可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-14">
        <br><font color="black">2020-04-14</font>
      </time>
    </span>
</section>
<!-- paper0: A Neural Entity Coreference Resolution Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_9.html">
      <font color="black">A Neural Entity Coreference Resolution Review</font>
    </a>
  </h2>
  <font color="black">エンティティリンキング、機械翻訳、要約、チャットボットなどのダウンストリームの自然言語処理タスクにとって非常に重要です。この作業は、ニューラルベースのアプローチを使用した共参照解決の解決に関する現在の進捗状況の詳細なレビューを提供することを目的としています。アプローチの長所と短所、タスクの課題、タスクで合意された基準の欠如、そしてフィールドの境界をさらに拡大する方法を提案します。 
[要約]解像度は自然言語処理にとって非常に重要です。データセットと評価指標に詳細な評価を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-21">
        <br><font color="black">2019-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Complex Relation Extraction: Challenges and Opportunities -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_10.html">
      <font color="black">Complex Relation Extraction: Challenges and Opportunities</font>
    </a>
  </h2>
  <font color="black">関係抽出は、知識ベースの構築とテキストの理解にとって非常に重要です。近年、多くの複雑な関係抽出タスク、つまり単純な二項関係抽出の変形が、実際の複雑なアプリケーションを満たすために提案されています。関係抽出は、識別を目的としています。テキスト内のエンティティのターゲット関係。 
[概要]知識ベースの構築とテキストの理解には、単純な二項関係の抽出が非常に重要です。近年、実際の複雑なアプリケーションに対応するために、多くの複雑な関係の抽出タスクが提案されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: On Knowledge Distillation for Direct Speech Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_11.html">
      <font color="black">On Knowledge Distillation for Direct Speech Translation</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、STのようなシーケンス間タスクで知識を抽出するためのさまざまなソリューションを比較します。直接音声翻訳（ST）は、サブタスクからの知識の伝達を必要とする複雑なタスクであることが示されています。自動音声認識（ ASR）と機械翻訳（MT）。さらに、このアプローチの最終的な欠点と、翻訳品質の観点からメリットを維持しながらそれらを軽減する方法を分析します。 
[概要]このアプローチの最終的な欠点と、メリットを維持しながらそれらを軽減する方法を分析します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Training with Fast Gradient Projection Method against
  Synonym Substitution based Text Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_12.html">
      <font color="black">Adversarial Training with Fast Gradient Projection Method against
  Synonym Substitution based Text Attacks</font>
    </a>
  </h2>
  <font color="black">これにより、同義語置換に基づくFast Gradient Projection Method（FGPM）と呼ばれる高速テキスト敵対的攻撃方法を提案します。これは既存のテキスト攻撃方法の約20倍高速であり、同様の攻撃パフォーマンスを達成できます。実験によると、ATFLは堅牢性をモデル化し、敵対的例の転送可能性をブロックします。次に、FGPMを敵対的トレーニングに組み込み、ロジットペアリング（ATFL）によって強化されたFGPMを使用した敵対的トレーニングと呼ばれるテキスト防御方法を提案します。 
[概要]字句、文法、意味の制約があるため、段落置換ベースのテキスト攻撃に実装するのは困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-09">
        <br><font color="black">2020-08-09</font>
      </time>
    </span>
</section>
<!-- paper0: Characterizing the Value of Information in Medical Notes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_13.html">
      <font color="black">Characterizing the Value of Information in Medical Notes</font>
    </a>
  </h2>
  <font color="black">さらに、選択した情報がトレーニングデータ（「すべてのメモ」）からの分布シフトにつながるにもかかわらず、すべてのメモを使用するよりも正確な予測を可能にするメモの部分を選択するためのプロービングフレームワークを提案します。2つの予測タスク、再入院を使用します。医療記録の情報の価値を特徴づけるための予測と院内死亡率予測。全体として、医療記録は再入院予測の構造化された情報に対して追加の予測力を提供するだけであることを示します。 
[要約]全体として、医療ノートは追加の予測力を提供するだけです。選択した貴重な情報でトレーニングされたモデルがさらに優れた予測パフォーマンスを達成することを実証しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-07">
        <br><font color="black">2020-10-07</font>
      </time>
    </span>
</section>
<!-- paper0: Hybrid Approaches for our Participation to the n2c2 Challenge on Cohort
  Selection for Clinical Trials -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_14.html">
      <font color="black">Hybrid Approaches for our Participation to the n2c2 Challenge on Cohort
  Selection for Clinical Trials</font>
    </a>
  </h2>
  <font color="black">用語ベースの方法は、医学的概念が関連情報のほとんどを運ぶ場合に非常に効率的です。結論：広範囲の患者表現型を特定するタスクのために、はるかに多くの注釈付きデータがすぐに利用可能になる可能性は低いです。ディスカッション：両方のアプローチ非常に有望な結果が得られ、さまざまなタイプの基準に適用されます。 
[要約]結果は、臨床試験のコホート選択に関するn2c2チャレンジで発表されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-03-19">
        <br><font color="black">2019-03-19</font>
      </time>
    </span>
</section>
<!-- paper0: Multidimensional scaling and linguistic theory -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_15.html">
      <font color="black">Multidimensional scaling and linguistic theory</font>
    </a>
  </h2>
  <font color="black">次に、MDS手法をパラレルコーパスデータと組み合わせて使用する過去の研究の概要を説明し、特定のMDSアプリケーションの主要なパラメータを簡潔に説明する一連の用語を提案します。次に、MDSを補完および比較する方法について説明します。これまで言語領域でほとんど使用されていなかった他の次元削減手法を使用します。まず、構成構造の言語間変動の調査にMDSを使用することを想定します。これは、変動研究の重要な領域であり、パラレルコーパスはまだ機能します。 
[ABSTRACT] mdsは、オブジェクト（語彙アイテム、言語コンテキスト、言語など）を表す手法を指します。パラレルコーパスデータにmdsを適用する最近の傾向に焦点を当てています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Word-level Textual Adversarial Attacking as Combinatorial Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_16.html">
      <font color="black">Word-level Textual Adversarial Attacking as Combinatorial Optimization</font>
    </a>
  </h2>
  <font color="black">3つのベンチマークデータセットでBiLSTMとBERTを攻撃することにより、攻撃モデルを評価するための徹底的な実験を行います。この論文では、セメムベースの単語置換法と粒子群最適化ベースの検索アルゴリズムを組み込んだ新しい攻撃モデルを提案します。 2つの問題は別々に..このペーパーのすべてのコードとデータはhttps://github.com/thunlp/SememePSO-Attackで入手できます。 
[要約]単語レベルの攻撃モデルは完全にはほど遠いです。これは主に、不適切な検索スペース削減方法と非効率的なアルゴリズムが採用されているためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-27">
        <br><font color="black">2019-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Fusing Context Into Knowledge Graph for Commonsense Reasoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_17.html">
      <font color="black">Fusing Context Into Knowledge Graph for Commonsense Reasoning</font>
    </a>
  </h2>
  <font color="black">CommonsenseQAタスクの場合、モデルは最初に質問と選択から概念を抽出し、次にこれらの概念の間に関連するトリプルを見つけます。このペーパーでは、外部エンティティの説明を利用してグラフエンティティのコンテキスト情報を提供することを提案します。 Wiktionaryからこれらの概念の説明を取得し、トリプルとともに、事前にトレーニングされた言語モデルへの追加入力としてフィードします。 
[要約]これは、知識グラフを言語モデリングに融合するときにギャップを作成します。特に、ペアのテキスト（知識データ）が不足している場合、シナリオでは、モデルは最初に質問と選択から概念を抽出し、次にこれらの概念の間に関連するトリプルを見つけます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Infusing Multi-Source Knowledge with Heterogeneous Graph Neural Network
  for Emotional Conversation Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_18.html">
      <font color="black">Infusing Multi-Source Knowledge with Heterogeneous Graph Neural Network
  for Emotional Conversation Generation</font>
    </a>
  </h2>
  <font color="black">実験結果は、私たちのモデルがマルチソースの知識から感情を効果的に認識し、満足のいく応答を生成できることを示しています。これは、以前の最先端のモデルを大幅に上回っています。感情的な会話システムの成功は、感情の十分な認識と適切な表現に依存します。 ..実世界の会話では、まず対話履歴の感情の流れ、表情、話者の性格など、マルチソース情報から感情を本能的に知覚し、次に私たちの性格に応じて適切な感情を表現しますが、これらの複数のタイプ感情的な会話の分野では、情報の活用が不十分です。 
[概要]モデルは、複数のソース情報から感情を効果的に知覚できます。これには、会話の履歴、表情、話者の性格の感情の流れが含まれますが、これらの複数のタイプの情報は、感情的な会話の分野では十分に活用されていません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Relation Extraction by Leveraging Knowledge Graph Link
  Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_19.html">
      <font color="black">Improving Relation Extraction by Leveraging Knowledge Graph Link
  Prediction</font>
    </a>
  </h2>
  <font color="black">いくつかの既存のREモデルに適用することでアプローチの一般性を説明し、一貫したパフォーマンスの向上を達成するのにどのように役立つかを経験的に示します。このホワイトペーパーでは、REのパフォーマンスを向上させるマルチタスク学習アプローチを提案することでこの洞察を活用します。 REタスクとKGLPタスクを共同でトレーニングすることでモデルを作成します。したがって、オブジェクトoはセットOに含まれると予想されます。
[ABSTRACT]主な目的は、マルチタスク学習アプローチの結果としてオブジェクトoのセットを予測することです。主語と目的語を含む文が与えられるo。これらの2つの問題は、それぞれの目的が絡み合っているため、密接に関連しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Interpretable Multi-dataset Evaluation for Named Entity Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_20.html">
      <font color="black">Interpretable Multi-dataset Evaluation for Named Entity Recognition</font>
    </a>
  </h2>
  <font color="black">精度、BLEU、F1などの全体的な指標の違いを見ただけでは、特定の方法のパフォーマンスが異なる理由や方法、さまざまなデータセットがモデル設計の選択にどのように影響するかはわかりません。分析ツールを利用できるようにすることで、将来に備えて簡単になります。研究者は、同様の分析を実行し、この分野で進歩を促進します：https：//github.com/neulab/InterpretEval ..提案された評価方法により、モデルとデータセットの違い、およびそれらの間の相互作用を解釈し、現在のシステムの長所と短所。 
[概要]提案された評価方法により、モデルとデータセットの違い、およびそれらの間の相互作用を解釈することができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-13">
        <br><font color="black">2020-11-13</font>
      </time>
    </span>
</section>
<!-- paper0: On an Unknown Ancestor of Burrows' Delta Measure -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_21.html">
      <font color="black">On an Unknown Ancestor of Burrows' Delta Measure</font>
    </a>
  </h2>
  <font color="black">この記事は、Georgy UdnyYuleによる1944年の研究と著者の帰属に対する現代的なアプローチとの間のいくつかの驚くべき類似点を指摘しています。 
[要約]この記事は、georgy udnyyuleによる1944年の研究と理論帰属への現代的なアプローチとの間のいくつかの驚くべき類似点を指摘しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: SongMASS: Automatic Song Writing with Pre-training and Alignment
  Constraint -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_22.html">
      <font color="black">SongMASS: Automatic Song Writing with Pre-training and Alignment
  Constraint</font>
    </a>
  </h2>
  <font color="black">この論文では、上記の課題に対処するためにSongMASSを提案します。これは、マスクされたシーケンスからシーケンス（MASS）の事前トレーニングと、歌詞からメロディーおよびメロディーから歌詞の生成のための注意ベースのアライメントモデリングを活用します。SongMASSを事前トレーニングします。対になっていない歌詞とメロディーのデータセットで、客観的評価と主観的評価の両方で、SongMASSは、事前トレーニングや配置の制約なしに、ベースラインメソッドよりも大幅に優れた品質の歌詞とメロディーを生成することが示されています。メロディー）機械による、これは学界と産業の両方で興味深いトピックです。 
[概要]自動作詞作曲では、歌詞からメロディーの生成とメロディーが2つの重要なタスクです。歌詞とメロディーのペアデータは限られており、2つのタスクの生成品質に影響します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Breeding Gender-aware Direct Speech Translation Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_23.html">
      <font color="black">Breeding Gender-aware Direct Speech Translation Systems</font>
    </a>
  </h2>
  <font color="black">この目的のために、話者の性別情報を使用して大規模なデータセットに手動で注釈を付け、さまざまな現実世界のシナリオを反映する実験に使用しました。さらに、性別の手がかりとして音声の生体認証機能のみに依存する直接STシステムは、不適切で潜在的に有害である可能性があります。特定のユーザー向け..私たちの結果は、性別を意識した直接STソリューションが、強力な、しかし性別を意識しない直接STモデルよりも大幅に優れていることを示しています。 
[概要]研究者は、さまざまなアプローチを比較して、直接stモデルに話者の性別を通知します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: RethinkCWS: Is Chinese Word Segmentation a Solved Task? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_24.html">
      <font color="black">RethinkCWS: Is Chinese Word Segmentation a Solved Task?</font>
    </a>
  </h2>
  <font color="black">すべてのコードを公開し、ユーザーのモデルをすばやく評価および診断できるインターフェースをリリースします：https：//github.com/neulab/InterpretEval ..中国の単語セグメンテーション（CWS）システムのパフォーマンスは、徐々にプラトーに達しました。ディープニューラルネットワークの急速な開発、特に事前にトレーニングされた大規模なモデルの使用の成功。方法論的には、既存のモデルの長所と短所を診断できるだけでなく、既存のCWSシステムのきめ細かい評価を提案します。データセット内の設定）が、異なる基準間の不一致を定量化し、複数基準の学習を行う際の負の転送の問題を軽減することができます。 
[概要] cwsはさまざまな種類のシステムを開発しましたが、この論文では新しい単語を提案していません。これらのテストは、将来の研究のための良い方向性を探すこともできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-13">
        <br><font color="black">2020-11-13</font>
      </time>
    </span>
</section>
<!-- paper0: Tracking Interaction States for Multi-Turn Text-to-SQL Semantic Parsing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/cs.CL/paper_25.html">
      <font color="black">Tracking Interaction States for Multi-Turn Text-to-SQL Semantic Parsing</font>
    </a>
  </h2>
  <font color="black">挑戦的なCoSQLデータセットの実験結果は、タスクリーダーボードで公開されている他の方法よりも優れたパフォーマンスを実現する提案された方法の有効性を示しています。リレーショナルグラフニューラルネットワークと非線形レイヤーは、これら2つの状態の表現を更新するように設計されています。それぞれ..履歴SQLクエリによって決定され、現在の発話の意図に関連する相互作用状態の記述と追跡を無視しましたが。 
[概要]これらの量子状態は、既存の発話に関連するスキーマとデータに基づいて定義されます。これらは、ユーザーの有用で有用な情報をデコードするために使用されます。調査は以前の研究によって行われました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: DeepTalk: Vocal Style Encoding for Speaker Recognition and Speech
  Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/eess.AS/paper_0.html">
      <font color="black">DeepTalk: Vocal Style Encoding for Speaker Recognition and Speech
  Synthesis</font>
    </a>
  </h2>
  <font color="black">DeepTalkを最先端の生理学的音声機能ベースの話者認識システムと組み合わせることにより、話者認識パフォーマンスがさらに向上します。また、DeepTalkメソッドを現在の最先端の音声合成装置に統合して合成を生成します。音声..DeepTalkメソッドは、複数の困難なデータセットにわたって、いくつかの最先端の生理学的音声特性ベースの話者認識システムよりも優れています。 
[要約] deeptalkメソッドは、複数の困難なデータセットにわたって、最先端の生理学的音声特性に基づく話者認識システムよりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Conjugate Mixture Models for Clustering Multimodal Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/eess.AS/paper_1.html">
      <font color="black">Conjugate Mixture Models for Clustering Multimodal Data</font>
    </a>
  </h2>
  <font color="black">問題を尤度最大化タスクとして定式化し、関連する共役期待値最大化アルゴリズムを導出します。提案されたアルゴリズムの収束特性を徹底的に調査します。これらのモデルは、観測されていないパラメーター空間（オブジェクト）間でしばしば利用可能な明示的な変換を利用します。 ）および各観測空間（センサー）。 
[要約]このようなアプローチの主な難しさは、単峰性クラスタリングが相互に一貫していることを保証することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Improved Lite Audio-Visual Speech Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/eess.AS/paper_2.html">
      <font color="black">Improved Lite Audio-Visual Speech Enhancement</font>
    </a>
  </h2>
  <font color="black">提案されたシステムは改良型LAVSE（iLAVSE）と呼ばれ、畳み込みリカレントニューラルネットワークアーキテクチャをコアAVSEモデルとして使用します。ビデオデータセットを使用して台湾マンダリン音声でiLAVSEを評価します。顔データのユーザープライバシー問題を適度に解決します。 
[ABSTRACT] lavseはライトオーディオ-視覚音声強調（lavse）アルゴリズムです。この研究では、3つの実用的な問題に対処するためにlavseを拡張します。結果は、ilaveが実際のシナリオに適していることも確認しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-30">
        <br><font color="black">2020-08-30</font>
      </time>
    </span>
</section>
<!-- paper0: SongMASS: Automatic Song Writing with Pre-training and Alignment
  Constraint -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-10/eess.AS/paper_3.html">
      <font color="black">SongMASS: Automatic Song Writing with Pre-training and Alignment
  Constraint</font>
    </a>
  </h2>
  <font color="black">自動作詞作曲では、歌詞からメロディへの生成とメロディから歌詞への生成は2つの重要なタスクであり、どちらも通常次の課題に悩まされます。1）歌詞とメロディのペアのデータが制限されているため、歌詞とメロディーの相関が弱いため、多くのペアのトレーニングデータが必要であることを考慮した2つのタスク。 2）歌詞とメロディーの間には厳密なアラインメントが必要であり、特定のアラインメントモデリングに依存しています。この論文では、上記の課題に対処するためにSongMASSを提案します。これは、マスクされたシーケンスツーシーケンス（MASS）の事前トレーニングと注意ベースのアラインメントモデリングを活用します。歌詞からメロディへ、メロディから歌詞への生成。具体的には、1）元の文レベルのMASS事前トレーニングを曲レベルに拡張して、音楽の長いコンテキスト情報をより適切にキャプチャし、それぞれに個別のエンコーダとデコーダを使用します。モダリティ（歌詞またはメロディー）; 2）トレーニング中に文レベルの注意マスクとトークンレベルの注意制約を活用して、歌詞とメロディーの整合性を強化します。 
[概要]自動作詞作曲では、歌詞からメロディーの生成とメロディーが2つの重要なタスクです。歌詞とメロディーのペアデータは限られており、2つのタスクの生成品質に影響します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
