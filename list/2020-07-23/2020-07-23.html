<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-07-23の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Resource-Efficient Speech Mask Estimation for Multi-Channel Speech
  Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.SD/paper_0.html">
      <font color="black">Resource-Efficient Speech Mask Estimation for Multi-Channel Speech
  Enhancement</font>
    </a>
  </h2>
  <font color="black">この音声マスクは、最小分散歪みのない応答（MVDR）または一般化固有値（GEV）ビームフォーマーを取得するために使用されます。特に、ノイズの多いマルチチャネルマイク観測から音声マスクを推定するために、精度の低いDNNを使用します。バイナリウェイトの極端なケースと精度のアクティブ化の低下、実行時間とメモリフットプリントの大幅な削減が可能でありながら、ほぼ同じ精度のDNNと同等のオーディオ品質と、単一スピーカーのシナリオのわずかに大きなワードエラーレート（WER）を実現WSJ0音声コーパスを使用します。 
[ABSTRACT]リソース効率の高い機械学習の必要性は、主にマルチチャネルマイクの需要によってもたらされます。特に、ノイズの多いマルチチャネルマイク観測に基づいて音声マスクを推定するために、精度の低いdnnsを使用します。大幅な削減実行時間とメモリフットプリントの可能性</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Rethinking CNN Models for Audio Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.SD/paper_1.html">
      <font color="black">Rethinking CNN Models for Audio Classification</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、ImageNet事前トレーニング済みの標準ディープCNNモデルが、オーディオ分類の強力なベースラインネットワークとして使用できることを示します。このパフォーマンスの変動は、複数の実行での線形分類レイヤーのランダム初期化とランダムミニバッチ順序付けによるものです。これにより、大幅な多様性がもたらされ、全体的な精度が向上した強力なアンサンブルモデルが構築されます。 
[ABSTRACT]事前トレーニング済みの重みを使用する特定の標準モデルの場合、ランダムに初期化された重みを使用するよりも優れていることを示します。これは、事前トレーニング済みモデル、事前学習済みモデルなどが原因で、ランダム初期化済み重みを使用するよりも標準モデルの方が優れているためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: A Transfer Learning End-to-End ArabicText-To-Speech (TTS) Deep
  Architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.SD/paper_2.html">
      <font color="black">A Transfer Learning End-to-End ArabicText-To-Speech (TTS) Deep
  Architecture</font>
    </a>
  </h2>
  <font color="black">ただし、多くの骨の折れる作業とドメインの専門知識が必要でした。また、イントネーション、ストレス、リズムなどの重要な音声キー要素も不足しています。成熟した自然で人間のような音声シンセサイザーを生成する多くの英語TTSシステムが存在します。 
[ABSTRACT]ナチュラルナチュラルナチュラル、人間のようなアラビア語のスピーチは、スピーチの形式です。高度な高度なシステムを使用して波形を作成します。英語の文字埋め込みの使用方法を説明します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Greenhouse Segmentation on High-Resolution Optical Satellite Imagery
  using Deep Learning Techniques -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.IV/paper_0.html">
      <font color="black">Greenhouse Segmentation on High-Resolution Optical Satellite Imagery
  using Deep Learning Techniques</font>
    </a>
  </h2>
  <font color="black">特に、温室を特定するためにU-Netのようなアーキテクチャのカスタマイズされたバリエーションが採用されています。拡張畳み込みを一意に組み込んで接続をスキップする2つのモデルが提案され、結果はベースラインU-Netモデルの結果と比較されます。使用されるのは、温室が密集しているアゼルバイジャンの15の地域から収集された、1.5メートルの解像度と注釈マスクを備えた、パンシャープンのオルソ補正されたアゼルスキー画像（赤、緑、青、近赤外線チャンネル）です。 
[要約]このペーパーでは、アゼルスキー（スポット-7）光学衛星によって取得された画像のピクセルネット分類のための適切な概念が提案されています。結果は、ベースラインuネットモデルの結果と比較されます。これらのモデルには、特にシャープ化が組み込まれています。畳み込みと接続のスキップ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Monocular Depth Estimation by Leveraging Structural Awareness
  and Complementary Datasets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.IV/paper_1.html">
      <font color="black">Improving Monocular Depth Estimation by Leveraging Structural Awareness
  and Complementary Datasets</font>
    </a>
  </h2>
  <font color="black">最後に、以前の方法の失敗事例の分析に基づいて、特別な照明条件、動的オブジェクト、傾斜したカメラ角度などの困難なシーンの新しいハードケース（HC）深度データセットを収集します。実験結果は、この方法が状態よりも優れていることを示しています。 NYUDv2データセットでの予測精度と目に見えないデータセットでの汎化パフォーマンスの両方の観点から、最先端のアプローチを採用しています。次に、予測における空間制約を強化するために、均一なポイントペアのグローバルな焦点相対損失を導入します。深さ方向の不連続な領域でのエラーのペナルティを明示的に増やします。これは、推定結果の鮮明さを維持するのに役立ちます。 
[ABSTRACT]新しいデータセットは、情報に基づく学習カリキュラムによって活用されます。さまざまなデータセットを処理するために、トレーニング例を段階的に組み合わせています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: TreeRNN: Topology-Preserving Deep GraphEmbedding and Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.IV/paper_2.html">
      <font color="black">TreeRNN: Topology-Preserving Deep GraphEmbedding and Learning</font>
    </a>
  </h2>
  <font color="black">さらに、従来の畳み込みニューラルネットワーク（CNN）およびリカレントニューラルネットワーク（RNN）に適した、ツリーを画像表現に転送する新しい投影スキームを提案しました。グラフツリー画像からパターンを最もよく学習するには、 TreeRNNを提案します。これは、画像のピクセルを行と列で繰り返し統合してグラフカテゴリを分類するのに役立つ2D RNNアーキテクチャです。複数のグラフ分類データセットで提案された方法を評価し、最新の状態と同等の精度を実証しています-MUTAG、PTC-MRおよびNCI1データセットに関するアート。 
[ABSTRACT]検索は、行と列ごとに画像ピクセルを繰り返し統合するパターンパターンパターンシステムに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-21">
        <br><font color="black">2020-06-21</font>
      </time>
    </span>
</section>
<!-- paper0: Fast Training of Deep Networks with One-Class CNNs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.IV/paper_3.html">
      <font color="black">Fast Training of Deep Networks with One-Class CNNs</font>
    </a>
  </h2>
  <font color="black">このアプローチの利点は、一般に、従来のマルチクラスディープネットワークのトレーニング時間のほぼ半分または2/3でありながら、認識精度が向上することです。提案されたアプローチは、顔認識およびオブジェクト認識タスクにうまく適用されています。提案されたアプローチのベンチマークには、多くの顔を合わせた1000フレームのRGBビデオである顔認識が使用されています。 
[ABSTRACT]システムは1つのクラスのcnnを使用します。つまり、マルチクラスの分類のために、クラスごとに1つのcnnをトレーニングします。このアプローチの利点は、一般に認識精度が向上します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-28">
        <br><font color="black">2020-06-28</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Disentangled Feature Representation for Hybrid-distorted Image
  Restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.IV/paper_4.html">
      <font color="black">Learning Disentangled Feature Representation for Hybrid-distorted Image
  Restoration</font>
    </a>
  </h2>
  <font color="black">広範な実験結果はまた、最新のHD-IRスキームと比較して、当社のアプローチの優れたパフォーマンスを証明しています。このような干渉を分解するために、ハイブリッド歪みの機能レベルの分割統治を達成するために、Disentangled Feature Learningの概念を導入します。また、歪みの表現を適応的にフィルターで除外し、生の画像を構築するためにさまざまなチャネルから有用なコンテンツ情報を集約するために、チャネルごとに注意を払った機能集約モジュール（FAM）を提案しています。 
[ABSTRACT]さまざまな歪みの特徴表現をさまざまなチャネルに配布するために、新しい絡み合い解消モジュールが提案されています。プロジェクトを使用して、プロジェクトの新しいバージョンを作成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Source Camera Verification from Strongly Stabilized Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.IV/paper_5.html">
      <font color="black">Source Camera Verification from Strongly Stabilized Videos</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、サブフレームレベルで変換を識別し、それらの正確さを検証するためにいくつかの制約を組み込んで、正しい変換の検索に計算の柔軟性を提供します。この方法は、他のビデオ生成ステップの破壊的な影響に対抗するために全体論的アプローチも採用します。より信頼性の高い帰属のために、ビデオコーディングやダウンサイジングなど。1つのパブリックデータセットと2つのカスタムデータセットで実行されたテストは、提案された方法が、計算に応じて、より強力な安定化を受けたすべてのビデオの23〜30％のソースを検証できることを示しています。負荷、虚偽の帰属への大きな影響なし。 
[ABSTRACT]デジタルで実行する場合、ビデオの修正には、ビデオフレームのトリミング、ワーピング、およびインペインティングが含まれます。この方法は、ビデオの編集やダウンサイジングなど、他のビデオ生成ステップの破壊的な影響に対する全体的な対応にも挑戦します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-26">
        <br><font color="black">2019-11-26</font>
      </time>
    </span>
</section>
<!-- paper0: Automated Detection and Forecasting of COVID-19 using Deep Learning
  Techniques: A Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.IV/paper_6.html">
      <font color="black">Automated Detection and Forecasting of COVID-19 using Deep Learning
  Techniques: A Review</font>
    </a>
  </h2>
  <font color="black">したがって、人工知能（AI）手法を使用して、一貫した高いパフォーマンスを得ることができます。AI手法の中で、ディープラーニング（DL）ネットワークは、従来の機械学習（ML）手法に比べて非常に人気があります。コロナウイルス、またはCOVID-19は、肺に直接影響を与えることにより世界中の多くの人々の健康を危険にさらしている危険な病気です。 
[ABSTRACT] covid-19は、中型サイズのコーティングされたウイルスで、一本鎖のrnaを備えています。X線とct）画像モダリティは、高速で正確な医療診断を得るために広く使用されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: DLow: Diversifying Latent Flows for Diverse Human Motion Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.IV/paper_7.html">
      <font color="black">DLow: Diversifying Latent Flows for Diverse Human Motion Prediction</font>
    </a>
  </h2>
  <font color="black">これらの問題に対処するために、新しいトレーニング方法である多様な潜在フロー（DLow）を提案し、事前学習済みの深生成モデルからサンプルの多様なセットを生成します。次に、相関潜在コードが相関サンプルのセットにデコードされます。生成モデルは、マルチモーダルデータ分布をモデル化し、多様な人間の行動を特徴付けることができるため、人間の動きの予測によく使用されます。 
[要約]提案されたdlowサンプリング方法は、単一のランダム変数変数をサンプリングし、それを学習可能なマッピング関数のセットでマッピングします。提案された方法は、2つの理由で多様なサンプルを生成することを保証していません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br><font color="black">2020-03-18</font>
      </time>
    </span>
</section>
<!-- paper0: Real-Time Instrument Segmentation in Robotic Surgery using Auxiliary
  Supervised Deep Adversarial Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.IV/paper_8.html">
      <font color="black">Real-Time Instrument Segmentation in Robotic Surgery using Auxiliary
  Supervised Deep Adversarial Learning</font>
    </a>
  </h2>
  <font color="black">手術シーンの正確で効率的なセグメンテーションは、器具の識別と追跡を支援するだけでなく、操作されているさまざまな組織と器具に関するコンテキスト情報も提供します。補助損失は、モデルが低解像度機能を学習するのに役立ち、敵対的損失が改善されますより高次の構造情報を学習することによるセグメンテーション予測。.補助ブランチとメインブランチからの異なる次元とチャネルのフィーチャーマップを融合するマルチ解像度フィーチャーフュージョンモジュール（MFF）を提案します。 
[ABSTRACT]実際の外科医は、高度な高度な高度なナビゲーションシステムを開発しました。mffは、補助ブランチとメインブランチからのさまざまな次元とチャネルの機能マップを融合するマルチ解像度機能融合モジュール</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Video-ception Network: Towards Multi-Scale Efficient Asymmetric
  Spatial-Temporal Interactions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.IV/paper_9.html">
      <font color="black">Video-ception Network: Towards Multi-Scale Efficient Asymmetric
  Spatial-Temporal Interactions</font>
    </a>
  </h2>
  <font color="black">メソッドを\ textit {plug-and-play}ブロックとしてインスタンス化し、Multi-Scale Efficient Asymmetric Spatial-Temporal Blockと呼びます。強力な時間的推論または外観の区別が必要な最新の大規模ビデオデータセットでメソッドを検証します。たとえば、Something-to-Something v1、KineticsおよびDiving48は、ベルとホイッスルのない新しい最先端の結果を示しています。以前のビデオモデリング方法は、3次3D畳み込みフィルターまたはその分解バリアントを利用して、時間軸と空間軸に沿って対称的にビデオ機能で実行される傾向がある正確なアクション認識。 
[ABSTRACT]最適化された機能の相互作用レイヤーは、最適化された機能の相互作用の作業です。これにより、機能の融合手順が効率的かつ効果的に可能になります。この方法では、従来の2d cnnをアクション認識などのビデオ理解タスクに簡単に適応できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: MI^2GAN: Generative Adversarial Network for Medical Image Domain
  Adaptation using Mutual Information Constraint -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.IV/paper_10.html">
      <font color="black">MI^2GAN: Generative Adversarial Network for Medical Image Domain
  Adaptation using Mutual Information Constraint</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案されたMI $ ^ 2 $ GANがエレガントな翻訳画像を生成できるだけでなく、広く使用されているディープラーニングネットワーク（U-Netなど）の一般化パフォーマンスを大幅に改善できることを示しています。ただし、既存のGANベースのアプローチは、画像から画像（I2I）への変換で画像オブジェクトを保持することに失敗する傾向があり、ドメイン適応タスクでの実用性が低下します。特に、ソースと翻訳された画像の両方のドメイン情報からコンテンツの機能を解きます。次に、絡み合っていないコンテンツ機能間の相互情報を最大化して、画像オブジェクトを保持します。 
[要約]提案されたmi $ ganは、ポリープと眼底画像における視神経乳頭と杯のパフォーマンスの2つのタスクで評価されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Essential Motor Cortex Signal Processing: an ERP and functional
  connectivity MATLAB toolbox -- user guide version 2.0 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.IV/paper_11.html">
      <font color="black">Essential Motor Cortex Signal Processing: an ERP and functional
  connectivity MATLAB toolbox -- user guide version 2.0</font>
    </a>
  </h2>
  <font color="black">電気および磁気）。2.. 3. 
[要約]ツールボックスは、人間の運動皮質を調査するためにさまざまな方法を使用します。これらには、ERPの推定と定量化、皮質の機能的接続性の分析、EMGが含まれます。ツールボックスは、キックスターターで事前注文できます。 7月24日から</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-15">
        <br><font color="black">2019-06-15</font>
      </time>
    </span>
</section>
<!-- paper0: A Graph Attention Spatio-temporal Convolutional Networks for 3D Human
  Pose Estimation in Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.IV/paper_12.html">
      <font color="black">A Graph Attention Spatio-temporal Convolutional Networks for 3D Human
  Pose Estimation in Video</font>
    </a>
  </h2>
  <font color="black">）、グローバル姿勢のセマンティクスは時間情報をより効果的に組み合わせて自己閉塞に対処できます。ローカル2次および対称制約は、これらの関節の深さのあいまいさを、1つだけの近傍（足首など）で緩和できます。3Dポーズ推定時間的および空間的情報の両方からのビデオの利点。
[ABSTRACT]情報の時空間情報は、未解決の問題であるオクルージョンと深度のあいまいさへの取り組みに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-11">
        <br><font color="black">2020-03-11</font>
      </time>
    </span>
</section>
<!-- paper0: A material decomposition method for dual-energy CT via dual interactive
  Wasserstein generative adversarial networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.IV/paper_13.html">
      <font color="black">A material decomposition method for dual-energy CT via dual interactive
  Wasserstein generative adversarial networks</font>
    </a>
  </h2>
  <font color="black">具体的には、2つのインタラクティブジェネレーターを使用して対応するマテリアルイメージを合成し、分解モデルをトレーニングするためのさまざまな損失関数を組み込んで、生成されたイメージのテクスチャとエッジを保持します。シミュレーションファントムと実際のデータの両方からの結果は、この利点を示していますノイズとビーム硬化アーティファクトを抑制する方法。この研究では、材料の分解精度を向上させるために、デュアルインタラクティブワッサースタイン生成敵対ネットワークを使用したデータ駆動型アプローチを提案します。 
[ABSTRACT]データ駆動型アプローチは、材料の分解精度を向上させるために提案されています。デュアルインタラクティブワッサースタインプロジェクトを使用したデータ駆動型データ駆動型アプローチ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Biologically Inspired Visual System Architecture for Object Recognition
  in Autonomous Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.IV/paper_14.html">
      <font color="black">Biologically Inspired Visual System Architecture for Object Recognition
  in Autonomous Systems</font>
    </a>
  </h2>
  <font color="black">これらのトップダウンメカニズムを最新のボトムアップフィードフォワードアルゴリズムと同様に模倣することで、正確で堅牢、かつ継続的に改善されるターゲット認識モデルが得られました。このメカニズムは、視覚入力時に不確実な状況で特に有利です。これらの予測は、認識プロセスの結果にバイアスをかける状況仮説の迅速な生成を可能にします。 
[要約]人間の視覚システムのメカニズムは、コンピュータビジョンアルゴリズムを人間のオペレータの能力に近づけるために分析されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-09">
        <br><font color="black">2020-02-09</font>
      </time>
    </span>
</section>
<!-- paper0: Feature based Sequential Classifier with Attention Mechanism -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.IV/paper_15.html">
      <font color="black">Feature based Sequential Classifier with Attention Mechanism</font>
    </a>
  </h2>
  <font color="black">子宮頸部疾患は一般に、上皮の下部（基底膜）から上部に進行すると理解されています。子宮頸がんは、女性に世界的に影響を与える最も致命的ながんの1つです。モデルは、CIN分類結果を生成し、 CINグレード予測。 
[ABSTRACT]子宮頸部生検スライドの組織病理学的検査を使用した子宮頸部上皮内腫瘍（cin）の評価は、観察者間のばらつきの影響を受けます。プレグナン（マリシー）は、通常、上皮の下部（基底膜）から上部に進行すると理解されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Simplex-Structured Matrix Factorization: Sparsity-based Identifiability
  and Provably Correct Algorithms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.IV/paper_16.html">
      <font color="black">Simplex-Structured Matrix Factorization: Sparsity-based Identifiability
  and Provably Correct Algorithms</font>
    </a>
  </h2>
  <font color="black">提案されたアルゴリズムが一意の分解を回復する条件は、ほとんどの場合、SSCよりもはるかに弱いです。重要なアイデアは、最大数のポイントを含むファセットの抽出に基づいています。このホワイトペーパーでは、シンプレックス構造化行列因数分解（SSMF）、非負の行列因数分解の一般化。 
[ABSTRACT]現在の状態-ssmfの識別可能性の結果を提供する最新のアルゴリズムは、十分に分散した状態（ssc）に依存しています。カンガルーの各ファセットに$ d $ポイントが必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Analysis and Comparison of Different Wavelet Transform Methods Using
  Benchmarks for Image Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.IV/paper_17.html">
      <font color="black">Analysis and Comparison of Different Wavelet Transform Methods Using
  Benchmarks for Image Fusion</font>
    </a>
  </h2>
  <font color="black">変換融合は、ソース画像をマルチスケールで表現するために変換を使用します。画像融合の目的は、補足情報と冗長情報を統合することです。補足情報は、CTとMRIによって提供されます。 
[ABSTRACT]画像を融合する2つの方法があります。これらは情報を結合します。これらの結合結合は、情報を表現する1つの画像を形成するために結合します。結果として得られる結果の結果変換画像は視覚的に比較されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Deep-VFX: Deep Action Recognition Driven VFX for Short Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.IV/paper_18.html">
      <font color="black">Deep-VFX: Deep Action Recognition Driven VFX for Short Video</font>
    </a>
  </h2>
  <font color="black">具体的には、人体に特殊効果を加えるためです。このペーパーは、従来のテンプレートマッチングではなく、モーションドリブンによるVFX合成を変更することを目的としています。これにより、ユーザーはこれらの個性を自慢することができます。 
[ABSTRACT] short-フォームモバイルビデオは、tik tokなど、世界中で非常に人気があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Deformable 3D Convolution for Video Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_0.html">
      <font color="black">Deformable 3D Convolution for Video Super-Resolution</font>
    </a>
  </h2>
  <font color="black">広範な実験により、時空間情報の活用におけるD3Dの有効性が実証されています。ビデオシーケンス間の時空間情報は、ビデオ超解像（SR）にとって重要です。ただし、既存のビデオでは時空間情報を完全に使用することはできません空間的特徴抽出と時間的動き補償は通常順次実行されるため、SRメソッド。 
[要約]空間-時間情報は既存のビデオsrメソッドでは完全には使用できません。これは、ネットワークが最新のsrパフォーマンスを実現するためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: DeepCLR: Correspondence-Less Architecture for Deep End-to-End Point
  Cloud Registration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_1.html">
      <font color="black">DeepCLR: Correspondence-Less Architecture for Deep End-to-End Point
  Cloud Registration</font>
    </a>
  </h2>
  <font color="black">KITTIオドメトリとModelNet40データセットを使用して、さまざまな点分布での方法を評価します。このような点群は、たとえば、移動プラットフォームに取り付けられたLiDARの連続測定から発生します。次に、これらの機能を使用して、両方の入力クラウド間の明示的なポイント対応を抽出することなく、エンドツーエンドの方法。 
[要旨]生の点群の深い登録における主な困難は、テンプレートとソースの点群の融合です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Movement Assessment from Skeleton Videos: A Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_2.html">
      <font color="black">Movement Assessment from Skeleton Videos: A Review</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、運動評価タスクを2次タスクに分割し、それらが必要な理由とその対処方法を説明します。このようなソリューションは、手頃な価格の機器と専用ソフトウェアを使用して家庭で実装できます。3Dカメラと可用性の向上最近の10年間でのコンピュータビジョンアルゴリズムの劇的な改善により、自動運動評価ソリューションの研究が加速しました。 
[ABSTRACT]スケルトンビデオからの自動運動評価の最近のソリューションを確認します。目的、機能、運動ドメイン、アルゴリズムアプローチによってそれらを比較します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-21">
        <br><font color="black">2020-07-21</font>
      </time>
    </span>
</section>
<!-- paper0: A simple way to make neural networks robust against diverse image
  corruptions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_3.html">
      <font color="black">A simple way to make neural networks robust against diverse image
  corruptions</font>
    </a>
  </h2>
  <font color="black">人間の視覚システムは、雨や雪などの自然に発生するさまざまな変化や破損に対して非常に堅牢です。ここでは、加法ガウスノイズとスペックルノイズを使用したシンプルだが適切に調整されたトレーニングが目に見えない破損に驚くほどうまく一般化し、簡単に破損のベンチマークImageNet-C（ResNet50を使用）およびMNIST-Cに関する以前の最新技術。これらの強力なベースライン結果に基づいて構築し、相関のない最悪の場合のノイズ分布に対する認識モデルの敵対的なトレーニングがパフォーマンスのさらなる向上につながることを示しています。対照的に、現代の画像認識モデルのパフォーマンスは、以前見られなかった破損。 
[ABSTRACT]最新の画像認識モデルのパフォーマンスは、以前には見られなかった破損を評価すると大幅に低下します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-16">
        <br><font color="black">2020-01-16</font>
      </time>
    </span>
</section>
<!-- paper0: Human-Centered Unsupervised Segmentation Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_4.html">
      <font color="black">Human-Centered Unsupervised Segmentation Fusion</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、Kモードのクラスタリングに基づく新しいセグメンテーションフュージョンモデルを紹介します。人間のグラウンドトゥルースセグメンテーションを使用して公開されているデータセットから得られた結果は、モデルが人間のセグメンテーションの最先端を上回っていることを明確に示しています。 。セグメンテーションは複数のソリューションをもたらし、したがってアルゴリズムを評価するためのグラウンドトゥルースデータを定義することが難しいため、一般に不適切な問題です。 
[ABSTRACT]問題は、画像ごとに1つのアノテーターを使用するだけで簡単に克服できます。ただし、このような取得は、大多数の人々による画像の認知的知覚を表すものではありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Greenhouse Segmentation on High-Resolution Optical Satellite Imagery
  using Deep Learning Techniques -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_5.html">
      <font color="black">Greenhouse Segmentation on High-Resolution Optical Satellite Imagery
  using Deep Learning Techniques</font>
    </a>
  </h2>
  <font color="black">使用されているデータセットは、温室が密集しているアゼルバイジャンの15の地域から収集された、1.5メートルの解像度と注釈マスクを備えた、パンシャープンのオルソ補正されたアゼルスキー画像（赤、緑、青、近赤外線チャネル）で構成されています。実験結果では、提案されたモデルは両方とも、ベースラインU-Netアーキテクチャよりも優れており、ベースラインアーキテクチャと比較して、提案された最良のモデルのスコアが$ 4.48 \％$高くなりました。拡張畳み込みとスキップ接続を独自に組み込んだ2つのモデルが提案され、結果が比較されます。ベースラインU-Netモデルのそれへ。 
[要約]このペーパーでは、アゼルスキー（スポット-7）光学衛星によって取得された画像のピクセルネット分類のための適切な概念が提案されています。結果は、ベースラインuネットモデルの結果と比較されます。これらのモデルには、特にシャープ化が組み込まれています。畳み込みと接続のスキップ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Variational Instance Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_6.html">
      <font color="black">Deep Variational Instance Segmentation</font>
    </a>
  </h2>
  <font color="black">具体的には、FCNをエンドツーエンドでトレーニングするために使用できる区分的に一定のセグメンテーション問題の最適化関数を最小化することとして、インスタンスセグメンテーションの変分緩和を提案します。PASCALVOC 2012の実験、セマンティック境界データセット（SBD） 、およびMSCOCO 2017データセットは、提案されたアプローチがインスタンスセグメンテーションタスクに効率的に取り組むことを示しています。これは、古典的なマムフォードシャー変分セグメンテーション問題を拡張して、インスタンスセグメンテーションのグラウンドトゥルースで順列不変ラベルを処理できるようにします。 
[ABSTRACT]状態、芸術のアルゴリズムはしばしば2つの別々の段階を使用します。最初の段階はオブジェクト提案を生成し、2番目は境界を認識して変更します。新しい方法は完全たたみ込みネットワーク（fcn）を使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Monocular Depth Estimation by Leveraging Structural Awareness
  and Complementary Datasets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_7.html">
      <font color="black">Improving Monocular Depth Estimation by Leveraging Structural Awareness
  and Complementary Datasets</font>
    </a>
  </h2>
  <font color="black">最後に、以前の方法の失敗事例の分析に基づいて、特別な照明条件、動的オブジェクト、傾斜したカメラ角度などの困難なシーンの新しいハードケース（HC）深度データセットを収集します。これらのブロックは、ネットワークの注意をグローバルに導きます異なるフィーチャレイヤー全体の構造またはローカルの詳細。このペーパーでは、この問題に3つの側面で取り組みます。 
[ABSTRACT]新しいデータセットは、情報に基づく学習カリキュラムによって活用されます。さまざまなデータセットを処理するために、トレーニング例を段階的に組み合わせています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: RAFT: Recurrent All-Pairs Field Transforms for Optical Flow -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_8.html">
      <font color="black">RAFT: Recurrent All-Pairs Field Transforms for Optical Flow</font>
    </a>
  </h2>
  <font color="black">Sintel（最終パス）では、RAFTは2.855ピクセルのエンドポイントエラーを取得します。これは、公開された最良の結果（4.098ピクセル）から30％のエラー削減です。さらに、RAFTは強力なクロスデータセット一般化と高い推論時間、トレーニング速度、パラメータ数の効率。RAFTはピクセルごとの特徴を抽出し、すべてのピクセルのペアに対してマルチスケール4D相関ボリュームを構築し、相関ボリュームに対してルックアップを実行する反復ユニットを通じてフローフィールドを繰り返し更新します。 。 
[ABSTRACT]ラフトはピクセルごとの機能を抽出し、すべてのピクセルのペアに対してマルチスケールの4D相関ボリュームを構築します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-26">
        <br><font color="black">2020-03-26</font>
      </time>
    </span>
</section>
<!-- paper0: DerainCycleGAN: A Simple Unsupervised Network for Single Image Deraining
  and Rainmaking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_9.html">
      <font color="black">DerainCycleGAN: A Simple Unsupervised Network for Single Image Deraining
  and Rainmaking</font>
    </a>
  </h2>
  <font color="black">その結果、Rain200Aでトレーニングされた既存の教師ありメソッドは、実際の雨の画像を処理するのにはるかに優れたパフォーマンスを発揮します。このホワイトペーパーでは、ペアになっていないデータを使用して教師なしSIDタスクを探索し、制約付きCycleGAN（またはまもなく、DerainCycleGAN）。CycleGANの制約付き転移学習能力と循環構造を完全に利用できます。合成と実際のデータセットに関する広範な実験により、当社のネットは既存の監視されていない排水ネットワークよりも優れており、他の関連する監視されているネットワークに対しても非常に競争力があります。 
[ABSTRACT]教師なし注意ガイド付き雨ストリーク抽出機能は、メモリを使用して2つの制約付きサイクル-整合性ブランチを持つ雨ストリークマスクを抽出します。その結果、教師なしプロジェクトを作成し、メモリを使用して雨の縞を削除する排水ツールを設計します監視されていない方法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-15">
        <br><font color="black">2019-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: TreeRNN: Topology-Preserving Deep GraphEmbedding and Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_10.html">
      <font color="black">TreeRNN: Topology-Preserving Deep GraphEmbedding and Learning</font>
    </a>
  </h2>
  <font color="black">さらに、従来の畳み込みニューラルネットワーク（CNN）およびリカレントニューラルネットワーク（RNN）に適した、ツリーを画像表現に転送する新しい投影スキームを提案しました。提案された方法をいくつかのグラフ分類データセットで評価し、管理します。 MUTAG、PTC-MR、NCI1データセットの最新技術と同等の精度を実証するため。グラフツリー画像からパターンを最もよく学ぶために、画像を繰り返し統合する2D RNNアーキテクチャであるTreeRNNを提案しますグラフのカテゴリの分類に役立つ行と列のピクセル。 
[ABSTRACT]検索は、行と列ごとに画像ピクセルを繰り返し統合するパターンパターンパターンシステムに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-21">
        <br><font color="black">2020-06-21</font>
      </time>
    </span>
</section>
<!-- paper0: DEAL: Deep Evidential Active Learning for Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_11.html">
      <font color="black">DEAL: Deep Evidential Active Learning for Image Classification</font>
    </a>
  </h2>
  <font color="black">ただし、それらは一貫して適切に実行されず、計算コストが高くなることがよくあります。CNNの最近のAL手法では、ラベル付けするインスタンスの選択にさまざまなソリューションが提案されています。このホワイトペーパーでは、ラベル付けされていないデータから効率的に学習する新しいALアルゴリズムを提案します。高い予測不確実性を捉えます。 
[要旨] cnnの最近の方法は、ラベル付けするインスタンスの選択にさまざまなソリューションを提供します。ただし、このようなモデルのトレーニングと検証には、通常、大きなラベル付きデータセットが必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Leveraging Undiagnosed Data for Glaucoma Classification with
  Teacher-Student Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_12.html">
      <font color="black">Leveraging Undiagnosed Data for Glaucoma Classification with
  Teacher-Student Learning</font>
    </a>
  </h2>
  <font color="black">教師モデルは診断されていない画像のラップされた情報を潜在的な特徴空間にエンコードし、一方で生徒モデルは教師から知識の伝達を通じて学習して緑内障の分類を改善します。実験により、提案されたフレームワークは診断されていないデータを効果的に利用して改善することができます緑内障の予測パフォーマンス。モデルのトレーニング手順では、「知識の伝達で教える学習（L2T-KT）」という名前の実際の教育実践をシミュレートする新しいトレーニング戦略を提案し、次のように「クイズプール」を確立します。教師の最適化ターゲット。 
[要約]深層学習モデルでは、適切にラベル付けされた大量のデータが必要です。緑内障の正確なラベル付けには数年の専門家のトレーニングが必要なため、これは比較的費用がかかります。具体的には、提案されたモデルは、教師-学生-学習の優先順位から適応されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Endo-Sim2Real: Consistency learning-based domain adaptation for
  instrument segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_13.html">
      <font color="black">Endo-Sim2Real: Consistency learning-based domain adaptation for
  instrument segmentation</font>
    </a>
  </h2>
  <font color="black">2つのデータセット（Cholec80とEndoVis&#39;15データセットの15ビデオ）の実験結果は、提案された\ emph {Endo-Sim2Real}メソッドの器具セグメンテーションの有効性を強調しています。介入システム..この作業は、シミュレーションと実際の（ラベル付けされていない）内視鏡データの共同学習のための一貫性ベースのフレームワークを提案し、このパフォーマンスの一般化の問題を解決します。 
[ABSTRACT]シミュレートされたデータでトレーニングされたモデルは実際のデータに一般化されませんが、モデルは一般化されていません。研究により、提案されたソリューションが効果的であることが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Shape and Pose Disentanglement for 3D Meshes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_14.html">
      <font color="black">Unsupervised Shape and Pose Disentanglement for 3D Meshes</font>
    </a>
  </h2>
  <font color="black">ポーズの転送や形状の取得など、いくつかのタスクを通じて学習した表現の有用性を実証します。それらの重要な強みは、表面の変化を形状およびポーズ依存コンポーネントに因数分解できることです。自己無矛盾性と相互無矛盾性の組み合わせを使用します。登録されたメッシュからポーズとシェイプ空間を学習するための制約。 
[ABSTRACT] 3D人間、顔、手、動物のデータセットの実験は、私たちのアプローチの一般性を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: MCU-Net: A framework towards uncertainty representations for decision
  support system patient referrals in healthcare contexts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_15.html">
      <font color="black">MCU-Net: A framework towards uncertainty representations for decision
  support system patient referrals in healthcare contexts</font>
    </a>
  </h2>
  <font color="black">MCU-Netと認識的不確実性およびこのアプリケーション用に調整された不確実性しきい値を組み合わせることで、個々の患者レベルで自動化されたパフォーマンスが最大化され、しかも本当に不確実なケースが参照されることを実証します。したがって、4つの異なる不確実性メトリックで評価されたU-Netとモンテカルロドロップアウトを組み合わせたMCU-Netを使用して、医療画像セグメンテーションで評価された不確実性表現のフレームワークを提示します。 
[要旨]ディープラーニングフレームワークでは、不確実性の表現がないため、この患者ベースのアプローチは許可されていません。これは、不確実なケースを医療専門家に自動紹介するためのステップです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Instance-aware Self-supervised Learning for Nuclei Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_16.html">
      <font color="black">Instance-aware Self-supervised Learning for Nuclei Segmentation</font>
    </a>
  </h2>
  <font color="black">提案されたアプローチは2つのサブタスク（つまり、スケールワイズトリプレット学習とカウントランキング）を含み、ニューラルネットワークが核のサイズと量の事前知識を暗黙的に活用できるようにし、したがって、生からインスタンス認識機能表現をマイニングしますデータ..核が広く存在し、形態学的分散が大きいため、正確な核インスタンスセグメンテーションは、依然として計算病理学において最も困難なタスクの1つです。私たちの知る限り、これは、自己監視学習に焦点を当てた最初の作業です。インスタンスのセグメンテーション。 
[ABSTRACT]新しい研究は、核インスタンスプロジェクトプロジェクトプロジェクトでたたみ込みニューラルネットワーク（cnns）の能力を活用するための自己管理学習フレームワークを提案しています。これは、性器が輪郭を描く能力を使用することを含み、非常に面倒で費用がかかります。多くの場合、注釈付きデータが不足します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Attend and Segment: Attention Guided Active Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_17.html">
      <font color="black">Attend and Segment: Attention Guided Active Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">エージェントは、訪問したエリアから来るキューに依存して他のパーツを幻覚にしながら、エリアを選択して参加できます。動的環境では、限られた視野/リソースを持つエージェントは、それを解析する前にシーンを完全に観察できません.. CityScapes、CamVid、およびKittiデータセットでは、画像ピクセルの18％のみを処理することで、平均ピクセル単位の精度が78.1％、80.9％、76.5％に達します（網膜のような垣間見る10）。 
[要約]戦略は、エージェントが環境についての理解を深めることであり、最も不確かな領域に参加する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Edge-aware Graph Representation Learning and Reasoning for Face Parsing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_18.html">
      <font color="black">Edge-aware Graph Representation Learning and Reasoning for Face Parsing</font>
    </a>
  </h2>
  <font color="black">相関関係は、顔の外観、ポーズ、表情などに関する重要な手がかりであり、顔の解析では考慮に入れる必要があります。このモデルは、グラフ上の頂点間で情報を伝播することにより、領域間の関係について学習し、理由を調べます。顔の解析最近注目を集めている各顔のコンポーネントにピクセル単位のラベルを推測します。 
[要約]コードはgithubで入手できます。 com / tegusi-スケール</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Adapting Object Detectors with Conditional Domain Normalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_19.html">
      <font color="black">Adapting Object Detectors with Conditional Domain Normalization</font>
    </a>
  </h2>
  <font color="black">次に、このドメインベクトルを使用して、条件付き正規化によって別のドメインの機能をエンコードし、異なるドメインの機能が同じドメイン属性を保持するようにします。ドメインを削除するためにセマンティック機能でドメイン混乱学習を行う既存の適応作業とは対照的です特定の要因、CDNは、別のドメインの学習されたドメインベクトルで条件付けられた1つのドメインのセマンティック機能を変調することにより、異なるドメイン分布を調整します。CDNは、異なるドメインからの機能が共有潜在空間にエンコードするように設計されています。同じドメイン属性。 
[要約]この作業では、ドメインギャップを埋めるために条件付きドメイン正規化（cdn）を提示します。これを達成するには、最初に、ドメイン固有の属性を1つのドメインのセマンティック機能から分解します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-16">
        <br><font color="black">2020-03-16</font>
      </time>
    </span>
</section>
<!-- paper0: Fast Training of Deep Networks with One-Class CNNs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_20.html">
      <font color="black">Fast Training of Deep Networks with One-Class CNNs</font>
    </a>
  </h2>
  <font color="black">1クラスCNNは、新規性検出で有望であることが示されています。ただし、マルチクラス分類に拡張するために行われた作業はほとんどありません。このアプローチの利点は、トレーニングのほぼ半分または2/3従来のマルチクラスディープネットワークの時間。 
[ABSTRACT]システムは1つのクラスのcnnを使用します。つまり、マルチクラスの分類のために、クラスごとに1つのcnnをトレーニングします。このアプローチの利点は、一般に認識精度が向上します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-28">
        <br><font color="black">2020-06-28</font>
      </time>
    </span>
</section>
<!-- paper0: Answering Questions about Data Visualizations using Efficient Bimodal
  Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_21.html">
      <font color="black">Answering Questions about Data Visualizations using Efficient Bimodal
  Fusion</font>
    </a>
  </h2>
  <font color="black">チャート質問応答（CQA）は、新しく提案された視覚的質問応答（VQA）タスクで、アルゴリズムはデータの視覚化に関する質問に答える必要があります。 PReFILはそのシンプルさにもかかわらず、FigureQAとDVQAの両方のデータセットで最先端のシステムと人間のベースラインを大幅に上回っています。 
[ABSTRACT] prefilは、グラフに関する一連の質問をすることでテーブルを再構築するために使用できます。prefilは、最初に、質問と画像の機能を融合することにより、バイモーダル埋め込みを学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-05">
        <br><font color="black">2019-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Multi-Object Tracking: A Baseline and New Evaluation Metrics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_22.html">
      <font color="black">3D Multi-Object Tracking: A Baseline and New Evaluation Metrics</font>
    </a>
  </h2>
  <font color="black">驚いたことに、システムでは2Dデータを入力として使用していませんが、KITTI 2D MOTリーダーボードで競争力のあるパフォーマンスを実現しています。 3D MOTメソッドの公平な比較..標準化された3D MOT評価を促進するために、システムと評価コードはhttps://github.com/xinshuoweng/AB3DMOTで公開されています。 
[ABSTRACT] 3d motは3d motシステムの新しいコンセプトです。提案されたシステムは$ 207のレートで実行されます。 4 $ fps</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-09">
        <br><font color="black">2019-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Disentangled Feature Representation for Hybrid-distorted Image
  Restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_23.html">
      <font color="black">Learning Disentangled Feature Representation for Hybrid-distorted Image
  Restoration</font>
    </a>
  </h2>
  <font color="black">広範な実験結果はまた、最新のHD-IRスキームと比較して、当社のアプローチの優れたパフォーマンスを証明しています。このような干渉を分解するために、ハイブリッド歪みの機能レベルの分割統治を達成するために、Disentangled Feature Learningの概念を導入します。また、歪みの表現を適応的にフィルターで除外し、生の画像を構築するためにさまざまなチャネルから有用なコンテンツ情報を集約するために、チャネルごとに注意を払った機能集約モジュール（FAM）を提案しています。 
[ABSTRACT]さまざまな歪みの特徴表現をさまざまなチャネルに配布するために、新しい絡み合い解消モジュールが提案されています。プロジェクトを使用して、プロジェクトの新しいバージョンを作成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Learning One Class Representations for Face Presentation Attack
  Detection using Multi-channel Convolutional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_24.html">
      <font color="black">Learning One Class Representations for Face Presentation Attack
  Detection using Multi-channel Convolutional Neural Networks</font>
    </a>
  </h2>
  <font color="black">この作業では、1クラス分類子を使用したPADの新しいフレームワークを提案します。使用される表現は、マルチチャネル畳み込みニューラルネットワーク（MCCNN）で学習されます。これらに加えて、1クラスガウス混合モデルが使用されます。 PADタスクの埋め込み..提案されたフレームワークは、真正で利用可能な（既知の）攻撃クラスから堅牢なPADシステムを学習するための新しいアプローチを導入します。 
[要約] 1つのクラスを使用するパッドの新しいフレームワーク。使用されるクラスclassifier.representationは、マルチチャネル畳み込みニューラルネットワークで学習されます。これは、真正なデータの収集として特に重要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Training Reduces Information and Improves Transferability -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_25.html">
      <font color="black">Adversarial Training Reduces Information and Improves Transferability</font>
    </a>
  </h2>
  <font color="black">最後に、理論的洞察を活用して、反転によって再構成された画像の品質を著しく改善します。CIFAR-10、CIFAR-100、およびImageNetでトレーニングされた堅牢なネットワークを使用して、いくつかのデータセットで結果を検証します。この矛盾に動機付けられて、敵対的訓練と情報理論の間の二重の関係。 
[ABSTRACT]敵対的なトレーニングにより、新しいタスクへの線形転送可能性が向上することを示します。これにより、表現の転送可能性とソースタスクの精度との間に新たなトレードオフが生じます。理論に反することなく、確定的ネットワークの可逆性を説明します。最小限の原則</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Exploit Multiple Vision Modalities by Using Grafted Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_26.html">
      <font color="black">Learning to Exploit Multiple Vision Modalities by Using Grafted Networks</font>
    </a>
  </h2>
  <font color="black">強化されたグラフトネットワークは、推論コストを増加させることなく、熱およびイベントカメラデータセットを使用したオブジェクト検出タスクで、事前学習済みネットワークの競争平均精度（AP50）スコアに到達することを示しています。グラフトされたフロントエンドは5〜8％しかありません全体のパラメータの1つであり、ラベル付きデータからオブジェクト検出器全体をトレーニングするのに必要な時間の5％に相当する単一のGPUで数時間トレーニングできます。特に、サーマルフレームによって駆動されるグラフトネットワークは、相対的な強度フレームの使用に比べて49.11％の改善。 
[ABSTRACT]移植されたネットワークは、強度フレームの使用に対して49. 11％の相対的な改善を示しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-24">
        <br><font color="black">2020-03-24</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Models and Shortwave Infrared Information to Detect Face
  Presentation Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_27.html">
      <font color="black">Deep Models and Shortwave Infrared Information to Detect Face
  Presentation Attacks</font>
    </a>
  </h2>
  <font color="black">提案されたデータベースがこの困難な問題の研究を促進することを願っています。実験は、さまざまな攻撃を含む新しい公開された無料のデータベースで行われました。実施された実験は、カラー画像または異なるモダリティ（可視、NIR、熱、深度）の組み合わせ、およびSWIR画像の違いに作用するSVMベースの分類子。 
[要約]短波赤外線（スワール）イメージングの使用が検討されています。データの提示が最も効果的な方法と見なされています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Finding Your (3D) Center: 3D Object Detection Using a Learned Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_28.html">
      <font color="black">Finding Your (3D) Center: 3D Object Detection Using a Learned Loss</font>
    </a>
  </h2>
  <font color="black">シーンは中心でラベル付けされていないと想定しているため、面取りなどの古典的な損失を使用してそれをトレーニングすることはできません。シーンネットワークは、3Dシーン全体を一連の3Dオブジェクトセンターにマッピングします。補足資料は、 ：https://dgriffiths3.github.io。 
[ABSTRACT]ネットワークは3dシーン全体を一連の3dオブジェクトセンターにマッピングします。オブジェクトラベルのわずか5％で同等のパフォーマンスを達成できます。代わりに、別のシーンネットワークを使用して損失をラベル付けします。この関数は非常に似ています-したがって、代わりに使用できます-監視あり損失が提供する勾配</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: Source Camera Verification from Strongly Stabilized Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_29.html">
      <font color="black">Source Camera Verification from Strongly Stabilized Videos</font>
    </a>
  </h2>
  <font color="black">1つのパブリックデータセットと2つのカスタムデータセットで実行されたテストは、提案された方法が、誤った帰属に大きな影響を与えることなく、計算負荷に応じて、より強力な安定化を受けたすべてのビデオの23〜30％のソースを検証できることを示しています。サブフレームレベルでの変換、それらの正当性を検証するための多くの制約を組み込んでおり、正しい変換の検索における計算の柔軟性を提供します。この課題に対処するために、安定化変換の空間的に変化する性質であり、それらの検索においてより大きな自由度を想定しています。 
[ABSTRACT]デジタルで実行する場合、ビデオの修正には、ビデオフレームのトリミング、ワーピング、およびインペインティングが含まれます。この方法は、ビデオの編集やダウンサイジングなど、他のビデオ生成ステップの破壊的な影響に対する全体的な対応にも挑戦します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-26">
        <br><font color="black">2019-11-26</font>
      </time>
    </span>
</section>
<!-- paper0: Unifying Deep Local and Global Features for Image Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_30.html">
      <font color="black">Unifying Deep Local and Global Features for Image Search</font>
    </a>
  </h2>
  <font color="black">また、モデルに統合され、トレーニング効率とマッチングパフォーマンスを向上させる、ローカルフィーチャーのオートエンコーダーベースの次元削減手法を紹介します。最近のフィーチャー学習作業からの教訓を活用し、グローバルフィーチャーの一般化された平均プーリングを組み合わせたモデルを提案します。ローカル機能の注意深い選択。この作業では、グローバルおよびローカル機能を単一のディープモデルに統合し、効率的な機能抽出による正確な検索を可能にすることが、私たちの主な貢献です。 
[ABSTRACT]新しいモデルはdelgと呼ばれ、ローカルとグローバルの深い機能を表しています。つまり、2つのヘッドの違いを注意深くバランスさせることで、ネットワークをエンドツーエンドで学習できます-画像レベルのラベルのみが必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-14">
        <br><font color="black">2020-01-14</font>
      </time>
    </span>
</section>
<!-- paper0: Comparing to Learn: Surpassing ImageNet Pretraining on Radiographs By
  Comparing Image Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_31.html">
      <font color="black">Comparing to Learn: Surpassing ImageNet Pretraining on Radiographs By
  Comparing Image Representations</font>
    </a>
  </h2>
  <font color="black">この手法は、異なる画像表現を比較することでロバストな特徴を学習するため、Comparing to Learn（C2L）と呼んでいます。 。 
[要約]異なる画像表現を比較することで堅牢な機能を学習するため、この方法を比較と比較して学習（c2l）と呼んでいます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-15">
        <br><font color="black">2020-07-15</font>
      </time>
    </span>
</section>
<!-- paper0: InsideBias: Measuring Bias in Deep Networks and Application to Face
  Gender Biometrics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_32.html">
      <font color="black">InsideBias: Measuring Bias in Deep Networks and Application to Face
  Gender Biometrics</font>
    </a>
  </h2>
  <font color="black">最後に、バイアスモデルを検出する新しい方法であるInsideBiasを提案します。InsideBiasは、モデルがどのように機能するかではなく、情報を表す方法に基づいています。これは、バイアス検出の他の既存の方法では通常行われています。InsideBiasを使用した戦略では、非常に少数のサンプルでバイアスされたモデルを検出します（このケーススタディでは15画像のみ）。 
[ABSTRACT] insidebiasを使用したGoogleの戦略により、サンプルが非常に少ないバイアスモデルを検出できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-14">
        <br><font color="black">2020-04-14</font>
      </time>
    </span>
</section>
<!-- paper0: Paraphrasing Complex Network: Network Compression via Factor Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_33.html">
      <font color="black">Paraphrasing Complex Network: Network Compression via Factor Transfer</font>
    </a>
  </h2>
  <font color="black">提案された因子伝達方法で訓練された学生ネットワークは、従来の知識伝達方法で訓練されたものよりも優れていることを観察しました。この論文では、畳み込み演算を使用して教師の知識を言い換え、学生のためにそれを翻訳する新しい知識伝達方法を提案します。 ..これは、言い換えと翻訳と呼ばれる2つの畳み込みモジュールによって行われます。 
[要約]知識の転送と呼ばれる方法は、より強力な教師ネットワークで生徒ネットワークをトレーニングすることです。これは、言い換えと翻訳と呼ばれる2つの畳み込みモジュールによって行われます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-02-14">
        <br><font color="black">2018-02-14</font>
      </time>
    </span>
</section>
<!-- paper0: Regularizing Deep Networks with Semantic Data Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_34.html">
      <font color="black">Regularizing Deep Networks with Semantic Data Augmentation</font>
    </a>
  </h2>
  <font color="black">次に、拡張サンプルの数が無限になると仮定することにより、拡張トレーニングセットの予想クロスエントロピー（CE）損失の上限が導出され、非常に効率的なアルゴリズムが生成されます。この観察に基づいて、トレーニングサンプルを多くの特徴空間でのこのような方向は、データセットを効果的に増強して多様性を高めることができます。従来のデータ増強スキーム（フリッピング、変換、回転など）は、低レベルでデータに依存せず、クラスに依存しない操作であり、増強されたサンプルの多様性が制限されます。 。 
[ABSTRACT]提案された方法は、ディープネットワークが線形化された特徴の学習に効果的であるという事実に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-21">
        <br><font color="black">2020-07-21</font>
      </time>
    </span>
</section>
<!-- paper0: Compressed DenseNet for Lightweight Character Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_35.html">
      <font color="black">Compressed DenseNet for Lightweight Character Recognition</font>
    </a>
  </h2>
  <font color="black">LDBに基づいて、軽量文字認識用の圧縮DenseNet（CDenseNet）を提案します。そのため、出力に近いレイヤーの入力として提供される組み合わせ機能のチャネル数と関連する計算コストは、密なブロックが深くなる..これは、重い計算コストと大きな重みサイズをもたらし、密なブロックの深さを制限します。 
[ABSTRACT] crnnのバリアントのような新しい進歩により、ネットワークの実行時間が短縮されましたが、畳み込みネットワークの内部計算コストと重みサイズがボトルネックとして公開されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-15">
        <br><font color="black">2019-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: DLow: Diversifying Latent Flows for Diverse Human Motion Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_36.html">
      <font color="black">DLow: Diversifying Latent Flows for Diverse Human Motion Prediction</font>
    </a>
  </h2>
  <font color="black">これらの問題に対処するために、新しいトレーニング方法である、多様化した潜在フロー（DLow）を提案して、事前学習済みの深生成モデルからサンプルの多様なセットを生成します。次に、相関潜在コードが一連の相関サンプルにデコードされます。ランダム（独立）サンプリング、提案されたDLowサンプリングメソッドは、単一のランダム変数をサンプリングし、学習可能なマッピング関数のセットを使用して、相関する潜在コードのセットにマッピングします。 
[要約]提案されたdlowサンプリング方法は、単一のランダム変数変数をサンプリングし、それを学習可能なマッピング関数のセットでマッピングします。提案された方法は、2つの理由で多様なサンプルを生成することを保証していません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br><font color="black">2020-03-18</font>
      </time>
    </span>
</section>
<!-- paper0: Real-Time Instrument Segmentation in Robotic Surgery using Auxiliary
  Supervised Deep Adversarial Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_37.html">
      <font color="black">Real-Time Instrument Segmentation in Robotic Surgery using Auxiliary
  Supervised Deep Adversarial Learning</font>
    </a>
  </h2>
  <font color="black">また、セグメンテーションモデルを正規化するために、補助損失と敵対損失を組み合わせる新しい方法を紹介します。さまざまな次元のフィーチャーマップと補助ブランチとメインブランチのチャネルを融合するマルチ解像度フィーチャーフュージョンモジュール（MFF）を提案します。この目的のために、商用のロボットシステムから取得した高解像度のビデオから手術器具をセグメント化するために、軽量のカスケード型畳み込みニューラルネットワーク（CNN）を開発しました。 
[ABSTRACT]実際の外科医は、高度な高度な高度なナビゲーションシステムを開発しました。mffは、補助ブランチとメインブランチからのさまざまな次元とチャネルの機能マップを融合するマルチ解像度機能融合モジュール</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Risk Assessment in the Face-based Watchlist Screening in e-Border -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_38.html">
      <font color="black">Risk Assessment in the Face-based Watchlist Screening in e-Border</font>
    </a>
  </h2>
  <font color="black">ウォッチリストテクノロジーの主要なタスクは、誤認やなりすましの影響を軽減することです。この研究の結果は、ウォッチリストテクノロジーで使用されるあらゆる生体認証モダリティに適用できます。この問題に対処するために、新しいコストベースの旅行者のリスク評価のモデルであり、大規模な顔のデータベースを使用した集中的な実験を通じてその効率を証明しました。 
[要約]ウォッチリストテクノロジーの主要なタスクは、ミスの影響を軽減すること-識別となりすまし</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Adaptive Offline Quintuplet Loss for Image-Text Matching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_39.html">
      <font color="black">Adaptive Offline Quintuplet Loss for Image-Text Matching</font>
    </a>
  </h2>
  <font color="black">（3）ペナルティには、「硬度」の程度が異なるハードネガに対する階層性と適応性がありません。さらに、ポジティブ、オフラインハードネガ、オンラインハードネガの知識を組み合わせた新しい損失関数が作成されます。（2）トレーニング済みモデルは、トレーニングセットからテストセットへの一般化機能が弱い。 
[ABSTRACT]トレーニングミニバッチ内の各画像またはテキストアンカーについて、モデルはアンカーのポジティブと最も紛らわしいネガを区別するようにトレーニングされます。この戦略により、モデルのキャパシティが改善され、きめの細かい対応と非-画像とテキスト入力の対応</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-07">
        <br><font color="black">2020-03-07</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning for Vision-based Prediction: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_40.html">
      <font color="black">Deep Learning for Vision-based Prediction: A Survey</font>
    </a>
  </h2>
  <font color="black">この調査で提示されたすべての情報のデータベースは、ペーパー、データセット、およびメトリックに従って相互参照されており、https：//github.com/aras62/vision-based-prediction。でオンラインで参照できます。さらに、ビジョンベースの予測タスクに使用される一般的な評価指標とデータセット。各カテゴリについて、使用される一般的なアーキテクチャ、トレーニング方法、およびデータのタイプを強調表示します。 
[要約]このホワイトペーパーの目的は、過去5年間のフィールドの概要を提供することです。各カテゴリについて、一般的なアーキテクチャ、トレーニング方法、使用するデータのタイプを強調しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br><font color="black">2020-06-30</font>
      </time>
    </span>
</section>
<!-- paper0: SPARK: Spatial-aware Online Incremental Attack Against Visual Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_41.html">
      <font color="black">SPARK: Spatial-aware Online Incremental Attack Against Visual Tracking</font>
    </a>
  </h2>
  <font color="black">OTB100、VOT2018、UAV123、およびLaSOTでの最新のトラッカー（つまり、AlexNet、MobileNetv2、およびResNet-50を備えたSiamRPN ++、およびSiamDW）に関する詳細な評価は、SPARKがマイナーな摂動を持つUAとTAの両方のトラッカー..このホワイトペーパーでは、ビジュアルトラッキングに対する敵対的攻撃の新しいタスクを識別します。不正な（非対象攻撃、UA）または指定された軌道（対象攻撃、TA）.. SPARK）は、オンラインで空間時間的スパース増分摂動を実行し、敵の攻撃を知覚しにくくします。 
[ABSTRACT]オンラインビデオオブジェクトトラッキングの敵対的攻撃はめったに探索されません。これには、カテゴリではなくオブジェクトの移動軌跡を追跡するオンライン敵対的攻撃が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-19">
        <br><font color="black">2019-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: CrossTransformers: spatially-aware few-shot transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_42.html">
      <font color="black">CrossTransformers: spatially-aware few-shot transfer</font>
    </a>
  </h2>
  <font color="black">次に、CrossTransformersと呼ばれる新しいトランスフォーマーベースのニューラルネットワークアーキテクチャを提案します。これは、少数のラベル付けされた画像とラベル付けされていないクエリを取り、クエリとラベル付けされた画像の間の粗い空間対応を見つけ、空間的距離を計算することによってクラスメンバーシップを推測します。対応する機能..次に、この問題を軽減する2つの方法を提案します。結果は、タスクとドメインのシフトに対してより堅牢な分類子です。これは、最近のMeta-Datasetの最先端のパフォーマンスを介して示しています。 ImageNetから他の多くのビジョンデータセットへの転送を評価するためのデータセット。 
[ABSTRACT]新しい研究は、ニューラルネットワーク表現が現代のビジョンシステムを支える方法が監督崩壊の対象となる方法を示しています。私たちは、自己管理学習を使用して、より優れた転送を行う小さな機能を奨励します。これらは、タスクとドメインフォームにより堅牢な新しい分類子を含みます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Operation-Aware Soft Channel Pruning using Differentiable Masks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_43.html">
      <font color="black">Operation-Aware Soft Channel Pruning using Differentiable Masks</font>
    </a>
  </h2>
  <font color="black">広範な実験を行い、最先端の方法と比較した場合に同じ量のリソースが与えられた場合の出力ネットワークの精度の面で優れたパフォーマンスを達成します。このために、個々のチャネルの差別化可能なマスクを学習し、ソフトにします最適化手順全体の決定。これにより、より大きな検索スペースを探索し、より安定したネットワークをトレーニングすることが容易になります。提案されたフレームワークにより、微調整の追加手順なしで、モデルパラメーターとチャネルプルーニングの共同学習を介して圧縮モデルを識別できます。 
[ABSTRACT]提案されたシステムは、モデルの学習とチャネルの剪定を通じてモデルを識別することを可能にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Video-ception Network: Towards Multi-Scale Efficient Asymmetric
  Spatial-Temporal Interactions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_44.html">
      <font color="black">Video-ception Network: Towards Multi-Scale Efficient Asymmetric
  Spatial-Temporal Interactions</font>
    </a>
  </h2>
  <font color="black">たとえば、Something-to-Something v1、Kinetics、Diving48などの強力な時間的推論または外観の区別を必要とする最新のいくつかの大規模なビデオデータセットでメソッドを検証し、ベルとホイッスルのない新しい最先端の結果を示します。 。マルチスケールの効率的な非対称時空間ブロックと呼ばれる\ textit {plug-and-play}ブロックとしてメソッドをインスタンス化します。このメソッドは、従来の2D CNNをアクション認識などのビデオ理解タスクに簡単に適合させることができます。 
[ABSTRACT]最適化された機能の相互作用レイヤーは、最適化された機能の相互作用の作業です。これにより、機能の融合手順が効率的かつ効果的に可能になります。この方法では、従来の2d cnnをアクション認識などのビデオ理解タスクに簡単に適応できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Making an Invisibility Cloak: Real World Adversarial Attacks on Object
  Detectors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_45.html">
      <font color="black">Making an Invisibility Cloak: Real World Adversarial Attacks on Object
  Detectors</font>
    </a>
  </h2>
  <font color="black">標準的な検出データセットを使用して、一般的に使用される一連の検出器と検出器のアンサンブルによって生成される客観性スコアを抑制するパターンをトレーニングします。広範な実験を通じて、ホワイトボックスとブラックボックスの両方の設定で敵対的にトレーニングされたパッチの効果をベンチマークします、およびデータセット、オブジェクトクラス、および検出器モデル間の攻撃の転送可能性を定量化します。最新のオブジェクト検出フレームワークに対する敵対的な攻撃の体系的な研究を紹介します。 
[ABSTRACT]一連の一般的なボックスと検出器のアンサンブルによって生成される客観性スコアを抑制するパターンをトレーニングします。印刷されたポスターとウェアラブルな服を使用した物理世界の攻撃の詳細な研究を提示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-31">
        <br><font color="black">2019-10-31</font>
      </time>
    </span>
</section>
<!-- paper0: MI^2GAN: Generative Adversarial Network for Medical Image Domain
  Adaptation using Mutual Information Constraint -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_46.html">
      <font color="black">MI^2GAN: Generative Adversarial Network for Medical Image Domain
  Adaptation using Mutual Information Constraint</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案されたMI $ ^ 2 $ GANがエレガントな翻訳画像を生成できるだけでなく、広く使用されているディープラーニングネットワーク（U-Netなど）の一般化パフォーマンスを大幅に改善できることを示しています。特に、コンテンツ機能のもつれを解きますソース画像と翻訳画像の両方のドメイン情報から取得し、絡み合っていないコンテンツ機能間の相互情報を最大化して、画像オブジェクトを保存します。提案されたMI $ ^ 2 $ GANは、2つのタスクで評価されます。画像と眼底画像における視神経乳頭と杯のセグメンテーション。 
[要約]提案されたmi $ ganは、ポリープと眼底画像における視神経乳頭と杯のパフォーマンスの2つのタスクで評価されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: FLOT: Scene Flow on Point Clouds Guided by Optimal Transport -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_47.html">
      <font color="black">FLOT: Scene Flow on Point Clouds Guided by Optimal Transport</font>
    </a>
  </h2>
  <font color="black">2点間の輸送コストは、合成データセットを使用した完全な監視の下でトレーニングされたニューラルネットワークによって抽出された深い特徴間のペアワイズ類似性によって与えられます。主な発見は、FLOTが合成および実世界で既存の最良の方法と同様に実行できることです。これにより、必要なパラメーターが少なく、マルチスケール分析を使用せずにデータセットを作成できます。これにより、最適なトランスポートパラメーターの特定の選択を使用して取得されるFLOT $ _0 $という簡単な方法が実現し、FLOTとほぼ同じように機能します。 
[ABSTRACT] flotは、合成および実世界のデータセットで既存の最良の方法と同様に実行でき、必要なパラメーターがはるかに少なく、マルチスケール分析を使用しません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: A Graph Attention Spatio-temporal Convolutional Networks for 3D Human
  Pose Estimation in Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_48.html">
      <font color="black">A Graph Attention Spatio-temporal Convolutional Networks for 3D Human
  Pose Estimation in Video</font>
    </a>
  </h2>
  <font color="black">これは、アテンションメカニズムを介してローカルとグローバルの両方の空間情報をモデル化することで行います。ローカル2次および対称制約は、これらの関節の深さのあいまいさを、1つだけの隣人（足首など）で緩和できます。ビデオでの3Dポーズ推定の利点時間情報と空間情報の両方。
[ABSTRACT]情報の時空間情報は、目立った問題であるオクルージョンと深度のあいまいさへの対処に役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-11">
        <br><font color="black">2020-03-11</font>
      </time>
    </span>
</section>
<!-- paper0: JRMOT: A Real-Time 3D Multi-Object Tracker and a New Large-Scale Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_49.html">
      <font color="black">JRMOT: A Real-Time 3D Multi-Object Tracker and a New Large-Scale Dataset</font>
    </a>
  </h2>
  <font color="black">作業の一環として、JRDBデータセットをリリースしました。これは、200万を超えるボックスと、54の屋内および屋外シーンにわたる3500時間の一貫性のある2D + 3D軌跡で注釈が付けられた、新しい大規模2D + 3Dデータセットおよびベンチマークです。ソーシャルロボットJackRabbotは、システムが複数の歩行者を高速かつ確実に追跡できることを示しています。この作業では、RGB画像と3D点群からの情報を統合してリアルタイムの状態を実現する新しい3D MOTシステムであるJRMOTを紹介します。 -最先端の追跡パフォーマンス。 
[要旨]私たちのシステムは、再識別、2dおよび3d検出、追跡記述のための最近のニューラルネットワークを使用して構築されています。これらは、軌道の開発、トレーニング、評価に使用する社会的設定の3d点群を含みます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br><font color="black">2020-02-19</font>
      </time>
    </span>
</section>
<!-- paper0: Wasserstein Routed Capsule Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_50.html">
      <font color="black">Wasserstein Routed Capsule Networks</font>
    </a>
  </h2>
  <font color="black">概算のWasserstein目標で訓練されたニューラルネットワークを使用して複雑なタスクに取り組むことができる新しいパラメーター効率の良いカプセルアーキテクチャを提案します。アーキテクチャ全体を通してカプセルを動的に選択します。提案された概念を検証するいくつかのアブレーション研究を実行し、ネットワークより少ないパラメーターを使用して、CIFAR-10で他のカプセルアプローチを1.2％以上大幅に上回ることができます。このアプローチは、ほとんどオーバーヘッドを使用せずに改善された結果を提供できる堅牢なルーティングスキームの実装に焦点を当てています。 
[ABSTRACT]シンプルなアーキテクチャは競争力のある結果を達成できませんでした。しかし、最近のモデルは競争力のある結果を提供できませんでした</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Rethinking CNN Models for Audio Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_51.html">
      <font color="black">Rethinking CNN Models for Audio Classification</font>
    </a>
  </h2>
  <font color="black">これにより、全体的な精度が向上した強力なアンサンブルモデルを構築するための大幅な多様性がもたらされます。さらに、初期化に事前トレーニング済みのモデルの重みを使用しても、同じモデルのさまざまな出力実行ではパフォーマンスにばらつきがあることを示しています。論文では、ImageNet事前トレーニング済みの標準ディープCNNモデルが、音声分類の強力なベースラインネットワークとして使用できることを示しています。 
[ABSTRACT]事前トレーニング済みの重みを使用する特定の標準モデルの場合、ランダムに初期化された重みを使用するよりも優れていることを示します。これは、事前トレーニング済みモデル、事前学習済みモデルなどが原因で、ランダム初期化済み重みを使用するよりも標準モデルの方が優れているためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: DeepSVG: A Hierarchical Generative Network for Vector Graphics Animation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_52.html">
      <font color="black">DeepSVG: A Hierarchical Generative Network for Vector Graphics Animation</font>
    </a>
  </h2>
  <font color="black">私たちのネットワークが多様なベクターグラフィックスを正確に再構築することを学習し、補間やその他の潜在的な空間操作を実行することにより、強力なアニメーションツールとして機能できることを示します。このアーキテクチャは、形状自体をエンコードする低レベルコマンドから高レベル形状を効果的に解きます..ネットワークは、非自己回帰的に一連の形状を直接予測します。 
[ABSTRACT]私たちのアーキテクチャは、形状自体をエンコードする低レベルコマンドから高レベル形状を効果的に解きます。新しい大規模データセットをリリースすることにより、複雑なsvgアイコン生成のタスクを紹介します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Directional Feature Maps for Cardiac MRI Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_53.html">
      <font color="black">Learning Directional Feature Maps for Cardiac MRI Segmentation</font>
    </a>
  </h2>
  <font color="black">心臓MRIセグメンテーションは、個人の心臓性能パラメーターを評価するための臨床診断で重要な役割を果たします。これら2つの問題に取り組むために、クラス間の違いとクラス内の類似性を同時に強化できる方向性特徴マップを活用する新しい方法を提案します。具体的には、心臓セグメンテーションを実行し、方向フィールド（DF）モジュールを介して、各ピクセルに最も近い心臓組織境界から離れた方向フィールドを学習します。 
[ABSTRACT]心臓mriには、不明瞭で一貫性のない長い歴史があります。これらには、不明瞭な境界や不均一な強度変動が含まれます。これらは単純ですが効果的で、既存のセグメンテーションネットワークに柔軟に追加できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Spectral Facial Biometrics in Access Control -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_54.html">
      <font color="black">Multi-Spectral Facial Biometrics in Access Control</font>
    </a>
  </h2>
  <font color="black">安価なRGB-Dセンサーを使用して取得した深度データを利用して、被験者の頭のポーズを見つけます。また、外科的制御、リハビリテーション、アクセシビリティのための自然で非接触の制御インターフェースでバイオメトリクスを使用することの新しい有望な視野を示しています。正面ビューフレームは顔認識の効率を向上させ、対応する同期IRビデオフレームは、関心のある顔領域のより効率的な温度推定を可能にします。 
[ABSTRACT]これにより、正面を含むビデオフレームを選択できます-顔認識と顔温度読み取りのための頭のポーズ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Task Curriculum Framework for Open-Set Semi-Supervised Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_55.html">
      <font color="black">Multi-Task Curriculum Framework for Open-Set Semi-Supervised Learning</font>
    </a>
  </h2>
  <font color="black">私たちはいくつかの実験を行い、この方法はOODサンプルの影響をうまく排除することで最先端の結果を達成しています。同時に、分布（ID）データの分類で高いパフォーマンスを達成するために、 OODスコアが小さいラベルなしデータ、およびこれらのデータをラベル付きデータとともに使用して、ディープニューラルネットワークをトレーニングし、半教師付き方法でIDサンプルを分類します。ネットワークパラメータとOODスコアを交互に更新する共同最適化フレームワークを使用します。 
[ABSTRACT] open-set sslは、ラベル付けされていないデータに分布外（ood）サンプルが含まれる場所です。代わりに、oodに属するサンプルの確率を推定します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Learnable Descent Algorithm for Nonsmooth Nonconvex Image Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_56.html">
      <font color="black">Learnable Descent Algorithm for Nonsmooth Nonconvex Image Reconstruction</font>
    </a>
  </h2>
  <font color="black">Nesterovの平滑化手法と残差学習のアイデアを活用して非平滑非凸最小化問題を解決する証明可能な収束降下型アルゴリズムを開発し、アルゴリズムの出力がトレーニングデータの参照と一致するようにネットワークパラメーターを学習します。また、提案されたネットワークはパラメーター効率が良く、そのパフォーマンスは実際にさまざまな画像再構成問題で最先端の方法に匹敵することを示しています。正則化関数を$ l_ {2の構成としてモデル化します。 、1} $ノルムと、滑らかであるが凸でないフィーチャマッピングは、深い畳み込みニューラルネットワークとしてパラメーター化されています。 
[要旨]正則化関数を$ l12-$ノルムと滑らかであるが非凸の特徴マッピングパラメーターの構成としてモデル化します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Interpretable Foreground Object Search As Knowledge Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_57.html">
      <font color="black">Interpretable Foreground Object Search As Knowledge Distillation</font>
    </a>
  </h2>
  <font color="black">広範な実験結果もさまざまな側面からその有効性を示しています。クエリ機能の表現は交換可能な前景と同じ潜在空間に投影され、非常に効率的で解釈可能なインスタンスレベルの検索を可能にします。次に、以下のトレーニングとテストのためのベンチマークデータセットを確立します。パイプライン。 
[ABSTRACT] fosは、特定のカテゴリの前景を取得して、後で画像を合成します。各パターン内の例は、任意の質問入力と互換性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-20">
        <br><font color="black">2020-07-20</font>
      </time>
    </span>
</section>
<!-- paper0: Feature based Sequential Classifier with Attention Mechanism -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_58.html">
      <font color="black">Feature based Sequential Classifier with Attention Mechanism</font>
    </a>
  </h2>
  <font color="black">子宮頸がんは、世界的に女性に影響を与える最も致命的ながんの1つです。子宮頸部疾患は、通常、上皮の下部（基底膜）から上部に進行すると理解されています。前悪性の正常から増加するグレードまでのグレード：CIN1、CIN2、CIN3。 
[ABSTRACT]子宮頸部生検スライドの組織病理学的検査を使用した子宮頸部上皮内腫瘍（cin）の評価は、観察者間のばらつきの影響を受けます。プレグナン（マリシー）は、通常、上皮の下部（基底膜）から上部に進行すると理解されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Spatial Attention Pyramid Network for Unsupervised Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_59.html">
      <font color="black">Spatial Attention Pyramid Network for Unsupervised Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">オブジェクト検出、インスタンスセグメンテーション、およびセマンティックセグメンテーションでの教師なしドメイン適応のために、さまざまな挑戦的なデータセットに対して広範な実験を行います。これは、このメソッドが最新のメソッドに対して大きなマージンで有利に機能することを示しています。固有の情報、密集したグローバル構造表現と空間的注意メカニズムを効果的に使用して各空間位置でのローカルテクスチャパターンを組み合わせます。ソースコードはhttps://isrc.iscas.ac.cn/gitlab/research/domainで入手できます。 -適応。 
[ABSTRACT]以前のほとんどの方法は、ソースドメインとターゲットドメインの単一の検出に依存して、それらを敵対的な学習に合わせて調整し、さまざまなシナリオで劣った結果をもたらしています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-29">
        <br><font color="black">2020-03-29</font>
      </time>
    </span>
</section>
<!-- paper0: Watchlist Risk Assessment using Multiparametric Cost and Relative
  Entropy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_60.html">
      <font color="black">Watchlist Risk Assessment using Multiparametric Cost and Relative
  Entropy</font>
    </a>
  </h2>
  <font color="black">さまざまなウォッチリストスクリーニングシナリオと制約の下での誤認となりすましの影響を実験的に実証します。このペーパーでは、リスク検出器が脅威の早期検出と攻撃の回避に必須のメカニズムである顔の生体認証対応ウォッチリストテクノロジーについて説明します。罪のない旅行者..このペーパーの主な貢献は、生体認証対応のウォッチリストとサポートインフラストラクチャの設計と分析、およびe-borderのパフォーマンスへのなりすましの影響を測定するための新しい手法です。 
[ABSTRACT]旅行者向けのマルチパラメトリックコスト評価を提案します。旅行者向けのマルチパラメータウォッチリストメジャーを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-View Optimization of Local Feature Geometry -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_61.html">
      <font color="black">Multi-View Optimization of Local Feature Geometry</font>
    </a>
  </h2>
  <font color="black">最初に、仮の一致間の局所的な幾何学的変換を推定し、次に非線形最小二乗法に従って複数のビューでキーポイントの場所を共同で最適化します。私たちの方法は、手作りのローカル機能と学習したローカル機能の両方について、三角測量とカメラのローカリゼーションのパフォーマンスを一貫して向上させることを示しています。 
[ABSTRACT]ローカルな特徴検出への現在のアプローチは、大きなビューでのみ動作するため、キーポイントのローカライズ精度が本質的に制限されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br><font color="black">2020-03-18</font>
      </time>
    </span>
</section>
<!-- paper0: Optical Flow Distillation: Towards Efficient and Stable Video Style
  Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_62.html">
      <font color="black">Optical Flow Distillation: Towards Efficient and Stable Video Style
  Transfer</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、知識蒸留パラダイムを介して軽量のビデオスタイルの転送ネットワークを学習することを提案します。これら2つの教師ネットワーク間の出力の違いは、オプティカルフローによる改善を強調しており、オプティカルフローを採用して、対象の学生ネットワークを蒸留します。97％以上の推論を占めています。時間。 
[ABSTRACT]高-ランク蒸留損失は、ビデオビデオのランクを模倣することによって学生ネットワークのフローを安定させるために使用されます。このシステムは、結論の間にオプティカルフローをブーストするために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-10">
        <br><font color="black">2020-07-10</font>
      </time>
    </span>
</section>
<!-- paper0: Fragments-Expert: A Graphical User Interface MATLAB Toolbox for
  Classification of File Fragments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_63.html">
      <font color="black">Fragments-Expert: A Graphical User Interface MATLAB Toolbox for
  Classification of File Fragments</font>
    </a>
  </h2>
  <font color="black">さまざまなファイル形式のファイルフラグメントの分類は、ファイアウォール、侵入検知システム、アンチウイルス、Webコンテンツフィルタリング、デジタルフォレンジックなどのさまざまなアプリケーションで不可欠なタスクです。これらの機能は、7つのカテゴリの機械学習アルゴリズムで使用できます。さまざまなファイル形式間での分類のタスク..このホワイトペーパーでは、ファイルフラグメントを分類するためのグラフィカルユーザーインターフェイスのMATLABツールボックスであるFragments-Expertを紹介します。 
[ABSTRACT]火災のコミュニティには適切なソフトウェアツールがありません。マシンから抽出された22のカテゴリの機能をユーザーに提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Learning towards Minimum Hyperspherical Energy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_64.html">
      <font color="black">Learning towards Minimum Hyperspherical Energy</font>
    </a>
  </h2>
  <font color="black">この直感に照らして、冗長正則化問題をジェネリックエネルギー最小化に削減し、最小超球エネルギー（MHE）目標をニューラルネットワークのジェネリック正則化として提案します。最後に、MHE正則化のニューラルネットワークをいくつかの困難なタスクに適用します。また、MHEのいくつかの新しいバリアントを提案し、理論的な観点からいくつかの洞察を提供します。 
[要約]複雑な関数を適合させる能力は、汎化能力を損なう可能性があります。また、赤い汎化能力を損なう可能性のある相関性の高いニューロンにもつながります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-05-23">
        <br><font color="black">2018-05-23</font>
      </time>
    </span>
</section>
<!-- paper0: Depthwise Spatio-Temporal STFT Convolutional Neural Networks for Human
  Action Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_65.html">
      <font color="black">Depthwise Spatio-Temporal STFT Convolutional Neural Networks for Human
  Action Recognition</font>
    </a>
  </h2>
  <font color="black">一般に、最先端の方法と比較すると、パラメーターの使用量は3.5から4.5倍少なく、計算コストは1.5から1.8倍少なくなります。従来の3D畳み込みニューラルネットワーク（CNN）は、計算コストが高く、メモリ集約的で、過適合、そして最も重要なこととして、それらの機能学習機能を改善する必要があります。STFTブロックは、複数の低周波数ポイントでSTFTカーネルを使用して空間的および/または時間的にローカルなフーリエ情報をキャプチャする非トレーニング可能なたたみ込み層で構成されます。チャネル相関を学習するためのトレーニング可能な線形重みのセット。 
[要約]不満のある3Dたたみ込みブロックは、3Dたたみ込み層の代替として機能できる新しいクラスのたたみ込みブロックです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Sparse Voxel Fields -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_66.html">
      <font color="black">Neural Sparse Voxel Fields</font>
    </a>
  </h2>
  <font color="black">ポージングされたRGB画像のセットのみから、微分可能な光線マーチング操作で基礎となるボクセル構造を段階的に学習します。難しいステップが必要なため、古典的なコンピューターグラフィックステクニックを使用した現実世界のシーンの写実的な自由視点レンダリングは困難です。詳細な外観とジオメトリモデルをキャプチャする方法です。この手法は、推論時に最先端の（つまり、NeRF）よりも10倍以上高速でありながら、より高い品質の結果を実現します。 
[ABSTRACT]新しい研究は、シーン表現を学習することで有望な結果を示しています。これらは、3D監視なしで外観と外観の両方をエンコードしました。これらの表現から高解像度画像を合成するには、多くの場合、時間がかかる光線の行進が必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Camera On-boarding for Person Re-identification using Hypothesis
  Transfer Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_67.html">
      <font color="black">Camera On-boarding for Person Re-identification using Hypothesis
  Transfer Learning</font>
    </a>
  </h2>
  <font color="black">新しいカメラを追加している間、既存のネットワーク内のラベル付きデータがまだ利用可能であると仮定することにより、この問題に対処することを試みる個人の再識別で提案されたいくつかの最近の方法があります。データプライバシーの問題を軽減する再識別モデルを学習し、既存のネットワークからのソースカメラデータを使用せずに、ソースモデルと限られたラベル付きデータのみを使用して知識を転送することを目的とした仮説伝達学習を使用した効率的なモデル適応アプローチを開発します..人の再識別のための既存のアプローチのほとんどは、ネットワーク内のカメラの数が固定されている静的な設定を考慮しています。 
[ABSTRACT]新しい方法は、カメラネットワークの動的な性質を調査することです。データにアクセスできないプライバシーの問題がある可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: FedOCR: Communication-Efficient Federated Learning for Scene Text
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_68.html">
      <font color="black">FedOCR: Communication-Efficient Federated Learning for Scene Text
  Recognition</font>
    </a>
  </h2>
  <font color="black">ただし、実際には、プライバシーの制限のため、一元化して共有できないさまざまなローカルデバイスにデータを配布する場合があります。そのため、FedOCRという名前を付けています。分散データセットのシミュレーションでは、提案されたFedOCRがモデルに対して競争力のある結果を達成していることが示されています。集中化されたデータでトレーニングされ、通信コストが少なく、プライバシー保護のレベルが高くなります。 
[ABSTRACT]ほとんどの既存のアルゴリズムは、共有またはハングしたトレーニングデータのセットを想定しています。これは、シーンテキスト認識機能のトレーニングに使用されるデータセットに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Deep-VFX: Deep Action Recognition Driven VFX for Short Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_69.html">
      <font color="black">Deep-VFX: Deep Action Recognition Driven VFX for Short Video</font>
    </a>
  </h2>
  <font color="black">このペーパーは、従来のテンプレートマッチングではなく、モーションドリブンによってVFX合成を変更することを目的としています。ただし、完璧なものを合成するには、ユーザーは新しいテンプレートのタイミングとリズムを把握するための面倒な試みを行う必要があります。簡単ではありません。特にモバイルアプリで使用します。 
[ABSTRACT] short-フォームモバイルビデオは、tik tokなど、世界中で非常に人気があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: PointContrast: Unsupervised Pre-training for 3D Point Cloud
  Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_70.html">
      <font color="black">PointContrast: Unsupervised Pre-training for 3D Point Cloud
  Understanding</font>
    </a>
  </h2>
  <font color="black">しかし、3D点群の理解におけるその有用性についてはほとんど知られていません。以前の作品とは異なり、高度なシーン理解タスクに焦点を当てています。この作品では、3D表現学習の研究を促進することを目指しています。 
[ABSTRACT]豊富なソースセット（例：imagenet）でネットワークを事前トレーニングすると、通常ははるかに小さいターゲットセットで微調整すると、パフォーマンスが向上することがわかります。これは、データに注釈を付けるために必要な作業を検討する機会です。 3D</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-21">
        <br><font color="black">2020-07-21</font>
      </time>
    </span>
</section>
<!-- paper0: Combining Implicit Function Learning and Parametric Models for 3D Human
  Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_71.html">
      <font color="black">Combining Implicit Function Learning and Parametric Models for 3D Human
  Reconstruction</font>
    </a>
  </h2>
  <font color="black">全身データとハンドスキャンの両方を使用した定量的および定性的実験では、提案された方法が一般化し、単一ビューの深度画像から収集された不完全な点群であっても効果的であることを示しています。その後、対応関係を使用して身体モデルを内側に適合させます表面、次にそれを（パラメトリックボディ+変位モデルの下で）外表面に非剛体的に変形して、衣服、顔、髪のディテールをキャプチャします。服を着た人の表面でサンプリングされた疎な3D点群を考えると、 Implicit Part Network（IP-Net）は、服を着た人の外側の3D表面、内側と内側の体表面、およびパラメトリックボディモデルへのセマンティック対応を共同で予測します。 
[ABSTRACT]モデルは、そのポーズまたはシェイプのパラメーターを編集することによってのみ操作できます。モデルとコードは、数か月以内にダウンロードできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Dense Residual Network: Enhancing Global Dense Feature Flow for
  Character Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CV/paper_72.html">
      <font color="black">Dense Residual Network: Enhancing Global Dense Feature Flow for
  Character Recognition</font>
    </a>
  </h2>
  <font color="black">FDRNを構築するために、ローカルフィーチャフュージョンと元のRDBのローカル残差学習の機能を保持する新しい高速残差密ブロック（f-RDB）を提案します。これにより、同時に計算の労力を削減できます。最後に、2つの畳み込み層を使用して、ダウンサンプリングブロックを構築し、グローバル機能のサイズを減らし、より深い機能を抽出します。ローカル残差密特徴を完全に学習した後、合計操作といくつかのf-RDBを使用して、グローバル密ブロック（GDB）と呼ばれる新しいブロックを定義します。 ）全体的な方法で適応的にグローバルな密な残差特徴を学習するために密なブロックの構築を模倣することによって。 
[ABSTRACT]これは、多くのネットワークが畳み込み層を単純にスタックするのは初めてです。これは、ローカルおよびグローバルの機能情報を検出しないためです。さらに、テキストコンピューティング用の効率的で効果的なcnnフレームワークを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-23">
        <br><font color="black">2020-01-23</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Exploratory Search with Sentence Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CL/paper_0.html">
      <font color="black">Exploratory Search with Sentence Embeddings</font>
    </a>
  </h2>
  <font color="black">次に、この性質の探索的検索システムの動機付けのユースケースについて説明し、将来の作業の可能な方向で締めくくります。文の埋め込みでは、ドキュメントを埋め込み文の平均として表し、このドキュメント表現に近い文を含む要約を抽出して抽出します。ドキュメント表現に近いキーフレーズ。検索システムを評価するために、過去1年間の個人の検索履歴をこすり取り、システムでの経験を報告します。 
[要約]文の埋め込みを使用した探索的検索システムの説明を提案します。文ネットワークを使用したソーシャルネットワークとドキュメントの要約に基づくシステムを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: To Be or Not To Be a Verbal Multiword Expression: A Quest for
  Discriminating Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CL/paper_1.html">
      <font color="black">To Be or Not To Be a Verbal Multiword Expression: A Quest for
  Discriminating Features</font>
    </a>
  </h2>
  <font color="black">驚くべきことに、単純なカスタム周波数ベースの特徴選択方法は、カイ二乗検定、情報ゲイン、決定木などの他の標準的な方法よりも効率的です。6つの特徴のみの最適なセットを使用するSVM分類器は、最近の最高のシステムよりも優れています。この事実を使用して、監視された分類設定でVMWE識別の副問題（以前に見られたVMWEの発生の識別）を解決するために使用できる最適な機能セットを決定します。 
[要旨] 6つの機能のみの最適なセットを使用したsvm分類子は、フランスのデータデータデータで最近共有されたタスクから最高のシステムよりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Massive Multi-Document Summarization of Product Reviews with Weak
  Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CL/paper_2.html">
      <font color="black">Massive Multi-Document Summarization of Product Reviews with Weak
  Supervision</font>
    </a>
  </h2>
  <font color="black">製品レビューの要約に関する以前の作業では、主に大規模なドキュメントセットを処理することが困難であるため、レビューの小さいサンプルを検討しました。小さいサンプルを要約すると、重要な情報が失われ、誤解を招く評価結果が得られる可能性があることを示しています。標準の要約アルゴリズムに加えて、大量のレビューを要約します。 
[要約]「大規模な複数ドキュメントの要約」という用語は、数百以上のドキュメントを含むタスクを指します。少量のサンプルを量化すると、重要な情報が失われ、誤解を招く評価結果が得られる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Answering Questions about Data Visualizations using Efficient Bimodal
  Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CL/paper_3.html">
      <font color="black">Answering Questions about Data Visualizations using Efficient Bimodal
  Fusion</font>
    </a>
  </h2>
  <font color="black">PReFILは単純ですが、FigureQAとDVQAの両方のデータセットで最先端のシステムと人間のベースラインを大幅に上回っています。CQAには、自然画像VQAアルゴリズムにはない機能が必要です。質問と回答の両方の語彙の単語。PReFILは、最初に質問と画像の特徴を融合してバイモーダル埋め込みを学習し、次に、これらの学習した埋め込みをインテリジェントに集約して、所定の質問に答えます。 
[ABSTRACT] prefilは、グラフに関する一連の質問をすることでテーブルを再構築するために使用できます。prefilは、最初に、質問と画像の機能を融合することにより、バイモーダル埋め込みを学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-05">
        <br><font color="black">2019-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: IITK at the FinSim Task: Hypernym Detection in Financial Domain via
  Context-Free and Contextualized Word Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CL/paper_4.html">
      <font color="black">IITK at the FinSim Task: Hypernym Detection in Financial Domain via
  Context-Free and Contextualized Word Embeddings</font>
    </a>
  </h2>
  <font color="black">2番目のサブセットでは、埋め込みに加えて、単純ベイブのような単純な教師付き分類子を使用して、最終的な予測に到達します。分析では、コンテキスト依存およびコンテキスト非依存の両方の単語埋め込みを利用します。1つのサブセットでは、教師なし距離測定を使用して用語を分類します。 
[ABSTRACT]このタスクの目的は、金銭的条件を分類することです。1つのサブセットについて、ゼロからトレーニングされたword2vec埋め込みをデプロイします。監視されていない距離測定を使用して、条件を分類します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: When Classical Chinese Meets Machine Learning: Explaining the Relative
  Performances of Word and Sentence Segmentation Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CL/paper_5.html">
      <font color="black">When Classical Chinese Meets Machine Learning: Explaining the Relative
  Performances of Word and Sentence Segmentation Tasks</font>
    </a>
  </h2>
  <font color="black">トレーニングコーパス間の相対的な関連性は、分類子をトレーニングするためにコーパスのさまざまな組み合わせを使用したときに達成されたセグメンテーション結果で観察された違いのヒント/説明を提供します。実験では、中国の唐王朝に関する3つの主要なテキストソースを検討します。古典的な中国語で書かれたテキストをセグメント化することを目的としています。さらに興味深いことに、さまざまな実験計画の中で観察された相対的な優位性の一部は説明可能である可能性があることがわかりました。 
[ABSTRACT]実験では、相対的な利点のいくつかを説明できる可能性があることがわかりました。実験には、唐の墓の伝記、新しい唐の本、古い唐の本のコレクションが含まれていました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Coinduction Plain and Simple -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CL/paper_6.html">
      <font color="black">Coinduction Plain and Simple</font>
    </a>
  </h2>
  <font color="black">この記事では、最初に宣言型プログラミングでのコインダクションについて概説します。次に、コデータを指定するために一般的に使用される形式をレビューし、少し拡張します。 
[ABSTRACT]この記事では、最初にcodismのcoinductionを確認します。通常、coinductionの証明原理の使用を確認します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-20">
        <br><font color="black">2020-07-20</font>
      </time>
    </span>
</section>
<!-- paper0: SemEval-2020 Task 1: Unsupervised Lexical Semantic Change Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CL/paper_7.html">
      <font color="black">SemEval-2020 Task 1: Unsupervised Lexical Semantic Change Detection</font>
    </a>
  </h2>
  <font color="black">33のチームが186のシステムを提出し、2つのサブタスクで評価されました。私たちは、研究者に評価フレームワークと、英語、ドイツ語、ラテン語、およびスウェーデン語..評価は、字句の意味の変化の検出において現在最も差し迫った問題です。コミュニティが利用できるゴールドスタンダードがないため、進歩が妨げられているためです。 
[要旨] 33人の研究者が186のタスクシステムを提出し、2つのサブタスクで評価されました。コミュニティが利用できるゴールドスタンダードがないため、進捗が妨げられています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Text-Based Ideal Points -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CL/paper_8.html">
      <font color="black">Text-Based Ideal Points</font>
    </a>
  </h2>
  <font color="black">モデルは投票または所属政党を分析しませんが、TBIPは議員を党ごとに分離し、解釈可能な政治トピックを学習し、古典的な投票ベースの理想的なポイントに近い理想的なポイントを推測します。投票とは対照的に、テキストを分析することの1つの利点は、 TBIPは、投票権のない俳優を含む、政治テキストを作成する人の理想的なポイントを推定できるということです。私たちは、2種類の政治化テキストデータを使用してTBIPを実証します。 
[ABSTRACT]テキストベースの理想点モデル（tbip）は、教師なしトピックモデルです。テキストを分析して、著者の政治的立場を定量化します。このモデルは、投票や所属政党を分析しません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-08">
        <br><font color="black">2020-05-08</font>
      </time>
    </span>
</section>
<!-- paper0: Dataset for Automatic Summarization of Russian News -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CL/paper_9.html">
      <font color="black">Dataset for Automatic Summarization of Russian News</font>
    </a>
  </h2>
  <font color="black">ただし、これはロシア語には当てはまりません。データセットがロシア語のテキスト要約のメソッドに対して有効なタスクであることを示します。さらに、事前訓練されたmBARTモデルがロシア語のテキスト要約に役立つことを証明します。 
[ABSTRACT]これはロシア語には当てはまりません。このデータセットのプロパティを説明します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-19">
        <br><font color="black">2020-06-19</font>
      </time>
    </span>
</section>
<!-- paper0: Cooking Is All About People: Comment Classification On Cookery Channels
  Using BERT and Classification Models (Malayalam-English Mix-Code) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CL/paper_10.html">
      <font color="black">Cooking Is All About People: Comment Classification On Cookery Channels
  Using BERT and Classification Models (Malayalam-English Mix-Code)</font>
    </a>
  </h2>
  <font color="black">この作業では、英語とマラヤーラム語のさまざまな組み合わせ（英語のみ、マラヤーラム語のみと英語とマラヤーラム語の混合）であるコメントを分類するための最高の分類モデルを評価しました。これは、コメントが多言語である場合の大きな課題です多くの場合、メッセージはそれぞれの固有語で溢れています。用語周波数ベクトライザーを備えたランダムフォレストは、63.59の精度を持つすべての従来の分類モデルの中で最高のパフォーマンスのモデルでした。 
[ABSTRACT]この一連の作業はgoogleによってコンパイルされ、google.itはコメントを分類するための最高のパフォーマンスの分類モデルを評価しました。これらは英語とベネチアン（英語のみ、インドのみ）のさまざまな組み合わせの混合です。結果が比較されます従来の機械学習手法に</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
</section>
<!-- paper0: Better Early than Late: Fusing Topics with Word Embeddings for Neural
  Question Paraphrase Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CL/paper_11.html">
      <font color="black">Better Early than Late: Fusing Topics with Word Embeddings for Neural
  Question Paraphrase Identification</font>
    </a>
  </h2>
  <font color="black">質問の言い換えの識別は、コミュニティの質問応答（CQA）で重要なタスクであり、着信する質問が以前に尋ねられたかどうかを判断します。質問の言い換えの識別..私たちの結果は、システムが複数のCQAデータセットの神経ベースラインよりも優れていることを示しています。一方、アブレーション研究は、トピックの重要性と、特にアーキテクチャの初期のトピック埋め込み融合を強調しています。 
[要約]当社のシステムは、複数のcqaデータセットの神経ベースラインを上回っています。アブレーション研究では、アーキテクチャにトピックを埋め込む融合の重要性を強調しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-Supervised Learning Approach to Discover Enterprise User Insights
  from Feedback and Support -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CL/paper_12.html">
      <font color="black">Semi-Supervised Learning Approach to Discover Enterprise User Insights
  from Feedback and Support</font>
    </a>
  </h2>
  <font color="black">2 ..従来の教師なし学習ベースのトピックモデルまたはクラスタリング手法では、意味のあるトピックラベルを自動的に生成することが難しいという問題がありますが、このシステムでは、Webを介して製品に関するドメイン知識を活用することにより、上位の単語を自助問題にマッピングできます。方法論と技術的な観点から、我々は転移学習を採用してBERTベースのマルチ分類システムを微調整し、メイントピックを分類してから、新しいPSHTIモデルを利用して予測されたメイントピックの下のサブトピックを推測します。 
[要約]システムは、教師あり学習によるbertベースの多分類アルゴリズムと、教師なし学習による新しい確率的および意味論的ハイブリッドトピック可能性（pshti）モデルを組み合わせたものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-18">
        <br><font color="black">2020-07-18</font>
      </time>
    </span>
</section>
<!-- paper0: Predicting job-hopping likelihood using answers to open-ended interview
  questions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CL/paper_13.html">
      <font color="black">Predicting job-hopping likelihood using answers to open-ended interview
  questions</font>
    </a>
  </h2>
  <font color="black">一方、純粋に履歴書に基づいてホッパーとして出会う経験豊富な候補者は、そうでないことを示す機会を得ます。特に、事前に候補者がいない候補者を評価する場合、候補者が就職する可能性を客観的に推測できることは、大きな機会をもたらします。職歴.. 45,000人を超える求職者からの回答を使用して、オンラインチャットインタビューを完了し、求人の動機スケールで自己評価し、2つの間の相関関係を分析しました。 
[要旨]自発的離職の大部分はジョブホップに関連しています。これには、インタビューの質問に回答するために使用される言語であるジョブホッピングが含まれます。これらには、4つのオープンボキャブラリーアプローチ、tf-idf、lda、グローブワードの埋め込み、およびdoc2vecドキュメントが含まれます埋め込み</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: An Accurate Model for Predicting the (Graded) Effect of Context in Word
  Similarity Based on Bert -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/cs.CL/paper_14.html">
      <font color="black">An Accurate Model for Predicting the (Graded) Effect of Context in Word
  Similarity Based on Bert</font>
    </a>
  </h2>
  <font color="black">私たちの論文では主に、文脈が類似の単語の人間の知覚に与える影響を分析する方法論について説明します。これは、SemEval 2020の3番目のタスクです。私たちのチームwill_goは、サブタスク1のフィンランド語トラックで1位、英語トラックで2位を獲得しました。サブタスク1の。トランスフォーマー（BERT）からの双方向エンコーダー表現によって生成された2つの埋め込みベクトル間の距離を計算する際に、いくつかの方法を適用します。 
[ABSTRACT]私たちのチームは `フィンランドで1位、英語で2位を獲得します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-03">
        <br><font color="black">2020-05-03</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Resource-Efficient Speech Mask Estimation for Multi-Channel Speech
  Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.AS/paper_0.html">
      <font color="black">Resource-Efficient Speech Mask Estimation for Multi-Channel Speech
  Enhancement</font>
    </a>
  </h2>
  <font color="black">このスピーチマスクは、最小分散歪みのない応答（MVDR）または一般化固有値（GEV）ビームフォーマーを取得するために使用されます。機械学習技術は伝統的にリソース集約型ですが、現在、ハードウェアとエネルギー効率の高いアプローチへの関心が高まっています。バイナリウェイトの極端なケースと精度のアクティブ化の低下、実行時間とメモリフットプリントの大幅な削減が可能でありながら、ほぼ同じ精度のDNNと同等のオーディオ品質と、単一スピーカーのシナリオのわずかに大きなワードエラーレート（WER）を実現WSJ0音声コーパスを使用します。 
[ABSTRACT]リソース効率の高い機械学習の必要性は、主にマルチチャネルマイクの需要によってもたらされます。特に、ノイズの多いマルチチャネルマイク観測に基づいて音声マスクを推定するために、精度の低いdnnsを使用します。大幅な削減実行時間とメモリフットプリントの可能性</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Rethinking CNN Models for Audio Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.AS/paper_1.html">
      <font color="black">Rethinking CNN Models for Audio Classification</font>
    </a>
  </h2>
  <font color="black">さらに、初期化に事前トレーニング済みのモデルの重みを使用しても、同じモデルのさまざまな出力実行でパフォーマンスにばらつきがあることを示します。これにより、大幅な多様性がもたらされ、全体的な精度が向上したより強力なアンサンブルモデルが構築されます。 ImageNetの事前トレーニング済みモデルが有用な音声表現を学習できるようにするために、スペクトログラムの学習に事前トレーニング済みの重みがどれだけ役立つかを体系的に調査します。 
[ABSTRACT]事前トレーニング済みの重みを使用する特定の標準モデルの場合、ランダムに初期化された重みを使用するよりも優れていることを示します。これは、事前トレーニング済みモデル、事前学習済みモデルなどが原因で、ランダム初期化済み重みを使用するよりも標準モデルの方が優れているためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: A Transfer Learning End-to-End ArabicText-To-Speech (TTS) Deep
  Architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-23/eess.AS/paper_2.html">
      <font color="black">A Transfer Learning End-to-End ArabicText-To-Speech (TTS) Deep
  Architecture</font>
    </a>
  </h2>
  <font color="black">音声合成は、人間の音声を人工的に生成するものです。この作品では、エンドツーエンドのニューラルディープネットワークアーキテクチャを使用して、高品質で自然な人間のようなアラビア語の音声を生成する方法について説明します。ただし、多くの面倒な作業が必要でしたとドメインの専門知識。 
[ABSTRACT]ナチュラルナチュラルナチュラル、人間のようなアラビア語のスピーチは、スピーチの形式です。高度な高度なシステムを使用して波形を作成します。英語の文字埋め込みの使用方法を説明します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
