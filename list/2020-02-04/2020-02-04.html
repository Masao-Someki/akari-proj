<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-02-04の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../..//index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<div class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</div>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Within-sample variability-invariant loss for robust speaker recognition
  under noisy environments -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.SD/paper_0.html">
      Within-sample variability-invariant loss for robust speaker recognition
  under noisy environments
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      VoxCeleb1の実験は、提案されたトレーニングフレームワークがクリーンな環境とノイズの多い環境の両方で話者検証システムのパフォーマンスを改善することを示しています。さらに、オンザフライでクリーンでノイズのある発話ペアを生成するためのデータ準備戦略を調査します。ディープニューラルネットワークによってスピーカーの認識が改善され、ノイズの多い環境でも不十分なパフォーマンスが持続します。 
[要旨]論文では、「きれいな」埋め込みを学習するために話者埋め込みネットワークをトレーニングします。この戦略は、各トレーニングステップで同じクリーンな発声に対して異なるノイズの多いコピーを生成します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Delving into VoxCeleb: environment invariant speaker recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.SD/paper_1.html">
      Delving into VoxCeleb: environment invariant speaker recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      タスクに適したより強力なアーキテクチャや損失関数を求めて多くの研究が行われていますが、これらの研究では、与えられたラベルを予測できることを除いて、モデルが学習する情報は考慮しません。 VoxCelebデータセット内の以前に使用されていない「ビデオ」情報を利用します。環境の敵対的トレーニングにより、ネットワークは目に見えない条件により良く一般化できます。 
[要約]システムは、voxcelebデータセットを使用して、話者の識別と検証の両方のタスクで評価されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Time Difference of Arrival Estimation from Frequency-Sliding Generalized
  Cross-Correlations Using Convolutional Neural Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.SD/paper_2.html">
      Time Difference of Arrival Estimation from Frequency-Sliding Generalized
  Cross-Correlations Using Convolutional Neural Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、周波数スライディングGCC（FS-GCC）は、クロスパワースペクトル位相のサブバンド解析に基づいたTDEの新しい手法として提案され、異なる領域に含まれる時間遅延情報の構造化された2次元表現を提供します。周波数帯域..深層学習ベースの画像ノイズ除去ソリューションに触発され、本論文では、不利な音響条件で抽出されたFS-GCCに含まれる時間遅延パターンを学習するために、畳み込みニューラルネットワーク（CNN）の使用を提案します。従来の信号処理タスクを解決するためのディープラーニングメソッドは、ここ数年着実に成長しています。 
[ABSTRACT]不利な設定での時間遅延推定（tde）は挑戦です。gccに基づくサブ耐性アプローチは何十年も広く使用されてきました。 in fs-悪い音響条件で抽出されたgcc
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Tensor-to-Vector Regression for Multi-channel Speech Enhancement based
  on Tensor-Train Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.SD/paper_3.html">
      Tensor-to-Vector Regression for Multi-channel Speech Enhancement based
  on Tensor-Train Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、TTNがDNNに匹敵する音声強調品質を達成できるが、パラメーターがはるかに少ないことを示します。たとえば、単一チャネルのシナリオでは、2700万から500万のパラメーターに減少します。入力サイズの爆発と隠れ層のサイズ拡大の問題に対処するためのマルチチャネル音声強調へのベクトル回帰アプローチ。最初に、DNNからTTNベースの回帰への理論的拡張を提供します。 
[要旨]重要な考え方は、従来のディープニューラルネットワーク（dnn）ベースの負債をキャストすることです。代わりに、ttnはdnnの表現力を維持しますが、トレーニング可能なモデルの量ははるかに少なくなります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving sequence-to-sequence speech recognition training with
  on-the-fly data augmentation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.SD/paper_4.html">
      Improving sequence-to-sequence speech recognition training with
  on-the-fly data augmentation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      データ増強方法の1つは文献から得られますが、他の2つの方法は私たち自身の開発です-周波数領域での時間摂動とサブシーケンスサンプリングです。自動音声認識（ASR）の最新のパフォーマンス。これらの大規模で深いモデルのオーバーフィッティングは最大の問題であり、より優れたアーキテクチャから得られるパフォーマンスの改善を上回っています。 
[要約]オーバーフィッティングは、より優れたアーキテクチャから得られるパフォーマンスの改善を上回っています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-29">
        <br>2019-10-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Regularized Fast Multichannel Nonnegative Matrix Factorization with
  ILRMA-based Prior Distribution of Joint-Diagonalization Process -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.SD/paper_5.html">
      Regularized Fast Multichannel Nonnegative Matrix Factorization with
  ILRMA-based Prior Distribution of Joint-Diagonalization Process
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、この事実に動機付けて、ILRMAでサポートされる新しい正規化FastMNMFを提案し、収束保証されたパラメーター更新ルールを導出します。これらの問題を解決するために、まず、ジョイント対角化プロセスと低ランクマトリックス分析（ILRMA）..本論文では、畳み込みブラインドソース分離（BSS）問題に対処し、空間共分散マトリックスモデルの対角化の事前情報を導入することにより、FastMNMFの新しい拡張フレームワークを提案します。 
[要約] fastmnmfは、マルチチャネル非負行列因子分解の高速バージョンとして提案されていますが、新しい方法は、ほぼ同じ時間で精度を制限することにより、従来のfastmnmfよりも優れています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Modeling ASR Ambiguity for Dialogue State Tracking Using Word Confusion
  Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.SD/paper_6.html">
      Modeling ASR Ambiguity for Dialogue State Tracking Using Word Confusion
  Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーでは、最先端のニューラルダイアログステートトラッカー（DST）を使用して混乱ネットワークを使用する利点を研究します。当社のconfnetエンコーダーは、最先端の「Global-locally Self- DSTのAttentionive Dialogue State Tacker（GLAD）モデルは、上位N ASR仮説を使用する場合と比較して、精度と推論時間の両方で大幅な改善を実現します。任意のDSTシステムで使用できるネットワークエンコーダー。 
[概要] asrシステムはどのdst systemでも使用できます。対話システムに使用されますが、top-n asrリストよりも豊富な仮説空間のコンパクトな表現があります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: End-to-End Automatic Speech Recognition Integrated With CTC-Based Voice
  Activity Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.SD/paper_7.html">
      End-to-End Automatic Speech Recognition Integrated With CTC-Based Voice
  Activity Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      単純なしきい値処理で音声セグメントを検出するためのキューとしてラベルを使用します。セグメント化されていないデータの実験結果は、提案された方法が従来のエネルギーベースおよびニューラルネットワークベースのVADメソッドを使用してベースラインメソッドを上回り、RTF未満を達成したことを示します0.2 ..提案された方法は公開されています。 
[要約]この予測には、連続した長い空白予測が含まれます。しきい値は、非音声領域の長さに直接関係します。提案された方法は公開されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: CoTK: An Open-Source Toolkit for Fast Development and Fair Evaluation of
  Text Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.CL/paper_0.html">
      CoTK: An Open-Source Toolkit for Fast Development and Fair Evaluation of
  Text Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      特に異なる実験設定で、モデルの開発と評価にCoTKを使用するのが便利であることを示します。テキスト生成評価では、一貫性のない実験設定やメトリックの実装など、多くの実用的な問題はしばしば無視されますが、不公平な評価と受け入れ難いことにつながります結論..ユニークな機能として、CoTKはいつどのメトリックを公正に比較できないかを示すことができます。 
[要約]テキスト生成の高速開発と公正な実装をサポートすることを目的とした実験ツールキットcotkを紹介します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Torch-Struct: Deep Structured Prediction Library -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.CL/paper_1.html">
      Torch-Struct: Deep Structured Prediction Library
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Torch-Structは、https：//github.com/harvardnlp/pytorch-structで入手できます。内部には、クロスアルゴリズム効率を提供するための汎用的な最適化も多数含まれています。実験では、高速ベースラインとケーススタディは、ライブラリの利点を示しています。 
[ABSTRACT]ライブラリは、structuralructを使用して、シンプルなsystem.itを活用し、統合します。多くのアルゴリズムに基づいて、システムの洞察を提供します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning Contextualized Document Representations for Healthcare Answer
  Retrieval -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.CL/paper_2.html">
      Learning Contextualized Document Representations for Healthcare Answer
  Retrieval
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのアプローチは、フリーテキストと医療分類からのエンティティとアスペクトの構造化されたクエリタプルに基づいています。一般化されたモデルは、ヘルスケアパッセージランキングのいくつかの最先端のベースラインを大幅に上回り、追加の微調整なしで異種ドメインに適応することができます。 
[ABSTRACT]私たちのアプローチは、エンティティの構造化された検索タプルに基づいています。我々は、短い表現でクエリを解決するために連続表現を使用します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Phylogenetic signal in phonotactics -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.CL/paper_3.html">
      Phylogenetic signal in phonotactics
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      オーストラリアの言語は、高度な音韻均一性を持つと特徴づけられています。データは系統発生の歴史を反映しています。 
[ABSTRACT]たとえばバイナリデータを含む3つのデータセットをテストしますが、すべてのデータセットで進化シグナルを検出します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi Sense Embeddings from Topic Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.CL/paper_4.html">
      Multi Sense Embeddings from Topic Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      埋め込みを使用して、コンテキストと単語の類似性を強力にキャプチャし、さまざまな最新の実装よりも優れていることを示します。また、各トピックの単語の確率的表現によって決定された埋め込みを削除する方法を紹介します。 。この作業では、語彙意味論、つまりベクトル空間で多義語のさまざまな感覚を表現するというこの重要な問題に取り組みます。 
[概要]トピックモデリングベースのスキップグラムアプローチを提案します。複数のプロトタイプの単語の埋め込みを学習するために使用します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-17">
        <br>2019-09-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: How Far are We from Effective Context Modeling ? An Exploratory Study on
  Semantic Parsing in Context -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.CL/paper_5.html">
      How Far are We from Effective Context Modeling ? An Exploratory Study on
  Semantic Parsing in Context
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、潜在的な研究の方向性を明らかにする可能性のある代表的なモデルの詳細な分析で、最も頻繁な文脈現象を要約します。最近、文脈の意味解析はかなりの注目を集めています。 .. 2つの大きな複雑なクロスドメインデータセットで13のコンテキストモデリング手法を評価し、最適なモデルにより、両方のデータセットで最先端のパフォーマンスを大幅に改善して達成します。 
[概要] 2つの大きな複雑なクロスドメインデータセットで13のコンテキストモデリング手法を評価します。最良のモデルは、両方のデータセットで最先端のパフォーマンスを大幅に改善して達成します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Tensor-to-Vector Regression for Multi-channel Speech Enhancement based
  on Tensor-Train Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.CL/paper_6.html">
      Tensor-to-Vector Regression for Multi-channel Speech Enhancement based
  on Tensor-Train Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、TTNがDNNに匹敵する音声強調品質を達成できるが、パラメーターがはるかに少ないことを示します。たとえば、単一チャネルシナリオでは、2700万から500万に減少します。TTNは最近登場したソリューションです。完全に接続された隠れ層を備えた深いモデルのコンパクトな表現のために。さらに、TTNは設計により多次元テンソル入力を処理できます。これは、マルチチャネル音声強調の目的の設定に正確に一致します。 
[要旨]重要な考え方は、従来のディープニューラルネットワーク（dnn）ベースの負債をキャストすることです。代わりに、ttnはdnnの表現力を維持しますが、トレーニング可能なモデルの量ははるかに少なくなります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Talk2Nav: Long-Range Vision-and-Language Navigation with Dual Attention
  and Spatial Memory -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.CL/paper_7.html">
      Talk2Nav: Long-Range Vision-and-Language Navigation with Dual Attention
  and Spatial Memory
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      アノテーションタスクはAMTプラットフォームでクラウドソーシングされ、$ 10,714 $のルートを持つ新しいTalk2Navデータセットを構築しました。ナビゲーション指示の精神的な概念化では、セグメント化された言語指示を介して定義されたソフトデュアルアテンションメカニズムを導入して、2つの部分的な指示を共同で抽出します.1つは次の視覚的なランドマークに一致し、もう1つはローカル方向を次のランドマークに一致させます。 
[概要]ナビゲーションシステムはgoogleストリートビューに基づいています。言葉によるナビゲーション指示に基づいて視覚的なガイダンスを提供します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-04">
        <br>2019-10-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Question Generation with Sentence-level Semantic Matching and
  Answer Position Inferring -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.CL/paper_8.html">
      Improving Question Generation with Sentence-level Semantic Matching and
  Answer Position Inferring
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、これらのアプローチはしばしば間違った質問語またはキーワードを生成し、入力から回答に関係のない語をコピーすることを観察します。実験結果は、モデルがSQuADおよびMARCOデータセットの最先端（SOTA）モデルよりも優れていることを示しています。 。グローバルな質問セマンティクスの欠如と回答の位置認識の悪用が鍵となる根本原因であると考えています。 
[ABSTRACT]私たちのモデルは、チームとマルコのデータセットに関する最新のモデルよりも優れています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-02">
        <br>2019-12-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ALBERT: A Lite BERT for Self-supervised Learning of Language
  Representations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.CL/paper_9.html">
      ALBERT: A Lite BERT for Self-supervised Learning of Language
  Representations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      その結果、BERTラージに比べてパラメーターが少なく、GLUE、RACE、およびSQuADベンチマークで最高のモデルが新しい最先端の結果を確立します。コードと事前学習済みモデルはhttps：// githubで入手できます。 .com / google-research / ALBERT ..また、文間の一貫性のモデリングに焦点を当てた自己監視型の損失を使用し、それが一貫してマルチセンテンス入力を持つダウンストリームタスクに役立つことを示します。自然言語表現を事前トレーニングする場合のモデルサイズの増加ダウンストリームタスクのパフォーマンスが向上します。 
[ABSTRACT]研究により、提案された方法は、元のbertよりもはるかに優れたスケールのモデルにつながることが示されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-26">
        <br>2019-09-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Bertrand-DR: Improving Text-to-SQL using a Discriminative Re-ranker -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.CL/paper_10.html">
      Bertrand-DR: Improving Text-to-SQL using a Discriminative Re-ranker
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      スキーマにとらわれないBERT微調整分類子としてリランカを構築します。最近、いくつかの生成テキストからSQLへのモデルが開発されました。リランカを2つの状態に適用することにより、リランカの有効性を実証します。この記事の執筆時点で、Spiderリーダーボードでトップ4のスコアを達成します。 
[要約]テキスト-to ------------- in-resistanceモデルは、パフォーマンスを改善するために開発されています。彼らは、ユーザーのパフォーマンスを改善する新しいツールを提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Fact-aware Sentence Split and Rephrase with Permutation Invariant
  Training -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.CL/paper_11.html">
      Fact-aware Sentence Split and Rephrase with Permutation Invariant
  Training
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      課題を克服するために、まず、モデルが長い文から事実を学習することを可能にし、それにより文分割の精度を向上させる、事実認識文エンコーディングを提案します。次に、順列不変トレーニングを導入して、このタスクのseq2seq学習における順序分散の影響を軽減します。以前の研究では、入力として複雑な文を取得し、一連の単純な文章..さらに、oie-benchmarkの外部評価は、OpenIEのパフォーマンスを向上させるために、前処理として最新モデルを使用して長い文章を分割することが役立つという観察により、アプローチの有効性を検証します。 
[ABSTRACT]以前の研究では、seqは並列文のペアから学習します。入力として複雑な文を受け取り、一連の単純な文を生成します。結果は、トレーニング中にseq2seqモデルを混乱させる可能性があります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-16">
        <br>2020-01-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Modeling ASR Ambiguity for Dialogue State Tracking Using Word Confusion
  Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.CL/paper_12.html">
      Modeling ASR Ambiguity for Dialogue State Tracking Using Word Confusion
  Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      弊社のconfnetエンコーダーは、DSTの最新の「Global-locally Self-Attentive Dialogue State Tacker」（GLAD）モデルにプラグインされており、トップN ASR仮説の使用と比較して、精度と推論時間の両方で大幅な改善を実現しています。 。本論文では、最新のニューラルダイアログステートトラッカー（DST）を使用して混乱ネットワークを使用する利点を研究します。注意深い混乱を使用して、2次元のconfnetを1次元の埋め込みシーケンスにエンコードします。任意のDSTシステムで使用できるネットワークエンコーダー。 
[概要] asrシステムはどのdst systemでも使用できます。対話システムに使用されますが、top-n asrリストよりも豊富な仮説空間のコンパクトな表現があります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: End-to-End Automatic Speech Recognition Integrated With CTC-Based Voice
  Activity Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/cs.CL/paper_13.html">
      End-to-End Automatic Speech Recognition Integrated With CTC-Based Voice
  Activity Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      セグメント化されていないデータの実験結果は、提案された方法が従来のエネルギーベースおよびニューラルネットワークベースのVAD方法を使用してベースラインメソッドを上回り、0.2未満のRTFを達成したことを示します..提案された方法は公開されています。オンライン音声インターフェイスに向けたエンドツーエンドの自動音声認識と非常に長い音声記録の転写を備えたアクティビティ検出（VAD）機能。 
[要約]この予測には、連続した長い空白予測が含まれます。しきい値は、非音声領域の長さに直接関係します。提案された方法は公開されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Within-sample variability-invariant loss for robust speaker recognition
  under noisy environments -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/eess.AS/paper_0.html">
      Within-sample variability-invariant loss for robust speaker recognition
  under noisy environments
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      VoxCeleb1の実験は、提案されたトレーニングフレームワークが、クリーンな条件とノイズの多い条件の両方で話者検証システムのパフォーマンスを向上させることを示しています。ネットワークは、元の話者識別損失と、サンプル内の変動不変損失の補助で訓練されます。 
[要旨]論文では、「きれいな」埋め込みを学習するために話者埋め込みネットワークをトレーニングします。この戦略は、各トレーニングステップで同じクリーンな発声に対して異なるノイズの多いコピーを生成します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Delving into VoxCeleb: environment invariant speaker recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/eess.AS/paper_1.html">
      Delving into VoxCeleb: environment invariant speaker recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      話者認識の研究では、ニューラルネットワークモデルの適用と新しい大規模データセットの利用可能性により、最近大きな進展が見られました。タスクに適したより強力なアーキテクチャまたは損失関数を探しますが、これらの作業では、指定されたラベルを予測できることを除いて、モデルが学習する情報を考慮しません。 
[要約]システムは、voxcelebデータセットを使用して、話者の識別と検証の両方のタスクで評価されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Time Difference of Arrival Estimation from Frequency-Sliding Generalized
  Cross-Correlations Using Convolutional Neural Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/eess.AS/paper_2.html">
      Time Difference of Arrival Estimation from Frequency-Sliding Generalized
  Cross-Correlations Using Convolutional Neural Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、周波数スライディングGCC（FS-GCC）は、クロスパワースペクトル位相のサブバンド解析に基づいたTDEの新しい手法として提案され、異なる領域に含まれる時間遅延情報の構造化された2次元表現を提供します。周波数帯域..深層学習ベースの画像ノイズ除去ソリューションに触発され、本論文では、不利な音響条件で抽出されたFS-GCCに含まれる時間遅延パターンを学習するたたみ込みニューラルネットワーク（CNN）の使用を提案します。提案されたアプローチが優れたTDEパフォーマンスを提供し、異なる部屋とセンサーの設定に一般化できることを確認します。 
[ABSTRACT]不利な設定での時間遅延推定（tde）は挑戦です。gccに基づくサブ耐性アプローチは何十年も広く使用されてきました。 in fs-悪い音響条件で抽出されたgcc
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Tensor-to-Vector Regression for Multi-channel Speech Enhancement based
  on Tensor-Train Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/eess.AS/paper_3.html">
      Tensor-to-Vector Regression for Multi-channel Speech Enhancement based
  on Tensor-Train Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、TTNがDNNに匹敵する音声強調品質を達成できるが、パラメーターがはるかに少ないことを示します。たとえば、単一チャネルのシナリオでは、2700万から500万のパラメーターに減少します。設計による多次元テンソル入力。これは、マルチチャネル音声強調の目的の設定に正確に一致します。まず、DNNからTTNベースの回帰への理論的拡張を提供します。 
[要旨]重要な考え方は、従来のディープニューラルネットワーク（dnn）ベースの負債をキャストすることです。代わりに、ttnはdnnの表現力を維持しますが、トレーニング可能なモデルの量ははるかに少なくなります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving sequence-to-sequence speech recognition training with
  on-the-fly data augmentation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/eess.AS/paper_4.html">
      Improving sequence-to-sequence speech recognition training with
  on-the-fly data augmentation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      過剰適合問題の解決策の1つは、利用可能なトレーニングデータの量と、データ増強の助けを借りてトレーニングデータが示す多様性を増やすことです。スイッチボードとフィッシャーのデータに関する私たちの実験は、音声トレーニングデータのみでトレーニングされ、追加のテキストデータは使用されません。データ増強方法の1つは文献に由来しますが、他の2つの方法は、周波数領域の時間摂動とサブシーケンスサンプリングです。 
[要約]オーバーフィッティングは、より優れたアーキテクチャから得られるパフォーマンスの改善を上回っています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-29">
        <br>2019-10-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Regularized Fast Multichannel Nonnegative Matrix Factorization with
  ILRMA-based Prior Distribution of Joint-Diagonalization Process -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/eess.AS/paper_5.html">
      Regularized Fast Multichannel Nonnegative Matrix Factorization with
  ILRMA-based Prior Distribution of Joint-Diagonalization Process
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、この事実に動機付けて、ILRMAでサポートされる新しい正規化FastMNMFを提案し、収束保証パラメーター更新ルールを導き出します。最近、FastMNMFは、次の空間共分散行列複数のソースを共同で対角化することができます。BSS実験から、提案された方法が、ほぼ同じ計算時間で、ソース分離精度において従来のFastMNMFより優れていることを示します。 
[要約] fastmnmfは、マルチチャネル非負行列因子分解の高速バージョンとして提案されていますが、新しい方法は、ほぼ同じ時間で精度を制限することにより、従来のfastmnmfよりも優れています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Modeling ASR Ambiguity for Dialogue State Tracking Using Word Confusion
  Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/eess.AS/paper_6.html">
      Modeling ASR Ambiguity for Dialogue State Tracking Using Word Confusion
  Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      弊社のconfnetエンコーダーは、DSTの最新の「Global-locally Self-Attentive Dialogue State Tacker」（GLAD）モデルにプラグインされており、トップN ASR仮説の使用と比較して、精度と推論時間の両方で大幅な改善を実現しています。 。本論文では、最新のニューラルダイアログステートトラッカー（DST）を使用して混乱ネットワークを使用する利点を研究します。注意深い混乱を使用して、2次元のconfnetを1次元の埋め込みシーケンスにエンコードします。任意のDSTシステムで使用できるネットワークエンコーダー。 
[概要] asrシステムはどのdst systemでも使用できます。対話システムに使用されますが、top-n asrリストよりも豊富な仮説空間のコンパクトな表現があります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: End-to-End Automatic Speech Recognition Integrated With CTC-Based Voice
  Activity Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-04/eess.AS/paper_7.html">
      End-to-End Automatic Speech Recognition Integrated With CTC-Based Voice
  Activity Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この予測には、非音声領域と見なすことができる連続した長い空白ラベルが含まれます。単純なしきい値処理で音声セグメントを検出するためのキューとしてラベルを使用します。非セグメント化データの実験結果は、提案した方法がベースライン方法よりも優れていることを示しています従来のエネルギーベースおよびニューラルネットワークベースのVADメソッドを使用して、0.2未満のRTFを達成しました。 
[要約]この予測には、連続した長い空白予測が含まれます。しきい値は、非音声領域の長さに直接関係します。提案された方法は公開されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-03">
        <br>2020-02-03
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本日更新された論文はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br>
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
