<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<title>Akari-2019-11-22の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
  <div class="header-logo">
    <a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
  </div>
</header>
<input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">

<div class="menubar">
<span class="bar"></span>
<span class="bar"></span>
<span class="bar"></span>
</div>

<ul>
<li><a id="home" href="../../index.html">Home</a></li>
<li><a id="about" href="../../teamAkariとは.html">About</a></li>
<li><a id="contact" href="../../contact.html">Contact</a></li>
<li><a id="contact" href="../../list/newest.html">New Papers</a></li>
<li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
</ul>

</label>
<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Temporal Reasoning via Audio Question Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.SD/paper_0.html">
      Temporal Reasoning via Audio Question Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      DAQAがAQAと時間的推論の研究を促進し、MALiMoがAQAのモデルへのステップを促進することを想定しています。AQAタスクに答える視覚的な質問にいくつかの最新の方法を適応させ、詳細な時間的推論を必要とする質問では不十分です。最後に、最近のフィーチャーワイズ線形変調（FiLM）モデルを拡張し、その時間的推論機能を大幅に改善する新しいモデル、線形変調用多重補助コントローラー（MALiMo）を提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Opus Low Bit Rate Quality with Neural Speech Synthesis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.SD/paper_1.html">
      Improving Opus Low Bit Rate Quality with Neural Speech Synthesis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      リスニングテストにより、同じ6 kb / s Opusビットストリームに対して、LPCNetを使用した合成音声は、標準のOpusデコーダーの出力より明らかに優れていることがわかります。2つの異なる神経生成モデル、WaveNetとLPCNetを比較します。コーダーは、6 kb / s〜40 kb / sのビットレートで広帯域音声を圧縮できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-12">
        <br>2019-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: InverSynth: Deep Estimation of Synthesizer Parameter Configurations from
  Audio Signals -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.SD/paper_2.html">
      InverSynth: Deep Estimation of Synthesizer Parameter Configurations from
  Audio Signals
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、ネットワークの深さが予測精度に寄与する重要な要因であることを示します。本書では、InverSynth-シンセサイザーのパラメーターを自動調整して、特定の入力音に一致させる方法を紹介します。 4つの周波数変調オシレーター、エンベロープジェネレーター、ゲーターエフェクトを備えたサブトラクティブシンセサイザー。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-15">
        <br>2018-12-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Designing Virtual Soundscapes for Alzheimer's Disease Care -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.SD/paper_3.html">
      Designing Virtual Soundscapes for Alzheimer's Disease Care
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      プラウストのマドレーヌに関連してマドレーヌ・ソノレスと名付けられたこの装置は、専用のアルツハイマー病治療室で24時間年中無休でホストされている14人の高齢者に1年間響く仮想サウンドスケープを提供しました。認知症とケアの活動。.科学研究は、アルツハイマー病の治療とケアの認知症でそのような処分の利点を評価するために開始されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Prosody Transfer in Neural Text to Speech Using Global Pitch and
  Loudness Features -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.SD/paper_4.html">
      Prosody Transfer in Neural Text to Speech Using Global Pitch and
  Loudness Features
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      リスニングテストでは、合成音声は非常に自然であると評価され、韻律は基準音声信号から合成信号に正常に転送されることが示されています。主なアイデアは、ピッチやラウドネスの輪郭などのよく知られた韻律の音響相関を組み込むことです具体的には、Tacotron2（TC2）などの最新のニューラルテキスト読み上げ（TTS）シンセサイザーに参照音声を追加します。具体的には、参照オーディオから音響特性の小さなセットを抽出し、TC2シンセサイザーの調整に使用します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Conditioned-U-Net: Introducing a Control Mechanism in the U-Net for
  Multiple Source Separations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.SD/paper_5.html">
      Conditioned-U-Net: Introducing a Control Mechanism in the U-Net for
  Multiple Source Separations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CU-Netはさまざまな機器の分離を実行し、すべてが単一のモデルで低コストで専用モデルと同じパフォーマンスを実現します。さまざまなタスクを一度にトレーニングすると、通常、1つの専門的なタスクをトレーニングするよりもパフォーマンスが低下します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-02">
        <br>2019-07-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning Hierarchical Discrete Linguistic Units from Visually-Grounded
  Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.SD/paper_6.html">
      Learning Hierarchical Discrete Linguistic Units from Visually-Grounded
  Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、これらのユニットの耐ノイズ性を実証する実験も示します。これらの検出器は非常に正確で、F1スコアが0.5を超える279ワードを発見することを示します。ZeroSpeech2019チャレンジでサブワードユニットを評価し、ビットレートをほぼ同じに保ちながら、最高性能の送信よりもABXエラー率を27.3 \％削減。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Temporal Reasoning via Audio Question Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_0.html">
      Temporal Reasoning via Audio Question Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、機械学習モデルの時間的推論能力を研究するために音声質問応答（AQA）のタスクを使用します。AQAタスクに視覚的な質問応答のためのいくつかの最新の手法を採用し、使用しますDAQAは、詳細な時間的推論を必要とする質問に対してパフォーマンスが低いことを実証します。一時的な推論機能を改善します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ChartNet: Visual Reasoning over Statistical Charts using MAC-Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_1.html">
      ChartNet: Visual Reasoning over Statistical Charts using MAC-Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は、ChartNetがこれらの質問に対する推論において他の最先端の方法よりも常に優れていることを示しており、統計チャートの画像を含むアプリケーションの実行可能な候補である可能性があります..ネットワークChartNetを呼び出し、両方の語彙の予測におけるその有効性を実証しますこの目的のために、我々は、MAC-Networksを使用した分類タスクとして統計チャートを推論する問題を定式化して、一般的な回答の事前定義された語彙から回答を提供します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_2.html">
      Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      HAKEは、極座標系の同心円が階層を自然に反映できるという事実に触発されます。エンティティと関係を低次元のベクトル（または行列、テンソルなど）として表すことを目的とする知識グラフ埋め込み。ナレッジグラフでセマンティック階層を効果的にモデル化し、リンク予測タスクのベンチマークデータセットで既存の最先端の方法よりも大幅に優れています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Attention-Informed Mixed-Language Training for Zero-shot Cross-lingual
  Task-oriented Dialogue Systems -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_3.html">
      Attention-Informed Mixed-Language Training for Zero-shot Cross-lingual
  Task-oriented Dialogue Systems
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、非常に少ない単語ペアで、モデルは現在の状態と比較して、言語間の対話状態追跡と自然言語理解（つまり、意図検出とスロット充填）の両方のタスクで大幅なゼロショット適応パフォーマンスの改善を実現します。はるかに大量のバイリンガルデータを使用するアートアプローチ。高価で時間のかかるデータ収集を回避するために、クロスリンクの新しいゼロショット適応方法であるアテンションインフォームド混合言語トレーニング（MLT）を導入します。リンガルタスク指向の対話システム..単語ペアを手動で選択する代わりに、訓練された英語のタスク関連モデルのアテンションレイヤーによって計算されたスコアに基づいてソースワードを抽出し、既存のバイリンガル辞書を使用して単語ペアを生成することを提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Entity Extraction with Knowledge from Web Scale Corpora -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_4.html">
      Entity Extraction with Knowledge from Web Scale Corpora
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験は、私たちのテクニックが効率と有効性に顕著な改善をもたらすことを示しています。これらのテクニックは、ウェブスケールコーパスで訓練されたモデルを利用し、私たちのテクニックを堅牢で多用途にします。エンティティ抽出の一般的な方法は、フリーテキストのサブストリングとエンティティの辞書。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Generating Diverse Translation by Manipulating Multi-Head Attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_5.html">
      Generating Diverse Translation by Manipulating Multi-Head Attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、実験により、これらの多様な翻訳による逆翻訳により、翻訳タスクのパフォーマンスが大幅に向上することが示されています。実験結果は、本手法が翻訳品質を大幅に低下させることなく多様な翻訳を生成することを示しています。同様に多様性の。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Chemical-protein Interaction Extraction via Gaussian Probability
  Distribution and External Biomedical Knowledge -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_6.html">
      Chemical-protein Interaction Extraction via Gaussian Probability
  Distribution and External Biomedical Knowledge
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたモデルは、他の最新モデルと比較してパフォーマンスが優れています。それらを統合すると、CPI抽出パフォーマンスを効果的に改善できます。データとコードはhttps://github.com/CongSun-dlut/で入手できます。 CPI_extraction。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An Empirical Study of Sections in Classifying Disease Outbreak Reports -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_7.html">
      An Empirical Study of Sections in Classifying Disease Outbreak Reports
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この章では、各セクションの重要性とセクションの重み付けがテキスト分類のパフォーマンスに与える影響を調査します。実験結果は、（1）見出しと主要な文を使用した分類モデルがFスコアに関して高いパフォーマンスを達成する記事の他の部分と比較。 （2）バッグオブワード表現（全文）を含むすべてのセクションが最も高いリコールを実現します。 （3）セクションの重み付け情報は、精度の向上に役立ちます。強力に構造化された形式で利用可能な科学記事とは異なり、ニュース記事は通常、大まかに構造化されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: When Low Resource NLP Meets Unsupervised Language Model:
  Meta-pretraining Then Meta-learning for Few-shot Text Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_8.html">
      When Low Resource NLP Meets Unsupervised Language Model:
  Meta-pretraining Then Meta-learning for Few-shot Text Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      データが不足している場合、または目に見えないクラスに適応する必要がある場合、テキスト分類は困難になる傾向があります。このアプローチは単純であるだけでなく、よく研究された感情分類で最先端のパフォーマンスを生成するデータセット..したがって、事前トレーニングは、他の多くのNLPタスクの少数ショット学習の有望なソリューションになる可能性があることをさらに示唆できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-22">
        <br>2019-08-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ERNIE 2.0: A Continual Pre-training Framework for Language Understanding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_9.html">
      ERNIE 2.0: A Continual Pre-training Framework for Language Understanding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、ERNIE 2.0がGLUEベンチマークの英語タスクと中国語のいくつかの一般的なタスクを含む16のタスクでBERTおよびXLNetよりも優れていることを示しています。最近、事前学習モデルはさまざまな言語理解タスクで最新の結果を達成しました。は、大規模コーパスの事前トレーニングが自然言語処理で重要な役割を果たす可能性があることを示しています。コーパスのトレーニングから語彙的、構文的、意味的な情報を最大限に抽出するために、継続的な事前トレーニングフレームワークを提案します。 ERNIE 2.0。一定のマルチタスク学習により、事前トレーニングタスクを徐々に構築して学習します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-29">
        <br>2019-07-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Automatic Text-based Personality Recognition on Monologues and
  Multiparty Dialogues Using Attentive Networks and Contextual Embeddings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_10.html">
      Automatic Text-based Personality Recognition on Monologues and
  Multiparty Dialogues Using Attentive Networks and Contextual Embeddings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      第二に、事前トレーニングされたコンテキスト埋め込み（BERTおよびRoBERTa）と注意深いニューラルネットワークを使用した自動パーソナリティ認識への新しいアプローチを提示します。モノローグエッセイデータセットの最新の結果が2.49％であり、FriendsPersonaの堅実なベンチマークを確立しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: How to Ask Better Questions? A Large-Scale Multi-Domain Dataset for
  Rewriting Ill-Formed Questions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_11.html">
      How to Ask Better Questions? A Large-Scale Multi-Domain Dataset for
  Rewriting Ill-Formed Questions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      不正な形式の質問から適切な形式の質問に移行すると、質問の質は3つの側面で平均45ポイント向上します。MQRデータセットをリリースして、質問の書き換えの問題に関する研究を促進します。構築されたデータセットのニューラルモデルを作成し、他のデータリソースから構築されたベースラインメソッドよりもBLEU-4で13.2％の改善を得ます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Paraphrasing with Large Language Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_12.html">
      Paraphrasing with Large Language Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのアプローチは、文レベルだけでなく、パラグラフなどのテキストの長いスパンに対しても、テキストを小さなチャンクに分割することなく、言い換えを生成できることが実証されています。大規模な言語モデルを使用して実行する便利な手法を提示しますさまざまなテキストや主題を言い換えるタスク。最近、GPT-2などの大規模な言語モデルは、テキスト生成に非常に精通していることを示し、多くのダウンストリームNLPタスクなどで高品質の結果を達成することもできました。テキスト分類、感情分析、微調整としての質問応答として。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Enhancing Context Modeling with a Query-Guided Capsule Network for
  Document-level Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_13.html">
      Enhancing Context Modeling with a Query-Guided Capsule Network for
  Document-level Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      コンテキストモデリングは、ドキュメントレベルのニューラル機械翻訳の一貫性のある一貫した翻訳を生成するために不可欠です。実験結果は、異なるドメインの複数のデータセットで強力なベースラインを大幅に上回ることができることを示しています。文脈語の役割も区別しません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-02">
        <br>2019-09-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Latent-Variable Non-Autoregressive Neural Machine Translation with
  Deterministic Inference Using a Delta Posterior -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_14.html">
      Latent-Variable Non-Autoregressive Neural Machine Translation with
  Deterministic Inference Using a Delta Posterior
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたモデルは、ASPE Ja-Enデータセットの非自己回帰アプローチと自己回帰アプローチのパフォーマンスギャップを8.6倍高速にデコードします。待機時間..私たちの実験は、推論アルゴリズムを実行することで下限を大幅に増加させ、結果として翻訳品質を大幅に改善できることを示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-20">
        <br>2019-08-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CAIL2019-SCM: A Dataset of Similar Case Matching in Legal Domain -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_15.html">
      CAIL2019-SCM: A Dataset of Similar Case Matching in Legal Domain
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、研究者がこのタスクをよりよく理解できるように、いくつかのベースラインを実装しました。CAIL2019-SCMには、中国最高人民法院が発行した8,964のトリプレットの事例が含まれています。 2つのケースは、トリプレットでより類似しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Natural- to formal-language generation using Tensor Product
  Representations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_16.html">
      Natural- to formal-language generation using Tensor Product
  Representations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、自然言語から形式言語への生成のためのTensor Product Representations（TPR）に基づくTP-N2Fと呼ばれる新しいエンコーダーデコーダーモデルを提案します。ほとんどの最先端のニューラルシーケンスモデルは明示的にキャプチャしませんTP-N2Fのエンコーダーはベクトル空間で自然言語の記号構造をエンコードするためにTPR「バインディング」を使用し、デコーダーはリレーショナルのシーケンスを生成するためにTPR「アンバインディング」を使用しますシンボリック空間にある、それぞれがリレーション（または操作）といくつかの引数で構成されるタプル。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-05">
        <br>2019-10-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Fine-Grained Argument Unit Recognition and Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_17.html">
      Fine-Grained Argument Unit Recognition and Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      文内のトークンのスパンとして注釈が付けられた異種ソースからの引数のデータセットを、対応するスタンスとともに提示します。以前の研究では、異種ドキュメントコレクションからの引数検索を文レベルの分類タスクとして一般的に定義しました。そして、そのような難しい議論の注釈が、アノノレーター間の高い合意のあるクラウドソーシングを通じてどのように効果的に収集されるか。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-22">
        <br>2019-04-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Prosody Transfer in Neural Text to Speech Using Global Pitch and
  Loudness Features -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_18.html">
      Prosody Transfer in Neural Text to Speech Using Global Pitch and
  Loudness Features
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      リスニングテストは、合成音声が非常に自然と評価され、韻律が基準音声信号から合成信号に正常に転送されることを示しています。訓練されたモデルは主観的リスニングテストを使用して評価され、韻律転送の新しい客観的評価が提案されています。論文は、基準音声信号から合成音声への韻律転送を達成するためのシンプルで効果的な方法を提示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Automatically Generating Macro Research Reports from a Piece of News -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_19.html">
      Automatically Generating Macro Research Reports from a Piece of News
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本質的に、中核課題は長いテキスト生成の問題です。提案されたシステムの目標は、マクロ分析レポートの草案としてマクロ研究レポートを生成することです。この問題に対処するために、モデルのパフォーマンス評価では、最初に大きなニュースからレポートへのデータセットをクロールし、次にこのデータセットに対するアプローチを評価します。生成されたレポートは主観的な評価のために提供されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Image Captioning with Very Scarce Supervised Data: Adversarial
  Semi-Supervised Learning Approach -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_20.html">
      Image Captioning with Very Scarce Supervised Data: Adversarial
  Semi-Supervised Learning Approach
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      経験的な結果は、特にペア化されたサンプルの量が少ない場合、いくつかの強力なベースラインと比較した本方法の有効性を示しています。画像とキャプションの共同分布を学習します。大量のペアになっていない画像とキャプションデータを活用して、それらを関連付けることを学習します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-05">
        <br>2019-09-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Assessing the Benchmarking Capacity of Machine Reading Comprehension
  Datasets -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_21.html">
      Assessing the Benchmarking Capacity of Machine Reading Comprehension
  Datasets
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの結果は、モデルによってすでに正解された質問のほとんどが必ずしも文法的かつ複雑な推論を必要としないことを示唆しています。この課題に対して、半自動化されたアブレーションベースの方法論を提案します。言語理解に必要なスキルに関連する機能を削除した後でも質問を解決できるかどうかを確認することにより、質問がスキルを必要としない程度を評価します。ただし、データセットの機能は、言語理解を正確にベンチマークするために評価されていません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: What Do You Mean `Why?': Resolving Sluices in Conversations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_22.html">
      What Do You Mean `Why?': Resolving Sluices in Conversations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      会話型QAデータセットから収集された4,000を超えるダイアログからの水門の注釈を含むクラウドソースのデータセットと、一連の強力なベースラインアーキテクチャを提示します。このような質問は通常、人間が答えるのは簡単ですが、コンピューターにとっては難しい場合があります。それらの解決には、コンテキストから適切なセマンティックフレームと適切な引数の両方を取得する必要があります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Scalable Attentive Sentence-Pair Modeling via Distilled Sentence
  Embedding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_23.html">
      Scalable Attentive Sentence-Pair Modeling via Distilled Sentence
  Embedding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このコードは、https：//github.com/microsoft/Distilled-Sentence-Embeddingで公開されています。このホワイトペーパーでは、Distilled Sentence Embedding（DSE）を紹介します。 、センテンスペアタスクに焦点を当てます。微調整されたBERT）、教師モデルによって得られたセンテンスペアスコアを再構築するために、センテンス埋め込みベースの学生モデルをトレーニングします。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-14">
        <br>2019-08-14
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning Hierarchical Discrete Linguistic Units from Visually-Grounded
  Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_24.html">
      Learning Hierarchical Discrete Linguistic Units from Visually-Grounded
  Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この方法は、構成方法に応じて、単語レベルとサブワードの両方のユニットをキャプチャできることを示します。これらのユニットのノイズ耐性を実証する実験も示します。再構成ベースの損失を使用するのではなく、識別されたマルチモーダルグラウンディングオブジェクティブを使用します。これにより、学習したユニットがセマンティックイメージの検索に役立つようになります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Story Realization: Expanding Plot Events into Sentences -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_25.html">
      Story Realization: Expanding Plot Events into Sentences
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、イベントから文への一般的なニューラル言語生成アプローチでは、イベントの詳細を無視して、文法的には正しいが意味的には無関係な文を生成できます。イベントに基づいて自然言語を生成するアンサンブルベースのモデルを提示します。 -人間の被験者の研究を含む---完全なエンドツーエンドの自動化されたストーリー生成システムで、本手法がベースラインアプローチよりも一貫性のある説得力のあるストーリーを生成することを示します。 （1）イベントのシーケンスの生成（イベントからイベントへ）および（2）これらのイベントの自然言語文への変換（イベントから文へ）
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-08">
        <br>2019-09-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Incorporating Textual Evidence in Visual Storytelling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_26.html">
      Incorporating Textual Evidence in Visual Storytelling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      VISTデータセットでの実験により、この手法は、重度のエンジニアリングなしで最先端のベースラインモデルよりも優れていることが示されています。 ..テキストエクスペリエンスを提供する可能性のある画像を選択するために、画像オブジェクト認識技術に基づく2段階のランク付け方法を提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An analysis of observation length requirements in spoken language for
  machine understanding of human behaviors -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_27.html">
      An analysis of observation length requirements in spoken language for
  machine understanding of human behaviors
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      したがって、このペーパーでは、（a）システムの予測と人間の専門家による評価の類似性を（b）一貫性を分析することにより、ウィンドウ長の選択が言語ベースの行動定量化の有効性にどのように影響するかを調査します関連する行動構築物の予測間の関係。私たちの調査結果を、音声の合図に基づく行動の定量化に関する関連作業と、薄いスライスと人間の人格予測に関する以前の作業と比較して、一般に一致していることを見つけます。一方、不快感を説明する構造は、観察される期間に関係なく、言語情報だけでは定量化できないようです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Empirical Autopsy of Deep Video Captioning Frameworks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_28.html">
      Empirical Autopsy of Deep Video Captioning Frameworks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人気のあるMSVDデータセットをテストベッドとして使用し、パイプライン自体に大きな変更を加えることなく構成要素を慎重に選択することにより、大幅なパフォーマンス向上が可能であることを示しています。ただし、現在の文献には、この点に関する体系的な調査はありません。これらの結果は、急速に成長するビデオキャプションの方向における将来の研究の指針となることが期待されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: How Do You #relax When You're #stressed? A Content Analysis and
  Infodemiology Study of Stress-Related Tweets -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_29.html">
      How Do You #relax When You're #stressed? A Content Analysis and
  Infodemiology Study of Stress-Related Tweets
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、ツイートの自動分類と公共ストレス調査の結果との相関の程度を評価する目的で、4つの都市から抽出されたサンプルデータセットにこれらの分類子を適用しました。分類子を都市データセットに適用した場合、ニューヨークとサンディエゴのストレスツイートは、ロサンゼルスとサンフランシスコのそれよりも大幅に高かった。結果：コンテンツ分析は、ストレスツイートの最も頻繁なトピックは教育であり、仕事と社会的関係がそれに続くことを示した。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Knowing What, How and Why: A Near Complete Solution for Aspect-based
  Sentiment Analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_30.html">
      Knowing What, How and Why: A Near Complete Solution for Aspect-based
  Sentiment Analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このタスクに対処するための2段階のフレームワークを提案します。議論された側面、その感情、および感情の原因。特に、このタスクのソルバーは、3つの要素（What、How、Why）を抽出する必要があります対象となる側面が何であるか、感情の極性がどのように、そしてそのような極性を持っているのかを示す入力
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-05">
        <br>2019-11-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Minimizing the Bag-of-Ngrams Difference for Non-Autoregressive Neural
  Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_31.html">
      Minimizing the Bag-of-Ngrams Difference for Non-Autoregressive Neural
  Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      3つの変換タスクでのアプローチを検証し、WMT14 En $ \ leftrightarrow $ Deで約5.0 BLEUスコア、WMT16 En $ \ leftrightarrow $ Roで約2.5 BLEUスコアだけ、NATベースラインを大幅に上回るアプローチであることを示します。 -ngramsトレーニングの目的は微分可能で、効率的に計算できるため、NATがターゲット側の順次依存関係をキャプチャし、翻訳品質とよく相関するようになります。本書では、Bag-of-Ngrams（ BoN）モデル出力と参照文の違い。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Emotion Recognition for Vietnamese Social Media Text -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_32.html">
      Emotion Recognition for Vietnamese Social Media Text
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      何よりもまず、標準的なベトナム語ソーシャルメディア感情コーパス（UIT-VSMEC）を作成し、正確に6,927の感情注釈付き文を使用して、自然言語処理（NLP）の低リソース言語であるベトナム語の感情認識研究に貢献しています。この研究では、2つの目標を達成しました。その結果、CNNモデルは59.74％の加重F1スコアで最高のパフォーマンスを達成しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Cluster Ranking Model for Full Anaphora Resolution -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_33.html">
      A Cluster Ranking Model for Full Anaphora Resolution
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      3番目に、CONLLデータ専用に設計されていないモデルにもかかわらず、そのデータセットでKantor and Globerson（2019）による最先端システムのスコアと同等のスコアを達成することを示します。この論文では、非参照式（exp語、述語{\ NP}、およびその他のタイプを含む）を同時に識別し、シングルトンを含む相互参照チェーンを構築するアーキテクチャを導入します。最初に、システムの言及を使用してCRACデータの最初の結果を報告します;結果は、ゴールドの言及を使用した共有タスクベースラインシステムよりも5.8％優れています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Span Model for Open Information Extraction on Accurate Corpus -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_34.html">
      Span Model for Open Information Extraction on Accurate Corpus
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      後者については、一連の言語的観察と分析に従って正確に再注釈付けされたベンチマークテストセット（Re-OIE6）を提示します。新しく導入されたモデルは、両方のベンチマーク評価データセットで新しい最先端のパフォーマンスを実現します。 。この作業では、最初にトレーニングとテストセットの両方の側面からこの困難を軽減します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-01-30">
        <br>2019-01-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Cantonese Automatic Speech Recognition Using Transfer Learning from
  Mandarin -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_35.html">
      Cantonese Automatic Speech Recognition Using Transfer Learning from
  Mandarin
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      主な調査結果は、このアプローチにより、より少ないデータでより短いトレーニング時間を実現できることです。転送されたレイヤーの数、その学習率、i-ベクトルの事前トレーニングを試します。転送学習モデルは、CERのわずかな改善を示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Thinking Globally, Acting Locally: Distantly Supervised Global-to-Local
  Knowledge Selection for Background Based Conversation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/cs.CL/paper_36.html">
      Thinking Globally, Acting Locally: Distantly Supervised Global-to-Local
  Knowledge Selection for Background Based Conversation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      前の作業では、アテンションおよび/またはポインターメカニズムを使用してKSを扱います。BBCの重要な課題は知識選択（KS）です。会話のコンテキストが与えられると、適切な背景知識（関連する事実やコメントなどを含むテキストフラグメント）を見つけようとします。 ）。次の応答を生成する対象に基づきます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-26">
        <br>2019-08-26
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Temporal Reasoning via Audio Question Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/eess.AS/paper_0.html">
      Temporal Reasoning via Audio Question Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      DAQAがAQAと時間的推論の研究を促進し、MALiMoがAQAのモデルへのステップを促進することを想定しています。AQAタスクへの視覚的な質問応答にいくつかの最新の手法を適用し、それらが実行することを実証するためにDAQAを使用します綿密な時間的推論を必要とする質問では不十分です。さまざまなタイプの入力モダリティに関する質問に答えると、視覚的推論、読解、ストーリー理解、ナビゲーションなどの推論のさまざまな側面が強調されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Opus Low Bit Rate Quality with Neural Speech Synthesis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/eess.AS/paper_1.html">
      Improving Opus Low Bit Rate Quality with Neural Speech Synthesis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      リスニングテストにより、同じ6 kb / s Opusビットストリームに対して、LPCNetを使用した合成音声は、標準のOpusデコーダーの出力より明らかに優れていることがわかります。Opusオーディオコーダーの音声モードは、6 kb / s〜40 kb /s。2つの異なる神経生成モデル、WaveNetとLPCNetを比較します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-12">
        <br>2019-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: InverSynth: Deep Estimation of Synthesizer Parameter Configurations from
  Audio Signals -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/eess.AS/paper_2.html">
      InverSynth: Deep Estimation of Synthesizer Parameter Configurations from
  Audio Signals
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、ネットワークの深さが予測精度に寄与する重要な要因であることを示します。複数のベースラインに対するInverSynthの優位性を示す広範な定量的および定性的結果を示します。InverSynthの有効性は、4つの周波数変調の減算シンセサイザーで実証されていますオシレーター、エンベロープジェネレーター、ゲーターエフェクト。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-15">
        <br>2018-12-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Designing Virtual Soundscapes for Alzheimer's Disease Care -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/eess.AS/paper_3.html">
      Designing Virtual Soundscapes for Alzheimer's Disease Care
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      プラウストのマドレーヌに関連してマドレーヌ・ソノレスと名付けられたこの装置は、専用のアルツハイマー病治療センターで24時間年中無休でホストされている14人の高齢者に1年間聞こえる仮想サウンドスケープを提供しました。認知症と思いやりの活動に..音環境は、リスナーが自分自身を置き、コミュニケーションし、感じ、記憶することを可能にする意識的および無意識的な情報の主要なソースです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Prosody Transfer in Neural Text to Speech Using Global Pitch and
  Loudness Features -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/eess.AS/paper_4.html">
      Prosody Transfer in Neural Text to Speech Using Global Pitch and
  Loudness Features
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      訓練されたモデルは主観的なリスニングテストを使用して評価され、韻律転送の新しい客観的評価が提案されます。リスニングテストは、合成音声が非常に自然と評価され、韻律が基準音声信号から合成信号に正常に転送されることを示します。主なアイデアは、参照音声のピッチやラウドネスの輪郭などの韻律のよく知られている音響相関を、Tacotron2（TC2）などの最新のニューラルテキスト音声合成（TTS）シンセサイザーに組み込むことです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Conditioned-U-Net: Introducing a Control Mechanism in the U-Net for
  Multiple Source Separations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/eess.AS/paper_5.html">
      Conditioned-U-Net: Introducing a Control Mechanism in the U-Net for
  Multiple Source Separations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CU-Netはさまざまな機器の分離を実行し、すべてが単一モデルで専用のモデルと同じパフォーマンスを低コストで実現します。特定の機器の分離。それらを一度にさまざまなタスクでトレーニングすると、パフォーマンスが低下します。単一の特別なタスク。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-02">
        <br>2019-07-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning Hierarchical Discrete Linguistic Units from Visually-Grounded
  Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-22/eess.AS/paper_6.html">
      Learning Hierarchical Discrete Linguistic Units from Visually-Grounded
  Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、これらのユニットの耐ノイズ性を実証する実験も行います。ZeroSpeech2019チャレンジのサブワードユニットを評価し、ビットレートをほぼ同じに保ちながら、最高性能の提出よりもABXエラー率を27.3 \％削減しました。 ..この論文を音声ユニット学習に関する以前の研究と区別するのは、トレーニング目標の選択です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-21">
        <br>2019-11-21
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本日更新された論文はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br>
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
