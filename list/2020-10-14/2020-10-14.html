<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-10-14の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: A Lightweight Speaker Recognition System Using Timbre Properties -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.SD/paper_0.html">
      <font color="black">A Lightweight Speaker Recognition System Using Timbre Properties</font>
    </a>
  </h2>
  <font color="black">また、話者認証と識別タスクの両方に使用される新機能も紹介します。ただし、ほとんどの高度なモデルは、リアルタイム音声認識にGPUサポートを必要とするディープラーニングを実装しており、ローエンドデバイスには適していません。実験は話者検証と話者識別タスクで実行され、提案されたモデルの成果と欠点を示しています。 
[概要]提案されたモデルは、ランダムフォレストを使用して分類される特徴として人間の音声ベースの音色特性を使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: Symbolic Music Playing Techniques Generation as a Tagging Problem -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.SD/paper_1.html">
      <font color="black">Symbolic Music Playing Techniques Generation as a Tagging Problem</font>
    </a>
  </h2>
  <font color="black">象徴的な音楽を議論するとき、通常、メロディーまたはハーモニーが唯一の生成ターゲットと見なされます。この論文では、タグ付けの問題と見なして、演奏技術の生成問題について説明します。現在のデータと現在のデータの両方を使用できるモデルを提案します。外部の知識。 【概要】演奏技術生成問題もタグ付け問題である。提案モデルを適用して実験を行った結果、生成された音楽をより生き生きとさせることができることがわかった。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-08">
        <br><font color="black">2020-08-08</font>
      </time>
    </span>
</section>
<!-- paper0: Converting Anyone's Emotion: Towards Speaker-Independent Emotional Voice
  Conversion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.SD/paper_2.html">
      <font color="black">Converting Anyone's Emotion: Towards Speaker-Independent Emotional Voice
  Conversion</font>
    </a>
  </h2>
  <font color="black">実験は、提案された話者に依存しないフレームワークが、見られる話者と見えない話者の両方に対して競争力のある結果を達成することを示しています。言語コンテンツと話者のアイデンティティを維持しながら、ある状態から別の状態へ。 
[概要]提案された話者-独立した感情的な音声変換フレームワークは、並列データを必要とせずに誰の感情も変換できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br><font color="black">2020-05-13</font>
      </time>
    </span>
</section>
<!-- paper0: Low-Latency Sequence-to-Sequence Speech Recognition and Translation by
  Partial Hypothesis Selection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.SD/paper_3.html">
      <font color="black">Low-Latency Sequence-to-Sequence Speech Recognition and Translation by
  Partial Hypothesis Selection</font>
    </a>
  </h2>
  <font color="black">チャンクベースのインクリメンタル推論のための3つのレイテンシー削減手法を提案し、2.4 BLEUポイント（5％rel。）の損失を被りながら、オフライン転写と比較した精度とレイテンシーのトレードオフの観点からそれらの効率を評価します。
[要約] how2データセットでは、レイテンシーを83％削減して0.8秒にします。オフラインシステムは、ワードエラー率（wer）やブルーなどの品質メトリックで評価されることがよくありますが、レイテンシーも多くの実際の使用において重要な要素です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-22">
        <br><font color="black">2020-05-22</font>
      </time>
    </span>
</section>
<!-- paper0: Sound event localization and detection based on crnn using rectangular
  filters and channel rotation data augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.SD/paper_4.html">
      <font color="black">Sound event localization and detection based on crnn using rectangular
  filters and channel rotation data augmentation</font>
    </a>
  </h2>
  <font color="black">スコアをさらに改善し、システムパフォーマンスを見えないデータに一般化するために、トレーニングデータセットのサイズはデータ拡張を使用して増加しました。そのために使用される手法は、チャネルの回転と1次アンビソニックスのxy平面での反射に基づいています。ドメイン。これにより、チャネル間の物理的関係を維持しながら到着方向ラベルを改善できます。アルゴリズムは、タスクに関連する重要なスペクトル特徴の認識に特化した、長方形フィルターを使用した畳み込みリカレントニューラルネットワークで構成されます。 
[ABSTRACT]畳み込みリカレントニューラルネットワークは、最も使用されているシステムの1つです。アルゴリズムは、長方形フィルターを使用した畳み込みリカレント問題で構成されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-end Triplet Loss based Emotion Embedding System for Speech
  Emotion Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.SD/paper_5.html">
      <font color="black">End-to-end Triplet Loss based Emotion Embedding System for Speech
  Emotion Recognition</font>
    </a>
  </h2>
  <font color="black">提案システムは、発話の感情情報から埋め込みを学習する。本論文では、音声感情認識のために、三重項損失と残差学習に基づくエンドツーエンドの神経埋め込みシステムを提案した。さまざまな埋め込み表現感情はハイパープレーンにマッピングされ、それらの間の角度は余弦の類似性を使用して計算されます。 
[ABSTRACT]提案されたシステムは、感情的な情報から埋め込みを学習します。埋め込みはさまざまな角度に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: A variational autoencoder for music generation controlled by tonal
  tension -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.SD/paper_6.html">
      <font color="black">A variational autoencoder for music generation controlled by tonal
  tension</font>
    </a>
  </h2>
  <font color="black">ユーザー入力または潜在空間からの直接サンプリングのいずれかから生じるシード音楽フラグメントが与えられると、モデルは、トーン張力が変更されたこの元のシードフラグメントのバリエーションを生成できます。ニューラルネットワークに基づく音楽生成システムの多くは完全に自律的です。生成プロセスの制御は提供しません。スパイラルアレイ張力理論に基づく2つの音の張力測定値を変分自動エンコーダモデルに組み込みます。 
[概要]これにより、生成されたピース全体の色調張力の方向と、全体的な色調張力のレベルを制御できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Training for End-to-End Speech Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.SD/paper_7.html">
      <font color="black">Self-Training for End-to-End Speech Translation</font>
    </a>
  </h2>
  <font color="black">これにより、MuST-C英語-フランス語および英語-ドイツ語データセットの強力な半教師ありベースラインを超える8.3および5.7 BLEUゲインが提供され、最先端のパフォーマンスに到達します。私たちのアプローチは、単に事前に作成するよりも効果的であることが示されています。音声認識タスクでエンコーダをトレーニングします。疑似ラベルの品質の影響を調査します。 
[概要]カスケードによってラベルなしオーディオから生成された疑似ラベルと、エンドツーエンドの音声翻訳モデルを活用します。エンドツーエンドの疑似ラベルを直接生成することにより、セルフトレーニングの有効性を実証しました。カスケードモデルの代わりに終了モデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-03">
        <br><font color="black">2020-06-03</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Boundary loss for highly unbalanced segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.IV/paper_0.html">
      <font color="black">Boundary loss for highly unbalanced segmentation</font>
    </a>
  </h2>
  <font color="black">さらに、境界損失は地域情報を補完します。残念ながら、非常に不均衡なセグメンテーションの場合、そのような地域の合計はクラス間で数桁異なる値を持ち、トレーニングのパフォーマンスと安定性に影響します。さまざまな不均衡な問題に関する包括的な評価と比較を報告します。 、トレーニングの安定性を向上させながら、境界損失によってパフォーマンスが大幅に向上する可能性があることを示しています。 
[概要]これにより、非常に不均衡な問題の問題を軽減できます。領域全体の不均衡な積分ではなく、領域間のインターフェースで積分を使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-17">
        <br><font color="black">2018-12-17</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Ice Layer Tracking and Thickness Estimation using Fully
  Convolutional Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.IV/paper_1.html">
      <font color="black">Deep Ice Layer Tracking and Thickness Estimation using Fully
  Convolutional Networks</font>
    </a>
  </h2>
  <font color="black">各内部氷層の深さと構造を理解するために、一連の画像処理技術を実行し、レーダー画像に対してセマンティックセグメンテーションを実行します。この論文では、を使用して各内部氷層の厚さを推定する新しい方法を紹介します。スノーレーダー画像と完全畳み込みネットワーク..各氷層を一意に検出した後、その厚さを計算し、利用可能なグラウンドトゥルースと比較します。 
[概要]推定厚さを分析して、毎年の積雪を理解することができます。各氷層を理解するために、その厚さを計算し、利用可能なグラウンドトゥルースと比較します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Spatially-Variant CNN-based Point Spread Function Estimation for Blind
  Deconvolution and Depth Estimation in Optical Microscopy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.IV/paper_2.html">
      <font color="black">Spatially-Variant CNN-based Point Spread Function Estimation for Blind
  Deconvolution and Depth Estimation in Optical Microscopy</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、光学セットアップに関する先験的な知識の必要性を最小限に抑えて、平らでないオブジェクトの画像を強化するための複数の可能性を開きます。顕微鏡固有のキャリブレーションに続いて、復元されたPSFモデルパラメータが表面深度を設計されたPSFを使用する場合、2マイクロメートル以上の拡張範囲。ここでは、焦点面までの物体距離を共同で推定しながら、画像の歪みを局所的に推定することにより、そのような物体の光学顕微鏡画像の解像度を向上させる方法を紹介します。 
[ABSTRACT]畳み込みニューラルネットワーク（cnn）を使用して、空間-バリアント点-広がり関数（psf）モデルのパラメーターを推定します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: A comprehensive protocol for manual segmentation of the human claustrum
  and its sub-regions using high-resolution MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.IV/paper_3.html">
      <font color="black">A comprehensive protocol for manual segmentation of the human claustrum
  and its sub-regions using high-resolution MRI</font>
    </a>
  </h2>
  <font color="black">また、その量は扁桃体の量に匹敵します。てんかんや統合失調症などの神経精神障害の将来の解剖学的研究に使用できるように、プロトコルの信頼性を評価する必要があります。プロトコルには、詳細なガイドラインが含まれています。幾何学的方法に基づいてパーセル化できる背側、腹側、側頭のClを含むClの3つのサブ領域。 
[概要]人間のてんかんと精神病におけるclの役割の詳細はほとんど不明です。これらには、clの薄い羽毛に関連する方法論的な制限が含まれます。これは、将来の解剖学的研究に使用できるプロトコルの信頼性を評価するために必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Machine learning for COVID-19 detection and prognostication using chest
  radiographs and CT scans: a systematic methodological review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.IV/paper_4.html">
      <font color="black">Machine learning for COVID-19 detection and prognostication using chest
  radiographs and CT scans: a systematic methodological review</font>
    </a>
  </h2>
  <font color="black">各論文の方法論品質レビューは、レビューが高品質の再現可能な論文のみに焦点を当てることを確実にするために確立されたベンチマークに対して実行されました。これは緊急に必要とされる安全な臨床実施の鍵です。方法：この系統的レビューでは、OVIDを介してEMBASEをレビューしました。 、2020年1月1日から2020年6月24日までにアップロードされた公開論文およびプレプリントのPubMed、bioRxiv、medRxiv、およびarXivを介したMEDLINE。
[要約]この系統的レビューでは、急速に成長している文献で採用されている機械学習方法を批判的に評価します。検証されたcovidの緊急性を考えると、大きな弱点-19のモデルが必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-14">
        <br><font color="black">2020-08-14</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Road Signs Detection performance by Combining the Features of
  Hough Transform and Texture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.IV/paper_5.html">
      <font color="black">Improving Road Signs Detection performance by Combining the Features of
  Hough Transform and Texture</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案されたアプローチにより、測定精度を実行できることを示しています。ランダム化ハフ変換（RHT）は、円形および八角形の形状を検出するために使用されます。この段階は、ハラリック特徴とゼルニケモーメントの抽出によって改善されます。 
[概要]道路標識検出の研究はアラブの文脈で行われていますが、道路標識を使用するにはまだ研究が不十分です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Deep Learning on Medical Images: A Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.IV/paper_6.html">
      <font color="black">3D Deep Learning on Medical Images: A Review</font>
    </a>
  </h2>
  <font color="black">最後に、医用画像領域での3D CNNの使用（および一般的な深層学習モデルの使用）に関連する課題と、この分野で考えられる将来の傾向について説明します。近年、3次元（3D）CNNには医用画像の分析に採用されました。この論文では、3D CNNが機械学習のルーツからどのように開発されたかの歴史をたどり、3D CNNの簡単な数学的説明を提供し、医用画像に必要な前処理手順をそれらを3DCNNにフィードします。 
[概要]近年、医用画像の分析に3d 3d 3d cnnsが採用されています。これは、畳み込みニューラルネットワーク（cnn）ベースのアーキテクチャが急速に進歩したためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-01">
        <br><font color="black">2020-04-01</font>
      </time>
    </span>
</section>
<!-- paper0: BoMuDA: Boundless Multi-Source Domain Adaptive Segmentation in
  Unconstrained Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.IV/paper_7.html">
      <font color="black">BoMuDA: Boundless Multi-Source Domain Adaptive Segmentation in
  Unconstrained Environments</font>
    </a>
  </h2>
  <font color="black">Indian Driving Dataset、CityScapes、Berkeley DeepDrive、GTA V、およびSynscapesデータセットを使用して広範な実験とアブレーション研究を実施しました。教師なしアプローチは、他の教師なしおよび半教師ありSOTAベンチマークを5.17％〜42.9％上回っています。モデルサイズを最大5.2倍に縮小しました。さらに、私たちのアプローチも無限です。各反復で、単一ソースDAは最初に選択されたソース上のニューラルネットワークを学習し、その後、残りのソースを使用してマルチソース微調整ステップが続きます。 
[概要]シングルソースドメインドライブとマルチソース蒸留を交互に行う新しいトレーニング戦略を提案します。このシステムは、一貫性のないインクリメンタル（alt-inc）メソッドと呼ばれます。トレーニングデータセットに属さないカテゴリを明示的に分類できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Correlation Filter for UAV-Based Aerial Tracking: A Review and
  Experimental Evaluation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.IV/paper_8.html">
      <font color="black">Correlation Filter for UAV-Based Aerial Tracking: A Review and
  Experimental Evaluation</font>
    </a>
  </h2>
  <font color="black">最後に、未解決の課題と将来の研究の方向性に関する包括的な結論が提示されます。最近、識別相関フィルター（DCF）ベースのトラッカーは、単一のCPUでの高い計算効率と魅力的な堅牢性で際立っており、UAVで栄えています。ビジュアルトラッキングコミュニティ..この作業では、DCFベースのトラッカーの基本的なフレームワークを最初に一般化し、それに基づいて、さまざまな問題を解決するための革新に従って、20の最先端のDCFベースのトラッカーを順番に要約します。 
[ABSTRACT]風の状態、UAVの機械構造の振動、限られた計算リソースに基づくすべてが、搭載された追跡方法にとって重要です。これは、20の最先端のdcfベースのトラッカーが整然としていることに基づいています。彼らの革新によると</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Procedural 3D Terrain Generation using Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.IV/paper_9.html">
      <font color="black">Procedural 3D Terrain Generation using Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">2番目の部分では、RGB画像から数値標高モデル（DEM）への1対1のマッピングが必要です。画像への最先端のアプローチである条件付き生成敵対ネットワーク（CGAN）を展開します。 -から画像への変換、最初のモデルのランダムに生成されたすべての画像のもっともらしい高さマップを生成します。生成されたDEM画像とRGB画像を組み合わせることで、もっともらしい高さの分布と色付けで構成される3D風景を構築できます。トレーニング中に提供されたリモートで感知された風景。 
[概要]新しいシステムを使用して、衛星やドローンによってキャプチャされた風景の画像の分布に基づいて3D環境を作成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Explaining Clinical Decision Support Systems in Medical Imaging using
  Cycle-Consistent Activation Maximization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.IV/paper_10.html">
      <font color="black">Explaining Clinical Decision Support Systems in Medical Imaging using
  Cycle-Consistent Activation Maximization</font>
    </a>
  </h2>
  <font color="black">近年、これはより深い洞察を提供することに成功したさまざまなアプローチによって対処されています。ただし、限られたデータしか利用できない場合、生成されたマップの品質が低下し、画像にノイズが発生する可能性があります。これは臨床の典型的なシナリオです。コンテキスト..最も注目すべきことに、付加的な機能の帰属方法は、開業医が「ネットワークが見ているものを見る」ことを可能にする顕著性マップを作成することによって、決定を入力空間に伝播することができます。 
[概要]ディープラーニングは、従来の方法よりも医用画像分類に大きな利点を提供します。システムは不透明で理解しにくいと考えられています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-09">
        <br><font color="black">2020-10-09</font>
      </time>
    </span>
</section>
<!-- paper0: Batch-Incremental Triplet Sampling for Training Triplet Networks Using
  Bayesian Updating Theorem -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.IV/paper_11.html">
      <font color="black">Batch-Incremental Triplet Sampling for Training Triplet Networks Using
  Bayesian Updating Theorem</font>
    </a>
  </h2>
  <font color="black">各クラスの埋め込みについて、多変量正規分布を検討します。トリプレットネットワークのバリアントは、識別可能な埋め込み部分空間を学習するための堅牢なエンティティです。ベイズ更新と共役事前分布を使用して、新しいミニバッチを受信することにより、クラスの分布を動的に更新します。トレーニングデータの。 
[概要]最適なトレーニングトリプレットを選択するためのさまざまな手法があります。これらには、埋め込みなどのこれらのタイプの埋め込みが含まれます。これらは、「トリプレットマイニング」と呼ばれるトリプレットマイニング方法と呼ばれます。ただし、確率的マイニングからサンプリングするのではなく、既存の埋め込みインスタンスからのみサンプリングすると、より識別力のある情報を提供できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-10">
        <br><font color="black">2020-07-10</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Universal Model for 3D Medical Image Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_0.html">
      <font color="black">Universal Model for 3D Medical Image Analysis</font>
    </a>
  </h2>
  <font color="black">幅広いタスクに対応するために、シンプルで効果的なスケール分類子が組み込まれており、マルチレベルの視覚的表現をキャプチャします。事前にトレーニングされたユニバーサルモデルは次の場所で入手できます：\ href {https://github.com/xm-cmic/ Universal-Model} {https://github.com/xm-cmic/Universal-Model} ..統一された自己教師あり学習スキームを利用して、異なるモダリティと特徴的なスキャン領域を持つ複数のラベルなしソースデータセットから表現を学習します。 
[ABSTRACT]ユニバーサルモデルは、3D医療画像分析のための転送可能で一般化可能な事前トレーニング済みモデルです。事前トレーニング済みモデルからの統合学習が、複数開発マルチ開発画像の標準セットとして提案されています。新しいモデルは事前トレーニング済みで利用可能です。 -トレーニング済みモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Impact of Thermal Throttling on Long-Term Visual Inference in a
  CPU-based Edge Device -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_1.html">
      <font color="black">Impact of Thermal Throttling on Long-Term Visual Inference in a
  CPU-based Edge Device</font>
    </a>
  </h2>
  <font color="black">これは、アクティブ冷却を適用できない場合に周囲温度が重要なパラメータであることを示しています。屋外アプリケーションでのパフォーマンスを評価するために、外部温度センサーをRPi4Bと統合し、アクティブ冷却を使用しない一連の実験を次の広い間隔で実施しました。 22 {\ deg} Cから36 {\ deg} Cの範囲の周囲温度。その間隔で達成された最大スループットに関して、最大27.7％の変動が測定されました。システム全体の消費電力に対するファンの影響を考えると、これらの結果は、CNNモデルとソフトウェアの適切な選択の重要性を強調しています。コンポーネント。 
[概要]この調査は、コンピューターシステムで80の異なるケースを分析することによって行われました。ヒステリシスベースのアクティブ冷却により、すべてのケースで熱スロットリングが防止されました。結果は、cnnモデルとソフトウェアコンポーネントの適切な選択の重要性を強調しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Object as Hotspots: An Anchor-Free 3D Object Detection Approach via
  Firing of Hotspots -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_2.html">
      <font color="black">Object as Hotspots: An Anchor-Free 3D Object Detection Approach via
  Firing of Hotspots</font>
    </a>
  </h2>
  <font color="black">LiDARベースの点群での正確な3Dオブジェクト検出は、データのスパース性と不規則性の課題に悩まされています。特に、私たちのアプローチは、サイクリストと歩行者の検出のためのKITTI 3D検出ベンチマークで1位にランクされ、NuScenes3Dで最先端のパフォーマンスを達成しました検出ベンチマーク..データのスパース性の性質に基づいた最先端のアンカーベースの方法とは異なり、個々のオブジェクトパーツ上のポイントでさえ、オブジェクトのセマンティック情報について情報を提供することがわかります。 
[概要]これはデータのスパース性の性質に基づいていますが、個々のオブジェクト部分のポイントでさえ、オブジェクトのセマンティック情報について有益であることがわかります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-30">
        <br><font color="black">2019-12-30</font>
      </time>
    </span>
</section>
<!-- paper0: MixCo: Mix-up Contrastive Learning for Visual Representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_3.html">
      <font color="black">MixCo: Mix-up Contrastive Learning for Visual Representation</font>
    </a>
  </h2>
  <font color="black">MixCoは、混合画像が元の陽性をどれだけ持っているかを反映して、表現の相対的な類似性を学習することを目的としています。実験では、MixCoは一貫してテスト精度を向上させます。この論文では、対照的な学習概念を拡張するMix-up Contrast（MixCo）を提案します。ポジティブ画像とネガティブ画像の組み合わせからエンコードされたセミポジティブに。 
[ABSTRACT] mixcoは、混合された画像が元のポジティブをどれだけ持っているかを反映して、表現の相対的な類似性を学習することを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Boundary loss for highly unbalanced segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_4.html">
      <font color="black">Boundary loss for highly unbalanced segmentation</font>
    </a>
  </h2>
  <font color="black">さらに、境界損失は地域情報を補完します。残念ながら、非常に不均衡なセグメンテーションの場合、そのような地域の合計はクラス間で数桁異なる値を持ち、トレーニングのパフォーマンスと安定性に影響します。これにより、地域のソフトマックスで表される境界損失が発生します。ネットワークの確率出力。これは、標準の地域損失と簡単に組み合わせることができ、NDセグメンテーション用の既存のディープネットワークアーキテクチャで実装できます。 
[概要]これにより、非常に不均衡な問題の問題を軽減できます。領域全体の不均衡な積分ではなく、領域間のインターフェースで積分を使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-17">
        <br><font color="black">2018-12-17</font>
      </time>
    </span>
</section>
<!-- paper0: How important are faces for person re-identification? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_5.html">
      <font color="black">How important are faces for person re-identification?</font>
    </a>
  </h2>
  <font color="black">これらの調査結果は、複数のモデルとデータセット間で一貫しています。これらの結果は、個人の再識別システムのパフォーマンスに大きな影響を与えることなく、顔をぼかすことによってデータセットを安全に匿名化できることを示しています。プライバシーまたはデータ保護の懸念..おそらく驚くべきことに、mAPへの影響は非常に小さく、元のデータではなく匿名化されたバージョンのデータでトレーニングするだけで精度が回復します。 
[概要]顔検出とぼかしのアルゴリズムを適用して、人気のある人物の再識別データセットの匿名バージョンを作成します。地図への影響は非常に小さく、再識別モデルをトレーニングするだけで精度が向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring Efficient Volumetric Medical Image Segmentation Using 2.5D
  Method: An Empirical Study -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_6.html">
      <font color="black">Exploring Efficient Volumetric Medical Image Segmentation Using 2.5D
  Method: An Empirical Study</font>
    </a>
  </h2>
  <font color="black">これらの作業はさまざまなセグメンテーションタスクの改善につながりますが、私たちの知る限り、これらの方法の大規模な経験的比較はこれまでありませんでした。さらに、パラメーターの数が増えると、過剰適合のリスクがあります。特にデータと注釈の取得に費用がかかる医用画像の場合、より高くなります。さらに、これらの方法のパフォーマンスと有効性を比較するために、異なるモダリティとターゲットを含む3つの代表的なセグメンテーションタスクに関するこれらの方法の実証的研究を提供します。 
[概要]多くの2.5dセグメンテーション手法が、より少ないコストで体積空間情報を利用するために提案されています。これは、3dcnnが250万年前により高い尤度時間と計算に苦しんでいるという事実にもかかわらずです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Experimental Quantum Generative Adversarial Networks for Image
  Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_7.html">
      <font color="black">Experimental Quantum Generative Adversarial Networks for Image
  Generation</font>
    </a>
  </h2>
  <font color="black">私たちの仕事は、短期量子デバイスで高度な量子生成モデルを開発するためのガイダンスを提供し、さまざまなGAN関連の学習タスクにおける量子の利点を探求するための道を開きます。量子機械学習は、短期の最初の実用的なアプリケーションの1つになると期待されています。用語量子デバイス..さらに、グレースケールバーデータセットを利用して、Fr \ &#39;echet Distanceスコアによってベンチマークされた、それぞれ多層知覚および畳み込みニューラルネットワークアーキテクチャに基づく量子GANと古典的なGANの間の競争力のあるパフォーマンスを示します。 
[ABSTRACT]量子ボーダは、古典的なガンよりも指数関数的に有利になる可能性があるため、幅広い注目を集めています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Weight Perturbation Helps Robust Generalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_8.html">
      <font color="black">Adversarial Weight Perturbation Helps Robust Generalization</font>
    </a>
  </h2>
  <font color="black">広範な実験により、AWPは確かにフラットな減量ランドスケープをもたらし、さまざまな既存の敵対者トレーニング方法に簡単に組み込んで、敵対者の堅牢性をさらに高めることができます。ただし、広く使用されている減量ランドスケープ（体重に対する損失の変化）が敵対者でどのように機能するかトレーニングが検討されることはめったにありません。早期打ち切り、新しい目的関数の設計、ラベルのないデータの活用など、よく知られている敵対的なトレーニングの改善はすべて、暗黙のうちに減量の状況を平坦化します。 
[ABSTRACT]敵対的なトレーニングは最も有望なものであり、敵対的な摂動の例を使用して入力損失の状況を平坦化します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-13">
        <br><font color="black">2020-04-13</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Understanding Pixel Vulnerability under Adversarial Attacks for
  Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_9.html">
      <font color="black">Towards Understanding Pixel Vulnerability under Adversarial Attacks for
  Images</font>
    </a>
  </h2>
  <font color="black">したがって、分類器の予測をより簡単に変更できる画像の最も脆弱なピクセルに摂動を課すことが重要です。ピクセルの脆弱性により、既存の攻撃が与えられると、敵の画像をより現実的にし、検出しにくくすることができます。摂動は少なくなりますが、攻撃パフォーマンスは同じに保たれます。ただし、通常、人間と敵対攻撃検出アルゴリズムの両方で、より簡単に検出可能な敵対画像が得られます。 
[概要]これらには、実際の画像のすべてのピクセルに小さな摂動を追加することが含まれますが、通常、より簡単に検出可能な敵対的な画像になります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Scenic: A Language for Scenario Specification and Data Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_10.html">
      <font color="black">Scenic: A Language for Scenario Specification and Data Generation</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、自動運転車やロボットなど、任意の時点での環境が「シーン」、物理オブジェクトとエージェントの構成であるシステムに焦点を当てます。確率的プログラミング言語として、Scenicではの機能に分布を割り当てることができます。シーン、およびシーンにハードとソフトの制約を宣言的に課します。サイバー物理システム、特に機械学習に基づくシステムの設計と分析のための新しい確率的プログラミング言語を提案します。 
[概要]これらには、まれなイベントに対して堅牢であるかどうかのシステムのテスト、さまざまな条件下でのパフォーマンスのテスト、および障害の種類が含まれます。より一般的には、このような言語を使用して環境モデルを作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Ice Layer Tracking and Thickness Estimation using Fully
  Convolutional Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_11.html">
      <font color="black">Deep Ice Layer Tracking and Thickness Estimation using Fully
  Convolutional Networks</font>
    </a>
  </h2>
  <font color="black">この手順により、約3.6ピクセルの平均絶対誤差内の氷層の厚さを推定することができました。推定された厚さを分析して、毎年の積雪を理解できます。各氷層を一意に検出した後、その厚さを計算して比較します。利用可能なグラウンドトゥルースでそれ。 
[概要]推定厚さを分析して、毎年の積雪を理解することができます。各氷層を理解するために、その厚さを計算し、利用可能なグラウンドトゥルースと比較します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Spatially-Variant CNN-based Point Spread Function Estimation for Blind
  Deconvolution and Depth Estimation in Optical Microscopy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_12.html">
      <font color="black">Spatially-Variant CNN-based Point Spread Function Estimation for Blind
  Deconvolution and Depth Estimation in Optical Microscopy</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、光学セットアップに関する先験的な知識を最小限に抑えて、平坦でないオブジェクトの画像を強調するための複数の可能性を開きます。具体的には、畳み込みニューラルネットワークを使用して空間的に変化する点像分布関数（PSF）モデルのパラメーターを推定します。機器またはオブジェクト固有のキャリブレーションを必要としないネットワーク（CNN）。私たちの方法は、オブジェクトの回転、照明の変化に対してロバストでありながら、理想的な条件で最大0.99のピアソン相関係数の2乗で画像自体からPSFパラメーターを回復します。 、またはフォトンノイズ。 
[ABSTRACT]畳み込みニューラルネットワーク（cnn）を使用して、空間-バリアント点-広がり関数（psf）モデルのパラメーターを推定します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Attn-HybridNet: Improving Discriminability of Hybrid Features with
  Attention Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_13.html">
      <font color="black">Attn-HybridNet: Improving Discriminability of Hybrid Features with
  Attention Fusion</font>
    </a>
  </h2>
  <font color="black">ハイブリッド特徴の識別性を高めるために、注意ベースの特徴融合を実行することによって特徴の冗長性を軽減するAttn-HybridNetを提案します。次に、PCANetとTFNetによって取得された情報が特徴的で重要であるが、個別に不十分であることを示します。 ..主成分分析ネットワーク（PCANet）は、教師なしの倹約的な深いネットワークであり、畳み込み層のフィルターとして主成分を利用します。 
[ABSTRACT] pcanetは、principalfnetや空間プーリングなどの基本的な操作で構成されていますが、主要なコンポーネントを含む2つの基本的な問題があります。また、自然画像の空間統計に対応できません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Map-Based Temporally Consistent Geolocalization through Learning Motion
  Trajectories -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_14.html">
      <font color="black">Map-Based Temporally Consistent Geolocalization through Learning Motion
  Trajectories</font>
    </a>
  </h2>
  <font color="black">予測シーケンスはグラフ構造のマップでトポロジー的に接続されている必要があることを考慮して、切断されたシーケンス予測を排除するために2つの異なる仮説の生成および排除戦略を採用します。時間的に一貫したジオロケーションは、提案された戦略の両方で予測できます。この論文では、オブジェクトの時間的に一貫したジオローカリゼーションのために反復ニューラルネットワークを使用してトポロジカルマップ上のモーション軌跡を活用する新しい軌道学習方法を提案します。 
[概要]私たちの軌道学習方法は、軌道のパターン表現を学習します。これは、ナビゲーションでの自己運動の距離と方向の両方を認識する人間の能力に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Two-Stream Compare and Contrast Network for Vertebral Compression
  Fracture Diagnosis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_15.html">
      <font color="black">Two-Stream Compare and Contrast Network for Vertebral Compression
  Fracture Diagnosis</font>
    </a>
  </h2>
  <font color="black">このネットワークは、隣接する椎骨間の比較と対比を通じてVCFの識別を学習する認識ストリームと、クラス内とクラス間を比較および対比してきめ細かい分類の機能を学習する分類ストリームの2つのストリームで構成されます。椎骨、良性VCF、および悪性VCF ..ただし、VCFの認識と分類には非常に異なる機能が必要であり、両方のタスクは、クラス内の変動が大きく、クラス間の類似性が高いという特徴があります。 
[概要]悪性（tsccn）システムはvcfsを処理するように設計されています。これは、異なるタイプの分類問題に基づいています。ただし、必要な機能は大きく異なり、両方のタスクは、クラス内の変動が大きく、クラス間のばらつきが大きいという特徴があります。類似性</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Matching Guided Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_16.html">
      <font color="black">Matching Guided Distillation</font>
    </a>
  </h2>
  <font color="black">b）ランダム初期化または特別な変換を使用する適応モジュールは、事前にトレーニングされた学生の蒸留には適していません。MGDには、計算コストがごくわずかな正規化またはプーリング操作しか含まれていないため、他の蒸留方法でネットワークにプラグインする柔軟性があります。全体的なトレーニングでは、2つの最適化オブジェクト（割り当ての更新とパラメーターの更新）間で座標降下法を採用します。 
[概要]教師と生徒の中間機能間の意味機能構造のギャップは一般的な障害です。これは、教師と南部の変更の変更が必要な方法を説明しています。適応モジュールは、トレーニングにより多くのパラメータをもたらしますが、これには2つの問題が追加されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-23">
        <br><font color="black">2020-08-23</font>
      </time>
    </span>
</section>
<!-- paper0: Contrast and Classify: Alternate Training for Robust VQA -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_17.html">
      <font color="black">Contrast and Classify: Alternate Training for Robust VQA</font>
    </a>
  </h2>
  <font color="black">クロスエントロピーと対照的な損失を交互に最適化する新しいトレーニングパラダイム（ConCAT）を提案します。最近の視覚的質問応答（VQA）モデルは、VQAベンチマークで印象的なパフォーマンスを示していますが、入力質問の小さな言語変化に敏感なままです。これらのアプローチ結合されたデータを使用して、標準のクロスエントロピー損失を最小化することにより、回答分類子を学習します。 
[要約]データセットを制御するための以前の試みは、対照的な学習によって行われていました。損失は、表現が質問の言語的変化に対してロバストになることを促進します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: VisualNews : Benchmark and Challenges in Entity-aware Image Captioning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_18.html">
      <font color="black">VisualNews : Benchmark and Challenges in Entity-aware Image Captioning</font>
    </a>
  </h2>
  <font color="black">具体的には、エンティティ認識モジュールとエンティティガイドアテンションレイヤーを提案して、名前付きエンティティのより正確な予測を促進します。この方法では、GoodNewsデータセットとVisualNewsデータセットの両方で最先端の結果が得られますが、大幅に少なくなります。競合する方法よりもパラメータ..提案された方法は、視覚的特徴とテキスト的特徴を効果的に組み合わせて、イベントやエンティティなどのより豊富な情報を含むキャプションを生成することができます。 
[概要]提案された方法は、視覚的機能と文学的機能を組み合わせて、イベントやエンティティなどのより豊富な情報を含むキャプションを生成することができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Which Model to Transfer? Finding the Needle in the Growing Haystack -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_19.html">
      <font color="black">Which Model to Transfer? Finding the Needle in the Growing Haystack</font>
    </a>
  </h2>
  <font color="black">最高スコアのImageNetモデルを選択する）およびタスクを意識した検索戦略（線形またはkNN評価など）。次に、既存のアプローチよりも優れた、シンプルで計算効率の高いハイブリッド検索戦略を提案します。これらのリポジトリは指数関数的に成長し続けるため、効率的に選択します。手元のタスクに適したモデルが最も重要になります。 
[概要]ハブなどの豊富なモデルリポジトリの出現により、実務家や研究者は、幅広いダウンストリームタスクにわたってこれらのモデルの可能性を解き放つことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Land Cover Semantic Segmentation Using ResUNet -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_20.html">
      <font color="black">Land Cover Semantic Segmentation Using ResUNet</font>
    </a>
  </h2>
  <font color="black">私たちの関心分野はイオニア諸島（ギリシャ）です。ただし、それらのモデルは私たちよりもはるかに大きなデータセットにトレーニングされているため、これらのネットワークの機能を利用して、事前にトレーニングされたモデルをアウトネットワークの最初の部分として使用して転移学習を適用しました衛星画像から有用な特徴を抽出するために開発されました（事前にトレーニングされたResNet50をU-Res-Netに転送しました）。モデルについては、U-Netアーキテクチャのバリエーションが適用されました。 
[概要]システムは、入力としてエリアの衛星画像を取得し、入力と同じ解像度でエリアのマップを配信します。たとえば、u-ネットアーキテクチャのバリエーションが適用されました。結果は、3clcクラス階層でテストされます。レベル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Self-paced Contrastive Learning with Hybrid Memory for Domain Adaptive
  Object Re-ID -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_21.html">
      <font color="black">Self-paced Contrastive Learning with Hybrid Memory for Domain Adaptive
  Object Re-ID</font>
    </a>
  </h2>
  <font color="black">従来の対照学習戦略とは異なり、提案されたフレームワークは、ソースドメインクラス、ターゲットドメインクラスター、およびクラスター化されていないインスタンスを共同で区別します。最も重要なことは、提案されたセルフペース方式は、ハイブリッドメモリを改良するためのより信頼性の高いクラスターを徐々に作成し、学習目標であり、卓越したパフォーマンスの鍵であることが示されています。このメソッドは、オブジェクトre-IDの複数ドメイン適応タスクで最先端のパフォーマンスを上回り、追加の注釈なしでソースドメインのパフォーマンスを向上させます。 
[ABSTRACT]最先端の疑似ラボ手法は大きな成功を収めましたが、ドメインのギャップと不十分なクラスタリングパフォーマンスのために、すべての貴重な情報を十分に活用していませんでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-04">
        <br><font color="black">2020-06-04</font>
      </time>
    </span>
</section>
<!-- paper0: Coarse-To-Fine Visual Localization Using Semantic Compact Map -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_22.html">
      <font color="black">Coarse-To-Fine Visual Localization Using Semantic Compact Map</font>
    </a>
  </h2>
  <font color="black">合成データセットと現実的なデータセットの両方でシステムを評価し、2つのベースライン、最先端のセマンティック機能ベースのシステムと従来のSIFT機能ベースのシステムと比較します。都市車両の堅牢な視覚的ローカリゼーションは依然として困難で未解決です。 。ローカリゼーションは、パーティクルフィルタによって実行され、その後、ポーズアラインメントモジュールが変換と回転を分離して、精度を向上させます。 
[概要]コンピューティング効率とメモリサイズの制限により、大規模なアプリケーションでは困難になっています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-11">
        <br><font color="black">2019-10-11</font>
      </time>
    </span>
</section>
<!-- paper0: DotSCN: Group Re-identification via Domain-Transferred Single and Couple
  Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_23.html">
      <font color="black">DotSCN: Group Re-identification via Domain-Transferred Single and Couple
  Representation Learning</font>
    </a>
  </h2>
  <font color="black">広範な実験結果は、RoadGroupデータセットで11.7 \％CMC-1、DukeMCMTデータセットで39.0 \％CMC-1だけ、最先端の方法を大幅に上回るアプローチの有効性を示しています。優位性を獲得するため。ディープラーニングモデルでは、グループを複数の人として扱い、ラベル付きReIDデータセットのドメインをG-ReIDターゲットデータセットスタイルに転送して、単一の表現を学習します。そのメリットは2つの側面です。1）ラベル付きトレーニングがないためサンプル、既存のG-ReIDメソッドは、主に不十分な手作りの機能に依存しています。 
[概要]たとえば、転送された単一およびカップル表現学習ネットワーク（tscn）を提案し、深層学習モデルの優位性を獲得するために、グループを複数の人として扱い、ラベル付けされたリードタスクのドメインをag-リードターゲットに転送します単一の表現を学習するためのデータセットスタイル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-13">
        <br><font color="black">2019-05-13</font>
      </time>
    </span>
</section>
<!-- paper0: Satellite Image Classification with Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_24.html">
      <font color="black">Satellite Image Classification with Deep Learning</font>
    </a>
  </h2>
  <font color="black">ディープラーニングは、そのようなタスクの自動化に有望な機械学習アルゴリズムのファミリーです。畳み込みニューラルネットワークによって画像理解に成功しました。この論文では、それらをオブジェクトと施設の認識の問題に適用します。高解像度のマルチスペクトル衛星画像で。 
[概要]これらのアプリケーションでは、画像内のオブジェクトと施設を手動で識別する必要がありますが、従来のオブジェクト検出および分類アルゴリズムは、問題を解決するには不正確で信頼性が低くなります。畳み込みニューラルネットワークによる画像理解に成功しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: RNN Training along Locally Optimal Trajectories via Frank-Wolfe
  Algorithm -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_25.html">
      <font color="black">RNN Training along Locally Optimal Trajectories via Frank-Wolfe
  Algorithm</font>
    </a>
  </h2>
  <font color="black">特定の条件下で、アルゴリズムが$ \ epsilon $エラーに対して$ O（1 / \ epsilon）$の劣線形収束率を持っていることを証明します。また、深いRNNアーキテクチャを実験し、効率的なトレーニングパフォーマンスを示します。新しいFrank-Wolfeメソッド。これは、本質的に、再起動スキームを備えたSGDアルゴリズムです。 
[ABSTRACT]私たちの方法は、新しい率直なウルフ法につながります。これは、本質的に、再起動スキームを備えたsgdアルゴリズムです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: Machine learning for COVID-19 detection and prognostication using chest
  radiographs and CT scans: a systematic methodological review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_26.html">
      <font color="black">Machine learning for COVID-19 detection and prognostication using chest
  radiographs and CT scans: a systematic methodological review</font>
    </a>
  </h2>
  <font color="black">これは、緊急に必要とされる安全な臨床実装の鍵です。方法：この系統的レビューでは、2020年1月1日から2020年6月24日までにアップロードされた公開論文とプレプリントについて、OVID経由のEMBASE、PubMed経由のMEDLINE、bioRxiv、medRxiv、arXivをレビューしました。 ..したがって、作成者は、確立された機械学習チェックリストを使用して、十分なドキュメントが利用可能であることを確認し、PROBAST（バイアス評価ツールの予測モデルリスク）フレームワークに従って、モデル開発プロセスの根本的なバイアスを決定し、これらを軽減することをお勧めします。可能。 
[概要]この系統的レビューでは、急速に成長している文献で採用されている機械学習手法を批判的に評価します。検証済みのcovid-19モデルが必要である緊急性を考えると、これは大きな弱点です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-14">
        <br><font color="black">2020-08-14</font>
      </time>
    </span>
</section>
<!-- paper0: ISTA-NAS: Efficient and Consistent Neural Architecture Search by Sparse
  Coding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_27.html">
      <font color="black">ISTA-NAS: Efficient and Consistent Neural Architecture Search by Sparse
  Coding</font>
    </a>
  </h2>
  <font color="black">その結果、検索用の密なスーパーネットはトレーニングが非効率的であり、評価用に投影されたアーキテクチャとのギャップがあります。元のスパースソリューションと同じ検証損失を持つ圧縮された低次元空間で微分可能検索を実行します。スペースを確保し、スパースコーディングの問題を解決してアーキテクチャを回復します。そうすることで、更新のたびに検索するネットワークがスパース性の制約を満たし、効率的にトレーニングできます。 
[概要]現在の検索ベースのNASメソッドは、検索フェーズでスパース性を無視することがよくありますが、後処理によって最適化されたソリューションを高密度のソリューションに投影します。検索とアーキテクチャの回復は、別の方法で最適化されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Three-Dimensional Lip Motion Network for Text-Independent Speaker
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_28.html">
      <font color="black">Three-Dimensional Lip Motion Network for Text-Independent Speaker
  Recognition</font>
    </a>
  </h2>
  <font color="black">さまざまな唇領域で注目を集めるために、新しい地域フィードバックモジュール（RFM）が提案されています。唇の動きは話者の行動特性を反映しているため、話者認識における新しい種類の生体認証として使用できます。さらに、唇の動きに関する事前知識ランドマークレベルとフレームレベルの特徴がマージされてより良い特徴表現を形成するRFMを補完するために調査されます。 
[概要]提案された3lmnetは、2D唇画像と3D顔を使用した最先端技術よりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: CurbScan: Curb Detection and Tracking Using Multi-Sensor Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_29.html">
      <font color="black">CurbScan: Curb Detection and Tracking Using Multi-Sensor Fusion</font>
    </a>
  </h2>
  <font color="black">検出アルゴリズムは、単一の3D LiDARと、候補の縁石の特徴を検出するために使用されるモノカメラセンサーに基づいており、周囲の静的および移動する障害物から生じる誤検知を効果的に除去します。信頼性の高い縁石検出は、都市環境での安全な自動運転にとって重要です。追跡アルゴリズムの検出精度は、カルマンフィルターベースの予測と低コストの超音波センサーからの横方向の距離情報との融合を使用することによって向上します。 
[概要]このシステムは、単一の3D LIDARと、縁石の候補の特徴を検出するために使用されるモノカメラセンサーに基づいています。周囲の静的および移動する障害物から誤った距離情報を効果的に削除します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-09">
        <br><font color="black">2020-10-09</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Road Signs Detection performance by Combining the Features of
  Hough Transform and Texture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_30.html">
      <font color="black">Improving Road Signs Detection performance by Combining the Features of
  Hough Transform and Texture</font>
    </a>
  </h2>
  <font color="black">この段階は、ハラリック特徴とゼルニケモーメントの抽出によって改善されます。セグメンテーション段階は、画像内の関心領域（ROI）を決定するのに役立ちます。ランダム化ハフ変換（RHT）は、円形および八角形の形状を検出するために使用されます。 。 
[概要]道路標識検出の研究はアラブの文脈で行われていますが、道路標識を使用するにはまだ研究が不十分です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Deep Learning on Medical Images: A Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_31.html">
      <font color="black">3D Deep Learning on Medical Images: A Review</font>
    </a>
  </h2>
  <font color="black">この論文では、3D CNNが機械学習のルーツからどのように開発されたかの歴史をたどり、3D CNNの簡単な数学的説明を提供し、医療画像を3DCNNに供給する前に必要な前処理ステップを提供します。機械学習では、グラフィックス処理技術と医療画像データの可用性により、医療分野での深層学習モデルの使用が急速に増加しています。医療画像での3DCNNの使用に関連する課題について説明します。ドメイン（および一般的な深層学習モデルの使用）と、この分野で考えられる将来の傾向。 
[概要]近年、医用画像の分析に3d 3d 3d cnnsが採用されています。これは、畳み込みニューラルネットワーク（cnn）ベースのアーキテクチャが急速に進歩したためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-01">
        <br><font color="black">2020-04-01</font>
      </time>
    </span>
</section>
<!-- paper0: BoMuDA: Boundless Multi-Source Domain Adaptive Segmentation in
  Unconstrained Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_32.html">
      <font color="black">BoMuDA: Boundless Multi-Source Domain Adaptive Segmentation in
  Unconstrained Environments</font>
    </a>
  </h2>
  <font color="black">各反復で、単一ソースDAは最初に選択されたソースでニューラルネットワークを学習し、次に残りのソースを使用してマルチソース微調整ステップを実行します。インドの運転データセットを使用して広範な実験とアブレーション研究を実施しました。 、CityScapes、Berkeley DeepDrive、GTA V、およびSynscapesデータセット、および教師なしアプローチが他の教師なしおよび半教師ありSOTAベンチマークより5.17％〜42.9％優れており、モデルサイズが最大5.2倍縮小されていることを示しています。このトレーニングルーチンは、Alternating-Incremental（ &quot;Alt-Inc&quot;）アルゴリズムです。 
[概要]シングルソースドメインドライブとマルチソース蒸留を交互に行う新しいトレーニング戦略を提案します。このシステムは、一貫性のないインクリメンタル（alt-inc）メソッドと呼ばれます。トレーニングデータセットに属さないカテゴリを明示的に分類できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-22">
        <br><font color="black">2020-09-22</font>
      </time>
    </span>
</section>
<!-- paper0: Electroencephalography signal processing based on textural features for
  monitoring the driver's state by a Brain-Computer Interface -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_33.html">
      <font color="black">Electroencephalography signal processing based on textural features for
  monitoring the driver's state by a Brain-Computer Interface</font>
    </a>
  </h2>
  <font color="black">1D-LBPは、信号の相互変動を短いビットコードとして一時的に「閉じる」ことを検出することでそれらを記述できます。さらに、全体的なパフォーマンスはまだ十分ではありませんが、EEG信号からのクラス遷移をキャプチャすることは効果的です。実環境でのドライバーの警戒を評価するためのBCIを開発する。私たちの分析により、1D-LBPの採用によりパフォーマンスが大幅に向上したと結論付けることができます。 
[概要]アイデアには、前処理された脳波データからの特徴抽出のためのアルゴリズムの使用が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Correlation Filter for UAV-Based Aerial Tracking: A Review and
  Experimental Evaluation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_34.html">
      <font color="black">Correlation Filter for UAV-Based Aerial Tracking: A Review and
  Experimental Evaluation</font>
    </a>
  </h2>
  <font color="black">最近、識別相関フィルター（DCF）ベースのトラッカーは、単一のCPUでの高い計算効率と魅力的な堅牢性で際立っており、UAVビジュアルトラッキングコミュニティで栄えています。さらに、徹底的かつ定量的な実験がさまざまな分野で拡張されています。普及しているUAV追跡ベンチマーク、つまりUAV123、UAV123_10fps、UAV20L、UAVDT、DTB70、VisDrone2019-SOTは、合計371,625フレームを含みます。前述のように、UAVベースの空中追跡プラットフォームは研究から実用化まで徐々に開発されてきました。アプリケーション段階で、将来的に主要な空中リモートセンシング技術の1つに到達します。 
[ABSTRACT]風の状態、UAVの機械構造の振動、限られた計算リソースに基づくすべてが、搭載された追跡方法にとって重要です。これは、20の最先端のdcfベースのトラッカーが整然としていることに基づいています。彼らの革新によると</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: DORi: Discovering Object Relationship for Moment Localization of a
  Natural-Language Query in Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_35.html">
      <font color="black">DORi: Discovering Object Relationship for Moment Localization of a
  Natural-Language Query in Video</font>
    </a>
  </h2>
  <font color="black">さらに、時間サブグラフは、時間の経過に伴うビデオ内のアクティビティをキャプチャします。私たちの重要な革新は、人間、オブジェクト、およびの間の関係をキャプチャする時間モーメントのローカリゼーションに適した言語条件付きメッセージパッシングアルゴリズムを介して埋め込まれたビデオ機能を学習することです。ビデオ内のアクティビティ..クエリ文が与えられた場合の目標は、ビデオ内の関連するセグメントの開始と終了を決定することです。 
[ABSTRACT]私たちの方法は3つの標準ベンチマークデータセットで評価されます。また、このタスクの新しい自然ベンチマークとしてyoucookiiを紹介します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: BOP Challenge 2020 on 6D Object Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_36.html">
      <font color="black">BOP Challenge 2020 on 6D Object Localization</font>
    </a>
  </h2>
  <font color="black">ディープニューラルネットワークに基づく方法は、以前の版の課題を支配していたポイントペア機能に基づく方法にようやく追いつきました。最高の方法はRGB-D画像チャネルに依存していますが、RGBチャネルのみで強力な結果が得られました。トレーニングとテストの両方で使用されました。評価された26の方法のうち、3番目の方法はPBRと実画像のRGBチャネルでトレーニングされ、5番目の方法はPBR画像のRGBチャネルでのみトレーニングされました。強力なデータ拡張が重要であると特定されました。最高性能のCosyPoseメソッドのコンポーネントであり、PBR画像のフォトリアリズムは増強にもかかわらず効果的であることが実証されました。 
[概要]パフォーマンスの高い方法は、rgb-d画像チャネルに依存しています。rgbチャネルのみを使用した場合に強力な結果が得られました。オンライン評価システムは開いたままで、Webサイトで入手できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: A Scale and Rotational Invariant Key-point Detector based on Sparse
  Coding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_37.html">
      <font color="black">A Scale and Rotational Invariant Key-point Detector based on Sparse
  Coding</font>
    </a>
  </h2>
  <font color="black">キーポイントの特性スケールとそのサブピクセル精度位置を計算する手法も提案されています。SCK検出器はさまざまなシナリオで柔軟性があり、アフィン強度の変化に対して完全に不変ですが、劇的なスケールの画像を処理するようには設計されていません。回転の変化..SRI-SCKでは、スケール不変性は画像ピラミッド手法で実装され、回転不変性はSCKのスパースコーディングステップで使用される辞書の複数の回転バージョンを組み合わせることで実現されます。 
[要約]新しい論文は、スケール不変性を有用で有用なキーポイント検出器（sck）に組み合わせることにより、この問題の解決策を提案しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: SD-RSIC: Summarization Driven Deep Remote Sensing Image Captioning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_38.html">
      <font color="black">SD-RSIC: Summarization Driven Deep Remote Sensing Image Captioning</font>
    </a>
  </h2>
  <font color="black">提案されたアプローチのコードは、https：//gitlab.tubit.tu-berlin.de/rsim/SD-RSICで公開されています。2番目のステップは、既存のRS画像のキャプション方法とは異なり、のグラウンドトゥルースキャプションを要約したものです。シーケンスを活用してニューラルネットワークをシーケンスし、トレーニングセットに存在する冗長性を排除することにより、各トレーニング画像を単一のキャプションに変換します。提案されたアプローチは、3つの主要なステップで構成されます。 
[概要]新しいdnnベースのアプローチは、キャプション付きの多数のrs画像で構成されるトレーニングセットの可用性に依存しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
</section>
<!-- paper0: A review of 3D human pose estimation algorithms for markerless motion
  capture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_39.html">
      <font color="black">A review of 3D human pose estimation algorithms for markerless motion
  capture</font>
    </a>
  </h2>
  <font color="black">さらに、さまざまなポーズ推定システムのメトリック、ベンチマーク、および構造を分析し、将来の研究のためにいくつかの方向性を提案します。精度、速度、および堅牢性のパフォーマンス基準に基づいて、分類法を使用して既存の方法を分類することをお勧めします。過去3年間の20の方法。 
[概要]過去5年間で、マーカーレスモーションキャプチャ技術の平均エラーは、今日では10cm以上から2cm未満に減少しています。過去3年間の20以上の方法を確認します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning for Recognizing Mobile Targets in Satellite Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_40.html">
      <font color="black">Deep Learning for Recognizing Mobile Targets in Satellite Imagery</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、分類用の畳み込みニューラルネットワーク（CNN）を、検出用のスライディングウィンドウアルゴリズムに拡張する方法について説明します。このような自動ターゲット認識（ATR）ソフトウェアのアプリケーションには、経済予測、交通計画、海事法執行、災害対応などがあります。飛行機、車、船などのモバイルターゲットを衛星画像で自動的に検出して分類するソフトウェアの需要が高まっています。 
[概要]このような自動目標認識ソフトウェアのアプリケーションには、経済予測、交通計画、海事法執行、災害対応などがあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: LM-Reloc: Levenberg-Marquardt Based Direct Visual Relocalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_41.html">
      <font color="black">LM-Reloc: Levenberg-Marquardt Based Direct Visual Relocalization</font>
    </a>
  </h2>
  <font color="black">学習した機能により、特にさまざまな条件での再ローカリゼーションにおいて、直接画像アライメントの堅牢性が大幅に向上します。したがって、この方法では、コーナーだけでなく、画像の任意の領域に勾配を付けることができます。LM-Relocを紹介します。直接画像アライメントに基づく視覚的な再ローカリゼーション。 
[概要]提案された方法は、機能のマッチングやransacに依存していません。代わりに、ransacなどの結果に依存していません。この方法は、結果の欠如に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Weaponizing Unicodes with Deep Learning -- Identifying Homoglyphs with
  Weakly Labeled Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_42.html">
      <font color="black">Weaponizing Unicodes with Deep Learning -- Identifying Homoglyphs with
  Weakly Labeled Data</font>
    </a>
  </h2>
  <font color="black">私たちのモデルは、ペアワイズホモグリフ識別の正規化圧縮距離アプローチを大幅に上回り、平均精度0.97を達成しています。視覚的に類似した文字またはホモグリフを使用して、ソーシャルエンジニアリング攻撃を実行したり、スパムや盗用検出器を回避したりできます。予測されるホモグリフのコードとリストはGithubにアップロードされます：https：//github.com/PerryXDeng/weaponizing_unicode 
[要約]ホモグリフ（特に以前に発見されていないもの）を識別する攻撃者の能力を理解することが重要です。アプローチは、ほとんどの文字がホモグリフではないという事実から生じる弱いラベルを独自に利用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-09">
        <br><font color="black">2020-10-09</font>
      </time>
    </span>
</section>
<!-- paper0: Similarity Based Stratified Splitting: an approach to train better
  classifiers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_43.html">
      <font color="black">Similarity Based Stratified Splitting: an approach to train better
  classifiers</font>
    </a>
  </h2>
  <font color="black">多層パーセプトロン、サポートベクターマシン、ランダムフォレスト、K最近傍法などの分類器と、Cityblock、Chebyshev、Cosine、Correlation、Euclideanの5つの類似関数を使用して、22のベンチマークデータセットで提案を評価します。 Wilcoxon Sign-Rankテスト、私たちのアプローチは、評価されたシナリオの75 \％で、通常の階層化された10倍の相互検証を一貫して上回りました。この戦略は、実際のアプリケーションで使用すると、より現実的なパフォーマンス推定につながります。 
[概要]分割は、サンプル間の類似性関数を使用して生成されます。この戦略により、より現実的なパフォーマンス推定が可能になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: VisualWordGrid: Information Extraction From Scanned Documents Using A
  Multimodal Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_44.html">
      <font color="black">VisualWordGrid: Information Extraction From Scanned Documents Using A
  Multimodal Approach</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、パブリックおよびプライベートのドキュメント画像データセットでテストされ、最近の最先端の方法と比較して高いパフォーマンスを示しています。フィールド抽出を実行するためのスキャンされたドキュメント表現の新しいアプローチを紹介します。最近のChargridを改善します。 Wordgridモデルはいくつかの方法で、最初に視覚モダリティを考慮に入れ、次に推論時間を低く保ちながら小さなデータセットに関する堅牢性を高めることによってモデル化します。 
[概要]私たちのアプローチは、パブリックドキュメントとプライベートドキュメントでテストされています-画像データセット。最近の最先端の方法と比較して、より高いパフォーマンスを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: High Speed Event Camera TRacking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_45.html">
      <font color="black">High Speed Event Camera TRacking</font>
    </a>
  </h2>
  <font color="black">この作業では、このセンシングテクノロジーの限界を探り、25.8 gを超えるダイナミクス、スループット10 kHz、1回あたり100万を超えるイベントを処理する6自由度のモーションを推定できる超高速トラッキングアルゴリズムを紹介します。第二に..この方法には、非常に高速な異常除去を伴う投影されたラインセグメントとイベントを照合するための堅牢なメカニズムが含まれています。比較とパフォーマンス分析のために、さまざまな複雑さのさまざまなモーションモデルが考慮されます
[要約]システムは追跡可能ですカメラの動きまたはオブジェクトの動き。エラーを使用します-嘘で設計された状態カルマンフィルター-理論的な意味</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: COVID-19 Imaging Data Privacy by Federated Learning Design: A
  Theoretical Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_46.html">
      <font color="black">COVID-19 Imaging Data Privacy by Federated Learning Design: A
  Theoretical Framework</font>
    </a>
  </h2>
  <font color="black">COVID-19ヘルスケアの課題に対処するには、健康データ、知識、リソースをグローバル規模で頻繁に共有する必要があります。フェデレーション機械学習システムの提案された設計の評価について説明し、設計による差分プライバシー（dPbD）フレームワークがどのようにできるかについて説明します。スケーラビリティと堅牢性を備えたフェデレーション学習システムのデータプライバシーを強化します。スケーラブルで差別化されたプライベートフェデレーション学習設計は、COVID19の課題に対処するために必要な、安全でプライベートな協調的な機械学習モデルを構築するための有望なソリューションであると主張します。 
[概要]コンピュータビジョンと深層学習アプローチによる疾患診断のためのcovid-19画像データプライバシーの問題シナリオについて説明します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: S3K: Self-Supervised Semantic Keypoints for Robotic Manipulation via
  Multi-View Consistency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_47.html">
      <font color="black">S3K: Self-Supervised Semantic Keypoints for Robotic Manipulation via
  Multi-View Consistency</font>
    </a>
  </h2>
  <font color="black">画像の再構築、潜在空間の滑らかさ、制御の有用性、または特定の機能（境界ボックス、セグメンテーションなど）で注釈が付けられた大きなデータセットを利用します。セマンティックキーポイントを見つけるこの機能により、人間の高レベルのスクリプトが可能になることを示します。理解できる振る舞い..これらの困難は、これらのモデルの幾何学的構造の欠如から生じると私たちは主張します。 
[要約]視覚表現学習への多くの既存のアプローチは、汎用のトレーニング基準を利用しています。 。再構築によって..アディダスなどの多くの既存のモデルは、詳細をキャプチャできません-センシングなどの特定のオブジェクトの精密タスクに必要な詳細</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-30">
        <br><font color="black">2020-09-30</font>
      </time>
    </span>
</section>
<!-- paper0: Does my multimodal model learn cross-modal interactions? It's harder to
  tell than you might think! -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_48.html">
      <font color="black">Does my multimodal model learn cross-modal interactions? It's harder to
  tell than you might think!</font>
    </a>
  </h2>
  <font color="black">7つの画像+テキスト分類タスク（それぞれに新しい最先端のベンチマークを設定）の場合、多くの場合、クロスモーダル相互作用を削除してもパフォーマンスの低下はほとんどまたはまったくないことがわかります。クロスモーダル相互作用が特定のタスクで特定のモデルのパフォーマンスを向上させるかどうかを分離するための新しい診断ツール、経験的マルチモーダル加法的関数投影（EMAP）。したがって、マルチモーダル機械学習の研究者は、ユニモーダルベースラインだけでなく、最もパフォーマンスの高いモデルのEMAP。 
[ABSTRACT]クロスモーダル相互作用が排除され、加法的なユニモーダル構造が分離されます。ただし、新しいブラックボックス相互作用は主にユニモーダル信号を利用しています。これは、クロスモーダル相互作用の観測に基づいていないためです。これは、次の場合でも当てはまります。相互作用を考慮する能力を備えた表現力豊かなモデル、そうでなければ表現力の低いモデルよりも優れている</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Wandering Within a World: Online Contextualized Few-Shot Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_49.html">
      <font color="black">Wandering Within a World: Online Contextualized Few-Shot Learning</font>
    </a>
  </h2>
  <font color="black">この設定に基づいて、世界内をさまようエージェントの視覚体験を模倣する大規模な屋内画像に基づく新しい数ショットの学習データセットを提案します。現実の世界と同様に、時空間コンテキストの存在が学習を取得するのに役立ちます。過去のスキル、オンラインの数ショット学習設定は、時間の経過とともに変化する基本的なコンテキストも備えています。さらに、人気のある数ショット学習アプローチをオンラインバージョンに変換し、使用できる新しいコンテキストのプロトタイプメモリモデルを提案します。最近の過去からの時空間コンテキスト情報の。 
[ABSTRACT]モデルモデルは、新しいクラスを学習しながらオンラインで評価されます。オブジェクトクラスはコンテキスト内で相互に関連付けられており、正しいコンテキストを推測すると、パフォーマンスが向上する可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: A Generalized Zero-Shot Framework for Emotion Recognition from Body
  Gestures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_50.html">
      <font color="black">A Generalized Zero-Shot Framework for Emotion Recognition from Body
  Gestures</font>
    </a>
  </h2>
  <font color="black">この問題を解決するために、一般化ゼロショット学習（GZSL）フレームワークを導入します。これは、セマンティック記述のみを使用して新しいボディジェスチャの感情状態を推測する3つのブランチで構成されます。2番目のブランチはStacked AutoEncoder（ StAE）は、意味表現を利用して見えないカテゴリからのサンプルを予測する多様な正規化を備えています。この感情分類タスクの特徴表現をよりよく学習するために、3番目のブランチとしてsoftmaxレイヤーを持つ感情分類子をさらに追加します。 
[概要]新しいシステムでは、感情的なジェスチャーを使用して感情を表現します。すべての感情的な身体のジェスチャーを列挙し、カテゴリごとに十分なサンプルを収集することは困難です。しかし、新しい方法では、どの感情的なフレームワークが属するかを正確に判断できません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Evolution for Facial Emotion Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_51.html">
      <font color="black">Deep Evolution for Facial Emotion Recognition</font>
    </a>
  </h2>
  <font color="black">パラメータの数を平均95％削減することができます（たとえば、深い表情の認識は、トレーニング可能なパラメータの数が多いことに起因する2つの課題に直面しています。トレーニング時間の長さと解釈可能性の欠如です。2Mから100kパラメータ）分類精度を損なうことなく。 
[概要]進化的アルゴリズムに基づく新しい方法を提案します。これは、分類パフォーマンスを維持しながら、トレーニング可能なパラメーターの数を減らすことで両方の課題に対処し、場合によっては優れたパフォーマンスを実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-29">
        <br><font color="black">2020-09-29</font>
      </time>
    </span>
</section>
<!-- paper0: Explaining Clinical Decision Support Systems in Medical Imaging using
  Cycle-Consistent Activation Maximization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_52.html">
      <font color="black">Explaining Clinical Decision Support Systems in Medical Imaging using
  Cycle-Consistent Activation Maximization</font>
    </a>
  </h2>
  <font color="black">ただし、限られたデータしか利用できない場合、生成されたマップの品質が低下し、画像にノイズが発生する可能性があります。これは、臨床状況での典型的なシナリオです。洞察..これらの視覚化が肺病変悪性腫瘍分類のためのLIDCデータセットの既存の方法を大幅に上回っているユーザー調査を実施しました。 
[概要]ディープラーニングは、従来の方法よりも医用画像分類に大きな利点を提供します。システムは不透明で理解しにくいと考えられています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-09">
        <br><font color="black">2020-10-09</font>
      </time>
    </span>
</section>
<!-- paper0: RMDL: Recalibrated multi-instance deep learning for whole slide gastric
  image classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_53.html">
      <font color="black">RMDL: Recalibrated multi-instance deep learning for whole slide gastric
  image classification</font>
    </a>
  </h2>
  <font color="black">さらに、私たちの方法は一般的であり、WSIに基づいてさまざまな癌タイプの他の診断タスクに拡張できます。最初に識別インスタンスを選択し、次にこれらのインスタンスを利用して、提案されたRMDLアプローチに基づいて疾患を診断します。設計されたRMDLネットワークは、インスタンスごとの依存関係をキャプチャし、融合された機能から学習した重要度係数に従ってインスタンス機能を再調整することができます。 
[概要]再調整されたマルチインスタンスディープラーニングメソッド（rmdl）は、この課題に対処するように設計されています。融合された機能から学習した重要度係数に従って、インスタンス機能を再調整する際のインスタンスの役割の役割をキャプチャできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Infant Pose Learning with Small Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_54.html">
      <font color="black">Infant Pose Learning with Small Data</font>
    </a>
  </h2>
  <font color="black">人間の姿勢推定領域の成熟度が増すにつれて、そのアプリケーションはますます広くなっています。幼児の動きの分析は、子供の健康と発達の研究において非常に重要なトピックです。私たちは、FiDIPモデルが他の状態よりも優れていることを示しました。乳児の姿勢推定のための最先端の人間の姿勢推定モデル。平均精度（AP）は92.2と高くなっています。 
[ABSTRACT]乳児のポーズデータセットは、体の比率に大きな違いがあるため、乳児のポーズの推定にほとんど成功していません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Batch-Incremental Triplet Sampling for Training Triplet Networks Using
  Bayesian Updating Theorem -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_55.html">
      <font color="black">Batch-Incremental Triplet Sampling for Training Triplet Networks Using
  Bayesian Updating Theorem</font>
    </a>
  </h2>
  <font color="black">ベイジアン更新と共役事前分布を使用して、トレーニングデータの新しいミニバッチを受信することにより、クラスの分布を動的に更新します。これらのマイニング方法の一部はインスタンス間の極端な距離に依存し、その他の方法はサンプリングを利用します。作業では、既存のインスタンスからではなく、データの分布からトリプレットをサンプリングします。 
[概要]最適なトレーニングトリプレットを選択するためのさまざまな手法があります。これらには、埋め込みなどのこれらのタイプの埋め込みが含まれます。これらは、「トリプレットマイニング」と呼ばれるトリプレットマイニング方法と呼ばれます。ただし、確率的マイニングからサンプリングするのではなく、既存の埋め込みインスタンスからのみサンプリングすると、より識別力のある情報を提供できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-10">
        <br><font color="black">2020-07-10</font>
      </time>
    </span>
</section>
<!-- paper0: Collaborative Video Object Segmentation by Multi-Scale
  Foreground-Background Integration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_56.html">
      <font color="black">Collaborative Video Object Segmentation by Multi-Scale
  Foreground-Background Integration</font>
    </a>
  </h2>
  <font color="black">さらに、CFBIは、参照シーケンスと予測シーケンスの間でピクセルレベルのマッチングプロセスとインスタンスレベルのアテンションメカニズムの両方を実行し、CFBIをさまざまなオブジェクトスケールに対して堅牢にします。CFBIに基づいて、マルチスケールマッチング構造を導入し、Atrousマッチングを提案します。戦略により、より堅牢で効率的なフレームワーク、CFBI + ..コード：https：//github.com/zx-yang/CFBI。 
[ABSTRACT] cfbiは、前景オブジェクト領域とそれに対応する背景領域への埋め込みをディスペンスします。新しい方法では、マルチスケールマッチング構造を導入し、大胆なマッチング戦略を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: DoFE: Domain-oriented Feature Embedding for Generalizable Fundus Image
  Segmentation on Unseen Datasets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_57.html">
      <font color="black">DoFE: Domain-oriented Feature Embedding for Generalizable Fundus Image
  Segmentation on Unseen Datasets</font>
    </a>
  </h2>
  <font color="black">深い畳み込みニューラルネットワークは、テストデータセットがトレーニングデータセットと同じ分布である場合、眼底画像セグメンテーションのパフォーマンスを大幅に向上させました。DoFEフレームワークは、目に見えないデータセットで満足のいくセグメンテーション結果を生成し、他のドメイン一般化およびネットワーク正則化方法を上回ります。ドメインナレッジプールを導入して、マルチソースドメインから抽出された以前の情報を学習して記憶します。 
[概要]ディープドメインベースの機能埋め込み（dofe）フレームワークは、複数のソースドメインからの知識を調査することにより、見えないターゲットドメインでのcnnsの一般化能力を向上させることを目的としています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Making Every Label Count: Handling Semantic Imprecision by Integrating
  Domain Knowledge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_58.html">
      <font color="black">Making Every Label Count: Handling Semantic Imprecision by Integrating
  Domain Knowledge</font>
    </a>
  </h2>
  <font color="black">NABirdsとILSVRC2012のノイズの多いバリアントでの実験では、私たちの方法が強力なベースラインを16.4パーセントポイント、現在の最先端技術を最大3.9パーセントポイント上回っていることを示しています。CHILLAX（不正確なラベル学習と注釈のクラス階層）を提案します。 eXtrapolation）は、階層分類に基づく方法で、あらゆる精度のラベルを十分に活用します。標準のsoftmax分類子は、すべてのクラスが相互に排他的であると見なすため、このような弱いラベルから学習できません。 
[概要]ラベルノイズの影響をマイパーパーパーすることに焦点を当てた研究があります。分類に基づく方法であるchillaxを提案し、あらゆる精度のラベルを最大限に活用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: When Wireless Communications Meet Computer Vision in Beyond 5G -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_59.html">
      <font color="black">When Wireless Communications Meet Computer Vision in Beyond 5G</font>
    </a>
  </h2>
  <font color="black">これは、RFベースの画像再構成のユースケースによって裏付けられ、再送信と遅延の削減につながる受信機側の画像障害補正を示しています。特に、コンピュータビジョンがミリ波チャネルで{先読み}予測を可能にする方法を示します。閉塞が実際に発生する前の閉塞シナリオ..コンピュータービジョンの観点から、無線周波数（RF）ベースのセンシングとイメージングがコンピュータービジョンアプリケーションを閉塞と障害から強化するのにどのように役立つかを強調します。 
[概要]ビジョン支援ワイヤレスネットワークは、効率を犠牲にすることなく、ワイヤレス通信の信頼性を大幅に向上させることが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Uniform Priors for Data-Efficient Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_60.html">
      <font color="black">Uniform Priors for Data-Efficient Transfer</font>
    </a>
  </h2>
  <font color="black">すべての実験を通じて、均一性の正則化がベースライン手法よりも一貫して利点を提供し、ディープメトリック学習とメタ学習で最先端のパフォーマンスを達成できることを示しています。見えないものへの適応を促進する能力について正則化を評価します。タスクとデータ。4つの関連する別個のドメインをカバーする徹底的な実験的研究を実施します。数ショットのメタ学習、ディープメトリック学習、ゼロショットドメイン適応、および分布外分類です。ディープニューラルネットワークは、さまざまなダウンストリームアプリケーションで大きな期待を示しています。しかし、新しいデータやタスクに適応して一般化する能力は依然として課題です。 
[概要]少数の実行能力-新しいタスクへのショットの適応は、機械学習モデルのスケーラビリティと展開にとって重要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br><font color="black">2020-06-30</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Anomalies from Video-Sequences: a Novel Descriptor -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_61.html">
      <font color="black">Detecting Anomalies from Video-Sequences: a Novel Descriptor</font>
    </a>
  </h2>
  <font color="black">私たちの仮説は、グループ数の急激な変化は、「異常なし」を説明するものとは大幅に異なる文字列の時間的トリットベースのシーケンスでこれらの変化を翻訳することにより、それに応じて検出できる異常なイベントが原因である可能性があるというものです。 1つ..群集行動分析と異常検出のための新しい記述子を提示します。報告された結果は、グループダイナミクスのトリットベースの測定によって異常を検出できることを示しています。 
[概要]目標は、群集内のグループの形成と崩壊の速度を測定することです。これは、グループの抽出数と比較されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Multi-View Synchronization Learning for 3D Pose
  Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_62.html">
      <font color="black">Self-Supervised Multi-View Synchronization Learning for 3D Pose
  Estimation</font>
    </a>
  </h2>
  <font color="black">Human3.6Mデータセットでの同期タスクの有効性を示し、3D人間の姿勢推定で最先端の結果を達成します。マルチビューカメラシステムでキャプチャされたビデオから抽出された画像を活用します。マルチビューデータセット。オブジェクトが非剛体で変形する場合、剛体変換は、まったく同時に取得された2つのビュー間、つまり同期されたときにのみ発生します。 
[概要]マルチビューカメラシステムでキャプチャされたビデオから抽出された画像を活用します。このプロジェクトは、小さな注釈付きデータセットを活用するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Few-shot Action Recognition with Implicit Temporal Alignment and Pair
  Similarity Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_63.html">
      <font color="black">Few-shot Action Recognition with Implicit Temporal Alignment and Pair
  Similarity Optimization</font>
    </a>
  </h2>
  <font color="black">これらの問題を解決するために、このペーパーでは1）数ショットの行動認識アルゴリズムのパフォーマンスを評価するための特定の設定を示します。 2）より良いビデオレベルの類似性比較のための暗黙のシーケンスアラインメントアルゴリズム。 3）限られたデータでペアの類似性を最適化するための数ショット学習の高度な損失..ビデオベースの数ショットアクション認識は十分に調査されておらず、挑戦的なままです：1）異なる論文間の実装の詳細の違いは公正な比較を行います難しい; 2）時間シーケンスの幅広い変動と不整合により、ビデオレベルの類似性の比較が困難になります。 3）ラベル付けされたデータが不足しているため、最適化が困難です。2つのデータセットでの広範な実験により、提案された方法の有効性が実証されています。 
[要約]提案された方法は、高度な高度な高度な記憶喪失に基づいています。新しい研究は、方法の有効性を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Reducing Drift in Structure From Motion Using Extended Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_64.html">
      <font color="black">Reducing Drift in Structure From Motion Using Extended Features</font>
    </a>
  </h2>
  <font color="black">低周波の長距離エラー（ドリフト）は、動きによる3D構造の固有の問題であり、シーンの合理的な再構成を妨げることがよくあります。従来の特徴の一致とは異なり、拡張された特徴は、重複しない入力画像にまたがることができます。したがって、再構成の規模と形状に長距離の制約を与えます。私たちの構造的特徴は、整列した窓の列や平面の建物のファサードなど、長距離の人工構造物を含むシーンのドリフトを大幅に減らすことができます。 
[概要]この論文では、平面や消失点などの拡張された構造的特徴を使用して、スケールと位置のドリフトを劇的に削減する方法を紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: DanHAR: Dual Attention Network For Multimodal Human Activity Recognition
  Using Wearable Sensors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_65.html">
      <font color="black">DanHAR: Dual Attention Network For Multimodal Human Activity Recognition
  Using Wearable Sensors</font>
    </a>
  </h2>
  <font color="black">ただし、焦点を合わせる場所とチャネル情報を見逃す場所しかわかりません。これは、焦点を合わせる対象を決定する上で重要な役割を果たします。ただし、リカレントネットワークは、畳み込みニューラルネットワーク（CNN）と比較してパワーを表す機能が弱いことがよくあります。 、注意ベースのGRUまたはLSTMと比較して、マルチモーダルセンシング信号の時空間依存性に対処できません。 
[概要]ゲート付き回帰ユニット（gru）と長短期記憶（lstm）ネットワークを組み合わせることにより、2つの注意方法が提案されます。これらは、空間ドメインと音声ドメインの両方でセンシング信号の依存関係を同時にキャプチャできます。これらには、ハードコンピューティングとソフトアテンションが含まれますターゲットアクティビティに</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-25">
        <br><font color="black">2020-06-25</font>
      </time>
    </span>
</section>
<!-- paper0: Coarse and fine-grained automatic cropping deep convolutional neural
  network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_66.html">
      <font color="black">Coarse and fine-grained automatic cropping deep convolutional neural
  network</font>
    </a>
  </h2>
  <font color="black">この論文では、畳み込みニューラルネットワークのより効率的で正確な圧縮加速を実現できる粗粒度の自動プルーニングアルゴリズムを提案します。まず、畳み込みニューラルネットワークの中間特徴マップをクラスター化して、粗粒度クリッピング後のネットワーク構造を取得します。 、次に、粒子群最適化アルゴリズムを使用して、構造を繰り返し検索および最適化します。最後に、最適なネットワーク調整部分構造が取得されます。 
[概要]この論文は、きめ細かい自動プルーニングアルゴリズムを提案します。畳み込みニューラルネットワークのより効率的で正確な圧縮加速を実現できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Audio-Visual Self-Supervised Terrain Type Discovery for Mobile Platforms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_67.html">
      <font color="black">Audio-Visual Self-Supervised Terrain Type Discovery for Mobile Platforms</font>
    </a>
  </h2>
  <font color="black">次に、地形クラスターラベルを使用して、画像ベースの畳み込みニューラルネットワークをトレーニングし、地形タイプの変化を予測します。実験を通じて、提案された自己教師あり地形タイプ検出方法が80％を超える精度を達成し、いくつかのベースラインを大幅に上回っていることを示します。視覚ベースの地形認識と発見に内在する曖昧さに対処するために、下側に取り付けられたマイクから抽出されたオーディオ機能を切り替えるマルチモーダル自己教師あり学習手法を提案します。地形タイプをクラスター化するためにプラットフォーム上のカメラによって抽出されたモバイルプラットフォームと画像の特徴。 
[概要]提案された自己教師あり学習手法は、ビジョンベースの地形認識と発見に固有のあいまいさを解決することです。モバイルプラットフォームの下側に取り付けられたマイクから抽出された音声特徴と、カメラによって抽出された画像特徴を削除する必要があります。地形タイプをクラスター化するためのプラットフォーム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Automation of Hemocompatibility Analysis Using Image Segmentation and a
  Random Forest -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_68.html">
      <font color="black">Automation of Hemocompatibility Analysis Using Image Segmentation and a
  Random Forest</font>
    </a>
  </h2>
  <font color="black">これは、それぞれレシーバー-オペレーターと予測-リコール曲線の下の高い領域によってサポートされます。この目的のために、蛍光画像は、多相相区分的定数マンフォード-シャーモデルのザックの凸面化を使用してセグメント化されます。材料の体外血液適合性試験の光学的血小板分析は、各研究グループによって個別に手動または半手動で実行されます。 
[概要]この論文は、光学的血小板数と分析の自動化アプローチを提案します。非バックグラウンドセグメントの結果の画像は、血小板または血小板なしとして分類する必要があります。このモデルには、全体的に高い精度と低いエラー率、ランダムが必要です。森は信頼できる結果を達成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Gradient Descent Ascent for Min-Max Problems on Riemannian Manifold -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_69.html">
      <font color="black">Gradient Descent Ascent for Min-Max Problems on Riemannian Manifold</font>
    </a>
  </h2>
  <font color="black">理論的分析では、RSGDAが$ O（\ kappa ^ 4 \ epsilon ^ {-4}）$のサンプル複雑度を達成できることを証明します。さらに、RGDAのサンプル複雑度が$ O（\ kappa ^ 2 \ epsilon ^ {-2}）$ $ \ epsilon $-非凸の強凹ミニマックス問題の停留点を見つけるため。ここで、$ \ kappa $は条件数を示します。ロバストな深部ニューラルに関する広範な実験結果Stiefelマニホールドを介したネットワークトレーニングは、提案されたアルゴリズムの効率を示しています。 
[概要]これは、ミニマックスターナーターナーターナー体制の最初の研究です。これは、チームが作業できなかったという事実に基づいています。さらに、新しいリーマン改善改善改善を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: SIMCO: SIMilarity-based object COunting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_70.html">
      <font color="black">SIMCO: SIMilarity-based object COunting</font>
    </a>
  </h2>
  <font color="black">実験によると、SIMCOはベンチマークのカウントで最先端のスコアを提供し、多くの困難な画像理解タスクにも役立つことが示されています。検出された各オブジェクトは、新しい類似性ベースのヘッドから取得された低次元の埋め込みによって記述されます。ブランチ;この後者はトリプレット損失を実装し、同様のオブジェクト（同じ2D形状+色とスケール）を近くにマッピングするように促します。その後、SIMCOはこの埋め込みをクラスタリングに使用して、さまざまなタイプのオブジェクトを出現させてカウントできるようにし、SIMCOを最初に作成します。マルチクラスの教師なしカウンター。 
[ABSTRACT] simcoは、最初のマルチクラスの教師なしカウンター教師ありカウンターです。コンセプトは、プリミティブな2D形状に似たすべてのオブジェクトを強調表示することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-15">
        <br><font color="black">2019-04-15</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Two-Stream Multi-Feature Network for Driver Drowsiness Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CV/paper_71.html">
      <font color="black">Robust Two-Stream Multi-Feature Network for Driver Drowsiness Detection</font>
    </a>
  </h2>
  <font color="black">提案された検出システムは、次の4つの部分に分けることができます。（1）疲労検出に重要な、検出されたドライバー画像の主要なパッチを特定し、対応するオプティカルフローを計算します。（2）コントラスト制限適応ヒストグラム均等化（CLAHE）が使用されます。私たちのシステムでは、さまざまな光条件の影響を減らすために..（3）注意メカニズムと組み合わせた3つの個別の2ストリームネットワークが、時間情報を抽出するために各機能用に設計されています。 
[概要]提案された検出システムは、疲労検出を検出するために使用できます。これは、有名な国立清華大学の居眠り運転検知（nthu --ddd）データセットでトレーニングおよび評価されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: KLearn: Background Knowledge Inference from Summarization Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_0.html">
      <font color="black">KLearn: Background Knowledge Inference from Summarization Data</font>
    </a>
  </h2>
  <font color="black">対照的に、この作業は背景知識を前面に置きます。まず、人間情報の重要性の優先順位に関する洞察を提供します。このフレームワークに基づいて、背景知識を明示的にモデル化する要約スコアリング関数を定義し、これらのスコアリング関数が人間の判断に適合することを示します。ベースラインよりも大幅に優れています。 
[要約]要約研究者は、背景知識よりも関連性にかなり注意を払っています。彼らは、人間の要約者とアノテーターが行った選択に、背景知識に関する暗黙の情報が含まれているという事実に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Stable Style Transformer: Delete and Generate Approach with
  Encoder-Decoder for Text Style Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_1.html">
      <font color="black">Stable Style Transformer: Delete and Generate Approach with
  Encoder-Decoder for Text Style Transfer</font>
    </a>
  </h2>
  <font color="black">並列データセットは限られており、構築が難しいため、ほとんどの既存の研究は非並列データセットで進行しています。この作業では、非並列データセットの2つの段階に従う方法を紹介します。テキストスタイルの転送は、文を生成するタスクです。入力文の内容を保存し、スタイルを転送することによって。 
[概要]ほとんどの既存の研究は非並列データセットで進行中です。これは、並列データセットが限られており、構築が難しいためです。最初の段階は、分類子を介して文の属性マーカーを直接削除することです。2つのベンチマークデータセットで実験し、評価します。コンテキスト、スタイル、流暢さ、およびセマンティック</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-25">
        <br><font color="black">2020-05-25</font>
      </time>
    </span>
</section>
<!-- paper0: Beyond 512 Tokens: Siamese Multi-depth Transformer-based Hierarchical
  Encoder for Long-Form Document Matching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_2.html">
      <font color="black">Beyond 512 Tokens: Siamese Multi-depth Transformer-based Hierarchical
  Encoder for Long-Form Document Matching</font>
    </a>
  </h2>
  <font color="black">ウィキペディアベースのベンチマークデータセット、コード、および事前にトレーニングされたチェックポイントをオープンソース化して、長い形式のドキュメントマッチングに関する将来の研究を加速します。私たちのモデルには、より長いテキスト入力に自己注意モデルを適応させるためのいくつかの革新が含まれています。長い形式のドキュメントマッチングのいくつかのベンチマークデータセットは、提案されたSMITHモデルが、階層的注意、マルチ深度注意ベースの階層的反復ニューラルネットワーク、BERTなどの以前の最先端モデルよりも優れていることを示しています。 
[概要]近年、トランスフォーマーやバートなどのセルフアテンションベースのモデルは、テキストマッチングで最先端のパフォーマンスを実現しています。これらには、最大テキスト長を512から2048に増やすことができる新しいモデルが含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-26">
        <br><font color="black">2020-04-26</font>
      </time>
    </span>
</section>
<!-- paper0: Enhancing Extractive Text Summarization with Topic-Aware Graph Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_3.html">
      <font color="black">Enhancing Extractive Text Summarization with Topic-Aware Graph Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">実験結果は、私たちのモデルがCNN / DMおよびNYTデータセットで最先端の結果を実質的に達成するだけでなく、はるかに長いドキュメントで構成される科学論文データセットでの既存のアプローチを大幅に上回り、ドキュメントのジャンルでの堅牢性が優れていることを示しています。長さ..さらに、私たちのモデルは、潜在的なトピックを発見するために共同ニューラルトピックモデル（NTM）を統合し、文選択のためのドキュメントレベルの機能を提供できます。さらなる議論は、トピック情報がモデルがドキュメント全体から顕著なコンテンツを事前選択するのに役立つことを示しています、これは長いドキュメントの要約におけるその有効性を解釈します。 
[要約]抽出的アプローチは、その流暢さと効率性のためにテキスト要約で広く使用されています。また、重要なコンテンツのキャプチャに対するトピック情報の影響を無視することもよくあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: The World is Not Binary: Learning to Rank with Grayscale Data for
  Dialogue Response Selection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_4.html">
      <font color="black">The World is Not Binary: Learning to Rank with Grayscale Data for
  Dialogue Response Selection</font>
    </a>
  </h2>
  <font color="black">3つのベンチマークデータセットと4つの最先端のマッチングモデルでの実験は、提案されたアプローチが大幅で一貫したパフォーマンスの向上をもたらすことを示しています。この作業では、グレースケールデータが人間の努力なしで自動的に構築できることを示します。自動グレースケールデータジェネレーターとしての既製の応答検索モデルと応答生成モデル。 
[ABSTRACT]私たちの方法は、既成の応答検索モデルと応答生成モデルをマッチングデータジェネレーターとして使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: Incorporating BERT into Parallel Sequence Decoding with Adapters -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_5.html">
      <font color="black">Incorporating BERT into Parallel Sequence Decoding with Adapters</font>
    </a>
  </h2>
  <font color="black">私たちのフレームワークは、BERTの双方向で条件付き独立性を考慮した、Mask-Predictという名前の並列シーケンスデコードアルゴリズムに基づいており、従来の自己回帰デコードに簡単に適合させることができます。推論の待ち時間を半分に減らしながら、自己回帰ベースラインを一貫して上回り、IWSLT14ドイツ語-英語/ WMT14ドイツ語-英語翻訳で$ 36.49 $ / $ 33.57 $ BLEUスコアを達成します。フレームワークの各コンポーネントは、プラグインユニットと見なすことができます。フレームワークは柔軟で、タスクに依存しません。 
[概要]提案されたモデルは、「存在しない」ベースのツールとして使用できます。これは、タスクの大部分の一部であると見なすことができます-特定のデータセット</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Debiasing NLU Models from Unknown Biases -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_6.html">
      <font color="black">Towards Debiasing NLU Models from Unknown Biases</font>
    </a>
  </h2>
  <font color="black">提案されたフレームワークは一般的であり、既存のバイアス除去方法を補完します。最近提案されたバイアス除去方法は、この傾向を緩和するのに効果的であることが示されています。これらの既存の方法がチャレンジデータセット（つまり、特定のバイアスを特に対象とせずに、モデルのバイアスへの依存を明らかにするように設計された例）。 
[要約]最近のバイアス除去方法は、問題を軽減するのに効果的であることが示されています。しかし、彼らは、新しい方法が効果的であると知られていると主張しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-25">
        <br><font color="black">2020-09-25</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Supervised Joint-Event-Extraction with Heterogeneous Information
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_7.html">
      <font color="black">Cross-Supervised Joint-Event-Extraction with Heterogeneous Information
  Networks</font>
    </a>
  </h2>
  <font color="black">次に、不足している情報を前述の共起関係に組み込むために、相互のタイプ分布に基づいてトリガーまたはエンティティの抽出を交互に監視する相互監視メカニズム（CSM）を提案します。私たちの提案する方法では、3つの実世界のデータセットで広範な実験を行い、私たちの方法を最先端の方法と比較します。この問題を軽減するために、最初に共起イベント抽出をシーケンスとして定義します。 -トリガーとエンティティのタグで構成されるタグセットを使用したシーケンスラベリングタスク。 
[ABSTRACT]以前の作業では、エンティティとトリガー間の密な共起関係に完全に対処していません。これらはこの重要な情報を失うため、抽出パフォーマンスが低下します。提案された方法では、3つの実世界のデータセットをテストします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Multilingual Argument Mining: Datasets and Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_8.html">
      <font color="black">Multilingual Argument Mining: Datasets and Analysis</font>
    </a>
  </h2>
  <font color="black">最後に、引数マイニングタスクでの転移学習の評価を容易にするために、複数の言語で10,000を超える引数を含む人間が生成したデータセットと、英語のデータセットの機械翻訳を提供します。さらに、翻訳トレインアプローチに焦点を当てます。 、翻訳する言語の選択とそれらの間の関係が、結果のモデルの精度にどのように影響するかを示します。この作業では、多言語BERTモデルを使用して、非言語の引数マイニングタスクに対処する転移学習の可能性を探ります。英語のデータセットと機械翻訳の使用に基づく英語。 
[概要]主な言語は英語であり、他の言語のリソースはほとんどありません。さらに、英語のデータセットの機械翻訳だけでなく、複数の言語で1万を超える引数を持つ人間が生成したデータセットを提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: RGCL at SemEval-2020 Task 6: Neural Approaches to Definition Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_9.html">
      <font color="black">RGCL at SemEval-2020 Task 6: Neural Approaches to Definition Extraction</font>
    </a>
  </h2>
  <font color="black">自動的に拡張されたトレーニングセットを含む、いくつかのタスク固有の適応を備えた最先端のニューラルネットワークアーキテクチャを利用します。全体として、このアプローチは、アーキテクチャ選択の柔軟性を維持しながら、許容可能な評価スコアを達成します。システムは定義を分類します。文とトークンのレベルで。 【アブストラクト】システムシステムシステム、システムシステムシステム。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: F1 is Not Enough! Models and Evaluation Towards User-Centered
  Explainable Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_10.html">
      <font color="black">F1 is Not Enough! Models and Evaluation Towards User-Centered
  Explainable Question Answering</font>
    </a>
  </h2>
  <font color="black">HOTPOTQAベンチマークデータセットで実験を行い、ユーザー調査を実施します。ただし、現在のモデルと評価設定には、回答と説明の組み合わせに関して欠点があり、ユーザーエクスペリエンスに深刻な問題を引き起こす可能性があることを示しています。ユーザー調査によると、私たちのモデルは、システムの正しさを判断するユーザーの能力を高め、F1のようなスコアは、人間のユーザーとの実際の設定でモデルの有用性を推定するのに十分ではありません。 
[概要]目標は、ユーザーがシステムの正確さを評価できるようにすることです。回答を強化するために、新しいモデルと新しい正則化項を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Model Selection for Cross-Lingual Transfer using a Learned Scoring
  Function -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_11.html">
      <font color="black">Model Selection for Cross-Lingual Transfer using a Learned Scoring
  Function</font>
    </a>
  </h2>
  <font color="black">この課題に対処するために、微調整されたモデル自体の内部表現を使用して言語間の機能を予測するモデル選択へのメタ学習アプローチを提案します。広範な実験で、私たちのアプローチは英語の検証データよりも優れたモデルを一貫して選択することがわかりました。 5つの言語と5つの十分に研究されたNLPタスクにわたって、少量のターゲット言語開発データに匹敵する結果を達成します。以前の作業は、英語の検証/開発データに依存して、さまざまな学習率で微調整されたモデルから選択しました。ステップ数およびその他のハイパーパラメーター。多くの場合、最適ではない選択になります。 
[要約]研究は、私たちのアプローチが、5つの言語と5つのよく研究されたnlpタスクにわたって英語の検証データよりも優れたモデルを一貫して選択することを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: On the Frailty of Universal POS Tags for Neural UD Parsers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_12.html">
      <font color="black">On the Frailty of Universal POS Tags for Neural UD Parsers</font>
    </a>
  </h2>
  <font color="black">結果は、ニューラルパーサーの機能としてUPOSタグを利用するには、非常に高いタグ付け精度が必要であり、ゴールドタグを使用すると、パフォーマンスが非線形に向上し、ある種の例外が示唆されることを示しています。UPOS精度の影響に関する分析を示します。解析パフォーマンスについて..また、予測されたUPOSタグのどの側面が解析精度に最も影響を与えるかを調査し、問題の潜在的に意味のある言語的側面を強調します。 
[ABSTRACT] uposタグの分析は、ゴールドタグを使用するとパフォーマンスが非線形に向上することを示しており、ある種の例外を示唆しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Continual adaptation for efficient machine communication -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_13.html">
      <font color="black">Continual adaptation for efficient machine communication</font>
    </a>
  </h2>
  <font color="black">COCOのシミュレーションと、人間のパートナーとのリアルタイムの参照ゲーム実験を通じて、このフレームワークを評価します。コミュニケーションにおける適応モデルのベンチマークとしてインタラクティブな反復参照タスクを導入し、人工エージェントを初期化できる正規化された継続的な学習フレームワークを提案します。最近のニューラル言語モデルは、トレーニングデータに存在する既存の規則を理解して生成することはできますが、これらの規則を柔軟かつインタラクティブに適応させることはできません。人間のように飛ぶ。 
[要約]新しい言語モデルは、トレーニングデータに存在する既存の規則を理解して生成することはできますが、人間のようにそれらを適応させることはできません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-22">
        <br><font color="black">2019-11-22</font>
      </time>
    </span>
</section>
<!-- paper0: Supertagging Combinatory Categorial Grammar with Attentive Graph
  Convolutional Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_14.html">
      <font color="black">Supertagging Combinatory Categorial Grammar with Attentive Graph
  Convolutional Networks</font>
    </a>
  </h2>
  <font color="black">CCGbankで実行された実験は、スーパータグ付けと構文解析の両方の点で、私たちのアプローチが以前のすべての研究よりも優れていることを示しています。さらなる分析は、CCGスーパータグ付けを強化するために単語ペアから識別的に学習するアプローチの各コンポーネントの有効性を示しています。レキシコンから抽出されたチャンク（n-gram）からのグラフで、グラフに注意を向けます。これにより、チャンク内およびチャンク間のコンテキストからの異なる単語ペアがモデル内で重み付けされ、それに応じてスーパータグ付けが容易になります。 
[概要]以前の研究では、コンテキスト機能を活用するための取り組みは限られていましたが、既存の研究ではこの言語を使用できませんでした。代わりに、レキシコンから抽出されたチャンクからグラフを作成し、グラフに注意を向けます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: CAPT: Contrastive Pre-Training for LearningDenoised Sequence
  Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_15.html">
      <font color="black">CAPT: Contrastive Pre-Training for LearningDenoised Sequence
  Representations</font>
    </a>
  </h2>
  <font color="black">提案されたCAPTは、教師なしインスタンスごとのトレーニング信号を介して、元のシーケンスの表現とその破損したバージョンの間の一貫性を促進します。特定のモダリティに焦点を当てたほとんどの以前の作業とは異なり、11の自然言語理解とクロスモーダルタスクに関する包括的な経験的証拠は、CAPTが言語タスクと視覚言語タスクの両方に適用可能であり、GLUEベンチマークで0.6％の絶対ゲイン、NLVRで0.8％の絶対増分など、驚くほど一貫した改善が得られることを示しています。このようにして、トレーニング前の微調整の不一致を軽減するだけではありません。事前トレーニングのノイズによって誘発されますが、事前トレーニングされたモデルが、より効果的な文レベルの監視を介して入力のグローバルセマンティクスをより適切にキャプチャするのにも役立ちます。 
[ABSTRACT] pre-トレーニングは、このタイプのノイズのベンチマークバージョンです。これは、以前の以前のモデルが破損していて、元の入力を復元しようとしていることを示しています。ただし、モデルはさまざまなレベルのノイズで動作します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Mitigating Gender Bias in Machine Translation with Target Gender
  Annotations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_16.html">
      <font color="black">Mitigating Gender Bias in Machine Translation with Target Gender
  Annotations</font>
    </a>
  </h2>
  <font color="black">文法的な性別の言語では、対象の「秘書」の性別を判別する必要があるかもしれません。そのために、対象の性別に関する情報を含む単語レベルの注釈を使用する機械翻訳システムをトレーニングする方法を紹介します。適切な翻訳に必要な情報は、翻訳されている文から常に推測できるとは限らず、外部の知識に依存している可能性さえあると主張します。 
[概要]最も一般的な翻訳オプション。これは、ステレオタイプの翻訳と一致することがよくあります。必要な情報を取得するタスクを分離することを提案します。トレーニングデータを準備するために、通常のソース言語の単語に、対応するターゲット言語の単語の文法的な性別情報を注釈します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: XL-WiC: A Multilingual Benchmark for Evaluating Semantic
  Contextualization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_17.html">
      <font color="black">XL-WiC: A Multilingual Benchmark for Evaluating Semantic
  Contextualization</font>
    </a>
  </h2>
  <font color="black">XL-WiCはhttps://pilehvar.github.io/xlwic/で入手できます。さまざまな言語ファミリーの12の新しい言語で、さまざまなリソースの可用性を備えたゴールドスタンダードを備えた大規模な多言語ベンチマークXL-WiCを提案します。 、ゼロショットのクロスリンガル転送などの評価シナリオの余地があります。ただし、この基準を評価するための既存の評価ベンチマークのほとんどは、センスインベントリ（通常はWordNet）に関連付けられており、知識ベースの表現手法の小さなサブセットに使用が制限されています。 。 
[概要]大規模な多言語ベンチマークxl-wicは、さまざまな言語族からの12の新しい言語のゴールドスタンダードを特徴としています。タスクは、離れた言語であっても、単語のさまざまな意味を区別することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Converting Anyone's Emotion: Towards Speaker-Independent Emotional Voice
  Conversion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_18.html">
      <font color="black">Converting Anyone's Emotion: Towards Speaker-Independent Emotional Voice
  Conversion</font>
    </a>
  </h2>
  <font color="black">また、感情変換パフォーマンスを向上させるためのデコーダーへの追加入力としてのF0の使用についても調査します。スペクトルと韻律マッピングを学習するためのVAW-GANベースのエンコーダーデコーダー構造を提案します。実験により、提案されたスピーカーに依存しないフレームワークが示されます。見えているスピーカーと見えていないスピーカーの両方で競争力のある結果を達成します。 
[概要]提案された話者-独立した感情的な音声変換フレームワークは、並列データを必要とせずに誰の感情も変換できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br><font color="black">2020-05-13</font>
      </time>
    </span>
</section>
<!-- paper0: BRUMS at SemEval-2020 Task 12 : Transformer based Multilingual Offensive
  Language Identification in Social Media -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_19.html">
      <font color="black">BRUMS at SemEval-2020 Task 12 : Transformer based Multilingual Offensive
  Language Identification in Social Media</font>
    </a>
  </h2>
  <font color="black">ソーシャルメディアで不快な言語を特定するための多言語ディープラーニングモデルを提示します。全体として、このアプローチは言語間の柔軟性を維持しながら、許容可能な評価スコアを達成します。OffensEval主催者は、アラビア語、デンマーク語、ソーシャルメディアからの投稿を含む注釈付きデータセットを参加者に提供しました。英語、ギリシャ語、トルコ語。 
[概要]プログラムは、アラビア語、デンマーク語、英語、ギリシャ語、トルコ語のソーシャルメディア投稿のデータセットを提供し、言語間の柔軟性を維持しながら、アプローチは許容可能な評価スコアを達成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Low-Latency Sequence-to-Sequence Speech Recognition and Translation by
  Partial Hypothesis Selection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_20.html">
      <font color="black">Low-Latency Sequence-to-Sequence Speech Recognition and Translation by
  Partial Hypothesis Selection</font>
    </a>
  </h2>
  <font color="black">チャンクベースのインクリメンタル推論のための3つのレイテンシー削減手法を提案し、オフライン転写と比較した精度とレイテンシーのトレードオフの観点からそれらの効率を評価します。私たちの実験ではTransformerを使用していますが、仮説選択戦略は他のエンコーダーにも適用できます。デコーダーモデル。 
[概要] how2データセットでは、レイテンシーを83％削減して0.8秒にします。オフラインシステムは、単語誤り率（wer）やブルーなどの品質指標で評価されることがよくありますが、レイテンシーも多くの実用的なユースケースで重要な要素です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-22">
        <br><font color="black">2020-05-22</font>
      </time>
    </span>
</section>
<!-- paper0: Interpreting Attention Models with Human Visual Attention in Machine
  Reading Comprehension -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_21.html">
      <font color="black">Interpreting Attention Models with Human Visual Attention in Machine
  Reading Comprehension</font>
    </a>
  </h2>
  <font color="black">人間の注意とパフォーマンスとの類似性が高いことは、LSTMモデルとCNNモデルと有意に相関していることがわかります。ただし、XLNetがこの困難なタスクで最高のパフォーマンスを発揮するにもかかわらず、この関係はXLNetモデルには当てはまらないことを示しています。この目的のために、参加者が映画のプロットを読み、事前定義された質問に答える、新しい23人の参加者の視線追跡データセットであるMQA-RCを紹介します。 
[概要]長短期記憶（lstm）、畳み込みニューラルモデル、xlnetトランスフォーマーアーキテクチャに基づいて最先端のネットワークを比較します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Corruption Is Not All Bad: Incorporating Discourse Structure into
  Pre-training via Corruption for Essay Scoring -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_22.html">
      <font color="black">Corruption Is Not All Bad: Incorporating Discourse Structure into
  Pre-training via Corruption for Essay Scoring</font>
    </a>
  </h2>
  <font color="black">提案された事前トレーニングアプローチのためのトークン、文、段落レベルの破損手法のいくつかのタイプを紹介し、コンテキスト化された情報と談話情報の両方を活用するために、事前トレーニング方法でマスクされた言語モデリングの事前トレーニングを強化します。提案された監視されていないアプローチは、新しいエッセイ組織のスコアリングタスクに関する最新の結果..この論文では、談話パーサーや注釈を必要としない一貫性と結束性の観点から、エッセイの談話構造をキャプチャするための監視されていない事前トレーニングアプローチを提案します。 
[概要]パーサーのパフォーマンスは、特に学生のエッセイなどのノイズの多いテキストで使用される場合は、必ずしも必要ではありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Modeling the Music Genre Perception across Language-Bound Cultures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_23.html">
      <font color="black">Modeling the Music Genre Perception across Language-Bound Cultures</font>
    </a>
  </h2>
  <font color="black">音楽ジャンルを研究するこのアプローチは、これまでで最も広範であり、音楽学と音楽情報検索に多くの影響を及ぼします。さらに、最先端の多言語事前トレーニング済み埋め込みモデルをベンチマークするために、新しいドメイン依存の言語間コーパスを紹介します。 ..この作業では、言語固有のセマンティック表現、つまり分散概念の埋め込みとオントロジーのみに基づいて、関連する言語間、文化固有の音楽ジャンル注釈を取得する可能性を研究します。 
[概要] 6つの言語に焦点を当てた調査では、教師なしの言語横断的な音楽ジャンルの注釈が高精度で実現可能であることが示されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: MALA: Cross-Domain Dialogue Generation with Action Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_24.html">
      <font color="black">MALA: Cross-Domain Dialogue Generation with Action Learning</font>
    </a>
  </h2>
  <font color="black">マルチドメインデータセット、SMDおよびMultiWOZを使用した実験では、提案されたモデルが、タスクの完了と言語の品質の両方の点で、ベースラインモデルよりも一貫した改善を達成していることが示されています。タスクの完了と言語の質..この問題に対処するために、対話の進行に対する発話の影響を区別することによって意味的な潜在的行動を学習する多段階適応潜在的行動学習（MALA）を提案します。 
[概要]これらのコンポーネントの目標に矛盾があるのはこれが初めてです。アクション表現を取得するために、最近の研究では、発話の語彙の類似度に基づいて教師なしで潜在的なアクションを学習しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br><font color="black">2019-12-18</font>
      </time>
    </span>
</section>
<!-- paper0: A Survey on Text Classification: From Shallow to Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_25.html">
      <font color="black">A Survey on Text Classification: From Shallow to Deep Learning</font>
    </a>
  </h2>
  <font color="black">
[概要]このペーパーでは、1961年から2020年までの最先端のアプローチを確認し、ギャップを埋めます。包括的な学習からディープラーニングまでのモデルに焦点を当てます。次に、主要な影響、将来の研究の方向性、および研究領域が直面する課題を要約して結論を出します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-02">
        <br><font color="black">2020-08-02</font>
      </time>
    </span>
</section>
<!-- paper0: BRUMS at SemEval-2020 Task 3: Contextualised Embeddings forPredicting
  the (Graded) Effect of Context in Word Similarity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_26.html">
      <font color="black">BRUMS at SemEval-2020 Task 3: Contextualised Embeddings forPredicting
  the (Graded) Effect of Context in Word Similarity</font>
    </a>
  </h2>
  <font color="black">全体として、このアプローチは、シンプルさを維持しながら、すべての言語で良好な評価スコアを達成します。このペーパーでは、SemEval-2020タスク3：コンテキストでの段階的な単語の類似性へのチームBRUMSの提出を示します。最終的なランキングに続いて、私たちのアプローチは、フィンランドのサブタスク2の1位を維持しながら、各言語の上位5つのソリューション。
[概要]システムは、いくつかのタスク（特定の適応）を持つ3つの単語の埋め込みを利用します。全体として、私たちのアプローチは各言語の上位5つのソリューションにランク付けされます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Restructuring Conversations using Discourse Relations for Zero-shot
  Abstractive Dialogue Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_27.html">
      <font color="black">Restructuring Conversations using Discourse Relations for Zero-shot
  Abstractive Dialogue Summarization</font>
    </a>
  </h2>
  <font color="black">PGNやBARTなどのドキュメント要約モデルを使用したAMIおよびICSI会議コーパスでの実験では、私たちの方法がROGUEスコアを最大3ポイント改善し、他の最先端の方法に対しても競争力があることを示しています。最近の進歩抽象要約では、データを大量に消費する神経モデルに焦点が当てられており、これらのモデルを新しいドメインに適応させるには、言語の専門家によって作成されたドメイン固有の手動で注釈が付けられたコーパスが利用可能である必要があります。談話関係を使用するゼロショットの抽象対話要約方法を提案します。会話に構造を提供し、すぐに使用できるドキュメント要約モデルを使用して最終的な要約を作成します。 
[概要] amiとicsiの会議コーパス-pgnやbartなどのドキュメント要約モデルを使用して、私たちの方法が不正スコアを最大3ポイント改善することを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-02-05">
        <br><font color="black">2019-02-05</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Text Generation Evaluation with Batch Centering and Tempered
  Word Mover Distance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_28.html">
      <font color="black">Improving Text Generation Evaluation with Batch Centering and Tempered
  Word Mover Distance</font>
    </a>
  </h2>
  <font color="black">手法の堅牢性を実証する数値実験を実施し、さまざまなBERTバックボーンで学習したメトリックに関する結果を報告し、いくつかのベンチマークで人間の評価との最先端の相関関係を実現します。この論文では、類似性のエンコーディング表現を改善するための2つの手法を紹介します。メトリック：統計的特性を改善するバッチ平均センタリング戦略。文脈化された単語表現の情報をよりよく融合するための、計算効率の高い強化された単語移動距離。テキストの自動評価メトリックの最近の進歩により、BERTエンコーダーによって生成されるような深い文脈化された単語表現が設計に役立つことが示されています。人間の判断とよく相関するメトリック。 
[概要]私たちは、私たちの技術の堅牢性を実証する実験を実施します。彼らは、いくつかのベンチマークで、状態表現と人間の評価を達成しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Multilingual Factual Knowledge Retrieval from Pretrained Language Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_29.html">
      <font color="black">Multilingual Factual Knowledge Retrieval from Pretrained Language Models</font>
    </a>
  </h2>
  <font color="black">広範な実験結果は、利用可能なリソースが多かれ少なかれ言語で、このタスクで現在の最先端のLMがどれだけうまく（または不十分に）実行されるかについての洞察を提供します。言語モデル（LM）は、完了することによって事実知識をキャプチャすることに驚くほど成功していることが証明されています。 「プンタカナは_にあります」などのクローズスタイルの空欄を埋める質問。ベンチマークデータとコードはhttps://x-factr.github.ioでリリースされています。 
[ABSTRACT] lmsの事実表現能力に関する研究は英語で行われています。これらの研究は、ほぼ確実に英語で行われています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: A Probabilistic End-To-End Task-Oriented Dialog Model with Latent Belief
  States towards Semi-Supervised Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_30.html">
      <font color="black">A Probabilistic End-To-End Task-Oriented Dialog Model with Latent Belief
  States towards Semi-Supervised Learning</font>
    </a>
  </h2>
  <font color="black">さらに、LABESのコピー拡張Seq2Seqモデルインスタンス化であるLABES-S2Sを紹介します。驚くべきことに、MultiWOZでパフォーマンスを低下させることなく、注釈の要求を50％に減らすことができます。ただし、信念トラッカーのトレーニングには、多くの場合、高価なターンレベルが必要です。すべてのユーザーの発話の注釈。 
[ABSTRACT]潜在的信念状態（labes）モデルを使用すると、ユーザーの発話について詳しく知ることができます。これは、「潜在的信念」と呼ばれる確率的ダイアログモデルと呼ばれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Group-wise Contrastive Learning for Neural Dialogue Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_31.html">
      <font color="black">Group-wise Contrastive Learning for Neural Dialogue Generation</font>
    </a>
  </h2>
  <font color="black">具体的には、事前にトレーニングされたベースラインモデルを参照として使用します。対照学習中、ターゲットダイアログモデルは、参照モデルと比較して、正のサンプルの条件付き確率が高く、負のサンプルの条件付き確率が低くなるようにトレーニングされます。人間の会話で普及しているマルチマッピング関係を管理し、グループごとのデュアルサンプリングで対照的な対話学習を強化します。 
[ABSTRACT]最尤推定（mle）の目的は、対話の生成に広く採用されています。モデルは、適切に選択された正の発話と負の発話の違いを明示的に認識します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: A Natural Language Processing Pipeline of Chinese Free-text Radiology
  Reports for Liver Cancer Diagnosis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_32.html">
      <font color="black">A Natural Language Processing Pipeline of Chinese Free-text Radiology
  Reports for Liver Cancer Diagnosis</font>
    </a>
  </h2>
  <font color="black">放射線学的特徴抽出のために提案されたNLPパイプラインは、他の種類の中国の臨床テキストおよび他の疾患予測タスクで簡単に実装できます。電子医療記録（EMR）での自然言語処理（NLP）実装の急速な発展にもかかわらず、中国のEMR処理特に放射線医学レポートでは、コーパスが限られており、特定の文法的特徴があるため、依然として困難です。肝がん診断では、ランダムフォレストが肝がん診断で最高の予測パフォーマンスを示しました（F1スコア86.97％、精度87.71％、想起86.25％）。 
[概要]提案されたパイプラインは、他の種類の中国の臨床テキストや他の疾患予測に簡単に実装できます。中国の大学の研究者によって開発されました。放射線学的特徴抽出の新しいモデルを開発するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-10">
        <br><font color="black">2020-04-10</font>
      </time>
    </span>
</section>
<!-- paper0: Brain2Word: Decoding Brain Activity for Language Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_33.html">
      <font color="black">Brain2Word: Decoding Brain Activity for Language Generation</font>
    </a>
  </h2>
  <font color="black">これはより現実的な設定であると主張し、見えない被験者からのfMRIデータをデコードできるモデルを提示します。さらに、デコードされた単語を使用して、GPT-2モデルで言語生成をガイドします。この作業では、 fMRIスキャンを直接分類し、固定語彙内の対応する単語にマッピングします。 
[概要]科学者は、fmriスキャンをデコードして、被験者が読んでいる単語の埋め込みに変換できると述べています。ただし、正確な刺激を回復する能力が制限されています。モデルは5を達成します。22％トップ-1以上のセットアップ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Don't Neglect the Obvious: On the Role of Unambiguous Words in Word
  Sense Disambiguation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_34.html">
      <font color="black">Don't Neglect the Obvious: On the Role of Unambiguous Words in Word
  Sense Disambiguation</font>
    </a>
  </h2>
  <font color="black">同時に、明確な単語はWordNetのすべての単語の大部分を占めますが、既存の意味注釈付きコーパスでは十分にカバーされていません。UWA（明確な単語注釈）データセットを紹介し、その状態を示します。アート伝播ベースのモデルは、それを使用して、ワードセンスの埋め込みのカバレッジと品質を大幅に拡張し、WSDでの元の結果を改善できます。ワードセンスの注釈を解除するための最先端の方法（WSD）は、2つを組み合わせたものです。さまざまな機能：事前にトレーニングされた言語モデルの能力と、そのようなモデルのカバレッジを拡張するための伝播方法。 
[要約]この方法は現在の感覚として必要です-注釈付きコーパスは多くのインスタンスをカバーしていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br><font color="black">2020-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: The Tatoeba Translation Challenge -- Realistic Data Sets for Low
  Resource and Multilingual MT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_35.html">
      <font color="black">The Tatoeba Translation Challenge -- Realistic Data Sets for Low
  Resource and Multilingual MT</font>
    </a>
  </h2>
  <font color="black">データリリースとともに、個々の言語ペアと選択した言語グループに対して、事前にトレーニングされたベースラインモデルの数も増えています。このペーパーでは、数千の言語のトレーニングとテストデータを提供する機械翻訳の新しいベンチマークの開発について説明します。そのコレクションから最先端の翻訳モデルを作成するための500以上の言語とツールをカバーするペア。このパッケージを使用すると、ゼロショットや数ショットの学習。 
[概要]主な目標は、世界の言語をはるかに幅広くカバーするオープンな翻訳ツールとモデルの開発をトリガーすることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: BERT-EMD: Many-to-Many Layer Mapping for BERT Compression with Earth
  Mover's Distance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_36.html">
      <font color="black">BERT-EMD: Many-to-Many Layer Mapping for BERT Compression with Earth
  Mover's Distance</font>
    </a>
  </h2>
  <font color="black">さらに、EMDで使用されるレイヤーの重みを自動的に学習するコストアテンションメカニズムを提案します。これにより、モデルのパフォーマンスがさらに向上し、収束時間が短縮されます。EMDにより、多対多のレイヤーマッピングの効果的なマッチングが可能になります。広範な実験GLUEベンチマークでは、精度とモデル圧縮の両方の点で、当社のモデルが強力な競合他社と比較して競争力のあるパフォーマンスを達成していることを示しています。 
[概要]このようにして、モデルはさまざまな教師レイヤーからさまざまなnlpタスクに適応的に学習できます。さらに、アースムーバーの距離（emd）を活用して、知識を教師ネットワークから生徒に変換するために支払う必要のあるコストを軽減します。通信網</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: RuSemShift: a dataset of historical lexical semantic change in Russian -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_37.html">
      <font color="black">RuSemShift: a dataset of historical lexical semantic change in Russian</font>
    </a>
  </h2>
  <font color="black">ターゲットワードは、複数のクラウドソースワーカーによって注釈が付けられました。さらに、RuSemShiftでのいくつかの分散アプローチのパフォーマンスを報告し、有望な結果を達成すると同時に、他の研究者が改善する余地を残します。注釈プロセスは、次のように編成されました。 DURelフレームワークであり、ロシア国立コーパスから抽出された文のコンテキストに基づいていました。 
[要約]ターゲットワードは複数のクラウドソーシングによって注釈が付けられました-ソースworkers.systemはターゲットワードの使用に基づいていました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: SEPT: Improving Scientific Named Entity Recognition with Span
  Representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_38.html">
      <font color="black">SEPT: Improving Scientific Named Entity Recognition with Span
  Representation</font>
    </a>
  </h2>
  <font color="black">さらに、オリジンネットワークアーキテクチャを簡素化して、スパンエクストラクタをBERTと組み合わせます。実験により、簡素化されたアーキテクチャでも同じパフォーマンスが達成され、SEPTは、関係情報が含まれていなくても、科学的な固有表現抽出で新しい最先端の結果を達成することが示されています。 、事前にトレーニングされた言語モデルの開発により、スパン抽出機能のパフォーマンスがシーケンスラベリングモデルと同様になるように見えることがわかりました。 
[概要]最近の論文では、スパン抽出器はシーケンスラベリングモデルと比較して強力なモデルであることが実証されています。正と負のサンプルのバランスを取り、検索スペースを減らすために、アンダーサンプリングによってモデルを変更しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-08">
        <br><font color="black">2019-11-08</font>
      </time>
    </span>
</section>
<!-- paper0: SD-RSIC: Summarization Driven Deep Remote Sensing Image Captioning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_39.html">
      <font color="black">SD-RSIC: Summarization Driven Deep Remote Sensing Image Captioning</font>
    </a>
  </h2>
  <font color="black">提案されたアプローチのコードは、https：//gitlab.tubit.tu-berlin.de/rsim/SD-RSICで公開されています。最初のステップでは、長い畳み込みニューラルネットワーク（CNN）を共同で利用して、標準の画像キャプションを取得します短期記憶（LSTM）ネットワーク..提案されたアプローチは、3つの主要なステップで構成されています。 
[概要]新しいdnnベースのアプローチは、キャプション付きの多数のrs画像で構成されるトレーニングセットの可用性に依存しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
</section>
<!-- paper0: Autotuning Search Space for Loop Transformations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_40.html">
      <font color="black">Autotuning Search Space for Loop Transformations</font>
    </a>
  </h2>
  <font color="black">サーチスペースを探索する単純なオートチューナーを実装し、それを選択したPolyBenchカーネルのセットに適用しました。オートチューナーはループ変換のすべての可能なシーケンスとそれらの関係を表すことができますが、その結果はモンテカルロなどのより優れた検索戦略の使用を動機付けます。マルチレベルタイリングなどの高度なループ変換を見つけるためのカルロツリー検索。自動調整の形での機械学習は、ユーザーが各プラットフォームに最適な最適化を見つけるのに役立ちます。 
[概要]オートチューナーは、ループ検索のすべての可能なシーケンスを表すことができます。結果は、マルチレベルタイリングなどの高度なループ変換を見つけるためのモンテカルロ木探索などのより優れた検索戦略の使用を動機付けます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Extraction of Urban Outdoor Perception from Geolocated
  Free-Texts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_41.html">
      <font color="black">Automatic Extraction of Urban Outdoor Perception from Geolocated
  Free-Texts</font>
    </a>
  </h2>
  <font color="black">これらの地域を調査したところ、LBSNデータが都市部に関する貴重な情報をもたらすという証拠が見つかりました。私たちのアプローチは、さまざまな視点を考慮して都市部をよりよく理解するのに役立つ可能性があることを示しています。どちらの結果も非常に類似したレベルの一致をもたらすことがわかります。 
[概要]人々の認識を抽出するための自動で一般的なタスクを提案します。たとえば、シカゴ、ニューヨーク市、ロンドンのソーシャルネットワークでの位置を例示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Extending Implicit Discourse Relation Recognition to the PDTB-3 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_42.html">
      <font color="black">Extending Implicit Discourse Relation Recognition to the PDTB-3</font>
    </a>
  </h2>
  <font color="black">この主張を裏付けるデータと、暗黙の談話関係の将来の最先端の認識機能の重要なベースラインとして役立つ方法を提示します。PDTB-3には、以前よりもはるかに多くの暗黙の談話関係が含まれています。 PDTB-2 ..これは、暗黙の関係が文内および文間で注釈が付けられているためです。 
[概要]これにより、ユーザーの場所を特定する問題が単純化されますが、ユーザーの感覚を特定する問題も単純化されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Pretrained Transformers for Text Ranking: BERT and Beyond -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_43.html">
      <font color="black">Pretrained Transformers for Text Ranking: BERT and Beyond</font>
    </a>
  </h2>
  <font color="black">私たちの調査に浸透している2つのテーマがあります。NLPで使用される典型的な文ごとの処理アプローチを超えて長いドキュメントを処理する手法と、有効性（結果の品質）と効率（クエリの待ち時間）の間のトレードオフに対処する手法です。多段階のランク付けアーキテクチャで再ランク付けを実行するトランスモデルと、ランク付けを直接実行しようとする高密度表現を学習した2つの高レベルのカテゴリにグループ化された、幅広い最新技術をカバーしています。ただし、多くの未解決の研究課題が残っているため、この調査では、テキストのランク付けのために事前にトレーニングされたトランスフォーマーの基礎をレイアウトすることに加えて、フィールドがどこに向かっているのかを予測しようとします。 
[ABSTRACT]マルチステージランキングアーキテクチャで再ランキングを実行し、ランキングを直接実行しようとする密な表現を学習するトランスフォーマーモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Theedhum Nandrum@Dravidian-CodeMix-FIRE2020: A Sentiment Polarity
  Classifier for YouTube Comments with Code-switching between Tamil, Malayalam
  and English -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_44.html">
      <font color="black">Theedhum Nandrum@Dravidian-CodeMix-FIRE2020: A Sentiment Polarity
  Classifier for YouTube Comments with Code-switching between Tamil, Malayalam
  and English</font>
    </a>
  </h2>
  <font color="black">私たちのシステムは、タミル語-英語で0.62の加重平均F1スコアで4位、マラヤーラム語-英語で0.65のスコアで9位にランク付けされました。言語固有のSoundexを使用して、コード混合データのスペルバリアントを調和させるSoundexの新しいアプリケーション。このパフォーマンスは、このデータセットのトップランクの分類器を大幅に改善します。 
[概要]私たちのシステムはタミル語で4位にランクされました-加重平均f1スコアの英語-ドラヴィダ語のコードミックスに合わせて調整-2020年の火災タスク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-07">
        <br><font color="black">2020-10-07</font>
      </time>
    </span>
</section>
<!-- paper0: Simulated Multiple Reference Training Improves Low-Resource Machine
  Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_45.html">
      <font color="black">Simulated Multiple Reference Training Improves Low-Resource Machine
  Translation</font>
    </a>
  </h2>
  <font color="black">英語に翻訳する際の低リソース設定でのSMRTの有効性を示し、1.2から7.0 BLEUに改善しました。また、SMRTは逆翻訳を補完するものであることがわかります。新しいMTであるSimulated Multiple Reference Training（SMRT）を紹介します。言い換えから参照文の言い換えをサンプリングし、MTモデルをトレーニングして、可能なトークンに対する言い換えの分布を予測することにより、可能な翻訳の全スペースを概算するトレーニング方法。 
[概要]可能な翻訳の全空間に一致する新しいmtトレーニング方法であるシミュレートされた複数参照トレーニング（smrt）を紹介します。この方法は、可能なトークンに対する言い換えの分布を予測するために使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: Program Enhanced Fact Verification with Verbalization and Graph
  Attention Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_46.html">
      <font color="black">Program Enhanced Fact Verification with Verbalization and Graph
  Attention Network</font>
    </a>
  </h2>
  <font color="black">上記のフレームワークをサポートするために、マージン損失に基づく新しいトレーニング戦略で最適化されたプログラム選択モジュールを提案し、より正確なプログラムを生成します。これは、最終的な検証結果の向上に効果的であることが示されています。実験結果は、提案されたフレームワークを示しています。ベンチマークデータセットTABFACTで、74.4％の精度という新しい最先端のパフォーマンスを実現します。その上に、言語化されたプログラム実行からのさまざまな証拠ソースを融合するように設計されたグラフ注意検証ネットワークを構築します。最終的な検証の決定を行うためのプログラム構造、および元のステートメントとテーブル。 
[要約]提案されたシステムは、さまざまな証拠源を融合するように設計されています。これには、プログラムが含まれます-強化された言語化とグラフ注意ネットワーク（progvgat）。提案されたフレームワークは、ベンチマークデータセットタブファクトで74％の精度を達成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Controlling the Interaction Between Generation and Inference in
  Semi-Supervised Variational Autoencoders Using Importance Weighting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_47.html">
      <font color="black">Controlling the Interaction Between Generation and Inference in
  Semi-Supervised Variational Autoencoders Using Importance Weighting</font>
    </a>
  </h2>
  <font color="black">この観察結果を踏まえると、教師なし目的がトレーニング手順に与える影響をより細かく制御できることを示します。変分オートエンコーダー（VAE）は半教師あり学習に広く使用されていますが、それらが機能する理由は不明です。 ..重要度の重み付けを使用して、部分的に観測された潜在変数または観測されていない潜在変数のいずれかを優先する2つの新しい目的を導き出します。 
[概要]教師なし目的の追加は教師なしです。これは「正則化」の結果です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: FILM: A Fast, Interpretable, and Low-rank Metric Learning Approach for
  Sentence Matching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_48.html">
      <font color="black">FILM: A Fast, Interpretable, and Low-rank Metric Learning Approach for
  Sentence Matching</font>
    </a>
  </h2>
  <font color="black">結果は、FILMメソッドが優れたパフォーマンスと最速の計算速度を達成することを示しています。これは、時間計算量の理論的分析と一致しています。この問題を軽減するために、FILM（Fast、Interpretable、および高次元データの高識別射影を効率的に見つけるための低ランクメトリック学習）。このメトリック学習問題を多様体最適化問題として構築し、Barzilai-Borweinステップサイズを使用したCayley変換法で解決します。 
[要約]テストでは、メトリック学習アプローチを適用して、高サイズのデータの高識別投影を見つけます。このメソッドは、フィルム（高速、解釈可能、および低ランクのメトリック学習）と呼ばれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: Does my multimodal model learn cross-modal interactions? It's harder to
  tell than you might think! -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_49.html">
      <font color="black">Does my multimodal model learn cross-modal interactions? It's harder to
  tell than you might think!</font>
    </a>
  </h2>
  <font color="black">7つの画像+テキスト分類タスク（それぞれに新しい最先端のベンチマークを設定）の場合、多くの場合、クロスモーダルインタラクションを削除しても、パフォーマンスの低下はほとんどまたはまったくないことがわかります。したがって、推奨します。マルチモーダル機械学習の研究者は、ユニモーダルベースラインのパフォーマンスだけでなく、最高のパフォーマンスを発揮するモデルのEMAPも報告します。この関数投影は、モデル予測を変更して、クロスモーダル相互作用を排除し、付加的なユニモーダル構造を分離します。 
[ABSTRACT]クロスモーダル相互作用が排除され、加法的なユニモーダル構造が分離されます。ただし、新しいブラックボックス相互作用は主にユニモーダル信号を利用しています。これは、クロスモーダル相互作用の観測に基づいていないためです。これは、次の場合でも当てはまります。相互作用を考慮する能力を備えた表現力豊かなモデル、そうでなければ表現力の低いモデルよりも優れている</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: ReviewRobot: Explainable Paper Review Generation based on Knowledge
  Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_50.html">
      <font color="black">ReviewRobot: Explainable Paper Review Generation based on Knowledge
  Synthesis</font>
    </a>
  </h2>
  <font color="black">ReviewRobotは、次の3つのステップでこれらの目標を達成します。（1）ドメイン固有の情報抽出を実行して、レビュー中の対象論文からナレッジグラフ（KG）、対象論文で引用された論文から関連する作業KG、および背景KGを作成します。ドメイン内の以前の論文の大規模なコレクションから..（3）人間のレビュー文を慎重に選択してテンプレートに一般化し、これらのテンプレートを適用してレビュースコアと証拠を自然な言語のコメントに変換します。（2）これら3つを比較することによってKGは、各レビューカテゴリの証拠として、レビュースコアと詳細な構造化された知識を予測します。 
[要約]良いレビューは知識が豊富である必要があります、とreviewrobotは言います。彼はコメントが論文を改善するのを助けるために建設的で有益であるべきだと言います。これらのコメントもより詳細で説明可能でなければなりません、と彼は言います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: The workweek is the best time to start a family -- A Study of GPT-2
  Based Claim Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_51.html">
      <font color="black">The workweek is the best time to start a family -- A Study of GPT-2
  Based Claim Generation</font>
    </a>
  </h2>
  <font color="black">さらに、このタスクとクレーム検索のタスクの相互作用を調査し、それらがどのように相互に補完できるかを示します。引数の生成は、ソーシャルメディアへの潜在的な影響と情報の普及をタイムリーに検討している、やりがいのあるタスクです。ここでは、一貫性のあるクレームを生成するためのGPT-2に基づくパイプラインを提案し、一連の手動および自動評価を使用して、生成されるクレームのタイプとその信憑性を調査します。 
[概要]一貫性のあるクレームを生成するために、gpt-2に基づくパイプラインを提案します。それが生成するクレームのタイプとその信憑性を調査します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Simultaneous Machine Translation with Visual Context -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_52.html">
      <font color="black">Simultaneous Machine Translation with Visual Context</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、視覚的コンテキストが有用であり、明示的なオブジェクト領域情報に基づく視覚的に接地されたモデルが、一般的に使用されるグローバル機能よりもはるかに優れており、低遅延シナリオで最大3BLEUポイントの改善に達することを示しています。マルチモーダルシステムは、英語から性別がマークされた言語に正しく翻訳することができ、英語とフランス語の形容詞-名詞の配置などの語順の違いに対処できます。この論文では、視覚的な追加が情報は、欠落しているソースコンテキストを補うことができます。 
[ABSTRACT]最先端のsimtフレームワークの視覚的機能は、さまざまなマルチモーダルアプローチと視覚的機能の影響を示しています。これらの研究は、マルチモーダルシステムのみが英語から性別でマークされた言語に正しく翻訳できることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Extremely Low Bit Transformer Quantization for On-Device Neural Machine
  Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_53.html">
      <font color="black">Extremely Low Bit Transformer Quantization for On-Device Neural Machine
  Translation</font>
    </a>
  </h2>
  <font color="black">量子化されたTransformerモデルは、ベースラインモデルよりも11.8 $ \ times $小さいモデルサイズを達成し、-0.5 BLEU未満です。広く使用されているTransformerアーキテクチャの展開は、特にターゲットの場合、推論中の計算負荷とメモリオーバーヘッドが大きいため、困難です。デバイスは、モバイルデバイスやエッジデバイスなどの計算リソースに制限があります。たとえば、埋め込みブロック内の単語ごとに、統計的特性に基づいて異なる量子化ビットを割り当てます。 
[ABSTRACT]量子化は、このような課題に対処するための効果的な手法です。さらに、この単語は非常に異なる貢献を示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Interpretable Entity Representations through Large-Scale Typing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_54.html">
      <font color="black">Interpretable Entity Representations through Large-Scale Typing</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、人間が読める形式のエンティティ表現を作成し、エンティティ関連のタスクですぐに高いパフォーマンスを実現するアプローチを紹介します。これらの表現は、教師あり超のいずれかでトレーニングされた、きめ細かいエンティティタイピングモデルを使用して取得します。細かいエンティティタイピングデータ（Choi et al .. 2018）またはウィキペディアからの遠隔教師ありの例。 
[ABSTRACT]埋め込みは、ダウンストリームモデルにフィードすると効果的ですが、エンド競争力のあるパフォーマンスが必要であり、解釈が困難です。また、特定のドメインに対して、学習ベースの方法でタイプセットのサイズを縮小できることも示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: Pagsusuri ng RNN-based Transfer Learning Technique sa Low-Resource
  Language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_55.html">
      <font color="black">Pagsusuri ng RNN-based Transfer Learning Technique sa Low-Resource
  Language</font>
    </a>
  </h2>
  <font color="black">
[概要]転移学習（tl）手法を使用すると、低リソースでこの問題が軽減されます。最近の調査によると、リソースベースの代替手段よりも安価で効果的な代替手段であることが示されています。より安価で効果的な代替手段が必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Paced Learning for Neural Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_56.html">
      <font color="black">Self-Paced Learning for Neural Machine Translation</font>
    </a>
  </h2>
  <font color="black">最近の研究では、人間の学習プロセスを模倣することでニューラル機械翻訳（NMT）のトレーニングを容易にできることが証明されています。文の長さや単語の希少性。複数の翻訳タスクにわたる実験結果は、提案されたモデルが強力なベースラインよりも優れたパフォーマンスをもたらすことを示しています。そして、翻訳品質と収束速度の両方について人間が設計したカリキュラムでトレーニングされたモデル。 
[概要]自己学習の概念は、私たちによって提案されました。これには、人間の学習によって達成できる自己学習が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-09">
        <br><font color="black">2020-10-09</font>
      </time>
    </span>
</section>
<!-- paper0: Asking Crowdworkers to Write Entailment Examples: The Best of Bad
  Options -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_57.html">
      <font color="black">Asking Crowdworkers to Write Entailment Examples: The Best of Bad
  Options</font>
    </a>
  </h2>
  <font color="black">これらのプロトコルと書き込みベースのベースラインを使用して、それぞれが3kを超える例のいくつかの新しい英語NLIデータセットを収集します。各データセットは、一定量のアノテーター時間を使用しますが、その時間予算に合わせてさまざまな数の例を使用します。含意データの最もよく知られているオプションであり、書き込みベースの注釈プロセスの改善に焦点を当てるためのさらなるデータ収集作業の必要性を強調しています。NLIと転送学習に関する実験では、否定的な結果が示されています。代替プロトコルのいずれも、 NLI内または外部のターゲットタスクへの転送時の一般化。 
[概要]注釈プロトコルは有用なベンチマークデータを作成するために使用されていますが、直接評価されていないため、書き込みベースの注釈プロトコルがどのような目的にも最適であるかどうかは不明です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Internal and external pressures on language emergence: least effort,
  object constancy and frequency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_58.html">
      <font color="black">Internal and external pressures on language emergence: least effort,
  object constancy and frequency</font>
    </a>
  </h2>
  <font color="black">さらに、オブジェクトの恒常性の原則に触発されたいくつかのゲームバリアントを探索します。この原理では、画像内のオブジェクトの頻度、位置、および明るさを変更します。構成メトリック、診断分類子、とゼロショット評価..私たちの調査結果は、提案された圧力の原因が、冗長性が少なく、高レベルの概念情報に焦点を当て、一般化の能力が向上した新しい言語をもたらすことを明らかにしています。 
[概要]通信プロトコルが自然言語の顕著な特徴を表示することはめったにありません。それらは、補助的な目的を通じて最小の労力の原則を形式化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br><font color="black">2020-04-08</font>
      </time>
    </span>
</section>
<!-- paper0: What do Models Learn from Question Answering Datasets? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_59.html">
      <font color="black">What do Models Learn from Question Answering Datasets?</font>
    </a>
  </h2>
  <font color="black">分析に続いて、読解を通じて質問応答のタスクをより適切に評価する将来のQAデータセットを構築するための推奨事項を作成します。ドメイン外の例への一般化可能性、欠落または不正確なデータへの応答、および処理能力についてモデルを評価します。質問のバリエーション..https：//github.com/amazon-research/qa-dataset-converterで、QAデータセットを共有形式に変換して実験を容易にするコードもリリースしています。 
[概要]すべての実験に対して堅牢な単一のデータセットはないことがわかりました。また、qaデータセットを共有形式に変換するための分隊コードもリリースしています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br><font color="black">2020-04-07</font>
      </time>
    </span>
</section>
<!-- paper0: Fantastic Features and Where to Find Them: Detecting Cognitive
  Impairment with a Subsequence Classification Guided Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_60.html">
      <font color="black">Fantastic Features and Where to Find Them: Detecting Cognitive
  Impairment with a Subsequence Classification Guided Approach</font>
    </a>
  </h2>
  <font color="black">このデモンストレーションでは、この方法を使用して、ヘルスケアなどの解釈可能性が重要な分野での分類を支援する方法の例を示します。これに対抗するために、シーケンシャル機械学習モデルとドメインを活用する機能エンジニアリングへの新しいアプローチについて説明します。どの機能がパフォーマンスの向上に役立つかを予測する知識。自然言語処理タスクでの埋め込みベースの機械学習手法の成功が広く報告されているにもかかわらず、認知障害（CI）検出などの分野では、より簡単に解釈できる工学的機能の使用が一般的です。 
[概要]ノイズの多いテキストからの手動エンジニアリング機能は時間とリソースを消費します。これにより、モデルのパフォーマンスが向上しない機能が発生する可能性があります。この方法は、ci音声の標準データセットで使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Demographic Representation and Collective Storytelling in the Me Too
  Twitter Hashtag Activism Movement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_61.html">
      <font color="black">Demographic Representation and Collective Storytelling in the Me Too
  Twitter Hashtag Activism Movement</font>
    </a>
  </h2>
  <font color="black">交差するアイデンティティは、動きを構成するために異なる物語に貢献し、並行して進行中の動きの可視性を高めるために動きを採用し、批判的かつ支持的に同じハッシュタグを採用し、重要な瞬間に応じて新しいハッシュタグを復活させて作成したことがわかりました。コンテンツ警告：この記事では、セクシャルハラスメントと暴力の問題について説明します。白人女性が作成したツイートは、他の人口統計と比較して、不平等な表現に対する批判と一致して、運動で過大評価されていることがわかりました。 
[概要] ＃metooは、自己タグによる暴力を支援していることで賞賛されていますが、フェミニスト運動への貢献と除外された色の女性がどのように割り引かれているかを例示していることでも批判されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Mathematical Word Problem Generation from Commonsense Knowledge Graph
  and Equations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_62.html">
      <font color="black">Mathematical Word Problem Generation from Commonsense Knowledge Graph
  and Equations</font>
    </a>
  </h2>
  <font color="black">教育用ゴールドスタンダードセットと大規模に生成されたMWPセットでの実験は、私たちのアプローチがMWP生成タスクで優れており、両方の自動評価メトリックの点で最先端のモデルよりも優れていることを示しています。 BLEU-4、ROUGE-L、Self-BLEU、および人間の評価指標、つまり方程式の関連性、トピックの関連性、言語の一貫性。上記の問題に対処するために、パーソナライズされた多様なMWPを生成するエンドツーエンドのニューラルモデルを開発します。常識的な知識グラフと方程式からの実際のシナリオでは..標準の自然な質問の生成とは異なり、MWPの生成では、量と変数の間の基礎となる数学的操作を維持すると同時に、出力と特定のトピックの間の関連性を確保する必要があります。 
[概要]提案されたモデルは、自己制御モジュールを使用してmwp生成を作成します。モデルは、問題への対処方法を含む一連の科学的研究に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Aspect-based Document Similarity for Research Papers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_63.html">
      <font color="black">Aspect-based Document Similarity for Research Papers</font>
    </a>
  </h2>
  <font color="black">この論文では、ペアワイズドキュメント分類タスクを実行することにより、アスペクト情報との類似性を拡張します。私たちの調査結果は、アスペクトベースのドキュメント類似性の将来の研究と、評価された手法に基づくレコメンダーシステムの開発の動機付けとなります。 、およびトレーニング済みモデルが公開されています。 
[要約]論文の引用は、アスペクトベースの類似性を示しています。2つの新しく構築されたデータセットで実験を実行します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Fine-grained linguistic evaluation for state-of-the-art Machine
  Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_64.html">
      <font color="black">Fine-grained linguistic evaluation for state-of-the-art Machine
  Translation</font>
    </a>
  </h2>
  <font color="black">2つのシステム（東北と霍山）は、他のシステムよりもテストスイートの精度が大幅に優れているようですが、WMT20の最良のシステムは、マクロ平均でWMT19のシステムよりも大幅に優れているわけではありません。新しいシステムを提出したWMT19のシステムのほとんど今年のバージョンは改善を示しています。このペーパーでは、第5回機械翻訳会議（WMT20）の最先端のドイツ語-英語システムの言語パフォーマンスの詳細な統計を提供するテストスイートの提出について説明します。 
[概要]分析は、約5、500のテスト項目に基づく107のシステムを対象としています。これらには、45人時間の手動注釈作業が含まれます。分析は、すべてのシステムが影響を受けるいくつかの言語現象も対象とします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Training for End-to-End Speech Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_65.html">
      <font color="black">Self-Training for End-to-End Speech Translation</font>
    </a>
  </h2>
  <font color="black">これにより、MuST-C英語-フランス語および英語-ドイツ語データセットの強力な半教師ありベースラインを超える8.3および5.7 BLEUゲインが提供され、最先端のパフォーマンスに到達します。私たちのアプローチは、単に事前に作成するよりも効果的であることが示されています。音声認識タスクでエンコーダをトレーニングします。疑似ラベルの品質の影響を調査します。 
[概要]カスケードによってラベルなしオーディオから生成された疑似ラベルと、エンドツーエンドの音声翻訳モデルを活用します。エンドツーエンドの疑似ラベルを直接生成することにより、セルフトレーニングの有効性を実証しました。カスケードモデルの代わりに終了モデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-03">
        <br><font color="black">2020-06-03</font>
      </time>
    </span>
</section>
<!-- paper0: Annotationsaurus: A Searchable Directory of Annotation Tools -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/cs.CL/paper_66.html">
      <font color="black">Annotationsaurus: A Searchable Directory of Annotation Tools</font>
    </a>
  </h2>
  <font color="black">31の機能のセットでツールを分析し、簡単なスクリプトと、選択した基準に基づいてツールをフィルタリングするWebアプリケーションを実装しました。ディレクトリ、スクリプトのソースコード、およびWebアプリケーションへのリンクは次のURLで入手できます。https：// github.com/mariananeves/annotation-tools。ディレクトリを使用して2つのユースケースを提示し、そのメンテナンスのアイデアを提案します。 
[概要]注釈ツールは注釈ツール注釈ツールによって作成されました。現在93個のツールを含むWebページツールのリストを作成しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: DcaseNet: An integrated pretrained deep neural network for detecting and
  classifying acoustic scenes and events -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.AS/paper_0.html">
      <font color="black">DcaseNet: An integrated pretrained deep neural network for detecting and
  classifying acoustic scenes and events</font>
    </a>
  </h2>
  <font color="black">
[概要]最初のアーキテクチャは、成人のシーン分類の短期的な知覚に似ています。成人のシーン分類では、さまざまなサウンドイベントを検出し、それを使用して音響シーンを識別できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-21">
        <br><font color="black">2020-09-21</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring Universal Speech Attributes for Speaker Verification with an
  Improved Cross-stitch Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.AS/paper_1.html">
      <font color="black">Exploring Universal Speech Attributes for Speaker Verification with an
  Improved Cross-stitch Network</font>
    </a>
  </h2>
  <font color="black">
[ABSTRACT]音響モデリング用の新しい音声属性（nsa）ユニットは、結合されたtri-sau状態によって作成されます。コア-コアの共通条件5（cc5）およびnistsre10評価セットの10秒-10秒テストで実施された実験</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Novel Architectures for Unsupervised Information Bottleneck based
  Speaker Diarization of Meetings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.AS/paper_2.html">
      <font color="black">Novel Architectures for Unsupervised Information Bottleneck based
  Speaker Diarization of Meetings</font>
    </a>
  </h2>
  <font color="black">
[概要]この論文の主な目的は2つあります：有用なスピーチ。教師なしダイアリゼーションフレームワークにスピーカー識別機能を提供します。tpibベースのスピーカーダイアリゼーションシステムは、ベースラインのibベースのシステムよりも改善されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Symbolic Music Playing Techniques Generation as a Tagging Problem -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.AS/paper_3.html">
      <font color="black">Symbolic Music Playing Techniques Generation as a Tagging Problem</font>
    </a>
  </h2>
  <font color="black">【概要】演奏技術生成問題もタグ付け問題である。提案モデルを適用して実験を行った結果、生成された音楽をより生き生きとさせることができることがわかった。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-08">
        <br><font color="black">2020-08-08</font>
      </time>
    </span>
</section>
<!-- paper0: Converting Anyone's Emotion: Towards Speaker-Independent Emotional Voice
  Conversion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.AS/paper_4.html">
      <font color="black">Converting Anyone's Emotion: Towards Speaker-Independent Emotional Voice
  Conversion</font>
    </a>
  </h2>
  <font color="black">
[概要]提案された話者-独立した感情的な音声変換フレームワークは、並列データを必要とせずに誰の感情も変換できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br><font color="black">2020-05-13</font>
      </time>
    </span>
</section>
<!-- paper0: Low-Latency Sequence-to-Sequence Speech Recognition and Translation by
  Partial Hypothesis Selection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.AS/paper_5.html">
      <font color="black">Low-Latency Sequence-to-Sequence Speech Recognition and Translation by
  Partial Hypothesis Selection</font>
    </a>
  </h2>
  <font color="black">
[概要] how2データセットでは、レイテンシーを83％削減して0.8秒にします。オフラインシステムは、単語誤り率（wer）やブルーなどの品質指標で評価されることがよくありますが、レイテンシーも多くの実用的なユースケースで重要な要素です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-22">
        <br><font color="black">2020-05-22</font>
      </time>
    </span>
</section>
<!-- paper0: Sound event localization and detection based on crnn using rectangular
  filters and channel rotation data augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.AS/paper_6.html">
      <font color="black">Sound event localization and detection based on crnn using rectangular
  filters and channel rotation data augmentation</font>
    </a>
  </h2>
  <font color="black">
[ABSTRACT]畳み込みリカレントニューラルネットワークは、最も使用されているシステムの1つです。アルゴリズムは、長方形フィルターを使用した畳み込みリカレント問題で構成されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Content-Based Sparse Attention with Routing Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.AS/paper_7.html">
      <font color="black">Efficient Content-Based Sparse Attention with Routing Transformers</font>
    </a>
  </h2>
  <font color="black">
[概要]私たちの仕事は、関心のある主題の前にメモリを割り当てることを回避する動的な密な注意パターンを学習することを提案しています。それは、新しくリリースされたpg-43データ-3に新しいイメージを構築します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-12">
        <br><font color="black">2020-03-12</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-end Triplet Loss based Emotion Embedding System for Speech
  Emotion Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.AS/paper_8.html">
      <font color="black">End-to-end Triplet Loss based Emotion Embedding System for Speech
  Emotion Recognition</font>
    </a>
  </h2>
  <font color="black">
[ABSTRACT]提案されたシステムは、感情的な情報から埋め込みを学習します。埋め込みはさまざまな角度に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: A variational autoencoder for music generation controlled by tonal
  tension -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.AS/paper_9.html">
      <font color="black">A variational autoencoder for music generation controlled by tonal
  tension</font>
    </a>
  </h2>
  <font color="black">
[概要]これにより、生成されたピース全体の色調張力の方向と、全体的な色調張力のレベルを制御できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Training for End-to-End Speech Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-14/eess.AS/paper_10.html">
      <font color="black">Self-Training for End-to-End Speech Translation</font>
    </a>
  </h2>
  <font color="black">
[概要]カスケードによってラベルなしオーディオから生成された疑似ラベルと、エンドツーエンドの音声翻訳モデルを活用します。エンドツーエンドの疑似ラベルを直接生成することにより、セルフトレーニングの有効性を実証しました。カスケードモデルの代わりに終了モデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-03">
        <br><font color="black">2020-06-03</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
