<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-09-16の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Self-and-Mixed Attention Decoder with Deep Acoustic Structure for
  Transformer-based LVCSR -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.SD/paper_0.html">
      <font color="black">Self-and-Mixed Attention Decoder with Deep Acoustic Structure for
  Transformer-based LVCSR</font>
    </a>
  </h2>
  <font color="black">また、共有の埋め込みスペースで音響抽象化のさまざまなレベルとそれに対応する言語情報との間のアライメントを同時に学習する混合注意メカニズムも設計します。トランスフォーマーは、自動音声認識で印象的なパフォーマンスを示しました。Aishell-1のASR実験は、提案された構造は、開発セットで4.8％、テストセットで5.1％のCERを達成します。これは、このタスクで私たちの知る限り最高の結果です。 
[要約]それは、ソースとターゲットの埋め込みとの関係を学習するために自己注意をもってエンコーダ/デコーダ構造を使用します。提案された構造は、開発セットで4.8％、デバイスで5.1％のCERSを達成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br><font color="black">2020-06-18</font>
      </time>
    </span>
</section>
<!-- paper0: When Automatic Voice Disguise Meets Automatic Speaker Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.SD/paper_1.html">
      <font color="black">When Automatic Voice Disguise Meets Automatic Speaker Verification</font>
    </a>
  </h2>
  <font color="black">話者の本当のアイデンティティを隠すために音声を変換する手法は、音声変装と呼ばれます。その中で、雑多なアルゴリズムで音声のスペクトルおよび時間特性を変更することによる自動音声変装（AVD）は、一般にアクセス可能なソフトウェアで簡単に実行できます。 。この論文では、ASVがAVDの犠牲者であるだけでなく、いくつかの単純なタイプのAVDを打ち負かすツールである可能性があることを発見しました。最新のASVメソッドは、AVDの影響を客観的に評価するために利用されます。等誤り率（EER）によるASV 
[要約]この手法は、人間のリスニングと自動話者検証（asv）の両方に大きな脅威をもたらしました。提案されたアプローチは、変装を復元するために一般化されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: RECOApy: Data recording, pre-processing and phonetic transcription for
  end-to-end speech-based applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.SD/paper_2.html">
      <font color="black">RECOApy: Data recording, pre-processing and phonetic transcription for
  end-to-end speech-based applications</font>
    </a>
  </h2>
  <font color="black">このツールは、プロンプト音声の録音、スペクトログラムと波形の分析、発話レベルの正規化と無音のトリミング、およびチェコ語、英語、フランス語、ドイツ語の8つの言語のプロンプトの書記素から音素への変換のための使いやすいインターフェースを実装しています、イタリア語、ポーランド語、ルーマニア語、スペイン語。ディープラーニングにより、専門的な言語および信号処理機能の必要性を回避しながら、効率的なエンドツーエンドの音声処理アプリケーションを開発できます。このホワイトペーパーでは、RECOApyツールを紹介します。 
[要約] recoapyは、end-to-of-waveテクノロジーで必要なデータの記録と前処理のステップを合理化します。書記素-から-音素（g2p）-コンバーターは、ウィクショナリーオンラインリソースから抽出された辞書でトレーニングされます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-11">
        <br><font color="black">2020-09-11</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Audio Attacks on ASR Systems with Dropout Uncertainty -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.SD/paper_3.html">
      <font color="black">Detecting Audio Attacks on ASR Systems with Dropout Uncertainty</font>
    </a>
  </h2>
  <font color="black">私たちは、MozillaのCommonVoiceデータセット、UrbanSoundデータセット、およびLibriSpeechデータセットの抜粋で防御をテストし、幅広いシナリオで高い検出精度を達成していることを示しています。防御は、最適化された摂動を通じて作成された攻撃を検出できることを示しています。最先端のエンドツーエンドのASRシステムでの周波数マスキング。さらに、防御は、ノイズ低減の影響を受けない攻撃に対して堅牢にすることができます。 
[ABSTRACT]防御は攻撃から保護するために使用できます。防御は防御防御防御で開発されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-02">
        <br><font color="black">2020-06-02</font>
      </time>
    </span>
</section>
<!-- paper0: Determined BSS based on time-frequency masking and its application to
  harmonic vector analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.SD/paper_4.html">
      <font color="black">Determined BSS based on time-frequency masking and its application to
  harmonic vector analysis</font>
    </a>
  </h2>
  <font color="black">マイクの数がソース信号の数と等しい場合（決定された状況）、オーディオブラインドソース分離（BSS）は通常、畳み込みミキシングプロセスに対処するためにマルチチャネル線形フィルタリングによって実行されます。この論文では、決定された決定ケプストラムのスパース性を介してオーディオ信号の調和構造をモデル化することにより、調和ベクトル分析（HVA）と呼ばれるBSSメソッド。実験的な調査により、音声と音声の両方でHVAがIVAおよび独立した低ランク行列分析（ILRMA）よりも優れていることが示されています。音楽信号。 
[要約]決定されたbss問題は、「独立した低ランクのマトリックス分析」に基づいています。これらには、これらのタイプの音声と音楽が含まれます。この方法は成功裏に開発されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br><font color="black">2020-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: A dataset and classification model for Malay, Hindi, Tamil and Chinese
  music -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.SD/paper_5.html">
      <font color="black">A dataset and classification model for Malay, Hindi, Tamil and Chinese
  music</font>
    </a>
  </h2>
  <font color="black">分類モデルは、さまざまな音楽的特徴の入力としての使用を調査することによって最適化されました。この新しいデータセットを使用して、さまざまな分類モデルをトレーニングし、これらの民族グループに関して音楽の起源を区別します。両方の高レベルの機能、つまり、さまざまな分類モデルのパフォーマンスを最適化するために、オーディオファイルから音楽的に意味のある機能と低レベルの機能、つまりスペクトログラムベースの機能が抽出されました。 
[ABSTRACT]このデータセットを使用して、音楽の起源を区別するさまざまな分類モデルをトレーニングします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-09">
        <br><font color="black">2020-09-09</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Noise2Inverse: Self-supervised deep convolutional denoising for
  tomography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_0.html">
      <font color="black">Noise2Inverse: Self-supervised deep convolutional denoising for
  tomography</font>
    </a>
  </h2>
  <font color="black">ここでは、追加のクリーンまたはノイズのあるデータを必要としない線形画像再構成アルゴリズム用のDeep CNNベースのノイズ除去方法であるNoise2Inverseを提案します。ただし、この仮定は逆問題には適用されず、その結果、ノイズ除去された画像にアーティファクトが生じます。既存の方法..ノイズの多い間接測定から高品質の画像を復元することは、多くのアプリケーションで重要な問題です。 
[ABSTRACT]教師付きディープたたみ込みニューラルネットワーク（cnn）-ベースのノイズ除去方法は強力な結果を示していますが、これらの教師付き方法の成功は、同様の測定の高品質トレーニングデータセットの可用性に大きく依存します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-31">
        <br><font color="black">2020-01-31</font>
      </time>
    </span>
</section>
<!-- paper0: Mapping horizontal and vertical urban densification in Denmark with
  Landsat time-series from 1985 to 2018: a semantic segmentation solution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_1.html">
      <font color="black">Mapping horizontal and vertical urban densification in Denmark with
  Landsat time-series from 1985 to 2018: a semantic segmentation solution</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、ディープネットワークの実装とマルチスケールのコンテキスト情報を含めることで、分類と、空間と時間全体を一般化するモデルの機能が大幅に向上することを示しています。 .. 1985年から2018年にかけての結果のマップは、デンマークの2つの最大の都市であるコペンハーゲンとオーフスの間の都市成長の異なるパターンを明らかにし、これらの都市が人口増加と住宅供給の課題に対処するためにさまざまな計画ポリシーを使用していることを示しています
[ABSTRACT] deeplabは、十分なトレーニングデータが利用可能な場合、fcnよりも正確な水平および垂直分類を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Feature Fusion via Multiresolution Compressive Measurement Matrix
  Analysis For Spectral Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_2.html">
      <font color="black">Feature Fusion via Multiresolution Compressive Measurement Matrix
  Analysis For Spectral Image Classification</font>
    </a>
  </h2>
  <font color="black">より正確には、フュージョン法は、圧縮測定から高空間解像度と低次元の特徴バンドを推定する逆問題として定式化されます。フュージョン問題を解決するために、交互方向法の加速バリアントに基づくアルゴリズムについて説明します乗数（accelerated-ADMM）の組み合わせです。さらに、隣接するピクセル間の相関を考慮してピクセルの精度を向上させるために、融合問題にスパース性の促進と総変動（TV）の正則化項の両方を含めます。ベースの分類子。 
[要約]分類方法として、マルチ解像度の圧縮情報から特徴を直接融合する方法が提案されています。この概念では、圧縮測定値を推定して圧縮特徴から回復します。この目的のために、銀河は、コード化されたバリエーションに埋め込まれた情報を使用して数学的にモデル化されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Resolution enhancement and realistic speckle recovery with generative
  adversarial modeling of micro-optical coherence tomography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_3.html">
      <font color="black">Resolution enhancement and realistic speckle recovery with generative
  adversarial modeling of micro-optical coherence tomography</font>
    </a>
  </h2>
  <font color="black">高解像度のスペックル回復の有用性は、唇組織の血管のマイクロOCTイメージングの例で示されました。人間の唇（唇）組織とマウスの皮膚のin vivoイメージングから得られた断面画像（Bスキャン）ボリューム別の実現可能性実験で使用されました。グラウンドトゥルースは、（1-D）または軸と横軸の両方（2-D）のいずれかで解像度4xを合成的に低下させることによって得られた低解像度画像とペアになりました。 
[ABSTRACT]ガンは、以前は写真や光学顕微鏡画像の解像度向上に使用されていました。これらは、micro-octと呼ばれる超高解像度スペクトルoctボリュームの新しいセットで、高解像度のグラウンドトゥルースとしてトレーニングされていました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-12">
        <br><font color="black">2020-03-12</font>
      </time>
    </span>
</section>
<!-- paper0: Label-Free Segmentation of COVID-19 Lesions in Lung CT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_4.html">
      <font color="black">Label-Free Segmentation of COVID-19 Lesions in Lung CT</font>
    </a>
  </h2>
  <font color="black">ピクセルレベルでのこのようなパターンの学習を容易にするために、驚くほど単純な一連の操作を使用して「病変」を合成し、合成した「病変」を通常のCT肺スキャンに挿入してトレーニングペアを形成し、そこから正常性変換ネットワークを学習します（NormNet）これにより、「異常な」画像が正常に戻ります。3つの異なるデータセットでの実験は、さまざまな監視なしの異常検出（UAD）メソッドを著しく上回っているNormNetの有効性を検証します。私たちのモデリングは、病変が属する高輝度範囲にある気管と血管の部分は、強いパターンを示します。 
[要旨] ctの研究により、病変が属する高輝度範囲にある気管と血管の部分が強いパターンを示すことが判明</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: Bi-functional Shrinking and Amplifying Device Using Transformation
  Optics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_5.html">
      <font color="black">Bi-functional Shrinking and Amplifying Device Using Transformation
  Optics</font>
    </a>
  </h2>
  <font color="black">提案されたデバイスは、コア領域内のラップされたオブジェクトのサイズと位置を再形成できます。また、提案されたデバイスの動作機能を検証するためにアクティブスキャッターを適用しました。縮小シフトデバイスは、大きなオブジェクトを小さなオブジェクトに縮小します。そしてそれを別の場所に移動しますが、縮小変形デバイスは、別の場所にある別の形状の小さなサイズの画像を生成できます。 
[ABSTRACT]提案されたデバイスは、ラップ-コア領域内のオブジェクトのサイズと位置を再形成できます。それらは、収縮、縮小、収縮、保護など、さまざまなタイプの材料を再形成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Hybrid Multiple Attention Network for Semantic Segmentation in Aerial
  Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_6.html">
      <font color="black">Hybrid Multiple Attention Network for Semantic Segmentation in Aerial
  Images</font>
    </a>
  </h2>
  <font color="black">それにもかかわらず、空間的注意とチャネル注意の単なる視点と自己注意メカニズムの巨大な計算の複雑さによって制限されているため、複雑なスペクトルのリモートセンシングデータの各ピクセルペア間の効果的な意味の相互依存性をモデル化することはほとんどありません。この作業では、ハイブリッドマルチアテンションネットワーク（HMANet）という新しいアテンションベースのフレームワークを提案し、より効果的かつ効率的な方法で、空間、チャネル、およびカテゴリの観点からグローバル相関を適応的にキャプチャします。具体的には、以下に組み込まれたクラス拡張アテンション（CAA）モジュールクラスチャネルアテンション（CCA）モジュールを使用して、カテゴリベースの相関を計算し、クラスレベルの情報を再調整できます。 
[ABSTRACT]現在のアプローチのほとんどは、深い畳み込みニューラルネットワーク（dcnns）に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-09">
        <br><font color="black">2020-01-09</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-structure bone segmentation in pediatric MR images with combined
  regularization from shape priors and adversarial network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_7.html">
      <font color="black">Multi-structure bone segmentation in pediatric MR images with combined
  regularization from shape priors and adversarial network</font>
    </a>
  </h2>
  <font color="black">小児の磁気共鳴（MR）画像をセグメント化するという困難なタスクのために、正規化された畳み込みエンコーダーデコーダーネットワークを提案します。このために、損失関数に追加の正則化項を含むセグメンテーションネットワークの新しい最適化スキームを考案しました。グローバルに一貫性のある予測を取得するために、オートエンコーダーによって学習された非線形形状表現から導出された、形状事前分布ベースの正則化を組み込みます。 
[ABSTRACT]研究は、セグメンテーションモデルの一般化を改善するために正則化戦略を採用していることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: A Longitudinal Method for Simultaneous Whole-Brain and Lesion
  Segmentation in Multiple Sclerosis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_8.html">
      <font color="black">A Longitudinal Method for Simultaneous Whole-Brain and Lesion
  Segmentation in Multiple Sclerosis</font>
    </a>
  </h2>
  <font color="black">スキャナー、MRIプロトコル、または縦方向のフォローアップスキャンの数とタイミングについて事前の仮定を行わないため、非常に一般的に適用できます。この方法は、同時全脳の既存の断面法に基づいています。縦断的スキャン間の時間的一貫性を促進するために被験者固有の潜在変数を導入する病変セグメンテーション。この論文では、多発性硬化症に苦しむ患者の縦断的脳MRIスキャンのセグメンテーションのための新しい方法を提案します。 
[ABSTRACT]提案された方法は、同時の全体-脳と病変のセグメンテーションのための既存の方法に基づいて構築されます。また、対象-特定の潜在変数を導入して、mriスキャン間の空間を促進します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Inline holographic microscopy through fiber imaging bundles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_9.html">
      <font color="black">Inline holographic microscopy through fiber imaging bundles</font>
    </a>
  </h2>
  <font color="black">次に、体積イメージングのホログラムを数値的に再フォーカスし、1 mmの深度範囲で約6 umの解像度を達成できます。マルチモードファイバー..このスキームは複雑な事前のキャリブレーションを必要としないため、曲げの影響を受けません。 
[ABSTRACT]イメージングのタイプの薄層は、顕微鏡を通して見ることができます。これは、事前に計算された複雑なミニを必要とせず、曲げの影響を受けません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-16">
        <br><font color="black">2020-06-16</font>
      </time>
    </span>
</section>
<!-- paper0: Multivariate analysis of Brillouin imaging data by supervised and
  unsupervised learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_10.html">
      <font color="black">Multivariate analysis of Brillouin imaging data by supervised and
  unsupervised learning</font>
    </a>
  </h2>
  <font color="black">推定されたスペクトルパラメータは、純粋なフィッティングから計算されたものと一致します。結果の画像は、よりコントラストと詳細を提供し、フィッティングよりも$ 10 ^ 2 $速いタイムスケールで取得されます。ブリルアンイメージングは、微妙なスペクトルの信頼できる抽出に依存していますハイパースペクトルデータセットからの情報。 
[ABSTRACT]標準的な手法では、ラインフィッティングを使用して平均ピークシフトと線幅パラメーターを取得しています。データの推定スペクトルスペクトルは、純粋なフィッティングから計算されたものと一致しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: X-ray Multimodal Intrinsic-Speckle-Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_11.html">
      <font color="black">X-ray Multimodal Intrinsic-Speckle-Tracking</font>
    </a>
  </h2>
  <font color="black">X線シンクロトロンデータへの適用は、この方法が効率的で迅速かつ安定していることを示しています。 X線マルチモーダル固有スペックルトラッキング（MIST）を開発します。これは、位置依存の位相シフトと位置依存の小角X線の両方を回復できるX線スペックルトラッキングの形式です。位相オブジェクトの散乱（SAXS）信号。 
[要約]迅速なシステムは、近軸X線光学系のフォッカー-プランク記述と、X線スペックル追跡のオプティカルフロー形式との組み合わせに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-15">
        <br><font color="black">2019-11-15</font>
      </time>
    </span>
</section>
<!-- paper0: Ensemble learning of diffractive optical networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_12.html">
      <font color="black">Ensemble learning of diffractive optical networks</font>
    </a>
  </h2>
  <font color="black">D2NNは、オブジェクトの分類、情報のスペクトルエンコーディング、光パルス整形、イメージングなど、さまざまなタスクで成功を収めています。入力光がこれらのパッシブ層を回折するときに情報をすべて光学的に処理するための連続的な回折層の設計に基づいています。この剪定により、N = 14およびN = 30 D2NNのアンサンブルが61.14％と62.13のブラインドテスト精度を達成することを数値的に実証しました。 CIFAR-10テスト画像の分類におけるそれぞれ％、各アンサンブル内の個々のD2NNの平均パフォーマンスと比較して&gt; 16％の推論の改善を提供します。 
[ABSTRACT]光学コンピューティングハードウェアへの関心が復活しました。これは、速度の点で機械学習タスクに潜在的な利点があるためです。d2nnsは、さまざまなタスクで成功を収めています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: RUHSNet: 3D Object Detection Using Lidar Data in Real Time -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_13.html">
      <font color="black">RUHSNet: 3D Object Detection Using Lidar Data in Real Time</font>
    </a>
  </h2>
  <font color="black">これにより、自動運転車を含むリアルタイムアプリケーションでの展開が実現可能なオプションになります。結果のベンチマークと検証にKitti 3D Birds Eye Viewデータセットを使用します。トレーニングと最適化の詳細とともに、新しいニューラルネットワークアーキテクチャを提案します点群データ内の3Dオブジェクトを検出するため。 
[ABSTRACT]自律走行車が機能するためには、知覚コンポーネントが実世界のオブジェクトを検出することが非常に重要です。vgg、resnetなどの標準的なものを含むさまざまなバックボーンアーキテクチャと結果を比較し、バックボーンとのインセプション</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-09">
        <br><font color="black">2020-05-09</font>
      </time>
    </span>
</section>
<!-- paper0: xQSM: Quantitative Susceptibility Mapping with Octave Convolutional and
  Noise Regularized Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_14.html">
      <font color="black">xQSM: Quantitative Susceptibility Mapping with Octave Convolutional and
  Noise Regularized Neural Networks</font>
    </a>
  </h2>
  <font color="black">数値ファントム、シミュレートされた人間の脳、4人のin vivo健康な被験者、多発性硬化症患者、膠芽腫患者、健康なマウスの脳からの結果は、xQSMが従来の方法よりもアーティファクトを抑制し、強化されたことを示しています。磁化率のコントラスト、特に元のUネットよりも鉄に富む深部灰白質領域で一貫しています。xQSM法では、再構成時間も従来の反復法を使用した分から数秒にまで大幅に短縮しました。しかし、画像QSMの再構築は、不適切な双極子反転プロセスのために困難です。 
[要約] xqsmメソッドは最近提案されたu-conベースおよび従来の正則化ベースのメソッドと比較されました。結果はxqsmプロセスのためにシミュレーションされています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-14">
        <br><font color="black">2020-04-14</font>
      </time>
    </span>
</section>
<!-- paper0: Investigating the impact of preprocessing and prediction aggregation on
  the DeepFake detection task -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_15.html">
      <font color="black">Investigating the impact of preprocessing and prediction aggregation on
  the DeepFake detection task</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案された前処理アプローチにより検出モデルのパフォーマンスが大幅に向上することを示しており、予測集約方式により、ビデオに複数の顔がある場合の検出効率がさらに向上します。このホワイトペーパーでは、前処理ステップを提案します。問題のトレーニングコーパスの品質を向上させるために。DeepFake検出パフォーマンスへの影響を調べ、ビデオレベルの予測集約アプローチの影響を調査します。 
[要約]多くのディープフェイク検出方法がありますが、データセット前処理の影響に焦点を当てているものはごくわずかです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-12">
        <br><font color="black">2020-06-12</font>
      </time>
    </span>
</section>
<!-- paper0: Learning a Single Model with a Wide Range of Quality Factors for JPEG
  Image Artifacts Removal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_16.html">
      <font color="black">Learning a Single Model with a Wide Range of Quality Factors for JPEG
  Image Artifacts Removal</font>
    </a>
  </h2>
  <font color="black">実例を示すために、1〜60の範囲の品質係数を使用したJPEG圧縮に注目します。さらに、復元ブランチとグローバルブランチの2つのブランチが並列にあります。提案されているネットワークは単一モデルのアプローチです。優れたまたは同等の画像アーチファクト除去パフォーマンスを一貫して提供しながら、幅広い品質要因を処理するようにトレーニングできます。 
[要約]提案されたネットワークは、畳み込みニューラルネットワーク（cnn）に基づいています。幅広い品質係数を処理するようにトレーニングできますが、優れた、または同等の画像アーチファクト除去パフォーマンスを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: A Physical Model for Microstructural Characterization and Segmentation
  of 3D Tomography Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_17.html">
      <font color="black">A Physical Model for Microstructural Characterization and Segmentation
  of 3D Tomography Data</font>
    </a>
  </h2>
  <font color="black">体積分率、界面面積、材料密度などの画像化されたサンプルのパラメーター、および画像解像度やノイズレベルなどの画像化プロセスに関連するパラメーターを直接定量化できます。既存の確率的手法への入力としてモデルを使用できることを示します。 、画像化されたサンプルの物理に基づくセグメンテーションを提供します。このモデルは、画像化技術に固有のぼかしに起因する混合材料ボクセルを考慮しているため、他の方法が材料間の界面で作成できるエラーを減らします。 
[要約]この方法は、voxtificationsの分布の新しい統計モデルに基づいています。これにより、イメージングプロセスの物理的性質に関する事前の知識が得られます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: F3RNet: Full-Resolution Residual Registration Network for Multimodal
  Image Registration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_18.html">
      <font color="black">F3RNet: Full-Resolution Residual Registration Network for Multimodal
  Image Registration</font>
    </a>
  </h2>
  <font color="black">臨床的に取得された50組の患者内腹部CT-MRIデータで提案された方法を検証します。したがって、これらのアプローチは、たとえば変形した肝葉の患者内登録など、一部の整列が困難な領域に敏感ではありません。 CTからMRIおよびMRIからCTへの登録の両方で、最先端のアプローチと比較して有望な結果が示されます。 
[要約]この論文は、重度に変形した臓器のマルチモーダル登録のための新しい教師なし登録ネットワークを提案します。これらには、フル解像度の残余登録ネットワーク（f3rnet）が含まれます。1つのストリームは、正確な学習に役立つフル解像度情報を利用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: 4S-DT: Self Supervised Super Sample Decomposition for Transfer learning
  with application to COVID-19 detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_19.html">
      <font color="black">4S-DT: Self Supervised Super Sample Decomposition for Transfer learning
  with application to COVID-19 detection</font>
    </a>
  </h2>
  <font color="black">この論文では、新しい深層畳み込みニューラルネットワークを提案し、転移学習（4S-DT）モデルの自己監視スーパーサンプル分解と呼びます。4S-DTは、クラスを使用したダウンストリーム学習戦略による知識変換の堅牢性の向上に役立ちます-データのローカル構造を簡略化するための分解レイヤー。4S-DTは、大規模な画像認識タスクから、一般的な自己監視サンプル分解を使用した特定の胸部X線画像分類タスクへの粗から細かい転送学習を促進します。アプローチ。 
[ABSTRACT] 4s-dtは、データの不規則性または不均衡なクラスを持つデータセット用の堅牢な画像分類モデルを開発しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-26">
        <br><font color="black">2020-06-26</font>
      </time>
    </span>
</section>
<!-- paper0: Microscope Based HER2 Scoring System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_20.html">
      <font color="black">Microscope Based HER2 Scoring System</font>
    </a>
  </h2>
  <font color="black">最近、人工知能（AI）はさまざまな病気の診断で診断の正確さと信頼性を向上させるために使用されていますが、診断結果の解釈は未解決の問題です。AIと病理学者のコラボレーションにより、システムの堅牢性が大幅に向上します。このペーパーでは、診断を完了するためにHER2スコアリングガイドラインに従うリアルタイムHER2スコアリングシステムを提案します。したがって、各ステップは説明可能です。 
[要約]人工知能は、診断の精度と信頼性を向上させるためにさまざまな病気の診断に使用されています。しかし、診断結果の解釈は未解決の問題です。当社のシステムは、読み取り中にAIの結果を病理医にフィードバックできる拡張現実顕微鏡に統合されていますスライド</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Context Model for Pedestrian Intention Prediction using Factored
  Latent-Dynamic Conditional Random Fields -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_21.html">
      <font color="black">Context Model for Pedestrian Intention Prediction using Factored
  Latent-Dynamic Conditional Random Fields</font>
    </a>
  </h2>
  <font color="black">2つの異なるデータセットにメソッドを適用します。1つは社内で収集されたもの-NTUデータセットともう1つの公共の実際のベンチマーク-JAADデータセットです。 .. FLDCRFは、同一の時系列特徴にわたってデータセット全体（データセットあたり$ \ sim $ 100シーケンス）のLong Short-Term Memory（LSTM）ネットワークよりも優れています。 
[ABSTRACT]既存のシステムは、歩行者の横断または非横断の予測を車両の前で支援します。これらのシステムは、歩行者の早期かつ正確な予測を必要とします。これらのシステムは、そのようなシステムの円滑な運用のための早期予測の必要性を述べています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-27">
        <br><font color="black">2019-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: UniVL: A Unified Video and Language Pre-Training Model for Multimodal
  Understanding and Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_22.html">
      <font color="black">UniVL: A Unified Video and Language Pre-Training Model for Multimodal
  Understanding and Generation</font>
    </a>
  </h2>
  <font color="black">ビデオテキストジョイント、条件付きマスク言語モデル（CMLM）、条件付きマスクフレームモデル（CMFM）、ビデオテキストの配置、および言語再構成を含む5つの目的は、各コンポーネントをトレーニングするように設計されています。実験結果は、UniVL強力なビデオテキスト表現を学習し、5つのダウンストリームタスクで最先端の結果を達成できます。さらに、2つの事前トレーニング戦略を段階的に事前トレーニング（StagedP）と強化されたビデオ表現（EnhancedV）で開発し、 UniVLのトレーニングプロセスをより効果的にします。 
[ABSTRACT]これらには、2つのシングルモーダルエンコーダー、クロスエンコーダー、およびトランスフォーマーバックボーンを備えたデコーダーが含まれます。univlは、強力なビデオ-テキスト表現を学習し、5つのダウンストリームタスクで最先端の結果を達成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-15">
        <br><font color="black">2020-02-15</font>
      </time>
    </span>
</section>
<!-- paper0: AIM 2020 Challenge on Efficient Super-Resolution: Methods and Results -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_23.html">
      <font color="black">AIM 2020 Challenge on Efficient Super-Resolution: Methods and Results</font>
    </a>
  </h2>
  <font color="black">彼らは、最先端の効率的な単一画像超解像を測定します。このペーパーでは、提案されたソリューションと結果に焦点を当てて、効率的な単一画像超解像に関するAIM 2020の課題をレビューします。目標は、ネットワークを考案することです。少なくともMSRResNetのPSNRを維持しながら、ランタイム、パラメーターカウント、FLOP、アクティブ化、メモリ消費などの1つまたはいくつかの側面を削減します。 
[要旨]課題は、画像を拡大係数x4で超解像することでした。トラックには150人の参加者が登録されており、25チームが最終結果を提出しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Attention Cube Network for Image Restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_24.html">
      <font color="black">Attention Cube Network for Image Restoration</font>
    </a>
  </h2>
  <font color="black">適応空間注意ブランチ（ASAB）と適応チャネル注意ブランチ（ACAB）は、適応型デュアル注意モジュール（ADAM）を構成します。これは、長距離空間情報とチャネルごとのコンテキスト情報をキャプチャして、受容野を拡張し、さまざまなタイプを区別します。より効果的な特徴表現のための情報の集合。さらに、既存の方法は常にマルチ教師付き方法を使用して異なる特徴マップを集約しますが、階層的特徴情報を効果的に集約することはできません。しかし、既存の方法のほとんどはローカル受容フィールドと等しいさまざまな種類の情報の扱い。 
[ABSTRACT]これは、多くの方法が局所受容野に限定された最初の例です。代わりに、より強力な特徴表現と特徴相関学習のために、画像復元用のアテンションキューブネットワーク（-cubenet）を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-13">
        <br><font color="black">2020-09-13</font>
      </time>
    </span>
</section>
<!-- paper0: Performance Estimation of a Real-Time Rosette Imager -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_25.html">
      <font color="black">Performance Estimation of a Real-Time Rosette Imager</font>
    </a>
  </h2>
  <font color="black">さらに、ベイジアンフレームワークでさまざまなロゼットイメージャーの構成を比較します。また、ロゼットイメージャーは、同等のサンプルのフォーカルプレーンアレイよりも画質が優れているとは言えませんが、パフォーマンスに匹敵します。センサーの視野は一様なランダムサンプリングを使用した貪欲なアプローチによって決定されます。 
[ABSTRACT]私たちは微調整-適切なセンサーの視野とロゼットパターンを選択することにより、ロゼットアプローチを調整します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: LAMP: Large Deep Nets with Automated Model Parallelism for Image
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.IV/paper_26.html">
      <font color="black">LAMP: Large Deep Nets with Automated Model Parallelism for Image
  Segmentation</font>
    </a>
  </h2>
  <font color="black">広範な実験により、自動化されたモデルの並列処理によって促進されるセグメンテーションの精度は、モデルサイズと入力コンテキストサイズを増やすことで改善でき、入力が大きいと、推論内の小さなパッチのスライディングウィンドウに比べて推論が大幅に高速化されることがわかります。コードが利用可能です\ footnote {https://monai.io/research/lamp-automated-model-parallelism} ..自動化されたモデルの並列処理により、画像全体でさえ、大きな入力パッチで大きな深い3D ConvNetをトレーニングすることが可能です。 
[ABSTRACT]データの並列処理とモデルの並列処理は、並列トレーニングの2つのよく知られたルートです。これらには、データの並列処理、モデルの並列処理、モデルのモデルの並列処理が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-22">
        <br><font color="black">2020-06-22</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Noise2Inverse: Self-supervised deep convolutional denoising for
  tomography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_0.html">
      <font color="black">Noise2Inverse: Self-supervised deep convolutional denoising for
  tomography</font>
    </a>
  </h2>
  <font color="black">ただし、この仮定は逆問題には適用されず、既存の方法で生成されたノイズ除去された画像にアーティファクトが発生します。CNNベースのノイズ除去のトレーニングは、ノイズモデルを活用して統計的に独立した複数の再構成を計算することで可能になります。ここで、Noise2Inverseを提案します。 、追加のクリーンなデータやノイズの多いデータを必要としない線形画像再構成アルゴリズム用のディープCNNベースのノイズ除去メソッド。 
[ABSTRACT]教師付きディープたたみ込みニューラルネットワーク（cnn）-ベースのノイズ除去方法は強力な結果を示していますが、これらの教師付き方法の成功は、同様の測定の高品質トレーニングデータセットの可用性に大きく依存します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-31">
        <br><font color="black">2020-01-31</font>
      </time>
    </span>
</section>
<!-- paper0: Decision-based Universal Adversarial Attack -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_1.html">
      <font color="black">Decision-based Universal Adversarial Attack</font>
    </a>
  </h2>
  <font color="black">単一の摂動は、最も自然な画像を分類子によって誤って分類される可能性があります。さらに、上部の畳み込み層はストライプに敏感であるため、直交行列に基づくストライプのようなテクスチャーを持つ単一の摂動を生成する敵を設計することを目指しています。データ、提案された敵は、最終的に推定されたラベルのみに基づいて摂動を計算しますが、モデル全体だけでなく、さまざまなビジョンタスクにまたがる優れた転送可能性が実現されています。 
[ABSTRACT]現在の普遍的な敵対的な攻撃方法は、代用モデルを使用して摂動を生成し、次に摂動したモデルに摂動を適用します。この目的のために、効率的な意思決定ベースの普遍的な攻撃（duattack）を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: ResNet-like Architecture with Low Hardware Requirements -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_2.html">
      <font color="black">ResNet-like Architecture with Low Hardware Requirements</font>
    </a>
  </h2>
  <font color="black">本稿では、より複雑なResNetアーキテクチャからその層を双極形態学的なものに変換することによって得られる双極形態的ResNet（BM-ResNet）モデルを紹介します。現代の認識システムで最も計算集約的な部分の1つは、画像の分類、セグメンテーション、強化、および認識に使用されるニューラルネットワーク。双極形態ニューロンは、乗算を加算および最大演算に置き換えるという考えに基づいています。 
[ABSTRACT]エッジコンピューティングの人気の高まりにより、モバイルデバイスや組み込みデバイスの時間を短縮する方法を模索しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Label-Free Segmentation of COVID-19 Lesions in Lung CT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_3.html">
      <font color="black">Label-Free Segmentation of COVID-19 Lesions in Lung CT</font>
    </a>
  </h2>
  <font color="black">ピクセルレベルでのこのようなパターンの学習を容易にするために、驚くほど単純な一連の操作を使用して「病変」を合成し、合成した「病変」を通常のCT肺スキャンに挿入してトレーニングペアを形成し、そこから正常性変換ネットワークを学習します（NormNet）これにより、「異常な」画像が正常に戻ります。3つの異なるデータセットでの実験により、さまざまな監視なしの異常検出（UAD）メソッドよりも著しく優れたNormNetの有効性が検証されています。注釈付き画像の不足により、 CTからの信頼できるCOVID-19診断と評価のための自動化ソリューション。データ注釈の負担を軽減するために、ここでは、通常のCT肺スキャンから関連知識を掘り出すピクセルレベルの異常モデリングを介して、CTのCOVID-19病変をセグメント化するためのラベルフリーアプローチを示します。 
[要旨] ctの研究により、病変が属する高輝度範囲にある気管と血管の部分が強いパターンを示すことが判明</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-08">
        <br><font color="black">2020-09-08</font>
      </time>
    </span>
</section>
<!-- paper0: RelativeNAS: Relative Neural Architecture Search via Slow-Fast Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_4.html">
      <font color="black">RelativeNAS: Relative Neural Architecture Search via Slow-Fast Learning</font>
    </a>
  </h2>
  <font color="black">比較的精度の高いネットワーク）とペアの方法で遅い学習者です。RelativeNASの実装は、https：//github.com/EMI-Group/RelativeNASで入手できます。さらに、RelativeNASは、高速学習者と低速学習者の各ペアを区別するために、忠実度の低いパフォーマンス推定しか必要としないため、候補アーキテクチャのトレーニングに必要な計算コストを節約できます。 
[ABSTRACT]微分可能なnasとポピュレーションベースのnasは、そのユニークな特性により関心を集めています。relativenasは、fast-learners。の間で共同学習を実行します。効率的な検索の鍵として、relativenasは、低いネットワークのCNNのみを必要とします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Consistency Regularization with Generative Adversarial Networks for
  Semi-Supervised Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_5.html">
      <font color="black">Consistency Regularization with Generative Adversarial Networks for
  Semi-Supervised Learning</font>
    </a>
  </h2>
  <font color="black">この作業では、バニラセミGANに整合性の正則化を導入して、この重大な制限に対処します。2つのSSL画像分類ベンチマークデータセット、SVHNとCIFAR-10に対するアプローチの有効性を示します。特に、新しいローカル整合性と補間整合性の両方を利用する複合整合性正則化メソッド。 
[ABSTRACT]新しい複合整合性正則化メソッドベースのセミガンは、パフォーマンスを大幅に向上させます。新しい方法は、ローカル整合性と補間整合性に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Reinforcement Learning for Unknown Anomaly Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_6.html">
      <font color="black">Deep Reinforcement Learning for Unknown Anomaly Detection</font>
    </a>
  </h2>
  <font color="black">部分的にラベル付けされた異常の小さなセットとラベル付けされていない大規模なデータセットから検出モデルを学習することを目的とする、重大で未解決の異常検出問題に対処します。このアプローチは、既存のデータモデルの活用と新しい探索のバランスをとることを学習します。異常のクラス..異常は必然的に形式的に予測不可能であり、見逃すのにしばしば費用がかかるため、これは重要な実用的な利点です。 
[ABSTRACT]これは、多くの重要なアプリケーションで一般的なシナリオです。ラベル付きのトレーニングデータの範囲を超えて存在する新しい種類の異常を積極的に探す、学習ベースのアプローチではなく、これを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Hybrid Multiple Attention Network for Semantic Segmentation in Aerial
  Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_7.html">
      <font color="black">Hybrid Multiple Attention Network for Semantic Segmentation in Aerial
  Images</font>
    </a>
  </h2>
  <font color="black">超高解像度（VHR）の航空写真でのセマンティックセグメンテーションは、リモートセンシングの画像理解において最も困難なタスクの1つです。具体的には、クラスチャネルアテンション（CCA）モジュールが組み込まれたクラス拡張アテンション（CAA）モジュールを使用して計算できます。カテゴリベースの相関とクラスレベル情報の再キャリブレーション。ただし、ローカル受容野との標準の畳み込みは、グローバル依存関係のモデリングに失敗します。 
[ABSTRACT]現在のアプローチのほとんどは、深い畳み込みニューラルネットワーク（dcnns）に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-09">
        <br><font color="black">2020-01-09</font>
      </time>
    </span>
</section>
<!-- paper0: Bayesian Geodesic Regression on Riemannian Manifolds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_8.html">
      <font color="black">Bayesian Geodesic Regression on Riemannian Manifolds</font>
    </a>
  </h2>
  <font color="black">次に、次元の削減と人間の脳梁と下顎骨のデータの形状変動の分析におけるモデルの有効性を示します。次元を自動的に選択するために、関連する次元の数を自動的に選択できる測地線回帰モデルの事前モデルを開発します。不必要な接線ベクトルをゼロに駆動することによって。オーバーフィットの問題を回避するために、モデルの有効性を制御するための正則化項を追加します。 
[ABSTRACT]過剰適合の問題を回避するために、モデルの有効性を制御するための定期的な用語を追加します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Unpaired Image-to-Image Translation using Adversarial Consistency Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_9.html">
      <font color="black">Unpaired Image-to-Image Translation using Adversarial Consistency Loss</font>
    </a>
  </h2>
  <font color="black">この損失により、変換された画像を特定のソース画像に変換する必要はありませんが、変換された画像がソース画像の重要な機能を保持し、上記のサイクルの一貫性の損失の欠点を克服するように促すことができます。厳密なピクセルレベルの制約、それは幾何学的な変更を実行したり、大きなオブジェクトを削除したり、無関係なテクスチャを無視したりすることはできません。私たちの方法は、3つの挑戦的なタスクで最先端の結果を達成します：メガネの削除、男性から女性への変換、そして自撮りからアニメへの翻訳。 
[ABSTRACT]この方法は、画像から画像への変換のための新しいレベルの「一貫性の損失」に基づいています。これは、ソースがビジョンの状態を達成するために管理するのが初めての場合です。画像と自撮りのマッピング結果-アニメ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-10">
        <br><font color="black">2020-03-10</font>
      </time>
    </span>
</section>
<!-- paper0: 360-Degree Gaze Estimation in the Wild Using Multiple Zoom Scales -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_10.html">
      <font color="black">360-Degree Gaze Estimation in the Wild Using Multiple Zoom Scales</font>
    </a>
  </h2>
  <font color="black">別の挑戦的なタスクである360度の視線推定（Gaze360データセットでも導入）は、前方の視線だけでなく後方の視線も推定することで構成されます。後方の視線は、視線のヨー角値に不連続性をもたらし、ディープラーニングモデルは、不連続点の周りのいくつかの大きな損失の影響を受けます。距離が変化すると、画像の顔のサイズが変化するため、現在のCNNバックボーンが視線をロバストに推定することが困難になります。 
[ABSTRACT] gaze360データセットは、さまざまなカメラ（人物の距離）がある制約のない環境で収集されたデータに基づいています。このプロジェクトは、顔の領域に焦点を当てて視線を特定するという自然のスキルに触発されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-structure bone segmentation in pediatric MR images with combined
  regularization from shape priors and adversarial network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_11.html">
      <font color="black">Multi-structure bone segmentation in pediatric MR images with combined
  regularization from shape priors and adversarial network</font>
    </a>
  </h2>
  <font color="black">このために、損失関数に追加の正則化項を含むセグメンテーションネットワークの新しい最適化スキームを考案しました。小児の筋骨格系の形態学的および診断的評価は、臨床診療において極めて重要です。グローバルに一貫した予測を得るために、オートエンコーダーによって学習された非線形形状表現から派生した、形状事前分布ベースの正則化を組み込みます。 
[ABSTRACT]研究は、セグメンテーションモデルの一般化を改善するために正則化戦略を採用していることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: AMRNet: Chips Augmentation in Areial Images Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_12.html">
      <font color="black">AMRNet: Chips Augmentation in Areial Images Object Detection</font>
    </a>
  </h2>
  <font color="black">具体的には、既存のすべてのトリミング方法と互換性のあるスケール適応モジュールを提案します。現在のソリューションでは、トリミング方法をほぼ採用しています。高解像度画像をシリアルサブ領域（チップ）に分割して検出します。オブジェクト間のカバー比率のバランスをとるようにトリミングサイズを動的に調整しますチップは、トレーニングにおけるオブジェクトスケールの変動を狭め、ベルやホイッスルなしでパフォーマンスを向上させます。さらに、面的なデータセットにモザイク効果のあるスロビングオブジェクトの距離と背景の類似性の問題を導入します。カテゴリのバランスをとるために、より高品質のトレーニングサンプルを提供するチップでのマスクリサンプリングを紹介します。私たちのモデルは、VisDroneとUAVDTの2つの人気のある航空写真データセットで最先端のパフォーマンスを実現します。 
[ABSTRACT]現在のソリューションはほぼトリミング方法を採用しています：高解像度画像を連続したサブ領域（チップ）に分割して検出します。この作業では、3つの拡張方法を紹介します。さらに、モザイクの効果的なスロビングオブジェクトのパリティと背景の類似性の問題を紹介します地域データセット</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Light Can Hack Your Face! Black-box BackdoorAttack on Face Recognition
  Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_13.html">
      <font color="black">Light Can Hack Your Face! Black-box BackdoorAttack on Face Recognition
  Systems</font>
    </a>
  </h2>
  <font color="black">私たちの研究が、既存の顔認識/検証技術のセキュリティ問題の注意を喚起する新しい物理的なバックドア攻撃を明らかにしたことを強調します。具体的には、新しいカラーストライプパターントリガーによるバックドア攻撃を提案します。 LEDを特殊な波形に変調することで生成されます。また、バックドア攻撃用に波形を最適化するために、進化的なコンピューティング戦略を使用しています。 
[ABSTRACT] bruce bruce schneier：新しいカラーストライプパターントリガーを使用したバックドア攻撃を提案します。攻撃は非常に穏やかな状態で実行できると言います。schneier：私たちの攻撃はまだ効果的です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Polyp-artifact relationship analysis using graph inductive learned
  representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_14.html">
      <font color="black">Polyp-artifact relationship analysis using graph inductive learned
  representations</font>
    </a>
  </h2>
  <font color="black">ただし、ポリープとアーティファクトの空間的相互作用に関連する事前知識の使用はまだ検討されていません。この作業では、アーティファクト知識を後処理ステップに組み込みます。ポリープとアーティファクトの周囲で検出された境界ボックスはノードと見なされます定義された基準によって接続されています。 
[要約]ポリープの空間的相互作用に関連する事前知識の使用はまだ考慮されていません。私たちの方法は、このタスクを帰納的グラフ表現の学習問題としてモデル化しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: A Longitudinal Method for Simultaneous Whole-Brain and Lesion
  Segmentation in Multiple Sclerosis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_15.html">
      <font color="black">A Longitudinal Method for Simultaneous Whole-Brain and Lesion
  Segmentation in Multiple Sclerosis</font>
    </a>
  </h2>
  <font color="black">この論文では、多発性硬化症に罹患している患者の縦脳MRIスキャンのセグメンテーションのための新しい方法を提案します。縦方向スキャン間の時間的一貫性を促進します。これは、スキャナー、MRIプロトコル、または縦方向フォローアップスキャンの数とタイミングに関する事前の仮定を行わないため、非常に一般的に適用できます。 
[ABSTRACT]提案された方法は、同時の全体-脳と病変のセグメンテーションのための既存の方法に基づいて構築されます。また、対象-特定の潜在変数を導入して、mriスキャン間の空間を促進します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Puzzle Mix: Exploiting Saliency and Local Statistics for Optimal Mixup -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_16.html">
      <font color="black">Puzzle Mix: Exploiting Saliency and Local Statistics for Optimal Mixup</font>
    </a>
  </h2>
  <font color="black">ソースコードはhttps://github.com/snu-mllab/PuzzleMixで入手できます。ディープニューラルネットワークはトレーニング分布の適合において優れたパフォーマンスを実現しますが、学習したネットワークは過剰適合する傾向があり、敵対的な攻撃を受けやすくなります。最適なミキシングマスクのマルチラベル目標と顕著性を割引かれた最適な輸送目標の間で交互になる興味深い最適化問題につながります。 
[ABSTRACT]パズルミックスは、最先端の一般化と敵対的な警戒結果を達成しました。これは、ciml-100、tiny-puzzlenet、およびimagenetデータセットの他のミックスアップメソッドと比較します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Deformable Kernel Networks for Joint Image Filtering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_17.html">
      <font color="black">Deformable Kernel Networks for Joint Image Filtering</font>
    </a>
  </h2>
  <font color="black">畳み込みニューラルネットワーク（CNN）に基づく以前の方法では、空間的に不変なカーネルの非線形活性化を組み合わせて、構造の詳細を推定し、フィルタリング結果を後退させます。モダリティ間の画像の復元、テクスチャの削除、セマンティックセグメンテーションなど。フィルタリングの結果は、加重平均として計算されます。 
[要約]変形可能なカーネルネットワーク（dkn）はcnnアーキテクチャです。近隣のセットと対応する重みを各ピクセルに適応的に生成します。dknの高速バージョンは、サイズ640 x 480の画像に対して17倍速く実行されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-17">
        <br><font color="black">2019-10-17</font>
      </time>
    </span>
</section>
<!-- paper0: Promoting Connectivity of Network-Like Structures by Enforcing Region
  Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_18.html">
      <font color="black">Promoting Connectivity of Network-Like Structures by Enforcing Region
  Separation</font>
    </a>
  </h2>
  <font color="black">2つの標準道路ベンチマークと灌漑用水路の新しいデータセットの実験で、損失関数で訓練されたコンネットが道路の接続性を非常によく回復し、最新のマップを作成するために出力をスケルトン化することで十分であることを示します。航空写真から道路や灌漑用水路などのネットワークのような構造を再構築するために深い畳み込みネットワークをトレーニングするための新しい接続指向の損失関数。簡単に言えば、予測された道路のギャップは、2つの背景領域を引き起こし、グランドトゥルース道路の反対側、予測に触れます。 
[要約]損失の背後にある主なアイデアは、道路または運河の接続を、画像の背景領域間に作成される切断の観点から表現することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: How to track your dragon: A Multi-Attentional Framework for real-time
  RGB-D 6-DOF Object Pose Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_19.html">
      <font color="black">How to track your dragon: A Multi-Attentional Framework for real-time
  RGB-D 6-DOF Object Pose Tracking</font>
    </a>
  </h2>
  <font color="black">提案されたフレームワークは、複数の並列ソフト空間注意モジュールをマルチタスクの畳み込みニューラルネットワーク（CNN）アーキテクチャに統合することで、バックグラウンドクラッタとオクルージョンの処理方法をカプセル化します。 D 6Dオブジェクトポーズは、単一の既知のオブジェクトを追跡します。このような問題は、オブジェクトの性質と環境との相互作用の両方に起因する複数の課題を引き起こします。これは、以前のアプローチでは十分に対処できませんでした。 
[ABSTRACT]問題は、オブジェクトの性質や環境との相互作用にどのように対応するかなど、複数の課題を引き起こします。これは、対象の全体的なプレゼンテーションなど、多くの技術的な問題が原因です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br><font color="black">2020-04-21</font>
      </time>
    </span>
</section>
<!-- paper0: A Mobile App for Wound Localization using Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_20.html">
      <font color="black">A Mobile App for Wound Localization using Deep Learning</font>
    </a>
  </h2>
  <font color="black">これらのモデルの堅牢性と信頼性は、Medetecという名前の公に利用可能なデータセットでもテストされ、非常に優れたパフォーマンスも示しています。YOLOv3モデルはSSDモデルと比較され、YOLOv3は93.9％のmAP値を提供します。 SSDモデル（86.4％）よりも優れています。自動化された完全な創傷診断システムを構築するための最初のステップとして、ディープニューラルネットワークを使用して、2D創傷および潰瘍画像から自動化された創傷ローカライザを提示します。 
[要旨] yolov3モデルを使用して開発された創傷ローカライザは、iOSモバイルアプリケーションに変換されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Ensemble learning of diffractive optical networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_21.html">
      <font color="black">Ensemble learning of diffractive optical networks</font>
    </a>
  </h2>
  <font color="black">ここでは、特徴エンジニアリングとアンサンブル学習を使用して、回折光ネットワークの推論パフォーマンスを大幅に改善します。この剪定により、N = 14とN = 30のD2NNのアンサンブルが、それぞれ61.14％と62.13％のブラインドテスト精度を達成することを数値で示しました、CIFAR-10テスト画像の分類で、各アンサンブル内の個々のD2NNの平均パフォーマンスと比較して&gt; 16％の推論の改善を提供します。回折ディープニューラルネットワーク（D2NN）は、このような光学コンピューティングフレームワークを形成し、入力光がこれらのパッシブ層を回折するときに情報をすべて光学的に処理するための、連続する回折層の深層学習ベースの設計。 
[ABSTRACT]光学コンピューティングハードウェアへの関心が復活しました。これは、速度の点で機械学習タスクに潜在的な利点があるためです。d2nnsは、さまざまなタスクで成功を収めています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Optimal Use of Multi-spectral Satellite Data with Convolutional Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_22.html">
      <font color="black">Optimal Use of Multi-spectral Satellite Data with Convolutional Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">利用可能なすべてのバンド情報を使用するだけでテスト時間のパフォーマンスが向上することを示し、この作業で最初にバンド選択に適用されたベイジアン最適化を使用して、精度をさらに高めることができることを示します。具体的には、以下を比較します。専門家;利用可能なすべてのバンドを使用します。入力バンド上の注意マップを学習します。ドメインの専門家が選択したバンドを使用するという標準的な業界の慣行は、比較される他の方法よりもテストの精度が大幅に低下することを示しています。 
[ABSTRACT]ドメインエキスパートによって選択されたバンドを使用する標準的な方法は、比較される他の方法よりもテスト精度が大幅に低下することを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-scale Attention U-Net (MsAUNet): A Modified U-Net Architecture for
  Scene Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_23.html">
      <font color="black">Multi-scale Attention U-Net (MsAUNet): A Modified U-Net Architecture for
  Scene Segmentation</font>
    </a>
  </h2>
  <font color="black">また、これらのネットワークは、ローカル機能の長期的な依存関係のマッピングに失敗します。その結果、セグメント化された画像の各セマンティッククラスに対応する特徴的な機能マップが生成されます。最近、コンボリューションニューラルネットワーク（CNN）の成功が高まっていますがシーンセグメンテーションのタスクでは、標準モデルには、次善のセグメンテーション出力をもたらす可能性のある重要な機能がいくつかありません。IoUロスを最適化し、ダイスロスと加重クロスエントロピーロスを融合することにより、複合ロス関数を提案します。より速い収束率で最適なソリューションを実現します。 
[ABSTRACT]過去に新しいマルチスケールアテンションネットワークを提案します。ネットワークは、ローカル機能をグローバルな対応機能とともに精度を向上させることができます。また、異なる出力でネットワークを出力し、識別画像領域を強調することもできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Collaborative Distillation in the Parameter and Spectrum Domains for
  Video Action Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_24.html">
      <font color="black">Collaborative Distillation in the Parameter and Spectrum Domains for
  Video Action Recognition</font>
    </a>
  </h2>
  <font color="black">したがって、以前の多くの作品のように機能を抽出する\ textit {implicitly}ではなく、生徒ネットワークに教師ネットワークからの時間周波数スペクトルを模倣するように強制するスペクトル損失を導入します。私たちの洞察は、アクション認識の魅力的なパフォーマンスには\ textitが必要であることです。 {explicitly}モデルによるビデオ特徴の時間的周波数スペクトルのモデリング。具体的には、周波数領域での2つの蒸留戦略、つまり、特徴スペクトルとパラメーター分布の蒸留をそれぞれ提案します。 
[ABSTRACT]研究は、行動認識のための小さく効率的なネットワークをトレーニングする方法を示しています。彼らは、行動認識の魅力的なパフォーマンスには「textit 
[明示的に]ビデオ機能の時間周波数スペクトルのモデリング」が必要であると主張しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: RUHSNet: 3D Object Detection Using Lidar Data in Real Time -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_25.html">
      <font color="black">RUHSNet: 3D Object Detection Using Lidar Data in Real Time</font>
    </a>
  </h2>
  <font color="black">結果のベンチマークと検証にKitti 3D Birds Eye Viewデータセットを使用します。また、効率的なアンカーの設計を含む最適化とアブレーションの研究を示します。この作業では、点群データからの3Dオブジェクト検出の問題に実際に対処します時間。 
[ABSTRACT]自律走行車が機能するためには、知覚コンポーネントが実世界のオブジェクトを検出することが非常に重要です。vgg、resnetなどの標準的なものを含むさまざまなバックボーンアーキテクチャと結果を比較し、バックボーンとのインセプション</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-09">
        <br><font color="black">2020-05-09</font>
      </time>
    </span>
</section>
<!-- paper0: Fairness Matters -- A Data-Driven Framework Towards Fair and High
  Performing Facial Recognition Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_26.html">
      <font color="black">Fairness Matters -- A Data-Driven Framework Towards Fair and High
  Performing Facial Recognition Systems</font>
    </a>
  </h2>
  <font color="black">したがって、この作業は、2つの部分（民族性と性別）に従います。不当な年齢予測は、犯罪防止だけでなく、マーケティング、ID取得、および認証においても、人間の不当な扱いにつながる可能性があります。 
[ABSTRACT]政府は年齢を使用して誰かが犯罪を犯す可能性を推定します。この場合、若い容疑者が関与する可能性が高くなります。advancedAdvanced Advanced Deep Learning（aw）およびAdvanced Advanced State-of-State Technologies（Advanced Advanced Technologyなど）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-11">
        <br><font color="black">2020-09-11</font>
      </time>
    </span>
</section>
<!-- paper0: PointIso: Point Cloud Based Deep Learning Model for Detecting
  Arbitrary-Precision Peptide Features in LC-MS Map through Attention Based
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_27.html">
      <font color="black">PointIso: Point Cloud Based Deep Learning Model for Detecting
  Arbitrary-Precision Peptide Features in LC-MS Map through Attention Based
  Segmentation</font>
    </a>
  </h2>
  <font color="black">これは、ペプチドフィーチャーのマルチアイソトピックパターンを電荷とともにセグメント化する注意ベースのスキャンステップと、それらの同位体を潜在的なペプチドフィーチャーにグループ化するシーケンス分類ステップで構成されます。プロテオミクス研究に貢献することに加えて、新しいセグメンテーションテクニックは同様に一般的な画像処理ドメインを提供します。病気のバイオマーカーを発見する有望な手法は、タンデム質量分析（LC-MS / MS）ベースの定量的プロテオミクスを用いた液体クロマトグラフィーにより、複数の生体液サンプル中の相対タンパク質存在量を測定することです。 
[ABSTRACT] pointtromは、問題に対処する最初のポイントクラウドベースのグループです。ベンチマークデータセットで高品質のms処理を98％検出しました。これは、広く使用されているいくつかのアルゴリズムよりも高い値です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: 3D_DEN: Open-ended 3D Object Recognition using Dynamically Expandable
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_28.html">
      <font color="black">3D_DEN: Open-ended 3D Object Recognition using Dynamically Expandable
  Networks</font>
    </a>
  </h2>
  <font color="black">この問題を緩和するために最近提案されたさまざまな解決策にもかかわらず、そのような解決策にはいくつかの副作用（時間/計算の複雑さなど）がまだ残っています。このモデルは、精度に関してだけでなく、計算の複雑さについてもです。動的に拡張可能なレイヤーと組み合わせたディープトランスファー学習ベースのアプローチを採用することで、3Dオブジェクトを自由に学習できるモデルを提案します。これにより、これらの副作用も確実になります。大幅に最小化されます。 
[ABSTRACT]新しい研究アプローチには、画像データセットに焦点を当てた深い畳み込みニューラルネットワーク（cnns）の使用が含まれます。モデルが新しいデータを学習しようとするときに壊滅的な忘却の問題がcnnsの使用における主な懸念です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: S2IGAN: Speech-to-Image Generation via Adversarial Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_29.html">
      <font color="black">S2IGAN: Speech-to-Image Generation via Adversarial Learning</font>
    </a>
  </h2>
  <font color="black">SENによって生成された音声埋め込みを条件として、提案されたRDGは、対応する音声記述と意味的に一致する画像を合成します。S2IGANという名前の提案されたS2IGフレームワークは、音声埋め込みネットワーク（SEN）と関係監視された高密度スタックで構成されます生成モデル（RDG）。2つの公開ベンチマークデータセットCUBおよびOxford-102での広範な実験により、音声信号から高品質で意味的に一貫性のある画像を合成する提案されたS2IGANの有効性が実証され、優れたパフォーマンスと強固なベースラインが得られます。 S2IGタスク。 
[要約]スピーチ-フォーム生成（s2ig）フレームワークが提案されています。テキストの情報を使用せずに、スピーチの説明を写真のリアルな画像に変換します。これにより、記述されていない言語がこのテクノロジーの恩恵を受ける可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-14">
        <br><font color="black">2020-05-14</font>
      </time>
    </span>
</section>
<!-- paper0: Investigating the impact of preprocessing and prediction aggregation on
  the DeepFake detection task -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_30.html">
      <font color="black">Investigating the impact of preprocessing and prediction aggregation on
  the DeepFake detection task</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案された前処理アプローチにより検出モデルのパフォーマンスが大幅に向上することを示しており、予測集約方式により、ビデオに複数の顔がある場合の検出効率がさらに向上します。このホワイトペーパーでは、前処理ステップを提案します。問題のトレーニングコーパスの品質を改善するために。コンテンツ生成テクノロジー（DeepFakesとして広く知られています）の最近の進歩と操作されたメディアのオンラインでの急増、および偽情報キャンペーンにより、そのような操作の検出はますます重要性が増しています。 
[要約]多くのディープフェイク検出方法がありますが、データセット前処理の影響に焦点を当てているものはごくわずかです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-12">
        <br><font color="black">2020-06-12</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Objective Evolutionary Design of Deep Convolutional Neural
  Networks for Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_31.html">
      <font color="black">Multi-Objective Evolutionary Design of Deep Convolutional Neural
  Networks for Image Classification</font>
    </a>
  </h2>
  <font color="black">提案された方法は、一連のアーキテクチャにデータを入力して、アーキテクチャコンポーネントを徐々に再結合および変更する遺伝的操作を通じてパレートフロンティア全体を近似することにより、最初の欠点に対処します。これら2つの主要な要素の統合により、競争力のあるアーキテクチャの効率的な設計が可能になります。ケースは、ベンチマーク画像分類データセット（CIFAR、ImageNet、および人間の胸部X線）で手動および自動の両方で設計されたアーキテクチャよりも優れています。異なるコンピューティング要件に対して複数のアーキテクチャの選択肢を同時に取得することにより提供される柔軟性は、文献の他の方法からのアプローチをさらに差別化します。 
[要約]分類性能や浮動小数点演算（フロップ）など、複数の目的の下でニューラルアーキテクチャを検索するためのアルゴリズム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-03">
        <br><font color="black">2019-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Short-term synaptic plasticity optimally models continuous environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_32.html">
      <font color="black">Short-term synaptic plasticity optimally models continuous environments</font>
    </a>
  </h2>
  <font color="black">SNNは、教師なしでシナプス的にローカルな学習、バイナリスパイク、および単一層のニューロンを使用して、少数の静止した未変換の画像でトレーニングされた場合でも、フレームをより正確に認識します-ディープラーニングでトレーニングされたANNとは対照的に。次に、シミュレーションを通じてこの理論的最適性を評価し、人工知能（AI）の改善も示します。これらの結果は、オンライン適応性とスパイクベースの計算が自然環境の自然知能を最適化できることを示しています。 
[ABSTRACT]生物学的にモデル化されたスパイキングニューラルネットワーク（snn）は、すべての関連する面で最先端の人工ニューラルネットワーク（anns）を超えています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Learning a Single Model with a Wide Range of Quality Factors for JPEG
  Image Artifacts Removal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_33.html">
      <font color="black">Learning a Single Model with a Wide Range of Quality Factors for JPEG
  Image Artifacts Removal</font>
    </a>
  </h2>
  <font color="black">さらに、2つのブランチが並列に存在します。つまり、復元ブランチとグローバルブランチです。明らかに、テストイメージの品質係数が想定値の範囲と一致しない場合、パフォーマンスが低下します。は、優れたまたは同等の画像アーチファクト除去パフォーマンスを一貫して提供しながら、幅広い品質要因を処理するようにトレーニングできる単一モデルのアプローチです。 
[要約]提案されたネットワークは、畳み込みニューラルネットワーク（cnn）に基づいています。幅広い品質係数を処理するようにトレーニングできますが、優れた、または同等の画像アーチファクト除去パフォーマンスを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Attention-SLAM: A Visual Monocular SLAM Learning from Human Gaze -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_34.html">
      <font color="black">Attention-SLAM: A Visual Monocular SLAM Learning from Human Gaze</font>
    </a>
  </h2>
  <font color="black">顕著な領域から抽出された特徴点は、最適化プロセスにおいてより重要です。包括的なテスト結果は、効率、精度、および面で、注目のSLAMが直接スパースオドメトリ（DSO）、ORB-SLAM、および顕著なDSOなどのベンチマークよりも優れていることを証明します。ほとんどのテストケースでの堅牢性。さらに、顕著性マップは、SLAM結果の改善のために人間の行動をシミュレートします。 
[要旨]意味的顕著性情報をeurocデータセットに追加します。ほとんどのSlamメソッドは、画像から抽出されたすべての特徴を同等の重要度として扱います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: AKHCRNet: Bengali Handwritten Character Recognition Using Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_35.html">
      <font color="black">AKHCRNet: Bengali Handwritten Character Recognition Using Deep Learning</font>
    </a>
  </h2>
  <font color="black">この提案されたモデルは、以前の作業と比較して、少数のエポックでより高い精度を実現します。ResNet50は、ImageNetデータセットでトレーニングされた優れたモデルですが、ベンガル語の文字なしでゼロからトレーニングされたHCRネットワークを提案しますEnsemble Learning」は、以前のアーキテクチャよりも優れています。ベンガル語のアルファベット、複合文字、および最新の精度96.8％を実現する数値の手書き文字認識のための最先端のニューラルアーキテクチャソリューションを提案します。 11エポック。 
[ABSTRACT] iより優れた「アンサンブル学習」なしでゼロからトレーニングされたhcrネットワークを提案します。似たような作業は以前、chatterjee、dutta、2019によって行われています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-29">
        <br><font color="black">2020-08-29</font>
      </time>
    </span>
</section>
<!-- paper0: 3DPVNet: Patch-level 3D Hough Voting Network for 6D Pose Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_36.html">
      <font color="black">3DPVNet: Patch-level 3D Hough Voting Network for 6D Pose Estimation</font>
    </a>
  </h2>
  <font color="black">3DPVNetは3つのモジュールで構成されています。特に、パッチ統合（\ textbf {PU}）モジュールが最初に導入され、入力パッチを正規化し、その上に標準ローカル座標フレームを作成して信頼できる投票を生成します。したがって、 3DPVNetは、ポイント/ピクセルレベルの投票方式よりも計算が少なく、部分的なデータに対する堅牢性があります。 
[要旨] 3dpvnetは、patch.patchベースの投票を含む3つのモジュールで構成され、ポーズ投票を生成できます。これは、点群のパッチレベルの投票に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring the ability of CNNs to generalise to previously unseen scales
  over wide scale ranges -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_37.html">
      <font color="black">Exploring the ability of CNNs to generalise to previously unseen scales
  over wide scale ranges</font>
    </a>
  </h2>
  <font color="black">スケールの不変性は、原則として、スケールチャネル間の重み共有と、スケールチャネルからの出力に対する最大または平均のプーリングを使用して実現できます。このようなスケールチャネルネットワークが、トレーニングセットに存在しないスケールに一般化する機能ただし、これまでに重要なスケール範囲を超えて検討されたことはありません。大規模な変動を処理する機能は、多くの現実世界の視覚タスクにとって重要です。 
[ABSTRACT]スケールチャネルネットワークは、一連のスケールチャネルで同時に複数のスケールで画像を処理できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-03">
        <br><font color="black">2020-04-03</font>
      </time>
    </span>
</section>
<!-- paper0: RaLL: End-to-end Radar Localization on Lidar Map Using Differentiable
  Measurement Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_38.html">
      <font color="black">RaLL: End-to-end Radar Localization on Lidar Map Using Differentiable
  Measurement Model</font>
    </a>
  </h2>
  <font color="black">実現可能性と有効性を検証するために、実際の世界から収集されたマルチセッションのマルチシーンデータセットを採用し、モデルトレーニングが英国にある一般化シナリオでも、提案されたシステムが90 km以上の運転で優れたパフォーマンスを実現することを結果が示しています。韓国でのテスト。最後に、この微分可能な測定モデルをカルマンフィルターに適用して、エンドツーエンドの方法でシーケンシャルローカリゼーションプロセス全体を学習します。この論文では、エンドツーエンドのディープニューラルネットワークを提案します。ギャップを埋めるためにLIDARマップでレーダー位置特定の学習を終了します。 
[ABSTRACT]現在最も人気のあるオンラインマップは現在LIDARによって構築されています。まず、両方のセンサーモーダルをニューラルネットワークによって共通の特徴空間に埋め込みます。最後に、この微分可能な測定モデルをカルマンフィルターに適用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: F3RNet: Full-Resolution Residual Registration Network for Multimodal
  Image Registration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_39.html">
      <font color="black">F3RNet: Full-Resolution Residual Registration Network for Multimodal
  Image Registration</font>
    </a>
  </h2>
  <font color="black">したがって、これらのアプローチは、変形した肝葉の患者内登録など、整列が難しい一部の領域に影響されません。他のストリームは、強力な認識を得るために深いマルチスケール残差表現を学習します。この論文では、重度に変形した臓器のマルチモーダル登録のために、新規の教師なし登録ネットワーク、つまり完全解像度残差登録ネットワーク（F3RNet）を提案します。 
[要約]この論文は、重度に変形した臓器のマルチモーダル登録のための新しい教師なし登録ネットワークを提案します。これらには、フル解像度の残余登録ネットワーク（f3rnet）が含まれます。1つのストリームは、正確な学習に役立つフル解像度情報を利用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-end Interpretable Learning of Non-blind Image Deblurring -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_40.html">
      <font color="black">End-to-end Interpretable Learning of Non-blind Image Deblurring</font>
    </a>
  </h2>
  <font color="black">これにより、完全に解釈可能で、エンドツーエンドで学習でき、非均一の場合にその精度が最新の技術と非常によく一致する、またはそれを超える、非ブラインド画像のブレ除去のシンプルで効率的なアルゴリズムが得られます。 （既知の）ブラーの近似逆フィルターと自然画像の前のカーネルを使用してリチャードソンソルバーを事前調整します。一般的な線形プリコンディショナーの代わりに畳み込みを使用すると、画像全体で非常に効率的なパラメーター共有が可能になり、精度や速度が大幅に向上します。従来のFFTおよび共役勾配法と比較して。 
[要約]提案されたアーキテクチャは、プレコンディショナーと近位の両方の学習に簡単に適応できます。また、プレコンディショナーまたは近位の学習にも簡単に適応できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-03">
        <br><font color="black">2020-07-03</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Random Subspace -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_41.html">
      <font color="black">Neural Random Subspace</font>
    </a>
  </h2>
  <font color="black">さらに、2D画像と3D点群認識タスクの両方で、NRSとCNNアーキテクチャの統合により、わずかな追加コストで一貫した改善が実現されます。さらに、畳み込みニューラルネットワーク（CNN）にエンコードされる非線形コンポーネントとして、NRSはCNNの線形特徴表現は、以前の高次のプーリング方法よりも効率的で、パラメーター、浮動小数点演算（FLOP）、および実際の実行時間の増加がほとんどない良好な結果を生成します。ランダムサブスペース、ランダムフォレスト、および勾配ブースティング決定ツリー（ GBDT）、NRSは35の機械学習データセットで優れたパフォーマンスを実現します。 
[ABSTRACT]方法はまだ不明ですが、簡単に組み合わせる方法があります。組み合わせる方法とディープラーニングを組み合わせる方法はまだ簡単ではありません。エンドツーエンドのデータ駆動型表現学習によって実現できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-18">
        <br><font color="black">2019-11-18</font>
      </time>
    </span>
</section>
<!-- paper0: FaceShifter: Towards High Fidelity And Occlusion Aware Face Swapping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_42.html">
      <font color="black">FaceShifter: Towards High Fidelity And Occlusion Aware Face Swapping</font>
    </a>
  </h2>
  <font color="black">困難な顔の咬合に対処するために、新しいヒューリスティックエラー承認精緻化ネットワーク（HEAR-Net）で構成される2番目のステージを追加します。これは、手動アノテーションなしで自己監視された方法で異常領域を回復するようにトレーニングされています。 、私たちは、FaceShifterと呼ばれる新しい2ステージフレームワークを提案します。 
[ABSTRACT]第1ステージでは、ターゲット属性を徹底的かつ適応的に活用して統合することにより、交換されたフェースを高忠実度で生成します。第2ステージでは、洗練ネットワークを認識する新規のヘリフトエラーが発生します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-31">
        <br><font color="black">2019-12-31</font>
      </time>
    </span>
</section>
<!-- paper0: Switching Gradient Directions for Query-Efficient Black-Box Adversarial
  Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_43.html">
      <font color="black">Switching Gradient Directions for Query-Efficient Black-Box Adversarial
  Attacks</font>
    </a>
  </h2>
  <font color="black">SWITCH $ _ \ text {neg} $とSWITCH $ _ \ text {rnd} $の2つのスイッチ操作が利用できます。SWITCHでは、勾配を推定するためのクエリは使用されません。すべてのクエリは、方向を切り替えて、前例のないクエリ効率を実現します。SWITCHは、将来のブラックボックス攻撃の強力なベースラインとして機能します。 
[ABSTRACT]ブラックボックス攻撃設定の単純なバージョンは未解決の問題です。これは、以前のサロゲートモデルに基づく新しいパターンに基づいています。これらの戦略は、転送転送プロセスを後押ししますが、元のサロゲートグラディエントは機能しません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: 4S-DT: Self Supervised Super Sample Decomposition for Transfer learning
  with application to COVID-19 detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_44.html">
      <font color="black">4S-DT: Self Supervised Super Sample Decomposition for Transfer learning
  with application to COVID-19 detection</font>
    </a>
  </h2>
  <font color="black">この論文では、トランスファーラーニング（4S-DT）モデルの自己教師付きスーパーサンプル分解と呼ばれる新しい深い畳み込みニューラルネットワークを提案します。大規模な注釈付き画像データセットの高可用性により、事前トレーニング済みモデルからの知識の伝達は、医療画像分類において卓越したパフォーマンスを示しました。 
[ABSTRACT] 4s-dtは、データの不規則性または不均衡なクラスを持つデータセット用の堅牢な画像分類モデルを開発しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-26">
        <br><font color="black">2020-06-26</font>
      </time>
    </span>
</section>
<!-- paper0: Group-Level Emotion Recognition Using a Unimodal Privacy-Safe
  Non-Individual Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_45.html">
      <font color="black">Group-Level Emotion Recognition Using a Unimodal Privacy-Safe
  Non-Individual Approach</font>
    </a>
  </h2>
  <font color="black">分析はグローバル機能のみに基づく単峰性であり、パフォーマンスは実際のデータセットで評価されるので、これらの結果は有望であり、このモデルを教室の雰囲気評価、つまり最終的なターゲットアプリケーションであるマルチモダリティに拡張することを想定します。方法論は、トレーニングソースとして最先端の専用コーパスと専用のコーパスを混合します。グループレベルの感情認識のためのニューラルネットワークアーキテクチャの詳細な調査により、VGAFテストで59.13％の精度を達成するVGGベースのモデルを構築しましたセット（チャレンジの11位）。 
[ABSTRACT]このサブチャレンジは、ワイルドビデオをポジティブ、ニュートラル、ネガティブの3つのカテゴリに分類することを目的としています。提案された方法は、最新の技術と専用のコーパスをトレーニングソースとして組み合わせたものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Microscope Based HER2 Scoring System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_46.html">
      <font color="black">Microscope Based HER2 Scoring System</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、診断を完了するためにHER2スコアリングガイドラインに従うリアルタイムHER2スコアリングシステムを提案します。したがって、各ステップは説明可能です。全スライドイメージングに基づく以前のスコアリングシステムとは異なり、当社のHER2スコアリングシステムはスライドを読みながらAIの結果を病理学者にフィードバックできる拡張現実（AR）顕微鏡に組み込まれています。病理学者は有益な視野（FOV）を選択し、DCISなどの交絡領域を回避できます。 
[要約]人工知能は、診断の精度と信頼性を向上させるためにさまざまな病気の診断に使用されています。しかし、診断結果の解釈は未解決の問題です。当社のシステムは、読み取り中にAIの結果を病理医にフィードバックできる拡張現実顕微鏡に統合されていますスライド</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Averaging Essential and Fundamental Matrices in Collinear Camera
  Settings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_47.html">
      <font color="black">Averaging Essential and Fundamental Matrices in Collinear Camera
  Settings</font>
    </a>
  </h2>
  <font color="black">最初のアルゴリズムは、ランク制約付き最小化を使用して、完全に同一線上にある設定でカメラマトリックスを復元します。同一線上シナリオで二焦点テンソルの完全なスペクトル特性を提供し、さらに2つの平均化アルゴリズムを提案します。モーションから構造化するグローバル手法は、近年人気を博しています。 
[要旨]共線性カメラと非共線性カメラが混在する可能性のあるセットを強化するには、グローバルな方法が必要です。一般的な位置に配置される「仮想カメラ」が含まれ、強化された画像に分析を適用できるようにします。 collinib設定に対する感度</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-30">
        <br><font color="black">2019-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding Deformable Alignment in Video Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_48.html">
      <font color="black">Understanding Deformable Alignment in Video Super-Resolution</font>
    </a>
  </h2>
  <font color="black">変形可能な線形への貢献とは別に、私たちの定式化は、フローベースの線形にオフセットの多様性を導入し、そのパフォーマンスを向上させる、より柔軟なアプローチを刺激します。この分解は、公式における変形可能なアライメントとフローベースのアライメントの共通性を明らかにしますが、それらのオフセットの多様性には重要な違いがあります。 
[要約]変形可能な畳み込みは、空間ワーピングと畳み込みの組み合わせに分解できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: CSI2Image: Image Reconstruction from Channel State Information Using
  Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_49.html">
      <font color="black">CSI2Image: Image Reconstruction from Channel State Information Using
  Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">CSI2ImageはIEEE 802.11ac圧縮CSIを使用して実装され、評価結果は画像が正常に再構築されたことを示しています。したがって、完全な答えはまだ得られていませんが、ここに向けてステップが実行されます。これを達成するために、CSI2Image、a生成的敵対的ネットワーク（GAN）に基づく新しいチャネル状態情報（CSI）から画像への変換方法が提案されています。 
[ABSTRACT] csi2image、推定ガンに基づく新しいチャネル状態情報（csi）から画像への変換方法が提案されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: ConsNet: Learning Consistency Graph for Zero-Shot Human-Object
  Interaction Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_50.html">
      <font color="black">ConsNet: Learning Consistency Graph for Zero-Shot Human-Object
  Interaction Detection</font>
    </a>
  </h2>
  <font color="black">オブジェクト、アクション、インタラクション間のマルチレベルの一貫性は、稀な、または以前には見られなかったHOIのセマンティック表現を生成するための強力な手がかりであると主張します。視覚的意味の共同埋め込み空間に挿入し、それらの類似性を測定することで検出結果を取得します。私たちは、HOIインスタンスを次の形式で見つけて認識することを目的としたヒューマンオブジェクトインタラクション（HOI）検出の問題を検討します。 <human, action, object>画像で。 
[要約]オブジェクト、アクション、相互作用の関係を無向グラフに明示的にエンコードする知識認識フレームワークであるconsnetを提案します。このモデルでは、ヒューマンアテンションネットワーク（gats）を使用して、ホイのカテゴリとその構成要素の間で知識を伝播します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-14">
        <br><font color="black">2020-08-14</font>
      </time>
    </span>
</section>
<!-- paper0: Image Based Artificial Intelligence in Wound Assessment: A Systematic
  Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_51.html">
      <font color="black">Image Based Artificial Intelligence in Wound Assessment: A Systematic
  Review</font>
    </a>
  </h2>
  <font color="black">また、創傷評価システム（ハードウェア、ソフトウェア、モバイルアプリを含む）に関する最近の研究をレビューしました。急性および慢性創傷の効率的かつ効果的な評価は、臨床現場の創傷ケアチームが創傷診断を大幅に改善し、治療計画を最適化し、人工知能（AI）は健康関連の科学と技術で幅広いアプリケーションを発見していますが、AIベースのシステムは、高品質の創傷治療のために臨床的および計算的に開発されたままです。 
[ABSTRACT] aiは、健康関連の科学と技術で幅広いアプリケーションを発見しましたが、aiベースのシステムは、高品質の創傷治療のために臨床的および計算的に開発されたままです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Context Model for Pedestrian Intention Prediction using Factored
  Latent-Dynamic Conditional Random Fields -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_52.html">
      <font color="black">Context Model for Pedestrian Intention Prediction using Factored
  Latent-Dynamic Conditional Random Fields</font>
    </a>
  </h2>
  <font color="black">2つの異なるデータセットにメソッドを適用します。1つは社内で収集されたもの-NTUデータセットともう1つの公共の実際のベンチマーク-JAADデータセットです。この目的のために、歩行者の意図に対する車両の相互作用の影響を紹介します。FLDCRFは長期的に優れています同一の時系列フィーチャ上のデータセット全体（データセットあたり$ \ sim $ 100シーケンス）のメモリ（LSTM）ネットワーク。 
[ABSTRACT]既存のシステムは、歩行者の横断または非横断の予測を車両の前で支援します。これらのシステムは、歩行者の早期かつ正確な予測を必要とします。これらのシステムは、そのようなシステムの円滑な運用のための早期予測の必要性を述べています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-27">
        <br><font color="black">2019-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: A Self Contour-based Rotation and Translation-Invariant Transformation
  for Point Clouds Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_53.html">
      <font color="black">A Self Contour-based Rotation and Translation-Invariant Transformation
  for Point Clouds Recognition</font>
    </a>
  </h2>
  <font color="black">最近、いくつかの直接処理点群モデルが、分類およびセグメンテーションタスクの最先端のパフォーマンスを達成しました。広範な実験結果と数学的分析は、提案された方法が、任意の回転の下で最先端のアプローチよりも優れていることを示しています。 ModelNet40、ScanObjectNN、ShapeNetなどの標準ベンチマークでの回転の増加。この問題に対処するために、Self Contour-based Transformation（SCT）という名前のメソッドを提案します。これは、任意の既存の点群認識モデルに柔軟に統合できます。追加の変更なしの回転。 
[ABSTRACT] sctは、回転に基づいて効率的で数学的に証明されたものを提供します。これらの方法は回転の堅牢性に欠け、ランダムな回転ではパフォーマンスが大幅に低下します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: UniVL: A Unified Video and Language Pre-Training Model for Multimodal
  Understanding and Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_54.html">
      <font color="black">UniVL: A Unified Video and Language Pre-Training Model for Multimodal
  Understanding and Generation</font>
    </a>
  </h2>
  <font color="black">ビデオテキストジョイント、条件付きマスク言語モデル（CMLM）、条件付きマスクフレームモデル（CMFM）、ビデオテキストの配置、および言語再構成を含む5つの目的は、各コンポーネントをトレーニングするように設計されています。実験結果は、UniVL強力なビデオテキスト表現を学習し、5つのダウンストリームタスクで最先端の結果を達成できます。さらに、2つの事前トレーニング戦略を段階的に事前トレーニング（StagedP）と強化されたビデオ表現（EnhancedV）で開発し、 UniVLのトレーニングプロセスをより効果的にします。 
[ABSTRACT]これらには、2つのシングルモーダルエンコーダー、クロスエンコーダー、およびトランスフォーマーバックボーンを備えたデコーダーが含まれます。univlは、強力なビデオ-テキスト表現を学習し、5つのダウンストリームタスクで最先端の結果を達成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-15">
        <br><font color="black">2020-02-15</font>
      </time>
    </span>
</section>
<!-- paper0: AIM 2020 Challenge on Efficient Super-Resolution: Methods and Results -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_55.html">
      <font color="black">AIM 2020 Challenge on Efficient Super-Resolution: Methods and Results</font>
    </a>
  </h2>
  <font color="black">彼らは、最先端の効率的な単一画像超解像を測定します。このペーパーは、提案されたソリューションと結果に焦点を当てて、効率的な単一画像超解像に関するAIM 2020の課題をレビューします。課題は、低解像度および対応する高解像度画像の前例のセットに基づいて、倍率x4で入力画像を解決します。 
[要旨]課題は、画像を拡大係数x4で超解像することでした。トラックには150人の参加者が登録されており、25チームが最終結果を提出しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Attention Cube Network for Image Restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_56.html">
      <font color="black">Attention Cube Network for Image Restoration</font>
    </a>
  </h2>
  <font color="black">具体的には、3つの次元、つまり空間次元、チャネルごとの次元、および階層次元から新しい注意メカニズムを設計します。適応空間注意ブランチ（ASAB）と適応チャネル注意ブランチ（ACAB）は、適応デュアル注意モジュール（ADAM）を構成します。 ）、長距離空間情報およびチャネルごとのコンテキスト情報をキャプチャして受容野を拡張し、さまざまなタイプの情報を区別してより効果的な機能表現を実現できます。ただし、既存の方法のほとんどは、局所受容野と同等の扱いに限定されています。さまざまな種類の情報。 
[ABSTRACT]これは、多くの方法が局所受容野に限定された最初の例です。代わりに、より強力な特徴表現と特徴相関学習のために、画像復元用のアテンションキューブネットワーク（-cubenet）を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-13">
        <br><font color="black">2020-09-13</font>
      </time>
    </span>
</section>
<!-- paper0: P-DIFF: Learning Classifier with Noisy Labels based on Probability
  Difference Distributions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_57.html">
      <font color="black">P-DIFF: Learning Classifier with Noisy Labels based on Probability
  Difference Distributions</font>
    </a>
  </h2>
  <font color="black">ベンチマークデータセットの実験では、P-DIFFが最先端のサンプル選択方法よりも優れていることも実証されています。P-DIFFは、トレーニングサンプルのノイズレートに関する事前の知識がなくても、優れたパフォーマンスを達成できます。差分分布は、トレーニングサンプルがクリーンになる確率を暗黙的に反映します。この確率は、トレーニングプロセス中に対応するサンプルを再重み付けするために使用されます。 
[ABSTRACT] p-diffはdnn分類子をトレーニングできますが、ノイズの多いラベルの悪影響を軽減できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Your Classifier is Secretly an Energy Based Model and You Should Treat
  it Like One -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_58.html">
      <font color="black">Your Classifier is Secretly an Energy Based Model and You Should Treat
  it Like One</font>
    </a>
  </h2>
  <font color="black">エネルギーベースのモデルのトレーニングをスケールアップするために最近提案された手法を改善し、標準の分類トレーニングと比較してオーバーヘッドがほとんどないアプローチを提示します。この設定では、標準クラスの確率とp（xの非正規化値を簡単に計算できます。 ）とp（x | y）..私たちのアプローチは、1つのハイブリッドモデル内で最新の生成学習と識別学習の両方に匹敵するパフォーマンスを達成する最初の方法です。 
[要約]共同分布のトレーニングにより、キャリブレーション、ロバスト性、および分布外検出が改善されることを示しました。これにより、最近のガンアプローチの品質に匹敵するサンプルを生成するモデルも使用可能に</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-06">
        <br><font color="black">2019-12-06</font>
      </time>
    </span>
</section>
<!-- paper0: LAMP: Large Deep Nets with Automated Model Parallelism for Image
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_59.html">
      <font color="black">LAMP: Large Deep Nets with Automated Model Parallelism for Image
  Segmentation</font>
    </a>
  </h2>
  <font color="black">コードは利用可能です\ footnote {https://monai.io/research/lamp-automated-model-parallelism} ..大規模な実験は、自動化されたモデルの並列処理によって促進され、セグメンテーションの精度がモデルサイズと入力の増加を通じて改善できることを示していますコンテキストサイズ、および大きな入力は、推論における小さなパッチのスライディングウィンドウと比較して、推論の大幅なスピードアップをもたらします。自動化されたモデルの並列処理により、画像全体でさえ、大きな入力パッチで大きな深い3D ConvNetをトレーニングすることが可能です。 
[ABSTRACT]データの並列処理とモデルの並列処理は、並列トレーニングの2つのよく知られたルートです。これらには、データの並列処理、モデルの並列処理、モデルのモデルの並列処理が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-22">
        <br><font color="black">2020-06-22</font>
      </time>
    </span>
</section>
<!-- paper0: Gravitational Models Explain Shifts on Human Visual Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_60.html">
      <font color="black">Gravitational Models Explain Shifts on Human Visual Attention</font>
    </a>
  </h2>
  <font color="black">この論文では、注意シフトを記述する重力モデル（GRAV）を提案します。これらは、ピクセルレベルで顕著性を推定する際にほぼ完璧なパフォーマンスを実現しますが、視覚的注意のシフトを生成する方法は、勝者総取り（WTA）に完全に依存します。 ）回路.. WTAは、最大の顕著性を持つ場所を選択するために生物学的ハードウェアによって実装され、そこに明白な注意を向けます。 
[要約]視覚プロセスは、アトラクタとして機能するパターンに基づいています。シフトは、アトラクタの共同効果の結果です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: HGCN-GJS: Hierarchical Graph Convolutional Network with Groupwise Joint
  Sampling for Trajectory Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CV/paper_61.html">
      <font color="black">HGCN-GJS: Hierarchical Graph Convolutional Network with Groupwise Joint
  Sampling for Trajectory Prediction</font>
    </a>
  </h2>
  <font color="black">さらに、将来の軌道における複数の歩行者の共同分布をモデル化するための新しい共同サンプリングスキームを紹介します。しかし、ほとんどの既存の方法は、ペア単位の相互作用のみに焦点を当て、グループ単位の相互作用を無視して、グループレベルの相互作用をうまくキャプチャできません。いくつかの軌道予測データセットでネットワークのパフォーマンスを実証し、検討したすべてのデータセットで最先端の結果を達成します。 
[ABSTRACT] hgcnによって開発されたシステム-gjsはグループ情報に基づいています。システムは、ある人の軌跡を他の人の軌跡に関連付けます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Functorial Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_0.html">
      <font color="black">Functorial Question Answering</font>
    </a>
  </h2>
  <font color="black">集合と関係のカテゴリのDisCoモデルがリレーショナルデータベースに正確に対応していることを示します。その結果、意味論と自然言語のフラグメントの含意から、結合クエリの評価と包含への複雑さの理論的な削減がそれぞれ得られます。分布合成（DisCo）モデルは、単語の意味から文の意味を計算する関数です。 
[要約]セットとリレーションのカテゴリのディスコモデルはデータベースに正確に対応しています。最後に、質問の回答をnp-完全な問題として定義します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-17">
        <br><font color="black">2019-05-17</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Abstractive Dialogue Summarization for Tete-a-Tetes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_1.html">
      <font color="black">Unsupervised Abstractive Dialogue Summarization for Tete-a-Tetes</font>
    </a>
  </h2>
  <font color="black">SuTaTは、条件付き生成モジュールと2つの教師なし要約モジュールで構成されます。実験結果は、SuTaTが自動評価と人間評価の両方で教師なし対話の要約よりも優れており、対話の分類と単一ターンの会話生成が可能であることを示しています。高品質の対話-概要のペアになっているデータは、生成に費用がかかり、ドメインに依存するため、抽象ダイアログの要約を困難な作業にします。 
[ABSTRACT] tete-a-tetes.sutatの最初の教師なし抽象対話要約モデルは、顧客とエージェントの会話など、teteの各話者について要約することを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Event Presence Prediction Helps Trigger Detection Across Languages -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_2.html">
      <font color="black">Event Presence Prediction Helps Trigger Detection Across Languages</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、英語と中国語のACE 2005データで新しい最先端のパフォーマンスを達成します。また、EREスペイン語でモデルをテストし、以前の最高パフォーマンスモデルよりも平均2絶対F1ポイントのゲインを達成しました。 BERTベースのイベント抽出モデルのパフォーマンスを大幅に向上させるセンテンスレベルとトークンレベルのトレーニング目標の組み合わせ。 
[ABSTRACT]トランスフォーマーベースのアーキテクチャが、イベント抽出をシーケンスラベリングタスクとして効果的にモデル化できることを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Noisy Self-Knowledge Distillation for Text Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_3.html">
      <font color="black">Noisy Self-Knowledge Distillation for Text Summarization</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、テキストの要約に自己知識蒸留を適用します。これにより、単一参照とノイズの多いデータセットでの最尤トレーニングの問題を軽減できると主張します。3つのベンチマークで、私たちのフレームワークが事前トレーニングと非事前トレーニングの両方のパフォーマンスを向上させることを実験的に示します。最先端の結果を達成するサマライザ..さらに、トレーニング中のモデルの不確実性を改善するために、教師モデルと生徒モデルの両方に複数のノイズ信号を導入します。 
[ABSTRACT]私たちの生徒の要約モデルは、教師からのガイダンスでトレーニングされています。3つのベンチマークで実験を行いました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: The Devil is the Classifier: Investigating Long Tail Relation
  Classification with Decoupling Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_4.html">
      <font color="black">The Devil is the Classifier: Investigating Long Tail Relation
  Classification with Decoupling Analysis</font>
    </a>
  </h2>
  <font color="black">この研究では、ロングテール問題の詳細な実証的調査を実施し、インスタンスバランスサンプリングを使用した事前トレーニング済みモデルが、すべてのクラスの十分に学習された表現をすでにキャプチャしていることを発見しました。さらに、分類子を調整するだけで、低コストでより優れたロングテール分類能力を実現できます。この観察から発想を得て、関係を自動的に集約することによりソフトな重みを割り当てる、注意深い関係ルーティングを備えたロバストな分類子を提案します。テールクラスはトレーニングフェーズを支配し、テールパフォーマンスの低下を招く可能性があるため、テール関係の分類は困難な問題です。 
[ABSTRACT]私たちは、関係を自動的に集約することによってソフトな重みを割り当てる、注意深い関係ルーティングを備えたロバストな分類子を提案します。研究は観察から着想を得ており、注意深い段階を備えたロバストなタイプ指定子を提案しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Achieving Real-Time Execution of Transformer-based Large-scale Models on
  Mobile with Compiler-aware Neural Architecture Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_5.html">
      <font color="black">Achieving Real-Time Execution of Transformer-based Large-scale Models on
  Mobile with Compiler-aware Neural Architecture Optimization</font>
    </a>
  </h2>
  <font color="black">具体的には、私たちのモデルは、BERTベースと比較して、CPUで5.2倍、GPUで4.1倍速く、0.5〜2％の精度の損失があります。このホワイトペーパーでは、特定の計算サイズで、特定のデバイスと一致します。CANAOは、識別されたモデルがモバイルデバイスのリソース仕様とリアルタイム仕様の両方を満たすことを保証できるため、BERTバリアントのような大規模な変圧器ベースのモデルをリアルタイムで実行できます。 
[ABSTRACT]最初のドキュメント-アウェアなニューラルアーキテクチャ拡張フレームワーク（canao）。canaoモデルcanaoは4,000カロリーと2,000カロリーに基づいています。これらのモデルが過去にトレーニングされたのはこれが初めてです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Cascaded Semantic and Positional Self-Attention Network for Document
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_6.html">
      <font color="black">Cascaded Semantic and Positional Self-Attention Network for Document
  Classification</font>
    </a>
  </h2>
  <font color="black">一般的に使用される位置エンコーディングスキームと比較して、CSPANはセマンティクスと単語位置の間の相互作用をより解釈可能で適応的な方法で活用でき、コンパクトなモデルサイズと高い収束率を同時に維持しながら分類パフォーマンスを著しく改善できます。慎重なアブレーション研究を伴う文書分類のためのいくつかのベンチマークデータセットのCSPANモデル。最新の技術と比較して有望な結果を示します。CSPANは、Bi-LSTMとカスケード接続されたセマンティック自己注意層を使用して、セマンティックおよび位置情報を処理します。シーケンシャル方式で、残差接続を介してそれらを適応的に組み合わせます。 
[ABSTRACT] cspanは、bi-lstm.itとカスケード接続されたセマンティックセルフアテンションレイヤーを使用して、視覚的な方法でセマンティック情報を処理し、残差接続を通じてそれらを適応的に結合します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: DUMA: Reading Comprehension with Transposition Thinking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_7.html">
      <font color="black">DUMA: Reading Comprehension with Transposition Thinking</font>
    </a>
  </h2>
  <font color="black">新しい、より強力なPrLMは、マッチングネットワークからのサポートがなくても、その力強さを示していますが、マルチ選択MRCを解く人間の転置思考プロセスに触発された新しいDUalマルチヘッド共同注意（DUMA）モデルを提案します。問題：パッセージと質問の観点からお互いの焦点をそれぞれ考慮します。私たちの提案された方法は、2つのベンチマークマルチチョイスMRCタスク、DREAMとRACEで評価され、強力なPrLMの観点から、DUMAはモデルを到達範囲までブーストできることを示しています新しい最先端のパフォーマンス。提案されたDUMAは効果的であることが示され、一般的にPrLMを促進することができます。 
[ABSTRACT]複数選択のmrcを使用して新しいモデルを作成できます。mrcにはエンコーダとして事前トレーニング済みの言語モデル（prlm）が必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-26">
        <br><font color="black">2020-01-26</font>
      </time>
    </span>
</section>
<!-- paper0: Iterative Refinement in the Continuous Space for Non-Autoregressive
  Neural Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_8.html">
      <font color="black">Iterative Refinement in the Continuous Space for Non-Autoregressive
  Neural Machine Translation</font>
    </a>
  </h2>
  <font color="black">このアプローチを、離散変数と連続変数の両方で構成されるハイブリッド空間で最適化する最近提案されたEMのような推論手順（Shu et al。、2020）と比較します。たとえば、WMT&#39;14 En-Deについては、は、翻訳品質の低下が最小限の自己回帰モデル（0.9 BLEU）の6.2倍の速度でデコードできます。機械翻訳の連続潜在変数モデル（Shu et al。、2020）を前提として、勾配を近似するように推論ネットワークをトレーニングします潜在変数のみを入力として使用して、ターゲット文の限界対数確率の
[ABSTRACT]これは、機械翻訳の連続潜在変数モデルに基づいています。潜在的な要因asbaのみを使用して、ターゲットネットワークの限界対数確率の勾配をシミュレートする結論ネットワークをトレーニングします。これにより、トークンスペースを調整することが多い既存の非自己回帰手順</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Current Limitations of Language Models: What You Need is Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_9.html">
      <font color="black">Current Limitations of Language Models: What You Need is Retrieval</font>
    </a>
  </h2>
  <font color="black">たとえば、（1）は現在、特定の微調整データセットが必要なため、出力が入力によって緩やかに制約され、GPT-2 / 3などの一般的なテキストタスクを実行する、オープンエンドのテキスト生成に苦労しています。 （5）これらの制限の多くを解決し、（a）監視の量を減らし、（b）コンテキストをトレーニングデータセット全体と現在のサンプルの過去全体に効率的に拡張できます。（2）および（3 ）最初の$ \ sim 10 ^ 3 $トークンの予測を改善しません。 
[ABSTRACT]これらの制限を緩めることでいくつかの制限を大まかに特定しますが、最初の$ / 3 $トークンの予測は改善されませんでした</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal Joint Attribute Prediction and Value Extraction for
  E-commerce Product -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_10.html">
      <font color="black">Multimodal Joint Attribute Prediction and Value Extraction for
  E-commerce Product</font>
    </a>
  </h2>
  <font color="black">本稿では、マルチモーダル手法を提案し、製品の画像を利用して、製品の属性を共同で予測し、テキストによる製品の説明から値を抽出します。コードとデータセットは公開されます。さらに、製品の画像は、さまざまな製品の属性と値に対するタスク。 
[ABSTRACT]製品の属性と値には高い相関関係があると主張しています。製品の値が指定されているという条件で値を抽出する方が簡単です。製品の画像は、タスクに明確な影響を与えます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Critical Thinking for Language Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_11.html">
      <font color="black">Critical Thinking for Language Models</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーは、神経自己回帰言語モデルのクリティカルシンキングカリキュラムに向けた最初のステップを踏みます。調査結果は、一般的な推論スキルを習得するのに十分であり、コアを形成する可能性のある適切な推論のパラダイムインスタンスの代表的なサンプルが存在することを示唆しています言語モデルの批判的思考のカリキュラムの例です。言語モデルは、コアな引数スキームを正しい方法で結び付けて一般化するようです。 
[ABSTRACT]演繹的に有効な引数の合成テキストコーパスを導入します。これは、gptのトレーニングと評価に使用できます。2。調査結果は、適切な推論の代表的なサンプルが存在する可能性があることを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Referenced Training for Dialogue Response Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_12.html">
      <font color="black">Multi-Referenced Training for Dialogue Response Generation</font>
    </a>
  </h2>
  <font color="black">自動評価と人間の評価の実験結果は、メソッドがベースラインを大幅に改善することを示しています。コードとデータはhttps://github.com/ZHAOTING/dialog-processing ..でリリースします。次に、複数参照のアプローチを検討します2つの側面でのトレーニング。 
[要約]現実世界の確率分布と単一の参照データの確率分布の間のギャップにより、モデルは1対多の関係を効率的に学習できません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Autonomization of Monoidal Categories -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_13.html">
      <font color="black">Autonomization of Monoidal Categories</font>
    </a>
  </h2>
  <font color="black">分布セマンティクスの場合、これにより、使用可能なモデルの範囲が広がり、非線形マップやデカルト積などが含まれるようになります。これは、モノイドカテゴリに随伴を自由に追加する構造に依存しています。この原理のアプリケーションについて説明します。意味のさまざまな分布モデルに。 
[ABSTRACT]これは、すべての随伴要素をモノイドカテゴリに自由に追加する構造に依存しています。これは、この原理の意味のさまざまな範囲モデルへの適用を説明しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2014-11-14">
        <br><font color="black">2014-11-14</font>
      </time>
    </span>
</section>
<!-- paper0: RECOApy: Data recording, pre-processing and phonetic transcription for
  end-to-end speech-based applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_14.html">
      <font color="black">RECOApy: Data recording, pre-processing and phonetic transcription for
  end-to-end speech-based applications</font>
    </a>
  </h2>
  <font color="black">ディープラーニングは、専門的な言語および信号処理機能の必要性を回避しながら、効率的なエンドツーエンドの音声処理アプリケーションの開発を可能にします。RECOApyは、エンドツーエンドの音声ベースのアプリケーションで必要なデータ記録および前処理のステップを合理化します。 ..このペーパーでは、RECOApyツールを紹介します。 
[要約] recoapyは、end-to-of-waveテクノロジーで必要なデータの記録と前処理のステップを合理化します。書記素-から-音素（g2p）-コンバーターは、ウィクショナリーオンラインリソースから抽出された辞書でトレーニングされます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-11">
        <br><font color="black">2020-09-11</font>
      </time>
    </span>
</section>
<!-- paper0: Autoregressive Knowledge Distillation through Imitation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_15.html">
      <font color="black">Autoregressive Knowledge Distillation through Imitation Learning</font>
    </a>
  </h2>
  <font color="black">翻訳や要約などの典型的な言語生成タスクでは、このメソッドはシーケンスレベルの知識蒸留などの他の蒸留アルゴリズムよりも常に優れています。このメソッドでトレーニングされた学生モデルは、ゼロからトレーニングされたものよりも1.4〜4.8 BLEU / ROUGEポイント高くなります。教師モデルと比較して推論速度が最大14倍増加します。知識の蒸留に関する模倣学習の視点によって駆動される自己回帰モデルの圧縮手法を開発します。 
[ABSTRACT] state-thegreveモデルは実際の時間に敏感な設定で展開できます。この方法は露出バイアスの問題に対処するように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: FGN: Fusion Glyph Network for Chinese Named Entity Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_16.html">
      <font color="black">FGN: Fusion Glyph Network for Chinese Named Entity Recognition</font>
    </a>
  </h2>
  <font color="black">（2）スライディングウィンドウとスライスアテンションを使用して、BERT表現と文字のグリフ表現を融合する方法を提供します。これにより、コンテキストとグリフ間の潜在的なインタラクティブな知識を獲得できます。FGNの主な革新には、次のものが含まれます。 CGS-CNNと呼ばれるCNN構造は、隣接する文字からのグリフ間のグリフ情報とインタラクティブ情報の両方を取得するために提案されています。 
[ABSTRACT]漢字には潜在的なグリフ情報が含まれているため、見過ごされがちです。この方法では、フュージョンメカニズムにインタラクティブな情報を追加することもできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-15">
        <br><font color="black">2020-01-15</font>
      </time>
    </span>
</section>
<!-- paper0: MatScIE: An automated tool for the generation of databases of methods
  and parameters used in the computational materials science literature -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_17.html">
      <font color="black">MatScIE: An automated tool for the generation of databases of methods
  and parameters used in the computational materials science literature</font>
    </a>
  </h2>
  <font color="black">具体的には、さまざまな研究記事から材料の詳細、メソッド、コード、パラメーター、および構造を抽出します。このコンテキストを優先事項として保持し、関連する情報を抽出できる自動ツールMatScIE（Material Scince Information Extractor）を開発しました材料科学の文献を作成し、材料シミュレーションではるかに使いやすい構造化データベースを作成します。最後に、ユーザーが公開記事をアップロードし、このツールから取得した情報を表示/ダウンロードして、独自のデータベースを作成できるWebアプリケーションを作成しました。個人的な使用。 
[ABSTRACT] matscie（材料科学情報抽出）は、材料科学文献から関連情報を抽出し、より使いやすい構造化データベースを作成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Elsevier OA CC-By Corpus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_18.html">
      <font color="black">Elsevier OA CC-By Corpus</font>
    </a>
  </h2>
  <font color="black">このコーパスには、記事の全文だけでなく、各参照の書誌情報とともにドキュメントのメタデータも含まれています。これは、科学分野全体からの代表的なサンプルを含む科学研究論文の最初のオープンコーパスです。 。Elsevier OA CC-BYコーパスを紹介します。 
[ABSTRACT]これは科学研究論文の最初のオープンコーパスです。科学分野全体からの代表的なサンプルがあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-03">
        <br><font color="black">2020-08-03</font>
      </time>
    </span>
</section>
<!-- paper0: High-order Refining for End-to-end Chinese Semantic Role Labeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_19.html">
      <font color="black">High-order Refining for End-to-end Chinese Semantic Role Labeling</font>
    </a>
  </h2>
  <font color="black">ベースライングラフモデルに基づいて、高次リファインモジュールは、注意計算を介してすべての候補ペア間の高次特徴を学習します。これらは後で元のトークン表現を更新するために使用されます。リファインを数回繰り返すと、基になるトークン表現をグローバルに相互作用する機能で強化されています。私たちの高次モデルは、CoNLL09やUniversal Proposition Bankを含む中国のSRLデータで最先端の結果を達成する一方で、長期的な依存関係の問題を緩和します。 
[ABSTRACT]高次モデルは、述語と引数のペア間のより多くの次数の特徴を学習します。これらは、注意計算を使用して反論できるベースライングラフモデルに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: MLMLM: Link Prediction with Mean Likelihood Masked Language Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_20.html">
      <font color="black">MLMLM: Link Prediction with Mean Likelihood Masked Language Model</font>
    </a>
  </h2>
  <font color="black">WN18RRデータセットで最先端の（SotA）結果を取得し、FB15k-237データセットでエンティティ非埋め込みベースの最良の結果を取得します。ただし、工数と高品質データでスケーリングされます。マスクされた言語モデル（ BERTなどのMLM）は、計算能力や非構造化生テキストデータに応じて拡張されます。 
[要約]ただし、これらのモデルに含まれる知識は直接解釈できません。mlmlm、平均尤度マスク言語モデル、さまざまなエンティティを生成する平均尤度を比較して扱いやすい方法でリンク予測を実行するアプローチを導入するには</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Lessons Learned from Applying off-the-shelf BERT: There is no
  SilverBullet -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_21.html">
      <font color="black">Lessons Learned from Applying off-the-shelf BERT: There is no
  SilverBullet</font>
    </a>
  </h2>
  <font color="black">BERTの複雑さと計算コストは、手元にある分類タスクの予測パフォーマンスの向上を保証するものではないことを示しています。事前学習済みの既製の単語埋め込み、モデル、およびモジュールの可用性の向上により、大きなモデルをトレーニングし、競争力のあるパフォーマンスを達成するプロセス。GPUハードウェアが利用できない場合はさらに困難になります。 
[ABSTRACT]最も優れた証言は、オフ-シェルフバートモデルの使用に基づいています。テスト結果は、lstmネットワークのテストおよびより単純なベースラインと比較されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: S2IGAN: Speech-to-Image Generation via Adversarial Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_22.html">
      <font color="black">S2IGAN: Speech-to-Image Generation via Adversarial Learning</font>
    </a>
  </h2>
  <font color="black">2つの公開ベンチマークデータセットCUBとOxford-102での広範な実験により、音声信号から高品質で意味的に一貫性のある画像を合成し、S2IGタスクの優れたパフォーマンスと強固なベースラインをもたらす提案されたS2IGANの有効性が実証されています。 SENによって生成された音声埋め込み、提案されたRDGは、対応する音声記述と意味的に一致する画像を合成します。SENは、対応する視覚情報の監視により音声埋め込みを学習します。 
[要約]スピーチ-フォーム生成（s2ig）フレームワークが提案されています。テキストの情報を使用せずに、スピーチの説明を写真のリアルな画像に変換します。これにより、記述されていない言語がこのテクノロジーの恩恵を受ける可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-14">
        <br><font color="black">2020-05-14</font>
      </time>
    </span>
</section>
<!-- paper0: It's Not Just Size That Matters: Small Language Models Are Also Few-Shot
  Learners -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_23.html">
      <font color="black">It's Not Just Size That Matters: Small Language Models Are Also Few-Shot
  Learners</font>
    </a>
  </h2>
  <font color="black">数千億のパラメータにスケーリングすると、GPT-3（Brown et al。、2020）などの事前トレーニング済みの言語モデルは、挑戦的な自然言語理解ベンチマークで驚くべき数ショットのパフォーマンスを実現します。勾配ベースの最適化と組み合わせた、何らかの形式のタスクの説明が含まれます。ラベルのないデータをさらに活用すると、さらに改善されます。調査結果に基づいて、小さな言語モデルで自然言語を正しく理解するために必要ないくつかの重要な要素を特定します。 
[ABSTRACT]新しい研究では、gpt-3と同様のパフォーマンスが言語モデルで得られることを示しています。これらの要因は、自然言語の理解を成功させるために必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Dialogue Response Ranking Training with Large-Scale Human Feedback Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_24.html">
      <font color="black">Dialogue Response Ranking Training with Large-Scale Human Feedback Data</font>
    </a>
  </h2>
  <font color="black">クラウドソーシングによる人間の評価は、私たちのランク付け方法がベースラインモデルよりも実際の人間の好みと相関していることを示しています。フィードバックとエンゲージメントの間で起こり得る歪みを軽減するために、ランク付けの問題を、交絡因子がほとんどない応答ペアの比較に変換します。 、私たちのランク付けツールは、Redditフィードバックの予測に大きなマージンを置いて、従来のダイアログの複雑さベースラインを上回っています。 
[ABSTRACT]既存の人間の返信は他の返信よりも関連性が高く、フォローアップの相互作用が多くなります。フィードバック予測のためのトレーニングデータセットを構築できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: A Systematic Characterization of Sampling Algorithms for Open-ended
  Language Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_25.html">
      <font color="black">A Systematic Characterization of Sampling Algorithms for Open-ended
  Language Generation</font>
    </a>
  </h2>
  <font color="black">私たちのデータとコードは、https：//github.com/moinnadeem/characterizing-sampling-algorithmsで入手できます。さまざまなサンプリングアルゴリズムによって定義された変換を注意深く調べた後、それらの間で共有される3つの主要なプロパティを識別します。エントロピー低減、次数保存、および勾配保存です。この作業では、自動回帰言語モデルに広く採用されている祖先サンプリングアルゴリズムを研究します。文献では広く研究されていません。 
[要旨]多様性の質（q-d）トレードオフを使用して、3つの人気のあるサンプリングアルゴリズムを調査します。最初に、既存のサンプリングアルゴリズムが同様のパフォーマンスであることを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Joint Layer RNN based Keyphrase Extraction by Using
  Syntactical Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_26.html">
      <font color="black">Improving Joint Layer RNN based Keyphrase Extraction by Using
  Syntactical Features</font>
    </a>
  </h2>
  <font color="black">キーワードの1つのシーケンスを出力し、単語の埋め込みのみを使用する元のジョイントレイヤーリカレントニューラルネットワーク（JRNN）とは異なり、ここでは、JRNNの入力レイヤーを変更して、構文機能の追加情報によって複数のキーワードシーケンスを抽出することを提案しますつまり、品詞、名前付きエンティティタイプ、依存構造などです。この研究では、Twitterからインドネシア語で書かれたテキストに焦点を当てています。実験により、メソッドがベースラインメソッドよりも優れていることがわかりました。 
[ABSTRACT]達成されたデータ拡張方法。 9597の精度と。 761のf1 ..ourメソッドは合計で。 9597。 9597.トレーニングの例の数を増やすためにデータ拡張技術を使用しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Using Known Words to Learn More Words: A Distributional Analysis of
  Child Vocabulary Development -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_27.html">
      <font color="black">Using Known Words to Learn More Words: A Distributional Analysis of
  Child Vocabulary Development</font>
    </a>
  </h2>
  <font color="black">以前の分析とは異なり、単語の軌跡を横断的に予測し、単一の時点では明らかではなかった語彙の発達の傾向に光を当てました。語彙の発達における項目ベースの変動性を、子供向けのスピーチの大きなコーパス..なぜ子供たちは他の言葉より先にいくつかの言葉を学ぶのですか？ 
[要約]単語の軌跡を断面的に予測し、語彙の発達の傾向に光を当てた</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: UniVL: A Unified Video and Language Pre-Training Model for Multimodal
  Understanding and Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_28.html">
      <font color="black">UniVL: A Unified Video and Language Pre-Training Model for Multimodal
  Understanding and Generation</font>
    </a>
  </h2>
  <font color="black">ビデオテキストジョイント、条件付きマスク言語モデル（CMLM）、条件付きマスクフレームモデル（CMFM）、ビデオテキストの配置、および言語再構成を含む5つの目的は、各コンポーネントをトレーニングするように設計されています。事前トレーニングは、かなりの教育用ビデオデータセットHowTo100Mを使います。UniVLのトレーニングプロセスをより効果的にするために、2つの事前トレーニング戦略（段階的な事前トレーニング（StagedP）と強化されたビデオ表現（EnhancedV））をさらに開発します。 
[ABSTRACT]これらには、2つのシングルモーダルエンコーダー、クロスエンコーダー、およびトランスフォーマーバックボーンを備えたデコーダーが含まれます。univlは、強力なビデオ-テキスト表現を学習し、5つのダウンストリームタスクで最先端の結果を達成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-15">
        <br><font color="black">2020-02-15</font>
      </time>
    </span>
</section>
<!-- paper0: Attention-Aware Inference for Neural Abstractive Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/cs.CL/paper_29.html">
      <font color="black">Attention-Aware Inference for Neural Abstractive Summarization</font>
    </a>
  </h2>
  <font color="black">Googleのニューラル機械翻訳（NMT）\ cite {Wu2016Google}に触発されて、推論中に最適な均一な注意分布を伴う翻訳タスクの1対1の配置をモデル化し、この研究はニューラル抽象要約のための注意を意識した推論アルゴリズムを提案します（ NAS）生成された要約を調整して、最適なカバレッジでソースの段落/文に対応します。最後に、注意が必要な推論を、モデルアーキテクチャに応じて簡単な変更を加えた単一文書の要約に採用できます。実験WikiSum \ cite {liu2018generating}は、提案されたHTが他の強力なTransformerベースのベースラインをすでに上回っていることを示唆しています。 
[ABSTRACT] googleの新しいシステムはアテンションジェネレーター（ht）の使用に基づいています。これは、最適なアテンションソースを予測するために使用できます。システムは、品質を改善するシステムを開発するために開発できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Self-and-Mixed Attention Decoder with Deep Acoustic Structure for
  Transformer-based LVCSR -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.AS/paper_0.html">
      <font color="black">Self-and-Mixed Attention Decoder with Deep Acoustic Structure for
  Transformer-based LVCSR</font>
    </a>
  </h2>
  <font color="black">また、共有の埋め込みスペースで音響抽象化の異なるレベルとそれに対応する言語情報との間のアライメントを同時に学習する混合注意メカニズムも設計します。これは、このタスクで得られた最良の結果であり、テストセットでは5.1％です。具体的には、複数のレベルの音響抽象化のために多層の深層音響構造を学習するための自己注意メカニズムを導入します。 。 
[要約]それは、ソースとターゲットの埋め込みとの関係を学習するために自己注意をもってエンコーダ/デコーダ構造を使用します。提案された構造は、開発セットで4.8％、デバイスで5.1％のCERSを達成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br><font color="black">2020-06-18</font>
      </time>
    </span>
</section>
<!-- paper0: When Automatic Voice Disguise Meets Automatic Speaker Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.AS/paper_1.html">
      <font color="black">When Automatic Voice Disguise Meets Automatic Speaker Verification</font>
    </a>
  </h2>
  <font color="black">最後に、復元ありと復元なしのASV機能の対照的な視覚化は、提案されたアプローチの役割を直感的な方法で示します。次に、最新のASVメソッドを使用して、等しいエラー率（ EER）。さらに、ASVスコアの関数を最小化することにより、偽装音声を元のバージョンに復元するアプローチが提案されています。変装を復元するために一般化する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: RECOApy: Data recording, pre-processing and phonetic transcription for
  end-to-end speech-based applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.AS/paper_2.html">
      <font color="black">RECOApy: Data recording, pre-processing and phonetic transcription for
  end-to-end speech-based applications</font>
    </a>
  </h2>
  <font color="black">このツールは、プロンプト音声の録音、スペクトログラムと波形の分析、発話レベルの正規化と無音のトリミング、およびチェコ語、英語、フランス語、ドイツ語の8つの言語のプロンプトの書記素から音素への変換のための使いやすいインターフェースを実装しています、イタリア語、ポーランド語、ルーマニア語、スペイン語..このペーパーでは、RECOApyツールを紹介します。書記素から音素（G2P）へのコンバーターは、ウィクショナリーのオンライン共同リソースから抽出された辞書でトレーニングされたディープニューラルネットワーク（DNN）ベースのアーキテクチャーです。 。 
[要約] recoapyは、end-to-of-waveテクノロジーで必要なデータの記録と前処理のステップを合理化します。書記素-から-音素（g2p）-コンバーターは、ウィクショナリーオンラインリソースから抽出された辞書でトレーニングされます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-11">
        <br><font color="black">2020-09-11</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Audio Attacks on ASR Systems with Dropout Uncertainty -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.AS/paper_3.html">
      <font color="black">Detecting Audio Attacks on ASR Systems with Dropout Uncertainty</font>
    </a>
  </h2>
  <font color="black">私たちは、MozillaのCommonVoiceデータセット、UrbanSoundデータセット、およびLibriSpeechデータセットの抜粋で防御をテストし、幅広いシナリオで高い検出精度を達成していることを示しています。防御は、最適化された摂動を通じて作成された攻撃を検出できることを示しています。最先端のエンドツーエンドのASRシステムでの周波数マスキング。さらに、防御は、ノイズ低減の影響を受けない攻撃に対して堅牢にすることができます。 
[ABSTRACT]防御は攻撃から保護するために使用できます。防御は防御防御防御で開発されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-02">
        <br><font color="black">2020-06-02</font>
      </time>
    </span>
</section>
<!-- paper0: Determined BSS based on time-frequency masking and its application to
  harmonic vector analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.AS/paper_4.html">
      <font color="black">Determined BSS based on time-frequency masking and its application to
  harmonic vector analysis</font>
    </a>
  </h2>
  <font color="black">HVAを処理するために、決定されたBSSのモデリング問題を時間周波数マスクの設計問題に再キャストする一般的なアルゴリズムフレームワークも提案されます。開発の鍵は、ソース信号のモデリング、たとえば独立ベクトル分析（IVA）です。 ）各ソースの周波数成分間の共起を考慮します。統計的独立性に基づいて決定されたBSS問題を定式化することにより、いくつかの方法が成功裏に開発されました。 
[要約]決定されたbss問題は、「独立した低ランクのマトリックス分析」に基づいています。これらには、これらのタイプの音声と音楽が含まれます。この方法は成功裏に開発されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br><font color="black">2020-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: A dataset and classification model for Malay, Hindi, Tamil and Chinese
  music -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.AS/paper_5.html">
      <font color="black">A dataset and classification model for Malay, Hindi, Tamil and Chinese
  music</font>
    </a>
  </h2>
  <font color="black">分類モデルは、さまざまな音楽的特徴を入力として使用することを検討することによって最適化されました。高レベルの特徴、つまり音楽的に意味のある特徴と、低レベルの特徴、つまりスペクトログラムベースの特徴の両方が、次のようにオーディオファイルから抽出されました。このホワイトペーパーでは、シンガポールの3つの主要な民族グループである中国、マレー、インド（ヒンディー語とタミル語）の音楽を除いて、新しいデータセットを提示します。 
[ABSTRACT]このデータセットを使用して、音楽の起源を区別するさまざまな分類モデルをトレーニングします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-09">
        <br><font color="black">2020-09-09</font>
      </time>
    </span>
</section>
<!-- paper0: UniVL: A Unified Video and Language Pre-Training Model for Multimodal
  Understanding and Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-16/eess.AS/paper_6.html">
      <font color="black">UniVL: A Unified Video and Language Pre-Training Model for Multimodal
  Understanding and Generation</font>
    </a>
  </h2>
  <font color="black">ビデオテキストジョイント、条件付きマスク言語モデル（CMLM）、条件付きマスクフレームモデル（CMFM）、ビデオテキストの配置、および言語再構成を含む5つの目的は、各コンポーネントをトレーニングするように設計されています。トレーニング戦略、ステージごとの事前トレーニング（StagedP）と強化されたビデオ表現（EnhancedV）。UniVLのトレーニングプロセスをより効果的にします。事前トレーニングは、かなりのサイズの教育用ビデオデータセットHowTo100Mで実行されます。 
[ABSTRACT]これらには、2つのシングルモーダルエンコーダー、クロスエンコーダー、およびトランスフォーマーバックボーンを備えたデコーダーが含まれます。univlは、強力なビデオ-テキスト表現を学習し、5つのダウンストリームタスクで最先端の結果を達成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-15">
        <br><font color="black">2020-02-15</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
