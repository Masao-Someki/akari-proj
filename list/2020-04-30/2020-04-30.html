<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-04-30の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Seeing voices and hearing voices: learning discriminative embeddings
  using cross-modal self-supervision -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.SD/paper_0.html">
      Seeing voices and hearing voices: learning discriminative embeddings
  using cross-modal self-supervision
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この方法の有効性は、2つの下流タスクで実証されます。オーディオビジュアル同期でトレーニングされた機能を使用した読唇、およびクロスモーダルバイオメトリックマッチング用にトレーニングされた機能を使用した話者認識です。提案された方法は、最先端のパフォーマンスより優れています。重要なマージンによる自己監視ベースライン。このために、モダリティ全体でメトリックを最適化するだけでなく、各モダリティ内でクラス内機能分離を実施する新しいトレーニング戦略を提案します。 
[要約]提案された方法を使用して、最先端の自己監視ベースラインを重要なマージンで識別することができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Determined BSS based on time-frequency masking and its application to
  harmonic vector analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.SD/paper_1.html">
      Determined BSS based on time-frequency masking and its application to
  harmonic vector analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      HVAを処理するために、決定されたBSSのモデリング問題を時間-周波数マスクの設計問題に再キャストする一般的なアルゴリズムフレームワークも提案されています。実験的調査により、HVAがIVAおよび独立した低ランクマトリックス分析よりも優れていることが示されています。 （ILRMA）音声信号と音楽信号の両方について。この論文では、ケプストラムのスパース性を介してオーディオ信号の調和構造をモデル化することにより、調和ベクトル分析（HVA）と呼ばれる決定されたBSS法を提案します。 
[要約]決定されたbss問題は、「独立した低ランクのマトリックス分析」に基づいています。これらには、これらのタイプの音声と音楽が含まれます。この方法は成功裏に開発されました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Speech Decomposition via Triple Information Bottleneck -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.SD/paper_2.html">
      Unsupervised Speech Decomposition via Triple Information Bottleneck
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、最先端の音声変換システムにより、話者に依存する独立した情報のもつれを解くことができる音声表現が可能になりました。残りの音声コンポーネントのもつれを解くのは、各コンポーネントに明示的な注釈がない場合、未確定の問題です。これらのシステムは音色のもつれをほぐすことができるだけで、ピッチ、リズム、内容に関する情報は依然として混合されています。 
[ABSTRACT]スピーチスプリットは、スピーチを4つのコンポーネントに分解できます。これらのシステムは、音色をほぐすことができるだけですが、ピッチ、リズム、内容に関する情報は依然依存しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-23">
        <br>2020-04-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Meta-Transfer Learning for Code-Switched Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.SD/paper_3.html">
      Meta-Transfer Learning for Code-Switched Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      したがって、新しい学習方法であるメタ転送学習を提案します。メタ転送学習は、高リソースの単一言語データセットから情報を慎重に抽出することにより、低リソースの設定でコード交換音声認識システムに学習を転送します。モデルは、個々の言語を認識することを学習し、コード切り替えデータに基づいて最適化を調整することにより、混合言語音声をよりよく認識するようにそれらを転送します。実験結果に基づいて、私たちのモデルは、音声認識および言語モデリングタスクの既存のベースラインよりも優れており、収束が高速です。 
[要約]音声認識システムを使用して音声認識システムを構築できます。ただし、リソースが不足しているため、混合言語データを収集しようとするとコストがかかるため、困難です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: VGGSound: A Large-scale Audio-Visual Dataset -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.SD/paper_4.html">
      VGGSound: A Large-scale Audio-Visual Dataset
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      既存のオーディオデータセットと比較して、VGGSoundはオーディオとビジュアルの対応を保証し、制約のない条件下で収集されます。3つの貢献を行います。次に、このパイプラインを使用して、310のオーディオクラスに対して210k以上のビデオで構成されるVGGSoundデータセットをキュレーションします。 
[要旨] vggsoundデータセットは、310のオーディオクラスに対して210k以上の動画で構成されています。データセットは制約のない条件下で収集されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Evaluating Dialogue Generation Systems via Response Selection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_0.html">
      Evaluating Dialogue Generation Systems via Response Selection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験を通じて、私たちの方法で開発されたテストセットを使用した応答選択によるシステムの評価は、BLEUなどの広く使用されている自動評価指標と比較して、人間の評価とより強く相関していることを示しています。 （i）グラウンドトゥルース応答に関係のないもの、（ii）適切な応答として許容できるもの。応答選択を介してシステムを適切に評価するために、適切に選択された誤った候補を含む応答選択テストセットを構築する方法を提案します。 。 
[ABSTRACT]テストシステムは、いくつかのタイプの偽の候補を除外するように設計されています。これらには、地面に関係のない候補が含まれます-真の応答と相関
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: TUNIZI: a Tunisian Arabizi sentiment analysis Dataset -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_1.html">
      TUNIZI: a Tunisian Arabizi sentiment analysis Dataset
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、ソーシャルネットワークから収集され、分析研究のために前処理され、チュニジアのネイティブスピーカーによって手動で注釈が付けられた感情分析チュニジアアラビジデータセットTUNIZIを紹介します。分析研究は、計画および予測の目的でそれらを活用することを目的として、オンラインの意見を探索および認識することを目的としています。たとえば、顧客満足度の測定や、販売およびマーケティング戦略の確立などです。ソーシャルメディアでは、アラビア人は自分の方言で自分を表現する傾向があります。 
[要旨]ディープラーニングに基づく研究はデータに飢えています。ただし、研究は言語に焦点を当てています。知る限りでは、注釈付きのチュニジアアラビジデータセットは存在しません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Analysing Lexical Semantic Change with Contextualised Word
  Representations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_2.html">
      Analysing Lexical Semantic Change with Contextualised Word
  Representations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      新しい評価データセットを作成し、モデル表現と検出された意味論的シフトが人間の判断と正の相関があることを示します。広範な定性分析により、この方法がさまざまな共時的および通時的言語現象を捉えていることが示されています。文脈化された単語表現を利用する語彙的意味変化へのアプローチ。 
[ABSTRACT]新しい方法は、bertvised言語モデルを使用して、単語の使用法の表現を取得します。提案されている3つのメトリックを使用して、時間の経過とともに変化を測定します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Leveraging Declarative Knowledge in Text and First-Order Logic for
  Fine-Grained Propaganda Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_3.html">
      Leveraging Declarative Knowledge in Text and First-Order Logic for
  Fine-Grained Propaganda Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験により、この方法が優れたパフォーマンスを達成することが示され、自然言語と一次論理の両方で表現された宣言的知識を注入することで、モデルがより正確な予測を行うのに役立つことが実証されています。後者は、粗い予測と細かい予測の間の論理的な一貫性を指します。これは、命題ブール式でトレーニングプロセスを正則化するために使用されます。ニュース記事での宣伝テキストフラグメントの検出を研究します。 
[ABSTRACT]細かいプロパガンダ手法の知識を注入するアプローチを紹介します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: AxCell: Automatic Extraction of Results from Machine Learning Papers -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_4.html">
      AxCell: Automatic Extraction of Results from Machine Learning Papers
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、結果抽出のためのトレーニングモデル用の構造化された注釈付きデータセットと、このタスクでのモデルのパフォーマンスを評価するためのデータセットもリリースします。最近の論文数の急増により、機械学習の進捗状況の追跡はますます難しくなっています。AxCellは、テーブルセグメンテーションサブタスクを含むいくつかの新しいコンポーネントを使用して、抽出を支援する関連する構造的知識を学習します。 
[ABSTRACT] axublは、論文から結果を抽出するための自動機械学習パイプラインであり、新しい論文で明らかになりました。axublと呼ばれるツールを使用して機械学習マシンから結果を学習します。これにより、半自動データに使用できます生産における抽出
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to Learn to Disambiguate: Meta-Learning for Few-Shot Word Sense
  Disambiguation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_5.html">
      Learning to Learn to Disambiguate: Meta-Learning for Few-Shot Word Sense
  Disambiguation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちはこのシナリオにいくつかの人気のあるメタ学習アプローチを拡張し、この新しい挑戦的な設定でそれらの長所と短所を分析します。メタ学習アプローチはこれまで、通常、$ N $ウェイ、$ K $ショット分類設定でテストされてきました各タスクには$ N $クラスがあり、クラスごとに$ K $の例があります。WSDはその性質上、この制御された設定から逸脱しており、非常に多くの不均衡なクラスを処理するモデルを必要とします。 
[ABSTRACT]これらのアプローチは、汎用性に欠け、すばやく学習して適応するのに苦労しています。少数の単語の意味の曖昧性解消（wsd）のためのメタ学習フレームワークを提案しています。目的は、目に見えない単語を少数のラベル付きインスタンスから明確にすることです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Attention Is All You Need for Chinese Word Segmentation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_6.html">
      Attention Is All You Need for Chinese Word Segmentation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、最高のセグメンテーション速度で、提案されたモデルが厳密なクローズドテスト設定の観点から強力なベースラインに対して新しい最先端または同等のパフォーマンスを達成することを示しています。このモデルは、SIGHAN Bakeoffベンチマークデータセットで評価されています。効果的なエンコーダー設計では、モデルはスコアリングにユニグラム機能のみを必要とします。 
[ABSTRACT]私たちのモデルは、アテンションのみのスタックエンコーダーと十分に軽量なデコーダー、さらにスムーズなトレーニングのための2つの高速道路接続で構成されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-31">
        <br>2019-10-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Contrastive Multi-document Question Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_7.html">
      Contrastive Multi-document Question Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      そのような特定の質問を生成するために、教師あり学習（SL）ステージと強化学習（RL）ステージを含む新しいフレームワークであるマルチソース協調質問ジェネレーター（MSCQG）を提案します。これらは、ドキュメントで説明されているよりも広い範囲をカバーしていますRLステージでは、コーディネーターモデルは、生成された質問の特定性を促進するように設計された報酬を最適化することにより、複数の単一ドキュメントジェネレーターインスタンスの間で最適な注意の重みを見つけるようにトレーニングされます。 
[ABSTRACT]「ポジティブ」と「ネガティブ」のドキュメントセットに基づくモデルは、一般的な質問を生成します。つまり、特定の質問を生成するために、教師あり学習を含む新しいフレームワークであるマルチソース協調質問ジェネレーター（mscqg）を提案します（ sl）ステージおよびウェズリーwesley s）ステージ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-08">
        <br>2019-11-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-View Attention Networks for Visual Dialog -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_8.html">
      Multi-View Attention Networks for Visual Dialog
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      VisDial v1.0およびv0.9ベンチマークの実験結果は、提案されたモデルの有効性を示しています。これは、すべての評価指標に関して、従来の最先端の方法よりも優れています。MVANは、質問に関連する情報を2つの異なるテキストビュー（つまり、トピック集約とコンテキストマッチング）を備えたダイアログ履歴。マルチモーダル表現を2段階のフュージョンプロセスと統合します。具体的には、エージェントが1）質問関連のダイアログ履歴を理解し、2）特定の画像の多様な視覚的コンテンツの中で、質問に関連する視覚的コンテンツに焦点を当てます。 
[要約]このホワイトペーパーでは、マルチビューアテンションネットワーク（mvan）を提案します。アテンションメカニズムに基づいてマルチモーダルインポートのさまざまなビューを考慮します。mvanは、従来の方法より優れた提案モデルです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Do Neural Language Models Show Preferences for Syntactic Formalisms? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_9.html">
      Do Neural Language Models Show Preferences for Syntactic Formalisms?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      13の異なる言語でトレーニングされたBERTモデルとELMoモデルに有向依存関係ツリーを抽出するためのプローブを適用し、2つの異なる構文アノテーションスタイル（ユニバーサル依存関係（UD）、深い構文関係の優先順位付け、および表面構文ユニバーサル依存関係（SUD））を調べ、表面構造について..両方のモデルがSUDよりもUDに対して好みを示している-言語とレイヤーにまたがる興味深い変化がある-そしてこの好みの強さが木の形の違いと相関していることを見つけます。深い神経の解釈可能性に関する最近の研究言語モデルは、自然言語構文の多くの特性がそれらの表現空間にエンコードされていると結論付けました。 
[要約]研究は、単一の言語と単一の言語形式に焦点を当てています。これらの研究は、範囲が限定されていることがよくあります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Zero-shot topic generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_10.html">
      Zero-shot topic generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は、ゼロショットモデルが、人間が書いたものと同等またはそれ以上の品質のニュースドキュメントのトピックラベルを生成することを示しています。人間による判断では、人間のアノテーターが品質を評価する二重盲検試験を実施しました。 The GuardianとThe Huffington Postのニュース記事に関連付けられた、人間が書いたオリジナルのトピックとともに、機械で生成されたトピックの一部です。ドキュメントのタイトルを生成するために、ドキュメント内の候補スパンの関連性をキャプチャする機能を活用します。 
[ABSTRACT]ドキュメントでは候補スパンの関連性を捉えたストーリーを使用しています。人権について被験者をテストするツールを作成するために使用しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Avoiding catastrophic forgetting in mitigating model biases in
  sentence-pair classification with elastic weight consolidation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_11.html">
      Avoiding catastrophic forgetting in mitigating model biases in
  sentence-pair classification with elastic weight consolidation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、NLIでトレーニングされたシステムを微調整して、ドメインシフトが大きくてもMultiNLIデータセットの精度の損失を最小限に抑えて、ストレステストチャレンジタスクの精度を向上できることを示します。このホワイトペーパーでは、弾性加重統合（EWC ）モデルの微調整により、破壊的な忘却の影響を受けにくく、NLIと事実検証のバイアスを軽減できます。トレーニングデータセットに存在するバイアスは、自然言語推論（NLI）などの多くのタスクのモデルに影響を与えることが示されていますそして事実の検証。 
[ABSTRACT]一般的な問題は、元のタスクの壊滅的な忘却の問題です。実際の検証システムでは、モデルの忘却レベルが低いほど、ewc paretoで微調整されたものが標準の罰金を支配することを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Deepening Hidden Representations from Pre-trained Language Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_12.html">
      Deepening Hidden Representations from Pre-trained Language Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      バックボーンエンコーダーとしてRoBERTaを利用して、事前トレーニング済みモデルに対する提案された改善は、複数の自然言語理解タスクに効果的であることが示され、GLUEベンチマークの最新モデルと競合するモデルを支援します。単一レイヤーの出力を取得すると、事前トレーニング済みの表現のパワーが制限されます。しかし、現在のアプローチでは、ダウンストリームタスクを微調整するときに、エンコーダーの最終レイヤーの出力のみを利用します。 
[ABSTRACT]私たちはの隠された表現を融合することによって学んだ表現を深めます。しかし、現在のモデルはプロジェクトを利用するだけです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-05">
        <br>2019-11-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: BLEU Neighbors: A Reference-less Approach to Automatic Evaluation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_13.html">
      BLEU Neighbors: A Reference-less Approach to Automatic Evaluation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この目的のために、BLEUスコアをカーネル関数として使用して言語品質を推定するための最近傍モデルであるBLEUネイバーを提案します。ゴールドスタンダードのリファレンスエッセイにアクセスできるモデルです。雑談の対話と自由記述式の文章生成用の既存のデータセットでは、平均して、BLEU近隣モデルからの品質推定の平均二乗誤差が低く、個々の人間のアノテーターよりも、スピアマンとグラウンドトゥルースとの相関が高い。 
[ABSTRACT] bleuなどの自動メトリックは参照に依存しますが、オープンエンドの生成などのタスクでは、参照する参照はありません。ただし、大規模な人間の評価は遅く、費用がかかるため、控えめに使用されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br>2020-04-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ConvLab-2: An Open-Source Toolkit for Building, Evaluating, and
  Diagnosing Dialogue Systems -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_14.html">
      ConvLab-2: An Open-Source Toolkit for Building, Evaluating, and
  Diagnosing Dialogue Systems
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      対話型ツールは、開発者がシステムと対話し、各システムコンポーネントの出力を変更することにより、組み立てられた対話システムを診断できるユーザーインターフェイスを提供します。分析ツールは、豊富な統計を提供し、シミュレーションされた対話からの一般的な間違いを要約します。システムの改善..さらに、研究者が対話システムを診断するのを支援する分析ツールと対話型ツールを開発しました。 
[要約] convlabの後継として、convlabのフレームワークを継承しますが、より強力な対話モデルを統合し、より多くのデータセットをサポートします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-12">
        <br>2020-02-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Adversarial Subword Regularization for Robust Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_15.html">
      Adversarial Subword Regularization for Robust Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      モデルベースの敵対サンプルがNMTモデルのセグメンテーションエラーに対する感度を下げ、低リソースデータセットのNMTモデルの堅牢性を効果的に向上させることを実験的に示します。ただし、サブワードセグメンテーションの分布は、サブワード言語モデルに大きく依存していますこのホワイトペーパーでは、トレーニング中の勾配信号が候補間のセグメンテーションを選択するための代替基準になるかどうかを調べるために、敵対的なサブワード正則化（ADVSR）を紹介します。 
[ABSTRACT]サブワードrousousousousousousモデルはサブワード候補を経験します。モデルはセグメンテーションエラーに対してより堅牢になります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Pre-training Is (Almost) All You Need: An Application to Commonsense
  Reasoning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_16.html">
      Pre-training Is (Almost) All You Need: An Application to Commonsense
  Reasoning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      微調整を行わずにスコアリング手法を活用することで、強力なベースラインを生成できます（例：モデルがCOPA、Swag、HellaSwag、およびCommonsenseQAデータセットに焦点を当てて、前提を与えられた仮説のセットをランク付けする必要がある常識推論タスクを研究します。 。管理されたアプローチに匹敵するCOPAの80％テスト精度）。 
[ABSTRACT]新しいメソッドは、説得力のランク付けタスクをフルテキスト形式でキャストします。トレーニング前の段階で調整されたマスクされた言語モデリングヘッドを使用します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: BERTRAM: Improved Word Embeddings Have Big Impact on Contextualized
  Model Performance -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_17.html">
      BERTRAM: Improved Word Embeddings Have Big Impact on Contextualized
  Model Performance
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは、ディープアーキテクチャで単語の表面形式とコンテキストが相互に対話できるようにすることで実現されます。静的な単語の埋め込みの場合、この問題は、珍しい単語の表現を個別に学習することで解決されています。BERTRAMをBERTに統合すると、レアワードプロービングタスクと3つのダウンストリームタスクの両方でレアおよびミディアムワードの表現が改善されたため、パフォーマンスが向上しました。 
[ABSTRACT]スーパートレーニング済み言語モデルは、希少単語の埋め込みを推測できます。これらのモデルは希少単語を理解するのに苦労しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-16">
        <br>2019-10-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Morphological Disambiguation of South Sámi with FSTs and Neural
  Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_18.html">
      Morphological Disambiguation of South Sámi with FSTs and Neural
  Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのアプローチは、南S \ &#39;amiに最小限のリソースしか必要としないため、他の危険にさらされている言語のコンテキストでも使用および適用できます。これにより、対訳辞書や整列された単語の埋め込みを必要とせずに、南S \ &#39;amiの北S \&#39; amiトレーニングデータを使用できるようになります。絶滅危惧言語。 
[ABSTRACT]曖昧性除去は、単語の形式と補題を無視して、量的タグのレベルで行われます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Normalizing Compositional Structures Across Graphbanks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_19.html">
      Normalizing Compositional Structures Across Graphbanks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの仕事は、MR間の構成構造の一致を大幅に向上させ、低リソース設定でのマルチタスク学習（MTL）を改善し、注意深いMR設計分析と比較の有用性を示しています。ここで、 MRは意味があり、意味的に根付いており、表面的なものです。MR間の不一致を構成レベルで正規化する方法論（Lindemann et al。、2019）を提示します。これにより、言語的に根拠のある多様な現象を正規化できます。ルール。 
[ABSTRACT]これらは、さまざまな理論的および設計上の考慮事項を反映する構造上の違いを示します。構成レベルでのmrs間の不一致を正規化する方法を提示します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: General Purpose Text Embeddings from Pre-trained Language Models for
  Scalable Inference -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_20.html">
      General Purpose Text Embeddings from Pre-trained Language Models for
  Scalable Inference
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      システムが約7つのタスクを処理すると、私たちの最良のアプローチは知識の蒸留に有利になり、より高い精度と低い計算コストを実現します。このようなエンコーダーのトレーニングのアプローチを比較し、複数のタスクで事前トレーニングされたエンコーダーが目に見えないタスクに一般化することを示します。その場合、推論中の計算コストの一部は、共有テキストエンコーダーを使用して、さまざまなタスクにわたって償却できます。 
[ABSTRACT]複数のタスクで事前トレーニングされたエンコーダは、目に見えないタスクに一般化します。この方法は、同じテキストで複数のタスクが実行されるときに、わずかなコストで大規模の事前トレーニング済みモデルを使用するための説得力のあるソリューションを提供します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Revisiting Pre-Trained Models for Chinese Natural Language Processing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_21.html">
      Revisiting Pre-Trained Models for Chinese Natural Language Processing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、MacBERTが多くのNLPタスクで最先端のパフォーマンスを達成できることを示しています。また、将来の研究に役立つ可能性のあるいくつかの調査結果で詳細を削除します。トランスフォーマー（BERT）からの双方向エンコーダー表現は、さまざまなNLP全体で驚くべき改善を示しています事前トレーニング済みモデルのパフォーマンスをさらに向上させるために、タスクとさまざまなバリアントが提案されています。MacBERTと呼ばれるシンプルだが効果的なモデルも提案します。これは、RoBERTaをいくつかの点で、特にマスキング戦略で改善します。 
[要約]論文では、英語以外の言語での効果を調べるために、多くの中国の事前トレーニング済みモデルを対象としています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-choice Dialogue-Based Reading Comprehension with Knowledge and Key
  Turns -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_22.html">
      Multi-choice Dialogue-Based Reading Comprehension with Knowledge and Key
  Turns
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      元のコンテキスト、質問、外部知識は事前トレーニング済みの言語モデルでエンコードされ、言語表現とキーターンは意志設計のメカニズムと組み合わされて回答を予測します。このホワイトペーパーでは、各ターンの関連性質問は主要なターンを選択するために計算されます。2つの課題があり、答えの選択は潜在的に役立つ常識のサポートなしで行われます。また、マルチターンコンテキストは重要でない情報を隠す可能性があります。 
[ABSTRACT]私たちの研究は、対話がマルチターンの対話である対話ベースのmrcに焦点を当てています。この研究は、コンテキストの表現を強化するための外部知識の使用にも焦点を当てています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Modeling Long Context for Task-Oriented Dialogue State Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_23.html">
      Modeling Long Context for Task-Oriented Dialogue State Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      発話連結された対話コンテキストから対話状態を予測する最近提案された転送可能な対話状態ジェネレータ（TRADE）に基づいて、シンプルでありながら効果的な発話タグ付け技術と双方向言語モデルをタスクの補助タスクとして使用するマルチタスク学習モデルを提案します指向の対話状態の生成..私たちの実験では、提案されたモデルはベースラインに対して7.03％の相対改善を達成し、MultiWOZ 2.0データセットで52.04％の新しい最先端の共同目標の精度を確立しています。長い対話コンテキストのより適切な表現を学習するためのモデルでは、入力対話コンテキストシーケンスが長いとベースラインのパフォーマンスが大幅に低下するという問題の解決を試みます。 
[ABSTRACT]ニューヨークベースのモデルは、長い対話言語のより良い表現を学ぶためのタスクを作成しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards Transparent and Explainable Attention Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_24.html">
      Towards Transparent and Explainable Attention Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      注意メカニズムをより忠実で妥当なものにするために、さまざまなタイムステップで学習された非表示表現が確実に多様化する、多様性主導のトレーニング目標を備えた修正LSTMセルを提案します。 -ステップは互いに非常に類似しており（高い円錐度）、注意の重みのランダムな順列でもモデルの予測に影響を与えないため、これらの状況での注意の重みはあまり意味がありません。さまざまなタスクの実験に基づいて、データセットでは、注意の分布が、モデルの予測を句読点などの重要でない単語に起因することが多く、予測に対してもっともらしい説明を提供できないことがわかります。 
[要旨]当社のコードはwwwで公開されています。 github.com / akashkm9999 / interpretable-注意の短所）.studyは、注意の促進者がモデルの予測に対してもっともらしい説明を提供しないことを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: UniConv: A Unified Conversational Neural Architecture for Multi-domain
  Task-oriented Dialogues -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_25.html">
      UniConv: A Unified Conversational Neural Architecture for Multi-domain
  Task-oriented Dialogues
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      MultiWOZ2.1ベンチマークで対話状態の追跡、コンテキストからテキスト、エンドツーエンドの設定で包括的な実験を行い、すべてのタスクで競争力のあるベースラインよりも優れたパフォーマンスを達成します。コードとモデルがリリースされます。マルチドメインのタスク指向の対話のためのエンドツーエンドの会話型エージェントは、主に2つの理由から未解決の課題でした。 
[ABSTRACT]「uniconv」を提案します-マルチドメインのタスク関連の対話におけるエンドツーエンドの会話システムのための新しい統合ニューラルアーキテクチャです。これは、スロットレベルとドメインレベルの両方で信号を個別に学習することで対話状態を追跡するように設計されています、および共同の対話行為と応答ジェネレータ。プロジェクトがリリースされ、コンテキスト、およびテストの実施が公開されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: From English To Foreign Languages: Transferring Pre-trained Language
  Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_26.html">
      From English To Foreign Languages: Transferring Pre-trained Language
  Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、6つの言語でモデルを評価すると、モデルが2つのゼロショットタスク（自然言語推論と依存関係の解析）で多言語BERTよりも優れていることを示しています。単一のGPUを使用すると、このアプローチでは、この作業では、限られた計算予算の下で、既存の事前トレーニング済みモデルを英語から他の言語に転送するという問題に取り組みます。 
[要約]多言語の事前トレーニングモデルを利用できるため、自然言語タスクのゼロショット転送が可能になります。単一のGPUに加えて、このアプローチでは、1日以内に外国のbertベースモデルを取得できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br>2020-02-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Measuring Information Propagation in Literary Social Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_27.html">
      Measuring Information Propagation in Literary Social Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このパイプラインを使用して、5,000を超えるフィクション作品における情報伝播のダイナミクスを分析し、情報がさまざまなコミュニティをつなぐ構造的な穴を埋めるキャラクターを介して流れ、女性であるキャラクターが、情報伝達をモデル化するタスクを文献で提示します。そこでは、文字Aから文字Bから文字Cに渡る情報の一部を特定しようとしますが、テキストでそれらの活動の説明のみを与えます。新しいこのドメインでの情報伝播を測定し、話者属性の新しいデータセットを公開するためのパイプライン。これにより、以前に調査されたよりも幅広い文学テキストでこのパイプラインの重要なコンポーネントの評価が可能になります。 
[要旨]情報の特徴を測定するための新しいパイプラインについて説明します。また、話者属性の新しいデータセットを公開します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Enhancing Answer Boundary Detection for Multilingual Machine Reading
  Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_28.html">
      Enhancing Answer Boundary Detection for Multilingual Machine Reading
  Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      多言語の事前トレーニング済みモデルは、豊富なソース言語（英語など）からのトレーニングデータを活用して、低リソース言語でのパフォーマンスを向上させることができます。このホワイトペーパーでは、微調整段階で2つの補助タスクを提案し、追加のフレーズ境界監視を作成します：（1）質問またはパッセージを他の言語に翻訳し、クロスリンガルな質問とパッセージのペアを構築する混合MRCタスク。 （2）Webからマイニングされた知識フレーズを活用することによる、言語にとらわれない知識マスキングタスク。さらに、2つのクロスリンガルMRCデータセットに対する広範な実験により、提案されたアプローチの有効性が示されています。 
[要約]多言語の機械読解（mrc）の転送品質は、文分類タスクよりも著しく悪い
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards Character-Level Transformer NMT by Finetuning Subword Systems -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_29.html">
      Towards Character-Level Transformer NMT by Finetuning Subword Systems
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このセグメンテーションに基づいてサブワードモデルを最初にトレーニングし、次にそれを文字に微調整することにより、セグメンテーションを必要とせずに文字レベルで機能するニューラル機械翻訳モデルを取得できることを示します。全体的な翻訳品質がいくらか悪くなりますが、ソース側のノイズに対するロバスト性がはるかに高くなります。通常、トランスフォーマアーキテクチャを文字レベルで適用するには、トレーニングが難しく、トレーニングが遅い非常に深いアーキテクチャが必要です。 
[要約]トークンへの明示的なセグメンテーションを使用してこの問題を部分的に克服するいくつかの提案が提案されています。これらの提案には、トークンへの明示的なセグメンテーションの使用が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Enhancing Pre-trained Chinese Character Representation with Word-aligned
  Attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_30.html">
      Enhancing Pre-trained Chinese Character Representation with Word-aligned
  Attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、文字レベルの注意を単語レベルに合わせるプールメカニズムを考案し、マルチソース情報融合によるセグメンテーションエラー伝播の潜在的な問題を軽減することを提案します。5つの中国のNLPベンチマークタスクの実験結果は、モデルがいくつかの事前トレーニング済みモデルに対して別の重要な利益をもたらします。したがって、さまざまな文字ベースの中国語事前トレーニング済み言語モデルを補完する、明示的な単語情報を活用するために、新しい単語を揃えた注意を提案します。 
[要約]明示的な単語情報の使用は、さまざまな中国語モデルの前兆です。これは、これらのモデルを使用した結果である可能性があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-07">
        <br>2019-11-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: How Does NLP Benefit Legal System: A Summary of Legal Artificial
  Intelligence -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_31.html">
      How Does NLP Benefit Legal System: A Summary of Legal Artificial
  Intelligence
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの作業の実装はhttps://github.com/thunlp/CLAIM。から見つけることができます。法務専門家は、ルールベースおよびシンボルベースの方法からタスクを解決する方法について考えることがよくありますが、NLPの研究者はデータ駆動型に集中します法と専門家とNLP研究者の観点からタスクを説明し、LegalAIのいくつかの代表的なアプリケーションを示します。 
[ABSTRACT] legalaiは、法務専門家を迷路の事務処理から解放するための法制度に有益です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-25">
        <br>2020-04-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Generating Safe Diversity in NLG via Imitation Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_32.html">
      Generating Safe Diversity in NLG via Imitation Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、模倣学習アプローチを使用して、言語生成モデルが安全に生成できる多様性のレベルを調査することにより、このコストを改善することを提案します。実験は、モデルがインクルージョンに敏感なコンセプトからテキストへの生成に焦点を当てています特に、入力と出力の厳密な関係に起因する無関係な単語の数。特に、特定のタイムステップでどの単語が高品質の出力につながるかを区別するようにトレーニングされたメタ分類子を使用して、デコードプロセスを強化します。 
[ABSTRACT]これは、出力の流暢さと妥当性の認識が原因です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploiting Structured Knowledge in Text via Graph-Guided Representation
  Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_33.html">
      Exploiting Structured Knowledge in Text via Graph-Guided Representation
  Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      既存のパラダイムとは対照的に、私たちのアプローチは、事前トレーニング中にのみ暗黙的にナレッジグラフを使用して、生のテキストからの学習を通じて構造化された知識を言語モデルに注入します。実験は、提案されたモデルが、質問応答を含む5つのベンチマークデータセットのパフォーマンスの向上を達成することを示しています。エンティティレベルのマスクされた言語モデルに基づいて構築した最初の貢献は、テキストの基礎となるリレーショナル知識を活用するエンティティマスキングスキームです。 
[ABSTRACT]私たちのアプローチは、ナレッジグラフを使用して、生のテキストから学習することにより、構造化された知識を言語モデルに注入します。これは、リンクされた言語グラフを使用して有益なエンティティを選択し、それらの言及をマスクすることによって実現されます。これらのモデルは、5つのベンチマークデータセットでパフォーマンスを向上させます。質問応答およびナレッジベースの完了タスクを含む
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Zero-Shot Cross-Lingual Transfer with Meta Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_34.html">
      Zero-Shot Cross-Lingual Transfer with Meta Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ゼロショットおよび少数ショットNLI（MultiNLIおよびXNLI）およびQA（MLQAデータセット）の最新技術を改善します。私たちの広範な実験的セットアップは、合計15言語。さまざまな自然言語理解タスク（自然言語の推論、質問応答）について、標準の教師なしゼロショットのクロスリンガル設定と、少数のショットのクロスリンガル設定を使用して実験します。 
[ABSTRACT]これは、世界中のほとんどの言語がリソース不足のため、多言語アプリケーションにとって特に重要です。ここでは、この課題のセットアップが、メタ学習を使用してアプローチできることを示します。ここでは、ソース言語モデルのトレーニングに加えて、別のモデル最初に最も有益なトレーニングインスタンスを選択する方法を学ぶ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-05">
        <br>2020-03-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Syntax-aware Data Augmentation for Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_35.html">
      Syntax-aware Data Augmentation for Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの提案する方法は、WMT14英語からドイツ語へのデータセットとIWSLT14ドイツ語から英語へのデータセットで評価されます。変更のために異なる文全体で同じ確率の単語を単に選択する既存のデータ拡張方法とは異なり、文固有の確率を設定します。文での役割を考慮した単語の選択。入力文の依存関係解析ツリーを有効な手掛かりとして使用して、各文のすべての単語の選択確率を決定します。 
[ABSTRACT]広範な実験の結果は、効果的なデータ拡張方法が既存の文を効果的に後押しする可能性があることを示しています-大幅な翻訳パフォーマンス向上のための独立した方法
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Structure-Level Knowledge Distillation For Multilingual Sequence
  Labeling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_36.html">
      Structure-Level Knowledge Distillation For Multilingual Sequence
  Labeling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、現在の多言語モデルは、モデルキャパシティの制限により、個々の単一言語モデルのパフォーマンスを大幅に下回っています。構造レベルの情報に基づいて、2つの新しいKD法を提案します。（1）学生と教師の構造レベルの確率分布の間の距離をほぼ最小化します。 （2）構造レベルの知識を局所分布に集約し、2つの局所確率分布間の距離を最小化します。この論文では、いくつかの単一言語モデルの構造知識を抽出することにより、単一言語モデルと統合多言語モデル間のギャップを減らすことを提案します。 （教師）統一された多言語モデル（学生）。 
[要旨]私たちは、モノリンギングモデルと統合多言語モデルの間のギャップを減らすことを提案します。多言語モデルを使用すると、モデルサイズが小さくなり、オンラインサービスが容易になり、低リソース言語への一般化が可能になります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Revisiting Round-Trip Translation for Quality Estimation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_37.html">
      Revisiting Round-Trip Translation for Quality Estimation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの方法は、以前のWMT 2019品質推定メトリックタスクサブミッションと比較して、人間の判断との最高の相関を実現します。RTTを使用する場合、逆変換モデルは欠点になる可能性がありますが、セマンティックレベルのメトリックでは、RTTベースのQEが逆方向変換システムの選択。さらに、提案された方法は、SMTおよびNMT順方向変換システムの両方で一貫したパフォーマンスを示し、この方法は特定のタイプのモデルにペナルティを課しません。 
[要約] hrpは当初qeのメトリックと見なされていましたが、翻訳品質の予測因子としては不十分であることが判明しました。代わりに、hrのツールとして使用されましたが、不適切な単語によって発見されました。現在、セマンティックを使用していますRTTベースのqeへの埋め込み
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploring the Suitability of Semantic Spaces as Word Association Models
  for the Extraction of Semantic Relationships -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_38.html">
      Exploring the Suitability of Semantic Spaces as Word Association Models
  for the Extraction of Semantic Relationships
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      現在、テキストからの関係抽出へのアプローチは、大規模コーパスからの機械学習において、ある種の遠隔（弱い）監視を実践する神経モデルによって支配されています。外部の知識源に相談するかどうかは関係ありません。研究の結果は、これらの単語の関連付けモデルが使用できる範囲と、抽出のために考慮される最も有望なタイプの関係にある程度の光を当てる必要があります。目標は、これらの単語の関連付けモデルを使用して現在の関係を強化することです抽出アプローチ。 
[要約]新しい知識はインテリジェントなアプリケーションの主要な要素です。古い知識を修正する必要がある一方で、新しい知識を収集する必要があります。これはこの種の最初の試みです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Span-based Localizing Network for Natural Language Video Localization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_39.html">
      Span-based Localizing Network for Natural Language Video Localization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたVSLNetは、NLVLとスパンベースのQAの違いを、シンプルでありながら効果的なクエリに基づく強調表示（QGH）戦略によって解決します。3つのベンチマークデータセットでの広範な実験を通じて、提案されたVSLNetが最新の性能より優れていることを示しています-アートメソッド;また、スパンベースのQAフレームワークの採用は、NLVLを解決するための有望な方向です。QGHは、ハイライトされた領域内で一致するビデオスパンを検索するようにVSLNetをガイドします。 
[ABSTRACT]標準スパンベースのqaフレームワークに加えて、ビデオスパンローカライズネットワーク（vslnet）を提案し、nlvlに対処します。強調表示された領域に基づいてビデオスパンを検索するqghガイドvslnet
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Generate, Delete and Rewrite: A Three-Stage Framework for Improving
  Persona Consistency of Dialogue Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_40.html">
      Generate, Delete and Rewrite: A Three-Stage Framework for Improving
  Persona Consistency of Dialogue Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人間と自動の両方のメトリックで評価を実行します。Persona-Chatデータセットでの実験により、私たちのアプローチが優れたパフォーマンスを達成することが示されています。人間のような応答の生成に関する既存のペルソナベースのモデルの成功にもかかわらず、それらの1段階のデコードフレームワーク一貫性のないペルソナワードの生成をほとんど回避できません。 
[要旨]人間ベースの対話生成タスクが導入され、人間-一貫性のない応答に対処します。この作業では、生成された応答プロトタイプから一貫性のない単語をデコードし、さらにパーソナリティ-一貫性に書き換える3段階のフレームワークを紹介します1
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: VD-BERT: A Unified Vision and Dialog Transformer with BERT -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_41.html">
      VD-BERT: A Unified Vision and Dialog Transformer with BERT
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      外部のビジョン言語データを事前にトレーニングする必要がないため、このモデルは新しい最先端の技術を生み出し、ビジュアルダイアログリーダーボードで単一モデルとアンサンブルの両方の設定（74.54および75.35 NDCGスコア）でトップの位置を獲得しています。視覚ベースのトレーニングによる視覚とダイアログコンテンツの効果的な融合にBERTを適合させます。これとは対照的に、この作業では、事前訓練されたBERT言語モデルを活用する統合ビジョンダイアログトランスフォーマーのシンプルで効果的なフレームワークであるVD-BERTを提案します。ビジュアルダイアログタスク。 
[要約]モデルは、シングルストリームトランスフォーマーエンコーダーを使用して画像とマルチターンダイアログ間の相互作用をキャプチャするという点で統合されています。ビジュアルダイアログの100万以上のコピーが作成されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: End-to-End Slot Alignment and Recognition for Cross-Lingual NLU -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_42.html">
      End-to-End Slot Alignment and Recognition for Cross-Lingual NLU
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、私たちの実験は、クロスリンガルトレーニングとゼロショット転送の両方にマルチリンガルBERTを使用する利点を示しています。既存のマルチリンガルNLUデータセットは、クロスリンガル転送の研究を制限する最大3つの言語のみをサポートします。自然言語の理解目標指向の対話システムのコンテキストでは、通常、意図の分類とスロットのラベル付けタスクが含まれます。 
[要約]新しい方法は、ターゲット言語への注釈投影による機械翻訳を使用しています。この作業では、alignsticsticsticsticsticsticsticsticsticスロットを学習する新しいエンドツーワードモデルを提案します。この目的のために、多言語NLUコーパス、マルチアティス、多言語atisコーパスをさまざまな言語ファミリの9つの言語に拡張する
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SubjQA: A Dataset for Subjectivity and Review Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_43.html">
      SubjQA: A Dataset for Subjectivity and Review Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      以前の研究の分析と比較対照し、最近開発されたNLPアーキテクチャを使用した場合、主観に関する調査結果が依然として保持されていることを確認します。たとえば、主観的な質問は主観的な回答に関連付けられている場合とそうでない場合があります。さらに、主観性は重要ですユーザー生成データの側面。 
[要約]主観性アノテーションを含む、顧客レビューに基づいた英語のqaデータセット（subjqa）をリリースします。主観性とqaの間のより複雑な相互作用ではありますが、subjectsivityもqaの場合の重要な機能です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: FastBERT: a Self-distilling BERT with Adaptive Inference Time -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_44.html">
      FastBERT: a Self-distilling BERT with Adaptive Inference Time
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、このモデルは、微調整時に独自の自己蒸留メカニズムを採用し、パフォーマンスの損失を最小限に抑えて計算効率をさらに向上させます。サンプルの冗長な計算を避けながら、推論の速度をさまざまな要求の下で柔軟に調整できます。私たちのモデルは、12の英語と中国語のデータセットで有望な結果を達成します。 
[ABSTRACT]結論の速度は、サンプルの冗長なカウントを回避しながら、さまざまな要求の下で柔軟に調整できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-05">
        <br>2020-04-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Active Learning for Coreference Resolution using Discrete Annotation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_45.html">
      Active Learning for Coreference Resolution using Discrete Annotation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのコードは公開されています。既存のベンチマーク相互参照データセットを使った実験では、この追加の質問からの信号により、人間の注釈の1時間あたりのパフォーマンスが大幅に向上することを示しています。どの例にラベルを付けるかは、注釈予算ごとに得られるパフォーマンスの点で非常にコスト効率が高くなります。 
[ABSTRACT]アップグレードはアクティブな言及antecom.itに関連していません。注釈予算ごとに取得されるパフォーマンスの点で非常にコスト効果があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Disfluency Detection by Self-Training a Self-Attentive Model -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_46.html">
      Improving Disfluency Detection by Self-Training a Self-Attentive Model
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      文脈化された単語の埋め込みは、ラベル付けされていない大量のデータで事前トレーニングされているため、追加のラベル付けされていないデータを使用して神経モデルをトレーニングすることは冗長に思えるかもしれません。文脈化された単語の埋め込み（例：ELMoまたはBERT）を使用した自己注意神経構文パーサーは現在生成されます最先端の結果により、音声筆記録の解析と流暢性の検出が同時に行われます。 
[ABSTRACT]セルフトレーニング-ラベルなしデータを組み込むための半教師付き手法-新しい状態を設定する-自己-流暢さの検出に関する注意深いパーサーの技術
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-11">
        <br>2020-04-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Cross-Genre Ensemble Approach to Robust Reddit Part of Speech Tagging -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_47.html">
      A Cross-Genre Ensemble Approach to Robust Reddit Part of Speech Tagging
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Redditデータのタグ付けに関する最先端のパフォーマンス、およびこれらのモデルの結果のエラー分析を提示し、トレーニングコーパスによって分類された、それらの間で最も一般的なエラータイプの類型を提供します。具体的には、データを使用します複数のソースから：OntoNotes、「十分に編集された」テキストを含む大規模なベンチマークコーパス、5つのWebジャンルの英語Web Treebank、およびGUM、Reddit以外の7つのジャンル。ただし、これらのモデルを他のコーパスに適用すると、さまざまなジャンル、特にWebからユーザーが生成したデータでは、パフォーマンスが大幅に低下します。 
[ABSTRACT]アートモデルの現在の状態は、特にニュースドメインで高い精度を達成しています。ただし、ドメイン外のタグ付けを進歩させることができました。また、複数の単一ジャンルのタガーを使用して、アンサンブルアプローチを評価しています。結果
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Entity Candidate Network for Whole-Aware Named Entity Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_48.html">
      Entity Candidate Network for Whole-Aware Named Entity Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ECNetは、エンティティの損失に基づいて、名前付きエンティティの全範囲と各位置でのそのタイプを識別します。一方、このホワイトペーパーでは、新しいモデルであるエンティティ候補ネットワーク（ECNet）と、特定の畳み込みネットワークであるAdaptive Context Convolution Network（ACCN）について説明します。 、マルチスケールコンテキストを融合し、各位置でエンティティ情報をエンコードします。さらに、ECNetは最高の精度と最高の再現率の間で調整可能ですが、タグスキームアプローチはそうではありません。 
[ABSTRACT]新しい論文では、新しいタグなしのスキームである、wholenet検出を提案しています。これにより、nevoがオブジェクト検出タスクになります。ecnetは、エンティティの損失に基づいて、名前付きエンティティの全スパンと各位置でのタイプを識別します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Don't Neglect the Obvious: On the Role of Unambiguous Words in Word
  Sense Disambiguation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_49.html">
      Don't Neglect the Obvious: On the Role of Unambiguous Words in Word
  Sense Disambiguation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      UWA（曖昧さのない単語注釈）データセットを紹介し、最先端の伝播ベースのモデルがそれを使用して、語義の埋め込みのカバレッジと品質を大幅に拡張し、元の結果を改善する方法を示しますWSD .. Word Sense Disambiguation（WSD）の最先端の方法は、2つの異なる機能を組み合わせたものです。事前にトレーニングされた言語モデルのパワーと、そのようなモデルのカバレッジを拡張する伝播方法です。同時に、明確です。単語はWordNet内のすべての単語の大部分を占めますが、既存のセンス付きコーパスでは十分にカバーされていません。 
[ABSTRACT]メソッドは現在の感覚として必要です-注釈付きのコーパスには多くのインスタンスのカバレッジがありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Meta-Transfer Learning for Code-Switched Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_50.html">
      Meta-Transfer Learning for Code-Switched Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      したがって、高リソースの単一言語データセットから慎重に情報を抽出することにより、低リソースの設定でコード切り替え音声認識システムに転移学習を導入するための新しい学習手法であるメタ転移学習を提案します。実験結果に基づいて、モデルのパフォーマンスが向上します音声認識と言語モデリングのタスクに関する既存のベースラインであり、収束がより高速です。今日、世界ではますます多くの人々が多言語の結果として混合言語を話します。 
[要約]音声認識システムを使用して音声認識システムを構築できます。ただし、リソースが不足しているため、混合言語データを収集しようとするとコストがかかるため、困難です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Detecting Domain Polarity-Changes of Words in a Sentiment Lexicon -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_51.html">
      Detecting Domain Polarity-Changes of Words in a Sentiment Lexicon
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このような単語を検出し、アプリケーションドメインの感情を修正することは非常に重要です。このホワイトペーパーでは、この問題に取り組むためのグラフベースの手法を提案します。 
[ABSTRACT]感情レキシコンで提供される感情単語のセットと分類子を使用して、感情分類を実行できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Evaluating the Role of Language Typology in Transformer-Based
  Multilingual Text Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_52.html">
      Evaluating the Role of Language Typology in Transformer-Based
  Multilingual Text Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、この背景を使用して、8つの言語と8つのモデルでマルチクラスのテキスト分類を使用して行った実験の分析をサポートします。その結果、NLPツールは、異なる構文および形態構造を持つ言語間で不均等に実行されます。語順の類型、形態論の類型、および比較言語学の中で、どの変数が言語モデリングの有効性に最も影響を与えるかを特定します。さらに、経験的研究を支援するために、単語の順序と形態学的類似性インデックスを計算します。 
[ABSTRACT]言語調査は類型の違いには対応していません。言語モデルに最も影響を与える変数を特定します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ToTTo: A Controlled Table-To-Text Generation Dataset -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_53.html">
      ToTTo: A Controlled Table-To-Text Generation Dataset
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      通常は流暢ですが、既存の方法は表でサポートされていないフレーズを幻覚化することがよくあります。このデータセットは、高精度のコンディショナルテキスト生成の有用な研究ベンチマークとして役立つ可能性があることを示唆しています。データセットと注釈プロセスの体系的な分析と、いくつかの最先端のベースラインによって達成された結果.. ToTTo、120,000を超えるトレーニング例を含むオープンドメインの英語のテーブルからテキストへのデータセットであるWikipediaのテーブルと強調表示されたセット表のセル。1文の説明を作成します。 
[要旨]アノテーターが既存のウィキペディアの文章を直接修正するデータセット構築プロセスを紹介します。既存の方法では、表でサポートされていないフレーズが幻覚になることがよくあります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving BERT with Self-Supervised Attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_54.html">
      Improving BERT with Self-Supervised Attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、SSAは前の反復から微調整されたモデルを「プローブ」することにより、弱いトークンレベルの注意ラベルを自動的に繰り返し生成します。SSAをBERTに統合する2つの異なる方法を調査し、それらの利点を組み合わせるハイブリッドアプローチを提案します。経験的に、さまざまなパブリックデータセットについて、SSA拡張BERTモデルを使用してパフォーマンスが大幅に向上することを示します。 
[ABSTRACT]微調整されたパフォーマンスモデルは、多くの場合、拡張データセットにオーバーフィットします。ただし、微調整されたパフォーマンスはしばしばオーバーフィットするため、課題が1つ残っています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Task-oriented Dialogue System for Automatic Disease Diagnosis via
  Hierarchical Reinforcement Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_55.html">
      Task-oriented Dialogue System for Automatic Disease Diagnosis via
  Hierarchical Reinforcement Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      高レベルのポリシーは、低レベルでのモデルのトリガーを担当するマスターという名前のモデルで構成され、低レベルのポリシーは、いくつかの症状チェッカーと疾患分類子で構成されます。この論文では、強化学習による自動疾患診断に焦点を当てます（ RL）タスク指向のダイアログ設定のメソッド..また、データセット（http://www.sdspeople.fudan.edu.cn/zywei/data/Fudan-Medical-Dialogue2.0）とコード（https：// github .com / nnbay / MeicalChatbot-HRL）はすべて利用できます。 
[ABSTRACT]病気の診断のためのアクションスペースはしばしば大きいですが、多くの懸念があります。これらには、病気の数を増やすことを目的とする「変性システム」が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning Non-Monotonic Automatic Post-Editing of Translations from Human
  Orderings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_56.html">
      Learning Non-Monotonic Automatic Post-Editing of Translations from Human
  Orderings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人間はほぼ左から右の順序に従う傾向があることを観察しますが、句読点や動詞を修正することから始めることを好むなど、興味深い偏差があります。このペーパーでは、人間のポストエディターによって生成された順序を分析して使用自動ポストエディットシステムをトレーニングするには..また、これらの自動順序付けは、人間の翻訳者の実際の動作とどのように比較されますか？ 
[ABSTRACT]現在のモデルは手動で作成したバイアスに依存しているか、自分ですべての可能性を探求することを任されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Conditional Neural Generation using Sub-Aspect Functions for Extractive
  News Summarization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_57.html">
      Conditional Neural Generation using Sub-Aspect Functions for Extractive
  News Summarization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最小の位置バイアスを使用して自動的に抽出された要約が、位置バイアスを利用する標準モデルと少なくとも同等のパフォーマンスを実現できることを示します。大規模なトレーニングコーパスを使用したニューラルアーキテクチャによって、テキストの要約が大幅に進歩しました。多様性に焦点を当てて作成されたニュースの要約は、人間の評価者がより好む可能性があることを示しています。 
[要約]多様性に焦点を当てて生成されたニュースの要約は、人間の評価者がより好む可能性があることも示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Data Augmentation for Spoken Language Understanding via Pretrained
  Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_58.html">
      Data Augmentation for Spoken Language Understanding via Pretrained
  Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、SLUのデータ不足の以前に見過ごされていた2つのシナリオに対する解決策を調査して提案します。 ii）発話が豊富：ラベルなしの発話が多数利用可能です。経験的結果は、この方法が、さまざまなシナリオでの言語理解モデルのパフォーマンスを向上させる合成トレーニングデータを生成できることを示しています。話し言葉理解のトレーニング（SLU ）モデルはしばしばデータ不足の問題に直面します。 
[ABSTRACT]生成された発話の精度を高めるために、事前トレーニング済みの言語モデルを使用したデータ拡張方法を提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Interpretable Multimodal Routing for Human Multimodal Language -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_59.html">
      Interpretable Multimodal Routing for Human Multimodal Language
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、ルーティング手順は、1）この概念がこの機能とどのように一致するかをチェックすることにより、機能と概念を繰り返し関連付けます。2）関連付けに基づいて概念を更新します。たとえば、モデルはテキストモダリティにほとんど依存していることがわかります。ニュートラルな感情予測、非常に否定的な予測の音響モダリティ、および非常に肯定的な予測のテキスト音響バイモーダル相互作用。私たちの方法の中心には、各予測を概念、つまりユークリッドのベクトルとして表すルーティングメカニズムがあります。スペース。 
[要約]この概念は、マルチモーダル機能の寄与からの線形集計を前提としています。これは、分析や感情予測を含む、2,000種類のデータの分析に基づいています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning Better Universal Representations from Pre-trained
  Contextualized Language Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_60.html">
      Learning Better Universal Representations from Pre-trained
  Contextualized Language Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      BERTなどの事前トレーニング済みの文脈化言語モデルは、幅広いダウンストリーム自然言語処理（NLP）タスクで優れた効果を示しています。この作業では、ユニバーサルな固定サイズの表現を生成できるBERTの新しいフレームワークを紹介します。大規模な自然言語推論と複数のトレーニング目標を持つ言い換えデータを使用して、任意の長さの入力シーケンス（つまり、単語、フレーズ、および文）に対して。私たちの提案するフレームワークは、シャムネットワークを採用し、自然言語推論から文レベルの表現を学習しますデータセット、言い換えデータセットからの句および単語レベルの表現。 
[ABSTRACT]細かい-調整されたステップには、一度に両方のシーケンスを入力する必要があるため、個々のシーケンスの表現が不十分になります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Basic Linguistic Resources and Baselines for Bhojpuri, Magahi and
  Maithili for Natural Language Processing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_61.html">
      Basic Linguistic Resources and Baselines for Bhojpuri, Magahi and
  Maithili for Natural Language Processing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      テキストはさまざまなドメインとジャンルに属します。インドのアーバン（またはインド）族に属するインドのプルバンチャル地域（北東部）の言語であるボージュプリ語、マガヒ語、およびマイティリ語は、リソースの少ない言語です。これらは、比較的リソースの多い言語であるヒンディー語と密接に関連しているため、ヒンディー語と比較します。 
[ABSTRACT]インドの広域地域の言語であるボージュプリー語、マガヒ語、およびマイシリ語は、インド系（またはインド系）族に属する低リソース言語です。これらの3つの言語のコーパスを収集し、可能な限りそれらをクリーンアップしました。それらのデータを変更せずに
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Empower Entity Set Expansion via Language Model Probing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_62.html">
      Empower Entity Set Expansion via Language Model Probing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      各反復で、事前トレーニング済みの言語モデルをプローブして1つのポジティブクラス名といくつかのネガティブクラス名を選択し、選択したクラス名に基づいて各候補エンティティにさらにスコアを付けます。この研究では、自動的に活用する新しい反復セット拡張フレームワークを提案します。セマンティックドリフトの問題に対処するために生成されたクラス名。2つのデータセットでの実験により、このフレームワークは高品質のクラス名を生成し、以前の最先端のメソッドよりも大幅に優れていることがわかりました。 
[要約]この調査では、自動生成されたクラス名を活用してセマンティックドリフトの問題に対処する新しいセット拡張フレームワークを提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: AMR Parsing via Graph-Sequence Iterative Inference -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_63.html">
      AMR Parsing via Graph-Sequence Iterative Inference
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちは反復推論に基づいてモデルを設計し、両方の観点でより良い答えを達成するのに役立ちます。これにより、解析精度が大幅に向上します。実験結果は、以前に報告されたすべての\ textsc {Smatch}スコアを大幅に上回っています。BERTの助けを借りて、 LDC2017T10（AMR 2.0）では最新の結果を80.2 \％に、LDC2014T12（AMR 1.0）では75.4 \％にプッシュできます。 
[ABSTRACT]私たちのモデルは、両方の観点でより良い答えを達成するのに役立つ反復結論に基づいています。これにより、解析精度が大幅に向上します。インクリメンタル言語モデルの助けなしで、私たちのモデルは以前の状態をすでに上回っています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-12">
        <br>2020-04-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: GePpeTto Carves Italian into a Language Model -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_64.html">
      GePpeTto Carves Italian into a Language Model
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人間の評価は、文の完了タスクに対して実行されます。GePpeTtoの出力は、自然と判断される頻度が高く、ベースラインとして使用する単純な言語モデルよりも元の人間のテキストに近いと判断されます。自動評価は、（i ）さまざまなジャンルの混乱を計算し、（ii）GePpeTtoの書き込み特性のプロファイリング分析を行います。GePpeTtoの生成は、人間の生成の一種の盆栽バージョンであり、短いながらも複雑なセンテンスです。 
[ABSTRACT] geppettoの生産は、人間の生産の一種の盆栽バージョンです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multiscale Collaborative Deep Models for Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_65.html">
      Multiscale Collaborative Deep Models for Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、当社のディープMSCは、最新のディープNMTモデルを大幅に上回るWMT14英語-ドイツ語タスクで30.56のBLEUスコアを達成しています。3つの翻訳方向を持つIWSLT翻訳タスクでは、非常に深いモデル（72-レイヤーエンコーダー）は強いベースラインを+ 2.2〜+ 3.1 BLEUポイント上回っています。MSCネットは最適化が容易であり、大幅に増加した深さから翻訳品質の改善が得られることを示す経験的証拠を提供します。 
[要旨]マルチスケールの協調的フレームワークを提示して、以前に使用されたものよりも大幅に深いモデルのトレーニングを容易にします。各モデルブロックにきめの細かい表現を学習させ、空間依存性をキャプチャすることでそれを強化します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Topic Propagation in Conversational Search -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_66.html">
      Topic Propagation in Conversational Search
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      会話のコンテキストでは、ユーザーは多面的な情報のニーズを一連の自然言語の質問、つまり発話として表現します。つまり、CAsTベースラインです。従来のIRメトリックの観点から評価されたアーキテクチャの包括的な実験的評価を以下に示します。小さなカットオフ。 
[ABSTRACT] 2019年のtrec会話型アシスタントトラックを採用して、モジュール式のアーキテクチャを実験します。人の発話とシステムの返信を識別するには、システムシステムシステムの変更が必要です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Politeness Transfer: A Tag and Generate Approach -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_67.html">
      Politeness Transfer: A Tag and Generate Approach
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、私たちのモデルは、文法の人間の評価に関する既存の方法を上回っています。つまり、6つのスタイル転送タスクすべてでの保存と転送の精度を意味します。データとコードはhttps://github.com/tag-and-generateにあります。これは紙は、意味を保存しながら非丁寧な文を丁寧な文に変換することを含む、丁寧な伝達の新しいタスクを紹介します。 
[要約]また、1つ以上のインスタンスのデータセットを提供しています。39のインスタンスには、丁寧さのラベルが自動的に付けられています。データとコードはwwwにあります。 github。 com / tag-および-生成
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ConveRT: Efficient and Accurate Conversational Representations from
  Transformers -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_68.html">
      ConveRT: Efficient and Accurate Conversational Representations from
  Transformers
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      BERTなどの汎用の事前トレーニング済み文エンコーダーは、実際の会話型AIアプリケーションには理想的ではありません。それらは、計算量が多く、低速で、トレーニングにコストがかかります。ConveRTは、広く確立されている応答選択タスク全体で最先端のパフォーマンスを実現することを示しています。また、コンテキストとして拡張ダイアログ履歴を使用すると、パフォーマンスがさらに向上することも示しています。 。 
[ABSTRACT]変換（トランスフォーマーからの会話表現）を提案します。これは、事前トレーニングフレームワークです。効果的で、手頃な価格で、すばやくトレーニングできます。developers.convertは、3つのデータセットで強力な結果を提供します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-09">
        <br>2019-11-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Benchmarking Robustness of Machine Reading Comprehension Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_69.html">
      Benchmarking Robustness of Machine Reading Comprehension Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのベンチマークは既存のRACEベンチマークに基づいて自動的に構築されるため、構築パイプラインは他のタスクやデータセットで簡単に採用できます。今後の作業を容易にするためにデータとソースコードをリリースします。 MRCおよびその他のNLUモデルの堅牢性の向上に関する研究。 
[ABSTRACT]新しいモデルはさまざまなmrcベンチマークで評価されています。これらは既存のレースベンチマークに基づいており、他のタスクやデータセットで簡単に採用できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Beyond Instructional Videos: Probing for More Diverse Visual-Textual
  Grounding on YouTube -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_70.html">
      Beyond Instructional Videos: Probing for More Diverse Visual-Textual
  Grounding on YouTube
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      そして、もしそうなら、どのタイプのビデオが「接地」され、どのタイプがそうでないのですか？ラベルなしのWebビデオからの事前トレーニングは、多くのビデオ理解タスクで高いパフォーマンスを達成するための事実上の手段になりました。しかし、事前の事前トレーニング作業は、演習用ビデオ、つまりアプリオリに比較的期待されるドメインのみに制限されています。簡単：」教育用ビデオのスピーカーは、描かれている文字通りのオブジェクト/アクションを参照することがよくあります。 
[ABSTRACT]より多様なセットで事前トレーニングを行うと、非教育ドメインと教育ドメインの両方に一般化される表現になります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Utterance Pair Scoring for Noisy Dialogue Data Filtering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_71.html">
      Utterance Pair Scoring for Noisy Dialogue Data Filtering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、（i）提案された関数による自動スコアリングと人間の評価の相関関係、および（ii）フィルタリングされたデータでトレーニングされた対話応答ジェネレーターのパフォーマンスを確認することにより、スコアリング関数の有効性を示します。この作業では、低品質の発話を識別するように特別に設計されたスコアリング関数-ノイズの多いトレーニングデータをフィルターする応答ペア。さらに、私たちはスコアリング関数が言語に依存しない方法として機能する可能性があることを実験的に確認しました。 
[要約]私たちの採点関数は、対話ペアとその内容-関連性における相互接続の自然さをモデル化しています。人間のテストコミュニティは、特にノイズの少ない十分に大きなデータの欠如に悩まされています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Parsing All: Syntax and Semantics, Dependencies and Spans -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_72.html">
      Parsing All: Syntax and Semantics, Dependencies and Spans
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      構文構造と意味構造の両方が重要な言語的文脈上の手がかりであり、後者の解析は前者の解析から有益であることがよく示されています。実験は、意味論と構文が共同の目的を最適化することによって互いに利益をもたらすことを示しています。 Propbankベンチマークでのスパンと依存関係の両方のセマンティック解析、およびPenn Treebankでの依存関係と構成要素の構文解析の両方での、最新または競合の結果。 
[ABSTRACT]セマンティック解析を使用して構文解析を支援することができます。しかし、多くの研究がセマンティック解析を支援する試みをしました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-30">
        <br>2019-08-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploring Fine-tuning Techniques for Pre-trained Cross-lingual Models
  via Continual Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_73.html">
      Exploring Fine-tuning Techniques for Pre-trained Cross-lingual Models
  via Continual Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、私たちの方法は、ゼロショットのクロスリンガルの品詞タグ付けおよび名前付きエンティティ認識タスクで他の微調整ベースラインよりも優れたパフォーマンスを実現します。この問題を緩和するために、継続的な学習のアイデアを活用して、元のダウントレーニングされたクロスリンガルタスクに微調整するときの事前トレーニング済みモデルのクロスリンガル機能..最近、ダウンストリームのクロスリンガルタスクに事前トレーニング済みのクロスリンガルモデル（たとえば、多言語BERT）を微調整することが示されています有望な結果。 
[ABSTRACT]微調整されたプロセスにより、事前トレーニング済みモデルのパラメーターが変更されます。これにより、クロスリンガル能力が弱まり、最適以下のパフォーマンスにつながる可能性があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Dynamic Fusion Network for Multi-Domain End-to-end Task-Oriented Dialog -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_74.html">
      Dynamic Fusion Network for Multi-Domain End-to-end Task-Oriented Dialog
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は、私たちのモデルがマルチドメインダイアログの既存の方法よりも優れていることを示しており、最先端の文献を提供します。さらに、自動的に関連性を利用する新しいダイナミックフュージョンネットワーク（DF-Net）を提案します。ターゲットドメインと各ドメイン。このために、ドメインの知識を明示的に利用できる方法を調査し、共有プライベートネットワークを導入して、共有された特定の知識を学習します。 
[ABSTRACT]ほとんどのニューラルモデルは、ナビゲーションやスケジューリングなど、特定の数のタスクドメインでのみ利用できる大量のトレーニングデータに依存しています。ただし、すべてのドメインのデータを効果的に使用してパフォーマンスを向上させる方法に関する研究はほとんどありません各ドメインの
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-23">
        <br>2020-04-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Detecting Perceived Emotions in Hurricane Disasters -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_75.html">
      Detecting Perceived Emotions in Hurricane Disasters
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちは、きめの細かい感情の包括的な研究を提示し、きめの粗い感情グループを区別するための分類タスクを提案します。人々は最近、ソーシャルメディアのWebサイト（Twitterなど）にアクセスして、感情や感情をより大きなコミュニティと共有しています。最高のBERTモデルは、ラベルなしのTwitterデータを利用するタスクガイド付き事前トレーニングの後でも、68％の精度しか達成しません（すべてのグループで平均）。 
[要約] hurricaneemoは、15,000の英語のツイートの感情データセットです。3つのハリケーン（harvey、irma、およびmaria）にまたがるツイートが含まれています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: UDapter: Language Adaptation for Truly Universal Dependency Parsing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_76.html">
      UDapter: Language Adaptation for Truly Universal Dependency Parsing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの詳細な分析は、類型学的機能を介したソフトパラメータ共有がこの成功の鍵であることを示しています。これらの問題に対処するために、パラメータ効率の高い転移学習における最近の研究に基づいた、新しい多言語タスク適応アプローチを提案します。既存の言語タイポロジー機能を構文解析ネットワークに効果的に統合すること。ただし、言語間の干渉とモデル容量の抑制は、この追求の大きな障害となっています。 
[ABSTRACT]これは、多言語ud解析における最先端の技術です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Automatically Identifying Gender Issues in Machine Translation using
  Perturbations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/cs.CL/paper_77.html">
      Automatically Identifying Gender Issues in Machine Translation using
  Perturbations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ベンチマークの例では、モデルで性別を表現する方法と、これらの性別表現が下流のアプリケーションに及ぼす可能性のある予期しない結果を明らかにしています。以前の研究で、手作業でキュレートされた合成例を使用して問題を特定した場合、活用する新しい手法を開発します展開されたシステムの課題を調査するための現実世界のデータ。これらの改善により、多くの人が、性別を定めた言語のモデリングと処理を含む、顕著な課題に気づきました。 
[ABSTRACT]新しい方法を使用して評価ベンチマークをコンパイルします。3つの言語ファミリの4つの言語に関連する例が含まれています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Seeing voices and hearing voices: learning discriminative embeddings
  using cross-modal self-supervision -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/eess.AS/paper_0.html">
      Seeing voices and hearing voices: learning discriminative embeddings
  using cross-modal self-supervision
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この方法の有効性は、2つの下流タスクで実証されます。オーディオビジュアル同期でトレーニングされた機能を使用した読唇、およびクロスモーダルバイオメトリックマッチング用にトレーニングされた機能を使用した話者認識です。有意義なマージンによる自己監視ベースライン。私たちは以前の作業に基づいて、ユニモーダルダウンストリームタスクにより特徴的な埋め込みをトレーニングします。 
[要約]提案された方法を使用して、最先端の自己監視ベースラインを重要なマージンで識別することができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Determined BSS based on time-frequency masking and its application to
  harmonic vector analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/eess.AS/paper_1.html">
      Determined BSS based on time-frequency masking and its application to
  harmonic vector analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、ケプストラムのスパース性を介してオーディオ信号の調和構造をモデル化することにより、調和ベクトル分析（HVA）と呼ばれる決定されたBSS法を提案します。マイクの数がソース信号の数と等しい場合（決定された状況） 、オーディオブラインドソース分離（BSS）は通常、複雑なミキシングプロセスに対処するためにマルチチャネル線形フィルタリングによって実行されます。HVAを処理するために、決定されたBSSのモデリング問題を時間周波数マスクの設計問題に再キャストする一般的なアルゴリズムフレームワークも提案されています。 
[要約]決定されたbss問題は、「独立した低ランクのマトリックス分析」に基づいています。これらには、これらのタイプの音声と音楽が含まれます。この方法は成功裏に開発されました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Speech Decomposition via Triple Information Bottleneck -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/eess.AS/paper_2.html">
      Unsupervised Speech Decomposition via Triple Information Bottleneck
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      残りの音声コンポーネントをさらに解きほぐすことは、各コンポーネントに明示的な注釈がない場合、十分に決定されない問題であり、取得するのは困難でコストがかかります。音声情報は、言語コンテンツ、音色、ピッチ、リズムの4つのコンポーネントに大まかに分解できます。 ..この論文では、注意深く設計された3つの情報ボトルネックを導入することにより、音声を盲目的に4つのコンポーネントに分解できるSpeechSplitを提案します。 
[ABSTRACT]スピーチスプリットは、スピーチを4つのコンポーネントに分解できます。これらのシステムは、音色をほぐすことができるだけですが、ピッチ、リズム、内容に関する情報は依然依存しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-23">
        <br>2020-04-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Meta-Transfer Learning for Code-Switched Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/eess.AS/paper_3.html">
      Meta-Transfer Learning for Code-Switched Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      したがって、新しい学習方法であるメタ転送学習を提案します。メタ転送学習は、高リソースの単一言語データセットから情報を慎重に抽出することにより、低リソースの設定でコード交換音声認識システムに学習を転送します。モデルは、個々の言語を認識することを学習し、コード交換データに基づいて最適化を調整することにより、混合言語の音声をよりよく認識できるようにそれらを転送します。今日、世界中でますます多くの人々が多言語の結果として混合言語を話します。 
[要約]音声認識システムを使用して音声認識システムを構築できます。ただし、リソースが不足しているため、混合言語データを収集しようとするとコストがかかるため、困難です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: VGGSound: A Large-scale Audio-Visual Dataset -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/eess.AS/paper_4.html">
      VGGSound: A Large-scale Audio-Visual Dataset
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      第3に、さまざまな畳み込みニューラルネットワーク（CNN）アーキテクチャと集約手法を調査して、新しいデータセットの音声認識ベースラインを確立します。私たちの目標は、野生のビデオから低ラベルノイズの大規模なオーディオビジュアルデータセットを収集することです。コンピュータビジョンテクニック..私たちのパイプラインはYouTubeからビデオを取得することを含みます。画像分類アルゴリズムを使用して視聴覚対応をローカライズします。オーディオ検証を使用して周囲のノイズを除去します。 
[要旨] vggsoundデータセットは、310のオーディオクラスに対して210k以上の動画で構成されています。データセットは制約のない条件下で収集されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Bitter Melon (Momordica Charantia) Supplementation Has no Effect on Hypercholesterolemia and Atherosclerosis in Mice -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/biorxiv.physiology/paper_0.html">
      Bitter Melon (Momordica Charantia) Supplementation Has no Effect on Hypercholesterolemia and Atherosclerosis in Mice
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      グループ1では、マウスにこの食餌のみを与え、グループ2および3のマウスには、それぞれ0.1％または1％wt / wtのM. Charantiaを補足した食餌を12週間与えました。一般的に知られているMomordica Charantia苦いメロンとして、食事誘発性の肥満と脂質異常症を改善することが報告されています。体重の有意差はグループ間で観察されませんでした。 
[要約] mの影響。アテローム性動脈硬化症に対するカランティアは決定されていません。アテローム性動脈硬化症のofiaは見つかりませんでした
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neutrophil to Lymphocyte Ratio (NLR) in captive chimpanzees (Pan troglodytes): The effects of sex, age, and rearing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/biorxiv.physiology/paper_1.html">
      Neutrophil to Lymphocyte Ratio (NLR) in captive chimpanzees (Pan troglodytes): The effects of sex, age, and rearing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、これらの関係の複雑さを考えると、チンパンジーで使用するための診断健康ツールとしてのNLRの有用性を判断するには、より多くの研究が必要です。最後に、男性とより高いNLR値を持つ男性は、若い年齢で死亡しました。これらの調査結果は、 NLRはチンパンジーの寿命の予測因子として使用できます。 
[要約]調査では、2つの飼育下のチンパンジー個体群における443匹のチンパンジーの健康記録の変化が調査されました。これらのデータを使用すると、nlr値はチンパンジー内の10年の期間にわたって変化しませんでした
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The hepatic compensatory response to elevated systemic sulfide impairs medium chain fat oxidation and promotes diabetes -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-30/biorxiv.physiology/paper_2.html">
      The hepatic compensatory response to elevated systemic sulfide impairs medium chain fat oxidation and promotes diabetes
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結論として、私たちの調査結果は、肝機能と代謝性疾患のコンテキストでの硫化物ドナー戦略に影響を与えます。硫化物酸化経路（SOP）による硫化物の処分は、安全な生理学的範囲内で硫化物を維持するために重要です。予期せず、肝臓の硫化物レベルはTst koマウスでは正常。ミトコンドリアの硫化物処理の恒常性誘導と、タンパク質の過硫化と核呼吸因子2標的タンパク質の正味の抑制に関連するグルタチオン排泄の結果。 
[要約]肝臓に富むミトコンドリアsop酵素チオ硫酸硫黄トランスフェラーゼは、高循環硫化物、増加した糖新生、高トリグリセリド血症および脂肪肝を示す
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
