<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<title>Akari-19-10-20の記事</title>
<link rel='stylesheet' type='text/css' href='../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../css/field.css'>
<link rel='stylesheet' type='text/css' href='../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
  <div class="header-logo">
    <a href="../index.html"><img src="../images/akari.png" width="100" height="100"></a>
  </div>
</header>
<input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">

<div class="menubar">
<span class="bar"></span>
<span class="bar"></span>
<span class="bar"></span>
</div>

<ul>
<li><a id="home" href="../index.html">Home</a></li>
<li><a id="about" href="../teamAkariとは.html">About</a></li>
<li><a id="contact" href="../contact.html">Contact</a></li>
<li><a id="contact" href="../list/newest.html">New Papers</a></li>
<li><a id="contact" href="../list/back_number.html">Back Numbers</a></li>
</ul>

</label>
<!--
	fields
	-->
<div class="topnav">
<!-- field: biorxiv-physiology -->
  <li class="hidden_box">
    <label for="label0">
biorxiv-physiology
  </label></li>
<!-- field: cs-CL -->
  <li class="hidden_box">
    <label for="label1">
cs-CL
  </label></li>
<!-- field: cs-SD -->
  <li class="hidden_box">
    <label for="label2">
cs-SD
  </label></li>
<!-- field: eess-AS -->
  <li class="hidden_box">
    <label for="label3">
eess-AS
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: A Search-based Neural Model for Biomedical Nested and Overlapping Event
  Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_0.html">
      A Search-based Neural Model for Biomedical Nested and Overlapping Event
  Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このモデルは、構文および手動の機能を使用せずに、BioNLP Cancer Genetics（CG）Shared Task 2013の最新モデルTurkuイベント抽出システム（TEES）に匹敵するパフォーマンスを達成することを示しています。依存関係解析などの既存の構造化予測タスク、リレーショングラフからイベントを構成するDAG構造を検出するタスクターゲット。開発セットのさらなる分析は、より高いF1スコアパフォーマンスをもたらす一方で、モデルの計算効率が高いことを示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-22">
        <br>2019-10-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Controlling the Output Length of Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_1.html">
      Controlling the Output Length of Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      トランスフォーマーアーキテクチャで出力長にバイアスをかける2つの方法を調査します。i）出力を特定のターゲットソース長さ比率クラスに調整し、ii）長さ情報でトランスフォーマーの位置埋め込みを強化します。 、字幕、およびダビング用のスクリプト。出力の長さは、入力テキストの長さにできるだけ近いことが理想的です。特に、翻訳が特定のレイアウトに適合しなければならない場合、品質は適切さだけで測定されるべきではありません流さだけでなく、長さ。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-23">
        <br>2019-10-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Predicting In-game Actions From the Language of NBA Players -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_2.html">
      Predicting In-game Actions From the Language of NBA Players
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちは、オープンエンドインタビューの言語信号のますます複雑な側面に基づいて、プレーヤーの行動予測のためのニューラルモデルを設計します。合計5,226のインタビューメトリックペアで構成されています。さらに、テキスト入力と過去のパフォーマンスメトリックの両方を使用するモデルが最良の結果をもたらしました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Detecting gender differences in perception of emotion in crowdsourced
  data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_3.html">
      Detecting gender differences in perception of emotion in crowdsourced
  data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      全体として、この論文の貢献は2つあります。クラウドソーシングデータからの知覚的研究のための信頼できる新しいフレームワーク。そして、性別間の音声ベースの感情知覚における統計的に有意な違いの実証。しかし、経験的調査結果は決定的なままである。さらに、ほとんどすべての研究は、制御された環境内の実験に限定されている。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Comparison of Quality Indicators in User-generated Content Using Social
  Media and Scholarly Text -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_4.html">
      Comparison of Quality Indicators in User-generated Content Using Social
  Media and Scholarly Text
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、ツイートなどのソーシャルユーザー生成データと学術論文などの学術ユーザー生成データの両方でメソッドを比較し、これらの異なるドメイン全体で同じ機能が品質の予測に異なる影響を与えることを示します。テキストドキュメントは、リリース前にドキュメントのパフォーマンスを測定する問題が発生した場合に重要なタスクです。この作業では、テキストコンテンツ（テキスト）から抽出された機能や、テキストから直接利用できないテキスト（メタ）機能、およびこれらの機能がさまざまな方法でドキュメント品質の予測を通知する方法を示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-Document Summarization with Determinantal Point Processes and
  Contextualized Representations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_5.html">
      Multi-Document Summarization with Determinantal Point Processes and
  Contextualized Representations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      決定的ポイントプロセスは、抽出的要約のための最高のパフォーマンステクニックの1つとして出現し、文のプロミネンスとペアの反発のモデリングによって定義された確率尺度に従って、最も可能性の高い文のセットを選択して要約を形成します。従来、これらの側面は、浅くて言語学的な情報に基づいた機能を使用してモデル化されていましたが、コンテキスト化された深い表現の台頭は、興味深いのかどうか、そして何に程度に応じて、コンテキスト化された表現を使用してDPPモデリングを改善できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Capacity, Bandwidth, and Compositionality in Emergent Language Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_6.html">
      Capacity, Bandwidth, and Compositionality in Emergent Language Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、学習した言語を分析するための一連の評価指標を紹介します。経験的にこの範囲の下限の証拠を確認していますが、範囲の上部の証拠を見つけられず、これは未解決の問題であると考えていますコミュニティのために..文学のお気に入りは、構成性を学ぶことです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An Empirical Study of Efficient ASR Rescoring with Transformers -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_7.html">
      An Empirical Study of Efficient ASR Rescoring with Transformers
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      特に、ビデオ音声認識データセットでの実験では、よく知られている大規模GPTモデル[1]の5.5％から11.9％のパラメーターサイズでのみ6.46％から7.17％の範囲のWERRを達成できることが示されています。同じデータセットでの再スコアリングは7.58％です。したがって、比較的小さなモデルサイズのトランスフォーマーLMを開発する一方で、これらのはるかに大きなモデルの良好なパフォーマンスを維持することは重要です。 ASR再スコアリングのコンテキストで小さなパラメータサイズのトランスフォーマーをトレーニングする。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Survey on Recent Advances in Named Entity Recognition from Deep
  Learning models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_8.html">
      A Survey on Recent Advances in Named Entity Recognition from Deep
  Learning models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      NERシステムは数十年にわたって広く研究開発されてきましたが、ディープニューラルネットワーク（NN）を使用した正確なシステムはここ数年で紹介されました。.NERのディープニューラルネットワークアーキテクチャの包括的な調査を提示し、以前と比較します機能エンジニアリングおよびその他の教師付きまたは半教師付き学習アルゴリズムに基づくNERへのアプローチ。名前付きエンティティ認識（NER）は、質問応答、情報検索、関係抽出などのためのNLPシステムの重要なコンポーネントです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Machine Translation from Natural Language to Code using Long-Short Term
  Memory -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_9.html">
      Machine Translation from Natural Language to Code using Long-Short Term
  Memory
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人間とコンピューターの言語の障壁を取り除くこの旅をさらに一歩進めるために、このペーパーでは、リカレントニューラルネットワーク（RNN）とLong-Short Term Memory（LSTM）を使用して人間の言語をプログラミング言語コードに変換する機械学習アプローチを提案します。プログラマーは素人の言語でコードの式を記述し、機械学習モデルはそれをターゲットのプログラミング言語に翻訳します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: QASC: A Dataset for Question Answering via Sentence Composition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_10.html">
      QASC: A Dataset for Question Answering via Sentence Composition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、推論モデルは、常識的な推論を使用して、これらの検索された事実の有効な構成を識別することを学習する必要があります。複数のテキストから知識を構成することは、マルチホップ質問応答の重要な課題です。QASCは、望ましい特性：（a）構成するファクトには大きなコーパスで注釈が付けられ、（b）これらのファクトへの分解は質問自体からは明らかではありません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Unified MRC Framework for Named Entity Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_11.html">
      A Unified MRC Framework for Named Entity Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      たとえば、\ textsc {per}ラベルを持つエンティティの抽出は、「{\ it which person is言及されているテキスト？}」という質問に対する回答範囲を抽出するものとして形式化されます。フラットNERで最も広く使用されるバックボーンであるラベリングモデルは、単一のラベルを特定のトークンにのみ割り当てることができます。これは、トークンに複数のラベルを割り当てるネストされたNERには適していません。フラットおよびネストされたNERタスクの両方を処理できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Generating a Common Question from Multiple Documents using Multi-source
  Encoder-Decoder Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_12.html">
      Generating a Common Question from Multiple Documents using Multi-source
  Encoder-Decoder Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最初に、（単一ドキュメント、質問）ペアからRNNベースの単一エンコーダー/デコーダージェネレーターをトレーニングします。テスト時に、複数のドキュメントが与えられた場合、MSQGモデルの &#39;Distribute&#39;ステップは、トレーニング済みモデルを使用して各ドキュメントのターゲットワード分布を予測します..「集計」ステップは、これらの分布を集計して共通の質問を生成します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Attention Optimization for Abstractive Document Summarization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_13.html">
      Attention Optimization for Abstractive Document Summarization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      注意は、シーケンスベースのドキュメント要約モデルの改善に重要な役割を果たします。CNN/ Daily Mailデータセットのパフォーマンスは、私たちの方法の有効性を検証します。繰り返しを避けて、ローカルとグローバルの両方の側面からバニラアテンションモデルを強化します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The SIGMORPHON 2019 Shared Task: Morphological Analysis in Context and
  Cross-Lingual Transfer for Inflection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_14.html">
      The SIGMORPHON 2019 Shared Task: Morphological Analysis in Context and
  Cross-Lingual Transfer for Inflection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      今年は、文脈における見出し語化と形態学的特徴分析に関する新たな第2の課題も提示します。参加チームはすべて、変曲課題のベースラインよりも精度が向上しました（ただし、レーベンシュタイン距離ではありません）。最先端の神経および非神経ベースライン。すべての提出物は、神経成分を特徴としており、今年の強力なベースラインまたは前年度の共有タスクからの高ランクのシステムのいずれかに基づいて構築されました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: L2RS: A Learning-to-Rescore Mechanism for Automatic Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_15.html">
      L2RS: A Learning-to-Rescore Mechanism for Automatic Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      公開データセットに基づいて広範な実験を実施し、実験結果は、L2RSが従来のリスコアリング方法だけでなく、NDCG @ 10に関して20.67％の大幅な改善により、その深層ニューラルネットワーク対応物よりも優れていることを示しています。 ASRのより効果的なリスコアリングモデル。このペーパーでは、最新のNLPモデルからの幅広いテキスト情報を自動的に利用することに特化した、新しいLearning-to-Rescore（L2RS）メカニズムを提案します。 ASRシステムのN-bestリストを再評価するために重みを決定します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Stem-driven Language Models for Morphologically Rich Languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_16.html">
      Stem-driven Language Models for Morphologically Rich Languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、各単語の基になるステムを認識するLMを提案します。マルチタスク学習と単語とステムの混合モデルを含むさまざまなアーキテクチャで実験を行います。ニューラル言語モデル（LM）は、特に形態学的に豊富な言語の場合、サブワードレベルの情報で単語ベクトルを強化する
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SpeechBERT: Cross-Modal Pre-trained Language Model for End-to-end Spoken
  Question Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_17.html">
      SpeechBERT: Cross-Modal Pre-trained Language Model for End-to-end Spoken
  Question Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      事前学習済み言語モデルのこの利点を音声による質問応答に取り入れるために、クロスモーダルトランスベースの事前学習済み言語モデルであるSpeechBERTを提案します。エンドツーエンドSQAモデルの最初の調査として、結果はASRからの出力テキストを入力し、事前学習済みの言語モデルにわずかに遅れていた従来のアプローチのパフォーマンス。エンドツーエンドのSQAモデルの可能性を示しています。最近、音声認識エラーによって壊滅的な影響を受ける音声による質問応答（SQA）タスクのエンドツーエンドモデルはまだありません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Meta-Learning with Dynamic-Memory-Based Prototypical Network for
  Few-Shot Event Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_18.html">
      Meta-Learning with Dynamic-Memory-Based Prototypical Network for
  Few-Shot Event Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、限られたラベル付きデータでEDタスクを数ショット学習問題として検討し、再定式化します。実験は、DMB-PNが一連のベースラインモデルよりもサンプル不足をうまく処理するだけでなく、イベントタイプの多様性は比較的大きく、インスタンスの量は非常に少ない。ダイナミックメモリネットワーク（DMN）を活用して、イベントタイプのより良いプロトタイプを学習するだけでなく、ダイナミックメモリベースのプロトタイプネットワーク（DMB-PN）を提案する、ただしイベントの言及に対してより堅牢な文エンコーディングを生成します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Diarization Robustness using Diversification, Randomization
  and the DOVER Algorithm -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_19.html">
      Improving Diarization Robustness using Diversification, Randomization
  and the DOVER Algorithm
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのハイパーパラメーターの最適化は困難で、多くの場合異なるデータセット全体で堅牢ではありません。また、クラスタリングの過程で異なるマージの選択を疑似ランダムに追跡することにより得られる多様な出力の組み合わせを調査し、それによりベストファーストクラスタリングの貪欲さを軽減します。音響類似性による音声セグメントのボトムアップクラスタリングに基づくダイアライゼーションは、多くの場合、クラスターの初期数や特徴の重みなどのハイパーパラメーターの選択に非常に敏感です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploring Multilingual Syntactic Sentence Representations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_20.html">
      Exploring Multilingual Syntactic Sentence Representations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの結果は、最新の言語モデルよりも少ないトレーニングデータ、少ないモデルパラメーターを使用して、構文文の埋め込みを学習できることを示しています。その結果、評価指標が向上しました。また、汎用品詞タグによって拡張された多言語並列コーパスを使用します。また、低リソース言語の構文文埋め込みを学習し、転移学習の強力な証拠を実証する方法の能力を評価します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: DENS: A Dataset for Multi-class Emotion Analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_21.html">
      DENS: A Dataset for Multi-class Emotion Analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は、データセットが既存の文レベルのテクニックを超えた移動を必要とする感情分析の新しい機会を提供することを示しています。多くの統計とベースラインベンチマークがデータセットに提供されています。テストされたテクニックのうち、微調整事前トレーニング済みBERTモデルの平均マイクロF1スコアは60.4％で、最良の結果が得られます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Measuring Conversational Fluidity in Automated Dialogue Agents -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_22.html">
      Measuring Conversational Fluidity in Automated Dialogue Agents
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの実験は、結果が流動性を測定するための既存のメトリクスの改善であることを示しています。会話型対話システムの流動性を測定する自動評価方法を提示します..この方法は、最先端の自然言語ツールを分類器に統合し、人間の評価を行います自動化された判断モデルを訓練するためのこれらの対話について。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Evaluation of Sentence Representations in Polish -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_23.html">
      Evaluation of Sentence Representations in Polish
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      特定のアプローチの長所と短所を示す、従来の単語埋め込みモデル、最近開発されたコンテキスト埋め込みと多言語文エンコーダを検討します。この研究では、文埋め込みを評価するための2つの新しいポーランドデータセットを紹介し、8つの文表現方法の包括的な評価を提供します。ポーランド語および多言語モデル..また、単語ベクトルを単一の文ベクトルに集約するさまざまな方法を検討します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On the Cross-lingual Transferability of Monolingual Representations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_24.html">
      On the Cross-lingual Transferability of Monolingual Representations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このアプローチは、共有の語彙や共同トレーニングに依存しません。ただし、標準のクロスリンガル分類ベンチマークおよび新しいクロスリンガル質問応答データセット（XQuAD）で多言語BERTと競合することを示しています。多言語モデルの一般化能力の基礎に関する共通の信念であり、深い単一言語モデルは、言語間で一般化するいくつかの抽象化を学習することを示唆しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On Automating Conversations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_25.html">
      On Automating Conversations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このポジションペーパーでは、ChorusとEvorusの開発および展開中に調査した2つの課題について説明します。「エージェント」であることに起因する課題と、自動化が困難な会話のサブセットに起因する課題です。 2年間の展開で、420人以上のユーザーがChorusと話し、2,200を超える会話セッションを行いました。2016年から2018年にかけて、リアルタイムの人間の計算と人工知能（AI）を組み合わせたシステムChorusを開発および展開しました。世界、ユーザーとのオープンな会話。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-21">
        <br>2019-10-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Review of the End-to-End Methodologies for Clinical Concept Extraction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_26.html">
      A Review of the End-to-End Methodologies for Clinical Concept Extraction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本研究では、2009年1月から2019年6月までの概念抽出に関する文献のレビューを行いました。概念抽出方法論の開発プロセスの体系的な要約は、臨床概念の抽出。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Fast and Accurate Knowledge-Aware Document Representation Enhancement
  for News Recommendations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_27.html">
      Fast and Accurate Knowledge-Aware Document Representation Enhancement
  for News Recommendations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      より良いニュース推薦サービスのためにこれらのエンティティを完全に活用する方法は重要です。コンテキスト埋め込みレイヤーは、頻度、カテゴリ、位置などのさまざまなエンティティの動的コンテキストを区別するように設計されています。ただし、これはニュース推薦の状況ではありません、ここで、アイテム、つまりニュース記事は、実際には知識エンティティのコレクションに関連しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Extending Event Detection to New Types with Learning from Keywords -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_28.html">
      Extending Event Detection to New Types with Learning from Keywords
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ドキュメント内のコンテキストに一致するようにいくつかのキーワードを介してタイプを記述するイベント検出の新しい定式化を研究します。新しい定式化におけるイベント検出のための畳み込みニューラルネットワークの注意メカニズム。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Fast Structured Decoding for Sequence Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_29.html">
      Fast Structured Decoding for Sequence Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      特に、WMT14 En-Deデータセットの場合、モデルは26.80のBLEUスコアを取得します。これは、以前の非自己回帰ベースラインを大幅に上回り、純粋な自己回帰モデルよりもBLEUが0.61だけ低くなっています。文が一貫していないため、学習した非自己回帰モデルは、自己回帰の対応するモデルに比べて精度が低くなります。自己回帰シーケンスモデルは、機械翻訳などの分野で最先端のパフォーマンスを実現します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The emotions that we perceive in music: the influence of language and
  lyrics comprehension on agreement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_30.html">
      The emotions that we perceive in music: the influence of language and
  lyrics comprehension on agreement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      個人的な特徴には、リスナーの一般的な人口統計、フラグメントの親しみやすさと好み、および音楽の洗練度が含まれます。2 ..個人の特徴は、特定の言語のリスナーの感情に影響を与えますか？
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-12">
        <br>2019-09-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Recognizing long-form speech using streaming end-to-end models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-CL\paper_31.html">
      Recognizing long-form speech using streaming end-to-end models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これに対処する2つの補完的なソリューションを提案します：多様な音響データのトレーニングと、短い発話を使用してトレーニングする場合の長形式のオーディオをシミュレートするLSTM状態操作。実際の長形式のコールセンターテストセットでは、データの多様性を追加することでWERが向上しますデータの多様性に加えて長時間トレーニングをシミュレートすると、パフォーマンスがさらに27％向上します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: L2RS: A Learning-to-Rescore Mechanism for Automatic Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-SD\paper_0.html">
      L2RS: A Learning-to-Rescore Mechanism for Automatic Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最新の自動音声認識（ASR）システムは、主に音響モデル（AM）および言語モデル（LM）のスコアに基づいてN-bestリストを再スコアリングします。L2RSは、ASRのより効果的な再スコアリングモデルの開発に道を開きます。公開データセットに基づいて広範な実験を実施し、実験結果は、L2RSが従来のリスコアリング方法だけでなく、NDCG @ 10の点で20.67％の大幅な改善によってディープニューラルネットワーク対応物よりも優れていることを示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SpeechBERT: Cross-Modal Pre-trained Language Model for End-to-end Spoken
  Question Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-SD\paper_1.html">
      SpeechBERT: Cross-Modal Pre-trained Language Model for End-to-end Spoken
  Question Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この事前トレーニング済み言語モデルの利点を音声による質問応答に取り入れるために、クロスモーダルトランスベースの事前トレーニング済み言語モデルであるSpeechBERTを提案します。質問応答..エンドツーエンドのSQAモデルの最初の調査として、ASRからの出力テキストを入力した従来のアプローチのパフォーマンスと一致し、事前学習済みの言語モデルにわずかに遅れて、エンドツーエンド-SQAモデルを終了します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Diarization Robustness using Diversification, Randomization
  and the DOVER Algorithm -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-SD\paper_2.html">
      Improving Diarization Robustness using Diversification, Randomization
  and the DOVER Algorithm
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのハイパーパラメーターの最適化は困難であり、異なるデータセット全体でロバストではない場合があります。クラスタリングの過程で疑似ランダムに、ベストファーストクラスタリングの貪欲さを軽減します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Self-supervised Moving Vehicle Tracking with Stereo Sound -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-SD\paper_3.html">
      Self-supervised Moving Vehicle Tracking with Stereo Sound
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      トレーニング中に、定評のある視覚車両検出モデルに組み込まれた知識は、ラベルのないビデオをブリッジとして使用してオーディオドメインに転送されます。人間は、視覚および聴覚の両方のキューを使用して環境内のオブジェクトをローカライズし、複数のモダリティからの情報を統合できます共通の参照フレーム..新しく収集されたAu-ditory Vehicle Trackingデータセットの実験結果は、提案されたアプローチがいくつかのベースラインアプローチよりも優れていることを検証します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The emotions that we perceive in music: the influence of language and
  lyrics comprehension on agreement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-SD\paper_4.html">
      The emotions that we perceive in music: the influence of language and
  lyrics comprehension on agreement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2つの主な研究上の質問に対処します。1。個人の特徴には、リスナーの一般的な人口統計、フラグメントの親しみやすさと好み、および音楽の洗練度が含まれます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-12">
        <br>2019-09-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploring Lexicon-Free Modeling Units for End-to-End Korean and
  Korean-English Code-Switching Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-SD\paper_5.html">
      Exploring Lexicon-Free Modeling Units for End-to-End Korean and
  Korean-English Code-Switching Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      5つのレキシコンなしユニットが調査されます：音節ベースの韓国語文字（コード切り替えタスク用の英語の文字付き）、韓国語のジャモ文字（英語の文字付き）、音節ベースの文字のサブワード（英語のサブワード付き） 、Jamoキャラクターのサブワード（英語のサブワードを含む）、そして最後に言語全体で共通のバイトユニットです。この作業では、レキシコンなしのモデリングユニットを韓国語で紹介し、ハイブリッドを使用してそれらを探索しますCTC / Attention-based encoder-decoder model ..韓国語の音節に基づくサブワード（および英語のサブワード）を使用したシーケンス間学習は、レキシコンと追加の言語モデル統合なしで両方のタスクに最適です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Channel adversarial training for speaker verification and diarization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-SD\paper_6.html">
      Channel adversarial training for speaker verification and diarization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      VoxCelebモデルは特によく機能し、同様のアーキテクチャと少ないトレーニングデータを使用しながら、カルディベースラインよりもEERが$ 4 \％$相対的に向上しています。VoxCelebの検証とCALLHOMEのダイアリゼーションと検証の実験では、データセット-敵対モデルよりも優れたベースライン..同じ話者の埋め込みのペアがシャム様式で同じ録音に属しているかどうかを予測するために敵を訓練することにより、学習機能は、話者を差別する可能性のあるチャンネル情報を利用することを阻止トレーニング。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SeCoST: Sequential Co-Supervision for Weakly Labeled Audio Event
  Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-SD\paper_7.html">
      SeCoST: Sequential Co-Supervision for Weakly Labeled Audio Event
  Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SeCoSTは、斬新な知識移転方法により、生徒と教師のペアのカスケードをインクリメンタルに構築します。提案された方法論をSeCoST（Sequestと発音）---世代の生徒のトレーニングのためのシーケンシャル共同監督と呼びます。逐次学習と知識の蒸留からアイデアを橋渡しすることにより、弱い監督で学習モデルを設計するための新しいフレームワーク。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Speaker diarization using latent space clustering in generative
  adversarial network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-SD\paper_8.html">
      Speaker diarization using latent space clustering in generative
  adversarial network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、オラクル音声セグメンテーションを使用したxベクトルベースラインと比較した場合、AMI評価、ADOSおよびBOSCCコーパスでそれぞれ31％、36％および49％の相対的なDER改善を達成するために、xベクトルとの埋め込み融合を実行します。 AMI会議コーパスで提案されたシステムのベンチマーク、および自閉症診断ドメインからの2つの小児臨床医相互作用コーパス（ADOSおよびBOSCC）。 。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Meta-learning for robust child-adult classification from speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-SD\paper_9.html">
      Meta-learning for robust child-adult classification from speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、メタ学習、特に複数のタスクにまたがるメトリック空間を最適化するプロトタイプネットワークの使用を提案します。臨床応用における自然な会話の計算モデリングは、過去10年で関心が高まっています。 -メタトレーニング中の個別のタスクとしてのトレーニングセットの大人のペアは、従来の教師あり学習と比較して一般化可能性が向上した表現を学習します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A study of semi-supervised speaker diarization system using gan mixture
  model -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-SD\paper_10.html">
      A study of semi-supervised speaker diarization system using gan mixture
  model
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      AMI会議コーパスの実験結果は、提案された半教師付きダイアライゼーションシステムが競合ベースラインのパフォーマンスに匹敵するか、それを超えることを示しています。 ）..スペクトル埋め込みは、GANMM事前トレーニング中の次元平均化とそれに続くk-means初期化に使用されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Recognizing long-form speech using streaming end-to-end models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-SD\paper_11.html">
      Recognizing long-form speech using streaming end-to-end models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これに対処するための2つの補完的なソリューションを提案します：多様な音響データのトレーニングと、短い発声を使用してトレーニングする場合の長形式のオーディオをシミュレートするLSTM状態操作。 ）90％相対、ロングフォームトレーニングをシミュレートすると67％相対改善しますが、組み合わせはデータの多様性だけでは改善されません。実際のロングフォームコールセンターテストセットでは、データの多様性を追加するとWER相対40％。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning Domain Invariant Representations for Child-Adult Classification
  from Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-SD\paper_12.html">
      Learning Domain Invariant Representations for Child-Adult Classification
  from Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、トレーニングデータの不足により、従来のディープラーニング手法の直接的な適用が制限されることがよくあります。データ.. 2つの方法、逆ラベル損失と勾配反転層を使用した生成的敵対訓練を使用して、上記の変動源に不変の話者の埋め込みを学習し、提案された手法が従来の学習方法よりも改善するさまざまな条件を分析します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Parallel WaveGAN: A fast waveform generation model based on generative
  adversarial networks with multi-resolution spectrogram -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-SD\paper_13.html">
      Parallel WaveGAN: A fast waveform generation model based on generative
  adversarial networks with multi-resolution spectrogram
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      知覚的リスニングテストの結果は、提案された方法が、トランスフォーマーベースの音声合成フレームワーク内で4.16の平均オピニオンスコアを達成することを検証します。これは、蒸留ベースの最適なParallel WaveNetシステムと比較されますMパラメータは、単一のGPU環境でリアルタイムより28.68倍高速な24 kHz音声波形を生成できます。提案方法では、非自己回帰WaveNetは、多重解像度スペクトログラムと敵対損失関数を効果的に共同最適化することにより訓練されます。現実的な音声波形の時間周波数分布をキャプチャします。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Multi-Phase Gammatone Filterbank for Speech Separation via TasNet -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-SD\paper_14.html">
      A Multi-Phase Gammatone Filterbank for Speech Separation via TasNet
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Conv-TasNetの訓練されたエンコーダーと聴覚フィルターバンクの類似性に動機付けられ、決定論的なガンマトーンフィルターバンクを採用することを提案します。さまざまな位相シフトで同じ中心周波数のフィルター..学習したエンコーダーを提案されたマルチフェーズガンマトーンフィルターバンク（MP-GTF）に置き換えると、スケール不変のソース/ノイズ比（SI-SNR）にさえなることを示します0.8 dBの改善。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Overlap-aware diarization: resegmentation using neural end-to-end
  overlapped speech detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-SD\paper_15.html">
      Overlap-aware diarization: resegmentation using neural end-to-end
  overlapped speech detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      第二に、検出されたオーバーラップ領域は、フレームレベルのスピーカー事後マトリックスと組み合わせて利用され、再セグメンテーションステップでオーバーラップフレームの2スピーカー割り当てを行います。オーバーラップ検出モジュールは、AMI、DIHARDで最先端のパフォーマンスを実現します、およびETAPE corpora.。このアプローチは、オーバーラップを意識したダイアライゼーションに対するすべてのソリューションではありませんが、オーバーラップを処理するための有望な方向性を明らかにします。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SPICE: Self-supervised Pitch Estimation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-SD\paper_16.html">
      SPICE: Self-supervised Pitch Estimation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CQTの2つのシフトスライスを同じ畳み込みエンコーダーに供給することにより、自己監視タスクを設計し、出力の差がピッチの対応する差に比例することを要求します。モノフォニックの基本周波数を推定するモデルを提案します。ピッチ推定と呼ばれることもあります。さらに、エンコーダの上部に小さなモデルヘッドを導入し、ピッチ推定の信頼性を判定できるため、有声音声と無声音声を区別できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Fast and High-Quality Singing Voice Synthesis System based on
  Convolutional Neural Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-SD\paper_17.html">
      Fast and High-Quality Singing Voice Synthesis System based on
  Convolutional Neural Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、提案手法が従来手法よりもはるかに高速で自然な歌声を合成できることを示しています。長期フレームで構成されるセグメントごとに音響特徴シーケンスが生成され、パラメータ生成アルゴリズムなしで自然な軌跡が得られます。 。提案された手法では、歌声の長期的な依存関係がCNNによってモデル化されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Adaptive blind audio source extraction supervised by dominant speaker
  identification using x-vectors -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\cs-SD\paper_18.html">
      Adaptive blind audio source extraction supervised by dominant speaker
  identification using x-vectors
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      クロストークの存在下で計算されたxベクトルの特性は、実験的に分析されます。提案されたアプローチは、移動するSOI、静的干渉スピーカー、および環境ノイズのシナリオで検証されます。 x-ベクトルを使用した混合物の主要なスピーカー。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Toward domain-invariant speech recognition via large scale training -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_0.html">
      Toward domain-invariant speech recognition via large scale training
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、各発話はトレーニング中に人工的に歪められ、バックグラウンドノイズ、コーデックディストーション、サンプリングレートなどの効果をシミュレートします。このようなスケールでも、トレーニングされたモデルは、特定のサブセット：単一のモデルは、複数のアプリケーションドメイン、およびコーデックやノイズなどのバリエーションに対して堅牢です。この作業では、複数のアプリケーションドメインからの大規模なトレーニングデータを組み合わせて、さまざまなユースケースの単一ドメイン不変モデルを構築するアイデアを探ります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-08-16">
        <br>2018-08-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An Empirical Study of Efficient ASR Rescoring with Transformers -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_1.html">
      An Empirical Study of Efficient ASR Rescoring with Transformers
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      サブワードユニット、アダプティブソフトマックス、大規模モデルの事前トレーニング、および知識の蒸留などの手法を組み合わせることにより、n-ベストリスコアリングを通じて、大幅な相対ワードエラー率の削減（WERR）を備えた小さなTransformer LMを正常にトレーニングできることを示します。したがって、比較的小さなモデルサイズのTransformer LMを開発することが重要です。ただし、これらのはるかに大きなモデルの優れたパフォーマンスを維持します。特に、ビデオ音声認識データセットの実験では、次のようなWERRを達成できることが示されています。同じデータセットで記録されたWERRが7.58％である有名な大規模なGPTモデル[1]のパラメーターサイズが5.5％から11.9％である場合、6.46％から7.17％になります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: L2RS: A Learning-to-Rescore Mechanism for Automatic Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_2.html">
      L2RS: A Learning-to-Rescore Mechanism for Automatic Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      パブリックデータセットに基づいて広範な実験を実施し、実験結果は、L2RSが従来のリスコアリング方法だけでなく、NDCG @ 10に関して20.67％の大幅な改善により、ディープニューラルネットワークの対応物よりも優れていることを示しています。最新の学習スコア（L2RS）メカニズム。これは、最先端のNLPモデルからの幅広いテキスト情報を利用し、ASRシステムのNベストリストを再スコア化するために自動的に重みを決定することに特化しています。 L2RSは、ASRのより効果的なリスコアリングモデルを開発する道を開きます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SpeechBERT: Cross-Modal Pre-trained Language Model for End-to-end Spoken
  Question Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_3.html">
      SpeechBERT: Cross-Modal Pre-trained Language Model for End-to-end Spoken
  Question Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この事前トレーニング済み言語モデルの利点を音声による質問応答に取り入れるために、クロスモーダルトランスベースの事前トレーニング済み言語モデルであるSpeechBERTを提案します。エンドツーエンドSQAモデルの最初の調査として、結果はASRからの出力テキストを入力する従来のアプローチのパフォーマンスは、事前学習済みの言語モデルよりわずかに遅れており、エンドツーエンドのSQAモデルの可能性を示しています。一方、BERTなどの事前学習済みの言語モデルテキストの質問に答えます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Diarization Robustness using Diversification, Randomization
  and the DOVER Algorithm -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_4.html">
      Improving Diarization Robustness using Diversification, Randomization
  and the DOVER Algorithm
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのハイパーパラメーターを最適化することは困難であり、異なるデータセット全体で堅牢ではない場合があります。また、クラスタリングの過程で異なるマージ選択を疑似ランダムに追跡することにより得られる多様な出力の組み合わせを調査します。 NIST評価から引き出された2つの会議会議データセットで、提案された方法が実際により堅牢で、いくつかのケースで全体的に改善された結果をもたらすことを示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploring Multilingual Syntactic Sentence Representations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_5.html">
      Exploring Multilingual Syntactic Sentence Representations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの結果は、最新の言語モデルよりも少ないトレーニングデータ、少ないモデルパラメーターを使用して、構文文の埋め込みを学習できることを示しています。その結果、評価指標が向上しました。また、汎用品詞タグによって拡張された多言語並列コーパスを使用します。また、低リソース言語の構文文埋め込みを学習し、転移学習の強力な証拠を実証する方法の能力を評価します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Self-supervised Moving Vehicle Tracking with Stereo Sound -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_6.html">
      Self-supervised Moving Vehicle Tracking with Stereo Sound
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人間は視覚と聴覚の両方の合図を使用して環境内のオブジェクトをローカライズでき、複数のモダリティからの情報を共通の参照フレームに統合します。トレーニング中、定評のある視覚車両検出モデルに組み込まれた知識は、ラベルなしビデオをブリッジとして使用します。オーディオとオブジェクトのバウンディングボックス間の対応に手動で注釈を付けるのは手間がかかるため、ラベルなしのビデオでのビジュアルストリームとオーディオストリームの共起を自己監視の形として使用することで、この目標を達成し、グラウンドトゥルースアノテーションのコレクションに頼ることなく。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The emotions that we perceive in music: the influence of language and
  lyrics comprehension on agreement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_7.html">
      The emotions that we perceive in music: the influence of language and
  lyrics comprehension on agreement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2 ..個人的な特徴には、リスナーの一般的な人口統計、フラグメントの親しみやすさと好み、および音楽の洗練度が含まれます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-12">
        <br>2019-09-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploring Lexicon-Free Modeling Units for End-to-End Korean and
  Korean-English Code-Switching Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_8.html">
      Exploring Lexicon-Free Modeling Units for End-to-End Korean and
  Korean-English Code-Switching Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、レキシコンなしのモデリングユニットを韓国語で紹介し、ハイブリッドCTC /アテンションベースのエンコーダ/デコーダモデルを使用してそれらを探索します。5つのレキシコンなしのユニットを調査します。コード切り替えタスク）、韓国語ジャモ文字（英語文字付き）、音節ベース文字のサブワード（英語のサブワード付き）、ジャモ文字のサブワード（英語のサブワード付き）、最後にバイトユニットは、言語間で普遍的なものです。Zeroth-Korean（51.6時間）とMedical Record（2530時間）の実験は、それぞれ韓国語と韓国語と英語のコード切り替えASRタスクに対して行われます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Channel adversarial training for speaker verification and diarization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_9.html">
      Channel adversarial training for speaker verification and diarization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      VoxCelebでの検証、CALLHOMEでのダイアライゼーションおよび検証の実験では、データセット-敵対モデルよりも優れたベースラインを超える有望な改善が示されています。特に、VoxCelebモデルは良好に機能し、カルディと比較してEERが$ 4 \％$相対的に改善されています似たアーキテクチャと少ないトレーニングデータを使用しながら、ベースライン。同じスピーカーの埋め込みのペアがシャム様式で同じ録音に属するかどうかを予測するために敵をトレーニングすることにより、学習機能は、スピーカー識別中のチャンネル情報を利用することを推奨しませんトレーニング。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SeCoST: Sequential Co-Supervision for Weakly Labeled Audio Event
  Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_10.html">
      SeCoST: Sequential Co-Supervision for Weakly Labeled Audio Event
  Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SeCoSTは、新しい知識伝達方法により、生徒と教師のペアのカスケードを段階的に構築します。オーディオイベント検出を数百の音声カテゴリにスケーリングするには、弱教師付き学習アルゴリズムが不可欠です。提案された方法論をSeCoST（Sequestと発音）と呼びます- -学生の世代を訓練するための順次共同監督。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Speaker diarization using latent space clustering in generative
  adversarial network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_11.html">
      Speaker diarization using latent space clustering in generative
  adversarial network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      AMI会議コーパス、および自閉症診断ドメインからの2つの小児クリニック相互作用コーパス（ADOSおよびBOSCC）で提案システムをベンチマークします。入力でxベクトルスピーカー埋め込みを使用し、潜在変数は組み合わせからサンプリングされます。元のスピーカーラベルを使用して、連続ランダム変数と離散ワンホットエンコード変数の組み合わせ。さらに、AMI評価、ADOS、およびBOSCCで31％、36％、49％の相対的なDER改善を達成するために、xベクトルとの埋め込み融合を実行しますOracleスピーチセグメンテーションを使用してxベクトルベースラインと比較した場合のコーパス。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Meta-learning for robust child-adult classification from speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_12.html">
      Meta-learning for robust child-adult classification from speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、メタ学習、特に複数のタスクにまたがるメトリックスペースを最適化するプロトタイプネットワークの使用を提案します。メタトレーニング中に個別のタスクとしてトレーニングセットのすべての子供と大人のペアをモデル化することにより、従来の教師あり学習と比較して一般化された表現を学習します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A study of semi-supervised speaker diarization system using gan mixture
  model -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_13.html">
      A study of semi-supervised speaker diarization system using gan mixture
  model
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      GANMMは、複雑なデータ分布を効率的にキャプチャすることにより、教師なし話者クラスタリングを実行します。最近導入された教師なしクラスタリング手法、すなわち生成的敵対ネットワーク混合モデル（GANMM）に基づく新しい話者ダイアライゼーションシステムを提案します。提案されている半教師付きダイアライゼーションシステムは、競合するベースラインのパフォーマンスと一致するか、それを上回ります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Recognizing long-form speech using streaming end-to-end models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_14.html">
      Recognizing long-form speech using streaming end-to-end models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これに対処する2つの補完的なソリューションを提案します：多様な音響データのトレーニング、および短い発声を使用してトレーニングする場合の長い音声をシミュレートするLSTM状態操作。単一のニューラルネットワークを使用して音声を単語シーケンスに変換すると、いくつかのタスクで最先端の結果が得られることが示されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning Domain Invariant Representations for Child-Adult Classification
  from Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_15.html">
      Learning Domain Invariant Representations for Child-Adult Classification
  from Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、ラベル付けされたターゲットドメインデータを必要としないドメイン敵対学習を使用して、2つの主要な変動源-子どもの年齢とデータソースの収集場所に対処します。ADOS-2の大規模なコーパス（自閉症診断観測スケジュール、第2版）セッションでは、従来の学習方法に比べて最大13.45％および6.44％の相対的な改善が実証されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Parallel WaveGAN: A fast waveform generation model based on generative
  adversarial networks with multi-resolution spectrogram -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_16.html">
      Parallel WaveGAN: A fast waveform generation model based on generative
  adversarial networks with multi-resolution spectrogram
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの方法は、従来の教師と生徒のフレームワークで使用される密度蒸留を必要としないため、少数のパラメーターでもモデル全体を簡単にトレーニングできます。蒸留不要、高速、小フットプリントの波形であるParallel WaveGANを提案します。生成的敵対ネットワークを使用した生成方法。特に、提案されたParallel WaveGANのパラメータは1.44 Mのみであり、単一のGPU環境でリアルタイムより28.68倍速い24 kHz音声波形を生成できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Structural sparsification for Far-field Speaker Recognition with GNA -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_17.html">
      Structural sparsification for Far-field Speaker Recognition with GNA
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ターゲットハードウェアでは、モデルはパラメーターの60％を削除し、等エラー率（EER）を0.18％だけわずかに増加させることができますが、構造スパースモデルでは2倍以上の高速化を実現できます。モバイルデバイスでは、遠方の条件で高い精度を維持しながら、低い計算コストを維持する必要があります。最近、ディープニューラルネットワーク（DNN）が話者認識領域で広く使用されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Multi-Phase Gammatone Filterbank for Speech Separation via TasNet -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_18.html">
      A Multi-Phase Gammatone Filterbank for Speech Separation via TasNet
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      一般的なガンマトーンフィルターバンクとは対照的に、低レイテンシー処理を可能にするために、フィルターの長さは2ミリ秒に制限されています。Conv-TasNetの訓練されたエンコーダーと聴覚フィルターバンクの類似性により、決定論的なガンマトーンフィルターバンクを採用することを提案します。学習したエンコーダーを提案されたマルチフェーズガンマトーンフィルターバンク（MP-GTF）で置き換えると、スケール不変のソース/ノイズ比（SI-SNR）が0.8 dB改善されることさえ示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Overlap-aware diarization: resegmentation using neural end-to-end
  overlapped speech detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_19.html">
      Overlap-aware diarization: resegmentation using neural end-to-end
  overlapped speech detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このアプローチは、オーバーラップを意識したダイアリゼーションのすべてを網羅するソリューションではありませんが、オーバーラップを処理するための有望な方向を明らかにします。オーバーラップ検出モジュールは、AMI、DIHARD、およびETAPEコーパスで最先端のパフォーマンスを実現します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SPICE: Self-supervised Pitch Estimation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_20.html">
      SPICE: Self-supervised Pitch Estimation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CQTの2つのシフトスライスを同じ畳み込みエンコーダーに供給することにより、自己監視タスクを設計し、出力の差が対応するピッチの差に比例することを要求します。さらに、上部に小さなモデルヘッドを導入します。ピッチ推定の信頼性を判断して、有声音声と無声音声を区別できるエンコーダの重要な観察結果は、音声信号がレンズのレンズを通して分析されるときに、ピッチシフトが単純な変換にマッピングされることです。定数Q変換（CQT）。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Fast and High-Quality Singing Voice Synthesis System based on
  Convolutional Neural Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_21.html">
      Fast and High-Quality Singing Voice Synthesis System based on
  Convolutional Neural Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本稿では、畳み込みニューラルネットワーク（CNN）に基づく歌声合成について説明します。長期フレームで構成されるセグメントごとに音響特徴シーケンスが生成され、パラメータ生成アルゴリズムを使用せずに自然な軌跡が得られます。提案された方法は、従来の方法よりもはるかに速く自然な響きの歌声を合成できること。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Adaptive blind audio source extraction supervised by dominant speaker
  identification using x-vectors -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../list\19-10-20\eess-AS\paper_22.html">
      Adaptive blind audio source extraction supervised by dominant speaker
  identification using x-vectors
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      クロストークの存在下で計算されたxベクトルの特性は、実験的に分析されます。パイロットは、xベクトルを使用した混合物の主要な話者の識別に基づいています。提案されたアプローチは、移動するSOI、静的干渉スピーカー、環境ノイズ。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-25">
        <br>2019-10-25
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
