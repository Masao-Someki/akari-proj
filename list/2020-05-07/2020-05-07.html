<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-05-07の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Self-supervised Learning of Visual Speech Features with Audiovisual
  Speech Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.SD/paper_0.html">
      Self-supervised Learning of Visual Speech Features with Audiovisual
  Speech Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの結果は、視聴覚音声強調の重要な側面についての洞察を提供し、そのようなモデルが視覚音声アプリケーションの自己監視タスクにどのように使用できるかを示しています。この発見の興味深い副産物は、学習した視覚埋め込みを他の視覚の機能として使用できることです音声アプリケーション..口形素（音素の視覚的類推）を分類するための学習した視覚表現の有効性を示します。 
[要約]口形素を分類するための学習された視覚表現の有効性を実証しました（音素への視覚的な類似）
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-25">
        <br>2020-04-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Seeing voices and hearing voices: learning discriminative embeddings
  using cross-modal self-supervision -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.SD/paper_1.html">
      Seeing voices and hearing voices: learning discriminative embeddings
  using cross-modal self-supervision
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この方法の有効性は、2つの下流タスクで実証されます。オーディオビジュアル同期でトレーニングされた機能を使用した口読み、およびクロスモーダルバイオメトリックマッチング用にトレーニングされた機能を使用した話者認識です。重要なマージンによる自己監視ベースライン。この作業の目標は、手動で注釈を付けたデータにアクセスせずに、特徴的なクロスモーダル埋め込みをトレーニングすることです。 
[要約]提案された方法は、最先端の自己監視ベースラインを重要なマージンで識別するために使用できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Singing Synthesis: with a little help from my attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.SD/paper_2.html">
      Singing Synthesis: with a little help from my attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これにもかかわらず、それは以前の神経歌合成モデルに比べて自然さの強い改善を示しています。モデルは、入力として期間やピッチパターンを必要とせず、音楽的文脈に従って自律的にビブラートを挿入することを学びます。しかし、つまり、明示的なデュレーションモデリングを完全に不要にすることで、曲のテンポに正確に一致させるために必要なタイミングを細かく制御することが難しくなります。 
[ABSTRACT]システムは、文献の以前のモデルよりも明確なモデリングを必要としません。モデルは、期間を必要としませんが、音楽的文脈に従って因果的にビブラートを挿入することを学習します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-12">
        <br>2019-12-12
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Crossing Variational Autoencoders for Answer Retrieval -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_0.html">
      Crossing Variational Autoencoders for Answer Retrieval
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、整列された回答で質問を生成し、整列された質問で回答を生成することにより、変分オートエンコーダーをクロスすることを提案します。実験により、この方法がSQuADの最先端の回答検索方法よりも優れていることがわかります。セマンティック情報言語モデルまたは質問から質問（回答から回答）の生成プロセスから学んだ。 
[ABSTRACT]自動トラックまたは自動エンコーダの学習は、回答を見つけるための重要な要素です。現在の方法では、二重回答の回答を使用して意味表現を学習しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An Empirical Study of Multi-Task Learning on BERT for Biomedical Text
  Mining -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_1.html">
      An Empirical Study of Multi-Task Learning on BERT for Biomedical Text
  Mining
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは、研究者が新しい問題に適したモデルを選択する面倒にある状況で特に役立ちます。私たちの実験結果は、MTL微調整モデルが最新のトランスモデル（たとえば、BERTとそのバリアント）2.0％および1.3％生物医学および臨床ドメインでそれぞれ。ペアワイズMTLはさらに、どのタスクが他のタスクを改善または減少させることができるかについての詳細を示します。 
[要約]コードとモデルはwwwで公開されています。 github。 com
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Neural Aspect Search with Related Terms Extraction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_2.html">
      Unsupervised Neural Aspect Search with Related Terms Extraction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      マルチアスペクト抽出の品質を向上させることを目的とした特別な損失を適用します。実験的研究では、この損失により、このジョイント設定だけでなく、アスペクト予測のみで精度が向上することを示しています。教師なしアプローチは、これらの方法よりも優れていますいくつかのタスクがありますが、特にマルチアスペクトの設定では、アスペクトと対応する用語の両方を抽出することは依然として困難です。 
[ABSTRACT]畳み込みマルチアテンションメカニズムを備えた教師なしニューラルネットワーク。ペア（アスペクト、ターム）を同時に抽出できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Probing the Natural Language Inference Task with Automated Reasoning
  Tools -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_3.html">
      Probing the Natural Language Inference Task with Automated Reasoning
  Tools
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これを行うには、機械指向の制御自然言語（Attempto Controlled English）を使用してNLI文を解析する方法と、自動化された定理の証明者が結果の式をどのように推論できるかをテストします。それらのパフォーマンスを報告し、その影響について説明します。 NLIと論理ベースのNLP ..自然言語推論（NLI）タスクは、他の多くのタスクを削減できる幅広い質問をするので、現代のNLPの重要なタスクです。二番目？ 
[ABSTRACT]ベンチマークデータセットの幅広い知識はディープラーニングに基づいています。ただし、他の手法を使用してnliタスクの論理構造を調べることは価値があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CODA-19: Reliably Annotating Research Aspects on 10,000+ CORD-19
  Abstracts Using Non-Expert Crowd -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_4.html">
      CODA-19: Reliably Annotating Research Aspects on 10,000+ CORD-19
  Abstracts Using Non-Expert Crowd
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CODA-19のラベルの精度は、生物医学の専門家のラベルと比較すると82.2％ですが、エキスパート間の精度は85.0％でした。エキスパートの注釈の取得は遅くなる可能性がありますが、CODA-19は、エキスパート以外の群衆を大規模に採用できることを示しましたCOVID-19に対抗するために迅速に参加します。信頼できる人間の注釈は、科学者が急速に加速するコロナウイルスの文献を理解するのに役立ち、AI / NLP研究のバッテリーとしても役立ちます。 
[ABSTRACT]このデータセットは、amazon Mechanical turkの非営利労働者によって作成されました。データセットは、10日以内に19人のクラウドワーカーによって作成されました。他のデータセットは、データセットを分析して作成されました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: TAG : Type Auxiliary Guiding for Code Comment Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_5.html">
      TAG : Type Auxiliary Guiding for Code Comment Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      構造からシーケンスへのフレームワークを使用した既存の主要なコードコメント生成アプローチでは、コードの解釈のタイプ情報（演算子、文字列など）が無視されます。広範な評価により、フレームワークの最先端のパフォーマンスが示されます。自動評価されたメトリックとケーススタディの両方。.上記の問題に対処するために、ソースコードをタイプ情報が関連付けられたN-aryツリーと見なすコードコメント生成タスクのタイプ補助ガイドエンコーダー/デコーダーフレームワークを提案します。各ノードで。 
[要旨]私たちのフレームワークは、タイプ-関連付けられたエンコーダーとタイプ制限されたデコーダーを備えています。さらにテストを行うと、フレームワークの最先端のパフォーマンスがわかります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Building A User-Centric and Content-Driven Socialbot -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_6.html">
      Building A User-Centric and Content-Driven Socialbot
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      競争中にサウンディングボードから収集されたデータを使用して、ソーシャルボットの評価方法に関する貴重な洞察を提供するソーシャルボットの会話とユーザー評価の詳細な分析を実行します。サウンディングボードを構築するために、私たちは対応できるシステムアーキテクチャを開発します。ソーシャルボットの会話用に設計した対話戦略。最後に、ソーシャルボットが非構造化データに関連するトピックについての浅い会話の問題に苦しんでいることを観察し、ドキュメントに基づいた拡張ソーシャルボット会話を有効にする問題を研究します。 
[ABSTRACT]アーキテクチャはsocialbotsを分析するためのsocialbotツールで構成されています。また、会話内の個々のダイアログセグメントのスコアリングを可能にするシステム評価および診断のための新しいアプローチも調査します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: TripPy: A Triple Copy Strategy for Value Independent Neural Dialog State
  Tracking -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_7.html">
      TripPy: A Triple Copy Strategy for Value Independent Neural Dialog State
  Tracking
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのアプローチは、スパンベースのスロット充填方法の利点とメモリ方法を組み合わせて、値の選択リストを完全に使用しないようにします。代わりに、すべての値がダイアログコンテキストから即座に抽出されます。コピーメカニズム：（1）スパン予測では、ユーザー入力から直接値を抽出できます。 （2）値は、システムの通知操作を追跡するシステム通知メモリからコピーできます。 （3）ドメイン内およびドメイン間の相互参照を解決するために、ダイアログ状態にすでに含まれている別のスロットから値がコピーされる場合があります。 
[要旨]私たちのモデルは候補値のリストを提示する必要はありません。スロットは、ユーザー入力から直接値を抽出するコピーメカニズムによって埋められます。値は、システムを追跡する別のスロットからコピーされる場合があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Review of text style transfer based on deep learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_8.html">
      Review of text style transfer based on deep learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      テキストスタイルの転送は、最近の自然言語処理におけるホットな問題であり、主にテキストを研究して、いくつかの変更を加えることによって、さまざまな特定の状況、対象者、および目的に適応します。この記事では、ディープラーニングに基づくテキストスタイルの転送モデルに関する研究を要約します。近年、主要な研究の方向性と進歩を要約し、分析し、比較しています。近年、自然言語処理研究では、テキストスタイルの転送がホットな問題になりつつあります。 
[ABSTRACT]テキストスタイルの転送は、自然言語の状況でホットな問題になりつつあります。さらに、この記事では、自然言語の研究に使用される公開データセットと評価指標も紹介します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning Architectures from an Extended Search Space for Language
  Modeling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_9.html">
      Learning Architectures from an Extended Search Space for Language
  Modeling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、学習したアーキテクチャは他のシステムへの優れた転送可能性を示します。特に、セル内およびセル間アーキテクチャ（ESSと呼ぶ）の両方を学習するための一般的なアプローチを示します。再帰的な神経言語モデリングでは、強力なベースラインを上回りますPTBとWikiTextデータに大幅に影響を与え、PTBに新しい最先端の技術を導入しました。 
[要約]このペーパーでは、セル内とセル間nasを同時に実行する共同学習方法を学習します。再発神経言語モデリングでは、ptbおよびwikitextデータの強力なベースラインを大幅に上回り、新しい状態- -Ptbのアート
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Adversarial NLI: A New Benchmark for Natural Language Understanding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_10.html">
      Adversarial NLI: A New Benchmark for Natural Language Understanding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      反復的な敵対的な人間とモデルインザループの手順で収集された、新しい大規模なNLIベンチマークデータセットを紹介します。私たちの分析は、現在の最先端モデルの欠点に光を当てます。専門家ではないアノテーターが弱点を見つけるのに成功していることを示しています。この新しいデータセットのトレーニングモデルは、さまざまな人気のあるNLIベンチマークで最先端のパフォーマンスにつながる一方で、新しいアノテーターでより困難な課題を提起していることを示しています。テストセット。 
[ABSTRACT]新しいデータセットでモデルをテストすると、最先端のパフォーマンスが得られます。データ収集方法は、終わりのない学習シナリオに適用できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-31">
        <br>2019-10-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Shape of synth to come: Why we should use synthetic data for English
  surface realization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_11.html">
      Shape of synth to come: Why we should use synthetic data for English
  surface realization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2018年の共有タスクの結果とは対照的に、2018年の英語データセットの実験では、合成データを使用することでかなりのプラスの効果が得られることを示しています-以前の状態ではBLEUポイントがほぼ8改善されていますアートシステム..私たちは合成データの影響を分析し、将来の研究努力がそのようなデータを利用できるシステムを探求し続けるために、その使用は禁止ではなく奨励されるべきであると主張します。2018の表面実現共有タスクと2019年は、Universal-Dependencyのようなツリーから複数の言語の表面文字列への表面実現へのアプローチを探ることを目的とした自然言語生成共有タスクでした。 
[要約] 2019共有タスクに合成データの使用を禁止する新しいルールが導入されました。新しいルールは2018年に導入され、使用をより効果的にすることができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Introducing a framework to assess newly created questions with Natural
  Language Processing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_12.html">
      Introducing a framework to assess newly created questions with Natural
  Language Processing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このフレームワークを使用して1つのモデルを実装し、CloudAcademyが提供する実際のデータセットでテストします。これは、以前に提案されたモデルよりも優れており、難易度の推定ではRMSEを6.7％削減し、識別の推定ではRMSEを10.8％削減します。論文では、質問と考えられる選択肢のテキストから意味のある特徴を抽出することにより、新しく作成された多肢選択問題の難易度と識別を推定するモデルをトレーニングおよび評価するためのフレームワークを提案します。また、IRTを使用して、すでに数人の学生が回答した質問の特性を推定することは可能ですが、この手法は、新しく生成された質問には使用できません。 
[ABSTRACT]システムはcloudacademyの学生によって開発されました。既存のモデルよりもパフォーマンスが優れており、6.7％から10.8％削減されています。結果はcloudacademyのデータに基づいていることが示されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to Understand Child-directed and Adult-directed Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_13.html">
      Learning to Understand Child-directed and Adult-directed Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CDSが学習の初期段階で役立つという兆候が見られますが、最終的に、ADSでトレーニングされたモデルは同等のタスクパフォーマンスに到達し、一般化します。人間の言語習得研究は、子供向けの音声が言語学習者に役立つことを示しています。音声から意味情報を直接抽出することを学ぶときの子供向けの音声の使用。 
[ABSTRACT]人間の言語習得調査は、子供向けのスピーチが言語学習者に役立つことを示しています。これは、2人の話者とは関係がないという事実が原因であることを示唆しています。結果は、スピーチが原因である可能性があると示唆しています早すぎるのかもしれません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Align, Mask and Select: A Simple Method for Incorporating Commonsense
  Knowledge into Language Representation Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_14.html">
      Align, Mask and Select: A Simple Method for Incorporating Commonsense
  Knowledge into Language Representation Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、提案されたアプローチを使用した事前トレーニングモデルとそれに続く微調整により、CommonsenseQAとWinograd Schema Challengeを含む2つの常識関連のベンチマークで、以前の最先端モデルよりも大幅に改善されていることを示しています。提案された事前トレーニングアプローチ後のチューニング済みモデルは、オリジナルのBERTモデルと比較して、文の分類や自然言語推論タスクなどの他のNLPタスクで同等のパフォーマンスを維持します。最先端の事前トレーニング済み言語表現モデルトランスフォーマーからの双方向エンコーダー表現（BERT）など、常識的な知識やその他の知識を明示的に組み込むことはほとんどありません。 
[ABSTRACT]常識的な知識を言語表現モデルに組み込むための事前設定アプローチを提案します。これにより、一般的な言語表現機能が低下することはありません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-19">
        <br>2019-08-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural translation and automated recognition of ICD10 medical entities
  from natural language -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_15.html">
      Neural translation and automated recognition of ICD10 medical entities
  from natural language
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、学習にはかなりの量のデータが必要です。これは通常、主な制限要因です。ただし、C \ &#39;epiDcは、提供された数百万の自然言語の例に相当する、フランスの国家規模での死亡証明書の完全なデータベースを格納しています。この記事では、ディープニューラルシーケンスモデルの自然言語問題からの医療エンティティ認識への適用について調査します。 
[ABSTRACT]開発は「人工」と呼ばれます。これは、さまざまな障害を持つ人々を支援するために使用されています。これは、カリフォルニアでの会議カンファレンス会議と呼ばれています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-27">
        <br>2020-03-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Fine-grained Financial Opinion Mining: A Survey and Research Agenda -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_16.html">
      Fine-grained Financial Opinion Mining: A Survey and Research Agenda
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、提案された研究課題に対処するための可能な指示を提供します。ただし、財務領域では、それはまだ初期段階です。このトピックに関する研究のほとんどは、粗視化された市場感情分析にのみ焦点を当てています。 、強気/弱気の2方向分類。 
[要約]金融技術（fintech）開発は、投資家の意見の詳細な分析に関与する共同研究者を育成しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: What are the Goals of Distributional Semantics? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_17.html">
      What are the Goals of Distributional Semantics?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      異なるサブフィールドで提案されたモデル間の明確な違いを考えると、それらをどのように統合できるかを確認するには、広い視野が必要です。分散意味論モデルは、NLPの主力になり、下流のタスクに役立つ機能を提供します。このホワイトペーパーでは、現在のモデルがさまざまなセマンティックの課題にどれだけうまく対処できるかを調べて、言語学的観点。 
[要約]長期的な進捗状況を理解するには、実質的な長期目標が必要ですが、明確な長期目標が必要になります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Recurrent Neural Network Language Models Always Learn English-Like
  Relative Clause Attachment -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_18.html">
      Recurrent Neural Network Language Models Always Learn English-Like
  Relative Clause Attachment
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      英語とスペイン語のモデルパフォーマンスを比較して、RNN LMの非言語的バイアスが英語の構文構造と有利にオーバーラップするが、スペイン語とはオーバーラップしないことを示します。したがって、スペイン語でトレーニングされたモデルが失敗する一方で、英語モデルは人間のような構文設定を取得するように見える場合があります。典型的な言語モデルのユースケース）と（言語モデルのトレーニングデータを生成する）プロダクションを取得し、トレーニング信号に必要な言語バイアスがまったく存在しないことを示唆しています。 
[要約]英語とスペイン語のモデルパフォーマンスを比較して、rnn lmsの非言語的バイアスが英語では構文構造と有利にオーバーラップするが、スペイン語ではないことを示す
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br>2020-05-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Seeing the Forest and the Trees: Detection and Cross-Document
  Coreference Resolution of Militarized Interstate Disputes -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_19.html">
      Seeing the Forest and the Trees: Detection and Cross-Document
  Coreference Resolution of Militarized Interstate Disputes
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      マルチタスクたたみ込みニューラルネットワークは、ヘッドラインのテキストと公開日を指定すると、イベントとイベント共参照を認識できることが示されています。さらに、両方のタスクを実行できるモデルを紹介します。イベント共参照に関する計算言語学の別の文献解決は、既知のイベントをドキュメント内（およびドキュメント間）で相互にリンクしようとします。 
[ABSTRACT]システムはテキストで特定の政治イベントを識別できます。特定のイベントを識別する方法を評価するためのデータセットを提供します。これには、イベントの追跡とそれらの相互リンクが含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Harvesting and Refining Question-Answer Pairs for Unsupervised QA -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_20.html">
      Harvesting and Refining Question-Answer Pairs for Unsupervised QA
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、QAモデルを利用してより適切な回答を抽出し、RefQAを介してデータを反復的に絞り込みます。手動で注釈を付けたデータにアクセスせずにBERTを微調整することにより、SQuAD 1.1とNewsQAで実験を行います。大幅に接近し、初期の監視モデルとの競争力があります。 
[要約]語彙的および構文的に異なる質問をwikipediaから収集します。チームの実験を行います1。 1、および手動で注釈が付けられたデータにアクセスできないnewsqa。少数のショット学習設定でのアプローチの有効性も示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Self-supervised Learning of Visual Speech Features with Audiovisual
  Speech Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_21.html">
      Self-supervised Learning of Visual Speech Features with Audiovisual
  Speech Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      口形素を分類するための学習された視覚表現（視覚的な音素への類似）の有効性を示します。この発見の興味深い副産物は、学習された視覚的埋め込みが他の視覚的音声アプリケーションの機能として使用できることです。その視覚的機能を示します。音声アクティビティに関する高レベルの情報を提供するだけでなく、
[ABSTRACT]口形素を分類するための学習された視覚的表現の有効性を実証しました（音素への視覚的な類似）
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-25">
        <br>2020-04-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Moving Down the Long Tail of Word Sense Disambiguation with
  Gloss-Informed Biencoders -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_22.html">
      Moving Down the Long Tail of Word Sense Disambiguation with
  Gloss-Informed Biencoders
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは、それらの定義をモデル化することにより、まれな感覚をより効果的に明確化できることを示しています。エンコーダーは同じ表現空間で共同で最適化されているため、各ターゲット単語の埋め込みに最も近い感覚の埋め込みを見つけることによって感覚の明確化を実行できます。英語の全単語WSDに関する以前の最先端モデル。これらの利益は主に、まれな感覚でのパフォーマンスの向上によるもので、以前の作業よりも頻度の少ない感覚で31.1％のエラー削減につながります。 
[ABSTRACT]ターゲットワードとその周囲のコンテキスト、および各感覚の辞書定義を埋め込むバイエンコーダーモデルを提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Top-Down Neural Architecture towards Text-Level Parsing of Discourse
  Rhetorical Structure -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_23.html">
      A Top-Down Neural Architecture towards Text-Level Parsing of Discourse
  Rhetorical Structure
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      特に、談話解析を再帰的な分割ポイントランキングタスクとしてキャストします。この場合、分割ポイントはそのランクに従ってさまざまなレベルに分類され、それに関連付けられた基本談話単位（EDU）がそれに応じて配置されます。このペーパーでは、正当化します。計算と知覚の両方の観点から、トップダウンアーキテクチャはテキストレベルのDRS解析に適しています。英語のRST-DTコーパスと中国語のCDTBコーパスの両方での実験は、提案されたトップ-テキストレベルのDRS解析へのダウンアプローチ。 
[ABSTRACT]これはテキストに関する以前の研究に基づいています-レベルの談話解析です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SLEDGE: A Simple Yet Effective Baseline for Coronavirus Scientific
  Knowledge Search -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_24.html">
      SLEDGE: A Simple Yet Effective Baseline for Coronavirus Scientific
  Knowledge Search
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SRECGEの有効性は、TREC-COVIDチャレンジの強力なベースラインとして観察されます（リーダーボードのnDCG @ 10が0.6844を上回ります）。この作業では、SciBERTを使用して記事を効果的に再ランク付けするSLEDGEと呼ばれる検索システムを紹介します。詳細な分析によって提供される洞察は、日付でフィルタリングすることの重要性や、カウント信号に大きく依存する神経方法の可能性など、探求するいくつかの潜在的な将来の方向性を提供します。 
[ABSTRACT]モデルを一般的な-ドメイン回答ランキングデータセットでトレーニングします。関連性信号をsars-cov-2に評価のために転送します。詳細な分析によって提供される洞察は、いくつかの潜在的な課題を提供します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Boosting Naturalness of Language in Task-oriented Dialogues via
  Adversarial Training -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_25.html">
      Boosting Naturalness of Language in Task-oriented Dialogues via
  Adversarial Training
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      たとえば、RNN-LGレストランデータセットでは、モデルAdvNLGがBLEUで以前の最先端の結果より3.6％優れています。また、パフォーマンスを向上させるために2段階のトレーニングスキームを提案しています。 -勾配計算用のGumbel-Softmax推定器を使用。 
[ABSTRACT]敵対的なトレーニングは、自動評価と人間評価の両方で言語生成の品質を効果的に向上させることができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Entity Type Prediction in Knowledge Graphs using Embeddings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_26.html">
      Entity Type Prediction in Knowledge Graphs using Embeddings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このアプローチを現在の最先端タイプの予測方法と比較し、KGを使用した実験について報告します。この問題に対処するために、この作業では、KG埋め込みを使用したエンティティのタイピングのためにマルチラベル分類アプローチを提案します。したがって、ナレッジグラフ（KG）の完全性と正確性は非常に重要です。 
[要約]私たちのアプローチを現在のwibdaタイプ予測方法と比較します。さらに、kgsを使用した実験について報告します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br>2020-04-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Don't Say That! Making Inconsistent Dialogue Unlikely with Unlikelihood
  Training -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_27.html">
      Don't Say That! Making Inconsistent Dialogue Unlikely with Unlikelihood
  Training
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人間の分布に一致するように生成された出力を正規化する適切な損失関数が最初の3つの問題に有効であることを示します。この作業では、最近導入された可能性の低い損失を拡張することでこれらの問題のすべてに対処できる方法を示します（Welleck et al。、2019 ）これらのケースに..最後の重要な一般的な問題について、モデルがすべきでないことの収集されたデータに可能性を適用することは、論理的一貫性を改善するのに効果的であり、より大きな推論能力を持つ生成モデルへの道を開く可能性があります。 
[要約]いくつかの対話タスクでのアプローチの有効性を示します。アプローチの有効性を示しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br>2019-11-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: PeTra: A Sparsely Supervised Memory Model for People Tracking -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_28.html">
      PeTra: A Sparsely Supervised Memory Model for People Tracking
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      PeTraは両方の評価で非常に効果的であり、アノテーションが制限されているにもかかわらず、メモリ内の人々を追跡する能力を示しています。メモリモデルの人々追跡機能を測定するために、（a）数のカウントに基づく新しい診断評価を提案しますテキスト内の一意のエンティティ、および（b）小規模な人間の評価を行って、以前のアプローチと比較してPeTraのメモリログを追跡している人々の証拠を比較します。主要なモデリングの選択を経験的に比較し、強力なパフォーマンスを維持しながらメモリモジュールの設計。 
[要約]私たちは、テキスト内の一意のエンティティの数をカウントすることに基づく新しい診断評価を提案します。また、以前のアプローチと比較して、ペトラのメモリログで追跡している人々の証拠を比較する小規模な人間評価を実施します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Encoders Help You Disambiguate Word Senses in Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_29.html">
      Encoders Help You Disambiguate Word Senses in Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、注意の重みと注意のエントロピーは、自己注意があいまいな名詞を検出し、コンテキストへの注意を分散できることを示しています。このホワイトペーパーでは、NMTエンコーダーとデコーダーが隠された状態を評価し、自己注意の分布..エンコーダの隠し状態は、単語の埋め込みを大幅に上回ることがわかります。これは、エンコーダが関連情報を適切にエンコードして隠し状態にエンコードすることを示しています。 
[ABSTRACT]復号化により、曖昧性解消に関連性の高い情報が提供される可能性があります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-30">
        <br>2019-08-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Singing Synthesis: with a little help from my attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_30.html">
      Singing Synthesis: with a little help from my attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これにもかかわらず、それは以前の神経歌合成モデルと比較して自然さの強い改善を示しています。しかし、明示的な持続時間モデリングを完全に省くと、テンポに正確に一致するために必要なタイミングの細かい制御を取得することが難しくなることがわかります曲の..モデルは、入力として期間やピッチパターンを必要とせず、ビブラートを音楽的なコンテキストに従って自律的に挿入することを学習します。 
[ABSTRACT]システムは、文献の以前のモデルよりも明確なモデリングを必要としません。モデルは、期間を必要としませんが、音楽的文脈に従って因果的にビブラートを挿入することを学習します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-12">
        <br>2019-12-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multitask Models for Supervised Protests Detection in Texts -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_31.html">
      Multitask Models for Supervised Protests Detection in Texts
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      3つのタスクには、記事の分類、文の検出、およびイベント抽出が含まれます。これらのタスクの2つと3つの予測を同時に生成できるマルチタスクニューラルネットワークを適用します。CLEF2019 ProtestNews Labは、参加者に、より大きなコーパス内の政治的抗議に関連するテキストを特定するようにタスクを割り当てますニュースデータの。 
[ABSTRACT]マルチタスクフレームワークにより、モデルは3つすべてのタスクのデータから関連機能を学習できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Graph-Embedding Empowered Entity Retrieval -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_32.html">
      Graph-Embedding Empowered Entity Retrieval
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの分析は、クラスターの仮説をさらに展開して、エンティティのランク付けを含むユーザータスクに対して、広く使用されている単語の埋め込みよりもグラフの埋め込みの利点を説明しています。この論文では、グラフの埋め込みがエンティティ指向の検索タスクに役立つことを示しています。 、グラフの埋め込みを使用して結果リストを再ランク付けすることにより、エンティティー検索における現在の最先端技術を改善します。 
[ABSTRACT]ペーパーペーパーペーパーは、埋め込みの埋め込みが検索に役立つことを示しています。このペーパーのペーパーペーパーは、以来ペーパーペーパーとなっています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Autoencoding Pixies: Amortised Variational Inference with Graph
  Convolutions for Functional Distributional Semantics -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/cs.CL/paper_33.html">
      Autoencoding Pixies: Amortised Variational Inference with Graph
  Convolutions for Functional Distributional Semantics
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      関数型分布セマンティクスは、単語の意味をベクトルではなく関数（バイナリ分類子）として表すことにより、分布セマンティクスの言語学的に解釈可能なフレームワークを提供します。これにより、モデルをより効果的にトレーニングし、2つのタスクでより良い結果を得ることができます。 （コンテキストと意味的構成の意味的類似性）、および事前トレーニング済みの大規模な言語モデルであるBERTを上回ります。ただし、潜在変数の数が多いということは、推論の計算コストが高く、モデルのトレーニングが収束に時間がかかることを意味します。 
[ABSTRACT]言語モデルである意味的類似性は、より複雑であることを意味します。これにより、モデルをより効果的にトレーニングできます。ただし、潜在変数が多いため、予測が難しくなります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br>2020-05-06
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: An investigation of phone-based subword units for end-to-end speech
  recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/eess.AS/paper_0.html">
      An investigation of phone-based subword units for end-to-end speech
  recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Switchboardの場合、電話ベースのBPEシステムは、テストセットのSwitchboard / CallHome部分で6.8％/ 14.4％のワードエラーレート（WER）を達成し、アンサンブルシステムは6.3％/ 13.3％のWERを達成しています。簡単に利用できるこのシステムでは、従来のシステムからの専門知識や処理手順を追加する必要がありません。実験結果から、電話ベースのBPEは文字ベースのBPEよりも正確な認識システムにつながり、さらに改善することができます。新しく開発されたワンパスビームサーチデコーダー。電話ベースと文字ベースの両方のBPEシステムを効率的に組み合わせます。 
[要約]電話は文字ベースの対応システムよりも正確な認識システムにつながります。新しいワンパスビーム検索デコーダーは、電話ベースと文字ベースの両方のbpeシステムを組み合わせたものです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Self-supervised Learning of Visual Speech Features with Audiovisual
  Speech Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/eess.AS/paper_1.html">
      Self-supervised Learning of Visual Speech Features with Audiovisual
  Speech Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この発見の興味深い副産物は、学習した視覚埋め込みを他の視覚音声アプリケーションの機能として使用できることです。口形素（音素に対する視覚の類推）を分類するための学習した視覚表現の有効性を示します。視聴覚音声強調の重要な側面、およびそのようなモデルを視覚音声アプリケーションの自己監視タスクに使用する方法を示します。 
[要約]口形素を分類するための学習された視覚表現の有効性を実証しました（音素への視覚的な類似）
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-25">
        <br>2020-04-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Seeing voices and hearing voices: learning discriminative embeddings
  using cross-modal self-supervision -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/eess.AS/paper_2.html">
      Seeing voices and hearing voices: learning discriminative embeddings
  using cross-modal self-supervision
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この方法の有効性は、2つの下流タスクで実証されます。オーディオビジュアル同期でトレーニングされた機能を使用した口読み、およびクロスモーダルバイオメトリックマッチング用にトレーニングされた機能を使用した話者認識です。重要なマージンによる自己監視ベースライン。この作業の目標は、手動で注釈を付けたデータにアクセスせずに、特徴的なクロスモーダル埋め込みをトレーニングすることです。 
[要約]提案された方法は、最先端の自己監視ベースラインを重要なマージンで識別するために使用できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Singing Synthesis: with a little help from my attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-07/eess.AS/paper_3.html">
      Singing Synthesis: with a little help from my attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これにもかかわらず、それは以前の神経歌合成モデルと比較して自然さの強い改善を示しています。UTACOは、注意が歌声合成フィールドにうまく適用され、最先端の自然さを改善できることを示しています。これらの2つのクラスのモデルには、音声合成の分野に大きな影響を与えましたが、歌声の合成のタスクに完全に適用されたことはありません。 
[ABSTRACT]システムは、文献の以前のモデルよりも明確なモデリングを必要としません。モデルは、期間を必要としませんが、音楽的文脈に従って因果的にビブラートを挿入することを学習します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-12">
        <br>2019-12-12
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本日更新された論文はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br>
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
