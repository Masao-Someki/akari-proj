<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-10-29の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Melody-Conditioned Lyrics Generation with SeqGANs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.SD/paper_0.html">
      <font color="black">Melody-Conditioned Lyrics Generation with SeqGANs</font>
    </a>
  </h2>
  <font color="black">入力条件が評価メトリックに悪影響を及ぼさない一方で、ネットワークがより意味のある結果を生成できることを示します。さらに、追加の入力条件（歌詞のテーマまたは包括的なトピック）を使用してジェネレーターのパフォーマンスを調査します。ただし、既存のアプローチの多くは、音楽や歌詞の作成に関する事前の知識に大きく依存しているか、メロディックな情報とそのテキストとの関係を大幅に破棄することでタスクを単純化しすぎています。 
[ABSTRACT]初期のルール-データに基づく---テキストメッセージに基づく。システムは、入力として対応するメロディーを指定して歌詞の行を生成します。入力条件が評価メトリックに悪影響を与えないことを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: PPG-based singing voice conversion with adversarial representation
  learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.SD/paper_1.html">
      <font color="black">PPG-based singing voice conversion with adversarial representation
  learning</font>
    </a>
  </h2>
  <font color="black">音色とメロディーのパフォーマンスを向上させるために、敵対的な歌手の混乱モジュールとメル回帰表現学習モジュールがモデル用に設計されています。客観的および主観的な実験は、私たちのプライベートな中国の歌唱コーパスで行われます。具体的には、2つの別々のエンコーダーを実装します。 ：1つはPPGをコンテンツとしてエンコードし、もう1つはメルスペクトログラムを圧縮して音響および音楽情報を提供します。 
[概要]自然とイントネーションを保ちながら曲を変換するために新しいモデルが使用されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Decoupling Pronunciation and Language for End-to-end Code-switching
  Automatic Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.SD/paper_2.html">
      <font color="black">Decoupling Pronunciation and Language for End-to-end Code-switching
  Automatic Speech Recognition</font>
    </a>
  </h2>
  <font color="black">一方、トレーニングプロセス中に、単一のオーディオデータの複数の電話シーケンス候補をリアルタイムで生成します。モデルは、オーディオから電話（A2P）ネットワークと電話からテキスト（P2T）ネットワークの2つの部分に分離されます。最後に、2つのネットワークは、アテンションフュージョンによって共同で最適化されます。 
[ABSTRACT]分離トランスモデルは、単言語のペアデータの使用を提案します。コードへの高い依存性を低減します-ペアのトレーニングデータを切り替えます。提案された方法は、パブリックマンダリンで提案されます-英語のコード切り替えミックス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Large-Scale MIDI-based Composer Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.SD/paper_3.html">
      <font color="black">Large-Scale MIDI-based Composer Classification</font>
    </a>
  </h2>
  <font color="black">畳み込みリカレントニューラルネットワークをモデルとして使用することにより、MIDIベースの作曲家分類システムは0.648と0.385（30秒のクリップで評価）および0.739と0.489（楽曲で評価）の10作曲家と100作曲家の分類精度を達成します。それぞれ..入力表現としてピアノロール、オンセットロール、速度ロールを使用し、分類器としてディープニューラルネットワークを使用することを提案します。当社のMIDIベースの作曲家システムは、いくつかのオーディオベースのベースライン分類システムよりも優れており、コンパクトなMIDI表現を使用することの有効性を示しています。作曲家の分類用。 
[ABSTRACT]作曲家分類システムは最大100人の作曲家の問題です。システムはいくつかのオーディオベースのベースライン分類システムよりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Speech Synthesis and Control Using Differentiable DSP -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.SD/paper_4.html">
      <font color="black">Speech Synthesis and Control Using Differentiable DSP</font>
    </a>
  </h2>
  <font color="black">この作業では、さまざまな変動要因を明示的に制御できるようにすることで、テキストの多様な音声表現を生成できる音声合成システムに移行します。最新のテキスト読み上げシステムは、自然で高い音声合成を生成できます。 -質の高い音声ですが、音声には変動要因が含まれています（たとえば、このような変動要因を制御できる新しいニューラルボコーダーを提案します。
[概要]提案されたアプローチでは、リアルな音色の自然な音声を生成できます。個々の変動要因は自由に制御できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Audio Fingerprint for High-specific Audio Retrieval based on
  Contrastive Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.SD/paper_5.html">
      <font color="black">Neural Audio Fingerprint for High-specific Audio Retrieval based on
  Contrastive Learning</font>
    </a>
  </h2>
  <font color="black">この作業では、オーディオの短い単位セグメントから低次元表現を生成し、このフィンガープリントを高速の最大内積検索と結合します。従来のオーディオフィンガープリントシステムが失敗していたセグメントレベルの検索タスクで、10分の1のストレージを使用するシステムは、有望な結果を示しています。これらのレプリカは、小さな時間オフセットと、バックグラウンドノイズや部屋/マイクのインパルス応答などのさまざまなタイプの歪みを適用することにより、元のオーディオ信号への劣化効果をシミュレートできます。 
[概要]この作業では、オーディオの短い単位セグメントから低次元を生成します。このフィンガープリントを使用して、高速の最大内積検索を作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-22">
        <br><font color="black">2020-10-22</font>
      </time>
    </span>
</section>
<!-- paper0: Toward Speech Separation in The Pre-Cocktail Party Problem with TasTas -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.SD/paper_6.html">
      <font color="black">Toward Speech Separation in The Pre-Cocktail Party Problem with TasTas</font>
    </a>
  </h2>
  <font color="black">公開WSJ0-5mixデータコーパスでの実験の結果、SDRが10.41dB向上しました。このノートでは、カクテルパーティー前のモノラル音声分離へのエンドツーエンドアプローチにTasTas \ cite {shi2020speech}を使用することを提案します。問題..https：//github.com/ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separationでDPRNN-TasNetの再実装をオープンソース化し、これに基づいてTasTasを実現しています。 DPRNN-TasNetの実装により、このペーパーの結果は簡単に再現できると考えられます。 
[概要]公開wsj0-5mixデータコーパスでの実験の結果は10です。41dbsdrの改善。このペーパーの結果は簡単に再現できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Optimizing Short-Time Fourier Transform Parameters via Gradient Descent -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.SD/paper_7.html">
      <font color="black">Optimizing Short-Time Fourier Transform Parameters via Gradient Descent</font>
    </a>
  </h2>
  <font color="black">これは、入力全体で一定に保たれるパラメーター値だけでなく、さまざまな信号特性に対応するためにこれらのパラメーターが時間の経過とともに動的に変化する必要がある場合にも行われます。短時間フーリエ変換（STFT）は、信号処理の定番です。多くの場合、多くのオーディオタスクの最初のステップになります。これらのパラメータは、多くの場合、整数のサンプルで定義されるため、最適化は簡単ではありません。 
[概要]シンプルでシンプルなシステムを使用して、最高のスタリーを検索します。stftやstftなどの音楽的に有用な有用な要素</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: INT8 Winograd Acceleration for Conv1D Equipped ASR Models Deployed on
  Mobile Devices -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.SD/paper_8.html">
      <font color="black">INT8 Winograd Acceleration for Conv1D Equipped ASR Models Deployed on
  Mobile Devices</font>
    </a>
  </h2>
  <font color="black">量子化とWinograd畳み込みの組み合わせによる情報損失を回避するために、範囲スケール量子化（RSQ）トレーニング方法を提案して、量子化された数値範囲を拡大し、高精度値から知識を抽出します。自動音声の集中計算認識（ASR）モデルは、モバイルデバイスへの展開を妨げます。ConvDFSMNモデルとWav2letterモデルの両方で広範な実験を実施します。 
[概要]この記事の新しいバージョンが新しい論文で発表されました。量子化と高速畳み込みを組み合わせて、asrモデルのモバイルデバイスで効率の加速を実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: FT Speech: Danish Parliament Speech Corpus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.SD/paper_9.html">
      <font color="black">FT Speech: Danish Parliament Speech Corpus</font>
    </a>
  </h2>
  <font color="black">コーパスの品質を評価するために、新しいリソースで自動音声認識システムをトレーニングし、これまでデンマークで最大のパブリックASRコーパスであるSpr \ r {a} kbankenのデンマークの部分でトレーニングされたシステムと比較します。は、FTスピーチがより自発的なスピーチでデンマークのASRの研究を促進するための貴重なリソースを提供することを示しています。ベースラインの結果は、新しいコーパスで14.01WERを達成することを示しています。 
[概要]新しいコーパスには、1,800フィートを超える既存の音声が含まれています。800時間以上の古い音声が含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-25">
        <br><font color="black">2020-05-25</font>
      </time>
    </span>
</section>
<!-- paper0: Seen and Unseen emotional style transfer for voice conversion with a new
  emotional speech dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.SD/paper_10.html">
      <font color="black">Seen and Unseen emotional style transfer for voice conversion with a new
  emotional speech dataset</font>
    </a>
  </h2>
  <font color="black">このようにして、ネットワークは、目に見える感情スタイルと目に見えない感情スタイルの両方を新しい発話に移すことができます。この論文では、変分自動エンコードWasserstein生成的敵対ネットワーク（VAW-GAN）に基づく新しいフレームワークを提案します。トレーニング中および実行時の推論時に感情的なスタイルを転送するための事前トレーニング済み音声感情認識（SER）モデルの使用。提案されたフレームワークが、ベースラインフレームワークを一貫して上回ることにより、優れたパフォーマンスを達成することを示します。 
[概要]以前の研究では、エンコーダー-デコーダーネットワークを使用して感情的なプロソディを解きほぐすことが可能であることが示されています。提案されたフレームワークは、トレーニング中に感情的なスタイルを転送するために事前にトレーニングされた音声感情認識モデルを利用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Non-Autoregressive Transformer ASR with CTC-Enhanced Decoder Input -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.SD/paper_11.html">
      <font color="black">Non-Autoregressive Transformer ASR with CTC-Enhanced Decoder Input</font>
    </a>
  </h2>
  <font color="black">この問題に対処するために、CTCモジュールの予測を精緻化することによってターゲットシーケンスを生成するCTC拡張NARトランスフォーマーを提案します。実験結果は、私たちの方法が以前のすべてのNARの対応物よりも優れており、強力なARベースラインよりも50倍速いデコード速度を達成することを示しています。 Aishell-1およびAishell-2データセットでの絶対CER劣化はわずか0.0〜0.3です。非自動回帰（NAR）トランスフォーマーモデルは、大幅な推論速度の向上を達成しましたが、自動音声認識の自動回帰（AR）モデルと比較して精度が劣ります（ ASR）。 
[ABSTRACT] ctの方法は、以前のすべてのnarモデルよりも優れており、ターゲット側のデコード速度が0. 0. 0.0の50倍高速になっています。 0.3aishell-1およびaishell-2データセットでの絶対cer劣化</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Window Data Augmentation Approach for Speech Emotion Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.SD/paper_12.html">
      <font color="black">Multi-Window Data Augmentation Approach for Speech Emotion Recognition</font>
    </a>
  </h2>
  <font color="black">IEMOCAPコーパスでのMWA-SERアプローチのパフォーマンスを評価し、提案された方法が最先端の結果を達成することを示します。マルチウィンドウ拡張方法は、複数のウィンドウサイズを使用することにより、音声信号からより多くのオーディオ機能を抽出します。さらに、提案されたシステムは、SAVEEおよびRAVDESSデータセットの感情を認識しながら、それぞれ70％および88％の精度を示しました。 
[概要]提案された拡張方法を深層学習モデルと組み合わせることで、音声感情認識パフォーマンスが向上することを示します。提案されたシステムは、saveeおよびravdessデータセットの感情を認識しながら、70％および88％の精度を示しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-19">
        <br><font color="black">2020-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: CASS-NAT: CTC Alignment-based Single Step Non-autoregressive Transformer
  for Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.SD/paper_13.html">
      <font color="black">CASS-NAT: CTC Alignment-based Single Step Non-autoregressive Transformer
  for Speech Recognition</font>
    </a>
  </h2>
  <font color="black">推論中に、エラーベースのアライメントサンプリング法をCTC出力空間に適用して、WERを削減し、並列性も維持することが提案されています。実験結果は、提案された方法がLibrispeechテストで3.8％/ 9.1％のWERを達成することを示しています。外部LMのないクリーン/その他のデータセット、およびAishell1北京語コーパスでそれぞれ5.8％のCER1 ..この情報は、各トークンの音響表現を並列に抽出するために使用されます。これは、埋め込みという単語を置き換えるトークンレベルの音響埋め込みと呼ばれます。自己回帰変換器（AT）で、デコーダーでの並列生成を実現します。 
[概要] ctcアライメントには、デコーダー入力用のトークンの数の情報が含まれます。これには、各トークンの音響の期間が含まれます。提案された方法は、ctcの音声空間に適用されることが提案されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: An Improved Event-Independent Network for Polyphonic Sound Event
  Localization and Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.SD/paper_14.html">
      <font color="black">An Improved Event-Independent Network for Polyphonic Sound Event
  Localization and Detection</font>
    </a>
  </h2>
  <font color="black">サウンドイベントのタイプと発生時間、および対応するDoA角度を同時に検出します。マルチヘッド自己注意をさらに使用してトラックを分離します。提案された方法をイベント独立ネットワークV2（EINV2）と呼びます。以前に提案された方法の改良版とSELDのエンドツーエンドネットワーク。 
[概要]このペーパーでは、2つの未解決の問題が取り上げられています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-25">
        <br><font color="black">2020-10-25</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Dynamic Point Cloud Denoising via Manifold-to-Manifold Distance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.IV/paper_0.html">
      <font color="black">Dynamic Point Cloud Denoising via Manifold-to-Manifold Distance</font>
    </a>
  </h2>
  <font color="black">特に、グラフ演算子がリーマン多様体の汎関数の離散対応物である場合、時間領域の表面パッチ間の変動ベースの固有距離を測定するために、グラフ上で多様体から多様体までの距離とその離散対応物を定義します。点群は、動いている実世界のオブジェクトやシーンの自然な離散表現を提供し、没入型テレプレゼンス、自律運転、監視などの幅広いアプリケーションを提供します。静的な点群のノイズ除去には、多数の方法が提案されていますが、動的な点群のノイズ除去にはほとんど努力が払われていませんが、空間的および時間的の両方で不規則なサンプリングパターンがあるため非常に困難です。 
[概要]この論文では、動的な点群を空間-熱グラフで自然に表現します。これらには、ハブなどの領域の有用な表現が含まれます。この記事では、さまざまな場面で見られる雲を作成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-17">
        <br><font color="black">2020-03-17</font>
      </time>
    </span>
</section>
<!-- paper0: Medical Deep Learning -- A systematic Meta-Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.IV/paper_1.html">
      <font color="black">Medical Deep Learning -- A systematic Meta-Review</font>
    </a>
  </h2>
  <font color="black">この開発が大きな可能性を示しているもう1つの分野は、医療分野です。一般に、特定の病状を含む医用画像の分析など、特定の医療シナリオに焦点を当てています。ディープラーニングが人間よりも優れているアプリケーションもあります。オブジェクト認識またはゲーム。 
[概要]ディープラーニングアルゴリズムは、画像処理や分析においても、最先端の手法を上回ることができました。オブジェクト認識やゲームなど、ディープラーニングが人間を上回ったアプリケーションもあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Forgery Blind Inspection for Detecting Manipulations of Gel
  Electrophoresis Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.IV/paper_2.html">
      <font color="black">Forgery Blind Inspection for Detecting Manipulations of Gel
  Electrophoresis Images</font>
    </a>
  </h2>
  <font color="black">\ textbf {PUBPEER}で一般市民から質問されたいくつかの論文にFBI $ _ {GEL} $を適用しました。その結果、これらの論文の図には、疑わしい不自然なパターンが実際に含まれていることがわかりました。ローカルを強調表示できる最適化された疑似背景に基づく残留物、FBI $ _ {GEL} $は、WB / PCR画像の不適切な局所的変更を示唆する追跡可能な痕跡を明らかにする可能性があります。最近、偽造された画像が研究の不正行為に関係する論文で発見されました。 
[ABSTRACT] fbi $ `gel &#39;は、wb / pcr画像の不適切なローカル変更を示唆する追跡可能な痕跡を明らかにする可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Diverse R-PPG: Camera-Based Heart Rate Estimation for Diverse Subject
  Skin-Tones and Scenes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.IV/paper_3.html">
      <font color="black">Diverse R-PPG: Camera-Based Heart Rate Estimation for Diverse Subject
  Skin-Tones and Scenes</font>
    </a>
  </h2>
  <font color="black">暗い肌の色調のベンチマークよりも毎分0.69ビートのパフォーマンスの向上と、すべての肌の色調で0.47 bpmの全体的な改善を報告します。肌の色調の偏りを軽減することに加えて、提案された方法が照明の変化によるエラーを軽減することを示します。 、影、および鏡面ハイライト.. COVID-19の大流行により、臨床の開発と展開が加速し、リモートバイタルサインモニタリングが近年注目を集めています。 
[概要]提案された方法は、フォトプレチスモグラフィーのストレスを軽減することによって提案されています。レポートによると、この方法はデータセット全体で全体的にトップパフォーマーです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-24">
        <br><font color="black">2020-10-24</font>
      </time>
    </span>
</section>
<!-- paper0: Deep neural network for fringe pattern filtering and normalisation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.IV/paper_4.html">
      <font color="black">Deep neural network for fringe pattern filtering and normalisation</font>
    </a>
  </h2>
  <font color="black">この論文の主な貢献は次のとおりです。（1）FP正規化タスクにU-netニューラルネットワークアーキテクチャを使用することを提案します。 （2）U-netの重み分布の修正を提案し、ここではV-netモデルと呼びます。これは、再構築タスクにより便利です。また、V-netが高品質を生成するという広範な実験的証拠を実施します。 FPフィルタリングと正規化の結果..実験結果（合成データと実際のデータの両方）は、インターフェログラムを処理するためのこの新しいパラダイムの機能と可能性を示しています。（3）V-netスキームの2つの変更、つまり、提案を変更する際の潜在的な改善を評価するための、ResV-netと呼ばれる残りのバージョンとV-netの高速動作バージョン。 
[概要]私たちの新しいアプローチは、ディープニューラルネットワークによってfpsを学習できるという理論に基づいています。提案を変更するときに潜在的な改善を評価するために、v-netスキームの2つの変更を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-14">
        <br><font color="black">2019-06-14</font>
      </time>
    </span>
</section>
<!-- paper0: Enhancing MRI Brain Tumor Segmentation with an Additional Classification
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.IV/paper_5.html">
      <font color="black">Enhancing MRI Brain Tumor Segmentation with an Additional Classification
  Network</font>
    </a>
  </h2>
  <font color="black">BraTSの検証セットでは、増強腫瘍、腫瘍全体、および腫瘍コアについて、それぞれ78.43％、89.99％、および84.22％の平均ダイススコアを達成しました。この論文では、増強する新しいトレーニング方法を提案します。ネットワークに分類ブランチを追加することにより、セグメンテーションが行われます。最近の研究では、ディープコンボリューションニューラルネットワーク（DCNN）は、腫瘍のセグメンテーションタスクに取り組むのに非常に強力です。 
[要約]最近の研究では、深い畳み込みニューラルネットワーク（dcnns）は、腫瘍のセグメンテーションタスクに取り組むのに強力です。ネットワーク全体がトレーニングされました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-25">
        <br><font color="black">2020-09-25</font>
      </time>
    </span>
</section>
<!-- paper0: An Attention Mechanism with Multiple Knowledge Sources for COVID-19
  Detection from CT Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.IV/paper_6.html">
      <font color="black">An Attention Mechanism with Multiple Knowledge Sources for COVID-19
  Detection from CT Images</font>
    </a>
  </h2>
  <font color="black">広範な実験は、最近のベースラインと比較して、私たちのアプローチの優れたパフォーマンスを示しています。具体的には、学習されたネットワークから抽出された感染領域とヒートマップは、学習プロセス中に注意メカニズムを介してグローバル画像と統合されます。この手順は、システムをより多くするだけではありません。ノイズに対してロバストであるだけでなく、局所的な病変領域に焦点を当てたネットワークをガイドします。 
[概要] covid-19の早期診断は時期尚早である可能性があります。これらのアプローチは主に、新しいアーキテクチャの導入、学習手法の伝達、または大規模データの構築に焦点を当てています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-23">
        <br><font color="black">2020-09-23</font>
      </time>
    </span>
</section>
<!-- paper0: Real-time Tropical Cyclone Intensity Estimation by Handling Temporally
  Heterogeneous Satellite Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.IV/paper_7.html">
      <font color="black">Real-time Tropical Cyclone Intensity Estimation by Handling Temporally
  Heterogeneous Satellite Data</font>
    </a>
  </h2>
  <font color="black">実験結果は、ハイブリッドGAN-CNNフレームワークが、最大推定頻度を3時間から15分未満に増やす機能を備えながら、最先端のモデルと同等の精度を達成することを示しています。したがって、新しい提案を行います。生成的敵対的ネットワーク（GAN）とCNNを組み合わせたフレームワーク。一方、可視（VIS）チャネルは、ノイズと日光の強度の影響を強く受け、利用が困難になります。 
[ABSTRACT]畳み込みニューラルネットワーク（cnn）は、衛星データに基づいて熱帯低気圧（tc）の強度を推定することに大きな成功を収めています。これらの要因には、赤外線（ir1）および水蒸気（wv）画像が含まれます。これらの画像は15分ごとに利用できます。一方、パッシブマイクロ波雨量（pmw）は約3時間ごとに利用可能です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: When Deep Learning Meets Data Alignment: A Review on Deep Registration
  Networks (DRNs) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.IV/paper_8.html">
      <font color="black">When Deep Learning Meets Data Alignment: A Review on Deep Registration
  Networks (DRNs)</font>
    </a>
  </h2>
  <font color="black">最後に、4）これは、従来のアプローチに影響を与える問題に対処できる一般的な解決策に到達するために依然として多大な努力を必要とする若いトピックです。結果の精度は複数の要因に依存します。最も重要なのは入力データの量です。 、ノイズの存在、外れ値とオクルージョン、抽出された特徴の品質、リアルタイムの要件、変換のタイプ、特に非剛体変形などの複数のパラメータによって定義されたもの。2）これらのアプローチにより、より複雑な入力が可能になります。概念モデルや従来の3Dデータセットのように。 
[概要]プロセスは、ターゲットの選択、特徴抽出、特徴マッチング、変換コンピューティングの4つの主要なステップに分けることができます。主なアプローチは、複数のコンピュータービジョンの問題を改善するのに役立つ深層学習（dl）技術の開発です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-06">
        <br><font color="black">2020-03-06</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Adversarial Networks in Human Emotion Synthesis:A Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.IV/paper_9.html">
      <font color="black">Generative Adversarial Networks in Human Emotion Synthesis:A Review</font>
    </a>
  </h2>
  <font color="black">このようなモデルのアプリケーションには、感情の認識と分類、ユニモーダル感情合成、クロスモーダル感情合成が含まれますが、これらに限定されません。現実的なデータサンプルを合成することは、学術界と産業界の両方にとって大きな価値があります。利用可能なデータベース、生成モデルの長所と短所、および2つの主要な人間のコミュニケーションモダリティ、つまりオーディオとビデオを考慮した関連するトレーニング戦略を研究することによる、人間の感情合成における最近の進歩のレビュー。 
[要約]人間の感情合成の研究は、生殖器モデルがどれほど深く出現しているかを示しています。これらのモデルが新たなトピックになったのはこれが初めてです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Classification Beats Regression: Counting of Cells from Greyscale
  Microscopic Images based on Annotation-free Training Samples -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.IV/paper_10.html">
      <font color="black">Classification Beats Regression: Counting of Cells from Greyscale
  Microscopic Images based on Annotation-free Training Samples</font>
    </a>
  </h2>
  <font color="black">さらに、細胞数間の序数関係は利用されません。このフレームワークでは、細胞数がクラスラベルとして扱われる画像分類問題として細胞数カウントタスクを定式化します。この定式化には、一部の細胞数がテスト段階はトレーニングデータに表示されません。 
[概要]コンセプトは分類に基づいています-目的の畳み込みニューラルネットワーク（cnns）。注釈付きのトレーニング画像を使用せずに、グレースケールの顕微鏡画像から細胞をカウントするために使用できます。フレームワークは、多くの最新の細胞カウント方法よりも優れており、データ分析の競争に勝ちました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: A Transfer Learning Approach for Automated Segmentation of Prostate
  Whole Gland and Transition Zone in Diffusion Weighted MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.IV/paper_11.html">
      <font color="black">A Transfer Learning Approach for Automated Segmentation of Prostate
  Whole Gland and Transition Zone in Diffusion Weighted MRI</font>
    </a>
  </h2>
  <font color="black">拡散強調MRI（DWI）での前立腺全腺と遷移ゾーンのセグメンテーションは、前立腺癌のコンピューター支援検出アルゴリズムを設計する最初のステップです。DWI画像で前立腺全腺と遷移ゾーンの輪郭を描くことは時間と費用がかかります。したがって、ソースドメインの画像で事前トレーニングされたCNNを有効にして、ターゲットドメインからの画像の手動セグメンテーションの最小要件でターゲットドメインの画像をセグメント化できるようにすることが重要です。 
[概要]この感度により、ソースコホートでトレーニングされ、別のスキャナーからのターゲットコホートでテストされたcnnのセグメンテーションパフォーマンスが低下します。ただし、MRI取得パラメーターとアーキテクチャのネットワークにより、画像内の前立腺組織の外観が異なります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-20">
        <br><font color="black">2019-09-20</font>
      </time>
    </span>
</section>
<!-- paper0: A Deep Unsupervised Feature Learning Spiking Neural Network with
  Binarized Classification Layers for EMNIST Classification using SpykeFlow -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.IV/paper_12.html">
      <font color="black">A Deep Unsupervised Feature Learning Spiking Neural Network with
  Binarized Classification Layers for EMNIST Classification using SpykeFlow</font>
    </a>
  </h2>
  <font color="black">勾配降下（バックプロパゲーション）は、分類のトレーニングを実行するために出力層でのみ使用されます。バランスの取れたEMNISTデータセットで得られた精度は、他のアプローチと比べて遜色ありません。この作業では、スパイキングニューラルネットワークを使用してこれにアプローチします。 
[概要]スパイクタイミングに依存する可塑性の教師なし学習手法を使用して、スパイク入力データから特徴を抽出します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-26">
        <br><font color="black">2020-02-26</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Model Rubik's Cube: Twisting Resolution, Depth and Width for TinyNets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_0.html">
      <font color="black">Model Rubik's Cube: Twisting Resolution, Depth and Width for TinyNets</font>
    </a>
  </h2>
  <font color="black">この目的のために、FLOPS制約を使用してEfficientNet-B0から派生した一連の小さなモデルを通じて、ニューラルアーキテクチャをダウンサイジングするための小さな式を要約します。これにより、3次元をねじることにより、高効率で優れたパフォーマンスのネットワークを見つけることができます。たとえば、TinyNet-Eはわずか2400万フロップスで59.9％のトップ1精度を達成します。これは、同様の計算コストで以前の最高のMobileNetV3よりも約1.9％高くなっています。 
[概要]解像度、深さ、幅を同時に拡大するためのジャイアントネット式は、ニューラルネットワーク用のルービックキューブを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic Point Cloud Denoising via Manifold-to-Manifold Distance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_1.html">
      <font color="black">Dynamic Point Cloud Denoising via Manifold-to-Manifold Distance</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案された方法が、ガウスノイズとシミュレートされたLiDARノイズの両方で、最先端の静的点群ノイズ除去アプローチからの各フレームの独立したノイズ除去よりも大幅に優れていることを示しています。特に、マニホールドからマニホールドまでの距離を定義します。グラフ演算子がリーマンマニフォールド上の汎関数の離散対応物である場合、時間領域の表面パッチ間の変動ベースの固有距離を測定するためのグラフ上の離散対応物。静的点群ノイズ除去のために多数の方法が提案されていますが、動的な点群のノイズ除去にはほとんど努力が払われていませんが、空間的および時間的の両方で不規則なサンプリングパターンがあるため、非常に困難です。 
[概要]この論文では、動的な点群を空間-熱グラフで自然に表現します。これらには、ハブなどの領域の有用な表現が含まれます。この記事では、さまざまな場面で見られる雲を作成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-17">
        <br><font color="black">2020-03-17</font>
      </time>
    </span>
</section>
<!-- paper0: Transferable Universal Adversarial Perturbations Using Generative Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_2.html">
      <font color="black">Transferable Universal Adversarial Perturbations Using Generative Models</font>
    </a>
  </h2>
  <font color="black">これにより、生成されたUAPを他のターゲットモデルに転送できるようになります。ただし、既存のUAPは、未知のターゲットモデルに適用された場合でも、十分に高いフールレートが不足しています。フールレートとモデルの転送可能性、提案されたアプローチの優位性を示すことができます。 
[概要]画像の存在-普遍的な敵対的摂動（uaps）としても知られる認識摂動が発見されました。これらの摂動は、さまざまなターゲットモデルに対して非常によく一般化されます。生成された非ターゲットuapを使用すると、93の平均だまし率が得られます。 。ソースモデルで36％</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Disentangling neural mechanisms for perceptual grouping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_3.html">
      <font color="black">Disentangling neural mechanisms for perceptual grouping</font>
    </a>
  </h2>
  <font color="black">視覚シーンで知覚グループを形成し、オブジェクトを個別化することは、ビジュアルインテリジェンスに向けた重要なステップです。水平接続は、増分グループ化をサポートすることでゲシュタルトキューを使用したタスクの負担を解決しますが、トップダウン接続は、粗いものを変更することで、高レベルのオブジェクトキューを使用したタスクの学習を支援しますターゲットオブジェクトの位置に関する予測..私たちの調査結果は、ボトムアップ、水平、トップダウンの接続性の計算上の役割を分離し、これらすべての相互作用を特徴とするモデルが知覚グループを形成することをより柔軟に学習できることを示しています。 
[要約]この能力は、ニューロン間のボトムアップ、水平、トップダウンの接続によって実装されたグループで発生すると考えられています。接続は、知覚的グループ化のための低レベルの「ゲシュタルト」対高レベルのオブジェクトキューを強調します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-04">
        <br><font color="black">2019-06-04</font>
      </time>
    </span>
</section>
<!-- paper0: Dual-Resolution Correspondence Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_4.html">
      <font color="black">Dual-Resolution Correspondence Networks</font>
    </a>
  </h2>
  <font color="black">これらすべてで最先端の結果を達成します。このようにして、DualRC-Netは、高解像度のフィーチャマップに高価な4D畳み込みカーネルを適用することを回避しながら、マッチングの信頼性とローカリゼーションの精度を劇的に向上させます。DualRC -Netは、粗い解像度と細かい解像度の両方の特徴マップを抽出します。 
[要約]単純なマップを使用して、完全であるが不十分な4D相関コンポーネントを生成します。次に、学習可能な近隣コンセンサスモジュールによって洗練されます。高解像度機能は、限られた数の可能な一致にのみ焦点を当てることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-16">
        <br><font color="black">2020-06-16</font>
      </time>
    </span>
</section>
<!-- paper0: Class-Agnostic Segmentation Loss and Its Application to Salient Object
  Detection and Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_5.html">
      <font color="black">Class-Agnostic Segmentation Loss and Its Application to Salient Object
  Detection and Segmentation</font>
    </a>
  </h2>
  <font color="black">完全畳み込みResNet101およびDeepLab-v3アーキテクチャを使用したCAS損失関数を、顕著なオブジェクト検出のバイナリセグメンテーション問題に適用します。クラスa-prioriのラベルを定義する必要はなく、CAS損失クラスター領域を次のように定義します。弱く監視された方法で一緒に同様の外観..忠実度の低いトレーニングデータ（誤ったクラスラベル）の場合、クラスに依存しないセグメンテーション損失は、約50％のマージンをずらすことにより、顕著なオブジェクト検出データセットの最先端の方法よりも優れています。 
[概要] cas損失を使用すると、ネットワークのトレーニング中にクラス記述子が学習されます。cas損失関数がスパースで、困惑し、クラスが不均衡であることがわかります。低と2つの設定でstatenetメソッドに対するパフォーマンスを調査します。高-7つの顕著なオブジェクト検出データセットに関する忠実度のトレーニングデータ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Medical Deep Learning -- A systematic Meta-Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_6.html">
      <font color="black">Medical Deep Learning -- A systematic Meta-Review</font>
    </a>
  </h2>
  <font color="black">患者データは、病院などの臨床センターで収集されるだけでなく、ほんの数例を挙げると、一般開業医、ヘルスケアスマートフォンアプリ、またはオンラインWebサイトからのデータにも関連しています。大量の患者記録とデータの収集により、そして、パーソナライズされた治療への傾向により、この情報の自動で信頼性の高い処理と分析が大いに必要とされています。彼らは一般に、特定の病状を含む医療画像の分析など、特定の医療シナリオに焦点を当てました。 
[概要]ディープラーニングアルゴリズムは、画像処理や分析においても、最先端の手法を上回ることができました。オブジェクト認識やゲームなど、ディープラーニングが人間を上回ったアプリケーションもあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Image Representations Learned With Unsupervised Pre-Training Contain
  Human-like Biases -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_7.html">
      <font color="black">Image Representations Learned With Unsupervised Pre-Training Contain
  Human-like Biases</font>
    </a>
  </h2>
  <font color="black">昆虫や花のように無害なものから、人種や性別のように潜在的に有害なものまで、社会心理学から文書化された15の人間の偏見のうち8つを複製します。機械学習の最近の進歩は、ウェブからのラベルのない画像の膨大なデータセットを活用して学習します画像分類から顔認識までのタスクのための汎用画像表現..画像領域で初めて、肌の色調と体重に関する人間のようなバイアスを再現します。 
[概要]教師なしコンピュータービジョンモデルは、人種、性別、交差点の目的を学習します。imagenetでトレーニングされた教師なしモデルにはバイアスがかかっていることがわかります。初めて、肌のバイアスのように、人間の色調と体重を再現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Template Matching via Hierarchical Convolutional Features from a
  Shape Biased CNN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_8.html">
      <font color="black">Robust Template Matching via Hierarchical Convolutional Features from a
  Shape Biased CNN</font>
    </a>
  </h2>
  <font color="black">これらの結果を確認するために、新しいベンチマークも作成し、提案された方法がこの新しいデータセットの既存の手法よりも優れていることを示します。この記事では、CNNの形状情報のエンコードを強化することで、テンプレートのパフォーマンスを向上させる、より識別可能な機能を生成できるかどうかを調査します。マッチング..この調査の結果、標準ベンチマークで最先端の結果を生成する新しいテンプレートマッチング方法が得られました。 
[概要]新しいテンプレートマッチングメソッドが標準の標準ベンチマークでテストされています。新しいメソッドは畳み込みニューラルネットワーク（cnn）によって作成されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-31">
        <br><font color="black">2020-07-31</font>
      </time>
    </span>
</section>
<!-- paper0: SFU-Store-Nav: A Multimodal Dataset for Indoor Human Navigation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_9.html">
      <font color="black">SFU-Store-Nav: A Multimodal Dataset for Indoor Human Navigation</font>
    </a>
  </h2>
  <font color="black">108人の参加者からビジュアルデータとモーションキャプチャデータを収集しました。ビジュアルデータには実験のライブ記録が含まれ、モーションキャプチャデータには世界座標における人間の参加者の位置と向きが含まれます。実験は人間が買い物をするシナリオをシミュレートします。参加者は自分のショッピングリストからアイテムを拾いに来て、人間の参加者を助けるようにプログラムされたペッパーロボットと対話します。 
[概要]一連の実験は、カナダのブリティッシュコロンビア州バーナビーにあるコンピューティングサイエンスロボティクスラボで実施されました。自律型ロボットナビゲーションに関連する人間のナビゲーション意図を示す可能性のある一般的なジェスチャー、動き、その他の動作が含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Forgery Blind Inspection for Detecting Manipulations of Gel
  Electrophoresis Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_10.html">
      <font color="black">Forgery Blind Inspection for Detecting Manipulations of Gel
  Electrophoresis Images</font>
    </a>
  </h2>
  <font color="black">さらに、最適化された疑似バックグラウンドは閉じた形式のソリューションに従って導出されるため、FBI $ _ {GEL} $は計算効率が高く、WB / PCR画像の整合性に関する大規模な照会タスクに適しています。最近、偽造された画像がFBI $ _ {GEL} $は、局所的な残留物を強調することができる最適化された疑似背景に基づいて、WB / PCR画像の不適切な局所的な変更を示唆する追跡可能な痕跡を明らかにすることができます。 
[ABSTRACT] fbi $ `gel &#39;は、wb / pcr画像の不適切なローカル変更を示唆する追跡可能な痕跡を明らかにする可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Monocular Depth Estimation via Listwise Ranking using the Plackett-Luce
  Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_11.html">
      <font color="black">Monocular Depth Estimation via Listwise Ranking using the Plackett-Luce
  Model</font>
    </a>
  </h2>
  <font color="black">リストごとのランク付けは、オブジェクト間のペアごとの比較を超えて、トレーニング情報として任意の長さのランク付けを考慮します。「ゼロショット」設定でのベンチマークデータの経験的評価は、既存のランク付けおよび回帰方法と比較した提案の有効性を示します。は、ランキングの確率分布であるPlackett-Luceモデルに基づいています。これを、最先端のニューラルネットワークアーキテクチャおよびサンプリング戦略と組み合わせて、トレーニングの複雑さを軽減します。 
[概要]単眼画像の深度予測は、最近、機械学習手法を使用して解決されました。ランク付けは、確率レバーに基づいているという事実に基づいています。方法は、問題を53歳のモデルとして扱うために使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-25">
        <br><font color="black">2020-10-25</font>
      </time>
    </span>
</section>
<!-- paper0: Scaling Laws for Autoregressive Generative Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_12.html">
      <font color="black">Scaling Laws for Autoregressive Generative Modeling</font>
    </a>
  </h2>
  <font color="black">&quot;;（b）数学的問題解決の場合、トレーニング分布を超えて外挿するときにモデルパフォーマンスのスケーリング則を特定します。（c）ImageNet分類の生成画像モデルを微調整し、分類損失とエラー率のスムーズなスケーリングを見つけます。生成損失が横ばいになっても..クロスエントロピー損失には、$ S（$ True $）+ D _ {\ mathrm {KL}}（$ True $ || $ Model $）$としての情報理論的解釈があり、経験的なスケーリング則は、真のデータ分布のエントロピーと、真の分布とモデル分布の間のKL発散の両方の予測を示唆しています。まとめると、これらの結果は、スケーリング則がダウンストリームタスクを含むニューラルネットワークのパフォーマンスに重要な影響を与えるというケースを強化します。
[要約]モデルがモデルの8％を占めるため、モデル時間は改善されます。モデルは、サイズ、モデル、および力のあるモデルで見つけることができます-法則</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: CompRess: Self-Supervised Learning by Compressing Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_13.html">
      <font color="black">CompRess: Self-Supervised Learning by Compressing Representations</font>
    </a>
  </h2>
  <font color="black">私たちの知る限り、自己教師ありAlexNetがImageNet分類で教師ありを上回ったのはこれが初めてです。AlexNetの場合、私たちの方法は、ImageNet線形評価の完全教師ありモデルを含む以前のすべての方法を上回ります（56.5と比較して59.0％）。 ％）および最近傍評価（41.4％と比較して50.7％）。教師の埋め込みスペース内のデータポイント間の相対的な類似性を模倣するように、学生モデルをトレーニングします。 
[概要]最近の研究では、大きなモデルは小さなモデルよりも自己教師あり学習の恩恵を受けることが示されています。この作品では、すでに学習した深い自己教師ありモデル（教師）を小さなモデル（教師）に圧縮するモデル圧縮方法を開発します。学生）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Multiple Instance Learning for Airplane Detection in High
  Resolution Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_14.html">
      <font color="black">Deep Multiple Instance Learning for Airplane Detection in High
  Resolution Imagery</font>
    </a>
  </h2>
  <font color="black">これらの課題を解決するために、回転とスケールが不変の飛行機提案ジェネレーターを提示します。各飛行機は複数のSLS提案を持つことができ、一部は胴体の方向にないため、1つの地面に対応するすべての提案を収集します-真実はポジティブバッグとして、その他はネガティブインスタンスとして..このジェネレーター対称ラインセグメント（SLS）は、平面図から見た飛行機の対称で規則的な境界に基づいて開発されたものです。 
[概要]発電機対称線分（sls）は、平面図から見た飛行機の対称境界に基づいて開発されています。各飛行機には複数の提案があり、一部は胴体の方向ではなく、1つの地面に対応するすべての提案を収集します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-08-19">
        <br><font color="black">2018-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Large-Scale MIDI-based Composer Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_15.html">
      <font color="black">Large-Scale MIDI-based Composer Classification</font>
    </a>
  </h2>
  <font color="black">畳み込みリカレントニューラルネットワークをモデルとして使用することにより、MIDIベースの作曲家分類システムは0.648と0.385（30秒のクリップで評価）および0.739と0.489（楽曲で評価）の10作曲家と100作曲家の分類精度を達成します。それぞれ..音楽分類は、曲をジャンルや作曲家などのラベルに分類するタスクです。当社のMIDIベースの作曲家システムは、いくつかのオーディオベースのベースライン分類システムよりも優れており、作曲家の分類にコンパクトなMIDI表現を使用することの有効性を示しています。 
[ABSTRACT]作曲家分類システムは最大100人の作曲家の問題です。システムはいくつかのオーディオベースのベースライン分類システムよりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Object Hider: Adversarial Patch Attack Against Object Detectors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_16.html">
      <font color="black">Object Hider: Adversarial Patch Attack Against Object Detectors</font>
    </a>
  </h2>
  <font color="black">ヒートマップベースのアルゴリズムとコンセンサスベースのアルゴリズムの2つの敵対的なパッチ生成アルゴリズムが提案されています。深層学習モデルをだますことができる精巧に設計された摂動を伴う入力は敵対的な例と呼ばれ、深層ニューラルの安全性について大きな懸念を集めています。ネットワーク..実用的な代替手段として、攻撃には敵対的なパッチを使用します。 
[要約]実験結果は、提案された方法が非常に効果的で、移転可能で、一般的であることを示しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Deep neural network for fringe pattern filtering and normalisation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_17.html">
      <font color="black">Deep neural network for fringe pattern filtering and normalisation</font>
    </a>
  </h2>
  <font color="black">実験結果（合成データと実際のデータの両方）は、インターフェログラムを処理するためのこの新しいパラダイムの機能と可能性を示しています。さまざまなシナリオでメソッドのパフォーマンスを評価します。さまざまな程度のノイズで破損したFP、さまざまなノイズ分布で破損したFP ..（3）また、V-netスキームの2つの変更、つまりResV-netと呼ばれる残余バージョンとV-netの高速動作バージョンを提案し、提案を変更する際の潜在的な改善を評価します。 
[概要]私たちの新しいアプローチは、ディープニューラルネットワークによってfpsを学習できるという理論に基づいています。提案を変更するときに潜在的な改善を評価するために、v-netスキームの2つの変更を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-14">
        <br><font color="black">2019-06-14</font>
      </time>
    </span>
</section>
<!-- paper0: Differentiable Channel Pruning Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_18.html">
      <font color="black">Differentiable Channel Pruning Search</font>
    </a>
  </h2>
  <font color="black">したがって、無視できる追加リソースで形状の不一致の問題をエレガントに排除できる新しいウェイトシェアリング手法を紹介します。微分可能アーキテクチャ検索（DARTS）に触発され、継続的な緩和から教訓を引き出し、勾配情報を活用してメトリックとパフォーマンス..DCPSは、PASCAL VOC2012のセマンティックセグメンテーションに2つの目的でさらに利用されます。 
[ABSTRACT] dcpsは、自動的にプルーニング比の最適な組み合わせを検索します。この方法では、メモリメモリの損失とメモリ損失が発生する可能性があります。これにより、メモリメモリメモリの問題が発生します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Leveraging Visual Question Answering to Improve Text-to-Image Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_19.html">
      <font color="black">Leveraging Visual Question Answering to Improve Text-to-Image Synthesis</font>
    </a>
  </h2>
  <font color="black">テキストによる説明から画像を生成することは、最近多くの関心を集めています。QAペアから生成された画像は、リアルに見えるようにし、さらに外部VQA損失を最小限に抑えることをお勧めします。ベースラインと比較して83.82％から84.79％であり、T2I合成を示しています。標準のVQAモデルを使用して正常に改善できます。 
[概要]質問と回答（qa）のペアを連結して追加のトレーニングサンプルを作成します。標準のvqaモデルを使用して、t2iモデルに補助学習信号を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Adaptive Classifiers Synthesis for Generalized Few-Shot
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_20.html">
      <font color="black">Learning Adaptive Classifiers Synthesis for Generalized Few-Shot
  Learning</font>
    </a>
  </h2>
  <font color="black">結果として、ACASTLEは異種ドメインのクラスでGFSLを効果的に処理できます。ヘッドクラスのマルチクラス分類器に加えて、キャリブレーションされた数ショット分類器を合成する方法を学習する学習フレームワークであるClAssifier SynThesis LEarning（CASTLE）を提案します。共有ニューラルディクショナリを使用して、誘導性GFSLに光を当てます。CASTLEおよびACASTLEは、既存のGFSLアルゴリズムよりも優れたパフォーマンスと、MiniImageNetおよびTieredImageNetデータセットでの強力なベースラインを示します。 
[概要]私たちの理想的な視覚システムは、入力された頭の視覚概念を認識する必要があります。多くの人が、いくつかのトレーニングインスタンスで新しい尾のカテゴリについて学びます。次の尾のトレーニング例を条件として、頭の分類子を適応させる城の適応バージョンを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-07">
        <br><font color="black">2019-06-07</font>
      </time>
    </span>
</section>
<!-- paper0: ElderSim: A Synthetic Data Generation Platform for Human Action
  Recognition in Eldercare Applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_21.html">
      <font color="black">ElderSim: A Synthetic Data Generation Platform for Human Action
  Recognition in Eldercare Applications</font>
    </a>
  </h2>
  <font color="black">高齢者の日常活動の視覚ベースの行動認識のための深層学習モデルをトレーニングするには、さまざまな日常生活環境および条件下で取得された大規模な活動データセットが必要です。最近、利用可能なデータセットのこのような制限は、から合成データを生成することによって積極的に補償されています。現実的なシミュレーション環境とそれらのデータを使用した深層学習モデルのトレーニング。ただし、人間の行動認識で使用されるほとんどの公開データセットは、多くの面で高齢者の活動とは異なるか、対象範囲が限られているため、高齢者の日常の活動を適切に認識することは困難です。既存のデータセットのみを利用します。 
[ABSTRACT] eldersimは、高齢者の日常活動に関する合成データを生成できるアクションシミュレーションプラットフォームです。これらはこれらのアイデアに基づいており、人間の行動認識モデルのトレーニングに利用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Cycle-Contrast for Self-Supervised Video Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_22.html">
      <font color="black">Cycle-Contrast for Self-Supervised Video Representation Learning</font>
    </a>
  </h2>
  <font color="black">ビデオ表現を学習するための新しい自己教師あり方法であるCycle-ContrastiveLearning（CCL）を紹介します。CCLによって学習されたビデオ表現は、ビデオ理解のダウンストリームタスクにうまく転送でき、最近傍検索の以前の方法よりも優れていることを示します。 UCF101、HMDB51、およびMMActでのアクション認識タスク。これは、フレームまたはクリップ間の対応を学習するだけの最近のアプローチとは異なります。 
[要約]私たちの方法では、フレームとビデオの表現は、r3dアーキテクチャに基づく単一のネットワークから学習されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Enhancing MRI Brain Tumor Segmentation with an Additional Classification
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_23.html">
      <font color="black">Enhancing MRI Brain Tumor Segmentation with an Additional Classification
  Network</font>
    </a>
  </h2>
  <font color="black">BraTSの検証セットでは、増強腫瘍、腫瘍全体、および腫瘍コアについて、それぞれ78.43％、89.99％、および84.22％の平均ダイススコアを達成しました。ネットワーク全体は、エンドツーエンドでトレーニングされました。マルチモーダル脳腫瘍セグメンテーションチャレンジ（BraTS）2020トレーニングデータセット..この論文では、ネットワークに分類ブランチを追加することでセグメンテーション結果を強化する新しいトレーニング方法を提案します。 
[要約]最近の研究では、深い畳み込みニューラルネットワーク（dcnns）は、腫瘍のセグメンテーションタスクに取り組むのに強力です。ネットワーク全体がトレーニングされました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-25">
        <br><font color="black">2020-09-25</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal End-to-End Learning for Autonomous Steering in Adverse Road
  and Weather Conditions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_24.html">
      <font color="black">Multimodal End-to-End Learning for Autonomous Steering in Adverse Road
  and Weather Conditions</font>
    </a>
  </h2>
  <font color="black">車線がなく、道路が雪に覆われ、視界が悪い可能性がある悪天候や悪天候では、自動運転は困難です。自動運転のエンドツーエンド学習に関するこれまでの作業を次のように拡張します。マルチモーダルデータを使用して、これらの不利な現実の条件で動作します。さまざまなモダリティに基づいてCNNモデルのパフォーマンスを比較した結果、リダーモダリティがさまざまなマルチモーダルセンサーフュージョンモデルのパフォーマンスを向上させることがわかりました。 
[概要] LIDARを使用して、さまざまなマルチモーダルセンサーのパフォーマンスを向上させることができます-フュージョンモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Road Damage Detection and Classification with Detectron2 and Faster
  R-CNN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_25.html">
      <font color="black">Road Damage Detection and Classification with Detectron2 and Faster
  R-CNN</font>
    </a>
  </h2>
  <font color="black">したがって、既存の注釈に対して予測結果を評価し、いくつかの不一致を発見します。この作業では、これらのタスクに対して評価された戦略と実験について詳しく説明します。また、Global Road Damage Detection Challenge 2020、A Track in theTrackを使用してこれらのアプローチを実験します。 IEEEビッグデータ2020ビッグデータカップチャレンジデータセット。 
[概要]結果は、detectron2のデフォルト構成でより高速なr-cnnのx101-fpnベースモデルが効率的で一般的であり、さまざまな国に転送できることを示しています。視覚化は良好な予測結果を示していますが、f1スコアは低いです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Domain Adaptation without Source Data by Casting a BAIT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_26.html">
      <font color="black">Unsupervised Domain Adaptation without Source Data by Casting a BAIT</font>
    </a>
  </h2>
  <font color="black">具体的には、最初にソースドメインでモデルをトレーニングします。ソースモデルをターゲットドメインに適応させると、ソースデータにアクセスできなくなり、ベイト分類器はターゲットフィーチャをアンカーの決定境界の右側にプッシュすることを目的とします。この論文では、モデルが適応期間中にソースデータにアクセスできない、ソースフリーの監視されていないドメイン適応（SFUDA）について説明します。 
[ABSTRACT]既存のudaメソッドでは、ターゲットドメインへの適応中に、ソースドメインからのデータにアクセスする必要があります。これは、実際の状況では実行できない場合があります。baitは、sfudaに取り組むためのbaitという名前の新しいフレームワークです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-23">
        <br><font color="black">2020-10-23</font>
      </time>
    </span>
</section>
<!-- paper0: An Attention Mechanism with Multiple Knowledge Sources for COVID-19
  Detection from CT Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_27.html">
      <font color="black">An Attention Mechanism with Multiple Knowledge Sources for COVID-19
  Detection from CT Images</font>
    </a>
  </h2>
  <font color="black">広範な実験は、最近のベースラインと比較して、私たちのアプローチの優れたパフォーマンスを示しています。具体的には、学習ネットワークから抽出された感染領域とヒートマップは、学習プロセス中に注意メカニズムを介してグローバル画像と統合されます。さらに、学習ネットワークガイダンスはグレーボックスモデルの入力と出力の関係を理解できるため、医師に説明可能な機能。 
[概要] covid-19の早期診断は時期尚早である可能性があります。これらのアプローチは主に、新しいアーキテクチャの導入、学習手法の伝達、または大規模データの構築に焦点を当てています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-23">
        <br><font color="black">2020-09-23</font>
      </time>
    </span>
</section>
<!-- paper0: Kinematic Single Vehicle Trajectory Prediction Baselines and
  Applications with the NGSIM Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_28.html">
      <font color="black">Kinematic Single Vehicle Trajectory Prediction Baselines and
  Applications with the NGSIM Dataset</font>
    </a>
  </h2>
  <font color="black">これにより、精度と不確実性の推定が大幅に改善され、複雑なモデルと解釈可能なモデルの両方の可能性が開かれます。最近の車両軌道予測の文献では、最も一般的なベースラインが、再現に必要な情報なしで簡単に紹介されています。その目的のために、プロセスは明示的であり、コードは利用可能です。 
[要約]このプロセスは、車両位置の追跡を含む任意のデータベースで再現できます。mrmrmr。 。 nll推定には注意深い定義が必要です。これは、数学コードとは異なるいくつかの化身が他の作業で使用されていることを意味します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-29">
        <br><font color="black">2019-08-29</font>
      </time>
    </span>
</section>
<!-- paper0: Attentive Semantic Exploring for Manipulated Face Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_29.html">
      <font color="black">Attentive Semantic Exploring for Manipulated Face Detection</font>
    </a>
  </h2>
  <font color="black">したがって、マルチレベルの顔のセマンティックセグメンテーションとカスケード注意メカニズムに基づく新しい操作された顔検出方法を提案します。4つのデータセットでの実験により、他の最先端技術に対するアプローチの利点、特にその一般化能力が検証されます。私たちの方法では、GGFIとFFMIの2つのデータセットを再構築し、2つのオープンソースデータセットも収集します。 
[要約]何年もの間、ggfiとffmiの2つのデータセットを再構築し、2つのオープンソースデータセットも収集します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br><font color="black">2020-05-06</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Sensor Periocular Biometrics for Partial Face Recognition in a
  Global Pandemic: Comparative Benchmark and Novel Multialgorithmic Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_30.html">
      <font color="black">Cross-Sensor Periocular Biometrics for Partial Face Recognition in a
  Global Pandemic: Comparative Benchmark and Novel Multialgorithmic Approach</font>
    </a>
  </h2>
  <font color="black">COVID-19に対する最前線のフェイスマスクにより、眼周囲の認識は、目に見える唯一の顔領域であるため、人気を取り戻しています。スコアがログで表される線形ロジスティック回帰に基づく融合スキームとさまざまなコンパレータを統合します。 -尤度比..最後に、提案された方法は、スコアの平均、SVM、ランダムフォレストなど、他の一般的な融合アプローチよりも優れていることが示されています。 
[ABSTRACT]バイオメトリクスを使用して、損傷したハードウェアや廃止されたハードウェアを置き換えることができます。さらに、眼周囲の認識が人気を取り戻しています。これにより、スコアの解釈とベイズしきい値の使用が容易になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-02-21">
        <br><font color="black">2019-02-21</font>
      </time>
    </span>
</section>
<!-- paper0: Real-time Tropical Cyclone Intensity Estimation by Handling Temporally
  Heterogeneous Satellite Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_31.html">
      <font color="black">Real-time Tropical Cyclone Intensity Estimation by Handling Temporally
  Heterogeneous Satellite Data</font>
    </a>
  </h2>
  <font color="black">ただし、よりタイムリー（30分未満）で正確なTC強度推定を実現するには、時間的に不均一な衛星観測を処理するための深層学習モデルが必要です。したがって、生成的敵対的ネットワーク（GAN）とCNNを組み合わせた新しいフレームワークを提案します。 。一方、可視（VIS）チャネルは、ノイズや太陽光の強さの影響を強く受け、利用が困難です。 
[ABSTRACT]畳み込みニューラルネットワーク（cnn）は、衛星データに基づいて熱帯低気圧（tc）の強度を推定することに大きな成功を収めています。これらの要因には、赤外線（ir1）および水蒸気（wv）画像が含まれます。これらの画像は15分ごとに利用できます。一方、パッシブマイクロ波雨量（pmw）は約3時間ごとに利用可能です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Displacement-Invariant Matching Cost Learning for Accurate Optical Flow
  Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_32.html">
      <font color="black">Displacement-Invariant Matching Cost Learning for Accurate Optical Flow
  Estimation</font>
    </a>
  </h2>
  <font color="black">さらに、異なる変位候補間の相関を再検討し、学習コストボリュームのマルチモーダル問題を軽減する、学習コストボリュームをスケーリングする変位認識投影レイヤーを提案します。これは主に、光フロー計算の場合、つまり、単純な拡張では、5Dフィーチャボリュームを処理するために高密度の4D畳み込みが必要になりますが、これは計算上法外です。私たちの重要な革新は、2D変位間の接続を分離し、それぞれのマッチングコストを学習することです。独立した2D変位仮説、つまり変位不変のコスト学習。 
[概要] 4Dコストボリュームを5Dフィーチャーボリュームに組み込む必要があります。これにより、ネットワークに適切なマッチングコストを学習させることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: MultiMix: Sparingly Supervised, Extreme Multitask Learning From Medical
  Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_33.html">
      <font color="black">MultiMix: Sparingly Supervised, Extreme Multitask Learning From Medical
  Images</font>
    </a>
  </h2>
  <font color="black">大量のラベルなしデータから得られる知識を最大化することは、半教師あり学習設定に役立ちます。2つのタスク間のブリッジの顕著性を通じて説明性を維持しながら、慎重に監督された方法で疾患分類と解剖学的セグメンテーションを共同で学習する、新しいマルチタスク学習モデル、つまりMultiMixを提案します。 ..トレーニングセット内のさまざまな量のラベル付きデータを使用した広範な実験により、胸部X線画像からの肺炎の分類と肺のセグメンテーションに対するマルチタスクモデルの有効性が正当化されます。 
[概要] multimixはmultimixの発案によるもので、慎重に監視された方法で疾患分類と解剖学的セグメンテーションを共同で学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Attribution Preservation in Network Compression for Reliable Network
  Interpretation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_34.html">
      <font color="black">Attribution Preservation in Network Compression for Reliable Network
  Interpretation</font>
    </a>
  </h2>
  <font color="black">この現象は、従来のネットワーク圧縮方法では、アトリビューションの品質を無視してネットワークの予測のみが保持されるために発生します。加重折りたたみアトリビューションマッチングレギュラライザーを使用することにより、圧縮されているネットワークのアトリビューションマップを以前の状態に一致させます。 -以前の自己の圧縮..属性の不整合の問題に対処するために、ネットワークを圧縮しながら属性を保持できるフレームワークを提示します。 
[概要]帰属の不整合の問題に対処するために、ネットワークを圧縮しながら帰属を保持できるフレームワークを提示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: When Deep Learning Meets Data Alignment: A Review on Deep Registration
  Networks (DRNs) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_35.html">
      <font color="black">When Deep Learning Meets Data Alignment: A Review on Deep Registration
  Networks (DRNs)</font>
    </a>
  </h2>
  <font color="black">登録は、データセットを調整する変換を計算するプロセスです。3）学習の一般性にもかかわらず、現在の提案は依然としてアドホックソリューションです。最後に、4）これはまだ多大な労力を必要とする若いトピックです。従来のアプローチに影響を与える問題に対処できる一般的な解決策に到達するため。 
[概要]プロセスは、ターゲットの選択、特徴抽出、特徴マッチング、変換コンピューティングの4つの主要なステップに分けることができます。主なアプローチは、複数のコンピュータービジョンの問題を改善するのに役立つ深層学習（dl）技術の開発です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-06">
        <br><font color="black">2020-03-06</font>
      </time>
    </span>
</section>
<!-- paper0: Quantified Facial Temporal-Expressiveness Dynamics for Affect Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_36.html">
      <font color="black">Quantified Facial Temporal-Expressiveness Dynamics for Affect Analysis</font>
    </a>
  </h2>
  <font color="black">TEDを使用することのプラスの影響を評価するために、UNBC-McMasterの自発的な肩の痛みのデータセットを使用して自発的な痛みに関するケーススタディを実施しました。実験結果は、定量化された影響分析にTEDを使用することの有効性を示しています。人間の顔の表現力を定量化するための時間的表現力ダイナミクス（TED）。 
[概要]提案されたアルゴリズムは、自動化された影響モデリングシステムを構築および監視するために使用できます。また、顔の表情の正確な測定にも使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Parabolic Approximation Line Search for DNNs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_37.html">
      <font color="black">Parabolic Approximation Line Search for DNNs</font>
    </a>
  </h2>
  <font color="black">したがって、ステップサイズのスケジュールが不明であるか、うまく機能しない目的に関心があります。他のステップサイズの推定方法を上回り、手作業で設計したステップサイズを必要とせずに、さまざまな実験で一般的な最適化方法と競合します。スケジュール..この放物線特性を利用することにより、損失形状に依存する更新ステップを実行する、シンプルで堅牢なライン探索アプローチを導入します。 
[概要]最適なステップサイズは、更新ステップ方向の損失の形状と密接に関連しています。ただし、この作業は、負の勾配方向のラインでのバッチ損失がほとんど局所的にあくびされ、1幅の放物線測定に適していることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-03-28">
        <br><font color="black">2019-03-28</font>
      </time>
    </span>
</section>
<!-- paper0: The DeepFake Detection Challenge (DFDC) Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_38.html">
      <font color="black">The DeepFake Detection Challenge (DFDC) Dataset</font>
    </a>
  </h2>
  <font color="black">DFDCデータセットは、現在公開されているフェイススワップビデオデータセットとしては群を抜いて最大であり、3,426の有料俳優から提供され、いくつかのDeepfake、GANベース、および未学習の方法で作成された合計100,000を超えるクリップがあります。方法の説明に加えてデータセットの構築に使用され、Kaggleコンテストからの上位の提出物の詳細な分析を提供します。ディープフェイクは、誰でも1つのビデオで2つのIDを交換できる最近の既製の操作手法です。 
[ABSTRACT]ジョードロップテクニックも単一のコードで公開されています。これらには、ジョードロップテクニックとフェイススワッピングなどのテクニックが含まれます。これらのテクニックには、ジョードロップとジョードロップテクニックが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-12">
        <br><font color="black">2020-06-12</font>
      </time>
    </span>
</section>
<!-- paper0: Micro Stripes Analyses for Iris Presentation Attack Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_39.html">
      <font color="black">Micro Stripes Analyses for Iris Presentation Attack Detection</font>
    </a>
  </h2>
  <font color="black">提案されたマイクロストライプ分析（MSA）ソリューションは、セグメント化された領域を個々のストライプとしてサンプリングします。次に、多数決により、これらのマイクロストライプの最終的な分類が決定されます。実験は、2つのデータベース（IIITD-WVUとノートルダム）は、LivDet-2017Irisコンペティションからのものです。 
[概要]システムは、虹彩提示攻撃を検出するように設計されています。拡張された正規化された虹彩テクスチャの複数のマイクロストライプを抽出する必要があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Synthetic Humans for Action Recognition from Unseen Viewpoints -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_40.html">
      <font color="black">Synthetic Humans for Action Recognition from Unseen Viewpoints</font>
    </a>
  </h2>
  <font color="black">個人の体型や衣服の変化、不均一なフレームサンプリングなどのアクション関連の拡張、同じアクションを実行する個人の動きの間の補間を検討します。 （ii）アクション分類のための時空間CNNのトレーニングを可能にする新しいデータ生成方法論SURREACTを導入します。 （iii）NTU RGB + DおよびUESTC標準のヒューマンアクションマルチビューベンチマークでの最先端のアクション認識パフォーマンスを大幅に改善します。最後に、（iv）Kineticsデータセットのサブセットからのインザワイルドビデオへの拡張アプローチを拡張して、ワンショットトレーニングデータのみが利用可能な場合を調査し、この場合も改善を示します。トレーニングデータは、人間の姿勢推定などのタスクに有益であることが示されています。RGBヒューマンアクション認識への使用は比較的未踏です。実際のアクションシーケンスからの単眼3D人体再構築の最近の進歩を利用して、合成トレーニングを自動的にレンダリングします。アクションラベルのビデオ。 
[ABSTRACT]合成人間は人間の行動認識のパフォーマンスを向上させることができます。目的は人間の行動がどのように向上するかを調査することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-09">
        <br><font color="black">2019-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Adversarial Networks in Human Emotion Synthesis:A Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_41.html">
      <font color="black">Generative Adversarial Networks in Human Emotion Synthesis:A Review</font>
    </a>
  </h2>
  <font color="black">深層生成モデルは、コンピュータービジョンや信号処理などのさまざまな研究分野で新たなトピックになっています。このようなモデルのアプリケーションには、感情の認識と分類、ユニモーダル感情合成、クロスモーダル感情合成が含まれますが、これらに限定されません。 、私たちは、利用可能なデータベース、生成モデルの長所と短所、および2つの主要な人間のコミュニケーションモダリティ、つまりオーディオとビデオを考慮した関連トレーニング戦略を研究することにより、人間の感情合成における最近の進歩のレビューを行いました。 
[要約]人間の感情合成の研究は、生殖器モデルがどれほど深く出現しているかを示しています。これらのモデルが新たなトピックになったのはこれが初めてです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Classification Beats Regression: Counting of Cells from Greyscale
  Microscopic Images based on Annotation-free Training Samples -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_42.html">
      <font color="black">Classification Beats Regression: Counting of Cells from Greyscale
  Microscopic Images based on Annotation-free Training Samples</font>
    </a>
  </h2>
  <font color="black">この定式化には、テスト段階の一部の細胞数がトレーニングデータに表示されない場合に制限があります。このフレームワークは、多くの最新の細胞数カウント方法を上回り、データ分析の競争に勝ちました（ケーススタディ1：顕微鏡画像からの細胞数のカウントhttps：//カナダ統計学会（SSC）の第47回年次総会のssc.ca/en/case-study/case-study-1-counting-cells-microscopic-images）。さらに、細胞数間の順序関係はそうではありません。利用。 
[概要]コンセプトは分類に基づいています-目的の畳み込みニューラルネットワーク（cnns）。注釈付きのトレーニング画像を使用せずに、グレースケールの顕微鏡画像から細胞をカウントするために使用できます。フレームワークは、多くの最新の細胞カウント方法よりも優れており、データ分析の競争に勝ちました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: AbdomenCT-1K: Is Abdominal Organ Segmentation A Solved Problem? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_43.html">
      <font color="black">AbdomenCT-1K: Is Abdominal Organ Segmentation A Solved Problem?</font>
    </a>
  </h2>
  <font color="black">この論文では、AbdomenCT-1Kと呼ばれる大規模で多様な腹部CT臓器セグメンテーションデータセットを提示し、多施設、多相、多ベンダー、多施設を含む11か国からの1000（1K）以上のCTスキャンを行います-疾患の症例..AbdomenCT-1Kデータセットの導入により、臨床的に適用可能な腹部臓器セグメンテーション手法に向けた将来の詳細な研究が促進されると考えています。深部学習における前例のない開発により、主要な腹部臓器（すなわち、肝臓、最先端の（SOTA）メソッドが既存のベンチマークデータセットの観察者間の変動性と同等の結果を達成しているため、腎臓、および脾臓）は解決された問題のようです。 
[概要]既存の腹部臓器セグメンテーションベンチマークデータセットのほとんどには、単相、単相、単相、または単相の疾患症例が含まれています。これは、優れたパフォーマンスがより多様なデータセットで一般化できるかどうかは不明です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Low-Rank Matrix Recovery from Noise via an MDL Framework-based Atomic
  Norm -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_44.html">
      <font color="black">Low-Rank Matrix Recovery from Noise via an MDL Framework-based Atomic
  Norm</font>
    </a>
  </h2>
  <font color="black">まず、アトミックノルムを使用して、低ランクおよびスパース項のすべての候補アトムを検索します。次に、モデルの記述長を最小化して、低ランクおよびスパース行列の適切なアトムをそれぞれ選択します。合成データと実際のセンシングアプリケーション（高ダイナミックレンジイメージング、バックグラウンドモデリング、ノイズとシャドウの除去）を利用した実験結果は、提案された方法の有効性、堅牢性、効率を示しています。私たちの実験分析は、提案されたアプローチがより高い成功率を得ることができることを示しています。観測数が限られている場合や破損率が高い場合でも、最先端の手法よりも優れています。 
[概要]特定のデータデータでは、低レベルの視力の問題は不明です。これらには、基礎となる構造の正確なターゲットランク、および密な外れ値の特定の範囲と値が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Learning from Noisy Labels with Deep Neural Networks: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_45.html">
      <font color="black">Learning from Noisy Labels with Deep Neural Networks: A Survey</font>
    </a>
  </h2>
  <font color="black">次に、46の最先端の堅牢なトレーニング方法の包括的なレビューを提供します。これらはすべて、方法論の違いに応じて7つのグループに分類され、その後、優位性を評価するために使用される6つのプロパティの体系的な比較が続きます。ラーニングは、大量のビッグデータの助けを借りて、多くの分野で目覚ましい成功を収めています。次に、パブリックノイズの多いデータセットや評価指標など、一般的に使用される評価方法を要約します。 
[概要]高品質の研究が不足しているため、データラベルの品質が懸念されます。低品質のデータは、データ品質が低いために懸念されます。低品質のデータは、研究の質が低いために懸念されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: MedMNIST Classification Decathlon: A Lightweight AutoML Benchmark for
  Medical Image Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_46.html">
      <font color="black">MedMNIST Classification Decathlon: A Lightweight AutoML Benchmark for
  Medical Image Analysis</font>
    </a>
  </h2>
  <font color="black">MedMNISTは、教育目的、ラピッドプロトタイピング、マルチモーダル機械学習、または医療画像分析のAutoMLに使用できます。MedMNISTは、背景知識を必要としない軽量の28x28画像で分類タスクを実行するように標準化されています。さらに、MedMNIST分類デカスロンが設計されています。 10個のデータセットすべてでAutoMLアルゴリズムのベンチマークを行います。オープンソースまたは商用のAutoMLツールを含むいくつかのベースライン手法を比較しました。 
[ABSTRACT] medmnistは、背景知識を必要としない軽量の28x28画像で分類タスクを実行するように標準化されています。medmnistのデータセット、評価コード、およびベースラインメソッドは公開されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Face Hallucination with Finishing Touches -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_47.html">
      <font color="black">Face Hallucination with Finishing Touches</font>
    </a>
  </h2>
  <font color="black">ただし、主流は、超解像の正面近くのLR顔、または正面以外の高解像度（HR）顔の正面化に焦点を当てています。VividGANは、粗いレベルと細かいレベルの顔幻覚ネットワーク（FHnet）と2つの弁別器で構成されます。 Coarse-DとFine-D ..日常生活の制約のない顔画像では、両方のタスクをシームレスに実行することが望ましいです。 
[ABSTRACT]鮮やかな顔の幻覚集団敵対的ネットワーク（vividgan）は、小さな非正面の顔画像を同時に超解像および正面化します。vividganは、顔画像の全体的な輪郭と詳細な顔の特徴をキャプチャするように設計された2つのレベルの顔をキャプチャします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-09">
        <br><font color="black">2020-02-09</font>
      </time>
    </span>
</section>
<!-- paper0: A Transfer Learning Approach for Automated Segmentation of Prostate
  Whole Gland and Transition Zone in Diffusion Weighted MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_48.html">
      <font color="black">A Transfer Learning Approach for Automated Segmentation of Prostate
  Whole Gland and Transition Zone in Diffusion Weighted MRI</font>
    </a>
  </h2>
  <font color="black">拡散強調MRI（DWI）での前立腺全腺と遷移ゾーンのセグメンテーションは、前立腺癌のコンピューター支援検出アルゴリズムを設計する最初のステップです。DWI画像で前立腺全腺と遷移ゾーンの輪郭を描くことは時間と費用がかかります。この作業では、ソースデータセットで事前トレーニングされ、ターゲットデータセットでテストされたCNNを使用して、DWIの前立腺全腺と遷移ゾーンをセグメンテーションするための修正U-netアーキテクチャと損失関数に基づく転移学習法を提案します。 
[概要]この感度により、ソースコホートでトレーニングされ、別のスキャナーからのターゲットコホートでテストされたcnnのセグメンテーションパフォーマンスが低下します。ただし、MRI取得パラメーターとアーキテクチャのネットワークにより、画像内の前立腺組織の外観が異なります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-20">
        <br><font color="black">2019-09-20</font>
      </time>
    </span>
</section>
<!-- paper0: Data Agnostic Filter Gating for Efficient Deep Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_49.html">
      <font color="black">Data Agnostic Filter Gating for Efficient Deep Networks</font>
    </a>
  </h2>
  <font color="black">この論文では、Daggerモジュールという名前の補助ネットワークを使用して剪定を誘導し、各フィルターの重要性を学習するための入力として事前トレーニング済みの重みを使用する、データに依存しないフィルター剪定方法を提案します。CIFAR-10およびImageNetデータセットに関する広範な実験結果は他の最先端のフィルタープルーニング方法に対する優位性..ローエンドの計算エッジデバイスに十分にトレーニングされたCNNモデルを展開するには、通常、特定の計算バジェット（FLOPなど）の下でモデルを圧縮またはプルーニングすることになっています。 。 
[ABSTRACT]現在のフィルタープルーニング方法は、主に特徴マップを利用してフィルターの重要なスコアを生成し、スコアが小さいものをプルーニングします。これは、入力バッチのバリエーションを、フィルター上の高密度モジュール構造の違いに説明します。これには、トレーニング済みのcnnベースのフロップモデルが含まれます。剪定フィルターを直接促進する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Toyota Smarthome Untrimmed: Real-World Untrimmed Videos for Activity
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_50.html">
      <font color="black">Toyota Smarthome Untrimmed: Real-World Untrimmed Videos for Activity
  Detection</font>
    </a>
  </h2>
  <font color="black">自発的に実行されるアクティビティは、ビジョンコミュニティによってしばしば無視される多くの現実世界の課題につながります。これには、同様のアクティビティの存在によるクラス間の低さ、クラス内の変動の大きさ、カメラのフレーミングの低さ、解像度の低さなどが含まれます。活動のロングテール分布とオクルージョン..この作業は、日常生活動作が自然な方法で実行される大規模なデータセットを構築することを目的としています。 
[ABSTRACT] toyota smarthome untrimmed --tsu）データセットは、豊富で密度の高いアノテーションを備えた自発的なアクティビティを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Manifold Computing and Visualization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CV/paper_51.html">
      <font color="black">Deep Manifold Computing and Visualization</font>
    </a>
  </h2>
  <font color="black">ELIS法では、適切な非線形相似関数のクラスを双方向の発散損失に組み込み、ハイパーパラメーター継続を使用して最適解を見つけます。さらに、ELISでは、複雑な非線形性に取り組むための十分な柔軟性を提供する方法で滑らかさを課す必要があります。非真正性;これは、類似性関数と活性化関数の両方の非線形性を介して層ごとに達成されます。広範な実験、比較、およびアブレーション研究は、ELISがUMAPおよびt-SNEよりも優れた結果を提供できること、および視覚化だけでなく、他の主要な対応物よりも優れていることを示しています。 NLDRおよび多様体データ生成のための多様体およびオートエンコーダ学習の開発。 
[ABSTRACT]弾性局所等尺性平滑性と呼ばれる方法は、そのような能力でディープニューラルネットワークに力を与える必要があります。elisは、複雑な線形性と戦う方法で平滑性を課す必要があります。これは、両方の類似性への線形性によってより低い層で達成されます。および活性化functions.elisは、umapおよびt-sne forおよび視覚化よりも優れた結果を提供できますが、マニフォールドおよびオートエンコーダー学習の他の主要な対応物よりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: A Cyclic Proof System for HFLN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_0.html">
      <font color="black">A Cyclic Proof System for HFLN</font>
    </a>
  </h2>
  <font color="black">このシステムのグローバルな状態と健全性をチェックする決定可能性を証明し、また、サイクリックプルーフシステムの無限バリアントの標準的な完全性の制限された形式を証明します。プログラム検証からHFLN妥当性チェックへの削減に関する最近の作業。循環証明システムにより、明示的な帰納なしで帰納的推論を実行できます。 
[ABSTRACT]高階述語システムであるhflnの循環証明システムを提案します。このシステムは、兄弟ストンとシンプソンの元のシステムよりも循環証明に、より繊細なグローバル条件を必要とします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Find or Classify? Dual Strategy for Slot-Value Predictions on
  Multi-Domain Dialog State Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_1.html">
      <font color="black">Find or Classify? Dual Strategy for Slot-Value Predictions on
  Multi-Domain Dialog State Tracking</font>
    </a>
  </h2>
  <font color="black">ただし、2つのスロットタイプのいずれかでどちらのスロットが適切に処理されるかは十分に明確ではなく、事前トレーニング済みモデルの使用方法は十分に調査されていません。MultiWOZデータセットでの実験では、この方法が重要なのはドメインスロットとコンテキスト情報の間の深い相互作用であることがわかったBERTベースの対応物。この論文では、単一のBERTスタイルの読解モデルを採用することにより、DSTのシンプルで効果的なデュアル戦略モデルを提案します。カテゴリスロットと非カテゴリスロットの両方を共同で処理します。 
[概要] dstの現在のアプローチは、主に2つのカテゴリのいずれかに分類されます。これらには、ターゲットシステムベースとオントロジー（無料の方法）が含まれます。ただし、新しい研究では、2つの方法のバランスをとるためにbertベースのモデルが導入されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-08">
        <br><font color="black">2019-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Is MAP Decoding All You Need? The Inadequacy of the Mode in Neural
  Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_2.html">
      <font color="black">Is MAP Decoding All You Need? The Inadequacy of the Mode in Neural
  Machine Translation</font>
    </a>
  </h2>
  <font color="black">モード..証拠は、モデルとそのトレーニングアルゴリズムに疑問を投げかける以上に、MAPデコードの不十分さを裏付けていると主張します。NMTの既知の病状とバイアスのいくつかは、NMTの統計ではなくMAPデコードによるものであることを示します。仮定もMLEも。 
[ABSTRACT]調査によると、モデルまたはそのトレーニングアルゴリズムに問題があり、最尤推定（mle）が発生します。モデルの下での変換では、確率質量がほとんど蓄積されないため、モードは本質的に任意であると見なすことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br><font color="black">2020-05-20</font>
      </time>
    </span>
</section>
<!-- paper0: Dual Attention Model for Citation Recommendation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_3.html">
      <font color="black">Dual Attention Model for Citation Recommendation</font>
    </a>
  </h2>
  <font color="black">本研究では、「書誌推奨デュアルアテンションモデル（DACR）」と呼ばれる新しい埋め込みベースのニューラルネットワークを提案し、原稿作成時に引用を推奨します。これらの欠点により、学術原稿に適切な引用を推奨するには、このような方法では不十分です。 、ユーザーが書いている論文のセクションで、引用を見つける必要があるセクション、ローカルコンテキスト内の単語間の関連性（引用を説明するテキストスパン）、または各単語の重要性は考慮されません。ローカルコンテキストから。 
[概要]私たちの方法は、学術論文に十分な引用を推奨するのに適しています。新しい方法は、非社会的情報の3つの次元を使用します。これらには、ローカルコンテキスト、構造コンテキスト、およびユーザーが作業しているセクションの単語が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-01">
        <br><font color="black">2020-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Ethics by Design in Online Abusive Content Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_4.html">
      <font color="black">Towards Ethics by Design in Online Abusive Content Detection</font>
    </a>
  </h2>
  <font color="black">倫理的な問題を前面に押し出し、2段階のプロセスとして統一されたフレームワークを提案します。タスクの定式化、データセットの設計、およびパフォーマンス評価のための共通のフレームワークの下でフィールドを統合する差し迫った必要性があります。新しいフレームワークは、 Ethics by Designの原則であり、より正確で信頼できるモデルを構築するためのステップです。 
[概要]研究努力は、ヘイトスピーチ、毒性、ネットいじめなどの範囲など、いくつかの分野に広がっています。倫理的な問題を含む、研究にはいくつかの倫理的な問題があります。新しいフレームワークは、倫理によって導かれます。設計原則であり、より正確で信頼できるモデルを構築するためのステップです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Unsupervised Domain Adaptation in NLP---A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_5.html">
      <font color="black">Neural Unsupervised Domain Adaptation in NLP---A Survey</font>
    </a>
  </h2>
  <font color="black">最後に、将来の方向性、特に将来のNLPの分布外一般化の幅広い必要性について概説します。対照的に、特にドメインシフトの下で、ラベルなしデータから学習することは依然として課題です。この調査では、最新の進歩に動機付けられています。ラベル付けされたターゲットドメインデータを必要としないニューラル教師なしドメイン適応技術をレビューします。 
[概要]ドメインの概念も再検討し、最も注目された自然言語処理タスクのタイプのバイアスを明らかにします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-31">
        <br><font color="black">2020-05-31</font>
      </time>
    </span>
</section>
<!-- paper0: PPG-based singing voice conversion with adversarial representation
  learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_6.html">
      <font color="black">PPG-based singing voice conversion with adversarial representation
  learning</font>
    </a>
  </h2>
  <font color="black">音色とメロディーのパフォーマンスを向上させるために、敵対的な歌手の混乱モジュールとメル回帰表現学習モジュールがモデル用に設計されています。客観的および主観的な実験が私たちのプライベートな中国の歌唱コーパスで行われます。歌声変換（SVC）の目的歌の内容とメロディーを保ちながら、ある歌手の声を他の歌手の声に変換すること。 
[概要]自然とイントネーションを保ちながら曲を変換するために新しいモデルが使用されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Decoupling Pronunciation and Language for End-to-end Code-switching
  Automatic Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_7.html">
      <font color="black">Decoupling Pronunciation and Language for End-to-end Code-switching
  Automatic Speech Recognition</font>
    </a>
  </h2>
  <font color="black">このモデルは、音声から音素（A2P）ネットワークと音素からテキスト（P2T）ネットワークの2つの部分に分離されています。一方、トレーニングプロセス中に、単一の音声データに対して複数の音素シーケンス候補をリアルタイムで生成します。 。このネットワークは、大量の外部の対になっていないテキストデータで事前にトレーニングすることができます。 
[ABSTRACT]分離トランスモデルは、単言語のペアデータの使用を提案します。コードへの高い依存性を低減します-ペアのトレーニングデータを切り替えます。提案された方法は、パブリックマンダリンで提案されます-英語のコード切り替えミックス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Scaling Laws for Autoregressive Generative Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_8.html">
      <font color="black">Scaling Laws for Autoregressive Generative Modeling</font>
    </a>
  </h2>
  <font color="black">クロスエントロピー損失には、$ S（$ True $）+ D _ {\ mathrm {KL}}（$ True $ || $ Model $）$としての情報理論的解釈があり、経験的スケーリング則は、両方の予測を示唆しています。真のデータ分布のエントロピーと、真の分布とモデル分布の間のKLダイバージェンス。すべての場合において、自動回帰トランスフォーマーは、パワー法則と一定のスケーリング法則に従って、モデルサイズと計算バジェットが増加するにつれて、パフォーマンスがスムーズに向上します。これらの結果を総合すると、スケーリング則が、ダウンストリームタスクを含むニューラルネットワークのパフォーマンスに重要な影響を与える場合。 
[ABSTRACT]モデルがモデルの8％を占めるため、モデル時間は改善されます。モデルは、サイズ、モデル、およびべき乗則のあるモデルで見つけることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: The Volctrans Machine Translation System for WMT20 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_9.html">
      <font color="black">The Volctrans Machine Translation System for WMT20</font>
    </a>
  </h2>
  <font color="black">私たちの基本的なシステムはトランスフォーマーに基づいており、いくつかのバリエーションがあります（より広いまたはより深いトランスフォーマー、動的畳み込み）。最終的なシステムには、テキストの前処理、データ選択、合成データの生成、高度なモデルアンサンブル、および多言語の事前トレーニングが含まれます。論文では、WMT20共有ニュース翻訳タスクに関するVolcTransシステムについて説明しています。 
[概要]最終的なシステムには、テキストの事前処理、データの選択、合成データの生成、および多言語の事前トレーニングが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Handling Class Imbalance in Low-Resource Dialogue Systems by Combining
  Few-Shot Classification and Interpolation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_10.html">
      <font color="black">Handling Class Imbalance in Low-Resource Dialogue Systems by Combining
  Few-Shot Classification and Interpolation</font>
    </a>
  </h2>
  <font color="black">低リソースの対話システムでの発話分類のパフォーマンスは、クラスラベルの必然的に高度なデータの不均衡によって制約されます。3つの異なるニューラルアーキテクチャの標準的なクロスエントロピートレーニングよりもマクロF1スコアが大幅に改善され、仮想の改善が実証されています。患者の対話データセットと、Switchboard対話行為分類データセットのリソースの少ないエミュレーション。私たちは、この現象に取り組むために特別に設計された新しいエンドツーエンドのペアワイズ学習フレームワークを提示します。発話表現と、発話表現の補間によるデータの拡張。 
[ABSTRACT]新しいシステムは、発話表現にいくつかのショット分類機能を導入し、発話表現の補間によってデータを拡張することにより、この現象に取り組むように設計されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Graph-based Topic Extraction from Vector Embeddings of Text Documents:
  Application to a Corpus of News Articles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_11.html">
      <font color="black">Graph-based Topic Extraction from Vector Embeddings of Text Documents:
  Application to a Corpus of News Articles</font>
    </a>
  </h2>
  <font color="black">ここでは、自然言語処理からの強力なベクトル埋め込みと、コーパス内のクラスターの数について事前に仮定することなく、さまざまな解像度で自然パーティションを明らかにできるマルチスケールグラフパーティショニングのツールを組み合わせた教師なしフレームワークを紹介します。他の一般的なクラスタリングおよびトピックモデリング手法とのエンドツーエンドの比較によるグラフベースのクラスタリング。また、従来のBag-of-WordsからDoc2Vec、最近のトランスフォーマーベースのモデルBertまで、さまざまなテキストベクトルの埋め込みを評価します。この比較作業は2016年の大統領選挙期間中の米国のニュース報道のコーパスの分析を通じて紹介されました。
[要約]膨大な量のテキストを管理および監視するのに役立つ効率的な方法を開発する必要性が高まっています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: DisenE: Disentangling Knowledge Graph Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_12.html">
      <font color="black">DisenE: Disentangling Knowledge Graph Embeddings</font>
    </a>
  </h2>
  <font color="black">さらに、エンティティ表現の各コンポーネントが分離されたセマンティックな側面を独立して反映するように促す2つの新しいレギュラライザーを導入します。実験結果は、提案されたDisenEがKGEの解釈可能性に対処するための視点を調査し、改善する効果的な方法であることが証明されていることを示しています。リンク予測タスクのパフォーマンス..コードとデータセットはhttps://github.com/KXY-PUBLIC/DisenEでリリースされています。 
[概要]新しい研究は主にブラックボックスニューラルモデルに基づいています。これにより、学習した表現の解釈が困難になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: What Does This Acronym Mean? Introducing a New Dataset for Acronym
  Identification and Disambiguation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_13.html">
      <font color="black">What Does This Acronym Mean? Introducing a New Dataset for Acronym
  Identification and Disambiguation</font>
    </a>
  </h2>
  <font color="black">さらに、既存のデータセットは主に医療ドメインに限定されており、他のドメインは無視されます。このデータセットには、以前の科学AIデータセットよりも大幅に大きい17,506文が含まれています。これら2つの制限に対処するために、最初に手動で注釈を付けた大きなAIを作成します。科学領域のデータセット。 
[概要]頭字語とフレーズの候補リストは、テキストを理解するために重要です。これは、手動で注釈が付けられたaiデータセットのサイズが短いためです。これにより、各頭字語の正しい意味を簡単に見つけることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Regularized Forward-Backward Decoder for Attention Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_14.html">
      <font color="black">Regularized Forward-Backward Decoder for Attention Models</font>
    </a>
  </h2>
  <font color="black">小さいTEDLIUMv2と大きいLibriSpeechデータセットでアプローチを評価し、両方で一貫した改善を実現します。現在、注意モデルは音声認識の人気のある候補の1つです。このデコーダーは事前に時間反転ターゲットラベルで最適化されています。将来のコンテキストからの知識を追加することにより、トレーニング中に標準デコーダーをサポートします。 
[概要]多くの研究は、これらのモデルのパフォーマンスを向上させるために、主にエンコーダー構造またはアテンションモジュールに焦点を当てています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
</section>
<!-- paper0: Second-Order Unsupervised Neural Dependency Parsing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_15.html">
      <font color="black">Second-Order Unsupervised Neural Dependency Parsing</font>
    </a>
  </h2>
  <font color="black">2次構文解析と語彙化の両方の恩恵を受けながらこの問題を回避するために、合意ベースの学習フレームワークを使用して、2次非語彙化モデルと1次語彙化モデルを共同でトレーニングします。2次モデルでは、数文法規則の数は、語彙サイズの増加とともに3次的に増加し、数千の単語を含む可能性のある語彙化モデルのトレーニングを困難にします。複数のデータセットでの実験は、最近の最先端と比較した2次モデルの有効性を示しています。メソッド。 
[概要]プロジェクトは、教師あり依存関係の2次解析に触発されました。教師なし神経依存関係モデルの2次拡張が含まれます。文法規則の数が3次的に増加し、数千の単語を含む可能性のある語彙化モデルのトレーニングが困難になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Character Entropy in Modern and Historical Texts: Comparison Metrics for
  an Undeciphered Manuscript -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_16.html">
      <font color="black">Character Entropy in Modern and Historical Texts: Comparison Metrics for
  an Undeciphered Manuscript</font>
    </a>
  </h2>
  <font color="black">Voynicheseスクリプトの異常に予測可能な性質は、特定のスクリプトまたは転写システム、基礎となる言語、または換字式暗号に起因するものではありません。グリフ構成の実質的な操作では、条件付きエントロピーレベルを自然言語に合わせるのに十分ではないことを示します。 Voynicheseの条件付き文字エントロピーの分析とともに、Voynichスクリプトと言語の特性を研究するためのこれらのコーパスの有用性。 
[概要]これらのコーパスは、イェール大学のボイニッチワーキンググループによるその後の作業で使用されます。研究によると、グリフ構成の実質的な操作は、自然言語の製品レベルを調整するのに十分ではないことが示されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Bridging the Modality Gap for Speech-to-Text Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_17.html">
      <font color="black">Bridging the Modality Gap for Speech-to-Text Translation</font>
    </a>
  </h2>
  <font color="black">これらの問題に対処するために、音声とテキストの間のモダリティギャップを埋めることによってエンドツーエンドモデルのパフォーマンスを向上させることを目的とした音声翻訳のための音声からテキストへの適応（STAST）モデルを提案します。エンドツーエンド音声翻訳は、ある言語の音声をエンドツーエンドの方法で別の言語のテキストに翻訳することを目的としています。さらに、音声とテキスト表現の間の距離を縮めるためのクロスモーダル適応方法を紹介します。 
[概要]ほとんどの既存の方法では、エンコーダーを使用します。単一のエンコーダーを備えたデコーダー構造を使用して、音響表現と意味情報を同時に学習します。これらには、音声変換端を分離して、テキストとテキストモデル間のギャップに一致するモデルを作成することが含まれます。また、音声とテキスト表現の間の距離を縮めるためのクロスモーダル適応方法を導入します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Bayesian Methods for Semi-supervised Text Annotation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_18.html">
      <font color="black">Bayesian Methods for Semi-supervised Text Annotation</font>
    </a>
  </h2>
  <font color="black">最近提案されたベイジアンアンサンブル法は、アノテーターのラベルをトレーニング済みモデルの予測と組み合わせるのに役立ちます。ベイジアン深層学習法を使用すると、信頼できず、再注釈が必要になる可能性のある注釈を発見できます。人間の注釈は重要な情報源です。自然言語理解アプローチの開発において。 
[概要]注釈プロセスをガイドする2つの半教師あり方法を提案します。この方法を使用すると、アノテーターのラベルをトレーニング済みモデルの予測と組み合わせることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: CAPT: Contrastive Pre-Training for Learning Denoised Sequence
  Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_19.html">
      <font color="black">CAPT: Contrastive Pre-Training for Learning Denoised Sequence
  Representations</font>
    </a>
  </h2>
  <font color="black">ただし、このような事前トレーニングアプローチは、ノイズと共変する表現を学習する傾向があり、事前トレーニング段階と微調整段階の間の不一致につながります。提案されたCAPTは、元のシーケンスの表現とその破損した表現の間の一貫性を促進します。教師なしインスタンスごとのトレーニング信号を介したバージョン..BERTなどの事前トレーニング済みの自己監視モデルは、特に自然言語処理のシーケンス表現の学習で目覚ましい成功を収めています。 
[ABSTRACT] pre-トレーニングは、このタイプのノイズのベンチマークバージョンです。これは、以前の以前のモデルが破損していて、元の入力を復元しようとしていることを示しています。ただし、モデルはさまざまなレベルのノイズで動作します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: From Hero to Zéroe: A Benchmark of Low-Level Adversarial Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_20.html">
      <font color="black">From Hero to Zéroe: A Benchmark of Low-Level Adversarial Attacks</font>
    </a>
  </h2>
  <font color="black">NLPの現在の主力製品であるRoBERTaが攻撃に失敗することを示します。ソーシャルメディアなどの一般的なアプリケーションシナリオでは、これらは現実的ではなく、代わりにキャラクターレベルでの低レベルの攻撃に焦点を当てていると主張します。将来のより人間らしいNLPモデルの堅牢性をテストするためのベンチマーク。 
[概要]私たちのデータセットは、nlpモデルのような将来のより人間的な堅牢性をテストするためのベンチマークを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: Predicting Subjective Features of Questions of QA Websites using BERT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_21.html">
      <font color="black">Predicting Subjective Features of Questions of QA Websites using BERT</font>
    </a>
  </h2>
  <font color="black">したがって、Q＆A Webサイトでのモデレートアクションを自動化するソリューションを提供するという全体的な目標を掲げて、QA Webサイトでの質問の20の品質または主観的な側面を予測するモデルを提供することを目指しています。この目的のために、CrowdSourceチームが収集したデータを使用しました。 2019年のGoogleResearchと、問題に関する微調整された事前トレーニング済みBERTモデル。Mean-Squared-Error（MSE）による評価に基づいて、モデルは2エポックのトレーニング後に0.046の値を達成しましたが、改善されませんでした。実質的に次のもので。 
[概要]ユーザーは主にコミュニティレポートに依存してコンテンツを評価します。これには、通常のユーザーと経験豊富なユーザーの時間が失われる、一部のレポートの品質が低い、新しいユーザーへのフィードバックが妨げられるなどの深刻な問題があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-24">
        <br><font color="black">2020-02-24</font>
      </time>
    </span>
</section>
<!-- paper0: A Comparative Analysis of Knowledge-Intensive and Data-Intensive
  Semantic Parsers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_22.html">
      <font color="black">A Comparative Analysis of Knowledge-Intensive and Data-Intensive
  Semantic Parsers</font>
    </a>
  </h2>
  <font color="black">次に、全体的に同等のパフォーマンスにもかかわらず、知識とデータを大量に消費するモデルが、理論的特性によって説明できる方法で、さまざまなタイプのエラーを生成することを示します。この分析は、パーサー開発の新しい方向性につながります。タスクに依存しないセマンティック構文解析における2つの主要なアプローチの現象指向の比較分析を提示します：古典的な知識集約型モデルとニューラルデータ集約型モデル。 
[概要]新しいターゲット構造を導入しました。これは、以前のデータ駆動型パーサーよりも正確にセマンティックグラフを生成できるセントリックパーサーです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-04">
        <br><font color="black">2019-07-04</font>
      </time>
    </span>
</section>
<!-- paper0: Measuring non-trivial compositionality in emergent communication -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_23.html">
      <font color="black">Measuring non-trivial compositionality in emergent communication</font>
    </a>
  </h2>
  <font color="black">最大のリンゴ）は、それらの構成要素の意味のより複雑な関数です..青いオブジェクトのセットと円のセットの共通部分）..それらは、自明でない構成性を構成性の失敗として扱います。 
[要約]複雑な信号（アップルなど）の意味がntcを検出できない場合、プロトコルは自明ではない構成（ntc）です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Why and when should you pool? Analyzing Pooling in Recurrent
  Architectures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_24.html">
      <font color="black">Why and when should you pool? Analyzing Pooling in Recurrent
  Architectures</font>
    </a>
  </h2>
  <font color="black">研究されたプーリング手法の中で、最大注意が最も効果的であり、いくつかのテキスト分類タスクで大幅なパフォーマンスの向上をもたらします。勾配伝播を分析することにより、プーリングがBiLSTMと比較してより良い勾配フローを促進することを発見します。 BiLSTMは、シーケンスの最初と最後のトークンに向かって位置的に偏っています。 
[概要]プーリングベースのアーキテクチャは、学習能力と位置バイアスにおいて、プーリング以外の相互作用とは大幅に異なることがわかりました。これにより、パフォーマンス上の利点が明らかになります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: A Chinese Text Classification Method With Low Hardware Requirement Based
  on Improved Model Concatenation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_25.html">
      <font color="black">A Chinese Text Classification Method With Low Hardware Requirement Based
  on Improved Model Concatenation</font>
    </a>
  </h2>
  <font color="black">一方、このモデルのハードウェア要件は、BERTベースのモデルよりもはるかに低くなっています。ハードウェア要件の低い中国のテキスト分類モデルの精度パフォーマンスを向上させるために、このペーパーでは、改良された連結ベースのモデルを設計します。 TextCNN、LSTM、Bi-LSTMを含む5つの異なるサブモデルの連結。既存のアンサンブル学習方法と比較して、テキスト分類ミッションでは、このモデルの精度は2％高くなります。 
[概要]モデルの精度は、以前のモデルと比較して2％高くなっています。モデルは高度なモデルに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Exploiting Sentence Order in Document Alignment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_26.html">
      <font color="black">Exploiting Sentence Order in Document Alignment</font>
    </a>
  </h2>
  <font color="black">また、同じ多言語埋め込みを使用する同等のコーパスメソッドよりも優れており、最終目標がセンテンスレベルのbitextであっても、センテンスの順序を活用することが有益であることを示しています。 、最新のParaCrawlリリースで使用されているドキュメントの位置合わせ方法を上回っています。候補の生成と候補の再スコアリングの両方に文の順序情報を組み込んだ簡単なドキュメントの位置合わせ方法を紹介します。 
[概要]私たちの方法では、wmt16ドキュメントアライメント共有タスクで以前に公開された最良の結果と比較して、エラーが61％減少します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: The geometry of integration in text classification RNNs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_27.html">
      <font color="black">The geometry of integration in text classification RNNs</font>
    </a>
  </h2>
  <font color="black">具体的には、アーキテクチャとデータセット全体で、RNNは、基礎となるメカニズムとして低次元のアトラクタマニホールドを使用して、テキストを処理するときに各クラスの証拠を蓄積します。この作業は、特定の自然言語処理タスクのコンテキストでこれらの質問に対処します：テキスト分類..さまざまなタスクにリカレントニューラルネットワーク（RNN）が広く適用されているにもかかわらず、RNNがこれらのタスクをどのように解決するかについての統一された理解はとらえどころのないままです。 
[概要]トレーニングされたrnnsでどの動的パターンが発生するかは不明です。これらのパターンはトレーニングデータセットまたはタスクによって異なります。これらは、自然および合成のテキスト分類の分析に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: INT8 Winograd Acceleration for Conv1D Equipped ASR Models Deployed on
  Mobile Devices -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_28.html">
      <font color="black">INT8 Winograd Acceleration for Conv1D Equipped ASR Models Deployed on
  Mobile Devices</font>
    </a>
  </h2>
  <font color="black">ConvDFSMNモデルとWav2letterモデルの両方で広範な実験を行います。量子化とWinograd畳み込みの組み合わせによる情報損失を回避するために、範囲スケール量子化（RSQ）トレーニング方法を提案して、量子化された数値範囲を拡大し、高精度の値..さらに、改良されたConv1Dを装備したDFSMN（ConvDFSMN）モデルは、モバイル展開用に設計されています。 
[概要]この記事の新しいバージョンが新しい論文で発表されました。量子化と高速畳み込みを組み合わせて、asrモデルのモバイルデバイスで効率の加速を実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: FT Speech: Danish Parliament Speech Corpus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_29.html">
      <font color="black">FT Speech: Danish Parliament Speech Corpus</font>
    </a>
  </h2>
  <font color="black">デンマーク語の既存の演説コーパスよりも、持続時間、語彙、自発的スピーチの量が大幅に大きく、読み上げと口述のデータに大きく限定されています。ベースラインの結果は、新しいコーパスで14.01WERを達成することを示しています。 ..コーパスの品質を評価するために、新しいリソースで自動音声認識システムをトレーニングし、デンマーク語でこれまでで最大のパブリックASRコーパスであるSpr \ r {a} kbankenのデンマーク語部分でトレーニングされたシステムと比較します。 
[概要]新しいコーパスには、1,800フィートを超える既存の音声が含まれています。800時間以上の古い音声が含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-25">
        <br><font color="black">2020-05-25</font>
      </time>
    </span>
</section>
<!-- paper0: Seen and Unseen emotional style transfer for voice conversion with a new
  emotional speech dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_30.html">
      <font color="black">Seen and Unseen emotional style transfer for voice conversion with a new
  emotional speech dataset</font>
    </a>
  </h2>
  <font color="black">このようにして、ネットワークは、見えている感情スタイルと見えない感情スタイルの両方を新しい発話に転送できます。提案されたフレームワークが、ベースラインフレームワークを一貫して上回ることにより、優れたパフォーマンスを達成することを示します。このようなネットワークは、感情スタイルの固定セットを記憶することを学習します。 。 
[概要]以前の研究では、エンコーダー-デコーダーネットワークを使用して感情的なプロソディを解きほぐすことが可能であることが示されています。提案されたフレームワークは、トレーニング中に感情的なスタイルを転送するために事前にトレーニングされた音声感情認識モデルを利用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Non-Autoregressive Transformer ASR with CTC-Enhanced Decoder Input -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_31.html">
      <font color="black">Non-Autoregressive Transformer ASR with CTC-Enhanced Decoder Input</font>
    </a>
  </h2>
  <font color="black">この問題に対処するために、CTCモジュールの予測を精緻化することによってターゲットシーケンスを生成するCTC拡張NARトランスフォーマーを提案します。ほとんどのNARトランスフォーマーは、MASKトークンで満たされた固定長シーケンスまたはエンコーダー状態からコピーされた冗長シーケンスを取ります。デコーダー入力として、それらは効率的なターゲット側の情報を提供できないため、精度の低下につながります。実験結果は、私たちの方法が以前のすべてのNARの対応物よりも優れており、0.0〜0.3の絶対CER低下のみで強力なARベースラインよりも50倍速いデコード速度を達成することを示していますAishell-1およびAishell-2データセット。 
[ABSTRACT] ctの方法は、以前のすべてのnarモデルよりも優れており、ターゲット側のデコード速度が0. 0. 0.0の50倍高速になっています。 0.3aishell-1およびaishell-2データセットでの絶対cer劣化</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Porous Lattice-based Transformer Encoder for Chinese NER -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_32.html">
      <font color="black">Porous Lattice-based Transformer Encoder for Chinese NER</font>
    </a>
  </h2>
  <font color="black">4つのデータセットでの実験結果は、私たちのモデルが最先端のモデルよりも最大9.47倍高速である一方で、そのパフォーマンスとほぼ同等であることを示しています。まず、相対位置と組み合わせた格子認識の自己注意を調査します。格子構造における効果的な単語情報を探索するための表現。さらに、隣接するトークン間の局所的な依存関係を強化するために、2つの非隣接トークンごとに共有ピボットを介して接続される自己注意計算処理中に新しい多孔質構造を提案します。ノード。 
[概要]論文では、中国語の固有表現抽出用の多孔質格子ベースのトランスフォーマーエンコーダーを提案します。トランスフォーマーのマスクメカニズムにより、GPU並列処理をより有効に活用し、コンピューティングをバッチ処理して、隣接するエンティティ間のローカル依存関係を強化できます。トークン、セルフアテンションコンピューティング中の新しい多孔質構造を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-07">
        <br><font color="black">2019-11-07</font>
      </time>
    </span>
</section>
<!-- paper0: A Comprehensive Survey on Word Representation Models: From Classical to
  State-Of-The-Art Word Representation Language Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_33.html">
      <font color="black">A Comprehensive Survey on Word Representation Models: From Classical to
  State-Of-The-Art Word Representation Language Models</font>
    </a>
  </h2>
  <font color="black">さらに、このような表現は、さまざまなNLP関連タスクのさまざまな機械学習（ML）アルゴリズムで利用できます。この調査では、古典的な状態から現代の状態まで、さまざまな単語表現モデルとその表現力を調査します。 -最先端の単語表現言語モデル（LMS）。さまざまなテキスト表現方法について説明し、SOTALMを含むNLPのコンテキストでモデル設計が開花しました。 
[概要]さまざまなテキスト表現方法について説明します。モデルデザインは言語のコンテキストで開花しました。例は機械学習（ml）アルゴリズムで使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: CASS-NAT: CTC Alignment-based Single Step Non-autoregressive Transformer
  for Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_34.html">
      <font color="black">CASS-NAT: CTC Alignment-based Single Step Non-autoregressive Transformer
  for Speech Recognition</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案された方法が、外部LMなしのLibrispeechテストクリーン/その他のデータセットで3.8％/ 9.1％のWERを達成し、Aishell1北京語コーパスでそれぞれ5.8％のCERを達成することを示しています1。推論中、エラーベースのアライメントサンプリングこの方法は、CTC出力空間に適用され、WERを削減し、並列処理も保持することが提案されています。この情報は、各トークンの音響表現を並列に抽出するために使用されます。これは、埋め込みという単語を置き換えるトークンレベルの音響埋め込みと呼ばれます。自己回帰トランス（AT）で、デコーダーでの並列生成を実現します。 
[概要] ctcアライメントには、デコーダー入力用のトークンの数の情報が含まれます。これには、各トークンの音響の期間が含まれます。提案された方法は、ctcの音声空間に適用されることが提案されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Active Sentence Learning by Adversarial Uncertainty Sampling in Discrete
  Space -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_35.html">
      <font color="black">Active Sentence Learning by Adversarial Uncertainty Sampling in Discrete
  Space</font>
    </a>
  </h2>
  <font color="black">AUSDSは、人気のある事前トレーニング済み言語モデルによって生成された潜在空間に文をマッピングし、敵対的攻撃による注釈のための有益なラベルなしテキストサンプルを発見します。5つのデータセットでの実験結果は、AUSDSが有効性に関する強力なベースラインを上回っていることを示しています。提案されたアプローチは非常に効率的です。 10倍以上のスピードアップを備えた従来の不確実性サンプリングと比較して。 
[概要]アクティブラーニングの一般的な不確実性サンプリング方法は時間がかかり、リアルタイムではほとんど機能しないため、効果のないサンプル選択につながる可能性があると主張します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-17">
        <br><font color="black">2020-04-17</font>
      </time>
    </span>
</section>
<!-- paper0: Tasty Burgers, Soggy Fries: Probing Aspect Robustness in Aspect-Based
  Sentiment Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_36.html">
      <font color="black">Tasty Burgers, Soggy Fries: Probing Aspect Robustness in Aspect-Based
  Sentiment Analysis</font>
    </a>
  </h2>
  <font color="black">SemEval 2014データセットに基づいて、ABSAモデルのアスペクトロバスト性の包括的なプローブとしてアスペクトロバストネステストセット（ARTS）を構築します。この問題を解決するために、ABSAテストセットを充実させるためのシンプルで効果的なアプローチを開発します。 ARTSの92％のデータは、人間の評価によるすべての側面で高い流暢さと望ましい感情を示しています。 
[ABSTRACT]既存のabsaテストを使用して、モデルが感情と非ターゲットの側面を区別できるかどうかを調べることができます。テストセットでは、アートテストをどのように効果的に行うことができるかも調べることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Joint Persian Word Segmentation Correction and Zero-Width Non-Joiner
  Recognition Using BERT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_37.html">
      <font color="black">Joint Persian Word Segmentation Correction and Zero-Width Non-Joiner
  Recognition Using BERT</font>
    </a>
  </h2>
  <font color="black">慎重に収集された500文のコーパスで、高レベルの難易度でマクロ平均F1スコア92.40％を達成しました。単語はペルシア語の書記体系で適切にセグメント化されています。ただし、実際には、これらの書き込みルールは無視されることが多く、1つの単語がばらばらに書き込まれ、複数の単語が空白なしで書き込まれます。このペーパーでは、単語のセグメンテーションとゼロ幅非接合子（ZWNJ）認識の問題について説明します。ペルシャ語で、シーケンスラベリング問題として共同でアプローチします。 
[要約]この論文は、ペルシア語での単語のセグメンテーションとゼロ幅非接合子（zwnj）認識の問題に取り組んでいます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-01">
        <br><font color="black">2020-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: How to Probe Sentence Embeddings in Low-Resource Languages: On
  Structural Design Choices for Probing Task Evaluation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_38.html">
      <font color="black">How to Probe Sentence Embeddings in Low-Resource Languages: On
  Structural Design Choices for Probing Task Evaluation</font>
    </a>
  </h2>
  <font color="black">したがって、将来的には、より公平で包括的な文レベルのプロービング評価を複数の言語で実行する必要があります。注釈付きプロービングデータセットのサイズや評価に使用される分類子のタイプなどの設計上の選択が、プロービングの結果に（場合によっては実質的に）影響することを示します。次に、英語を特定するときに、「安定した領域」にあるデザインの選択肢を使用して多言語設定で埋め込みを調査し、英語での結果が他の言語に転送されないことを確認します。 
[ABSTRACT]「安定した地域」でのタスクの調査。英語で識別され、英語での結果が他の言語に転送されないことがわかりました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-16">
        <br><font color="black">2020-06-16</font>
      </time>
    </span>
</section>
<!-- paper0: TopicModel4J: A Java Package for Topic Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_39.html">
      <font color="black">TopicModel4J: A Java Package for Topic Models</font>
    </a>
  </h2>
  <font color="black">Javaプログラミング環境のTopicModel4Jは、データアナリストがアルゴリズムを実行するための使いやすいインターフェイスを提供し、データを簡単に入力および出力できるようにします。さらに、このパッケージは、テキストの分割など、いくつかの非構造化テキスト前処理技術を提供します。データを単語に変換し、単語を小文字にし、レンマ化を実行し、不要な文字、URL、ストップワードを削除します。このペーパーでは、トピックモデルをフィッティングするための13種類の代表的なアルゴリズムを含むJavaパッケージTopicModel4Jを設計および実装します。 
[概要]このペーパーでは、Javaパッケージを設計および実装します。topicmodel4j。トピックモデルをフィッティングするための13種類の代表的なアルゴリズムが含まれています。このパッケージは、非構造化テキスト前処理技術を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Paraphrase Generation as Zero-Shot Multilingual Translation:
  Disentangling Semantic Similarity from Lexical and Syntactic Diversity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_40.html">
      <font color="black">Paraphrase Generation as Zero-Shot Multilingual Translation:
  Disentangling Semantic Similarity from Lexical and Syntactic Diversity</font>
    </a>
  </h2>
  <font color="black">最近の研究では、多言語ニューラル機械翻訳（NMT）モデルを使用して、ある文が同じ言語で別の文をどれだけうまく言い換えているかを判断できることが示されています（Thompson and Post、2020）。ただし、標準のビーム検索を使用してこのようなモデルから言い換えを生成しようとすると、些細なコピーまたはニアコピーが生成されます。人間による評価を行って、英語の大規模な合成言い換えデータベースParaBank 2でトレーニングされた言い換えと比較します（Hu et al。、 2019c）そして、私たちの方法が、同じレベルの語彙の多様性に対して、意味をよりよく保存し、より文法的な言い換えを生成することを発見します。私たちのアプローチは、単一の多言語NMTモデルから多くの言語で言い換えを生成することを可能にします。 
[要約]単純な言い換え生成アルゴリズムは、入力に存在するnグラムの生成を阻止します。入力とデータベース間の語彙の多様性の量は、判断できる期間を制御できます。さらに、人間によるより小さな評価は、私たちの言語も機能することを示しています。英語以外の2つの言語で</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-11">
        <br><font color="black">2020-08-11</font>
      </time>
    </span>
</section>
<!-- paper0: Pre-trained Summarization Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/cs.CL/paper_41.html">
      <font color="black">Pre-trained Summarization Distillation</font>
    </a>
  </h2>
  <font color="black">3番目の、より単純なアプローチは、「縮小と微調整」（SFT）です。これは、パラメーターをより小さな学生モデルにコピーしてから微調整することにより、明示的な蒸留を回避します。分類および回帰タスクのためのBERTの蒸留に関する最近の研究は強力です。直接知識蒸留を使用したパフォーマンス..ペガサスとBARTの蒸留に関するこれらの3つのアプローチ、現在および以前の最先端の事前トレーニング済み要約モデルを比較し、SFTがCNN / DailyMailでの知識蒸留および疑似ラベル付けよりも優れていることを確認します。データセットですが、より抽象的なXSUMデータセットでは疑似ラベル付けを実行しません。 
[概要]モデルをより小さな学生モデルに蒸留することは、実際の使用にとって非常に重要になっています。ただし、nlpの文献で提案されているさまざまな直接的な方法があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-24">
        <br><font color="black">2020-10-24</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: One in a hundred: Select the best predicted sequence from numerous
  candidates for streaming speech recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.AS/paper_0.html">
      <font color="black">One in a hundred: Select the best predicted sequence from numerous
  candidates for streaming speech recognition</font>
    </a>
  </h2>
  <font color="black">RNNトランスデューサーと改良された注意ベースのシーケンス間モデルはストリーミング音声認識に広く適用されています。これらの2つのエンドツーエンドモデルと比較して、CTCモデルはトレーニングと推論においてより効率的です。ベースラインCTCモデルよりも文字エラー率を最大20％削減します。 
[要約]結果は、提案されたモデルが高速で簡単な方法でストリームデコードを実装できることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Melody-Conditioned Lyrics Generation with SeqGANs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.AS/paper_1.html">
      <font color="black">Melody-Conditioned Lyrics Generation with SeqGANs</font>
    </a>
  </h2>
  <font color="black">ただし、既存のアプローチの多くは、音楽や歌詞の作成に関する事前の知識に大きく依存しているか、メロディック情報とそのテキストとの関係を大幅に破棄することでタスクを単純化しすぎています。入力条件が評価指標に悪影響を与えないことを示します。より意味のある結果を生成するためのネットワーク..SequenceGenerative Adversarial Networks（SeqGAN）に基づくエンドツーエンドのメロディ条件付き歌詞生成システムを提案します。これは、対応するメロディを入力として与えられた歌詞の行を生成します。 
[ABSTRACT]初期のルール-データに基づく---テキストメッセージに基づく。システムは、入力として対応するメロディーを指定して歌詞の行を生成します。入力条件が評価メトリックに悪影響を与えないことを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: PPG-based singing voice conversion with adversarial representation
  learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.AS/paper_2.html">
      <font color="black">PPG-based singing voice conversion with adversarial representation
  learning</font>
    </a>
  </h2>
  <font color="black">音色とメロディーのパフォーマンスを向上させるために、敵対的な歌手の混乱モジュールとメル回帰表現学習モジュールがモデル用に設計されています。具体的には、2つの別々のエンコーダーを実装します。1つはPPGをコンテンツとしてエンコードし、もう1つはメルスペクトログラムを音響および音楽情報を提供します。ベースラインと比較して、私たちの方法は、自然さ、メロディー、および音声の類似性の点で変換パフォーマンスを大幅に向上させることができます。 
[概要]自然とイントネーションを保ちながら曲を変換するために新しいモデルが使用されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Decoupling Pronunciation and Language for End-to-end Code-switching
  Automatic Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.AS/paper_3.html">
      <font color="black">Decoupling Pronunciation and Language for End-to-end Code-switching
  Automatic Speech Recognition</font>
    </a>
  </h2>
  <font color="black">このモデルは、音声から音素（A2P）ネットワークと音素からテキスト（P2T）ネットワークの2つの部分に分離されています。一方、トレーニングプロセス中に、単一の音声データに対して複数の音素シーケンス候補をリアルタイムで生成します。次に、生成された音素とテキストのペアデータを使用して、P2Tネットワークをトレーニングします。 
[ABSTRACT]分離トランスモデルは、単言語のペアデータの使用を提案します。コードへの高い依存性を低減します-ペアのトレーニングデータを切り替えます。提案された方法は、パブリックマンダリンで提案されます-英語のコード切り替えミックス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Large-Scale MIDI-based Composer Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.AS/paper_4.html">
      <font color="black">Large-Scale MIDI-based Composer Classification</font>
    </a>
  </h2>
  <font color="black">当社のMIDIベースの作曲家システムは、いくつかのオーディオベースのベースライン分類システムよりも優れており、作曲家の分類にコンパクトなMIDI表現を使用することの有効性を示しています。モデルとして畳み込みリカレントニューラルネットワークを使用することにより、MIDIベースの作曲家分類システムは10コンポーザーと100コンポーザーを実現します。 -作曲家の分類精度は、それぞれ0.648と0.385（30秒のクリップで評価）と0.739と0.489（楽曲で評価）です。入力表現としてピアノロール、オンセットロール、速度ロールを使用し、ディープニューラルを使用することを提案します。分類器としてのネットワーク。 
[ABSTRACT]作曲家分類システムは最大100人の作曲家の問題です。システムはいくつかのオーディオベースのベースライン分類システムよりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Regularized Forward-Backward Decoder for Attention Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.AS/paper_5.html">
      <font color="black">Regularized Forward-Backward Decoder for Attention Models</font>
    </a>
  </h2>
  <font color="black">このデコーダーは、事前に時間反転されたターゲットラベルで最適化され、将来のコンテキストからの知識を追加することにより、トレーニング中に標準デコーダーをサポートします。ただし、デコーダーはほとんど無視されます。この論文では、トレーニングフェーズ。 
[概要]多くの研究は、これらのモデルのパフォーマンスを向上させるために、主にエンコーダー構造またはアテンションモジュールに焦点を当てています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
</section>
<!-- paper0: Speech Synthesis and Control Using Differentiable DSP -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.AS/paper_6.html">
      <font color="black">Speech Synthesis and Control Using Differentiable DSP</font>
    </a>
  </h2>
  <font color="black">この作業では、さまざまな変動要因を明示的に制御できるようにする（ただし必須ではない）ことで、テキストの多様な音声表現を生成できる音声合成システムに移行します。これは、微分可能デジタル信号処理（DDSP）（以前は）を採用することで実現されます。これらの変動要因を明らかにする、音声ではなく音楽にのみ使用されます。このような変動要因の制御を提供する新しいニューラルボコーダーを提案します。 
[概要]提案されたアプローチは、リアルな音色で自然なスピーチを生成できます。変化の個々の要因は自由に制御できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Audio Fingerprint for High-specific Audio Retrieval based on
  Contrastive Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.AS/paper_7.html">
      <font color="black">Neural Audio Fingerprint for High-specific Audio Retrieval based on
  Contrastive Learning</font>
    </a>
  </h2>
  <font color="black">この目的のために、セグメントレベルの検索目的から派生した対照的な学習フレームワークを提示します。これらのレプリカは、小さな時間オフセットと、バックグラウンドノイズや部屋などのさまざまなタイプの歪みを適用することにより、元のオーディオ信号に対する劣化効果をシミュレートできます。マイクインパルス応答..トレーニングの各更新では、疑似ラベルのセット、ランダムに選択された元のサンプル、およびそれらの拡張レプリカで構成されるバッチが使用されます。 
[概要]この作業では、オーディオの短い単位セグメントから低次元を生成します。このフィンガープリントを使用して、高速の最大内積検索を作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-22">
        <br><font color="black">2020-10-22</font>
      </time>
    </span>
</section>
<!-- paper0: Frequency-Undersampled Short-Time Fourier Transform -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.AS/paper_8.html">
      <font color="black">Frequency-Undersampled Short-Time Fourier Transform</font>
    </a>
  </h2>
  <font color="black">短時間フーリエ変換（STFT）は通常、フレーム長と同じ数の周波数成分を計算し、隣接する時間フレームを半分以上オーバーラップさせます。その結果、スペクトログラム行列の成分数は信号の2倍以上になります。長さであるため、STFTは信号圧縮にはほとんど使用されません。オーディオ信号の簡単な数値例では、FUSTFTと反転の有効性を確認します。 
[ABSTRACT] stft-stft-は信号圧縮にはほとんど使用されません。さらに、スペクトログラム行列の成分数が目的の2倍以上になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Toward Speech Separation in The Pre-Cocktail Party Problem with TasTas -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.AS/paper_9.html">
      <font color="black">Toward Speech Separation in The Pre-Cocktail Party Problem with TasTas</font>
    </a>
  </h2>
  <font color="black">DPRNN-TasNetの再実装はhttps://github.com/ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separationでオープンソース化されており、TasTasはこのDPRNNの実装に基づいて実現されています。 -TasNet、この論文の結果は簡単に再現できると考えられています。公開WSJ0-5mixデータコーパスでの実験により、10.41dBのSDRが向上しました。オンライン音声データリミックス拡張\ cite {zeghidour2020wavesplit}が採用された場合トレーニングでは、11.14dBのSDRの改善を達成できます。 
[概要]公開wsj0-5mixデータコーパスでの実験の結果は10です。41dbsdrの改善。このペーパーの結果は簡単に再現できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Optimizing Short-Time Fourier Transform Parameters via Gradient Descent -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.AS/paper_10.html">
      <font color="black">Optimizing Short-Time Fourier Transform Parameters via Gradient Descent</font>
    </a>
  </h2>
  <font color="black">これは、入力全体で一定に保たれるパラメーター値だけでなく、さまざまな信号特性に対応するためにこれらのパラメーターが時間の経過とともに動的に変化する必要がある場合にも行われます。短時間フーリエ変換（STFT）は、信号処理の定番です。多くの場合、多くのオーディオタスクの最初のステップです。このペーパーでは、任意のコスト関数に関してSTFTパラメーターの勾配を取得し、STFTのような量の勾配降下最適化を採用できるようにするアプローチを示します。ウィンドウの長さ、またはSTFTホップサイズ。 
[概要]シンプルでシンプルなシステムを使用して、最高のスタリーを検索します。stftやstftなどの音楽的に有用な有用な要素</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: INT8 Winograd Acceleration for Conv1D Equipped ASR Models Deployed on
  Mobile Devices -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.AS/paper_11.html">
      <font color="black">INT8 Winograd Acceleration for Conv1D Equipped ASR Models Deployed on
  Mobile Devices</font>
    </a>
  </h2>
  <font color="black">ConvDFSMNモデルとWav2letterモデルの両方で広範な実験を実施します。自動音声認識（ASR）モデルの集中的な計算により、モバイルデバイスへの展開が妨げられます。量子化とWinogradコンボリューションの組み合わせによる情報損失を回避するために、範囲-量子化された数値範囲を拡大し、高精度の値から知識を抽出するために、スケーリングされた量子化（RSQ）トレーニング方法が提案されています。 
[概要]この記事の新しいバージョンが新しい論文で発表されました。量子化と高速畳み込みを組み合わせて、asrモデルのモバイルデバイスで効率の加速を実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: FT Speech: Danish Parliament Speech Corpus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.AS/paper_12.html">
      <font color="black">FT Speech: Danish Parliament Speech Corpus</font>
    </a>
  </h2>
  <font color="black">これは、FTスピーチがより自発的なスピーチでデンマークのASRの研究を促進するための貴重なリソースを提供することを示しています。コーパスの品質を評価するために、新しいリソースで自動音声認識システムをトレーニングし、デンマークの部分でトレーニングされたシステムと比較します。デンマークでこれまでで最大のパブリックASRコーパスであるSpr \ r {a} kbankenの。ベースラインの結果は、新しいコーパスで14.01WERを達成したことを示しています。 
[概要]新しいコーパスには、1,800フィートを超える既存の音声が含まれています。800時間以上の古い音声が含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-25">
        <br><font color="black">2020-05-25</font>
      </time>
    </span>
</section>
<!-- paper0: Seen and Unseen emotional style transfer for voice conversion with a new
  emotional speech dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.AS/paper_13.html">
      <font color="black">Seen and Unseen emotional style transfer for voice conversion with a new
  emotional speech dataset</font>
    </a>
  </h2>
  <font color="black">このようにして、ネットワークは目に見える感情スタイルと目に見えない感情スタイルの両方を新しい発話に移すことができます。提案されたフレームワークは、ベースラインフレームワークを一貫して上回ることにより、優れたパフォーマンスを達成することを示します。以前の研究では、感情的なプロソディを解きほぐすことが可能であることが示されています。ワンホット感情ラベルなどの離散表現を条件とするエンコーダー-デコーダーネットワークを使用します。 
[概要]以前の研究では、エンコーダー-デコーダーネットワークを使用して感情的なプロソディを解きほぐすことが可能であることが示されています。提案されたフレームワークは、トレーニング中に感情的なスタイルを転送するために事前にトレーニングされた音声感情認識モデルを利用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Non-Autoregressive Transformer ASR with CTC-Enhanced Decoder Input -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.AS/paper_14.html">
      <font color="black">Non-Autoregressive Transformer ASR with CTC-Enhanced Decoder Input</font>
    </a>
  </h2>
  <font color="black">この問題に対処するために、CTCモジュールの予測を精緻化することによってターゲットシーケンスを生成するCTC拡張NARトランスフォーマーを提案します。実験結果は、私たちの方法が以前のすべてのNARの対応物よりも優れており、強力なARベースラインよりも50倍速いデコード速度を達成することを示しています。 Aishell-1およびAishell-2データセットでの絶対CER劣化はわずか0.0〜0.3です。非自動回帰（NAR）トランスフォーマーモデルは、大幅な推論速度の向上を達成しましたが、自動音声認識の自動回帰（AR）モデルと比較して精度が劣ります（ ASR）。 
[ABSTRACT] ctの方法は、以前のすべてのnarモデルよりも優れており、ターゲット側のデコード速度が0. 0. 0.0の50倍高速になっています。 0.3aishell-1およびaishell-2データセットでの絶対cer劣化</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Window Data Augmentation Approach for Speech Emotion Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.AS/paper_15.html">
      <font color="black">Multi-Window Data Augmentation Approach for Speech Emotion Recognition</font>
    </a>
  </h2>
  <font color="black">IEMOCAPコーパスでのMWA-SERアプローチのパフォーマンスを評価し、提案された方法が最先端の結果を達成することを示します。提案された拡張方法を深層学習モデルと組み合わせることで、音声感情が改善されることを示します。認識性能..さらに、提案されたシステムは、SAVEEおよびRAVDESSデータセットの感情を認識しながら、それぞれ70％および88％の精度を示しました。 
[概要]提案された拡張方法を深層学習モデルと組み合わせることで、音声感情認識パフォーマンスが向上することを示します。提案されたシステムは、saveeおよびravdessデータセットの感情を認識しながら、70％および88％の精度を示しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-19">
        <br><font color="black">2020-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Adversarial Networks in Human Emotion Synthesis:A Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.AS/paper_16.html">
      <font color="black">Generative Adversarial Networks in Human Emotion Synthesis:A Review</font>
    </a>
  </h2>
  <font color="black">このようなモデルのアプリケーションには、感情の認識と分類、ユニモーダル感情合成、クロスモーダル感情合成が含まれますが、これらに限定されません。その結果、利用可能なデータベース、利点、およびを研究することにより、人間の感情合成における最近の進歩のレビューを行いました。生成モデルの欠点と、2つの主要な人間のコミュニケーションモダリティ、つまりオーディオとビデオを考慮した関連するトレーニング戦略。現実的なデータサンプルを合成することは、学術界と産業界の両方にとって大きな価値があります。 
[要約]人間の感情合成の研究は、生殖器モデルがどれほど深く出現しているかを示しています。これらのモデルが新たなトピックになったのはこれが初めてです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: CASS-NAT: CTC Alignment-based Single Step Non-autoregressive Transformer
  for Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.AS/paper_17.html">
      <font color="black">CASS-NAT: CTC Alignment-based Single Step Non-autoregressive Transformer
  for Speech Recognition</font>
    </a>
  </h2>
  <font color="black">この情報は、トークンレベルの音響埋め込みと呼ばれる、各トークンの音響表現を並列に抽出するために使用されます。これは、自己回帰トランスフォーマー（AT）に埋め込みという単語を置き換えて、デコーダーで並列生成を実現します。実験結果は、提案された方法がWERを実現することを示しています。外部LMのないLibrispeechテストクリーン/その他のデータセットで3.8％/ 9.1％、Aishell1北京語コーパスでそれぞれ5.8％のCER1 ..推論中に、エラーベースのアライメントサンプリング方法をCTCに適用することが提案されています。出力スペース、WERを削減し、並列処理も維持します。 
[概要] ctcアライメントには、デコーダー入力用のトークンの数の情報が含まれます。これには、各トークンの音響の期間が含まれます。提案された方法は、ctcの音声空間に適用されることが提案されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Replay and Synthetic Speech Detection with Res2net Architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.AS/paper_18.html">
      <font color="black">Replay and Synthetic Speech Detection with Res2net Architecture</font>
    </a>
  </h2>
  <font color="black">また、ResNetベースのモデルと比較してモデルサイズが小さくなります。この複数のスケーリングメカニズムにより、目に見えないなりすまし攻撃に対する対策の一般化が大幅に向上します。Res2Netは、主にResNetブロックを変更して複数の機能スケールを有効にします。 
[ABSTRACT]新しいモデル構造、いわゆるres2netは、なりすまし対策の一般化可能性を向上させることを目的としています。具体的には、1つのブロック内の機能マップを複数のチャネルグループに分割し、異なるチャネルグループ間の接続のように残余を設計します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: An Improved Event-Independent Network for Polyphonic Sound Event
  Localization and Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-29/eess.AS/paper_19.html">
      <font color="black">An Improved Event-Independent Network for Polyphonic Sound Event
  Localization and Detection</font>
    </a>
  </h2>
  <font color="black">第二に、以前の発見は、ハードパラメータ共有を使用することにより、SELDはサブタスクを個別に学習する場合と比較してパフォーマンスが低下するということです。これはソフトパラメータ共有スキームによって解決されます。ソースコードが利用可能です。 
[概要]このペーパーでは、2つの未解決の問題が取り上げられています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-25">
        <br><font color="black">2020-10-25</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
