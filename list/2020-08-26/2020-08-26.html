<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-08-26の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: ICE-Talk: an Interface for a Controllable Expressive Talking Machine -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.SD/paper_0.html">
      <font color="black">ICE-Talk: an Interface for a Controllable Expressive Talking Machine</font>
    </a>
  </h2>
  <font color="black">これは、制御可能なTTSの潜在スペースの調査を可能にします。さらに、ヒューマンエージェントの相互作用の一部として使用できるモジュールとして実装されます。ICE-Talkは、オープンソースのWebベースのGUIで、テキストフィールドとクリック可能な2Dプロットを介して制御可能なパラメーターを備えたTTSシステム。 
[ABSTRACT]これは、制御可能なコントロールの潜在スペースの研究を可能にします。これは、テキストコントローラーに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Few Shot Text-Independent speaker verification using 3D-CNN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.SD/paper_1.html">
      <font color="black">Few Shot Text-Independent speaker verification using 3D-CNN</font>
    </a>
  </h2>
  <font color="black">ただし、テキストに依存しない音声データは、話者検証などのタスクで常に利用できるとは限らず、また、トレーニングデータが非常に少ないと仮定して、テキストに依存しない話者検証の作業はこれまで行われていません。これを実現するために、シャムニューラルネットワークを使用しています。 VoxCeleb1データセットに対して行われた実験では、データが非常に少ないトレーニングでも、提案されたモデルの精度は、テキストに依存しない話者の検証に関する最新のモデルに近いことが示されています。既存の認識システムの代替として使用できるバイオメトリクス.voxceleb1データセットに対して行われた実験は、非常に少ないデータのトレーニングでも、提案されたモデルの精度がテキストの最新モデルに近いことを示しています-独立した話者検証</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Aphasic Speech Recognition using a Mixture of Speech Intelligibility
  Experts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.SD/paper_2.html">
      <font color="black">Aphasic Speech Recognition using a Mixture of Speech Intelligibility
  Experts</font>
    </a>
  </h2>
  <font color="black">テスト時に、各専門家の貢献度は、音声了解度検出器（SID）を使用して音声了解度を推定することで決定されます。提案されたアプローチは、重要度情報をモデリングプロセスに組み込まないでください。ロバストな音声認識は、自動失語音声分析での意味的特徴抽出の重要な前提条件です。 
[ABSTRACT]自動音声認識モデルは、失語症の音声に適用するとパフォーマンスが低下します。これは、エキスパート（moe）の混合によるものです。エキスパート（moe）は、深刻度を明示的に定義することにより、音声に存在するさまざまな了解度を処理します。アプローチは、モデリングプロセスに重大度情報を組み込んでいないベースラインアプローチと比較して、失語症のスピーチのすべての重大度段階にわたる電話エラー率を大幅に低減します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Medley2K: A Dataset of Medley Transitions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.SD/paper_3.html">
      <font color="black">Medley2K: A Dataset of Medley Transitions</font>
    </a>
  </h2>
  <font color="black">メドレーの自動生成、つまりスムーズなトランジションを介して連結されたさまざまな曲によって形成された楽曲は、現在の文献では十分に研究されていません。このデータセットの詳細な説明を提供し、最先端のトレーニングによって検証します曲間のトランジションを生成するタスクにおける生成モデル。私たちのデータセットは、さまざまな音楽ジャンルにわたる曲のトランジションを豊富に備えています。 
[要旨] medley2kと呼ばれる2,00のメドレーと7、712のラベルが付けられたtransition.datasetで構成されるデータセットを利用可能にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Tandem Assessment of Spoofing Countermeasures and Automatic Speaker
  Verification: Fundamentals -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.SD/paper_4.html">
      <font color="black">Tandem Assessment of Spoofing Countermeasures and Automatic Speaker
  Verification: Fundamentals</font>
    </a>
  </h2>
  <font color="black">拡張機能には、パラメーターが少ないt-DCFの簡略化バージョン、固定ASVシステムの特殊なケースの分析、その解釈に独自の洞察を与えるシミュレーション、ASVspoof 2019データベースを使用した新しい分析などが含まれます。スプーフィング対策（CM）を開発して、自動スピーカー検証（ASV）システムが操作または人工入力によって欺かれることから保護します。プリミティブEERは、ASVへのアプリケーション要件とスプーフィングとCMの影響、およびプライマリメトリックとしてのその使用を反映できません。従来のASV研究では、評価にリスクベースのアプローチを採用することで長い間見捨てられてきました。 
[要約] cmsのスプーフィングの信頼性は、通常、等しいエラー率（eer）メトリックを使用して測定されます。プリミティブな影響率は、システムの開発に対するリスクの主要なポイントです。t-dcfの採用が促進されることが望まれますなりすまし防止とasv研究コミュニティ間のより緊密な協力</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-12">
        <br><font color="black">2020-07-12</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Deep Learning based Dimple Detection for Quantitative Fractography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.IV/paper_0.html">
      <font color="black">Deep Learning based Dimple Detection for Quantitative Fractography</font>
    </a>
  </h2>
  <font color="black">破壊の原因を特定することは、材料特性、機械的特性の予測、および新しい破壊耐性材料の開発に役立ちます。この作業では、特に機械学習法を使用して、チタン合金のディンプル検出とセグメンテーションの難しい問題に取り組みます。ニューラルネットワーク。この方法は、破面のトポグラフィーと材料の機械的特性を関連付けるのにも役立ちます。 
[ABSTRACT]金属の破損の原因を特定するために、フラクトグラフのディンプルのセグメンテーションの問題に対処します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-05">
        <br><font color="black">2020-07-05</font>
      </time>
    </span>
</section>
<!-- paper0: On Data Augmentation for GAN Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.IV/paper_1.html">
      <font color="black">On Data Augmentation for GAN Training</font>
    </a>
  </h2>
  <font color="black">次に、GANトレーニングで拡張データを使用して元の分布の学習を改善できるようにする、GANに最適化されたデータ拡張（DAG）と呼ばれる原理的なフレームワークを提案します。元の分布は、拡張データを利用して学習を改善します。弁別子と生成器の比較。提案されたDAGを使用してJS発散wrt 
[ABSTRACT] dagを最小化する際に元のGANに合わせると、生成器が拡張データの分布を学習するように誤解される可能性があることを示す理論分析を提供します。元のデータの</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-09">
        <br><font color="black">2020-06-09</font>
      </time>
    </span>
</section>
<!-- paper0: GAN Slimming: All-in-One GAN Compression by A Unified Optimization
  Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.IV/paper_2.html">
      <font color="black">GAN Slimming: All-in-One GAN Compression by A Unified Optimization
  Framework</font>
    </a>
  </h2>
  <font color="black">トレーニングGANの悪名高い不安定性のため、異なる圧縮手法をヒューリスティックに積み重ねると、満足のいく結果が得られないことがわかります。GSは、3つの主流圧縮手法をシームレスに統合します。エンドツーエンドで効率的に最適化できる最適化フォーム。コードと事前トレーニング済みモデルは、https：//github.com/TAMU-VITA/GAN-Slimmingにあります。 
[ABSTRACT]最先端のガンは、リソースが非常に複雑になる問題があります。ガンの圧縮は、ガンのスリム化（gs）と呼ばれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Blind-Spot Neural Network Architecture for Image Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.IV/paper_3.html">
      <font color="black">Efficient Blind-Spot Neural Network Architecture for Image Denoising</font>
    </a>
  </h2>
  <font color="black">私たちのネットワークは、以前の作業よりもパフォーマンスを向上させ、確立されたデータセットで最先端の結果を実現します。現在、ブラインドスポットは主にシフトされた畳み込みまたはシリアル化を使用して実現されています。これらのネットワークにより、ノイズの多い画像を直接トレーニングできます。彼らは設計上、簡単な解決策を避けているからです。 
[要約]ノイズ除去技術には、クリーンでノイズの多い画像のペアが必要です。これらのネットワークでは、ノイズの多い画像を直接トレーニングできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Localizing the Common Action Among a Few Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.IV/paper_4.html">
      <font color="black">Localizing the Common Action Among a Few Videos</font>
    </a>
  </h2>
  <font color="black">ネットワークには以下が含まれます：（\ textit {i}）いくつかのトリミングされたサポートビデオとトリミングされていないクエリビデオの表現を同時に補完する相互強化モジュール。 （\ textit {ii}）サポートビデオをクエリブランチに繰り返し融合するプログレッシブアラインメントモジュール。 （\ textit {iii}）ペアワイズマッチングモジュールで、さまざまなサポートビデオの重要性を比較検討します。このホワイトペーパーでは、長いトリミングされていないビデオでのアクションの時間的な範囲を特定することを目指しています..長いアクションの開始と終了トリミングされていない動画は、共通のクラスラベルを知らずに、同じアクションを含むトリミングされた動画の例を数に基づいて決定されます。 
[ABSTRACT]新しい3Dたたみ込みネットワークアーキテクチャは、サポート動画の表現を検索動画セグメントに合わせるように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-13">
        <br><font color="black">2020-08-13</font>
      </time>
    </span>
</section>
<!-- paper0: Spatiotemporal Action Recognition in Restaurant Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.IV/paper_5.html">
      <font color="black">Spatiotemporal Action Recognition in Restaurant Videos</font>
    </a>
  </h2>
  <font color="black">2番目の方法では、YOWOの3次元畳み込みが独自のデータセットの時空間的特徴をキャプチャする能力を調査します。最初に、畳み込みLSTMを使用してYOLOの新しい反復的な変更を設計および実装し、そのようなネットワークのトレーニングでさまざまな微妙な点を調査します。2つのアプローチを検討します。 
[ABSTRACT]プロジェクトは、食品を準備しているレストランの労働者のビデオ映像に基づいています。これらのビデオは、チェックアウトや在庫など、人々の行動を示すために使用されます。これらは、人々が発展するのを助ける新しいシステムを開発するための小さなステップを含みます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Measure Anatomical Thickness from Cardiac MRI with Deep Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.IV/paper_6.html">
      <font color="black">Measure Anatomical Thickness from Cardiac MRI with Deep Neural Networks</font>
    </a>
  </h2>
  <font color="black">厚さの推定は、反復ソルバーや手動補正なしで実行されます。これは、数学モデルよりも100倍高速です。数学モデルは、正確な密な厚さの推定を取得できますが、反復ソルバーにより計算オーバーヘッドが大きくなります。厚さも分析します標準的な臨床モデルを用いたさまざまな心臓病変のパターンと結果は、厚さベースの心臓病診断のための私たちの方法の潜在的な臨床的価値を示しています。 
[要約]この目的のために、密な厚さを推定するための新しい方法を提案します。これらには、バイナリ環状形状から厚さを推定する高速ソルバーが含まれます。3つの心臓データセットと1つの合成データセットで提案されたモデルをテストします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Variational Image Restoration Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.IV/paper_7.html">
      <font color="black">Variational Image Restoration Network</font>
    </a>
  </h2>
  <font color="black">さらに、目的の損失の明示的な形式を使用して、提案されたモデルに含まれるすべてのパラメーターを学習する変分推論アルゴリズムを設計します。複雑な実際のノイズに適合するために、より柔軟性のあるガウス分布がこの方法で採用されています。これらの問題に対処するには、画像の復元のための統合生成モデルを提案します。これは、潜在的なクリーンな画像から観察された破損した画像への劣化プロセスを精巧に構成します。 
[ABSTRACT]ディープラーニング（dl）ベースの方法は、一般化を改善するために使用されます。これらの単純な結果は、1つの想定される劣化プロセスに基づいています。これらには、一般的な画像劣化プロセスに基づいて構築されたプロセスが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: DefSLAM: Tracking and Mapping of Deforming Scenes from Monocular
  Sequences -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.IV/paper_8.html">
      <font color="black">DefSLAM: Tracking and Mapping of Deforming Scenes from Monocular
  Sequences</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、Shape-from-Template（SfT）とNon-Rigid Structure-from-Motion（NRSfM）のテクニックを組み合わせて、SLAMの典型的な探索シーケンスを処理します。変形マッピングスレッドは、トラッキングと並行して実行され、テンプレートを更新します。キーフレームレートで、等角投影NRSfMが完全な遠近キーフレームのバッチを処理することによって。実験では、DefSLAMは、実験室制御実験と医療内視鏡シーケンスの両方で変形シーンのクローズアップシーケンスを処理し、正確な3Dモデルを生成します。移動するカメラに対するシーン。 
[ABSTRACT] defslamは、シーンの変形でリアルタイムに操作できる最初の単眼スラムです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-20">
        <br><font color="black">2019-08-20</font>
      </time>
    </span>
</section>
<!-- paper0: DELTAS: Depth Estimation by Learning Triangulation And densification of
  Sparse points -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.IV/paper_9.html">
      <font color="black">DELTAS: Depth Estimation by Learning Triangulation And densification of
  Sparse points</font>
    </a>
  </h2>
  <font color="black">エンドツーエンドネットワークは、ディープラーニングフレームワーク内で3つのステップすべてを効率的に実行し、中間の2D画像と3Dの幾何学的監視、さらに深度の監視でトレーニングします。重要なのは、最初のステップで、関心点検出と記述子学習を使用してポーズ推定を補完することです。マルチビューステレオ（MVS）は、アクティブな深度センシングの精度と単眼深度推定の実用性との間の黄金の平均です。 
[ABSTRACT] 3D畳み込みニューラルネットワーク（cnns）を使用したコストボリュームベースのアプローチにより、mvsシステムの精度が向上しました。この方法では、特徴点の記述子を検出および評価します。次に、（b）少数の特徴点のセットをマッチングおよび三角形分割する学習cnnsの使用</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-19">
        <br><font color="black">2020-03-19</font>
      </time>
    </span>
</section>
<!-- paper0: Image Colorization: A Survey and Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.IV/paper_10.html">
      <font color="black">Image Colorization: A Survey and Dataset</font>
    </a>
  </h2>
  <font color="black">最近、特に画像の色付けのための深層学習技術が進歩しました。画像の色付けは、画像とビデオを色付けするための必須の画像処理およびコンピュータービジョンブランチです。評価用のデータセットとコードは、https：//github.com/saeed-で公開されます。 anwar / ColorSurvey 
[ABSTRACT]今週、画像のカラー化のためにディープラーニングテクニックが特に進歩しました。adamsobel：コミュニティはこの問題にさらに取り組む必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: A Critical Analysis of Patch Similarity Based Image Denoising Algorithms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.IV/paper_11.html">
      <font color="black">A Critical Analysis of Patch Similarity Based Image Denoising Algorithms</font>
    </a>
  </h2>
  <font color="black">厳密な実験を通じて、このペーパーでは、非局所的な類似性に基づく画像ノイズ除去アルゴリズム開発の複数の側面をレビューします。最後に、画像ノイズ除去を取り巻くほとんどの作業は、ノイズ除去された間のピーク信号対ノイズ比（PSNR）に基づいてパフォーマンス結果を提示します。画像と参照画像（加法性ホワイトガウスノイズで摂動されます）。次に、開発された画像ノイズ除去アルゴリズムは、複数のビルディングブロックの組み合わせであり、それらを比較するのは面倒な作業です。 
[ABSTRACT]写真のノイズ除去に関するアルゴリズムのほとんどは、ラルフローレンに焦点を合わせています。これらは、画像を不釣り合いに改造するツールを含みます。代わりに、参照なしの局所類似性測定値と未処理の画像を組み込む方法論の見直しを主張しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Masked Face Recognition for Secure Authentication -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.IV/paper_12.html">
      <font color="black">Masked Face Recognition for Secure Authentication</font>
    </a>
  </h2>
  <font color="black">これらのフェイスマスクの使用は、学校/オフィスの出席の追跡と電話のロック解除に使用される顔認識システムの正確性に深刻な疑問を投げかけています。最近の世界的なCOVID-19パンデミックでは、フェイスマスクの使用が重要になっています残念ながら、マスクされた顔は検出や認識が困難になり、社内のデータセットが無効になり、そのような顔認識システムが機能しなくなる恐れがあります。 
[ABSTRACT]人々は感染を避けるために公共エリアで自分の顔を覆うことをお勧めします。これらの人々は偽陽性-正の率と高い全体的な精度で自分自身を識別することができました。これらのツールは、ターゲットの精度で効果的な顔認識システムのトレーニングに使用されますマスクされた顔用</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Think about boundary: Fusing multi-level boundary information for
  landmark heatmap regression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_0.html">
      <font color="black">Think about boundary: Fusing multi-level boundary information for
  landmark heatmap regression</font>
    </a>
  </h2>
  <font color="black">挑戦的なベンチマークデータセットで実施された実験結果は、私たちのアプローチが文献の最先端の方法よりも優れていることを示しています。SCBEモジュールから継承された境界認識機能は、マルチスケールフュージョンフレームワークのBALTモジュールに統合され、境界からランドマークヒートマップへの変換をモデル化します。SCBEモジュールでは、幹層を変更し、中間監視を使用して高品質の顔面境界ヒートマップを生成します。 
[ABSTRACT]顔の境界のマッピングは、これらのシーンで予約および推定される可能性が高くなります。ただし、ヒートマップモジュールは他の形式のマッピングよりも重要です。これは、顔の表面の理解が不足しているためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: MCU-Net: A framework towards uncertainty representations for decision
  support system patient referrals in healthcare contexts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_1.html">
      <font color="black">MCU-Net: A framework towards uncertainty representations for decision
  support system patient referrals in healthcare contexts</font>
    </a>
  </h2>
  <font color="black">MCU-Netが認識の不確実性とこのアプリケーションに合わせて調整された不確実性のしきい値を組み合わせると、個々の患者レベルで自動化されたパフォーマンスが最大化されるが、本当に不確実なケースが参照されることを示します。したがって、以下を使用して、医療画像のセグメンテーションについて評価された不確実性表現のフレームワークを提示します。 U-Netとモンテカルロドロップアウトを組み合わせたMCU-Netは、4つの異なる不確実性メトリックで評価されます。自動意思決定サポートを導入する際にヒューマンインザループシステムを組み込むことは、ヘルスケアコンテキストで信頼を作成し、提供するために重要です。患者ごとの信頼できるパフォーマンス。 
[要約]ディープラーニングフレームワークは、不確実性の表現がないため、この患者ベースのアプローチを許可しません。これは、不確実なケースを医療専門家に自動紹介するためのステップです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning based Dimple Detection for Quantitative Fractography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_2.html">
      <font color="black">Deep Learning based Dimple Detection for Quantitative Fractography</font>
    </a>
  </h2>
  <font color="black">破壊の原因を特定することは、材料特性、機械的特性の予測、および新しい耐破壊性材料の開発に役立ちます。金属の破壊の原因を特定するには、フラクトグラフのディンプルのセグメンテーションの問題に対処します。私たちの知る限りでは、これは、ディンプルフラクトグラフィの教師あり学習のための自己注意を伴う完全畳み込みニューラルネットワークを使用したフラクトグラフィの最初の作品ですが、脆弱な特性も考慮して簡単に拡張できます。 
[ABSTRACT]金属の破損の原因を特定するために、フラクトグラフのディンプルのセグメンテーションの問題に対処します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-05">
        <br><font color="black">2020-07-05</font>
      </time>
    </span>
</section>
<!-- paper0: On Data Augmentation for GAN Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_3.html">
      <font color="black">On Data Augmentation for GAN Training</font>
    </a>
  </h2>
  <font color="black">さらに、DAGが一部のGANモデルで使用されている場合、システムは最新のFr \ &#39;echet Inception Distance（FID）スコアを確立します。元の分布と拡張データを利用して、弁別器と生成器の学習を改善します..理論的な分析を提供して、提案されたDAGを使用して、JS発散wrt 
[ABSTRACT] dagを最小化する際に元のGANに合わせると、ジェネレーターが拡張データの分布を学習するように誤解する可能性があることを示します。データ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-09">
        <br><font color="black">2020-06-09</font>
      </time>
    </span>
</section>
<!-- paper0: Bias-Awareness for Zero-Shot Learning the Seen and Unseen -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_4.html">
      <font color="black">Bias-Awareness for Zero-Shot Learning the Seen and Unseen</font>
    </a>
  </h2>
  <font color="black">トレーニング中、モデルは、温度スケーリングを使用して埋め込み空間で実数値クラスのプロトタイプに回帰することを学習し、マージンベースの双方向エントロピー項は、見られる確率と目に見えない確率を正則化します。 ..モデルは、見えているクラスと見えていないクラスの両方の異なるタイプのセマンティック情報を操作できるため、実数値のセマンティック埋め込みスペースに依存することで、用途が広がります。 
[ABSTRACT]標準の検索を使用して、モデルは、見えているクラスと見えていないクラスの両方のさまざまなタイプのセマンティック情報を操作できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Domain Few-Shot Learning with Meta Fine-Tuning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_5.html">
      <font color="black">Cross-Domain Few-Shot Learning with Meta Fine-Tuning</font>
    </a>
  </h2>
  <font color="black">これは、miniImagenetのみでトレーニングされた既存のベンチマークより6.51％改善されています。これを行うには、エピソードトレーニングプロセスを変更して、一次MAMLベースのメタ学習アルゴリズムを含め、グラフニューラルネットワークモデルを後続のメタ学習モジュール。提案された方法は、特にデータ拡張と組み合わせると、精度を大幅に向上させるのに役立ちます。 
[ABSTRACT]この目的のために、シンプルなアンサンブルで新規メソッドとベースラインメソッドを組み合わせ、ベンチマークで平均精度73. 78％を達成しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br><font color="black">2020-05-21</font>
      </time>
    </span>
</section>
<!-- paper0: GAN Slimming: All-in-One GAN Compression by A Unified Optimization
  Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_6.html">
      <font color="black">GAN Slimming: All-in-One GAN Compression by A Unified Optimization
  Framework</font>
    </a>
  </h2>
  <font color="black">ジェネレーティブアドバタリアルネットワーク（GAN）は、さまざまなコンピュータービジョンアプリケーションで人気が高まっており、最近リソースに制約のあるモバイルデバイスへの展開が始まっています。具体的には、GSを適用して最先端のスタイルの転送ネットワークであるCartoonGANを圧縮します、最大47回、視覚品質の低下を最小限に抑えます。コードと事前トレーニング済みモデルは、https：//github.com/TAMU-VITA/GAN-Slimmingにあります。 
[ABSTRACT]最先端のガンは、リソースが非常に複雑になる問題があります。ガンの圧縮は、ガンのスリム化（gs）と呼ばれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Towards End-to-end Car License Plate Location and Recognition in
  Unconstrained Scenarios -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_7.html">
      <font color="black">Towards End-to-end Car License Plate Location and Recognition in
  Unconstrained Scenarios</font>
    </a>
  </h2>
  <font color="black">最後に、認識タスクは、Connectionist Temporal Classification（CTC）によって直接解決されるシーケンスのラベル付け問題として扱われます。多数の実験により、提案された方法は、速度と速度の両方において以前の最先端の方法を大幅に上回っています。精度..これは、軽量で統一されたディープニューラルネットワークであり、エンドツーエンドで最適化してリアルタイムで機能します。 
[ABSTRACT]軽量で統一されたdeepconシナリオです。エンドツーエンドで最適化でき、リアルタイムで機能します。新しい畳み込みニューラルネットワークブランチは、プレートなしでキャラクターの機能をさらに抽出するように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Graphical Object Detection in Document Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_8.html">
      <font color="black">Graphical Object Detection in Document Images</font>
    </a>
  </h2>
  <font color="black">GODは、伝達学習とドメイン適応の概念を調査して、ドキュメント画像のグラフィカルオブジェクト検出タスクのラベル付きトレーニング画像の希少性を処理します。グラフィカルオブジェクト検出（GOD）と呼ばれるドキュメントイメージ内のオブジェクト。グラフィカル要素：特に表と図には、ドキュメントに含まれる最も価値のある情報の視覚的な要約が含まれています。 
[要旨]これは、ドキュメント画像のローカライズの内容を理解するための最初のステップです。これは、データに基づいており、ヒューリスティックスやメタデータを必要とせず、ドキュメント画像内のグラフィックオブジェクトを特定するためのデータです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Learn in a Semi-Supervised Fashion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_9.html">
      <font color="black">Learning to Learn in a Semi-Supervised Fashion</font>
    </a>
  </h2>
  <font color="black">したがって、私たちの戦略は、自己監視学習スキームと見なすことができます。これは、完全に監視された学習タスクに適用してパフォーマンスを向上させることができます。さまざまなタスクと設定に対する実験により、提案されたアプローチの有効性と状態に対するその優位性が確認されますほとんどのメタ学習アルゴリズムが行うように、関連するクラスごとの類似性スコアを適合させる代わりに、ラベル付きデータからセマンティクス指向の類似性表現を導出し、そのような表現をラベルなしデータに転送することを提案します。 
[ABSTRACT]研究者は、ラベル付きデータとラベルなしデータから学習できると言います。関連するクラスごとの類似性スコアを適合させる代わりに、そのような表現をラベルなしデータに転送することを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Omni-sourced Webly-supervised Learning for Video Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_10.html">
      <font color="black">Omni-sourced Webly-supervised Learning for Video Recognition</font>
    </a>
  </h2>
  <font color="black">データバランシング、リサンプリング、クロスデータセットミックスアップなど、いくつかの優れた手法が共同トレーニングで採用されています。Webデータを活用してビデオ認識モデルをトレーニングするための新しいフレームワークであるOmniSourceを紹介します。最初に、タスク固有のデータ収集と教師モデルによって自動的にフィルタリングされたものは、統一された形式に変換されます。 
[ABSTRACT]共同-Webly-統一学習における複数のデータソースとフォーマット間のギャップに対処するためのトレーニング戦略が提案されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-29">
        <br><font color="black">2020-03-29</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Blind-Spot Neural Network Architecture for Image Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_11.html">
      <font color="black">Efficient Blind-Spot Neural Network Architecture for Image Denoising</font>
    </a>
  </h2>
  <font color="black">私たちのネットワークは、以前の作業よりもパフォーマンスを向上させ、確立されたデータセットで最先端の結果を達成します。現在、盲点は主にシフト畳み込みまたはシリアル化を使用して達成されています。クリーンなサンプルを所有していない場合、は、隣接するピクセルのみに基づいてピクセル値を推定するブラインドスポットニューラルネットワークアーキテクチャを使用できます。 
[要約]ノイズ除去技術には、クリーンでノイズの多い画像のペアが必要です。これらのネットワークでは、ノイズの多い画像を直接トレーニングできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot
  Cross-dataset Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_12.html">
      <font color="black">Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot
  Cross-dataset Transfer</font>
    </a>
  </h2>
  <font color="black">これらのツールを使用して、新しい大規模なデータソースである3Dフィルムを含む5つの多様なトレーニングデータセットを実験します。私たちのアプローチは、多様なデータセット全体で競合する方法よりも明らかに優れており、単眼深度推定の最先端技術を設定しています。ゼロショットクロスデータセット転送を使用するアプローチの一般化力}、つまり
[ABSTRACT]明確な特性とバイアスを持つ多数のデータセットが出現しました。これらには、さまざまなソースからのデータを結合するための原理的な多目的学習のテストと使用が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-02">
        <br><font color="black">2019-07-02</font>
      </time>
    </span>
</section>
<!-- paper0: Localizing the Common Action Among a Few Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_13.html">
      <font color="black">Localizing the Common Action Among a Few Videos</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、トリミングされていない長い動画でのアクションの時間的な範囲を特定することを目指しています。このタスクに対処するために、サポート動画の表現を関連するクエリ動画セグメントに合わせることができる新しい3D畳み込みネットワークアーキテクチャを紹介します。トリミングされていない長いビデオのアクションの終了は、共通のクラスラベルを知らなくても、同じアクションを含むトリミングされたビデオのサンプルのほんの一部に基づいて決定されます。 
[ABSTRACT]新しい3Dたたみ込みネットワークアーキテクチャは、サポート動画の表現を検索動画セグメントに合わせるように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-13">
        <br><font color="black">2020-08-13</font>
      </time>
    </span>
</section>
<!-- paper0: Adaptive Context-Aware Multi-Modal Network for Depth Completion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_14.html">
      <font color="black">Adaptive Context-Aware Multi-Modal Network for Depth Completion</font>
    </a>
  </h2>
  <font color="black">さらに、入力データのマルチモダリティを考慮して、2つのモダリティのグラフ伝播を利用してマルチモーダル表現を抽出します。具体的には、最初に、観測されたピクセルから異なるスケールで複数のグラフを作成します。}、KITTI、NYU- v2、同時に最新のモデルよりもパラメーターが少ない。 
[ABSTRACT]観測されたピクセルは、観測されていないモーダルの回復のための重要なガイダンスを提供します。データの完成により、観測された空間環境をキャプチャするためにグラフ通信を採用することを提案します。ネットワークは、伝播に注意メカニズムを適用します、ネットワークがコンテキスト情報を適応的にモデル化することを奨励します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Spatiotemporal Action Recognition in Restaurant Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_15.html">
      <font color="black">Spatiotemporal Action Recognition in Restaurant Videos</font>
    </a>
  </h2>
  <font color="black">時空間アクション認識は、ビデオ内のアクションを見つけて分類するタスクです。最初に、畳み込みLSTMを使用してYOLOの新しい反復的な修正を設計および実装し、そのようなネットワークのトレーニングにおけるさまざまな微妙な点を探ります。最初のアプローチおなじみのオブジェクト検出器「You Only Look Once」と、最近提案されたアクション認識の類似物である「You Only Watch Once」を使用するものがあります。 
[ABSTRACT]プロジェクトは、食品を準備しているレストランの労働者のビデオ映像に基づいています。これらのビデオは、チェックアウトや在庫など、人々の行動を示すために使用されます。これらは、人々が発展するのを助ける新しいシステムを開発するための小さなステップを含みます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Realistic Video Summarization through VISIOCITY: A New Benchmark and
  Evaluation Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_16.html">
      <font color="black">Realistic Video Summarization through VISIOCITY: A New Benchmark and
  Evaluation Framework</font>
    </a>
  </h2>
  <font color="black">VISIOCITYに存在する間接的なグラウンドトゥルースから複数のリファレンスサマリーを自動的に生成するパレート最適性に基づく新しいレシピを紹介します。次に、長いビデオの場合、人間のリファレンスサマリーを取得することは困難です。これらのサマリーが人間のサマリーと同等であることを示します。 。 
[ABSTRACT] visiocityは、6つの異なるカテゴリにまたがる長い動画で構成される新しいベンチマークデータセットです。これには、さまざまなフレーバーの動画要約をサポートできる高密度のコンセプトアノテーションが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: In-Home Daily-Life Captioning Using Radio Signals -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_17.html">
      <font color="black">In-Home Daily-Life Captioning Using Radio Signals</font>
    </a>
  </h2>
  <font color="black">RF-Diaryは、壁やオクルージョンを通して、暗い場所で人々の生活をさらに観察し、キャプションを付けることができます。詳細については、プロジェクトのWebページ（http://rf-diary.csail.mit.edu）にアクセスしてください。また、既存のビデオベースのキャプションデータセットを活用して、ラジオベースのキャプションモデルのパフォーマンスを向上させるマルチモーダル機能調整トレーニングスキームを使用しています。 
[ABSTRACT] rf-日記は、壁やオクルージョンを通して、暗い設定で人々の生活をさらに観察し、キャプションを付けることができます。また、ラジオベースのキャプションモデルのパフォーマンスを向上させるために、マルチモーダル機能の位置合わせトレーニングスキームを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Model Generalization in Deep Learning Applications for Land Cover
  Mapping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_18.html">
      <font color="black">Model Generalization in Deep Learning Applications for Land Cover
  Mapping</font>
    </a>
  </h2>
  <font color="black">これは、モデルが1つの大陸または季節の土地利用クラスを正確に予測するからといって、モデルが別の大陸または季節の土地利用クラスを正確に予測することを意味するわけではないことを示唆しています。次に、異なる大陸の衛星画像にクラスタリング手法を使用します。地理空間の一般化を特に困難にする風景の違いを視覚化し、将来の衛星画像関連のアプリケーションのために私たちの要点をまとめます。これらのディープラーニングモデルが特定の大陸/季節からのデータでトレーニングされると、高度なサンプル外の大陸/季節のモデルパフォーマンスの変動性。 
[ABSTRACT]ディープラーニングモデルは、特定の大陸からのデータに基づいてトレーニングされます。サンプルの大陸/シーズン外では、モデルのパフォーマンスに大きな変動があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-09">
        <br><font color="black">2020-08-09</font>
      </time>
    </span>
</section>
<!-- paper0: New Directions in Distributed Deep Learning: Bringing the Network at
  Forefront of IoT Design -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_19.html">
      <font color="black">New Directions in Distributed Deep Learning: Bringing the Network at
  Forefront of IoT Design</font>
    </a>
  </h2>
  <font color="black">上記の研究の方向性には、エッジインテリジェンスを有効にして、IoTの真の可能性を十分に活用するためのネットワーク中心のアプローチが必要であると考えています。このホワイトペーパーでは、まず、エッジ：（i）ハードウェアに制約のあるIoTデバイス、（ii）IoT時代のデータセキュリティとプライバシー、および（iii）複数のIoTデバイス間で分散推論を行うためのネットワーク対応の深層学習アルゴリズムの欠如。上記の課題から自然に浮かび上がる3つの研究方向をターゲットにしたビュー：（1）ディープネットワークをトレーニングするためのフェデレーテッドラーニング、（2）データに依存しない学習アルゴリズムの導入、（3）通信を意識した分散推論
[ABSTRACT]米国はデータ、データ、およびデータの分析を開始しました。データベースのプログラムは、3つの研究方向の統一されたビューを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Two-Stream Networks for Lane-Change Prediction of Surrounding Vehicles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_20.html">
      <font color="black">Two-Stream Networks for Lane-Change Prediction of Surrounding Vehicles</font>
    </a>
  </h2>
  <font color="black">得られた結果は、これらの方法論が1〜2秒の時間範囲で周辺車両の将来の車線変更の強力な予測子として機能する可能性を示しています。周辺車両の車線変更の認識と予測に対処するには、次のように問題を提起します。ビデオカメラからの視覚的な合図を積み重ねることによる行動の認識/予測の問題。自動化されたシステムは、そのパフォーマンスの安全性と効率を高めるために、初期の段階でもこれらの状況を予測する必要があります。 
[ABSTRACT]ビデオアクション認識アプローチが分析されます。これらは、異なるサイズと異なる予測予測パターン間の異なる予測パターンに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Measure Anatomical Thickness from Cardiac MRI with Deep Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_21.html">
      <font color="black">Measure Anatomical Thickness from Cardiac MRI with Deep Neural Networks</font>
    </a>
  </h2>
  <font color="black">正確な密な厚さの推定を取得するために数学モデルを利用できますが、反復ソルバーのために計算オーバーヘッドが大きくなります。厚さの推定は、反復ソルバーや手動修正なしで実行されます。これは、数学モデルより100倍高速です。バイナリ環状形状から厚さを推定する高速ソルバーや生の心臓画像から直接厚さを推定するエンドツーエンドネットワークなど、密な厚さ推定のための新しい方法を提案します.3つの心臓データセットと1つの合成データセットで提案されたモデルをテストします、すべてで印象的な結果と一般化可能性を達成します。 
[要約]この目的のために、密な厚さを推定するための新しい方法を提案します。これらには、バイナリ環状形状から厚さを推定する高速ソルバーが含まれます。3つの心臓データセットと1つの合成データセットで提案されたモデルをテストします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Streaming Perception -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_22.html">
      <font color="black">Towards Streaming Perception</font>
    </a>
  </h2>
  <font color="black">過去の研究では、レイテンシと精度の間のアルゴリズムのトレードオフについて検討しましたが、パレート最適レイテンシ-精度曲線に沿ってさまざまな方法を比較する明確な基準はありませんでした。オブジェクト検出と都市でのインスタンスセグメンテーションの例示的なタスクに焦点を当てますビデオストリーム、および高品質で時間的に密な注釈を備えた新しいデータセットを提供します。具体化された知覚とは、自律エージェントが環境を知覚して（再）動作できるようにする自律エージェントの能力を指します。 
[ABSTRACT]エージェントの応答性は、主にその処理パイプラインのレイテンシによって決まります。ツールは、知覚スタック全体の出力を共同で評価することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br><font color="black">2020-05-21</font>
      </time>
    </span>
</section>
<!-- paper0: Label Decoupling Framework for Salient Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_23.html">
      <font color="black">Label Decoupling Framework for Salient Object Detection</font>
    </a>
  </h2>
  <font color="black">詳細マップは、従来のエッジ監視よりもはるかに多くのピクセルを必要とするため、より適切に機能します。顕著性マップとは異なり、ボディマップはエッジピクセルを破棄し、中心領域にのみ注意を払います。6つのベンチマークデータセットでの包括的な実験は、LDFが最新の性能より優れていることを示しています-さまざまな評価指標に関するアートアプローチ。 
[ABSTRACT]たとえば、ピクセルがエッジに近いほど、予測が難しくなります。これは、エッジピクセルの分布が非常に不均衡であるためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Discriminability Distillation in Group Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_24.html">
      <font color="black">Discriminability Distillation in Group Representation Learning</font>
    </a>
  </h2>
  <font color="black">さらに、これらのタスクの最先端の結果を印象的なマージンで押し上げます。提案されたDDLは、元のトレーニング手順に影響を与えることなく、多くのグループベースの認識タスクに柔軟にプラグインできます。識別性の知識を示します軽量蒸留ネットワークで蒸留できる優れた特性を持ち、目に見えないターゲットセットで一般化できます。 
[要約]識別可能性蒸留学習（ddl）は、識別可能性蒸留器学習（dl）として分類されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Data Science for Motion and Time Analysis with Modern Motion Sensor Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_25.html">
      <font color="black">Data Science for Motion and Time Analysis with Modern Motion Sensor Data</font>
    </a>
  </h2>
  <font color="black">この論文では、人間の動きと実行率の新しい数学的表現空間を定義し、これらの新しい空間で統計ツールを開発することにより、モーションセンサーデータを使用した動きと時間分析のための新しい数学的フレームワークを開発します。は、特に製造およびサービスオペレーションの作業パフォーマンスを分析するために、オペレーションズリサーチで人気のあるリサーチトピックです。現代のモーションセンサー。 
[要約]モーションデータ分析は、時間のかかるストップウォッチングとビデオテーピングに主に基づいており、その後に最新のデータ分析が続きます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Boundary Uncertainty in a Single-Stage Temporal Action Localization
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_26.html">
      <font color="black">Boundary Uncertainty in a Single-Stage Temporal Action Localization
  Network</font>
    </a>
  </h2>
  <font color="black">両方の不確実性モデリングアプローチにより、mAP @ tIoU = 0.5で$ 1.5 \％$以上検出性能が向上すること、および提案された単純な1ステージネットワークがより複雑な1および2ステージネットワークと密接に連携することを示します。2つの不確実性を使用します。 -aware境界回帰損失：最初に、境界のグラウンドトゥルースの場所と境界の予測をモデル化するガウスの間のカルバックライブラーダイバージェンス、次に、同じガウスでの$ \ ell_1 $損失の予測。提案されたアーキテクチャでは、不確実性をモデル化するために、境界予測を一変量ガウス分布としてモデル化します。これは、この分野で私たちの知る限りでは初めてです。 
[ABSTRACT]提案されたアーキテクチャでは、一変量ガウス分布として境界予測をモデル化します。提案されたネットワークは、より複雑な1および2ステージネットワークと密接に連携します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Protect, Show, Attend and Tell: Image Captioning Model with Ownership
  Protection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_27.html">
      <font color="black">Protect, Show, Attend and Tell: Image Captioning Model with Ownership
  Protection</font>
    </a>
  </h2>
  <font color="black">また、広範な実験により、提案された方法がFlickr30kおよびMS-COCOデータセットのすべての一般的なキャプションメトリックの元の画像キャプションパフォーマンスを損なうことはなく、同時に除去攻撃とあいまいな攻撃の両方に耐えることができることが示されています。現在のデジタル透かしフレームワークは、フロンティアAIの1つと見なされることが多い画像キャプションタスクを保護するには不十分です。理論的および経験的の両方の点から、偽造されたキーが使用できない画像キャプションモデルを生成し、侵害の目的を無効にすることを証明します。 
[要約]このペーパーでは、現在のデジタル透かしフレームワークでは画像キャプションタスクを保護するのに不十分であることを示しています。このペーパーでは、対策として、再帰型ニューラルネットワークの非表示のメモリ状態における2つの異なる埋め込みスキームを研究および提案しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: f-BRS: Rethinking Backpropagating Refinement for Interactive
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_28.html">
      <font color="black">f-BRS: Rethinking Backpropagating Refinement for Interactive
  Segmentation</font>
    </a>
  </h2>
  <font color="black">ネットワーク入力の代わりに補助変数に関する最適化問題を解決し、ネットワークのごく一部に対してのみ順方向と逆方向のパスを実行する必要があるf-BRS（機能逆伝播改良スキーム）を提案します。GrabCut、Berkeley、 DAVISとSBDのデータセットは、オリジナルのBRSと比較して、クリックごとの時間を大幅に削減する新しい最先端の技術を設定します。 
[要旨]ネットワークは、改善点を提供するインタラクティブなバージョンのネットワークを提供します。ネットワークは、深いネットワークを介してフォワードパスとバックワードパスを実行する必要があります。同時に、brsはネットワークのアップグレードを必要とします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-28">
        <br><font color="black">2020-01-28</font>
      </time>
    </span>
</section>
<!-- paper0: GRAB: A Dataset of Whole-Body Human Grasping of Objects -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_29.html">
      <font color="black">GRAB: A Dataset of Whole-Body Human Grasping of Objects</font>
    </a>
  </h2>
  <font color="black">これにより、時間の経過に伴う詳細な3Dメッシュが得られます。そこから、物体とオブジェクト間の接触を計算します。データセットとコードは、https：//grab.is.tue.mpg.de。で研究目的に使用できます。これはユニークなデータセットですこれは、人間がオブジェクトをどのように把握して操作するか、オブジェクト全体がどのように関与するか、相互作用がタスクによってどのように変化するかをモデル化および理解するために、既存のものをはるかに超えています。 
[ABSTRACT]データセットとコードは研究目的で使用できます。これらのデータセットを使用すると、オブジェクトを把握、操作し、身体がどのように関与しているかを確認できます。データセットを使用して、「全身把握」の概念を作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: AgingMapGAN (AMGAN): High-Resolution Controllable Face Aging with
  Spatially-Aware Conditional GANs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_30.html">
      <font color="black">AgingMapGAN (AMGAN): High-Resolution Controllable Face Aging with
  Spatially-Aware Conditional GANs</font>
    </a>
  </h2>
  <font color="black">これらの制限に対処するために、民族固有の老化情報と弱い空間監視を使用して高解像度画像の外観を変更し、老化プロセスをガイドするアプローチを提示します。提案された方法の品質、制御の面での利点を示します。 、および計算のオーバーヘッドを制限しながら高解像度画像でどのように使用できるか。顔の加齢に関する既存のアプローチとデータセットは、平均に向かって歪んだ結果を生成します。顔の肥育。 
[要約]提案された方法は、高精細画像で使用できます。顔の老化方法を制御することはほとんどできません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Variational Image Restoration Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_31.html">
      <font color="black">Variational Image Restoration Network</font>
    </a>
  </h2>
  <font color="black">広範な実験により、画像のノイズ除去、画像の超解像、JPEG画像のデブロッキングなど、3つの古典的な画像復元タスクに対する提案された方法の優位性が実証されています。これらの問題に対処するために、潜在的なクリーンな画像から観察された破損した画像への劣化プロセス..より柔軟性のあるガウス分布が、複雑な実際のノイズに適合するために私たちの方法で採用されています。 
[ABSTRACT]ディープラーニング（dl）ベースの方法は、一般化を改善するために使用されます。これらの単純な結果は、1つの想定される劣化プロセスに基づいています。これらには、一般的な画像劣化プロセスに基づいて構築されたプロセスが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: How does Lipschitz Regularization Influence GAN Training? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_32.html">
      <font color="black">How does Lipschitz Regularization Influence GAN Training?</font>
    </a>
  </h2>
  <font color="black">経験的に、MNIST、CIFAR10、CelebAデータセットに対する命題を検証します。この作業では、損失関数への影響を調べることにより、リプシッツ正則化のさらに重要な効果を明らかにします。GAN損失関数を、それらの領域と達成可能な勾配値の間隔.. GANトレーニングの安定化におけるリプシッツ正規化の成功にもかかわらず、その有効性の正確な理由はよくわかっていません。 
[ABSTRACT] $ k $の直接的な影響は、$ l2 $を制限することです-ニューラルネットワークの勾配のノルムがしきい値よりも小さくなるようにします。lipschitz正則化により、すべての損失関数が同じように効果的に機能</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-11-23">
        <br><font color="black">2018-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: MonStereo: When Monocular and Stereo Meet at the Tail of 3D Human
  Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_33.html">
      <font color="black">MonStereo: When Monocular and Stereo Meet at the Tail of 3D Human
  Localization</font>
    </a>
  </h2>
  <font color="black">KITTIデータセットの3Dローカリゼーションタスクの最新の定量的結果を達成し、困難なインスタンスを説明する信頼区間を推定します。閉塞、遠く、および子供のインスタンスなどのロングテールチャレンジの定性的な例を示します..私たちの方法は、共同で（i）左右の画像に人間を関連付け、（ii）ステレオ設定での閉塞および遠方のケースを単眼キューのロバスト性に依存することで処理し、（iii）単眼透視投影の固有の曖昧性に取り組みます。人間の身長分布に関する事前知識を活用する。 
[要約]私たちの方法は共同で（i）左右の画像で人間を関連付ける、（ii）単眼の手がかりのロバスト性に依存することにより、ステレオ設定での閉塞した遠いケースを扱います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: DefSLAM: Tracking and Mapping of Deforming Scenes from Monocular
  Sequences -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_34.html">
      <font color="black">DefSLAM: Tracking and Mapping of Deforming Scenes from Monocular
  Sequences</font>
    </a>
  </h2>
  <font color="black">変形マッピングスレッドは、トラッキングと並行して実行され、等角投影NRSfMが完全な遠近キーフレームのバッチを処理することにより、キーフレームレートでテンプレートを更新します。変形トラッキングスレッドは、カメラの姿勢と観測された変形を回復します。静止時のシーンの形状をモデル化するテンプレートをSfT処理することにより、フレームレートでマップします。単眼SLAMアルゴリズムは、硬性のシーンを観察するときに堅牢に動作しますが、たとえば医療用内視鏡検査で観察されるシーンが変形すると失敗しますアプリケーション。 
[ABSTRACT] defslamは、シーンの変形でリアルタイムに操作できる最初の単眼スラムです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-20">
        <br><font color="black">2019-08-20</font>
      </time>
    </span>
</section>
<!-- paper0: Toward unsupervised, multi-object discovery in large-scale image
  collections -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_35.html">
      <font color="black">Toward unsupervised, multi-object discovery in large-scale image
  collections</font>
    </a>
  </h2>
  <font color="black">（2）提案の固有の階層構造を活用して、Voらのオブジェクト検出へのアプローチの効果的な正則化手法として活用し、そのパフォーマンスを向上させて、いくつかの標準ベンチマークで最先端の技術を大幅に改善します。画像のコレクション全体を使用してオブジェクトを発見する前に、小さなランダムな画像セットを使用して有望な提案を選択する2段階の戦略を採用しています。最初に（私たちの知る限りで）取り組むために、最大20,000の画像のデータセットを構成する各画像の複数のオブジェクトの発見、既存の方法と比較して5倍以上の増加、そして最初の真の大規模な教師なし画像解釈へのステップ。 
[ABSTRACT] cnnのjanet ahnは、画像をキャプチャする新しい方法を見つける方法を見つける時がきたと言います。彼女は、小さなランダムな画像セットを使用して有望な提案を選択する2段階の戦略を開発したと言います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: DELTAS: Depth Estimation by Learning Triangulation And densification of
  Sparse points -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_36.html">
      <font color="black">DELTAS: Depth Estimation by Learning Triangulation And densification of
  Sparse points</font>
    </a>
  </h2>
  <font color="black">マルチビューステレオ（MVS）は、アクティブな深度センシングの精度と単眼深度推定の実用性の間の黄金の平均です。エンドツーエンドネットワークは、ディープラーニングフレームワーク内の3つのすべてのステップを効率的に実行し、中間2D画像でトレーニングされます深度の監視に加えて、3Dの幾何学的な監視。ただし、この精度は高い計算コストを伴うため、実際の採用は妨げられます。 
[ABSTRACT] 3D畳み込みニューラルネットワーク（cnns）を使用したコストボリュームベースのアプローチにより、mvsシステムの精度が向上しました。この方法では、特徴点の記述子を検出および評価します。次に、（b）少数の特徴点のセットをマッチングおよび三角形分割する学習cnnsの使用</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-19">
        <br><font color="black">2020-03-19</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Long-Term Object Tracking via Improved Discriminative Model
  Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_37.html">
      <font color="black">Robust Long-Term Object Tracking via Improved Discriminative Model
  Prediction</font>
    </a>
  </h2>
  <font color="black">（3）より特徴的な特徴の学習のための背景の増強：バックグラウンドクラッターでよりロバストなモデルをトレーニングするために、検索領域に含まれていないさまざまなバックグラウンドを増強します。ロバストな長期追跡ベースの改良された判別モデル予測方法を提案します。事前トレーニング済みの短期トラッカー..トラッカーRLT-DiMPは、次の3つの点でSuperDiMPを改善します。確実性として長方形の領域。 
[ABSTRACT] superdimpは、提案されたprdimpのsuperdimpリグレッサを標準のdimp分類子と組み合わせます。superdimpは、superdimpと呼ばれる短期モデルに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-11">
        <br><font color="black">2020-08-11</font>
      </time>
    </span>
</section>
<!-- paper0: RAFT: Recurrent All-Pairs Field Transforms for Optical Flow -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_38.html">
      <font color="black">RAFT: Recurrent All-Pairs Field Transforms for Optical Flow</font>
    </a>
  </h2>
  <font color="black">Sintel（最終パス）では、RAFTは2.855ピクセルのエンドポイントエラーを取得します。これは、公開された最良の結果（4.098ピクセル）から30％のエラー削減です。KITTIでは、RAFTは5.10％のF1-allエラーを達成します。最高の結果（6.10％）から16％のエラー削減。RAFTは、最先端のパフォーマンスを実現します。 
[ABSTRACT]ラフトはピクセルごとの機能を抽出し、すべてのピクセルのペアに対してマルチスケールの4D相関ボリュームを構築します。相関ボリュームに対してルックアップを実行する反復ユニットを通じて、フローフィールドを更新します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-26">
        <br><font color="black">2020-03-26</font>
      </time>
    </span>
</section>
<!-- paper0: Joint Face Completion and Super-resolution using Multi-scale Feature
  Relation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_39.html">
      <font color="black">Joint Face Completion and Super-resolution using Multi-scale Feature
  Relation Learning</font>
    </a>
  </h2>
  <font color="black">GANに基づいて、MFG-GANは、グラフの畳み込みと機能ピラミッドネットワークを統合して、閉塞された低解像度の顔画像を閉塞されていない高解像度の顔画像に復元します。さらに、ネットワークをエンドツーエンドで設計しました。形式.. MFG-GANは、カスタマイズされた損失のセットを使用して、高品質の画像が生成されるようにします。 
[要約]提案されたアプローチは、単一のタイプの劣化で画像を修復するために使用できます。ガンは、高品質の画像が生成されることを保証するためにカスタマイズされた損失のセットを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-29">
        <br><font color="black">2020-02-29</font>
      </time>
    </span>
</section>
<!-- paper0: FastSal: a Computationally Efficient Network for Visual Saliency
  Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_40.html">
      <font color="black">FastSal: a Computationally Efficient Network for Visual Saliency
  Prediction</font>
    </a>
  </h2>
  <font color="black">ソースコードはhttps://github.com/feiyanhu/FastSal。で入手できます。MobileNetV2は視覚的顕著性モデルの優れたバックボーンを構成し、複雑なデコーダーがなくても効果的であることがわかります。また、 DeepGaze IIのような計算コストの高いモデルは、ラベル付けされていないデータセットを疑似ラベル付けすることで実現できます。このアプローチでは、計算コストとモデルサイズの数分の1の多くの最先端のアルゴリズムと同等の結果が得られます。 
[ABSTRACT]私たちは、efficientnetやmobilenetv2などの最近のさまざまな効率的なネットワークを変更してテストします。これらを既存の状態と比較します-salganやdeepgaze iiなどの最先端の顕著性モデル。このアプローチは、ラベルなしのデータセットに疑似ラベルを付けることで実現できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Fast Adaptation to Super-Resolution Networks via Meta-Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_41.html">
      <font color="black">Fast Adaptation to Super-Resolution Networks via Meta-Learning</font>
    </a>
  </h2>
  <font color="black">次に、テスト段階で、このメタ学習ネットワークのパラメーターは、指定された低解像度画像のみを使用することにより、数回の反復で迅速に微調整されます。自然画像で..私たちの方法は未知のSRカーネルを効果的に処理し、既存の任意のモデルに適用できます。 
[ABSTRACT]トレーニング段階では、メタ学習を介してネットワークをトレーニングします。次に、ネットワークはテスト時に任意の入力画像にすばやく適応できます。テストデータでの適応は、パッチを最大限に活用します-テスト結果</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-09">
        <br><font color="black">2020-01-09</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Active Learning in Remote Sensing for data efficient Change
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_42.html">
      <font color="black">Deep Active Learning in Remote Sensing for data efficient Change
  Detection</font>
    </a>
  </h2>
  <font color="black">したがって、アクティブ学習システムのコアコンポーネントは、モデルの不確実性を推定するメカニズムであり、これを使用して不確実で有益なサンプルを選択します。分散に基づいて、ディープネットワークで作業するときに、この不確実性をキャプチャして定量化するさまざまなメカニズムを研究します。明示的または暗黙的なモデルアンサンブル全体のエントロピー。アクティブな学習が非常に有益なサンプルを正常に見つけ、トレーニング分布のバランスを自動的にとり、大規模な事前注釈付きトレーニングセットで監視されたモデルと同じパフォーマンスを$ \ approxで達成することを示します。注釈付きサンプルが$ 99％少なくなりました。 
[ABSTRACT]アクティブラーニングは、ローカルサーフェスの変化の検出を含む、多くのリモートセンシングタスクにとって自然な選択です。変化は一方ではまれであり、もう一方では、その外観が変化して拡散し、収集が困難になります。事前に設定された代表的なトレーニング</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Using the discrete radon transformation for grayscale image moments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_43.html">
      <font color="black">Using the discrete radon transformation for grayscale image moments</font>
    </a>
  </h2>
  <font color="black">必要な乗算の数がO（N + M）としてスケーリングされることを示し、生画像モーメントの最も広く使用されているアルゴリズムよりも高速にします。この論文では、生画像モーメントを計算するために離散ラドン変換を使用するアルゴリズムの概要を示します。グレースケール画像の現在の一般的なアルゴリズムは、生の画像モーメントのために計算コストが高く、必要な乗算の数は画像のピクセル数に比例します。 
[ABSTRACT]生の画像の瞬間は画像から直接得られます。画像のデータに基づいてアルゴリズムを作成する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: On estimating gaze by self-attention augmented convolutions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_44.html">
      <font color="black">On estimating gaze by self-attention augmented convolutions</font>
    </a>
  </h2>
  <font color="black">私たちは、フレームワークARes-gazeを吹き替えました。これは、注意強化ResNet（ARes-14）をツインたたみ込みバックボーンとして探索します。このメカニズムは、視線回帰の前に、顔と目の画像から派生した、より良い空間的特徴表現を作成することもできます。 。注目すべきは、提案されたフレームワークが、両方のデータセットで同時に高精度に到達する唯一のフレームワークであったことです。 
[ABSTRACT] wei wei weiweilは、この特定のタスクのネットワークアーキテクチャにはまだ改善の余地があると述べています。システムは、顔全体の画像で遠方の領域間の依存関係を学習することにより、より深いアーキテクチャよりも優れたパフォーマンスを発揮できると述べています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: 3rd Place Solution to "Google Landmark Retrieval 2020" -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_45.html">
      <font color="black">3rd Place Solution to "Google Landmark Retrieval 2020"</font>
    </a>
  </h2>
  <font color="black">データクリーニングとメトリック学習によるモデルの調査に焦点を当てています。さらに、モデルのマルチスケールおよびオクルードされたランドマーク画像を認識する能力を向上させる、Corner-Cutmixと呼ばれるデータ拡張方法を採用しています。 Google Landmark Retrieval 2020チャレンジの詳細なソリューション。 
[ABSTRACT]検索の巨人が、Googleのランドマーク検索2020チャレンジに対して3位の詳細なソリューションを提示しました。埋め込みクラスタリングに基づくデータクリーニング戦略を使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Active Class Incremental Learning for Imbalanced Datasets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_46.html">
      <font color="black">Active Class Incremental Learning for Imbalanced Datasets</font>
    </a>
  </h2>
  <font color="black">また、ILは、壊滅的な忘却に対する知識蒸留の確立された使用法ではなく、不均衡な学習問題と見なされます。インクリメンタル学習（IL）により、AIシステムはストリーミングデータに適応できます。 
[ABSTRACT] streamed.testsがバランスの取れたデータセットで実行されるとき、新しいデータは簡単に注釈が付けられていると想定されますが、実際のほとんどのデータセットは実際に不均衡です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Two-hand Global 3D Pose Estimation Using Monocular RGB -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_47.html">
      <font color="black">Two-hand Global 3D Pose Estimation Using Monocular RGB</font>
    </a>
  </h2>
  <font color="black">私たちのシステムは、RGBのみの情報を使用して、3Dの標準的な手姿勢推定ベンチマークデータセットに関する以前の作業よりも優れていることを示しています。さらに、RGBのみの入力を使用して両手で正確なグローバル3D手の追跡を実現し、広範な定量的および定性評価..この新しいタスクのCNNをトレーニングするために、大規模な合成3D手のポーズデータセットを導入します。 
[要旨]私たちは、正確に手をセグメント化して位置を特定する、新しい多段畳み込み畳み込みニューラルネットワークベースのパイプラインを提案します。rgbを使用して、両手で正確なグローバル3Dハンドトラッキングを実現する最初の作業を提示</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br><font color="black">2020-06-01</font>
      </time>
    </span>
</section>
<!-- paper0: Mask-guided sample selection for Semi-Supervised Instance Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_48.html">
      <font color="black">Mask-guided sample selection for Semi-Supervised Instance Segmentation</font>
    </a>
  </h2>
  <font color="black">この作業では、半教師付きインスタンスセグメンテーションのために注釈を付けるサンプルを決定するためのサンプル選択アプローチを提案します。画像セグメンテーションメソッドは通常、ピクセルレベルのアノテーションでトレーニングされます。品質スコアを指定して注釈を付け、ランダムな選択よりもアプローチが優れていることを示し、低い注釈予算で半教師付きインスタンスセグメンテーションのパフォーマンスを向上させます。 
[ABSTRACT]これの最も一般的な解決策は、弱い監視付きパイプラインを実装することです。この方法では、ラベルなしのサンプルプールの疑似マスクを予測し、マスクの品質を予測するスコアも含めます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Adaptation Regularization for Spectral Pruning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_49.html">
      <font color="black">Domain Adaptation Regularization for Spectral Pruning</font>
    </a>
  </h2>
  <font color="black">これは、展開の2番目の制限です。このホワイトペーパーでは、DA設定での圧縮方法の可能な改善について調査します。ドメイン適応（DA）は、1つのラベル付きソース配布で学習した知識をターゲットに転送できるようにすることで、この問題に対処します。分布、おそらくラベルなし。 
[ABSTRACT] dnsは通常、トレーニングするために大量のラベル付きデータを必要とします。これにより、圧縮結果を改善できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-26">
        <br><font color="black">2019-12-26</font>
      </time>
    </span>
</section>
<!-- paper0: Occupancy Anticipation for Efficient Exploration and Navigation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_50.html">
      <font color="black">Occupancy Anticipation for Efficient Exploration and Navigation</font>
    </a>
  </h2>
  <font color="black">占有率の予測を提案します。エージェントはエゴセントリックなRGB-D観測を使用して、可視領域を超えて占有率の状態を推測します。そうすることで、エージェントは空間認識をより迅速に構築し、3D環境での効率的な探索とナビゲーションを容易にします。最先端のナビゲーション方法は空間メモリを活用して新しい環境に一般化しますが、それらの占有マップはエージェントによって直接観察された幾何学的構造のキャプチャに制限されています。 
[要約]占有率予測を提案します。エージェントは、自己中心的なrgb-d観測を使用して、可視領域を超えて占有率の状態を推測します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-21">
        <br><font color="black">2020-08-21</font>
      </time>
    </span>
</section>
<!-- paper0: Interpretable Neural Network Decoupling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_51.html">
      <font color="black">Interpretable Neural Network Decoupling</font>
    </a>
  </h2>
  <font color="black">さらに、分離されたネットワークの解釈可能性とコンパクトさを向上させるために、各層の出力がエンコードされ、スパース正則化の制約とアーキテクチャエンコーディングベクトルを合わせます。ベクトルと入力画像間の相互情報を最大化することにより、モジュールはトレーニングされます特定のフィルターを選択して、各入力に固有の計算パスを抽出します。従来のピクセルレベルまたはフィルターレベルのネットワーク解釈方法とは異なり、パスレベル分析を提案して、フィルターとセマンティックの概念の組み合わせの関係を調査します。分離されたネットワークの動作原理を解釈するのにより適しています。 
[ABSTRACT]分離されたネットワークは、いくつかのアプリケーションを実現します。ネットワークの解釈、ネットワークの加速、および敵対的なサンプルの検出</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-04">
        <br><font color="black">2019-06-04</font>
      </time>
    </span>
</section>
<!-- paper0: DLGAN: Disentangling Label-Specific Fine-Grained Features for Image
  Manipulation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_52.html">
      <font color="black">DLGAN: Disentangling Label-Specific Fine-Grained Features for Image
  Manipulation</font>
    </a>
  </h2>
  <font color="black">定性的および定量的な実験は、提案された方法の有効性を実証します。さらに重要なことは、監視として連続ラベルを必要とせずに2つの異なるドメイン間の画像補間を実現する最初の作業です。私たちの知る限り、これは最初の作業ですこれは、単一のモデル内でこのようなハイブリッド操作を実現します。 
[ABSTRACT]これは、監督としての連続したラベルを必要とせずに2つの異なるタイプ間の画像補間を実現する最初の作品です。コンセプトはカリフォルニア大学によって開発されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-22">
        <br><font color="black">2019-11-22</font>
      </time>
    </span>
</section>
<!-- paper0: Cascade Convolutional Neural Network for Image Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_53.html">
      <font color="black">Cascade Convolutional Neural Network for Image Super-Resolution</font>
    </a>
  </h2>
  <font color="black">異なるスケールの画像を同時にトレーニングでき、学習したネットワークは、異なるスケールの画像にある情報を最大限に活用できます。ただし、これらのアプローチのほとんどは、トレーニングプロセス中に特定のスケール画像のみを考慮し、異なるスケール間の関係を無視します。画像のスケール..超解像畳み込みニューラルネットワーク（SRCNN）の開発により、画像の超解像の分野でディープラーニング技術が広く適用されています。 
[ABSTRACT]高速srcnnのネットワークは、特定のスケールの画像を処理できます。これらには、3つの高速高速srcnnが含まれ、各高速インターネットで画像を処理できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Deep Stereo Network Generalization with Geometric Priors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_54.html">
      <font color="black">Improving Deep Stereo Network Generalization with Geometric Priors</font>
    </a>
  </h2>
  <font color="black">実験的に、合成データセットでトレーニングし、ミドルベリー（実際の画像）データセットでテストすると、一貫した改善が見られます。ただし、グラウンドトゥルースの密度が高い多様な現実世界のシーンの大規模なデータセットは入手が困難であり、現時点では調査に利用できませんコミュニティエンドツーエンドのディープラーニング手法は、近年ステレオビジョンを進歩させ、トレーニングデータとテストデータが類似している場合に優れた結果を得ました。 
[ABSTRACT]高度なデータセットの大規模なデータセットは入手が困難です。これらは現在、研究コミュニティに公開されていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Image Colorization: A Survey and Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_55.html">
      <font color="black">Image Colorization: A Survey and Dataset</font>
    </a>
  </h2>
  <font color="black">評価用のデータセットとコードは、https：//github.com/saeed-anwar/ColorSurveyで公開されます。最近、特に画像のカラー化のためにディープラーニングテクニックが進歩しました。この記事では、ディープラーニングアルゴリズムを使用した最近の最先端のカラー化の包括的な調査を提示し、スキップ接続、入力などに関する基本的なブロックアーキテクチャについて説明します。オプティマイザ、損失関数、トレーニングプロトコル、およびトレーニングデータ\ etc一般に、既存のカラー化手法を7つのクラスに大まかに分類できます。 
[ABSTRACT]今週、特に画像の色付けのためのディープラーニングテクニックが進歩しました。adamsobel：コミュニティはこの問題にさらに取り組む必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Channel-Directed Gradients for Optimization of Convolutional Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_56.html">
      <font color="black">Channel-Directed Gradients for Optimization of Convolutional Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">このような勾配の連続体理論、その離散化、およびディープネットワークへの適用について説明します。出力チャネルの方向に沿って勾配を定義するとパフォーマンスが向上する一方で、他の方向では悪影響が生じる可能性があることを示します。ベンチマークデータセットの実験、いくつかネットワークとベースラインオプティマイザは、出力チャネル向けのメトリックに関する確率的勾配を単純に計算することにより、オプティマイザが汎化誤差を改善できることを示しています。 
[ABSTRACT]この方法は、既存の確率的スウェルの単純な処理のみを必要とします。任意のオプティマイザーと組み合わせて使用でき、線形損失しかありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: CDeC-Net: Composite Deformable Cascade Network for Table Detection in
  Document Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_57.html">
      <font color="black">CDeC-Net: Composite Deformable Cascade Network for Table Detection in
  Document Images</font>
    </a>
  </h2>
  <font color="black">広く利用可能なすべてのベンチマークデータセット（ICDAR-2013、ICDAR-2017、ICDAR-2019、UNLV、Marmot、PubLayNet、およびTableBank）でCDeC-Netを経験的に評価します-私たちのソリューションには3つの重要な特性があります：（i）単一のトレーニング済みモデルCDeC-Net {\ ddag}は、すべての一般的なベンチマークデータセット全体で良好に機能します。 （ii）IoUのより高いしきい値を含む、複数にわたる優れたパフォーマンスを報告します。 （iii）各ベンチマークについて、最近の論文と同じプロトコルに従うことにより、優れた定量的パフォーマンスを一貫して実証します。結果の再現性を可能にするために、コードとモデルを公開します。 
[要約]提案されたネットワークは、利用可能なベンチマークで変形可能な畳み込みを持つデュアルバックボーンを備えたマスクr-cnnの多段拡張で構成されています。新しいネットワークによると、iouのより高いしきい値を含む、複数のノードにわたる優れたパフォーマンスを報告します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Target Domain Specific Classifier for Partial Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_58.html">
      <font color="black">Learning Target Domain Specific Classifier for Partial Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">PDAシナリオでは、ターゲットドメインに存在しないソースの外れ値がターゲットドメインに誤って一致する可能性があり（技術的に負の転送と呼ばれます）、UDAメソッドのパフォーマンスが低下します。ラベル付けされたソースドメインからラベル付けされていないターゲットドメインに知識を転送するときの分布の不一致。このホワイトペーパーでは、新しいターゲットドメイン固有の分類子学習ベースのドメイン適応（TSCDA）メソッドを提案します。 
[要約]この論文では、新しいターゲットドメイン固有の分類器学習ベースのドメイン適応（tscda）メソッドを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: A Critical Analysis of Patch Similarity Based Image Denoising Algorithms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_59.html">
      <font color="black">A Critical Analysis of Patch Similarity Based Image Denoising Algorithms</font>
    </a>
  </h2>
  <font color="black">最後に、画像のノイズ除去を取り巻く作業のほとんどは、ノイズ除去された画像と（加法性ホワイトガウスノイズで摂動された）参照画像の間のピーク信号対ノイズ比（PSNR）に基づくパフォーマンス結果を示します。画像のノイズ除去は、非局所的な類似性のパラダイムに焦点を当てており、類似する近傍の画像ブロックが収集されて再構成の基礎を構築します。最後に、参照なしの画像品質測定を組み込む方法論の見直しを主張し、画像のノイズ除去アルゴリズムのパフォーマンス評価中の未処理の画像（生）。 
[ABSTRACT]写真のノイズ除去に関するアルゴリズムのほとんどは、ラルフローレンに焦点を合わせています。これらは、画像を不釣り合いに改造するツールを含みます。代わりに、参照なしの局所類似性測定値と未処理の画像を組み込む方法論の見直しを主張しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Masked Face Recognition for Secure Authentication -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_60.html">
      <font color="black">Masked Face Recognition for Secure Authentication</font>
    </a>
  </h2>
  <font color="black">オープンソースツールのMaskTheFaceを使用して顔をマスクし、マスクされた顔の大規模なデータセットを効果的に作成します。このペーパーでは、マスクされた顔を低い偽陽性で認識できるようにするツールで現在の顔のデータセットを使用する方法を扱います認証のために新しい写真を撮ってユーザーデータセットを再作成する必要なしに、レートと高い全体的な精度。.最近の世界的なCOVID-19パンデミックにより、フェイスマスクの使用は私たちの生活の重要な部分になりました。 
[ABSTRACT]人々は感染を避けるために公共エリアで自分の顔を覆うことをお勧めします。これらの人々は偽陽性-正の率と高い全体的な精度で自分自身を識別することができました。これらのツールは、ターゲットの精度で効果的な顔認識システムのトレーニングに使用されますマスクされた顔用</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Confidence-aware Adversarial Learning for Self-supervised Semantic
  Matching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_61.html">
      <font color="black">Confidence-aware Adversarial Learning for Self-supervised Semantic
  Matching</font>
    </a>
  </h2>
  <font color="black">最初に、自己教師あり学習によるマッチング予測のための密な信頼マップを推定することを提案します。この論文では、マッチングのあいまいさを学習した深い特徴でも解決することが難しいセマンティックマッチングの挑戦的なタスクに取り組むことを目指します。 https://github.com/ShuaiyiHuang/CAMNetでソースコードをリリースします。 
[ABSTRACT]予測の意味的信頼性を活用してこの問題に取り組みます。それらは、部分的アリアエラーを修正するための即時の改善戦略を開発します。これらは、一致する予測の密な信頼マップを推定することを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Neighbourhood-Insensitive Point Cloud Normal Estimation Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CV/paper_62.html">
      <font color="black">Neighbourhood-Insensitive Point Cloud Normal Estimation Network</font>
    </a>
  </h2>
  <font color="black">また、アプリケーションケースとしてポイントツープレーン反復最近傍点（ICP）を使用して、通常の推定が、近傍範囲パラメーターを手動で微調整することなく、他の方法からの通常の推定よりも速く収束することを示しています。 -関連するポイントに柔らかく焦点を合わせ、温度パラメーターを学習することにより柔らかさを調整できる注意ベースの通常の推定ネットワーク。広い近隣範囲内で自然かつ効果的に機能できるようにします。https：// codeでコードを入手できます。 active.vision。 
[ABSTRACT]当社のモデルは、既存のすべてのアルゴリズムを大幅に上回っています。以前の最新の91. 2％と比較して、94。1％の精度を達成しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-23">
        <br><font color="black">2020-08-23</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: DUTH at SemEval-2020 Task 11: BERT with Entity Mapping for Propaganda
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CL/paper_0.html">
      <font color="black">DUTH at SemEval-2020 Task 11: BERT with Entity Mapping for Propaganda
  Classification</font>
    </a>
  </h2>
  <font color="black">浅い自然言語処理（NLP）前処理技術を使用して、データセット、特徴選択方法、および一般的な教師付き機械学習アルゴリズムのノイズを低減しました。このレポートでは、デモクリタストラキア大学（DUTH）チームが参加するために採用した方法について説明します。 SemEval-2020タスク11：ニュース記事での宣伝テクニックの検出モデルの精度を向上させるために、単語クラスとエンティティ認識を使用して、特定の単語を5つの異なるカテゴリにマッピングしました。 
[要旨]チームは、隔離のためのサブタスク2を処理しました。サブタスク2：隔離、サブタスク2、サブタスク2</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-22">
        <br><font color="black">2020-08-22</font>
      </time>
    </span>
</section>
<!-- paper0: Query Understanding via Intent Description Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CL/paper_1.html">
      <font color="black">Query Understanding via Intent Description Generation</font>
    </a>
  </h2>
  <font color="black">人間のアノテーターのように、システムが検索クエリの詳細かつ正確なインテントの説明を自動的に生成できた場合、クエリの理解が深まったことを示します。この新しいタスクに対処するために、新しい対照生成モデル、つまりつまり、クエリを与えられた関連ドキュメントと関連のないドキュメントを対比してインテントの説明を生成します。したがって、このホワイトペーパーでは、クエリを理解するための新しいQuery-to-Intent-Description（Q2ID）タスクを提案します。 
[ABSTRACT]クエリは、人間のアノテーターによって提供される詳細な説明に関連付けられることがよくあります。これらは、ドキュメントの関連性を評価するのに役立ちます。この新しいタスクは、意図の説明を作成する新しいモデルを作成することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: TabSim: A Siamese Neural Network for Accurate Estimation of Table
  Similarity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CL/paper_2.html">
      <font color="black">TabSim: A Siamese Neural Network for Accurate Estimation of Table
  Similarity</font>
    </a>
  </h2>
  <font color="black">ランキングシナリオで1.5％pp。これらの問題はすべて、2つのテーブルの意味的類似性の正確な測定に本質的に依存しています。この表現で2つのテーブルが与えられると、シャムニューラルネットワークは、テーブルと相関するスコアを計算するようにトレーニングされます。意味的類似性。 
[ABSTRACT]テーブルは、ウェブページを含むさまざまな形式のドキュメントで広く使用されています。それらは、emmembersで人気がありますが、依然として多くの方法で人気があります。これらは、テキストの補遺としてだけでなく、ファーストクラスのオブジェクトとしても使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Comparative Computational Analysis of Global Structure in Canonical,
  Non-Canonical and Non-Literary Texts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CL/paper_3.html">
      <font color="black">Comparative Computational Analysis of Global Structure in Canonical,
  Non-Canonical and Non-Literary Texts</font>
    </a>
  </h2>
  <font color="black">研究の特定の結果を超えて、テキストの美学の実験的研究に新しい視点を開くつもりです。グローバルな構造の2つの側面、つまりテキストに沿った長距離の相関を反映する変動性と自己相似（フラクタル）パターンが調査されます..これらの基本的な観察は、2つのより一般的なカテゴリに分類されます。（a）低レベルのプロパティ（i）および（ii）は、文のレベルで観察されます（言語のデコードを反映）。（b）高レベルのプロパティレベルレベルのプロパティ（iii）および（iv）。これらはテキストレベルで観察されます（理解度を反映）。 
[ABSTRACT]イェーナ文学美学コーパスには、関心のある3つのカテゴリのテキストが含まれています。これらには、文ごとのposタグの頻度、テキストのチャンクの語彙の多様性が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Probing Linguistic Systematicity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CL/paper_4.html">
      <font color="black">Probing Linguistic Systematicity</font>
    </a>
  </h2>
  <font color="black">言語の観点から体系性の概念を検討し、体系的な動作を測定するための一連のプローブと一連のメトリックを定義しました。ケーススタディとして、自然言語推論（NLI）の設定で一連の実験を行い、一部のNLUシステムは、体系的ではなくても全体的に高いパフォーマンスを実現します。また、ネットワークアーキテクチャが非体系的に一般化できる方法を特定し、そのような形式の一般化では不十分な理由についても説明します。 
[要約]ニューラルモデルが非体系的に一般化することが多いという証拠があります。ネットワークアーキテクチャが一般化できる方法も特定しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-08">
        <br><font color="black">2020-05-08</font>
      </time>
    </span>
</section>
<!-- paper0: YNU-HPCC at SemEval-2020 Task 11: LSTM Network for Detection of
  Propaganda Techniques in News Articles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CL/paper_5.html">
      <font color="black">YNU-HPCC at SemEval-2020 Task 11: LSTM Network for Detection of
  Propaganda Techniques in News Articles</font>
    </a>
  </h2>
  <font color="black">SIサブタスクのマクロF1-scoreは0.406、TCサブタスクのmicro-F1-scoreは0.505です。このタスクを実行するために、GloVeワード表現、BERT事前トレーニングモデル、およびLSTMモデルアーキテクチャを実装しました。 。このペーパーは、SemEval-2020タスク11のニュース記事のプロパガンダ検出手法に関する私たちの研究をまとめたものです。
[要約]私たちのアプローチは、siおよびtcサブタスクの両方で良好な結果を達成しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: ICE-Talk: an Interface for a Controllable Expressive Talking Machine -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CL/paper_6.html">
      <font color="black">ICE-Talk: an Interface for a Controllable Expressive Talking Machine</font>
    </a>
  </h2>
  <font color="black">さらに、Human-Agentインタラクションの一部として使用できるモジュールとして実装されています。これにより、制御可能なTTSの潜在スペースの調査が可能になります。ICE-Talkは、WebベースのオープンソースGUIで、テキストフィールドとクリック可能な2Dプロットを介して制御可能なパラメーターを備えたTTSシステム。 
[ABSTRACT]これは、制御可能なコントロールの潜在スペースの研究を可能にします。これは、テキストコントローラーに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Learning from students' perception on professors through opinion mining -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CL/paper_7.html">
      <font color="black">Learning from students' perception on professors through opinion mining</font>
    </a>
  </h2>
  <font color="black">教育調査に対する意見を通じて測定されたクラスの学生の認識は、環境と学習方法の両方における欠陥と問題を特定することを可能にします。学生がクラスについての意見を表明する自由な質問を通じて提供できる情報。その結果、関連する感情やそのような意見の関連トピックを予測する2つのアルゴリズムが実装、トレーニング、テストされています。 
[要約]学生の意見の目的は、ポジティブ、ネガティブ、またはニュートラルな意見を特定することです。学生は、極性分析を介して関連する感情を予測する方法を教えられます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Attention Guided Graph Convolutional Networks for Relation Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CL/paper_8.html">
      <font color="black">Attention Guided Graph Convolutional Networks for Relation Extraction</font>
    </a>
  </h2>
  <font color="black">私たちのモデルは、関係抽出タスクに役立つ関連するサブ構造に選択的に対応する方法を自動的に学習するソフトプルーニングアプローチとして理解できます。クロスセンテンスn項関係抽出や大規模などのさまざまなタスクに関する広範な結果文レベルの関係抽出は、モデルが完全な依存関係ツリーの構造情報をより有効に活用できることを示しており、以前のアプローチよりもはるかに優れた結果をもたらします。最適な結果が得られます。 
[ABSTRACT]調査は注意ルールの使いにくい依存関係ツリーによって実行されています。これは、ソーシャルネットワークからの無関係な情報を無視しながら、関連情報を利用するために使用できます。このモデルは、完全な依存関係ツリー。以前のアプローチよりもはるかに優れた結果を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-18">
        <br><font color="black">2019-06-18</font>
      </time>
    </span>
</section>
<!-- paper0: Conceptualized Representation Learning for Chinese Biomedical Text
  Mining -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CL/paper_9.html">
      <font color="black">Conceptualized Representation Learning for Chinese Biomedical Text
  Mining</font>
    </a>
  </h2>
  <font color="black">ベンチマークの実験結果は、私たちのアプローチが大幅な利益をもたらす可能性があることを示しています。また、新しい中国の生物医学言語理解評価ベンチマーク（\ textbf {ChineseBLUE}）もリリースしています。一般的なコーパスと生物医学的コーパスの単語分布はかなり異なります。 
[ABSTRACT] bertなどの中国語の言語モデルは研究者の間で人気を博していますが、中国の医療ドメインには長い尾の概念と用語が言語モデルで学習することが困難です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Simple Unsupervised Similarity-Based Aspect Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CL/paper_10.html">
      <font color="black">Simple Unsupervised Similarity-Based Aspect Extraction</font>
    </a>
  </h2>
  <font color="black">最初のタスクは、レビューテキストで言及されている側面を発見する責任があり、2番目のタスクは、その側面に感情の方向（ポジティブ、ネガティブ、またはニュートラル）を割り当てます。現在、ABSAの最新技術は、再帰、畳み込み、注意ニューラルネットワークなどの深層学習手法の適用。これらの手法の制限は、大量のトレーニングデータを必要とし、計算コストがかかることです。 
[ABSTRACT]論文で、granはアスペクト抽出のためにsuaexと呼ばれる単純なアプローチを提案しました。suaexは、最先端の注目に基づくアプローチよりもわずかな時間でパフォーマンスを向上できる結果を達成しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Abstractive Summarization of Spoken and Written Instructions with BERT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CL/paper_11.html">
      <font color="black">Abstractive Summarization of Spoken and Written Instructions with BERT</font>
    </a>
  </h2>
  <font color="black">人間の裁判官を雇って、HowTo100MとYouTubeからキュレーションされたデータセットからランダムに選択された一連の要約を採点します。結果は、How2およびWikiHowデータセットのROUGEおよびContent-F1スコアリングで評価されます。モデルは、WikiHowに適用されると、現在のSOTAに勝ります標準のCNN / DailyMailデータセットでパフォーマンスの低下を示さない一方で、スタイルとトピックが大きく異なる記事。 
[ABSTRACT]ビデオは会話へのbertsumモデルの最初の適用を示しています。彼らはいくつかの大きなクロスドメインデータセットでモデルを事前トレーニングしました。結果はルージュとコンテンツで評価されます-dicおよびwikihowデータセットのf1スコアリング</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-21">
        <br><font color="black">2020-08-21</font>
      </time>
    </span>
</section>
<!-- paper0: Word2vec Skip-gram Dimensionality Selection via Sequential Normalized
  Maximum Likelihood -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CL/paper_12.html">
      <font color="black">Word2vec Skip-gram Dimensionality Selection via Sequential Normalized
  Maximum Likelihood</font>
    </a>
  </h2>
  <font color="black">単語の埋め込みに関する他の評価方法と比較して、SNMLによって選択された次元は、単語の類推または単語の類似性タスクによって取得された最適な次元に非常に近くなります。したがって、対応するように最適な次元を選択することを目的として、情報基準を適用します。モデルは、真の分布に可能な限り近づけることができます。提案されたアプローチは、元のSGモデルとSGネガティブサンプリングモデルの両方に適用され、情報基準の使用の考え方を明確にします。 
[要約]提案されたアプローチは、元のsgモデルとsgネガティブサンプリングモデルの両方に適用されます。snmlは、bicとaicの両方より優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-18">
        <br><font color="black">2020-08-18</font>
      </time>
    </span>
</section>
<!-- paper0: ETC-NLG: End-to-end Topic-Conditioned Natural Language Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CL/paper_13.html">
      <font color="black">ETC-NLG: End-to-end Topic-Conditioned Natural Language Generation</font>
    </a>
  </h2>
  <font color="black">次に、並列コーパスを使用してイタリア語と英語のETC-NLGの比較評価を実行します。最初に、イタリア語の低リソース設定でのアプローチの有効性をテストし、トピックモデルとゴールドアノテーションの両方の条件付けを評価します。 、生成された発話に対する条件付けの有効性を推定する自動アプローチを提案します。 
[要約]まず、低発電機でのアプローチの有効性をテストします。次に、有効性を推定する自動アプローチを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: JokeMeter at SemEval-2020 Task 7: Convolutional humor -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CL/paper_14.html">
      <font color="black">JokeMeter at SemEval-2020 Task 7: Convolutional humor</font>
    </a>
  </h2>
  <font color="black">公式データセットでシステムを調査し、学習した内部特徴がどのように見えるかを確認するためにモデル化するための洞察を提供します。このペーパーでは、SemEval-2020タスク7.内のユーモア評価用に設計されたシステムについて説明します。システムは畳み込みニューラルネットワークアーキテクチャに基づいています。 
[要約]機密サポートについては、08457 90 90 90にサマリア人に電話するか、地元のサマリア人の支店を訪問してください。詳細については、www.samaritans.orgを参照してください。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Complicating the Social Networks for Better Storytelling: An Empirical
  Study of Chinese Historical Text and Novel -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CL/paper_15.html">
      <font color="black">Complicating the Social Networks for Better Storytelling: An Empirical
  Study of Chinese Historical Text and Novel</font>
    </a>
  </h2>
  <font color="black">\ textit {Romance}のソーシャルネットワークは\ textit {Records}のソーシャルネットワークよりも複雑で動的であり、メインキャラクターの影響は異なります。自然言語処理技術を使用して、キャラクターとその関係を抽出します。デジタル人文科学は、歴史、文学、映画の発展を可能にする重要なテーマです。 
[要約]中国の歴史的テキストの研究、3つの王国の記録と同じ物語の歴史小説、3つの王国のロマンス。この研究は、物語のさまざまなスタイルと、歴史小説がどのようにソーシャルネットワークを複雑にしているのかを明らかにします。物語の文学性を豊かにするキャラクター</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Contextualized moral inference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CL/paper_16.html">
      <font color="black">Contextualized moral inference</font>
    </a>
  </h2>
  <font color="black">インテリジェントシステムでの道徳的意識の発達は、過去数十年にわたって哲学的調査のトピックから人工知能の重要かつ実用的な問題へと移行しました。文脈化された表現は、人間の道徳的判断を推論し、評価し、道徳心理学からの3つの独立したデータセットに反映します。私たちの方法論は、文脈化言語モデルと道徳的感情のテキスト推論における最近の研究に基づいています。 
[ABSTRACT]自動化された文学的道徳的推論におけるアプローチの約束と限界について説明します。問題を理解できるようにする必要があると言います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Is this sentence valid? An Arabic Dataset for Commonsense Validation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/cs.CL/paper_17.html">
      <font color="black">Is this sentence valid? An Arabic Dataset for Commonsense Validation</font>
    </a>
  </h2>
  <font color="black">データセットはCreative Commons BY-SA 4.0ライセンスで配布され、GitHubで見つけることができます。このホワイトペーパーでは、常識的な理解と検証のためのアラビア語のベンチマークデータセットと、同じデータセットを使用してトレーニングされたベースライン調査とモデルを示します。私たちの知る限りでは、このデータセットはアラビア語テキストの常識的な検証の分野で最初のものと見なされています。 
[要約]データセットは、アラビア語のテキストの常識的な検証の分野で最初のものと見なされます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Dual Attention in Time and Frequency Domain for Voice Activity Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.AS/paper_0.html">
      <font color="black">Dual Attention in Time and Frequency Domain for Voice Activity Detection</font>
    </a>
  </h2>
  <font color="black">私たちの提案する方法は、ROC曲線（AUC）の下の95.58％の面積を取得し、ベースラインと比較して22.05％の相対的な改善を達成し、パラメーターの数を2.44％だけ増加させます。時間領域と周波数領域の両方に適応的に焦点を合わせることができます。また、トレーニングセットの音声セクションと非音声セクションの不均衡によるパフォーマンスの低下を軽減するために、焦点損失を利用します。 
[ABSTRACT] lstmは長期の短期メモリ（lstm）に統合できます。システムは長期の短期的な損失に統合できます。プロジェクトを使用してパフォーマンスパフォーマンスを向上できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-27">
        <br><font color="black">2020-03-27</font>
      </time>
    </span>
</section>
<!-- paper0: ICE-Talk: an Interface for a Controllable Expressive Talking Machine -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.AS/paper_1.html">
      <font color="black">ICE-Talk: an Interface for a Controllable Expressive Talking Machine</font>
    </a>
  </h2>
  <font color="black">さらに、Human-Agentインタラクションの一部として使用できるモジュールとして実装されています。ICE-Talkは、テキストフィールドとクリック可能なコントロールを介して制御可能なパラメーターを持つTTSシステムの使用を可能にするオープンソースのWebベースのGUIです。 2Dプロット..制御可能なTTSの潜在スペースの研究を可能にします。 
[ABSTRACT]これは、制御可能なコントロールの潜在スペースの研究を可能にします。これは、テキストコントローラーに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Tail Performance of a Deliberation E2E ASR Model Using a Large
  Text Corpus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.AS/paper_2.html">
      <font color="black">Improving Tail Performance of a Deliberation E2E ASR Model Using a Large
  Text Corpus</font>
    </a>
  </h2>
  <font color="black">浅いフュージョンは、事前トレーニングされたLMを推定時にE2Eモデルに組み込む方法として提案されていますが、非常に大きなテキストコーパスについてはまだ調査されておらず、ハイパーパラメータ設定に非常に敏感であることが示されています。ビーム検索..この作業では、浅い融合を適用して、非常に大きなテキストコーパスを最新のE2EASRモデルに組み込みます。モデルサイズの影響を調査し、トレーニングセットのインテリジェントなプルーニングがパラメータ数を増やすよりも効果的です。 
[ABSTRACT]短期e2easrは最新のe2mモデルです。これらにはテキストが含まれます-トレーニングへのデータのみです。これは、オーディオでは頻繁に発生しないテールワードの認識に重要です-テキストペア</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Few Shot Text-Independent speaker verification using 3D-CNN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.AS/paper_3.html">
      <font color="black">Few Shot Text-Independent speaker verification using 3D-CNN</font>
    </a>
  </h2>
  <font color="black">これを達成するために、センターロスとスピーカーバイアスロスのあるシャムニューラルネットワークを使用しています。したがって、このホワイトペーパーでは、非常に少ないトレーニングデータを使用して、クレームされたスピーカーの同一性を検証する新しい方法を提案しました。 -独立したオーディオデータは、話者の確認などのタスクで常に利用できるとは限りません。また、トレーニングデータが非常に少ないと仮定して、テキストに依存しない話者の確認のための作業が過去に行われていません。 
[要約]オーディオは、既存の認識システムの代替として使用できるもう1つの可能な生体認証です。voxceleb1データセットに対して実施された実験は、非常に少ないデータを使用したトレーニングでも、提案されたモデルの精度が最新のモデルに近いことを示していますテキスト-独立した話者認証</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Aphasic Speech Recognition using a Mixture of Speech Intelligibility
  Experts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.AS/paper_4.html">
      <font color="black">Aphasic Speech Recognition using a Mixture of Speech Intelligibility
  Experts</font>
    </a>
  </h2>
  <font color="black">テスト時に、各専門家の貢献度は、音声了解度検出器（SID）を使用して音声了解度を推定することによって決定されます。提案されたアプローチは、重大度情報をモデリングプロセスに組み込まないでください。これの1つの理由は、重大度のレベルが異なるため、音声の明瞭度の範囲が広いことです（つまり、重大度が高いほど、音声がわかりにくくなります）。 
[ABSTRACT]自動音声認識モデルは、失語症の音声に適用するとパフォーマンスが低下します。これは、エキスパート（moe）の混合によるものです。エキスパート（moe）は、深刻度を明示的に定義することにより、音声に存在するさまざまな了解度を処理します。アプローチは、モデリングプロセスに重大度情報を組み込んでいないベースラインアプローチと比較して、失語症のスピーチのすべての重大度段階にわたる電話エラー率を大幅に低減します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Assessment of Parkinson's Disease Medication State through Automatic
  Speech Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.AS/paper_5.html">
      <font color="black">Assessment of Parkinson's Disease Medication State through Automatic
  Speech Analysis</font>
    </a>
  </h2>
  <font color="black">結果は、混合スピーチのテストタスクで90.54％の精度、半自発的スピーチタスクで95.27％の精度を示しています。全体的に、実験的評価では、このアプローチが信頼性の高いリモートの毎日のモニタリングの開発に向けた可能性を示しています。 PD患者の薬物摂取のスケジューリング..この作業では、自動音声処理とディープラーニング技術を組み合わせて、個人の音声ベースのバイオマーカーを活用してPD患者の薬物状態を分類するシステムを紹介します。 
[要約]システムは、自動音声処理とディープラーニング技術を組み合わせて、pd患者の投薬状態を分類します。これには、個人の音声ベースのバイオマーカーの活用が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-29">
        <br><font color="black">2020-05-29</font>
      </time>
    </span>
</section>
<!-- paper0: Medley2K: A Dataset of Medley Transitions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.AS/paper_6.html">
      <font color="black">Medley2K: A Dataset of Medley Transitions</font>
    </a>
  </h2>
  <font color="black">私たちのデータセットは、さまざまな音楽ジャンルにわたるさまざまな曲のトランジションを特徴としています。メドレーの自動生成、つまりスムーズなトランジションを介して連結されたさまざまな曲によって形成された楽曲は、現在の文献では詳しく研究されていません。このデータセットを使用して、曲間のトランジションを生成するタスクで最先端の生成モデルをトレーニングして検証します。 
[要旨] medley2kと呼ばれる2,00のメドレーと7、712のラベルが付けられたtransition.datasetで構成されるデータセットを利用可能にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: Tandem Assessment of Spoofing Countermeasures and Automatic Speaker
  Verification: Fundamentals -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-26/eess.AS/paper_7.html">
      <font color="black">Tandem Assessment of Spoofing Countermeasures and Automatic Speaker
  Verification: Fundamentals</font>
    </a>
  </h2>
  <font color="black">近年、自動スピーカー検証（ASV）システムが操作または人工入力によってだまされるのを防ぐためにスプーフィング対策（CM）を開発する取り組みが増えています。固定ASVシステムの特別なケース、ASVspoof 2019データベースを使用して、その解釈と新しい分析に独自の洞察を与えるシミュレーション。CM評価にt-DCFを採用することで、なりすましおよびASV研究コミュニティ。 
[要約] cmsのスプーフィングの信頼性は、通常、等しいエラー率（eer）メトリックを使用して測定されます。プリミティブな影響率は、システムの開発に対するリスクの主要なポイントです。t-dcfの採用が促進されることが望まれますなりすまし防止とasv研究コミュニティ間のより緊密な協力</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-12">
        <br><font color="black">2020-07-12</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
