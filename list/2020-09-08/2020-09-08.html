<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-09-08の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: audioLIME: Listenable Explanations Using Source Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.SD/paper_0.html">
      <font color="black">audioLIME: Listenable Explanations Using Source Separation</font>
    </a>
  </h2>
  <font color="black">局所性の音楽的定義によって拡張されたローカル解釈可能モデルにとらわれない説明（LIME）に基づく方法であるaudioLIMEを提案します。2つの異なる音楽タグ付けシステムでaudioLIMEを検証し、競合する方法ではできない状況での合理的な説明を生成することを示します。 LIMEで使用される摂動は、ソース分離によって抽出されたコンポーネントのオン/オフを切り替えることによって作成され、説明を聞き取りやすくします。 
[ABSTRACT] audiolimeは、ローカルの解釈可能なモデルに基づくメソッドです。競合するメソッドができない状況で、合理的な説明を生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-02">
        <br><font color="black">2020-08-02</font>
      </time>
    </span>
</section>
<!-- paper0: An End-to-end Architecture of Online Multi-channel Speech Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.SD/paper_1.html">
      <font color="black">An End-to-end Architecture of Online Multi-channel Speech Separation</font>
    </a>
  </h2>
  <font color="black">すべての方法で勾配の伝播を可能にするために、注意の重みが各ビームフォーマーと空間でサンプリングされた空間特徴について学習される注意選択モジュールが提案されています。マルチスピーカー音声認識は、シングルアクティブなスピーカーの仮定を破る会話の書き起こしにおける重要な課題の1つです。ほとんどの最先端の音声認識システムで採用されています。この作業では、UFEのエンドツーエンドのモデリングバージョンを紹介します。 
[要約]提案されたシステムは音声認識の代替として開発されました。複数のビームフォーマーによって開発され、次にufeと呼ばれます。新しいシステムは音声認識の開発に使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Digital Envelope Estimation Via Geometric Properties of an
  Arbitrary Real Signal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.SD/paper_2.html">
      <font color="black">Robust Digital Envelope Estimation Via Geometric Properties of an
  Arbitrary Real Signal</font>
    </a>
  </h2>
  <font color="black">具体的には、離散曲率の新しい測定値を使用して、離散波の平均曲率半径を取得し、波のフロンティアポイントを識別するためのしきい値として機能します。ここで説明するアプローチは、幾何学的概念からインスピレーションを引き出し、フロンティアを分離して推定します任意の信号の時間エンベロープ。そのために、アルファ形状、凹面の外皮、および離散的な曲率が検討されています。エンベロープ検出技術は、健康、音の分類と合成、地震学、音声認識などの分野での用途があります。 
[ABSTRACT]エンベロープ検出は、健康、音の分類と合成、地震学、音声認識などの分野に応用できます。この問題に対処するために、信号の固有の特性を使用してエンベロープを推定するフレームワークを提案します。次のようなエンティティも定義します。パルスとフロンティア、提案されたアルゴリズムの剛性と複雑さを減らす手段として</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchical Timbre-Painting and Articulation Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.SD/paper_3.html">
      <font color="black">Hierarchical Timbre-Painting and Articulation Generation</font>
    </a>
  </h2>
  <font color="black">モデルは、再構成損失としてマルチ解像度スペクトル損失、オーディオサウンドをより現実的にするための敵対的損失、および出力を目的の入力ピッチコンターに揃えるための知覚f0損失を最適化します。コードとオーディオサンプルはhttpsで共有されます。 ：//github.com/mosheman5/timbre_painting ..提案されたアーキテクチャは、数分という短時間のサンプルを前提として、機器の高品質なフィッティングを可能にし、メソッドは最先端の音色転送を実証します機能。 
[ABSTRACT]提案された設計は、音の損失を再構築するために使用できます。この方法は、最先端の音色転送機能を実証しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-30">
        <br><font color="black">2020-08-30</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: 3D Contouring for Breast Tumor in Sonography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/eess.IV/paper_0.html">
      <font color="black">3D Contouring for Breast Tumor in Sonography</font>
    </a>
  </h2>
  <font color="black">提案された方法は、効率的なセグメンテーション手順を利用します。ただし、超音波画像にはノイズと組織のテクスチャが含まれています。したがって、臨床診断は医師の経験に大きく依存します。この研究では、10個の良性腫瘍と10個の悪性腫瘍からなる20例を評価しています。 
[ABSTRACT]腫瘍の輪郭は時間のかかる複雑なタスクです。提案された3Dセグメンテーション方法は、堅牢な輪郭を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-01-27">
        <br><font color="black">2019-01-27</font>
      </time>
    </span>
</section>
<!-- paper0: Edge effect removal in Fourier ptychographic microscopy via perfect
  Fourier transformation (PFT) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/eess.IV/paper_1.html">
      <font color="black">Edge effect removal in Fourier ptychographic microscopy via perfect
  Fourier transformation (PFT)</font>
    </a>
  </h2>
  <font color="black">フーリエ超音波顕微鏡（FPM）でのみPFTのパフォーマンスを実証しましたが、従来のFFTを使用する場合はいつでも拡張できます。 （FFT）。この手紙では、PFTと呼ばれる完全なフーリエ変換アルゴリズムが、FFTに匹敵する効率でアーティファクトを除去することが報告されています。 
[ABSTRACT] pftはfftに匹敵する効率でアーティファクトを削除すると報告されています。結果は事前に示されていました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Localization and classification of intracranialhemorrhages in CT data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/eess.IV/paper_2.html">
      <font color="black">Localization and classification of intracranialhemorrhages in CT data</font>
    </a>
  </h2>
  <font color="black">この自動システムは、急性の場合、診断プロセスの期間を明らかに短縮する可能性があります。一般に入手可能な頭部CTデータセットCQ500からのデータで、平均53.7％のJaccard係数が達成されます。頭蓋内出血（ICH）は生命を脅かします比較的高い発生率で脳を傷つけます。 
[要約] ichsの検出と分類のための自動アルゴリズムが存在します。システムは、急性の場合にシステムの期間の減少につながる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-Supervised Deep Learning for Multi-Tissue Segmentation from
  Multi-Contrast MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/eess.IV/paper_3.html">
      <font color="black">Semi-Supervised Deep Learning for Multi-Tissue Segmentation from
  Multi-Contrast MRI</font>
    </a>
  </h2>
  <font color="black">大腿組織の完全に自動化された、堅牢で正確な定量化に向けて、ここではディープネットワークアーキテクチャに基づいた新しい半教師付きセグメンテーションアルゴリズムを設計しました。提案されたシステムは、トレーニングに高い有効性を持つラベル付きデータとラベルなしデータの両方を利用し、優れた性能を発揮しましたダイススコア97.52％、94.61％、80.14％、95.93％、および96.83％の現在の最先端の方法は、それぞれ、筋肉、脂肪、IMAT、骨、および骨髄組織でした。結果から、提案されたシステムは、体積および分布組織の定量化が極めて重要であり、ラベリングが重要な問題である臨床研究研究に役立ちます。 
[ABSTRACT]研究者は50人の異なる被験者から150以上のスキャンを使用しています。このシステムは臨床研究に役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Refining Deep Symmetry Enhanced Network for Rain Removal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/eess.IV/paper_4.html">
      <font color="black">Self-Refining Deep Symmetry Enhanced Network for Rain Removal</font>
    </a>
  </h2>
  <font color="black">このメカニズムは、勾配フローを上位のステージに渡す新しい情報リンクでDSENを再利用します。さらに、蓄積された雨の筋を粗から細まで除去する自己精製メカニズムを設計します。雨の除去は、雨の画像の雨の筋を削除します。 
[ABSTRACT]ソフトウェアを使用して、雨の画像から回転同変の特徴を抽出しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-11-06">
        <br><font color="black">2018-11-06</font>
      </time>
    </span>
</section>
<!-- paper0: Brain Tumor Survival Prediction using Radiomics Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/eess.IV/paper_5.html">
      <font color="black">Brain Tumor Survival Prediction using Radiomics Features</font>
    </a>
  </h2>
  <font color="black">さらに、予測の改善に貢献する最も重要な機能を特定します。最近、深層学習アプローチが脳腫瘍セグメンテーションに広く使用され、その後、予後診断に深い機能を使用しています。したがって、正確な生存予後は重要なステップです。治療計画。 
[要約]このホワイトペーパーでは、マルチクラス生存予測のための3段階のアプローチを提案します。次に、これらの2Dスライスから放射線の特徴を抽出します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: COVID-MobileXpert: On-Device COVID-19 Patient Triage and Follow-up using
  Chest X-rays -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/eess.IV/paper_6.html">
      <font color="black">COVID-MobileXpert: On-Device COVID-19 Patient Triage and Follow-up using
  Chest X-rays</font>
    </a>
  </h2>
  <font color="black">COVID-19のパンデミック時には、リソースの利用と臨床ワークフローを最適化するための、迅速で専用のポイントオブケアのCOVID-19患者配置技術が新たに必要になっています。クラウドおよびモバイルベースのモデルのソースコードが利用可能です次のURLから：https://github.com/xinli0928/COVID-Xray ..このニーズに鑑みて、胸部X線を使用できる軽量のディープニューラルネットワーク（DNN）ベースのモバイルアプリCOVID-MobileXpertを提示します。 （CXR）COVID-19症例スクリーニングおよび放射線軌跡予測。 
[ABSTRACT] covid-mobilexpertは、軽量のディープニューラルネットワーク（dnn）ベースのモバイルアプリです。胸部x線（cxr）を使用して、covid-19ケーススクリーニングと放射線軌跡予測を行うことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: Towards non-parametric fiber-specific $T_1$ relaxometry in the human
  brain -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/eess.IV/paper_7.html">
      <font color="black">Towards non-parametric fiber-specific $T_1$ relaxometry in the human
  brain</font>
    </a>
  </h2>
  <font color="black">結果：$ \ mathcal {P}（\ mathbf {D}、R_1）$の統計記述子に対応するパラメーターマップが取得され、脳組織のタイプ間で予想される$ R_1 $コントラストが示されました。方向分布関数（ODF）の$ \ mathcal {P}（\ mathbf {D}、R_1）$の非常に異方性の高い成分は、方向固有の拡散緩和特性を視覚化するために定義されました。方法：拡散-$ T_1 $相関実験がテンソル値拡散エンコーディングと複数の繰り返し時間を使用した生体内の人間の脳。 
[要約]取得したデータは、モンテカルロ反転アルゴリズムを使用して反転されました。それは、脳の非パラメトリック金融プロパティを取得します。実験は、繊維固有の機能を定量化するために実行されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-14">
        <br><font color="black">2020-06-14</font>
      </time>
    </span>
</section>
<!-- paper0: Towards learned optimal q-space sampling in diffusion MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/eess.IV/paper_8.html">
      <font color="black">Towards learned optimal q-space sampling in diffusion MRI</font>
    </a>
  </h2>
  <font color="black">以前の結果に触発されて、現在の作業は、上記の戦略を統合された推定フレームワークに統合します。この推定フレームワークでは、推定モデルとサンプリング設計の両方に関して最適化が実行されます。 2つの主要な戦略..一方、サンプリングスキームに対する最適化も効果的であることが証明されています。 
[ABSTRACT]ファイバートラクトグラフィーは、相対磁気共鳴画像（dmri）を利用しています。これにより、異なる空間方向に沿った脳水の見かけの拡散率を測定できます。この問題は、2つの主要な戦略を使用して解決されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Information: to Harvest, to Have and to Hold -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/eess.IV/paper_9.html">
      <font color="black">Information: to Harvest, to Have and to Hold</font>
    </a>
  </h2>
  <font color="black">それらの定式化はその後、文字通り電子顕微鏡の実際の科学にコピーされました。そこでは、それらの先験的な仮定により、Cryo-EMのほとんどの品質メトリクスが歪められています。これらの初期の誤解は、独立して得られた結果の客観的な比較を妨げています。しかし、BershadとRockmore 
[1974]は、現実空間とフーリエ空間での矛盾したアプリオリな仮定に基づいて式を作成しました。 
[ABSTRACT] cryo-snrは、ウイルスやコロナウイルスのスパイクなどの生物学的複合体の構造を明らかにするために使用され、現在のcovid-19のパンデミック時に極めて重要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Deepfake detection: humans vs. machines -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/eess.IV/paper_10.html">
      <font color="black">Deepfake detection: humans vs. machines</font>
    </a>
  </h2>
  <font color="black">評価には、KaggleのDeepfake Detection Challenge 2020で提供されたFacebookのディープフェイクデータベースから手動で事前選択された120の異なるビデオ（60のディープフェイクと60のオリジナル）を使用しました。各ビデオについて、簡単な質問：「偽の本物のビデオの人？」具体的には、アルゴリズムはこれらのディープフェイクビデオを検出するのに苦労しています。 
[ABSTRACT]「長期調査」では、動画が本物であるかどうかを人間が確認するのがどれほど難しいかを分析します。各動画について、簡単な質問：「動画内の人物の顔は本物の偽物ですか？」と結果を比較しました2つの異なる最先端のディープフェイク検出方法のパフォーマンス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Introduction to Medical Image Registration with DeepReg, Between Old and
  New -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/eess.IV/paper_11.html">
      <font color="black">Introduction to Medical Image Registration with DeepReg, Between Old and
  New</font>
    </a>
  </h2>
  <font color="black">最適化を使用した2つの反復的な古典的なアルゴリズムとディープラーニングを使用した1つの学習ベースのアルゴリズムは、DeepRegユーティリティを使用して段階的にコード化され、すべて実際のオープンアクセス可能な医療データを使用します。オープンソースパッケージのDeepRegを使用した登録。医用画像登録の基本的な概念について説明し、ディープラーニングを使用して従来の方法と新しい方法を関連付けます。 
[ABSTRACT]医用画像登録の基本概念について説明します。実際のアイデアには、ディープラーニングを使用した簡単な学習ツールが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-29">
        <br><font color="black">2020-08-29</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: 3D Room Layout Estimation Beyond the Manhattan World Assumption -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_0.html">
      <font color="black">3D Room Layout Estimation Beyond the Manhattan World Assumption</font>
    </a>
  </h2>
  <font color="black">単一の画像から3D部屋のレイアウトを予測することは、多くのアプリケーションで困難な作業です。私たちの方法は、2020年の3Dビジョンワークショップのホリスティックシーン構造で3位を獲得しました。実験結果は、この方法が最先端のアプローチよりも優れていることを示しています。目に見える部屋のレイアウトを予測する際の大きなマージン。 
[要約]このペーパーでは、3Dの部屋のレイアウトを推定するための新しいトレーニングと後処理の方法を提案します。この方法は、2020年に3位になりました-3Dビジョンワークショップの全体的なシーン構造</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Semantic Estimation of 3D Body Shape and Pose using Minimal Cameras -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_1.html">
      <font color="black">Semantic Estimation of 3D Body Shape and Pose using Minimal Cameras</font>
    </a>
  </h2>
  <font color="black">推論は、広範囲の主題とアクションのビューアブレーションされたマルチビュービデオ映像のデータセットを介して事前に学習されて正則化され、これを表示して、目に見えない主題とアクション全体で一般化します。 2つのMVVパフォーマンスキャプチャデータセット（Human 3.6MとTotalCapture）での以前の作業に関連する推定誤差。3D関節式ポーズとヒューマンパフォーマンスの高忠実度体積占有率を、わずか2つの多視点ビデオ（MVV）から同時に推定することを目的としています。ビュー。 
[ABSTRACT]私たちは、デュアルロスのあるマルチチャネル3Dたたみ込みエンコーダーを使用して、潜在的な埋め込みの学習を強制します。2つの人間のパフォーマンスキャプチャデータセットの事前の作業：人間3. 6mとtotalcapture</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-08">
        <br><font color="black">2019-08-08</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Contouring for Breast Tumor in Sonography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_2.html">
      <font color="black">3D Contouring for Breast Tumor in Sonography</font>
    </a>
  </h2>
  <font color="black">提案された方法は、効率的なセグメンテーション手順を利用します。自動輪郭が正確な乳房腫瘍の輪郭を提供し、医師が正確な診断を行うのに役立つ場合。この研究では、3Dソノグラフィーで乳房腫瘍を自動的に輪郭付けるための効率的な方法を紹介します。 
[ABSTRACT]腫瘍の輪郭は時間のかかる複雑なタスクです。提案された3Dセグメンテーション方法は、堅牢な輪郭を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-01-27">
        <br><font color="black">2019-01-27</font>
      </time>
    </span>
</section>
<!-- paper0: Localization and classification of intracranialhemorrhages in CT data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_3.html">
      <font color="black">Localization and classification of intracranialhemorrhages in CT data</font>
    </a>
  </h2>
  <font color="black">公に入手可能な頭部CTデータセットCQ500からのデータで、平均53.7％のJaccard係数が達成されます。このホワイトペーパーでは、ローカリゼーションを含むICHの検出と分類のための自動アルゴリズムが存在します。この自動システムは、急性の場合の診断プロセスの期間の明確な減少。 
[要約] ichsの検出と分類のための自動アルゴリズムが存在します。システムは、急性の場合にシステムの期間の減少につながる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Dictionary Learning for Anomaly Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_4.html">
      <font color="black">Unsupervised Dictionary Learning for Anomaly Detection</font>
    </a>
  </h2>
  <font color="black">また、サンプルの性質を示すものとして学習アルゴリズムのパフォーマンスを使用する、新しい教師なし手法も紹介します。マネーロンダリング防止アプリケーションに関する最近の半教師付きオンラインアルゴリズムTODDLeRの新しい結果を示します。監視の欠如、オンライン定式化、低い偽陽性率など、ほとんどの異常検出アプリケーションの要件に対処するために辞書学習を使用する可能性を調査します。 
[ABSTRACT]アンチマネーロンダリングアプリケーションについて、最近のビザである幼児の新しい課題を提示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-29">
        <br><font color="black">2020-02-29</font>
      </time>
    </span>
</section>
<!-- paper0: The Maximum Entropy on the Mean Method for Image Deblurring -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_5.html">
      <font color="black">The Maximum Entropy on the Mean Method for Image Deblurring</font>
    </a>
  </h2>
  <font color="black">画像のぼかしは悪名高い挑戦的な悪条件の逆問題です。凸分析と確率理論からの手法を使用して、この方法が計算上実行可能であり、非常に大きなぼかしに適していることを示します。さらに、画像にシンボル（既知のパターンが埋め込まれている場合） ）、未知のブラーカーネルを顕著な効果で近似するために、この方法をどのように適用できるかを示します。 
[ABSTRACT]近年、画像のレベルでの正則化または機械学習に基づいて、さまざまなアプローチが提案されています。私たちの方法は、私たちが次のレベルで作業する平均の最大シンプソンという考え方に基づいています。予想がグラウンドトゥルースの推定である画像の確率密度関数。ただし、最新の方法で前処理されたノイズ除去を行うとうまく機能します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-24">
        <br><font color="black">2020-02-24</font>
      </time>
    </span>
</section>
<!-- paper0: DV-ConvNet: Fully Convolutional Deep Learning on Point Clouds with
  Dynamic Voxelization and 3D Group Convolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_6.html">
      <font color="black">DV-ConvNet: Fully Convolutional Deep Learning on Point Clouds with
  Dynamic Voxelization and 3D Group Convolution</font>
    </a>
  </h2>
  <font color="black">この作業では、効率的な3D点群の解釈に向けて、標準の3D畳み込みに注意を向けます。点群全体を他のボリュメトリック手法のようにボクセル表現に変換する代わりに、点群のサブ部分をボクセル化します。自己適応型ボクセル化解像度を使用した動的ボクセル化操作を使用して、各コンボリューションレイヤー内の必要な場所をオンザフライで実行します。さらに、3Dグループコンボリューションを高密度コンボリューションカーネル実装に組み込んで、点群の回転不変機能をさらに活用します。 
[ABSTRACT]最近提案された方法の多くは、通常、複雑なネットワークアーキテクチャを伴う、ポイント単位の入力特徴としてポイント座標から形状記述を学習することに焦点を合わせてきました。その単純な完全たたみ込みアーキテクチャに加えて、ネットワークは実行可能で、かなり速い速度で収束し、同等またはそれ以上のパフォーマンスを実現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Variational State-Space Models for Localisation and Dense 3D Mapping in
  6 DoF -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_7.html">
      <font color="black">Variational State-Space Models for Localisation and Dense 3D Mapping in
  6 DoF</font>
    </a>
  </h2>
  <font color="black">最先端の視覚慣性オドメトリシステムのパフォーマンスに近い、現実的な無人航空機の飛行データに対するアプローチを評価します。生成された予測や計画などの下流タスクへの学習モデルの適用性が調査されます。推論により、システム識別にニューラルネットワークを使用できます。一方、放出モデルには微分可能なレイキャスターが使用されます。 
[ABSTRACT]これは、不確実性と確率論の原理的な扱いです。これにより、現在の状態（最先端のソリューション）の欠点が克服されます。これにより、モデルの最終的な最適化が可能になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br><font color="black">2020-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: Dataset Bias in Few-shot Image Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_8.html">
      <font color="black">Dataset Bias in Few-shot Image Recognition</font>
    </a>
  </h2>
  <font color="black">これらの観察が将来のFSIR研究の指針として役立つことを願っています。基本カテゴリの分布は、インスタンス密度とカテゴリの多様性によって示されます。このホワイトペーパーでは、まず、基本カテゴリから学習した転送可能な機能の影響を調査します。 
[ABSTRACT]ほとんどの現在の研究では、伝達可能な知識が新しいカテゴリを特定するためにうまく使用できると想定しています。しかし、ほとんどの少数ショット学習方法は、異なるデータセットに偏っています。これもまた、深く調査する必要がある重要な問題です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-18">
        <br><font color="black">2020-08-18</font>
      </time>
    </span>
</section>
<!-- paper0: Light Field View Synthesis via Aperture Flow and Propagation Confidence
  Map -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_9.html">
      <font color="black">Light Field View Synthesis via Aperture Flow and Propagation Confidence
  Map</font>
    </a>
  </h2>
  <font color="black">これは自由空間レンダリングに関連し、オブジェクトの境界付近で失敗する可能性がありますが、これらの困難な領域のピクセルオクルージョンに対処するための伝播信頼マップをさらに開発します。これは、いくつかの最先端の技術に対して優れたパフォーマンスを示します。まず、視差を近似し、2つのビュー間のピクセル単位のシフトを測定するアパーチャフローマップを定義して計算します。 
[要約]提案された方法は、ライトフィールドイメージのさまざまな領域で評価されます。いくつかの最先端の技術に対して優れたパフォーマンスを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Channel-wise Alignment for Adaptive Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_10.html">
      <font color="black">Channel-wise Alignment for Adaptive Object Detection</font>
    </a>
  </h2>
  <font color="black">広範な実験は、提案された方法が既存の方法よりも著しく優れており、さまざまなドメインシフト設定で約5％改善されていることを示しています。インスタンスのセグメンテーション）も、その優れたスケーラビリティを示しています。各チャネルが特定のパターン（例： 、車などの特殊な意味領域では、ソースドメインとターゲットドメインの分布をチャネルレベルで揃えることを目的としています。これは、矛盾するドメイン間の統合に適しています。 
[要約]私たちの方法は、主に自己チャネル型とクロスチャネル型の整列で構成されています。これらのタイプは、さまざまなタイプのさまざまなタイプと整列することを目的としています。これは、暗黙的に天候の変化が原因であり、これによりエリアギャップが発生します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: A Review on Near Duplicate Detection of Images using Computer Vision
  Techniques -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_11.html">
      <font color="black">A Review on Near Duplicate Detection of Images using Computer Vision
  Techniques</font>
    </a>
  </h2>
  <font color="black">今日、デジタルコンテンツは、合法的または違法に広く普及しており、単純に再配布可能です。コンピュータービジョンの主な用途は、画像の理解です。重複に近いものの存在は、検索エンジンのパフォーマンスに重大な影響を与えます。 
[ABSTRACT]コンピュータビジョンは、デジタル画像からの有用な情報の自動抽出、分析、理解に関係しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Frontier Detection and Reachability Analysis for Efficient 2D Graph-SLAM
  Based Active Exploration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_12.html">
      <font color="black">Frontier Detection and Reachability Analysis for Efficient 2D Graph-SLAM
  Based Active Exploration</font>
    </a>
  </h2>
  <font color="black">また、フロンティアとそのクラスタの到達可能性の分析を行い、検出されたフロンティアにロボットが到達できることを確認します。この手法は、実際の室内シーンでモバイルロボットでテストされ、アプローチの有効性と効率を示しています。地図作成法をサブマップ作成の基本SLAMモジュールとして活用し、グラフ最適化によって幾何学的に整列したサブマップで効率的なフロンティア検出を実行することにより、アクティブな探索への統合アプローチを提案します。 
[ABSTRACT]また、検出されたフロンティアにロボットが到達できることを確認するために分析を実行します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Improving colonoscopy lesion classification using semi-supervised deep
  learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_13.html">
      <font color="black">Improving colonoscopy lesion classification using semi-supervised deep
  learning</font>
    </a>
  </h2>
  <font color="black">ここでは、教師なしのジグソー学習タスクを教師付きトレーニングと組み合わせると、完全に監視されたベースラインと比較して、結腸鏡検査画像の病変を正しく分類する際に最大9.8％改善することを示します。大腸内視鏡アプリケーションでは、これらの測定基準が重要です。病変の内視鏡評価に必要なスキル、使用中のさまざまな内視鏡検査システム、およびラベル付きデータセットに典型的な均一性を考えると、データ駆動型アプローチは多くの画像分析タスクに優れていますが、これらのアプローチのパフォーマンスはしばしば制限されますトレーニングに利用できる注釈付きデータの不足による。 
[ABSTRACT]これらの表現は、教師付きタスクのパフォーマンスを向上させることができます。彼らは、半教師付き学習が教師付き学習よりも優れていることを示しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Are L2 adversarial examples intrinsically different? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_14.html">
      <font color="black">Are L2 adversarial examples intrinsically different?</font>
    </a>
  </h2>
  <font color="black">したがって、少なくとも$ L_2 $の敵対的な例は、理論的にも経験的にも通常の入力と本質的に十分に異なることが確認されています。MNISTでは最大99 \％、CIFAR-10では89 \％、87では分類精度が回復しました。 \ L_2 $攻撃に対するImageNetサブセットの\％..さらに、ホワイトボックス設定では、全体的な防御モジュールが有望な程度の堅牢性を示します。 
[ABSTRACT]これらの例は、$ lによって生成されます。 2 $攻撃は、通常、入力感度が高く、効率的に識別することができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-28">
        <br><font color="black">2020-02-28</font>
      </time>
    </span>
</section>
<!-- paper0: Scale Calibrated Training: Improving Generalization of Deep Networks via
  Scale-Specific Normalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_15.html">
      <font color="black">Scale Calibrated Training: Improving Generalization of Deep Networks via
  Scale-Specific Normalization</font>
    </a>
  </h2>
  <font color="black">したがって、Scale-Specific Batch Normalizationと呼ばれる新しい正規化スキームがバッチ正規化の代わりにSCTに装備されています。私たちの分析では、驚くべきことに、バニラバッチ正規化がSCTで最適以下のパフォーマンスにつながることがわかりました。標準の畳み込みニューラルネットワーク（ CNN）は、トレーニング段階とテスト段階の両方で一貫した画像解像度を必要とします。 
[ABSTRACT]実際には、小さな画像でのテストが迅速な結論に必要です。スケールキャリブレーショントレーニング（sct）と呼ばれる新しいトレーニング方法を提案します。これにより、ネットワークは入力の異なるスケールから同時に学習できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-31">
        <br><font color="black">2019-08-31</font>
      </time>
    </span>
</section>
<!-- paper0: User-assisted Video Reflection Removal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_16.html">
      <font color="black">User-assisted Video Reflection Removal</font>
    </a>
  </h2>
  <font color="black">空間情報と時間情報の両方に依存し、疎なユーザーヒントを利用して分離を改善します。ビデオでの反射は、ビデオがガラスなどの反射面の背後で撮影されるときによく発生する障害です。提案された方法を定量的および定性的な結果で実装および評価します実際のビデオと合成ビデオ。 
[ABSTRACT]これらの反射は、そのようなビデオの品質を低下させ、情報の損失につながり、多くのコンピュータビジョンアルゴリズムの精度を低下させます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Are Deep Neural Architectures Losing Information? Invertibility Is
  Indispensable -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_17.html">
      <font color="black">Are Deep Neural Architectures Losing Information? Invertibility Is
  Indispensable</font>
    </a>
  </h2>
  <font color="black">私たちの仕事は、将来のディープラーニング研究に独自の視点と方向性を提供すると信じています。AlexNetの出現以来、さまざまなタスクのための新しいディープニューラルアーキテクチャの設計は、一貫して生産的な研究方向でした。相互情報の定義を使用して、つまり、ディープニューラルアーキテクチャは、アーキテクチャが反転可能な場合にのみ、特定のデータに関する最大の詳細を保持できます。 
[ABSTRACT]入力データのすべての情報を保存するためのディープニューラルアーキテクチャの条件。これらのアーキテクチャには、アーキテクチャが不可逆である場合にのみ、特定のデータの詳細が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: A Light-Weight Object Detection Framework with FPA Module for Optical
  Remote Sensing Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_18.html">
      <font color="black">A Light-Weight Object Detection Framework with FPA Module for Optical
  Remote Sensing Imagery</font>
    </a>
  </h2>
  <font color="black">精度を向上させるために、FPAモジュールを設計しました。これは、さまざまなレベルの機能マップをリンクし、機能マップの各レベルの重みを動的に調整するアテンションメカニズムを導入します。リモートセンシングオブジェクト..このホワイトペーパーでは、効率的なアンカーフリーオブジェクト検出器CenterFPANetを提案します。 
[ABSTRACT]新しい戦略では、検出速度を落とさずに画像のキャプチャ速度を調整できます。このツールは、画像オブジェクトリソースのキャプチャ精度を向上できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Benchmarking off-the-shelf statistical shape modeling tools in clinical
  applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_19.html">
      <font color="black">Benchmarking off-the-shelf statistical shape modeling tools in clinical
  applications</font>
    </a>
  </h2>
  <font color="black">統計的形状モデリング（SSM）は、解剖学形状の定量分析のための形態計測アプローチの新世代として、生物学および医学で広く使用されています。また、学習された人口レベルに関して微妙な異常形状変化を客観的に特徴付ける病変スクリーニング法を提示します。コントロールの統計。さまざまなツールから形状モデルを評価するために、定量的および定性的なメトリックの両方を使用します。 
[ABSTRACT]新しいツールは、解剖学的形状のモデルとその母集団レベルの変動を自動化します。これらには、shapeworks、deformetrica、およびspharm-pdmが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Revisiting the Modifiable Areal Unit Problem in Deep Traffic Prediction
  with Visual Analytics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_20.html">
      <font color="black">Revisiting the Modifiable Areal Unit Problem in Deep Traffic Prediction
  with Visual Analytics</font>
    </a>
  </h2>
  <font color="black">ドメインエキスパートとの定期的な交換を通じて、1）空間全体の入力トラフィックと予測エラーを同時に表現する高度な2変量カラーマップを備えた2変量マップ、2）ローカルインジケーターを提供するMorans I散布図を統合する視覚分析ソリューションを設計および開発します空間相関分析の例、および3）非線形ドットプロットをツリーレイアウトに配置して、モデル分析とスケール間の比較を促進するマルチスケールアトリビューションビュー。時空間交通データが存在する都市交通予測には、深層学習法がますます使用されています。は、順次編成された行列に集約され、畳み込みベースの残余ニューラルネットワークに送られます。私たちは、深センのタクシー旅行の実際のデータセットを含む一連のケーススタディと、ドメインの専門家へのインタビューを通じて、アプローチを評価します。 
[ABSTRACT]問題はネットワーク入力の摂動につながる可能性があります。これは問題の中心に摂動をもたらす可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-30">
        <br><font color="black">2020-07-30</font>
      </time>
    </span>
</section>
<!-- paper0: Stochastic-YOLO: Efficient Probabilistic Object Detection under Dataset
  Shifts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_21.html">
      <font color="black">Stochastic-YOLO: Efficient Probabilistic Object Detection under Dataset
  Shifts</font>
    </a>
  </h2>
  <font color="black">たとえば、ラベルの不確実性の品質を評価する必要があります（つまり、何ですか？）。特定のバウンディングボックスに対して、その評価は従来の平均精度メトリック（たとえば、mAP）では実行できません。この新しいアーキテクチャをStochastic-YOLOと呼び、MC-Dropサンプリングの負担を効果的に軽減するための効率的な実装を提供します推論時のメカニズム。 
[要約]このホワイトペーパーでは、yolov3アーキテクチャを適用して不確実性推定を生成します。これらには、モンテカルロドロップアウト（mc-drop）の形式の確率が含まれ、データセットシフトのさまざまなレベルで評価します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Progressive Bilateral-Context Driven Model for Post-Processing Person
  Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_22.html">
      <font color="black">Progressive Bilateral-Context Driven Model for Post-Processing Person
  Re-Identification</font>
    </a>
  </h2>
  <font color="black">ポイントツーポイント比較を双方向のポイントツーセット比較に変換します。4つの大規模な個人再識別ベンチマークデータセットでの実験は、（1）提案された方法が一貫してより高い精度を達成できることを示しています。最先端の結果を示すコンテンツベースの個人再識別メソッドの後の後処理手順、（2）提案された軽量メソッドは、1つのサンプルのランキング結果を最適化するために約6ミリ秒しか必要とせず、その高い-efficiency ..コードはhttps://github.com/123ci/PBCmodelで入手できます。 
[ABSTRACT]データは、監視されていない方法でのサンプルとカウンターパートのコンテキスト間の関係に基づいています。サンプルのコンテキストは、2つの異なる定義方法を持つ隣接サンプルで構成されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Quantifying Explainability of Saliency Methods in Deep Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_23.html">
      <font color="black">Quantifying Explainability of Saliency Methods in Deep Neural Networks</font>
    </a>
  </h2>
  <font color="black">比較と推奨が行われ、選択された事後分析方法の詳細を処理するための将来の研究方向の提案とともに欠点が明らかにされます。特に、ヒートマップを生成する方法は、ディープなどのブラックボックスモデルを説明するために使用されていますニューラルネットワーク..このホワイトペーパーでは、アドホックで生成できる合成データと、グラウンドトゥルースヒートマップを導入して、定量的評価を向上させます。 
[要約]ヒートマップを生成する方法は、ディープニューラルネットワークなどのブラックボックスモデルを説明するために使用されています。ただし、ヒートマップの可能性を示す定量分析は欠けており、異なる方法の比較は標準化されていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: A novel action recognition system for smart monitoring of elderly people
  using Action Pattern Image and Series CNN with transfer learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_24.html">
      <font color="black">A novel action recognition system for smart monitoring of elderly people
  using Action Pattern Image and Series CNN with transfer learning</font>
    </a>
  </h2>
  <font color="black">一般に、ビデオの背景はアクションの識別に何も貢献せず、実際にはアクション分類を誤解させます。したがって、私たちは新しいアクション認識システムを提案し、私たちの貢献は1）影響を受けないより一般的なアクションパターンを生成することです。ビデオシーケンスの照明と背景の変化によって、CNNトレーニングでの画像増強の義務を排除します。2）SCNNアーキテクチャを設計し、特徴抽出プロセスを強化して大量のデータを学習します。3）ニューロンの学習したパターンを提示します。層を形成し、入力パターンがこれらのニューロンを通過するときにこれらのニューロンがどのようにアクションをキャプチャするかを分析し、4）転移学習を使用して、訓練されたSCNNが転倒アクションを認識する能力を拡張します。健康リスクへ。 
[ABSTRACT] cnnが動画のフレームによって直接トレーニングされると、背景ピクセルを含むすべてのネットワークから学習します。したがって、新しいアクション認識システムを提案し、照明の影響を受けないより一般的なアクションパターンを作成することに貢献しています。ビデオシーケンスの背景のバリエーション。画像拡張の義務を排除するアクションシステムを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Interpretable Deep Multimodal Image Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_25.html">
      <font color="black">Interpretable Deep Multimodal Image Super-Resolution</font>
    </a>
  </h2>
  <font color="black">実験結果は、私たちのモデルが最先端の方法よりも優れていることを示しています。この方法は、結合畳み込みスパースコーディングの新しい反復アルゴリズムに着想を得ており、設計により解釈可能なネットワークをもたらします。マルチモーダル画像超解像（SR）は別の画像モダリティの助けを借りて低解像度の観察を与えられた高解像度画像の再構成。 
[ABSTRACT]モデルはマルチモーダルディープネットワークデザインに基づいています。疎な事前分布を統合し、別のモダリティからの情報を再構成プロセスに効果的に融合できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: COVID-MobileXpert: On-Device COVID-19 Patient Triage and Follow-up using
  Chest X-rays -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_26.html">
      <font color="black">COVID-MobileXpert: On-Device COVID-19 Patient Triage and Follow-up using
  Chest X-rays</font>
    </a>
  </h2>
  <font color="black">私たちは、大規模な肺疾患のCXR画像、細かく調整された居住者の仲間からCXRイメージング機能を抽出する事前トレーニング済みの主治医（AP）ネットワークを含む、新しい3プレーヤー知識転送および蒸留（KTD）フレームワークを設計および実装します（ RF）COVID-19を肺炎や少量のCOVID-19ケースを伴う通常のケースから区別するために不可欠なCXRイメージング機能を学習するネットワーク、およびデバイス上でCOVID-19を実行するためのトレーニング済みの軽量医学生（MS）ネットワーク患者のトリアージとフォローアップ。さまざまなMSアーキテクチャとチューニングパラメータ設定を使用した大規模な実験により、COVID-MobileXpertを迅速に展開できる大きな可能性を示しています。クラウドおよびモバイルベースのモデルのソースコードは、次のURLから入手できます：https ：//github.com/xinli0928/COVID-Xray。 
[ABSTRACT] covid-mobilexpertは、軽量のディープニューラルネットワーク（dnn）ベースのモバイルアプリです。胸部x線（cxr）を使用して、covid-19ケーススクリーニングと放射線軌跡予測を行うことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: Integrating Egocentric Localization for More Realistic Point-Goal
  Navigation Agents -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_27.html">
      <font color="black">Integrating Egocentric Localization for More Realistic Point-Goal
  Navigation Agents</font>
    </a>
  </h2>
  <font color="black">これらのエージェントは、この設定に対する従来のローカリゼーションベースラインを組み込んだものと同様に、現在のポイントゴールエージェントの素朴な適応よりも優れていることがわかります。この設定は、ノイズの多いセンサーや現実世界の作動の汚い現実と比較すると、実際には無菌です。車輪が滑ったり、モーションセンサーにエラーが発生したり、作動が跳ね返ったりする可能性があります。 
[ABSTRACT]これらのエージェントには、ローカリゼーション用のセンサーが表示され、確定的なアクションを実行します。これにより、実際のオドメトリモデルを再調整するだけで、変化するダイナミクスにシームレスに適応でき、ナビゲーションポリシーの再トレーニングにかかる費用を回避できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Real-Time Segmentation of Non-Rigid Surgical Tools based on Deep
  Learning and Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_28.html">
      <font color="black">Real-Time Segmentation of Non-Rigid Surgical Tools based on Deep
  Learning and Tracking</font>
    </a>
  </h2>
  <font color="black">リアルタイムのツールセグメンテーションは、コンピューター支援手術システムに不可欠なコンポーネントです。さらに、事前トレーニング済みのFCNは、機能を手動で作成する必要なく、少量の医用画像で微調整できます。ディープニューラルネットワークが、オプティカルフローの高速とともに、非常に変形しやすいパーツの正確なセグメンテーションを生成する能力。 
[ABSTRACT]リアルタイム自動メソッドは、完全畳み込みネットワーク（fcn）とオプティカルフロートラッキングに基づいています。このメソッドは、ディープラーニングとオプティカルスピードトラッキングを組み合わせたものです。検証済みのすべてのデータセットで平均78.2％のバランスの取れた平均精度が得られます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Towards learned optimal q-space sampling in diffusion MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_29.html">
      <font color="black">Towards learned optimal q-space sampling in diffusion MRI</font>
    </a>
  </h2>
  <font color="black">以前の結果に触発されて、現在の作業は、上記の戦略を統合された推定フレームワークに統合します。この推定フレームワークでは、推定モデルとサンプリング設計の両方に関して最適化が実行されます{\ it it}。ファイバートラクトグラフィは、計算の重要なツールです。脳の白質の空間的接続性と組織の再構築を可能にする神経科学。https：//github.com/tomer196/Learned_dMRIで入手可能なコードおよび学習したサンプリング設計。 
[ABSTRACT]ファイバートラクトグラフィーは、相対磁気共鳴画像（dmri）を利用しています。これにより、異なる空間方向に沿った脳水の見かけの拡散率を測定できます。この問題は、2つの主要な戦略を使用して解決されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Stem-leaf segmentation and phenotypic trait extraction of maize shoots
  from three-dimensional point cloud -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_30.html">
      <font color="black">Stem-leaf segmentation and phenotypic trait extraction of maize shoots
  from three-dimensional point cloud</font>
    </a>
  </h2>
  <font color="black">セグメンテーションアルゴリズムの平均精度、平均再現率、平均マイクロF1スコア、および平均精度は、0.964、0.966、0.963、および0.969でした。セグメンテーション結果を使用して、表現型の特徴抽出とスケルトン最適化を含む2つのアプリケーションもこの論文で開発されました..植物の高さ、樹冠の直径、茎の高さと直径、葉の幅と長さなど、6つの表現型パラメーターを正確かつ自動的に測定できます。 
[要約]主な茎-葉の分割方法を30枚のトウモロコシの苗でテストしました。手動で取得したグラウンドトゥルースと比較しました。主な方法は、新しい技術の開発に使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Weingarten Map and Curvature Estimation on Manifolds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_31.html">
      <font color="black">Efficient Weingarten Map and Curvature Estimation on Manifolds</font>
    </a>
  </h2>
  <font color="black">特に、サンプルサイズが無限大になる傾向がある場合の収束率を示します。この論文では、ユークリッド空間に埋め込まれた多様体からサンプリングされた点群データのWeingartenマップを推定する効率的な方法を提案します。統計モデルは、推定器の漸近特性を分析します。 
[概要] weingartenマップを分析するシステムが確立されています。このシステムは、weingartenポイントを推定するために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-26">
        <br><font color="black">2019-05-26</font>
      </time>
    </span>
</section>
<!-- paper0: Improved Modeling of 3D Shapes with Multi-view Depth Maps -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_32.html">
      <font color="black">Improved Modeling of 3D Shapes with Multi-view Depth Maps</font>
    </a>
  </h2>
  <font color="black">新しいアイデンティティエンコーダーとクラス条件付き視点ジェネレーターで構成されるシンプルなエンコーダー/デコーダーフレームワークは、3Dの一貫した深度マップを生成します。1つ目は、2D画像領域で適切に機能するアーキテクチャーを3Dに直接借りることです。2つ目は、少ない計算メモリで高解像度の3D形状を効果的に生成します。 
[ABSTRACT]シンプルな3Dモデルを使用して3Dシェイプを作成できます。1つのポイントだけを使用して、3Dオブジェクトの密なマルチビュービュー深度マップ表現を生成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Implicit Multidimensional Projection of Local Subspaces -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_33.html">
      <font color="black">Implicit Multidimensional Projection of Local Subspaces</font>
    </a>
  </h2>
  <font color="black">既存の方法は多次元データポイントの投影に焦点を当てており、近傍情報は無視されます。ローカルサブスペースは、基底ベクトルがまたがる多次元楕円によってフィットされます。結果は、グリフとして視覚化され、特別に設計されたフルセットを使用して分析されます効率的なWebベースの視覚化ツールでサポートされる相互作用。 
[ABSTRACT]私たちの方法の有用性は、さまざまな複数の高品質のベンチマークデータセットを使用して示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Deepfake detection: humans vs. machines -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_34.html">
      <font color="black">Deepfake detection: humans vs. machines</font>
    </a>
  </h2>
  <font color="black">各動画について、簡単な質問：「動画内の人物の顔は本物ですか？」ただし、平均的な人にとってのディープフェイク動画のリアルさや、アルゴリズムが人間よりもはるかに優れているかどうかはまだはっきりしていません。具体的には、アルゴリズムは、ディープフェイク動画を検出するのに苦労しています。 
[ABSTRACT]「長期調査」では、動画が本物であるかどうかを人間が確認するのがどれほど難しいかを分析します。各動画について、簡単な質問：「動画内の人物の顔は本物の偽物ですか？」と結果を比較しました2つの異なる最先端のディープフェイク検出方法のパフォーマンス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Object Detection for Graphical User Interface: Old Fashioned or Deep
  Learning or a Combination? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_35.html">
      <font color="black">Object Detection for Graphical User Interface: Old Fashioned or Deep
  Learning or a Combination?</font>
    </a>
  </h2>
  <font color="black">私たちは、50k以上のGUI画像に対して7つの代表的なGUI要素検出方法の最初の大規模な実証研究を実施して、これらの方法の機能、制限、および効果的な設計を理解します。それに応じて、非GUI向けの新しいGUI固有の古い方法を設計します。テキストGUI要素の検出。これは、新規のトップダウンの粗雑な手法を採用し、それをGUIテキスト検出用の成熟したディープラーニングモデルに組み込んだものです。25,000のGUI画像に対する私たちの評価は、私たちの方法が-GUI要素検出におけるアートパフォーマンス。この研究は、対処すべき技術的課題に光を当てるだけでなく、新しいGUI要素検出方法の設計にも影響を与えます。 
[要約]新しいgui要素検出モデルは、guiとgui要素を検出する機能を使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Semantic Segmentation of Urban-Scale 3D Point Clouds: A Dataset,
  Benchmarks and Challenges -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_36.html">
      <font color="black">Towards Semantic Segmentation of Urban-Scale 3D Point Clouds: A Dataset,
  Benchmarks and Challenges</font>
    </a>
  </h2>
  <font color="black">特に、都市規模のポイントクラウドの理解に向けたいくつかの重要な課題を特定します。3Dシーンの理解の分野での教師ありディープラーニングアルゴリズムの可能性を解き放つための重要な前提条件は、大規模で豊富な注釈付きのデータセットの可用性です。データセットでは、各3Dポイントは13のセマンティッククラスの1つとしてラベル付けされています。 
[ABSTRACT]一般に利用可能なデータセットは、比較的小さな空間スケールであるか、セマンティックアノテーションが制限されています。データ取得とデータアノテーションのコストにより、3D点群のコンテキストでの細かいセマンティック理解の開発が大幅に制限されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Introduction to Medical Image Registration with DeepReg, Between Old and
  New -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_37.html">
      <font color="black">Introduction to Medical Image Registration with DeepReg, Between Old and
  New</font>
    </a>
  </h2>
  <font color="black">最適化を使用した2つの反復的な古典的なアルゴリズムとディープラーニングを使用した1つの学習ベースのアルゴリズムは、DeepRegユーティリティを使用して段階的にコード化され、すべて実際のオープンアクセス可能な医療データを使用します。オープンソースパッケージのDeepRegを使用した登録。医用画像登録の基本的な概念について説明し、ディープラーニングを使用して従来の方法と新しい方法を関連付けます。 
[ABSTRACT]医用画像登録の基本概念について説明します。実際のアイデアには、ディープラーニングを使用した簡単な学習ツールが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-29">
        <br><font color="black">2020-08-29</font>
      </time>
    </span>
</section>
<!-- paper0: Uncertainty Inspired RGB-D Saliency Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CV/paper_38.html">
      <font color="black">Uncertainty Inspired RGB-D Saliency Detection</font>
    </a>
  </h2>
  <font color="black">私たちのフレームワークには、1）入力画像と潜在変数を確率的顕著性予測にマッピングするジェネレーターモデル、および2）真または近似事後分布から潜在変数をサンプリングすることにより潜在変数を徐々に更新する推論モデルの2つの主要モデルが含まれます。 。ジェネレーターモデルはエンコーダーデコーダー顕著性ネットワークです。データラベリングプロセスから学習することにより、RGB-D顕著性検出に不確実性を採用する最初の確率的フレームワークを提案します。 
[ABSTRACT]既存のrgb-d顕著性検出モデルは、決定論的学習パイプラインに従って単一の顕著性マップを予測することにより、このタスクを点推定問題として扱います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Measuring Massive Multitask Language Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CL/paper_0.html">
      <font color="black">Measuring Massive Multitask Language Understanding</font>
    </a>
  </h2>
  <font color="black">さらに悪いことに、道徳や法律などの社会的に重要な主題については、ほぼランダムな精度があります。このテストでは、初等数学、米国の歴史、コンピュータサイエンス、法律など57のタスクをカバーしています。このテストで高い精度を達成するには、モデルは、広範な世界の知識と問題解決能力を備えている必要があります。 
[ABSTRACT]テストは、初等数学、米国の歴史、コンピューターサイエンス、法律などを含む57のタスクをカバーしています。テストするには、テストを使用して、多くのタスクにわたってモデルを分析し、重要な欠点を特定できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: CS-Embed at SemEval-2020 Task 9: The effectiveness of code-switched word
  embeddings for sentiment analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CL/paper_1.html">
      <font color="black">CS-Embed at SemEval-2020 Task 9: The effectiveness of code-switched word
  embeddings for sentiment analysis</font>
    </a>
  </h2>
  <font color="black">この作品では、コード切り替えされたツイートでトレーニングされた単語埋め込み、特にスペイン語と英語を使用する埋め込み、Spanglishを紹介します。埋め込みスペースを探索して、両方の言語の単語の意味をどのように捉えるかを調べます。 SemEval 2020タスク9：〜\ emph {コード混合ソーシャルメディアテキストの感情分析}に参加して、これらの埋め込みの有効性をテストします。 
[ABSTRACT]埋め込みはユーザーベースのデータについてトレーニングされていませんが、ユーザーが呼び出す埋め込みについてトレーニングされていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-08">
        <br><font color="black">2020-06-08</font>
      </time>
    </span>
</section>
<!-- paper0: COVCOR20 at WNUT-2020 Task 2: An Attempt to Combine Deep Learning and
  Expert rules -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CL/paper_2.html">
      <font color="black">COVCOR20 at WNUT-2020 Task 2: An Attempt to Combine Deep Learning and
  Expert rules</font>
    </a>
  </h2>
  <font color="black">このワークショップの後にアノテーションマニュアルとテストデータのゴールドラベルをリリースすると、これらの複雑な結果が明らかになることが予想されます。ただし、テストデータでは、統合のパフォーマンスは、最もパフォーマンスの高いディープラーニングモデルよりもわずかに低くなりました。これらの結果は、機械学習とエキスパートルール駆動型システムの統合の進展をほとんど示していません。 
[ABSTRACT]これら2つのシステムはどちらも、言語情報に基づいたルールを使用してシステムをアウトプレックスしました。ただし、相互検証設定では、各アプローチのスタンドアロンパフォーマンスよりも優れたパフォーマンスを達成できることがわかりました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Watermarking Transformer: Towards Tracing Text Provenance
  with Data Hiding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CL/paper_3.html">
      <font color="black">Adversarial Watermarking Transformer: Towards Tracing Text Provenance
  with Data Hiding</font>
    </a>
  </h2>
  <font color="black">AWTは、メッセージをエンコードするために、その場所とともに単語の置換を自動的に（グラウンドトゥルースなしで）学習することにより、テキスト内のデータを非表示にする最初のエンドツーエンドモデルです。このモデルは、テキストをほぼ保存するのに効果的であることを示しています。ユーティリティを使用して透かしをデコードし、その存在を敵から隠します。さらに、入力テキストのセマンティクスと正確さの変更を最小限に抑えるために、さまざまなトレーニングおよび推論戦略を研究します。 
[ABSTRACT]私たちは敵対的な透かしトランスフォーマー（awt）を紹介します。入力テキストとバイナリメッセージが与えられると、指定されたメッセージで目立たないようにエンコードされた出力テキストを生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: BiTT: Bidirectional Tree Tagging for Joint Extraction of Overlapping
  Entities and Relations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CL/paper_4.html">
      <font color="black">BiTT: Bidirectional Tree Tagging for Joint Extraction of Overlapping
  Entities and Relations</font>
    </a>
  </h2>
  <font color="black">フレームワークのエンコーダーとしてBi-LSTMとBERTをそれぞれ採用し、公の英語と中国語のデータセットで有望な結果を取得します。BiTTスキームに基づいて、BiTTを予測するエンドツーエンドの抽出フレームワークを開発しますタグを付け、さらにトリプルを効率的に抽出します。共同抽出とは、エンティティとリレーションで構成されるトリプルを、単一のモデルを使用してテキストから同時に抽出することです。 
[ABSTRACT] bittでは、文で同じリレーションカテゴリを持つトリプルは、2つのバイナリツリーとして特に表され、それぞれが単語レベルのタグシーケンスに変換されて、各単語にラベルが付けられます。bi-lstmとbertを採用します私たちのフレームワークのエンコーダとしてそれぞれ、そして公の英語と中国語のデータセットで有望な結果を得る</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-31">
        <br><font color="black">2020-08-31</font>
      </time>
    </span>
</section>
<!-- paper0: Ambiguity Hierarchy of Regular Infinite Tree Languages -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CL/paper_5.html">
      <font color="black">Ambiguity Hierarchy of Regular Infinite Tree Languages</font>
    </a>
  </h2>
  <font color="black">通常の言語のあいまいさの程度は自然な方法で定義されます。k曖昧（それぞれ、有限、有限、有限、あいまいに受け入れられる場合、言語はkあいまい（それぞれ、有限、有限、多義的にあいまい）です。 ）automaton ..オートマトンは、すべての入力に対して最大で1つの計算を受け入れる場合、あいまいではありません。 
[ABSTRACT]オートマトンはk-不確定なオートマトンによって受け入れられるすべての入力に対して最大でkの受け入れがある場合、あいまいです。有限ツリーごとに、すべての通常の言語は、明確なオートマトンによって受け入れられます。k-1オートマトンによって、次の階層があります。あいまいさの程度</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Spoken Language Understanding with RL-based Value Error Recovery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CL/paper_6.html">
      <font color="black">Robust Spoken Language Understanding with RL-based Value Error Recovery</font>
    </a>
  </h2>
  <font color="black">パブリックCATSLUデータセットに対する広範な実験は、SLUの堅牢性を向上させ、ベースラインを大幅に上回ることができる、提案されたアプローチの有効性を示しています。フレームワークは、スロットタグ付けモデルとルールベースの値エラー回復モジュールで構成されています。音声言語理解（SLU）は、自動音声認識（ASR）のエラーに悩まされている音声認識テキストから構造化されたセマンティック表現（スロットと値のペアなど）を抽出することを目的としています。 
[要約]以前の作品は、音声認識されたテキストに入力適応を適用する場合があります。これらは、発音で最も類似した候補を検索することにより、予測値に正しいasrエラーを含みます。ただし、ルールでslu入力適応を導く新しい堅牢なsluフレームワークを提案します-ベースの値エラー回復モジュール</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: KoSpeech: Open-Source Toolkit for End-to-End Korean Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CL/paper_7.html">
      <font color="black">KoSpeech: Open-Source Toolkit for End-to-End Korean Speech Recognition</font>
    </a>
  </h2>
  <font color="black">私たちのベースラインモデルは、Listen、Attend and Spell（LAS）アーキテクチャに基づいており、さまざまなトレーニングハイパーパラメーターを便利にカスタマイズできます。KsponSpeechコーパスでは、音響モデルのみで10.31％の文字エラー率（CER）を達成しました。これが韓国語の音声認識を研究する人たちのためのガイドラインになることを願っています。 
[ABSTRACT] aiハブはksponspeechとして知られる韓国の音声コーパスの1時間をオープンしました。モデルのパフォーマンスを比較するための確立された前処理方法とベースラインモデルはありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Team Alex at CLEF CheckThat! 2020: Identifying Check-Worthy Tweets With
  Transformer Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CL/paper_8.html">
      <font color="black">Team Alex at CLEF CheckThat! 2020: Identifying Check-Worthy Tweets With
  Transformer Models</font>
    </a>
  </h2>
  <font color="black">さらに、いくつかの追加の実験と比較について説明します。これらは、タスクにどの手法が有効であるかについていくつかの指標を提供するため、将来の研究に役立つはずです。タスク1、システムTeam_Alexは、MAPスコア0.8034で2位は、勝利システムとほぼ結びついており、MAPポイントの絶対ポイントは0.003だけ遅れています。残念ながら、手動のファクトチェックは時間がかかり、自動のファクトチェックはリソースを大量に消費するため、事前フィルタリングする必要があります。ソーシャルメディアの投稿を入力し、チェックに値しないと思われる投稿を破棄します。 
[ABSTRACT] covid-19は、ソーシャルコンテキストとツイートのソーシャルコンテキストへのリサーチを組み合わせたものです。これは、ツイートすることができます。これは、自動的にツイートされるツイートのモデルです。英語バージョンの一連のツイートの最新です。音部記号-2020 checkthat！</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Why Not Simply Translate? A First Swedish Evaluation Benchmark for
  Semantic Similarity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CL/paper_9.html">
      <font color="black">Why Not Simply Translate? A First Swedish Evaluation Benchmark for
  Semantic Similarity</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、このようなシンプルなアプローチを使用してスウェーデン語の評価ベンチマークをコンパイルする際に発生する可能性のある問題について説明します。この論文は、テキストの意味的類似性に関するスウェーデン初の評価ベンチマークを提示します。 
[ABSTRACT]ベンチマークは、Google Machinemark APIを介してスウェーデンのデータセットを実行するだけでコンパイルされます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Jointly Encoding Word Confusion Network and Dialogue Context with BERT
  for Spoken Language Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CL/paper_10.html">
      <font color="black">Jointly Encoding Word Confusion Network and Dialogue Context with BERT
  for Spoken Language Understanding</font>
    </a>
  </h2>
  <font color="black">この問題に対処するために、ワードコンフュージョンネットワーク（WCN）を使用して、1-bestまたはn-best仮説リストよりも豊富な情報を含むSLUの入力をエンコードしました。 BERT SLU）は、WCNと対話コンテキストを一緒にエンコードするために提案されています。音声言語理解（SLU）は、仮説を自動音声認識（ASR）から構造化された意味論的表現に変換します。 
[ABSTRACT] asrmarkエラーは、後続のsluモジュールのパフォーマンスを大幅に低下させる可能性があります。これらはシステムへの変更の例です。これには、ダイアログコンテキストの最後のシステム動作の削除が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-24">
        <br><font color="black">2020-05-24</font>
      </time>
    </span>
</section>
<!-- paper0: UIT-HSE at WNUT-2020 Task 2: Exploiting CT-BERT for Identifying COVID-19
  Information on the Twitter Social Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CL/paper_11.html">
      <font color="black">UIT-HSE at WNUT-2020 Task 2: Exploiting CT-BERT for Identifying COVID-19
  Information on the Twitter Social Network</font>
    </a>
  </h2>
  <font color="black">特に、COVID-Twitter-BERT（CT-BERT）に基づく変圧器ベースのモデルと、さまざまな微調整手法を使用したシンプルで効果的なアプローチを提案します。その結果、90.94 \％のF1スコアを達成します。このタスクのリーダーボードで3位になり、合計で56の送信済みチームが参加しました。COVID-19に関するツイートがTwitterで公開されています。 
[要約] covid-19に関するツイートがますます多くTwitterで公開されています。結果はw-nut 2020共有システムシステムで発表されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Uncovering the Corona Virus Map Using Deep Entities and Relationship
  Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CL/paper_12.html">
      <font color="black">Uncovering the Corona Virus Map Using Deep Entities and Relationship
  Models</font>
    </a>
  </h2>
  <font color="black">いくつかのインポートサブネットワークを明らかにし、重要な用語と概念を強調し、過去に関連する病気で使用されたいくつかの治療法を解明します。COVID-19に関連するエンティティと関係を、新しいエンティティを使用してコロナウイルスに関連する記事のコーパスから抽出します。関係モデル..エンティティ認識モデルと関係ディスカバリーモデルは、注釈付きの大きなコーパスに対するマルチタスク学習目標でトレーニングされます。 
[ABSTRACT]関係ディスカバリーモデルは、注釈付きの大規模なコーパスに対するマルチタスク学習目的でトレーニングされます。いくつかのインポートサブネットワークを明らかにし、重要な用語をハイライトし、ネットワークを誘導します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: TorchKGE: Knowledge Graph Embedding in Python and PyTorch -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CL/paper_13.html">
      <font color="black">TorchKGE: Knowledge Graph Embedding in Python and PyTorch</font>
    </a>
  </h2>
  <font color="black">BSDライセンスの下でPyPIを使用して配布されます。さまざまなKG埋め込みモデルもすでに実装されています。コードの効率とシンプルさ、ドキュメント、APIの一貫性に特別な注意が払われています。 
[ABSTRACT]パッケージは、新しいモデルを設計およびテストするためのクリーンで効率的なAPIを研究者とエンジニアに提供します。主な強みは、kg埋め込みの中心的なアプリケーションであるリンク予測タスクの非常に高速な評価モジュールです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: E-BERT: A Phrase and Product Knowledge Enhanced Language Model for
  E-commerce -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CL/paper_14.html">
      <font color="black">E-BERT: A Phrase and Product Knowledge Enhanced Language Model for
  E-commerce</font>
    </a>
  </h2>
  <font color="black">具体的には、フレーズレベルの知識を維持するために、2つのモードのフィッティングの進捗状況に基づいて、モデルが予備的な単語の知識の学習から複雑なフレーズの学習に適応的に切り替えることを可能にする、適応ハイブリッドマスキングを導入します。製品レベルの知識を利用するには、隣接製品再構成を紹介します。これは、ノイズを含むクロスアテンションレイヤーを使用して、製品に関連付けられた近傍を予測するようにE-BERTをトレーニングします。この問題に取り組むために、統合された事前トレーニングフレームワーク、つまりE-BERTを提案します。 
[要約] 2レベルのドメイン知識の欠如は、商取引の欠如によるものです。これは、事実事実eレベルと製品レベルのためです。モデルは、複雑なフレーズを先制的に教えることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: TransModality: An End2End Fusion Method with Transformer for Multimodal
  Sentiment Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/cs.CL/paper_15.html">
      <font color="black">TransModality: An End2End Fusion Method with Transformer for Multimodal
  Sentiment Analysis</font>
    </a>
  </h2>
  <font color="black">さまざまな融合方法が提案されていますが、モダリティ間の微妙な相関関係を見つけるためにエンドツーエンドの翻訳モデルを採用しているものはほとんどありません。マルチモーダル感情分析は、テキスト、ビジュアルから抽出された特徴を通じて話者の感情傾向を予測する重要な研究分野ですと音響モダリティ。複数のマルチモーダルデータセット（CMU-MOSI、MELD、IEMOCAP）でモデルを検証します。 
[要約]私たちは、マルチモーダル感情分析のタスクに対処するために、新しい融合方法トランスモダリティを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Deep Learning-Based Single-Ended Objective Quality Measures for
  Time-Scale Modified Audio -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/eess.AS/paper_0.html">
      <font color="black">Deep Learning-Based Single-Ended Objective Quality Measures for
  Time-Scale Modified Audio</font>
    </a>
  </h2>
  <font color="black">TSMアルゴリズムを評価するために提案された測定値が使用され、16 TSM実装の比較が提供されます。データ駆動型機能は、畳み込みニューラルネットワーク（CNN）または双方向ゲーテッドリカレントユニット（BGRU）ネットワークのいずれかによって作成され、完全に供給されます主観的な平均意見スコアを予測するために接続されたネットワーク。提案されたCNNおよびBGRUメジャーは、0.608および0.576の平均二乗平均誤差と、それぞれ0.771および0.794の平均ピアソン相関を達成します。 
[ABSTRACT]時間-スケーリングされたオーディオデータセットを使用して、tsm評価の客観的指標をトレーニングしました。提案されたcnnおよびbgru指標は、平均根が0. 608および0. 576を達成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: audioLIME: Listenable Explanations Using Source Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/eess.AS/paper_1.html">
      <font color="black">audioLIME: Listenable Explanations Using Source Separation</font>
    </a>
  </h2>
  <font color="black">2つの異なる音楽タギングシステムでaudioLIMEを検証し、競合する方法では実現できない状況で、合理的な説明が生成されることを示します。audioLIMEは、局所性の音楽的定義によって拡張されたLocal Interpretable Model-agnostic Descriptions（LIME）に基づく方法を提案します。 LIMEで使用される摂動は、ソース分離によって抽出されたコンポーネントのオン/オフを切り替えることによって作成され、説明を聞き取りやすくします。 
[ABSTRACT] audiolimeは、ローカルの解釈可能なモデルに基づくメソッドです。競合するメソッドができない状況で、合理的な説明を生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-02">
        <br><font color="black">2020-08-02</font>
      </time>
    </span>
</section>
<!-- paper0: An End-to-end Architecture of Online Multi-channel Speech Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/eess.AS/paper_2.html">
      <font color="black">An End-to-end Architecture of Online Multi-channel Speech Separation</font>
    </a>
  </h2>
  <font color="black">すべての方法で勾配の伝播を可能にするために、注意の重みが各ビームフォーマーと空間でサンプリングされた空間特徴について学習される注意選択モジュールが提案されています。マルチスピーカー音声認識は、シングルアクティブなスピーカーの仮定を破る会話の書き起こしにおける重要な課題の1つです。ほとんどの最先端の音声認識システムで採用されています。音声分離はこの問題の解決策と見なされています。 
[要約]提案されたシステムは音声認識の代替として開発されました。複数のビームフォーマーによって開発され、次にufeと呼ばれます。新しいシステムは音声認識の開発に使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Digital Envelope Estimation Via Geometric Properties of an
  Arbitrary Real Signal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/eess.AS/paper_3.html">
      <font color="black">Robust Digital Envelope Estimation Via Geometric Properties of an
  Arbitrary Real Signal</font>
    </a>
  </h2>
  <font color="black">具体的には、離散曲率の新しい測定値を使用して、離散波の平均曲率半径を取得し、波のフロンティアポイントを特定するためのしきい値として使用します。それにもかかわらず、ほとんどの方法は、フィルター設計、平滑化、およびその他の特定の設計選択の形で、手動による介入を含むため、豊富なスペクトルコンテンツを持つ信号のデジタルエンベロープ検出の一般的な方法はありません。調査中の特定の波の性質に関する先験的な知識
[ABSTRACT]エンベロープ検出は、健康、音の分類と合成、地震学、音声認識などの分野に応用できます。この問題に対処するために、信号の固有の特性を使用してエンベロープを推定するフレームワークを提案します。次のようなエンティティも定義します。パルスとフロンティア、提案されたアルゴリズムの剛性と複雑さを減らす手段として</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: KoSpeech: Open-Source Toolkit for End-to-End Korean Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/eess.AS/paper_4.html">
      <font color="black">KoSpeech: Open-Source Toolkit for End-to-End Korean Speech Recognition</font>
    </a>
  </h2>
  <font color="black">KoSpeechによって、これが韓国語の音声認識を研究する人のためのガイドラインになることを願っています。私たちのベースラインモデルは、Listen、Attend and Spell（LAS）アーキテクチャに基づいており、さまざまなトレーニングハイパーパラメータを簡単にカスタマイズできます。.ベースラインモデルは10.31％を達成しました音響モデルのみのKsponSpeechコーパスでの文字誤り率（CER）。 
[ABSTRACT] aiハブはksponspeechとして知られる韓国の音声コーパスの1時間をオープンしました。モデルのパフォーマンスを比較するための確立された前処理方法とベースラインモデルはありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Localization Uncertainty in Time-Amplitude Stereophonic Reproduction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/eess.AS/paper_5.html">
      <font color="black">Localization Uncertainty in Time-Amplitude Stereophonic Reproduction</font>
    </a>
  </h2>
  <font color="black">この記事では、定位の不確実性に対する知覚されたステレオ再生のチャンネル間時間とレベル差の影響を調べます。これは、音源がどこにあるかをリスナーが知るのがいかに難しいかと定義されています。次に、モデルを使用して定位を予測しますステレオ構成と中央および中央外の位置でのリスナーの不確実性。モデルは正式なリスニングテストによって検証され、0.99のピアソン相関を実現します。次に、このモデルを使用して、ステレオ再生の定位の不確実性を予測します。これは、中心位置と中心から外れた位置のリスナーを予測します。リスナーがその位置から離れると、状況は逆になります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-26">
        <br><font color="black">2019-07-26</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchical Timbre-Painting and Articulation Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-08/eess.AS/paper_6.html">
      <font color="black">Hierarchical Timbre-Painting and Articulation Generation</font>
    </a>
  </h2>
  <font color="black">提案されたアーキテクチャは、数分という短時間のサンプルが与えられれば、楽器の高品質なフィッティングを可能にし、このメソッドは、最先端の音色転送機能を実証します。コードとオーディオのサンプルは、https：で共有されます。 //github.com/mosheman5/timbre_painting ..生成プロセスは、学習したソースフィルタリングネットワークで構成され、解像度を上げながら信号を再構築します。 
[ABSTRACT]提案された設計は、音の損失を再構築するために使用できます。この方法は、最先端の音色転送機能を実証しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-30">
        <br><font color="black">2020-08-30</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
