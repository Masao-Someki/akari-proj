<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-04-17の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Voice-Indistinguishability: Protecting Voiceprint in Privacy-Preserving
  Speech Data Release -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.SD/paper_0.html">
      Voice-Indistinguishability: Protecting Voiceprint in Privacy-Preserving
  Speech Data Release
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、声の区別がつかないプライバシーを保護する音声データのリリースのためのメカニズムとフレームワークを提案します。この研究では、声のプライバシーについて、差別的なプライバシーを拡張することで、声の区別をするための新しい厳密なプライバシーメトリックを設計します。声紋のプライバシー保護に関する現在の調査では、プライバシーとユーティリティの意味のあるトレードオフや、プライバシーの正式かつ厳密な定義は提供されていません。 
[ABSTRACT]音声データに声紋が含まれています。これは、生体認証識別子の一種と見なされています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: AI4COVID-19: AI Enabled Preliminary Diagnosis for COVID-19 from Cough
  Samples via an App -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.SD/paper_1.html">
      AI4COVID-19: AI Enabled Preliminary Diagnosis for COVID-19 from Cough
  Samples via an App
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      テストは、AI4COVID-19という名前のモバイルアプリを介して大規模に展開できます。AI4COVID-19アプリは、被験者の2秒の咳の録音を必要とします。この問題は、リスクを嫌うAIアーキテクチャを中心とした新しい多面的なメディエーターを開発することで解決します誤診を最小限に抑えます。 
[要約]テストはai4covidという名前のモバイルアプリを介して大規模に展開できます。アプリはクラウドで実行されているAIエンジンを使用し、アプリは1分以内に予備診断を返します。これにより、covid-19は咳だけからの診断になります。非常に困難な問題
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-02">
        <br>2020-04-02
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Distinguish Confusing Law Articles for Legal Judgment Prediction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_0.html">
      Distinguish Confusing Law Articles for Legal Judgment Prediction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      紛らわしい料金を区別するために、私たちは、紛らわしい法律の記事間の微妙な違いを自動的に学び、事実の説明から効果的な識別機能を注意深く抽出するために学んだ違いを十分に活用する新しい注意メカニズムを設計する新しいグラフニューラルネットワークを提案します。データセットは、LADANの優位性を示しています。法的判決予測（LJP）は、その事実を説明するテキストが与えられた場合、裁判の判決結果を自動的に予測するタスクであり、司法支援システムと公共サービスに大きな展望があります。 
[ABSTRACT]同様の法律記事に関連する訴訟は、しばしば誤って判断されます。ljpのタスクを修正するために、エンドツーエンドモデル、ladanを提示します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Generate, Delete and Rewrite: A Three-Stage Framework for Improving
  Persona Consistency of Dialogue Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_1.html">
      Generate, Delete and Rewrite: A Three-Stage Framework for Improving
  Persona Consistency of Dialogue Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人間に似た応答を生成する既存のペルソナベースのモデルの成功にもかかわらず、それらの1段階のデコードフレームワークでは、一貫性のないペルソナワードの生成をほとんど回避できません。人間と自動の両方のメトリックによる評価を実行します。ペルソナベースの対話したがって、生成タスクは、明示的なペルソナテキストを対話生成モデルに組み込むことにより、パーソナリティの一貫性のない問題に取り組むために導入されます。 
[ABSTRACT]ペルソナベースの対話生成タスクが導入されて、人間-一貫性のない応答に対処します。この作業では、生成された応答プロトタイプから一貫性のない単語をデコードし、さらにパーソナリティ-一貫性に書き換える3段階のフレームワークを紹介します1
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Null It Out: Guarding Protected Attributes by Iterative Nullspace
  Projection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_2.html">
      Null It Out: Guarding Protected Attributes by Iterative Nullspace
  Projection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      一般的なシナリオに適用できますが、私たちはバイアスと公平性のユースケースで私たちの方法を評価し、私たちの方法が単語の埋め込みのバイアスを軽減し、マルチクラス分類の設定で公平性を高めることができることを示します。ニューラル表現でエンコードされた種類の情報を制御するには、特にこれらのモデルを解釈するという課題に照らして、さまざまなユースケースがあります。そうすることで、分類子はそのターゲットプロパティに気づかなくなり、線形に分離することが難しくなります。それによるとデータ。 
[ABSTRACT] mitは、神経表現から情報を削除するシステムを開発しました。この方法は、データから情報を削除する新しい方法に基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to Contextually Aggregate Multi-Source Supervision for Sequence
  Labeling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_3.html">
      Learning to Contextually Aggregate Multi-Source Supervision for Sequence
  Labeling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      すべてのソースの個々の表現を学習し、コンテキスト認識型アテンションモジュールによってソース固有の知識を動的に集約します。そのパフォーマンスは、教師あり学習シナリオのアノテーションの品質と量に大きく影響され、グラウンドトゥルースラベルの取得には多くのコストがかかります。マルチソース学習の2つの実際的な設定で提案されたフレームワークを評価します。群衆の注釈による学習と教師なしのクロスドメインモデルの適応です。 
[要約]このホワイトペーパーでは、新しいフレームワークコンセンサスnetwork.itを提案します。複数のソースからのアノテーションでトレーニングできます。複数のソース間の合意（コンセンサス）を反映したモデルになります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-09">
        <br>2019-10-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Deep Generation of Coq Lemma Names Using Elaborated Terms -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_4.html">
      Deep Generation of Coq Lemma Names Using Elaborated Terms
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Coqプロジェクトの補題名を学習および提案するための新しい生成モデルを提示します。慣例は高コストで手動で文書化および適用できますが、新しいアプローチでは、大規模なコードコーパスに統計言語モデルを適用することにより、Javaのような言語で慣用名を自動的に学習および提案します。 .. Roosterizeと呼ばれるツールチェーンにモデルを実装し、その厳格なコーディング規約で知られているMathematical Componentsファミリーのプロジェクトから派生した大規模なコードのコーパスに適用しました。 
[ABSTRACT]新しい研究は、coqが自動学習手法の難しいターゲットであることを示しています。マルチ入力ニューラルネットワークに基づく新しいモデルは、coqのレクサー、パーサー、カーネルからの情報を利用して最初に命名します。重要な洞察は詳細な用語から学ぶことで、モデルのパフォーマンスを大幅に向上させることができる
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Leveraging Pre-trained Checkpoints for Sequence Generation Tasks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_5.html">
      Leveraging Pre-trained Checkpoints for Sequence Generation Tasks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちは、公に利用可能な事前トレーニング済みのBERT、GPT-2、RoBERTaチェックポイントと互換性のあるトランスフォーマーベースのシーケンスツーシーケンスモデルを開発し、これらのモデルを使用して、エンコーダーとデコーダーの両方のモデルを初期化するユーティリティに関する広範な実証研究を行いましたチェックポイント..最近、大規模ニューラルモデルの教師なし事前トレーニングが自然言語処理に革命をもたらしました。私たちのモデルは、機械翻訳、テキストの要約、文の分割、および文の融合に関する新しい最先端の結果をもたらします。 
[ABSTRACT]新しい言語テストは、事前トレーニング済みのチェックポイントを事前トレーニングできることを示しています。新しいモデルは、事前トレーニング済みのチェックポイントの有効性を示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-29">
        <br>2019-07-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Balancing Training for Multilingual Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_6.html">
      Balancing Training for Multilingual Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、代わりに、すべてのテスト言語でパフォーマンスを最大化するように最適化されたデータスコアラーを通じてトレーニングデータの重み付け方法を自動的に学習する方法を提案します。1対多と多対多の両方での2セットの言語の実験-1つのMT設定は、平均的なパフォーマンスの面でヒューリスティックなベースラインを一貫して上回っているだけでなく、最適化されている言語のパフォーマンスを柔軟に制御できることを示しています。複数に翻訳できる複数言語の機械翻訳（MT）モデルをトレーニングする場合言語、我々は不均衡なトレーニングセットに直面しています：一部の言語は他よりもはるかに多くのトレーニングデータを持っています。 
[ABSTRACT]標準的な方法は、アップ-リソースの少ない言語をサンプリングすることです。アップの度合いは、全体的なパフォーマンスに大きな影響を与えます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-14">
        <br>2020-04-14
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Methodology for Creating Question Answering Corpora Using Inverse Data
  Annotation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_7.html">
      A Methodology for Creating Question Answering Corpora Using Inverse Data
  Annotation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、アノテーターがトークンをOT操作に割り当てます。最後に、最新のセマンティック解析モデルをデータでトレーニングし、コーパスが挑戦的なデータセットであることと、トークンのアライメントを活用して増加させることができることを示しますパフォーマンスが大幅に向上します。このメソッドを適用して、データベースへの自然言語インターフェースを評価するための大きなセマンティック解析コーパスである新しいコーパスOTTA（操作ツリーとトークン割り当て）を作成します。 
[ABSTRACT]このメソッドを適用して、データベースへの自然言語インターフェースを評価するための大きなセマンティック解析コーパスである新しいコーパスottaを作成します。データの最先端の意味解析モデルをトレーニングし、コーパスが挑戦的なデータセットであることを示します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: There is Strength in Numbers: Avoiding the Hypothesis-Only Bias in
  Natural Language Inference via Ensemble Adversarial Training -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_8.html">
      There is Strength in Numbers: Avoiding the Hypothesis-Only Bias in
  Natural Language Inference via Ensemble Adversarial Training
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      敵の集団を使用すると、モデルのトレーニングが完了した後にバイアスが再学習されるのを防ぐことができ、モデルがさまざまなNLIデータセットに一般化される度合いがさらに向上することを示します。より大きな次元の表現は、より多くの敵とトレーニングしたときにメリットがあります。特に、これらのモデルは、モデルトレーニングで使用されていない12の異なるNLIデータセットでテストした場合、以前のアプローチよりも優れていました。 
[ABSTRACT]これらのアーティファクトは、理論のみを考慮し、前提を無視している場合でもニューラルネットワークによって悪用され、不要なバイアスにつながります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Cross-lingual Contextualized Topic Models with Zero-shot Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_9.html">
      Cross-lingual Contextualized Topic Models with Zero-shot Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      モデルは単一言語であるか、非常にまばらな語彙に悩まされている必要があります。同じドキュメントのテキストを異なる言語で使用することにより、予測の品質を評価できます。ドメイン内の多くのデータセット（レビュー、フォーラム、ニュースなど）
[ABSTRACT]これらのモデルは単一言語であるか、非常に密度の高い膨大な語彙に悩まされている必要があります。これらのモデルには、さまざまなトピックを学習し、他の言語のドキュメントでそれらを予測するモデルが含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Kvistur 2.0: a BiLSTM Compound Splitter for Icelandic -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_10.html">
      Kvistur 2.0: a BiLSTM Compound Splitter for Icelandic
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      手動で分割された単語形式のコーパスで評価すると、モデルは他の以前に公開された方法よりも優れています。これにより、多数の語彙外（OOV）単語が生じ、多くのNLPツールのパフォーマンスに悪影響を与えます。モデルは、複合語を2つの部分に分割し、任意の単語形式の構成構造を導出するために使用できます。 
[ABSTRACT]アイスランドでは、合成の生産性が高く、新しい化合物が常に作成されています。この方法は、アイスランドの複合語アナライザーに統合されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: TriggerNER: Learning with Entity Triggers as Explanations for Named
  Entity Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_11.html">
      TriggerNER: Learning with Entity Triggers as Explanations for Named
  Entity Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2つの十分に研究されたNERデータセットの14kエンティティトリガーをクラウドソーシングしました。実験により、フレームワークは大幅に費用対効果が高く、トリガー注釈付き文の20％を使用すると、70を使用した従来の監視アプローチの同等のパフォーマンスが得られることが示されています％トレーニングデータ..新しいドメインで名前付きエンティティ認識（NER）のニューラルモデルをトレーニングするには、通常、収集に費用と時間がかかる追加の人間の注釈（たとえば、数万のラベル付きインスタンス）が必要です。 
[ABSTRACT]トリガーマッチングという名前の提案されたモデルは、人々がさまざまな形式のフォームを学習できるように設計されています。コスト効率の高い方法で監視を提供することを目的としています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Controlling Computation versus Quality for Neural Sequence Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_12.html">
      Controlling Computation versus Quality for Neural Sequence Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ほとんどのニューラルネットワークは、入力の固有の複雑さに関係なく、すべての例で同じ量の計算を利用します。次に、このモデルをマルチタスク設定でトレーニングします。各タスクは特定の計算予算に対応します。 2つのタスク：（i）WMT英語-フランス語翻訳および（ii）教師なし表現学習（BERT）。 
[要約]提案された条件付きアルゴリズムトランスフォーマー（cct）は、完全なコンピューティングバジェットを利用できる場合、バニラトランスフォーマーと競合します。これにより、計算の異なるポイントで動作するように制御できる単一のモデルをトレーニングできます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-17">
        <br>2020-02-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Bootstrapping a Crosslingual Semantic Parser -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_13.html">
      Bootstrapping a Crosslingual Semantic Parser
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      新しいバージョンのATISとドイツ語と中国語のOvernightの実験結果は、MTが複数のMTエンジンを介して言い換えると、正確な構文解析のために新しい言語でトレーニングデータを概算できることを示しています。翻訳は法外な費用がかかる可能性があります。機械翻訳がトレーニングデータの適切な代替物であるかどうかを評価し、これを拡張して、英語、言い換え、および多言語BERTなどのリソースとの共同トレーニングを使用したブートストラップを調査します。 
[ABSTRACT]新しい研究によると、mtは最小限の注釈で新しい言語と複数のドメインに適応できることが示されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: LEAN-LIFE: A Label-Efficient Annotation Framework Towards Learning from
  Explanation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_14.html">
      LEAN-LIFE: A Label-Efficient Annotation Framework Towards Learning from
  Explanation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      3つの一般的なNLPタスク（名前付きエンティティの認識、関係の抽出、感情分析）で、この強化された監視を使用すると、モデルが競合ベースラインF1スコアを5〜10％以上超え、ラベル付きインスタンスを2倍に削減できることがわかります。 。ただし、各ラベルは、必要な数のラベルから学び、収集するために限られた情報しか提供しません。人間の多大な労力が含まれます。この作業では、シーケンスのラベル付けと分類のためのWebベースのラベル効率の良いAnnotatioNフレームワークであるLEAN-LIFEを紹介します。アノテーターがタスクに必要なラベルを提供できるようにするだけでなく、各ラベル付けの決定について「説明からの学習」も可能にする使いやすいUIを備えたタスク。 
[ABSTRACT]このツールを使用して、有用な追加のラベル付きデータを作成する必要があります。これらの説明により、有用な追加の追加のラベル付き情報を生成できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Generating Emotionally Aligned Responses in Dialogues using Affect
  Control Theory -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_15.html">
      Generating Emotionally Aligned Responses in Dialogues using Affect
  Control Theory
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ACTを使用して、プロンプトに感情的に対応する応答を生成し、対話者の感情的アイデンティティを考慮に入れる、感情認識神経会話エージェントを開発する方法を調査します。ACTは、社会的状況での人間の感情的刺激への応答について予測します。この特性により、ACTとその派生確率モデルは、共感的な個別指導システム、支援医療機器、2人用の社会的ジレンマゲームなど、人間とコンピューターの相互作用のいくつかのアプリケーションに正常に展開されています。 
[ABSTRACT] actは、神経対話生成設定に対する、人間と人間のつながりのための社会-数学的感情モデルです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-07">
        <br>2020-03-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards Instance-Level Parser Selection for Cross-Lingual Transfer of
  Dependency Parsers -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_16.html">
      Towards Instance-Level Parser Selection for Cross-Lingual Transfer of
  Dependency Parsers
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このために、トランスフォーマーアーキテクチャに基づいて、監視付き回帰モデルをトレーニングし、個々のPOSシーケンスのパーサー精度を予測します。次に、インスタンスレベルで最適なパーサーを予測することを提案します。さらに、 「ツリーバンクレベル」（SBPS）の最良のパーサーは、インスタンスレベルのモデルからの予測の集計を使用して、17/20および16/20テスト言語で同じベースラインよりも優れています。 
[ABSTRACT]以前の調査では、インスタンスレベルのパーサー選択はツールではないことが示されています。彼は、新しいクロスリンガル転送パターンについて論じています。example.heは、インスタンスレベルで最高のパーサーを予測することを提案しています。ターゲットベースのパーサーのベスト
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Pretrained Transformers Improve Out-of-Distribution Robustness -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_17.html">
      Pretrained Transformers Improve Out-of-Distribution Robustness
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      どの要素がロバスト性に影響するかを調べ、大きなモデルは必ずしもロバストではないこと、蒸留は有害である可能性があること、そして多様な事前トレーニングデータがロバスト性を高めることができることを発見します。バッグオブワードモデル、ConvNetsなどの以前のモデルの一般化を測定し、 LSTM、および事前トレーニング済みのトランスフォーマーのパフォーマンス低下が大幅に小さいことを示します。最後に、将来の作業でOODの堅牢性を向上できる場所を示します。 
[ABSTRACT]事前学習済みの変圧器は、異常またはフードの例を検出するのにより効果的ですが、以前の多くのモデルは、偶然よりも悪いことが多い
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-13">
        <br>2020-04-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Do sequence-to-sequence VAEs learn global features of sentences? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_18.html">
      Do sequence-to-sequence VAEs learn global features of sentences?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この方法を使用すると、VAEは最初の単語と文の長さを覚えやすくなり、その有用性が大幅に制限されることがわかります。これを軽減するために、単語の袋の仮定と言語モデルの事前トレーニングに基づいてバリアントを提案します。単語は、文の位置ごとの再構成損失を分解することにより、潜在情報から最も恩恵を受けます。 
[ABSTRACT]これらの表現は、サンプル-効率的な半教師付き学習と制御可能なテキスト生成に役立ちます。これを軽減するために、バッグオブワードの仮定と言語モデルの事前トレーニングに基づくバリアントを提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Integrating Discrete and Neural Features via Mixed-feature
  Trans-dimensional Random Field Language Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_19.html">
      Integrating Discrete and Neural Features via Mixed-feature
  Trans-dimensional Random Field Language Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、混合機能のTRF LMを開発し、離散機能とニューラル機能の統合におけるその利点を示します。ディスクリート機能（n-gram機能）とニューラルネットワークベースの機能には、言語モデル（LM）の補完的な強みがあることは長い間認識されています。 ..個別にトレーニングされた2つの個別にトレーニングされたモデルとニューラル機能をそれぞれ補間するのと比較して、混合機能TRF LMのパフォーマンスは、最適化された補間モデルと一致し、ワンステップトレーニングプロセスが簡略化され、トレーニング時間が短縮されます。 
[ABSTRACT]モデル補間は、システムのサブオプティポリング2ステップ統合です。これらの2ステップモデルには、連続的および神経的特徴が含まれます。これらは、ptbおよびgoogle 1-billion-wordデータセットでトレーニングされます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-14">
        <br>2020-02-14
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The Right Tool for the Job: Matching Model and Instance Complexities -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_20.html">
      The Right Tool for the Job: Matching Model and Instance Complexities
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのコードは公開されています。この方法では、ほとんどすべての場合に好ましい速度と精度のトレードオフがあり、最新の最大5倍の速度で、正確性を維持しながらモデルを作成しています。最後に、この方法で必要性が軽減されます。さまざまなレベルの効率で複数のモデルの費用のかかる再トレーニングを行うため。推論時に単一の変数を設定することにより、ユーザーは単一のトレーニング済みモデルを使用して推論速度/精度のトレードオフを制御できます。 
[要約]提案されたモデルは、ニューラルネットワーク計算からの早期の「終了」を必要とします。3つのテキスト分類データセットと2つの自然言語可能性ベンチマークの2つのタスクで、5つの異なるデータセットで提案された変更をテストします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Data-to-Text Generation with Dynamic Content Planning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_21.html">
      Neural Data-to-Text Generation with Dynamic Content Planning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人間の評価結果は、提案されたNDPによって生成されたテキストは、ほとんどの時間でNCPによって生成された対応するテキストよりも優れていることを示しています。さらに、使用されたデータのエントリ全体を順次再構築できる新しい目的関数を使用して再構築メカニズムを設計します。デコーダーの隠された状態から、生成されたテキストの精度を支援します。ニューラルデータからテキストへの生成モデルは、近年大きな進歩を遂げました。 
[要約]カナダのモデルは、以前に生成されたテキストを使用して、指定された構造化データから適切なエントリを設計できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Non-Autoregressive Machine Translation with Latent Alignments -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_22.html">
      Non-Autoregressive Machine Translation with Latent Alignments
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは、27.8 BLEUのベースライン自己回帰トランスフォーマーと比べて遜色がありません。さらに、入出力クロスアテンションが使用されないため、このアーキテクチャは通常のエンコーダ/デコーダアーキテクチャよりもシンプルです。.競合するWMT&#39;14 En $ \ rightarrow $ Deタスクでは、CTCモデルは1つの生成ステップで25.7 BLEUを実現し、Imputerは2つの生成ステップで27.5 BLEU、4つの生成ステップで28.0 BLEUを実現しています。 
[ABSTRACT] ctcは、出力変数に関する強力な条件付き独立性仮定を行って、単一のステップで出力を生成します。これらのモデルは、前処理として出力長の不安定性を必要としないため、既存の非自己回帰メソッドよりも単純です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Queens are Powerful too: Mitigating Gender Bias in Dialogue Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_23.html">
      Queens are Powerful too: Mitigating Gender Bias in Dialogue Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちは、対話データの性別バイアスを分析し、このバイアスが実際の後続の生成チャットチャットモデルでどのように増幅されるかを調べます。6つの既存の対話データセットで性別バイアスを測定し、最もバイアスされているもの、マルチプレイヤーテキストに焦点を当てますベースのファンタジーアドベンチャーデータセットLIGHT、バイアス緩和手法のテストベッドとして。性別バイアスを緩和するために、3つの手法を検討します：反事実的データ増大、ターゲットを絞ったデータ収集、バイアス制御トレーニング。 
[ABSTRACT]軽いデータセットは、性別に関して非常に不均衡です。主に男性のキャラクターが含まれています。おそらくクラウドワーカーによって完全に収集されているためです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br>2019-11-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: COSTRA 1.0: A Dataset of Complex Sentence Transformations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_24.html">
      COSTRA 1.0: A Dataset of Complex Sentence Transformations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このデータセットを使用すると、文の埋め込みのセマンティックプロパティをテストでき、さらには文の埋め込みスペースでトポロジー的に興味深い「スケルトン」を見つけることができるはずです。 、簡略化、一般化、または公式と非公式の言語バリエーションなどの15種類の変更を示しています。LASERを使用した予備分析、多目的多言語センテンス埋め込みは、LASERスペースが望ましい特性を示さないことを示唆しています。 
[ABSTRACT]データセットは、4、262文で構成され、平均の長さは10ワードです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-03">
        <br>2019-12-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Interactive Machine Comprehension with Information Seeking Agents -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_25.html">
      Interactive Machine Comprehension with Information Seeking Agents
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SQuADとNewsQAを最初のケーススタディとして再利用し、インタラクティブコーパスを使用して、逐次的な意思決定を通じて関連情報を求めるモデルをトレーニングする方法を示します。これは、MRCデータセットの性質に由来すると主張します。これらのほとんどは、サポートドキュメントとすべての必要な情報が完全に監視される静的な環境です。具体的には、ドキュメントのテキストの大部分を「隠蔽」し、非表示のテキストの「概要」をモデルに表示する状況依存コマンドを追加します。 
[ABSTRACT]ドキュメントのテキストの大部分を「オクルード」し、状況依存のコマンドをモデルに追加します。この設定は、Webレベルのqaシナリオへのモデルのスケーリングに貢献できると考えています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-27">
        <br>2019-08-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: BLiMP: The Benchmark of Linguistic Minimal Pairs for English -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_26.html">
      BLiMP: The Benchmark of Linguistic Minimal Pairs for English
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最先端のモデルは形態学的コントラストを確実に識別しますが、数量詞と負の極性項目の分布に対する意味論的制限、および抽出アイランドなどの微妙な構文現象に悩まされています。BLiMPは、それぞれ67個のサブデータセットで構成されています。構文、形態、またはセマンティクスの特定のコントラストを分離する1000個の最小ペアを含みます。n-gram、LSTM、およびトランスフォーマー（GPT-2およびTransformer-XL）のLMを評価するために使用します。 
[要約]飛行船は67のサブ言語および言語のカテゴリで構成されています。システムは飛行船と呼ばれる言語に基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-02">
        <br>2019-12-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Paraphrase Augmented Task-Oriented Dialog Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_27.html">
      Paraphrase Augmented Task-Oriented Dialog Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      PARGは、TSCP（Lei et al。、2018）やDAMD（Zhang et al。、2019）などのさまざまなダイアログ生成モデルに適用できます。PARGは、特に低リソース設定で、ダイアログ生成タスクの他のデータ拡張方法よりも大幅に優れています。 ..実験結果は、提案されたフレームワークがこれらの最先端の対話モデルをCamRest676とMultiWOZでさらに改善することを示しています。 
[ABSTRACT]会話の状態と会話の行動のラベルに基づいて言い換えトレーニングデータセットを自動的に構築する方法も設計します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Suicidal Ideation and Mental Disorder Detection with Attentive Relation
  Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/cs.CL/paper_28.html">
      Suicidal Ideation and Mental Disorder Detection with Attentive Relation
  Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      関係モジュールには、より重要な関係機能を優先する注意メカニズムがさらに装備されています。しかし、自殺念慮やその他の精神障害の分類は、言語の使用法と感情の極性で非常に類似したパターンを共有しているため、困難な作業です。精神の早期発見社会的コンテンツからの障害と自殺念慮は、効果的な社会的介入のための潜在的な方法を提供します。 
[ABSTRACT]ソーシャルコンテンツからの精神障害と自殺念慮は、効果的な社会的介入のための潜在的な方法を提供します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Voice-Indistinguishability: Protecting Voiceprint in Privacy-Preserving
  Speech Data Release -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/eess.AS/paper_0.html">
      Voice-Indistinguishability: Protecting Voiceprint in Privacy-Preserving
  Speech Data Release
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、声の区別がつかないプライバシーを保護する音声データのリリースのためのメカニズムとフレームワークを提案します。公開データセットでの実験により、提案された方法の有効性と効率を検証します。これは、差別化されたプライバシーを拡張することにより、音声を区別できないことと呼ばれます。 
[ABSTRACT]音声データに声紋が含まれています。これは、生体認証識別子の一種と見なされています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Integrating Discrete and Neural Features via Mixed-feature
  Trans-dimensional Random Field Language Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/eess.AS/paper_1.html">
      Integrating Discrete and Neural Features via Mixed-feature
  Trans-dimensional Random Field Language Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      別々にトレーニングされた2つの個別にトレーニングされたモデルを補間するのと比較して、それぞれ個別の機能とニューラル機能を使用して、混合機能TRF LMのパフォーマンスは、最適化された補間モデルと一致し、ワンステップのトレーニングプロセスが簡略化され、トレーニング時間が短縮されます。トランスディメンションランダムフィールド（TRF ）フレームワークには、豊富な機能のセットを柔軟に統合できるという潜在的な利点があります。モデルの補間なしで）、混合機能のTRF LMは最高のパフォーマンスを発揮し、離散TRF LMとニューラルTRF LMの両方を改善し、さらに大幅に向上します。 LSTM LMよりも優れています。 
[ABSTRACT]モデル補間は、システムのサブオプティポリング2ステップ統合です。これらの2ステップモデルには、連続的および神経的特徴が含まれます。これらは、ptbおよびgoogle 1-billion-wordデータセットでトレーニングされます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-14">
        <br>2020-02-14
      </time>
    </span>
  </h3>
</article>
<!-- paper0: AI4COVID-19: AI Enabled Preliminary Diagnosis for COVID-19 from Cough
  Samples via an App -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/eess.AS/paper_2.html">
      AI4COVID-19: AI Enabled Preliminary Diagnosis for COVID-19 from Cough
  Samples via an App
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      AI4COVID-19は、臨床試験と競合するように設計されていません。AI4COVID-19アプリは、被験者の2秒の咳の録音を必要とします。このテストは、AI4COVID-19というモバイルアプリを介して大規模に展開できます。 
[要約]テストはai4covidという名前のモバイルアプリを介して大規模に展開できます。アプリはクラウドで実行されているAIエンジンを使用し、アプリは1分以内に予備診断を返します。これにより、covid-19は咳だけからの診断になります。非常に困難な問題
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-02">
        <br>2020-04-02
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Proteomics of protein trafficking by in vivo tissue-specific labeling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-17/biorxiv.physiology/paper_0.html">
      Proteomics of protein trafficking by in vivo tissue-specific labeling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      特に、保存された脂肪体由来の新規臓器間コミュニケーション因子CG31326、CG2145、およびCG4332が筋活動を促進することを実証します。我々の結果は、分泌タンパク質のコミュニケーションネットワークが広大であることを示し、これらの多くの全身機能を特定しました要因プロテオーム全体の臓器間の分泌タンパク質輸送を調査するためのin vivoプラットフォームを確立しました。定量的質量分析を使用して、遠位臓器から濃縮および同定。 
[要約]私たちは、臓器間の分泌タンパク質輸送を調査するために入院プラットフォームを確立しました。これらには、1つの組織の細胞内コンパートメント内のビオチン化タンパク質が含まれ、ビオチン化タンパク質は親和性が高く、定量的質量分析を使用して識別されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
