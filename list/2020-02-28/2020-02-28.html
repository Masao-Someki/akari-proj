<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-02-28の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Environment Sound Classification using Multiple Feature Channels and
  Attention based Deep Convolutional Neural Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.SD/paper_0.html">
      Environment Sound Classification using Multiple Feature Channels and
  Attention based Deep Convolutional Neural Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このモデルは、3つすべてのベンチマーク環境サウンド分類データセットで最先端のパフォーマンスを実現できます。また、以前のモデルと比較してより深いCNN（DCNN）を採用しています。これは、時間と機能ドメインで別々に動作する空間的に分離可能な畳み込みで構成されています。 
[ABSTRACT]複数の機能チャネルには、mel-周波数ケプストラム度（mfcc）、ガンマトーン周波数ケプストラムエントリ（gfcc）、定数q-変換（cqt）およびクロマグラムが含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-28">
        <br>2019-08-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ASVspoof 2019: a large-scale public database of synthetic, converted and
  replayed speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.SD/paper_1.html">
      ASVspoof 2019: a large-scale public database of synthetic, converted and
  replayed speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、2019年版には、固定ASVシステムの信頼性に対するなりすましおよび対策の影響を反映するタンデム検出コスト関数メトリックの使用も新たに追加されました。以前よりもはるかに明らかに分析をサポートする制御されたシミュレーション。また、論理アクセスにおけるスプーフィングされたデータに関する人間の評価についても説明します。 
[要約] asvは、「プレゼンテーション攻撃」としても知られるスプーフィングに対して脆弱です。asvシステムは、リプレイ、音声合成、および音声変換攻撃に対しても脆弱です。これらのシステムは、2つの特定のユースケースシナリオで検討されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-05">
        <br>2019-11-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Density Ratio Approach to Language Model Fusion in End-To-End
  Automatic Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.SD/paper_2.html">
      A Density Ratio Approach to Language Model Fusion in End-To-End
  Automatic Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、YouTubeの音声とトランスクリプトのペアデータでトレーニングされたRNN-Tモデルは、音声検索データに一般化する能力について評価されます。特定のドメインでトレーニングされたリカレントニューラルネットワークトランスデューサー（RNN-T）ASRモデルに適用され、整合ドメイン内RNN-LMおよびターゲットドメインRNN-LMで、提案された方法は、ベイズのルールを使用して、Deep Neuralに基づくASRの古典的なハイブリッドモデルに直接類似する方法で、ターゲットドメインのRNN-T事後を定義します隠れマルコフモデル（HMM）フレームワークのネットワーク（DNN）またはLSTM（Bourlard＆Morgan、1994）..提案されたアプローチは、クロスドメインおよび限定データシナリオで評価されます。 LMトレーニングに使用されますが、RNN-Tのトレーニングには、限られた（またはまったくない）{audio、transcript}トレーニングデータペアのみが使用されます。 
[概要]提案された方法は、ベイズのルールを使用して、ターゲットドメインのrnn-t事後を定義します。これは、ディープニューラルネットワーク（dnns）またはlstmsに基づくasrのタイプに基づいています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-26">
        <br>2020-02-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An Open-set Recognition and Few-Shot Learning Dataset for Audio Event
  Classification in Domestic Environments -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.SD/paper_3.html">
      An Open-set Recognition and Few-Shot Learning Dataset for Audio Event
  Classification in Domestic Environments
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、限られた数のサンプルを使用して、ドアベルや火災警報などのさまざまな種類の音響警報によって与えられる特定の意図的な音響イベントの検出へのFSLの適用について説明します。実用的なシナリオは、オープンセット認識（OSR）の問題と考えることができます。オーディオの分野では、音楽詐欺や話者の認識がFSLメソッドから明らかに恩恵を受けることができます。 
[ABSTRACT] fslは小さなデータセットを使用して、特定の意図的なイベントを検出します。これらには、ドアベル、火災警報器、ドアベルが含まれます。これらの音は、オープンセット認識（osr）問題と見なすことができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-26">
        <br>2020-02-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The sound of my voice: speaker representation loss for target voice
  separation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.SD/paper_4.html">
      The sound of my voice: speaker representation loss for target voice
  separation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、残余スペクトログラム出力からターゲットスピーカー情報を削除するための追加の基準として、トリプレットスピーカー表現の損失を提案します。コンテンツおよびスタイル表現は、スタイル転送の分野で広く研究されています。 VCTKデータベース。ネットワークパラメータを追加することなく、ベースライン損失機能と比較してパフォーマンスが向上しました。 
[ABSTRACT] voicefilterフレームワークは、vctkデータベースを使用してソース分離パフォーマンスを評価するために採用されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-06">
        <br>2019-11-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SkinAugment: Auto-Encoding Speaker Conversions for Automatic Speech
  Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.SD/paper_5.html">
      SkinAugment: Auto-Encoding Speaker Conversions for Automatic Speech
  Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、アプローチを機械翻訳されたトランスクリプトによる拡張と組み合わせて、English $ \ to $ French ASTタスクで非常に強力なカスケードモデルよりも優れた競合エンドツーエンドASTモデルを取得できることを示します。 English $ \ to $ FrenchおよびEnglish $ \ to $ Romanian自動音声翻訳（AST）タスクおよび低リソースの英語自動音声認識（ASR）タスクでのSpecAugmentに有利です。さらに、アブレーションでは、拡張データの量と多様性の両方の利点。 
[要約]拡張データの量と多様性の両方の利点を示します。この方法は、他の音声生成および分析タスクに適用できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-27">
        <br>2020-02-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Streaming automatic speech recognition with the transformer model -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.SD/paper_6.html">
      Streaming automatic speech recognition with the transformer model
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、ASRをストリーミングするためのトランスベースのエンドツーエンドASRシステムを提案します。このシステムでは、各発話語の直後に出力を生成する必要があります。これを実現するために、エンコーダとエンコーダー-デコーダーのアテンションメカニズムに注目します。提案されたストリーミングトランスアーキテクチャーは、LibriSpeechのクリーンデータおよびその他のテストデータに対して2.8％および7.3％WERを達成します。仕事。 
[概要]トランスフォーマーアーキテクチャは、リカレントニューラルネットワーク（rnn）ベースのシステムアーキテクチャと比較して、大幅に低いワードエラー率（wers）を達成することが示されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-08">
        <br>2020-01-08
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Generating Followup Questions for Interpretable Multi-hop Question
  Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.CL/paper_0.html">
      Generating Followup Questions for Interpretable Multi-hop Question
  Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      気を散らす施設を避けながら、関連する回答範囲を選択するフォローアップ質問を生成する学習は、テキスト生成のためのエキサイティングなセマンティックチャレンジをもたらします。HotpotQAの2ホップブリッジ質問を使用した評価を提示します。ニューラル質問生成ネットワークの適用。これは、最終的な回答とその裏付けとなる事実に基づいて、弱いグラウンドトゥルースのシングルホップフォローアップ質問を提供するために適用されます。 
[要約]これは、ニューラル質問生成ネットワークの新規アプリケーションを提供します。2ホップブリッジ質問を使用した評価を提示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-27">
        <br>2020-02-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Density Ratio Approach to Language Model Fusion in End-To-End
  Automatic Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.CL/paper_1.html">
      A Density Ratio Approach to Language Model Fusion in End-To-End
  Automatic Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      密度比法は、LMおよびエンドツーエンドASR統合、Shallow Fusionへの支配的なアプローチよりも常に優れていることがわかりました。提案されたアプローチは、クロスドメインおよび限られたデータのシナリオで評価されます。テキストデータはLMトレーニングに使用されますが、RNN-Tのトレーニングには限られた（またはまったくない）{audio、transcript}トレーニングデータペアのみが使用されます。具体的には、YouTubeからのオーディオとトランスクリプトのペアデータでトレーニングされたRNN-Tモデルは音声検索データに一般化する能力について評価されました。 
[概要]提案された方法は、ベイズのルールを使用して、ターゲットドメインのrnn-t事後を定義します。これは、ディープニューラルネットワーク（dnns）またはlstmsに基づくasrのタイプに基づいています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-26">
        <br>2020-02-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving cross-lingual model transfer by chunking -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.CL/paper_2.html">
      Improving cross-lingual model transfer by chunking
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ソース言語とターゲット言語の間の構文上の違いにさらに効果的に対処するために、浅いパーサーにガイドされたクロスリンガルモデル転送アプローチを提示します。フレーズ内の単語の順序の違いと、文内のフレーズの順序の違いにより生じるソース言語とターゲット言語の違い。 
[ABSTRACT]この作品では、ソース言語とターゲット言語の違いに対処するために、文のチャンクを転送単位として想定しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-27">
        <br>2020-02-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Echo State Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.CL/paper_3.html">
      Echo State Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      モデルを特徴付ける重要な量であるリザーバーのスペクトル半径がモデルの挙動をどのように決定するかを調べます。我々の発見は、ランダム化ネットワークが複雑なシーケンス間予測NLPタスクに対してもうまく機能することを示しています。 （NMT）モデルは、エコー状態ネットワーク（ESN）に触発され、エコー状態NMT（ESNMT）と呼ばれます。このモデルでは、エンコーダーとデコーダーのレイヤーの重みがランダムに生成され、トレーニング中に固定されます。 
[ABSTRACT] esnmtは、完全にトレーニング可能なベースラインの品質の70〜80％にすでに到達できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-27">
        <br>2020-02-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CrossWOZ: A Large-Scale Chinese Cross-Domain Task-Oriented Dialogue
  Dataset -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.CL/paper_4.html">
      CrossWOZ: A Large-Scale Chinese Cross-Domain Task-Oriented Dialogue
  Dataset
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、パイプライン化されたタスク指向の対話システム用のユーザーシミュレーターといくつかのベンチマークモデルを提供します。これにより、研究者はこのコーパスでモデルを比較および評価できます。 CrossWOZの大きなサイズと豊富な注釈は、対話状態の追跡、ポリシー学習、ユーザーシミュレーションなど、クロスドメイン対話モデリングのさまざまなタスクの調査に適しています。要約] 5つのドメインの6kコーパスと102kの発話が含まれます。対話の60％には、ドメイン間の依存関係を支持するクロスマーク目標があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-27">
        <br>2020-02-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Model to Measure the Spread Power of Rumors -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.CL/paper_5.html">
      A Model to Measure the Spread Power of Rumors
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      （iii）T-Testの結果は、SPR基準がFRとTRを大幅に区別できることを示しています。さらに、噂の真実性を検証する新しい方法としても役立ちます。合計51個のコンテキスト機能がSPRを測定するために導入され、それらの分類への影響が調査され、次にSPRを計算するために「重要」（28機能）と「あいまいさ」（14機能）の2つのカテゴリの42機能が選択されます。 
[ABSTRACT]提案された噂拡散パワー測定モデル（rspmm）は、文学ベースのアプローチを使用してsprを計算します。提案されたrspmmは、twitterおよび電報から収集された2つのラベル付きデータセットで検証されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br>2020-02-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SkinAugment: Auto-Encoding Speaker Conversions for Automatic Speech
  Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.CL/paper_6.html">
      SkinAugment: Auto-Encoding Speaker Conversions for Automatic Speech
  Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、機械翻訳された転写産物による増強とアプローチを組み合わせて、English $ \ to $ French ASTタスクで非常に強力なカスケードモデルよりも優れた競争力のあるエンドツーエンドASTモデルを取得できることを示します。アブレーションでは、拡張データで量と多様性の両方の利点を示します。この方法は、English $ \ to $ FrenchおよびEnglish $ \ to $ Romanian自動音声翻訳（AST）タスクのSpecAugmentと同様に、リソース英語の自動音声認識（ASR）タスク。 
[要約]拡張データの量と多様性の両方の利点を示します。この方法は、他の音声生成および分析タスクに適用できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-27">
        <br>2020-02-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Annotation of Emotion Carriers in Personal Narratives -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.CL/paper_7.html">
      Annotation of Emotion Carriers in Personal Narratives
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ニュースやマイクロブログなどの他のテキストのジャンルと比較して、話されたPNは、ナレーターが知覚する思考や関連する感情だけでなく、複数のサブイベントやキャラクターを含む物語が通常構造化されていないため、特に困難です。この作品は、注釈を提案し、評価します話された個人的な物語における感情キャリアを識別するためのモデル。ユーザーの感情的な状態を説明します。これらのセグメントは、anne anne anneの発案であり、このリソースを使用して感情キャリアを抽出できると考えています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-27">
        <br>2020-02-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Integrating Boundary Assembling into a DNN Framework for Named Entity
  Recognition in Chinese Social Media Text -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.CL/paper_8.html">
      Integrating Boundary Assembling into a DNN Framework for Named Entity
  Recognition in Chinese Social Media Text
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、最新のディープニューラルネットワークモデルと境界組み立て方法を統合し、名前付きエンティティ認識のために、更新された単語境界情報を条件付きランダムフィールドモデルに組み込みます。不適切に対処すると、カスケードが生成される可能性があります。その後、名前付きエンティティの認識の質が低下しました。この方法は、以前の最先端の結果に対して2％の絶対的な改善を示しています。 
[ABSTRACT]中国語テキストの名前付きエンティティ認識は、単語境界検出の恩恵を受けることができます。中国語の単語境界もエンティティ情報です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-27">
        <br>2020-02-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Streaming automatic speech recognition with the transformer model -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.CL/paper_9.html">
      Streaming automatic speech recognition with the transformer model
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これを達成するために、エンコーダーに時間制限付きの自己注意を適用し、エンコーダーデコーダー注意機構にトリガーされた注意を適用します。私たちの知る限りでは、このタスクに対して公開されたストリーミングエンドツーエンドASRの最高の結果が得られます。この作業では、各A語。 
[概要]トランスフォーマーアーキテクチャは、リカレントニューラルネットワーク（rnn）ベースのシステムアーキテクチャと比較して、大幅に低いワードエラー率（wers）を達成することが示されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-08">
        <br>2020-01-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Binarized PMI Matrix: Bridging Word Embeddings and Hyperbolic Spaces -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.CL/paper_10.html">
      Binarized PMI Matrix: Bridging Word Embeddings and Hyperbolic Spaces
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      経験的に、そのようなグラフは複雑なネットワークです。 SGNS目的でシグモイド変換を削除しても、単語ベクトルの品質に重大な悪影響を与えず、同時に特定のグラフの隣接行列として扱うことができる2値化PMI行列の因数分解に関連していることを分析的に示します。 。強力なクラスタリングとスケールフリーの次数分布を持ち、双曲線空間と密接に関連しています。 
[概要]二値化されたpmi行列を介して、静的な単語の埋め込みと双曲線空間の関係を示します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-27">
        <br>2020-02-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Training language GANs from Scratch -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.CL/paper_11.html">
      Training language GANs from Scratch
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      言語バッチを安定化および改善するために、大規模なバッチサイズ、高密度の報酬、および弁別子の正則化などの既存の手法を組み合わせます。結果のモデルであるScratchGANは、品質と多様性の指標に従って、EMNLP2017 NewsおよびWikiText-103コーパスの最尤トレーニングに匹敵します。 。私たちは、実際に言語GANを最初から訓練することが可能であることを示します-最尤事前訓練なしで。 
[概要]結果のモデルscratchganは、品質と多様性の指標に従って、最尤トレーニングに匹敵する性能を発揮します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-23">
        <br>2019-05-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Analysis of diversity-accuracy tradeoff in image captioning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.CL/paper_12.html">
      Analysis of diversity-accuracy tradeoff in image captioning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、キャプションセットの精度と多様性の両方を単一の値で評価するための新しいメトリックAllSPICEを提案します。自動生成された画像の多様性に対する異なるモデルアーキテクチャ、トレーニング目標、ハイパーパラメータ設定、およびデコード手順の影響を調査しますキャプション..我々の結果は、1）低温と組み合わせた単純なサンプリングによる単純なデコードが、多様で正確なキャプションセットを作成するための競争力のある高速な方法であることを示しています。 2）強化学習を使用したCIDErベースの報酬でのトレーニングは、結果のジェネレーターの多様性プロパティに害を及ぼします。これは、デコードパラメーターを操作しても軽減できません。 
[要約]デコードの新しいモデルは、さまざまな要因からのデータに基づいています。また、データがどのようになっているかをテストできることもわかりました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-27">
        <br>2020-02-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Primer in BERTology: What we know about how BERT works -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.CL/paper_13.html">
      A Primer in BERTology: What we know about how BERT works
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      トランスフォーマーベースのモデルは現在、NLPで広く使用されていますが、その内部の仕組みについてはまだあまり理解していません.2019）、40を超える分析研究を統合しています。その後、さらなる研究の方向性を概説します。 
[要旨]新しい論文には、有名なバートモデルに関するこれまでに知られているものがリストされています。これには、モデルとそのトレーニング体制に対する提案された変更に関する詳細かつ詳細な研究が含まれています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-27">
        <br>2020-02-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Portuguese Named Entity Recognition using BERT-CRF -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.CL/paper_14.html">
      Portuguese Named Entity Recognition using BERT-CRF
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの微調整アプローチは、HAREM Iデータセットで最新の結果を取得し、選択的シナリオで1ポイント（5 NEクラス）、合計シナリオで4ポイント（10 NEクラス）のF1スコアを改善します。 ）..事前学習済みの言語モデルの活用により、多くのタスクの全体的なパフォーマンスが向上し、ラベル付きデータが少ない場合に非常に有益であることが示されています。ニューラルネットワークを使用した言語表現の最近の進歩により、学習したデータを転送できるようになりました名前付きエンティティ認識（NER）や質問応答など、下流の自然言語処理タスクに対するトレーニング済みモデルの内部状態。 
[概要]自然言語モデルの活用が示されています。bertモデルから学習する方法を理解する方法の役割を調査します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-23">
        <br>2019-09-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Few-shot Natural Language Generation for Task-Oriented Dialog -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.CL/paper_15.html">
      Few-shot Natural Language Generation for Task-Oriented Dialog
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      FewShotWozと大規模なMulti-Domain-WOZデータセットの実験は、提案されたSC-GPTが、さまざまな自動メトリックと人間の評価によって測定された既存の方法を大幅に上回ることを示します。さらに、SC-GPTモデルを開発します。制御可能な生成能力を獲得するために注釈付きのNLGコーパスの大規模なセットで、新しいドメインに適応するために少数のドメイン固有のラベルのみで微調整されています。 
[概要]従来のテンプレートベースのモデルの成功は、通常、新しいドメインでは実行不可能な大量の注釈付きデータに依存しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-27">
        <br>2020-02-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards a Human-like Open-Domain Chatbot -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/cs.CL/paper_16.html">
      Towards a Human-like Open-Domain Chatbot
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの実験は、複雑さとSSAの間に強い相関関係があることを示しています。さらに、Meenaのフルバージョン（フィルタリングメカニズムと調整されたデコードを使用）は、評価した既存のチャットボットよりも絶対SSAが23％高いSSAを79％獲得しました。マルチターンのオープンドメインチャットボットは、パブリックドメインのソーシャルメディアの会話からマイニングおよびフィルタリングされたデータをエンドツーエンドでトレーニングしました。 
[概要]ヒューマンネットワークは、次のトークンの複雑さを最小限に抑えるように単純に訓練されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-27">
        <br>2020-01-27
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Environment Sound Classification using Multiple Feature Channels and
  Attention based Deep Convolutional Neural Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/eess.AS/paper_0.html">
      Environment Sound Classification using Multiple Feature Channels and
  Attention based Deep Convolutional Neural Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの知る限り、単一の環境音分類モデルが3つのデータセットすべてで最先端の結果を達成できるのはこれが初めてです。当社のモデルは最先端を達成することができます3つのベンチマーク環境すべての音分類データセットでのパフォーマンス。このような複数の機能は、信号処理や音声処理に使用されたことはありません。 
[ABSTRACT]複数の機能チャネルには、mel-周波数ケプストラム度（mfcc）、ガンマトーン周波数ケプストラムエントリ（gfcc）、定数q-変換（cqt）およびクロマグラムが含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-28">
        <br>2019-08-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ASVspoof 2019: a large-scale public database of synthetic, converted and
  replayed speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/eess.AS/paper_1.html">
      ASVspoof 2019: a large-scale public database of synthetic, converted and
  replayed speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、2019年版には、固定ASVシステムの信頼性に対するスプーフィングと対策の影響を反映するタンデム検出コスト関数メトリックの使用も新たに追加されました。また、論理アクセスにおけるスプーフィングされたデータに関する人間の評価についても説明しています。論理アクセス（LA）シナリオ内の攻撃は、最新の神経音響および波形モデル技術を含む最新の音声合成および音声変換技術を使用して生成されます。 
[要約] asvは、「プレゼンテーション攻撃」としても知られるスプーフィングに対して脆弱です。asvシステムは、リプレイ、音声合成、および音声変換攻撃に対しても脆弱です。これらのシステムは、2つの特定のユースケースシナリオで検討されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-05">
        <br>2019-11-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Density Ratio Approach to Language Model Fusion in End-To-End
  Automatic Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/eess.AS/paper_2.html">
      A Density Ratio Approach to Language Model Fusion in End-To-End
  Automatic Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたアプローチは、クロスドメインおよび限られたデータのシナリオで評価され、LMトレーニングにはかなりの量のターゲットドメインテキストデータが使用されますが、トレーニングには限られた（またはまったくない）{audio、transcript}トレーニングデータペアのみが使用されます密度比法は、LMおよびエンドツーエンドのASR統合であるShallow Fusionへの支配的なアプローチよりも一貫して優れていることがわかりました。音声検索データに一般化する能力について評価されました。 
[概要]提案された方法は、ベイズのルールを使用して、ターゲットドメインのrnn-t事後を定義します。これは、ディープニューラルネットワーク（dnns）またはlstmsに基づくasrのタイプに基づいています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-26">
        <br>2020-02-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An Open-set Recognition and Few-Shot Learning Dataset for Audio Event
  Classification in Domestic Environments -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/eess.AS/paper_3.html">
      An Open-set Recognition and Few-Shot Learning Dataset for Audio Event
  Classification in Domestic Environments
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      オーディオ領域では、音楽詐欺や話者認識はFSLメソッドから明らかに恩恵を受けることができます。このペーパーでは、ドアベルや火災などのさまざまな種類の音響アラームによって与えられる特定の意図的な音響イベントの検出へのFSLの適用を扱います限られた数のサンプルを使用したアラーム。したがって、実用的なシナリオでのそのようなアラームの検出は、オープンセット認識（OSR）問題と見なすことができます。 
[ABSTRACT] fslは小さなデータセットを使用して、特定の意図的なイベントを検出します。これらには、ドアベル、火災警報器、ドアベルが含まれます。これらの音は、オープンセット認識（osr）問題と見なすことができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-26">
        <br>2020-02-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The sound of my voice: speaker representation loss for target voice
  separation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/eess.AS/paper_4.html">
      The sound of my voice: speaker representation loss for target voice
  separation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、残留スペクトログラム出力からターゲットスピーカー情報を削除するための追加基準としてトリプレットスピーカー表現損失を提案します。VoiceFilterフレームワークを採用して、VCTKデータベースを使用してソース分離パフォーマンスを評価し、追加のネットワークパラメータ..従来のスペクトル再構成と比較して、提案されたフレームワークは、参照のスピーカー表現とソース分離出力間の距離を最小化することにより、ターゲットスピーカー情報の使用を最大化します。 
[ABSTRACT] voicefilterフレームワークは、vctkデータベースを使用してソース分離パフォーマンスを評価するために採用されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-06">
        <br>2019-11-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SkinAugment: Auto-Encoding Speaker Conversions for Automatic Speech
  Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/eess.AS/paper_5.html">
      SkinAugment: Auto-Encoding Speaker Conversions for Automatic Speech
  Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、アプローチを機械翻訳されたトランスクリプトによる拡張と組み合わせて、English $ \ to $ French ASTタスクで非常に強力なカスケードモデルよりも優れた競合エンドツーエンドASTモデルを取得できることを示します。 English $ \ to $ FrenchおよびEnglish $ \ to $ Romanian自動音声翻訳（AST）タスクおよび低リソースの英語自動音声認識（ASR）タスクでのSpecAugmentに有利です。さらに、アブレーションでは、拡張データの量と多様性の両方の利点。 
[要約]拡張データの量と多様性の両方の利点を示します。この方法は、他の音声生成および分析タスクに適用できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-27">
        <br>2020-02-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Streaming automatic speech recognition with the transformer model -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/eess.AS/paper_6.html">
      Streaming automatic speech recognition with the transformer model
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、自己注意を使用して時間コンテキスト情報をモデル化するトランスフォーマアーキテクチャは、リカレントニューラルネットワーク（RNN）ベースのシステムアーキテクチャと比較して、大幅に低いワードエラー率（WER）を達成することが示されています。 -エンコーダの自己注意を制限し、エンコーダとデコーダのアテンションメカニズムの注意をトリガーします。その成功にもかかわらず、エンコーダとデコーダのアーキテクチャは通常、音声発話全体を入力として必要とするため、実際の使用はオフラインASRタスクに限定されます。 
[概要]トランスフォーマーアーキテクチャは、リカレントニューラルネットワーク（rnn）ベースのシステムアーキテクチャと比較して、大幅に低いワードエラー率（wers）を達成することが示されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-08">
        <br>2020-01-08
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Low-protein/high-carbohydrate diet induces AMPK-dependent canonical and non-canonical thermogenic response in subcutaneous adipose tissue -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-28/biorxiv.physiology/paper_0.html">
      Low-protein/high-carbohydrate diet induces AMPK-dependent canonical and non-canonical thermogenic response in subcutaneous adipose tissue
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ベージュの脂肪細胞では、AMPKの活性化がUcp1とSercaの両方に依存するエネルギー散逸を維持する脂肪の異化を促進し、アミノ酸の低下を引き起こすことを観察しました。しかし、LPHCダイエットが代謝の利点につながる複雑な分子基盤私たちは、ミトコンドリアの活性酸素種が、アミノ酸制限されたベージュ脂肪細胞のAMPK媒介代謝再配線を制御する上流分子であることを観察しました。 
[概要] ampkの活性化を制限すると、ucp1やsercaを含む茶色の脂肪や筋肉の遺伝子、およびミトコンドリアの酸化遺伝子の発現が抑制されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-27">
        <br>2020-02-27
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
