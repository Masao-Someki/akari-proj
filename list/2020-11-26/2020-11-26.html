<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-11-26の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Detection and Evaluation of human and machine generated speech in
  spoofing attacks on automatic speaker verification systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.SD/paper_0.html">
      <font color="black">Detection and Evaluation of human and machine generated speech in
  spoofing attacks on automatic speaker verification systems</font>
    </a>
  </h2>
  <font color="black">この論文では、ブラックボックスおよびホワイトボックスASVシステムで、人間のなりすまし（音声偽装）ベースの攻撃の可能性を、マシン生成音声に基づく攻撃と比較します。基本的な周波数シーケンス関連のエントロピー、スペクトルエンベロープを示します。 、および非周期的パラメータは、未知の方法で生成された偽造音声のロバスト検出の有望な候補です。また、機械は細かいレベルの複雑さの多くをエミュレートできないという仮説の下で、人間の音声生成の固有の側面をキャプチャする機能を使用して対策を研究します。人間の音声生成メカニズムの。 
[概要]使用される手法は悪意のある攻撃に対して脆弱であることがよくあります。これにより、詐欺師はシステムをバイパスしてアクセスできます。また、人間の音声生成の独自の側面をキャプチャする機能を使用して対策を検討します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-07">
        <br><font color="black">2020-11-07</font>
      </time>
    </span>
</section>
<!-- paper0: A Lightweight Music Texture Transfer System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.SD/paper_1.html">
      <font color="black">A Lightweight Music Texture Transfer System</font>
    </a>
  </h2>
  <font color="black">このシステムを複数の観点から評価し、実験結果から、効果音と計算性能の両方で説得力のある結果が得られることが明らかになりました。そのコアアルゴリズムは、サウンドをテクスチャスペクトルとして表すコンバータ、対応するリコンストラクタ、フィードフォワード転送で構成されています。ネットワーク..この論文では、音楽のテクスチャを転送するための新しいシステムを開始し、それをオープンソースプロジェクトとしてリリースします。 
[概要]ニューヨークを拠点とする調査によると、データの使用は公開されていませんが、ニューラルネットワークを使用した音楽機能の転送の新しい方法は公開されていません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-09-27">
        <br><font color="black">2018-09-27</font>
      </time>
    </span>
</section>
<!-- paper0: MTCRNN: A multi-scale RNN for directed audio texture synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.SD/paper_2.html">
      <font color="black">MTCRNN: A multi-scale RNN for directed audio texture synthesis</font>
    </a>
  </h2>
  <font color="black">さまざまなデータセットでのモデルのパフォーマンスを示し、さまざまなメトリックでのパフォーマンスを調べ、いくつかの潜在的なアプリケーションについて説明します。これらの複雑なサウンドには複数のタイムスケールのパターンが含まれているため、従来の方法でモデル化するのは困難です。雨、風、エンジンなどの日常の音。 
[概要]テクスチャには、雨、風、エンジンなどの工業用音が含まれます。これらの音は、単純な音で定義されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Deep generative models for musical audio synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.SD/paper_3.html">
      <font color="black">Deep generative models for musical audio synthesis</font>
    </a>
  </h2>
  <font color="black">さらに、機械学習システムは、これらのモデルの制御およびナビゲーション戦略を設計するための新しい手法を提供しています。オーディオ合成用の最近の生成的深層学習システムは、トレーニングするデータによって定義される音の任意の空間を横断できるモデルを学習できます。これはペーパーは、サウンドモデリングの実践を変えているディープラーニングの開発のレビューです。 
[概要]ディープラーニング技術の研究が進行中です。これには、音響特性をキャプチャするための要素の組み立てと処理、録音されたオーディオサンプルのコレクションの操作が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-10">
        <br><font color="black">2020-06-10</font>
      </time>
    </span>
</section>
<!-- paper0: Vocal Tract Length Perturbation for Text-Dependent Speaker Verification
  with Autoregressive Prediction Coding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.SD/paper_4.html">
      <font color="black">Vocal Tract Length Perturbation for Text-Dependent Speaker Verification
  with Autoregressive Prediction Coding</font>
    </a>
  </h2>
  <font color="black">実験は、ガウス混合モデル-ユニバーサルバックグラウンドモデルとi-ベクトル手法を使用した短い発話を使用して、TD-SVのRedDotsチャレンジ2016データベースで実行されます。最後に、MFCCでトレーニングされたVTL摂動システムと2つのBN機能を組み合わせます。スコアドメイン..次に、提案されたVTLメソッドがAPCおよび話者識別BN機能に適用されます。 
[概要]提案されたシステムは、スコアドメインのmfccと2つのbn機能に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Non-Attentive Tacotron: Robust and Controllable Neural TTS Synthesis
  Including Unsupervised Duration Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.SD/paper_5.html">
      <font color="black">Non-Attentive Tacotron: Robust and Controllable Neural TTS Synthesis
  Including Unsupervised Duration Modeling</font>
    </a>
  </h2>
  <font color="black">トレーニングデータで正確なターゲット期間が不足しているか利用できない場合は、細粒度の変分オートエンコーダーを使用して、半教師ありまたは教師なしの方法で期間予測子をトレーニングする方法を提案します。結果は、教師ありトレーニングとほぼ同じです。ガウスアップサンプリングを使用すると、教師なしタコトロンは、自然性について5スケールの平均意見スコア4.41を達成し、タコトロン2をわずかに上回ります。持続時間予測子は、推論時間での持続時間の発話全体と電話ごとの両方の制御を可能にします。 
[概要]これは、アラインされていないマナー比率と単語の削除率に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Interpreting Imagined Speech Waves with Machine Learning techniques -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.SD/paper_6.html">
      <font color="black">Interpreting Imagined Speech Waves with Machine Learning techniques</font>
    </a>
  </h2>
  <font color="black">実験結果に基づいて、単語の長さと複雑さを使用してIS信号を高精度でデコードでき、BCIシステムをコンピューターインタラクション用のIS信号で設計できることを提案します。実験結果に基づいて、NNをフィードフォワードします。アンサンブルおよび共分散行列変換された機能を備えたモデルは、他の既存の方法と比較して最高のパフォーマンスを示しました。この作業では、ヒューマンコンピューターインターフェイス（HCI）の新しい設計を作成するために使用できるImagined Speech（IS）信号をデコードする可能性を探ります。 。 
[概要]脳波信号を生成するプロセスは不明です。さまざまな特徴抽出方法を使用してデータ分布を定義し、信号を分類します。これらの結果は、商用レベルのbciシステムの開発の方向性を示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-07">
        <br><font color="black">2020-10-07</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-task Language Modeling for Improving Speech Recognition of Rare
  Words -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.SD/paper_7.html">
      <font color="black">Multi-task Language Modeling for Improving Speech Recognition of Rare
  Words</font>
    </a>
  </h2>
  <font color="black">これらの追加タスクでトレーニングされた再スコアリングモデルは、言語モデリングタスクのみでトレーニングされたベースライン再スコアリングモデルよりも、一般テストで1.4％、単語エラーの観点から設定されたまれな単語テストで2.6％優れていることを示します。レート相対（WERR）..エンドツーエンド自動音声認識（ASR）システムは、その相対的なアーキテクチャの単純さと競争力のあるパフォーマンスのためにますます人気があります。この論文では、マルチタスク学習を備えたセカンドパスシステムを提案します。セマンティックターゲット（インテントやスロット予測など）を利用して、音声認識のパフォーマンスを向上させます。 
[概要]新しい研究では、音声認識のパフォーマンスを向上させるためにマルチタスク学習を備えたセカンドパスシステムを提案しています。音声認識を向上させるためにセマンティックターゲットを使用したセカンドパスシステムを提案しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Phase retrieval with Bregman divergences: Application to audio signal
  recovery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.SD/paper_8.html">
      <font color="black">Phase retrieval with Bregman divergences: Application to audio signal
  recovery</font>
    </a>
  </h2>
  <font color="black">オーディオ信号処理アプリケーションに適したダイバージェンスを含む、ブレグマンダイバージェンスに基づく別の定式化を提案します。この問題を解決するために高速勾配アルゴリズムを導出します。これは、2次コスト関数を含む最小化問題を検討することによって対処されることがよくあります。 
[ABSTRACT]スピードアップスピードアップスピードアップ、スピードアップ、スピードアップ。最小化問題を考慮することで解決されることがよくあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: SAR-Net: A End-to-End Deep Speech Accent Recognition Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.SD/paper_9.html">
      <font color="black">SAR-Net: A End-to-End Deep Speech Accent Recognition Network</font>
    </a>
  </h2>
  <font color="black">私たちの深いフレームワークはマルチタスク学習メカニズムを採用しており、主に3つのモジュールで構成されています。共有CNNおよびRNNベースのフロントエンドエンコーダー、コアアクセント認識ブランチ、および音声スペクトログラムを入力として受け取る補助音声認識ブランチです。 、共有エンコーダから学習したシーケンシャル記述子を使用して、アクセント認識ブランチは最初にすべての記述子を埋め込みベクトルに凝縮し、次に、埋め込み識別を強化するために顔認識ドメインで人気のあるさまざまな識別損失関数を探索します。同じ言語でアクセントの種類を認識するためのto-endディープネットワーク。ここでは、話者認識領域のディープアーキテクチャを開発し、発話レベルのアクセント表現を学習するためのアクセント分類タスクに転送します。 
[ABSTRACT]アクセント認識は、同じアクセントを持つスピーカーのコンパクトなグループレベルの機能を取得する上でより難しい問題です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Feature Selection based on Principal Component Analysis for Underwater
  Source Localization by Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.SD/paper_10.html">
      <font color="black">Feature Selection based on Principal Component Analysis for Underwater
  Source Localization by Deep Learning</font>
    </a>
  </h2>
  <font color="black">この特徴選択方法は、半教師あり学習スキームに基づく水中ソースローカリゼーションの2ステップフレームワークと組み合わされます。2番目のステップは、の限られたラベル部分でトレーニングされたエンコーダ多層パーセプトロン（MLP）を介してソースローカリゼーションを実行します。データセット..結果は、特にトレーニングに使用されるデータの数が徐々に減少する場合に、フレームワークが目に見えないデータに対して魅力的な精度と堅牢性を備えていることを示しています。 
[概要]この特徴選択方法は、2ボーレスシステムと組み合わされます。最初のステップでは、エンコーダーを介してソースのローカリゼーションを実行します。2番目のステップでは、データセット</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Light Field Image Super-Resolution Using Deformable Convolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_0.html">
      <font color="black">Light Field Image Super-Resolution Using Deformable Convolution</font>
    </a>
  </h2>
  <font color="black">さらに、ベースライン調整可能なLFデータセットを開発して、さまざまな視差変動下でのSRパフォーマンスを評価します。LF-DFnetは、より忠実な詳細を備えた高解像度画像を生成し、最先端の再構成精度を実現できます。 、我々は、LF画像SRの視差問題を処理するために変形可能な畳み込みネットワーク（すなわち、LF-DFnet）を提案します。 
[概要]私たちのアプローチを使用すると、角度情報を適切に組み込み、各ビューの特徴にエンコードすることができます。これらの特徴は、すべてのlf画像のsr再構成に役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Evaluation of quality measures for color quantization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_1.html">
      <font color="black">Evaluation of quality measures for color quantization</font>
    </a>
  </h2>
  <font color="black">本論文では、9つの有名で一般的に使用されているフルリファレンス画質評価尺度の定量的性能評価を提案し、実行します。結果は、主観的な人間との相関の観点から、より近い性能を持つ品質尺度を示しています。色量子化の品質測定の統計的パフォーマンスの評価は、各データベースで同様の傾向を維持しながら、選択した画質データベースによって大きく影響を受けることを評価し、示します。これは、色量子化評価を必要とする幅広いアプリケーションがあるにもかかわらずです。少ない色数で色ベースのタスクをより効率的に実行する場合の前処理ステップとして使用されます。 
[概要]評価は、色の量子化劣化に関する2つの公開され、定量的に評価された画質データベースを使用して行われます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: CT-based COVID-19 Triage: Deep Multitask Learning Improves Joint
  Identification and Severity Quantification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_2.html">
      <font color="black">CT-based COVID-19 Triage: Deep Multitask Learning Improves Joint
  Identification and Severity Quantification</font>
    </a>
  </h2>
  <font color="black">最も一般的なマルチタスクアプローチとは対照的に、U-Netの下部ではなく、空間的に詳細な上部に分類レイヤーを追加します。同様の問題は個別に十分に研究されていますが、既存の方法が提供することを示します。これらの設定の1つに対してのみ妥当な品質。現在のCOVID-19パンデミックは、放射線科を含む医療システムに過負荷をかけています。 
[概要]最も詳細なusct分析アプローチのいくつかが開発されました。しかし、コンピュータサイエンスの問題として研究トライタスクを検討した人は誰もいませんでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-02">
        <br><font color="black">2020-06-02</font>
      </time>
    </span>
</section>
<!-- paper0: Physics-informed neural networks for myocardial perfusion MRI
  quantification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_3.html">
      <font color="black">Physics-informed neural networks for myocardial perfusion MRI
  quantification</font>
    </a>
  </h2>
  <font color="black">この研究では、心筋灌流MRの定量化を実行する手段として、物理情報に基づくニューラルネットワーク（PINN）を紹介します。これにより、運動パラメータを推測するための多様なスキームが提供されます。これらのニューラルネットワークは、観察された灌流MRデータに合わせてトレーニングできます。マルチコンパートメント交換モデルによって記述された基礎となる物理的保存法..ここでは、心筋灌流MRでPINNを実装するためのフレームワークを提供します。 
[概要]これらのニューラルネットワークは、ピンの観測データに適合するようにトレーニングできます。これは、動的であり、血流と微小血管機能を直接解決するためです。ただし、これにより、モデルモデルモデルモデルが不正確になる可能性があります。これにより、モデルモデルが改善される可能性があります。インシリコとマウスの両方のモデルモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Data-driven regularization parameter selection in dynamic MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_4.html">
      <font color="black">Data-driven regularization parameter selection in dynamic MRI</font>
    </a>
  </h2>
  <font color="black">2番目のアプローチでは、スパース性ベースのパラメーター選択は、Sカーブ法を使用して2つの1D検索に分割されます。予想されるスパース性レベルは、時間正則化の測定データと空間正則化の参照画像から取得されます。 1つ目は、時間的および空間的正則化ドメインの両方で期待されるスパース性を生成するパラメーターペアの2D検索です。 
[ABSTRACT]モデルは、圧縮センシング（cs）ベースの再構成アプローチの人気につながりました。1つのアプローチでは、データ駆動型アプローチが全変動正則化ツールに提案されます。再構成により、正則化ドメインから期待されるスパース性レベルが得られます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-03">
        <br><font color="black">2020-04-03</font>
      </time>
    </span>
</section>
<!-- paper0: Privacy Preserving for Medical Image Analysis via Non-Linear Deformation
  Proxy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_5.html">
      <font color="black">Privacy Preserving for Medical Image Analysis via Non-Linear Deformation
  Proxy</font>
    </a>
  </h2>
  <font color="black">私たちのシステムには3つのコンポーネントがあります：1）疑似ランダム変形関数を生成するフローフィールドジェネレータ、2）処理された画像から患者のアイデンティティを学習するシャム弁別器、3）コンテンツを分析する医用画像処理ネットワークプロキシイメージ..システムは敵対的な方法でエンドツーエンドでトレーニングされます。これにより、プロキシイメージが生成され、サーバーに送信されて処理されます。 
[要約]サーバーは、クライアントが元に戻す変形されたプロセスを返します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Image Embedded Segmentation: Uniting Supervised and Unsupervised
  Objectives for Segmenting Histopathological Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_6.html">
      <font color="black">Image Embedded Segmentation: Uniting Supervised and Unsupervised
  Objectives for Segmenting Histopathological Images</font>
    </a>
  </h2>
  <font color="black">この提案は、同じ正則化の目的で画像再構成を使用する既存のアプローチとは異なります。既存のアプローチは、セグメンテーションと画像再構成をマルチタスクネットワークの2つの別個のタスクと見なし、それらの損失を個別に定義し、それらを結合して共同損失にします。次に、このメソッドは、条件付きの生成的敵対的ネットワークを使用して、入力画像をこの埋め込み出力画像に変換することを学習します。これは、画像から画像への変換に非常に効果的であることが知られています。 
[要約]この方法は、ネットワークトレーニングのための、画像再構成の形での教師なし学習の利点に依存しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br><font color="black">2020-01-30</font>
      </time>
    </span>
</section>
<!-- paper0: The Unreasonable Effectiveness of Encoder-Decoder Networks for Retinal
  Vessel Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_7.html">
      <font color="black">The Unreasonable Effectiveness of Encoder-Decoder Networks for Retinal
  Vessel Segmentation</font>
    </a>
  </h2>
  <font color="black">さらに、このフレームワーク（VLightと呼ばれる）が特定のトレーニング画像への過剰適合を回避し、さまざまなデータセット間で十分に一般化されることを示します。これにより、高解像度の眼底画像での堅牢性、精度、および推論時間が短い実際のアプリケーションに非常に適しています。トレーニング中の複数の画像スケールでの大規模パッチの抽出に依存する網膜画像の血管のセグメンテーションのためのエンコーダ-デコーダフレームワークを提案します。3つの眼底画像データセットでの実験は、このアプローチが達成することを示しています。最先端の結果であり、0.8M未満のパラメータ数でシンプルで効率的な完全畳み込みネットワークを使用して実装できます。 
[ABSTRACT]画像は、このアプローチが最先端の結果を達成することを示しています。シンプルで効率的な完全畳み込みネットワークを使用して実装できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Interpreting U-Nets via Task-Driven Multiscale Dictionary Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_8.html">
      <font color="black">Interpreting U-Nets via Task-Driven Multiscale Dictionary Learning</font>
    </a>
  </h2>
  <font color="black">これらの結果は、U-Netの成功は、主にそのマルチスケールアーキテクチャと誘導されたスパース表現によって説明できることを示唆しています。これは、標準のU-Netから特定のマルチスケール畳み込み辞書を抽出することによって実現されます。この辞書は、 U-Netは、畳み込み、スケール分離、および接続のスキップの側面で、非線形部分を排除します。 
[概要]私たちの研究者は、強力なラボパフォーマンスを維持しながら、au-netを畳み込みのよく理解された辞書モデルに縮小することができました。これらの結果は、u-netの成功は主にそのマルチスケールアーキテクチャと誘導された密な表現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Single-Image Lens Flare Removal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_9.html">
      <font color="black">Single-Image Lens Flare Removal</font>
    </a>
  </h2>
  <font color="black">既存のソフトウェアメソッドは、アーティファクトのジオメトリまたは明るさについて強い仮定を行うため、フレアの小さなサブセットのみを処理します。実験によると、モデルはさまざまなデバイスによってキャプチャされた実際のレンズフレアによく一般化され、最先端の性能を上回ります。 PSNRで3dBの方法。このパイプラインによって生成された半合成データを使用して、レンズフレアを除去するためのニューラルネットワークを構築します。 
[ABSTRACT]フレアは、レンズ内での複数の反射、またはレンズの傷やほこりによる散乱によって発生します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Semantic Labeling of Large-Area Geographic Regions Using Multi-View and
  Multi-Date Satellite Images and Noisy OSM Training Labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_10.html">
      <font color="black">Semantic Labeling of Large-Area Geographic Regions Using Multi-View and
  Multi-Date Satellite Images and Noisy OSM Training Labels</font>
    </a>
  </h2>
  <font color="black">私たちのシステムのユニークな（そしておそらく驚くべき）特性は、マルチビューデータから学習するためにCNNのテールエンドに追加された変更を、推論時に破棄できることです。全体的なパフォーマンス..さらに、私たちのアプローチでは、シーンごとに最大32ビューでトレーニングする場合でも、GPUメモリ消費の点でわずかなオーバーヘッドしか追加されません。人間の監督なしで、建物と道路のクラスのIoUスコアは0.8です。それぞれ0.64であり、OSMラベルを使用し、完全に自動化されていない最先端のアプローチよりも優れています。 
[概要]マルチビューセマンティックセグメンテーションへのアプローチでは、クラスごとのiouスコアが4〜7％向上します。これは、ビューを互いに独立して使用する従来のアプローチと比較されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Rank-One Network: An Effective Framework for Image Restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_11.html">
      <font color="black">Rank-One Network: An Effective Framework for Image Restoration</font>
    </a>
  </h2>
  <font color="black">RO分解は、破損した画像をRO成分と残差に分解するために開発されました。画像の復元ではROプロパティを利用し、間引きを回避することをお勧めします。ニューラルネットワークに基づくRO投影は、最も近いものを抽出します。画像のRO成分。 
[概要]破損した画像のro成分は、画像のノイズ除去の手順によって間引きされる可能性があります。これは、ro投影を画像またはその残差に適用して、ro成分を抽出することによって実現されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Contrastive Representation Learning for Whole Brain Cytoarchitectonic
  Mapping in Histological Human Brain Sections -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_12.html">
      <font color="black">Contrastive Representation Learning for Whole Brain Cytoarchitectonic
  Mapping in Histological Human Brain Sections</font>
    </a>
  </h2>
  <font color="black">この学習タスクを使用して事前トレーニングされたモデルは、最初からトレーニングされたモデル、および最近提案された補助タスクで事前トレーニングされたモデルよりも優れていることを示します。細胞構築マップは、脳の微細構造参照パーセルを提供し、その組織を用語で説明します。組織学的組織切片から測定された神経細胞体の空間配置の分析..最近の研究は、畳み込み神経ネットワークを使用した視覚系の細胞構築領域の最初の自動セグメンテーションを提供しました。 
[ABSTRACT]最近の研究により、畳み込みニューラルネットワークを使用した視覚系の細胞構造領域の最初の自動セグメンテーションが提供されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Reduced Reference Perceptual Quality Model and Application to Rate
  Control for 3D Point Cloud Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_13.html">
      <font color="black">Reduced Reference Perceptual Quality Model and Application to Rate
  Control for 3D Point Cloud Compression</font>
    </a>
  </h2>
  <font color="black">400個の圧縮された3D点群を使用した主観的品質テストは、提案されたモデルが平均オピニオン評点とよく相関し、スピアマンの順位係数とピアソンの線形相関係数の点で最先端の完全な参照客観的尺度を上回っていることを示しています。このアプローチの主な課題は、低い計算コストで計算でき、知覚品質とよく相関する品質指標を定義することです。さらに、同じターゲットビットレートに対して、提案されたモデルに基づくレートディストーション最適化がより高いものを提供することを示します。ポイントツーポイントの客観的品質メトリックを使用した徹底的な検索に基づくレート歪み最適化よりも知覚品質。 
[概要]同じターゲットビットレートに対して、提案されたモデルに基づくレート歪みの強化は、レートよりも高い知覚品質を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Neural network for estimation of optical characteristics of optically
  active and turbid scattering media -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_14.html">
      <font color="black">Neural network for estimation of optical characteristics of optically
  active and turbid scattering media</font>
    </a>
  </h2>
  <font color="black">その目標は、基礎となる構造を開業医によく理解させることでしたが、OCTイメージングの精度とイメージング品質を向上させる包括的なアプローチを提供することはできず、イメージング方法がどのように失敗するかについての一連の例しか提供しません。アプローチシミュレーションにより、基礎となる物理構造とそのOCTイメージングの対応物を1対1で比較できます。この問題を軽減し、ハードウェアを変更せずに医用画像を改善する新しいアプローチを示すために、モンテカルロで構成される新しいパイプラインを導入します。シミュレーションとそれに続く深い神経ネットワーク。 
[概要]この固有の問題は、干渉法の高解像度の場合でもイメージングエラーを引き起こします。この固有の性質の性質は問題の原因です。新しいアプローチを提示するために、モンテカルロシミュレーションを含む新しいパイプラインを紹介します。ディープニューラルネットワークによる</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Convolutional Neural Networks for cytoarchitectonic brain mapping at
  large scale -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_15.html">
      <font color="black">Convolutional Neural Networks for cytoarchitectonic brain mapping at
  large scale</font>
    </a>
  </h2>
  <font color="black">自動スキャン手順と観察者に依存しない方法は、細胞構築領域を確実に識別し、脳分離の再現可能なモデルを実現するための前提条件です。細胞構築マッピングにディープニューラルネットワークを適用すると、脳領域の高解像度モデルを可能にする新しい視点が開かれ、CNNを導入して識別します。脳領域の境界..これは、Deep Convolutional Neural Network（CNN）に基づいています。これは、注釈付きのセクション画像のペアでトレーニングされ、その間に多数の注釈なしセクションがあります。 
[ABSTRACT]細胞構築は、脳の微細構造組織の基本原理です。神経細胞の配置と構成の地域差は、接続性と機能の変化の指標です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Noise2Context: Context-assisted Learning 3D Thin-layer Low Dose CT
  Without Clean Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_16.html">
      <font color="black">Noise2Context: Context-assisted Learning 3D Thin-layer Low Dose CT
  Without Clean Data</font>
    </a>
  </h2>
  <font color="black">単一の3D薄層低線量CTスキャンで1つのノイズLDCT画像を2つの隣接するLDCT画像に同時にマッピングするように、ノイズ除去ニューラルネットワークをトレーニングしました。言い換えると、いくつかの潜在的な仮定を使用して、統合による教師なし損失関数を提案しました。教師なし方法でノイズ除去ニューラルネットワークをトレーニングするための3D薄層低線量CTでの隣接CTスライス間の類似性の評価..MayoLDCTデータセットと現実的な豚の頭でさらに実験を行い、既存の教師なし方法よりも優れたパフォーマンスを示しました。 3D薄スライスCTスキャンの場合、提案された仮想教師なし損失関数は、単一スキャンからの異なるスライスのノイズが無相関で平均がゼロの場合に、ノイズの多いクリーンなサンプルのペアを使用した教師なし損失関数と同等でした。 
[概要] 3Dスキャンでは、x-vising露出の増加に関する懸念がより注目されています。この論文では、ペアのクリーンデータなしでノイズ除去ニューラルネットワークをトレーニングするトレーニング方法を提案しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Cryo-RALib -- a modular library for accelerating alignment in cryo-EM -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_17.html">
      <font color="black">Cryo-RALib -- a modular library for accelerating alignment in cryo-EM</font>
    </a>
  </h2>
  <font color="black">多参照アラインメントに基づく従来の方法では、信号対ノイズ比（SNR）が低い場合に、微妙な構造の違いをより適切に区別できることに注意してください。分析を非常に困難にしました。この作業では、Cryo-RALibと呼ばれるモジュラーGPU加速アライメントライブラリが提案されています。 
[概要] 2019年の最初の構造-ncovスパイク三量体は、ワクチン開発に重要な医学的洞察を提供する、cryo-emを使用して3月に公開されました。データ特性には、強いノイズ、巨大な寸法、大きなサンプルサイズ、未知の方向での高い不均一性が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Simple statistical methods for unsupervised brain anomaly detection on
  MRI are competitive to deep learning methods -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_18.html">
      <font color="black">Simple statistical methods for unsupervised brain anomaly detection on
  MRI are competitive to deep learning methods</font>
    </a>
  </h2>
  <font color="black">すべての方法は、健康な症例と病理学的な症例のそれぞれ、専門家がキュレーションした新しいマルチパラメトリック（8シーケンス）ヘッドMRIデータセットでトレーニング（N = 395）および比較（N = 44）されました。これらの単純な方法がより正確である可能性があることを示します。小さな病変の検出において、トレーニングと理解がかなり容易です。方法は、AUCと平均精度を使用して定量的に比較され、脳萎縮、腫瘍（小さな転移）、および運動アーチファクトを含む臨床使用例で定性的に評価されました。 
[概要]ディープラーニング（mri）は、2Dデータの処理に有望であることが示されています。これらの単純な手法は、小さな病変をより正確に検出できます。トレーニングと理解が非常に簡単です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Iterative training of neural networks for intra prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_19.html">
      <font color="black">Iterative training of neural networks for intra prediction</font>
    </a>
  </h2>
  <font color="black">反復的にトレーニングされたニューラルネットワークをH.265（HM-16.15）に配置すると、平均dBレートの減少の-4.2％が得られます。それらをH.266（VTM-5.0）に移動することにより、平均dBレートの減少-1.9％に達します。さらに、反復プロセスにより、ニューラルネットワークトレーニングに不可欠なトレーニングデータクレンジングの設計が可能になります。 
[ABSTRACT]イントラ予測作業により、ネットワークはコーデックを改善できます。最初のコーデックにすでに存在するものよりも際立っているイントラ予測関数を学習し、レートの観点からコーデックをブーストできます-歪み</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-15">
        <br><font color="black">2020-03-15</font>
      </time>
    </span>
</section>
<!-- paper0: Open-World Learning Without Labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.IV/paper_20.html">
      <font color="black">Open-World Learning Without Labels</font>
    </a>
  </h2>
  <font color="black">ここでは、エージェントが教師なしの方法でラベルなしデータのストリームから新しいクラスを学習できるようにする新しいフレームワークを提案します。自律エージェントがほぼリアルタイムで応答するか、通信インフラストラクチャが限られている領域で作業する必要があるシナリオでは、データは不可能です。また、ラベルなしのオープンワールド学習のための新しいメトリックを導入します。 
[概要]自律的な真のオープン-世界の終わりのない学習エージェント。私たちの理論と方法は、自律的な真のオープン-世界の終わりのない学習を開発するための出発点になると期待しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Improving Augmentation and Evaluation Schemes for Semantic Image
  Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_0.html">
      <font color="black">Improving Augmentation and Evaluation Schemes for Semantic Image
  Synthesis</font>
    </a>
  </h2>
  <font color="black">拡張GANモデルを対応するバニラに対してベンチマークしている間、以前のセマンティック画像合成研究で報告された定量化メトリックは、外部の事前トレーニング済みセグメンテーションネットワークを介して導出されるため、特定のセマンティッククラスに強く偏っていることを発見しました。 3つの異なるデータセットにわたる最先端のセマンティック画像合成モデルを使用して、両方のクラス分割で拡張スキームを使用して得られた強力な定量的および定性的改善。データ拡張は、ディープニューラルネットワークのパフォーマンスを向上させるための事実上の手法ですが、生成的敵対的ネットワーク（GAN）の拡張戦略の開発にはほとんど注意が払われていません。 
[概要]ガンベースのセマンティック画像研究のために特別に作成された新しいセマンティック画像合成スキーム。この目的のために、超解像度モデルのために特別に設計された新しい拡張スキームを紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: A Sparse and Locally Coherent Morphable Face Model for Dense Semantic
  Correspondence Across Heterogeneous 3D Faces -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_1.html">
      <font color="black">A Sparse and Locally Coherent Morphable Face Model for Dense Semantic
  Correspondence Across Heterogeneous 3D Faces</font>
    </a>
  </h2>
  <font color="black">オリジナルの非剛体変形アルゴリズムとともに、3DMMが見えない顔に正確にフィットし、そのセマンティックアノテーションを任意の3D顔に転送できるようにする、顔のローカルサポートを備えたスパース変形コンポーネントのセットを学習するための新しい定式化を提案します。したがって、3DMMの記述力を高めるには、アイデンティティ、民族性、または表現の点で十分な多様性を備えた異種スキャン間で密な対応を正確に確立することが不可欠になります。密な登録の正確さは、異種の大規模な構築によって実証されます。 3つのデータセットを結合することによって取得された9,000を超える完全に登録されたスキャンからの3DMM。 
[概要] 3dotaを使用すると、フルポイントまたは電力対応のスキャンのトレーニングセットが可能になります。モデルを使用して、3dmmを使用して3dmmを構築できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-06">
        <br><font color="black">2020-06-06</font>
      </time>
    </span>
</section>
<!-- paper0: Transfer Learning for Aided Target Recognition: Comparing Deep Learning
  to other Machine Learning Approaches -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_2.html">
      <font color="black">Transfer Learning for Aided Target Recognition: Comparing Deep Learning
  to other Machine Learning Approaches</font>
    </a>
  </h2>
  <font color="black">分類のためのTLは、何十年にもわたって機械学習（ML）研究の活発な分野でしたが、深層学習フレームワーク内の転移学習は、比較的新しい研究分野のままです。深層学習（DL）は、最近の実際の世界の問題では、DLを使用することで他のMLアーキテクチャと比較して、どの程度の転送のメリットが得られるかについて、未解決の問題が残っています。私たちの目標は、DLフレームワーク内の転送学習を、転送タスクやデータセット全体で他のMLアプローチと比較することでこの欠点に対処することです。 
[ABSTRACT]ディープラーニング（dl）は、最近の現実世界の問題に対して卓越したモデリングの柔軟性と精度を提供します。ただし、dlと他のmmアーキテクチャを使用することで、転送のメリットがどれだけ得られるかについては疑問が残ります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Multiclass non-Adversarial Image Synthesis, with Application to
  Classification from Very Small Sample -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_3.html">
      <font color="black">Multiclass non-Adversarial Image Synthesis, with Application to
  Classification from Very Small Sample</font>
    </a>
  </h2>
  <font color="black">合成画像の生成は、現在、生成的敵対的ネットワーク（GAN）によって支配されています。この作業では、GANの制限のいくつかを克服する、新しい非敵対的生成手法である潜在空間のクラスター化最適化（COLA）を紹介します。トレーニングデータが不足している場合、GANを上回ります。完全なデータレジームでは、私たちの方法は、画質と多様性の点で以前の非敵対的方法を超えて、監視なしで多様なマルチクラス画像を生成できます。 
[ABSTRACT]新しい方法は、監視なしで多様なマルチクラス画像を生成することができます。完全なデータ体制では、小規模なサンプル分類タスクで最先端のパフォーマンスを上回ります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Object Keypoint Learning using Local Spatial Predictability -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_4.html">
      <font color="black">Unsupervised Object Keypoint Learning using Local Spatial Predictability</font>
    </a>
  </h2>
  <font color="black">さらに、AtariドメインのダウンストリームRLタスクでは、背景やディストラクタオブジェクトが移動する困難な環境でも、キーポイントを備えたエージェントが競合する代替手段を使用したエージェントよりも優れていることを示します。AtariでのPermaKeyの有効性を示し、最も顕著なオブジェクトパーツであり、特定の視覚的な注意散漫に対して堅牢です。これにより、動き、形状、色など、オブジェクトに固有ではない特性に焦点を合わせるためにキーポイントに過度のバイアスがかからないことが保証されます。
[要約]予測可能性を使用します局所画像領域を使用して、オブジェクトパーツに対応する顕著な領域を識別し、キーポイントに変換します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: StyleSpace Analysis: Disentangled Controls for StyleGAN Image Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_5.html">
      <font color="black">StyleSpace Analysis: Disentangled Controls for StyleGAN Image Generation</font>
    </a>
  </h2>
  <font color="black">最後に、実際の画像の操作に対するStyleSpaceコントロールの適用可能性を示します。これを示すために、新しく提案された属性依存性メトリックを使用します。次に、それぞれのスタイルチャネルの大規模なコレクションを検出する方法について説明します。これは、高度にローカライズされ、解きほぐされた方法で明確な視覚属性を制御することが示されています。 
[概要]最初に、styleslicaが以前の作品で調査された他の中間潜在空間よりも大幅に解きほぐされていることを示します。事前にトレーニングされた分類器または少数のサンプル画像を使用して、特定のオブジェクトを制御するスタイルチャネルを識別する簡単な方法を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Light Field Image Super-Resolution Using Deformable Convolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_6.html">
      <font color="black">Light Field Image Super-Resolution Using Deformable Convolution</font>
    </a>
  </h2>
  <font color="black">当社のLF-DFnetは、より忠実な詳細を備えた高解像度画像を生成し、最先端の再構成精度を実現できます。さらに、さまざまな視差変動の下でSRパフォーマンスを評価するために、ベースライン調整可能なLFデータセットを開発します。 LF画像間の不一致のため、角度情報を組み込むことは困難です。 
[概要]私たちのアプローチを使用すると、角度情報を適切に組み込み、各ビューの特徴にエンコードすることができます。これらの特徴は、すべてのlf画像のsr再構成に役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: DSAM: A Distance Shrinking with Angular Marginalizing Loss for High
  Performance Vehicle Re-identificatio -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_7.html">
      <font color="black">DSAM: A Distance Shrinking with Angular Marginalizing Loss for High
  Performance Vehicle Re-identificatio</font>
    </a>
  </h2>
  <font color="black">高性能車両ReIDモデルを取得するために、角度マージナリゼーション（DSAM）損失関数を使用した新しい距離縮小を提示し、ローカル検証とグローバル識別情報..実験結果は、DSAM損失がPKU-VD1-LargeデータセットでSoftMax損失を大幅に強化することを示しています：mAPで10.41％、cmc1で5.29％、cmc5で4.60％..具体的には、同じクラスのサンプル間の距離を元の特徴空間でローカルに縮小し、異なるクラスのサンプルを特徴角度空間で遠くに保ちます。 
[概要] dsam損失関数は、元の特徴空間でローカルに同じクラスのサンプル間の距離を縮小します。異なるクラスのサンプルを特徴の角度空間で遠くに保持します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Evaluation of quality measures for color quantization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_8.html">
      <font color="black">Evaluation of quality measures for color quantization</font>
    </a>
  </h2>
  <font color="black">本論文では、9つのよく知られた一般的に使用されているフルリファレンス画質評価尺度の定量的性能評価を提案し、実行します。評価は、色の量子化劣化について、2つの公開され主観的に評価された画質データベースを使用して行われます。そして、それらの適切な組み合わせまたはサブパートを検討することによって..また、多くのメソッドの形成、実装、最適化、およびテストにおいて中心的な役割を果たします。 
[概要]評価は、色の量子化劣化に関する2つの公開され、定量的に評価された画質データベースを使用して行われます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: StyleUV: Diverse and High-fidelity UV Map Generative Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_9.html">
      <font color="black">StyleUV: Diverse and High-fidelity UV Map Generative Model</font>
    </a>
  </h2>
  <font color="black">ただし、このような高品質のUVマップは、取得に費用がかかり、改良に手間がかかるため困難です。一方、Generative Adversarial Networks（GAN）の出現により、リアルな2D画像の再構築が大きく進歩しました。私たちが提案するフレームワークは、GANと差別化可能なレンダラーの組み合わせを活用することで、実際の画像のみでトレーニングできます（つまり、UVマップは必要ありません）。 
[概要]新しいマッピングモデルは、トレーニング用の高品質のUVマップを必要とせずに、多様でリアルな合成UVマップを作成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Domain Adaptation in Semantic Segmentation via Orthogonal
  and Clustered Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_10.html">
      <font color="black">Unsupervised Domain Adaptation in Semantic Segmentation via Orthogonal
  and Clustered Embeddings</font>
    </a>
  </h2>
  <font color="black">合成から現実へのシナリオでの広範な評価は、最先端のパフォーマンスを達成することを示しています。これらのモジュールの共同効果は、特徴空間の構造を正規化することです。さらに、2つの新しい学習目標を導入します。識別クラスタリングのパフォーマンスを向上させます。直交性の損失により、間隔を空けた個々の表現が直交するように強制され、スパース性の損失により、アクティブな特徴チャネルの数がクラスごとに減少します。 
[概要]たとえば、機能クラスタリング手法に基づいた、効果的な教師なしドメイン適応（uda）戦略が必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Using Radiomics as Prior Knowledge for Abnormality Classification and
  Localization in Chest X-rays -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_11.html">
      <font color="black">Using Radiomics as Prior Knowledge for Abnormality Classification and
  Localization in Chest X-rays</font>
    </a>
  </h2>
  <font color="black">私たちのアルゴリズムであるChexRadiNetは、軽量でありながら効率的なトリプレットアテンションメカニズムを適用して、意味のある画像領域を強調表示し、ローカリゼーションの精度を向上させます。まず、ChexRadiNetを適用して、画像の特徴のみを使用して胸部X線を分類します。 
[要約] X線の数は急増しましたが、放射線科の読み取りは依然として放射線科医によって手動で行われているため、大きなバーンアウトと遅延が発生します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: CT-based COVID-19 Triage: Deep Multitask Learning Improves Joint
  Identification and Severity Quantification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_12.html">
      <font color="black">CT-based COVID-19 Triage: Deep Multitask Learning Improves Joint
  Identification and Severity Quantification</font>
    </a>
  </h2>
  <font color="black">現在のCOVID-19パンデミックは、放射線科を含む医療システムに過負荷をかけています。2つの基本的な設定について説明します。感染の可能性のある患者の研究に優先順位を付けてできるだけ早く隔離するためのCOVID-19の特定。重症患者の研究を強調し、病院に案内するか、救急医療を提供するための重症度の定量化。マルチタスクアプローチを採用して両方のトリアージアプローチを統合し、畳み込みニューラルネットワークを提案して1つのモデル内で利用可能なすべてのラベルを組み合わせます。 
[概要]最も詳細なusct分析アプローチのいくつかが開発されました。しかし、コンピュータサイエンスの問題として研究トライタスクを検討した人は誰もいませんでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-02">
        <br><font color="black">2020-06-02</font>
      </time>
    </span>
</section>
<!-- paper0: Delving Deep into Label Smoothing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_13.html">
      <font color="black">Delving Deep into Label Smoothing</font>
    </a>
  </h2>
  <font color="black">提案されたOLSは、ターゲットカテゴリと非ターゲットカテゴリの間のより合理的な確率分布を構築して、DNNを監視します。ラベル平滑化はディープニューラルネットワーク（DNN）の効果的な正則化ツールであり、一様分布の間に加重平均を適用することでソフトラベルを生成します。分布とハードラベル..実験は、同じ分類モデルに基づいて、提案されたアプローチがCIFAR-100、ImageNet、およびきめ細かいデータセットの分類パフォーマンスを効果的に改善できることを示しています。 
[ABSTRACT]メソッドは、ターゲットカテゴリのモデル予測の統計に基づいてソフトラベルを生成するために使用されます。これは、トレーニングdnnの過剰適合問題を減らし、分類パフォーマンスをさらに向上させるためによく使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: A Surgery of the Neural Architecture Evaluators -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_14.html">
      <font color="black">A Surgery of the Neural Architecture Evaluators</font>
    </a>
  </h2>
  <font color="black">一般的に使用される高速アーキテクチャエバリュエーターには、パラメーター共有のものと予測子ベースのものが含まれます。具体的には、さまざまなトレーニング段階での高速アーキテクチャエバリュエーターの動作を理解するための一連のNAS指向の基準を開発します。 NAS-Bench-201検索スペースでのパラメーター共有と予測子ベースの両方の評価者の評価、およびさまざまな構成と戦略が評価者の適合性に影響を与える方法と理由を分析します。 
[概要] nasの主な課題は、ニューラルアーキテクチャの高速評価を実施することです。nasのニューラルアーキテクチャの高速で正確な評価は依然として疑わしいです。nas-高速アーキテクチャ評価者の動作を理解するために設計された基準</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-07">
        <br><font color="black">2020-08-07</font>
      </time>
    </span>
</section>
<!-- paper0: Fast Region Proposal Learning for Object Detection for Robotics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_15.html">
      <font color="black">Fast Region Proposal Learning for Object Detection for Robotics</font>
    </a>
  </h2>
  <font color="black">最近の方法
[1]は、ディープラーニング記述子の強力な表現を活用しながら、高速な適応時間を可能にするアーキテクチャを提案しています。（i）領域候補生成、（ii）特徴抽出、および（ii）でのタスクの自然分解を活用します。 iii）領域分類、この方法は、分類層を再トレーニングするだけで、検出器の高速適応を実行します。オブジェクト検出は、ロボットが非構造化環境で動作するための基本的なタスクです。 
[概要]この方法は、タスクの自然分解に基づいています。オブジェクト検出器の分類レイヤーを再トレーニングすることで機能します。これは、手元のタスクで領域候補の生成を適応させることで実現できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Physics-informed neural networks for myocardial perfusion MRI
  quantification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_16.html">
      <font color="black">Physics-informed neural networks for myocardial perfusion MRI
  quantification</font>
    </a>
  </h2>
  <font color="black">この研究では、心筋灌流MRの定量化を実行する手段として、物理情報に基づくニューラルネットワーク（PINN）を紹介します。これにより、動的パラメーターを推測するための多様なスキームが提供されます。これにより、パラメーターの推定が不正確になる可能性があります。ここでは、心筋灌流MRにおけるPINNの実装。 
[概要]これらのニューラルネットワークは、ピンの観測データに適合するようにトレーニングできます。これは、動的であり、血流と微小血管機能を直接解決するためです。ただし、これにより、モデルモデルモデルモデルが不正確になる可能性があります。これにより、モデルモデルが改善される可能性があります。インシリコとマウスの両方のモデルモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Auto Graph Encoder-Decoder for Model Compression and Network
  Acceleration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_17.html">
      <font color="black">Auto Graph Encoder-Decoder for Model Compression and Network
  Acceleration</font>
    </a>
  </h2>
  <font color="black">私たちの実験では、最初に私たちの方法をルールベースのDNN埋め込み方法と比較して、グラフの自動エンコーダーデコーダーの有効性を示しました。さらに、MobileNet-V2の最先端の方法よりも高い圧縮率を達成しました。 0.93％の精度低下..ターゲットDNNをグラフとしてモデル化し、GNNを使用してDNNの埋め込みを自動的に学習します。 
[概要]私たちの方法ベースのdnn埋め込みは、より少ない検索ステップでより良いパフォーマンスとより高い圧縮率を達成しました。ターゲットdnnをグラフとしてモデル化し、gnnを使用してdnnの埋め込みを自動的に学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Anytime Prediction as a Model of Human Reaction Time -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_18.html">
      <font color="black">Anytime Prediction as a Model of Human Reaction Time</font>
    </a>
  </h2>
  <font color="black">非常に類似した速度と精度のトレードオフ..2人の観測者（人間とネットワーク）を同じ精度範囲にするために適切な量のノイズが存在する場合、それらは持続時間またはFLOPSに非常に類似した依存性を示します。追加されたガウスノイズでCIFAR-10画像を分類する際の人間とMSDNetの精度を比較すると、ネットワーク等価入力ノイズSDは人間の15倍であり、人間の効率はネットワークの0.6 \％にすぎないことがわかります。 
[概要]早期終了分類器を使用していつでも予測を行う分類ネットワーク。人間の反応時間は期間またはフロップに依存します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Boosting Adversarial Training with Hypersphere Embedding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_19.html">
      <font color="black">Boosting Adversarial Training with Hypersphere Embedding</font>
    </a>
  </h2>
  <font color="black">実験では、CIFAR-10およびImageNetデータセットに対するさまざまな敵対的攻撃の下でメソッドを評価します。これにより、HEを統合することで、追加の計算をほとんど行わずに、各ATフレームワークのモデルの堅牢性を一貫して強化できることが確認されます。 ATとHEは、いくつかの側面から敵対的に訓練されたモデルの堅牢性に利益をもたらすようにうまく結合されています。PGD-AT、ALP、TRADESなどの一般的なATフレームワークに組み込むことで、HEの有効性と適応性を検証します。 FreeATおよびFastAT戦略。 
[概要]システムは、人気のあるフレームワークに統合されるように設計されています。これには、軽量でありながら効果的なコンパクトなマニホールドに機能を正規化することが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-20">
        <br><font color="black">2020-02-20</font>
      </time>
    </span>
</section>
<!-- paper0: Privacy Preserving for Medical Image Analysis via Non-Linear Deformation
  Proxy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_20.html">
      <font color="black">Privacy Preserving for Medical Image Analysis via Non-Linear Deformation
  Proxy</font>
    </a>
  </h2>
  <font color="black">私たちのシステムには3つのコンポーネントがあります：1）疑似ランダム変形関数を生成するフローフィールドジェネレータ、2）処理された画像から患者のアイデンティティを学習するシャム弁別器、3）コンテンツを分析する医用画像処理ネットワークプロキシイメージ..システムは敵対的な方法でエンドツーエンドでトレーニングされます。これにより、プロキシイメージが生成され、サーバーに送信されて処理されます。 
[要約]サーバーは、クライアントが元に戻す変形されたプロセスを返します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Semantic Segmentation of Urban-Scale 3D Point Clouds: A Dataset,
  Benchmarks and Challenges -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_21.html">
      <font color="black">Towards Semantic Segmentation of Urban-Scale 3D Point Clouds: A Dataset,
  Benchmarks and Challenges</font>
    </a>
  </h2>
  <font color="black">この論文では、既存の最大の写真測量点群データセットの3倍である、約30億の豊富な注釈付きポイントを含む都市規模の写真測量点群データセットを提示します。監視対象の可能性を解き放つための必須の前提条件3Dシーン理解の分野における深層学習アルゴリズムは、大規模で注釈の豊富なデータセットの可用性です。データセットでは、各3Dポイントは13のセマンティッククラスの1つとしてラベル付けされています。 
[ABSTRACT]データセットは、比較的小さな空間スケールであるか、セマンティックアノテーションが制限されています。データ取得とデータアノテーションのコストにより、3Dポイントクラウドのコンテキストでのきめ細かいセマンティック理解の開発が大幅に制限されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Deep-learning coupled with novel classification method to classify the
  urban environment of the developing world -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_22.html">
      <font color="black">Deep-learning coupled with novel classification method to classify the
  urban environment of the developing world</font>
    </a>
  </h2>
  <font color="black">さらに、従来の方法では、小規模な分類が提案されています。これは、スケーラビリティが低く、計算が遅い限られた情報を提供します。最先端技術は、主に建物の構造、建物の種類などの分類によって支配され、主にバングラデシュのように周囲が分類に欠かせない発展途上国には不十分な先進国。 
[概要]分類は、都市化と都市環境の建築形態の2つの側面に大きく基づいています。システムの大部分は、バングラデシュなどの発展途上国には不十分な先進国で構成されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Filter Pre-Pruning for Improved Fine-tuning of Quantized Deep Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_23.html">
      <font color="black">Filter Pre-Pruning for Improved Fine-tuning of Quantized Deep Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">次に、これらの結果に基づいて、DNNの微調整を妨げるフィルターを削除し、推定結果にできるだけ影響を与えない、Pruning for Quantization（PfQ）と呼ばれる新しいプルーニング方法を提案します。この問題を解決するには、この論文は、追加の学習パラメータとハイパーパラメータを使用せずに、次の3つの貢献をします。最初に、前述の問題の原因となるバッチ正規化が、量子化DNNの微調整をどのように妨げるかを分析します。 
[ABSTRACT]メソッドは、重みとアクティベーションに低ビット式を使用し、精度の低下を回復するために微調整してdnnのサイズを縮小することです。これは、プルニファーメソッド（pfq）と呼ばれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-13">
        <br><font color="black">2020-11-13</font>
      </time>
    </span>
</section>
<!-- paper0: Space-time Neural Irradiance Fields for Free-Viewpoint Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_24.html">
      <font color="black">Space-time Neural Irradiance Fields for Free-Viewpoint Video</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、陰的表現の最近の進歩に基づいています。ビデオには任意の時点でシーンの観測が1つしかないため、単一のビデオから時空間放射照度フィールドを学習することは重大な課題をもたらします。時間変化を制限することにより、このあいまいさに対処します。ビデオ深度推定方法から推定されたシーン深度を使用して、個々のフレームのコンテンツを単一のグローバル表現に集約する、動的シーン表現のジオメトリ。 
[概要]私たちの説得力のある表現は、ビデオの自由な視点によるレンダリングを可能にします。単一のビデオから時空間放射照度フィールドを学習することは、重大な課題をもたらします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: DASGIL: Domain Adaptation for Semantic and Geometric-aware Image-based
  Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_25.html">
      <font color="black">DASGIL: Domain Adaptation for Semantic and Geometric-aware Image-based
  Localization</font>
    </a>
  </h2>
  <font color="black">提案されたアプローチは、一連の重要な比較実験を通じて、ExtendedCMU-SeasonsデータセットとOxfordRobotCarデータセットで検証されます。この実験では、パフォーマンスが、検索ベースのローカリゼーションと困難な状況下での大規模な場所認識の最先端のベースラインを上回っています。環境..この論文では、幾何学的情報と意味情報を視覚的な場所認識のためのマルチスケール潜在埋め込み表現に融合する新しいマルチタスクアーキテクチャを提案します。人間の努力なしに高品質のグラウンドトゥルースを使用するには、効果的なマルチスケール機能弁別器は、合成仮想KITTIデータセットから実世界のKITTIデータセットへのドメイン適応を達成するための敵対的トレーニングのために提案されています。 
[概要]効果的なマルチスケール機能弁別器が敵対的訓練のために提案されている</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-01">
        <br><font color="black">2020-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Domain Adversarial Feature Generalization for Person
  Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_26.html">
      <font color="black">Multi-Domain Adversarial Feature Generalization for Person
  Re-Identification</font>
    </a>
  </h2>
  <font color="black">この目的を果たすために、このホワイトペーパーでは、個人の再識別をマルチデータセットドメインの一般化問題として再定式化します。他のデータセットで事前トレーニングされた実用的なPerson Re-IDシステムは、新しいサイトに展開した直後に、十分な画像またはビデオが収集され、事前トレーニングされたモデルが調整されるまで待機します。複数のラベル付きデータセットからユニバーサルドメイン不変の特徴表現を学習できるマルチデータセット特徴一般化ネットワーク（MMFA-AAE）を提案します。そしてそれを「見えない」カメラシステムに一般化する。 
[ABSTRACT]敵対的なオートエンコーダーに基づくモデルモデルモデル。これらのアプローチでは、ターゲットドメインのラベルのないデータが必要です。これにより、非実用的になり、非実用的になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: DeRF: Decomposed Radiance Fields -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_27.html">
      <font color="black">DeRF: Decomposed Radiance Fields</font>
    </a>
  </h2>
  <font color="black">これにより、分解されたパーツの数に関係なく、ほぼ一定の推論時間が可能になります。これらのネットワークを連携させると、シーン全体をレンダリングできます。さらに、互換性が証明できるため、この目的にはボロノイ空間分解が望ましいことを示します。効率的でGPUに適したレンダリングのための画家のアルゴリズムを使用します。 
[概要]私たちの重要な観察は、より大きなネットワークを採用すると収穫逓減があることです。この目にはボロノイ空間分解が望ましいです。効率的でGPUに適したレンダリングのための画家のアルゴリズムと互換性があることが証明されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: DRACO: Weakly Supervised Dense Reconstruction And Canonicalization of
  Objects -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_28.html">
      <font color="black">DRACO: Weakly Supervised Dense Reconstruction And Canonicalization of
  Objects</font>
    </a>
  </h2>
  <font color="black">DRACOは、列車の時間にカメラのポーズとセマンティックキーポイントの形で弱い監視のみを使用して密な正規化を実行します。以前のアプローチは、入念に収集された密な3D監視に依存するか、疎な正規表現のみを生成して、実際の適用性を制限します。 DRACOは、オブジェクトの1つ以上のRGB画像のみを使用して、正準座標空間で密なオブジェクト中心の深度マップを予測します。 
[ABSTRACT]座標空間で3Dオブジェクトの形状を推定するdraco.dracoは、弱い監視のみを使用して高密度のバインディングを実行します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Reference-Based Video Colorization with Spatiotemporal Correspondence -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_29.html">
      <font color="black">Reference-Based Video Colorization with Spatiotemporal Correspondence</font>
    </a>
  </h2>
  <font color="black">時空間対応を備えた新しい参照ベースのビデオカラー化フレームワークを提案します。2つの補完的な追跡アプローチを使用して、マスクを時間対応として伝播します。高性能セグメンテーションのための既成のインスタンス追跡と、さまざまなタイプを追跡するための新しく提案された高密度追跡です。オブジェクト..既存の方法は、オブジェクト間の色漏れと、空間内の非局所的な意味的対応に由来する平均的な色の出現に悩まされています。 
[ABSTRACT]時間の対応によって制限された参照フレームから離れた領域からのみ色をワープします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Image Embedded Segmentation: Uniting Supervised and Unsupervised
  Objectives for Segmenting Histopathological Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_30.html">
      <font color="black">Image Embedded Segmentation: Uniting Supervised and Unsupervised
  Objectives for Segmenting Histopathological Images</font>
    </a>
  </h2>
  <font color="black">提案されたアプローチは、これら2つのタスクを1つに統合し、本質的に損失を結合することで、この問題のより簡単な解決策を提供します。この提案は、同じ正則化の目的で画像再構成を使用する既存のアプローチとは異なります。これらのデータセットでは、対応するデータセットと比較して、より良いセグメンテーション結果が得られます。 
[要約]この方法は、ネットワークトレーニングのための、画像再構成の形での教師なし学習の利点に依存しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-30">
        <br><font color="black">2020-01-30</font>
      </time>
    </span>
</section>
<!-- paper0: Combinatorial 3D Shape Generation via Sequential Assembly -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_31.html">
      <font color="black">Combinatorial 3D Shape Generation via Sequential Assembly</font>
    </a>
  </h2>
  <font color="black">実験結果は、私たちの方法が組み合わせ3D形状を正常に生成し、より現実的な生成プロセスをシミュレートすることを示しています。すべてのコードは\ url {https://github.com/POSTECH-CVLab/Combinatorial-3D-Shape-Generation}で入手できます。実行可能な膨大な数の組み合わせによって引き起こされるこの結果を軽減するために、組み合わせ3D形状生成フレームワークを提案します。 
[概要]提案されたフレームワークは、実生活における人間の生成プロセスの重要な側面を反映しています。これは、体積プリミティブの量を排除することを目的としています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br><font color="black">2020-04-16</font>
      </time>
    </span>
</section>
<!-- paper0: Match Them Up: Visually Explainable Few-shot Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_32.html">
      <font color="black">Match Them Up: Visually Explainable Few-shot Image Classification</font>
    </a>
  </h2>
  <font color="black">少数ショット学習（FSL）アプローチは、通常、事前にトレーニングされた知識が基本（表示）カテゴリから取得でき、新規（非表示）カテゴリに適切に転送できるという仮定に基づいています。この問題は、の未知の性質につながります。ほとんどのFSLメソッドの推論プロセスは、リスクに敏感な一部の領域での適用を妨げます。ただし、特に後半の部分については、保証はありません。 
[要約]提案された方法は、3つの主流のデータセットで優れた精度と十分な説明性の両方を達成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: FixMatch: Simplifying Semi-Supervised Learning with Consistency and
  Confidence -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_33.html">
      <font color="black">FixMatch: Simplifying Semi-Supervised Learning with Consistency and
  Confidence</font>
    </a>
  </h2>
  <font color="black">その単純さにもかかわらず、FixMatchは、250ラベルのCIFAR-10で94.93％の精度、40ラベルで88.61％の精度など、さまざまな標準的な半教師あり学習ベンチマークで最先端のパフォーマンスを達成することを示しています。クラスごとに..モデルは、同じ画像の強力に拡張されたバージョンが供給されたときに疑似ラベルを予測するようにトレーニングされます。コードはhttps://github.com/google-research/fixmatchで入手できます。 
[ABSTRACT] fixmatchは、さまざまな半教師あり学習ベンチマークで見つけることができます。これには、cifarで94. 93％の精度（250ラベルで10）、40で88. 61％の精度（クラスあたりわずか4ラベル）が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-21">
        <br><font color="black">2020-01-21</font>
      </time>
    </span>
</section>
<!-- paper0: Sparse R-CNN: End-to-End Object Detection with Learnable Proposals -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_34.html">
      <font color="black">Sparse R-CNN: End-to-End Object Detection with Learnable Proposals</font>
    </a>
  </h2>
  <font color="black">100）学習可能な提案、スパースR-CNNは、オブジェクト候補の設計と多対1のラベル割り当てに関連するすべての労力を完全に回避します。ただし、この方法では、学習されたオブジェクト提案の固定されたスパースセット、全長$ N $、分類と位置特定を実行するためにオブジェクト認識ヘッドに提供されます。さらに重要なことに、最終的な予測は、手順後に非最大抑制なしで直接出力されます。 
[ABSTRACT]既存の作品は、密集したオブジェクト候補に大きく関連するオブジェクト検出に取り組んでいます。たとえば、オブジェクト検出結果は、最大抑制なしで直接出力されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: OGAN: Disrupting Deepfakes with an Adversarial Attack that Survives
  Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_35.html">
      <font color="black">OGAN: Disrupting Deepfakes with an Adversarial Attack that Survives
  Training</font>
    </a>
  </h2>
  <font color="black">OGANを実装するために、ジェネレータとフェイススワッピングモデルインスタンスを相互にトレーニングする2レベルの最適化問題を構築します。より広く、これらの結果は、トレーニングに耐性のある敵対的攻撃の存在を示しています。ドメイン..最後に、FaceSwapの一般的な実装を使用して両方の攻撃を検証し、敵対的な攻撃が訓練されていない顔を含む、異なるターゲットモデルとターゲット顔間で転送されることを示します。 
[ABSTRACT]振動ガン（ogan）攻撃は、トレーニングに最適化された新しい攻撃です。耐性があります。各入力画像をターゲットの歪みとペアにして、敵対的な画像を生成するジェネレーターにフィードします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br><font color="black">2020-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: Dissecting Image Crops -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_36.html">
      <font color="black">Dissecting Image Crops</font>
    </a>
  </h2>
  <font color="black">コードはhttps://github.com/basilevh/dissecting-image-cropsで入手できます。トリミングの基本操作は、データの拡張や翻訳の不変性から計算写真や表現学習に至るまで、ほぼすべてのコンピュータービジョンシステムを支えています。目的は、空間作物の基本的な影響を分析することです。画像操作の検出や、ニューラルネットワークの研究者にショートカット学習の理解を深めるなど、私たちの仕事には多くの実際的な影響もあります。 
[概要]画像はロンドンの写真家バシロフによって撮影されました。彼らは現在、空間作物の基本的な影響を分析しようとしています。しかし、私たちの仕事には多くの実際的な影響もあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Supercharging Imbalanced Data Learning With Causal Representation
  Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_37.html">
      <font color="black">Supercharging Imbalanced Data Learning With Causal Representation
  Transfer</font>
    </a>
  </h2>
  <font color="black">既存のソリューションは主に、病理学的不均衡を緩和するためのサンプリングまたは重み付けの調整、または非疑似相関を優先するための誘導バイアスの適用に訴えますが、因果関係の不変性原理に基づいてサンプルの効率とモデルの一般化を促進するために新しい視点を取ります。クラスの不均衡は、特に少数派クラスの正確な分類と一般化が主な関心事である場合、実際のアプリケーションに大きな課題をもたらします。私たちの提案は、データ生成メカニズムがラベル条件付き機能全体で不変であるメタ分散シナリオを想定しています。分布。 
[概要]コンピュータービジョンでは、ロングテールデータセットからの学習は繰り返し発生するテーマです。これにより、知識プロセスを活用してマイノリティクラスの表現を拡大できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Image Inpainting with Contextual Reconstruction Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_38.html">
      <font color="black">Image Inpainting with Contextual Reconstruction Loss</font>
    </a>
  </h2>
  <font color="black">畳み込みニューラルネットワーク（CNN）は、画像内の離れた空間位置に情報を伝播するのに非効率的であることが観察されています。また、欠落領域と既知の領域との対応に関する監視が不足しているため、適切な参照領域を見つけることができないことがよくあります。 ..この操作は、多くの深層学習ベースの方法で広く使用されているコンテキストアテンションレイヤー（CAレイヤー）\ cite {yu2018generative}として実装できます。 
[概要]これらの問題を解決するために、新しいコンテキスト再構成損失（cr損失）を提案します。最初に、修復モデルの新しいタイプの検索と置換操作で、クリーニングと交換のコストを挙げます。しかし、2つに多額の費用がかかります。 -機能パッチの賢明な類似性</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: AutoAssign: Differentiable Label Assignment for Dense Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_39.html">
      <font color="black">AutoAssign: Differentiable Label Assignment for Dense Object Detection</font>
    </a>
  </h2>
  <font color="black">さらに、PASCAL VOC、Objects365、WiderFaceなどの他のデータセットでの実験は、AutoAssignの幅広い適用性を示しています。トレーニング中に、データの事前分布を満たし、カテゴリの特性に適応するために、カテゴリを調整するための中央の重み付けを示します。 -特定の事前分布..次に、2つの重み付けモジュールを組み合わせて正と負の重みを生成し、各場所の信頼度を調整します。 
[ABSTRACT] autoassignは、autoassignと呼ばれるオブジェクトです。カテゴリ（特定の事前分布）を調整するために使用できます。2つの重み付けモジュールを組み合わせて、正と負の重みを作成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-feature driven active contour segmentation model for infrared
  image with intensity inhomogeneity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_40.html">
      <font color="black">Multi-feature driven active contour segmentation model for infrared
  image with intensity inhomogeneity</font>
    </a>
  </h2>
  <font color="black">次に、局所範囲で計算された適応重み係数を利用して、前述のグローバル項とローカル項を調整します。まず、グローバル平均グレーで計算されたグローバル情報を組み合わせて、特別に設計された符号付き圧力（SPF）関数を構築します。情報と局所エントロピー、局所標準偏差、勾配情報によって計算された局所多特徴情報..本論文では、強度が不均一なIR画像を処理するための多特徴駆動アクティブ輪郭セグメンテーションモデルを提案する。 
[ABSTRACT]モデルは現在最も広く使用されている写真セグメンテーションツールの1つですが、既存の方法では、画像のローカルまたはグローバルな単一特徴情報のみを使用してエネルギー関数を最小化します。これにより、ir画像で誤ったセグメンテーションが発生しやすくなります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: The Unreasonable Effectiveness of Encoder-Decoder Networks for Retinal
  Vessel Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_41.html">
      <font color="black">The Unreasonable Effectiveness of Encoder-Decoder Networks for Retinal
  Vessel Segmentation</font>
    </a>
  </h2>
  <font color="black">さらに、このフレームワーク（VLightと呼ばれる）が特定のトレーニング画像への過剰適合を回避し、さまざまなデータセット間で十分に一般化されることを示します。これにより、高解像度の眼底画像での堅牢性、精度、および推論時間が短い実際のアプリケーションに非常に適しています。トレーニング中の複数の画像スケールでの大規模パッチの抽出に依存する網膜画像の血管のセグメンテーションのためのエンコーダ-デコーダフレームワークを提案します。3つの眼底画像データセットでの実験は、このアプローチが達成することを示しています。最先端の結果であり、0.8M未満のパラメータ数でシンプルで効率的な完全畳み込みネットワークを使用して実装できます。 
[ABSTRACT]画像は、このアプローチが最先端の結果を達成することを示しています。シンプルで効率的な完全畳み込みネットワークを使用して実装できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Encoder-Decoder Based Convolutional Neural Networks with
  Multi-Scale-Aware Modules for Crowd Counting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_42.html">
      <font color="black">Encoder-Decoder Based Convolutional Neural Networks with
  Multi-Scale-Aware Modules for Crowd Counting</font>
    </a>
  </h2>
  <font color="black">5つの群集カウントデータセットと1つの車両カウントデータセットで広範な実験を行い、これらの変更により、最先端の群集カウント方法を改善できるアルゴリズムが得られることを示します。この組み合わせにより、密集した群集と疎な群集の両方でカウントするための効果的なモデルが得られます。シーン..SFANetに触発された、M-SFANetという名前の最初のモデルには、大規模な空間ピラミッドプーリング（ASPP）とコンテキスト認識モジュール（CAN）が付属しています。 
[ABSTRACT] m-sfanetのデコーダーには、密度マップとアテンションマップを生成するためのデュアルパスがあります。モデルには、アトラス空間ピラミッドプーリング（aspp）とコンテキストアウェアモジュール（can）が付属しています。デュアルパスを使用して、より高速な作成を行います。競争力のあるカウントパフォーマンスを提供しながらモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-12">
        <br><font color="black">2020-03-12</font>
      </time>
    </span>
</section>
<!-- paper0: Interpreting U-Nets via Task-Driven Multiscale Dictionary Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_43.html">
      <font color="black">Interpreting U-Nets via Task-Driven Multiscale Dictionary Learning</font>
    </a>
  </h2>
  <font color="black">U-Netは、多くのイメージング逆問題で大成功を収めています。このモデルは、タスク駆動型辞書学習フレームワークでトレーニングでき、CTやMRIなどの多くの関連タスクで標準のU-Netと同等の結果が得られることを示しています。再構成..これらの結果は、U-Netの成功は、主にそのマルチスケールアーキテクチャと誘導されたスパース表現によって説明される可能性があることを示唆しています。 
[概要]私たちの研究者は、強力なラボパフォーマンスを維持しながら、au-netを畳み込みのよく理解された辞書モデルに縮小することができました。これらの結果は、u-netの成功は主にそのマルチスケールアーキテクチャと誘導された密な表現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: CLAWS: Clustering Assisted Weakly Supervised Learning with Normalcy
  Suppression for Anomalous Event Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_44.html">
      <font color="black">CLAWS: Clustering Assisted Weakly Supervised Learning with Normalcy
  Suppression for Anomalous Event Detection</font>
    </a>
  </h2>
  <font color="black">提案された方法は、UCF CrimeおよびShanghaiTechデータセットでそれぞれ83.03％および89.67％のフレームレベルのAUCパフォーマンスを取得し、既存の最先端のアルゴリズムよりも優れていることを示しています。ビデオを通じて現実世界の異常イベントを検出する方法を学ぶレベルのラベルは、ラベル内のノイズだけでなく異常の発生もまれであるため、困難な作業です。この作業では、1）ランダムバッチベースのトレーニング手順を含む、弱く監視された異常検出方法を提案します。 -バッチ相関、2）1つのトレーニングバッチで利用可能な全体的な情報を考慮してビデオの正常領域の異常スコアを最小化する正常性抑制メカニズム、および3）ラベルノイズの軽減に寄与するクラスタリング距離ベースの損失モデルに明確な正常クラスターと異常クラスターを生成するように促すことで、より良い異常表現を生成します。 
[概要]この方法は、上海のau auによって提案されました。これには、バッチ間の相関を減らすためのランダムなバッチベースのトレーニング手順が含まれます。この方法を使用して、より良い異常表現を作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Single-Image Lens Flare Removal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_45.html">
      <font color="black">Single-Image Lens Flare Removal</font>
    </a>
  </h2>
  <font color="black">フレアの光学的原因を明示的にモデル化するための原理的なアプローチを採用しています。これにより、経験的レンズフレアと波動光学シミュレーションレンズフレアの両方からフレアが破損した画像を生成するための新しい半合成パイプラインが実現します。既存のソフトウェア手法では、アーティファクトの形状または明るさ、したがってフレアの小さなサブセットのみを処理します。その外観の多様性により、フレアの除去は非常に困難になります。 
[ABSTRACT]フレアは、レンズ内での複数の反射、またはレンズの傷やほこりによる散乱によって発生します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Model-Enhanced Human Motion Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_46.html">
      <font color="black">Generative Model-Enhanced Human Motion Prediction</font>
    </a>
  </h2>
  <font color="black">コードはhttps://github.com/bouracha/OoDMotionで入手できます。現在の最先端の識別モデルに適用すると、提案されたアプローチが配布内のパフォーマンスを犠牲にすることなくOoDの堅牢性を向上させることを示します。モデルの解釈可能性を理論的に促進します。人間の動きの予測子は、OoDの課題を念頭に置いて構築する必要があり、多様な識別アーキテクチャを極端な分布シフトに強化するための拡張可能な一般的なフレームワークを提供することをお勧めします。 
[概要] human3。 6mおよびcmuのモーションキャプチャデータセットは、human3に基づいています。 6m。これらには、頭の中でのフードチャレンジと人間の動きの新しいモデルが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: AdaCoSeg: Adaptive Shape Co-Segmentation with Group Consistency Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_47.html">
      <font color="black">AdaCoSeg: Adaptive Shape Co-Segmentation with Group Consistency Loss</font>
    </a>
  </h2>
  <font color="black">次に、コセグメンテーションネットワークは反復的に}共同で、マトリックスランクによって定義される新しいグループ整合性損失の影響を受けるセット全体のパーツラベリングを最適化します。パーツの前のネットワークは、ノイズが多く一貫性のないセグメント化された形状でトレーニングできますが、 AdaCoSegは、入力セットの一貫したパーツラベル付けであり、各形状は最大（ユーザー指定）のKパーツにセグメント化されます。具体的には、セグメント化されていない形状の入力セットが与えられた場合、最初にオフラインの事前トレーニング済みパーツを採用します。形状ごとのパーツを提案します。 
[ABSTRACT] adacosegは、ノイズが多く一貫性のないセグメント化された形状でトレーニングできるパーツ事前ネットワークです。adacosegの最終出力は、入力セットの一貫したパーツラベル付けであり、各形状は最大（ユーザー指定）k個のパーツにセグメント化されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-03-25">
        <br><font color="black">2019-03-25</font>
      </time>
    </span>
</section>
<!-- paper0: Bag of Tricks for Adversarial Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_48.html">
      <font color="black">Bag of Tricks for Adversarial Training</font>
    </a>
  </h2>
  <font color="black">たとえば、重みの減衰の値がわずかに異なると、モデルのロバスト精度が7％以上低下する可能性があります。これは、提案された方法によって引き起こされる潜在的な促進を無効にする可能性があります。経験的観察によると、敵対的なロバスト性は、私たちが思っていたよりも基本的なトレーニング設定..これらの事実は、防御をベンチマークするときに見落とされている混乱者に対するより多くの懸念にも訴えます。 
[概要]最近のベンチマークでは、atで提案された改善のほとんどは、トレーニング手順を早期に停止するよりも効果が低いことが示されています。驚くべきことに、基本設定（卵、体重減少、トレーニングスケジュールなど）に一貫性がないことがわかりました。cifar-10、敵対的に訓練されたモデルのほとんど見過ごされている訓練トリックとハイパーパラメータの影響に焦点を当てています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-01">
        <br><font color="black">2020-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: Semantic Labeling of Large-Area Geographic Regions Using Multi-View and
  Multi-Date Satellite Images and Noisy OSM Training Labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_49.html">
      <font color="black">Semantic Labeling of Large-Area Geographic Regions Using Multi-View and
  Multi-Date Satellite Images and Noisy OSM Training Labels</font>
    </a>
  </h2>
  <font color="black">私たちのシステムのユニークな（そしておそらく驚くべき）特性は、マルチビューデータから学習するためにCNNのテールエンドに追加された変更を、推論時に破棄できることです。全体的なパフォーマンス..人間の監督なしで、建物と道路のクラスのIoUスコアはそれぞれ0.8と0.64であり、OSMラベルを使用し、完全に自動化されていない最先端のアプローチよりも優れています。このアプローチでは、シーンごとに最大32ビューでトレーニングする場合でも、GPUメモリの消費に関してわずかなオーバーヘッドしか追加されません。 
[概要]マルチビューセマンティックセグメンテーションへのアプローチでは、クラスごとのiouスコアが4〜7％向上します。これは、ビューを互いに独立して使用する従来のアプローチと比較されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Quantifying Explainers of Graph Neural Networks in Computational
  Pathology -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_50.html">
      <font color="black">Quantifying Explainers of Graph Neural Networks in Computational
  Pathology</font>
    </a>
  </h2>
  <font color="black">ディープラーニング手法の説明可能性は、デジタルパソロジーでの臨床採用を促進するために不可欠です。提案されたメトリックを使用して、3種類のグラフ説明、つまり、レイヤーごとの関連性の伝播、勾配ベースの顕著性、およびグラフプルーニングアプローチを評価します。乳がんサブタイピングのセルグラフ表現..この目的のために、ここでは、病理学的に測定可能な概念を使用してグラフの説明を特徴付けるクラス分離可能性の統計に基づく一連の新しい定量的メトリックを提案します。 
[ABSTRACT]ピクセル単位の処理に基づく深層学習方法と説明可能性のアイデア（説明者）は、生物学的エンティティの概念を無視するため、病理学者による明確さを複雑にします。乳がんロイスの大規模なコホートであるbracsデータセットの適格性と定量的所見を検証します。専門の病理学者による</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: CircleGAN: Generative Adversarial Learning across Spherical Circles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_51.html">
      <font color="black">CircleGAN: Generative Adversarial Learning across Spherical Circles</font>
    </a>
  </h2>
  <font color="black">したがって、対応する球面上の円に基づいてサンプルを識別することで、生成されたサンプルに多様性を自然に誘発できます。球面上の円を使用して構造化された超球埋め込み空間を学習することにより、生成されたサンプルの現実性と多様性を向上させるGANの新しい識別器を提示します。非現実的なサンプルを大円に垂直な極に向かって押しながら、最も長い球形の円、つまり大円の周りに現実的なサンプルを配置します。 
[概要]提案された弁別器は、非現実的なサンプルを大円に平行な極に向かって押しながら、最も長い球形の円、つまり大円の周りに現実的なサンプルを配置することを学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Bayesian Triplet Loss: Uncertainty Quantification in Image Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_52.html">
      <font color="black">Bayesian Triplet Loss: Uncertainty Quantification in Image Retrieval</font>
    </a>
  </h2>
  <font color="black">計算効率を確保するために、ベイズトリプレット損失と呼ばれる事後の変分近似を導出します。これは、最先端の不確実性推定値を生成し、現在の最先端の方法の予測パフォーマンスと一致します。主な貢献は次のとおりです。（1）トリプレット制約に一致し、アンカーが負よりも正に近い確率を評価する可能性。 （2）従来のl2正規化を正当化する特徴空間に対する優先順位。画像の埋め込みを決定論的特徴ではなく確率的特徴として表示する新しい方法を提示します。 
[概要]不確実性を推定する現在の方法は、不十分に調整されているか、高価です。現在の方法は、不確実性を予測するために使用されます。私たちは、私たちがどのようになっているかについてもっと知る必要があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: ImCLR: Implicit Contrastive Learning for Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_53.html">
      <font color="black">ImCLR: Implicit Contrastive Learning for Image Classification</font>
    </a>
  </h2>
  <font color="black">ImCLRが既存のデータ拡張手法を補完し、いずれかのベースラインでImCLRとCutMixを組み合わせることでCIFAR-100で1％以上、Tiny ImageNetで2％の改善を達成し、いずれかのベースラインでImCLRとAutoAugmentを組み合わせることで2％の改善を達成することを示します。対照学習に触発されて、主に教師あり設定で、暗黙的対照学習（ImCLR）の巧妙な入力構造を導入します。そこで、ネットワークは、類似画像と非類似画像を区別することを暗黙的に学習できます。つまり、損失に変化はありません。ハイパーパラメータに変更はなく、一般的なネットワークアーキテクチャにも変更はありません。 
[要約]ほとんどの場合、これには、特定の画像が同様の表現を持つように促す明示的な損失関数と、異なる表現を示すための異なる画像を追加することが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Recent Progress in Appearance-based Action Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_54.html">
      <font color="black">Recent Progress in Appearance-based Action Recognition</font>
    </a>
  </h2>
  <font color="black">各カテゴリーの代表的な方法を包括的に分析し、議論します。最近、外観ベースの方法は、正確な行動認識に向けて有望な進歩を遂げました。私たちのカテゴリーから収集した将来の研究のための重要な領域を特定することによって結論を下します。 
[概要]これらのタイプには、3D畳み込み、3D畳み込み、およびモーション表現ベースのメソッドが含まれます。包括的な結果も要約され、最先端のアルゴリズムをわかりやすく説明します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Face recognition using PCA integrated with Delaunay triangulation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_55.html">
      <font color="black">Face recognition using PCA integrated with Delaunay triangulation</font>
    </a>
  </h2>
  <font color="black">この研究では、2つの異なるアプローチの組み合わせを利用するそのようなアルゴリズムの1つを開発します。顔認識は、顔の特徴に基づいてユーザーを識別する生体認証のユーザー認証に最もよく使用されます。このシステムは、多くの企業であり、スマートフォンや監視カメラなどの多くのデバイスで採用されています。 
[概要]このシステムは、スマートフォンや監視カメラなどの多くのデバイスで観察および使用されているため、需要が高くなっています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Rank-One Network: An Effective Framework for Image Restoration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_56.html">
      <font color="black">Rank-One Network: An Effective Framework for Image Restoration</font>
    </a>
  </h2>
  <font color="black">ニューラルネットワークに基づくRO投影は、画像の最も近いRO成分を抽出します。RO分解は、破損した画像をRO成分と残差に分解するために開発されます。これは、RO投影を画像またはその画像に連続して適用することによって実現されます。 RO成分を抽出するための残差。 
[概要]破損した画像のro成分は、画像のノイズ除去の手順によって間引きされる可能性があります。これは、ro投影を画像またはその残差に適用して、ro成分を抽出することによって実現されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Contrastive Representation Learning for Whole Brain Cytoarchitectonic
  Mapping in Histological Human Brain Sections -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_57.html">
      <font color="black">Contrastive Representation Learning for Whole Brain Cytoarchitectonic
  Mapping in Histological Human Brain Sections</font>
    </a>
  </h2>
  <font color="black">この学習タスクを使用して事前トレーニングされたモデルは、最初からトレーニングされたモデル、および最近提案された補助タスクで事前トレーニングされたモデルよりも優れていることを示します。細胞構築マップは、脳の微細構造参照パーセルを提供し、その組織を用語で説明します。組織学的組織切片から測定された神経細胞体の空間配置の分析..学習された表現が解剖学的に意味のあるグループを形成することを示すために、特徴空間でクラスター分析を実行します。 
[ABSTRACT]最近の研究により、畳み込みニューラルネットワークを使用した視覚系の細胞構造領域の最初の自動セグメンテーションが提供されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Correlation Tracking via Multi-channel Fused Features and
  Reliable Response Map -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_58.html">
      <font color="black">Robust Correlation Tracking via Multi-channel Fused Features and
  Reliable Response Map</font>
    </a>
  </h2>
  <font color="black">効果的な機能の設計とモデルドリフトの処理は、オンラインビジュアルトラッキングの2つの重要な側面です。複数のトラッキングベンチマークで実行される体系的な比較評価は、提案されたアプローチの有効性を示しています。最初に、追跡対象の勾配と色の情報をより自然に記述するために特徴を融合する方法を提案し、融合された特徴を背景認識相関フィルターに導入して応答マップを取得します。 
[概要]シンプルでシンプルな戦略は、追跡用の新しいシステムを開発することです。これを使用して、効果的な機能のフィルターを作成し、モデルのドリフトを処理できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Temporal Autoencoder with U-Net Style Skip-Connections for Frame
  Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_59.html">
      <font color="black">Temporal Autoencoder with U-Net Style Skip-Connections for Frame
  Prediction</font>
    </a>
  </h2>
  <font color="black">循環学習率の利用についても説明し、標準的なアプローチよりも少ないエポックで低い損失スコアを達成することでトレーニング効率を向上させます。このペーパーでは、畳み込みLSTMを使用してU-を使用した時間オートエンコーダーを作成するトラフィックフレーム予測アプローチについて説明します。特定の都市のトポロジの詳細を失うことなく、さまざまなスケールで時空間依存関係をキャプチャするために、繰り返し発生する従来のコンピュータビジョン技術を組み合わせたネットスタイルのスキップ接続。都市全体のモビリティ動作を予測するための持続可能で斬新なソリューションを見つけることは、ますます成長しています。都市の複雑さが増し、人口が増加していることを考えると、問題が発生します。 
[概要]新しい論文では、畳み込みlstmを使用してオートエンコーダーを作成するトラフィックフレーム予測アプローチの概要を説明しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: CellSegmenter: unsupervised representation learning and instance
  segmentation of modular images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_60.html">
      <font color="black">CellSegmenter: unsupervised representation learning and instance
  segmentation of modular images</font>
    </a>
  </h2>
  <font color="black">構造化された背景を持つ挑戦的な合成マルチMNISTデータセットでメソッドを評価し、わずか数百のトレーニングエポックでほぼ完全な精度を達成します。最後に、細胞核イメージングデータセットで得られたセグメンテーション結果を示し、メソッドの能力を示します。多数のインスタンスを含む現実的なユースケースを処理しながら、高品質のセグメンテーションを提供します。これにより、任意の数のインスタンスへの外挿を可能にしながら、トレーニング時間が非常に高速になります。 
[概要]提案されたアルゴリズムは畳み込みで並列化されており、再発メカニズムはありません。オブジェクト-オブジェクトのオクルージョンを解決すると同時に、離れた非オクルージョンオブジェクトを独立して処理できます。また、透過的な後方正則化戦略を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Combining Semantic Guidance and Deep Reinforcement Learning For
  Generating Human Level Paintings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_61.html">
      <font color="black">Combining Semantic Guidance and Deep Reinforcement Learning For
  Generating Human Level Paintings</font>
    </a>
  </h2>
  <font color="black">3）焦点の合ったオブジェクトの際立った特徴は、新しいガイド付きバックプロパゲーションベースの焦点報酬を最大化することによって増幅されます。2）また、オブジェクトのローカリゼーションを組み合わせたニューラルアライメントモデルを通じて、前景オブジェクトの位置とスケールに不変性を導入します。最後に、挑戦的な仮想オブジェクトでメソッドの拡張を評価することにより、複数のフォアグラウンドオブジェクトインスタンスを持つ複雑なデータセットでのメソッドのさらなる有効性を示します。 KITTIデータセット。 
[要約]「明らかにこれが重要」は、cnn techの毎週の、特定のトピックの風変わりな見方です。これらのツールを使用して「ペイント方法」を教えるのはこれが初めてです。しかし、これらの方法は、所有する粒度と多様性をカバーするのに苦労しています。実世界の画像による</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Reduced Reference Perceptual Quality Model and Application to Rate
  Control for 3D Point Cloud Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_62.html">
      <font color="black">Reduced Reference Perceptual Quality Model and Application to Rate
  Control for 3D Point Cloud Compression</font>
    </a>
  </h2>
  <font color="black">400個の圧縮された3D点群を使用した主観的品質テストは、提案されたモデルが平均オピニオン評点とよく相関し、スピアマンの順位係数とピアソンの線形相関係数の点で最先端の完全な参照客観的尺度を上回っていることを示しています。 -歪みの最適化、エンコーダ設定は、ビットレートの制約を受ける再構成品質測定値を最大化することによって決定されます。これら2つの基準を満たすいくつかの品質測定値が画像とビデオ用に開発されましたが、3D点群にはそのようなものは存在しません。 。 
[概要]同じターゲットビットレートに対して、提案されたモデルに基づくレート歪みの強化は、レートよりも高い知覚品質を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Physics-aware Inference of Cloth Deformation for Monocular Human
  Performance Capture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_63.html">
      <font color="black">Deep Physics-aware Inference of Cloth Deformation for Monocular Human
  Performance Capture</font>
    </a>
  </h2>
  <font color="black">物理学をトレーニングプロセスに統合することで、学習した布の変形がどのように改善され、衣服を別個のジオメトリとしてモデル化できるようになり、布と体の交差が大幅に減少するかを示します。これにより、焼き付けられたしわなど、再構築で顕著なアーティファクトが発生します。一見重力に逆らうように見える信じられないほどの変形、および布と体の交差点..トレーニング中の弱い2Dマルチビュー監視のみに依存する私たちのアプローチは、現在の最先端の方法を大幅に改善し、明確なステップです。服を着た人間の変形する表面全体のリアルな単眼キャプチャに向けて。 
[ABSTRACT]既存の方法では、基礎となる物理的原理を考慮する代わりに、衣服をまったく推定したり、単純な幾何学的事前分布で衣服の変形をモデル化したりしません。これらの問題に対処するために、人に固有の学習ベースの方法を提案します。初めての物理監視を提供するためのトレーニングプロセスへの有限要素ベースのシミュレーションレイヤー</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Enhanced 3DMM Attribute Control via Synthetic Dataset Creation Pipeline -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_64.html">
      <font color="black">Enhanced 3DMM Attribute Control via Synthetic Dataset Creation Pipeline</font>
    </a>
  </h2>
  <font color="black">より優れた3D属性制御方法を開発するための重要な課題は、一方の属性が変更され、もう一方の属性が固定されているペアのトレーニングデータがないことです。たとえば、一方が男性でもう一方が女性であるがすべての3D面のペア人種や表情など、他の属性も同じです。GenerativeAdversarialNetworks（GAN）を介した2D画像の顔の属性操作は、その多くの実用的な用途のためにコンピュータービジョンやグラフィックスで一般的になっていますが、3D属性操作の研究は比較的未開発..このパイプラインに加えて、既存の方法と比較して3D属性制御の精度と多様性を向上させる拡張非線形3D条件付き属性コントローラーを提案します。 
[概要]プロジェクトは、3Dに基づく3D属性操作に基づいています。これらは、すべての3D面に適用されるのと同じセマンティック変更に基づいています。プロジェクトは、ガンの力を利用して3D面を作成するために作成されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Humble Teacher and Eager Student: Dual Network Learning for
  Semi-supervised 2D Human Pose Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_65.html">
      <font color="black">Humble Teacher and Eager Student: Dual Network Learning for
  Semi-supervised 2D Human Pose Estimation</font>
    </a>
  </h2>
  <font color="black">具体的には、2つのネットワークを相互に教え合うように学習します。半教師あり学習は、ラベルのない画像を探索することでモデルの精度を高めることを目的としています。これにより、信頼性の高い疑似ラベルを取得してトレーニングを安定させることができます。 
[ABSTRACT]最先端の方法は一貫性に基づいており、ラベルのない画像について学習します。これは、矛盾する予測が徐々に背景にプッシュされるためです。これにより、信頼性の高い疑似モデルラベルを取得して、トレーニングを安定させることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: EI-MTD:Moving Target Defense for Edge Intelligence against Adversarial
  Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_66.html">
      <font color="black">EI-MTD:Moving Target Defense for Edge Intelligence against Adversarial
  Attacks</font>
    </a>
  </h2>
  <font color="black">まず、クラウドデータセンターの複雑な教師モデルから差分知識蒸留を通じて小さなサイズの堅牢なメンバーモデルを取得します。この課題を克服するために、動的防御メカニズム、つまりEI-MTDを提案します。次に、動的スケジューリングポリシーに基づくBayesian Stackelbergゲームでは、サービスのターゲットモデルの選択に適用されます。 
[概要]いわゆる敵対的な例は、エッジノードの深層学習モデルをだまして誤分類する可能性があります。このため、エッジノードのリソースの制限により、クラウドデータセンターの場合と同様に複雑な防御メカニズムが提供される可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-19">
        <br><font color="black">2020-09-19</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Nets: What have they ever done for Vision? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_67.html">
      <font color="black">Deep Nets: What have they ever done for Vision?</font>
    </a>
  </h2>
  <font color="black">現在の形のディープネットは、コンピュータビジョンの根本的な問題、つまり、自然画像の非常に複雑なものによって引き起こされる組み合わせ爆発にどのように対処するかを克服し、視覚シーンの豊富な理解を得ることができない可能性が高いと主張します。人間の視覚が達成する..視覚アルゴリズムが実世界のアプリケーションでますます使用されるにつれて、パフォーマンス評価は単なる学術的な演習ではなく、実世界で重要な結果をもたらすことを強調します。これは長所と短所についての意見書です。ビジョンのためのディープネットの。 
[ABSTRACT]ディープネットは、ベンチマークデータセットを使用した特定の視覚的タスクで非常に優れたパフォーマンスを発揮しますが、汎用性、柔軟性、適応性ははるかに劣ります。この組み合わせ爆発により、「ビッグデータでは不十分」な状況に陥ります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-05-10">
        <br><font color="black">2018-05-10</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Object Detection with LiDAR Clues -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_68.html">
      <font color="black">Unsupervised Object Detection with LiDAR Clues</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチでは、3D点群に基づく候補オブジェクトセグメントが最初に生成されます。教師なしオブジェクト検出の重要性にもかかわらず、私たちの知る限り、この問題に対処する以前の作業はありません。さらに、別の主要な問題を特定することはめったにありません。コミュニティは、ロングテールおよびオープンエンド（サブ）カテゴリの分布に対応する必要があることに気づきました。 
[概要] LIDARの手がかりを使用して、スーパーテールのないオブジェクトを検出する最初の実用的な方法を紹介します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: GIF: Generative Interpretable Faces -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_69.html">
      <font color="black">GIF: Generative Interpretable Faces</font>
    </a>
  </h2>
  <font color="black">最近の方法は、教師なしの方法でさまざまな要因を解きほぐすことを試みるか、事前にトレーニングされたモデルに事後的に制御を追加することによって、部分的な制御を取得します。 FLAMEパラメータで満足のいく結果が得られない場合、レンダリングされたFLAMEジオメトリと測光の詳細の調整が適切に機能することがわかります。 
[概要]コード、データ、トレーニング済みモデルは、研究目的で公開されています。この研究は、パラメトリック制御を提供するが非現実的な画像を生成する一連の3D顔モデルに基づいています。ただし、無条件のガンは、困難な要因を絡ませることがあります。後で元に戻す</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-31">
        <br><font color="black">2020-08-31</font>
      </time>
    </span>
</section>
<!-- paper0: Fast Object Segmentation Learning with Kernel-based Methods for Robotics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_70.html">
      <font color="black">Fast Object Segmentation Learning with Kernel-based Methods for Robotics</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、事前にトレーニングされたマスクR-CNNに基づいており、さまざまなレイヤーが、新しいタスクのために再トレーニングされた分類器とリグレッサーのセットに置き換えられています。私たちのアプローチは、広く普及しているYCB-Videoデータセットで検証されています。 Computer Vision and Roboticsコミュニティで採用され、トレーニング時間の大幅な短縮（$ {\ sim} 6 \ times $）で、最先端のパフォーマンスを達成し、さらには超えることができることを示しています。大規模な問題に関する迅速なトレーニングを可能にする効率的なカーネルベースの方法を採用します。 
[概要]この作業では、オブジェクトセグメンテーションの新しいアーキテクチャを提案します。これは、最先端の方法で必要とされる時間の何分の1かで同等のパフォーマンスを提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Occlusion-Aware Depth Estimation with Adaptive Normal Constraints -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_71.html">
      <font color="black">Occlusion-Aware Depth Estimation with Adaptive Normal Constraints</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、深度推定精度の点で最先端を上回り、他のアルゴリズムよりもはるかに優れた人工屋内シーンの本質的な幾何学的特徴を保持します。したがって、深度推定アルゴリズムは、Combined Normal Map（CNM）制約を導入します。は、高曲率の特徴とグローバルな平面領域をより適切に保持するように設計されています。深度推定の精度をさらに向上させるために、複数の隣接するビューからの初期深度予測を1つの最終深度マップに集約する新しいオクルージョン認識戦略を導入します。現在の参照ビューの1つのオクルージョン確率マップ。 
[概要]深度マップからエクスポートされた3D点群は、多くの場合、人工のシーンの重要な幾何学的特徴を保持できません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-02">
        <br><font color="black">2020-04-02</font>
      </time>
    </span>
</section>
<!-- paper0: PGL: Prior-Guided Local Self-supervised Learning for 3D Medical Image
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_72.html">
      <font color="black">PGL: Prior-Guided Local Self-supervised Learning for 3D Medical Image
  Segmentation</font>
    </a>
  </h2>
  <font color="black">結果は、事前にトレーニングされたPGLモデルを使用してダウンストリームネットワークを初期化すると、ランダムな初期化とグローバル整合性ベースのモデルによる初期化の両方でパフォーマンスが大幅に向上することを示しています。位置合わせされた特徴マップ間の不一致..したがって、PGLモデルはローカル領域の特徴的な表現を学習し、したがって構造情報を保持することができます。 
[概要]「モデルモデルモデル」として特定されたモデルは、この問題に対処する大きな可能性を示しています。11種類の主要な人間の臓器をカバーする4つの公共コンピュータ断層撮影（ct）データセットで詳細に詳細に説明されています。 2つの腫瘍</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal Learning for Hateful Memes Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_73.html">
      <font color="black">Multimodal Learning for Hateful Memes Detection</font>
    </a>
  </h2>
  <font color="black">嫌いなミームもソーシャルネットワークを通じて憎悪を広めています。私たちはミームデータセットで広範な実験を行い、私たちの方法の有効性を示しました。嫌いなミームを自動的に検出することは、それらの有害な社会的影響を減らすのに役立ちます。 
[概要]嫌なミーム検出の課題は、視覚情報と文学的情報が調整される従来のマルチモーダルタスクとは異なり、そのマルチモーダル情報にあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Batch Normalization Embeddings for Deep Domain Generalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_74.html">
      <font color="black">Batch Normalization Embeddings for Deep Domain Generalization</font>
    </a>
  </h2>
  <font color="black">テスト時に、未知のドメインからのサンプルを同じ空間に投影し、既知のドメインの線形結合としてドメインのプロパティを推測します。最近のいくつかの方法では、複数のデータセットを使用してモデルをトレーニングし、ドメイン不変の特徴を抽出して、一般化することを望んでいます。目に見えないドメインへ..人気のあるドメイン一般化ベンチマークであるPACS、Office-31、Office-Caltechで、現在の最先端技術よりも分類精度が大幅に向上していることを示しています。 
[概要]最近のいくつかの方法では、複数のデータセットを使用してモデルをトレーニングし、ドメインの政治的特徴を抽出します。pacは統計を使用して、ドメインのメンバーシップを距離関数で測定できる場所を見つけます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Magnification-Arbitrary Upsampling over 3D Point Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_75.html">
      <font color="black">Deep Magnification-Arbitrary Upsampling over 3D Point Clouds</font>
    </a>
  </h2>
  <font color="black">この論文では、与えられた疎な点群から密な点群を生成して、オブジェクト/シーンの基礎となる幾何学的構造をモデル化する問題に対処します。具体的には、線形近似定理を利用して、最初に問題を明示的に定式化します。内挿重みと高次近似誤差..私たちの知る限り、これは3D点群上で倍率-任意のアップサンプリングを実現できる最初のエンドツーエンドの学習ベースの方法です。 
[ABSTRACT] mapu-netは、1回のトレーニングで単一のニューラルネットワークであり、任意のアップサンプリング係数を処理できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Convolutional Neural Networks for cytoarchitectonic brain mapping at
  large scale -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_76.html">
      <font color="black">Convolutional Neural Networks for cytoarchitectonic brain mapping at
  large scale</font>
    </a>
  </h2>
  <font color="black">細胞構築マッピングにディープニューラルネットワークを適用すると、脳領域の高解像度モデルを可能にする新しい視点が開かれ、CNNが導入されて脳領域の境界が識別されます。モデルは、欠落しているすべての注釈を高精度で、以前のワークフローよりも高速に作成することを学習します。オブザーバーに依存しないマッピングに基づいています。これは、注釈付きのセクション画像のペアでトレーニングされ、間に多数の注釈なしセクションがあるディープ畳み込みニューラルネットワーク（CNN）に基づいています。 
[ABSTRACT]細胞構築は、脳の微細構造組織の基本原理です。神経細胞の配置と構成の地域差は、接続性と機能の変化の指標です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: CRACT: Cascaded Regression-Align-Classification for Robust Visual
  Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_77.html">
      <font color="black">CRACT: Cascaded Regression-Align-Classification for Robust Visual
  Tracking</font>
    </a>
  </h2>
  <font color="black">重要なのは、位置合わせステップを介してボックスの回帰と分類を橋渡しすることです。これにより、堅牢性が向上した提案分類のより正確な機能が得られます。オブジェクトの外観の変化に対処するために、オフラインを活用するボックス分類の識別識別コンポーネントを導入します。ターゲットとバックグラウンドを区別するための信頼性の高いきめ細かいテンプレートとオンラインの豊富なバックグラウンド情報。 -多くのベンチマークでのアートパフォーマンス。 
[ABSTRACT]これらの提案のオーバーホールは、追跡パフォーマンスを向上させるために広く採用されています。しかし、重要なのは、提案ネットワークネットワークネットワークと分類をブリッジすることです。ブリッジするには、cracに役立つピラミッドロイアラインを紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Unfolding the Alternating Optimization for Blind Super Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_78.html">
      <font color="black">Unfolding the Alternating Optimization for Blind Super Resolution</font>
    </a>
  </h2>
  <font color="black">この2段階のソリューションには、2つの独立してトレーニングされたモデルが含まれ、相互に互換性がない可能性があります。ソースコードはhttps://github.com/greatlog/DAN.gitで入手できます。最初のステップでは、LR画像からの限られた情報しか利用できないため、非常に正確なブラーカーネルを予測することは困難です。 
[概要] 2ステップのソリューションには、2つの独立してトレーニングされたモデルが含まれますが、これらは互いに十分に互換性がない可能性があります。最初のステップでは、lr画像からの限られた情報しか利用できないため、高精度のぼやけたモデルを予測することは困難です。これら2つの畳み込みモデル低解像度の解像度を含むニューラルモジュールは、推定されたostrollableモデルに置き換えることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Deformable Neural Radiance Fields -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_79.html">
      <font color="black">Deformable Neural Radiance Fields</font>
    </a>
  </h2>
  <font color="black">D-NeRFは、何気なく撮影した自撮り写真/ビデオを変形可能なNeRFモデルに変換できることを示します。これにより、「ナーフ」と呼ばれる任意の視点から被写体を写実的にレンダリングできます。これらのNeRFのような変形場は極小値になりやすいことを観察し、よりロバストな最適化を可能にする座標ベースのモデルの粗いものから細かいものへの最適化方法を提案します。非現実的に再構築できる最初の方法を提示します。携帯電話からさりげなくキャプチャした写真/ビデオを使用して、シーンを厳密に変形させます。 
[ABSTRACT] s --d --nerf-は神経放射輝度フィールド（nerf）を拡張します。これらには、ロバスト性をさらに向上させるフィールドの弾性正則化が含まれます。この方法は、2台の携帯電話でリグを使用してデータをキャプチャすることで使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Attention Aware Cost Volume Pyramid Based Multi-view Stereo Network for
  3D Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_80.html">
      <font color="black">Attention Aware Cost Volume Pyramid Based Multi-view Stereo Network for
  3D Reconstruction</font>
    </a>
  </h2>
  <font color="black">結果は、私たちのモデルがほとんどの最先端（SOTA）メソッドよりも優れていることを示しました。このペーパーでは、高解像度の深度を実現するための粗い深度から細かい深度の推論戦略を紹介します。このプロジェクトのコードベースはhttps：にあります。 //github.com/ArthasMil/AACVP-MVSNet。 
[ABSTRACT]以前の学習ベースの再構成アプローチはうまく機能しました。それらのほとんどは、平面掃引ボリュームを使用して固定解像度で深度マップを推定します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Relation3DMOT: Exploiting Deep Affinity for 3D Multi-Object Tracking
  from View Aggregation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_81.html">
      <font color="black">Relation3DMOT: Exploiting Deep Affinity for 3D Multi-Object Tracking
  from View Aggregation</font>
    </a>
  </h2>
  <font color="black">最後に、提案されたモデルがKITTI追跡ベンチマークで最先端のパフォーマンスを達成していることを明らかにするための広範な評価を提供します。これらの問題を解決するために、まず、両方の2Dからキャプチャされた2Dと3Dの外観特徴を融合するために共同特徴抽出器を採用します。 RGB画像と3D点群をそれぞれ提案し、RelationConvという名前の新しい畳み込み演算を提案して、隣接するフレーム内のオブジェクトの各ペア間の相関をより有効に活用し、さらにデータを関連付けるための深い親和性マトリックスを学習します。ほとんどのMOTメソッドはオブジェクト検出とデータ関連付け処理を含む、検出による追跡パイプライン。 
[ABSTRACT] motは、自律ナビゲーションで重要な役割を果たします。これらのアプローチのほとんどは、追跡のために2d rgbシーケンス内のオブジェクトを検出します。これは、3D空間でオブジェクトをローカライズする際の信頼性の欠如です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Evaluation of Multimodal Models under Realistic Gray Box
  Assumption -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_82.html">
      <font color="black">Adversarial Evaluation of Multimodal Models under Realistic Gray Box
  Assumption</font>
    </a>
  </h2>
  <font color="black">この作業では、マルチモーダル（画像+テキスト）モデルの、ユニモーダル（画像またはテキストのみ）モデルに関する以前の文献で説明されているものと同様の敵対的脅威に対する脆弱性を調べます。これらの「グレーボックス」仮定のさまざまなレベルで作業します。マルチモーダル分類に固有の新しい攻撃方法を開発し、Hateful Memes Challenge分類タスクで評価します。複数のモダリティを攻撃すると、ユニモーダル攻撃のみよりも強力な攻撃が発生し（ケースの最大73％でエラーが発生します）、ユニモーダル画像が私たちが調査したマルチモーダル分類器への攻撃は、文字ベースのテキスト拡張攻撃よりも強力でした（それぞれ平均45％と30％のケースでエラーを引き起こしました）。 
[概要]部分的なモデルの知識とアクセスの現実的な仮定を紹介します。これらの仮定は、標準の「ブラックボックス」二分法とは異なります。さまざまな理論が、敵対的攻撃に関する現在の文献で一般的です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: The Virtual Goniometer: A new method for measuring angles on 3D models
  of fragmentary bone and lithics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_83.html">
      <font color="black">The Virtual Goniometer: A new method for measuring angles on 3D models
  of fragmentary bone and lithics</font>
    </a>
  </h2>
  <font color="black">仮想ゴニオメーターは、オープンソースのメッシュ処理パッケージMeshlabおよびBlenderのプラグインとして利用できるため、考古学的手法を改善し、人類学的問題に対処するためのゴニオメトリーの可能性を探る研究者が簡単にアクセスできます。手動ゴニオメーターと仮想ゴニオメーターを使用すると、仮想ゴニオメーターの一貫性と信頼性が大幅に向上します。さらに、仮想ゴニオメーターを使用すると、複数のユーザー間でも角度測定値を正確に複製できます。これは、ゴニオメーターベースの研究の再現性にとって重要です。 
[概要]仮想ゴニオメーターは、迅速なデータ収集を可能にし、手動ゴニオメーターでは物理的にアクセスできない多くの角度の測定を可能にします。これは、ゴニオメーターベースの研究にとって重要な角度の測定に使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: An Efficient and Scalable Deep Learning Approach for Road Damage
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_84.html">
      <font color="black">An Efficient and Scalable Deep Learning Approach for Road Damage
  Detection</font>
    </a>
  </h2>
  <font color="black">この論文では、画像ベースの苦痛データをリアルタイムで分析するための深層学習ベースの調査スキームを紹介します。モバイルデバイスを使用して撮影された、縦、横、ワニの亀裂などの亀裂苦痛タイプの多様な集団からなるデータベース次に、舗装の亀裂検出用に調整された効率的でスケーラブルなモデルのファミリがトレーニングされ、さまざまな拡張ポリシーが検討されます。 
[要約]タイムリーな評価の実施に失敗すると、インフラストラクチャの深刻な構造的および経済的損失または完全な再構築につながる可能性があります。データベースには、亀裂の苦痛の種類の多様な集団が含まれています。提案されたモデルは、52％から56％の範囲のf1-スコアをもたらしました。調査員の平均時間は178〜10画像/秒</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-18">
        <br><font color="black">2020-11-18</font>
      </time>
    </span>
</section>
<!-- paper0: torchdistill: A Modular, Configuration-Driven Framework for Knowledge
  Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_85.html">
      <font color="black">torchdistill: A Modular, Configuration-Driven Framework for Knowledge
  Distillation</font>
    </a>
  </h2>
  <font color="black">このフレームワークは、ユーザーが宣言型PyYAML構成ファイルによって実験を設計できるように設計されており、研究者が最近提案されたMLコード完全性チェックリストを完了するのに役立ちます。また、主要な機械学習で提示されたImageNetおよびCOCOデータセットで元の実験結果の一部を再現します。 ICLR、NeurIPS、CVPR、ECCVなどの会議（最近の最先端の方法を含む）。知識の蒸留（転送）が研究コミュニティから注目を集めている一方で、この分野の最近の発展により、再現性のあるものの必要性が高まっています。このような高品質で再現性のある深層学習研究への障壁を下げるための研究と高度に一般化されたフレームワーク。 
[概要]他の関心のある研究者が元の作品を複製するのを助けるために、いくつかの研究者が知識蒸留研究で使用されるフレームワークを自発的に公開しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Recalibration of Neural Networks for Point Cloud Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_86.html">
      <font color="black">Recalibration of Neural Networks for Point Cloud Analysis</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、ベースライン法と比較してModelNet40の精度が最大1％向上することを示しています。アプローチを検証するために2セットの実験を実行します。再キャリブレーションは画像分析のために広く研究されていますが、まだ行われていません。形状表現に使用されます。 
[ABSTRACT] re-3Dポイントクラウド用のディープニューラルネットワークのキャリブレーションモジュール。ブロックを使用して、ポイントクラウドアーキテクチャの精度を向上させることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Simple statistical methods for unsupervised brain anomaly detection on
  MRI are competitive to deep learning methods -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_87.html">
      <font color="black">Simple statistical methods for unsupervised brain anomaly detection on
  MRI are competitive to deep learning methods</font>
    </a>
  </h2>
  <font color="black">ここでは、ボクセル単位（ベースラインおよび共分散）モデルや空間パターンを使用した線形射影法などの単純な統計手法でも、教師なし病理検出でDL相当（3D畳み込みオートエンコーダー）のパフォーマンスを実現できることを示します。すべての手法がトレーニングされました（ N = 395）および比較（N = 44）は、それぞれ、健康な症例と病理学的症例の新しい専門家がキュレートしたマルチパラメトリック（8シーケンス）ヘッドMRIデータセットです。トレーニングと理解がかなり簡単です。 
[概要]ディープラーニング（mri）は、2Dデータの処理に有望であることが示されています。これらの単純な手法は、小さな病変をより正確に検出できます。トレーニングと理解が非常に簡単です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Generalized Focal Loss V2: Learning Reliable Localization Quality
  Estimation for Dense Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_88.html">
      <font color="black">Generalized Focal Loss V2: Learning Reliable Localization Quality
  Estimation for Dense Object Detection</font>
    </a>
  </h2>
  <font color="black">ローカリゼーション品質推定（LQE）は、非最大抑制処理に役立つ正確なランキングスコアを提供し、検出パフォーマンスを向上させることができるため、最近の高密度オブジェクト検出器の進歩において非常に重要で人気があります。このようなプロパティにより、バウンディングボックスの分布統計が作成されます。その実際のローカリゼーション品質と高い相関関係があります。一般的な方法として、ほとんどの既存の方法は、オブジェクト分類またはバウンディングボックス回帰と共有されるバニラ畳み込み特徴を通じてLQEスコアを予測します。 
[概要]バニリングボックスは、gflv1で「一般的な分布」としてインスピレーションを得て導入されています。これは、予測されたバウンディングボックスの不確実性をよく説明しています。これらは、オブジェクト分類と共有されるバニラ畳み込み特徴に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Iterative training of neural networks for intra prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_89.html">
      <font color="black">Iterative training of neural networks for intra prediction</font>
    </a>
  </h2>
  <font color="black">反復的にトレーニングされたニューラルネットワークをH.265（HM-16.15）に入れると、平均dBレートの-4.2％の削減が得られます。さらに、反復プロセスにより、ニューラルネットワークのトレーニングに不可欠なトレーニングデータクレンジングの設計が可能になります。次に、前の反復でトレーニングされたニューラルネットワークを含むコーデックを介して画像の分割からブロックが繰り返し収集され、それぞれがそのコンテキストとペアになり、ニューラルネットワークが新しいペアで再トレーニングされます。 
[ABSTRACT]イントラ予測作業により、ネットワークはコーデックを改善できます。最初のコーデックにすでに存在するものよりも際立っているイントラ予測関数を学習し、レートの観点からコーデックをブーストできます-歪み</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-15">
        <br><font color="black">2020-03-15</font>
      </time>
    </span>
</section>
<!-- paper0: SurFree: a fast surrogate-free black-box attack -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_90.html">
      <font color="black">SurFree: a fast surrogate-free black-box attack</font>
    </a>
  </h2>
  <font color="black">機械学習分類器は、回避攻撃を非常に受けやすいです。敵対的な例は、わずかに変更された入力であり、元の入力に知覚的に近いまま、誤って分類されます。このペーパーでは、クエリの量を同様に大幅に削減する幾何学的アプローチであるSurFreeを紹介します。最も難しい設定：ブラックボックスの意思決定ベースの攻撃（上位1つのラベルのみが使用可能）。 
[概要]これは、ブラックボックススコアベースのセットアップに関係します。クエリの量は、数百万から数千未満になりました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Privacy-preserving Collaborative Learning with Automatic Transformation
  Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_91.html">
      <font color="black">Privacy-preserving Collaborative Learning with Automatic Transformation
  Search</font>
    </a>
  </h2>
  <font color="black">したがって、効果的な緩和ソリューションが緊急に求められています。データのプライバシーとモデルのユーザビリティに対する変換の影響を定量化するために2つの新しいメトリックを採用します。これにより、検索速度が大幅に向上します。このホワイトペーパーでは、データ拡張を活用して再構築を無効にすることを提案します。攻撃：慎重に選択された変換ポリシーを使用して機密画像を前処理することにより、攻撃者が対応する勾配から有用な情報を抽出することが不可能になります。 
[ABSTRACT]新しい作品は、敵が共有勾配から敏感なトレーニングサンプルを完全に回復できることを発見しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Open-World Learning Without Labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_92.html">
      <font color="black">Open-World Learning Without Labels</font>
    </a>
  </h2>
  <font color="black">ここでは、エージェントが教師なしの方法でラベルのないデータのストリームから新しいクラスを学習できるようにする新しいフレームワークを提案します。オープンワールド学習は、自律エージェントが知らないことを検出し、それらを時間の経過とともに学習する問題です。定常的で終わりのないデータの流れ。オープンワールド環境では、トレーニングデータと客観的基準が一度に利用できることはありません。また、ラベルなしのオープンワールド学習のための新しいメトリックを導入します。 
[概要]自律的な真のオープン-世界の終わりのない学習エージェント。私たちの理論と方法は、自律的な真のオープン-世界の終わりのない学習を開発するための出発点になると期待しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: RobustPointSet: A Dataset for Benchmarking Robustness of Point Cloud
  Classifiers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_93.html">
      <font color="black">RobustPointSet: A Dataset for Benchmarking Robustness of Point Cloud
  Classifiers</font>
    </a>
  </h2>
  <font color="black">私たちの実験は、点群分類のすべての進歩にもかかわらず、変換されたテストセットで評価したときに一貫して優れたパフォーマンスを発揮する単一のアーキテクチャはないことを示しています---いくつかの劇的な失敗---これらのデータセットでトレーニングされたモデルは、解釈できず、直感的ではありませんトレーニング時に「見えない」変換を含むデータが提示された場合の方法。この目的のために、RobustPointSetと呼ばれる、入力変換に対する点群分類モデル（データ拡張とは無関係）のロバスト性分析用に公開されているデータセットを作成します。 
[概要]ディープモデルはこれらのデータセットでトレーニングされています。これらのデータセットは、解釈不能で直感的でない方法で失敗します。これらのデータには、トレーニング時に「見えない」観測が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Detection as Regression: Certified Object Detection by Median Smoothing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_94.html">
      <font color="black">Detection as Regression: Certified Object Detection by Median Smoothing</font>
    </a>
  </h2>
  <font color="black">まず、オブジェクト検出から回帰問題への削減を提示します。$ \ ell_2 $に制限された攻撃に対するオブジェクト検出のための、モデルにとらわれない、トレーニング不要の、認定された最初の防御を取得します。この作業は、最近の進歩に動機付けられています。ランダム化平滑化による認定分類について。 
[ABSTRACT]敵対的なトレーニングは画像分類器の堅牢性を向上させることができますが、オブジェクト検出への直接の拡張は非常に高価です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: GOCor: Bringing Globally Optimized Correspondence Volumes into Your
  Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_95.html">
      <font color="black">GOCor: Bringing Globally Optimized Correspondence Volumes into Your
  Neural Network</font>
    </a>
  </h2>
  <font color="black">GOCorモジュールを広範なアブレーション実験で分析します。ただし、画像内の複数の類似領域を明確にする場合、このポイントツーポイントの特徴比較は不十分であり、エンドタスクのパフォーマンスに深刻な影響を及ぼします。モジュールによって生成される対応ボリュームは次のとおりです。シーン内の同様の領域を明示的に説明する内部最適化手順の結果。 
[ABSTRACT] gocorは、特徴相関層の直接の代替として機能する、完全に微分可能な高密度マッチングモジュールです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Emotional Semantics-Preserved and Feature-Aligned CycleGAN for Visual
  Emotion Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_96.html">
      <font color="black">Emotional Semantics-Preserved and Feature-Aligned CycleGAN for Visual
  Emotion Adaptation</font>
    </a>
  </h2>
  <font color="black">教師なしドメイン適応（UDA）は、あるラベル付きソースドメインでトレーニングされたモデルを別のラベルなしターゲットドメインに転送する問題を研究します。まず、CycleGANをマルチで改善することにより、ピクセルレベルでソースドメインとターゲットドメインを整列させる適応ドメインを生成します。 -スケールの構造化されたサイクルの一貫性の喪失..大規模なラベル付きトレーニングデータのおかげで、ディープニューラルネットワーク（DNN）は多くのビジョンおよびマルチメディアタスクで目覚ましい成功を収めています。 
[概要] dnnsは、ラベルが少ないデータセットを保持できません。ただし、ドメインシフトが存在するため、dnnsの知識を保持できません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Attack on Facial Recognition using Visible Light -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CV/paper_97.html">
      <font color="black">Adversarial Attack on Facial Recognition using Visible Light</font>
    </a>
  </h2>
  <font color="black">結果が収集されると、プロジェクトの目的は結果に合うように調整されました。プロジェクトの現在の調査結果と可能な将来の推奨事項の詳細な分析が提示されます。このため、次のペーパーでは、最初に赤外線を使用した敵対攻撃を調査してから、可視光攻撃。 
[概要]これらのシステムは、人体や顔を高い精度で識別するように訓練されています。この論文では、顔認識システムで可視光を使用した敵対攻撃の最終レポートを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: XTQA: Span-Level Explanations of the Textbook Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CL/paper_0.html">
      <font color="black">XTQA: Span-Level Explanations of the Textbook Question Answering</font>
    </a>
  </h2>
  <font color="black">この問題に対処するために、提案された粗粒度から細粒度のアルゴリズムに基づいて、TQA（XTQA）のスパンレベルの説明に向けた新しいアーキテクチャを考案します。これにより、回答だけでなく、それらを選択するためのスパンレベルの証拠も提供できます。学生向け..実験結果は、XTQAがベースラインと比較して最先端のパフォーマンスを大幅に改善することを示しています。このアルゴリズムは、最初にTF-IDFメソッドを使用して質問に関連する上位$ M $段落を大まかに選択し、次に上位$を選択します。 K $の証拠は、質問に対する各スパンの情報ゲインを計算することにより、これらの段落内のすべての候補スパンから細かくスパンされます。 
[要約]このタスクの説明性は、学生を重要な側面として位置付ける必要があります。質問に答えるには、学生が考慮される可能性が高くなります。このアルゴリズムは、最初に質問に関連する上位$ m $段落を選択します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Evaluating Input Representation for Language Identification in
  Hindi-English Code Mixed Text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CL/paper_1.html">
      <font color="black">Evaluating Input Representation for Language Identification in
  Hindi-English Code Mixed Text</font>
    </a>
  </h2>
  <font color="black">LSTMモデルとともにサブワード表現が最良の結果をもたらすことを示します。言語識別のタスクはトークン分類タスクとして定式化されます。このタスクのさまざまな深層学習モデルと入力表現の組み合わせを評価します。 
[概要]コード-混合テキストは複数の言語で書かれたテキストで構成されます。人々はそのようなテキストを処理する傾向があり、現在の自然言語処理技術では不十分です。監視された設定では、文の各単語に関連する言語ラベルがあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: The Geometry of Distributed Representations for Better Alignment,
  Attenuated Bias, and Improved Interpretability -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CL/paper_2.html">
      <font color="black">The Geometry of Distributed Representations for Better Alignment,
  Attenuated Bias, and Improved Interpretability</font>
    </a>
  </h2>
  <font color="black">その結果、無効な関連付け（さまざまな人種や、善と悪の極概念との関連付けなど）が作成され、表現によって伝播され、それらが使用されるさまざまなタスクで不公平な結果につながります。この作業は、これらのいくつかに対処します。このような表現の透明性と解釈可能性に関する問題。単語、テキスト、画像、知識グラフ、その他の構造化データの高次元表現は、機械学習やデータマイニングのさまざまなパラダイムで一般的に使用されています。 
[要約]これらの表現は解釈可能性の程度が異なり、効率的な分散表現は緩和の損失を犠牲にします。これは、基礎となるデータから学習された社会的バイアスが未知の次元で捕捉され、閉塞されることを意味します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Vocal Tract Length Perturbation for Text-Dependent Speaker Verification
  with Autoregressive Prediction Coding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CL/paper_3.html">
      <font color="black">Vocal Tract Length Perturbation for Text-Dependent Speaker Verification
  with Autoregressive Prediction Coding</font>
    </a>
  </h2>
  <font color="black">次に、提案されたVTL法をAPCおよび話者判別BN機能に適用します。この手紙では、テキスト依存話者検証（TD-SV）のための声道長（VTL）摂動法を提案します。 -SVシステムはVTLファクターごとに1つずつトレーニングされ、スコアレベルの融合が適用されて最終決定が行われます。次に、自己監視の目的で自動回帰を使用してディープニューラルネットワークをトレーニングすることによって抽出されたボトルネック（BN）機能を調べますTD-SVの予測コーディング（APC）を、よく研究されている話者判別BN機能と比較します。 
[概要]提案されたシステムは、スコアドメインのmfccと2つのbn機能に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: A Panoramic Survey of Natural Language Processing in the Arab World -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CL/paper_4.html">
      <font color="black">A Panoramic Survey of Natural Language Processing in the Arab World</font>
    </a>
  </h2>
  <font color="black">NLPは、コンピュータサイエンス、言語学、認知科学、心理学、数学などに関連する非常に学際的な分野です。自然言語という用語は、意図せずに人間の中で自然に進化したシンボリックコミュニケーション（音声、署名、または記述）のシステムを指します。人間の計画と設計..計算言語学または人間言語技術とも呼ばれる自然言語処理（NLP）は、音声認識と合成、機械翻訳などのアプリケーションを構築するための自然言語のモデリングに焦点を当てた人工知能（AI）のサブフィールドです。 、光学的文字認識（OCR）、感情分析（SA）、質問回答、対話システムなど。
[要約]人工的に構築されたアラビア語や日本語などの自然言語。これらは、エスペラントやパイソンなどの人工的に構築されたものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Non-Attentive Tacotron: Robust and Controllable Neural TTS Synthesis
  Including Unsupervised Duration Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CL/paper_5.html">
      <font color="black">Non-Attentive Tacotron: Robust and Controllable Neural TTS Synthesis
  Including Unsupervised Duration Modeling</font>
    </a>
  </h2>
  <font color="black">ガウスアップサンプリングを使用すると、教師なしタコトロンは、自然性について5スケールの平均オピニオン評点4.41を達成し、タコトロン2をわずかに上回ります。トレーニングデータで正確なターゲット期間が不足しているか利用できない場合は、罰金を使用する方法を提案します。半教師ありまたは教師なしの方法で継続時間予測子をトレーニングするための粒度のある変分オートエンコーダー。教師ありトレーニングとほぼ同じ結果が得られます。継続時間予測子により、推定時間での継続時間の発話全体と電話ごとの両方の制御が可能になります。 
[概要]これは、アラインされていないマナー比率と単語の削除率に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: SECNLP: A Survey of Embeddings in Clinical Natural Language Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CL/paper_6.html">
      <font color="black">SECNLP: A Survey of Embeddings in Clinical Natural Language Processing</font>
    </a>
  </h2>
  <font color="black">最後に、臨床包埋の研究を前進させる将来の方向性のいくつかで締めくくります。臨床包埋を9つのタイプに分類し、各包埋タイプについて詳細に説明します。さまざまな評価方法と、それに続く臨床のさまざまな課題に対する可能な解決策について説明します。埋め込み。 
[概要]埋め込みの単純な表現は、埋め込みを無視するのが簡単です。さまざまな医療コーパスとその特性、医療コードについて説明し、簡単な概要と人気のある埋め込みモデルの比較を示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-03-04">
        <br><font color="black">2019-03-04</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Expand: Reinforced Pseudo-relevance Feedback Selection for
  Information-seeking Conversations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CL/paper_7.html">
      <font color="black">Learning to Expand: Reinforced Pseudo-relevance Feedback Selection for
  Information-seeking Conversations</font>
    </a>
  </h2>
  <font color="black">ランカーのパフォーマンスは、セレクターが有用なPRF用語を抽出するようにガイドし、タスクのパフォーマンスを向上させるための報酬として機能します。具体的には、有用なPRF用語を抽出して応答候補を強化する強化セレクターと、BERTベースの応答ランカーを提案しました。 PRFで強化された応答をランク付けします。ただし、既存の調査はヒューリスティックルールに基づいているか、手動で大量のラベルを付ける必要があります。 
[要約]疑似関連性フィードバック（prf）は、外部ドキュメントからのprf信号を組み込む際の有効性を実証しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Representations for Modeling Variation in English Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CL/paper_8.html">
      <font color="black">Neural Representations for Modeling Variation in English Speech</font>
    </a>
  </h2>
  <font color="black">また、これらの神経音声表現は、分節の違いだけでなく、発音表記で使用される離散記号のセットでは表現できないイントネーションと持続時間の違いもキャプチャすることを示します。これらの表現を使用して、非単語間の単語ベースの発音の違いを計算します。英語のネイティブスピーカーとネイティブスピーカー、および人間のネイティブらしさの判断と比較することによってこれらの違いを評価します。音声の変化は、発音表記を使用して表され、調査されることがよくありますが、音声の転写には時間がかかり、エラーが発生しやすくなります。 
[ABSTRACT]トランスフォーマー-ネイティブの音声表現により、パフォーマンスが大幅に向上します。トランスフォーマーベースのトランスフォーマーモデルの使用は、最終レイヤーではなく1つ以上の中間レイヤーで最も効果的であることを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-task Language Modeling for Improving Speech Recognition of Rare
  Words -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CL/paper_9.html">
      <font color="black">Multi-task Language Modeling for Improving Speech Recognition of Rare
  Words</font>
    </a>
  </h2>
  <font color="black">これらの追加タスクでトレーニングされた再スコアリングモデルは、言語モデリングタスクのみでトレーニングされたベースライン再スコアリングモデルよりも、一般的なテストで1.4％、単語誤りの観点から設定されたまれな単語テストで2.6％優れていることを示します。相対レート（WERR）。ただし、これらのシステムの平均精度は高い場合でも、まれなコンテンツの単語のパフォーマンスは、ハイブリッドASRシステムよりも遅れることがよくあります。この論文では、マルチタスクを備えたセカンドパスシステムを提案します。学習、セマンティックターゲット（インテントやスロット予測など）を利用して、音声認識のパフォーマンスを向上させます。 
[概要]新しい研究では、音声認識のパフォーマンスを向上させるためにマルチタスク学習を備えたセカンドパスシステムを提案しています。音声認識を向上させるためにセマンティックターゲットを使用したセカンドパスシステムを提案しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Pre-training Text-to-Text Transformers for Concept-centric Common Sense -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/cs.CL/paper_10.html">
      <font color="black">Pre-training Text-to-Text Transformers for Concept-centric Common Sense</font>
    </a>
  </h2>
  <font color="black">概念中心の常識知識でPTLMを補強するために、この論文では、テキストから常識を学習するための生成的および対照的な目的の両方を提案し、PTLMを段階的に事前トレーニングするための中間の自己教師あり学習タスクとして使用します（タスク固有の前に）ダウンストリームデータセットの微調整）。広範な実験結果は、私たちの方法である概念認識言語モデル（CALM）が、外部の知識に依存することなく、事前にトレーニングされたテキストからテキストへの変換器のパラメーターに、より常識的な知識を詰め込むことができることを示しています。グラフを作成すると、NLUタスクとNLGタスクの両方でパフォーマンスが向上します。比較的小さなコーパスで数ステップの事前トレーニングを段階的に行うだけで、CALMはベースラインメソッドよりも一定のマージンで優れており、一部の大きなPTLMと同等であることがわかります。そのCALMは、PTLMの常識的な推論能力を向上させるための一般的なプラグアンドプレイ方法として機能します。 
[概要]これらの事前訓練ミッションが完全に訓練されたのはこれが初めてです。ただし、これらは特にptlmのモデルではありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-24">
        <br><font color="black">2020-10-24</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Detection and Evaluation of human and machine generated speech in
  spoofing attacks on automatic speaker verification systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.AS/paper_0.html">
      <font color="black">Detection and Evaluation of human and machine generated speech in
  spoofing attacks on automatic speaker verification systems</font>
    </a>
  </h2>
  <font color="black">この論文では、ブラックボックスおよびホワイトボックスASVシステムで、人間のなりすまし（音声偽装）ベースの攻撃の可能性を、マシン生成音声に基づく攻撃と比較します。また、独自の側面をキャプチャする機能を使用して対策を検討します。機械は人間の音声生成メカニズムの細かいレベルの複雑さの多くをエミュレートできないという仮説の下で、人間の音声生成の例..基本的な周波数シーケンス関連のエントロピー、スペクトルエンベロープ、および非周期的パラメータが、のロバストな検出の有望な候補であることを示します。未知の方法で生成された偽造音声。 
[概要]使用される手法は悪意のある攻撃に対して脆弱であることがよくあります。これにより、詐欺師はシステムをバイパスしてアクセスできます。また、人間の音声生成の独自の側面をキャプチャする機能を使用して対策を検討します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-07">
        <br><font color="black">2020-11-07</font>
      </time>
    </span>
</section>
<!-- paper0: A Lightweight Music Texture Transfer System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.AS/paper_1.html">
      <font color="black">A Lightweight Music Texture Transfer System</font>
    </a>
  </h2>
  <font color="black">このシステムを複数の観点から評価し、実験結果から、効果音と計算性能の両方で説得力のある結果が得られることが明らかになりました。そのコアアルゴリズムは、サウンドをテクスチャスペクトルとして表すコンバーター、対応するリコンストラクター、およびフィードフォワード転送で構成されています。ネットワーク..しかし、ニューラルネットワークを使用した音楽特徴転送の現在の方法は、実用化にはほど遠い。 
[概要]ニューヨークを拠点とする調査によると、データの使用は公開されていませんが、ニューラルネットワークを使用した音楽機能の転送の新しい方法は公開されていません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-09-27">
        <br><font color="black">2018-09-27</font>
      </time>
    </span>
</section>
<!-- paper0: MTCRNN: A multi-scale RNN for directed audio texture synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.AS/paper_2.html">
      <font color="black">MTCRNN: A multi-scale RNN for directed audio texture synthesis</font>
    </a>
  </h2>
  <font color="black">さまざまなデータセットでのモデルのパフォーマンスを示し、さまざまなメトリックでのパフォーマンスを調べ、いくつかの潜在的なアプリケーションについて説明します。これらの複雑なサウンドには複数のタイムスケールのパターンが含まれているため、従来の方法でモデル化するのは困難です。オーディオテクスチャは環境音のサブセット。多くの場合、十分に長い時間枠内で安定した統計的特性を持つと定義されますが、局所的に構造化されていない場合があります。 
[概要]テクスチャには、雨、風、エンジンなどの工業用音が含まれます。これらの音は、単純な音で定義されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Soft-Median Choice: An Automatic Feature Smoothing Method for Sound
  Event Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.AS/paper_3.html">
      <font color="black">Soft-Median Choice: An Automatic Feature Smoothing Method for Sound
  Event Detection</font>
    </a>
  </h2>
  <font color="black">実験により、提案された方法が対照的なアルゴリズムよりも高い精度と再現率を達成することが明らかになりました。まず、畳み込みリカレントニューラルネットワーク（CRNN）では、1次元（1-D）畳み込み層が追加され、より多くの情報が時間的に抽出されます。既存のサウンドではイベント検出（SED）アルゴリズムでは、抽出された特徴の粗さが精度と再現率の低下を引き起こします。 
[ABSTRACT]ソフト-中央値選択に基づく新しい自動特徴平滑化アルゴリズムが提案されています。この問題を再現するために、「ソフト」システムに基づく新しいシステムが提案されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Deep generative models for musical audio synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.AS/paper_4.html">
      <font color="black">Deep generative models for musical audio synthesis</font>
    </a>
  </h2>
  <font color="black">さらに、機械学習システムは、これらのモデルの制御およびナビゲーション戦略を設計するための新しい手法を提供しています。オーディオ合成用の最近の生成的深層学習システムは、トレーニングするデータによって定義される音の任意の空間を横断できるモデルを学習できます。これはペーパーは、サウンドモデリングの実践を変えているディープラーニングの開発のレビューです。 
[概要]ディープラーニング技術の研究が進行中です。これには、音響特性をキャプチャするための要素の組み立てと処理、録音されたオーディオサンプルのコレクションの操作が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-10">
        <br><font color="black">2020-06-10</font>
      </time>
    </span>
</section>
<!-- paper0: Zero-Shot Audio Classification with Factored Linear and Nonlinear
  Acoustic-Semantic Projections -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.AS/paper_5.html">
      <font color="black">Zero-Shot Audio Classification with Factored Linear and Nonlinear
  Acoustic-Semantic Projections</font>
    </a>
  </h2>
  <font color="black">以前の双線形モデルと比較して、実験結果は、提案された投影法が音声分類におけるゼロショット学習の分類性能を改善するのに効果的であることを示している。本論文では、因数分解線形および非線形音響による音声分類におけるゼロショット学習を研究する。 -オーディオインスタンスとサウンドクラス間のセマンティックプロジェクション..オーディオ分類におけるゼロショット学習とは、利用可能なトレーニングデータがなく、セマンティックサイド情報のみを持つサウンドクラスのオーディオインスタンスの認識を目的とした分類問題を指します。 
[ABSTRACT]ゼロ-音声分類におけるショット学習は、音声クラスの音声インスタンスを見つけることを目的とした分類問題を指します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Vocal Tract Length Perturbation for Text-Dependent Speaker Verification
  with Autoregressive Prediction Coding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.AS/paper_6.html">
      <font color="black">Vocal Tract Length Perturbation for Text-Dependent Speaker Verification
  with Autoregressive Prediction Coding</font>
    </a>
  </h2>
  <font color="black">次に、提案されたVTLメソッドがAPCおよび話者判別BN機能に適用されます。実験は、ガウス混合モデル-ユニバーサルバックグラウンドモデルおよびi-ベクトル手法を使用した短い発話を使用して、TD-SVのRedDotsチャレンジ2016データベースで実行されます。提案された方法は、ベースラインを大幅に上回っています。 
[概要]提案されたシステムは、スコアドメインのmfccと2つのbn機能に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Interpreting Imagined Speech Waves with Machine Learning techniques -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.AS/paper_7.html">
      <font color="black">Interpreting Imagined Speech Waves with Machine Learning techniques</font>
    </a>
  </h2>
  <font color="black">実験結果に基づいて、単語の長さと複雑さを使用してIS信号を高精度でデコードでき、BCIシステムをコンピュータインタラクション用のIS信号で設計できることを提案します。平均分類精度は80％です。休息と想像状態、2つのデータセットで長い単語と短い単語をデコードするための96％と80％..実験結果に基づいて、アンサンブルと共分散行列変換された機能を備えたフィードフォワードNNモデルは、他の既存の方法と比較して最高のパフォーマンスを示しました。 
[概要]脳波信号を生成するプロセスは不明です。さまざまな特徴抽出方法を使用してデータ分布を定義し、信号を分類します。これらの結果は、商用レベルのbciシステムの開発の方向性を示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-07">
        <br><font color="black">2020-10-07</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Representations for Modeling Variation in English Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.AS/paper_8.html">
      <font color="black">Neural Representations for Modeling Variation in English Speech</font>
    </a>
  </h2>
  <font color="black">また、これらの神経音声表現は、分節の違いだけでなく、発音表記で使用される離散記号のセットでは表現できないイントネーションと持続時間の違いもキャプチャすることを示します。これらの表現を使用して、非単語間の単語ベースの発音の違いを計算します。英語のネイティブスピーカーとネイティブスピーカー、および人間のネイティブらしさの判断と比較することによってこれらの違いを評価します。音声の変化は、発音表記を使用して表され、調査されることがよくありますが、音声の転写には時間がかかり、エラーが発生しやすくなります。 
[ABSTRACT]トランスフォーマー-ネイティブの音声表現により、パフォーマンスが大幅に向上します。トランスフォーマーベースのトランスフォーマーモデルの使用は、最終レイヤーではなく1つ以上の中間レイヤーで最も効果的であることを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Small Footprint Convolutional Recurrent Networks for Streaming Wakeword
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.AS/paper_9.html">
      <font color="black">Small Footprint Convolutional Recurrent Networks for Streaming Wakeword
  Detection</font>
    </a>
  </h2>
  <font color="black">CRNNを使用してストリーミングオーディオで推論を実行するという難しい問題の解決策、およびCNN、DNN、およびDNN-HMMモデルと比較した開始-終了インデックスエラーと遅延の違いについて説明します。この作業では、小さなフットプリントを提案します。畳み込みリカレントニューラルネットワークモデルをウェイクワード検出の問題に適用し、スケーリングされたドット製品の注意でそれらを補強します。250kのパラメーターバジェットで畳み込みニューラルネットワークモデルと比較して、誤った受け入れを25％削減し、10％削減できることがわかりました。 CRNNを使用することでパラメーターサイズが向上し、ワードレベルの高密度ニューラルネットワークモデルと比較してパラメーターサイズが75％削減され、50kのパラメーターバジェットで最大32％の改善が得られます。 
[概要]誤った受け入れモデルを25％削減できることがわかりました。5万カレンダーで最大32％の改善が得られます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-task Language Modeling for Improving Speech Recognition of Rare
  Words -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.AS/paper_10.html">
      <font color="black">Multi-task Language Modeling for Improving Speech Recognition of Rare
  Words</font>
    </a>
  </h2>
  <font color="black">これらの追加タスクでトレーニングされた再スコアリングモデルは、言語モデリングタスクのみでトレーニングされたベースライン再スコアリングモデルよりも、一般テストで1.4％、単語エラーの観点から設定されたまれな単語テストで2.6％優れていることを示しています。相対レート（WERR）..エンドツーエンドの自動音声認識（ASR）システムは、その相対的なアーキテクチャの単純さと競争力のあるパフォーマンスのためにますます人気があります。ただし、これらのシステムの平均精度は高い場合がありますが、まれなコンテンツの単語は、ハイブリッドASRシステムに遅れをとることがよくあります。 
[概要]新しい研究では、音声認識のパフォーマンスを向上させるためにマルチタスク学習を備えたセカンドパスシステムを提案しています。音声認識を向上させるためにセマンティックターゲットを使用したセカンドパスシステムを提案しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Bootstrap an end-to-end ASR system by multilingual training, transfer
  learning, text-to-text mapping and synthetic audio -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-26/eess.AS/paper_11.html">
      <font color="black">Bootstrap an end-to-end ASR system by multilingual training, transfer
  learning, text-to-text mapping and synthetic audio</font>
    </a>
  </h2>
  <font color="black">実験によると、多言語RNN-Tワードピースモデル、ASR後のテキストからテキストへのマッピング、および合成オーディオの組み合わせにより、ターゲット言語データがほとんどないスケーラブルな方法で、新しい言語のASRシステムを効果的にブートストラップできます。オールニューラルモデルとエンドツーエンド（E2E）トレーニングへの最近の移行は、これらのモデルがデータを大量に消費することが知られているため、特定の課題をもたらしましたが、多言語データから派生した言語に依存しない表現や共有の機会もありましたスクリプトとルーツを共有する言語間での単語の断片的な出力表現ここでは、豊富なリソースを活用しながら、低リソース体制でRNN Transducer（RNN-T）ベースの自動音声認識（ASR）システムをブートストラップするさまざまな戦略の有効性を調査します他の言語で利用可能なリソース、およびtext-to-speech（TTS）エンジンからの合成オーディオ..限られたデータリソースでの音声認識のブートストラップは、活動の領域です。 e長い間研究します。 
[概要]新しい調査によると、低リソース体制でrnnトランスデューサー（rnn --t）ベースの自動音声認識（asr）システムをブートストラップするためのさまざまな戦略があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
