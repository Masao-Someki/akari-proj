<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-09-02の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Voice Separation with an Unknown Number of Multiple Speakers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.SD/paper_0.html">
      <font color="black">Voice Separation with an Unknown Number of Multiple Speakers</font>
    </a>
  </h2>
  <font color="black">複数の音声が同時に話す混合オーディオシーケンスを分離するための新しい方法を紹介します。この方法は、現在の技術水準を大幅に上回っています。は、可能性のある話者の数ごとにトレーニングされ、話者数が最大のモデルを使用して、所定のサンプルの実際の話者数が選択されます。 
[ABSTRACT]新しい方法は、話者を固定したまま、複数の処理ステップで音声を分離するようにトレーニングされたゲーテッドニューラルネットワークを採用しています。この方法は、3人以上の話者には競合しません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-29">
        <br><font color="black">2020-02-29</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Architecture Search For Keyword Spotting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.SD/paper_1.html">
      <font color="black">Neural Architecture Search For Keyword Spotting</font>
    </a>
  </h2>
  <font color="black">Googleの音声コマンドデータセットで提案された方法を評価し、文献で一般的に報告されている12クラスの発話分類の設定で97％を超える最先端の精度を達成しました。事前定義されたセルサーチスペースで演算子とその接続を検索します。ディープニューラルネットワークは最近、キーワードによるスポッティングシステムの人気のあるソリューションになり、音声によるスマートデバイスの制御を可能にします。 
[ABSTRACT]許容可能なメモリフットプリントを維持しながら、音響信号から抽出された特徴に基づいてキーワードスポッティングのパフォーマンスを向上させるのに役立つ畳み込みニューラルネットワークモデルを検索します。見つかったセルは、競争力のあるパフォーマンスを実現するために深さと幅の両方で拡大されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Analysis of memory in LSTM-RNNs for source separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.SD/paper_2.html">
      <font color="black">Analysis of memory in LSTM-RNNs for source separation</font>
    </a>
  </h2>
  <font color="black">長期の短期記憶再帰型ニューラルネットワーク（LSTM-RNN）は、多くの音声処理タスクで最先端と見なされています。スピーカーの特性のみが400ミリ秒以上メモリに保持されます。さらに、パフォーマンス賢いのは、より深い層に長いメモリを実装することで十分です。 
[要約]ネットワークでの繰り返しにより、原則として、入力を無期限に記憶できます。この機能は、音声などの時系列データに非常に役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: On Bottleneck Features for Text-Dependent Speaker Verification Using
  X-vectors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.SD/paper_3.html">
      <font color="black">On Bottleneck Features for Text-Dependent Speaker Verification Using
  X-vectors</font>
    </a>
  </h2>
  <font color="black">また、ガウス混合モデル-ユニバーサルバックグラウンドモデル（GMM-UBM）、i-vector、x-vectorなど、さまざまなモデリング手法のTD-SVパフォーマンスを比較します。TCLは、教師付き学習方式で、均一にトレーニングデータを構築します各発話を事前定義された数のセグメントに分割し、発話内の位置に応じて各セグメントにクラスラベルを割り当てます。実験はRedDots 2016チャレンジデータベースで行われます。 
[ABSTRACT] x -bms for text-dependentpeaker validation（td-sv）、unexplored.This model is based on the組み合わせof bn and i-たとえば</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-15">
        <br><font color="black">2020-05-15</font>
      </time>
    </span>
</section>
<!-- paper0: Learned Transferable Architectures Can Surpass Hand-Designed
  Architectures for Large Scale Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.SD/paper_4.html">
      <font color="black">Learned Transferable Architectures Can Surpass Hand-Designed
  Architectures for Large Scale Speech Recognition</font>
    </a>
  </h2>
  <font color="black">大規模な実験により、（i）小さなプロキシデータセットで検索されたアーキテクチャを音声認識タスク用の大きなデータセットに転送できることがわかります。（ii）改訂された検索スペースで学習したアーキテクチャにより、計算オーバーヘッドとGPUメモリを大幅に削減できます。穏やかなパフォーマンス低下を伴う使用法..このホワイトペーパーでは、自動音声認識（ASR）システムのニューラルアーキテクチャ検索（NAS）について説明します。 
[要約]音声認識タスクの修正された検索スペースを提案します。これらのアーキテクチャは、穏やかなパフォーマンスの低下でasrのメモリ使用量を大幅に削減できます。これは、大規模なデータセット（最大1万時間）でのnasの結果の最初のレポートです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Single-Shot 3D Widefield Fluorescence Imaging with a Computational
  Miniature Mesoscope -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.IV/paper_0.html">
      <font color="black">Single-Shot 3D Widefield Fluorescence Imaging with a Computational
  Miniature Mesoscope</font>
    </a>
  </h2>
  <font color="black">特に、CM $ ^ 2 $は、イメージング用のマイクロレンズアレイと励起用のLEDアレイを単一のプラットフォームに統合したコンパクトな軽量設計を備えています。蛍光イメージングは、生物学および神経科学に不可欠です。その拡張されたイメージング機能は、計算により可能になりますアルゴリズムによって光学系を増強するイメージング。 
[ABSTRACT]これは、動物の大規模なイメージングが必要なためです。これにより、2.5 mmの深度-of---field-of-viewおよび2.5-mmのdepth-of-fieldが発生しました。これにより、シングルショット3dが可能になります8 $ `mm &#39;-mmの視野と2. 5 mmの深さ-視野のイメージング、7-$` mu $ mの横方向の解像度、200以上の解像度を実現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-26">
        <br><font color="black">2020-03-26</font>
      </time>
    </span>
</section>
<!-- paper0: Recognition Oriented Iris Image Quality Assessment in the Feature Space -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.IV/paper_1.html">
      <font color="black">Recognition Oriented Iris Image Quality Assessment in the Feature Space</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーで提案されている品質メトリックは、認識アルゴリズムのパフォーマンスを大幅に向上させると同時に、認識のために破棄される画像の数を減らします。これは、手作りの要因に基づく虹彩の品質評価方法よりも優れています。提案された方法は、画質評価と生体認証のギャップを埋める試みです。画像拒否率（IRR）と等誤り率（EER）の関係は、同じ条件下で品質評価アルゴリズムのパフォーマンスを評価するために提案されています。画質分布と同じ認識アルゴリズム。 
[要約]メソッドは、特徴空間における虹彩画像の埋め込み距離を品質メトリックと見なします。予測は、注意メカニズムを備えたディープニューラルネットワークに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Image Super-Resolution using Explicit Perceptual Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.IV/paper_2.html">
      <font color="black">Image Super-Resolution using Explicit Perceptual Loss</font>
    </a>
  </h2>
  <font color="black">以前のアプローチでは、解釈が困難で暗黙的な関係を持ついくつかの損失関数を使用して、知覚スコアを改善しています。生成された画像に知覚スコアを提供するように直接トレーニングされている機械学習ベースのモデルを活用する方法を示します。結果は、明示的アプローチが他のアプローチよりも知覚スコアが高いことを示しています。 
[要約]明示的アプローチは他のアプローチよりも知覚スコアが高い。これらのモデルは、解釈が容易な超解像ネットワークを最適化するために使用できると考えられている</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Reinforcement Learning Designed Shinnar-Le Roux RF Pulse using
  Root-Flipping: DeepRF_SLR -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.IV/paper_3.html">
      <font color="black">Deep Reinforcement Learning Designed Shinnar-Le Roux RF Pulse using
  Root-Flipping: DeepRF_SLR</font>
    </a>
  </h2>
  <font color="black">実験では、DeepRF_SLRからのRFパルスにより、最小位相SLR RFパルスと同様のスライスプロファイルと、コンピューターシミュレーションのプロファイルに一致するプロファイルが生成されました。この方法では、RFパルスを決定するSLR多項式のルートパターン形状は、深層強化学習と貪欲ツリー検索の反復アプリケーションによって最適化されます。私たちのアプローチは、機械学習アルゴリズムを適用してRFを設計する新しい方法を提案し、機械設計のMRIシーケンスを示します。 
[ABSTRACT] deeprf-slrは、マルチバンドリフォーカスパルスのピーク重大度を最小限に抑えるように設計されています。この方法は、最小パルスと呼ばれ、shinar le-roux（slr）アルゴリズムによって開発されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-19">
        <br><font color="black">2019-12-19</font>
      </time>
    </span>
</section>
<!-- paper0: Deep unsupervised learning for Microscopy-Based Malaria detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.IV/paper_4.html">
      <font color="black">Deep unsupervised learning for Microscopy-Based Malaria detection</font>
    </a>
  </h2>
  <font color="black">細胞セグメンテーションとマラリア検出プロセスの両方で、多くの場合、手作業による強力なラベルが必要ですが、監視されていないワークフローで排除したいと考えています。人々は、治療しないと深刻な合併症を引き起こし、死に至る場合があります。寄生虫は、毎年世界中で100万人以上の人々を殺しています。 
[要旨]治療しないままにしておくと、深刻な合併症を起こして死に至る可能性があります。治療を受けていない人はマラリアに感染しています。血液細胞は、マハラノビス距離アルゴリズムによって色空間で識別されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: A Review of Single-Source Deep Unsupervised Visual Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.IV/paper_5.html">
      <font color="black">A Review of Single-Source Deep Unsupervised Visual Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">まず、さまざまなドメイン適応戦略の定義と既存のベンチマークデータセットの説明から始めます。最後に、今後の研究の方向性と課題と考えられる解決策について説明します。このホワイトペーパーでは、最新の単一ソースの深い教師なしドメイン適応手法に焦点を当てます視覚的なタスクについて学び、将来の研究のための新しい展望について話し合います。 
[ABSTRACT]これは最新の単一ソースの深い教師なしドメイン適応手法です。最新の単一ソースの深いモデル範囲の範囲を確認します。次に、単一ソースの教師なしドメインの研究のさまざまなカテゴリを要約して比較します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Ice Layer Tracking and Thickness Estimation using Fully
  Convolutional Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.IV/paper_6.html">
      <font color="black">Deep Ice Layer Tracking and Thickness Estimation using Fully
  Convolutional Networks</font>
    </a>
  </h2>
  <font color="black">この手順により、約3.6ピクセルの平均絶対誤差内で氷層の厚さを推定できました。推定された厚さを分析して、毎年の積雪量を把握できます。各氷層を一意に検出した後、その厚さを計算して比較します利用可能なグラウンドトゥルースを使用してください。 
[ABSTRACT]推定された厚さを分析して、毎年積雪量を理解できます。各氷層を理解するために、その厚さを計算し、利用可能なグラウンドトゥルースと比較します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: On The Usage Of Average Hausdorff Distance For Segmentation Performance
  Assessment: Hidden Bias When Used For Ranking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.IV/paper_7.html">
      <font color="black">On The Usage Of Average Hausdorff Distance For Segmentation Performance
  Assessment: Hidden Bias When Used For Ranking</font>
    </a>
  </h2>
  <font color="black">シミュレートされたセグメンテーションの各セットは、AVDおよびbAVDを使用してランク付けされました。作成されたエラーを連続的かつランダムにグラウンドトゥルースに追加して、エラー数が増加するシミュレートされたセグメンテーションのセットを作成しました。医療画像セグメンテーションでは、AVDを使用してグラウンドトゥルースを比較しました。ランク付けを可能にするセグメンテーション結果を含む画像。 
[ABSTRACT]医療画像のセグメンテーションでは、avdを使用してグラウンドトゥルース画像と結果をランク付けできる結果を比較します。このバイアスを軽減するために、セグメンテーションとしてバランスのとれたavdを作成したavdの修正計算を作成しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Displacement-agnostic coherent imaging through scatter with an
  interpretable deep neural network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.IV/paper_8.html">
      <font color="black">Displacement-agnostic coherent imaging through scatter with an
  interpretable deep neural network</font>
    </a>
  </h2>
  <font color="black">さらに、DNNモデルのメカニズムを解釈し、教師なしの次元削減手法に基づいてその一般化可能性を視覚化するための新しい分析フレームワークを開発します。私たちの作業は、散乱メディアを介したイメージングへの非常に堅牢で解釈可能な深層学習アプローチへの道を開きます。ここでは、散乱体の変化、変位、最大10倍の被写界深度を含むシステムの焦点ぼけを含む、より広いクラスの摂動にとらわれない新しいディープニューラルネットワーク（DNN）モデルを提案します。 
[ABSTRACT]ディープニューラルネットワーク（dnn）は、散乱-固有情報を分離し、オブジェクト固有情報を抽出して一般化を実現できる新しいモデルです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-15">
        <br><font color="black">2020-05-15</font>
      </time>
    </span>
</section>
<!-- paper0: Topological Sweep for Multi-Target Detection of Geostationary Space
  Objects -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.IV/paper_9.html">
      <font color="black">Topological Sweep for Multi-Target Detection of Geostationary Space
  Objects</font>
    </a>
  </h2>
  <font color="black">幾何学的双対性を使用すると、計算効率が高く、オンライン処理に適したアルゴリズムも生成されます。標準のマルチターゲットメソッドとは異なり、このアルゴリズムは組み合わせ問題を決定的に解決し、正確な初期化を必要とせずに高い再現率を保証します。トポロジースイープテクニック入力シーケンス全体でターゲットオブジェクトのほぼ線形の軌跡を支える幾何学的双対性を利用して、大きなクラッタとノイズからターゲットを抽出します。 
[ABSTRACT]私たちの仕事は、人工物体の光学的検出に焦点を当てています。これらには、衛星、スペースデブリ、テレコミュニケーション、およびナビゲーション衛星が含まれます。これは、サットンスイープに基づく新しいマルチターゲット検出技術によるものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-21">
        <br><font color="black">2020-03-21</font>
      </time>
    </span>
</section>
<!-- paper0: Key Points Estimation and Point Instance Segmentation Approach for Lane
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.IV/paper_10.html">
      <font color="black">Key Points Estimation and Point Instance Segmentation Approach for Lane
  Detection</font>
    </a>
  </h2>
  <font color="black">予測されたキーポイントのクラスタリング問題をインスタンスセグメンテーション問題としてキャストします。 PINetは、動線の数に関係なくトレーニングできます。したがって、トレーニングされたモデルのサイズは、ターゲット環境の計算能力に応じて選択できます。PINetには、同時にトレーニングされる複数のスタックされた砂時計ネットワークが含まれます。 
[要約]ピネットには、同時に訓練されるいくつかの砂時計ネットワークが含まれています。動線の数に関係なく訓練できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-16">
        <br><font color="black">2020-02-16</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Hyperspectral-Depth Imaging with Learned Diffractive Optics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.IV/paper_11.html">
      <font color="black">End-to-End Hyperspectral-Depth Imaging with Learned Diffractive Optics</font>
    </a>
  </h2>
  <font color="black">1つはディープオプティカルHS-Dイメージングのエンドツーエンドの最適化に使用され、もう1つはリアルDOEプロトタイプを使用して再構成パフォーマンスを向上させるために使用されます。最適化されたDOEはグレースケールリソグラフィプロセスで製造され、ポータブルに挿入されますHS-Dカメラプロトタイプ。HS-D情報を確実にキャプチャすることが示されています。この高次元視覚データの自然画像統計を研究し、そのような機械学習ベースのDOEトレーニング手順を有効にするために、2つのHS-Dデータセットを記録します。 。 
[要約]不完全に結合されたイメージングシステムはhs-d画像をキャプチャする機能をキャプチャしますが、結合されたイメージのフォームファクタが増加し、この新しいテクノロジーの適用性が制限されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Quality-aware semi-supervised learning for CMR segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.IV/paper_12.html">
      <font color="black">Quality-aware semi-supervised learning for CMR segmentation</font>
    </a>
  </h2>
  <font color="black">これまでの研究でこれらの臨床評価を使用して、自動心臓磁気共鳴（CMR）分析用の堅牢な品質管理（QC）分類子を作成しました。SemiQCSegは、ラベル付きデータセットが不足している場合に、医療画像データのセグメンテーションネットワークをトレーニングするための効率的なアプローチです。 。臨床医は、画像解析結果を評価する際に、生物物理学および生理学に関する豊富な事前知識を考慮に入れます。 
[ABSTRACT]データ拡張と半教師あり学習（ssl）メソッドが開発されました。これにより、セグメンテーションネットワーク（semiqcseg）のsslのバリアントで品質を意識したトレーニングデータの拡張が提供されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal Image-to-Image Translation via Mutual Information Estimation
  and Maximization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.IV/paper_13.html">
      <font color="black">Multimodal Image-to-Image Translation via Mutual Information Estimation
  and Maximization</font>
    </a>
  </h2>
  <font color="black">最先端の方法と比較して、さまざまなベンチマークの画像から画像への変換データセットに対して、監視ありおよび監視なしの設定で実験を行い、マルチモーダルで高品質の結果を達成するための方法の有効性とシンプルさを示しています。また、この方法では、ソースドメインのコンテンツとターゲットドメインのスタイルを自由に解くことができます。このホワイトペーパーでは、潜在コードとの統計的依存関係を促進するだけで、マルチモーダルな画像から画像への変換を実現できる新しいフレームワークを紹介します。条件付き生成敵対ネットワークの出力画像。 
[要旨]さまざまなベンチマーク画像からスポットへの方法で、監視ありおよび監視なしの設定で実験を行います。この方法では、両方のソース画像ドメインからターゲット画像ドメインへの片側変換モデルを学習するだけで済みます。教師ありまたは教師なしマルチモーダル画像-から-画像への変換</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-08">
        <br><font color="black">2020-08-08</font>
      </time>
    </span>
</section>
<!-- paper0: Thick Cloud Removal of Remote Sensing Images Using Temporal Smoothness
  and Sparsity-Regularized Tensor Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.IV/paper_14.html">
      <font color="black">Thick Cloud Removal of Remote Sensing Images Using Temporal Smoothness
  and Sparsity-Regularized Tensor Optimization</font>
    </a>
  </h2>
  <font color="black">この論文では、時間的平滑性とスパース性正則化テンソル最適化（TSSTO）に基づくリモートセンシング画像の新しい厚い雲の除去方法を提案します。雲と雲の影の要素を精製して、雲の領域と雲の影の領域を取得します。したがって、スパース性ノルムは、雲と雲の影のスパース性を高めるために使用され、単方向のトータルバリエーション（UTV）レギュラライザーが適用されて、一方向の滑らかさを保証します。 
[ABSTRACT]一連の実験は、シミュレートされたクラウドと実際のクラウドの両方で行われます-さまざまなセンサーからのさまざまな解像度の汚染された画像</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-11">
        <br><font color="black">2020-08-11</font>
      </time>
    </span>
</section>
<!-- paper0: Machine learning for COVID-19 detection and prognostication using chest
  radiographs and CT scans: a systematic methodological review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.IV/paper_15.html">
      <font color="black">Machine learning for COVID-19 detection and prognostication using chest
  radiographs and CT scans: a systematic methodological review</font>
    </a>
  </h2>
  <font color="black">確立されたベンチマークに対して各論文の方法論品質レビューを実施し、レビューが高品質の再現可能な論文のみに焦点を当てていることを確認しました。 2020年1月1日から2020年6月24日までにアップロードされたプレプリント。これは、緊急に必要とされる安全な臨床実施の鍵です。 
[要約]この体系的なレビューでは、急速に成長している文献で採用されている機械学習手法を批判的に評価しています。これは、検証済みのcovid-19モデルが必要な緊急性を考えると、大きな弱点です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-14">
        <br><font color="black">2020-08-14</font>
      </time>
    </span>
</section>
<!-- paper0: Lossless CNN Channel Pruning via Gradient Resetting and Convolutional
  Re-parameterization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.IV/paper_16.html">
      <font color="black">Lossless CNN Channel Pruning via Gradient Resetting and Convolutional
  Re-parameterization</font>
    </a>
  </h2>
  <font color="black">記憶と忘却の独立性に関する神経生物学の研究から発想を得て、CNNをパラメータ化して記憶の部分と忘却の部分に再編成することを提案します。前者はパフォーマンスを維持することを学び、後者は効率を学習します。前者は通常のSGDを使用するパラメータ化モデルですが、後者はペナルティグラディエントを使用する新しい更新ルールにより、構造化されたスパース性を実現し、再パラメータ化されたモデルをより狭いレイヤーの元のアーキテクチャに同等に変換できるようにします。この方法では、 ImageNetで76.15 \％のトップ1の精度を持つ標準のResNet-50を、わずか43.9 \％のFLOPで精度が低下しないより狭いものにスリム化します。 
[ABSTRACT] `filter pruning &#39;は、畳み込みニューラルネットワーク（cnn）をスリム化することを目的としています。それは、畳み込み層の幅（つまり、出力チャネルの数）を減らすことを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Image reconstruction through a multimode fiber with a simple neural
  network architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.IV/paper_17.html">
      <font color="black">Image reconstruction through a multimode fiber with a simple neural
  network architecture</font>
    </a>
  </h2>
  <font color="black">かなり単純なニューラルネットワークアーキテクチャである単一の隠れ層の高密度ニューラルネットワークは、少なくとも以前に使用されたCNNと同様に、画像再構成の忠実度の点で機能し、トレーニング時間と必要なコンピューティングリソースの点で優れていることがわかります。トレーニングされたネットワークは、トレーニングセットの停止後1週間にわたって収集されたMMF画像を正確に再構築できます。高密度ネットワークは、期間全体にわたってCNNを実行します。マルチモードファイバー（MMF）は、内視鏡検査や関連するアプリケーションですが、MMFのモード混合とモーダル分散によって生成される複雑なスペックルパターンをデコードすることは深刻な課題です。 
[要約]たたみ込みニューラルネットワーク（cnns）は、高忠実度のmmf画像再構成を実行するようにトレーニングできます。ネットワークは、トレーニングの開始後1週間にわたってmmf画像を実行できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-10">
        <br><font color="black">2020-06-10</font>
      </time>
    </span>
</section>
<!-- paper0: PiNet: Deep Structure Learning using Feature Extraction in Trained
  Projection Space -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.IV/paper_18.html">
      <font color="black">PiNet: Deep Structure Learning using Feature Extraction in Trained
  Projection Space</font>
    </a>
  </h2>
  <font color="black">また、公開チャレンジデータセットでPiNetフレームワークをテストして、私たちのアプローチがほんのわずかな量のパラメーターとストレージを使用するだけで同等の結果を達成できることを示しています。これらの問題を克服するために、自動調整およびデータ依存バージョンの低次元空間での畳み込みによる特徴抽出を可能にするラドン変換（投影データ）。結果として生じるPiNetというフレームワークは、エンドツーエンドでトレーニングでき、ボリュームセグメンテーションタスクで有望なパフォーマンスを示します。 
[要約]一連の畳み込みの結果は、どれだけのデータストレージを実行できるかを示します。これらには、エンドによってトレーニングできるpinetという名前のフレームワークが含まれており、有望な結果が示されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: LabelEnc: A New Intermediate Supervision Method for Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_0.html">
      <font color="black">LabelEnc: A New Intermediate Supervision Method for Object Detection</font>
    </a>
  </h2>
  <font color="black">コードはhttps://github.com/megvii-model/LabelEncで入手できます。さらに、補助構造はトレーニング中にのみ存在します。実験により、1段階または2段階のフレームワークに関係なく、この方法によりCOCOデータセットでさまざまな検出システムが約2％向上することが示されています。 
[ABSTRACT]新しい方法は、ラベルスペースでオートエンコーダを使用します。検出バックボーンに対する補助的な中間監視として機能します。この方法は、さまざまな検出システムを約2％改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Recognition Oriented Iris Image Quality Assessment in the Feature Space -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_1.html">
      <font color="black">Recognition Oriented Iris Image Quality Assessment in the Feature Space</font>
    </a>
  </h2>
  <font color="black">手作りの要因ベースの方法と比較して、提案された方法は、画質評価とバイオメトリック認識の間のギャップを埋める試みです。このホワイトペーパーで提案されている品質メトリックは、認識アルゴリズムのパフォーマンスを大幅に改善しながら、認識のために破棄された画像は、手作りの要素に基づく虹彩品質評価方法よりも優れています。この方法では、虹彩画像の埋め込み距離（DFS）を品質測定基準と見なし、予測は、注意深いディープニューラルネットワークに基づいています。機構。 
[要約]メソッドは、特徴空間における虹彩画像の埋め込み距離を品質メトリックと見なします。予測は、注意メカニズムを備えたディープニューラルネットワークに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Gaussian Process Gradient Maps for Loop-Closure Detection in
  Unstructured Planetary Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_2.html">
      <font color="black">Gaussian Process Gradient Maps for Loop-Closure Detection in
  Unstructured Planetary Environments</font>
    </a>
  </h2>
  <font color="black">次に、従来の画像レジストレーション手法を使用して、一致する可能性のあるものを検索します。環境の3D点群が与えられると、提案されたアプローチは、線形演算子を使用したガウスプロセス（GP）回帰を利用して、地形標高情報の連続勾配マップを生成します。重要なアイデア地形標高マップの新しい連続的で確率的な表現を使用することです。 
[要約]この論文では、空間情報のみを使用してループクロージャ問題を解決する方法を示しました。提案されたアプローチは、線形演算子を使ってガウス過程（gp）novaを活用し、地形の連続的な勾配マップを生成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: A Deep 2-Dimensional Dynamical Spiking Neuronal Network for Temporal
  Encoding trained with STDP -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_3.html">
      <font color="black">A Deep 2-Dimensional Dynamical Spiking Neuronal Network for Temporal
  Encoding trained with STDP</font>
    </a>
  </h2>
  <font color="black">ここでは、STDPなどの生物学にヒントを得た学習ルールを備えた哺乳類の皮質を模倣する、動的で無秩序な活動を伴う大規模な深層SNNが、時間データからの情報をエンコードできることを示します。入力刺激の正確なタイミングを示すことを目的としています。レイヤードネットワークで同期ニューラルグループを形成する上で重要です。2つの問題に同時に取り組みたいと考えています。人工知能のための人工側頭神経システムの作成と、脳のコーディングメカニズムの解決です。 
[ABSTRACT]ネットワークの重みにより、ニューロンはデータをエンコードするグループを形成できます。彼らは、組織が整理できるようにするグループを作成することを目的としています。このネットワークは、学習情報を中心に構成されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: 3D-DEEP: 3-Dimensional Deep-learning based on elevation patterns forroad
  scene interpretation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_4.html">
      <font color="black">3D-DEEP: 3-Dimensional Deep-learning based on elevation patterns forroad
  scene interpretation</font>
    </a>
  </h2>
  <font color="black">検証画像を使用して19のCityscapesトレーニングクラスについて、ユニオン上の平均交差点（mIoU）が72.32％取得されました。一方、KITTIdatasetを介して、モデルはF1エラー値97.85％無効化およびテスト画像を使用して96.02％を達成しました..この方法は、完全にたたみ込みネットワークアーキテクチャによる3次元情報と画像の特徴抽出のために、視差フィルタリングされたLiDAR投影画像に依存しています。 
[ABSTRACT]開発されたモデルは、細かいアノテーションの例を使用して、都市景観データセットとキティ道路データセットに投影および検証されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: MORPH-DSLAM: Model Order Reduction for PHysics-based Deformable SLAM -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_5.html">
      <font color="black">MORPH-DSLAM: Model Order Reduction for PHysics-based Deformable SLAM</font>
    </a>
  </h2>
  <font color="black">モデル次数削減法を使用すると、高次元空間での解の可視化を維持しながら、問題の次元を削減し、したがってその計算コストを削減できます。通常は非現実的な構成則を使用して、この問題をリアルタイムで解決します-linearは、現在のシステムでは到達できません。これは、閉塞面であっても、外部表面と材料特性と形状の知識を観察するだけで、オブジェクトの内部状態を推定できることを意味します。 
[ABSTRACT]リアルタイムで、完全な（場合によっては粘性-）超弾性問題を解決します。実際の物理学によって制約された、画像によってキャプチャされた変位と一致するひずみおよび応力フィールドを課します。これは、内部の推定も可能であることを意味します外表面を観察するだけで、オブジェクトの状態、たとえ閉塞された領域でも</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: To augment or not to augment? Data augmentation in user identification
  based on motion sensors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_6.html">
      <font color="black">To augment or not to augment? Data augmentation in user identification
  based on motion sensors</font>
    </a>
  </h2>
  <font color="black">2つのディープラーニングアーキテクチャである畳み込みニューラルネットワークとLong Short-Term Memoryネットワークを使用して、ベンチマークデータセットで実験を行い、どのデータ補強方法がいつ精度を向上させるかを示します。ユーザーから収集されるデータサンプルの数は通常は少ないです。 ..起こり得る攻撃の一部を防ぐために、これらの明示的な認証システムは、2要素認証方式を検討することで強化できます。2要素認証方式は、加速度計またはジャイロスコープによってキャプチャされたモーションセンサーデータの分析に基づく暗黙の認証システムです。 
[要旨]パスワードチェック、顔認識、指紋スキャンは、さまざまなタイプの攻撃の影響を受けます。ユーザーへの追加の負担を回避するために、大陸間認証システムの登録プロセスは迅速に実行する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: A High-Level Description and Performance Evaluation of Pupil Invisible -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_7.html">
      <font color="black">A High-Level Description and Performance Evaluation of Pupil Invisible</font>
    </a>
  </h2>
  <font color="black">最近、Pupil Labsは、これらの制限に対処するために設計されたヘッドマウントアイトラッカー、Pupil Invisible Glassesをリリースしました。ヘッドマウントアイトラッカーは、制約のない環境で信頼性の高い視線データへの便利なアクセスを約束します。これらの中には、次のものがあります。（i）必要性アイトラッカーを使用する前にデバイスのセットアップとキャリブレーションを実行すること（ii）屋外の照明条件や被験者の頭でのアイトラッカーの不可避なずれなどの摂動に対する視線推定結果の堅牢性の欠如、 （iii）現在のヘッドマウントアイトラッカーの不自然な外観による、社会的なぎこちなさから生じる行動の歪み。 
[ABSTRACT]これらの制限に対処するように設計されたヘッドマウント式アイトラッカー。アイトラッカー、アイトラッカー、アイトラッカーが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Image Super-Resolution using Explicit Perceptual Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_8.html">
      <font color="black">Image Super-Resolution using Explicit Perceptual Loss</font>
    </a>
  </h2>
  <font color="black">実験結果は、明示的アプローチが他のアプローチよりも知覚スコアが高いことを示しています。最後に、主観的評価を使用して、明示的知覚的損失と視覚的に心地よい画像の関係を示します。既存の損失の特性と提案された明示的知覚をさらに分析しますより良い解釈のための損失。 
[要約]明示的アプローチは他のアプローチよりも知覚スコアが高い。これらのモデルは、解釈が容易な超解像ネットワークを最適化するために使用できると考えられている</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: LodoNet: A Deep Neural Network with 2D Keypoint Matchingfor 3D LiDAR
  Odometry Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_9.html">
      <font color="black">LodoNet: A Deep Neural Network with 2D Keypoint Matchingfor 3D LiDAR
  Odometry Estimation</font>
    </a>
  </h2>
  <font color="black">畳み込みニューラルネットワークパイプラインは、抽出されたMKPによるLiDARオドメトリ推定用に設計されています。次に、提案されたスキーム、つまりLodoNetがKITTIオドメトリ推定ベンチマークで評価され、最新の技術と同等またはそれ以上の結果を達成します。 ..対照的に、画像ベースの特徴抽出器の成功を動機として、LiDARフレームを画像空間に転送し、問題を画像特徴抽出として再定式化することを提案します。 
[ABSTRACT]提案されたスキームlodonetは、次にキットオドメトリ推定ベンチマークで評価され、最新の技術と同等またはそれ以上の結果を達成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: LiftFormer: 3D Human Pose Estimation using attention models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_10.html">
      <font color="black">LiftFormer: 3D Human Pose Estimation using attention models</font>
    </a>
  </h2>
  <font color="black">モデルのパラメーターの数は簡単に調整でき、現在の方法論（16.95Mおよび11.25M）よりも少なく（9.5M）、パフォーマンスは向上しています。したがって、3Dリフティングモデルの精度は他のエンドツーエンドの精度を超えています。またはSMPLアプローチであり、多くのマルチビュー手法に匹敵します。最新の研究動向では、Transformer Encoderブロックは、以前のアプローチよりもはるかに優れた時間情報の集計を行うことが証明されています。 
[ABSTRACT]ニューヨークベースのmpは3dモデルのコンセプトを開発しました。これは、ルート-人間の骨格に関連付けられた関節の相対座標を予測するために使用できると主張しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Object Detection-Based Variable Quantization Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_11.html">
      <font color="black">Object Detection-Based Variable Quantization Processing</font>
    </a>
  </h2>
  <font color="black">この方法は人間の知覚に基づいているため、同様のMS-SSIMを使用しても、全体的な視聴体験は直接エンコードされたものよりも優れています。この方法からもメリットがあります。 
[ABSTRACT]この方法はjpeg圧縮理論に基づいています。従来のエンコーダーなどのエンコーダーに最適です。この方法でもこの方法のメリットを享受できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Inducing Predictive Uncertainty Estimation for Face Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_12.html">
      <font color="black">Inducing Predictive Uncertainty Estimation for Face Recognition</font>
    </a>
  </h2>
  <font color="black">PCNetの有用性をエラー対拒否のパフォーマンスで体系的に評価し、検証モデルと普遍的に組み合わせて堅牢性を向上できることを実証します。パブリックIJB-Cフェイス検証ベンチマークの3つのユースケースについて説明します：（i ）低品質の顔画像を拒否することにより、1：1の画像ベースの検証エラー率を改善します。 （ii）1：1のセットベースの検証ベンチマークで、品質スコアに基づく融合パフォーマンスを改善する。 （iii）コレクションから高品質（ぼやけのない、良い照明、より正面の）顔を選択するための品質尺度としての使用。自動登録または表示用。 
[ABSTRACT]画質トレーニングデータを自動的に生成する方法を提案します。生成されたデータを使用して、顔画像の信頼スコアを推定するための軽量予測信頼ネットワークをトレーニングします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: A Review of Single-Source Deep Unsupervised Visual Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_13.html">
      <font color="black">A Review of Single-Source Deep Unsupervised Visual Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">最後に、今後の研究の方向性と課題と考えられる解決策について説明します。まず、さまざまなドメイン適応戦略の定義と既存のベンチマークデータセットの説明から始めます。残念ながら、ドメインシフトの存在やデータセットのバイアス。 
[ABSTRACT]これは最新の単一ソースの深い教師なしドメイン適応手法です。最新の単一ソースの深いモデル範囲の範囲を確認します。次に、単一ソースの教師なしドメインの研究のさまざまなカテゴリを要約して比較します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Ice Layer Tracking and Thickness Estimation using Fully
  Convolutional Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_14.html">
      <font color="black">Deep Ice Layer Tracking and Thickness Estimation using Fully
  Convolutional Networks</font>
    </a>
  </h2>
  <font color="black">各氷層を一意に検出した後、その厚さを計算し、利用可能なグラウンドトゥルースと比較します。この手順により、約3.6ピクセルの平均絶対誤差内で氷層の厚さを推定できました。推定された厚さを分析できます。毎年積雪を理解するために。 
[ABSTRACT]推定された厚さを分析して、毎年積雪量を理解できます。各氷層を理解するために、その厚さを計算し、利用可能なグラウンドトゥルースと比較します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: On The Usage Of Average Hausdorff Distance For Segmentation Performance
  Assessment: Hidden Bias When Used For Ranking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_15.html">
      <font color="black">On The Usage Of Average Hausdorff Distance For Segmentation Performance
  Assessment: Hidden Bias When Used For Ranking</font>
    </a>
  </h2>
  <font color="black">私たちが提案する評価指標であるbAVDは、AVDのランキングバイアスを軽減し、セグメンテーションのランキングと品質評価により適したものにします。シミュレーションされたセグメンテーションの各セットは、AVDとbAVDを使用してランク付けされました。作成されたエラーを連続的かつランダムにグラウンドトゥルースに追加します。エラーの数が増えるシミュレーションセグメンテーションのセットを作成しました。 
[ABSTRACT]医療画像のセグメンテーションでは、avdを使用してグラウンドトゥルース画像と結果をランク付けできる結果を比較します。このバイアスを軽減するために、セグメンテーションとしてバランスのとれたavdを作成したavdの修正計算を作成しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: A Unified Weight Learning and Low-Rank Regression Model for Robust Face
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_16.html">
      <font color="black">A Unified Weight Learning and Low-Rank Regression Model for Robust Face
  Recognition</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、統合されたスパースウェイト学習と低ランク近似回帰モデルによってこの問題に対処し、ランダムピクセルの破損やブロックオクルージョンなど、さまざまな種類とレベルの破損が存在する場合にロバストな顔認識に適用しました。変装..ランダムノイズの場合、エラー分布に一致する一般化されたコレントロピー（GC）関数を提案しました。効果的な反復最適化を開発して、最適な重み学習と低ランクの近似を解決します。 
[ABSTRACT]モデルの最も重要な問題は、さまざまな破損や環境の変化によって引き起こされる複雑な表現エラーのフィッティングです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-10">
        <br><font color="black">2020-05-10</font>
      </time>
    </span>
</section>
<!-- paper0: Semantics-aware Adaptive Knowledge Distillation for Sensor-to-Vision
  Action Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_17.html">
      <font color="black">Semantics-aware Adaptive Knowledge Distillation for Sensor-to-Vision
  Action Recognition</font>
    </a>
  </h2>
  <font color="black">SAKDNは、教師モダリティとして複数のウェアラブルセンサーを使用し、生徒モダリティとしてRGBビデオを使用します。具体的には、グラミアン角度フィールドベースの仮想画像生成モデルを設計することにより、ウェアラブルセンサーの1次元時系列信号を2次元画像に変換します。 。Berkeley-MHAD、UTD-MHADおよびMMActデータセットの実験結果は、提案されたSAKDNの有効性をよく示しています。 
[ABSTRACT] sakdnという名前のsakdnは、複数のウェアラブル-センサーを教師のウェアラブルとして使用し、rgbビデオを学生のモダリティとして使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Active Deep Densely Connected Convolutional Network for Hyperspectral
  Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_18.html">
      <font color="black">Active Deep Densely Connected Convolutional Network for Hyperspectral
  Image Classification</font>
    </a>
  </h2>
  <font color="black">次に、追加のネットワークを使用して、深い密に接続された畳み込みネットワークが誤ったラベルを生成する可能性が高いというラベルのないサンプルを提案できます。したがって、提案された方法は、エンドツーエンドのフレームワークです。深い密に接続された畳み込みネットワークしたがって、新しいトレーニングセットを使用してトレーニングされます。 
[要約]ディープラーニングはハイパースペクトル画像分類コストに関連付けられています。ただし、ディープラーニングの成功は、多数のラベル付きサンプルに起因しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Radish Wilt Detection Using Image Processing Based Techniques
  and Machine Learning Algorithm -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_19.html">
      <font color="black">Automatic Radish Wilt Detection Using Image Processing Based Techniques
  and Machine Learning Algorithm</font>
    </a>
  </h2>
  <font color="black">しかし、私たちの方法論は、画像処理と機械学習を組み合わせたハイブリッドアルゴリズムに基づいています。このホワイトペーパーでは、大根作物のフザリウム青枯病を検出するためのセグメンテーションと抽出ベースの手法を提案します。提案されたアルゴリズムの組み合わせは、青枯れを検出しますこれは、画像処理技術や機械学習を個別に使用する従来の慣例を超えています。 
[要約]しおれ検出アルゴリズムの提案された組み合わせは、元のしおれを検出します。これらは、画像処理技術または機械学習アルゴリズムに基づいています。これらには、作物の植栽、健康な植物、地面、梱包材が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Prototype Mixture Models for Few-shot Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_20.html">
      <font color="black">Prototype Mixture Models for Few-shot Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">PMMは、表現としても分類子としても使用され、セマンティクスを完全に活用して、クエリ画像内のオブジェクトをアクティブ化しながら、二重に背景領域を押し下げます。 the-arts ..期待値最大化アルゴリズムによって推定されたPMMは、限られたサポート画像からのチャネル指向の空間セマンティクスを豊富に組み込んでいます。 
[ABSTRACT] 1つのプロトタイプを使用して、pmmsは限られたサポート画像からの豊富なチャネル-賢明な、空間的な意味を組み込み</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Visualizing Point Cloud Classifiers by Curvature Smoothing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_21.html">
      <font color="black">Visualizing Point Cloud Classifiers by Curvature Smoothing</font>
    </a>
  </h2>
  <font color="black">平滑化アルゴリズムに基づいて、形状の最も重要な特徴をカバーする最小顕著性マップを自動的に見つけることができる視覚化手法であるPCI-GOS（点群統合勾配最適化顕著性）を提案します。顕著な特徴を平滑化した後、結果として得られる点群をネットワークで評価して、分類器にとって機能が重要かどうかを評価できます。このアプローチは、点群の曲線領域の平滑化に基づいています。 
[要旨]私たちのアプローチは、点群の曲線領域を平滑化することに基づいています。これは、ネットワークの診断とより良いアーキテクチャの設計に役立つ可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-23">
        <br><font color="black">2019-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-channel Transformers for Multi-articulatory Sign Language
  Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_22.html">
      <font color="black">Multi-channel Transformers for Multi-articulatory Sign Language
  Translation</font>
    </a>
  </h2>
  <font color="black">RWTH-PHOENIX-Weather-2014Tデータセットでのアプローチを評価し、競争力のある翻訳パフォーマンスを報告します。重要なのは、他の最先端のアプローチを支える光沢アノテーションへの依存を克服し、それによって将来の高価なキュレーションデータセットの必要性を取り除くことです。 ..提案されたアーキテクチャでは、チャネル固有の情報を維持しながら、異なるサインアーティキュレータ間のコンテキスト内とコンテキスト内の両方の関係をトランスフォーマネットワーク自体内でモデル化できます。 
[要約]この論文では、マルチ調音手話タスクに取り組み、新しいマルチチャネルトランスフォーマアーキテクチャを提案します。新しいアーキテクチャはannronによって提案されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Topological Sweep for Multi-Target Detection of Geostationary Space
  Objects -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_23.html">
      <font color="black">Topological Sweep for Multi-Target Detection of Geostationary Space
  Objects</font>
    </a>
  </h2>
  <font color="black">標準のマルチターゲットメソッドとは異なり、アルゴリズムは組み合わせ問題を決定的に解決し、正確な初期化を必要とせずに高い再現率を保証します。トポロジースイープテクニックは、入力シーケンス全体でターゲットオブジェクトのほぼ線形の軌跡を支える幾何学的双対性を利用して抽出します。大きなクラッタとノイズのターゲット。幾何学的双対性を使用すると、計算効率が高く、オンライン処理に適したアルゴリズムも生成されます。 
[ABSTRACT]私たちの仕事は、人工物体の光学的検出に焦点を当てています。これらには、衛星、スペースデブリ、テレコミュニケーション、ナビゲーション衛星が含まれます。これは、サットンスイープに基づく新しいマルチターゲット検出技術が原因です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-21">
        <br><font color="black">2020-03-21</font>
      </time>
    </span>
</section>
<!-- paper0: Utilizing Satellite Imagery Datasets and Machine Learning Data Models to
  Evaluate Infrastructure Change in Undeveloped Regions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_24.html">
      <font color="black">Utilizing Satellite Imagery Datasets and Machine Learning Data Models to
  Evaluate Infrastructure Change in Undeveloped Regions</font>
    </a>
  </h2>
  <font color="black">利用可能な衛星データの写真測量技術を利用して3Dメッシュとデジタルサーフェスモデル（DSM）を作成することで、輸送ルートを効果的に予測したいと考えています。この研究の目標は、鉄道などの大規模インフラプロジェクトの自動監視を可能にし、信頼できる建設イニシアチブがとる方向を定義および予測するメトリックにより、狭くてターゲットを絞った衛星画像リクエストを介した直接監視が可能になります。ただし、多数の商用、民間、および政府の衛星からの画像は、全世界をカバーする巨大なデータセットを生成し、コンパイルしています。機械学習アルゴリズムとニューラルネットワークを使用してマイニングおよび処理できる地理空間リソース。 
[ABSTRACT]商用、民間、政府の衛星からの画像は、全世界をカバーする膨大なデータセットを生成しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Key Points Estimation and Point Instance Segmentation Approach for Lane
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_25.html">
      <font color="black">Key Points Estimation and Point Instance Segmentation Approach for Lane
  Detection</font>
    </a>
  </h2>
  <font color="black">予測されたキーポイントのクラスタリング問題をインスタンスセグメンテーション問題としてキャストします。 PINetは、動線の数に関係なくトレーニングできます。PINetには、同時にトレーニングされる複数の積み重ねられた砂時計ネットワークが含まれます。 
[要約]ピネットには、同時に訓練されるいくつかの砂時計ネットワークが含まれています。動線の数に関係なく訓練できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-16">
        <br><font color="black">2020-02-16</font>
      </time>
    </span>
</section>
<!-- paper0: Uncovering Hidden Challenges in Query-Based Video Moment Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_26.html">
      <font color="black">Uncovering Hidden Challenges in Query-Based Video Moment Retrieval</font>
    </a>
  </h2>
  <font color="black">最後に、将来の一時的な文の根拠を改善するための可能な方向を提案します。クエリベースのモーメント検索は、クエリ文に従ってトリミングされていないビデオから特定のクリップをローカライズする問題です。さらに、新しい健全性チェック実験を提示し、結果を視覚化するためのアプローチ。 
[要約]このペーパーでは、ベンチマークの結果がモーメント検索タスクの解決における真の進捗状況をどの程度反映しているかを評価する一連の実験を紹介します。また、結果を視覚化するための新しい健全性チェック実験とアプローチも紹介します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Heatmap Regression via Randomized Rounding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_27.html">
      <font color="black">Heatmap Regression via Randomized Rounding</font>
    </a>
  </h2>
  <font color="black">結果として、ローカライズの精度と計算コストの間には常にトレードオフがあり、ヒートマップ回帰の計算の複雑さはヒートマップの解像度に2次式で依存します。具体的には、ヒートマップのアクティベーションポイントインデックスが常に整数であることを考えるとしたがって、数値座標の表現としてヒートマップを使用すると、量子化エラーが表示されます。このホワイトペーパーでは、バニラヒートマップ回帰の量子化エラーを正式に分析し、サブピクセルローカリゼーションの問題に対処するためのシンプルかつ効果的な量子化システムを提案します。 
[要約]ヒートマップ用に提案された量子化システムは魅力的です。サブピクセルのローカリゼーションの問題を克服することは困難です。問題を克服するための以前の方法は、通常、高解像度ヒートマップに依存しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Hyperspectral-Depth Imaging with Learned Diffractive Optics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_28.html">
      <font color="black">End-to-End Hyperspectral-Depth Imaging with Learned Diffractive Optics</font>
    </a>
  </h2>
  <font color="black">最適化されたDOEはグレースケールリソグラフィプロセスで製造され、ポータブルHS-Dカメラプロトタイプに挿入されます。これは、HS-D情報を確実にキャプチャすることが示されています。この高次元視覚データの自然画像統計を研究し、そのような機械学習ベースのDOEトレーニング手順では、2つのHS-Dデータセットを記録します。1つはディープオプティカルHS-Dイメージングのエンドツーエンドの最適化に使用され、もう1つは実際のDOEプロトタイプで再構成パフォーマンスを強化するために使用されます。 。 
[要約]不完全に結合されたイメージングシステムはhs-d画像をキャプチャする機能をキャプチャしますが、結合されたイメージのフォームファクタが増加し、この新しいテクノロジーの適用性が制限されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Distinctive 3D local deep descriptors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_29.html">
      <font color="black">Distinctive 3D local deep descriptors</font>
    </a>
  </h2>
  <font color="black">結果は、DIPが（i）最新のRGB-D屋内シーン（3DMatchデータセット）に匹敵する結果を達成していること、（ii）レーザースキャナー屋外で最新のパフォーマンスを大幅に上回っていることを示しています。シーン（ETHデータセット）、および（iii）Android ARCoreのVisual-SLAMシステムで再構築された屋内シーンに一般化します。点群パッチが抽出され、推定されたローカル参照フレームに関して正規化され、 PointNetベースのディープニューラルネットワーク。さまざまなセンサーを使用して再構築された点群からなるいくつかの屋内および屋外データセットで、代替の手作りおよびディープ記述子に対してDIPを評価および比較します。 
[要約]ディップ（i）は、室内シーンのデータセット（3dmatchデータセット）の状態に匹敵する結果を達成しました。しかし、それらはシンプルであり、乱雑で、オクルージョンがランダムであることがわかりました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Personalization in Human Activity Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_30.html">
      <font color="black">Personalization in Human Activity Recognition</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、この情報に依存しない深層学習分類器に関して、物理的特性と信号の類似性を活用してより良い結果を得る可能性を探ります。HARは、特に高齢者や退行性疾患の影響を受けている人々。この分野は、ヒューマンアクティビティ認識（HAR）として知られています。 
[ABSTRACT]分野は人間活動認識（har）として知られています。この情報は、身体的特徴とライフスタイルによりさまざまな方法で実行できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Quality-aware semi-supervised learning for CMR segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_31.html">
      <font color="black">Quality-aware semi-supervised learning for CMR segmentation</font>
    </a>
  </h2>
  <font color="black">英国のバイオバンクデータと2つの一般的に使用されるネットワークアーキテクチャ（U-netと完全畳み込みネットワーク）を使用して、2つのCMRセグメンテーションタスク（大動脈と短軸の心臓ボリュームセグメンテーション）でアプローチを評価し、監視ありおよびSSL戦略と比較します。画像解析結果を評価するとき、生物物理学および生理学に関する豊富な事前知識を説明します。semiQCSegがセグメンテーションネットワークのトレーニングを改善することを示します。 
[ABSTRACT]データ拡張と半教師あり学習（ssl）メソッドが開発されました。これにより、セグメンテーションネットワーク（semiqcseg）のsslのバリアントで品質を意識したトレーニングデータの拡張が提供されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal Image-to-Image Translation via Mutual Information Estimation
  and Maximization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_32.html">
      <font color="black">Multimodal Image-to-Image Translation via Mutual Information Estimation
  and Maximization</font>
    </a>
  </h2>
  <font color="black">さらに、私たちの方法は、ソースドメインのコンテンツとターゲットドメインスタイルの間の絡み合いを無料で解消します。このホワイトペーパーでは、潜在コード間の統計的依存を促進するだけで、マルチモーダルな画像から画像への変換を実現できる新しいフレームワークを紹介します。条件付き生成敵対的ネットワークの出力画像。最新の方法と比較して、さまざまなベンチマークの画像から画像への変換データセットに対して、監視ありおよび監視なしの設定で実験を行い、方法の有効性とシンプルさを示しています。マルチモーダルで高品質の結果を実現します。 
[要旨]さまざまなベンチマーク画像からスポットへの方法で、監視ありおよび監視なしの設定で実験を行います。この方法では、両方のソース画像ドメインからターゲット画像ドメインへの片側変換モデルを学習するだけで済みます。教師ありまたは教師なしマルチモーダル画像-から-画像への変換</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-08">
        <br><font color="black">2020-08-08</font>
      </time>
    </span>
</section>
<!-- paper0: Thick Cloud Removal of Remote Sensing Images Using Temporal Smoothness
  and Sparsity-Regularized Tensor Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_33.html">
      <font color="black">Thick Cloud Removal of Remote Sensing Images Using Temporal Smoothness
  and Sparsity-Regularized Tensor Optimization</font>
    </a>
  </h2>
  <font color="black">したがって、スパースノルムは、雲と雲の影のスパース性を高めるために使用され、単方向の全変動（UTV）レギュラライザーが適用されて、一方向の滑らかさを保証します。影の領域..この論文では、時間的平滑性とスパース性正則化テンソル最適化（TSSTO）に基づくリモートセンシング画像のための新しい厚い雲の除去方法を提案します。 
[ABSTRACT]一連の実験は、シミュレートされたクラウドと実際のクラウドの両方で行われます-さまざまなセンサーからのさまざまな解像度の汚染された画像</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-11">
        <br><font color="black">2020-08-11</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Domain Adaptation with Progressive Adaptation of Subspaces -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_34.html">
      <font color="black">Unsupervised Domain Adaptation with Progressive Adaptation of Subspaces</font>
    </a>
  </h2>
  <font color="black">これを克服するために、サブスペースのプログレッシブ適応アプローチ（PAS）と呼ばれる新しいUDAメソッドを提案します。このアプローチでは、信頼できる疑似ラベルを徐々に取得するのに非常に合理的であると思われる直感を利用します。当然、この問題を軽減する効果的な方法の1つは、それ自体が難しいターゲットドメインの疑似ラベルを確実に推定するためです。ただし、このようなアプローチでは、ターゲットドメインにラベルがないため、悪意のあるモード折りたたみの問題が発生しやすくなります。 
[ABSTRACT]既存の方法のほとんどは、ドメインの不一致を減らすことで、シフトによって引き起こされる悪影響を緩和しようとします。pasは、一般的なudaには効果的ですが、より挑戦的な部分ドメイン適応の技術よりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: PIDNet: An Efficient Network for Dynamic Pedestrian Intrusion Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_35.html">
      <font color="black">PIDNet: An Efficient Network for Dynamic Pedestrian Intrusion Detection</font>
    </a>
  </h2>
  <font color="black">計算の複雑さを軽減するために、3つの効率的なネットワーク設計が提案され、PIDNetに組み込まれています。1）機能共有のための特別なPIDタスクバックボーン、2）機能クロッピングのための機能クロッピングモジュール、3）機能圧縮のための軽量検出ブランチネットワークです。ビジョンベースの動的歩行者侵入検知（PID）、歩行者が移動するカメラによって対象領域（AoI）に侵入するかどうかを判断することは、モバイル監視における重要なタスクです。実験結果は、PIDNetが67.1％のPID精度と提案されたデータセットの9.6 fps推論速度。これは、将来のビジョンベースの動的PID研究の良いベースラインとして機能します。 
[要約] pidnetは主に2つの要素を考慮して設計されています。移動カメラでキャプチャされたビデオフレームからaoisを正確にセグメント化し、生成されたリソースから歩行者をすばやく検出します。pidnetは、提案されたネットワークを評価し、対応する初めての評価指標</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Training Deep Neural Networks with Constrained Learning Parameters -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_36.html">
      <font color="black">Training Deep Neural Networks with Constrained Learning Parameters</font>
    </a>
  </h2>
  <font color="black">次に、理論的な基盤について詳しく説明し、CoNNTrAの計算の複雑さを評価します。ニューロモーフィックコンピューティングシステムで実行される学習パラメーターが有限離散値のセットを持つように制約されているディープニューラルネットワーク（DNN）は、これらの望ましい特性を持つインテリジェントエッジコンピューティングシステム。今日のディープラーニングモデルは、主にCPUとGPUでトレーニングされています。 
[ABSTRACT]そのようなシステムのディープラーニングモデルのトレーニングは、低エラー、低メモリ、低消費電力のモデルを作成するために調整および採用する必要があります。これらのモデルは、32倍少ないメモリを使用し、バックプロパゲーションと同等のエラーがありますモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: ExplAIn: Explanatory Artificial Intelligence for Diabetic Retinopathy
  Diagnosis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_37.html">
      <font color="black">ExplAIn: Explanatory Artificial Intelligence for Diabetic Retinopathy
  Diagnosis</font>
    </a>
  </h2>
  <font color="black">このようなアーキテクチャの利点は、自動診断が画像や数文で簡単に説明できることです。病変の位置特定を改善するために、前景/背景の分離は、前景のピクセル変換を遮断するような方法で、自己監視を通じてトレーニングされます。入力画像を健全に見える画像に変換します。AIの展開を容易にするために、高い分類パフォーマンスと説明可能性を同時に提供するこの新しいフレームワークを期待しています。 
[ABSTRACT]成功したaiプログラムの「ブラックボックス」という性質は、依然としてその広範な使用を抑制しています。しかし、「ブラックボックス」の概念は、依然としてその広範な使用を抑制しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-13">
        <br><font color="black">2020-08-13</font>
      </time>
    </span>
</section>
<!-- paper0: Temporal Continuity Based Unsupervised Learning for Person
  Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_38.html">
      <font color="black">Temporal Continuity Based Unsupervised Learning for Person
  Re-Identification</font>
    </a>
  </h2>
  <font color="black">具体的には、TCULは同時に、ラベルなし（ターゲット）データセットのセンターベースのクラスタリングを行い、無関係なラベル付き（ソース）データセットで事前トレーニングされた畳み込みニューラルネットワーク（CNN）を微調整して、ターゲットデータセットのCNNの識別能力を強化します。トレーニングが進むと、信頼できるサンプルの数が適応的に増加し続け、CNNの表現能力が向上します。さらに、カメラ全体のフィーチャマップの空間的類似性と組み合わせて、カメラ内の画像の時間的に連続する性質を利用して、信頼できる疑似ラベルを生成します。再識別モデルのトレーニング用。 
[ABSTRACT] re-idメソッドは一般に、表現学習の識別ガイドラインとして機能するために大量のアイデンティティラベル付きデータを必要とします。この問題を克服するために、基礎となるre-idを段階的に学習および活用できる監視なしのセンターベースのクラスタリングアプローチを提案します差別的な情報</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Machine learning for COVID-19 detection and prognostication using chest
  radiographs and CT scans: a systematic methodological review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_39.html">
      <font color="black">Machine learning for COVID-19 detection and prognostication using chest
  radiographs and CT scans: a systematic methodological review</font>
    </a>
  </h2>
  <font color="black">背景：機械学習手法は、標準治療の胸部X線写真（CXR）およびコンピューター断層撮影（CT）画像からCOVID-19を迅速かつ正確に検出および予測する大きな可能性を提供します。 ..方法：この系統的レビューでは、2020年1月1日から2020年6月24日までにアップロードされた公開論文およびプレプリントについて、OVIDを介したEMBASE、PubMedを介したMEDLINE、bioRxiv、medRxiv、およびarXivをレビューしました。
[ABSTRACT]急速に成長している文献で採用されている機械学習手法。検証済みのcovid-19モデルが必要とされる緊急性を考えると、これは大きな弱点です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-14">
        <br><font color="black">2020-08-14</font>
      </time>
    </span>
</section>
<!-- paper0: Discriminability Distillation in Group Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_40.html">
      <font color="black">Discriminability Distillation in Group Representation Learning</font>
    </a>
  </h2>
  <font color="black">モデル..全体の手順は、識別可能蒸留学習（DDL）として示されます。識別可能知識には、軽量蒸留ネットワークによって抽出でき、目に見えないターゲットセットで一般化できる優れた特性があることを示します。 
[要約]識別可能性蒸留学習（ddl）は、識別可能性蒸留器学習（dl）として分類されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
<!-- paper0: A Primer on Motion Capture with Deep Learning: Principles, Pitfalls and
  Perspectives -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_41.html">
      <font color="black">A Primer on Motion Capture with Deep Learning: Principles, Pitfalls and
  Perspectives</font>
    </a>
  </h2>
  <font color="black">ビデオから非侵襲的に行動測定値を抽出することは、それが難しい計算上の問題であるという事実によって困惑します。特に、これらの新しいアルゴリズムの原理について説明し、それらの可能性と実験者の落とし穴を強調し、未来..この入門書では、ディープラーニングによるモーションキャプチャの新進分野をレビューします。 
[ABSTRACT]これらの新しいアルゴリズムの原理について説明し、実験家にとっての可能性と落とし穴を強調します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal Aggregation Approach for Memory Vision-Voice Indoor
  Navigation with Meta-Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_42.html">
      <font color="black">Multimodal Aggregation Approach for Memory Vision-Voice Indoor
  Navigation with Meta-Learning</font>
    </a>
  </h2>
  <font color="black">比較実験は、私たちの方法が最先端のベースラインよりも優れていることを証明しています。特定のタスクを不必要に繰り返すことを避け、エージェントが新しいシーンに適切に適応するためには、メモリが重要です。したがって、メタ学習を利用します。 ..目視観察から抽出したさまざまな機能的特徴を実験しました。 
[ABSTRACT]メモリビジョン-音声屋内ナビゲーション（mvv-）は、ロボットの環境理解を強化するために、音声コマンドを使用し、視覚観察のマルチモーダル情報を分析します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: RangeRCNN: Towards Fast and Accurate 3D Object Detection with Range
  Image Representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_43.html">
      <font color="black">RangeRCNN: Towards Fast and Accurate 3D Object Detection with Range
  Image Representation</font>
    </a>
  </h2>
  <font color="black">既存の3Dオブジェクト検出方法のほとんどは、ボクセルベースまたはポイントベースです。スパース性の問題を緩和し、実行時間を短縮するためにいくつかの最適化が導入されていますが、2つの表現は依然として計算上非効率的です。距離画像表現に基づく効果的な3Dオブジェクト検出フレームワーク。 
[ABSTRACT]距離画像表現は高密度でコンパクトであり、強力な2D畳み込みを利用し、スパース性の問題によって引き起こされる不確実な受容野を回避できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Generalized Zero-Shot Learning via VAE-Conditioned Generative Flow -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_44.html">
      <font color="black">Generalized Zero-Shot Learning via VAE-Conditioned Generative Flow</font>
    </a>
  </h2>
  <font color="black">より具体的には、GZSLの生成フローの条件付きバージョン、つまり、VAE条件付き生成フロー（VAE-cFlow）を提案します。再構成の目的、ii）VAE事後正則化でゼロ平均制約を解放、iii）潜在変数に分類正則化を追加.. VAEを使用することにより、意味論的記述はまず、生成フローを条件として扱いやすい潜在分布にエンコードされます。観察された視覚的特徴の正確な対数尤度を最適化します。 
[ABSTRACT] gzslは欠損データの問題であり、主にgansまたはvaesを使用して、目に見えないクラスの視覚的機能を生成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Lossless CNN Channel Pruning via Gradient Resetting and Convolutional
  Re-parameterization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_45.html">
      <font color="black">Lossless CNN Channel Pruning via Gradient Resetting and Convolutional
  Re-parameterization</font>
    </a>
  </h2>
  <font color="black">私たちの方法では、ImageNetで76.15 \％のトップ1の精度を持つ標準のResNet-50を、43.9 \％FLOPのみで精度の低下のないより狭いものにスリム化することができます。記憶の独立性に関する神経生物学の研究に触発され、忘れて、我々はCNNを記憶する部分と忘れる部分に再パラメーター化することを提案します。前者はパフォーマンスの維持を学び、後者は効率を学びます。前者の通常のSGDを使用して再パラメーター化されたモデルをトレーニングすることにより、新しい後者のペナルティグラディエントを使用してルールを更新すると、構造化されたスパース性が実現され、再パラメーター化されたモデルをより狭いレイヤーの元のアーキテクチャに同等に変換できるようになります。 
[ABSTRACT] `filter pruning &#39;は、畳み込みニューラルネットワーク（cnn）をスリム化することを目的としています。それは、畳み込み層の幅（つまり、出力チャネルの数）を減らすことを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Atrous Guided Filter for Image Restoration in Under Display Cameras -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_46.html">
      <font color="black">Deep Atrous Guided Filter for Image Restoration in Under Display Cameras</font>
    </a>
  </h2>
  <font color="black">この作業では、UDCシステムで画像を復元するための2段階のエンドツーエンドアプローチであるDeep Atrous Guided Filter（DAGF）を紹介します。最初のダウンサンプリングに加えて、低解像度ネットワークでは、複数の並列な環空間解像度を保持し、マルチスケール処理をエミュレートします。さらに、モデルを事前トレーニングしてパフォーマンスを向上させる簡単なシミュレーションスキームを提案します。 
[要旨]メガピクセルの画像を直接トレーニングするアプローチにより、パフォーマンスが大幅に向上します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-14">
        <br><font color="black">2020-08-14</font>
      </time>
    </span>
</section>
<!-- paper0: A Short Review on Data Modelling for Vector Fields -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_47.html">
      <font color="black">A Short Review on Data Modelling for Vector Fields</font>
    </a>
  </h2>
  <font color="black">3Dベクトル場を使用した3D点群のノンパラメトリック変換、地球科学における流体のモデリング、および物理場のモデリング..このレビュー記事は、ベクトルデータ表現、予測を含む、ベクトル場の最近の計算ツールに特化しています。空間データのモデルだけでなく、コンピュータビジョン、信号処理、および経験科学のアプリケーション..畳み込み層やスキップ接続などの効果的な構造を備えたディープニューラルネットワークを使用したエンドツーエンドモデリングスキームの最近の成功は、拡張を可能にします。自然言語、画像、動画など、より洗練された構造化された実用的なデータに変換します。
[要約]従来のデータモデルは、主に独立して同一に分散されたデータに関係しています。従来のネットワークは、主にこのような委託consに基づいています。このレビュー記事は、データモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: One Shot 3D Photography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CV/paper_48.html">
      <font color="black">One Shot 3D Photography</font>
    </a>
  </h2>
  <font color="black">まとめると、モバイルデバイスでの処理は数秒で完了し、その結果を即座に表示して共有できます。また、モバイルデバイス用に最適化された修復ネットワークを使用して、視差領域のカラーテクスチャと構造も合成します。 LDIを直接使用します。3D写真を作成および表示するためのエンドツーエンドのシステムと、アルゴリズムと設計の選択肢を提示します。 
[ABSTRACT]方法は、視差を表示する新しい写真に基づいています。結果の深度は、レイヤー化された深度画像に持ち上げられます。さらに、結果をメッシュベースの表現に変換します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Parallel Rescoring with Transformer for Streaming On-Device Speech
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CL/paper_0.html">
      <font color="black">Parallel Rescoring with Transformer for Streaming On-Device Speech
  Recognition</font>
    </a>
  </h2>
  <font color="black">LSTMベースのベースラインと比較して、提案されたトランスフォーマーリスコアラーは、50％以上のレイテンシ削減と品質向上を実現します。2番目のパスモデルは、従来のモデルを超えるエンドツーエンドモデルの品質向上に重要な役割を果たします。 .. 2パスモデルの主な課題の1つは、2パスモデルによって導入される計算待ち時間です。 
[ABSTRACT] 2パスモデルは、オンデバイスの音声認識により優れた速度と品質のトレードオフを提供します。1パスモデルは、ストリーミング方式で仮説を生成し、2パスモデルは、仮説を生成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-30">
        <br><font color="black">2020-08-30</font>
      </time>
    </span>
</section>
<!-- paper0: Interacting with Explanations through Critiquing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CL/paper_1.html">
      <font color="black">Interacting with Explanations through Critiquing</font>
    </a>
  </h2>
  <font color="black">システムはその批評に従ってユーザーモデルと結果の推奨事項を更新します。2つの実世界のデータセットでの実験は、私たちのシステムが、多段階の批評で表現された好みに適応して優れたパフォーマンスを達成した最初のものであることを示しています。推奨事項をサポートすることは、信頼と知覚品質を向上させることが示されています。 
[要約]これは、教師なしの新しい批評手法に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-22">
        <br><font color="black">2020-05-22</font>
      </time>
    </span>
</section>
<!-- paper0: Suicidal Ideation Detection: A Review of Machine Learning Methods and
  Applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CL/paper_2.html">
      <font color="black">Suicidal Ideation Detection: A Review of Machine Learning Methods and
  Applications</font>
    </a>
  </h2>
  <font color="black">最後に、現在の作業の制限を要約し、さらなる研究の方向性の見通しを提供します。自殺念慮検出のドメイン固有のアプリケーションは、アンケート、電子健康記録、自殺メモ、オンラインユーザーコンテンツなどのデータソースに従ってレビューされます..さらなる研究を容易にするために、いくつかの特定のタスクとデータセットが導入および要約されています。 
[ABSTRACT]自殺未遂の早期発見と防止に取り組む必要があると主任研究者は述べています。これは、これらのカテゴリーの方法を包括的に紹介し、議論する最初の調査です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-23">
        <br><font color="black">2019-10-23</font>
      </time>
    </span>
</section>
<!-- paper0: What Can We Learn From Almost a Decade of Food Tweets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CL/paper_3.html">
      <font color="black">What Can We Learn From Almost a Decade of Food Tweets</font>
    </a>
  </h2>
  <font color="black">また、質問と回答のツイートと感情の注釈が付けられたツイートの2つのサブコーパスを分離します。コーパスの内容を分析し、サブコーパスのユースケースを、ドメイン固有の質問応答と感情分析モデルを、コーパス..コーパスは8年以上の期間にわたって収集され、追加の有用なデータを伴う200万を超えるツイートが含まれています。 
[要約]コーパスは長期間にわたって収集されており、8年以上にわたっています。これには、有用なデータを伴う200万を超えるツイートが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-10">
        <br><font color="black">2020-07-10</font>
      </time>
    </span>
</section>
<!-- paper0: SuperPAL: Supervised Proposition ALignment for Multi-Document
  Summarization and Derivative Sub-Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CL/paper_4.html">
      <font color="black">SuperPAL: Supervised Proposition ALignment for Multi-Document
  Summarization and Derivative Sub-Tasks</font>
    </a>
  </h2>
  <font color="black">高品質のソースリファレンスアライメントアルゴリズムを開発することを推奨します。これは、最近の大規模なデータセットに適用して、有用な「シルバー」を取得できます。次に、トレーニング用の新しい大規模なアライメントデータセットを紹介します。これにより、自動アライメントモデルがトレーニングされました。近似、トレーニングデータ。 
[ABSTRACT]基礎となるアライメントステップは、個別に対処または評価されることはありませんでした。自動アライメントモデルがトレーニングされるトレーニング用の新しい大規模なアライメントデータセットによって作成されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Twitter Corpus of the #BlackLivesMatter Movement And Counter Protests:
  2013 to 2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CL/paper_5.html">
      <font color="black">Twitter Corpus of the #BlackLivesMatter Movement And Counter Protests:
  2013 to 2020</font>
    </a>
  </h2>
  <font color="black">BlackLivesMatter、AllLivesMatter、BlueLivesMatterのいずれかのキーワードを含む、1,000万人のユーザーからの4180万のツイートのデータセットを紹介します。これまで、同様にテーマが設定されていますが、範囲ははるかに小さいものの、BLMデータセットが談話の研究に使用されています抗議運動と反抗運動、リツイートの予測、抗議運動におけるソーシャルメディアの役割の調査、ナラティブエージェンシーの調査。このデータセットには、2013年のBLM運動の開始から2020年6月までの現在利用可能なすべてのツイートが含まれています。
[要約]運動は重要なメディアと政治的注目を集めています.2020年のアーモウアーバリー、ブレナテイラー、ジョージフロイドの殺害に続いて、同様のハッシュタグが＃alllivesmatterや＃bluelivesmatterなどのblm運動に対抗するように見えました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Temporal Mental Health Dynamics on Social Media -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CL/paper_6.html">
      <font color="black">Temporal Mental Health Dynamics on Social Media</font>
    </a>
  </h2>
  <font color="black">ソーシャルメディアプラットフォームからのメンタルヘルスデータマイニングの遠方監視に既存の方法論を利用し、ケーススタディとしてグローバルCOVID-19パンデミック中にシステムを展開します。戦略的な意思決定に利用できます。このタスクの困難な性質にもかかわらず、私たちは、世界的なパンデミックに明白であり、文献に裏付けられたグローバルな現象であるクリスマス不況に暗黙的な、有望な結果を生み出します。 
[要約]戦略的意思決定に使用するメンタルヘルスのダイナミクスへの洞察を提供するシステムを提案する-意思決定</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-30">
        <br><font color="black">2020-08-30</font>
      </time>
    </span>
</section>
<!-- paper0: Extracting Semantic Concepts and Relations from Scientific Publications
  by Using Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CL/paper_7.html">
      <font color="black">Extracting Semantic Concepts and Relations from Scientific Publications
  by Using Deep Learning</font>
    </a>
  </h2>
  <font color="black">この論文の目的は、科学出版物から意味論的概念と関係を自動的に抽出する提案を紹介することです。さらに、現在のオントロジー抽出システムには、事前定義された大量のパターンに応じて、小さなデータセットを使用するなど、多くの欠点と欠点があります。意味的関係を抽出し、非常に少数のタイプの関係を抽出します。現在のオントロジーリポジトリは、その範囲または最新性のいずれかについて非常に制限されています。 
[ABSTRACT]新しい論文は情報の新しい表現を示唆しています。新しいタイプの意味論的知識を示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: AMBERT: A Pre-trained Language Model with Multi-Grained Tokenization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/cs.CL/paper_8.html">
      <font color="black">AMBERT: A Pre-trained Language Model with Multi-Grained Tokenization</font>
    </a>
  </h2>
  <font color="black">この論文では、細粒度と粗粒度の両方のトークン化に基づいて、AMBERT（マルチグレインBERT）と呼ばれる新しい事前トレーニング済み言語モデルを提案します。英語の場合、AMBERTは次の両方のシーケンスを取ります。トークン化後の入力としての単語（細粒度トークン）およびフレーズのシーケンス（粗粒度トークン）は、1つのエンコーダーを使用して単語のシーケンスを処理し、もう1つのエンコーダーをフレーズのシーケンスを処理し、2つの間の共有パラメーターを利用します。エンコーダー、そして最後に単語の文脈化された表現のシーケンスとフレーズの文脈化された表現のシーケンスを作成します。モデルのトークンは通常、英語などの言語では単語またはサブワードであり、中国語のような言語の場合、これらは文字です。 
[ABSTRACT]事前トレーニング済みの言語モデルは細かい-ベルト付きで細かい-細かい。英語などの言語の場合、これらは単語またはサブユニットであり、chinese.ambertの場合、ほとんどすべての場合で既存の最高のパフォーマンスモデルより優れている</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Non-Parallel Voice Conversion with Augmented Classifier Star Generative
  Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.AS/paper_0.html">
      <font color="black">Non-Parallel Voice Conversion with Augmented Classifier Star Generative
  Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">第3に、変換された音声信号をリアルタイムで実装できるほど迅速に生成することができ、適度に現実的なサウンドの音声を生成するのに必要なトレーニング例はわずか数分です。この論文では、新しく導入されたStarGANの3つの定式化について説明します。 「拡張分類子StarGAN（A-StarGAN）」と呼ばれる新しいStarGANバリアントは、非並列VCタスクでそれらを比較します。また、いくつかのベースラインメソッドと比較します。 
[要約] stargan-vcと呼ばれるこのメソッドの主な機能は驚異的です。最初に、音声ジェネレータのトレーニングに、並列発話、翻訳、または時間調整手順は必要ありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Voice Separation with an Unknown Number of Multiple Speakers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.AS/paper_1.html">
      <font color="black">Voice Separation with an Unknown Number of Multiple Speakers</font>
    </a>
  </h2>
  <font color="black">新しい方法は、各出力チャネルのスピーカーを固定したまま、複数の処理ステップで音声を分離するようにトレーニングされたゲートニューラルネットワークを採用しています。複数の音声が同時に話す混合オーディオシーケンスを分離する新しい方法を紹介します。私たちの方法は、現在の技術水準を大幅に上回っています。これは、私たちが示しているように、3人以上のスピーカーにとって競争力がありません。 
[ABSTRACT]新しい方法は、話者を固定したまま、複数の処理ステップで音声を分離するようにトレーニングされたゲーテッドニューラルネットワークを採用しています。この方法は、3人以上の話者には競合しません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-29">
        <br><font color="black">2020-02-29</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Architecture Search For Keyword Spotting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.AS/paper_2.html">
      <font color="black">Neural Architecture Search For Keyword Spotting</font>
    </a>
  </h2>
  <font color="black">Googleの音声コマンドデータセットで提案された方法を評価し、文献で一般的に報告されている12クラスの発話分類の設定で97％を超える最先端の精度を達成しました。ディープニューラルネットワークは最近人気のあるソリューションになりましたキーワードスポッティングシステムとは、音声によるスマートデバイスの制御を可能にします。具体的には、差別化可能なアーキテクチャ検索技術を使用して、事前定義されたセル検索スペースで演算子とその接続を検索します。 
[ABSTRACT]許容可能なメモリフットプリントを維持しながら、音響信号から抽出された特徴に基づいてキーワードスポッティングのパフォーマンスを向上させるのに役立つ畳み込みニューラルネットワークモデルを検索します。見つかったセルは、競争力のあるパフォーマンスを実現するために深さと幅の両方で拡大されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Analysis of memory in LSTM-RNNs for source separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.AS/paper_3.html">
      <font color="black">Analysis of memory in LSTM-RNNs for source separation</font>
    </a>
  </h2>
  <font color="black">長期の短期記憶再帰型ニューラルネットワーク（LSTM-RNN）は、多くの音声処理タスクで最先端の技術と見なされています。400ミリ秒以上、メモリに保持されるのは話者の特性のみです。このアプローチをタスクに適用します。マルチスピーカーの音源分離の例ですが、RNNを使用するあらゆるタスクに使用できます。 
[要約]ネットワークでの繰り返しにより、原則として、入力を無期限に記憶できます。この機能は、音声などの時系列データに非常に役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-01">
        <br><font color="black">2020-09-01</font>
      </time>
    </span>
</section>
<!-- paper0: Parallel Rescoring with Transformer for Streaming On-Device Speech
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.AS/paper_4.html">
      <font color="black">Parallel Rescoring with Transformer for Streaming On-Device Speech
  Recognition</font>
    </a>
  </h2>
  <font color="black">LSTMベースのベースラインと比較して、提案されたトランスフォーマーリスコアラーは、50％を超えるレイテンシの削減と品質の向上を実現します。特に、2パスモデルの元の設計は、2番目のパスモデルにLSTMを使用します。これらは反復的な性質によって制約され、推論を順次実行する必要があるためです。この作業では、2番目のパスのリスコアラーのLSTMレイヤーをトランスフォーマーレイヤーで置き換えることを検討します。トランスフォーマーレイヤーは、仮説シーケンス全体を並列に処理できるため、 -デバイスの計算リソースをより効率的に。 
[ABSTRACT] 2パスモデルは、オンデバイスの音声認識により優れた速度と品質のトレードオフを提供します。1パスモデルは、ストリーミング方式で仮説を生成し、2パスモデルは、仮説を生成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-30">
        <br><font color="black">2020-08-30</font>
      </time>
    </span>
</section>
<!-- paper0: On Bottleneck Features for Text-Dependent Speaker Verification Using
  X-vectors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.AS/paper_5.html">
      <font color="black">On Bottleneck Features for Text-Dependent Speaker Verification Using
  X-vectors</font>
    </a>
  </h2>
  <font color="black">また、ガウス混合モデル-ユニバーサルバックグラウンドモデル（GMM-UBM）、i-vector、x-vectorなど、さまざまなモデリング手法のTD-SVパフォーマンスを比較します。さまざまなボトルネック（BN）機能の影響をさらに調査します最近導入された時間対比学習（TCL）BN機能と電話判別BN機能を含むx-ベクトルのパフォーマンスについて。GMM-UBMテクニックは、短い発話を使用したTD-SVの利点を示しています。 
[ABSTRACT] x -bms for text-dependentpeaker validation（td-sv）、unexplored.This model is based on the組み合わせof bn and i-たとえば</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-15">
        <br><font color="black">2020-05-15</font>
      </time>
    </span>
</section>
<!-- paper0: Learned Transferable Architectures Can Surpass Hand-Designed
  Architectures for Large Scale Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-02/eess.AS/paper_6.html">
      <font color="black">Learned Transferable Architectures Can Surpass Hand-Designed
  Architectures for Large Scale Speech Recognition</font>
    </a>
  </h2>
  <font color="black">（ii）改訂された検索スペースで学習したアーキテクチャは、パフォーマンスの低下がわずかなため、計算オーバーヘッドとGPUメモリ使用量を大幅に削減できます。広範な実験により、次のことがわかります。特に、複雑さの低いアーキテクチャを探索するための検索アルゴリズムを理論的に容易にする、音声認識タスクの修正された検索スペースを提案します。 
[要約]音声認識タスクの修正された検索スペースを提案します。これらのアーキテクチャは、穏やかなパフォーマンスの低下でasrのメモリ使用量を大幅に削減できます。これは、大規模なデータセット（最大1万時間）でのnasの結果の最初のレポートです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
