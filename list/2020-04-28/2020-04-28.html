<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-04-28の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: DWT-GBT-SVD-based Robust Speech Steganography -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-28/cs.SD/paper_0.html">
      DWT-GBT-SVD-based Robust Speech Steganography
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この方法では、最初にフレームのエネルギーとゼロクロッシングカウントに基づいて有声フレームを見つけ、次にバイナリメッセージを有声フレームに埋め込みます。NOIZEUSデータベースの実験結果は、提案された方法が感知できず、ガウスノイズに対してもロバストであることを示しています。 、再サンプリング、再量子化、ハイパスフィルター、およびローパスフィルター。また、透かしアプリケーションのMP3圧縮およびスケーリングに対して堅牢です。 
[要約]この論文では、新しい音声ステガノグラフィ法を提案します。提案された方法は知覚できず、ガウスノイズに対してもロバストです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br>2020-04-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Comparison of Speech Representations for Automatic Quality Estimation in
  Multi-Speaker Text-to-Speech Synthesis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-28/cs.SD/paper_1.html">
      Comparison of Speech Representations for Automatic Quality Estimation in
  Multi-Speaker Text-to-Speech Synthesis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      マルチスピーカーの音声合成（TTS）合成の知覚される出力品質にさまざまなスピーカーがどのように寄与するかを特徴付けることを目指しています。主要な発見は、TTSまたはVCシステムに関係なく、特定のスピーカーで達成される品質が一貫しているように見えることです。私たちのNNは、人間の判断と高い相関関係を持つMOSを予測します。 
[ABSTRACT]人間の平均オピニオンスコア（mos）評価でトレーニングされたニューラルネットワーク（nn）を使用して、ttsの品質を自動的に評価します。mosnetフレームベースの機能と一緒に8つの異なる表現を比較します。人間の判断
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-28">
        <br>2020-02-28
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Large Scale Question Answering using Tourism Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-28/cs.CL/paper_0.html">
      Large Scale Question Answering using Tourism Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      再ランキングでは、より深い注意に基づくアーキテクチャを使用して、選択したエンティティから最良の回答を選択します。まず、各エンティティのテキストをクラスタリングして、エンティティを説明する例文を特定します。解決策として、スケーラブルなクラスタ選択再ランクアプローチを設計します。 
[ABSTRACT] 47、124段落のサイズの質問を含むqaデータセットを収集します。このデータセットは、推論に一般的に使用されるニューラルアーキテクチャのため、特に挑戦的です。リランカーは、より深い注意-ベースのアーキテクチャを使用して、選択したエンティティから最良の回答を選びます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-08">
        <br>2019-09-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploiting Cloze Questions for Few Shot Text Classification and Natural
  Language Inference -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-28/cs.CL/paper_1.html">
      Exploiting Cloze Questions for Few Shot Text Classification and Natural
  Language Inference
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      いくつかのタスクと言語で、PETはリソースの少ない設定で監視付きトレーニングと監視なしアプローチの両方を大幅に上回っています。これらのフレーズは、ラベルなしの例のセットにソフトラベルを割り当てるために使用されます。この作業では、2つのアイデアを組み合わせることができることを示します。パターンの活用トレーニング（PET）を導入します。これは、言語モデルが特定のタスクを理解できるように、入力例をクローズスタイルのフレーズとして再定式化する半教師付きトレーニングプロシージャです。 
[ABSTRACT]パターンを利用して、言語モデルが特定のタスクを理解できるように、入力例をクローズ形式のフレーズとして再定式化する半教師付きトレーニング手順であるトレーニング（ペット）を利用します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-21">
        <br>2020-01-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Simple and Effective Model for Answering Multi-span Questions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-28/cs.CL/paper_2.html">
      A Simple and Effective Model for Answering Multi-span Questions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのモデルは、DROPとQuorefからのスパン抽出質問のパフォーマンスをそれぞれ9.9ポイントと5.5 EMポイントで大幅に改善します。読解（RC）のモデルは、一般に、出力スペースを、入力からのすべての単一の連続するスパンのセットに制限して、緩和します。学習の問題を解決し、テキストを明示的に生成するモデルの必要性を回避します。当然、シングルスパンを返すモデルはこれらの質問に答えることができません。 
[ABSTRACT]新しいデータセットにはマルチスパンの質問も含まれます。これには、回答が非連続のスパンのセットである質問が含まれます。ただし、単一のスパンを要求することは制限される場合があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-29">
        <br>2019-09-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Lexically Constrained Neural Machine Translation with Levenshtein
  Transformer -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-28/cs.CL/paper_3.html">
      Lexically Constrained Neural Machine Translation with Levenshtein
  Transformer
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      英語-ドイツ語WMTデータセットの実験は、私たちのアプローチが制約のないベースラインと以前のアプローチを改善することを示しています。以前の作業では、字句制約を使用して既存のモデルを再トレーニングするか、大幅に高い計算オーバーヘッドでビーム検索デコード中にそれらを組み込む必要がありました。柔軟性を活用そして、最近提案されたレーベンシュタイン変圧器モデル（Gu et al。、2019）の速度と同様に、私たちの方法は、復号化速度に影響を与えることなく、推論時に用語の制約を注入します。 
[要旨]私たちの方法は、トレーニング方法を変更する必要がありません。カスタム辞書を使用して、実行時に簡単に適用できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br>2020-04-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CodeBERT: A Pre-Trained Model for Programming and Natural Languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-28/cs.CL/paper_4.html">
      CodeBERT: A Pre-Trained Model for Programming and Natural Languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      モデルパラメーターを微調整することにより、2つのNL-PLアプリケーションでCodeBERTを評価します。結果は、CodeBERTが自然言語コード検索とコードドキュメント生成タスクの両方で最先端のパフォーマンスを実現することを示しています。 -プログラミング言語（PL）および自然言語（NL）のトレーニング済みモデル。 
[ABSTRACT]これにより、nl-plペアの二峰性データと単峰性データの両方を利用できます。前者はモデルトレーニングの入力トークンを提供し、後者はより優れたジェネレーターの学習に役立ちます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Recall and Learn: Fine-tuning Deep Pretrained Language Models with Less
  Forgetting -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-28/cs.CL/paper_5.html">
      Recall and Learn: Fine-tuning Deep Pretrained Language Models with Less
  Forgetting
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験は、この方法がGLUEベンチマークで最先端のパフォーマンスを達成することを示しています。具体的には、データなしで事前トレーニングタスクから知識を呼び出す事前トレーニングシミュレーションメカニズムと、下流のタスクに学習を集中させる目的シフトメカニズムを提案します。徐々に..この方法では、BERTベースでBERT-largeを直接微調整するよりも優れたパフォーマンスを実現することもできます。 
[ABSTRACT]これは、データなしで事前トレーニングタスクから知識を呼び出す事前トレーニングシミュレーションメカニズムに基づいています。この方法は、トレーニングよりも大きな成功を可能にします。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br>2020-04-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Introducing RONEC -- the Romanian Named Entity Corpus -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-28/cs.CL/paper_6.html">
      Introducing RONEC -- the Romanian Named Entity Corpus
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このコーパスはルーマニア語の言語空間における最初のイニシアチブを表しており、特に名前付きエンティティの認識を対象としています。この文章は、著作権のない新聞から抽出され、いくつかのスタイルをカバーしています。BRATおよびCoNLL-U Plusフォーマットで利用できます。 github.com/dumitrescustefan/ronecで自由に使用および拡張できます。 
[要約]コーパスには、約5000の注釈付き文に26000を超えるエンティティが含まれています。ルーマニア語言語空間での最初のイニシアチブを表しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-03">
        <br>2019-09-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On the Importance of Word and Sentence Representation Learning in
  Implicit Discourse Relation Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-28/cs.CL/paper_7.html">
      On the Importance of Word and Sentence Representation Learning in
  Implicit Discourse Relation Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのモジュールを組み合わせる新しいモデルを提案します。広範な実験により、提案されたモデルはPDTBデータセットでBERTおよびその他の最先端システムよりも約8％、CoNLL 2016データセットで約16％優れています。暗黙的な談話明示的な接続詞なしの関係予測では、テキストスパンレベルと文レベルの両方で言語を理解する必要があるため、関係分類は浅い談話解析で最も難しい部分の1つです。 
[要約]システムはモジュールを組み合わせることが提案されています。テキストメッセージは、表現学習のさまざまなレベルが結果にどのように影響するかを説明するのに役立ちます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br>2020-04-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Comparison of Speech Representations for Automatic Quality Estimation in
  Multi-Speaker Text-to-Speech Synthesis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-28/cs.CL/paper_8.html">
      Comparison of Speech Representations for Automatic Quality Estimation in
  Multi-Speaker Text-to-Speech Synthesis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      予測の相関とエラーを報告します。複数のスピーカーの音声合成（TTS）合成の知覚される出力品質に、さまざまなスピーカーがどのように寄与するかを特徴付けることを目的としています。 TTSシステム：私たちの方法は、そのような話者を識別する自動方法を提供します。 
[ABSTRACT]人間の平均オピニオンスコア（mos）評価でトレーニングされたニューラルネットワーク（nn）を使用して、ttsの品質を自動的に評価します。mosnetフレームベースの機能と一緒に8つの異なる表現を比較します。人間の判断
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-28">
        <br>2020-02-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Machine Translation with Monte-Carlo Tree Search -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-28/cs.CL/paper_9.html">
      Neural Machine Translation with Monte-Carlo Tree Search
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このネットワークは、ローカルとグローバルの両方の先読み参照として機能し、検索結果を使用してそれ自体を改善します。値ネットワークを追加すると、BLEUスコアなどの評価指標でアルゴリズムのパフォーマンスが向上します。私たちのプロジェクトは、代わりにモンテカルロツリー検索（MCTS）を利用して、AlphaZeroと同様の方法でポリシーとバリューネットワークアーキテクチャの組み合わせからのガイダンスで適切な出力ワードを検索します。 
[要約]私たちのプロジェクトの主なアイデアは、代わりにモンテカルロツリー検索（mcts）を使用して、ポリシーとバリューネットワークアーキテクチャの組み合わせからのガイダンスで適切な出力ワードを検索することです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br>2020-04-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Batch Normalized Inference Network Keeps the KL Vanishing Away -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-28/cs.CL/paper_10.html">
      A Batch Normalized Inference Network Keeps the KL Vanishing Away
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、提案されたBN-VAEを条件付きVAE（CVAE）に拡張できることを示します。次に、分布を正則化することで期待値の下限を設定するシンプルで効果的なアプローチであるバッチ正規化VAE（BN-VAE）を提案します。変分オートエンコーダ（VAE）は、生成変分モデルとして広く使用されており、償却変分推論とディープニューラルネットワークを組み合わせることで、潜在変数のモデルの事後を近似します。 
[ABSTRACT] vaeは、しばしば「事後崩壊」として知られる縮退した局所最適に収束します。vaeのアプローチは、言語モデリング、テキスト分類、およびダイアログ生成の強力な自己回帰ベースラインを超えています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br>2020-04-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: PANDORA Talks: Personality and Demographics on Reddit -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-28/cs.CL/paper_11.html">
      PANDORA Talks: Personality and Demographics on Reddit
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、すべての性格および人口統計変数のベンチマーク予測モデルを提示します。性格および人口統計は社会科学の重要な変数ですが、NLPでは、社会バイアスの解釈可能性と除去に役立ちます。これに対処するために、最初のPANDORA 3人の性格モデル（確立されたBig 5モデルを含む）および人口統計（年齢、性別、場所）でラベル付けされたRedditコメントの大規模なデータセット。 
[ABSTRACT]個性と人口統計の両方のラベルを持つデータセットは不足しています。データセットを使用して、大きな5つの特性を予測できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br>2020-04-09
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: DWT-GBT-SVD-based Robust Speech Steganography -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-28/eess.AS/paper_0.html">
      DWT-GBT-SVD-based Robust Speech Steganography
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、電子透かしアプリケーションのMP3圧縮およびスケーリングに対して堅牢です。この論文では、離散ウェーブレット変換、グラフベースの変換、および特異値分解（SVD）の組み合わせに基づく新しい音声ステガノグラフィ法を提案します。この方法では、まずエネルギーとフレームのゼロクロッシングカウントに基づいて有声フレームを見つけ、次にバイナリメッセージを有声フレームに埋め込みます。 
[要約]この論文では、新しい音声ステガノグラフィ法を提案します。提案された方法は知覚できず、ガウスノイズに対してもロバストです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br>2020-04-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Comparison of Speech Representations for Automatic Quality Estimation in
  Multi-Speaker Text-to-Speech Synthesis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-28/eess.AS/paper_1.html">
      Comparison of Speech Representations for Automatic Quality Estimation in
  Multi-Speaker Text-to-Speech Synthesis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのNNは、人間の判断と高い相関関係でMOSを予測します。重要な発見は、TTSまたはVCシステムに関係なく、特定のスピーカーで達成された品質が一貫しているように見えることです。 T60残響時間など、さまざまなタイプのノイズをモデル化します。 
[ABSTRACT]人間の平均オピニオンスコア（mos）評価でトレーニングされたニューラルネットワーク（nn）を使用して、ttsの品質を自動的に評価します。mosnetフレームベースの機能と一緒に8つの異なる表現を比較します。人間の判断
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-28">
        <br>2020-02-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Time-Frequency Analysis and Parameterisation of Knee Sounds for
  Non-invasive Detection of Osteoarthritis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-28/eess.AS/paper_2.html">
      Time-Frequency Analysis and Parameterisation of Knee Sounds for
  Non-invasive Detection of Osteoarthritis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      正常な信号と異常な信号の分類のタスクに対するそれらの有効性は、包括的な実験フレームワークを使用して評価されます。結論：分析は、不均一な周波数スケーリングを使用した場合の分類パフォーマンスの改善を示し、差別的な特徴を含む特定の周波数帯域を識別します。重要性：反対座位から立位への動きと膝の屈曲/伸展に焦点を当てた他の研究では、この研究は歩行中に得られた膝の音を使用しました。 
[ABSTRACT]分析は分類パフォーマンスの改善を示しています。これらのバンドは差別的な特徴で識別されます。これは、分類パフォーマンスへの特徴抽出パラメーターの影響が調査され、分析が膝変形性関節症の非侵襲的検出につながることを示唆しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br>2020-04-27
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本日更新された論文はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br>
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
