<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-10-06の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: JDI-T: Jointly trained Duration Informed Transformer for Text-To-Speech
  without Explicit Alignment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.SD/paper_0.html">
      <font color="black">JDI-T: Jointly trained Duration Informed Transformer for Text-To-Speech
  without Explicit Alignment</font>
    </a>
  </h2>
  <font color="black">ESPnet-TTSによってトレーニングされたベースラインのテキスト読み上げ（TTS）モデルと比較して、公開されている韓国語の単一話者音声（KSS）データセットで提案されたモデルの有効性を評価します。具体的には、自動回帰から音素持続時間を抽出します。自動回帰モデルを事前トレーニングして音素持続時間抽出器として使用する代わりに、共同トレーニング中にオンザフライでトランスフォーマーを使用します。明示的になしで共同トレーニングされた持続時間予測子を備えたフィードフォワードトランスフォーマーである、共同トレーニングされた持続時間インフォームドトランスフォーマー（JDI-T）を提案します。入力テキストから音響特徴シーケンスを生成するための配置。 
[概要]これは、単一のスピーカーで前方音素持続時間抽出器を使用せずに音響モデルを共同でトレーニングする最初の実装です。このプロジェクトは、fastspeechやsなどの持続時間情報ネットワークの最近の成功に触発されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-15">
        <br><font color="black">2020-05-15</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Adversarial Text-to-Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.SD/paper_1.html">
      <font color="black">End-to-End Adversarial Text-to-Speech</font>
    </a>
  </h2>
  <font color="black">モデルが生成されたオーディオの時間的変化をキャプチャできるようにするために、スペクトログラムベースの予測損失にソフトダイナミックタイムワーピングを採用しています。結果のモデルは、状態に匹敵する5ポイントスケールで4を超える平均オピニオン評点を達成します。多段階トレーニングと追加の監視に依存する最先端のモデル。提案されたジェネレーターはフィードフォワードであるため、トークンの長さの予測に基づく差別化可能なアライメントスキームを使用して、トレーニングと推論の両方に効率的です。 
[ABSTRACT]モデルは、敵対的なフィードバックと予測損失の組み合わせから生の音声を生成します。結果のモデルは、5ポイントスケールで4を超える平均オピニオン評点を達成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-05">
        <br><font color="black">2020-06-05</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Speaker Diarization for an Unknown Number of Speakers with
  Encoder-Decoder Based Attractors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.SD/paper_2.html">
      <font color="black">End-to-End Speaker Diarization for an Unknown Number of Speakers with
  Encoder-Decoder Based Attractors</font>
    </a>
  </h2>
  <font color="black">音声埋め込みシーケンスは、従来の自己注意型エンドツーエンドニューラルスピーカーダイアリゼーション（SA-EEND）ネットワークを使用して抽出されます。この論文では、最初に柔軟な数値を生成するエンコーダ-デコーダベースのアトラクタ計算（EDA）の方法を提案します。音声埋め込みシーケンスからのアトラクタの数..2スピーカー条件で、私たちの方法は、シミュレートされた混合物で2.69％のダイアリゼーションエラー率（DER）を達成し、CALLHOMEの2スピーカーサブセットで8.07％DERを達成しましたが、バニラSA-EENDそれぞれ4.56％と9.54％に達しました。 
[ABSTRACT]この方法は、話者の数に関して柔軟性が低くなります。これにより、同じ数の話者アクティビティを作成するために、いくつかの埋め込みシーケンスが作成されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br><font color="black">2020-05-20</font>
      </time>
    </span>
</section>
<!-- paper0: TD-GIN: Token-level Dynamic Graph-Interactive Network for Joint Multiple
  Intent Detection and Slot Filling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.SD/paper_3.html">
      <font color="black">TD-GIN: Token-level Dynamic Graph-Interactive Network for Joint Multiple
  Intent Detection and Slot Filling</font>
    </a>
  </h2>
  <font color="black">この論文では、共同の複数インテント検出とスロット充填のための適応グラフ-インタラクティブフレームワーク（AGIF）を提案します。ここでは、インテント-スロットグラフ相互作用レイヤーを導入して、スロットとインテント間の強い相関をモデル化します。このような相互作用レイヤーは各トークンに適応的に適用されます。これには、関連するインテント情報を自動的に抽出し、トークンレベルのスロット予測のためのきめ細かいインテント情報の統合を行うという利点があります。さらに、フレームワークは新しい最先端を実現します。 2つのシングルインテントデータセットでのパフォーマンス。 
[概要]ほとんどの話し言葉理解（slu）モデルは、主に単一のインテント状態に焦点を当てています-または単にすべてのトークンの全体的なインテントコンテキストツールを組み込んでいます。さらに、私たちのフレームワークは、2つの単一のインテントデータセットで新しい最先端のパフォーマンスを実現します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br><font color="black">2020-04-21</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Unsupervised Region-based Anomaly Detection in Brain MRI with
  Adversarial Image Inpainting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.IV/paper_0.html">
      <font color="black">Unsupervised Region-based Anomaly Detection in Brain MRI with
  Adversarial Image Inpainting</font>
    </a>
  </h2>
  <font color="black">最後に、スーパーピクセルセグメンテーションを実行してそれらの領域をセグメント化します。次に、適用時に、再構成損失が最も大きい領域を特定することによって異常領域を決定します。提案されたシステムがさまざまなサイズの抽象的な腫瘍をセグメント化でき、平均と標準を達成できることを示します。偏差ダイススコアはそれぞれ0.771と0.176です。 
[要約]提案されたシステムは、さまざまなサイズの抽象的な腫瘍を伸ばすことができます。0.771および0.176の平均および標準偏差のダイススコアを達成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic CAD-RADS Scoring Using Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.IV/paper_1.html">
      <font color="black">Automatic CAD-RADS Scoring Using Deep Learning</font>
    </a>
  </h2>
  <font color="black">さらなる侵襲的調査の必要性を示すCAD-RADSスコアを持つ患者を特定するタスクでは、患者がCADに苦しんでいるかどうかを判断するために、私たちのアプローチは0.923の曲線下面積（AUC）と0.914のAUCに達します。以前の完全に自動化された中心線抽出とセグメントラベリングに基づいて、マルチタスク学習セットアップの補助タスクとしてセグメントごとの狭窄度と全体的な石灰化グレードを予測します。2,867人の患者からなるデータ収集でアプローチを評価します。 
[ABSTRACT] cad-レポートおよびデータシステム（cad-rads）は、コミュニケーションを標準化し、cctaの調査結果に基づいたグレーディングを支援するために開発されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Painting Outside as Inside: Edge Guided Image Outpainting via
  Bidirectional Rearrangement with Step-By-Step Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.IV/paper_2.html">
      <font color="black">Painting Outside as Inside: Edge Guided Image Outpainting via
  Bidirectional Rearrangement with Step-By-Step Learning</font>
    </a>
  </h2>
  <font color="black">より方向性のある情報を反映することにより、画像の修復タスクを活用するために画像を再配置します。従来の画像の修復方法では、一貫性のないぼやけた繰り返しのピクセルが生成されます。さらに、画像を構造情報と元の入力と見なすエッジマップジェネレータを使用します。未知の領域のエッジを幻覚させて画像を生成します。 
[ABSTRACT]双方向境界領域再配置により、画像修復タスクと同様の双方向情報を使用して、欠落領域を生成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Detection of Coronavirus Disease (COVID-19) Using X-ray Images
  and Deep Convolutional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.IV/paper_3.html">
      <font color="black">Automatic Detection of Coronavirus Disease (COVID-19) Using X-ray Images
  and Deep Convolutional Neural Networks</font>
    </a>
  </h2>
  <font color="black">5分割交差検定を使用して、4つのクラス（COVID-19、正常（健康）、ウイルス性肺炎、細菌性肺炎）の3つの異なる二項分類を実装しました。したがって、迅速な代替手段として自動検出システムを実装する必要があります。 COVID-19が人々に広がるのを防ぐための診断オプション..得られたパフォーマンス結果を考慮すると、事前にトレーニングされたResNet50モデルが最高の分類パフォーマンスを提供することがわかりました（データセット-1で96.1％の精度、データセット-2で99.5％の精度）他の4つの使用済みモデルの中でデータセット-3）の99.7％の精度。 
[概要]毎日の症例数の増加により、病院で利用できるcovid-19テストキットの数は限られています。その中で、胸部xを使用したコロナウイルス肺炎感染患者の検出のために5つの事前トレーニング済み畳み込みニューラルネットワークベースのモデルが提案されています。 -光線X線写真</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-24">
        <br><font color="black">2020-03-24</font>
      </time>
    </span>
</section>
<!-- paper0: Time-Dynamic Estimates of the Reliability of Deep Semantic Segmentation
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.IV/paper_4.html">
      <font color="black">Time-Dynamic Estimates of the Reliability of Deep Semantic Segmentation
  Networks</font>
    </a>
  </h2>
  <font color="black">自動運転などのアプリケーションと同様に、画像のビデオストリームが利用可能であるため、不確実性を調査し、ニューラルネットワークの予測品質を評価するための時間動的アプローチを提示します。時間の経過とともにセグメントを追跡し、セグメントごとに集計されたメトリックを収集して、時系列を取得します。これは、0に等しい0より大きいユニオン上の交差を分類するか、ユニオン上の交差を直接予測することによって行われます。 
[概要]不確実性によるニューラルネットワークの評価は一般的な仮説です。時間の経過とともにセグメントを追跡し、セグメントごとに集計されたメトリックを収集して、メトリックの時系列を取得します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-12">
        <br><font color="black">2019-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Motion Correction of 3D Dynamic Contrast-Enhanced Ultrasound Imaging
  without Anatomical Bmode Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.IV/paper_5.html">
      <font color="black">Motion Correction of 3D Dynamic Contrast-Enhanced Ultrasound Imaging
  without Anatomical Bmode Images</font>
    </a>
  </h2>
  <font color="black">NCCによって評価されたフレーム間の類似性は、0.694（元のシネ）から0.862（対応するMCシネ）および0.723から0.886までの2つの異なる時点のセットでも大幅に改善されました。 Philips X6-1マトリックストランスデューサを1〜3 Hzのフレームレートで使用した肝臓..補正なしの68％からモーション補正ありの83％まで、すべての患者でフレーム間の病変の重複が大幅に改善されたことを確認しました（p = 0.023）。 
[概要] 3ddce-uscineは3dソフトウェアを使用して3ddceを修正します。ローカル登録を実行するために3〜6の連続するフレームの短い時間ウィンドウが作成されます。これらはすべてのフレームの加重平均に基づいてマスター参照に登録されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: A Comparative Study of Existing and New Deep Learning Methods for
  Detecting Knee Injuries using the MRNet Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.IV/paper_6.html">
      <font color="black">A Comparative Study of Existing and New Deep Learning Methods for
  Detecting Knee Injuries using the MRNet Dataset</font>
    </a>
  </h2>
  <font color="black">また、磁気共鳴画像法（MRI）データのいくつかの特性を活用するために、たとえば、軸方向、冠状面、矢状面のそれぞれからの固定数のスライスまたは2D画像を使用したり、3つの面を1つのマルチプレーンネットワークに結合したりします。 .. MRIを処理するモデルの開発とトレーニングに役立つ可能性のある、より柔軟なアーキテクチャも提案されています。転送学習と慎重に調整されたデータ拡張戦略が、最高のパフォーマンスを決定する重要な要素であることがわかりました。 
[概要]すべてのアプローチは、磁気学習とゼロからトレーニングされた深層残差ネットワークに基づいています。全体として、最新の深層学習アーキテクチャとデータ拡張戦略を使用して、検証データで93.4％aucのパフォーマンスを達成しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding Catastrophic Overfitting in Single-step Adversarial
  Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.IV/paper_7.html">
      <font color="black">Understanding Catastrophic Overfitting in Single-step Adversarial
  Training</font>
    </a>
  </h2>
  <font color="black">この方法は、壊滅的な過剰適合を防ぐだけでなく、シングルステップの敵対的トレーニングはマルチステップの攻撃を防ぐのが難しいという信念を無効にします。（i）敵対的な画像をトレーニングするため、シングルステップの敵対的トレーニングで壊滅的な過剰適合が発生することを示します。最大摂動のみであり、敵対方向のすべての敵対的例ではなく、歪んだ決定境界と高度に湾曲した損失面につながります。（ii）チェックポイントを使用する簡単な方法を提案することにより、この現象を実験的に証明します。 
[概要]「壊滅的な過剰適合」の問題が観察されました。これは、数百のトレーニングエポックを短時間で実行した後でも、さまざまな攻撃に対する堅牢性を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Review: Deep Learning in Electron Microscopy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.IV/paper_8.html">
      <font color="black">Review: Deep Learning in Electron Microscopy</font>
    </a>
  </h2>
  <font color="black">コンテキストとして、電子顕微鏡での深層学習の一般的なアプリケーションを確認します。次に、ニューラルネットワークコンポーネント、一般的なアーキテクチャ、およびそれらの最適化を確認します。最後に、電子顕微鏡での深層学習の将来の方向性について説明します。 
[概要]このレビューペーパーは、知識が限られている開発者を対象とした実用的な視点を提供します。これには、電子顕微鏡などの技術の実用的な視点が含まれます。最後に、電子顕微鏡における深層学習の将来の方向性について説明します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Trainable Structure Tensors for Autonomous Baggage Threat Detection
  Under Extreme Occlusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.IV/paper_9.html">
      <font color="black">Trainable Structure Tensors for Autonomous Baggage Threat Detection
  Under Extreme Occlusion</font>
    </a>
  </h2>
  <font color="black">提案されたフレームワークは、4つの公開されているX線データセットで広範囲にテストされており、平均精度スコアの点で最先端のフレームワークよりも優れています。多くの研究者が、これらの脅威を認識するためのコンピュータ支援スクリーニングシステムを開発しました。手荷物のX線スキャン..さらに、私たちの知る限りでは、4つの異なるタイプのX線スキャナーから取得したグレースケールスキャンとカラースキャンの組み合わせで検証された唯一のフレームワークです。 
[概要]新しい論文は、訓練可能な構造を使用して、閉塞および乱雑な密輸品の輪郭を強調するツールを示しています。これは、4種類のX線スキャナーから取得したグレースケールスキャンとカラースキャンの組み合わせで検証された唯一のフレームワークです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Test-time Unsupervised Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.IV/paper_10.html">
      <font color="black">Test-time Unsupervised Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">ターゲットドメインから特定のターゲットサブジェクトに適合されたモデルが、ターゲットドメインのより多くのデータを確認したが、この特定のターゲットサブジェクトを確認しなかったドメイン適応方法よりも優れていることを示します。したがって、テスト時UDAを実行する評価フレームワークを提案します。この結果は、単一のターゲットドメインサブジェクトのみを使用している場合でも、監視されていないドメイン適応をテスト時に使用する必要があるという理論をサポートしています
[ABSTRACT]したがって、それぞれに対してテストを実行する評価フレームワークを提案します。個別に主題</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient and flexible approach to ptychography using an optimization
  framework based on automatic differentiation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.IV/paper_11.html">
      <font color="black">Efficient and flexible approach to ptychography using an optimization
  framework based on automatic differentiation</font>
    </a>
  </h2>
  <font color="black">シミュレーションを使用して、ADベースのフレームワークが、再構築の速度と品質の点で、運動量加速されたサイコグラフィック反復エンジン（mPIE）の最先端の実装と同等に機能することを示します。最後に、実験的にフレームワークは生物学的標本を忠実に再構築します。再構築距離をトレーニング可能なパラメーターとして設定することで示すように、ADベースのアプローチは大きな柔軟性を提供します。 
[概要]広告ベースのフレームワークが、最先端の勢いの実装に匹敵するパフォーマンスを発揮することを示します。加速されたサイコグラフィック反復エンジン</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: GMMLoc: Structure Consistent Visual Localization with Gaussian Mixture
  Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CV/paper_0.html">
      <font color="black">GMMLoc: Structure Consistent Visual Localization with Gaussian Mixture
  Models</font>
    </a>
  </h2>
  <font color="black">この目的のために、ガウス混合モデル（GMM）によってモデル化された以前のマップでカメラを追跡するクロスモダリティ手法を提示します。ハイブリッド構造因子をジョイント最適化に導入することにより、カメラのポーズがバンドル調整されます。ローカル視覚構造..さらに、最先端のビジョン優位の状態推定器との比較研究は、私たちの方法の競争力のあるパフォーマンスを示しています。 
[概要]三角測量による視覚的構造が同時に洗練されます。精度と効率のパラドックスに対処することを目指しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-24">
        <br><font color="black">2020-06-24</font>
      </time>
    </span>
</section>
<!-- paper0: Sub-Instruction Aware Vision-and-Language Navigation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CV/paper_1.html">
      <font color="black">Sub-Instruction Aware Vision-and-Language Navigation</font>
    </a>
  </h2>
  <font color="black">トレーニング中にエージェントにきめ細かい注釈を提供し、エージェントが指示にうまく従うことができ、テスト時にターゲットに到達する可能性が高いことを確認します。ビジョンと言語のナビゲーションでは、エージェントが実際の3Dをナビゲートする必要があります。自然言語の指示に従った環境..Fine-GrainedR2Rデータセット（FGR2R）とコードをhttps://github.com/YicongHong/Fine-Grained-R2Rでリリースします。 
[概要]提案された方法は、4つのエージェントすべてのパフォーマンスを向上させるように設計されています。これらの作業でデータセットを完全に使用できるのは初めてです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Detection of Coronavirus Disease (COVID-19) Using X-ray Images
  and Deep Convolutional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CV/paper_2.html">
      <font color="black">Automatic Detection of Coronavirus Disease (COVID-19) Using X-ray Images
  and Deep Convolutional Neural Networks</font>
    </a>
  </h2>
  <font color="black">5分割交差検定を使用して、4つのクラス（COVID-19、正常（健康）、ウイルス性肺炎、細菌性肺炎）で3つの異なる二項分類を実装しました。この研究では、5つの事前トレーニング済み畳み込み神経ネットワークベースのモデル（ResNet50 、ResNet101、ResNet152、InceptionV3およびInception-ResNetV2）は、胸部X線写真を使用したコロナウイルス肺炎感染患者の検出に提案されています。得られたパフォーマンス結果を考慮すると、事前にトレーニングされたResNet50モデルが最高の分類を提供することがわかりました。他の4つの使用済みモデルの中で、パフォーマンス（Dataset-1の96.1％の精度、Dataset-2の99.5％の精度、Dataset-3の99.7％の精度）。 
[概要]毎日の症例数の増加により、病院で利用できるcovid-19テストキットの数は限られています。その中で、胸部xを使用したコロナウイルス肺炎感染患者の検出のために5つの事前トレーニング済み畳み込みニューラルネットワークベースのモデルが提案されています。 -光線X線写真</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-24">
        <br><font color="black">2020-03-24</font>
      </time>
    </span>
</section>
<!-- paper0: Graph Adversarial Networks: Protecting Information against Adversarial
  Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CV/paper_3.html">
      <font color="black">Graph Adversarial Networks: Protecting Information against Adversarial
  Attacks</font>
    </a>
  </h2>
  <font color="black">レコメンダーシステム、知識グラフ、量子化学からの複数のデータセットにわたる実験は、提案されたアプローチが、競争力のあるGNNエンコーダーを生成しながら、さまざまなグラフ構造とタスクにわたって堅牢な防御を提供することを示しています。最悪の場合の敵に対するフレームワークの有効性を分析します。予測精度と敵対的防御の間のトレードオフを特徴づけます。これに対抗するために、目的のGNNエンコーダーと最悪の場合の攻撃者の間のミニマックスゲームを提案します。 
[概要]近隣軌道ツールは、攻撃者に追加の脆弱性を公開します。結果として生じる敵対的なトレーニングは、結論に対する強力な防御を作成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Addressing Class Imbalance in Scene Graph Parsing by Learning to
  Contrast and Score -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CV/paper_4.html">
      <font color="black">Addressing Class Imbalance in Scene Graph Parsing by Learning to
  Contrast and Score</font>
    </a>
  </h2>
  <font color="black">さらに、画像の特徴と関係の特徴に基づいて関係をランク付けし、予測の想起を改善することを学習する、スコアラーと呼ばれる新しいスコアリングモジュールを提案します。具体的には、新しい対照的なクロスエントロピー損失を設計します。誤った頻繁な関係を抑制することによるまれな関係の検出..これらのまれな関係の検出が実際のアプリケーションで重要になる可能性があるという事実に動機付けられて、この論文は、シーングラフ解析におけるクラス不均衡問題を解決するための分類とランク付けの新しい統合フレームワークを紹介します。 。 
[ABSTRACT]最近のアプローチは、いくつかの人気のあるベンチマークで高い平均スコアを達成していますが、データの非常にロングテールな分布が学習を頻繁なラベルに偏らせるため、まれな関係の検出に失敗します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Time-Dynamic Estimates of the Reliability of Deep Semantic Segmentation
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CV/paper_5.html">
      <font color="black">Time-Dynamic Estimates of the Reliability of Deep Semantic Segmentation
  Networks</font>
    </a>
  </h2>
  <font color="black">これは、0に等しい0より大きいユニオンの交差を分類するか、ユニオンの交差を直接予測することによって行われます。これら2つのタスクのさまざまなモデルを調査し、時系列の長さがメトリックの予測力に与える影響を分析します。 ..ニューラルネットワークを使用したストリートシーンのセマンティックセグメンテーションでは、予測の信頼性が最も重要です。 
[概要]不確実性によるニューラルネットワークの評価は一般的な仮説です。時間の経過とともにセグメントを追跡し、セグメントごとに集計されたメトリックを収集して、メトリックの時系列を取得します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-12">
        <br><font color="black">2019-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Patch Priors for Practical Compressive Image Recovery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CV/paper_6.html">
      <font color="black">Generative Patch Priors for Practical Compressive Image Recovery</font>
    </a>
  </h2>
  <font color="black">最後に、GPPを使用して、キャリブレーションと再構築を組み合わせた代替最適化戦略を提案します。これは、実際のキャリブレーションされていない圧縮センシングデータセットの複数のベースラインに対して良好に機能します。学習したものとは異なり、範囲空間に制限された画像レベルの事前分布事前にトレーニングされたジェネレーターの場合、GPPは、事前にトレーニングされたパッチジェネレーターを使用して、さまざまな自然画像を復元できます。さらに、GPPは、非常に低いセンシングレートでの高い再構成品質など、生成可能な事前分布の利点を保持します。該当します。 
[ABSTRACT] gppは、事前にトレーニングされたパッチジェネレータを使用して、さまざまな自然画像を復元できます。また、3つの異なるセンシングモデルで、いくつかの教師なしおよび教師あり手法よりも優れたパフォーマンスを発揮します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br><font color="black">2020-06-18</font>
      </time>
    </span>
</section>
<!-- paper0: An Ensemble of Simple Convolutional Neural Network Models for MNIST
  Digit Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CV/paper_7.html">
      <font color="black">An Ensemble of Simple Convolutional Neural Network Models for MNIST
  Digit Recognition</font>
    </a>
  </h2>
  <font color="black">回転と平行移動は、ほとんどの画像分類タスクで頻繁に使用されるトレーニングデータを補強するために使用されます。2層アンサンブル、3つの同種アンサンブルネットワークの異種アンサンブルは、最大99.91％のテスト精度を達成できます。トレーニングデータセットで個別にトレーニングされた3つのモデルは、テストセットで最大99.87％の精度を達成できます。これは、最先端の結果の1つです。 
[概要]トレーニングデータセットで個別にトレーニングされた3つのモデルを使用した過半数の投票では、最大99. 87％の精度を達成できます。結果はgithubのコードを使用して再現できます。 com</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Feature Learning by Cross-Level Discrimination between
  Instances and Groups -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CV/paper_8.html">
      <font color="black">Unsupervised Feature Learning by Cross-Level Discrimination between
  Instances and Groups</font>
    </a>
  </h2>
  <font color="black">グループレベルの識別を課すことによってではなく、インスタンスとグループの間にクロスレベルの識別を課すことによって、グループ化をインスタンスレベルの識別に統合することを提案します。不変のマッピングは、拡張されたインスタンス間のローカルな引力によって達成されますが、インスタンスの類似性は長い間共通のインスタンスグループに対する範囲の反発..グループ化と識別の目的の間の衝突をさらに回避するために、共通の機能から派生した個別の機能にもそれらを課します。 
[概要]これらのデータセットは、特徴的でクラスのバランスが取れているようにキュレートされています。ただし、これらのデータインスタンスは、反発のためにキュレーションされています。これは、引力だけでなく反発からも結果をグループ化することを意味します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-09">
        <br><font color="black">2020-08-09</font>
      </time>
    </span>
</section>
<!-- paper0: Linguistic Structure Guided Context Modeling for Referring Image
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CV/paper_9.html">
      <font color="black">Linguistic Structure Guided Context Modeling for Referring Image
  Segmentation</font>
    </a>
  </h2>
  <font color="black">文のマルチモーダルコンテキストは、指示対象を背景から区別するために重要です。LSCMモジュールは、依存関係解析ツリー抑制ワードグラフ（DPT-WG）を構築します。これは、すべての単語をガイドして、文の有効なマルチモーダルコンテキストを含め、邪魔なものを除外します。マルチモーダル機能の3つのステップ、つまり、収集、制約付き伝播、および配布。この問題に取り組むために、クロスモーダル相互作用によってマルチモーダルコンテキストをモデル化し、このスキームを新しい言語として実装する「収集-伝播-配布」スキームを提案します。構造ガイドコンテキストモデリング（LSCM）モジュール。 
[概要]クロスモーダルインタラクションによってマルチモーダルコンテキストをモデル化するための「収集-伝播-配布」スキームを提案します。これには、新しい言語構造に基づくコンテキストモデリングの作成が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-01">
        <br><font color="black">2020-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: PareCO: Pareto-aware Channel Optimization for Slimmable Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CV/paper_10.html">
      <font color="black">PareCO: Pareto-aware Channel Optimization for Slimmable Neural Networks</font>
    </a>
  </h2>
  <font color="black">ただし、現在のスリミング可能なニューラルネットワークは、すべてのレイヤーに単一の幅乗数を使用して、パフォーマンスプロファイルが異なるサブネットワークに到達します。これは、レイヤーが異なるとネットワークの予測精度に異なる影響を与え、FLOP要件が異なることを無視します。 -異なる層にまたがる乗数、多目的最適化レンズからスリム化可能なネットワークを最適化する問題を定式化します。これにより、サブネットワークの共有重みと幅乗数の両方を最適化するための新しいアルゴリズムが導き出されます。スリム化可能なネットワークの重みと併せて、さまざまなレイヤーのチャネル数を最適化する可能性。 
[ABSTRACT]ネットワークネットワークネットワークユーザーは、さまざまなレイヤーを幅広く予測できる可能性があります。これは、スリム化可能なネットワークがスリム化可能なネットワークを改善するのに役立つ可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-23">
        <br><font color="black">2020-07-23</font>
      </time>
    </span>
</section>
<!-- paper0: Review: Deep Learning in Electron Microscopy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CV/paper_11.html">
      <font color="black">Review: Deep Learning in Electron Microscopy</font>
    </a>
  </h2>
  <font color="black">次に、ニューラルネットワークコンポーネント、一般的なアーキテクチャ、およびそれらの最適化を確認します。ディープラーニングは、電子顕微鏡を含む科学技術のほとんどの分野を変革しています。最後に、電子顕微鏡におけるディープラーニングの将来の方向性について説明します。 
[概要]このレビューペーパーは、知識が限られている開発者を対象とした実用的な視点を提供します。これには、電子顕微鏡などの技術の実用的な視点が含まれます。最後に、電子顕微鏡における深層学習の将来の方向性について説明します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-17">
        <br><font color="black">2020-09-17</font>
      </time>
    </span>
</section>
<!-- paper0: Auxiliary Learning by Implicit Differentiation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CV/paper_12.html">
      <font color="black">Auxiliary Learning by Implicit Differentiation</font>
    </a>
  </h2>
  <font color="black">次に、有用な補助タスクがわからない場合、意味のある新しい補助タスクを生成するネットワークを学習する方法を説明します。まず、有用な補助タスクがわかっている場合、すべての損失を単一のコヒーレント目的関数に結合するネットワークの学習を提案します。 ..画像のセグメンテーションや属性を使用した学習など、一連のタスクとドメインでAuxiLearnを評価します。 
[要約]すべての損失を単一の一貫した目的関数に結合するネットワーク。ネットワークは、意味のある、斬新な補助タスクを生成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-22">
        <br><font color="black">2020-06-22</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Scaffold the Development of Robotic Manipulation Skills -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CV/paper_13.html">
      <font color="black">Learning to Scaffold the Development of Robotic Manipulation Skills</font>
    </a>
  </h2>
  <font color="black">2つの学習ループで構成される学習システムを提案します。外側のループでは、ロボットがフィクスチャをワークスペースに配置します。これにより、知覚と運動制御、および足場操作スキルの学習から不確実性が高まります。 
[概要]このホワイトペーパーでは、ロボットが自律的に環境を変更できるようにします。これらのフィクスチャは、ロボットアクションの結果を制限する厳しい制約を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-03">
        <br><font color="black">2019-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Trainable Structure Tensors for Autonomous Baggage Threat Detection
  Under Extreme Occlusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CV/paper_14.html">
      <font color="black">Trainable Structure Tensors for Autonomous Baggage Threat Detection
  Under Extreme Occlusion</font>
    </a>
  </h2>
  <font color="black">提案されたフレームワークは、4つの公開されているX線データセットで広範囲にテストされており、平均精度スコアの点で最先端のフレームワークよりも優れています。さらに、私たちの知る限り、これは唯一のフレームワークです。これは、4つの異なるタイプのX線スキャナーから得られたグレースケールスキャンとカラースキャンの組み合わせで検証されています。このペーパーでは、トレーニング可能な構造テンサーを利用して、閉塞および乱雑なコントラバンドアイテムの輪郭を強調する新しいインスタンスセグメンテーションフレームワークを紹介します（複数のスキャンによって優勢な方向性）、同時に無関係な手荷物の内容を抑制します。 
[概要]新しい論文は、訓練可能な構造を使用して、閉塞および乱雑な密輸品の輪郭を強調するツールを示しています。これは、4種類のX線スキャナーから取得したグレースケールスキャンとカラースキャンの組み合わせで検証された唯一のフレームワークです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Theme-Matters: Fashion Compatibility Learning via Theme Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CV/paper_15.html">
      <font color="black">Theme-Matters: Fashion Compatibility Learning via Theme Attention</font>
    </a>
  </h2>
  <font color="black">これは、特定のカテゴリの互換性のある服のアイテムをサブスペースに近づけるように投影する、カテゴリ固有のサブスペース学習から始まります。）は、「デート」イベントには互換性があると見なされますが、「ビジネス」の機会には互換性がない可能性があります。 。この論文では、特定のテーマを与えられたファッションの互換性の問題を解決することを目指しています。 
[概要]これは、テーマを条件として服の互換性を推定する最初の試みです。32のテーマでラベル付けされた14kの服で構成されています。これは、ファッションのテーマとカテゴリが関連しているためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-12">
        <br><font color="black">2019-12-12</font>
      </time>
    </span>
</section>
<!-- paper0: Transductive Information Maximization For Few-Shot Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CV/paper_16.html">
      <font color="black">Transductive Information Maximization For Few-Shot Learning</font>
    </a>
  </h2>
  <font color="black">標準的な数ショットの設定に従って、包括的な実験2は、複雑なメタ学習スキームに頼ることなく、ベースクラスで単純なクロスエントロピートレーニングを使用しながら、TIMがすべてのデータセットとネットワークで最先端の方法を大幅に上回っていることを示しています。確立されたすべての数ショットのベンチマークだけでなく、ドメインシフトとクラス数の多い、より困難なシナリオでも、最高のパフォーマンスの方法よりも精度が2％から5％向上します。さらに、次の新しい交互方向ソルバーを提案します。相互情報の損失。これにより、同様の精度パフォーマンスを示しながら、勾配ベースの最適化よりも変換推論の収束が大幅に高速化されます。 
[概要]相互情報量の新しい調査方向ソルバーを提案します。これにより、トランスダクティブが大幅に高速化されます。分析精度が2％から5％向上します。常に、最高のパフォーマンスを発揮する方法よりも合計0.2％から5％向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-25">
        <br><font color="black">2020-08-25</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: A Concise Model for Multi-Criteria Chinese Word Segmentation with
  Transformer Encoder -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_0.html">
      <font color="black">A Concise Model for Multi-Criteria Chinese Word Segmentation with
  Transformer Encoder</font>
    </a>
  </h2>
  <font color="black">さらに、提案された統合モデルは、簡体字中国語と繁体字中国語の両方をセグメント化でき、優れた転送機能を備えています。異なる基準を持つ8つのデータセットでの実験は、モデルが単一基準ベースラインモデルや他の多基準モデルよりも優れていることを示しています。 Transformerエンコーダの強力な機能である提案された統合モデルは、出力基準を示す一意の基準トークンに従って中国語のテキストをセグメント化できます。 
[概要]中国の研究者は、モデルを作成するための統一モデルを提案しました。提案された統一モデルは、中国語のテキストを伸ばすことができる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-28">
        <br><font color="black">2019-06-28</font>
      </time>
    </span>
</section>
<!-- paper0: Beyond Fine-tuning: Few-Sample Sentence Embedding Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_1.html">
      <font color="black">Beyond Fine-tuning: Few-Sample Sentence Embedding Transfer</font>
    </a>
  </h2>
  <font color="black">この経験的観察を説明するために理論的分析を提供します。さらに、CCAやKCCAなどの高度な組み合わせ手法は実際には連結ほどうまく機能しないことも示します。NLPタスクからの7つの小さなデータセットで評価を実行し、私たちのアプローチがエンドツーエンドのトレーニングでは、計算のオーバーヘッドはごくわずかで、FTよりも優れています。 
[ABSTRACT]埋め込み付きの事前トレーニング済みモデルからの埋め込みは、いくつかのサンプルタスクでftのパフォーマンスを向上させることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-10">
        <br><font color="black">2020-04-10</font>
      </time>
    </span>
</section>
<!-- paper0: JDI-T: Jointly trained Duration Informed Transformer for Text-To-Speech
  without Explicit Alignment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_2.html">
      <font color="black">JDI-T: Jointly trained Duration Informed Transformer for Text-To-Speech
  without Explicit Alignment</font>
    </a>
  </h2>
  <font color="black">ESPnet-TTSによってトレーニングされたベースラインのテキスト読み上げ（TTS）モデルと比較して、公開されている韓国語のシングルスピーカースピーチ（KSS）データセットで提案されたモデルの有効性を評価します。具体的には、自動回帰から音素持続時間を抽出します。自動回帰モデルを事前トレーニングして音素持続時間抽出器として使用する代わりに、共同トレーニング中にオンザフライでトランスフォーマーを使用します。私たちの知る限り、事前トレーニングされた音素に依存せずにフィードフォワードトランスフォーマーを共同トレーニングする最初の実装です。単一のトレーニングパイプラインでの期間抽出。 
[概要]これは、単一のスピーカーで前方音素持続時間抽出器を使用せずに音響モデルを共同でトレーニングする最初の実装です。このプロジェクトは、fastspeechやsなどの持続時間情報ネットワークの最近の成功に触発されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-15">
        <br><font color="black">2020-05-15</font>
      </time>
    </span>
</section>
<!-- paper0: Finding the Optimal Vocabulary Size for Neural Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_3.html">
      <font color="black">Finding the Optimal Vocabulary Size for Neural Machine Translation</font>
    </a>
  </h2>
  <font color="black">言語のジップの性質は不均衡なクラスを引き起こすため、NMTへの影響を調査します。自己回帰設定で分類タスクとしてニューラル機械翻訳（NMT）をキャストし、分類コンポーネントと自己回帰コンポーネントの両方の制限を分析します。トレーニング中のバランスの取れたクラス分布により、パフォーマンスが向上します。 
[概要]さまざまな語彙サイズがnamtのパフォーマンスに与える影響を分析します。特定の語彙サイズが他の語彙サイズよりも優れている理由の説明を明らかにします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-05">
        <br><font color="black">2020-04-05</font>
      </time>
    </span>
</section>
<!-- paper0: A Simple and Effective Model for Answering Multi-span Questions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_4.html">
      <font color="black">A Simple and Effective Model for Answering Multi-span Questions</font>
    </a>
  </h2>
  <font color="black">私たちのモデルは、DROPとQuorefからのスパン抽出質問のパフォーマンスをそれぞれ9.9EMポイントと5.5EMポイント大幅に向上させます。当然、単一スパンを返すモデルはこれらの質問に答えることができません。ただし、答えを単一スパンにすることは制限的であり、最近のデータセットの中には、マルチスパンの質問、つまり、テキスト内の連続していないスパンのセットが回答である質問も含まれているものがあります。 
[ABSTRACT]新しいデータセットにはマルチスパンの質問も含まれます。これには、回答が非連続スパンのセットである質問が含まれます。ただし、単一のスパンを要求することを制限することができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-29">
        <br><font color="black">2019-09-29</font>
      </time>
    </span>
</section>
<!-- paper0: BAE: BERT-based Adversarial Examples for Text Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_5.html">
      <font color="black">BAE: BERT-based Adversarial Examples for Text Classification</font>
    </a>
  </h2>
  <font color="black">これらの戦略は、人間が簡単に識別できる、コンテキスト外の不自然に複雑なトークン置換につながる可能性があります。BERTマスク言語モデルからのコンテキスト摂動を使用して敵対的な例を生成するためのブラックボックス攻撃であるBAEを提示します。BAE置換とテキストの一部をマスクし、BERT-MLMを利用してマスクされたトークンの代替を生成することにより、元のテキストにトークンを挿入します。 
[概要] nlpの最近の作業では、ルールベースのサブセット置換戦略を使用して敵対的な例を生成します。これらには、バートマスク言語モデルからのコンテキスト摂動を使用して敵対的な例を生成するためのブラックボックス攻撃が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-04">
        <br><font color="black">2020-04-04</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Speaker Diarization for an Unknown Number of Speakers with
  Encoder-Decoder Based Attractors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_6.html">
      <font color="black">End-to-End Speaker Diarization for an Unknown Number of Speakers with
  Encoder-Decoder Based Attractors</font>
    </a>
  </h2>
  <font color="black">この論文は、音声埋め込みシーケンスから最初に柔軟な数のアトラクタを生成するエンコーダ-デコーダベースのアトラクタ計算（EDA）の方法を提案します。最近提案されたエンドツーエンドのスピーカーダイアリゼーションは、従来のクラスタリングベースのスピーカーダイアリゼーションよりも優れていますが、欠点が1つあります。スピーカーの数の点で柔軟性が低くなります。音声埋め込みシーケンスは、従来の自己注意型エンドツーエンドニューラルスピーカーダイアリゼーション（SA-EEND）ネットワークを使用して抽出されます。 
[ABSTRACT]この方法は、話者の数に関して柔軟性が低くなります。これにより、同じ数の話者アクティビティを作成するために、いくつかの埋め込みシーケンスが作成されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br><font color="black">2020-05-20</font>
      </time>
    </span>
</section>
<!-- paper0: TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and
  Adversarial Training in NLP -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_7.html">
      <font color="black">TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and
  Adversarial Training in NLP</font>
    </a>
  </h2>
  <font color="black">TextAttackは、目標関数、一連の制約、変換、検索方法の4つのコンポーネントから攻撃を構築します。このペーパーでは、NLPでの敵対攻撃、データ拡張、および敵対的トレーニングのためのPythonフレームワークであるTextAttackを紹介します。TextAttackは実装を提供します文献からの16の敵対的攻撃のうち、BERTやその他のトランスフォーマー、およびすべてのGLUEタスクを含むさまざまなモデルとデータセットをサポートします。 
[ABSTRACT] textattackは、ゴール関数、一連の制約、変換、および検索方法の4つのコンポーネントから攻撃を構築します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br><font color="black">2020-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding tables with intermediate pre-training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_8.html">
      <font color="black">Understanding tables with intermediate pre-training</font>
    </a>
  </h2>
  <font color="black">長い例をBERTモデルの入力として使用できるようにするために、前処理ステップとしてテーブルプルーニング手法を評価し、精度を適度に低下させてトレーニングと予測の効率を大幅に向上させます。さまざまな方法により、新しい状態が設定されます。 TabFact（Chen et al。、2020）およびSQAデータセットに関する最新技術..テーブルの内容によって文がサポートまたは反論されているかどうかを見つけるバイナリ分類タスクであるテーブル含意には、言語とテーブル構造の解析も必要です。数値的および離散的な推論として。 
[ABSTRACT]テーブルの含意はあまりよく研究されていない、とadam scottによると、彼は何百万もの例のバランスの取れたデータセットを作成すると言います。トレーニングと予測の効率を改善するためにテーブルの剪定技術が必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-01">
        <br><font color="black">2020-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: KorNLI and KorSTS: New Benchmark Datasets for Korean Natural Language
  Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_9.html">
      <font color="black">KorNLI and KorSTS: New Benchmark Datasets for Korean Natural Language
  Understanding</font>
    </a>
  </h2>
  <font color="black">韓国語のNLUの研究を加速するために、KorNLIとKorSTSのベースラインも確立しています。データセットはhttps://github.com/kakaobrain/KorNLUDatasetsで公開されています。以前のアプローチに従って、既存の英語のトレーニングセットを手動で機械翻訳します。開発セットとテストセットを韓国語に翻訳します。 
[概要]ベンチマークデータセットは英語と他のいくつかの言語でリリースされています。韓国語で公開されているnliおよびissデータセットは公開されていません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br><font color="black">2020-04-07</font>
      </time>
    </span>
</section>
<!-- paper0: AmbigQA: Answering Ambiguous Open-domain Questions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_10.html">
      <font color="black">AmbigQA: Answering Ambiguous Open-domain Questions</font>
    </a>
  </h2>
  <font color="black">また、AmbigQAの強力なベースラインモデルを提示します。これは、NQ-openを組み込んだ弱教師あり学習のメリットを示しており、新しいタスクとデータが将来の重要な研究努力をサポートすることを強く示唆しています。NQ-openの質問の半分以上があいまいで、イベントやエンティティの参照など、あいまいさのさまざまな原因があります。あいまいさは、オープンドメインの質問回答に固有のものです。特に新しいトピックを探索する場合、単一の明確な答えを持つ質問をするのは難しい場合があります。 
[ABSTRACT] ambigqaは、新しいオープンドメインの質問回答タスクです。すべてのもっともらしい回答を見つけて、それぞれの質問を書き直す必要があります。このタスクでは、質問を置き換えて不確実性を解決します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-22">
        <br><font color="black">2020-04-22</font>
      </time>
    </span>
</section>
<!-- paper0: An Information Bottleneck Approach for Controlling Conciseness in
  Rationale Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_11.html">
      <font color="black">An Information Bottleneck Approach for Controlling Conciseness in
  Rationale Extraction</font>
    </a>
  </h2>
  <font color="black">理論的根拠は、タスクのパフォーマンスを大幅に低下させることなく、可能な限り簡潔にする必要がありますが、このバランスを実際に達成するのは難しい場合があります。複雑な言語理解モデルの決定は、入力を元のテキストの関連するサブシーケンスに制限することで合理化できます。実験ERASERベンチマークタスクでは、タスクのパフォーマンスと人間の論理的根拠との一致の両方について、標準最小化手法よりも大幅に向上していることが示されています。 
[要約]私たちの完全な教師なしアプローチは、文の密なバイナリマスクを予測する説明者を共同で学習します。終了-抽出された理論的根拠のみを決定するタスク予測子</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: Sparse Text Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_12.html">
      <font color="black">Sparse Text Generation</font>
    </a>
  </h2>
  <font color="black">ストーリーの完成と会話の生成における人間が評価した実験は、entmaxサンプリングが、より魅力的で一貫性のあるストーリーと会話につながることを示しています。これにより、トレーニング条件とテスト条件の間に不一致が生じます。その結果、流暢さと一貫性、繰り返しの減少、および人間のテキストに近いn-gramの多様性。 
[概要]モデルを評価するために、3つの新しいメトリックを提案します。縮退したテキストを回避するには、変更されたソフトマックスからのサンプリングが必要です。これには、温度パラメータまたはentmaxリードの使用が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: Leveraging Declarative Knowledge in Text and First-Order Logic for
  Fine-Grained Propaganda Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_13.html">
      <font color="black">Leveraging Declarative Knowledge in Text and First-Order Logic for
  Fine-Grained Propaganda Detection</font>
    </a>
  </h2>
  <font color="black">後者は、モデルパラメータを正規化するためのクラス表現を取得するために使用される各プロパガンダ手法の文字通りの定義を指します。実験は、宣言的知識を活用することでモデルがより正確な予測を行うのに役立つことを示し、優れたパフォーマンスを達成することを示しています。 。プロパガンダ手法コーパスで実験を行います。これは、きめ細かいプロパガンダ検出のための手動で注釈が付けられた大規模なデータセットです。 
[概要]きめ細かいプロパガンダ手法の宣言的知識を使用して、命題ブール式を使用してトレーニングプロセスを正規化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br><font color="black">2020-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: BERTweet: A pre-trained language model for English Tweets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_14.html">
      <font color="black">BERTweet: A pre-trained language model for English Tweets</font>
    </a>
  </h2>
  <font color="black">実験によると、BERTweetは強力なベースラインであるRoBERTaベースおよびXLM-Rベースよりも優れており（Conneau et al。、2020）、3つのツイートNLPタスクで以前の最先端モデルよりも優れたパフォーマンス結果を生み出しています。品詞タグ付け、固有表現抽出、テキスト分類..ツイートデータの将来の研究とアプリケーションを容易にするために、MITライセンスの下でBERTweetをリリースします..BERTベースと同じアーキテクチャを持つBERTweet（Devlin et al。、2019）、 RoBERTa事前トレーニング手順を使用してトレーニングされます（Liu et al。、2019）。 
[概要]将来の研究を容易にするために、mitライセンスの下でbertweetをリリースします。ツイートライセンスの下でモデルをリリースします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br><font color="black">2020-05-20</font>
      </time>
    </span>
</section>
<!-- paper0: A Survey of Evaluation Metrics Used for NLG Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_15.html">
      <font color="black">A Survey of Evaluation Metrics Used for NLG Systems</font>
    </a>
  </h2>
  <font color="black">NLGモデルの数の増加と現在のメトリックの欠点により、2014年以降に提案された評価メトリックの数が急増しています。また、さまざまなメトリックについて詳しく説明し、それらの主な貢献を強調します。最後に、自動評価指標を改善するための次のステップに関する提案と推奨事項。 
[概要]ディープラーニングは、いくつかの既存のnlgタスクで最先端技術を推進しましたが、研究者は画像キャプションなどの新しいnlgタスクを探索することもできました。これにより、2014年以降に提案された評価指標の数が急増しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Named Entity Recognition Only from Word Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_16.html">
      <font color="black">Named Entity Recognition Only from Word Embeddings</font>
    </a>
  </h2>
  <font color="black">まず、エンティティスパン検出とタイプ予測のための単語埋め込みにガウス隠れマルコフモデルとディープオートエンコーディングガウス混合モデルを適用し、次に強化学習に基づいてインスタンスセレクターを設計して、ポジティブセンテンスとノイズの多いセンテンスを区別し、これらの粗いアノテーションをニューラルネットワーク..人間の注釈を外部の知識（NE辞書、スピーチの一部のタグなど）に置き換える努力がなされてきましたが、そのような効果的なリソースを取得することは別の課題です.. CoNLLベンチマークデータセットでの広範な実験は、提案されたライトNE認識モデルは、注釈付きのレキシコンやコーパスを使用せずに、優れたパフォーマンスを実現します。 
[概要]人間のデータを検出するために必要な人間の注釈付きトレーニングデータ。人間のne認識モデルは、事前にトレーニングされた単語の埋め込みから情報を取得するだけで済みます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-31">
        <br><font color="black">2019-08-31</font>
      </time>
    </span>
</section>
<!-- paper0: Zero-Shot Cross-Lingual Transfer with Meta Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_17.html">
      <font color="black">Zero-Shot Cross-Lingual Transfer with Meta Learning</font>
    </a>
  </h2>
  <font color="black">さまざまな自然言語理解タスク（自然言語推論、質問応答）に対して、標準の教師ありゼロショットクロスリンガル設定と数ショットクロスリンガル設定を使用して実験します。広範な実験セットアップは、メタの一貫した有効性を示しています。合計15の言語で学習します。知識の戦略的共有が下流のタスクのパフォーマンスを向上させることが示されているため、タスク間で何を共有するかを学ぶことは最近非常に重要なトピックです。 
[概要]これは多言語アプリケーションにとって特に重要です。世界中のほとんどの言語がリソース不足であるためです。ここでは、メタ学習を使用してこのチャレンジセットアップにアプローチできることを示します。ここでは、ソース言語モデルのトレーニングに加えて、別のモデルを使用します。どのトレーニングインスタンスが最初の人にとって最も有益であるかを選択することを学びます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-05">
        <br><font color="black">2020-03-05</font>
      </time>
    </span>
</section>
<!-- paper0: Identifying Necessary Elements for BERT's Multilinguality -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_18.html">
      <font color="black">Identifying Necessary Elements for BERT's Multilinguality</font>
    </a>
  </h2>
  <font color="black">私たちの洞察に基づいて、VecMapを使用してマスキング戦略を変更する多言語事前トレーニングセットアップ、つまり教師なし埋め込みアライメントを実験します。多言語BERT（mBERT）は、高品質の多言語表現を生成し、効果的なゼロショット転送を可能にすることが示されています。 。全体として、多言語性に影響を与える4つのアーキテクチャ要素と2つの言語要素を特定します。 
[ABSTRACT]クロスリンガルシグナルなしで、私たちはバートの建築的特性と多言語に必要な言語の言語的特性を特定することを目指しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: SubjQA: A Dataset for Subjectivity and Review Comprehension -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_19.html">
      <font color="black">SubjQA: A Dataset for Subjectivity and Review Comprehension</font>
    </a>
  </h2>
  <font color="black">以前の作業の分析と比較対照し、最近開発されたNLPアーキテクチャを使用した場合でも、主観に関する調査結果が保持されることを確認します。たとえば、主観的な質問は主観的な回答に関連付けられる場合と関連付けられない場合があります。主観性は内部の表現です客観的に観察または検証することができず、感情分析および単語感覚の曖昧さの解消に重要であることが示されている意見または信念。 
[概要]顧客のレビューに基づいて、主観性の注釈を含む英語のqaデータセット（subjqa）をリリースします。主観性とqaの間の相互作用はより複雑ですが、主観性もqaの場合の重要な機能です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br><font color="black">2020-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: WeChat Neural Machine Translation Systems for WMT20 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_20.html">
      <font color="black">WeChat Neural Machine Translation Systems for WMT20</font>
    </a>
  </h2>
  <font color="black">私たちのシステムは、効果的なバリアントとDTMT（Meng and Zhang、2019）アーキテクチャを備えたTransformer（Vaswani et al。、2017a）に基づいています。制約付きの中国語から英語へのシステムは、36.9の大文字と小文字を区別するBLEUスコアを達成します。すべての提出物..私たちの実験では、データ選択、いくつかの合成データ生成アプローチ（つまり、逆翻訳、知識蒸留、および反復的なドメイン内知識転送）、高度な微調整アプローチ、および自己ブリューベースのモデルアンサンブルを採用しています。 
[概要]私たちのシステムは変圧器に基づいており、dtmt.ourの制約付き中国語から英語へのシステムは36.9、細かいブルースコアを達成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-01">
        <br><font color="black">2020-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: TaxiNLI: Taking a Ride up the NLU Hill -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_21.html">
      <font color="black">TaxiNLI: Taking a Ride up the NLU Hill</font>
    </a>
  </h2>
  <font color="black">TAXINLIでのさまざまな実験を通じて、特定の分類学的カテゴリでは、SOTAニューラルモデルがほぼ完全な精度を達成しているのに対し（以前のモデルを大幅に上回っています）、一部のカテゴリは依然として困難であることがわかります。推論カテゴリの体系的な提示と分析による現在のNLIシステムとデータセットのギャップ..事前にトレーニングされたTransformerベースのニューラルアーキテクチャは、Natural Language Inference（NLI）タスクで常に最先端のパフォーマンスを達成しています。 
[概要] mnliデータセットからの10kの例を含む新しいデータセットであるtaxinliを紹介します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-30">
        <br><font color="black">2020-09-30</font>
      </time>
    </span>
</section>
<!-- paper0: Making Monolingual Sentence Embeddings Multilingual using Knowledge
  Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_22.html">
      <font color="black">Making Monolingual Sentence Embeddings Multilingual using Knowledge
  Distillation</font>
    </a>
  </h2>
  <font color="black">多言語文の埋め込みをトレーニングする他の方法と比較して、このアプローチにはいくつかの利点があります。サンプルが比較的少ない既存のモデルを新しい言語に拡張するのが簡単で、ベクトル空間に必要なプロパティを確保するのが簡単です。トレーニングのハードウェア要件は次のとおりです。より低い..文埋め込みモデルを400以上の言語に拡張するコードが公開されています。さまざまな言語ファミリーの50以上の言語に対するアプローチの有効性を示しています。 
[概要]元のモデルを使用してソース言語の文の埋め込みを生成します。次に、元のモデルを模倣するように翻訳された文で新しいシステムをトレーニングします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br><font color="black">2020-04-21</font>
      </time>
    </span>
</section>
<!-- paper0: Linguistic Structure Guided Context Modeling for Referring Image
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_23.html">
      <font color="black">Linguistic Structure Guided Context Modeling for Referring Image
  Segmentation</font>
    </a>
  </h2>
  <font color="black">文のマルチモーダルコンテキストは、指示対象を背景から区別するために重要です。既存のメソッドは、マルチモーダルコンテキストを十分にまたは冗長にモデル化します。LSCMモジュールは、すべての単語をセンテンスの有効なマルチモーダルコンテキストを含め、マルチモーダル機能の3つのステップ、つまり、収集、制約付き伝播、および配布を通じて、邪魔なものを除外します。 
[概要]クロスモーダルインタラクションによってマルチモーダルコンテキストをモデル化するための「収集-伝播-配布」スキームを提案します。これには、新しい言語構造に基づくコンテキストモデリングの作成が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-01">
        <br><font color="black">2020-10-01</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-model Back-translated Distillation for Unsupervised Machine
  Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_24.html">
      <font color="black">Cross-model Back-translated Distillation for Unsupervised Machine
  Translation</font>
    </a>
  </h2>
  <font color="black">特に、WMT&#39;14英語-フランス語、WMT&#39;16ドイツ語-英語、英語-ルーマニア語では、CBDはクロスリンガルマスク言語モデル（XLM）をそれぞれ2.3、2.2、1.6BLEU上回っています。 3.3 IWSLT英語-フランス語および英語-ドイツ語タスクにおけるBLEUの改善..広範な実験的分析を通じて、CBDはデータの多様性を取り入れているが、他の同様のバリアントは取り入れていないため、効果的であることを示しています。 
[概要]クロスモデルバックトランスレーテッド蒸留（cbd）は、標準のumtシステムの新しいコンポーネントです。マシンのパフォーマンスを1.5〜2.0 bleu向上させます。また、iwsltで1.5〜3〜3ブルーの改善をもたらします。英語-フランス語と英語-ドイツ語のタスク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-03">
        <br><font color="black">2020-06-03</font>
      </time>
    </span>
</section>
<!-- paper0: Fixed Encoder Self-Attention Patterns in Transformer-Based Machine
  Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_25.html">
      <font color="black">Fixed Encoder Self-Attention Patterns in Transformer-Based Machine
  Translation</font>
    </a>
  </h2>
  <font color="black">さまざまなデータサイズと複数の言語ペアを使用した実験では、トレーニング時にTransformerのエンコーダ側にアテンションヘッドを固定しても、翻訳品質に影響がなく、リソースが少ないシナリオではBLEUスコアが最大3ポイント増加することが示されています。 、最近の研究では、ほとんどの注意の頭が単純で、しばしば冗長な位置パターンを学習することが示されています。トランスフォーマーベースのモデルは、ニューラルマシンの変換に根本的な変化をもたらしました。 
[ABSTRACT]トランスフォーマーアーキテクチャは、注意メカニズムを使用して、エンコーダーのさまざまな部分に焦点を合わせます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-24">
        <br><font color="black">2020-02-24</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Persona-Based Empathetic Conversational Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_26.html">
      <font color="black">Towards Persona-Based Empathetic Conversational Models</font>
    </a>
  </h2>
  <font color="black">最後に、ペルソナが共感的反応に与える影響を調査するために広範な実験を行います。具体的には、まず、ペルソナベースの共感的会話のための新しい大規模マルチドメインデータセットを提示します。次に、効率的なBERTベースの反応であるCoBERTを提案します。データセットで最先端のパフォーマンスを取得する選択モデル。 
[概要]心理学では、ペルソナは性格と高い相関関係があることが示され、それが共感に影響を与えます。さらに、ペルソナベースの共感的な会話に向けた新しいタスクを提案します。これは、共感に対するペルソナの影響に関する最初の研究です。応答する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-26">
        <br><font color="black">2020-04-26</font>
      </time>
    </span>
</section>
<!-- paper0: AdapterHub: A Framework for Adapting Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_27.html">
      <font color="black">AdapterHub: A Framework for Adapting Transformers</font>
    </a>
  </h2>
  <font color="black">アダプターのダウンロード、共有、およびトレーニングは、トレーニングスクリプトと特殊なインフラストラクチャへの最小限の変更を使用して、可能な限りシームレスに行われます。AdapterHubには、最近のすべてのアダプターアーキテクチャが含まれており、https：//AdapterHub.mlにあります。AdapterHubを提案します。さまざまなタスクや言語用に事前にトレーニングされたアダプターの動的な「ステッチイン」を可能にするフレームワーク。 
[概要]フレームワークは、人気のあるハグフェイストランスフォーマーライブラリの上に構築されています。これにより、最先端のモデルを簡単かつ迅速に適応させることができます。これらには、bert、roberta、xlmなどの最先端のモデルが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-15">
        <br><font color="black">2020-07-15</font>
      </time>
    </span>
</section>
<!-- paper0: Byte Pair Encoding is Suboptimal for Language Model Pretraining -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_28.html">
      <font color="black">Byte Pair Encoding is Suboptimal for Language Model Pretraining</font>
    </a>
  </h2>
  <font color="black">BPEとユニグラムLMトークン化の違いを分析し、後者の方法では、形態とより密接に一致するサブワードユニットが復元され、BPEの貪欲な構築手順に起因する問題が回避されることがわかりました。ただし、私たちの知る限り、文献には言語モデルの事前トレーニングに対するトークン化の影響の直接評価..将来の事前トレーニング済みLMの開発者が、より普及しているBPEよりもユニグラムLMメソッドの採用を検討することを期待します。 
[概要]これらのモデルは、さまざまなサブワードトークン化メソッドを採用しています。これらには、ワードピースメソッドとユニグラム言語モデリングが含まれます。ユニグラムlmトークン化メソッドは、bpeと一致するか、それよりも優れていることがわかります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br><font color="black">2020-04-07</font>
      </time>
    </span>
</section>
<!-- paper0: Robustness to Modification with Shared Words in Paraphrase
  Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_29.html">
      <font color="black">Robustness to Modification with Shared Words in Paraphrase
  Identification</font>
    </a>
  </h2>
  <font color="black">修正ソリューションを見つけるために、ヒューリスティックルールによって制約されたビーム検索を使用し、BERTマスク言語モデルを利用して、コンテキストと互換性のある置換単語を生成します。実験によると、ターゲットモデルのパフォーマンスは修正された例で劇的に低下します。 、それによってロバスト性の問題が明らかになります。ターゲットモデルが誤った予測を行うような有効な新しい例を構築することを目指しています。 
[概要]ターゲットモデルが誤った予測を行うような有効な新しい例を構築することを目指しています。実験では、ターゲットモデルのパフォーマンスが変更された例で劇的に低下していることが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-05">
        <br><font color="black">2019-09-05</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal Routing: Improving Local and Global Interpretability of
  Multimodal Language Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_30.html">
      <font color="black">Multimodal Routing: Improving Local and Global Interpretability of
  Multimodal Language Analysis</font>
    </a>
  </h2>
  <font color="black">マルチモーダルルーティングは、個々のモダリティとクロスモダリティ機能の両方の相対的な重要性を識別できます。人間の言語は、声のトーン、顔のジェスチャー、話し言葉など、モダリティと呼ばれる複数の情報ソースを通じて表現できます。さらに、重みの割り当てルーティングにより、モダリティと予測の関係をグローバルに解釈できるだけでなく（つまり、
[ABSTRACT]人間中心のタスクはブラックボックスであることが多く、解釈可能性が非常に限られています。マルチモーダルルーティングでは、個々のモダリティとクロスモダリティ機能の両方の相対的な重要性を識別できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br><font color="black">2020-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: TD-GIN: Token-level Dynamic Graph-Interactive Network for Joint Multiple
  Intent Detection and Slot Filling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_31.html">
      <font color="black">TD-GIN: Token-level Dynamic Graph-Interactive Network for Joint Multiple
  Intent Detection and Slot Filling</font>
    </a>
  </h2>
  <font color="black">3つのマルチインテントデータセットの実験結果は、私たちのフレームワークが大幅な改善を達成し、最先端のパフォーマンスを達成することを示しています。この論文では、ジョイントマルチインテント検出とスロットのための適応グラフインタラクティブフレームワーク（AGIF）を提案します。充填では、インテント-スロットグラフ相互作用レイヤーを導入して、スロットとインテント間の強い相関関係をモデル化します。さらに、フレームワークは、2つの単一インテントデータセットで新しい最先端のパフォーマンスを実現します。 
[概要]ほとんどの話し言葉理解（slu）モデルは、主に単一のインテント状態に焦点を当てています-または単にすべてのトークンの全体的なインテントコンテキストツールを組み込んでいます。さらに、私たちのフレームワークは、2つの単一のインテントデータセットで新しい最先端のパフォーマンスを実現します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br><font color="black">2020-04-21</font>
      </time>
    </span>
</section>
<!-- paper0: MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_32.html">
      <font color="black">MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer</font>
    </a>
  </h2>
  <font color="black">MAD-Xは、固有表現抽出と因果的常識推論において、類型的に多様な言語の代表的なセット間での言語間転送において最先端技術を上回り、質問応答で競争力のある結果を達成します。さらに、新しい可逆アダプターアーキテクチャを紹介します。事前にトレーニングされた多言語モデルを新しい言語に適応させるための強力なベースライン方法。多言語BERTやXLM-Rなどの最先端の事前トレーニングされた多言語モデルの背後にある主な目標は、NLPアプリケーションを有効にしてブートストラップすることです。ゼロショットまたは数ショットのクロスリンガル転送による低リソース言語。 
[概要]転送パフォーマンスは、このような低リソース言語で正確に最も弱くなります。これらには、低リソース言語と事前トレーニング中に見えない言語が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: PhoBERT: Pre-trained language models for Vietnamese -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_33.html">
      <font color="black">PhoBERT: Pre-trained language models for Vietnamese</font>
    </a>
  </h2>
  <font color="black">PhoBERTモデルはhttps://github.com/VinAIResearch/PhoBERTで入手できます。ベトナムのNLPの将来の研究とダウンストリームアプリケーションを容易にするためにPhoBERTをリリースします。実験結果は、PhoBERTが最近の最高の事前トレーニング済み多言語モデルXLM-R（Conneau et al。、2020）を一貫して上回り、状態を改善することを示しています音声部分のタグ付け、依存関係の解析、固有表現抽出、自然言語推論など、ベトナム固有の複数のNLPタスクにおけるアート。 
[概要] phobertは、最近の最高の事前トレーニング済み多言語モデルxlm --rを一貫して上回っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-02">
        <br><font color="black">2020-03-02</font>
      </time>
    </span>
</section>
<!-- paper0: Reevaluating Adversarial Examples in Natural Language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/cs.CL/paper_34.html">
      <font color="black">Reevaluating Adversarial Examples in Natural Language</font>
    </a>
  </h2>
  <font color="black">人間の調査によると、セマンティクスを正常に保持するには、スワップされた単語の埋め込み間、および元のセンテンスと摂動されたセンテンスのセンテンスエンコーディング間の最小コサイン類似度を大幅に増やす必要があります。制約を調整してセマンティクスと文法性をより適切に保持すると、攻撃の成功率が低下します。 70パーセントポイント以上..それらの摂動はしばしばセマンティクスを保存せず、38％は文法エラーを導入します。次に、2つの最先端の同義語置換攻撃の出力を分析します。 
[要約]成功した自然言語の敵対的な例は、モデルをだまし、いくつかの言語的制約に従う摂動です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-25">
        <br><font color="black">2020-04-25</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: D3Net: Densely connected multidilated DenseNet for music source
  separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.AS/paper_0.html">
      <font color="black">D3Net: Densely connected multidilated DenseNet for music source
  separation</font>
    </a>
  </h2>
  <font color="black">MUSDB18データセットの実験結果は、D3Netが6.01 dBの平均信号対歪み比（SDR）で最先端のパフォーマンスを達成することを示しています。音源分離には、オーディオの長期依存性をモデル化するための大きな入力フィールドが含まれます。信号..マルチ拡張コンボリューションをDenseNetアーキテクチャと組み合わせることにより、D3Netは、拡張コンボリューションをDenseNetに単純に組み込むときに存在するエイリアスの問題を回避します。 
[概要]新しい畳み込み畳み込みには、異なる解像度を同時にモデル化するために、単一レイヤーに異なる拡張拡張拡張畳み込み係数がある新しいマルチステート畳み込みが含まれます。新しい畳み込み畳み込みは、畳み込み畳み込みへの新しいアプローチです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: CTC-Segmentation of Large Corpora for German End-to-end Speech
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.AS/paper_1.html">
      <font color="black">CTC-Segmentation of Large Corpora for German End-to-end Speech
  Recognition</font>
    </a>
  </h2>
  <font color="black">データ準備のために、Connectionist Temporal Classification（CTC）で事前トレーニングされたASRモデルを使用して、セグメント化されていない、またはラベル付けされていないトレーニングデータからより多くのトレーニングデータをブートストラップする2段階のアプローチを提案します。このトレーニングデータを使用して、ハイブリッドをトレーニングしました。 Tuda-DEテストセットで$ 12.8 \％$ WERを達成するCTC / Attention Transformerモデルは、従来のハイブリッドDNN / HMMASRの以前のベースラインである$ 14.4 \％$を上回ります。ただし、これらのモデルでは、同等のトレーニングデータを達成するためにさらに多くのトレーニングデータが必要です。パフォーマンス。 
[概要]まだラベル付けされていない音声データを含むドイツ語の音声認識用のコーパスを、1700ドル以上の大きなデータセットに結合します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-17">
        <br><font color="black">2020-07-17</font>
      </time>
    </span>
</section>
<!-- paper0: JDI-T: Jointly trained Duration Informed Transformer for Text-To-Speech
  without Explicit Alignment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.AS/paper_2.html">
      <font color="black">JDI-T: Jointly trained Duration Informed Transformer for Text-To-Speech
  without Explicit Alignment</font>
    </a>
  </h2>
  <font color="black">具体的には、自己回帰モデルを事前トレーニングして音素持続時間抽出器として使用する代わりに、共同トレーニング中にその場で自己回帰トランスフォーマーから音素持続時間を抽出します。公開されている韓国のシングルスピーカー音声で提案されたモデルの有効性を評価します。 （KSS）データセットとESPnet-TTSによってトレーニングされたベースラインのテキスト読み上げ（TTS）モデルとの比較。私たちの知る限り、これは事前にトレーニングされた音素に依存せずにフィードフォワードトランスフォーマーを共同でトレーニングする最初の実装です。単一のトレーニングパイプラインでの期間抽出。 
[概要]これは、単一のスピーカーで前方音素持続時間抽出器を使用せずに音響モデルを共同でトレーニングする最初の実装です。このプロジェクトは、fastspeechやsなどの持続時間情報ネットワークの最近の成功に触発されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-15">
        <br><font color="black">2020-05-15</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Adversarial Text-to-Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.AS/paper_3.html">
      <font color="black">End-to-End Adversarial Text-to-Speech</font>
    </a>
  </h2>
  <font color="black">モデルが生成されたオーディオの時間的変化をキャプチャできるようにするために、スペクトログラムベースの予測損失にソフトダイナミックタイムワーピングを採用しています。結果のモデルは、状態に匹敵する5ポイントスケールで4を超える平均オピニオン評点を達成します。マルチステージトレーニングと追加の監視に依存する最先端のモデル..敵対的なフィードバックと予測損失の組み合わせにより、生成されたオーディオをその合計時間の点でグラウンドトゥルースとほぼ一致するように制約することにより、忠実度の高いオーディオを生成することを学習しますとメルスペクトログラム。 
[ABSTRACT]モデルは、敵対的なフィードバックと予測損失の組み合わせから生の音声を生成します。結果のモデルは、5ポイントスケールで4を超える平均オピニオン評点を達成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-05">
        <br><font color="black">2020-06-05</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Speaker Diarization for an Unknown Number of Speakers with
  Encoder-Decoder Based Attractors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.AS/paper_4.html">
      <font color="black">End-to-End Speaker Diarization for an Unknown Number of Speakers with
  Encoder-Decoder Based Attractors</font>
    </a>
  </h2>
  <font color="black">この論文は、最初に音声埋め込みシーケンスから柔軟な数のアトラクタを生成するエンコーダ-デコーダベースのアトラクタ計算（EDA）の方法を提案します。未知の数の話者条件で、私たちの方法はCALLHOMEで15.29％DERを達成しました。 xベクトルベースのクラスタリング手法は19.43％DERを達成しました。音声埋め込みシーケンスは、従来の自己注意型エンドツーエンドニューラルスピーカーダイアリゼーション（SA-EEND）ネットワークを使用して抽出されます。 
[ABSTRACT]この方法は、話者の数に関して柔軟性が低くなります。これにより、同じ数の話者アクティビティを作成するために、いくつかの埋め込みシーケンスが作成されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br><font color="black">2020-05-20</font>
      </time>
    </span>
</section>
<!-- paper0: Auxiliary Function-Based Algorithm for Blind Extraction of a Moving
  Speaker -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.AS/paper_5.html">
      <font color="black">Auxiliary Function-Based Algorithm for Blind Extraction of a Moving
  Speaker</font>
    </a>
  </h2>
  <font color="black">これらは、CHiME-4音声分離および認識チャレンジ内でも検証されます。実験は、CSVの適用性と、提案されたアルゴリズムの収束の改善を裏付けています。メソッドは、モデルベースおよび実際のを使用して、残響およびノイズの多い条件下で検証されます。 -世界の音響インパルス応答。 
[概要]新しい方法は、モデルベースおよび実世界の音響インパルス応答を使用して、残響およびノイズの多い条件下で検証されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-28">
        <br><font color="black">2020-02-28</font>
      </time>
    </span>
</section>
<!-- paper0: TD-GIN: Token-level Dynamic Graph-Interactive Network for Joint Multiple
  Intent Detection and Slot Filling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.AS/paper_6.html">
      <font color="black">TD-GIN: Token-level Dynamic Graph-Interactive Network for Joint Multiple
  Intent Detection and Slot Filling</font>
    </a>
  </h2>
  <font color="black">このようなインタラクションレイヤーは各トークンに適応的に適用され、関連するインテント情報を自動的に抽出して、トークンレベルのスロット予測のためのきめ細かいインテント情報の統合を行うという利点があります。さらに、フレームワークは新しい状態を実現します。 -2つのシングルインテントデータセットでの最先端のパフォーマンス。3つのマルチインテントデータセットでの実験結果は、フレームワークが大幅に改善され、最先端のパフォーマンスを達成していることを示しています。 
[概要]ほとんどの話し言葉理解（slu）モデルは、主に単一のインテント状態に焦点を当てています-または単にすべてのトークンの全体的なインテントコンテキストツールを組み込んでいます。さらに、私たちのフレームワークは、2つの単一のインテントデータセットで新しい最先端のパフォーマンスを実現します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br><font color="black">2020-04-21</font>
      </time>
    </span>
</section>
<!-- paper0: High-resolution Piano Transcription with Pedals by Regressing Onsets and
  Offsets Times -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.AS/paper_7.html">
      <font color="black">High-resolution Piano Transcription with Pedals by Regressing Onsets and
  Offsets Times</font>
    </a>
  </h2>
  <font color="black">私たちのシステムは、91.86％のペダル開始F1スコアを達成し、MAESTROデータセットの最初のベンチマーク結果です。高解像度の評価については、これまでの研究では、異なる開始とオフセットの許容範囲で評価されたAMTシステムを調査していません。ノートとペダルの両方の転写を備えたAMTシステムの構築に関する研究は不足しています。 
[概要]この記事では、開始とオフセットの正確な時間を回帰することによってトレーニングされた高解像度のamtシステムを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: JSSS: free Japanese speech corpus for summarization and simplification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-10-06/eess.AS/paper_8.html">
      <font color="black">JSSS: free Japanese speech corpus for summarization and simplification</font>
    </a>
  </h2>
  <font color="black">この論文では、プロジェクトページで入手できるコーパスの設計方法について説明します。また、オプションのタスクとして長い形式の文の発話も含まれています。短い形式の文からの読み上げスタイルの音声合成の成功を踏まえて、私たちは目指しています人間に情報を提供するためのより難しいタスクを設計する。 
[概要] `コーパス &#39;には、短い形式の文からの情報が含まれています。また、人間に配信できる情報も含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
