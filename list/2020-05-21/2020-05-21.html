<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-05-21の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Evaluating Features and Metrics for High-Quality Simulation of Early
  Vocal Learning of Vowels -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.SD/paper_0.html">
      Evaluating Features and Metrics for High-Quality Simulation of Early
  Vocal Learning of Vowels
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この目的に向けて、フォルマントエラーの有用性と、正規化されたF1-F2フォルマント空間でのフィーチャーメトリックエラーサーフェスの投影を評価します。このアプローチを使用して、フィーチャーとメトリックの影響を評価し、さらに知覚結果への洞察。これらのシミュレーションの重要なパラメーターの1つは、機能の選択と、合成音と参照ターゲット間の音響誤差を評価するための測定基準です。 
[ABSTRACT]調音音声合成を使用した初期の音声学習のシミュレーションは、このプロセスをより深く理解する方法を提供します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Early Stage LM Integration Using Local and Global Log-Linear Combination -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.SD/paper_1.html">
      Early Stage LM Integration Using Local and Global Log-Linear Combination
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      対照的に、注意モデルには複数の統合スキームが提案されています。暗黙のアライメントメカニズムを備えたシーケンス間モデル（例：これにより、トレーニングとテストの両方で完全な正規化項を効率的に計算できます。
[ABSTRACT]新しいシステム従来のハイブリッド隠れマルコフモデルとのパフォーマンスのギャップを縮めています。提案された方法は、標準モデルの組み合わせよりも優れた改善を示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploring Recurrent, Memory and Attention Based Architectures for
  Scoring Interactional Aspects of Human-Machine Text Dialog -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.SD/paper_2.html">
      Exploring Recurrent, Memory and Attention Based Architectures for
  Scoring Interactional Aspects of Human-Machine Text Dialog
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      複数のアーキテクチャの融合は、エキスパートの評価者間合意に関連する自動スコアリングタスクで適切に機能し、（i）サポートベクター学習者に渡されたハンドエンジニアリング機能、および（ii）トランスフォーメーションベースのアーキテクチャが最も顕著に融合に貢献していることがわかります..クラウドベースのダイアログシステムと対話する人間の学習者からのテキストダイアログの会話データベースで実験を行いました。これは、会話能力の複数の側面に沿ってトリプルスコアされました。英語の学習者が会話のスピーキングを改善できるようにするための重要なステップ習熟度には、相互作用能力の複数の側面の自動スコアリングとその後の対象を絞ったフィードバックが含まれます。 
[ABSTRACT]複数のニューラルアーキテクチャの融合は、自動化されたスコアリングタスクで（ii）ベースのアーキテクチャが優れて融合に貢献します。新しい論文は、複数のニューラルアーキテクチャの再帰的な注目を調査するための以前の研究に基づいていますおよびメモリベース-テキストダイアログデータの機能設計されたモデルとともに
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Saving the Sonorine: Audio Recovery Using Image Processing and Computer
  Vision -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.SD/paper_3.html">
      Saving the Sonorine: Audio Recovery Using Image Processing and Computer
  Vision
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ソノリンのフラットベッドスキャンを使用して以前に成功した非接触方式とこの手法の結果を比較し、この写真視覚的手法を音声回復に適用できる将来の研究で締めくくります。物理的な表面の特徴の反射動作の変化を観察し、表面の3次元の高さマップを作成します。この論文では、20世紀初頭のアナログサウンドストレージであるソノリンからオーディオを復元する新しい手法を紹介します。 
[要旨]私たちの方法は、ソノリンの高解像度写真を使用して表面の高さマップを作成します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-16">
        <br>2020-05-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SADDEL: Joint Speech Separation and Denoising Model based on Multitask
  Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.SD/paper_4.html">
      SADDEL: Joint Speech Separation and Denoising Model based on Multitask
  Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      現実のシナリオで収集された音声データは、2つの問題に遭遇することがよくあります。次に、録音中にバックグラウンドノイズが存在することは避けられません。しかし、音声の分離と類似した性質のノイズ除去タスクにもかかわらず、問題に同時に対処しようとする作品はほとんどありません。 
[要約]複数のソースが同時に存在する可能性があり、ソースの数は時間とともに変化する可能性があります。これらには、未知の数の話者からの個別の音声が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: AI Pipeline -- bringing AI to you. End-to-end integration of data,
  algorithms and deployment tools -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.SD/paper_5.html">
      AI Pipeline -- bringing AI to you. End-to-end integration of data,
  algorithms and deployment tools
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのAIパイプラインは4つのモジュラー主なステップで構成されています：i）データの取り込み、ii）モデルトレーニング、iii）デプロイメントの最適化、およびiv）IoTハブの統合。この作業では、モジュラーAIパイプラインを統合フレームワークとして提示します。データ、アルゴリズム、配置ツールを組み合わせて使用します。最後に、一連の有名な組み込みプラットフォームでのキーワードスポッティング、画像分類、オブジェクト検出などのいくつかのAIアプリケーションの配置を示すことにより、AIパイプラインの結果を示します。他のすべての一般的な展開フレームワークよりも常に優れています。 
[ABSTRACT]ツールのさまざまな段階を相互接続し、モジュール式のエンドツーエンドの組み込みデバイス用AI製品の開発を提供できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-01-15">
        <br>2019-01-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Sparse and Cosparse Audio Dequantization Using Convex Optimization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.SD/paper_6.html">
      Sparse and Cosparse Audio Dequantization Using Convex Optimization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      （IEEE ICASSP 2016）、評価シナリオの範囲を大幅に拡大：分析（cosparse）モデルを導入し、より効果的なアルゴリズムを使用し、別の時間-周波数変換を実験します。最後に、コードを提供し、データを再現可能な方法で。Brauerらの研究のフォローアップ。 
[ABSTRACT]この論文は、分析ベースのモデルが効果的な合成モデルと同等に機能することを示しています。しかし、ガボール変換は、最初に使用されたコサイン変換よりも優れた結果を生成します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-05">
        <br>2020-03-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Meta-Learning for Short Utterance Speaker Recognition with Imbalance
  Length Pairs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.SD/paper_7.html">
      Meta-Learning for Short Utterance Speaker Recognition with Imbalance
  Length Pairs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、特定のエピソードのクラスのみを最適化することは、目に見えないクラスの識別的な埋め込みを学習するには不十分な場合があるため、トレーニングセットのクラスセット全体に対してサポートとクエリセットの両方を分類するようにモデルを強制します。この問題を解決するには、不均衡長ペアのメタ学習フレームワークを導入します。また、目に見えない話者を特定するための提案モデルを検証します。これにより、既存のアプローチよりも大幅にパフォーマンスが向上します。 
[ABSTRACT]既存の話者認識モデルは短い発話ではパフォーマンスが低下します。既存のモデル認識モデルにはそのような発話はありません。モデルは既存の最新モデルより優れています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: End-to-End Speaker Diarization for an Unknown Number of Speakers with
  Encoder-Decoder Based Attractors -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.SD/paper_8.html">
      End-to-End Speaker Diarization for an Unknown Number of Speakers with
  Encoder-Decoder Based Attractors
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近提案されたエンドツーエンドのスピーカーダイアライゼーションは、従来のクラスター化ベースのスピーカーダイアライゼーションを上回りましたが、1つの欠点があります。それは、スピーカーの数の点で柔軟性が低いということです。音声埋め込みシーケンスは、従来の自己注意型エンドto-endニューラルスピーカーダイアライゼーション（SA-EEND）ネットワーク。2スピーカー条件では、本手法は、シミュレートされた混合物で2.69％のダイアライゼーションエラー率（DER）を達成し、CALLHOMEの2スピーカーサブセットで8.07％DER一方、バニラSA-EENDは、それぞれ4.56％および9.54％を達成しました。 
[要約]この方法は、話者の数の点で柔軟性が低くなります。これにより、多くの埋め込みシーケンスが作成され、同じ数の話者アクティビティが作成されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Comparison of Label-Synchronous and Frame-Synchronous End-to-End
  Models for Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.SD/paper_9.html">
      A Comparison of Label-Synchronous and Frame-Synchronous End-to-End
  Models for Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      3つのパブリックデータセットと12000時間のトレーニングデータを含む大規模データセットの結果は、2つのタイプのモデルにそれぞれの利点が同期モードと一致していることを示しています。エンドツーエンドモデルは、フィールドでより大きな注目を集めています自動音声認識（ASR）の例です。この作業では、代表的なラベル同期モデル（トランスフォーマー）とソフトフレーム同期モデル（連続積分発火（CIF）ベースのモデル）の詳細な比較を行います。 
[要約]シンプルなモデルは、詳細な比較を行うように設計されています。これらには、音声フレームを認識するために構築できるシンプルなシステムが含まれています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Relative Positional Encoding for Speech Recognition and Direct
  Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.SD/paper_10.html">
      Relative Positional Encoding for Speech Recognition and Direct
  Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの実験は、結果のモデルが非拡張条件でスイッチボードベンチマークで最高の認識結果を達成し、MuST-C音声翻訳ベンチマークで最もよく公開された結果を達成することを示しています。また、このモデルは合成データはトランスフォーマーよりもデータに適しており、音声翻訳の可変センテンスセグメンテーション品質によりよく適合します。その結果、ネットワークは音声データに存在する可変分布によりよく適合できます。 
[ABSTRACT]このモデルの位置をモデル化するメカニズムは、テキストモデリング用に調整されているため、音響入力にはあまり適していません。ネットワークは、音声データに存在する変数の発生に、よりよく適応できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Statistical and Neural Network Based Speech Activity Detection in
  Non-Stationary Acoustic Environments -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.SD/paper_11.html">
      Statistical and Neural Network Based Speech Activity Detection in
  Non-Stationary Acoustic Environments
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      音響シーンの時間変化により音声とノイズを区別することが困難になるため、非定常環境では、ノイズが音声よりも「定常的」であるという事実にしばしば依存する音声アクティビティ検出（SAD）が特に困難です。 。システムは、Apollo-11宇宙ミッションからの送信データで構成されるFearless Stepsチャレンジでテストされます。前者は、高度な信号処理を使用してノイズと音声エネルギーを追跡し、リソース効率の高いケースをサポートすることを目的としています、教師なし信号処理アプローチ。 
[要約] sadには2つのアプローチを提案します。1つは統計信号処理に基づいています。もう1つは、入力音声の短いセグメントで動作するリカレントネットワークレイヤーを導入します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Jointly optimal denoising, dereverberation, and source separation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.SD/paper_12.html">
      Jointly optimal denoising, dereverberation, and source separation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、提案されたアプローチは、従来の共同最適化アプローチと比較して、推定精度が向上し、計算コストを大幅に削減できることも示されています。このため、CBFをWPEフィルターとビームフォーマーに因数分解する2つの異なる手法を紹介します。新規の因数分解手法に基づいてDR + SSおよびその他に提案された従来の共同最適化アプローチの拡張、およびニューラルネットワークでサポートされているステアリングベクトル推定を使用した最尤推定に基づいてDN + DR + SSに最適化する方法を導出します。ノイズの多い残響音の混合物を使用した実験では、提案された最適化アプローチにより、信号歪みの測定値とASRのパフォーマンスに関して、従来のカスケード構成と比較して音声強調のパフォーマンスが大幅に向上することが示されています。 
[ABSTRACT]新しい論文は、dn dr ss。で最適化するための新しいアプローチを開発しました。制限を克服するために、この論文は同じ方法で最適化するための新しい戦略を必要とします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Investigation of Large-Margin Softmax in Neural Language Modeling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.SD/paper_13.html">
      Investigation of Large-Margin Softmax in Neural Language Modeling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、予測マージンは、単語ベクトルの視覚化を通じて分析され、構文および意味の関係も保持されていることを示しています。現在、言語モデリングは、一般に、ソフトマックスとクロスエントロピーを使用したニューラルネットワークでアプローチされています。その後、最適なノルムを適用します。さまざまなマージンと組み合わせてセットアップをスケーリングし、自動音声認識の実験を記録する神経言語モデルを実行します。 
[ABSTRACT]言語モデルのマージンが大きい-ソフトマックスは、標準のソフトマックスベースラインと同様の単語エラー率をもたらす可能性があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: PyChain: A Fully Parallelized PyTorch Implementation of LF-MMI for
  End-to-End ASR -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.SD/paper_14.html">
      PyChain: A Fully Parallelized PyTorch Implementation of LF-MMI for
  End-to-End ASR
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      PyChainの効率と柔軟性は、分子/分母グラフでの完全なGPUトレーニング、不等長シーケンスのサポートなどの新しい機能を通じて実証されています。 Kaldiに匹敵し、他のエンドツーエンドのASRシステムよりも優れた結果。他のPyTorchおよびKaldiベースのASRツールキットとは異なり、PyChainは可能な限り柔軟で軽量になるように設計されているため、新しいASRプロジェクト、または他の既存のPyTorchベースのASRツール。それぞれ、新しいプロジェクトPyChain-exampleと、既存のエンドツーエンドのASRツールキットであるEspressoで例示されています。 
[ABSTRACT] pychainは、可能な限り柔軟で軽量になるように設計されています。新しいasrプロジェクトまたは他の既存のpytorchベースのasrツールに簡単にプラグインできます。wsjデータセットの実験は、pychainが同等の競争力のある結果を達成できることを示していますカルディへ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Further Study of Unsupervised Pre-training for Transformer Based
  Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.SD/paper_15.html">
      A Further Study of Unsupervised Pre-training for Transformer Based
  Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、MPCについてさらに調査し、3つの重要な側面に焦点を当てます。事前トレーニングデータスピーキングスタイルの効果、ストリーミングモデルへの拡張、および事前トレーニングステージからダウンストリームタスクに学習した知識をより適切に転送する方法。実験により、発話スタイルが一致する事前トレーニングデータは、下流の認識タスクでより有用であることが明らかになりました。これらの方法の中で、マスク予測コーディングは、BERTのようなMasked Reconstruction lossとTransformerバックボーンを備えたさまざまな音声認識データセットで大幅な改善を実現しました。 
[要約]多くの教師なし事前トレーニング方法が提案されています。これらには、これらのタイプの音声ベースの音声認識と音声認識が含まれます。しかし、mpcの一部の側面は完全には調査されていません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Consistent ICA: Determined BSS meets spectrogram consistency -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.SD/paper_16.html">
      Consistent ICA: Determined BSS meets spectrogram consistency
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、スペクトログラム整合性と呼ばれる時間-周波数領域表現の一般的なプロパティが、順列問題を解決するための補助となることを示しています。決定された状況でのマルチチャネルオーディオブラインドソース分離（BSS）（マイクの数）はソースのそれと等しい）、または決定されたBSSは、時間-周波数領域でマルチチャネル線形フィルタリングによって実行され、畳み込みミキシングプロセスを処理します。通常、フィルターは各周波数を個別に処理するため、よく知られている置換の問題が発生します。つまり、分離された各コンポーネントが対応するソースに正しく割り当てられるように、周波数ごとのフィルターを調整する方法の問題。 
[ABSTRACT]フィルターは問題を解決するために各周波数を処理します。問題はよく知られている順列問題を引き起こします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Analysis of Railway Accidents' Narratives Using Deep Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_0.html">
      Analysis of Railway Accidents' Narratives Using Deep Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2001年から2016年までの米国での鉄道事故の費用は46億ドル以上です。これらのレポートには、事故の主な原因（389の値を持つコード化された変数）と短いテキストである説明フィールドを含む、さまざまな固定フィールドエントリが含まれています。事故の説明..したがって、そのようなドメイン固有のテキスト（ナラティブ）から主な原因を入力するための支援方法を提供することは、事故をより正確にラベル付けするのに役立ちます。 
[ABSTRACT]鉄道ドライバーは、事故の報告を連邦鉄道管理局に提出する必要があります。これらの説明は、固定フィールドのエントリよりも多くの情報を提供します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-10-17">
        <br>2018-10-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Computational Analysis of Polarization on Indian and Pakistani Social
  Media -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_1.html">
      A Computational Analysis of Polarization on Indian and Pakistani Social
  Media
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちは、ハッシュタグの共起に焦点を当てたラベル伝播手法を使用して、二極化したツイートとユーザーを見つけます。私たちの仕事は、インドとパキスタン間の緊張の高まりがTwitterにどのように現れているかの最初の分析を提供し、二極化メッセージを研究するためのフレームワークを提供します。 2019年3月4日、カシミールのプルワマでのテロ攻撃、それに続く報復攻撃により、2つの核武装国であるインドとパキスタンの間の緊張が高まりました。 
[ABSTRACT]カシミール分析は、インドの与党政党の政治家が極性ハッシュタグを使用したことを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Leveraging Graph to Improve Abstractive Multi-Document Summarization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_2.html">
      Leveraging Graph to Improve Abstractive Multi-Document Summarization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      WikiSumおよびMultiNewsデータセットの実証結果は、提案されたアーキテクチャがいくつかの強力なベースラインを大幅に改善することを示しています。グラフを利用して要約生成プロセスをガイドします。これは、首尾一貫した簡潔な要約を生成するのに役立ちます。 
[ABSTRACT]複数のドキュメントを使用して、要約を作成できます。これらのモデルは、グラフを利用して要約生成プロセスをガイドすることもできます。これは、一貫性のある簡潔な要約を生成するのに役立ちます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SKEP: Sentiment Knowledge Enhanced Pre-training for Sentiment Analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_3.html">
      SKEP: Sentiment Knowledge Enhanced Pre-training for Sentiment Analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      特に、アスペクトと感情のペアの予測は、ペア内の単語間の依存関係をキャプチャすることを目的として、マルチラベル分類に変換されます。ほとんどのテストデータセットに関する最新の結果。ただし、感情の単語やアスペクトと感情のペアなどの感情の知識は、広く使用されているにもかかわらず、事前トレーニングのプロセスでは無視されます。従来の感情分析アプローチでは。 
[ABSTRACT]感情分析は、従来の感情分析アプローチで使用されていました。ただし、事前トレーニングのプロセスでは、感情知識は無視されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br>2020-05-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Sentence level estimation of psycholinguistic norms using joint
  multidimensional annotations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_4.html">
      Sentence level estimation of psycholinguistic norms using joint
  multidimensional annotations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、このパラメーターを文レベルで使用して、規範を推定します。さまざまな規範的な次元の文レベルのスコアを予測してアプローチを評価し、標準の単語集計方式と比較します。この作業では、心理言語学的規範を推定する新しいアプローチを紹介します文レベルで。 
[ABSTRACT]多次元アノテーションフュージョンモデルをサイコレベルのアノテーションに適用します。これらは、単純な軌道戦略を使用して単語レベルのスコアを推定することで推定されますが、常に最適とは限りません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Early Stage LM Integration Using Local and Global Log-Linear Combination -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_5.html">
      Early Stage LM Integration Using Local and Global Log-Linear Combination
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは、トレーニングで浅い融合を適用することと同等であるグローバルくりこみスキームと比較されます。音響モデルと言語モデルの対数線形モデルの組み合わせは、トークンごとのくりこみで実行されます。さらに、LMが訓練後により強力なものと交換しました。 
[ABSTRACT]新しいシステムは、従来のハイブリッド隠しマルコフモデルに対するパフォーマンスのギャップを埋めています。提案された方法は、標準モデルの組み合わせよりも優れた改善を示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On embedding Lambek calculus into commutative categorial grammars -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_6.html">
      On embedding Lambek calculus into commutative categorial grammars
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作品のテンソル文法は、直観的な線形論理ではなく、古典的な「論理」に基づいた「可換」文法のもう1つの例です。よく知られている「非可換性」のランベック文法とそのバリエーションとは対照的に、暗黙の線形論理と線形$ \ lambda $ -calculus .. ACGは多くの点で魅力的であるように見えます。 
[要約]新しいシステムでは、acgおよびlambek文法を保守的なフラグメントとして表すことができます。これらのシステムは、acgを非可換構文で強化するように設計されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: BERTweet: A pre-trained language model for English Tweets -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_7.html">
      BERTweet: A pre-trained language model for English Tweets
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験は、BERTweetが強力なベースラインであるRoBERTaベースとXLM-Rベース（Conneau et al。、2020）よりも優れており、3つのツイートNLPタスクで以前の最先端モデルよりも優れたパフォーマンス結果を生み出していることを示しています。スピーチのタグ付け、名前付きエンティティの認識、テキスト分類など。今後の調査やツイートデータのダウンストリームアプリケーションを容易にするためにBERTweetをリリースしています。当社のBERTweetは、https：//github.com/VinAIResearch/BERTweetで入手できます。 roberta事前トレーニング手順を使用してトレーニングされます。bert-baseと同じモデル位置を使用します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Finding Universal Grammatical Relations in Multilingual BERT -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_8.html">
      Finding Universal Grammatical Relations in Multilingual BERT
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この証拠は、明示的な監督がなくても、多言語マスク言語モデルが特定の言語普遍性を学習することを示唆しています。mBERT表現の部分空間が英語以外の言語の構文木の距離を回復し、これらの部分空間が言語間でほぼ共有されていることを示しています。結果、我々は、mBERTが普遍的な依存関係の分類法にほぼ同意するクラスターの形で、構文の依存関係のラベルの表現を学習する証拠を提供する教師なし分析方法を提示します。 
[要約]私たちは、mbertが構文依存関係ラベルの表現を学習するという証拠を提供する教師なし分析方法を提示します。これは、この重複を理解する方法を見つけることができることを示唆しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-09">
        <br>2020-05-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Examining the State-of-the-Art in News Timeline Summarization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_9.html">
      Examining the State-of-the-Art in News Timeline Summarization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      より堅牢な評価のために、以前のデータセットよりも大きく、長い期間にわたる新しいTLSデータセットも提示します。このホワイトペーパーでは、適切な評価フレームワークを使用してさまざまなTLS戦略を比較し、メソッドのシンプルで効果的な組み合わせを提案します。これは、テストされたすべてのベンチマークで最先端の技術を上回っています。これは主に、日付の選択や日付の要約などの個々のサブタスクに焦点が当てられていることと、以前の完全なTLSタスクに適切な評価指標がないことによるものです。 。 
[ABSTRACT]以前の完全なtlsタスクの適切な評価の欠如は、日付の選択や日付の要約などのサブタスクに重点が置かれているためです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Enhancing Word Embeddings with Knowledge Extracted from Lexical
  Resources -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_10.html">
      Enhancing Word Embeddings with Knowledge Extracted from Lexical
  Resources
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのアプローチでは、BabelNetなどの豊富な語彙リソースからの外部知識を活用します。このために、従来の単語の埋め込みを使用し、特殊化手法を適用して、単語間の意味関係をより適切にキャプチャします。この作業では、意味論の効果的な方法を示します単語ベクトル表現の特殊化。 
[ABSTRACT]これに加えて、単語の埋め込みを使用して、単語間の意味関係をより適切にキャプチャします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CODA-19: Reliably Annotating Research Aspects on 10,000+ CORD-19
  Abstracts Using a Non-Expert Crowd -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_11.html">
      CODA-19: Reliably Annotating Research Aspects on 10,000+ CORD-19
  Abstracts Using a Non-Expert Crowd
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CODA-19のラベルの精度は、生物医学の専門家のラベルと比較すると82.2％ですが、専門家の間の精度は85.0％でした。群衆と生物医学の専門家の間のアノテーター間の合意（Cohenのカッパ）（0.741）は、専門家間の合意（0.788）。COVID-19との戦いに参加するために、専門家ではない群衆を大規模に迅速に採用できることを示しました。 
[ABSTRACT] coda-19は、エキスパートと同等のラベル品質を達成するために、10日以内にamazonメカニカルタークの248人のクラウドワーカーによって作成されました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Abstract categorial grammars with island constraints and effective
  decidability -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_12.html">
      Abstract categorial grammars with island constraints and effective
  decidability
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、特定の安全にブラケット化されたACGを特定します。これは、通常の（ブラケットのない）2次ACGと同様に、効果的に決定可能な言語を生成しますが、相対化などの高次現象をモデル化し、少なくとも単純なおもちゃの例では構文アイランドを正しく処理するのに十分な柔軟性があります。 ..ランベック文法の設定で構文島制約を処理するためのよく知られたアプローチは、特定のブラケットモダリティをロジックに追加することです。このアプローチを抽象カテゴリ文法（ACG）に適合させます。 
[要旨]以前、「フックフックフック」のコンセプトへのアップグレードを求めていました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-16">
        <br>2019-07-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: End-to-End Speaker Diarization for an Unknown Number of Speakers with
  Encoder-Decoder Based Attractors -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_13.html">
      End-to-End Speaker Diarization for an Unknown Number of Speakers with
  Encoder-Decoder Based Attractors
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文は、最初に音声埋め込みシーケンスから柔軟な数のアトラクタを生成するエンコーダ/デコーダベースのアトラクタ計算（EDA）の方法を提案します。未知の話者数の条件で、本方法はCALLHOMEで15.29％DERを達成しましたが、 x-ベクトルベースのクラスタリング手法は19.43％のDER。を達成しました。最近提案されたエンドツーエンドのスピーカーダイアライゼーションは、従来のクラスタリングベースのスピーカーダイアライゼーションを上回りましたが、1つ欠点があります。 
[要約]この方法は、話者の数の点で柔軟性が低くなります。これにより、多くの埋め込みシーケンスが作成され、同じ数の話者アクティビティが作成されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Comparison of Label-Synchronous and Frame-Synchronous End-to-End
  Models for Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_14.html">
      A Comparison of Label-Synchronous and Frame-Synchronous End-to-End
  Models for Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      3つのパブリックデータセットと12000時間のトレーニングデータを含む大規模データセットの結果は、2つのタイプのモデルにそれぞれの同期モードと一致するそれぞれの利点があることを示しています。認識プロセスの原動力となるエンドによると、 -end ASRモデルは、ラベル同期とフレーム同期の2つのタイプに分類できます。それぞれに固有のモデルの動作と特性があります。この作業では、代表的なラベル同期モデル（トランスフォーマー）とソフトフレーム同期モデル（継続的統合射撃（CIF）ベースのモデル）。 
[要約]シンプルなモデルは、詳細な比較を行うように設計されています。これらには、音声フレームを認識するために構築できるシンプルなシステムが含まれています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Text Classification Algorithms: A Survey -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_15.html">
      Text Classification Algorithms: A Survey
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、各手法の制限と実際の問題におけるそれらのアプリケーションについて説明します。このホワイトペーパーでは、テキスト分類アルゴリズムの概要を説明します。この概要では、さまざまなテキスト特徴抽出、次元削減方法、既存のアルゴリズム、および技術、および評価方法。 
[ABSTRACT]多くの機械学習アプローチは、自然言語処理で優れた結果を達成しています。これらは発見の簡単な例ですが、複雑なデータは研究者にとって課題です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-17">
        <br>2019-04-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: BlaBla: Linguistic Feature Extraction for Clinical Analysis in Multiple
  Languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_16.html">
      BlaBla: Linguistic Feature Extraction for Clinical Analysis in Multiple
  Languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      BlaBlaのアーキテクチャと12の疾患にまたがるその機能の臨床検証について説明します。このライブラリは最新のNLPフレームワークに基づいて構築されており、ネイティブPython呼び出しとコマンドラインインターフェースの両方を介してマルチスレッド/ GPU対応の機能抽出をサポートしています。さらに、AphasiaBankデータセットの実際の臨床データに基づいて、3つの言語で言語障害を視覚化および分類するタスクへのBlaBlaの適用を示します。 
[ABSTRACT] blablaは、臨床言語研究を加速および簡素化するための統合フレームワークです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Question-Driven Summarization of Answers to Consumer Health Questions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_17.html">
      Question-Driven Summarization of Answers to Consumer Health Questions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      国立医学図書館の消費者健康質問回答システムによって提供される回答を使用して、MEDIQA回答要約データセットを提示します。これは、消費者健康質問に対する回答の質問駆動型要約を含む最初の要約コレクションです。このデータセットは、単一または複数の評価に使用できます。 -抽出または抽象アプローチを使用してアルゴリズムによって生成された要約を文書化します。データセットをベンチマークするために、ベースラインと最先端のディープラーニング要約モデルの結果を含め、このデータセットを使用して質問を効果的に評価できることを示します-機械で生成された要約を駆動し、医学的質問応答におけるさらなる機械学習研究を促進します。 
[ABSTRACT]最初の要約コレクションには、消費者の健康に関する質問に対する回答の質問駆動型の要約が含まれています。データセットを使用して、質問駆動型の機械で生成された要約を効果的に評価し、機械学習の研究をさらに促進できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-18">
        <br>2020-05-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Positive emotions help rank negative reviews in e-commerce -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_18.html">
      Positive emotions help rank negative reviews in e-commerce
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      より合理的な評価手順を適用することにより、関連するバックグラウンドを持つ専門家が、ランキングアプローチに投票するために雇われます。否定的なレビュー、購入後の評価における低い評価は、特に将来の販売と企業株式の形成において、eコマースに不可欠な役割を果たします。この論文では、レビューを評価する際の感情に関するこれまでの理解も深めています。 
[要約]ランキング方式の目的は、特定の製品属性の下でオンラインの販売者と生産者に最も役立つ否定的なレビューを提供することです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Relative Positional Encoding for Speech Recognition and Direct
  Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_19.html">
      Relative Positional Encoding for Speech Recognition and Direct
  Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      トランスフォーマーモデルは、音声入力を文字起こしまたは翻訳に直接マッピングできる、強力なシーケンスツーシーケンスアーキテクチャです。私たちの実験では、結果のモデルが非拡張条件でスイッチボードベンチマークで最高の認識結果を達成し、最高のMuST-C音声翻訳ベンチマークで公開された結果。ただし、このモデルの位置をモデリングするメカニズムはテキストモデリング用に調整されているため、音響入力にはあまり適していません。 
[ABSTRACT]このモデルの位置をモデル化するメカニズムは、テキストモデリング用に調整されているため、音響入力にはあまり適していません。ネットワークは、音声データに存在する変数の発生に、よりよく適応できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Conversational Transfer Learning for Emotion Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_20.html">
      Conversational Transfer Learning for Emotion Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      利用可能な会話データが大量にある場合、生成される会話モデルを活用して、情動をコンテキスト内で検出するための感情的な知識を伝達できるかどうかを調査します。ただし、純粋に監視された戦略では、利用可能なコーパスのほとんどに欠けている大量の注釈付きデータが必要ですこのタスクでは..アプローチ、TL-ERCを提案します。ここでは、マルチターン会話（ソース）で階層的対話モデルを事前トレーニングし、そのパラメーターを会話型感情分類子（ターゲット）に転送します。 
[ABSTRACT]このアイデアに加えて、複数のデータセットに対していくつかの実験を実行しました。限られたトレーニングデータに対してパフォーマンスと堅牢性が向上したことがわかりました。全体として、会話ジェネレーターから取得した知識は、会話の感情の認識に実際に役立つと推測しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-11">
        <br>2019-10-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Large-Scale Multi-Document Summarization Dataset from the Wikipedia
  Current Events Portal -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_21.html">
      A Large-Scale Multi-Document Summarization Dataset from the Wikipedia
  Current Events Portal
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、このタスクの教師付きモデルをトレーニングするのに十分な規模でこのようなユースケースに現実的に対処するデータセットはありません。マルチドキュメント要約（MDS）は、大規模なドキュメントコレクションのコンテンツを短い要約に圧縮することを目的としており、重要です。ニュースフィードのストーリークラスタリング、検索結果の表示、タイムライン生成のアプリケーション。CommonCrawlアーカイブで関連記事を検索することにより、これらのソース記事を自動的に拡張します。 
[ABSTRACT]ウィキペディアの現在のイベントポータルは、外部のソース記事へのリンクとともに、ニュースイベントの簡潔で中立な人間が書いた要約を提供します。このための監視モデルをトレーニングするのに十分な規模でそのようなユースケースに現実的に対処するデータセットがありません仕事
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Applying the Transformer to Character-level Transduction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_22.html">
      Applying the Transformer to Character-level Transduction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの洞察により、形態素変化と歴史的なテキストの正規化で最先端のパフォーマンスを実現します。コードはhttps://github.com/shijie-wu/neural-transducer。で入手できます。また、簡単な手法も紹介します。パフォーマンスをさらに向上させる機能ガイドの文字レベルの変換を処理します。 
[ABSTRACT] transformerは2つの変換タスクで強力なニューラルよりもパフォーマンスが優れています。このモデルは、トランスフォーマを使用した反復モデルのパフォーマンスを向上させることができません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SPECTER: Document-level Representation Learning using Citation-informed
  Transformers -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_23.html">
      SPECTER: Document-level Representation Learning using Citation-informed
  Transformers
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      分類や推奨などの科学文書のアプリケーションの場合、埋め込みは最終タスクの強力なパフォーマンスを強化します。既存の事前トレーニング済み言語モデルとは異なり、SPECTERはタスク固有の微調整なしでダウンストリームアプリケーションに簡単に適用できます。SPECTERが優れていることを示していますベンチマークのさまざまな競争力のあるベースライン。 
[要旨]科学ドキュメントのドキュメントレベルの埋め込みを生成する新しい方法であるスペクターを提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-15">
        <br>2020-04-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Investigation of Large-Margin Softmax in Neural Language Modeling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_24.html">
      Investigation of Large-Margin Softmax in Neural Language Modeling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      その後、さまざまなマージンと組み合わせて最適なノルムスケーリング設定を適用し、自動音声認識の実験を記録する神経言語モデルを実行します。最後に、予測されるマージンは、単語ベクトルの可視化を通じて分析され、構文および意味の関係も示されます具体的には、まず、以前の顔認識の作業に続いて、さまざまなタイプの従来のマージンを実装してテストします。 
[ABSTRACT]言語モデルのマージンが大きい-ソフトマックスは、標準のソフトマックスベースラインと同様の単語エラー率をもたらす可能性があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: PyChain: A Fully Parallelized PyTorch Implementation of LF-MMI for
  End-to-End ASR -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_25.html">
      PyChain: A Fully Parallelized PyTorch Implementation of LF-MMI for
  End-to-End ASR
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      PyChainの効率と柔軟性は、分子/分母グラフでの完全なGPUトレーニング、不等長シーケンスのサポートなどの新しい機能を通じて実証されています。 Kaldiに匹敵し、他のエンドツーエンドのASRシステムよりも優れた結果。他のPyTorchおよびKaldiベースのASRツールキットとは異なり、PyChainは可能な限り柔軟で軽量になるように設計されているため、新しいASRプロジェクト、または他の既存のPyTorchベースのASRツール。それぞれ、新しいプロジェクトPyChain-exampleと、既存のエンドツーエンドのASRツールキットであるEspressoで例示されています。 
[ABSTRACT] pychainは、可能な限り柔軟で軽量になるように設計されています。新しいasrプロジェクトまたは他の既存のpytorchベースのasrツールに簡単にプラグインできます。wsjデータセットの実験は、pychainが同等の競争力のある結果を達成できることを示していますカルディへ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Further Study of Unsupervised Pre-training for Transformer Based
  Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_26.html">
      A Further Study of Unsupervised Pre-training for Transformer Based
  Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーでは、MPCについてさらに調査を行い、3つの重要な側面に焦点を当てます。事前トレーニングデータの発話スタイルの影響、ストリーミングモデルへの拡張、および事前トレーニングステージからダウンストリームタスクに学習した知識をより適切に転送する方法。 。ただし、MPCの多くの側面は完全には調査されていません。実験により、発話スタイルが一致する事前トレーニングデータが、下流の認識タスクでより有用であることが明らかになりました。 
[要約]多くの教師なし事前トレーニング方法が提案されています。これらには、これらのタイプの音声ベースの音声認識と音声認識が含まれます。しかし、mpcの一部の側面は完全には調査されていません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Fine-grained Financial Opinion Mining: A Survey and Research Agenda -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_27.html">
      Fine-grained Financial Opinion Mining: A Survey and Research Agenda
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このポジションペーパーでは、まず大まかな視点と細かい視点の両方から財務的な見解を定義し、次に、すでに取り組んでいる問題の概要を示します。既存のトピックの研究課題をリストすることに加えて、さらに提案します。将来の研究のためのきめの細かい金融意見マイニングのロードマップ、そしてまだ探求していないいくつかの課題を指摘します。最近の金融技術（FinTech）開発のおかげで、学際的な研究者が投資家の詳細な分析に関与し始めます意見。 
[要約]金融技術（fintech）の開発により、投資家の意見の詳細な分析に関与する共同研究者が育った
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br>2020-05-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: GM-CTSC at SemEval-2020 Task 1: Gaussian Mixtures Cross Temporal
  Similarity Clustering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_28.html">
      GM-CTSC at SemEval-2020 Task 1: Gaussian Mixtures Cross Temporal
  Similarity Clustering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さまざまな期間に一時的な単語の埋め込みによってキャプチャされた単語のセマンティクスを考慮して、監視されていない方法を使用して、ターゲットの単語が感覚を獲得または緩和した時期を検出する方法を調査します。提案されたアプローチを類似性ベースのしきい値の数と比較しました。私たちはアプローチを検出問題に集中させました。 
[要約]システムシステムは、パターンの持続不可能な使用を検出するために開発されました。ニューヨーク大学の研究者によって開発されました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Creative Artificial Intelligence -- Algorithms vs. humans in an
  incentivized writing competition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_29.html">
      Creative Artificial Intelligence -- Algorithms vs. humans in an
  incentivized writing competition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのサンプルから、ランダムな詩が選択された（Human-out-of-the-loop）か、最適な詩が選択された（Human-in-the-loop）か、どちらか一方が人間が書いた詩と一致しました。人間の詩の出発点であるGPT-2は、アルゴリズムによって生成された複数の詩のサンプルを生成しました。さまざまな分野にわたって人間のようなテキストを生成するアルゴリズムの能力が主張されているため、オープンで入手可能な堅牢なテキスト生成アルゴリズムのリリースにより、多くの人々の注目と議論に拍車がかかっています。ドメイン。 
[ABSTRACT]インセンティブ試験の参加者は、人間-s-で確実に検出できませんでしたが、人間では成功しました-ループ治療外。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: How Good is Artificial Intelligence at Automatically Answering Consumer
  Questions Related to Alzheimer's Disease? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_30.html">
      How Good is Artificial Intelligence at Automatically Answering Consumer
  Questions Related to Alzheimer's Disease?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの知る限りでは、これは、ADに関連する消費者の質問に自動的に回答するように設計されたAIモデルを適用および評価する文献の最初の研究です。その割合は家族が提供するケアに関連しています。しかし、多くの場合、関連する質問と検索する回答の数が限られているため、投稿された質問にすぐに回答することはほとんどありません。 
[要約] 2019年に推定500万人がアルツハイマー型認知症と暮らしていました。ほとんどの家族介護者は、感情的、経済的、身体的な困難に直面しています。介護者が投稿した広告関連の質問に対する回答を自動生成するためにaiを利用することを提案します。それらの質問に答えるのがどれほど優れているかを評価する
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-21">
        <br>2019-08-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: BLEURT: Learning Robust Metrics for Text Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/cs.CL/paper_31.html">
      BLEURT: Learning Robust Metrics for Text Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      BLEURTは、WMTメトリックの共有タスクとWebNLG競争データセットの過去3年間の最先端の結果を提供します。バニラBERTベースのアプローチとは対照的に、トレーニングデータが不足している場合でも優れた結果が得られますout-of-distribution ..私たちのアプローチの重要な側面は、モデルを一般化するのに役立つ数百万の合成例を使用する新しい事前トレーニングスキームです。 
[ABSTRACT]評価指標は遅れています。最も一般的な選択は人間の判断とあまり相関しない可能性があるためです。私たちのアプローチの重要な側面は、モデルの一般化に役立つ数百万の合成例を使用する新しい事前トレーニングスキームです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br>2020-04-09
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: The Privacy ZEBRA: Zero Evidence Biometric Recognition Assessment -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/eess.AS/paper_0.html">
      The Privacy ZEBRA: Zero Evidence Biometric Recognition Assessment
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ZEBRAフレームワークは音声アプリケーションを念頭に置いて設計されていますが、生体認証情報保護標準への組み込みの候補であり、音声および生体認証を超えてアプリケーションのプライバシーの研究に容易に拡張できます。提供されるプライバシー保護の平均レベルを測定します。人口のための与えられた保護と個人のための最悪の場合のプライバシー開示によって。。プライバシー法の施行は、音声技術におけるプライバシーの保護を要求しますが、解決策は非常に欠けています。 
[ABSTRACT]私たちはゼロエビデンスバイオメトリック認識評価（zebra）フレームワークを導入し、2つの新しいプライバシーメトリックを提案します。このペーパーでは、音声プライバシーの課題の範囲内でのプライバシー保護評価への応用を示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-19">
        <br>2020-05-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Evaluating Features and Metrics for High-Quality Simulation of Early
  Vocal Learning of Vowels -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/eess.AS/paper_1.html">
      Evaluating Features and Metrics for High-Quality Simulation of Early
  Vocal Learning of Vowels
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この目的に向けて、フォルマントエラーの有用性と、正規化されたF1-F2フォルマント空間でのフィーチャーメトリックエラーサーフェスの投影を評価します。このアプローチを使用して、フィーチャーとメトリックの影響を評価し、さらに知覚結果への洞察。これらのシミュレーションの重要なパラメーターの1つは、機能の選択と、合成音と参照ターゲット間の音響誤差を評価するための測定基準です。 
[ABSTRACT]調音音声合成を使用した初期の音声学習のシミュレーションは、このプロセスをより深く理解する方法を提供します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Early Stage LM Integration Using Local and Global Log-Linear Combination -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/eess.AS/paper_2.html">
      Early Stage LM Integration Using Local and Global Log-Linear Combination
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      音響モデルと言語モデルの対数線形モデルの組み合わせは、トークンごとのくりこみを使用して実行されます。これとは対照的に、注意モデルには複数の統合スキームが提案されています。暗黙のアラインメントメカニズムを備えたシーケンス間モデル（たとえば
[ABSTRACT]新しいシステムは、従来のハイブリッド隠れマルコフモデルに対するパフォーマンスのギャップを埋めています。提案された方法は、標準モデルの組み合わせよりも優れた改善を示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploring Recurrent, Memory and Attention Based Architectures for
  Scoring Interactional Aspects of Human-Machine Text Dialog -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/eess.AS/paper_3.html">
      Exploring Recurrent, Memory and Attention Based Architectures for
  Scoring Interactional Aspects of Human-Machine Text Dialog
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      複数のアーキテクチャの融合は、エキスパートの評価者間合意に関連する自動スコアリングタスクで適切に機能し、（i）サポートベクター学習者に渡されたハンドエンジニアリング機能、および（ii）トランスフォーメーションベースのアーキテクチャが最も顕著に融合に貢献していることがわかります..クラウドベースのダイアログシステムと対話する人間の学習者からのテキストダイアログの会話データベースで実験を行いました。これは、会話能力の複数の側面に沿ってトリプルスコアされました。英語の学習者が会話のスピーキングを改善できるようにするための重要なステップ習熟度には、相互作用能力の複数の側面の自動スコアリングとその後の対象を絞ったフィードバックが含まれます。 
[ABSTRACT]複数のニューラルアーキテクチャの融合は、自動化されたスコアリングタスクで（ii）ベースのアーキテクチャが優れて融合に貢献します。新しい論文は、複数のニューラルアーキテクチャの再帰的な注目を調査するための以前の研究に基づいていますおよびメモリベース-テキストダイアログデータの機能設計されたモデルとともに
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Saving the Sonorine: Audio Recovery Using Image Processing and Computer
  Vision -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/eess.AS/paper_4.html">
      Saving the Sonorine: Audio Recovery Using Image Processing and Computer
  Vision
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ソノリンのフラットベッドスキャンを使用して、以前に成功した非接触方式とこの手法の結果を比較し、この写真視覚的アプローチにオーディオの回復に適用できる将来の研究で結論を出します。従来の再生方法とは異なり、この方法には非接触：メディアは繰り返し再生しても損傷や摩耗を被ることはありません。このペーパーでは、20世紀初頭のアナログサウンドストレージであるソノリンからオーディオを復元する新しい手法を紹介します。 
[要旨]私たちの方法は、ソノリンの高解像度写真を使用して表面の高さマップを作成します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-16">
        <br>2020-05-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SADDEL: Joint Speech Separation and Denoising Model based on Multitask
  Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/eess.AS/paper_5.html">
      SADDEL: Joint Speech Separation and Denoising Model based on Multitask
  Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      現実のシナリオで収集された音声データは、2つの問題に遭遇することがよくあります。2番目の問題に対処するために、ノイズ成分を除去し、純粋な音声信号を取得する音声ノイズ除去アプローチを参照します。音声分離とノイズ除去のための多くのディープラーニングベースの方法が有望な結果を示すことを提案しました。 
[要約]複数のソースが同時に存在する可能性があり、ソースの数は時間とともに変化する可能性があります。これらには、未知の数の話者からの個別の音声が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: AI Pipeline -- bringing AI to you. End-to-end integration of data,
  algorithms and deployment tools -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/eess.AS/paper_6.html">
      AI Pipeline -- bringing AI to you. End-to-end integration of data,
  algorithms and deployment tools
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、データ、アルゴリズム、デプロイメントツールを統合する統合フレームワークとしてモジュール式AIパイプラインを示します。パイプラインの有効性を示すために、各ステップでのさまざまなAIアプリケーションの例を示します。ただし、組み込みデバイスでのカスタムAIソリューションのトレーニングと展開には、高精度を実現するためのデータ、アルゴリズム、およびツールのきめ細かな統合が必要です。 
[ABSTRACT]ツールのさまざまな段階を相互接続し、モジュール式のエンドツーエンドの組み込みデバイス用AI製品の開発を提供できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-01-15">
        <br>2019-01-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Sparse and Cosparse Audio Dequantization Using Convex Optimization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/eess.AS/paper_7.html">
      Sparse and Cosparse Audio Dequantization Using Convex Optimization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に重要なことですが、再現可能な方法でコードとデータを提供します。（IEEE ICASSP 2016）、評価シナリオの範囲を大幅に拡張します。分析（cosparse）モデルを導入し、より効果的なアルゴリズムを使用して、実験を行います別の時間-周波数変換..このペーパーは、量子化された信号を復元する際のスパース性に基づく方法の可能性を示しています。 
[ABSTRACT]この論文は、分析ベースのモデルが効果的な合成モデルと同等に機能することを示しています。しかし、ガボール変換は、最初に使用されたコサイン変換よりも優れた結果を生成します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-05">
        <br>2020-03-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Meta-Learning for Short Utterance Speaker Recognition with Imbalance
  Length Pairs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/eess.AS/paper_8.html">
      Meta-Learning for Short Utterance Speaker Recognition with Imbalance
  Length Pairs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、特定のエピソードのクラスのみを最適化することは、目に見えないクラスの識別的埋め込みを学習するには不十分な場合があるため、トレーニングセットのクラスセット全体に対してサポートとクエリセットの両方を分類するようにモデルを強制します。この問題を解決するために、不均衡長ペアのメタ学習フレームワークを導入します。これらの2つの学習スキームを組み合わせると、短い発話に関する標準の教師あり学習フレームワークで学習した既存の最先端の話者検証モデルよりも、モデルの方が優れています（1 -2秒）VoxCelebデータセット。 
[ABSTRACT]既存の話者認識モデルは短い発話ではパフォーマンスが低下します。既存のモデル認識モデルにはそのような発話はありません。モデルは既存の最新モデルより優れています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: End-to-End Speaker Diarization for an Unknown Number of Speakers with
  Encoder-Decoder Based Attractors -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/eess.AS/paper_9.html">
      End-to-End Speaker Diarization for an Unknown Number of Speakers with
  Encoder-Decoder Based Attractors
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      音声埋め込みシーケンスは、従来の自己注意型のエンドツーエンドのニューラルスピーカーダイアライゼーション（SA-EEND）ネットワークを使用して抽出されます。 ：話者の数の点で柔軟性が低くなります。話者数が不明な状態では、このメソッドはCALLHOMEで15.29％DERを達成しましたが、x-vectorベースのクラスタリング方法は19.43％DERを達成しました。 
[要約]この方法は、話者の数の点で柔軟性が低くなります。これにより、多くの埋め込みシーケンスが作成され、同じ数の話者アクティビティが作成されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Comparison of Label-Synchronous and Frame-Synchronous End-to-End
  Models for Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/eess.AS/paper_10.html">
      A Comparison of Label-Synchronous and Frame-Synchronous End-to-End
  Models for Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      3つのパブリックデータセットと12000時間のトレーニングデータを含む大規模データセットの結果は、2つのタイプのモデルにそれぞれの同期モードと一致するそれぞれの利点があることを示しています。認識プロセスの原動力となるエンドによると、エンドASRモデルは、ラベル同期とフレーム同期の2つのタイプに分類できます。それぞれに固有のモデル動作と特性があります。エンドツーエンドモデルは、自動音声認識（ASR）の分野で大きな注目を集めています。 。 
[要約]シンプルなモデルは、詳細な比較を行うように設計されています。これらには、音声フレームを認識するために構築できるシンプルなシステムが含まれています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Relative Positional Encoding for Speech Recognition and Direct
  Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/eess.AS/paper_11.html">
      Relative Positional Encoding for Speech Recognition and Direct
  Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの実験は、結果のモデルが非拡張条件でスイッチボードベンチマークで最高の認識結果を達成し、MuST-C音声変換ベンチマークで最もよく公開された結果を達成することを示しています。その結果、ネットワークは変数によりよく適応できます音声データに存在する分布..トランスフォーマーモデルは、音声入力を文字起こしや翻訳に直接マッピングできる、強力なシーケンスツーシーケンスアーキテクチャです。 
[ABSTRACT]このモデルの位置をモデル化するメカニズムは、テキストモデリング用に調整されているため、音響入力にはあまり適していません。ネットワークは、音声データに存在する変数の発生に、よりよく適応できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Statistical and Neural Network Based Speech Activity Detection in
  Non-Stationary Acoustic Environments -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/eess.AS/paper_12.html">
      Statistical and Neural Network Based Speech Activity Detection in
  Non-Stationary Acoustic Environments
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      システムは、フィアレスステップチャレンジでテストされます。これは、アポロ11宇宙ミッションからの送信データで構成されます。統計SADは、以前に提案されたニューラルネットワークベースのSADに匹敵する検出性能を実現し、ニューラルネットワークベースのアプローチは、決定につながります。 2020年のフィアレスステップチャレンジの評価セットでのコスト関数は1.07％であり、新しい最先端の技術を設定します。後者は、入力音声の短いセグメントで動作する反復的なネットワークレイヤーを導入して、非定常ノイズ。 
[要約] sadには2つのアプローチを提案します。1つは統計信号処理に基づいています。もう1つは、入力音声の短いセグメントで動作するリカレントネットワークレイヤーを導入します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Jointly optimal denoising, dereverberation, and source separation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/eess.AS/paper_13.html">
      Jointly optimal denoising, dereverberation, and source separation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、提案されたアプローチは、従来の共同最適化アプローチと比較して、推定精度が向上し、計算コストを大幅に削減できることも示されています。ブラインド信号処理領域では、残響除去と音源分離（DR + SS）を共同で最適化するアプローチがあります。しかし、このアプローチは莫大な計算コストを必要とし、DN + DR + SSへのアプリケーションに拡張されていません。このために、CBFをWPEフィルターとビームフォーマーに因数分解する2つの異なる手法を紹介します。新しい因数分解手法に基づいてDR + SSとその他に提案された従来のジョイント最適化アプローチと、ニューラルネットワークでサポートされているステアリングベクトル推定を使用した最尤推定に基づいてDN + DR + SSに最適化する方法を導き出します。 
[ABSTRACT]新しい論文は、dn dr ss。で最適化するための新しいアプローチを開発しました。制限を克服するために、この論文は同じ方法で最適化するための新しい戦略を必要とします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Investigation of Large-Margin Softmax in Neural Language Modeling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/eess.AS/paper_14.html">
      Investigation of Large-Margin Softmax in Neural Language Modeling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、予測マージンは、単語ベクトルの視覚化を通じて分析され、構文および意味の関係も保持されていることを示しています。具体的には、まず、顔認識における以前の作業に続いて、さまざまなタイプの従来のマージンを実装およびテストします。次に、自然言語データを使用して、単語ベクトルの標準スケーリングのさまざまな戦略を比較します。 
[ABSTRACT]言語モデルのマージンが大きい-ソフトマックスは、標準のソフトマックスベースラインと同様の単語エラー率をもたらす可能性があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: PyChain: A Fully Parallelized PyTorch Implementation of LF-MMI for
  End-to-End ASR -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/eess.AS/paper_15.html">
      PyChain: A Fully Parallelized PyTorch Implementation of LF-MMI for
  End-to-End ASR
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      PyChainの効率と柔軟性は、分子/分母グラフでの完全なGPUトレーニング、不等長シーケンスのサポートなどの新しい機能を通じて実証されています。WSJデータセットでの実験では、シンプルなニューラルネットワークと一般的に使用される機械学習技術により、PyChainが競争力を発揮できるカルディに匹敵し、他のエンドツーエンドのASRシステムよりも優れた結果です。PyChainは、完全に並列化されたPyTorch実装であり、エンドツーエンドの格子フリー最大相互情報（LF-MMI）トレーニングを実装します。カルディ自動音声認識（ASR）ツールキットでは\ emph {チェーンモデル}と呼ばれています。 
[ABSTRACT] pychainは、可能な限り柔軟で軽量になるように設計されています。新しいasrプロジェクトまたは他の既存のpytorchベースのasrツールに簡単にプラグインできます。wsjデータセットの実験は、pychainが同等の競争力のある結果を達成できることを示していますカルディへ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Further Study of Unsupervised Pre-training for Transformer Based
  Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/eess.AS/paper_16.html">
      A Further Study of Unsupervised Pre-training for Transformer Based
  Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーでは、MPCについてさらに調査を行い、3つの重要な側面に焦点を当てます。事前トレーニングデータの発話スタイルの影響、ストリーミングモデルへの拡張、および事前トレーニングステージからダウンストリームタスクに学習した知識をより適切に転送する方法。 。優れた音声認識システムを構築するには、通常、大量の文字起こしデータが必要であり、収集にはコストがかかります。APCとMPCを使用した統合トレーニング目標により、HKUSTでトレーニングされたストリーミングモデルで8.46％の相対エラーが削減されました。 
[要約]多くの教師なし事前トレーニング方法が提案されています。これらには、これらのタイプの音声ベースの音声認識と音声認識が含まれます。しかし、mpcの一部の側面は完全には調査されていません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Consistent ICA: Determined BSS meets spectrogram consistency -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/eess.AS/paper_17.html">
      Consistent ICA: Determined BSS meets spectrogram consistency
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、スペクトログラム整合性と呼ばれる時間周波数領域表現の一般的なプロパティが順列問題を解決するための助力となり得ることを示しています。通常、フィルターは各周波数を個別に処理するため、よく知られている順列問題が発生します。 、つまり、各分離コンポーネントが対応するソースに正しく割り当てられるように、周波数ごとのフィルターを調整する方法の問題。決定された状況でのマルチチャネルオーディオブラインドソース分離（BSS）（マイクの数は、ソース）、または決定されたBSSは、時間-周波数領域でマルチチャネル線形フィルタリングによって実行され、畳み込みミキシングプロセスを処理します。 
[ABSTRACT]フィルターは問題を解決するために各周波数を処理します。問題はよく知られている順列問題を引き起こします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Reduced expression of TCF7L2 in adipocyte impairs glucose tolerance associated with decreased insulin secretion, incretins levels and lipid metabolism dysregulation in male mice -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/biorxiv.physiology/paper_0.html">
      Reduced expression of TCF7L2 in adipocyte impairs glucose tolerance associated with decreased insulin secretion, incretins levels and lipid metabolism dysregulation in male mice
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ここでは、成熟した脂肪細胞におけるTCF7L2発現の変化がグルコースの恒常性にどのように影響するかを調査することを目的としています。成体脂肪細胞のグルコースおよび脂質代謝におけるTCF7L2の正確な役割は、まだ定義されていません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Spontaneous restoration of functional β-cell mass in obese SM/J mice -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/biorxiv.physiology/paper_1.html">
      Spontaneous restoration of functional β-cell mass in obese SM/J mice
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      膵臓切片の免疫染色は、肥満SM / Jマウスが選択的に{ベータ}細胞量を増加させるが、-細胞量を増加させないことを明らかにします。機能的な{ベータ}細胞量の維持は、糖尿病を防ぐために重要ですが、{ベータ}を引き起こす生理学的メカニズム肥満のコンテキストで繁栄または失敗する細胞集団は不明です。ここでは、SM / Jの糖尿病の寛解時のインスリンのホメオスタシス、島の形態、および{ベータ}細胞の機能を特徴付けます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Protective role of neuronal and lymphoid cannabinoid CB2 receptors in neuropathic pain -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/biorxiv.physiology/paper_2.html">
      Protective role of neuronal and lymphoid cannabinoid CB2 receptors in neuropathic pain
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ニューロン、単球、または構成的にCB2rを欠く野生型およびノックアウトマウスで、選択的CB2rアゴニストJWH133をオンデマンドで自己投与することにより、自発的な神経因性疼痛を調査しました。単球特異的CB2rノックアウトで変更され、神経性CB2rノックアウトに欠陥のあるマウスで増加した。自発痛の増加を示唆している。 
[ABSTRACT] cb2r-陽性のリンパ節が損傷した神経に浸潤しました。神経因性疼痛におけるこれらの細胞へのcb2rの関与は未解決のままです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Prostaglandin in the ventromedial hypothalamus regulates peripheral glucose metabolism -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-21/biorxiv.physiology/paper_3.html">
      Prostaglandin in the ventromedial hypothalamus regulates peripheral glucose metabolism
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのデータは、cPLA2を介した視床下部リン脂質代謝がRCD中の全身性グルコース代謝を制御するために重要であるのに対し、HFD中にプロスタグランジンを生成する同じ経路の継続的な活性化は、グルコース代謝を悪化させることを示唆しています。リン脂質からアラキドン酸を生成し、視床下部腹内側核（VMH）で、通常の固形飼料（RCD）給餌中に筋肉のインスリン感受性を低下させました。 
[要約]脳はポリ不飽和脂肪酸を含むリン脂質で強化されています。糖鎖が生理的調節において生物学的に活性であることを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
