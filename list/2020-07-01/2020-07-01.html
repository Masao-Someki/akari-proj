<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-07-01の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Encoding Musical Style with Transformer Autoencoders -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.SD/paper_0.html">
      Encoding Musical Style with Transformer Autoencoders
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このグローバル表現を他の時間的に分散した埋め込みと組み合わせることが可能であることを示し、パフォーマンススタイルとメロディの個別の側面の制御を改善できるようにします。経験的に、MAESTROデータセットと10,000時間以上のピアノ演奏を含むYouTubeデータセット。ベースラインと比較して、対数尤度と平均リスニングスコアが向上しています。特に、生成されたシーケンスのグローバル構造に対する高レベルの制御の学習の問題を考慮しています。複雑な言語モデルによる象徴的な音楽生成のコンテキスト。 
[ABSTRACT]トランスフォーマオートエンコーダは、時間の経過とともにビジュアル表現を集約します。さまざまなパフォーマンスからスタイルのグローバル表現を取得することが可能です。このメソッドは、人々がさまざまな音楽を視覚化するのに役立ちます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-10">
        <br>2019-12-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ASVspoof 2019: A large-scale public database of synthesized, converted
  and replayed speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.SD/paper_1.html">
      ASVspoof 2019: A large-scale public database of synthesized, converted
  and replayed speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      論理アクセス（LA）シナリオ内のスプーフィング攻撃は、最新の音声合成および音声変換技術（最先端の神経音響および波形モデル技術を含む）で生成されます。また、論理アクセスにおけるスプーフィングされたデータに対する人間の評価についても説明します。 .. ASVspoof 2019データベースのスプーフィングデータは、人間の被験者によっても真実の発話と区別できないスプーフィングデータを含め、知覚される品質と対象話者との類似度がさまざまであることが実証されました。 
[ABSTRACT] asvはスプーフィングに対して脆弱であり、「プレゼンテーション攻撃」としても知られています。asvシステムは、再生、音声合成、および音声変換攻撃に対しても脆弱です。これらのシステムは、2つの特定のユースケースシナリオで探索されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-05">
        <br>2019-11-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Speech Enhancement Algorithm based on Non-negative Hidden Markov Model
  and Kullback-Leibler Divergence -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.SD/paper_2.html">
      A Speech Enhancement Algorithm based on Non-negative Hidden Markov Model
  and Kullback-Leibler Divergence
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      より具体的には、従来のNMFベースの音声強調方法と比較して、提案されたアルゴリズムは、短時間の客観的了解度（STOI）を5 \％改善し、音声品質の知覚評価（PESQ）を0.18改善します。提案されたアルゴリズムは客観的測定によって検証されます。トレーニング段階では、KL発散測定につながるポアソンの合計が、HMMの各状態の観測モデルとして使用されます。 
[要約]音声強調のために提案された戦略は以前の方法と比較されました。これは、音声強調が提案されたモデルの観察に使用できることを意味します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br>2020-06-30
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Neural Machine Translation with Noisy Lexical Constraints -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.CL/paper_0.html">
      Neural Machine Translation with Noisy Lexical Constraints
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このような実用的なシナリオでこれらのノイズの多い制約を操作する方法については未だ未解決の問題です。実験により、我々のアプローチがノイズの多い制約の処理でBLEUの大幅な向上を達成できることが実証されています。これらの結果は、制約がある新しいシナリオに提案されたアプローチを適用する動機を与えますユーザーの助けなしに生成されます。 
[要約]新しい研究は、制約を外部記憶として扱う新しいフレームワークを提示することを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-13">
        <br>2019-08-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: PLATO-2: Towards Building an Open-Domain Chatbot via Curriculum Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.CL/paper_1.html">
      PLATO-2: Towards Building an Open-Domain Chatbot via Curriculum Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      PLATO-2は中国語と英語の両方のデータでトレーニングされ、その有効性と優位性は包括的な評価を通じて検証され、新しい最先端の結果が得られます。学習プロセスには2つの段階があります。2番目の段階では、きめの細かい生成モデルと評価モデルは、多様な応答生成と応答コヒーレンス推定をそれぞれ学習するようにさらにトレーニングされます。 
[要約]学習プロセスには2つの段階があります。1つの段階は、きめの細かい生成モデルと評価モデルです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br>2020-06-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ERNIE-ViL: Knowledge Enhanced Vision-Language Representations Through
  Scene Graph -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.CL/paper_2.html">
      ERNIE-ViL: Knowledge Enhanced Vision-Language Representations Through
  Scene Graph
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      したがって、ERNIE-ViLは、ビジョンと言語にわたる詳細なセマンティクスのアラインメントを特徴付ける共同表現をモデル化できます。ERNIE-ViLを微調整した後、5つのビジョン言語のダウンストリームタスクで最先端のパフォーマンスを実現します。具体的には、これらの予測タスクは、センテンスから解析されたシーングラフ内のさまざまなタイプのノードを予測することによって実装されます。 
[ABSTRACT] ernie-vilは詳細なセマンティックコネクションを開発しました。これらには、オブジェクト、オブジェクトの属性、オブジェクト間の関係が含まれます。これらは、ビジョン-言語のクロスモーダルタスクに不可欠です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br>2020-06-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Decomposing Word Embedding with the Capsule Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.CL/paper_3.html">
      Decomposing Word Embedding with the Capsule Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CapsDecE2Sをトレーニングするために、センスマッチングトレーニング方法を提案します。このアプローチでは、教師なしのあいまいな埋め込みがカプセルネットワークに供給され、意味の基本的な意味言語単位として定義される複数の形態素のようなベクトルが生成されます。単語の感覚曖昧性除去は、特定のコンテキストでのあいまいな単語の適切な意味を学習しようとします。 
[ABSTRACT]教師なし単語embedding.capsdece2sを分解する新しいシステムは、単語コンテキストを統合して、複数の形態素を再構築します-フロートをコンテキストに組み込みます-特定の意味の埋め込み
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving GAN Training with Probability Ratio Clipping and Sample
  Reweighting -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.CL/paper_4.html">
      Improving GAN Training with Probability Ratio Clipping and Sample
  Reweighting
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのアプローチは、変分的な視点でのGANと強化学習の接続に触発されています。このアプローチの収束に関する理論的分析を提供します。この接続により、（1）発生率のトレーニングを正規化して過度に大きな更新を防ぐ確率比クリッピングが発生します。 （2）品質の悪い偽サンプルを軽視することによって弁別器訓練を安定させるサンプル再重み付けメカニズム。 
[ABSTRACT]優れたトレーニングの安定性を享受する新しいバリエーションガントレーニングフレームワークを提案します。接続により、ジェネレータートレーニングを正規化して確率が大きくなりすぎて更新が過度に行われるのを防ぐクリッピングにつながります。悪い品質を軽視して弁別トレーニングを安定させるサンプルの再重み付けメカニズム偽のサンプル
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-12">
        <br>2020-06-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: GShard: Scaling Giant Models with Conditional Computation and Automatic
  Sharding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.CL/paper_5.html">
      GShard: Scaling Giant Models with Conditional Computation and Automatic
  Sharding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      GShardを使用すると、自動シャーディングを使用して、6千億を超えるパラメーターがスパースゲーティングされたエキスパート混合で多言語のニューラル機械翻訳トランスフォーマーモデルをスケールアップできます。このような巨大なモデルは、2048 TPU v3アクセラレーターで4日間で効率的にトレーニングできることを示しています。先行技術と比較して100言語から英語への翻訳ではるかに優れた品質を実現します。GShardは、軽量注釈APIのセットとXLAコンパイラの拡張で構成されるモジュールです。 
[要約]巨大なモデルを2048 tpu v3アクセラレータで4日間効率的にトレーニングして、100言語から英語への翻訳ではるかに優れた品質を実現できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br>2020-06-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to Read through Machine Teaching -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.CL/paper_6.html">
      Learning to Read through Machine Teaching
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このシーケンス最適化問題が、時変分布全体の最適化、つまり、トレーニングのさまざまなステップでの単語の確率分布を定義する方法として提示できる方法を示します。次に、確率勾配降下法を使用して、最適な時変分布と対応する最適なトレーニングを見つけます。シーケンス..声を出して単語を読むことを学ぶことは、読者になるための主要なステップです。 
[ABSTRACT]多くの子供が英語のスペルの不一致のために課題に苦労しています-健全な対応。子供は限られた時間内にシステムを習得することが期待されています（学習4による）。これは、適度な数の学習試行でも難しい組み合わせの失敗です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br>2020-06-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Data-driven Neural Network Architecture for Sentiment Analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.CL/paper_7.html">
      A Data-driven Neural Network Architecture for Sentiment Analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、歌の感情の2つの大きなデータセットの作成手順を示します。結果から、最大3つのフィルター長の並列たたみ込みで通常、関連するテキストの特徴をキャプチャするのに十分であることがわかります。 6〜18。
[要約]これは、摂食ネットワークに十分なデータを見つけるのが困難です。また、歌の歌詞、製品、映画のレビューテキストデータセットでの畳み込みと最大プーリングニューラルレイヤーの使用法についても調査します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br>2020-06-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Non-Autoregressive Machine Translation with Disentangled Context
  Transformer -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.CL/paper_8.html">
      Non-Autoregressive Machine Translation with Disentangled Context
  Transformer
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さまざまなデータサイズの7つの翻訳方向に関する広範な実験は、非自己回帰機械翻訳の最新技術と比較して、モデルが優れたとは言えないにしても、平均でデコード時間を大幅に削減しながら、競争力のあるパフォーマンスを達成することを示しています。簡単な最初の推論アルゴリズム。すべてのトークンを並行して反復的に調整し、必要な反復の数を減らします。コードはhttps://github.com/facebookresearch/DisCoで入手できます。 
[ABSTRACT]ディスコマスカーは、他の参照トークンの任意のサブセットが指定されたすべての出力トークンを予測するようにトレーニングされています。調査によると、私たちのモデルは、非自己回帰機械翻訳の最先端技術と比較して、優れたパフォーマンスではないにしても、ステップパフォーマンスを達成しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-15">
        <br>2020-01-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SE3M: A Model for Software Effort Estimation Using Pre-trained Embedding
  Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.CL/paper_9.html">
      SE3M: A Model for Software Effort Estimation Using Pre-trained Embedding
  Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      単一のプロジェクトリポジトリで事前調整されたBERTモデルを微調整して適用した結果を強調表示します。その値は平均絶対誤差（MAE）が4.25であり、標準偏差はわずか0.17です。これは、結果は非常に有望で、事前トレーニング済みの組み込みモデルを使用して、要件テキストのみに基づいてソフトウェアの作業を推定できることがわかりました。生成されたモデルは、適用されたディープラーニングアーキテクチャの入力として、線形出力で使用されました。 。 
[要約]このペーパーでは、事前トレーニング済みの埋め込みモデルの有効性を評価することを提案しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br>2020-06-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Rethinking Positional Encoding in Language Pre-training -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.CL/paper_10.html">
      Rethinking Positional Encoding in Language Pre-training
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この設計は、ノイズの多い単語と位置の相関を取り除き、さまざまな射影行列を使用して、単語/位置間の関係を特徴付ける表現力を高めます。位置情報をニューラルネットワークに明示的にエンコードする方法は、自然言語処理で重要な問題です。特に、 30％のトレーニング前の計算コストのみを使用しながら、ベースラインよりも高いスコアを達成できます。 
[ABSTRACT]デザインにより、ノイズの多い単語と位置の問題の相関関係が削除されます。単語/位置間の関係を特徴付ける表現力が高まります。tupeは、ほぼすべてのタスクのベースラインを大幅に上回っています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-28">
        <br>2020-06-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Correction of Faulty Background Knowledge based on Condition Aware and
  Revise Transformer for Question Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.CL/paper_11.html">
      Correction of Faulty Background Knowledge based on Condition Aware and
  Revise Transformer for Question Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CAR-Transformerは、（1）会話全体と元の条件値に基づいて各条件値を修正し、（2）修正された条件をエンコードし、埋め込んだ条件を利用して回答を選択します。不良条件値の影響を軽減するために、これはペーパーは条件を認識して修正するトランスフォーマー（CAR-Transformer）を提案します。実際のカスタマーサービスデータセットの実験結果は、CARトランスフォーマーが質問に対応する条件が間違っているか欠落している値が存在する場合でも適切な応答を選択できることを示しています。自動および人間の評価でベースラインモデルより優れています。 
[ABSTRACT]提案されたカートランスフォーマーは、条件付け情報を考慮する必要がある他のnlpタスクに拡張できます。既存の質問応答システムは、カテゴリ属性や知識ベースのトリプルなどの外部情報を考慮しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br>2020-06-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Technical Report: Auxiliary Tuning and its Application to Conditional
  Text Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.CL/paper_12.html">
      Technical Report: Auxiliary Tuning and its Application to Conditional
  Text Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの方法は、トレーニングに使用するリソースを大幅に減らしながら、いくつかの異なるタスクをゼロからトレーニングするのと同様の結果を達成しました。キーワードで条件付けされたテキスト生成の特定の例を共有します。この方法は、補助アーキテクチャに制約を課しません。補助モデルは、事前訓練されたモデルロジットにロジットを追加し、ターゲットタスクの出力の可能性を最大化することによって訓練されます。 
[要約]ターゲットタスクに応じて出力分布をシフトする補助モデルを条件としたアプローチ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br>2020-06-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Graph-based, Self-Supervised Program Repair from Diagnostic Feedback -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.CL/paper_13.html">
      Graph-based, Self-Supervised Program Repair from Diagnostic Feedback
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      導入アプローチの修正（DeepFixデータセット）とプログラム合成の出力の修正（SPoCデータセット）の2つのアプリケーションで提案されたアプローチを評価します。最終システムのDrRepairは、以前の作業を大幅に上回り、DeepFixで68.2％の完全な修復率を達成します（ + 22.9％（前回より最高）、および48.4％のSPoCでの合成成功率（+ 3.7％（前回より最高））。第二に、プログラムの修復に使用できるラベル付きデータセットは比較的小さいです。 
[ABSTRACT]プログラムの修復は2つの理由で困難です。ソースコードと診断フィードバック全体にわたって、推論と追跡のシンボルが必要です。システム、drrepairは、以前の作業を大幅に上回っており、deepfixで68. 2％の完全な修復率、48。4％を達成しています。 spocでの合成成功率
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br>2020-05-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Attention-Based Neural Networks for Sentiment Attitude Extraction using
  Distant Supervision -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.CL/paper_14.html">
      Attention-Based Neural Networks for Sentiment Attitude Extraction using
  Distant Supervision
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      態度抽出の問題は、ドキュメント全体の2クラス（ポジティブ、ネガティブ）および3クラス（ポジティブ、ネガティブ、ニュートラル）の分類タスクと見なされます。また、用語タイプに応じた注意の重み分布の分析も提供します。 。私たちの研究では、ロシア語の分析テキストであるRuSentRelのコーパスを利用し、トレーニングセットを充実させるために自動的にニュースコレクションRuAttitudesを構築しました。 
[ABSTRACT]私たちの研究では、ロシア語の分析テキストrusentrelのコーパスを利用しています。これらは、トレーニングセットを充実させるために、ニュースコレクションのルート度を自動的に構築しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-23">
        <br>2020-06-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Sequence Tagging for Vietnamese Text Using Transformer-based
  Neural Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.CL/paper_15.html">
      Improving Sequence Tagging for Vietnamese Text Using Transformer-based
  Neural Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      コードと事前トレーニング済みモデルviBERTとvELECTRAは、採用とさらなる調査を容易にするオープンソースとしてリリースされています。特に、VLSP 2010コーパスでは品詞タグ付けの精度を95.40％に、96.77％にプッシュしました。 VLSP 2013コーパス。また、名前付きエンティティ認識のF1スコアは、VLSP 2016コーパスでは94.07％、VLSP 2018コーパスでは90.31％です。このペーパーでは、ベトナム語のシーケンスタグ付けタスクを改善するための複数言語BERT埋め込みといくつかの新しいニューラルモデルの使用に関する研究について説明します。言語。 
[ABSTRACT]新しいモデルアーキテクチャは、vlsp 2016とvlsp 2018の2つの名前付きエンティティ認識データセットに基づいています。パートパースピーチのタグ付けの精度を95にプッシュしました。vlsp2010コーパスでは40％、96.77％にはvlsp 2013コーパス
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-29">
        <br>2020-06-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to cooperate: Emergent communication in multi-agent navigation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.CL/paper_16.html">
      Learning to cooperate: Emergent communication in multi-agent navigation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      エージェントのポリシーを分析すると、緊急信号が状態空間を空間的にクラスター化し、「左」、「上」、「左上の部屋」などの特定の場所や空間方向を参照する信号があることがわかります。エージェントの集団を使用して、出現するプロトコルは基本的な構成構造を持ち、自然言語のコアプロパティを示すことを示しています。人工エージェントでの創発的コミュニケーションは、言語の進化を理解し、人間とのコミュニケーションを学ぶ人工システムを開発するために研究されています。 
[ABSTRACT]特定のタスクを実行するエージェントが解釈可能な通信プロトコルを学習することを示します。これにより、エージェントはタスクに応答し、多くの場合、最適にタスクを解決できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-02">
        <br>2020-04-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Predicting Subjective Features from Questions on QA Websites using BERT -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/cs.CL/paper_17.html">
      Predicting Subjective Features from Questions on QA Websites using BERT
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      したがって、Q＆A Webサイトでモデレートアクションを自動化するソリューションを提供することを全体的な目標として、QA Webサイトでの質問の20の品質または主観的な側面を予測するモデルを提供することを目指しています。平均二乗誤差（MSE）による評価に基づいて、モデルは2エポックのトレーニング後に0.046の値を達成しましたが、次のエポックでは大幅に改善されませんでした。結果は、単純な微調整によって、短時間で、より少ないデータ量で正確なモデルを達成できることを確認しています。 
[ABSTRACT]ユーザーは主にコミュニティレポートに依存してコンテンツを評価しています。これには、通常のユーザーと経験豊富なユーザーの時間の損失、一部のレポートの質の低下、新しいユーザーへのフィードバックの妨げなど、深刻な問題があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-24">
        <br>2020-02-24
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Encoding Musical Style with Transformer Autoencoders -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/eess.AS/paper_0.html">
      Encoding Musical Style with Transformer Autoencoders
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このグローバル表現を他の時間的に分散した埋め込みと組み合わせることが可能であることを示し、パフォーマンススタイルとメロディの個別の側面の制御を改善できるようにします。経験的に、MAESTROデータセットと10,000時間以上のピアノ演奏を含むYouTubeデータセット。ベースラインと比較して、対数尤度と平均リスニングスコアが向上しています。特に、生成されたシーケンスのグローバル構造に対する高レベルの制御の学習の問題を考慮しています。複雑な言語モデルによる象徴的な音楽生成のコンテキスト。 
[ABSTRACT]トランスフォーマオートエンコーダは、時間の経過とともにビジュアル表現を集約します。さまざまなパフォーマンスからスタイルのグローバル表現を取得することが可能です。このメソッドは、人々がさまざまな音楽を視覚化するのに役立ちます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-10">
        <br>2019-12-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ASVspoof 2019: A large-scale public database of synthesized, converted
  and replayed speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/eess.AS/paper_1.html">
      ASVspoof 2019: A large-scale public database of synthesized, converted
  and replayed speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、2019年版の新機能はタンデム検出コスト関数メトリックの使用です。これは、固定ASVシステムの信頼性に対するスプーフィングと対策の影響を反映しています。ASVspoof2019データベースのスプーフィングデータの程度はさまざまであることが実証されました人間の被験者によっても真実の発話と区別できないスプーフィングされたデータを含む、知覚された品質とターゲットスピーカーとの類似性。ASVspoof2019エディションは、単一のチャレンジ内で3つすべてのスプーフィング攻撃タイプを最初に検討します。 
[ABSTRACT] asvはスプーフィングに対して脆弱であり、「プレゼンテーション攻撃」としても知られています。asvシステムは、再生、音声合成、および音声変換攻撃に対しても脆弱です。これらのシステムは、2つの特定のユースケースシナリオで探索されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-05">
        <br>2019-11-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Speech Enhancement Algorithm based on Non-negative Hidden Markov Model
  and Kullback-Leibler Divergence -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/eess.AS/paper_2.html">
      A Speech Enhancement Algorithm based on Non-negative Hidden Markov Model
  and Kullback-Leibler Divergence
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      より具体的には、従来のNMFベースの音声強調方法と比較して、提案されたアルゴリズムは、短時間の客観的了解度（STOI）を5 \％改善し、音声品質の知覚評価（PESQ）を0.18改善します。トレーニング段階、KL発散測度につながるポアソンの合計は、HMMの各状態の観測モデルとして使用されます。提案されたアルゴリズムのパフォーマンスは、客観的な測度によって検証されます。 
[要約]音声強調のために提案された戦略は以前の方法と比較されました。これは、音声強調が提案されたモデルの観察に使用できることを意味します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br>2020-06-30
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: The effect of delayed processing on ovarian tissue stored for fertility preservation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/biorxiv.physiology/paper_0.html">
      The effect of delayed processing on ovarian tissue stored for fertility preservation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      所見：合計1541個の卵胞を分析しました。組織は凍結保存または10日間の異種移植後に新鮮に固定されました。 
[要約] 24時間の処理遅延は、新鮮な組織または凍結保存された組織のpfの健康には影響しなかった
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br>2020-06-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Active integrins regulate white adipose tissue insulin sensitivity and brown fat thermogenesis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/biorxiv.physiology/paper_1.html">
      Active integrins regulate white adipose tissue insulin sensitivity and brown fat thermogenesis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      線維症は脂肪機能障害と炎症の重要な特徴であるのに対し、細胞外マトリックスの再編成は健康な脂肪組織の拡大に必須です。基質送達の増加、内皮基底膜の厚みの減少、および内皮小胞輸送の増加。 
[要約]障害のある細胞の直接的な影響についてはほとんど知られていない-脂肪細胞機能とインスリン感受性におけるマトリックス相互作用
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br>2020-06-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Changes to zonular tension alters the subcellular distribution of AQP5 in regions of influx and efflux of water in the rat lens. -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-01/biorxiv.physiology/paper_2.html">
      Changes to zonular tension alters the subcellular distribution of AQP5 in regions of influx and efflux of water in the rat lens.
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      キーワード：水晶体、水輸送、免疫組織化学、AQP0、AQP1、AQP5、小帯張力..小帯張力は、トロピカミド（増加）またはピロカルピン（減少）のいずれかを適用することによって薬理学的に調節されました。目的：レンズは、イオンと水の循環フラックスを利用します。両極からレンズに入り、赤道から出て、光学特性を維持します。 
[要約]これらの水の流入と流出ゾーンにおけるレンズアクアポリン（aqp0、1、および5）の細胞内分布をマッピングしました。トロピカミド極と毛様体極のいずれかを適用することにより、方法を薬理学的に調整しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br>2020-06-30
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
