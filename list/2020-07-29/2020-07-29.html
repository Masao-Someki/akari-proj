<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-07-29の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Dual-Path Transformer Network: Direct Context-Aware Modeling for
  End-to-End Monaural Speech Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.SD/paper_0.html">
      <font color="black">Dual-Path Transformer Network: Direct Context-Aware Modeling for
  End-to-End Monaural Speech Separation</font>
    </a>
  </h2>
  <font color="black">さらに、デュアルパスの構造により、非常に長い音声シーケンスモデリングでモデルが効率的になります。ベンチマークデータセットでの広範囲な実験により、このアプローチが現在の最先端技術（パブリックWSj0-2mixデータで20.6 dB SDR）を上回ることが示されていますコーパス）..改良されたトランスフォーマーを導入することにより、音声シーケンスの要素が直接相互作用できるようになり、DPTNetが直接コンテキスト認識を使用して音声シーケンスをモデル化できるようになります。 
[要約]エンドツーエンドのスピーチ分離のためのデュアルパストランスフォーマーネットワーク（dptnet）。これにより、直接的なコンテキストが導入され、スピーチシーケンスのモデリングに認識がもたらされます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Voice activity detection in the wild via weakly supervised sound event
  detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.SD/paper_1.html">
      <font color="black">Voice activity detection in the wild via weakly supervised sound event
  detection</font>
    </a>
  </h2>
  <font color="black">3つの異なる評価プロトコル（クリーン、合成ノイズ、実際のデータ）でCRNNベースの標準VADモデル（VAD-C）に対して2つのGPVモデルを評価します。結果は、提案されたGPV-Fがクリーンおよび合成シナリオで競争力のあるパフォーマンスを示すことを示しています。従来のVAD-Cと比較して。さらに、実際の評価では、GPV-Fはフレームレベルの評価指標とセグメントレベルの評価指標の点でVAD-Cを大幅に上回っています。これとは対照的に、私たちは汎用のVAD（GPVAD）フレームワークを提案します。クリップレベルのラベルのみを必要とする、弱く監視された方法でノイズの多いデータから簡単にトレーニングできます。 
[要約] 2つのgpvadモデルを提案しました。1つはフル（gpv -f）、527個のオーディオセットサウンドイベントでトレーニングされ、1つはバイナリ（gpv）で、音声とノイズのみを区別します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-27">
        <br><font color="black">2020-03-27</font>
      </time>
    </span>
</section>
<!-- paper0: A Comparative Study of Multilateration Methods for Single-Source
  Localization in Distributed Audio -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.SD/paper_2.html">
      <font color="black">A Comparative Study of Multilateration Methods for Single-Source
  Localization in Distributed Audio</font>
    </a>
  </h2>
  <font color="black">これらの方法は、計算効率が高く、信号に依存せず、感知ノードの数とその空間配置に関して柔軟です。関連する参考文献の調査に加えて、いくつかの「主流」のマルチラテレーションの小規模ベンチマークの結果を提示します。社内のルームインパルス応答データセットに基づくアルゴリズム。この記事では、最新のマルチラテレーション（範囲の差の観測によって可能になるローカリゼーション手法のファミリ）を分析します。 
[ABSTRACT]これらの方法は、人工的に効率的で、信号が遅れ、柔軟です。ただし、センシングノードの数とその空間配置に関しては、より効率的でマルチタスクです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-23">
        <br><font color="black">2019-10-23</font>
      </time>
    </span>
</section>
<!-- paper0: Direct Modelling of Speech Emotion from Raw Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.SD/paper_3.html">
      <font color="black">Direct Modelling of Speech Emotion from Raw Speech</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、提案されたモデルがIEMOCAPとMSP-IMPROVデータセットの両方からハンドエンジニアリングされた機能でトレーニングされたCNNのパフォーマンスに到達できることを示唆しています。このホワイトペーパーでは、生の感情認識のパフォーマンスを改善する機会がまだあることを示します。コンテキスト情報のモデル化でCNNのプロパティを利用して音声を生成します。これにより、特にディープラーニングニューラルネットワークを使用して生の音声から表現を学習するという新たな傾向が加速しています。 
[要約] cnnsと長期短期記憶（lstm）は、感情認識に重要なコンテキスト情報を学習する際のlstmの本質的な特性を牽引しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-08">
        <br><font color="black">2019-04-08</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Attentive Multi-Layer Aggregation with Feature Recalibration and
  Normalization for End-to-End Speaker Verification System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.SD/paper_4.html">
      <font color="black">Self-Attentive Multi-Layer Aggregation with Feature Recalibration and
  Normalization for End-to-End Speaker Verification System</font>
    </a>
  </h2>
  <font color="black">次に、完全に接続されたレイヤーと非線形アクティブ化関数を使用して、集合体フィーチャーにフィーチャー再キャリブレーションレイヤーが適用されます。モデルパラメーターの数を減らすために、チャネル幅とレイヤー深度をスケーリングしたResNetがベースラインとして使用されます。トレーニングの変動性を制御するために、自己注意メカニズムが適用され、ドロップアウトの正規化とバッチの正規化を使用して多層集約を実行します。 
[ABSTRACT]ショートカット接続により、スピーカーの埋め込みの表現力が向上します。そのため、エンドツーエンドのエンドツーエンドのスピーカー検証システム用の自己注意深い多層集合体を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Kalman Filtering for Speech Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.SD/paper_5.html">
      <font color="black">Neural Kalman Filtering for Speech Enhancement</font>
    </a>
  </h2>
  <font color="black">監視付き共同トレーニングをNKFに適用して、WFによって行われる瞬時線形推定とRNNによって行われる長期非線形推定との間の自動トレードオフを学習します。さまざまなノイズ条件での実験により、提案された方法が客観的評価指標と自動音声認識（ASR）単語誤り率（WER）の両方に関するベースライン手法。統計信号処理に基づく音声強調手法は、専門家の知識を利用して、深層ニューラルを補完する統計モデルと線形フィルターを設計します。データ駆動型のネットワーク（DNN）ベースのメソッド。 
[要約]提案された方法は、音声強調のための新しいシステムの構築を支援するために使用できます。また、ニューラルカルマンフィルタリング（nkf）にも使用できます。また、ニューラルカルマンフィルター（nkf&#39;s）にも採用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Adversarial Domain Adaptation for Cross-Lingual Speech
  Emotion Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.SD/paper_6.html">
      <font color="black">Unsupervised Adversarial Domain Adaptation for Cross-Lingual Speech
  Emotion Recognition</font>
    </a>
  </h2>
  <font color="black">したがって、このホワイトペーパーでは、多言語SERの生成的敵対的ネットワーク（GAN）ベースのモデルを提案します。この結果は、提案されたモデルが、非主流を含むすべての検討対象データセットのベースラインのクロスリンガルSERパフォーマンスを大幅に改善できることを示しています。ラベルを必要としないウルドゥー語の言語データ。SERシステムのパフォーマンスは、トレーニングデータとテストデータの分布の違いによって低下することがよくあります。 
[ABSTRACT]たとえば、serシステムの実際のアプリケーションに適合できる、より堅牢なモデルを構築する必要があります。私たちの言語モデルは、基礎となるデータ分布の学習での大きな成功が動機です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-13">
        <br><font color="black">2019-07-13</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervised Neural Audio-Visual Sound Source Localization via
  Probabilistic Spatial Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.SD/paper_7.html">
      <font color="black">Self-supervised Neural Audio-Visual Sound Source Localization via
  Probabilistic Spatial Modeling</font>
    </a>
  </h2>
  <font color="black">この問題を解決するために、このペーパーでは、360 {\ deg}画像とマルチチャネルオーディオ信号を使用した自己監視トレーニング方法を紹介します。画像内の音源オブジェクトの位置を特定するためのシステムは、音声および視覚DNNで構成されています。音源オブジェクトの検出自律ロボットが周囲の環境を理解するためには、目視観察内が重要です。 
[要約]私たちの方法は、複数の音源オブジェクトを区別するためにディープニューラルネットワーク（dnns）をトレーニングします。視覚的なdnnは、入力画像内の音源候補を特定するようにトレーニングされます。これらのdnnは、確率的空間に基づいて、自己監視方式で共同トレーニングされます音声モデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: A Hybrid Approach to Audio-to-Score Alignment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.SD/paper_8.html">
      <font color="black">A Hybrid Approach to Audio-to-Score Alignment</font>
    </a>
  </h2>
  <font color="black">標準の位置合わせ方法はダイナミックタイムワーピング（DTW）に基づいており、手作りの機能を採用しています。DTWベースの自動位置合わせ方法の前処理ステップとしてニューラルネットワークの使用法を検討します。さまざまな音響条件からの音楽データの実験により、この方法が実証されています同時に適応可能でありながら、堅牢な配置を生成します。 
[ABSTRACT]標準的な位置合わせ方法は、動的タイムワーピング（dtw）に基づいており、自動スタイル機能を採用しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Siamese x-vector reconstruction for domain adapted speaker recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.SD/paper_9.html">
      <font color="black">Siamese x-vector reconstruction for domain adapted speaker recognition</font>
    </a>
  </h2>
  <font color="black">ただし、条件（ノイズ、サンプルレートなど）を記録すると、精度は大幅に低下します。リーン補助シャムDNNを使用して、低品質の対応物からの高品質信号の埋め込みを再構築します。ドメイン適応のためのシャムxベクトル再構築（SVR）を導入します。 
[ABSTRACT] x-シナリオはディープニューラルネットワーク（dnn）に基づいています。リーン補助を使用して、より高品質の信号の埋め込みを再構築します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Statistical and Neural Network Based Speech Activity Detection in
  Non-Stationary Acoustic Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.SD/paper_10.html">
      <font color="black">Statistical and Neural Network Based Speech Activity Detection in
  Non-Stationary Acoustic Environments</font>
    </a>
  </h2>
  <font color="black">統計的SADは、以前に提案されたニューラルネットワークベースのSADに匹敵する検出性能を実現しますが、ニューラルネットワークベースのアプローチは、2020年のフィアレスステップチャレンジの評価セットで1.07％の決定コスト関数につながり、新しい最先端技術を設定します。 。音響シーンの時間変化により音声とノイズを区別することが困難になるため、非定常環境では、ノイズが音声よりも「定常的」であるという事実にしばしば依存する音声アクティビティ検出（SAD）が特に困難です。 ..前者は、高度な信号処理を使用してノイズと音声のエネルギーを追跡し、リソース効率が高く、監視されていない信号処理アプローチのケースをサポートすることを目的としています。 
[要約] sadには2つのアプローチがあり、1つは統計的信号処理に基づいています。もう1つは、入力音声の短いセグメントで動作するリカレントネットワークレイヤーを導入します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br><font color="black">2020-05-20</font>
      </time>
    </span>
</section>
<!-- paper0: MCSAE: Masked Cross Self-Attentive Encoding for Speaker Embedding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.SD/paper_11.html">
      <font color="black">MCSAE: Masked Cross Self-Attentive Encoding for Speaker Embedding</font>
    </a>
  </h2>
  <font color="black">MCSAEでは、クロス自己注意モジュールは、各入力フィーチャの相互依存性をトレーニングします。ランダムマスキング正則化モジュールは、過適合問題を防ぐためにも適用されます。これらは、以前の自己注意型エンコーディングおよび状態-artエンコーディング方法。 
[ABSTRACT]これはマルチレイヤの集約に基づいています。各残余レイヤの出力機能はmcsaeに使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-28">
        <br><font color="black">2020-01-28</font>
      </time>
    </span>
</section>
<!-- paper0: Variational Autoencoders for Learning Latent Representations of Speech
  Emotion: A Preliminary Study -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.SD/paper_12.html">
      <font color="black">Variational Autoencoders for Learning Latent Representations of Speech
  Emotion: A Preliminary Study</font>
    </a>
  </h2>
  <font color="black">IEMOCAPデータセットの評価は、VAEによって学習された機能が音声感情分類の最先端の結果を生成できることを示しています。教師なしでデータの潜在表現を学習することは、パフォーマンスを向上させるための関連機能を提供する非常に興味深いプロセスです。分類子..特に、Variational Autoencoders（VAE）などの深い生成モデルは、自然画像の特徴を生成するために大きな成功を収めています。 
[ABSTRACT]音声感情認識では、学習機能が重要です。これはファッション脱線を提案する最初の時間です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2017-12-23">
        <br><font color="black">2017-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting and analysing spontaneous oral cancer speech in the wild -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.SD/paper_13.html">
      <font color="black">Detecting and analysing spontaneous oral cancer speech in the wild</font>
    </a>
  </h2>
  <font color="black">口腔癌の発話の分析は、これまでのところ読話に重点を置いてきました。これらの説明可能な機械学習ベースラインの分析は、歯擦音と停止子音が自発的な口腔癌発話検出の最も重要な指標であることを示しています。この論文では、1） 2）YouTubeから収集された3時間の長さの自発的口腔がん発話データセットを分析します。 
[要約]口腔癌の発話の分析はこれまでのところ、発話の読み上げに焦点を合わせてきました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal Integration for Large-Vocabulary Audio-Visual Speech
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.SD/paper_14.html">
      <font color="black">Multimodal Integration for Large-Vocabulary Audio-Visual Speech
  Recognition</font>
    </a>
  </h2>
  <font color="black">ここで多くの利点を提供することが示されている1つの側面は、動的ストリーム信頼性インジケーターの使用です。これにより、ハイブリッドアーキテクチャは、オーディオチャネルが少しでも歪んでいるときはいつでも、視覚情報を含めることで大きな利益を得ることができます。動的ストリームの重み付けを使用した状態後確率のレベルは、小さな語彙システムではほぼ普遍的に役立ちますが、大きな語彙の音声認識では、認識精度を向上させるのは難しいままです。以下では、特に大きな語彙のタスクについて検討します。 LRS2データベースを使用して、初期の統合とエンドツーエンドの学習をハイブリッド認識と動的ストリーム重み付けの多くのバージョンと比較して、幅広い統合戦略を調査します。 
[ABSTRACT]マルチモーダル情報の最適な組み合わせ戦略についての議論がまだあります。これにより、大きな語彙認識へのストリーミングゲインが可能になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Autosegmental Neural Nets: Should Phones and Tones be Synchronous or
  Asynchronous? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.SD/paper_15.html">
      <font color="black">Autosegmental Neural Nets: Should Phones and Tones be Synchronous or
  Asynchronous?</font>
    </a>
  </h2>
  <font color="black">同期モデルと非同期モデルの両方が、多言語設定とクロス言語設定の両方で効果的です。このペーパーでは、4つのConnectionist Temporal Classification（CTC）ベースの音響モデルをテストします。これらのモデルは、電話とトーンの同期の度合いが異なります。以前の研究では、自動音声認識（ASR）電話モデルのクロスリンガル適応を調査しましたが、電話とトーン間の同期の多言語クロスリンガル転送を調査したものはほとんどありません。 
[要約] lexiosは、3つの言語で多言語でトレーニングおよびテストされます。次に、相互に適応され、クロスリンガルでテストされます。これらは、4番目の言語でテストされ、どちらもより低いエラーを達成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: RatLesNetv2: A Fully Convolutional Network for Rodent Brain Lesion
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.IV/paper_0.html">
      <font color="black">RatLesNetv2: A Fully Convolutional Network for Rodent Brain Lesion
  Segmentation</font>
    </a>
  </h2>
  <font color="black">結果：RatLesNetv2は、他のConvNetよりも高いDice係数値と同様に取得し、特により少ないホールとより低いHausdorff距離で、より現実的でコンパクトなセグメンテーションを生成しました。そのようなセグメンテーションはまた、評価者間の合意を超えました。 
[ABSTRACT] ratlesnetv2は、3階建てのイメージでエンドツーエンドでトレーニングされます。他の事前準備とは異なり、前処理は必要ありません。システムは、自動化された病変セグメンテーションに使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-24">
        <br><font color="black">2020-01-24</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient adaptation of neural network filter for video compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.IV/paper_1.html">
      <font color="black">Efficient adaptation of neural network filter for video compression</font>
    </a>
  </h2>
  <font color="black">ビデオコーディングパイプラインの後処理アーティファクト削除ステップとして適用されるニューラルネットワークフィルターの効率的な微調整方法を提示します。重みの更新は、既存のビデオコーデックによって生成されたビデオビットストリームに含めることができます。提案された方法は、従来の微調整アプローチよりもはるかに速く収束するため、実用的なアプリケーションに適しています。 
[要約]提案された方法は、微調整のビットを作成するために使用できます。微調整の代替として使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning for Deepfakes Creation and Detection: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.IV/paper_2.html">
      <font color="black">Deep Learning for Deepfakes Creation and Detection: A Survey</font>
    </a>
  </h2>
  <font color="black">したがって、デジタルビジュアルメディアの完全性を自動的に検出および評価できるテクノロジーの提案は不可欠です。ディープフェイクテクノロジーに関連する課題、研究動向、および方向性について幅広いディスカッションを行います。ディープラーニングは、さまざまな複雑な問題を解決するためにうまく適用されていますビッグデータ分析からコンピュータービジョンや人間レベルの制御まで。 
[要約]深い学習の進歩は、プライバシー、民主主義、国家安全保障に対する脅威を引き起こす可能性のあるソフトウェアの作成にも採用されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-25">
        <br><font color="black">2019-09-25</font>
      </time>
    </span>
</section>
<!-- paper0: Melanoma Detection using Adversarial Training and Deep Transfer Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.IV/paper_3.html">
      <font color="black">Melanoma Detection using Adversarial Training and Deep Transfer Learning</font>
    </a>
  </h2>
  <font color="black">この論文では、メラノーマ検出に向けて敵対的トレーニングと転移学習を使用して皮膚病変画像を自動分類するための2段階のフレームワークを提案します。第2段階では、元のトレーニングセットを使用して皮膚病変分類用の深い畳み込みニューラルネットワークをトレーニングします。新しく合成された表現不足のクラスサンプルと組み合わせます。最初の段階では、クラス間マッピングを学習し、表現不足のクラスサンプルを次のクラスから合成することにより、条件付き画像合成のタスクにデータ分布のクラス間変動を活用します。対にならない画像から画像への変換を使用する、過剰に表現されたもの。 
[ABSTRACT]病変の画像は、クラス間のばらつきが少ないため、全体的な外観はほぼ同じです。分類器のトレーニングは、焦点損失関数を最小限に抑えることで実行されます。簡単なもの</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-14">
        <br><font color="black">2020-04-14</font>
      </time>
    </span>
</section>
<!-- paper0: CovMUNET: A Multiple Loss Approach towards Detection of COVID-19 from
  Chest X-ray -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.IV/paper_4.html">
      <font color="black">CovMUNET: A Multiple Loss Approach towards Detection of COVID-19 from
  Chest X-ray</font>
    </a>
  </h2>
  <font color="black">提案されたアルゴリズムのロバスト性を確保するために広範な実験が行われ、パフォーマンスは精度、再現率、精度、およびF1スコアの観点から評価されます。提案されたニューラルアーキテクチャは、CXR画像の異常も正常に検出します。 3クラスの分類（COVID-19 vs正常vs肺炎）の精度は96.97％、2クラスの分類（COVID vs非COVID）の精度は99.41％の最先端のアプローチ。 
[要約]提案された方法は、covid-cxr画像からの19ケースを検出できます。これは、最先端のアプローチよりも優れています-96の精度で最先端のアプローチを実現します。97％</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Generative networks as inverse problems with fractional wavelet
  scattering networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.IV/paper_5.html">
      <font color="black">Generative networks as inverse problems with fractional wavelet
  scattering networks</font>
    </a>
  </h2>
  <font color="black">GSNの利点を維持しながら生成画像の品質をさらに向上させるために、このペーパーでは、特徴を取得するためのエンコーダーとしてScatNetsの代わりに、より表現力のあるフラクショナルウェーブレット散乱ネットワーク（FrScatNets）を使用するジェネレーショナルフラクショナルスキャッタリングネットワーク（GFRSN）を提案します（またはFrScatNet埋め込み）、デコーダーとしてGSNの同様のCNNを使用して画像を生成します。さらに、このペーパーでは、FrScatNetとFrScatNetの情報をより適切に保持するために、PCAの代わりにFeature-Map Fusion（FMF）という新しい次元削減方法を開発します。画像生成の品質に対する画像融合の影響についても説明します。GANとVAEの同期トレーニングの困難な問題を解決または軽減するために、最近、研究者はウェーブレット散乱ネットワーク（ScatNets）を使用するジェネレーティブスキャタリングネットワーク（GSN）を提案します。 imagを生成するデコーダーとして機能（またはScatNet埋め込み）を取得するためのエンコーダーおよび畳み込みニューラルネットワーク（CNN）としてe。 
[ABSTRACT]学習技術はトレーニングが困難ですが、ジェネレーター（またはエンコーダー）とディスクリミネーター（またはデコーダー）を同時にトレーニングする必要があるため、不安定なトレーニングが発生しやすくなります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Low-complexity Point Cloud Filtering for LiDAR by PCA-based Dimension
  Reduction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.IV/paper_6.html">
      <font color="black">Low-complexity Point Cloud Filtering for LiDAR by PCA-based Dimension
  Reduction</font>
    </a>
  </h2>
  <font color="black">2つの主成分にまたがる2D空間では、生成された2Dデータは3Dに復元される前にノイズ削減のためにクラスター化されます。次元削減と生成された2Dデータのクラスター化により、この方法は計算の複雑さを軽減し、保持しながらノイズを効果的に削除します環境特性の詳細。実験結果は、従来の密度ベースのクラスタリング手法と比較して、複雑さが50％削減された0.92ものFスコアを示しています。 
[ABSTRACT]提案された方法は、次元削減を使用してLIDAR点群をフィルタリングします。この方法は、情報の消耗がほとんどない元のデータの第1主成分と第2主成分を抽出することで2Dデータを生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Faster Mean-shift: GPU-accelerated Embedding-clustering for Cell
  Segmentation and Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.IV/paper_7.html">
      <font color="black">Faster Mean-shift: GPU-accelerated Embedding-clustering for Cell
  Segmentation and Tracking</font>
    </a>
  </h2>
  <font color="black">当社のFaster Mean-shiftアルゴリズムは、メモリ消費を最適化した他のGPUベンチマークと比較して最高の計算速度も達成しました。FasterMean-shiftはプラグアンドプレイモデルであり、医療用の他のピクセル埋め込みベースのクラスタリング推論に採用できます。画像解析..この研究では、埋め込みに基づくセルのセグメンテーションとトラッキングの計算のボトルネックに取り組む、新しいFaster Mean-shiftアルゴリズムを提案します。 
[ABSTRACT]より高速な平均-シフトアルゴリズムにより、最新の埋め込みベースのセルインスタンスのセグメンテーションとトラッキングと比較して7〜10倍のスピードアップを達成しました。新しい方法を使用して、境界と重複オブジェクトのあいまいなピクセルを特定できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Don't Forget The Past: Recurrent Depth Estimation from Monocular Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.IV/paper_8.html">
      <font color="black">Don't Forget The Past: Recurrent Depth Estimation from Monocular Video</font>
    </a>
  </h2>
  <font color="black">これは、単眼のビデオにのみ適用したり、さまざまなタイプのまばらな深度パターンと組み合わせたりできます。また、3つの人気グループの以前の深度推定方法よりも優れています。対応するネットワークをConvLSTMと統合して、全体の深度の時空間構造がフレームを利用して、より正確な深度推定を行うことができます。 
[ABSTRACT]私たちの方法は、さまざまなタイプの深度推定を反映するように調整できます。これらには、監視深度予測、自己tm深度予測、自己ポーラー深度完了が含まれます。この方法は、両方の自己において、画像ベースの対応物を一貫して大幅に上回ります監視付きシナリオ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-08">
        <br><font color="black">2020-01-08</font>
      </time>
    </span>
</section>
<!-- paper0: Accelerating ptychographic reconstructions using spectral
  initializations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.IV/paper_9.html">
      <font color="black">Accelerating ptychographic reconstructions using spectral
  initializations</font>
    </a>
  </h2>
  <font color="black">シミュレーションデータと実験データの両方でスペクトル初期化を使用して、標準の勾配降下アルゴリズムを使用した場合よりも3倍高速なタイコグラフィック再構成を初めて報告します。スペクトル手法は、新しい理論的洞察とタイコグラフィーの実験実装を開発するためのパラダイム変化を表しています。位相回復の最近の進歩は、勾配降下アルゴリズムを加速するために、スペクトル法の開発を目撃しました。 
[ABSTRACT]標準グラジエントアルゴリズムを使用した場合よりも3倍高速なタイコグラフィ再構成を初めて報告します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: CloudifierNet -- Deep Vision Models for Artificial Image Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.IV/paper_10.html">
      <font color="black">CloudifierNet -- Deep Vision Models for Artificial Image Processing</font>
    </a>
  </h2>
  <font color="black">最後に、実験的な開発と最先端の転移学習を実装したディープビジョンモデルに対するベンチマークに基づいて結論を提示します。人工知能とディープラーニングが多数のアプリケーションとともに進歩したことで、新しい研究分野自動化システムの開発と保守の要素が出現しています。このようなシステムの重要な要素の1つは、ディープラーニングコンピュータビジョンシステムに基づく人工的なシーンの検出と分析です。 
[要約]この論文では、コンピュータビジョンのためのディープニューラルパイプラインの基本原理を紹介します。カリフォルニア大学によって現在の論文で発表されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-04">
        <br><font color="black">2019-11-04</font>
      </time>
    </span>
</section>
<!-- paper0: Spectral Superresolution of Multispectral Imagery with Joint Sparse and
  Low-Rank Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.IV/paper_11.html">
      <font color="black">Spectral Superresolution of Multispectral Imagery with Joint Sparse and
  Low-Rank Learning</font>
    </a>
  </h2>
  <font color="black">この目的のために、重複する領域から低ランクのHS-MS辞書ペアを共同で学習することによってMS画像をスペクトル的に強化するために、共同スパース低ランク学習（J-SLoL）と呼ばれるシンプルだが効果的な方法を開発します。J-SLoL学習した辞書ペアのスパースコーディングにより、より広いカバレッジで未知のハイパースペクトル信号を推測および回復します。さらに、再構築、分類の観点から、3つのHS-MSデータセット（分類用に2つと非混合用に1つ）のSSRパフォーマンスを検証します。そして、いくつかの既存の最先端のベースラインと比較することにより、混合を解き、提案されたJ-SLoLアルゴリズムの有効性と優位性を示します。 
[ABSTRACT] hsとmsの画像の融合機能は、特に大規模なシーンではhs画像の取得に制限があるため、改善の余地があります。これは、j-msの画像を学習するため、難しく、調査が不十分なタスクです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Superpixel Based Graph Laplacian Regularization for Sparse Hyperspectral
  Unmixing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.IV/paper_12.html">
      <font color="black">Superpixel Based Graph Laplacian Regularization for Sparse Hyperspectral
  Unmixing</font>
    </a>
  </h2>
  <font color="black">グラフの各ノードはピクセルのスペクトルを表し、エッジはスーパーピクセル内の同様のピクセルを接続します。次に、各スーパーピクセルの加重グラフが作成されます。スパースセグメンテーションとグラフラプラシアン正則化を使用した効率的な空間正則化方法が疎に提案されていますハイパースペクトル非混合法。 
[要約]スーパーピクセルは、構造化された隣接ピクセルのグループとして定義されます。スーパーピクセルは、各スーパーピクセルのグラフを使用して構築されます。空間類似性は、グラフラプラシアン正則化を使用してスーパーピクセルで調査されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: EasierPath: An Open-source Tool for Human-in-the-loop Deep Learning of
  Renal Pathology -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.IV/paper_13.html">
      <font color="black">EasierPath: An Open-source Tool for Human-in-the-loop Deep Learning of
  Renal Pathology</font>
    </a>
  </h2>
  <font color="black">EasierPathソフトウェアは、大規模な糸球体プロトタイピングを可能にするオープンソースとしてリリースされました。一方、糸球体検出の平均精度は0.504から0.620まで活用されました。EasierPathを使用すると、医師は（1）リコールを最適化し、深層学習オブジェクト検出結果の精度、（2）医師のユーザーの習慣を変えることなく、EasierPathまたは一般的なImageScopeソフトウェアを使用して深層学習結果の洗練をシームレスにサポートし、（3）ユーザー定義のクラスで各オブジェクトを管理および表現型化します。 
[ABSTRACT] easierpathは、人間の医師とディープラーニングアルゴリズムを統合して、効率的な大規模な病理画像の定量化をループとして行うオープンソースツールです。このツールは、2つのループを持つ人間のループ内スタイルで使用できます。平均glomer3検出の精度は0. 504から0. 620まで活用されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Low-rank Prior in Dynamic MR Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.IV/paper_14.html">
      <font color="black">Deep Low-rank Prior in Dynamic MR Imaging</font>
    </a>
  </h2>
  <font color="black">プラグアンドプレイの方法では、ネットワークパラダイムを変更せずに他の動的MRニューラルネットワークに簡単に組み込むことができるプラグアンドプレイLRネットワークモジュールを提示します。この論文では、学習された特異値しきい値（学習済み-SVT）操作は、改善された再構成結果を得るために、動的MRイメージングで事前に深い低ランクを探索するために提案されています。 
[ABSTRACT] mr画像の低ランク（lr）事前調査は行われていないため、動的mr再構成のさらなる改善は制限されます。これらの方法は、貧弱なmr画像などによってのみ駆動されますが、重要な低ランク優先ダイナミックmrシネ画像の探索されていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-22">
        <br><font color="black">2020-06-22</font>
      </time>
    </span>
</section>
<!-- paper0: Coupled Convolutional Neural Network with Adaptive Response Function
  Learning for Unsupervised Hyperspectral Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.IV/paper_15.html">
      <font color="black">Coupled Convolutional Neural Network with Adaptive Response Function
  Learning for Unsupervised Hyperspectral Super-Resolution</font>
    </a>
  </h2>
  <font color="black">2つの特殊な畳み込み層は、3つのオートエンコーダネットと調整するブリッジとして機能するように設計されており、PSFおよびSRFパラメータは、トレーニングプロセス中に2つの畳み込み層で適応的に学習されます。この作業では、教師なしの深層学習ベースの融合方法-HyCoNet-以前のPSFおよびSRF情報なしでHSI-MSI融合の問題を解決できる方法が提案されます。HyCoNetは、HSIとMSIが線形混合モデルに基づいてエンドメンバーと存在量に混合されていない3つの結合オートエンコーダネットで構成されます。 。 
[ABSTRACT]ハイパースペクトルスーパー超音波超解像度とは、hsiとmsiを融合して、高空間と高解像度の両方の画像を作成することを指します。これらには、ハイパースペクトルハイパースペクトル超スペクトルスーパーモーションが含まれます。hyconetは、3つのリンクされたオートエンコーダネットネットネットネット</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Kalman Filter-based Head Motion Prediction for Cloud-based Mixed Reality -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.IV/paper_16.html">
      <font color="black">Kalman Filter-based Head Motion Prediction for Cloud-based Mixed Reality</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、カルマンフィルターが60ミリ秒の先読み時間に対して、自己回帰モデルよりも0.5度正確に頭部の向きを予測できることを示しています。記録された頭部のモーショントレースを使用してアプローチのパフォーマンスを分析し、そのパフォーマンスを自己回帰モデルと比較します。異なる予測間隔（先読み時間）の場合。このホワイトペーパーでは、クラウドベースのボリュームビデオストリーミングシステムで頭の動きを予測するためのカルマンフィルターを設計します。 
[ABSTRACT]モーションからフォトン（モーションからフォトン）のレイテンシにより、mr環境で登録エラーが発生することがある</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Monochrome and Color Polarization Demosaicking Using Edge-Aware Residual
  Interpolation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.IV/paper_17.html">
      <font color="black">Monochrome and Color Polarization Demosaicking Using Edge-Aware Residual
  Interpolation</font>
    </a>
  </h2>
  <font color="black">この論文では、エッジ認識残差補間（EARI）に基づく新しいMPFAデモザイキング手法を提案し、それをCPFAデモザイキングにも拡張します。EARIの鍵は、欠落を補間するために使用される効果的なガイド画像を生成するための新しいエッジ検出器です。ピクセル値..偏光計は、モノクロまたはカラー偏光フィルターアレイ（MPFAまたはCPFA）を備えたイメージセンサーで構成されているため、欠落したピクセル値を補間するデモザイキングプロセスは、高品質の偏光画像を取得する上で重要な役割を果たします。 
[要旨]イメージセンサーにus偏光フィルターアレイ（mpfaまたはcpfa）があります。eariと呼ばれ、新しい方法は効果的なガイドを作成するための新しいエッジ検出器です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: DeScarGAN: Disease-Specific Anomaly Detection with Weak Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.IV/paper_18.html">
      <font color="black">DeScarGAN: Disease-Specific Anomaly Detection with Weak Supervision</font>
    </a>
  </h2>
  <font color="black">DeScarGANと呼ばれる私たちの方法は、合成データセットおよび胸部X線画像データセットを目視検査することにより、他の異常検出方法よりも優れています。異常検出方法..標準の異常検出方法とは対照的に、この方法では、2つのグループから疾患の特徴に関する情報を抽出します。同じ疾患に罹患した患者のグループと健康な対照グループです。 
[ABSTRACT]この方法では、既存の解剖学的構造の構造変化を検出できます。これにより、この方法では、疾患-構造変化をより詳細に検出するための特定の特性を抽出できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Reachable Sets of Classifiers & Regression Models: (Non-)Robustness
  Analysis and Robust Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_0.html">
      <font color="black">Reachable Sets of Classifiers & Regression Models: (Non-)Robustness
  Analysis and Robust Training</font>
    </a>
  </h2>
  <font color="black">ニューラルネットワークは、分類および回帰タスクで卓越した精度を実現します。到達可能なセットの過大および過小近似につながる2つの効率的なアプローチを提供します。これらの質問に答えるには、ニューラルネットワークの到達可能なセットを計算します。ラベル付けされていない入力の信頼できる予測と信頼できない予測を区別する技法。予測に対する各特徴の影響を定量化し、特徴のランキングを計算します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Contraction Mapping of Feature Norms for Classifier Learning on the Data
  with Different Quality -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_1.html">
      <font color="black">Contraction Mapping of Feature Norms for Classifier Learning on the Data
  with Different Quality</font>
    </a>
  </h2>
  <font color="black">手書き数字認識、肺結節分類、顔認証、顔認識を含むさまざまな分類アプリケーションの実験は、提案されたアプローチが異なる品質のデータの学習の問題に効果的に対処することを約束し、有意で安定した分類精度の向上。この発見に基づいて、トレーニング画像の特徴ノルムの範囲を品質に応じて圧縮する収縮マッピング関数を提案し、この収縮マッピング関数をソフトマックス損失またはその拡張に組み込んで、新しい学習目標を生成します。このような問題を無視して、低品質データの正しい分類を解決することは困難です。 
[ABSTRACT]調査により、提案されたアプローチは異なる品質のデータの学習の問題に対処することが約束されており、分類精度の大幅な改善につながることが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: RatLesNetv2: A Fully Convolutional Network for Rodent Brain Lesion
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_2.html">
      <font color="black">RatLesNetv2: A Fully Convolutional Network for Rodent Brain Lesion
  Segmentation</font>
    </a>
  </h2>
  <font color="black">目的：RatLesNetv2という名前の完全畳み込みニューラルネットワーク（ConvNet）を導入して検証し、MR画像で齧歯類の脳病変をセグメント化します。RatLesNetv2アーキテクチャは自動エンコーダーに似ており、最適化を容易にする残差ブロックが組み込まれています。結果：RatLesNetv2は同様に取得されました他のConvNetよりも高いDice係数値に変換すると、特により少ない穴とより短いハウスドルフ距離で、より現実的でコンパクトなセグメンテーションが生成されます。 
[ABSTRACT] ratlesnetv2は、3階建てのイメージでエンドツーエンドでトレーニングされます。他の事前準備とは異なり、前処理は必要ありません。システムは、自動化された病変セグメンテーションに使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-24">
        <br><font color="black">2020-01-24</font>
      </time>
    </span>
</section>
<!-- paper0: Demystifying Contrastive Self-Supervised Learning: Invariances,
  Augmentations and Dataset Biases -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_3.html">
      <font color="black">Demystifying Contrastive Self-Supervised Learning: Invariances,
  Augmentations and Dataset Biases</font>
    </a>
  </h2>
  <font color="black">MOCOやPIRLのようなアプローチがオクルージョン不変表現を学習することを示します。最後に、構造化されていないビデオを活用して、より高い視点不変性を持つ表現を学習するアプローチを提案します。ただし、重要なコンポーネントである視点とカテゴリインスタンスの不変性をキャプチャできませんオブジェクト認識用。 
[ABSTRACT]私たちは、mocoやpirlのようなアプローチがオクルージョン（有形の表現）を学習することを実証しました。また、クリーンオブジェクトへのアクセスも学習します-imagenetのような中心的なトレーニングデータセット</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Large Scale Image Segmentation with Structured Loss based Deep Learning
  for Connectome Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_4.html">
      <font color="black">Large Scale Image Segmentation with Structured Loss based Deep Learning
  for Connectome Reconstruction</font>
    </a>
  </h2>
  <font color="black">私たちの予測は十分に正確であり、単純な学習なしのパーセンタイルベースの凝集は、以前に劣った予測で使用されたより複雑な方法よりも優れています。拡張は2つの部分で構成されています。最初に、損失線形を計算する準線形法を提示し、元の二次アルゴリズム。アフィニティ予測と領域の凝集を組み合わせた方法を提示します。これにより、電子顕微鏡（EM）の最先端のニューロンセグメンテーションから精度とスケーラビリティが大幅に向上します。 
[要約]私たちの方法は、ボクセル間の類似性を予測するようにトレーニングされた3d u-netで構成され、その後、反復的な領域の凝集が続きます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2017-09-09">
        <br><font color="black">2017-09-09</font>
      </time>
    </span>
</section>
<!-- paper0: RadarNet: Exploiting Radar for Robust Perception of Dynamic Objects -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_5.html">
      <font color="black">RadarNet: Exploiting Radar for Robust Perception of Dynamic Objects</font>
    </a>
  </h2>
  <font color="black">RadarNetは、オブジェクト検出と速度推定のタスクで、2つの大規模な実世界のデータセットで最先端の結果を達成します。これにより適切に対処するために、LiDARセンサーとレーダーセンサーの両方を知覚に活用する新しいソリューションを提案します。さらに、レーダーを活用することで、遠くのオブジェクトを検出し、動的オブジェクトの動きを理解する知覚能力が向上することを示しています。 
[ABSTRACT]私たちのアプローチは、レーダーネットと呼ばれ、ボクセルベースの早期フュージョンと注意ベースのレイトフュージョンを特徴としています。これらは、データから学習して、レーダーデータの幾何学的情報と動的情報の両方を活用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic Routing Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_6.html">
      <font color="black">Dynamic Routing Networks</font>
    </a>
  </h2>
  <font color="black">大規模な実験により、DRNetは推論中に相当量のパラメーターサイズとFLOPを削減でき、予測パフォーマンスは最新のアーキテクチャに匹敵します。同じ変換を介してすべての入力インスタンスを処理する静的アーキテクチャとの推論により、不必要になる計算コスト..このホワイトペーパーでは、変換ノード間の接続の候補セットから選択された必要な変換ブランチのみに入力インスタンスをルーティングすることにより、効率的なインスタンス認識推論をサポートする動的ルーティングネットワーク（DRNet）を提案します。 
[ABSTRACT]動的ルーティングネットワーク（drnets）は効率的なインスタンスをサポートします-入力インスタンスを必要な変換ブランチのみにルーティングすることにより、可能性を認識します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-13">
        <br><font color="black">2019-05-13</font>
      </time>
    </span>
</section>
<!-- paper0: The Unsupervised Method of Vessel Movement Trajectory Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_7.html">
      <font color="black">The Unsupervised Method of Vessel Movement Trajectory Prediction</font>
    </a>
  </h2>
  <font color="black">これにより、トレーニングセットを使用せずに、リアルタイムの信頼性が高く正確な予測が可能になります。ほとんどの統計学習やディープラーニングの方法とは異なり、提案されたクラスタリングベースの軌道再構成方法では、計算コストの高いモデルトレーニングは必要ありません。実際のアプリケーションシナリオでは、船舶ナビゲーターやセキュリティアナリストが、自動識別システム（AIS）のデータに基づいて、指定された期間内の船舶の動きを予測することは非常に重要です。 
[要約]システムの提案されたアプリケーションは十分なセキュリティを必要としません。モデルのトレーニングは必要ないため、安定したモデルのトレーニングは必要ありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-camera Torso Pose Estimation using Graph Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_8.html">
      <font color="black">Multi-camera Torso Pose Estimation using Graph Neural Networks</font>
    </a>
  </h2>
  <font color="black">人間の位置と向きを推定することは、サービスおよび支援ロボットにとって不可欠なスキルです。まず、これらのセットアップは比較的費用がかかります。オクルージョンと部分ビューにより、この2番目のポイントがこれらのシナリオに非常に関連します。 
[ABSTRACT]複数のRGBカメラが広域を推定するために頻繁に使用されます。複数のカメラソースを使用して有効なポイントポイントを実行することはめったにありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient adaptation of neural network filter for video compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_9.html">
      <font color="black">Efficient adaptation of neural network filter for video compression</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、7つのテストシーケンスで最新の多用途ビデオコーディング（VVC）標準コーデックと比較して、最大9.7％の平均BDレートゲインを達成することを示しています。生成されたビデオビットストリームに重み更新を含めることができます。提案された方法は、従来の微調整アプローチよりもはるかに速く収束を実現し、実用的なアプリケーションに適しています。 
[要約]提案された方法は、微調整のビットを作成するために使用できます。微調整の代替として使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning for Deepfakes Creation and Detection: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_10.html">
      <font color="black">Deep Learning for Deepfakes Creation and Detection: A Survey</font>
    </a>
  </h2>
  <font color="black">ディープフェイクアルゴリズムは、人間が本物と区別できない偽の画像やビデオを作成する可能性があります。ディープフェイクテクノロジーに関連する課題、研究動向、および方向性について幅広いディスカッションを行います。ディープラーニングは、ビッグデータからさまざまな複雑な問題を解決するためにうまく適用されていますコンピュータビジョンと人間レベルの制御への分析。 
[要約]深い学習の進歩は、プライバシー、民主主義、国家安全保障に対する脅威を引き起こす可能性のあるソフトウェアの作成にも採用されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-25">
        <br><font color="black">2019-09-25</font>
      </time>
    </span>
</section>
<!-- paper0: EXPO-HD: Exact Object Perception usingHigh Distraction Synthetic Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_11.html">
      <font color="black">EXPO-HD: Exact Object Perception usingHigh Distraction Synthetic Data</font>
    </a>
  </h2>
  <font color="black">ドメインのランダム化手法を使用してデータを生成します。これは、注意散漫オブジェクトと呼ばれる、シーン内の他の写実的なオブジェクトもシミュレートします。追加の利点は、結果のテストと検証を容易にするために世界中のオフィスでこのオブジェクトを利用できることです。オブジェクトの検出とセグメンテーションタスクで使用するための新しいラベル付きビジュアルデータセットを提示します。 
[ABSTRACT]ドメインの視覚化手法を使用してデータを生成します。これは、気晴らしオブジェクトとして知られる、世界の他のオブジェクトもシミュレートします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Nonnegative Low Rank Tensor Approximation and its Application to
  Multi-dimensional Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_12.html">
      <font color="black">Nonnegative Low Rank Tensor Approximation and its Application to
  Multi-dimensional Images</font>
    </a>
  </h2>
  <font color="black">非負性は、各ピクセル値が画像データ取得における非ゼロ光強度を参照するため、重要な特性の1つです。提案されたNLRTアプローチは、従来のNTFとは異なります。これは、提案されたNLRT法がより良い低ランクのテンソル近似を取得できることを意味します。 
[ABSTRACT]主要な非負性は、各ピクセル値が画像データの取得における非ゼロの光強度を参照するため、重要な特性の1つです。提案されたnlrtアナロジーアルゴリズムは、低ランクマトリックス多様体の積の平均投影を使用して導出されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: A Deep Learning-based Detector for Brown SpotDisease in Passion Fruit
  Plant Leaves -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_13.html">
      <font color="black">A Deep Learning-based Detector for Brown SpotDisease in Passion Fruit
  Plant Leaves</font>
    </a>
  </h2>
  <font color="black">国のパッションフルーツ農家を含む大多数の農家は、低所得世帯の小規模農家であるため、これらの課題に対処するための十分な情報と手段がありません。画像の収集にエクステンションサービスを利用していますウガンダの5つの地区のデータセットを使用して、機械学習、特にディープラーニングで最先端の技術を採用しています。オブジェクトの検出と分類に大規模な技術を使用して、パッションフルーツの健康状態を正しく判断していますこの作業は、2つの主要な疾患である木質（ウイルス性）と褐色斑点（真菌）の疾患に焦点を当てています。これらは、収量の減少と損失の増加に伴い、投資の損失につながります。 
[ABSTRACT]パッションフルーツは、農家の幸福を向上させる可能性があります。作物の健康に関する必要な知識がなければ、農家はすぐに介入して状況を変えることはできません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Change Detection Using Synthetic Aperture Radar Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_14.html">
      <font color="black">Change Detection Using Synthetic Aperture Radar Videos</font>
    </a>
  </h2>
  <font color="black">Lucas Kanade（LK）法を使用したオプティカルフロー計算とブロブ検出を組み合わせたアルゴリズムを提案します。高レベルのスペックルノイズ、ビデオのSAR画像フレームの回転など、SARビデオに関連するさまざまな課題があります。航空機の円運動、SARパルスの不均一な後方散乱による特定の軸。開発されたアプローチのパフォーマンスは、Sandia National LaboratoriesのWebサイトで入手できるSARビデオおよびSARシミュレーターによって生成されたSARビデオでテストされました。 
[要約]このペーパーでは、sarビデオを使用して変更を検出するアルゴリズムを開発しました。このペーパーでは、従来の変更検出アルゴリズムにより、sarビデオを使用できるように提案しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Melanoma Detection using Adversarial Training and Deep Transfer Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_15.html">
      <font color="black">Melanoma Detection using Adversarial Training and Deep Transfer Learning</font>
    </a>
  </h2>
  <font color="black">皮膚科の画像ベンチマークで実施された実験は、いくつかの標準的なベースライン方法に対する提案されたアプローチの優位性を示し、大幅なパフォーマンスの改善を達成しています。この論文では、敵対的なトレーニングと転移学習を使用した皮膚病変画像の自動分類のための2段階のフレームワークを提案します。メラノーマ検出に向けて..この分類子のトレーニングは、焦点の損失関数を最小限に抑えることで実行されます。これにより、モデルを難しい例から学習するのを支援し、簡単な例の重みを下げます。 
[ABSTRACT]病変の画像は、クラス間のばらつきが少ないため、全体的な外観はほぼ同じです。分類器のトレーニングは、焦点損失関数を最小限に抑えることで実行されます。簡単なもの</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-14">
        <br><font color="black">2020-04-14</font>
      </time>
    </span>
</section>
<!-- paper0: Transfer Learning for Improving Speech Emotion Classification Accuracy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_16.html">
      <font color="black">Transfer Learning for Improving Speech Emotion Classification Accuracy</font>
    </a>
  </h2>
  <font color="black">結果はまた、トレーニングに多数の言語を使用し、トレーニングでターゲットデータのごく一部を使用することで、限られたトレーニング例のコーパスでも、ベースラインと比較して精度を大幅に向上できることを示唆しています。このようなシステムのパフォーマンスは低下することが示されています重要なコーパスとクロス言語のシナリオで。この問題に対処するために、このペーパーでは、転移学習手法を利用して、クロス言語とコーパスのシナリオで新しい音声感情認識システムのパフォーマンスを向上させます。 
[ABSTRACT] 3つの異なる言語での5つの異なるコーパスのテストは、深い信念ネットワークが以前のアプローチよりも優れた精度を提供することを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-01-19">
        <br><font color="black">2018-01-19</font>
      </time>
    </span>
</section>
<!-- paper0: Class Anchor Clustering: a Distance-based Loss for Training Open Set
  Classifiers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_17.html">
      <font color="black">Class Anchor Clustering: a Distance-based Loss for Training Open Set
  Classifiers</font>
    </a>
  </h2>
  <font color="black">アンカークラスセンターは、特にオブジェクトベースのデータセットと多数のトレーニングクラスで、学習したクラスセンターよりも高いオープンセットパフォーマンスを実現することも示しています。CACを使用したトレーニングは、最新のオープンセットパフォーマンスを実現することを示しています。標準ベンチマークデータセットの距離ベースのオープンセット分類子。分類の精度を犠牲にすることなく、挑戦的なTinyImageNetでAUROCのパフォーマンスが2.4％向上します。このクラスタリングの動作は保証されません。 
[ABSTRACT]既存のオープンセット分類子は、ネットワークのロジットスペースで距離を測定することにより、既知のクラスと未知のクラスを区別します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: Generative networks as inverse problems with fractional wavelet
  scattering networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_18.html">
      <font color="black">Generative networks as inverse problems with fractional wavelet
  scattering networks</font>
    </a>
  </h2>
  <font color="black">GSNの利点を維持しながら生成画像の品質をさらに向上させるために、このペーパーでは、特徴を取得するためのエンコーダーとしてScatNetsの代わりに、より表現力のあるフラクショナルウェーブレット散乱ネットワーク（FrScatNets）を使用するジェネレーショナルフラクショナルスキャッタリングネットワーク（GFRSN）を提案します（またはFrScatNet埋め込み）、デコーダーとしてGSNの同様のCNNを使用して画像を生成します。さらに、このペーパーでは、FrScatNetとFrScatNetの情報をより適切に保持するために、PCAの代わりにFeature-Map Fusion（FMF）という新しい次元削減方法を開発します。画像生成の品質に対する画像融合の影響についても説明します。GANとVAEの同期トレーニングの困難な問題を解決または軽減するために、最近、研究者はウェーブレット散乱ネットワーク（ScatNets）を使用するジェネレーティブスキャタリングネットワーク（GSN）を提案します。 imagを生成するデコーダーとして機能（またはScatNet埋め込み）を取得するためのエンコーダーおよび畳み込みニューラルネットワーク（CNN）としてe。 
[ABSTRACT]学習技術はトレーニングが困難ですが、ジェネレーター（またはエンコーダー）とディスクリミネーター（またはデコーダー）を同時にトレーニングする必要があるため、不安定なトレーニングが発生しやすくなります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: AutoAssign: Differentiable Label Assignment for Dense Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_19.html">
      <font color="black">AutoAssign: Differentiable Label Assignment for Dense Object Detection</font>
    </a>
  </h2>
  <font color="black">MS COCOに関する広範な実験は、この手法が他の最良のサンプリング戦略を$ \ sim $ 1 \％APさまざまなバックボーンで着実に上回っていることを示しています。割り当てプロセスは区別可能であり、異なるデータセットやタスクに転送するために追加の変更を必要としません。 
[ABSTRACT] autoassignは、各場所の予測を動的に変更することにより、ポジティブサンプルとネガティブサンプルを自動的に決定</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Faster Mean-shift: GPU-accelerated Embedding-clustering for Cell
  Segmentation and Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_20.html">
      <font color="black">Faster Mean-shift: GPU-accelerated Embedding-clustering for Cell
  Segmentation and Tracking</font>
    </a>
  </h2>
  <font color="black">ISBIセルトラッキングチャレンジの4つのコホートによる埋め込みシミュレーションと経験的検証の両方により、提案されたFaster Mean-shiftアルゴリズムは、最先端の埋め込みベースのセルインスタンスセグメンテーションとトラッキングアルゴリズムと比較して7〜10倍の高速化を実現しました。 。最近、単一段階の埋め込みベースのディープラーニングアルゴリズムは、セルのセグメンテーションと追跡においてますます注目を集めています。Faster Mean-shiftは、プラグアンドプレイモデルであり、医用画像分析のための他のピクセル埋め込みベースのクラスタリング推論に採用できます。 。 
[ABSTRACT]より高速な平均-シフトアルゴリズムにより、最新の埋め込みベースのセルインスタンスのセグメンテーションとトラッキングと比較して7〜10倍のスピードアップを達成しました。新しい方法を使用して、境界と重複オブジェクトのあいまいなピクセルを特定できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: WaveFuse: A Unified Deep Framework for Image Fusion with Wavelet
  Transform -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_21.html">
      <font color="black">WaveFuse: A Unified Deep Framework for Image Fusion with Wavelet
  Transform</font>
    </a>
  </h2>
  <font color="black">したがって、トレーニング時間が大幅に短縮され、実用性とトレーニング効率の両方でモデルのパフォーマンスが向上します。特徴マップの有用な情報は、提案された方法のマルチスケール離散ウェーブレット変換を介して適切に利用できます。提案されたアルゴリズムは、主観的評価と客観的評価の両方で優れた融合パフォーマンスを示します。さらに、COCOデータセットでトレーニングされた同等の融合パフォーマンスは、 COCOからランダムに選択された何百もの画像。 
[ABSTRACT]これは、従来の画像変換方法とディープラーニングを組み合わせた初めての方法です。ディープラーニングを使用して開発された方法と同じです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Don't Forget The Past: Recurrent Depth Estimation from Monocular Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_22.html">
      <font color="black">Don't Forget The Past: Recurrent Depth Estimation from Monocular Video</font>
    </a>
  </h2>
  <font color="black">単眼のビデオのみに適用することも、さまざまなタイプのまばらな深度パターンと組み合わせて使用することもできます。繰り返しネットワークのアーキテクチャとそのトレーニング戦略を注意深く研究します。この方法は柔軟です。 
[ABSTRACT]私たちの方法は、さまざまなタイプの深度推定を反映するように調整できます。これらには、監視深度予測、自己tm深度予測、自己ポーラー深度完了が含まれます。この方法は、両方の自己において、画像ベースの対応物を一貫して大幅に上回ります監視付きシナリオ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-08">
        <br><font color="black">2020-01-08</font>
      </time>
    </span>
</section>
<!-- paper0: Black-Box Face Recovery from Identity Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_23.html">
      <font color="black">Black-Box Face Recovery from Identity Features</font>
    </a>
  </h2>
  <font color="black">最新の顔認識システム（ArcFace）を攻撃してアルゴリズムをテストします。異なるアーキテクチャの別のネットワーク（FaceNet）を独立した評論家として使用して、ターゲットの人物が再構成された画像で識別できないattackedmodelへのアクセス..この作業では、ブラックボックスの顔の回復用のランダムガウスblobの反復サンプリングに基づく新しいアルゴリズムを提示します。深い顔認識システムの出力特徴ベクトルのみが与えられます。 
[ABSTRACT]アルゴリズムをテストするための攻撃顔認識システム（arcface）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Assessing Risks of Biases in Cognitive Decision Support Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_24.html">
      <font color="black">Assessing Risks of Biases in Cognitive Decision Support Systems</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、バイアスのアンサンブルをどのように管理するかについての難しい研究課題に対処します。バイアスの観点からDSSの運用環境のパフォーマンス予測を提供します。確率論的推論手法は、そのようなバイアスのリスクの評価に使用されます。 
[要約]そのようなシステムの例は、認知バイオメトリックセキュリティチェックポイントです。さまざまな人口統計グループのリスク評価は、チェックポイントでのリスク評価に深刻な影響を与える可能性があります。バイアスの観点から、ds運用状況のパフォーマンス予測を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervised Neural Audio-Visual Sound Source Localization via
  Probabilistic Spatial Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_25.html">
      <font color="black">Self-supervised Neural Audio-Visual Sound Source Localization via
  Probabilistic Spatial Modeling</font>
    </a>
  </h2>
  <font color="black">画像内の音源オブジェクトをローカライズするためのシステムは、オーディオとビジュアルのDNNで構成されています。この問題を解決するために、このペーパーでは、360 {\ deg}画像とマルチチャネルオーディオ信号を使用した自己監視トレーニング方法を紹介します。マルチチャネルオーディオ信号の空間情報であるこの方法は、ディープニューラルネットワーク（DNN）をトレーニングして、複数の音源オブジェクトを区別します。 
[要約]私たちの方法は、複数の音源オブジェクトを区別するためにディープニューラルネットワーク（dnns）をトレーニングします。視覚的なdnnは、入力画像内の音源候補を特定するようにトレーニングされます。これらのdnnは、確率的空間に基づいて、自己監視方式で共同トレーニングされます音声モデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: A Large Scale Urban Surveillance Video Dataset for Multiple-Object
  Tracking and Behavior Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_26.html">
      <font color="black">A Large Scale Urban Surveillance Video Dataset for Multiple-Object
  Tracking and Behavior Analysis</font>
    </a>
  </h2>
  <font color="black">さらに、このデータセットを使用して、複数オブジェクトの追跡と異常動作分析の一般的なアルゴリズムのパフォーマンスを評価し、都市の混雑したシナリオにおけるこれらの方法の堅牢性を調査します。 、病院の入り口、学校の門、公園、歩行者天国、公共広場。200kを超えるビデオフレームには注意深く注釈が付けられており、300万を超えるオブジェクトの境界ボックスと約7：1の軌跡が生成されます。 
[ABSTRACT]都市監視ビデオデータセット（usvd）は最大かつ最も包括的です。データセットは、群を抜いて最大で最も包括的です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-26">
        <br><font color="black">2019-04-26</font>
      </time>
    </span>
</section>
<!-- paper0: Representation Learning with Video Deep InfoMax -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_27.html">
      <font color="black">Representation Learning with Video Deep InfoMax</font>
    </a>
  </h2>
  <font color="black">自然レートシーケンスと時間的にダウンサンプリングされたシーケンスの両方からビューを描画すると、よりコストのかかる大規模スケールトランスモデルを使用する従来の最先端の方法と一致またはそれを上回る速度論トレーニング済みアクション認識タスクで結果が得られることがわかります。 。DeepInfoMax（DIM）は、ディープネットワークの内部構造を利用してそのようなビューを構築し、画像内の小さなパッチに依存するローカルフィーチャーと画像全体に依存するグローバルフィーチャーとの間に予測タスクを形成する、自己監視方式です。また、UCF-101データセットのみでトレーニングする場合、データの増加と微調整の方法の効果を調べ、SoTAを大幅に達成します。 
[ABSTRACT]最も効果的なセルフパーパー学習方法には、予測技術が含まれます。これらには、データのさまざまなビューに基づく予測タスクが含まれます。これらには、ビデオディープコンピューターと呼ばれる方法が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: CloudifierNet -- Deep Vision Models for Artificial Image Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_28.html">
      <font color="black">CloudifierNet -- Deep Vision Models for Artificial Image Processing</font>
    </a>
  </h2>
  <font color="black">人工知能とディープラーニングが多数のアプリケーションとともに進歩するにつれ、自動化されたシステムの開発とメンテナンスという新しい研究領域が生まれています。最後に、実験的な開発と最新の状態に対するベンチマークに基づいて結論を提示します。 the-art transfer-learningはディープビジョンモデルを実装しました。このようなシステムの重要な要素の1つは、ディープラーニングコンピュータービジョンシステムに基づく人工的なシーンの検出と分析です。 
[要約]この論文では、コンピュータビジョンのためのディープニューラルパイプラインの基本原理を紹介します。カリフォルニア大学によって現在の論文で発表されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-04">
        <br><font color="black">2019-11-04</font>
      </time>
    </span>
</section>
<!-- paper0: Quantum-soft QUBO Suppression for Accurate Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_29.html">
      <font color="black">Quantum-soft QUBO Suppression for Accurate Object Detection</font>
    </a>
  </h2>
  <font color="black">次に、量子コンピューティングの利点を活用して、高速かつ正確な検出のために提案されたQuantum-soft QUBO Suppression（QSQS）アルゴリズムを使用してQUBO問題を解決します。 、この貪欲なアルゴリズムは、検出スコアが低い真の陽性が抑制される可能性があるオクルージョンシナリオでのオブジェクト検出にはうまく機能しない可能性があります。 
[ABSTRACT]画像mを最も高い検出スコアで維持することにより、誤検知を排除します。ただし、mとのオーバーラップ率が事前定義されたしきい値よりも小さい画像。quantumは、新しいアルゴリズムと連携して検出を削除します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Joint Learning of Social Groups, Individuals Action and Sub-group
  Activities in Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_30.html">
      <font color="black">Joint Learning of Social Groups, Individuals Action and Sub-group
  Activities in Videos</font>
    </a>
  </h2>
  <font color="black">ビデオストリームから人間の活動を理解するための最先端のソリューションは、タスクを時空間問題として定式化します。この問題は、シーン内のすべての個人の共同位置特定と、時間の経過に伴う彼らの行動またはグループ活動の分類を必要とします。 、私たちは人々を彼らの社会的相互作用によって同時にグループ化し、個人の行動と各社会グループの社会活動を予測する問題を解決します。これは社会的タスクと呼ばれます。私たちの主な貢献は次のとおりです。i）エンドツーエンドを提案する社会的課題のためのトレーニング可能なフレームワーク。 ii）私たちの提案する方法は、従来のグループアクティビティ認識タスクに広く採用されている2つのベンチマーク（シーンの個人が単一グループを形成し、シーンの単一グループアクティビティラベルを予測する）に最先端の結果を設定します。 iii）既存のグループ活動データセットに新しい注釈を導入し、それをソーシャルタスクに転用します。 
[ABSTRACT]ソーシャルタスクは、サブグループに分割するのが最適な人々によって提案されます。これは、ソーシャルグループと呼ばれ、各ソーシャルグループは異なる社会活動に従事している可能性があります。提案された方法は、2つの結果を広く設定します従来のグループ活動認識タスクに採用されたベンチマーク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Prototypical Contrastive Learning of Unsupervised Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_31.html">
      <font color="black">Prototypical Contrastive Learning of Unsupervised Representations</font>
    </a>
  </h2>
  <font color="black">PCLは、複数の教師なし表現学習ベンチマークで最先端の結果を達成し、低リソース転送タスクで10％を超える精度の向上を実現します。ProtoNCE損失は、表現を促進する対照学習用のInfoNCE損失の一般化バージョンです。 PCLは、割り当てられたプロトタイプに近づきます。PCLは、インスタンス識別のタスクの低レベルの機能を学習するだけでなく、さらに重要なことに、学習した埋め込みスペースにデータの意味構造を暗黙的にエンコードします。 
[ABSTRACT] pclは教師なし表現の学習ベンチマークを学習できます。これらにはe-ステップが含まれ、クラスタリングによりプロトタイプの分布を見つけることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br><font color="black">2020-05-11</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Modality Interaction for Temporal Sentence Localization and
  Event Captioning in Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_32.html">
      <font color="black">Learning Modality Interaction for Temporal Sentence Localization and
  Event Captioning in Videos</font>
    </a>
  </h2>
  <font color="black">イベントを説明するための文の自動生成と、ビデオ内の文の時間的ローカライズは、言語とビデオをつなぐ2つの重要なタスクです。モダリティの相互作用は、シーケンスレベルとチャネルレベルの両方でペアワイズ方式でモデル化されます。ペアワイズ相互作用は、ターゲットタスクの予測..最近の手法では、既製の機能を使用してビデオを表現することにより、ビデオのマルチモーダルな性質を活用していますが、モダリティ間の相互作用はほとんど調査されていません。 
[ABSTRACT] 4つの標準的なベンチマークデータセットで最先端のパフォーマンスを実現するための手法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Optimization of XNOR Convolution for Binary Convolutional Neural
  Networks on GPU -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_33.html">
      <font color="black">Optimization of XNOR Convolution for Binary Convolutional Neural
  Networks on GPU</font>
    </a>
  </h2>
  <font color="black">実験結果は、GPUを使用すると、カーネルサイズが$ 3 \ times3 $で最大$ 42.61 \ times $の高速化を実現できることを示しています。この実装は、https：//github.com/metcan/Binary-Convolutional-で公開されています。ニューラルネットワーク推論のGPU。バイナリ畳み込みネットワークは、完全精度のネットワークと比較して、計算負荷とメモリ使用量が少なくなっています。 
[要約] gpuでのバイナリ畳み込みネットワークの可能性は、限られた容量の組み込みデバイスにコンピュータービジョンアプリケーションを展開するための実行可能な代替手段です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Black-Box Adversarial Attack Guided by the Distribution of
  Adversarial Perturbations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_34.html">
      <font color="black">Efficient Black-Box Adversarial Attack Guided by the Distribution of
  Adversarial Perturbations</font>
    </a>
  </h2>
  <font color="black">この作業では、ガウス分布変数を条件付きフローベースのモデルを介して別の空間に変換し、良性の例を条件とする敵対的な摂動の本質的な分布をキャプチャする機能と柔軟性を強化することを提案します。クエリの効率性については、いくつかのホワイトボックスサロゲートモデルに基づいて条件付きフローモデルを事前トレーニングすることを提案します。これは、敵対的な例の文献で広く観察されている、さまざまなモデルにわたる敵対的な摂動の転送可能性を利用します。メソッドは、クエリベースと転送ベースの両方の攻撃方法を利用して、有効性と効率の両方で満足のいく攻撃パフォーマンスを実現できます。 
[ABSTRACT]進化戦略（es）は、敵対的である可能性が高い摂動をサンプリングするために検索分布を導入しました。しかし、これらのさまざまな異なるタイプなどの多様な分布分布パターンをキャプチャするには十分な柔軟性がない場合があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
</section>
<!-- paper0: Risk-Averse MPC via Visual-Inertial Input and Recurrent Networks for
  Online Collision Avoidance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_35.html">
      <font color="black">Risk-Averse MPC via Visual-Inertial Input and Recurrent Networks for
  Online Collision Avoidance</font>
    </a>
  </h2>
  <font color="black">私たちの方法の堅牢性は、複雑な四足ロボットのダイナミクスで検証され、一般的にほとんどのロボットプラットフォームに適用でき、ゴールポイントに向かって高速で衝突のない経路を計画できる自律的な動作を示します。RNNモデルは、以下を含むデータセットでトレーニングされます最先端の視覚慣性オドメトリフレームワークを介してカメラ画像と慣性測定ユニット（IMU）の読み取り値から生成されたロボットとランドマークポーズの比較。回避するためにオブジェクトの位置を検出して抽出するには、カスタム訓練された畳み込みニューラルを使用します。ネットワークモデルと特徴抽出器を組み合わせて使用し、近くの障害物の3D重心と半径の境界を取得します。 
[要旨]私たちのアルゴリズムは、オブジェクト検出パイプラインと再帰型ニューラルネットワーク（rnn）を組み合わせています。モデルは、カメラの有限時間範囲の各ステップを通じて状態推定の共分散を推測できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Spectral Superresolution of Multispectral Imagery with Joint Sparse and
  Low-Rank Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_36.html">
      <font color="black">Spectral Superresolution of Multispectral Imagery with Joint Sparse and
  Low-Rank Learning</font>
    </a>
  </h2>
  <font color="black">あるいは、部分的にオーバーラップしたHS画像を使用してスペクトル領域でMS画像を超解像し、新規かつ有望なトピックを生成します：MS画像のスペクトル超解像（SSR）。このために、シンプルだが効果的な方法を開発します。重複領域から低ランクHS-MS辞書ペアを共同で学習することによりMS画像をスペクトル的に強化するために、共同スパース低ランク学習（J-SLoL）と呼ばれます。J-SLoLは、次の方法で未知のハイパースペクトル信号を推測および回復します。学習した辞書ペアのスパースコーディング。 
[ABSTRACT] hsとmsの画像の融合機能は、特に大規模なシーンではhs画像の取得に制限があるため、改善の余地があります。これは、j-msの画像を学習するため、難しく、調査が不十分なタスクです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Superpixel Based Graph Laplacian Regularization for Sparse Hyperspectral
  Unmixing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_37.html">
      <font color="black">Superpixel Based Graph Laplacian Regularization for Sparse Hyperspectral
  Unmixing</font>
    </a>
  </h2>
  <font color="black">重み付きスパース性を促進するノルムは、存在量行列をスパース化するための定式化に含まれています。シミュレーションおよび実際のデータセットに関する実験結果は、文献にある既知のアルゴリズムに対する提案されたアルゴリズムの優位性を示しています。グラフの各ノードは、ピクセルとエッジのスペクトルは、スーパーピクセル内の同様のピクセルを接続します。 
[要約]スーパーピクセルは、構造化された隣接ピクセルのグループとして定義されます。スーパーピクセルは、各スーパーピクセルのグラフを使用して構築されます。空間類似性は、グラフラプラシアン正則化を使用してスーパーピクセルで調査されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Tiny Transfer Learning: Towards Memory-Efficient On-Device Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_38.html">
      <font color="black">Tiny Transfer Learning: Towards Memory-Efficient On-Device Learning</font>
    </a>
  </h2>
  <font color="black">重みを更新せずに適応能力を維持するために、TinyTLはメモリ効率の高いlite残差モジュールを導入して、途中で小さな残差特徴マップを学習することにより特徴抽出を改良します。効率的なオンデバイスであるTiny-Transfer-Learning（TinyTL）を提示します。事前にトレーニングされたモデルをエッジデバイスで新しく収集されたデータに適応させる学習方法。このバックプロパゲーションのない離散サブネット選択により、メモリのオーバーヘッドは発生しません。 
[ABSTRACT] tinytlは、特徴抽出器の重みを固定しながら、bias.tinytlを学習するだけで、精度を犠牲にすることなく、トレーニングメモリコストを1桁（最大13.3倍）削減できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: LANCE: Efficient Low-Precision Quantized Winograd Convolution for Neural
  Networks Based on Graphics Processing Units -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_39.html">
      <font color="black">LANCE: Efficient Low-Precision Quantized Winograd Convolution for Neural
  Networks Based on Graphics Processing Units</font>
    </a>
  </h2>
  <font color="black">線形量子化演算をWinogradドメインに埋め込むことにより、グラフィックス処理ユニットの低精度計算の下で高速畳み込みを効率的に実行できます。実験結果は、8ビットの量子化されたWinograd畳み込みがパフォーマンスを最大2.40倍向上させることを示しています。ささいな精度損失を伴う完全精度のたたみ込み。SVHN、CIFAR、ImageNetなどの代表的な画像分類データセットでLANCEを使用してニューラルネットワークモデルをテストします。 
[ABSTRACT]このシステムは、高速たたみ込みと量子化技術の利点を組み合わせています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-19">
        <br><font color="black">2020-03-19</font>
      </time>
    </span>
</section>
<!-- paper0: Effective and Efficient Dropout for Deep Convolutional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_40.html">
      <font color="black">Effective and Efficient Dropout for Deep Convolutional Neural Networks</font>
    </a>
  </h2>
  <font color="black">これらのドロップアウトバリアントは、CNNのビルディングブロックに容易に統合でき、既存のディープラーニングプラットフォームに実装できます。しかし、最近の多くの研究では、標準のドロップアウトはCNNのトレーニングに効果がないか、有害でさえあることが示されています。ドロップアウトの確率と次のバッチ正規化（BN）の間の競合にドロップアウトし、BNの代わりに畳み込み演算の直前にドロップアウト操作を配置して競合を減らすか、BNをグループ正規化（GN ）。 
[ABSTRACT] dropoutはcnnsの効率的な正則化手法として広く使用されています。ただし、主要ネットワーク間の競合を減らすために使用されています。これらには、より効率的で効果的な正則化を提供する、構造的により適したドロップアウトバリアントdrop-conv2dが含まれています深いcnns</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-06">
        <br><font color="black">2019-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: Flower: A Friendly Federated Learning Research Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_41.html">
      <font color="black">Flower: A Friendly Federated Learning Research Framework</font>
    </a>
  </h2>
  <font color="black">FLアルゴリズム（TensorFlow Federatedなど）のシミュレーションに使用できるフレームワークはいくつかありますが、モバイルデバイスでのFLワークロードの実装はサポートされていません。このホワイトペーパーでは、FL（https://flower.dev/)、FL異種のクライアント環境にとらわれず、モバイルデバイスや組み込みデバイスを含む多数のクライアントに対応できるフレームワークです。Flowerの抽象化により、開発者は使用するプログラミング言語やMLフレームワークに関係なく、既存のモバイルワークロードをわずかなオーバーヘッドで移植できます。研究者が最先端の技術を進歩させるための新しいアプローチを柔軟に実験できるようにします。 
[要約]目的は、開発者が既存のモバイルワークロードをわずかなオーバーヘッドで移植できるようにすることです。また、最新の通信機能を進歩させるための新しいアプローチを実験することもできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Spatially Adaptive Convolution and Correlation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_42.html">
      <font color="black">Efficient Spatially Adaptive Convolution and Correlation</font>
    </a>
  </h2>
  <font color="black">このフレームワークは、回転（2Dおよび3Dで）やスケールなどの変換グループの拡張畳み込みと相関の効率的な実装を可能にし、操縦可能なフィルターや一般化されたハフ変換などの以前の方法に新しい解釈を提供します。パターンマッチングへのアプリケーションを提示します。 、画像機能の説明、ベクトル場の視覚化、および適応型画像フィルタリング。初期の研究で、FreemanとAdelsonは、操縦可能なフィルターがこの制限に対処する方法を示し、信号を通過するときにフィルターを回転させる方法を提供しました。 
[ABSTRACT]この作業では、空間的に変化する線形変換をフィルターに適用できるようにするフレームワークを提供します。これにより、そのような需要の高い効果を使用してフィルターを作成できます。たとえば、パターンマッチングへのアプリケーションを提示します、画像機能の説明、マトリックス、および適応画像フィルタリング</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-23">
        <br><font color="black">2020-06-23</font>
      </time>
    </span>
</section>
<!-- paper0: Monocular Real-Time Volumetric Performance Capture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_43.html">
      <font color="black">Monocular Real-Time Volumetric Performance Capture</font>
    </a>
  </h2>
  <font color="black">評価のために不必要な領域を大雑把に選別することにより、品質を損なうことなく、ベースラインから2桁の大きさで再構成を加速することに成功しました。提案されたアプローチは、マルチビュースタジオの設定を不要にし、ボリュームキャプチャのアクセス可能なソリューション。このために、表面メッシュを明示的に抽出せずに、新しい階層的表面位置特定アルゴリズムと直接レンダリング方法を提案します。 
[要旨]私たちのシステムは、ピクセル配列の陰関数（pifu）を利用して、各フレームから完全にテクスチャ化された3D人間を再構築します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Discrepancy Minimization in Domain Generalization with Generative
  Nearest Neighbors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_44.html">
      <font color="black">Discrepancy Minimization in Domain Generalization with Generative
  Nearest Neighbors</font>
    </a>
  </h2>
  <font color="black">経験的に、PACSとVLCSの2つのデータセットでのメソッドの有効性を示します。このソースドメインから抽出された特徴は、生成モデルを使用して学習されます。その生成空間の潜在空間は、ターゲットデータポイントの最近傍を取得するサンプラーとして使用されます。ターゲットのラベリングプロセスのエラーによって上限が定められた理論上の保証を提供する生成的最近傍に基づく不一致最小化（GNNDM）方法を提案します。 
[ABSTRACT]ドメイン不一致最小化ネットワーク（ddmn）は、ドメインの重要な機能を学習して、最も近いデータポイントのクラスラベルを保持しながら、単一のソースドメインを生成します。提案された方法は、以前のアプローチとは異なり、ドメインラベルへのアクセスを必要としません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Exploit the potential of Multi-column architecture for Crowd Counting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_45.html">
      <font color="black">Exploit the potential of Multi-column architecture for Crowd Counting</font>
    </a>
  </h2>
  <font color="black">さらに、特徴の類似性のために、PSMの各列によって学習される特徴を適切に異なるようにするために、Multi-column variance lossという新しい損失関数が導入されています。具体的には、スケール制限のために、3つのピラミッドスケールモジュール（PSM）を採用しています。メッセージパッシングメカニズムとアテンションメカニズムをマルチカラムアーキテクチャに統合するマルチスケール機能を効率的にキャプチャします。このホワイトペーパーでは、これらの問題に明示的に対処するPyramid Scale Network（PSNet）と呼ばれる新しい群衆カウントフレームワークを提案します。 
[ABSTRACT] psnetは、マルチカラム設計におけるスケール制限と機能の類似性に対処した最初の作業です。これらの課題を克服するために広く採用されており、多くのパブリックベンチマークで複雑なパフォーマンスの状態を提供しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-11">
        <br><font color="black">2020-07-11</font>
      </time>
    </span>
</section>
<!-- paper0: A Fast and Robust Matching Framework for Multimodal Remote Sensing Image
  Registration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_46.html">
      <font color="black">A Fast and Robust Matching Framework for Multimodal Remote Sensing Image
  Registration</font>
    </a>
  </h2>
  <font color="black">多くの異なるタイプのマルチモーダル画像で得られた実験結果は、最先端の方法と設計されたシステムの有効性に関して、提案されたフレームワークの優れたマッチング性能と、非常に優れた潜在的な大型画像のレジストレーションを示しています。実際のアプリケーション。このペーパーではコードを利用できます。さらに、提案されたフレームワークに基づいて、非常に大きなサイズのマルチモーダル画像の自動登録システムを設計します。提案されたフレームワークの主な利点は、（1）ピクセル単位の機能の説明と（2）FFTの使用による高い計算効率。 
[ABSTRACT]高速で堅牢なマッチンググラムは、マルチモーダル登録用のローカル記述子を統合します。これらには、多くの大型マルチモーダル画像用の詳細な詳細システムが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-08-19">
        <br><font color="black">2018-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: EasierPath: An Open-source Tool for Human-in-the-loop Deep Learning of
  Renal Pathology -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_47.html">
      <font color="black">EasierPath: An Open-source Tool for Human-in-the-loop Deep Learning of
  Renal Pathology</font>
    </a>
  </h2>
  <font color="black">EasierPathソフトウェアは、大規模な糸球体プロトタイピングを可能にするオープンソースとしてリリースされました。一方、糸球体検出の平均精度は0.504から0.620まで活用されました。EasierPathを使用すると、医師は（1）リコールを最適化し、深層学習オブジェクト検出結果の精度、（2）医師のユーザーの習慣を変えることなく、EasierPathまたは一般的なImageScopeソフトウェアを使用して深層学習結果の洗練をシームレスにサポートし、（3）ユーザー定義のクラスで各オブジェクトを管理および表現型化します。 
[ABSTRACT] easierpathは、人間の医師とディープラーニングアルゴリズムを統合して、効率的な大規模な病理画像の定量化をループとして行うオープンソースツールです。このツールは、2つのループを持つ人間のループ内スタイルで使用できます。平均glomer3検出の精度は0. 504から0. 620まで活用されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: On the Impact of Lossy Image and Video Compression on the Performance of
  Deep Convolutional Neural Network Architectures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_48.html">
      <font color="black">On the Impact of Lossy Image and Video Compression on the Performance of
  Deep Convolutional Neural Network Architectures</font>
    </a>
  </h2>
  <font color="black">入力圧縮と出力タスクパフォーマンスの関係の特性を使用して、将来の画像/ビデオデバイスおよびインフラストラクチャ内の設計決定を通知できます。現代の損失の多い代表的なプロキシとしてのJPEGおよびH.264（MPEG-4 AVC）に焦点を当てますネットワーク接続された画像/ビデオデバイスとインフラストラクチャ内で一般的に使用されている画像/ビデオ圧縮技術について、5つの個別のタスク（人間の姿勢推定、セマンティックセグメンテーション、オブジェクト検出、アクション認識、単眼深度推定）のパフォーマンスへの影響を調べます。さらに、エンコーダー/デコーダーパイプラインを使用するアーキテクチャーと非可逆画像圧縮に対する回復力を示すアーキテクチャーの間には相関関係があります。 
[ABSTRACT]調査では、このようなディープラーニングアーキテクチャのパフォーマンスに対する一般的な画像とビデオの圧縮技術の影響について、これまでにないアプローチを検討します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Open Cross-Domain Visual Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_49.html">
      <font color="black">Open Cross-Domain Visual Search</font>
    </a>
  </h2>
  <font color="black">かなりの進歩にもかかわらず、検索は2つの定義済みドメイン間の閉じた設定で行われます。次に、ソースまたはターゲットとして使用されているドメインに関係なく、共通の意味空間で検索することにより、オープンクロスドメインビジュアル検索が実行されます。すべての視覚領域から共通の意味空間へのマッピングとしての検索。カテゴリは超球のプロトタイプによって表されます。 
[要旨]ドメインをまたがる視覚的な検索は、ソースまたはターゲットとして使用されるドメインに関係なく、共通の意味空間で検索することによって実行されます。ドメイン固有のマッピング機能により、影響を与えることなく、任意の数のドメインに効率的にスケーリングできます。検索パフォーマンス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br><font color="black">2019-11-19</font>
      </time>
    </span>
</section>
<!-- paper0: Recovery of Superquadrics from Range Images using Deep Learning: A
  Preliminary Study -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_50.html">
      <font color="black">Recovery of Superquadrics from Range Images using Deep Learning: A
  Preliminary Study</font>
    </a>
  </h2>
  <font color="black">この問題を緩和するために、この論文では、現代のディープラーニングモデル、より具体的には畳み込みニューラルネットワーク（CNN）を使用して、時間のかかる反復パラメーター推定手法なしで距離画像から超二次関数を復元する可能性を探ります。さらに、現実世界のオブジェクトのデータセットを含む定性分析。しかし、超二次回復の既存のソリューションには、コストのかかる反復フィッティング手順が含まれており、実際にそのような手法の適用を制限しています。 
[ABSTRACT]これらのモデルは、少数のパラメータセットを使用して、個々のオブジェクトから複雑なシーンまでの物理的な単語のすべての要素を表すことを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-13">
        <br><font color="black">2019-04-13</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Low-rank Prior in Dynamic MR Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_51.html">
      <font color="black">Deep Low-rank Prior in Dynamic MR Imaging</font>
    </a>
  </h2>
  <font color="black">深層学習法は、動的MRシネイメージングで魅力的なパフォーマンスを実現しました。このホワイトペーパーでは、学習済み特異値しきい値処理（Learned-SVT）操作を提案して、動的MRイメージングで事前に深い低ランクを探索して、再構成結果を改善します。ただし、動的MRシネ画像の重要な低ランク（LR）は検討されていないが、動的MR再構成のさらなる改善を制限する一方で、これらすべての方法は、MR画像のまばらな事前によってのみ駆動されます。 
[ABSTRACT] mr画像の低ランク（lr）事前調査は行われていないため、動的mr再構成のさらなる改善は制限されます。これらの方法は、貧弱なmr画像などによってのみ駆動されますが、重要な低ランク優先ダイナミックmrシネ画像の探索されていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-22">
        <br><font color="black">2020-06-22</font>
      </time>
    </span>
</section>
<!-- paper0: NeuRoRA: Neural Robust Rotation Averaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_52.html">
      <font color="black">NeuRoRA: Neural Robust Rotation Averaging</font>
    </a>
  </h2>
  <font color="black">提案されたネットワークは、2つのネットワークの組み合わせです。（1）ビューグラフ内の外れ値のエッジを検出し、ノイズの多い測定値を修正するビューグラフクリーニングネットワーク。 （2）微調整ネットワーク。クリーンなグラフからブートストラップされた絶対方向の初期化を1ステップで微調整します。この作業では、データからノイズパターンを学習するニューラルネットワークを構築することを目指しています。これらのロバストなコスト関数は非常に非線形であり、ノイズと外れ値の分布に関する特定の仮定に基づいて設計されています。 
[要約]タスクは、いくつかのカメラの絶対方向を推定することです。これらの堅牢なコスト関数は、ノイズと外れ値の分布に関する特定の仮定に基づいて設計されています。提案されているネットワークは、2つのネットワークの組み合わせです。外れ値のエッジを検出し、ノイズの多い測定値を修正します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-10">
        <br><font color="black">2019-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Coupled Convolutional Neural Network with Adaptive Response Function
  Learning for Unsupervised Hyperspectral Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_53.html">
      <font color="black">Coupled Convolutional Neural Network with Adaptive Response Function
  Learning for Unsupervised Hyperspectral Super-Resolution</font>
    </a>
  </h2>
  <font color="black">HyCoNetは、HSIとMSIが線形混合モデルに基づいて端成分と存在量に混合されていない3つの結合オートエンコーダネットで構成されています。最近、この融合問題を解決するいくつかの新しい方法が提案され、これらの方法のほとんどは、ポイントスプレッド関数（PSF）とスペクトル応答関数（SRF）の情報は既知です。2つの特別な畳み込み層は、3つのオートエンコーダネットと調整するブリッジとして機能するように設計されており、PSFおよびSRFパラメータは、トレーニングプロセス中の2つの畳み込み層。 
[ABSTRACT]ハイパースペクトルスーパー超音波超解像度とは、hsiとmsiを融合して、高空間と高解像度の両方の画像を作成することを指します。これらには、ハイパースペクトルハイパースペクトル超スペクトルスーパーモーションが含まれます。hyconetは、3つのリンクされたオートエンコーダネットネットネットネット</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Toward Zero-Shot Unsupervised Image-to-Image Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_54.html">
      <font color="black">Toward Zero-Shot Unsupervised Image-to-Image Translation</font>
    </a>
  </h2>
  <font color="black">さらに、我々のフレームワークがゼロショット分類やファッションデザインなどの多くのタスクに適用できることを実証します。特に、目に見えないクラスの属性ベクトルを利用することにより、視覚空間への意味関係を維持し、属性空間を拡張することを提案します。この作業では、カテゴリを属性などのサイド情報に関連付けることによって、この制限に対処するためのゼロショットの教師なし画像間変換フレームワークを提案します。 
[要旨]目に見えないクラスのスペースを活用するための2つの戦略を提案します。トランスレータを以前の目に見えないクラスに一般化するには、スペースを活用するための2つの戦略を紹介します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Weakly Supervised 3D Object Detection from Point Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_55.html">
      <font color="black">Weakly Supervised 3D Object Detection from Point Clouds</font>
    </a>
  </h2>
  <font color="black">弱く監視された学習は、アノテーション要件を減らすための有望なアプローチですが、既存の弱く監視されたオブジェクト検出器は、主に3Dではなく2D検出用です。最初に、正規化された点群密度を利用してオブジェクト提案を生成する監視なし3D提案モジュールを紹介します。挑戦的なKITTIデータセットに関する包括的な実験は、さまざまな評価設定でのVS3Dの優れたパフォーマンスを示しています。 
[ABSTRACT]既存の3Dオブジェクト検出器は、トレーニング中に注釈付き3Dバウンディングボックスに大きく依存しています。これらの注釈は、取得に費用がかかり、限られたシナリオでのみアクセスできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Cross Lingual Speech Emotion Recognition: Urdu vs. Western Languages -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_56.html">
      <font color="black">Cross Lingual Speech Emotion Recognition: Urdu vs. Western Languages</font>
    </a>
  </h2>
  <font color="black">結果として、複数の言語のトレーニングインスタンスを選択すると、ベースラインに匹敵する結果が得られ、テスト言語データの一部が拡張されます。一方、トレーニングは、音声感情認識の精度を高めるのに役立ちます。この研究では、クロスリンガル感情認識の問題を調査しますウルドゥー語の場合、URDUに貢献します---初めての自発的なウルドゥー語音声感情データベース。評価は、ウルドゥー語に対して3つの異なる西洋言語を使用して実行され、さまざまな可能なシナリオでの実験結果により、より適応的な感情認識システムを設計するためのさまざまな興味深い側面が示唆されています。そのような限られた言語。 
[要約]自動音声感情認識システムのパフォーマンスが低下します。テストは、ウルドゥー語に対して3つの異なる西洋言語を使用して実行されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-15">
        <br><font color="black">2018-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: KOVIS: Keypoint-based Visual Servoing with Zero-Shot Sim-to-Real
  Transfer for Robotics Manipulation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_57.html">
      <font color="black">KOVIS: Keypoint-based Visual Servoing with Zero-Shot Sim-to-Real
  Transfer for Robotics Manipulation</font>
    </a>
  </h2>
  <font color="black">データ拡張、ドメインのランダム化、および敵対的な例でトレーニングした後、ゼロショットのsimからrealへの現実世界のロボット操作タスクへの転送を実現できます。ディープニューラルネットワークは、シミュレーション環境でのみトレーニングします。そして訓練されたモデルは、実世界の視覚サーボタスクに直接使用できます。私たちはKOVISを紹介します。 
[ABSTRACT]最初のキーポイントネットワークは、自動エンコーダーを使用して画像からキーポイント表現を学習します。2つのネットワークは、手動でデータをラベル付けすることなく、自己監視学習により視覚化されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Phonocardiographic Sensing using Deep Learning for Abnormal Heartbeat
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_58.html">
      <font color="black">Phonocardiographic Sensing using Deep Learning for Abnormal Heartbeat
  Detection</font>
    </a>
  </h2>
  <font color="black">RNNを使用した私たちの提案するアプローチは、リモート監視アプリケーションのためのInternet of Medical Thingsのリアルタイム異常心拍検出に潜在的に使用できます。さまざまなRNNモデルの使用を調査し、これらのモデルが異常心拍分類スコアを重要な改善..しかし、自動心臓聴診の問題は、信頼性と高精度の要件、および心拍音の背景ノイズの存在のために複雑です。 
[要約]ディープラーニングに基づく心臓聴診は、ヘルスケアコミュニティにとって大きな関心事です。異常な心拍の自動検出により、手動聴診の負担を軽減できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-01-25">
        <br><font color="black">2018-01-25</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Ego and Object 6-DoF Motion Estimation and Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_59.html">
      <font color="black">Robust Ego and Object 6-DoF Motion Estimation and Tracking</font>
    </a>
  </h2>
  <font color="black">提案されたアプローチは仮想KITTIデータセットで評価され、実際のKITTIデータセットでテストされ、自動運転アプリケーションへの適用性を示しています。コンパクトで効果的なフレームワークは、セマンティックインスタンスレベルのセグメンテーションと正確なオプティカルフロー推定の最近の進歩を活用して提案されています。追跡されたポイントの品質とモーション推定の精度を向上させる、SE（3）モーションとオプティカルフローを一緒に最適化する新しい定式化が導入されました。 
[ABSTRACT]モーションデータデータセットは、データを適切に追跡するための鍵です。モーションデータデータデータは米国でテストされています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Context-Aware Dynamic Feature Extraction for 3D Object Detection in
  Point Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_60.html">
      <font color="black">Context-Aware Dynamic Feature Extraction for 3D Object Detection in
  Point Clouds</font>
    </a>
  </h2>
  <font color="black">複数の固定カーネルの位置依存係数を適応的に生成し、それらを組み合わせてローカル機能ウィンドウとたたみ込みます。有効な受容フィールドを拡大するために、元の点群からポイントレベルのコンテキストが生成されます。同じカーネルが異なるサンプルと位置の間で共有される従来の畳み込みの表現能力では、ローカルのセマンティックコンテキストから学習することにより、入力特徴の分散に適応する分解可能な動的畳み込み層を提案します。 
[要約]構造は、ポイントコンテキストとセマンティックコンテキストの両方を考慮して密度の密度を取得するために使用されます。これらは、ボクセル化されたピラーの周囲に抽出され、拡張ボクセル化手法に基づいて、ピラー機能と並行してコンテキストエンコーダーで処理されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-10">
        <br><font color="black">2019-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Accurate, Low-Latency Visual Perception for Autonomous
  Racing:Challenges, Mechanisms, and Practical Solutions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_61.html">
      <font color="black">Accurate, Low-Latency Visual Perception for Autonomous
  Racing:Challenges, Mechanisms, and Practical Solutions</font>
    </a>
  </h2>
  <font color="black">DUT18Dの主要コンポーネントには、YOLOv3ベースのオブジェクト検出、ポーズ推定、およびデュアルステレオビジョン/モノビジョンカメラセットアップでの時間同期が含まれます。レーシングドメインに知覚CNNを適応させるために必要な変更、ポーズ推定に使用される損失関数の改善、および他の改善点の中でサブマイクロ秒のカメラ同期のための方法論。システムの徹底的な実験的評価を行い、実際のレースシナリオでの正確さと低レイテンシを実証します。 
[ABSTRACT]コンピュータービジョンアルゴリズムは、低レーテンシーで高精度の知覚システムであるdut18ドライバーレス（dut18d）を構築しました。4wd電気レースカーは、レースに参加したすべてのフォーミュラドライバーレスコンテストで表彰台を獲得しました。システムを構築するための技術システムの適用</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Combine: Knowledge Aggregation for Multi-Source Domain
  Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_62.html">
      <font color="black">Learning to Combine: Knowledge Aggregation for Multi-Source Domain
  Adaptation</font>
    </a>
  </h2>
  <font color="black">さらに、カテゴリの関係相互依存性の一貫性と機能のコンパクト性を促進するために、Relation Alignment Loss（RAL）を設計します。これにより、機能のクラス内の不変性とクラス間の分離性が向上します。このようなことに基づいて、グラフモデルは相関プロトタイプのガイダンスの下でクエリサンプルを予測することを学習しました。簡単に言うと、知識グラフがさまざまなドメインのプロトタイプに構築され、意味的に隣接する表現間の情報伝播を実現します。 
[要約]さまざまなドメインのプロトタイプに知識グラフが構築され、意味的に隣接する表現間の情報伝播が実現されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-17">
        <br><font color="black">2020-07-17</font>
      </time>
    </span>
</section>
<!-- paper0: Variants of BERT, Random Forests and SVM approach for Multimodal
  Emotion-Target Sub-challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_63.html">
      <font color="black">Variants of BERT, Random Forests and SVM approach for Multimodal
  Emotion-Target Sub-challenge</font>
    </a>
  </h2>
  <font color="black">感情認識は、近年、コンピュータビジョンの主要な問題となっており、研究者はこの課題の困難を克服するために多大な努力を払ってきました。このホワイトペーパーでは、MuSe-Topic Sub-challengeの分類方法を次のように提示して説明します。データと結果も同様です。トピックの分類では、ALBERTとRoBERTaの2つの言語モデルをアンサンブルして、トピックの10クラスを予測します。 
[ABSTRACT]感情認識には、ヘルスケア、ロボット工学、人間とコンピュータの相互作用など、幅広い用途があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Monochrome and Color Polarization Demosaicking Using Edge-Aware Residual
  Interpolation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_64.html">
      <font color="black">Monochrome and Color Polarization Demosaicking Using Edge-Aware Residual
  Interpolation</font>
    </a>
  </h2>
  <font color="black">この論文では、エッジ認識残差補間（EARI）に基づく新しいMPFAデモザイキング手法を提案し、それをCPFAデモザイキングにも拡張します。EARIの鍵は、欠落を補間するために使用される効果的なガイド画像を生成するための新しいエッジ検出器です。ピクセル値。3-CCDカメラと回転偏光子を使用してキャプチャされた、新しく構築されたフルカラー偏光画像データセットも示します。 
[要旨]イメージセンサーにus偏光フィルターアレイ（mpfaまたはcpfa）があります。eariと呼ばれ、新しい方法は効果的なガイドを作成するための新しいエッジ検出器です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Handling confounding variables in statistical shape analysis --
  application to cardiac remodelling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_65.html">
      <font color="black">Handling confounding variables in statistical shape analysis --
  application to cardiac remodelling</font>
    </a>
  </h2>
  <font color="black">ただし、交絡因子が考慮されていない場合、心筋量の増加は検出されません。統計的形状分析は、臓器の形態を評価し、特定の疾患に関連する形状変化を検出するための強力なツールです。交絡補正方法には、交絡収縮と調整。 
[ABSTRACT]人口統計などの交絡因子の不均衡は、考慮に入れないと、分析を無効にする可能性があります。データセット全体の分析は、スポーツ選手の心室容積と心筋量の増加を示し、臨床文献と一致しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: DeScarGAN: Disease-Specific Anomaly Detection with Weak Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CV/paper_66.html">
      <font color="black">DeScarGAN: Disease-Specific Anomaly Detection with Weak Supervision</font>
    </a>
  </h2>
  <font color="black">DeScarGANと呼ばれる方法は、合成データセットおよび胸部X線画像データセットの目視検査で他の異常検出方法よりも優れています。最後に、胸部X線画像でのこの方法のパフォーマンスを示します。特定の私たちの方法を評価し、最先端の異常検出方法と比較するための合成データセット。 
[ABSTRACT]この方法では、既存の解剖学的構造の構造変化を検出できます。これにより、この方法では、疾患-構造変化をより詳細に検出するための特定の特性を抽出できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Deep Transformer based Data Augmentation with Subword Units for
  Morphologically Rich Online ASR -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_0.html">
      <font color="black">Deep Transformer based Data Augmentation with Subword Units for
  Morphologically Rich Online ASR</font>
    </a>
  </h2>
  <font color="black">この方法は、語彙サイズとメモリ要件を大幅に削減しながら、WERを大幅に削減できることを示しています。最後に、サブワードベースのニューラルテキストの拡張が、WER全体だけでなく、 OOV語..したがって、サブワードベースのニューラルテキスト拡張と呼ばれる新しい方法を提案します。この方法では、生成されたテキストを統計的に派生したサブワードに再トークン化します。 
[ABSTRACT]サブワードベースのニューラルテキスト拡張は新しい方法です。生成されたテキストを統計的に導出されたサブワードに削減します。また、全体的な観点から、ワードベースのアプローチよりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-14">
        <br><font color="black">2020-07-14</font>
      </time>
    </span>
</section>
<!-- paper0: Emotion Correlation Mining Through Deep Learning Models on Natural
  Language Text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_1.html">
      <font color="black">Emotion Correlation Mining Through Deep Learning Models on Natural
  Language Text</font>
    </a>
  </h2>
  <font color="black">感情分析は研究者の注意を引いています。コメントは愛の怒りと悲しみの怒りの感情循環を刺激する傾向があります。ニュースリリース後、ネチズンは怒り、悲しみ、愛などの激しい感情を表す感情的なコメントを生成します。 
[ABSTRACT]人工知能分野のこれまでのほとんどの作品は、感情が認識されない、または誤って認識される理由を掘り下げるのではなく、感情を見つけることに焦点を当てています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Transfer Learning for Improving Speech Emotion Classification Accuracy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_2.html">
      <font color="black">Transfer Learning for Improving Speech Emotion Classification Accuracy</font>
    </a>
  </h2>
  <font color="black">結果はまた、トレーニングに多数の言語を使用し、トレーニングでターゲットデータのごく一部を使用することで、トレーニングの例が限られているコーパスでも、ベースラインと比較して精度を大幅に向上できることを示唆しています。この問題を解決するために、このホワイトペーパーでは、言語間およびコーパス間のシナリオで斬新な音声感情認識システムのパフォーマンスを向上させる学習手法。このようなシステムのパフォーマンスは、コーパス間および言語間シナリオで大幅に低下することが示されています。 
[ABSTRACT] 3つの異なる言語での5つの異なるコーパスのテストは、深い信念ネットワークが以前のアプローチよりも優れた精度を提供することを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-01-19">
        <br><font color="black">2018-01-19</font>
      </time>
    </span>
</section>
<!-- paper0: NLPContributions: An Annotation Scheme for Machine Reading of Scholarly
  Contributions in Natural Language Processing Literature -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_3.html">
      <font color="black">NLPContributions: An Annotation Scheme for Machine Reading of Scholarly
  Contributions in Natural Language Processing Literature</font>
    </a>
  </h2>
  <font color="black">自然言語処理（NLP）記事、特にさまざまな情報抽出タスクの機械学習（ML）アプローチについて論じている記事で、学術的貢献を捉えるための注釈イニシアチブについて説明します。50のNLP-ML学術記事のパイロット注釈付きデータセットNLPContributionsスキームによると、https：//github.com/jenlindadsouza/NLPContributions。の研究コミュニティに公開されています。5つの情報抽出への貢献を示す50のNLP-ML学術論文のパイロットアノテーション演習に基づいて、アノテーションタスクを開発します。タスク1.機械翻訳、2。名前付きエンティティの認識、3。質問応答、4。関係の分類、5。テキストの分類。 
[要約]パイロットアノテーションタスクは、50のnlp-mlの文学記事に対するパイロットアノテーション演習に基づいています。目的は4つあります。サブジェクト-述語-オブジェクトステートメントの体系的なパターンセットを見つけることです。これには、データセットの取り込みが含まれます。使いやすい最先端の技術概要を作成するためのショーケースとしてのオープンな研究知識グラフ（orkg）インフラストラクチャ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-23">
        <br><font color="black">2020-06-23</font>
      </time>
    </span>
</section>
<!-- paper0: Big Bird: Transformers for Longer Sequences -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_4.html">
      <font color="black">Big Bird: Transformers for Longer Sequences</font>
    </a>
  </h2>
  <font color="black">途中で、私たちの理論的な分析は、疎アテンションメカニズムの一部としてシーケンス全体に対応する$ O（1）$グローバルトークン（CLSなど）のいくつかの利点を明らかにします。提案された疎アテンションはシーケンスを処理できます長いコンテキストを処理する機能の結果として、BigBirdは、質問応答や要約などのさまざまなNLPタスクのパフォーマンスを大幅に向上させます。 
[ABSTRACT] bigbirdはシーケンス機能の普遍的な模倣者であり、完全に機能しています。提案された密集した注意は、以前可能であったものの最大8倍の長さのシーケンスを処理できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: CUHK at SemEval-2020 Task 4: CommonSense Explanation, Reasoning and
  Prediction with Multi-task Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_5.html">
      <font color="black">CUHK at SemEval-2020 Task 4: CommonSense Explanation, Reasoning and
  Prediction with Multi-task Learning</font>
    </a>
  </h2>
  <font color="black">事後評価中に、システムはサブタスクA（ランク11）で92.9％の精度、サブタスクB（ランク9）で89.7％の精度、サブタスクC（ランク8）で12.9のBLEUスコアに達しました。このペーパーでは、3つのサブタスクで構成されるSemEval 2020のタスク4に提出されたシステムについて説明します。3つのサブタスクで構成されるCommonsense Validation and Explanation（ComVE）。マルチタスク設定のBERTarchitectureに基づいて、効果的で解釈可能な「説明、理由、および常識に関する3つのサブタスクを解決するための予測（ERP）システム：（a）検証、（b）推論、および（c）説明。 
[ABSTRACT]タスクは特定の文を直接検証し、モデルにそれを説明するように要求することです。研究に基づいて、システムは最初に文の理由または理解を生成し、次にどの文が意味があるかを選択します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-12">
        <br><font color="black">2020-06-12</font>
      </time>
    </span>
</section>
<!-- paper0: The STEM-ECR Dataset: Grounding Scientific Entity References in STEM
  Scholarly Content to Authoritative Encyclopedic and Lexicographic Sources -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_6.html">
      <font color="black">The STEM-ECR Dataset: Grounding Scientific Entity References in STEM
  Scholarly Content to Authoritative Encyclopedic and Lexicographic Sources</font>
    </a>
  </h2>
  <font color="black">私たちの調査結果は累積的に、人間の注釈と学際的な科学的概念の自動学習、ならびにSTEMとしての幅広い設定でのそれらの意味の明確化が合理的であることを示しています。科学エンティティ用のSTEM（科学、技術、工学、および医学）データセットを導入します抽出、分類、および解決、バージョン1.0（STEM-ECR v1.0）。このような集学的コーパスの作成について説明し、次の機能の観点から得られた結果を強調します。1）科学エンティティの一般的な概念形式学際的な科学的文脈; 2）そのような一般的な形式の下での科学的エンティティのドメインに依存しない人間の注釈の実現可能性; 3）BERTベースのニューラルモデルを使用して学際的な科学エンティティを自動抽出するために取得可能なパフォーマンスベンチマーク。 4）百科事典のエンティティリンクと辞書式単語感覚の曖昧性解消による科学エンティティの人間による注釈付けのための、3ステップのエンティティ解決手順。 5）Babelfyの人間による評価は、私たちのエンティティに百科事典のリンクと辞書式感覚を返しました。 
[要約]ステム-ecr v1。 0データセットは、科学的エンティティの評価のベンチマークを提供するために開発されました。自動v1のパフォーマンスベンチマーク取得機能を提供します。調査結果には、学際的な科学的コンテキストにおける科学的エンティティの一般的な概念形式が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-02">
        <br><font color="black">2020-03-02</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring the Limits of Transfer Learning with a Unified Text-to-Text
  Transformer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_7.html">
      <font color="black">Exploring the Limits of Transfer Learning with a Unified Text-to-Text
  Transformer</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、すべてのテキストベースの言語の問題をテキストからテキストへのフォーマットに変換する統一されたフレームワークを導入することにより、NLPの転移学習技術の全体像を探ります。私たちの調査から得られた洞察をスケールと新しい ` 「Colossal Clean Crawled Corpus」では、要約、質問応答、テキスト分類などをカバーする多くのベンチマークで最先端の結果を達成しています。NLPの転移学習に関する将来の作業を容易にするために、データセットをリリースしています。事前トレーニング済みのモデルとコード。 
[要約]転移学習の効果により、多様なアプローチが生まれました。データセット、事前トレーニング済みモデル、コードをリリースしています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-23">
        <br><font color="black">2019-10-23</font>
      </time>
    </span>
</section>
<!-- paper0: BUT-FIT at SemEval-2020 Task 5: Automatic detection of counterfactual
  statements with deep pre-trained language representation models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_8.html">
      <font color="black">BUT-FIT at SemEval-2020 Task 5: Automatic detection of counterfactual
  statements with deep pre-trained language representation models</font>
    </a>
  </h2>
  <font color="black">サブタスク2の完全一致とF1の両方で1位を達成し、サブタスク1で2番目にランク付けしました。RoBERTaLRMが両方のサブタスクで最高のパフォーマンスを発揮することを発見しました。さまざまな最先端の言語表現モデル（ LRM）。 
[要約]課題は、特定のサブタスク1であるかどうかを検出し、反事実の前件と後件の両方を抽出することに焦点を当てました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Preparation of Sentiment tagged Parallel Corpus and Testing its effect
  on Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_9.html">
      <font color="black">Preparation of Sentiment tagged Parallel Corpus and Testing its effect
  on Machine Translation</font>
    </a>
  </h2>
  <font color="black">翻訳モデルの出力は、BLEUやTERなどの自動化されたメトリックを使用してベースライン翻訳モデルと手動で比較されています。現在の作業では、トレーニング並列コーパスが使用されている場合の機械翻訳出力の充実度を調査します。感情分析の導入で強化されました。このペーパーでは、同じ感情をタグ付けした英語-ベンガル語対訳コーパスの準備について説明します。 
[ABSTRACT]このペーパーでは、新しい英語の準備について説明しています-ベンガル語の対訳コーパス。同じキャラクターのトレーニングについて説明しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Reasoning with Latent Structure Refinement for Document-Level Relation
  Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_10.html">
      <font color="black">Reasoning with Latent Structure Refinement for Document-Level Relation
  Extraction</font>
    </a>
  </h2>
  <font color="black">さらに、広範な分析により、モデルがより正確な文間の関係を発見できることがわかります。さらに、モデルがマルチホップ推論の関連情報を段階的に集約できるようにする改良戦略を開発します。具体的には、このモデルではF1大規模なドキュメントレベルのデータセット（DocRED）でのスコアは59.05で、以前の結果を大幅に改善し、CDRおよびGDAデータセットに新しい最先端の結果をもたらします。 
[ABSTRACT]モデルはドキュメント内の主要な協力情報を取り込むことができます。しかし、それは効果的な協力協力がいかに必要であるかという課題のままです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-13">
        <br><font color="black">2020-05-13</font>
      </time>
    </span>
</section>
<!-- paper0: Deep learning models for representing out-of-vocabulary words -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_11.html">
      <font color="black">Deep learning models for representing out-of-vocabulary words</font>
    </a>
  </h2>
  <font color="black">ベンチマークデータセットを使用した本質的な評価と、さまざまなNLPタスク（テキストの分類、名前付きエンティティの認識、品詞のタグ付け）を使用した外部の評価を実行しました。結果から、OOVワードを処理するための最適な手法はそれぞれ異なることがわかりましたタスク、Comick、OOV単語のコンテキストと形態学的構造に基づいて埋め込みを推論するディープラーニング手法で、有望な結果が得られました。これらの単語は、モデルでは未知であり、語彙外（OOV）単語として知られています。 、テキストの適切なベクトル表現に依存する自然言語処理（NLP）アプリケーションの品質を低下させないように適切に処理する必要があります。 
[要約]結果は、oovワードの処理に最適な手法はtask.comickごとに異なることを示していました。これは、oovワードのコンテキストに基づいて埋め込みを推論するディープラーニングメソッドであり、有望な結果が得られました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-14">
        <br><font color="black">2020-07-14</font>
      </time>
    </span>
</section>
<!-- paper0: Information Extraction of Clinical Trial Eligibility Criteria -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_12.html">
      <font color="black">Information Extraction of Clinical Trial Eligibility Criteria</font>
    </a>
  </h2>
  <font color="black">私たちは問題を新しい知識ベースの人口タスクとして組み立て、機械学習と文脈自由文法を組み合わせたソリューションを実装します。最後に、モジュールごとのパフォーマンスとエンドツーエンドのパフォーマンスを報告します。私たちのシステムは、Criteria2Queryと競争力があると結論付けます。これは、現在の最先端の基準抽出と見なしています。この作業は、私たちの知る限り、注意ベースの条件付きランダムフィールドアーキテクチャを適用した最初の基準抽出システムです。名前付きエンティティ認識（NER）、および名前付きエンティティリンク（NEL）のためのword2vec埋め込みクラスタリング。 
[ABSTRACT]テストは、名前付きエンティティの認識に注意ベースの条件付きランダムフィールドアーキテクチャを適用する最初の基準抽出システムです。word2vec埋め込みクラスタリングを名前付きエンティティリンク（ner）に埋め込みます。モジュールごとのパフォーマンスとエンドツーエンドのパフォーマンスを報告します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-12">
        <br><font color="black">2020-06-12</font>
      </time>
    </span>
</section>
<!-- paper0: ECNU-SenseMaker at SemEval-2020 Task 4: Leveraging Heterogeneous
  Knowledge Resources for Commonsense Validation and Explanation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_13.html">
      <font color="black">ECNU-SenseMaker at SemEval-2020 Task 4: Leveraging Heterogeneous
  Knowledge Resources for Commonsense Validation and Explanation</font>
    </a>
  </h2>
  <font color="black">その結果、このモデルは検証と説明の両方で非常にうまく機能します。さらに、内部共有メカニズムが協力して、モデルが常識に対して不十分で過度な推論をするのを防ぎます。ConceptNet）と構造化されていないテキストにより、マシンの能力が向上します常識的に理解しています。 
[ABSTRACT]このタスクには、新しい知識-強化されたグラフアテンションネットワーク（kegat）アーキテクチャを提案します。構造化された知識ベースの両方からの異種の知識を活用します。たとえば、システムは検証と説明の両方に非常によく機能します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Cross Lingual Speech Emotion Recognition: Urdu vs. Western Languages -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_14.html">
      <font color="black">Cross Lingual Speech Emotion Recognition: Urdu vs. Western Languages</font>
    </a>
  </h2>
  <font color="black">この研究では、ウルドゥー語の言語間感情認識の問題を調査し、URDUに貢献します。これは、史上初の自発的なウルドゥー語音声感情データベースです。URDUデータは、さらなる研究のために公開されています。結果として、トレーニングの選択複数言語のインスタンスは、ベースラインに匹敵する結果を提供し、テスト言語データの一部を増強することができ、トレーニングは、音声感情認識の精度を高めるのに役立ちます。 
[要約]自動音声感情認識システムのパフォーマンスが低下します。テストは、ウルドゥー語に対して3つの異なる西洋言語を使用して実行されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-15">
        <br><font color="black">2018-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Results on Russian Sentiment Datasets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_15.html">
      <font color="black">Improving Results on Russian Sentiment Datasets</font>
    </a>
  </h2>
  <font color="black">この研究では、標準のニューラルネットワークアーキテクチャ（CNN、LSTM、BiLSTM）をテストし、以前のロシアの感情評価データセットにBERTアーキテクチャを最近発表しました。ロシアのBERTの2つのバリアントを比較し、この研究のすべての感情タスクについて、会話型バリアントを示します。ロシアのBERTのパフォーマンスは向上します。最高の結果は、感情分類タスクを自然言語推論タスクとして扱うBERT-NLIモデルによって達成されました。 
[ABSTRACT] cnnの研究者は、ロシアのbertの2つのバリアントを比較し、この研究のすべての感情タスクで、ロシア語のデータの会話型のバリアントがより優れていることを示しています。データセットの1つで、このモデルはほぼ人間のレベルを達成しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: YNU-HPCC at SemEval-2020 Task 8: Using a Parallel-Channel Model for
  Memotion Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_16.html">
      <font color="black">YNU-HPCC at SemEval-2020 Task 8: Using a Parallel-Channel Model for
  Memotion Analysis</font>
    </a>
  </h2>
  <font color="black">BiLSTM、BIGRU、およびアテンションモデルを組み合わせたアンサンブルモデルを適用して、クロスドメイン提案マイニングを実行しました。次に、トランスフォーマー（BERT）からの双方向エンコーダー表現と2種類の畳み込みニューラルネットワークモデル（ CNN）を使用して、写真から特徴を抽出しました。この問題に対処するために、このペーパーでは、ミームのテキスト情報と視覚情報を処理し、ミームの感情の極性を分析するパラレルチャネルモデルを提案しました。 
[要約]インターネットはソーシャルテキストよりも複雑です。これには視覚的な手がかりと言語の理解が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Socially Responsible AI: Cognitive Bias-Aware Multi-Objective
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_17.html">
      <font color="black">Towards Socially Responsible AI: Cognitive Bias-Aware Multi-Objective
  Learning</font>
    </a>
  </h2>
  <font color="black">予測出力の可能なクラスの機密カテゴリのサブセットは、それらの特定の組み合わせを予測する頻度を減らすことを学習します。事前にバランスの取れたクラスの感情予測タスクで行った実験は、ベースラインバイアスにとらわれないモデルのセットが、女性が恐れる傾向があるのに対し、男性はより怒りがちであるなど、性別に関する認知バイアスを示すことを示しています。 「ほとんどの黒人は虐待的な言葉を使う」、「恐怖は女性の美徳だ」など。 
[ABSTRACT]履歴データの社会的偏見は偏見につながる可能性があるとaiシステムは述べています。「多目的学習手法」は予測された感情の偏りを減らすことが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-14">
        <br><font color="black">2020-05-14</font>
      </time>
    </span>
</section>
<!-- paper0: SalamNET at SemEval-2020 Task12: Deep Learning Approach for Arabic
  Offensive Language Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_18.html">
      <font color="black">SalamNET at SemEval-2020 Task12: Deep Learning Approach for Arabic
  Offensive Language Detection</font>
    </a>
  </h2>
  <font color="black">私たちの目標を追求するために、異なるデザインアーキテクチャを備えたリカレントニューラルネットワーク（RNN）、ゲーテッドリカレントユニット（GRU）、およびLong-Short Term Memory（LSTM）モデルが開発および評価されています。SalamNET、双方向ゲーテッドRecurrent Unit（Bi-GRU）ベースのモデルは、0.83のマクロF1スコアを報告します。このペーパーでは、SamEval 2020共有タスク12：ソーシャルメディアでの多言語攻撃言語識別に提出されたアラビア語の攻撃言語検出システムであるSalamNETについて説明します。 
[要旨]私たちのシステムは、複数のディープラーニングモデルの適用と結果の詳細なエラー分析の実施に重点を置いています。長距離モデルのsalamnetは、マクロ-f1スコア0を報告します。83</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Word embedding and neural network on grammatical gender -- A case study
  of Swedish -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_19.html">
      <font color="black">Word embedding and neural network on grammatical gender -- A case study
  of Swedish</font>
    </a>
  </h2>
  <font color="black">ケーススタディとしてスウェーデン語の名義分類を取り上げ、まず、言語の文法上の性別に関する情報が、単語埋め込みモデルと人工ニューラルネットワークによってどのように取得できるかを示します。スウェーデン語の文法上の性別に関する単語埋め込みによって提供される情報を分析します。次に、スウェーデン語での文法上の性別の割り当てと使用法に関する以前の言語仮説と結果を照合し、計算モデルによって作成されたエラーを言語の観点から分析します。 
[要約]この論文が数学の方法をつなぐ架け橋の一つとして役立つことを願っています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Variants of BERT, Random Forests and SVM approach for Multimodal
  Emotion-Target Sub-challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/cs.CL/paper_20.html">
      <font color="black">Variants of BERT, Random Forests and SVM approach for Multimodal
  Emotion-Target Sub-challenge</font>
    </a>
  </h2>
  <font color="black">この論文では、MuSe-Topic Sub-challengeの分類方法、ならびにデータと結果を提示し、議論します。感情認識は、近年コンピュータビジョンの主要な問題となっており、研究者は多くの努力を払っていますこのタスクの困難を克服してください。他のタスクに対する実用的な重要性のため、さまざまな問題とさまざまなデータソースについて、多くの手法とアプローチが調査されてきました。 
[ABSTRACT]感情認識には、ヘルスケア、ロボット工学、人間とコンピュータの相互作用など、幅広い用途があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Dual-Path Transformer Network: Direct Context-Aware Modeling for
  End-to-End Monaural Speech Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.AS/paper_0.html">
      <font color="black">Dual-Path Transformer Network: Direct Context-Aware Modeling for
  End-to-End Monaural Speech Separation</font>
    </a>
  </h2>
  <font color="black">さらに、デュアルパスの構造により、非常に長い音声シーケンスモデリングでモデルが効率的になります。このアプローチの改良されたトランスフォーマーは、元のトランスフォーマーにリカレントニューラルネットワークを組み込むことにより、位置エンコーディングなしで音声シーケンスの順序情報を学習します。ベンチマークデータセットでの実験は、私たちのアプローチが現在の最先端技術（パブリックWSj0-2mixデータコーパスで20.6 dB SDR）よりも優れていることを示しています。 
[要約]エンドツーエンドのスピーチ分離のためのデュアルパストランスフォーマーネットワーク（dptnet）。これにより、直接的なコンテキストが導入され、スピーチシーケンスのモデリングに認識がもたらされます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Transformer based Data Augmentation with Subword Units for
  Morphologically Rich Online ASR -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.AS/paper_1.html">
      <font color="black">Deep Transformer based Data Augmentation with Subword Units for
  Morphologically Rich Online ASR</font>
    </a>
  </h2>
  <font color="black">Transformerで生成されたテキストを使用したデータ拡張は、言語の分離には効果的ですが、形態学的にリッチな言語で語彙が爆発的に増加することを示しています。 、サブワードベースのニューラルテキスト拡張と呼ばれる新しい方法を提案します。この方法では、生成されたテキストを統計的に導出されたサブワードに再トークン化します。 
[ABSTRACT]サブワードベースのニューラルテキスト拡張は新しい方法です。生成されたテキストを統計的に導出されたサブワードに削減します。また、全体的な観点から、ワードベースのアプローチよりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-14">
        <br><font color="black">2020-07-14</font>
      </time>
    </span>
</section>
<!-- paper0: Voice activity detection in the wild via weakly supervised sound event
  detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.AS/paper_2.html">
      <font color="black">Voice activity detection in the wild via weakly supervised sound event
  detection</font>
    </a>
  </h2>
  <font color="black">これとは対照的に、クリップレベルのラベルのみを必要とする、監視の弱い方法でノイズの多いデータから簡単にトレーニングできる汎用VAD（GPVAD）フレームワークを提案します。CRNNベースの標準VADモデルに対して2つのGPVモデルを評価します（VAD-C）3つの異なる評価プロトコル（クリーン、合成ノイズ、実際のデータ）について。527オーディオセットサウンドイベントでトレーニングされた1つのフル（GPV-F）と1つのバイナリ（GPV-B）の2つのGPVADモデルを提案しました。 、音声とノイズのみを区別します。 
[要約] 2つのgpvadモデルを提案しました。1つはフル（gpv -f）、527個のオーディオセットサウンドイベントでトレーニングされ、1つはバイナリ（gpv）で、音声とノイズのみを区別します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-27">
        <br><font color="black">2020-03-27</font>
      </time>
    </span>
</section>
<!-- paper0: A Comparative Study of Multilateration Methods for Single-Source
  Localization in Distributed Audio -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.AS/paper_3.html">
      <font color="black">A Comparative Study of Multilateration Methods for Single-Source
  Localization in Distributed Audio</font>
    </a>
  </h2>
  <font color="black">関連する参考文献の調査に加えて、社内のルームインパルス応答データセットに基づいて、いくつかの「主流」マルチラテレーションアルゴリズムの小規模ベンチマークの結果を提示します。ただし、マルチラテレーション問題は、閉形式を認めていません。これらの方法は、計算ノードで効率がよく、信号に依存せず、センシングノードの数とその空間配置に関して柔軟です。 
[ABSTRACT]これらの方法は、人工的に効率的で、信号が遅れ、柔軟です。ただし、センシングノードの数とその空間配置に関しては、より効率的でマルチタスクです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-23">
        <br><font color="black">2019-10-23</font>
      </time>
    </span>
</section>
<!-- paper0: Direct Modelling of Speech Emotion from Raw Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.AS/paper_4.html">
      <font color="black">Direct Modelling of Speech Emotion from Raw Speech</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、提案されたモデルが、IEMOCAPとMSP-IMPROVデータセットの両方からハンドエンジニアリングされた機能でトレーニングされたCNNのパフォーマンスに到達できることを示唆しています。この論文では、文脈情報のモデル化においてCNNの特性を利用することにより、生の音声からの感情認識のパフォーマンスを改善する機会がまだあることを示します。 
[要約] cnnsと長期短期記憶（lstm）は、感情認識に重要なコンテキスト情報を学習する際のlstmの本質的な特性を牽引しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-08">
        <br><font color="black">2019-04-08</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Attentive Multi-Layer Aggregation with Feature Recalibration and
  Normalization for End-to-End Speaker Verification System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.AS/paper_5.html">
      <font color="black">Self-Attentive Multi-Layer Aggregation with Feature Recalibration and
  Normalization for End-to-End Speaker Verification System</font>
    </a>
  </h2>
  <font color="black">モデルパラメーターの数を減らすために、チャネル幅と層の深さをスケーリングしたResNetがベースラインとして使用されます。トレーニングの変動性を制御するために、自己注意メカニズムが適用され、ドロップアウト付きの多層集約を実行します正規化とバッチの正規化.. VoxCeleb1評価データセットを使用した実験結果は、提案された方法のパフォーマンスが最先端のモデルのパフォーマンスに匹敵することを示しました（VoxCeleb1とVoxCeleb2を使用すると、エラー率は4.95％と2.86％になります）それぞれトレーニングデータセット）。 
[ABSTRACT]ショートカット接続により、スピーカーの埋め込みの表現力が向上します。そのため、エンドツーエンドのエンドツーエンドのスピーカー検証システム用の自己注意深い多層集合体を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Kalman Filtering for Speech Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.AS/paper_6.html">
      <font color="black">Neural Kalman Filtering for Speech Enhancement</font>
    </a>
  </h2>
  <font color="black">2つの中間的なクリーンな音声推定は、最初にリカレントニューラルネットワーク（RNN）と線形ウィーナーフィルタリング（WF）から個別に生成され、学習されたNKFゲインによって線形結合されて、NKF出力を生成します。 WFによる瞬時線形推定とRNNによる長期非線形推定の間のトレードオフが自動的に行われます。さまざまなノイズ条件での実験により、提案された方法は、客観的な評価指標と自動音声認識（ASR）の単語エラー率（WER）。 
[要約]提案された方法は、音声強調のための新しいシステムの構築を支援するために使用できます。また、ニューラルカルマンフィルタリング（nkf）にも使用できます。また、ニューラルカルマンフィルター（nkf&#39;s）にも採用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Adversarial Domain Adaptation for Cross-Lingual Speech
  Emotion Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.AS/paper_7.html">
      <font color="black">Unsupervised Adversarial Domain Adaptation for Cross-Lingual Speech
  Emotion Recognition</font>
    </a>
  </h2>
  <font color="black">提案されたモデルは、ターゲット言語のデータラベルを必要とせずに言語不変の表現を学習できるように設計されています。これらの違いは、トレーニングデータとテストデータが異なる言語に属している場合により明確になり、検証とテストの間に大きなパフォーマンスギャップが生じます。スコア..クロスリンガル音声感情認識（SER）は、多くの現実世界のアプリケーションにとって重要なタスクです。 
[ABSTRACT]たとえば、serシステムの実際のアプリケーションに適合できる、より堅牢なモデルを構築する必要があります。私たちの言語モデルは、基礎となるデータ分布の学習での大きな成功が動機です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-13">
        <br><font color="black">2019-07-13</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervised Neural Audio-Visual Sound Source Localization via
  Probabilistic Spatial Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.AS/paper_8.html">
      <font color="black">Self-supervised Neural Audio-Visual Sound Source Localization via
  Probabilistic Spatial Modeling</font>
    </a>
  </h2>
  <font color="black">画像内の音源オブジェクトをローカライズするためのシステムは、オーディオとビジュアルのDNNで構成されています。これらのDNNは、確率的空間オーディオモデルに基づいて、自己監視方式で共同トレーニングされます。オーディオDNNは、各候補が実際に音を出すかどうかを確認します。ない。 
[要約]私たちの方法は、複数の音源オブジェクトを区別するためにディープニューラルネットワーク（dnns）をトレーニングします。視覚的なdnnは、入力画像内の音源候補を特定するようにトレーニングされます。これらのdnnは、確率的空間に基づいて、自己監視方式で共同トレーニングされます音声モデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: A Hybrid Approach to Audio-to-Score Alignment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.AS/paper_9.html">
      <font color="black">A Hybrid Approach to Audio-to-Score Alignment</font>
    </a>
  </h2>
  <font color="black">オーディオからスコアへのアラインメントは、パフォーマンスオーディオと特定の曲のスコアとの間の正確なマッピングを生成することを目的としています。さまざまな音響条件からの音楽データに対する実験は、この方法が同時に適応可能でありながら、堅牢なアラインメントを生成することを示しています。調整方法は動的時間ワーピング（DTW）に基づいており、手作りの機能を採用しています。 
[ABSTRACT]標準的な位置合わせ方法は、動的タイムワーピング（dtw）に基づいており、自動スタイル機能を採用しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Siamese x-vector reconstruction for domain adapted speaker recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.AS/paper_10.html">
      <font color="black">Siamese x-vector reconstruction for domain adapted speaker recognition</font>
    </a>
  </h2>
  <font color="black">ドメイン適応用のSiamese x-vector Reconstruction（SVR）を紹介します。x-vectorトレーニングデータとターゲットデータ間、または登録データとテストデータ間で不一致です。リーン補助シャムDNNを使用した低品質の対応物。 
[ABSTRACT] x-シナリオはディープニューラルネットワーク（dnn）に基づいています。リーン補助を使用して、より高品質の信号の埋め込みを再構築します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Statistical and Neural Network Based Speech Activity Detection in
  Non-Stationary Acoustic Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.AS/paper_11.html">
      <font color="black">Statistical and Neural Network Based Speech Activity Detection in
  Non-Stationary Acoustic Environments</font>
    </a>
  </h2>
  <font color="black">統計的SADは、以前に提案されたニューラルネットワークベースのSADに匹敵する検出性能を実現しますが、ニューラルネットワークベースのアプローチは、2020年のフィアレスステップチャレンジの評価セットで1.07％の決定コスト関数につながり、新しい最先端技術を設定します。 。音響シーンの時間変化により音声とノイズを区別することが困難になるため、非定常環境では、ノイズが音声よりも「定常的」であるという事実にしばしば依存する音声アクティビティ検出（SAD）が特に困難です。 ..後者は、非定常ノイズの存在下で時間平滑化を行うために入力音声の短いセグメントで動作する反復ネットワーク層を導入します。 
[要約] sadには2つのアプローチがあり、1つは統計的信号処理に基づいています。もう1つは、入力音声の短いセグメントで動作するリカレントネットワークレイヤーを導入します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br><font color="black">2020-05-20</font>
      </time>
    </span>
</section>
<!-- paper0: MCSAE: Masked Cross Self-Attentive Encoding for Speaker Embedding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.AS/paper_12.html">
      <font color="black">MCSAE: Masked Cross Self-Attentive Encoding for Speaker Embedding</font>
    </a>
  </h2>
  <font color="black">これらは、以前の自己注意型エンコーディングおよび最先端のエンコーディング方法と比較してパフォーマンスが向上しました。MCSAEでは、クロス自己注意モジュールが各入力フィーチャの相互依存性をトレーニングします。ランダムマスキング正則化モジュールも適用されました過剰適合問題を防ぐために。 
[ABSTRACT]これはマルチレイヤの集約に基づいています。各残余レイヤの出力機能はmcsaeに使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-28">
        <br><font color="black">2020-01-28</font>
      </time>
    </span>
</section>
<!-- paper0: Variational Autoencoders for Learning Latent Representations of Speech
  Emotion: A Preliminary Study -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.AS/paper_13.html">
      <font color="black">Variational Autoencoders for Learning Latent Representations of Speech
  Emotion: A Preliminary Study</font>
    </a>
  </h2>
  <font color="black">IEMOCAPデータセットの評価は、VAEによって学習された機能が音声感情分類の最先端の結果を生成できることを示しています。現在、手作りの機能は主に音声感情の認識に使用されていますが、ディープラーニングを使用して自動的に学習された機能は強い多くの問題、特に画像処理での成功。私たちの知る限り、音声感情分類用のVAEを最初に提案しました。 
[ABSTRACT]音声感情認識では、学習機能が重要です。これはファッション脱線を提案する最初の時間です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2017-12-23">
        <br><font color="black">2017-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting and analysing spontaneous oral cancer speech in the wild -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.AS/paper_14.html">
      <font color="black">Detecting and analysing spontaneous oral cancer speech in the wild</font>
    </a>
  </h2>
  <font color="black">この論文では、1）を提示し、2）YouTubeから収集された3時間の長さの自発的な口腔癌の音声データセットを分析します。口腔癌の音声分析はこれまでのところ、読み上げの音声に重点を置いています。口腔癌の音声は、さらに影響を与える疾患です毎年世界中で50万人を超える人々。 
[要約]口腔癌の発話の分析はこれまでのところ、発話の読み上げに焦点を合わせてきました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal Integration for Large-Vocabulary Audio-Visual Speech
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.AS/paper_15.html">
      <font color="black">Multimodal Integration for Large-Vocabulary Audio-Visual Speech
  Recognition</font>
    </a>
  </h2>
  <font color="black">ここで多くの利点を提供することが示されている1つの側面は、ダイナミックストリーム信頼性インジケーターの使用です。これにより、オーディオチャネルが少しでも歪んでいるときはいつでも、ハイブリッドアーキテクチャーが視覚情報を含めることで大きな利益を得ることができます。これらのゲインを大語彙認識に変換できるマルチモーダル情報の最適な組み合わせ戦略に関する継続的な議論。以下では、LRS2データベースの大語彙タスクを具体的に検討し、調査します。初期の統合とエンドツーエンドの学習をハイブリッド認識と動的ストリーム重み付けの多くのバージョンと比較する、幅広い統合戦略。 
[ABSTRACT]マルチモーダル情報の最適な組み合わせ戦略についての議論がまだあります。これにより、大きな語彙認識へのストリーミングゲインが可能になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Autosegmental Neural Nets: Should Phones and Tones be Synchronous or
  Asynchronous? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-29/eess.AS/paper_16.html">
      <font color="black">Autosegmental Neural Nets: Should Phones and Tones be Synchronous or
  Asynchronous?</font>
    </a>
  </h2>
  <font color="black">同期モデルと非同期モデルの両方が、多言語設定とクロス言語設定の両方で効果的です。同期モデルでは、電話とトーンの共同階層でエラーレートが低くなりますが、非同期トレーニングでは、トーンエラーレートが低くなります。 Temporal Classification（CTC）ベースの音響モデル。電話とトーンの同期の度合いが異なります。 
[要約] lexiosは、3つの言語で多言語でトレーニングおよびテストされます。次に、相互に適応され、クロスリンガルでテストされます。これらは、4番目の言語でテストされ、どちらもより低いエラーを達成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
