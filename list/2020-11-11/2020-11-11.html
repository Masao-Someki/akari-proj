<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-11-11の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Enhancing Low-Quality Voice Recordings Using Disentangled Channel Factor
  and Neural Waveform Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.SD/paper_0.html">
      <font color="black">Enhancing Low-Quality Voice Recordings Using Disentangled Channel Factor
  and Neural Waveform Model</font>
    </a>
  </h2>
  <font color="black">また、いくつかの最先端のベースラインシステムと比較して、音声強調のパフォーマンスが向上します。最後に、ニューラルボコーダーを適用して音声波形を合成します。実験結果は、提案されたシステムがプロフェッショナルな高品質の音声波形を生成できることを示しています。高品質のオーディオを基準として設定する場合。 
[ABSTRACT]次に、自己回帰デコーダーを使用して、ターゲットを予測します-環境メルスペクトログラム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Convolutional Speech Recognition with Pitch and Voice Quality Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.SD/paper_1.html">
      <font color="black">Convolutional Speech Recognition with Pitch and Voice Quality Features</font>
    </a>
  </h2>
  <font color="black">私たちの知る限り、これは、このようなピッチと音声品質の機能を最新の畳み込みアーキテクチャと組み合わせた最初の作業であり、公開されているスペイン語のCommonVoiceとLibriSpeech100hデータセットについて、それぞれ最大7％と3％の相対WERポイントの改善を示しています。さらに、私たちの知る限り、スペイン語のCommon Voiceレシピは、wav2letterの最初の公開スペイン語レシピです。最新のCNNモデルにピッチやジッターやキラキラなどの音声品質機能を追加した場合の効果この作業では、自動音声認識について学習します。 
[ABSTRACT]ピッチ機能は、以前は古典的なhrおよびdnnベースラインを改善するために使用されていました。ジッターおよびシマーパラメーターは、最新のタスクに役立つことが証明されています。ソフトウェアは、Facebookのwav2letter音声認識フレームワークに追加されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Deconstruct and Reconstruct Dizi Music of the Northern School and the
  Southern School -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.SD/paper_2.html">
      <font color="black">Deconstruct and Reconstruct Dizi Music of the Northern School and the
  Southern School</font>
    </a>
  </h2>
  <font color="black">特徴は、2つの異なる音楽スタイルのメロディーと演奏技術を分解します。再構成の例、メロディー転送と演奏技術転送を含む音楽スタイル転送を行い、主観的評価を行って再構成結果を評価します。今日の中国音楽の研究テクノロジーは主に、データ収集、音楽の分解、音楽の再構築という3つの側面に焦点を当てています。 
[概要]中国の音楽を収集するための新しい方法が提案されています。diziデータセットは、この方法を使用して収集されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Pretraining Strategies, Waveform Model Choice, and Acoustic
  Configurations for Multi-Speaker End-to-End Speech Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.SD/paper_3.html">
      <font color="black">Pretraining Strategies, Waveform Model Choice, and Acoustic
  Configurations for Multi-Speaker End-to-End Speech Synthesis</font>
    </a>
  </h2>
  <font color="black">単純な品質しきい値を超えた、見つかったオーディオブックデータからマルチスピーカーモデルを微調整すると、合成音声の見えないターゲットスピーカーとの自然さと類似性が向上することがわかります。さらに、リスナーは16kHzと24kHzのサンプリングを識別できることがわかります。 WaveRNNは、WaveNetと同等の品質の出力波形を生成し、推論時間が短縮されます。ゼロショットマルチスピーカーのエンドツーエンドに最適な戦略を選択することを目的として、ベースコーパスの選択を含む事前トレーニング戦略を検討します。合成を終了します。 
[概要]リスナーが16khzと24khzのサンプリングレートを識別できることを確認します。wavernnはwavenetと同等の品質の出力波形を生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Supervised attention for speaker recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.SD/paper_4.html">
      <font color="black">Supervised attention for speaker recognition</font>
    </a>
  </h2>
  <font color="black">ただし、一部の設定では、SAPは時間平均プーリング（TAP）ベースラインと比較してパフォーマンスが低く、エンドツーエンドのトレーニングでは注意が効果的に学習されないことを意味します。提案された方法では、コンテキストベクトルをブーストして選択することができます。最も有益なフレーム..この問題に取り組むために、分類されたサンプルを使用してコンテキストベクトルを学習する監視された方法で注意メカニズムをトレーニングするための戦略を紹介します。 
[概要] SAPシステムでは、コンテキストセンサーは特徴抽出器と一緒に終了するようにトレーニングされます。コンテキストプールの役割は、話者認識のために最もベースラインのフレームを選択することです。この方法は、短い発話話者を含むさまざまな実験設定で既存の方法よりも優れています。認識</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Time-Frequency Scattering Accurately Models Auditory Similarities
  Between Instrumental Playing Techniques -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.SD/paper_5.html">
      <font color="black">Time-Frequency Scattering Accurately Models Auditory Similarities
  Between Instrumental Playing Techniques</font>
    </a>
  </h2>
  <font color="black">この記事では、31人の被験者に、78個の孤立した音を音色クラスターのセットに編成するように依頼します。さらに、楽器、ミュート、テクニック全体の聴覚類似性のクラスターグラフを復元するためのマシンリスニングモデルを提案します。応答は、音色の知覚が、楽器や演奏技術だけで提供されるものよりも柔軟な分類法の範囲内で機能することを示唆しています。 
[ABSTRACT]音色の知覚は、楽器や演奏技術だけで提供されるものよりも柔軟な分類内で機能します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-21">
        <br><font color="black">2020-07-21</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Neural Networks Optimally Compress the Sawbridge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.IV/paper_0.html">
      <font color="black">Neural Networks Optimally Compress the Sawbridge</font>
    </a>
  </h2>
  <font color="black">このソースの最適なエントロピーと歪みのトレードオフを正確に特徴付け、確率的勾配降下法によってトレーニングされたニューラルネットワークベースのコンプレッサーによって達成されることを数値的に示します。ニューラルネットワークベースのコンプレッサーは、ソースの圧縮に非常に効果的であることが証明されています。画像として、名目上は高次元ですが、低次元の多様体に集中していると推定されます。このようなソースの極端なバージョンをモデル化する連続時間ランダムプロセスを検討します。このプロセスでは、実現は1次元に沿って行われます。無限次元の線形スパンを持つ関数空間の「曲線」。 
[概要]連続時間ランダムプロセスは、そのようなソースの極端なバージョンをモデル化します。光子は、無限の父線形スパンを持つ関数空間の1幅の「曲線」に沿って落下します。また、分析的および実験的に、フレームが非常に抑圧的</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Classification of optics-free images with deep neural networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.IV/paper_1.html">
      <font color="black">Classification of optics-free images with deep neural networks</font>
    </a>
  </h2>
  <font color="black">可能な限り薄いカメラは、イメージセンサーのみを残して、すべての光学系を削除することで実現されます。光学系のない画像からの推論は、プライバシーと電力効率を向上させる可能性があります。マルチクラス検出とバイナリ分類を実行するようにディープニューラルネットワークをトレーニングします（人体中心の画像再構成を必要とせずに、光学系のない画像で92％の精度で）。 
[概要]ディープニューラルネットワークをトレーニングして、マルチクラス検出と二項分類を実行します（精度92％）。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Point of Care Image Analysis for COVID-19 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.IV/paper_2.html">
      <font color="black">Point of Care Image Analysis for COVID-19</font>
    </a>
  </h2>
  <font color="black">COVID-19は胸部CTで検出するのが簡単ですが、高価で、持ち運びができず、消毒が難しいため、ポイントオブケア（POC）モダリティとしては不向きです。さらに、ULTRa（超音波研究所トレント、イタリア）とイタリアの病院では、疾患の重症度を注釈したPOC超音波データを取得し、自動重症度評価のための深いネットワークをトレーニングしました。一方、胸部X線（CXR）と肺超音波（LUS） ）は広く使用されていますが、これらのモダリティでのCOVID-19の所見は必ずしも明確ではありません。 
[ABSTRACT]画像に基づく病気の検出と評価は迅速かつ安価です。covid-19の結果は必ずしも明確ではありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Deeply-Supervised Density Regression for Automatic Cell Counting in
  Microscopy Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.IV/paper_3.html">
      <font color="black">Deeply-Supervised Density Regression for Automatic Cell Counting in
  Microscopy Images</font>
    </a>
  </h2>
  <font color="black">4つのデータセットで評価された実験的研究は、提案された方法の優れたパフォーマンスを示しています。提案された方法は、他の最先端の密度回帰ベースの方法と比較して2つの革新を処理します。ただし、自動カウント方法の設計は、低いため、依然として困難です。画像のコントラスト、複雑な背景、細胞の形状と数の大きな変動、および2次元顕微鏡画像における有意な細胞閉塞。 
[概要]ニューヨークベースのシステムは、画像内の細胞を自動的にカウントするように設計されています。画像から細胞密度マップを予測するために使用できます。この方法は現在、4つのデータセットでテストされています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-07">
        <br><font color="black">2020-11-07</font>
      </time>
    </span>
</section>
<!-- paper0: Noise2Stack: Improving Image Restoration by Learning from Volumetric
  Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.IV/paper_4.html">
      <font color="black">Noise2Stack: Improving Image Restoration by Learning from Volumetric
  Data</font>
    </a>
  </h2>
  <font color="black">Noise2SelfやNoise2Voidなどの自己監視方式は、明示的なターゲットなしで信号を学習することでデータ要件を緩和しますが、単一の画像内の情報が不足しているために制限されます。イメージング機器自体には物理的な制限があり、その結果、実験的なトレードオフが発生します。信号対雑音比、取得速度、およびイメージング深度の間で問題が悪化します。この作業の一環として、マルチプレーン画像のノイズ除去のベンチマークを確立するための顕微鏡データセットをリリースします。 
[ABSTRACT] noise2stackはnoise2noiseメソッドの拡張です。空間的に隣接するプレーン間の共有信号を利用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding the physics of coherent LiDAR -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.IV/paper_5.html">
      <font color="black">Understanding the physics of coherent LiDAR</font>
    </a>
  </h2>
  <font color="black">次に、コヒーレントLiDARの収集効率に注目し、信号強度がレーザービームの集束の程度に強く依存することを示します。コヒーレントLiDAR（Light Detecting And Ranging）は、より大きな利点を提供する有望な3Dイメージングテクノロジーです。より伝統的なLiDARシステム..この原稿の目的は、最初の原則から厳密に派生したコヒーレントLiDARの基本的な物理学を説明することです。 
[概要]モーションベースのレーザーは、並外れた深度精度を実現できます。また、光のドップラーシフトを感知することにより、移動する物体の速度を検出することもできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Conceptual Compression via Deep Structure and Texture Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.IV/paper_6.html">
      <font color="black">Conceptual Compression via Deep Structure and Texture Synthesis</font>
    </a>
  </h2>
  <font color="black">特に、2つの補完的な視覚的特徴からなる2層モデルによって画像を圧縮することを提案します：1）構造マップによって表される構造層と2）低次元の深い表現によって特徴付けられるテクスチャ層..デコード段階では、階層フュージョンGAN（HF-GAN）は、テクスチャがデコードされた構造マップにレンダリングされる合成パラダイムを学習するために提案され、優れた視覚的リアリズムを備えた高品質の再構成につながります。既存の圧縮方法は通常、信号レベルの冗長性の除去に焦点を当てています。 、ビジュアルデータをコンパクトな概念コンポーネントに分解する可能性と多様性はまだ研究が不足しています。 
[概要]概念圧縮フレームワークを使用して、新しいモデルを作成できます。これは、コンパクトで解釈可能な状態間ビットストリームを作成するように設計されています。これらの構造は削除および圧縮され、コンパクトで解釈が作成されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning-based End-to-end Diagnosis System for Avascular Necrosis
  of Femoral Head -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.IV/paper_7.html">
      <font color="black">Deep Learning-based End-to-end Diagnosis System for Avascular Necrosis
  of Femoral Head</font>
    </a>
  </h2>
  <font color="black">大腿骨頭の無血管性壊死（AVNFH）の最初の画像診断法として、単純X線写真からAVNFHを正確に病期分類することは重要ですが、整形外科医にとっては挑戦的です。実験結果は有望です。システム（AVN-net）。 
[概要]これは、avnfhのディープラーニングベースの診断システムの潜在的な使用に関する最初の研究です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-12">
        <br><font color="black">2020-02-12</font>
      </time>
    </span>
</section>
<!-- paper0: Hi-UCD: A Large-scale Dataset for Urban Semantic Change Detection in
  Remote Sensing Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.IV/paper_8.html">
      <font color="black">Hi-UCD: A Large-scale Dataset for Urban Semantic Change Detection in
  Remote Sensing Imagery</font>
    </a>
  </h2>
  <font color="black">バイナリおよびマルチクラスの変更検出でいくつかの古典的な方法を使用してデータセットのベンチマークを行います。ただし、既存のデータセットには3つのボトルネックがあります。（1）高空間解像度の画像がない。 （2）セマンティックアノテーションの欠如。 （3）長距離の多時期画像の欠如..洗練された都市の変化を検出および分析するために使用できます。 
[概要]このデータセットは、空間解像度が0.1 mの航空写真を使用しています。3つの時相が含まれ、9つのクラスの土地被覆で意味的に注釈が付けられています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-06">
        <br><font color="black">2020-11-06</font>
      </time>
    </span>
</section>
<!-- paper0: MMDF: Mobile Microscopy Deep Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.IV/paper_9.html">
      <font color="black">MMDF: Mobile Microscopy Deep Framework</font>
    </a>
  </h2>
  <font color="black">この作業では、モバイル顕微鏡に意図的に調整された一連のメソッドを接続することにより、包括的なパイプラインを作成することを目指しています：（1）安定した焦点/焦点外分類のためのCNNモデル、（2）画像用の変更されたDeblurGANアーキテクチャブレ除去、（3）複数の画像からの焦点の合った部分を組み合わせて詳細を強調するためのFuseGANモデル。焦点の合った/焦点の合っていない分類、高速スキャンのぼけ除去、フォーカススタッキングなどの問題。取得した画像の平凡な品質によってその広範な採用が妨げられている、疾患診断を支援および加速するための有望な技術。 
[概要]モバイル画像は高度な代理システムで開発されていますが、これらの課題はまだ解決されるのを待っています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Line Art Correlation Matching Feature Transfer Network for Automatic
  Animation Colorization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.IV/paper_10.html">
      <font color="black">Line Art Correlation Matching Feature Transfer Network for Automatic
  Animation Colorization</font>
    </a>
  </h2>
  <font color="black">既存の方法は、次の線画に色を付けるための参照として前の色のフレームを入力するだけです。これは、特に明らかな変化が発生する位置で、前の色のフレームと次の線画の空間的な不整合のために色付けを誤解させます。課題として、色付きの参照特徴を学習可能な方法で位置合わせし、モデルをU-Netベースのジェネレーターに粗い方法から細かい方法で統合する一種の相関マッチング機能転送モデル（CMFTと呼ばれる）を設計します。フレーム間の一貫性が考慮されていないため、アニメーションのカラー化の目的でメソッドを採用することはできません。 
[概要]単一線画の色付けのための多くのザラベースの方法が出現しました。フレーム間の一貫性の考慮が不足しているため、それらを採用することはできません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-14">
        <br><font color="black">2020-04-14</font>
      </time>
    </span>
</section>
<!-- paper0: AIM 2020 Challenge on Learned Image Signal Processing Pipeline -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.IV/paper_11.html">
      <font color="black">AIM 2020 Challenge on Learned Image Signal Processing Pipeline</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、AIMが学習した2番目のISPの課題を確認し、提案されたソリューションと結果について説明します。検討対象のタスクには、画像のデモザイキング、ノイズ除去、ホワイトバランシング、色とコントラストの補正、デモイアリング、提案されたソリューションは、ベースラインの結果を大幅に改善し、実用的な画像信号処理パイプラインモデリングの最先端を定義しました。 
[概要]目標は、huawei p20デバイスでキャプチャされた元の低品質の生画像を、canon 5ddslrカメラで取得された同じ写真にマッピングすることでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Tattoo tomography: Freehand 3D photoacoustic image reconstruction with
  an optical pattern -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.IV/paper_12.html">
      <font color="black">Tattoo tomography: Freehand 3D photoacoustic image reconstruction with
  an optical pattern</font>
    </a>
  </h2>
  <font color="black">このパターンは、その断層画像がパターンの座標系に対するプローブポーズの回復を可能にするように設計されています。方法：この論文では、PATデータの3D再構成への新しいアプローチを提示します（Tattooトモグラフィー）。 ）外部追跡システムを必要とせず、臨床ワークフローにスムーズに統合できます。これは、画像取得前に関心領域に配置された光学パターンに基づいています。 
[概要]従来適用されていた2dプローブによって提供される限られた視野（fov）。これは、関心領域に配置された光学パターンに基づいています。これにより、取得した一連のpa画像を共通のグローバル座標に復元できます。システム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: A Multi-stream Convolutional Neural Network for Micro-expression
  Recognition Using Optical Flow and EVM -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.IV/paper_13.html">
      <font color="black">A Multi-stream Convolutional Neural Network for Micro-expression
  Recognition Using Optical Flow and EVM</font>
    </a>
  </h2>
  <font color="black">マイクロエクスプレッション（ME）認識は、幅広いアプリケーション、特に公安や心理療法で重要な役割を果たします。最近の多くの最先端のアプローチと比較して、私たちの方法はより有望な認識結果を達成します。 、マスク、オプティカルフロー画像、およびグレースケール画像をMSCNNに追加します。 
[概要]この論文では、私が認識できるマルチストリーム畳み込みニューラルネットワークを作成します。クリスタルフロー画像を使用し、それらをmscnnに追加します。広範なテストの後、2つのパブリックmeデータベースでさらに多くのことを行いました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-07">
        <br><font color="black">2020-11-07</font>
      </time>
    </span>
</section>
<!-- paper0: Pristine annotations-based multi-modal trained artificial intelligence
  solution to triage chest X-ray for COVID-19 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.IV/paper_14.html">
      <font color="black">Pristine annotations-based multi-modal trained artificial intelligence
  solution to triage chest X-ray for COVID-19</font>
    </a>
  </h2>
  <font color="black">マルチモーダルソリューションは、AUC（受信者動作特性曲線の下の面積）を0.89から0.93に増加させ、病理をローカライズするためのダイス係数（0.59から0.62）にもプラスの影響を与えます。提案されたソリューションは、業界や学術による既存のソリューションとは異なります。コミュニティ、および単一のX線画像を使用して推論することによってトリアージする機能的AIモデルを示し、深層学習モデルはX線とCTデータの両方を使用してトレーニングされます。このようなマルチモーダルトレーニングがどのように改善するかについて報告します。 X線のみのトレーニングと比較したソリューション。 
[ABSTRACT]人工知能（ai）を利用したトリアージとモニタリングのためのxベースのアプリケーションでは、経験豊富な放射線科医がタイムリーに患者を特定する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Scannerless non-line-of-sight three dimensional imaging with a 32x32
  SPAD array -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.IV/paper_15.html">
      <font color="black">Scannerless non-line-of-sight three dimensional imaging with a 32x32
  SPAD array</font>
    </a>
  </h2>
  <font color="black">フィルター処理された逆投影の結果は、識別可能な再構成を示していますが、仮想波動場を使用した結果は、単一ピクセルSPADを備えた以前のスキャンイメージングシステムによって作成されたものと同様のより良い品質を示しています。視界の3次元イメージングアプリケーション..70psのパルスレーザーと組み合わせた市販の32x32SPADカメラに基づいたスキャナーレスの視線のない3次元イメージングシステムを開発します。 
[概要]私たちの実験では、1024時間のヒストグラムを3秒で同期可能に約165psの時間分解能で実現できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Learning the geometry of wave-based imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.IV/paper_16.html">
      <font color="black">Learning the geometry of wave-based imaging</font>
    </a>
  </h2>
  <font color="black">FIOは、地震学やレーダーからドップラーや超音波まで、幅広いイメージングモダリティをモデル化します。最適なトランスポートに基づく損失を介して、データに暗黙的に含まれるFIOによってキャプチャされた波動伝搬のジオメトリの学習に焦点を当てます。波動ベースのイメージング問題のための一般的な物理ベースの深層学習アーキテクチャ。 
[概要]イメージングの問題における主な問題は、媒体が波の位置と方向に応じて波を「曲げる」方法が異なることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-10">
        <br><font color="black">2020-06-10</font>
      </time>
    </span>
</section>
<!-- paper0: Approaching geoscientific inverse problems with vector-to-image domain
  transfer networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.IV/paper_17.html">
      <font color="black">Approaching geoscientific inverse problems with vector-to-image domain
  transfer networks</font>
    </a>
  </h2>
  <font color="black">全体として、この調査では、ディープラーニングを使用して間接測定データから地下モデルを推測する方法の理解が進んでいます。トレーニングサンプルサイズを小さくしてさらにテストすると、5000のトレーニング例のみを使用した場合にパフォーマンスが中程度に低下するだけです。各タイプの問題について、マルチガウスと長距離接続のバイナリチャネル化地下ドメインの両方が考慮されます。 
[要約]この方法は、前方のシミュレートされたデータ空間で最も近いトレーニングモデルよりも真のモデルとはるかによく一致する2次元モデルを復元することがわかりました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-20">
        <br><font color="black">2019-12-20</font>
      </time>
    </span>
</section>
<!-- paper0: Quantitative imaging for complex-objects via a single-pixel detector -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.IV/paper_18.html">
      <font color="black">Quantitative imaging for complex-objects via a single-pixel detector</font>
    </a>
  </h2>
  <font color="black">このアプローチはさまざまな波長に共通であり、ターゲットの事前情報を必要としません。照明構造と点信号に基づいて、位相回復アルゴリズムを実行することによって複雑な画像が再構築されます。特に複雑な値のイメージングでは、構造化された照明は位相領域で実行され、センサーサイズが制限されたポイント検出器がゼロ周波数領域の強度を検出します。 
[概要]人々は干渉を利用して位相分布を強度フリンジにマッピングするか、強度を分析することができます-回折パターンのみ。この作品では、単一ピクセルカメラ（spc）に触発された新しいqpiスキームが報告されています。複雑な画像は実行によって再構築されます位相回復アルゴリズム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: AIM 2020 Challenge on Rendering Realistic Bokeh -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.IV/paper_19.html">
      <font color="black">AIM 2020 Challenge on Rendering Realistic Bokeh</font>
    </a>
  </h2>
  <font color="black">このチャレンジで使用されたターゲットメトリックは、ユーザー調査で測定されたソリューションの実行時間と知覚品質を組み合わせたものです。Canon7DDSLRカメラを使用してキャプチャされた5Kの浅い/広い被写界深度の画像ペアで構成されるボケデータセット。 2番目のAIMの現実的なボケ効果レンダリングの課題を確認し、提案されたソリューションと結果の説明を提供します。 
[概要]参加者は現実世界のボケシミュレーション問題を解決していました。目標は、大規模な引き潮を使用して現実的な浅い焦点技術を学ぶことでした！ボケ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: A Multi-Plant Disease Diagnosis Method using Convolutional Neural
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_0.html">
      <font color="black">A Multi-Plant Disease Diagnosis Method using Convolutional Neural
  Network</font>
    </a>
  </h2>
  <font color="black">植物を最大能力から制限する病気を植物病と定義します。したがって、この章では、複数の植物の診断を組み合わせた最適な植物病害識別モデルを調査します。実験と評価のために、さまざまなデータを収集しました。トマト、ジャガイモ、米、トウモロコシ、ブドウ、リンゴを含む6つの植物の葉の画像を含むオンラインソース。 
[概要]最も導入されたモデルは、特定の植物の病気のみを診断できます。マルチラベル分類法を継承して、植物と病気の種類を並行して識別します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Towards a Better Global Loss Landscape of GANs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_1.html">
      <font color="black">Towards a Better Global Loss Landscape of GANs</font>
    </a>
  </h2>
  <font color="black">RpGANに悪い盆地がないことを証明します。また、生成されたサンプルと真のサンプルを結合する相対論的ペアリングGAN（RpGAN）損失を研究します。元のJS-GANを含む分離可能なGANのクラスがモード崩壊として認識される指数関数的に多くの悪い盆地。 
[要約]コードはgithubで入手できます。 com / ailsaf.com / rs-gan。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Task-Assisted Domain Adaptation with Anchor Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_2.html">
      <font color="black">Task-Assisted Domain Adaptation with Anchor Tasks</font>
    </a>
  </h2>
  <font color="black">2種類のアンカータスク（セマンティックセグメンテーションと顔のランドマーク）を使用して、2組のデータセット（屋内シーンと顔）の表面法線推定の方法を評価します。表面法線や単一ビュー深度推定などの一部のタスクでは、 -実際の画像では取得が難しいが、合成では簡単に取得できるピクセルのグラウンドトゥルース。アンカーとメインタスク間の暗黙的な関係をさらに活用するために、ソースドメインでのクロスタスクガイダンスを学習する\ freeze手法を適用します。最終的なネットワークレイヤーで、ターゲットドメインで使用します。 
[ABSTRACT]ドメインシフトのため、合成画像は実際の画像にうまく一般化されないことがよくあります。ソースドメインのクロスタスクガイダンスを学習し、それをターゲットサーフェスで使用する手法を適用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-16">
        <br><font color="black">2019-08-16</font>
      </time>
    </span>
</section>
<!-- paper0: Social-STAGE: Spatio-Temporal Multi-Modal Future Trajectory Forecast -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_3.html">
      <font color="black">Social-STAGE: Spatio-Temporal Multi-Modal Future Trajectory Forecast</font>
    </a>
  </h2>
  <font color="black">既存の公開データセットETHおよびUCYでのアプローチを評価し、提案されたアルゴリズムがこれらのデータセットの最新技術よりも優れていることを示します。Social-STAGE、社会的相互作用を意識した時空間マルチアテンショングラフコンボリューションネットワークを新しい評価で提案します。マルチモダリティの場合..この論文では、マルチモーダルの将来の軌道予測の問題をランキングとともに考察します。 
[概要]ソーシャルネットワークの将来を予測する方法を探しています。何が起こったのかを知る方法を見つける必要があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: A low latency ASR-free end to end spoken language understanding system -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_4.html">
      <font color="black">A low latency ASR-free end to end spoken language understanding system</font>
    </a>
  </h2>
  <font color="black">ストリーミング入力音声信号が与えられると、提案されたシステムは、処理の瞬間にストリーム全体を持っている必要なしに、セグメントごとにそれを処理することができます。実験は、提案されたシステムが最新のパフォーマンスをもたらすことを示しています。同じタスクの他の公開された作品と比較した場合の低遅延とはるかに小さいモデルの利点..この作品は、小さなマイクロコントローラーで実行するのに十分小さいフットプリントを持ち、埋め込まれたシステムを設計するという追加の制約があるシステムなどを提案します待ち時間が最小のシステム。 
[ABSTRACT]提案されたシステムは、最小のレイテンシーで小さなマイクロコントローラーと組み込みシステムで実行できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Deep traffic light detection by overlaying synthetic context on
  arbitrary natural images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_5.html">
      <font color="black">Deep traffic light detection by overlaying synthetic context on
  arbitrary natural images</font>
    </a>
  </h2>
  <font color="black">このデータは、基本的な非現実的なコンピュータグラフィックスを使用して生成され、トラフィックドメインに関係のない任意の画像背景の上に偽のトラフィックシーンをブレンドします。実際の参照モデルで取得されたそれぞれのメトリックよりも高くなります。また、主に黄色の状態のサンプルの量が少ないことによって引き起こされる、トラフィックライトデータセットに固有のデータの不均衡の問題にも取り組みます。 
[概要]この文脈において、我々は、人工交通に関連する深層信号検出器のトレーニングデータを生成する方法を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-07">
        <br><font color="black">2020-11-07</font>
      </time>
    </span>
</section>
<!-- paper0: Joint Super-Resolution and Rectification for Solar Cell Inspection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_6.html">
      <font color="black">Joint Super-Resolution and Rectification for Solar Cell Inspection</font>
    </a>
  </h2>
  <font color="black">これは、別個の処理ステップを省略し、動き推定がより安定し、整流されたモジュール画像上の高解像度（HR）ピクセルの間隔が均一になるため、有利です。したがって、遠近法の歪みに関係なく、この前処理を標準のMFSRアルゴリズムと融合することを提案します。 
[概要]低解像度測定のシーケンスにマルチフレーム超解像（mfsr）を適用します。この前処理を標準のmfsrアルゴリズムと融合することが提案されています。この方法は、バイキュービックアップサンプリングの3倍、状態の2倍のパフォーマンスを発揮します。自動検査のための最先端</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: DeepMark++: Real-time Clothing Detection at the Edge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_7.html">
      <font color="black">DeepMark++: Real-time Clothing Detection at the Edge</font>
    </a>
  </h2>
  <font color="black">最も正確なモデルは、DeepFashion2データセットの最先端のソリューションに匹敵する結果を達成し、軽量で高速なモデルは、Huawei P40Proスマートフォンで17FPSで実行されます。さらに、DeepFashion2ランドマークで2位を獲得しました。テストデータセットに0.582mAPを使用したEstimationChallenge 2020 ..衣類の認識は、ファッションドメイン内で最も基本的なAIアプリケーションの課題です。 
[概要] aiシステムはマルチターゲットネットワークに基づいています。パフォーマンスを向上させるために、いくつかの強力な後処理技術を紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br><font color="black">2020-06-01</font>
      </time>
    </span>
</section>
<!-- paper0: Distance-Based Anomaly Detection for Industrial Surfaces Using Triplet
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_8.html">
      <font color="black">Distance-Based Anomaly Detection for Industrial Surfaces Using Triplet
  Networks</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、代わりに距離ベースの異常検出目的を使用して表面テクスチャパッチでCNNをトレーニングすることにより、この課題に対処します。特に、深層学習畳み込みニューラルネットワーク（CNN）は、これらの画像処理ベースのソリューションの最前線にあります。予測の正確さと効率のために..近年、人間の専門家の代わりに、機械ベースの目視検査がこのタスクを実行するために利用されています。 
[要約]分類目標のcnnは、十分に大量の欠陥データを必要としますが、これは多くの場合利用できません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Once-for-All Adversarial Training: In-Situ Tradeoff between Robustness
  and Accuracy for Free -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_9.html">
      <font color="black">Once-for-All Adversarial Training: In-Situ Tradeoff between Robustness
  and Accuracy for Free</font>
    </a>
  </h2>
  <font color="black">重要なノブとして、デュアルバッチ正規化を利用して標準機能と敵対機能の統計を分離し、パフォーマンスを低下させることなく1つのモデルで学習できるようにします。さらにOATを1回限りの敵対的トレーニングとスリミング（OATS）に拡張します。精度、堅牢性、実行時効率の間の共同トレードオフを可能にするフレームワーク。提案されたフレームワークであるOnce-for-all Adversarial Training（OAT）は、革新的なモデル条件付きトレーニングフレームワークに基づいて構築されており、ハイパー入力としてのパラメータ。 
[ABSTRACT]精度の高いトレーニング（オート麦）は、革新的なモデル（条件付きトレーニングフレームワーク）に基づいて構築されています。トレーニングされたモデルは、パフォーマンスを低下させることなく1つのモデルで学習できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-22">
        <br><font color="black">2020-10-22</font>
      </time>
    </span>
</section>
<!-- paper0: Classification of optics-free images with deep neural networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_10.html">
      <font color="black">Classification of optics-free images with deep neural networks</font>
    </a>
  </h2>
  <font color="black">可能な限り薄いカメラは、イメージセンサーのみを残して、すべての光学系を削除することで実現されます。光学系のない画像からの推論は、プライバシーと電力効率を向上させる可能性があります。マルチクラス検出とバイナリ分類を実行するようにディープニューラルネットワークをトレーニングします（人体中心の画像再構成を必要とせずに、光学系のない画像で92％の精度で）。 
[概要]ディープニューラルネットワークをトレーニングして、マルチクラス検出と二項分類を実行します（精度92％）。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-pooled Inception features for no-reference image quality
  assessment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_11.html">
      <font color="black">Multi-pooled Inception features for no-reference image quality
  assessment</font>
    </a>
  </h2>
  <font color="black">したがって、CNNベースアーキテクチャとさまざまな深い特徴の有効性に関する詳細なパラメータ研究を提示します。さらに、これらの結果は、LIVE In the Wild Image QualityChallengeデータベースを使用したクロスデータベーステストでも確認されました。このアプローチでは、グローバル平均プーリング（GAP）レイヤーをImageNetデータベースの事前トレーニング済み畳み込みニューラルネットワーク（CNN）の複数のInceptionモジュールにアタッチすることにより、視覚的特徴を抽出します。 
[概要]画質の分析には、画像の内容と特徴のバランスの取れた調査が必要です。マルチギャップと呼ばれます-nriqa、3つのベンチマークiqaデータベースで最先端の結果を提供できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Point of Care Image Analysis for COVID-19 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_12.html">
      <font color="black">Point of Care Image Analysis for COVID-19</font>
    </a>
  </h2>
  <font color="black">さらに、ULTRa（Ultrasound Laboratory Trento、Italy）およびイタリアの病院と協力して、疾患の重症度の注釈付きのPOC超音波データを取得し、自動重症度評価のための深いネットワークをトレーニングしました。COVID-19は胸部で検出しやすいただし、CTは高価で、携帯性がなく、消毒が難しいため、ポイントオブケア（POC）モダリティとしては不向きです。イスラエルのいくつかの病院と協力して、CXRの大規模なデータセットを収集し、このデータセットを使用します。 COVID-19の90％を超える検出率を取得するニューラルネットワークをトレーニングします。 
[ABSTRACT]画像に基づく病気の検出と評価は迅速かつ安価です。covid-19の結果は必ずしも明確ではありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-28">
        <br><font color="black">2020-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Human-Object Interaction with Mixed Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_13.html">
      <font color="black">Detecting Human-Object Interaction with Mixed Supervision</font>
    </a>
  </h2>
  <font color="black">ほとんどの弱教師あり学習方法は、利用可能な場合、強力な教師ありのデータを活用するための準備をしていません。実際、HOI検出におけるこの2つのパラダイムの素朴な組み合わせは、相互に貢献することができません。強い注釈と弱い注釈を混合して使用することにより、多くの完全に監視された方法に近いか、それよりも優れたパフォーマンスを発揮します。さらに、同じ監視下で、代表的な最先端の弱く完全に監視された方法を上回ります。さらに、混合監視における注釈の不十分さを考慮して、画像全体で多様でハードなネガを合成し、モデルの堅牢性。 
[ABSTRACT] hoi triplet hhuman（動詞; objecti）には、人間とオブジェクトの境界ボックス、およびタスクを完了するためのそれらの間のアクションが必要です。これを克服するための自然な解決策は、ギルバートを追求することです-教師あり学習、特定の存在のみを知っている画像のホイトリプレットですが、正確な位置は不明です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Deeply-Supervised Density Regression for Automatic Cell Counting in
  Microscopy Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_14.html">
      <font color="black">Deeply-Supervised Density Regression for Automatic Cell Counting in
  Microscopy Images</font>
    </a>
  </h2>
  <font color="black">4つのデータセットで評価された実験的研究は、提案された方法の優れたパフォーマンスを示しています。次に、補助畳み込みニューラルネットワーク（AuxCNN）を使用して、設計されたC-FCRNの中間層のトレーニングを支援し、見えないデータセットのDRMパフォーマンスを向上させます。 。顕微鏡画像の細胞数を正確に数えることは、多くの医学的診断や生物学的研究で必要です。 
[概要]ニューヨークベースのシステムは、画像内の細胞を自動的にカウントするように設計されています。画像から細胞密度マップを予測するために使用できます。この方法は現在、4つのデータセットでテストされています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-07">
        <br><font color="black">2020-11-07</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Learning of Depth and Ego-Motion from Cylindrical Panoramic
  Video with Applications for Virtual Reality -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_15.html">
      <font color="black">Unsupervised Learning of Depth and Ego-Motion from Cylindrical Panoramic
  Video with Applications for Virtual Reality</font>
    </a>
  </h2>
  <font color="black">アプローチを評価するために、2つの新しいデータセットを作成します。CARLAシミュレーターを使用して作成された合成データセットと、都市環境で自転車に乗るときにヘルメットに取り付けられたカメラから収集されたパノラマビデオの新しいデータセットであるHeadcamです。畳み込みニューラルネットワークモデルを紹介します。円筒形のパノラマビデオからの深度と自我運動の監視されていない学習のために..パノラマ深度推定は、仮想現実、3Dモデリング、自律型ロボットナビゲーションなどのアプリケーションにとって重要なテクノロジーです。 
[概要]パノラマ深度推定は、バーチャルリアリティ、3Dモデリング、自律型ロボットナビゲーションなどのネットワークにとって重要なテクノロジーです。私たちはネットワークを使用して、パノラマパノラマをステレオパノラマに変換する問題を解決します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: HyperCon: Image-To-Video Model Transfer for Video-To-Video Translation
  Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_16.html">
      <font color="black">HyperCon: Image-To-Video Model Transfer for Video-To-Video Translation
  Tasks</font>
    </a>
  </h2>
  <font color="black">マスクされた入力とマスクされていない入力の両方を処理し、以前の画像からビデオへのモデル転送技術よりもさらに多くのビデオからビデオへの変換タスクのサポートを可能にします。当社のプロジェクトWebサイトはhttps://ryanszeto.com/projects/hyperconで入手できます。 。HyperConは、ビデオスタイルの転送と修復について説明します。HyperConは、単一の定型化されたビデオや不完全なビデオのトレーニングを行わなくても、以前の最先端の方法と比較して良好に機能します。 
[ABSTRACT] hyperconは、時間的に補間されたビデオフレームを変換することによって機能します-wise.itは、補間されたビデオ上の補間されたウィンドウ上で集約します。これを使用して、hyperconの技術的な利点を作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-10">
        <br><font color="black">2019-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Noise2Stack: Improving Image Restoration by Learning from Volumetric
  Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_17.html">
      <font color="black">Noise2Stack: Improving Image Restoration by Learning from Volumetric
  Data</font>
    </a>
  </h2>
  <font color="black">この作業の一環として、顕微鏡データセットをリリースして、マルチプレーン画像のノイズ除去のベンチマークを確立します。したがって、ノイズ除去は画像処理パイプラインの重要な部分であり、畳み込みニューラルネットワークが現在このタスクに最適な方法です。 ..磁気共鳴脳スキャンと新しく取得したマルチプレーン顕微鏡データに関する私たちの実験は、スタック内の隣接する画像からのみ学習することで、Noise2NoiseとNoise2Voidを上回り、監視されたノイズ除去方法とのギャップを埋めることができることを示しています。 
[ABSTRACT] noise2stackはnoise2noiseメソッドの拡張です。空間的に隣接するプレーン間の共有信号を利用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Extracting Optimal Solution Manifolds using Constrained Neural
  Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_18.html">
      <font color="black">Extracting Optimal Solution Manifolds using Constrained Neural
  Optimization</font>
    </a>
  </h2>
  <font color="black">最適なセットを近似多様体として抽出するためのニューラルソリューションを提示します。ここで、変更されていない非凸の目的と制約は、モデラーがガイドするドメイン情報に基づく$ L_2 $損失関数として定義されます。実際のシナリオには、暗黙関数、ハイパースペクトルアンミキシング、およびパレート最適フロント..非凸型に直面した場合、局所的または全体的な凸面化が一般的な回避策です。 
[ABSTRACT]現実から複数の目的が満たされる必要があり、目的関数と制約の両方が開発されていない可能性があります。非営利ソリューションに直面した場合、現実またはハイパー認識の厳密さが一般的な回避策であり、検証するための合成的で現実的なケースを提示します私たちのアプローチとベンチマーキングのための既知のソルバーとの比較</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-13">
        <br><font color="black">2020-09-13</font>
      </time>
    </span>
</section>
<!-- paper0: RarePlanes: Synthetic Data Takes Flight -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_19.html">
      <font color="black">RarePlanes: Synthetic Data Takes Flight</font>
    </a>
  </h2>
  <font color="black">実際の航空機と合成で生成された航空機はどちらも、航空機の長さ、翼幅、翼の形状、翼の位置、翼幅のクラス、推進力、エンジンの数、垂直尾翼の数、カナードの存在、航空機の役割など、10の細粒属性を備えています。 。他の合成/実際の組み合わせデータセットは存在しますが、RarePlanesは、オーバーヘッドの観点から合成データの価値をテストするために構築された、公開されている最大の超高解像度データセットです。データセットの実際の部分は、253台のMaxarWorldView-3衛星で構成されています。 112の場所と2,142km ^ 2にまたがるシーンで、14,700機の手動注釈付き航空機があります。 
[ABSTRACT] rareplanesデータセットは、合成データの価値に焦点を当てています。合成データは、コンピュータービジョンアルゴリズムが衛星画像内の航空機とその属性を検出するのに役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-04">
        <br><font color="black">2020-06-04</font>
      </time>
    </span>
</section>
<!-- paper0: On Efficient and Robust Metrics for RANSAC Hypotheses and 3D Rigid
  Registration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_20.html">
      <font color="black">On Efficient and Robust Metrics for RANSAC Hypotheses and 3D Rigid
  Registration</font>
    </a>
  </h2>
  <font color="black">迷惑とアプリケーションシナリオが異なる4つの標準データセットでの比較実験により、提案されたメトリックが登録パフォーマンスを大幅に向上させ、いくつかの最先端の競合他社よりも堅牢であり、実用的なアプリケーションへの優れた贈り物になることが確認されています。 RANSAC仮説のメトリックは、時間がかかるか、一般的な迷惑、パラメータの変動、およびさまざまなアプリケーションシナリオに敏感であるため、全体的な登録の精度と速度が低下します。最初にインライアとアウトライアの寄与を分析することで、この問題を軽減します。次に、RANSAC仮説の設計動機が異なる、いくつかの効率的で堅牢なメトリックを提案します。 
[概要]ニューヨーク大学の研究者は、3D厳密な登録のためのツールを開発しました。彼らは、仮説はより正確であるほど正確ではないと言います。しかし、彼らは、さまざまなグループの貢献を分析することによってこの問題を軽減するのに役立つと言います。次に、いくつかの効率的で堅牢なメトリックを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Residual Pose: A Decoupled Approach for Depth-based 3D Human Pose
  Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_21.html">
      <font color="black">Residual Pose: A Decoupled Approach for Depth-based 3D Human Pose
  Estimation</font>
    </a>
  </h2>
  <font color="black">その行で、私たちの貢献は3つあります。畳み込みニューラルネットワーク（CNN）を使用した信頼性の高い2Dポーズ推定の最近の進歩を活用して、複数人の人間とロボットの相互作用（HRI）シナリオで深度画像から人々の3Dポーズを推定することを提案します。 （i）2Dポーズ推定と3Dポーズリファインメントを分離することにより、深度画像から3Dポーズ推定を実行することを提案します。 （ii）持ち上げられた3Dポーズと真の3Dポーズの間の残余ポーズを回帰する深層学習アプローチを提案します。 （iii）その単純さにもかかわらず、私たちのアプローチは、2つの公開データセットで精度と速度の両方で非常に競争力のある結果を達成し、したがって、最近の最先端の方法と比較して複数人のHRIに魅力的であることを示します。 
[概要]私たちの方法は、深度情報を使用して2Dボディランドマーク検出から3Dリフトポイントを取得すると、真の3D人間ポーズの概算が得られるという観察に基づいています。2Dポーズ推定を分離することにより、深度画像から3Dポーズ推定を実行することを提案します。と3Dポーズの洗練</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Conceptual Compression via Deep Structure and Texture Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_22.html">
      <font color="black">Conceptual Compression via Deep Structure and Texture Synthesis</font>
    </a>
  </h2>
  <font color="black">特に、2つの補完的な視覚的特徴からなる2層モデルによって画像を圧縮することを提案します：1）構造マップによって表される構造層と2）低次元の深い表現によって特徴付けられるテクスチャ層..デコード段階では、階層フュージョンGAN（HF-GAN）は、テクスチャがデコードされた構造マップにレンダリングされる合成パラダイムを学習するために提案され、優れた視覚的リアリズムを備えた高品質の再構成につながります。既存の圧縮方法は通常、信号レベルの冗長性の除去に焦点を当てています。 、ビジュアルデータをコンパクトな概念コンポーネントに分解する可能性と多様性はまだ研究が不足しています。 
[概要]概念圧縮フレームワークを使用して、新しいモデルを作成できます。これは、コンパクトで解釈可能な状態間ビットストリームを作成するように設計されています。これらの構造は削除および圧縮され、コンパクトで解釈が作成されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning-based End-to-end Diagnosis System for Avascular Necrosis
  of Femoral Head -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_23.html">
      <font color="black">Deep Learning-based End-to-end Diagnosis System for Avascular Necrosis
  of Femoral Head</font>
    </a>
  </h2>
  <font color="black">したがって、深層学習ベースのAVNFH診断システム（AVN-net）を提案します。AVN-netは、AVNFH検出で0.97（95％CI：0.97-0.98）の最先端のテストAUCを取得できます。すべての診断テストで、経験の浅い整形外科医よりも有意に高いF1スコア（p &lt;0.01）。私たちの知る限り、この研究は、AVNFHの深層学習ベースの診断システムの将来の使用に関する最初の研究です。実際のアプリケーションシナリオを表す2つのパイロット調査を実施します。 
[概要]これは、avnfhのディープラーニングベースの診断システムの潜在的な使用に関する最初の研究です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-12">
        <br><font color="black">2020-02-12</font>
      </time>
    </span>
</section>
<!-- paper0: RGBT Salient Object Detection: A Large-scale Dataset and Benchmark -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_24.html">
      <font color="black">RGBT Salient Object Detection: A Large-scale Dataset and Benchmark</font>
    </a>
  </h2>
  <font color="black">この作業は、グラウンドトゥルースアノテーション付きの5000の空間的に整列されたRGBT画像ペアを含むVT5000という名前のRGBT画像データセットに貢献します。広範な実験は、提案されたベースラインアプローチがVT5000データセットと他の2つの公開データセットの最先端の方法よりも優れていることを示しています.. VT5000には、アルゴリズムの堅牢性を調査するために、さまざまなシーンや環境で収集された11の課題があります。 
[概要]ほとんどの作品は、実際のアプリケーションのパフォーマンスを制限するrgbベースのデータセットに焦点を当てています。新しい研究の利点は、大規模なデータセットと包括的なベンチマークの欠如によって制限されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Classification of Polarimetric SAR Images Using Compact Convolutional
  Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_25.html">
      <font color="black">Classification of Polarimetric SAR Images Using Compact Convolutional
  Neural Networks</font>
    </a>
  </h2>
  <font color="black">これは、PolSAR分類のラベリングに伴う高コストを考慮すると、非常に重要です。この作業では、従来のMLおよびディープCNNベースの方法の制限に対処するために、PolSAR画像の分類に基づく新しい体系的な分類フレームワークを提案します。スライディングウィンドウ分類アプローチを使用したCNNのコンパクトで適応性のある実装について..深い畳み込みニューラルネットワーク（CNN）に基づく他のアプローチには、計算の複雑さの高さ、グラウンドトゥルースラベルを使用した実行不可能な大規模なトレーニングセットなど、特定の制限と欠点があります。 、および特別なハードウェア要件。 
[ABSTRACT]このドメインで提案されている合成機械学習（ml）手法は、一般に識別性の高い特徴を排除することに重点を置いていますが、研究によると、このタスクは「耐久性の呪い」によって複雑になっています。 cnns</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Hi-UCD: A Large-scale Dataset for Urban Semantic Change Detection in
  Remote Sensing Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_26.html">
      <font color="black">Hi-UCD: A Large-scale Dataset for Urban Semantic Change Detection in
  Remote Sensing Imagery</font>
    </a>
  </h2>
  <font color="black">洗練された都市の変化を検出および分析するために使用できます。実験結果は、Hi-UCDが挑戦的でありながら有用であることを示しています。バイナリおよびマルチクラスの変化検出でいくつかの古典的な方法を使用してデータセットをベンチマークします。 
[概要]このデータセットは、空間解像度が0.1 mの航空写真を使用しています。3つの時相が含まれ、9つのクラスの土地被覆で意味的に注釈が付けられています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-06">
        <br><font color="black">2020-11-06</font>
      </time>
    </span>
</section>
<!-- paper0: Pixel precise unsupervised detection of viral particle proliferation in
  cellular imaging data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_27.html">
      <font color="black">Pixel precise unsupervised detection of viral particle proliferation in
  cellular imaging data</font>
    </a>
  </h2>
  <font color="black">細胞および分子イメージング技術およびモデルは、invitroでの細胞の病巣感染後のウイルス増殖の単一段階を特徴づけるために開発されました。実験的な時間ベースのイメージングデータに触発されて、この研究では、ウイルス粒子の時間の増加が1つによってシミュレートされます。画像全体で、死んだ細胞または部分的に感染した細胞を表す黒または灰色の単一ピクセルが1つずつ増加し、元の画像モデルの生細胞をコードする白いピクセルが1つずつ増加することによる仮想的な寛解。SOMによる監視なしの分類-それぞれ300万ピクセルを超える160のモデル画像のQEは、統計的に信頼性が高く、ピクセル精度が高く、高速な分類モデルを提供し、RGB画像平均計算による人間のコンピューター支援画像分類よりも優れていることが示されています。 
[概要]細胞イメージングデータの高速かつ自動分類が必要です。これは、データを宿主細胞内のウイルス通信の数学的モデルと比較するプロセスの最初のステップです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Stage-wise Channel Pruning for Model Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_28.html">
      <font color="black">Stage-wise Channel Pruning for Model Compression</font>
    </a>
  </h2>
  <font color="black">以前のほとんどのAuto-MLプルーニング方法と同様に、SPは、サブネットのプロキシパフォーマンスを提供し、最高のプロキシパフォーマンスを持つ最高のサブネットを検索できるスーパーネットもトレーニングします。驚くべきことに、subのプロキシパフォーマンスは-SPでトレーニングされたネットは、以前のほとんどのAuto-MLプルーニング作業よりも実際のパフォーマンスに近いです。ただし、以前のいくつかの作業では、多くのAuto-MLプルーニング方法の結果が均一プルーニング方法の結果を超えることさえできないことがわかりました。 
[概要] auto-ml剪定方法はauto-ml剪定を超える可能性があります。以前の作業で見つかった結果は、均一剪定方法の結果を超えることはできません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Frequency-Weighted Robust Tensor Principal Component Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_29.html">
      <font color="black">Frequency-Weighted Robust Tensor Principal Component Analysis</font>
    </a>
  </h2>
  <font color="black">したがって、周波数加重テンソル特異値しきい値演算子を厳密に推定し、RTPCAの低ランク近似サブ問題に適用します。ロバストテンソル主成分分析（RTPCA）は、低ランク成分とスパース成分を多次元データから分離できます。いくつかの画像アプリケーションでうまく使用されています。この論文では、周波数成分分析をt-SVDに組み込んで、RTPCAのパフォーマンスを向上させます。 
[概要] t-svdに関連する中性子核ノルムを最小化すると、周波数領域のすべての正面スライスが等しく最適化されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br><font color="black">2020-04-21</font>
      </time>
    </span>
</section>
<!-- paper0: MMDF: Mobile Microscopy Deep Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_30.html">
      <font color="black">MMDF: Mobile Microscopy Deep Framework</font>
    </a>
  </h2>
  <font color="black">焦点が合っている/焦点が合っていない分類、高速スキャンのブレ除去、焦点合成などの問題はすべて、モバイルデバイスを使用してデータを記録するときに特定の特性があります。この作業では、包括的なものを作成することを目指していますモバイル顕微鏡に意図的に調整された一連の方法を接続することによるパイプライン：（1）安定した焦点/焦点外分類のためのCNNモデル、（2）画像のぼけ除去のための修正されたDeblurGANアーキテクチャ、（3）で組み合わせるためのFuseGANモデル-複数の画像のパーツに焦点を合わせて、細部を強調します。 
[概要]モバイル画像は高度な代理システムで開発されていますが、これらの課題はまだ解決されるのを待っています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-27">
        <br><font color="black">2020-07-27</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding Contrastive Representation Learning through Alignment and
  Uniformity on the Hypersphere -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_31.html">
      <font color="black">Understanding Contrastive Representation Learning through Alignment and
  Uniformity on the Hypersphere</font>
    </a>
  </h2>
  <font color="black">漸近的に、対照的な損失がこれらのプロパティを最適化し、ダウンストリームタスクへのプラスの効果を分析することを証明します。標準のビジョンと言語データセットでの広範な実験により、メトリックとダウンストリームタスクのパフォーマンスの両方の間の強い一致が確認されます。経験的に、最適化可能なものを導入します。各プロパティを定量化するためのメトリック。 
[概要] 2,000人以上が超球の喪失の影響を受けています。これには、誘発された分布の整列と均一性が含まれます。調査によると、指標は喪失に関連していることが示されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br><font color="black">2020-05-20</font>
      </time>
    </span>
</section>
<!-- paper0: HYDRA: Pruning Adversarially Robust Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_32.html">
      <font color="black">HYDRA: Pruning Adversarially Robust Neural Networks</font>
    </a>
  </h2>
  <font color="black">剪定の目的を、SGDを使用して効率的に解決される経験的リスク最小化問題として定式化することにより、この洞察を実現します。HYDRAというタイトルのアプローチが、最先端の良性と堅牢な精度を同時に備えた圧縮ネットワークを実現することを示します。 。当社のコードと圧縮ネットワークは、\ url {https://github.com/inspire-group/compactness-robustness}で公開されています。 
[要約]研究コミュニティは、これらの課題の1つに対処するために、堅牢なトレーニングとネットワークのプルーリングを個別に使用することを検討しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-24">
        <br><font color="black">2020-02-24</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Networks with Recurrent Generative Feedback -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_33.html">
      <font color="black">Neural Networks with Recurrent Generative Feedback</font>
    </a>
  </h2>
  <font color="black">ベイジアン脳仮説は、人間の脳が内部生成モデルを使用して感覚入力の事後信念を更新すると述べています。フィードバック付き畳み込みニューラルネットワーク（CNN-F）と呼ばれる提案されたフレームワークは、既存のCNNに潜在変数を含む生成フィードバックを導入します。ベイジアンフレームワークの下でMAP推論を交互に行うことで一貫した予測が行われるアーキテクチャ。実験では、CNN-Fは、標準ベンチマークで従来のフィードフォワードCNNよりも大幅に改善された敵対的ロバスト性を示しています。 
[概要]人間の知覚は、そのような摂動に対してはるかに堅牢です。このメカニズムは、自己一貫性の形式として解釈できます。cnn-fは、敵対的な堅牢性が大幅に向上していることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-17">
        <br><font color="black">2020-07-17</font>
      </time>
    </span>
</section>
<!-- paper0: A Soft Computing Approach for Selecting and Combining Spectral Bands -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_34.html">
      <font color="black">A Soft Computing Approach for Selecting and Combining Spectral Bands</font>
    </a>
  </h2>
  <font color="black">GPベースのソリューションを使用して、熱帯バイオーム内および熱帯バイオーム間の植生タイプの識別に関連する問題など、複雑な分類問題を評価しました。クラスのすべてのペアに特化したインデックスが取得されると、ピクセル単位で使用されます。分類タスク..学習したスペクトルインデックスの観点から定義された時系列を使用して、GPフレームワークが熱帯生物群系の識別と分類に使用される他のインデックスよりも優れた結果をもたらすことを示します。 
[概要]提案されたアプローチは、遺伝的プログラミング（gp）フレームワークに基づいています。熱帯バイオームを分類するためにさまざまなアルゴリズムで使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Removing Brightness Bias in Rectified Gradients -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_35.html">
      <font color="black">Removing Brightness Bias in Rectified Gradients</font>
    </a>
  </h2>
  <font color="black">特定のケースでは視覚的にコヒーレントですが、整流勾配の明るさの偏りを特定します。ディープニューラルネットワークの解釈と改善は、その根底にあるメカニズムのより良い理解に依存しています。「偏りのない整流勾配」は\ url {https：//で入手できます。 github.com/lenbrocki/NoBias-Rectified-Gradient} 
[ABSTRACT]顕著性マップは、さまざまな顕著性マップを使用して、入力画像の暗い領域が顕著性マップによってどのように強調表示されていないかを調べます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Line Art Correlation Matching Feature Transfer Network for Automatic
  Animation Colorization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_36.html">
      <font color="black">Line Art Correlation Matching Feature Transfer Network for Automatic
  Animation Colorization</font>
    </a>
  </h2>
  <font color="black">既存の方法は、次の線画を着色するための参照として前の色のフレームを入力するだけです。これは、特に明らかな変化が発生する位置で、前の色のフレームと次の線画の空間的な不整合のために色付けを誤解させます。レイヤーごとに同期された機能をディープセマンティックコードからコンテンツに段階的に転送するジェネレーター。これらの課題に対処するために、色付きの参照機能を学習可能な方法で位置合わせする一種の相関マッチング機能転送モデル（CMFTと呼ばれる）を設計します。モデルをU-Netベースのジェネレーターに粗い方法から細かい方法で統合します。 
[概要]単一線画の色付けのための多くのザラベースの方法が出現しました。フレーム間の一貫性の考慮が不足しているため、それらを採用することはできません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-14">
        <br><font color="black">2020-04-14</font>
      </time>
    </span>
</section>
<!-- paper0: Do We Need Depth in State-Of-The-Art Face Authentication? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_37.html">
      <font color="black">Do We Need Depth in State-Of-The-Art Face Authentication?</font>
    </a>
  </h2>
  <font color="black">一部の顔認識方法は、深度センサーから抽出された幾何学的情報を利用して、単一画像ベースの認識技術の弱点を克服するように設計されています。また、提案された方法が左右の画像の顔の位置を使用することを示すアブレーション研究を提供します。全体的なパフォーマンスを向上させる有益な機能をエンコードします。提案された方法は、大規模なベンチマークで既存の単一画像と明示的な深度ベースの方法の両方を上回り、なりすまし攻撃を認識することさえできることを示します。 
[概要]提案された方法は、顔の参加者を認識するために使用できます。また、参加者を理解するためのツールとして使用することもできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-24">
        <br><font color="black">2020-03-24</font>
      </time>
    </span>
</section>
<!-- paper0: ActionSpotter: Deep Reinforcement Learning Framework for Temporal Action
  Spotting in Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_38.html">
      <font color="black">ActionSpotter: Deep Reinforcement Learning Framework for Temporal Action
  Spotting in Videos</font>
    </a>
  </h2>
  <font color="black">さらに、正確な境界をローカライズするには、通常、高密度のビデオ分析を効果的に行う必要があります。このようなリストは、アクション検出アルゴリズムを使用して抽出できます。データセットTHUMOS14およびActivityNetで実行された実験は、フレームワークが最先端の検出方法よりも優れていることを示しています。 
[概要]タスクは、動画内の特定のアクションの可能性として定義できます。ただし、アクションの存在を知るためにアクションの境界を決定する必要はありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-15">
        <br><font color="black">2020-04-15</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Contrastive Photo-to-Caricature Translation based on
  Auto-distortion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_39.html">
      <font color="black">Unsupervised Contrastive Photo-to-Caricature Translation based on
  Auto-distortion</font>
    </a>
  </h2>
  <font color="black">写真から似顔絵への翻訳は、スケッチ、鉛筆画、またはその他の芸術的な描画によって特徴を誇張したレンダリング画像として似顔絵を合成することを目的としています。対になっていない/監視されていない方法で誇張された変形を取得するために、歪み予測モジュール（DPM）を提案します。 ）いくつかの制御点を固定しながら、各入力画像の変位ベクトルのセットを予測し、続いてワーピングのための薄板スプライン補間を行います。既存の方法の直感的なアーティファクトを考慮して、スタイルレンダリングの対照的なスタイル損失を提案して、レンダリングされた写真のスタイルと似顔絵の類似性と同時に、写真との不一致を強調します。 
[概要]写真からシーンへの変換では、写真から空気への変換の最も重要な側面を確認します。新しい方法では、レンダリングされた写真のスタイルと似顔絵の類似性を強化するために、スタイルレンダリングの対照的なスタイルの喪失が示唆されます。モデルはペアリングされていないものでトレーニングされており、写真または似顔絵のいずれかを入力することで双方向の合成を提供できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Data Augmentation with Online Bilevel Optimization for Image
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_40.html">
      <font color="black">Learning Data Augmentation with Online Bilevel Optimization for Image
  Classification</font>
    </a>
  </h2>
  <font color="black">ただし、データ拡張ハイパーパラメータに高価な外部検証ループは必要ありません。このフレームワークは、分類器などのエンドタスクモデルと組み合わせて最適なデータ拡張を学習するための一般的なソリューションとして使用できます。バイレベル最適化を使用して、直接検証セットを使用して、データ拡張パラメーターを最適化します。 
[ABSTRACT]バイレベルを使用して、検証セットを使用してデータ拡張パラメータを最適化する方法を学びます。結果は、共同トレーニング方法が、慎重に手作りされたデータ拡張と同等またはそれ以上の画像分類精度を生成することを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-25">
        <br><font color="black">2020-06-25</font>
      </time>
    </span>
</section>
<!-- paper0: Ellipse Detection and Localization with Applications to Knots in Sawn
  Lumber Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_41.html">
      <font color="black">Ellipse Detection and Localization with Applications to Knots in Sawn
  Lumber Images</font>
    </a>
  </h2>
  <font color="black">この論文では、Faster R-CNNとそのRegionProposal Network（RPN）を適応させて、ガウス関数を使用して楕円形オブジェクトをモデル化し、関心領域のプーリングと回帰を追加することにより、既存のGaussian Proposal Network（GPN）アーキテクチャを拡張します。分岐、および楕円オブジェクトの正確な位置を予測するための損失関数としてワッサースタイン距離を使用します。モデルを楕円形状に合わせて調整し、それによって汎用検出器を改善する方法を示します。より一般的には、楕円形の欠陥は、ガラスやプラスチックを鋳造する際の密閉気泡など、工業生産で一般的です。木材用途に固有で、スキャン中の原木画像のミスアライメントを修正するアルゴリズムも提案し、最初の貢献をします。前処理された画像の楕円形の結び目にラベルを付けることによるオープンソースの材木結び目データセット。 
[要約]この論文では、ガウス関数を使用してahmadオブジェクトをモデル化するために、より高速なr --cnnをその領域提案ネットワーク（rpn）に適合させます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: AIM 2020 Challenge on Learned Image Signal Processing Pipeline -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_42.html">
      <font color="black">AIM 2020 Challenge on Learned Image Signal Processing Pipeline</font>
    </a>
  </h2>
  <font color="black">提案されたソリューションは、ベースラインの結果を大幅に改善し、実用的な画像信号処理パイプラインモデリングの最先端を定義しました。このペーパーでは、2番目のAIM学習ISPチャレンジをレビューし、提案されたソリューションと結果の説明を提供します。このチャレンジで使用されるメトリックは、忠実度スコア（PSNRおよびSSIM）と、ユーザー調査で測定されたソリューションの知覚結果を組み合わせたものです。 
[概要]目標は、huawei p20デバイスでキャプチャされた元の低品質の生画像を、canon 5ddslrカメラで取得された同じ写真にマッピングすることでした。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Decoupled Appearance and Motion Learning for Efficient Anomaly Detection
  in Surveillance Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_43.html">
      <font color="black">Decoupled Appearance and Motion Learning for Efficient Anomaly Detection
  in Surveillance Video</font>
    </a>
  </h2>
  <font color="black">自動化された異常検出には、純粋に監視されていないアプローチの方がはるかに適しています。このベースラインから逸脱するものはすべて、下流でさらに分析するために異常としてフラグが付けられます。以前の作業とは対照的に、異常メトリックとして潜在的なコード予測を使用します。 
[要約]カメラごとに、個別のアルゴリズムを展開できます。外観と動きに関連する機能のベースラインモデルを時間の経過とともに学習します。これは、さまざまなベンチマークデータセットでの再構成ベースおよびフレーム予測ベースの方法よりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: SelfDeco: Self-Supervised Monocular Depth Completion in Challenging
  Indoor Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_44.html">
      <font color="black">SelfDeco: Self-Supervised Monocular Depth Completion in Challenging
  Indoor Environments</font>
    </a>
  </h2>
  <font color="black">NYUv2、KITTI、およびNAVERLABS屋内データセットの既存のアプローチと比較し、二乗平均平方根誤差（RMSE）の削減が5 \：-\：34 \％向上することを確認します。自己監視単眼深度の新しいアルゴリズムを提示します。完了..私たちの自己監視アルゴリズムは、テクスチャのない領域、光沢のある透明な表面、非ランバーシアン表面、動く人々、長くて多様な深度範囲、複雑な自我運動によってキャプチャされたシーンなど、挑戦的な屋内環境向けに設計されています。 
[概要]私たちのアプローチは、高密度の深度測定のみを必要とするニューラルネットワークのトレーニングに基づいています。システムのルートは、最小限の最小深度測定を必要とするシステムと呼ばれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Tattoo tomography: Freehand 3D photoacoustic image reconstruction with
  an optical pattern -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_45.html">
      <font color="black">Tattoo tomography: Freehand 3D photoacoustic image reconstruction with
  an optical pattern</font>
    </a>
  </h2>
  <font color="black">方法：この論文では、外部追跡システムを必要とせず、臨床ワークフローにスムーズに統合できるPATデータの3D再構成（タトゥートモグラフィー）への新しいアプローチを提示します。このパターンは、トモグラフィー画像のように設計されています。これにより、パターンの座標系に対するプローブポーズの回復が可能になります。したがって、臨床フリーハンドPATの貴重なツールになる可能性があります。 
[概要]従来適用されていた2dプローブによって提供される限られた視野（fov）。これは、関心領域に配置された光学パターンに基づいています。これにより、取得した一連のpa画像を共通のグローバル座標に復元できます。システム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: A Multi-stream Convolutional Neural Network for Micro-expression
  Recognition Using Optical Flow and EVM -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_46.html">
      <font color="black">A Multi-stream Convolutional Neural Network for Micro-expression
  Recognition Using Optical Flow and EVM</font>
    </a>
  </h2>
  <font color="black">最近の多くの最先端のアプローチと比較して、私たちの方法はより有望な認識結果を達成します。次に、マスク、オプティカルフロー画像、およびグレースケール画像をMSCNNに追加します。具体的には、EVMとオプティカルフローを採用します。 MEの微妙な動きの変化を拡大して視覚化し、オプティカルフロー画像からマスクを抽出します。 
[概要]この論文では、私が認識できるマルチストリーム畳み込みニューラルネットワークを作成します。クリスタルフロー画像を使用し、それらをmscnnに追加します。広範なテストの後、2つのパブリックmeデータベースでさらに多くのことを行いました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-07">
        <br><font color="black">2020-11-07</font>
      </time>
    </span>
</section>
<!-- paper0: CenterFusion: Center-based Radar and Camera Fusion for 3D Object
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_47.html">
      <font color="black">CenterFusion: Center-based Radar and Camera Fusion for 3D Object
  Detection</font>
    </a>
  </h2>
  <font color="black">コードはhttps://github.com/mrnabati/CenterFusionで入手できます。関連するレーダー検出を使用して、レーダーベースの特徴マップを生成し、画像の特徴を補完し、深度、回転、速度などのオブジェクトプロパティに回帰します。自律型車両の知覚システムは、周囲の物体を検出して追跡する役割を果たします。 
[概要] centerfusionと呼ばれる私たちのアプローチは、最初に中心点検出ネットワークを使用して、中心点を識別することによってオブジェクトを検出します。キーポイント検出は、レーダーベースの特徴マップを生成して画像の特徴を補完し、次のようなオブジェクトのプロパティに回帰するために使用されます。深さ、回転、速度</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Deep correction of breathing-related artifacts in MR-thermometry -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_48.html">
      <font color="black">Deep correction of breathing-related artifacts in MR-thermometry</font>
    </a>
  </h2>
  <font color="black">このため、畳み込みニューラルネットワーク（CNN）は、温熱療法の前の準備学習段階で取得された画像から見かけの温度摂動を学習するように設計されました。その後の温熱療法の手順では、最近のマグニチュード画像がCNN-の入力として使用されます。現在の温度マップのオンライン補正を生成するためのモデル。補正しないままにすると、これらのアーティファクトは温度推定値に重大なエラーを引き起こし、治療ガイダンスを損ないます。 
[ABSTRACT]温度アーチファクトが呼吸および生理学的運動によって誘発されるため、移動するターゲットの温度測定は依然として困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Simple means Faster: Real-Time Human Motion Forecasting in Monocular
  First Person Videos on CPU -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_49.html">
      <font color="black">Simple means Faster: Real-Time Human Motion Forecasting in Monocular
  First Person Videos on CPU</font>
    </a>
  </h2>
  <font color="black">CityWalksでトレーニングされたシンプルなメソッドは、最先端のメソッド（STED）の予測精度を上回り、CPUでは9.6倍高速です（STEDはGPUで実行されます）。シンプルで高速、軽量です。一人称単眼ビデオで人間の将来の位置を予測するためのRNNベースのフレームワーク。具体的には、過去の情報のエンコード段階で自動エンコーダーを使用し、最終的に正規化レイヤーを使用すると、オーバーヘッドを無視して予測の精度が向上することを示します。 
[概要]バウンディングボックスに依存するネットワークは、CPU上で非常に高いレートでより優れた予測軌道を実行できます。システムは、ゼロショットまたはわずか15％の罰金の後、他の同様のデータセクターに転送することもできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Covariance-free Partial Least Squares: An Incremental Dimensionality
  Reduction Method -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_50.html">
      <font color="black">Covariance-free Partial Least Squares: An Incremental Dimensionality
  Reduction Method</font>
    </a>
  </h2>
  <font color="black">特徴選択のコンテキストでは、CIPLSは、最先端の手法と比較した場合に同等の結果を達成します。このコンテキストでは、部分最小二乗（PLS）は、画像分類やニューラルネットワークの最適化などのタスクで注目すべき結果を示しています。顔の検証と画像分類タスクでCIPLSを検証します。このタスクでは、他のいくつかの増分次元削減手法よりも優れています。 
[ABSTRACT]部分最小二乗（pls）は、画像分類などのタスクで顕著な結果を示しました。これにより、データが継続的に生成されているストリーミングアプリでplsを使用する必要があります。この要件により、plsを使用できなくなり、視聴者は使用する必要があります。それら</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-05">
        <br><font color="black">2019-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Deep Analysis Dictionaries for Image Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_51.html">
      <font color="black">Learning Deep Analysis Dictionaries for Image Super-Resolution</font>
    </a>
  </h2>
  <font color="black">ディープニューラルネットワークの最近の成功と多層辞書モデルを開発するための最近の取り組みに触発されて、単一画像超解像として知られる特定の回帰タスクに対処するために最適化されたディープ分析辞書モデル（DeepAM）を提案します。DeepAM監視付きセットアップと監視なしセットアップの両方を使用します。IPADと対応するソフトしきい値は、前のレイヤーから次のレイヤーに重要な情報を渡すように設計されていますが、CADと対応するソフトしきい値演算子は、スパースを生成するように設計されています。主要な特徴の識別を容易にする入力データの特徴表現。 
[概要]提案された深層分析辞書タスクは、分析辞書とソフトしきい値演算子に基づいています。CADは、対応するソフトしきい値とともに、前のレイヤーから次のレイヤーに重要な情報を渡すように設計されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-31">
        <br><font color="black">2020-01-31</font>
      </time>
    </span>
</section>
<!-- paper0: Kinematics-Guided Reinforcement Learning for Object-Aware 3D Ego-Pose
  Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_52.html">
      <font color="black">Kinematics-Guided Reinforcement Learning for Object-Aware 3D Ego-Pose
  Estimation</font>
    </a>
  </h2>
  <font color="black">また、ドリフトを修正し、推定された人間とオブジェクトの相互作用を改善するための微調整ステップを構築します。制御された設定と野生の設定の両方での実験は、私たちの方法がオブジェクト条件付き3Dエゴポーズシーケンスを正常に抽出できることを示していますは物理法則と一致しています。これは、エゴセントリックビデオからオブジェクト（椅子、ボックス、障害物など）との物理的に有効な3D全身相互作用シーケンスを推定する最初の作業です。 
[概要]目的は、3Dシーンのコンテキストを組み込み、ポーズ推定の品質を向上させることです。これは、自己中心的なビデオからのオブジェクトとの物理的に有効な3D全身相互作用シーケンスを推定する最初の作業です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: InfoMax-GAN: Improved Adversarial Image Generation via Information
  Maximization and Contrastive Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_53.html">
      <font color="black">InfoMax-GAN: Improved Adversarial Image Generation via Information
  Maximization and Contrastive Learning</font>
    </a>
  </h2>
  <font color="black">これは、GANに対照的な学習と相互情報量最大化アプローチを採用し、広範な分析を実行して改善の原因を理解することで実現します。このアプローチは、実装が簡単で実用的です。補助的な目的が1つだけで、計算コストが低く、ハイパーパラメータ調整なしで、幅広いトレーニング設定とデータセットにわたって堅牢に実行されます。私たちのアプローチは、GANトレーニングを大幅に安定させ、最先端の作業に対する同じトレーニングと評価条件下で、5つのデータセットにわたる画像合成のGANパフォーマンスを向上させます。 
[概要]私たちのアプローチは、ガンのトレーニングを大幅に安定させ、ガンのパフォーマンスを向上させます。再現性のために、私たちのコードは模倣で利用可能です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Human-centric Spatio-Temporal Video Grounding With Visual Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_54.html">
      <font color="black">Human-centric Spatio-Temporal Video Grounding With Visual Transformers</font>
    </a>
  </h2>
  <font color="black">このタスクは、監視ビデオが非常に長くなる可能性があるが、特定の期間の特定の人物のみが関係するヘルスケアおよびセキュリティ関連のアプリケーションに特に役立ちます。この作業では、新しいタスクであるHumancentricSpatioを紹介します。時間的ビデオ接地（HC-STVG）.. HC-STVGは、空間的（場所）と時間的（いつ）の両方のローカリゼーションを必要とするビデオ接地タスクです。 
[ABSTRACT] hc-stvgは、指定されたテクスチャの説明に基づいて、トリミングされていないビデオからターゲット人物の時空間チューブをローカライズすることを目的としています。これは、空間（where）と時間（when）の両方のローカリゼーションを必要とするビデオ接地タスクです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Pristine annotations-based multi-modal trained artificial intelligence
  solution to triage chest X-ray for COVID-19 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_55.html">
      <font color="black">Pristine annotations-based multi-modal trained artificial intelligence
  solution to triage chest X-ray for COVID-19</font>
    </a>
  </h2>
  <font color="black">コンピュータ断層撮影（CT）やX線などの最前線のモダリティは、COVID患者のトリアージに重要な役割を果たします。リソース（ハードウェアと訓練を受けた要員の両方）へのアクセスの制限と除染の考慮事項を考慮すると、CTは疑わしいトリアージには理想的ではない可能性があります被験者..マルチモーダルソリューションは、AUC（レシーバーの動作特性曲線の下の領域）を0.89から0.93に増加させ、病理を特定するためのダイス係数（0.59から0.62）にもプラスの影響を与えます。 
[ABSTRACT]人工知能（ai）を利用したトリアージとモニタリングのためのxベースのアプリケーションでは、経験豊富な放射線科医がタイムリーに患者を特定する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding the hand-gestures using Convolutional Neural Networks and
  Generative Adversial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_56.html">
      <font color="black">Understanding the hand-gestures using Convolutional Neural Networks and
  Generative Adversial Networks</font>
    </a>
  </h2>
  <font color="black">さらに、トレーニング画像の選択や、入力パターンをジェスチャとして認定するのに役立つ非ジェスチャパターンを削除する適応しきい値ジェスチャなどのアプローチを使用して、認識のパフォーマンスと精度を向上させる手法が提案されています。システムは、リアルタイムのハンドトラッキング、トレーニングジェスチャ、およびConvolutional Neural Networksを使用したジェスチャ認識の3つのモジュールで構成されます。実験では、アルファベットと数字を含む36のジェスチャの語彙に対してテストされ、アプローチの有効性が得られました。 
[ABSTRACT]システムは、リアルタイムのハンドトラッキング、トレーニングジェスチャ、畳み込みニューラルネットワークを使用したジェスチャ認識の3つのモジュールで構成されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Adjusting Bias in Long Range Stereo Matching: A semantics guided
  approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_57.html">
      <font color="black">Adjusting Bias in Long Range Stereo Matching: A semantics guided
  approach</font>
    </a>
  </h2>
  <font color="black">この問題を解決するために、まずこれらのバイアスの影響を分析し、次に前景と背景の新しい深度ベースの損失関数のペアを別々に提案します。ただし、視差推定の精度は深度の精度に直接変換されません。特に遠方のオブジェクトの推定。同時ローカリゼーションおよびマッピング（SLAM）や3Dオブジェクト検出など、多くのアプリケーションでは、視差は主に深度値の計算に必要であり、深度推定の精度は視差推定よりも説得力があります。 
[ABSTRACT]視差は主に深度値を計算するために必要です。これは主に、視差ベースの損失関数とトレーニングデータの選択によって課せられるバイアスによるものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: The Virtual Goniometer: A new method for measuring angles on 3D models
  of fragmentary bone and lithics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_58.html">
      <font color="black">The Virtual Goniometer: A new method for measuring angles on 3D models
  of fragmentary bone and lithics</font>
    </a>
  </h2>
  <font color="black">さらに、仮想ゴニオメーターは、複数のユーザー間でも角度測定値の正確な複製を可能にします。これは、ゴニオメーターベースの研究の再現性にとって重要です。仮想ゴニオメーターは、オープンソースメッシュ処理パッケージMeshlabおよびBlenderのプラグインとして利用できます。 、ゴニオメトリーが考古学的手法を改善し、人類学的問題に対処する可能性を探る研究者が簡単にアクセスできるようにします。手動ゴニオメーターと仮想ゴニオメーターの観察者内変動を比較すると、仮想ゴニオメーターの方がはるかに一貫性があり、信頼性が高いことがわかります。 
[概要]仮想ゴニオメーターは、迅速なデータ収集を可能にし、手動ゴニオメーターでは物理的にアクセスできない多くの角度の測定を可能にします。これは、ゴニオメーターベースの研究にとって重要な角度の測定に使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: FPCR-Net: Feature Pyramidal Correlation and Residual Reconstruction for
  Semi-supervised Optical Flow Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_59.html">
      <font color="black">FPCR-Net: Feature Pyramidal Correlation and Residual Reconstruction for
  Semi-supervised Optical Flow Estimation</font>
    </a>
  </h2>
  <font color="black">残余再構成モジュールは、各段階でより細かいオプティカルフローのサブバンド高周波残余を再構成することを目的としています。オプティカルフロー推定は、ビデオ分析の分野で重要でありながら困難な問題です。ピラミッド相関マッピングモジュールは、さまざまなスケールの機能を集約してマルチレベルのコストボリュームを形成することによる、グローバル/ローカルパッチのマルチスケール相関。 
[ABSTRACT]システムは、ピラミッド相関マッピングと残差再構成の2つの主要モジュールで構成されています。ピラミッド相関は、むしゃむしゃシステムの効果を特徴としています。結果は、提案されたスキームが最先端のパフォーマンスを達成することを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-17">
        <br><font color="black">2020-01-17</font>
      </time>
    </span>
</section>
<!-- paper0: Point Cloud Registration Based on Consistency Evaluation of Rigid
  Transformation in Parameter Space -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_60.html">
      <font color="black">Point Cloud Registration Based on Consistency Evaluation of Rigid
  Transformation in Parameter Space</font>
    </a>
  </h2>
  <font color="black">さらに、この方法では、各トリプレットの剛体変換パラメーターの整合性をヒストグラムで評価し、点群間の剛体変換を取得します。登録と呼ばれる方法を使用して、実世界の形状を表すいくつかの点群を統合できます。その結果、比較手法に比べて十分に正確で安定した登録結果が得られました。 
[概要]本論文では、高精度で安定したレジストレーション法を提案する。我々の方法は、ヒストグラムを用いて各トリプレットの剛体変換パラメータの整合性を分析し、点群間の剛体変換を取得する。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Hypersim: A Photorealistic Synthetic Dataset for Holistic Indoor Scene
  Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_61.html">
      <font color="black">Hypersim: A Photorealistic Synthetic Dataset for Holistic Indoor Scene
  Understanding</font>
    </a>
  </h2>
  <font color="black">驚くべきことに、最先端の自然言語処理モデルのトレーニングの約半分のコストで、データセット全体を最初から生成できることがわかりました。データセットの生成に使用したすべてのコードが利用可能になります。オンライン..私たちのデータセット：（1）公的に利用可能な3D資産のみに依存しています。 （2）すべてのシーンの完全なシーンジオメトリ、マテリアル情報、および照明情報が含まれます。 （3）すべての画像のピクセルごとの密なセマンティックインスタンスセグメンテーションが含まれます。 （4）すべての画像を、拡散反射、拡散照明、およびビューに依存する照明効果をキャプチャする非拡散残差項に因数分解します。 
[ABSTRACT]ハイパーアリティは、全体的な屋内シーンを理解するための合成データセットであり、ハイパーアリティが必要です。データセットは、公開されている3Dアセットのみに依存しています。これには、3Dから3Dまでのすべてが含まれます。たとえば、データセットの生成に使用したすべてのコードは次のようになります。オンラインで利用可能</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-04">
        <br><font color="black">2020-11-04</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Multimodal Fusion by Channel Exchanging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_62.html">
      <font color="black">Deep Multimodal Fusion by Channel Exchanging</font>
    </a>
  </h2>
  <font color="black">この目的のために、この論文は、異なるモダリティのサブネットワーク間でチャネルを動的に交換するパラメータフリーのマルチモーダル融合フレームワークであるチャネル交換ネットワーク（CEN）を提案します。詳細なアブレーション研究も実施されており、これは確かに利点を確認しています。このような交換プロセスの有効性は、畳み込みフィルターを共有しながら、モダリティ間で個別のBNレイヤーを維持することによっても保証されます。これにより、アドオンの利点として、マルチモーダルアーキテクチャをユニモーダルネットワークとほぼ同じくらいコンパクトにすることができます。 。 
[概要]システムは、個々のチャネルの重要性によって自己誘導されます。これは、現在の最先端の方法と比較されます。これにより、パフォーマンスのボトルネックが発生します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-modal Fusion for Single-Stage Continuous Gesture Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_63.html">
      <font color="black">Multi-modal Fusion for Single-Stage Continuous Gesture Recognition</font>
    </a>
  </h2>
  <font color="black">これを可能にするために、マルチモーダル入力から流れる重要な情報の統合をサポートするマルチモーダル融合メカニズムを導入し、任意の数のモードにスケーラブルです。パフォーマンスをさらに向上させるために、中間点ベースの損失を提案します。グラウンドトゥルースと予測の間のスムーズな位置合わせを促進する関数。さらに、ユニモーダルフィーチャマッピング（UFM）モデルとマルチモーダルフィーチャマッピング（MFM）モデルを提案して、それぞれユニモーダルフィーチャと融合マルチモーダルフィーチャをマッピングします。 
[ABSTRACT]既存の連続ジェスチャ認識方法は2段階のアプローチによって制限されます。これらのモデルは検出と分類に必要であり、後者のパフォーマンスは検出パフォーマンスによって制約されます。ユニモーダルフィーチャのユニモーダルフィーチャマッピングを提案します。それぞれ融合されたマルチモーダル機能</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Communicate and Correct Pose Errors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_64.html">
      <font color="black">Learning to Communicate and Correct Pose Errors</font>
    </a>
  </h2>
  <font color="black">したがって、通信、潜在的なエラーの推定、そして最終的にそれらのエラーについてのコンセンサスに到達することを学習する新しい神経推論フレームワークを提案します。実験により、提案されたフレームワークがマルチエージェント自己駆動知覚のロバスト性を大幅に改善し、現実的で深刻なローカリゼーションノイズ下のモーション予測システム。エージェントがタスクを一緒に解決するとパフォーマンスが大幅に向上しますが、通信は空間変換に依存しているため、ポーズノイズが存在するとゲインが急速に低下します。 
[概要]この研究はニューヨーク大学の研究者によって実施されました。彼らは、個々のエージェントが一緒に課題を解決することは困難であると述べています。しかし、ポーズノイズがあるとゲインは急速に低下します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: STCNet: Spatio-Temporal Cross Network for Industrial Smoke Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_65.html">
      <font color="black">STCNet: Spatio-Temporal Cross Network for Industrial Smoke Detection</font>
    </a>
  </h2>
  <font color="black">たとえば、空間パスは樹木や建物などの明らかな干渉を簡単に認識でき、時間パスは煙の動きのあいまいな痕跡を強調できます。産業用煙の放出は、自然の生態系と人間の健康に深刻な脅威をもたらします。産業排出粒子は煙突や施設の外で急速に崩壊することが多く、蒸気は煙と非常に似ているため、煙の検出は困難な作業です。 
[概要]産業用煙の排出を認識するために、新しい空間-時間的クロスネットワーク（stcnet）が提案されています。これらの問題を克服するために提案された、新しい排出ネットワーク（stc net）が提案されました。2つの経路が互いにガイドすることができます。煙探知性能に役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Loss Weighting with Coefficient of Variations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_66.html">
      <font color="black">Multi-Loss Weighting with Coefficient of Variations</font>
    </a>
  </h2>
  <font color="black">重みの適切なセットを見つけることは、多くの場合、広範なグリッド検索を使用して設定されるハイパーパラメーターのセットにそれらを採用することによって行われます。機械学習とコンピュータービジョンの多くの興味深いタスクは、重みとして定義された目的関数を最適化することによって学習されます。複数の損失の線形組み合わせ..文献の多くの損失重み付け方法とは対照的に、単眼深度推定やセマンティックセグメンテーションなどの単一タスクの複数損失問題に焦点を当て、損失重み付けのマルチタスクアプローチが機能しないことを示しますそれらの単一タスクで。 
[要約]提案された方法は、損失のバランスをとるために不確実性の尺度を使用するために提案されています。その結果、損失の重みは、別の（学習ベースの）最適化を必要とせずにトレーニング中に進化します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-03">
        <br><font color="black">2020-09-03</font>
      </time>
    </span>
</section>
<!-- paper0: Temporal Stochastic Softmax for 3D CNNs: An Application in Facial
  Expression Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_67.html">
      <font color="black">Temporal Stochastic Softmax for 3D CNNs: An Application in Facial
  Expression Recognition</font>
    </a>
  </h2>
  <font color="black">いくつかの表情認識ベンチマークで提案された方法で得られた実験結果は、トレーニングビデオでより有益なクリップに焦点を当てることの利点を示しています。特に、私たちのアプローチは、ビデオの不正確なトリミングと粗い注釈の影響を減らすことによってパフォーマンスと計算コストを改善します。ビデオ内の顔の表情を正確に時空間的に認識するための深層学習モデルのトレーニングには、かなりの計算リソースが必要です。 
[概要] 3d畳み込みニューラルネットワーク（3d cnns）は通常、ビデオからランダムに抽出された比較的短いクリップでトレーニングされます。提案されたソフトマックス戦略には、いくつかの利点があります。効率的なクリップサンプリングによる認知の複雑さの軽減、時間的重み付けがより多くに焦点を当てているため、精度の向上です。関連するクリップ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Multi-Target Domain Adaptation Through Knowledge
  Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_68.html">
      <font color="black">Unsupervised Multi-Target Domain Adaptation Through Knowledge
  Distillation</font>
    </a>
  </h2>
  <font color="black">私たちのマルチティーチャーMTDA（MT-MTDA）メソッドは、マルチティーチャー知識蒸留（KD）に依存して、複数の教師から一般の学生にターゲットドメイン知識を繰り返し抽出します。監視されていないドメイン適応（UDA）は、ドメインシフトの問題を軽減しようとします。ターゲットドメインからのラベルなしデータの配布の間。 MT-MTDAは、いくつかの挑戦的なUDAベンチマークで最先端の方法と比較され、経験的な結果は、提案されたモデルが複数のターゲットドメインにわたってかなり高いレベルの精度を提供できることを示しています。 
[ABSTRACT]教師なしmtdaは、複数のターゲットドメイン間で十分に一般化できるcnnをトレーニングする新しい方法です。この方法は、ターゲットドメインごとに1つの特殊なモデルを適応させることで解決できますが、このソリューションは多くの実際のアプリケーションではコストがかかりすぎます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-14">
        <br><font color="black">2020-07-14</font>
      </time>
    </span>
</section>
<!-- paper0: An Attack on InstaHide: Is Private Learning Possible with Instance
  Encoding? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_69.html">
      <font color="black">An Attack on InstaHide: Is Private Learning Possible with Instance
  Encoding?</font>
    </a>
  </h2>
  <font color="black">InstaHide 
[Huang、Song、Li、Arora、ICML&#39;20]は、通常の学習者によって処理される前に入力を変更するエンコードメカニズムによってプライバシーを保護すると主張する最近の提案です。私たちの攻撃は効果的かつ効率的であり、経験的に破られますInstaHide on CIFAR-10、CIFAR-100、および最近リリースされたInstaHide Challenge ..インスタンスエンコーディングを通じて学習のさまざまなプライバシー概念をさらに形式化し、これらの概念を実現する可能性を調査します。 
[ABSTRACT] instahideは、preservehideを主張する最近の提案です。私たちの攻撃は効果的かつ効率的です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: On-Device Language Identification of Text in Images using Diacritic
  Characters -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_70.html">
      <font color="black">On-Device Language Identification of Text in Images using Diacritic
  Characters</font>
    </a>
  </h2>
  <font color="black">発音区別符号のオブジェクト検出にSqueezedetと同様のアーキテクチャを使用し、その後に浅いネットワークを使用して最終的に言語を識別します。発音区別符号は、特定の言語をかなりの量で識別するための適切で重要な手がかりを提供する一意の文字セットと見なすことができます。高精度..85の発音区別符号を含む13のラテン言語にわたる作業を紹介します。 
[概要]発音区別符号の改善は、多くの言語の定義機能になる可能性があります。発音区別符号に加えて、これらはツールとして簡単に識別できません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: CoADNet: Collaborative Aggregation-and-Distribution Networks for
  Co-Salient Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_71.html">
      <font color="black">CoADNet: Collaborative Aggregation-and-Distribution Networks for
  Co-Salient Object Detection</font>
    </a>
  </h2>
  <font color="black">Co-Salient Object Detection（CoSOD）は、2つ以上の関連画像を含む特定のクエリグループに繰り返し表示される顕著なオブジェクトを検出することを目的としています。まず、顕著性の事前情報をバックボーン機能に統合し、オンラインのイントラを通じて冗長な背景情報を抑制します。顕著性ガイダンス構造..その後、グループごとのセマンティック相互作用を調査し、共顕著性機能を生成するために、2段階の集約および分散アーキテクチャを設計します。 
[概要]これは、インターネットの関係をモデル化して活用することにより、共同顕著性の手がかりを効果的にキャプチャする方法です。conetタスク用のグループ整合性保持デコーダーを開発します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: AIM 2020 Challenge on Rendering Realistic Bokeh -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_72.html">
      <font color="black">AIM 2020 Challenge on Rendering Realistic Bokeh</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、2番目のAIMの現実的なボケ効果レンダリングチャレンジをレビューし、提案されたソリューションと結果の説明を提供します。このチャレンジで使用されたターゲットメトリックは、ユーザー調査で測定されたソリューションの実行時間と知覚品質を組み合わせたものです。他のカメラやセンサーからの追加データなしで、1つのフレームのみに基づいてボケ効果をレンダリングします。 
[概要]参加者は現実世界のボケシミュレーション問題を解決していました。目標は、大規模な引き潮を使用して現実的な浅い焦点技術を学ぶことでした！ボケ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: MP-ResNet: Multi-path Residual Network for the Semantic segmentation of
  High-Resolution PolSAR Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CV/paper_73.html">
      <font color="black">MP-ResNet: Multi-path Residual Network for the Semantic segmentation of
  High-Resolution PolSAR Images</font>
    </a>
  </h2>
  <font color="black">高分コンテストは、高品質のPolSARセマンティックセグメンテーションデータセットへのオープンアクセスを提供しました。また、全体的な精度（OA）、平均F1およびfwIoUの点で、いくつかの古典的な最先端の方法を上回っていますが、計算コストはそれほど増加していません。さらに、MP-ResNetは、デコーダーにマルチレベルの機能融合設計を採用して、さまざまなブランチから学習した機能を最大限に活用しています。 
[概要]高分コンテストは、高品質のポルサーセマンティックセグメンテーションデータセットへのオープンアクセスを提供しました。mp--resnetは、並列マルチネットブランチでセマンティックコンテキストを学習します。アブレーション研究に加えて、mpresnetにはベースラインメソッドに比べて大きな利点があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Generalized LSTM-based End-to-End Text-Independent Speaker Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_0.html">
      <font color="black">Generalized LSTM-based End-to-End Text-Independent Speaker Verification</font>
    </a>
  </h2>
  <font color="black">話者認識分野の多くの研究者も、以前の最先端の手法をDL技術に置き換え始めていますが、従来のi-vectorベースの手法のいくつかは、現在でも最先端の手法です。テキストに依存しない話者認証（TI-SV）。このペーパーでは、GoogleによるTI-SV用のLong Short-term Memory（LSTM）ユニットに基づく最新の一般化されたエンドツーエンド（GE2E）DL手法について説明します。発話時間、トレーニング時間、精度などのさまざまなシナリオと側面を比較して、私たちの方法が従来の方法よりも優れていることを証明します。DLの急速な進歩と人気の高まりにより、機械学習が行われるほぼすべての分野に侵入し始めています。従来の最先端の方法を変更することにより、適用可能です。 
[概要]研究者は、発話時間、トレーニング時間、精度などのさまざまなシナリオと側面を比較して、私たちの方法が従来の方法よりも優れていることを証明します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: A Transfer Learning Approach for Dialogue Act Classification of GitHub
  Issue Comments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_1.html">
      <font color="black">A Transfer Learning Approach for Dialogue Act Classification of GitHub
  Issue Comments</font>
    </a>
  </h2>
  <font color="black">問題のコメントを対話行為にマッピングできることは、認知チームのプロセスを理解するための有用な足がかりです。問題のコメントで表現されているように、チームメンバー間の対話を分析すると、仮想チームのパフォーマンスに関する重要な洞察を得ることができます。単語表現用のグローバルベクトル（GloVe）、ユニバーサルセンテンスエンコーダー（USE）、トランスフォーマーからの双方向エンコーダー表現（BERT）など、いくつかの単語および文レベルのエンコードモデルのパフォーマンス。 
[要約]問題のコメントで表現されているように、チームメンバー間の対話を理解することで、仮想チームのパフォーマンスに関する重要な洞察を得ることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Sparse Stochastic Zeroth-Order Optimization with an Application to
  Bandit Structured Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_2.html">
      <font color="black">Sparse Stochastic Zeroth-Order Optimization with an Application to
  Bandit Structured Prediction</font>
    </a>
  </h2>
  <font color="black">確率的ゼロ次（SZO）、または勾配のない最適化では、パラメーター摂動下の関数評価のみに依存することで任意の関数を最適化できますが、SZOメソッドの反復の複雑さは、摂動関数の次元に比例する要因に影響されます。スパースSZO最適化をリプシッツ連続、非凸、確率的目的に適用する一般的な証明を提供し、理論的結果を確認するスパースワードベースの特徴表現を使用した線形バンディット構造化予測タスクの実験的評価を提示します。シナリオでそれを示します。構造化予測アプリケーションのように自然なスパース性パターンを使用すると、この係数を、入力と出力のペアで予想されるアクティブな機能の数に減らすことができます。 
[ABSTRACT]線形ソフトウェアソフトウェアソフトウェアは、活動のネットワークを予測するのが難しい可能性があることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-06-12">
        <br><font color="black">2018-06-12</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Machine Translation for Extremely Low-Resource African Languages:
  A Case Study on Bambara -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_3.html">
      <font color="black">Neural Machine Translation for Extremely Low-Resource African Languages:
  A Case Study on Bambara</font>
    </a>
  </h2>
  <font color="black">低リソース言語での作業における課題について話し合い、低リソース機械翻訳（MT）でのデータ不足に対処するための戦略を提案します。バンバラ自体の言語的状況以上に、バンバラスピーカーが住む社会文化的文脈が課題を提起します。この言語の自動処理のために..トレーニングデータが不足していて、かなりの量の前処理を必要とするマンデ言語であるバンバラのケースについて説明します。 
[概要]バンバラはトレーニングデータが不足している人間の言語です。人間の言語はより多くの前処理を必要とします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Biomedical Information Extraction for Disease Gene Prioritization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_4.html">
      <font color="black">Biomedical Information Extraction for Disease Gene Prioritization</font>
    </a>
  </h2>
  <font color="black">確立された構造化されたソースからのPPIがすでに含まれているにもかかわらず、独自のIEベースの抽出をグラフに追加することで、医薬品開発に向けた重要なステップであるhit @ 30の相対的な増加が20％増加する、新しい疾患と遺伝子の関連を予測できることを示します。未治癒疾患の標的..それを数千万のPubMed抄録に適用して、タンパク質-タンパク質相互作用（PPI）を抽出し、これらの抽出を、主要な構造化PPIデータベースであるSTRINGから抽出されたPPIをすでに含む生物医学知識グラフに拡張します。テキストから生物学的関係を抽出する生物医学情報抽出（IE）パイプラインを導入し、名前付きエンティティ認識（NER）や関係抽出（RE）などのコンポーネントがBioNLPの最先端を上回っていることを示します。 
[ABSTRACT]タンパク質間相互作用（ppis）の抽出に適用します。抽出された抽出抽出物は、将来的に使用される可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Action State Update Approach to Dialogue Management -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_5.html">
      <font color="black">Action State Update Approach to Dialogue Management</font>
    </a>
  </h2>
  <font color="black">私たちの目標は、ドメイン固有の自然言語理解コンポーネントを使用せずに、ユーザー入力の参照式を解釈することです。ユーザーがシミュレートした人間の評価とインタラクティブな人間の評価の両方を使用して、ASUアプローチが、参照を含む対話システムでユーザーの発話を正常に解釈することを示します。式..発話解釈は、対話システムの主要コンポーネントである対話マネージャーの主要な機能の1つです。 
[ABSTRACT]発話解釈のアクション状態更新アプローチを提案します。これは、ユーザーの発話のテキスト内のダイアログ状態更新アクションを検出するために使用される、統計的にトレーニングされたバイナリ分類子を備えています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Training for Code Retrieval with Question-Description
  Relevance Regularization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_6.html">
      <font color="black">Adversarial Training for Code Retrieval with Question-Description
  Relevance Regularization</font>
    </a>
  </h2>
  <font color="black">2つのプログラミング言語の大規模なコード検索データセットでの実験は、敵対的学習方法が最先端のモデルのパフォーマンスを向上させることができることを示しています。コード検索は、自然言語とプログラミング言語を一致させることを目的とした重要なタスクです。まず、単純な敵対的学習手法を採用して、入力質問を指定して難しいコードスニペットを生成します。これは、バイモーダルでデータが不足している課題に直面するコード検索の学習に役立ちます。 
[概要]コード検索の敵対的学習を提案します。これは、質問によって正規化されます-説明の関連性。生成されたコードスニペットは、ペアの自然言語の説明がユーザーとの関連性が低いと予測される場合にのみ、コード検索トレーニングの損失に寄与するはずです。与えられた質問</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-19">
        <br><font color="black">2020-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: Translating Similar Languages: Role of Mutual Intelligibility in
  Multilingual Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_7.html">
      <font color="black">Translating Similar Languages: Role of Mutual Intelligibility in
  Multilingual Transformers</font>
    </a>
  </h2>
  <font color="black">私たちのスペイン語-カタロニア語モデルは、5つの言語ペアすべての中で最高のパフォーマンスを発揮します。また、言語ペアの1つに逆翻訳を活用して、3BLEUポイント以上の改善を実現します。類似言語間で翻訳するためのさまざまなアプローチを調査します。低リソース条件下で、WMT2020類似言語翻訳共有タスクへの貢献の一環として。 
[概要] 2つの方向で、すべての言語ペアに対してトランスフォーマーベースのバイリンガルおよびマルチリンガルシステムを提出しました。各ポイント間の相互理解度に照らして結果を解釈します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: To What Degree Can Language Borders Be Blurred In BERT-based
  Multilingual Spoken Language Understanding? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_8.html">
      <font color="black">To What Degree Can Language Borders Be Blurred In BERT-based
  Multilingual Spoken Language Understanding?</font>
    </a>
  </h2>
  <font color="black">実験を通じて、離れた言語グループでも実質的にうまく機能するものの、理想的な多言語パフォーマンスにはまだギャップがあることを示します。このペーパーでは、BERTベースの多言語音声言語理解（SLU）の程度に関する質問に対処します。モデルは言語間で知識を伝達することができます。私たちの実験結果は、提案されたモデルが理想的な多言語パフォーマンスへのギャップを狭めることができることを証明しています。 
[概要]提案されたモデルは、理想的な多言語パフォーマンスへのギャップを狭めることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Simultaneous Speech-to-Speech Translation System with Neural Incremental
  ASR, MT, and TTS -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_9.html">
      <font color="black">Simultaneous Speech-to-Speech Translation System with Neural Incremental
  ASR, MT, and TTS</font>
    </a>
  </h2>
  <font color="black">システムのEar-VoiceSpanでの全体的な遅延と、モジュールレベルのパフォーマンスとともに話す遅延を調査しました。システムは、自動音声認識（ASR）、機械翻訳（MT）、およびテキスト用の3つの完全インクリメンタルニューラル処理モジュールで構成されています。 -to-speech Synthesis（TTS）..このペーパーでは、新しく開発された同時ニューラル音声合成システムとその評価について説明します。 
[概要]システムは3つの完全にインクリメンタルな神経処理モジュールで構成されています。システムは3つの高度に高度に制御されたスピーキングシステムで構成されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Determining Question-Answer Plausibility in Crowdsourced Datasets Using
  Multi-Task Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_10.html">
      <font color="black">Determining Question-Answer Plausibility in Crowdsourced Datasets Using
  Multi-Task Learning</font>
    </a>
  </h2>
  <font color="black">私たちの最高のパフォーマンスのアプローチは、質問の妥当性を決定するシングルタスクモデルと、それに続く応答の妥当性を評価し、回答を抽出するマルチタスクモデルで構成されます（質問の妥当性AUROC = 0.75、応答の妥当性AUROC = 0.78、回答抽出F1 = 0.665）..マシンまたはユーザーが生成した質問と、ソーシャルメディアユーザーからのクラウドソースの応答が与えられた場合、質問と応答が有効かどうかを判断します。その場合、自由形式の応答内で回答を特定します。QA妥当性タスクを実行するBERTベースのモデルを設計し、クリーンで使用可能な質問回答データセットを生成するモデルの能力を評価します。 
[概要]プロジェクトは、質問への回答を支援するためにソーシャルメディアユーザーによって作成されました。これは、データ分析に基づく一連のTシャツに基づいています。プロジェクトは「質問-ユーザー」、「qa」の妥当性と呼ばれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Preemptive Detection of Depression and Anxiety in Twitter -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_11.html">
      <font color="black">Towards Preemptive Detection of Depression and Anxiety in Twitter</font>
    </a>
  </h2>
  <font color="black">この論文では、Twitterでのうつ病と不安の検出の研究を促進するように設計されたデータセットを開発し、検出タスクをバイナリツイート分類問題としてフレーミングします。それにもかかわらず、特に不均衡なトレーニングセットの場合、および一見明白な言語的手がかり（キーワード）が直感に反して使用されています。私たちの結果は、言語モデルがかなりうまく機能し、従来のベースラインよりも優れていることを示しています。 
[概要]これらの障害は、ソーシャルメディアで診断されていないユーザーが書いたテキストにやや頻繁に現れます。利用可能な場合は、不安やうつ病の可能性を示す言語フラグを医療専門家のツールとして使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Task Sequence Prediction For Tunisian Arabizi Multi-Level
  Annotation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_12.html">
      <font color="black">Multi-Task Sequence Prediction For Tunisian Arabizi Multi-Level
  Annotation</font>
    </a>
  </h2>
  <font color="black">システムは、Arabizi入力から開始して、カスケード内のすべての注釈レベルを予測することを学習します。また、後で手動で修正され、シーケンスモデルをさらに評価するために使用されたチュニジアのArabiziコーパスに注釈を付けるためにシステムをどのように使用したかを示します。チュニジアのデータ..私たちのシステムはFairseqフレームワーク用に開発されており、他のシーケンス予測問題をすばやく簡単に使用できます。 
[概要]このシステムは、データを使用してニューラルアーキテクチャの有効性を示すタイガードイツ語コーパスに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: On Posterior Collapse and Encoder Feature Dispersion in Sequence VAEs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_13.html">
      <font color="black">On Posterior Collapse and Encoder Feature Dispersion in Sequence VAEs</font>
    </a>
  </h2>
  <font color="black">この単純な手法は、事後崩壊を効果的に防止し、モデルが標準シーケンスVAEよりも大幅に優れたデータ対数尤度を達成できるようにします。既存の作業と比較して、提案された方法は、計算効率を高めながら、同等以上のパフォーマンスを達成できます。この仮説を検証し、プーリングを使用した簡単な修正を提案する証拠。自己回帰デコーダーを備えた
[ABSTRACT] vaesは、事後崩壊に悩まされます。これにより、シーケンスvaeが言語モデルに縮退します。提案された方法は、同等または優れたパフォーマンスを達成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br><font color="black">2019-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: UPB at SemEval-2020 Task 8: Joint Textual and Visual Modeling in a
  Multi-Task Learning Architecture for Memotion Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_14.html">
      <font color="black">UPB at SemEval-2020 Task 8: Joint Textual and Visual Modeling in a
  Multi-Task Learning Architecture for Memotion Analysis</font>
    </a>
  </h2>
  <font color="black">このようにして、背後にある情報を適切に明らかにできることを示します。具体的には、これらの投稿を分析するための新しいシステム、テキストエンコーディング用のALBERTと画像表現用のVGG-16を組み合わせたマルチモーダルマルチタスク学習アーキテクチャを紹介します。 ..インターネットミームはこれらの状況のために特別に作成されました。 
[概要]インターネットミームはこれらの状況のために特別に作成されました。これらの画像はさまざまな状況やイベントに関連付けることができます。これにより、私たちの世界が置かれているあらゆる状況に面白い側面を追加できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-06">
        <br><font color="black">2020-09-06</font>
      </time>
    </span>
</section>
<!-- paper0: Information Seeking in the Spirit of Learning: a Dataset for
  Conversational Curiosity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_15.html">
      <font color="black">Information Seeking in the Spirit of Learning: a Dataset for
  Conversational Curiosity</font>
    </a>
  </h2>
  <font color="black">ユーザーの事前知識を使用した応答は、エンゲージメントを高めます。このデータセットには、既存のユーザー知識、メッセージレベルのダイアログ動作、Wikipediaへの根拠、およびメッセージに対するユーザーの反応が注釈として付けられます。オープンエンドの人間の学習と情報探索はますます仲介されています。デジタルアシスタントによる。 
[概要]実験は群衆によって実施されました-オンス。結果はユーザーの事前知識を使用して作成されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: Investigating Transferability in Pretrained Language Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_16.html">
      <font color="black">Investigating Transferability in Pretrained Language Models</font>
    </a>
  </h2>
  <font color="black">さらに、レイヤーに事前トレーニング済みのパラメーターを使用する利点は、データセットサイズを微調整することで劇的に異なります。データが豊富な場合にパフォーマンスを大幅に向上させるパラメーターは、データが不足している設定では無視できるほどの利点を提供します。これらの結果は、転送学習プロセスの複雑さを明らかにしています。凍結モデルまたは単一のデータサンプルで動作するメソッドの制限を強調します。このメソッド、部分的な再初期化では、事前トレーニング済みモデルのさまざまなレイヤーをランダムな重みで置き換え、転送タスクでモデル全体を微調整し、パフォーマンスの変化を観察します。 
[要約]単純なアブレーション手法を使用して、事前トレーニングされた各レイヤーが転送タスクのパフォーマンスに与える影響を判断します。これらのデータサンプルは、転送学習プロセスの複雑さを明らかにし、凍結モデルまたは単一のデータサンプルで動作する手法の制限を強調しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: Medical Knowledge-enriched Textual Entailment Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_17.html">
      <font color="black">Medical Knowledge-enriched Textual Entailment Framework</font>
    </a>
  </h2>
  <font color="black">ベンチマークMEDIQA-RQEデータセットでフレームワークを評価し、知識が豊富なデュアルエンコーディングメカニズムの使用がSOTA言語モデルよりも8.27％の絶対的な改善を達成するのに役立つことを明らかにします。ただし、2つの大きな欠点が含意の特定におけるより高い成功を妨げています。 （1）質問の焦点/意図を理解し、（2）実世界の背景知識を利用して、文を超えたコンテキストをキャプチャする能力。既存のアプローチは、事前にトレーニングされた言語モデルまたはデータ拡張のアンサンブルを利用します。 、多くの場合、検証メトリックでより高い数値を記録します。 
[概要]既存のアプローチでは、事前にトレーニングされた言語モデルまたはデータ拡張のアンサンブルを利用して、検証メトリックでより多くの数値を記録することがよくあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: When Do You Need Billions of Words of Pretraining Data? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_18.html">
      <font color="black">When Do You Need Billions of Words of Pretraining Data?</font>
    </a>
  </h2>
  <font color="black">NLPは現在、RoBERTaのような汎用の事前トレーニング済み言語モデルによって支配されています。RoBERTaは、数十億の単語の事前トレーニングを通じてNLUタスクで強力なパフォーマンスを実現します。4つのプロービング方法を採用しています。 NLUタスクの微調整---そして、1M、10M、100M、および1Bの単語で事前トレーニングされたRoBERTaモデルのグループであるMiniBERTasを使用して、データ量の事前トレーニングに関する言語能力のこれらのさまざまな測定値の成長を追跡する学習曲線を描きます..しかし、Transformer LMは、大規模な事前トレーニングから、より少ないデータからは学ぶことができない正確な知識やスキルをどのように学びますか？ 
[要約]言語モデルは、事前トレーニングから学ぶために1億語以上を必要とします。lmsは約10mまたは1億語しか必要としない、研究結果。他の形式の知識が言語理解の最近の改善の主な推進力です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: UmBERTo-MTSA @ AcCompl-It: Improving Complexity and Acceptability
  Prediction with Multi-task Learning on Self-Supervised Annotations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_19.html">
      <font color="black">UmBERTo-MTSA @ AcCompl-It: Improving Complexity and Acceptability
  Prediction with Multi-task Learning on Self-Supervised Annotations</font>
    </a>
  </h2>
  <font color="black">ニューラル言語モデルは、EVALITA 2020でのAcCompl-it共有タスクのコンテキストでこの手順を使用して微調整され、予測品質が大幅に向上します。次に、それらの予測を使用して、ラベルのない多数の例に注釈を付けます。 -タスクトレーニングは、結果のトレーニングセットの並列注釈に対して実行され、最終スコアは、アノテーター固有の頭部予測を平均することによって取得されます。 
[ABSTRACT]元のモデルの複数のコピーが最初にダウンストリームタスクでトレーニングされます。最終的に、マルチタスクトレーニングが結果のトレーニングセットの並列アノテーションで実行されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Recursive Non-Autoregressive Graph-to-Graph Transformer for Dependency
  Parsing with Iterative Refinement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_20.html">
      <font color="black">Recursive Non-Autoregressive Graph-to-Graph Transformer for Dependency
  Parsing with Iterative Refinement</font>
    </a>
  </h2>
  <font color="black">BERTで事前トレーニングされたリファインメントモデルを使用して、いくつかの依存コーパスに対するRNGTrの能力と有効性を示します。任意のグラフを繰り返しリファインするための再帰的非自己回帰グラフ間トランスフォーマーアーキテクチャ（RNGTr）を提案します。非自己回帰のGraph-to-GraphTransformerを再帰的に適用し、構文依存性解析に適用します。RNGTrは、Universal Dependencies Treebanks、英語と中国語のPenn Treebanks、およびからの13言語でのさまざまな初期パーサーの精度を向上させることができます。ドイツのCoNLL2009コーパスは、SynTrによって達成された新しい最先端の結果をさらに改善し、テストされたすべてのコーパスの最先端を大幅に改善しました。 
[概要]いくつかの依存関係コーパスに対するrngtrの能力と有効性を実証しました。これにより、13言語のさまざまな初期パーサーの精度を向上させることができます。syntrによって達成される新しい最先端の結果よりもさらに向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-29">
        <br><font color="black">2020-03-29</font>
      </time>
    </span>
</section>
<!-- paper0: Pretraining Strategies, Waveform Model Choice, and Acoustic
  Configurations for Multi-Speaker End-to-End Speech Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_21.html">
      <font color="black">Pretraining Strategies, Waveform Model Choice, and Acoustic
  Configurations for Multi-Speaker End-to-End Speech Synthesis</font>
    </a>
  </h2>
  <font color="black">単純な品質しきい値を超えた、見つかったオーディオブックデータからマルチスピーカーモデルを微調整すると、合成音声の見えないターゲットスピーカーとの自然さと類似性が向上することがわかります。さらに、リスナーは16kHzと24kHzのサンプリングを識別できることがわかります。また、WaveRNNは、WaveNetに匹敵する品質の出力波形を生成し、推論時間が短縮されます。また、波形合成用のニューラルボコーダーの選択、およびメルスペクトログラムと最終オーディオ出力に使用される音響構成についても検討します。 
[概要]リスナーが16khzと24khzのサンプリングレートを識別できることを確認します。wavernnはwavenetと同等の品質の出力波形を生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Natural Language Inference in Context -- Investigating Contextual
  Reasoning over Long Texts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_22.html">
      <font color="black">Natural Language Inference in Context -- Investigating Contextual
  Reasoning over Long Texts</font>
    </a>
  </h2>
  <font color="black">セマンティック表現のテストには十分ですが、人間の推論プロセスの自然な部分である長いテキストのコンテキスト推論のテストには不十分です。長いテキストのConTextualReasoningの新しいデータセットであるConTRoLを紹介します。要約の事実上の正しさのチェックなどのダウンストリームタスクのテストセットとして。 
[概要]新しい言語テストは、言語言語言語テストに基づいています。新しい調査によると、最先端の言語モデルは、教育を受けた人間よりもはるかにパフォーマンスが劣っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Does Social Support Expressed in Post Titles Elicit Comments in Online
  Substance Use Recovery Forums? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_23.html">
      <font color="black">Does Social Support Expressed in Post Titles Elicit Comments in Online
  Substance Use Recovery Forums?</font>
    </a>
  </h2>
  <font color="black">この作業では、2つのReddit物質回復フォーラム（/ r / Leavesおよび/ r / OpiatesRecovery）からのデータを使用して、投稿のタイトルで表現されたソーシャルサポートとそれらが受け取るコメントの数との関係を判断します。コメントを引き出す投稿タイトルで表現されるソーシャルサポートの種類は、薬物使用回復フォーラムごとに異なります。薬物使用から回復する個人は、オンライン回復フォーラムでソーシャルサポート（感情的および情報的）を求めることが多く、書き込みとコメントの両方が可能です。投稿で、彼らの闘争と成功を表現します。 
[要約]これらのフォーラムでの一般的な課題は、特定の投稿がコメントを受け取らないことです。投稿のタイトルで表現されるソーシャルサポートの種類はサイトごとに異なることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Dialogue Distillation: Open-Domain Dialogue Augmentation Using Unpaired
  Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_24.html">
      <font color="black">Dialogue Distillation: Open-Domain Dialogue Augmentation Using Unpaired
  Data</font>
    </a>
  </h2>
  <font color="black">さらに、モデルレベルの蒸留プロセスを使用して、高品質のペアデータでトレーニングされた教師モデルを拡張ダイアログペアに蒸留し、それによってダイアログモデルが拡張データのノイズの影響を受けないようにします。このデータのジレンマに対処するために、対になっていないデータを利用してオープンドメインの対話モデルをトレーニングするための新しいデータ拡張方法を提案します。ランク付けモジュールを使用して、低品質の対話を除外します。 
[ABSTRACT]研究は、重要なデータを初めて収集する方法を示しています。拡張対話システムを構築するために、データレベルの蒸留プロセスが最初に提案されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-20">
        <br><font color="black">2020-09-20</font>
      </time>
    </span>
</section>
<!-- paper0: DoLFIn: Distributions over Latent Features for Interpretability -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_25.html">
      <font color="black">DoLFIn: Distributions over Latent Features for Interpretability</font>
    </a>
  </h2>
  <font color="black">このアプローチの有用性を示すために、DoLFInをテキスト分類に適用し、DoLFInが解釈可能なソリューションを提供するだけでなく、SST2およびAGニュースデータセットの従来のCNNおよびBiLSTMテキスト分類子よりもわずかに優れていることを示します。 0から1の範囲の関連する確率は、さらなる処理のための重要性を評価します。私たちのアプローチは、たとえば注意メカニズム内など、確率を中心的な量として使用することに成功したことに基づいています。 
[概要]私たちのアーキテクチャであるドルフィンでは、各機能が何を表すかを事前に決定することはなく、機能はすべて順序付けられていないセットになります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Latent Compositional Representations Improve Systematic Generalization
  in Grounded Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_26.html">
      <font color="black">Latent Compositional Representations Improve Systematic Generalization
  in Grounded Question Answering</font>
    </a>
  </h2>
  <font color="black">ツリー構造に対するこの誘導バイアスは、算術式ベンチマークや、根拠のある質問応答の体系的な一般化に焦点を当てたデータセットであるCLOSUREの強力なベースラインと比較して、分布外の例への体系的な一般化を劇的に改善することを示します。このやりがいのあるデータセットでは、モデルの精度は96.1％に達し、ランダムな分布内分割でタスクをほぼ完全に解決する以前のモデルよりも大幅に高くなっています。この作業では、すべての表現と表記を計算するモデルを提案します。質問は、CKYスタイルのパーサーを使用してボトムアップの構成的な方法で広がります。 
[要約]質問応答では、明示的に分解を実行しないため、分布の例から外への一般化が困難になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-01">
        <br><font color="black">2020-07-01</font>
      </time>
    </span>
</section>
<!-- paper0: Global Sentiment Analysis Of COVID-19 Tweets Over Time -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_27.html">
      <font color="black">Global Sentiment Analysis Of COVID-19 Tweets Over Time</font>
    </a>
  </h2>
  <font color="black">いくつかの最悪の被害を受けた国で1日あたりの確認された症例数に関する情報を提供するデータセットに対して探索的データ分析も実行され、感情の変化と開始以降の症例の変化との比較が提供されました。 2020年6月までのこのパンデミック..ソーシャルネットワーキングサイトのTwitterは、非常に短い期間で、新しいコロナウイルスに関連するツイートの前例のない増加を示しました。コロナウイルスのパンデミックは、通常の生活に影響を与えました。 
[概要]世界中の人々が自分の意見を表明するためにソーシャルメディアを利用しています。この現象は世界を席巻しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: On the State of Social Media Data for Mental Health Research -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_28.html">
      <font color="black">On the State of Social Media Data for Mental Health Research</font>
    </a>
  </h2>
  <font color="black">これは、メタ分析を容易にするために標準化されたスキーマを使用して注釈が付けられたメンタルヘルスデータセットのオープンソースディレクトリを導入することによって実現します。メンタルヘルスの治療と監視のためのデータ駆動型の方法は、過去10年間で計算科学研究の主要な焦点となっています。 ..以前の体系的なレビューでは、データ関連の課題が研究の進捗にどの程度影響したかを測定できるとは限りませんでした。 
[概要]メンタルヘルスの研究は、適切なデータが利用できることによって複雑になっています。ただし、ドメインの進捗状況は、データの量に依存し続けています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-document Summarization via Deep Learning Techniques: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/cs.CL/paper_29.html">
      <font color="black">Multi-document Summarization via Deep Learning Techniques: A Survey</font>
    </a>
  </h2>
  <font color="black">マルチドキュメント要約（MDS）は、トピック関連ドキュメントのクラスターから有益で簡潔な要約を生成する情報集約のための効果的なツールです。特に、ニューラルネットワークの設計戦略を要約して包括的なメカニズムを実行するための新しいメカニズムを提案します。最先端の要約..最後に、この分野の新しくエキサイティングな開発に関連するいくつかの将来の方向性を提案します。 
[概要] mdはその種の最初のものです。さまざまな目的関数間の違いを強調します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Generalized LSTM-based End-to-End Text-Independent Speaker Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.AS/paper_0.html">
      <font color="black">Generalized LSTM-based End-to-End Text-Independent Speaker Verification</font>
    </a>
  </h2>
  <font color="black">話者認識分野の多くの研究者も、以前の最先端の手法をDL技術に置き換え始めていますが、従来のi-vectorベースの手法のいくつかは、現在でも最先端の手法です。テキストに依存しない話者認証（TI-SV）。このペーパーでは、GoogleによるTI-SV用のLong Short-term Memory（LSTM）ユニットに基づく最新の一般化されたエンドツーエンド（GE2E）DL手法について説明します。発話時間、トレーニング時間、精度などのさまざまなシナリオと側面を比較して、私たちの方法が従来の方法よりも優れていることを証明します。利用可能なデータの量の増加とより手頃なハードウェアソリューションにより、ディープラーニング（DL）の領域への門が開かれました。 
[概要]研究者は、発話時間、トレーニング時間、精度などのさまざまなシナリオと側面を比較して、私たちの方法が従来の方法よりも優れていることを証明します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Enhancing Low-Quality Voice Recordings Using Disentangled Channel Factor
  and Neural Waveform Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.AS/paper_1.html">
      <font color="black">Enhancing Low-Quality Voice Recordings Using Disentangled Channel Factor
  and Neural Waveform Model</font>
    </a>
  </h2>
  <font color="black">最後に、ニューラルボコーダーを適用して音声波形を合成します。この作業では、エンコーダーデコーダーニューラルネットワークを提案して、低品質の録音をプロの高品質の録音に自動的に拡張します。チャネルの変動に対処するために、最初にフィルターを除外します。敵対的なトレーニングを伴うエンコーダネットワークを使用した、元の入力オーディオからのチャネル特性。 
[ABSTRACT]次に、自己回帰デコーダーを使用して、ターゲットを予測します-環境メルスペクトログラム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Convolutional Speech Recognition with Pitch and Voice Quality Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.AS/paper_2.html">
      <font color="black">Convolutional Speech Recognition with Pitch and Voice Quality Features</font>
    </a>
  </h2>
  <font color="black">私たちの知る限り、これは、このようなピッチと音声品質の機能を最新の畳み込みアーキテクチャと組み合わせた最初の作業であり、公開されているスペイン語のCommonVoiceとLibriSpeech100hデータセットについて、それぞれ最大7％と3％の相対WERポイントの改善を示しています。さらに、私たちの知る限り、スペイン語のCommon Voiceレシピはwav2letterの最初の公開スペイン語レシピです。Facebookのwav2letter音声認識フレームワークにピッチと音声品質の機能を追加し、そのようなコードとレシピをコミュニティに提供しています。 、さらなる実験を続けるために。 
[ABSTRACT]ピッチ機能は、以前は古典的なhrおよびdnnベースラインを改善するために使用されていました。ジッターおよびシマーパラメーターは、最新のタスクに役立つことが証明されています。ソフトウェアは、Facebookのwav2letter音声認識フレームワークに追加されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Deconstruct and Reconstruct Dizi Music of the Northern School and the
  Southern School -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.AS/paper_3.html">
      <font color="black">Deconstruct and Reconstruct Dizi Music of the Northern School and the
  Southern School</font>
    </a>
  </h2>
  <font color="black">特徴には、2つの異なる音楽スタイルのメロディーと演奏技術が分解されます。再構成の例、メロディー転送と演奏技術転送を含む音楽スタイル転送が与えられ、主観的評価が行われて再構成結果が評価されます。収集されたディジに基づいてデータセットでは、ノーザンスクールとサザンスクールのディジ音楽スタイルに関する研究を行っています。 
[概要]中国の音楽を収集するための新しい方法が提案されています。diziデータセットは、この方法を使用して収集されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Source-Aware Neural Speech Coding for Noisy Speech Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.AS/paper_4.html">
      <font color="black">Source-Aware Neural Speech Coding for Noisy Speech Compression</font>
    </a>
  </h2>
  <font color="black">このシステムの追加の利点は、コーデックが基になるソースに異なる量のビットを割り当てることができるため、デコードされた信号でより重要なソースの音声が良くなることです。受信側のユーザーが気にする新しいユースケースを対象としています。音声ソースが依然として最も重要な情報を運んでいる間、音声通信における非音声コンポーネントの品質。この論文は、ノイズの多い音声を効果的に処理できる新しいニューラルネットワークベースの音声コーディングシステムを紹介します。 
[概要]提案されたソース認識ニューラルオーディオシステムが開発されています。これにより、システムは潜在空間に対してさまざまな量の音声を実行できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-29">
        <br><font color="black">2020-08-29</font>
      </time>
    </span>
</section>
<!-- paper0: Supervised attention for speaker recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.AS/paper_5.html">
      <font color="black">Supervised attention for speaker recognition</font>
    </a>
  </h2>
  <font color="black">ただし、一部の設定では、SAPは時間平均プーリング（TAP）ベースラインと比較してパフォーマンスが低く、エンドツーエンドのトレーニングでは注意が効果的に学習されないことを意味します。提案された方法では、コンテキストベクトルをブーストして最も有益なフレーム..私たちの方法は、短い発話話者認識を含むさまざまな実験設定で既存の方法よりも優れており、VoxCelebデータセットの既存のベースラインに対して競争力のあるパフォーマンスを達成することを示しています。 
[概要] SAPシステムでは、コンテキストセンサーは特徴抽出器と一緒に終了するようにトレーニングされます。コンテキストプールの役割は、話者認識のために最もベースラインのフレームを選択することです。この方法は、短い発話話者を含むさまざまな実験設定で既存の方法よりも優れています。認識</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Nonparallel Voice Conversion with Augmented Classifier Star Generative
  Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.AS/paper_6.html">
      <font color="black">Nonparallel Voice Conversion with Augmented Classifier Star Generative
  Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">第三に、変換された音声信号をリアルタイムの実装を可能にするのに十分な速さで生成でき、適度にリアルな音声を生成するために数分のトレーニング例しか必要としません。この論文では、新しく導入された新しいStarGANを含むStarGANの3つの定式化について説明します。 「拡張分類器StarGAN（A-StarGAN）」と呼ばれるバリアントを、非並列VCタスクで比較します。StarGAN-VCと呼ばれるこのメソッドの主な機能は次のとおりです。まず、並列発話、文字起こし、または音声ジェネレータトレーニングのタイムアラインメント手順。 
[概要] stargan-vcと呼ばれる私たちの方法の主な機能は単純です。並列発話、翻訳、または時間調整手順は必要ありません。singlegan-非営利の方法では、数分のトレーニング例が必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Time-Frequency Scattering Accurately Models Auditory Similarities
  Between Instrumental Playing Techniques -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-11/eess.AS/paper_7.html">
      <font color="black">Time-Frequency Scattering Accurately Models Auditory Similarities
  Between Instrumental Playing Techniques</font>
    </a>
  </h2>
  <font color="black">さらに、楽器、ミュート、テクニック全体の聴覚の類似性のクラスターグラフを復元するためのマシンリスニングモデルを提案します。それらの応答を分析すると、音色の知覚は、楽器や演奏テクニックだけで提供されるものよりも柔軟な分類法の範囲内で機能することがわかります。この記事では、31人の被験者に、78個の孤立した音符を音色クラスターのセットに編成するように依頼します。 
[ABSTRACT]音色の知覚は、楽器や演奏技術だけで提供されるものよりも柔軟な分類内で機能します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-21">
        <br><font color="black">2020-07-21</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
