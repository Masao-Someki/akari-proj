<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-04-08の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: SNR-Based Features and Diverse Training Data for Robust DNN-Based Speech
  Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.SD/paper_0.html">
      SNR-Based Features and Diverse Training Data for Robust DNN-Based Speech
  Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      （2）に対処するために、Huノイズコーパス（限られたサイズ）、CHiME 3ノイズコーパス（限られた多様性）でネットワークをトレーニングし、自由に利用可能なサウンドに基づいて収集された大規模で多様なデータセットを提案します。実験結果とt分布確率的近傍埋め込み（t-SNE）を使用した分析では、入力データのサイズと多様性が制限されている場合でも、SNR-NAT機能がロバストであることを示します。（3）を比較するために、完全に接続されたフィードフォワードDNNとLong Short-term Memory（LSTM）は、LSTMが限られたトレーニングデータと単純化された機能に対して一般化することを示しています。 
[ABSTRACT]たとえば、huノイズコーパス（限られたサイズ）、chime 3ノイズコーパスでネットワークをトレーニングし、さまざまな音に基づいて大規模で多様なデータセットを提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to fool the speaker recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.SD/paper_1.html">
      Learning to fool the speaker recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      TIMITデータセットの実験は、平均SNR $ 57.2 \ text {dB} $とPESQ 4.2でリアルタイムよりもかなり速い速度で$ 99.2 \％$の文誤り率を達成できることを示しています。指紋や顔認識などの視覚ベースのシステム。話者認識システムも攻撃に対して脆弱であり、非標的型攻撃で高い成功率を達成しています。 
[ABSTRACT]生の音声波形に感知できないほどの摂動を追加してシステムをだます軽量モデル。話者認識攻撃者を最適化する効果的な方法も紹介します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: WaveTTS: Tacotron-based TTS with Joint Time-Frequency Domain Loss -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.SD/paper_2.html">
      WaveTTS: Tacotron-based TTS with Joint Time-Frequency Domain Loss
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、提案されたフレームワークがベースラインを上回り、高品質の合成音声を実現することを示しています。WaveTTSは、音響機能の品質と結果の音声波形の両方を保証します。この問題に対処するために、タコトロンベースの新しいトレーニングスキームを提案します。 WaveTTSと呼ばれるTTS。2つの損失関数があります。1）自然領域と生成された波形の間の歪みを測定する、波形損失として表される時間領域損失。 2）周波数領域の損失。自然と生成された音響特性の間のメルスケール音響特性損失を測定します。 
[要約] wavettsとして知られているタコトロンには2つの損失関数があります。これらには、時間領域損失が含まれます。これは、自然の特徴と生成された特徴の間のメルスケールの音響特徴の損失を測定します。これは、時間と周波数の結合領域を持つタコトロンの最初の実装です損失
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-02">
        <br>2020-02-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: AI4COVID-19: AI Enabled Preliminary Diagnosis for COVID-19 from Cough
  Samples via an App -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.SD/paper_3.html">
      AI4COVID-19: AI Enabled Preliminary Diagnosis for COVID-19 from Cough
  Samples via an App
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      AI4COVID-19アプリは、被験者の2秒間の咳の録音を必要とします。残念ながら、咳は、20を超えるCOVID-19に関連しない病状の一般的な症状です。このテストは、AI4COVID-19というモバイルアプリを通じて大規模に展開できます。 。 
[要約]テストは、ai4covid-19という名前のモバイルアプリを介して大規模に展開できます。アプリはクラウドで実行されているAIエンジンを使用し、アプリは1分以内に予備診断を返します。これにより、covid-19は咳だけからの診断になります。非常に困難な問題
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-02">
        <br>2020-04-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Direct Speech-to-image Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.SD/paper_4.html">
      Direct Speech-to-image Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      合成データと実際のデータの両方の実験結果は、提案された方法が生の音声信号を中央のテキスト表現のない画像に変換するのに効果的であることを示しています。アブレーション研究は、私たちの方法についてより多くの洞察を提供します。音声信号を直接画像に変換する方法と、信号をどれだけうまく変換できるかについては十分に研究されていません。 
[要約]提案された方法は、生の音声信号を中央のテキスト表現のない画像に変換するのに効果的です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Homophone-based Label Smoothing in End-to-End Automatic Speech
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.SD/paper_5.html">
      Homophone-based Label Smoothing in End-to-End Automatic Speech
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      音響モデルと言語モデルを一緒に学習するエンドツーエンドのASRモデルと文字のモデリングユニットは、この方法に必要な条件です。人間レベルの言語の事前知識を利用する新しいラベル平滑化方法、ホモフォンが提案されていますこの論文では、自動音声認識（ASR）について説明します。ハイブリッドCTCシーケンスツーシーケンスモデルを使用した実験では、新しい方法で文字エラー率（CER）を0.4％削減できることを示しています。 
[ABSTRACT]新しい方法により、文字エラー率（cer）を0.4％削減できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Universal Adversarial Perturbations Generative Network for Speaker
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.SD/paper_6.html">
      Universal Adversarial Perturbations Generative Network for Speaker
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      低次元正規分布からUAPサブスペースへのマッピングを学習する生成ネットワークを提案し、UAPを合成して入力信号を摂動させ、十分に訓練された話者認識モデルを高い確率で偽装します。ニューラルネットワークは、人間にはほとんど知覚できないままであるように意図的に動揺させられている敵対的な例に対して脆弱であることを考えると、指紋/顔/話者認識システムの幅広い展開でますます注目を集めています。TIMITの実験結果およびLibriSpeechデータセットは、モデルの有効性を示しています。 
[ABSTRACT]ハイテクデータセットはモデルの有効性を示しています。私たちは普遍的な敵対的摂動の存在を示しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.SD/paper_7.html">
      Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      我々はCycleGANネットワークを提案し、敵対的およびサイクル一貫性損失を使用してフォワードおよびインバースマッピングを同時に学習することにより、非並列トレーニングデータから最適な疑似ペアを見つけます。また、効果的なF0変換のために、F0を10の時間スケールに分解するための連続ウェーブレット変換（CWT）の使用についても検討します。 
[ABSTRACT]多くの研究では、異なる線形パターン間の並列音声データが必要です。これらの研究では、イントネーションの主要な側面であるf0が必要です。ただし、ウェーブレット変換を使用してf0をモデル化する方が適切であると考えています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-01">
        <br>2020-02-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-Scale Aggregation Using Feature Pyramid Module for
  Text-Independent Speaker Verification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.SD/paper_8.html">
      Multi-Scale Aggregation Using Feature Pyramid Module for
  Text-Independent Speaker Verification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      特徴抽出のさまざまなレイヤーのマルチスケール特徴を利用するマルチスケール集約（MSA）が最近アプローチに導入され、短い発話と長い発話の両方でパフォーマンスが向上することが示されています。VoxCelebデータセットの実験では、提案されたモジュールは、少数のパラメーターで以前のMSAメソッドを改善し、最先端のアプローチよりも優れたパフォーマンスを提供します。さまざまな解像度で豊富なスピーカー情報を含む拡張機能を使用して、スピーカーの埋め込みを抽出します。 
[要旨]スピーカーの埋め込みは、機能抽出の最後のレイヤーから抽出されます。msaはスピーカーをブーストします-トップダウン経路と横方向の接続を介して機能の短い情報
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Non-parallel Voice Conversion System with WaveNet Vocoder and Collapsed
  Speech Suppression -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.SD/paper_9.html">
      Non-parallel Voice Conversion System with WaveNet Vocoder and Collapsed
  Speech Suppression
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、LPCDCによって引き起こされる悪影響を緩和するために、LPCDCが問題のあるセグメントにのみ適用され、品質の損失を短期間に制限することを保証するために、折りたたみ音声セグメント検出器（CSSD）を提案します。問題に取り組むために、従来のボコーダーで生成された音声を参照音声として使用して、線形予測符号化分布制約（LPCDC）を導出し、音声の折りたたみの問題を回避します。しかし、WNボコーダーをVCシステムと組み合わせると、歪んだ音響特性、音響および時間の不一致、および露出の偏りは通常、音声品質の大幅な低下につながり、WNは折りたたまれた音声と呼ばれる非常にノイズの多い音声セグメントを生成します。 
[ABSTRACT] wnは、忠実度の高い音声波形を作成するためのボコーダーです。これにより、折りたたみ音声の問題を含む折りたたみ音声システムが作成されます。提案された方法は、以前の非平行制限の音声品質をさらに改善します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-26">
        <br>2020-03-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: iMetricGAN: Intelligibility Enhancement for Speech-in-Noise using
  Generative Adversarial Network-based Metric Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.SD/paper_10.html">
      iMetricGAN: Intelligibility Enhancement for Speech-in-Noise using
  Generative Adversarial Network-based Metric Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、正式なリスニングテストでは、ノイズと残響の両方が存在する場合に明瞭度が大幅に向上することがわかります。具体的には、iMetricGANアプローチを使用して、生成的敵対ネットワーク（GAN）で音声明瞭度メトリックを最適化します。実験結果は、提案されたiMetricGANが従来の状態よりも優れていることを示しています。客観的尺度、つまりカフェテリアノイズ条件下でのビット単位の音声明瞭度（SIIB）と拡張短時間客観的明瞭度（ESTOI）に関する最新のアルゴリズム。 
[要約]提案された了解度法は、音声の損失を補償するように設計されています。これは、修正の前後に音声信号の二乗平均平方根（rms）レベルと持続時間が維持されるためです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-02">
        <br>2020-04-02
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Neutralizing Gender Bias in Word Embedding with Latent Disentanglement
  and Counterfactual Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_0.html">
      Neutralizing Gender Bias in Word Embedding with Latent Disentanglement
  and Counterfactual Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      感情分析..実験結果は、量的および質的に、導入された方法が単語の埋め込みのバイアスを解除し、NLPダウンストリームタスクのセマンティック情報の損失を最小限に抑えるのに優れていることを示しています。その後、単語の性別情報を変更するためのCounterfactual Generationモデルを導入します。そのため、元の埋め込みと変更された埋め込みは、幾何学的配置の後に、意味情報を失うことなく、性別を排除した単語の埋め込みを生成できます。 
[ABSTRACT]システムは、単語の偏見を排除するのに優れており、nlpダウンストリームタスクの意味情報の損失
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Inferential Text Generation with Multiple Knowledge Sources and
  Meta-Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_1.html">
      Inferential Text Generation with Multiple Knowledge Sources and
  Meta-Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、メタ学習ベースのマルチタスク学習アルゴリズムを導入します。対象となる常識関係ごとに、他の関係からの例の学習をメタトレーニングプロセスと見なし、対象とする関係からの例の評価をメタテストプロセス。Event2MindおよびATOMICデータセットで実験を行います。 
[ABSTRACT]既存のアプローチは通常、トレーニング例からの限られた証拠を使用し、各関係について個別に学習します。複数の知識ソースの統合とメタ学習アルゴリズムの使用により、パフォーマンスが向上します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Fine-Grained Named Entity Typing over Distantly Supervised Data Based on
  Refined Representations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_2.html">
      Fine-Grained Named Entity Typing over Distantly Supervised Data Based on
  Refined Representations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは、文の境界を越えて情報が渡されるのを妨げるため、非常に重なってノイズの多いタイプラベルには不適切です。実験的評価では、マクロf1とマイクロf1の相対スコアがそれぞれ最大10.2％と8.3％で、提案されたモデルが既存の研究を上回っています。 。ノイズの多いラベルを軽減するために、FGNETの既存のアプローチは、エンティティの言及を互いに完全に独立して分析し、言及文固有のコンテキストのみに基づいてタイプラベルを割り当てます。 
[ABSTRACT]オンザフライの新しいアプローチは、エンティティの言及を互いに完全に独立して分析し、言及文（特定のコンテキスト）のみに基づいてタイプラベルを割り当てます。このため、参加することにより、ノイズの多い言及表現を洗練するエッジ加重注意深いグラフ畳み込みネットワークを提案しますコーパス上-分類が終了する前のレベルの文脈的手がかり
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Interview: A Large-Scale Open-Source Corpus of Media Dialog -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_3.html">
      Interview: A Large-Scale Open-Source Corpus of Media Dialog
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      会話型データの既存の大規模なプロキシと比較して、データセットでトレーニングされた言語モデルは、既存の音声ダイアログデータセットでのゼロショットドメイン外パフォーマンスを示し、実際の会話のモデリングにおけるその有用性を示しています。 2つのダイアログタスクは、このようなラベルを活用することで、話者に依存しない強力なベースラインよりもパフォーマンスが向上し、インタビュースタイルの会話でより具体的で探究的な応答を生成できるようにすることを示しています。既存の会話データセットは、ダイアログ用の書かれたプロキシまたは小規模な書き起こしのいずれかで構成されています自然なスピーチ。 
[ABSTRACT] `インタビュー &#39;には、各ターンのスピーカーロールアノテーションが含まれ、魅力的で応答性の高い対話システムの開発を可能にします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Neural Machine Translation with Indirect Supervision -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_4.html">
      Unsupervised Neural Machine Translation with Indirect Supervision
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      より具体的には、教師なし言語ペア\ texttt {En-De}の場合、並列データセット\ texttt {En-Fr}からの情報を最大限に活用して、1つのモデルですべて教師なし翻訳方向を共同でトレーニングできます。\メソッドは標準の教師なしNMTへの変更を必要としない多言語モデルについて。この作業では、多言語の教師なしNMT（\ method）フレームワークを導入して、リソースの高い言語ペアからリソースがゼロの翻訳方向への、教師の弱い信号を活用します。 
[要約]教師なしのニューラルマシンスコアは教師なしの「unmt」に基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Corpus Study and Annotation Schema for Named Entity Recognition and
  Relation Extraction of Business Products -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_5.html">
      A Corpus Study and Annotation Schema for Named Entity Recognition and
  Relation Extraction of Business Products
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、進行中の注釈の取り組みについて説明し、提案されたガイドラインに従って注釈が付けられた英語のWebおよびソーシャルメディアドキュメントの予備的なコーパスを提示します。この作業では、製品の注釈のためのコーパス調査、注釈スキーマおよび関連するガイドラインを提示します。エンティティと会社と製品の関係の言及。製品の言及は名詞句として実現されることが多いですが、境界の曖昧性が高く、表面の実現の幅広い構文的および意味的多様性のため、正確な範囲の定義は困難です。 
[ABSTRACT]このドメインには、注釈付きコーパスと注釈ガイドラインの決定的な欠如があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On the Role of Conceptualization in Commonsense Knowledge Graph
  Construction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_6.html">
      On the Role of Conceptualization in Commonsense Knowledge Graph
  Construction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験は、私たちの方法がもっともらしいトリプルを効果的に特定し、新しいノードと、多様性と新規性の高いエッジの両方のトリプルによってKGを拡張できることを示しています。ノード間のKGに存在しない関係を特定することに加えて、このような方法は、さまざまな実世界の物、またはエンティティが表示される可能性のあるテキスト。概念化によって合成トリプルを構築し、さらに、事前学習済み言語モデルから転送された知識を備えた識別モデルによって処理され、微調整されたタスクをトリプル分類として定式化します。負のサンプリング。 
[ABSTRACT]これらのメソッドは、テキストで表される存在しないノードを探索することも期待されます。これらには、さまざまな実世界の物やエンティティを探索する方法を見つけることが含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-06">
        <br>2020-03-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Automated Utterance Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_7.html">
      Automated Utterance Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、1）抽出要約を使用して説明から重要な文を抽出し、2）複数の言い換え技法を使用して、タイトルと要約文の多様な言い換えのセットを生成し、3）適切な候補を選択する発話生成システムを提案します。新しい候補選択アルゴリズムの助けを借りて言い換えると、質問応答の機能として関連する発話を使用すると、会話アシスタントが正しい答えを取得する精度と再現率の両方が向上することが示されています。したがって、発話の生成は重要な問題になっています。タイトルと説明で構成されるナレッジベース記事から関連する発話（文またはフレーズ）を生成することを目的としています。 
[ABSTRACT]英国では1,000人を超える人々が一連の誤認的な言葉で診断されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: WaveTTS: Tacotron-based TTS with Joint Time-Frequency Domain Loss -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_8.html">
      WaveTTS: Tacotron-based TTS with Joint Time-Frequency Domain Loss
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、提案されたフレームワークがベースラインを上回り、高品質の合成音声を実現することを示しています。WaveTTSは、音響機能の品質と結果の音声波形の両方を保証します。この問題に対処するために、タコトロンベースの新しいトレーニングスキームを提案します。 WaveTTSと呼ばれるTTS。2つの損失関数があります。1）自然領域と生成された波形の間の歪みを測定する、波形損失として表される時間領域損失。 2）周波数領域の損失。自然と生成された音響特性の間のメルスケール音響特性損失を測定します。 
[要約] wavettsとして知られているタコトロンには2つの損失関数があります。これらには、時間領域損失が含まれます。これは、自然の特徴と生成された特徴の間のメルスケールの音響特徴の損失を測定します。これは、時間と周波数の結合領域を持つタコトロンの最初の実装です損失
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-02">
        <br>2020-02-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Efficient Context and Schema Fusion Networks for Multi-Domain Dialogue
  State Tracking -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_9.html">
      Efficient Context and Schema Fusion Networks for Multi-Domain Dialogue
  State Tracking
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      対話コンテキストを効率的にエンコードするために、以前の対話状態（予測）と現在のダイアログ発話をDSTの入力として利用することを提案します。内部および外部の注意メカニズムを使用したグラフ。実験結果は、私たちのアプローチがMultiWOZ 2.0とMultiWOZ 2.1の両方のベンチマークでオープンボキャブラリDSTの新しい最先端のパフォーマンスを獲得できることを示しています。 
[ABSTRACT]データのスパース性の問題は、状態候補の数が増加し、ダイアログの長さが異なるため、主要な障害です。異なるドメイン間のダイアログが利用されます-スロット。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Is Graph Structure Necessary for Multi-hop Reasoning? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_10.html">
      Is Graph Structure Necessary for Multi-hop Reasoning?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最先端の公開モデルである動的融合グラフネットワーク（DFGN）をベースラインとして使用します。事前にトレーニングされたモデルを適切に使用すれば、グラフ構造はマルチホップの推論..事前トレーニング済みモデルを直接変更することにより、ベースラインモデルは大幅に改善され、公開済みおよび未公開の両方の作品を大幅に上回ります。 
[要旨]私たちの分析はhotpotqaに集中しています。 hotpotqaを使用します。ネットワークはhotpotqaに基づいています。 hotpotqaに基づいています。グラフ構造とそれを含むネットワークは、タスクに関連する事前知識です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A German Corpus for Fine-Grained Named Entity Recognition and Relation
  Extraction of Traffic and Industry Events -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_11.html">
      A German Corpus for Fine-Grained Named Entity Recognition and Relation
  Extraction of Traffic and Industry Events
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、事故、交通渋滞、買収、ストライキなど、15の交通関連および業界関連のn項関係とイベントの注釈が付けられています。これにより、両方の名前付きエンティティ認識アルゴリズムをトレーニングおよび評価できます。ジオエンティティのきめの細かい入力と、n項関係抽出システム。コーパスは、ニュースワイヤのテキスト、Twitterメッセージ、およびラジオ局、警察、鉄道会社からの交通情報で構成されます。 
[ABSTRACT]ドイツ語のドキュメントのコーパスに注釈が付けられました。ストリート、ストップ、ルートなどのきめ細かな地理エンティティが含まれています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: MedDialog: A Large-scale Medical Dialogue Dataset -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_12.html">
      MedDialog: A Large-scale Medical Dialogue Dataset
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      知る限りでは、MedDialogはこれまでで最大の医療対話データセットです。医療対話システムは、遠隔医療を支援して医療サービスへのアクセスを増やし、患者のケアの質を向上させ、医療費を削減することを約束しています。 https://github.com/UCSD-AI4H/Medical-Dialogue-System 
[ABSTRACT]データセットには、患者と医師間の100万の会話と400万の発話が含まれています。データセットはwwwで入手できます。 github。 com
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Few Topical Tweets are Enough for Effective User-Level Stance
  Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_13.html">
      A Few Topical Tweets are Enough for Effective User-Level Stance
  Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2番目のアプローチでは、Twitterタイムラインのツイートを使用して特定のユーザーのツイートを拡張し、その後、ユーザーの教師なし分類を実行します。これにより、トレーニングセット内のユーザーを他のユーザーとクラスター化します。最初のアプローチでは、コンテキスト内の単語の潜在的な意味をキャプチャする、文脈化された埋め込みを使用してツイートを表現することによるユーザーレベルのスタンス検出。監視されていない分類を使用する最近の研究では、ターゲットに多くのツイートを持っている音声Twitterユーザーに対してスタンス検出を実行すると、高精度（+ 98％）。 
[ABSTRACT]このペーパーでは、2つのアプローチを使用して、このようなユーザーのタックルスタンスの検出に取り組みます。このアプローチでは、targetなど、89。6％の精度と91. 3％のマクロfを達成します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Homophone-based Label Smoothing in End-to-End Automatic Speech
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_14.html">
      Homophone-based Label Smoothing in End-to-End Automatic Speech
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      音響モデルと言語モデルを一緒に学習するエンドツーエンドのASRモデルと文字のモデリングユニットは、この方法の必要条件です。人間レベルの言語の事前知識を利用する新しいラベル平滑化方法、ホモフォンが提案されています。この論文では、自動音声認識（ASR）について説明します。提案手法は、その前身と比較して、同音異義語の発音知識をより複雑な方法で使用します。 
[ABSTRACT]新しい方法により、文字エラー率（cer）を0.4％削減できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Data Manipulation: Towards Effective Instance Learning for Neural
  Dialogue Generation via Learning to Augment and Reweight -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_15.html">
      Data Manipulation: Towards Effective Instance Learning for Neural
  Dialogue Generation via Learning to Augment and Reweight
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、効果的な学習サンプルを拡張および強調表示し、非効率的なサンプルの効果を同時に減らすことで、信頼性のあるサンプルに向けてデータ分布を積極的に再形成するデータ操作フレームワークを提案します。特に、データ操作モデルは、トレーニングサンプルを選択的に増強します。トレーニングデータを再構成するために、各インスタンスに重要度の重みを割り当てます。したがって、効果的な対話学習には、より信頼性の高い学習サンプルだけでなく、ノイズの多いサンプルも必要です。 
[ABSTRACT]提案されたデータ操作フレームワークは、信頼性の高いサンプルに向けてデータ分布を積極的に再形成できます。これにより、これらのデータの学習を妨げる神経対話モデル
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Sentence Cloze Dataset for Chinese Machine Reading Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_16.html">
      A Sentence Cloze Dataset for Chinese Machine Reading Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたデータセットには、中国のナラティブストーリーに由来する1万以上のパッセージ内に10万以上の空白（質問）が含まれています。中国のNLPコミュニティによる継続的な貢献により、ますます多くの中国の機械読解データセットが利用可能になり、中国のMRC研究を前進させます。データセットを評価するために、事前トレーニング済みのモデルに基づいていくつかのベースラインシステムを実装しました。結果は、最先端のモデルが人間のパフォーマンスを大幅に下回っていることを示しています。 
[要約]この論文では、新しい文のクローズスタイルの機械読解（sc-mrc）を提案します。このタスクは、さらに困難を加えることを目的としています。また、正しいものに類似した偽の候補を作成しました。データセット、いくつかのベースラインシステムを実装しています事前トレーニング済みのモデルに基づいています。最新のモデルは、人間のパフォーマンスを大幅に下回っています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_17.html">
      Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CycleGANネットワークを提案し、敵対的損失とサイクル整合性損失を使用してフォワードマッピングとインバースマッピングを同時に学習することにより、非並列トレーニングデータから最適な疑似ペアを見つけます。効果的なF0変換のための、異なる時間解像度での音声韻律を表す時間スケール。感情的な音声変換は、話者のアイデンティティと言語的内容を維持しながら、スペクトルと韻律を変換して音声の感情パターンを変更することを目的としています。 
[ABSTRACT]多くの研究では、異なる線形パターン間の並列音声データが必要です。これらの研究では、イントネーションの主要な側面であるf0が必要です。ただし、ウェーブレット変換を使用してf0をモデル化する方が適切であると考えています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-01">
        <br>2020-02-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Entity Linking via Dual and Cross-Attention Encoders -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_18.html">
      Entity Linking via Dual and Cross-Attention Encoders
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、ターゲット言及と候補エンティティのそれぞれに対してクロスアテンションエンコーダーを使用して、エンティティを再ランク付けします。一方、デュアルエンコーダーアプローチでは、すべての情報が、言及とエンティティーを表すために使用されるベクトル次元の小さな固定セットに含まれます、クロスアテンションモデルでは、それぞれの全体から詳細情報（読み取り：機能）を使用できます。 <mention, context, candidate entity> tuple ..エンティティリンクには2つの主要な研究領域があります。1）エイリアステーブルを使用せずに候補エンティティを生成し、2）メンションとエンティティの両方のコンテキスト表現を生成します。 
[要約]同じ空間での言及とエンティティ表現を学習するための新しいシステムが開発されています。システムは、ターゲット言及と各候補情報に対してクロスアテンションエンコーダを使用します。次に、クロスアテンションを使用してエンティティを再ランク付けしますエンコーダー
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improved Code Summarization via a Graph Neural Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_19.html">
      Improved Code Summarization via a Graph Neural Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      構造情報を使用する最初のアプローチは、ASTをシーケンスにフラット化しました。最近、ランダムASTパスまたはグラフニューラルネットワークに基づくより複雑なアプローチが、フラット化されたASTを使用するモデルで改善されました。一般に、ソースコードの要約手法ではソースコード入力として、自然言語の説明を出力します。 
[要約]自動コード要約は急速に拡大している研究分野ですが、構造情報を入力として使用するとパフォーマンスが向上するという強いコンセンサスが生まれています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Operationalizing the legal concept of 'Incitement to Hatred' as an NLP
  task -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_20.html">
      Operationalizing the legal concept of 'Incitement to Hatred' as an NLP
  task
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーでは、ドイツ刑法の{\ S} 130にある「憎しみへの扇動」という犯罪と、根底にあるEU理事会フレームワーク決定に基づいて、これらの質問を追求します。「憎しみへの扇動」の法的概念この問題は、ターゲットグループに対する差別と隔離を防ぎ、それによってメンバーが社会で同等に受け入れられることを保証することにより、同様に民主主義の前提条件となります。このように、最終的には、根本的な価値に基づく決定の範囲も調査します。 NLPに引き継ぐことができます。 
[要旨]ソーシャルメディアプロバイダーは、この違反に違反する投稿を削除する直接の義務の対象となります。ドイツのネットワーク施行法に基づき、ソーシャルメディアプロバイダーは、この違反に違反する投稿を削除する義務の対象となります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Machine Translation with Unsupervised Length-Constraints -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_21.html">
      Machine Translation with Unsupervised Length-Constraints
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、これらの1つである制約翻訳の生成について説明します。このアイデアをゼロショット多言語機械翻訳と組み合わせることで、教師なし単言語文圧縮も実行できます。長さ制約を満たすために、制約をモデルに統合するいくつかの方法を調査しました。 
[ABSTRACT]エンコーダー-デコーダーアーキテクチャにより、さらに多くの可能性が可能になります。長さの制約を満たすために、制約をモデルに統合するいくつかの方法を調査しました。さらに、教師なし単一言語の文の圧縮を実行できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Inexpensive Domain Adaptation of Pretrained Language Models: A Case
  Study on Biomedical Named Entity Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_22.html">
      Inexpensive Domain Adaptation of Pretrained Language Models: A Case
  Study on Biomedical Named Entity Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ここでは、より安価な代替案を提案します。ドメイン内テキストでWord2Vecをトレーニングし、結果の単語ベクトルを一般ドメインPTLM（ここではBERT）の入力スペースに揃えます。通常、事前トレーニング済み言語モデル（PTLM）のドメイン適応はドメイン内のテキストを事前トレーニングすることで達成されます。このアプローチは成功しますが、ハードウェア、ランタイム、CO_2排出量の点でコストがかかります。 
[ABSTRACT]目的地に加えて、8つの「ner」タスクを評価しています。最近提案されたbiobertモデルと比較します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exemplar Auditing for Multi-Label Biomedical Text Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_23.html">
      Exemplar Auditing for Multi-Label Biomedical Text Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの課題は、特徴空間が非常に高次元であり、多くの場合、かなりの量のノイズが含まれるテキストなどのモダリティに対して複合されます。この作業では、最近提案されたゼロショットシーケンスラベリング手法「利用可能なドキュメントレベルの人間のラベル自体が比較的高次元である場合への畳み込み分解」。このアプローチは、「内省」による分類をもたらし、推論時間予測の細粒度の特徴を、モデルの下のトレーニングセット。 
[ABSTRACT]アプローチは効果的ですが、電子カルテデータの分析で示されているように節約できます。予測とデータセットの分析を整理するためのツールとして役立ちます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Knowledge Fusion and Semantic Knowledge Ranking for Open Domain Question
  Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_24.html">
      Knowledge Fusion and Semantic Knowledge Ranking for Open Domain Question
  Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      OpenBookQAとQASCの両方のデータセットで、意味論的に再ランク付けされた知識を備えた知識融合モデルは、以前の試みよりも優れています。OpenDomain Question Answeringは、外部知識を取得し、複数の文に広がる知識を構成することによってマルチホップ推論を実行するシステムを必要とします。 、我々は、Luceneベースの情報検索システムを通じて検索された知識を再ランク付けするための意味的知識ランク付けモデルを学習します。 
[ABSTRACT] open domain質問回答回答回答チャレンジデータセット、qascおよびopenbookqa。質問に正しく回答するには、ファクトの検索を実行し、ファクトを作成する必要があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: RYANSQL: Recursively Applying Sketch-based Slot Fillings for Complex
  Text-to-SQL in Cross-Domain Databases -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_25.html">
      RYANSQL: Recursively Applying Sketch-based Slot Fillings for Complex
  Text-to-SQL in Cross-Domain Databases
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、生成パフォーマンスをさらに改善するために2つの入力操作メソッドが提示されています。テキストからSQLは、質問とデータベースが指定されたときに、ユーザーの質問をSQLクエリに変換する問題です。ステートメントポジションコード（SPC）ネストされたSQLクエリをネストされていないSELECTステートメントのセットに変換するように定義されています。対応するSPCの各SELECTステートメントを合成するために、スケッチベースのスロット充填アプローチが提案されています。 
[要約]このホワイトペーパーでは、複雑なテキストを解決するために設計されたryansql.itと呼ばれるニューラルネットワークアプローチを紹介します。spc.synthizingスケッチのネストされたタスクに対して、スロットパフォーマンスをさらに改善するために提示されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multilingual enrichment of disease biomedical ontologies -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_26.html">
      Multilingual enrichment of disease biomedical ontologies
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      カバー範囲と品質の2つの側面に焦点を当てています。9つのヨーロッパ言語（チェコ語、オランダ語、英語、フランス語、ドイツ語、イタリア語、ポーランド語、ポルトガル語、スペイン語）のWikidataに関して、疾患に焦点を当てた2つの生物医学オントロジーのカバー範囲を調べます。両方のオントロジーに加えて、2番目のオントロジーにはアラビア語、中国語、ロシア語を使用します。次に、Wikidataのおかげで得られた翻訳の品質を、商用の機械翻訳ツール（ここではGoogle Cloud Translation）と比較します。 
[要旨]オープンソースのナレッジベースを使用してオントロジーを翻訳する可能性を検討します。ウィキデータのおかげで、得られた翻訳の品質を比較します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: g2pM: A Neural Grapheme-to-Phoneme Conversion Package for
  MandarinChinese Based on a New Open Benchmark Dataset -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_27.html">
      g2pM: A Neural Grapheme-to-Phoneme Conversion Package for
  MandarinChinese Based on a New Open Benchmark Dataset
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらに動機付けされて、この作業では、中国語の多音多義性解消のための99,000以上の文で構成される新しいベンチマークデータセットを紹介します。最後に、プロジェクトをパッケージ化してPyPiで共有します。現在までの公正な比較のための標準的なベンチマークとして役立つオープンなデータセットはありません。 
[要約]報告されたシステムのほとんどは、中国語のテキストを中国語に変換したい研究者や実務家に採用するのが難しい
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Negative Training for Neural Dialogue Response Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_28.html">
      Negative Training for Neural Dialogue Response Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      トレーニングされたモデルが与えられると、フレームワークは最初に望ましくない動作を示す生成されたサンプルを見つけ、次にそれらを使用してモデルを微調整するための負のトレーニング信号を送ります。私たちの実験は、負のトレーニングが悪意のある応答のヒット率を大幅に減らすことができることを示しています、または頻繁な応答を抑制し、応答の多様性を改善します。この作業では、このような行動を最小限に抑えるための「ネガティブトレーニング」という名前のフレームワークを提案します。 
[ABSTRACT]科学者は、否定的なトレーニングが悪意のある応答のヒット率を大幅に低下させる可能性があることを示しています。これらには、応答の多様性を改善するための推奨応答の奨励が含まれます。結果は実験で明らかになりました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-03-06">
        <br>2019-03-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Establishing Strong Baselines for the New Decade: Sequence Tagging,
  Syntactic and Semantic Parsing with BERT -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_29.html">
      Establishing Strong Baselines for the New Decade: Sequence Tagging,
  Syntactic and Semantic Parsing with BERT
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、BERT埋め込みの影響に関する詳細な分析は、自己注意を使用して提供されます。これは、このリッチでありながら表現を理解するのに役立ちます。BERTモデルは、以前の最高パフォーマンスモデルよりも平均2.5％優れています（最も重要なケース）。すべてのモデルとソースコードは公開されており、研究者はそれらを改善して活用し、次の10年間の強力なベースラインを確立できます。 
[ABSTRACT]新しい研究は、まず現在の状態を複製して単純化することを示しています-モデルの効率を高めるための最先端のアプローチ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-14">
        <br>2019-08-14
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Information-Theoretic Probing for Linguistic Structure -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_30.html">
      Information-Theoretic Probing for Linguistic Structure
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの論文の経験的部分は、BERTが構文解析の研究でしばしば過小評価されている5つの類型学的に多様な言語と英語の合計6つの言語のセットで品詞についてどのくらいの情報を知っているかについての厳密な推定を得ることに焦点を当てています。 、研究者は、表現がタスクに関連する知識をエンコードしていると結論を下す可能性があります。論理は、そのようなモデルは言語構造を識別しますが、タスク自体は学習しないということです。 
[ABSTRACT]プローブがうまくいく場合、研究者は表現がタスクに関連する知識をエンコードしていると結論付けることができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-Scale Aggregation Using Feature Pyramid Module for
  Text-Independent Speaker Verification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_31.html">
      Multi-Scale Aggregation Using Feature Pyramid Module for
  Text-Independent Speaker Verification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      特徴抽出のさまざまなレイヤーのマルチスケール特徴を利用するマルチスケール集約（MSA）が最近アプローチに導入され、短い発話と長い発話の両方でパフォーマンスが向上することが示されています。拡張機能を使用してスピーカーの埋め込みを抽出します。このペーパーでは、フィーチャーピラミッドモジュールを使用してMSAを改善します。フィーチャーピラミッドモジュールは、トップダウンパスウェイとラテラル接続を介して、複数のレイヤーでのフィーチャーのスピーカー識別情報を強化します。 
[要旨]スピーカーの埋め込みは、機能抽出の最後のレイヤーから抽出されます。msaはスピーカーをブーストします-トップダウン経路と横方向の接続を介して機能の短い情報
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transformers to Learn Hierarchical Contexts in Multiparty Dialogue for
  Span-based Question Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_32.html">
      Transformers to Learn Hierarchical Contexts in Multiparty Dialogue for
  Span-based Question Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのアプローチはFriendsQAデータセットで評価され、2つの最先端のトランスフォーマーモデルであるBERTとRoBERTaに対してそれぞれ3.8％と1.4％の改善を示しています。最初に、3つの言語モデリングタスクを使用して、トランスフォーマー、トークンおよび発話レベルの言語モデリングおよび発話順序予測。これは、対話コンテキストでの理解を深めるためにトークンと発話の埋め込みの両方を学習します。次に、発話予測とトークンスパン予測の間のマルチタスク学習が、スパンベースの質問応答（QA）を調整します。 
[ABSTRACT] 3つの言語モデリングタスクを使用して、トランスフォーマー、トークンレベルおよび発話レベルの言語モデリングと発話順序予測を事前トレーニングします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: More Data, More Relations, More Context and More Openness: A Review and
  Outlook for Relation Extraction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_33.html">
      More Data, More Relations, More Context and More Openness: A Review and
  Outlook for Relation Extraction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、既存のREメソッドを振り返り、現在直面している主要な課題を分析し、より強力なREへの有望な方向を示します。初期のパターンマッチングから現在のニューラルネットワークまで、既存のREメソッドは大きな進歩を遂げています。私たちの見解は、この分野を前進させ、コミュニティでより多くの努力を刺激することができます。 
[ABSTRACT]人々は関係の知識に取り組み、テキストからこれらの事実を抽出しています。reからの `more &#39;が必要です。より複雑なコンテキストを簡単に処理でき、よりオープンなドメインに柔軟に一般化できるより強力なシステムです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Emergent Language Generalization and Acquisition Speed are not tied to
  Compositionality -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_34.html">
      Emergent Language Generalization and Acquisition Speed are not tied to
  Compositionality
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      神経エージェントが共同タスクを解決するために通信するときに出現する個別の言語の研究は、組成構造の証拠を探すことがよくあります。この分野のさらなる研究は、組成からどのような利点が期待され、後者がどのようにそれらにつながるかについてより明確になるはずです。これらの有益な特性は、構成性に大まかにのみ関連していると主張します。 
[ABSTRACT]調査によると、非構成言語は、一般化パフォーマンスと取得速度が同等またはそれ以上である可能性があります。これは、このような構造により、エージェントが言語をより速く取得できると予想されるためです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature
  and PRESupposition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_35.html">
      Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature
  and PRESupposition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      BOWとInferSentは、実用的な推論の弱い証拠を示しています。MultiNLIには、これらの推論タイプを示すペアがほとんど含まれていませんが、BERTは実用的な推論を描くことを学習していることがわかります。 PRESupposition診断データセット（IMPPRES）。よく研究された実用的な推論タイプを示す32Kの半自動生成された文のペアで構成されます。 
[ABSTRACT] nliモデルが自然な情報を作成する能力はまだ十分に研究されていません。nliトレーニングはモデルの一部だけを学習することを奨励すると結論付けています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Class-Agnostic Continual Learning of Alternating Languages and Domains -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_36.html">
      Class-Agnostic Continual Learning of Alternating Languages and Domains
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、興味深い特性を表示しながらこの問題を強力に実行する簡単なProduct of Experts学習システムを紹介し、忘却を回避するためのそのメリットを調査します。継続学習は、一連のタスクでモデルをトレーニングする問題としてしばしば組み立てられます。これに関して、ニューラルネットワークは、新しいニューラルネットワークを学習するときに、前のタスクのソリューションを忘れることが証明されています。 
[ABSTRACT]ベンチマークは、多言語およびマルチドメイン設定の言語モデルに基づいています。トレーニングの例を明確に区切って、個別のタスクにまとめます。継続的な学習と壊滅的な忘却を研究するための指標を提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Reinforced Multi-task Approach for Multi-hop Question Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_37.html">
      Reinforced Multi-task Approach for Multi-hop Question Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      マルチホップ質問応答データセットHotPotQAの実験を通じて、アプローチの有効性を実証します。質問認識をサポートするために、回答認識型のサポート事実予測の補助タスクを備えたマルチタスク学習を採用します。さらに、補強学習（RL）フレームワークの質問対応の報酬機能。サポートする事実を最大限に活用します。 
[ABSTRACT]コンテキスト内のサポートする事実に基づいて関連する質問を生成することを目的としたマルチホップの質問の生成が必要です。また、サポートする事実の使用を最大化するための質問対応報酬関数（rl）を提案しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-05">
        <br>2020-04-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Image Inpainting Guided with Descriptive Text -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_38.html">
      Neural Image Inpainting Guided with Descriptive Text
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、提案されたNIGDTモデルが、量的比較と質的比較の両方ですべての比較モデルよりも優れていることを示しています。システムとコードは間もなくリリースされます。次に、画像とテキストのマッチングロスは、説明テキストに従ってモデル出力を強制するように設計されています。 
[ABSTRACT]最近の作品のほとんどは、視覚情報に応じた画像の修復に主に焦点を当てていますが、人間の言語に含まれる意味情報は無視しています。ユーザーがガイドする修復に柔軟な方法を提供するガイダンステキストと一致する画像を作成するには、キャプション付きの2つのオープンデータセットに対して実施
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Self-Induced Curriculum Learning in Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_39.html">
      Self-Induced Curriculum Learning in Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人間のガニングフォグ読みやすさ指数（GF）に関して、SS-NMTは、高校（GF = 10--11）に適したウィキペディアのデータから抽出および学習することから始まり、1年生の大学生に適したコンテンツにすばやく移動することを示します学生（GF = 13）。両方のシステム内部表現タイプの相互監視のダイナミクスが、抽出、したがって翻訳パフォーマンスに不可欠であることを観察します。この研究では、サンプリングの選択の詳細な分析を提供します。 SS-NMTモデルはトレーニング中に取得します。 
[ABSTRACT]モデルは高校に適したウィキペディアのデータから学習します。また、1年生に適したウィキペディアの情報から抽出して学習します。モデルは、タスクの増加のサンプルを選択します-ノイズ除去カリキュラムではなく関連性
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Knowledge Guided Named Entity Recognition for BioMedical Text -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_40.html">
      Knowledge Guided Named Entity Recognition for BioMedical Text
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このナレッジガイド付きNER（KGNER）配合の広範な実験を18の生物医学NERデータセットで実行し、これらの実験を通して、知識が役立つことに注意します。問題の配合では、16種類の最先端の結果を達成できます。 18データセット..この定式化は、（a）システムがさまざまなNERデータセットから共同で学習できるようにし、システムがより多くのNER固有の機能を学習できるようにします。（b）知識テキスト注意を使用して、提供された知識との類似性が高い単語を識別し、パフォーマンスを向上させます。 （c）予測されるクラスをB、I、Oのみに減らすことでシステムの混乱を減らし、（d）ネストされたエンティティの検出を容易にします。 
[ABSTRACT]問題のタスクタスクは18データセットのうち16データセットで知識を達成できます。また、より具体的な機能を学習できます。また、ナレッジ-テキストアテンションを使用して、提供されたナレッジとの類似性が高い単語を特定し、パフォーマンスを向上できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br>2019-11-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Appraisal Theories for Emotion Classification in Text -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_41.html">
      Appraisal Theories for Emotion Classification in Text
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの結果は、イベントの説明における高品質の評価次元の割り当てが、個別の感情カテゴリの分類の改善につながることを示しています。自動感情カテゴリ化は、主に、事前定義されたインベントリからの感情にテキスト単位が割り当てられるテキスト分類として定式化されています。 Paul Ekman（恐怖、喜び、怒り、嫌悪感、悲しみ、驚き）またはRobert Plutchik（信頼、期待を追加）によって提案された基本的な感情クラスに従うインスタンス。この論文では、理論に従って、イベントのそのような解釈を明確にすることを提案します。イベントの認知的評価の結果、分類モデルでエンコードされたときに感情分類の可能性を示します。 
[ABSTRACT]これらのイベントの解釈は、paul ek ek ekによって提案されています。これらはイベントの評価理論に基づいており、感情分類の可能性を示しています。悲しみの理論に従って、これらの解釈は嫌悪感を持って行う必要があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br>2020-03-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: How Additional Knowledge can Improve Natural Language Commonsense
  Question Answering? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_42.html">
      How Additional Knowledge can Improve Natural Language Commonsense
  Question Answering?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業での目標は、追加（常識）の知識を言語モデルベースのアプローチに組み込んで、そのようなドメインでの質問応答を改善する方法を開発することです。予測を分析して、さらなる改善の範囲を調査します。次に、3つの異なる方法を調査します。知識取り込みの戦略と、外部の常識知識を使用した質問応答の4つの異なるモデル。 
[ABSTRACT]最近の言語モデルはwikipediaに事前に組み込まれています。この作業では、最初に外部の知識ソースを分類し、そのようなソースを使用するとパフォーマンスが向上することを示します。予測を分析して、さらなる改善の範囲を調査します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-19">
        <br>2019-09-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: KorNLI and KorSTS: New Benchmark Datasets for Korean Natural Language
  Understanding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_43.html">
      KorNLI and KorSTS: New Benchmark Datasets for Korean Natural Language
  Understanding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      自然言語推論（NLI）と意味テキストの類似性（STS）は、自然言語理解（NLU）の主要なタスクです。韓国語NLUの研究を加速するために、KorNLIとKorSTSのベースラインも確立します。以前のアプローチに従って、機械翻訳を行います既存の英語トレーニングセット、および開発セットとテストセットを韓国語に手動で翻訳します。 
[要約]ベンチマークデータセットは英語と他のいくつかの言語でリリースされています。韓国語で公開されているnliまたはissデータセットはありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Bootstrapping a Crosslingual Semantic Parser -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_44.html">
      Bootstrapping a Crosslingual Semantic Parser
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      新しいバージョンのATISとドイツ語と中国語のOvernightの実験結果は、MTが複数のMTエンジンを介して言い換えると、正確な構文解析のために新しい言語でトレーニングデータを概算できることを示しています。翻訳は法外な費用がかかる可能性があります。機械翻訳がトレーニングデータの適切な代替物であるかどうかを評価し、これを拡張して、英語、言い換え、および多言語BERTなどのリソースとの共同トレーニングを使用したブートストラップを調査します。 
[ABSTRACT]新しい研究によると、mtは最小限の注釈で新しい言語と複数のドメインに適応できることが示されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: What do Models Learn from Question Answering Datasets? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_45.html">
      What do Models Learn from Question Answering Datasets?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ドメイン外の例に対する一般化可能性、データセット内の欠落または不正確な情報への応答、および質問のバリエーションを処理する能力についてモデルを評価します。分析に続いて、次のタスクをより適切に評価するQAデータセットを構築するための推奨事項を作成します。質問応答..モデルは、SQuADなどの一般的な質問応答（QA）データセットで超人的なパフォーマンスに達していますが、質問応答自体のタスクで人間をしのいでいます。 
[ABSTRACT]すべての実験に堅牢な単一のデータセットはありません。また、データセットと評価方法の両方で欠点を特定します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Selective Attention Based Graph Convolutional Networks for Aspect-Level
  Sentiment Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_46.html">
      Selective Attention Based Graph Convolutional Networks for Aspect-Level
  Sentiment Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      現在のほとんどのアプローチでは、主に注意メカニズムを使用してコンテキストとアスペクト項の間の相互作用をキャプチャすることにより、セマンティック情報を考慮しています。ただし、依存関係ツリーの2ホップ以内で重要なコンテキストワードに到達できない場合があります。したがって、選択的注意に基づくGCNブロック（SA-GCN）。最も重要なコンテキストワードを見つけ、これらの情報をアスペクト用語表現に直接集約します。 
[ABSTRACT]最新のアプローチでは、注意メカニズムを使用して、コンテキストとコンテキスト用語の間の相互作用をキャプチャしています。これは、最も重要な用語である単語を見つけるために選択的注意ベースのgcnブロック（sa-gcn）を設計しているためです。現在の状態-アート-
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-24">
        <br>2019-10-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards Multimodal Simultaneous Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_47.html">
      Towards Multimodal Simultaneous Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Multi30kデータセットを使った実験では、同時設定のMSNMTは、翻訳を開始するために必要な入力トークンが5以下の場合に、テキストのみの対応物よりも大幅に優れていることを示しました。次に、（a）を実行して、デコード中の視覚情報の重要性を検証しました。 MSNMTの敵対的評価では、モデルが一致しない入力モダリティでどのように動作するかを調べ、（b）画像の注意を分析しました。追加のモダリティとしての画像の有用性は全文翻訳にとって中程度ですが、初めて検証しました。同時翻訳の重要性。 
[要約]このタスクは、デコード中の入力情報が不足しているため、一般的な全文翻訳よりもはるかに困難です。軽減するために、私たちは初めて、同時状況に対するその重要性を検証しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Windowing Models for Abstractive Summarization of Long Texts -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_48.html">
      Windowing Models for Abstractive Summarization of Long Texts
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      経験的な結果により、意図したユースケースでモデルが効果的になります。ドキュメントの冒頭にバインドされていない関連コンテンツを含む長いテキストを要約します。2つのウィンドウ処理バリアントを検討します。静的ウィンドウ処理は、デコーダーが各ウィンドウから生成する必要があるトークンの数を事前計算します（ベースコーパス統計のトレーニングについて）;動的ウィンドウ処理では、デコーダーは、エンコーダーのシフトを次の入力ウィンドウに通知するトークンを発行することを学習します。ポインタージェネレーターネットワークで拡張されたシーケンスツーシーケンスモデルを拡張し、（1）エンコーダーが入力の異なるウィンドウ上をスライドできるようにします。ドキュメントおよび（2）デコーダを共有し、異なる入力ウィンドウ間でその状態を保持します。 
[要約]私たちは、長いテキストの神経抽象要約のためのウィンドウモデルを提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards Non-task-specific Distillation of BERT via Sentence
  Representation Approximation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_49.html">
      Towards Non-task-specific Distillation of BERT via Sentence
  Representation Approximation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、事前訓練されたBERTを、タスクを指定せずに単純なLSTMベースのモデルに蒸留できる、方向付けされた蒸留フレームワークを近似する文表現を提案します。さらに、このモデルは、タスク固有の蒸留手順とさらに連携できます。BERTと一貫しています、私たちの蒸留モデルは、微調整を介して転移学習を実行して、文レベルのダウンストリームタスクに適応できます。 
[ABSTRACT]蒸留モデルは、任意の文レベルのダウンストリームタスクに適応するように微調整を介して転移学習を実行できます。バートによれば、蒸留モデルは微調整を介して転移に到達できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Variational Question-Answer Pair Generation for Machine Reading
  Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_50.html">
      Variational Question-Answer Pair Generation for Machine Reading
  Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、モデルが潜在変数を無視してほぼ同じQAペアを生成する「事後崩壊」の問題を回避するために、変分下限でKL項を明示的に制御する効果についても検討します。2つの独立した潜在ランダムを導入します回答と質問を別々に多様化するためにモデルに変数を追加します。SQuADv1.1に関する私たちの実験は、変分法がQAペアのモデリング能力を支援し、制御されたKL項が高品質の質問と回答を生成しながら多様性を大幅に改善できることを示しました既存のシステムに匹敵します。 
[要約]回答と質問を多様化するために、2つの独立した潜在確率変数を導入します。制御されたkl項は、既存のシステムに匹敵する高品質の質問と回答を生成しながら、多様性を大幅に改善できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Fluency of Non-Autoregressive Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/cs.CL/paper_51.html">
      Improving Fluency of Non-Autoregressive Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は、提案されたモデルがデコード速度の点でより効率的であり、ARモデルと比較して競争力のあるBLEUスコアを達成できることを示しています。3つの言語ペア（ドイツ語、チェコ語、ルーマニア語）のモデルをトレーニングします。私たちのモデルでのビームサーチデコードは、ネットワークを単一の順方向パスで実行することのみを必要とします。デコード速度は、標準のARモデルよりも著しく高速です。 
[要約]ビームサーチのデコード中に使用されるスコアリングモデルに追加機能を採用することにより、narモデルの流暢さを改善します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: SNR-Based Features and Diverse Training Data for Robust DNN-Based Speech
  Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/eess.AS/paper_0.html">
      SNR-Based Features and Diverse Training Data for Robust DNN-Based Speech
  Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      （3）に対処するために、完全に接続されたフィードフォワードDNNと長期短期記憶（LSTM）を比較し、LSTMが限られたトレーニングデータと単純化した機能に対して一般化することを示します。（2）に対処するためにトレーニングしますHuノイズコーパス（制限されたサイズ）、CHiME 3ノイズコーパス（制限された多様性）、および自由に利用可能なサウンドに基づいて収集された大規模で多様なデータセットを提案します。一方で、量と多様性を増やすことを示しますのトレーニングデータは、DNNの一般化に役立ちます。 
[ABSTRACT]たとえば、huノイズコーパス（限られたサイズ）、chime 3ノイズコーパスでネットワークをトレーニングし、さまざまな音に基づいて大規模で多様なデータセットを提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning to fool the speaker recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/eess.AS/paper_1.html">
      Learning to fool the speaker recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      TIMITデータセットでの実験は、平均SNR $ 57.2 \ text {dB} $とPESQ 4.2でリアルタイムよりも速い速度で$ 99.2 \％$の文誤り率を達成できることを示しています。話者認識システムがまた、攻撃に対して脆弱であり、非標的型攻撃で高い成功率を達成します。さらに、攻撃者の成功率と知覚のトレードオフを得るように話者認識攻撃者を最適化する効果的な方法も提示します。品質。 
[ABSTRACT]生の音声波形に感知できないほどの摂動を追加してシステムをだます軽量モデル。話者認識攻撃者を最適化する効果的な方法も紹介します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: WaveTTS: Tacotron-based TTS with Joint Time-Frequency Domain Loss -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/eess.AS/paper_2.html">
      WaveTTS: Tacotron-based TTS with Joint Time-Frequency Domain Loss
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      WaveTTSは、音響機能と結果の音声波形の両方の品質を保証します。通常、損失関数は周波数領域の音響機能に対してのみ計算されるため、生成される時間領域の波形の品質を直接制御するわけではありません。実験結果提案されたフレームワークがベースラインを上回り、高品質の合成音声を実現することを示しています。 
[要約] wavettsとして知られているタコトロンには2つの損失関数があります。これらには、時間領域損失が含まれます。これは、自然の特徴と生成された特徴の間のメルスケールの音響特徴の損失を測定します。これは、時間と周波数の結合領域を持つタコトロンの最初の実装です損失
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-02">
        <br>2020-02-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: AI4COVID-19: AI Enabled Preliminary Diagnosis for COVID-19 from Cough
  Samples via an App -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/eess.AS/paper_3.html">
      AI4COVID-19: AI Enabled Preliminary Diagnosis for COVID-19 from Cough
  Samples via an App
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      AI4COVID-19は、臨床試験と競合するように設計されていません。AI4COVID-19アプリは、被験者の2秒間の咳の録音を必要とします。残念ながら、咳は、20を超えるCOVID-19以外の関連する病状の一般的な症状です。 
[要約]テストは、ai4covid-19という名前のモバイルアプリを介して大規模に展開できます。アプリはクラウドで実行されているAIエンジンを使用し、アプリは1分以内に予備診断を返します。これにより、covid-19は咳だけからの診断になります。非常に困難な問題
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-02">
        <br>2020-04-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Direct Speech-to-image Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/eess.AS/paper_4.html">
      Direct Speech-to-image Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、音声信号を転写段階なしで画像信号に変換することを試みます。アブレーション研究により、本手法についての洞察が得られます。続いて、スタック型生成敵対ネットワークを使用して、埋め込み条件付きの高品質画像を合成します。特徴。 
[要約]提案された方法は、生の音声信号を中央のテキスト表現のない画像に変換するのに効果的です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Homophone-based Label Smoothing in End-to-End Automatic Speech
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/eess.AS/paper_5.html">
      Homophone-based Label Smoothing in End-to-End Automatic Speech
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      音響モデルと言語モデルを一緒に学習するエンドツーエンドのASRモデルとキャラクターのモデリングユニットは、この方法に必要な条件です。ハイブリッドCTCシーケンスツーシーケンスモデルを使用した実験では、新しい方法でキャラクターエラーレート（CER ）0.4％絶対に..この論文では、自動音声認識（ASR）のために、人間レベルでの言語の事前知識を利用する新しいラベル平滑化方法である同音異義語が提案されています。 
[ABSTRACT]新しい方法により、文字エラー率（cer）を0.4％削減できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Universal Adversarial Perturbations Generative Network for Speaker
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/eess.AS/paper_6.html">
      Universal Adversarial Perturbations Generative Network for Speaker
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      低次元正規分布からUAP部分空間へのマッピングを学習する生成ネットワークを提案し、UAPを合成して入力信号を摂動させ、十分に訓練された話者認識モデルを高い確率で偽装します。TIMITとLibriSpeechの実験結果データセットは、モデルの有効性を示しています。このペーパーでは、話者認識システムの普遍的な敵対的摂動〜（UAP）の存在を示しました。 
[ABSTRACT]ハイテクデータセットはモデルの有効性を示しています。私たちは普遍的な敵対的摂動の存在を示しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/eess.AS/paper_7.html">
      Transforming Spectrum and Prosody for Emotional Voice Conversion with
  Non-Parallel Training Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CycleGANネットワークを提案し、敵対的損失とサイクル整合性損失を使用してフォワードマッピングとインバースマッピングを同時に学習することにより、非並列トレーニングデータから最適な疑似ペアを見つけます。効果的なF0変換のために、異なる時間解像度での音声韻律を記述する時間スケール。F0は本質的に階層的であるイントネーションの主要な側面であるため、ウェーブレット変換を使用して異なる時間スケールでF0をモデル化する方が適切であると考えます。 。 
[ABSTRACT]多くの研究では、異なる線形パターン間の並列音声データが必要です。これらの研究では、イントネーションの主要な側面であるf0が必要です。ただし、ウェーブレット変換を使用してf0をモデル化する方が適切であると考えています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-01">
        <br>2020-02-01
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-Scale Aggregation Using Feature Pyramid Module for
  Text-Independent Speaker Verification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/eess.AS/paper_8.html">
      Multi-Scale Aggregation Using Feature Pyramid Module for
  Text-Independent Speaker Verification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーでは、トップダウンパスウェイとラテラル接続を介して複数のレイヤーで機能のスピーカー識別情報を強化する機能ピラミッドモジュールを使用して、MSAを改善します。さまざまな解像度で豊富なスピーカー情報を含む拡張機能を使用して、スピーカーの埋め込みを抽出します。 ..特徴抽出のさまざまなレイヤーからのマルチスケール特徴を利用するマルチスケール集約（MSA）が最近アプローチに導入され、短い発話と長い発話の両方でパフォーマンスの向上が示されました。 
[要旨]スピーカーの埋め込みは、機能抽出の最後のレイヤーから抽出されます。msaはスピーカーをブーストします-トップダウン経路と横方向の接続を介して機能の短い情報
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Non-parallel Voice Conversion System with WaveNet Vocoder and Collapsed
  Speech Suppression -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/eess.AS/paper_9.html">
      Non-parallel Voice Conversion System with WaveNet Vocoder and Collapsed
  Speech Suppression
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、LPCDCによって引き起こされる悪影響を緩和するために、LPCDCが問題のあるセグメントにのみ適用され、品質の損失を短期間に制限することを保証するために、折りたたみ音声セグメント検出器（CSSD）を提案します。問題に取り組むために、従来のボコーダーで生成された音声を参照音声として使用して、線形予測符号化分布制約（LPCDC）を導出し、音声の崩壊の問題を回避します。音響に基づいて高忠実度音声波形を生成するボコーダーとしてのWNの有効性最近の作品で特徴が確認されています。 
[ABSTRACT] wnは、忠実度の高い音声波形を作成するためのボコーダーです。これにより、折りたたみ音声の問題を含む折りたたみ音声システムが作成されます。提案された方法は、以前の非平行制限の音声品質をさらに改善します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-26">
        <br>2020-03-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: iMetricGAN: Intelligibility Enhancement for Speech-in-Noise using
  Generative Adversarial Network-based Metric Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/eess.AS/paper_10.html">
      iMetricGAN: Intelligibility Enhancement for Speech-in-Noise using
  Generative Adversarial Network-based Metric Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、正式なリスニングテストにより、ノイズと残響の両方が存在する場合に明瞭度が大幅に向上することがわかります。実験結果は、提案されたiMetricGANが客観的測定、つまりビット単位の音声明瞭度（SIIB）に関して従来の最先端のアルゴリズムよりも優れていることを示しています。カフェテリアノイズ条件下での拡張短時間客観的了解度（ESTOI）。具体的には、iMetricGANアプローチを使用して、生成的敵対的ネットワーク（GAN）で音声了解度メトリックを最適化します。 
[要約]提案された了解度法は、音声の損失を補償するように設計されています。これは、修正の前後に音声信号の二乗平均平方根（rms）レベルと持続時間が維持されるためです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-02">
        <br>2020-04-02
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Impact of Advanced Maternal Age on Physiologic Adaptations to Pregnancy in Vervet Monkeys -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/biorxiv.physiology/paper_0.html">
      Impact of Advanced Maternal Age on Physiologic Adaptations to Pregnancy in Vervet Monkeys
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのデータは、ベルベット/アフリカミドリザルが、AMA妊娠における母性疾患の病理学的メディエーターを解読するための有用な前臨床モデルおよびツールとして役立つ可能性があることを示しています。最後に、AMA母親から生まれた子孫は出産後発育遅延の表現型を示しました。コンテキスト：米国で妊娠を遅らせる傾向により、高度な妊産婦年齢（AMA）妊娠の数も増加しています。 
[ABSTRACT]子癇前症（pe）は子癇前症の要因であり、子癇前症として知られています。これは、人間の妊娠と生理学的関連性がある前臨床モデルがないことが一部の原因です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Small Molecule Channels Harness Membrane Potential to Concentrate Potassium in trk1Δtrk2Δ Yeast -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/biorxiv.physiology/paper_1.html">
      Small Molecule Channels Harness Membrane Potential to Concentrate Potassium in trk1Δtrk2Δ Yeast
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      trk1 {Delta} trk2 {Delta}酵母にはこれらのカリウム輸送体が欠けているため、カリウムを濃縮したり、標準培地で増殖したりすることはできません。この発見により、分子補綴アプローチで対処できる可能性のあるヒトのチャネル障害のリストが拡大します。多くのタンパク質イオンチャネル膜電位を利用して、化学勾配に対抗してイオンを移動します。 
[ABSTRACT]多くのタンパク質チャネルが原因で嚢胞性線維症、バーター症候群II型、および近位腎腎臓、腎臓、腎臓、アシドーシスを引き起こします。細胞は、細胞外の比較的低濃度のコンパートメントから内部の10倍の高濃度（150〜500mm）の1つに移動する可能性があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A temperate endotherm trades thermoregulation for self-preservation: stress-induced changes in surface temperature as thermoregulatory trade-offs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-08/biorxiv.physiology/paper_2.html">
      A temperate endotherm trades thermoregulation for self-preservation: stress-induced changes in surface temperature as thermoregulatory trade-offs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ストレッサーへの対処にはかなりの精力的な投資が必要な場合があり、リソースが限られている場合、そのような投資は他の生物学的プロセスへの同時支出を妨げる可能性があります。リソースが限られている個人の表面温度と乾熱損失は、低い温度でストレスにさらされると予測しました資源制限のない個人と比較した場合、周囲温度および高周囲温度でのストレス暴露下での上昇。吸熱の中で、体温調節のエネルギー需要は計り知れませんが、ストレス応答が体温調節投資の変化を誘発するのに十分であるかどうかはまだ調査されていないようです。 
[要約]サーモギュレーション理論はストレス関連の活動と一致しています。研究では、社会的支配者よりも少ない食事を与えた社会的部下がストレスによって引き起こされた質量の低下に苦しんだことを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
