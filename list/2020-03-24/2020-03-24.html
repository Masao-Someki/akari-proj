<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-03-24の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Multi-task U-Net for Music Source Separation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-24/cs.SD/paper_0.html">
      Multi-task U-Net for Music Source Separation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの方法は、CU-Netおよび専用U-Netに匹敵するパフォーマンスをはるかに低いトレーニングコストで実現します。マルチタスク損失の2つの重み付け戦略を調査します。1）Dynamic Weighted Average（DWA）、および2）Energyベースの重み付け（EBW）..音楽ソース分離のかなり簡単なアプローチは、独立したモデルをトレーニングすることです。各モデルは特定のソースのみの推定専用です。 
[概要] c-uの代替として、重み付きマルチタスク損失を使用してトレーニングされたマルチタスクu-netを提案します。 based.these戦略は、ネットと比較して2つの利点を提供します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-23">
        <br>2020-03-23
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: RUBi: Reducing Unimodal Biases in Visual Question Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-24/cs.CL/paper_0.html">
      RUBi: Reducing Unimodal Biases in Visual Question Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      画像を見なくても正しく分類できる例。最も偏っている例の重要性を減らします。これは、バイアスを補正するために損失を動的に調整することにつながります。 
[要旨]この重大な問題により、現実世界の設定には不適切になります。vqa-cp v2の最新の結果を超えることにより、貢献を検証します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-24">
        <br>2019-06-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Caption Generation of Robot Behaviors based on Unsupervised Learning of
  Action Segments -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-24/cs.CL/paper_1.html">
      Caption Generation of Robot Behaviors based on Unsupervised Learning of
  Action Segments
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      K平均クラスタリングに基づく教師なしセグメンテーションを導入して、典型的なロボット観測パターンをクラスに統合します。実験結果は、教師なし学習に基づく提案モデルが他の方法よりも優れた記述を生成できることを示します。 ;ロボットの動作と自然言語のキャプションの間のエンドツーエンドのブリッジングに向けた、アクチュエータシステムとカメラからの履歴。 
[概要]自然言語のキャプションを生成するシステムが開発されています。人間支援ロボットの動作を説明するキャプションのペアを作成するために使用できます。既存のシーケンスを適用することは困難です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-23">
        <br>2020-03-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multimodal Intelligence: Representation Learning, Information Fusion,
  and Applications -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-24/cs.CL/paper_2.html">
      Multimodal Intelligence: Representation Learning, Information Fusion,
  and Applications
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      マルチモーダル融合では、このレビューは特定のタスクのユニモーダル信号の表現を統合するための特別なアーキテクチャに焦点を当てています。クロスモダリティ信号処理を可能にします。このレビューにより、コミュニティのマルチモーダルインテリジェンスの新たな分野における将来の研究が促進されると考えています。 
[概要]マルチモーダルインテリジェンスのモデルと学習方法の技術的レビューが提供されます。メインレビューは、3つの角度からのマルチモーダルディープラーニングに関する最近の研究の包括的な分析を提供します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br>2019-11-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Word Polysemy Quantification with Multiresolution Grids of
  Contextual Embeddings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-24/cs.CL/paper_3.html">
      Unsupervised Word Polysemy Quantification with Multiresolution Grids of
  Contextual Embeddings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、人間のランキング間の相関関係を視覚化および分析します。この方法の貴重な副産物は、特定の単語の異なる感覚を含む文を追加費用なしでサンプリングできることです。最後に、完全に教師なしの性質メソッドは、どの言語にも適用できるようにします。 
[要約]我々は、文脈埋め込み空間の単純な幾何学に基づいて、多義性を推定する新しい方法を提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-23">
        <br>2020-03-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Fast Cross-domain Data Augmentation through Neural Sentence Editing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-24/cs.CL/paper_4.html">
      Fast Cross-domain Data Augmentation through Neural Sentence Editing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Edit-transformerを作成します。これは、最新技術よりも大幅に高速で、クロスドメインでも機能するTransformerベースのセンテンスエディターです。これは、既存の方法の場合、完全な学習を行うために拡張が最も難しい場合です。データ配布は不可能です。Yelpとウィキペディアのドメインペアでこのパフォーマンスのギャップを示しています。 
[ABSTRACT]自然言語の場合、文の編集は解決策を提供します-元の変更に対する小さなしかし意味のある変更に依存しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-23">
        <br>2020-03-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Automatic Identification of Types of Alterations in Historical
  Manuscripts -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-24/cs.CL/paper_5.html">
      Automatic Identification of Types of Alterations in Historical
  Manuscripts
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ここで提案する方法は、デジタル学術版ベルリン知識人で実施された実験に基づいて開発されたものであり、alterLDAはラベル付きデータの変更を認識する際に高い性能を発揮します。デジタル学術版ベルリン知識人に基づく発見に加えて、このドキュメントでは、ドキュメントの変更を分類するのに役立つ機械学習ベースのアプローチを提示します。テキスト生成の分析のための一般的なフレームワークは、ドキュメントバリアントを表す他のデジタルリソースのコンテキストで使用できます。 
[ABSTRACT]ラベルなしのデータについて、アルテルダを適用すると、著者、編集者、および他の原稿寄稿者の修正行動に関する興味深い新しい洞察が得られます。これについて、このような結果を達成するために従う方法論的な手順を詳細に示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-20">
        <br>2020-03-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: E2EET: From Pipeline to End-to-end Entity Typing via Transformer-Based
  Embeddings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-24/cs.CL/paper_6.html">
      E2EET: From Pipeline to End-to-end Entity Typing via Transformer-Based
  Embeddings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      広範囲のアブレーション研究は、言及レベルのモデルのコンテキスト化された埋め込みの有効性と、エンティティタイプのエンドツーエンドモデルの競争力を示しています。したがって、ウィンドウサイズの選択に敏感であり、ドキュメント全体のコンテキストを組み込むことはできません..これらの欠点を考慮して、言及レベルのモデルにはトランスベースの埋め込みを使用したコンテキストを組み込み、Bi-GRUを使用したエンドツーエンドのモデルはウィンドウサイズへの依存を削除することを提案します。 
[ABSTRACT] etには、各オブジェクトに1つ以上のクラスラベルを付けることが含まれます。これらのモデルはウィンドウサイズの選択の影響を受けやすく、ドキュメント全体のコンテキストを組み込むことができません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-23">
        <br>2020-03-23
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Reducing the Latency of End-to-End Streaming Speech Recognition Models
  with a Scout Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-24/eess.AS/paper_0.html">
      Reducing the Latency of End-to-End Streaming Speech Recognition Models
  with a Scout Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、TransformerベースのストリーミングSRは、業界と学界の両方から注目を集めていますが、固定長の先読みウィンドウを採用すると、エンコーダーレイヤーの数に応じてレイテンシが直線的に増加します。認識境界線の前にあるすべてのフレームを考慮して、認識ネットワークが次のサブワードを予測します。認識品質を確保し、待ち時間を短縮するために、スカウトネットワークと認識ネットワークで構成される新しいストリーミング認識方法を提案します。 
[ABSTRACT]トランスフォーマーベースのストリーミングは、業界や学術機関から注目を集めていますが、そのレイテンシーはエンコーダーレイヤーの数に比例して増加します。スカウトネットワークは、将来のフレームを見ることなく単語境界全体を検出します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-23">
        <br>2020-03-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Dialect Identification of Spoken North Sámi Language Varieties Using
  Prosodic Features -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-24/eess.AS/paper_1.html">
      Dialect Identification of Spoken North Sámi Language Varieties Using
  Prosodic Features
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの結果は、すべての音響韻律特徴の文脈情報を含めることが単語や音節の方言を識別するために重要である北S \ &#39;amiの5種類の地域を区別する上で、韻律情報が重要な役割を果たすことを示しています。 、この作業では、エネルギーの基本的な音響韻律の特徴、基本周波数、スペクトルチルト、持続時間、およびそれらの組み合わせの調査に焦点を当て、順次およびコンテキスト非依存の教師付き分類方法を使用し、音声の2つの異なる単位：単語と音節で個別に評価します。これらの特性は、分節および超分節（韻律）の違いだけでなく、語彙や形態統語などの高レベルの特性も反映しています。 
[ABSTRACT]言語の組み合わせは、地域またはコミュニティに固有の特性を囲みます。これらの特性は、異なる地域の地域にとって重要です。これらの作業は、異なる言語の種類を識別する際の韻律の役割についての理解を深めることです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-23">
        <br>2020-03-23
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Diversified regulation of circadian clock gene expression following whole genome duplication -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-24/biorxiv.physiology/paper_0.html">
      Diversified regulation of circadian clock gene expression following whole genome duplication
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      複数の組織にわたって発現パターンを比較することにより、および開発中に、機能的多様化と一致する、発現パターンにおける強力な遺伝子および組織特異的相違の証拠を提示します。時計遺伝子ファミリーメンバーの複数のコピーが機能的に重複する程度は不明のままです現代の脊椎動物では、これらのネットワークには時計遺伝子ファミリーのメンバーの複数のコピーが含まれており、進化の歴史の中で全ゲノム複製（WGD）イベントによって発生しました。 
[概要]現代の脊椎動物では、これらのネットワークは時計遺伝子ファミリーのメンバーの複数のコピーを含んでいます。これらは全ゲノム複製（wgd）イベントによって発生しました。複数のコピーは大西洋サケで見つかりました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-23">
        <br>2020-03-23
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
