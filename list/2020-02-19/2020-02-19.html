<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-02-19の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Metric Learning with Background Noise Class for Few-shot Detection of
  Rare Sound Events -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.SD/paper_0.html">
      Metric Learning with Background Noise Class for Few-shot Detection of
  Rare Sound Events
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは、イベントクラスとバックグラウンドノイズクラスが十分に分離された特徴空間を提供します。バックグラウンドノイズを独立したクラスとして明示的に含めること、この追加クラスを強調する適切な損失関数、および対応するサンプリング戦略を提供することトレーニングを支援します。サウンドイベント認識のためのショットラーニングシステムは、微調整せずに新しいターゲットクラスに適応するのに必要な例が少ないため、関心を集めています。 
[概要]これらのシステムは、分類または検証のために音の塊にのみ適用されています。ただし、他のイベントとバックグラウンドノイズの両方に対する誤検知を防ぐために必要です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-30">
        <br>2019-10-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: PitchNet: Unsupervised Singing Voice Conversion with Pitch Adversarial
  Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.SD/paper_1.html">
      PitchNet: Unsupervised Singing Voice Conversion with Pitch Adversarial
  Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      歌声変換は、歌手の内容を変更せずに歌手の声を他の人の声に変換することです。また、変換された歌のピッチは、デコーダネットワークに渡す前に抽出されたピッチのレベルを変更することで、生成中に簡単に制御できることを示します。 。私たちの評価は、提案された方法が変換された歌声の品質を大きく改善できることを示しています（MOSで2.92対3.75）。 
[要約]歌声の変換は、オートエンコーダーを使用して実現できます-ベースのアプローチ。提案された方法は、変換された歌声の品質を大幅に改善できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Audio-attention discriminative language model for ASR rescoring -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.SD/paper_2.html">
      Audio-attention discriminative language model for ASR rescoring
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      自動音声認識（ASR）のエンドツーエンドのアプローチは、単一のニューラルネットワークで入力オーディオストリームが与えられた場合に単語シーケンスの確率を直接モデル化することから恩恵を受けます。トレーニングデータの量は、初回通過システムのトレーニングに使用されるデータの一部です。この作業では、学習する注意ベースの識別言語モデルを使用して、エンドツーエンドのアプローチの利点を従来のシステムと組み合わせることを提案します初回通過ASRシステムの出力を再スコアリングします。 
[ABSTRACT] researchは、潜在的なasr出力のリストを再スコアリングする学習は、仮説を生成する学習よりもはるかに簡単であることを示しています。このモデルは、比較可能な結果を得るためにより多くのデータを必要とします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-06">
        <br>2019-12-06
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Gradient-Based Adversarial Training on Transformer Networks for
  Detecting Check-Worthy Factual Claims -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_0.html">
      Gradient-Based Adversarial Training on Transformer Networks for
  Detecting Check-Worthy Factual Claims
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果に加えて、コードベースと手動でラベル付けされたデータセットをリリースしています。ClaimBusterDatasetおよびCLEF2019 Datasetの最新のモデルと比較して、F1スコアが4.31ポイント、mAPスコアが1.09ポイント向上しています。その過程で、我々は敵の訓練を変圧器モデルに適用する方法を提案します。これは、多くの同様のテキスト分類タスクに一般化される可能性があります。 
[概要]複数の課題に関する最新の結果を達成する、最初の敵対的で正規化されたトランスベースのクレームスポッターモデルを導入します。プロセスでは、トランスフォーマーモデルに敵対的トレーニングを適用する方法を提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br>2020-02-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Sequential Latent Knowledge Selection for Knowledge-Grounded Dialogue -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_1.html">
      Sequential Latent Knowledge Selection for Knowledge-Grounded Dialogue
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最も大規模で挑戦的なベンチマークの1つとして、ウィキペディアのウィザード（Dinan et al。、2019）で新しい最先端のパフォーマンスを実現します。知識に基づく対話は、情報に基づいた応答を生成するタスクです談話コンテキストと外部知識の両方について。我々の実験結果は、提案されたモデルが知識選択の精度を向上させ、発話生成のパフォーマンスを向上させることを示しています。 
[ABSTRACT]提案されたモデルは、知識選択の精度を向上させるために使用できます。提案されたモデルは、発話生成のパフォーマンスも向上させます。既存の会話方法に対するモデルの有効性をさらに検証します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br>2020-02-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: VL-BERT: Pre-training of Generic Visual-Linguistic Representations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_2.html">
      VL-BERT: Pre-training of Generic Visual-Linguistic Representations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      その中で、入力の各要素は、入力文からの単語、または入力画像からの関心領域（RoI）のいずれかです。一般的な表現をより活用するために、VL-BERTを事前にトレーニングします。 VL-BERTは、シンプルで強力なTransformerモデルをバックボーンとして採用し、それを拡張して視覚的および言語的埋め込み機能の両方を入力として使用します。 
[ABSTRACT]モデルは、ほとんどの視覚的、視覚的視覚的視覚タスクに適合するように設計されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-22">
        <br>2019-08-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Multi-Turn Response Selection Models with Complementary
  Last-Utterance Selection by Instance Weighting -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_3.html">
      Improving Multi-Turn Response Selection Models with Complementary
  Last-Utterance Selection by Instance Weighting
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      重要な点は、補完タスクの出力を使用してメインタスクのインスタンスの重みを設定することです。メインタスク（つまりフォーカス）は、最後の発話とコンテキストが与えられると正しい応答を選択し、補完タスクは最後の応答とコンテキストが与えられた発話。2つの公開データセットで広範な実験を行い、両方のデータセットで大幅な改善を実現します。 
[要約]メインタスク（phすなわち私たちのフォーカス）は、最後の発話とコンテキストを前提として正しい応答を選択し、補完タスクは最後のペアとコンテキストを選択します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br>2020-02-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Machine Translation with Joint Representation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_4.html">
      Neural Machine Translation with Joint Representation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案された効率的なアテンション操作で表現を洗練することにより、非効率性の問題を回避します。統計的機械翻訳（SMT）システムの初期の成功は、2つのソースとターゲットのユニット間の相互作用の明示的なモデリングに一部起因しています最近のニューラルマシントランスレーション（NMT）システムは、効率のために相互作用を部分的にエンコードする注意に頼っています。結果のリフォーマーモデルは、エンコーダー-デコーダーフレームワークに加えて、新しいシーケンス間モデリングパラダイムを提供し、小規模なIWSLT14ドイツ語-英語、英語-ドイツ語、およびIWSLT15ベトナム語-英語、または大規模なNIST12中国語-英語翻訳タスク約1 BLEUポイント。パラメータが約50％少ないIWSLT14ドイツ語-英語およびNIST12中国語-英語の最新のトランスフォーマー。 
[概要]リフォーマーモデルは、新しいシーケンス-シーケンスモデルモデルmodel.theyを提供します。体系的なモデルスケーリングアプローチを提供し、iWSLT14ドイツ語-英語およびnist12中国語-英語で、リフォーマーモデルが最先端のトランスを打ち負かすことができます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-16">
        <br>2020-02-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Reformer: The Efficient Transformer -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_5.html">
      Reformer: The Efficient Transformer
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果のモデルであるリフォーマーは、Transformerモデルと同等のパフォーマンスを発揮しますが、長いシーケンスでははるかにメモリ効率が高く、はるかに高速です。さらに、標準残差の代わりに可逆残差レイヤーを使用します。 $ N $回の代わりに処理します（$ N $はレイヤーの数です）。大規模なTransformerモデルでは、多くのタスクで常に最新の結果が得られますが、これらのモデルのトレーニングは、特に長いシーケンスで非常にコストがかかる可能性があります。 
[ABSTRACT]変圧器の効率を改善するための2つの新しい方法を導入します。1つは、標準残差を置き換えることを含みます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br>2020-01-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Relationship-Embedded Representation Learning for Grounding Referring
  Expressions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_6.html">
      Relationship-Embedded Representation Learning for Grounding Referring
  Expressions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本論文では、与えられた表現に関連するオブジェクトと関係（空間的および意味的関係）をクロスモーダルな注意メカニズムで適応的に強調し、抽出された情報を言語ガイドとして表現するために、クロスモーダル関係抽出（CMRE）を提案します視覚的関係グラフ。3つの一般的なベンチマークデータセットの実験結果は、CMREとGGCNで構成されるクロスモーダル関係推論ネットワークが、既存のすべての最先端の方法を大幅に上回ることを示しています。言語と画像のコンテンツであり、人間とコンピューターの相互作用に関連する一連の視覚タスクに不可欠です。 
[要約]参照式のグラウンディングに関する以前の作業では、参照式から複数順序の関係を抽出できず、それらを画像内のオブジェクトおよびそれらの関連コンテキストに関連付けることができません。さらに、マルチモーダルを計算するためのゲーテッドグラフマークネットワークセマンティック環境
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-11">
        <br>2019-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Relation Prediction for Simple Question Answering over Knowledge
  Graph -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_7.html">
      Neural Relation Prediction for Simple Question Answering over Knowledge
  Graph
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SimpleQuestionsデータセットでの実験により、提案されたモデルは、最新の関係抽出モデルと比較してより高い精度を達成したことが示されます。本論文では、新しい質問の同様の質問を見つけるためのインスタンスベースの方法を提案します。言及された関係を予測するための関係の意味。関係は異なる形式の質問で表現でき、これらの形式はほとんど同様の用語または概念を共有するという事実に基づいています。 
[ABSTRACT]最新の方法では、ニューラルネットワークを利用して質問をすべての回答と照合し、その質問で表現される最適な関係を見つけます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br>2020-02-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Model to Measure the Spread Power of Rumors -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_8.html">
      A Model to Measure the Spread Power of Rumors
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      （iii）T-Testの結果は、SPR基準がFRとTRを大幅に区別できることを示しています。さらに、噂の真実性を検証するための新しい方法としても役立ちます。既存の手法は構造とコンテンツの機能に基づいていますが、RSPMMはかなり優れた結果（F-measure = 83％）を達成しています。これは、噂の拡散力（SPR）の計算に関連する未解決の問題に初めて取り組み、マルチコンテキスト機能の機能としての拡散力を調べる。 
[ABSTRACT]提案された噂拡散パワー測定モデル（rspmm）は、文学ベースのアプローチを使用してsprを計算します。提案されたrspmmは、twitterおよび電報から収集された2つのラベル付きデータセットで検証されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br>2020-02-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Conditional Self-Attention for Query-based Summarization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_9.html">
      Conditional Self-Attention for Query-based Summarization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CSAは、指定されたクエリへの入力の一致スコアを使用して、自己注意モジュールの入力トークン間のペアごとの注意を調整することによって機能します。これにより、CSAによってモデル化されたコンテキスト依存関係は、クエリに非常に関連性が高くなります。シーケンス内の任意の位置間の依存関係を柔軟にキャプチャできるため、さまざまなNLPタスクで大きな成功を収めています。 
[要約]さまざまなタイプのアテンションによって定義されるcsaのバリアントをさらに研究しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br>2020-02-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Cross-lingual Alignment vs Joint Training: A Comparative Study and A
  Simple Unified Framework -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_10.html">
      Cross-lingual Alignment vs Joint Training: A Comparative Study and A
  Simple Unified Framework
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの経験的な結果は、両方の方法の長所と短所のセットを明らかにし、アライメントと関節トレーニングの相対的なパフォーマンスがタスク依存であることを示しています。この分析から、これら2つを相互に結合するシンプルで斬新なフレームワークを提案します。排他的なアプローチ。広範な実験により、提案されたフレームワークが両方のアプローチの制限を緩和し、MUSEバイリンガルレキシコン誘導（BLI）ベンチマークで既存の方法を上回ることを実証します。 
[概要]調査では、アライメントと関節トレーニングの相対的なパフォーマンスが課題に依存していることが示されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-10">
        <br>2019-10-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning by Semantic Similarity Makes Abstractive Summarization Better -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_11.html">
      Learning by Semantic Similarity Makes Abstractive Summarization Better
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      自動評価をサポートするために、人間の評価も実施し、ベースラインと参照の両方の概要に比べて高いスコアを受け取りました。事前学習済みの言語モデルを活用することで、このモデルは新しい最先端のパフォーマンスであるROUGE-Lスコアを達成しましたCNN / DMデータセットの41.5。クロスエントロピー損失など、教師あり学習のために広く使用されている目的関数は、代替答えを効果的に処理できません。 
[ABSTRACT]検索の巨人は、cnn / dmデータセットで41.5の新しいスコアを獲得しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br>2020-02-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Few-shot Text Classification with Distributional Signatures -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_12.html">
      Few-shot Text Classification with Distributional Signatures
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのモデルはメタ学習フレームワーク内で訓練され、これらの署名を注意スコアにマッピングし、単語の語彙表現に重み付けするために使用されます。ただし、このアプローチをテキストに直接適用することは困難です。私たちのモデルは、6回のベンチマークデータセット（20.0％ 1ショット分類の平均）。 
[ABSTRACT]研究は、低レベルのパターンが学習タスク間で転送可能なコンピュータービジョンで強力なパフォーマンスを示しました。具体的には、このモデルは、適切な単語発生パターンをエンコードする分布シグネチャも使用します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-16">
        <br>2019-08-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: PitchNet: Unsupervised Singing Voice Conversion with Pitch Adversarial
  Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_13.html">
      PitchNet: Unsupervised Singing Voice Conversion with Pitch Adversarial
  Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、提案されたPitchNetは、敵対的に訓練されたピッチ回帰ネットワークを追加して、エンコーダーネットワークにピッチ不変音素表現を学習させ、ソースオーディオから抽出されたピッチをデコーダーネットワークに供給する別のモジュールを追加しました。変換された歌声の品質を大幅に改善します（MOSで2.95対3.75）。歌声変換は、歌の内容を変更せずに歌手の声を別の声に変換することです。 
[要約]歌声の変換は、オートエンコーダーを使用して実現できます-ベースのアプローチ。提案された方法は、変換された歌声の品質を大幅に改善できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Decidability of cutpoint isolation for letter-monotonic probabilistic
  finite automata -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_14.html">
      Decidability of cutpoint isolation for letter-monotonic probabilistic
  finite automata
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      指数関数的に曖昧なPFAであっても、カットポイント分離問題を解決するための建設的な非決定性アルゴリズムを提供し、問題が少なくともNP困難であることも示します。この問題の決定可能性は、（厳密な）PFAの多項式のあいまいさ、可換行列、文字単調言語上の入力、および文字単調言語上のPFAで決定不可能な単射性の入力のさらに厳しい制限の下では決定できない空の問題。カットポイントarbitrarily意的に接近できない場合は隔離されます。 
[要約]これは、文字に対する分離の厳密なカットにもかかわらずです。また、文字あたり1,000語未満です。これらには、pfaには決定不可能な単射性の問題が含まれます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br>2020-02-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: From English To Foreign Languages: Transferring Pre-trained Language
  Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_15.html">
      From English To Foreign Languages: Transferring Pre-trained Language
  Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      単一のGPUを使用すると、1日以内に外国のBERTベースモデルを取得し、2日以内に外国のBERTを取得することができます。この作業では、さらに、6言語でモデルを評価すると、2つのゼロショットタスク（自然言語推論と依存関係解析）でのモデルが多言語BERTよりも優れていることを実証します。 
[概要]多言語の事前トレーニングモデルの可用性により、自然言語タスクのゼロショット転送が可能になります。1つのGPUに加えて、1日以内に外国のバートベースモデルを取得できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br>2020-02-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Audio-attention discriminative language model for ASR rescoring -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_16.html">
      Audio-attention discriminative language model for ASR rescoring
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたモデルは、トレーニングデータの量がファーストパスシステムのトレーニングに使用されるデータの一部である場合でも、ワード誤り率の8％の改善をもたらします。一方、従来のHMMベースのシステムは、本作業では、エンドツーエンドのアプローチの利点を、ファーストパスASRシステムの出力を再スコアリングすることを学習する注意ベースの識別言語モデルを使用して、従来のシステムと組み合わせることを提案します。 
[ABSTRACT] researchは、潜在的なasr出力のリストを再スコアリングする学習は、仮説を生成する学習よりもはるかに簡単であることを示しています。このモデルは、比較可能な結果を得るためにより多くのデータを必要とします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-06">
        <br>2019-12-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A New Clustering neural network for Chinese word segmentation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_17.html">
      A New Clustering neural network for Chinese word segmentation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この記事では、将来的に他のドメインに適用される可能性のある中国語の単語分割（CWS）を実現するための新しいモデルを提案しました。これは、クラスタリングの問題と見なすために、以前の作品と比較したCWSの新しい考え方ですこのモデルでは、LSTMと自己注意構造を使用して、すべてのレイヤーで文レベルの特徴もコンテキストを収集します。いくつかのレイヤーの後、クラスタリングモデルを適用して、文字をグループに分割します。このモデルをCLNNと呼びます。このアルゴリズムは、トレーニングデータセットでFスコアの98％（OOVワードなし）および85〜95％Fスコア（OOVワードあり）に達することができます。エラー分析は、OOVワードがパフォーマンスを大幅に低下させることを示しています。将来、より深い研究が必要です。 
[要旨] iは、中国語のセグメンテーション（cws）を実現するための新しいモデルを提案します。将来、他のドメインに適用できる可能性があります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br>2020-02-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Survey of Deep Learning Techniques for Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_18.html">
      A Survey of Deep Learning Techniques for Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      しかし、過去数年間に提案されたかなりの数の研究により、この新しい技術トレンドの開発プロセスを調査する作業はほとんどありません。機械翻訳のサブフィールドでは、Neural Machine Translation（NMT）と呼ばれる新しいアプローチがあります。学界と産業界の両方から大きな注目を集めています。近年、自然言語処理（NLP）はディープラーニングテクニックにより大きな発展を遂げています。 
[要旨]ニューラル機械翻訳と呼ばれる新しいアプローチが登場し、大きな注目を集めました。この新しいアプローチは、性別と業界の両方からほとんど注目されていません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br>2020-02-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An enhanced Tree-LSTM architecture for sentence semantic modeling using
  typed dependencies -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_19.html">
      An enhanced Tree-LSTM architecture for sentence semantic modeling using
  typed dependencies
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この調査結果は、文モデリングにおける文法関係の重要性を暗示しています。また、文の意味を密なベクトルに埋め込むために、文の依存関係解析構造と依存関係タイプを使用する、Typed Dependency Tree-LSTMと呼ばれるTree-LSTMモデルを紹介します。 。ツリーベースのLong Short Term Memory（LSTM）ネットワークは、言語のテキストの意味をモデリングするための最先端技術になりました。これは、文法構文を効果的に活用し、それによって文の単語間の非線形依存性を活用できるためです。 
[要約]これらのモデルは、文構造内の文法的関係のタイプ、型付き依存関係とも呼ばれません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br>2020-02-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Annotating and Extracting Synthesis Process of All-Solid-State Batteries
  from Scientific Literature -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/cs.CL/paper_20.html">
      Annotating and Extracting Synthesis Process of All-Solid-State Batteries
  from Scientific Literature
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、最適設定のシーケンスタガーがマクロ平均F1スコア0.826のエンティティを検出できること、ルールベースの関係抽出ツールがマクロ平均F1スコア0.887で高いパフォーマンスを達成できることを示しています。機械読み取りシステムは、深層学習ベースのシーケンスタガーと単純なヒューリスティックルールベースのリレーション抽出器によって開発されます。合成プロセスは、無機材料化学の分野で計算実験設計を達成するために不可欠です。 
[ABSTRACT]このプロジェクトは、シンプルでシンプルなシンプルなデータシステムによって作成されました。深層学習-ベースのシーケンスタガーとシンプルなヒューリスティックルールベースのリレーションエクストラクターによって開発されました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br>2020-02-18
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Metric Learning with Background Noise Class for Few-shot Detection of
  Rare Sound Events -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/eess.AS/paper_0.html">
      Metric Learning with Background Noise Class for Few-shot Detection of
  Rare Sound Events
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは、イベントクラスとバックグラウンドノイズクラスが十分に分離された機能空間を提供します。バックグラウンドノイズを独立したクラスとして明示的に含めること、この追加クラスを強調する適切な損失関数、および対応するサンプリング戦略を提供することトレーニングを支援します。少数ショット検出のために、バックグラウンドノイズクラスを使用したメトリック学習を提案します。 
[概要]これらのシステムは、分類または検証のために音の塊にのみ適用されています。ただし、他のイベントとバックグラウンドノイズの両方に対する誤検知を防ぐために必要です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-30">
        <br>2019-10-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multitask Learning with Capsule Networks for Speech-to-Intent
  Applications -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/eess.AS/paper_1.html">
      Multitask Learning with Capsule Networks for Speech-to-Intent
  Applications
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ユーザーの労力は可能な限り低くする必要があるため、カプセルネットワークは、より深いニューラルネットワークと比較して、トレーニングデータをほとんど必要としない可能性があるため、関心を集めています。必要な情報をカプセルベクトルに強制することにより、発話の話者を識別することを学習します。ユーザーはフレージングを選択することもできますが、逸脱したり障害のあるスピーチであっても
[ABSTRACT]発言は複数の複数の発言者によって制御できます。これらには、モデルのパフォーマンスを改善できるマルチタスク学習が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br>2020-02-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: PitchNet: Unsupervised Singing Voice Conversion with Pitch Adversarial
  Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/eess.AS/paper_2.html">
      PitchNet: Unsupervised Singing Voice Conversion with Pitch Adversarial
  Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、提案されたPitchNetは、敵対的に訓練されたピッチ回帰ネットワークを追加して、ピッチ不変の音素表現を学習するエンコーダーネットワークを強制し、ソースオーディオから抽出されたピッチをデコーダーネットワークに供給する別のモジュールを追加しました。また、変換されたピッチ抽出されたピッチのレベルをデコーダーネットワークに渡す前に変更することにより、生成中に歌を簡単に制御できます。 
[要約]歌声の変換は、オートエンコーダーを使用して実現できます-ベースのアプローチ。提案された方法は、変換された歌声の品質を大幅に改善できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Audio-attention discriminative language model for ASR rescoring -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-19/eess.AS/paper_3.html">
      Audio-attention discriminative language model for ASR rescoring
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、エンドツーエンドアプローチの利点を、初回通過ASRシステムの出力を再スコア化することを学習する注意ベースの識別言語モデルを使用して、従来のシステムと組み合わせることを提案します。 、ドメインおよびスタイルの適応を考慮して、エンドツーエンドシステムに簡単に適用できません。提案されたモデルは、トレーニングデータの量が初回通過システム。 
[ABSTRACT] researchは、潜在的なasr出力のリストを再スコアリングする学習は、仮説を生成する学習よりもはるかに簡単であることを示しています。このモデルは、比較可能な結果を得るためにより多くのデータを必要とします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-06">
        <br>2019-12-06
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本日更新された論文はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br>
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
