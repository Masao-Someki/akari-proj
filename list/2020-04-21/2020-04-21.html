<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-04-21の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Multi-task Learning for Voice Trigger Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.SD/paper_0.html">
      Multi-task Learning for Voice Trigger Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、ベースラインシステムに挑戦する例のはるかに小さいデータセットを収集します。この結果は、提案されたモデルが、追加のパラメーターを必要としない一連の挑戦的なテスト条件で\ emph {なし}で、ベースラインと比較してエラーを半分に削減することを示しています。この段階で検出が行われると、セグメントがトリガーフレーズを含んでいることを確認するために、候補の音声セグメントがより大きく複雑なモデルによって再スコアリングされます。 
[要約]研究はマンチェスター大学によって実施されました。特定のキーワードまたはトリガーフレーズのトレーニング例に基づいています。これにより、トリガーフレーズ固有のトレーニングデータが不足します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-26">
        <br>2020-01-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CHiME-6 Challenge:Tackling Multispeaker Speech Recognition for
  Unsegmented Recordings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.SD/paper_1.html">
      CHiME-6 Challenge:Tackling Multispeaker Speech Recognition for
  Unsegmented Recordings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、セグメント化されたマルチスピーカー音声認識（トラック1）とセグメント化されていないマルチスピーカー音声認識（トラック2）の両方に対するCHiME-6チャレンジのベースラインについて説明します。特に、トラック2は、コミュニティーでセグメント化されていない最初のチャレンジ活動です音声強調、話者ダイアライゼーション、および音声認識モジュールを提供する再現可能なオープンソースベースラインの完全なセットを備えたマルチスピーカー音声認識シナリオ。新しい課題は、以前のCHiME-5課題を再検討し、遠くのマルチマイク会話型音声ダイアライゼーションの問題をさらに考慮します。日常の家庭環境での認識。 
[ABSTRACT]新しい課題は以前のチャイムを再訪します-5つの課題。それはさらに、日常の家庭環境における遠くのマルチマイク会話音声のダイアライゼーションと認識の問題を考慮します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: CheXbert: Combining Automatic Labelers and Expert Annotations for
  Accurate Radiology Report Labeling Using BERT -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_0.html">
      CheXbert: Combining Automatic Labelers and Expert Annotations for
  Accurate Radiology Report Labeling Using BERT
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最終的なモデルであるCheXbertは、以前の最高のルールベースのラベラーよりも統計的有意性が優れており、胸部X線の最大のデータセットの1つにレポートのラベル付け用の新しいSOTAを設定できることがわかりました。この作業では、利用可能なルールベースのシステムの規模とエキスパートアノテーションの品質の両方を活用する医療画像レポートのラベル付けに対するBERTベースのアプローチ。ルールベースのラベラーのアノテーションで最初にトレーニングされ、次に微調整されたBERTモデルの優れたパフォーマンスを示します。自動化された逆翻訳で増強された専門家の注釈の小さなセット。 
[ABSTRACT]私たちは、ルールベースのラベラーに基づいて、ルールの注釈に微調整され、その後、エキスパート注釈の小さなセットに微調整されたbertモデルの優れたパフォーマンスを示しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On the Encoder-Decoder Incompatibility in Variational Text Modeling and
  Beyond -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_1.html">
      On the Encoder-Decoder Incompatibility in Variational Text Modeling and
  Beyond
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案する結合VAEアプローチを、さまざまな正則化、事後ファミリー、デコーダー構造、および最適化戦略を備えたさまざまなVAEモデルに適用します。また、条件付き言語モデリングにこの方法を一般化し、対話生成の多様性を大幅に改善する結合CVAEを提案します。スイッチボードデータセット上。変分オートエンコーダー（VAE）は、潜在変数を償却変分推論と組み合わせます。その最適化は通常、特にテキストモデリングにおいて、事後崩壊と呼ばれる自明な局所最適に収束します。 
[ABSTRACT]これは、VAEモデルがautoencodersにリンクされた初めてです。デコーダーの非互換性が組み合わされて、データマニホールドのローカルログが不十分になります。また、エンコーダーの重みの共有とデコーダーの信号のマッチングが向上します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Controllable Sentence Simplification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_2.html">
      Controllable Sentence Simplification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちがACCESS（AudienCe-CEntric Sentence Simplificationの省略形）と呼ぶこのモデルは、WikiLargeテストセットの41.87 SARIで最先端の技術を確立し、以前に報告された最高スコアよりも+1.42改善されています。これらの属性の選択された値により、すぐに使用可能なSequence-to-Sequenceモデルが、単純化ベンチマークで標準の対応物をしのぐことができます。多くの場合、同じ単純化がすべてに適している汎用的な汎用タスクと見なされます。ただし、複数の対象者がさまざまな方法で簡略化されたテキストから利益を得ることができます。 
[要約]ユーザーは、長さ、言い換えの量、字句の複雑さ、構文の複雑さなどの属性に基づいて、モデルによって返される簡略化を条件付けることができます。これは、41での最新の技術を示しています。87wikilargeテストセットのサリー、1。以前に報告された最高スコアより42改善
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-07">
        <br>2019-10-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Specializing Unsupervised Pretraining Models for Word-Level Semantic
  Similarity -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_3.html">
      Specializing Unsupervised Pretraining Models for Word-Level Semantic
  Similarity
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このために、標準のBERTモデルをマルチタスク学習設定に一般化し、BERTのマスクされた言語モデリングと次の文の予測目的をバイナリワード関係分類の補助タスクと結合します。 （LIBERT）は、単語レベルの意味的類似性に特化しており、いくつかの言語理解タスクで字句盲の「バニラ」BERTよりも優れたパフォーマンスを発揮します。教師なし事前トレーニングモデルは、ダウンストリームNLPアプリケーションの幅広い範囲を促進することが示されています。 
[ABSTRACT]新しいモデルは、このような分散知識を外部の字句知識で補完することを示しています。単語レベルの意味的類似性に関する離散知識を事前トレーニングに統合しています。字句の簡略化のために3つのベンチマークで一貫した利益を示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-05">
        <br>2019-09-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: MultiWOZ -- A Large-Scale Multi-Domain Wizard-of-Oz Dataset for
  Task-Oriented Dialogue Modelling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_4.html">
      MultiWOZ -- A Large-Scale Multi-Domain Wizard-of-Oz Dataset for
  Task-Oriented Dialogue Modelling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されているデータ収集パイプラインは、完全にクラウドソーシングに基づいており、専門のアノテーターを雇う必要はありません。次に、信念追跡、対話行為、および応答生成の一連のベンチマーク結果が報告されます。これは、データの有用性を示し、将来の研究のベースラインを設定します。機械学習は対話研究コミュニティの主要なシーンになっていますが、利用可能なデータの規模により、実際のブレークスルーは阻止されています。対話の信念の状態と対話のアクションでラベル付けされたオープンソースのデータセットとは別に、この作業の貢献は2つあります。1つは、データ収集手順の詳細な説明です。データ構造と分析の要約が提供されます。 
[ABSTRACT]マルチドメインウィザード-オンスデータセット（multiwoz）は、複数のカテゴリとトピックにまたがる人間-人間-人間-会話の完全にラベル付けされたコレクションです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-09-29">
        <br>2018-09-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Adaptation of a Lexical Organization for Social Engineering Detection
  and Response Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_5.html">
      Adaptation of a Lexical Organization for Social Engineering Detection
  and Response Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このパラダイムは、タスク固有のパフォーマンスを向上させるためのリソース適応への体系的かつ効率的なアプローチを示しています。レキシカル構成の改良による質問/フレーミング検出の改善を示し、質問/フレーミング検出パフォーマンスが向上するにつれて、応答生成が質的に向上することを示しています。ソーシャルエンジニアリングの検出と応答生成をサポートするために、字句概念構造に基づく拡張可能な辞書開発のパラダイムを提示します。 
[要旨]私たちは質問とフレーミング（リスク/報酬）のネットワークを活用します。ソーシャルネットワーキングサイトを使用してより良い環境を開発します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning Geometric Word Meta-Embeddings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_6.html">
      Learning Geometric Word Meta-Embeddings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案された潜在空間は、2つの特定の幾何学的変換-直交回転とマハラノビスメトリックスケーリングから生じます。私たちのフレームワークは、埋め込みを共通の潜在空間に変換します。たとえば、（特定の単語の）異なる埋め込みの単純な平均はいくつかの単語の類似性と単語の類似性のベンチマークに関する実証結果は、提案されたフレームワークの有効性を示しています。 
[要約]提案されたフレームワークは埋め込みを潜在的な空間に変換します。この概念は初めて提案されました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Study of Cross-Lingual Ability and Language-specific Information in
  Multilingual BERT -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_7.html">
      A Study of Cross-Lingual Ability and Language-specific Information in
  Multilingual BERT
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      潜在表現を操作することにより、多言語BERTの出力言語を制御し、教師なしのトークン変換を実現できます。さらに、観察に基づいて、多言語BERTのクロスリンガル能力を改善するための計算コストは安いが効果的なアプローチがあることを示します。 ..また、多言語BERTの言語固有の情報も確認します。 
[要約]クロスリンガル能力に関する既存の文献を補足するための詳細な実験的研究を提供しました。データサイズとコンテキストウィンドウサイズが転送可能性の重要な要素であることを発見しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Regularized Context Gates on Transformer for Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_8.html">
      Regularized Context Gates on Transformer for Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、最初にソースコンテキストとターゲットコンテキストを特定し、Transformerでソースとターゲットの寄与を制御するためのゲートメカニズムを導入する方法を提供します。4つの翻訳データセットに対する広範な実験により、提案されたモデルが平均で1.0 BLEUスコアのゲインを得ることが実証されています。強力な変圧器ベースライン..さらに、ゲートメカニズムのバイアス問題をさらに減らすために、この論文では、点ごとの相互情報を使用して自動的に生成される監視機能を使用してゲートの学習をガイドする正則化手法を提案します。 
[ABSTRACT]新しい論文では、ゲートの学習をガイドするための正則化手法を提案しています。これらは、高度なトランスフォーマネットワークに変換する必要があります。この手法は、ゲートメカニズムのバイアス問題をさらに減らすために必要です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-29">
        <br>2019-08-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The State and Fate of Linguistic Diversity and Inclusion in the NLP
  World -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_9.html">
      The State and Fate of Linguistic Diversity and Inclusion in the NLP
  World
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーを通じて、ACLコミュニティにここで強調した苦境の解決に優先順位を付けて、言語が取り残されないように説得しようと試みます。現在のモデルとシステムの「言語にとらわれない」状態。このホワイトペーパーでは、言語の種類、リソース、NLP会議での表現の関係を調べて、さまざまな言語が時間とともにたどってきた軌跡を理解します。 
[ABSTRACT]世界の7000を超える言語の数は、言語技術とアプリケーションで表されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-task Learning for Voice Trigger Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_10.html">
      Multi-task Learning for Voice Trigger Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、ベースラインシステムにとって難しいサンプルの非常に小さなデータセットを収集します。この段階で検出が行われた場合、候補の音声セグメントは、セグメントがトリガーを含んでいることを確認するために、より大きく複雑なモデルによって再スコアリングされます。私たちの結果は、提案されたモデルが、追加のパラメーターを必要としないさまざまな困難なテスト条件の\ emph {なし}で、ベースラインと比較してエラーを半分に削減することを示しています。 
[要約]研究はマンチェスター大学によって実施されました。特定のキーワードまたはトリガーフレーズのトレーニング例に基づいています。これにより、トリガーフレーズ固有のトレーニングデータが不足します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-26">
        <br>2020-01-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Adversarial Training for Large Neural Language Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_11.html">
      Adversarial Training for Large Neural Language Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、敵対的な事前トレーニングによって汎化と堅牢性の両方を向上できることを示します。敵対的なトレーニングによって堅牢性を強化できますが、過去の作業では一般化が損なわれることがよくあります。自然言語処理（NLP）では、大きな神経言語モデルを事前にトレーニングBERTなどは、さまざまなタスクの一般化において印象的な利得を示しており、敵対的な微調整からさらに改善されています。 
[ABSTRACT]一般的なアルゴリズムalum（大規模な神経言語モデルの敵対的訓練）
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Practical Guide to Studying Emergent Communication through Grounded
  Language Games -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_12.html">
      A Practical Guide to Studying Emergent Communication through Grounded
  Language Games
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実世界について通信するための豊富なシステムが出現する実験をセットアップすることは、マルチエージェント実験の実行、センサーやアクチュエーターとの対話、意味構造の概念化と解釈のためにさまざまなソフトウェアコンポーネントを必要とするため、主要な企業です。そして、これらの意味構造と言語的発話の間のマッピングに使用します。この論文の目的は2つあります。一方では、Babelソフトウェアシステムを拡張する高レベルのロボットインターフェースを導入し、初めて提供するツールキットを提供します。高度な接地言語ゲーム実験の実行に関連する各サブタスクを処理するための柔軟なモジュール。 
[ABSTRACT]実験には、一連の「言語ゲーム」に参加するエージェントの集団が含まれます。これらには、予防接種、予防接種の相互作用、センサーやアクチュエーターと接続する機能が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Taming the Expressiveness and Programmability of Graph Analytical
  Queries -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_13.html">
      Taming the Expressiveness and Programmability of Graph Analytical
  Queries
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、\ flashの表現力と、満足のいく実行時間を達成する複雑なアルゴリズムをプログラミングするその能力を示しています。既存の作業は、これらの見方の満足のいくカバレッジを達成しました。コード生成に基づいて\ flashの実装を提供し、代表的なクエリを使用してネイティブC ++コードおよび既存のDSLと比較します。 
[ABSTRACT]これは分析クエリの分析に基づいています。これらは10年間の観察に基づいています。代表的なアルゴリズムを使用して、さまざまな言語と比較します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Geometry-aware Domain Adaptation for Unsupervised Alignment of Word
  Embeddings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_14.html">
      Geometry-aware Domain Adaptation for Unsupervised Alignment of Word
  Embeddings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この視点は、2つの言語空間の2次情報を揃えることを目的としています。経験的に、提案されたアプローチは、複数の言語ペアにまたがるバイリンガル辞書誘導タスクに基づく最先端の最適なトランスポートベースのアプローチよりも優れています。二重確率多様体の形状により、提案された定式化に効率的なリーマン共役勾配アルゴリズムを使用できます。 
[要約]私たちのアプローチは、二重学習行列の道を越えた領域適応問題として、整列学習問題を定式化します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On the Language Neutrality of Pre-trained Multilingual Representations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_15.html">
      On the Language Neutrality of Pre-trained Multilingual Representations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、並列文の言語識別と単語の配置について最先端の精度に到達する方法を示します。文脈依存の埋め込みは、デフォルトでは中程度の言語中立のみですが、より強力な言語を実現するための2つの簡単な方法を示します中立性：1つ目は、言語の表現の監視なしのセンタリングによるもの、2つ目は、小さな並列データに明示的な投影を当てはめることによるものです。 
[ABSTRACT]以前の研究では、表現のクロスリンガル性を調査しました。代わりに、コンテキストの埋め込みがより言語的で中立であることを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br>2020-04-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Compositionality and Generalization in Emergent Languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_16.html">
      Compositionality and Generalization in Emergent Languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      第二に、出現言語の構成性の程度と一般化する能力との間に相関関係はありません。新しい学習者が元のエージェントとアーキテクチャが異なる場合でも、新しい学習者はより簡単にそれを見つけられます。自然言語を使用すると、\と呼ばれるプロパティである体系的な規則に従って部分を表す式を組み合わせることにより、新しい複合概念を参照できます。強調{構成性}。 
[要約]言語はディープマルチエージェントシミュレーションで出現しています。新しい複合概念を参照するように翻訳できます。識別可能な言語を見つけるチャンスがあります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Simple Approach to Learning Unsupervised Multilingual Embeddings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_17.html">
      A Simple Approach to Learning Unsupervised Multilingual Embeddings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたアプローチは、バイリンガルの語彙誘導、クロスリンガルの単語の類似性、多言語のドキュメント分類、および多言語の依存解析などのさまざまなタスクで驚くほど優れたパフォーマンスを実現します。アプローチ..対照的に、上記の2つのサブ問題を分離し、既存の手法を使用して個別に解決する、単純な2段階のフレームワークを提案します。 
[要約]提案されたアプローチは、さまざまな言語で優れたパフォーマンスを提供します。これには、共有された多言語スペースへのすべての言語のdecolingual埋め込みが含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-10">
        <br>2020-04-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Gated Convolutional Bidirectional Attention-based Model for Off-topic
  Spoken Response Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_18.html">
      Gated Convolutional Bidirectional Attention-based Model for Off-topic
  Spoken Response Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、新しいネガティブサンプリング法もトレーニングデータを補強するために提案されています。このホワイトペーパーでは、見られたプロンプトと目に見えないプロンプトの両方に高いオフトピック想起を伴うオフトピック音声応答検出の新しいアプローチを提案します。実験結果は、私たちの新しいアプローチは、目に見えるプロンプトと目に見えないプロンプトの両方について、トピック外の応答を非常に高いトピック上の想起率で検出することで大幅な改善を実現できます。 
[ABSTRACT] off-見られたプロンプトとトレーニングプロセス中に見えないプロンプトで高い再現率を達成するには、トピック音声応答検出アルゴリズムが必要です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CHiME-6 Challenge:Tackling Multispeaker Speech Recognition for
  Unsegmented Recordings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_19.html">
      CHiME-6 Challenge:Tackling Multispeaker Speech Recognition for
  Unsegmented Recordings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、セグメント化されたマルチスピーカー音声認識（トラック1）とセグメント化されていないマルチスピーカー音声認識（トラック2）の両方に対するCHiME-6チャレンジのベースラインについて説明します。新しいチャレンジは、以前のCHiME-5チャレンジを再検討し、遠くの問題をさらに考慮します。日常の家庭環境でのマルチマイクによる会話型音声のダイアライゼーションと認識..注目すべきことに、トラック2は、セグメンテーション強化されたオープンソースベースラインの完全なセットを備えた、セグメント化されていないマルチスピーカー音声認識シナリオに取り組むコミュニティでの最初のチャレンジアクティビティであり、スピーチの強化、スピーカーのダイアライゼーションを提供します。 、および音声認識モジュール。 
[ABSTRACT]新しい課題は以前のチャイムを再訪します-5つの課題。それはさらに、日常の家庭環境における遠くのマルチマイク会話音声のダイアライゼーションと認識の問題を考慮します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: MPNet: Masked and Permuted Pre-training for Language Understanding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_20.html">
      MPNet: Masked and Permuted Pre-training for Language Understanding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      MPNetは、置換された言語モデリング（BERTのMLMと比較）を通じて予測トークン間の依存関係を活用し、補助的な位置情報を入力として使用して、モデルに完全な文を表示させ、位置の不一致（XLNetのPLMと比較）を削減します。 XLNetは文の完全な位置情報を活用していないため、事前トレーニングと微調整の間の位置の不一致に悩まされていると主張します。大規模なデータセット（160GB以上のテキストコーパス）でMPNetを事前トレーニングし、微調整しますさまざまなダウンストリームタスク（GLUE、SQuADなど）。 
[ABSTRACT] xlnetは、この問題に対処するための事前トレーニング用に置換言語モデリング（plm）を導入しています。bertとxlnetの利点を継承し、それらの制限を回避する新しい事前トレーニング方法であるmpnetを提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Incorporating External Knowledge through Pre-training for Natural
  Language to Code Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_21.html">
      Incorporating External Knowledge through Pre-training for Natural
  Language to Code Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      コードとリソースはhttps://github.com/neulab/external-knowledge-codegen。で入手できます。開発者は通常、コードを書くときにWeb上のリソースを取得するという直感に動機付けられ、2種類の外部を組み込むことの有効性を探りますNL-to-code生成に関する知識：オンラインプログラミングQAフォーラムStackOverflowおよびプログラミング言語APIのドキュメントから自動的にマイニングされたNL-コードペアコード生成テストベッドCoNaLaでの最新の絶対BLEUスコアは最大2.2％。 
[要約] 2種類の外部知識を組み合わせてnlからコードへの生成の有効性を調査します。コードとリソースはwwwで入手できます。 githubの目的
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Data-to-Text Generation with Dynamic Content Planning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_22.html">
      Neural Data-to-Text Generation with Dynamic Content Planning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの問題を緩和するために、NDPという略語のダイナミックコンテンツプランニングを使用したニューラルデータからテキストへの生成モデルを提案します。さらに、使用されたデータのエントリ全体を次から順に再構築できる新しい目的関数を使用して再構築メカニズムを設計します。生成されたテキストの正確さを支援するデコーダーの隠された状態。人間の評価結果は、提案されたNDPによって生成されたテキストが、ほとんどの時間でNCPによって生成された対応するテキストよりも優れていることを示しています。 
[要約]カナダのモデルは、以前に生成されたテキストを使用して、指定された構造化データから適切なエントリを設計できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br>2020-04-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Language as a Cognitive Tool to Imagine Goals in Curiosity-Driven
  Exploration -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_23.html">
      Language as a Cognitive Tool to Imagine Goals in Curiosity-Driven
  Exploration
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人間と同じように、私たちのエージェントは、言語の構成性を使用して、子供の言語習得の構築文法モデルに基づいたアルゴリズムを使用して、既知の目標を構成することによって新しい目標を生成します。 ..自分の目標を想像するとき、エージェントは報酬関数のゼロショット一般化を活用して、想像された目標をさらにトレーニングし、その動作を改善します。 
[ABSTRACT]一連の動作を自律的に構築し、さまざまなタイプの汎化に対して適切なゼロショット汎化プロパティを示します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-21">
        <br>2020-02-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Variational Inference for Learning Representations of Natural Language
  Edits -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_24.html">
      Variational Inference for Learning Representations of Natural Language
  Edits
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これを念頭に置いて、変分推論を使用してベクトル表現の連続的な潜在空間を学習し、ドキュメント編集プロセスに関する根本的な意味情報を取得する新しいアプローチを提案します。ドキュメント編集は、情報生成の普及コンポーネントになりました編集を効率的に保存および適用できるようにするバージョン管理システムを使用します。さらに、これまで直接人間の入力に大きく依存していた編集表現の標準化された自動評価を容易にするために、特別に設計された一連の下流タスクPEERも提案します。自然言語処理のコンテキストで編集表現の品質を測定します。 
[要約]編集の分散連続表現を学習するタスクが最近提案されました。これには、同じ機能を明示的にモデル化する潜在変数が含まれています。一連のダウンストリーム編集、ピア、コンテキストで編集表現の品質を測定するように特別に設計されています自然言語処理
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: #MeTooMA: Multi-Aspect Annotations of Tweets Related to the MeToo
  Movement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_25.html">
      #MeTooMA: Multi-Aspect Annotations of Tweets Related to the MeToo
  Movement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      データ収集と注釈プロセスの詳細な説明を示します。最後に、このデータセットの潜在的な使用例をいくつか示します。言語的側面：関連性、スタンス、悪意のある表現、皮肉、および対話行為。 
[ABSTRACT]データ収集と注釈プロセスの詳細な説明を提示します。地理的分布、ラベルの相関、キーワードの観点からデータを使用します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-14">
        <br>2019-12-14
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Question Classification with Deep Contextualized Transformer -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_26.html">
      Question Classification with Deep Contextualized Transformer
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      質問と回答の問題の最新の作業は、スタンフォードパースツリーを使用することです。これは、新しい方法がQA問題をより高い精度で解決するのにより効果的であることを示しています。また、問題の回答の正確さと効率について、さまざまなモデルの影響を調査します。 
[ABSTRACT]以前の作業に基づいて構築し、質問と回答の問題を処理するための新しい方法を開発します。問題の回答の正確さと効率について、さまざまなモデルの影響も調査します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-17">
        <br>2019-10-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SPECTER: Document-level Representation Learning using Citation-informed
  Transformers -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/cs.CL/paper_27.html">
      SPECTER: Document-level Representation Learning using Citation-informed
  Transformers
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      BERTのような最近のTransformer言語モデルは強力なテキスト表現を学習しますが、これらのモデルはトークンレベルおよび文レベルのトレーニング目標を対象としており、ドキュメントレベルの関連性に関する情報を活用しないため、ドキュメントレベルの表現力が制限されます。は、ベンチマークでさまざまな競争力のあるベースラインを上回っています。さらに、ドキュメントレベルのモデルに関するさらなる研究を促進するために、引用予測からドキュメントの分類および推奨に至るまでの7つのドキュメントレベルのタスクで構成される新しい評価ベンチマークであるSciDocsを導入しています。 
[要旨]科学文書の文書レベルの埋め込みを生成する新しい方法であるスペクターを提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-15">
        <br>2020-04-15
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Music Gesture for Visual Sound Separation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/eess.AS/paper_0.html">
      Music Gesture for Visual Sound Separation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近のディープラーニングアプローチは、視覚的な音の分離タスクで印象的なパフォーマンスを達成しました。これに対処するために、音楽家が音楽を演奏するときの身体と指の動きを明示的にモデル化するキーポイントベースの構造化表現「Music Gesture」を提案します。 ）; 2）ピアノ、フルート、トランペットのデュエットのための効果的なホモ音楽分離のための新しい能力。これは、私たちの知る限りでは、他の方法では達成できなかったものです。 
[ABSTRACT]これらのアプローチは、主に外観とモーションフローモデルのようなオプティカルフローに基づいて構築されています。これらには、複数の機器を分離するために使用できる視覚的な分離が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-task Learning for Voice Trigger Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/eess.AS/paper_1.html">
      Multi-task Learning for Voice Trigger Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、ベースラインシステムにとって困難な例の非常に小さなデータセットを収集します。この研究では、これらのセカンドパス検出器のアーキテクチャと設計に注目します。1つ目は、検出器が複雑に配置されていることです。外部ノイズのある音響環境と、デバイス自体による大きな再生。 
[要約]研究はマンチェスター大学によって実施されました。特定のキーワードまたはトリガーフレーズのトレーニング例に基づいています。これにより、トリガーフレーズ固有のトレーニングデータが不足します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-26">
        <br>2020-01-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CHiME-6 Challenge:Tackling Multispeaker Speech Recognition for
  Unsegmented Recordings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/eess.AS/paper_2.html">
      CHiME-6 Challenge:Tackling Multispeaker Speech Recognition for
  Unsegmented Recordings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、セグメント化されたマルチスピーカー音声認識（トラック1）とセグメント化されていないマルチスピーカー音声認識（トラック2）の両方に対するCHiME-6チャレンジのベースラインについて説明します。 ..第1、第2、第3、第4、第5のCHiMEチャレンジの成功に続いて、第6回のCHiME音声分離および認識チャレンジ（CHiME-6）を開催します。 
[ABSTRACT]新しい課題は以前のチャイムを再訪します-5つの課題。それはさらに、日常の家庭環境における遠くのマルチマイク会話音声のダイアライゼーションと認識の問題を考慮します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: A pilot study of assisting IVF by personalized Endo-Gym exercises -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-21/biorxiv.physiology/paper_0.html">
      A pilot study of assisting IVF by personalized Endo-Gym exercises
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このプログラムは、不規則な期間や痛みを伴う期間、骨盤臓器脱（POP）や失禁など、他の婦人科の症状も緩和することができ、一般的な健康のための定期的な体力管理として女性によって選択されることもよくあります。 Endo-Gymのメリットを合理的に適用し、このアプローチをIVFの有益な補完として、そしておそらくARTの他のブランチとして導入することを可能にします。251歳の女性、40代の女性を多く含む私たちの経験に基づいて、ここでEndo-Gymメソッド（内分泌体操用）は、個別の身体運動、生殖能力を最適化する食事療法と個人的なコーチングの組み合わせで、おそらく反復サイクルによって引き起こされる苦痛を軽減し、生殖能力に影響する問題などを軽減することによって、体外受精の成功を大幅に高めることができる多嚢胞性卵巣症候群（PCOS）および早期卵巣不全（POF）として。 
[ABSTRACT] ivf治療サイクルは、財政的、肉体的、心理的負担が大きくなります。ただし、出産は4回に1回未満です。また、骨盤臓器脱や失禁などの問題も緩和できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br>2020-04-20
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
