<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-12-24の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Incremental Text-to-Speech Synthesis Using Pseudo Lookahead with Large
  Pretrained Language Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.SD/paper_0.html">
      <font color="black">Incremental Text-to-Speech Synthesis Using Pseudo Lookahead with Large
  Pretrained Language Model</font>
    </a>
  </h2>
  <font color="black">観測されていない将来の文（以下、「先読み」）をあまり利用しない低遅延設定で高品質の音声を生成することは困難です。一般に、増分TTSは遅延間のトレードオフの影響を受けます。この研究では、言語モデルで生成された疑似先読みを使用して、待ち時間を増やすことなく将来のコンテキスト情報を検討するインクリメンタルTTSメソッドを提案します。 
[ABSTRACT]インクリメンタルttsは、遅延と出力音声の品質の間のトレードオフの影響を受けます。この方法では、言語モデルで作成された疑似先読みを使用して、遅延を増やすことなく将来のコンテキスト情報を検討します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Meta Sampling for Multilingual Low-Resource Speech
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.SD/paper_1.html">
      <font color="black">Adversarial Meta Sampling for Multilingual Low-Resource Speech
  Recognition</font>
    </a>
  </h2>
  <font color="black">この問題を解決するために、メタ学習は各ソース言語のASRを多くの小さなASRタスクに定式化し、異なるソース言語からのすべてのタスクのモデル初期化をメタ学習して、見えないターゲット言語の高速適応にアクセスします。最後に、2つの多言語での実験結果データセットは、MML-ASRにAMSを適用するとパフォーマンスが大幅に向上することを示し、他の低リソース音声タスクや転移学習ASRアプローチへのAMSの適用性も示しています。ただし、ソース言語が異なると、その量と難易度は大きく異なります。それらの異なるデータスケールと多様な音声システムは、タスクの量とタスクの難しさの不均衡の問題につながり、したがって多言語メタ学習ASR（MML-ASR）の失敗につながります。 
[要約]各ソース言語について、質問の損失が大きい場合、そのタスクは、量と難易度の観点からasrモデルをトレーニングするために十分にサンプリングされていないことを意味します。mml-asrのリソースは学習状況をマスターできるため、予測できます。各言語の良好なタスクサンプリング確率</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Speaker Diarization as Post-Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.SD/paper_2.html">
      <font color="black">End-to-End Speaker Diarization as Post-Processing</font>
    </a>
  </h2>
  <font color="black">互いの弱点を補うために、クラスタリングベースの方法で得られた結果の後処理として、2スピーカーのエンドツーエンドダイアリゼーション法を使用することを提案します。一方、一部のエンドツーエンドダイアリゼーションメソッドは、問題をマルチラベル分類として扱うことにより、重複する音声を処理できます。結果から2人の話者を繰り返し選択し、2人の話者の結果を更新して、重複領域を改善します。 
[ABSTRACT]ダイアリゼーション方式は、フレームを話者数のクラスターに分割します。これは、各フレームが1人の話者に割り当てられるため、通常、重複する音声を処理できないことを意味します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-18">
        <br><font color="black">2020-12-18</font>
      </time>
    </span>
</section>
<!-- paper0: A Principle Solution for Enroll-Test Mismatch in Speaker Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.SD/paper_3.html">
      <font color="black">A Principle Solution for Enroll-Test Mismatch in Speaker Recognition</font>
    </a>
  </h2>
  <font color="black">結果は、提案されたSDアプローチが非常に効果的であり、一般的に採用されているが理論的には最適ではないアドホックマルチ条件トレーニングアプローチよりも優れていることを示しました。このアプローチは正規化尤度（NL）スコアリングフレームワークに基づいており、登録条件とテスト条件の両方の統計が正確である場合、理論的に最適です。このペーパーでは、この問題を解決するための統計分解（SD）アプローチを紹介します。 
[概要]調査は、異なるタイプの不一致を持つ3つのデータセットで実施されました。これには、物理チャネルの不一致と発話スタイルの不一致が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Code Switching Language Model Using Monolingual Training Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.SD/paper_4.html">
      <font color="black">Code Switching Language Model Using Monolingual Training Data</font>
    </a>
  </h2>
  <font color="black">結果は、RNNベースの言語モデルの出力埋め込みで平均二乗誤差（MSE）を使用して一貫して改善されました。結果から、トレーニングで単言語データの代替バッチを使用すると、CS言語モデルの複雑さが軽減されたと結論付けられます。リカレントニューラルネットワーク（RNN）モデルは、シーケンシャルデータの予測に最適です。 
[要約]提案された方法は、コードスイッチトレーニングデータを使用した言語モデルの微調整に匹敵しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: CN-Celeb: multi-genre speaker recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.SD/paper_5.html">
      <font color="black">CN-Celeb: multi-genre speaker recognition</font>
    </a>
  </h2>
  <font color="black">次に、このデータセットを使用して、マルチジャンルの現象、特に話者認識に対するマルチジャンルの課題の影響、および貴重なマルチジャンルのデータをより効率的に利用する方法について包括的な調査を実施します。既存のマルチジャンルのコーパスは、サイズが制限されているだけでなく、制御された条件下で記録されているため、マルチジャンルの問題に関する決定的な研究をサポートすることはできません。話者認識の研究は、野生の条件の脆弱性に対処するために拡張されています。ジャンルの不一致は、おそらく最も難しいものです。たとえば、会話や歌の音声でテストしながら、音声を読むことで登録します。 
[要約]この不一致は、複雑で複合的なセッション間の変動につながります。これらは不可欠です-話し方、生理学的状態、および外因性です。しかし、マルチスピーカーは、影響を受ける人の数がわかりません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: StainNet: a fast and robust stain normalization network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/eess.IV/paper_0.html">
      <font color="black">StainNet: a fast and robust stain normalization network</font>
    </a>
  </h2>
  <font color="black">提案された方法は、最先端の方法よりも優れており、より良い精度と画質を実現します。この論文では、1.28Kのパラメータのみを持つ完全に1x1の畳み込み染色正規化ネットワークを提案します。ただし、従来の方法は参照に大きく依存します。画像、および現在の深層学習ベースの方法では、色の強度またはテクスチャが誤って変更される可能性があります。 
[ABSTRACT]手法を使用して、コンピューター支援診断（cad）システムのパフォーマンスを向上させることができます。ただし、従来の方法は参照画像に大きく依存します。現在の深層学習ベースの方法では、色の強度やテクスチャが誤って変化する可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Comparison of Classification Algorithms Towards Subject-Specific and
  Subject-Independent BCI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/eess.IV/paper_1.html">
      <font color="black">Comparison of Classification Algorithms Towards Subject-Specific and
  Subject-Independent BCI</font>
    </a>
  </h2>
  <font color="black">したがって、被験者ごとに異なる分類アルゴリズムが必要になる場合があります。SIモデルはパフォーマンスの変動が少ないですが、比較的大きなサンプルサイズが利用可能な場合にのみ使用する必要があります。SS設計は特定の被験者にとってより有望に聞こえますが、SIアプローチは精神的または肉体的に問題のあるユーザーにとってより便利です。 
[概要]たとえば、被験者-中程度（si）の設計は、事前のキャリブレーションなしで複数のユーザーに適応できるため、注目を集めています。システムパフォーマンスの2つの主要な要因は、分類アルゴリズムと利用可能なデータの品質です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Multiclass Spinal Cord Tumor Segmentation on MRI with Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/eess.IV/paper_2.html">
      <font color="black">Multiclass Spinal Cord Tumor Segmentation on MRI with Deep Learning</font>
    </a>
  </h2>
  <font color="black">ここでは、脊髄腫瘍セグメンテーションタスクに適合したモデルを調整します。腫瘍、空洞、および浮腫のセグメンテーション（単一クラスとして）は、ダイススコアの76.7 $ \ pm $ 1.5％に達し、腫瘍のみのセグメンテーションに達しました。 61.8 $ \ pm $ 4.0％ダイススコア..モデルは最初に脊髄を見つけ、バウンディングボックス座標を生成します。 
[概要]外科医は腫瘍、浮腫、空洞を特定できます。これは、脊髄腫瘍セグメンテーションの最初の完全自動深層学習モデルです。カスタムデータを使用して数秒で実行できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: RAP-Net: Coarse-to-Fine Multi-Organ Segmentation with Single Random
  Anatomical Prior -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/eess.IV/paper_3.html">
      <font color="black">RAP-Net: Coarse-to-Fine Multi-Organ Segmentation with Single Random
  Anatomical Prior</font>
    </a>
  </h2>
  <font color="black">私たちの方法を訓練および評価するために、十分に注釈が付けられた13の臓器を備えた100の患者ボリュームからなる臨床研究コホートが使用されます。複数の臓器のグローバルな事前コンテキストの抽出から始まる粗いパイプラインから細かいパイプラインを提案します。低解像度の粗いネットワークを使用した3Dボリュームに続いて、複数の臓器に対応するモデルではなく、単一の洗練されたモデルを使用してすべての腹部臓器をセグメント化する細かいフェーズが続きます。単一の自動コンテキストを使用する提案手法は、現状よりも優れています。平均ダイススコア84.58％対81.69％（p &lt;0.0001）の13モデルのアート。 
[ABSTRACT]高解像度で単一臓器の精密化を実行するために使用される13のモデル。解剖学的位置と境界情報を保持するために、対応する抽出パッチとともに腹部の事前を使用しました。また、4分割交差検証を使用してアルゴリズムをテストしました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: INTEL-TAU: A Color Constancy Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/eess.IV/paper_4.html">
      <font color="black">INTEL-TAU: A Color Constancy Dataset</font>
    </a>
  </h2>
  <font color="black">さらに、このペーパーでは、提案されたデータセットに対するいくつかの色恒常性アプローチのベンチマークを行います。Canon5DSR、Nikon D810、Sony IMX135の3つの異なるカメラモデルを使用してキャプチャされたさまざまなシーンにより、データセットはカメラとシーンの不変性を評価するのに適しています。さまざまな照明推定手法..さらに、生データの修正バージョンと未修正バージョンの両方が提供されているため、モバイル画像のカラーシェーディングの効果をINTEL-TAUデータセットで評価できます。 
[概要]このデータセットは、インテル-タウと呼ばれ、7022枚の画像が含まれています。これにより、情報に利用できる最大の高解像度データセットになります。データセットには、3種類の画像が含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-23">
        <br><font color="black">2019-10-23</font>
      </time>
    </span>
</section>
<!-- paper0: Chest x-ray automated triage: a semiologic approach designed for
  clinical implementation, exploiting different types of labels through a
  combination of four Deep Learning architectures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/eess.IV/paper_5.html">
      <font color="black">Chest x-ray automated triage: a semiologic approach designed for
  clinical implementation, exploiting different types of labels through a
  combination of four Deep Learning architectures</font>
    </a>
  </h2>
  <font color="black">病院のワークフローにうまく統合できる臨床的に有用なツールの入手に焦点を当てました。各所見について、最も適切なタイプのグラウンドトゥルースラベルを定義し、公共の胸部X線データセットと私たちの胸部X線データセットからの画像を組み合わせた4つのトレーニングデータセットを構築しました。施設のアーカイブ..材料と方法：専門家の意見に基づいて、4つの標的胸部X線所見、すなわち肺混濁、骨折、気胸、胸膜滲出液を選択しました。 
[概要]この作品は、異なる畳み込みアーキテクチャのレイトフュージョンに基づくディープラーニング手法を示しています。これにより、簡単な実装で異種データを使用したトレーニングが可能になり、独立したテストデータでのパフォーマンスが評価されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Contrast Computed Tomography Healthy Kidney Atlas -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/eess.IV/paper_6.html">
      <font color="black">Multi-Contrast Computed Tomography Healthy Kidney Atlas</font>
    </a>
  </h2>
  <font color="black">したがって、非造影CTと初期動脈、後期動脈、静脈および遅延造影CT全体で腎臓に特に最適化された高解像度CT後腹膜アトラスを提案しました。ただし、マルチ造影CT用の腹部および後腹膜臓器アトラスフレームワークはありません。造影CT ..腹部コンピュータ断層撮影（CT）では、体の大きさ、性別、およびイメージングプロトコル全体で腎臓の形態計測と外観にかなりの正常な変動があります。 
[概要]新しい高解像度のct後腹膜アトラスは、非造影CT全体の腎臓用に特別に最適化されています。これにより、集団全体の腎臓の解剖学的構造の変化をよりよく理解できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: GANDA: A deep generative adversarial network predicts the spatial
  distribution of nanoparticles in tumor pixelly -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/eess.IV/paper_7.html">
      <font color="black">GANDA: A deep generative adversarial network predicts the spatial
  distribution of nanoparticles in tumor pixelly</font>
    </a>
  </h2>
  <font color="black">GANDAは、実際の分布を知らなくてもNP分布（R2 = 0.93）と血管外漏出の定量分析を可能にしました。GANDAが腫瘍血管と核の元の画像と同じ空間分解能でNP分布の画像を生成できることを示しました。このモデル影響因子が個々の腫瘍のNP分布にどのように影響するかを調査する機会を提供し、個別化された治療のためのナノ医療の最適化を導く可能性があります。 
[概要]分布解析ネットワーク（ガンダ）を開発しました。ガンダは、腫瘍血管や核の元の画像と同じ空間分解能でnps分布の画像を生成できます。このモデルは、影響因子が個々の腫瘍のnps分布にどのように影響するかを調査する機会を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Focal Frequency Loss for Generative Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/eess.IV/paper_8.html">
      <font color="black">Focal Frequency Loss for Generative Models</font>
    </a>
  </h2>
  <font color="black">この目的関数は、既存の空間損失を補完し、ニューラルネットワークの固有の核心による重要な周波数情報の損失に対して大きなインピーダンスを提供します。深いニューラルネットワークを使用してフォトリアリスティックな画像を作成する生成モデルの目覚ましい成功にもかかわらず、ギャップは依然として存在する可能性があります特に周波数領域で、実際の画像と生成された画像の間で..知覚品質と定量的パフォーマンスの両方でさまざまなベースラインを改善するために、焦点周波数損失の多様性と有効性を示します。 
[要約]提案された損失により、モデルは、簡単な周波数を重み付けすることによって合成するのが難しい周波数成分に動的に焦点を合わせることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Boosting the Channel Attention in Real Image Denoising :
  Sub-band Pyramid Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/eess.IV/paper_9.html">
      <font color="black">Towards Boosting the Channel Attention in Real Image Denoising :
  Sub-band Pyramid Attention</font>
    </a>
  </h2>
  <font color="black">さらに、我々の結果は、ピラミッドレベルがSPAブロックのパフォーマンスにどのように影響し、SPAブロックに対して好ましい一般化機能を示すかを示しています。実際の画像ノイズ除去タスクのチャネルアテンション方法は、特徴チャネル間の依存関係を利用するため、周波数成分フィルタリングメカニズムです。 。既存のチャネルアテンションモジュールは通常、チャネル間の相関関係を学習するための記述子としてグローバル統計を使用します。 
[要約]提案された方法は、ウェーブレットサブバンドピラミッドに基づいています。抽出された特徴の周波数部分をよりきめ細かく再較正します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Diabetic Retinopathy Grading System Based on Transfer Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/eess.IV/paper_10.html">
      <font color="black">Diabetic Retinopathy Grading System Based on Transfer Learning</font>
    </a>
  </h2>
  <font color="black">この論文では、マルチラベル分類に応じた完全ベースのDLCADシステムを紹介します。学習転送は小さなデータセットのトレーニングに非常に役立ちます。提案されたDLCADシステムでは、診断のためにカスタマイズされた効率的なNetモデルを紹介します。 DR疾患の初期および高度なグレード。 
[概要]ディープラーニング（dl）手法に基づく多くのCADシステムが採用されています。提案されたDL CADシステムでは、dr疾患の初期および高度なグレードを診断するためのカスタマイズされた効率的なネットモデルを提示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Prognostic Power of Texture Based Morphological Operations in a
  Radiomics Study for Lung Cancer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/eess.IV/paper_11.html">
      <font color="black">Prognostic Power of Texture Based Morphological Operations in a
  Radiomics Study for Lung Cancer</font>
    </a>
  </h2>
  <font color="black">腫瘍の特徴はCT画像から抽出され、PCAとカプランマイヤー生存分析によって分析されて最も関連性の高いものが選択されます。このため、数学的形態学に基づく操作によって得られた新しいラジオミクスの特徴が提案されます。予後モデルに貢献し、最終的には臨床的意思決定と患者の治療過程に貢献します。 
[要約]予後の特徴の初期の研究は、より効率的な治療につながる可能性があります。それらは、非小細胞肺癌（nsclc）に苦しむ患者のオープンデータベースで実施されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: HDR Denoising and Deblurring by Learning Spatio-temporal Distortion
  Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/eess.IV/paper_12.html">
      <font color="black">HDR Denoising and Deblurring by Learning Spatio-temporal Distortion
  Models</font>
    </a>
  </h2>
  <font color="black">残念ながら、歪んだセンサーの読み取り値のキャプチャには時間がかかります。また、CLEAN HDRビデオが不足しています。まず、代わりに別の関数を学習します。CLEAN-&gt; DISTORTEDは、相関するピクセルノイズ、行と列のノイズ、および少数からのモーションブラーを含むサンプルを生成します。 CLEANセンサーの読み取り値の..これらの2つの制限を克服する方法を提案します。 
[概要]以前のldrの作業では、クリーンな画像と歪んだ画像のペアによって監視され、ブレ除去とノイズ除去（歪んだ-クリーン）を学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: StainNet: a fast and robust stain normalization network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_0.html">
      <font color="black">StainNet: a fast and robust stain normalization network</font>
    </a>
  </h2>
  <font color="black">提案された方法は、最先端の方法よりも優れており、より良い精度と画質を実現します。病理画像は、染色プロセス、オペレーターの能力、スキャナーの仕様の違いにより、色の強度に大きなばらつきがある可能性があります。色の濃さの変動性と予測精度の向上。 
[ABSTRACT]手法を使用して、コンピューター支援診断（cad）システムのパフォーマンスを向上させることができます。ただし、従来の方法は参照画像に大きく依存します。現在の深層学習ベースの方法では、色の強度やテクスチャが誤って変化する可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Coarse-to-Fine Object Tracking Using Deep Features and Correlation
  Filters -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_1.html">
      <font color="black">Coarse-to-Fine Object Tracking Using Deep Features and Correlation
  Filters</font>
    </a>
  </h2>
  <font color="black">さらに、モデルのドリフトを回避しながら外観の変化を学習する更新制御メカニズムを設計しました。過去数年間、深層学習トラッカーは、追跡問題を解決するための興味深いアイデアをもたらしながら刺激的な結果を達成しました。実験結果は、アルゴリズムの堅牢性を示しています。 CNNおよびDCFベースのトラッカーに対して有利に機能します。 
[概要]これは主に、大規模な画像データベースでディープ畳み込みニューラルネットワーク（cnns）をトレーニングすることで得られる深い特徴を学習するためです。それ以来、相関フィルターの識別力を利用して、追跡対象を正確にローカライズします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Lipschitz Constrained GANs via Boundedness and Continuity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_2.html">
      <font color="black">Lipschitz Constrained GANs via Boundedness and Continuity</font>
    </a>
  </h2>
  <font color="black">CNNに$ BC $条件を満たすように強制することにより、畳み込みニューラルネットワーク（CNN）に基づくGANの実用的に非常に効果的な実装を提示します（BC-GAN）。理論的には、BC条件を満たす弁別器を備えたGANがLipschitz制約..勾配ペナルティやスペクトル正規化を含む最近の手法と比較して、BC-GANはパフォーマンスが優れているだけでなく、計算の複雑さも低いことを示しています。 
[概要]リプシッツは、リプシッツのトレーニングの安定性を確保するために不可欠です。リプシッツではなく、トレーニングの安定性を確保するために不可欠です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-03-16">
        <br><font color="black">2018-03-16</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring Instance-Level Uncertainty for Medical Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_3.html">
      <font color="black">Exploring Instance-Level Uncertainty for Medical Detection</font>
    </a>
  </h2>
  <font color="black">実験は、LUNA16データセットで肺結節を検出するために実施されます。これは、結節と非結節の間に有意な意味のあいまいさが存在する可能性があるタスクです。結果は、両方のタイプの組み合わせを利用することにより、評価スコアが84.57％から88.86％に向上することを示しています。分散..結節の検出例を視覚化して、この方法の利点をさらに説明します。 
[ABSTRACT]パフォーマンスの向上は、調査に従って不確実性をモデル化することで可能になりました。これらのツールを使用すると、この方法の利点を説明できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Overcoming False Positives in Visual Relationship Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_4.html">
      <font color="black">Towards Overcoming False Positives in Visual Relationship Detection</font>
    </a>
  </h2>
  <font color="black">BNPSは、提案を5つの明確に定義されたサブクラスに分割し、逆頻度に従ってバランスの取れたトレーニング分布を生成します。空間的曖昧さが高い低頻度の挑戦的な誤検出提案をさらに解決するために、2つの側面でSABRAの空間モデリング能力を向上させます。 ：オブジェクトのグローバルな空間的相互作用をモデル化するシンプルで効率的なマルチヘッド異種グラフアテンションネットワーク（MH-GAT）、およびローカルな空間構成を学習する空間マスクデコーダー..BNPSは、より簡単な最適化ランドスケープを提供し、数を大幅に削減します誤検知の。 
[要約]トレーニングでは、関係提案の分布は非常に不均衡です。sabraは、ミニバッチサンプリングのためのバランスの取れたネガティブ提案サンプリング（bnps）戦略を開発します。sabraはsotaメソッドを大幅に上回っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Training data-efficient image transformers & distillation through
  attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_5.html">
      <font color="black">Training data-efficient image transformers & distillation through
  attention</font>
    </a>
  </h2>
  <font color="black">さらに、トランスフォーマーに固有の教師と生徒の戦略を紹介します。特にconvnetを教師として使用する場合は、このトークンベースの蒸留の関心を示します。コードとモデルを共有して、この研究ラインでのコミュニティの進歩を加速します。 。 
[概要]ビジュアルトランスフォーマーは、数億の画像で事前トレーニングされています。高価なインフラストラクチャを使用して事前トレーニングされているため、より大きなコミュニティでの採用が制限されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Blur More To Deblur Better: Multi-Blur2Deblur For Efficient Video
  Deblurring -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_6.html">
      <font color="black">Blur More To Deblur Better: Multi-Blur2Deblur For Efficient Video
  Deblurring</font>
    </a>
  </h2>
  <font color="black">次に、隣接するフレームからよりぼやけた画像を合成できるマルチブラーリカレントニューラルネットワーク（MBRNN）を提案し、既存のビデオブレ除去方法でパフォーマンスを大幅に向上させます。最後に、MBRNNからのリカレント特徴マップを接続するマルチスケールデブラーを提案します（ MSDR）は、人気のあるGoProおよびSuデータセットで最新のパフォーマンスを高速かつメモリ効率の高い方法で実現します。まず、アンシャープマスキングに触発され、追加の入力として長時間露光でよりぼやけた画像を使用すると、パフォーマンスが大幅に向上すると主張します。 。 
[概要]新しい方法は、追加の要因として長時間露光でよりぼやけた画像を使用します。新しい方法は、goproおよびsuデータセットのパフォーマンスを向上させるために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Generative 3D Part Assembly via Dynamic Graph Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_7.html">
      <font color="black">Generative 3D Part Assembly via Dynamic Graph Learning</font>
    </a>
  </h2>
  <font color="black">この問題に取り組むために、反復グラフニューラルネットワークをバックボーンとして活用するアセンブリ指向の動的グラフ学習フレームワークを提案します。これは、大まかな方法から細かい方法で順次パーツアセンブリの改良を明示的に実行し、パーツ関係の推論のペアを活用します。パーツグラフ内のパーツの特徴とそれらの関係の両方を動的に調整するためのモジュールとパーツ集約モジュール。3つの強力なベースラインメソッドに対して広範な実験と定量的比較を行い、提案されたアプローチの有効性を示します。 
[概要] 3Dパーツの組み立てのタスクは、剛体の回転と平行移動を含む6自由度のパーツポーズを予測することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-14">
        <br><font color="black">2020-06-14</font>
      </time>
    </span>
</section>
<!-- paper0: Comparison of Classification Algorithms Towards Subject-Specific and
  Subject-Independent BCI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_8.html">
      <font color="black">Comparison of Classification Algorithms Towards Subject-Specific and
  Subject-Independent BCI</font>
    </a>
  </h2>
  <font color="black">SIモデルの場合、LDAとCARTは、それぞれ小さいサンプルサイズと中程度のサンプルサイズで最高の精度を示しましたが、大きなトレーニングサンプルサイズが利用可能な場合、SVMは他の分類器よりも優れていると仮定します。SIモデルはパフォーマンスの変動が少ないですが、比較的大きなサンプルサイズが利用可能な場合にのみ使用する必要があります。したがって、被験者ごとに異なる分類アルゴリズムが必要になる場合があります。 
[概要]たとえば、被験者-中程度（si）の設計は、事前のキャリブレーションなしで複数のユーザーに適応できるため、注目を集めています。システムパフォーマンスの2つの主要な要因は、分類アルゴリズムと利用可能なデータの品質です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Dose Plugin Towards Real-time Monte Carlo Dose Calculation Through
  a Deep Learning based Denoising Algorithm -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_9.html">
      <font color="black">Deep Dose Plugin Towards Real-time Monte Carlo Dose Calculation Through
  a Deep Learning based Denoising Algorithm</font>
    </a>
  </h2>
  <font color="black">この問題に取り組むために、現在のGPUベースのMC線量エンジンにプラグインしてリアルタイムのMC線量計算を可能にする、リアルタイムの深層学習ベースの線量デノイザーを開発しました。その結果、MC線量計算パイプライン全体をGPU MC線量計算と深層学習ベースのノイズ除去の両方を含め、0.15秒以内に完了し、オンライン適応放射線療法などの一部の放射線療法アプリケーションに必要なリアルタイム効率を達成しました。さらに、弱く監視された学習フレームワークを使用してネットワークをトレーニングしました。これにより、必要なトレーニングデータセットのサイズが大幅に削減され、トレーニング済みモデルをさまざまな放射線ビームに迅速に微調整して適応させることができます。 
[ABSTRACT] mc線量計算は、いくつかの臨床アプリケーションで開発されました。これらには、時間がかかるmc線量測定が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Warping of Radar Data into Camera Image for Cross-Modal Supervision in
  Automotive Applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_10.html">
      <font color="black">Warping of Radar Data into Camera Image for Cross-Modal Supervision in
  Automotive Applications</font>
    </a>
  </h2>
  <font color="black">到着方向（DoA）推定、ターゲット検出、セマンティックセグメンテーション、カメラデータからのレーダーパワーの推定など、複数のアプリケーションでフレームワークを示します。DoAアプリケーションに対して広範な評価が行われ、NNベースの優れた品質が提案されています。従来の推定器と比較した推定器..ワーピング操作は正確なシーンフローに依存しているため、さらに、カメラ、リダー、レーダーから供給される新しいシーンフロー推定アルゴリズムを提示し、ワーピング操作の精度を向上させることができます。 
[概要]ワーピング操作は完全に微分可能であるように設計されており、状態を介したエラーの逆伝播を可能にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Multiclass Spinal Cord Tumor Segmentation on MRI with Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_11.html">
      <font color="black">Multiclass Spinal Cord Tumor Segmentation on MRI with Deep Learning</font>
    </a>
  </h2>
  <font color="black">データは、頸部、胸部、および/または腰部をカバーするガドリニウム造影T1強調およびT2強調MRIスキャンを使用して343人の患者から取得されました。モデルは最初に脊髄を見つけ、境界ボックス座標を生成します。マルチクラスセグメンテーションパイプラインは脊髄ツールボックス（https://spinalcordtoolbox.com/）で入手できます。 
[概要]外科医は腫瘍、浮腫、空洞を特定できます。これは、脊髄腫瘍セグメンテーションの最初の完全自動深層学習モデルです。カスタムデータを使用して数秒で実行できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: FcaNet: Frequency Channel Attention Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_12.html">
      <font color="black">FcaNet: Frequency Channel Attention Networks</font>
    </a>
  </h2>
  <font color="black">提案された方法は単純ですが効果的です。既存のチャネル注意方法内に私たちの方法を実装するために計算の1行のコードのみを変更できます。さらに、提案された方法は他のチャネル注意と比較して最先端の結果を達成します。画像分類、オブジェクト検出、およびインスタンスセグメンテーションタスクのメソッド。 
[概要]コードとモデルは、年末までに公開される可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: MG-SAGC: A multiscale graph and its self-adaptive graph convolution
  network for 3D point clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_13.html">
      <font color="black">MG-SAGC: A multiscale graph and its self-adaptive graph convolution
  network for 3D point clouds</font>
    </a>
  </h2>
  <font color="black">この論文では、最大プーリングを採用して、さまざまな縮尺マップの特徴を合成し、点群の特徴を生成します。ニューラルネットワークがローカルの点群の特徴を抽出してその品質を向上させる能力を高めるために、この論文では、マルチスケールを提案します。グラフ生成法と自己適応型グラフ畳み込み法..従来の畳み込みニューラルネットワークは不規則な頂点近傍を持つグラフデータには適用できないため、この論文では、チェビシェフ多項式を使用して不規則な畳み込みフィルターを適合させるsef適応型グラフ畳み込みカーネルを紹介します。最適近似の理論に基づいています。 
[概要]提案された方法は、マルチスケールグラフクラウドシステムを変換できます。ポイントクラウドのマルチスケールシステムを作成するために使用できます。ただし、従来の畳み込みニューラルネットワークはグラフデータには適用されません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Semantic Dictionary Learning for Multi-label Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_14.html">
      <font color="black">Deep Semantic Dictionary Learning for Multi-label Image Classification</font>
    </a>
  </h2>
  <font color="black">DSDLでは、オートエンコーダーを適用してクラスレベルのセマンティクスからセマンティック辞書を生成し、そのような辞書を使用して、畳み込みニューラルネットワーク（CNN）によって抽出された視覚的特徴をラベル埋め込みで表現します。DSDLはシンプルでありながらエレガントです。ラベル、セマンティック、ビジュアルスペースを同時に活用し、それらの間で辞書学習を実行することで調整する方法。3つの人気のあるベンチマークでの広範な実験結果は、私たちの方法が最先端と比較して有望なパフォーマンスを達成することを示しています。 
[概要]最近のいくつかの研究では、マルチラベル画像分類のパフォーマンスを向上させるためにカテゴリのセマンティック情報を活用しようとしました。dsdlでは、オートエンコーダを適用してクラスレベルからセマンティック辞書を生成します。このような辞書は、によって抽出された視覚的特徴を表します。ラベルが埋め込まれた畳み込みニューラルネットワーク（cnn）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding when spatial transformer networks do not support
  invariance, and what to do about it -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_15.html">
      <font color="black">Understanding when spatial transformer networks do not support
  invariance, and what to do about it</font>
    </a>
  </h2>
  <font color="black">最後に、ローカリゼーションネットワークの複雑さと反復的な画像の位置合わせの間の相互作用を調査します。より深いローカリゼーションネットワークのトレーニングは困難ですが、分類ネットワークとパラメータを共有するローカリゼーションネットワークは、深くなるにつれて安定したままであるため、分類の精度が高くなります。ただし、STNは純粋に空間変換を実行するため、一般的な場合、変換された画像の特徴マップを元の画像の特徴マップに揃える機能はありません。 
[ABSTRACT] stnsは、もともとcnn特徴マップを変換するために提案されましたが、変換された画像の特徴マップを元の画像の特徴マップに揃える機能はありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-24">
        <br><font color="black">2020-04-24</font>
      </time>
    </span>
</section>
<!-- paper0: Vehicle Re-identification Based on Dual Distance Center Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_16.html">
      <font color="black">Vehicle Re-identification Based on Dual Distance Center Loss</font>
    </a>
  </h2>
  <font color="black">VeRi-776データセットおよびVehicleIDデータセットという名前の車両再識別の分野でDDCLを適用します。また、その優れた一般化能力を検証するために、MSMT17という名前の個人再識別の分野で一般的に使用される2つのデータセットでも検証します。データセットとMarket1501データセット..具体的には、同じ中心までのユークリッド距離に基づいてピアソン距離を追加します。これにより、同じクラスのすべてのフィーチャが、フィーチャ空間内の超球と超立方体の交点に限定されます。 。 
[要約]この論文では、中心損失の5つの欠点を要約します。それらは、二重距離中心損失（ddcl）を提案することによってそれらすべてを解決しました。提案されたピアソン距離は、中心損失のクラス内コンパクト性を強化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Active Sampling for Accelerated MRI with Low-Rank Tensors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_17.html">
      <font color="black">Active Sampling for Accelerated MRI with Low-Rank Tensors</font>
    </a>
  </h2>
  <font color="black">本論文では、高速MRイメージングのためのアクティブ低ランクテンソルモデルを紹介します。低ランクテンソル構造の利点を利用して、Query-by-Committeeモデルに基づくアクティブサンプリング方法を提案します。磁気共鳴イメージング（MRI）は、医学と生物学に革命をもたらす強力な画像診断法です。3DMRIデータセットの数値実験は、提案された方法の有効性を示しています。 
[要約] MRIの速度はしばしば制限され、その実用性を制約します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: SLAP: Improving Physical Adversarial Examples with Short-Lived
  Adversarial Perturbations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_18.html">
      <font color="black">SLAP: Improving Physical Adversarial Examples with Short-Lived
  Adversarial Perturbations</font>
    </a>
  </h2>
  <font color="black">これにより、敵のパッチと比較して、敵は攻撃をより細かく制御できます。（i）投影は動的にオンとオフを切り替えたり、自由に変更したりできます。（ii）投影はパッチによって課せられる局所性の制約を受けず、検出が困難になります。 ..一時停止の標識の検出に焦点を当て、オブジェクト検出器と交通標識認識タスクの両方を対象とした自動運転シナリオでのSLAPの実現可能性を研究します。..阻止できる敵対的学習を使用して、適応防御器を含む他の防御を評価します。攻撃者の状態が良好な場合でも、攻撃の有効性は最大80％です。 
[ABSTRACT]短命の敵対者の摂動（スラップ）は、光プロジェクターを使用して、敵対者が物理的に堅牢な実世界のaeを実現できるようにする新しい手法です。これにより、敵対者のパッチと比較して、攻撃をより細かく制御できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: RAP-Net: Coarse-to-Fine Multi-Organ Segmentation with Single Random
  Anatomical Prior -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_19.html">
      <font color="black">RAP-Net: Coarse-to-Fine Multi-Organ Segmentation with Single Random
  Anatomical Prior</font>
    </a>
  </h2>
  <font color="black">私たちの方法を訓練および評価するために、十分に注釈が付けられた13の臓器を備えた100人の患者ボリュームからなる臨床研究コホートが使用されます。単一の自動コンテキストを使用する提案された方法は、平均的なダイスを持つ13のモデルで最先端を上回ります。スコア84.58％対81.69％（p &lt;0.0001）..解剖学的事前情報を対応する抽出パッチと組み合わせて、単一モデル内のすべての臓器にわたって高解像度セグメンテーションを実行するための解剖学的位置と境界情報を保持します。 
[ABSTRACT]高解像度で単一臓器の精密化を実行するために使用される13のモデル。解剖学的位置と境界情報を保持するために、対応する抽出パッチとともに腹部の事前を使用しました。また、4分割交差検証を使用してアルゴリズムをテストしました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: IIRC: Incremental Implicitly-Refined Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_20.html">
      <font color="black">IIRC: Incremental Implicitly-Refined Classification</font>
    </a>
  </h2>
  <font color="black">さらに、この設定により、既存の設定では簡単に対処できないいくつかの重要な生涯学習の課題についてモデルを評価できます。提案された設定がベンチマークとともに、実践者に意味のある問題設定を提供することを願っています。一度に提供されるラベルは1つだけであり、モデルは、すでに学習している場合は、もう1つのラベルを把握する必要があります。 
[概要] iircセットアップでモデルを評価できるようにする標準化されたベンチマークを開発します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-grained Trajectory Graph Convolutional Networks for
  Habit-unrelated Human Motion Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_21.html">
      <font color="black">Multi-grained Trajectory Graph Convolutional Networks for
  Habit-unrelated Human Motion Prediction</font>
    </a>
  </h2>
  <font color="black">マルチグレイン軌道グラフ畳み込みネットワークベースの軽量フレームワークは、習慣に関係のない人間の動きの予測のために提案されます。具体的には、人間の動きを、関節軌道とサブジョイント軌道を含むマルチグレイン軌道として表します。 -大多数の人々の手持ちの習慣、左利きの動きを生成するための新しい動き生成方法が提案され、人間の習慣への偏りが少なく、動きをより適切にモデル化する。 
[ABSTRACT]モーション生成方法は、左利きのモーションを生成し、人間の習慣へのバイアスを少なくしてより適切にモデル化するために提案されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: INTEL-TAU: A Color Constancy Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_22.html">
      <font color="black">INTEL-TAU: A Color Constancy Dataset</font>
    </a>
  </h2>
  <font color="black">さらに、この論文では、提案されたデータセットに対するいくつかの色恒常性アプローチのベンチマークを行います。この論文では、照明推定用の新しい大規模データセットについて説明します。3つの異なるカメラモデル、つまりCanon 5DSR、Nikon D810、Sonyを使用してキャプチャされたさまざまなシーンIMX135は、さまざまな照明推定手法のカメラとシーンの不変性を評価するのに適したデータセットを作成します。 
[概要]このデータセットは、インテル-タウと呼ばれ、7022枚の画像が含まれています。これにより、情報に利用できる最大の高解像度データセットになります。データセットには、3種類の画像が含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-23">
        <br><font color="black">2019-10-23</font>
      </time>
    </span>
</section>
<!-- paper0: Chest x-ray automated triage: a semiologic approach designed for
  clinical implementation, exploiting different types of labels through a
  combination of four Deep Learning architectures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_23.html">
      <font color="black">Chest x-ray automated triage: a semiologic approach designed for
  clinical implementation, exploiting different types of labels through a
  combination of four Deep Learning architectures</font>
    </a>
  </h2>
  <font color="black">この作業では、さまざまな畳み込みアーキテクチャのレイトフュージョンに基づくディープラーニング手法を紹介します。これにより、簡単な実装で異種データを使用したトレーニングが可能になり、独立したテストデータでのパフォーマンスが評価されます。臨床的に有用なツールの取得に重点を置きました。病院のワークフローに統合されました。各調査結果について、最も適切なタイプのグラウンドトゥルースラベルを定義し、公共の胸部X線データセットと組織のアーカイブからの画像を組み合わせた4つのトレーニングデータセットを構築しました。 
[概要]この作品は、異なる畳み込みアーキテクチャのレイトフュージョンに基づくディープラーニング手法を示しています。これにより、簡単な実装で異種データを使用したトレーニングが可能になり、独立したテストデータでのパフォーマンスが評価されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Localization in the Crowd with Topological Constraints -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_24.html">
      <font color="black">Localization in the Crowd with Topological Constraints</font>
    </a>
  </h2>
  <font color="black">これらのセマンティックエラーを対象としたトポロジカルアプローチを提案します。この制約を適用するために、永続的ホモロジーの理論に基づいて永続性損失を定義します。さらに、群集カウントタスクのパフォーマンスを改善する方法の可能性を示します。 
[概要]ローカリゼーション手法は、空間的なセマンティックエラーが発生しやすいです。これには、同じ人物内の複数のドットの予測や、雑然とした領域内の複数のドットの折りたたみが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Domain Adaptation for Semantic Segmentation by Content
  Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_25.html">
      <font color="black">Unsupervised Domain Adaptation for Semantic Segmentation by Content
  Transfer</font>
    </a>
  </h2>
  <font color="black">したがって、画像内のコンテンツとスタイルを正確に分離することは、合成データで学習する場合でも、実際のデータの教師としての効果につながります。この問題を解決するために、画像内の情報をコンテンツとスタイルに分離することに焦点を当てました。ラベル付き合成データを使用してラベルなし実データをセグメント化することを目的とした、セマンティックセグメンテーションの教師なしドメイン適応（UDA）に取り組みます。 
[概要]セマンティックセグメンテーションにおけるudaの主な問題は、実像と合成画像の間のドメインギャップを減らすことに依存しています。この効果を最大限に活用するために、ゼロスタイルの損失を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Information Bottleneck Constrained Latent Bidirectional Embedding for
  Zero-Shot Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_26.html">
      <font color="black">Information Bottleneck Constrained Latent Bidirectional Embedding for
  Zero-Shot Learning</font>
    </a>
  </h2>
  <font color="black">コードはhttps://github.com/osierboy/IBZSLで入手できます。ただし、ほとんどの生成モデルは、トレーニングに使用されるのは表示されたデータのみであるため、表示されないバイアスの問題に悩まされています。これらの問題に対処するために、提案します。緊密な視覚と意味の結合制約を持つ新しい双方向埋め込みベースの生成モデル。 
[概要]キャリブレーションの偏差とハブネスの問題により、一般化機能が見えないクラスに制限されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: MARA-Net: Single Image Deraining Network with Multi-level connections
  and Adaptive Regional Attentions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_27.html">
      <font color="black">MARA-Net: Single Image Deraining Network with Multi-level connections
  and Adaptive Regional Attentions</font>
    </a>
  </h2>
  <font color="black">マルチレベル接続は、デコードプロセスがすべてのレベルの特徴情報を使用することを促進します。雨の筋は屋外の画像を劣化させ、その視認性を低下させる可能性があるため、単一の画像から雨の筋を取り除くことは、さまざまなコンピュータビジョンタスクで重要な問題です。マルチレベル接続で、現在のレベルのデコードプロセスでどのレベルの機能が重要であるかを学習します。 
[概要]最初の主なアイデアは、エンコーダネットワークのマルチレベル機能をデコーダネットワークに繰り返し接続するマルチレベル接続設計です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-29">
        <br><font color="black">2020-09-29</font>
      </time>
    </span>
</section>
<!-- paper0: Hard-Mining Loss based Convolutional Neural Network for Face Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_28.html">
      <font color="black">Hard-Mining Loss based Convolutional Neural Network for Face Recognition</font>
    </a>
  </h2>
  <font color="black">トレーニングはCASIA-WebFaceおよびMS-Celeb-1Mデータセットに対して実行されます。実験結果は、提案されたハードマイニング損失のフレームワークで使用すると、既存の損失関数のパフォーマンスが向上することを示しています。クロスなどのさまざまな損失関数-顔認識のためのネットワークの重みを学習するために、Entropy、Angular-Softmax、およびArcFaceが導入されました。 
[概要]提案された損失は、野生の顔とYouTubeの顔で広く使用されているラベル付きの顔でテストされます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-09">
        <br><font color="black">2019-08-09</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervised Learning of Interpretable Keypoints from Unlabelled
  Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_29.html">
      <font color="black">Self-supervised Learning of Interpretable Keypoints from Unlabelled
  Videos</font>
    </a>
  </h2>
  <font color="black">KeypointGANを提案します。これは、単一の画像からオブジェクトのポーズを認識するための新しい方法であり、学習にはラベルのないビデオとオブジェクトのポーズの弱い経験的事前情報のみを使用します。これには3つの利点があります。（1）タイトな「幾何学的ボトルネック」を提供します。 &#39;ポーズを外観から解きほぐし、（2）強力な画像間変換ネットワークを活用して測光とジオメトリをマッピングし、（3）経験的なポーズの事前評価を学習プロセスに組み込むことができます。ポーズの標準ベンチマーク人間と顔を認識し、私たちの方法は、トレーニングのためにラベル付けされた画像を必要としない方法の中で最先端のパフォーマンスを実現します。 
[概要]この方法では、ビデオ間の違いを分析してポーズ情報を抽出します。位置の事前情報は、ペアになっていない写真から取得されます。ポーズ認識ネットワークの学習に注釈付きの画像は使用されません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-03">
        <br><font color="black">2019-07-03</font>
      </time>
    </span>
</section>
<!-- paper0: Skeleton-based Approaches based on Machine Vision: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_30.html">
      <font color="black">Skeleton-based Approaches based on Machine Vision: A Survey</font>
    </a>
  </h2>
  <font color="black">いくつかのスケルトンベースのアプローチは、オブジェクト検出に関するいくつかの概要で必須ではない部分として言及されています。理論的構成の観点からこれらの手法を説明する代わりに、アプリケーションフィールドと与えられたタスクに関してスケルトンベースのアプローチを要約することに専念します。このホワイトペーパーは、スケルトンベースのアプリケーションをさらに理解し、特定の問題に対処するのに役立ちます。 
[概要]スケルトン機能の迅速なアプリケーションが開発されましたが、スケルトンベースのアプローチの合計分析はありませんでした</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Principled network extraction from images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_31.html">
      <font color="black">Principled network extraction from images</font>
    </a>
  </h2>
  <font color="black">これに動機付けられて、スケーラブルで効率的な画像からネットワークトポロジを抽出するための原理モデルを提示します。網膜血管系、粘液型、河川ネットワークの実際の画像でモデルをテストし、画像処理技術を組み合わせたルーチンと比較します。 。この目標をルーティング最適化問題の解決にマッピングします。ソリューションは、運用コストとインフラストラクチャコストの観点から解釈できるエネルギー関数を最小化するネットワークです。 
[概要]私たちの方法は、最適な輸送理論からの最近の結果に依存しています。これは、ヒューリスティックに基づく成形ネットワークの原理的な代替手段です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Contrastive Learning for Label-Efficient Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_32.html">
      <font color="black">Contrastive Learning for Label-Efficient Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、ラベルベースの対照損失を使用した事前トレーニングにより、ラベル付きデータの量が制限されている場合に、パフォーマンスが大幅に向上することを示しています（一部の設定では20％以上の絶対的な改善）。このアプローチにより、クラス内のコンパクト性とクラス間の分離性が向上します。その結果、より優れたピクセル分類子が得られます。セマンティックセグメンテーションのタスクのためにラベル付けされたデータを収集するには、高密度のピクセルレベルの注釈が必要になるため、費用と時間がかかります。 
[概要]これはシンプルで効果的な学習ベースのトレーニング戦略です。ピクセルごとのクラスラベルベースの対照損失を使用し、次にクロスシーリング損失を使用して微調整します。提案されたトレーニング戦略は完全に使用できます。 -監視ありおよび半監視あり設定</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-13">
        <br><font color="black">2020-12-13</font>
      </time>
    </span>
</section>
<!-- paper0: Learning from Lexical Perturbations for Consistent Visual Question
  Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_33.html">
      <font color="black">Learning from Lexical Perturbations for Consistent Visual Question
  Answering</font>
    </a>
  </h2>
  <font color="black">私たちのベンチマークは、大規模な言語リソースから独自に引き出し、生成的アプローチと比較してデータ品質を維持しながら、人間の注釈の労力を回避します。VQAP2を使用して既存のVQAモデルをベンチマークし、各タイプの言語バリエーションの堅牢性分析を提供します。一貫性と一般化能力が著しく向上し、VQAモデルの有用で現在十分に活用されていないトレーニングおよび正規化ツールとしての制御された言語摂動の価値を示しています。 
[概要]このペーパーでは、モジュラーネットワークに基づいてこの問題に対処するための新しいアプローチを提案します。また、vqaの質問の制御可能な言語バリエーションを作成するための、新しい低コストのベンチマークと拡張パイプラインであるvqa摂動ペアリング（vqa p2）も紹介します。 .we vqa p2を使用して既存のvqaモデルのベンチマークを行い、各タイプの言語バリエーションのスケール分析を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-26">
        <br><font color="black">2020-11-26</font>
      </time>
    </span>
</section>
<!-- paper0: Non-Rigid Neural Radiance Fields: Reconstruction and Novel View
  Synthesis of a Deforming Scene from Monocular Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_34.html">
      <font color="black">Non-Rigid Neural Radiance Fields: Reconstruction and Novel View
  Synthesis of a Deforming Scene from Monocular Video</font>
    </a>
  </h2>
  <font color="black">特に、消費者向けカメラは、短くて単純なシーンの説得力のあるバレットタイムビデオを合成するのに十分であることを示します。この技術レポートでは、のニューラルラディアンスフィールド（NERF）の再構築に関する現在進行中の作業の現状を示します。光線の曲げによる一般的な非剛体のシーン..定性的な結果を得るために、補足ビデオを視聴することをお勧めします。 
[ABSTRACT] non-rigid nerf（nr --nerf）は、変形するオブジェクトのrgb画像を入力として取得します。次に、入力シーケンスを再構築し、任意のタイムステップを新しいカメラビューに再レンダリングできる彫刻と外観の表現を学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Contrast Computed Tomography Healthy Kidney Atlas -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_35.html">
      <font color="black">Multi-Contrast Computed Tomography Healthy Kidney Atlas</font>
    </a>
  </h2>
  <font color="black">アトラスと人口統計のリンクにより、集団間の腎臓の解剖学的構造の変化をよりよく理解できました。ただし、マルチコントラストCT用の腹部および後腹膜臓器のアトラスフレームワークはありません。統合するためのアトラステンプレートの安定した一般化可能性を示します。人口統計の大きな変動を伴うコントラストモダリティおよび集団にわたる、小さいものから大きいものへの正常な腎臓の変動。 
[概要]新しい高解像度のct後腹膜アトラスは、非造影CT全体の腎臓用に特別に最適化されています。これにより、集団全体の腎臓の解剖学的構造の変化をよりよく理解できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: GANDA: A deep generative adversarial network predicts the spatial
  distribution of nanoparticles in tumor pixelly -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_36.html">
      <font color="black">GANDA: A deep generative adversarial network predicts the spatial
  distribution of nanoparticles in tumor pixelly</font>
    </a>
  </h2>
  <font color="black">GANDAは、実際の分布を知らなくてもNP分布（R2 = 0.93）と血管外漏出の定量分析を可能にしました。GANDAが腫瘍血管と核の元の画像と同じ空間分解能でNP分布の画像を生成できることを示しました。この予測モデルは、深部学習アプローチを使用して、腫瘍切片の全スライド画像から腫瘍血管と細胞核の特徴を自動的に学習しました。 
[概要]分布解析ネットワーク（ガンダ）を開発しました。ガンダは、腫瘍血管や核の元の画像と同じ空間分解能でnps分布の画像を生成できます。このモデルは、影響因子が個々の腫瘍のnps分布にどのように影響するかを調査する機会を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Small-Group Learning, with Application to Neural Architecture Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_37.html">
      <font color="black">Small-Group Learning, with Application to Neural Architecture Search</font>
    </a>
  </h2>
  <font color="black">ニューラルアーキテクチャ検索にアプローチを適用し、CIFAR-100、CIFAR-10、およびImageNetを大幅に改善します。3つの学習段階を含むSGLを定式化するためのマルチレベル最適化フレームワークを提案します。学習者はネットワークの重みを個別にトレーニングします。学習者は、相互の疑似ラベリングを介してネットワークの重みを共同でトレーニングします。学習者は、検証の損失を最小限に抑えることでアーキテクチャを改善します。SGL問題を解決するための効率的なアルゴリズムを開発します。 
[概要]研究者たちは、この強力な学習手法を人間から借りて、機械の学習能力を向上させることができるかどうかを模索しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Noisy Labels Can Induce Good Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_38.html">
      <font color="black">Noisy Labels Can Induce Good Representations</font>
    </a>
  </h2>
  <font color="black">アーキテクチャがタスクに「適している」場合、モデルの一般化が不十分な場合でも、ノイズの多いラベルを使用したトレーニングにより、有用な隠れた表現が誘発される可能性があることがわかります。つまり、モデルの最後の数レイヤーは、ノイズの多いラベルの影響をより受けます。3つのアーキテクチャ（畳み込みニューラルネットワーク、グラフニューラルネットワーク、多層パーセプトロン）と2つのドメイン（グラフアルゴリズムタスクと画像）での調査結果を経験的に検証します。分類）..この発見は、ノイズの多いラベルでトレーニングされたモデルを改善する簡単な方法につながります。最終的な密な層を線形モデルに置き換えます。線形モデルの重みは、クリーンなデータの小さなセットから学習されます。 
[ABSTRACT]アーキテクチャは、ノイズの多いラベルを使用した学習に影響を与えます。この発見は、ノイズの多いデータでトレーニングされたモデルを改善する簡単な方法につながります。また、画像分類ベンチマークで最先端の結果を達成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: CPF: Learning a Contact Potential Field to Model the Hand-object
  Interaction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_39.html">
      <font color="black">CPF: Learning a Contact Potential Field to Model the Hand-object
  Interaction</font>
    </a>
  </h2>
  <font color="black">2つの公開ベンチマークでの広範な実験により、私たちの方法はいくつかの再構成メトリックで最先端を達成でき、グラウンドトゥルースが深刻な相互侵入またはばらばらを示している場合でも、より物理的にもっともらしいHOポーズを生成できることが示されています。以前の作品は通常、HOポーズを共同で推定することに焦点を当てていますが、把握で保持される物理的接触を完全には調査していません。CPFを回復するために、MIHOという名前の学習に適したハイブリッドフレームワークも提案します。 
[概要]この論文では、明示的な接触表現、各手をモデル化する接触ポテンシャル場（cpf）-物体接触をばね-質量システムとして提示します。また、mihoと呼ばれる学習適合ハイブリッドフレームワークを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Training Robust Deep Neural Networks via Adversarial Noise Propagation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_40.html">
      <font color="black">Training Robust Deep Neural Networks via Adversarial Noise Propagation</font>
    </a>
  </h2>
  <font color="black">したがって、ディープモデルの敵対的ロバスト性を向上させるために、さまざまな敵対的防御方法が開発されました。ただし、敵対的な例と混合されたデータをトレーニングするだけでは、これらのモデルのほとんどは、一般化されたタイプのノイズに対して防御できません。実際には、ディープニューラルネットワーク敵対的な例や破損など、さまざまなタイプのノイズに対して脆弱であることがわかっています。 
[ABSTRACT]ディープモデルのノイズを改善するために、さまざまな敵対的防御方法が開発されました。これらには、層ごとに隠れ層にノイズを注入するアルゴリズムの使用が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-19">
        <br><font color="black">2019-09-19</font>
      </time>
    </span>
</section>
<!-- paper0: Focal Frequency Loss for Generative Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_41.html">
      <font color="black">Focal Frequency Loss for Generative Models</font>
    </a>
  </h2>
  <font color="black">知覚品質と定量的パフォーマンスの両方でさまざまなベースラインを改善するための焦点周波数損失の多様性と有効性を示します。この目的関数は、既存の空間損失を補完し、ニューラルの固有の核心による重要な周波数情報の損失に対して大きなインピーダンスを提供します。ネットワーク..提案された損失により、モデルは、簡単な周波数をダウンウェイトすることによって、合成が難しい周波数成分に動的に焦点を合わせることができます。 
[要約]提案された損失により、モデルは、簡単な周波数を重み付けすることによって合成するのが難しい周波数成分に動的に焦点を合わせることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: ANR: Articulated Neural Rendering for Virtual Avatars -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_42.html">
      <font color="black">ANR: Articulated Neural Rendering for Virtual Avatars</font>
    </a>
  </h2>
  <font color="black">ただし、この場合、ニューラルシェーディングのステップでは、メッシュにキャプチャされない可能性のある変形、およびアライメントの不正確さとダイナミクスを考慮する必要があります。これにより、DNRパイプラインが混乱する可能性があります。2つのユーザー調査では、私たちのアバターモデルと定量的評価指標で最先端のパフォーマンスを示します。知覚的には、より良い時間的安定性、詳細レベル、妥当性を観察します。 
[概要]アーティキュレートニューラルレンダリング（anr）、仮想人間アバターの制限に明示的に対処するdnrに基づく新しいフレームワークを紹介します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Pit30M: A Benchmark for Global Localization in the Age of Self-Driving
  Cars -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_43.html">
      <font color="black">Pit30M: A Benchmark for Global Localization in the Age of Self-Driving
  Cars</font>
    </a>
  </h2>
  <font color="black">Pit30Mは、さまざまな条件（季節、天気、時刻、交通量など）でキャプチャされ、正確なローカリゼーションのグラウンドトゥルースを提供します。また、過去の天気と天文データ、および画像とLiDARセマンティックでデータセットに自動的に注釈を付けます。オクルージョンの代理測定としてのセグメンテーション..データセット、追加の実験結果、およびセンサー、キャリブレーション、メタデータに関する詳細情報は、プロジェクトのWebサイト（https://uber.com/atg/datasets/pit30m）で入手できます。 
[ABSTRACT] pit30mは、3000万フレームを超える新しい画像とライダーのデータセットです。これは、前の作業で使用されたものの10倍から100倍の大きさです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Estimation of Driver's Gaze Region from Head Position and Orientation
  using Probabilistic Confidence Regions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_44.html">
      <font color="black">Estimation of Driver's Gaze Region from Head Position and Orientation
  using Probabilistic Confidence Regions</font>
    </a>
  </h2>
  <font color="black">たとえば、95％信頼領域は、ドライバーを囲む球の3.77％領域をカバーする領域によって定義されます。頭のポーズと視線方向の関係は1対1ではないため、この論文では、ドライバーの視覚的注意を表す顕著な領域を作成するための確率モデル。スマートビークルは、危険な状況を回避するために、人間の行動を理解し、その行動を予測できる必要があります。 
[概要]車の視覚的注意は、車両がドライバーの認識状態を理解するのに役立ち、重要なコンテキスト情報を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: ICMSC: Intra- and Cross-modality Semantic Consistency for Unsupervised
  Domain Adaptation on Hip Joint Bone Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_45.html">
      <font color="black">ICMSC: Intra- and Cross-modality Semantic Consistency for Unsupervised
  Domain Adaptation on Hip Joint Bone Segmentation</font>
    </a>
  </h2>
  <font color="black">具体的には、私たちのモデルは、画像変換モジュールとドメイン固有のセグメンテーションモジュールで構成されています。画像変換モジュールは標準のCycleGANですが、セグメンテーションモジュールには2つのドメイン固有のセグメンテーションネットワークが含まれています。 UDAのクロスモダリティセマンティックコンシステンシー（ICMSC）と私たちの重要な洞察は、さまざまなスタイルで合成された画像のセグメンテーションが一貫している必要があるということです。 
[ABSTRACT]適応された特徴学習は通常、ピクセルレベルでドメインシフトを検出できません。高密度のセマンティックセグメンテーションタスクで良好な結果を達成することはできません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Distance Preserving Grid Layouts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_46.html">
      <font color="black">Distance Preserving Grid Layouts</font>
    </a>
  </h2>
  <font color="black">この論文では、距離保存グリッド（DGrid）と呼ばれる新しい手法を紹介します。これは、バイナリ空間分割プロセスを多次元投影と組み合わせて使用して、直交する規則的なグリッドレイアウトを作成します。正確ではありますが、このような戦略は計算コストが高く、小さなデータセット、またはプロセスを高速化するために特殊なハードウェアに依存している。現在、最先端のアプローチは、割り当ての問題を解決するか、順列を使用してコスト関数を最適化することにより、そのようなグリッドを生成します。 
[概要]現在、データインスタンスは2つの幅の広いグリッドに配置されています。これは、インスタンス間のペアワイズ距離が生成されたレイアウトに保持されることを意味します。現在、このような戦略は数学的に高価であり、小さなデータセットに限定されているか、特殊なハードウェアに依存しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-03-08">
        <br><font color="black">2019-03-08</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Boosting the Channel Attention in Real Image Denoising :
  Sub-band Pyramid Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_47.html">
      <font color="black">Towards Boosting the Channel Attention in Real Image Denoising :
  Sub-band Pyramid Attention</font>
    </a>
  </h2>
  <font color="black">さらに、私たちの結果は、ピラミッドレベルがSPAブロックのパフォーマンスにどのように影響し、SPAブロックの好ましい一般化機能を示すかを示しています。この方法は、周波数レベルでチャネルを再スケーリングするための代表的な係数を学習するのに非効率的であると見なします。人工の畳み込み層ニューラルネットワーク（ANN）は、機能選択の柔軟性なしにチャネル機能を同等に扱います。 
[要約]提案された方法は、ウェーブレットサブバンドピラミッドに基づいています。抽出された特徴の周波数部分をよりきめ細かく再較正します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: SWA Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_48.html">
      <font color="black">SWA Object Detection</font>
    </a>
  </h2>
  <font color="black">広範な実験を通じて、オブジェクト検出でSWAを実行するという優れたポリシーを発見し、挑戦的なCOCOベンチマークでさまざまな一般的な検出器に対して$ \ sim $ 1.0APの改善を一貫して達成しています。驚くほど簡単です。検出器をさらに12エポックトレーニングします。周期的な学習率を使用して、これらの12のチェックポイントを最終的な検出モデルとして平均します。コードはhttps://github.com/hyz-xmaster/swa_object_detectionで入手できます。 
[概要]このレシピは、確率的重み平均化（swa）に触発されています。ディープニューラルネットワークの一般化を改善するために提案されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Vid2Actor: Free-viewpoint Animatable Person Synthesis from Video in the
  Wild -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_49.html">
      <font color="black">Vid2Actor: Free-viewpoint Animatable Person Synthesis from Video in the
  Wild</font>
    </a>
  </h2>
  <font color="black">実験により、設計の選択が検証され、合成データと、制約のないアクティビティを実行する多様な人々の実際のビデオで結果が得られます（たとえば、人の「野生の」ビデオが与えられた場合、ビデオ内の人のアニメート可能なモデルを再構築します。最後に、学習したモデルを使用して、モーションのリターゲティングとバレットタイムレンダリングを示します。
[ABSTRACT]私たちの方法は、深い入力を備えたganベースの画像を超える進歩です。これにより、任意のポーズとカメラの画像合成が可能になります。内部3D表現。同時に、事前テーブルモデルやグラウンドトゥルースメッシュは必要ありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Analyzing Representations inside Convolutional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_50.html">
      <font color="black">Analyzing Representations inside Convolutional Neural Networks</font>
    </a>
  </h2>
  <font color="black">提案された方法を広範囲に評価し、ResNet-18がCIFAR-100データセットで学習した人間が理解できる一貫した概念を生成することを示します。この作業では、ネットワークが学習する概念を分類するフレームワークを提案します。入力例のセットをクラスター化し、アクティブ化する例に基づいてニューロンをクラスター化し、入力機能をすべて同じ潜在空間にクラスター化する方法。このフレームワークは監視されておらず、入力機能のラベルがなくても機能します。内部へのアクセスのみが必要です。入力例ごとにネットワークをアクティブ化することで、広く適用できるようにします。 
[ABSTRACT]ネットワークは、入力機能のラベルがなくても機能します。入力例ごとに、ネットワークの内部アクティベーションにアクセスするだけで済みます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Correspondence Learning for Controllable Person Image Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_51.html">
      <font color="black">Correspondence Learning for Controllable Person Image Generation</font>
    </a>
  </h2>
  <font color="black">最後に、ネットワークはワープされたソース画像の特徴とターゲットポーズに基づいて画像をレンダリングします。その後、シャーディングされたドメイン内でターゲットポーズとソース画像の間に密な対応を確立します。制御可能な人物の生成モデルを提示します。図に示すように、ポーズ誘導人物画像合成に適用できる画像合成$ ie $は、ソース人物画像のテクスチャを保持しながら、ソース人物画像のポーズをターゲットポーズに変換し、衣服誘導人物画像合成$ ie $、ソース人物画像の衣服テクスチャを目的の衣服テクスチャに変更します。 
[ABSTRACT]ポーズ転送によって生じるミスアライメントに効果的に対処し、高品質の画像を生成できます。具体的には、ターゲットポーズとソース画像の間の密な対応を確立します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Diabetic Retinopathy Grading System Based on Transfer Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_52.html">
      <font color="black">Diabetic Retinopathy Grading System Based on Transfer Learning</font>
    </a>
  </h2>
  <font color="black">学習転送は、小さなデータセットのトレーニングに非常に役立ちます。この論文では、マルチラベル分類に応じた完全ベースのDLCADシステムを紹介します。提案されたDLCADシステムでは、診断のためにカスタマイズされた効率的なNetモデルを紹介します。 DR疾患の初期および高度なグレード。 
[概要]ディープラーニング（dl）手法に基づく多くのCADシステムが採用されています。提案されたDL CADシステムでは、dr疾患の初期および高度なグレードを診断するためのカスタマイズされた効率的なネットモデルを提示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Deep manifold learning reveals hidden dynamics of proteasome
  autoregulation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_53.html">
      <font color="black">Deep manifold learning reveals hidden dynamics of proteasome
  autoregulation</font>
    </a>
  </h2>
  <font color="black">重要なことに、AlphaCryo4Dは、転座開始時のプロテアソームAAA-ATPaseモーターの単一ヌクレオチド交換ダイナミクスを振り分けます。これは、求核攻撃をアロステリックに促進することによってタンパク質分解活性をアップレギュレートします。エネルギーベースの粒子投票アルゴリズムを介して..私たちの体系的な分析は、プロテアソームの自動調節のための壮大な階層的アロステリックを明らかにします。 
[概要] alphacryo4dの130個の配座異性体-結合したヒト26sプロテアソーム。これにより、二重にキャップされたホロ酵素における2つの調節粒子のコンフォメーションの絡み合いと、単一にキャップされたホロ酵素とのエネルギーの違いが明らかになります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: A Survey on Visual Transformer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_54.html">
      <font color="black">A Survey on Visual Transformer</font>
    </a>
  </h2>
  <font color="black">特に、主なカテゴリには、基本的な画像分類、高レベルのビジョン、低レベルのビジョン、およびビデオ処理が含まれます。Transformerベースのモデルは、畳み込みネットワークなどの他のネットワークタイプと比較して、さまざまなビジュアルベンチマークで競争力がありさらに優れたパフォーマンスを示します。リカレントネットワーク..Transformerは、主に自己注意メカニズムに基づく一種のディープニューラルネットワークであり、元々は自然言語処理の分野で適用されていました。 
[ABSTRACT]研究者は、コンピュータービジョンタスク用にトランスフォーマーを拡張することを提案しています。トランスフォーマーの強力な表現能力に基づいて、研究者は示唆しています。この論文では、これらの視覚トランスフォーマーモデルの文献レビューを提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Prognostic Power of Texture Based Morphological Operations in a
  Radiomics Study for Lung Cancer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_55.html">
      <font color="black">Prognostic Power of Texture Based Morphological Operations in a
  Radiomics Study for Lung Cancer</font>
    </a>
  </h2>
  <font color="black">これらの機能は、予後モデルに貢献し、最終的には患者の臨床的意思決定と治療過程に貢献します。調査された1,589の機能のうち、32が患者の生存を予測するのに関連していることがわかりました。27の古典的なラジオミクス機能と5つのMM機能（両方を含む）粒度と形態学的共分散の特徴）。腫瘍の特徴はCT画像から抽出され、PCAとKaplan-Meier生存分析を介して分析され、最も関連性の高いものが選択されます。 
[要約]予後の特徴の初期の研究は、より効率的な治療につながる可能性があります。それらは、非小細胞肺癌（nsclc）に苦しむ患者のオープンデータベースで実施されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Identifying Mislabeled Data using the Area Under the Margin Ranking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_56.html">
      <font color="black">Identifying Mislabeled Data using the Area Under the Margin Ranking</font>
    </a>
  </h2>
  <font color="black">私たちのアルゴリズムの中心は、Area Under the Margin（AUM）統計です。これは、クリーンなサンプルと誤ってラベル付けされたサンプルのトレーニングダイナミクスの違いを利用します。このアプローチは、合成データセットと実世界のデータセットに関する以前の作業を一貫して改善します。そのようなサンプルを識別し、ニューラルネットワークをトレーニングする際の影響を軽減するための新しい方法。 
[要約]簡単な手順-意図的に誤ってラベル付けされたしきい値サンプルが入力されたクラスを追加する-誤ってラベル付けされたデータを学習する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-28">
        <br><font color="black">2020-01-28</font>
      </time>
    </span>
</section>
<!-- paper0: Visual Question Answering using Deep Learning: A Survey and Performance
  Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_57.html">
      <font color="black">Visual Question Answering using Deep Learning: A Survey and Performance
  Analysis</font>
    </a>
  </h2>
  <font color="black">最後に、バニラVQAモデル、Stacked Attention Network、VQA Challenge 2017の勝者モデルで計算された結果の一部を紹介して説明します。次に、VQAで有望な結果を示した新しいディープラーニングモデルについて説明します。データセット..また、課題と将来の研究の方向性とともに詳細な分析を提供します。 
[概要] vqaシステムは、画像の視覚要素を使用して正しい答えを見つけようとします。これは、さまざまな質問と質問からの回答に基づいています。新しいモデルは、詳細な分析を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-27">
        <br><font color="black">2019-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: FaceDet3D: Facial Expressions with 3D Geometric Detail Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_58.html">
      <font color="black">FaceDet3D: Facial Expressions with 3D Geometric Detail Prediction</font>
    </a>
  </h2>
  <font color="black">たとえば、笑顔は頬のしわやくぼみの形成を引き起こし、怒りは額のしわを引き起こすことがよくあります。顔の詳細は頂点変位マップとして表され、ニューラルレンダラーがフォトリアリスティックに小説をレンダリングするために使用します。任意の表現とビューの任意の単一画像の画像..プロジェクトのWebサイトは次のとおりです。http：//shahrukhathar.github.io/2020/12/14/FaceDet3D.html 
[ABSTRACT] facedet3dは最初の-その種の生成-単一の画像から-任意のターゲット表現と一致する幾何学的な顔の詳細。この作品では、facedet3dを紹介します。これは、作成されたfaceet3dなどの最初の方法です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-14">
        <br><font color="black">2020-12-14</font>
      </time>
    </span>
</section>
<!-- paper0: Spatially Aware Multimodal Transformers for TextVQA -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_59.html">
      <font color="black">Spatially Aware Multimodal Transformers for TextVQA</font>
    </a>
  </h2>
  <font color="black">さらに、マルチヘッド自己注意レイヤーの各ヘッドは、関係の異なるサブセットに焦点を合わせます。私たちのアプローチには、2つの利点があります。（1）各ヘッドは、すべての視覚エンティティに注意を分散させるのではなく、ローカルコンテキストを考慮します。 （2）冗長な機能の学習を避けます。食料品の購入や公共交通機関の使用などの日常業務には、テキストによる手がかりが不可欠です。 
[概要]私たちのアプローチには2つの利点があります。各ヘッドは、すべての視覚エンティティに注意を分散させるのではなく、ローカルコンテキストを考慮します。ただし、st --vqaを含む他のヘッドは、絶対精度を4.2％向上させます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-23">
        <br><font color="black">2020-07-23</font>
      </time>
    </span>
</section>
<!-- paper0: Direct Estimation of Spinal Cobb Angles by Structured Multi-Output
  Regression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_60.html">
      <font color="black">Direct Estimation of Spinal Cobb Angles by Structured Multi-Output
  Regression</font>
    </a>
  </h2>
  <font color="black">提案されたS ^ 2VRは、出力の固有の相関関係を明示的にキャプチャしながら、入力画像と定量的出力の間の非線形関係を忠実に処理できます。出力空間のジオメトリを活用するためにマニホールド正規化を導入します。ただし、高いあいまいさが存在するため椎骨の境界の周りの変動性、およびコブ角度を自動的に取得することは困難です。 
[概要]提案されたs * 2vrは、出力の固有の相関関係を明示的にキャプチャしながら、コブ角度と定量的出力の間の線形関係を忠実に処理できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: The Translucent Patch: A Physical and Universal Attack on Object
  Detectors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_61.html">
      <font color="black">The Translucent Patch: A Physical and Universal Attack on Object
  Detectors</font>
    </a>
  </h2>
  <font color="black">そのため、自動運転で使用される最先端の物体検出モデルで実施される実験では、選択したターゲットクラスと他のクラスの両方の検出に対するパッチの影響を調査します。主な目標パッチの目的は、選択したターゲットクラスのすべてのインスタンスを非表示にすることです。パッチは、他のクラスの高い検出（ほぼ80％）を維持しながら、すべての一時停止標識インスタンスの42.27％の検出を防ぐことができたことを示します。 
[概要]パッチは、他のクラスの高い（ほぼ80％）検出を維持しながら、すべての一時停止標識インスタンスの42. 27％の検出を防ぐことができました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: CholecSeg8k: A Semantic Segmentation Dataset for Laparoscopic
  Cholecystectomy Based on Cholec80 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_62.html">
      <font color="black">CholecSeg8k: A Semantic Segmentation Dataset for Laparoscopic
  Cholecystectomy Based on Cholec80</font>
    </a>
  </h2>
  <font color="black">Cholec80データセット
[3]に基づいて、Cholec80の17のビデオクリップから8,080の腹腔鏡下胆嚢摘出術画像フレームを抽出し、画像に注釈を付けました。CholecSeg8kはライセンスCC BY-NC-SA4.0でリリースされています。合計サイズは3GBです。 
[概要]データセットの名前はcholecseg8kで、合計サイズは3GBです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Uncertainty Sets for Image Classifiers using Conformal Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_63.html">
      <font color="black">Uncertainty Sets for Image Classifiers using Conformal Prediction</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、既存の共形予測アルゴリズムを変更して、Plattスケーリング後にありそうもないクラスの小さなスコアを正則化することにより、より安定した予測セットを提供します。アルゴリズムはPlattスケーリングのようにシンプルで高速ですが、すべてのモデルに正式な有限サンプルカバレッジ保証を提供します。データセット..ResNet-152およびその他の分類器を使用したImagenetとImagenet-V2の両方での実験では、私たちのスキームは既存のアプローチよりも優れており、多くの場合5〜10倍小さいセットでカバレッジを達成します。 
[ABSTRACT]プラットスケーリングなどの既存の不確実性定量化手法は、ネットワークの確率推定を較正しようとしますが、正式な保証はありません。アルゴリズムはシンプルで高速ですが、すべてのモデルに正式な有限のサンプルカバレッジ保証を提供します。およびデータセット</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-29">
        <br><font color="black">2020-09-29</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Object Classification on Partial Point Clouds: A Practical
  Perspective -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_64.html">
      <font color="black">3D Object Classification on Partial Point Clouds: A Practical
  Perspective</font>
    </a>
  </h2>
  <font color="black">オブジェクト表面上の部分点群の位置を指定することは、6Dオブジェクトポーズ推定の補助タスクによって解決できる前述の課題の苦しみを軽減するために不可欠であると考えます。これに照らして、この論文では実際の設定を紹介します。任意のポーズでオブジェクトインスタンスの部分的な点群を分類する。完全なオブジェクトの点群の分類と比較して、このような問題は、オブジェクトクラス間のローカル形状の幾何学的類似性およびによって制限されるジオメトリのクラス内非類似性を考慮すると、より困難になります。彼らの観察ビュー。 
[ABSTRACT]点群は通常、任意の視点（3）で観測された可視オブジェクト部分からスキャンされます。これは、自己およびオブジェクト間の設定のために不完全です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-18">
        <br><font color="black">2020-12-18</font>
      </time>
    </span>
</section>
<!-- paper0: ConvMath: A Convolutional Sequence Network for Mathematical Expression
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_65.html">
      <font color="black">ConvMath: A Convolutional Sequence Network for Mathematical Expression
  Recognition</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案されたネットワークが最新の精度と以前の方法よりもはるかに優れた効率を達成することを示しています。ConvMathのパフォーマンスは、103556サンプルを含むIM2LATEX-100Kという名前のオープンデータセットで評価されます。さらに、ネットワークデコーダーにマルチレイヤーアテンションメカニズムを採用しているため、モデルは出力シンボルをソース特徴ベクトルに自動的に位置合わせし、モデルのトレーニング中にカバレッジが不足する問題を軽減します。 
[概要]この論文では、畳み込みシーケンスモデリングネットワークconvmathを提案します。これは、画像内の数式の記述をラテックスシーケンスに結合します。convmathのパフォーマンスは、103556サンプルを含むim2latex-100kという名前のオープンデータセットに対して評価されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Modality Cut and Paste for 3D Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_66.html">
      <font color="black">Multi-Modality Cut and Paste for 3D Object Detection</font>
    </a>
  </h2>
  <font color="black">MoCaは、点群とグラウンドトゥルースオブジェクトの画像パッチをカットし、オブジェクト間の衝突を回避しながら、一貫した方法でそれらを異なるシーンに貼り付けることで、検出パフォーマンスを向上させます。次に、新しいマルチモダリティ拡張アプローチであるマルチモダリティカットとpAste（MoCa）..また、優れたマルチモダリティ検出器を実装する際の有益なアーキテクチャ設計と最適化の実践についても説明します。 
[ABSTRACT] mocaは、点群と地面の画像パッチを切り取り、それらをさまざまなシーンに貼り付けることで、検出パフォーマンスを向上させます。検出器のアンサンブルを使用せずに、マルチモダリティ検出器は、nuscenesデータセットと競争力のあるパフォーマンスで新しい最先端のパフォーマンスを実現します。キティ3Dベンチマーク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: On Calibration of Scene-Text Recognition Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_67.html">
      <font color="black">On Calibration of Scene-Text Recognition Models</font>
    </a>
  </h2>
  <font color="black">特に、注意ベースのデコーダーの場合、個々の文字予測のキャリブレーションにより、キャリブレーションされていないモデルと比較して単語レベルのキャリブレーションエラーが増加することを示します。さらに、既存のキャリブレーション方法と新しいシーケンスベースの拡張を多数のSTRモデルに適用します。キャリブレーションエラーが最大で約7分の1に減少することを示しています。この作業では、シーンテキスト認識（STR）の単語レベルの信頼性キャリブレーションの問題を調査します。 
[概要]信頼性キャリブレーションの方法は、過去数十年にわたって活発な研究分野でした。次に、文字レベルではなく単語でのstrモデルのキャリブレーションに焦点を当てます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient video annotation with visual interpolation and frame selection
  guidance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_68.html">
      <font color="black">Efficient video annotation with visual interpolation and frame selection
  guidance</font>
    </a>
  </h2>
  <font color="black">最後に、人間の注釈実験を実行し、結果の広範な分析を提供します。これは、このアプローチにより、一般的に使用される線形補間と比較して、実際に測定された注釈時間が50％短縮されることを示しています。シミュレーションでいくつかの困難なデータセットに対してアプローチを広範囲に評価し、削減を示します。線形補間で60％、既製のトラッカーで35％描画される手動バウンディングボックスの数に関して。さらに、最先端の方法よりも10％の注釈時間の改善も示しています。バウンディングボックスを使用したビデオ注釈用
[25]。 
[要約]ビデオ注釈は、退屈なプロセスであるため、長年の問題です。ビデオ注釈の最先端の方法よりもすぐに改善されることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: HDR Denoising and Deblurring by Learning Spatio-temporal Distortion
  Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CV/paper_69.html">
      <font color="black">HDR Denoising and Deblurring by Learning Spatio-temporal Distortion
  Models</font>
    </a>
  </h2>
  <font color="black">残念ながら、歪んだセンサーの読み取り値のキャプチャには時間がかかります。また、CLEAN HDRビデオが不足しています。まず、代わりに別の関数を学習します。CLEAN-&gt; DISTORTEDは、相関するピクセルノイズ、行と列のノイズ、および少数からのモーションブラーを含むサンプルを生成します。 CLEANセンサーの読み取り値の概要..異なるピクセル列に異なる低ダイナミックレンジ（LDR）情報を記録するデュアル露出センサーから、シャープでノイズのないハイダイナミックレンジ（HDR）ビデオを再構築しようとしています。奇数列は低-露出、シャープ、しかしノイズの多い情報。列でさえ、ノイズが少なく、露出が高く、モーションブラーのあるデータでこれを補完します。 
[概要]以前のldrの作業では、クリーンな画像と歪んだ画像のペアによって監視され、ブレ除去とノイズ除去（歪んだ-クリーン）を学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Deep Open Intent Classification with Adaptive Decision Boundary -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CL/paper_0.html">
      <font color="black">Deep Open Intent Classification with Adaptive Decision Boundary</font>
    </a>
  </h2>
  <font color="black">本論文では、オープンインテント分類のための適応決定境界（ADB）を学習するための後処理法を提案する。具体的には、経験的リスクとオープンスペースリスクの両方のバランスをとるための新しい損失関数を提案する。モデルを事前トレーニングするためのラベル付きの既知のインテントサンプル。 
[要約]既知のインテントの分類品質を確保する必要があります。私たちのアプローチは、ラベル付けされたデータが少なく、既知のインテントが少ないため、驚くほど鈍感であることがわかります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-18">
        <br><font color="black">2020-12-18</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Meta Sampling for Multilingual Low-Resource Speech
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CL/paper_1.html">
      <font color="black">Adversarial Meta Sampling for Multilingual Low-Resource Speech
  Recognition</font>
    </a>
  </h2>
  <font color="black">最後に、2つの多言語データセットでの実験結果は、MML-ASRにAMSを適用するとパフォーマンスが大幅に向上することを示しています。また、他の低リソース音声タスクや転移学習ASRアプローチへのAMSの適用性も示しています。この事実に触発されて、 MML-ASRの現在のクエリ損失を敵対的に増加させるためのタスクサンプリングポリシーを学習するための、ネットワークへのすべてのソース言語ドメインの過去のタスククエリ損失。具体的には、各ソース言語について、クエリ損失が大きい場合、それはそのタスクを意味します。量と難易度の点でASRモデルをトレーニングするために十分にサンプリングされていないため、追加の学習のためにより頻繁にサンプリングする必要があります。 
[要約]各ソース言語について、質問の損失が大きい場合、そのタスクは、量と難易度の観点からasrモデルをトレーニングするために十分にサンプリングされていないことを意味します。mml-asrのリソースは学習状況をマスターできるため、予測できます。各言語の良好なタスクサンプリング確率</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Adaptation of NMT models for English-Hindi Machine Translation
  Task at AdapMT ICON 2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CL/paper_2.html">
      <font color="black">Domain Adaptation of NMT models for English-Hindi Machine Translation
  Task at AdapMT ICON 2020</font>
    </a>
  </h2>
  <font color="black">これらのモデルは、主にドメイン外データを使用してトレーニングし、ドメイン内データセットの特性に基づいた単純なドメイン適応手法を採用しています。ドメイン適応には、微調整と混合ドメインデータアプローチが使用されます。私たちのチームはランク付けされました。最初は化学および一般ドメインのEn-Hi変換タスクで、2番目はAIドメインのEn-Hi変換タスクです。 
[概要]英語の2つの人気モデルの有効性を調べました-ブルースコアに基づくヒンディー語の機械翻訳タスク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: EmotionGIF-IITP-AINLPML: Ensemble-based Automated Deep Neural System for
  predicting category(ies) of a GIF response -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CL/paper_3.html">
      <font color="black">EmotionGIF-IITP-AINLPML: Ensemble-based Automated Deep Neural System for
  predicting category(ies) of a GIF response</font>
    </a>
  </h2>
  <font color="black">ラウンド2フェーズでは、タスクのいくつかの深いニューラルベースの分類器を構築し、多数決ベースのアンサンブル手法を通じて最終予測を報告します。提案されたモデルは、52.92％および53.80％の最高の平均想起（MR）スコアを達成します。それぞれラウンド1とラウンド2 ..タスクのラウンド1フェーズでは、ツイート（テキスト）とその返信（可能な場合はテキスト）および指定されたカテゴリ（可能な場合はテキスト）の両方でトレーニングされた注意ベースの双方向GRUネットワークを提案します。 ies）そのGIF応答。 
[概要]ツイートとその返信の両方、およびgif応答の特定のカテゴリでトレーニングされた注意ベースのネットワークを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Investigating Pretrained Language Models for Graph-to-Text Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CL/paper_4.html">
      <font color="black">Investigating Pretrained Language Models for Graph-to-Text Generation</font>
    </a>
  </h2>
  <font color="black">特に、LDC2017T10で49.72、WebNLGで59.70、AGENDAデータセットで25.66の新しい最先端のBLEUスコアを報告します。それぞれ31.8％、4.5％、42.4％の相対的な改善です。証拠が見つかりました。真の事実に関する彼らの知識は、入力グラフ表現がノードラベルとエッジラベルの単純なバッグに縮小された場合でも、パフォーマンスを向上させるのに役立ちます。広範な分析で、グラフからテキストへのタスクでPLMが成功する理由を特定します。 。 
[概要] plmsバートとt5は、新しい最先端の結果を達成します。また、新しい結果とそのタスクを達成します。適応型事前トレーニング戦略により、パフォーマンスがさらに向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: TicketTalk: Toward human-level performance with end-to-end,
  transaction-based dialog systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CL/paper_5.html">
      <font color="black">TicketTalk: Toward human-level performance with end-to-end,
  transaction-based dialog systems</font>
    </a>
  </h2>
  <font color="black">同じ10,000のダイアログセットでトレーニングされたモデルのAPI呼び出し予測は、評価で93.9％の確率で正しいと評価され、対応する人間のラベルの評価を上回りました。これは、APIを予測できるようにするための重要なコンポーネントでもあります。正確に呼び出します。トランザクションベースのダイアログでの将来の作業を容易にするために、このペーパーでTicketTalkデータセットを公開しています。 
[概要] API予測と応答生成のスコアがどのように向上するかを示します。データセットのサイズは5000から21,000に段階的に増加します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Speaker Diarization as Post-Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CL/paper_6.html">
      <font color="black">End-to-End Speaker Diarization as Post-Processing</font>
    </a>
  </h2>
  <font color="black">互いの弱点を補うために、クラスタリングベースの方法で得られた結果の後処理として、2スピーカーのエンドツーエンドダイアリゼーション法を使用することを提案します。結果から2つのスピーカーを繰り返し選択し、結果を更新します。重複領域を改善するために2つのスピーカーの..いくつかの方法は柔軟な数のスピーカーを処理できますが、スピーカーの数が多い場合はうまく機能しません。 
[ABSTRACT]ダイアリゼーション方式は、フレームを話者数のクラスターに分割します。これは、各フレームが1人の話者に割り当てられるため、通常、重複する音声を処理できないことを意味します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-18">
        <br><font color="black">2020-12-18</font>
      </time>
    </span>
</section>
<!-- paper0: Future-Guided Incremental Transformer for Simultaneous Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CL/paper_7.html">
      <font color="black">Future-Guided Incremental Transformer for Simultaneous Translation</font>
    </a>
  </h2>
  <font color="black">将来のガイド付きトレーニングでは、インクリメンタルトランスフォーマーの教師として従来のトランスフォーマーを提案し、知識の蒸留によってモデルに将来の情報を目に見えない形で埋め込むようにします。この方法では、トレーニング速度を平均で約28倍効果的に向上させることができます。異なるkをモデルに暗黙的に埋め込み、wait-kベースラインよりも優れた翻訳品質を実現します。中国語-英語およびドイツ語-英語の同時翻訳タスクで実験を行い、wait-kポリシーと比較して提案された方法を評価しました。 。 
[ABSTRACT]トレーニング中の隠れた状態の計算速度を加速するための平均埋め込み層（ael）を備えたインクリメンタルトランスフォーマー</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Dense Representations of Phrases at Scale -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CL/paper_8.html">
      <font color="black">Learning Dense Representations of Phrases at Scale</font>
    </a>
  </h2>
  <font color="black">5つの人気のあるQAデータセットで、モデルDensePhrasesは、以前のフレーズ検索モデルを15％〜25％の絶対精度で改善し、最先端のレトリーバーリーダーモデルのパフォーマンスと一致します。最後に、事前にインデックス付けされた高密度を直接使用します。 2つのスロット充填タスクのフレーズ表現。DensePhrasesをダウンストリームタスクの高密度ナレッジベースとして利用する可能性を示しています。この作業では、オープンではるかに強力なパフォーマンスを実現する高密度フレーズ表現だけを学習できることを初めて示します。ドメインQA。 
[概要]現在のフレーズ検索モデルは、その密度の高い表現に大きく依存しています。これらは、依然としてパフォーマンスの低いレトリーバーです-リーダーアプローチ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Software Pipelining for Quantum Loop Programs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CL/paper_9.html">
      <font color="black">Software Pipelining for Quantum Loop Programs</font>
    </a>
  </h2>
  <font color="black">評価結果は、ループプログラムの合計深度を完全なループ展開によって得られる最適なプログラム深度に近づけることで、ループ内最適化の可能性のみを活用するループオプティマイザーよりも優れたパフォーマンスを示し、サイズがはるかに小さいコードを生成することを示しています。私たちが知る限り、このようなループ制御フローを使用した量子プログラムの最適化に向けた最初のステップ。再定義された概念を使用して、量子ループプログラムの命令レベルの並列処理を活用するソフトウェアパイプライニングアルゴリズムを紹介します。 
[概要]量子プログラムで役立つ概念を再定義します。配列エイリアシング、命令依存性、リソース主義が含まれます。これは、量子プログラムを排除するための最初のステップです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: A Multimodal Framework for the Detection of Hateful Memes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CL/paper_10.html">
      <font color="black">A Multimodal Framework for the Detection of Hateful Memes</font>
    </a>
  </h2>
  <font color="black">単純な微調整を超えて既存のマルチモーダルアプローチのパフォーマンスを改善し、とりわけ、ロバスト性を改善するためのクロス検証に基づくマルチモダリティとアンサンブル学習を促進するための対照的な例のアップサンプリングの有効性を示します。ベースのモデルであり、AUROCスコア80.53を達成し、Facebookが主催する2020 Hateful Memes Challengeのフェーズ2で4位になりました。マルチモーダルヘイトスピーチの検出は本質的に困難で未解決の問題です。ミームは、画像とテキスト、したがって、マルチモーダル推論と視覚と言語の共同理解が必要です。 
[概要]私たちは、憎むべきミームを検出するためのマルチモーダルフレームワークの開発を目指しています。また、モデルの誤分類を分析し、仮説に基づく拡張とそのパフォーマンスへの影響について説明します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Scansion of Spanish Poetry without Syllabification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CL/paper_11.html">
      <font color="black">Automatic Scansion of Spanish Poetry without Syllabification</font>
    </a>
  </h2>
  <font color="black">ただし、これらのコストのかかる方法を使用せずに、有益で正確なメトリック分析を実行することは可能です。また、それぞれ21倍および25倍高速に実行されます。正確なスキャン（音節の数、ストレスパターン、およびタイプ）を実行するアルゴリズムを提案します。詩の）音節なし。 
[概要]これらのシステムは、コストが高いposタグ付けライブラリを使用する複雑な音節化とストレス割り当ての方法に依存しています。また、以上の詩の半句間の補償の現象など、音節数の問題を決定することも考慮していません。 11音節</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Bridging Textual and Tabular Data for Cross-Domain Text-to-SQL Semantic
  Parsing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CL/paper_12.html">
      <font color="black">Bridging Textual and Tabular Data for Cross-Domain Text-to-SQL Semantic
  Parsing</font>
    </a>
  </h2>
  <font color="black">ハイブリッドシーケンスはBERTによってエンコードされ、後続のレイヤーは最小限に抑えられ、テキストDBのコンテキスト化は、BERTの微調整された深い注意によって実現されます。スキーマ整合性駆動型の検索スペースプルーニングを備えたポインタージェネレータデコーダーと組み合わせて、BRIDGEは状態を達成しました-人気のあるクロスDBテキストからSQLへのベンチマークであるSpider（71.1 \％dev、67.5 \％test with ensemble model）およびWikiSQL（92.6 \％dev、91.9 \％test）での最先端のパフォーマンス。 \ url {https://github.com/salesforce/TabularSemanticParsing}で入手できます。 
[ABSTRACT] bridgeは、タグ付きシーケンスで質問とdbスキーマを表し、フィールドのサブセットは、質問に記載されているセル値で拡張されます。bridgeは、人気のあるクロス-dbテキスト-から-トリッキーなベンチマーク、スパイダーで最先端のパフォーマンスを達成しましたおよびwikisql</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Negation in Cognitive Reasoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CL/paper_13.html">
      <font color="black">Negation in Cognitive Reasoning</font>
    </a>
  </h2>
  <font color="black">したがって、構文の否定、厳密に言えば、否定されたイベントまたはプロパティをその逆に減らすことを目指します。否定は、形式論理と自然言語の両方での操作であり、命題が反対を表すものに置き換えられます。 「not」または別の否定キューの追加。ただし、実際の論理データベースの知識は常に不完全であるため、自動推論システムの前方推論だけでは、完全な証明ではなく部分的であることが多いため、質問に対する回答を導き出すのに十分ではありません。肯定的な知識を引き出すことができます。 
[ABSTRACT]否定は、常識的な推論で構成される認知的推論に必要です。これは、一般的な質問応答に論理と機械学習の両方を使用する認知的推論の基礎を築きます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Theoretical Knowledge Graph Reasoning via Ending Anchored Rules -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CL/paper_14.html">
      <font color="black">Theoretical Knowledge Graph Reasoning via Ending Anchored Rules</font>
    </a>
  </h2>
  <font color="black">結果は、EARDictモデルが、WN18RRで96.6％のHits @ 10スコアを達成するなど、知識グラフ補完の2つの大きなデータセットですべてのベンチマークモデルを大幅に上回っていることを示しています。私たちの理論は、トリプルが正しい理由またはそうでない理由を説明する正確な理由を提供します。次に、EARDictモデルと呼ばれるものによって理論を実装します。 
[概要] eardictモデルからの新しい調査は、必要な情報量の証拠を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Visual Question Answering using Deep Learning: A Survey and Performance
  Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CL/paper_15.html">
      <font color="black">Visual Question Answering using Deep Learning: A Survey and Performance
  Analysis</font>
    </a>
  </h2>
  <font color="black">最後に、バニラVQAモデル、Stacked Attention Network、VQA Challenge 2017の受賞者モデルについて計算した結果の一部を紹介し、説明します。また、課題と今後の研究の方向性とともに詳細な分析を提供します。次へ、VQAデータセットに対して有望な結果を示した新しい深層学習モデルについて説明します。 
[概要] vqaシステムは、画像の視覚要素を使用して正しい答えを見つけようとします。これは、さまざまな質問と質問からの回答に基づいています。新しいモデルは、詳細な分析を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-27">
        <br><font color="black">2019-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Code Switching Language Model Using Monolingual Training Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CL/paper_16.html">
      <font color="black">Code Switching Language Model Using Monolingual Training Data</font>
    </a>
  </h2>
  <font color="black">リカレントニューラルネットワーク（RNN）モデルは、シーケンシャルデータの予測に最適であるため、両方の方法を組み合わせることで、パープレキシティが299.63から80.38に減少します。結果から、トレーニングで単言語データの代替バッチを使用すると、パープレキシティが減少したと結論付けられます。 CS言語モデルの。 
[要約]提案された方法は、コードスイッチトレーニングデータを使用した言語モデルの微調整に匹敵しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Automated Lay Language Summarization of Biomedical Scientific Reviews -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/cs.CL/paper_17.html">
      <font color="black">Automated Lay Language Summarization of Biomedical Scientific Reviews</font>
    </a>
  </h2>
  <font color="black">この論文では、生物医学科学レビューの一般言語要約の自動生成の新しいタスクを紹介し、生物医学文献のアクセシビリティを強化するための自動化された方法の開発と評価をサポートするデータセットを構築します。現在の試みの限界、将来の作業のための洞察と方向性を提供します。最先端の要約モデルといくつかのデータ拡張手法を実験し、自動化されたメトリックと人間による評価の両方を使用してそれらのパフォーマンスを評価します。 
[概要]医療用語とこのドメインの専門用語の複雑な構造により、健康情報の解釈が困難になります。医療用語は、医療用語と同じくらい重要な健康情報を識別するために使用できますが、医療専門用語はプロセスにとって非常に重要です。一般の人々は問題に対応する可能性が高い</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Incremental Text-to-Speech Synthesis Using Pseudo Lookahead with Large
  Pretrained Language Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/eess.AS/paper_0.html">
      <font color="black">Incremental Text-to-Speech Synthesis Using Pseudo Lookahead with Large
  Pretrained Language Model</font>
    </a>
  </h2>
  <font color="black">観測されていない将来の文（以下、「先読み」）をあまり利用しない低遅延設定で高品質の音声を生成することは困難です。この研究では、待ち時間を増やさずに将来の文脈情報を考慮する言語モデル..評価結果は、私たちの方法が1）観測された情報のみを使用する方法よりも待ち時間を増やさずに高い音声品質を達成し、2）待機と同等の音声品質を達成しながら待ち時間を短縮することを示しています将来のコンテキスト観察のために。 
[ABSTRACT]インクリメンタルttsは、遅延と出力音声の品質の間のトレードオフの影響を受けます。この方法では、言語モデルで作成された疑似先読みを使用して、遅延を増やすことなく将来のコンテキスト情報を検討します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Meta Sampling for Multilingual Low-Resource Speech
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/eess.AS/paper_1.html">
      <font color="black">Adversarial Meta Sampling for Multilingual Low-Resource Speech
  Recognition</font>
    </a>
  </h2>
  <font color="black">最後に、2つの多言語データセットでの実験結果は、MML-ASRにAMSを適用するとパフォーマンスが大幅に向上することを示しています。また、他の低リソース音声タスクや転移学習ASRアプローチへのAMSの適用性も示しています。 MML-ASRの現在のクエリ損失を敵対的に増加させるためのタスクサンプリングポリシーを学習するための、ネットワークへのすべてのソース言語ドメインの過去のタスククエリ損失。低リソースターゲット言語として、低リソース自動音声認識（ASR）は困難です。データはASRモデルを適切にトレーニングできません。 
[要約]各ソース言語について、質問の損失が大きい場合、そのタスクは、量と難易度の観点からasrモデルをトレーニングするために十分にサンプリングされていないことを意味します。mml-asrのリソースは学習状況をマスターできるため、予測できます。各言語の良好なタスクサンプリング確率</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-22">
        <br><font color="black">2020-12-22</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Speaker Diarization as Post-Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/eess.AS/paper_2.html">
      <font color="black">End-to-End Speaker Diarization as Post-Processing</font>
    </a>
  </h2>
  <font color="black">互いの弱点を補うために、クラスタリングベースの方法で得られた結果の後処理として、2スピーカーのエンドツーエンドダイアリゼーション法を使用することを提案します。結果から2つのスピーカーを繰り返し選択し、結果を更新します。重複領域を改善するための2つの話者の比較..一方、一部のエンドツーエンドのダイアリゼーション方法では、問題をマルチラベル分類として扱うことにより、重複する音声を処理できます。 
[ABSTRACT]ダイアリゼーション方式は、フレームを話者数のクラスターに分割します。これは、各フレームが1人の話者に割り当てられるため、通常、重複する音声を処理できないことを意味します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-18">
        <br><font color="black">2020-12-18</font>
      </time>
    </span>
</section>
<!-- paper0: A Principle Solution for Enroll-Test Mismatch in Speaker Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/eess.AS/paper_3.html">
      <font color="black">A Principle Solution for Enroll-Test Mismatch in Speaker Recognition</font>
    </a>
  </h2>
  <font color="black">結果は、提案されたSDアプローチが非常に効果的であり、一般的に採用されているが理論的には最適ではないアドホックマルチ条件トレーニングアプローチよりも優れていることを示しました。このアプローチは正規化尤度（NL）スコアリングフレームワークに基づいており、登録条件とテスト条件の両方の統計が正確である場合、理論的に最適です。このペーパーでは、この問題を解決するための統計分解（SD）アプローチを紹介します。 
[概要]調査は、異なるタイプの不一致を持つ3つのデータセットで実施されました。これには、物理チャネルの不一致と発話スタイルの不一致が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: Code Switching Language Model Using Monolingual Training Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/eess.AS/paper_4.html">
      <font color="black">Code Switching Language Model Using Monolingual Training Data</font>
    </a>
  </h2>
  <font color="black">単一言語データのみを使用してコードスイッチング（CS）言語モデルをトレーニングすることは、現在も進行中の研究課題です。提案された方法は、コードスイッチトレーニングデータを使用した言語モデルの微調整に匹敵しました。結果から、トレーニングにおける単一言語データの代替バッチは、CS言語モデルの複雑さを軽減しました。 
[要約]提案された方法は、コードスイッチトレーニングデータを使用した言語モデルの微調整に匹敵しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
<!-- paper0: CN-Celeb: multi-genre speaker recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-24/eess.AS/paper_5.html">
      <font color="black">CN-Celeb: multi-genre speaker recognition</font>
    </a>
  </h2>
  <font color="black">次に、このデータセットを使用して、マルチジャンル現象、特にマルチジャンルチャレンジが話者認識に与える影響、および貴重なマルチジャンルデータをより効率的に利用する方法に関する包括的な調査を実施します。スピーカーに関する研究認識は、野生の状況での脆弱性に対処するために拡張されています。その中で、ジャンルの不一致はおそらく最も困難です。たとえば、会話や歌の音声でテストしながら音声を読むことで登録します。残念ながら、既存のマルチジャンルのコーパスは、サイズは限られていますが、管理された条件下でも記録されているため、マルチジャンルの問題に関する決定的な研究をサポートすることはできません。 
[要約]この不一致は、複雑で複合的なセッション間の変動につながります。これらは不可欠です-話し方、生理学的状態、および外因性です。しかし、マルチスピーカーは、影響を受ける人の数がわかりません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-23">
        <br><font color="black">2020-12-23</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
