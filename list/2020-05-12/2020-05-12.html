<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-05-12の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: A Study of Non-autoregressive Model for Sequence Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.SD/paper_0.html">
      A Study of Non-autoregressive Model for Sequence Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ニューラル機械翻訳（NMT）、自動音声認識（ASR）、テキスト音声変換（TTS）などのさまざまなタスクで、ARとNARモデル間のギャップを埋めるために、知識の抽出やソースとターゲットの配置など、さまざまな手法が提案されています。 3）ソースとターゲットのアラインメントの制約により、ターゲットトークンのソーストークンへの依存が促進され、NARモデルのトレーニングが容易になります。2）知識の抽出により、ターゲットシーケンスのターゲットトークンの依存関係が減少し、NARモデルの精度が向上します。 
[要約] arモデルとnarモデルの間のギャップを埋める新しい手法が提案されています。narモデルはターゲットトークン間の依存関係を使用しません。ただし、直感的に、narシーケンス生成の難しさはターゲット精度間の依存関係の強さに大きく依存します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-22">
        <br>2020-04-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Incremental Learning for End-to-End Automatic Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.SD/paper_1.html">
      Incremental Learning for End-to-End Automatic Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      新しい名前付きエンティティタスクの場合、この方法により、事前トレーニング済みのモデルと比較して精度が大幅に向上します。実験により、この方法では、事前トレーニング済みモデルと完全データ再トレーニングベースラインと比較した場合、新しいシナリオでそれぞれ3.25％と0.88％の絶対文字誤り率（CER）が削減されることがわかりました。両方の新しいタスクの適応について、新しいモデルでも、古いタスクのベースラインと同じ精度が維持されます。 
[要約]提案された方法は、古いデータセットにアクセスしなくても効果的です。これは、トレーニングコストが高く、古いデータセットが利用できないという問題に対処します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br>2020-05-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Spatio-Temporal Beamformer for Target Speech Separation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.SD/paper_2.html">
      Neural Spatio-Temporal Beamformer for Target Speech Separation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらなる改善には、実数値マスクの複素数値マスクへの置き換えと、複素マスクNNの共同トレーニングが含まれます。最新のNNマスクベースのMVDRビームフォーマーと比較すると、マルチタップMVDRビームフォーマーは、先行技術ですでに利用されているマイク間相関に加えて、フレーム間相関を利用します。自動音声認識（ASR）に有害です。 
[要約] nn-予測マスクを備えた最小変動歪みなし応答（mvdr）ビームフォーマーは、音声歪みを大幅に削減できます。新しいシステムは、状態に基づいています-nn-マスクベースのmvdr
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-08">
        <br>2020-05-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: GACELA -- A generative adversarial context encoder for long audio
  inpainting -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.SD/paper_3.html">
      GACELA -- A generative adversarial context encoder for long audio
  inpainting
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの被験者はしばしば修復を検出することができましたが、アーティファクトの重大度は許容できないものから穏やかな不安に減少しました。第2に、ギャップを取り巻く利用可能な情報、つまりコンテキストだけでなく、潜在的な変数にも条件があります。条件付きGANの概要。GACELLAは、さまざまな複雑さおよび375〜msから1500〜msの範囲のギャップ時間の音楽信号のリスニングテストでテストされました。 
[ABSTRACT] gacelaは、音楽信号のリスニングテストのビジュアルビジュアルプロダクトです。さまざまなタイプの音楽の録音を使用できます。これには、さまざまな複雑さとギャップ時間の音楽信号が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br>2020-05-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-band MelGAN: Faster Waveform Generation for High-Quality
  Text-to-Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.SD/paper_4.html">
      Multi-band MelGAN: Faster Waveform Generation for High-Quality
  Text-to-Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたマルチバンドMelGANは、波形生成とTTSでそれぞれ4.34と4.22の高いMOSを達成しました。Pytorchの実装は、まもなくオープンリソースとなり、ハードウェア固有の最適化なしでCPUでリアルタイム係数0.03を達成できます。 ..さらに重要なことには、MelGANをマルチバンド処理で拡張します。ジェネレータはメルスペクトログラムを入力として受け取り、サブバンド信号を生成します。その後、サブバンド信号を合計して弁別器入力としてフルバンド信号に戻します。 
[ABSTRACT]ジェネレーターは、mel-スペクトログラムを入力として受け取り、サブバンド信号を生成します。その後、サブバンド信号を合計して、弁別器入力としてフルバンド信号に戻します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br>2020-05-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Online Monaural Speech Enhancement Using Delayed Subband LSTM -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.SD/paper_5.html">
      Online Monaural Speech Enhancement Using Delayed Subband LSTM
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ネットワークは、信号の定常性とローカルスペクトルパターンに依存する音声対雑音の識別関数を学習します。これに基づいて、各周波数でクリーンな音声マスクを予測します。将来の情報、つまり先読みでは、出力遅延サブバンドアーキテクチャを提案します。これにより、単方向転送ネットワークは、現在のフレームに加えていくつかの将来のフレームを処理できます。 
[要約]提案された方法は、短時間のセオドア変換（stft）ドメインで開発されています。周波数全体で同じlstmを使用する必要があるため、ネットワークパラメーターの数、トレーニングデータの量、および計算負荷が大幅に削減されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br>2020-05-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Segment Aggregation for short utterances speaker verification using raw
  waveforms -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.SD/paper_6.html">
      Segment Aggregation for short utterances speaker verification using raw
  waveforms
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      話者検証システムに関するほとんどの研究は、十分な音声情報で構成される長時間の発話に焦点を当てています。提案された方法は、入力発話をいくつかの短い発話にセグメント化し、セグメント化された入力から抽出されたセグメント埋め込みを集約して、スピーカー埋め込みを構成します。提案された方法は、話者認証システムの安定性と精度を改善するためにアンサンブルベースの設計を採用しています。 
[要約]提案された方法は、アンサンブルベースの設計を使用して話者検証システムの精度を向上させます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: LaFurca: Iterative Multi-Stage Refined End-to-End Monaural Speech
  Separation Based on Context-Aware Dual-Path Deep Parallel Inter-Intra Bi-LSTM -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.SD/paper_7.html">
      LaFurca: Iterative Multi-Stage Refined End-to-End Monaural Speech
  Separation Based on Context-Aware Dual-Path Deep Parallel Inter-Intra Bi-LSTM
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      デュアルパス双方向長期短期メモリ（BiLSTM）ブロックを備えたディープニューラルネットワークは、シーケンスモデリング、特に音声分離などで非常に効果的であることが証明されています。 https://github.com/ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separationでDPRNN-TasNetの再実装をオープンソース化しており、LaFurcaはこのDPRNNの実装に基づいて実現されています-TasNet、この論文の結果はスムーズに再現できると考えられています。パブリックWSJ0-2mixデータコーパスでの実験では、20.55dBのSDR改善、20.35dBのSI-SDR改善、PESQの3.69、94.86 \％が得られました。 ESTOIは、提案されたネットワークが話者分離タスクのパフォーマンス向上につながることを示しています。 
[ABSTRACT] bi bitm、bitm、bitom、bitm：bitom、bitomtom、bitm.networkには「順列ターナーターナーターナー」が含まれ、順列バインディングtraining.networkは「並列」に基づいています-bitm-bitm
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-23">
        <br>2020-01-23
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Listen Attentively, and Spell Once: Whole Sentence Generation via a
  Non-Autoregressive Architecture for Low-Latency Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.CL/paper_0.html">
      Listen Attentively, and Spell Once: Whole Sentence Generation via a
  Non-Autoregressive Architecture for Low-Latency Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      LASOは6.4％の文字エラー率を達成します。これは、最先端の自己回帰トランスフォーマーモデル（6.7％）よりも優れています。また、モデルは注意ベースのフィードフォワード構造に基づいているため、効率的に並列に計算を実装できます。 ..注意ベースのエンドツーエンドモデルは音声認識で有望なパフォーマンスを達成しましたが、ビーム検索でのマルチパスフォワード計算は、推論時間コストを増加させ、実際のアプリケーションを制限します。 
[ABSTRACT] laso（注意深く聞いて、1回綴る）と呼ばれるシステム。非自動再生のend-to-time音声認識システムを予測します。自己回帰音声認識を使用しない場合、ワンパス通信によりブラウザの時間が大幅に短縮されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br>2020-05-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Copy mechanism and tailored training for character-based data-to-text
  generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.CL/paper_1.html">
      Copy mechanism and tailored training for character-based data-to-text
  generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、文字はすべてのテキストの共通の「ビルディングブロック」を構成するため、テキスト生成へのより一般的なアプローチを可能にし、伝達学習をトレーニングに活用する可能性を可能にします。しかし、これらの形式の処理は、依存するモデルを生み出します。 E2Eチャレンジで使用されている有名なE2Eデータセットの修正バージョンである、文字ベースのモデルのコピー機能を強調するために設計されたE2E +と呼ばれる新しいデータセットも導入します。 
[ABSTRACT]最も広く使用されているシーケンス-ツーシーケンスのニューラルメソッドは単語ベースです。一般的でない単語や不明な単語に対処するには、語彙化と呼ばれる前処理ステップが必要です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-26">
        <br>2019-04-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Leveraging Monolingual Data with Self-Supervision for Multilingual
  Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.CL/paper_2.html">
      Leveraging Monolingual Data with Self-Supervision for Multilingual
  Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちは3つの主要な結果を提供します。（i）単一言語データを使用すると、多言語モデルでの低リソース言語の翻訳品質が大幅に向上します。過去数年間で、低リソースニューラル機械翻訳（NMT）で2つの有望な研究方向が明らかになりました。 （iii）自己監督機能を備えた単一言語データを活用することで、多言語モデルに新しい言語を追加し、並列データや逆翻訳なしでローエン翻訳で最大33 BLEUを実現するための実行可能なパスが提供されます。 
[要旨]最初は、単一言語データを使用して低言語から多言語へのパスを改善することに焦点を当てています。最初は、将来的に多言語データを開発することを目的としています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br>2020-05-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Entity Synonym Discovery via Multipiece Bilateral Context Matching -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.CL/paper_3.html">
      Entity Synonym Discovery via Multipiece Bilateral Context Matching
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      オープンワールド設定で同義エンティティを自動的に検出できることは、エンティティの曖昧性解消やナレッジグラフの正規化などのさまざまなタスクに役立ちます。同義語検出の主要コンポーネントの1つとして、2つが指定されているかどうかを判断するニューラルネットワークモデルSYNONYMNETを導入しますエンティティは相互に同義です。エンティティ機能を使用する代わりに、SYNONYMNETはエンティティが言及されている複数のコンテキストを利用し、双方向のマッチングスキーマを介してコンテキストレベルの類似性を比較します。 
[ABSTRACT]ニューヨークを拠点とするスタートアップは、指定された2つのエンティティが互いに同義であるかどうかを確認できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-31">
        <br>2018-12-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: UiO-UvA at SemEval-2020 Task 1: Contextualised Embeddings for Lexical
  Semantic Change Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.CL/paper_4.html">
      UiO-UvA at SemEval-2020 Task 1: Contextualised Embeddings for Lexical
  Semantic Change Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      それらは強力なベースラインを大幅に上回っていますが（評価後の段階では、SemEval-2020タスク1のサブタスク2の提出が最も優れています）、興味深いことに、特定のアルゴリズムの選択はテストセット内のゴールドスコアの分布に依存します.. SemEval-2020共有タスク1.の字句意味変化検出に文脈化された単語埋め込みを適用します。2つの文脈化アーキテクチャ（BERTおよびELMo）と3つの変化検出アルゴリズムのパフォーマンスを分析します。 
[ABSTRACT]最も効果的なアルゴリズムは、平均トークン埋め込みとペアワイズ距離の間のコサイン類似性に依存していることがわかります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br>2020-04-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multiscale Collaborative Deep Models for Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.CL/paper_5.html">
      Multiscale Collaborative Deep Models for Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、当社のディープMSCは、最新のディープNMTモデルを大幅に上回るWMT14英語-ドイツ語タスクで30.56のBLEUスコアを達成しています。ブロックを導入することにより、トップレベルからボトムレベルへの勾配の逆伝播を明示的にブーストします。深いNMTモデルへの大規模なコラボレーションメカニズム。MSCネットは最適化が容易であり、大幅に増加した深さから翻訳品質の改善が得られることを示す経験的証拠を提供します。 
[要旨]マルチスケールの協調的フレームワークを提示して、以前に使用されたものより大幅に深いモデルのトレーニングを容易にします。各モデルブロックにきめの細かい表現を学習させ、空間依存性をキャプチャすることでそれを強化します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br>2020-04-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Study of Non-autoregressive Model for Sequence Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.CL/paper_6.html">
      A Study of Non-autoregressive Model for Sequence Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2）知識の蒸留により、ターゲットシーケンスのターゲットトークンの依存関係が減少し、NARモデルの精度が向上します。この作業では、NARシーケンスの生成の難しさを理解するための調査を実施し、回答を試みます。一部のタスクではARモデルに追いつくことができますが、すべてではありませんか？非自己回帰（NAR）モデルは、シーケンスのすべてのトークンを並行して生成するため、自己回帰（AR）の対応物と比較して生成速度が速くなりますが、精度は低下します。 
[要約] arモデルとnarモデルの間のギャップを埋める新しい手法が提案されています。narモデルはターゲットトークン間の依存関係を使用しません。ただし、直感的に、narシーケンス生成の難しさはターゲット精度間の依存関係の強さに大きく依存します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-22">
        <br>2020-04-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Synchronous Bidirectional Learning for Multilingual Lip Reading -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.CL/paper_7.html">
      Synchronous Bidirectional Learning for Multilingual Lip Reading
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      したがって、多言語ターゲットの学習は、音素の予測に改善をもたらすはずです。類似の音素は、常に類似の視覚パターンにつながります。多言語設定は、異なる言語間で共有される各音素の量と多様性の両方を増加させます。 
[要約]この論文では、多言語の読唇の相乗効果に焦点を当てています。すべての言語の唇の動きは類似したパターンを共有しています。唇の動きは、異なる言語間で共有される各音素の量と多様性を増加させます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-08">
        <br>2020-05-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Incremental Learning for End-to-End Automatic Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.CL/paper_8.html">
      Incremental Learning for End-to-End Automatic Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      どちらの新しいタスクの適応でも、新しいモデルは古いタスクのベースラインと同じ精度を維持しています。実験により、このシナリオでは、新しいシナリオで3.25％と0.88％の絶対文字エラー率（CER）が減少することが示されています。事前トレーニング済みモデルと完全データ再トレーニングベースラインとそれぞれ比較。16.95％の絶対CER削減。 
[要約]提案された方法は、古いデータセットにアクセスしなくても効果的です。これは、トレーニングコストが高く、古いデータセットが利用できないという問題に対処します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br>2020-05-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Deep Learning Approach for Automatic Detection of Fake News -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.CL/paper_9.html">
      A Deep Learning Approach for Automatic Detection of Fake News
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたシステムは、2つのモデルでそれぞれ3.08％と9.3％の大幅なマージンで現在の手作りの機能エンジニアリングベースの最新システムよりも優れた、有望なパフォーマンスをもたらします。データセットを利用するために、関連するタスクでは、クロスドメイン分析（つまり、FakeNews AMTでトレーニングされ、Celebrityでテストされたモデル、およびその逆）を実行して、ドメイン全体でのシステムの適用性を調査します。 
[ABSTRACT] fakenews amtとセレブの偽ニュース検出はマルチドメインプラットフォームでテストされています。データセットは現在データセットでテストされています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br>2020-05-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: BLEURT: Learning Robust Metrics for Text Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.CL/paper_10.html">
      BLEURT: Learning Robust Metrics for Text Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      BLEURTは、過去3年間のWMTメトリック共有タスクとWebNLG競争データセットに関する最新の結果を提供します。私たちのアプローチの重要な側面は、何百万もの合成例を使用して、モデルは一般化します。バニラBERTベースのアプローチとは対照的に、トレーニングデータが不足していて分布が不足している場合でも、優れた結果が得られます。 
[ABSTRACT]評価指標は遅れています。最も一般的な選択は人間の判断とあまり相関しない可能性があるためです。私たちのアプローチの重要な側面は、モデルの一般化に役立つ数百万の合成例を使用する新しい事前トレーニングスキームです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br>2020-04-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Combining Visual and Textual Features for Semantic Segmentation of
  Historical Newspapers -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.CL/paper_11.html">
      Combining Visual and Textual Features for Semantic Segmentation of
  Historical Newspapers
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ディープラーニングテクニックのおかげで、過去数年間でドキュメントイメージ内の関心のあるセグメントの識別と分類が大幅に進歩した場合、とりわけ、より細かいセグメンテーションタイポロジーの使用や複雑で異種のドキュメントの検討など、多くの課題が残っています。歴史的な新聞など。結果は、強い視覚的ベースラインと比較してマルチモーダルモデルの一貫した改善、および大きな材料の変化に対するより優れた堅牢性を示しています。さらに、ほとんどのアプローチは視覚的特徴のみを考慮し、テキスト信号を無視しています。 
[ABSTRACT]新しいレイアウトは、処理されたドキュメントの数を調べるために使用されています。ドキュメントレイアウト分析の最初の重要なステップとして、ドキュメントはますます増加しているとのことです。結果は、通時的なスイスとルクセンブルクの新聞に関する一連の実験に基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-14">
        <br>2020-02-14
      </time>
    </span>
  </h3>
</article>
<!-- paper0: KinGDOM: Knowledge-Guided DOMain adaptation for sentiment analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.CL/paper_12.html">
      KinGDOM: Knowledge-Guided DOMain adaptation for sentiment analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの学習された概念で人気のあるドメイン敵対的なベースラインメソッドを調整すると、最先端のアプローチよりもパフォーマンスが向上し、提案されたフレームワークの有効性が実証されます。新しいフレームワークであるKinGDOMを導入します。ドメイン固有の背景概念とドメイン一般的な背景概念の両方を提供することにより、ドキュメントのセマンティクスを充実させます。これらの概念は、ドメイン不変の方法でドメイン間概念を活用するグラフ畳み込みオートエンコーダーをトレーニングすることによって学習されます。 
[要約]このペーパーでは、外部の常識的な知識の役割を探ります。これらの概念は、グラフ畳み込みオートエンコーダーをトレーニングすることによって学習されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-02">
        <br>2020-05-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: DIET: Lightweight Language Understanding for Dialogue Systems -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.CL/paper_13.html">
      DIET: Lightweight Language Understanding for Dialogue Systems
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの最高のパフォーマンスのモデルはBERTの微調整よりもパフォーマンスが高く、トレーニングが約6倍高速です。驚くべきことに、このタスクに大規模な事前トレーニング済みモデルを使用しても明確な利点はなく、実際にDIETは事前にトレーニングされた埋め込みのない純粋に監視されたセットアップでもアート。大規模な事前トレーニングされた言語モデルは、GLUEやSuperGLUEなどの言語理解ベンチマークで印象的な結果を示し、分散表現（GloVe ）および純粋に監視されたアプローチ。 
[ABSTRACT]二重の意図とエンティティトランスフォーマー（ダイエット）アーキテクチャを紹介します。意図とエンティティの予測に関する2つの事前トレーニング済みモデルの有効性を調査します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br>2020-04-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: To Test Machine Comprehension, Start by Defining Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.CL/paper_14.html">
      To Test Machine Comprehension, Start by Defining Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、既存のシステムがナラティブを定義するときにナラティブ理解のタスクに達していないことを強く示唆する実験を行います。次に、広く役立つクラスの理解の詳細な定義（「理解のテンプレート」）を示します。テキスト、つまり短いナラティブ。最初に、既存のアプローチでは理解度を適切に定義していないと主張します。彼らはどのコンテンツがテストされるかについてあまりにも体系的ではありません。 
[ABSTRACT]多くのタスク設計者は、実際にはどのシステムがどうあるべきかを議論することから始めます。彼らは、既存の定義は理解を適切に定義していないと主張します。彼らはどのコンテンツがテストされるかについてあまりに体系的ではありません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-04">
        <br>2020-05-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards logical negation for compositional distributional semantics -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/cs.CL/paper_15.html">
      Towards logical negation for compositional distributional semantics
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーでは、この演算子を提供するためのいくつかのステップを示し、単語に直交する部分空間への投影のバージョンとしてモデル化します。意味のカテゴリカル構成分布モデルは、単語の構成をフレーズとセンテンスのプライドに構成します。文含意タスクにおけるオペレーターのパフォーマンスの小さなデモンストレーション。 
[ABSTRACT]これまでは否定のモデルがありませんでした。文の含意タスクで演算子の小さなデモンストレーションを提供します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br>2020-05-11
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Listen Attentively, and Spell Once: Whole Sentence Generation via a
  Non-Autoregressive Architecture for Low-Latency Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/eess.AS/paper_0.html">
      Listen Attentively, and Spell Once: Whole Sentence Generation via a
  Non-Autoregressive Architecture for Low-Latency Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、モデルは注意ベースのフィードフォワード構造に基づいているため、計算を効率的に並列に実装できます。LASOは6.4％の文字エラー率を達成し、最新の自己回帰変換モデル（6.7％）よりも優れています。 ..公開されている中国語データセットAISHELL-1で実験を行います。 
[ABSTRACT] laso（注意深く聞いて、1回綴る）と呼ばれるシステム。非自動再生のend-to-time音声認識システムを予測します。自己回帰音声認識を使用しない場合、ワンパス通信によりブラウザの時間が大幅に短縮されます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br>2020-05-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: End-To-End Speech Synthesis Applied to Brazilian Portuguese -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/eess.AS/paper_1.html">
      End-To-End Speech Synthesis Applied to Brazilian Portuguese
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、転移学習、音声文字起こし、ノイズ除去が、提示されたデータセットでモデルをトレーニングするのに役立つことを確認しました。エンドツーエンドの音声合成を実行する3つの異なるアーキテクチャを調査しました：Tacotron 1、DCTTS、およびMozilla TTS。さまざまなボコーダー（RTISI-LA、WaveRNN、Universal WaveRNN）、音声文字起こしの使用、転移学習（英語から）、ノイズ除去によるモデルのパフォーマンス。 
[ABSTRACT]これは、ブラジルのポルトガル語で公的に利用可能なリソースの作成です。これらには、エンドツーエンドの音声合成用のデータセットとディープラーニングモデルが含まれています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br>2020-05-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Study of Non-autoregressive Model for Sequence Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/eess.AS/paper_2.html">
      A Study of Non-autoregressive Model for Sequence Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2）知識の蒸留により、ターゲットシーケンスのターゲットトークンの依存関係が減少し、NARモデルの精度が向上します。この作業では、NARシーケンスの生成の難しさを理解するための調査を実施し、回答を試みます。 
[要約] arモデルとnarモデルの間のギャップを埋める新しい手法が提案されています。narモデルはターゲットトークン間の依存関係を使用しません。ただし、直感的に、narシーケンス生成の難しさはターゲット精度間の依存関係の強さに大きく依存します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-22">
        <br>2020-04-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Incremental Learning for End-to-End Automatic Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/eess.AS/paper_3.html">
      Incremental Learning for End-to-End Automatic Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      どちらの新しいタスクの適応でも、新しいモデルは古いタスクのベースラインと同じ精度を維持します。提案された方法は、古いデータセットにアクセスせずに効果的で、高いトレーニングコストと古いデータセットが利用できないという問題に対処します。実験により、この方法では、事前トレーニング済みモデルと完全データ再トレーニングベースラインと比較した場合、新しいシナリオでそれぞれ3.25％と0.88％の絶対文字誤り率（CER）が削減されることが示されています。 
[要約]提案された方法は、古いデータセットにアクセスしなくても効果的です。これは、トレーニングコストが高く、古いデータセットが利用できないという問題に対処します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br>2020-05-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Neural Spatio-Temporal Beamformer for Target Speech Separation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/eess.AS/paper_4.html">
      Neural Spatio-Temporal Beamformer for Target Speech Separation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらなる改善には、実数値マスクの複素数値マスクへの置き換え、および複素マスクNNの合同トレーニングが含まれます。純粋にニューラルネットワーク（NN）ベースの音声分離および拡張方法ですが、必然的に良好な客観的スコアを達成できます。自動音声認識（ASR）に有害な非線形音声歪みを引き起こします。このホワイトペーパーでは、音声の分離と強化のために、複素数値マスクを備えたマルチタップMVDRビームフォーマーを提案します。 
[要約] nn-予測マスクを備えた最小変動歪みなし応答（mvdr）ビームフォーマーは、音声歪みを大幅に削減できます。新しいシステムは、状態に基づいています-nn-マスクベースのmvdr
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-08">
        <br>2020-05-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: GACELA -- A generative adversarial context encoder for long audio
  inpainting -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/eess.AS/paper_5.html">
      GACELA -- A generative adversarial context encoder for long audio
  inpainting
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの被験者はしばしばインペインティングを検出できましたが、アーティファクトの重大度は、許容できないものから穏やかな妨害にまで減少しました。 、それは、受容野の解像度を高めることで5つの並列弁別器に依存することにより、オーディオ情報のさまざまな時間スケールを考慮します。 
[ABSTRACT] gacelaは、音楽信号のリスニングテストのビジュアルビジュアルプロダクトです。さまざまなタイプの音楽の録音を使用できます。これには、さまざまな複雑さとギャップ時間の音楽信号が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br>2020-05-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-band MelGAN: Faster Waveform Generation for High-Quality
  Text-to-Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/eess.AS/paper_6.html">
      Multi-band MelGAN: Faster Waveform Generation for High-Quality
  Text-to-Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたマルチバンドMelGANは、波形生成とTTSでそれぞれ4.34と4.22の高いMOSを達成しています。さらに重要なことに、MelGANをマルチバンド処理で拡張します。ジェネレータはメルスペクトログラムを入力として受け取り、サブバンド信号を生成します。続いて、弁別器入力としてフルバンド信号に加算されます。事前トレーニングとともに、この改善により、品質が向上し、トレーニングの安定性が向上します。 
[ABSTRACT]ジェネレーターは、mel-スペクトログラムを入力として受け取り、サブバンド信号を生成します。その後、サブバンド信号を合計して、弁別器入力としてフルバンド信号に戻します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br>2020-05-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Online Monaural Speech Enhancement Using Delayed Subband LSTM -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/eess.AS/paper_7.html">
      Online Monaural Speech Enhancement Using Delayed Subband LSTM
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ネットワークは、信号の定常性とローカルスペクトルパターンに基づいて音声対雑音の識別関数を学習し、それに基づいて、各周波数でクリーンな音声マスクを予測します。この論文では、オンラインモノラル用の遅延サブバンドLSTMネットワーク（単一チャネル）音声強調...提案された方法は、短時間フーリエ変換（STFT）ドメインで開発されました。 
[要約]提案された方法は、短時間のセオドア変換（stft）ドメインで開発されています。周波数全体で同じlstmを使用する必要があるため、ネットワークパラメーターの数、トレーニングデータの量、および計算負荷が大幅に削減されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br>2020-05-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Segment Aggregation for short utterances speaker verification using raw
  waveforms -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/eess.AS/paper_8.html">
      Segment Aggregation for short utterances speaker verification using raw
  waveforms
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案手法は、入力発話をいくつかの短い発話にセグメント化し、セグメント化された入力から抽出されたセグメントの埋め込みを集約して話者の埋め込みを構成します。 「セグメント集約」と呼ばれます。話者検証システムに関するほとんどの研究は、十分な音声情報で構成される長時間の発話に焦点を当てています。 
[要約]提案された方法は、アンサンブルベースの設計を使用して話者検証システムの精度を向上させます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br>2020-05-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: LaFurca: Iterative Multi-Stage Refined End-to-End Monaural Speech
  Separation Based on Context-Aware Dual-Path Deep Parallel Inter-Intra Bi-LSTM -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-05-12/eess.AS/paper_9.html">
      LaFurca: Iterative Multi-Stage Refined End-to-End Monaural Speech
  Separation Based on Context-Aware Dual-Path Deep Parallel Inter-Intra Bi-LSTM
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      https://github.com/ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separationでDPRNN-TasNetの再実装をオープンソース化しており、LaFurcaはこのDPRNNの実装に基づいて実現されています-TasNet、このペーパーの結果はスムーズに再現できると考えられています。.DPRNN-TasNet \ cite {luo2019dual} ..このペーパーでは、エンドツーエンドアプローチのためのデュアルパスBiLSTMベースのネットワークのいくつかの改善を提案します1）並列BiLSTMと並列BiLSTMコンポーネントを備えたデュアルパスネットワーク、2）グローバルコンテキスト対応の相互並列BiLSTM、3）複数のスパイラル反復改良デュアルパスBiLSTM、これらのネットワークはすべて、2人の話者の混合発話を受け取り、それを2つの別々の発話にマッピングします。各発話には1人の話者の声だけが含まれます。 
[ABSTRACT] bi bitm、bitm、bitom、bitm：bitom、bitomtom、bitm.networkには「順列ターナーターナーターナー」が含まれ、順列バインディングtraining.networkは「並列」に基づいています-bitm-bitm
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-23">
        <br>2020-01-23
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本日更新された論文はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br>
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
