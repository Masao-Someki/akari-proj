<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-04-09の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Proximal binaural sound can induce subjective frisson -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.SD/paper_0.html">
      Proximal binaural sound can induce subjective frisson
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ここでは、リスナーの頭の周りのノイズ音（ホワイトノイズ、ローリングビーズノイズ、またはビニール袋をこすることによって発生する摩擦ノイズ）の刺激を動かすことによって、フリッソンの主観的な感覚を生み出すことができるかどうかを調査しました。ピアソンの相関分析は、いくつかの音響両耳間レベル差（ILD）の分散、ラウドネス、シャープネスなどの聴覚刺激の特徴は、主観的なフリッソンの大きさと相関していました。また、音楽を動かすことによるフリッソンの主観的な感情は、静的な音楽サウンド。 
[アブストラクト]聴覚フリパーソナルスペースの音のメカニズムは不明です。これらの音は、フリソンの音と似ています-音を誘発します。音-誘発されたフリソンは、聴覚刺激が回転していないものよりも頭の周りを回転するときに強く感じることができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-15">
        <br>2019-04-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An empirical analysis of information encoded in disentangled neural
  speaker representations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.SD/paper_1.html">
      An empirical analysis of information encoded in disentangled neural
  speaker representations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      話者表現の解きほぐしは、発話中に取得される内因性要素（感情、語彙内容など）と信号キャプチャ中に取得される外因性要素（チャネル、ノイズなど）の両方に対する話者表現のロバスト性を改善するために使用される手法の1つです。 ..どちらの場合でも、さまざまな変動要素が表現に絡み合っている程度を理解することが重要です。分類実験を使用して、話者表現を維持しながら、絡み合いの解消が話者表現からの迷惑要因に関する情報を減らすという実証的証拠を提供します。情報。 
[要約]話者表現の解きほぐしは、話者情報のロバスト性を改善するために使用される手法の1つです。これらには、音声生成中に取得される要素（感情、語彙の内容など）や信号形式で達成できる外因性要素が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-10">
        <br>2020-02-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: MM Algorithms for Joint Independent Subspace Analysis with Application
  to Blind Single and Multi-Source Extraction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.SD/paper_2.html">
      MM Algorithms for Joint Independent Subspace Analysis with Application
  to Blind Single and Multi-Source Extraction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、1つ以上の音源のブラインド抽出が、より大きなマイクアレイを活用してより良い分離を実現するための合理的な方法として注目を集めています。特に、過決定IVA（OverIVA）のためにいくつかのMMアルゴリズムが提案されています。補助機能の精神ベースの独立ベクトル分析（AuxIVA）では、1つまたは2つのグループの分離ベクトルに交互に適用できるいくつかの更新を提案します。 
[ABSTRACT]たとえば、メジャー化-最小化手法（jisa-mm）に基づいてjisaのアルゴリズムフレームワークを作成します。この代理関数の最小化は、ハイブリッド厳密-225対角化問題のバリアントにつながります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Comparison for Improvements of Singing Voice Detection System Based on
  Vocal Separation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.SD/paper_3.html">
      Comparison for Improvements of Singing Voice Detection System Based on
  Vocal Separation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後のものは、分類器の予測結果で異常フレームをフィルタリングする後処理です。提案されたシステムでは、主要な3つの部分があります。最初は、ボーカルを抽出する歌声分離の前処理です。音楽なし。 
[要約]歌声検出は、音楽情報検索（mir）の主要なコンポーネントの1つです。提案されたシステムは、長期反復畳み込みネットワーク（lrcn）モデルに基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An initial investigation on optimizing tandem speaker verification and
  countermeasure systems using reinforcement learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.SD/paper_4.html">
      An initial investigation on optimizing tandem speaker verification and
  countermeasure systems using reinforcement learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このような組み合わせはタンデム検出コスト関数（t-DCF）メジャーで評価できますが、個々のコンポーネントは独自のパフォーマンスメトリックを使用して互いに個別にトレーニングされます。この作業では、より良いt -強化学習を使用したDCFの測定。このようなトレーニング手順は実際に複合システムのパフォーマンスを向上させることができ、比較する標準の教師あり学習手法よりも信頼性の高い結果が得られることを示します。 
[要約]これらのシステムは、カスケードシステムに組み合わせることができます。たとえば、システムが合成音声か真正音声かを最初に決定します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br>2020-02-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Conditioned Source Separation for Music Instrument Performances -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.SD/paper_5.html">
      Conditioned Source Separation for Music Instrument Performances
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      プライマリソース分離ネットワークのさまざまなレベルでのコンディショニング手法を探索し、2つの追加のデータモダリティ、つまり混合内の楽器の有無と、対応するビデオストリームデータを利用します。この論文では、複数の楽器のソース分離方法を提案します。同時に鳴って、オーディオストリームとは別の追加情報がどれだけソース分離の品質を上げることができるかを調査します。異なる音楽ソースを同期して調和して再生するため、同じ曲を演奏する異なる楽器を分離することは困難な作業です。 
[要旨]ソースの数はピースごとに異なる場合があります。一部のソースは同じ種類の楽器に属している可能性があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Search Result Clustering in Collaborative Sound Collections -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.SD/paper_6.html">
      Search Result Clustering in Collaborative Sound Collections
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      クラスタリングに最適な機能を特定した後、サウンドデザインタスクを実行するユーザーを対象に実験を行い、アプローチとそのユーザーインターフェイスを評価します。この作業では、多様なクラスター化のためのオーディオ機能を使用したグラフベースのアプローチを提案します。大規模なオンラインデータベースをクエリするときに取得されるサウンドコレクション。各サウンドに関連付けられているメタデータを利用して、さまざまな機能のパフォーマンスを大規模に評価するアプローチを提案します。 
[ABSTRACT]大きくて管理不可能な結果セットは、アイテムの検索に使用されます。これは、従来の検索エンジンを補完するのに役立ちます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Bayesian x-vector: Bayesian Neural Network based x-vector System for
  Speaker Verification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.SD/paper_7.html">
      Bayesian x-vector: Bayesian Neural Network based x-vector System for
  Speaker Verification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、DNN x-ベクトルとベイジアンx-ベクトルシステムの融合により、さらなる改善を達成できます。NISTSRE10コアテストで評価されているVoxceleb1でトレーニングされたモデルは、BNNが約4.69％の大きな相対EER減少をもたらす可能性があることを示唆しています。 、結果は、システムがBNNから恩恵を受ける可能性があることを示しています。ドメイン内の短い発話と長い発話の評価では、それぞれEERが2.66％と2.32％減少しています。 
[要旨]システムは目に見えないデータに対して優れた汎化能力を持っている必要があります。システムは、評価データをより一般化し、一般的な決定をより正確に行うことができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Conditional Rap Lyrics Generation with Denoising Autoencoders -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_0.html">
      Conditional Rap Lyrics Generation with Denoising Autoencoders
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      3つの多様な入力ドメイン（既存のラップの歌詞、ニュース、映画のプロットの要約）での実験結果は、この方法が、入力コンテンツの単語を保存する一貫した技術的に流暢なラップの詩を生成できることを示しています。強力な情報検索ベースラインと比較した、コンテンツの保存とスタイルの転送の間の優れたトレードオフ。歌詞の本質的な意味を伝えるコンテンツの単語を自動的に取り除く3つの異なるアプローチを研究します。 
[ABSTRACT]私たちのアプローチは、トランスフォーマーベースのノイズ除去オートエンコーダーをトレーニングして、コンテンツの単語からラップの歌詞を再構築することです。歌詞の平均韻密度を10％増加させる、BERTベースの言い換えスキームを提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: LadaBERT: Lightweight Adaptation of BERT through Hybrid Model
  Compression -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_1.html">
      LadaBERT: Lightweight Adaptation of BERT through Hybrid Model
  Compression
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、LadaBERT（ハイブリッドモデル圧縮によるBERTの軽量適応）という名前のハイブリッドソリューションを提案することでこの問題に対処します。これは、重みの剪定、行列因数分解、知識の蒸留など、さまざまなモデル圧縮方法の利点を組み合わせたものです。トレーニングのオーバーヘッドを1桁減らすことができる一方で、さまざまなパブリックデータセットの最先端の精度。ただし、知識抽出のトレーニング手順は、教師モデルを模倣するために十分なトレーニングデータが必要であるため、それ自体が高価です。 
[ABSTRACT] bertをオンラインサービスに適用すると、メモリを大量に消費し、ユーザーの行動の待ち時間が不十分になります。知識抽出のトレーニング手順は、教師モデルを模倣するのに十分なトレーニングデータが必要になるため、コストがかかります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Mining Implicit Entity Preference from User-Item Interaction Data for
  Knowledge Graph Completion via Adversarial Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_2.html">
      Mining Implicit Entity Preference from User-Item Interaction Data for
  Knowledge Graph Completion via Adversarial Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このようなアプローチは、KGCタスクのデータの不均一性とセマンティックの複雑さに関する問題を緩和するのに効果的です。弁別器は、ユーザーインタラクションデータから学習された有用な情報を入力として受け取り、評価能力を徐々に高めて、ジェネレーター。私たちの仕事は、多くのKGエンティティがアプリケーションシステムのオンラインアイテムに対応しているという観察に触発されました。 
[ABSTRACT]このホワイトペーパーでは、kgcタスクを改善するためにユーザーとアイテムの豊富なインタラクションデータを活用することを目的とした新しい視点を採用しています。2種類のデータソースには固有の特性が大きく異なるため、元のパフォーマンスを低下させる可能性があります単純な融合戦略
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-28">
        <br>2020-03-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Structure-Level Knowledge Distillation For Multilingual Sequence
  Labeling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_3.html">
      Structure-Level Knowledge Distillation For Multilingual Sequence
  Labeling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      構造レベルの情報に基づく2つの新しいKD法を提案します。（1）学生と教師の構造レベルの確率分布の間の距離をほぼ最小化します。（2）構造レベルの知識を局所分布に集約し、2つの間の距離を最小化します。ローカル確率分布.. 25のデータセットを持つ4つの多言語タスクに関する私たちの実験は、私たちのアプローチがいくつかの強力なベースラインを上回り、ベースラインモデルと教師モデルの両方よりもゼロショットの一般化可能性が高いことを示しています。このホワイトペーパーでは、複数の単一言語モデル（教師）の構造的知識を統合多言語モデル（学生）に抽出することによる、単一言語モデルと統合多言語モデル。 
[ABSTRACT]モノリンガルモデルと統合多言語モデルのギャップを減らすことを提案します。多言語モデルを使用すると、モデルサイズが小さくなり、オンラインサービスが容易になり、低リソース言語への一般化が可能になります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SIA: A Scalable Interoperable Annotation Server for Biomedical Named
  Entities -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_4.html">
      SIA: A Scalable Interoperable Annotation Server for Biomedical Named
  Entities
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのソースから特定の情報を抽出するには、非常に高度なテキストマイニングと情報抽出ツールが必要です。このシステムは現在、6つの名前付きエンティティタイプ（つまり、化学物質、病気、遺伝子、miRNA、突然変異、および生物）をカバーしており、Apache 2.0ライセンスの下で無料で利用できます。 https://github.com/Erechtheus/sia ..しかし、自由に利用できるツールをカスタマイズされたワークフローに統合することは、しばしば煩雑で困難です。 
[ABSTRACT]注釈サーバーsiaは、注釈サーバーのbecalbersとパフォーマンスへの貢献です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Understanding Knowledge Gaps in Visual Question Answering: Implications
  for Gap Identification and Testing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_5.html">
      Understanding Knowledge Gaps in Visual Question Answering: Implications
  for Gap Identification and Testing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、研究者は、このようなデータセットのバランスを改善して、記憶されている言語機能や統計的バイアスに対するシステムの依存性を減らし、視覚的な理解を向上させる必要性を認識しています。しかし、潜在的なパターンが存在するかどうかは不明ですこれらの失敗を定量化して説明するために使用できます。各KGは、解決策に到達するために必要な推論能力を説明し、ギャップを解決できないことは、必要な推論能力がないことを示します。 
[ABSTRACT]現在のvqaデータセットには、通常、オブジェクトの空間情報、オブジェクト属性、または一般的なシーンの質問に関する質問が含まれています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Self-Attention Gazetteer Embeddings for Named-Entity Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_6.html">
      Self-Attention Gazetteer Embeddings for Named-Entity Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、オープンソースのWikidata知識ベースからGazetteerリソースを構築する方法を示します。CoNLL-03およびOntonotes 5データセットの評価では、ベースラインモデルに対するF1の改善をそれぞれ92.34から92.86および89.11から89.32に示し、大規模なパフォーマンスに匹敵するパフォーマンスを達成しています。最先端のモデル..この作品では、GazSelfAttnを紹介します。これは、自己注目とマッチスパンエンコーディングを使用して、拡張されたGazetteer埋め込みを構築する、斬新なGazetteer埋め込みアプローチです。 
[ABSTRACT] gazselfattnは自己アテンションとマッチスパンを使用して、拡張されたGazetteer埋め込みを構築します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploiting Redundancy in Pre-trained Language Models for Efficient
  Transfer Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_7.html">
      Exploiting Redundancy in Pre-trained Language Models for Efficient
  Transfer Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      BERTとXLNetの2つの事前トレーニング済みモデルの包括的な評価では、シーケンスのラベリングとシーケンス分類タスクの多様なスイートを使用して、97以上を維持しながら、機能セットを元のサイズの1〜7％に削減しますパフォーマンスの割合..コンテキスト表現には固有の冗長性とタスク固有の冗長性の両方があると仮定します。大規模な事前トレーニング済みのコンテキスト単語表現は、自然言語処理の分野を変革し、幅広いタスクで印象的な結果を得ています。 
[ABSTRACT]モデルモデルモデルは冗長性を使用して冗長性のサイズを縮小します。ただし、結果は研究者および実務者にとって同様に非現実的です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Frequency, Acceptability, and Selection: A case study of
  clause-embedding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_8.html">
      Frequency, Acceptability, and Selection: A case study of
  clause-embedding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      すべてのデータとコードはhttp://megaattitude.io。で入手できます。動詞のサブカテゴリフレームの頻度分布は、それらのフレームでの許容性の予測因子としては不十分であることを示しています-せいぜい合計の1/3未満しか説明しません辞書全体の受容性に関する情報---さらに、サブカテゴリー化フレームでの動詞の受容性のモデル化に使用されるその一般的な行列因数分解手法は、ほんのわずかに優れています。特に、動詞が見つかる頻度の関係を調査しますサブカテゴリー化フレームとそれらのフレームでのこれらの動詞の受け入れ可能性。特に、「考える」、「欲しい」、「伝える」などの従属節をとる動詞に焦点を当てています。 
[ABSTRACT]サブカテゴリ化フレームは受容性の予測因子としては不十分であることを示します。これらは、受容性の獲得をモデル化するために使用される一般的な行列因数分解手法が、受容性のみであるという説明です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Satirical News Detection with Semantic Feature Extraction and
  Game-theoretic Rough Sets -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_9.html">
      Satirical News Detection with Semantic Feature Extraction and
  Game-theoretic Rough Sets
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ゲーム理論的なラフセットモデルを適用して、ゲームの均衡と反復学習メカニズムによって確率的しきい値が導出される、風刺ニュースを検出します。収集されたデータセットの実験結果は、提案されたアプローチの堅牢性と改善を、Pawlakラフセットモデルと比較して示しています。 SVM ..既存のアプローチでは、風刺ニュースの記事から包括的な単語の特徴を探っていますが、ツイート形式の風刺ニュースに単語ベクトルを使用した意味論的メトリックが欠けています。 
[要約]風刺ニュースの検出システムのホストが提案されています。これらには風刺ニュースのツイートではほとんど分類できないツイートが含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: S2ORC: The Semantic Scholar Open Research Corpus -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_10.html">
      S2ORC: The Semantic Scholar Open Research Corpus
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      8.1Mオープンアクセスペーパーの構造化されたフルテキストを提供します。フルテキスト内のすべてのインライン引用言及が検出され、対応する参考文献エントリにリンクされます。これらの参考文献エントリは、参照論文にリンクされ、コンテキスト引用エッジを形成します。フルテキストのみがこれまでで最大の構造化された学術テキストコーパス。 
[要旨]構造化された全文を8に提供します。100万のオープンアクセスペーパーです。参照は公に最大の-利用可能なコンテキスト引用グラフです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-07">
        <br>2019-11-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: DialBERT: A Hierarchical Pre-Trained Model for Conversation
  Disentanglement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_11.html">
      DialBERT: A Hierarchical Pre-Trained Model for Conversation
  Disentanglement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      モデルは、IBMによって提案された新しいデータセットで最先端の結果を達成し、以前の作業を大幅に上回っています。ローカルとグローバルのセマンティクスを統合した、Dialogue BERT（DialBERT）という新しいモデルを提案します。 1つのメッセージストリームで、混合した会話を解きほぐします。パラメーターを3％だけ増やすだけで、F1-Scoreに基づいて、BERTと比較して12％の改善が達成されました。 
[ABSTRACT] Dialogue bertと呼ばれる新しいモデルは、混合した会話のもつれをほどき、もつれをほどくように設計されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Diverse, Controllable, and Keyphrase-Aware: A Corpus and Method for News
  Multi-Headline Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_12.html">
      Diverse, Controllable, and Keyphrase-Aware: A Corpus and Method for News
  Multi-Headline Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      3つのソースを入力として使用するマルチソーストランスフォーマーデコーダーを提案します。（a）キーフレーズ、（b）キーフレーズフィルター処理された記事、および（c）キーフレーズ関連の高品質で多様な見出しを生成する元の記事。実世界のデータセットに対する広範な実験的比較は、提案された方法が品質と多様性の点で最先端の結果を達成することを示しています。ニュースの見出しの生成は、読者がニュースを読むように引き付ける短い文を作成することを目的としています。 
[ABSTRACT]複数のキーフレーズは、さまざまなユーザーが関心を持つ複数のキーフレーズを生成します。当然、複数の適切な見出しを付けることができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: KdConv: A Chinese Multi-domain Dialogue Dataset Towards Multi-turn
  Knowledge-driven Conversation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_13.html">
      KdConv: A Chinese Multi-domain Dialogue Dataset Towards Multi-turn
  Knowledge-driven Conversation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このコーパスに関する以下の調査を容易にするために、いくつかのベンチマークモデルを提供します。コーパスには、3つのドメイン（映画、音楽、旅行）からの4.5Kの会話と、平均ターン数19.0の86Kの発話が含まれています。これらの会話には-関連トピックに関する詳細なディスカッション、および複数のトピック間の自然な移行。 
[要約]背景知識を導入することでモデルを強化できますが、会話を活用するための大きなスペースがまだあります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Explicit Reordering for Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_14.html">
      Explicit Reordering for Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、最初にソースの並べ替え情報と翻訳パフォーマンスの関係を実証的に調査します。WMT14の英語からドイツ語、WAT ASPECの日本語から英語、WMT17の中国語から英語への翻訳タスクの実証結果は、提案されたアプローチの有効性。したがって、変圧器ベースのNMTのこの並べ替え情報を明示的にモデル化する新しい並べ替え方法を提案します。 
[ABSTRACT] transformer-based ohtは、この文の情報の並べ替えを明示的に考慮していません。調査では、バイリンガルの並列データセットから学習したターゲット順序を含むソース入力により、翻訳パフォーマンスが大幅に向上することが示されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Word frequency and sentiment analysis of twitter messages during
  Coronavirus pandemic -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_15.html">
      Word frequency and sentiment analysis of twitter messages during
  Coronavirus pandemic
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      R2の高い値とSSEとRMSEの低い値は、このモデルの適合度の根拠となります。2つのタイプの実証研究が行われています。単語の頻度の検査は、単語のパターンまたは傾向を特徴付けるのに役立ちます。サイトで使用。 
[要約]結果は、二乗モデル、r2、および二乗平均平方根誤差の合計によって検証されています。結果は、ツイートの大部分が正の極性を持ち、約15％だけが負だったことを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Cross-lingual Emotion Intensity Prediction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_16.html">
      Cross-lingual Emotion Intensity Prediction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このために、ベストワーストスケーリングを使用して、スペイン語とカタロニア語のツイートのテストセットに注釈を付けます。そのため、スペイン語とカタロニア語のツイートにおけるきめ細かい感情検出のためのクロスリンガル転送アプローチを検討します。著者がテキストで表現することを意図している感情の、感情検出への以前のカテゴリー的アプローチの拡張。 
[ABSTRACT]結果は、低-検出法が従来の監視法よりも驚くほど優れた性能を発揮することを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Comprehensive Named Entity Recognition on CORD-19 with Distant or Weak
  Supervision -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_17.html">
      Comprehensive Named Entity Recognition on CORD-19 with Distant or Weak
  Supervision
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、このデータセットが生物医学的側面と社会的側面の両方でCOVID-19研究の洞察をもたらすことを願っています。これは、4つのソースからの注釈結果を組み合わせることによって自動的に生成されます。（1）18の事前トレーニング済みNERモデルSpacyの一般的なエンティティタイプ、（2）SciSpacyの18の生物医学エンティティタイプの事前トレーニング済みNERモデル、（3）127の生物医学エンティティタイプのナレッジベース（KB）ガイド付きNERモデル、遠隔監視付きNERメソッド、および（4 ）8つの新しいエンティティタイプ（特にCOVID-19の研究に関連）のシードガイド付きNERモデルと、監視の弱いNERメソッド。このデータセットが、テキストマイニングコミュニティによるダウンストリームアプリケーションの構築に役立つことを願っています。 
[ABSTRACT]このデータセットがテキストマイニングコミュニティに役立つことを願っています。さまざまな方法を開くことが可能です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-27">
        <br>2020-03-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Entity-Switched Datasets: An Approach to Auditing the In-Domain
  Robustness of Named Entity Recognition Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_18.html">
      Entity-Switched Datasets: An Approach to Auditing the In-Domain
  Robustness of Named Entity Recognition Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最先端のシステムのパフォーマンスはドメイン内でも大きく異なることがわかります。同じコンテキストで、特定の起源のエンティティは他の場所のエンティティよりも確実に認識されます。ドメイン内の堅牢性を監査する方法を提案します特に、エンティティの国内起源によるパフォーマンスの違いに焦点を当てたシステムです。エンティティ切り替えデータセットを作成します。元のテキストの名前付きエンティティが、同じタイプであるが国の起源が異なるもっともらしい名前付きエンティティに置き換えられます。 
[ABSTRACT]システムは、アメリカおよびインドのエンティティで最高のパフォーマンスを発揮し、ベトナムおよびインドネシアのエンティティで最悪のパフォーマンスを発揮します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Which one is the dax? Achieving mutual exclusivity with neural networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_19.html">
      Which one is the dax? Achieving mutual exclusivity with neural networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      認知研究のために、彼らは単語学習、指示対象選択メカニズム、および刺激の構造の間の潜在的な相互作用を強調しています。この研究では、神経モデルが類似の行動を示すことができるかどうか、およびどのような状況下で調査できるかを調査します。単語間の競争をもたらすため、学習と指示対象の選択の両方に制約があるため、新しい単語と指示対象のあるタスクでの成功を向上させることができます。 
[要旨]ニューラルネットワークの研究では、パフォーマンスを向上させるために利用可能なオプションの役割を明らかにしました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Quantum Inspired Word Representation and Computation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_20.html">
      Quantum Inspired Word Representation and Computation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験は、密度行列表現がベクトル表現と同等の信頼性を維持しながら、単語の意味のさまざまな側面を効果的にキャプチャできることを示しています。さらに、ベクトルと密度行列の両方の計算でコヒーレント合計とインコヒーレント合計を組み合わせる新しい方法を提案します。 ..それは単語の類推タスクの一貫した改善を達成します。 
[概要]コンセプトは、quantumpressに触発されたものであり、1つの単語の単語を表します。コンセプトは、「レゴワード」と呼ばれるコンセプトに基づいています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br>2020-04-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: DynaBERT: Dynamic BERT with Adaptive Width and Depth -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_21.html">
      DynaBERT: Dynamic BERT with Adaptive Width and Depth
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ネットワークの再配線は、より重要なアテンションヘッドとニューロンをより多くのサブネットワークで共有するためにも使用されます。さまざまな効率制約の下での包括的な実験は、提案された動的BERT（またはRoBERTa）が最大サイズでBERT（またはRoBERTa ）、幅と深度が小さい場合、既存のBERT圧縮方法よりも常にパフォーマンスが優れています。DynaBERTのトレーニングプロセスには、最初に幅対応BERTのトレーニングが含まれ、フルサイズモデルから小さなサブモデルに知識を抽出することで、適応幅と深度の両方が可能-ネットワーク。 
[要約]このホワイトペーパーでは、適応型の幅と深度で実行できる固定動的bertモデルを提案します。これを使用して、より重要な注意ヘッドとより多くのサブネットワークで共有されるニューロンを維持します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SentiLR: Linguistic Knowledge Enhanced Language Representation for
  Sentiment Analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_22.html">
      SentiLR: Linguistic Knowledge Enhanced Language Representation for
  Sentiment Analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      事前トレーニング中、最初にSentiWordNet辞書に品詞タグを付けてクエリすることにより、各単語の以前の感情の極性を取得します。次に、2つで構成されるラベル認識マスク言語モデルと呼ばれる新しい事前トレーニングタスクを考案します。サブタスク：1）文レベルのラベルが与えられたときの単語知識の回復。 2）言語知識が強化されたコンテキストによる文レベルのラベル予測。実験により、SentiLRが文レベル/アスペクトレベルの感情分析と感情認識データ拡張で最先端のパフォーマンスを実現することが示されています。 
[要約]プロジェクトは、sentirr.itと呼ばれる新しい言語表現モデルに基づいています。これには、一部の音声タグと、sentiwordnetからの以前の感情極性を含む、単語レベルの言語知識が含まれています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-06">
        <br>2019-11-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Interactive Refinement of Cross-Lingual Word Embeddings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_23.html">
      Interactive Refinement of Cross-Lingual Word Embeddings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、CLIMEはアノテーションを使用して埋め込みを更新します。CLIMEはまた、アクティブな学習ベースラインよりも速くテストの精度を向上させ、結果を改善するためにアクティブな学習と簡単に組み合わせることができます。クロスリンガルの単語の埋め込みは、言語間で知識を転送します。 -resource言語は、低リソース言語で使用できます。 
[ABSTRACT]埋め込みは通常、汎用のコーパスでトレーニングされます。これらはドメイン固有のタスクに使用されます。埋め込みは、より微妙な単語の意味をキャプチャし、元の埋め込みよりも高いテスト精度を備えています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-08">
        <br>2019-11-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Poor Man's BERT: Smaller and Faster Transformer Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_24.html">
      Poor Man's BERT: Smaller and Faster Transformer Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この問題に対処するために、最初からモデルの事前トレーニングを必要としない多くのメモリライトモデル削減戦略を検討します。当然のことながら、この状況により、これまでにない大きなモデルの競争が解き放たれました。 BERT、XLNet、RoBERTaなどの人気のあるモデルは、大容量メモリのGPU / TPUを持たない研究者や実務家には手が届きません。また、モデルのサイズとパフォーマンスの両方に関して、プルーニングモデルがDistilBERTと同等であることを示しています。 
[要旨] bert、メモリモデルを最大40％削減できます。モデルモデルモデルは、大容量メモリのgpusまたはtpusの欠如によっても制御できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving BERT with Self-Supervised Attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_25.html">
      Improving BERT with Self-Supervised Attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      経験的に、さまざまなパブリックデータセットで、SSA拡張BERTモデルを使用してパフォーマンスの大幅な改善を示しています。具体的には、SSAは前の反復から微調整されたモデルを「プローブ」することにより、弱いトークンレベルの注意ラベルを繰り返し自動的に生成します。 。ただし、微調整されたモデルが小さいデータセットに適合しすぎることが多いため、課題が1つ残っています。 
[ABSTRACT]微調整されたパフォーマンスモデルは、多くの場合、拡張データセットにオーバーフィットします。ただし、微調整されたパフォーマンスはしばしばオーバーフィットするため、課題が1つ残っています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Putting a Spin on Language: A Quantum Interpretation of Unary
  Connectives for Linguistic Applications -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_26.html">
      Putting a Spin on Language: A Quantum Interpretation of Unary
  Connectives for Linguistic Applications
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの方法は、あいまいな発話の共存する解釈を同時に表現する方法を導入し、語彙と派生のあいまいさの統合のための統一されたフレームワークを提供します。計算言語学で現在使用されているLambek計算の拡張バージョンは、単項法に依存して、単語の順序と句の構造に影響を与える構造規則の制御された適用（Correia et al、2019）の密度行列のセマンティクスに基づいて、追加のスピン密度行列空間で型システムの解釈を拡張します。 
[要約]目的は、モダリティを最初のタイプに変更することです-モダリティのタイプのスティント。表現とルールルールルールは、注ぐ順序を変更します。その結果、パターンに基づくあいまいな発音になります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: KorNLI and KorSTS: New Benchmark Datasets for Korean Natural Language
  Understanding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_27.html">
      KorNLI and KorSTS: New Benchmark Datasets for Korean Natural Language
  Understanding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これを動機として、韓国語のNLIとSTSの新しいデータセットをそれぞれ構築し、リリースします。それぞれ、KorNLIとKorSTSと呼ばれます。韓国のNLUに関する研究を加速し、KorNLIおよびKorSTSのベースラインも確立します。 
[要約]ベンチマークデータセットは英語と他のいくつかの言語でリリースされています。韓国語で公開されているnliまたはissデータセットはありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Internal and external pressures on language emergence: least effort,
  object constancy and frequency -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_28.html">
      Internal and external pressures on language emergence: least effort,
  object constancy and frequency
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      それにもかかわらず、結果として生じる通信プロトコルは、構成性などの自然言語の顕著な特徴を表示することはめったにありません。より具体的には、補助目的を通じて最小労力の原則を形式化します。では、画像内のオブジェクトの周波数、位置、光度を変更します。 
[要約]通信プロトコルは、自然言語の顕著な特徴を表示することはめったにありません。それらは、補助的な目的を通じて最小の努力の原則を形式化します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Automated Utterance Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_29.html">
      Automated Utterance Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、1）抽出要約を使用して説明から重要な文を抽出し、2）複数の言い換え技法を使用して、タイトルと要約文の多様な言い換えのセットを生成し、3）適切な候補を選択する発話生成システムを提案します。新しい候補選択アルゴリズムの助けを借りて言い換えます。したがって、発話の生成は、タイトルと説明で構成されるナレッジベース記事から関連する発話（文またはフレーズ）を生成することを目的とした重要な問題になっています。しかし、優れた発話を生成するには、通常、多くの手作業が必要であり、自動発話の生成が必要になります。 
[ABSTRACT]英国では1,000人を超える人々が一連の誤認的な言葉で診断されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-07">
        <br>2020-04-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: XPersona: Evaluating Multilingual Personalized Chatbot -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_30.html">
      XPersona: Evaluating Multilingual Personalized Chatbot
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、ペルソナチャットの多言語拡張、つまりXPersonaを提案します。実験結果は、多言語トレーニング済みモデルが翻訳パイプラインよりも優れ、単言語モデルと同等であり、複数の言語にまたがる単一のモデル。私たちのデータセットには、多言語のパーソナライズされたエージェントを構築および評価するための、英語以外の6つの異なる言語のペルソナ会話が含まれています。 
[ABSTRACT]パーソナライズされた対話エージェントは主に単一言語であり、他の言語でのチャットエージェントの使用を制限します。データセットとベースラインが多言語対話システムの研究を加速することを願っています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-17">
        <br>2020-03-17
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Downstream Model Design of Pre-trained Language Model for Relation
  Extraction Task -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_31.html">
      Downstream Model Design of Pre-trained Language Model for Relation
  Extraction Task
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、PLMの元の標準タスクにはまだ関係抽出タスクが含まれていません。PLMを使用して関係抽出問題を解決することもできると考えられますが、特別に設計されたダウンストリームタスクモデルまたは対処するための損失関数を確立する必要があります複雑な関係を持つ。実験により、私たちの方法は、関係抽出の複数のパブリックデータセット全体で現在の最適なベースラインモデルを大幅に超えていることがわかっています。 
[要約]ユニバーサル抽出は、特別な損失関数を備えた新しいネットワークアーキテクチャです。監視付き関係抽出のためのplmsのダウンストリームモデルとして機能するように設計されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Are All Good Word Vector Spaces Isomorphic? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_32.html">
      Are All Good Word Vector Spaces Isomorphic?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      「トレーニング不足」）。さまざまな言語にわたる一連の実験を提示します。これは、固有のタイプの違いに加えて、言語ペア間のパフォーマンスのばらつきは、利用可能な単一言語リソースのサイズ、およびプロパティと単一言語トレーニングの期間（例：クロスリンガルワードのベクトル空間を整列させるための既存のアルゴリズムは、ベクトル空間がほぼ同型であると想定します。これらの作業は、非同型空間に基づいています。これらは、動作が不十分であるか、完全に失敗すると想定しています。これら実際にパフォーマンスを改善するためのトレーニングをしています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CALM: Continuous Adaptive Learning for Language Modeling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_33.html">
      CALM: Continuous Adaptive Learning for Language Modeling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      大規模言語表現モデルのトレーニングは、自然言語処理コミュニティの標準になりました。これらの方法により、生物医学および臨床領域で継続的な学習設定を使用して実証するタスク固有のモデルによって導入される監視対象タスク間のパフォーマンスギャップを減らすことができます..この作業では、CALM、言語モデリングの継続的適応学習：複数のドメインにわたって知識を保持するモデルをレンダリングする手法を提案します。 
[ABSTRACT]大容量モデルは、ラベルのないデータでトレーニングを継続できます。これにより、監視対象タスクの初期化がさらに堅牢になります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SciWING -- A Software Toolkit for Scientific Document Processing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_34.html">
      SciWING -- A Software Toolkit for Scientific Document Processing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      すぐに使用できるWebおよび端末ベースのアプリケーションとデモンストレーションが含まれます（http://sciwing.ioから入手可能）。科学文書処理の事前トレーニング済みモデルへのアクセスを提供するオープンソースソフトウェアツールキットであるSciWINGを紹介します。引用文字列の解析と論理構造の回復を含むタスク。SciWINGを使用すると、さまざまなモジュールを交換してスタックすることで、さまざまなモデルをすばやく実験できます。 
[ABSTRACT]このツールにより、研究者はさまざまなモデルをすばやく実験できます。また、エンドユーザーアプリケーションの開発にも役立ちます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Pre-training is a Hot Topic: Contextualized Document Embeddings Improve
  Topic Coherence -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_35.html">
      Pre-training is a Hot Topic: Contextualized Document Embeddings Improve
  Topic Coherence
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      4つのデータセットの結果は、私たちのアプローチがトピックの一貫性を効果的に高めることを示しています。最近、神経系トピックモデルが利用可能になり、BERTベースの表現は、最新の神経モデル一般をさらに推し進めました。神経トピックモデル。 
[ABSTRACT]最近、ニューラルトピックモデルが利用可能になりましたが、バートベースの表現は、一般的なニューラルモデルの最先端技術をさらに推し進めました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Generating Narrative Text in a Switching Dynamical System -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_36.html">
      Generating Narrative Text in a Switching Dynamical System
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      状態ベクトルが時間とともにどのように変換されるか）は、トップレベルの離散スイッチング変数によって制御されます。この確率論的定式化により、生成を制御でき、ラベル付きデータとラベルなしデータの両方を使用して半教師付き方法で学習できます。スイッチング変数は、ナラティブ構造（たとえば、感情または談話状態）、潜在状態ベクトルはナラティブの現在の状態に関する情報をエンコードします。 
[ABSTRACT]スイッチング変数はナラティブ構造を表しますが、潜在状態波の波はナラティブの現在の状態に関する情報をエンコードします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transfer learning and subword sampling for asymmetric-resource
  one-to-many neural translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_37.html">
      Transfer learning and subword sampling for asymmetric-resource
  one-to-many neural translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人為的に制限された3つの翻訳タスク（英語からエストニア語（リソースが少ない）とフィンランド語（リソースが多い））、英語からスロバキア語とチェコ語、英語からデンマーク語とスウェーデン語---、および1つの実際のタスクでさまざまな方法をテストします。ノルウェー語から北S&#39;amiおよびフィンランド語へ。実験は、特にスケジュールされたマルチタスク学習、ノイズ除去オートエンコーダ、およびサブワードサンプリングにプラスの効果を示しています。低リソース言語のニューラル機械翻訳を改善するには、いくつかのアプローチがあります。事前トレーニングまたはデータ拡張によって悪用される;関連言語ペアの並列コーパスは、多言語モデルのパラメーター共有または転移学習を介して使用できます。サブワードのセグメンテーションと正則化技術を適用して、語彙の高いカバレッジを確保できます。 
[ABSTRACT]低リソースのリソースと高リソースの言語は改善できます。これらはスウェーデン語ベースの言語に関連しています。テストを使用してデンマーク語とデータを共有できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Text Complexity Classification Based on Linguistic Information:
  Application to Intelligent Tutoring of ESL -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_38.html">
      Text Complexity Classification Based on Linguistic Information:
  Application to Intelligent Tutoring of ESL
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この評価では、テストセットのテキストはトレーニングセットのテキストと異なるだけでなく、タイプも異なります（ESLテキストと子供たちの読書テキスト）。この動作は、2つの間の分類基準の違いによって説明できます。コーパス..したがって、観察された結果は、実際のアプリケーション内でのこのような分類子の有用性を確認します。 
[ABSTRACT]結果は、採用された言語機能が優れた全体的な分類パフォーマンスを提供することを示しました（f-スコア= 0. 97）
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-07">
        <br>2020-01-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: ShanghaiTech at MRP 2019: Sequence-to-Graph Transduction with
  Second-Order Edge Inference for Cross-Framework Meaning Representation
  Parsing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_39.html">
      ShanghaiTech at MRP 2019: Sequence-to-Graph Transduction with
  Second-Order Edge Inference for Cross-Framework Meaning Representation
  Parsing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのシステムは、フレームワーク内ランクでDMおよびPSDフレームワークでそれぞれ\ n {1}および\ n {2}位を達成し、クロスフレームワークランクでDMフレームワークで\ n {3}位を達成しました。 \ textit {CoNLL 2019共有タスク：クロスフレームワーク意味表現解析}への提出で使用されるシステムを示します。私たちのシステムは、ノードと2次を生成する拡張ポインタージェネレーターネットワークを組み合わせたグラフベースのパーサーですエッジを予測する平均場変分推論モジュール。 
[要旨]私たちのシステムは、グラフベースのWebベースのパーサーです。拡張ポインター-ジェネレーターネットワークと2次-平均フィールドの説明を組み合わせたものです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploring Versatile Generative Language Model Via Parameter-Efficient
  Transfer Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_40.html">
      Exploring Versatile Generative Language Model Via Parameter-Efficient
  Transfer Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、これには、タスクごとに1つの大きなモデルを作成するコストが伴います。これは、低メモリ/電力シナリオ（モバイルなど）では理想的ではありません。このホワイトペーパーでは、複数の微調整を効果的に行う方法を提案します。単一の大規模な事前トレーニング済みモデルを使用して下流の生成タスクを同時に実行します。5つの異なる言語生成タスクの実験では、各タスクに追加の2〜3％のパラメーターを使用するだけで、モデルがパフォーマンスを維持または向上できることを示していますモデル全体を微調整します。 
[ABSTRACT]実験は5つの異なる言語生成タスクで行われました。追加の2〜3％のパラメーターを使用することにより、モデル全体でモデル全体の微調整のパフォーマンスを維持または改善できることを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Cross-lingual Representation Learning at Scale -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_41.html">
      Unsupervised Cross-lingual Representation Learning at Scale
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      コード、データ、モデルを公開します。XLM-Rと呼ばれるこのモデルは、XNLIの平均精度+ 14.6％、平均+ 13％を含む、さまざまなクロスリンガルベンチマークで多言語BERT（mBERT）よりも大幅に優れています。 MLQAのF1スコア、およびNER。の+ 2.4％F1スコア。XLM-Rは低リソース言語で特に良好に機能し、スワヒリ語のXNLI精度が15.7％、ウルドゥー語が以前のXLMモデルより11.4％向上しています。 
[ABSTRACT]トランスフォーマーをトレーニングします。100言語に基づくマスク言語モデルに基づいています。このモデルは、2テラバイトを超えるフィルター処理されたcommoncrawl data.xliを使用しています。低リソース言語で特に優れたパフォーマンスを発揮します。初めて、言語ごとのパフォーマンスを犠牲にすることなく、多言語モデリングの可能性
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-05">
        <br>2019-11-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Natural Language Adversarial Attacks and Defenses in Word Level -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_42.html">
      Natural Language Adversarial Attacks and Defenses in Word Level
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SEMをより適切に評価するために、同義語置換ベースの攻撃に遺伝的メタヒューリスティックを採用する、改良型遺伝的アルゴリズム（IGA）と呼ばれる強力な攻撃方法も設計します。このギャップを埋めるのに貢献し、\ textit {Synonym Encodingと呼ばれる新しい敵対的防御方法を提案しますメソッド}（SEM）、モデルの入力層の前にエンコーダーを挿入し、モデルをトレーニングして敵対的摂動を排除します。2018年に提案された最初の遺伝的ベースの敵対的攻撃と比較して、IGAは低い単語でより高い攻撃成功率を達成できます置換率は、同時に敵対的な例の移転可能性を維持します。 
[ABSTRACT]最近の研究では、成功したゲエール置換ベースの敵対的攻撃に対する防御方法がないことを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-15">
        <br>2019-09-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-Agent Task-Oriented Dialog Policy Learning with Role-Aware Reward
  Decomposition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/cs.CL/paper_43.html">
      Multi-Agent Task-Oriented Dialog Policy Learning with Role-Aware Reward
  Decomposition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ユーザーシミュレーターを事前に明示的に構築することを回避するために、システムとユーザーの両方をダイアログエージェントと見なすマルチエージェントダイアログポリシー学習を提案します。また、ロール固有の統合のためのロール対応報酬分解のためのハイブリッド値ネットワークを提案します。タスク指向ダイアログの各エージェントのドメイン知識。結果は、この方法がシステムポリシーとユーザーポリシーを同時に正常に構築でき、2つのエージェントが会話型対話を通じて高いタスク成功率を達成できることを示しています。 
[ABSTRACT]ルール-シミュレータに基づく複雑なタスクには専門知識が必要です。データ-駆動シミュレータ-シミュレータの評価方法も不明確です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Personal VAD: Speaker-Conditioned Voice Activity Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/eess.AS/paper_0.html">
      Personal VAD: Speaker-Conditioned Voice Activity Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは、ターゲットスピーカーの埋め込みまたはスピーカーの検証スコアを条件とするVADに似たニューラルネットワークをトレーニングすることで実現します。最適な設定では、個別にトレーニングしたベースラインシステムよりも優れた130Kのパラメーターでモデルをトレーニングできます。標準のVADと話者認識ネットワークを組み合わせて同じタスクを実行します。このシステムは、デバイス上のストリーミング音声認識システムへの入力をゲーティングして、ターゲットユーザーに対してのみトリガーするようにして、計算コストを削減し、特にキーワード検出器が好ましくないシナリオでのバッテリー消費。 
[ABSTRACT]パーソナルVADは、3つのクラスの確率を提供します：非スピーチ、ターゲットスピーカースピーチ、および非ターゲットスピーカースピーチ
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-12">
        <br>2019-08-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Proximal binaural sound can induce subjective frisson -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/eess.AS/paper_1.html">
      Proximal binaural sound can induce subjective frisson
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ここでは、リスナーの頭の周りのノイズ音（ホワイトノイズ、ローリングビーズノイズ、またはビニール袋をこすることによって発生する摩擦ノイズ）の刺激を動かすことによって、フリッソンの主観的な感覚を生み出すことができるかどうかを調査しました。ピアソンの相関分析は、いくつかの音響両耳間レベル差（ILD）の分散、ラウドネス、シャープネスなどの聴覚刺激の特徴は、主観的フリッソンの大きさと相関していました。物理的な冷たい刺激。 
[アブストラクト]聴覚フリパーソナルスペースの音のメカニズムは不明です。これらの音は、フリソンの音と似ています-音を誘発します。音-誘発されたフリソンは、聴覚刺激が回転していないものよりも頭の周りを回転するときに強く感じることができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-15">
        <br>2019-04-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An empirical analysis of information encoded in disentangled neural
  speaker representations -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/eess.AS/paper_2.html">
      An empirical analysis of information encoded in disentangled neural
  speaker representations
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この研究では、因子のスイートに関連してキャプチャする情報量について、教師なし解きほぐしがある場合とない場合の話者表現を調べます。話者表現の解きほぐしは、スピーカー表現の堅牢性を両方の本質的な要素に対して向上させるために使用される手法の1つです。音声生成中に取得された（感情、語彙内容など）および信号キャプチャ中に取得された外的要因（チャネル、ノイズなど）。どちらの場合でも、さまざまな変動要因がどの程度絡み合っているかを理解することが重要です。表現。 
[要約]話者表現の解きほぐしは、話者情報のロバスト性を改善するために使用される手法の1つです。これらには、音声生成中に取得される要素（感情、語彙の内容など）や信号形式で達成できる外因性要素が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-10">
        <br>2020-02-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: MM Algorithms for Joint Independent Subspace Analysis with Application
  to Blind Single and Multi-Source Extraction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/eess.AS/paper_3.html">
      MM Algorithms for Joint Independent Subspace Analysis with Application
  to Blind Single and Multi-Source Extraction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最近、1つ以上のソースのブラインド抽出が、より大きなマイクアレイを活用してより良い分離を実現するための合理的な方法として注目を集めています。特に、過決定IVA（OverIVA）のためにいくつかのMMアルゴリズムが提案されています。この代理機能の最小化ハイブリッド厳密近似対角化問題の変形につながりますが、複数の分離ベクトルが一緒にグループ化されます。 
[ABSTRACT]たとえば、メジャー化-最小化手法（jisa-mm）に基づいてjisaのアルゴリズムフレームワークを作成します。この代理関数の最小化は、ハイブリッド厳密-225対角化問題のバリアントにつながります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Comparison for Improvements of Singing Voice Detection System Based on
  Vocal Separation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/eess.AS/paper_4.html">
      Comparison for Improvements of Singing Voice Detection System Based on
  Vocal Separation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後の1つは、分類器の予測結果で異常フレームをフィルタリングする後処理です。提案されたシステムには、主に3つの部分があります。分析に基づいて、より効率的な歌声を構築する新しい方法が提案されました音声検出システム。 
[要約]歌声検出は、音楽情報検索（mir）の主要なコンポーネントの1つです。提案されたシステムは、長期反復畳み込みネットワーク（lrcn）モデルに基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-Target Emotional Voice Conversion With Neural Vocoders -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/eess.AS/paper_5.html">
      Multi-Target Emotional Voice Conversion With Neural Vocoders
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      客観的な測定基準と実験結果の主観的な評価により、EVCの提案されたMTEVCアーキテクチャの有効性が検証されます。ボコーダーは、追加の話者情報と感情情報を補助機能として取り込み、マルチスピーカーとマルチ感情音声コーパスでトレーニングされます。このホワイトペーパーでは、深い双方向の長期短期記憶（DBLSTM）ベースの変換モデルとニューラルボコーダーを組み合わせたマルチターゲットEVC（MTEVC）アーキテクチャの構築について検討します。 
[要旨] mel-ケプストラルボコーダーの研究者は、さまざまな意味合いを発達させました。彼らは、マルチスピーカーとマルチ感情のスピーチコーパスでトレーニングされています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An initial investigation on optimizing tandem speaker verification and
  countermeasure systems using reinforcement learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/eess.AS/paper_6.html">
      An initial investigation on optimizing tandem speaker verification and
  countermeasure systems using reinforcement learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      自動スピーカー検証（ASV）のスプーフィング対策（CM）システムは、通常、相互に分離して使用されません。CMが正当なサンプルであるとCMが判断した場合、ASVシステムはスピーカー検証のためにそれを考慮します。システムのユーザーは、個々のサブモジュールのパフォーマンスには関心がなく、結合されたシステムのパフォーマンスに関心があります。 
[要約]これらのシステムは、カスケードシステムに組み合わせることができます。たとえば、システムが合成音声か真正音声かを最初に決定します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br>2020-02-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Emotional Voice Conversion With Cycle-consistent Adversarial Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/eess.AS/paper_7.html">
      Emotional Voice Conversion With Cycle-consistent Adversarial Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CycleGANの非並列トレーニングは、非並列の感情的なVCの可能性を示します。CycleGANモデルのトレーニングプロセスは、時間的整列操作なしに、ソースとターゲットの音声パラメータをランダムにペアリングします。.感情的な音声変換、または感情的なVCは、基本的な言語情報と話者のアイデンティティを維持しながら、音声をある感情状態から別の感情状態に変換する手法。 
[要約] cycleganは2つの弁別子と1つの分類子を使用して学習プロセスをガイドします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Noise Tokens: Learning Neural Noise Templates for Environment-Aware
  Speech Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/eess.AS/paper_8.html">
      Noise Tokens: Learning Neural Noise Templates for Environment-Aware
  Speech Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、従来の逆STFT（ISTFT）ではなく、最新のニューラルボコーダーを適用して波形を生成することを検討します。実験結果は、NTを使用することが、さまざまなDNNにわたるSEシステムの汎化能力を一貫して改善する効果的な戦略であることを示しています。アーキテクチャー近年、ディープニューラルネットワーク（DNN）の成功により、音声強調（SE）が印象的な進歩を遂げました。 
[要約] dnnアプローチは通常、トレーニングに含まれていない目に見えない環境ノイズにうまく一般化できません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Conditioned Source Separation for Music Instrument Performances -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/eess.AS/paper_9.html">
      Conditioned Source Separation for Music Instrument Performances
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、同時に鳴っている複数の楽器の音源分離方法を提案し、オーディオストリームとは別にどれだけの追加情報が音源分離の品質を向上させることができるかを探ります。データのモダリティ、つまり、混合内の楽器の有無、および対応するビデオストリームデータ。異なるオーディオソースが同期され、調和して演奏されるため、同じ曲を演奏する異なる楽器を分離することは困難な作業です。 
[要旨]ソースの数はピースごとに異なる場合があります。一部のソースは同じ種類の楽器に属している可能性があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Bayesian x-vector: Bayesian Neural Network based x-vector System for
  Speaker Verification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/eess.AS/paper_10.html">
      Bayesian x-vector: Bayesian Neural Network based x-vector System for
  Speaker Verification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      NIST SRE10コアテストで評価されている間にVoxceleb1でトレーニングされたモデルは、BNNが約4.69％の大きな相対EER低下をもたらす可能性があることを示唆しています。ドメイン外のデータを使用した評価用。さらに、DNN x-ベクトルとベイジアンx-ベクトルシステムの融合により、さらに改善することができます。 
[要旨]システムは目に見えないデータに対して優れた汎化能力を持っている必要があります。システムは、評価データをより一般化し、一般的な決定をより正確に行うことができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Background white noise and speech facilitate visual working memory -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/biorxiv.physiology/paper_0.html">
      Background white noise and speech facilitate visual working memory
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      音韻ループと視覚空間スケッチパッドは、ワーキングメモリ（WM）の2つの独立したシステムとして提案されています。ただし、背景音が視覚WMに影響を与えるかどうかは不明のままです。皮膚電気活動（EDA）と筋電図（EMG）は同時に記録されました。 
[要約]以前の研究では、ホワイトノイズではなくバックグラウンドスピーチが口頭wmのパフォーマンスを低下させることが示唆されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Inflammation promotes adipocyte lipolysis via IRE1 kinase -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-04-09/biorxiv.physiology/paper_1.html">
      Inflammation promotes adipocyte lipolysis via IRE1 kinase
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      免疫応答がホルモンまたはアドレナリン作動性信号とは別に脂肪分解を促進するかどうかは不明です。肥満は炎症、インスリン抵抗性、およびより高い血中脂質と関連します。 
[要旨]イソプロテレノールとキャンプではire1は必須ではありませんでした-component.ire1酵素で脂肪分解が誘発されました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br>2020-04-08
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
