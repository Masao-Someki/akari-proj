<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-12-03の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Top-1 CORSMAL Challenge 2020 Submission: Filling Mass Estimation Using
  Multi-modal Observations of Human-robot Handovers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.SD/paper_0.html">
      <font color="black">Top-1 CORSMAL Challenge 2020 Submission: Filling Mass Estimation Using
  Multi-modal Observations of Human-robot Handovers</font>
    </a>
  </h2>
  <font color="black">次に、これらの指標を組み合わせて、コンテナの充填量を推定します。充填量の3つの主要な指標である充填タイプ、充填レベル、およびコンテナ容量を予測するマルチモーダル手法を提案します。過剰適合の証拠を示さずに、パブリックサブセットとプライベートサブセットの両方でCORSMAL2020チャレンジへのすべての提出物の中でパフォーマンス。 
[概要]ロボットは、人間が保持するコンテナの充填質量を推定する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Sequence Generation using Deep Recurrent Networks and Embeddings: A
  study case in music -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.SD/paper_1.html">
      <font color="black">Sequence Generation using Deep Recurrent Networks and Embeddings: A
  study case in music</font>
    </a>
  </h2>
  <font color="black">特に、機械学習とリカレントニューラルネットワークなどの固有記憶メカニズムを備えたニューラルネットワークの最近の進歩により、自然言語処理と自動音楽作曲が重要性を増しています。提案されたアプローチは、転置などの音楽理論の概念を考慮し、データ変換を使用します。 （埋め込み）セマンティックな意味を導入し、生成されたメロディーの品質を向上させます。このペーパーでは、さまざまなタイプのメモリメカニズム（メモリセル）を評価し、音楽作曲の分野でのパフォーマンスを分析します。 
[ABSTRACT]機械学習により自動音楽作曲の重要性が増しています。提案されたアプローチでは、移調などの音楽理論の概念が考慮されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Neural MOS Prediction for Synthesized Speech Using Multi-Task Learning
  With Spoofing Detection and Spoofing Type Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.SD/paper_2.html">
      <font color="black">Neural MOS Prediction for Synthesized Speech Using Multi-Task Learning
  With Spoofing Detection and Spoofing Type Classification</font>
    </a>
  </h2>
  <font color="black">いくつかの研究は、合成音声の平均オピニオン評点（MOS）を予測するための深層学習ベースのモデルを提案しており、人間の評価者を置き換える可能性を示しています。音声変換チャレンジ2018のMOS評価結果を使用した実験では、提案されたMTLが2つであることが示されています。補助タスクによりMOS予測が向上します。さらに、焦点損失を使用して、MOS予測のSDとSTC間の相乗効果を最大化します。 
[概要]提案されたモスモデルは、パフォーマンスが向上する可能性があります。ただし、モスの評価者間および評価者内の変動により、モデルの高性能を確保することは困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Virufy: Global Applicability of Crowdsourced and Clinical Datasets for
  AI Detection of COVID-19 from Cough Audio Samples -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.SD/paper_3.html">
      <font color="black">Virufy: Global Applicability of Crowdsourced and Clinical Datasets for
  AI Detection of COVID-19 from Cough Audio Samples</font>
    </a>
  </h2>
  <font color="black">より多くのクラウドソーシングデータが収集されると、さまざまな呼吸オーディオサンプルを使用してさらなる開発を実装し、COVID-19検出用の咳分析ベースの機械学習（ML）ソリューションを作成できます。これは、臨床および非臨床の両方のすべての人口統計グループにグローバルに一般化できる可能性があります。臨床設定..さらに、これらの地域の特定のサンプルを使用してさらにトレーニングすることなく、私たちの方法がラテンアメリカのクラウドソーシングサンプルと南アジアの臨床サンプルに一般化できることを示します。この研究は、クラウドソーシングされた咳の音声サンプルが世界中のスマートフォンを使用して、77.1％（75.2％-78.3％）のROC-AUCでCOVID-19感染を正確に予測するAIベースの方法を開発できます。 
[概要]新しい方法は、さらなるトレーニングなしで、ラテンアメリカからのクラウドソーシングされたサンプルと南アジアからの臨床サンプルに一般化することができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-26">
        <br><font color="black">2020-11-26</font>
      </time>
    </span>
</section>
<!-- paper0: Deconstruct and Reconstruct Dizi Music of the Northern School and the
  Southern School -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.SD/paper_4.html">
      <font color="black">Deconstruct and Reconstruct Dizi Music of the Northern School and the
  Southern School</font>
    </a>
  </h2>
  <font color="black">再構成の例として、メロディ転送と演奏技術転送を含む音楽スタイル転送が与えられ、再構成結果を評価するために聴衆評価が行われます。中国の音楽技術に関する今日の研究は、主にデータ収集、音楽分解、音楽の3つの側面に焦点を当てています再構成..特徴には、2つの異なる音楽スタイルのメロディーと演奏技術が分解されます。 
[ABSTRACT] diziデータセットは、この方法を使用して収集され、中国の音楽を収集します。データセットは、さまざまな手法に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: How Far Are We from Robust Voice Conversion: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.SD/paper_5.html">
      <font color="black">How Far Are We from Robust Voice Conversion: A Survey</font>
    </a>
  </h2>
  <font color="black">すべてのVCモデルは目に見えないデータに悩まされていますが、AdaIN-VCは比較的堅牢です。また、パフォーマンスをさらに向上させるために、スピーカーの埋め込みの交換など、これらのモデルを変更しました。このホワイトペーパーでは、既知のVCモデルの堅牢性。 
[概要]論文では、既知のvcモデルの堅牢性について詳細に研究しました。共同でトレーニングされた埋め込みは、話者識別でトレーニングされたモデルよりも音声変換に適しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Tensor Completion via Few-shot Convolutional Sparse Coding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.IV/paper_0.html">
      <font color="black">Tensor Completion via Few-shot Convolutional Sparse Coding</font>
    </a>
  </h2>
  <font color="black">それどころか、信号処理の分野では、畳み込みスパースコーディング（CSC）は、一般にデータの詳細コンポーネントに関連付けられている画像の高周波コンポーネントの適切な表現を提供できます。テンソルデータはしばしば苦しみます。取得時の複雑な高次元構造による欠測値問題。したがって、LRTC-CSCは欠測値問題を解決するだけでなく、詳細を復元することもできます。 
[ABSTRACT] lrtc-cscは欠測値の問題を解決し、詳細を回復するだけでなく、詳細情報を低くすることはできないという欠点があります-ランク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Image inpainting using directional wavelet packets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.IV/paper_1.html">
      <font color="black">Image inpainting using directional wavelet packets</font>
    </a>
  </h2>
  <font color="black">この問題で得られた結果は、最先端のアルゴリズムと非常に競争力があります。修復は、反復スキームによって実装されます。反復スキームは、本質的に、適応変数を備えたスプリットブレグマン反復（SBI）手順です。二変量収縮アルゴリズムに基づくソフトしきい値..この論文は、画像修復問題のための新しいアルゴリズムを提示します。 
[概要]アルゴリズムは、最近設計された準分析複合値のウェーブレットアプリケーションのコレクションを使用しています。これは、パターン化に由来する一連の独自の製品に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-12">
        <br><font color="black">2020-01-12</font>
      </time>
    </span>
</section>
<!-- paper0: Broadband holography-assisted coherent imaging -- towards attosecond
  imaging at the nanoscale -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.IV/paper_2.html">
      <font color="black">Broadband holography-assisted coherent imaging -- towards attosecond
  imaging at the nanoscale</font>
    </a>
  </h2>
  <font color="black">Petahertzエレクトロニクスと将来のデータストレージに関連する超高速電荷移動または超高速スピン電流..ここでは、高品質で高空間分解能のコヒーレントイメージングと広いスペクトル帯域幅の組み合わせを可能にする堅牢なホログラフィ強化コヒーレントイメージング法を紹介します。ナノメートルの空間分解能でのポンププローブ実験の時間分解能は、最小の時空間スケールで超高速ダイナミクスを研究することを可能にしますが、まだ実証されていません。 
[ABSTRACT]アト秒科学は、原子、分子、および複雑な材料の超高速ダイナミクスを明らかにしました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-25">
        <br><font color="black">2020-06-25</font>
      </time>
    </span>
</section>
<!-- paper0: Red Blood Cell Segmentation with Overlapping Cell Separation and
  Classification on Imbalanced Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.IV/paper_3.html">
      <font color="black">Red Blood Cell Segmentation with Overlapping Cell Separation and
  Classification on Imbalanced Dataset</font>
    </a>
  </h2>
  <font color="black">重複する細胞分離に焦点を当て、セグメンテーションプロセスは最初に楕円を推定して赤血球を表します。血液塗抹標本画像での自動赤血球分類は、血液学者がRBCラボの結果をより少ない時間とコストで分析するのに役立ちます。精度は20血液塗抹標本で0.889です。画像。 
[概要]この方法は、凹点を検出して楕円を見つけます。次に、有向楕円フィッティングを使用してセルデータの拡張を見つけます。この方法を使用して、セルのオーバーラップとデータの不均衡の問題に取り組むことが望まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Fighting together against the pandemic: learning multiple models on
  tomography images for COVID-19 diagnosis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.IV/paper_4.html">
      <font color="black">Fighting together against the pandemic: learning multiple models on
  tomography images for COVID-19 diagnosis</font>
    </a>
  </h2>
  <font color="black">次に、アンサンブル分類のコンテキストでニューラルアーキテクチャによって画像から抽出された知識を組み合わせます。代替ソリューションは、リアルタイムポリメラーゼ連鎖反応（RT-PCR）テストまたは胸部コンピューター断層撮影（CT）スキャン画像によって実行される早期診断のままです。 ..それらは、医療を含むさまざまなタイプの画像への自動アプローチに不可欠な分類設計タスクを最適化します。 
[概要]科学者は、まだ感染していない人々に効果的なワクチンを見つけようとしています。彼らは、現在テストされている病気の解決策を見つけたいと考えています。これらには、深層学習アルゴリズム、特に畳み込みニューラルネットワークが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Channel Attention Networks for Robust MR Fingerprinting Matching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.IV/paper_5.html">
      <font color="black">Channel Attention Networks for Robust MR Fingerprinting Matching</font>
    </a>
  </h2>
  <font color="black">この研究のもう1つの貢献は、新しいチャネル選択方法です。注意ベースのチャネル選択です。磁気共鳴フィンガープリント（MRF）により、T1およびT2緩和時間などの複数の組織パラメーターの同時マッピングが可能になります。チャネルごとの注意モジュールと完全に畳み込みのあるネットワークで構成される新しいニューラルネットワークアーキテクチャを提案することによる欠点。 
[ABSTRACT] mrfは、さまざまなアクティベーションのデメリットのデメリットに依存しているため、スキャン中に各組織が独自の信号進化を生成します。提案されたmrfのアプローチにより、緩和時間がt1で8.88％、t2で75. 44％短縮されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Viral Pneumonia Screening on Chest X-ray Images Using Confidence-Aware
  Anomaly Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.IV/paper_6.html">
      <font color="black">Viral Pneumonia Screening on Chest X-ray Images Using Confidence-Aware
  Anomaly Detection</font>
    </a>
  </h2>
  <font color="black">この論文では、ウイルス性肺炎を非ウイルス性肺炎および健康な対照から1つのクラスの分類ベースの異常検出問題に区別するタスクを定式化し、信頼性を意識した異常検出（CAAD）モデルを提案します。共有特徴抽出、異常検出モジュール、および信頼性予測モジュール。バイナリ分類に対する私たちのアプローチの主な利点は、個々のウイルス性肺炎クラスを明示的にモデル化することを避け、すべての既知のウイルス性肺炎の症例を異常として扱い、1つのクラスを強化することです。モデル..胸部X線を使用したウイルス性肺炎の迅速かつ正確な検出は、特に他の胸部画像診断法が利用できない場合に、大規模なスクリーニングと流行予防に非常に役立ちます。 
[概要]胸部X線を使用したウイルス性肺炎の迅速かつ正確な検出は、大規模なスクリーニングとエピデミック予防に非常に役立ちます。多様なデータセットシフトが分類アプローチのパフォーマンスを制御します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-27">
        <br><font color="black">2020-03-27</font>
      </time>
    </span>
</section>
<!-- paper0: Explainable-by-design Semi-Supervised Representation Learning for
  COVID-19 Diagnosis from CT Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.IV/paper_7.html">
      <font color="black">Explainable-by-design Semi-Supervised Representation Learning for
  COVID-19 Diagnosis from CT Imaging</font>
    </a>
  </h2>
  <font color="black">説明可能な分類結果により、提案された診断システムはCOVID-19分類に非常に効果的です。定性的および定量的に得られた有望な結果に基づいて、大規模な臨床研究における当社の開発した技術の幅広い展開を想定しています。 https://git.etrovub.be/AVSP/ct-based-covid-19-diagnostic-tool.git .. CT画像用に2つの異なるネットワークのアーキテクチャを最適化しました。（i）新しい条件付き変分オートエンコーダー（CVAE） ）エンコーダ層内のクラスラベルを統合し、表現学習のコンテキストの手がかりを最大限に活用するエンコーダの共有アテンション層とサイド情報を使用する特定のアーキテクチャ、および（ii）監視された分類のためのダウンストリーム畳み込みニューラルネットワークCVAEのエンコーダー構造を使用します。 
[ABSTRACT]コードはwwwで入手できます。ギット。 etrovub。 etrovub。 be / avsp / avsp。 avsp / avsp.itは、エンコーダーレイヤー内のクラスラベルを統合し、共有アテンションレイヤーでサイド情報を使用する特定のアーキテクチャを備えた新しい条件付き変分オートエンコーダー（cvae）のct画像に使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Imperceptible Adversarial Image Patches Based on Network
  Explanations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.IV/paper_8.html">
      <font color="black">Towards Imperceptible Adversarial Image Patches Based on Network
  Explanations</font>
    </a>
  </h2>
  <font color="black">このソフトマスクに基づいて、CFRの最適な摂動を検索するために、逆温度を使用した新しい目的関数を開発します。ネットワークの説明により、CFRに追加された摂動は他の領域よりも効果的です。したがって、摂動は冗長です。人間の目で簡単に検出できます。 
[概要]主なアイデアは、摂動のネットワーク説明に基づいて、画像の寄与特徴領域を見つけることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Deep learning for photoacoustic imaging: a survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.IV/paper_9.html">
      <font color="black">Deep learning for photoacoustic imaging: a survey</font>
    </a>
  </h2>
  <font color="black">このレビューでは、光音響イメージングの深層学習に特に焦点を当てて、医療画像分析への機械学習の適用におけるいくつかの新しい開発と課題の概要を説明しました。機械学習は劇的に開発され、多くのアプリケーションを目撃しました。過去数年間のさまざまな分野..ディープニューラルネットワークは、医用画像技術、医療データ分析、医療診断、その他の医療問題において大きな可能性を秘めており、前臨床段階と臨床段階の両方で推進されています。 
[概要]深い人工ニューラルネットワークは、最先端の機械学習モデルになりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: ProsRegNet: A Deep Learning Framework for Registration of MRI and
  Histopathology Images of the Prostate -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.IV/paper_10.html">
      <font color="black">ProsRegNet: A Deep Learning Framework for Registration of MRI and
  Histopathology Images of the Prostate</font>
    </a>
  </h2>
  <font color="black">私たちのコードはhttps://github.com/pimed//ProsRegNetで無料で入手できます。結果は、ディープラーニングパイプラインがより正確な登録結果を達成し、最先端の登録よりも少なくとも20倍高速であることを示しています。アルゴリズム..ただし、従来のMRI組織病理学登録アプローチは計算コストが高く、コスト関数と登録ハイパーパラメーターを慎重に選択する必要があります。 
[要約] mriのmri定義は、放射線科医間での観察者間の高いばらつきに悩まされています。これは、臨床的に重要な癌の見逃し、低リスクネットワークの過剰診断、および頻繁な偽陽性につながる可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Addressing Artificial Intelligence Bias in Retinal Disease Diagnostics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.IV/paper_11.html">
      <font color="black">Addressing Artificial Intelligence Bias in Retinal Disease Diagnostics</font>
    </a>
  </h2>
  <font color="black">調査結果は、データの不均衡とドメインの一般化がサブポピュレーション間の精度の不一致につながる可能性があることを示し、合成眼底画像の新しい生成方法がAIのバイアスを取り除く役割を果たす可能性があることを示しています。従来の/ベースライン診断DLSを使用する新しいDLSと比較しましたバイアス除去のための生成モデルを介して拡張されたトレーニングデータ..パブリックドメインのKaggle-EyePACSデータセット（88,692眼底および44,346個体、元々は民族性が多様）は、臨床医が注釈を付けたラベルを追加し、データの不均衡とドメインの一般化の人工的なシナリオを作成することによって変更されました。紹介を保証するDRを伴う網膜の画像（DR参照可能）およびおそらく平均してブドウ膜メラノサイト内のメラニンの濃度が高く、網膜画像の色素沈着に寄与する暗い肌の個人からの網膜の画像のトレーニング（テストではない）例。 
[概要]パブリックドメインのkaggle-eyepacsデータセット（88、692 Fundiおよび44、346の個人、元々は民族性が異なる）は、臨床医の注釈付きラベルを追加し、データの不均衡とドメインの一般化の人工的なシナリオを構築することによって変更されました。サブポピュラ間で精度の不一致につながります。111,000t.5百万のtメールがaiの使用によって影響を受けています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br><font color="black">2020-04-28</font>
      </time>
    </span>
</section>
<!-- paper0: Anisotropic 3D Multi-Stream CNN for Accurate Prostate Segmentation from
  Multi-Planar MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.IV/paper_12.html">
      <font color="black">Anisotropic 3D Multi-Stream CNN for Accurate Prostate Segmentation from
  Multi-Planar MRI</font>
    </a>
  </h2>
  <font color="black">それぞれ2つ（デュアルプレーン）と3つ（トリプルプレーン）の画像方向で機能するアーキテクチャの2つのバリエーションを調査します。文献で使用されている標準のベースライン（シングルプレーン）、つまりプレーンアキシャルと比較します。セグメンテーション..結果：複数のサイトにまたがる2つのデータセットでのトレーニングと評価により、単純な軸方向セグメンテーションよりも統計的に有意な改善が得られます（ダイス類似度係数で$ p &lt;0.05 $）。 
[要約] cnnのセグメンテーションアプローチの大部分は、mrスキャンのエスクワイアのみを考慮しています。彼は、特にベースで進捗状況を観察できると述べています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-23">
        <br><font color="black">2020-09-23</font>
      </time>
    </span>
</section>
<!-- paper0: LIFI: Towards Linguistically Informed Frame Interpolation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.IV/paper_13.html">
      <font color="black">LIFI: Towards Linguistically Informed Frame Interpolation</font>
    </a>
  </h2>
  <font color="black">また、従来の非言語メトリックで高いパフォーマンスを示しているにもかかわらず、コンピュータビジョンモデルが音声の忠実な補間を正確に生成できない例も示します。このようなコンテンツは、今日、オンラインコミュニケーションの主要な形式を形成しています。この動機により、新しいセットを提供します。特に音声ビデオの補間の問題を対象とした、言語学的に情報に基づいたメトリック。 
[概要]音声理解のコンピュータービジョンビデオ生成モデルをテストするためのいくつかのデータセットもリリースします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-30">
        <br><font color="black">2020-10-30</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Chair Segments: A Compact Benchmark for the Study of Object Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_0.html">
      <font color="black">Chair Segments: A Compact Benchmark for the Study of Object Segmentation</font>
    </a>
  </h2>
  <font color="black">ChairSegmentsがCIFAR-10データセットと同等であるが、セグメンテーションのための新しいモデルアーキテクチャを迅速に設計および反復することを目指しています。最後に、このデータセットは半合成ですが、実際のデータの有用なプロキシになる可能性があります。事前トレーニングのソースとして使用した場合のObjectDiscoveryデータセットの最先端の精度。ChairSegmentsは、さまざまな背景の配列に合成された透明な背景を持つ椅子のさまざまな典型的な画像のセットで構成されます。 
[概要]この論文では、オブジェクトセグメンテーション用の斬新でコンパクトな半合成データセットであるchairsegmentsを紹介します。これは、実際のデータの便利なプロキシとなり、ソースとして使用した場合のオブジェクト検出データセットの最先端の精度につながります。事前トレーニングの</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: BlockGAN: Learning 3D Object-aware Scene Representations from Unlabelled
  Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_1.html">
      <font color="black">BlockGAN: Learning 3D Object-aware Scene Representations from Unlabelled
  Images</font>
    </a>
  </h2>
  <font color="black">これにより、BlockGANは、影や照明などのオブジェクトの外観間のオクルージョンと相互作用を推論し、画像のリアリズムを維持しながら、各オブジェクトの3Dポーズとアイデンティティを制御できます。BlockGANは、ラベルのない単一のシングルのみを使用して、エンドツーエンドでトレーニングされます。 3Dジオメトリ、ポーズラベル、オブジェクトマスク、または同じシーンの複数のビューを必要としない画像。私たちの実験では、明示的な3D機能を使用してオブジェクトを表現すると、BlockGANがオブジェクト（前景と背景）の両方の観点から解きほぐされた表現を学習できることが示されています）とそのプロパティ（ポーズとアイデンティティ）。 
[ABSTRACT] blockganは、コンピューターグラフィックスパイプラインに基づいています。ラベルのない単一の画像のみを使用して3Dフィーチャを作成します。これには、シーン全体の3Dフィーチャの作成が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-20">
        <br><font color="black">2020-02-20</font>
      </time>
    </span>
</section>
<!-- paper0: Attention-gating for improved radio galaxy classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_2.html">
      <font color="black">Attention-gating for improved radio galaxy classification</font>
    </a>
  </h2>
  <font color="black">注意ゲーティングで使用される正規化および集約方法の選択が個々のモデルの出力にどのように影響するかを定量的に示し、結果の注意マップを使用して、モデルによって行われた分類の選択を解釈できることを示します。正規化と集約の選択は、個々のモデルのパフォーマンスに最小限の影響しか及ぼさない可能性があり、それぞれの注意マップの解釈可能性に大きな影響を与える可能性があり、天文学者が無線ソースを目で分類する方法とよく一致するモデルを選択することにより、ユーザーはモデルを使用できます。より効果的な方法..私たちのモデルによって識別された顕著な領域は、同等の分類を行うために専門家の人間の分類者が参加する領域とよく一致していることがわかります。 
[概要]以前の分類と同等のパフォーマンスを発揮する新しいモデルを紹介します。このモデルでは、この分野で次に小さいクラシッククラシックcnnアプリケーションよりも50％以上少ない質問を使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Maximum Roaming Multi-Task Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_3.html">
      <font color="black">Maximum Roaming Multi-Task Learning</font>
    </a>
  </h2>
  <font color="black">全体的な方法は柔軟性があり、簡単に適用でき、優れた正則化を提供し、最近のマルチタスク学習の定式化と比較して一貫して改善されたパフォーマンスを実現します。さまざまな視覚的マルチタスクデータセットでの実験を通じて、方法の特性を研究します。異なるタスク間でパラメーターを分割することは、共有された重みに対する最適化の制約を緩和する効率的な方法であることが証明されています。パーティションがばらばらであるか、重複している可能性があります。 
[概要]共同タスクの強化により、共同タスクの分離によって設定された誘導バイアスを弱めることができます。この方法により、ユーザーは規制された頻度でできるだけ多くのタスクにアクセスできるため、ネットワークは各更新に完全に適応します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br><font color="black">2020-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: A Framework and Dataset for Abstract Art Generation via CalligraphyGAN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_4.html">
      <font color="black">A Framework and Dataset for Abstract Art Generation via CalligraphyGAN</font>
    </a>
  </h2>
  <font color="black">また、アメリカの画家フランツ・クラインの作品など、1940年代と1950年代の抽象表現主義運動の絵画からインスピレーションを得ています。私たちの作品は、キャラクター自体が視覚芸術のユニークな形である中国の書道に触発されています。美的絵画..さらに、中国の書道画像データセットを公開し、プロトタイプシステムとユーザースタディを使用してフレームワークをデモンストレーションしました。 
[ABSTRACT]研究は絵画や音楽の生成に適用されていますが、aiはまだ創造性において人間に遅れをとっており、aiの究極のムーンショットと見なされることがよくあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Tensor Completion via Few-shot Convolutional Sparse Coding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_5.html">
      <font color="black">Tensor Completion via Few-shot Convolutional Sparse Coding</font>
    </a>
  </h2>
  <font color="black">さらに、LRTC-CSCは、CSCのスパース性特性により、小さなサンプルでトレーニングできます。逆に、信号処理の分野では、畳み込みスパースコーディング（CSC）を使用すると、の高周波成分を適切に表現できます。一般にデータの詳細成分に関連付けられている画像。この目的のために、高周波成分をキャプチャするためのLRTCの補足正規化としてCSCを採用する新しい方法LRTC-CSCを提案します。 
[ABSTRACT] lrtc-cscは欠測値の問題を解決し、詳細を回復するだけでなく、詳細情報を低くすることはできないという欠点があります-ランク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Vector Quantized Shape Code for Amodal Blastomere Instance
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_6.html">
      <font color="black">Learning Vector Quantized Shape Code for Amodal Blastomere Instance
  Segmentation</font>
    </a>
  </h2>
  <font color="black">まず、ベクトル量子化変分オートエンコーダ（VQ-VAE）モデルを事前トレーニングして、グラウンドトゥルースアモーダルマスクからこれらの離散形状コードを学習します。また、オクルージョンマップを検出して、オクルージョン情報をバックボーン機能と統合します。正確な測定を行うには割球の形状とサイズ、それらの非モーダルセグメンテーションが必要です。 
[ABSTRACT]各オブジェクトについて、以前の方法では、入力フィーチャからターゲットマスクを直接回帰します。問題を軽減するために、入力フィーチャを中間形状コードに分類し、それらから完全なオブジェクト形状を復元することを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Fine-grained activity recognition for assembly videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_7.html">
      <font color="black">Fine-grained activity recognition for assembly videos</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、アセンブリアクションを構造として認識するタスクについて説明します（たとえば、最後に、2つのアプリケーション駆動型データソース（（1）IKEA家具アセンブリデータセット、および（2）ブロック構築）でメソッドを経験的に評価します。データセット..2つ目は、アセンブリを区別するためにきめ細かい幾何学的推論が必要ですが、システムは平均正規化編集距離23％を達成します。これは、以前の作業に比べて69％の相対的な改善です。
[ABSTRACT]アセンブリアクションを認識するメソッド単一のフレームワーク内の運動構造。これには、イケアの家具（アセンブリデータセット）とブロック（建物のデータセット）が含まれます。2つ目は、アセンブリを区別するためにきめ細かい幾何学的な推論が必要であり、システムは平均正規化編集距離23％を達成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: PV-RAFT: Point-Voxel Correlation Fields for Scene Flow Estimation of
  Point Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_8.html">
      <font color="black">PV-RAFT: Point-Voxel Correlation Fields for Scene Flow Estimation of
  Point Clouds</font>
    </a>
  </h2>
  <font color="black">実験結果は、PV-RAFTが最先端の方法を著しく上回っていることを示しています。点群をマルチスケールでボクセル化することにより、ピラミッド相関ボクセルが構築され、長距離の対応をモデル化します。すべてのペアの相関シーンフロー推定タスクで重要な役割を果たします。 
[ABSTRACT]すべて-ペア相関はシーンフロー推定タスクで重要な役割を果たします。それらはポイントペアのローカルおよび長距離依存関係をキャプチャします。この問題に取り組むために、ポイント-ボクセル相関フィールドを提示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Shapeshifter Networks: Decoupling Layers from Parameters for Scalable
  and Effective Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_9.html">
      <font color="black">Shapeshifter Networks: Decoupling Layers from Parameters for Scalable
  and Effective Deep Learning</font>
    </a>
  </h2>
  <font color="black">SSNは、モデルの損失関数やアーキテクチャを変更する必要がないため、使いやすくなっています。画像分類、双方向の画像文検索、フレーズの接地など、さまざまなタスクにわたって7つのネットワークアーキテクチャを使用してSSNを評価し、高性能モデルを作成します。パラメータのわずか1％を使用する場合でも..モデルが成長し続けるにつれて、トレーニング中にモデルをGPUメモリに適合させることがますます懸念されています。 
[概要]モデルの重みから分類を分離する柔軟なニューラルネットワークフレームワークであるシェイプシフターネットワーク（ssns）を紹介しました。これにより、任意の数のパラメーターを使用して任意のニューラルネットワークを実装できます。これにより、サイズが異なっていても設定を共有できます。または別の操作を実行します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br><font color="black">2020-06-18</font>
      </time>
    </span>
</section>
<!-- paper0: Analyzing Neural Networks Based on Random Graphs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_10.html">
      <font color="black">Analyzing Neural Networks Based on Random Graphs</font>
    </a>
  </h2>
  <font color="black">さまざまなタイプのランダムグラフに対応するアーキテクチャを備えたニューラルネットワークの大規模な評価を実行します。また、主に短距離接続のネットワークは、多くの長距離接続を可能にするネットワークよりもパフォーマンスが優れていることがわかります。最高のパフォーマンスを発揮するネットワークの大部分を占める準1次元グラフのセットを選択する数値グラフ特性。 
[概要]グラフのさまざまな構造的および数値的特性を調査します。これらは、新しい数値グラフ特性の結果に基づいています。これは、最高のパフォーマンスを発揮するネットワークの準-1形式のセットを選択します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br><font color="black">2020-02-19</font>
      </time>
    </span>
</section>
<!-- paper0: Curiosity-driven 3D Scene Structure from Single-image Self-supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_11.html">
      <font color="black">Curiosity-driven 3D Scene Structure from Single-image Self-supervision</font>
    </a>
  </h2>
  <font color="black">好奇心が強く、したがって、それらのあいまいさを解決し、実行可能な最小値を見つけるために..微分可能レンダリングを使用した3Dシーン構造の監視のための合成による分析のような損失が、ほとんどの場合、極小値でスタックするため、実用的でない理由を分析します。これは、新しい形式のトレーニングによって克服できます。追加のネットワークを使用して最適化自体を操作し、可能なソリューションの全範囲を探索します。つまり、
[ABSTRACT]結果のシステムは異なる仮想または実画像の2D画像を変換します。作成された3Dシーンから作成され、2D画像からのみ学習されます。たとえば、新しい形式のトレーニングによって克服できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: FairFace Challenge at ECCV 2020: Analyzing Bias in Face Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_12.html">
      <font color="black">FairFace Challenge at ECCV 2020: Analyzing Bias in Face Recognition</font>
    </a>
  </h2>
  <font color="black">参加者による一般的な戦略は、顔の前処理、データ分布の均質化、バイアスを意識した損失関数とアンサンブルモデルの使用でした。チャレンジの最終段階では、36のアクティブなチームが集まり、そのうち10は0.999AUC-ROCを超えました。提案されたバイアス指標のスコアが低い。この作業は、2020年のChaLearnの人々の公正な顔の認識と分析の課題を要約し、最も優れたソリューションの説明と結果の分析を提供します。 
[概要]課題の目的は、提出されたアルゴリズムの性別と肌の色の精度とバイアスを評価することでした。データセットはバランスが取れていません。これは、公正な結果を提示するはずのaiベースのモデルがトレーニングおよび評価される現実世界のシナリオをシミュレートします。不均衡なデータ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Top-1 CORSMAL Challenge 2020 Submission: Filling Mass Estimation Using
  Multi-modal Observations of Human-robot Handovers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_13.html">
      <font color="black">Top-1 CORSMAL Challenge 2020 Submission: Filling Mass Estimation Using
  Multi-modal Observations of Human-robot Handovers</font>
    </a>
  </h2>
  <font color="black">次に、これらの指標を組み合わせて、コンテナの充填質量を推定します。CORSMAL2020チャレンジは、この問題の知覚部分に焦点を当てています。ロボットは、人間が保持するコンテナの充填質量を推定する必要があります。過剰適合の証拠を示さずに、パブリックサブセットとプライベートサブセットの両方でCORSMAL2020チャレンジへのすべての提出物の全体的なパフォーマンス。 
[概要]ロボットは、人間が保持するコンテナの充填質量を推定する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Vision-based flocking in outdoor environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_14.html">
      <font color="black">Vision-based flocking in outdoor environments</font>
    </a>
  </h2>
  <font color="black">結果は、ドローンがかなりの背景の乱雑さと困難な照明条件にもかかわらず、屋外環境で安全にナビゲートできることを示しています。カメラのセットアップは、エージェントの構成に関係なく死角を回避することによって群れの安全を保証します。ドローンには複数のカメラが装備されています全方向の視覚入力を提供します。 
[ABSTRACT]ドローンには、全方向の視覚入力を提供する複数のカメラが装備されています。これらは、ビジョンベースの検出および追跡アルゴリズムを使用して制御されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Text Recognition in the Wild: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_15.html">
      <font color="black">Text Recognition in the Wild: A Survey</font>
    </a>
  </h2>
  <font color="black">この論文の目的は、（1）シーンテキスト認識に関連する基本的な問題と最新技術を要約することです。 （2）新しい洞察とアイデアを紹介します。 （3）公的に利用可能なリソースの包括的なレビューを提供する。 （4）今後の作業の方向性を指摘する。テキストの歴史は数千年以上前にさかのぼることができる。近年、深層学習の台頭と発展に伴い、革新性、実用性、と効率。 
[概要] githubの研究者は、シーンテキスト認識の分野に関する新しい研究を書きました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br><font color="black">2020-05-07</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Accuracy of Binary Neural Networks using Unbalanced Activation
  Distribution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_16.html">
      <font color="black">Improving Accuracy of Binary Neural Networks using Unbalanced Activation
  Distribution</font>
    </a>
  </h2>
  <font color="black">ニューラルネットワークモデルの二値化は、モバイルデバイスなどのリソースに制約のある環境にディープニューラルネットワークモデルを展開するための有望な方法の1つと見なされています。広範な分析に基づいて、以前の作業とはまったく対照的に、不均衡なアクティベーション分布が実際に可能であると主張します。 BNNの精度を向上させます。また、バイナリアクティベーション関数のしきい値を調整すると、バイナリアクティベーションの分布が不均衡になり、BNNモデルの精度が向上することも示します。 
[ABSTRACT]バイナリプロシージャ（bnns）は、フルプレッパモデルと比較して精度が大幅に低下する傾向があります。ただし、バイナリ活性化関数のしきい値を制限する代わりに、モデルの精度を向上させます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Ship Detection: Parameter Server Variant -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_17.html">
      <font color="black">Ship Detection: Parameter Server Variant</font>
    </a>
  </h2>
  <font color="black">パラメータサーバーバリアントは、ターゲットデータセットのクラス精度を上回り、最良の単一ノードアプローチと比較して73 \％のクラス精度に達します。単一ノードとパラメータサーバーバリアントのアーキテクチャの体系的なパフォーマンスに関する比較調査について、経験的調査結果のサポートを受けて説明します。 。また、単一ノードアーキテクチャを、ワーカーがブースティングメカニズムとして機能するパラメーターサーバーバリアントと比較します。 
[概要]この作業では、クラウドベースのソリューションにおけるカスタマイズ戦略、クラスの正解率、トレーニング時間、およびコストの間の緊張関係を探ります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Learning View-Disentangled Human Pose Representation by Contrastive
  Cross-View Mutual Information Maximization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_18.html">
      <font color="black">Learning View-Disentangled Human Pose Representation by Contrastive
  Cross-View Mutual Information Maximization</font>
    </a>
  </h2>
  <font color="black">学習された表現の力を評価するために、従来の完全に監視された行動認識設定に加えて、シングルショットクロスビュー行動認識と呼ばれる新しいタスクを導入します。さらに、解きほぐしと滑らかさを確保するための2つの正則化項を提案します。学習された表現..この方法は、対照的な学習方法で異なる視点から実行された同じポーズの相互情報を最大化するクロスビュー相互情報最大化（CV-MIM）を使用してネットワークをトレーニングします。 
[要約]この方法は、クロスビュー相互情報量最大化（cv-mim）を使用してネットワークをトレーニングします。標準表現は、ビューアクション認識に使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Synthesizing Coupled 3D Face Modalities by Trunk-Branch Generative
  Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_19.html">
      <font color="black">Synthesizing Coupled 3D Face Modalities by Trunk-Branch Generative
  Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">最近、Generative Adversarial Networks（GAN）を使用して、顔の高品質のテクスチャを生成できることが実証されました。それでも、生成プロセスでは、ジオメトリと法線を省略するか、独立したプロセスを使用して3D形状情報を生成します。この論文では、高品質のテクスチャ、形状、法線を共同で生成する最初の方法論を紹介します。これは、フォトリアリスティックな合成に使用できます。 
[概要] 3D顔生成の研究は、顔面の線形統計モデルを中心に展開しています。これらのモデルは、写真に使用できます-リアルなビジョン。コードとモデルは、プロジェクトページで入手できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-05">
        <br><font color="black">2019-09-05</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Descriptor Visual Localization and Mapping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_20.html">
      <font color="black">Cross-Descriptor Visual Localization and Mapping</font>
    </a>
  </h2>
  <font color="black">広範な実験により、さまざまな手作りおよび学習された機能の最先端のベンチマークに対するアプローチの有効性が実証されています。データ駆動型アプローチは、機能記述子タイプにとらわれず、計算要件が低く、記述アルゴリズムの数..ただし、生の画像が保存されないことが多く、マップを再構築すると、添付されたデジタルコンテンツが失われる可能性があるため、実際にはこれを繰り返すことは通常不可能です。 
[ABSTRACT]ローカリゼーションとマッピングは基本的なコンピュータビジョンの問題ですが、従来の設定では、マップの進化全体を通じて同じローカル画像機能を使用するシングルショットプロセスとして扱われます。代わりに、生の画像であるため、マッピングは通常実際には不可能です。多くの場合、保存されておらず、ローカル画像のマップを再構築すると、添付されたデジタルコンテンツが失われる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Neural Domain Adaptation for Document Image Binarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_21.html">
      <font color="black">Unsupervised Neural Domain Adaptation for Document Image Binarization</font>
    </a>
  </h2>
  <font color="black">したがって、私たちの方法論は、最初に革新的な方法でドメイン間の類似性を測定して、適応プロセスを適用することが適切かどうかを判断します。二値化はよく知られた画像処理タスクであり、その目的はの前景を分離することです。背景からの画像..これは、教師あり学習でよくある問題であり、いわゆるドメイン適応（DA）手法を使用して対処できます。 
[概要]これらの手法は、ラベル付きデータが利用可能な1つのドメインで学習した知識を利用して、ラベル付きデータがない他のドメインに適用します。ただし、ソースドメインとターゲットドメインの両方が非常に類似している場合、これは適応は有害である可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Monocular 3D Object Detection with Sequential Feature Association and
  Depth Hint Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_22.html">
      <font color="black">Monocular 3D Object Detection with Sequential Feature Association and
  Depth Hint Augmentation</font>
    </a>
  </h2>
  <font color="black">デプスプライア、ポスト最適化、またはその他の改良モジュールを利用せずに、当社のネットワークは、適切な実行速度を維持しながら、最先端の方法に対して競争力を発揮します。トレーニング段階では、回帰出力が均一にエンコードされ、損失のもつれを解きます。深さ推定のヒントとして特性化された深さパターンを提供するために、専用の深さヒントモジュールは、深さヒントと呼ばれる行方向の特徴を生成するように設計されています。 
[要約]この作業では、単眼の3Dオブジェクト検出のタスクに対処するために、fadnetという名前のキーポイントベースのネットワークが提示されます。この作業のもう1つの貢献は、深度ヒント拡張の戦略です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Siamese Basis Function Networks for Defect Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_23.html">
      <font color="black">Siamese Basis Function Networks for Defect Classification</font>
    </a>
  </h2>
  <font color="black">このアプローチを使用して、著者はシャムカーネル内にある種のクラス認識を作成しました。著者は、基底関数ネットワークでいわゆるシャムカーネルを使用してシャム基底関数ネットワーク（SBF-Network）を作成する新しいアプローチを提案します。 ..これらのベクトルは、低次元空間でのそれぞれの画像のエンコードを表します。 
[概要]シャムカーネルは基底関数ネットワークで使用されます。次に、データセット内の他の画像から中心を区別する方法でソロモンを生成するようにトレーニングされます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: A Photogrammetry-based Framework to Facilitate Image-based Modeling and
  Automatic Camera Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_24.html">
      <font color="black">A Photogrammetry-based Framework to Facilitate Image-based Modeling and
  Automatic Camera Tracking</font>
    </a>
  </h2>
  <font color="black">モジュラーシステム設計により、追加の労力なしでさらなるアプローチを統合できます。フレームワークはオープンソースソフトウェアパッケージとして公開されています。現在、フレームワークはいくつかの最先端のSfMおよびMVSパイプラインをサポートしています。 
[概要] sfmを適用すると、フィーチャトラックを手動で定義したり、画像データのキャプチャに使用するカメラを調整したりすることなく、カメラの動きを判断できます。このコンセプトは、オープンソースソフトウェアパッケージとして公開されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-modal Retrieval and Synthesis (X-MRS): Closing the modality gap in
  shared subspace -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_25.html">
      <font color="black">Cross-modal Retrieval and Synthesis (X-MRS): Closing the modality gap in
  shared subspace</font>
    </a>
  </h2>
  <font color="black">食品の理解を自動化しようとする幅広い方法のセットである計算食品分析（CFA）は、当然、特定の食品または料理のマルチモーダル証拠の分析を必要とします。さらに、学習した部分空間の表現力を実証するために、レシピの埋め込みを条件とした生成的食品画像合成モデルを提案します。画像、レシピテキスト、準備ビデオ、栄養表示など。
[要約]提案された方法は食品からレシピへの問題に取り組むために使用されます。これには、食品の検索において現在の状態（sota）よりも大幅に優れていることを見つけることが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Assessing the Influencing Factors on the Accuracy of Underage Facial Age
  Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_26.html">
      <font color="black">Assessing the Influencing Factors on the Accuracy of Underage Facial Age
  Estimation</font>
    </a>
  </h2>
  <font color="black">徹底的な評価により、将来の年齢推定システムで克服すべき最も影響力のある要因を特定できます。このペーパーでは、2つのクラウド年齢推定サービス（Amazon WebServiceのRekognitionサービスとMicrosoftAzureのFaceAPI）のパフォーマンスの包括的な評価を示しました。 21,800を超える未成年者のデータセット（ぼかし、ノイズ、露出、解像度）は、自動年齢推定サービスの結果に影響を与えます。 
[概要]自動年齢推定サービスは、デバイスやオンラインサービスの数の増加から得られる証拠のオーバーフローバックログを減らす可能性を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: A Multi-Task Learning Approach for Human Activity Segmentation and
  Ergonomics Risk Assessment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_27.html">
      <font color="black">A Multi-Task Learning Approach for Human Activity Segmentation and
  Ergonomics Risk Assessment</font>
    </a>
  </h2>
  <font color="black">HASヘッドは、エンコーダーデコーダー時間畳み込みネットワークを利用して、長いビデオをセマンティックに個別のアクティビティクラスにセグメント化しますが、HAEは、長短期記憶ベースのアーキテクチャを使用します。このフレームワークでは、ヒューマンアクティビティセグメンテーションを解決します。活動評価を改善するための補助タスクとしての（HAS）問題..グラフ畳み込みネットワークバックボーンを利用して人間の関節間の相互接続を機能に埋め込む、HAEの新しいマルチタスクフレームワークを提案します。 
[概要]人間活動セグメンテーション（has）問題は、活動評価を改善するための補助タスクです。人間活動セグメンテーションは、人間活動セグメンテーション問題に基づく問題です。シーン情報を使用して、アクティビティスコアを回帰します。これらは非常にシーンです-これらの方法の一般化可能性を疑わしいものにする依存</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-07">
        <br><font color="black">2020-08-07</font>
      </time>
    </span>
</section>
<!-- paper0: Classifying bacteria clones using attention-based deep multiple instance
  learning interpreted by persistence homology -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_28.html">
      <font color="black">Classifying bacteria clones using attention-based deep multiple instance
  learning interpreted by persistence homology</font>
    </a>
  </h2>
  <font color="black">これは、以前はクローンの類似性が高いため不可能と考えられていた困難な作業です。この目的のために、注意ベースの複数インスタンス学習を使用したマルチステップアルゴリズムを適用します。0.9レベルの精度を取得することを除いて、広範な導入を行います。 CellProfilerと永続性の相同性に基づく解釈可能性により、モデルの理解可能性と信頼性が向上します。 
[要約]プロセスは別のタスクであり、以前はクローンの類似性が高いため不可能と考えられていました。たとえば、セルプロファイラーと永続性の相同性に基づいた広範な解釈可能性を導入します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: PatchmatchNet: Learned Multi-View Patchmatch Stereo -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_29.html">
      <font color="black">PatchmatchNet: Learned Multi-View Patchmatch Stereo</font>
    </a>
  </h2>
  <font color="black">初めて、エンドツーエンドのトレーニング可能なアーキテクチャに反復マルチスケールPatchmatchを導入し、反復ごとに新しい学習済みの適応伝播および評価スキームを使用してPatchmatchコアアルゴリズムを改善します。PatchmatchNet、新しい学習可能なものを紹介します。高解像度マルチビューステレオ用のPatchmatchのカスケード定式化。高い計算速度と低いメモリ要件により、PatchmatchNetは高解像度の画像を処理でき、3Dコストボリュームの正規化を採用する競合他社よりもリソースが限られたデバイスでの実行に適しています。 
[概要] patchmatchnetは高解像度の画像を処理できます。競合他社よりもリソースが限られたデバイスで実行するのに適しています。patchmatchnetは3Dコストボリュームの正則化よりもスケーリングに適しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Delaunay Surface Elements for Mesh Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_30.html">
      <font color="black">Learning Delaunay Surface Elements for Mesh Reconstruction</font>
    </a>
  </h2>
  <font color="black">再構築されたメッシュの多様性を最大化するために、隣接する要素のローカル2D投影を同期します。結果は、任意のトポロジでメッシュを再構築する現在の方法よりも、再構築されたメッシュの全体的な多様性が向上することを示しています。学習した対数マップを使用してこれらの近隣。 
[ABSTRACT]既存の学習ベースのメッシュ再構築方法では、ほとんどの場合、側面が個別に生成されます。私たちの方法では、最初に各ポイント周辺のローカル測地線近傍を推定します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: PWCLO-Net: Deep LiDAR Odometry in 3D Point Clouds Using Hierarchical
  Embedding Mask Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_31.html">
      <font color="black">PWCLO-Net: Deep LiDAR Odometry in 3D Point Clouds Using Hierarchical
  Embedding Mask Optimization</font>
    </a>
  </h2>
  <font color="black">推定された現在のポーズを使用して、最初の点群をワープして2番目の点群までの距離を橋渡しし、残差運動のコストボリュームを構築します。PWCLO-という名前のディープLiDARオドメトリ用の新しい3D点群学習モデルネット、階層的埋め込みマスク最適化を使用して、この論文で提案されます。同時に、埋め込みマスクは、ポーズの洗練のためのより正確なフィルタリング情報を取得するために、粗いものから細かいものまで階層的に最適化されます。 
[概要] LIDARオドメトリタスクの新しいモデルは、単純なアプローチから細かいアプローチに基づいて推定ポーズを作成するのに役立つように構築されています。モデルは、すべてのポイントのコストボリュームを全体的なポーズ情報に重み付けし、外れ値ポイントをフィルタリングするように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Meta-Cognition-Based Simple And Effective Approach To Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_32.html">
      <font color="black">Meta-Cognition-Based Simple And Effective Approach To Object Detection</font>
    </a>
  </h2>
  <font color="black">作業のベースモデルとしてYOLOv3 Tinyを使用し、MS COCOデータセットを使用してパフォーマンスを評価します。このペーパーでは、オブジェクト検出のメタ認知学習戦略を検討して、一般化能力を向上させると同時に、検出速度を維持します。 ..メタ認知メソッドは、トレーニングデータセット内のオブジェクトインスタンスを選択的にサンプリングして、過剰適合を減らします。 
[概要]メタ認知メソッドは、トレーニングデータセット内のオブジェクトインスタンスを選択的にサンプリングして、過剰適合を減らします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: DA2: Deep Attention Adapter for Memory-EfficientOn-Device Multi-Domain
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_33.html">
      <font color="black">DA2: Deep Attention Adapter for Memory-EfficientOn-Device Multi-Domain
  Learning</font>
    </a>
  </h2>
  <font color="black">1つのビジュアルドメイン）。現在、ディープニューラルネットワーク（DNN）の実際的な制限の1つは、単一のタスクまたはドメインへの高度な特殊化です（たとえば、調査中、アクティベーションストレージに使用されるメモリが主にボトルネックであることがわかりました。エッジデバイスでのトレーニング時間とコストを制限します。
[ABSTRACT]ディープアテンションアダプターは新しいドメイン学習方法です。モデルを適応させて、メモリ使用量のターゲットターゲット領域をターゲットにすることを目的としています。これにより、より広く展開することが不可能になります。使用済みリソース-限られたエッジデバイス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Spatial Attention for Face Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_34.html">
      <font color="black">Learning Spatial Attention for Face Super-Resolution</font>
    </a>
  </h2>
  <font color="black">この論文では、顔の超解像のために新しく提案された顔注意ユニット（FAU）上に構築された新しい空間注意残余ネットワーク（SPARNet）を紹介します。SPARNetHDと呼ばれるマルチスケール弁別器でSPARNetをさらに拡張し、高解像度の結果（つまり、$ 512 \ times512 $）。具体的には、バニラの残余ブロックに空間的注意メカニズムを導入します。 
[概要]ディープラーニングでは、顔画像の詳細な手法が必要です。これらには、顔の解析やランドマーク予測などの詳細な機能が含まれます。ただし、既存の作品のほとんどは、比較的低解像度の顔画像しか生成できません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Privacy-Preserving Image Features via Adversarial Affine Subspace
  Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_35.html">
      <font color="black">Privacy-Preserving Image Features via Adversarial Affine Subspace
  Embeddings</font>
    </a>
  </h2>
  <font color="black">元の機能と比較して、私たちのアプローチはパフォーマンスにわずかな影響しか与えませんが、攻撃者が個人情報を回復することを大幅に困難にします。顔認証と同様に..プライバシー保護表現の特徴マッチングは、部分空間から部分空間までの距離の概念に基づいて有効になります。 
[ABSTRACT]画像を利用して、対象の被写体に関する機密情報を復元できますが、元の画像の外観を再構築するためにも使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br><font color="black">2020-06-11</font>
      </time>
    </span>
</section>
<!-- paper0: Dehazing Cost Volume for Deep Multi-view Stereo in Scattering Media with
  Airlight and Scattering Coefficient Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_36.html">
      <font color="black">Dehazing Cost Volume for Deep Multi-view Stereo in Scattering Media with
  Airlight and Scattering Coefficient Estimation</font>
    </a>
  </h2>
  <font color="black">また、エアライトなどの散乱パラメータと、デヘイズコストボリュームに必要な散乱係数を推定する方法を提案します。フォグなどの散乱媒体での学習ベースのマルチビューステレオ（MVS）法を提案します。または、デヘイズコストボリュームと呼ばれる新しいコストボリュームを持つ煙。デヘイズコストボリュームは、コストボリューム内の掃引平面を使用して散乱効果を計算することにより、深度推定と画像復元のこの鶏肉と卵の問題を解決できます。 
[概要]実際の霧のシーンへのデヘイズコストボリュームの適用可能性を示しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-18">
        <br><font color="black">2020-11-18</font>
      </time>
    </span>
</section>
<!-- paper0: Red Blood Cell Segmentation with Overlapping Cell Separation and
  Classification on Imbalanced Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_37.html">
      <font color="black">Red Blood Cell Segmentation with Overlapping Cell Separation and
  Classification on Imbalanced Dataset</font>
    </a>
  </h2>
  <font color="black">20個の血液塗抹標本画像での精度は0.889です。したがって、不均衡データセットを使用したRBC分類に機械学習を使用することは、他の多くのアプリケーションよりも困難です。重複する細胞分離に焦点を当て、セグメンテーションプロセスでは最初に楕円を推定して赤血球を表します。 。 
[概要]この方法は、凹点を検出して楕円を見つけます。次に、有向楕円フィッティングを使用してセルデータの拡張を見つけます。この方法を使用して、セルのオーバーラップとデータの不均衡の問題に取り組むことが望まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Invariant Representation Learning for Infant Pose Estimation with Small
  Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_38.html">
      <font color="black">Invariant Representation Learning for Infant Pose Estimation with Small
  Data</font>
    </a>
  </h2>
  <font color="black">人間の姿勢推定ドメインの成熟度が増すにつれて、そのアプリケーションはますます広くなっています。これらの知識を微調整されたドメイン適応幼児ポーズ（FiDIP）推定モデルに徐々に転送するための多段階トレーニング戦略を導入します。 。私たちのFiDIPモデルは、乳児の姿勢推定のための最先端の人間の姿勢推定モデルよりも優れており、平均平均精度（AP）は90.1と高いことを実証しました。 
[ABSTRACT]モデルのパフォーマンスは、独特の動きをする幼児など、新しい被写体やポーズを含むアプリケーションでは大幅に低下します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-13">
        <br><font color="black">2020-10-13</font>
      </time>
    </span>
</section>
<!-- paper0: GMOT-40: A Benchmark for Generic Multiple Object Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_39.html">
      <font color="black">GMOT-40: A Benchmark for Generic Multiple Object Tracking</font>
    </a>
  </h2>
  <font color="black">最初に、GMOT-40と名付けられた最初の公開GMOTデータセットを構築します。これには、10のオブジェクトカテゴリに均等に分散された40の注意深く注釈が付けられたシーケンスが含まれます。GMOT-40ベンチマーク、評価結果、およびベースラインアルゴリズムをにリリースします。論文の発表時に公開されます。さらに、追跡アルゴリズムのさまざまな特性を評価するために、2つの追跡プロトコルが採用されています。 
[概要]この論文では、3つの側面でgmotの研究を後押しするために貢献します。最初に、motアルゴリズムと提案されたベースラインを含むgmot-40の徹底的な評価を行います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Mesh Flow: 3D Manifold Mesh Generation via Diffeomorphic Flows -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_40.html">
      <font color="black">Neural Mesh Flow: 3D Manifold Mesh Generation via Diffeomorphic Flows</font>
    </a>
  </h2>
  <font color="black">コードとデータがリリースされます。以前の方法では、幾何学的精度は高くなりますが、多様性は低くなります。重要なことに、NMFを使用して生成された多様体メッシュは、物理ベースのレンダリングとシミュレーションに適しています。 
[ABSTRACT]メッシュは「不適切」と呼ばれるため、実際のオブジェクトのように世界と対話できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-21">
        <br><font color="black">2020-07-21</font>
      </time>
    </span>
</section>
<!-- paper0: An Once-for-All Budgeted Pruning Framework for ConvNets Considering
  Input Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_41.html">
      <font color="black">An Once-for-All Budgeted Pruning Framework for ConvNets Considering
  Input Resolution</font>
    </a>
  </h2>
  <font color="black">画像分類とオブジェクト検出に基づく実験では、OFARPruningは、US-NetやMutualNetなどの1回限りの圧縮方法よりも精度が高く（FLOPが少ないと1〜2％向上）、同じ精度がさらに高くなることが示されています。従来のプルーニング方法（170 MFLOPでのMobileNetv2では72.6％対70.5％）として、はるかに高い効率で..最終的に、さまざまな解像度に適応するコンパクトなネットワークのコホートを取得して、1回だけでさまざまなエッジデバイスの動的FLOP制約を満たすことができますトレーニング..構造検索段階の後、提案された方法は、異なる剪定率と入力解像度でコンパクトな構造をランダムにサンプリングして、ジョイントの最適化を実現します。 
[概要]剪定マスクで剪定マスクが見つかったのはこれが初めてです。現在に加えて、コサイン％を使用して剪定マスクの類似性を測定し、エネルギーと時間の消費が少ない高品質のネットワークを取得します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: SensitiveLoss: Improving Accuracy and Fairness of Face Representations
  with Discrimination-Aware Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_42.html">
      <font color="black">SensitiveLoss: Improving Accuracy and Fairness of Face Representations
  with Discrimination-Aware Deep Learning</font>
    </a>
  </h2>
  <font color="black">この方法は、最先端のバイアス除去ネットワークに匹敵する結果を示し、自動システムによる識別効果を防ぐための一歩を表しています。最も使用されている顔データベースに基づく学習プロセスが、人気のあるプレバイアスにつながっていることを実験的に示します。強力なアルゴリズムによる識別を示す訓練された深顔モデル。実験には、ツリーで人気のある顔認識モデルと、性別と民族性を特徴とするさまざまな人口統計グループからの64,000のIDで構成される3つの公開データベースが含まれます。 
[概要]最も人気のある顔認識ベンチマークは、人口統計学的属性にあまり注意を払わずに被験者の分布を想定しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-22">
        <br><font color="black">2020-04-22</font>
      </time>
    </span>
</section>
<!-- paper0: Channel Attention Networks for Robust MR Fingerprinting Matching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_43.html">
      <font color="black">Channel Attention Networks for Robust MR Fingerprinting Matching</font>
    </a>
  </h2>
  <font color="black">磁気共鳴フィンガープリント（MRF）により、T1およびT2緩和時間などの複数の組織パラメーターの同時マッピングが可能になります。この論文では、チャネルごとの注意モジュールと完全なアテンションモジュールで構成される新しいニューラルネットワークアーキテクチャを提案することにより、これらの欠点の両方に対処しました。畳み込みネットワーク..MRFはより高速なスキャンを提供しますが、対応するパラメトリックマップの誤った生成や生成が遅いなどの欠点があり、改善が必要です。 
[ABSTRACT] mrfは、さまざまなアクティベーションのデメリットのデメリットに依存しているため、スキャン中に各組織が独自の信号進化を生成します。提案されたmrfのアプローチにより、緩和時間がt1で8.88％、t2で75. 44％短縮されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Generating Descriptions for Sequential Images with Local-Object
  Attention and Global Semantic Context Modelling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_44.html">
      <font color="black">Generating Descriptions for Sequential Images with Local-Object
  Attention and Global Semantic Context Modelling</font>
    </a>
  </h2>
  <font color="black">並列LSTMネットワークを利用して、シーケンスの説明をデコードします。実験結果は、Microsoftが公開したデータセットの3つの異なる評価指標で、モデルがベースラインを上回っていることを示しています。一貫性のある説明を生成するために、マルチレイヤーを使用してグローバルセマンティックコンテキストをキャプチャします。連続画像間の依存関係を学習するパーセプトロン。 
[ABSTRACT]一貫性のある記述を生成するために、多層パーセプトロンを使用してグローバルなセマンティックコンテキストをキャプチャします。パーセプトロンは視覚画像間の依存関係を学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Suppressing Spoof-irrelevant Factors for Domain-agnostic Face
  Anti-spoofing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_45.html">
      <font color="black">Suppressing Spoof-irrelevant Factors for Domain-agnostic Face
  Anti-spoofing</font>
    </a>
  </h2>
  <font color="black">第2の敵対的学習スキームでは、各識別ヘッドも敵対的に訓練されてなりすまし要因を抑制し、二次なりすまし分類器とエンコーダーのグループは、抑制を克服することによってなりすまし要因を強化することを目的としています。 4つの公開ベンチマークデータセットで、優れた評価結果を達成します。結果は、提案された方法の有効性を示しています。 
[概要]パロディを効果的に抑制する二重学習学習学習と呼ばれる新しい方法を提案します-無関係な要因（sifs）。新しい方法は4つの公開ベンチマークデータセットに基づいており、優れた評価結果を達成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: FairFaceGAN: Fairness-aware Facial Image-to-Image Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_46.html">
      <font color="black">FairFaceGAN: Fairness-aware Facial Image-to-Image Translation</font>
    </a>
  </h2>
  <font color="black">さらに、新しい公平性メトリック、つまりFrechet Protected Attribute Distance（FPAD）を提案します。これは、保護された属性がどの程度保持されているかを測定します。このペーパーでは、公平性を意識した顔の画像間変換モデルであるFairFaceGANを紹介します。顔属性編集中の保護された属性（性別、年齢、人種など）での不要な翻訳の問題。さらに、FairFaceGANが既存の方法と比較して競争力のある結果を示す画像翻訳パフォーマンスも評価します。 
[ABSTRACT] fairfaceganは、2つの別個の潜在性を持つ公正な表現を学習できます。1つは翻訳するターゲット属性に関連し、もう1つはそれらに関連しません。fairfaceganモデルは、ターゲットサブジェクトの編集中に保護された属性の不要な翻訳も防止します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Wide-Area Crowd Counting: Multi-View Fusion Networks for Counting in
  Large Scenes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_47.html">
      <font color="black">Wide-Area Crowd Counting: Multi-View Fusion Networks for Counting in
  Large Scenes</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、他のマルチビューカウントベースラインと比較して最先端の結果を達成します。3つのマルチビューカウントデータセット、PETS2009、DukeMTMC、および新しく収集されたマルチビューカウントデータセットで3つの融合モデルをテストします。混雑した通りの交差点..この論文では、マルチビュー群集カウントのためのディープニューラルネットワークフレームワークを提案します。これは、複数のカメラビューからの情報を融合して、3D世界の地表面上のシーンレベルの密度マップを予測します。 
[概要]マルチビューカウントでは、複数のカメラビューを組み合わせて、3Dワールドのシーン（地上のレベル密度マップ）を予測します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchical Multi-task Deep Neural Network Architecture for End-to-End
  Driving -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_48.html">
      <font color="black">Hierarchical Multi-task Deep Neural Network Architecture for End-to-End
  Driving</font>
    </a>
  </h2>
  <font color="black">モデルのこの後者の側面が、現在の車両ステアリング戦略を超えて多くのアプリケーションにとって魅力的なアプローチになっています。このモジュラーネットワーク戦略を使用すると、2つの主な利点が得られます。完全なトレーニングに必要なデータ量の全体的な削減。システム、およびより複雑なモデルをより困難なタスクに使用でき、簡素化されたネットワークがより平凡なタスクを処理できるモデル調整用。これらの従属ネットワークは、特定の運転タスク（直進、旋回操作、タイトターン、段階的ターン）用に設計およびトレーニングされています。 、およびchicane。 
[ABSTRACT]モデルは、入力ステレオ画像から必要な運転戦略を決定するマスター分類器ネットワークを使用します。これは、証言を実行してステアリングコマンドを出力する一連の従属ネットワークモデルの1つに画像を送信します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-02-09">
        <br><font color="black">2019-02-09</font>
      </time>
    </span>
</section>
<!-- paper0: Viral Pneumonia Screening on Chest X-ray Images Using Confidence-Aware
  Anomaly Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_49.html">
      <font color="black">Viral Pneumonia Screening on Chest X-ray Images Using Confidence-Aware
  Anomaly Detection</font>
    </a>
  </h2>
  <font color="black">この論文では、ウイルス性肺炎を非ウイルス性肺炎および健康な対照から1つのクラスの分類ベースの異常検出問題に区別するタスクを定式化し、信頼性を意識した異常検出（CAAD）モデルを提案します。共有特徴抽出、異常検出モジュール、および信頼性予測モジュール。提案されたモデルは、5,977のウイルス性肺炎（COVID-19なし）の症例、18,619の非ウイルス性肺炎の症例を含む臨床X-VIRALデータセットのバイナリ分類モデルよりも優れています。異常検出モジュールによって生成された異常スコアが十分に大きい場合、または信頼性予測モジュールによって推定された信頼スコアが十分に小さい場合、入力を異常ケース（ウイルス性肺炎）として受け入れます。 
[概要]胸部X線を使用したウイルス性肺炎の迅速かつ正確な検出は、大規模なスクリーニングとエピデミック予防に非常に役立ちます。多様なデータセットシフトが分類アプローチのパフォーマンスを制御します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-27">
        <br><font color="black">2020-03-27</font>
      </time>
    </span>
</section>
<!-- paper0: Real-time object detection method based on improved YOLOv4-tiny -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_50.html">
      <font color="black">Real-time object detection method based on improved YOLOv4-tiny</font>
    </a>
  </h2>
  <font color="black">最終的には、補助ネットワークとバックボーンネットワークを統合して、改良されたYOLOv4-tinyのネットワーク構造全体を構築します。オブジェクト検出のリアルタイム性を向上させるために、YOLOv4-tinyに基づく高速オブジェクト検出方法を提案します。リアルタイムのオブジェクト検出に適しています。 
[概要]提案されたシステムは、yolov4よりも高速なオブジェクト検出を備えています-小さく、平均精度の平均値はほぼ同じです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Explainable-by-design Semi-Supervised Representation Learning for
  COVID-19 Diagnosis from CT Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_51.html">
      <font color="black">Explainable-by-design Semi-Supervised Representation Learning for
  COVID-19 Diagnosis from CT Imaging</font>
    </a>
  </h2>
  <font color="black">説明可能な分類結果により、提案された診断システムはCOVID-19分類に非常に効果的です。定性的および定量的に得られた有望な結果に基づいて、大規模な臨床研究における当社の開発した技術の幅広い展開を想定しています。 https://git.etrovub.be/AVSP/ct-based-covid-19-diagnostic-tool.git ..私たちのやる気を起こさせるアプリケーションは現実世界の問題です：CTイメージングからのCOVID-19分類。変分オートエンコーダーを使用して効率的な特徴の埋め込みを抽出する、半監視分類パイプラインに基づく説明可能なディープラーニングアプローチ。 
[ABSTRACT]コードはwwwで入手できます。ギット。 etrovub。 etrovub。 be / avsp / avsp。 avsp / avsp.itは、エンコーダーレイヤー内のクラスラベルを統合し、共有アテンションレイヤーでサイド情報を使用する特定のアーキテクチャを備えた新しい条件付き変分オートエンコーダー（cvae）のct画像に使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-23">
        <br><font color="black">2020-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Applying Deep-Learning-Based Computer Vision to Wireless Communications:
  Methodologies, Opportunities, and Challenges -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_52.html">
      <font color="black">Applying Deep-Learning-Based Computer Vision to Wireless Communications:
  Methodologies, Opportunities, and Challenges</font>
    </a>
  </h2>
  <font color="black">DLベースのCVをワイヤレス通信に適用する方法を説明するために、ミリ波（mmWave）システムでDLベースのCVを使用して、最適なミリ波多入力多出力（MIMO）ビームフォーミングを実現する例を示します。モバイルシナリオ..ただし、これまでのところ、このような作業は文献ではまれです。実験結果は、フレームワークがベースライン方式よりもはるかに高い精度を達成し、視覚データがMIMOビームフォーミングシステムのパフォーマンスを大幅に向上できることを示しています。 
[概要]この記事の主な目的は、無線通信で使用されているdlの適用に関するアイデアを紹介することです。resnetを使用して既存のシステムから将来のビームオブジェクトを予測することができます。3-実際の出力。この方法を使用して開発できます。たとえば新しいシステム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-10">
        <br><font color="black">2020-06-10</font>
      </time>
    </span>
</section>
<!-- paper0: MAAD-Face: A Massively Annotated Attribute Dataset for Face Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_53.html">
      <font color="black">MAAD-Face: A Massively Annotated Attribute Dataset for Face Images</font>
    </a>
  </h2>
  <font color="black">その結果、CelebAおよびLFWの15倍および137倍の属性ラベルを提供します。MAADFaceはVGGFace2データベース上に構築されているため、9k人を超える個人の330万人の顔で構成されています。MAAD-Face注釈データセットは公開されています。 
[ABSTRACT] maadfaceは、多数の高品質属性を特徴とする新しい顔注釈データベースです。これは、47の異なるバイナリ属性の123.9m属性注釈で構成されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Artist, Style And Year Classification Using Face Recognition And
  Clustering With Convolutional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_54.html">
      <font color="black">Artist, Style And Year Classification Using Face Recognition And
  Clustering With Convolutional Neural Networks</font>
    </a>
  </h2>
  <font color="black">クラスターはさらに分析され、パフォーマンスメトリックが計算されます。この調査では、アーティスト、年、スタイルが58.8、63.7、および81.3パーセントの精度でクラスター化され、クラスターの平均純度が63.1であるため、有望な結果が示されています。 72.4、および85.9パーセント..生成されたクラスターは、絵画のファイル名によって分析され、クラスターは、多数派のアーティスト、年の範囲、およびスタイルによって名前が付けられます。 
[ABSTRACT]アーティスト、年、スタイルは、絵画のファイル名によって分析されます。それらは、多数派の画像、年の範囲、およびスタイルによって名前が付けられます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Two-Stage Single Image Reflection Removal with Reflection-Aware Guidance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_55.html">
      <font color="black">Two-Stage Single Image Reflection Removal with Reflection-Aware Guidance</font>
    </a>
  </h2>
  <font color="black">5つの一般的に使用されるデータセットでの実験は、最先端のSIRRメソッドと比較したRAGNetの定量的および定性的な優位性を示しています。推定された反射と観測からの特徴マップを組み込むことにより、RAGは（i）軽減するために使用できます。観測からの反射の影響、および（ii）線形結合仮説からの逸脱の影響を軽減するために部分畳み込みでマスクを生成する。反射除去を改善するために、カスケードディープモデルが通常採用され、漸進的に透過を推定している。 。 
[概要]新しいシステムを使用して問題を段階的に予測しましたが、通常、多くのモデルを使用して問題を推定しました。この情報を使用して、推定された反射を活用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: PlueckerNet: Learn to Register 3D Line Reconstructions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_56.html">
      <font color="black">PlueckerNet: Learn to Register 3D Line Reconstructions</font>
    </a>
  </h2>
  <font color="black">屋内と屋外の両方のデータセットでの実験は、私たちの方法の登録（回転と平行移動）の精度がベースラインを大幅に上回っていることを示しています。 ）ベースのネットワークは、入力としてラインのPluecker表現を取り、識別可能なラインごとの特徴と一致可能性（各ラインが一致する可能性）を抽出します。（ii）最適なトランスポート（OT）レイヤーはラインごとに2つのビューを取ります2D結合確率行列を推定するための入力としての特徴と一致可能性。各項目はラインペアの一致を記述し、（iii）Top-K一致確率を持つラインペアは、RANSACフレームワークの2行最小ソルバーに供給されます。 6自由度（6-DoF）の剛体変換を推定します。対応とrを同時に解く必要があるため、ユークリッド空間で2つの部分的にオーバーラップした3Dライン再構成を整列させることは困難です。ライン再構成間の相対的なポーズ。 
[概要]この論文では、ニューラルネットワークベースの方法を提案します。3つのモジュールが順番に接続されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Joint Learning of Generative Translator and Classifier for Visually
  Similar Classes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_57.html">
      <font color="black">Joint Learning of Generative Translator and Classifier for Visually
  Similar Classes</font>
    </a>
  </h2>
  <font color="black">私たちのアーキテクチャが完全なデータセットでトレーニングされると、軽量アーキテクチャを使用しているにもかかわらず、最先端の方法で同等のパフォーマンスを達成します。翻訳ネットワークは、クラス間でオンラインデータ拡張を実行するために使用されますが、以前の作業は主にドメインの適応に関係しています。さまざまな設定で提案されたメソッドのパフォーマンスを実証するために、複数のデータセットで実験を実行します。 
[ABSTRACT]データセットの40％でトレーニングすることで、モデルが完全なデータセットでトレーニングされたベースラインのパフォーマンスを超えることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-15">
        <br><font color="black">2019-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Universal Shape Dictionary for Realtime Instance Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_58.html">
      <font color="black">Learning Universal Shape Dictionary for Realtime Instance Segmentation</font>
    </a>
  </h2>
  <font color="black">まず、形状データセットの大規模なコレクションから辞書を学習し、辞書を介して任意の形状を線形結合に分解できるようにします。そのため、「UniversalShapeDictionary」という名前が付けられました。提案されたUSD-Segは線形モデルを採用しています。 、オブジェクト形状の辞書を使用したスパースコーディング。 
[ABSTRACT]現在のインスタンスセグメンテーションシステムは、線形モデルと明示的モデルの2つのカテゴリに分類できます。これらは、オブジェクトの形状をモデル化する方法に基づいています。ただし、明示的な方法についてはあまり検討されていません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: A Self-Supervised Feature Map Augmentation (FMA) Loss and Combined
  Augmentations Finetuning to Efficiently Improve the Robustness of CNNs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_59.html">
      <font color="black">A Self-Supervised Feature Map Augmentation (FMA) Loss and Combined
  Augmentations Finetuning to Efficiently Improve the Robustness of CNNs</font>
    </a>
  </h2>
  <font color="black">CAを使用すると、歪んだ画像を使用する画像分類タスクで、ImageNetのST絶対値で8.27％、CIFAR-10で平均8.94％、ST絶対値で8.86％、FMAで8.04％、ST絶対値で8.27％の精度向上を達成します。クリーンなベースラインパフォーマンスを維持しながら、よく知られているデータ拡張方法でそれぞれ1.98％と2.12％.. CA戦略を使用して、安定性トレーニング（ST）と呼ばれる既存の最先端の方法を改善します。ニューラルネットワークは、入力の意味的に無関係な変更に対して堅牢ではないことがよくあります。 
[ABSTRACT]深い畳み込みニューラルネットワーク（cnns）には、特徴と呼ばれる新しい正則化損失があります-マップ拡張（fma）損失。これは、微調整中に使用して、入力のいくつかの歪みに対してモデルを堅牢にすることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: A Temporally Consistent Image-based Sun Tracking Algorithm for Solar
  Energy Forecasting Applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_60.html">
      <font color="black">A Temporally Consistent Image-based Sun Tracking Algorithm for Solar
  Energy Forecasting Applications</font>
    </a>
  </h2>
  <font color="black">これらの制限に対処するために、この研究では、画像ベースの太陽追跡アルゴリズムを導入して、太陽が見えるときに画像内の太陽を特定し、過去の観測から毎日の軌道を補間します。実験結果は、提案された方法が堅牢で滑らかな太陽軌道を提供することを示しています。画像サイズの1％未満の平均絶対誤差..エネルギーミックスにおける太陽のシェアをさらに増やすには、放射予測を改善することが重要です。 
[概要]太陽追跡法は雲の変位をキャプチャするために使用されます。太陽追跡法は既存の太陽追跡技術を使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Depth Completion Using Learned Bases -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_61.html">
      <font color="black">Efficient Depth Completion Using Learned Bases</font>
    </a>
  </h2>
  <font color="black">私たちのカラーガイドPCA深度補完法は閉形式の解を持っているため、効率的に解くことができ、PCAのみの方法よりもはるかに正確です。この問題に対処するために、別の正則化項としてカラーガイド自己回帰モデルを追加します。 。深度フィールドの主成分は、自然深度マップから学習できます。 
[概要]密な深度マップは、フル解像度の主深度ベースの加重和で近づけることができます。これらは、加重プロセスを制約するためのデータ項として機能します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Attentive WaveBlock: Complementarity-enhanced Mutual Networks for
  Unsupervised Domain Adaptation in Person Re-identification and Beyond -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_62.html">
      <font color="black">Attentive WaveBlock: Complementarity-enhanced Mutual Networks for
  Unsupervised Domain Adaptation in Person Re-identification and Beyond</font>
    </a>
  </h2>
  <font color="black">ただし、2つのニューラルネットワークが徐々に収束するにつれて、それらの相補性は弱まり、同じ種類のノイズに偏る可能性があります。具体的には、最初にパラメータのないモジュールであるWaveBlockを導入します。これにより、2つの学習した特徴の間に違いが生まれます。特徴マップのブロックを異なる方法で振ることによるネットワーク..さらに、2種類の組み合わせ戦略、すなわち
[ABSTRACT]注意深いウェーブブロック（awb）を相互学習のデュアルネットワークに統合して、相補性を高め、疑似のノイズをさらに抑えることができます。ラベル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br><font color="black">2020-06-11</font>
      </time>
    </span>
</section>
<!-- paper0: CPF: Learning a Contact Potential Field to Model the Hand-object
  Interaction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_63.html">
      <font color="black">CPF: Learning a Contact Potential Field to Model the Hand-object
  Interaction</font>
    </a>
  </h2>
  <font color="black">CPFを回復するために、MIHOという名前の学習フィッティングハイブリッドフレームワークも提案します。この論文では、各手と物体の接触をばね-質量システムとしてモデル化する明示的な接触表現である接触ポテンシャル場（CPF）を提示します。 、以前の作品は通常、HOポーズを共同で推定することに焦点を当てていますが、把握する際に保持される物理的接触を完全には調査していません。 
[概要]この論文では、明示的な接触表現、各手をモデル化する接触ポテンシャル場（cpf）-物体接触をばね-質量システムとして提示します。また、mihoと呼ばれる学習適合ハイブリッドフレームワークを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Patch-wise Attack for Fooling Deep Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_64.html">
      <font color="black">Patch-wise Attack for Fooling Deep Neural Network</font>
    </a>
  </h2>
  <font color="black">これに動機付けられて、パッチごとの反復アルゴリズムを提案します。これは、ピクセル単位のノイズを操作する既存の攻撃方法とは異なる、通常トレーニングされた主流の防御モデルに対するブラックボックス攻撃です。具体的には、増幅係数を導入します。各反復のステップサイズ、および$ \ epsilon $制約をオーバーフローする1ピクセルの全体的な勾配は、プロジェクトカーネルによって周囲の領域に適切に割り当てられます。クリーンな画像に人間が知覚できないノイズを追加することにより、結果として生じる敵対的な例は他の未知のものをだますことができます。モデル。 
[概要]私たちのツールは、一般的に任意の勾配ベースのフロー攻撃に統合できます。また、ホワイトボックス攻撃の敵対的なバージョンを作成するために使用することもできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-14">
        <br><font color="black">2020-07-14</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Imperceptible Adversarial Image Patches Based on Network
  Explanations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_65.html">
      <font color="black">Towards Imperceptible Adversarial Image Patches Based on Network
  Explanations</font>
    </a>
  </h2>
  <font color="black">このソフトマスクに基づいて、CFRの最適な摂動を検索するために、逆温度を使用した新しい目的関数を開発します。したがって、摂動は冗長性があり、人間の目で簡単に検出できます。領域の摂動。 
[概要]主なアイデアは、摂動のネットワーク説明に基づいて、画像の寄与特徴領域を見つけることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Deep learning for photoacoustic imaging: a survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_66.html">
      <font color="black">Deep learning for photoacoustic imaging: a survey</font>
    </a>
  </h2>
  <font color="black">このレビューでは、光音響イメージングの深層学習に特に焦点を当てて、機械学習を医用画像分析に適用する際のいくつかの新しい開発と課題の概要を説明しました。画像分析から自然言語処理に至るまで、魔法であり、今では最先端の機械学習モデルになります。このレビューの目的は3つあります。（i）いくつかの重要な基本を備えた深層学習の導入、（ii）生態系全体に深層学習を適用する最近の作品のレビュー画像再構成から疾患診断までの光音響イメージングのチェーン。（iii）深層学習を光音響イメージングに適用することに関心のある研究者に、いくつかのオープンソース資料やその他のリソースを提供します。 
[概要]深い人工ニューラルネットワークは、最先端の機械学習モデルになりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: Sparse Convolutions on Continuous Domains for Point Cloud and Event
  Stream Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_67.html">
      <font color="black">Sparse Convolutions on Continuous Domains for Point Cloud and Event
  Stream Networks</font>
    </a>
  </h2>
  <font color="black">また、オペレーターをイベントストリーム処理に適用し、数十万のイベントのストリームを使用して複数のタスクで最先端の結果を実現します。画像の畳み込みは、コンピュータービジョンにおける多数のディープラーニングの進歩の基礎となっています。 。これらの場合の畳み込み演算子のエレガントなスパース行列ベースの解釈を提示します。これは、畳み込みの数学的定義と一致し、トレーニング中に効率的です。 
[概要]研究コミュニティは、ユニバーサルデータのシステムについてまだ合意していません。それは、点群やイベントストリームなどのデータの分析に基づいている可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: MEVA: A Large-Scale Multiview, Multimodal Video Dataset for Activity
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_68.html">
      <font color="black">MEVA: A Large-Scale Multiview, Multimodal Video Dataset for Activity
  Detection</font>
    </a>
  </h2>
  <font color="black">私たちのコレクションでは、アクセス制御された会場で3週間にわたってスクリプトシナリオと自発的なバックグラウンドアクティビティを実行する約100人の俳優を観察し、屋内と屋外の視点が重複および非重複する複数のモダリティで収集しました。37のアクティビティに対して144時間の注釈を付けました。タイプ、俳優と小道具の境界ボックスをマークします。データはIRBの監視と承認を得て収集され、CC-BY-4.0ライセンスの下でリリースされました。 
[概要] 37のアクティビティタイプについて144時間の注釈を付けました。これらには、38 rgbおよびサーマルirカメラからのビデオ、42時間のuav映像、および俳優のgpsロケーションが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: SemiNLL: A Framework of Noisy-Label Learning by Semi-Supervised Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_69.html">
      <font color="black">SemiNLL: A Framework of Noisy-Label Learning by Semi-Supervised Learning</font>
    </a>
  </h2>
  <font color="black">私たちのフレームワークは、さまざまなSS戦略とSSLバックボーンを吸収し、その力を利用して有望なパフォーマンスを実現できます。直感的には、より強力なSS戦略とSSLモデルを採用すると、パフォーマンスが向上する可能性があります。この問題を防ぐために、汎用性の高いフレームワークであるSemiNLLを提案します。 SS戦略とSSLモデルをエンドツーエンドで組み合わせます。 
[概要]新しい方法では、ss戦略とsslモデルのさまざまな組み合わせを使用します。これらには、さまざまな半教師あり学習（ssl）ベンチが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Rethinking Object Detection in Retail Stores -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_70.html">
      <font color="black">Rethinking Object Detection in Retail Stores</font>
    </a>
  </h2>
  <font color="black">この目的のために、小売店で豊富な注釈付きの大規模なオブジェクトのローカリゼーションとカウントのデータセットを収集します。これは、140のカテゴリに190万を超えるオブジェクトインスタンスを持つ50,394の画像で構成されています。さらに、カスケードされたローカリゼーションとカウントのネットワークを強力なベースライン。オブジェクトのバウンディングボックスを徐々に分類および回帰し、バウンディングボックスで囲まれたインスタンスの予測数をエンドツーエンドでトレーニングします。オブジェクト検出の従来の標準では、バウンディングボックスを使用してそれぞれを表します。個々のオブジェクトインスタンス。 
[概要]そのようなタスク用に設計されたデータセットまたはベンチマークは存在しません。ただし、そのようなタスクのベンチマークは存在しません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br><font color="black">2020-03-18</font>
      </time>
    </span>
</section>
<!-- paper0: q-SNE: Visualizing Data using q-Gaussian Distributed Stochastic Neighbor
  Embedding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_71.html">
      <font color="black">q-SNE: Visualizing Data using q-Gaussian Distributed Stochastic Neighbor
  Embedding</font>
    </a>
  </h2>
  <font color="black">データセットMNIST、COIL-20を使用して、SNE、t-SNE、およびUMAPと比較した、埋め込み空間でのk最近傍（k-NN）分類器による2次元マッピングおよび分類の視覚化としてのq-SNEのパフォーマンスを示します。 、OlivettiFaces、FashionMNIST、Glove ..したがって、q-SNEはパラメータqを変更することでt-SNEとSNEを表現することもできます。これにより、パラメータqを選択することで最適な視覚化を見つけることができます。高次元データであるt-SNEは、低次元データの分布としてt分布を使用することにより、SNEよりも2次元または3次元マッピングでより強力で柔軟な視覚化を実現します。 
[概要] q-sneは、より強力で柔軟な視覚化につながります。これにより、単語qを選択することで最適な視覚化を見つけることができます。また、基準を変更することでk-sneとsneを表すこともできます。何が起こったのかを知る方法を見つけるために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Minimal Adversarial Examples for Deep Learning on 3D Point Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_72.html">
      <font color="black">Minimal Adversarial Examples for Deep Learning on 3D Point Clouds</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、例の知覚可能性を考慮し、ポイント操作の最小レベルを確保しながら、ポイントクラウドベースのネットワークの分類能力を攻撃することによって敵対的な例を生成します。実験結果は、私たちの方法が最先端のパフォーマンスを達成することを示しています合成データと実世界のデータに対する攻撃の成功率はそれぞれ89 \％と90 \％を超え、ポイント全体の約4 \％しか操作していません。この作業では、ポイントクラウドベースのニューラルネットワークに対する敵対的な攻撃を調査します。 。 
[概要]提案された方法は一般的であり、さまざまな攻撃戦略で実現できます。さまざまな攻撃で実現できます、電子メールショー</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware
  Image Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_73.html">
      <font color="black">pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware
  Image Synthesis</font>
    </a>
  </h2>
  <font color="black">生成的視覚モデルと神経レンダリングの最近の進歩を活用して、3D対応の画像合成が急速に進歩しているのを目の当たりにしました。PeriodicImplicitGenerativeAdversarial Networks（$ \ pi $ -GANまたはpi-GAN）という名前の新しい生成モデルを提案します。高品質の3D対応の画像合成のために.. $ \ pi $ -GANは、定期的なアクティブ化機能とボリュームレンダリングを備えたニューラル表現を活用して、シーンを詳細なビュー整合性のある3D表現として表現します。 
[概要]新しいアプローチは3Dでは不十分です。基礎となる3D表現が不足しているか、ビューに依存している可能性があります-一貫性のないレンダリング。表現力が十分でない表現ネットワークアーキテクチャに依存していることがよくあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Addressing Artificial Intelligence Bias in Retinal Disease Diagnostics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_74.html">
      <font color="black">Addressing Artificial Intelligence Bias in Retinal Disease Diagnostics</font>
    </a>
  </h2>
  <font color="black">調査結果は、データの不均衡とドメインの一般化がサブポピュレーション間の精度の不一致につながる可能性があることを示し、合成眼底画像の新しい生成方法がAIのバイアスを取り除く役割を果たす可能性があることを示しています。従来の/ベースライン診断DLSを使用する新しいDLSと比較しましたバイアス除去のための生成モデルを介して拡張されたトレーニングデータ..パブリックドメインのKaggle-EyePACSデータセット（88,692眼底および44,346個体、元々は民族性が多様）は、臨床医が注釈を付けたラベルを追加し、データの不均衡とドメインの一般化の人工的なシナリオを作成することによって変更されました。紹介を保証するDRを伴う網膜の画像（DR参照可能）およびおそらく平均してブドウ膜メラノサイト内のメラニンの濃度が高く、網膜画像の色素沈着に寄与する暗い肌の個人からの網膜の画像のトレーニング（テストではない）例。 
[概要]パブリックドメインのkaggle-eyepacsデータセット（88、692 Fundiおよび44、346の個人、元々は民族性が異なる）は、臨床医の注釈付きラベルを追加し、データの不均衡とドメインの一般化の人工的なシナリオを構築することによって変更されました。サブポピュラ間で精度の不一致につながります。111,000t.5百万のtメールがaiの使用によって影響を受けています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br><font color="black">2020-04-28</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Classifiers as a Basis for Trustworthy Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_75.html">
      <font color="black">Generative Classifiers as a Basis for Trustworthy Image Classification</font>
    </a>
  </h2>
  <font color="black">事前トレーニング済みのResNetアーキテクチャが識別分類に対して行うのとほぼ同じ方法で、他の生成的分類タスクの開始点として機能することを期待して、トレーニング済みモデルをダウンロード用にリリースします。次に、信頼できる画像に対するGCの計り知れない可能性を示します。分類..すべての信頼性の問題が完全に解決されるわけではありませんが、GCはさらなるアルゴリズムと変更の非常に有望な基盤であることがわかります。 
[概要]信頼性は説明可能性と堅牢性の組み合わせとして理解されていますが、この点は主に単純なデータセットで実証されています。gcsは、さらなるアルゴリズムと変更の非常に有望な基盤です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-29">
        <br><font color="black">2020-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Anisotropic 3D Multi-Stream CNN for Accurate Prostate Segmentation from
  Multi-Planar MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_76.html">
      <font color="black">Anisotropic 3D Multi-Stream CNN for Accurate Prostate Segmentation from
  Multi-Planar MRI</font>
    </a>
  </h2>
  <font color="black">したがって、提案されたモデルは、前立腺癌の診断と治療の結果を改善する可能性があります。前立腺の正確な境界の知識は、リスク構造の保存に不可欠です。結果：複数のサイトにまたがる2つのデータセットでのトレーニングと評価により、単純な軸方向セグメンテーションに対する統計的に有意な改善（ダイス類似性係数で$ p &lt;0.05 $）。 
[要約] cnnのセグメンテーションアプローチの大部分は、mrスキャンのエスクワイアのみを考慮しています。彼は、特にベースで進捗状況を観察できると述べています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-23">
        <br><font color="black">2020-09-23</font>
      </time>
    </span>
</section>
<!-- paper0: TinaFace: Strong but Simple Baseline for Face Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_77.html">
      <font color="black">TinaFace: Strong but Simple Baseline for Face Detection</font>
    </a>
  </h2>
  <font color="black">ResNet-50 \ cite {he2016deep}をバックボーンとして使用し、TinaFaceのすべてのモジュールと手法は既存のモジュール上に構築され、簡単に実装でき、一般的なオブジェクト検出に基づいています。テスト時間拡張（TTA）を使用した後、TinaFaceは現在の最先端の方法で、92.4 \％APを達成しています。最も人気があり挑戦的な顔検出ベンチマークWIDER FACE \ cite {yang2016wider}のハードテストセットで、シングルモデルとシングルスケールのTinaFaceを使用92.1 \％の平均精度（AP）を達成します。これは、より大きなバックボーンを持つ最近の顔検出器のほとんどを上回っています。 
[概要] tinafaceという名前の顔検出を処理するための強力でシンプルなベースラインメソッドを提供します。ハードテストバックボーンを使用すると、tinafaceは92％の平均精度（ap）を達成します。これは、バックボーンが大きい最近の顔検出器のほとんどを上回っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-26">
        <br><font color="black">2020-11-26</font>
      </time>
    </span>
</section>
<!-- paper0: ReMP: Rectified Metric Propagation for Few-Shot Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_78.html">
      <font color="black">ReMP: Rectified Metric Propagation for Few-Shot Learning</font>
    </a>
  </h2>
  <font color="black">広範な実験は、提案されたReMPが効果的かつ効率的であり、さまざまな標準の数ショット学習データセットで最先端を上回っていることを示しています。少数ショット学習は、いくつかの例から一般化する機能を備えています。目標を変更すると、パフォーマンスが大幅に向上します。 
[ABSTRACT]メトリックデータの識別は、学習を成功させるために不可欠なコンポーネントです。トレーニングからテストまでメトリックの一貫性を維持するために、識別可能な特徴空間が学習されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Single-Shot Freestyle Dance Reenactment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_79.html">
      <font color="black">Single-Shot Freestyle Dance Reenactment</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、以前の方法よりも大幅に優れた視覚品質を取得し、実験と補足ビデオに示されているように、挑戦的なポーズでキャプチャされたさまざまな体型と外観をアニメーション化できます。ソースダンサーとターゲット間のモーション転送のタスク人は、ダンサーの動きに応じて対象者がポーズを変えるポーズ転送問題の特殊なケースです。このタスクを3つのステージに分割することで、リアルなフレームの新しいシーケンスを実現できます。自然な動きと外観。 【アブストラクト】本研究では、トレーニング中には見えない、任意のビデオシーケンスで単一の画像を蘇生させることができる新しい方法を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: LIFI: Towards Linguistically Informed Frame Interpolation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_80.html">
      <font color="black">LIFI: Towards Linguistically Informed Frame Interpolation</font>
    </a>
  </h2>
  <font color="black">この動機付けにより、音声ビデオの補間の問題を特に対象とした、言語情報に基づいた新しいメトリックのセットを提供します。また、音声理解のコンピュータービジョンビデオ生成モデルをテストするためのデータセットをいくつかリリースします。いくつかの深層学習ビデオ生成アルゴリズムを使用して、欠落しているフレームを生成します。 
[概要]音声理解のコンピュータービジョンビデオ生成モデルをテストするためのいくつかのデータセットもリリースします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-30">
        <br><font color="black">2020-10-30</font>
      </time>
    </span>
</section>
<!-- paper0: Spatiotemporal Contrastive Video Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_81.html">
      <font color="black">Spatiotemporal Contrastive Video Representation Learning</font>
    </a>
  </h2>
  <font color="black">具体的には、フレーム間の時間的一貫性を維持しながら、ビデオの各フレームに強力な空間的拡張を課す、時間的一貫性のある空間的拡張方法を提案します。Kinetics-600データセットでは、CVRLによって学習された表現でトレーニングされた線形分類器が70.4％を達成します。 3D-ResNet-50（R3D-50）バックボーンでトップ1の精度、同じ膨張したR3D-50を使用してImageNetの教師あり事前トレーニングを15.7％、SimCLRの教師なし事前トレーニングを18.8％上回っています。サンプリングも提案します。ビデオ内で離れているクリップに過度に不変性を強制することを回避するためのベースの時間的拡張方法。 
[要約]ビデオ表現は、2つの拡張表現が埋め込みスペースで一緒に引き寄せられ、異なるビデオからのクリップが押しのけられる対照的な損失を使用して学習されます。空間的および時間的手がかりを含むデータ拡張を慎重に設計します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-09">
        <br><font color="black">2020-08-09</font>
      </time>
    </span>
</section>
<!-- paper0: Global Table Extractor (GTE): A Framework for Joint Table Identification
  and Cell Structure Recognition Using Visual Context -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CV/paper_82.html">
      <font color="black">Global Table Extractor (GTE): A Framework for Joint Table Identification
  and Cell Structure Recognition Using Visual Context</font>
    </a>
  </h2>
  <font color="black">GTE-Tableを使用して、テーブルの自然なセル封じ込め制約に基づいて新しいペナルティを発明し、セル位置予測を利用してテーブルネットワークをトレーニングします。さらなる実験により、バニラRetinaNetと比較してセル構造認識が45％以上向上することが示されています。新しいドメイン外FinTabNetのオブジェクト検出モデル。GTE-Cellは、テーブルスタイルを活用する新しい階層セル検出ネットワークです。 
[概要]ビジョン-ジョイントテーブル検出とセル構造化結果のためのガイド付き体系的フレームワーク。これらは、任意のオブジェクト検出モデルの上に構築できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Toward Gender-Inclusive Coreference Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_0.html">
      <font color="black">Toward Gender-Inclusive Coreference Resolution</font>
    </a>
  </h2>
  <font color="black">英語のテキストで行われたこれらの研究を通じて、性別の複雑さを認識して構築することなく、多くの潜在的な害につながるシステムを構築することを確認します。人々のテキストによる言及を正しく解決するには、基本的にそれらの人々について推論する必要があります。このようなバイアスをよりよく理解するために、社会学と社会言語学からジェンダーの微妙な概念化を前景にし、群集注釈と既存の共参照解決システムのバイアスを調査するための2つの新しいデータセットを開発します。 
[概要]これらの研究は、私たちが多くの潜在的な危害につながるシステムを構築していることを証明しています。これらの研究は、性別の複雑さを認識して構築することなく、</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-30">
        <br><font color="black">2019-10-30</font>
      </time>
    </span>
</section>
<!-- paper0: A Computational Approach to Measuring the Semantic Divergence of
  Cognates -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_1.html">
      <font color="black">A Computational Approach to Measuring the Semantic Divergence of
  Cognates</font>
    </a>
  </h2>
  <font color="black">この言語に依存しない方法は、同族のペア間の意味的類似度を計算することにより、同族の発散の定量分析を容易にし、空似言葉を識別するための洞察を提供します。さらに、空似言葉を修正するための提案を出力できるアルゴリズムを提案します。言語学習や翻訳に非常に役立つツールになる可能性があります。2番目の貢献として、偽の友人を検出するための簡単な方法を定式化し、「ソフト偽の友人」と「ハード偽の友人」の概念を紹介します。空似言葉ペアの「虚偽」の程度の尺度。 
[概要]この方法は、複数の言語の同族セットの意味的類似性に基づいています。これは、任意の言語ペアに簡単に拡張でき、関連する言語には大きな単一言語コーパス、ペアには小さな二言語辞書のみが必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Developing Real-time Streaming Transformer Transducer for Speech
  Recognition on Large-scale Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_2.html">
      <font color="black">Developing Real-time Streaming Transformer Transducer for Speech
  Recognition on Large-scale Dataset</font>
    </a>
  </h2>
  <font color="black">ストリーミングシナリオでは、TTがハイブリッドモデル、RNNトランスデューサー（RNN-T）、およびストリーミング可能なTransformerアテンションベースのエンコーダーデコーダーモデルよりも優れていることを示します。Transformer-XLとチャンクワイズストリーミング処理のアイデアを組み合わせて、ストリーミング可能なTransformerTransducerモデル..最近、Transformerベースのエンドツーエンドモデルは、音声認識を含む多くの分野で大きな成功を収めています。 
[概要]トランスフォーマー-xlとチャンク-ワイズストリーミング処理のアイデアを組み合わせて、ストリーミング可能なトランスフォーマートランスデューサーモデルを作成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-22">
        <br><font color="black">2020-10-22</font>
      </time>
    </span>
</section>
<!-- paper0: Shapeshifter Networks: Decoupling Layers from Parameters for Scalable
  and Effective Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_3.html">
      <font color="black">Shapeshifter Networks: Decoupling Layers from Parameters for Scalable
  and Effective Deep Learning</font>
    </a>
  </h2>
  <font color="black">SSNでは、各レイヤーは、パラメーターをレイヤーに割り当てる場所と方法を決定するパラメーターストアから重みを取得します。画像分類、双方向の画像文の取得、フレーズの接地など、さまざまなタスクにわたって7つのネットワークアーキテクチャを使用してSSNを評価し、高性能を実現します。パラメータのわずか1％を使用する場合でも、モデル。SSNは、モデルの損失関数またはアーキテクチャを変更する必要がないため、使いやすくなっています。 
[概要]モデルの重みから分類を分離する柔軟なニューラルネットワークフレームワークであるシェイプシフターネットワーク（ssns）を紹介しました。これにより、任意の数のパラメーターを使用して任意のニューラルネットワークを実装できます。これにより、サイズが異なっていても設定を共有できます。または別の操作を実行します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br><font color="black">2020-06-18</font>
      </time>
    </span>
</section>
<!-- paper0: How Can We Know When Language Models Know? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_4.html">
      <font color="black">How Can We Know When Language Models Know?</font>
    </a>
  </h2>
  <font color="black">まず、最先端の生成QAモデルであるT5を調べ、その確率が適切に調整されているかどうかを調べます。答えは比較的重要ではありません。さまざまなデータセットでの実験により、この方法の有効性が実証されています。次に、そのようなモデルを調整して、微調整、事後確率の変更、または予測された出力または入力の調整を通じて、信頼スコアが正しさの可能性とよりよく相関するようにする方法を検討します。 
[要約]キャリブレーションの観点から行われた研究、確率モデルの予測確率の特性は、実際には正しさの確率とよく相関しています。次に、そのようなモデルをキャリブレーションして、信頼スコアとの相関を高める方法を検討します。正しさの可能性</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Supertagging the Long Tail with Tree-Structured Decoding of Complex
  Categories -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_5.html">
      <font color="black">Supertagging the Long Tail with Tree-Structured Decoding of Complex
  Categories</font>
    </a>
  </h2>
  <font color="black">私たちの最高のタガーは、ロングテールスーパータグのかなりの部分を回復することができ、トレーニングでは見られなかったCCGカテゴリを生成すると同時に、より少ないパラメータで全体的なタグ精度で以前の最先端技術に近づきます。ただし、スーパータグはそれ自体がツリーです。さらに、さまざまなアプローチがドメイン外の評価セットにどの程度一般化されるかを調査します。 
[概要]タグセットは伝統的に短縮され、ロングテールの多くのまれで複雑なカテゴリタイプを破棄します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Analyzing Stylistic Variation across Different Political Regimes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_6.html">
      <font color="black">Analyzing Stylistic Variation across Different Political Regimes</font>
    </a>
  </h2>
  <font color="black">また、スタイルレベルでの変化と比較するために、2つのエポック間のトピックの変化の分析を実行します。テキストに対してクラスタリングと分類の実験を実行することにより、これらのテキストのスタイルプロファイルを比較します。伝統的な著者の帰属方法と特徴..この記事では、時間的だけでなく、政治的および文化的に異なる2つの異なる期間にわたって書かれたテキストの文体分析を提案します：ルーマニアの共産主義と民主主義。 
[要約]分析は、2つの期間の間のスタイルの変化が統計的に有意であることを示しています。分析はまた、期間からのテキストが実際に区別できることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Extraction of Ranked SNP-Phenotype Associations from
  Literature through Detecting Neural Candidates, Negation and Modality Markers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_7.html">
      <font color="black">Automatic Extraction of Ranked SNP-Phenotype Associations from
  Literature through Detecting Neural Candidates, Negation and Modality Markers</font>
    </a>
  </h2>
  <font color="black">実験は、否定の手がかりと範囲、および中立的な候補の検出を使用して、文の固有の極性が均一であり、コーパス内の複雑な文の数が少ないため、カーネルベースの対応物よりも優れた関係抽出方法を実装できることを示しています。さらに、モダリティベースのアプローチは、報告された関連の信頼性を評価するために使用できる抽出された関連の信頼レベルを推定するために提案されます。キーワード：SNP、表現型、生物医学関係抽出、否定検出。 
[概要]突然変異を抽出するための最近のいくつかの方法が開発されました-疾患の関連性。現在、キーワードを抽出するためのいくつかの方法があります-疾患の関連性</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: DyERNIE: Dynamic Evolution of Riemannian Manifold Embeddings for
  Temporal Knowledge Graph Completion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_8.html">
      <font color="black">DyERNIE: Dynamic Evolution of Riemannian Manifold Embeddings for
  Temporal Knowledge Graph Completion</font>
    </a>
  </h2>
  <font color="black">製品多様体により、時間的KGのさまざまな幾何学的構造をより適切に反映するアプローチが可能になります。さらに、時間的KGの進化のダイナミクスをキャプチャするために、各タイムスタンプの接空間で定義された速度ベクトルに従ってエンティティ表現を進化させます。 。最近、時間の経過に伴うエンティティ間の動的な関係を記録する時間的知識グラフ（KG）の表現を学習することに関心が高まっています。 
[ABSTRACT] dy-ernie、非伝統的な埋め込みアプローチは、時間的kgの進化のダイナミクスをキャプチャします。埋め込みの進化をキャプチャするために、エンティティを砂利モデルに従って進化させます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-08">
        <br><font color="black">2020-11-08</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End QA on COVID-19: Domain Adaptation with Synthetic Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_9.html">
      <font color="black">End-to-End QA on COVID-19: Domain Adaptation with Synthetic Training</font>
    </a>
  </h2>
  <font color="black">さらに、ラベル付けされたデータがほとんどまたはまったくない場合、このようなターゲットドメインでは、QAシステムの効果的な適応も困難になる可能性があります。ニューラルIRシステムとMRCシステムを組み合わせて、最先端のオープンドメインQAベースラインを超えるCORD-19コレクションのエンドツーエンドQAの大幅な改善を示します。 
[概要]最近の作業では、オープンドメインデータセットからの監視付き質問応答（qa）の例のみを使用して、ニューラルirシステムのトレーニングに成功しています。ただし、このようなターゲットドメインでは、qaシステムの効果的な適応も困難な場合があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Fairness and Robustness in Invariant Learning: A Case Study in Toxicity
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_10.html">
      <font color="black">Fairness and Robustness in Invariant Learning: A Case Study in Toxicity
  Classification</font>
    </a>
  </h2>
  <font color="black">この作業が、ロバストな機械学習手法がアルゴリズムの公平性にどのように関連するかについてのさらなる研究を刺激することを願っています。ロバスト性は機械学習において中心的な重要性であり、パフォーマンスの向上に関係するドメイン一般化と不変学習の分野を生み出しました。トレーニング分布とは異なるが関連するテスト分布。インターネットコメントの毒性を公正に予測するタスクに、因果的発見に触発された方法を使用して堅牢な予測子を見つけるドメイン一般化アルゴリズムである不変リスク最小化（IRM）を適用します。 
[概要]ロバストmlのアルゴリズムを使用して、分類器の公平性を向上できるかどうかを調査します。irmがシナリオでより公平で効果的かつ効果的に使用することを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-12">
        <br><font color="black">2020-11-12</font>
      </time>
    </span>
</section>
<!-- paper0: Braid: Weaving Symbolic and Neural Knowledge into Coherent Logical
  Explanations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_11.html">
      <font color="black">Braid: Weaving Symbolic and Neural Knowledge into Coherent Logical
  Explanations</font>
    </a>
  </h2>
  <font color="black">童話の簡単なQAの例を使用して、Braid-BCの設計を動機付け、さまざまなコンポーネントがどのように連携して一貫した論理的説明を生成するかを説明します。従来のシンボリック推論エンジンは、精度と説明性に魅力的ですが、いくつかの大きな欠点があります。 ：論理用語の正確な一致（統一）、不確実性に対処できないこと、および事前にコンパイルされた知識のルールベースの必要性（「知識獲得」問題）に依存する脆弱な推論手順の使用。これらに対処するため。問題については、確率的ルールをサポートし、カスタム統合関数と動的ルール生成の概念を使用して、従来の推論者に蔓延している脆弱なマッチングと知識ギャップの問題を克服する、Braidと呼ばれる新しいFOLベースの推論を考案します。 
[概要]これらの問題は、自然言語理解タスクにとって特に深刻です。テキストについて理解し、推論するために暗黙の背景知識を使用することがよくあります。これらには、推論中の概念と関係のあいまいな配置に頼ることが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-26">
        <br><font color="black">2020-11-26</font>
      </time>
    </span>
</section>
<!-- paper0: Learning from others' mistakes: Avoiding dataset biases without modeling
  them -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_12.html">
      <font color="black">Learning from others' mistakes: Avoiding dataset biases without modeling
  them</font>
    </a>
  </h2>
  <font color="black">最先端の自然言語処理（NLP）モデルは、意図された基礎となるタスクを対象とする機能ではなく、データセットのバイアスと表面形状の相関関係をモデル化することを学習することがよくあります。バイアスモデルの対象となる特定のバイアスがない場合でも、分布設定。バイアスの問題が明示的に識別されない場合を考慮し、これらの問題のある相関を無視することを学習するモデルをトレーニングする方法を示します。 
[要約]以前の研究では、バイアスの知識が利用可能な場合に問題を回避するための効果的な方法が示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Generating Descriptions for Sequential Images with Local-Object
  Attention and Global Semantic Context Modelling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_13.html">
      <font color="black">Generating Descriptions for Sequential Images with Local-Object
  Attention and Global Semantic Context Modelling</font>
    </a>
  </h2>
  <font color="black">並列LSTMネットワークを利用して、シーケンスの説明をデコードします。実験結果は、Microsoftが公開したデータセットの3つの異なる評価指標で、モデルがベースラインを上回っていることを示しています。一貫性のある説明を生成するために、マルチレイヤーを使用してグローバルセマンティックコンテキストをキャプチャします。連続画像間の依存関係を学習するパーセプトロン。 
[ABSTRACT]一貫性のある記述を生成するために、多層パーセプトロンを使用してグローバルなセマンティックコンテキストをキャプチャします。パーセプトロンは視覚画像間の依存関係を学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Extracting COVID-19 Diagnoses and Symptoms From Clinical Text: A New
  Annotated Corpus and Neural Event Extraction Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_14.html">
      <font color="black">Extracting COVID-19 Diagnoses and Symptoms From Clinical Text: A New
  Annotated Corpus and Neural Event Extraction Framework</font>
    </a>
  </h2>
  <font color="black">二次利用アプリケーションでは、構造化された患者データを使用してCOVID-19テスト結果の予測を調査しました（たとえば、フリーテキストの臨床ノートには、これらの質問を解決するための重要な情報が含まれています。自動的に抽出された症状は、構造化データだけでなく、予測パフォーマンスを向上させます。 
[概要]コロナウイルスの追跡に関連する多くの未解決の質問があります。これらの質問には、感染の重症度の予測、および医療利用の予測が含まれます。これらには、データ駆動型の自動情報抽出モデルが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Annotating Social Determinants of Health Using Active Learning, and
  Characterizing Determinants Using Neural Event Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_15.html">
      <font color="black">Annotating Social Determinants of Health Using Active Learning, and
  Characterizing Determinants Using Neural Event Extraction</font>
    </a>
  </h2>
  <font color="black">より複雑なイベント抽出タスクのプロキシとして代理テキスト分類タスクを使用して注釈のサンプルを選択する新しいアクティブラーニングフレームワークを紹介します。この作業では、SDOH注釈付きの新しいコーパス、新しいアクティブラーニングフレームワーク、および最初の抽出を示します。新しいコーパスでの結果..アクティブラーニングフレームワークは、健康リスク要因の頻度を正常に増加させ、無向注釈よりもこれらのイベントの自動抽出を改善します。 
[概要]社会史注釈コーパス（shac）には、12 sdohの詳細な注釈が付いた4、480の社会史セクションが含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-11">
        <br><font color="black">2020-04-11</font>
      </time>
    </span>
</section>
<!-- paper0: Longformer: The Long-Document Transformer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_16.html">
      <font color="black">Longformer: The Long-Document Transformer</font>
    </a>
  </h2>
  <font color="black">事前にトレーニングされたLongformerは、長いドキュメントタスクで常にRoBERTaを上回り、WikiHopとTriviaQAで新しい最先端の結果を設定します。Transformerベースのモデルは、自己注意操作のために長いシーケンスを処理できません。シーケンスの長さ..ほとんどの以前の作業とは対照的に、Longformerを事前トレーニングし、さまざまなダウンストリームタスクで微調整します。 
[ABSTRACT]この制限に対処するために、シーケンスの長さに比例してスケーリングするアテンションメカニズムを備えたlongformerを導入し、ドキュメントの処理を容易にします。longformerを文字レベルの言語モデリングで評価し、状態を達成します。 text8とenwik8で1つの結果</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-10">
        <br><font color="black">2020-04-10</font>
      </time>
    </span>
</section>
<!-- paper0: Injecting Entity Types into Entity-Guided Text Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_17.html">
      <font color="black">Injecting Entity Types into Entity-Guided Text Generation</font>
    </a>
  </h2>
  <font color="black">最初に文脈上の単語またはエンティティであるというトークンを予測し、次にエンティティの場合はエンティティの言及を予測します。NLGでのエンティティの役割を強化するために、このペーパーでは、デコードでエンティティタイプをモデル化することを目的としています。コンテキストワードを正確に生成するフェーズ。生成品質は、入力エンティティが論理的に接続され、出力で表現されているかどうかに大きく依存します。 
[概要]エンティティの特定のリストに基づいてターゲットシーケンスを生成する新しいnlgモデルを開発します。モデルには、エンティティタイプをプロセスに挿入するマルチステップデコーダーがあります。エンティティの意味を非表示の状態に埋め込みます。生成された単語を正確にする</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-28">
        <br><font color="black">2020-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Automated Concatenation of Embeddings for Structured Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_18.html">
      <font color="black">Automated Concatenation of Embeddings for Structured Prediction</font>
    </a>
  </h2>
  <font color="black">具体的には、コントローラーは、タスクを考慮した個々の埋め込みタイプの有効性に関する現在の信念に従って、埋め込みの連結を交互にサンプリングし、報酬に基づいて信念を更新します。ただし、最良の連結を形成するための埋め込みの選択表現は通常、タスクと候補埋め込みのコレクションによって異なり、埋め込みタイプの数が増え続けると、問題はさらに難しくなります。強化学習の戦略に従って、コントローラーのパラメーターを最適化し、に基づいて報酬を計算します。サンプリングされた連結が入力として供給され、タスクデータセットでトレーニングされるタスクモデルの精度。 
[ABSTRACT]埋め込みは、ニューラルアーキテクチャ検索の最近の進歩に触発されたプレゼンテーションに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-10">
        <br><font color="black">2020-10-10</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Create Better Ads: Generation and Ranking Approaches for Ad
  Creative Refinement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_19.html">
      <font color="black">Learning to Create Better Ads: Generation and Ranking Approaches for Ad
  Creative Refinement</font>
    </a>
  </h2>
  <font color="black">特に、入力広告クリエイティブを前提として、（i）新しい広告テキストを生成する、（ii）新しい広告テキストのキーフレーズを推奨する、（iii）画像タグ（のオブジェクト）を推奨することにより、特定の広告テキストと画像を洗練するアプローチを研究します。画像）新しい広告画像を選択します。また、Yahoo Gemini広告プラットフォームのデータを使用した実験から、広く適用可能な洞察を共有します。このプロセスは手動で行われるため、学習、改良、展開に時間がかかります。変更されたクリエイティブ。 
[概要]広告主はオンラインのa / bテストを使用して効果的なクリエイティブを推測します。これらは、クリエイティブを学習するために反復的にさらに洗練されます。キーフレーズと画像タグの単語については、関連性の高いマッチングモデルの有効性を示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Interactive Teaching for Conversational AI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_20.html">
      <font color="black">Interactive Teaching for Conversational AI</font>
    </a>
  </h2>
  <font color="black">提案されたセットアップでは、3つのモデルを使用して、a）ライブの会話対話中に自動的に理解する際のギャップを特定し、b）ユーザーとのライブの対話からそのような未知の概念のそれぞれの解釈を学習し、c）インタラクティブな教育用に特別に調整された教室のサブダイアログを管理します。セッション..この方法が、より適応性のあるパーソナライズされた言語理解モデルを構築するための主要な方法で非常に有望であることを示します。事前にトレーニングされた上で微調整された、モデルの最先端のトランスベースのニューラルアーキテクチャを提案します。モデル、およびそれぞれのコンポーネントの精度の向上を示しています。 
[概要]新しい教育可能なaiシステムはconceptsと呼ばれる新しい言語ナゲットを学習できます。ライブインタラクティブティーチングセッションを使用して新しい言語ギャップを教えます。aiシステムはconceptsと呼ばれる新しい言語ナゲットを学習できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Biomedical Knowledge Graph Refinement with Embedding and Logic Rules -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_21.html">
      <font color="black">Biomedical Knowledge Graph Refinement with Embedding and Logic Rules</font>
    </a>
  </h2>
  <font color="black">COVID-19知識グラフでモデルを評価し、競争力のある結果を取得します。提案されたモデルでは、BioKGリファインメント問題がBioKGのトリプレットの確率推定として定式化されます。変分EMアルゴリズムを使用して知識グラフの埋め込みを最適化します。と論理ルール推論を交互に。 
[要約]提案されたモデルは、知識グラフの埋め込みと論理ルールの両方からの努力を組み合わせることができ、それらを単独で使用するよりも良い結果につながる</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Classification of Multimodal Hate Speech -- The Winning Solution of
  Hateful Memes Challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_22.html">
      <font color="black">Classification of Multimodal Hate Speech -- The Winning Solution of
  Hateful Memes Challenge</font>
    </a>
  </h2>
  <font color="black">これらのルールはトレーニングセットから抽出され、難しいサンプルの分類精度の向上に焦点を当てています。HatefulMemesは、マルチモーダルミームでのヘイトスピーチの検出に焦点を当てたマルチモーダル分類の新しいチャレンジセットです。Kielaによると、最先端の方法は、ヘイトフルミームで人間と比較してパフォーマンスが低くなります（64.73％対84.7％の精度）。 
[ABSTRACT]難しい例がデータセットに追加され、ユニモーダル信号に依存しにくくなりました。つまり、マルチモーダルモデルのみが成功する可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Bayesian multilingual topic model for zero-shot cross-lingual topic
  identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_23.html">
      <font color="black">Bayesian multilingual topic model for zero-shot cross-lingual topic
  identification</font>
    </a>
  </h2>
  <font color="black">それでも、不確実性を利用することは常に有益です。さらに、データ量がはるかに少ない単一のGPUで1日でトレーニングされたシステムは、93言語でトレーニングされた最先端のユニバーサルBiLSTMセンテンスエンコーダーと比較して競争力があります。 ..学習した不確実性を、ゼロショットのクロスリンガルトピック識別のための線形分類器を介して伝播します。 
[要約]提案されたモデルは、多言語の単語埋め込みおよびbilstmセンテンスエンコーダベースのシステムよりも優れており、転送方向の大部分でかなりのマージンがあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-02">
        <br><font color="black">2020-07-02</font>
      </time>
    </span>
</section>
<!-- paper0: Meta-KD: A Meta Knowledge Distillation Framework for Language Model
  Compression across Domains -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/cs.CL/paper_24.html">
      <font color="black">Meta-KD: A Meta Knowledge Distillation Framework for Language Model
  Compression across Domains</font>
    </a>
  </h2>
  <font color="black">この目的のために、メタ学習に触発されたドメイン間で転送可能な知識をキャプチャし、それを使用して学生に知識を渡すメタ教師モデルを構築するためのメタ知識蒸留（Meta-KD）フレームワークを提案します。ドメイン間で消化された移転可能な知識を持つ教師は、知識の蒸留を支援するためのより優れた一般化機能を実現できます。典型的なアプローチでは、知識の蒸留を検討して、大きな教師モデルを小さな学生モデルに蒸留します。 
[概要]これらの研究は、他のドメインからの移転可能な知識を無視する単一ドメインのみに焦点を当てています。メタ学習に触発されたドメイン間で移転可能な知識をキャプチャし、それを使用して学生に知識を渡すモデルを提案しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Developing Real-time Streaming Transformer Transducer for Speech
  Recognition on Large-scale Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.AS/paper_0.html">
      <font color="black">Developing Real-time Streaming Transformer Transducer for Speech
  Recognition on Large-scale Dataset</font>
    </a>
  </h2>
  <font color="black">ストリーミングシナリオでは、TTがハイブリッドモデル、RNNトランスデューサー（RNN-T）、およびストリーミング可能なTransformerアテンションベースのエンコーダーデコーダーモデルよりも優れていることを示します。この作業では、Transformer Transducer（TT）モデルの可能性を調査しました。大規模データセットでの低遅延と高速での最初のパスデコード。Transformer-XLのアイデアとチャンクワイズストリーミング処理を組み合わせて、ストリーミング可能なTransformerTransducerモデルを設計します。 
[概要]トランスフォーマー-xlとチャンク-ワイズストリーミング処理のアイデアを組み合わせて、ストリーミング可能なトランスフォーマートランスデューサーモデルを作成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-22">
        <br><font color="black">2020-10-22</font>
      </time>
    </span>
</section>
<!-- paper0: Sequence Generation using Deep Recurrent Networks and Embeddings: A
  study case in music -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.AS/paper_1.html">
      <font color="black">Sequence Generation using Deep Recurrent Networks and Embeddings: A
  study case in music</font>
    </a>
  </h2>
  <font color="black">特に、機械学習とリカレントニューラルネットワークなどの固有のメモリメカニズムを備えたニューラルネットワークの最近の進歩により、自然言語処理と自動音楽作曲が重要性を増しています。提案されたアーキテクチャのパフォーマンスを評価するために、一連の定量的メトリックが提示されます。自動的に、楽曲の音色を測定します。シーケンスの自動生成は、ここ数年で非常に探求されてきた分野です。 
[ABSTRACT]機械学習により自動音楽作曲の重要性が増しています。提案されたアプローチでは、移調などの音楽理論の概念が考慮されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Neural MOS Prediction for Synthesized Speech Using Multi-Task Learning
  With Spoofing Detection and Spoofing Type Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.AS/paper_2.html">
      <font color="black">Neural MOS Prediction for Synthesized Speech Using Multi-Task Learning
  With Spoofing Detection and Spoofing Type Classification</font>
    </a>
  </h2>
  <font color="black">いくつかの研究では、合成音声の平均オピニオン評点（MOS）を予測するための深層学習ベースのモデルが提案されており、人間の評価者を置き換える可能性が示されています。提案されたモデルは、ベースラインモデルよりもパフォーマンスが最大11.6％向上します。音声変換チャレンジ2018のMOS評価結果を使用した実験では、2つの補助タスクを備えた提案されたMTLがMOS予測を改善することが示されています。 
[概要]提案されたモスモデルは、パフォーマンスが向上する可能性があります。ただし、モスの評価者間および評価者内の変動により、モデルの高性能を確保することは困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Virufy: Global Applicability of Crowdsourced and Clinical Datasets for
  AI Detection of COVID-19 from Cough Audio Samples -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.AS/paper_3.html">
      <font color="black">Virufy: Global Applicability of Crowdsourced and Clinical Datasets for
  AI Detection of COVID-19 from Cough Audio Samples</font>
    </a>
  </h2>
  <font color="black">より多くのクラウドソーシングデータが収集されると、さまざまな呼吸オーディオサンプルを使用してさらなる開発を実装し、COVID-19検出用の咳分析ベースの機械学習（ML）ソリューションを作成できます。これは、臨床および非臨床の両方のすべての人口統計グループにグローバルに一般化できる可能性があります。臨床設定..さらに、私たちの方法は、ラテンアメリカからのクラウドソーシングされたサンプルと南アジアからの臨床サンプルに一般化できることを示しています。これらの地域からの特定のサンプルを使用してさらにトレーニングする必要はありません。COVID-19の迅速で手頃なテスト方法感染率を減らし、医療施設が圧倒されるのを防ぐには、感染が不可欠です。 
[概要]新しい方法は、さらなるトレーニングなしで、ラテンアメリカからのクラウドソーシングされたサンプルと南アジアからの臨床サンプルに一般化することができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-26">
        <br><font color="black">2020-11-26</font>
      </time>
    </span>
</section>
<!-- paper0: Deconstruct and Reconstruct Dizi Music of the Northern School and the
  Southern School -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.AS/paper_4.html">
      <font color="black">Deconstruct and Reconstruct Dizi Music of the Northern School and the
  Southern School</font>
    </a>
  </h2>
  <font color="black">再構成の例として、メロディ転送と演奏技術転送を含む音楽スタイル転送を行い、再構成結果を評価するために聴衆評価を行います。収集したDiziデータセットに基づいて、北部の学校とのDizi音楽スタイルの調査を行います。サザンスクール..特徴はメロディーを含み、2つの異なる音楽スタイルの演奏技術が分解されます。 
[ABSTRACT] diziデータセットは、この方法を使用して収集され、中国の音楽を収集します。データセットは、さまざまな手法に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-10">
        <br><font color="black">2020-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: How Far Are We from Robust Voice Conversion: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.AS/paper_5.html">
      <font color="black">How Far Are We from Robust Voice Conversion: A Survey</font>
    </a>
  </h2>
  <font color="black">すべてのVCモデルは目に見えないデータに悩まされていますが、AdaIN-VCは比較的堅牢です。また、共同でトレーニングされたスピーカー埋め込みは、スピーカー識別でトレーニングされたものよりも音声変換に適しています。音声変換テクノロジーは近年大幅に改善されています。ディープラーニングの助けを借りて、しかし、さまざまな条件で自然な響きの発話を生成するそれらの能力は不明なままです。 
[概要]論文では、既知のvcモデルの堅牢性について詳細に研究しました。共同でトレーニングされた埋め込みは、話者識別でトレーニングされたモデルよりも音声変換に適しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Speaker Recognition Based on Deep Learning: An Overview -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-03/eess.AS/paper_6.html">
      <font color="black">Speaker Recognition Based on Deep Learning: An Overview</font>
    </a>
  </h2>
  <font color="black">従来の方法に対する深層学習の主な利点は、発話から高度に抽象的な埋め込み特徴を生成できる表現能力であるため、入力、ネットワーク構造、時間など、深層学習ベースの話者特徴抽出に最初に細心の注意を払います。多くの話者認識サブタスクの基本コンポーネントであるプーリング戦略と目的関数。話者認識は、声から人を識別するタスクです。次に、最近の監視に重点を置いて、話者のダイアリゼーションの概要を説明します。エンドツーエンドのオンラインダイアリゼーション。 
[概要]話者認識のいくつかの主要なサブタスクを確認します。それらには、サブタスクのサブタスクに基づくディープラーニングが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
