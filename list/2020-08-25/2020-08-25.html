<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-08-25の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: CRNNs for Urban Sound Tagging with spatiotemporal context -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.SD/paper_0.html">
      <font color="black">CRNNs for Urban Sound Tagging with spatiotemporal context</font>
    </a>
  </h2>
  <font color="black">このコードは、https：//github.com/multitel-ai/urban-sound-tagging。のGitHubリポジトリで利用できます。このペーパーでは、DCASE 2020チャレンジのタスク5に参加するために使用したCRNNについて説明します。このタスクは、時空間コンテキストを使用した階層的マルチラベルアーバンサウンドタギング。 
[ABSTRACT]このタスクは、マルチラベルのアーバンサウンドタギングの再構築に焦点を当てています。このタスクは、このタスクを使用して問題を理解することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: AMRConvNet: AMR-Coded Speech Enhancement Using Convolutional Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.SD/paper_1.html">
      <font color="black">AMRConvNet: AMR-Coded Speech Enhancement Using Convolutional Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">AMRConvNetの平均改善点は、平均オピニオンスコア0.425-AMRビットレートが4.75kのリスニング品質目標（MOS-LQO）ポイント、およびAMRビットレートが12.2kの0.073 MOS-LQOポイントです。AMRConvNetは、AMRビットレート入力の堅牢性も示しました。 ..モデルは、入力音声と出力音声の両方の時間領域で直接動作しますが、時間領域の再構成損失と周波数領域の知覚損失を組み合わせて最適化します。 
[ABSTRACT] amrconvnetは、amr.itでエンコードされた音声に対して阿部と音声強調を実行する畳み込みニューラルネットワークで、平均0の改善をもたらしました。 425平均オピニオンスコア-4.75kのamrビットレートのリスニング品質目標（mos-lqo）ポイント、およびamrの0.al-拡張ネットワーク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Similarity-and-Independence-Aware Beamformer: Method for Target Source
  Extraction using Magnitude Spectrogram as Reference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.SD/paper_2.html">
      <font color="black">Similarity-and-Independence-Aware Beamformer: Method for Target Source
  Extraction using Magnitude Spectrogram as Reference</font>
    </a>
  </h2>
  <font color="black">インデックス用語：セミブラインドソース分離、類似性と独立性を意識したビームフォーマー、デフレ独立コンポーネント分析、ソースモデル。抽出では、参照と抽出されたターゲット間の類似性、およびすべての潜在的なソースの相互独立性を考慮することにより、デフレ独立コンポーネント分析のフレームワークを拡張します。この研究では、ソース抽出の新しい方法を紹介します。類似性と独立性を意識したビームフォーマー（SIBF）として。 
[ABSTRACT] sibfは、基準信号として大まかなスペクトログラムを使用してターゲット信号を抽出します。この方法は、ターゲット信号を抽出するsibfの方法に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br><font color="black">2020-06-01</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: FOCAL: A Forgery Localization Framework based on Video Coding
  Self-Consistency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/eess.IV/paper_0.html">
      <font color="black">FOCAL: A Forgery Localization Framework based on Video Coding
  Self-Consistency</font>
    </a>
  </h2>
  <font color="black">実験結果は、時間的スプライシングのローカリゼーションに関する最先端の改善と、合成ビデオと現実世界のビデオの両方で、空間スプライシングの新たに取り組んだケースで有望なパフォーマンスを示しています。全体的なフレームワークは、2つの典型的な偽造で検証されましたシナリオ：時間的および空間的スプライシング..特徴抽出ステップは、コーディングアーティファクトを探して分類するように特別に設計された、説明可能な畳み込みニューラルネットワークアーキテクチャによって実行されます。 
[ABSTRACT]動画の完全性の検証と認証はジャーナリズムへの大きな関心を表しています。全体的なフレームワークは2つの典型的な偽造シナリオで検証されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Joint Design of RF and gradient waveforms via auto-differentiation for
  3D tailored excitation in MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/eess.IV/paper_1.html">
      <font color="black">Joint Design of RF and gradient waveforms via auto-differentiation for
  3D tailored excitation in MRI</font>
    </a>
  </h2>
  <font color="black">このアプローチは、任意の微分不可能な損失関数と互換性があり、波形形状を制限せずにRFと勾配を直接最適化します。したがって、既存のアプローチは、通常、たとえば小先端近似または勾配波形の制約に基づく単純化された問題定式化に依存します。特定の形状に適用し、設計目標の狭いセット（ハードウェアの制約を無視するなど）の特定の目的関数にのみ適用されることがよくあります。このホワイトペーパーでは、磁気共鳴イメージング（RF）と勾配波形の共同設計のための新しい方法を提案します（ MRI）、そしてそれを3D空間的に調整された飽和および反転パルスの設計に適用します。 
[要約]このペーパーでは、自動固有のブロッホシミュレータを開発して活用します。設計に加えて、3D 3D励起パルスを作成します。結果のシステムは、オードブロッホ方程式に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Image inpainting using directional wavelet packets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/eess.IV/paper_2.html">
      <font color="black">Image inpainting using directional wavelet packets</font>
    </a>
  </h2>
  <font color="black">洗練された周波数分解能、無制限の方向を持つ波形の方向性、波形の（反）対称性、さまざまな周波数の波形のウィンドウ化された振動構造など、提示されたqWPのプロパティは、特に画像処理アプリケーションで効率的になります、論文で取り上げられている修復問題に対処する上で。この問題について得られた結果は、最高の最先端のアルゴリズムとかなり競争力があります。修復実験では、qWPベースの方法と最先端のアルゴリズムが提示されます。 
[ABSTRACT]アルゴリズムは、最近設計された準-分析複合体-値のウェーブレットアプリケーションのコレクションを使用しています。これは、パターン化に由来する一連のユニークな製品に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-12">
        <br><font color="black">2020-01-12</font>
      </time>
    </span>
</section>
<!-- paper0: Inpainting-based Video Compression in FullHD -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/eess.IV/paper_3.html">
      <font color="black">Inpainting-based Video Compression in FullHD</font>
    </a>
  </h2>
  <font color="black">これらの手法の核となる考え方は、少数の位置にのみ値を格納し、インペインティングによって欠落した領域を再構築することです。インペインティングベースのビデオ圧縮で初めて、FullHD（1080p）ビデオをリアルタイムで解凍できます完全にCPUベースの実装です。これらのコンポーネントを使用すると、品質と速度の点で、他の修復ベースのビデオコーデックより優れたパフォーマンスを実現できます。 
[要約]コンセプトは一連の短いビデオに基づいています。予測および修正方法に使用できます。コンセプトは10年の終わりまでに開発できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Semantic Labeling of Large-Area Geographic Regions Using Multi-View and
  Multi-Date Satellite Images, and Noisy OSM Training Labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/eess.IV/paper_4.html">
      <font color="black">Semantic Labeling of Large-Area Geographic Regions Using Multi-View and
  Multi-Date Satellite Images, and Noisy OSM Training Labels</font>
    </a>
  </h2>
  <font color="black">私たちのシステムのユニークな（そしておそらく、驚くべき）特性は、マルチビューデータから学習するためにCNNの末尾に追加された変更が、推論時に破棄され、ペナルティが比較的小さいことです。全体的なパフォーマンス..さらに、私たちのアプローチは、シーンあたり最大32のビューでトレーニングする場合でも、GPUメモリ消費の点でわずかなオーバーヘッドしか追加しません。これは、複数のビューを使用したトレーニングの利点がすべてのレイヤーで吸収されることを意味します。ネットワークの。 
[要約]マルチビューセマンティックセグメンテーションへのアプローチにより、クラスごとのiouスコアが4〜7％向上しました。これは、ビューを相互に独立して使用する従来のアプローチと比較したものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal Image-to-Image Translation via Mutual Information Estimation
  and Maximization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/eess.IV/paper_5.html">
      <font color="black">Multimodal Image-to-Image Translation via Mutual Information Estimation
  and Maximization</font>
    </a>
  </h2>
  <font color="black">この論文では、条件付き生成敵対ネットワークにおける潜在コードと出力画像の間の統計的依存性を促進することにより、マルチモーダルな画像から画像への変換を実現できる新しいフレームワークを提示します。さらに、この方法は、ソース間のもつれを解消します。ドメインコンテンツとターゲットドメインスタイルを無料で提供します。最新の方法と比較して、さまざまなベンチマークの画像から画像への翻訳データセットに対して、監視ありおよび監視なしの設定で実験を行い、メソッドの有効性とシンプルさを示しています。マルチモーダルで高品質の結果を実現します。 
[要旨]さまざまなベンチマーク画像からスポットへの方法で、監視ありおよび監視なしの設定で実験を行います。この方法では、両方のソース画像ドメインからターゲット画像ドメインへの片側変換モデルを学習するだけで済みます。教師ありまたは教師なしマルチモーダル画像-から-画像への変換</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-08">
        <br><font color="black">2020-08-08</font>
      </time>
    </span>
</section>
<!-- paper0: Accurate Alignment Inspection System for Low-resolution Automotive and
  Mobility LiDAR -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/eess.IV/paper_6.html">
      <font color="black">Accurate Alignment Inspection System for Low-resolution Automotive and
  Mobility LiDAR</font>
    </a>
  </h2>
  <font color="black">提案された方法の性能は、3度と30ミリメートルの範囲内でそれぞれLiDARの参照ヨーと水平移動を制御できるテストベンチを使用して評価されます。提案されたシステムの高精度とシンプルさにより、自動車やロボットの製造プロセスなど、安全品質管理のためにセンサーアタッチメントを検査する産業アプリケーションをスケールします。提案された方法は、固定位置で単一のターゲットボードのみを使用して、3つの方向（ロール、チルト、ヨー）とLiDARアタッチメントの水平位置。サブディグリーおよびミリメートルレベルの精度。 
[ABSTRACT]ミスアライメントは、0.2度および4 mm以内の精度で推定できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Fidelity-Controllable Extreme Image Compression with Generative
  Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/eess.IV/paper_7.html">
      <font color="black">Fidelity-Controllable Extreme Image Compression with Generative
  Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">2段階のトレーニングは、トレーニングを安定させるのに効果的です。第2に、再構成には不快なノイズやアーティファクトが含まれることがよくあります。したがって、モデルを再トレーニングしなくても、知覚品質と忠実度の間のトレードオフを制御できます。 
[要旨]私たちの方法は、2段階のトレーニングとネットワーク補間を採用しています。ネットワーク補間は、重要なエッジを維持しながら、望ましくないノイズとアーティファクトを低減します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic LiDAR Extrinsic Calibration System using Photodetector and
  Planar Board for Large-scale Applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/eess.IV/paper_8.html">
      <font color="black">Automatic LiDAR Extrinsic Calibration System using Photodetector and
  Planar Board for Large-scale Applications</font>
    </a>
  </h2>
  <font color="black">提案されたキャリブレーションシステムの高精度とシンプルさは、自律システムの信頼性と安全性のための大規模なアプリケーションに実用的になります。さらに、提案されたシステムは、ターゲットボードのシンプルな設計のみを必要としますこの論文は、高度に自動化された車両の大規模生産におけるセンサーのミスアライメント検査のためにモバイルプラットフォームに取り付けられたLiDARの外部パラメーターを推定する新しい自動キャリブレーションシステムを紹介します。 
[ABSTRACT]ターゲット表面上の対応するレーザービームの正確な位置を見つけるための、pd-ターゲットシステムと呼ばれる、埋め込まれた光検出器アレイを備えたターゲットボードの新しいコンセプト</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: W2S: Microscopy Data with Joint Denoising and Super-Resolution for
  Widefield to SIM Mapping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/eess.IV/paper_9.html">
      <font color="black">W2S: Microscopy Data with Joint Denoising and Super-Resolution for
  Widefield to SIM Mapping</font>
    </a>
  </h2>
  <font color="black">W2Sを使用すると、6つのノイズ除去方法と6つのSR方法の組み合わせをベンチマークできます。また、再構成エラーの観点から最適なノイズ除去を適用し、その後に最適なSR方法を適用しても、必ずしも最良の最終結果が得られるわけではないこともわかります。ただし、前者のオプションは、サンプルに損傷を与える可能性のある複数のショットを必要とし、後者のオプションには効率的なディープラーニングベースのアルゴリズムが存在しますが、ノイズ除去とSR（JDSR）の共同タスクでこれらのアルゴリズムを評価するベンチマークはありません。 
[要約]セットは、ノイズレベルの異なるノイズのある低解像度の画像で構成されます。これらには、ノイズのないlr画像と、対応する高品質のhr sim画像が含まれます。これらを使用して、新しい、より広い範囲の異なる`sr &#39;の形式</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-12">
        <br><font color="black">2020-03-12</font>
      </time>
    </span>
</section>
<!-- paper0: The role of late photons in diffuse optical imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/eess.IV/paper_10.html">
      <font color="black">The role of late photons in diffuse optical imaging</font>
    </a>
  </h2>
  <font color="black">この結果は、ここで説明する強く拡散する領域での完全な時間分解イメージングテクニックの重要性を強調しています。 ..有機組織などの混濁した媒体を介して画像化する機能は、生物学的および医学的画像化の非常に魅力的な展望です。 
[ABSTRACT]新しい研究では、初期のフォトンには、初期のフォトンゲートデータと同様の品質の画像を取得するための十分な情報があることが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Classification of Noncoding RNA Elements Using Deep Convolutional Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_0.html">
      <font color="black">Classification of Noncoding RNA Elements Using Deep Convolutional Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">その結果、RNAシーケンスの分類は、利用可能なCNNベースの分類モデルによって効率的に解決できる画像分類問題に変換されます。提案されたアプローチに基づいて、ncRNAシーケンスのRFAMデータベースからベンチマーク画像分類データセットが生成されます。広範な実験結果は、RNA分類に深層学習アプローチを使用する大きな可能性を示しています。 
[要約]このペーパーでは、RNAシーケンスを画像に変換する効率的なアプローチを提案します。また、プライマリシーケンスに加えてNCRNASのフォールディングの可能性も考慮します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Canonical Representations for Scene Graph to Image Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_1.html">
      <font color="black">Learning Canonical Representations for Scene Graph to Image Generation</font>
    </a>
  </h2>
  <font color="black">データから正準グラフ表現を学習することによってこれらの問題に対処する新しいモデルを提示し、その結果、複雑なビジュアルシーンの画像生成を改善します。 ..私たちのモデルは、大きなシーングラフの改善された経験的パフォーマンス、入力シーングラフのノイズに対するロバスト性、および意味的に等価なグラフの一般化を示しています。 
[要約]モデルはビジュアルゲノム、ココ、およびclevrによって作成されました。3つの異なるレベルでモデルのパフォーマンスが向上しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-16">
        <br><font color="black">2019-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: FOCAL: A Forgery Localization Framework based on Video Coding
  Self-Consistency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_2.html">
      <font color="black">FOCAL: A Forgery Localization Framework based on Video Coding
  Self-Consistency</font>
    </a>
  </h2>
  <font color="black">特徴抽出ステップは、説明可能な畳み込みニューラルネットワークアーキテクチャによって実行されます。コーディングアーティファクトを探して分類するために特別に設計されています。近年、いくつかの戦略とさまざまなフォレンジックトレースが提案されていますが、最新のソリューションでは、複数の検出器と機能を組み合わせます。全体的なフレームワークは、時間的および空間的スプライシングという2つの典型的な偽造シナリオで検証されました。 
[ABSTRACT]動画の完全性の検証と認証はジャーナリズムへの大きな関心を表しています。全体的なフレームワークは2つの典型的な偽造シナリオで検証されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Probabilistic Object Classification using CNN ML-MAP layers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_3.html">
      <font color="black">Probabilistic Object Classification using CNN ML-MAP layers</font>
    </a>
  </h2>
  <font color="black">キャリブレーションされた予測レイヤーと提案された予測レイヤーを使用した実験は、KITTIデータベースからのデータを使用してオブジェクト分類で実行されます。このアプローチにより、MLレイヤーとMAPレイヤーによるベイジアン推論が可能になります。ディープネットワークは現在、感覚のための最先端技術です自動運転とロボット工学の知覚。 
[ABSTRACT]ディープモデルは、しばしば自信過剰な予測を生成します。これは、ソフトマックスレイヤーの性質によるものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-29">
        <br><font color="black">2020-05-29</font>
      </time>
    </span>
</section>
<!-- paper0: Products-10K: A Large-scale Product Recognition Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_4.html">
      <font color="black">Products-10K: A Large-scale Product Recognition Dataset</font>
    </a>
  </h2>
  <font color="black">products-10Kデータセットは、https：//products-10k.github.io/ ..から入手できます。このペーパーでは、「Products-10K」という名前の人間がラベル付けした製品画像データセットを作成します。 JD.comのオンライン顧客が頻繁に購入するレベルの製品。すでにいくつかの製品ベンチマークが利用可能ですが、これらのデータセットは小さすぎる（製品数が限られている）か、ノイズの多いラベル（人間のラベルがない）です。 
[ABSTRACT]小売AIシステムは画像や動画から商品を認識する必要があります。これらのデータセットは小さすぎてノイズが多い-ラベルが付けられています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Certainty Pooling for Multiple Instance Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_5.html">
      <font color="black">Certainty Pooling for Multiple Instance Learning</font>
    </a>
  </h2>
  <font color="black">MNISTと実際の組織病理学データセット-Camelyon16に基づいて、証拠の比率が低いバッグを使用して、制御実験で提案された方法を他のプーリングオペレーターと比較します。\ textbf {Certainty Pooling}と呼ばれる新しいプーリングオペレーターを紹介します。バッグ予測に確実性をモデル化することで、より堅牢で説明可能なモデルが得られます。この方法は、バッグレベルとインスタンスレベルの両方の予測において、他の方法よりも優れています。 
[要約]バッグレベルのクラス予測は、例または埋め込みにプーリングオペレーターを適用することにより、複数のインスタンスから導き出されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: CSCL: Critical Semantic-Consistent Learning for Unsupervised Domain
  Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_6.html">
      <font color="black">CSCL: Critical Semantic-Consistent Learning for Unsupervised Domain
  Adaptation</font>
    </a>
  </h2>
  <font color="black">転移性批評家は、転移性知識の否定的転移が発生するものの、強化学習法の下で陽性転移ゲインを最大化するために転移性量子化器をガイドします。一貫した学習（CSCL）モデル。ドメインごとの分布とカテゴリごとの分布の不一致を軽減します。 
[要約]重要な移管ベースの敵対的なフレームワークは、移管可能なドメインを強調するように設計されています-賢明な知識は移譲できない知識を無視します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: 3D for Free: Crossmodal Transfer Learning using HD Maps -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_7.html">
      <font color="black">3D for Free: Crossmodal Transfer Learning using HD Maps</font>
    </a>
  </h2>
  <font color="black">重要なことに、高解像度マップとオブジェクトサイズの事前計算を使用して、この不適切な2Dから3Dへのマッピングを制限します。3Dオブジェクトの検出は、ロボット工学と自動運転の主要な知覚上の課題です。このマイニングプロセス自体が3Dオブジェクト検出器ですとして評価された場合、特に正確ではありません。 
[ABSTRACT]オブジェクト検出データセットは、既製の2Dインスタンスセグメンテーションモデルに基づいています。マイニングプロセスの結果は、さまざまな信頼度の3D直方体です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: EfficientFCN: Holistically-guided Decoding for Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_8.html">
      <font color="black">EfficientFCN: Holistically-guided Decoding for Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">そのようなフレームワークは、計算コストのわずか3分の1で、最先端の方法に匹敵する、またはさらに優れたパフォーマンスを実現します。 -ガイド付きデコーダーが導入され、エンコーダーからマルチスケール機能を介して高解像度のセマンティックリッチ機能マップを取得します。 
[要約]拡張された完全たたみ込みネットワーク（dilatedfcn）に基づくアルゴリズム。パフォーマンスと効率のバランスが取れているため、エンコーダーからのマルチレベルの機能マップを組み合わせて空間情報を徐々に回復するエンコーダー-デコーダー構造があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Semantic View Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_9.html">
      <font color="black">Semantic View Synthesis</font>
    </a>
  </h2>
  <font color="black">まず、3Dシーンの可視面の色と深度の合成に焦点を当てます。次に、合成された色と深度を使用して、複数平面画像（MPI）表現の予測プロセスに明示的な制約を課します。元のビューのコンテンツと、新しい視点での幾何学的に一貫したレンダリング。 
[要約]セマンティック画像合成の最近の進歩に基づいて構築します。欠点に対処する既存の方法を提案します。2段階のアプローチを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Global-local Enhancement Network for NMFs-aware Sign Language
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_10.html">
      <font color="black">Global-local Enhancement Network for NMFs-aware Sign Language
  Recognition</font>
    </a>
  </h2>
  <font color="black">上記の問題に取り組むために、SLRのさまざまな重要な側面に向けて相互に促進された2つのストリームを含む、グローバルローカル拡張ネットワーク（GLE-Net）と呼ばれるシンプルで効果的なアーキテクチャを提案します。NMFs-CSLおよびSLR500データセットでの広範な実験により、効果が実証されます2つのストリームのうち、1つはグローバルなコンテキスト関係をキャプチャし、もう1つは判別可能なきめの細かい手がかりをモデル化します。 
[ABSTRACT]サインワードは手動認識よりも複雑です。これにはサインワードの普遍的な認識が含まれますが、これらの機能はサインワードの表現にも重要な役割を果たします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Improved Mutual Mean-Teaching for Unsupervised Domain Adaptive Re-ID -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_11.html">
      <font color="black">Improved Mutual Mean-Teaching for Unsupervised Domain Adaptive Re-ID</font>
    </a>
  </h2>
  <font color="black">（iii）事前トレーニング済みネットワークは、ターゲットドメインでMMTによってさらに微調整されます。提案された方法は、mAPの観点で74.78％の精度を達成し、153チームのうち2位にランク付けされました。（i）SDAを採用してソースからターゲットに変換された画像を生成し、（ii）そのような画像は、ネットワークを事前トレーニングするための有益なトレーニングサンプルとして機能します。 
[要約]私たちのソリューションは、構造化ドメインフレームワークと相互平均に基づいています-ティーチング（mmt）。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_12.html">
      <font color="black">Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial
  Networks</font>
    </a>
  </h2>
  <font color="black">ただし、多くのタスクでは、ペアになったトレーニングデータは利用できません。以前のいくつかの方法に対する定量的な比較は、このアプローチの優位性を示しています。このマッピングは非常に制約が少ないため、逆マッピング$ F：Y \と組み合わせます。右矢印X $および$ F（G（X））\約X $（およびその逆）をプッシュするためにサイクル整合性の損失を導入します。 
[ABSTRACT]目標は、$ g（x）$ .dualのトレーニングデータのマッピングを学習することです。多くのタスクでは、デュアルトレーニングデータは利用できません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2017-03-30">
        <br><font color="black">2017-03-30</font>
      </time>
    </span>
</section>
<!-- paper0: Bosch Deep Learning Hardware Benchmark -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_13.html">
      <font color="black">Bosch Deep Learning Hardware Benchmark</font>
    </a>
  </h2>
  <font color="black">以前のベンチマークに加えて、DLモデルの一般的なサブモジュールを評価するための新しい細分性レベル、HWAメーカーによって行われたハードウェアとモデルの最適化を説明する2倍のベンチマーク手順、および不一致の特定に役立つ拡張パフォーマンスインジケーターセットを提案しますHWAと私たちのベンチマークで使用されているDLモデルとの間の関係です。科学および産業でのディープラーニング（DL）アプリケーションの普及により、効率的な推論システムに対する大きな需要が生まれました。これに対処するために、いくつかのDLハードウェアベンチマークが提案されています。多くのモデル、タスク、ハードウェアプラットフォームの包括的な比較。 
[ABSTRACT]これによりベンチマークが急速に増加しました。ベンチマークは比較のために特別に開発されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: What makes fake images detectable? Understanding properties that
  generalize -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_14.html">
      <font color="black">What makes fake images detectable? Understanding properties that
  generalize</font>
    </a>
  </h2>
  <font color="black">私たちは、偽の画像のどのような特性がそれらを検出可能にするかを理解し、さまざまなモデルアーキテクチャ、データセット、およびトレーニングのバリエーション全体で何が一般化するかを識別しようとします。さらに、これらの検出可能な特性を誇張する手法を示し、画像ジェネレーターが敵対的である場合でもそれを示します偽の画像分類子に対して微調整しても、不完全であり、特定の画像パッチに検出可能なアーティファクトが残ります。限定的な受容野を持つパッチベースの分類子を使用して、偽の画像のどの領域がより簡単に検出できるかを視覚化します。 
[要約]パッチ-一般的な受容野が限定された分類子を使用して、偽の画像のどの領域がより簡単に検出できるかを見つける</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Kinship Identification through Joint Learning Using Kinship Verification
  Ensembles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_15.html">
      <font color="black">Kinship Identification through Joint Learning Using Kinship Verification
  Ensembles</font>
    </a>
  </h2>
  <font color="black">親族照合はよく調査されたタスクです。2人が親族であるかどうかを識別する。親族識別は、特定の種類の親族をさらに識別することを目的としています。このために、親族検証の共同トレーニングに基づく新しい親族識別アプローチを提案しますアンサンブルと分類モジュール。 
[ABSTRACT]検証ネットワークは、特定の血族関係で個別にトレーニングされます。既存の検証ネットワークは、異なる品種間のコンテキストを考慮していません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-14">
        <br><font color="black">2020-04-14</font>
      </time>
    </span>
</section>
<!-- paper0: Semantic Labeling of Large-Area Geographic Regions Using Multi-View and
  Multi-Date Satellite Images, and Noisy OSM Training Labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_16.html">
      <font color="black">Semantic Labeling of Large-Area Geographic Regions Using Multi-View and
  Multi-Date Satellite Images, and Noisy OSM Training Labels</font>
    </a>
  </h2>
  <font color="black">さらに、私たちのアプローチでは、シーンごとに32のビューでトレーニングを行っている場合でも、GPUメモリ消費の点でわずかなオーバーヘッドしか追加されません。人間の監督なしでは、建物と道路のクラスのIoUスコアはそれぞれ0.8と0.64 OSMラベルを使用し、完全に自動化されていない最新のアプローチよりも優れています。このシステムのユニークな（そしておそらく、驚くべき）プロパティは、CNNの末尾に変更が追加されることですマルチビューデータからの学習は、全体的なパフォーマンスのペナルティが比較的小さい推論時に破棄できます。 
[要約]マルチビューセマンティックセグメンテーションへのアプローチにより、クラスごとのiouスコアが4〜7％向上しました。これは、ビューを相互に独立して使用する従来のアプローチと比較したものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Symbiotic Adversarial Learning for Attribute-based Person Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_17.html">
      <font color="black">Symbiotic Adversarial Learning for Attribute-based Person Search</font>
    </a>
  </h2>
  <font color="black">コードは、https：//github.com/ycao5602/SAL ..で公開されています。前者はデータが不十分なため、埋め込みが不十分になる傾向がありますが、後者は生成中にクラス内のコンパクトさを維持しません。広範な評価によりSALが示されています2つの挑戦的な歩行者ベンチマーク、PETAおよびMarket-1501を備えた9つの最先端の方法に対する優位性。 
[要約]共生敵対学習フレームワークはsal。と呼ばれます。2つのガンが共生学習スキームのフレームワークのベースにあります。1つは見えないクラスの機能を統合し、もう1つは埋め込みを最適化します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-19">
        <br><font color="black">2020-07-19</font>
      </time>
    </span>
</section>
<!-- paper0: A Dataset for Evaluating Blood Detection in Hyperspectral Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_18.html">
      <font color="black">A Dataset for Evaluating Blood Detection in Hyperspectral Images</font>
    </a>
  </h2>
  <font color="black">さまざまな取得環境、バックグラウンドのタイプ、血液の年齢、その他の血液に似た物質の存在に関連して、機械学習メソッドのパフォーマンスをテストできます。結果とその考察により、ハイパースペクトルデータとフォームでの血液検出の課題が明らかになります今後の作品のためのリファレンス。よく知られているマッチドフィルター検出器に基づくハイパースペクトルターゲット検出アルゴリズムを使用しました。 
[要約]このデータセットは、複雑さのレベルが異なる複数の検出シナリオで構成されています。このパフォーマンスは、ハイパースペクトル血液検出アルゴリズムの開発に対応して開発されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal Image-to-Image Translation via Mutual Information Estimation
  and Maximization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_19.html">
      <font color="black">Multimodal Image-to-Image Translation via Mutual Information Estimation
  and Maximization</font>
    </a>
  </h2>
  <font color="black">さらに、私たちの方法は、ソースドメインのコンテンツとターゲットドメインスタイルの間の絡み合いを無料で解消します。このホワイトペーパーでは、潜在コード間の統計的依存を促進するだけで、マルチモーダルな画像から画像への変換を実現できる新しいフレームワークを紹介します。条件付き生成敵対的ネットワークの出力画像。最新の方法と比較して、さまざまなベンチマークの画像から画像への翻訳データセットに対して、監視ありと監視なしの設定で実験を行い、手法の有効性とシンプルさを示しています。マルチモーダルで高品質の結果を実現します。 
[要旨]さまざまなベンチマーク画像からスポットへの方法で、監視ありおよび監視なしの設定で実験を行います。この方法では、両方のソース画像ドメインからターゲット画像ドメインへの片側変換モデルを学習するだけで済みます。教師ありまたは教師なしマルチモーダル画像-から-画像への変換</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-08">
        <br><font color="black">2020-08-08</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Kernel for Conditional Moment-Matching Discrepancy-based Image
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_20.html">
      <font color="black">Learning Kernel for Conditional Moment-Matching Discrepancy-based Image
  Classification</font>
    </a>
  </h2>
  <font color="black">条件付き最大平均不一致（CMMD）は、非線形カーネル関数からサポートを引き出すことにより、条件付き分布間の不一致をキャプチャできるため、パターン分類に正常に使用されています。特に、カーネルベースの類似性は、ディープネットワーク機能で繰り返し学習されます。このアルゴリズムでは、CMMDの識別性能を改善するために、新しいカーネル学習方法が提案されています。 
[ABSTRACT] cmmdはディープネットワーク機能で繰り返し操作できるため、略してklnと呼ばれます。ostrooperを使用して、カーネルの効率を向上させることができます。カーネルの効率はklnによって監視されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Accurate Alignment Inspection System for Low-resolution Automotive and
  Mobility LiDAR -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_21.html">
      <font color="black">Accurate Alignment Inspection System for Low-resolution Automotive and
  Mobility LiDAR</font>
    </a>
  </h2>
  <font color="black">提案された方法の性能は、3度と30ミリメートルの範囲内でそれぞれLiDARの参照ヨーと水平移動を制御できるテストベンチを使用して評価されます。提案されたシステムの高精度とシンプルさにより、自動車やロボットの製造プロセスなど、安全品質管理のためにセンサーアタッチメントを検査する産業アプリケーションをスケールします。提案された方法は、固定位置で単一のターゲットボードのみを使用して、3つの方向（ロール、チルト、ヨー）とLiDARアタッチメントの水平位置。サブディグリーおよびミリメートルレベルの精度。 
[ABSTRACT]ミスアライメントは、0.2度および4 mm以内の精度で推定できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Learning for Large-Scale Unsupervised Image Clustering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_22.html">
      <font color="black">Self-Supervised Learning for Large-Scale Unsupervised Image Clustering</font>
    </a>
  </h2>
  <font color="black">この論文では、自己教師付き表現に基づく教師なし分類のための簡単なスキームを提案します。教師なし評価を、教師付き学習の標準ベンチマークのセットに追加することをお勧めします。自己教師付きディープラーニングは、コンピュータビジョンでの表現学習。 
[ABSTRACT]複雑なデータの教師なし学習は困難です。最良のアプローチでも、教師付き対応よりもはるかに低いパフォーマンスを示します。ただし、教師なし学習は完全に教師付きの環境で評価されていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: LMSCNet: Lightweight Multiscale 3D Semantic Completion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_23.html">
      <font color="black">LMSCNet: Lightweight Multiscale 3D Semantic Completion</font>
    </a>
  </h2>
  <font color="black">ボクセル化LiDARスキャンのようなスパース3D占有グリッドからマルチスケール3Dセマンティックシーンを完成するための新しいアプローチを紹介します。アブレーション研究は、この方法が低密度入力に対してロバストであり、最も粗いレベルで非常に高速なセマンティック完成を可能にすることを示しています。私たちのアプローチの定性的な結果は、http：//tiny.cc/lmscnetで提供されています。 
[ABSTRACT]包括的なマルチスケールスキップ接続を備えた2Dバックボーンを使用して機能フローを強化します。モバイル-ロボットアプリケーションに優れたパフォーマンス/速度のトレードオフを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Affinity-aware Compression and Expansion Network for Human Parsing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_24.html">
      <font color="black">Affinity-aware Compression and Expansion Network for Human Parsing</font>
    </a>
  </h2>
  <font color="black">特に、LIPベンチマークで平均IoUが58.1％達成されます。さらに、GEMは、境界ガイダンスと空間親和性を組み込むことにより、各パーツのセマンティック情報を完全なピースに拡張します。 .. ACENetは、挑戦的なLIPとPascal-Person-Partデータセットで新しい最先端のパフォーマンスを実現します。 
[要約]このペーパーは、新しい「あいまいな」ネットワークを提案します。主に、2つのモジュールで構成されます：ローカル圧縮モジュール（lcm）とグローバル拡張モジュール（gem）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Why do These Match? Explaining the Behavior of Image Similarity Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_25.html">
      <font color="black">Why do These Match? Explaining the Behavior of Image Similarity Models</font>
    </a>
  </h2>
  <font color="black">ディープラーニングモデルを説明すると、ユーザーがその動作を理解し、研究者がその欠点を識別できるようになります。SANEの説明では、重要な画像領域を識別する顕著性マップと、一致を最もよく説明する属性を組み合わせています。このタスクでは、説明は両方に依存します入力画像のため、標準的な方法は適用されません。 
[ABSTRACT]説明には、通常は顕著性マップだけではキャプチャされない追加情報が含まれており、属性認識の従来のタスクのパフォーマンスを向上できることもわかりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-26">
        <br><font color="black">2019-05-26</font>
      </time>
    </span>
</section>
<!-- paper0: Automated Search for Resource-Efficient Branched Multi-Task Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_26.html">
      <font color="black">Automated Search for Resource-Efficient Branched Multi-Task Networks</font>
    </a>
  </h2>
  <font color="black">通常、このようなアーキテクチャは文献で手作りされています。リソースに制約のある環境で柔軟性を持たせるために、モデルサイズを動的に制御するプロキシレスのリソース認識損失を導入します。しかし、問題のサイズと複雑さを考えると、この手動のアーキテクチャ探索は、人間の設計能力を超える可能性があります。 
[要約]この論文では、差別化可能なニューラルアーキテクチャの検索に根ざした原理的なアプローチを提案します。マルチタスクニューラルネットワークの圧倒的な段階で分岐（ツリーのような）構造を自動的に定義します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Lossy Image Compression with Normalizing Flows -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_27.html">
      <font color="black">Lossy Image Compression with Normalizing Flows</font>
    </a>
  </h2>
  <font color="black">ディープラーニングベースの画像圧縮は最近、目覚ましい進歩を遂げており、場合によっては、何十年にもわたって確立および改良されてきた変換コーディングベースのアプローチを超えることもできました。これに加えて、複数回実行した場合でも、再エンコードによって一定の品質結果を維持する機能。興味深いことに、情報を明示的に破棄する量子化ステップを実行する前に、可逆変換を採用しています。 
[ABSTRACT]これは、非可逆画像圧縮のために正規化フローを活用する機会を探る最初の作業です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchical Style-based Networks for Motion Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_28.html">
      <font color="black">Hierarchical Style-based Networks for Motion Synthesis</font>
    </a>
  </h2>
  <font color="black">私たちの提案する方法は、長距離生成タスクを階層的に分解することによって人間の動きをモデル化することを学習します。最初に、多様な合成が行われる双線形変換モデリングを介して、提供されたモーション素材をスタイルとコンテンツの対応物に明示的に解きほぐすことを提案しますこれらの2つのコンポーネントの自由形式の組み合わせによって達成されます。次に、短距離クリップが接続され、長距離モーションシーケンスが形成されます。 
[ABSTRACT]提案された方法は、特定の目標位置を達成するために、長距離で多様で妥当な動作を作成します。提案された方法は、テスト中に目に見えないモーションデータに一般化できる世界の最良のモーションを合成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: 3rd Place Solution to "Google Landmark Retrieval 2020" -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_29.html">
      <font color="black">3rd Place Solution to "Google Landmark Retrieval 2020"</font>
    </a>
  </h2>
  <font color="black">さらに、Corner-Cutmixと呼ばれるデータ拡張方法を採用しています。これにより、モデルのマルチスケールおよびオクルードされたランドマーク画像を認識する能力が向上します。画像検索は、コンピュータービジョンの基本的な問題です。 Google Landmark Retrieval 2020チャレンジ。 
[ABSTRACT]検索の巨人が、Googleのランドマーク取得2020チャレンジに対して3位の詳細なソリューションを提示しました。埋め込みクラスタリングに基づくデータクリーニング戦略を使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: CA-GAN: Weakly Supervised Color Aware GAN for Controllable Makeup
  Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_30.html">
      <font color="black">CA-GAN: Weakly Supervised Color Aware GAN for Controllable Makeup
  Transfer</font>
    </a>
  </h2>
  <font color="black">最後に、メイクアップスタイルの転送とカラーコントロールのパフォーマンスの定量分析を初めて紹介します。これにより、複雑なオブジェクトの制御可能な合成を学習でき、変更したいイメージ属性の弱いプロキシのみが必要です。特定のオブジェクトの色を変更することを学習する生成モデルであるCA-GANを導入します（たとえば
[ABSTRACT]メイクアップスタイルの転送タスクの新しいプレゼンテーションを提案し、色制御可能なメイクアップスタイルの合成を学習することを目的としています）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: VLANet: Video-Language Alignment Network for Weakly-Supervised Video
  Moment Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_31.html">
      <font color="black">VLANet: Video-Language Alignment Network for Weakly-Supervised Video
  Moment Retrieval</font>
    </a>
  </h2>
  <font color="black">VLANetは、意味論的に類似したビデオとクエリを収集することを強制する対照的な損失を使用して、エンドツーエンドでトレーニングされます。実験により、このメソッドがCharades-STAおよびDiDeMoデータセットで最先端のパフォーマンスを実現することがわかります。wVMRの既存のメソッドマルチスケールの提案を生成し、クエリに基づく注意メカニズムを適用して、最も関連性の高い提案を強調表示します。 
[ABSTRACT]ビデオ-言語調整ネットワーク（vlanet）は、疑似候補の提案を排除することにより、より鋭い注意を学ぶために提案されています。この方法は、charades-staおよびdidemoデータセットで最先端のパフォーマンスを実現します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: TORNADO-Net: mulTiview tOtal vaRiatioN semAntic segmentation with
  Diamond inceptiOn module -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_32.html">
      <font color="black">TORNADO-Net: mulTiview tOtal vaRiatioN semAntic segmentation with
  Diamond inceptiOn module</font>
    </a>
  </h2>
  <font color="black">このローカルな近隣情報をより有効に利用してノイズの多い予測を減らすために、総変動、Lovasz-Softmax、および重み付きクロスエントロピー損失の組み合わせを導入します。また、LiDARデータが360度の視野と円形のパディングを使用します。新しいダイヤモンドコンテキストブロックを備えたエンコーダーデコーダーResNetアーキテクチャにマルチビュー（鳥瞰図と範囲）の投影特徴抽出を組み込みます。 
[要旨]トルネード-ネット-3D LIDARポイントクラウドセマンティックセグメンテーションのニューラルセットを導入します。また、LIDARデータが360度の視野であり、円形のパディングを使用するという事実を利用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: LC-NAS: Latency Constrained Neural Architecture Search for Point Cloud
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_33.html">
      <font color="black">LC-NAS: Latency Constrained Neural Architecture Search for Point Cloud
  Networks</font>
    </a>
  </h2>
  <font color="black">アーキテクチャ検索で精度とレイテンシをトレードオフするために、新しいレイテンシ制約定式化を実装します。このホワイトペーパーでは、LC-NASと呼ばれる新しいNASフレームワークを導入し、ターゲットに制約されているポイントクラウドアーキテクチャを検索します。レイテンシ..ただし、これらの取り組みでは、推論中のレイテンシなどの重要な要素を考慮することができません。 
[ABSTRACT] lc-nasは最小限のコストでmodelnet40の点群分類のための最先端のアーキテクチャを見つけることができます。これにより、レイテンシを10％削減できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Dogs as Model for Human Breast Cancer: A Completely Annotated Whole
  Slide Image Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_34.html">
      <font color="black">Dogs as Model for Human Breast Cancer: A Completely Annotated Whole
  Slide Image Dataset</font>
    </a>
  </h2>
  <font color="black">人間の乳がんに関する現在公開されているデータセットは、スライド画像全体（WSI）の小さなサブセットの注釈のみを提供します。このデータセットは、13,907 MFと36,379のハードネガティブで構成されています。このため、病理学者はすべてのWSIで潜在的なMFと構造をスクリーニングしました。同様の外観。 
[ABSTRACT]現在のシステムは、有糸分裂像の密度（mf）です。mfは、人間の乳がんに対するこのスキームの主要なコンポーネントです。結果は、注釈の一貫性をさらに高めるために行われました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: The Hessian Penalty: A Weak Prior for Unsupervised Disentanglement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_35.html">
      <font color="black">The Hessian Penalty: A Weak Prior for Unsupervised Disentanglement</font>
    </a>
  </h2>
  <font color="black">ヘッセンペナルティでのトレーニングにより、いくつかのデータセットでProGANに適用すると、潜在空間で軸に沿った解きほぐしが頻繁に発生することを示します。 。さらに、正則化用語を使用して、BigGANの潜在的な空間での監視可能な方法で解釈可能な方向を識別します。 
[要約]このホワイトペーパーでは、ヘッセンペナルティを提案します。これは、単純な正則化用語です。この用語を使用して、監視なしの方法でbigganの潜在空間の解釈可能変数を識別します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Explainable Disease Classification via weakly-supervised segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_36.html">
      <font color="black">Explainable Disease Classification via weakly-supervised segmentation</font>
    </a>
  </h2>
  <font color="black">公開データセットの優れた評価結果は、提案されたソリューションの一般化可能性を強調しています。決定に対応するアクティベーションマップは、特定の疾患の関心領域と十分に相関していません。提案されたアプローチは、糖尿病性黄斑浮腫（DME）の検出で示されています。 OCTスライス。 
[要約]これらのシステムは、特定の疾患の検出において高い精度から非常に高い精度を実現します。ただし、提供された決定または分類結果についての説明がないため、提案されたアプローチは、マンモグラフィ画像からの乳がん検出に適用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Fidelity-Controllable Extreme Image Compression with Generative
  Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_37.html">
      <font color="black">Fidelity-Controllable Extreme Image Compression with Generative
  Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">したがって、モデルを再トレーニングすることなく、知覚品質と忠実度の間のトレードオフを制御できます。2段階トレーニングは、トレーニングを安定させるのに効果的です。次に、再構成に不快なノイズやアーティファクトが含まれることがよくあります。 
[要旨]私たちの方法は、2段階のトレーニングとネットワーク補間を採用しています。ネットワーク補間は、重要なエッジを維持しながら、望ましくないノイズとアーティファクトを低減します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic LiDAR Extrinsic Calibration System using Photodetector and
  Planar Board for Large-scale Applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_38.html">
      <font color="black">Automatic LiDAR Extrinsic Calibration System using Photodetector and
  Planar Board for Large-scale Applications</font>
    </a>
  </h2>
  <font color="black">提案されたキャリブレーションシステムの高精度とシンプルさは、自律システムの信頼性と安全性のための大規模なアプリケーションに実用的になります。さらに、提案されたシステムは、ターゲットボードのシンプルな設計のみを必要とします低解像度のLiDARに関する提案されたシステムの実験的評価により、LiDARオフセットポーズは0.1度および3 mmレベルの精度で推定できることがわかりました。 
[ABSTRACT]ターゲット表面上の対応するレーザービームの正確な位置を見つけるための、pd-ターゲットシステムと呼ばれる、埋め込まれた光検出器アレイを備えたターゲットボードの新しいコンセプト</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: W2S: Microscopy Data with Joint Denoising and Super-Resolution for
  Widefield to SIM Mapping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_39.html">
      <font color="black">W2S: Microscopy Data with Joint Denoising and Super-Resolution for
  Widefield to SIM Mapping</font>
    </a>
  </h2>
  <font color="black">顕微鏡データでJDSRを研究するために、従来の蛍光広視野およびSIMイメージングを使用して取得した、このような新しいJDSRデータセットWidefield2SIM（W2S）を提案します。最後に、JDSRのSRネットワークがエンドツーエンドで再トレーニングされ、最先端のディープノイズ除去およびSRネットワーク。きれいな高解像度（HR）画像を取得するには、構造化照明顕微鏡（SIM）などの顕微鏡技術を使用するか、ノイズ除去および超解像度（SR）アルゴリズムを適用します。 
[要約]セットは、ノイズレベルの異なるノイズのある低解像度の画像で構成されます。これらには、ノイズのないlr画像と、対応する高品質のhr sim画像が含まれます。これらを使用して、新しい、より広い範囲の異なる`sr &#39;の形式</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-12">
        <br><font color="black">2020-03-12</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchical Adaptive Lasso: Learning Sparse Neural Networks with
  Shrinkage via Single Stage Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_40.html">
      <font color="black">Hierarchical Adaptive Lasso: Learning Sparse Neural Networks with
  Shrinkage via Single Stage Training</font>
    </a>
  </h2>
  <font color="black">スパース性は、モデルサイズを制限するための1つのアプローチです。過度にパラメータ化されたネットワークのトレーニングに使用すると、サブネットワークが個別にトレーニングされていない場合でも、ペナルティによって高精度の小さなサブネットワーク（当選チケット）が生成されます。経験的に、CIFAR-100データセット、HALOは、高度にスパースなネットワーク（パラメーターの$ 5 \％$のみ）を学習できることがわかります。これにより、最新のマグニチュードプルーニングメソッドよりも約$ 2 \％$および$ 4 \％$パフォーマンスが向上します。同じレベルのスパース性。 
[ABSTRACT] sparsityは、sparso.methodを使用してモデルサイズを制限する1つの方法で、サブネットワークを個別に再トレーニングしなくてもパフォーマンスが向上するペナルティを作成することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Decision Support for Video-based Detection of Flu Symptoms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_41.html">
      <font color="black">Decision Support for Video-based Detection of Flu Symptoms</font>
    </a>
  </h2>
  <font color="black">提案されたネットワークのパフォーマンスと、これらのパフォーマンス測定をリスクと組み合わせて信頼を生み出す方法を評価する実験を提供します。スケルトン機能を使用したアクション認識のために、修正された残差時間畳み込みネットワークが提案されます。意思決定支援システムの開発は、疾患の制御と診断の分野に適用できる成長分野。 
[ABSTRACT]監視データを使用して、動作認識を実行するためにスケルトンの特徴が抽出されます。これらには、咳やくしゃみの動きの検出と認識が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Monocular Reconstruction of Neural Face Reflectance Fields -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_42.html">
      <font color="black">Monocular Reconstruction of Neural Face Reflectance Fields</font>
    </a>
  </h2>
  <font color="black">パラメトリックモデルを使用して反射率の各コンポーネントを個別にモデル化する代わりに、ニューラル表現を使用すると、入力光の方向、視点、および顔のジオメトリによってパラメーター化された、幾何学的な変形不変空間に基本セットの顔を生成できます。高次のグローバルイルミネーションエフェクトとセルフシャドウイングはモデル化されていないため、反射率の重要な知覚的側面はモデル化されていません。この方法は、8つの視点から150の照明条件で照明された300人をキャプチャするライトステージトレーニングデータセットでトレーニングされます。 
[ABSTRACT]単眼画像から顔の反射率を推定するための既存のほとんどの方法では、鏡面反射成分を追加するアプローチはほとんどなく、顔が拡散していると仮定しています。単一の単眼画像からの最終的な外観</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: A Single Frame and Multi-Frame Joint Network for 360-degree Panorama
  Video Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_43.html">
      <font color="black">A Single Frame and Multi-Frame Joint Network for 360-degree Panorama
  Video Super-Resolution</font>
    </a>
  </h2>
  <font color="black">デュアル学習戦略は、より良いソリューションを見つけることができるようにソリューションのスペースを制限するために実行されます。ただし、高解像度の球面ビデオのキャプチャ、保存、および送信は非常に高価です。機能の表現を強化するために、混合注意メカニズムが考案されています能力。 
[ABSTRACT]素晴らしい没入感が見られるため、球形の動画は大きな関心を集めます。これらには、低解像度から高解像度の動画を復元するための新しいシングルフレームおよびマルチフレームジョイントネットワーク（smfn）が含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: LCA-Net: Light Convolutional Autoencoder for Image Dehazing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_44.html">
      <font color="black">LCA-Net: Light Convolutional Autoencoder for Image Dehazing</font>
    </a>
  </h2>
  <font color="black">リアルタイムの出力が即座に得られるため、時間は画像の前処理で重要です。ネットワークの複雑さと画像品質のトレードオフは、このニューラルネットワークでうまく処理され、このネットワークのパフォーマンスは低スペックシステムによって制限されません。 。このネットワークは、いくつかの標準データセットではるかに速い速度で最適な曇り除去のパフォーマンスを実現します。これは、画質の点で最先端の方法に匹敵します。 
[要約]提案されたモデルは、非常に軽い畳み込みエンコーダー-デコーダーネットワークを使用します。このネットワークは、はるかに速い速度での畳み込み除去のパフォーマンスを向上させます。これは、いくつかの標準データセットで、画像品質の点で最新の方法に匹敵する曇り除去に先行します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: VoxelPose: Towards Multi-Camera 3D Human Pose Estimation in Wild
  Environment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_45.html">
      <font color="black">VoxelPose: Towards Multi-Camera 3D Human Pose Estimation in Wild
  Environment</font>
    </a>
  </h2>
  <font color="black">ベルとホイッスルがないと、パブリックデータセットの最先端技術よりも優れています。このアプローチは、実際に頻繁に発生するオクルージョンに対して堅牢です。コードは、https：//github.com/microsoft/multipersonでリリースされます。 -pose-estimation-pytorch。 
[ABSTRACT] $ 3 $ d空間で直接動作するエンドビューソリューションを提示します。これにより、2 d空間での誤った決定を回避します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-13">
        <br><font color="black">2020-04-13</font>
      </time>
    </span>
</section>
<!-- paper0: Universal Semantic Segmentation for Fisheye Urban Driving Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_46.html">
      <font color="black">Universal Semantic Segmentation for Fisheye Urban Driving Images</font>
    </a>
  </h2>
  <font color="black">最後に、実際の魚眼画像で普遍的なセマンティックセグメンテーションモデルをテストし、満足のいく結果を得ました。トレーニングプロセスでは、直線画像が7つのDoFで魚眼画像に変換され、異なる位置、方向、焦点距離..この7自由度の拡張機能は、さまざまな自動運転アプリケーションの魚眼カメラにユニバーサルセマンティックセグメンテーションソリューションを提供します。 
[ABSTRACT] 7自由度（dof）増大法が提案され、直線的な画像をより包括的な方法で魚眼画像に変換します。この手法を使用してトレーニングすると、さまざまな歪んだ魚眼データに対するモデルの精度とロバスト性を向上できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-31">
        <br><font color="black">2020-01-31</font>
      </time>
    </span>
</section>
<!-- paper0: Strawberry Detection using Mixed Training on Simulated and Real Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_47.html">
      <font color="black">Strawberry Detection using Mixed Training on Simulated and Real Data</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、シミュレートされたデータセットで補強された実際のデータセットを使用すると、精度がわずかに高くなることを示しています。実際の画像でイチゴを検出するために、実際のデータとシミュレーションされたデータが混在するデータセットのトレーニングを検討します。 
[要旨]イチゴを実際の画像で検出するために、実際のデータとシミュレーションデータが混在するデータセットのトレーニングを検討します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-scale Deep Feature Representation Based on SR-GAN for Low
  Resolution Person Re-identfication -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_48.html">
      <font color="black">Multi-scale Deep Feature Representation Based on SR-GAN for Low
  Resolution Person Re-identfication</font>
    </a>
  </h2>
  <font color="black">この論文では、画像と歩行者のマッチングの超解像を最適化することを目的とした、超解像GAN（SR-GAN）ベースの低解像度人物再識別のためのマルチスケールディープフィーチャー表現（MFR-GAN）フレームワークを提案します。 ..このような状況は解像度の不一致の問題を引き起こします。.2つの合成データセットと共通のRe-IDデータセットでの実験により、この方法（MFR-GAN）が解像度の不一致の問題を効果的に解決できることが確認されます。 
[要約] re-idシステムは、いくつかのre-ids.gansを作成するために使用されており、異なるアップスケーリング係数を持つ人物の画像の解像度を高めるように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Fast Bi-layer Neural Synthesis of One-Shot Realistic Head Avatars -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_49.html">
      <font color="black">Fast Bi-layer Neural Synthesis of One-Shot Realistic Head Avatars</font>
    </a>
  </h2>
  <font color="black">視覚的な品質と速度に関して、システムを類似の最先端システムと比較します。テクスチャ画像はオフラインで生成され、ワープされて粗い画像に追加され、合成されたヘッドビューの高い効果的な解像度を保証します。私たちのシステムのリアルタイムのスマートフォンベースの実装についても報告します。 
[概要]私たちのアプローチは、2つのレイヤーにレンダリングすることで人の外観をモデル化します。最初のレイヤーは、高周波の詳細を含むポーズに依存しないテクスチャイメージによって定義されます。2番目のレイヤーは、高い周波数を含むポーズのある独立したレイヤーによって定義されます-周波数の詳細</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-view Graph Learning by Joint Modeling of Consistency and
  Inconsistency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_50.html">
      <font color="black">Multi-view Graph Learning by Joint Modeling of Consistency and
  Inconsistency</font>
    </a>
  </h2>
  <font color="black">グラフ学習は、複数のビューから統一されたロバストなグラフを学習する機能を備えたマルチビュークラスタリングの有望な手法として浮上しています。目的関数の最適化はNP困難ですが、非常に効率的な最適化アルゴリズムを設計して、統合されたグラフのエッジの数が線形時間複雑である近似解。さらに、マルチビューグラフ学習アプローチは、類似性グラフと非類似性グラフの両方に適用でき、フレームワークで2つのグラフ融合ベースのバリアントにつながります。 。 
[ABSTRACT]学習方法は、主にマルチビューの一貫性の問題に焦点を当てていますが、複数のビューにわたる一貫性を無視していることがよくあります。これにより、低品質またはノイズの多いデータセットに対して脆弱になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: SPINN: Synergistic Progressive Inference of Neural Networks over Device
  and Cloud -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CV/paper_51.html">
      <font color="black">SPINN: Synergistic Progressive Inference of Neural Networks over Device
  and Cloud</font>
    </a>
  </h2>
  <font color="black">提案されたシステムは、動的な条件に適応し、ユーザー定義のサービスレベル要件を満たすために、実行時に早期終了ポリシーとCNN分割を共同最適化する新しいスケジューラーを導入します。それにもかかわらず、クラウドに依存することにより、出力を生成し、ドローン障害物回避やインタラクティブアプリケーションなどの新たなミッションクリティカルで移動性の高いアプリケーションは、動的な接続状態とクラウドの不確実な可用性に悩まされる可能性があります。定量的評価は、SPINNが最新の性能を上回っていることを示していますさまざまなネットワーク条件下で達成されたスループットで最大2倍のアートコラボレーティブ推論の対応物、サーバーのコストを最大6.8倍削減し、レイテンシの制約の下で精度を20.7％改善しながら、不確実な接続条件下での堅牢な操作と大幅なエネルギー節約を実現クラウド中心の実行。 
[ABSTRACT]理論システムはクラウドコンピューティングを使用して高速で堅牢なcons.systemを使用して、システムからクラウドベースシステムにシフトシフトをシフトします。理論を使用して、ネットワークネットワークネットワークシステムを作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-14">
        <br><font color="black">2020-08-14</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Example-Based Named Entity Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CL/paper_0.html">
      <font color="black">Example-Based Named Entity Recognition</font>
    </a>
  </h2>
  <font color="black">例に基づいたNERと呼ばれる希少なデータの存在下での名前付きエンティティ認識（NER）への新しいアプローチを提示します。現在の最先端技術と比較して、提案された方法は、特に少数のサポート例です。トレーニングを必要としない数回の学習のアプローチでは、質問応答からインスピレーションを得て、新しく見えないドメインのエンティティスパンを特定します。 
[ABSTRACT]新しい方法は、質問からインスピレーションを得ています-新しい方法で異なる形式を識別するための回答-少ない数</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: End to End Dialogue Transformer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CL/paper_1.html">
      <font color="black">End to End Dialogue Transformer</font>
    </a>
  </h2>
  <font color="black">ここでは、シークシティのRNNベースのアーキテクチャではなく、トランスフォーマアーキテクチャに基づく対話システムを提案します。これは、エンドツーエンド、シーケンスツーシーケンスの方法で同様に機能します。ここでは、リカレントニューラルネットワークのパフォーマンスに触発されていますベースのモデルSequicity。これは、対話を実行するときに、シーケンスからシーケンスへのアーキテクチャを使用して、最初に対話で起こっていることのテキスト表現を生成し、次のステップでこれをデータベースの結果とともに使用して、応答への応答を生成します。ユーザー..対話システムは、人とコンピューターの間の会話を促進することを試みます。 
[ABSTRACT]私たちはここで、秘密性モデルのパフォーマンスに触発されています。それは、シーケンス-to-to-シーケンスアーキテクチャを使用して応答を作成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: syrapropa at SemEval-2020 Task 11: BERT-based Models Design For
  Propagandistic Technique and Span Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CL/paper_2.html">
      <font color="black">syrapropa at SemEval-2020 Task 11: BERT-based Models Design For
  Propagandistic Technique and Span Detection</font>
    </a>
  </h2>
  <font color="black">開発セットでは、SIサブタスク（F1-measureの0.4711）で7位、TCサブタスク（F1-measureの0.6783）で3位です。コスト関数を調整して、不均衡なデータセットに対処するよう努めています。次に、テクニック分類（TC）のハイブリッドモデルを開発します。 
[要旨]まず、スパンベルトに基づいてスパン識別（si）のモデルを構築します。ハイブリッドモデルは、トレーニング方法が異なる2つのベルトモデルを含む3つのサブモデルで構成されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Word2vec Skip-gram Dimensionality Selection via Sequential Normalized
  Maximum Likelihood -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CL/paper_3.html">
      <font color="black">Word2vec Skip-gram Dimensionality Selection via Sequential Normalized
  Maximum Likelihood</font>
    </a>
  </h2>
  <font color="black">単語の埋め込みに関する他の評価方法と比較して、SNMLによって選択された次元は、単語の類推または単語の類似性タスクによって取得された最適な次元に非常に近くなります。したがって、対応するモデルは、真の分布に可能な限り近づけることができます。このホワイトペーパーでは、word2vecスキップグラム（SG）の次元を選択するための、新しい情報基準ベースのアプローチを提案します。 
[要約]提案されたアプローチは、元のsgモデルとsgネガティブサンプリングモデルの両方に適用されます。snmlは、bicとaicの両方より優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-18">
        <br><font color="black">2020-08-18</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-lingual Semantic Role Labeling with Model Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CL/paper_4.html">
      <font color="black">Cross-lingual Semantic Role Labeling with Model Transfer</font>
    </a>
  </h2>
  <font color="black">以前の研究では、ユニバーサル機能の助けを借りて、モデル転送によってクロスリンガルセマンティックロールラベリング（SRL）を実現できることが示されています。UniversalProposition Bankコーパスの実験結果では、クロスリンガルSRLのパフォーマンスは、さまざまなクロスを活用することで異なる可能性があることを示しています。 -lingual features ..正確には、ゴールドの構文機能は、自動生成されたものと比較して、クロスリンガルSRLにとってはるかに重要であることがわかります。 
[ABSTRACT]ユニバーサル機能には、ユニバーサル機能と転送コンテキストが含まれます。ユニバーサル機能は、自動生成されたものと比較して、クロスリンガルsrlの方がはるかに重要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: YNU-HPCC at SemEval-2020 Task 11: LSTM Network for Detection of
  Propaganda Techniques in News Articles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CL/paper_5.html">
      <font color="black">YNU-HPCC at SemEval-2020 Task 11: LSTM Network for Detection of
  Propaganda Techniques in News Articles</font>
    </a>
  </h2>
  <font color="black">SIサブタスクのマクロF1スコアは0.406、TCサブタスクのマイクロF1スコアは0.505です。この方法は、公式にリリースされたベースラインメソッドを大幅に上回っており、SIおよびTCサブタスクはそれぞれ17位と22位にランク付けされています。 、テストセットの場合。このペーパーでは、SemEval-2020タスク11のニュース記事のプロパガンダ検出手法に関する調査をまとめています。
[要約]私たちのアプローチは、siおよびtcサブタスクの両方で優れた結果を達成しました。ベースライン法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: How To Evaluate Your Dialogue System: Probe Tasks as an Alternative for
  Token-level Evaluation Metrics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CL/paper_6.html">
      <font color="black">How To Evaluate Your Dialogue System: Probe Tasks as an Alternative for
  Token-level Evaluation Metrics</font>
    </a>
  </h2>
  <font color="black">手作りのタスクは、生成されたテキストのトークンレベルの評価を超えて、生成的対話モデルの理解を定量的に評価することを目的としています。プローブタスクの実験では、RNNベースのアーキテクチャとは異なり、トランスフォーマーモデルは、生成されたテキストがターゲットテキストとより高いオーバーラップを持っているにもかかわらず、入力テキスト。そのようなメトリックは、人間の判断と相関しないことが以前に示されていました。 
[要約]使用される自動メトリックは、エージェントの全体的な相互作用のプロキシとして生成されたテキストの品質を評価します。この作業では、適切な評価のための十分な情報がないため、対話エージェントの人間による評価は決定的ではない可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Masked Language Modeling for Proteins via Linearly Scalable Long-Context
  Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CL/paper_7.html">
      <font color="black">Masked Language Modeling for Proteins via Linearly Scalable Long-Context
  Transformers</font>
    </a>
  </h2>
  <font color="black">タンパク質配列モデリングの困難なタスクに対するその有効性を実証し、詳細な理論的分析を提供します。さらに、それは強力な理論的保証を提供します。注意マトリックスの偏りのない推定と均一な収束。シーケンスでは、2次空間の複雑さを特徴とし、スパースパターンの事前分布を組み込んでいません。 
[ABSTRACT]アテンションメカニズムのトレーニングコストに対する懸念は高まり続けていますが、長いシーケンスを含む実際のアプリケーションでは、これらの前提を満たすことができない場合があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-05">
        <br><font color="black">2020-06-05</font>
      </time>
    </span>
</section>
<!-- paper0: BPGC at SemEval-2020 Task 11: Propaganda Detection in News Articles with
  Multi-Granularity Knowledge Sharing and Linguistic Features based Ensemble
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CL/paper_8.html">
      <font color="black">BPGC at SemEval-2020 Task 11: Propaganda Detection in News Articles with
  Multi-Granularity Knowledge Sharing and Linguistic Features based Ensemble
  Learning</font>
    </a>
  </h2>
  <font color="black">Task-11は2つのサブタスク、つまりSpan Identificationで構成されます-ニュース記事が与えられると、システムは少なくとも1つのプロパガンダ手法を含む特定のフラグメントにタグを付けます。 and Technique Classification-14のプロパガンダテクニックの中から特定のプロパガンディストのステートメントを正しく分類します。サブタスク2では、BERTのアンサンブルと言語的特徴を備えたロジスティック回帰分類子を使用します。この結果から、言語的特徴がカバーするための強力な指標であることがわかります非常に不均衡なデータセット内の少数派クラス。 
[要旨]技術的特徴は、非常に不均衡なデータセットの少数派クラスをカバーするための強力な指標です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-31">
        <br><font color="black">2020-05-31</font>
      </time>
    </span>
</section>
<!-- paper0: Prediction of ICD Codes with Clinical BERT Embeddings and Text
  Augmentation with Label Balancing using MIMIC-III -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CL/paper_9.html">
      <font color="black">Prediction of ICD Codes with Clinical BERT Embeddings and Text
  Augmentation with Label Balancing using MIMIC-III</font>
    </a>
  </h2>
  <font color="black">al。）。 F1スコアが0.76の場合、最終的なF1スコアは0.75になりますが、合計で上位50のICDコードです。パフォーマンスの向上は、主に新規テキスト拡張を使用して、トレーニング中に文の順序をシャッフルしたためです。 
[ABSTRACT]これは、臨床bert.itを使用して達成されました。データの75％を使用して達成されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Machine Semiotics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CL/paper_10.html">
      <font color="black">Machine Semiotics</font>
    </a>
  </h2>
  <font color="black">したがって、機械は、個々の単語の意味を理解する必要はなく、個々の単語の意味と追加の暗黙の世界知識を組み合わせた句と文の意味論の意味も理解する必要はありません。音声支援デバイスの場合、人間の発話の機械固有の意味の学習試行錯誤で十分です。これに続いて、以前に生成された兆候の詳細な記号論的文脈化が続きます。 
[ABSTRACT]マシンの場合、（人間の）発話の意味は、それ自体のアクションの範囲によって定義されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Knowledge-Empowered Representation Learning for Chinese Medical Reading
  Comprehension: Task, Model and Resources -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CL/paper_11.html">
      <font color="black">Knowledge-Empowered Representation Learning for Chinese Medical Reading
  Comprehension: Task, Model and Resources</font>
    </a>
  </h2>
  <font color="black">高品質のデータセットは、マルチタスク中国医学MRCデータセット（CMedMRC）という名前の目的で手動で作成され、詳細な分析が行われます。実験により、CMedBERTは、コンテキスト認識と知識認識のトークン表現を融合することにより、強力なベースラインを常に上回っています。ただし、主に大規模なトレーニングデータが不足しているため、クローズドドメインMRCでの取り組みはほとんど行われていません。 
[ABSTRACT]医療分野のmrcタスクは広く研究されています。中国の医療バートモデルは、医療知識を事前トレーニング済みの言語モデルに融合します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Reasoning Strategies in End-to-End Differentiable Proving -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/cs.CL/paper_12.html">
      <font color="black">Learning Reasoning Strategies in End-to-End Differentiable Proving</font>
    </a>
  </h2>
  <font color="black">すべてのソースコードとデータセットは、https：//github.com/uclnlp/ctpでオンラインで入手できます。条件付き定理証明（CTP）を提示します。これは、勾配ベースの最適化によって最適なルール選択戦略を学習するNTPの拡張機能です。ただし、目標を説明するために可能なすべての証明パスを考慮する必要があるため、大規模なアプリケーションには適さないため、計算の複雑さによって制限されます。 
[ABSTRACT]これらのニューロシンボリックモデルは、解釈可能なルールを誘導し、バックコミュニケーションを介してデータから表現を学習することができます。これらのモデルは、予測の説明と、予測の説明に限定されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-13">
        <br><font color="black">2020-07-13</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: CRNNs for Urban Sound Tagging with spatiotemporal context -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/eess.AS/paper_0.html">
      <font color="black">CRNNs for Urban Sound Tagging with spatiotemporal context</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、DCASE 2020チャレンジのタスク5に参加するために使用したCRNNについて説明します。このコードは、GitHubリポジトリ（https://github.com/multitel-ai/urban-sound-tagging ..）から入手できます。このタスクは、時空間コンテキストを使用した階層的マルチラベルアーバンサウンドタギング。 
[ABSTRACT]このタスクは、マルチラベルのアーバンサウンドタギングの再構築に焦点を当てています。このタスクは、このタスクを使用して問題を理解することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: AMRConvNet: AMR-Coded Speech Enhancement Using Convolutional Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/eess.AS/paper_1.html">
      <font color="black">AMRConvNet: AMR-Coded Speech Enhancement Using Convolutional Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">AMRConvNetの平均改善点は、平均オピニオンスコア0.425-AMRビットレートが4.75kのリスニング品質目標（MOS-LQO）ポイント、およびAMRビットレートが12.2kの0.073 MOS-LQOポイントです。AMRConvNetは、AMRビットレート入力の堅牢性も示しました。 ..モデルは、入力音声と出力音声の両方の時間領域で直接動作しますが、時間領域の再構成損失と周波数領域の知覚損失を組み合わせて最適化します。 
[ABSTRACT] amrconvnetは、amr.itでエンコードされた音声に対して阿部と音声強調を実行する畳み込みニューラルネットワークで、平均0の改善をもたらしました。 425平均オピニオンスコア-4.75kのamrビットレートのリスニング品質目標（mos-lqo）ポイント、およびamrの0.al-拡張ネットワーク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Tail Performance of a Deliberation E2E ASR Model Using a
  LargeText Corpus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/eess.AS/paper_2.html">
      <font color="black">Improving Tail Performance of a Deliberation E2E ASR Model Using a
  LargeText Corpus</font>
    </a>
  </h2>
  <font color="black">浅いフュージョンは、事前トレーニングされたLMを推定時にE2Eモデルに組み込む方法として提案されていますが、非常に大きなテキストコーパスについてはまだ調査されておらず、ハイパーパラメータ設定に非常に敏感であることが示されています。ビーム検索..モデルサイズの影響を調査し、トレーニングセットのインテリジェントなプルーニングがパラメーター数を増やすよりも効果的であることを示します。この作業では、浅いフュージョンを適用して、非常に大きなテキストコーパスを状態に組み込みます。最新のE2EASRモデル。 
[ABSTRACT]短期e2easrは最新のe2mモデルです。これらにはテキストが含まれます-トレーニングへのデータのみです。これは、オーディオでは頻繁に発生しないテールワードの認識に重要です-テキストペア</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: A Computational Analysis of Real-World DJ Mixes using Mix-To-Track
  Subsequence Alignment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/eess.AS/paper_3.html">
      <font color="black">A Computational Analysis of Real-World DJ Mixes using Mix-To-Track
  Subsequence Alignment</font>
    </a>
  </h2>
  <font color="black">オーディオ機能がミックス内の元のトラックのテンポやキーの変更に影響されないように、サブシーケンスアラインメントを設定します。DJミックスがスタジオで作成されるか、ライブバージョンが音楽ストリーミングサービス用に録音されると、計算たとえば、トラック情報の抽出やDJテクニックの理解など、DJミックスを分析する方法は、研究の関心を集めています。 DJの音楽制作の創造的なプロセスを解明する。 
[ABSTRACT] DJミックスを分析するための最良の方法のいくつかは、トラック情報を抽出したり、DJテクニックを理解したりすることを含む研究を引き付けました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Similarity-and-Independence-Aware Beamformer: Method for Target Source
  Extraction using Magnitude Spectrogram as Reference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-25/eess.AS/paper_4.html">
      <font color="black">Similarity-and-Independence-Aware Beamformer: Method for Target Source
  Extraction using Magnitude Spectrogram as Reference</font>
    </a>
  </h2>
  <font color="black">インデックス用語：セミブラインドソース分離、類似性と独立性を意識したビームフォーマー、デフレ独立コンポーネント分析、ソースモデル。最尤推定による抽出問題を解決するために、類似性を反映できる2つのソースモデルタイプを紹介します。CHiME3データセットからの実験結果は、SIBFによって抽出されたターゲット信号が、 DNN。 
[ABSTRACT] sibfは、基準信号として大まかなスペクトログラムを使用してターゲット信号を抽出します。この方法は、ターゲット信号を抽出するsibfの方法に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br><font color="black">2020-06-01</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
