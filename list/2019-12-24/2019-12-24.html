<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<title>Akari-2019-12-24の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
  <div class="header-logo">
    <a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
  </div>
</header>
<input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">

<div class="menubar">
<span class="bar"></span>
<span class="bar"></span>
<span class="bar"></span>
</div>

<ul>
<li><a id="home" href="../../index.html">Home</a></li>
<li><a id="about" href="../../teamAkariとは.html">About</a></li>
<li><a id="contact" href="../../contact.html">Contact</a></li>
<li><a id="contact" href="../../list/newest.html">New Papers</a></li>
<li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
</ul>

</label>
<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Mixture of Inference Networks for VAE-based Audio-visual Speech
  Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-24/cs.SD/paper_0.html">
      Mixture of Inference Networks for VAE-based Audio-visual Speech
  Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたVAEを訓練するために、変分推論アプローチが導出されます。さらに、音声強調中に、視覚データを使用して潜在変数を初期化し、ノイズの多い音声スペクトログラムよりも堅牢な初期化を提供します。データ、つまり話者の唇の画像は、音声に関する有用かつ補足的な情報を提供します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-23">
        <br>2019-12-23
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: BioConceptVec: creating and evaluating literature-based biomedical
  concept embeddings on a large scale -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-24/cs.CL/paper_0.html">
      BioConceptVec: creating and evaluating literature-based biomedical
  concept embeddings on a large scale
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、BioConceptVecは、https：//github.com/ncbi-nlp/BioConceptVecを介して研究コミュニティおよび一般に無料で提供されています。評価結果は、BioConceptVecがすべてのタスクで既存の方法よりも優れたパフォーマンスを持っていることを示しています。 9つの異なる生物学的データセットからの2500万を超えるインスタンスで構成される複数のバイオインフォマティクスタスクで徹底的に評価されました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-23">
        <br>2019-12-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SberQuAD -- Russian Reading Comprehension Dataset: Description and
  Analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-24/cs.CL/paper_1.html">
      SberQuAD -- Russian Reading Comprehension Dataset: Description and
  Analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SberQuAD-ロシア語でのスタンフォードSQuADの大規模な類似体-は、科学界に適切に提示されていない貴重なリソースです。説明、徹底的な分析、およびベースラインの実験結果を提供することにより、このギャップを埋めます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-20">
        <br>2019-12-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Knowledge-guided Convolutional Networks for Chemical-Disease Relation
  Extraction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-24/cs.CL/paper_2.html">
      Knowledge-guided Convolutional Networks for Chemical-Disease Relation
  Extraction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、エンティティ埋め込みを使用して、ゲート畳み込みを伴う化学疾患ペアへのコンテキスト機能の伝播を制御します。提案モデルでは、まず、KBからエンティティ埋め込みと関係埋め込みを含む知識表現を学習します。事前知識を最大限に活用するためのモデルKCN。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-23">
        <br>2019-12-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Plug and Play Language Models: A Simple Approach to Controlled Text
  Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-24/cs.CL/paper_3.html">
      Plug and Play Language Models: A Simple Approach to Controlled Text
  Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      PPLMは柔軟性が高く、差別化可能な属性モデルの任意の組み合わせを使用してテキスト生成を制御できます。これにより、このペーパーで示した例以外の多様で創造的なアプリケーションが可能になります。広範な自動化された人間による注釈付きの評価は、属性の整合性と流showさを示します。サンプリングには、属性モデルからの勾配がLMの隠されたアクティベーションをプッシュし、生成を導く順方向および逆方向パスが含まれます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: TextNAS: A Neural Architecture Search Space tailored for Text
  Representation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-24/cs.CL/paper_4.html">
      TextNAS: A Neural Architecture Search Space tailored for Text
  Representation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      自動検索により、発見されたネットワークアーキテクチャは、テキスト分類および自然言語推論タスクに関するさまざまな公開データセットで最先端のモデルよりも優れています。したがって、テキスト表現に合わせた新しい検索スペースを提案します。サーチスペースは、さまざまなアプリケーションでNASが成功する前に重要な人間であると主張しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-23">
        <br>2019-12-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Language comparison via network topology -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-24/cs.CL/paper_5.html">
      Language comparison via network topology
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案された方法は、市販のラップトップ上で数十万の整列された文で構成される大きなコーパスに拡張できることを実証します。実験では、8つの異なるネットワークトポロジメトリックを使用し、並列コーパスでどのようにメソッドは、9つの選択された言語間の関係をモデル化するために使用できます。次に、ネットワークコミュニティ構造などのさまざまな高速ネットワークトポロジメトリックを言語間比較に使用する方法について説明します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-16">
        <br>2019-07-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Reweighted Proximal Pruning for Large-Scale Language Representation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-24/cs.CL/paper_6.html">
      Reweighted Proximal Pruning for Large-Scale Language Representation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SQuADおよびGLUEベンチマークスイートでの実験により、近位プルーニングBERTが事前プルーニングタスクとダウンストリームの複数の微調整タスクの両方で高いプルーン比で高い精度を維持することを示します。さらに、RPPにより大規模な一連の個別のデバイス（オンラインサーバー、携帯電話、エッジデバイスなど）でのBERTなどの最新の言語表現モデル。学ぶ。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-27">
        <br>2019-09-27
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Hunt Protagonist of Sentiment: Sentiment Analysis via Capsule Network
  with Sentiment-Aspect Reconstruction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-24/cs.CL/paper_7.html">
      Hunt Protagonist of Sentiment: Sentiment Analysis via Capsule Network
  with Sentiment-Aspect Reconstruction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CAPSARは、カプセルの階層構造を採用し、パッケージ化された感情-アスペクト再構成により、アスペクトと感情間の対話型パターンを学習します。レベル感情分析。CAPSARのカプセルは、共有ウェイトルーティングアルゴリズムを介して他のカプセルと通信できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-23">
        <br>2019-12-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Siamese Networks for Large-Scale Author Identification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-24/cs.CL/paper_8.html">
      Siamese Networks for Large-Scale Author Identification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      著者の帰属の文体的なタスクへの適用を検討し、多数の著者を含むデータセットで、分類ベースのアプローチと既存の類似性ベースのアプローチの両方を大幅に上回ることができることを示します。著者帰属は、テキストの著者を識別するプロセスです。シャムのネットワークは、ワンショット画像タスクの類似性の学習概念を開発するために、またNLPのセマンティック関連性のタスクにも使用されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-23">
        <br>2019-12-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Probing the phonetic and phonological knowledge of tones in Mandarin TTS
  models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-24/cs.CL/paper_9.html">
      Probing the phonetic and phonological knowledge of tones in Mandarin TTS
  models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      TTSモデルはいくつかの言語現象をキャプチャすることを考えると、特定の言語仮説を生成および検証するために使用できると主張されています。マンダリンの調音調音と音のサンディは、Tacotron 2とWaveGlowに送られて音声サンプルが生成され、音響分析と人間の評価の対象となりました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-23">
        <br>2019-12-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: LAMOL: LAnguage MOdeling for Lifelong Language Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-24/cs.CL/paper_10.html">
      LAMOL: LAnguage MOdeling for Lifelong Language Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      全体的に、LAMOLは以前の方法よりもかなりのマージンで優れており、通常LLLの上限と見なされるマルチタスクよりも2〜3％だけ悪いです。具体的には、LAMOLはタスクの解決とトレーニングサンプルの生成を同時に学ぶ言語モデルです。モデルが新しいタスク用にトレーニングされると、新しいタスク用のデータと一緒にトレーニング用の以前のタスクの擬似サンプルが生成されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-07">
        <br>2019-09-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Combining Context and Knowledge Representations for Chemical-Disease
  Relation Extraction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-24/cs.CL/paper_11.html">
      Combining Context and Knowledge Representations for Chemical-Disease
  Relation Extraction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、CDR抽出用のニューラルネットワークベースのアテンションモデル（NAM）を提案します。これは、文書内のコンテキスト情報とKB内の事前知識を最大限に活用します。とヘルスケア..ただし、以前の研究では、KBに存在する事前知識にあまり注意を払っていません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-23">
        <br>2019-12-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On the Weaknesses of Reinforcement Learning for Neural Machine
  Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-24/cs.CL/paper_12.html">
      On the Weaknesses of Reinforcement Learning for Neural Machine
  Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      MTの最も一般的なRLメソッドの1つが期待される報酬を最適化しないことを証明し、他のメソッドが収束するのに実行不可能なほど長い時間がかかることを示します。トレーニング信号、具体的には、分布曲線の形状の変化。実際、我々の結果は、MTでのRLプラクティスは、事前トレーニングされたパラメータがすでに正しい変換をもたらしている場合にのみパフォーマンスを改善する可能性が高いことを示唆しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-03">
        <br>2019-07-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Joint Embedding Learning of Educational Knowledge Graphs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-24/cs.CL/paper_13.html">
      Joint Embedding Learning of Educational Knowledge Graphs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、教育知識グラフでは、構造関係は焦点ではありません。一般に、知識グラフ埋め込み技術は、グラフの構造情報を保存するベクトル化された表現を学習することを目的としています。代わりに、グラフの豊富なリテラルがより価値があります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Continuous Speech Recognition using EEG and Video -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-24/eess.AS/paper_0.html">
      Continuous Speech Recognition using EEG and Video
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      EEG機能は、連続的な視覚音声認識システムのパフォーマンスを向上させるのに役立つことを示しています。認識を実行するための時間分類（CTC）ベースのエンドツーエンド自動音声認識（ASR）モデル。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-16">
        <br>2019-12-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Mixture of Inference Networks for VAE-based Audio-visual Speech
  Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-24/eess.AS/paper_1.html">
      Mixture of Inference Networks for VAE-based Audio-visual Speech
  Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたVAEを訓練するために、変分推論アプローチが導き出されます。これは、視覚データ、つまり話者の唇の画像が、音声に関する有用かつ補足的な情報を提供するという事実に基づいています。潜在変数を初期化して、ノイズの多い音声スペクトログラムよりも堅牢な初期化を提供します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-23">
        <br>2019-12-23
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: The Lands cycle modulates plasma membrane lipid organization and insulin sensitivity in skeletal muscle -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-24/biorxiv.physiology/paper_0.html">
      The Lands cycle modulates plasma membrane lipid organization and insulin sensitivity in skeletal muscle
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの変化は、リン脂質のアシル化に関与する酵素であるリゾホスファチジルコリンアシルトランスフェラーゼ3（LPCAT3）のより大きな発現と一致しました。驚くべきことに、LPCAT3（LPCAT3-MKO）の骨格筋特異的ノックアウトを持つマウスは、生体内でより高いインスリン感受性および生体外でのインスリン刺激骨格筋グルコース取り込みを伴う、より大きな筋肉リゾPC / PCを示しました。 。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-23">
        <br>2019-12-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transcriptomic responses to hypoxia in endometrial and decidual stromal cells -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-24/biorxiv.physiology/paper_1.html">
      Transcriptomic responses to hypoxia in endometrial and decidual stromal cells
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      DSCでは、低酸素はプロゲステロン受容体の既知の標的である転写因子のサブセットの転写状態のようなESFを回復し、低酸素がプロゲステロンシグナル伝達を部分的に妨害することを示唆している。酸素レベルの変動は月経時および胎盤中の両方で子宮内膜で機能的に関連しているためこのオーバーラップの遺伝子のプロモーター分析は、子宮内膜症関連転写の潜在的なドライバーとして低酸素がJun / FosおよびCEBP転写因子をアップレギュレートすることを示唆しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-23">
        <br>2019-12-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Age and life expectancy clocks based on machine learning analysis of mouse frailty -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-12-24/biorxiv.physiology/paper_2.html">
      Age and life expectancy clocks based on machine learning analysis of mouse frailty
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2番目のモデルは、残りの寿命についてトレーニングされ、AFRAID（脆弱性と死の分析）クロックを生成します。AFRAIDは、寿命と寿命延長介入の有効性を正確に1年前まで予測します。.Frailty Indices（FIs）in mouse費用対効果が高く、非侵襲的な健康の複合的な測定値ですが、健康と寿命を正確に予測できるかどうかは不明です。老化を遅らせるまたは逆行させる遺伝子および介入の特定は、非侵襲的な測定基準の欠如によって妨げられます前臨床モデルの平均余命を予測できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-23">
        <br>2019-12-23
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
