<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-08-06の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Neural Loop Combiner: Neural Network Models for Assessing the
  Compatibility of Loops -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.SD/paper_0.html">
      <font color="black">Neural Loop Combiner: Neural Network Models for Assessing the
  Compatibility of Loops</font>
    </a>
  </h2>
  <font color="black">モデルとデータセットを構築するためのコードのソースを開きました。このデータを使用して、ループの互換性を推定するための2つのタイプのモデルアーキテクチャを調査します。1つはシャムネットワークに基づくもの、もう1つは純粋な畳み込みニューラルネットワーク（CNN ）..再現性のために、無料の音楽アーカイブからのデータを管理しています。 
[ABSTRACT] automashupperとautomashupperは、ほとんどがルールベースであり、機械学習で改善できる可能性があります。既存の音楽からループを抽出して、互換性のあるループのポジティブな例を見つけます。ネガティブな例を選択するためのさまざまな戦略を提案して比較します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Data Cleansing with Contrastive Learning for Vocal Note Event
  Annotations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.SD/paper_1.html">
      <font color="black">Data Cleansing with Contrastive Learning for Vocal Note Event
  Annotations</font>
    </a>
  </h2>
  <font color="black">以前に提案されたデータクレンジングモデルでは、構造化は考慮されません（例：転写モデルの精度は、提案された戦略を使用してトレーニングすると、元のデータセットを使用してトレーニングしたときの精度と比較して大幅に向上することを示します。音楽データに。 
[ABSTRACT]以前に提案されたデータクレンジングモデルは、構造化を考慮していません。これらには、時間変化する構造化ラベルが含まれています。これらは、音楽のボーカルノートイベントアノテーションの有用性を示しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Acoustical classification of different speech acts using nonlinear
  methods -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.SD/paper_2.html">
      <font color="black">Acoustical classification of different speech acts using nonlinear
  methods</font>
    </a>
  </h2>
  <font color="black">クリップは、音色の変化に起因する知覚の違いを回避するために、同じ人物が（リズムのない平らなスピーチの形で）読み上げ、読み上げました。次に、5つの朗読の感情的な内容が、 50人の参加者のプールで実施されたリスニングテスト。朗読とスピーチは、スケーリング指数{\ alpha}を提供するトレンド除去変動分析（DFA）と呼ばれる最新の非線形技術を使用して分析されました。信号に存在する長距離相関の測定。 
[要約]さまざまな気分を伝えるさまざまな詩人の5つのよく知られているベンガル語の朗読。50人の参加者のプールで行われたリスニングテストの助けを借りて、5つの朗読の感情的な内容が標準化されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-15">
        <br><font color="black">2020-04-15</font>
      </time>
    </span>
</section>
<!-- paper0: CSTNet: Contrastive Speech Translation Network for Self-Supervised
  Speech Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.SD/paper_3.html">
      <font color="black">CSTNet: Contrastive Speech Translation Network for Self-Supervised
  Speech Representation Learning</font>
    </a>
  </h2>
  <font color="black">オーディオエンコーダーは、対照的な学習フレームワークで音声翻訳検索タスクを実行するようにトレーニングされています。この作業では、2つのモダリティ、つまり音声とそれに対応するテキスト翻訳の相関関係を利用して、音声表現学習用のマルチモーダル機械学習フレームワークを提供します。 ..スピーチに対応するテキスト翻訳を取得することは比較的簡単です。 
[ABSTRACT]多くの危険にさらされている言語には正字法の形式はありませんが、通常はバイリンガルで話者が多く、リソースの高い言語でトレーニングされています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-04">
        <br><font color="black">2020-06-04</font>
      </time>
    </span>
</section>
<!-- paper0: MusPy: A Toolkit for Symbolic Music Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.SD/paper_4.html">
      <font color="black">MusPy: A Toolkit for Symbolic Music Generation</font>
    </a>
  </h2>
  <font color="black">結果は、一般的に使用されるさまざまなデータセット間のドメイン重複のマップを提供し、一部のデータセットには他よりも代表的なジャンル間サンプルが含まれていることを示しています。これらの結果は、データセット分析とともに、将来の研究でデータセットを選択するためのガイドとして役立つ可能性があります。その可能性を示すために、MusPyが現在サポートしている11のデータセットの統計分析を示します。 
[ABSTRACT] muspyは、データセット管理、データI / O、データ前処理、モデル評価など、音楽生成システムの必須コンポーネント用の使いやすいツールを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: A study on more realistic room simulation for far-field keyword spotting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.SD/paper_5.html">
      <font color="black">A study on more realistic room simulation for far-field keyword spotting</font>
    </a>
  </h2>
  <font color="black">ソースコードはPyroomacousticsパッケージで利用可能になり、他の人がこれらの手法を作業に組み込むことができるようになります。クリーンでノイズの多い遠方場条件下での一連の再録音の差し控えにより、最大$ 35.8 \％$の相対的な改善を示します一般的に使用されている（単一吸収係数）画像ソース法を超えています。このために、室内インパルス応答（RIR）生成に次の要素を組み込むことの影響を調べます。空気吸収、表面および周波数依存係数マテリアル、確率的レイトレーシング。 
[ABSTRACT]クリーンでノイズのある遠方場の状態の再記録の保留セットで、最大35ドルを示しました。一般的に使用されている部屋のインパルス応答（riyr）画像ソースメソッドよりも大幅に改善されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-04">
        <br><font color="black">2020-06-04</font>
      </time>
    </span>
</section>
<!-- paper0: On the Characterization of Expressive Performance in Classical Music:
  First Results of the Con Espressione Game -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.SD/paper_6.html">
      <font color="black">On the Characterization of Expressive Performance in Classical Music:
  First Results of the Con Espressione Game</font>
    </a>
  </h2>
  <font color="black">このペーパーと一緒に公開するデータセットは、テンポやダイナミクスカーブなどの説明的なオーディオ機能だけでなく、手動で修正したスコアとパフォーマンスの調整を追加することで充実しました。（2）の主な次元（または軸）は何ですかこれから浮かび上がる表情豊かなキャラクター。 ; （3）パフォーマンスの測定可能なパラメーター（例：テンポ、ダイナミクス）と、機械学習モデル（例：構音、覚醒）で予測できる中高レベルの機能は、これらの表現的次元とどのように関連していますか。 
[要約]表現力豊かなキャラクターの500以上の説明をオンラインアンケートで分析しました。これらは、クラシックピアノ曲からの9つの抜粋の45の演奏を説明するために使用されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Content based singing voice source separation via strong conditioning
  using aligned phonemes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.SD/paper_7.html">
      <font color="black">Content based singing voice source separation via strong conditioning
  using aligned phonemes</font>
    </a>
  </h2>
  <font color="black">音素行列は、機能ごとの線形変調（FiLM）レイヤーを制御するパラメーターを取得するために埋め込まれます。音素条件付けをうまく適用して、歌声の音源分離を改善できることを示しています。歴史的に、音楽情報検索の研究者は主にスコアに焦点を当ててきました-情報に基づいたソースの分離。ただし、最近のアプローチでは、歌詞に基づいたソースの分離を検討しています。 
[ABSTRACT]新しいシステムは、ターゲットのソースに関する以前の情報を使用します。モデルは、非整列の歌詞で弱い条件付けを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Architecture Search on Acoustic Scene Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.SD/paper_8.html">
      <font color="black">Neural Architecture Search on Acoustic Scene Classification</font>
    </a>
  </h2>
  <font color="black">畳み込みニューラルネットワークは、音響シーン分類（ASC）タスクで広く採用されていますが、一般に重い計算負荷を負っています。評価セットは、ベースラインネットワークと比較してFLOPを25％節約しながら、新しい最先端のパフォーマンスをマークします。さらに、最近のニューラルアーキテクチャ検索で提案されたベースラインに基づいて構築された動的アーキテクチャスペースを探索します（ NAS）パラダイム。最初にすべての候補ネットワークを組み込んだスーパーネットをトレーニングし、次によく知られた進化的アルゴリズムNSGA-IIを適用して、より高い精度と低い計算コストでより効率的なネットワークを発見します。 
[ABSTRACT]畳み込みカーネルを単方向カーネルに置き換えて、空間次元の特徴を抽出します。実験結果は、検索されたネットワークがascタスクに対応しており、タスク全体の90.3％を達成していることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-30">
        <br><font color="black">2019-12-30</font>
      </time>
    </span>
</section>
<!-- paper0: Speech-to-Singing Conversion based on Boundary Equilibrium GAN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.SD/paper_9.html">
      <font color="black">Speech-to-Singing Conversion based on Boundary Equilibrium GAN</font>
    </a>
  </h2>
  <font color="black">再現性のために、コードは紙の出版時にGitHubリポジトリで公開されます。私たちの定量的および定性的分析は、提案されたモデルが、既存の敵対的訓練を受けていないベースラインよりもはるかに自然な歌声を生成することを示しています。入力、およびオプションでターゲットの歌唱のF0輪郭である提案モデルは、漸進的に成長するエンコーダー/デコーダーアーキテクチャと境界平衡GAN損失関数を備えた歌声信号を出力として生成します。 
[要約]提案されたモデルは、既存の非発声レベルよりもはるかに自然な歌声を生成します。これにより、発声に対する発声の使用を削減するさまざまな方法を開発するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br><font color="black">2020-05-28</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Combining Anatomical and Functional Networks for Neuropathology
  Identification: A Case Study on Autism Spectrum Disorder -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.IV/paper_0.html">
      <font color="black">Combining Anatomical and Functional Networks for Neuropathology
  Identification: A Case Study on Autism Spectrum Disorder</font>
    </a>
  </h2>
  <font color="black">自閉症スペクトラム障害（ASD）の有病率が増加している間、研究は共通の病因学的および病態生理学的基盤を特定するための努力を続けています。次に、周波数信号に関連する機能を構築するために、グラフ信号処理（GSP）の新興分野からツールを借りますこれらの信号の特徴..これらの特徴を高度に識別できるようにするために、Fukunaga-Koontz変換の拡張を適用します。 
[ABSTRACT]これらの機能に加えて、fukunagaの拡張機能-koontz変換を使用して、これらの機能を高度に区別します。結果として得られる決定木は、公に利用可能な自閉症診断データ交換の最新の方法を上回ります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-25">
        <br><font color="black">2019-04-25</font>
      </time>
    </span>
</section>
<!-- paper0: MultiCheXNet: A Multi-Task Learning Deep Network For Pneumonia-like
  Diseases Diagnosis From X-ray Scans -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.IV/paper_1.html">
      <font color="black">MultiCheXNet: A Multi-Task Learning Deep Network For Pneumonia-like
  Diseases Diagnosis From X-ray Scans</font>
    </a>
  </h2>
  <font color="black">最後に、転移学習を使用して、目に見えない肺炎のような疾患の分類子を微調整します。共通のエンコーダには、効率的な計算という別の利点があり、個別のモデルと比較して推論時間を短縮します。MTLアーキテクチャは、ジョイントまたはラベルの付いていないデータセットを切り離します。 
[ABSTRACT]私たちのアーキテクチャの共通エンコーダーは、有用な共通機能をキャプチャできます。専用デコーダーヘッドは、問題-特定の機能をキャプチャできます。これらのビデオは、転移学習を使用して分類子を微調整できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: An Unsupervised Generative Neural Approach for InSAR Phase Filtering and
  Coherence Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.IV/paper_2.html">
      <font color="black">An Unsupervised Generative Neural Approach for InSAR Phase Filtering and
  Coherence Estimation</font>
    </a>
  </h2>
  <font color="black">それにもかかわらず、この研究はほとんど未踏です。このようにして、InSARデータ分布を直接学習する、ジョイントフェーズフィルタリングとコヒーレンス推定のためのCNNベースの生成モデル「GenInSAR」を提案します。並列計算の進歩により、畳み込みニューラルネットワーク（CNN）が加速しました）、視覚的なパターン認識における人間のパフォーマンスよりも優れているため、CNNはWAMに適しています。 
[ABSTRACT] genferferferferのインサーデータは、監視されていないレーダー画像の分析に役立ちます。genferferferferのインサーレーダートレーニングとシミュレートされたノイズの多い画像は、他の5つのgeninsarのデジタルトレーニングより優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-27">
        <br><font color="black">2020-01-27</font>
      </time>
    </span>
</section>
<!-- paper0: SODA: Detecting Covid-19 in Chest X-rays with Semi-supervised Open Set
  Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.IV/paper_3.html">
      <font color="black">SODA: Detecting Covid-19 in Chest X-rays with Semi-supervised Open Set
  Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">これらの2つの重要な問題に対処するために、半教師付きオープンセットドメイン適応設定でのCOVID-19胸部X線画像分類の問題を定式化し、新しいドメイン適応方法である半教師付きオープンセットドメイン敵対ネットワークを提案します。 （SODA）。ただし、異なるドメインのデータセット間で直接転送すると、2つの問題が原因でCNNのパフォーマンスが低下する可能性があります。それは、生物医学イメージングデータセットに存在する大きなドメインシフトとCOVID-19胸部X線の非常に小さなスケールです。データセット..これらの作業のほとんどは、最初に既存の大規模胸部X線画像データセットでたたみ込みニューラルネットワーク（CNN）をトレーニングし、次にそれをはるかに小さなスケールでCOVID-19データセットで微調整します。 
[要約]ディープラーニングメソッドは、covid-19胸部X線画像の自動検出に積極的な役割を果たしています。最近の作品は2020年の初めに記録されました。ただし、異なるドメインのデータセット間で直接転送すると、cnnのパフォーマンスが低下する可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-22">
        <br><font color="black">2020-05-22</font>
      </time>
    </span>
</section>
<!-- paper0: Fully Self-Gated Whole-Heart 4D Flow Imaging from a Five-Minute Scan -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.IV/paper_4.html">
      <font color="black">Fully Self-Gated Whole-Heart 4D Flow Imaging from a Five-Minute Scan</font>
    </a>
  </h2>
  <font color="black">患者-ReVEAL4Dからのフローの定量化は2D-PCリファレンスとよく一致します。 L1-SENSEのピーク速度とピーク流量は大幅に過小評価されています。 
[ABSTRACT] reveal4dは、8人の健康なボランティアと2人の患者からのデータを使用して検証され、l1-senseと呼ばれる圧縮センシング手法と比較されます。データは、地図製作者のサンプリングを使用して収集され、自己ゲーティング信号を使用して呼吸ビンと心臓ビンに分類されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-19">
        <br><font color="black">2020-04-19</font>
      </time>
    </span>
</section>
<!-- paper0: Fully Automated and Standardized Segmentation of Adipose Tissue
  Compartments by Deep Learning in Three-dimensional Whole-body MRI of
  Epidemiological Cohort Studies -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.IV/paper_5.html">
      <font color="black">Fully Automated and Standardized Segmentation of Adipose Tissue
  Compartments by Deep Learning in Three-dimensional Whole-body MRI of
  Epidemiological Cohort Studies</font>
    </a>
  </h2>
  <font color="black">代謝性疾患のリスクが高い個人を正しく識別して表現型を決定するには、脂肪組織を皮下および内臓脂肪組織に確実に自動分割する必要があります。この遡及的研究では、1000例（66 $ \ pm $ 13年間、523女性）Tuebingen Family Studyおよびドイツ糖尿病研究センター（TUEF / DZD）、ならびにモデルトレーニング用のドイツ国立コホート（NAKO）データベースの300ケース（53 $ \ pm $ 11年、女性152人） 、検証、およびコホート間の転移学習によるテスト。セグメンテーションマスクと脂肪組織プロファイルは、自動的に紹介医師に報告されます。 
[ABSTRACT]高速（5-adicut）で信頼性の高い組織の細分化は、3d全身mrデータセットから高いダイスオーバーラップ（0. 94）、感度（96. 6％）および精度（98. 4％）で取得できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: A coarse-to-fine framework for unsupervised multi-contrast MR image
  deformable registration with dual consistency constraint -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.IV/paper_6.html">
      <font color="black">A coarse-to-fine framework for unsupervised multi-contrast MR image
  deformable registration with dual consistency constraint</font>
    </a>
  </h2>
  <font color="black">提案された方法は、555ケースからなる臨床データセットで評価され、有望なパフォーマンスが達成されました。登録速度に関して、この方法は、同じCPUでテストした場合、最も競争力のあるSyNの方法よりも約17倍高速です。さらに、登録のパフォーマンスを向上させるために、二重整合性制約と新しい事前知識ベースの損失関数が開発されています。 
[要約]提案された方法は、555ケースからなる臨床データセットで評価されています。これは、マルチステップ反復プロセスと複雑な画像前処理操作を取り除くように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Long-term Visual Dynamics with Region Proposal Interaction
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.IV/paper_7.html">
      <font color="black">Learning Long-term Visual Dynamics with Region Proposal Interaction
  Networks</font>
    </a>
  </h2>
  <font color="black">この目的のために、私たちは、領域提案相互作用ネットワーク（RPIN）を提案します。これにより、潜在領域提案機能空間での各オブジェクトの軌跡が理由になります。コードはhttps://github.com/HaozhiQi/RPIN。で入手できます。おかげでシンプルでありながら効果的なオブジェクト表現である私たちのアプローチは、予測品質とダウンストリームタスクを計画する能力の両方の点で大幅なマージンで従来の方法よりも優れており、新しい環境にも一般化できます。 
[ABSTRACT]長期予測には、短期モデルによる迅速な再計画が必要です。長期にわたってオブジェクト間およびオブジェクトと環境の相互作用をキャプチャできるオブジェクト表現の構築を目指しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodality Biomedical Image Registration using Free Point Transformer
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.IV/paper_8.html">
      <font color="black">Multimodality Biomedical Image Registration using Free Point Transformer
  Networks</font>
    </a>
  </h2>
  <font color="black">前立腺MRとまばらに取得した超音波画像を使用したマルチモーダル登録タスクでは、FPTは他の固定および非固定登録方法と比較して同等または改善された結果をもたらします。FPTは、変数の順序付けられていないソースおよびターゲットポイントセットを受け入れるグローバルフィーチャーエクストラクターで構築されます。サイズ..抽出された特徴は、共有ソースの多層パーセプトロンポイント変換モジュールによって条件付けされ、各ソースポイントの変位ベクトルを予測して、ターゲットスペースに変換します。 
[ABSTRACT] fptは、順序付けされていないソースポイントとターゲットポイントの可変サイズのセットを受け入れるグローバルフィーチャエクストラクタで構築されます。ポイントトランスフォーマモジュールは、空間変換の予測において近傍も滑らかさも想定せず、グローバルフィーチャエクストラクタとともに、データ-教師なし損失関数を使用する主導型の方法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Multiple Sclerosis Lesion Activity Segmentation with Attention-Guided
  Two-Path CNNs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.IV/paper_9.html">
      <font color="black">Multiple Sclerosis Lesion Activity Segmentation with Attention-Guided
  Two-Path CNNs</font>
    </a>
  </h2>
  <font color="black">単一ボリュームの病変セグメンテーションの成功にもかかわらず、ディープラーニングアプローチは病変活動セグメンテーションではまだまれです。このタスクでは、CNNは2つの点からの情報をさまざまな方法で組み合わせて設計および評価されます。この作業では、畳み込みニューラルネットワーク（CNN）は、2つの時点からの病変活動セグメンテーションについて調査されます。 
[ABSTRACT] scorching Imaging（mri）は、疾患の進行を追跡するために使用されます。通常、個々のmriスキャンの病変活動を分析するために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchical Amortized Training for Memory-efficient High Resolution 3D
  GAN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.IV/paper_10.html">
      <font color="black">Hierarchical Amortized Training for Memory-efficient High Resolution 3D
  GAN</font>
    </a>
  </h2>
  <font color="black">また、同様の階層構造を持つエンコーダーをモデルに組み込んで、画像から特徴を抽出します。トレーニング中に、画像の低解像度バージョンとランダムに選択された高解像度のサブボリュームを同時に生成する階層構造を採用します高解像度画像。3D胸部CTと脳MRIの実験は、私たちのアプローチが画像生成、画像再構成、および臨床関連変数の予測において最先端の技術よりも優れていることを示しています。 
[ABSTRACT]最新の3Dガンモデルは低解像度の医療画像でトレーニングされています。さらに、このモデルは完全な高解像度画像を直接生成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Structure Preserving Stain Normalization of Histopathology Images Using
  Self-Supervised Semantic Guidance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.IV/paper_11.html">
      <font color="black">Structure Preserving Stain Normalization of Histopathology Images Using
  Self-Supervised Semantic Guidance</font>
    </a>
  </h2>
  <font color="black">生成的敵対的ネットワーク（GAN）ベースのスタイル転送は、組織病理学の色染色の正規化における最新技術ですが、組織の構造情報を明示的に統合していません。この方法では、既存の方法に比べて大きな利点である手動のセグメンテーションマップは必要ありません。 。提案されたスキームは、他の色正規化手法よりも優れており、分類とセグメンテーションのパフォーマンスが向上します。 
[要旨]セマンティックガイダンスをガンベースの染色正規化フレームワークに組み込むには、自己監視アプローチが必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Extracting and Leveraging Nodule Features with Lung Inpainting for Local
  Feature Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.IV/paper_12.html">
      <font color="black">Extracting and Leveraging Nodule Features with Lung Inpainting for Local
  Feature Augmentation</font>
    </a>
  </h2>
  <font color="black">ネットワークは、結節を含むパッチで現実的で健康な組織と構造を生成するために適用されます。ただし、結節を含むスキャンの可用性が限られていることと、CXRでの結節の微妙な特性のため、最新の方法はうまく機能しません結節分類について..結節は、修復された表現では完全に削除されます。 
[要約]この論文では、局所結節を抽出することにより局所特徴を増大させる方法を提案します。これらの特徴は修復された表現から削除されます。結節はスキャンのキャプチャーによって削除されます。その後、結節の位置から削除されます。肺領域</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised seismic facies classification using deep convolutional
  autoencoder -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.IV/paper_13.html">
      <font color="black">Unsupervised seismic facies classification using deep convolutional
  autoencoder</font>
    </a>
  </h2>
  <font color="black">教師なし地震相分類にディープたたみ込みオートエンコーダを適用します。手動でラベル付けされた例は必要ありません。相マップは、入力データから取得された深部特徴ベクトルをクラスタリングすることによって生成されます。地震探査のサイズと複雑さが増し、地震相の手動によるラベル付けは重要な課題となっています。 
[要旨]地震相の解釈のための自動方法は、特定の通訳者の手作業と主観性を大幅に削減できる可能性があります。これらのアプローチはデータ駆動型であり、ネットワークトレーニングには大きなラベル付きデータセットが必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: A feature-supervised generative adversarial network for environmental
  monitoring during hazy days -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.IV/paper_14.html">
      <font color="black">A feature-supervised generative adversarial network for environmental
  monitoring during hazy days</font>
    </a>
  </h2>
  <font color="black">第二に、基本的なGANの定式化は、知覚損失、スタイル損失、および特徴正則化損失を導入することによって変更され、より良い結果を生成します。最初に、かすんできれいな画像のペアが入力として使用され、エンコードプロセスを監視し、高品質の特徴マップを取得します。 ..このペーパーでは、4つの主要な技術的貢献が行われています。 
[要約]提案された方法は、現在の状態よりも優れたパフォーマンスを実現しました-合成データセットと実際のリモートセンシング画像の両方で最先端の方法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: A DICOM Framework for Machine Learning Pipelines against Real-Time
  Radiology Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.IV/paper_15.html">
      <font color="black">A DICOM Framework for Machine Learning Pipelines against Real-Time
  Radiology Images</font>
    </a>
  </h2>
  <font color="black">Nifflerはさらに、MLパイプラインからの結果を匿名化された方法で共有できるようにします。Nifflerは19か月以上安定して動作しており、部門でいくつかの研究プロジェクトをサポートしています。このペーパーでは、そのアーキテクチャとその使用例の3つ：リアルタイムでの画像からの下大静脈（IVC）フィルターの検出、スキャナーの使用状況の識別、スキャナーの時計の較正。 
[ABSTRACT] nifflerは、研究センターでのmlパイプラインの実行を可能にする統合フレームワークを提案します。nifflerは、mlパイプラインからの結果を特定できない方法で共有できるようにします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br><font color="black">2020-04-16</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Learning Canonical Representations for Scene Graph to Image Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_0.html">
      <font color="black">Learning Canonical Representations for Scene Graph to Image Generation</font>
    </a>
  </h2>
  <font color="black">私たちのモデルは、大きなシーングラフの経験的パフォーマンスの向上、入力シーングラフのノイズに対する堅牢性、および意味的に同等のグラフの一般化を示しています。最後に、3つの異なるベンチマーク（ビジュアルゲノム、COCO、およびCLEVR）でのモデルのパフォーマンスの向上を示します。 。データから正準グラフ表現を学習することでこれらの問題に対処し、複雑な視覚シーンの画像生成を改善する新しいモデルを提示します。 
[ABSTRACT]モデルはビジュアルゲノム、ココ、clevrによって作成されました。3つの異なるレベルでモデルのパフォーマンスが向上しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-16">
        <br><font color="black">2019-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Breaking the Curse of Space Explosion: Towards Efficient NAS with
  Curriculum Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_1.html">
      <font color="black">Breaking the Curse of Space Explosion: Towards Efficient NAS with
  Curriculum Search</font>
    </a>
  </h2>
  <font color="black">提案された検索戦略により、私たちのカリキュラムニューラルアーキテクチャ検索（CNAS）メソッドは検索効率を大幅に向上させ、既存のNASメソッドよりも優れたアーキテクチャを見つけます。CIFAR-10とImageNetに関する広範な実験は、提案されたメソッドの有効性を実証しています。大きな検索スペースを考えると、宇宙爆発の非常に困難な問題に直面する可能性があります。 
[要旨]考えられるすべての優れたアーキテクチャをカバーするには、数十億の候補アーキテクチャを備えた非常に大きな検索スペースで検索する必要があります。ただし、コンピューティングリソースの制限により、サンプリングできるのはごく一部のアーキテクチャのみであり、不十分です。トレーニングの情報</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo
  Collections -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_2.html">
      <font color="black">NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo
  Collections</font>
    </a>
  </h2>
  <font color="black">NeRF-Wをダビングしたシステムを有名なランドマークのインターネット写真コレクションに適用することで、未知で交絡する要素にもかかわらず、写真のように空間的に一貫したシーン表現を生成し、最先端技術を大幅に改善します。制御された設定の下でキャプチャされた静的な被写体の画像では、可変照明や一時的なオクルーダーなど、制御されていない画像で多くのユビキタスな現実世界の現象をモデル化することはできません。この作業では、これらに対処するためにNeRFに一連の拡張機能を導入します問題により、インターネットから取得した非構造化画像コレクションからの正確な再構成が可能になります。 
[ABSTRACT]私たちは、多層パーセプトロンの重みを使用してシーンの容積密度と色をシミュレートする神経放射輝度フィールド（neunding）に基づいて構築します。インターネットから取得した非構造化画像コレクションから正確な再構成を可能にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: MultiCheXNet: A Multi-Task Learning Deep Network For Pneumonia-like
  Diseases Diagnosis From X-ray Scans -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_3.html">
      <font color="black">MultiCheXNet: A Multi-Task Learning Deep Network For Pneumonia-like
  Diseases Diagnosis From X-ray Scans</font>
    </a>
  </h2>
  <font color="black">私たちの実験的なセットアップには、3つのタスクのベースラインパフォーマンスがMTLアーキテクチャのパフォーマンスと比較されるさまざまなデータセットが含まれます。さらに、COVID-19データセットへの転移学習モードを評価します。アーキテクチャ分類ヘッド..アーキテクチャのトレーニングは、慎重に設計されたプロトコルに従います。このプロトコルは、ジョイントMTLモデルに統合される前に、特殊なデータセットでさまざまなサブモデルを事前トレーニングします。 
[ABSTRACT]私たちのアーキテクチャの共通エンコーダーは、有用な共通機能をキャプチャできます。専用デコーダーヘッドは、問題-特定の機能をキャプチャできます。これらのビデオは、転移学習を使用して分類子を微調整できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Graph Signal Processing for Geometric Data and Beyond: Theory and
  Applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_4.html">
      <font color="black">Graph Signal Processing for Geometric Data and Beyond: Theory and
  Applications</font>
    </a>
  </h2>
  <font color="black">この分野での研究をさらに進めるために、幾何学的データとグラフの間、さまざまな幾何学的データモダリティ間、およびスペクトル/節点グラフをつなぐことにより、幾何学的データのGSP方法論の最初のタイムリーで包括的な概要を提供します。フィルタリング技術..未解決の問題と課題について簡単に説明します。また、最近開発されたグラフニューラルネットワーク（GNN）についても説明し、これらのネットワークの動作をGSPの観点から解釈します。 
[ABSTRACT]パターン信号処理（gsp）は、信号処理コミュニティで急速に発展している分野です。不規則なドメインに存在し、幾何データの多数のアプリケーションで重要な役割を果たす信号を処理できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: SODA: Detecting Covid-19 in Chest X-rays with Semi-supervised Open Set
  Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_5.html">
      <font color="black">SODA: Detecting Covid-19 in Chest X-rays with Semi-supervised Open Set
  Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">これらの作業のほとんどは、最初に既存の大規模胸部X線画像データセットでたたみ込みニューラルネットワーク（CNN）をトレーニングし、次に、はるかに小さいスケールでCOVID-19データセットを使用して微調整します。これらに対処するために2つの重要な問題、我々は半教師付きオープンセットドメイン適応設定でCOVID-19胸部x線画像分類の問題を定式化し、新しいドメイン適応方法である半教師付きオープンセットドメイン敵対ネットワーク（SODA）を提案します。 、異なるドメインからのデータセット間での直接転送は、2つの問題、生物医学イメージングデータセットに存在する大きなドメインのシフト、およびCOVID-19胸部X線データセットの非常に小さなスケールにより、CNNのパフォーマンスの低下につながる可能性があります。 
[要約]ディープラーニングメソッドは、covid-19胸部X線画像の自動検出に積極的な役割を果たしています。最近の作品は2020年の初めに記録されました。ただし、異なるドメインのデータセット間で直接転送すると、cnnのパフォーマンスが低下する可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-22">
        <br><font color="black">2020-05-22</font>
      </time>
    </span>
</section>
<!-- paper0: Attribute analysis with synthetic dataset for person re-identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_6.html">
      <font color="black">Attribute analysis with synthetic dataset for person re-identification</font>
    </a>
  </h2>
  <font color="black">知る限りでは、これは合成データセットの属性の側面から個人のIDを明示的に分析する最初の試みです。私たちの研究は、データセットの構築と将来の実用的な使用に役立つ洞察も提供しています。それに基づいて、大規模な規模の合成データセット。照明や視点などのさまざまな属性から多様化およびカスタマイズされます。 
[ABSTRACT]合成データエンジンの人気から恩恵を受ける合成データからの学習は、驚くべきパフォーマンスを達成しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-12">
        <br><font color="black">2020-06-12</font>
      </time>
    </span>
</section>
<!-- paper0: Intra-Camera Supervised Person Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_7.html">
      <font color="black">Intra-Camera Supervised Person Re-Identification</font>
    </a>
  </h2>
  <font color="black">たとえば、提案されたICS個人のre-id設定では、MATEはMarket-1501で88.7％のランク1スコアを生み出し、教師なし学習モデルを大幅に上回り、従来の完全教師付き学習競合他社と密接に接近しています。これにより、最も時間のかかる面倒な-カメラのIDラベル付けプロセス。人間による注釈の労力を大幅に削減します。一方、教師なしのre-idメソッドでは、IDラベル情報は必要ありませんが、通常、モデルのパフォーマンスがはるかに劣っており不十分です。 
[ABSTRACT]これには退屈なデータ収集と注釈プロセスが必要であり、re-idアプリケーションのスケーラビリティが低下します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-12">
        <br><font color="black">2020-02-12</font>
      </time>
    </span>
</section>
<!-- paper0: F2GAN: Fusing-and-Filling GAN for Few-shot Image Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_8.html">
      <font color="black">F2GAN: Fusing-and-Filling GAN for Few-shot Image Generation</font>
    </a>
  </h2>
  <font color="black">この論文では、少数の画像だけで新しいカテゴリーの現実的で多様な画像を生成するために、融合と充填の生成的敵対的ネットワーク（F2GAN）を提案します。少数の画像のみから画像を生成することを目的とした少数ショット画像生成新しいカテゴリのために、いくつかの研究関心が集まっています。特定のカテゴリの画像を生成するために、既存のディープジェネレーティブモデルは通常、豊富なトレーニング画像に依存しています。 
[ABSTRACT]私たちのf2versでは、フュージョンジェネレーターは条件付き画像の高レベルの機能を融合し、非ローカルアテンションモジュールを使用して、対応する低レベルの詳細を入力して新しい画像を生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Point Proposal Network: Accelerating Point Source Detection Through Deep
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_9.html">
      <font color="black">Point Proposal Network: Accelerating Point Source Detection Through Deep
  Learning</font>
    </a>
  </h2>
  <font color="black">シミュレートされたMeerKAT画像で測定された結果は、主要な代替アプローチと比較すると精度は劣りますが、代替アプローチとは異なり、PPNはソース検出をより高速に実行し、大きな画像にスケーリングできることを示しています。ポイントソース検出は、 SKAパスファインダー望遠鏡によって行われた最近の調査..この論文は、高速音源検出に深い畳み込みニューラルネットワークを利用する点音源検出器（PPN）を提案します。 
[ABSTRACT]新しい調査画像では、サイズがギガピクセルからテラピクセルに大幅に増加します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Structural Plan of Indoor Scenes with Personalized Preferences -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_10.html">
      <font color="black">Structural Plan of Indoor Scenes with Personalized Preferences</font>
    </a>
  </h2>
  <font color="black">データセットの数値結果は、最新の方法と比較した提案モデルの有効性を示しています。特に、モデルは、抽象グラフの抽出、条件付きグラフの生成、および条件付きシーンのインスタンス化で構成されています。プロのデザイナーによる実際の11000設計を含むインテリアレイアウトデータセット。 
[要約]提案されたモデルは、プロパティ所有者の好みに従ってオブジェクトのレイアウトを生成できます。さらに、モデルを使用してオブジェクトのデザインを作成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic Language Binding in Relational Visual Reasoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_11.html">
      <font color="black">Dynamic Language Binding in Relational Visual Reasoning</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、複数のオブジェクト関係が関与する高度な質問応答タスクで他の方法よりも優れています。私たちは、視覚的質問応答にアプリケーションを使用して、視覚的およびテキストの両方のドメインにまたがる動的な関係構造を持つ最初の神経推論方法である言語バインディングオブジェクトグラフネットワークを提示します。このような発見された動的グラフは、最終的な回答のコンパクトな表現を繰り返し推定するマルチステップの知識の組み合わせと改良を促進します。 
[ABSTRACT]ネットワークは他の推論モデルと比較して効率的に学習しています。これらの構造は条件付きのデュアルドメインオブジェクトの依存関係を反映しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: EagleEye: Fast Sub-net Evaluation for Efficient Neural Network Pruning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_12.html">
      <font color="black">EagleEye: Fast Sub-net Evaluation for Efficient Neural Network Pruning</font>
    </a>
  </h2>
  <font color="black">MobileNet V1のコンパクトモデルの剪定のより困難な実験でさえ、EagleEyeは70.9％の最高精度を達成し、全体で50％の演算（FLOP）を剪定します。 ..この強力な相関関係により、剪定された候補を実際に微調整することなく、潜在的な精度が最も高いものをすばやく見つけることができます。 
[ABSTRACT]多くのアルゴリズムは、さまざまな評価方法を導入することにより、枝刈りされたサブネットのモデルパフォーマンスを予測しようとします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Project to Adapt: Domain Adaptation for Depth Completion from Noisy and
  Sparse Sensor Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_13.html">
      <font color="black">Project to Adapt: Domain Adaptation for Depth Completion from Noisy and
  Sparse Sensor Data</font>
    </a>
  </h2>
  <font color="black">実際のドメインまたは追加のセンサーでの注釈なしで、合成データからトレーニングされた疎から密な深度の補完のためのドメイン適応アプローチを提案します。深度の補完は、疎な深度の入力から密な深度マップを予測することを目的としています。これらのモジュールをKITTI深度完了ベンチマークの最新技術と比較して評価すると、大幅な改善が見られます。 
[ABSTRACT]私たちのアプローチは、rgb LIDAR設定で実際のセンサーノイズをシミュレートします。3つのモジュールで構成されます。投影を介して合成ドメインで実際のLIDAR入力をシミュレーションし、監視のために実際のノイズの多いLIDARをフィルタリング</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-03">
        <br><font color="black">2020-08-03</font>
      </time>
    </span>
</section>
<!-- paper0: A Benchmark of Medical Out of Distribution Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_14.html">
      <font color="black">A Benchmark of Medical Out of Distribution Detection</font>
    </a>
  </h2>
  <font color="black">結論：特徴表現の単純なバイナリ分類器が最も精度が高く、平均してAUPRCであることがわかります。これらの画像には、診断の前にOoDDメソッドでフラグを付ける必要があります。分布外のサンプルでは、トレーニング分布に近い画像を認識できません。 
[要約]問題は実際にはどのoprdメソッドを使用する必要があるか不明です。これらの画像には、診断前にooddドメインによってフラグを立てる必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Fully Automated and Standardized Segmentation of Adipose Tissue
  Compartments by Deep Learning in Three-dimensional Whole-body MRI of
  Epidemiological Cohort Studies -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_15.html">
      <font color="black">Fully Automated and Standardized Segmentation of Adipose Tissue
  Compartments by Deep Learning in Three-dimensional Whole-body MRI of
  Epidemiological Cohort Studies</font>
    </a>
  </h2>
  <font color="black">代謝性疾患のリスクが高い個人を正しく識別して表現型を決定するには、脂肪組織の信頼性の高い皮下および内臓脂肪組織への自動セグメンテーションが必要です。女性）Tuebingen Family Studyおよびドイツ糖尿病研究センター（TUEF / DZD）、ならびにモデル訓練用のドイツ国立コホート（NAKO）データベースの300ケース（53 $ \ pm $ 11年、女性152人） 、検証、コホート間の転移学習によるテスト。方法：全身MR画像からの異なる脂肪組織コンパートメントの定量化と位置特定は、代謝状態を調べるのに非常に重要です。 
[ABSTRACT]高速（5-adicut）で信頼性の高い組織の細分化は、3d全身mrデータセットから高いダイスオーバーラップ（0. 94）、感度（96. 6％）および精度（98. 4％）で取得できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Fast top-K Cosine Similarity Search through XOR-Friendly Binary
  Quantization on GPUs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_16.html">
      <font color="black">Fast top-K Cosine Similarity Search through XOR-Friendly Binary
  Quantization on GPUs</font>
    </a>
  </h2>
  <font color="black">実験により、この量子化方法は前処理時間が短く、高精度が必要な場合に、包括的な検索方法の検索速度を一般的な近似最近傍アルゴリズムの検索速度よりもはるかに高速にすることができます。このアルゴリズムは、新しいXOR対応のバイナリを使用します。高複雑度の乗算を低複雑度のビットごとの演算として最適化できるように、浮動小数点数をエンコードする量子化方法。GPUを使用して大規模最近傍探索を高速化し、高速ベクトル量子化ベースの網羅的最近傍を提案します。コサインの類似性のために特別に設計されたインデックス作成を行わなくても高精度を達成できるネイバー検索アルゴリズム。 
[要約]アルゴリズムは、新しいxor-フレンドリーなバイナリ量子化法を使用します。最適化できる浮動小数点数をエンコードします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: A coarse-to-fine framework for unsupervised multi-contrast MR image
  deformable registration with dual consistency constraint -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_17.html">
      <font color="black">A coarse-to-fine framework for unsupervised multi-contrast MR image
  deformable registration with dual consistency constraint</font>
    </a>
  </h2>
  <font color="black">この論文では、正確で効率的なマルチコントラストMR画像登録を達成するための新しい教師なし学習ベースのフレームワークを提案します。具体的には、アフィン変換と変形可能変換からなるエンドツーエンドの粗密ネットワークアーキテクチャは、マルチステップ反復プロセスと複雑な画像前処理操作の両方を取り除きます。登録速度に関して、この方法は、同じCPUでテストする場合、最も競争力のあるSyNの方法よりも約17倍高速です。 
[要約]提案された方法は、555ケースからなる臨床データセットで評価されています。これは、マルチステップ反復プロセスと複雑な画像前処理操作を取り除くように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Long-term Visual Dynamics with Region Proposal Interaction
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_18.html">
      <font color="black">Learning Long-term Visual Dynamics with Region Proposal Interaction
  Networks</font>
    </a>
  </h2>
  <font color="black">この目的のために、私たちは、領域提案相互作用ネットワーク（RPIN）を提案します。これは、潜在領域提案特徴空間における各オブジェクトの軌跡についての理由です。これは、そのようなモデルが非常に正確である必要があるだけでなく、エージェントがシンプルでありながら効果的なオブジェクト表現のおかげで、私たちのアプローチは、予測品質と、下流のタスクを計画する能力、および一般化する能力の両方の点で、従来の方法よりもはるかに優れています。新しい環境にも。 
[ABSTRACT]長期予測には、短期モデルによる迅速な再計画が必要です。長期にわたってオブジェクト間およびオブジェクトと環境の相互作用をキャプチャできるオブジェクト表現の構築を目指しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodality Biomedical Image Registration using Free Point Transformer
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_19.html">
      <font color="black">Multimodality Biomedical Image Registration using Free Point Transformer
  Networks</font>
    </a>
  </h2>
  <font color="black">前立腺MRとまばらに取得した超音波画像を使用したマルチモーダル登録タスクで、FPTは他の固定および非固定登録方法と比較して同等または改善された結果をもたらします。新規の自由点変換器（FPT）ネットワークに基づく点セット登録アルゴリズムについて説明します、超音波誘導介入手順で頻繁に遭遇するような登録タスクのためのマルチモーダル生体医用画像から抽出されたポイント用に設計されています。ポイント変換モジュールは、空間変換の予測において近傍も滑らかさも想定しておらず、グローバル特徴抽出とともにトレーニングされます監視なしの損失関数を使用したデータ駆動型の方法で。 
[ABSTRACT] fptは、順序付けされていないソースポイントとターゲットポイントの可変サイズのセットを受け入れるグローバルフィーチャエクストラクタで構築されます。ポイントトランスフォーマモジュールは、空間変換の予測において近傍も滑らかさも想定せず、グローバルフィーチャエクストラクタとともに、データ-教師なし損失関数を使用する主導型の方法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Domain-Specific Mappings for Generative Adversarial Style Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_20.html">
      <font color="black">Domain-Specific Mappings for Generative Adversarial Style Transfer</font>
    </a>
  </h2>
  <font color="black">コードと結果は、https：//acht7111020.github.io/DSMAP-demo/で入手できます。この問題に対処するために、このペーパーでは、ドメイン固有のマッピングを利用して、共有コンテンツスペースの潜在的な機能をドメイン固有のコンテンツスペースに再マッピングします。 。これにより、スタイルを転送するために画像をより適切にエンコードできます。 
[要約]提案された方法は、以前のスタイル転送方法よりも優れており、特に画像間の意味的対応が必要となる困難なシナリオでは</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Can You Read Me Now? Content Aware Rectification using Angle Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_21.html">
      <font color="black">Can You Read Me Now? Content Aware Rectification using Angle Supervision</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、OCRの精度、幾何学的エラー、視覚的な類似性の点で以前のアプローチを上回っています。スマートフォンのカメラの普及により、スキャンされるのではなく、カメラでキャプチャされるドキュメントの数が増えています。最近の研究では、取得したドキュメントの画像を修正する問題に取り組んできましたさまざまな監視信号と調整手段を使用して、実際に使用します。 
[ABSTRACT]最近のocrシステムの進歩にもかかわらず、ほとんどの場合、テキスト行がまっすぐで軸が揃っていることを保証する前処理に依存していますが、ドキュメントの境界から抽出できるグローバル機能に焦点を当てています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: CoReNet: Coherent 3D scene reconstruction from a single RGB image -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_22.html">
      <font color="black">CoReNet: Coherent 3D scene reconstruction from a single RGB image</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、両方のデータセットの最新の単一オブジェクトの方法よりも優れています。すべてのオブジェクトを1つのパスで共同で再構築し、すべてのオブジェクトがカメラに対して単一の一貫した3D座標フレームに存在するコヒーレント再構築を生成します。そして、それらは3D空間で交差しません。また、オクルージョンを処理し、3Dボリューム内の失われたオブジェクトパーツを幻覚化することによってそれらを解決します。 
[要約] 3つの新しいエンコーダー/デコーダーアーキテクチャに加えて、3つの拡張機能を提案します。これらには、ローカル2d情報を物理的に正しい方法で出力3dボリュームに伝播するレイトレーススキップ接続が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br><font color="black">2020-04-27</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Boost by Exploiting the Auxiliary Task in Multi-task Domain -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_23.html">
      <font color="black">Learning Boost by Exploiting the Auxiliary Task in Multi-task Domain</font>
    </a>
  </h2>
  <font color="black">ネガティブ転送は、最適性の達成から機能し、パフォーマンスを低下させます。MTLは複数のタスクからの情報のポジティブ転送から恩恵を受けますが、実際の環境では、タスクは学習フェーズ中にそれらの間で必然的にネガティブ転送と呼ばれる競合があります。タスクの競合の問題を解決するために、以前の研究では、基本的ではなく、その場限りの部分的なソリューションのみを提案しました。 
[ABSTRACT]マルチタスク学習（mtl）は、コンピュータビジョン、言語理解、音声合成などのさまざまな分野で長い間研究されてきました。負の転送は、最適性の達成からの機能を妨げ、パフォーマンスを低下させます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Iris Presentation Attack Detection Fusing 2D and 3D Information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_24.html">
      <font color="black">Robust Iris Presentation Attack Detection Fusing 2D and 3D Information</font>
    </a>
  </h2>
  <font color="black">2D（テクスチャ）虹彩の特徴は、バイナリ統計画像特徴（BSIF）を採用した最先端の方法で抽出され、分類子のアンサンブルを使用して、2Dモダリティ関連の決定が行われます。表示される可能性のあるアーチファクトの多様性と予測不可能性虹彩センサーには、プレゼンテーション攻撃機器の特定性にとらわれないプレゼンテーション攻撃検出方法が必要です。3D（形状）虹彩機能は、2つの異なる角度で配置された近赤外線照明下でキャプチャされた2つの画像のみから、フォトメトリックステレオ法によって再構築されます。 、多くの現在の市販の虹彩認識センサーと同様に。 
[要約]新しい論文は、観察された虹彩の2階建てと3階建ての特性を組み合わせる方法を提案します。これら2つのアプローチの組み合わせは、対象がテクスチャードコンタクトレンズを着用しているかどうかを検出するために適用され、アイデンティティを偽装しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-21">
        <br><font color="black">2020-02-21</font>
      </time>
    </span>
</section>
<!-- paper0: Geometric Interpretations of the Normalized Epipolar Error -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_25.html">
      <font color="black">Geometric Interpretations of the Normalized Epipolar Error</font>
    </a>
  </h2>
  <font color="black">特に、次の量に直接関連していることを示します：（1）2つの逆投影光線間の最短距離、（2）2つの境界エピポーラ平面間の二面角、（3）$ L_1 $最適角度再投影エラー..この作業では、正規化されたエピポーラエラーの幾何学的解釈を提供します。 
[ABSTRACT] 2つの逆生成された光線間の最短距離に直接関連していることを示します。これには、2つの境界エピポーラ平面間の無効距離が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervised learning using consistency regularization of
  spatio-temporal data augmentation for action recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_26.html">
      <font color="black">Self-supervised learning using consistency regularization of
  spatio-temporal data augmentation for action recognition</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、元のビデオが供給されたクリーンパスと対応する拡張ビデオが供給されたノイズパスを含むシャムネットワークから生成されたさまざまな出力機能間の時空間整合性正則化を提案します。現在の代理監視信号と組み合わせると、HMDB51で以前の最先端技術と比較して22％、UCF101で7％の相対的な改善を達成します。自己監視学習は、監視なしのディープラーニングモデルの改善に大きな可能性を示しています。ラベルのないデータから直接代理監視信号を構築する方法。 
[要約]システムは、ビデオの時間的特性である空間に基づいています。これにより、2種類のビデオが作成されます-異なるタイプの学習に基づいています。この方法は、最先端の自主学習方法に似ています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Augmented Skeleton Based Contrastive Action Learning with Momentum LSTM
  for Unsupervised Action Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_27.html">
      <font color="black">Augmented Skeleton Based Contrastive Action Learning with Momentum LSTM
  for Unsupervised Action Recognition</font>
    </a>
  </h2>
  <font color="black">最後に、クエリエンコーダーによって学習された隠されたアクションの状態を時間的に平均化することにより、コントラストアクションエンコーディング（CAE）という名前の新しい表現が提案され、人間のアクションを効果的に表現します。3Dスケルトンデータによるアクション認識は、近年重要なトピックとして浮上しています。具体的には、最初に、複数の新しい拡張戦略によって変換される入力スケルトンシーケンスの拡張インスタンス（クエリとキー）間の類似性を対比して、異なるスケルトン変換の固有のアクションパターン（「パターン不変性」）を学習します。 
[ABSTRACT]ほとんどの既存の手作りの記述子は、アクション表現を学習するために使用されます。これらには、平均的な被験者の被験者の対面データによるアクション表現が含まれます。このメソッドは、同等またはさらに優れたパフォーマンスを達成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-01">
        <br><font color="black">2020-08-01</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic ReLU -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_28.html">
      <font color="black">Dynamic ReLU</font>
    </a>
  </h2>
  <font color="black">静的な対応物と比較して、DY-ReLUの計算コストはごくわずかですが、特に軽量ニューラルネットワークの場合、表現能力が大幅に向上します。重要な洞察は、DY-ReLUがグローバルコンテキストをハイパー関数にエンコードし、区分線形活性化関数に応じて..整流線形単位（ReLU）は、ディープニューラルネットワークで一般的に使用されます。 
[ABSTRACT] dy-reluのハイパー関数に加えて、reluはグローバルコンテキストをエンコードします。それに応じて区分線形活性化関数を適応させます。imagenet分類のトップ1の精度は72から0に向上しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-22">
        <br><font color="black">2020-03-22</font>
      </time>
    </span>
</section>
<!-- paper0: TRIE: End-to-End Text Reading and Information Extraction for Document
  Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_29.html">
      <font color="black">TRIE: End-to-End Text Reading and Information Extraction for Document
  Understanding</font>
    </a>
  </h2>
  <font color="black">具体的には、テキスト読み取りのマルチモーダルな視覚的機能とテキスト機能が融合して情報抽出が行われ、情報抽出のセマンティクスがテキスト読み取りの最適化に貢献します。ただし、これらは主に情報抽出タスクの改善に焦点を当てていますが、テキストの読み取りと情報の抽出は相互に関連付けられています。さまざまなドキュメント画像（固定レイアウトから可変レイアウト、構造化テキストから半構造化テキスト）を含む3つの実世界のデータセットでは、提案された方法が最新のパフォーマンスを大幅に上回っています。効率と正確さの両方で芸術の方法。 
[ABSTRACT]既存のほとんどの作業は、問題を2つの別々のタスクに分離します。これらには、画像内のテキストを検出および認識するためのテキストの読み取りが含まれます。メインタスクには、以前に抽出されたプレーンテキストからキー要素を抽出するための情報抽出が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-27">
        <br><font color="black">2020-05-27</font>
      </time>
    </span>
</section>
<!-- paper0: Tiny-YOLO object detection supplemented with geometrical data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_30.html">
      <font color="black">Tiny-YOLO object detection supplemented with geometrical data</font>
    </a>
  </h2>
  <font color="black">シーンジオメトリに関する事前知識を活用して、検出精度（mAP）を改善する方法を提案します。シーンは、オブジェクトが配置された平面であると想定します。わずかに変更されたYOLOv3-tinyを使用して、検出が補完されたことを示しますスケールチャネル（Sとも呼ばれます）は、小さな計算オーバーヘッドで標準的なRGBベースの検出よりも優れています。自律型ロボットに焦点を当てているため、ロボットの寸法とカメラの傾斜角度を考えると、空間を予測することが可能です。入力フレームの各ピクセルのスケール。 
[ABSTRACT]ロボットのサイズとカメラの設定角度により、各ピクセルの正確なスケールを予測できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Multiple Sclerosis Lesion Activity Segmentation with Attention-Guided
  Two-Path CNNs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_31.html">
      <font color="black">Multiple Sclerosis Lesion Activity Segmentation with Attention-Guided
  Two-Path CNNs</font>
    </a>
  </h2>
  <font color="black">通常、磁気共鳴画像法（MRI）は、疾患の進行を追跡するために使用されます。自動画像処理方法を使用して、病変をセグメント化し、定量的な病変パラメータを導き出すことができます。単一ボリュームの病変セグメンテーションが成功したにもかかわらず、深層学習アプローチはまだまれです病変活動セグメンテーション。 
[ABSTRACT] scorching Imaging（mri）は、疾患の進行を追跡するために使用されます。通常、個々のmriスキャンの病変活動を分析するために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Ultra Fast Structure-aware Deep Lane Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_32.html">
      <font color="black">Ultra Fast Structure-aware Deep Lane Detection</font>
    </a>
  </h2>
  <font color="black">具体的には、車線検出のプロセスをグローバルフィーチャーを使用した行ベースの選択問題として扱います。グローバルフィーチャーに大きな受容フィールドを使用すると、困難なシナリオにも対応できます。行ベースの選択を利用して、定式化計算コストを大幅に削減できます。 
[要約]車線検出の認識は、コンテキスト情報とグローバル情報に基づいています。グローバル機能に大きな受容フィールドを使用することで、課題にも対処できます。この方法は、速度と精度の両方の面で最先端の技術を実現できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-24">
        <br><font color="black">2020-04-24</font>
      </time>
    </span>
</section>
<!-- paper0: Active Perception using Light Curtains for Autonomous Driving -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_33.html">
      <font color="black">Active Perception using Light Curtains for Autonomous Driving</font>
    </a>
  </h2>
  <font color="black">コードと詳細は、プロジェクトのWebページ（http://siddancha.github.io/projects/active-perception-light-curtains ..）にあります。次に、物理的オブジェクトをエンコードすることにより、この目的を最大化するための新しい効率的な最適化アルゴリズムを開発します。デバイスの制約を制約グラフに追加し、動的プログラミングで最適化します。3D検出器をトレーニングして、不確実性ガイド付きライトカーテンを連続して配置し、検出精度を連続的に改善して、シーン内のオブジェクトを検出する方法を示します。 
[ABSTRACT]ライトカーテンを使用した3Dオブジェクト認識の方法を提案します。センサーは、ユーザーの奥行きを測定します-環境内の指定された場所</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervised Temporal Discriminative Learning for Video
  Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_34.html">
      <font color="black">Self-supervised Temporal Discriminative Learning for Video
  Representation Learning</font>
    </a>
  </h2>
  <font color="black">最後に、時間的識別機能は、各アンカーとその拡張されたポジティブ間の距離を最小化することによって学習され、各アンカーとその拡張されたネガティブ間の距離、およびメモリバンクに保存された他のビデオは、表現の多様性を豊かにするために最大化されます。下流のアクション認識タスクでは、提案された方法は既存の関連作業を大幅に上回ります。コードはhttps://github.com/FingerRec/Self-Supervised-Temporal-Discriminative-Representation-Learning-for-Video-アクション認識。 
[ABSTRACT]非表示の機能は、注釈付きの大きな-トレーニング用の大規模なビデオアクションデータセットを使用せずに抽出することはほとんどできません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Performance Improvement of Path Planning algorithms with Deep Learning
  Encoder Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_35.html">
      <font color="black">Performance Improvement of Path Planning algorithms with Deep Learning
  Encoder Model</font>
    </a>
  </h2>
  <font color="black">次に、最終的なアルゴリズム（結合されたものと結合されていないもの）が、5つのシナリオで構成されるデータベースでチェックされます。それらの提案モデルであるCNNエンコーダーは、文献の他の既存の経路計画アルゴリズムに関連付けられており、時間を短縮できました。分析したすべての経路計画アルゴリズムと比較して最短経路を見つけます。このホワイトペーパーでは、このCNNエンコーダーモデルを使用して無駄な経路を排除するためにパフォーマンスを詳細に分析します。 
[ABSTRACT]大規模な環境では、これらのアルゴリズムが最短のパスを見つけるのに多くの時間を費やします。手の削減は、この問題の解決策として表示されます。つまり、このコンテキストでは、その環境に存在する不要なパスを削除する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchical Amortized Training for Memory-efficient High Resolution 3D
  GAN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_36.html">
      <font color="black">Hierarchical Amortized Training for Memory-efficient High Resolution 3D
  GAN</font>
    </a>
  </h2>
  <font color="black">さらに、高解像度サブボリュームを単一の低解像度画像に固定すると、サブボリューム間の解剖学的整合性が保証されます。ジェネレーティブアドバーサリネットワーク（GAN）には、データ拡張、ドメイン適応、モデルの説明など、多くの潜在的な医療画像アプリケーションがあります。3Dの実験胸部CTおよび脳MRIは、私たちのアプローチが画像生成、画像再構成、および臨床関連変数の予測において最先端の技術よりも優れていることを示しています。 
[ABSTRACT]最新の3Dガンモデルは低解像度の医療画像でトレーニングされています。さらに、このモデルは完全な高解像度画像を直接生成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Subclass Contrastive Loss for Injured Face Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_37.html">
      <font color="black">Subclass Contrastive Loss for Injured Face Recognition</font>
    </a>
  </h2>
  <font color="black">この論文では、初めて、負傷した顔認識の問題に取り組み、このタスクのための新しいサブクラスのコントラスト損失（SCL）を提案します。実験分析は、提案された損失関数が負傷した顔認識の既存のアルゴリズムを上回っていることを示しています。は、認識のために最も一般的に使用され、広く受け入れられている生体認証モダリティの1つです。 
[ABSTRACT]顔の外傷がある場合、顔の認識は困難です。これには、腫れ、あざ、血栓、裂傷、および裂傷が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Beyond Controlled Environments: 3D Camera Re-Localization in Changing
  Indoor Scenes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_38.html">
      <font color="black">Beyond Controlled Environments: 3D Camera Re-Localization in Changing
  Indoor Scenes</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、長期的な屋内再ローカリゼーションが未解決の問題であることを明確に示しています。カメラの再ローカリゼーションを評価するための新しいメトリックを提案し、これらのメトリックに従って最新のカメラリローカライザがどのように機能するかを調査します。ベンチマークとツールは、waldjohannau.github.io / RIO10で公開されています。
[概要] 3rscanを採用しました-最近導入された屋内rgb-オブジェクトインスタンスのdデータセットre-localization。また、さまざまなタイプのシーン変更がパフォーマンスにどのように影響するかを詳細に調査しますさまざまな方法の</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Weight-Sharing Neural Architecture Search: A Battle to Shrink the
  Optimization Gap -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_39.html">
      <font color="black">Weight-Sharing Neural Architecture Search: A Battle to Shrink the
  Optimization Gap</font>
    </a>
  </h2>
  <font color="black">これらの方法は、はるかに高速ですが、しばしば不安定性の問題に悩まされます。このホワイトペーパーでは、NASに関する文献のレビュー、特に重み共有方法を提供し、主な課題はスーパーネットワーク間の最適化のギャップに起因することを指摘します。そして最後に、NASとAutoMLの将来の方向性についての意見を共有します。 
[ABSTRACT]この研究は幼い頃の研究者によって行われました。彼らは代替のアーキテクチャを作成するために重量試験方法を使用しました。しかし、彼らはしばしば不安定性の問題に苦しみます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Structure Preserving Stain Normalization of Histopathology Images Using
  Self-Supervised Semantic Guidance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_40.html">
      <font color="black">Structure Preserving Stain Normalization of Histopathology Images Using
  Self-Supervised Semantic Guidance</font>
    </a>
  </h2>
  <font color="black">提案されたスキームは、他の色正規化手法よりも優れており、分類とセグメンテーションのパフォーマンスが向上します。この手法では、手動のセグメンテーションマップが不要で、既存の手法よりもはるかに優れています。事前学習済みのセマンティックネットワークと染色色正規化ネットワーク。 
[要旨]セマンティックガイダンスをガンベースの染色正規化フレームワークに組み込むには、自己監視アプローチが必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: COALESCE: Component Assembly by Learning to Synthesize Connections -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_41.html">
      <font color="black">COALESCE: Component Assembly by Learning to Synthesize Connections</font>
    </a>
  </h2>
  <font color="black">COALESCEは、ディープラーニングを使用してパーツ接続を合成する、コンポーネントベースの形状アセンブリ用の最初のデータ駆動型フレームワークであるCOALESCEを導入します。さまざまなオブジェクトから抽出された一連の入力パーツが与えられると、COALESCEはそれらを自動的に位置合わせし、妥当なジョイントを合成してパーツを接続しますメッシュで表現された一貫性のある3Dオブジェクト。この方法は、3D形状合成のベースラインディープモデルや形状完成の最先端の方法など、以前のアプローチよりも大幅に優れていることを示しています。 
[ABSTRACT]ジョイント合成ネットワークは、ジョイント領域に焦点を合わせるように設計されています。スムーズでサットのみの意味のある接続を作成しながら、最初のパーツと一致するインサート形状表現を予測することにより、パーツ間のサーフェスを再構築します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: AE TextSpotter: Learning Visual and Linguistic Representation for
  Ambiguous Text Spotting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_42.html">
      <font color="black">AE TextSpotter: Learning Visual and Linguistic Representation for
  Ambiguous Text Spotting</font>
    </a>
  </h2>
  <font color="black">1（c））..テキストの検出に視覚的な機能のみを使用した以前の作品とは異なり、この作品は、テキストのあいまいさを大幅に減らすために視覚的機能と言語的機能の両方を学習する、あいまいさ除去テキストスポッター（AE TextSpotter）という新しいテキストスポッターを提案します。検出..「ベルリン」は、図で「BERL」および「IN」として誤って検出されます。
[要約]提案されたae textspotterには3つの重要な利点があります。言語モデルを使用してテキスト検出を改善するのは初めて</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-03">
        <br><font color="black">2020-08-03</font>
      </time>
    </span>
</section>
<!-- paper0: Extracting and Leveraging Nodule Features with Lung Inpainting for Local
  Feature Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_43.html">
      <font color="black">Extracting and Leveraging Nodule Features with Lung Inpainting for Local
  Feature Augmentation</font>
    </a>
  </h2>
  <font color="black">ネットワークは、結節を含むパッチで現実的で健康な組織と構造を生成するために適用されます。結節の特徴の抽出は、結節パッチから修復されたパッチを差し引くことによって処理されます。胸部X線（CXR）が最も一般的な検査です肺異常の迅速な検出のため。 
[要約]この論文では、局所結節を抽出することにより局所特徴を増大させる方法を提案します。これらの特徴は修復された表現から削除されます。結節はスキャンのキャプチャーによって削除されます。その後、結節の位置から削除されます。肺領域</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Counterfactual Explanation Based on Gradual Construction for Deep
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_44.html">
      <font color="black">Counterfactual Explanation Based on Gradual Construction for Deep
  Networks</font>
    </a>
  </h2>
  <font color="black">この問題に対処するために、トレーニングデータセットから学習した統計を活用する反事実的な説明方法を提案します。実験結果は、この方法がさまざまな分類データセットに対して人間にやさしい解釈を生成し、そのような解釈が少ない機能修正で達成できることを確認していることを示しています。マスキングステップは、ターゲットクラスとして分類される入力データから重要な特徴を選択することを目的としています。 
[要約]ディープネットワークがトレーニングデータセットから学習したパターンは、さまざまなクラス間の特徴のばらつきを観察することで解釈できます。これにより、現在、実際の実際のデータ分布から逸脱した不明確な説明が生じています。これは、説明を徐々に構築することを示唆していますオーバーマスキングとコンポジションのステップを推定する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: PyRetri: A PyTorch-based Library for Unsupervised Image Retrieval by
  Deep Convolutional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_45.html">
      <font color="black">PyRetri: A PyTorch-based Library for Unsupervised Image Retrieval by
  Deep Convolutional Neural Networks</font>
    </a>
  </h2>
  <font color="black">私たちの知る限りでは、これはディープラーニングによる教師なし画像検索のための最初のオープンソースライブラリです。コンテンツベースの画像検索の分野へのディープラーニング手法の適用が大幅に進歩したにもかかわらず、ソフトウェアライブラリはこれまでありませんでした。は、これらの方法を統一的にカバーしています。このギャップを埋めるために、ディープラーニングベースの教師なし画像検索用のオープンソースライブラリであるPyRetriを紹介します。 
[ABSTRACT] pyretriは、ディープラーニングベースの教師なし画像検索用のオープンソースライブラリです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-02">
        <br><font color="black">2020-05-02</font>
      </time>
    </span>
</section>
<!-- paper0: More Than Accuracy: Towards Trustworthy Machine Learning Interfaces for
  Object Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_46.html">
      <font color="black">More Than Accuracy: Towards Trustworthy Machine Learning Interfaces for
  Object Recognition</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、画像内のオブジェクトを認識する機械学習（ML）システムの視覚化のユーザーエクスペリエンスを調査します。意味的に妥当なエラーは、妥当ではないエラーよりも重大ではないと判断されます。つまり、システムの精度は、エラーの種類によって伝達されます。 ..これは重要です。優れたシステムでも、写真共有Webサイトの誤分類が示すように、予期しない方法で失敗する可能性があるためです。 
[要約]視覚化は、ユーザーが使用中のシステムの精度を評価するのに役立ちました。また、誤分類の知覚された妥当性と重大度を考慮に入れました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised seismic facies classification using deep convolutional
  autoencoder -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_47.html">
      <font color="black">Unsupervised seismic facies classification using deep convolutional
  autoencoder</font>
    </a>
  </h2>
  <font color="black">相マップは、入力データから取得された深部特徴ベクトルをクラスタリングすることによって生成されます。提案されたアプローチは、人間の介入なしにリアルタイムで地質パターンを分析する可能性を切り開きます。最近出現した方法のグループは、深層ニューラルネットワークに基づいています。 
[要旨]地震相の解釈のための自動方法は、特定の通訳者の手作業と主観性を大幅に削減できる可能性があります。これらのアプローチはデータ駆動型であり、ネットワークトレーニングには大きなラベル付きデータセットが必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Compact Global Descriptor for Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_48.html">
      <font color="black">Compact Global Descriptor for Neural Networks</font>
    </a>
  </h2>
  <font color="black">ベンチマーク実験は、提案された方法が、追加のコンピューティングコストを大幅に削減して、最先端の長期的なメカニズムを完成できることを示しています。このホワイトペーパーでは、異なる次元（チャネル、フレームなど）。この記述子により、後続のたたみ込みで、計算の複雑さとパラメーターを無視して、有益なグローバル機能にアクセスできます。 
[ABSTRACT]この記述子により、後続の畳み込みが有益なグローバル機能にアクセスできるようになります。この記述子により、後続の情報に役立つグローバル機能にアクセスできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-23">
        <br><font color="black">2019-07-23</font>
      </time>
    </span>
</section>
<!-- paper0: Component Divide-and-Conquer for Real-World Image Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_49.html">
      <font color="black">Component Divide-and-Conquer for Real-World Image Super-Resolution</font>
    </a>
  </h2>
  <font color="black">SRのコンポーネント分割統治（CDC）モデルと勾配加重（GW）損失を提案します。私たちのCDCは、3つのコンポーネントで画像を解析し、3つのComponent-Attentive Block（CAB）を使用して、注意深いマスクと中間監視学習戦略による中間SR予測を学習し、分割統治学習原理に従ってSRモデルをトレーニングします。この論文では、大規模な多様な実世界の画像の超解像データセット、つまりDRealSRと、分割統治の超解像（SR）ネットワークを提示し、低SRモデルのガイドの有用性を探ります。レベルの画像コンポーネント..当社のデータセットとコードはhttps://github.com/xiezw5/Component-Divide-and-Conquer-for-Real-World-Image-Super-Resolution 
[ABSTRACT] drealsrで公開され、新しい実世界の多様な劣化プロセスを備えたSRベンチマーク。従来のシミュレートされた画像劣化の制限を緩和します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: A feature-supervised generative adversarial network for environmental
  monitoring during hazy days -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_50.html">
      <font color="black">A feature-supervised generative adversarial network for environmental
  monitoring during hazy days</font>
    </a>
  </h2>
  <font color="black">第二に、より良い結果を生成するために、知覚損失、スタイル損失、および機能正則化損失を導入することにより、基本的なGANの定式化が変更されます。主なアイデアは、グラウンドトゥルースからの機能マップの監視下でモデルをトレーニングすることです。3番目に、マルチスケールイメージは、弁別器のパフォーマンスを向上させるための入力として適用されます。 
[要約]提案された方法は、現在の状態よりも優れたパフォーマンスを実現しました-合成データセットと実際のリモートセンシング画像の両方で最先端の方法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: U$^2$-Net: Going Deeper with Nested U-Structure for Salient Object
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_51.html">
      <font color="black">U$^2$-Net: Going Deeper with Nested U-Structure for Salient Object
  Detection</font>
    </a>
  </h2>
  <font color="black">提案されたアーキテクチャの2つのモデル、U $ ^ 2 $ -Net（176.3 MB、GTX 1080Ti GPUで30 FPS）とU $ ^ 2 $ -Net $ ^ {\ dagger} $（4.7 MB、40 FPS）、さまざまな環境での使用を容易にするために..このホワイトペーパーでは、重要なオブジェクトの検出（SOD）のために、シンプルでありながら強力なディープネットワークアーキテクチャU $ ^ 2 $ -Netを設計します。コードはhttps：// githubで入手できます。 .com / NathanUA / U-2-Net。 
[ABSTRACT]このアーキテクチャにより、画像分類タスクのバックボーンを使用せずにディープネットワークをトレーニングできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-18">
        <br><font color="black">2020-05-18</font>
      </time>
    </span>
</section>
<!-- paper0: Anti-Bandit Neural Architecture Search for Model Defense -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_52.html">
      <font color="black">Anti-Bandit Neural Architecture Search for Model Defense</font>
    </a>
  </h2>
  <font color="black">広範な実験により、ABanditNASは他のNAS方式よりも高速であると同時に、PGD- $ 7 $でCIFAR-10の先行技術よりも$ 8.73 \％$向上していることがわかります。信頼限界の下限と上限に基づく検索プロセス（LCBおよびUCB）。評価のみにUCBを使用する従来のバンディットアルゴリズムとは異なり、検索効率のためにUCBを放棄し、アーム間の公正な競争のためにLCBを使用します。 
[ABSTRACT]ニューラルアーキテクチャ検索（nas）は、ノイズ除去ブロック、無重量演算、ガボールフィルター、およびたたみ込みの包括的な検索に基づいています。システムは、刺激的なブロックと無重み演算の高度な検索を使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-03">
        <br><font color="black">2020-08-03</font>
      </time>
    </span>
</section>
<!-- paper0: Compact Graph Architecture for Speech Emotion Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_53.html">
      <font color="black">Compact Graph Architecture for Speech Emotion Recognition</font>
    </a>
  </h2>
  <font color="black">人気のIEMOCAPデータベースで音声感情認識のモデルのパフォーマンスを評価しました。グラフ信号処理の理論に従って、音声信号をサイクルグラフまたは折れ線グラフとしてモデル化することを提案します。このモデルは、標準のGCNおよびその他の関連するモデルよりも優れています。私たちのアプローチの有効性を示す深いグラフアーキテクチャ。 
[ABSTRACT] Googleのモデルは、標準のGCNおよびその他の関連するディープグラフアーキテクチャよりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Simultaneous Semantic Alignment Network for Heterogeneous Domain
  Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_54.html">
      <font color="black">Simultaneous Semantic Alignment Network for Heterogeneous Domain
  Adaptation</font>
    </a>
  </h2>
  <font color="black">特に、ソースのカテゴリカル予測分布の相関知識をターゲットドメインに転送するための暗黙的な意味相関損失を提案します。これまでのほとんどのHDAメソッドは、ドメイン間の不一致を減らすためにドメイン不変の特徴部分空間を学習することでこの問題に取り組んでいます。包括的な実験text-to-image、image-to-image、text-to-textにわたるさまざまなHDAタスクで、最新のHDAメソッドに対するSSANの優位性を検証します。 
[要約]この論文では、相関関係を同時に活用し、各カテゴリの重心を整列させる同時セマンティックアライメントネットワーク（ssan）を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Uncertainty-Aware Multiview Triangulation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_55.html">
      <font color="black">Robust Uncertainty-Aware Multiview Triangulation</font>
    </a>
  </h2>
  <font color="black">第3に、三角測量点の不確実性を3つの要因の関数としてモデル化します。カメラの数、平均再投影誤差、最大視差角です。三角測量の前に2つのビューのサンプルを事前にスクリーニングすることにより、 -芸術の効率.. 2番目に、初期解とインライアセットを洗練するためのさまざまなローカル最適化手法を比較します。 
[ABSTRACT]私たちは、2点ランサックと中点法を使用した外れ値拒否スキームを提案します。比較により、三角点を優先するためのさまざまな局所強調法を比較します。これらは、広範な評価を通じて本法を検証します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Duality Diagram Similarity: a generic framework for initialization
  selection in task transfer learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_56.html">
      <font color="black">Duality Diagram Similarity: a generic framework for initialization
  selection in task transfer learning</font>
    </a>
  </h2>
  <font color="black">さらに、NYUv2およびPascal VOCデータセットでの2D、3D、およびセマンティックタスクでの転移学習のために、DNN内の最適なレイヤーの場所を選択するために、この方法を適用できることを示します。 17のタスクノミータスクにおける実際の転移学習のパフォーマンスランキングと予測されたランキング。また、新しいタスク、つまりPascal VOCセマンティックセグメンテーションに対するモデル選択アプローチの堅牢性も示します。 
[ABSTRACT]ディープニューラルネットワーク（dnns）間の双対図の類似性（dds）に基づく新しい非常に効率的なアプローチを提案します。実際の移動と予測される移動の対応を測定することにより、タスクノミーデータセットに対するアプローチを検証します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Pose-based Modular Network for Human-Object Interaction Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_57.html">
      <font color="black">Pose-based Modular Network for Human-Object Interaction Detection</font>
    </a>
  </h2>
  <font color="black">コードは\ url {https://github.com/birlrobotics/PMN}で入手できます。提案された方法を評価するために、VS-GATsという名前の最先端のモデルとモジュールを組み合わせて、大幅な改善を実現します2つのパブリックベンチマーク：V-COCOとHICO-DETは、その有効性と柔軟性を示します。別のブランチは、完全に接続されたグラフ構造を介して絶対ポーズ機能を更新します。 
[要約]目標は、シーン内のトリプレット（主語、述語、オブジェクト）を推測することです。オブジェクトの機能を調査して、ホイホイ検出を改善するポーズベースのモジュール式ネットワーク（pmn）に貢献しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: A DICOM Framework for Machine Learning Pipelines against Real-Time
  Radiology Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CV/paper_58.html">
      <font color="black">A DICOM Framework for Machine Learning Pipelines against Real-Time
  Radiology Images</font>
    </a>
  </h2>
  <font color="black">Nifflerはさらに、MLパイプラインからの結果を匿名化された方法で共有できるようにします。Nifflerは19か月以上安定して動作しており、部門でいくつかの研究プロジェクトをサポートしています。このペーパーでは、そのアーキテクチャとその使用例の3つ：リアルタイムでの画像からの下大静脈（IVC）フィルターの検出、スキャナーの使用状況の識別、スキャナーの時計の較正。 
[ABSTRACT] nifflerは、研究センターでのmlパイプラインの実行を可能にする統合フレームワークを提案します。nifflerは、mlパイプラインからの結果を特定できない方法で共有できるようにします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br><font color="black">2020-04-16</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Weighted Accuracy Algorithmic Approach In Counteracting Fake News And
  Disinformation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CL/paper_0.html">
      <font color="black">Weighted Accuracy Algorithmic Approach In Counteracting Fake News And
  Disinformation</font>
    </a>
  </h2>
  <font color="black">したがって、偽のニュースと偽情報の問題に真剣に取り組む必要があります。このホワイトペーパーでは、4つの機械学習アルゴリズムの重み付き精度を組み合わせて利用する制約メカニズムを通じて、偽のニュースを検出して報告する方法を提案します。世界は情報交換のためにインターネットに依存するようになっています。熱狂的なジャーナリスト、ハッカー、ブロガー、個人、組織は、偽のニュース、偽情報、そして自分の議題のための大げさなコンテンツでそれを汚染することにより、無料の情報環境の贈り物を悪用する傾向があります。 
[要約]偽のジャーナリストの問題に対処する必要があるとcnn.comは言います。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-30">
        <br><font color="black">2020-07-30</font>
      </time>
    </span>
</section>
<!-- paper0: An exploration of the encoding of grammatical gender in word embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CL/paper_1.html">
      <font color="black">An exploration of the encoding of grammatical gender in word embeddings</font>
    </a>
  </h2>
  <font color="black">文脈化された埋め込みに関する私たちの実験結果は、より多くの文脈的（意味論的）情報を埋め込みに追加することは、分類器のパフォーマンスに有害であることを指摘しました。単語のベクトル表現は、単語の埋め込みと呼ばれ、言語の研究に新しい研究アプローチをもたらしました。この研究では、名詞の文法上の性別を決定する神経分類子の精度に応じて、異なる組の単語埋め込みを比較します。 
[要約]単語の埋め込みに基づく文法上の性別の研究は、文法上の性別がセマンティックである方法についての議論に洞察を与えることができます。これらの表現は、単語に関するさまざまなタイプの情報を取り込むことができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Event-QA: A Dataset for Event-Centric Question Answering over Knowledge
  Graphs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CL/paper_2.html">
      <font color="black">Event-QA: A Dataset for Event-Centric Question Answering over Knowledge
  Graphs</font>
    </a>
  </h2>
  <font color="black">既存のQAシステムとデータセットのほとんどはエンティティ中心の質問に焦点を当てていますが、イベントのコンテキストでのこれらのシステムのパフォーマンスについてはほとんど知られていません。Event-QAには、1000のセマンティッククエリと対応するEventKGの英語、ドイツ語、ポルトガル語の言語化が含まれています-970千を超えるイベントを含むイベント中心のナレッジグラフ。セマンティッククエスチョンアンサー（QA）は、ナレッジグラフに保存されているセマンティック情報への直感的なユーザーアクセスを容易にする重要なテクノロジーです。 
[ABSTRACT]現在のqaシステムのほとんどはオブジェクトに焦点を当てています-中心的な質問。データセットにはナレッジグラフに関する質問が含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-24">
        <br><font color="black">2020-04-24</font>
      </time>
    </span>
</section>
<!-- paper0: CSTNet: Contrastive Speech Translation Network for Self-Supervised
  Speech Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CL/paper_3.html">
      <font color="black">CSTNet: Contrastive Speech Translation Network for Self-Supervised
  Speech Representation Learning</font>
    </a>
  </h2>
  <font color="black">ここでは、音声から言語表現を抽出できる畳み込みニューラルネットワークオーディオエンコーダーを構築します。このオーディオエンコーダーは、対比学習フレームワークで音声翻訳検索タスクを実行するようにトレーニングされています。この作業では、マルチモーダル機械学習フレームワークを提供します2つのモダリティ、つまり音声とそれに対応するテキスト翻訳の間の相関関係を利用することによる音声表現学習。 
[ABSTRACT]多くの危険にさらされている言語には正字法の形式はありませんが、通常はバイリンガルで話者が多く、リソースの高い言語でトレーニングされています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-04">
        <br><font color="black">2020-06-04</font>
      </time>
    </span>
</section>
<!-- paper0: Contextualized Translation of Automatically Segmented Speech -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CL/paper_4.html">
      <font color="black">Contextualized Translation of Automatically Segmented Speech</font>
    </a>
  </h2>
  <font color="black">この目的のために、ランダムにセグメント化されたデータでモデルをトレーニングし、2つのアプローチを比較します。微調整と前のセグメントをコンテキストとして追加します。このペーパーでは、代わりにモデルの問題に対処し、別のモデルに対してより堅牢にします、潜在的に次善のセグメンテーション..我々は、コンテキスト認識ソリューションがVADセグメント化された入力に対してより堅牢であり、強力なベースモデルおよび最大4.25までに設定された英語-ドイツ語テストのさまざまなVADセグメンテーションの微調整よりも優れていることを示します。 BLEUポイント。 
[ABSTRACT]研究者はオーディオセグメンテーションの改善に焦点を当てています。この目的は、ランダムにセグメント化されたデータでモデルをトレーニングすることです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Computational linguistic assessment of textbook and online learning
  media by means of threshold concepts in business education -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CL/paper_5.html">
      <font color="black">Computational linguistic assessment of textbook and online learning
  media by means of threshold concepts in business education</font>
    </a>
  </h2>
  <font color="black">この目的のために、ビジネスの教育からの63のしきい値概念（しきい値概念の研究から収集された）の分布プロファイルは、3種類の（ドイツ語）リソース、すなわち、教科書、新聞、およびWikipediaで調査されています。言語の観点から、ただし、しきい値の概念は、特定の言語機能を示す特殊な語彙のインスタンスです。しきい値の概念の頻度分布、複合分布、および3種類のリソース内のネットワーク構造を調べました。 
[ABSTRACT]しきい値の概念は通常、教科書などの正式な学習環境内にある特殊なテキストで使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Trove: Ontology-driven weak supervision for medical entity
  classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CL/paper_6.html">
      <font color="black">Trove: Ontology-driven weak supervision for medical entity
  classification</font>
    </a>
  </h2>
  <font color="black">私たちのフレームワークは、弱い監視を使用して、手動でラベル付けされたトレーニングデータを必要とせずに、幅広い医療エンティティ分類子をすばやく構築する方法を示しています。医療オントロジーはラベルを生成するための説得力のあるソースですが、グラウンドトゥルースデータなしで複数のオントロジーを組み合わせると、ラベルが原因で課題が生じますエンティティ定義の競合によって導入されるノイズ。結果：医療オントロジーを使用した、監視が弱いエンティティ分類のフレームワークであるTroveを示します。 
[ABSTRACT]多数のオントロジーを組み合わせた場合の影響を測定します。最新の状態を報告し、2つのエンティティ分類タスクの新しいベースラインを確立します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Antibody Watch: Text Mining Antibody Specificity from the Literature -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CL/paper_7.html">
      <font color="black">Antibody Watch: Text Mining Antibody Specificity from the Literature</font>
    </a>
  </h2>
  <font color="black">結果：私たちの目標は、問題のある抗体のサポートステートメントを含む「Antibody Watch」ナレッジベースを構築することです。2番目のタスクは、これらのスニペットのそれぞれをスニペットで言及されている1つ以上の抗体にリンクすることです。問題を2つのタスクに分けました。 。 
[ABSTRACT]研究者は、抗体の特異性に関する記述を抽出するためにディープニューラルネットワークシステムを開発しました。彼らは、テキストマイニングによって問題のある抗体に関する信頼できる知識ベースを構築することが可能であると言います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Elsevier OA CC-By Corpus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CL/paper_8.html">
      <font color="black">Elsevier OA CC-By Corpus</font>
    </a>
  </h2>
  <font color="black">このコーパスには、記事の全文だけでなく、各参照の書誌情報とともにドキュメントのメタデータも含まれています。ElsevierOA CC-BYコーパスを紹介します。これは、Scientific Researchの最初のオープンコーパスです。科学分野全体からの代表的なサンプルがある論文。 
[ABSTRACT]これは科学研究論文の最初のオープンコーパスです。科学分野全体からの代表的なサンプルがあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-03">
        <br><font color="black">2020-08-03</font>
      </time>
    </span>
</section>
<!-- paper0: Designing the Business Conversation Corpus -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CL/paper_9.html">
      <font color="black">Designing the Business Conversation Corpus</font>
    </a>
  </h2>
  <font color="black">コーパスの詳細な分析は、自動翻訳のための挑戦的な例とともに提供されます。この論文では、新しく構築された日英ビジネス会話並列コーパスを導入することにより、会話テキストの機械翻訳品質を向上させることを目指しています。並列コーパスおよびコーパスベースのトレーニングテクノロジーの利用可能性が高まったおかげで、書かれたテキストの機械翻訳はここ数年で大きく進んでおり、音声テキストやダイアログの自動翻訳は、現代のシステムでも困難なままです。 
[ABSTRACT]新しい論文では、新しく構築された日本語と英語のビジネス会話の並列コーパスを導入することで、会話テキストの機械翻訳品質を向上させることを目指しています。また、機械翻訳トレーニングシナリオでコーパスを追加して実験し、その結果システムはその使用から利益を得ます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Translation of Programming Languages -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CL/paper_10.html">
      <font color="black">Unsupervised Translation of Programming Languages</font>
    </a>
  </h2>
  <font color="black">トランスコンパイラーは主に相互運用性と、廃止または非推奨の言語で記述されたコードベースを移植するために使用されます（例：852並列関数で構成されるテストセットをビルドしてリリースし、ユニットテストとともに翻訳の正確さをチェックします。自然言語翻訳のコンテキストでは、ルールベースの対応物を大幅に上回っていますが、このドメインでは並列データが不足しているため、トランスコンパイルへの適用は制限されています。
[要約]トランスコンパイラーは主に相互運用性と、廃止または非推奨の言語です。これらは通常、ソースコードに適用される手作りの書き換えルールに依存します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-05">
        <br><font color="black">2020-06-05</font>
      </time>
    </span>
</section>
<!-- paper0: Generalized Word Shift Graphs: A Method for Visualizing and Explaining
  Pairwise Comparisons Between Texts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CL/paper_11.html">
      <font color="black">Generalized Word Shift Graphs: A Method for Visualizing and Explaining
  Pairwise Comparisons Between Texts</font>
    </a>
  </h2>
  <font color="black">いくつかのケーススタディを通じて、診断調査、仮説の生成、および実質的な解釈のために、一般化された単語シフトグラフをどのように柔軟に適用できるかを示します。加重平均として定式化できるメジャーの2つのテキスト間の変動に個々の単語がどのように寄与するかについての意味のある解釈可能な要約。このフレームワークは、相対頻度を含め、テキストを比較するために最も一般的に使用されるアプローチの多くを自然に包含することを示しています。 、辞書スコア、およびカルバックライブラーとジェンセンシャノンの分岐などのエントロピーベースの測定。 
[要約]単語の概念は、テキストを比較する方法と同じくらい簡単に見ることができます。これらには、相対頻度、辞書スコア、およびquan divergencesが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Improving End-to-End Speech-to-Intent Classification with Reptile -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CL/paper_12.html">
      <font color="black">Improving End-to-End Speech-to-Intent Classification with Reptile</font>
    </a>
  </h2>
  <font color="black">爬虫類はもともとモデルにとらわれないメタ学習用に提案されましたが、ターゲットタスクを直接学習し、従来の勾配降下法よりも一般化するためにも使用できると主張します。多くの研究者が他の関連データリソースを利用するアプローチを模索しています、通常、高リソースの音声認識でモデルの一部を事前トレーニングすることによります。異なる言語とドメインの4つのデータセットでの実験は、爬虫類を単独で使用した場合と事前トレーニングに加えて使用した場合の両方で、意図予測の精度が向上することを示しています。 
[要約]このホワイトペーパーでは、非標準の学習アルゴリズムである爬虫類を使用して、sluモデルの一般化パフォーマンスを改善することをお勧めします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Multiple Texts as a Limiting Factor in Online Learning: Quantifying
  (Dis-)similarities of Knowledge Networks across Languages -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CL/paper_13.html">
      <font color="black">Multiple Texts as a Limiting Factor in Online Learning: Quantifying
  (Dis-)similarities of Knowledge Networks across Languages</font>
    </a>
  </h2>
  <font color="black">教育科学の観点から、この記事では、Webベースの読書の典型的な入力として複数のテキストが抽出される情報ランドスケープの計算モデルを開発しています。WikipediaはWebベースの情報ランドスケープの中心的な部分であるため、これは言語関連の言語バイアス。この目的のために、情報ランドスケープのさまざまな部分のテキスト内およびテキスト間類似性のハイブリッドモデルを開発し、35の言語と対応するWikipediaの例でこのモデルをテストします。 
[要旨] 25の主題領域についてこの理論を調査します。ウィキペディアは、テキスト内およびテキスト間の類似性のハイブリッドモデルに基づいています。このモデルは、35の言語と対応するウィキペディアに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Classifying Constructive Comments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CL/paper_14.html">
      <font color="black">Classifying Constructive Comments</font>
    </a>
  </h2>
  <font color="black">モデルがこの機能に大きく依存している場合、コメントの長さは簡単にゲーム化できるため、モデルで長さが果たす役割を調べます。各モデルで発生したエラーと長さによる分布を調べると、最高のパフォーマンスのモデルが少ないことがわかりますコメントの長さと相関します。建設性コーパスと私たちの実験は、望ましくないコンテンツをフィルターするだけでなく、貢献するコメントの促進に焦点を当てたモデレーションツールへの道を開きます。アノテーター間の合意、サンプルの専門家による評価、および構成性のサブ特性によって、一般的な構成性の概念のプロキシを提供します。 
[要旨]建設的なコメントを、会話に貢献する質の高いコメントと定義します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-11">
        <br><font color="black">2020-04-11</font>
      </time>
    </span>
</section>
<!-- paper0: Glushkov's construction for functional subsequential transducers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CL/paper_15.html">
      <font color="black">Glushkov's construction for functional subsequential transducers</font>
    </a>
  </h2>
  <font color="black">ここで紹介する方法とアルゴリズムは、正規表現のコンパイラーを実装するために使用されました。Glushkovの構造には多くの興味深い特性がありますが、トランスデューサーに適用すると、さらに明確になります。この記事では、機能的な後続有限状態トランスデューサーの間の異常なリンクを示すことに努めていますそしてGlushkovの建設。 
[要約]この記事は、機能的な後続有限状態トランスデューサとglushkovの構造との間の異常なリンクを示すよう努めています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Aligning AI With Shared Human Values -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CL/paper_16.html">
      <font color="black">Aligning AI With Shared Human Values</font>
    </a>
  </h2>
  <font color="black">ETHICSデータセットを使用すると、現在の言語モデルには、基本的な倫理知識の有望ではあるが不完全な理解があることがわかります。モデルは、さまざまなテキストシナリオに関する広範な道徳的判断を予測します。私たちの研究は、今日、機械倫理に進歩があり、人間の価値観に沿ったAIへの足掛かり。 
[ABSTRACT]私たちは倫理データセット、正義、幸福、義務、美徳、常識の道徳の概念にまたがる新しいベンチマークを導入します。これには、物理的および社会的世界の知識を価値判断に関連付ける必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: LP-SparseMAP: Differentiable Relaxed Optimization for Sparse Structured
  Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/cs.CL/paper_17.html">
      <font color="black">LP-SparseMAP: Differentiable Relaxed Optimization for Sparse Structured
  Prediction</font>
    </a>
  </h2>
  <font color="black">LP-SparseMAPは、因子グラフの柔軟で強力なドメイン固有言語を使用して、任意の非表示構造を定義および逆伝播し、粗分解、ハードロジック制約、および高次相関をサポートします。これには、たとえば、ループ状のグラフィカルモデルや概して概算を必要とする論理制約。SparseMAPは、少数の構造の組み合わせを返します。これは、一部のダウンストリームアプリケーションでは望ましいプロパティです。 
[ABSTRACT]これは、最大の事後（マップ）と限界の可能性に対する微分可能な高密度の代替の最新の例です。このペーパーでは、多数の人々に対応するスパースマップの拡張であるlp-densenmapを紹介します。魅力的な方法はオブジェクトの数をシステムに説明するために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-13">
        <br><font color="black">2020-01-13</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Neural Loop Combiner: Neural Network Models for Assessing the
  Compatibility of Loops -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.AS/paper_0.html">
      <font color="black">Neural Loop Combiner: Neural Network Models for Assessing the
  Compatibility of Loops</font>
    </a>
  </h2>
  <font color="black">モデルとデータセットを構築するためのコードのソースを開きました。このデータを使用して、ループの互換性を推定するための2つのタイプのモデルアーキテクチャを調査します。1つはシャムネットワークに基づくもの、もう1つは純粋な畳み込みニューラルネットワーク（CNN ）..再現性のために、無料の音楽アーカイブからのデータを管理しています。 
[ABSTRACT] automashupperとautomashupperは、ほとんどがルールベースであり、機械学習で改善できる可能性があります。既存の音楽からループを抽出して、互換性のあるループのポジティブな例を見つけます。ネガティブな例を選択するためのさまざまな戦略を提案して比較します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Denoise Historical Music -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.AS/paper_1.html">
      <font color="black">Learning to Denoise Historical Music</font>
    </a>
  </h2>
  <font color="black">ネットワークは、古い録音の静かなセグメントから抽出された実際のノイズサンプルとクリーンな音楽を混合することによって作成された、合成ノイズの多い音楽データセットの再構築と敵対的な目的の両方でトレーニングされます。合成データセット、および実際の履歴録音のサンプルに対する人間の評価による質的評価。古い音楽録音のノイズを除去することを学習する音声間ニューラルネットワークモデルを提案します。 
[要旨]私たちのモデルは内部的にその入力を時間-周波数表現に変換します。それは、結果の複雑なスペクトログラムを、コンセットを使用して処理します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Data Cleansing with Contrastive Learning for Vocal Note Event
  Annotations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.AS/paper_2.html">
      <font color="black">Data Cleansing with Contrastive Learning for Vocal Note Event
  Annotations</font>
    </a>
  </h2>
  <font color="black">提案された戦略を使用してトレーニングした場合、元のデータセットを使用してトレーニングした場合の精度と比較して、転写モデルの精度が大幅に向上することを示しています。時系列）音楽データに共通するラベルなど。 
[ABSTRACT]以前に提案されたデータクレンジングモデルは、構造化を考慮していません。これらには、時間変化する構造化ラベルが含まれています。これらは、音楽のボーカルノートイベントアノテーションの有用性を示しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Acoustical classification of different speech acts using nonlinear
  methods -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.AS/paper_3.html">
      <font color="black">Acoustical classification of different speech acts using nonlinear
  methods</font>
    </a>
  </h2>
  <font color="black">より興味深い結果を生み出すために、さまざまな朗読による分析が行われています。クリップは、音色から生じる知覚の違いを回避するために、同じ人物によって（リズムのない平らなスピーチの形で）読み取られ、読み取られました。変化..ケースは従来の相転移に似ている可能性があり、変態が発生する外部条件（一般に温度）の測定は相転移と呼ばれます。 
[要約]さまざまな気分を伝えるさまざまな詩人の5つのよく知られているベンガル語の朗読。50人の参加者のプールで行われたリスニングテストの助けを借りて、5つの朗読の感情的な内容が標準化されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-15">
        <br><font color="black">2020-04-15</font>
      </time>
    </span>
</section>
<!-- paper0: CSTNet: Contrastive Speech Translation Network for Self-Supervised
  Speech Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.AS/paper_4.html">
      <font color="black">CSTNet: Contrastive Speech Translation Network for Self-Supervised
  Speech Representation Learning</font>
    </a>
  </h2>
  <font color="black">ここでは、音声から言語表現を抽出できる畳み込みニューラルネットワークオーディオエンコーダーを構築します。音声に対応するテキスト翻訳を取得するのは比較的簡単です。世界中の7,000言語の半分以上が絶滅の危機に瀕しています。 
[ABSTRACT]多くの危険にさらされている言語には正字法の形式はありませんが、通常はバイリンガルで話者が多く、リソースの高い言語でトレーニングされています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-04">
        <br><font color="black">2020-06-04</font>
      </time>
    </span>
</section>
<!-- paper0: MusPy: A Toolkit for Symbolic Music Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.AS/paper_5.html">
      <font color="black">MusPy: A Toolkit for Symbolic Music Generation</font>
    </a>
  </h2>
  <font color="black">結果は、一般的に使用されるさまざまなデータセット間のドメインオーバーラップのマップを提供し、一部のデータセットには他よりも代表的なジャンル間サンプルが含まれていることを示しています。データセット分析とともに、これらの結果は、将来の研究でデータセットを選択するためのガイドとして役立つ可能性があります。 
[ABSTRACT] muspyは、データセット管理、データI / O、データ前処理、モデル評価など、音楽生成システムの必須コンポーネント用の使いやすいツールを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: A study on more realistic room simulation for far-field keyword spotting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.AS/paper_6.html">
      <font color="black">A study on more realistic room simulation for far-field keyword spotting</font>
    </a>
  </h2>
  <font color="black">ソースコードはPyroomacousticsパッケージで利用可能になり、他の人がこれらの手法を作業に組み込むことができるようになります。クリーンでノイズの多い遠方場条件下での一連の再録音の差し控えにより、最大$ 35.8 \％$の相対的な改善を示します一般的に使用されている（単一吸収係数）画像ソース法を超えています。このために、室内インパルス応答（RIR）生成に次の要素を組み込むことの影響を調べます。空気吸収、表面および周波数依存係数マテリアル、確率的レイトレーシング。 
[ABSTRACT]クリーンでノイズのある遠方場の状態の再記録の保留セットで、最大35ドルを示しました。一般的に使用されている部屋のインパルス応答（riyr）画像ソースメソッドよりも大幅に改善されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-04">
        <br><font color="black">2020-06-04</font>
      </time>
    </span>
</section>
<!-- paper0: On the Characterization of Expressive Performance in Classical Music:
  First Results of the Con Espressione Game -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.AS/paper_7.html">
      <font color="black">On the Characterization of Expressive Performance in Classical Music:
  First Results of the Con Espressione Game</font>
    </a>
  </h2>
  <font color="black">このペーパーと一緒に公開するデータセットは、テンポやダイナミクスカーブなどの説明的なオーディオ機能だけでなく、手動で修正したスコアとパフォーマンスの調整を追加することで充実しました。（2）の主な次元（または軸）は何ですかこれから浮かび上がる表情豊かなキャラクター。 ; （3）パフォーマンスの測定可能なパラメーター（例：テンポ、ダイナミクス）と、機械学習モデル（例：構音、覚醒）で予測できる中高レベルの機能は、これらの表現的次元とどのように関連していますか。 
[要約]表現力豊かなキャラクターの500以上の説明をオンラインアンケートで分析しました。これらは、クラシックピアノ曲からの9つの抜粋の45の演奏を説明するために使用されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: GEV Beamforming Supported by DOA-based Masks Generated on Pairs of
  Microphones -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.AS/paper_8.html">
      <font color="black">GEV Beamforming Supported by DOA-based Masks Generated on Pairs of
  Microphones</font>
    </a>
  </h2>
  <font color="black">このペーパーで紹介するソリューションは、異なる間隔と音響環境条件を持つマイクのペアでニューラルネットワークをトレーニングし、このネットワークを使用して、任意の形状のアレイを形成するすべてのマイクのペアから時間周波数マスクを推定することです。結果は、提案されたアプローチが、市販のハードウェアに対応するさまざまなマイクアレイジオメトリで、SDRを平均で4.78 dBから7.69 dBに改善することを示しています。このマスクを使用して、ターゲットとノイズの共分散行列を推定し、次に使用することができます。一般化固有値（GEV）ビームフォーミングを実行します。 
[ABSTRACT]音声認識は、信号対歪み比（sdr）を改善するために必要です。ただし、このタイプのアプローチでは、ニューラルネットワークを事前にトレーニングする必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-19">
        <br><font color="black">2020-05-19</font>
      </time>
    </span>
</section>
<!-- paper0: Content based singing voice source separation via strong conditioning
  using aligned phonemes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.AS/paper_9.html">
      <font color="black">Content based singing voice source separation via strong conditioning
  using aligned phonemes</font>
    </a>
  </h2>
  <font color="black">音素条件付けが歌声の音源分離を改善するためにうまく適用できることを示します。これまで、音楽情報検索の研究者は主にスコアに基づく音源分離に焦点を当ててきましたが、最近のアプローチでは歌詞に基づく音源分離に取り組んでいます。 -アフィン変換を介して分離プロセスをさまざまな音素の存在に適合させるネットフィーチャーマップ。 
[ABSTRACT]新しいシステムは、ターゲットのソースに関する以前の情報を使用します。モデルは、非整列の歌詞で弱い条件付けを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Architecture Search on Acoustic Scene Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.AS/paper_10.html">
      <font color="black">Neural Architecture Search on Acoustic Scene Classification</font>
    </a>
  </h2>
  <font color="black">実験結果は、検索されたネットワークがASCタスクで有能であることを示しています。これは、DCASE2018タスク5評価セットで90.3％のF1スコアを達成し、ベースラインネットワークと比較してFLOPを25％節約しながら、新しい最先端のパフォーマンスをマークします。 ..さらに、最近のニューラルアーキテクチャ検索（NAS）パラダイムを使用して、提案されたベースラインに基づいて構築された動的アーキテクチャ空間を探索します。これは、最初にすべての候補ネットワークを組み込んだスーパーネットをトレーニングし、次によく知られている進化アルゴリズムNSGA-を適用します。 IIより高い精度とより低い計算コストでより効率的なネットワークを発見します。たたみ込みニューラルネットワークは、音響シーン分類（ASC）タスクで広く採用されていますが、一般に計算負荷が大きくなります。 
[ABSTRACT]畳み込みカーネルを単方向カーネルに置き換えて、空間次元の特徴を抽出します。実験結果は、検索されたネットワークがascタスクに対応しており、タスク全体の90.3％を達成していることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-30">
        <br><font color="black">2019-12-30</font>
      </time>
    </span>
</section>
<!-- paper0: Speech-to-Singing Conversion based on Boundary Equilibrium GAN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.AS/paper_11.html">
      <font color="black">Speech-to-Singing Conversion based on Boundary Equilibrium GAN</font>
    </a>
  </h2>
  <font color="black">再現性のために、コードは紙の出版時にGitHubリポジトリで公開されます。私たちの定量的および定性的分析は、提案されたモデルが、既存の敵対的訓練を受けていないベースラインよりもはるかに自然な歌声を生成することを示しています。入力、およびオプションでターゲットの歌唱のF0輪郭である提案モデルは、漸進的に成長するエンコーダー/デコーダーアーキテクチャと境界平衡GAN損失関数を備えた歌声信号を出力として生成します。 
[要約]提案されたモデルは、既存の非発声レベルよりもはるかに自然な歌声を生成します。これにより、発声に対する発声の使用を削減するさまざまな方法を開発するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br><font color="black">2020-05-28</font>
      </time>
    </span>
</section>
<!-- paper0: Compact Graph Architecture for Speech Emotion Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-06/eess.AS/paper_12.html">
      <font color="black">Compact Graph Architecture for Speech Emotion Recognition</font>
    </a>
  </h2>
  <font color="black">既存の音声感情認識方法と比較すると、モデルは最先端のパフォーマンス（4クラス、$ 65.29 \％$）を実現し、学習可能なパラメーターが大幅に少なくなっています。人気のIEMOCAPデータベース..私たちのモデルは、標準のGCNおよび他の関連するディープグラフアーキテクチャよりも優れており、私たちのアプローチの有効性を示しています。 
[ABSTRACT] Googleのモデルは、標準のGCNおよびその他の関連するディープグラフアーキテクチャよりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
