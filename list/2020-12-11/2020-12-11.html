<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-12-11の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Data-Efficient Framework for Real-world Multiple Sound Source 2D
  Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.SD/paper_0.html">
      <font color="black">Data-Efficient Framework for Real-world Multiple Sound Source 2D
  Localization</font>
    </a>
  </h2>
  <font color="black">音響シミュレータを活用して、ラベル付けされたトレーニングデータを安価に生成できます。私たちの新しいアンサンブル識別方法は、実際のデータからのラベルを必要とせずに、ローカリゼーションパフォーマンスを大幅に向上させます。さらに、ローカリゼーションアーキテクチャに埋め込まれる新しい明示的な変換レイヤーを提案します。 。 
[ABSTRACT]合成データモデルは、ドメインの不一致により、実際の記録ではパフォーマンスが低下します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Direct multimodal few-shot learning of speech and images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.SD/paper_1.html">
      <font color="black">Direct multimodal few-shot learning of speech and images</font>
    </a>
  </h2>
  <font color="black">改善は、直接モデルでの教師なし学習と転移学習の組み合わせ、および2段階の複合エラーがないことによるものであることを示します。以前の作業では、学習した単峰性表現に依存する2段階の間接アプローチを使用しました。画像と画像の比較は、指定された音声と画像のペアのサポートセット全体で実行されます。エージェントが画像内のオブジェクトを説明する話し言葉とともに画像を表示されると想像してください。たとえば、
[ABSTRACT]単一の学習を行う2つの直接モデルを提案します。マルチモーダル画像。これらはスピーチのマルチモーダルに基づいています-直接モデルを実行します。代わりにスピーチを学習します-間接モデルを実行します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Multiple Sound Source 2D Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.SD/paper_2.html">
      <font color="black">Learning Multiple Sound Source 2D Localization</font>
    </a>
  </h2>
  <font color="black">この論文では、複数の音源定位のための新しい深層学習ベースのアルゴリズムを提案します。結果は、この問題に対する以前のベースラインアプローチを改善する方法を示しています。最後に、解像度ベースの複数ソースの関連付けに依存する新しいメトリックが開発されています。さまざまなローカリゼーションアプローチを評価および比較できます。 
[概要]複数のマイクを使用して、密閉された環境で複数の音源の2次元座標を見つけることを目指しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Unified Streaming and Non-streaming Two-pass End-to-end Model for Speech
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.SD/paper_3.html">
      <font color="black">Unified Streaming and Non-streaming Two-pass End-to-end Model for Speech
  Recognition</font>
    </a>
  </h2>
  <font color="black">次に、CTC仮説は、アテンションデコーダーによって再スコアリングされ、最終結果が得られます。推論レイテンシは、チャンクサイズを変更するだけで簡単に制御できます。AISHELL-1テストセットでは、統合モデルは5.60％の相対文字エラー率を達成します。 （CER）標準の非ストリーミングトランスと比較した非ストリーミングASRの削減。 
[概要]提案手法は、ストリーミングモデルと非ストリーミングモデルを簡単かつ効率的に統合することができます。この方法は、統合して効果的に使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Fast and Effective Robustness Certification for Recurrent Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.SD/paper_4.html">
      <font color="black">Fast and Effective Robustness Certification for Recurrent Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">これには、音声前処理を構成する一般的な操作のためのカスタム凸緩和も開発する必要がありました。R2と呼ばれるリカレントニューラルネットワークの正確でスケーラブルなベリファイアを提示します。R2を使用して、重要なことを証明する最初の研究を提示します。リカレントニューラルネットワークのユースケース、つまり音声分類。 
[概要]検証者は、以前に行われた単一の境界ではなく、各ニューロンの多重化の一般的な組み合わせを最適化するシステムを含む、2つの重要なアイデアに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-27">
        <br><font color="black">2020-05-27</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: 3D Bounding Box Detection in Volumetric Medical Image Data: A Systematic
  Literature Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/eess.IV/paper_0.html">
      <font color="black">3D Bounding Box Detection in Volumetric Medical Image Data: A Systematic
  Literature Review</font>
    </a>
  </h2>
  <font color="black">バウンディングボックス検出オプションの概要が示され、研究者がターゲットオブジェクトに対して最も有望なアプローチを選択するのに役立ちます。ランダム回帰-森林..結果は、ほとんどの研究が最近、畳み込みニューラルネットワークと。手動機能エンジニアリングを使用した方法、たとえば
[ABSTRACT]解剖学的構造をローカライズするための複数の識別されたアプローチが提示されます。複数の識別アプローチが提示されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Effect of Different Batch Size Parameters on Predicting of COVID19 Cases -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/eess.IV/paper_1.html">
      <font color="black">Effect of Different Batch Size Parameters on Predicting of COVID19 Cases</font>
    </a>
  </h2>
  <font color="black">このウイルスは通常、くしゃみや咳、または感染した表面への接触によって引き起こされる飛沫によって伝染すると言われています。最高のCOVID19検出はBH = 3で95.17％でしたが、全体的な精度値はBH = 20で97.97％でした。ただし、バッチサイズの値が大きくなると、テストデータの定常状態が遅れることが観察されました。 
[概要]ウイルスは2020年3月に世界保健機関によって送信されます。これは、rrt-pcrテストの精度感度が低いことが知られているためです。しかし、コンピュータイメージングはウイルスを検出するための非常に重要な場所です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Analytical phase optical transfer function for Gaussian illumination and
  the optimized profiles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/eess.IV/paper_2.html">
      <font color="black">Analytical phase optical transfer function for Gaussian illumination and
  the optimized profiles</font>
    </a>
  </h2>
  <font color="black">最適な一般プロファイルは、緩和された最適検索によって分析的に検出され、最適なガウスプロファイルは、ツリー検索によって検出されます。さらに、POTFの均一性を最適化するために、POTFのバランスの取れた分布基準と最小二乗最小化が提示されます。トモグラフィーデコンボリューション位相顕微鏡のイメージング性能は、位相光学伝達関数（POTF）の観点から説明できます。これは、照明プロファイルに依存します。 
[概要] potfは最適化のパターンと最適最適最適最適最適最適最適に基づいています。最適最適一般プロファイルは緩和された最適フェーズによって分析的に見つけられます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Performance Comparison of Balanced and Unbalanced Cancer Datasets using
  Pre-Trained Convolutional Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/eess.IV/paper_3.html">
      <font color="black">Performance Comparison of Balanced and Unbalanced Cancer Datasets using
  Pre-Trained Convolutional Neural Network</font>
    </a>
  </h2>
  <font color="black">この研究では、BreakHisデータセットの組織病理学的データを使用して、2つの異なる平衡および不平衡研究グループが形成されました。コンピューターを使用してこのプロセスを検出することは非常に一般的です。特に良性または悪性腫瘍の検出異なる拡大率のデータを使用することにより、文献で行われます。 
[ABSTRACT]特に女性によく見られるがんの病気である乳がんは非常に一般的です。これらの画像は病理学者によって検査され、確定診断が行われます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Imperceptible Adversarial Image Patches Based on Network
  Explanations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/eess.IV/paper_4.html">
      <font color="black">Towards Imperceptible Adversarial Image Patches Based on Network
  Explanations</font>
    </a>
  </h2>
  <font color="black">このソフトマスクに基づいて、CFRの最適な摂動を検索するために、逆温度の新しい目的関数を開発します。したがって、摂動は冗長であり、人間の目で簡単に検出できます。ネットワークの説明により、摂動がCFRに追加されました。他の地域よりも効果的です。 
[概要]主なアイデアは、摂動のネットワーク説明に基づいて、画像の寄与特徴領域を見つけることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Calibrationless MRI Reconstruction with a Plug-in Denoiser -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/eess.IV/paper_5.html">
      <font color="black">Calibrationless MRI Reconstruction with a Plug-in Denoiser</font>
    </a>
  </h2>
  <font color="black">非線形機械学習の事前情報を活用するために、高次元高速畳み込みフレームワーク（HICU）をプラグインデノイザーと組み合わせて、2D脳データを使用してその実現可能性を実証します。磁気共鳴イメージング（MRI）は、以下を提供する非侵襲的イメージング手法です。イオン化放射線を使用しない優れた軟組織コントラスト..MRIの臨床応用は、長いデータ取得時間によって制限される可能性があります。したがって、高度にアンダーサンプリングされたk空間データからのMR画像再構成は活発な研究分野です。 
[概要] mriのmriは、長いデータ収集時間なしで3Dデータを使用します。非常にアンダーサンプリングされたk空間データからのmr画像再構成は活発な研究分野です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: A Database of Dorsal Hand Vein Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/eess.IV/paper_6.html">
      <font color="black">A Database of Dorsal Hand Vein Images</font>
    </a>
  </h2>
  <font color="black">この作業の目的は、一般に共有されているデータベースの参照として機能することです。背側の手の静脈は、身元確認のための有用な生体認証として実証されています。この作業では、2つのデータベースを収集する手順について詳しく説明します。生体認証プロジェクトにおける背側手の静脈。 
[概要]生体認証プロジェクトは、背側の手の静脈のデータベースを収集する方法を示しています。これには、データベースを収集するために取られた手順が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Tubule-Sensitive CNNs for Pulmonary Airway and Artery-Vein
  Segmentation in CT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/eess.IV/paper_7.html">
      <font color="black">Learning Tubule-Sensitive CNNs for Pulmonary Airway and Artery-Vein
  Segmentation in CT</font>
    </a>
  </h2>
  <font color="black">広範な実験により、これらのコンポーネントによって大幅なパフォーマンスの向上が実証されました。機能の空間情報は、アクティブ化された領域の相対的な優先順位を保持するために適切に統合され、その後のチャネルごとの再キャリブレーションに役立ちます。正確な気道と動脈のためのCNNベースの方法を提示します。非造影コンピュータ断層撮影における静脈セグメンテーション。 
[ABSTRACT] cnns。正確な気道と動脈のための末梢法-非コントラスト構築トモグラフィーにおける静脈セグメンテーション。方法は、最初に特徴再較正モジュールを使用して、ニューラルネットワークから学習した特徴を最大限に活用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Detection of Covid-19 Patients with Convolutional Neural Network Based
  Features on Multi-class X-ray Chest Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/eess.IV/paper_8.html">
      <font color="black">Detection of Covid-19 Patients with Convolutional Neural Network Based
  Features on Multi-class X-ray Chest Images</font>
    </a>
  </h2>
  <font color="black">これらの中で最も重要なのは、Covid-19を取得した人を正しく識別することです。サポートベクターマシンによる分類パフォーマンスは、畳み込みニューラルネットワークモデルの1つである残余ネットワーク（ResNet-50）で抽出された特徴を使用して取得されています。これらの画像..Covid-19検出はサポートベクターマシン（SVM）で取得されますが、5倍クロスバリデーション法で96.35％の最高感度値を持つ二次関数ですが、両方のSVMで最高の全体的なパフォーマンス値が検出されました- 99％を超える2次およびSVM-3次。 
[要約] covid-19のパンデミックにより、国はできるだけ早く深刻な健康と経済の問題に直面します。これは世界で最悪のシナリオであり、深刻な健康問題に直面しているパンデミックに関連しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: COVID-MTL: Multitask Learning with Shift3D and Random-weighted Loss for
  Diagnosis and Severity Assessment of COVID-19 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/eess.IV/paper_9.html">
      <font color="black">COVID-MTL: Multitask Learning with Shift3D and Random-weighted Loss for
  Diagnosis and Severity Assessment of COVID-19</font>
    </a>
  </h2>
  <font color="black">次に、ランダム加重マルチタスク損失関数が提案され、さまざまなCOVID-19タスクの同時学習がより安定して正確になりました。CTデータを使用して肺画像の特徴を抽出するだけで、COVID-MTLは930 CTスキャンでトレーニングされ、別の399例では、AUCが0.939と0.846、精度が90.23％と79.20％で、放射線学とNATに対するCOVID-19の検出がそれぞれ行われ、最先端のモデルを上回りました。COVIDの発生- 19は、これまでに世界中で150万人以上の死者を出し、6700万人以上の感染をもたらしました。 
[概要] covid-19ctスキャンとshift3dリアルタイム3d拡張アルゴリズムで肺のセグメンテーション結果を改善するためのアクティブな輪郭ベースの方法を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Deep learning methods for SAR image despeckling: trends and perspectives -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/eess.IV/paper_10.html">
      <font color="black">Deep learning methods for SAR image despeckling: trends and perspectives</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、教師ありアプローチと最近の自己教師ありアプローチの両方をカバーする、SARスペックル除去に適用されるディープラーニング手法に関する文献を調査します。最初のスペックル除去手法は1970年代にさかのぼり、その後、いくつかのモデルベースのアルゴリズムが開発されました。年..合成開口レーダー（SAR）画像は、スペックルと呼ばれる空間的に相関し、信号に依存するノイズの影響を受けます。スペックルは非常に深刻で、画像の利用を妨げる可能性があります。 
[ABSTRACT]スペックル除去は、このようなノイズを除去して、すべてのダウンストリーム画像処理タスクの精度を向上させることを目的とした重要なタスクです。深層学習モデルは、画像処理の逆問題に対して優れたパフォーマンスをもたらしました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Effect of the regularization hyperparameter on deep learning-based
  segmentation in LGE-MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/eess.IV/paper_11.html">
      <font color="black">Effect of the regularization hyperparameter on deep learning-based
  segmentation in LGE-MRI</font>
    </a>
  </h2>
  <font color="black">実験で使用された任意のL2正則化値を使用すると、結果は、L2正則化数が小さいほど、心筋のセグメンテーションが改善され、精度が高くなる可能性があることを示しました。この予備評価では、著者は任意のL2正則化の程度を示します。 L2正則化ハイパーパラメーターの選択は、LGE-MRIでの深層学習ベースのセグメンテーションの結果に影響を与える可能性があります。また、著者は、他の深層学習ハイパーパラメーターの手動調整または調整を採用して、すべてのエポックの10％が90％の検証精度を達成する前に到達しました。 
[概要]著者はまた、すべてのエポックの10％に達した場合にのみ手動パラメーターを実行できることを採用しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Developing High Quality Training Samples for Deep Learning Based Local
  Climate Zone Classification in Korea -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/eess.IV/paper_12.html">
      <font color="black">Developing High Quality Training Samples for Deep Learning Based Local
  Climate Zone Classification in Korea</font>
    </a>
  </h2>
  <font color="black">代わりに、この研究では、マルチスケール畳み込みニューラルネットワークを使用して韓国の主要都市をマッピングするカスタムLCZデータを開発しました。グローバルスケールのLCZマッピングが検討されていますが、精度の低さ、ラベルの品質の変動、またはドメイン適応の課題によって制限されています。結果は、深層学習で新しいカスタムLCZデータを使用すると、グローバルSo2Satデータセットの転送学習だけでなく機械学習を使用した従来のコミュニティベースのLCZマッピングと比較して、より正確なLCZマップ結果を生成できることを示しました。 
[ABSTRACT]都市フットプリントデータは、高解像度の都市フレームワークを提供しますが、分布、パターン、および特性に関する重要な情報が不足しています。都市ゾーンマップは調査されていますが、精度の低さ、ラベルの品質の変動、またはドメイン適応の課題によって制限されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Generation of Interpretable Lung Cancer Scoring Models from
  Chest X-Ray Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/eess.IV/paper_13.html">
      <font color="black">Automatic Generation of Interpretable Lung Cancer Scoring Models from
  Chest X-Ray Images</font>
    </a>
  </h2>
  <font color="black">さらに、このプロセスによって作成された決定木は、医療専門家が臨床的に使用可能な多変量肺がんのスコアリングおよび診断モデルに改良するための開始点と見なすことができます。小さな推論データセットの場合、この方法は84％を超える最高の精度を達成します。悪性クラスの陽性予測値は83％です。人工的な「2回目の読み取り」を提供しようとするのではなく、コンピュータービジョンと機械学習技術を使用して、公開されているデータから実行可能な決定木モデルを自動的に作成することに焦点を当てます。 
[要約]研究によると、機械学習技術は肺がんを自動的に診断するのに効果的ですが、これらの技術はまだ医学界によって承認および承認されていません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Learning Optimization-inspired Image Propagation with Control Mechanisms
  and Architecture Augmentations for Low-level Vision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_0.html">
      <font color="black">Learning Optimization-inspired Image Propagation with Control Mechanisms
  and Architecture Augmentations for Low-level Vision</font>
    </a>
  </h2>
  <font color="black">さらに、伝播の安定性とタスク/データ適応能力をそれぞれ強化するために、2つのアーキテクチャ拡張戦略（つまり、正規化と自動検索）を導入します。ただし、これらのヒューリスティック学習モデルには、伝播を制御するメカニズムがなく、アーキテクチャエンジニアリングに大きく依存していることがよくあります。 ..画像の伝播をガイドする制御メカニズムを設計することにより、完全に定義された最適化の定式化と部分的に定義された最適化の定式化の両方について、GDCの収束保証を取得します。 
[概要]新しいアプローチを構築する主なアイデアは、ハイジャックとネットワークアーキテクチャを組み合わせて、特定の種類のアピールの画像通信を生成することです。これにより、問題を軽減できますが、さまざまな低レベルの統合モデルを作成するために使用できます。ビジョンタスク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: A New 3D Method to Segment the Lumbar Vertebral Bodies and to Determine
  Bone Mineral Density and Geometry -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_1.html">
      <font color="black">A New 3D Method to Segment the Lumbar Vertebral Bodies and to Determine
  Bone Mineral Density and Geometry</font>
    </a>
  </h2>
  <font color="black">真の3Dセグメンテーションは、BMDの古典的な測定を強化できる幾何学的パラメーターの正確な測定も可能にします。この作業の長期的な目標は、骨粗鬆症の分野でより良い骨折予測と改善された患者モニタリングを可能にすることです。スパイラル計算機トモグラフィーデータセットで、胸部下部の椎骨と腰椎の新しい3Dセグメンテーションアプローチを紹介します。 
[要約] 10人の患者からのctデータセットを使用したオペレーターの精度は、臨床使用の可能性を強調しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2017-05-19">
        <br><font color="black">2017-05-19</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Bounding Box Detection in Volumetric Medical Image Data: A Systematic
  Literature Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_2.html">
      <font color="black">3D Bounding Box Detection in Volumetric Medical Image Data: A Systematic
  Literature Review</font>
    </a>
  </h2>
  <font color="black">結果は、ほとんどの研究が最近、畳み込みニューラルネットワークなどのディープラーニング手法と手動機能エンジニアリングを使用した手法に焦点を合わせていることを示しています。 Random-Regression-Forests .. 2Dおよび3Dの実装について説明し、比較します。 
[概要]解剖学的構造を特定するための複数の識別されたアプローチが提示されます。複数の識別されたアプローチが提示されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Modality to Modality Translation: An Adversarial Representation Learning
  and Graph Fusion Network for Multimodal Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_3.html">
      <font color="black">Modality to Modality Translation: An Adversarial Representation Learning
  and Graph Fusion Network for Multimodal Fusion</font>
    </a>
  </h2>
  <font color="black">コードは\ url {https://github.com/TmacMai/ARGF_multimodal_fusion}で入手できます。学習された埋め込みの視覚化は、私たちの方法によって学習された共同埋め込み空間が識別可能であることを示唆しています。さまざまなモダリティの分布は性質が異なるため、モダリティのギャップを減らすために、ソースモダリティの分布をそれぞれの方法でターゲットモダリティの分布に変換します。敵対的な訓練を使用するエンコーダー。 
[概要]敵対的トレーニングを使用して、それぞれのエンコーダーを介してソースモダリティの分布をターゲットモダリティの分布に変換します。学習した埋め込み者の視覚化は、私たちの方法で学習した共同埋め込みスペースが識別可能であることを示唆しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-18">
        <br><font color="black">2019-11-18</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Consistent Video Depth Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_4.html">
      <font color="black">Robust Consistent Video Depth Estimation</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、深度とポーズの両方の推定において、Sintelベンチマークの最新技術を定量的に上回り、多様な野生データセット全体で好ましい定性的結果を達成します。私たちのアルゴリズムは、2つの補完的な手法を組み合わせています。（1）低周波用の柔軟な変形スプライン大規模アライメントと（2）細かい深度詳細の高周波アライメントのためのジオメトリ認識深度フィルタリング..単眼ビデオから一貫した高密度深度マップとカメラポーズを推定するためのアルゴリズムを提示します。 
[概要]私たちの方法は、単一の画像深度推定用にトレーニングされた畳み込みニューラルネットワークの形式で、学習ベースの深度事前を組み合わせます。この方法は、入力としてカメラポーズを必要とせず、挑戦的な携帯電話のキャプチャのための堅牢な再構成を実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Retinex-inspired Unrolling with Cooperative Prior Architecture Search
  for Low-light Image Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_5.html">
      <font color="black">Retinex-inspired Unrolling with Cooperative Prior Architecture Search
  for Low-light Image Enhancement</font>
    </a>
  </h2>
  <font color="black">広範な実験により、最近提案された最先端の方法に対するRUASフレームワークの優位性が検証されます。ただし、これらのアプローチは主に重要なアーキテクチャエンジニアリングに依存しており、計算負荷が高くなります。具体的には、RUASは最初にRetinexルールに基づいて確立します。低照度画像の固有の露出不足構造を特徴付け、それらの最適化プロセスを展開して、全体的な伝播構造を構築するためのモデル。 
[概要]レチネックス-アーキテクチャ検索によるインスピレーションを受けた展開（ruas）は、現実世界のシナリオでの低照度画像用の軽量で効果的な拡張ネットワークを構築するための新しい方法です。レチネックス-インスパイアされたレチネックス-アーキテクチャ検索でのインスピレーションを受けた展開、ruas 、最高のパフォーマンスを発揮する画像強調ネットワークを取得できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Debiased-CAM for bias-agnostic faithful visual explanations of deep
  convolutional networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_6.html">
      <font color="black">Debiased-CAM for bias-agnostic faithful visual explanations of deep
  convolutional networks</font>
    </a>
  </h2>
  <font color="black">Debiased-CAMを提示して、CAMとバイアスレベル予測の補助タスクを備えたマルチ入力マルチタスクモデルをトレーニングすることにより、さまざまなバイアスタイプとレベルにわたる説明の忠実度を回復します。クラスアクティベーションマップ（CAM）は、特定することによって畳み込みニューラルネットワーク予測を説明します。顕著なピクセルですが、プライバシー保護のために誤ってまたは意図的にぼやけた画像や不適切なホワイトバランスの画像など、バイアスのある画像の予測を説明するときに、位置がずれて誤解を招くようになります。予測タスクとしてCAMを使用すると、説明を再トレーニングすることで調整可能になります。メインモデルレイヤーとバイアスのない画像のCAMからの自己監視学習によって忠実になりました。 
[ABSTRACT] debiased-camは、カムの忠実度とタスクのパフォーマンスの両方を改善しました。たとえば、debiasedは、両方のモデルのアカウントを改善しました。debiasedバージョンは、より真実で役に立ちました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Geometric Adversarial Attacks and Defenses on 3D Point Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_7.html">
      <font color="black">Geometric Adversarial Attacks and Defenses on 3D Point Clouds</font>
    </a>
  </h2>
  <font color="black">これまでの研究は、セマンティックレベル、つまりディープポイントクラウド分類子に焦点を当ててきました。つまり、クリーンなソースポイントクラウドへの小さな変更は、オートエンコーダモデルを通過した後、別のターゲットクラスの形状につながります。防御側では、攻撃のターゲット形状の残骸が、敵の入力に防御を適用した後も、再構築された出力にまだ存在していることを示します。 
[概要]そのようなモデルに対する敵対的攻撃と防御への関心が高まっています。しかし、点群は、点群の変更と再構築を含む幾何学的関連の形式でも広く使用されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: R-AGNO-RPN: A LIDAR-Camera Region Deep Network for Resolution-Agnostic
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_8.html">
      <font color="black">R-AGNO-RPN: A LIDAR-Camera Region Deep Network for Resolution-Agnostic
  Detection</font>
    </a>
  </h2>
  <font color="black">さらに、そのパフォーマンスを評価するために、私たちの方法を、よく知られている3D検出ネットワークであるPointPillarsと比較します。実験結果は、点群データが元のポイントの$ 80 \％$削減された場合でも、私たちの方法は依然として関連する提案のローカリゼーションを提供します。低解像度の点群に対する復元力は、バーズアイビューに正確にマッピングされた画像機能と、RGB画像の寄与を改善する特定のデータ拡張手順によって得られます。 
[ABSTRACT]提案されたネットワークは、さまざまな点群解像度を処理することを目的としています。実験は、kitti3dオブジェクト検出からのデータとnuscenesデータセットの両方で実施されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Concept Generalization in Visual Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_9.html">
      <font color="black">Concept Generalization in Visual Representation Learning</font>
    </a>
  </h2>
  <font color="black">この論文では、見えた概念と見えない概念の間の意味関係が一般化のパフォーマンスに影響を与えると主張し、概念の一般化を原理的に測定できるImageNetデータセットの新しいベンチマークであるImageNet-CoGを提案します。 ImageNet-1Kすぐに使用可能：概念の一般化のプリズムの下で、監視、半監視、および自己監視のアプローチからそのようなモデルの数を分析し、ベンチマークが多くの興味深い洞察を明らかにする方法を示します。 。https：//europe.naverlabs.com/cog-benchmarkでベンチマークのリソースを提供します。 
[概要]ベンチマークは、ワードマークの知識を使用するワードマークに基づいています。これにより、これらの概念セットをイメージネットからますます遠ざけることができます。これには、ユビキタストレーニングセットである1kサブセットが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Full-Glow: Fully conditional Glow for more realistic image generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_10.html">
      <font color="black">Full-Glow: Fully conditional Glow for more realistic image generation</font>
    </a>
  </h2>
  <font color="black">この論文では、シーンのレイアウトを示すセマンティックセグメンテーションマップを指定して、新しいストリートシーンのもっともらしいリアルな画像を生成するための完全条件付きグローベースのアーキテクチャであるFull-Glowを提案します。ベンチマークの比較は、モデルが最近の作品よりも優れていることを示しています。事前にトレーニングされたPSPNetのセマンティックセグメンテーションパフォーマンス。無人車などの自律エージェントは、トレーニングのために大量のラベル付きビジュアルデータを必要とします。 
[概要]モデルはモデルをトレーニングし、シーンのレイアウトとグラウンドトゥルースのラベル付けを制御して生成されたモデルからの合成画像でデータセットを拡張します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: VGAI: End-to-End Learning of Vision-Based Decentralized Controllers for
  Robot Swarms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_11.html">
      <font color="black">VGAI: End-to-End Learning of Vision-Based Decentralized Controllers for
  Robot Swarms</font>
    </a>
  </h2>
  <font color="black">初めて、コミュニケーションと視覚の2つの主要コンポーネントの学習を1つのエンドツーエンドフレームワークに統合します。提案された学習フレームワークは、各ロボットの畳み込みニューラルネットワーク（CNN）を組み合わせて、視覚からメッセージを抽出します。入力、およびアクションを決定するためにこれらのメッセージを送信、受信、および処理するための群れ全体にわたるグラフ畳み込みネットワーク（GNN）。より具体的には、各ロボットが周囲の視覚にアクセスできると見なします。他の隣接するロボットとの間でメッセージを送受信するための通信機能。 
[概要]自律自律自律概念のネットワークが自律自律開発に提案されました。この概念は、人間開発のための自律自律システムの開発に使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br><font color="black">2020-02-06</font>
      </time>
    </span>
</section>
<!-- paper0: Wasserstein-2 Generative Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_12.html">
      <font color="black">Wasserstein-2 Generative Networks</font>
    </a>
  </h2>
  <font color="black">理論的な側面から、アルゴリズムによって適合された生成マッピングの特性を推定します。実用的な側面から、画像から画像への色の転送、潜在空間の最適な転送、画像-の幅広いタスクでアルゴリズムを評価します。画像へのスタイル転送、およびドメイン適応..アルゴリズムは、入力凸型ニューラルネットワークとサイクル整合性の正規化を使用して、Wasserstein-2距離を概算します。 
[要約]アルゴリズムはサイクルを使用します-一貫性の正則化を使用してワッサーシュタインを測定します-2距離</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-28">
        <br><font color="black">2019-09-28</font>
      </time>
    </span>
</section>
<!-- paper0: Look Before you Speak: Visually Contextualized Utterances -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_13.html">
      <font color="black">Look Before you Speak: Visually Contextualized Utterances</font>
    </a>
  </h2>
  <font color="black">残念ながら、会話の会話に視覚的なコンテキストを組み込むための主な課題は、大規模なラベル付きデータセットの欠如です。オンラインで多数の教育ビデオを活用することにより、手動の注釈を必要とせずに、このタスクを大規模に解決するモデルをトレーニングします。 ..マルチモーダル学習の最近の進歩を活用して、私たちのモデルは、新しい共注意マルチモーダルビデオトランスフォーマーで構成され、テキストとビジュアルの両方のコンテキストでトレーニングすると、テキスト入力のみを使用するベースラインを上回ります。 
[概要]私たちのタスクには、視覚的なフレームと文字起こしされた音声の両方をコンテキストとして使用して、ビデオ内の次の発話を予測することが含まれます。視覚的な視覚的な会話には大規模なデータセットが必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Effect of Different Batch Size Parameters on Predicting of COVID19 Cases -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_14.html">
      <font color="black">Effect of Different Batch Size Parameters on Predicting of COVID19 Cases</font>
    </a>
  </h2>
  <font color="black">最高のCOVID19検出はBH = 3で95.17％でしたが、全体的な精度値はBH = 20で97.97％でした。さらに、X線およびCTイメージング法もこの方法をサポートするために使用されます。バッチサイズの値は全体のパフォーマンスに大きな影響を与えないと言えますが、バッチサイズの値が大きくなると安定した結果が得られなくなります。 
[概要]ウイルスは2020年3月に世界保健機関によって送信されます。これは、rrt-pcrテストの精度感度が低いことが知られているためです。しかし、コンピュータイメージングはウイルスを検出するための非常に重要な場所です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: BSN++: Complementary Boundary Regressor with Scale-Balanced Relation
  Modeling for Temporal Action Proposal Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_15.html">
      <font color="black">BSN++: Complementary Boundary Regressor with Scale-Balanced Relation
  Modeling for Temporal Action Proposal Generation</font>
    </a>
  </h2>
  <font color="black">2つの人気のあるベンチマークであるActivityNet-1.3とTHUMOS14で広範な実験が行われ、BSN ++が最先端のパフォーマンスを達成していることを示しています。次に、以前の方法で無視された提案と提案の関係を説明するために、提案を考案します。位置とチャネルの観点から2つの自己注意モジュールを含む関係ブロック。この論文では、時間的提案生成のために補完的な境界回帰子と関係モデリングを活用する新しいフレームワークであるBSN ++を提示します。 
[ABSTRACT]現在の方法では、境界の場所にノイズが多く、提案の取得に使用される信頼スコアの品質が低いことがよくあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: MorphGAN: One-Shot Face Synthesis GAN for Detecting Recognition Bias -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_16.html">
      <font color="black">MorphGAN: One-Shot Face Synthesis GAN for Detecting Recognition Bias</font>
    </a>
  </h2>
  <font color="black">MorphGANを使用して生成された画像は、元の画像内の人物のIDを保存し、頭のポーズと顔の表情を制御できるため、ポーズと表情に関する顔認識の深いネットワークの堅牢性の問題を特定するためのテストセットを作成できます。顔認識ネットワークのバイアスを検出する場合、特定の属性のみが何らかの制御された方法で変化するサンプルを使用して、テスト対象のネットワークをプローブすると便利です。次に、元の画像とレンダリングされたモーフィング可能条件を条件とする条件付きGenerative Adversarial Network（GAN）モデルは、新しい表情と頭のポーズで元の人物の画像を生成するために使用されます。 
[概要]シミュレーターシティは、最初に3Dモーフィング可能なモデルを提供された画像に適合させます。目的の頭のポーズと表情のコントロールを適用してから、モデルを画像にレンダリングします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Performance Comparison of Balanced and Unbalanced Cancer Datasets using
  Pre-Trained Convolutional Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_17.html">
      <font color="black">Performance Comparison of Balanced and Unbalanced Cancer Datasets using
  Pre-Trained Convolutional Neural Network</font>
    </a>
  </h2>
  <font color="black">特に異なる倍率のデータを使用することによる良性または悪性腫瘍の検出は、文献で行われています。この研究では、BreakHisデータセットの組織病理学的データを使用して、2つの異なる平衡および不平衡研究グループが形成されました。バランスの取れた方法で作成されたデータセットの助けを借りて訓練されたモデルは、病理学の専門家により高く正確な結果をもたらすと言えます。 
[ABSTRACT]特に女性によく見られるがんの病気である乳がんは非常に一般的です。これらの画像は病理学者によって検査され、確定診断が行われます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Enhancing Human Pose Estimation in Ancient Vase Paintings via
  Perceptually-grounded Style Transfer Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_18.html">
      <font color="black">Enhancing Human Pose Estimation in Ancient Vase Paintings via
  Perceptually-grounded Style Transfer Learning</font>
    </a>
  </h2>
  <font color="black">（2）すでに強力な結果をさらに改善するために、紀元前6〜5世紀の古代ギリシャの花瓶の絵画と人物とポーズの注釈で構成される小さなデータセット（ClassArch）を作成しました。知覚的に根拠のあるスタイルの転送トレーニングを導入して実施します。知覚の一貫性..スタイル転送学習を使用すると、平均平均精度（mAP）と平均平均想起（mAR）が6％以上、ラベルなしデータのSOTAパフォーマンスが大幅に向上することを示します。 
[概要]新しいhpeの結果はドメイン間で十分に一般化されず、ポーズの認識が不十分になります。ただし、既存の新しい方法では、さまざまなタイプで十分に一般化されません。つまり、知覚の一貫性を強化するために、知覚的に根拠のあるスタイルの転送トレーニングを導入します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Few-shot Medical Image Segmentation using a Global Correlation Network
  with Discriminative Embedding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_19.html">
      <font color="black">Few-shot Medical Image Segmentation using a Global Correlation Network
  with Discriminative Embedding</font>
    </a>
  </h2>
  <font color="black">医用画像の空間的一貫性と規則性に動機付けられて、サポート画像とクエリ画像の間の相関をキャプチャし、それをグローバル相関ネットワークと呼ばれる深いネットワークに組み込むための効率的なグローバル相関モジュールを開発しました。アブレーション研究は、提案されたグローバルの有効性を証明しました相関モジュールと識別的埋め込み損失..さらに、異なる器官の特徴ドメインを遠くに保ちながら、同じクラスの特徴ドメインのクラスター化を促進するために、深い埋め込みの識別可能性を強化します。 
[ABSTRACT]大規模なセマンティックアノテーションは、条件によっては取得が困難です。これは、アノテーション付きクラスがほとんどない一般的な条件でもあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Augmented Equivariant Attention Networks for Electron Microscopy Image
  Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_20.html">
      <font color="black">Augmented Equivariant Attention Networks for Electron Microscopy Image
  Super-Resolution</font>
    </a>
  </h2>
  <font color="black">これらの制限に対処するために、空間順列への等分散性を維持しながら、画像間の依存関係と共有機能をキャプチャするためのより優れた機能を備えた拡張同変注意ネットワーク（AEANets）を提案します。実験的に取得したEM画像のペアで超解像度モデルをトレーニングする場合、以前のモデルは、画像間依存関係と画像間で共有される共通機能をキャプチャできないため、プールトレーニング戦略を使用しているときにパフォーマンスが低下します。提案されたAEANetsは、画像間依存関係と画像間で共有される共通機能を2つの拡張機能を介してキャプチャします。注意メカニズム;つまり、共有参照とトレーニング中のバッチ認識の注意。 
[概要]提案されたaeanetsは、画像間の依存関係と画像間で共有される共通の機能をキャプチャします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-06">
        <br><font color="black">2020-11-06</font>
      </time>
    </span>
</section>
<!-- paper0: Scene Text Detection with Scribble Lines -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_21.html">
      <font color="black">Scene Text Detection with Scribble Lines</font>
    </a>
  </h2>
  <font color="black">いくつかのベンチマークでの実験は、提案された方法が弱いラベリング方法と元のポリゴンベースのラベリング方法の間のパフォーマンスギャップを埋め、さらに優れたパフォーマンスを示すことを示しています。さらに、落書きを使用するために弱く監視されたシーンテキスト検出フレームワークが提案されます。テキスト検出用の行..これは、さまざまな形状のテキストの一般的なラベル付け方法であり、低いラベル付けコストが必要です。 
[ABSTRACT]ベンチマークは、テキスト検出のためにポリゴンではなく落書き線でテキストに注釈を付けるために提案されています。この方法は、より単純な注釈でパフォーマンスを向上させるために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Large-Scale Generative Data-Free Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_22.html">
      <font color="black">Large-Scale Generative Data-Free Distillation</font>
    </a>
  </h2>
  <font color="black">この目的のために、トレーニングされた教師ネットワークの固有の正規化レイヤーの統計を活用して生成画像モデルをトレーニングする新しい方法を提案します。しかし、これはプライバシー、所有権、可用性の懸念のために実際には問題になる可能性があります。後続の蒸留のための代替入力を効率的に生成できるトレーニングデータなしで、ジェネレータのアンサンブルを構築します。 
[概要]ほとんどの既存の蒸留アプローチでは、古いトレーニングサンプルまたは拡張トレーニングサンプルにアクセスする必要がありますが、それらは高度に実践されているか、大規模なデータセットに拡張できません。これにより、トレーニングデータなしでジェネレーターのアンサンブルを構築できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Imperceptible Adversarial Image Patches Based on Network
  Explanations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_23.html">
      <font color="black">Towards Imperceptible Adversarial Image Patches Based on Network
  Explanations</font>
    </a>
  </h2>
  <font color="black">このソフトマスクに基づいて、CFRの最適な摂動を検索するために、逆温度を使用した新しい目的関数を開発します。したがって、摂動は冗長性があり、人間の目で簡単に検出できます。この論文では、ローカルを生成する新しい方法を提案します。領域の摂動。 
[概要]主なアイデアは、摂動のネットワーク説明に基づいて、画像の寄与特徴領域を見つけることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Low Rank Regularization: A Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_24.html">
      <font color="black">Low Rank Regularization: A Review</font>
    </a>
  </h2>
  <font color="black">続いて、従来の機械学習タスクで大きな成功を収めたが、実際の問題の解決ではめったに見られない正則化と最適化の方法を要約します。低ランクの正則化は、本質的に、目的のマトリックスに低ランクまたはほぼ低ランクの仮定を導入することを含みます。機械学習、データマイニング、コンピューターバージョンなど、多くの分野で大きな成功を収めているlearn。最後に、凸型および非凸型の緩和を含むいくつかの代表的な正則化について説明し、比較します。 
[概要]実用化と理論研究の架け橋となるため、本稿では低ランク正則化の総合調査を行います。正則化応用は機械学習タスクで大きな成功を収めることができますが、実用的な問題の解決にはほとんど見られません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-08-14">
        <br><font color="black">2018-08-14</font>
      </time>
    </span>
</section>
<!-- paper0: Planet cartography with neural learned regularization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_25.html">
      <font color="black">Planet cartography with neural learned regularization</font>
    </a>
  </h2>
  <font color="black">単一の通過帯域観測を使用する場合でも、信頼性の高いマッピングを実行でき、非常にコンパクトな大陸を生成できることを示します。この作業では、私たちが見つけたものに触発された、惑星の手続き型生成に基づく方法を使用することを提案します。 Earth ..ディープラーニングの可能性を活用し、正則化が模擬表面から学習されるエキソアースのマッピング手法を提案します。 
[概要]太陽系外惑星での生命の兆候を見つけることは、惑星大気のバルク組成を決定することによって最初に達成される可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-08">
        <br><font color="black">2020-12-08</font>
      </time>
    </span>
</section>
<!-- paper0: SPAA: Stealthy Projector-based Adversarial Attacks on Deep Image
  Classifiers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_26.html">
      <font color="black">SPAA: Stealthy Projector-based Adversarial Attacks on Deep Image
  Classifiers</font>
    </a>
  </h2>
  <font color="black">注意深く設計されたステッカーや印刷された敵対的なオブジェクトを配置する物理的な攻撃と比較して、プロジェクターベースの攻撃は物理的なエンティティの変更を不要にします。この論文では、初めてこの問題をエンドツーエンドの差別化可能なプロセスとして定式化し、ステルスを提案します。プロジェクターベースの敵対的攻撃（SPAA）。光ベースの敵対的攻撃は、プロジェクターなどの制御可能な光源を使用して物理的な光の状態を変更することにより、深い学習ベースの画像分類器をだますことを目的としています。 
[ABSTRACT]既存のアプローチは、はっきりと知覚できるカメラ（キャプチャされた摂動）をもたらす敵対的なパターンの投影に焦点を当てていますが、より興味深いが挑戦的なプロジェクターベースの攻撃はオープンソースのままです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Model-based Catheter Segmentation in MRI-images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_27.html">
      <font color="black">Model-based Catheter Segmentation in MRI-images</font>
    </a>
  </h2>
  <font color="black">平均誤差は1.40mm、中央値誤差は1.05 mmでした。それらの曲げ特性は、画像の特徴に基づく候補点を制約するために使用されます。101個の手動セグメントカテーテルを含む10人の患者MRIスキャンのデータベースで方法を評価します。 
[概要] 10人の患者のMRIスキャンのデータベースには、手動でセグメント化された101本のカテーテルが含まれています。この方法は、1,000本のカテーテルの失敗したデータベースに基づいています。これには、98％を超える正しいカテーテル識別率が含まれます（エラー2.88 mm）。カテーテルの異常値の減少。最先端技術と比較して1/4に</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2017-05-18">
        <br><font color="black">2017-05-18</font>
      </time>
    </span>
</section>
<!-- paper0: Learning 3D Dynamic Scene Representations for Robot Manipulation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_28.html">
      <font color="black">Learning 3D Dynamic Scene Representations for Robot Manipulation</font>
    </a>
  </h2>
  <font color="black">さらに、DSR-Netを提案します。これは、DSRを徐々に構築および改良するために、複数のインタラクションにわたって視覚的観察を集約することを学習します。ロボット操作の3Dシーン表現は、3つの主要なオブジェクトプロパティをキャプチャする必要があります。アモーダル完全性-部分的な観測しか利用できない場合でも、オブジェクトには3D占有率があります。時空間連続性-各オブジェクトの動きは、空間と時間にわたって連続的です。私たちのモデルは、シミュレートされたデータと実際のデータの両方でDSRを使用して3Dシーンダイナミクスをモデリングする際に最先端のパフォーマンスを実現します。 
[概要]たとえば、3D動的シーン表現（dsr）を導入します。これは、3つのプロパティすべてをキャプチャしながら、オブジェクトの検出、追跡、再構築、およびダイナミクスの予測を同時に行います。このビデオは、さまざまなビデオで利用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Amodal Segmentation Based on Visible Region Segmentation and Shape Prior -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_29.html">
      <font color="black">Amodal Segmentation Based on Visible Region Segmentation and Shape Prior</font>
    </a>
  </h2>
  <font color="black">ほとんどすべての既存のアモーダルセグメンテーション方法は、画像全体に対応する特徴を使用して、遮蔽された領域の推論を行います。 
[要約]ほとんどすべての既存のアモーダルセグメンテーション方法は、画像全体に対応する特徴を使用することにより、閉塞領域の可能性を作ります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Portrait Neural Radiance Fields from a Single Image -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_30.html">
      <font color="black">Portrait Neural Radiance Fields from a Single Image</font>
    </a>
  </h2>
  <font color="black">単一のヘッドショットポートレートからニューラルラディアンスフィールド（NeRF）を推定する方法を示します。NeRFは高品質のビュー合成を示していますが、静的シーンの複数の画像が必要であるため、カジュアルなキャプチャや動く被写体には実用的ではありません。見えない顔への一般化では、3D顔モーフィング可能モデルによって近似された正準座標空間でMLPをトレーニングします。 
[ABSTRACT] nerfは見えない顔に高品質の視覚化を示しました。3D顔モーフィング可能モデル間のリンクでmmpをトレーニングします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Manifold Implicitly via Explicit Heat-Kernel Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_31.html">
      <font color="black">Learning Manifold Implicitly via Explicit Heat-Kernel Learning</font>
    </a>
  </h2>
  <font color="black">フレームワークの実用的なアルゴリズムと理論的分析の両方を提供します。学習した熱核は、データ生成用の深層生成モデル（DGM）やベイズ推定用のスタイン変分勾配降下など、さまざまなカーネルベースの機械学習モデルに適用できます。実験は、私たちのフレームワークが2つのタスクの既存の方法と比較して最先端の結果を達成できることを示しています。 
[概要]熱核は、対応する熱方程式の解であり、「熱」が道路上でどのように伝達されるかを記述します。学習した熱核は、深層熱核モデルを含むさまざまなカーネルベースの機械学習モデルに適用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Learned Block Iterative Shrinkage Thresholding Algorithm for
  Photothermal Super Resolution Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_32.html">
      <font color="black">Learned Block Iterative Shrinkage Thresholding Algorithm for
  Photothermal Super Resolution Imaging</font>
    </a>
  </h2>
  <font color="black">ブロックスパース正則化は、アクティブ熱画像ですでによく知られており、複数の測定ベースの逆問題に使用されます。さらに、このアルゴリズムにより、適切な重み行列を決定して、根本的な逆問題を解決できます。学習されたブロックスパース最適化アプローチを使用すると、学習しない場合よりも、固定された少数の反復に対して、より小さな正規化された平均二乗誤差が提供されます。 
[ABSTRACT]ブロック反復収縮しきい値処理は、正則化パラメーターの選択を学習できます。この方法では、光熱超解像イメージングで正確な欠陥再構成を生成するために数回の反復が可能です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Composite Adversarial Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_33.html">
      <font color="black">Composite Adversarial Attacks</font>
    </a>
  </h2>
  <font color="black">実験結果は、CAAが11の多様な防御で10人の上位の攻撃者をより短い経過時間で打ち負かし（\ textbf {6 $ \ times $ AutoAttack}よりも速い）、$ l _ {\ infty}で新しい最先端を達成することを示しています。 $、$ l_ {2} $および無制限の敵対的攻撃..攻撃ポリシーが攻撃シーケンスとして表される検索スペースを設計します。つまり、前の攻撃者の出力が後継者の初期化入力として使用されます。多目的NSGA-II遺伝子アルゴリズムは、最小限の複雑さで最強の攻撃ポリシーを見つけるために採用されています。 
[概要]攻撃アルゴリズムとそのハイパーパラメータの最適な組み合わせを自動的に検索するために、複合敵対的攻撃（caa）と呼ばれる新しい手法が提案されています。新しい方法は「複合敵対的」と呼ばれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Interactive Fusion of Multi-level Features for Compositional Activity
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_34.html">
      <font color="black">Interactive Fusion of Multi-level Features for Compositional Activity
  Recognition</font>
    </a>
  </h2>
  <font color="black">2つの行動認識データセット、Something-SomethingとCharadesでアプローチを評価します。この論文では、インタラクティブな融合、つまり、異なる空間に特徴を投影し、補助予測タスクを使用してそれを導くことによって、この目標を達成する新しいフレームワークを提示します。 。インタラクティブフュージョンは、既製のアクション認識アルゴリズムを超えて一貫した精度の向上を実現します。 
[ABSTRACT]インタラクティブな融合を作成するために、3つのステップでフレームワークを実装します。これには、位置から外観への特徴抽出、意味的特徴の相互作用、および意味から位置への予測が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Topology-Adaptive Mesh Deformation for Surface Evolution, Morphing, and
  Multi-View Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_35.html">
      <font color="black">Topology-Adaptive Mesh Deformation for Surface Evolution, Morphing, and
  Multi-View Reconstruction</font>
    </a>
  </h2>
  <font color="black">これらの問題を自然に克服するレベルセット。結果として、メソッドの大部分は、サーフェスの暗黙的な表現に依存しています。ただし、明示的なメッシュ表現は、正確なサーフェスモデリングを可能にする一方で、自己交差や、マージや分割などのトポロジの変更を確実に処理するという固有の困難に悩まされています。 
[概要]この論文では、構造変化を引き起こす可能性のある強い変形を受けている間、表面の特性を維持する方法の問題に対処します。これは、不適切なメッシュ表現を含む、3つの異なる形態の高血圧を管理する方法を説明します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Noise Estimation Using Density Estimation for Self-Supervised Multimodal
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_36.html">
      <font color="black">Noise Estimation Using Density Estimation for Self-Supervised Multimodal
  Learning</font>
    </a>
  </h2>
  <font color="black">この作業では、マルチモーダルデータのノイズ推定の問題をマルチモーダル密度推定タスクに還元できることを示します。マルチモーダル密度推定を使用して、固有の相関に厳密に基づくマルチモーダル表現学習のノイズ推定ビルディングブロックを提案します。異なるモダリティ間..コード：https：//github.com/elad-amrani/ssml。 
[要約]マルチモーダルデータの注釈付けは困難で費用がかかりますが、マルチモーダルモデルは高レベルのノイズの存在を無視することを選択することがよくあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-06">
        <br><font color="black">2020-03-06</font>
      </time>
    </span>
</section>
<!-- paper0: Tensor Composition Net for Visual Relationship Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_37.html">
      <font color="black">Tensor Composition Net for Visual Relationship Prediction</font>
    </a>
  </h2>
  <font color="black">私たちの方法の有効性を示すために、最初にモデルをVRPのマルチラベル分類の選択肢と経験的に比較し、モデルが最先端のMLIC方法よりも優れていることを示します。最後にTCNの画像レベルの視覚的関係を示します。予測は、関係ベースの画像検索のためのシンプルで効率的なメカニズムを提供します。次に、テンソル（分解）合成レイヤーのおかげで、モデルがトレーニングデータセットでは見られなかった視覚的関係を予測できることを示します。 
[概要]タグの重要なアイデアは、視覚的関係ラベルの低ランクのプロパティを活用することです。次に、トレーニングデータセットでは見られなかった視覚的関係をモデルが予測できることを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Developing Motion Code Embedding for Action Recognition in Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_38.html">
      <font color="black">Developing Motion Code Embedding for Action Recognition in Videos</font>
    </a>
  </h2>
  <font color="black">得られたモデルは、EPIC-KITCHENSデータセットからの自己中心性ビデオの動詞分類タスクのベースラインモデルよりも高い精度を達成しました。視覚的特徴と意味的特徴を組み合わせてモーション分類で見つかった特徴を識別するディープニューラルネットワークモデルを開発およびトレーニングしました。ビデオをモーションコードで埋め込んだり、注釈を付けたりします。この作業では、モーションコードと呼ばれるモーション埋め込み戦略を提案します。これは、操作の顕著な機械的属性に基づいたモーションのベクトル化された表現です。 
[概要]これらの動画は、モーション分類と呼ばれる機能の階層を使用して開発されました。これらの指標は、堅牢なモーション表現を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Learning event representations for temporal segmentation of image
  sequences by dynamic graph embedding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_39.html">
      <font color="black">Learning event representations for temporal segmentation of image
  sequences by dynamic graph embedding</font>
    </a>
  </h2>
  <font color="black">DGEの主な目新しさは、グラフとそのグラフ埋め込みを共同で学習することです。最先端の自己監視アプローチに対するDGEの主な利点は、トレーニングセットを必要とせず、代わりに、から繰り返し学習することです。データ自体は、時間的および意味的類似性を反映する低次元の埋め込みです。一定の時間間隔でキャプチャされた実際の画像シーケンスの2つのベンチマークデータセットでの実験結果は、提案されたDGEが時間的セグメンテーションに効果的なイベント表現につながることを示しています。 
[概要]提案されたアートワークは、2つのステップを繰り返すことによって機能します：意味的および時間的類似性の両方をエンコードするパターンから学習します。メイン、dgeは、視覚的表現に効果的であると考えられていますが、高価な手動注釈は必要ありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-08">
        <br><font color="black">2019-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: One for More: Selecting Generalizable Samples for Generalizable ReID
  Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_40.html">
      <font color="black">One for More: Selecting Generalizable Samples for Generalizable ReID
  Model</font>
    </a>
  </h2>
  <font color="black">実験結果は、私たちの方法がReIDモデルのトレーニングを効果的に改善し、ReIDモデルのパフォーマンスを向上させることができることを示しています。したがって、この論文では、どのサンプルが一般化可能であるかを単純に推測するのではなく、直接取る1対1のトレーニング目標を提案します。損失関数として選択されたサンプルの一般化能力と、一般化可能なサンプルを自動的に選択するサンプラーを学習します。これにより、必然的に、モデルが支配的な位置のデータ（たとえば、不均衡なクラスのヘッドデータ、簡単なサンプル、またはノイズの多いサンプル）にオーバーフィットします。 ）。 
[ABSTRACT]より多くのベースのサンプラーのために提案されたreidは、reidトレーニングフレームワークにシームレスに統合できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: AutoSelect: Automatic and Dynamic Detection Selection for 3D
  Multi-Object Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_41.html">
      <font color="black">AutoSelect: Automatic and Dynamic Detection Selection for 3D
  Multi-Object Tracking</font>
    </a>
  </h2>
  <font color="black">また、以前の作業では、データシーケンスごとに単一のしきい値を使用することがよくあります。これは、特定のフレームまたは特定のオブジェクトに対して最適ではありません。また、このしきい値は、ターゲットオブジェクトのカテゴリなどの多くの要因に敏感であるため、しきい値を再検索する必要があります。これらの要因が変化した場合..KITTIとnuScenesでの実験を通じて、私たちの方法は、リコールを維持しながら$ 45.7 \％$の誤検出を除外し、新しいSOTA 
[ABSTRACT]の最近の作業を検出パイプラインによって実行します。このプロセスを容易にするために、高品質の検出を自動的に選択することを提案します。代わりに、フレームごとまたはオブジェクトごとにしきい値を動的に検索して、パフォーマンスをさらに向上させます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Tubule-Sensitive CNNs for Pulmonary Airway and Artery-Vein
  Segmentation in CT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_42.html">
      <font color="black">Learning Tubule-Sensitive CNNs for Pulmonary Airway and Artery-Vein
  Segmentation in CT</font>
    </a>
  </h2>
  <font color="black">広範な実験により、これらのコンポーネントによって大幅なパフォーマンスの向上が実証されました。肺コンテキストマップと距離変換マップの前の解剖学的構造は、動脈と静脈の分化能力を向上させるように設計および組み込まれています。肺気道、動脈のセグメンテーションのための回旋神経ネットワーク（CNN）のトレーニング管状のターゲットと背景の間の深刻なクラスの不均衡によって引き起こされるまばらな監視信号のために、静脈は挑戦的です。 
[ABSTRACT] cnns。正確な気道と動脈のための末梢法-非コントラスト構築トモグラフィーにおける静脈セグメンテーション。方法は、最初に特徴再較正モジュールを使用して、ニューラルネットワークから学習した特徴を最大限に活用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: SSD-GAN: Measuring the Realness in the Spatial and Spectral Domains -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_43.html">
      <font color="black">SSD-GAN: Measuring the Realness in the Spatial and Spectral Domains</font>
    </a>
  </h2>
  <font color="black">具体的には、周波数認識分類器を弁別器に組み込んで、空間領域とスペクトル領域の両方で入力の現実性を測定することを提案します。提案された方法は一般的であり、過剰なコストをかけずにほとんどの既存のGANフレームワークに簡単に統合できます。強化されたディスクリミネーターにより、SSD-GANのジェネレーターは、実際のデータの高周波コンテンツを学習し、正確な詳細を生成することが推奨されます。 
[概要] ssd-ganのジェネレーターは、実際のデータの高周波コンテンツを学習し、正確な詳細を生成することをお勧めします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Transformer-Based Anomaly Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_44.html">
      <font color="black">Transformer-Based Anomaly Segmentation</font>
    </a>
  </h2>
  <font color="black">具体的には、マルチスケールトランスアーキテクチャに基づくアプローチを提示し、それがパフォーマンスをさらに向上させることを示します。この論文では、異常セグメンテーションのために事前トレーニングされた機能のフルパワーを解き放つための新しい方法を調査します。ベースのメソッドは、グローバルコンテキストをより有効に活用できます。 
[概要]グローバルアテンションベースの方法がグローバルコンテキストをより有効に活用できることを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br><font color="black">2020-05-05</font>
      </time>
    </span>
</section>
<!-- paper0: Full Matching on Low Resolution for Disparity Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_45.html">
      <font color="black">Full Matching on Low Resolution for Disparity Estimation</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案された方法がより正確な視差推定結果を達成し、シーンフロー、KITTI2012およびKITTI2015データセットで最先端の方法よりも優れていることを示しています。具体的には、高解像度の予測結果を複数のグループに分解し、新しく設計されたコスト集計モジュールのすべてのステージは、ポイントのグループの結果を推定するためだけに学習します。これにより、1つのステージからの1つの低解像度4Dボリューム出力からすべての候補の類似性スコアを学習するときの機能の内部競合の問題が軽減されます。 
[概要]高解像度の予測結果を複数のグループに分解します。新しく設計されたコスト分析モジュールのすべての段階では、ポイントのグループの結果を推定することのみを学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Image Captioning with Context-Aware Auxiliary Guidance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_46.html">
      <font color="black">Image Captioning with Context-Aware Auxiliary Guidance</font>
    </a>
  </h2>
  <font color="black">キャプションモデルでは、CAAGはグローバル予測の有用な情報に選択的に集中して現在の世代を再現するセマンティックアテンションを実行します。このような方法では、将来の予測情報を効果的に利用して完全なセマンティクスを学習することはできません。キャプションモデルをガイドしてグローバルコンテキストを認識することができるコンテキスト認識補助ガイダンス（CAAG）メカニズム。 
[要約]キャプションの概念は、現在の予測に対する単語の欠如に基づいています。この方法は、方法の適応性を検証することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Detection of Covid-19 Patients with Convolutional Neural Network Based
  Features on Multi-class X-ray Chest Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_47.html">
      <font color="black">Detection of Covid-19 Patients with Convolutional Neural Network Based
  Features on Multi-class X-ray Chest Images</font>
    </a>
  </h2>
  <font color="black">これらの中で最も重要なのは、Covid-19を入手した人を正しく特定することです。Covid-19は、世界保健機関（WHO）によってパンデミックとして発表された非常に深刻な致命的な病気です。逆転写ポリメラーゼ連鎖反応（RT-PCR）テストが文献で行われ始めています。 
[要約] covid-19のパンデミックにより、国はできるだけ早く深刻な健康と経済の問題に直面します。これは世界で最悪のシナリオであり、深刻な健康問題に直面しているパンデミックに関連しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Conditional Pre-training for Transfer Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_48.html">
      <font color="black">Efficient Conditional Pre-training for Transfer Learning</font>
    </a>
  </h2>
  <font color="black">教師なし設定と教師なし設定の両方でImageNetを事前トレーニングし、ターゲットデータセットとタスクの多様なコレクションを微調整することで、手法を検証します。さらに、事前トレーニングステップで画像の解像度を下げると、大きなトレードオフが生じることがわかります。コストとパフォーマンスの間..以前の作業とは異なり、パフォーマンスに加えて、効率、適応性、柔軟性に重点を置いています。 
[概要]有用性の低いサンプルを削除するための効率的なターゲットデータセットを提案します。画像の解像度を下げると、コストとパフォーマンスのトレードオフが大きくなることがわかります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-20">
        <br><font color="black">2020-11-20</font>
      </time>
    </span>
</section>
<!-- paper0: A Free Lunch for Unsupervised Domain Adaptive Object Detection without
  Source Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_49.html">
      <font color="black">A Free Lunch for Unsupervised Domain Adaptive Object Detection without
  Source Data</font>
    </a>
  </h2>
  <font color="black">一般に、簡単な方法は、ソースドメインから事前にトレーニングされたネットワークを活用して、ターゲットドメインの最適化のための疑似ラベルを生成することです。監視されていないドメイン適応（UDA）は、ソースドメインとターゲットドメインのデータが自由に利用可能であり、通常は一緒にトレーニングされて削減されることを前提としています。ドメインギャップ..徹底的な実験分析の結果、生成されたノイズの多いラベルでは偽陰性が優勢であることがわかりました。 
[概要]初めて、ソースデータを提案します-フリードメイン適応オブジェクト検出（sfod）フレームワーク。基本的に、疑似ラベルの品質を評価することは困難です。フォールスネガティブマイニングを使用すると、パフォーマンスの向上に役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Synthesizing Long-Term 3D Human Motion and Interaction in 3D Scenes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_50.html">
      <font color="black">Synthesizing Long-Term 3D Human Motion and Interaction in 3D Scenes</font>
    </a>
  </h2>
  <font color="black">3Dシーン構造上で長期的な3D人間の動きの条件付けを合成するための階層的生成フレームワークを提示します。この論文では、人間の動きの合成とシーンの余裕の推論を橋渡しすることを提案します。このフレームワークに基づいて、複数のジオメトリ制約をさらに適用します。現実的な合成を改善するための最適化による人間のメッシュとシーンポイントクラウドの間。 
[概要]この論文では、人間の動きの合成とシーンアフォーダンスの推論を橋渡しすることを提案します。また、現実的な合成を改善するために、人間の動きにおける複数の役割の役割の役割を強制します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: HRCenterNet: An Anchorless Approach to Chinese Character Segmentation in
  Historical Documents -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_51.html">
      <font color="black">HRCenterNet: An Anchorless Approach to Chinese Character Segmentation in
  Historical Documents</font>
    </a>
  </h2>
  <font color="black">この調査では、アンカーレスオブジェクト検出方法と並列化アーキテクチャを組み合わせたHRCenterNetという名前のモデルを提案します。ソースコードはhttps://github.com/Tverous/HRCenterNetで入手できます。したがって、この調査では、歴史的な中国の文書の文字セグメンテーションにのみ焦点を当てます。 
[概要]中国の歴史的文書の迅速なデジタル化は、最も迅速で効果的な保存手段の1つです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: COVID-MTL: Multitask Learning with Shift3D and Random-weighted Loss for
  Diagnosis and Severity Assessment of COVID-19 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_52.html">
      <font color="black">COVID-MTL: Multitask Learning with Shift3D and Random-weighted Loss for
  Diagnosis and Severity Assessment of COVID-19</font>
    </a>
  </h2>
  <font color="black">次に、ランダム加重マルチタスク損失関数が提案され、さまざまなCOVID-19タスクの同時学習がより安定して正確になりました。さらに、COVIDの陽性と重症度に有意に関連する（P &lt;0.001）上位のイメージングバイオマーカーを特定しました。 -19 .. CTデータのみを使用し、肺画像の特徴を抽出することにより、COVID-MTLは930のCTスキャンでトレーニングされ、別の399のケースでテストされ、AUCは0.939と0.846、精度は90.23％と79.20％でした。それぞれ放射線学とNATに対するCOVID-19であり、最先端のモデルを上回っています。 
[概要] covid-19ctスキャンとshift3dリアルタイム3d拡張アルゴリズムで肺のセグメンテーション結果を改善するためのアクティブな輪郭ベースの方法を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Curriculum Labeling: Revisiting Pseudo-Labeling for Semi-Supervised
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_53.html">
      <font color="black">Curriculum Labeling: Revisiting Pseudo-Labeling for Semi-Supervised
  Learning</font>
    </a>
  </h2>
  <font color="black">現在の方法では、このアプローチを放棄して、ラベルのないサンプルでのさまざまなスタイルの自己教師あり損失とラベルの付いたサンプルでの標準の教師あり損失の組み合わせの下でモデルをトレーニングする整合性正則化方法を採用しているようです。学習アルゴリズムがラベル付きサンプルの小さなセットとラベルなしサンプルの大きなセットにアクセスできる半教師あり学習のコンテキストでの疑似ラベリング..疑似ラベリングがそのような顕著な結果を達成できるようにする2つの重要な要因を特定します（1 ）カリキュラム学習の原則を適用し、（2）各自己トレーニングサイクルの前にモデルパラメータを再開することにより、概念のドリフトを回避します。 
[ABSTRACT]疑似ラベル付けは、ラベル付けされたサンプルと以前に疑似ラベル付けされたサンプルの組み合わせでトレーニングされたモデルを使用して機能します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-16">
        <br><font color="black">2020-01-16</font>
      </time>
    </span>
</section>
<!-- paper0: Can we detect harmony in artistic compositions? A machine learning
  approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_54.html">
      <font color="black">Can we detect harmony in artistic compositions? A machine learning
  approach</font>
    </a>
  </h2>
  <font color="black">最高性能モデル（SVM）は、調和画像と不調和画像を区別する際に80％の精度を達成しました。これは、調和の概念が人間が評価できる数学的な方法で表現できるという仮定を強化します。そうすることで、主観的に判断された構図に客観的な尺度を割り当てます。画像を表すために、一連の特別な特徴が設計され、抽出されました。 
[概要]研究の目的は、芸術的構成の数値表現を見つけることでした。機械学習アルゴリズムを使用して、そのような表現の効率を評価しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Probabilistic Tracklet Scoring and Inpainting for Multiple Object
  Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_55.html">
      <font color="black">Probabilistic Tracklet Scoring and Inpainting for Multiple Object
  Tracking</font>
    </a>
  </h2>
  <font color="black">私たちの実験は、挑戦的なシーケンスでオブジェクトを追跡するという私たちのアプローチの優位性を示しています。これは、MOT16、MOT17、MOT20などの複数のMOTベンチマークデータセットのほとんどの標準MOTメトリックで最先端を上回っています。そのため、このモデルでは、既存のトラックレットに新しい検出を割り当てるだけでなく、トラックレットを修復することもできます。誤検出によって生じたギャップを埋めるためにトラックレットをサンプリングすることによって、たとえばオクルージョンのためにオブジェクトが長期間失われた場合。複数オブジェクト追跡（MOT）の最近の進歩にもかかわらず、共同検出と追跡によって達成されました。長い咬合に対処することは依然として課題です。 
[概要]これは、このような手法では長期的なモーション情報が無視される傾向があるためです。これは、モデルをトレーニングして、自然なトラックレットの基本的な分布を学習することで実現されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
<!-- paper0: Exploiting Diverse Characteristics and Adversarial Ambivalence for
  Domain Adaptive Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_56.html">
      <font color="black">Exploiting Diverse Characteristics and Adversarial Ambivalence for
  Domain Adaptive Segmentation</font>
    </a>
  </h2>
  <font color="black">新しいセルフトレーニングスキームは、簡単な適応領域と難しい適応領域の敵対的なアンビバレンスと、ターゲットサブドメイン間の相関関係を効果的に活用します。ターゲット画像が気象条件によって異なるさまざまな適応シナリオで、メソッド（DCAA）を評価します。APAT戦略は、条件固有の調整と注意深いグローバル機能マッチングを段階的に実行します。 
[概要]新しいターゲットドメインは、複数のサブドメイン（たとえば、多様な気象特性）で構成されます。新しいセルフトレーニングスキームは、簡単な適応領域と難しい適応領域の敵対的なアンビエンスを使用します。ベースラインとの比較および最先端のアプローチ競合他社に対するdcaaの優位性を実証する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Deep learning methods for SAR image despeckling: trends and perspectives -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_57.html">
      <font color="black">Deep learning methods for SAR image despeckling: trends and perspectives</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、教師ありアプローチと最近の自己教師ありアプローチの両方をカバーする、SARスペックル除去に適用される深層学習手法に関する文献を調査します。合成開口レーダー（SAR）画像は、スペックルと呼ばれる空間相関および信号依存ノイズの影響を受けます。これは非常に深刻で、画像の活用を妨げる可能性があります。スペックル除去は、すべてのダウンストリーム画像処理タスクの精度を向上させるために、このようなノイズを除去することを目的とした重要なタスクです。 
[ABSTRACT]スペックル除去は、このようなノイズを除去して、すべてのダウンストリーム画像処理タスクの精度を向上させることを目的とした重要なタスクです。深層学習モデルは、画像処理の逆問題に対して優れたパフォーマンスをもたらしました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Spatiotemporal Graph Neural Network based Mask Reconstruction for Video
  Object Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_58.html">
      <font color="black">Spatiotemporal Graph Neural Network based Mask Reconstruction for Video
  Object Segmentation</font>
    </a>
  </h2>
  <font color="black">この論文は、半教師あり設定でクラスにとらわれないオブジェクトをセグメント化するタスクに対処します。この論文では、ローカルコンテキストをキャプチャするビデオオブジェクトセグメンテーションのより正確なマスクを再構築するための新しい時空間グラフニューラルネットワーク（STG-Net）を提案します。すべての提案を利用することによって..ローカルパッチの詳細と時間的関係の両方を併用することで、オブジェクトのオクルージョンや欠落などの課題により適切に対処できます。 
[ABSTRACT]空間グラフでは、フレームのオブジェクト提案をノードとして扱います。これらは、マスクコンテキストのエッジウェイト戦略との相関関係を表します。ローカルパッチの詳細と相互関係を併用することで、課題により適切に対処できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Demystifying Pseudo-LiDAR for Monocular 3D Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_59.html">
      <font color="black">Demystifying Pseudo-LiDAR for Monocular 3D Object Detection</font>
    </a>
  </h2>
  <font color="black">2番目の貢献により、3D信頼性予測モジュールの導入により、疑似LiDARベースの方法がランキングに戻ります。驚くべきことに、重なりを地理的に取り除いた後もバイアスが残り、より構造化された汚染の存在が明らかになります。バイアスの重なりは、KITTI3Dオブジェクト検出検証セットと、疑似LiDARベースの方法を供給する深度予測子のトレーニングに使用されるトレーニング/検証セットとの間の重なりにあります。 
[概要]私たちの修正された疑似-LIDARベースの方法は、テストスコアで並外れた向上を示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: E3D: Event-Based 3D Shape Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_60.html">
      <font color="black">E3D: Event-Based 3D Shape Reconstruction</font>
    </a>
  </h2>
  <font color="black">移動イベントカメラからの出力は、時空間勾配のスパースポイントセットであり、主にシーン/オブジェクトのエッジと輪郭をスケッチします。最後に、3Dからイベントへのシミュレーションパイプラインを導入し、公開されているオブジェクトデータセットに適用して生成します。監視学習用の合成イベント/シルエットトレーニングペア..最初に、イベントフレームのスタックを対応するシルエットに変換するイベントツーシルエット（E2S）ニューラルネットワークモジュールを導入し、カメラポーズ回帰用の追加のニューラルブランチを追加します。 
[概要]現在の3Dモデルは、rgb、rgb --d、LIDARセンサーに基づいています。これらには、イベントフレームのスタックを対応するシルエットに変換する3dおよびe2sニューラルネットワークモジュールが含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-09">
        <br><font color="black">2020-12-09</font>
      </time>
    </span>
</section>
<!-- paper0: Probabilistic Jacobian-based Saliency Maps Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_61.html">
      <font color="black">Probabilistic Jacobian-based Saliency Maps Attacks</font>
    </a>
  </h2>
  <font color="black">したがって、私たちの新しい攻撃は、前述のようなデータセットに対する$ L_0 $のリアルタイムの敵対的テストに対して、JSMAとCWの間で適切なトレードオフを提供します。コードはリンクhttps://github.com/probabilistic-から公開されています。 jsmas / probabilistic-jsmas ..このペーパーでは、出力確率とNNCの入力機能によって、JSMAの顕著性マップにペナルティを課すことで、各入力の特性をより適切に考慮した、より強力な攻撃アルゴリズムを取得できることを示します。 
[ABSTRACT]効果的で高速な$ l --z（wjsma）攻撃は、時間を欺くだけでなく、堅牢性も向上させるのに実用的です。これにより、nncbaおよびtaylor jsma（ts）の入力の改善が導入されます。これらのデータセットは大幅に高速であり、 jsmaの元のターゲットバージョンと非ターゲットバージョンよりも効率的</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-12">
        <br><font color="black">2020-07-12</font>
      </time>
    </span>
</section>
<!-- paper0: Effect of the regularization hyperparameter on deep learning-based
  segmentation in LGE-MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_62.html">
      <font color="black">Effect of the regularization hyperparameter on deep learning-based
  segmentation in LGE-MRI</font>
    </a>
  </h2>
  <font color="black">また、作成者は、他の深層学習ハイパーパラメータの手動調整または調整を採用して、90％の検証精度を達成する前にすべてのエポックの10％に達した場合にのみ実行します。この予備評価では、作成者はどの程度かを示します。 L2正則化ハイパーパラメータの任意の選択は、LGE-MRIでの深層学習ベースのセグメンテーションの結果に影響を与える可能性があります。実験で使用された任意のL2正則化値を使用すると、結果は、L2正則化数が小さいほどセグメンテーションが向上することを示しました。心筋のおよび/またはより高い精度。 
[概要]著者はまた、すべてのエポックの10％に達した場合にのみ手動パラメーターを実行できることを採用しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Investigating Bias in Image Classification using Model Explanations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_63.html">
      <font color="black">Investigating Bias in Image Classification using Model Explanations</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、説明を使用してバイアスを検出するための長所とベストプラクティス、および3つの主な短所を特定します。説明はバイアスの程度を適切に推定せず、分析に追加のバイアスを導入する可能性があり、人的労力の点で非効率的な場合があります。モデルの説明が、識別機能を強調表示することで画像分類のバイアスを効率的に検出できるかどうかを評価し、それによって公平性計算の機密属性への依存を排除しました。この目的のために、バイアス検出の重要な特性を定式化し、バイアスの程度として説明がどのように変化するかを観察しました。モデルが変わります。 
[概要]バイアスを検出すると、原因が間違っていることを見つける方法を見つけます。この目的のために、モデルのバイアスの結果として説明がどのように変化するかを観察しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Direct Depth Learning Network for Stereo Matching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_64.html">
      <font color="black">Direct Depth Learning Network for Stereo Matching</font>
    </a>
  </h2>
  <font color="black">結果は、従来の方法と比較して、DDL-NetがSceneFlowデータセットで平均25％、DrivingStereoデータセットで$ 12 \％$の改善を達成することを示しています。DDL-Netは、粗深度推定段階と適応グレイン段階の2つの段階で構成されます。 Depth Refinementステージは、すべて視差ではなく深度によって監視されます。Adaptive-GrainedDepthRefinementステージは、粗い深度の近くでさらにマッチングを実行して、不正確なマッチングと誤ったマッチングを修正します。 
[概要]新しい直接深度学習ネットワーク（ddl-net）はステレオマッチング用に設計されています。深度の代わりに、新しい視差推定は視差です。これらの段階で視差と深度範囲が決定されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Image Matching with Scale Adjustment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_65.html">
      <font color="black">Image Matching with Scale Adjustment</font>
    </a>
  </h2>
  <font color="black">したがって、低解像度の画像が高解像度の画像のすべてのスケール空間表現と比較されるため、1対1の古典的な画像マッチングパラダイムは1対多になります。興味のあるポイントを表現および抽出する方法を可変スケールであり、2つの異なる解像度で2つの画像を比較できる方法を考案します。このようなプロセスを成功させる鍵は、スケール空間で一致する特徴を適切に表現することです。 
[概要] 2つの画像間の解像度の正しい表現は不明です。使用を失うことなく、画像の1つは高解像度のものと見なされます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Developing High Quality Training Samples for Deep Learning Based Local
  Climate Zone Classification in Korea -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_66.html">
      <font color="black">Developing High Quality Training Samples for Deep Learning Based Local
  Climate Zone Classification in Korea</font>
    </a>
  </h2>
  <font color="black">代わりに、この研究では、マルチスケール畳み込みニューラルネットワークを使用して韓国の主要都市をマッピングするカスタムLCZデータを開発しました。国連の予測によると、3人に2人が2050年までに都市部に住むことになり、持続可能な必要性が強調されます。都市開発とモニタリング..結果は、深層学習で新しいカスタムLCZデータを使用すると、機械学習やグローバルSo2Satデータセットの転送学習を使用した従来のコミュニティベースのLCZマッピングと比較して、より正確なLCZマップ結果を生成できることを示しました。 
[ABSTRACT]都市フットプリントデータは、高解像度の都市フレームワークを提供しますが、分布、パターン、および特性に関する重要な情報が不足しています。都市ゾーンマップは調査されていますが、精度の低さ、ラベルの品質の変動、またはドメイン適応の課題によって制限されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Flexible Few-Shot Learning with Contextual Similarity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_67.html">
      <font color="black">Flexible Few-Shot Learning with Contextual Similarity</font>
    </a>
  </h2>
  <font color="black">この柔軟な数ショットのシナリオの新しいベンチマークデータセットを定義します。タスクは、顔（Celeb-A）、靴（Zappos50K）、および一般的なオブジェクト（ImageNet-with-Attributes）の画像に基づいています。同じものからの2つの例クラスには、どのエピソードでも常に同じラベルが割り当てられます。分類ベースラインとエピソードアプローチは、標準的な数ショットの学習に適した表現を学習しますが、テスト中に新しい類似性の定義が発生するため、柔軟なタスクに苦しみます。 
[概要]既存の例は、学習者に与えられていないタスクのコンテキストに応じてエピソードごとに変わる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: OneNet: Towards End-to-End One-Stage Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_68.html">
      <font color="black">OneNet: Towards End-to-End One-Stage Object Detection</font>
    </a>
  </h2>
  <font color="black">エンドツーエンドの1ステージオブジェクト検出器を設計するために、最小コストの割り当てを提案します。コードは次の場所で入手できます。\ url {https://github.com/PeizeSun/OneNet} ..コストはの合計です。サンプルとグラウンドトゥルース間の分類コストとロケーションコスト。 
[要約]各オブジェクトグラウンド-真実、最小コストの1つのサンプルのみが正のサンプルとして割り当てられ、その他はすべて負のサンプルとして割り当てられます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: iNeRF: Inverting Neural Radiance Fields for Pose Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_69.html">
      <font color="black">iNeRF: Inverting Neural Radiance Fields for Pose Estimation</font>
    </a>
  </h2>
  <font color="black">私たちの実験では、最初に1）iNeRFのポーズ調整中に光線をサンプリングして有益な勾配を収集する方法と2）光線のさまざまなバッチサイズが合成データセットのiNeRFにどのように影響するかを研究します。最初のポーズ推定から始めて、勾配降下法を使用します。すでにトレーニングされたNeRFからレンダリングされたピクセルと、観測された画像のピクセルとの間の残差を最小限に抑えるために..トレーニングされたニューラルラディアンスフィールド（NeRF）を「反転」することによってポーズ推定を実行するフレームワークであるiNeRFを紹介します。 
[ABSTRACT] nerfsは、ビュー合成のタスクに非常に効果的であることが示されています。inerfは、新しい画像のカメラポーズを推定し、これらの画像をnerfの追加トレーニングデータとして使用することで、nerfを改善できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Auto-MVCNN: Neural Architecture Search for Multi-view 3D Shape
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_70.html">
      <font color="black">Auto-MVCNN: Neural Architecture Search for Multi-view 3D Shape
  Recognition</font>
    </a>
  </h2>
  <font color="black">3D形状認識では、マルチビューベースの方法が人間の視点を活用して3D形状を分析し、重要な結果を達成しました。ただし、これらのネットワークアーキテクチャが3D分析に適しているかどうかは不明です。Auto-MVCNNは勾配ベースのフレームワークを融合セルを自動的に検索してビュー機能間の固有の相関関係を調査することにより、マルチビュー画像を処理します。 
[概要]この論文では、auto-mvcnnと呼ばれるニューラルアーキテクチャ検索方法を提案します。これは、マルチビュー3D形状認識でアーキテクチャを最適化するために特別に設計されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Are Fewer Labels Possible for Few-shot Learning? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_71.html">
      <font color="black">Are Fewer Labels Possible for Few-shot Learning?</font>
    </a>
  </h2>
  <font color="black">バニラの教師なし事前トレーニング（クラスタリングが不十分）が監視対象よりも悪い理由を説明します。データとラベルが非常に限られているため、ショット学習が困難です。たとえば、各ターゲットカテゴリにラベル付きサンプルが10個しかない場合、平均上記の2つのベースラインでの精度の向上は、それぞれ9.2％と3.42です。 
[概要]大規模な転送に関する最近の研究では、異なるドメインの大規模なラベル付きデータセットで事前トレーニングを行うことで、ショット学習に大きなメリットが得られることが示されています。固有の微調整を提案します。事前トレーニングの実施</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: DI-Fusion: Online Implicit 3D Reconstruction with Deep Priors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_72.html">
      <font color="black">DI-Fusion: Online Implicit 3D Reconstruction with Deep Priors</font>
    </a>
  </h2>
  <font color="black">私たちのPLIVoxは、ディープニューラルネットワークによってパラメータ化されたローカルジオメトリと不確実性の両方を考慮してシーンの事前分布をエンコードします。このような深い事前分布を使用して、最先端のマッピング品質を実現するオンラインの暗黙的な3D再構成を実行できることを広範な実験で示します。以前のオンライン3D再構成アプローチと比較してはるかに少ないストレージを使用しながら、カメラ軌道推定精度。以前のオンライン3D高密度再構成方法は、主にTSDFなどの停滞した基礎となるジオメトリ表現の使用により、不十分な表面品質を達成しながら、大容量のメモリストレージを必要とすることがよくあります。 （切り捨てられた符号付き距離関数）またはサーフェル、シーンの事前確率の知識なし。 
[ABSTRACT] di --fusionは、コモディティrgb --d camera.priorsを使用したオンライン3D再構成の新しい3D表現に基づいています。以前のオンライン再構成アプローチと比較して、はるかに少ないストレージでオンライン暗黙的3D再構成を実行できることを示しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: MeshWalker: Deep Mesh Understanding by Random Walks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_73.html">
      <font color="black">MeshWalker: Deep Mesh Understanding by Random Walks</font>
    </a>
  </h2>
  <font color="black">さらに、非常に少数の例でも学習に十分です。重要なアイデアは、メッシュのジオメトリとトポロジを「探索」する、サーフェスに沿ったランダムウォークによってメッシュを表すことです。各ウォークは頂点のリストとして編成されます。これは、何らかの方法でメッシュに規則性を課します。 
[概要]この論文では、コンピュータグラフィックスで最も一般的な3D形状の表現を見ていきます。これは、メッシュウォーカーと呼ばれる、特定のメッシュから直接形状を学習するための非常に異なるアプローチを示唆しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-09">
        <br><font color="black">2020-06-09</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Generation of Interpretable Lung Cancer Scoring Models from
  Chest X-Ray Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_74.html">
      <font color="black">Automatic Generation of Interpretable Lung Cancer Scoring Models from
  Chest X-Ray Images</font>
    </a>
  </h2>
  <font color="black">さらに、このプロセスによって作成された決定木は、医療専門家が臨床的に使用可能な多変量肺がんのスコアリングおよび診断モデルに改良するための開始点と見なすことができます。小さな推論データセットの場合、この方法は84％を超える最高の精度を達成します。悪性クラスの陽性予測値は83％です。肺がんは世界中のがんによる死亡と罹患の主な原因であり、早期発見が患者の陽性予後の鍵となります。 
[要約]研究によると、機械学習技術は肺がんを自動的に診断するのに効果的ですが、これらの技術はまだ医学界によって承認および承認されていません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: An Asynchronous Kalman Filter for Hybrid Event Cameras -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CV/paper_75.html">
      <font color="black">An Asynchronous Kalman Filter for Hybrid Event Cameras</font>
    </a>
  </h2>
  <font color="black">低ダイナミックレンジ画像をイベントデータと融合することにより、高ダイナミックレンジ（HDR）ビデオを再構築する非同期カルマンフィルター（AKF）を紹介します。イベントカメラは、ぼやけることなくHDR視覚情報をキャプチャするのに最適ですが、静的またはゆっくりと変化する場合はパフォーマンスが低下します。シーン..私たちのビデオ再構成は、既存のデータセットとターゲットのHDRデータセットの最先端のアルゴリズムよりも優れています。 
[ABSTRACT]イベントカメラは、ブラーなしでhdr視覚情報をキャプチャするのに理想的な強度ですが、静的またはゆっくりと変化するシーンではパフォーマンスが低下します。提案されたアプローチは、従来のフレームとイベントの両方の統一不確実性モデルの下でハイブリッドセンサーの利点を活用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Causal-BERT : Language models for causality detection between events
  expressed in text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_0.html">
      <font color="black">Causal-BERT : Language models for causality detection between events
  expressed in text</font>
    </a>
  </h2>
  <font color="black">また、この問題にはよく知られているデータセットが存在しますが、それらの例は、特に暗黙の関係に関連する場合に、それらが表す因果関係の範囲と複雑さに制限されています。このペーパーでは、言語モデルの因果関係の機能を調査します。イベント情報と組み合わせた文コンテキストを使用し、ドメイン内およびドメイン外のデータ分散でマスクされたイベントコンテキストを活用することにより、自然言語テキストで表現されたイベント間の関連付け。イベント間の因果関係の理解は、役立つ重要な自然言語処理タスクです。ヘルスケア、ビジネスリスク管理、財務など、多くの分野で。 
[概要]膨大な量の文学コンテンツがコミュニケーションと探索に専念しています。これらには、正式なドキュメント、ツイッター、ツイッター、ツイッターが含まれます。ただし、これらの多くはあいまいまたはあいまいであることが知られています。現代の方法のほとんどは、 lexico-セマンティックパターンマッチングまたは機能駆動型の監視対象メソッド</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Rewriter-Evaluator Framework for Neural Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_1.html">
      <font color="black">Rewriter-Evaluator Framework for Neural Machine Translation</font>
    </a>
  </h2>
  <font color="black">中国語-英語と英語-ドイツ語の2つの翻訳タスクで広範な実験を行い、提案されたフレームワークがNMTモデルのパフォーマンスを大幅に改善し、以前のベースラインを大幅に上回っていることを示します。すべてのパスで、リライターは新しい翻訳を作成して、過去の翻訳と評価者は、書き直しプロセスを終了するかどうかを決定するために翻訳品質を推定します。ただし、適切な終了ポリシーがないため、その潜在能力は十分に制限されています。 
[概要]デコードの複数のパスでリライターを改善するためにいくつかの方法が提案されています。これらには新しいフレームワークが含まれ、リライター-evaluator.rewriterとエバリュエーターも存在します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Longitudinal Citation Prediction using Temporal Graph Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_2.html">
      <font color="black">Longitudinal Citation Prediction using Temporal Graph Neural Networks</font>
    </a>
  </h2>
  <font color="black">私たちの実験は、時間的情報と位相的情報の両方を活用することで、時間の経過に伴う引用数の予測のパフォーマンスが大幅に向上することを示しています。導入されたタスクにアプローチするために、42年以上にわたるSemanticScholarから動的引用ネットワークを導出します。引用の構造化されたネットワークとして、トポロジー情報を学習信号として使用できるようにします。 
[要約]これまでの研究では、これを静的予測タスクと見なしていました。ここでは、シーケンス引用予測のタスクを紹介します。目標は、文学作品が時間の経過とともに受け取る引用数の軌跡を正確に予測することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: A Framework for Generating Annotated Social Media Corpora with
  Demographics, Stance, Civility, and Topicality -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_3.html">
      <font color="black">A Framework for Generating Annotated Social Media Corpora with
  Demographics, Stance, Civility, and Topicality</font>
    </a>
  </h2>
  <font color="black">さらに、大規模なデータセットを分析する場合、データの小さなサンプルに注釈を付け、このサンプルを使用して予測モデルをトレーニングして、関連するカテゴリの完全なデータに注釈を付けることができます。Facebookコメントの3つのデータセットをリリースし、次の場所でさらに調査します。 https://github.com/socialmediaie/StudentDebtFbComments。性別、軍隊、年齢層、政治的傾向、人種、スタンス、話題性、新自由主義的見解、コメントの礼儀正しさについて注釈が付けられた学生ローンの議論に関するFacebookコメントコーパスのケーススタディを使用します。 
[概要] Facebookのコメントコーパスには、性別、軍隊、年齢-グループ、政治的傾向、人種、話題性、新自由主義的見解、コメントの礼儀正しさについて注釈が付けられました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Standardization of Colloquial Persian -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_4.html">
      <font color="black">Automatic Standardization of Colloquial Persian</font>
    </a>
  </h2>
  <font color="black">さらに、さまざまなドメインのセットからの1912文で構成される公開されている評価データに注釈を付けます。私たちの本質的な評価は、オリジナルの既製のルールベースの標準化モデルと比較して、62.8に対して62.8の高いBLEUスコアを示しています。テキストのBLEUスコアは46.4です。また、トレーニングデータが口語的なペルシャからのものであり、開発データで絶対BLEUスコアの差が1.4、テストで0.8であるシナリオで、モデルが英語からペルシャへのマシン変換を改善することも示しています。データ。 
[概要]ペルシア語のほとんどの自然言語処理ツールは、テキストが標準形式であることを前提としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Direct multimodal few-shot learning of speech and images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_5.html">
      <font color="black">Direct multimodal few-shot learning of speech and images</font>
    </a>
  </h2>
  <font color="black">以前の作業では、学習した単峰性表現に依存する2段階の間接アプローチを使用しました。音声-音声と画像-画像の比較は、指定された音声-画像ペアのサポートセット全体で実行されます。改善は教師なしとの組み合わせによるものであることを示します。直接モデルでの伝達学習、および2段階の複合エラーの不在..代わりに、異なるモダリティからの入力が直接比較できる単一のマルチモーダル空間を学習する2つの直接モデルを提案します：マルチモーダルトリプレットネットワーク（MTriplet）とマルチモーダル対応自動エンコーダー（MCAE）。 
[概要]単一のマルチモーダル画像を学習する2つの直接モデルを提案します。これらは音声のマルチモーダルに基づいており、直接モデルを実行します。代わりに、音声を学習して間接モデルを実行します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: AI Driven Knowledge Extraction from Clinical Practice Guidelines:
  Turning Research into Practice -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_6.html">
      <font color="black">AI Driven Knowledge Extraction from Clinical Practice Guidelines:
  Turning Research into Practice</font>
    </a>
  </h2>
  <font color="black">まず、私たちのシステムは、CPGセンテンスを、センテンスに提示された情報に基づいて、条件-アクション、条件-結果、アクション、および該当なしの4つのクラスに分類します。方法：この研究は、CPGから知識を抽出するための新しい方法論を提示します。ギャップを減らし、最新の研究結果を臨床実践に変えるために。したがって、最先端のコンピューティング研究、特に機械学習を使用して、CPGから知識を抽出して削減するための人工知能ベースのソリューションを提供することが不可欠です。ヘルスケアの研究/ガイドラインと実践の間のギャップ。 
[要約]研究は、cpgsから知識を抽出するための新しい方法を提供します。すでに負担のかかっている医療専門家には実行不可能であり、調査結果と実際の実践との間に大きなギャップが生じます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Unified Streaming and Non-streaming Two-pass End-to-end Model for Speech
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_7.html">
      <font color="black">Unified Streaming and Non-streaming Two-pass End-to-end Model for Speech
  Recognition</font>
    </a>
  </h2>
  <font color="black">この効率的な再スコアリングプロセスにより、文レベルの遅延はほとんど発生しません。このモデルは、エンコーダーの配座異性体レイヤーが変更されるハイブリッドCTC /アテンションアーキテクチャを採用しています。AISHELL-1テストセットでは、統合モデルは5.60％の相対値を達成します。標準の非ストリーミングトランスフォーマーと比較した非ストリーミングASRの文字エラー率（CER）の削減。 
[概要]提案手法は、ストリーミングモデルと非ストリーミングモデルを簡単かつ効率的に統合することができます。この方法は、統合して効果的に使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Diversity Aware Relevance Learning for Argument Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_8.html">
      <font color="black">Diversity Aware Relevance Learning for Argument Search</font>
    </a>
  </h2>
  <font color="black">私たちの経験的評価は、私たちのアプローチが、必要なデータが少なくても、引数検索タスクの大幅な改善につながることを示しています。それを超えて、重複を明示的に識別しようとするのではなく、クエリの多様な側面をカバーすることを目的としています。クラスタリングを介して重複を削除することに依存していますが、選択した施設がすべての側面をカバーしていることを直接保証するものではありません。 
[ABSTRACT]新しい作業は、引数検索問題のための新しいマルチステップアプローチを導入します。それはクレームと前提の間の明示的なマッピングに依存することを含みます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-04">
        <br><font color="black">2020-11-04</font>
      </time>
    </span>
</section>
<!-- paper0: An Event Correlation Filtering Method for Fake News Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_9.html">
      <font color="black">An Event Correlation Filtering Method for Fake News Detection</font>
    </a>
  </h2>
  <font color="black">さらに、イベント信頼性アップデーターは、適応カルマンフィルターを使用して、イベントの信頼性変動を弱めます。偽のニュースの検出パフォーマンスを向上させるために、ニュースのイベント相関を利用して、偽のイベント相関フィルタリング方法（ECFM）を提案します。主にニュース特性、疑似ラベルアノテーター、イベント信頼性アップデーター、ニュースエントロピーセレクターで構成されるニュース検出。広範な実験により、ニュースのイベント相関の説明可能な導入が偽のニュースの検出パフォーマンスを向上させるのに有益であることが証明されています。 。 
[概要]ニュース特性担当者は、ニュースからニュースを抽出する責任があります。ニュースのイベント相関を利用して、疑似ラベルアノテーターと連携し、ラベルのないニュースに疑似ラベルを割り当てます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Recurrent Point Review Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_10.html">
      <font color="black">Recurrent Point Review Models</font>
    </a>
  </h2>
  <font color="black">同時に、私たちの方法論は、要約されたレビューコンテンツ表現を組み込むことにより、ポイントプロセスモデルの予測力を強化します。ディープニューラルネットワークモデルは、自然言語処理の最先端の方法論を表します。レビューコンテンツのモデリング。 
[概要]これらのポイントプロセスモデルに基づいて構築し、時間情報を組み込み、時間の経過に伴うデータの変化を確認する方法をモデル化します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Sense Language Modelling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_11.html">
      <font color="black">Multi-Sense Language Modelling</font>
    </a>
  </h2>
  <font color="black">マルチセンス言語モデリングには、標準言語モデルを超えるアーキテクチャが必要であることがわかりました。ここでは、タスクを単語に分解し、その後にセンス予測タスクを実行する構造化予測フレームワークを提案します。次を予測するだけでなく、言語モデルを提案します。単語だけでなく、文脈におけるその意味も..このより高い予測の粒度は、補助的な書き込みなどの最終タスクに役立つ可能性があり、言語モデルと知識ベースのより正確なリンクを可能にする可能性があると主張します。 
[要約]このより高い予測粒度は、支援的ライティングなどの最終タスクに役立つ可能性があると主張します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring Pair-Wise NMT for Indian Languages -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_12.html">
      <font color="black">Exploring Pair-Wise NMT for Indian Languages</font>
    </a>
  </h2>
  <font color="black">多言語NMTモデルは、リソースの少ない言語で妥当な量の有効性を示しています。この作業では、フィルター処理された逆翻訳プロセスによる逆翻訳とその後の微調整を使用することで、これらのモデルのパフォーマンスを大幅に向上できることを示します。限られたペアワイズ言語コーパスのチューニング..このペーパーでは、特定の低リソースのインド言語のペアワイズマシン翻訳を改善するタスクについて説明します。 
[要約]この論文の分析は、この方法が多言語モデルのパフォーマンスをそのベースラインよりも大幅に改善できることを示唆しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Segmenting Natural Language Sentences via Lexical Unit Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_13.html">
      <font color="black">Segmenting Natural Language Sentences via Lexical Unit Analysis</font>
    </a>
  </h2>
  <font color="black">LUAは、予測されたセグメンテーションが有効であることを本質的に保証し、グローバルに最適なトレーニングと推論を容易にするなど、多くの魅力的な特性を楽しんでいます。私たちのモデルは、13のモデルで最先端のパフォーマンスを達成しています。 15のデータセットにわたる、構文チャンク、名前付きエンティティ認識（NER）、スロット充填、中国語の単語セグメンテーション、中国語の音声部分（POS）タグ付けを含む5つのタスク。 
[ABSTRACT] luaは、中国語のスピーチですべての有効なセグメンテーション候補をスコアリングします。また、競争の最大スコアを提供します。さらに、luaの実際の時間計算量を線形時間に短縮できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Deep Learning Techniques for Password Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_14.html">
      <font color="black">Generative Deep Learning Techniques for Password Generation</font>
    </a>
  </h2>
  <font color="black">最後に、よく知られているデータセット（RockYou、LinkedIn、Youku、Zomato、Pwnd）に対して、統合された制御フレームワークで徹底的な実証分析を実行します。結果は、ディープニューラルネットワークによって駆動される最も有望なスキームを特定するだけでなく、生成の変動性とサンプルの一意性に関する各アプローチの長所。最先端のサンプリングパフォーマンスを示す変分オートエンコーダーの観点から、新しい生成的深層学習モデルを提供し、補間やターゲットサンプリングなどの追加の潜在空間機能を生成します。 
[概要]パスワード推測に照らしたディープラーニングと確率ベースのモデル。これらには、注意ベースのディープニューラルネットワークと自動エンコーディングネットワークが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: HIGhER : Improving instruction following with Hindsight Generation for
  Experience Replay -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_15.html">
      <font color="black">HIGhER : Improving instruction following with Hindsight Generation for
  Experience Replay</font>
    </a>
  </h2>
  <font color="black">これらの特性は、インタラクティブなエージェントの動作の指示、条件付け、または構造化を促進する可能性がありますが、シナリオに従った単純な指示でも、言語理解と強化学習を正しく関連付けることは未解決の問題です。エージェントが指示を満たさない場合は常に、HIGhERは出力を学習します。エージェントの軌跡に一致する新しいディレクティブで、エピソードにプラスの報酬を付け直します。BabyAI環境でのアプローチの効率を示し、他の指示に従う方法をどのように補完するかを示します。 
[概要]言語ベースの評価の文字列を解決できるのはこれが初めてですが、未解決のままです-言語理解を正しく関連付けるための問題です。これは、効果的な言語に対処する方法に役立つ可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-21">
        <br><font color="black">2019-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Empirical Analysis of Unlabeled Entity Problem in Named Entity
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_16.html">
      <font color="black">Empirical Analysis of Unlabeled Entity Problem in Named Entity
  Recognition</font>
    </a>
  </h2>
  <font color="black">合成データセットと実際のデータセットでの実験は、モデルがラベルのないエンティティの問題に対して堅牢であり、以前のベースラインを超えていることを示しています。2番目の原因は、トレーニングでモデルを深刻に誤解させ、そのパフォーマンスに大きな影響を与えます。コアアイデアは、ネガティブサンプリングを使用して維持することです。非常に低いレベルでラベルのないエンティティを使用してトレーニングする確率。 
[概要]パフォーマンス低下の最初の原因は、2番目の原因よりも影響が少ないです。これらの例は、ラベルのないエンティティを処理することで軽減できます。この概念は、合成データセットでの実験に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Machine Translation Doesn't Translate Gender Coreference Right
  Unless You Make It -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_17.html">
      <font color="black">Neural Machine Translation Doesn't Translate Gender Coreference Right
  Unless You Make It</font>
    </a>
  </h2>
  <font color="black">単純な既存のアプローチは、文内の複数のエンティティに性別の特徴を過度に一般化する可能性があり、タグ付き共参照適応データの形で効果的な代替案を提案する可能性があることがわかります。この問題に対する多くの既存のアプローチは、ターゲット言語での性別の変化を制御しようとします。明示的または暗黙的に、通常は文レベルで、ソース文に性別機能を追加します。また、非バイナリの屈曲などの対応する言語規則を前提として、英語からの性別中立エンティティの翻訳を評価する拡張機能を提案します。ターゲット言語。 
[概要]この問題に対する多くの既存のアプローチは、ターゲット言語で性別を制御しようとしています。英語に翻訳されたものを評価するための拡張機能を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-11">
        <br><font color="black">2020-10-11</font>
      </time>
    </span>
</section>
<!-- paper0: Research Challenges in Designing Differentially Private Text Generation
  Mechanisms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_18.html">
      <font color="black">Research Challenges in Designing Differentially Private Text Generation
  Mechanisms</font>
    </a>
  </h2>
  <font color="black">大まかに言えば、2つの提案を提供します。（1）ノイズの一部をプライバシー増幅ステップに延期するLACと呼ばれるフレームワーク、および（2）周囲のローカル領域に基づいてノイズを較正するための3つの異なる手法の追加スイート一言..そのようなメカニズムは、高次元のテキストのベクトル表現にプライバシー保護ノイズを追加し、ノイズの多いベクトルのテキストベースの投影を返します。ただし、これらのメカニズムは、プライバシーとユーティリティの間のトレードオフにおいて最適ではありません。 
[概要]プライバシーの概念は、テキストクエリの保護を支援するために開発されました。これらのシステムは、プライバシーとユーティリティの間のトレードオフにおいて最適ではありません。これらの要素は、プライバシーとノイズを保護するために最適ではありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Approches quantitatives de l'analyse des pr{é}dictions en traduction
  automatique neuronale (TAN) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_19.html">
      <font color="black">Approches quantitatives de l'analyse des pr{é}dictions en traduction
  automatique neuronale (TAN)</font>
    </a>
  </h2>
  <font color="black">ニューラル機械翻訳の最適な学習条件に関する大規模なプロジェクトの一環として、翻訳エンジンの特徴的なトレーニングフェーズを調査します。テキストメトリック探索の結果に続いて、さまざまなプロセスをマッピングするために、時系列の進行に関連する現象の重要性を特定します。ニューラル機械翻訳（NMT）での作業中。すべての実験はOpenNMT-Pyを使用して実行されます。前処理ステップは、Europarlトレーニングコーパスを使用して実装され、INTERSECTコーパスが検証に使用されます。 
[概要]テキスト調査の結果に続いて、時系列の進行に関連する現象の重要性を特定します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Bew: Towards Answering Business-Entity-Related Web Questions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_20.html">
      <font color="black">Bew: Towards Answering Business-Entity-Related Web Questions</font>
    </a>
  </h2>
  <font color="black">Bew質問と呼ばれるクラスの質問に回答するように特別に設計されたシステムであるBewQAを紹介します。重要なことに、BewQAはトレーニングを必要としません。答え。 
[概要] 1066の質問と根拠の新しいデータセットが必要です-レストランドメインの真実の回答。ドメイン内のビジネスエンティティに関する情報を集約するウェブサイトを活用して、テンプレートを自動的に抽出する方法を示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Improving short text classification through global augmentation methods -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_21.html">
      <font color="black">Improving short text classification through global augmentation methods</font>
    </a>
  </h2>
  <font color="black">\ emph {mixup}を使用すると、すべてのテキストベースの拡張のパフォーマンスがさらに向上し、テスト済みの深層学習モデルに対する過剰適合の影響が軽減されます。テキスト拡張へのさまざまなアプローチの影響を調査します。翻訳サービスを使用した往復翻訳コストが原因で使用が困難であることが判明しているため、通常のユースケースと低リソースのユースケースの両方でアクセスしにくくなっています。 
[概要]ソーシャルメディアとニュース記事の形式の正式なテキストを含む3つのデータセットを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-07">
        <br><font color="black">2019-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: As good as new. How to successfully recycle English GPT-2 to make models
  for other languages -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_22.html">
      <font color="black">As good as new. How to successfully recycle English GPT-2 to make models
  for other languages</font>
    </a>
  </h2>
  <font color="black">さらに、GPT-2小の再学習された字句埋め込みをGPT-2中埋め込みスペースに変換することにより、複雑さをスケールアップする方法を示します。イタリア語の場合、GPT-2モデルによって生成された文と同等に評価されていることがわかります。ゼロからトレーニングされます。私たちの仕事は、他の言語のGPT-2をトレーニングするための青写真として考えることができ、そのための「レシピ」を提供します。 
[ABSTRACT]元の英語の語彙埋め込みと整合し、バイリンガルの語彙を誘発するイタリア語とオランダ語の語彙埋め込み。この方法は、トレーニングの量を最小限に抑え、gpt-2によって学習された適応中に情報が失われるのを防ぎます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Infusing Finetuning with Semantic Dependencies -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_23.html">
      <font color="black">Infusing Finetuning with Semantic Dependencies</font>
    </a>
  </h2>
  <font color="black">このアプローチは、従来の事前トレーニングや微調整に加えて、（タスク固有ではなく）汎用の言語監視の可能性を示しています。最近の言語モデルに新しいプローブを適用します。特に、セマンティック依存関係によって操作可能な述語-項構造に焦点を当てます。 （Ivanova et al。、2012）-そして、構文とは異なり、セマンティクスは今日の事前トレーニングされたモデルによって表面化されないことがわかります。次に、畳み込みグラフエンコーダーを使用して、セマンティック解析をタスク固有の微調整に明示的に組み込み、 GLUEベンチマークの自然言語理解（NLU）タスク。 
[要約]根拠のある監督の欠如は、これらの表現がどれほどうまく意味を捉えることができるかについて疑問を投げかけています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Comprehensive Analysis of Aspect Term Extraction Methods using Various
  Text Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/cs.CL/paper_24.html">
      <font color="black">Comprehensive Analysis of Aspect Term Extraction Methods using Various
  Text Embeddings</font>
    </a>
  </h2>
  <font color="black">さらに、文字の埋め込みを使用して単語のベクトル化ステップを拡張するパフォーマンスへの影響を分析しました。追加のCRFレイヤーも一貫して結果を改善します。SemEvalデータセットの実験結果は、双方向の長期短期記憶だけでなく、メモリ（BiLSTM）は通常のLSTMを上回りますが、単語埋め込みカバレッジとそのソースもアスペクト検出のパフォーマンスに大きく影響します。 
[概要]特に、事前にトレーニングされたさまざまな単語の埋め込みを使用した、オプションの条件付き確率場（crf）拡張機能を備えた長短期記憶（lstm）に基づくアーキテクチャに焦点を当てました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-11">
        <br><font color="black">2019-09-11</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Data-Efficient Framework for Real-world Multiple Sound Source 2D
  Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/eess.AS/paper_0.html">
      <font color="black">Data-Efficient Framework for Real-world Multiple Sound Source 2D
  Localization</font>
    </a>
  </h2>
  <font color="black">さらに、さまざまなマイクアレイレイアウトを学習すると、可能なレイアウトの数が無限になるため、タスクがより複雑になります。さらに、ローカリゼーションアーキテクチャに埋め込まれる新しい明示的な変換レイヤーを提案します。音響シミュレータを活用して、ラベルを安価に生成できます。トレーニングデータ。 
[ABSTRACT]合成データモデルは、ドメインの不一致により、実際の記録ではパフォーマンスが低下します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Direct multimodal few-shot learning of speech and images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/eess.AS/paper_1.html">
      <font color="black">Direct multimodal few-shot learning of speech and images</font>
    </a>
  </h2>
  <font color="black">以前の作業では、学習した単峰性表現に依存する2段階の間接アプローチを使用しました。音声と画像の比較は、指定された音声と画像のペアのサポートセット全体で実行されます。改善は、監視されていないものと監視されていないものの組み合わせによるものであることを示します。直接モデルでの転移学習、および2段階の複合エラーの欠如..音声から画像への数字マッチングタスクでは、直接モデルは間接モデルよりも優れており、MTripletは最高のマルチモーダル5ショット精度を達成します。 
[概要]単一のマルチモーダル画像を学習する2つの直接モデルを提案します。これらは音声のマルチモーダルに基づいており、直接モデルを実行します。代わりに、音声を学習して間接モデルを実行します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Multiple Sound Source 2D Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/eess.AS/paper_2.html">
      <font color="black">Learning Multiple Sound Source 2D Localization</font>
    </a>
  </h2>
  <font color="black">さらに、精度を高める2つの新しいローカリゼーション表現も提案します。具体的には、複数のマイクアレイを使用して、密閉された環境で複数の音源の2Dデカルト座標を見つけることを目指します。この目的のために、エンコーディングを使用します。アーキテクチャをデコードし、タスクを実行するために2つの改善を提案します。 
[概要]複数のマイクを使用して、密閉された環境で複数の音源の2次元座標を見つけることを目指しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Unified Streaming and Non-streaming Two-pass End-to-end Model for Speech
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/eess.AS/paper_3.html">
      <font color="black">Unified Streaming and Non-streaming Two-pass End-to-end Model for Speech
  Recognition</font>
    </a>
  </h2>
  <font color="black">AISHELL-1テストセットでは、統合モデルは、標準の非ストリーミングトランスフォーマーと比較して、非ストリーミングASRで5.60％の相対文字エラー率（CER）の削減を達成します。CTC仮説は、アテンションデコーダーによって再スコアリングされ、最終結果..私たちのモデルは、エンコーダーのコンフォーマーレイヤーが変更されたハイブリッドCTC /アテンションアーキテクチャを採用しています。 
[概要]提案手法は、ストリーミングモデルと非ストリーミングモデルを簡単かつ効率的に統合することができます。この方法は、統合して効果的に使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Fast and Effective Robustness Certification for Recurrent Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-11/eess.AS/paper_4.html">
      <font color="black">Fast and Effective Robustness Certification for Recurrent Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">これには、音声前処理を構成する一般的な操作のためのカスタム凸緩和も開発する必要がありました。R2を使用して、リカレントニューラルネットワークの重要なユースケース、つまり音声分類を証明する最初の研究を提示します。正確なものを提示します。 R2と呼ばれるリカレントニューラルネットワーク用のスケーラブルなベリファイア。 
[概要]検証者は、以前に行われた単一の境界ではなく、各ニューロンの多重化の一般的な組み合わせを最適化するシステムを含む、2つの重要なアイデアに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-27">
        <br><font color="black">2020-05-27</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
