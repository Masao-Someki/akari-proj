<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-12-17の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: A Synergistic Kalman- and Deep Postfiltering Approach to Acoustic Echo
  Cancellation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.SD/paper_0.html">
      <font color="black">A Synergistic Kalman- and Deep Postfiltering Approach to Acoustic Echo
  Cancellation</font>
    </a>
  </h2>
  <font color="black">提案された相乗的スキームは、静的シナリオでの最先端のアプローチによって達成される定常状態のパフォーマンスを損なうことなく、突然のエコーパスの変化後に適応フィルターの迅速な再収束を可能にします。提案されたアルゴリズムは、カルマンフィルターのよく知られた制限を克服します。急激なエコーパスの変化を特徴とするシナリオでのベースの適応制御..適応カルマンフィルタリングとディープニューラルネットワークベースのポストフィルターを組み合わせた、ダブルトークのロバストな音響エコーキャンセルへの相乗的アプローチを紹介します。 
[要約]提案されたアルゴリズムは、カルマンフィルターベースの適応制御のよく知られた制限を克服します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: GAN Compression: Efficient Architectures for Interactive Conditional
  GANs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/eess.IV/paper_0.html">
      <font color="black">GAN Compression: Efficient Architectures for Interactive Conditional
  GANs</font>
    </a>
  </h2>
  <font color="black">検索プロセスを加速するために、重み共有を介してモデルトレーニングとアーキテクチャ検索を分離します。まず、GANトレーニングを安定させるために、元のモデルの複数の中間表現の知識を圧縮モデルに転送し、ペアのない学習とペアの学習を統合します。 。これらの課題には2つの方法で対処します。 
[概要]最近のcgansは、現代のビジョンよりも1〜2桁多く、たとえば、これらのモデルは知識不足の影響を受けやすくなっています。メソッドは、ニューラルアーキテクチャ検索を介して効率的なアーキテクチャを自動的に検出します（nas）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-19">
        <br><font color="black">2020-03-19</font>
      </time>
    </span>
</section>
<!-- paper0: SimuGAN: Unsupervised forward modeling and optimal design of a LIDAR
  Camera -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/eess.IV/paper_1.html">
      <font color="black">SimuGAN: Unsupervised forward modeling and optimal design of a LIDAR
  Camera</font>
    </a>
  </h2>
  <font color="black">短距離用の省エネLIDARカメラは、時間的に強度コード化されたレーザー光パルスを使用して物体の距離を推定し、後方散乱パルスとの最大相関を計算します。この目標を達成するために、背面に指定された新しいカスタム損失関数も提案します。 -散乱コード分布の弱点とその循環動作..この問題に対処するために、敵対プロセスを通じて複雑なクラス分布を学習できる2つのニューラルネットワークであるGAN（Generative Adversarial Networks）を使用します。 
[概要] lidlカメラの非表示のプロパティと動作を学習し、カメラをシミュレートする完全に監視されていない新しいモデルを作成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: PGMAN: An Unsupervised Generative Multi-adversarial Network for
  Pan-sharpening -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/eess.IV/paper_2.html">
      <font color="black">PGMAN: An Unsupervised Generative Multi-adversarial Network for
  Pan-sharpening</font>
    </a>
  </h2>
  <font color="black">ただし、学習の参照として意図されたHR MS画像がないため、既存の方法のほとんどすべてがMSおよびPAN画像をダウンサンプリングし、元のMS画像をターゲットと見なして、トレーニングの教師あり設定を形成します。この問題を克服するには、前処理なしでフル解像度画像から直接学習できる教師なしフレームワークを設計します。GaoFen-2およびQuickBird画像での他の最先端の方法との実験と比較は、提案された方法が取得できることを示しています。フル解像度の画像ではるかに優れた融合結果が得られます。 
[概要]これらの手法は、縮小された画像ではうまく機能する可能性がありますが、フル解像度の画像への一般化は不十分です。このモデルは、新しい属ベースの衛星に基づいて構築されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Evaluation of deep learning-based myocardial infarction quantification
  using Segment CMR software -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/eess.IV/paper_3.html">
      <font color="black">Evaluation of deep learning-based myocardial infarction quantification
  using Segment CMR software</font>
    </a>
  </h2>
  <font color="black">MIのサイズの実験的評価では、ネットワークベースの結果の50％（平均梗塞瘢痕量）、75％（平均梗塞瘢痕率）、および65％（平均微小血管閉塞率）がほぼ非常に近いことが示されています。専門家の描写に基づく結果..また、心筋および梗塞の輪郭の視覚化を含む実験では、選択したスタックのすべての画像で、ネットワークと専門家に基づく結果は、梗塞および輪郭のある画像の数に関して結びついています。ここでは、深層学習を使用して、心筋境界のセグメンテーションを自動化してから、セグメントCMRソフトウェアに組み込まれている期待値最大化、加重強度、事前情報（EWA）アルゴリズムを使用してMIのサイズの自動定量化をトリガーします。 
[ABSTRACT]ディープラーニングは、心筋境界のセグメンテーションを自動化するために使用されます。これにより、期待値（最大化、加重強度、事前情報（ewa）アルゴリズム）を使用してmiのサイズの自動定量化がトリガーされました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Learning-Based Quality Assessment for Image Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/eess.IV/paper_4.html">
      <font color="black">Learning-Based Quality Assessment for Image Super-Resolution</font>
    </a>
  </h2>
  <font color="black">SISARデータベースとDISQモデルは、再現性のある研究を容易にするために公開されます。特徴抽出に2ストリームのディープニューラルネットワーク（DNN）を採用し、続いてエンドツーエンドのディープイメージSR品質（DISQ）モデルをトレーニングします。品質予測のための特徴融合ネットワーク..実験結果は、提案された方法が最先端のメトリックを上回り、クロスデータベーステストで有望な一般化パフォーマンスを達成することを示しています。 
[要約]品質評価指標は、sr手法の比較と最適化において重要な役割を果たします。しかし、現在の指標は、主に大規模な品質データベースがないため、限られた成功しか達成していません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: PALMNUT: An Enhanced Proximal Alternating Linearized Minimization
  Algorithm with Application to Separate Regularization of Magnitude and Phase -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/eess.IV/paper_5.html">
      <font color="black">PALMNUT: An Enhanced Proximal Alternating Linearized Minimization
  Algorithm with Application to Separate Regularization of Magnitude and Phase</font>
    </a>
  </h2>
  <font color="black">振幅と位相の正則化を分離するアプリケーションに焦点を当てていますが、同じアプローチが、同様の目的関数構造を持つ他の非凸最適化問題でも役立つ可能性があると予想しています。磁気共鳴イメージングのコンテキストで得られた経験的結果は、PALMNUTが交互最小化のような一般的な既存のアプローチに対する計算上の利点..理論的には、PALMNUTのバージョン（ネステロフの勢いなし）が目的関数を単調に減少させ、関心のある多くの場合に収束が保証されることを確立します。 
[ABSTRACT] palmnutは、手のひらとnesterovの運動量を組み合わせた新しいアルゴリズムです。新しいアルゴリズムは、非結合の座標方向のステップサイズを使用します。これらには、非結合の座標方向のステップが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient $\ell^0$ gradient-based Super Resolution for simplified image
  segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/eess.IV/paper_6.html">
      <font color="black">Efficient $\ell^0$ gradient-based Super Resolution for simplified image
  segmentation</font>
    </a>
  </h2>
  <font color="black">高度に劣化した合成データと実世界データでモデルをテストし、その結果をいくつかの変分アプローチや最先端の深層学習手法と定量的に比較します。モデルの数値実現のために、提案します。サブステップ解がハードスレッショルドおよび標準共役勾配ソルバーによって効率的に計算される、新しい効率的なADMM分割アルゴリズム。私たちの実験は、$ \ ell ^ 0 $勾配正規化超解像画像を効果的に使用して改善することができることを示しています。他のアプローチによって達成された結果と比較した、QRおよびセル検出、および土地被覆分類問題に適用された場合の標準セグメンテーションアルゴリズムの精度。 
[概要]モデルは、データデータ分析とデータデータデータに基づいています。「スーパーエンジン」モデル、または異方性を予測するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: Learning-Based Algorithms for Vessel Tracking: A Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/eess.IV/paper_7.html">
      <font color="black">Learning-Based Algorithms for Vessel Tracking: A Review</font>
    </a>
  </h2>
  <font color="black">レビューされた方法に基づいて、評価の問題が紹介されます。論文は、残りの緊急事態と将来の研究についての議論で終わります。最初に、従来の機械学習ベースのアルゴリズムがレビューされ、次に、ディープラーニングベースのフレームワークが提供されます。 
[ABSTRACT]血管追跡は、認識の問題を解決することを目的としています。これらには、キー（シード）ポイントの検出、中心線の抽出、および血管のセグメンテーションが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Cohort Generalizability of Deep and Conventional Machine Learning
  for MRI-based Diagnosis and Prediction of Alzheimer's Disease -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/eess.IV/paper_8.html">
      <font color="black">Cross-Cohort Generalizability of Deep and Conventional Machine Learning
  for MRI-based Diagnosis and Prediction of Alzheimer's Disease</font>
    </a>
  </h2>
  <font color="black">三次記憶クリニックの人口を表すこの多施設共同研究から、199人のAD患者、139人の主観的認知障害の参加者、48人のMCI患者が認知症に転向し、91人のMCI患者が認知症に転向しなかった。ベクトルマシン（SVM）と構造的MRIスキャンに基づくディープコンボリューションニューラルネットワーク（CNN）アプローチは、最小限の前処理または変調された灰色物質（GM）マップへのより広範な前処理のいずれかを受けました。外部検証では、パフォーマンスはわずかでした。減少しました。 
[概要]これは、変調灰白質（gm）マップへの最小限の前処理またはより広範な前処理を行った構造的mriスキャンに基づいています。その後、分類子を適用して、adni mcizaへの変換を予測しました。adnimciza参加者は231のコンバーターを表します、628非コンバーター</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Improving distribution and flexible quantization for DCT coefficients -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/eess.IV/paper_9.html">
      <font color="black">Improving distribution and flexible quantization for DCT coefficients</font>
    </a>
  </h2>
  <font color="black">両方を最適化すると、ここではほぼ均一な量子化が実現し、テール処理が自動化されます。歪みのみに対して$ q $を最適化すると、大幅な改善が見られますが、より均一な分布によりエントロピーが増加します。特にこのような連続分布の場合は、また、最適化された連続\ emph {量子化密度関数} $ q $による量子化アプローチについても説明します。これは、CDF（累積分布関数）$ Q $を通常の格子$ \ {Q ^ {-1}（（i-1 / 2） / N）：i = 1 \ ldots N \} $は、速度歪み制御を備えた、さまざまなサイズ$ N $の最適化された（不均一な）量子化の柔軟で安価な選択を可能にする量子化ノードを提供します。 
[概要] dctカクテルの分布の予測についても説明します。これらは、dctブロックのすでにデコエグされた領域からのものです。これらの要因には、最適化された連続およびmu mu muemphが含まれます。これらには、最適化された「不均一」量子化が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-23">
        <br><font color="black">2020-07-23</font>
      </time>
    </span>
</section>
<!-- paper0: Spatial light interference microscopy (SLIM): principle and applications
  to biomedicine -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/eess.IV/paper_10.html">
      <font color="black">Spatial light interference microscopy (SLIM): principle and applications
  to biomedicine</font>
    </a>
  </h2>
  <font color="black">ゼルニケ位相差顕微鏡法、SLIMでの位相回復、およびハロー除去アルゴリズムについて説明します。SLIMは、細胞のダイナミクス、細胞の成長と増殖、細胞の移動、大量輸送などを研究できます。臨床現場では、SLIMは癌研究を支援できます。 、生殖技術、血液検査など。
[ABSTRACT]スリムは最も感度の高い定量的位相イメージング（qpi）法の1つです。スペックル-サブナノメートルの経路での自由位相再構成-長さの安定性を可能にします。さらに、概要を説明します。理論から芳香族化までのスリムイメージング次に、スリムイメージング、プロセス、スライド全体のスキャン、モザイクタイルの登録、カラーカメラによるイメージングの概要を説明します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Feature Space Adversarial Attack -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/eess.IV/paper_11.html">
      <font color="black">Towards Feature Space Adversarial Attack</font>
    </a>
  </h2>
  <font color="black">この実験は、既存のピクセル空間の敵対的攻撃の検出および防御技術では、スタイル関連の特徴空間の堅牢性をほとんど保証できないこともサポートしています。私たちの攻撃は、最先端の状態よりも自然に見える敵対的サンプルを生成できることを示しています。アートの無制限の攻撃..入力ピクセルを直接混乱させるほとんどの既存の攻撃とは異なり、私たちの攻撃は抽象的な特徴、より具体的には、鮮やかな色やシャープな輪郭などの解釈可能なスタイルや解釈できないスタイルを含むスタイルを表す特徴に焦点を当てています。 
[ABSTRACT]私たちの攻撃は抽象的な特徴を混乱させることに焦点を当てています。私たちの攻撃が敵対的なサンプルを生成する可能性があることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-26">
        <br><font color="black">2020-04-26</font>
      </time>
    </span>
</section>
<!-- paper0: CT Super Resolution via Zero Shot Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/eess.IV/paper_12.html">
      <font color="black">CT Super Resolution via Zero Shot Learning</font>
    </a>
  </h2>
  <font color="black">結果は、ゼロショットSADIR-Netが、特にトレーニングデータが限られている状況で、CT SR再構成のための他のSotAメソッドに匹敵するパフォーマンスを実際に提供できることを示しています。このメソッドは、サイノグラムドメインのSRモデルを相乗的に組み合わせます。画像領域のモデル、およびCT SRアルゴリズムの超解像およびデブラーベースの反復再構成（SADIR）への反復フレームワーク。SADIRネットはゼロショット学習（ZSL）ネットワークであり、単一のサイノグラムでトレーニングおよびテストできます。テスト時間。 
[概要]ディープラーニング（dl）ベースのct超解像（sr）メソッドは、低解像度（cs）を高解像度（hr）ct画像で再構成できます。sadirは、catphan700物理ファントムのsrctイメージングを介して評価されました。および生物学的ハム、およびその性能を他の最先端の（sota）dlベースの方法と比較しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Do not repeat these mistakes -- a critical appraisal of applications of
  explainable artificial intelligence for image based COVID-19 detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/eess.IV/paper_13.html">
      <font color="black">Do not repeat these mistakes -- a critical appraisal of applications of
  explainable artificial intelligence for image based COVID-19 detection</font>
    </a>
  </h2>
  <font color="black">最終結果は、信頼できるCOVID-19診断モデルが満たす必要のある最小条件を備えたチェックリストの提案です。この作業では、提案されたモデルのさまざまな側面の体系的な分析を実行します。この作業では、調査されたML記事で提案されたアプローチは、X線撮影領域の深い理解の欠如から生じる典型的なエラーを示しています。 
[概要]これにより、covid用の多くのディープニューラルネットワークモデルが開発されました。説明可能性のためのモジュールを使用した19の検出。短期間で、モデル開発は多数のエラーにリンクされました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-11">
        <br><font color="black">2020-12-11</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: C2F-FWN: Coarse-to-Fine Flow Warping Network for Spatial-Temporal
  Consistent Motion Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_0.html">
      <font color="black">C2F-FWN: Coarse-to-Fine Flow Warping Network for Spatial-Temporal
  Consistent Motion Transfer</font>
    </a>
  </h2>
  <font color="black">特に、C2F-FWNは、粗いものから細かいものへのフローワーピングとレイアウト制約付き変形可能畳み込み（LC-DConv）を利用して空間的一貫性を改善し、フロー時間的一貫性（FTC）損失を採用して時間的一貫性を強化します。既存のGANベースのHVMT方法は大きな成功を収めており、合成画像と例示的な画像の間の空間的一貫性が失われるために外観の詳細を保持できないか、ビデオフレーム間の時間的一貫性がないために一貫性のないビデオ結果を生成します。ソースの外観入力であるC2F-FWNは、外観属性の編集を非常に柔軟かつ効率的にサポートできます。 
[ABSTRACT] hvmtは、シンセから-ファインモーションモーションモーションとレイアウト-制約付き変形可能畳み込み（lc-dconv）を使用して、空間の一貫性を向上させます。さらに、評価のために、solodanceという名前の大規模なhvmtual一貫性データセットも収集しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: GAN Compression: Efficient Architectures for Interactive Conditional
  GANs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_1.html">
      <font color="black">GAN Compression: Efficient Architectures for Interactive Conditional
  GANs</font>
    </a>
  </h2>
  <font color="black">検索プロセスを加速するために、重み共有を介してモデルトレーニングとアーキテクチャ検索を分離します。まず、GANトレーニングを安定させるために、元のモデルの複数の中間表現の知識を圧縮モデルに転送し、ペアのない学習とペアの学習を統合します。第二に、既存のCNN設計を再利用する代わりに、私たちの方法は、ニューラルアーキテクチャ検索（NAS）を介して効率的なアーキテクチャを自動的に見つけます。 
[概要]最近のcgansは、現代のビジョンよりも1〜2桁多く、たとえば、これらのモデルは知識不足の影響を受けやすくなっています。メソッドは、ニューラルアーキテクチャ検索を介して効率的なアーキテクチャを自動的に検出します（nas）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-19">
        <br><font color="black">2020-03-19</font>
      </time>
    </span>
</section>
<!-- paper0: Enhancing Unsupervised Video Representation Learning by Decoupling the
  Scene and the Motion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_2.html">
      <font color="black">Enhancing Unsupervised Video Representation Learning by Decoupling the
  Scene and the Motion</font>
    </a>
  </h2>
  <font color="black">具体的には、動画ごとにポジティブクリップとネガティブクリップを作成します。こうすることで、シーンのインパクトを弱め、ネットワークの時間感度をさらに高めます。この問題に取り組むために、デカップリングを提案します。シーンとモーション（DSM）を2つの簡単な操作で実行できるため、モーション情報に対するモデルの注意がより適切に支払われます。 
[概要]これは、動画表現学習に対する当初の意図に反しています。現在の動画データセットでは、一部のアクションカテゴリは、アクションが発生するシーンとの関連性が高く、モデルが劣化して、シーン情報のみが含まれるソリューションになる傾向があります。エンコードされた</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-12">
        <br><font color="black">2020-09-12</font>
      </time>
    </span>
</section>
<!-- paper0: Revisiting 3D Context Modeling with Supervised Pre-training for
  Universal Lesion Detection in CT Slices -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_3.html">
      <font color="black">Revisiting 3D Context Modeling with Supervised Pre-training for
  Universal Lesion Detection in CT Slices</font>
    </a>
  </h2>
  <font color="black">さらに、提案された3D事前トレーニングされた重みは、他の3D医療画像分析タスクのパフォーマンスを向上させるために使用できる可能性があります。新しい事前トレーニング方法により、提案されたMP3DFPNが最先端の検出を実現することを示します。 DeepLesionデータセットのパフォーマンス（FPs @ 0.5の感度が3.48％絶対的に向上）、3Dコンテキストモデリングに2D畳み込みを採用するベースラインメソッドを最大6.06％（MAP @ 0.5）上回っています。この作業では、深さ方向に分離可能な畳み込みフィルターとグループ変換モジュール（GTM）を活用して、CTスライスの普遍的な病変検出のための3Dコンテキスト拡張2D特徴を効率的に抽出する、修正疑似3D特徴ピラミッドネットワーク（MP3D FPN）を提案します。 
[概要]自然画像領域の大規模な2Dオブジェクト検出データセットを使用して、新しい3Dネットワークの事前トレーニング方法が開発されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: StrokeGAN: Reducing Mode Collapse in Chinese Font Generation via Stroke
  Encoding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_4.html">
      <font color="black">StrokeGAN: Reducing Mode Collapse in Chinese Font Generation via Stroke
  Encoding</font>
    </a>
  </h2>
  <font color="black">その結果、StrokeGANと呼ばれる効率的な方法を提案します。これは主に、ストロークエンコーディングに漢字のモード情報が大量に含まれているという観察に基づいています。数値結果は、StrokeGANが一般に最先端の方法よりも優れていることを示しています。コンテンツと認識の精度、および特定のストロークエラー、さらに現実的な文字を生成します。関連する生成された文字の1ビットストロークエンコーディングを再構築するために、ディスクリミネータに課せられるストロークエンコーディング再構築損失を導入します。 
[概要]ストロークガンの効果は、フォントの異なる9つのデータセットに対する一連の生成方法によって示されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Seeing Behind Objects for 3D Multi-Object Tracking in RGB-D Sequences -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_5.html">
      <font color="black">Seeing Behind Objects for 3D Multi-Object Tracking in RGB-D Sequences</font>
    </a>
  </h2>
  <font color="black">RGB-Dフレームのシーケンスから、各フレーム内のオブジェクトを検出し、それらの完全なオブジェクトジオメトリと、正規空間への密な対応マッピングを予測する方法を学習します。さらに、オブジェクトの完了が追跡に大きく役立ち、平均MOTAで$ 6.5 \％$の改善。オブジェクトの見えない領域を幻覚化することにより、同じインスタンス間の追加の対応を取得できるため、外観が大きく変化した場合でも堅牢な追跡が可能になります。 
[概要]オブジェクトの完成は追跡に大きく役立ち、平均モタで$ 6.5- $の改善を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Image Quality Assessment: Unifying Structure and Texture Similarity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_6.html">
      <font color="black">Image Quality Assessment: Unifying Structure and Texture Similarity</font>
    </a>
  </h2>
  <font color="black">この表現の特徴マップの空間平均が、さまざまなテクスチャパターンを合成するための十分な統計的制約のセットを提供するという点で、テクスチャの外観をキャプチャすることを経験的に示します。次に、これらの相関関係を組み合わせた画質メソッドについて説明します。特徴マップ（「構造類似性」）の相関関係を伴う空間平均（「テクスチャ類似性」）。コードはhttps://github.com/dingkeyan93/DISTSで入手できます。 
[概要]最適化された方法は、従来の画質データベースとテクスチャデータベースの両方で、人間の知覚スコアを説明します。空間平均の相関（「テクスチャ類似性」）と特徴マップの相関を組み合わせます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br><font color="black">2020-04-16</font>
      </time>
    </span>
</section>
<!-- paper0: SimuGAN: Unsupervised forward modeling and optimal design of a LIDAR
  Camera -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_7.html">
      <font color="black">SimuGAN: Unsupervised forward modeling and optimal design of a LIDAR
  Camera</font>
    </a>
  </h2>
  <font color="black">この問題に対処するために、GAN（Generative Adversarial Networks）を使用します。これは、敵対的プロセスを通じて複雑なクラス分布を学習できる2つのニューラルネットワークです。次に、モデルの微分可能性を使用して、カメラのパラメーター空間を探索し、それらのパラメーターを最適化します。深さ、精度、および安定性の..この目標を達成するために、後方散乱コード分布の弱点とその循環動作に指定された新しいカスタム損失関数も提案します。 
[概要] lidlカメラの非表示のプロパティと動作を学習し、カメラをシミュレートする完全に監視されていない新しいモデルを作成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Continuous Image Representation with Local Implicit Image
  Function -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_8.html">
      <font color="black">Learning Continuous Image Representation with Local Implicit Image
  Function</font>
    </a>
  </h2>
  <font color="black">コード付きのプロジェクトページはhttps://yinboc.github.io/liif/にあります。学習した連続表現は、トレーニングタスクが提供されていない場合でも、$ \ times 30 $高い解像度に外挿しても任意の解像度で表示できます。 。座標は連続しているため、LIIFは任意の解像度で表示できます。 
[概要]この論文は、陰関数を使用した3D再構成の最近の進歩に触発されました。これは、画像座標と座標周辺の2d深部特徴を寄与として取得する、局所陰画像関数（liif）を示唆し、でのrgb値を予測します。出力として与えられた座標</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: One-Pixel Attack Deceives Automatic Detection of Breast Cancer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_9.html">
      <font color="black">One-Pixel Attack Deceives Automatic Detection of Breast Cancer</font>
    </a>
  </h2>
  <font color="black">攻撃はサイバーセキュリティの観点から脅威をもたらします。意欲的な攻撃者は1ピクセル方式を攻撃ベクトルとして使用できます。結果は、分析中のスライド画像全体のわずかな1ピクセルの変更が診断に影響を与える可能性があることを示しています。 ..この研究では、1ピクセルの攻撃が、実際の腫瘍データセットを使用した実際のシナリオで実証されています。 
[ABSTRACT] 1つ-実際の腫瘍データセットを使用した実際のシナリオで実証されたピクセル攻撃</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Specular- and Diffuse-reflection-based Face Spoofing Detection for
  Mobile Devices -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_10.html">
      <font color="black">Specular- and Diffuse-reflection-based Face Spoofing Detection for
  Mobile Devices</font>
    </a>
  </h2>
  <font color="black">このコードはhttps://github.com/Akinori-F-Ebihara/SpecDiff-spoofing-detectorで公開されています。$ SpecDiff $記述子でトレーニングされた分類子は、社内データベースとオンの両方で他のフラッシュベースのPADアルゴリズムよりも優れています。公開されているNUAA、Replay-Attack、およびSiWデータベース。提案された$ SpecDiff $記述子は、2種類の反射を利用して構築されます。（i）活気に応じて特定の強度分布を持つ虹彩領域からの鏡面反射。 ）被写体の顔の3D構造を表す顔領域全体からの拡散反射。 
[概要]提案された$ specdiffアルゴリズムは、最小限のハードウェアと小さなデータベースのみを必要とし、携帯電話などのリソースに制約のあるデバイスに適しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-29">
        <br><font color="black">2019-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning to Segment Pelvic Bones: Large-scale CT Datasets and
  Baseline Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_11.html">
      <font color="black">Deep Learning to Segment Pelvic Bones: Large-scale CT Datasets and
  Baseline Models</font>
    </a>
  </h2>
  <font color="black">結論：この大規模なデータセットはコミュニティ全体の開発を促進し、このURL1で画像、注釈、コード、トレーニング済みベースラインモデルをオープンソース化する予定です。SDFポストプロセッサはハウスドルフで10.5％の減少をもたらします。後処理段階で重要な骨片を維持することによる距離..次に、私たちの知る限り、腰椎、仙骨、左股関節、右股関節をセグメント化するための深いマルチクラスネットワークを学ぶことを初めて提案します。複数ドメインの画像から同時に取得して、より効果的で堅牢な特徴表現を取得します。 
[ABSTRACT]骨盤骨セグメンテーションの既存の方法は、手作りまたは半自動のいずれかです。画像の外観の変化を処理するときに精度が制限されます。符号付き距離関数（sdf）に基づく後処理ツールにより、誤った予測が排除されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: I3DOL: Incremental 3D Object Learning without Catastrophic Forgetting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_12.html">
      <font color="black">I3DOL: Incremental 3D Object Learning without Catastrophic Forgetting</font>
    </a>
  </h2>
  <font color="black">一方、スコアフェアネス補正戦略は、検証フェーズで新しいクラスの偏った予測を補正することにより、3Dオブジェクトの過去と新しいクラス間の不均衡なデータによって引き起こされる壊滅的な忘却をさらに軽減するために提案されます。その後、によってもたらされる壊滅的な忘却を防ぎます。冗長な幾何学的情報、幾何学的な注意メカニズムが開発され、局所的な幾何学的構造の寄与を定量化し、クラスの増分学習に大きく寄与する独自の3D幾何学的特性を探索します。3D代表データセットでの実験により、I3DOLフレームワークの優位性が検証されます。 
[概要]新しいインクリメンタル3Dオブジェクト学習（i 3dクラウド）モデルは、3Dオブジェクトの新しいクラスを継続的に学習する最初の探索です。さらに学習した後、局所的な幾何学的構造の寄与を定量化するために、幾何学的認識の注意メカニズムが開発されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: FNA++: Fast Network Adaptation via Parameter Remapping and Architecture
  Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_13.html">
      <font color="black">FNA++: Fast Network Adaptation via Parameter Remapping and Architecture
  Search</font>
    </a>
  </h2>
  <font color="black">一連のアブレーション研究が有効性を実証するために実行され、詳細な分析が提供されて、動作メカニズムのより深い洞察が得られます。ImageNetの事前トレーニング済みネットワーク）は、パラメーターの再マッピングを介して、さまざまな深さ、幅、またはカーネルサイズのネットワークになります。技術、セグメンテーションと検出タスクのためにNASをはるかに効率的に使用することを可能にします..スーパーネットワーク）または検索されたネットワークは莫大な計算コストを負担します。 
[概要]最新の（sota）マッピングアプローチのほとんどは、画像分類用に設計されたニューラルネットワークアーキテクチャをバックボーンとして再利用し、通常はimagenetで事前トレーニングされます。ただし、大きな課題の1つは、画像ネットによる検索空間表現（別名ネットワーク）の事前トレーニングです。 ）この論文では、シードネットワークのカーネルまたはパラメータの両方を適応させることができる高速ネットワーク適応（fna）法を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-21">
        <br><font color="black">2020-06-21</font>
      </time>
    </span>
</section>
<!-- paper0: Two-Stage Copy-Move Forgery Detection with Self Deep Matching and
  Proposal SuperGlue -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_14.html">
      <font color="black">Two-Stage Copy-Move Forgery Detection with Self Deep Matching and
  Proposal SuperGlue</font>
    </a>
  </h2>
  <font color="black">最初の段階はバックボーンの自己ディープマッチングネットワークであり、2番目の段階はProposal SuperGlueと呼ばれます。最初の段階では、空間情報を充実させ、階層機能を活用するために、激しい畳み込みとスキップマッチングが組み込まれます。2段階のフレームワークが統合されます非常に疑わしい提案を取得することにより、エンドツーエンドのディープマッチングとキーポイントマッチングを行い、コピームーブ偽造検出におけるディープラーニング研究の新しい門を開きます。 
[概要] 2段階のフレームワークは、非常に疑わしい提案を取得することにより、エンドツーエンドのディープマッチングとキーポイントマッチングを統合します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: PGMAN: An Unsupervised Generative Multi-adversarial Network for
  Pan-sharpening -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_15.html">
      <font color="black">PGMAN: An Unsupervised Generative Multi-adversarial Network for
  Pan-sharpening</font>
    </a>
  </h2>
  <font color="black">GaoFen-2およびQuickBird画像での実験と他の最先端の方法との比較は、提案された方法がフル解像度画像ではるかに優れた融合結果を得ることができることを示しています。多くの深層学習ベースの方法が過去に開発されました。数年..ただし、学習の参照として意図されたHR MS画像がないため、既存の方法のほとんどすべてがMSおよびPAN画像をダウンサンプリングし、元のMS画像をターゲットと見なしてトレーニングの監視設定を形成します。 
[概要]これらの手法は、縮小された画像ではうまく機能する可能性がありますが、フル解像度の画像への一般化は不十分です。このモデルは、新しい属ベースの衛星に基づいて構築されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Reusable Network Components by Learning Compatible
  Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_16.html">
      <font color="black">Towards Reusable Network Components by Learning Compatible
  Representations</font>
    </a>
  </h2>
  <font color="black">元のタスクの精度を微調整したり妥協したりすることなく、直接互換性のあるコンポーネントを作成できることを示します。その後、教師なしドメイン適応、異なるアーキテクチャの特徴抽出器間で分類子を転送する3つのアプリケーションで互換性のあるコンポーネントを使用する方法を示します。 、および伝達学習の計算効率を向上させます。さまざまなタスクのネットワークを個別にトレーニングするのではなく、トレーニングプロセスを適応させて、タスク間で互換性のあるネットワークコンポーネントを作成します。 
[概要]トレーニングプロセスを適応させて、タスク間で互換性のあるネットワークコンポーネントを作成します。これには、異なるタスクとは異なるネットワークコンポーネントの作成が含まれます。教師なしドメイン適応、異なるアーキテクチャの機能抽出機能間でのコミファイアの転送の3つのアプリケーションがあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-08">
        <br><font color="black">2020-04-08</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Adaptive Object Detection via Feature Separation and Alignment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_17.html">
      <font color="black">Domain Adaptive Object Detection via Feature Separation and Alignment</font>
    </a>
  </h2>
  <font color="black">したがって、グレースケール特徴分離（GSFS）モジュール、ローカルグローバル特徴整列（LGFA）モジュール、および領域インスタンスレベル整列（RILA）モジュールで構成される特徴分離および整列ネットワーク（FSANet）を確立します。第一に、多くの方法は、各ドメインの個人情報を無視しながら、ソースドメインとターゲットドメインの間ですべての機能を調整することによってのみ分布シフトを減らします。しかし、領域提案の冗長性とバックグラウンドノイズは、ドメインの転送可能性を低下させる可能性があります。 
[ABSTRACT] daodは、画像内のオブジェクトの既存の領域でのフィーチャの配置を考慮する必要があります。ただし、daodは、マルチレベルフィーチャの分布シフトを減らすこともできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Evaluation of deep learning-based myocardial infarction quantification
  using Segment CMR software -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_18.html">
      <font color="black">Evaluation of deep learning-based myocardial infarction quantification
  using Segment CMR software</font>
    </a>
  </h2>
  <font color="black">MIのサイズの実験的評価では、ネットワークベースの結果の50％（平均梗塞瘢痕量）、75％（平均梗塞瘢痕率）、および65％（平均微小血管閉塞率）がほぼ非常に近いことが示されています。専門家の描写に基づく結果..ここでは、深部学習を使用して、心筋境界のセグメンテーションを自動化してから、期待値最大化、加重強度、事前情報（EWA）アルゴリズムを使用してMIのサイズの自動定量化をトリガーします。セグメントCMRソフトウェア..また、心筋と梗塞の輪郭の視覚化を含む実験では、選択したスタックのすべての画像で、ネットワークと専門家ベースの結果は、梗塞と輪郭の画像の数に関して結びついています。 
[ABSTRACT]ディープラーニングは、心筋境界のセグメンテーションを自動化するために使用されます。これにより、期待値（最大化、加重強度、事前情報（ewa）アルゴリズム）を使用してmiのサイズの自動定量化がトリガーされました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Learning-Based Quality Assessment for Image Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_19.html">
      <font color="black">Learning-Based Quality Assessment for Image Super-Resolution</font>
    </a>
  </h2>
  <font color="black">この作業では、最初に、新しい半自動ラベル付けアプローチを使用して大規模なSR画像データベースを構築します。これにより、管理可能な人的作業負荷で多数の画像にラベルを付けることができます。結果として得られる半自動評価付きSR画像品質データベース（SISAR）は、これまでで最大のSR-IQAデータベースであり、100の自然シーンの8,400枚の画像が含まれています。画像超解像度（SR）技術は、画像の空間解像度を向上させることで視覚品質を向上させます。 
[要約]品質評価指標は、sr手法の比較と最適化において重要な役割を果たします。しかし、現在の指標は、主に大規模な品質データベースがないため、限られた成功しか達成していません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: DeltaGAN: Towards Diverse Few-shot Image Generation with Sample-Specific
  Delta -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_20.html">
      <font color="black">DeltaGAN: Towards Diverse Few-shot Image Generation with Sample-Specific
  Delta</font>
    </a>
  </h2>
  <font color="black">生成サブネットワークは、入力画像のサンプル固有の「デルタ」を生成し、この入力画像と組み合わせて同じカテゴリ内の新しい画像を生成します。5つの数ショット画像データセットでの広範な実験により、提案された方法の有効性が実証されます。 。再構成サブネットワークは、同じカテゴリペア間のカテゴリ内変換、つまり「デルタ」をキャプチャします。 
[概要]再構築サブネットワークは、カテゴリ内変換「デルタ」をキャプチャします。いくつかの新しい作品が有効性を示していますが、多様性はまだ制限されています。これにより、デルタマッチング画像の画像が作成されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-18">
        <br><font color="black">2020-09-18</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Run with Potential-Based Reward Shaping and Demonstrations
  from Video Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_21.html">
      <font color="black">Learning to Run with Potential-Based Reward Shaping and Demonstrations
  from Video Data</font>
    </a>
  </h2>
  <font color="black">PBRSは最適なポリシーを変更しないため、このアプローチにより、RLエージェントは、ビデオに示されている人間の動きの準最適性を克服できます。YouTubeから取得）を使用して、ヒューマノイド学習エージェントの報酬をスピードアップできます。具体的には、主要な身体部分の位置を一定の時間間隔で使用して、潜在的な報酬形成（PBRS）の潜在的な関数を定義しています。 
[概要]ニップ競技の目標は、シミュレートされたレースコースを最高速度で走るように人体の2脚モデルをトレーニングすることでした。調査によると、私たちのアプローチは、ビデオでの次善のランニング行動を克服できることが示されています。ビデオから実行中のエージェントのポリシーを大幅に上回る学習済みポリシー</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Difficulty in estimating visual information from randomly sampled images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_22.html">
      <font color="black">Difficulty in estimating visual information from randomly sampled images</font>
    </a>
  </h2>
  <font color="black">画像分類実験では、ランダムサンプリング法は、空間情報不変の性質を維持しながら、難易度が高いだけでなく、他の次元削減法に匹敵することが実証されています。このため、視覚情報の推定が困難です。最近、ランダム変数の数を減らすだけでなく、プライバシーを保護する機械学習のために視覚情報を保護するプロセスとして、次元削減が注目されています。 
[ABSTRACT]確率変数の数を減らすために数量削減方法が使用されています。このプロセスでは実際のデータの数も削減されています。特に、ランダムサンプリング方法が他の方法と比較されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Image Segmentation using Mutual Mean-Teaching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_23.html">
      <font color="black">Unsupervised Image Segmentation using Mutual Mean-Teaching</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案されたモデルがさまざまなタイプの画像をセグメント化でき、既存の方法よりも優れたパフォーマンスを達成できることを示しています。この問題に対処するために、相互平均教育（MMT）フレームワークに基づく教師なし画像セグメンテーションモデルを提案します。より安定した結果..さらに、2つのモデルからのピクセルのラベルが一致しないため、ハンガリーのアルゴリズムに基づくラベル整列アルゴリズムがクラスターラベルと一致するように提案されます。 
[概要]事前の知識がない場合、既存のモデルのほとんどは通常、トレーニングが必要です。代わりに、かなりの量の作業を取得できる可能性があります。これは、事前の知識が不足しているためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Sketch Generation with Drawing Process Guided by Vector Flow and
  Grayscale -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_24.html">
      <font color="black">Sketch Generation with Drawing Process Guided by Vector Flow and
  Grayscale</font>
    </a>
  </h2>
  <font color="black">既存の鉛筆画アルゴリズムとの比較は、テクスチャの品質、スタイル、およびユーザー評価の点で、私たちの方法が他の方法よりも優れていることを示しています。既存の鉛筆スケッチアルゴリズムは、ストロークを直接模倣するのではなく、テクスチャレンダリングに基づいているため、描画プロセスですが、最終結果のみです。このフレームワークのガイダンスの下で、毎回1つのストロークを描画することで鉛筆スケッチを作成できます。 
[ABSTRACT]スケッチは、ストロークの直接の模倣だけでなく、テクスチャレンダリングに基づいています。既存のテクニックはプロセスに基づいているため、プロセスを表示できず、最終結果のみが表示されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Meta-Aggregation Networks for Class-Incremental Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_25.html">
      <font color="black">Meta-Aggregation Networks for Class-Incremental Learning</font>
    </a>
  </h2>
  <font color="black">クラス増分学習（CIL）は、クラスの数がフェーズごとに増加する分類モデルを学習することを目的としています。2つのタイプのブロック間で動的に最適化およびバランスを取るために、つまり本質的に、集計の重みをメタ学習します。安定性と可塑性の間..メタアグリゲーションネットワーク（MANets）と呼ばれる新しいネットワークアーキテクチャを提案することでこの問題を軽減します。このアーキテクチャでは、各残余レベルで2つの残余ブロックを明示的に構築します（ResNetをベースラインアーキテクチャとします）。プラスチックブロック。 
[概要]これは安定性です-古いクラスと新しいクラスの学習の間の可塑性のジレンマ。これは、パフォーマンスを向上させるためにマネのアーキテクチャに既存のcilメソッドをいくつ組み込むことができるかを説明しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-10">
        <br><font color="black">2020-10-10</font>
      </time>
    </span>
</section>
<!-- paper0: Distilling Optimal Neural Networks: Rapid Search in Diverse Spaces -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_26.html">
      <font color="black">Distilling Optimal Neural Networks: Rapid Search in Diverse Spaces</font>
    </a>
  </h2>
  <font color="black">このアプローチにより、DONNAは、最先端のアーキテクチャを上回るアーキテクチャを見つけます。次に、急速な進化的検索フェーズで、予測子とデバイス上の測定を使用して、あらゆるシナリオの精度と遅延の観点からパレート最適なアーキテクチャのセットを見つけます。第三に、パレート最適モデルは、完全な精度にすばやく微調整できます。 
[概要]イメージネット分類では、donnaによって検出されたアーキテクチャは、検索が3つのフェーズで構成されるよりも数倍高速です。この予測子により、さまざまなマクロ（レイヤータイプ、アテンションメカニズム、チャネル幅などのアーキテクチャネットワークパラメータ）を検索できます。パレート-最適なモデルをすばやく完全な精度に微調整できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: CompositeTasking: Understanding Images by Spatial Composition of Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_27.html">
      <font color="black">CompositeTasking: Understanding Images by Spatial Composition of Tasks</font>
    </a>
  </h2>
  <font color="black">ソースコードはwww.github.com/nikola3794/composite-taskingで公開されます。空間的に分散されたタスクを実行する方法を学ぶことは、タスク間でまばらなラベルのみが頻繁に利用可能であり、コンパクトなマルチタスクが必要なことによって動機付けられます。 network ..後者に関しては、いくつかのCompositeTaskingルールに従って実行する必要があるタスクの構成を学習します。 
[ABSTRACT]空間的に分散されたタスクを実行することを学ぶことは、タスク間で密な条件付けのみが頻繁に利用できることによって動機付けられます。提案されたネットワークは、画像のペアとピクセルのセットを取得します-賢明な密なタスク、および各ピクセルのタスク関連の予測を行います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Few-shot Font Generation with Localized Style Representations and
  Factorization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_28.html">
      <font color="black">Few-shot Font Generation with Localized Style Representations and
  Factorization</font>
    </a>
  </h2>
  <font color="black">提案されたスタイル表現により、テキストデザインで複雑なローカル詳細を合成できます。ただし、このようなアプローチでは、モデルが多様なローカルスタイルを表現するのが制限されるため、文字が中国語などの最も複雑な文字システムには適していません。非常に複雑な構造を持つさまざまな数のコンポーネント（「ラジカル」と呼ばれることが多い）。ソースコードはhttps://github.com/clovaai/lffontで入手できます。 
[概要]既存のいくつかのショットフォント生成方法は、いくつかの参照グリフからスタイルとコンテンツ要素を解きほぐすことを学ぶことを目的としています。これらには、各フォントスタイルのユニバーサルスタイル表現が含まれていますが、学習コンポーネント-ユニバーサルスタイルではなく、賢明なスタイル表現、実行不可能なデザインです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-23">
        <br><font color="black">2020-09-23</font>
      </time>
    </span>
</section>
<!-- paper0: AdjointBackMap: Reconstructing Effective Decision Hypersurfaces from CNN
  Layers Using Adjoint Operators -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_29.html">
      <font color="black">AdjointBackMap: Reconstructing Effective Decision Hypersurfaces from CNN
  Layers Using Adjoint Operators</font>
    </a>
  </h2>
  <font color="black">CNNユニットの決定面は主に入力に依存していることがわかります。これは、敵対的な入力がCNNを効果的に欺くことができる理由を説明している可能性があります。この方法で再構築された超曲面は、元の入力画像と乗算すると、ほぼ正確になります。そのユニットの出力値..畳み込みニューラルネットワーク（CNN）の内部動作を説明するには、いくつかの効果的な方法があります。 
[ABSTRACT] cnnsは、結果を説明するためにcnns全体によって実行されました。しかし、一般的に、結果はcnnsが任意のタスクであることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: TEMImageNet and AtomSegNet Deep Learning Training Library and Models for
  High-Precision Atom Segmentation, Localization, Denoising, and
  Super-resolution Processing of Atom-Resolution Scanning TEM Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_30.html">
      <font color="black">TEMImageNet and AtomSegNet Deep Learning Training Library and Models for
  High-Precision Atom Segmentation, Localization, Denoising, and
  Super-resolution Processing of Atom-Resolution Scanning TEM Images</font>
    </a>
  </h2>
  <font color="black">シミュレーション画像をトレーニングデータセットとして使用しているにもかかわらず、深層学習モデルは実験的なSTEM画像に自己適応でき、困難なコントラスト条件での原子の検出と位置特定において卓越したパフォーマンスを示し、精度は常に最先端の2つよりも優れています。次元ガウスフィット法..特に、原子分解能STEM画像の場合、これまでのところ、記録された画像に大きな厚さの変動がある場合にすべての原子列をセグメント化または検出するのに十分な堅牢性を備えた確立されたアルゴリズムはありません。また、トレーニングデータを簡単に閲覧およびダウンロードできるようにTEMImageNetプロジェクトのWebサイトを構築しました。 
[概要]これらの作品が新しいシステムで開発されたのはこれが初めてです。これらの作品には、トレーニングライブラリと深層学習方法が含まれています。実験画像の堅牢性、ローカリゼーション、ノイズ除去、超解像処理を実行できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Analysing the Direction of Emotional Influence in Nonverbal Dyadic
  Communication: A Facial-Expression Study -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_31.html">
      <font color="black">Analysing the Direction of Emotional Influence in Nonverbal Dyadic
  Communication: A Facial-Expression Study</font>
    </a>
  </h2>
  <font color="black">二者間対話における感情的影響の方向を特定することは、心理療法、政治的相互作用の分析、または対人対立行動への応用を伴う心理学への関心の高まりです。次に、強いときに存在するきめの細かい顔の表情を使用することを提案します。明確な顔の感情は見えません。そのため、社会的感情的な認知プロセスに関する意図しない行動の手がかりをよりよく理解するための完璧な尺度です。 
[要約]この研究は、顔の表情のみに基づく二者間対話における感情的影響の方向の分析に関係しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Joint Generative and Contrastive Learning for Unsupervised Person
  Re-identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_32.html">
      <font color="black">Joint Generative and Contrastive Learning for Unsupervised Person
  Re-identification</font>
    </a>
  </h2>
  <font color="black">教師なしReIDは、ラベルのない画像から直接表現を学習することでこの問題に対処します。最近の教師あり対照学習は、教師なし表現学習に効果的なアプローチを提供します。GANは対照学習のためのオンラインデータ拡張を提供しますが、対照モジュールは次のビュー不変機能を学習します。世代。 
[ABSTRACT]教師なしリードは、ラベルのない画像から直接表現を学習することでこの問題に対処します。最近の結果は、完全に教師なしと教師なしの両方のドメイン適応設定の下で、私たちの方法が最先端の方法を大幅に上回っていることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Reinforcement Learning for Active Human Pose Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_33.html">
      <font color="black">Deep Reinforcement Learning for Active Human Pose Estimation</font>
    </a>
  </h2>
  <font color="black">この目的に向けて、Pose-DRLを紹介します。これは、完全にトレーニング可能な深層強化学習ベースのアクティブポーズ推定アーキテクチャであり、空間と時間で適切なビューを選択して、基礎となる単眼ポーズ推定器にフィードすることを学習します。ほとんどの3D人間の姿勢推定方法は、入力（1つまたは複数の視点から収集されたシーンの画像、またはビデオから）が与えられることを前提としています。 
[概要]完全にトレーニング可能な深く強化された学習ベースのアクティブポーズ推定アーキテクチャを導入しました。システムは、自動停止条件を時間内にさらに学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-07">
        <br><font color="black">2020-01-07</font>
      </time>
    </span>
</section>
<!-- paper0: Temporal Graph Modeling for Skeleton-based Action Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_34.html">
      <font color="black">Temporal Graph Modeling for Skeleton-based Action Recognition</font>
    </a>
  </h2>
  <font color="black">広く使用されている2つの大規模データセット、NTU-60 RGB + DとNTU-120RGB + Dで広範な実験が行われます。この論文では、この制限に対処するために、時間拡張グラフ畳み込みネットワーク（TE-GCN）を提案します。したがって、これらの方法は、スケルトンシーケンスの時間的ダイナミクスを完全に探索する方法がまだ不明です。 
[概要]構造構造構造gcnは、この制限に対処するように設計されています。これらには、多数の大規模データセットに基づく3Dベースの「拡張グラフ」が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Secret Key Agreement with Physical Unclonable Functions: An Optimality
  Summary -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_35.html">
      <font color="black">Secret Key Agreement with Physical Unclonable Functions: An Optimality
  Summary</font>
    </a>
  </h2>
  <font color="black">ベクトル量子化器とエラー訂正コードパラメータを共同で設計する提案された最適なコード構造がリストされています。これらの構造には、極座標コードや畳み込みコードなどの最新の代数コードが含まれ、どちらも短いブロック長で小さなブロックエラー確率を実現できます。少数のPUF回路に対応します。信号処理、情報理論、コーディング理論、ハードウェアの複雑さの観点からのPUF文献の未解決の問題とそれらの組み合わせがリストされ、地域のプライバシーとセキュリティに関する研究のさらなる進歩を刺激します。 
[概要]物理的なクローン不可能な機能（puf）は、デジタルデバイスのローカルセキュリティの有望なソリューションです。このレビューでは、情報理論家、コーディング理論家、および信号処理コミュニティのメンバーに最も関連性の高い要約を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Recognizing New Semantic Concepts in New Visual Domains -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_36.html">
      <font color="black">Towards Recognizing New Semantic Concepts in New Visual Domains</font>
    </a>
  </h2>
  <font color="black">ソースとターゲットが複数の潜在ドメインの混合である場合のドメイン適応から、ドメインの一般化、連続ドメイン適応、予測ドメイン適応まで、バッチ正規化（BN）のバリアントをさまざまなシナリオに適用する方法を示します。ターゲットドメインは、メタデータの形式でのみ使用できます。変換されたタスク固有のバイナリマスク、オープンワールド認識、エンドツーエンドのトレーニングと強制クラスタリング、および増分クラスを使用して、順次マルチタスク学習のシナリオに対応します。バックグラウンドクラスのセマンティックシフトの問題を強調して対処するセマンティックセグメンテーションでの学習。また、この問題を解決するための最初の有望なステップである、入力と機能のドメインとセマンティックミキシングに基づくアプローチを提案します。 
[ABSTRACT]ディープモデルは、新しいビジュアルドメインに一般化できます。これには、ラベル付きソースドメイン（s）からラベル付きデータが利用できないドメイン（ターゲット）への知識の転送が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Event-based Motion Segmentation with Spatio-Temporal Graph Cuts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_37.html">
      <font color="black">Event-based Motion Segmentation with Spatio-Temporal Graph Cuts</font>
    </a>
  </h2>
  <font color="black">利用可能なデータセットでの実験は、さまざまなモーションパターンと移動オブジェクトの数を持つシーンでの方法の多様性を示しています。対照的に、イベントベースのカメラは、そのような制限を克服する利点を提供する新しいバイオインスパイアードセンサーです。問題を、エネルギー最小化を介して弱く制約されたマルチモデルフィッティングとして定式化し、その2つのサブ問題（イベントクラスター割り当て（ラベリング）とモーションモデルフィッティング）を、空間を利用して反復的に解決する方法を説明します。時空間グラフの形式での入力イベントの時間的構造。 
[ABSTRACT]モーションブラーまたは露出アーティファクトは、サンプリング原理によりモーションブラーおよび露出アーティファクトの影響を受ける可能性があります。ピクセル単位の強度変化を非同期で報告するため、シーンダイナミクスとまったく同じレートで視覚情報を取得できます。予想される移動オブジェクトの数を事前に決定する必要なしに、最先端技術と同等またはそれ以上のパフォーマンスを発揮します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Responsible Disclosure of Generative Models Using Scalable
  Fingerprinting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_38.html">
      <font color="black">Responsible Disclosure of Generative Models Using Scalable
  Fingerprinting</font>
    </a>
  </h2>
  <font color="black">対照的に、私たちの仕事は、そのような最先端の生成モデルの責任ある開示を可能にし、研究者や企業がモデルにフィンガープリントを付けることを可能にし、フィンガープリントを含む生成されたサンプルを正確に検出してソースに帰することができます。残念ながら、現在のディープフェイク検出方法は、本物と偽物のギャップが縮まり続けているため、持続可能ではありません。推奨される操作ポイントは128ビットの指紋を使用するため、原則として$ 10 ^ {36} $を超える識別可能なモデルになります。 
[概要]ディープフェイク検出は、ディープフィンガーフィンガーフィンガープリントに使用できます。ただし、ディープフェイク検出は、ディープフェイク、ディープフェイクのスポッティング、および帰属を検出します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: What BERT Sees: Cross-Modal Transfer for Visual Question Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_39.html">
      <font color="black">What BERT Sees: Cross-Modal Transfer for Visual Question Generation</font>
    </a>
  </h2>
  <font color="black">この論文では、補足データで行われる事前トレーニングを回避することにより、BERTの視覚的機能をすぐに評価することに関心があります。私たちは、根拠のある対話にとって非常に興味深いタスクである視覚的質問生成を研究することを選択します。これにより、各モダリティの影響を調査できます（入力は視覚的および/またはテキストである可能性があるため）。提案されたモデルは、2つの確立されたVQGデータセットの最先端を大幅に改善します。 
[ABSTRACT]テキスト生成用のbertベースのアーキテクチャであるbert-genは、モノモードまたはマルチモーダル表現を活用できます。提案されたモデルは、2つの確立されたデータセットで最先端技術を大幅に改善します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-25">
        <br><font color="black">2020-02-25</font>
      </time>
    </span>
</section>
<!-- paper0: Learning-Based Algorithms for Vessel Tracking: A Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_40.html">
      <font color="black">Learning-Based Algorithms for Vessel Tracking: A Review</font>
    </a>
  </h2>
  <font color="black">最後に、残りの緊急事態と今後の研究について議論します。レビューされた方法に基づいて、評価の問題を紹介します。最初に、従来の機械学習ベースのアルゴリズムをレビューし、次に、ディープラーニングベースのフレームワークが提供されます。 
[ABSTRACT]血管追跡は、認識の問題を解決することを目的としています。これらには、キー（シード）ポイントの検出、中心線の抽出、および血管のセグメンテーションが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Canny-VO: Visual Odometry with RGB-D Cameras based on Geometric 3D-2D
  Edge Alignment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_41.html">
      <font color="black">Canny-VO: Visual Odometry with RGB-D Cameras based on Geometric 3D-2D
  Edge Alignment</font>
    </a>
  </h2>
  <font color="black">最近傍フィールドの適応的にサンプリングされた定義によって効率がさらに向上します。本論文では、自由形式の曲線登録の古典的な問題をレビューし、すべてのキャニーを効率的に追跡するため、キャニー-VOと呼ばれる効率的なRGBD視覚オドメトリシステムに適用します。画像から抽出されたエッジ特徴..さまざまなロバストな重み関数が調査され、残差誤差の統計に基づいて最適な選択が行われます。 
[ABSTRACT]距離変換の2つの置換が提案されています。これにより、モデル登録、双一次内挿、劣勾配計算など、より計算量の多いデータの解釈が不要になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-15">
        <br><font color="black">2020-12-15</font>
      </time>
    </span>
</section>
<!-- paper0: Training an Emotion Detection Classifier using Frames from a Mobile
  Therapeutic Game for Children with Developmental Disorders -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_42.html">
      <font color="black">Training an Emotion Detection Classifier using Frames from a Mobile
  Therapeutic Game for Children with Developmental Disorders</font>
    </a>
  </h2>
  <font color="black">分類器は、CAFE全体で66.9％のバランスの取れた精度と67.4％のF1スコアを達成し、感情ラベルで少なくとも60％の人間の合意を含むサブセットであるCAFEサブセットAで79.1％のバランスの取れた精度と78.0％のF1スコアを達成しました。この大幅に拡張された小児感情中心データベース（既存の公開小児影響データセットの30倍以上）を使用して、幸せ、悲しい、驚き、恐れ、怒り、嫌悪、中立的な表現の小児感情分類畳み込みニューラルネットワーク（CNN）分類子をトレーニングしました。子供..人間のラベリング作業をゲーム化する安全なWebインターフェイスを通じて、すべての画像に2,155のビデオ、39,968の感情フレーム、および106,001のラベルを収集してラベルを付けました。 
[概要]コンピュータービジョンの感情モデルは、大人の感情についてトレーニングされているため、子供の顔ではパフォーマンスが低下します。私たちは、発達および行動状態の子供向けに大部分が設計されたインタラクティブなスマートフォンゲーム、guesswhatを使用しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Person Detection in 2D Range Data using a Calibrated
  Camera -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_43.html">
      <font color="black">Self-Supervised Person Detection in 2D Range Data using a Calibrated
  Camera</font>
    </a>
  </h2>
  <font color="black">2つの検出器モデルDROW3とDR-SPAAMを使用したJackRabbotデータセットでの実験を通じて、疑似ラベルでトレーニングまたは微調整された自己監視検出器が、異なるデータセットからの手動アノテーションを使用してトレーニングされた検出器よりも優れていることを示します。追加のラベル付け作業なしで展開中に人の検出器を改善する効果的な方法。関連するロボットアプリケーションをサポートするためのソースコードをリリースします。2Dのトレーニングラベル（疑似ラベルと呼ばれる）を自動的に生成するキャリブレーション済みカメラでの高速R-CNN LiDARベースの人物検出器。 
[抽象]学習データセットは、新しい環境または異なるLIDARモデルで展開された場合、パフォーマンスを制限する可能性があります。自己監視検出器は、手動アノテーションを使用してトレーニングされたものに近いパフォーマンスに達します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Reinforcement Learning of Graph Matching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_44.html">
      <font color="black">Deep Reinforcement Learning of Graph Matching</font>
    </a>
  </h2>
  <font color="black">その上、モデルはマッチングのためにノードの固定数に制限されていません。私たちの方法は、学習を目的としている一方で、フロントエンド機能とアフィニティ関数の学習に焦点を当てているという点で、以前のディープグラフマッチングモデルとは異なります。学習によって得られたかどうかにかかわらず、アフィニティ目的関数が与えられた場合のバックエンドの意思決定。ノードおよびペアワイズ制約の下でのグラフマッチングは、効果的な構造表現と関連付けのための、組み合わせ最適化、機械学習からコンピュータビジョンまでの領域の構成要素です。 
[概要]システムは変更回数に制限されるように設計されています。たとえば、ラベルフリーのシステムに修正できます。これは、グラフマッチングのための最初の深く推奨される学習ソルバーです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: SID-NISM: A Self-supervised Low-light Image Enhancement Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_45.html">
      <font color="black">SID-NISM: A Self-supervised Low-light Image Enhancement Framework</font>
    </a>
  </h2>
  <font color="black">暗い場所で画像をキャプチャすると、画像の視認性が低下することがよくあります。これにより、画像の美観が低下するだけでなく、多くのコンピュータビジョンアルゴリズムのパフォーマンスが大幅に低下します。次に、分解された照明マップは、 NISM ..復元された照明マップを使用すると、それに応じて拡張を行うことができます。 
[概要] sid-nismによって強化された画像は、より自然で、予期しないアーティファクトが少なくなっています。いくつかの公共の挑戦的な低光イメージングデータセットでの実験により、画像を強化できることが明らかになりました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Point Transformer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_46.html">
      <font color="black">Point Transformer</font>
    </a>
  </h2>
  <font color="black">たとえば、大規模なセマンティックシーンセグメンテーションのための挑戦的なS3DISデータセットでは、ポイントトランスフォーマーはエリア5で70.4％のmIoUを達成し、最強の以前のモデルを3.3絶対パーセンテージポイント上回り、初めて70％mIoUしきい値を超えました..ポイントクラウドの自己注意レイヤーを設計し、これらを使用して、セマンティックシーンセグメンテーション、オブジェクトパーツセグメンテーション、オブジェクト分類などのタスクの自己注意ネットワークを構築します。ポイントトランスフォーマーの設計は、ドメインおよびタスク全体の以前の作業を改善します。 
[ABSTRACT]セルフコンディショニングにより、ユーザーは「セルフネットワーク」の概念を使用して概念を開発できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Cohort Generalizability of Deep and Conventional Machine Learning
  for MRI-based Diagnosis and Prediction of Alzheimer's Disease -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_47.html">
      <font color="black">Cross-Cohort Generalizability of Deep and Conventional Machine Learning
  for MRI-based Diagnosis and Prediction of Alzheimer's Disease</font>
    </a>
  </h2>
  <font color="black">変調されたGMマップに基づくAD-CN分類では、SVM（0.940）とCNN（0.933）で同様のAUCが得られました。AD-CNでは、SVM（0.896）とCNN（0.876）で同様のAUCが得られました。三次記憶クリニックの人口を表す多施設共同研究では、199人のAD患者、主観的な認知機能低下を伴う139人の参加者、48人のMCI患者が認知症に転向し、91人のMCI患者が痴呆に転向しなかった。 
[概要]これは、変調灰白質（gm）マップへの最小限の前処理またはより広範な前処理を行った構造的mriスキャンに基づいています。その後、分類子を適用して、adni mcizaへの変換を予測しました。adnimciza参加者は231のコンバーターを表します、628非コンバーター</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: DECOR-GAN: 3D Shape Detailization by Conditional Refinement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_48.html">
      <font color="black">DECOR-GAN: 3D Shape Detailization by Conditional Refinement</font>
    </a>
  </h2>
  <font color="black">幾何学的詳細であるスタイルによる様式化に似た、3D形状詳細化のための深い生成ネットワークを紹介します。条件付きリファインメントによる3D詳細化は、生成的敵対的ネットワーク、造語DECOR-GANによって実現されます。 、私たちのネットワークは、ボクセルのアップサンプリングを介して、幾何学的な詳細が豊富な高解像度の形状にそれを洗練します。 
[ABSTRACT]ネットワークは3dcnnジェネレーターを使用して、3d形状をさまざまなスタイルのさまざまな詳細形状にリファインします。ネットワークはジェネレーターを使用して、生成されたモデルのローカルパッチをトレーニング詳細形状のものと同様に強制します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Feature Space Adversarial Attack -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_49.html">
      <font color="black">Towards Feature Space Adversarial Attack</font>
    </a>
  </h2>
  <font color="black">この実験は、既存のピクセル空間の敵対的攻撃の検出および防御技術では、スタイル関連の特徴空間の堅牢性をほとんど保証できないこともサポートしています。最適化手順を通じて知覚できないスタイルの変更を注入することにより、モデルの誤分類を引き起こします。直接混乱するほとんどの既存の攻撃とは異なります。入力ピクセル、私たちの攻撃は、抽象的な特徴、より具体的には、鮮やかな色やシャープな輪郭などの解釈可能なスタイル、および解釈できないスタイルを含むスタイルを表す特徴に焦点を当てています。 
[ABSTRACT]私たちの攻撃は抽象的な特徴を混乱させることに焦点を当てています。私たちの攻撃が敵対的なサンプルを生成する可能性があることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-26">
        <br><font color="black">2020-04-26</font>
      </time>
    </span>
</section>
<!-- paper0: Artificial GAN Fingerprints: Rooting Deepfake Attribution in Training
  Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_50.html">
      <font color="black">Artificial GAN Fingerprints: Rooting Deepfake Attribution in Training
  Data</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、最初に指紋をトレーニングデータに埋め込み、次にそのような指紋のトレーニングデータからGANモデルへの転送可能性に関する驚くべき発見を示します。これにより、ディープフェイクの信頼性の高い検出と帰属が可能になります。フォトリアリスティックな画像生成は、新しいレベルに達しました。生成的敵対的ネットワーク（GAN）の飛躍的進歩による品質。ディープフェイク検出に関する既存の研究は高い精度を示していますが、生成技術の進歩と検出対策技術の敵対的反復の影響を受けます。 
[概要]生成された画像に人工指紋を導入することで、ディープフェイク検出の解決策を模索しています。私たちの調査によると、私たちの指紋技術はさまざまな最先端のガンの組み合わせに当てはまりますが、ガンの使用は懸念を引き起こします。視覚的な誤報</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Do not repeat these mistakes -- a critical appraisal of applications of
  explainable artificial intelligence for image based COVID-19 detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_51.html">
      <font color="black">Do not repeat these mistakes -- a critical appraisal of applications of
  explainable artificial intelligence for image based COVID-19 detection</font>
    </a>
  </h2>
  <font color="black">最終結果は、信頼できるCOVID-19診断モデルが満たす必要のある最小条件を備えたチェックリストの提案です。この作業では、提案されたモデルのさまざまな側面の体系的な分析を実行します。両方の視点を提示します。この分野の専門家-放射線科医、およびモデルの説明を扱う深層学習エンジニア。 
[概要]これにより、covid用の多くのディープニューラルネットワークモデルが開発されました。説明可能性のためのモジュールを使用した19の検出。短期間で、モデル開発は多数のエラーにリンクされました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-11">
        <br><font color="black">2020-12-11</font>
      </time>
    </span>
</section>
<!-- paper0: Latent Space Conditioning on Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_52.html">
      <font color="black">Latent Space Conditioning on Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">生成的敵対的ネットワークは、学習した合成画像生成に向けた最先端のアプローチです。この作業では、敵対的トレーニングと表現学習という2つの一般的な学習手法の恩恵を受け、監視されていない条件付きGANに向けた一歩を踏み出す新しいフレームワークを紹介します。特に、私たちのアプローチは、潜在空間の構造（表現学習によって学習された）を活用し、それを使用して生成モデルを調整します。 
[概要]新しい方法は、監視対象の品質を維持しながら、オンデマンドでサンプルを生成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Exploiting Sample Uncertainty for Domain Adaptive Person
  Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_53.html">
      <font color="black">Exploiting Sample Uncertainty for Domain Adaptive Person
  Re-Identification</font>
    </a>
  </h2>
  <font color="black">平均教師法と追加の対照的損失を使用してベースラインフレームワークを構築します。多くの教師なしドメイン適応（UDA）個人再識別（ReID）アプローチは、クラスタリングベースの疑似ラベル予測と機能の微調整を組み合わせます。この発見では、不確実性（一貫性レベルで測定）を利用してサンプルの疑似ラベルの信頼性を評価し、不確実性を組み込んで、アイデンティティ（ID）分類損失を含むさまざまなReID損失内でその寄与を再重み付けすることを提案します。サンプルあたり、トリプレット損失、および対照的な損失。 
[概要]各サンプルに割り当てられた疑似ラベルの信頼性を推定および活用して、ノイズの多いサンプルの寄与を抑制することにより、ノイズの多いラベルの影響を軽減することを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Sit: Synthesizing Human-Chair Interactions via Hierarchical
  Control -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_54.html">
      <font color="black">Learning to Sit: Synthesizing Human-Chair Interactions via Hierarchical
  Control</font>
    </a>
  </h2>
  <font color="black">補足ビデオはhttps://youtu.be/3CeN0OGz2cAにあります。さまざまな非階層的および階層的ベースラインに対するアプローチの強さを実験的に示します。このギャップを埋めるために、1つのクラスのインタラクティブタスクに焦点を当てます- -椅子に座っています。 
[概要]システムは、サブタスクコントローラーを使用して、シンプルで再利用可能なモーションキャプチャモーションを模倣し、サブタスクを適切に実行してメインタスクを完了するようにトレーニングされたメタコントローラーを使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-20">
        <br><font color="black">2019-08-20</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring Data-Efficient 3D Scene Understanding with Contrastive Scene
  Contexts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CV/paper_55.html">
      <font color="black">Exploring Data-Efficient 3D Scene Understanding with Contrastive Scene
  Contexts</font>
    </a>
  </h2>
  <font color="black">点群）は非常に難しいことで有名です。この方向への第一歩として、シーン内のポイントレベルの対応と空間コンテキストの両方を利用する3D事前トレーニング方法であるContrastive Scene Contextsを提案します。アクセスおよびスキャンが制限される場合があります。十分なデータが与えられたとしても、3Dラベルを取得します（たとえば、このペーパーの
[ABSTRACT]では、データを調査します-3Dポイントクラウドの効率的な学習。この方法は、トレーニングデータまたはラベルが不足しているベンチマークを使用して実現します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Building domain specific lexicon based on TikTok comment dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_0.html">
      <font color="black">Building domain specific lexicon based on TikTok comment dataset</font>
    </a>
  </h2>
  <font color="black">このアプローチでは、
[13]に基づいて、中国語のTikTokレビューと感情的な語彙ソース（シードワード）の単語埋め込みを通じて、超高密度スペース埋め込みテーブルがトレーニングされます。ソースコードはgithub：https：// githubでリリースされています。 .com / h2222 / douyin_comment_dataset。モデルの結果は、単語の感情的な傾向を表すドメイン固有の辞書です。 
[概要]モデルは、感情的な傾向を持つ中国語の単語を分類できます。これには、単語の感情的な傾向を表すドメイン固有の辞書が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: LIREx: Augmenting Language Inference with Relevant Explanation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_1.html">
      <font color="black">LIREx: Augmenting Language Inference with Relevant Explanation</font>
    </a>
  </h2>
  <font color="black">自然言語の説明（NLE）は、アノテーターがデータインスタンスにラベルを割り当てるときに根拠（最も重要なテキストトークン）を識別し、根拠に基づいて自然言語でラベルの説明を書き出す特殊な形式のデータ注釈です。これらを克服するために制限事項として、理論的根拠に対応した説明ジェネレーターとインスタンスセレクターの両方を組み込んだ新しいフレームワークLIRExを提案し、NLIモデルを拡張するために関連するもっともらしいNLEのみを選択します。自然言語推論（NLI）用。 
[要約]言語の説明は、人間の推論をよりよく捉えることが示されています。説明ジェネレーターは、ラベルの人間の説明のバリエーションを考慮していないことがわかります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Fork or Fail: Cycle-Consistent Training with Many-to-One Mappings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_2.html">
      <font color="black">Fork or Fail: Cycle-Consistent Training with Many-to-One Mappings</font>
    </a>
  </h2>
  <font color="black">経験的側面では、既知のグラウンドトゥルースを使用した合成画像データセットと、知識グラフからの自然言語生成を含む実際のアプリケーション、およびその逆のプロトタイプの全射ケースを検討します。この体制に対処するために、条件付き変分自動エンコーダー（CVAE）アプローチは、全射マッピングを暗黙の双対に変換するものと見なすことができます。これにより、両方向の再構成エラーを最小限に抑えることができ、自然な副産物として、1対多の方向で現実的な出力ダイバーシティを得ることができます。この制限の重要な例の1つとして、ドメイン間に多対1または全射マッピングが存在する実際に関連する状況を検討します。 
[要約]少なくともほぼ根拠が存在するという仮定-いずれかのドメインからの与えられた入力などの真の全単射は正確に再構築できます。ドメイン間の多くの-全単射マッピングは、それぞれのマッピングのその後の適用から見ることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-14">
        <br><font color="black">2020-12-14</font>
      </time>
    </span>
</section>
<!-- paper0: Discovering New Intents with Deep Aligned Clustering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_3.html">
      <font color="black">Discovering New Intents with Deep Aligned Clustering</font>
    </a>
  </h2>
  <font color="black">最後に、整列された疑似ラベルの監視下でインテント表現を学習します。最初に、いくつかのラベル付きの既知のインテントサンプルを事前知識として活用して、モデルを事前トレーニングします。次に、k-meansを実行してクラスター割り当てを生成します。疑似ラベルとして。 
[概要]この作業では、限られた既知のインテントデータを使用して新しいインテントを発見するための効果的な方法（ディープアラインクラスタリング）を提案します。k-は、クラスター割り当てを疑似ラベルとして生成することを意味します。テスト中に、整列された疑似ラベルの監督下での意図表現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: No Budget? Don't Flex! Cost Consideration when Planning to Adopt NLP for
  Your Business -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_4.html">
      <font color="black">No Budget? Don't Flex! Cost Consideration when Planning to Adopt NLP for
  Your Business</font>
    </a>
  </h2>
  <font color="black">多くの状況下で、小型で軽量のモデルはAIピボットビジネスに適していると主張し、特にリソース不足の言語については、低コストのモデルについてさらに調査する必要があると主張します。この作業では、パフォーマンスとパフォーマンスの両方を比較します。古典的な学習アルゴリズムのコストから、一般的なシーケンスおよびテキストのラベル付けタスクにおける最新のアルゴリズムへ。生産と利用のコストに関して。 
[ABSTRACT]これらの方法を採用することを計画している企業は、それらを構築するための機械と人材が不足しているため、困難に直面しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Using Meta-Knowledge Mined from Identifiers to Improve Intent
  Recognition in Neuro-Symbolic Algorithms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_5.html">
      <font color="black">Using Meta-Knowledge Mined from Identifiers to Improve Intent
  Recognition in Neuro-Symbolic Algorithms</font>
    </a>
  </h2>
  <font color="black">そのようなプロトタクソノミーを組み込んで意図表現を拡張できる神経記号アルゴリズムを使用することにより、そのようなマイニングされたメタ知識が意図認識の精度を向上できることを示します。これらの結果に基づいて、マイニングされたメタ知識の使用方法についても説明します。ニューロシンボリックアルゴリズムにおける知識獲得の課題に対する答えになる可能性があります。メタ知識は、範囲外の発話の検出にさらに関連性があり、誤認率（FAR）を20 \％以上減少させることが証明されました。チャットボットの約半分で。 
[概要]チャットボットのほぼ3分の1で、等意図率（eer）が10％以上向上しました。実験により、これらのシンボリックメタ知識構造をニューロシンボリックアルゴリズムで使用できることが実証されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: A learning perspective on the emergence of abstractions: the curious
  case of phonemes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_6.html">
      <font color="black">A learning perspective on the emergence of abstractions: the curious
  case of phonemes</font>
    </a>
  </h2>
  <font color="black">一般化のプロセスは、言語学者が操作する抽象化の根底にあり、MBLとECLが言語抽象化に似たタイプの言語知識を生み出すことができるかどうかを調査しました。本稿では、抽象電話かどうかを調査するためにさまざまなモデリング手法を使用します。 ECL学習モデルが抽象化を学習できること、および電話インベントリの少なくとも一部が入力から確実に識別できることを示します。 
[ABSTRACT]メモリベースの学習（mbl）とエラー訂正学習（ecl）は、言語知識の2つの重要な原則です。テスターは言語インベントリに関する2つの異なる原則をテストします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-14">
        <br><font color="black">2020-12-14</font>
      </time>
    </span>
</section>
<!-- paper0: Stylized Dialogue Response Generation Using Stylized Unpaired Texts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_7.html">
      <font color="black">Stylized Dialogue Response Generation Using Stylized Unpaired Texts</font>
    </a>
  </h2>
  <font color="black">この研究では、最初に逆対話モデルを導入して入力応答の可能な投稿を予測し、次にこの逆モデルを使用して、これらの定型化されたペアになっていないテキストに基づいて定型化された疑似対話ペアを生成します。は、与えられたコンテキストに一貫性があり、ターゲットスタイルに準拠しています。このペーパーでは、ペアになっていないテキストに埋め込まれたスタイルの特徴をキャプチャできる、スタイル化されたダイアログ生成方法を提案します。 
[概要]与えられたコンテキストに一貫性があり、ターゲットスタイルに準拠する対話応答を作成するための研究が進行中です。これらの疑似ペアは、共同トレーニングプロセスで凝縮された対話モデルをトレーニングするために使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-27">
        <br><font color="black">2020-09-27</font>
      </time>
    </span>
</section>
<!-- paper0: Categorical Vector Space Semantics for Lambek Calculus with a Relevant
  Modality -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_8.html">
      <font color="black">Categorical Vector Space Semantics for Lambek Calculus with a Relevant
  Modality</font>
    </a>
  </h2>
  <font color="black">このカテゴリを「量子化」ファンクタを介して有限次元ベクトル空間と線形マップにインスタンス化し、余代数モダリティの3つの具体的な解釈を処理します。具体的な解釈の有効性は、文の曖昧性解消データセットの拡張で、曖昧性解消タスクを介して評価されます。 BERT、Word2Vec、FastTextベクトルとリレーショナルテンサーを使用して、寄生ギャップフレーズに..モデルを適用して、！L *の動機付けの例（寄生ギャップを持つフレーズの導出）のカテゴリ的で具体的な意味解釈を構築します。 
[要約]スペクトルのカテゴリ部分は、モノイド圏の閉じたカテゴリです。主な目的は、寄生ギャップのあるフレーズを作成することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br><font color="black">2020-05-06</font>
      </time>
    </span>
</section>
<!-- paper0: Faster Depth-Adaptive Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_9.html">
      <font color="black">Faster Depth-Adaptive Transformers</font>
    </a>
  </h2>
  <font color="black">さらに、他の深度適応アプローチと比較すると、効率とロバスト性が大幅に向上します。具体的には、入力単語の硬さを明示的に測定し、対応する適応深度を推定するために、1）相互情報量（MI）ベースの推定と2 ）再構成損失ベースの推定..この論文では、停止ユニットを取り除き、必要な深度を事前に推定します。これにより、より高速な深度適応モデルが得られます。 
[要約]停止ユニットが最適化されておらず、不正確である可能性があります。その結果、文をモデル化するときに最適ではなく不安定なパフォーマンスが発生します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br><font color="black">2020-04-27</font>
      </time>
    </span>
</section>
<!-- paper0: Show or Tell? Demonstration is More Robust to Changes in Shared
  Perception than Explanation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_10.html">
      <font color="black">Show or Tell? Demonstration is More Robust to Changes in Shared
  Perception than Explanation</font>
    </a>
  </h2>
  <font color="black">人間の教育学と機械学習への影響について話し合います。教育には常に不整合な信念が含まれますが、教育学の研究では、教師と学習者が認識を共有する状況に焦点を当てることがよくあります。具体的な媒体（デモンストレーション、または「表示」）かどうかをテストするための共同教育ゲームを開発します。 &quot;）は、教師と学習者が知覚的に一致していない場合、抽象的なもの（言語、または「語り」）よりも堅牢です。 
[概要]教師と学習者は、環境の同じ側面を常に経験したり、それに参加したりするわけではありません。さまざまな形式のコミュニケーションの有効性は、共有された知覚状態に依存すると仮定します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: AMR Quality Rating with a Lightweight CNN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_11.html">
      <font color="black">AMR Quality Rating with a Lightweight CNN</font>
    </a>
  </h2>
  <font color="black">これにより、グラフの品質を評価する人間の裁判官を模倣する単純な畳み込みニューラルネットワーク（CNN）を作成できます。抽象的な意味表現（AMR）などの構造化された意味文表現は、さまざまなNLPタスクで役立つ可能性があります。効率的であり、発生するエネルギー消費を削減することが証明されています。 
[要約]この方法は、強力で有用な有用な領域よりも正確に品質を評価できます。したがって、自動解析の品質は大きく異なる可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-25">
        <br><font color="black">2020-05-25</font>
      </time>
    </span>
</section>
<!-- paper0: DialogXL: All-in-One XLNet for Multi-Party Conversation Emotion
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_12.html">
      <font color="black">DialogXL: All-in-One XLNet for Multi-Party Conversation Emotion
  Recognition</font>
    </a>
  </h2>
  <font color="black">次に、XLNetのバニラ自己注意の代わりにダイアログ認識自己注意を導入して、スピーカー内およびスピーカー間の有用な依存関係をキャプチャします。アブレーション研究やエラー分析などの他のいくつかの実験も実施され、結果はDialogXLの重要なモジュールの役割。具体的には、会話データをより適切にモデル化するために、最初にXLNetの繰り返しメカニズムをセグメントレベルから発話レベルに変更します。 
[概要]提案されたモデルは、この問題に対処するために提案されました。dialogxlと呼ばれ、より長い履歴コンテキストを格納するための拡張メモリと、マルチパーティ構造を処理するためのダイアログ認識自己注意を備えています。実験結果は、モデルが優れていることを示していますすべてのデータセットのベースライン</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Multilingual Neural Machine Translation For Low-Resource
  Languages: French-, English- Vietnamese -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_13.html">
      <font color="black">Improving Multilingual Neural Machine Translation For Low-Resource
  Languages: French-, English- Vietnamese</font>
    </a>
  </h2>
  <font color="black">両方の言語ペアのバイリンガルベースラインシステムに対して最大+1.62および+ 2.54BLEUポイントの大幅な改善を示し、研究コミュニティ向けのデータセットをリリースしました。以前の研究では、低リソースの言語ペアが多言語マシンの恩恵を受けることができることが実証されています。多くの言語ペアの共同トレーニングに依存する翻訳（MT）システム。さらに、多言語MTシステムの単言語データを活用して、データの希薄性の問題に対処しながら、合成並列コーパスの量を増やします。 
[概要]新しい研究では、2つの低リソース言語ペアの多言語mtシステムの問題に対処するための2つの簡単な戦略を提案しています。データのスパース性の問題に対処しながら、単一言語データを使用して合成並列コーパスの量を増やします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Guiding Non-Autoregressive Neural Machine Translation Decoding with
  Reordering Information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_14.html">
      <font color="black">Guiding Non-Autoregressive Neural Machine Translation Decoding with
  Reordering Information</font>
    </a>
  </h2>
  <font color="black">この問題に対処するために、デコード手順で並べ替え情報を明示的にモデル化するReorderNATという名前の新しいNATフレームワークを提案します。さらに、提案されたReorderNATで、並べ替え情報を利用してデコード検索スペースを狭める決定論的および非決定論的デコード戦略を紹介します。広く使用されているさまざまなデータセットでの実験結果は、提案されたモデルが既存のNATモデルと比較して優れたパフォーマンスを実現し、大幅な高速化を備えた自動回帰変換モデルと同等の変換品質を実現することを示しています。 
[ABSTRACT]既存のNATモデルには、まだ翻訳品質に大きなギャップがあります。これは、膨大なデコードスペースが原因です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-06">
        <br><font color="black">2019-11-06</font>
      </time>
    </span>
</section>
<!-- paper0: You Are What You Tweet: Profiling Users by Past Tweets to Improve Hate
  Speech Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_15.html">
      <font color="black">You Are What You Tweet: Profiling Users by Past Tweets to Improve Hate
  Speech Detection</font>
    </a>
  </h2>
  <font color="black">アノテーションスキームとプロセスの違い、Twitter APIの制限、データ共有ポリシーによって分析は複雑になりますが、有望な結果はさらに調査するメリットを示唆しています。次に、新しいかどうかをより正確に予測する前に、過去の発言によってユーザーのプロファイリングを調査します。発話はヘイトスピーチを構成します。ヘイトスピーチ検出研究は、追加のコンテキストを利用することなく、純粋にコンテンツベースの方法に主に焦点を合わせてきました。 
[概要] 3つのTwitterヘイトスピーチデータセットを追加のタイムラインデータで補強します。次に、この追加のコンテキストを強力なベースラインモデルに埋め込みます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: R$^2$-Net: Relation of Relation Learning Network for Sentence Semantic
  Matching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_16.html">
      <font color="black">R$^2$-Net: Relation of Relation Learning Network for Sentence Semantic
  Matching</font>
    </a>
  </h2>
  <font color="black">2文のセマンティックマッチングタスクに関する経験的実験は、提案されたモデルの優位性を示しています。ラベルを十分に活用して関係情報をより適切に抽出するために、R2-Netがラベルについてさらに検討するように導くための自己教師あり関係分類タスクを導入します。次に、CNNベースのエンコーダーは、ローカルの観点からキーワードとフレーズ情報をキャプチャするように設計されています。 
[概要]ディープニューラルネットワークが成功したのはこれが初めてです。この問題に対処するために、文のセマンティックマッチングのための関係学習ネットワーク（r2-net）の関係を提案します。cnnベースのエンコーダーはキーワードとフレーズをキャプチャするように設計されていますローカルの観点からの情報。トリプレット損失を使用して、クラス内関係とクラス間関係をより細かく区別します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: A Lightweight Neural Model for Biomedical Entity Linking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_17.html">
      <font color="black">A Lightweight Neural Model for Biomedical Entity Linking</font>
    </a>
  </h2>
  <font color="black">ここでは、BERTモデルのパラメータのごく一部と、はるかに少ないコンピューティングリソースを必要とする、生物医学的エンティティリンキングのための軽量ニューラルメソッドを提案します。最近、BERTベースのメソッドは、単語シーケンスの豊富な表現のために..生物医学エンティティリンキングは、病気や薬などの生物医学的言及を、特定の知識ベースの標準エンティティにマッピングすることを目的としています。 
[概要]同じ医療機関はさまざまな名前を持つことができます。それらは単純な分析レイヤーに基づいており、大量のコンピューティングリソースを必要とします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Learning from the Best: Rationalizing Prediction by Adversarial
  Information Calibration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_18.html">
      <font color="black">Learning from the Best: Rationalizing Prediction by Adversarial
  Information Calibration</font>
    </a>
  </h2>
  <font color="black">最初のモデルは、2番目のモデルのガイドとして使用されます。抽出的根拠の生成に関する以前の作業では、通常、2フェーズモデルを使用します。最も重要な特徴（つまり、根拠）を選択するセレクターと、それに続く予測を行う予測子です。選択された機能のみに基づいています。この作業では、情報キャリブレーション方法を介して予測子からより多くの情報を絞り出すことを提案します。 
[要約]特徴を選択することを学ぶための主な信号は、予測子と地面によって与えられた答えの比較から来ます-真実の答え</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Building and Using Personal Knowledge Graph to Improve Suicidal Ideation
  Detection on Social Media -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_19.html">
      <font color="black">Building and Using Personal Knowledge Graph to Improve Suicidal Ideation
  Detection on Social Media</font>
    </a>
  </h2>
  <font color="black">さらに、個人の自殺念慮に対する主要なリスク要因を明確に推論して確立するために、2層の注意メカニズムを設計します。これらのカテゴリでは、投稿されたテキスト、ストレスレベル、ストレス期間、投稿された画像、および反逆的思考が、自殺念慮の検出に貢献します。データの暗黙性と希薄性により、投稿に基づいて個人の内面の真の意図を発見することは困難です。 
[概要]ソーシャルメディアベースの自殺念慮の検出は、93％以上の精度を達成できます。構築された個人的な知識グラフ、投稿、性格、および経験が上位3つの主要な指標です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Clinical Temporal Relation Extraction with Probabilistic Soft Logic
  Regularization and Global Inference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_20.html">
      <font color="black">Clinical Temporal Relation Extraction with Probabilistic Soft Logic
  Regularization and Global Inference</font>
    </a>
  </h2>
  <font color="black">2つのベンチマークデータセット、I2B2-2012とTB-Denseでの広範な実験は、CTRL-PGが時間的関係抽出のベースライン方法を大幅に上回っていることを示しています。 。医学界では、臨床イベント間の時間的関係を正確に抽出することが着実に必要とされています。 
[要約]ドキュメントレベルで問題に取り組むための新しい方法があります。現在、情報の使用の即時の兆候はありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: What BERT Sees: Cross-Modal Transfer for Visual Question Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_21.html">
      <font color="black">What BERT Sees: Cross-Modal Transfer for Visual Question Generation</font>
    </a>
  </h2>
  <font color="black">さらに、BERTは主にエンコーダーとして設計されているため、タスクの生成の側面には適応が必要です。このペーパーでは、事前トレーニングを回避することにより、BERTの視覚的機能をすぐに評価することに関心があります。補足データ..最近、BERTのマルチモーダルバージョンが開発されました。これは、主にVQAなどの分類タスクに適用される、整列されたテキストデータと画像データの膨大なコーパスに依存する大量の事前トレーニングを使用しています。 
[ABSTRACT]テキスト生成用のbertベースのアーキテクチャであるbert-genは、モノモードまたはマルチモーダル表現を活用できます。提案されたモデルは、2つの確立されたデータセットで最先端技術を大幅に改善します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-25">
        <br><font color="black">2020-02-25</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Training with Fast Gradient Projection Method against
  Synonym Substitution based Text Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_22.html">
      <font color="black">Adversarial Training with Fast Gradient Projection Method against
  Synonym Substitution based Text Attacks</font>
    </a>
  </h2>
  <font color="black">これにより、同義語置換に基づく高速テキスト敵対的攻撃手法（FGPM）を提案します。これは、既存のテキスト攻撃手法の約20倍の速度であり、同様の攻撃パフォーマンスを実現できます。次に、FGPMを敵対的トレーニングと統合します。ロジットペアリング（ATFL）によって強化されたFGPMを使用した敵対的トレーニングと呼ばれるテキスト防御方法を提案します。実験は、ATFLがモデルの堅牢性を大幅に改善し、敵対的例の転送可能性をブロックできることを示しています。 
[概要]字句、文法、意味の制約があるため、段落置換ベースのテキスト攻撃に実装するのは困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-09">
        <br><font color="black">2020-08-09</font>
      </time>
    </span>
</section>
<!-- paper0: Multilingual Evidence Retrieval and Fact Verification to Combat Global
  Disinformation: The Power of Polyglotism -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_23.html">
      <font color="black">Multilingual Evidence Retrieval and Fact Verification to Combat Global
  Disinformation: The Power of Polyglotism</font>
    </a>
  </h2>
  <font color="black">コード、データセット、トレーニング済みモデルを公開時に利用できるようにします。この記事では、この種の最初の取り組みであるグローバルな偽情報と戦うためのステップとして、多言語の証拠の取得と事実の検証について調査します。言語英語-ローマ字データセットは、言語間の伝達学習評価のために作成されます。 
[概要]幻滅する400の混合言語の例がテスト用に作成されています。データセットは言語横断的な転移学習評価用です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Leveraging Transfer Learning for Reliable Intelligence Identification on
  Vietnamese SNSs (ReINTEL) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_24.html">
      <font color="black">Leveraging Transfer Learning for Reliable Intelligence Identification on
  Vietnamese SNSs (ReINTEL)</font>
    </a>
  </h2>
  <font color="black">私たちのチームは、他の参加者と競争力のあるプライベートテストセットのROC-AUCメトリックで0.9378のスコアを達成しました。単一言語と多言語の両方の事前トレーニング済みモデルを活用します。このペーパーでは、信頼性の高いインテリジェンス識別のためのいくつかのトランスベースのアプローチを提案しました。 VLSP2020評価キャンペーンのベトナムのソーシャルネットワークサイトで。 
[概要]チームはrocで0.9378のスコアを達成しました-aucmetric.itは他の参加者と競争力があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-10">
        <br><font color="black">2020-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-type Disentanglement without Adversarial Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_25.html">
      <font color="black">Multi-type Disentanglement without Adversarial Training</font>
    </a>
  </h2>
  <font color="black">潜在空間を解きほぐすことによって自然言語のスタイルを制御することは、解釈可能な機械学習に向けた重要なステップです。この論文では、それぞれの特定のスタイル値（たとえば、ポジティブ感情、または過去形）を独自の表現で..以前の作品は通常、敵対的なトレーニングを使用して、解きほぐされたベクトルが互いに影響を与えないことを保証します。 
[ABSTRACT]潜在空間が解きほぐされると、文のスタイルを変えることができます。しかし、敵対的な方法を訓練することは困難です。しばしば、敵対的な方法を採用することは困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring Thematic Coherence in Fake News -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_26.html">
      <font color="black">Exploring Thematic Coherence in Fake News</font>
    </a>
  </h2>
  <font color="black">フェイクニュースの拡散は依然として深刻な世界的問題です。この調査では、トピックモデルを使用して、オンラインで共有されるクロスドメインニュースの一貫性を分析します。7つのクロスドメインデータセットでの実験結果は、フェイクニュースが冒頭の文の間で主題の偏差が大きいことを示しています。そしてその残り。 
[要約] 7つのクロスドメインデータセットは、フェイクニュースがその冒頭の文とその残りの間のより大きな空間的偏差を示していることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Do Response Selection Models Really Know What's Next? Utterance
  Manipulation Strategies for Multi-turn Response Selection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_27.html">
      <font color="black">Do Response Selection Models Really Know What's Next? Utterance
  Manipulation Strategies for Multi-turn Response Selection</font>
    </a>
  </h2>
  <font color="black">複数の言語とモデルにわたる広範な評価は、UMSがダイアログの一貫性を教えるのに非常に効果的であることを示しています。これにより、モデルは複数の公開ベンチマークデータセットに大きなマージンを持って最先端を推進します。最近、事前にトレーニングされた言語モデル（例： 、BERT、RoBERTa、およびELECTRA）は、さまざまな自然言語処理タスクで大幅な改善を示しました。この目的のために、この問題に対処するための発話操作戦略（UMS）を提案します。 
[概要]このようにトレーニングされた言語モデルは、歴史と候補者の関連性に基づいて予測を行う傾向があることを観察しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Focusing More on Conflicts with Mis-Predictions Helps Language
  Pre-Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/cs.CL/paper_28.html">
      <font color="black">Focusing More on Conflicts with Mis-Predictions Helps Language
  Pre-Training</font>
    </a>
  </h2>
  <font color="black">この作業では、事前トレーニング中の誤予測の助けを借りて、言語事前トレーニング方法の有効性を改善することを提案します。この目的に向けて、誤予測のコンテキスト（McMisP）に焦点を当てないことを紹介します。事前トレーニング中の誤予測は、モデルの不適切な焦点の検出器として機能する可能性があるという仮説を立てます。 
[ABSTRACT] mis-予測をより簡単に修正でき、モデル全体をより適切にトレーニングできます。トレーニングでは、単語間の共起情報を記録して、mis-予測との競合する単語を検出します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: A Synergistic Kalman- and Deep Postfiltering Approach to Acoustic Echo
  Cancellation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-17/eess.AS/paper_0.html">
      <font color="black">A Synergistic Kalman- and Deep Postfiltering Approach to Acoustic Echo
  Cancellation</font>
    </a>
  </h2>
  <font color="black">提案された相乗的スキームは、静的シナリオでの最先端のアプローチによって達成される定常状態のパフォーマンスを損なうことなく、突然のエコーパスの変化後に適応フィルターの迅速な再収束を可能にします。ダブルトークロバスト音響エコーへの相乗的アプローチを紹介します。適応カルマンフィルタリングとディープニューラルネットワークベースのポストフィルターを組み合わせたキャンセル。提案されたアルゴリズムは、急激なエコーパスの変化を特徴とするシナリオでのカルマンフィルターベースの適応制御のよく知られた制限を克服します。 
[要約]提案されたアルゴリズムは、カルマンフィルターベースの適応制御のよく知られた制限を克服します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-16">
        <br><font color="black">2020-12-16</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
