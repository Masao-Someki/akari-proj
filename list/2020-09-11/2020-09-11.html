<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-09-11の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: ICASSP 2021 Acoustic Echo Cancellation Challenge: Datasets and Testing
  Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.SD/paper_0.html">
      <font color="black">ICASSP 2021 Acoustic Echo Cancellation Challenge: Datasets and Testing
  Framework</font>
    </a>
  </h2>
  <font color="black">この課題では、シングルトークとダブルトークの両方のシナリオでAECモデルをトレーニングするために、2つの大きなデータセットをオープンソースにします。これらのデータセットは、実際の環境での2,500以上のリアルオーディオデバイスとヒューマンスピーカーからの録音、および合成データセットで構成されます。 。私たちは、ITU-T P.808に基づくオンラインの主観的テストフレームワークをオープンソース化し、研究者が結果をすばやくテストできるようにしています。 
[ABSTRACT]最近の多くのaec調査では、合成データセットで妥当なパフォーマンスが報告されています。ただし、従来の客観的な指標のほとんどは、主観的な音声品質テストと十分に相関していません。環境</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Subword RNNLM Approximations for Out-Of-Vocabulary Keyword Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.SD/paper_1.html">
      <font color="black">Subword RNNLM Approximations for Out-Of-Vocabulary Keyword Search</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、従来のn-gramモデルとRNNLM近似を補間してOOV認識を改善することを提案します。これを解決する1つの方法は、バックオフn-gramモデルでRNNLMを近似することです。RecurrentNeural Network（RNN） LMはスパース性の問題を軽減しますが、最初のパスの認識自体には適していません。 
[ABSTRACT]初回パス認識でサブワード言語モデル（lms）を使用すると、oovワードを認識できます。ただし、サブワードn-gram lmsでもデータのスパース性に悩まされています。このような新しい方法は、サブワード認識用に開発されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br><font color="black">2020-05-28</font>
      </time>
    </span>
</section>
<!-- paper0: Exploration of End-to-end Synthesisers forZero Resource Speech Challenge
  2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.SD/paper_2.html">
      <font color="black">Exploration of End-to-end Synthesisers forZero Resource Speech Challenge
  2020</font>
    </a>
  </h2>
  <font color="black">Zerospeech 2020チャレンジで提案されたシステムの評価は、非常に高品質の合成が達成できることを示しています。4つの異なるシステムが提案されています。この作業の主な目的は、ゼロリソースTTSシステムの合成品質を改善することです。 
[ABSTRACT]音声は、過渡状態と定常状態の音響単位のシーケンスとしてモデル化されます。固有の音響単位のセットが反復トレーニングによって発見されます。これらの変更には、音声データのマッピングのトレーニングが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Real-time Plant Health Assessment Via Implementing Cloud-based Scalable
  Transfer Learning On AWS DeepLens -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/eess.IV/paper_0.html">
      <font color="black">Real-time Plant Health Assessment Via Implementing Cloud-based Scalable
  Transfer Learning On AWS DeepLens</font>
    </a>
  </h2>
  <font color="black">私たちが提案するDeepLens分類および検出モデル（DCDM）アプローチは、AWS SageMakerのスケーラブルな転送学習を介して、果物（リンゴ、ブドウ、桃、イチゴ）および野菜（ジャガイモ、トマト）の葉の病気の自動検出および分類を導入することで、このような制限に対処しますAWSのディープレンズにインポートして、リアルタイムの実用的な使いやすさを実現します。クラウド統合により、スケーラビリティとアプローチへのユビキタスなアクセスが実現します。ディープラーニングモデルのトレーニングに4万枚の画像を使用し、1万枚の画像で評価しました。 
[要約]提案されたディープレンズ分類および検出モデル（dcdm）アプローチは、限られた制限に対処します。拡張可能な転送を介して、果物（リンゴ、ブドウ、桃、イチゴ）および野菜（ジャガイモ、トマト）における葉の病気の自動検出および分類を提供します学習する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-09">
        <br><font color="black">2020-09-09</font>
      </time>
    </span>
</section>
<!-- paper0: Curvature Regularized Surface Reconstruction from Point Cloud -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/eess.IV/paper_1.html">
      <font color="black">Curvature Regularized Surface Reconstruction from Point Cloud</font>
    </a>
  </h2>
  <font color="black">これは、元の高次PDEを、半陰解法によって解かれる分離PDEシステムで置き換えます。最小化関数は、点群からの距離関数と平均曲率項のバランスをとります。また、拡張されたラグランジュ法。 
[要約]最小化機能は、点群から平均曲率項までの距離関数のバランスをとります。これは、元の高次pdesを分離されたpdeシステムで置き換えます。提案された方法は、アルゴリズムに対する堅牢性を示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br><font color="black">2020-01-22</font>
      </time>
    </span>
</section>
<!-- paper0: Hard Occlusions in Visual Object Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/eess.IV/paper_2.html">
      <font color="black">Hard Occlusions in Visual Object Tracking</font>
    </a>
  </h2>
  <font color="black">トラッカーを現実のシナリオに近づけ、安全性が重要なデバイスに展開するには、非常にまれなハードシナリオでも適切に対処する必要があります。ハードオクルージョン内のさまざまなカテゴリを含む小規模なデータセットを作成しました。このホワイトペーパーでは、特にハードオクルージョンのケースに焦点を当て、最近の最先端のトラッカー（SOTA）のパフォーマンスをベンチマークします。 
[ABSTRACT]トラッキングデータセットはvot2019とlasot.datasetsのデータセットによって作成され、パフォーマンスがハードオクルージョンのさまざまなカテゴリ間で大きく異なることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Domain Adaptation via CycleGAN for White Matter
  Hyperintensity Segmentation in Multicenter MR Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/eess.IV/paper_3.html">
      <font color="black">Unsupervised Domain Adaptation via CycleGAN for White Matter
  Hyperintensity Segmentation in Multicenter MR Images</font>
    </a>
  </h2>
  <font color="black">この作業では、脳の病変を含む多施設MR画像で教師なしドメイン適応を実行するために、サイクルコンシステントな敵対的ネットワーク（CycleGAN）の使用を調査します。実験により、CycleGANにより、MRドメイン間のJensen-Shannon発散を低減し、MRドメイン間のラベル付きデータが利用できなかったドメインでのCNNモデルによる自動セグメンテーション。このような分布が変更されても同じタスクの実行を目的とする場合、ドメイン適応問題が発生します（例：
[ABSTRACT]トレーニングとテストデータセット間のデータ分布が残っている場合）変更されていません。ボリュームイメージを変換するマッピング関数を学習することを目指しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Fully automated analysis of muscle architecture from B-mode ultrasound
  images with deep learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/eess.IV/paper_4.html">
      <font color="black">Fully automated analysis of muscle architecture from B-mode ultrasound
  images with deep learning</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、表面および深部腱膜の位置、および画像ごとの複数の束状断片を検出します。この方法は完全に自動化されたオープンソースであり、単一の画像またはビデオから束の長さ、ペナン角度、および筋肉の厚さを推定することもできます。複数の浅筋からのように..方法間のペニング角度の違いは1 $ ^ \ circ $以内で、筋肉の厚さの平均の違いは0.2 mm未満でした。 
[ABSTRACT]この研究は、ディープニューラルネットワーク（u-netに基づく）によって行われました。筋骨格の超音波画像のセットを使用して筋束と腱膜を検出するようにトレーニングされています。この方法では、トレーニング不可能な自動化された方法と同様の結果が得られました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Shape Features and Abstractions in 3D Convolutional Neural
  Networks for Detecting Alzheimer's Disease -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/eess.IV/paper_5.html">
      <font color="black">Learning Shape Features and Abstractions in 3D Convolutional Neural
  Networks for Detecting Alzheimer's Disease</font>
    </a>
  </h2>
  <font color="black">この論文では、アルツハイマー病を検出するための3D ConvNetによって学習された形状の特徴と抽象化が、さまざまな視覚化手法を使用して調査されました。最後に、畳み込みオートエンコーダからの転移学習を実装して、入力のパッチでトレーニングサンプルの数を増やし、低レベルの機能は、学習された機能とモデルのパフォーマンスを向上させます。優れたパフォーマンスを提供する能力があるにもかかわらず、モデルの決定の解釈ができないと誤診につながり、生命を脅かす可能性があります。 
[要約] convnetは、医療データを分析して効率的な方法で疾患を診断する医療分野での可能性を秘めています。モデルの決定を理解しなければ、生命を脅かす可能性のある誤診につながる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Ultrasound Liver Fibrosis Diagnosis using Multi-indicator guided Deep
  Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/eess.IV/paper_6.html">
      <font color="black">Ultrasound Liver Fibrosis Diagnosis using Multi-indicator guided Deep
  Neural Networks</font>
    </a>
  </h2>
  <font color="black">これは、臨床診断のワークフローに従い、予測手順を解釈可能にします。実験結果に示されているように、提案されたモデルは、最先端のパフォーマンスを達成することによってその有効性を示しています。具体的には、精度は65.6％（20％提案されたモデルのトレーニングを容易にするために、指標に基づく学習メカニズムがさらに提案されています。 
[要約]研究は229人の患者のデータセットを分析することによって行われました。これらには、患者の超音波ビデオ、画像、インジケーター、ラベルが含まれていました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal Noisy Segmentation based fragmented burn scars identification
  in Amazon Rainforest -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/eess.IV/paper_7.html">
      <font color="black">Multimodal Noisy Segmentation based fragmented burn scars identification
  in Amazon Rainforest</font>
    </a>
  </h2>
  <font color="black">提案されたフレームワークは、積み重ねられたRGB-NIRチャネルを利用して、Amazoniaからの新しい弱くラベル付けされたノイズの多いデータセットでトレーニングすることにより、牧草地から火傷をセグメント化します。この作業では、AmazonNETを紹介します。これは、マルチモーダルリモートセンシング画像から書き込みパターンを抽出できる畳み込みベースのネットワークです。 
[要旨] amazonのamazonベースのエンコーダネットワークは、マルチモーダル火傷の識別でよく知られています。ネットワークは、生物医学的セグメンテーションで一般的に使用されるスキップ接続を使用する、よく知られているエンコーダネットワークであるunetで構成されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Facial Matching by Spiral Convolutional Metric Learning and a
  Biometric Fusion-Net of Demographic Properties -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/eess.IV/paper_8.html">
      <font color="black">3D Facial Matching by Spiral Convolutional Metric Learning and a
  Biometric Fusion-Net of Demographic Properties</font>
    </a>
  </h2>
  <font color="black">最初のステップは、関心のあるプロパティに関する情報を保持しながら、顔の形状を低次元の埋め込みに圧縮するトリプレット損失ベースのメトリック学習器で構成されます。埋め込みは入力として受け入れられるため、さまざまなプロパティの分類器をトレーニングする必要はありません。そして、利用可能なデータをより効率的に使用することができます。この作業では、幾何学的深層学習を使用して、3D顔面メッシュから直接学習します。 
[ABSTRACT]ネットワークは入力として埋め込みとプロパティラベルの組み合わせを取り、正規のスコアと偽のスコアを返します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: A leak in PRNU based source identification? Questioning fingerprint
  uniqueness -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/eess.IV/paper_9.html">
      <font color="black">A leak in PRNU based source identification? Questioning fingerprint
  uniqueness</font>
    </a>
  </h2>
  <font color="black">この目的のために、最も関連性の高いブランドを構成する最近のスマートフォンモデル$ 54 $から$ 240000 $以上の画像ペアをテストしました。実験により、Samsung、Xiaomi、Huaweiの多くのデバイスがこの問題の影響を強く受けていることがわかりました。制御された環境下で、Flickr画像に対して大規模なテストキャンペーンを実行し、問題がどれほど広範であり、どれが原因であるかを判断します。 
[要約]この問題に対するカメラメーカーの対応は新しいペーパーでテストされています。多くのsamsung、xiaomi、およびhuaweiデバイスがこの問題の影響を強く受けていることが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: MedMeshCNN -- Enabling MeshCNN for Medical Surface Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/eess.IV/paper_10.html">
      <font color="black">MedMeshCNN -- Enabling MeshCNN for Medical Surface Models</font>
    </a>
  </h2>
  <font color="black">病理学的所見から派生する不均衡なクラス分布はMedMeshCNNによって考慮され、患者固有のプロパティはセグメンテーションプロセス中にほとんど保持されます。背景と目的：MeshCNNは最近提案されたディープラーニングフレームワークで、不規則なものに対する直接操作のため注意を引きました。不均一な3Dメッシュ..病理学的動脈瘤は71.4 \％のユニオン上の交差でセグメント化されています。 
[ABSTRACT] meshcnnは、分類およびセグメンテーションタスク内で最先端の方法を上回りましたが、いくつかの制限により、非常に多様な医療表面モデルでのmeshcnnの卓越したパフォーマンスが妨げられています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting the Presence of Vehicles and Equipment in SAR Imagery Using
  Image Texture Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/eess.IV/paper_11.html">
      <font color="black">Detecting the Presence of Vehicles and Equipment in SAR Imagery Using
  Image Texture Features</font>
    </a>
  </h2>
  <font color="black">探索的データセットを使用して、サポートベクターマシン（SVM）、ランダムバイナリフォレスト、および分類用の完全に接続されたニューラルネットワークをトレーニングしました。解像度には制限がありますが、私たちの方法論では活動レベルを監視できます（つまり、各分類子は2つの可能なタイプの建設現場の活動レベルを区別できるという有望な結果。
[ABSTRACT]このペーパーでは、石油とガスのフラッキングウェルの建設プロセスの監視を中心としたケーススタディを文書化しています。vvではハラリックテクスチャ機能を使用しています。分類子への入力機能としてのvh偏波チャネル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Annotation of Seismic Images using Latent Space
  Factorization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/eess.IV/paper_12.html">
      <font color="black">Self-Supervised Annotation of Seismic Images using Latent Space
  Factorization</font>
    </a>
  </h2>
  <font color="black">私たちのフレームワークは、潜在的な空間を学習されたサブスペースに投影することにより、深いエンコーダー/デコーダーネットワークの潜在的な空間を因数分解します。このホワイトペーパーでは、地震レベルのピクセルに注釈を自動化して、画像レベルの地質構造要素を描写するフレームワークを開発します。各画像に割り当てられたラベル..ピクセル空間の制約を使用して、地震画像はさらに分解され、対象の地質学的要素に関連付けられたピクセルの信頼値を明らかにします。 
[ABSTRACT]科学者は、地震画像のピクセル数を自動化して地質構造要素を描写するフレームワークを開発しています。地震画像はさらに、対象の地質要素に関連付けられたピクセルの信頼値を明らかにするために因数分解されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Centering noisy images with application to cryo-EM -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/eess.IV/paper_13.html">
      <font color="black">Centering noisy images with application to cryo-EM</font>
    </a>
  </h2>
  <font color="black">私たちの方法の1つの特定のアプリケーションは、単一粒子低温電子顕微鏡法（クライオEM）での3D再構成を改善することです。実験データから選択された高分子のより良い並進整列のために私たちのアプローチを適用する方法を示します。方法は、再構築の後続ステップを促進し、クライオEMパイプライン全体を合理化して、貴重な計算時間を節約し、解像度の向上をサポートします。 
[要約]実験データから選択された高分子のより良い並進整列のために私たちのアプローチを適用する方法を説明します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Self-supervised Depth Denoising Using Lower- and Higher-quality RGB-D
  sensors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_0.html">
      <font color="black">Self-supervised Depth Denoising Using Lower- and Higher-quality RGB-D
  sensors</font>
    </a>
  </h2>
  <font color="black">次に、ディープニューラルネットワークを学習し、対応する高品質のデータを監視信号のソースとして使用して、低品質の深度をノイズ除去します。モバイルデバイスに組み込まれた消費者レベルの深度カメラと深度センサーは、ARゲームや顔の識別..この論文では、低品質のセンサーからの深度をノイズ除去し、改善するための自己管理型深度ノイズ除去アプローチを提案します。 
[要約]キャプチャされた深度の品質が、3D再構成、追跡、その他のコンピュータビジョンタスクには不十分な場合があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: OrthoReg: Robust Network Pruning Using Orthonormality Regularization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_1.html">
      <font color="black">OrthoReg: Robust Network Pruning Using Orthonormality Regularization</font>
    </a>
  </h2>
  <font color="black">フィルターのグループのプルーニングがネットワークの精度に与える影響を判断するために、最先端のプルーニング手法では、CNNのフィルターが常に独立していると想定しています。この問題に対処するために、正規直交化を実施する原則的な正則化戦略であるOrthoRegを提案します。ネットワークのフィルター上でフィルター間相関を低減し、それによってグループ重要度推定の信頼できる効率的な決定、プルーニングされたネットワークの改善されたトレーニング、およびフィルターの大きなグループの効率的な同時プルーニングを可能にします。VGG-13で反復プルーニングに使用される場合、 MobileNet-V1とResNet-34のOrthoRegは、CIFAR-100とTiny-ImageNetの最先端技術を含む5つのベースラインテクニックよりも常に優れています。 
[要約]プルーニングは、ネットワークの精度の影響を判断するために使用できます。これは、最新のネットワークでの過剰パラメーター化により、仮定が無効になる非常に相関性の高いフィルターになり、結果として重要度の推定が不正確になるためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: MAT: Motion-Aware Multi-Object Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_2.html">
      <font color="black">MAT: Motion-Aware Multi-Object Tracking</font>
    </a>
  </h2>
  <font color="black">剛体カメラモーションと非剛体歩行者モーションは、互換性のある方法でブレンドされ、統合されたモーションローカリゼーションモジュールを形成します。一方、動的再接続コンテキストモジュールを導入します。これは、長距離モーションベースの再接続の堅牢性のバランスを目的とし、周期的な疑似を含みます閉塞またはぼやけによって引き起こされる追跡フラグメントをスムーズに埋めるための観察更新戦略。再識別がしばしば使用されますが、ノイズのある部分検出、同様の外観、および時間空間的制約がないため、信頼性が低いだけでなく、時間はかかりますが、隠れたオブジェクトやぼやけたオブジェクトの偽陰性には対処できません。 
[ABSTRACT]モーションセンシングトラッカー（マット）は、さまざまなオブジェクトのさまざまなモーションパターンにさらに焦点を当てることを目的としています。モーション-アウェアトラッカー（et）は、さまざまなモーションパターンにさらに焦点を当てています。モーションセンシティブシステムは、トラックレットの純度を確保するためにも使用できます。特に小さなオブジェクトの場合</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: DiVA: Diverse Visual Feature Aggregation for Deep Metric Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_3.html">
      <font color="black">DiVA: Diverse Visual Feature Aggregation for Deep Metric Learning</font>
    </a>
  </h2>
  <font color="black">ただし、効果的な一般化のために、このような画像表現はさまざまなデータ特性をキャプチャする必要があります。このために、利用可能なトレーニングサンプルとラベルを使用するだけで、概念的に異なるデータ関係を対象とした複数の補完的な学習タスクを提案および調査します。標準のDML設定。視覚的類似性は、多くのコンピュータビジョンアプリケーションで重要な役割を果たします。 
[要約]ディープメトリック学習（dml）は、そのような類似性を学習するための強力なフレームワークです。トレーニングデータから、同じように分散されたテストクラスまで学習できます。特に、このような画像表現は、さまざまな範囲のデータ特性をキャプチャする必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br><font color="black">2020-04-28</font>
      </time>
    </span>
</section>
<!-- paper0: Constraining Implicit Space with Minimum Description Length: An
  Unsupervised Attention Mechanism across Neural Network Layers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_4.html">
      <font color="black">Constraining Implicit Space with Minimum Description Length: An
  Unsupervised Attention Mechanism across Neural Network Layers</font>
    </a>
  </h2>
  <font color="black">最後に、UAMは、レイヤー全体の依存関係と重要な学習段階、およびディープネットワークの反復的な時間ステップを追跡します。ニューラルネットワークレイヤー全体でこのユニバーサルコードを段階的に計算し、トップダウンの注意やその他のオラクル情報などのデータの事前情報を含める柔軟性を示しました。経験的に、私たちのアプローチは、画像分類、クラシック制御、手続き型生成強化学習、生成モデリング、手書き生成、およびさまざまなニューラルネットワークアーキテクチャによる質問応答タスクにおいて、既存の正規化手法よりも優れており、限定的で不均衡な非定常入力分布に取り組んでいます。 
[ABSTRACT]不均衡な非定常データは、さまざまなタイプの改善に示されています。システムは、システムへの変更のパターンに基づいています。これらには、正規化係数、ユニバーサルコード長が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-02-27">
        <br><font color="black">2019-02-27</font>
      </time>
    </span>
</section>
<!-- paper0: Real-time Plant Health Assessment Via Implementing Cloud-based Scalable
  Transfer Learning On AWS DeepLens -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_5.html">
      <font color="black">Real-time Plant Health Assessment Via Implementing Cloud-based Scalable
  Transfer Learning On AWS DeepLens</font>
    </a>
  </h2>
  <font color="black">クラウド統合は、スケーラビリティと私たちのアプローチへのユビキタスアクセスを提供します。したがって、初期の植物の葉病の自動識別と分類は、経済的損失を削減し、特定の種を保護するために不可欠です。 AWS SageMakerでスケーラブルな転送学習を介して果物（リンゴ、ブドウ、桃、イチゴ）と野菜（ジャガイモ、トマト）の葉の病気の自動検出と分類を導入し、AWS DeepLensにリアルタイムでインポートすることで、このような制限に対処するアプローチ実用性。 
[要約]提案されたディープレンズ分類および検出モデル（dcdm）アプローチは、限られた制限に対処します。拡張可能な転送を介して、果物（リンゴ、ブドウ、桃、イチゴ）および野菜（ジャガイモ、トマト）における葉の病気の自動検出および分類を提供します学習する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-09">
        <br><font color="black">2020-09-09</font>
      </time>
    </span>
</section>
<!-- paper0: Curvature Regularized Surface Reconstruction from Point Cloud -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_6.html">
      <font color="black">Curvature Regularized Surface Reconstruction from Point Cloud</font>
    </a>
  </h2>
  <font color="black">曲率制約が追加されると、計算は特に困難になります。元の高次PDEは、半陰解法によって解かれる分離PDEシステムに置き換えられます。ローカルの法線や各ポイントでの曲率推定。 
[要約]最小化機能は、点群から平均曲率項までの距離関数のバランスをとります。これは、元の高次pdesを分離されたpdeシステムで置き換えます。提案された方法は、アルゴリズムに対する堅牢性を示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-22">
        <br><font color="black">2020-01-22</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding the Role of Individual Units in a Deep Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_7.html">
      <font color="black">Understanding the Role of Individual Units in a Deep Neural Network</font>
    </a>
  </h2>
  <font color="black">ユニットの小さなセットがアクティブ化または非アクティブ化されたときに加えられた変更を分析することにより、コンテキストに適応しながらオブジェクトを出力シーンに追加および削除できることがわかります。最後に、分析フレームワークを適用して敵対的攻撃を理解し、セマンティックイメージ編集を行います..次に、同様の分析方法を使用して、シーンを生成するようにトレーニングされた生成的敵対的ネットワーク（GAN）モデルを分析します。 
[ABSTRACT]シーン分類でトレーニングされた畳み込みニューラルネットワークを分析します。オブジェクトのさまざまな概念に一致するユニットを発見します。同様の分析方法を使用して、シーンを生成するようトレーニングされた割り当てシステムを分析します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Improved Robustness to Open Set Inputs via Tempered Mixup -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_8.html">
      <font color="black">Improved Robustness to Open Set Inputs via Tempered Mixup</font>
    </a>
  </h2>
  <font color="black">ここでは、既存の畳み込みニューラルネットワークアーキテクチャに簡単に適用できる単純な正則化手法を提案します。これにより、バックグラウンドデータセットなしでオープンセットの堅牢性が向上します。この手法は、オープンセット分類ベースラインで最先端の結果を達成し、簡単に大規模にスケーリングします。オープンセット分類の問題。既存のアプローチは、新しい推論方法、独自のトレーニングアーキテクチャ、または追加のバックグラウンドサンプルでトレーニングデータを補足することに重点を置いています。 
[ABSTRACT]実際のクラスの評価は未知のクラスを処理する必要があります。既存のアプローチは、新しい可能性のある方法、独自のトレーニングアーキテクチャ、または追加のバックグラウンドサンプルでトレーニングデータを補足することに焦点を当てています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Proposal-Free Volumetric Instance Segmentation from Latent
  Single-Instance Masks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_9.html">
      <font color="black">Proposal-Free Volumetric Instance Segmentation from Latent
  Single-Instance Masks</font>
    </a>
  </h2>
  <font color="black">私たちは、競合するスコアを達成する挑戦的なCREMI 2016ニューロンセグメンテーションベンチマークでメソッドをテストします。すべてのマスクは、低次元の潜在表現からデコードされます。これにより、大容量画像へのアプリケーションに厳密に必要な大幅なメモリ節約が実現します。この作業により、スライドウィンドウスタイルで画像全体に予測された単一インスタンスのセグメンテーションマスクに基づいて構築された、新しい提案のないインスタンスセグメンテーションメソッド。 
[要旨]私たちの方法は、各ピクセルに1つずつ、すべてのマスクを同時に予測します。そのため、画像全体ですべての競合を共同で解決します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Long Range Stereo Matching by Learning Depth and Disparity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_10.html">
      <font color="black">Long Range Stereo Matching by Learning Depth and Disparity</font>
    </a>
  </h2>
  <font color="black">特に、私たちの結果は、提案された損失関数が50メートルを超える距離にあるオブジェクトの深度と視差の推定に非常に効果的であることを示しています。には2つのコンポーネントがあります：損失は深度ベースで、前景ピクセルと背景ピクセルの2つの異なる部分があります。また、人気のあるKITTI 2015ステレオデータセットと一般的に使用されるスムーズL1損失関数の両方にバイアスが存在することも示します。 
[ABSTRACT]損失は深度に基づいており、前景ピクセルと背景ピクセルの2つの異なる部分があります。効果的な方法は、一連の広範な実験によって示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Hard Occlusions in Visual Object Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_11.html">
      <font color="black">Hard Occlusions in Visual Object Tracking</font>
    </a>
  </h2>
  <font color="black">トラッカーを現実のシナリオに近づけ、安全性が重要なデバイスに展開するには、非常にまれなハードシナリオでも適切に対処する必要があります。ビジュアルオブジェクトトラッキングは、コンピュータービジョンで最も困難な問題の1つです。とりわけ、照明の変化、高速モーション、オクルージョンなどの困難な状況。このホワイトペーパーでは、特にハードオクルージョンのケースに焦点を当て、最近の最先端のトラッカー（SOTA）のパフォーマンスをベンチマークします。 
[ABSTRACT]トラッキングデータセットはvot2019とlasot.datasetsのデータセットによって作成され、パフォーマンスがハードオクルージョンのさまざまなカテゴリ間で大きく異なることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Channel Pruning via Optimal Thresholding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_12.html">
      <font color="black">Channel Pruning via Optimal Thresholding</font>
    </a>
  </h2>
  <font color="black">OTを使用することで、パフォーマンスの低下を最小限に抑えながら、スパース性を達成するために、無視できるか重要でないチャネルがほとんど排除されます。最も重要な重みが保持されるため、排除されたモデルをさらに微調整し、非常に少ない反復ですばやく収束できます。事前定義されたグローバルしきい値ベースの設計では、さまざまなレイヤーと重みの分布の違いを無視するため、過剰剪定または剪定不足が原因でパフォーマンスが最適とはいえないことがよくあります。 
[要約]このホワイトペーパーでは、重要なチャネルを無視できるチャネルから最適に分離する、レイヤーに依存するしきい値を使用してチャネルをプルーニングするシンプルで効果的な方法を紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-10">
        <br><font color="black">2020-03-10</font>
      </time>
    </span>
</section>
<!-- paper0: Orientation Keypoints for 6D Human Pose Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_13.html">
      <font color="black">Orientation Keypoints for 6D Human Pose Estimation</font>
    </a>
  </h2>
  <font color="black">このメソッドは、主要なデータセットでMPJPEによって測定された現在の最先端の関節位置の結果を14 \％改善し、一般的なデータセットに一般化します。ビデオはhttps：//で入手できます。 youtu.be/1EBUrfu_CaE。回転予測は、報告された関節角度の平均誤差を48 \％改善し、15の骨の回転にわたって93 \％の精度を達成します。 
[要約]検出された関節位置を使用して、手足のヤジとピッチを計算できます。位置位置の位置と手の回転を測定できます。位置は、関節角度の48％の最良の平均誤差に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Domain Adaptation via CycleGAN for White Matter
  Hyperintensity Segmentation in Multicenter MR Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_14.html">
      <font color="black">Unsupervised Domain Adaptation via CycleGAN for White Matter
  Hyperintensity Segmentation in Multicenter MR Images</font>
    </a>
  </h2>
  <font color="black">そのような分布が変化しても、同じタスクを実行することを目的とする場合、ドメイン適応問題が発生します（たとえば、私たちの実験では、CycleGANにより、MRドメイン間のJensen-Shannon発散を低減し、ドメインのCNNモデルで自動セグメンテーションを有効にできることが示されていますこの作業では、脳の病変がある多施設のMR画像で教師なしドメイン適応を実行するために、サイクルコンシステントな敵対的ネットワーク（CycleGAN）の使用を調査します。
[要約]トレーニングデータセットとテストデータセット間のデータ分布が残っている場合変更されていません。ボリュームイメージを変換するマッピング関数を学習することを目指しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Fully automated analysis of muscle architecture from B-mode ultrasound
  images with deep learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_15.html">
      <font color="black">Fully automated analysis of muscle architecture from B-mode ultrasound
  images with deep learning</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、表面および深部腱膜の位置、および画像ごとの複数の束断片を検出します。次に、新しい見えない画像のニューラルネットワーク予測を、手動分析と2つの既存の半自動分析アプローチ（SMAおよびUltratrack）。GPUを使用した場合、CPUを使用した4.6秒と比較して、新しいアプローチを使用した単一の画像の推定時間は約0.7秒でした。 
[ABSTRACT]この研究は、ディープニューラルネットワーク（u-netに基づく）によって行われました。筋骨格の超音波画像のセットを使用して筋束と腱膜を検出するようにトレーニングされています。この方法では、トレーニング不可能な自動化された方法と同様の結果が得られました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Part Discovery by Unsupervised Disentanglement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_16.html">
      <font color="black">Unsupervised Part Discovery by Unsupervised Disentanglement</font>
    </a>
  </h2>
  <font color="black">実験では、私たちのアプローチを以前の最先端のアプローチと比較し、セグメンテーションの精度と形状の一貫性の大幅な向上を観察します。場所とセマンティクスの両方を捉えることで、教師あり学習アプローチの魅力的なターゲットとなります。私たちのアプローチは、オブジェクトの形状と外観の2つの絡み合っていない表現と、パーツセグメンテーションの潜在変数で構成される生成モデル。 
[ABSTRACT]教師なしのアプローチは、最終的な表現への監督により洗練される抽象表現の学習に焦点を当てています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-09">
        <br><font color="black">2020-09-09</font>
      </time>
    </span>
</section>
<!-- paper0: QuantNet: Learning to Quantize by Learning within Fully Differentiable
  Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_17.html">
      <font color="black">QuantNet: Learning to Quantize by Learning within Fully Differentiable
  Framework</font>
    </a>
  </h2>
  <font color="black">CIFAR-100とImageNetの定量的実験は、QuantNetが以前の2値化方法と比較して大幅な改善を達成し、2値化モデルと完全精度モデル間の精度のギャップを埋めることさえ実証しています。この手法は、勾配の不一致の問題を解決するだけでなく、また、展開における2値化操作によって引き起こされる離散化エラーがパフォーマンスに与える影響も低減します。バイナリーニューラルネットワーク（BNN）のパフォーマンス低下を低減する最近の2値化手法の成果にもかかわらず、ストレートスルーによる勾配不整合Estimator（STE）は依然として量子化ネットワークを支配しています。 
[要約] quantnetと呼ばれる新しいシステムは、微分可能なサブネットワークを使用して、steおよび学習可能な問題システムに頼ることなく、完全な精度の重みを2値化します。提案されたアルゴリズムは、通常、完全に微分可能なフレームワーク内に実装され、簡単にサブ解釈されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Virtual Image Correlation uncertainty -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_18.html">
      <font color="black">Virtual Image Correlation uncertainty</font>
    </a>
  </h2>
  <font color="black">仮想画像の幅の最適値、メソッドの唯一のパラメータ、最適な数値設定が確立されます。ユーザーが選択した曲線の関連性を評価して、サブピクセル精度で輪郭を記述するための推定量が提案されます。新しい定式化により、この方法は1Dで正確であり、局所的な曲率やコントラストの変化に影響されないこと、および輝度の変化によって引き起こされるバイアスを簡単に修正できることがわかります。 
[ABSTRACT]対象の画像と、パラメータ化された曲線に基づく仮想画像との相関で構成されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Globally-scalable Automated Target Recognition (GATR) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_19.html">
      <font color="black">Globally-scalable Automated Target Recognition (GATR)</font>
    </a>
  </h2>
  <font color="black">GATR（グローバルにスケーラブルな自動ターゲット認識）は、ロッキードマーティンのソフトウェアシステムで、世界中の衛星画像でリアルタイムにオブジェクトを検出して分類します。GATRは、自動車や船などの新しいターゲットにも拡張可能で、レーダーも処理します。赤外線画像..単一のGPUで16平方km /秒（または10メガピクセル/秒以上）の速度で画像を処理し、ペンシルベニア州全体でガスフラッキングウェルを検索するのに2時間しかかかりません。 
[ABSTRACT] gatrはgpuで高速化されたディープラーニングソフトウェアを使用して大規模な地理的領域をすばやく検索します。検索時間は地理的領域に比例して比例し、処理速度は線形に比例します。gatrは16年前の検索システムを10年以上使用しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Shape Features and Abstractions in 3D Convolutional Neural
  Networks for Detecting Alzheimer's Disease -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_20.html">
      <font color="black">Learning Shape Features and Abstractions in 3D Convolutional Neural
  Networks for Detecting Alzheimer's Disease</font>
    </a>
  </h2>
  <font color="black">異なるモデルのLRP関連性マップにより、脳のどの部分が分類の決定により関連するかが明らかになりました。最後に、畳み込みオートエンコーダーからの転移学習を実装して、入力のパッチでトレーニングサンプルの数を増やし、低レベルを抽出するかどうかを確認しましたfeaturesは、学習された機能とモデルのパフォーマンスを改善します。ネットワーク構造、使用されたフィルターサイズ、およびフィルターの形状の変更が全体的なパフォーマンスにどのように影響するか、およびモデルの学習された機能も検査されました。 
[要約] convnetは、医療データを分析して効率的な方法で疾患を診断する医療分野での可能性を秘めています。モデルの決定を理解しなければ、生命を脅かす可能性のある誤診につながる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: A Comparison of Deep Learning Object Detection Models for Satellite
  Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_21.html">
      <font color="black">A Comparison of Deep Learning Object Detection Models for Satellite
  Imagery</font>
    </a>
  </h2>
  <font color="black">また、スライディングウィンドウオブジェクト検出アルゴリズムのタイミング結果を測定して、比較のベースラインを提供します。ただし、小型車を検出する場合、2ステージモデルとマルチステージモデルは、ある程度の速度を犠牲にして、かなり高い精度を提供します。ウェルパッド（50m〜250m）をフラッキングすることにより、1段の検出器が優れた予測速度を提供すると同時に、2段および多段の対応する検出器の検出性能と一致することがわかります。 
[ABSTRACT]いくつかのモデルは、シングルステージ、2ステージ、およびマルチステージのオブジェクト検出技術のファミリから研究されています。小型車を検出するために、2ステージおよびマルチステージモデルは、いくつかの速度でかなり高い精度を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Measuring Generalisation to Unseen Viewpoints, Articulations, Shapes and
  Objects for 3D Hand Pose Estimation under Hand-Object Interaction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_22.html">
      <font color="black">Measuring Generalisation to Unseen Viewpoints, Articulations, Shapes and
  Objects for 3D Hand Pose Estimation under Hand-Object Interaction</font>
    </a>
  </h2>
  <font color="black">RGB画像は照明条件や色によっても変化するため、手がオブジェクトとやり取りしている場合や、入力が深度画像ではなくRGBである場合、このサンプリングの問題はさらに深刻になります。分析により、次の影響が明らかになります。 、パラメトリック3Dハンドモデル（MANO）の使用、および異なるHPEメソッド/バックボーン.. 4つの主軸：形状、アーティキュレーション、視点、およびオブジェクト。 （c）現在のデータセットのギャップを埋めるための合成手のモデルの使用を調査する。 
[ABSTRACT] hands &#39;19は、オブジェクトの存在下または不在下で、3D手の姿勢推定に対する深度と色の両方のモダリティの影響を評価するように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-30">
        <br><font color="black">2020-03-30</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Fine-grained Large Object Segmentation 1st Place Solution to 3D
  AI Challenge 2020 -- Instance Segmentation Track -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_23.html">
      <font color="black">Towards Fine-grained Large Object Segmentation 1st Place Solution to 3D
  AI Challenge 2020 -- Instance Segmentation Track</font>
    </a>
  </h2>
  <font color="black">コードはhttps://github.com/zehuichen123/3DFuture_ins_seg。で入手できます。3D-FUTUREで非常に大きなオブジェクトを処理するために、HTCおよびSOLOv2と比較してより細かいマスクを出力する基本フレームワークとしてPointRendを採用しています。 ..最終提出は5つのPointRendモデルの組み合わせであり、検証とテストのリーダーボードの両方で1位を獲得しています。 
[ABSTRACT] pointrendは、きめの細かいマスクを提供する基本的なフレームワークです。コードは電子メールで入手できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-Anchored Detector for One-Stage Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_24.html">
      <font color="black">Semi-Anchored Detector for One-Stage Object Detection</font>
    </a>
  </h2>
  <font color="black">この作業では、セミアンカーフレームワークを提案します。最近、多くのアンカーフリーアルゴリズムが位置を直接分類するために提案されています。具体的には、分類でポジティブな位置を特定し、回帰でポジティブな位置に複数のアンカーを関連付けます。 
[ABSTRACT]場所ごとに異なる形状のアンカーが導入されています。これは、マルチスケールオブジェクトの分類の課題を軽減するためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Ultrasound Liver Fibrosis Diagnosis using Multi-indicator guided Deep
  Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_25.html">
      <font color="black">Ultrasound Liver Fibrosis Diagnosis using Multi-indicator guided Deep
  Neural Networks</font>
    </a>
  </h2>
  <font color="black">実験結果に示されているように、提案されたモデルは、最先端のパフォーマンスを達成することによってその有効性を示しています。具体的には、精度は65.6％（以前の最高より20％高い）です。線維化ステージの正確な分析は、慢性B型肝炎感染患者のフォローアップにおける重要な役割。トレーニングをサポートするために、229人の患者の超音波ビデオ/画像、インジケーター、ラベルを含むデータセットが収集されています。 
[要約]研究は229人の患者のデータセットを分析することによって行われました。これらには、患者の超音波ビデオ、画像、インジケーター、ラベルが含まれていました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Multiple instance learning on deep features for weakly supervised object
  detection with extreme domain shifts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_26.html">
      <font color="black">Multiple instance learning on deep features for weakly supervised object
  detection with extreme domain shifts</font>
    </a>
  </h2>
  <font color="black">そのシンプルさにもかかわらず、私たちの方法は、絵画（People-Art、IconArt）、水彩画、クリップアート、コミックなど、一般に利用可能なさまざまなデータセットで競争力のある結果を示し、目に見えない視覚的なカテゴリをすばやく学習できます。提案されたアプローチのいくつかのフレーバーを調査します、一部は多層パーセプトロンと多面体分類子を含みます。このアプローチは微調整やクロスドメイン学習を含まないため、効率的であり、任意のデータセットとクラスに適用できる可能性があります。 
[ABSTRACT]事前トレーニング済みのディープフィーチャに適用されたシンプルなマルチインスタンスアプローチにより、写真クラス以外のデータセット（おそらく新しいクラスを含む）で優れたパフォーマンスが得られます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-03">
        <br><font color="black">2020-08-03</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal Noisy Segmentation based fragmented burn scars identification
  in Amazon Rainforest -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_27.html">
      <font color="black">Multimodal Noisy Segmentation based fragmented burn scars identification
  in Amazon Rainforest</font>
    </a>
  </h2>
  <font color="black">この作業では、AmazonNET-マルチモーダルリモートセンシング画像から火傷のパターンを抽出できる畳み込みベースのネットワークを紹介します。アクセスできない熱帯雨林での山火事による火傷の検出は、さまざまな災害管理や生態学的研究にとって重要です。断片化された性質耕地の景観と多様な作付けパターンは、火傷跡の正確なマッピングを妨げることがよくあります。 
[要旨] amazonのamazonベースのエンコーダネットワークは、マルチモーダル火傷の識別でよく知られています。ネットワークは、生物医学的セグメンテーションで一般的に使用されるスキップ接続を使用する、よく知られているエンコーダネットワークであるunetで構成されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: 3D Facial Matching by Spiral Convolutional Metric Learning and a
  Biometric Fusion-Net of Demographic Properties -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_28.html">
      <font color="black">3D Facial Matching by Spiral Convolutional Metric Learning and a
  Biometric Fusion-Net of Demographic Properties</font>
    </a>
  </h2>
  <font color="black">顔には、個人のアイデンティティに関する多くの情報が含まれているため、顔認識は広く受け入れられている生体認証ツールです。解像度のレベル.. 2番目のステップは、完全に接続されたニューラルネットワークによるマルチバイオメトリック融合です。 
[ABSTRACT]ネットワークは入力として埋め込みとプロパティラベルの組み合わせを取り、正規のスコアと偽のスコアを返します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Assignment Flow for Order-Constrained OCT Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_29.html">
      <font color="black">Assignment Flow for Order-Constrained OCT Segmentation</font>
    </a>
  </h2>
  <font color="black">新規の純粋にデータ駆動型の\ textit {順序が制約された3D OCT網膜細胞層セグメンテーションへの幾何学的アプローチ}を提案します。これは、任意のメトリック空間で入力データを取り、効率的に並列計算できる基本的な操作を伴います。多くの確立された網膜検出方法に対して、私たちの提示された定式化は、事前の形状の使用を回避し、純粋に幾何学的な方法で網膜の自然な秩序を実現します。これにより、アプローチが偏りなくなり、網膜組織の局所解剖学的変化の検出に適します構造。 
[要約]網膜層の厚さを正確に特定することは、患者ごとに個別に実行する必要のあるタスクとして機能します。自動セグメンテーションモデルの作成は、医用画像処理の分野で重要なタスクになっています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: HSolo: Homography from a single affine aware correspondence -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_30.html">
      <font color="black">HSolo: Homography from a single affine aware correspondence</font>
    </a>
  </h2>
  <font color="black">既存のロバストなホモグラフィ推定アルゴリズムのパフォーマンスは、特徴点の対応のインライアレートに大きく依存します。特に、低いインライアレートでは、新しいアルゴリズムが劇的なパフォーマンスの向上を提供します。アフィン対応の特徴検出器によって作成されたスケールと回転の副産物を利用することなどSIFTおよびSURFとして、単一の対応ペアから初期ホモグラフィ推定を取得します。 
[ABSTRACT]論文では、インライア-貧弱なドメインに特に適したホモファイン推定の新しい手順を紹介します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Non-contact Real time Eye Gaze Mapping System Based on Deep
  Convolutional Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_31.html">
      <font color="black">Non-contact Real time Eye Gaze Mapping System Based on Deep
  Convolutional Neural Network</font>
    </a>
  </h2>
  <font color="black">さらに、GIST Gazeマッピング（GGM）データセット、Gazeマッピングを学習および評価するために作成されたGazeマッピングデータセットを紹介します。ユーザーが見つめている領域を見つけるGaze Matchingメソッドによって、信頼できる視覚的注意を得ることができます。 -Computer Interaction（HCI）は、人間のユーザーとコンピュータシステム間の相互作用を研究する分野です。 
[ABSTRACT]視線認識は、人間の行動の理解を高めることができるため、hciフィールドと密接に関連しています。実際の環境でのマッピングシステムを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Video Moment Retrieval via Natural Language Queries -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_32.html">
      <font color="black">Video Moment Retrieval via Natural Language Queries</font>
    </a>
  </h2>
  <font color="black">第2に、モーメントセグメンテーションタスク、開始/終了分布予測、開始/終了位置回帰タスクで構成される複数のタスクトレーニング目標を使用することも提案します。開始/終了予測は、アノテーターの不一致とモーメントによるジョイントトレーニングによってノイズが多いことを確認しましたターゲットクリップ内のフレームはポジティブトレーニングの例としても利用されるため、セグメンテーションタスクはより豊富な情報を提供できます。このホワイトペーパーでは、R @で最先端のSOTAパフォーマンスを実現するビデオモーメント検索（VMR）の新しい方法を提案します。 1メトリックおよび高IoUメトリック（R @ 1、IoU = 0.7）でSOTAを上回ります。 
[要旨]マルチヘッドセルフアテンションメカニズムを使用することを提案します。さらに、クロスアテンションスキームを使用して、ビデオコンテキストからビデオ/検索の相互作用と長距離検索の依存関係をキャプチャします。コンセプトに基づいて、終了予測がうるさい</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-04">
        <br><font color="black">2020-09-04</font>
      </time>
    </span>
</section>
<!-- paper0: A leak in PRNU based source identification? Questioning fingerprint
  uniqueness -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_33.html">
      <font color="black">A leak in PRNU based source identification? Questioning fingerprint
  uniqueness</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、制御された環境下で問題を強調した後、Flickr画像に対して大規模なテストキャンペーンを実行して、問題がどれほど広範であり、それがもっともらしい原因であるかを判断します。この目的のために、54ドルから240000ドル以上の画像ペアをテストしました最も関連性の高いブランドを含む最近のスマートフォンモデル。ただし、計算写真の登場により、同じモデルの最新のデバイスは相関パターンを公開し始め、誤った画像ソース属性の本当のチャンスをもたらしています。 
[要約]この問題に対するカメラメーカーの対応は新しいペーパーでテストされています。多くのsamsung、xiaomi、およびhuaweiデバイスがこの問題の影響を強く受けていることが示されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to segment microscopy images with lazy labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_34.html">
      <font color="black">Learning to segment microscopy images with lazy labels</font>
    </a>
  </h2>
  <font color="black">この方法は2つの顕微鏡データセットで示されています。アノテーション付きデータの大部分で正確な境界ラベルが欠落している場合でも、モデルが正確なセグメンテーション結果を与えることを示しています。画像セグメンテーションは、3つの関連するタスクに分類されます：大まかな内部領域検出、オブジェクト分離これらのタスクは、エンドツーエンドのマルチタスク学習フレームワークで学習されます。 
[ABSTRACT]たとえば、顕微鏡画像セグメンテーションのための深い畳み込みニューラルネットワークを導入します。これらのタスクは、高度なマルチタスク学習フレームワークで学習されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-20">
        <br><font color="black">2019-06-20</font>
      </time>
    </span>
</section>
<!-- paper0: CAD-PU: A Curvature-Adaptive Deep Learning Solution for Point Set
  Upsampling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_35.html">
      <font color="black">CAD-PU: A Curvature-Adaptive Deep Learning Solution for Point Set
  Upsampling</font>
    </a>
  </h2>
  <font color="black">貢献の有効性と既存の方法に対する方法の利点を示す徹底的な実験を行います。アップサンプリングの結果でポイントの固定予算が与えられた場合、局所的な曲率が比較的大きい表面領域に多くのポイントを分配する必要があることを示唆しています。動機付けを実装するために、曲率適応機能拡張のモジュールをコアとする曲率適応ポイントセットアップサンプリングネットワーク（CAD-PU）の新しい設計を提案します。 
[ABSTRACT]ポイント設定のアップサンプリングは、密度と規則性を高めることを目的としています。問題は非常に悪いため、より良い表面回復を実現できます。これらは、表面推定を改善するために設定されたポイントに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: NPENAS: Neural Predictor Guided Evolution for Neural Architecture Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_36.html">
      <font color="black">NPENAS: Neural Predictor Guided Evolution for Neural Architecture Search</font>
    </a>
  </h2>
  <font color="black">最初の予測子はベイズ最適化から定義され、グラフベースの不確実性推定ネットワークを、実装が簡単で計算効率の高い代理モデルとして提案します。広範な実験は、NPENASの優位性を示しています。2番目の予測子はグラフベースのニューラルです。入力ニューラルアーキテクチャのパフォーマンス予測を直接出力するネットワーク。 
[ABSTRACT] nasは検索戦略を採用して、事前定義された検索スペースを探索し、最小の検索コストで非常に高価なパフォーマンスアーキテクチャを見つけます。2種類のニューラル予測子は、入力ニューラルアーキテクチャのパフォーマンス予測を直接出力するグラフベースのニューラルネットワークです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-28">
        <br><font color="black">2020-03-28</font>
      </time>
    </span>
</section>
<!-- paper0: Quantifying the Preferential Direction of the Model Gradient in
  Adversarial Training With Projected Gradient Descent -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_37.html">
      <font color="black">Quantifying the Preferential Direction of the Model Gradient in
  Adversarial Training With Projected Gradient Descent</font>
    </a>
  </h2>
  <font color="black">画像に存在するクラスを変更するために必要な最小の残差を生成する生成的対立モデルトレーニングを使用して、バイナリ分類問題のこの配置を測定する方法を提案します。他のクラスのサポートの最も近い点..我々の定義によれば、PGDトレーニング済みモデルはベースラインよりも解釈しやすく、メトリックは競合するメトリックの公式よりも高いアライメント値を示します。 
[ABSTRACT]次の解釈可能性に従うと、それらのビューに対するモデルの重力は意味があり、人間が解釈できます。これは、pgd-トレーニング済みモデルがベースラインよりも適応可能であることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Bootstrap your own latent: A new approach to self-supervised Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_38.html">
      <font color="black">Bootstrap your own latent: A new approach to self-supervised Learning</font>
    </a>
  </h2>
  <font color="black">BYOLは、転送と半教師付きベンチマークの両方で、現在の技術水準と同等以上のパフォーマンスを発揮することを示しています。より大きなResNetを使用した$ 79.6 \％$ ..最先端の方法は負のペアに依存していますが、BYOLはそれらなしで新しい最先端の技術を実現します。 
[ABSTRACT] byolは、相互に作用し、相互に学習する2つのニューラルネットワークに依存しています。ターゲットネットワークの拡張バージョンは、低速です-オンラインネットワークの移動平均</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-13">
        <br><font color="black">2020-06-13</font>
      </time>
    </span>
</section>
<!-- paper0: Prototype Completion with Primitive Knowledge for Few-Shot Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_39.html">
      <font color="black">Prototype Completion with Primitive Knowledge for Few-Shot Learning</font>
    </a>
  </h2>
  <font color="black">その理由は、事前トレーニング済みの特徴空間では、基本クラスがすでにコンパクトなクラスターを形成している一方で、新規クラスは大きな分散を持つグループとして広がるという事実に根ざしています。プロトタイプ..フレームワークは最初に基本的な知識（つまり、クラスレベルの属性または部品の注釈）を導入し、代表的な属性の特徴を事前情報として抽出します。 
[要旨]重要なアイデアは、事前トレーニングで特徴抽出を学習し、最も近い重心ベースのメタ学習を介してそれを微調整することです。ただし、現在のメタ学習スキームでは、事前学習の力を完全に探求していません。トレーニング</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Modeling User Behaviors in Machine Operation Tasks for Adaptive Guidance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_40.html">
      <font color="black">Modeling User Behaviors in Machine Operation Tasks for Adaptive Guidance</font>
    </a>
  </h2>
  <font color="black">機器オペレーターをサポートするアダプティブガイダンスシステムには、さまざまなスキルや知識レベルを考慮したさまざまなユーザーの行動、および急速に変化するタスク状況を含む包括的なモデルが必要です。2段階の方法を使用して、ユーザーの行動：プロトタイプの選択とスキルランキングに基づくエクスペリエンスの統合..オペレーターの視線と頭の動き、手の相互作用、ホットスポットなどの行動の特徴は、継続的なユーザーのスキルの向上に起因する重要な行動の傾向とともに観察されました。 
[要約]たとえば、12人のオペレーターがヘッドマウントrgb -dカメラと静的な視線追跡を使用して実行した2つの縫製タスクの144サンプルを調べました。ユーザーレコードの統合により、次のような豊富で包括的なタスクモデルを開発できました。多様なユーザーに適応するために柔軟に使用-特定のニーズ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-06">
        <br><font color="black">2020-03-06</font>
      </time>
    </span>
</section>
<!-- paper0: Activate or Not: Learning Customized Activation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_41.html">
      <font color="black">Activate or Not: Learning Customized Activation</font>
    </a>
  </h2>
  <font color="black">次に、メタACONを提示します。これは、非線形（アクティブ化）と線形（非アクティブ化）の間のパラメーター切り替えを最適化することを明示的に学習し、新しい設計スペースを提供します。アクティブ化機能を変更するだけで、ImageNetのトップ1が向上します。 MobileNet-0.25およびResNet-152でそれぞれ6.7％および1.8％の正確率。現代の活性化層は非線形関数を使用してニューロンを活性化します。 
[ABSTRACT] aconを呼び出します。これはニューロンをアクティブ化するかどうかを学習します。これは、シンプルですが効果的なアクティブ化機能の働きです。これを使用して、イメージネットのトップ-1の精度を6.7向上させます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Objects detection for remote sensing images based on polar coordinates -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_42.html">
      <font color="black">Objects detection for remote sensing images based on polar coordinates</font>
    </a>
  </h2>
  <font color="black">これらの方法では、指向型検出器の設計は水平型検出器よりもはるかに複雑です。なぜなら、前者は通常、より複雑な回転アンカーを考案する必要があるためです。極域リモートセンシングオブジェクト検出器（P-RSDet）と呼ばれるこのモデルは、極座標系を確立するための極点としての各オブジェクトの中心点と極軸としての水平方向の正方向。この座標系では、P-RSDetは水平方向の境界ボックスの表現を統合し、指向の出力形式は、水平形式と同じくらい簡単です。 
[ABSTRACT] structures構造は、極座標でのオブジェクト検出を検出するために使用されます。msの研究者は、新しいアンカー-リモートセンシング画像用の無料の検出器を提案しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-09">
        <br><font color="black">2020-01-09</font>
      </time>
    </span>
</section>
<!-- paper0: MedMeshCNN -- Enabling MeshCNN for Medical Surface Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_43.html">
      <font color="black">MedMeshCNN -- Enabling MeshCNN for Medical Surface Models</font>
    </a>
  </h2>
  <font color="black">さらに、高度に不均衡なクラス分布を伴うことが多い病理構造のセグメンテーションを可能にします。病理学的所見に由来する不均衡なクラス分布はMedMeshCNNによって考慮され、患者固有のプロパティはセグメンテーションプロセス中にほとんど保持されます。メソッド：MedMeshCNNは次のとおりです。大幅に向上したメモリ効率を備えたMeshCNNの機能により、セグメンテーションプロセス中に患者固有のプロパティを保持できます。 
[ABSTRACT] meshcnnは、分類およびセグメンテーションタスク内で最先端の方法を上回りましたが、いくつかの制限により、非常に多様な医療表面モデルでのmeshcnnの卓越したパフォーマンスが妨げられています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting the Presence of Vehicles and Equipment in SAR Imagery Using
  Image Texture Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_44.html">
      <font color="black">Detecting the Presence of Vehicles and Equipment in SAR Imagery Using
  Image Texture Features</font>
    </a>
  </h2>
  <font color="black">各分類子は、建設現場の活動レベルの2つの可能なタイプを区別できるという有望な結果を示しました。この作業では、低解像度のSAR画像で、人工の建設のような活動を監視する方法論を紹介します。探索的データセット、サポートベクターマシン（SVM）、ランダムバイナリフォレスト、および分類のための完全に接続されたニューラルネットワークをトレーニングしました。 
[要約]このペーパーでは、石油とガスのフラッキングウェルの建設プロセスの監視を中心としたケーススタディについて説明します。分類子への入力フィーチャとして、vvおよびvh分極チャネルのハラリックテクスチャフィーチャを使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: RVL-BERT: Visual Relationship Detection with Visual-Linguistic Knowledge
  from Pre-trained Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_45.html">
      <font color="black">RVL-BERT: Visual Relationship Detection with Visual-Linguistic Knowledge
  from Pre-trained Representations</font>
    </a>
  </h2>
  <font color="black">さらに、私たちのモデルは、オブジェクト名を直接取り込むことにより、視覚的な関係の認識からオブジェクトの検出を切り離し、あらゆるオブジェクト検出システムの上で使用できるようにします。RVL-BERTは、効果的な空間モジュールと新しいマスク注意モジュールを使用して、明示的にキャプチャしますオブジェクト間の空間情報。この論文では、トランスフォーマーからの関係性視覚言語双方向エンコーダー表現（RVL-BERT）という新しいアプローチを提案します。マルチモーダル表現によるトレーニング。 
[要約]調査では、外部の視覚的常識知識が画像内のオブジェクトの視覚的関係を推論するのに有益であることが示されています。研究は人間の推論メカニズムに触発されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Enhanced Quadratic Video Interpolation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_46.html">
      <font color="black">Enhanced Quadratic Video Interpolation</font>
    </a>
  </h2>
  <font color="black">その中で、二次ビデオ補間（QVI）という名前の最近のアルゴリズムは魅力的なパフォーマンスを実現します。加速）、補間されたフローの推定を正常にモデル化します。画像のピクセルレベルのブレンディングと相補的に、使用する残差コンテキスト合成ネットワーク（RCSN）を導入します。高次元の特徴空間におけるコンテキスト情報。これにより、モデルがより複雑なシーンやモーションパターンを処理できるようになります。 
[ABSTRACT]多くの学習ベースの方法が提案され、進歩的な結果が得られました。これらの中で、高次のモーション情報が利用されています。ただし、生成された中間フレームには、まだ不十分なファセットが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Distributed Variable-Baseline Stereo SLAM from two UAVs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_47.html">
      <font color="black">Distributed Variable-Baseline Stereo SLAM from two UAVs</font>
    </a>
  </h2>
  <font color="black">この問題に取り組むために、この記事では、1つの単眼カメラと1つのIMUを備えた2つのUAVを使用して、オンボードのUWBモジュールを使用してそれらのビューのオーバーラップとそれらの間の相対距離測定を活用し、協調VIOを有効にします。最後に、固定されたターゲットベースラインに対してオンザフライでベースラインをアクティブに調整し、実験のエラーを2分の1に削減する利点。フォトリアリスティックなシミュレーションを徹底的に評価した後、高高度飛行でのアプローチの有効性を示します最大160mで、最先端のVIOメソッドの機能を大幅に超えます。 
[ABSTRACT]ロボットのシステム内のセンサーを使用して、センサーの位置を特定できます。このシステムは、2つのuavから調整可能なベースラインを備えた仮想ステレオカメラリグを実現するように開発できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Text-independent writer identification using convolutional neural
  network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_48.html">
      <font color="black">Text-independent writer identification using convolutional neural
  network</font>
    </a>
  </h2>
  <font color="black">畳み込みニューラルネットワーク（CNN）は、最初に訓練されて、局所的な特徴を抽出します。これは、文字画像全体とそのサブ領域内の個々の手書きの特性を表します。訓練するためにライターごとに1ページのみを使用して、この方法では900人のライターを分類します。オフラインの手書き英語テキストのFiremakerおよびIAMデータベースでさらに実験を行いました。 
[要旨]タプルのcnnのランダム分析を使用してcnnをトレーニングします。次に、それらを使用してグローバルフィーチャを作成します。たとえば、91以上で達成された方法。81％の精度</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Visual Re-Identification with Confidence -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_49.html">
      <font color="black">Deep Visual Re-Identification with Confidence</font>
    </a>
  </h2>
  <font color="black">私たちは、重なり合っていない視野からキャプチャされた画像全体で同じエージェントを再識別する技術を開発する必要があります。これは、視覚的再識別タスクと呼ばれます。または歩行者、および5つのデータセットにわたって高度に専門化された最先端の方法よりも優れています。カメラがドローンに取り付けられていても、車両に組み込まれていても、構築環境に固定されていても、必然的に散乱したままです。 
[要約]センシング技術の最近の進歩により、カメラを使用して需要をよりよく理解できるようになります。変化のない環境からキャプチャされた画像全体で同じエージェントを再特定する技術を開発する必要があります。このような損失関数は視覚的な再識別タスクに適しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-11">
        <br><font color="black">2019-06-11</font>
      </time>
    </span>
</section>
<!-- paper0: Attributes-Guided and Pure-Visual Attention Alignment for Few-Shot
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_50.html">
      <font color="black">Attributes-Guided and Pure-Visual Attention Alignment for Few-Shot
  Recognition</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、人間が注釈を付けた属性を利用し、より特徴的な機能を学習するために、属性ガイドアテンションモジュール（AGAM）を考案します。このプラグアンドプレイモジュールにより、視覚的なコンテンツと対応する属性をまとめて、重要なチャネルと領域に集中できます。サポートセット..したがって、両方のセットからの表現がきめ細かく改善されます。 
[ABSTRACT]以前のアプローチでは、補助的な意味論的モダリティが導入されています。これらは、トレーニングサンプルとテストサンプルの特徴の類似性を学習することを目的としています。これらのアプローチには、より特徴的な特徴を学習する機能が含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Performance of object recognition in wearable videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CV/paper_51.html">
      <font color="black">Performance of object recognition in wearable videos</font>
    </a>
  </h2>
  <font color="black">私たちは公開ADLデータセットに焦点を当てていますが、補足的な評価のために追加の公開データも使用しています。この作品では、このタイプのカメラでキャプチャされたビデオのオブジェクト検出と位置特定の問題を研究しています。ウェアラブル録音で一般的です。 
[ABSTRACT]これらは、カメラによってキャプチャされたシーンの関心のある要素を認識するために必要です。これらの作品は、精度と速度の優れたトレードオフを提供する、よく知られたyoloアーキテクチャの徹底的な研究を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Modern Methods for Text Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CL/paper_0.html">
      <font color="black">Modern Methods for Text Generation</font>
    </a>
  </h2>
  <font color="black">最近、Transformersと呼ばれる新しいアーキテクチャにより、機械学習モデルは、変換や要約などのより優れた順次データを理解できるようになります。BERTおよびGPT-2は、コアにトランスフォーマーを使用しており、テキスト分類などのタスクで優れたパフォーマンスを示しています。翻訳とNLIタスク..この記事では、両方のアルゴリズムを分析し、テキスト生成タスクでの出力品質を比較します。 
[ABSTRACT]新しいアーキテクチャにより、機械学習モデルは、翻訳や要約など、より優れた連続データを理解できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Subword RNNLM Approximations for Out-Of-Vocabulary Keyword Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CL/paper_1.html">
      <font color="black">Subword RNNLM Approximations for Out-Of-Vocabulary Keyword Search</font>
    </a>
  </h2>
  <font color="black">この論文では、従来のn-gramモデルとRNNLM近似を補間してOOV認識を改善することを提案します。さらに、サブワード単位に適した新しいRNNLM近似法を開発します。近似をスパンし、トレーニングコーパスで元々観察されなかったn-gramも考慮します。リカレントニューラルネットワーク（RNN）LMは、スパース性の問題を軽減しますが、初回パスの認識には適していません。 
[ABSTRACT]初回パス認識でサブワード言語モデル（lms）を使用すると、oovワードを認識できます。ただし、サブワードn-gram lmsでもデータのスパース性に悩まされています。このような新しい方法は、サブワード認識用に開発されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br><font color="black">2020-05-28</font>
      </time>
    </span>
</section>
<!-- paper0: Emora: An Inquisitive Social Chatbot Who Cares For You -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CL/paper_2.html">
      <font color="black">Emora: An Inquisitive Social Chatbot Who Cares For You</font>
    </a>
  </h2>
  <font color="black">非常に表現力豊かな自然言語テンプレート、強力な意図分類、オントロジーリソースを活用して、すべてのユーザーに魅力的で興味深い会話体験を提供するキュレーションされた対話システムを紹介します。人間と人間の会話における経験共有の圧倒的な存在に関する研究に触発されましたEmoryは、Emory Universityによって開発されたソーシャルチャットボットであり、このような経験に焦点を当てた対話を会話型AIの現在の分野にもたらすことを目的としています。情報共有トピックハンドラーの従来のアプローチは、Emoraが提供する意見指向の交換に重点を置いてバランスが取れています、そしてパートナーの人生経験の協調的理解と学習プロセスからなる対話をサポートする新しい会話能力が開発されます。 
[ABSTRACT]人々が自分の人材について話すことを可能にする会話をサポートする新しい会話能力が開発されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Coreference Resolution by Leveraging Entity-Centric Features
  with Graph Neural Networks and Second-order Inference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CL/paper_3.html">
      <font color="black">Improving Coreference Resolution by Leveraging Entity-Centric Features
  with Graph Neural Networks and Second-order Inference</font>
    </a>
  </h2>
  <font color="black">相互参照の解決における主な課題の1つは、言及のペアではなく、言及のクラスター上で定義されたエンティティーレベルの機能をどのように利用するかです。マナーを一貫したグループにクラスター化するために、2次機能までのグローバル推論アルゴリズムも提示されます。 
[ABSTRACT]共通の言及は通常、テキスト全体で離れて広がります。2つのリンクされた言及が同じエンティティを指している可能性が高いエッジモデリングを介して、互いにリンクできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: GeoSPARQL+: Syntax, Semantics and System for Integrated Querying of
  Graph, Raster and Vector Data -- Technical Report -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CL/paper_4.html">
      <font color="black">GeoSPARQL+: Syntax, Semantics and System for Integrated Querying of
  Graph, Raster and Vector Data -- Technical Report</font>
    </a>
  </h2>
  <font color="black">セマンティックWebグラフでラスターデータを意味的に表現してクエリするアプローチを紹介します。GeoSPARQL語彙とクエリ言語を拡張して、ラスターデータを新しいタイプの地理空間データとしてサポートします。新しいフィルター関数を定義し、いくつかの方法を使用してアプローチを説明します実際のデータセットのユースケース。 
[要旨] geosparqlボキャブラリーを拡張して、新しいタイプのWebとしてラスターデータをサポートします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-modal embeddings using multi-task learning for emotion recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CL/paper_5.html">
      <font color="black">Multi-modal embeddings using multi-task learning for emotion recognition</font>
    </a>
  </h2>
  <font color="black">ネットワークの埋め込みは、マルチタスクトレーニングを使用してトレーニングされたトランスフォーマモデルのエンコーダを使用して抽出されます。word2vec、GloVe、ELMoなどの一般的な埋め込みは、自然言語タスクで多くの成功を収めています。このペーパーでは、作業を拡張します。自然言語の理解から、機械学習タスクにオーディオ、ビジュアル、テキスト情報を使用するマルチモーダルアーキテクチャまで。 
[ABSTRACT]埋め込みは、スキップなどの一般的なタスクに基づいて構築されたモデルから抽出されます-グラムモデルおよび自然言語生成</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Meta-Learning with Sparse Experience Replay for Lifelong Language
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CL/paper_6.html">
      <font color="black">Meta-Learning with Sparse Experience Replay for Lifelong Language
  Learning</font>
    </a>
  </h2>
  <font color="black">メタラーニングに基づく言語タスクの生涯学習への新しいアプローチを提案します。これは、スパース体験リプレイを使用して、忘却を直接防ぐために最適化されます。ディープラーニングモデルは、非順次学習パラダイムで成功しています。ただし、一連のタスクの学習に使用した場合、過去の知識を保持して段階的に学習することはできません。アプローチの有効性を分析し、計算と空間の複雑さが低いことをさらに示します。 
[ABSTRACT]ディープラーニングモデルは学習へのアプローチで成功しましたが、一連のタスクを学習するために使用すると、過去の知識を保持して段階的に学習することができません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Analyze the Effects of Weighting Functions on Cost Function in the Glove
  Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CL/paper_7.html">
      <font color="black">Analyze the Effects of Weighting Functions on Cost Function in the Glove
  Model</font>
    </a>
  </h2>
  <font color="black">また、実験を気にすることなく、ほぼ同じ精度を同時に得ることができます。その結果、重み付け関数の最適なパラメータを見つけて選択すると、弱いハードウェアで多くの困難が生じます。大きなボキャブラリサイズとコーパスのサイズ、Gloveモデルのトレーニングの実行時間は長く、データのサイズは約500MBです。 
[ABSTRACT]重み付け関数は、首の選択とベンチマークの作成にかかる時間を節約できます。重み付け関数は重み付け関数に似ています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Brain2Word: Decoding Brain Activity for Language Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CL/paper_8.html">
      <font color="black">Brain2Word: Decoding Brain Activity for Language Generation</font>
    </a>
  </h2>
  <font color="black">これはより現実的な設定であり、目に見えない被験者からのfMRIデータをデコードできるモデルを提示します。既存の作業とは異なり、以前に目に見えない被験者からのスキャンで評価します。したがって、正確な刺激を回復する能力が制限されます。 
[ABSTRACT]科学者は、被験者が読んでいる単語の埋め込みにfmriスキャンをデコードすることが可能であると言います。しかし、彼らは正確な刺激を回復する私たちの能力を制限します。モデルは5. 22％トップ-1以上の設定を達成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: The Grievance Dictionary: Understanding Threatening Language Use -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CL/paper_9.html">
      <font color="black">The Grievance Dictionary: Understanding Threatening Language Use</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、苦情を煽る暴力の脅威評価のコンテキストで言語の使用を自動的に理解するために使用できる心理言語辞典である苦情辞典を紹介します。人間および計算による単語リストの生成により、2,318人の参加者が注釈を付けた20,502語の辞書が作成されました。 
[要約]苦情評価辞書は、経験豊富な脅威評価実践者からの提案によって通知されました。辞書は、暴力的で非Annによって書かれたテキストに適用することで検証されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Graph-based Modeling of Online Communities for Fake News Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CL/paper_10.html">
      <font color="black">Graph-based Modeling of Online Communities for Fake News Detection</font>
    </a>
  </h2>
  <font color="black">この作業では、グラフニューラルネットワーク（GNN）に基づく新しいソーシャルコンテキスト認識の偽ニュース検出フレームワーク、SAFERを提案します。提案されたフレームワークは、1）に関する情報を集約します。1）配信されるコンテンツの性質、2）コンテンツ-ユーザーの行動を共有し、3）それらのユーザーのソーシャルネットワーク。私たちは、私たちのフレームワークが既存のテキストベースの手法を大幅に改善し、2つの異なるドメインからの偽のニュースデータセットで最先端の結果を達成することを実証的に実証します。 。 
[ABSTRACT]既存の研究は、オンライン投稿の普及における構造、スタイル、コンテンツ、およびパターンをモデル化しています。この研究では、グラフニューラルネットワーク（gnns）に基づいて、新しいソーシャルコンテキスト対応の偽のニュース検出フレームワーク、より安全なものを提案しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-14">
        <br><font color="black">2020-08-14</font>
      </time>
    </span>
</section>
<!-- paper0: Knowledgeable Dialogue Reading Comprehension on Key Turns -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CL/paper_11.html">
      <font color="black">Knowledgeable Dialogue Reading Comprehension on Key Turns</font>
    </a>
  </h2>
  <font color="black">元のコンテキスト、質問、および外部の知識は、事前トレーニング済みの言語モデルでエンコードされ、言語表現とキーターンは、意志で設計されたメカニズムと組み合わされて、答えを予測します。多肢選択式機械読解（MRC）には、パッセージと質問を与えられた候補オプションから正しい答えを選択するためのモデル。DREAMデータセットの実験結果は、提案されたモデルがベースラインの大幅な改善を達成することを示しています。 
[要約]私たちの研究は、対話がマルチターンの対話である対話ベースのmrcに焦点を当てています。また、研究は、コンテキストの表現を強化するための外部知識の使用にも焦点を当てています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-29">
        <br><font color="black">2020-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: Video Moment Retrieval via Natural Language Queries -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CL/paper_12.html">
      <font color="black">Video Moment Retrieval via Natural Language Queries</font>
    </a>
  </h2>
  <font color="black">次に、モーメントセグメンテーションタスク、開始/終了分布予測、開始/終了位置回帰タスクで構成される複数のタスクのトレーニング目標を使用することも提案します。このモデルはシンプルなアーキテクチャであり、..を維持しながらトレーニングと推論を高速化できます。ベースのメソッドは、任意の位置でフレームとクエリの相互作用およびクエリとフレームの相互作用を開発でき、マルチヘッド設定により、複雑な依存関係を十分に理解できます。 
[要旨]マルチヘッドセルフアテンションメカニズムを使用することを提案します。さらに、クロスアテンションスキームを使用して、ビデオコンテキストからビデオ/検索の相互作用と長距離検索の依存関係をキャプチャします。コンセプトに基づいて、終了予測がうるさい</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-04">
        <br><font color="black">2020-09-04</font>
      </time>
    </span>
</section>
<!-- paper0: Do Response Selection Models Really Know What's Next? Utterance
  Manipulation Strategies for Multi-turn Response Selection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CL/paper_13.html">
      <font color="black">Do Response Selection Models Really Know What's Next? Utterance
  Manipulation Strategies for Multi-turn Response Selection</font>
    </a>
  </h2>
  <font color="black">複数の言語とモデルにわたる広範な評価は、UMSが対話の一貫性を教えるのに非常に効果的であることを示しており、モデルが複数のパブリックベンチマークデータセットに大幅なマージンを備えた最先端の技術を推進することにつながります。これは、応答選択タスクのみが発話間の時間的依存関係を学習するには不十分です。このために、この問題に対処する発話操作戦略（UMS）を提案します。 
[ABSTRACT]最近の言語モデルは、さまざまな自然言語処理タスクの改善を示しています。これらには、bert、roberta、およびelectraが含まれます。umsなどのこれらのタイプの言語応答は、簡単に組み込むことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Task-specific Objectives of Pre-trained Language Models for Dialogue
  Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CL/paper_14.html">
      <font color="black">Task-specific Objectives of Pre-trained Language Models for Dialogue
  Adaptation</font>
    </a>
  </h2>
  <font color="black">大規模なドメイン内対話コーパスでDAPOを使用するPrLMは、ダウンストリームのDrNLPタスク用に微調整されます。この問題に対処するために、タスク固有の目的を持つドメイン内タスク関連コーパスに対するタスク固有の事前トレーニングを紹介します。この手順は、特定のタスクのモデル理解能力を高めるために、元の2つのステージの間に配置されます。 
[ABSTRACT]大規模なドメイン内対話コーパスでdapoを使用したprlmsは問題ありません-drnlp用に調整されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Classification of descriptions and summary using multiple passes of
  statistical and natural language toolkits -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CL/paper_15.html">
      <font color="black">Classification of descriptions and summary using multiple passes of
  statistical and natural language toolkits</font>
    </a>
  </h2>
  <font color="black">このアプローチから取得したパーセンテージスコアは、単独で使用することも、他のメトリックから取得したスコアを補完して最終的な分類に到達するために使用することもできます。このドキュメントの最後に、潜在的な改善点についても概説しています。このドキュメントでは、エンティティの名前に関する概要/定義の関連性を確認するために使用できるアプローチについて説明します。このドキュメントで取り上げるデータセット客観的なスコアを達成するには、パッケージ名とそれぞれの要約（pypi.orgから提供）のリストです。 
[ABSTRACT]パッケージ名とそれぞれの概要のリストがまとめられました。このリストには、パッケージ名などの潜在的なアップグレードのリストが含まれています。データセットはpypiに基づいています。組織</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Investigating Gender Bias in BERT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CL/paper_16.html">
      <font color="black">Investigating Gender Bias in BERT</font>
    </a>
  </h2>
  <font color="black">したがって、BERTの各レイヤーで、主に性別情報をエンコードする方向を特定します。これにより、複数の次元で性別サブスペースを実現する必要がなくなり、他の重要な情報が省略されるのを防ぎます。次に、株式評価コーパス。 
[ABSTRACT] clmは、テキスト分類などの領域に単語の埋め込みを提供します。ただし、結果は、システムの予測が特定の単語や語句に大きく依存していることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: On Target Segmentation for Direct Speech Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CL/paper_17.html">
      <font color="black">On Target Segmentation for Direct Speech Translation</font>
    </a>
  </h2>
  <font color="black">このように、音声翻訳に関する最近の研究は、文字の最初の使用と、文字レベルでより良い結果のいくつかの最近の主張にもかかわらず、ターゲットサブワードの使用を開始しました。文字レベルのセグメンテーションは、オープンボキャブラリーを得るために最初に提案されましたが、長い間シーケンスと長いトレーニング時間。次に、サブワードレベルのセグメンテーションは、トレーニングレベルを短縮する短いシーケンスを生成すると同時に、単語レベルのモデルよりも優れているため、ニューラル機械翻訳の最先端になりました。 
[ABSTRACT]最近の研究では、文字の初期使用と、文字レベルでのより良い結果のいくつかの最近の主張にもかかわらず、ターゲットサブワードの使用が開始されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Universal Representations from Word to Sentence -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CL/paper_18.html">
      <font color="black">Learning Universal Representations from Word to Sentence</font>
    </a>
  </h2>
  <font color="black">保険FAQタスクのさらなる実験は、現実世界のアプリケーションでのユニバーサル表現モデルの有効性を示しています。次に、適切なトレーニング設定に組み込まれた事前トレーニング済みのトランスフォーマーモデルが効果的にユニバーサル表現を生成できることを経験的に検証します。特に、細かいNLIおよびPPDBデータセットでALBERTを調整すると、さまざまな言語レベルの類推タスクで最高の精度が得られます。 
[ABSTRACT]普遍的な表現の学習、すなわち、タスクに依存しない評価を通じて、言語レベルの異なるレベルを一様確率空間に埋め込む</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: RVL-BERT: Visual Relationship Detection with Visual-Linguistic Knowledge
  from Pre-trained Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/cs.CL/paper_19.html">
      <font color="black">RVL-BERT: Visual Relationship Detection with Visual-Linguistic Knowledge
  from Pre-trained Representations</font>
    </a>
  </h2>
  <font color="black">さらに、私たちのモデルは、オブジェクト名を直接取り込むことにより、視覚的な関係の認識からオブジェクトの検出を切り離し、あらゆるオブジェクト検出システムの上でそれを使用できるようにします。この論文では、Relational Visual-Linguistic Bidirectional Encoder Representationsという新しいアプローチを提案します。トランスフォーマー（RVL-BERT）は、マルチモーダル表現による自己監視事前トレーニングを通じて学習した視覚的知識と言語常識の両方で関係推論を実行します。RVL-BERTは、効果的な空間モジュールと新しいマスク注意モジュールを使用して、空間を明示的にキャプチャします。オブジェクト間の情報。 
[要約]調査では、外部の視覚的常識知識が画像内のオブジェクトの視覚的関係を推論するのに有益であることが示されています。研究は人間の推論メカニズムに触発されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: ICASSP 2021 Acoustic Echo Cancellation Challenge: Datasets and Testing
  Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/eess.AS/paper_0.html">
      <font color="black">ICASSP 2021 Acoustic Echo Cancellation Challenge: Datasets and Testing
  Framework</font>
    </a>
  </h2>
  <font color="black">この課題では、シングルトークとダブルトークの両方のシナリオでAECモデルをトレーニングするために、2つの大きなデータセットをオープンソースにします。ICASSP2021音響エコーキャンセレーションチャレンジは、音響エコーキャンセレーション（AEC）の分野における研究を刺激することを目的としています。音声通信の重要な部分であり、音声通信および会議システムで依然として最大の課題です。ITU-TP.808に基づくオンライン主観テストフレームワークをオープンソース化し、研究者が結果をすばやくテストできるようにしています。 
[ABSTRACT]最近の多くのaec調査では、合成データセットで妥当なパフォーマンスが報告されています。ただし、従来の客観的な指標のほとんどは、主観的な音声品質テストと十分に相関していません。環境</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
<!-- paper0: Subword RNNLM Approximations for Out-Of-Vocabulary Keyword Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/eess.AS/paper_1.html">
      <font color="black">Subword RNNLM Approximations for Out-Of-Vocabulary Keyword Search</font>
    </a>
  </h2>
  <font color="black">この論文では、従来のn-gramモデルとRNNLM近似を補間してOOV認識を改善することを提案します。これを解決する1つの方法は、RNNLMをバックオフn-gramモデルで近似することです。さらに、ベースライン近似を置き換える提案された方法では、複数文字と単一文字の両方のサブワードで最高のパフォーマンスが得られます。 
[ABSTRACT]初回パス認識でサブワード言語モデル（lms）を使用すると、oovワードを認識できます。ただし、サブワードn-gram lmsでもデータのスパース性に悩まされています。このような新しい方法は、サブワード認識用に開発されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br><font color="black">2020-05-28</font>
      </time>
    </span>
</section>
<!-- paper0: Exploration of End-to-end Synthesisers forZero Resource Speech Challenge
  2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-11/eess.AS/paper_2.html">
      <font color="black">Exploration of End-to-end Synthesisers forZero Resource Speech Challenge
  2020</font>
    </a>
  </h2>
  <font color="black">Zerospeech 2020チャレンジで提案されたシステムの評価は、非常に高品質の合成が達成できることを示しています。目に見えない言語の音声対話システムは、ゼロリソーススピーチと呼ばれます。音響ユニットシーケンスを使用して、TTSモデルがトレーニングされます。 
[ABSTRACT]音声は、過渡状態と定常状態の音響単位のシーケンスとしてモデル化されます。固有の音響単位のセットが反復トレーニングによって発見されます。これらの変更には、音声データのマッピングのトレーニングが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-10">
        <br><font color="black">2020-09-10</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
