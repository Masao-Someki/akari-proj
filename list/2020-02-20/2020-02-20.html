<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-02-20の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Rnn-transducer with language bias for end-to-end Mandarin-English
  code-switching speech recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.SD/paper_0.html">
      Rnn-transducer with language bias for end-to-end Mandarin-English
  code-switching speech recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これにより、モデルはトランスクリプションから言語識別情報を直接学習し、追加のLIDモデルは必要ありません。マンダリン-英語CSコーパスSEAMEでアプローチを評価します。ポイント。 
[要約]言語のアイデンティティを使用してモデルにバイアスをかけ、csポイントを予測します。マンダリンでのアプローチを評価します-英語csコーパスシーム
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Gradient-Adjusted Neuron Activation Profiles for Comprehensive
  Introspection of Convolutional Speech Recognition Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.SD/paper_1.html">
      Gradient-Adjusted Neuron Activation Profiles for Comprehensive
  Introspection of Convolutional Speech Recognition Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      GradNNPを使用して、ANNでデータが処理される方法について洞察を得る方法を示します。音声データは画像データよりも複雑で解釈しにくいため、このような手法をコンピュータービジョンから音声認識に適応させるのは簡単ではありません。 、ディープニューラルネットワークの機能と表現を解釈する手段として、勾配調整ニューロン活性化プロファイル（GradNAP）を導入します。 
[ABSTRACT]イントロスペクション手法は、人工ニューラルネットワークの仕組みをよりよく理解するために提案されています。ネットワークのより良い理解と理解を得るために、イントロスペクション手法が提供されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Speech Corpus of Ainu Folklore and End-to-end Speech Recognition for
  Ainu Language -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.SD/paper_2.html">
      Speech Corpus of Ainu Folklore and End-to-end Speech Recognition for
  Ainu Language
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本稿では、音声コーパスの開発と、アイヌ語のエンドツーエンドASRの構造とパフォーマンスについて報告します。アイヌ語は、日本の民族グループの1つであるアイヌの人々によって話されている、書かれていない言語です。 80％と90％の単語と電話の精度は、スピーカーを閉じた設定で達成されました。 
[ABSTRACT] ainuは、ユネスコとアーカイブによって非常に危険にさらされていると認識されています。このプロジェクトは、注釈付き言語アーカイブの開発に貢献するために開始されました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-16">
        <br>2020-02-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multilogue-Net: A Context Aware RNN for Multi-modal Emotion Detection
  and Sentiment Analysis in Conversation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.SD/paper_3.html">
      Multilogue-Net: A Context Aware RNN for Multi-modal Emotion Detection
  and Sentiment Analysis in Conversation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたモデルは、さまざまな精度と回帰メトリックに関する2つのベンチマークデータセットで最先端を実行します。会話の感情分析と感情検出は、さまざまな種類のデータを活用するさまざまなアプリケーションで重要ですモデルの実装は公開されており、github.com / amanshenoy / multilogue-netで見つけることができます
[要約]合成感情の検出と感情分析は特に有用です。予測を生成できるモダリティ。現在のシステムでは、異なる種類の音声の組み合わせを使用します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Deep compositional robotic planners that follow natural language
  commands -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_0.html">
      Deep compositional robotic planners that follow natural language
  commands
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この2つを組み合わせることで、新しいマップ、新しい種類の障害、トレーニングセットでは発生しないより複雑な文への一般化が可能になります。階層的な深層ネットワークは、プランナーが環境を探索する方法を制御し、計画されたパスがいつ達成されるかを決定しますネットワークとプランナー間の搾取と探索をトレードオフする各動きの信頼度を推定します。環境の機能を抽出するCNNを共同で取得するにもかかわらず、モデルのトレーニングにはほとんどデータは必要ありません。言葉。 
[ABSTRACT] planは、環境を制御する機能を含むコマンドの解析に従って構造化された深いネットワークを組み合わせます。ネットワークは、タスクに関する情報が欠落している場合にほぼ最適な動作をするように設計されていますが、ネットワークは、環境から利用可能です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-12">
        <br>2020-02-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Retrospective and Prospective Mixture-of-Generators for Task-oriented
  Dialogue Response Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_1.html">
      Retrospective and Prospective Mixture-of-Generators for Task-oriented
  Dialogue Response Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      MoGNetは、チェアジェネレーターと複数のエキスパートジェネレーターで構成されています。DRG用の新しいジェネレーター混合ネットワーク（MoGNet）を提案します。ここでは、応答の各トークンが分布の混合から引き出されると想定しています。 DRG）は、タスク指向の対話システム（TDS）の重要なコンポーネントです。 
[ABSTRACT] mognetはdrgのネットワークです。各トークンはシステムの混合物から引き出されると仮定します。議長は複数のエキスパートを調整し、生成した出力を組み合わせてより適切な応答を生成します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-19">
        <br>2019-11-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Reconfigurable Interaction for MAS Modelling -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_2.html">
      Reconfigurable Interaction for MAS Modelling
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      マルチエージェントシステムについてモデル化および推論するための形式を提案します。また、この拡張機能の充足可能性とモデルチェックの複雑さを研究します。エージェントは、さまざまなモードで対話および通信できるようになります。エージェントは、動的に同期し、データを交換し、動作を適合させ、通信インターフェイスを再構成できます。 
[要約]エージェントが異なるモードで対話および通信できるようにすることで、エージェントは共同タスクを遂行できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-26">
        <br>2019-06-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Rnn-transducer with language bias for end-to-end Mandarin-English
  code-switching speech recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_3.html">
      Rnn-transducer with language bias for end-to-end Mandarin-English
  code-switching speech recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、問題を軽減するための言語バイアスを備えた改良型リカレントニューラルネットワークトランスデューサー（RNN-T）モデルを提案します。言語アイデンティティを使用してモデルにバイアスをかけ、CSポイントを予測します。エンドツーエンドのコードスイッチング（CS）音声認識のパフォーマンスを向上させるために利用されます。 
[要約]言語のアイデンティティを使用してモデルにバイアスをかけ、csポイントを予測します。マンダリンでのアプローチを評価します-英語csコーパスシーム
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: LayoutLM: Pre-training of Text and Layout for Document Image
  Understanding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_4.html">
      LayoutLM: Pre-training of Text and Layout for Document Image
  Understanding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      フォームの理解（70.72から79.27）、領収書の理解（94.02から95.24）、ドキュメントイメージの分類（93.07から94.42）など、いくつかのダウンストリームタスクで新しい最先端の結果を達成します。私たちの知識では、文書レベルの事前トレーニングのために単一のフレームワークでテキストとレイアウトが共同で学習されるのは初めてです。事前トレーニング技術は、近年さまざまなNLPタスクで検証されています。 
[概要] nlpの事前トレーニング手法は正常に実装されましたが、ドキュメントイメージの理解に不可欠なレイアウトとスタイル情報を無視しながら、テキストレベルの操作にほぼ焦点を当てていました。フォームの理解とレシートの理解を含む下流のタスク
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-31">
        <br>2019-12-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: VQA-LOL: Visual Question Answering under the Lens of Logic -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_5.html">
      VQA-LOL: Visual Question Answering under the Lens of Logic
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、論理演算を含む質問でVQAデータセットの拡張を構築し、ベースラインを確立するために同じモデルを再トレーニングします。さらに、論理構成の学習と学習の改善を示すモデルをトレーニングする新しい方法論を提案します。 VQAのパフォーマンスを維持します。VQAシステムが質問に回答できる場合、質問の論理的な構成にも回答できる必要があります。 
[要旨]視覚的な質問応答（vqa）を論理変換のレンズを通して接続します。vqaタスクのモデルのパフォーマンスを分析し、そのような質問に正しく答えることが難しいことを示します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Hierarchical models vs. transfer learning for document-level sentiment
  classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_6.html">
      Hierarchical models vs. transfer learning for document-level sentiment
  classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      非自明な階層モデルは、以前のベースラインよりも優れており、5つの言語でドキュメントレベルの感情分類に関する学習を転送することを示します。互いに複雑な関係にある小さな断片-段落、文、およびトークン-。 
[ABSTRACT]研究は、感情分類モデルが以前のベースラインよりも優れており、5つの言語での文書レベルの感情分類の学習を移行することを示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Non-Autoregressive Dialog State Tracking -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_7.html">
      Non-Autoregressive Dialog State Tracking
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、次の2つの側面が不十分です。（1）モデルは、ドメインとスロット間の信号を明示的に学習して、（ドメイン、スロット）ペア間の潜在的な依存関係を検出できません。 （2）既存のモデルは、対話が複数のドメインおよび複数のターンにわたって進化する場合、高い時間コストが発生する自己回帰アプローチに従います。タスク指向の対話のための対話状態追跡（DST）の最近の取り組みは、オープンボキャブラリーまたは生成に向けて進歩していますモデルが対話履歴自体からスロット値候補を生成できるベースのアプローチ。我々の経験的結果は、モデルがMultiWOZ 2.1コーパス上のすべてのドメインにわたって最先端の共同精度を達成し、対話の履歴は時間とともに拡大するため、モデルは以前の最新技術よりも1桁低くなります。 
[要約]これらのアプローチは、特に動的なスロット値を持つ複雑なダイアログドメインで、良好なパフォーマンスの向上を示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Tensorized Embedding Layers for Efficient Model Compression -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_8.html">
      Tensorized Embedding Layers for Efficient Model Compression
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、語彙が大きい場合、対応する重み行列は膨大になる可能性があり、限られたリソース設定での展開が不可能になります。入力語を実ベクトルに変換する埋め込み層は、自然言語処理で使用されるディープニューラルネットワークの重要なコンポーネントです。 。テンソルトレイン（TT）分解に基づいて埋め込みレイヤーをパラメーター化する新しい方法を導入します。これにより、無視できるほどのドロップまたはパフォーマンスのわずかな向上を犠牲にしてモデルを大幅に圧縮できます。 
[要約]自然言語の幅広いベンチマークでメソッドを評価します。mlpsからlstmsおよびトランスフォーマーまで、さまざまなアーキテクチャのパフォーマンスと圧縮率のトレードオフを分析します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-01-30">
        <br>2019-01-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Speech Corpus of Ainu Folklore and End-to-end Speech Recognition for
  Ainu Language -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_9.html">
      Speech Corpus of Ainu Folklore and End-to-end Speech Recognition for
  Ainu Language
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、話者が閉じた環境で80％と90％の単語と電話の精度が達成されました。この論文では、音声コーパスの開発と、アイヌのエンドツーエンドASRの構造とパフォーマンスを報告します。注釈付き言語アーカイブの開発に貢献するために、アイヌ語の自動音声認識（ASR）のプロジェクトを開始しました。 
[ABSTRACT] ainuは、ユネスコとアーカイブによって非常に危険にさらされていると認識されています。このプロジェクトは、注釈付き言語アーカイブの開発に貢献するために開始されました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-16">
        <br>2020-02-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Toward Making the Most of Context in Neural Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_10.html">
      Toward Making the Most of Context in Neural Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、当社のモデルがTransformerベースラインおよび最新のベースラインで最大2.1 BLEUの実質的なマージンを持つ以前のドキュメントレベルNMTモデルよりも優れていることを示しています。また、隣接する2つをはるかに超えるコンテキストの利点を示す分析も提供しますこの統一されたアプローチにより、センテンスレベルとドキュメントレベルのデータを個別にトレーニングする必要なく、標準データセットでモデルをエレガントにトレーニングできます。 
[概要]新しいドキュメント-レベルnmtの概念は、標準のデータセットでエレガントに訓練できるように設計されています。以前の研究ではグローバルコンテキストを明確に利用していなかったと主張しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language
  Representation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_11.html">
      KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language
  Representation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      KEPLERでは、エンティティのテキスト記述を埋め込みとしてPLMでエンコードし、KEと言語モデリングの目的を共同で最適化します。このペーパーでは、知識埋め込みと事前トレーニングされたLanguagE表現（KEPLER）の統一モデルを提案します。事実に関する知識をPLMに統合するだけでなく、テキスト内の豊富な情報を通じてKEを効果的に学習できます。データセットはhttps://deepgraphlearning.github.io/project/wikidata5mから取得できます。 
[ABSTRACT] keplerでは、エンベディングとしてplmを使用してエンティティの文学的記述をエンコードします。ただし、従来のkeモデルはリッチテキストデータを使用しません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br>2019-11-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Joint Extraction of Entities and Relations Based on a Novel
  Decomposition Strategy -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_12.html">
      Joint Extraction of Entities and Relations Based on a Novel
  Decomposition Strategy
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      前者のサブタスクは、ターゲットリレーションに関与する可能性のあるすべてのヘッドエンティティを区別することであり、後者は、抽出された各ヘッドエンティティに対応するテールエンティティとリレーションを識別することです。提案されたスパンベースのタギングスキームに基づく問題は、階層境界タガーとマルチスパンデコードアルゴリズムによって簡単に解決されます。合理的な分解戦略により、モデルは異なるステップ間のセマンティック相互依存性も完全にキャプチャできます。無関係なエンティティペアからのノイズを削減します。 
[ABSTRACT]ジョイント抽出タスクは、2つの個別のサブタスクに分解されました。これらの2つのサブタスクは、提案されたスパンベースのタグ付けスキームに基づくさらなるターゲットです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-10">
        <br>2019-09-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multilogue-Net: A Context Aware RNN for Multi-modal Emotion Detection
  and Sentiment Analysis in Conversation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_13.html">
      Multilogue-Net: A Context Aware RNN for Multi-modal Emotion Detection
  and Sentiment Analysis in Conversation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたモデルは、さまざまな精度と回帰メトリックに関する2つのベンチマークデータセットで最先端を実行します。会話の感情分析と感情検出は、さまざまな種類のデータを活用するさまざまなアプリケーションで重要です。マルチモーダル感情検出および感情分析は、アプリケーションが利用可能なデータに従って、利用可能なモダリティの特定のサブセットを使用して関連する予測を生成できるため、特に有用です。 
[要約]合成感情の検出と感情分析は特に有用です。システムは、利用可能なモダリティの特定のサブセットを使用して予測を生成できます。現在のシステムシステムは、異なる種類の音声の組み合わせを使用します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: FreeLB: Enhanced Adversarial Training for Natural Language Understanding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_14.html">
      FreeLB: Enhanced Adversarial Training for Natural Language Understanding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたアプローチの有効性を検証するために、自然言語理解と常識的な推論タスクのためのトランスフォーマーベースのモデルにそれを適用します。ラベル保存入力摂動の最大リスクを最小化する敵対的トレーニングは、言語モデルの一般化.. GLUEベンチマークの実験では、微調整段階にのみ適用した場合、BERTベースモデルの全体のテストスコアを78.3から79.4に、RoBERTaラージモデルを88.5から88.8に改善できることが示されています。 
[ABSTRACT] freelbは、埋め込み空間のより高い不変性を促進する新しい敵対訓練アルゴリズムです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-25">
        <br>2019-09-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: LAMBERT: Layout-Aware language Modeling using BERT for information
  extraction -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_15.html">
      LAMBERT: Layout-Aware language Modeling using BERT for information
  extraction
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーでは、ローカルセマンティクスが非自明なレイアウトに影響されるドキュメントを理解する問題への新しいアプローチを紹介します。つまり、Transformerアーキテクチャを、レイアウトで定義されたグラフィカル機能を使用できるように変更します。従来の言語モデリングタスクで事前トレーニングされたモデルからトレーニングプロセスを開始することで、言語のセマンティクスをゼロから再学習する必要がなくなりました。 
[要約]トランスフォーマーアーキテクチャを変更して、レイアウトで定義された視覚的な機能を使用できるようにしました。トランスフォーマーアーキテクチャは、既存の既存の機能を使用するように設計されています。文法を最初から再学習する必要はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Compressing BERT: Studying the Effects of Weight Pruning on Transfer
  Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_16.html">
      Compressing BERT: Studying the Effects of Weight Pruning on Transfer
  Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      パフォーマンスに影響を与えることなく、タスクごとに個別にではなく、事前トレーニング中にBERTを1回プルーニングできると結論付けました。プルーニングは、3つの広いレジームで転移学習に影響することがわかります。 -下流のタスクに転送される情報を訓練します。 
[ABSTRACT]プルーニングは、3つの広範なレジームでの転移学習に影響します。プルーニングの影響は、プルーニングの30％などです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CodeBERT: A Pre-Trained Model for Programming and Natural Languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_17.html">
      CodeBERT: A Pre-Trained Model for Programming and Natural Languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      モデルパラメータを微調整することにより、2つのNL-PLアプリケーションでCodeBERTを評価します。結果は、CodeBERTが自然言語コード検索とコードドキュメント生成タスクの両方で最先端のパフォーマンスを達成することを示しています。ニューラルアーキテクチャ、および置換トークン検出の事前トレーニングタスクを組み込んだハイブリッド目的関数でトレーニングします。これは、ジェネレーターからサンプリングされたもっともらしい選択肢を検出することです。 
[要約]これにより、nl-plペアのバイモーダルデータとユニモーダルデータの両方を利用できます。前者はモデルトレーニング用の入力トークンを提供し、後者はより良いジェネレーターの学習に役立ちます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Differential-form Pullback Programming Language for Higher-order
  Reverse-mode Automatic Differentiation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_18.html">
      A Differential-form Pullback Programming Language for Higher-order
  Reverse-mode Automatic Differentiation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      逆方向の自動微分（AD）-逆伝播の一般化-が差分1形式のプルバックとして自然に表現できるという観察に基づいて、一流の差分演算子を使用して単純な高次プログラミング言語を設計します。そして、逆モードADを正確にシミュレートする削減戦略を提示します。Hahn-Banach分離定理を満たす微分$ \ lambda $ -categoryで言語を解釈することにより削減戦略を正当化し、削減戦略が正確に逆をキャプチャすることを示します真に高次の設定でのモードAD 
[要約]削減戦略は、フォームフォームを形成する抜け穴に基づいています。これは、戦略が真に高次の設定でリバースモード広告をキャプチャすることを示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural
  Language Understanding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_19.html">
      The Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural
  Language Understanding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      効率的な生産展開を可能にするために、MT-DNNはマルチタスクナレッジ蒸留をサポートします。これにより、パフォーマンスを大幅に低下させることなく、ディープニューラルモデルを大幅に圧縮できます。 NLUタスク。さまざまな目的（分類、回帰、構造化予測）およびテキストエンコーダー（RNN、BERT、RoBERTa、UniLMなど）を使用します。一般的なおよび生物医学ドメイン。 
[概要] pytorchとトランスフォーマーに基づいて構築されたmt-dnnは、広範囲のnluタスクの迅速なカスタマイズを容易にするように設計されています。ソフトウェアと事前にトレーニングされたモデルは公開されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Open Knowledge Enrichment for Long-tail Entities -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_20.html">
      Open Knowledge Enrichment for Long-tail Entities
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この記事では、欠落しているプロパティを予測し、オープンWebからロングテールエンティティの真の事実を推測する、知識の強化に対する本格的なアプローチを提案します。合成および実世界のデータセットに関する実験と、関連する研究との比較により、アプローチの実現可能性と優位性が実証されています。 
[ABSTRACT]現在のkcsの多くは非常に大きいですが、不完全であると広く認識されています。しかし、それらは濃縮問題の一部のみに取り組んでいます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-15">
        <br>2020-02-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Tree-structured Attention with Hierarchical Accumulation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/cs.CL/paper_21.html">
      Tree-structured Attention with Hierarchical Accumulation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このアプローチは、4つのIWSLT翻訳タスクとWMT&#39;14英語-ドイツ語翻訳タスクでSOTAメソッドよりも優れています。一方、Tree-LSTMなどの専用モデルは、階層構造を明示的にモデル化しながら、Transformerほど効率的に実行しません。また、3つのテキスト分類タスクに関して、TransformerおよびTree-LSTMよりも改善されています。 
[概要] 14歳のモデルには、構造をエンコードするための多くの作業がありません。また、トランスフォーマーとツリーを改善します-lstm
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Speech-driven facial animation using polynomial fusion of features -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/eess.AS/paper_0.html">
      Speech-driven facial animation using polynomial fusion of features
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これは、機能の1次相互作用のみを考慮し、高次相互作用を無視します。ビデオ品質、視聴覚同期、まばたきの生成に関する一連のメトリックで評価された生成ビデオの実験を通じて、このアプローチの適合性を示します。駆動の顔面アニメーションでは、音声信号を使用して、話している顔のリアルなビデオを生成します。 
[要約]深層学習の手法では、顔との会話が必要です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-12">
        <br>2019-12-12
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Rnn-transducer with language bias for end-to-end Mandarin-English
  code-switching speech recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/eess.AS/paper_1.html">
      Rnn-transducer with language bias for end-to-end Mandarin-English
  code-switching speech recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      マンダリン-英語CSコーパスSEAMEでアプローチを評価します。これにより、転写から直接言語識別情報を学習するモデルが促進され、追加のLIDモデルは不要です。最近、言語識別情報がパフォーマンスの向上に利用されていますエンドツーエンドのコード切り替え（CS）音声認識。 
[要約]言語のアイデンティティを使用してモデルにバイアスをかけ、csポイントを予測します。マンダリンでのアプローチを評価します-英語csコーパスシーム
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A comparative study of estimating articulatory movements from phoneme
  sequences and acoustic features -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/eess.AS/paper_2.html">
      A comparative study of estimating articulatory movements from phoneme
  sequences and acoustic features
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      R2の場合、調音運動の推定にアテンションネットワークが使用されますが、R1およびR3にはBLSTMネットワークが使用されます。10人の被験者の音響調音データの実験により、推定手法により平均相関係数0.85、0.81 R1、R2、およびR3の場合はそれぞれ0.81。この作業では、3つの異なる入力表現から調音運動を推定します。R1）音響信号、R2）音素シーケンス、R3）タイミング情報付き音素シーケンス。 
[概要]調音運動は言語情報からのみ予測できます。分析では、注意ネットワークはタイミング情報なしで音素シーケンス（r2）のみを使用しますが、調音運動を予測するための推定入札になります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-31">
        <br>2019-10-31
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Gradient-Adjusted Neuron Activation Profiles for Comprehensive
  Introspection of Convolutional Speech Recognition Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/eess.AS/paper_3.html">
      Gradient-Adjusted Neuron Activation Profiles for Comprehensive
  Introspection of Convolutional Speech Recognition Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      GradNAPを使用して、ANNでデータが処理される方法についての洞察を得る方法を示します。これには、機能を視覚化するさまざまな方法と、特定のネットワークの任意のレイヤーの異なる入力グループの埋め込みを比較するためのGradNAPのクラスター化が含まれます.GradNAPは特性応答です予測のためのニューロンの関連性を組み込んだ特定の入力グループへのANNの。 
[ABSTRACT]イントロスペクション手法は、人工ニューラルネットワークの仕組みをよりよく理解するために提案されています。ネットワークのより良い理解と理解を得るために、イントロスペクション手法が提供されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Speech Corpus of Ainu Folklore and End-to-end Speech Recognition for
  Ainu Language -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/eess.AS/paper_4.html">
      Speech Corpus of Ainu Folklore and End-to-end Speech Recognition for
  Ainu Language
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、話し手が閉じた環境で80％と90％の単語と電話の精度が達成されました。この論文では、音声コーパスの開発とアイヌのエンドツーエンドASRの構造とパフォーマンスを報告します。 4つのモデリングユニット（電話、音節、ワードピース、および単語）で、音節ベースのモデルが、単語と電話の認識精度の両方で最高のパフォーマンスを発揮したことがわかりました。 
[ABSTRACT] ainuは、ユネスコとアーカイブによって非常に危険にさらされていると認識されています。このプロジェクトは、注釈付き言語アーカイブの開発に貢献するために開始されました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-16">
        <br>2020-02-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multilogue-Net: A Context Aware RNN for Multi-modal Emotion Detection
  and Sentiment Analysis in Conversation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/eess.AS/paper_5.html">
      Multilogue-Net: A Context Aware RNN for Multi-modal Emotion Detection
  and Sentiment Analysis in Conversation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたモデルは、さまざまな精度と回帰メトリックに関する2つのベンチマークデータセットで最先端を実行します。会話の感情分析と感情検出は、さまざまな種類のデータを活用するさまざまなアプリケーションで重要です。マルチモーダル感情検出および感情分析は、アプリケーションが利用可能なデータに従って、利用可能なモダリティの特定のサブセットを使用して関連する予測を生成できるため、特に有用です。 
[要約]合成感情の検出と感情分析は特に有用です。システムは、利用可能なモダリティの特定のサブセットを使用して予測を生成できます。現在のシステムシステムは、異なる種類の音声の組み合わせを使用します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Dynamic contrast enhanced MRI with clinical hepatospecific MRI contrast agents in pigs: initial experience -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/biorxiv.physiology/paper_0.html">
      Dynamic contrast enhanced MRI with clinical hepatospecific MRI contrast agents in pigs: initial experience
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      
[要約]ダイナミックコントラストの強化（e）-mriは実験的にヒトの肝機能を測定するために使用されますが、ブタの肝臓では特定されていません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Bile Acid pool composition and Gallbladder function are controlled by TGR5 to protect the liver against Bile Acid overload -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-02-20/biorxiv.physiology/paper_1.html">
      Bile Acid pool composition and Gallbladder function are controlled by TGR5 to protect the liver against Bile Acid overload
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      
[要旨] baの生存率は、baプールをより親水性のプールにシフトすることにより改善されました。これは患者で見られ、より疎水性のbaプールは肝切除後の不利な結果と相関しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-19">
        <br>2020-02-19
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
