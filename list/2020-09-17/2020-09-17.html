<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-09-17の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Similarity-based data mining for online domain adaptation of a sonar ATR
  system -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.SD/paper_0.html">
      <font color="black">Similarity-based data mining for online domain adaptation of a sonar ATR
  system</font>
    </a>
  </h2>
  <font color="black">幅広いシミュレーション環境での比較パフォーマンス分析を提示し、以前に見たことのない環境への迅速な適応のために私たちの方法を使用する利点を強調します。フィールドデータ収集の高価な性質により、トレーニングデータの欠如がパフォーマンスを制限することがよくあります。自動ターゲット認識（ATR）システムの概要。新しいデータ選択方法を使用したATRアルゴリズムのオンライン微調整により、この問題に対処することを提案します。 
[要約]提案されたデータ-マイニングアプローチは視覚的な類似性に依存し、ハードマイニング手法よりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Deep Learning in Photoacoustic Tomography: Current approaches and future
  directions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/eess.IV/paper_0.html">
      <font color="black">Deep Learning in Photoacoustic Tomography: Current approaches and future
  directions</font>
    </a>
  </h2>
  <font color="black">迅速な画像形成の必要性と、臨床ワークフローの制約から生じるデータ取得の実際的な制限は、新しい画像再構成の課題を提示しています。画像再構成には多くの古典的なアプローチがありますが、不完全または不完全なデータの影響を改善する正確な事前分布を組み込むことは困難であり、アルゴリズムが遅くなります。このペーパーでは、学習した画像再構成に対する3つのプロトタイプ的なアプローチの簡潔なチュートリアルのデモも提供します。 
[ABSTRACT]迅速な画像形成の必要性とデータ取得に対する実際的な制限が新しい課題を提示しています。これらの多くは、新しい技術を古典的な観点から理解する方法の例であり、有用な洞察を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Sensor Data Fusion for Cloud Removal in Global and All-Season
  Sentinel-2 Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/eess.IV/paper_1.html">
      <font color="black">Multi-Sensor Data Fusion for Cloud Removal in Global and All-Season
  Sentinel-2 Imagery</font>
    </a>
  </h2>
  <font color="black">私たちのデータセットは、相互に登録されたレーダーと光学観測の全球サンプルを含む、曇りと雲なしで最初に公に利用可能になりました。どちらの極値にも対応し、提案されたデータセットでそのパフォーマンスを評価できる新しいモデル。クラウドでカバーされた情報の再構築に関する多くの以前の研究がありますが、以前の研究はしばしば狭く定義された関心領域に限定され、アプローチは、さまざまな雲のカバレッジで、または異なる地域や季節で取得された多様な観測セットに一般化できます。 
[ABSTRACT]宇宙からの地球の画像を介して取得される光学観測の大部分は雲の影響を受けます。どちらの極値にも対応し、提案されたデータセットでそのパフォーマンスを評価できる新しいモデルを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Video Compression with CNN-based Post Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/eess.IV/paper_2.html">
      <font color="black">Video Compression with CNN-based Post Processing</font>
    </a>
  </h2>
  <font color="black">このネットワークは、知覚的に刺激された損失関数で訓練されており、知覚的品質評価（VMAF）に基づいて再構成品質がさらに改善され、平均コーディングゲインはVVCに対して13.9％、AV1に対して10.5％向上しています。ディープラーニングの進歩に触発され、 2つの最新のコーディング標準であるVVCとAV1と統合された、新しいCNNベースの後処理アプローチを提案します。近年、ビデオ圧縮技術は、高品質で臨場感あふれるビデオコンテンツ。 
[要約]結果は、さまざまな空間解像度でテストされたすべてのシーケンスで一貫したコーディングゲインを示し、平均のビットレートの節約はそれぞれ元のvvcおよびav1に対して4. 0％および5. 8％です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: RegQCNET: Deep Quality Control for Image-to-template Brain MRI Affine
  Registration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/eess.IV/paper_3.html">
      <font color="black">RegQCNET: Deep Quality Control for Image-to-template Brain MRI Affine
  Registration</font>
    </a>
  </h2>
  <font color="black">1つまたは複数の脳画像を共通の参照空間にアフィン登録することは、脳のセグメンテーションや機能分析など、多くの画像処理タスクに必要な前提条件です。したがって、意味のあるタスク固有のしきい値を手動または自動で定義できます。最後に、RegQCNETの精度を通常の画像機能と比較します。 
[要約]提案されたディープラーニングqcは、処理パイプラインのアフィン登録エラーを推定するために、堅牢で高速かつ正確です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-14">
        <br><font color="black">2020-05-14</font>
      </time>
    </span>
</section>
<!-- paper0: Fourier DiffuserScope: Single-shot 3D Fourier light field microscopy
  with a diffuser -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/eess.IV/paper_4.html">
      <font color="black">Fourier DiffuserScope: Single-shot 3D Fourier light field microscopy
  with a diffuser</font>
    </a>
  </h2>
  <font color="black">私たちのディフューザーは、焦点距離が変化するランダムに配置されたマイクロレンズで構成されています。ランダムな位置は、従来のMLAと比較してより大きなFOVを提供し、多様な焦点距離は軸方向の深さの範囲を改善します。ここでは、瞳面のディフューザーを使用して3Dをエンコードする、フーリエDiffuserScopeで大容量の解像度が向上することを示します情報、次に、スパース制約の逆問題を解くことにより、ボリュームを計算的に再構築します。ディフューザーパラメーターに基づいてシステムパフォーマンスを予測するには、数値シミュレーションによって検証される理論的なフレームワークと設計ガイドラインを初めて確立し、次に実験を構築します$ 1000 \ times 1000 \ times 280 $ um $ ^ 3 $ボリュームで$ &lt;3 $ umの横方向および$ 4 $ umの軸方向解像度を達成するシステム。 
[ABSTRACT]モデルモデルは、瞳面のディフューザーを使用して3d情報をエンコードします。次に、スパース性-microbes。を解決してボリュームを数学的に再構築し、システムパフォーマンスを予測します。理論的なフレームワークと設計ガイドラインを初めて確立しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-29">
        <br><font color="black">2020-06-29</font>
      </time>
    </span>
</section>
<!-- paper0: RCNN for Region of Interest Detection in Whole Slide Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/eess.IV/paper_5.html">
      <font color="black">RCNN for Region of Interest Detection in Whole Slide Images</font>
    </a>
  </h2>
  <font color="black">実験では、西オーストラリアの公立病院病理サービスの実際のWSIを使用しました。結果は、RCNNがWSIからのROI検出に効果的に使用できることを示しています。RCNNモデルのトレーニングに60 WSIを使用し、テストに別の12 WSIを使用しました。 
[要約]スライドイメージ全体（wsis）は非常に大きいため、つまりギガピクセル解像度の領域の分析は困難です。rcnnモデルのトレーニングには60 wsisを使用し、テストには別の12 wsisを使用しました。結果はrcnn wsisからのroi検出に効果的に使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: PCA Reduced Gaussian Mixture Models with Applications in Superresolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/eess.IV/paper_6.html">
      <font color="black">PCA Reduced Gaussian Mixture Models with Applications in Superresolution</font>
    </a>
  </h2>
  <font color="black">数値結果は、超解像結果全体に対する次元削減の適度な影響を確認します。幸いなことに、これらの制約のある問題は、通常、多数のサンプルに依存せず、（慣性）近接交互線形化最小化アルゴリズムによって効率的に解決できます。 、SandeepとJacobのアプローチに基づく2Dおよび3D素材画像の超解像にPCA-GMMを適用します。 
[ABSTRACT]この記事は、トピックに2倍の貢献をします。最初に、mステップが解を必要とするアルゴリズムを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Stage CNN Architecture for Face Mask Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/eess.IV/paper_7.html">
      <font color="black">Multi-Stage CNN Architecture for Face Mask Detection</font>
    </a>
  </h2>
  <font color="black">私たちのシステムは、マスクされた顔とマスクされていない顔を検出できるデュアルステージの畳み込みニューラルネットワーク（CNN）アーキテクチャで構成されており、プリインストールされたCCTVカメラと統合できます。フェイスマスクがないインスタンスを検出できるディープラーニングベースのシステムを紹介します適切に使用されます。ただし、このポリシーの実装を手動で追跡することはできません。 
[要約]世界がパンデミックから回復するにつれ、すべての個人の間で不安の波があります。ただし、このポリシーの実施を手動で追跡することは現実的ではありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Decoupling Inherent Risk and Early Cancer Signs in Image-based Breast
  Cancer Risk Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/eess.IV/paper_8.html">
      <font color="black">Decoupling Inherent Risk and Early Cancer Signs in Image-based Breast
  Cancer Risk Models</font>
    </a>
  </h2>
  <font color="black">がんを発症する患者からの画像）：がんの兆候が見られない画像でトレーニングされた固有のリスクモデル、がんまたはがんの初期の兆候を含む画像でトレーニングされたがんの兆候モデル、および患者のすべての画像でトレーニングされた融合モデル癌の診断..結果として、融合モデルは、早期の癌の兆候がすでに見える場合に医師が予防措置を推奨するように導く可能性があります。ただし、トレーニングデータの選択がネットワークが学習するパターンに影響を与えるため、このようなモデルを使用する場合は注意が必要です。識別します。 
[ABSTRACT]これらのモデルは、さまざまなパターンに焦点を当てた特徴的な機能を学習します。これは、パフォーマンスの対比に変換されます。リスクモデルは、より良い結果を開発するために使用できるディープニューラルネットワークに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-11">
        <br><font color="black">2020-07-11</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Sinogram Completion with Image Prior for Metal Artifact Reduction
  in CT Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/eess.IV/paper_9.html">
      <font color="black">Deep Sinogram Completion with Image Prior for Metal Artifact Reduction
  in CT Images</font>
    </a>
  </h2>
  <font color="black">コンピュータ断層撮影（CT）は、医療診断、評価、および治療計画とガイダンスに広く使用されています。金属トレースの境界で完成した投影の連続性を改善し、再構成されたCT画像の新しいアーチファクトを軽減するために、別のトレーニングを行いますニューロネットワーク（PriorNet）は、サイノグラムの学習をガイドするための適切な事前画像を生成し、さらに新しい残差サイノグラム学習戦略を設計して、事前画像情報を効果的に利用してサイノグラムの完了を改善します。2つのネットワークは、エンドツーエンドで共同でトレーニングされます。以前の画像生成とディープサイノグラム完了手順が互いに利益をもたらすように、微分可能な順投影（FP）演算でファッションを終了します。 
[ABSTRACT]金属物体の存在下でスキャンが影響を受ける可能性があります。これにより、重度の金属アーチファクトが発生し、放射線療法に影響を与える可能性があります。これらは、診断または線量計算にも影響を与える可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Brain tumour segmentation using cascaded 3D densely-connected U-net -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/eess.IV/paper_10.html">
      <font color="black">Brain tumour segmentation using cascaded 3D densely-connected U-net</font>
    </a>
  </h2>
  <font color="black">ネットワークは、2つの異なるアプローチを使用してトレーニングおよびテストされました。すべての腫瘍サブ領域を同時にセグメント化するマルチタスクフレームワークと、一度に1つのサブ領域をセグメント化する3段階カスケードフレームワークです。BraTS20検証データセットの実験結果は、提案されたモデルは、腫瘍全体、腫瘍コア、および腫瘍の増強について、それぞれ平均ダイススコア0.90、0.82、および0.78を達成しました。提案されたアーキテクチャは、Ronneberger et al。 
[要約]新しい方法-脳腫瘍、私たちおよび他の脳疾患-は脳の発達の次の段階で使用できる</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Probabilistic dipole inversion for adaptive quantitativesusceptibility
  mapping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/eess.IV/paper_11.html">
      <font color="black">Probabilistic dipole inversion for adaptive quantitativesusceptibility
  mapping</font>
    </a>
  </h2>
  <font color="black">私たちの実験に基づいて、PDIは、従来のMAPアプローチと比較して不確実性の推定を追加し、一方で、テストデータがトレーニングから逸脱した場合の事前トレーニング済みのCNNの潜在的な問題に対処します。トレーニングデータセットには、真の事後分布からのサンプルが含まれています。学習ベースの事後分布推定法である確率的双極子反転（PDI）は、不確実性推定を使用したMRIの定量的感受性マッピング（QSM）逆問題を解決するために提案されています。 
[ABSTRACT] cnnは、pdi.itで多変量ガウス分布を表すために使用されます。次に、事前トレーニングに含まれていない新しい病理学者がいる患者のデータセットで使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-07">
        <br><font color="black">2020-09-07</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Fingerprints for No-reference Image Quality Assessment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/eess.IV/paper_12.html">
      <font color="black">Domain Fingerprints for No-reference Image Quality Assessment</font>
    </a>
  </h2>
  <font color="black">特徴的な画像の歪みにより、大規模な実験で検証されているように、画質をより正確に評価できます。これにより、提案されたDA-IQAは、比較された最先端のNR-IQA手法のほとんどすべてよりも優れていることがわかります..画像のドメインフィンガープリントは、さまざまな劣化の画像コレクションから学習され、劣化の原因を特定して画像の品質を評価するための固有の特性として使用されます。このために、新しいドメイン対応アーキテクチャを設計します。これにより、歪みの原因と画像の品質の両方を同時に測定できます。 
[要旨]ドメイン-対応iqa（da-iqa）は、ドメインフィンガープリントの概念をnr-iqaフィールドに導入しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-02">
        <br><font color="black">2019-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Anonymization of labeled TOF-MRA images for brain vessel segmentation
  using generative adversarial networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/eess.IV/paper_13.html">
      <font color="black">Anonymization of labeled TOF-MRA images for brain vessel segmentation
  using generative adversarial networks</font>
    </a>
  </h2>
  <font color="black">これにより、医用画像における乏しいデータと匿名化の課題を克服する道が開かれます。さらに、2番目のデータセットで転移学習を使用して合成パッチを適用しました。使用例として脳血管セグメンテーションを分析し、3つのGANを時間でトレーニングしました-画像ラベル生成のための飛行時間型（TOF）磁気共鳴血管造影（MRA）パッチ：1）深い畳み込みGAN、2）グラディエントペナルティ付きのWasserstein-GAN（WGAN-GP）および3）スペクトル正規化付きのWGAN-GP（WGAN- GP-SN）。 
[要旨]キャプターは、予測特性を保持しながら匿名の画像を提供できます。これにより、医療用画像での不十分なデータと匿名化の課題を克服する道が開かれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-09">
        <br><font color="black">2020-09-09</font>
      </time>
    </span>
</section>
<!-- paper0: U-Net with Graph Based Smoothing Regularizer for Small Vessel
  Segmentation on Fundus Image -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/eess.IV/paper_14.html">
      <font color="black">U-Net with Graph Based Smoothing Regularizer for Small Vessel
  Segmentation on Fundus Image</font>
    </a>
  </h2>
  <font color="black">小血管の再構成における提案されたグラフベースの平滑化レギュライザーの可能性は、レギュラライザーがある場合とない場合の従来のUネット上で比較されます。眼底領域の低コントラストの小血管に注目して、グラフベースの平滑レギュライザーを組み合わせるU-netフレームワークの損失関数を使用します。提案されたレギュラライザーは、画像の血管領域と背景領域のグラフラプラシアンを計算することにより、画像を2つのグラフとして扱いました。 
[要約]提案されたレギュラライザーは、画像を、血管領域と画像の背景領域に基づく2つのグラフとして扱いました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Attacks on Co-Occurrence Features for GAN Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/eess.IV/paper_15.html">
      <font color="black">Adversarial Attacks on Co-Occurrence Features for GAN Detection</font>
    </a>
  </h2>
  <font color="black">さらに、ディープラーニングモデルの詳細を完全に理解していれば、精度を0％に下げることができます。ディープラーニングモデルや重みを知らなくても、この方法では精度を98％以上から4％未満に下げることができることを示しています。これらは、このような検出器に対して提示される最初の攻撃です。 
[ABSTRACT]この方法では、深層学習モデルや重みについての知識がなくても、精度を98％から4％未満に下げることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Surgical Video Motion Magnification with Suppression of Instrument
  Artefacts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/eess.IV/paper_16.html">
      <font color="black">Surgical Video Motion Magnification with Suppression of Instrument
  Artefacts</font>
    </a>
  </h2>
  <font color="black">構造的類似性（SSIM）を使用した最近の方法との定量的比較、およびビデオと個々のフレームの時空間断面積を比較することによる定性分析により、内視鏡経鼻経蝶形骨下垂体手術に関する有望な結果を提示します。ツールをシーンに導入する前の単一の心血管サイクルの局所空間周波数情報から、フィルターを使用して、手術画像の空間領域に対してモーション拡大をアクティブにするかどうかを決定できます。完全な手術画像にモーションフィルターを適用すると、ただし、外科用器具からの残留運動に敏感であり、収差運動アーチファクトが原因で実際のアプリケーションを妨げる可能性があります。 
[ABSTRACT]完全な手術画像にモーションフィルターを適用すると、映像に敏感です。ただし、手術機器を使用するため、実際のアプリケーションを妨げる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Evaluating Self-Supervised Pretraining Without Using Labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_0.html">
      <font color="black">Evaluating Self-Supervised Pretraining Without Using Labels</font>
    </a>
  </h2>
  <font color="black">この作業では、画像回転予測の単純な自己監視評価タスクが、標準的な視覚認識タスクとデータセットの監視付きパフォーマンスと高度に相関していることを示します（ランク相関&gt; 0.94）。ラベル付けされたデータを使用していないにもかかわらず、これらのポリシーは監視対象のダウンストリームタスクを使用して決定されたポリシーと同等です。さらに、この評価を使用して、使用する拡張ポリシーなどのトレーニングプロセスに関する決定を行うことはできますか？ 
[要約]教師なしの評価基準を使用して、ラベル付けされたデータなしでトレーニングするときに、研究者と実務家が意思決定を行うのを支援する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Eating Habits Discovery in Egocentric Photo-streams -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_1.html">
      <font color="black">Eating Habits Discovery in Egocentric Photo-streams</font>
    </a>
  </h2>
  <font color="black">結果は、提案されたモデルの優れたパフォーマンスと、個人の栄養習慣を視覚化するその関連性を示しています。1日を通して行われる活動から栄養ルーチンを開示する、食品関連の行動パターン発見モデルを構築します。さらに、カメラ装着者が単独で食事するときの食品関連シーンの識別のためのアプリケーション。 
[要旨]食品関連の行動パターン発見モデルを構築します。カメラ着用者が単独で食事をするときの食品関連シーンの識別のためのアプリケーションを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Person Re-Identification through Contextual Mutual Boosting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_2.html">
      <font color="black">Robust Person Re-Identification through Contextual Mutual Boosting</font>
    </a>
  </h2>
  <font color="black">コンテキスト情報と統計的推論を効果的に活用して、歩行者の位置を特定し、機能を再調整します。最初に、フォアグラウンド機能とバックグラウンド機能をそれぞれ学習するために、畳み込みフロントエンドを共有する2つのブランチを構築します。 、ディープラーニングの開発によって推進されます。 
[ABSTRACT]これらのタイプは実際には一般的ですが、これらは一般的な慣行です。これらには、これらのタイプのre- re-id-正式に正式に正式な再介入が含まれます。これらのタイプには、re-repressingとre---re-が含まれます立地-正式に再999</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: From Design Draft to Real Attire: Unaligned Fashion Image Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_3.html">
      <font color="black">From Design Draft to Real Attire: Unaligned Fashion Image Translation</font>
    </a>
  </h2>
  <font color="black">未調整のファッションデザイン翻訳に関する広範な実験は、最先端の方法に対する私たちの方法の優位性を示しています。D2RNetは、デザインドラフトに対する質感と形状の両方の一貫性を備えた現実的な衣服を生成できます。ミスアライメントの問題を解決するために、主なアイデアは、サンプリングネットワークをトレーニングして、入力を中間状態に適応的に調整し、出力に構造を揃えることです。 
[ABSTRACT]デザイナーはまず、デザインデザインのデザインを調整せずに、ペアのデザインドラフトと実際のファッションアイテムの画像を収集します。このアイデアは、逆変換の問題に効果的に適用でき、それに応じてr2dnetを提示できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-03">
        <br><font color="black">2020-08-03</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning in Photoacoustic Tomography: Current approaches and future
  directions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_4.html">
      <font color="black">Deep Learning in Photoacoustic Tomography: Current approaches and future
  directions</font>
    </a>
  </h2>
  <font color="black">また、学習画像再構成への3つのプロトタイプ的なアプローチの簡潔なチュートリアルデモも提供します。特に、ベイジアンの観点からこれらの新しい手法を理解し、有用な洞察を提供する方法を示します。高解像度3Dを提供できる生物医学的光音響トモグラフィー光吸収に基づく軟組織画像は、研究室から臨床環境への変換が可能になる段階まで進んでいます。 
[ABSTRACT]迅速な画像形成の必要性とデータ取得に対する実際的な制限が新しい課題を提示しています。これらの多くは、新しい技術を古典的な観点から理解する方法の例であり、有用な洞察を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: MSP: An FPGA-Specific Mixed-Scheme, Multi-Precision Deep Neural Network
  Quantization Framework -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_5.html">
      <font color="black">MSP: An FPGA-Specific Mixed-Scheme, Multi-Precision Deep Neural Network
  Quantization Framework</font>
    </a>
  </h2>
  <font color="black">ディープラーニングの途方もない成功により、ディープラーニングモデルをエッジデバイスに展開する差し迫った必要性が存在します。この作業の目新しさは2つあります。（i）線形と非の両方を組み込んだ混合スキームDNN量子化法を提案します。異種のコンピューティングリソース、つまり、FPGA上のLUT（ルックアップテーブル）とDSP（デジタルシグナルプロセッサ）の利用率を高めることを目的とした、量子化のための線形数値システム。既存のすべて（単一スキーム）に注意してください。量子化方法は、深層学習計算で1種類のリソース（MAC（乗累算）演算用のLUTまたはDSP）のみを使用できます。
[要約]これは、dnnモデルの主要なモデルゲート方法です。dnn量子化は、ハードウェアプラットフォームでのdnnモデルの実装</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Compressing Facial Makeup Transfer Networks by Collaborative
  Distillation and Kernel Decomposition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_6.html">
      <font color="black">Compressing Facial Makeup Transfer Networks by Collaborative
  Distillation and Kernel Decomposition</font>
    </a>
  </h2>
  <font color="black">協調蒸留の主なアイデアは、エンコーダとデコーダのペアが排他的な協調関係を構築するという発見に支えられています。これは、低レベルのビジョンタスクの新しい種類の知識と見なされます。カーネル分解では、深さ方向に適用します。元のネットワークから軽量の畳み込みニューラルネットワーク（CNN）を構築するための畳み込みカーネルの分離。広範な実験により、最先端のフェイシャルメイク転送ネットワーク-BeautyGANに適用した場合の圧縮方法の有効性が示されています。 
[要旨]この問題は、協調蒸留とカーネル分解を使用して顔のメイク転送ネットワークを圧縮することで解決します。主なツールは、元のネットワークから軽量の畳み込みニューラルネットワークを構築することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: HOTA: A Higher Order Metric for Evaluating Multi-Object Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_7.html">
      <font color="black">HOTA: A Higher Order Metric for Evaluating Multi-Object Tracking</font>
    </a>
  </h2>
  <font color="black">MOTChallengeベンチマークでのHOTAの有効性を評価し、以前に確立されたメトリックでは考慮されなかったMOTパフォーマンスの重要な側面をキャプチャできることを示します。以前のメトリックは、検出または関連付けの重要性を強調しすぎています。さらに、 HOTAスコアは、追跡パフォーマンスの人間の視覚的評価とよりよく一致します。 
[要約] hotaはサブ検出のファミリーに分解されます。hotaスコアは、追跡パフォーマンスの人間の視覚的評価とよりよく一致します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: DRL-FAS: A Novel Framework Based on Deep Reinforcement Learning for Face
  Anti-Spoofing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_8.html">
      <font color="black">DRL-FAS: A Novel Framework Based on Deep Reinforcement Learning for Face
  Anti-Spoofing</font>
    </a>
  </h2>
  <font color="black">提示された顔の例が本物であるかどうかを判断するために人間が採用した哲学に触発されました。つまり、最初に全体的に例を見て、次に局所的な領域を注意深く観察して、顔のなりすましの問題についてより詳細な情報を取得します。畳み込みニューラルネットワーク（CNN）とリカレントニューラルネットワーク（RNN）に基づく新しいフレームワークを提案します。さらに、RNNを使用して、探索されたサブパッチからローカル情報の表現を順次学習するリカレントメカニズムを紹介します。分類のために、ローカル情報とグローバル情報を融合します。グローバル情報は、CNNを介して元の入力画像から学習できます。 
[ABSTRACT]実験は、一般的に投票のパフォーマンスを観察することを示しています。それは、私たちの方法が一般的に投票の状態を達成できることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Visible Feature Guidance for Crowd Pedestrian Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_9.html">
      <font color="black">Visible Feature Guidance for Crowd Pedestrian Detection</font>
    </a>
  </h2>
  <font color="black">Crowdhuman、Cityperson、Caltech、およびKITTIデータセットでの実験は、可視機能のガイダンスが検出器の期待できるより優れたパフォーマンスの達成に役立つことを示しています。人混みのシーンに集まると、歩行者の検出が困難な問題になります。人間の見えない部分によると、正確な完全な境界ボックスを推測することが難しいためです。 
[ABSTRACT]たとえば、トレーニングとためらいのために可視機能ガイダンス（vfg）と呼ばれるメカニズムを提案します。これらには、ハンガリーのアルゴリズムを使用して人間のインスタンスのパーツを関連付けることが含まれます。特に厳密なiouを使用するmr-2の場合はより効果的です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-23">
        <br><font color="black">2020-08-23</font>
      </time>
    </span>
</section>
<!-- paper0: Similarity-based data mining for online domain adaptation of a sonar ATR
  system -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_10.html">
      <font color="black">Similarity-based data mining for online domain adaptation of a sonar ATR
  system</font>
    </a>
  </h2>
  <font color="black">私たちが提案するデータマイニングアプローチは、視覚的な類似性に依存し、伝統的に採用されているハードマイニング手法よりも優れています。幅広いシミュレーション環境での比較パフォーマンス分析を提示し、以前には見えなかった環境への迅速な適応にこの手法を使用する利点を強調します。 ..新規のデータ選択方法を使用して、ATRアルゴリズムのオンライン微調整を介してこの問題に対処することを提案します。 
[要約]提案されたデータ-マイニングアプローチは視覚的な類似性に依存し、ハードマイニング手法よりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Red Carpet to Fight Club: Partially-supervised Domain Transfer for Face
  Recognition in Violent Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_11.html">
      <font color="black">Red Carpet to Fight Club: Partially-supervised Domain Transfer for Face
  Recognition in Violent Videos</font>
    </a>
  </h2>
  <font color="black">さらに、ドメイン移管の自己注意ベースのモデルを定式化します。このために、さまざまな悪条件下でのクロスドメイン認識を研究するために調整されたWildestFacesデータセットを紹介します。私たちの実験は、WildestFacesによって導入されたユニークな課題を強調していますデータセットと提案されたアプローチの利点。 
[要旨]犯罪事件では、容疑者は以前のビデオ録画ではなく、きれいな肖像画のような写真に基づいて識別する必要があります。目的は、乱暴なビデオのターゲットドメインにクリーンなポーズの画像でトレーニングされた認識モデルを転送することです。トレーニングビデオがサブジェクトのサブセットでのみ利用できる場合</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: FairFace Challenge at ECCV 2020: Analyzing Bias in Face Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_12.html">
      <font color="black">FairFace Challenge at ECCV 2020: Analyzing Bias in Face Recognition</font>
    </a>
  </h2>
  <font color="black">チャレンジの最終フェーズでは36のアクティブなチームが参加し、そのうち10が0.999 AUC-ROCを超え、提案されたバイアスメトリックで非常に低いスコアを達成しました。参加者による一般的な戦略は、前処理、データ分布の均質化、バイアス対応の損失関数とアンサンブルモデル。データセットはバランスが取れていません。これは、公平な結果を提示することになっているAIベースのモデルが不均衡なデータでトレーニングおよび評価される実際のシナリオをシミュレートします。 
[要約]課題の目的は、送信されたアルゴリズムの性別と肌の色の正確さと偏見を評価することでした。データセットはバランスがとれていません。不均衡なデータ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Hybrid-Attention Guided Network with Multiple Resolution Features for
  Person Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_13.html">
      <font color="black">Hybrid-Attention Guided Network with Multiple Resolution Features for
  Person Re-Identification</font>
    </a>
  </h2>
  <font color="black">悪用されたオブジェクト検出アルゴリズムはしばしば不正確なバウンディングボックスを生成するため、実際のアプリケーションでは非現実的です。これにより、既存のアルゴリズムのパフォーマンスが必然的に低下します。一般的に普及している深い畳み込みニューラルネットワーク（CNN）は、歩行者を識別するために高レベルの機能を使用します。 
[ABSTRACT] IDの使用は、多くの場合、画像が揃っている境界ボックスに基づいています。これにより、個人のRE-IDシステムのパフォーマンスが必然的に低下します。次に、埋め込みをいくつかの部分に分割し、それらを再接続して、不正確な境界ボックス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Handwritten Script Identification from Text Lines -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_14.html">
      <font color="black">Handwritten Script Identification from Text Lines</font>
    </a>
  </h2>
  <font color="black">認識は、チェーンコードヒストグラム（CCH）と離散フーリエ変換（DFT）を使用して抽出された特徴に基づいています。提案された方法は、グジャラート語、カンナダ語、マラヤーラム語、オリヤー語、タミル語の7つのインド語スクリプトで記述された800個の手書きテキスト行で実験されています。テルグ語、ウルドゥー語、およびローマ字スクリプトを使用し、サポートベクターマシン（SVM）分類器を使用して95.14％の平均識別率を実現しました。このホワイトペーパーでは、テキスト行レベルで手書きドキュメントからスクリプトを識別するための堅牢な方法を提案します。 
[要約]提案された方法は、7つのインド文字で書かれた800テキスト行で実験されています。7つのインド文字で書かれた800手書きテキストで実験されています。これには、95の自動識別率が含まれます。14％</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Sensor Data Fusion for Cloud Removal in Global and All-Season
  Sentinel-2 Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_15.html">
      <font color="black">Multi-Sensor Data Fusion for Cloud Removal in Global and All-Season
  Sentinel-2 Imagery</font>
    </a>
  </h2>
  <font color="black">最後に、合成データよりも実際のトレーニングモデルの方が優れていることを示し、実際の観測の慎重にキュレーションされたデータセットの必要性を強調します。雲のカバレッジは晴天と絶対カバレッジの間で大きく異なるという観測に基づいて、新しいモデルを提案します。どちらの極端な場合にも対応でき、提案されたデータセットでそのパフォーマンスを評価できます。Googleのデータセットは、共同登録レーダーと光学観測の全天候サンプルを含む最初の一般公開であり、曇りおよび雲なしです。 
[ABSTRACT]宇宙からの地球の画像を介して取得される光学観測の大部分は雲の影響を受けます。どちらの極値にも対応し、提案されたデータセットでそのパフォーマンスを評価できる新しいモデルを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: SLGAN: Style- and Latent-guided Generative Adversarial Network for
  Desirable Makeup Transfer and Removal -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_16.html">
      <font color="black">SLGAN: Style- and Latent-guided Generative Adversarial Network for
  Desirable Makeup Transfer and Removal</font>
    </a>
  </h2>
  <font color="black">アイデンティティシフトの問題を回避するために、ヒストグラムマッチングに基づいてメイクアップスタイルを転送できる、新しい知覚的なメイクアップロスとスタイル不変のデコーダーを提供します。主に生成的敵対的ネットワーク（GAN）を使用して、いくつかの関連作業が提案されています。紙は、革新的なスタイルと潜在誘導型GAN（SLGAN）でギャップを埋めます。 
[ABSTRACT]私たちの提案は、顔のメイク画像を補間して固有の機能を決定できます。また、既存の方法を比較して、ユーザーが望ましいメイク構成を見つけるのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Exploring Font-independent Features for Scene Text Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_17.html">
      <font color="black">Exploring Font-independent Features for Scene Text Recognition</font>
    </a>
  </h2>
  <font color="black">これらの方法は、文字のフォント機能とコンテンツ機能が絡み合っているため、斬新なフォントスタイルのテキストを含むシーン画像でのテキスト認識がうまく機能しません。本質的なパターンのみを表すシーンテキストの生成。生成プロセスは、不注意なテキストに効果的に対処し、既存の画像間変換方法よりも高品質のグリフを生成する空間注意メカニズムによって指示されます。 
[ABSTRACT]最近の多く-提案された方法は、シーンテキストの任意の形状、レイアウト、方向に対応するように特別に設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: RegQCNET: Deep Quality Control for Image-to-template Brain MRI Affine
  Registration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_18.html">
      <font color="black">RegQCNET: Deep Quality Control for Image-to-template Brain MRI Affine
  Registration</font>
    </a>
  </h2>
  <font color="black">最後に、RegQCNETの精度が通常の画像機能と比較されます。したがって、自動化されたディープニューラルネットワークアプローチは、登録品質を自動的に評価するための選択方法として表示されます。現在の研究では、コンパクト3D畳み込みニューラルネットワーク（CNN） RegQCNETとして、登録画像と参照テンプレート間のアフィン登録不一致の振幅を定量的に予測するために導入されました。 
[要約]提案されたディープラーニングqcは、処理パイプラインのアフィン登録エラーを推定するために、堅牢で高速かつ正確です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-14">
        <br><font color="black">2020-05-14</font>
      </time>
    </span>
</section>
<!-- paper0: Information Bottleneck Constrained Latent Bidirectional Embedding for
  Zero-Shot Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_19.html">
      <font color="black">Information Bottleneck Constrained Latent Bidirectional Embedding for
  Zero-Shot Learning</font>
    </a>
  </h2>
  <font color="black">具体的には、不確実性の推定とウェイクスリープ手順を使用して、ノイズを軽減し、モデルの抽象化機能を改善します。広範な実験結果は、ほとんどのベンチマークデータセットのさまざまなZSL設定で、この手法が最先端の手法よりも優れていることを示しています。コードはhttps://github.com/osierboy/IBZSLで入手できます。 
[ABSTRACT]キャリブレーションの偏差とハブネスの問題により、一般化機能が見えないクラスに制限されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: ChoreoNet: Towards Music to Dance Synthesis with Choreographic Action
  Unit -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_20.html">
      <font color="black">ChoreoNet: Towards Music to Dance Synthesis with Choreographic Action
  Unit</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案されたChoreoNetがベースラインメソッドより優れていることを示しています（CAU BLEUスコアで0.622、ユーザー調査スコアで1.59）。これらに触発されて、このような2段階の振り付けアプローチを体系的に調査し、そのような振り付けを組み込むデータセットを構築します知識..私たちのフレームワークはまず、音楽とCAUシーケンス間のマッピング関係を学習するためのCAU予測モデルを考案します。 
[ABSTRACT]人間の振付家は、音楽から2ステージの方法でダンスモーションをデザインします。彼らは、それぞれが一連のダンスモーションを持つ複数のダンスユニット（caus）を考案し、リズム、メロディー、感情のコーシーケンスを配置します音楽</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: TreeGAN: Incorporating Class Hierarchy into Image Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_21.html">
      <font color="black">TreeGAN: Incorporating Class Hierarchy into Image Generation</font>
    </a>
  </h2>
  <font color="black">事前制御では、まずクラス階層をエンコードし、次にそれを事前条件として条件付きジェネレーターにフィードして画像を生成します。ポスト制約では、画像が生成された後、クラス階層との整合性を測定し、整合性スコアを使用してジェネレーターのトレーニングをガイドします。クラス階層を組み込む2つの方法を提案します。事前制御と事後制約です。 
[要旨]クラスを実際に作成する場合、クラスは階層に配置されます。ポスト制約では、画像が生成された後、クラス階層との整合性を測定します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Enhancing Geometric Factors in Model Learning and Inference for Object
  Detection and Instance Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_22.html">
      <font color="black">Enhancing Geometric Factors in Model Learning and Inference for Object
  Detection and Instance Segmentation</font>
    </a>
  </h2>
  <font color="black">CIoU損失を使用したディープモデルのトレーニングは、広く採用されている$ \ ell_n $ -norm損失とIoUベースの損失と比較して、APとARの一貫した改善をもたらします。3つの幾何学的要因は、CIoU損失に組み込まれ、難しい回帰ケースをより適切に区別します。 ..特に、オブジェクトの検出とインスタンスのセグメンテーションでバウンディングボックスの回帰を測定するために重要な3つの幾何学的要素、つまりオーバーラップエリア、正規化された中心点距離、アスペクト比を検討します。 
[要約]このペーパーでは、完全なiou（ciou）損失とクラスターベースのベースを提案します。これらの要因は、困難なケースをより適切に区別するためにciou損失に組み込まれます。それらは、トレーニングおよびトレーニング結果に追加されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-07">
        <br><font color="black">2020-05-07</font>
      </time>
    </span>
</section>
<!-- paper0: A Convolutional LSTM based Residual Network for Deepfake Video Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_23.html">
      <font color="black">A Convolutional LSTM based Residual Network for Deepfake Video Detection</font>
    </a>
  </h2>
  <font color="black">私たちは、ビデオからの入力として連続画像のシーケンスを取り、ディープフェイクビデオのフレーム間に存在する不自然に見えるアーティファクトの検出に役立つ時間情報を学習する、畳み込みLSTMベースの残余ネットワーク（CLRNet）を開発しました。いくつかのディープラーニングベースの検出方法は、これらのディープフェイクを識別するために開発されました。FaceForensics++データセットを使用した厳密な実験により、異なるディープフェイク手法の検出をより一般化することにより、以前に提案された最先端のディープフェイク検出手法の5つよりも優れていることを示しました。同じモデルを使用しています。 
[ABSTRACT]これは、注目度の高いディープフェイク動画の数に基づいています。この方法は、他のディープフェイク方法を検出するために転送できません。ただし、これらの方法は一般化されていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Weakly-Supervised Online Hashing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_24.html">
      <font color="black">Weakly-Supervised Online Hashing</font>
    </a>
  </h2>
  <font color="black">ソーシャルWebサイトの急速な発展に伴い、近年、ユーザー提供のタグを使用してソーシャルイメージが爆発的に増加し、ストリーミング形式で継続的に配信されています。高品質のハッシュコードを学習するために、WOHは、タグのセマンティクスとノイズの除去..高速なクエリ速度と低いストレージコストにより、ハッシュに基づく画像検索の方法が注目を集めています。 
[ABSTRACT]オンライン画像のハッシュ方法はたくさんありますが、教師なし学習を採用するか、高品質のラベルを必要とする教師付きの方法で設計されています。高品質のハッシュコードを学習するには、有効性を考慮して弱い監視を活用しますタグとノイズの除去</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Layered Neural Rendering for Retiming People in Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_25.html">
      <font color="black">Layered Neural Rendering for Retiming People in Video</font>
    </a>
  </h2>
  <font color="black">レイヤーは個別にリタイミングして新しいビデオに再結合できるため、複雑なアクションを描写し、ダンス、トランポリンジャンプ、グループランニングなどの複数の個人が関与する現実世界のビデオのリタイミング効果のリアルで高品質なレンダリングを実現できます。これらの効果は、学習ベースのレイヤー化された専用のビデオ表現を介してこれらの効果を計算的に実現します。ビデオの各フレームは、ビデオ内のさまざまな人物の外観を表す別々のRGBAレイヤーに分解されます。モデルの重要な特性は、は、入力ビデオ内の各人物の直接的な動きのもつれをほぐしますが、影、反射、ゆるい衣服の動きなど、生成されるシーンの変化と各人物を自動的に関連付けます。 
[ABSTRACT]さまざまなモーションを調整したり、特定のアクションの速度を変更したりできます。これらには、速度の変更、または「フリーズ」する人々への切り替えが含まれます。人々がビデオでどのように描かれているかを確認することもできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Modeling User Behaviors in Machine Operation Tasks for Adaptive Guidance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_26.html">
      <font color="black">Modeling User Behaviors in Machine Operation Tasks for Adaptive Guidance</font>
    </a>
  </h2>
  <font color="black">機器オペレーターをサポートするアダプティブガイダンスシステムには、さまざまなスキルや知識レベルを考慮したさまざまなユーザーの行動や、急速に変化するタスク状況など、包括的なモデルが必要です。オペレーターの視線や頭の動きなどの行動機能、手の相互作用とホットスポットは、継続的なユーザースキルの向上に起因する重要な行動傾向とともに観察されました。2段階の方法を使用して、ユーザーの行動の多様性をモデル化しました。プロトタイプの選択とスキルランキングに基づくエクスペリエンスの統合です。 
[要約]たとえば、12人のオペレーターがヘッドマウントrgb-dカメラと静的な視線追跡を使用して実行した2つの縫製タスクの144サンプルを調べました。ユーザーレコードの統合により、次のような豊富で包括的なタスクモデルを開発できました。多様なユーザーに適応するために柔軟に使用-特定のニーズ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-06">
        <br><font color="black">2020-03-06</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Shape Normality Metric for Severity Quantification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_27.html">
      <font color="black">Unsupervised Shape Normality Metric for Severity Quantification</font>
    </a>
  </h2>
  <font color="black">この作業では、一般的な解剖学的形状の異常を客観的に定量化する教師なしの方法について説明します。データから自動的に推測されるランドマークによって形状を表し、多変量ガウス分布によって正常なグループをモデル化します。通常の人口に。 
[要約]形状正規性メトリック（snm）は、正常なサンプルと解剖学のゼロモデルからのみ学習する必要がある</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-18">
        <br><font color="black">2020-07-18</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Adaptation for Outdoor Robot Traversability Estimation from RGB
  data with Safety-Preserving Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_28.html">
      <font color="black">Domain Adaptation for Outdoor Robot Traversability Estimation from RGB
  data with Safety-Preserving Loss</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、ディープラーニングに基づいて、オンボードRGBカメラの視野内のさまざまなルートのトラバーススコアを推定および予測するアプローチを紹介します。実験結果から、このアプローチでは、通過可能な領域を十分に特定でき、次に、a）勾配反転の教師なし適応を通じてドメインシフトに対処し、b）モデルを安全な側で誤ることを奨励することにより、モバイルロボットの特定の安全要件を考慮することで、モデルの機能を強化します。つまり、ロボットを事前に停止させるエラーよりも障害物との衝突を引き起こすエラーにペナルティを課します。 
[ABSTRACT]提案されたモデルは、最先端のディープセグメンテーションモデルに基づいています。ルートの衝突を予測するタスクに合わせて微調整されています。モデルは、通過可能な領域を十分に識別できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: RCNN for Region of Interest Detection in Whole Slide Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_29.html">
      <font color="black">RCNN for Region of Interest Detection in Whole Slide Images</font>
    </a>
  </h2>
  <font color="black">関心領域（ROI）の特定は、病理医が癌の検出やその他の異常について診断の関心領域をさらに分析するための最初のステップです。実験では、西オーストラリアの公立病院病理サービスの実際のWSIを使用しました。 RCNNモデルのトレーニング用のWSI、およびテスト用の12のWSI。 
[要約]スライドイメージ全体（wsis）は非常に大きいため、つまりギガピクセル解像度の領域の分析は困難です。rcnnモデルのトレーニングには60 wsisを使用し、テストには別の12 wsisを使用しました。結果はrcnn wsisからのroi検出に効果的に使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: One-bit Supervision for Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_30.html">
      <font color="black">One-bit Supervision for Image Classification</font>
    </a>
  </h2>
  <font color="black">これにより1ビット（はいまたはいいえ）の情報が提供され、さらに重要なことに、多くの候補クラスから正確なラベルを見つけるよりも、各サンプルに注釈を付けることがはるかに簡単になります。これらの目的のために、負のラベル抑制を既製の半教師あり学習アルゴリズムに組み込んだ多段階トレーニングパラダイムを提案します。 
[ABSTRACT]各サンプルの正確なラベルに基づいてモデルをトレーニングする代わりに、この設定では、モデルが答えから推測が容易かどうかを学習する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Control Design of Autonomous Drone Using Deep Learning Based Image
  Understanding Techniques -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_31.html">
      <font color="black">Control Design of Autonomous Drone Using Deep Learning Based Image
  Understanding Techniques</font>
    </a>
  </h2>
  <font color="black">シミュレーション結果は、ディープラーニングベースの画像理解技術（RetinaNetアリコロニー検出とPSMNet）を提案されたコントローラーに適応させることで、環境障害がある場合に目的のポイントを生成および追跡できることを示しています。数学モデルは、非線形性、不確実性、および結合の問題に対処することにより、高レベルの忠実度を備えた正確なモデル。提案されたPIDAコントローラーは、自律飛行をサポートするために確率的デュアルシンプレックスアルゴリズム（SDSA）によって調整されます。 
[要約]提案されたpidaコントローラーには微分フィルターがあります。これはドローンとクワッドコプターの飛行安定性を改善するように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-27">
        <br><font color="black">2020-04-27</font>
      </time>
    </span>
</section>
<!-- paper0: Perceiving Traffic from Aerial Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_32.html">
      <font color="black">Perceiving Traffic from Aerial Images</font>
    </a>
  </h2>
  <font color="black">フィールドの概念を拡張し、検出されたオブジェクトのスケールだけでなく出力フィーチャの空間情報を記述する複合フィールドの一種であるバタフライフィールドを導入します。ローカリゼーションプロセスを妨げる可能性があるオクルージョンと視野角の変動を克服するために、この制限に対処するために、空中画像からオブジェクトを検出するように調整された、バタフライ検出器と呼ばれるオブジェクト検出方法を提案します。 
[要約]ドローンの概念は、交通のさまざまな側面を制御するために使用できます。これらには、広範囲のオブジェクトのスケールに一般化できない空中画像が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: UXNet: Searching Multi-level Feature Aggregation for 3D Medical Image
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_33.html">
      <font color="black">UXNet: Searching Multi-level Feature Aggregation for 3D Medical Image
  Segmentation</font>
    </a>
  </h2>
  <font color="black">（2）UXNetの継続的な緩和は注意深く設計されており、効率的に微分可能な方法で検索スキームを実行できます。（3）広範な実験により、UXNetの有効性が最近のNASの医療画像セグメンテーション法と比較して実証されています。UXNetにはいくつかの魅力的な利点があります。 
[要約]新しい論文は、3D医用画像セグメンテーションのための新しいnasメソッドを提案します。uxnetは、エンコーダー/デコーダーネットワークのスケールワイズ機能分析とブロックワイズ演算子の両方を検索します。これにより、従来のアンネットアーキテクチャーの柔軟性が大幅に向上します。エンコーダとデコーダの機能表現のみを同等の解像度で集約します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: PL-VINS: Real-Time Monocular Visual-Inertial SLAM with Point and Line -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_34.html">
      <font color="black">PL-VINS: Real-Time Monocular Visual-Inertial SLAM with Point and Line</font>
    </a>
  </h2>
  <font color="black">パブリックEuRocベンチマークデータセットの実験では、GPU並列化なしの低電力CPU @ 1.1 GHzで同じ作業周波数で、VINS-Monoと比較して、私たちの方法の位置エラーが12-16 \％減少していることを示しています。 Pl \ &quot;{u} cker座標のランドマークでは、ライン再投影残差は中点からラインまでの距離としてモデル化され、Pl \&quot; {u} cker座標の最小4パラメータ正規直交表現を繰り返し更新することによって最小化されます。仕事では、修正されたLSDアルゴリズムが、隠れたパラメーターの調整と長さの拒絶戦略を研究することによって提示されます。 
[ABSTRACT]このペーパーでは、pl-vinsを紹介します。これは、最先端のポイントベースのvins-monoに基づいて開発された、ポイントとラインを使用したリアルベースの単眼vinsメソッドです。リアル-vinsメソッドは、ポイントベースのポイントに基づいています- vinsに基づく-mono ::::::::: 9 / vins）.itは、リアルタイム拡張メソッドのリアルタイム機会として使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Fairness Matters -- A Data-Driven Framework Towards Fair and High
  Performing Facial Recognition Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_35.html">
      <font color="black">Fairness Matters -- A Data-Driven Framework Towards Fair and High
  Performing Facial Recognition Systems</font>
    </a>
  </h2>
  <font color="black">最初に、経験的研究が実施されて、ベースラインと学界および主要な産業サービスプロバイダー（Amazon AWSおよびMicrosoft Azure）の最新の研究を含む、年齢予測のための最先端のシステムのパフォーマンスと公平性が評価されます。例えばに向けての等しく多様なDLシステムの動作を検証するために利用される配信外検出に基づいています。したがって、この作業は2つの部分に従います。 
[ABSTRACT]政府は年齢を使用して誰かが犯罪を犯す可能性を推定します。この場合、若い容疑者が関与する可能性が高くなります。advancedAdvanced Advanced Deep Learning（aw）およびAdvanced Advanced State-of-State Technologies（Advanced Advanced Technologyなど）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-11">
        <br><font color="black">2020-09-11</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Stage CNN Architecture for Face Mask Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_36.html">
      <font color="black">Multi-Stage CNN Architecture for Face Mask Detection</font>
    </a>
  </h2>
  <font color="black">研究により、フェイスマスクを着用すると、ウイルス感染のリスクが大幅に軽減されるだけでなく、保護感も得られることが証明されています。ここで鍵となるのはテクノロジーです。当社のシステムは、検出可能なデュアルステージの畳み込みニューラルネットワーク（CNN）アーキテクチャで構成されていますマスクされた顔とマスクされていない顔。事前にインストールされたCCTVカメラと統合できます。 
[要約]世界がパンデミックから回復するにつれ、すべての個人の間で不安の波があります。ただし、このポリシーの実施を手動で追跡することは現実的ではありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: DAER to Reject Seeds with Dual-loss Additional Error Regression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_37.html">
      <font color="black">DAER to Reject Seeds with Dual-loss Additional Error Regression</font>
    </a>
  </h2>
  <font color="black">これらの実験では、この方法により、ターゲットパフォーマンスについて確認する必要のあるシードの数が、強力なベースラインと比較して最大23％削減されることを示しています。これらの課題を念頭に、新しいトレーニング方法と評価指標を提案します次に、シードを追加情報のソースとして使用する2つの問題について、これらのメトリックとメソッドを検証します。クラウドソースシードによるキーポイント条件付き視点推定と自動シードによる階層的シーン分類。 
[ABSTRACT]たとえば、最初のオブジェクトセグメンテーションはビデオオブジェクトセグメンテーションに必要ですが、実際には、群集から-騒々しいパフォーマンスまで、これは当てはまりません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: The 1st Tiny Object Detection Challenge:Methods and Results -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_38.html">
      <font color="black">The 1st Tiny Object Detection Challenge:Methods and Results</font>
    </a>
  </h2>
  <font color="black">1610枚の画像と72651のボックスレベルの注釈が付いています。第1回の小さなオブジェクト検出（TOD）チャレンジは、広い視野を持つ画像で小さなオブジェクトを検出するための新しい正確な方法を開発する研究を奨励し、現在は小さな人物の検出に焦点を当てています。データセットはTODChallengeに使用され、一般にリリースされています。 
[要旨] tinypersonデータセットがtodchallengeに使用され、一般にリリースされました。世界中の約36の参加チームが簡単なチャレンジに参加しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Calibrating Self-supervised Monocular Depth Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_39.html">
      <font color="black">Calibrating Self-supervised Monocular Depth Estimation</font>
    </a>
  </h2>
  <font color="black">次に、スケーリング係数は通常、テスト時にLiDARgroundの真理値から取得され、これらの方法の実際のアプリケーションを大幅に制限します。このホワイトペーパーでは、カメラの構成と環境に関する以前の情報を組み込むことで、スケールのあいまいさを取り除くことができることを示します。そして、深度を直接予測し、依然として自己監視式を使用し、追加のセンサーに依存しません。近年、多くの方法が、自己監視のみを使用して、ニューラルネットワークが深度を学習し、一連の画像の変化をもたらす能力を実証しました。ネットワークは良好なパフォーマンスを達成しますが、見過ごされがちな詳細は、単眼視の固有の曖昧さのために、未知のスケーリング係数まで深度を予測するというものです。 
[ABSTRACT]頻繁に終了-見た目の詳細は単眼視力の欠如の結果です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Multiple Exemplars-based Hallucinationfor Face Super-resolution and
  Editing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_40.html">
      <font color="black">Multiple Exemplars-based Hallucinationfor Face Super-resolution and
  Editing</font>
    </a>
  </h2>
  <font color="black">これらは、それらの出力を調整するときにニューラルネットワークを導きます。このドキュメントでは、以前の一般的な顔に依存するのではなく、一連の見本の使用を検討します。ユーザー調査が実施され、超解像画像がCelebAデータセットの実際の画像とほとんど区別できないことが示されています。 
[ABSTRACT]低解像度の入力に高周波情報が欠落しており、画像コンテンツに関する事前の知識に基づいて幻覚をかける必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Decoupling Inherent Risk and Early Cancer Signs in Image-based Breast
  Cancer Risk Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_41.html">
      <font color="black">Decoupling Inherent Risk and Early Cancer Signs in Image-based Breast
  Cancer Risk Models</font>
    </a>
  </h2>
  <font color="black">結果として、融合モデルは、早期の癌の兆候がすでに見えている場合に医師が予防措置を推奨するように導く可能性があります。しかし、トレーニングデータの選択はネットワークが特定する学習パターンに影響を与えるため、このようなモデルを使用する場合は注意が必要です。これらの3つのモデルが、さまざまなパターンに焦点を当てた特徴的な機能を学習していることを確認します。これは、パフォーマンスの対照につながります。 
[ABSTRACT]これらのモデルは、さまざまなパターンに焦点を当てた特徴的な機能を学習します。これは、パフォーマンスの対比に変換されます。リスクモデルは、より良い結果を開発するために使用できるディープニューラルネットワークに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-11">
        <br><font color="black">2020-07-11</font>
      </time>
    </span>
</section>
<!-- paper0: Infrastructure-based Multi-Camera Calibration using Radial Projections -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_42.html">
      <font color="black">Infrastructure-based Multi-Camera Calibration using Radial Projections</font>
    </a>
  </h2>
  <font color="black">ただし、カメラ間の視覚的な重なりがほとんどない、またはまったくないシステムの外因性キャリブレーションは課題です。次に、固有パラメーターと欠落している変換コンポーネントの両方について解決します。最初に、カメラリグの外因性を単一の未知の変換まで推定します。カメラごとのコンポーネント。 
[ABSTRACT]インフラストラクチャベースのキャリブレーション手法を使用して、カメラの本質を個別に視覚化できます。これらには、単純なアプローチよりも堅牢な、プロセスのカメラの主要なポイントである剖検が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-30">
        <br><font color="black">2020-07-30</font>
      </time>
    </span>
</section>
<!-- paper0: Pooling Methods in Deep Neural Networks, a Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_43.html">
      <font color="black">Pooling Methods in Deep Neural Networks, a Review</font>
    </a>
  </h2>
  <font color="black">1つ目は、パラメーターまたは重みの数を減らし、計算コストを削減することです。ディープニューラルネットワークでプーリング操作を実装する方法はたくさんあります。2つ目は、ネットワークの過剰適合を制御することです。 
[要旨]畳み込みニューラルネットワークは、dnnの特殊なタイプです。いくつかの畳み込み層で構成され、それぞれに活性化関数とプーリング層が続きます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Faster RER-CNN: application to the detection of vehicles in aerial
  images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_44.html">
      <font color="black">Faster RER-CNN: application to the detection of vehicles in aerial
  images</font>
    </a>
  </h2>
  <font color="black">他の2つのベースラインのFaster R-CNN：MunichとGoogleEarth ..残念ながら、Faster R-CNNのような最高の古典的な検出パイプラインでさえ、すぐに使用することはできません。マルチスケールの垂直オブジェクトを使用した日常生活この作業では、高速R-CNNアプローチに基づいて、空中画像タスクに固有の回転等分散を適切に処理する検出フレームワークに変換します。 
[ABSTRACT]フォトインタープリターの作業は、退屈で飽き飽きしています。回転するオブジェクト、低解像度、小さなアート、最も難しい画像は難しい場合があります。システムは、回転の等分散を適切に処理する検出フレームワークです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-09-20">
        <br><font color="black">2018-09-20</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Sinogram Completion with Image Prior for Metal Artifact Reduction
  in CT Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_45.html">
      <font color="black">Deep Sinogram Completion with Image Prior for Metal Artifact Reduction
  in CT Images</font>
    </a>
  </h2>
  <font color="black">この論文では、画像領域とサイノグラム領域ベースのMAR技術の利点を同時に活用することで、金属アーチファクト低減（MAR）の一般化可能なフレームワークを提案します。コンピュータ断層撮影（CT）は、医療診断、評価、および治療に広く使用されています計画とガイダンス..金属トレースの境界で完了した投影の連続性を改善し、再構成されたCT画像の新しいアーティファクトを軽減するには、別のニューラルネットワーク（PriorNet）をトレーニングして、サイノグラム学習をガイドするための適切な事前画像を生成します。より優れたサイノグラム完了のために以前の画像情報を効果的に利用するために、新規の残留サイノグラム学習戦略をさらに設計します。 
[ABSTRACT]金属物体の存在下でスキャンが影響を受ける可能性があります。これにより、重度の金属アーチファクトが発生し、放射線療法に影響を与える可能性があります。これらは、診断または線量計算にも影響を与える可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: EfficientNet-eLite: Extremely Lightweight and Efficient CNN Models for
  Edge Devices by Network Candidate Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_46.html">
      <font color="black">EfficientNet-eLite: Extremely Lightweight and Efficient CNN Models for
  Edge Devices by Network Candidate Search</font>
    </a>
  </h2>
  <font color="black">コードはhttps://github.com/Ching-Chen-Wang/EfficientNet-eLiteで入手できます。一方、EfficientNet-eLiteと呼ばれる非常に軽量なEfficientNetのファミリーが得られます。ImageNetデータセットの評価では、提案されたEfficientNet-eLiteとEfficientNet-HFの両方が、以前の最先端のCNNよりも優れたパラメーターの使用法と精度を示します。 
[ABSTRACT]この実験では、efficientnet-b0から候補cnnモデルを収集し、幅、深さ、入力解像度、および複合スケーリングを通じてさまざまな方法でスケールダウンします。cnnエッジのアプリケーション固有の集積回路（asic）をさらに採用するために、 efficientnetのアーキテクチャを調整します-よりハードウェアを構築するためのエリート-フレンドリーなバージョン、efficientnet-hf</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Geometric Uncertainty in Patient-Specific Cardiovascular Modeling with
  Convolutional Dropout Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_47.html">
      <font color="black">Geometric Uncertainty in Patient-Specific Cardiovascular Modeling with
  Convolutional Dropout Networks</font>
    </a>
  </h2>
  <font color="black">提案されたアプローチで導入された重要な革新は、トレーニングデータから幾何学的不確実性を直接学習する機能です。結果は、幾何学的不確実性が壁せん断応力と速度の大きさの他の不確実性のソースに匹敵するか、それより大きい変動係数をどのように生成するかを示していますが、圧力への影響は限定的です。特に、これは、血管サイズが小さいことを特徴とする解剖学、およびネットワークトレーニング中にまれに見られる局所血管病変に当てはまります。 
[要約]ドロップアウトレイヤーを備えた畳み込みニューラルネットワークアーキテクチャは、最初に血管内腔のセグメンテーションのためにトレーニングされます。主な目的は、血管の内腔表面の正確な観測をベイに維持できるようにすることです。結果は、幾何学的不確実性が他と同等以上の変動のエントリーをどのように生成するかを示します壁のせん断応力と速度の大きさの不確実性の原因</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: GOCor: Bringing Globally Optimized Correspondence Volumes into Your
  Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_48.html">
      <font color="black">GOCor: Bringing Globally Optimized Correspondence Volumes into Your
  Neural Network</font>
    </a>
  </h2>
  <font color="black">広範なアブレーション実験でGOCorモジュールを分析します。このモジュールで生成された対応ボリュームは、シーン内の類似領域を明示的に説明する内部最適化手順の結果です。ただし、このポイントツーポイントの特徴比較は、画像内の複数の類似領域を明確化し、最終タスクのパフォーマンスに深刻な影響を与えます。 
[ABSTRACT] gocorは、特徴相関レイヤーの直接の代替として機能する、完全に区別可能な高密度マッチングモジュールです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Domain-invariant Similarity Activation Map Metric Learning for
  Retrieval-based Long-term Visual Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_49.html">
      <font color="black">Domain-invariant Similarity Activation Map Metric Learning for
  Retrieval-based Long-term Visual Localization</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチの強力な汎化能力は、CMU-Seasonsデータセットの都市部で事前トレーニングされたモデルを使用して、RobotCarデータセットで検証されます。次に、新しい勾配加重類似度活性化マッピング損失（Grad-SAM）が組み込まれ、精度..自己監視方式で埋め込みのメトリック学習を後押しする新しい適応トリプレット損失も提案します。 
[ABSTRACT]これは視覚化方法として効率的かつ効果的な手法です。ローカリゼーションを抽出するには、一般的なアーキテクチャが最初に確率的です。新しい適応トリプレット損失は、埋め込みの学習を促進します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: A Metric Learning Reality Check -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_50.html">
      <font color="black">A Metric Learning Reality Check</font>
    </a>
  </h2>
  <font color="black">過去4年間のディープメトリックラーニングペーパーは常に精度の大幅な進歩を主張しており、多くの場合、10年前のメソッドのパフォーマンスを2倍以上にしています。多くのメトリックラーニングペーパーの実験方法論に欠陥が見つかり、実際の改善が時間はせいぜいわずかなものでした。このホワイトペーパーでは、フィールドを詳細に調べて、これが実際に当てはまるかどうかを確認します。 
[ABSTRACT]論文では、これが正しいかどうかを確認するためにフィールドを詳しく調べます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br><font color="black">2020-03-18</font>
      </time>
    </span>
</section>
<!-- paper0: CogTree: Cognition Tree Loss for Unbiased Scene Graph Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_51.html">
      <font color="black">CogTree: Cognition Tree Loss for Unbiased Scene Graph Generation</font>
    </a>
  </h2>
  <font color="black">まず、認知構造CogTreeを構築して、バイアスされたSGGモデルの予測に基づいて関係を整理します。損失はモデルに依存せず、特別な監視なしでさまざまなSGGモデルに適用できます。このために、新しい認識を提案します。公平なSGGのツリー（CogTree）損失。 
[ABSTRACT]シーングラフ生成（sgg）のパフォーマンスは満足のいくものではありません。これは、実際のシナリオでのデータの欠如に基づいています。代わりに、不偏sggの新しい認識ツリー（cogtree）損失を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: m-arcsinh: An Efficient and Reliable Function for SVM and MLP in
  scikit-learn -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_52.html">
      <font color="black">m-arcsinh: An Efficient and Reliable Function for SVM and MLP in
  scikit-learn</font>
    </a>
  </h2>
  <font color="black">オープンソースのPythonライブラリ「scikit-learn」に実装されたm-arcsinhは、SVMとMLPのそれぞれに効率的で信頼性の高いカーネルとアクティベーション関数として提示されています。実験結果は、SVMとMLPの両方の全体的な競合分類パフォーマンスを示しています。この論文は、逆双曲線正弦関数（ &#39;arcsinh&#39;）の変更（ &#39;m-&#39;）バージョンである &#39;m-arcsinh&#39;について説明します。 
[ABSTRACT]機械学習（ml）ベースのアルゴリズム（サポートマシン（svm）や多層パーセプトロン（mlp）など）で、監視された方法でデータから学習します。カーネルとアクティベーション関数は、複雑さに関係なく、全体的な競争の信頼性を示します含まれる分類タスクの</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Fingerprints for No-reference Image Quality Assessment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_53.html">
      <font color="black">Domain Fingerprints for No-reference Image Quality Assessment</font>
    </a>
  </h2>
  <font color="black">特徴的な画像の歪みにより、大規模な実験で検証されているように、画質をより正確に評価できます。これにより、提案されたDA-IQAは、比較された最先端のNR-IQA手法のほとんどすべてよりも優れていることがわかります..画像のドメインフィンガープリントは、さまざまな劣化の画像コレクションから学習され、劣化の原因を特定して画像の品質を評価するための固有の特性として使用されます。このために、新しいドメイン対応アーキテクチャを設計します。これにより、歪みの原因と画像の品質の両方を同時に測定できます。 
[要旨]ドメイン-対応iqa（da-iqa）は、ドメインフィンガープリントの概念をnr-iqaフィールドに導入しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-02">
        <br><font color="black">2019-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-domain semantic segmentation with pyramidal fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_54.html">
      <font color="black">Multi-domain semantic segmentation with pyramidal fusion</font>
    </a>
  </h2>
  <font color="black">コンテストでは、3つの異なるドメインの7つのベンチマークに同じモデルを提出する必要があります。単一レベルの193次元のソフトマックス出力を使用して、一貫性のない分類に対処します。 
[要約]コンテストでは、3つの異なるドメインの7つのベンチマークに同じモデルを提出する必要があります。シングルレベル193-テクニカルソフトマックス出力に基づいています。これを行うには、log-sum-prob損失によるカスタムの後方ステップを実装し、人口統計を凍結する前に小さな作物を使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchical brain parcellation with uncertainty -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_55.html">
      <font color="black">Hierarchical brain parcellation with uncertainty</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、フラットな不確実性方法のパフォーマンスを上回っており、ラベル階層のどのレベルでも自己矛盾のないパーセル化と不確実性マップを取得できるようにする分解不確実性推定も提供しています。これらの決定固有の不確実性マップを簡単な方法で示しますラベルツリーの任意のレベルで不確実性しきい値のある組織マップを提供するために使用されます。ラベルツリーの各ブランチでの決定を予測することによって機能する、階層を意識した脳パーセル化法を紹介します。 
[ABSTRACT]システムを使用して、このラベルツリーのすべてのブランチに対して個別に不確実性をモデル化できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Dual Semantic Fusion Network for Video Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_56.html">
      <font color="black">Dual Semantic Fusion Network for Video Object Detection</font>
    </a>
  </h2>
  <font color="black">さらに、ノイズによって引き起こされる情報の歪みの影響を軽減するために、フュージョンプロセスに幾何学的類似度測定を導入します。その結果、提案されたDSFNetは、多粒度フュージョンによってより堅牢な機能を生成し、以下の不安定性の影響を回避できます。特に、提案されたデュアルセマンティックフュージョンネットワークは、ResNet-101と85.4 \％を備えた最新のビデオオブジェクト検出器の中で、最高のパフォーマンス84.1 \％mAPを実現しています。 ResNeXt-101を使用したmAP（後処理ステップを使用しない）。 
[ABSTRACT]提案されたdsfnetは、複数の粒度の融合により、より堅牢な機能を生成できます。私たちの知る限りでは、現在の状態の中で84％マップの最高のパフォーマンス-ressetを備えた最新のビデオオブジェクト検出器-101を使用せずにインスタンス-レベルlevel.itを使用して、外部のガイダンスなしでより詳細な機能を作成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_57.html">
      <font color="black">Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News</font>
    </a>
  </h2>
  <font color="black">攻撃者が利用できる潜在的な弱点を特定するために、4種類の生成された記事で構成されるNeuralNewsデータセットを作成し、このデータセットに基づいて一連の人間のユーザー調査実験を行います。このホワイトペーパーでは、より現実的な画像とキャプションを含む機械で生成されたニュースを防御するという困難なタスク。ユーザー調査の実験から収集された貴重な洞察に加えて、効果的な視覚意味の不一致の検出に基づく比較的効果的なアプローチを提供します。防御の最前線であり、機械で生成された偽情報から防御するための将来の作業に役立つ参考資料です。 
[ABSTRACT]画像、動画、自然言語モデルの急速な進歩により、効果的な防御メカニズムの必要性が高まっています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Meta Learning for Few-Shot One-class Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_58.html">
      <font color="black">Meta Learning for Few-Shot One-class Classification</font>
    </a>
  </h2>
  <font color="black">サポートベクターデータの記述方法をこの方法で使用する方法を示し、プロトタイプネットワークに基づいて同等のパフォーマンスを得る簡単なバリアントを提案します。これは、データから特徴表現を直接学習することが、どの1クラスアルゴリズムよりも重要であることを示しています。選択します。少数ショット分類データセットを少数ショット1クラス分類シナリオに適合させ、従来の1クラス分類の最新技術と同様の結果を得て、アプローチを検証します。少数ショット設定で採用されている1クラスの分類ベースライン。私たちのコードはhttps://github.com/gdahia/meta_occで入手できます。
[ABSTRACT]私たちのコードはwwwで入手できます。 github。 com / gdahia</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-11">
        <br><font color="black">2020-09-11</font>
      </time>
    </span>
</section>
<!-- paper0: Probabilistic Jacobian-based Saliency Maps Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_59.html">
      <font color="black">Probabilistic Jacobian-based Saliency Maps Attacks</font>
    </a>
  </h2>
  <font color="black">効果的で高速な$ L_0 $攻撃は、NNCを阻止してその堅牢性を向上させるのに実用的です。ニューラルネットワーク分類器（NNC）は、スパースまたは$ L_0という名前の入力機能のほんの一部を変更するものを含む、入力の悪意のある敵の摂動に対して脆弱であることが知られています$攻撃..しかし、私たちの攻撃はCW $ L_0 $よりもはるかに高速です（たとえば、CIFAR-10での平均実行時間を測定すると5,000倍以上高速です）。 
[要約]論文では、対象を誤ってnncに分類することで使用できるjsmaの新しいバリアントを紹介します。これらは3つの異なるデータセットに基づいています。これらはjsmaよりも大幅に高速で効率的であり、既知の非対象の非ただし、これらの攻撃はcw $ lよりもはるかに高速です。 0、cifarの平均実行時間を測定するもの-10</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-12">
        <br><font color="black">2020-07-12</font>
      </time>
    </span>
</section>
<!-- paper0: Knowledge Guided Learning: Towards Open Domain Egocentric Action
  Recognition with Zero Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_60.html">
      <font color="black">Knowledge Guided Learning: Towards Open Domain Egocentric Action
  Recognition with Zero Supervision</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、自己中心的なビデオのオープン語彙分類の新しいクラスと、監督なしの新しいオブジェクト検出の推論と学習に使用できることを示しています。ただし、最初のトレーニング環境以外のシーンや例に直面すると、エラーが発生する傾向があります。現在のアルゴリズムは帰納的学習環境でトレーニングされており、データ駆動モデルを使用して、既知のクラスの固定セットとの入力観測間の関連を学習します。 
[ABSTRACT]ディープアルゴリズムは、帰納的学習環境でトレーニングされます。これらは、データ駆動型モデルを使用して、inputota観測間の関連を学習します。これを使用して、オープンワールドの設定で新規アクションの自己監視発見を有効にすることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Transformers: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_61.html">
      <font color="black">Efficient Transformers: A Survey</font>
    </a>
  </h2>
  <font color="black">トランスフォーマーモデルアーキテクチャは、言語、ビジョン、強化学習などのさまざまな領域にわたる有効性により、最近非常に大きな関心を集めています。最近、目まぐるしい数の「X-former」モデルが提案されています-Reformer、Linformer、Performer、Longformer、いくつか例を挙げると、元のTransformerアーキテクチャを改善したもので、その多くは計算効率とメモリ効率を改善します。たとえば、自然言語処理の分野では、Transformerが最新のディープラーニングスタックの不可欠な要素になっています。 
[ABSTRACT]新しいペーパーは、最近の効率学習モデルのリストを概説しています。複数の範囲の範囲にわたる既存の作業とモデルの詳細かつ包括的な洞察を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Label Activity Recognition using Activity-specific Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_62.html">
      <font color="black">Multi-Label Activity Recognition using Activity-specific Features</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、3つのマルチラベル活動認識データセットで最先端のアプローチを上回りました。さらに、システムが生成する活動固有の機能をよりよく理解するために、これらの活動固有の機能をCharadesデータセットで視覚化しました。また、手法を評価し、2つの単一アクティビティ認識データセットで最先端のパフォーマンスを実現して、アプローチの一般化可能性を示しました。 
[要旨]私たちのアプローチは、最初に一連の独立した機能スニペットを抽出します。これらは、さまざまな状況に基づいています-ビデオの時間領域。これらには、「観測」と呼ばれる「観測」が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Cross-View Gait Recognition with Evidence: A Discriminant Gait
  GAN (DiGGAN) Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_63.html">
      <font color="black">Robust Cross-View Gait Recognition with Evidence: A Discriminant Gait
  GAN (DiGGAN) Approach</font>
    </a>
  </h2>
  <font color="black">ただし、それらは大規模なデータセットにうまく拡張できず、パフォーマンスは大幅に低下します。ただし、堅牢な自動歩行認識システムを開発することは非常に困難です。なぜなら、歩行は、衣服、歩行面、歩行速度、カメラの視野角など、多くの共変量の要因の影響を受ける可能性があるためです。規模の監視アプリケーション。 
[ABSTRACT]歩行認識システムの開発は非常に困難です。歩行は、衣服、歩行面、歩行速度、カメラの視野角などの共変量の要因の影響を受ける可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-11-26">
        <br><font color="black">2018-11-26</font>
      </time>
    </span>
</section>
<!-- paper0: A New Approach for Texture based Script Identification At Block Level
  using Quad Tree Decomposition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_64.html">
      <font color="black">A New Approach for Texture based Script Identification At Block Level
  using Quad Tree Decomposition</font>
    </a>
  </h2>
  <font color="black">結果は、手書きのインド文字の分類に対する現在のアプローチの有効性を確立するのに役立ちます。インド語のスクリプト用の単一言語OCRシステムの開発では、かなりの成功が収められています。実験は、四分木分解アプローチに基づいてブロックレベルで行われ、6つの異なる既知の分類子を使用して評価されます。 
[要約]実験は、クワッドツリー分解アプローチに基づいてブロックレベルで行われ、6つの異なる既知の分類子を使用して評価されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Surgical Video Motion Magnification with Suppression of Instrument
  Artefacts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CV/paper_65.html">
      <font color="black">Surgical Video Motion Magnification with Suppression of Instrument
  Artefacts</font>
    </a>
  </h2>
  <font color="black">不注意による損傷や出血を防ぐために、ビデオモーション拡大機能は、内視鏡ビデオで地下血管を直接強調表示できます。ツールをシーンに導入する前に、単一の心血管サイクルの局所空間周波数情報からの時間的フィルター応答を保存することにより、フィルターを使用できます。手術画像の空間領域に対してモーション拡大を有効にするかどうかを決定するために使用されます。ただし、手術画像全体にモーションフィルターを適用すると、手術器具からの残留モーションに敏感であり、収差モーションアーティファクトのために実際のアプリケーションが妨げられる可能性があります。 
[ABSTRACT]完全な手術画像にモーションフィルターを適用すると、映像に敏感です。ただし、手術機器を使用するため、実際のアプリケーションを妨げる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Group-wise Contrastive Learning for Neural Dialogue Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_0.html">
      <font color="black">Group-wise Contrastive Learning for Neural Dialogue Generation</font>
    </a>
  </h2>
  <font color="black">具体的には、事前トレーニングされたベースラインモデルを参照として使用します。人間の会話で広く使用されているマルチマッピング関係を管理するために、グループ単位のデュアルサンプリングで対照対話学習を拡張します。対照学習では、対象対話モデルが参照モデルと比較して、ポジティブサンプルの条件付き確率が高く、ネガティブサンプルの条件付き確率が低い。 
[要約]最尤推定（mle）目的は、対話生成で広く採用されています。モデルは、適切に選択された正の発話と負の発話の違いを明示的に認識します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Solomon at SemEval-2020 Task 11: Ensemble Architecture for Fine-Tuned
  Propaganda Detection in News Articles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_1.html">
      <font color="black">Solomon at SemEval-2020 Task 11: Ensemble Architecture for Fine-Tuned
  Propaganda Detection in News Articles</font>
    </a>
  </h2>
  <font color="black">動的に適合された最小共通サブシーケンスアルゴリズムを使用する特別な分類子は、反復クラスの複雑さに適応するために使用されます。私たちは、マルチクラス分類タスクであるタスク「テクニック分類」（TC）に参加しました。他の参加システムでは、提出物はリーダーボードで4位にランクされています。 
[ABSTRACT]私たちは、マルチクラスカテゴリカテゴリタスクであるタスク「テクニック分類」（tc）に参加しました。結果は、参加のさまざまな部分に基づいています。他の参加システムと比較すると、参加はリーダーボードで4番目にランクされています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Claim Check-Worthiness Detection as Positive Unlabelled Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_2.html">
      <font color="black">Claim Check-Worthiness Detection as Positive Unlabelled Learning</font>
    </a>
  </h2>
  <font color="black">これを適用することで、英語でクレームチェックの価値を検出するために調査された3つのタスクのうち2つで最新の技術を上回りました。それらすべてに対する統一されたアプローチが達成可能かどうかの調査。したがって、アノテーターは、明確なチェックに値すると判断したインスタンスのみをマークします。 
[要約]問題を研究する複数の研究行があります。これらには、政治演説、噂、ウィキペディアのチェックアウトが含まれます。ここでは、チェックの中心的な課題を明らかにします-価値</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-05">
        <br><font color="black">2020-03-05</font>
      </time>
    </span>
</section>
<!-- paper0: DDRQA: Dynamic Document Reranking for Open-domain Multi-hop Question
  Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_3.html">
      <font color="black">DDRQA: Dynamic Document Reranking for Open-domain Multi-hop Question
  Answering</font>
    </a>
  </h2>
  <font color="black">HotpotQAフルWiki設定での実験は、私たちの方法が以前の最良の検索モデルよりも7ポイント以上高い再ランキングパフォーマンスを達成し、公式のリーダーボードで最先端の質問応答パフォーマンスも達成することを示しています。オープンドメインマルチホップ質問応答（QA）では、複数のサポートドキュメントを取得する必要があります。それらのドキュメントの一部は、質問との字句の重複がほとんどなく、反復ドキュメント取得によってのみ見つけることができます。この課題に対処するために、動的ドキュメント再ランキング（DDR）を反復取得することを提案します。ドキュメントを再ランク付けしてフィルタリングし、検索プロセスを停止するタイミングを適切に決定します。 
[ABSTRACT]ドキュメントの再ランキングはより重要ですが、耐性はありません。再ランキングのドキュメントは、下流のノイズを弱める可能性があります-敏感なリーダー</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Automated Source Code Generation and Auto-completion Using Deep
  Learning: Comparing and Discussing Current Language-Model-Related Approaches -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_4.html">
      <font color="black">Automated Source Code Generation and Auto-completion Using Deep
  Learning: Comparing and Discussing Current Language-Model-Related Approaches</font>
    </a>
  </h2>
  <font color="black">そのアプローチの人気の高まりを考慮して、プログラミングコードに基づいて言語モデルを作成および使用するためのさまざまな方法とディープラーニングアーキテクチャを比較する経験的な論文が不足していることを発見しました。これらの目標を追求するために近年続いているアプローチの1つは、ディープラーニング対応の言語モデルの例です。言語処理に関連するさまざまな領域の中で、このタイプのモデリングを適用する上で最も注目すべきものの1つは、プログラミング言語の処理です。 
[ABSTRACT]長年にわたり、機械学習コミュニティは、人間がプログラムしたコードをオートコンプリートして生成、修正、または評価するさまざまなアプローチを適用するなどの目標を追求してきました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Neural Dialogue State Tracking with Temporally Expressive Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_5.html">
      <font color="black">Neural Dialogue State Tracking with Temporally Expressive Networks</font>
    </a>
  </h2>
  <font color="black">標準データセットを評価すると、TENはターンレベル状態予測と状態集約の精度を向上させるのに効果的であることが実証されています。既存のDSTモデルは、ダイアログターン全体の時間的機能の依存関係を無視するか、ダイアログで時間的状態の依存関係を明示的にモデル化できません..この作業では、DSTの2つのタイプの時間依存性を共同でモデル化するためのTemporally Expressive Networks（TEN）を提案します。 
[要約] 10のモデルは、再帰ネットワークのパワーと確率論的シンボルに基づいています。標準データは、さまざまなモデルに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Graph-to-Sequence Neural Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_6.html">
      <font color="black">Graph-to-Sequence Neural Machine Translation</font>
    </a>
  </h2>
  <font color="black">サブグラフ表現を融合するために、異なる順序のサブグラフの異なるグループに重みを付ける3つの方法を経験的に調査します。WMT14英語-ドイツ語およびIWSLT14ドイツ語-英語の実験結果は、1.1 BLEUポイントの改善によりトランスフォーマーを効果的にブーストできることを示しています。 WMT14の英語-ドイツ語のデータセットとIWSLT14のドイツ語-英語のデータセットの1.0 BLEUポイント。詳細には、レイヤーごとに異なる次数のサブグラフの情報をキャプチャすることにより、Graph-Transformerと呼ばれるグラフベースのSANベースのNMTモデルを提案します。 
[ABSTRACT]サブグラフは、その順序に従って異なるグループに入れられます。サブグラフの各グループはそれぞれ、単語間の異なるレベルの依存関係を反映します。この方法は、トランスフォーマーを効果的にブーストできます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: GLUCOSE: GeneraLized and COntextualized Story Explanations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_7.html">
      <font color="black">GLUCOSE: GeneraLized and COntextualized Story Explanations</font>
    </a>
  </h2>
  <font color="black">人間が読んだり聞いたりすると、何が起こったのか、なぜ起こったのかを理解するための暗黙の常識的な推論を行います。このホワイトペーパーでは、2つの具体的な貢献について詳しく説明します。まず、半構造化テンプレートを使用してGLUCOSEデータを効果的にクラウドソーシングするプラットフォーム因果関係の説明を引き出します。各GLUCOSEエントリには、ストーリー固有の因果関係のステートメントと、そのステートメントから一般化された推論規則とのペアが含まれています。 
[ABSTRACT]私たちはブドウ糖を導入します。これは暗黙の常識因果知識の大規模なデータセットです。日常的な状況についての半知識を取り込む440kの特定のステートメントと一般的なルールを収集しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Arabic Opinion Mining Using a Hybrid Recommender System Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_8.html">
      <font color="black">Arabic Opinion Mining Using a Hybrid Recommender System Approach</font>
    </a>
  </h2>
  <font color="black">この研究は特にアラビア語のレビューに焦点を当てており、アラビア語（OCA）データセットの意見コーパスを使用してモデルが評価されます。ユーザーの評価が不十分であったり、ユーザーやアイテムに関するデータがないため、データの希薄性はレコメンダーシステムの大きな問題を表しています。私たちのシステムは効率的であり、レビューからの評価を予測する際に85％近くの優れた精度を示しました。
[要約]感情分析は、文学的な意見の態度（ポジティブかネガティブかニュートラルか）を判断するプロセスです。研究ではハイブリッドを提案しています。感情分析とレコメンダーシステムを組み合わせて、データスパース性の問題に取り組むアプローチ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Reusing a Pretrained Language Model on Languages with Limited Corpora
  for Unsupervised NMT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_9.html">
      <font color="black">Reusing a Pretrained Language Model on Languages with Limited Corpora
  for Unsupervised NMT</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチであるRE-LMは、英語-マケドニア語（En-Mk）および英語-アルバニア語（En-Sq）の競合するクロスリンガルプレトレーニングモデル（XLM）よりも優れており、4つの翻訳方向すべてで+8.3 BLEUポイントを超えています。 。したがって、新しい語彙拡張方法を提案します。事前トレーニング済みのLMを再利用するには、新しい言語を考慮して、事前定義された語彙を変更する必要があります。 
[要約] 1つの言語で使用できるデータが限られている場合、この方法では翻訳が不十分になります。単一言語lmは両方の言語で微調整され、新しい言語のテストに使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Contextualized Perturbation for Textual Adversarial Attack -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_10.html">
      <font color="black">Contextualized Perturbation for Textual Adversarial Attack</font>
    </a>
  </h2>
  <font color="black">さまざまな長さの出力を生成できるように、3つのコンテキスト化された摂動、Replace、Insert、Mergeを提案します。CLAREは事前トレーニング済みのマスク言語モデルに基づいて構築され、コンテキストを意識した方法で入力を変更します。広範な実験と人間の評価により、 CLAREは、攻撃の成功率、テキストの類似性、流暢さ、文法性の点でベースラインを上回っています。 
[ABSTRACT]そのような例を生成する既存の手法は、ローカルのヒューリスティックルールによって駆動されます。clareは事前トレーニング済みのマスク言語モデルに基づいて構築され、コンテキストを意識した方法でニューロンを変更します。少ない編集で犠牲者モデルをより効率的に攻撃できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: RDF2Vec Light -- A Lightweight Approachfor Knowledge Graph Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_11.html">
      <font color="black">RDF2Vec Light -- A Lightweight Approachfor Knowledge Graph Embeddings</font>
    </a>
  </h2>
  <font color="black">ナレッジグラフの埋め込みアプローチは、グラフのノードとエッジを数学的ベクトルとして表します。ただし、ほとんどのダウンストリームアプリケーションシナリオでは、実際に重要なのは概念の小さなサブセットのみです。そのため、RDF2Vec Lightはナレッジのサブグラフのみをトラバースして処理します。グラフ。 
[ABSTRACT]現在のアプローチは完全なナレッジグラフの埋め込みに焦点を当てています。これらには非常に大きなナレッジグラフの埋め込みが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: RobBERT: a Dutch RoBERTa-based Language Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_12.html">
      <font color="black">RobBERT: a Dutch RoBERTa-based Language Model</font>
    </a>
  </h2>
  <font color="black">多言語BERTは多くのタスクで良好に機能しますが、最近の研究では、単一言語でトレーニングされたBERTモデルが多言語バージョンよりも大幅に優れていることが示されています。さまざまなタスクでのパフォーマンスと、データセットサイズの微調整の重要性を測定しました。アプローチでは、以前のBERTの実装を使用してオランダ語版のBERTをトレーニングしました。堅牢に最適化されたBERTアプローチであるRoBERTaを使用して、RobBERTと呼ばれるオランダ語言語モデルをトレーニングしました。 
[ABSTRACT] dutch bertモデルのトレーニングには、幅広いオランダのnlpタスクの可能性がたくさんあります。成功する前に、さまざまなパフォーマンスに対してそのパフォーマンスを測定しました。小さなデータセットを処理する場合、他のモデルよりも堅牢にパフォーマンスが優れていることがわかりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-17">
        <br><font color="black">2020-01-17</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Persona-Based Empathetic Conversational Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_13.html">
      <font color="black">Towards Persona-Based Empathetic Conversational Models</font>
    </a>
  </h2>
  <font color="black">最後に、ペルソナが共感的な応答に及ぼす影響を調査するために、広範な実験を行います。次に、データセットで最先端のパフォーマンスを取得する、BERTベースの効率的な応答選択モデルであるCoBERTを提案します。具体的には、最初にペルソナベースの共感的な会話のための新しい大規模マルチドメインデータセットを提示します。 
[要約]心理学では、ペルソナは性格と高い相関関係があることが示されています。これは、共感に影響を及ぼします。さらに、ペルソナベースの共感的な会話に向けた新しいタスクを提案します。これは、ペルソナが共感に与える影響に関する最初の研究です応答する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-26">
        <br><font color="black">2020-04-26</font>
      </time>
    </span>
</section>
<!-- paper0: Asking Complex Questions with Multi-hop Answer-focused Reasoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_14.html">
      <font color="black">Asking Complex Questions with Multi-hop Answer-focused Reasoning</font>
    </a>
  </h2>
  <font color="black">HOTPOTQAデータセットでの広範な実験を通じて、私たちは将来の作業を動機付けるためのベースラインとして機能する提案モデルの優位性と有効性を実証します。この論文では、マルチホップ質問生成と呼ばれる新しいタスクを提案します。さらに、ドキュメントのコレクションと対応する回答1を与えられた複数のエンティティとそれらの意味的関係の発見とモデリング1 ..問題を解決するために、異なる粒度レベルを含めるために、固定回答中心のエンティティグラフにマルチホップの回答に焦点を当てた推論を提案しますエンティティの単語レベルおよびドキュメントレベルのセマンティクスとそれらのセマンティック関係を含むセマンティック情報の。 
[ABSTRACT]単純な質問には、シングルホップの関係を含む質問が含まれます。これらには、意味情報の単語レベルとドキュメントレベルの用語が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: CoDEx: A Comprehensive Knowledge Graph Completion Benchmark -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_15.html">
      <font color="black">CoDEx: A Comprehensive Knowledge Graph Completion Benchmark</font>
    </a>
  </h2>
  <font color="black">次に、広範囲に調整された5つの埋め込みモデルについて、CoDExのベースラインリンク予測とトリプル分類の結果を報告します。最後に、CoDExがより多様で解釈可能なコンテンツをカバーし、以下のことができる関係パターンが少ないことを示すことで、CoDExを一般的なリンク予測ベンチマークと区別します自明な頻度ベースのルールでカバーされます。データ、コード、および事前トレーニング済みモデルは、https：//github.com/tsafavi/codexで入手できます。 
[ABSTRACT] codexは、3つのナレッジアカウント、エンティティと関係の多言語記述、およびもっともらしいが偽であることが確認されている数万のハードネガティブトリプルで構成されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Is Multihop QA in DiRe Condition? Measuring and Reducing Disconnected
  Reasoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_16.html">
      <font color="black">Is Multihop QA in DiRe Condition? Measuring and Reducing Disconnected
  Reasoning</font>
    </a>
  </h2>
  <font color="black">これに対処するために3つの貢献をします。最近の大規模モデル（XLNet）では、多因子推論によって回答スコアの18％しか得られないことを示しています。これは、単純なRNNベースラインとほぼ同じです。敵対的なアプローチを補完し、関連してさらに削減をもたらします。 
[ABSTRACT]これに対処するために3つの貢献をしました..最初にこれに対処するために3つの貢献をしました。これにより、モデルをテストできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-02">
        <br><font color="black">2020-05-02</font>
      </time>
    </span>
</section>
<!-- paper0: Minimize Exposure Bias of Seq2Seq Models in Joint Entity and Relation
  Extraction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_17.html">
      <font color="black">Minimize Exposure Bias of Seq2Seq Models in Joint Entity and Relation
  Extraction</font>
    </a>
  </h2>
  <font color="black">シーケンス長から順序なしマルチツリー（Seq2UMTree）への新規モデル（Seq2UMTree）を提案し、トリプレット内のデコード長を3に制限し、トリプレット間の順序を削除することで、露出バイアスの影響を最小限に抑えます。モデルは頻繁なラベルの組み合わせに適合しすぎて一般化が悪化します。2つのデータセット、DuIEとNYTでモデルを評価し、露出バイアスがSeq2Seqモデルのパフォーマンスをどのように変えるかを体系的に調査します。 
[ABSTRACT]事前の作業では、トリプレットシーケンスシーケンスのシーケンス間（seq2seq）モデルを活用します。これらは露出バイアスを導入し、モデルが頻繁なラベルの組み合わせに適合しすぎて、一般化が悪化する可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Grounded Adaptation for Zero-shot Executable Semantic Parsing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_18.html">
      <font color="black">Grounded Adaptation for Zero-shot Executable Semantic Parsing</font>
    </a>
  </h2>
  <font color="black">私たちの分析は、GAZPがトレーニング環境でのデータ拡張より優れており、GAZP合成データの量に応じてパフォーマンスが向上し、サイクルの一貫性が適応の成功の中心であることを示しています。GAZPは、前方セマンティックパーサーと後方発話ジェネレーターを組み合わせてデータを合成しています（例えば、新しいデータベーススキーマ）。 
[ABSTRACT] gazpを使用すると、ユーザーはサイクルに適応できます-パーサーを適応させる一貫した例.gazpは、データのフォームと実行の精度のシミュレーションを改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Are Interpretations Fairly Evaluated? A Definition Driven Pipeline for
  Post-Hoc Interpretability -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_19.html">
      <font color="black">Are Interpretations Fairly Evaluated? A Definition Driven Pipeline for
  Post-Hoc Interpretability</font>
    </a>
  </h2>
  <font color="black">定義は、解釈を取得するためのアルゴリズムと、さらに重要なことに、評価に使用されるメトリックの両方に影響します。そうでない場合、どの解釈基準で異なる解釈方法を比較できますか？。理論的分析と実験的分析の両方を通じて、特定の評価指標では解釈方法が異なる方法で実行されますが、そのような違いは解釈の質や忠実度ではなく、むしろ評価指標の固有のバイアスに起因する場合があります。 
[ABSTRACT]以前の調査では、特定の評価指標では解釈方法のパフォーマンスが異なることが示されています。ただし、このような違いは、解釈の質や忠実度ではなく、評価指標の固有のバイアスによるものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Leveraging Semantic Parsing for Relation Linking over Knowledge Bases -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_20.html">
      <font color="black">Leveraging Semantic Parsing for Relation Linking over Knowledge Bases</font>
    </a>
  </h2>
  <font color="black">3つのKBQAデータセットを使用したリレーションリンクの実験。 QALD-7、QALD-9、およびLC-QuAD 1.0は、提案されたアプローチがすべてのベンチマークで最先端のパフォーマンスを達成することを示しています。SLINGは、言語的手がかり、豊富なセマンティック表現などの補完的な信号をキャプチャする複数の関係リンクアプローチを統合します、およびナレッジベースからの情報。ナレッジベースの質問応答システムは、関係の抽出とリンクのモジュールに大きく依存しています。 
[ABSTRACT]ナレッジベースへのリンクを抽出してリンクするタスクは、州の課題に直面しています。目的は、自然言語のバランスとトレーニングデータの不足のバランスをとることです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: MedType: Improving Medical Entity Linking with Semantic Type Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_21.html">
      <font color="black">MedType: Improving Medical Entity Linking with Semantic Type Prediction</font>
    </a>
  </h2>
  <font color="black">医療エンティティリンクの研究でソースコードとデータセットを公開します。医療エンティティリンクの注釈付きトレーニングデータの不足に対処するために、2つの大規模医療エンティティリンクデータセットであるWikiMedとPubMedDSを提示し、事前トレーニングを示しますこれらのデータセットのMedTypeは、エンティティリンクのパフォーマンスをさらに改善します。MedTypeを医療エンティティリンク用の5つの既製のツールキットに組み込み、いくつかのベンチマークデータセット全体でエンティティリンクのパフォーマンスが一貫して改善されることを示します。 
[ABSTRACT] medtypeは完全にモジュール化されたツールで、無関係な候補概念を排除します。データセットをリンクする2つの大規模医療エンティティであるwikimedおよびpubmeddsを提示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: The World is Not Binary: Learning to Rank with Grayscale Data for
  Dialogue Response Selection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_22.html">
      <font color="black">The World is Not Binary: Learning to Rank with Grayscale Data for
  Dialogue Response Selection</font>
    </a>
  </h2>
  <font color="black">3つのベンチマークデータセットと4つの最先端のマッチングモデルでの実験は、提案されたアプローチが重要で一貫したパフォーマンスの向上をもたらすことを示しています。応答の選択は、検索ベースの会話システムの構築に重要な役割を果たします。この作業では、そのグレースケールデータは、人間の手間をかけずに自動的に構築できます。 
[ABSTRACT]私たちの方法はオフを使用しています-一致するデータジェネレーターとしての棚の応答検索モデルと応答生成モデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: Knowledge Graphs for Multilingual Language Translation and Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_23.html">
      <font color="black">Knowledge Graphs for Multilingual Language Translation and Generation</font>
    </a>
  </h2>
  <font color="black">エンティティは、固有名詞と一般名詞の2つのグループに分類できます。自然言語処理（NLP）コミュニティは、さまざまなニューラルネットワーク（NN）アーキテクチャのリリースに触媒されて、最近、目覚ましい進歩を遂げています。固有名詞も知られています名前付きエンティティ（NE）として、人、組織、場所の名前に対応します（John、WHO、カナダなど）。 
[ABSTRACT]これらのツールは、nlpタスクの多数の自動化ソリューションの出力品質を向上させることで効果的であることが証明されています。これらには、kgsの作業に対する自動化された応答の品質の向上が含まれます。これらの作業は、kgsの自然への貢献をうまく利用しています。言語生成（nlg）タスク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: What Are People Asking About COVID-19? A Question Classification Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_24.html">
      <font color="black">What Are People Asking About COVID-19? A Question Classification Dataset</font>
    </a>
  </h2>
  <font color="black">COVID-Qが、適用システムの開発で直接使用するため、またはモデル評価のドメイン固有のリソースとして役立つことを願っています。質問を15のカテゴリに分類する場合、BERTベースラインは、カテゴリごとに20の例をトレーニングしたときに58.1％の精度でした。質問のクラスタリングタスクの場合、BERT +三重項損失ベースラインは49.5％の精度を達成しました。https：//github.com/JerryWei03/COVID-Qにデータセットを公開しています。 
[要約]データセットでcovidについて尋ねられた最も一般的な質問。複数のソースに表示される多くの質問は、cdcやfdaなどの信頼できる組織のfaub Webサイトでは回答されていないことがわかりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-26">
        <br><font color="black">2020-05-26</font>
      </time>
    </span>
</section>
<!-- paper0: UNION: An Unreferenced Metric for Evaluating Open-ended Story Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_25.html">
      <font color="black">UNION: An Unreferenced Metric for Evaluating Open-ended Story Generation</font>
    </a>
  </h2>
  <font color="black">2つのストーリーデータセットの実験は、UNIONが生成されたストーリーの品質を評価するための信頼できる尺度であることを示しています。これは、人間の判断とよりよく相関し、既存の最先端のメトリックよりも一般化できます。ネガティブサンプルを構築するアプローチを提案します。繰り返しのプロット、矛盾するロジック、長距離インコヒーレンスなど、既存のNLGモデルで一般的に観察されるエラーを模倣することによって。既存の参照メトリック（例：BLEUとMoverScore）の成功にもかかわらず、それらはオープンエンドの人間の判断とあまり相関しません悪名高い1対多の問題によるストーリーまたはダイアログの生成を含むテキスト生成：同じ入力に対して多くのもっともらしい出力があり、与えられた参照の限られた数とは文字またはセマンティクスが大幅に異なる場合があります。 
[ABSTRACT]負の生成を作成するためのアプローチを提案します。これらは、多くのモデルに共通するエラーに基づいています。これらには、繰り返しのプロットと長期的な非干渉性が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Text Generation by Learning from Off-Policy Demonstrations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_26.html">
      <font color="black">Text Generation by Learning from Off-Policy Demonstrations</font>
    </a>
  </h2>
  <font color="black">これらの問題を緩和するために、テキスト生成をエキスパートデモンストレーション（つまり、トレーニングデータ）による強化学習（RL）問題としてフレーム化します。目標は、モデル生成履歴が与えられた場合に品質を最大化することです。アクションスペースが大きく、報酬が少ないため、問題が発生します。さらに、GOLDでトレーニングされたモデルは、デコードアルゴリズムの影響を受けにくく、長さが増加しても生成品質はそれほど低下しません。 
[ABSTRACT]生成への事前のRLアプローチは、アクションスペースが大きく、報酬が濃いため、問題に直面することがよくあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Reasoning about Goals, Steps, and Temporal Ordering with WikiHow -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_27.html">
      <font color="black">Reasoning about Goals, Steps, and Temporal Ordering with WikiHow</font>
    </a>
  </h2>
  <font color="black">自動生成されたトレーニングセットを使用すると、手順イベントの知識を必要とするドメイン外のタスクにモデルを効果的に転送でき、SWAG、スニップ、およびストーリークローズテストのパフォーマンスが大幅に改善され、ゼロショットと数ショットの設定で実行できます。 -検証済みのテストセットは、常識的な推論の信頼できるベンチマークとして機能し、最新のトランスモデルのパフォーマンスと人間のパフォーマンスの間に約10％〜20％のギャップがあります。2つの推論タスクのスイートを提案します。手続き型イベント間の関係のタイプ：目標とステップの関係（「ポーズを学ぶ」は、「ヨガをする」という大きな目標の1ステップです）とステップと時間の関係（「ヨガマットを購入する」は、通常「ポーズを学ぶ」の前にあります）。 
[ABSTRACT]これらの2つの関係を対象とするデータセットを紹介します。wikienseは、how-to-articles.humanトレーニングセットを学習するためのWebサイトです。テストは、wikihow、サイトに基づいてモデルを効果的に転送できます。ガイダンスのハウツー記事</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Meta Fine-Tuning Neural Language Models for Multi-Domain Text Mining -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_28.html">
      <font color="black">Meta Fine-Tuning Neural Language Models for Multi-Domain Text Mining</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、メタ言語学習者（MFT）と呼ばれる効果的な学習手順を提案します。これは、神経言語モデルの類似したNLPタスクのグループを解くメタ学習者として機能します。MFTの後、モデルを微調整できます。各ドメインは、パラメータの初期化が改善され、汎化能力が高くなっています。実験結果により、MFTの有効性と、少数ショット学習に対するその有用性が確認されています。 
[ABSTRACT] mftは、さまざまなドメインの典型的なインスタンスからのみ学習して、転送可能な高度な知識を獲得します。mftの後で、モデルは各ドメインに対して細かくコード化され、より良い不安定性とより高い汎化能力を備えます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-29">
        <br><font color="black">2020-03-29</font>
      </time>
    </span>
</section>
<!-- paper0: Extremely Low Bit Transformer Quantization for On-Device Neural Machine
  Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_29.html">
      <font color="black">Extremely Low Bit Transformer Quantization for On-Device Neural Machine
  Translation</font>
    </a>
  </h2>
  <font color="black">リソースが限られているモバイルデバイスまたはエッジデバイスにTransformerモデルを展開することは、推論中の計算とメモリのオーバーヘッドが大きいため、困難です。それに対応して、下位ビットでトランスフォーマーの重みを表す混合精度量子化戦略を提案します（たとえば、埋め込みブロック内でも、各単語は大きく異なる貢献を示します。
[ABSTRACT]トランスフォーマーモデルは、リソースが限られているモバイルデバイスまたはエッジデバイスに展開されています。多数の埋め込みブロックの場合、トランスフォーマーの各ブロックは、翻訳の精度に貢献します。これは、重いコンピューティングとメモリオーバーヘッドが原因です。結論の間に</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: CogTree: Cognition Tree Loss for Unbiased Scene Graph Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_30.html">
      <font color="black">CogTree: Cognition Tree Loss for Unbiased Scene Graph Generation</font>
    </a>
  </h2>
  <font color="black">データの分散のバランスをとるか、偏りのないモデルと表現を学習し、人間がこのタスクを実行する方法を無視します。まず、認知構造CogTreeを構築して、偏ったSGGモデルの予測に基づいて関係を整理します。次に、階層的損失を提案します。特に、適切な関係の大まかな細かい区別をサポートしながら、無関係なものの干渉を徐々に排除するこの認知構造のために。 
[ABSTRACT]シーングラフ生成（sgg）のパフォーマンスは満足のいくものではありません。これは、実際のシナリオでのデータの欠如に基づいています。代わりに、不偏sggの新しい認識ツリー（cogtree）損失を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Tag and Correct: Question aware Open Information Extraction with
  Two-stage Decoding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_31.html">
      <font color="black">Tag and Correct: Question aware Open Information Extraction with
  Two-stage Decoding</font>
    </a>
  </h2>
  <font color="black">もう1つは、シーケンスからシーケンスモデルを使用して回答を直接生成する生成方法です。質問とパッセージを同時に入力として結合しますが、最初から回答を生成するため、ほとんどの事実を使用しません回答語句は、パッセージから取得されます。1つは、Open IEモデルを使用してパッセージから候補の回答を抽出し、質問と照合してランク付けする抽出方法です。 
[要約]この問題を解決するには2つの方法があります。1つのモデルを完全にトレーニングすることができます。もう1つは問題のないオプションです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: WNTRAC: Artificial Intelligence Assisted Tracking of Non-pharmaceutical
  Interventions Implemented Worldwide for COVID-19 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_32.html">
      <font color="black">WNTRAC: Artificial Intelligence Assisted Tracking of Non-pharmaceutical
  Interventions Implemented Worldwide for COVID-19</font>
    </a>
  </h2>
  <font color="black">公共施設の清掃）.. NPI対策は、自然言語処理技術を使用してWikipediaの記事から毎日自動的に抽出され、手動で検証されて正確さと信憑性が保証されます。世界。 
[要約]世界中の政府がウイルスの蔓延を遅らせるために非製薬的介入（npi）を実施しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning Approaches for Extracting Adverse Events and Indications
  of Dietary Supplements from Clinical Text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_33.html">
      <font color="black">Deep Learning Approaches for Extracting Adverse Events and Indications
  of Dietary Supplements from Clinical Text</font>
    </a>
  </h2>
  <font color="black">ディープラーニングモデルは、DSの安全性を監視する大きな可能性を秘めた、臨床ノート内の有害事象とDSの兆候を検出できます。私たちの作業の目的は、ディープラーニングモデルを利用して安全に関する信号を抽出することの実現可能性を実証することです。臨床テキストでの栄養補助食品（DS）の使用..関係抽出（RE）タスクでは、注意ベースのBi-LSTMおよびCNN（畳み込みニューラルネットワーク）を含む2つの深層学習モデルと、ランダムフォレストモデルが抽出されるようにトレーニングされました。 DSとイベントの間の関係。3つのクラスに分類されました：陽性（つまり、適応症）、陰性（つまり、有害事象）、関連なし。 
[ABSTRACT] 2つのタスクが実験で実行されました-dsにちなんで名付けられました。結果は2つのディープラーニングモデルで分析されました。dsとイベントの関係を抽出できました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Language-Grounded Policy in Vision-and-Language Navigation
  with Bayes' Rule -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_34.html">
      <font color="black">Generative Language-Grounded Policy in Vision-and-Language Navigation
  with Bayes' Rule</font>
    </a>
  </h2>
  <font color="black">この論文では、アクションと遷移履歴を与えられたすべての可能な命令の分布を計算する生成言語に基づいたポリシーを設計および調査します。さらに、生成ポリシーと識別ポリシーの組み合わせにより、アートはR2Rデータセットを生成し、生成的および差別的なポリシーがVLNのさまざまな側面をキャプチャすることを示します。実験では、提案された生成的アプローチがルーム2ルーム（R2R）データセットの識別的アプローチよりも優れていることを示します。目に見えない環境で。 
[要約]差別的なシステムの提案されたルールが開発されました。ただし、そのようなdiscriminative.inテストを構築するには2つの異なる方法があります。提案されたポリシーがvlnよりも優れていることを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Retrofitting Structure-aware Transformer Language Model for End Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_35.html">
      <font color="black">Retrofitting Structure-aware Transformer Language Model for End Tasks</font>
    </a>
  </h2>
  <font color="black">実験結果は、改良された構造認識Transformer言語モデルが改善された複雑さを実現する一方で、正確な構文フレーズを誘導することを示しています。構文距離を活用して両方の句構成性をエンコードすることを提案することにより、最終タスクを容易にするために構造認識Transformerベースの言語モデルを改良することを検討します。言語モデルへの依存関係の接続。構造に対応した微調整を実行することにより、モデルは、セマンティックおよび構文に依存するタスクの両方で大幅な改善を実現します。 
[ABSTRACT]構造を認識し、微調整を行うことで、モデルは、セマンティック依存タスクとシンタックス依存タスクの両方で大幅な改善を実現します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Summarization by Jointly Extracting Sentences and Keywords -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_36.html">
      <font color="black">Unsupervised Summarization by Jointly Extracting Sentences and Keywords</font>
    </a>
  </h2>
  <font color="black">複数のベンチマークデータセットを使用した実験結果は、RepRankがROUGEで最高または同等のパフォーマンスを達成したことを示しています。学習した表現を使用して、共同および相互強化プロセスで顕著な文とキーワードを抽出できることを示し、このプロセスが常にパフォーマンスの改善につながる独自のソリューション。ランダムウォークの吸収のバリアントと対応するサンプリングベースのアルゴリズムも、冗長性を回避し、要約の多様性を高めるために説明されています。 
[要約]望ましい表現を取得するために、単語の埋め込みの加重和によって文を表現する自己注意ベースの学習方法を提案します。重みは、ドキュメントの内容をより適切に反映することが望ましいこれらの単語に集中されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_37.html">
      <font color="black">Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News</font>
    </a>
  </h2>
  <font color="black">攻撃者が利用できる潜在的な弱点を特定するために、4種類の生成された記事で構成されるNeuralNewsデータセットを作成し、このデータセットに基づいて一連の人間のユーザー調査実験を実施します。既存のアプローチは、ニューラルを防御するために提案されていますが偽のニュース、それらは通常、記事がテキストとメタデータ（タイトルや著者など）しか持たない非常に限定された設定に制限されます。このホワイトペーパーでは、画像も含む機械で生成されたニュースを防ぐ、より現実的で挑戦的なタスクを紹介します。とキャプション。 
[ABSTRACT]画像、動画、自然言語モデルの急速な進歩により、効果的な防御メカニズムの必要性が高まっています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: CopyMTL: Copy Mechanism for Joint Extraction of Entities and Relations
  with Multi-Task Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_38.html">
      <font color="black">CopyMTL: Copy Mechanism for Joint Extraction of Entities and Relations
  with Multi-Task Learning</font>
    </a>
  </h2>
  <font color="black">これらの問題に対処するために、不正確なエンティティ抽出問題の背後にある理由の詳細な分析を行い、この問題を解決するためのシンプルでありながら非常に効果的なモデル構造を提案します。また、マルチトークンエンティティ（たとえば、モデルがマルチトークンエンティティを予測できるようにするために、CopyMTLと呼ばれるコピーメカニズムを備えたマルチタスク学習フレームワークを提案します。
[要約]モデルは、ヘッドエンティティとテールエンティティの違いが非常に弱いため、エンティティ抽出が不正確になります。分析すると、マルチトークンエンティティの予測に使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-24">
        <br><font color="black">2019-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Transformer Based Multi-Source Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_39.html">
      <font color="black">Transformer Based Multi-Source Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">最後に、大規模な事前トレーニング済みトランスベースのドメインエキスパートの予測は非常に均質であるため、予測を混合するための効果的な関数を学習するのは困難です。ドメイン敵対トレーニングは、これらのモデルの学習表現にほとんど影響を与えないことがわかります。大規模な変圧器ベースのモデルはすでにドメイン全体で比較的堅牢であることを示唆しています。さらに、注意に基づく1つの新しい混合を含む、混合関数のいくつかのバリアントを比較することにより、専門家の混合が大幅なパフォーマンスの向上につながることを示しています。 
[要旨]教師なしマルチソースドメインアダプテーションの問題。モデルは複数のソースドメインのラベル付きデータでトレーニングされます。ラベル付きデータが表示されていないドメインで予測を行う必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Transformers: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_40.html">
      <font color="black">Efficient Transformers: A Survey</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、熱心な研究者がこの混乱を乗り越えるのを支援することを目的として、最近の効率風味の「Xフォーマー」モデルの大規模で思慮深い選択を特徴付け、複数のドメインにわたる既存の作業とモデルの体系化された包括的な概要を提供します。変圧器モデルアーキテクチャは、言語、ビジョン、強化学習などのさまざまな領域での有効性により、最近非常に大きな関心を集めています。最近、目を見張るような数の「X-former」モデルが提案されています-名前を付けるために、Reformer、Linformer、Performer、Longformerいくつか-元のTransformerアーキテクチャを改善し、その多くは計算効率とメモリ効率を改善します。 
[ABSTRACT]新しいペーパーは、最近の効率学習モデルのリストを概説しています。複数の範囲の範囲にわたる既存の作業とモデルの詳細かつ包括的な洞察を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-14">
        <br><font color="black">2020-09-14</font>
      </time>
    </span>
</section>
<!-- paper0: NABU -- Multilingual Graph-based Neural RDF Verbalizer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_41.html">
      <font color="black">NABU -- Multilingual Graph-based Neural RDF Verbalizer</font>
    </a>
  </h2>
  <font color="black">ただし、英語が広く対象となっている唯一の言語です。NABUはエンコーダーデコーダーアーキテクチャに基づいており、Graph Attention Networksにヒントを得たエンコーダーとトランスフォーマーをデコーダーとして使用します。NABUが最新のアプローチよりも優れていることがわかった66.21 BLEUの英語で、56.04 BLEUの多言語シナリオですべての言語にわたって一貫した結果を達成します。 
[ABSTRACT] nabuは多言語のグラフベースのニューラルモデルであり、RDFデータをドイツ語、ロシア語、english。に言語化します。ナレッジグラフは言語でマークされているという事実に基づいています。ブルー</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Multilingual Music Genre Embeddings for Effective Cross-Lingual Music
  Item Annotation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_42.html">
      <font color="black">Multilingual Music Genre Embeddings for Effective Cross-Lingual Music
  Item Annotation</font>
    </a>
  </h2>
  <font color="black">最初に、事前トレーニングされた単語の埋め込みに合成関数を適用して、複数の単語のタグを表します。2番目に、改良された改造アルゴリズムで多言語の音楽ジャンルのグラフを活用することにより、タグの表現を音楽ドメインに適合させます。実験により、この方法が示されます：1 ）複数の言語（英語、フランス語、スペイン語）のタグシステム全体で音楽ジャンルを翻訳するのに効果的です。 2）英語のマルチソース翻訳タスクで以前のベースラインよりも優れています。音楽アイテムに音楽ジャンルの注釈を付けることは、音楽の推奨と情報検索にとって非常に重要ですが、音楽ジャンルが主観的な概念であることを考えると挑戦的です。 
[ABSTRACT]並行コーパスに依存せずに、クロスリンガルの音楽ジャンル翻訳を可能にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Parallel Interactive Networks for Multi-Domain Dialogue State Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_43.html">
      <font color="black">Parallel Interactive Networks for Multi-Domain Dialogue State Generation</font>
    </a>
  </h2>
  <font color="black">具体的には、インタラクティブエンコーダーを統合して、ターン内依存関係とクロスターン依存性を共同でモデル化します。スロットレベルのコンテキストを導入して、さまざまなスロットのより表現力のある機能を抽出します。そして、分散コピーメカニズムを使用して、単語を選択的にコピーします過去のシステム発話または過去のユーザー発話から。 
[ABSTRACT]これらの依存関係を組み込むことは、mdstの設計に不可欠であると主張し、これらの依存関係をモデル化する並列インタラクティブネットワーク（pin）を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Mimic and Conquer: Heterogeneous Tree Structure Distillation for
  Syntactic NLP -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_44.html">
      <font color="black">Mimic and Conquer: Heterogeneous Tree Structure Distillation for
  Syntactic NLP</font>
    </a>
  </h2>
  <font color="black">4つの一般的な構文依存タスクの実験結果は、エラーの伝播を減らしながら、豊富な異種構造構文を効果的に統合することによって、このメソッドがツリーエンコーダよりも優れていること、および効率と精度の両方の点で、集団法よりも優れていることを示しています。構文は有用であることが示されています。さまざまなNLPタスクに対して、既存の作業は主に1つの階層型ニューラルネットワークを使用してシングルトン構文ツリーをエンコードします。このホワイトペーパーでは、異種構造の知識を統合シーケンシャルLSTMエンコーダーに統合するためのシンプルで効果的な方法である知識蒸留を調査します。 
[要約]知識の抽出を使用して、知識を統合コーダーに統合する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: Adoption of Twitter's New Length Limit: Is 280 the New 140? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/cs.CL/paper_45.html">
      <font color="black">Adoption of Twitter's New Length Limit: Is 280 the New 140?</font>
    </a>
  </h2>
  <font color="black">この増加にもかかわらず、長さが制限に近づくツイートの頻度は、切り替え前よりもはるかに少なくなりました。2017年11月、Twitterは最大許容ツイート長を140から280文字に倍増しました。これは、世界で最も影響力のあるソーシャルメディアの1つに大幅な切り替えプラットフォーム..長さの制限は、Twitterデータを使用するすべての調査で考慮すべき重要な要素であり続けます。 
[概要] 11月に文字数制限が140文字から280文字に引き上げられましたが、引き上げるとすぐにツイート数が2倍になりました。約280文字のツイートと同様の変化です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Similarity-based data mining for online domain adaptation of a sonar ATR
  system -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-09-17/eess.AS/paper_0.html">
      <font color="black">Similarity-based data mining for online domain adaptation of a sonar ATR
  system</font>
    </a>
  </h2>
  <font color="black">フィールドデータの収集はコストがかかるため、トレーニングデータがないと、自動ターゲット認識（ATR）システムのパフォーマンスが制限されることがよくあります。幅広いシミュレーション環境での比較パフォーマンス分析を示し、この方法を使用する利点を強調します。以前に見えなかった環境への迅速な適応のために。提案されたデータマイニングアプローチは、視覚的な類似性に依存し、従来採用されていたハードマイニング手法よりも優れています。 
[要約]提案されたデータ-マイニングアプローチは視覚的な類似性に依存し、ハードマイニング手法よりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-16">
        <br><font color="black">2020-09-16</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
