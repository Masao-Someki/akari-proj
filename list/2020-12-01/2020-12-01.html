<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-12-01の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Multi-Decoder DPRNN: High Accuracy Source Counting and Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.SD/paper_0.html">
      <font color="black">Multi-Decoder DPRNN: High Accuracy Source Counting and Separation</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、スピーカーの数を数える点で最先端を上回り、再構成された信号の品質で競争力を維持していることを示しています。具体的には、グラウンドトゥルースが多かれ少なかれ品質を評価する方法の問題を解決しました。モデルによって予測されたものよりもスピーカー..最大5人のスピーカーが混在するWSJ0-mixデータセットでのアプローチを評価します。 
[ABSTRACT]私たちのアプローチは、追加の出力ヘッドでmulcatソース分離バックボーンを拡張します。カウント-スピーカーの数を推測するためのヘッド、および元の信号を再構築するためのデコーダーヘッド</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: Sound Synthesis, Propagation, and Rendering: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.SD/paper_1.html">
      <font color="black">Sound Synthesis, Propagation, and Rendering: A Survey</font>
    </a>
  </h2>
  <font color="black">私たちの知る限り、これはコンピュータグラフィックスの分野におけるサウンド研究の包括的な要約を提供する最初の試みです。さらに、最新の深層学習ベースのサウンドシミュレーションアプローチを示します。最初に、以下を含むさまざまなサウンド合成方法を調査します。ハーモニック合成、テクスチャ合成、スペクトル分析、および物理ベースの合成。 
[ABSTRACT]サウンドは、サウンドグラフィックや空間サイズなどの重要な手がかりを提供できます。さらに、サウンドのレンダリング方法を確認します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-11">
        <br><font color="black">2020-11-11</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to dance: A graph convolutional adversarial network to generate
  realistic dance motions from audio -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.SD/paper_2.html">
      <font color="black">Learning to dance: A graph convolutional adversarial network to generate
  realistic dance motions from audio</font>
    </a>
  </h2>
  <font color="black">生成方法の3つの定量的メトリックとユーザー調査を使用して方法を評価します。結果は、提案されたGCNモデルが、さまざまな実験で音楽を条件とする最先端のダンス生成方法よりも優れていることを示唆しています。実際のモーションデータに匹敵する動きの知覚品質。 
[ABSTRACT]音楽から自然に動くこと、つまりダンスを学ぶことは、人間が楽に行うことが多いより複雑な動きの1つです。この方法は、音声情報からの自動ダンス生成の問題に取り組むように設計されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Sparsity-based audio declipping methods: selected overview, new
  algorithms, and large-scale evaluation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.SD/paper_3.html">
      <font color="black">Sparsity-based audio declipping methods: selected overview, new
  algorithms, and large-scale evaluation</font>
    </a>
  </h2>
  <font color="black">コードは、再現性のある調査とベンチマークを目的として公開されています。最後に、これらの組み合わせと最先端の方法の選択を体系的に比較します。オーディオデクリッピングの最近の進歩により、最先端技術が大幅に向上しました。 。特定の飽和状態での％。 
[ABSTRACT]新しい方法は、大規模な数値ベンチマークと小規模な正式なリスニングテストを使用します。これは、音声と音楽の両方のジャンルのさまざまなクリッピングレベルのガイドラインを提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-19">
        <br><font color="black">2020-05-19</font>
      </time>
    </span>
</section>
<!-- paper0: ResNeXt and Res2Net Structures for Speaker Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.SD/paper_4.html">
      <font color="black">ResNeXt and Res2Net Structures for Speaker Verification</font>
    </a>
  </h2>
  <font color="black">残余接続をCNNに導入し、残余ブロックを標準化することにより、ResNet構造は、高度なネットワークをトレーニングして、競争力の高い認識パフォーマンスを実現できます。深さと幅に加えて、モデルの表現能力を向上させます。スケールの次元を増やすことにより、Res2Netモデルはさまざまな粒度でマルチスケールの特徴を表現でき、特に短い発話のスピーカー検証を容易にします。 
[概要]このホワイトペーパーでは、話者認証のために、resnetアーキテクチャの2つの拡張機能であるresnextとres2netを紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Regularization and Normalization For Generative Adversarial Networks: A
  Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_0.html">
      <font color="black">Regularization and Normalization For Generative Adversarial Networks: A
  Survey</font>
    </a>
  </h2>
  <font color="black">認められているように、正則化と正規化は事前情報を導入する一般的な方法であり、安定性トレーニングにも使用できます。このペーパーでは、これらの方法の分析を示し、この分野で可能な将来の研究に焦点を当てます。現在、多くの正則化と正規化方法はGANで提案されています。これらの方法を体系的に説明するために、このペーパーでは、GANで使用される正規化と正規化の方法を要約し、勾配ペナルティ、ノルムの正規化と正規化、ヤコビアンの正規化、レイヤーの正規化、一貫性の正規化の7つのグループに分類します。 、データ拡張、および自己監視。 
[概要]標準ガンの提案は、ネットワークの無限容量のノンパラメトリック仮定に基づいています。これは、可能な将来のノンパラメトリック仮定に基づいています。これは、非現実的などのガントレーニングで説明できます。 、モードの崩壊、勾配の消失、およびハイパーパラメータの感度</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: SAR Image Despeckling Based on Convolutional Denoising Autoencoder -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_1.html">
      <font color="black">SAR Image Despeckling Based on Convolutional Denoising Autoencoder</font>
    </a>
  </h2>
  <font color="black">バッチ正規化戦略はC-DAEと統合され、列車の時間を短縮します。合成開口レーダー（SAR）イメージングでは、スペックル除去は画像分析にとって非常に重要ですが、スペックルはコヒーレントイメージングシステムによって引き起こされる一種の乗法性ノイズとして知られています。 ..ほとんどの画像SAR画像スペックル除去アプローチとは異なり、提案されたアプローチは、破損した画像からスペックルを直接学習します。 
[概要]過去30年間で、sar画像のノイズを除去するためのさまざまなアルゴリズムが提案されてきました。この方法では、オートエンコーダ（c --dae）を使用してプロセスを再構築します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Sparse-View Spectral CT Reconstruction Using Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_2.html">
      <font color="black">Sparse-View Spectral CT Reconstruction Using Deep Learning</font>
    </a>
  </h2>
  <font color="black">代わりに、マルチチャネル入力および出力を備えたU-Netを使用してスパースビュースペクトルCTデータを高速に再構成するためのアプローチを提案します。結果は、私たちのアプローチが最先端を凌駕できることを定性的および定量的に示しています。反復法..スペクトルCTは、高い化学的特異性を提供できる新しいテクノロジーであり、荷物の脅威の検出など、多くのアプリケーションにとって重要です。 
[ABSTRACT]ネットワークは、入力画像から高品質の画像を生成するようにトレーニングされています。ネットワークは、チャネルの相互作用を利用して品質を向上させることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: DRDr II: Detecting the Severity Level of Diabetic Retinopathy Using Mask
  RCNN and Transfer Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_3.html">
      <font color="black">DRDr II: Detecting the Severity Level of Diabetic Retinopathy Using Mask
  RCNN and Transfer Learning</font>
    </a>
  </h2>
  <font color="black">世界中から収集された35,000を超える眼底画像を含む大きなデータセットを採用し、特徴抽出と2段階の前処理を行った後、92％を超える精度で正しい重症度レベルを予測することに成功しました。つまり、DRDrは、糖尿病性網膜症（DR）患者の目に見られる2種類の病変（滲出液と微小動脈瘤）のセグメンテーションマスクを検出、特定、作成するようにトレーニングされています。モデル全体をパイプラインのコアで固体特徴抽出器として使用して、DRケースの重大度レベルを検出します。DRDrIIは、機械学習と深層学習の世界のハイブリッドです。 
[ABSTRACT] drdrは、糖尿病性網膜症（dr）患者の眼に見られる2種類の病変のセグメンテーションマスクを検出、特定、作成するようにトレーニングされています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: SIR: Self-supervised Image Rectification via Seeing the Same Scene from
  Multiple Different Lenses -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_4.html">
      <font color="black">SIR: Self-supervised Image Rectification via Seeing the Same Scene from
  Multiple Different Lenses</font>
    </a>
  </h2>
  <font color="black">さらに、微分可能なワーピングモジュールを活用して、歪みパラメータから修正された画像と再歪みされた画像を生成し、トレーニング中にそれらの間のモデル内およびモデル間の一貫性を活用します。これにより、地面を必要としない自己教師あり学習スキームが実現します。 -真の歪みパラメータまたは通常の画像..自己教師あり学習は、自己一貫性を維持しながら歪みモデルの普遍性も向上させます。この論文では、重要な洞察に基づいた新しい自己監視画像補正（SIR）法を提案します。異なるレンズからの同じシーンの歪んだ画像の修正結果は同じでなければならないこと。 
[概要]モデルは合成画像に適合しすぎて、現実世界の魚眼画像では一般化されない可能性があります。これは、特定の歪みモデルの普遍性が限られていることと、歪みと補正のプロセスを明示的にモデル化していないことが原因です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Image Quality Assessment for Perceptual Image Restoration: A New
  Dataset, Benchmark and Metric -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_5.html">
      <font color="black">Image Quality Assessment for Perceptual Image Restoration: A New
  Dataset, Benchmark and Metric</font>
    </a>
  </h2>
  <font color="black">既存のIQA手法は、空間的な不整合に対する許容度が低いこともあり、GANベースの歪みに対して不十分なパフォーマンスを示すという発見に触発され、この不整合を明示的に考慮することにより、GANベースの歪みに対するIQAネットワークのパフォーマンスを改善することを提案します。 。最後に、GANベースの歪みに対するIQAパフォーマンスを改善する方法に光を当てました。特に、知覚品質と評価結果の間にますます矛盾が見られます。 
[概要] 2つの質問を提示します：既存のiqaメソッドは最近のirアルゴリズムを客観的に評価できますか？より信頼性の高いeloシステムを使用してpipal画像の主観的スコアを割り当てるために113万人以上の人間の判断を収集します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Enhanced 3D Myocardial Strain Estimation from Multi-View 2D CMR Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_6.html">
      <font color="black">Enhanced 3D Myocardial Strain Estimation from Multi-View 2D CMR Imaging</font>
    </a>
  </h2>
  <font color="black">手順は、16人の健康なボランティアのCMRSSFP画像を含むSTACOM2011データセットで評価されました。さらに、長軸に沿った変位に基づく重み付けスキームを導入することにより、変位の過大評価を修正します。対象のイメージングモダリティ（SSFP）について、チャレンジで報告された結果と比較した3つのひずみ成分（半径方向、円周方向、縦方向）。 
[概要]提案された手順は、再構築されたメッシュモデルを変形する際の柔軟性を追加して、2Dトラッキング結果を改善するための比較的高速で簡単な方法を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-25">
        <br><font color="black">2020-09-25</font>
      </time>
    </span>
</section>
<!-- paper0: DiCENet: Dimension-wise Convolutions for Efficient Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_7.html">
      <font color="black">DiCENet: Dimension-wise Convolutions for Efficient Networks</font>
    </a>
  </h2>
  <font color="black">深さ方向に分離可能な畳み込みと比較して、DiCEユニットはさまざまなアーキテクチャ間で大幅な改善を示しています。DiCEユニットを積み重ねてDiCENetモデルを構築すると、画像を含むさまざまなコンピュータビジョンタスク全体で最先端モデルよりも大幅な改善が見られます。分類、オブジェクト検出、およびセマンティックセグメンテーション..ImageNetデータセットでは、DiCENetは、最先端の手動で設計されたモデル（MobileNetv2やShuffleNetv2など）よりも2〜4％高い精度を提供します。 
[概要]ダイスユニットは、軽量の畳み込みフィルタリングを使用してデータをエンコードします。空間およびチャネルのパフォーマンスをエンコードできます。ただし、さまざまなアーキテクチャ間で大幅な改善が見られます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-08">
        <br><font color="black">2019-06-08</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Interactive Denoiser (DID) for X-Ray Computed Tomography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_8.html">
      <font color="black">Deep Interactive Denoiser (DID) for X-Ray Computed Tomography</font>
    </a>
  </h2>
  <font color="black">実験結果は、DIDが異なるノイズ解像度のトレードオフで複数の画像候補を提供できることを示し、さまざまなネットワークアーキテクチャに関する優れた一般化可能性、およびさまざまなノイズレベルのデータセットのトレーニングとテストを示しています。デノイザーはLDCTの品質を向上させるために公然と使用されています。ただし、DLベースのデノイザーに関しては2つの課題があります。1）トレーニング済みモデルは通常、さまざまな臨床タスクで必要になることがあるさまざまなノイズ解像度のトレードオフを持つさまざまな画像候補を生成しません。 2）テスト画像のノイズレベルがトレーニングデータセットのノイズレベルと異なる場合、モデルの一般化可能性が問題になる可能性があります。 
[概要]トレーニングされたモデルは通常、異なるノイズを持つ異なる画像候補を生成しません-解像度のトレードオフ。テスト画像のノイズレベルがトレーニングデータセットのノイズレベルと異なる場合、モデルの一般化可能性が問題になる可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Fast, Self Supervised, Fully Convolutional Color Normalization of H&E
  Stained Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_9.html">
      <font color="black">Fast, Self Supervised, Fully Convolutional Color Normalization of H&E
  Stained Images</font>
    </a>
  </h2>
  <font color="black">以前に提案された色正規化方法は、正規化の参照として小さなパッチを考慮します。これにより、分布外のソース画像にアーティファクトが作成されます。色の変化は、組織病理学における自動診断システムの深層学習ベースのソリューションの展開に問題を引き起こします。ほとんどの計算はGPUではなくCPUで実行されるため、メソッドも低速です。 
[概要]以前に提案された色正規化方法は、正規化の参照として小さなパッチを考慮します。これにより、分布ソース画像の外にアーティファクトが作成されます。現在、提案された方法は、最先端技術よりも高速で、精度が大幅に向上しています。メソッド</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Quantitative Assessment of Adulteration and Reuse of Coconut Oil Using
  Transmittance Multispectral Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_10.html">
      <font color="black">Quantitative Assessment of Adulteration and Reuse of Coconut Oil Using
  Transmittance Multispectral Imaging</font>
    </a>
  </h2>
  <font color="black">さまざまなレベルの再加熱油クラスに対して異なるクラスターが取得され、トレーニングサンプルで0.983の精度で分類が実行されました。幅広い用途で知られているココナッツオイルは、他の食用油と混ぜ合わされることがよくあります。その後、別のアルゴリズムが提案されます。ココナッツオイルの再加熱と再利用の効果を決定するためのスペクトルクラスタリングベースの分類器を開発する。 
[概要]食品の調理にココナッツオイルを使用すると、健康上の問題が発生する可能性があります。他の方法には、観察されたマルチスペクトルイメージングシステムの使用が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Distortion-aware Monocular Depth Estimation for Omnidirectional Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_11.html">
      <font color="black">Distortion-aware Monocular Depth Estimation for Omnidirectional Images</font>
    </a>
  </h2>
  <font color="black">360Dデータセットでの実験は、提案された方法が歪んだパノラマから意味的特徴を効果的に抽出し、歪によって引き起こされる監視バイアスを軽減できることを示しています。それは高効率で360Dデータセットの最先端のパフォーマンスを達成します。変形可能な畳み込みを利用して、サンプリンググリッドをパノラマ上の歪んだオブジェクトの幾何学的変化に調整し、ストリッププーリングモジュールを利用して、逆ノモニック投影によって導入された水平方向の歪みに対してサンプリングします。 
[概要]歪みを意識した単眼全方向（ダモ）高密度深度推定ネットワークが提案されました。このプロジェクトでは、変形可能な畳み込みを使用して、歪みのあるオブジェクトの幾何学的変化に合わせてサンプリング機能を調整します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-18">
        <br><font color="black">2020-10-18</font>
      </time>
    </span>
</section>
<!-- paper0: MAVIDH Score: A Corona Severity Scoring using Interpretable Chest X-Ray
  Pathology Features -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_12.html">
      <font color="black">MAVIDH Score: A Corona Severity Scoring using Interpretable Chest X-Ray
  Pathology Features</font>
    </a>
  </h2>
  <font color="black">主な貢献として、この方法は、他の既存の方法と比較すると、疾患進行のさまざまな段階で患者の重症度と比較的よく相関していることが示されています。データ選択の独自のアプローチも提案されており、単純なモデルで重症度関連を学習できます。機能..COVID-19診断のためのコンピュータービジョンの適用は、患者の誤分類に関連するリスクを考えると、複雑で困難です。 
[要約]肺に基づく簡単な方法-胸部X線から疾患の重症度をスコアリングするための病理学的特徴が提案されています。他の端よりも簡単で解釈可能です-より複雑なモデルで、この作業も脇に置いています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Independent Component Analysis for noise and artifact removal in
  Three-dimensional Polarized Light Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_13.html">
      <font color="black">Independent Component Analysis for noise and artifact removal in
  Three-dimensional Polarized Light Imaging</font>
    </a>
  </h2>
  <font color="black">灰白質領域の自動セグメンテーションとは別に、ラットとベルベットモンキーの脳切片からのいくつかの3D-PLI画像にノイズ除去手順を適用しました。ここでは、ICAを適用できる灰白質領域の自動ノイズ除去手順を示します。微視的画像にも、妥当な計算量で..近年、独立成分分析（ICA）を適用して、メソスケール（すなわち、3次元偏光イメージング）から得られた画像のノイズとアーティファクトを除去することに成功しました。 、64 $ \ mu $ m）。 
[概要] 3dに加えて、灰白質の自動ノイズ除去手順を紹介します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: A Tiny CNN Architecture for Medical Face Mask Detection for
  Resource-Constrained Endpoints -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_14.html">
      <font color="black">A Tiny CNN Architecture for Medical Face Mask Detection for
  Resource-Constrained Endpoints</font>
    </a>
  </h2>
  <font color="black">世界保健機関によると、コロナウイルスの感染を阻止する最も効果的な方法は、医療用フェイスマスクを着用することです。480MHzで動作し、わずか496KBのフレームバッファRAMを備えたARMCortex-M7マイクロコントローラを備えた小さな開発ボードにはモデルの展開に使用されました。提案されたモデルは、量子化後138 KBであり、30FPSの推論速度で実行されます。 
[概要]世界保健機関によると、コロナウイルスの感染を阻止する最も効果的な方法は、医療用フェイスマスクを着用することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Deep Video Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_15.html">
      <font color="black">Unsupervised Deep Video Denoising</font>
    </a>
  </h2>
  <font color="black">蛍光顕微鏡および電子顕微鏡データに関する実験は、グラウンドトゥルースクリーンデータが一般的に利用できないイメージングモダリティに対する私たちのアプローチの可能性を示しています。ディープコンボリューションニューラルネットワーク（CNN）は、現在、ノイズ除去において最先端のパフォーマンスを実現しています。ビデオ..それらは通常、監視下でトレーニングされ、ネットワーク出力とグラウンドトゥルースクリーンビデオの間のエラーを最小限に抑えます。 
[概要]ネットワークは通常、監視付きでトレーニングされ、ネットワーク出力とグラウンド間のエラーを最小限に抑えます-真実のクリーンなビデオ。これはこれらのケースに対処するためのものであり、教師なし静止画像ノイズ除去の最近の進歩に基づいて、教師なしディープビデオノイズ除去装置を開発しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Deep learning approach to left ventricular non-compaction measurement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_16.html">
      <font color="black">Deep learning approach to left ventricular non-compaction measurement</font>
    </a>
  </h2>
  <font color="black">推論結果は、ディープラーニングベースのアプローチがLVNCの診断と測定で優れた結果を達成できることを確認します。さらに、特定されたゾーンでの出力画像の主観的評価は、すべてのスライスについて完全な視覚的一致で、専門の心臓専門医によって実行されます、既存の自動ツールよりも優れています。4つのCNNは、肥大性心筋症と診断された患者の集団に対して、左心室の圧縮された小柱領域を自動的にセグメント化するようにトレーニングされています。 
[概要] 4つのcnnは、左心室の圧縮された小柱領域を自動的にセグメント化するようにトレーニングされています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Adaptive noise imitation for image denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_17.html">
      <font color="black">Adaptive noise imitation for image denoising</font>
    </a>
  </h2>
  <font color="black">実験によると、ADANIによって生成されたノイズの多いデータは実際のデータと視覚的および統計的に類似しているため、この方法のノイズ除去CNNは、外部のペアデータでトレーニングされた他のネットワークと競合します。既存のノイズ除去アルゴリズムの有効性は、通常、正確な事前定義に依存します。ノイズ統計または多くのペアデータ。これは実用性を制限します。この作業では、ノイズ統計とペアデータが利用できない、より一般的なケースでのノイズ除去に焦点を当てます。 
[概要]この作業では、ノイズ統計とペアデータが利用できない、より一般的なケースでのノイズ除去に焦点を当てます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Long-range medical image registration through generalized mutual
  information (GMI): toward a fully automatic volumetric alignment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_18.html">
      <font color="black">Long-range medical image registration through generalized mutual
  information (GMI): toward a fully automatic volumetric alignment</font>
    </a>
  </h2>
  <font color="black">GMI関数は、アルゴリズムをグローバルな最大値に駆動する滑らかな等値面を持っていることが示されました。画像レジストレーションは、医用画像処理の重要な操作であり、多数のアプリケーションを可能にします。画像。 
[要約]結果は、極大値のトラップを回避して、登録範囲が延長されたことを示しています。ただし、1、113人の被験者のt1およびt2 mri画像からのモンテカルロシミュレーションで150％の成功</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Driver Anomaly Detection: A Dataset and Contrastive Learning Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_19.html">
      <font color="black">Driver Anomaly Detection: A Dataset and Contrastive Learning Approach</font>
    </a>
  </h2>
  <font color="black">このタスクでは、新しいビデオベースのベンチマークであるDriver Anomaly Detection（DAD）データセットを紹介します。これには、通常の運転ビデオと、トレーニングセット内の一連の異常アクションが含まれています。DADデータセットのテストセットには、は、通常の運転からまだ除外する必要がある目に見えない異常なアクションです。私たちの方法は、テストセットで0.9673 AUCに達し、異常検出タスクでの対照的な学習アプローチの有効性を示しています。 
[概要]お父さんのデータセットのテストセットには、通常の運転からまだ選別する必要がある目に見えない異常なアクションがあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-30">
        <br><font color="black">2020-09-30</font>
      </time>
    </span>
</section>
<!-- paper0: ViDi: Descriptive Visual Data Clustering as Radiologist Assistant in
  COVID-19 Streamline Diagnostic -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_20.html">
      <font color="black">ViDi: Descriptive Visual Data Clustering as Radiologist Assistant in
  COVID-19 Streamline Diagnostic</font>
    </a>
  </h2>
  <font color="black">ほとんどの記述的クラスタリングアプローチは、ドメイン固有の特性を使用して意味のあるクラスターを形成しますが、クラスターの均一性を実現するためのすべての学習プロセスのより汎用的な要素として、モデルレベルの説明に焦点を当てます。DeepSHAPを使用して、疾患に関して均一なクラスターを生成します。重大度を決定し、画像のクラス識別領域を視覚化する有利および不利な顕著性マップを使用してクラスターを記述します。調査によると、分類は実際の意思決定を加速する上で重要なルールとなる可能性があります。 
[ABSTRACT] covidは、vgg-19に基づくモデルであり、95％および97％の正の予測可能な予測値でcovidおよび肺炎の症例を特定できます。これらのモデルは、人間と機械の相互作用および専門家の意思決定を特定できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Reducing Textural Bias Improves Robustness of Deep Segmentation CNNs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_21.html">
      <font color="black">Reducing Textural Bias Improves Robustness of Deep Segmentation CNNs</font>
    </a>
  </h2>
  <font color="black">ディープラーニングの現在の進歩にもかかわらず、ドメインシフトは医療画像設定で一般的な問題のままです。これを達成するために、Developing Human Connectome Projectから公開されているMRIスキャンを使用して、テクスチャノイズのシミュレーションが堅牢なモデルのトレーニングに役立つ方法を調査します。複雑なセグメンテーションタスク..私たちの調査結果は、モデルをトレーニングする前に特定のタイプのテクスチャフィルタを適用することで、以前は見えなかったノイズによって破損したスキャンをセグメント化する能力をどのように高めることができるかを示しています。 
[ABSTRACT]ディープニューラルモデルは、画像分類タスクを実行するときにテクスチャバイアスを示す可能性があります。これは、畳み込みニューラルネットワーク（cnns）の一般的な理解に反します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Zero-Shot Calibration of Fisheye Cameras -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_22.html">
      <font color="black">Zero-Shot Calibration of Fisheye Cameras</font>
    </a>
  </h2>
  <font color="black">実験結果は、ゼロショット法のキャリブレーション精度が従来のフルキャリブレーション結果に匹敵することを示しています。さらに、この方法で推定されたカメラパラメータを使用して、既存のキャリブレーション方法を適切に初期化し、収束させることもできます。より安定し、局所的な最小値を回避します。提案された方法のキャリブレーション精度は、8つの異なる市販のカメラで定性的および定量的に評価され、従来のキャリブレーション方法と比較されます。 
[概要]提案された方法は、画像の歪みが大きい広角カメラまたは魚眼カメラに特に役立ちます。この方法は、実際のキャリブレーションの実用的な代替手段として、およびキャリブレーションの精度がそれほど重要ではないほとんどのフィールドアプリケーションで使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Learning-based lossless compression of 3D point cloud geometry -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.IV/paper_23.html">
      <font color="black">Learning-based lossless compression of 3D point cloud geometry</font>
    </a>
  </h2>
  <font color="black">私たちのコンテキストモデルは、これらのプロパティの恩恵を受け、VoxelDNNと呼ばれるマスクされたフィルターを備えた深い畳み込みニューラルネットワークを使用してボクセルの確率分布を学習します。ポイントクラウドをポイントクラウド構造に従ってマルチ解像度ボクセルブロックに適応的に分割し、octreeを使用します。パーティショニングを通知するために..ニューラルネットワークによって明示的に処理されます。 
[概要]当社のエンコーダーはハイブリッドモードで動作し、オクツリーとボクセルベースのプログラミングを混合します。この方法は、最先端のmpegg-pcc標準よりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Regularization and Normalization For Generative Adversarial Networks: A
  Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_0.html">
      <font color="black">Regularization and Normalization For Generative Adversarial Networks: A
  Survey</font>
    </a>
  </h2>
  <font color="black">人気のある生成モデルである生成的敵対的ネットワーク（GAN）は、ディープニューラルネットワークの開発のおかげでさまざまなシナリオで広く適用されています。認められているように、正則化と正規化は事前情報を導入する一般的な方法であり、安定性トレーニングに使用できます。現在、GANでは多くの正則化と正規化の方法が提案されています。これらの方法を体系的に説明するために、このペーパーでは、GANで使用される正則化と正規化の方法を要約し、勾配ペナルティ、ノルム正規化、および7つのグループに分類します。正則化、Jacobian正則化、レイヤー正規化、整合性正則化、データ拡張、および自己監視。 
[概要]標準ガンの提案は、ネットワークの無限容量のノンパラメトリック仮定に基づいています。これは、可能な将来のノンパラメトリック仮定に基づいています。これは、非現実的などのガントレーニングで説明できます。 、モードの崩壊、勾配の消失、およびハイパーパラメータの感度</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-19">
        <br><font color="black">2020-08-19</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End 3D Point Cloud Learning for Registration Task Using Virtual
  Correspondences -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_1.html">
      <font color="black">End-to-End 3D Point Cloud Learning for Registration Task Using Virtual
  Correspondences</font>
    </a>
  </h2>
  <font color="black">これに基づいて、仮想対応点をソフトポインターベースの方法で生成でき、最後に、SVD法を実装することで点群登録の問題を解決できます。3D点群登録は、困難なため、依然として非常に難しいトピックです。部分的に対応する2つの点群間の剛体変換を見つける際に、初期推定情報がない場合はさらに困難になります。ModelNet40データセットの比較結果は、提案されたアプローチが点群登録の最先端に到達することを検証します。 KITTIデータセットのタスクと実験結果は、実際のアプリケーションで提案されたアプローチの有効性を検証します。 
[概要]この論文では、点群登録問題を解決するためのエンドツー-機能を紹介します。自己注意メカニズムは、構造情報を強化するために強化されています。クロスポインタメカニズムは、 2点群</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: SAR Image Despeckling Based on Convolutional Denoising Autoencoder -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_2.html">
      <font color="black">SAR Image Despeckling Based on Convolutional Denoising Autoencoder</font>
    </a>
  </h2>
  <font color="black">バッチ正規化戦略はC-DAEと統合されており、列車の時間を短縮します。私たちのアプローチは他のアプローチよりも優れていることが明らかになりました。 -DAE）スペックルのないSAR画像を再構成します。 
[概要]過去30年間で、sar画像のノイズを除去するためのさまざまなアルゴリズムが提案されてきました。この方法では、オートエンコーダ（c --dae）を使用してプロセスを再構築します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: AFD-Net: Adaptive Fully-Dual Network for Few-Shot Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_3.html">
      <font color="black">AFD-Net: Adaptive Fully-Dual Network for Few-Shot Object Detection</font>
    </a>
  </h2>
  <font color="black">具体的には、個別の特徴抽出用のデュアルクエリエンコーダーとデュアルアテンションジェネレーター、および個別のモデルの再重み付け用のデュアルアグリゲーターを導入することにより、Faster R-CNNを拡張します。検出器は、2つのサブタスクの明示的な分解を考慮し、両方からの情報を活用して特徴表現を強化する必要があります。自発的に、R-CNN検出器を使用して個別の意思決定が行われます。 
[ABSTRACT]新しい方法は、検出器の共有コンポーネントを使用して機能しますが、2つのサブタスクの埋め込みスペースの優先度の違いを考慮に入れて分析するものはほとんどありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: On Initial Pools for Deep Active Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_4.html">
      <font color="black">On Initial Pools for Deep Active Learning</font>
    </a>
  </h2>
  <font color="black">自己監視/教師なしの方法で表現を学習する最近の成功を踏まえ、インテリジェントにサンプリングされた初期ラベル付きプールが深いALパフォーマンスを改善できるかどうかを調査することを提案します。能動学習（AL）手法は、モデルのトレーニングに必要なトレーニングデータを最小限に抑えることを目的としています。与えられたタスクについて..自己監視および教師なし戦略の使用を含む、インテリジェントにサンプリングされた初期ラベル付きプールが深いALメソッドに与える影響を調査します。 
[概要]プールベースのすべての手法は、最初にラベル付けされた小さなプールから始まり、ラベル付けのために最も有益なサンプルのバッチを選択します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: How Good MVSNets Are at Depth Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_5.html">
      <font color="black">How Good MVSNets Are at Depth Fusion</font>
    </a>
  </h2>
  <font color="black">追加の入力深度がディープマルチビューステレオの品質を向上させる可能性があることを示します。低品質のセンサー深度の形で、ディープマルチビューステレオメソッドへの追加入力の影響を調査します。2つの状態を変更します-入力深度で使用するための最先端のディープマルチビューステレオメソッド。 
[ABSTRACT]入力深度で使用するための2つの最先端のディープマルチビューステレオメソッドを変更します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: CIAGAN: Conditional Identity Anonymization Generative Adversarial
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_6.html">
      <font color="black">CIAGAN: Conditional Identity Anonymization Generative Adversarial
  Networks</font>
    </a>
  </h2>
  <font color="black">条件付き生成敵対的ネットワークに基づく画像とビデオの匿名化のモデルであるCIAGANを提案および開発します。以前の方法とは異なり、匿名化（匿名化）手順を完全に制御し、匿名化と多様性の両方を保証します。いくつかのベースラインへの私たちの方法と最先端の結果を達成します。 
[概要]私たちは私たちの方法をいくつかのベースラインと比較し、最先端の結果を達成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-19">
        <br><font color="black">2020-05-19</font>
      </time>
    </span>
</section>
<!-- paper0: 3DSNet: Unsupervised Shape-to-Shape 3D Style Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_7.html">
      <font color="black">3DSNet: Unsupervised Shape-to-Shape 3D Style Transfer</font>
    </a>
  </h2>
  <font color="black">提案されたフレームワークは、点群とメッシュの両方の形式で新しい3D形状を合成できます。学習した分布からスタイルコードをサンプリングすることにより、モデルが特定の参照オブジェクトに与えることができるスタイルの多様性を増やします。 3D設定でのベースのスタイル転送は、ほとんど未踏の問題のままです。 
[概要]私たちの方法では、ソースとターゲットの3Dモデルのコンテンツとスタイルを組み合わせて、ソースコンテンツを保持しながら、ターゲットのスタイルに似た新しいスタイルを生成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-26">
        <br><font color="black">2020-11-26</font>
      </time>
    </span>
</section>
<!-- paper0: SplitNet: Divide and Co-training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_8.html">
      <font color="black">SplitNet: Divide and Co-training</font>
    </a>
  </h2>
  <font color="black">その結果、小規模なネットワークは、追加のパラメーターやFLOPがほとんどまたはまったくない大規模なネットワークよりも優れたアンサンブルパフォーマンスを実現できます。コードは\ url {https://github.com/mzhaoshuai/SplitNet-Divide-and-Coで入手できます。 -トレーニング} ..広範な実験を通じて、共通のベンチマークでさまざまなネットワークアーキテクチャを使用して、ネットワークの数を増やすことが効果的なモデルスケーリングの新しい次元であるというアイデアを検証します。 
[ABSTRACT]ネットワークは幅に比例して改善せず、すぐに飽和状態になります。それを証明するために、1つの大きなネットワークがいくつかの小さなネットワークに分割されます。これらのグループはこの共同トレーニングプロセス中にそれらから学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: DRDr II: Detecting the Severity Level of Diabetic Retinopathy Using Mask
  RCNN and Transfer Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_9.html">
      <font color="black">DRDr II: Detecting the Severity Level of Diabetic Retinopathy Using Mask
  RCNN and Transfer Learning</font>
    </a>
  </h2>
  <font color="black">世界中から収集された35,000を超える眼底画像を含む大きなデータセットを採用し、特徴抽出と2段階の前処理を行った後、92％を超える精度で正しい重症度レベルを予測することに成功しました。つまり、DRDrは、糖尿病性網膜症（DR）患者の目に見られる2種類の病変（滲出液と微小動脈瘤）のセグメンテーションマスクを検出、特定、作成するようにトレーニングされています。モデル全体をパイプラインのコアで固体特徴抽出器として使用して、DRケースの重大度レベルを検出します。DRDrIIは、機械学習と深層学習の世界のハイブリッドです。 
[ABSTRACT] drdrは、糖尿病性網膜症（dr）患者の眼に見られる2種類の病変のセグメンテーションマスクを検出、特定、作成するようにトレーニングされています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-scale Adaptive Task Attention Network for Few-Shot Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_10.html">
      <font color="black">Multi-scale Adaptive Task Attention Network for Few-Shot Learning</font>
    </a>
  </h2>
  <font color="black">人気のあるベンチマークでの広範な実験は、最先端の方法と比較して提案されたMATANetの有効性を明確に示しています。具体的には、最初にマルチスケールフィーチャジェネレータを使用して、異なるスケールで複数のフィーチャを生成します。次に、適応タスクタスク全体の中から最も重要なLRを選択するために、アテンションモジュールが提案されています。 
[要約]ローカル表現（lrs）が表示されているクラスと表示されていないクラスの間でより一貫しているため、低レベルの情報メトリック-学習ベースの方法は満足のいくパフォーマンスを達成しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: SIR: Self-supervised Image Rectification via Seeing the Same Scene from
  Multiple Different Lenses -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_11.html">
      <font color="black">SIR: Self-supervised Image Rectification via Seeing the Same Scene from
  Multiple Different Lenses</font>
    </a>
  </h2>
  <font color="black">さらに、微分可能なワーピングモジュールを活用して、歪みパラメータから修正された画像と再歪みされた画像を生成し、トレーニング中にそれらの間のモデル内およびモデル間の一貫性を活用します。これにより、地面を必要としない自己教師あり学習スキームが実現します。 -真の歪みパラメータまたは通常の画像..具体的には、共有エンコーダといくつかの予測ヘッドを備えた新しいネットワークアーキテクチャを考案し、それぞれが特定の歪みモデルの歪みパラメータを予測します。自己教師あり学習により、歪みの普遍性も向上します。自己一貫性を保ちながらモデルを作成します。 
[概要]モデルは合成画像に適合しすぎて、現実世界の魚眼画像では一般化されない可能性があります。これは、特定の歪みモデルの普遍性が限られていることと、歪みと補正のプロセスを明示的にモデル化していないことが原因です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Meta Batch-Instance Normalization for Generalizable Person
  Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_12.html">
      <font color="black">Meta Batch-Instance Normalization for Generalizable Person
  Re-Identification</font>
    </a>
  </h2>
  <font color="black">多くの既存の方法は、スタイルのバリエーションを減らすためにインスタンス正規化手法を採用していますが、識別情報の損失は避けられませんでした。広範な実験結果は、私たちのモデルが大規模なドメインの一般化で最先端の方法よりも優れていることを示していますRe-IDベンチマーク..さらに、一般化機能を強化するために、周期的な内部更新方法を伴うメタトレイン損失を介して仮想シミュレーションを多様化します。 
[概要]このペーパーでは、メタバッチ-インスタンス正規化（メタビン）という名前の新しい一般化可能なre-idフレームワークを提案します。アイデアはドメインとメタを組み合わせて学習し、課題の課題を調査します。メタビンフレームワークは、モデルの過剰適合を防ぎます。追加のデータ拡張や複雑なネットワーク設計なしで、見えないドメインへの一般化機能を改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Where to Explore Next? ExHistCNN for History-aware Autonomous 3D
  Exploration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_13.html">
      <font color="black">Where to Explore Next? ExHistCNN for History-aware Autonomous 3D
  Exploration</font>
    </a>
  </h2>
  <font color="black">この作業では、深度カメラを使用して未知の屋内環境の自律3D探索の問題に対処します。これを分類問題としてNBV推定を再定式化することで行い、現在の両方をエンコードする新しい学習ベースのメトリックを提案します。 3D観測（深度フレーム）と進行中の再構築の履歴..この作業の主な貢献の1つは、現在の深度観測と効率的に結合される補助ユーティリティマップとして3D再構築履歴の新しい表現を導入することです。 
[概要]提案されたexhistcnnは、3D環境の完全な知識を使用してオラクルの探索パフォーマンスにアプローチすることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Where Should We Begin? A Low-Level Exploration of Weight Initialization
  Impact on Quantized Behaviour of Deep Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_14.html">
      <font color="black">Where Should We Begin? A Low-Level Exploration of Weight Initialization
  Impact on Quantized Behaviour of Deep Neural Networks</font>
    </a>
  </h2>
  <font color="black">重みの最終的な分布とさまざまなCNNアーキテクチャのアクティブ化に対するさまざまな重みの初期化の影響に関する詳細で詳細なアブレーション研究を紹介します。その結果、さまざまな作業で、固定精度の量子化アルゴリズムと量子化に焦点を当てた最適化を設計しようとしています。量子化によるパフォーマンスの低下を最小限に抑える手法。私たちの知る限り、重みの初期化と量子化された動作への影響について、このような低レベルで詳細な定量分析を行ったのは私たちが初めてです。 
[要約]分析により、初期の重みが最終的な精度と量子化された動作にどのように影響するかについての深い知識を得ることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Vehicle Reconstruction and Texture Estimation Using Deep Implicit
  Semantic Template Mapping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_15.html">
      <font color="black">Vehicle Reconstruction and Texture Estimation Using Deep Implicit
  Semantic Template Mapping</font>
    </a>
  </h2>
  <font color="black">さらに、提示された手法により、3D車両テクスチャ転送やマテリアル識別などの追加アプリケーションが可能になります。また、スパースキーポイントでラベル付けされ、測定されたHDRIを備えた物理ベースレンダリング（PBRT）システムを使用してレンダリングされた830の精巧なテクスチャカーモデルを含む新しい合成データセットを提供します。スカイマップを使用して、非常にリアルな画像を取得します。3Dテクスチャ分布を推測する既存の表現と比較して、この方法では、テンプレートの2D表面のテクスチャ分布を明示的に制約し、固定解像度とトポロジの制限を回避します。 
[概要]このコンセプトは、車両の3D表現を組み合わせたものです。これを使用して、可視領域とbr領域の両方で詳細なテクスチャを作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Two-Level Adversarial Visual-Semantic Coupling for Generalized Zero-shot
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_16.html">
      <font color="black">Two-Level Adversarial Visual-Semantic Coupling for Generalized Zero-shot
  Learning</font>
    </a>
  </h2>
  <font color="black">生成的ゼロショットメソッドのパフォーマンスは、主に、生成された機能の品質と、モデルが視覚ドメインとセマンティックドメイン間の知識の伝達をどの程度促進するかに依存します。4つのベンチマークデータセットでアプローチを評価します。さらに、既存の方法は、合成画像の特徴を生成するか、表現学習を活用して生成された潜在的な埋め込みのいずれかでゼロショット分類器をトレーニングします。 
[要約]これは、視覚ドメインと意味ドメインの間で知識を効果的に伝達するための強力なクロスモーダル相互作用を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-15">
        <br><font color="black">2020-07-15</font>
      </time>
    </span>
</section>
<!-- paper0: How to train your conditional GAN: An approach using geometrically
  structured latent manifolds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_17.html">
      <font color="black">How to train your conditional GAN: An approach using geometrically
  structured latent manifolds</font>
    </a>
  </h2>
  <font color="black">幾何学的な観点からこの問題に取り組み、バニラcGANの多様性と視覚的品質の両方を向上させる新しいトレーニングメカニズムを提案します。提案されたソリューションは、アーキテクチャの変更を必要とせず、条件付き生成を対象とするより効率的なアーキテクチャへの道を開きます。マルチモーダル空間..さまざまなタスクのセットに対するモデルの有効性を検証し、提案されたソリューションが複数のデータセットにわたって一般的で効果的であることを示します。 
[要約]バニラ条件付きガン（cgan）は、モード-崩壊をもたらす潜在的なシードの変化を無視する傾向があります。これは、能力の不足によるものではなく、最適でないトレーニングスキームの結果です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Heuristic Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_18.html">
      <font color="black">Heuristic Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">ビジュアルドメインアダプテーション（DA）では、ドメイン固有の特性をドメイン不変表現から分離することは不適切な問題です。HDAを実行するには、コサイン類似性スコアと、ドメイン不変表現とドメイン固有表現の間の独立性測定をキャストします。学習手順中の初期状態と最終状態での制約について説明します。このペーパーでは、ヒューリスティック検索の観点から、ドメイン不変およびドメイン固有の情報のモデリングについて説明します。 
[概要]このホワイトペーパーでは、ドメインのモデリング（ヒューリスティック検索の観点からの応答性のあるドメイン固有の情報）について説明します。これらの例に加えて、ヒューリスティックドメイン適応の原理的な表現を定式化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Neural networks with late-phase weights -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_19.html">
      <font color="black">Neural networks with late-phase weights</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、後期の重みで標準モデルを拡張すると、CIFAR-10 / 100、ImageNet、enwik8などの確立されたベンチマークの一般化が改善されることを示しています。これらの調査結果は、ノイズの多い2次問題の理論的分析によって補完されます。ニューラルネットワーク学習の後期段階..計算コストの増加を回避するために、残りのパラメーターと乗法的に相互作用する低次元後期段階の重みモデルのファミリーを調査します。 
[ABSTRACT]学習ソリューションは、学習の後期段階で重みのサブセットをアンサンブルすることによってさらに改善できます。これらの調査結果は、ノイズの多い2次問題の理論的分析によって補完されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-25">
        <br><font color="black">2020-07-25</font>
      </time>
    </span>
</section>
<!-- paper0: DUT:Learning Video Stabilization by Simply Watching Unstable Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_20.html">
      <font color="black">DUT:Learning Video Stabilization by Simply Watching Unstable Videos</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、Deep Unsupervised Trajectoryベースの安定化フレームワーク（DUT）を提案します\ footnote {コードはhttps://github.com/Annbless/DUTCodeで入手できます。} ..従来のスタビライザーは、軌道ベースのスムージングに重点を置いています。手作りの機能の使用に関して、オクルージョンされたテクスチャのないケースでは制御可能ですが壊れやすいです。制御可能で堅牢なスタビライザーを構築するために、DUTは、教師なしの深い学習方法で軌道を明示的に推定および平滑化することにより、不安定なビデオを安定化する最初の試みを行います。グリッドベースの軌跡を生成するためのDNNベースのキーポイント検出器とモーションエスティメータ、およびビデオを安定させるためのDNNベースの軌跡スムーザーで構成されています。 
[ABSTRACT]制御可能で堅牢なスタビライザーを構築するために、dutはビデオを安定化しようとしています。制御可能で堅牢なスタビライザーを作成するために、軌道ベースのスムージングに焦点を当てます。これは、制御可能ですが、閉塞したテクスチャのない場合には壊れやすくなります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: FTBNN: Rethinking Non-linearity for 1-bit CNNs and Going Beyond -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_21.html">
      <font color="black">FTBNN: Rethinking Non-linearity for 1-bit CNNs and Going Beyond</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、適切な非線形モジュールを再調査および調整してその矛盾を修正し、精度とトレーニング効率の点で大規模なImageNetデータセットで最先端のパフォーマンスを実現する強力なベースラインを導き出します。 。さらに、BNNモデルの制限された容量は、グループ実行の助けを借りて増やすこともできます。これらの洞察に基づいて、ベースラインを改善し、より少ない場合でも4〜5％のトップ1精度の向上を実現できます。計算コスト。 
[概要]提案されたモデルは、精度を失うことなく、効率的な二項演算をより有効に活用することで圧縮できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-19">
        <br><font color="black">2020-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: FrostNet: Towards Quantization-Aware Network Architecture Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_22.html">
      <font color="black">FrostNet: Towards Quantization-Aware Network Architecture Search</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、単精度（FLOAT32）と量子化（INT8）の両方のパフォーマンスを保証するネットワークを見つけるための新しいネットワークアーキテクチャ検索（NAS）手順を紹介します。勾配ベースのNASをStatAssistおよびGradBoostと統合することにより、量子化効率の高いネットワークビルディングブロック、フロストボトルネック..最初に、量子化対応トレーニング（QAT）を可能にする重要で簡単な最適化方法を提案します：浮動小数点統計支援（StatAssist）と確率的勾配ブースト（GradBoost）。 
[概要]これは、既存のモバイルターゲットネットワークアーキテクチャの量子化されたパフォーマンスに基づいています。最初に、量子化を意識したトレーニングを可能にする方法を提案します。これには、浮動小数点統計支援（statassist）と確率的勾配ブーストが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br><font color="black">2020-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: Enhanced 3D Myocardial Strain Estimation from Multi-View 2D CMR Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_23.html">
      <font color="black">Enhanced 3D Myocardial Strain Estimation from Multi-View 2D CMR Imaging</font>
    </a>
  </h2>
  <font color="black">さらに、長軸に沿った変位に基づく重み付けスキームを導入することにより、変位の過大評価を修正します。この論文では、単一のイメージングの複数の方向からの相補的な変位情報を組み合わせた、拡張された3D心筋ひずみ推定手順を提案します。モダリティ（タグなしCMR SSFP画像）。左心室全体の心筋ひずみを推定するために、市販のソフトウェア（Segment）に実装された2D非剛体登録アルゴリズムを介して短軸、4チャンバー、2チャンバービューのセットを登録します。 、Medviso）。 
[概要]提案された手順は、再構築されたメッシュモデルを変形する際の柔軟性を追加して、2Dトラッキング結果を改善するための比較的高速で簡単な方法を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-25">
        <br><font color="black">2020-09-25</font>
      </time>
    </span>
</section>
<!-- paper0: Perceptual Deep Neural Networks: Adversarial Robustness through Input
  Recreation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_24.html">
      <font color="black">Perceptual Deep Neural Networks: Adversarial Robustness through Input
  Recreation</font>
    </a>
  </h2>
  <font color="black">敵対的な例では、非常に正確ですが、人間とは異なり、機械によって学習されたモデルには多くの弱点があることが示されています。概念は数学的に形式化され、2つのバリエーションが開発されています（1つは画像全体の修復に基づいており、もう1つはノイズの多いものに基づいています）。サイズ変更された超解像レクリエーション）。したがって、$ \ varphi $ DNNは、入力レクリエーションが生物学的ネットワークと同様の人工神経ネットワークに強力な利点をもたらし、入力を意図的に破壊することの重要性に光を当て、知覚モデルベースの領域を開拓することを明らかにします。人工知能におけるロバストな認識のためのGANと自動エンコーダに関する。 
[ABSTRACT]網膜に到達する信号が見えないため、人の知覚も機械とは根本的に異なります。さらに処理する前に独自の入力を再作成する知覚ディープニューラルネットワークを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-02">
        <br><font color="black">2020-09-02</font>
      </time>
    </span>
</section>
<!-- paper0: DiCENet: Dimension-wise Convolutions for Efficient Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_25.html">
      <font color="black">DiCENet: Dimension-wise Convolutions for Efficient Networks</font>
    </a>
  </h2>
  <font color="black">DiCEユニットを積み重ねてDiCENetモデルを構築すると、画像分類、オブジェクト検出、セマンティックセグメンテーションなどのさまざまなコンピュータービジョンタスク全体で、最先端のモデルに比べて大幅な改善が見られます。PyTorchのソースコードはオープンソースです。 https://github.com/sacmehta/EdgeNets/で入手できます。深さ方向に分離可能な畳み込みと比較して、DiCEユニットはさまざまなアーキテクチャ間で大幅な改善を示しています。 
[概要]ダイスユニットは、軽量の畳み込みフィルタリングを使用してデータをエンコードします。空間およびチャネルのパフォーマンスをエンコードできます。ただし、さまざまなアーキテクチャ間で大幅な改善が見られます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-08">
        <br><font color="black">2019-06-08</font>
      </time>
    </span>
</section>
<!-- paper0: Sim2SG: Sim-to-Real Scene Graph Generation for Transfer Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_26.html">
      <font color="black">Sim2SG: Sim-to-Real Scene Graph Generation for Transfer Learning</font>
    </a>
  </h2>
  <font color="black">私たちの実験は、定性的および定量的の両方でドメインギャップを削減することでベースラインを大幅に改善することを示しています。Sim2SGは、2つのドメイン間の外観、ラベル、および予測の不一致に分解することでドメインギャップに対処します。疑似統計ベースの自己を導入することにより、これらの不一致を処理します。学習と敵対的なテクニック。 
[概要]ただし、現在のsg生成手法は、高価で限られた数のラベル付きデータセットの可用性に依存しています。sim2sgは、ドメインギャップを外観、ラベル、予測に分解することで提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: DeepCloth: Neural Garment Representation for Shape and Style Editing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_27.html">
      <font color="black">DeepCloth: Neural Garment Representation for Shape and Style Editing</font>
    </a>
  </h2>
  <font color="black">結論として、提案されたDeepClothを使用して、より柔軟で一般的な3D衣服デジタル化フレームワークの確立に一歩前進します。この作業では、DeepClothと呼ばれる新しい方法を紹介し、無料でスムーズな衣服スタイルの遷移..さらに、上記のUV空間からマッピングされた連続的な特徴空間を学習し、衣服の特徴を制御することで衣服の形状の編集と遷移を可能にします。 
[概要]私たちの重要なアイデアは、衣服の彫刻を「uv-マスク付き位置マップ」で表すことです。衣服のアニメーション、再構築、編集のアプリケーションを示しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Predicting galaxy spectra from images with hybrid convolutional neural
  networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_28.html">
      <font color="black">Predicting galaxy spectra from images with hybrid convolutional neural
  networks</font>
    </a>
  </h2>
  <font color="black">分光法は銀河の進化を支配する物理的プロセスの豊富な説明を提供しますが、分光法データは観測的に取得するのに費用がかかります。銀河イメージングとスペクトルの間の学習されたマッピングは、Vera C.Rubinなどの将来の広視野調査に変換されます。天文台とナンシーグレースローマ宇宙望遠鏡、分光学的に制限された銀河サンプルの科学的リターンを乗算することによって..銀河は、酸素輝線などの光学スペクトルの特徴、またはスパイラルアームなどの形態学的特徴によって説明できます。 
[ABSTRACT]銀河の進化の分光データを取得するには不十分です。たとえば、分光データの取得には観測コストがかかります。新しいアプローチでは、バッチ正規化の代わりにデコンボリューションを使用したハイブリッド畳み込みニューラルネットワークを使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-25">
        <br><font color="black">2020-09-25</font>
      </time>
    </span>
</section>
<!-- paper0: A CRF-based Framework for Tracklet Inactivation in Online Multi-Object
  Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_29.html">
      <font color="black">A CRF-based Framework for Tracklet Inactivation in Online Multi-Object
  Tracking</font>
    </a>
  </h2>
  <font color="black">特徴関数の個別のセットは、実際の状況でのさまざまな課題に対処するために、CRFの単項項と2項項用に設計されています。仮説フィルタリングとダミーノード手法を使用して、MOTコンテキストでCRFノードが変化する問題を処理します。このような欠点を克服するために、離散条件付き確率場（CRF）が開発され、追跡仮説間のフレーム内関係が活用されます。 
[概要]この論文では、crfベースのフレームワークを提案して、オンラインmot問題におけるトラックレットの非アクティブ化の問題に取り組んでいます。これには、固定のしきい値を使用して分割された追跡仮説の分類スコアに依存するトラックレットの非アクティブ化が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Are We Hungry for 3D LiDAR Data for Semantic Segmentation? A Survey and
  Experimental Study -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_30.html">
      <font color="black">Are We Hungry for 3D LiDAR Data for Semantic Segmentation? A Survey and
  Experimental Study</font>
    </a>
  </h2>
  <font color="black">調査結果と議論を共有し、将来の作業で潜在的なトピックにつながる可能性があります。最後に、データ飢餓問題を解決するための既存の取り組みに対する体系的な調査が、方法論とデータセットの両方の観点で行われ、残りの問題と未解決の質問私たちの知る限り、これは、文献レビュー、統計分析、データセット間およびアルゴリズム間の実験で扱われる深層学習手法を使用して、3Dセマンティックセグメンテーションのデータハンガー問題を分析する最初の作業です。次に、最先端の3Dセマンティックセグメンテーションの体系的なレビューが行われ、続いて3つの代表的な深層学習方法の実験と相互検査が行われ、データセットのサイズと多様性が深層モデルのパフォーマンスにどのように影響するかがわかります。 
[概要]この調査は、次の質問に関する包括的な調査と実験的研究を提供します。セマンティックセグメンテーション用の3D LIDARデータに飢えていますか？ディープラーニング手法を使用してデータ飢餓問題を分析する最初の作業</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-08">
        <br><font color="black">2020-06-08</font>
      </time>
    </span>
</section>
<!-- paper0: HybrIK: A Hybrid Analytical-Neural Inverse Kinematics Solution for 3D
  Human Pose and Shape Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_31.html">
      <font color="black">HybrIK: A Hybrid Analytical-Neural Inverse Kinematics Solution for 3D
  Human Pose and Shape Estimation</font>
    </a>
  </h2>
  <font color="black">スイング回転は3Dジョイントで分析的に解決され、ツイスト回転はニューラルネットワークを介した視覚的な手がかりから導出されます。コードはhttps://github.com/Jeff-sjtu/HybrIKで入手できます。モデルベースの3Dポーズと形状の推定方法は、いくつかのパラメータを推定することにより、人体の完全な3Dメッシュを再構築します。 
[概要]この論文では、ボディメッシュ推定と3Dキーポイント推定の間のボリュームについて説明します。hybrikは、3Dポーズの精度と、パラメトリック人間モデルのリアルなボディ構造の両方を維持し、ピクセル整列された3Dボディメッシュを実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: FactorizeNet: Progressive Depth Factorization for Efficient Network
  Architecture Exploration Under Quantization Constraints -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_32.html">
      <font color="black">FactorizeNet: Progressive Depth Factorization for Efficient Network
  Architecture Exploration Under Quantization Constraints</font>
    </a>
  </h2>
  <font color="black">したがって、固定精度の量子化の下での効率と精度のトレードオフに関する詳細なレイヤーレベルの洞察を得ることができます。このような漸進的な深度因数分解戦略により、最適な深度因数分解マクロアーキテクチャ設計の効率的な識別も可能になります（ここで参照します）。望ましい効率-精度要件に基づいてFactorizeNetとして）。この研究では、量子化の制約下で効率的なCNNアーキテクチャ探索のための漸進的な深度因数分解戦略を紹介します。 
[要約]提案された戦略は、層ごとの分散の詳細な低レベルの分析を可能にします。また、最適な層の効率的なIDを可能にします-因数分解されたマクロアーキテクチャ設計</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: DetectoRS: Detecting Objects with Recursive Feature Pyramid and
  Switchable Atrous Convolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_33.html">
      <font color="black">DetectoRS: Detecting Objects with Recursive Feature Pyramid and
  Switchable Atrous Convolution</font>
    </a>
  </h2>
  <font color="black">コードは公開されています。これらを組み合わせると、DetectoRSが生成され、オブジェクト検出のパフォーマンスが大幅に向上します。マクロレベルでは、機能ピラミッドネットワークからの追加のフィードバック接続をボトムアップバックボーンに組み込んだ再帰機能ピラミッドを提案します。レイヤー。 
[概要]本論文では、異なるアトラスレートで特徴を畳み込み、スイッチ機能を使用して結果を収集する、切り替え可能なアトラスコンボリューションを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-03">
        <br><font color="black">2020-06-03</font>
      </time>
    </span>
</section>
<!-- paper0: Duality-Gated Mutual Condition Network for RGBT Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_34.html">
      <font color="black">Duality-Gated Mutual Condition Network for RGBT Tracking</font>
    </a>
  </h2>
  <font color="black">RGBTトラッキングでよく発生する突然のカメラの動きによって引き起こされるトラッキングの失敗に対処するために、オプティカルフローアルゴリズムに基づいてリサンプリング戦略を設計します。4つのRGBTトラッキングベンチマークデータセットでの広範な実験により、この方法が状態に対して良好に機能することが示されています。 -最先端の追跡アルゴリズム。このようなモジュールは、低品質のモダリティが存在する場合でも、すべてのモダリティのターゲット表現を効果的に強化できます。 
[要約]低品質のモダリティの可能性は、既存のrgbt追跡アルゴリズムでは十分に調査されていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-14">
        <br><font color="black">2020-11-14</font>
      </time>
    </span>
</section>
<!-- paper0: Interpreting and Improving Adversarial Robustness of Deep Neural
  Networks with Neuron Sensitivity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_35.html">
      <font color="black">Interpreting and Improving Adversarial Robustness of Deep Neural
  Networks with Neuron Sensitivity</font>
    </a>
  </h2>
  <font color="black">この論文では、敏感なニューロンが敵対的な設定でのモデル予測に最も重要な貢献をするため、最初に敵対的なロバスト性とニューロンの感度の間の密接な関係を描きます。さまざまなデータセットでの広範な実験は、アルゴリズムが効果的に優れた結果を達成することを示しています。ディープニューラルネットワーク（DNN）は、知覚できない摂動を伴う入力がDNNを誤った結果に導くという敵対的な例に対して脆弱です。 
[要約]敵対的な例は、dnnsの弱点と死角への洞察を提供するためにも価値があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-16">
        <br><font color="black">2019-09-16</font>
      </time>
    </span>
</section>
<!-- paper0: End-to-End Video Instance Segmentation with Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_36.html">
      <font color="black">End-to-End Video Instance Segmentation with Transformers</font>
    </a>
  </h2>
  <font color="black">コアとなるのは、新しい効果的なインスタンスシーケンスマッチングおよびセグメンテーション戦略です。これは、インスタンス全体をシーケンスレベルで監視およびセグメント化します。ビデオインスタンスセグメンテーション（VIS）は、対象のオブジェクトインスタンスを同時に分類、セグメント化、および追跡する必要があるタスクです。ビデオでは..VisTRは、類似性学習の同じ観点でインスタンスのセグメンテーションとトラッキングをフレーム化するため、パイプライン全体が大幅に簡素化され、既存のアプローチとは大幅に異なります。 
[要約]最新の方法は通常、このタスクに取り組むための洗練されたパイプラインを開発します。vistrは、類似性の同じ観点でインスタンスタスクタスクタスクと追跡をフレーム化します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Latent Neural Differential Equations for Video Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_37.html">
      <font color="black">Latent Neural Differential Equations for Video Generation</font>
    </a>
  </h2>
  <font color="black">神経微分方程式の影響に対処するために、時間モデルの変更が生成されたビデオ品質にどのように影響するかを調査します。ビデオ生成の時間ダイナミクスをモデル化するために神経微分方程式の影響を研究することを提案します。神経微分方程式のパラダイムビデオ生成内の時間の最初の連続表現を含む多くの理論上の強みを提示します。 
[ABSTRACT]時間はいくつかの初期の研究で分析されましたが、文献は成長していません。時間は最近の研究のいくつかで見られました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-07">
        <br><font color="black">2020-11-07</font>
      </time>
    </span>
</section>
<!-- paper0: Just One Moment: Inconspicuous One Frame Attack on Deep Action
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_38.html">
      <font color="black">Just One Moment: Inconspicuous One Frame Attack on Deep Action
  Recognition</font>
    </a>
  </h2>
  <font color="black">さらに、普遍的な摂動を見つけるビデオにとらわれないアプローチを提示します。私たちの方法は、高いだまし率を示し、主観的なテストによって評価される人間の観察者にはほとんど知覚できない摂動を生成します。1フレーム攻撃の有効性を調査します。最先端のアクション認識モデルについて、モデル構造と摂動の知覚可能性の観点から脆弱性を徹底的に分析します。 
[概要]新しい1フレーム攻撃により、ビデオクリップの1フレームのみに目立たない摂動が追加されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: RfD-Net: Point Scene Understanding by Semantic Instance Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_39.html">
      <font color="black">RfD-Net: Point Scene Understanding by Semantic Instance Reconstruction</font>
    </a>
  </h2>
  <font color="black">この設計では、インスタンスの再構築をグローバルオブジェクトのローカリゼーションとローカル形状予測に分離します。これにより、スパース3D空間から2Dマニホールドサーフェスを学習する難しさが緩和されるだけでなく、各オブジェクト提案の点群が暗黙的な形状の詳細を伝達します。高解像度の表面を再構築するための関数学習..通常のグリッドでシーンを表現する代わりに、私たちの方法は点群データの希薄性を活用し、高いオブジェクト性で認識される形状の予測に焦点を当てています。 
[概要]パターンパターンの検出と再構築が効果を示します。形状予測ヘッドは、最新の3Dプロポーザルネットワークバックボーンを使用したオブジェクト検出の改善に一貫した効果を示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Distortion-aware Monocular Depth Estimation for Omnidirectional Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_40.html">
      <font color="black">Distortion-aware Monocular Depth Estimation for Omnidirectional Images</font>
    </a>
  </h2>
  <font color="black">360Dデータセットでの実験は、提案された方法が歪んだパノラマから意味的特徴を効果的に抽出し、歪によって引き起こされる監視バイアスを軽減できることを示しています。具体的には、変形可能な畳み込みを利用して、サンプリンググリッドをパノラマ上の歪んだオブジェクトの幾何学的変化に調整し、逆心射方位図法によって導入された水平歪みに対してサンプリングするためのストリッププーリングモジュール。次に、球から投影された領域の不均一な分布を処理する目的関数用のプラグアンドプレイ球形認識重み行列をさらに導入します。 
[概要]歪みを意識した単眼全方向（ダモ）高密度深度推定ネットワークが提案されました。このプロジェクトでは、変形可能な畳み込みを使用して、歪みのあるオブジェクトの幾何学的変化に合わせてサンプリング機能を調整します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-18">
        <br><font color="black">2020-10-18</font>
      </time>
    </span>
</section>
<!-- paper0: Inter-layer Transition in Neural Architecture Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_41.html">
      <font color="black">Inter-layer Transition in Neural Architecture Search</font>
    </a>
  </h2>
  <font color="black">外側のエッジのアーキテクチャの重みは個別に最適化されますが、内側のエッジのアーキテクチャの重みは、前のエッジのアーキテクチャの重みと学習可能な遷移行列に基づいて、注意深い確率遷移方式で順次導出されます。アーキテクチャの最適化を順次決定プロセスにキャストします。ここで、接続されたエッジのアーキテクチャの重み間の依存関係が明示的にモデル化されます。5つのベンチマークでの実験により、層間依存関係のモデル化の価値が確認され、提案された方法が最先端の方法よりも優れていることが示されます。 
[ABSTRACT] networkの新しいメソッドは、各エッジのアーキテクチャの重みをモデル化します。代わりに、関連する関連するソーシャルネットワークによって引き起こされるdagのエッジ間の依存関係を無視します。代わりに、前任者の重みと学習可能な遷移マトリックスに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Boosting Deep Open World Recognition by Clustering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_42.html">
      <font color="black">Boosting Deep Open World Recognition by Clustering</font>
    </a>
  </h2>
  <font color="black">開集合認識）、および（ii）知識を拡張して、時間の経過とともに新しいクラスを学習します（つまり、増分学習）。RGB-DオブジェクトおよびCore50データセットでの実験は、私たちのアプローチの有効性を示しています。 
[ABSTRACT]閉世界仮説を破り、ロボットにオープンワールドで行動する能力を装備する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br><font color="black">2020-04-20</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-MPI: Cross-scale Stereo for Image Super-Resolution using
  Multiplane Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_43.html">
      <font color="black">Cross-MPI: Cross-scale Stereo for Image Super-Resolution using
  Multiplane Images</font>
    </a>
  </h2>
  <font color="black">デジタル合成データと光学ズームクロススケールデータの両方での実験結果は、Cross-MPIフレームワークが既存のRefSR手法に対して優れたパフォーマンスを達成でき、大きなスケールの違いがあっても実際のマルチスケールカメラシステムに最適であることを示しています。 Cross-MPI、新しい平面認識アテンションベースのMPIメカニズム、マルチスケールガイド付きアップサンプリングモジュール、および超解像（SR）合成および融合モジュールで構成されるエンドツーエンドのRefSRネットワーク。この論文では、マルチプレーン画像（MPI）表現に触発された（実際のマルチスケールカメラシステムにおける）RefSR問題を解決するため。 
[概要]提案されたクロスmpiネットワークはクロス（mpi）であると提案されています。ネットワークはエンスイート画像のネットワークに基づいています。簡単に詳細化できるネットワークを作成するために使用することを目的としています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Localization Uncertainty Estimation for Anchor-Free Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_44.html">
      <font color="black">Localization Uncertainty Estimation for Anchor-Free Object Detection</font>
    </a>
  </h2>
  <font color="black">ディラックのデルタ分布がガウス分布として正確に表されていないため、つまり$ \ mu $と$ \ Sigma $の場合..外科用ロボットや自動運転車などの多くのセーフティクリティカルシステムは、センサーノイズのある不安定な環境にあるためデータが不完全な場合、オブジェクト検出器はローカリゼーション予測の信頼性を考慮することが望ましいです。アンカーベースのオブジェクト検出の以前の不確実性推定方法には3つの制限があります。 
[概要]アンカーベースのオブジェクト検出の以前の不確実性推定方法には3つの特徴があります。これらは、同様の特性を持つボックスオフセットの4つの方向に基づいています。これにより、不確実なポイントをキャプチャし、範囲内の定量値を提供できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-28">
        <br><font color="black">2020-06-28</font>
      </time>
    </span>
</section>
<!-- paper0: CoSE: Compositional Stroke Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_45.html">
      <font color="black">CoSE: Compositional Stroke Embeddings</font>
    </a>
  </h2>
  <font color="black">コードとモデルをhttps://eth-ait.github.io/coseで公開しています。提案されたアプローチが個々のストロークの外観と、より大きな構造の構成をモデル化できることを定性的および定量的に示しています。ダイアグラムの描画..アプローチの中核には、可変長のストロークを固定寸法の潜在空間に投影する新しい自動エンコーダーがあります。 
[概要]モデルは、図面の簡単な例に基づいています。これらのモデルは、図などの複雑な構造に構成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br><font color="black">2020-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: Adaptive Compact Attention For Few-shot Video-to-video Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_46.html">
      <font color="black">Adaptive Compact Attention For Few-shot Video-to-video Translation</font>
    </a>
  </h2>
  <font color="black">信頼性をさらに向上させるために、推論フェーズでは、入力ラベルに従ってリソースの豊富な参照を自動的に選択するDelaunay Triangulationアルゴリズムに基づく新しい方法も提案します。したがって、コンテキストを効率的に抽出するための新しい適応型コンパクトアテンションメカニズムを導入します。エンコードされたビュー依存およびモーション依存の情報がリアルなビデオの合成に大きく役立つ可能性がある複数の参照画像から共同で機能を提供します。私たちのコアアイデアは、すべての参照画像からコンパクトな基底セットを高レベルの表現として抽出することです。 
[概要]私たちの主なアイデアは、すべての参照画像からコンパクトな基底関数系を高レベルの表現として抽出することです。実験結果は、フォトリアリスティックで時間的に一貫性のあるビデオを作成するための私たちの方法の優れたパフォーマンスを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: CanonPose: Self-Supervised Monocular 3D Human Pose Estimation in the
  Wild -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_47.html">
      <font color="black">CanonPose: Self-Supervised Monocular 3D Human Pose Estimation in the
  Wild</font>
    </a>
  </h2>
  <font color="black">それでも、静的カメラセットアップの場合、複数のビューで一定の相対カメラ回転をフレームワークに含めるオプションの拡張機能を提示します。ほとんどの既存の方法とは対照的に、キャリブレーションされたカメラを必要としないため、移動するカメラから学習できます。 ..成功の鍵は、ビュー全体の情報とトレーニングサンプルを組み合わせた新しい偏りのない再構築目標です。 
[概要]提案されたアプローチは、2つのベンチマークデータセットと、野生のスキップスデータセットに基づいています。2つの異なるタイプの視覚機器に適用されます。ただし、この概念では、トレーニングを単純に拡張する必要はありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Deformed Implicit Field: Modeling 3D Shapes with Learned Dense
  Correspondence -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_48.html">
      <font color="black">Deformed Implicit Field: Modeling 3D Shapes with Learned Dense
  Correspondence</font>
    </a>
  </h2>
  <font color="black">また、テクスチャ転送や形状編集など、以前の方法では達成できなかった説得力のある結果を達成するいくつかのアプリケーションを示します。学習したDIF-Netは、形状構造の不一致を反映した信頼性の高い対応の不確かさの測定も提供できます。変形フィールドを使用して簡単に確立できます。 
[ABSTRACT]対応やパーツラベルを使用せずに、カテゴリに属する3Dオブジェクトの形状潜在空間とこれらのフィールドを学習できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-27">
        <br><font color="black">2020-11-27</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Adaptation for Robust Workload Level Alignment Between Sessions
  and Subjects using fNIRS -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_49.html">
      <font color="black">Domain Adaptation for Robust Workload Level Alignment Between Sessions
  and Subjects using fNIRS</font>
    </a>
  </h2>
  <font color="black">結論：ドメイン適応は、fNIRSデータを使用することにより、メンタルワークロードのセッションごとおよびサブジェクトごとのアラインメントの可能性があります。GWとFG-Wの両方からのアラインメント精度の結果は、SVM、CNN、およびRNNからの結果よりも大幅に高くなります。 。これらの各ケースで、25％の精度はチャンスを表しています。 
[ABSTRACT] fnirsデータのドメインシフトは、さまざまな実験セッションや被験者間でのワークロードレベルの調整における課題です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-02">
        <br><font color="black">2020-07-02</font>
      </time>
    </span>
</section>
<!-- paper0: General Data Analytics with Applications to Visual Information Analysis:
  A Provable Backward-Compatible Semisimple Paradigm over T-Algebra -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_50.html">
      <font color="black">General Data Analytics with Applications to Visual Information Analysis:
  A Provable Backward-Compatible Semisimple Paradigm over T-Algebra</font>
    </a>
  </h2>
  <font color="black">公開データセットでの実験は、一般化されたアルゴリズムがそれらの標準的な対応物と比べて遜色がないことを示しています。複雑な数の固定サイズの多方向配列と代数によってt代数の要素を表すことにより、t代数上の抽象代数フレームワークを研究します。直接積の構成要素のコレクションによるt代数上の構造..t代数では、すべてではないにしても、多くのアルゴリズムがこの新しい半単純なパラダイムを使用して簡単な方法で一般化されます。 
[概要]たとえば、視覚的なパターン分析のための一連の新しいアルゴリズムを一般化します。新しいツールのパフォーマンスとその下位互換性を示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-31">
        <br><font color="black">2020-10-31</font>
      </time>
    </span>
</section>
<!-- paper0: A Comprehensive Review on Recent Methods and Challenges of Video
  Description -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_51.html">
      <font color="black">A Comprehensive Review on Recent Methods and Challenges of Video
  Description</font>
    </a>
  </h2>
  <font color="black">この作業では、ビデオ記述アプローチのフェーズ、ビデオ記述のデータセット、評価指標、ビデオ記述に関する研究を動機付けるための公開コンテスト、この分野での未解決の課題、および将来の研究の方向性に関する包括的な調査を報告します。ビデオ記述タスクの進捗状況を分析するには、最近の深層学習アプローチに特に焦点を当てて、ビデオ記述アプローチのすべてのフェーズをカバーする包括的な調査が必要です。さらに、すべてのデータセットをオープンドメインデータセットとドメインの2つのクラスに分類します。 -特定のデータセット。 
[要約]過去10年間で、ビデオの説明、評価指標、およびデータセットのアプローチに関して、この分野でいくつかの作業が行われてきました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Learnable Motion Coherence for Correspondence Pruning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_52.html">
      <font color="black">Learnable Motion Coherence for Correspondence Pruning</font>
    </a>
  </h2>
  <font color="black">モーションコヒーレンスに関する既存の研究は、パラメータ設定に敏感であり、複雑なモーションパターンを処理するのが困難です。実験は、LMCNetが、相対的なカメラポーズ推定および動的シーンの対応プルーニングにおいて最先端のパフォーマンスよりも優れていることを示しています。コヒーレンスは、別のローカルレイヤーによって抽出されたローカルコヒーレンスとさらに組み合わされて、インライア対応を確実に検出します。 
[ABSTRACT]ラプラシアンモーションコヒーレンスネットワーク（lmcnet）は、対応剪定のためのモーションコヒーレンスプロパティを学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Adversarial Networks for Image and Video Synthesis:
  Algorithms and Applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_53.html">
      <font color="black">Generative Adversarial Networks for Image and Video Synthesis:
  Algorithms and Applications</font>
    </a>
  </h2>
  <font color="black">また、コンテンツ作成において多くの新しいアプリケーションの作成につながりました。難しいことで有名なGANトレーニングを安定させるためのいくつかの重要なテクニックについて説明します。また、画像翻訳、画像処理、ビデオ合成へのアプリケーションについても説明します。 、およびニューラルレンダリング。 
[概要]これにより、高解像度のフォトリアリスティックな画像やビデオの生成が可能になりました。これは、以前の方法では困難または不可能だった作業です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-06">
        <br><font color="black">2020-08-06</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to dance: A graph convolutional adversarial network to generate
  realistic dance motions from audio -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_54.html">
      <font color="black">Learning to dance: A graph convolutional adversarial network to generate
  realistic dance motions from audio</font>
    </a>
  </h2>
  <font color="black">それぞれのダンスの動きは独特ですが、そのような動きはダンススタイルのコア特性を維持しています。結果は、提案されたGCNモデルが、さまざまな実験で音楽を条件とする最先端のダンス生成方法よりも優れていることを示唆しています。生成方法の3つの定量的メトリックとユーザー調査を使用した方法。 
[ABSTRACT]音楽から自然に動くこと、つまりダンスを学ぶことは、人間が楽に行うことが多いより複雑な動きの1つです。この方法は、音声情報からの自動ダンス生成の問題に取り組むように設計されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Annotation-Efficient Untrimmed Video Action Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_55.html">
      <font color="black">Annotation-Efficient Untrimmed Video Action Recognition</font>
    </a>
  </h2>
  <font color="black">コードはオンラインでリリースされます。この問題の課題は、（1）トリミングされていないビデオからの行動認識、（2）弱い監視、（3）トレーニングサンプルが少ない新しいクラスの3つから生じます。ただし、既存のものはほとんどありません。作品は両方の側面を同時に処理できます。 
[ABSTRACT]いくつかのような作品-ショット学習またはトリミングされていないビデオ認識は、いずれかの側面を処理するために提案されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Deep learning approach to left ventricular non-compaction measurement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_56.html">
      <font color="black">Deep learning approach to left ventricular non-compaction measurement</font>
    </a>
  </h2>
  <font color="black">推論結果は、深層学習ベースのアプローチがLVNCの診断と測定で優れた結果を達成できることを確認しています。4つのCNNは、肥大型心筋症と診断された患者の集団の左心室の圧縮された小柱領域を自動的にセグメント化するようにトレーニングされています。 2つの最高のCNN（U-NetとEfficient U-Net B1）は、CPUでは0.2秒未満、GPUでは0.01秒未満で画像セグメンテーションを実行します。 
[概要] 4つのcnnは、左心室の圧縮された小柱領域を自動的にセグメント化するようにトレーニングされています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Adaptive noise imitation for image denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_57.html">
      <font color="black">Adaptive noise imitation for image denoising</font>
    </a>
  </h2>
  <font color="black">実験によると、ADANIによって生成されたノイズの多いデータは、実際のデータと視覚的および統計的に類似しているため、この方法のノイズ除去CNNは、外部のペアデータでトレーニングされた他のネットワークと競合します。ノイズのタイプ、レベル、勾配に明示的な制約を課すことにより、 、ADANIの出力ノイズは、画像の元のクリーンな背景を維持しながら、ガイドノイズと同様になります。ADANIから出力されたノイズの多いデータを対応するグラウンドトゥルースと結合すると、ノイズ除去CNNが完全に監視された状態でトレーニングされます。マナー。 
[概要]この作業では、ノイズ統計とペアデータが利用できない、より一般的なケースでのノイズ除去に焦点を当てます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Dual Geometric Graph Network (DG2N) -- Zero-Shot Refinement for Dense
  Shape Correspondence -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_58.html">
      <font color="black">Dual Geometric Graph Network (DG2N) -- Zero-Shot Refinement for Dense
  Shape Correspondence</font>
    </a>
  </h2>
  <font color="black">テンプレートアラインメントと機能マップでDNNモデルを使用することで飛躍的な進歩が見られましたが、これらの方法は、非等尺性変形が存在するクラス間アラインメントでは失敗します。メッシュの迅速で安定したソリューションでのストレッチ可能なドメインアラインメントに関する最先端の結果を報告します。ここでは、このタスクを再考し、双対グラフ構造で展開の概念を使用することを提案します。1つはフォワードマップ用、もう1つはバックワードマップ用で、特徴は一致する確率をターゲットからソースにプルバックします。 
[概要]二重に見える構造は、コンピュータビジョンタスクの最も難しい例の1つです。対応をモデル化するために必要な未知数が多数あります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Training and Inference for Integer-Based Semantic Segmentation Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_59.html">
      <font color="black">Training and Inference for Integer-Based Semantic Segmentation Network</font>
    </a>
  </h2>
  <font color="black">セマンティックセグメンテーションネットワークは、従来のディープ畳み込みニューラルネットワーク（DCNN）とは多くの点で異なり、このトピックは既存の作業では十分に検討されていません。セグメンテーションネットワークを高速化する既存のスキームは、ネットワーク構造を変更し、顕著な精度の低下を伴います。この論文では、パラメータと操作が初めて8ビットの整数ベースの値に制約されるセグメンテーションネットワークのトレーニングと推論のための新しい量子化フレームワークを提案します。 
[概要]提案されたシステムは、データ検索の記念日を減らすために使用できますが、データ負荷の量を減らすためのツールとして使用できます。また、元のネットワーク構造の現在の記念日を減らすこともできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Deformable DETR: Deformable Transformers for End-to-End Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_60.html">
      <font color="black">Deformable DETR: Deformable Transformers for End-to-End Object Detection</font>
    </a>
  </h2>
  <font color="black">これらの問題を軽減するために、Deformable DETRを提案しました。そのアテンションモジュールは、参照の周りの主要なサンプリングポイントの小さなセットにのみ対応します。DeformableDETRは、トレーニングエポックが10分の1で、DETR（特に小さなオブジェクト）よりも優れたパフォーマンスを実現できます。 DETRは最近、優れたパフォーマンスを示しながら、オブジェクト検出で多くの手作業で設計されたコンポーネントの必要性を排除するために提案されました。 
[ABSTRACT]変形可能なdetrは、モジュールよりも優れたパフォーマンスを実現できます。mitのソフトウェアエンジニアcocoによって開発されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Monocular 3D Object Detection with Sequential Feature Association and
  Depth Hint Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_61.html">
      <font color="black">Monocular 3D Object Detection with Sequential Feature Association and
  Depth Hint Augmentation</font>
    </a>
  </h2>
  <font color="black">このような設計は、2D推定と3D推定の間の幾何学的一貫性に寄与することも観察されます。順次特徴の関連付けの目的は、より簡単な推定のガイダンスの下で、より難しい推定の精度を向上させることです。この作業のもう1つの貢献は、深さのヒントの増強。 
[ABSTRACT] fadnetは、自動運転をターゲットアプリケーションとする単眼3Dオブジェクト検出のタスクに対処するために提示されます。この目的のために、畳み込みゲート付き回帰ユニットがネットワークに組み込まれ、さまざまなグループの畳み込み特徴全体で時系列の特徴の関連付けが可能になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Driver Anomaly Detection: A Dataset and Contrastive Learning Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_62.html">
      <font color="black">Driver Anomaly Detection: A Dataset and Contrastive Learning Approach</font>
    </a>
  </h2>
  <font color="black">このタスクでは、新しいビデオベースのベンチマークであるDriver Anomaly Detection（DAD）データセットを紹介します。このデータセットには、通常の運転ビデオとトレーニングセット内の一連の異常アクションが含まれています。この方法は、テストセットで0.9673AUCに達します。異常検出タスクに対する対照的な学習アプローチの有効性を示しています。DADデータセットのテストセットには、通常の運転から除外する必要のある、目に見えない異常なアクションがあります。 
[概要]お父さんのデータセットのテストセットには、通常の運転からまだ選別する必要がある目に見えない異常なアクションがあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-30">
        <br><font color="black">2020-09-30</font>
      </time>
    </span>
</section>
<!-- paper0: Revisiting Unsupervised Meta-Learning: Amplifying or Compensating for
  the Characteristics of Few-Shot Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_63.html">
      <font color="black">Revisiting Unsupervised Meta-Learning: Amplifying or Compensating for
  the Characteristics of Few-Shot Tasks</font>
    </a>
  </h2>
  <font color="black">まず、混合埋め込みを組み込んで、数ショットのタスクの難易度を高めます。変更されたベースラインに基づいて、UMLモデルをトレーニングするときに、タスクの特性をさらに増幅または補正します。メタ学習は、少数のタスクに対する実用的なアプローチになります。限られた注釈付きデータで視覚認識システムが構築されるショット画像分類。 
[ABSTRACT]埋め込みの誘導バイアスは、十分なラベルの付いた例が設定された基本クラスから学習されます。次に、新しいクラスを使用した少数のショットタスクに一般化します。少数のショットの学習ベンチマークでの実験は、アプローチが以前のumlメソッドよりも4〜10優れていることを証明します。 ％パフォーマンスギャップ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Revisiting Batch Normalization for Training Low-latency Deep Spiking
  Neural Networks from Scratch -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_64.html">
      <font color="black">Revisiting Batch Normalization for Training Low-latency Deep Spiking
  Neural Networks from Scratch</font>
    </a>
  </h2>
  <font color="black">CIFAR-10、CIFAR-100、Tiny-ImageNet、およびイベント駆動型DVS-CIFAR10データセットで実験を行います。以前の作業とは異なり、提案されたBNTTは、時間軸に沿ってBNTTレイヤーのパラメーターを分離し、の時間ダイナミクスをキャプチャします。スパイク..これまでのほとんどの以前のSNN作業は、一時的なSNNのトレーニングには効果がないと見なしてバッチ正規化を無視していました。 
[概要]高精度と低遅延のsnnを最初からトレーニングすると、スパイキングニューロンの微分不可能な性質に悩まされます。アドレスアドレスにアドレス指定します。bnttは、一時的なsnnのトレーニングには効果がないと見なします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: ScaleNAS: One-Shot Learning of Scale-Aware Representations for Visual
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_65.html">
      <font color="black">ScaleNAS: One-Shot Learning of Scale-Aware Representations for Visual
  Recognition</font>
    </a>
  </h2>
  <font color="black">ScaleNASは、任意の数のブロックとクロススケール機能の融合を可能にする柔軟な検索スペースを採用しています。ScaleNASは、マルチスケール機能集約を検索することにより、一度に複数のタスクを解決します。特に、ScaleNet-P4はCOCOテストで71.6％のAPを達成します。 -dev、新しい最先端の結果を達成します。 
[ABSTRACT] scalenasは、スケールを意識した表現を探索するためのワンショット学習方法です。任意の数のブロックを許可する柔軟な検索スペースを使用します。さらに再トレーニングすることなく、scalenetをさまざまな視覚認識タスクに直接展開して優れたパフォーマンスを実現できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: EqCo: Equivalent Rules for Self-supervised Contrastive Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_66.html">
      <font color="black">EqCo: Equivalent Rules for Self-supervised Contrastive Learning</font>
    </a>
  </h2>
  <font color="black">EqCoは、さまざまな負のサンプルサイズ間のパフォーマンスのギャップを埋めるため、使用できる負のペアはごくわずかです（たとえば、これは、現在の慣行で広く使用されている大規模なバッチトレーニングまたはメモリバンクメカニズムとはかなり対照的です。クエリ）ImageNetのような大規模なビジョンデータセットに対して、精度の低下をほとんど伴わずに、自己監視型の対照トレーニングを実行します。 
[概要]対比損失のマージン項は、負のペアの数に応じて適応的にスケーリングする必要があります。ブリッジブリッジブリッジは、安定した相互情報量の限界と勾配を維持できます。この方法は、infomaxの原則に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: BOTD: Bold Outline Text Detector -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_67.html">
      <font color="black">BOTD: Bold Outline Text Detector</font>
    </a>
  </h2>
  <font color="black">これは、後処理プロセスがほとんどない新しい1段階の検出フレームワークです。最近、任意の形状のテキスト検出がますます検索の注目を集めています。具体的には、BOTDは最初に各テキストインスタンスのセンターマスク（CM）を生成します。粘着テキストを簡単に区別できます。 
[ABSTRACT] botdのf-メジャーは80.1％、ctw1500、52 fpsです。これは、任意の後処理プロセスがほとんどない、新しい1段階の検出フレームワークです。検出速度が遅く、後処理が複雑で、テキストの貼り付けがあります問題はまだ実際のアプリケーションの制限です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Scale-covariant and scale-invariant Gaussian derivative networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_68.html">
      <font color="black">Scale-covariant and scale-invariant Gaussian derivative networks</font>
    </a>
  </h2>
  <font color="black">結果として得られるアプローチにより、スケールの一般化が可能になり、トレーニングデータに存在しないスケールでパターンを分類するための優れたパフォーマンスが可能になることが実証されています。MNISTLargeScaleデータセットでこのようなネットワークのパフォーマンスを調査します。このデータセットには、元のMNISTからの再スケーリングされた画像が含まれています。トレーニングデータに関しては4、テストデータに関しては16倍以上です。さらに、複数のスケールチャネルで最大プーリングを実行することにより、結果として得られる画像分類のネットワークアーキテクチャもスケール不変になります。 
[概要]ネットワークは確かにスケール共変になります。学習したパラメータを複数のスケールチャネル間で共有することにより、結果のネットワークは共変になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Quantifying Sources of Uncertainty in Deep Learning-Based Image
  Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_69.html">
      <font color="black">Quantifying Sources of Uncertainty in Deep Learning-Based Image
  Reconstruction</font>
    </a>
  </h2>
  <font color="black">推定された不確実性は、制限された測定モデルと、制限された角度ジオメトリによる情報の欠落によって引き起こされる再構成の変動をキャプチャします。角度データ..この作業では、学習した反復画像再構成における気管およびエピステミックの不確実性を同時に定量化するためのスケーラブルで効率的なフレームワークを提案します。 
[概要]反復画像再構成の学習における偶然性および認識論的不確実性を定量化するためのスケーラブルで効率的なフレームワークを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-17">
        <br><font color="black">2020-11-17</font>
      </time>
    </span>
</section>
<!-- paper0: TransMIA: Membership Inference Attacks Using Transfer Shadow Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_70.html">
      <font color="black">TransMIA: Membership Inference Attacks Using Transfer Shadow Training</font>
    </a>
  </h2>
  <font color="black">2つの実際のデータセットを使用して攻撃を評価し、転送シャドウトレーニング手法を使用しない最先端の攻撃よりも優れていることを示します。次に、信頼値の分布に基づいて、これら4つのアプローチのパフォーマンスを調べます。 、および攻撃に対する可能な対策について説明します。このペーパーでは、TransMIA（Transfer Learning-based Membership Inference Attacks）を提案します。これは、攻撃者がのパラメータにアクセスできるときに、転送学習を使用してソースモデルに対してメンバーシップ推論攻撃を実行します。転送されたモデル。 
[概要]転移学習が機械学習モデルに対するプライバシー攻撃を強化できることが調査で指摘されたのはこれが初めてです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: SMPR: Single-Stage Multi-Person Pose Regression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_71.html">
      <font color="black">SMPR: Single-Stage Multi-Person Pose Regression</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、既存の単一段階の方法を上回るだけでなく、COCOtest-devポーズベンチマークで70.2APと77.5AP75を使用して、最新のボトムアップ方法と競合することを示します。これは、密な予測とすべての場所からインスタンス対応のキーポイントを予測します。ネットワークは、推定されたポーズのスコアも学習します。 
[概要] 2段階の方法では、追加の人物検出器の冗長性が失われるか、すべてのインスタンスを予測した後にヒューリスティックにキーポイントをグループ化します-無料のキーポイント。smprと呼ばれるこの作業は、新しい例の例-単一段階の複数人のポーズ予測に従います。ポーズスコアリング戦略は、非最大抑制中に優れたポーズを優先することにより、ポーズ推定パフォーマンスをさらに向上させます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-28">
        <br><font color="black">2020-06-28</font>
      </time>
    </span>
</section>
<!-- paper0: CommonGen: A Constrained Text Generation Challenge for Generative
  Commonsense Reasoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_72.html">
      <font color="black">CommonGen: A Constrained Text Generation Challenge for Generative
  Commonsense Reasoning</font>
    </a>
  </h2>
  <font color="black">実験によると、最先端のテキスト生成モデル（T5など）と人間のパフォーマンスの間には大きなギャップがあります。ただし、現実的にもっともらしい文章を作成するための常識を備えたマシンの構築は、依然として困難です。一連の共通概念を考えると、 （例：{犬、フリスビー、キャッチ、スロー}）;タスクは、これらの概念を使用して日常のシナリオを説明する一貫した文を生成することです（たとえば、「男性がフリスビーを投げ、犬がそれを捕まえる」）。 
[概要]私たちのデータセットは、35kのユニークなコンセプトを超える79kの常識的な説明で構成されています-セット</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-09">
        <br><font color="black">2019-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Why Convolutional Networks Learn Oriented Bandpass Filters: Theory and
  Empirical Support -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_73.html">
      <font color="black">Why Convolutional Networks Learn Oriented Bandpass Filters: Theory and
  Empirical Support</font>
    </a>
  </h2>
  <font color="black">これらの固有関数はグローバルに定義されています。ただし、畳み込みアーキテクチャはローカルで動作します。畳み込みアーキテクチャを画像理解タスクに適用すると、指向性バンドパスフィルタが学習されることが繰り返し観察されています。局所性を強制するために、ウィンドウ関数を固有関数に適用できます。これにより、指向性バンドパスフィルタが畳み込みアーキテクチャで学習する自然演算子。 
[ABSTRACT]畳み込みネットワークは、すべての畳み込み層でこのようなフィルターを学習します。これは、これらのフィルターがトレーニング中に露光された画像の構造を反映していることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Incremental Learning via Rate Reduction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_74.html">
      <font color="black">Incremental Learning via Rate Reduction</font>
    </a>
  </h2>
  <font color="black">最後に、私たちの実験は、提案された学習アルゴリズムが分類パフォーマンスの低下を大幅に減らし、MNISTおよびCIFAR-10の最先端の方法を大幅に上回り、十分な場合でも増分学習のための「ホワイトボックス」アルゴリズムの使用を正当化することを示しています複雑な画像データ..壊滅的な忘却の問題を克服するために、レート削減の原理から派生した代替の「ホワイトボックス」アーキテクチャを利用することを提案します。このアーキテクチャでは、ネットワークの各層が逆伝播せずに明示的に計算されます。深層学習手法では、深層学習モデルが「ブラックボックス」として最適化されるため、モデルパラメータを適切に調整して、以前に表示されたデータに関する知識を保持することが困難になります。 
[概要]深層学習モデルは「ブラックボックス」として最適化されているため、モデルモデルモデルを適切に調整することが困難です。新しいネットワークは、過去および新規のすべてのクラスとの共同トレーニングをエミュレートします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Invisible Perturbations: Physical Adversarial Examples Exploiting the
  Rolling Shutter Effect -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_75.html">
      <font color="black">Invisible Perturbations: Physical Adversarial Examples Exploiting the
  Rolling Shutter Effect</font>
    </a>
  </h2>
  <font color="black">攻撃者が、シーンを敵対的に照らし、最先端のImageNetディープラーニングモデルでターゲットを絞った誤分類を引き起こす変調光信号を作成する方法を示します。人間の目には、オブジェクトは照らされているように見えますが、カメラはMLモデルに攻撃者が望む分類を出力させるストライプのある画像を作成します。犠牲オブジェクトを目に見えるアーティファクトで変更するのではなく、オブジェクトを照らす光を変更します。 
[ABSTRACT] van jones：放射分析ローリングシャッター効果を利用します。彼はそれが画像に現れるパターンの兆候だと言います</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-26">
        <br><font color="black">2020-11-26</font>
      </time>
    </span>
</section>
<!-- paper0: SFTrack++: A Fast Learnable Spectral Segmentation Approach for
  Space-Time Consistent Tracking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_76.html">
      <font color="black">SFTrack++: A Fast Learnable Spectral Segmentation Approach for
  Space-Time Consistent Tracking</font>
    </a>
  </h2>
  <font color="black">これにより、学習プロセスでノイズやディストラクタを導入するラフコモンバウンディングボックスアプローチが防止されます。これらの特徴マップを抽出して組み合わせた後、適切なトラッキングバウンディングボックスを予測するために非表示レイヤー表現のみに依存するのではなく、中間の詳細を明示的に学習します。洗練されたもの、つまり追跡対象のセグメンテーションマップ。VOT2018、LaSOT、TrackingNet、GOT10k、NFS、OTB-100、UAV123の7つの追跡ベンチマークでメソッドSFTrack ++をテストします。 
[概要]追跡対象の複雑な側面をキャプチャするメソッドをテストします。非表示のレイヤー表現に依存する代わりに、中間のより洗練された表現を明示的に学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-27">
        <br><font color="black">2020-11-27</font>
      </time>
    </span>
</section>
<!-- paper0: REaL: Real-time Face Detection and Recognition Using Euclidean Space and
  Likelihood Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_77.html">
      <font color="black">REaL: Real-time Face Detection and Recognition Using Euclidean Space and
  Likelihood Estimation</font>
    </a>
  </h2>
  <font color="black">キャプチャされた画像は、不要なノイズを除去するために自動的にトリミングされます。システムは、計算から人間以外のオブジェクトを除去することにも成功しています。顔を正確に検出して認識することは、常に課題でした。 
[概要]実際の実験はライブ画像で実行され、認識率は有望です。システムはローカルデータベースを使用してキャプチャされた画像を保存し、ニューラルネットワークに頻繁にフィードします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Zero-Shot Calibration of Fisheye Cameras -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_78.html">
      <font color="black">Zero-Shot Calibration of Fisheye Cameras</font>
    </a>
  </h2>
  <font color="black">実験結果は、ゼロショット法のキャリブレーション精度が従来のフルキャリブレーション結果に匹敵することを示しています。さらに、この方法で推定されたカメラパラメータを使用して、既存のキャリブレーション方法を適切に初期化し、収束させることもできます。より安定し、局所的な最小値を回避します。提案された方法のキャリブレーション精度は、8つの異なる市販のカメラで定性的および定量的に評価され、従来のキャリブレーション方法と比較されます。 
[概要]提案された方法は、画像の歪みが大きい広角カメラまたは魚眼カメラに特に役立ちます。この方法は、実際のキャリブレーションの実用的な代替手段として、およびキャリブレーションの精度がそれほど重要ではないほとんどのフィールドアプリケーションで使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: What Can Style Transfer and Paintings Do For Model Robustness? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_79.html">
      <font color="black">What Can Style Transfer and Paintings Do For Model Robustness?</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、様式化がモデルの堅牢性をどのように改善するかについての洞察を提供し、アーティストが作成した絵画がモデルの堅牢性の貴重なデータソースになり得るという証拠を提供します。次に、知覚データ拡張の形式として絵画から学ぶことでモデルの堅牢性を改善できることを示します..ただし、定型化された写真は、アーティストが作成した絵画とはまったく同じではありません。 
[概要]データの拡張により、モデルは、垂直方向の反転に対する不変性や色の小さな変化など、必要な不変性を学習するようになります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Video Self-Stitching Graph Network for Temporal Action Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_80.html">
      <font color="black">Video Self-Stitching Graph Network for Temporal Action Localization</font>
    </a>
  </h2>
  <font color="black">VSSでは、短期間のビデオに焦点を合わせ、時間次元に沿って拡大して、より大きなスケールを取得します。セルフステッチのアプローチにより、元のクリップとその拡大された対応物を1つの入力シーケンスで利用できます。両方のスケールの補完的なプロパティを利用します。VSGNには、ビデオセルフステッチ（VSS）とクロススケールグラフピラミッドネットワーク（xGPN）の2つの主要コンポーネントがあります。 
[要約]ビデオ自己-短いアクションは、現在のすべての方法で最低のパフォーマンスを示します。データでは、短いアクションには最低レベルとクロススケールグラフピラミッドネットワーク（xgpn）が含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Implicit Templates for 3D Shape Representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_81.html">
      <font color="black">Deep Implicit Templates for 3D Shape Representation</font>
    </a>
  </h2>
  <font color="black">この目的のために、条件付き空間変換を複数のアフィン変換に分解し、一般化機能を保証する空間ワーピングLSTMを提案します。私たちの重要なアイデアは、DIFをテンプレート暗黙関数の条件付き変形として定式化することです。形状のコレクションに共通の暗黙のテンプレートを学習するだけでなく、監視なしですべての形状にわたって同時に密な対応を確立します。 
[ABSTRACT] difsはポリゴンメッシュベースのテンプレートに基づいていますが、difで表される形状間で密な対応やその他の意味関係を推論することは依然として課題です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Learning-based lossless compression of 3D point cloud geometry -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CV/paper_82.html">
      <font color="black">Learning-based lossless compression of 3D point cloud geometry</font>
    </a>
  </h2>
  <font color="black">一方、ボクセル領域では、畳み込みを自然に表現でき、幾何学的情報（平面、表面など）を表現できます。私たちのコンテキストモデルは、これらのプロパティの恩恵を受け、VoxelDNNと呼ばれるマスクされたフィルターを備えた深い畳み込みニューラルネットワークを使用してボクセルの確率分布を学習します。一方で、オクツリー表現はポイントクラウドのスパース性を排除できます。 
[概要]当社のエンコーダーはハイブリッドモードで動作し、オクツリーとボクセルベースのプログラミングを混合します。この方法は、最先端のmpegg-pcc標準よりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Dynamic Curriculum Learning for Low-Resource Neural Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CL/paper_0.html">
      <font color="black">Dynamic Curriculum Learning for Low-Resource Neural Machine Translation</font>
    </a>
  </h2>
  <font color="black">この場合、データの使用方法がより重要であるように見えます。前の作業とは異なり、並べ替えに静的スコアリング関数を使用しません。実験結果は、DCLが3つの低リソース機械翻訳ベンチマークでいくつかの強力なベースラインを上回っていることを示しています。 WMT &#39;16En-Deのさまざまなサイズのデータ。 
[ABSTRACT] dclは、3つの低リソース機械翻訳ベンチマークとwmt &#39;16 en-deのさまざまなサイズのデータで、いくつかの強力なベースラインを上回っています。これにより、現在のモデルが学習するのに十分な能力を備えている簡単なサンプルを強調表示することで、トレーニングが容易になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Feature Adaptation of Pre-Trained Language Models across Languages and
  Domains with Robust Self-Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CL/paper_1.html">
      <font color="black">Feature Adaptation of Pre-Trained Language Models across Languages and
  Domains with Robust Self-Training</font>
    </a>
  </h2>
  <font color="black">自己トレーニングのロバスト性を向上させるために、この論文では、PrLMから識別機能を学習するためのクラス認識機能自己蒸留（CFd）を紹介します。この場合、PrLM機能は機能適応モジュールとその機能に自己蒸留されます。クラスはより緊密にクラスター化されます。セルフトレーニングは、トレーニングのターゲットドメインデータの疑似ラベルを予測するUDAに広く使用されています。このホワイトペーパーでは、監視されていないドメイン適応（UDA）について説明します。 
[概要] prlmsの機能を新しいドメインに適応させる方法を開発します。ラベル付きでトレーニングされたモデルをラベルなしのターゲットドメインに適応させます。ただし、予測される疑似ラベルには必然的にノイズが含まれ、トレーニングに悪影響を及ぼします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-24">
        <br><font color="black">2020-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: Forecasting financial markets with semantic network analysis in the
  COVID-19 crisis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CL/paper_2.html">
      <font color="black">Forecasting financial markets with semantic network analysis in the
  COVID-19 crisis</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、株式市場データを予測するために新しいテキストデータインデックスを使用します。証拠は、インデックスが金融時系列のさまざまなフェーズを適切にキャプチャしていることを示しています。さらに、結果は、リターンとボラティリティの両方の債券市場データの予測可能性の強力な証拠を示しています。短期および長期の満期、および株式市場の変動性。 
[概要]このインデックスは、テキストに表示されるキーワードの重要性を評価するために多数のニュースに適用されます。これをイタリアの報道機関に適用し、最近のサンプル期間におけるイタリアの株式および債券市場のリターンとボラティリティを予測するためのインデックスを作成します。 covid-19危機を含む</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-09">
        <br><font color="black">2020-09-09</font>
      </time>
    </span>
</section>
<!-- paper0: Catch the "Tails" of BERT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CL/paper_3.html">
      <font color="black">Catch the "Tails" of BERT</font>
    </a>
  </h2>
  <font color="black">これらの「テール」がどこから来ているかを分析するための新しいニューロンレベルの方法を紹介します。RoBERTaの場合、$ 588 ^ {th} $要素が常に最大で、$ 77 ^ {th} $要素が最小です。 BERTとRoBERTaのコンテキスト化された単語ベクトルのほとんどすべてが共通のパターンを持っていることがわかります。 
[ABSTRACT]研究者は、「テール」が位置情報と密接に関連していることを発見しました。また、これらの「5,570億ドル（th）$要素」が常に最小であることも発見しました。調査結果は、文脈化された単語センターの内部動作への洞察を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Modelling Verbal Morphology in Nen -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CL/paper_4.html">
      <font color="black">Modelling Verbal Morphology in Nen</font>
    </a>
  </h2>
  <font color="black">また、シンクレティズムのケーススタディを通じて、トレーニングデータから推測できるパターンのタイプを示します。ネンの形態は、分散指数を利用します。これは、フォームを意味にマッピングするための重要な手段です。これらのエラーのタイプを調査して分類します。システムが生成します。 
[概要]大きな組み合わせスペースと低いリソース設定の複合効果により、nlpツールの必要性が高まる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Gunrock 2.0: A User Adaptive Social Conversational System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CL/paper_5.html">
      <font color="black">Gunrock 2.0: A User Adaptive Social Conversational System</font>
    </a>
  </h2>
  <font color="black">Gunrock 2.0は、固有表現抽出、リンク、ダイアログ動作予測など、さまざまな神経自然言語理解モジュールを組み合わせて、ユーザーの理解を向上させます。Gunrock2.0は、5月29日から6月4日までの最新ビルドで平均3.73の評価を達成できます。 。Gunrock 2.0は、ユーザーの適応に重点を置いてGunrockの上に構築されています。 
[ABSTRACT] gunrock 2. 0は、さまざまなニューラル自然言語理解モジュールを組み合わせたものです。システムレベルのダイアログマネージャーは、質問の検出、確認応答、エラー処理、および追加機能を処理できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-17">
        <br><font color="black">2020-11-17</font>
      </time>
    </span>
</section>
<!-- paper0: Blind signal decomposition of various word embeddings based on join and
  individual variance explained -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CL/paper_6.html">
      <font color="black">Blind signal decomposition of various word embeddings based on join and
  individual variance explained</font>
    </a>
  </h2>
  <font color="black">さらに、異なるコンポーネントを連結することにより、同じモデルでパフォーマンスが向上することがわかりました。近年、自然言語処理（NLP）は、人間の生活の中でさまざまなアプリケーションで最も重要な領域の1つになっています。この分解フレームワークを通じて、異なる単語の埋め込み間の類似点と相違点を簡単に調査できます。 
[概要]新しい論文では、新しいジョイント信号分離方法を使用することを提案します-ジャイブは、さまざまな訓練された単語の埋め込みをジョイントと個々のコンポーネントに分解します。パフォーマンスの低い元の単語の埋め込みでは、感情のパフォーマンスが大幅に向上することがわかりました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: RNN based Incremental Online Spoken Language Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CL/paper_7.html">
      <font color="black">RNN based Incremental Online Spoken Language Understanding</font>
    </a>
  </h2>
  <font color="black">ASRトランスクリプトのインクリメンタルおよびオンライン処理のためのさまざまなリカレントニューラルネットワークアーキテクチャを紹介および分析し、既存のオフラインシステムと比較します。トランスクリプトのストリームを文にセグメント化するために、字句の文末（EOS）検出器が提案されます。インテント分類..インテント検出実験は、ベンチマークATIS、Snips、およびFacebookの多言語タスク指向ダイアログデータセットで実行され、発話境界のない単語の連続増分ストリームをエミュレートします。 
[概要]提案されたコンセプトは、典型的なsluシステムよりも低いレイテンシーを提供します。それは、話された相互作用を不自然にする高いレイテンシーにつながる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-23">
        <br><font color="black">2019-10-23</font>
      </time>
    </span>
</section>
<!-- paper0: Investigating Catastrophic Forgetting During Continual Training for
  Neural Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CL/paper_8.html">
      <font color="black">Investigating Catastrophic Forgetting During Continual Training for
  Neural Machine Translation</font>
    </a>
  </h2>
  <font color="black">NMTモデルのモジュールに関する調査では、一部のモジュールは一般的なドメイン知識と密接な関係があり、他のいくつかのモジュールはドメイン適応においてより重要であることが示されています。有効性と信頼性を確保するために、さまざまな言語ペアとドメインにわたって実験を行います。この問題を解決するために多くの方法が提案されてきましたが、この現象の原因をまだ知ることはできません。 
[概要]継続的なトレーニング中のツールの大幅な変更により、一般的にパフォーマンスが低下します-ドメイン。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: A Comprehensive Review on Recent Methods and Challenges of Video
  Description -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CL/paper_9.html">
      <font color="black">A Comprehensive Review on Recent Methods and Challenges of Video
  Description</font>
    </a>
  </h2>
  <font color="black">この調査では、すべてのデータセットに対して提案されている最先端のアプローチとその長所と短所について説明します。さらに、すべてのデータセットをオープンドメインデータセットとドメイン固有データセットの2つのクラスに分類します。この研究領域の成長、多数のベンチマークデータセットの可用性は基本的なニーズです。 
[要約]過去10年間で、ビデオの説明、評価指標、およびデータセットのアプローチに関して、この分野でいくつかの作業が行われてきました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: UWB @ DIACR-Ita: Lexical Semantic Change Detection with CCA and
  Orthogonal Transformation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CL/paper_10.html">
      <font color="black">UWB @ DIACR-Ita: Lexical Semantic Change Detection with CCA and
  Orthogonal Transformation</font>
    </a>
  </h2>
  <font color="black">この論文では、DIACR-Ita共有タスクの語彙の意味変化（つまり、時間の経過に伴う単語の意味変化）を検出する方法について説明します。ここでは、$ 1 ^ {st} $をランク付けしました。最後に、変換されたベクトル..私たちの方法は完全に監視されておらず、言語に依存しません。 
[概要]異なる期間から選択された2つのイタリア語コーパスの単語間の意味の違いを調べます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Generalization of Transformer for Speech Recognition with
  Parallel Schedule Sampling and Relative Positional Embedding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CL/paper_11.html">
      <font color="black">Improving Generalization of Transformer for Speech Recognition with
  Parallel Schedule Sampling and Relative Positional Embedding</font>
    </a>
  </h2>
  <font color="black">私たちが提案する方法は、10,000時間の北京語ASRタスクで短い発話に対して7％の相対的改善を達成し、長い発話に対して70％の相対的ゲインを達成します。コンピューティング..ただし、スケジュールされたサンプリングトレーニングを適用すると、この並列化機能は失われます。 
[概要]注意ベースのエンコーダデコーダ（aed）のリカレントニューラルネットワーク（rnn）を置き換えるために、多数のフィードフォワード自己注意層を使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-01">
        <br><font color="black">2019-11-01</font>
      </time>
    </span>
</section>
<!-- paper0: CommonGen: A Constrained Text Generation Challenge for Generative
  Commonsense Reasoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CL/paper_12.html">
      <font color="black">CommonGen: A Constrained Text Generation Challenge for Generative
  Commonsense Reasoning</font>
    </a>
  </h2>
  <font color="black">CommonGenタスクは、1）背景の常識知識を備えた関係推論、および2）目に見えない概念の組み合わせに取り組むための構成的一般化能力を本質的に必要とするため、困難です。実験によると、最先端のテキスト生成には大きなギャップがあります。モデル（T5など）と人間のパフォーマンス..クラウドソースと既存のキャプションコーパスの組み合わせによって構築されたデータセットは、35kの固有の概念セットを超える79kの常識的な記述で構成されています。 
[概要]私たちのデータセットは、35kのユニークなコンセプトを超える79kの常識的な説明で構成されています-セット</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-09">
        <br><font color="black">2019-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Language Generation via Combinatorial Constraint Satisfaction: A Tree
  Search Enhanced Monte-Carlo Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CL/paper_13.html">
      <font color="black">Language Generation via Combinatorial Constraint Satisfaction: A Tree
  Search Enhanced Monte-Carlo Approach</font>
    </a>
  </h2>
  <font color="black">複雑な制約の下で自然言語を生成することは、制御可能なテキスト生成に向けた原則的な定式化です。実験は、TSMHが複数の言語生成タスクで一貫した大幅な改善を達成することを示しています。既存のMCMCアプローチと比較して、サンプリングアプローチはより優れたミキシングパフォーマンスを備えています。 
[概要]組み合わせ制約の指定を可能にするフレームワークを提示します。チャレンジは非常に柔軟性があり、タスクを必要とせず、特定のトレーニングを必要とせず、効率的な制約満足度解決手法を活用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: CovidExplorer: A Multi-faceted AI-based Search and Visualization Engine
  for COVID-19 Information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CL/paper_14.html">
      <font color="black">CovidExplorer: A Multi-faceted AI-based Search and Visualization Engine
  for COVID-19 Information</font>
    </a>
  </h2>
  <font color="black">他の既存のシステムとは対照的に、CovidExplorerは、ソーシャルメディアでインド固有のトピックディスカッションを持ち込み、COVID-19のさまざまな側面を研究します。このペーパーでは、多面的なAIベースの検索および視覚化エンジンであるCovidExplorerを紹介します。全世界がCOVID-19パンデミックとの戦いに巻き込まれ、研究実験、政府の政策、ソーシャルメディアの議論が大幅に急増しています。 
[概要]システム、デモビデオ、およびデータ視覚化プラットフォームは、パンデミックの予防策の理解と開発を目的とした研究をサポートする上で重要な役割を果たすことができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Data Agnostic RoBERTa-based Natural Language to SQL Query Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/cs.CL/paper_15.html">
      <font color="black">Data Agnostic RoBERTa-based Natural Language to SQL Query Generation</font>
    </a>
  </h2>
  <font color="black">最先端の結果は得られていませんが、モデルのトレーニングから直接テーブルデータの必要性を排除し、76.7％のテストセット実行精度を達成しました。RoBERTaの埋め込みとデータに合格しました-最終的なクエリを予測するためのLSTMベースのサブモデルへの無関心な知識ベクトル。一部のデータベースの機密性とデータプライバシーのニーズの高まりを考慮して、データプライバシーを中核とするアプローチを提示しました。 
[概要] nl2sqlタスクは、この問題を解決するための深層学習アプローチを見つけることを目的としています。これらのデータベースは平均的なユーザーを満たす必要がありますが、平均的なコンピューターとの間に障壁があります。ゼロショット学習ベースのモデルを作成しました。自然言語の質問とテーブルスキーマだけで</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-11">
        <br><font color="black">2020-10-11</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Convolutive Transfer Function Invariant SDR training criteria for
  Multi-Channel Reverberant Speech Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.AS/paper_0.html">
      <font color="black">Convolutive Transfer Function Invariant SDR training criteria for
  Multi-Channel Reverberant Speech Separation</font>
    </a>
  </h2>
  <font color="black">これはよく知られている評価指標（BSS Eval）ですが、これまでトレーニングの目的として使用されたことはありません。時間領域のトレーニング基準は、単一チャネルの非残響音声混合物の分離に非常に効果的であることが証明されています。目的のために、畳み込み伝達関数不変の信号対歪み比（CI-SDR）ベースの損失を使用することを提案します。 
[概要] librispeechベースの残響混合物でのパフォーマンスを実証しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Decoder DPRNN: High Accuracy Source Counting and Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.AS/paper_1.html">
      <font color="black">Multi-Decoder DPRNN: High Accuracy Source Counting and Separation</font>
    </a>
  </h2>
  <font color="black">最大5人のスピーカーを混合したWSJ0-mixデータセットでアプローチを評価します。スピーカーの数を数える点で最先端のアプローチを上回り、再構築された信号の品質で競争力を維持していることを示します。具体的には、モデルによって予測されたスピーカーよりもグラウンドトゥルースのスピーカーの数が多かれ少なかれ、品質を評価する方法に関する問題を解決しました。 
[ABSTRACT]私たちのアプローチは、追加の出力ヘッドでmulcatソース分離バックボーンを拡張します。カウント-スピーカーの数を推測するためのヘッド、および元の信号を再構築するためのデコーダーヘッド</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-24">
        <br><font color="black">2020-11-24</font>
      </time>
    </span>
</section>
<!-- paper0: A proposal and evaluation of new timbre visualisation methods for audio
  sample browsers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.AS/paper_2.html">
      <font color="black">A proposal and evaluation of new timbre visualisation methods for audio
  sample browsers</font>
    </a>
  </h2>
  <font color="black">形状はタスクのパフォーマンスを大幅に向上させますが、色とテクスチャはほとんど効果がないことがわかります。また、直接参加者とオンライン参加者の結果を比較し、さらなる調査のための調査の方向性を提案します。調査の動機と実装について説明し、提示します。結果の詳細な分析。 
[概要]最新のオーディオサンプルブラウザは、音響特性と視覚属性の間のマッピングを使用して、アイテムを視覚的に分離します。音色の知覚表現に基づいて、テクスチャラベルを生成し、サンプルを配置するための新しい方法を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Transformer-Transducers for Code-Switched Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.AS/paper_3.html">
      <font color="black">Transformer-Transducers for Code-Switched Speech Recognition</font>
    </a>
  </h2>
  <font color="black">コードスイッチングのさまざまな側面を処理するために、バニラモデルに対して3つの変更を提案します。提案されたアプローチの有効性を、北京語と英語のパブリックコードスイッチングコーパスであるSEAMEデータセットで示し、混合エラー率18.5を達成します。 test_manセットとtest_sgeセットでそれぞれ％と26.3％。次に、センテンス内コードスイッチングに向けたラベルエンコーダトレーニングを改善するために、言語ID情報を使用した新しいマスクベースのトレーニング戦略を提案します。 
[概要]トランスフォーマーを使用したエンドツーエンドのasrシステム-コードの完全なモデルアーキテクチャ-スイッチ音声認識。これらには、コードの低リソースシナリオを処理するための2つの補助損失関数が含まれています-スイッチング。次に、マルチラベル/マルチオーディオコーパスは、テストに向けて広大な単一言語音声コーパスを活用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: RNN based Incremental Online Spoken Language Understanding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.AS/paper_4.html">
      <font color="black">RNN based Incremental Online Spoken Language Understanding</font>
    </a>
  </h2>
  <font color="black">意図検出実験は、ベンチマークATIS、Snips、およびFacebookの多言語タスク指向ダイアログデータセットで実施され、発話境界のない単語の連続増分ストリームをエミュレートします。ASRトランスクリプトの増分およびオンライン処理のために、さまざまな反復ニューラルネットワークアーキテクチャを導入および分析します。そして、それを既存のオフラインシステムと比較します。意図分類のために、トランスクリプトのストリームをセンテンスにセグメント化するために、語彙のEnd-of-Sentence（EOS）検出器が提案されています。 
[概要]提案されたコンセプトは、典型的なsluシステムよりも低いレイテンシーを提供します。それは、話された相互作用を不自然にする高いレイテンシーにつながる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-23">
        <br><font color="black">2019-10-23</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to dance: A graph convolutional adversarial network to generate
  realistic dance motions from audio -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.AS/paper_5.html">
      <font color="black">Learning to dance: A graph convolutional adversarial network to generate
  realistic dance motions from audio</font>
    </a>
  </h2>
  <font color="black">また、実際のモーションデータに匹敵する視覚的な動きの知覚品質も示しました。生成メソッドの3つの定量的メトリックとユーザー調査を使用してメソッドを評価します。古典的な畳み込みニューラルモデルと再帰型ニューラルモデルでこの問題に対処するほとんどのアプローチは、トレーニングと変動性の問題が発生します。本論文では、音声情報からの自動ダンス生成の問題に取り組むために、グラフ畳み込みネットワークに基づく新しい方法を設計します。 
[ABSTRACT]音楽から自然に動くこと、つまりダンスを学ぶことは、人間が楽に行うことが多いより複雑な動きの1つです。この方法は、音声情報からの自動ダンス生成の問題に取り組むように設計されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Generalization of Transformer for Speech Recognition with
  Parallel Schedule Sampling and Relative Positional Embedding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.AS/paper_6.html">
      <font color="black">Improving Generalization of Transformer for Speech Recognition with
  Parallel Schedule Sampling and Relative Positional Embedding</font>
    </a>
  </h2>
  <font color="black">私たちが提案する方法は、10,000時間の北京語ASRタスクで短い発話に対して7％の相対的改善を達成し、長い発話に対して70％の相対的ゲインを達成します。正弦波の位置埋め込みによる自己注意は、同様の音響またはさまざまな位置でのセマンティック情報も..自己注意層は、並列計算のシーケンスにトークンの正弦波位置埋め込みを組み込むことにより、時間依存性を学習します。 
[概要]注意ベースのエンコーダデコーダ（aed）のリカレントニューラルネットワーク（rnn）を置き換えるために、多数のフィードフォワード自己注意層を使用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-01">
        <br><font color="black">2019-11-01</font>
      </time>
    </span>
</section>
<!-- paper0: Sparsity-based audio declipping methods: selected overview, new
  algorithms, and large-scale evaluation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.AS/paper_7.html">
      <font color="black">Sparsity-based audio declipping methods: selected overview, new
  algorithms, and large-scale evaluation</font>
    </a>
  </h2>
  <font color="black">コードは、再現性のある調査とベンチマークを目的として公開されています。最後に、これらの組み合わせと最先端の方法の選択を体系的に比較します。大規模な数値ベンチマークと小規模な正式なリスニングを使用します。テストでは、音声とさまざまな音楽ジャンルの両方について、さまざまなクリッピングレベルのガイドラインを提供します。 
[ABSTRACT]新しい方法は、大規模な数値ベンチマークと小規模な正式なリスニングテストを使用します。これは、音声と音楽の両方のジャンルのさまざまなクリッピングレベルのガイドラインを提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-19">
        <br><font color="black">2020-05-19</font>
      </time>
    </span>
</section>
<!-- paper0: Look who's not talking -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.AS/paper_8.html">
      <font color="black">Look who's not talking</font>
    </a>
  </h2>
  <font color="black">この方法では、音声アクティビティ検出に独立したモデルが必要ないため、スピーカーモデリングと音声アクティビティ検出の両方に統一された表現を使用してスピーカーのダイアリゼーションを実行できます。社内および公開のデータセットで多数の実験を実行します。私たちの方法は、一般的なベースラインを上回っています。この論文では、話者の埋め込みに基づく音声活動検出のためのシンプルで効果的なソリューションを紹介します。 
[要約]音声セグメントを決定する機能は、ダイアリゼーションシステムの重要な部分です。特に、話者の埋め込みの基準が音声アクティビティの非常に効果的な指標であることを発見しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-30">
        <br><font color="black">2020-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: ResNeXt and Res2Net Structures for Speaker Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-01/eess.AS/paper_9.html">
      <font color="black">ResNeXt and Res2Net Structures for Speaker Verification</font>
    </a>
  </h2>
  <font color="black">スケールの次元を増やすことにより、Res2Netモデルはさまざまな粒度でマルチスケールの特徴を表すことができ、特に短い発話の話者検証を容易にします。元々画像認識用に提案されたResNeXtとRes2Netは、さらに2つの次元、カーディナリティとスケールを導入します。モデルの表現能力を向上させるために、深さと幅に..提案されたシステムを3つの話者検証タスクで評価します。 
[概要]このホワイトペーパーでは、話者認証のために、resnetアーキテクチャの2つの拡張機能であるresnextとres2netを紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
