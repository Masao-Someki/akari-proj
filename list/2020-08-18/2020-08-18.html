<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-08-18の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: DCCRN: Deep Complex Convolution Recurrent Network for Phase-Aware Speech
  Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.SD/paper_0.html">
      <font color="black">DCCRN: Deep Complex Convolution Recurrent Network for Phase-Aware Speech
  Enhancement</font>
    </a>
  </h2>
  <font color="black">Interspeech 2020 Deep Noise Suppression（DNS）チャレンジに提出された当社のDCCRNモデルは、わずか3.7Mのパラメーターで、平均オピニオンスコア（MOS）に関して、リアルタイムトラックで1位、非リアルタイムトラックで2番目にランク付けされました。特に、たたみ込みリカレントネットワーク（CRN）は、たたみ込みエンコーダーデコーダー（CED）構造と長い短期記憶（LSTM）を統合します。これは、複雑なターゲットに役立つことが証明されています。トレーニングターゲットですが、実際の値のネットワークでトレーニングし、マグニチュードとフェーズコンポーネント、または実部と虚部をそれぞれ予測します。 
[ABSTRACT]畳み込み実ネットワークは、畳み込みニューラルネットワーク（cnn）を使用します。これらの畳み込み実項には、畳み込み部分と長い短期記憶（lstm）が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-01">
        <br><font color="black">2020-08-01</font>
      </time>
    </span>
</section>
<!-- paper0: PIANOTREE VAE: Structured Representation Learning for Polyphonic Music -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.SD/paper_1.html">
      <font color="black">PIANOTREE VAE: Structured Representation Learning for Polyphonic Music</font>
    </a>
  </h2>
  <font color="black">実験は、（i）を介してPianoTree VAEの有効性を証明します。 （ii）-潜在空間で学習されたまともな形状を除いて、より満足できる再構成。 （iii）-下流の音楽世代の多様性に対するこのモデルの利点..通常、より豊かなモダリティとより複雑な音楽構造で構成されるポリフォニック対応は、音楽表現学習のコンテキストではまだ対処されていません..音楽の主要なアプローチ表現学習には、深い教師なしモデルファミリー変分オートエンコーダ（VAE）が含まれます。 
[ABSTRACT]成功した試みのほとんどはモノラル音楽に限定されています。ただし、これらの試みの多くは解決されていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: StoRIR: Stochastic Room Impulse Response Generation for Audio Data
  Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.SD/paper_2.html">
      <font color="black">StoRIR: Stochastic Room Impulse Response Generation for Audio Data
  Augmentation</font>
    </a>
  </h2>
  <font color="black">StoRIRのPython実装をオンラインで公開しています。このホワイトペーパーでは、機械学習アプリケーションでのオーディオデータ拡張専用の確率的ルームインパルス応答生成方法であるStoRIRを紹介します。この方法は直感的で実装が簡単で、非常に複雑なエンクロージャのRIRを生成できます。 
[ABSTRACT] storirを使用すると、ディープラーニングモデルは、従来のイメージを使用する場合よりも幅広いメトリックでより良い結果を達成できます-ソースメソッド</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Variational Generative Models for Audio-visual Speech Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.SD/paper_3.html">
      <font color="black">Deep Variational Generative Models for Audio-visual Speech Separation</font>
    </a>
  </h2>
  <font color="black">この論文では、単一チャンネルのオーディオ録音と各スピーカーに関連する視覚情報（唇の動き）が与えられた場合の視聴覚音声分離に関心があります。具体的には、トレーニング中に潜在変数生成モデルがクリーンから学習されます。変分オートエンコーダー（VAE）を使用した音声スペクトログラム。私たちは、クリーンな音声の視聴覚生成モデリングに基づく教師なし手法を提案します。 
[ABSTRACT]クリーンな音声のオーディオスペクグラムモデリングに基づいた教師なし手法を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Exploiting Fully Convolutional Network and Visualization Techniques on
  Spontaneous Speech for Dementia Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.SD/paper_4.html">
      <font color="black">Exploiting Fully Convolutional Network and Visualization Techniques on
  Spontaneous Speech for Dementia Detection</font>
    </a>
  </h2>
  <font color="black">さらに、畳み込み層を構築して、大津の視覚化方法を使用してヒートマップを作成し、時系列のオーディオセグメントが分類結果に与える影響を理解できるようにします。視覚化手法により、オーディオセグメントなどの影響を評価できます。具体的には、最初に各参加者のオーディオデータからメル周波数ケプストラム係数（MFCC）機能マップを取得し、オーディオデータの音声分類タスクをMFCCフィーチャーマップの画像分類タスク。 
[要約]完全な畳み込みネットワークは、さまざまな次元の音声サンプルに対応します。このシステムにより、手動のセグメンテーションなしで音声サンプルを分析できます。これは、データ不足の問題を理解するためにも使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Low-Latency Speech Enhancement with Mobile Audio Streaming
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.SD/paper_5.html">
      <font color="black">Efficient Low-Latency Speech Enhancement with Mobile Audio Streaming
  Networks</font>
    </a>
  </h2>
  <font color="black">MASnetは、Layer-by-Layerバッチモードの複雑さに一致する低レイテンシの増分推論モードで動作できます。モバイルデバイスに特に適した効率的な低レイテンシ音声拡張のためのモバイルオーディオストリーミングネットワーク（MASnet）を提案します。計算能力が制限されている他のアプリケーション。同様の完全たたみ込みアーキテクチャと比較して、MASnetは深度ごとおよび点ごとのたたみ込みを組み込んで、1秒あたりの融合型積和演算（FMA / s）を大幅に削減します。 SNR。 
[ABSTRACT] masnetは線形スケールのスペクトログラムを処理し、連続するノイズフレームを複雑な値の比率マスクに変換します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Mask CTC: Non-Autoregressive End-to-End ASR with CTC and Mask Predict -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.SD/paper_6.html">
      <font color="black">Mask CTC: Non-Autoregressive End-to-End ASR with CTC and Mask Predict</font>
    </a>
  </h2>
  <font color="black">推論中に、ターゲットシーケンスは貪欲なCTC出力で初期化され、信頼性の低いトークンはCTC確率に基づいてマスクされます。この作業では、マスク予測とCTCの共同トレーニングを備えたトランスフォーマーエンコーダー/デコーダーを使用してマスクCTCモデルがトレーニングされます。 ..異なる音声認識タスクの実験結果は、Mask CTCが標準のCTCモデル（たとえば、WSJで17.9％-&gt; 12.1％WER）を上回り、自己回帰モデルに近づき、CPUを使用して推論時間を大幅に短縮することを示しています（Python実装では0.07 RTF） ）。 
[ABSTRACT]モデルは、出力トークン間の条件付き依存関係に基づいています。これらのマスクされた低-信頼性トークンは、高信頼性トークンの条件付けで予測されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-18">
        <br><font color="black">2020-05-18</font>
      </time>
    </span>
</section>
<!-- paper0: POP909: A Pop-song Dataset for Music Arrangement Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.SD/paper_7.html">
      <font color="black">POP909: A Pop-song Dataset for Music Arrangement Generation</font>
    </a>
  </h2>
  <font color="black">さらに、テンポ、ビート、キー、コードのアノテーションを提供します。テンポ曲線は手動でラベル付けされ、その他はMIRアルゴリズムによって行われます。最後に、標準のディープミュージック生成アルゴリズムを使用して、このデータセットでいくつかのベースライン実験を行います。 。音楽アレンジメントの生成は、自動音楽生成のサブタスクであり、新しい作曲技法で曲を再構築および再概念化することを含みます。 
[ABSTRACT] pop909は、プロのミュージシャンが作成した909の人気曲のピアノアレンジの複数のバージョンを含むデータセットです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Transfer Learning Approaches for Streaming End-to-End Speech Recognition
  System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.SD/paper_8.html">
      <font color="black">Transfer Learning Approaches for Streaming End-to-End Speech Recognition
  System</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、RNN-Tフレームワークの4つの異なるTL手法の比較研究を紹介します。また、50時間から1000時間の範囲のさまざまなトレーニングデータでTLの影響を研究し、少量の言語でのTLの有効性を示します。トレーニングデータ..ランダムに初期化されたRNN-Tモデルに対して、さまざまなTL手法で17％の相対ワードエラー率の低下を示しています。 
[ABSTRACT] tlは、少量の知識によって、リカレントニューラルネットワークトランスデューサー（rnn -t）モデルなどのエンドツーエンド（e2e）asrシステムに適用できます。この調査では、さまざまなtlメソッドで17％の相対ワードエラー率が減少</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Interpretable Representation for Controllable Polyphonic Music
  Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.SD/paper_9.html">
      <font color="black">Learning Interpretable Representation for Controllable Polyphonic Music
  Generation</font>
    </a>
  </h2>
  <font color="black">現在のモデルは、8ビートの長いピアノの作曲セグメントの学習に焦点を当てています。客観的評価と主観的評価の両方から、解法の成功と高品質の制御された音楽生成が達成されていることがわかります。コンポジションスタイルの転送、テクスチャのバリエーション、伴奏の配置など、幅広いアプリケーションに対応します。 
[ABSTRACT] vaeフレームワークに基づく新しいアーキテクチャは、ポリフォニック音楽の2つの潜在的な要素を学ぶことを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning Based Open Set Acoustic Scene Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.SD/paper_10.html">
      <font color="black">Deep Learning Based Open Set Acoustic Scene Classification</font>
    </a>
  </h2>
  <font color="black">適応C2AEは、所定の実験のより公平な比較を包含し、元の推論手順を簡素化して、実際のシナリオでより適切に適用できるようにします。3番目のモデルとして、私たちの適応クラス条件付きオートエンコーダ（適応C2AE）を使用します。 C2AEと呼ばれる別のコンピュータービジョン関連手法のバリエーション。2つのトレーニングシナリオも分析します。未知のクラスの追加知識なしと、未知のクラスの例の限られたサブセットが利用可能な別のシナリオです。 
[ABSTRACT]ディープネットワーク分類器のソフトマックス出力のテストテストスレッショルドをテストします。これは現在ascで使用されている最も一般的な手法です。2つのトレーニングシナリオも分析します。未知のクラスに関する追加の知識なしと、例の限られたサブセットがある場合未知のクラスから利用可能です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Timbre latent space: exploration and creative aspects -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.SD/paper_11.html">
      <font color="black">Timbre latent space: exploration and creative aspects</font>
    </a>
  </h2>
  <font color="black">あるいは、教師なしの次元が残りの機能を考慮に入れている間に、特定のサウンド属性を制御変数として学習できます。最近の研究では、教師なしモデルがオートエンコーダーを使用して可逆オーディオ表現を学習する能力が示されています。高品質のサウンド合成を可能にしますが、潜在的なスペースは音色の特性をほどかさないため、制限された制御。 
[ABSTRACT]潜在スペースは音色のプロパティを解きほぐしません。疑いのない音色操作の新しい可能性が有効になります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Task Learning for Interpretable Weakly Labelled Sound Event
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.SD/paper_12.html">
      <font color="black">Multi-Task Learning for Interpretable Weakly Labelled Sound Event
  Detection</font>
    </a>
  </h2>
  <font color="black">コードは公開されています。提案された方法論の評価のために、DCASE 2019タスク1音響シーンデータをDCASE 2018タスク2サウンドイベントデータと0、10、20 db SNRでリミックスします。補助タスクは、自動エンコーダー構造を使用します。ソース固有の情報を保持するためのネットワークを奨励する。 
[要約]このペーパーは、弱いラベルのオーディオデータから学習するためのマルチタスク学習（mtl）フレームワークを提案します。2つのステップを使用して、分類パフォーマンスを損なうことなく時間レベル情報を保持します。これにより、内部t-f表現が間接的にノイズ除去され、分類が改善されますノイズの多い録音でのパフォーマンス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Siloed Federated Learning for Multi-Centric Histopathology Datasets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.IV/paper_0.html">
      <font color="black">Siloed Federated Learning for Multi-Centric Histopathology Datasets</font>
    </a>
  </h2>
  <font color="black">この戦略は、データの不均一性に対する堅牢性を向上させると同時に、センター固有のレイヤーアクティベーション統計を共有しないことにより、情報漏えいの可能性を低減します。特に、トランスファーラーニングについて、私たちのアプローチは以前の最先端の方法と比較して有利であることを示しています。データセット..私たちは、Camelyon16およびCamelyon17データセットから抽出された腫瘍性組織病理画像パッチの分類について、提案された方法をベンチマークします。 
[要約]提案された方法は、データデータセットからのデータに基づいています。ディープラーニングアーキテクチャにシステムを使用するのは初めてです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Conditional Adversarial Camera Model Anonymization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.IV/paper_1.html">
      <font color="black">Conditional Adversarial Camera Model Anonymization</font>
    </a>
  </h2>
  <font color="black">このような変換を学習するための条件付き敵対的アプローチを提案します。量的比較により、制限的な非インタラクティブブラックボックス設定でのフレームワークの有効性を示します。以前の作品とは対照的に、モデルの匿名化は、高と低空間周波数情報。 
[ABSTRACT]モデルの匿名化は、見かけのキャプチャモデルが変更されるなど、これらのアーティファクトを変換するプロセスです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br><font color="black">2020-02-18</font>
      </time>
    </span>
</section>
<!-- paper0: Classification of diffraction patterns in single particle imaging
  experiments performed at X-ray free-electron lasers using a convolutional
  neural network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.IV/paper_2.html">
      <font color="black">Classification of diffraction patterns in single particle imaging
  experiments performed at X-ray free-electron lasers using a convolutional
  neural network</font>
    </a>
  </h2>
  <font color="black">必要なデータ分析パイプラインには、バイナリオブジェクト分類（単一ヒットと複数ヒット）を含むいくつかのステップがあります。YOLOv2カラー画像の線形スケール分類で最良の結果が得られます。これは、約97％の精度と約手動のデータ分類と比較すると、それぞれ52％と61％です。ここでは、畳み込みニューラルネットワーク（CNN）を使用してSPI実験からのデータを正常に分類できることを示します。 
[ABSTRACT] spi実験中に大量のデータが収集されます。これにより、自動データ分析の必要性が高まっています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Model-based Learning for Quantitative Susceptibility Mapping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.IV/paper_3.html">
      <font color="black">Model-based Learning for Quantitative Susceptibility Mapping</font>
    </a>
  </h2>
  <font color="black">本質的に存在しないグラウンドトゥルースQSMリファレンスがあるため、これらのDL手法では、複数の方向のサンプリング（COSMOS）マップによる感受性の計算またはネットワークトレーニング用の合成データのいずれかを使用しました。これらの制限に対処するために、モデルベースのDLメソッドを提示します。 、uQSMと表示されます。最近、いくつかのディープラーニング（DL）QSM技術が提案され、印象的なパフォーマンスが実証されました。 
[要約] qsmの生成には、問題のある難しいフィールドを解決する必要があります。ソースの反転問題です。多くの手法が提案され、優れたパフォーマンスが実証されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-14">
        <br><font color="black">2020-04-14</font>
      </time>
    </span>
</section>
<!-- paper0: MRQy: An Open-Source Tool for Quality Control of MR Imaging Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.IV/paper_4.html">
      <font color="black">MRQy: An Open-Source Tool for Quality Control of MR Imaging Data</font>
    </a>
  </h2>
  <font color="black">特定のMRQyメジャーのマークされた違いは、一般的なMRイメージングアーティファクトを修正する必要がある外れ値MRIデータセットを特定することもできました。MRQyは、標準のデスクトップコンピューターで効率的に実行できるスタンドアロンの監視なしツールになるように設計されています。MRQyメジャー両方のコホートでサイト固有の有意な変動が明らかになり、バッチ効果の可能性を示しています。 
[ABSTRACT]このツールは、（a）画像解像度、視野、または画像コントラストのサイト固有の変動、または（b）ノイズ、動き、不均一性、リンギング、またはaliasing.mrqyの測定により、コミュニティ固有の詳細が明らかになり、潜在的なバッチ効果が示されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-10">
        <br><font color="black">2020-04-10</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Cardiac Intervention Assistance: Hardware-aware Neural
  Architecture Exploration for Real-Time 3D Cardiac Cine MRI Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.IV/paper_5.html">
      <font color="black">Towards Cardiac Intervention Assistance: Hardware-aware Neural
  Architecture Exploration for Real-Time 3D Cardiac Cine MRI Segmentation</font>
    </a>
  </h2>
  <font color="black">この作業では、リアルタイム3D心臓シネMRIセグメンテーション用の最初のハードウェア認識マルチスケールニューラルアーキテクチャ検索（NAS）フレームワークを示します。ACDCMICCAI 2017データセットの実験結果は、ハードウェア認識マルチスケールNASフレームワークであることを示しています。最先端のNASセグメンテーションフレームワークと比較して、競合のセグメンテーション精度を達成しながら、レイテンシを最大3.5倍削減し、リアルタイムの制約を満たすことができます。リアルタイムの心臓磁気共鳴画像（MRI）の再生様々な心臓インターベンションを導く上でますます重要な役割。 
[ABSTRACT]目立つことを減らすために、シネmriフレームはオンザフライでセグメント化する必要があります-目立つlag.stateを回避するために-最先端の方法のほとんどは精度のみに焦点を当てており、リアルタイムアプリケーションにはほとんど採用できませんまたはローカルハードウェア</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: SoftPoolNet: Shape Descriptor for Point Cloud Completion and
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.IV/paper_6.html">
      <font color="black">SoftPoolNet: Shape Descriptor for Point Cloud Completion and
  Classification</font>
    </a>
  </h2>
  <font color="black">デコーダーステージでは、グローバルな活性化エントロピーを最大化することを目的とした新しいオペレーターである領域畳み込みを提案します。点群は、ボリュームデータよりも柔軟性と効率が高いため、多くのアプリケーションでデフォルトの選択肢となることがよくあります。さらに、ローカルポイントコンプリーションネットワーク（PCN）での改良手順では、点群のデコンボリューション演算をシミュレートするパッチ変形演算も提案します。 
[要約]ポイントコンプリーションネットワーク（convo）は、アクティブ化に基づいて抽出された特徴を整理する新しい方法です。これをソフトプーリングと呼びます。新しい方法では、点群のデコンボリューション操作をシミュレートするパッチ変形操作を提案しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: First U-Net Layers Contain More Domain Specific Information Than The
  Last Ones -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.IV/paper_7.html">
      <font color="black">First U-Net Layers Contain More Domain Specific Information Than The
  Last Ones</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、1）ドメインシフトは、単純な脳抽出セグメンテーションタスクでも品質を低下させる可能性があることを示しています（表面のダイススコアが0.85〜0.89から0.09にまで低下）。 2）最初の層の微調整は、ほとんどすべての監視ドメイン適応設定で最後の層の微調整よりも大幅に優れています。サイトは、目に見えないドメインのCNNセグメンテーション品質を劇的に低下させます。 
[ABSTRACT] mriはネットワークの最初の層で低下します。これは、mriの変動が必ずしもcnnのカバレッジに関連していないことを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Autoencoder GAN for Cryo-EM Image Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.IV/paper_8.html">
      <font color="black">Robust Autoencoder GAN for Cryo-EM Image Denoising</font>
    </a>
  </h2>
  <font color="black">従来の画像のノイズ除去方法では、画像の信号ノイズ比（SNR）が低い場合、Cryo-EM画像のノイズを適切に除去できません。敵対的ネットワーク（GAN）方式。ただし、Cryo-EMが検出する2D画像はノイズが高く、多くの場合、複数の不均一なコンフォメーションまたは汚染が混在しているため、ノイズ除去に課題があります。 
[ABSTRACT] cryo-em（dai）は、新しい効果的なノイズ除去技術を開発しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Emergency Response during Hurricane Season using Computer
  Vision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.IV/paper_9.html">
      <font color="black">Improving Emergency Response during Hurricane Season using Computer
  Vision</font>
    </a>
  </h2>
  <font color="black">特に損傷評価の場合は、U-Netに2つ目のエンコーダーを追加して、イベント前とイベント後の画像機能を同時に学習できるようにしました。 OpenStreetMapsを含むオープンソースラベルの使用を追加し、ネットワークの入力にサイドチャネルとしてHeight Above Nearest Drainage（HAND）を含む補完的なデータソースを追加して、視覚的特性に直交する他の機能を学習するように促します。米国海洋大気庁（NOAA）のリモートセンシング部門からのデータ。これには、都市と街路レベルの詳細がモザイクタイル画像として表示されるほか、Xview2チャレンジの一部としてリリースされたデータも含まれます。 
[ABSTRACT]システムは、危機の前、最中、および後に収集されたデータを使用します。これは、災害対応のすべての段階で意思決定を可能にするために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Fast and Accurate Modeling of Transient-state Gradient-Spoiled Sequences
  by Recurrent Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.IV/paper_10.html">
      <font color="black">Fast and Accurate Modeling of Transient-state Gradient-Spoiled Sequences
  by Recurrent Neural Networks</font>
    </a>
  </h2>
  <font color="black">RNNモデルの計算効率は、他の既存のモデルと比較することで示され、最新のGPU加速オープンソースEPGパッケージと比較して1〜3桁の加速を示しています。結果は、RNNサロゲートモデルが計算に効率的に使用できることを示しています。数十秒以内の過渡状態信号と導関数の大規模な辞書により、最新の実装と比較して数桁の加速が得られます。通常、さまざまな定量的応答には、MR信号応答の高速かつ正確なモデリングが必要です。 MRフィンガープリンティングやMR-STATなどのMRIアプリケーション。 
[ABSTRACT]この作業では、正確なシミュレーションのために新しいepg-blochモデルを使用しています。高速のsurrogate.mrf辞書の生成と最適な脳データが必要であるため、リカレントニューラルネットワーク（rnn）が推奨されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Reversing the cycle: self-supervised deep stereo through enhanced
  monocular distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_0.html">
      <font color="black">Reversing the cycle: self-supervised deep stereo through enhanced
  monocular distillation</font>
    </a>
  </h2>
  <font color="black">このアーキテクチャは、従来のステレオアルゴリズムをソースとする単一画像の手掛かりといくつかのスパースポイントを利用して、複数の推定に対するコンセンサスメカニズムによって、密で正確な視差マップを推定します。 。私たちは、人気のステレオデータセットを使用して、さまざまな監視信号の影響を徹底的に評価し、パラダイムで訓練されたステレオネットワークが既存の自己監視フレームワークよりも優れていることを示します。 
[ABSTRACT]ディープステレオネットワークをトレーニングするために、単眼の完了ネットワークを通じて知識を抽出します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: A Visual Analytics Framework for Reviewing Multivariate Time-Series Data
  with Dimensionality Reduction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_1.html">
      <font color="black">A Visual Analytics Framework for Reviewing Multivariate Time-Series Data
  with Dimensionality Reduction</font>
    </a>
  </h2>
  <font color="black">次元数が時点または属性の数のいずれかで大きい場合、この手動のタスクは面倒になり、実行不可能になります。フレームワークでは、DRを2つのステップで使用します。多くの現実のデータ駆動型問題解決世界のアプリケーションには、時間依存の多変量データの分析が含まれます。この分析では、データの固有の構造と機能を明らかにするために、次元削減（DR）メソッドがよく使用されます。 
[ABSTRACT] multidrは、全体の時間依存の多変量データのプロセスを可能にする新しいdrフレームワークです。データのインスタンス、タイムポイント、および属性を3D配列として扱う場合、最初の配列は、配列の3つの軸を2、そして2番目のdrステップは、より低い品質の空間でデータを視覚化します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-02">
        <br><font color="black">2020-08-02</font>
      </time>
    </span>
</section>
<!-- paper0: Alpha Net: Adaptation with Composition in Classifier Space -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_2.html">
      <font color="black">Alpha Net: Adaptation with Composition in Classifier Space</font>
    </a>
  </h2>
  <font color="black">分類子レベルの知識の伝達を使用して、「テール」カテゴリの最先端のパフォーマンスを12.6％まで大幅に改善できます。このタスクでのアプローチの成功を紹介します。ロングテール認識の例です。例として、「テール」クラスとも呼ばれる少数のクラスは、パフォーマンスが最も低下し、習得が最も難しいクラスです。独自に、既存の分類の上にモデルを実装できます。分類子レイヤーを含むモデル。 
[要約]分類された空間内で知識を伝達するモデルが開発されています。これらのモデルは、分類子レイヤーを含む既存の分類モデルの上に実装できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Spherical coordinates transformation pre-processing in Deep Convolution
  Neural Networks for brain tumor segmentation in MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_3.html">
      <font color="black">Spherical coordinates transformation pre-processing in Deep Convolution
  Neural Networks for brain tumor segmentation in MRI</font>
    </a>
  </h2>
  <font color="black">デカルトボリュームと球形ボリュームの両方が、BraTS 2019データセットを使用して同じネットワーク構造を持つ2つのDCNNモデルで評価されました。理由の1つは、さまざまなモデルとMRマシンに合わせて調整するデータ標準化がないためです。さらに、球形変換解像度に依存せず、異なる入力解像度でも同じ結果が得られます。 
[要約] mriとmriデータセットが脳腫瘍の治療に導入されました。これは、さまざまなモデルとmrマシンを調整するための情報が不足しているためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: WSRNet: Joint Spotting and Recognition of Handwritten Words -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_4.html">
      <font color="black">WSRNet: Joint Spotting and Recognition of Handwritten Words</font>
    </a>
  </h2>
  <font color="black">数値結果は、提案されたアーキテクチャの有用性を検証します。これは、この方法がキーワードスポッティングにおいて以前の最先端技術を上回り、単語認識の主要な方法の大枠で結果を提供するためです。提案されたネットワークは、 -recurrent CTCブランチと、Autoencodingモジュールでさらに拡張されたSeq2Seqブランチ。これらの表現を2値化と再トレーニングスキームでさらに処理して、キーワードスポッティングに適したコンパクトで非常に効率的な記述子を提供する方法を示します。 
[要約]提案されたネットワークは、非反復ctcブランチとseq2seqブランチに存在します。提案されたシステムは、コンパクトで非常に効率的な記述子を作成するために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Learning for Monocular Depth Estimation from Aerial
  Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_5.html">
      <font color="black">Self-Supervised Learning for Monocular Depth Estimation from Aerial
  Imagery</font>
    </a>
  </h2>
  <font color="black">最大93.5％の精度{\ delta} 1.25を達成します。さらに、未知のデータへのトレーニング済みモデルの一般化と、アプローチの自己改善機能に特に注意を払いました。閉塞またはテクスチャレス地域。 
[要約]このため、単一の移動カメラからの画像シーケンスのみを使用し、深度とポーズ情報を同時に推定する方法を学習します。結果を、マルチビューの数学に基づいて深度マップを推定する従来の方法と比較することにより、</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Weight-dependent Gates for Differentiable Neural Network Pruning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_6.html">
      <font color="black">Weight-dependent Gates for Differentiable Neural Network Pruning</font>
    </a>
  </h2>
  <font color="black">この論文では、フィルタを適応的に枝刈りするために新しい重み依存ゲートを導入するシンプルで効果的なネットワーク剪定フレームワークを提案します。このようにして、重み依存ゲート（W-Gate）を構築し、フィルタ重みから情報を学習してバイナリを取得します。フィルターゲートでフィルターを自動的に除去または保持します。フレームワーク全体は区別可能であり、勾配ベースの方法で最適化して、精度と効率のトレードオフがより優れたコンパクトなネットワークを実現できます。 
[要約]プルーニングの決定はたたみ込みの重みに依存する必要があると主張します。候補となる新規ネットワークのハードウェアレイテンシを推定するために、レイテンシ予測ネット（lpnet）をトレーニングします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-04">
        <br><font color="black">2020-07-04</font>
      </time>
    </span>
</section>
<!-- paper0: An Overview of Deep Learning Architectures in Few-Shot Learning Domain -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_7.html">
      <font color="black">An Overview of Deep Learning Architectures in Few-Shot Learning Domain</font>
    </a>
  </h2>
  <font color="black">少数ショット学習に基づくディープラーニングアーキテクチャの最近の成果、課題、および改善の可能性について説明しました。少数ショット学習（少数ショット学習とも呼ばれます）は、次のようなモデルを作成することを目的とした機械学習のサブフィールドです。人間が学習するのと同じように、少ないデータで目的を学習できます。このホワイトペーパーでは、少数ショット学習に向けた、よく知られているディープラーニングベースのアプローチのいくつかをレビューしました。 
[ABSTRACT]このホワイトペーパーでは、最もよく知られているディープラーニングベースのアプローチのいくつかをレビューしました。これらには、コア参照へのポインターを使用した少数ショットラーニングのディープラーニングアーキテクチャが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: How to Train Your Robust Human Pose Estimator: Pay Attention to the
  Constraint Cue -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_8.html">
      <font color="black">How to Train Your Robust Human Pose Estimator: Pay Attention to the
  Constraint Cue</font>
    </a>
  </h2>
  <font color="black">W32-256x192およびW48plus-384x288構成内のHRNetの場合、オクルージョン拡張により、COCO test-devセットでそれぞれ0.6 AP（75.6〜76.2）および0.7 AP（76.8〜77.5）のゲインが得られます。さらに、2ステップのスケジュールは初期のトレーニングプロセスにおける情報不足に対処するように設計されており、提案されているオクルージョン拡張の可能性を効果的に活用します。人間の姿勢推定では、出現キューと制約キューの両方が重要です。 
[ABSTRACT]オクルージョンの増強により、入力サイズ、フレームワーク、バックボーン、トレーニング、テストセットが異なるほとんどのsotaが一貫して促進されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Meta Learning Deep Visual Words for Fast Video Object Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_9.html">
      <font color="black">Meta Learning Deep Visual Words for Fast Video Object Segmentation</font>
    </a>
  </h2>
  <font color="black">パーソナルロボットや自動運転車は、新しい環境で操作できる必要があり、新しいオブジェクトクラスの認識を迅速かつ効率的に学習する必要があります。オブジェクトの部分に対応する埋め込み空間では、クラスター、つまり「ビジュアルワード」でオブジェクトを表現します。画像空間で..私たちはこれらの視覚的単語を教師なしの方法で学習し、メタ学習を使用してトレーニング目標が推論手順と確実に一致するようにします。 
[要旨]微調整やフローを必要としない高速な因果的アルゴリズムを開発します。オブジェクトオブジェクトがオクルージョンを受けたときにオブジェクトオブジェクトが変化しますが、より局所的なパーツの外観は一貫したままになる場合があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-04">
        <br><font color="black">2018-12-04</font>
      </time>
    </span>
</section>
<!-- paper0: A Neural Markovian Multiresolution Image Labeling Algorithm -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_10.html">
      <font color="black">A Neural Markovian Multiresolution Image Labeling Algorithm</font>
    </a>
  </h2>
  <font color="black">画像に適用しながら（つまり、多くの画像ラベリングアルゴリズムは単一のパーティションまたはセグメンテーションを出力しますが、MCVアルゴリズムはパーティションのシーケンスを出力します。このより複雑な構造は、より高いレベルのビジョンシステムに役立つ情報を提供します。音声）または3D信号（例：
[ABSTRACT]画像評価のためのシステムのコンポーネントは、ハードワイヤードフィードとして同時に実装できます。これは、特定のタイプのmrfをテストする目的です。アルゴリズムは、2dとmrfの領域に等しく適用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-03-20">
        <br><font color="black">2018-03-20</font>
      </time>
    </span>
</section>
<!-- paper0: Video Region Annotation with Sparse Bounding Boxes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_11.html">
      <font color="black">Video Region Annotation with Sparse Bounding Boxes</font>
    </a>
  </h2>
  <font color="black">VGCNのグローバル最適化により、既存のソリューションよりも大幅に強化され、一般化されます。この作業は、ターゲット領域の疎に注釈が付けられた境界ボックスからビデオのすべてのフレームの領域境界を自動的に生成することを学習することにより、このジレンマを解決することを目的としています。これらのタスクは、ただし、空間と時間の両方で、高密度に注釈が付けられたトレーニングデータにますます依存しています。 
[ABSTRACT]以前のデータセットは、私たちの方法の有効性を示しています。これらには、アブレーション研究とアブレーション研究が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Oriented Object Detection in Aerial Images with Box Boundary-Aware
  Vectors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_12.html">
      <font color="black">Oriented Object Detection in Aerial Images with Box Boundary-Aware
  Vectors</font>
    </a>
  </h2>
  <font color="black">特に、最初にオブジェクトの中心キーポイントを検出し、それに基づいてボックス境界認識ベクトル（BBAVectors）を回帰して、方向付けられた境界ボックスをキャプチャします。航空写真での方向付けされたオブジェクトの検出は、航空写真は任意の方向に表示され、通常は密にパックされます。ボックス境界認識ベクトルは、すべての任意の向きのオブジェクトのデカルト座標系の4つの象限に分散されます。 
[ABSTRACT]開発途上国で最も効果的なオブジェクトのビジョン。ただし、これらは、ベースライン法で採用されているように、固定された境界ボックスの幅、高さ、角度を予測することは困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Task Incremental Learning for Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_13.html">
      <font color="black">Multi-Task Incremental Learning for Object Detection</font>
    </a>
  </h2>
  <font color="black">ドメインギャップと特にカテゴリの違いが大きい困難なケースでは、データセット全体から多様で有益なサンプルを選択して、忘れをさらに防ぐための適応型標本抽出法を提案します。実験結果は、 7つのオブジェクト検出ベンチマークデータセットにわたる3つの異なるシナリオでの最先端のパフォーマンス。オブジェクト検出器を段階的にトレーニングすることはほとんど検討されていません。 
[ABSTRACT]新しい方法は、増分検出における忘却を軽減することができます。一般的な理解に反して、ドメインのギャップは増分検出に比較的小さな悪影響を与えることがわかりますが、カテゴリの違いが主要な問題です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-13">
        <br><font color="black">2020-02-13</font>
      </time>
    </span>
</section>
<!-- paper0: Conditional Adversarial Camera Model Anonymization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_14.html">
      <font color="black">Conditional Adversarial Camera Model Anonymization</font>
    </a>
  </h2>
  <font color="black">生成ネットワークを抑制してアーティファクトの全範囲を変換する事前トレーニング済みのデュアルストリームモデル属性分類子からの損失で目的を拡大します。このような変換を学習するための条件付き敵対的アプローチを提案します。 、モデルの匿名化を空間周波数情報の高低両方の変換プロセスとしてキャストします。 
[ABSTRACT]モデルの匿名化は、見かけのキャプチャモデルが変更されるなど、これらのアーティファクトを変換するプロセスです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br><font color="black">2020-02-18</font>
      </time>
    </span>
</section>
<!-- paper0: Consistency Guided Scene Flow Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_15.html">
      <font color="black">Consistency Guided Scene Flow Estimation</font>
    </a>
  </h2>
  <font color="black">アブレーション研究を含む複数の実験で、提案されたモデルは、困難な画像の視差とシーンの流れを確実に予測でき、最新技術よりも一般化が進んでおり、目に見えないドメインに迅速かつロバストに適応することを示しています。一貫性の損失に固有のモデリングエラー（例：モデルは、予測を反復的に洗練することにより、テスト時に自己適応します。
[要約]精緻化システムは、ステレオと写真の一貫性を組み合わせた一貫性の損失によってガイドされます。そして3Dモーション</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-19">
        <br><font color="black">2020-06-19</font>
      </time>
    </span>
</section>
<!-- paper0: Not 3D Re-ID: a Simple Single Stream 2D Convolution for Robust Video
  Re-identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_16.html">
      <font color="black">Not 3D Re-ID: a Simple Single Stream 2D Convolution for Robust Video
  Re-identification</font>
    </a>
  </h2>
  <font color="black">逆に、2D畳み込みネットワークによって抽出されたグローバルな特徴は、最新のビデオRe-IDの堅牢な状態の十分な表現であることを私たちの作業は示しています。私たちのアプローチは、最高のビデオRe-IDプラクティスを使用し、データセット間で学習を転送して既存の状態を上回る-MARS、PRID2011、およびiLIDS-VIDデータセットに対する最新の手法。それぞれ89：62％、97：75％、97：33％のランク1の精度で、MARSの84：61％mAPを使用します。メモリを多用する3Dコンボリューションまたは他の現代の作品で見られるようなマルチストリームネットワークアーキテクチャ。これらのクリップレベルの機能を一般化して、大幅な追加コストなしで平均化することでビデオレベルの機能を抽出できます。 
[ABSTRACT] video-based re-idは、人物ごとに複数のフレームを介してビデオから機能を学習することにより、以前の画像ベースのre-idメソッドを拡張したものです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-14">
        <br><font color="black">2020-08-14</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchical and Unsupervised Graph Representation Learning with
  Loukas's Coarsening -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_17.html">
      <font color="black">Hierarchical and Unsupervised Graph Representation Learning with
  Loukas's Coarsening</font>
    </a>
  </h2>
  <font color="black">高品質の埋め込みを生成するには、強力な理論的保証を持つ粗雑化法と相互情報最大化で十分であることを示します。このアルゴリズムは、教師なしグラフ表現学習法の中で最先端の技術と競争力があることを示しています。文献の一般的なベンチマーク。 
[ABSTRACT]このメソッドはディープラーニングパイプラインにプラグインでき、バックコミュニケーションを可能にします。共通のベンチマークを使用して分類タスクで評価します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-organ Segmentation via Co-training Weight-averaged Models from
  Few-organ Datasets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_18.html">
      <font color="black">Multi-organ Segmentation via Co-training Weight-averaged Models from
  Few-organ Datasets</font>
    </a>
  </h2>
  <font color="black">公開されている3つの単一臓器データセットLiTS、KiTS、膵臓、およびMOBAから手動で作成した単一臓器データセットに対する広範な実験により、本手法は少数臓器データセットをより適切に利用でき、推論の計算コストを抑えながら優れたパフォーマンスを実現できることが示されています。 2つのネットワークをトレーニングし、結合されたネットワークが注釈なしの臓器について互いに教え合うようにします。この論文では、少数臓器データセットから統合多臓器セグメンテーションネットワークを学習するための重み平均モデルを共同トレーニングすることを提案します。 
[要旨]一部の医療センターでは、独自の臨床実習のために、臓器の完全な注釈しかありません。既存のアプローチは、臓器のサブセットごとに単一のモデルをトレーニングおよび展開します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: White blood cell classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_19.html">
      <font color="black">White blood cell classification</font>
    </a>
  </h2>
  <font color="black">それにもかかわらず、冗長な機能は分類の速度と効率に影響を与える可能性があるため、分類と回帰ツリー（CART）に基づく機能選択アルゴリズムが設計されています。セグメント化された核および細胞領域のそれぞれ95.98％および97.57％のダイス類似性の平均。この論文では、5種類の白血球を認識するための新しい自動分類フレームワークを提案します。 
[要旨]これらの機能は、白血球の分類において依然として困難なタスクです。これらには、500の血液塗抹標本画像を含むデータベースのデータセットのスティントスティントスティントが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Category-Level 3D Non-Rigid Registration from Single-View RGB Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_20.html">
      <font color="black">Category-Level 3D Non-Rigid Registration from Single-View RGB Images</font>
    </a>
  </h2>
  <font color="black">これは、カノニカルモデルの可視部分の変形フィールドを推測するCNNをトレーニングし、学習された形状（潜在）空間を使用して、閉塞部分の変形を推測することによって行われます。登録の結果、観測されたモデルは私たちの方法は深度情報を必要としないため、RGB-Dセンサーでは通常は認識しにくいオブジェクトを登録できます。たとえば、
[要約]目的は、特定の3Dモデルを観測された新しいインスタンスに歪める剛体フィールドを見つけることができます。シングルビューrgb画像。たとえば再構成の場合、観測されたネットワークが再構成される</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Edge Network-Assisted Real-Time Object Detection Framework for
  Autonomous Driving -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_21.html">
      <font color="black">Edge Network-Assisted Real-Time Object Detection Framework for
  Autonomous Driving</font>
    </a>
  </h2>
  <font color="black">次に、AVはRoIに基づいて画像データを圧縮し、圧縮された画像をエッジクラウドに送信します。この問題を軽減するために、エッジネットワークを利用したリアルタイムODフレームワーク〜（EODF）を提案します。 AV）は、エッジクラウドに高い計算能力（オブジェクト検出（OD）など）を要求する場合でも、タスクの負荷を軽減することで、短時間で目的の結果を達成できます。 
[ABSTRACT]提案されたeodfは、リアルタイムでAVに結果を提供し、満足のいく精度を達成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: AP-Loss for Accurate One-Stage Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_22.html">
      <font color="black">AP-Loss for Accurate One-Stage Object Detection</font>
    </a>
  </h2>
  <font color="black">この目的のために、パーセプトロン学習のエラー駆動型更新スキームとディープネットワークのバックプロパゲーションアルゴリズムをシームレスに組み合わせる新しい最適化アルゴリズムを開発します。提案されたアルゴリズムの良好な収束特性と計算の複雑さに関する詳細な分析を提供します。理論的にも経験的にも..その微分不可能性と非凸性のため、AP損失は直接最適化できません。 
[要約]このペーパーでは、1ステージ検出器の分類タスクをランク付けタスクに置き換える新しいフレームワークを提案します。また、ランク付け問題に平均精度損失（ap-loss）を採用しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Measuring Human Perception to Improve Handwritten Document Transcription -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_23.html">
      <font color="black">Measuring Human Perception to Improve Handwritten Document Transcription</font>
    </a>
  </h2>
  <font color="black">人間の知覚の微妙さは、心理物理学の使用を通じてビジョンサイエンティストによって測定され、視覚認識の内部動作への重要な手がかりです。ここでは、新しい損失の定式化によってサポートされる一般的な強化戦略について説明します。深層学習ベースの文書転記システムのトレーニング体制。現代の手書き文字の自動転記に向けて大きな進歩がありましたが、歴史的文書の転記には大きな課題が残っています。 
[要約]新しい損失の化身は、あらゆる深層学習ベースのドキュメント入力システムのトレーニング体制に適用できます。元はst。の回廊によって生成された、デジタル化されたラテン語の原稿の新しいデータセット。 9世紀の胆嚢</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-07">
        <br><font color="black">2019-04-07</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Feature Learning by Cross-Level Discrimination between
  Instances and Groups -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_24.html">
      <font color="black">Unsupervised Feature Learning by Cross-Level Discrimination between
  Instances and Groups</font>
    </a>
  </h2>
  <font color="black">グループレベルの差別を課すのではなく、インスタンスとグループの間にクロスレベルの差別を課すことによって、グループ化をインスタンスレベルの差別に統合することを提案します。自然なグループ化も尊重する最も差別的な機能を見つけるために、各インスタンスに尋ねますそれから遠く離れたインスタンスのグループを弾くために。一般的なデータセットでの分類によってベンチマークとして、教師なし特徴学習は、不変のマッピングとインスタンスレベルの識別で大きな進歩を遂げました。 
[ABSTRACT]これらのデータセットは、特徴的でクラスが認識されるようにキュレーションされています。ただし、これらも反発力を課すように設計されています。このクロスレベルの反発力は、類似のインスタンスをアクティブにバインドします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-09">
        <br><font color="black">2020-08-09</font>
      </time>
    </span>
</section>
<!-- paper0: Fast and Robust Face-to-Parameter Translation for Game Character
  Auto-Creation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_25.html">
      <font color="black">Fast and Robust Face-to-Parameter Translation for Game Character
  Auto-Creation</font>
    </a>
  </h2>
  <font color="black">ニューラルスタイルの転送または単眼の3D顔再構成に基づいて設計された以前の方法とは異なり、キャラクターの自動作成プロセスを別の視点で再定式化します。教師あり学習パラダイム.7つの公開顔検証データセットの比較結果とアブレーション分析は、私たちの方法の有効性を示唆しています。その高い効率にもかかわらず、インタラクティブ性は、ユーザーがオプションで顔のパラメーターを微調整できる私たちの方法で維持されます。彼らのニーズに応じて作成。 
[要約]このペーパーでは、プレーヤーの入力顔写真に応じてゲーム内キャラクターを生成するゲームキャラクター自動作成フレームワークを提案します。異なるパラメーターを更新する代わりに、顔ベースのトランスレーターを導入します。これにより、作成を行うことができます主題への編集、編集、編集を使用して、自分のペースで効率的に</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: An Improved Dilated Convolutional Network for Herd Counting in Crowded
  Scenes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_26.html">
      <font color="black">An Improved Dilated Convolutional Network for Herd Counting in Crowded
  Scenes</font>
    </a>
  </h2>
  <font color="black">上海のデータセットに適用すると、平均絶対誤差（MAE）が20 \％低くなることも示されています。バックエンドで最適化された拡張率構成を見つけるために、遺伝的アルゴリズムを利用することも提案しています。 。バックエンドと呼ばれる2番目の部分は、プーリング層を置き換えるために使用される拡張畳み込みニューラルネットワーク（CNN）です。 
[ABSTRACT]システムは、非常に混雑した画像の人数を予測するために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Incomplete Descriptor Mining with Elastic Loss for Person
  Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_27.html">
      <font color="black">Incomplete Descriptor Mining with Elastic Loss for Person
  Re-Identification</font>
    </a>
  </h2>
  <font color="black">次に、CBDBMは各パッチを機能マップの上から下に独立して継続的にドロップします。これにより、複数の不完全な機能を出力し、モデルをプッシュして堅牢な人物記述子を取得します。弾性損失では、ディープモデルがトレーニングプロセス全体でハードサンプルペアとイージーサンプルペアを適応的にバランスさせるのに役立ちます。連続バッチDropBlockモジュール（CBDBM）では、最初に機能マップで均一な分割を行います。 
[ABSTRACT] cbdb-netには2つの新しいモジュールが含まれています：連続バッチドロップブロックモジュール（cbdbm）と弾性損失</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: MRQy: An Open-Source Tool for Quality Control of MR Imaging Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_28.html">
      <font color="black">MRQy: An Open-Source Tool for Quality Control of MR Imaging Data</font>
    </a>
  </h2>
  <font color="black">特定のMRQy測定値のマーク付きの違いにより、一般的なMRイメージングアーティファクトを修正する必要がある外れ値MRIデータセットを特定することもできました。ノイズ比、変動メトリクス、エントロピーおよびエネルギー基準）およびMR画像メタデータ（例：新しいMRQy （a）サイトまたは機器ベースの違いについてMRIコホートを調査し、（b）相対的な画像品質に対するMRIアーティファクトの影響を定量化するオープンソース品質管理ツール;モデル開発の前にこれらの変動を修正する方法を決定するのに役立ちます
[ABSTRACT]このツールは、（a）画像の解像度、視野、または画像のコントラストにおけるサイト固有の変動、または（b）ノイズ、動き、不均一性、リンギングなどの画像のアーチファクトの存在を定量化するのに役立ちますまたはaliasing.mrqyメジャーにより、コミュニティ固有のより広い範囲が明らかになり、バッチの影響の可能性が示されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-10">
        <br><font color="black">2020-04-10</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Cardiac Intervention Assistance: Hardware-aware Neural
  Architecture Exploration for Real-Time 3D Cardiac Cine MRI Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_29.html">
      <font color="black">Towards Cardiac Intervention Assistance: Hardware-aware Neural
  Architecture Exploration for Real-Time 3D Cardiac Cine MRI Segmentation</font>
    </a>
  </h2>
  <font color="black">さらに、信頼性と患者データのプライバシーを考慮して、計算はローカルハードウェアで行うのが望ましいです。この作業では、リアルタイム3D心臓シネMRIセグメンテーション用の最初のハードウェア認識マルチスケールニューラルアーキテクチャ検索（NAS）フレームワークを示します。 ..提案されたフレームワークは、潜在的な正則化項を損失関数に組み込んで、基盤となるハードウェアを考慮して、リアルタイム制約を処理します。 
[ABSTRACT]目立つことを減らすために、シネmriフレームはオンザフライでセグメント化する必要があります-目立つlag.stateを回避するために-最先端の方法のほとんどは精度のみに焦点を当てており、リアルタイムアプリケーションにはほとんど採用できませんまたはローカルハードウェア</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Vision-Based Fall Event Detection in Complex Background Using Attention
  Guided Bi-directional LSTM -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_30.html">
      <font color="black">Vision-Based Fall Event Detection in Complex Background Using Attention
  Guided Bi-directional LSTM</font>
    </a>
  </h2>
  <font color="black">他の最先端の方法と比較したアルゴリズムのパフォーマンスの評価は、提案された設計が正確で堅牢であることを示しています。これは、複雑な状況での落下イベント検出のタスクに適していることを意味します。効率を実証するために、提案された方法は、パブリックデータセットとセルフビルドデータセットで検証されています。バックグラウンドモデリングに依存するほとんどの従来のバックグラウンドサブトラクション法とは異なり、深層学習技術に基づくマスクR-CNN法は、ノイズバックグラウンドで移動オブジェクトを明確に抽出できます。 
[要約]アルゴリズムの提案された設計は正確でロバストです。これは、複雑なバックグラウンドでの落下イベント検出の作業に適しています。注意ガイド付きバイセットlstmモデルの開発にも使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-24">
        <br><font color="black">2020-06-24</font>
      </time>
    </span>
</section>
<!-- paper0: Apparel-invariant Feature Learning for Apparel-changed Person
  Re-identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_31.html">
      <font color="black">Apparel-invariant Feature Learning for Apparel-changed Person
  Re-identification</font>
    </a>
  </h2>
  <font color="black">実験結果は、私たちの提案がベースラインモデルのReIDパフォーマンスを改善できることを示しています。しかし、ほとんどの公開ReIDデータセットは、人の外見がめったに変化しない短い時間枠で収集されます。（2）身に着けている同じ人の画像を取得するには異なる衣服、私たちは、監視対象の衣服シミュレーションGAN（AS-GAN）を提案し、対象の布の埋め込みに応じて布の変化する画像を合成します。 
[ABSTRACT]公開リードデータセットは、人物の外見がめったに変化しない短いウィンドウで収集されます。これらのアプリケーションは、一貫性のないパフォーマンスをもたらす可能性があり、現在のリードモデルが人物の服装に大きく依存しているという重大な問題が明らかになります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-14">
        <br><font color="black">2020-08-14</font>
      </time>
    </span>
</section>
<!-- paper0: FakePolisher: Making DeepFakes More Detection-Evasive by Shallow
  Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_32.html">
      <font color="black">FakePolisher: Making DeepFakes More Detection-Evasive by Shallow
  Reconstruction</font>
    </a>
  </h2>
  <font color="black">ただし、既存の検出方法では、アーティファクトパターンに重点が置かれており、アーティファクトパターンが減少すると無駄になります。合成画像のアーティファクトの減少に向けて、このペーパーでは、FakePolisherと呼ばれるシンプルで強力な手法を考案します。画像合成中に導入されたアーティファクトを効果的かつ効率的に低減することを目的とした、学習された線形辞書による偽の画像の浅い再構成。3つの最新のDeepFake検出方法および16の人気のGANベースの偽の画像の包括的な評価偽の画像生成技術は、私たちの技術の有効性を示しています。全体的に、アーティファクトパターンを減らすことにより、私たちの技術は、3つの最新の偽の画像検出方法の精度を大幅に低下させます。最悪の場合の％。 
[ABSTRACT] fakepolisherはfakepolisherと呼ばれるシンプルで強力なアプローチです。学習した線形辞書を使用してアーティファクトを削除します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-13">
        <br><font color="black">2020-06-13</font>
      </time>
    </span>
</section>
<!-- paper0: Two-hand Global 3D Pose Estimation Using Monocular RGB -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_33.html">
      <font color="black">Two-hand Global 3D Pose Estimation Using Monocular RGB</font>
    </a>
  </h2>
  <font color="black">カメラの原点に対するグローバルジョイントの位置は、新しいポーズアルゴリズムを使用して、手のポーズの推定とキーボーンの実際の長さを使用して計算されます。さらに、RGBを使用して両手で正確なグローバル3Dハンドトラッキングを実現する最初の作業を紹介します。のみの入力を提供し、広範な定量的および定性的評価を提供します。このシステムは、RGBのみの情報を使用して、3Dの標準的な手姿勢推定ベンチマークデータセットに関する以前の作業よりも優れていることを示しています。 
[要旨]私たちは、正確に手をセグメント化して位置を特定する、新しい多段畳み込み畳み込みニューラルネットワークベースのパイプラインを提案します。rgbを使用して、両手で正確なグローバル3Dハンドトラッキングを実現する最初の作業を紹介します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br><font color="black">2020-06-01</font>
      </time>
    </span>
</section>
<!-- paper0: Geometric Image Correspondence Verification by Dense Pixel Matching -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_34.html">
      <font color="black">Geometric Image Correspondence Verification by Dense Pixel Matching</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、2つの画像間の密なピクセル対応を決定する問題と、画像検索での幾何学的対応検証へのその応用について説明します。密なマッチングのために、このアプローチでは、最近提案された密な幾何学的対応ネットワーク（DGC-Net）の修正バージョンを利用しています。また、アーキテクチャを最適化することで改善されます。提案されたモデルと類似性メトリックは、最新の画像検索方法と比較して優れています。 
[ABSTRACT] re-ランキングは、新規の類似度関数に基づいています。提案されたモデルと類似度ピクセルは、最新の画像検索方法と比較して有利です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-15">
        <br><font color="black">2019-04-15</font>
      </time>
    </span>
</section>
<!-- paper0: Give Me Something to Eat: Referring Expression Comprehension with
  Commonsense Knowledge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_35.html">
      <font color="black">Give Me Something to Eat: Referring Expression Comprehension with
  Commonsense Knowledge</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、KB-Refと呼ばれる新しい参照式データセットを収集します。このデータセットには、16kの画像に43kの式が含まれています。次に、KB-Refで最先端の（SoTA）REFモデルをテストし、それらすべてを見つけます一般的なREFデータセットでの卓越したパフォーマンスと比較して大きな低下を示します。たとえば、「私に何か食べさせて」と言うことがあります。 
[ABSTRACT]たとえば、「食べるものをくれ」と言います。さらに、43人が表現に答えるように求められます。各表現に答えるには、少なくとも1つの練習が必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-02">
        <br><font color="black">2020-06-02</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-label Learning with Missing Values using Combined Facial Action
  Unit Datasets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_36.html">
      <font color="black">Multi-label Learning with Missing Values using Combined Facial Action
  Unit Datasets</font>
    </a>
  </h2>
  <font color="black">この作業では、この課題を検証し、値が推測されずにラベルが欠落している状況でも学習できるデータベースとアルゴリズムを組み合わせて作成するアプローチを紹介します。このアプローチは、アクションユニット検出における最近の競争と比較して競争力のあるパフォーマンスを示しています。異なる研究からの複数のデータセットを組み合わせることにより、機械学習アルゴリズムのトレーニングデータの量を増やし、自動化されたマルチラベルアクションユニット検出のための堅牢なモデルを作成できます。 
[ABSTRACT]アクションユニットのデータに注釈を付けると、コストがかかり、時間のかかるタスクになります。ただし、すべてのスタディでさまざまなアクションユニットに注釈を付けるため、ラベルが失われる可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: DeepGIN: Deep Generative Inpainting Network for Extreme Image Inpainting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_37.html">
      <font color="black">DeepGIN: Deep Generative Inpainting Network for Extreme Image Inpainting</font>
    </a>
  </h2>
  <font color="black">また、モデルがマスクされた画像を野生で完成できることも示します。また、マルチスケール自己注意（MSSA）メカニズムと逆投影（BP）技術を使用して、修復結果を向上させます。空間ピラミッド拡張を設計します。 （SPD）ResNetブロック。遠隔地の機能を使用して再構成できます。 
[ABSTRACT]私たちのディープギンは、一般的に最先端のアプローチよりも優れています。これらには、2つの公開されているデータセット（ffhqとoxfordの建物）が含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Extending and Analyzing Self-Supervised Learning Across Domains -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_38.html">
      <font color="black">Extending and Analyzing Self-Supervised Learning Across Domains</font>
    </a>
  </h2>
  <font color="black">コードとモデルはhttps://github.com/BramSW/Extending_SSRL_Across_Domains/。で入手できます。他の調査結果の中でも、ローテーションはジグソーパズルとインスタンス識別のパフォーマンスの多くが原因であるという意味で、最も意味のあるタスクであることを発見しましたこれらの失敗と成功の理由を、口実の一般化、ランダムなラベリング、および暗黙の次元性を研究する新しい実験によって定量的かつ定性的に診断します。 
[ABSTRACT]ジグソーパズルとインスタンスの識別のパフォーマンスの多くは、誘導された分布の性質に起因するものであり、回転がはるかに意味的に意味のあるタスクであることを発見しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-24">
        <br><font color="black">2020-04-24</font>
      </time>
    </span>
</section>
<!-- paper0: Bayesian deep learning: a new era for 'big data' geostatistics? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_39.html">
      <font color="black">Bayesian deep learning: a new era for 'big data' geostatistics?</font>
    </a>
  </h2>
  <font color="black">ただし、クリギングとそのバリアント（これらの補助変数またはそれらの導関数が共変量として含まれる回帰クリギングなど）は比較的制限的なモデルであり、過去10年間にディープニューラルネットワークによって提供されてきた機能がありません。テレインデリバティブを提供する必要はありません（たとえば、不確実性が問題となる大規模な地球統計学アプリケーションのベイジアンディープラーニングおよびその特徴学習機能の適合性についての認識が高まることを願っています。
[ABSTRACT]ディープニューラルネットワークは、空間的ターゲッティングとグリッド化された補助変数間の複雑な関係。これらは、リモートセンシングによって提供されるような、選択されたターゲット変数の詳細なマップも生成します。結果は、大規模なベイリカンディープラーニングとその機能学習機能の適合性の認識を高めます。 -地球統計学的アプリケーションのスケーリング</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Image Matching across Wide Baselines: From Paper to Practice -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_40.html">
      <font color="black">Image Matching across Wide Baselines: From Paper to Practice</font>
    </a>
  </h2>
  <font color="black">実施された実験により、実際の最先端技術を確立することに加えて、アルゴリズムと学習方法の両方で、Structure from Motion（SfM）パイプラインの予期しない特性が明らかになり、それらのパフォーマンスを向上させることができます。私たちは、主要な指標として、下流のタスク（再構築されたカメラポーズの精度）に焦点を当てて、ローカル機能と堅牢な推定アルゴリズムの包括的なベンチマークを導入します。 
[要旨]パイプラインのモジュラー構造により、さまざまなメソッドとヒューリスティックを簡単に統合、構成、および組み合わせることができます。ローカル機能のベンチマークと堅牢な推定方法のための使いやすく柔軟なフレームワークが提供されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br><font color="black">2020-03-03</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Multispectral Pedestrian Detection by Addressing Modality
  Imbalance Problems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_41.html">
      <font color="black">Improving Multispectral Pedestrian Detection by Addressing Modality
  Imbalance Problems</font>
    </a>
  </h2>
  <font color="black">第二に、照明認識機能アラインメントモジュールは、照明条件に応じて補完的な機能を選択し、2つのモダリティ機能を適応的に調整します。最初に、2つのモダリティが相互に補完し合うように、新しいモダリティ対応の融合（DMAF）モジュールを設計します。実験結果は、MBNetが、精度と計算効率の面で、困難なKAISTとCVC-14のマルチスペクトル歩行者データセットの両方で最先端の技術を上回っていることを示しています。 
[ABSTRACT]コードはgithubで入手できます。 mbnet.itのcom / calayzhouは、2つのモダリティに互換性がないことを確認するように設計されています。2つを融合する方法に関する歩行者情報が不足しています。より柔軟でバランスの取れた方法で機能する設計についての提案もあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-07">
        <br><font color="black">2020-08-07</font>
      </time>
    </span>
</section>
<!-- paper0: Progressively Guided Alternate Refinement Network for RGB-D Salient
  Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_42.html">
      <font color="black">Progressively Guided Alternate Refinement Network for RGB-D Salient
  Object Detection</font>
    </a>
  </h2>
  <font color="black">各副出力内の積み重ねられたGRブロックにプログレッシブガイダンスを割り当てることにより、誤検出と欠落している部分を適切に修正できます。ImageNetの事前トレーニング済みバックボーンネットワークを使用する代わりに、最初から学習して軽量の深度ストリームを構築します。 7つのベンチマークデータセットでの広範な実験により、補完的な機能をより効率的に抽出できます。7つのベンチマークデータセットでの広範な実験により、モデルが既存の最先端のアプローチを大幅に上回っており、効率（71 FPS）とモデルサイズ（ 64.9 MB）。 
[ABSTRACT]たとえば、我々はそれを洗練するために漸進的に導かれる代替の洗練ネットワークを提案します。代わりに、ネットワークはそれらの相互劣化をより再評価することに供給されます。grを割り当てることにより、よりスムーズな開発の効率的な方法を減らすことを目的とします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Sim2Real Predictivity: Does Evaluation in Simulation Predict Real-World
  Performance? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_43.html">
      <font color="black">Sim2Real Predictivity: Does Evaluation in Simulation Predict Real-World
  Performance?</font>
    </a>
  </h2>
  <font color="black">この質問は、具体化されたPointGoalナビゲーション、開発ツール、およびsim2real予測性によってシミュレータを評価するための研究パラダイムについて検討します。実験では、シミュレーションパラメータを調整してsim2real予測性を改善できることが示されています（たとえば、 Sim-vs-Real相関係数（SRCC）で予測可能性を定量化します。
[要約]私たちは、ハビタット-パイロボットブリッジ（hapy）を開発します。仮想化されたレプリカを作成し、9つの異なるモデルの並列テストを実行する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-13">
        <br><font color="black">2019-12-13</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Design by Reinforcement Learning: Maximizing Diversity of
  Topology Optimized Designs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_44.html">
      <font color="black">Generative Design by Reinforcement Learning: Maximizing Diversity of
  Topology Optimized Designs</font>
    </a>
  </h2>
  <font color="black">ジェネレーティブデザインは、特定の制約を満たしながら、トポロジー最適化のパラメーターを多様化することにより、構造的に最適な多数のデザインを並行して生成するデザイン探索プロセスです。この研究では、報酬関数を最大化する強化学習（RL）ベースのジェネレーティブデザインプロセスを提案します。設計の多様性。生成された設計を、与えられた初期設計に従って最適なパラメーターレベルの値を見つける順次問題として定式化します。 
[ABSTRACT]人工知能（ai）テクノロジーとの統合により、zativeデザインは多くの注目を集めています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Neutral Face Game Character Auto-Creation via PokerFace-GAN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_45.html">
      <font color="black">Neutral Face Game Character Auto-Creation via PokerFace-GAN</font>
    </a>
  </h2>
  <font color="black">さらに、以前の方法で使用されたニューラルネットワークベースのレンダラーも、マルチビューレンダリングの場合に拡張するのが困難です。最初に、マルチビューレンダリングの場合の以前の方法よりも柔軟性のある微分可能な文字レンダラーを構築します。ただし、従来の方法では、表情パラメータと顔のアイデンティティパラメータは互いに高度に結合されているため、キャラクターの固有の顔の特徴をモデル化することが困難でした。 
[ABSTRACT]ニュートラルフェイスゲームキャラクターの新しいメソッドは「pokerface-gan」と呼ばれます。これは、1枚の写真でゲーム内キャラクターを自動的に作成する問題に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: MLBF-Net: A Multi-Lead-Branch Fusion Network for Multi-Class Arrhythmia
  Classification Using 12-Lead ECG -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CV/paper_46.html">
      <font color="black">MLBF-Net: A Multi-Lead-Branch Fusion Network for Multi-Class Arrhythmia
  Classification Using 12-Lead ECG</font>
    </a>
  </h2>
  <font color="black">提案された方法は、情報融合の観点からマルチリードECG分析の有望なソリューションを提供します。マルチリードECGの情報学習を最大化するには、完全性を備えた包括的な機能と多様性を備えたリード固有の機能の情報融合を取り入れるべきです。ただし、12誘導間の多様な鉛固有の機能（多様性）が無視されたため、12誘導ECGの情報学習が不十分になりました。 
[ABSTRACT]不整脈信号信号信号システムは不整脈検出の新しい方法です。提案された方法はマルチリード心電図解析の有望なソリューションを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: CODA-19: Using a Non-Expert Crowd to Annotate Research Aspects on
  10,000+ Abstracts in the COVID-19 Open Research Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CL/paper_0.html">
      <font color="black">CODA-19: Using a Non-Expert Crowd to Annotate Research Aspects on
  10,000+ Abstracts in the COVID-19 Open Research Dataset</font>
    </a>
  </h2>
  <font color="black">CODA-19のラベルは、生物医学の専門家のラベルと比較すると82.2％の精度ですが、専門家間の精度は85.0％でした。COVID-19との戦いに参加するために、専門家以外の群衆を大規模に迅速に採用できることを実証しました..このペーパーでは、COVID-19 Open Research Datasetの10,966英語の抄録の背景、目的、方法、発見/貢献、およびその他のセクションをコード化した人間が注釈を付けたデータセットCODA-19を紹介します。 
[ABSTRACT] coda-19は、エキスパートと同等のラベル品質を達成するために、10日以内にamazonメカニカルタークの248人のクラウドワーカーによって作成されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br><font color="black">2020-05-05</font>
      </time>
    </span>
</section>
<!-- paper0: PIANOTREE VAE: Structured Representation Learning for Polyphonic Music -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CL/paper_1.html">
      <font color="black">PIANOTREE VAE: Structured Representation Learning for Polyphonic Music</font>
    </a>
  </h2>
  <font color="black">実験は、（i）を介してPianoTree VAEの有効性を証明します。 （ii）-潜在空間で学習されたまともな形状を除いて、より満足できる再構成。 （iii）-下流の音楽世代の多様性に対するこのモデルの利点..通常、より豊かなモダリティとより複雑な音楽構造で構成されるポリフォニックの対応物は、音楽表現学習のコンテキストではまだ対処されていません。この作業では、 PianoTree VAEを提案します。これは、ポリフォニック音楽の学習に適合することを目的とした、VAEの新しいツリー構造拡張です。 
[ABSTRACT]成功した試みのほとんどはモノラル音楽に限定されています。ただし、これらの試みの多くは解決されていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: A Survey of Active Learning for Text Classification using Deep Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CL/paper_2.html">
      <font color="black">A Survey of Active Learning for Text Classification using Deep Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">結果として、現在の研究のギャップを強調し、未解決の研究の質問を提示します。さらに、（D）NNのコンテキストでの単語の埋め込みや言語モデルなど、NLPにおける最近のNNベースの進歩をレビューし、現在の状態を調査します。 AL、テキスト分類、およびDNNの交差点のアート、およびNLPの最近の進歩をALに関連付けます。最後に、テキスト分類のALでの最近の作業を分析し、それぞれのクエリ戦略を分類法に接続し、共通点と欠点の概要を示します。 。 
[要約]ディープニューラルネットワーク（dnns）を使用したテキスト分類についてalを確認します。これらは、採用を妨げていた2つの主な原因について詳しく説明しています。学ぶために、nnsはテキストとテキスト分類の異なる形式に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Gated Convolutional Bidirectional Attention-based Model for Off-topic
  Spoken Response Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CL/paper_3.html">
      <font color="black">Gated Convolutional Bidirectional Attention-based Model for Off-topic
  Spoken Response Detection</font>
    </a>
  </h2>
  <font color="black">さらに、トレーニングデータを補強するために、新しいネガティブサンプリング法が提案されています。オフトピック音声応答検出、応答が対応するプロンプトに対してトピック外であるかどうかを予測するタスクは、自動音声評価システムにとって重要です。新しいモデル、Gated Convolutional Bidirectional Attention-based Model（GCBiA）を導入します。これは、双方向注意メカニズムと畳み込みを適用して、プロンプトのトピックワードと応答のキーフレーズを抽出し、ゲートユニットと主要レイヤー間の残余接続を導入して、より適切に表現します。応答とプロンプトの関連性。 
[ABSTRACT]新しいモデル、ゲート付き畳み込み双方向注意ベースのモデル（gcbia）。それは、双方向注意メカニズムと畳み込みを適用して、プロンプトとキーのトピック単語を抽出します-応答応答応答。新しいアプローチでは、発話応答検出器が高い表示されたプロンプトと表示されていないプロンプトの両方のリコール</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-20">
        <br><font color="black">2020-04-20</font>
      </time>
    </span>
</section>
<!-- paper0: HunFlair: An Easy-to-Use Tool for State-of-the-Art Biomedical Named
  Entity Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CL/paper_4.html">
      <font color="black">HunFlair: An Easy-to-Use Tool for State-of-the-Art Biomedical Named
  Entity Recognition</font>
    </a>
  </h2>
  <font color="black">連絡先：{weberple、saengema、alan.akbik} @ informatik.hu-berlin.de。この目的のために、広く使用されているNLPフレームワークFlairに統合された複数のエンティティタイプをカバーするNERタガーであるHunFlairを提案します。 、1つのコマンドでインストールでき、4行のコードで適用されます。 
[ABSTRACT] hunflairは他の状態よりも優れています-最先端のスタンドアロンner tools。単一のコマンドでインストールでき、4行のコードのみで適用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Comparison of Syntactic Parsers on Biomedical Texts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CL/paper_5.html">
      <font color="black">Comparison of Syntactic Parsers on Biomedical Texts</font>
    </a>
  </h2>
  <font color="black">構文解析は、情報抽出を目的とする自動テキスト分析の重要なステップです。このホワイトペーパーでは、バイオメディカルテキストマイニングへの適用におけるいくつかの一般的な構文パーサーのパフォーマンスを評価します。構文解析の品質は、テキストマイニング結果の再現と精度。 
[ABSTRACT]構文解析の品質により、テキストマイニング結果の再現率と精度が決まります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Logical Semantics, Dialogical Argumentation, and Textual Entailment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CL/paper_6.html">
      <font color="black">Logical Semantics, Dialogical Argumentation, and Textual Entailment</font>
    </a>
  </h2>
  <font color="black">自然言語のセマンティクスと議論を対話ロジックと結びつけるこの作品は、自然言語のセマンティクスの推論主義的見方への第一歩と見なすことができます。この章では、自然に近い一次古典論理の新しい対話システムを紹介します自動化されたテキストの含意に対処するために、対話システムを2人目の著者が開発したGrail構文およびセマンティックパーサーと組み合わせます。つまり、これを使用して、文が短いテキストの結果であるかどうか。 
[要約]システムは、自動化された文学的含意に対処するために2人目の著者によって開発されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Transfer Learning Approaches for Streaming End-to-End Speech Recognition
  System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CL/paper_7.html">
      <font color="black">Transfer Learning Approaches for Streaming End-to-End Speech Recognition
  System</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、RNN-Tフレームワーク用の4つの異なるTL手法の比較研究を紹介します。ランダムに初期化されたRNN-Tモデルに対して、さまざまなTL手法で17％の相対ワードエラー率の低下を示します。また、さまざまな量のTLの影響を研究します50時間から1000時間の範囲のトレーニングデータで、トレーニングデータが少ない言語でのTLの有効性を示します。 
[ABSTRACT] tlは、少量の知識によって、リカレントニューラルネットワークトランスデューサー（rnn -t）モデルなどのエンドツーエンド（e2e）asrシステムに適用できます。この調査では、さまざまなtlメソッドで17％の相対ワードエラー率が減少</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Interpretable Representation for Controllable Polyphonic Music
  Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CL/paper_8.html">
      <font color="black">Learning Interpretable Representation for Controllable Polyphonic Music
  Generation</font>
    </a>
  </h2>
  <font color="black">現在のモデルは、8ビートの長いピアノの作曲セグメントの学習に焦点を当てています。このようなコードテクスチャの絡み合い解消が、作曲スタイルの転送、テクスチャの変化、伴奏の配置など、幅広いアプリケーションにつながる制御可能な生成経路を提供することを示します。客観的および主観的な評価は、私たちの方法が絡み合い解消と高品質の制御された音楽生成を成功させることを示しています。 
[ABSTRACT] vaeフレームワークに基づく新しいアーキテクチャは、ポリフォニック音楽の2つの潜在的な要素を学ぶことを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Evaluating for Diversity in Question Generation over Text -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CL/paper_9.html">
      <font color="black">Evaluating for Diversity in Question Generation over Text</font>
    </a>
  </h2>
  <font color="black">BLEUやMETEORなどの一般的に使用される評価指標は、参照質問に固有の多様性があるため、このタスクに適さないと主張し、多様性を反映するように従来の指標を拡張するためのスキームを提案します。広範なアプリケーションでのタスク。私たちは、変分モデルが品質を損なうことなく多様性を改善することを自動および人間の評価を通じて示し、評価スキームがこの改善をどのように反映するかを示します。 
[要約]従来のメトリックを拡張して多様性を反映するためのスキームを提案します。自動および人間の評価を通じて、変分モデルが品質を失うことなく多様性を改善することを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: BUT-FIT at SemEval-2020 Task 4: Multilingual commonsense -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CL/paper_10.html">
      <font color="black">BUT-FIT at SemEval-2020 Task 4: Multilingual commonsense</font>
    </a>
  </h2>
  <font color="black">サブタスクCでは、事前トレーニングされたシーケンスツーシーケンスモデル（BART）に基づく提出がBLEUスコアランキングで1位にランク付けされましたが、BLEUと人間の評価との相関関係が示され、提出は4番目に終わりました。このペーパーでは、SemEval 2020タスク4-常識の検証と説明におけるBUT-FITチームの作業について説明します。評価で使用されたメトリックを分析し、サブタスクBのモデルに基づいて追加のスコアを提案します。手動ランキングと同じ原理に基づく再ランキング方法を使用して。 
[要約]チームは3つのサブタスクすべてに参加しました。すべてのサブタスクでエラーとデータセット分析を実行しました。ブルーと人間の評価の相関は低いです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Automated Factchecking: Developing an Annotation Schema and
  Benchmark for Consistent Automated Claim Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/cs.CL/paper_11.html">
      <font color="black">Towards Automated Factchecking: Developing an Annotation Schema and
  Benchmark for Consistent Automated Claim Detection</font>
    </a>
  </h2>
  <font color="black">このシステムは運用環境に導入され、ユーザーからの肯定的なフィードバックを受けました。Googleのアノテーションスキーマは、英国の政治テレビ番組の文章を含むデータセットのアノテーションをクラウドソーシングするために使用されています。事実確認が可能と見なされます。 
[ABSTRACT]システムは分類を実行するための普遍的な文の表現に基づいています。最先端の方法であるClaimBusterおよびClaimRankに比べて5％以上の改善があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-09-21">
        <br><font color="black">2018-09-21</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: DCCRN: Deep Complex Convolution Recurrent Network for Phase-Aware Speech
  Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.AS/paper_0.html">
      <font color="black">DCCRN: Deep Complex Convolution Recurrent Network for Phase-Aware Speech
  Enhancement</font>
    </a>
  </h2>
  <font color="black">複雑なターゲットをより効果的にトレーニングするために、このホワイトペーパーでは、CNN構造とRNN構造の両方が複素数値演算を処理できる、Deep Complex Convolution Recurrent Network（DCCRN）と呼ばれる複素数値演算をシミュレートする新しいネットワーク構造を設計します。特に、コンボリューションリカレントネットワーク（CRN）は、コンボリューショナルエンコーダーデコーダー（CED）構造と長い短期記憶（LSTM）を統合しており、複雑なターゲットに役立つことが証明されています。了解度と知覚品質の観点から学ぶ。 
[ABSTRACT]畳み込み実ネットワークは、畳み込みニューラルネットワーク（cnn）を使用します。これらの畳み込み実項には、畳み込み部分と長い短期記憶（lstm）が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-01">
        <br><font color="black">2020-08-01</font>
      </time>
    </span>
</section>
<!-- paper0: PIANOTREE VAE: Structured Representation Learning for Polyphonic Music -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.AS/paper_1.html">
      <font color="black">PIANOTREE VAE: Structured Representation Learning for Polyphonic Music</font>
    </a>
  </h2>
  <font color="black">実験は、（i）を介してPianoTree VAEの有効性を証明します。 （ii）-潜在空間で学習されたまともな形状を除いて、より満足できる再構成。 （iii）-下流の音楽生成の多様性に対するこのモデルの利点..音楽表現学習の主要なアプローチには、深い教師なしモデルファミリー変分オートエンコーダ（VAE）が含まれます。主にモノラル音楽に限定されています。 
[ABSTRACT]成功した試みのほとんどはモノラル音楽に限定されています。ただし、これらの試みの多くは解決されていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: StoRIR: Stochastic Room Impulse Response Generation for Audio Data
  Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.AS/paper_2.html">
      <font color="black">StoRIR: Stochastic Room Impulse Response Generation for Audio Data
  Augmentation</font>
    </a>
  </h2>
  <font color="black">StoRIRのPython実装をオンラインで公開しています。この方法は直感的で実装が簡単で、非常に複雑なエンクロージャーのRIRを生成できます。StoRIRを音声強調タスクのオーディオデータ拡張に使用すると、ディープラーニングモデルが幅広いメトリックでより良い結果を達成できることを示します従来の画像ソース方式を使用する場合よりも、多くの画像ソースを5％以上効果的に改善します。 
[ABSTRACT] storirを使用すると、ディープラーニングモデルは、従来のイメージを使用する場合よりも幅広いメトリックでより良い結果を達成できます-ソースメソッド</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Variational Generative Models for Audio-visual Speech Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.AS/paper_3.html">
      <font color="black">Deep Variational Generative Models for Audio-visual Speech Separation</font>
    </a>
  </h2>
  <font color="black">この論文では、各チャンネルに関連付けられた視覚情報（唇の動き）だけでなく、シングルチャネルオーディオの記録が与えられた場合の視聴覚音声分離に関心があります。次に、すべての潜在変数とノイズパラメーターがモンテカルロ期待値によって推定されます。 -最大化アルゴリズム。私たちは、クリーンな音声の視聴覚生成モデリングに基づく教師なし手法を提案します。 
[ABSTRACT]クリーンな音声のオーディオスペクグラムモデリングに基づいた教師なし手法を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Exploiting Fully Convolutional Network and Visualization Techniques on
  Spontaneous Speech for Dementia Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.AS/paper_4.html">
      <font color="black">Exploiting Fully Convolutional Network and Visualization Techniques on
  Spontaneous Speech for Dementia Detection</font>
    </a>
  </h2>
  <font color="black">さらに、畳み込み層を構築して、大津の視覚化方法を使用してヒートマップを作成し、時系列のオーディオセグメントが分類結果に与える影響を理解できるようにします。視覚化手法により、オーディオセグメントなどの影響を評価できます。参加者からの塗りつぶされた一時停止と、分類結果についての調査員からの繰り返しの質問として。次に、データ不足の問題を解決するために、MobileNetアーキテクチャーから事前トレーニング済みのバックボーンたたみ込みニューラルネットワーク（CNN）モデルを採用することにより、転移学習を適用します。およびImageNetデータセット。 
[要約]完全な畳み込みネットワークは、さまざまな次元の音声サンプルに対応します。このシステムにより、手動のセグメンテーションなしで音声サンプルを分析できます。これは、データ不足の問題を理解するためにも使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Do face masks introduce bias in speech technologies? The case of
  automated scoring of speaking proficiency -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.AS/paper_5.html">
      <font color="black">Do face masks introduce bias in speech technologies? The case of
  automated scoring of speaking proficiency</font>
    </a>
  </h2>
  <font color="black">2つのサンプルは、音響測定の範囲全体で異なり、音声パターンにも小さいが有意な違いがあることを発見しました。しかし、これらの違いは、英語能力の人間または自動スコアの違いにはつながりません。バイアスのいくつかの測定2つのグループ間でスコアに違いはありませんでした。 
[ABSTRACT]フェイスカバーリングは、信号と音声パターンの両方の音響特性に影響を与える可能性があります。ただし、わずかな違いは、英語能力の人間または自動スコアの違いにはつながりません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Low-Latency Speech Enhancement with Mobile Audio Streaming
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.AS/paper_6.html">
      <font color="black">Efficient Low-Latency Speech Enhancement with Mobile Audio Streaming
  Networks</font>
    </a>
  </h2>
  <font color="black">MASnetは、レイヤーごとのバッチモードの複雑さに一致する低遅延の増分推論モードで動作できます。MASnetは、同様の完全たたみ込みアーキテクチャと比較して、深さ方向および点方向のたたみ込みを組み込んで、融合積和演算を大幅に削減します。 1秒あたり（FMA / s）、SNRはいくらか低下します。効率的な低レイテンシのスピーチ拡張のためにモバイルオーディオストリーミングネットワーク（MASnet）を提案します。これは、モバイルデバイスや計算能力が他のアプリケーションに特に適しています。制限。 
[ABSTRACT] masnetは線形スケールのスペクトログラムを処理し、連続するノイズフレームを複雑な値の比率マスクに変換します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Mask CTC: Non-Autoregressive End-to-End ASR with CTC and Mask Predict -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.AS/paper_7.html">
      <font color="black">Mask CTC: Non-Autoregressive End-to-End ASR with CTC and Mask Predict</font>
    </a>
  </h2>
  <font color="black">推論中、ターゲットシーケンスは貪欲なCTC出力で初期化され、信頼性の低いトークンはCTC確率に基づいてマスクされます。すべてのコードは公開されます。この作業では、Transformerエンコーダーを使用してMask CTCモデルがトレーニングされます。 -マスク予測とCTCの合同トレーニングを備えたデコーダ。 
[ABSTRACT]モデルは、出力トークン間の条件付き依存関係に基づいています。これらのマスクされた低-信頼性トークンは、高信頼性トークンの条件付けで予測されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-18">
        <br><font color="black">2020-05-18</font>
      </time>
    </span>
</section>
<!-- paper0: Clarity: Machine Learning Challenges to Revolutionise Hearing Device
  Processing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.AS/paper_8.html">
      <font color="black">Clarity: Machine Learning Challenges to Revolutionise Hearing Device
  Processing</font>
    </a>
  </h2>
  <font color="black">課題への関心を登録するには、www.claritychallenge.org。にアクセスしてください。強化の課題は、スピーチ用の補聴器信号処理のための新しい改善されたアプローチを提供します。各ペアは、補聴器処理（「強化&quot;）ともう1つは、音声認識モデリング（&quot;予測 &quot;）に焦点を当てたものです。 
[要旨]強化の課題は、音声用の補聴器信号処理のための新しい改善されたアプローチを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-19">
        <br><font color="black">2020-06-19</font>
      </time>
    </span>
</section>
<!-- paper0: POP909: A Pop-song Dataset for Music Arrangement Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.AS/paper_9.html">
      <font color="black">POP909: A Pop-song Dataset for Music Arrangement Generation</font>
    </a>
  </h2>
  <font color="black">最後に、標準のディープミュージック生成アルゴリズムを使用して、このデータセットでいくつかのベースライン実験を行います。アレンジメントにはいくつかの有望なモデルがありますが、より優れた評価とより実際的な結果を達成するためのより洗練されたデータがありません。さらに、テンポ、ビートの注釈を提供します。 、キー、コード。テンポカーブは手動でラベル付けされ、その他はMIRアルゴリズムによって行われます。 
[ABSTRACT] pop909は、プロのミュージシャンが作成した909の人気曲のピアノアレンジの複数のバージョンを含むデータセットです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Transfer Learning Approaches for Streaming End-to-End Speech Recognition
  System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.AS/paper_10.html">
      <font color="black">Transfer Learning Approaches for Streaming End-to-End Speech Recognition
  System</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、RNN-Tフレームワークの4つの異なるTL手法の比較研究を紹介します。また、50時間から1000時間の範囲のさまざまなトレーニングデータでTLの影響を研究し、少量の言語でのTLの有効性を示します。トレーニングデータ..ランダムに初期化されたRNN-Tモデルに対して、さまざまなTL手法で17％の相対ワードエラー率の低下を示しています。 
[ABSTRACT] tlは、少量の知識によって、リカレントニューラルネットワークトランスデューサー（rnn -t）モデルなどのエンドツーエンド（e2e）asrシステムに適用できます。この調査では、さまざまなtlメソッドで17％の相対ワードエラー率が減少</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Interpretable Representation for Controllable Polyphonic Music
  Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.AS/paper_11.html">
      <font color="black">Learning Interpretable Representation for Controllable Polyphonic Music
  Generation</font>
    </a>
  </h2>
  <font color="black">客観的評価と主観的評価の両方から、私たちの方法が解きほぐしの成功と高品質の制御された音楽生成を実現することがわかります。コンポジションスタイルの転送、テクスチャのバリエーション、伴奏の配置など、幅広いアプリケーションに対応します。 
[ABSTRACT] vaeフレームワークに基づく新しいアーキテクチャは、ポリフォニック音楽の2つの潜在的な要素を学ぶことを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning Based Open Set Acoustic Scene Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.AS/paper_12.html">
      <font color="black">Deep Learning Based Open Set Acoustic Scene Classification</font>
    </a>
  </h2>
  <font color="black">適応C2AEは、所定の実験のより公平な比較を包含し、元の推論手順を簡素化して、実際のシナリオでより適用可能にします。受信者動作特性曲線（AUROC）と音響シーンおよびイベントチャレンジ2019タスク1Cの検出と分類で使用されるデータの$ 66 \％$のオープンセット精度.2つのトレーニングシナリオも分析します：未知のクラスに関する追加の知識なしと別のクラス未知のクラスの例の限られたサブセットが利用可能です。 
[ABSTRACT]ディープネットワーク分類器のソフトマックス出力のテストテストスレッショルドをテストします。これは現在ascで使用されている最も一般的な手法です。2つのトレーニングシナリオも分析します。未知のクラスに関する追加の知識なしと、例の限られたサブセットがある場合未知のクラスから利用可能です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
<!-- paper0: Timbre latent space: exploration and creative aspects -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.AS/paper_13.html">
      <font color="black">Timbre latent space: exploration and creative aspects</font>
    </a>
  </h2>
  <font color="black">次の実験は、2人の作曲家と協力して進められ、ディスクリプターベースの合成のために特別に設計されたインターフェイス（Max / MSP、Pure Data）またはマッピングを使用して、音楽ティンバーの潜在音合成を探求する新しい創造的な方向性を提案します。音色操作の新しい可能性生成ニューラルネットワークで有効になっていますが、その表現の探求と創造的な使用はほとんど残っていません。あるいは、教師なしの寸法が残りの機能を説明しながら、特定のサウンド属性を制御変数として学習できます。 
[ABSTRACT]潜在スペースは音色のプロパティを解きほぐしません。疑いのない音色操作の新しい可能性が有効になります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-04">
        <br><font color="black">2020-08-04</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Task Learning for Interpretable Weakly Labelled Sound Event
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-08-18/eess.AS/paper_14.html">
      <font color="black">Multi-Task Learning for Interpretable Weakly Labelled Sound Event
  Detection</font>
    </a>
  </h2>
  <font color="black">実行された結果とアブレーションスタディは、補助タスクに対するオートエンコーダの有用性を示し、デコーダ部分の出力がオーディオ/ソースのクリーンな時間周波数（TF）表現を提供し、ソース分離にさらに使用できることを確認します。コードは公開された方法..提案された方法論の評価のために、DCASE 2019タスク1音響シーンデータをDCASE 2018タスク2サウンドイベントデータと0、10、20 db SNRでリミックスします。 
[要約]このペーパーは、弱いラベルのオーディオデータから学習するためのマルチタスク学習（mtl）フレームワークを提案します。2つのステップを使用して、分類パフォーマンスを損なうことなく時間レベル情報を保持します。これにより、内部t-f表現が間接的にノイズ除去され、分類が改善されますノイズの多い録音でのパフォーマンス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-17">
        <br><font color="black">2020-08-17</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
