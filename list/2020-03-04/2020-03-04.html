<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-03-04の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Audio-Visual Speech Separation and Dereverberation with a Two-Stage
  Multimodal Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.SD/paper_0.html">
      Audio-Visual Speech Separation and Dereverberation with a Two-Stage
  Multimodal Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2つのモジュールは、最初に個別にトレーニングされ、その後、新しい多目的損失関数に基づく共同トレーニング用に統合されます。実験結果は、提案されたマルチモーダルネットワークが、いくつかの1段階よりも一貫して優れた客観的明瞭度と知覚品質をもたらすことを示していますバックグラウンドノイズ、干渉するスピーチ、部屋の残響は、実際のリスニング環境でターゲットのスピーチを歪めることがよくあります。 
[要旨]提案されたネットワークアーキテクチャは、共同音声分離と残響除去を提案します。背景雑音、干渉音声、部屋の残響からターゲット音声を分離することを目的としています。ネットワークアーキテクチャは、話者数の知識を必要としません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-16">
        <br>2019-09-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-Task Learning Network for Emotion Recognition in Conversation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.SD/paper_1.html">
      Multi-Task Learning Network for Emotion Recognition in Conversation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2つのベンチマークデータセットの実験により、提案されたアーキテクチャがCERに非常に効果的であり、2つのデータセットで最新の結果が得られることが実証されています。会話感情認識（CER）は、自然言語処理（NLP）コミュニティへの関心を高めています..バニラ感情認識とは異なり、効果的な話者に敏感な発話表現は、CERの1つの大きな課題です。 
[要旨]新しいsi si siコーパス-データと呼ばれる-新しいコミュニケーション形式
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The Effect of Silence Feature in Dimensional Speech Emotion Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.SD/paper_2.html">
      The Effect of Silence Feature in Dimensional Speech Emotion Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は、沈黙機能が他の感情の次元よりも覚醒次元に大きく影響することを示しています。反対に、その要素の不適切な選択は同じアーキテクチャを使用することによるパフォーマンスの低下につながります。一連の音響的特徴からの高い統計関数で無音の特徴をグループ化しました。 
[要旨]人間の感情がコンピュータによる自動感情認識に使用できるかどうかは明らかではない
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Uyghur ASR systems with decoders using morpheme-based language
  models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.SD/paper_3.html">
      Improving Uyghur ASR systems with decoders using morpheme-based language
  models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ウイグル語は少数言語であり、自動音声認識（ASR）の研究のためのリソースは常に不十分です。MLDGデコーダーは、メモリ消費を合理的に維持しながら、WERを14.54％に減らします。現在、THUYG-20は唯一のオープンソースですウイグル語スピーチのデータセット。 
[要約]静的で完全に構成されたデコーダーに基づくデコードにより、状態-クリーンでノイズのないスピーチテストタスクの最新のワードエラー率が20〜14に減少します。24％デコードにより、最新のワードが減少しますクリーンでノイズのない音声テストのエラー率（wer）。結果は、デコードの14.6％が最新のエラー率を低下させることを示しています。たとえば、詳細についてはここをクリックしてください。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An Open-set Recognition and Few-Shot Learning Dataset for Audio Event
  Classification in Domestic Environments -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.SD/paper_4.html">
      An Open-set Recognition and Few-Shot Learning Dataset for Audio Event
  Classification in Domestic Environments
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      オーディオ領域では、音楽詐欺や話者認識はFSLメソッドから明らかに恩恵を受けることができます。従来のディープラーニング（DL）アルゴリズムは、通常、大規模なデータセットでトレーニングすると非常に良いパフォーマンスを示すことが広く知られています。さまざまなサウンドクラスに対応する多くのイベントが行われます。 
[ABSTRACT] fslは小さなデータセットを使用して、特定の意図的なイベントを検出します。これらには、ドアベル、火災警報器、ドアベルが含まれます。これらの音は、オープンセット認識（osr）問題と見なすことができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-26">
        <br>2020-02-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SELD-TCN: Sound Event Localization & Detection via Temporal
  Convolutional Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.SD/paper_5.html">
      SELD-TCN: Sound Event Localization & Detection via Temporal
  Convolutional Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、時間たたみ込みネットワーク（TCN）に基づいて、より堅牢でハードウェアに優しい新しいアーキテクチャを開発します。さらに、SELD-TCNは、エポックあたり4倍のトレーニング時間と、通常のグラフィック処理装置（GPU）で40倍の推論時間を実現します。 
[概要]提案されたフレームワーク（seld-tcn）は、4つの異なるデータセットで最先端のseldnetパフォーマンスよりも優れています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Augmentation Methods on Monophonic Audio for Instrument Classification
  in Polyphonic Music -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.SD/paper_6.html">
      Augmentation Methods on Monophonic Audio for Instrument Classification
  in Polyphonic Music
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本論文では、純粋にモノフォニックなデータからポリフォニック音楽の楽器を分類する方法を提案します。これは、異なるオーディオセグメントを混合することによりデータ増強を実行することを含みます。データセット..非拡張、ピッチ同期、テンポ同期、およびジャンル類似の抜粋でそれぞれトレーニングされたVGGのような分類子のアンサンブルは、最良の結果をもたらし、ラベルランキングの平均精度に関して80％をわずかに上回っています（ LRAP）2300以上のテストトラックのIRMASテストset.rumentsで。 
[要約]データ増強技術は、異なる音の側面に焦点を当てています。これらには、同じジャンルのオーディオセグメントのオーバーレイが含まれます。データ増強には、同じ音楽のオーバーレイも含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-28">
        <br>2019-11-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Pathological speech detection using x-vector embeddings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.SD/paper_7.html">
      Pathological speech detection using x-vector embeddings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、後者に焦点を当て、パーキンソン病（PD）および閉塞性睡眠時無呼吸（OSA）の検出への一般的な特徴抽出方法としての適用性を評価します。知識ベースの機能およびi-また、OSAとPDの2つのヨーロッパポルトガル語コーパス、およびPDの追加のスペイン語コーパスの結果を報告します。さらに、xベクトルは、一致した条件でiベクトルと同様に動作しますが、ドメインの場合、 -ミスマッチが発生します。 
[ABSTRACT]研究者は、症状を本質的にモデル化する一般的な話者表現の方向に移動します。彼らは、2つのヨーロッパポルトガル語コーパス、osaおよびpd、およびpdの追加のスペイン語コーパスの結果を報告します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-02">
        <br>2020-03-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Mixup-breakdown: a consistency training method for improving
  generalization of speech separation models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.SD/paper_8.html">
      Mixup-breakdown: a consistency training method for improving
  generalization of speech separation models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ラベルのない入力を「分解」する教師モデルを学習し、推定分離を補間して、より有用な疑似「ミックスアップ」入力-出力ペアを生成します。これにより、一貫性の正規化が学生モデルの学習に適用できます。目に見えない干渉する音声、ノイズ、音楽など、不一致の昇順でさまざまな条件下でMBTを評価し、MBTの一般化機能を最先端の教師付き学習およびSSLアプローチと比較します。結果は、MBTがいくつかの強力なSI-SNRiの相対的な改善が最大13.77％のベースライン。 
[ABSTRACT] mixup-ブレークダウントレーニング（mbt）は一貫性の間に合わせのモデルです。これらのタイプの音声、ノイズ、音楽は分離できます。しかし、mbtは標準のトレーニングスキームに無視できる計算オーバーヘッドのみを追加します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-28">
        <br>2019-10-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Interpretable Representation Learning for Singing Voice
  Separation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.SD/paper_9.html">
      Unsupervised Interpretable Representation Learning for Singing Voice
  Separation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの発見は、私たちの方法が歌の声の分離のための意味のある表現を学習できることを示唆している一方、オーディオと音楽ソースの分離..本手法の利点を実証するために、バイナリマスキングによる情報に基づいた歌声の分離のタスクに取得した表現を使用し、スケール不変の信号対歪み比を使用して取得した分離品質を測定します。教師なしの目的を使用して訓練することができ、歌声を再構築するためのデコード関数として単純な正弦波モデルを使用するノイズ除去オートエンコーダモデルに依存します。 
[要約]教師なし目的を使用してメソッドをトレーニングできます。これは、単純な正弦波モデルを使用して歌声を再構築するノイズ除去自動エンコーダモデルに依存しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Controllable Time-Delay Transformer for Real-Time Punctuation Prediction
  and Disfluency Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.SD/paper_10.html">
      Controllable Time-Delay Transformer for Real-Time Punctuation Prediction
  and Disfluency Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      IWSLT2011ベンチマークデータセットと社内の注釈付きデータセットの実験結果は、提案されたアプローチがFスコアの以前の最先端モデルよりも優れており、競合の推論速度を達成することを示しています。競合するパフォーマンスを維持しながらレイテンシを最小限に抑える。近年の自動音声認識（ASR）のアプリケーションの増加に伴い、トランスクリプトの読みやすさとパフォーマンスを向上させるために、句読点を自動的に挿入し、トランスクリプトの不均衡を除去することが不可欠です機械翻訳、対話システムなどの後続のアプリケーションの。 
[要約]制御可能な時間遅延トランスフォーマー（ct-トランスフォーマー）モデルがあり、リアルタイムで句読点予測と流dis性検出タスクを共同で完了します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Benchmark Performance of Machine And Deep Learning Based Methodologies
  for Urdu Text Document Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_0.html">
      Benchmark Performance of Machine And Deep Learning Based Methodologies
  for Urdu Text Document Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ソースコードと提示されたデータセットはGithubリポジトリで入手できます。ウルドゥー語のテキストドキュメント分類のベンチマークパフォーマンスを提供するために、このペーパーの貢献は多岐にわたります。4番目に、双方向学習を使用した転送学習のパフォーマンスへの影響も調査しますウルドゥー語のトランスフォーマーアプローチからのエンコーダー表現。 
[ABSTRACT]最初に、公に利用可能なパフォーマンスベンチマークデータセットを提供します。2番目に、ウルドゥー語のテキストドキュメント分類のためのさまざまな深層学習ベースのメソッドのパフォーマンスを初めて評価します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-Task Learning Network for Emotion Recognition in Conversation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_1.html">
      Multi-Task Learning Network for Emotion Recognition in Conversation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2つのベンチマークデータセットの実験により、提案されたアーキテクチャがCERに非常に効果的であり、2つのデータセットで新しい最先端の結果が得られることが実証されています。 ..この論文では、会話の発話表現を強化するための補助的なタスクとして話者識別（SI）を活用します。 
[要旨]新しいsi si siコーパス-データと呼ばれる-新しいコミュニケーション形式
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Using Interlinear Glosses as Pivot in Low-Resource Multilingual Machine
  Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_2.html">
      Using Interlinear Glosses as Pivot in Low-Resource Multilingual Machine
  Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      そのため、NMTのピボットまたはインターリンガとして機能します。すべてのグロステキストにグロスソース言語タグをタグ付けする多言語NMTモデルを導入し、1,497言語で共通の注意を払ってユニバーサルシステムをトレーニングします。英語の補題および形態素ラベルのシーケンスとしての英語の文。 
[要約] igtは、英語の補題と形態素ラベルのシーケンスとして非英語の文を表します。私たちは、1,497の言語に共通の注意を払って普遍的なシステムを訓練します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-07">
        <br>2019-11-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Understanding the Prediction Mechanism of Sentiments by XAI
  Visualization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_3.html">
      Understanding the Prediction Mechanism of Sentiments by XAI
  Visualization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの予測の詳細は、4つの主要機能のwhat-if分析によって裏付けられました。研究1では、抽出された感情を機能として使用して、5つの機械学習アルゴリズム（knn 、CART決定木、サポートベクターマシン、ランダムフォレスト、勾配ブースティングマシン）、ランダムフォレストを最適なアルゴリズムとして特定しました。 
[要旨]本研究は、機械学習モデルの予測メカニズムを理解することを目的としています。この研究では、説明可能なai（xai）メソッドを使用して抽出されたレビューの効果を調べました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Robust Self-Learning Method for Fully Unsupervised Cross-Lingual
  Mappings of Word Embeddings: Making the Method Robustly Reproducible as Well -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_4.html">
      A Robust Self-Learning Method for Fully Unsupervised Cross-Lingual
  Mappings of Word Embeddings: Making the Method Robustly Reproducible as Well
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、完全に再現可能な研究を提供するために、任意の研究プロジェクトに適用できる重要な推奨事項を提案します。モデルの安定性を評価するために、実用的なハイパーパラメーターを介したグリッド検索も実施します。元の論文で提案されているものよりも英語に似ていない4つの新しい言語。 
[要旨]オリジナルの論文で提案されたものよりも英語にあまり似ていない4つの新しい言語を導入することにより、モデルの堅牢性をさらに調査します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-03">
        <br>2019-12-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The STEM-ECR Dataset: Grounding Scientific Entity References in STEM
  Scholarly Content to Authoritative Encyclopedic and Lexicographic Sources -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_5.html">
      The STEM-ECR Dataset: Grounding Scientific Entity References in STEM
  Scholarly Content to Authoritative Encyclopedic and Lexicographic Sources
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このような学際的なコーパスの作成について説明し、得られた結果を次の特徴の観点から強調します。1）学際的な科学的文脈における科学的実体の一般的な概念形式。 2）そのような一般的形式主義の下での科学的実体のドメインに依存しない人間の注釈の実現可能性。 3）BERTベースのニューラルモデルを使用した学際的な科学的エンティティの自動抽出で取得可能なパフォーマンスベンチマーク。 4）百科事典エンティティのリンクと辞書式単語の意味の曖昧性解消を介した科学エンティティの人間による注釈付けのための詳細な3段階のエンティティ解決手順。 5）Babelfyの人間評価により、私たちのエンティティの百科事典リンクと辞書編集の感覚が返されました。ScientificEntity Extraction、Classification、and Resolution、Version 1.0（STEM-ECR v1 .0）..私たちの調査結果は、STEMとしての幅広い設定での人間の注釈と学際的な科学的概念の自動学習、およびそれらの意味的曖昧性解消が累積的に示されています。 
[概要]ステム-ecr v1。 0データセットは、科学エンティティの評価のベンチマークを提供するために開発されました。自動v1のパフォーマンスベンチマーク取得機能を提供します。調査結果には、学際的な科学的文脈における科学エンティティの一般的な概念形式が含まれます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-02">
        <br>2020-03-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: XGPT: Cross-modal Generative Pre-Training for Image Captioning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_6.html">
      XGPT: Cross-modal Generative Pre-Training for Image Captioning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験により、XGPTは、COCOキャプションやFlickr30kキャプションなどのベンチマークデータセットで最新の結果を取得することが示されています。その結果、事前にトレーニングされたXGPTは、タスク固有のアーキテクチャを変更することなく微調整できます画像キャプションの最新モデル。XGPTを使用して、画像検索タスクのデータ増強として新しい画像キャプションを生成し、すべてのリコールメトリックを大幅に改善します。 
[ABSTRACT] xgptは、3つの新しい生成タスクを介してテキスト-リーダージェネレーターを事前にトレーニングするように設計された、イメージキャプションのクロスモーダル属の事前トレーニングの新しい方法です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-View Learning for Vision-and-Language Navigation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_7.html">
      Multi-View Learning for Vision-and-Language Navigation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、LEOはビジョンおよび言語ナビゲーションの既存のほとんどのモデルを補完するものであり、既存の技術と簡単に統合できるため、LEO +につながり、R2Rベンチマークが62％（9％絶対）改善）..最近のRoom-to-Room（R2R）ベンチマークデータセットでは、LEOは、パスで重み付けされた成功率のベースエージェント（25.3％$ \ rightarrow $ 41.4％）として、貪欲なエージェントに対して16％の改善（絶対）を達成します。長さ（SPL）..命令間でパラメータを共有することにより、当社のアプローチは限られたトレーニングデータからより効果的に学習し、見えない環境でより一般化します。 
[概要]新しい論文では、全員から学ぶ新しいトレーニングツール（leo）を紹介します。leoは、ベースエージェントとしてのタスクに対して16％の改善を達成しました。leoは、言語の曖昧さを解決するために同じ軌道に複数の命令を使用します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-02">
        <br>2020-03-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Uyghur ASR systems with decoders using morpheme-based language
  models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_8.html">
      Improving Uyghur ASR systems with decoders using morpheme-based language
  models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ウイグル語は少数言語であり、自動音声認識（ASR）の研究のためのリソースは常に不十分です。MLDGデコーダーは、メモリ消費を合理的に維持しながら、WERを14.54％に減らします。現在、THUYG-20は唯一のオープンソースですウイグル語スピーチのデータセット。 
[要約]静的で完全に構成されたデコーダーに基づくデコードにより、状態-クリーンでノイズのないスピーチテストタスクの最新のワードエラー率が20〜14に減少します。24％デコードにより、最新のワードが減少しますクリーンでノイズのない音声テストのエラー率（wer）。結果は、デコードの14.6％が最新のエラー率を低下させることを示しています。たとえば、詳細についてはここをクリックしてください。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Candidate Generation for Low-resource Cross-lingual Entity
  Linking -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_9.html">
      Improving Candidate Generation for Low-resource Cross-lingual Entity
  Linking
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、まず、低リソースXELの現在のエンティティ候補生成方法が直面する問題を評価し、（1）エンティティの言及とKBエントリ間の接続を削減し、（2）モデルの堅牢性を改善する3つの改善を提案します改善されたモデルでは、エンドツーエンドXELのKB単位の精度が平均で7.9％向上します。最近、転送学習方法がLRLのリソースの需要を減らすことが示されました。密接に関連する言語でリソースを使用しますが、パフォーマンスはリソースの高い言語に比べてまだかなり遅れています。 
[概要]（x）elの最初のステップは候補生成です。ターゲット候補から妥当な候補エンティティのリストを取得します-言語kb。これには、転送学習法を使用してリソースの需要を減らすことが含まれます。高-見つけるタスク
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Abstractive Document Summarization without Parallel Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_10.html">
      Abstractive Document Summarization without Parallel Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CNN / DailyMailベンチマークでは、アプローチを完全に監視されたベースラインと比較し、科学ジャーナルの記事からプレスリリースを自動的に生成するという新しいタスクに適しています。私たちのシステムのために。記事と要約のペアに依存することなく、両方のタスクで有望なパフォーマンスを示します。サンプルの要約と一致しない記事の大規模なコレクションのみに依存する抽象要約システムを開発します。 
[ABSTRACT]両方のタスクで使用できる並列データがたくさんあります。しかし、実際に使用するという事実など、多くのエラーがあります。記事に依存せずに有望なパフォーマンスを示しています-合計
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-30">
        <br>2019-07-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Meta-Embeddings Based On Self-Attention -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_11.html">
      Meta-Embeddings Based On Self-Attention
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、我々のモデルは、より良い結果を達成するという点だけでなく、WMT 2014英語からフランス語への翻訳タスクなどの認識されたベンチマークでの収束が速いという点で、Transformerよりも優れていることが判明しました。 Duoメカニズムは、20NGなどのテキスト分類タスクで最先端の精度を実現します。言語モデリングのパフォーマンスを向上させるためのメタ埋め込みの作成が最近注目されており、連結に基づく方法または単に算術平均を計算する方法メタ埋め込みを実行するために個別にトレーニングされた複数の埋め込みが有益であることが示されています。 
[概要]フランスの論文では、機械翻訳の新しいモデルが提案されています。これは、単語の埋め込み以上の最初の機械翻訳モデルです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CLUECorpus2020: A Large-scale Chinese Corpus for Pre-trainingLanguage
  Model -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_12.html">
      CLUECorpus2020: A Large-scale Chinese Corpus for Pre-trainingLanguage
  Model
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      前者は最先端の結果を達成し、後者はBert-baseに比べてトレーニングと予測速度を8倍高速化しながら、最高の精度を維持します。また、トレーニング済みモデルの大小両方のバージョンをこのコーパス..計算コストとメモリを節約しながら、元の語彙と同じように機能します。 
[概要] 8kのサイズの新しい中国語の語彙をリリースします。これは、Googleがリリースした中国語のbertで使用される語彙サイズのわずか3分の1です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Hybrid Approach Towards Two Stage Bengali Question Classification
  Utilizing Smart Data Balancing Technique -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_13.html">
      A Hybrid Approach Towards Two Stage Bengali Question Classification
  Utilizing Smart Data Balancing Technique
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      各粗クラスについて、その粗クラス内のより細かいクラスを区別するために、個別の確率的勾配降下（SGD）ベースの分類子が使用されています。質問コーパスの既存の単語のWord2vec表現が構築され、1D CNNを支援します.. 1次元畳み込みニューラルネットワークを使用して、最初の段階で質問を粗いクラスに分類します。 
[ABSTRACT]質問分類（qc）システムは、質問回答（qa）システムが質問に対して正しい回答を提供できるように、特定のクラスの質問を分類します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-30">
        <br>2019-11-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multilingual Twitter Corpus and Baselines for Evaluating Demographic
  Bias in Hate Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_14.html">
      Multilingual Twitter Corpus and Baselines for Evaluating Demographic
  Bias in Hate Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      推測された人口統計ラベルをクラウドソーシングプラットフォーム、図8で評価します。4つの一般的なドキュメント分類子のパフォーマンスを測定し、著者レベルの人口統計属性に対するベースライン分類子の公平性とバイアスを評価します。 、イタリア語、ポーランド語、ポルトガル語、スペイン語。 
[概要]悪意のある音声の検出タスク用の多言語twitterコーパスを作成して公開します。4つの著者の人口統計学的要因：年齢、国、性別、人種
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-24">
        <br>2020-02-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On the Robustness of Unsupervised and Semi-supervised Cross-lingual Word
  Embedding Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_15.html">
      On the Robustness of Unsupervised and Semi-supervised Cross-lingual Word
  Embedding Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      しかし、評価のための特定の制御されたシナリオに焦点が当てられており、現在の最先端システムがノイズの多いテキストや言語の大きな違いがある言語にどのように対応するかについての強力な証拠はありません。本書では、ターゲット言語などのさまざまな変数に関する長所と限界を分析し、複数の言語間埋め込みモデルに対する広範な評価を提示します。 、コーパスのトレーニングと監督の量。 
[概要]クロスリンガル埋め込みは、ターゲット言語、コーパスのトレーニング、監督の量など、さまざまな異なる変数に基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-21">
        <br>2019-08-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transfer Learning for Context-Aware Spoken Language Understanding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_16.html">
      Transfer Learning for Context-Aware Spoken Language Understanding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      音声言語理解（SLU）は、タスク指向の対話システムの重要なコンポーネントです。データ収集と注釈への依存を減らすために、さまざまな転送学習アプローチを検討します。SLUは、自然言語ユーザーの発話をセマンティックフレームに解析します。 
[概要]ターゲットドメインの大規模な人間のラベル付きマルチターンダイアログコーパスは複雑でコストがかかります。このプロジェクトは、依存関係のデータの収集と注釈を減らすことを目的としています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Plug and Play Language Models: A Simple Approach to Controlled Text
  Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_17.html">
      Plug and Play Language Models: A Simple Approach to Controlled Text
  Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提示する標準的なシナリオでは、属性モデルは、ユーザーが指定した単語の袋またはLMよりも100,000倍少ないパラメーターを持つ単一の学習レイヤーで構成される単純な分類子です。PPLMは、微分可能な属性モデルの任意の組み合わせが可能であるという点で柔軟性がありますモデルのサンプルは、さまざまなトピックと感情スタイルの制御を示し、自動化された人間による注釈付きの広範な評価は、属性の整合性と流さを示します。 
[概要]プラグアンドプレイ言語モデル（pplm）は、事前学習済みのlmと、それ以上のlmのトレーニングなしでテキスト生成をガイドする1つ以上の単純な属性分類子を組み合わせます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-04">
        <br>2019-12-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Pathological speech detection using x-vector embeddings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_18.html">
      Pathological speech detection using x-vector embeddings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、後者に焦点を当て、パーキンソン病（PD）および閉塞性睡眠時無呼吸（OSA）の検出に対する一般的な特徴抽出方法としての適用性を評価します。知識ベースの特徴およびi- OSAとPDの2つのヨーロッパポルトガル語コーパス、およびPDの追加のスペイン語コーパスの結果を報告します。xベクトルモデルとiベクトルモデルの両方が、ドメイン外のヨーロッパポルトガル語コーパスでトレーニングされました。 
[ABSTRACT]研究者は、症状を本質的にモデル化する一般的な話者表現の方向に移動します。彼らは、2つのヨーロッパポルトガル語コーパス、osaおよびpd、およびpdの追加のスペイン語コーパスの結果を報告します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-02">
        <br>2020-03-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Seshat: A tool for managing and verifying annotation campaigns of audio
  data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_19.html">
      Seshat: A tool for managing and verifying annotation campaigns of audio
  data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、パーソナライズされたパーサーに実装されている特定のルールに従って注釈の内容をチェックする手順が含まれます。最後に、Seshatが$ \ gamma $メジャーと関連付けられた注釈者間合意を自動的に計算する二重注釈モードを提案しますカテゴリ化とセグメンテーションの不一致を考慮に入れます。音声コーパスの注釈を効率的に管理するための新しいシンプルでオープンソースのソフトウェアであるSeshatを紹介します。 
[要約] seshatソフトウェアにより、ユーザーは大規模な音声コーポレーションの注釈を簡単に開いて管理できます。さらに、二重注釈コンテンツを提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-Dimensional Explanation of Ratings from Reviews -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_20.html">
      Multi-Dimensional Explanation of Ratings from Reviews
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本研究では、教師なしで、解釈可能であり、多面的感情評価を予測する確率的多次元マスクを生成するニューラルモデルを提案します。 、予測を行うのに十分です。マルチタスク学習を使用すると、解釈可能性とF1スコアの両方がどのように改善されるかを示します。 
[ABSTRACT]マルチ可視学習を使用すると、プロの解釈可能性とf1スコアの両方がどのように改善されるかを示します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-25">
        <br>2019-09-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: GoodNewsEveryone: A Corpus of News Headlines Annotated with Emotions,
  Semantic Roles, and Reader Perception -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_21.html">
      GoodNewsEveryone: A Corpus of News Headlines Annotated with Emotions,
  Semantic Roles, and Reader Perception
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちがリリースするコーパスは、感情分類、感情強度予測、感情原因検出に関するさらなる研究を可能にし、さらなる定性的研究をサポートします。最後に、セマンティックロール構造の自動予測タスクのベースラインを開発し、結果を議論します。最初に感情的な内容を持つ関連するインスタンスを見つけてから、よりきめ細かい側面に注釈を付けるマルチフェーズ注釈手順を提案します。 
[ABSTRACT]少数の作品は、構造化された学習で取り組むべき現象として感情に取り組んでいます。データセットの不足は、datacing.finallyの不足によって説明できます。自動ターゲットのタスクのベースラインを開発します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-06">
        <br>2019-12-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Controllable Time-Delay Transformer for Real-Time Punctuation Prediction
  and Disfluency Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_22.html">
      Controllable Time-Delay Transformer for Real-Time Punctuation Prediction
  and Disfluency Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      IWSLT2011ベンチマークデータセットと社内の注釈付きデータセットの実験結果は、提案されたアプローチがFスコアの以前の最先端モデルよりも優れており、競合の推論速度を達成することを示しています。句読点予測と不明瞭性検出タスクをリアルタイムで共同で完了する制御可能な時間遅延トランスフォーマー（CT-Transformer）モデル。さらに、競争力のあるパフォーマンスを維持しながらレイテンシーを最小限に抑える高速デコード戦略を提案します。 
[要約]制御可能な時間遅延トランスフォーマー（ct-トランスフォーマー）モデルがあり、リアルタイムで句読点予測と流dis性検出タスクを共同で完了します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Med7: a transferable clinical natural language processing model for
  electronic health records -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_23.html">
      Med7: a transferable clinical natural language processing model for
  electronic health records
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、米国の集中治療室から英国の二次医療メンタルヘルス記録（CRIS）へのデータを使用して、開発したモデルの転送可能性を評価しました。これは、データセットとNERタスクの密接な類似性にもかかわらず、 、より正確な結果を得るには、ターゲットドメインデータを微調整することが不可欠です。この作業では、臨床自然言語処理のための名前付きエンティティ認識モデルを導入しました。 
[概要]モデルは、7つのカテゴリを認識するようにトレーニングされています：薬剤名、ルート、頻度、投与量、強度、形態、期間
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Hybrid Generative-Retrieval Transformers for Dialogue Domain Adaptation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_24.html">
      Hybrid Generative-Retrieval Transformers for Dialogue Domain Adaptation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、実際のシナリオでは、このようなリソースはすべての新しいドメインで使用できるわけではないため、いくつかの対話例を使用してトレーニングする能力が不可欠であると考えることができます。 DSTC8のタスク、マルチドメインMetaLWOzデータセットに微調整されたGPT-2に基づくハイブリッド生成-検索モデル。ドメイン適応は、対話システムの研究における最近の重要な問題になりました。 
[要約]ディープラーニングは、少数ショット問題の標準的な方法になりました。さらに、生成では、モデルはフォールバックとして検索ロジックを使用します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploring BERT Parameter Efficiency on the Stanford Question Answering
  Dataset v2.0 -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_25.html">
      Exploring BERT Parameter Efficiency on the Stanford Question Answering
  Dataset v2.0
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このホワイトペーパーでは、Stanford Question Answeringデータセット（SQuAD2.0）のバージョン2.0でのBERT arXiv：1810.04805のパラメーター効率を調査します。 ：1709.08294v3、SQuAD2.0タスクの最終増強レイヤーとして。これらのモデルは、arXiv：1907.10597で提案されている浮動小数点演算の効率に基づいて評価していませんが、トレーニング時間、推論時間、モデルパラメータの総数。 
[ABSTRACT] arxivのテスト基準に対する一連の劇的な変更を確認します。異なる数の最終トランス層を凍結しながら、bertの対数効率を評価します。arxiv：1902で提案されたアダプター層も確認します。 00751
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-25">
        <br>2020-02-25
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Hierarchical Context Enhanced Multi-Domain Dialogue System for
  Multi-domain Task Completion -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/cs.CL/paper_26.html">
      Hierarchical Context Enhanced Multi-Domain Dialogue System for
  Multi-domain Task Completion
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      リーダーボードにリストされている結果は、システムが自動評価で1位、人間評価で2位になっていることを示しています。DSTC8-track1チャレンジのタスク1は、複雑なマルチドメイン対話システムの開発を目的としていますより具体的には、BERTを適用してトークンレベルの情報を取得し、アテンションメカニズムを使用して文レベルの情報を取得します。 
[概要]課題は、システム構築のタスクに対して提出された目標に基づいています。目標は、人間の対話システムの自動評価を作成することです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Audio-Visual Speech Separation and Dereverberation with a Two-Stage
  Multimodal Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/eess.AS/paper_0.html">
      Audio-Visual Speech Separation and Dereverberation with a Two-Stage
  Multimodal Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2つのモジュールは、最初に個別にトレーニングされ、その後、新しい多目的損失関数に基づく共同トレーニング用に統合されます。バックグラウンドノイズ、干渉音声、部屋の残響は、実際のリスニング環境でターゲット音声を頻繁に歪めます。提案されたマルチモーダルネットワークは、いくつかの1段階および2段階のベースラインよりも一貫して優れた客観的明瞭度と知覚品質をもたらします。 
[要旨]提案されたネットワークアーキテクチャは、共同音声分離と残響除去を提案します。背景雑音、干渉音声、部屋の残響からターゲット音声を分離することを目的としています。ネットワークアーキテクチャは、話者数の知識を必要としません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-16">
        <br>2019-09-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The Effect of Silence Feature in Dimensional Speech Emotion Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/eess.AS/paper_1.html">
      The Effect of Silence Feature in Dimensional Speech Emotion Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      反対に、その要素の不適切な選択は、同じアーキテクチャを使用することでパフォーマンスの低下につながります。沈黙は、人間と人間のコミュニケーションの一部であり、人間の感情知覚の手がかりになる可能性があります。沈黙機能は、他の感情の次元よりも覚醒の次元に大きく影響します。 
[要旨]人間の感情がコンピュータによる自動感情認識に使用できるかどうかは明らかではない
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving Uyghur ASR systems with decoders using morpheme-based language
  models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/eess.AS/paper_2.html">
      Improving Uyghur ASR systems with decoders using morpheme-based language
  models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ウイグル語は少数言語であり、自動音声認識（ASR）の研究のためのリソースは常に不十分です。MLDGデコーダーは、メモリ消費を合理的に維持しながら、WERを14.54％に削減します。最初のリリース以降、クリーンでノイズのない音声テストタスクは更新されておらず、メインストリーム言語とウイグル語の間のASRの開発に大きなギャップがあることを示しています。このホワイトペーパーでは、ASRシステムを最終的に最適化することでギャップを埋めようとしています。形態素ベースのデコーダMLDG-Decoder（Mypheme Lattice Dynamically Generate Decoder for Uyghur DNN-HMM systems）を開発しました。 
[要約]静的で完全に構成されたデコーダーに基づくデコードにより、状態-クリーンでノイズのないスピーチテストタスクの最新のワードエラー率が20〜14に減少します。24％デコードにより、最新のワードが減少しますクリーンでノイズのない音声テストのエラー率（wer）。結果は、デコードの14.6％が最新のエラー率を低下させることを示しています。たとえば、詳細についてはここをクリックしてください。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An Open-set Recognition and Few-Shot Learning Dataset for Audio Event
  Classification in Domestic Environments -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/eess.AS/paper_3.html">
      An Open-set Recognition and Few-Shot Learning Dataset for Audio Event
  Classification in Domestic Environments
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      オーディオ領域では、音楽詐欺または話者認識はFSL方式から明らかに恩恵を受けることができます。したがって、実際のシナリオでこのようなアラームを検出することは、オープンセット認識（OSR）問題と考えることができます。限られた数のサンプルを使用して、ドアベルや火災警報器などの異なるタイプの音響警報器によって与えられる特定の意図的な音響イベントの検出へのFSLの適用。 
[ABSTRACT] fslは小さなデータセットを使用して、特定の意図的なイベントを検出します。これらには、ドアベル、火災警報器、ドアベルが含まれます。これらの音は、オープンセット認識（osr）問題と見なすことができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-26">
        <br>2020-02-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SELD-TCN: Sound Event Localization & Detection via Temporal
  Convolutional Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/eess.AS/paper_4.html">
      SELD-TCN: Sound Event Localization & Detection via Temporal
  Convolutional Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、時間畳み込みネットワーク（TCN）に基づいた、より堅牢でハードウェアに優しい新しいアーキテクチャを開発します。 GPU）..ただし、CRNNの再発性を考慮すると、CRNNを組み込みハードウェアに効率的に実装することは困難になります。 
[概要]提案されたフレームワーク（seld-tcn）は、4つの異なるデータセットで最先端のseldnetパフォーマンスよりも優れています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Augmentation Methods on Monophonic Audio for Instrument Classification
  in Polyphonic Music -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/eess.AS/paper_5.html">
      Augmentation Methods on Monophonic Audio for Instrument Classification
  in Polyphonic Music
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、それぞれが単一の増強されたデータセットで訓練された上記の分類器の組み合わせの使用を調査します。本論文では、純粋にモノフォニックなデータからのポリフォニック音楽における楽器分類のアプローチを提案します。セグメント..しかし、その大部分はモノフォニック音楽を扱っていますが、ポリフォニック素材の取り組みは主に主要な楽器認識に焦点を当てています。 
[要約]データ増強技術は、異なる音の側面に焦点を当てています。これらには、同じジャンルのオーディオセグメントのオーバーレイが含まれます。データ増強には、同じ音楽のオーバーレイも含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-28">
        <br>2019-11-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Pathological speech detection using x-vector embeddings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/eess.AS/paper_6.html">
      Pathological speech detection using x-vector embeddings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      知識ベースの機能とi-vectorに対してアプローチをテストし、OSAとPDの2つのヨーロッパポルトガル語コーパスの結果と、PDの追加のスペイン語コーパスの結果を報告します。 -一致した条件のベクトルは、ドメインの不一致が発生した場合に大幅に優れています。この作業では、後者に焦点を当て、パーキンソン病（PD）および閉塞性睡眠時無呼吸の検出への一般的な特徴抽出方法としての適用性を評価します（OSA）。 
[ABSTRACT]研究者は、症状を本質的にモデル化する一般的な話者表現の方向に移動します。彼らは、2つのヨーロッパポルトガル語コーパス、osaおよびpd、およびpdの追加のスペイン語コーパスの結果を報告します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-02">
        <br>2020-03-02
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Mixup-breakdown: a consistency training method for improving
  generalization of speech separation models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/eess.AS/paper_7.html">
      Mixup-breakdown: a consistency training method for improving
  generalization of speech separation models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この問題に対処するために、Mixup-Breakdownトレーニング（MBT）である、実装しやすいが効果的な一貫性ベースの半教師付き学習（SSL）アプローチを提案します。結果は、MBTが最大13.77相対SI-SNRiの改善率。ラベルなしの入力を「分解」する教師モデルを学習し、推定された分離を補間して、より有用な疑似「ミックスアップ」入出力ペアを生成します。モデル。 
[ABSTRACT] mixup-ブレークダウントレーニング（mbt）は一貫性の間に合わせのモデルです。これらのタイプの音声、ノイズ、音楽は分離できます。しかし、mbtは標準のトレーニングスキームに無視できる計算オーバーヘッドのみを追加します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-28">
        <br>2019-10-28
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Interpretable Representation Learning for Singing Voice
  Separation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/eess.AS/paper_8.html">
      Unsupervised Interpretable Representation Learning for Singing Voice
  Separation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの方法の利点を実証するために、バイナリマスキングによる情報に基づいた歌声分離のタスクに取得した表現を使用し、スケール不変の信号対歪み比によって取得した分離品質を測定します。波形信号から直接解釈可能な音楽信号表現を学習する方法。我々の発見は、非負性、滑らかさ、再構成などの短時間フーリエ変換の利便性を維持しながら、音声分離の意味のある表現を学習できることを示唆しています。オーディオと音楽ソースの分離に必要な時間周波数マスキングの対象となります。 
[要約]教師なし目的を使用してメソッドをトレーニングできます。これは、単純な正弦波モデルを使用して歌声を再構築するノイズ除去自動エンコーダモデルに依存しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: p38delta genetic ablation protects female mice from anthracycline cardiotoxicity -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/biorxiv.physiology/paper_0.html">
      p38delta genetic ablation protects female mice from anthracycline cardiotoxicity
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      
[要旨] doxは、p38 mapksを含む細胞内ストレスシグナル伝達経路の活性化に関連しています。これらのdoxは、抗うつ薬とp38delta遺伝子欠失の組み合わせと関連しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Endothelial cell response to Hedgehog ligands depends on their processing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/biorxiv.physiology/paper_1.html">
      Endothelial cell response to Hedgehog ligands depends on their processing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      
[要旨]異所的に投与されたn末端ソニックハリネズミ（n-shh）と内生砂漠ハリネズミ（dhh）が内皮細胞に逆の効果を誘発することを示すのは今年が初めてです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Innate immune signaling in Drosophila shifts anabolic lipid metabolism from triglyceride storage to phospholipid synthesis in an ER stress dependent manner. -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/biorxiv.physiology/paper_2.html">
      Innate immune signaling in Drosophila shifts anabolic lipid metabolism from triglyceride storage to phospholipid synthesis in an ER stress dependent manner.
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      対照的に、リン脂質とその生成物であるホスファチジルコリンとホスファチジルエタノールアミンを合成するケネディ経路酵素は、Tollシグナル伝達が活発な脂肪体に誘導されます。これはAMPの生成に応答して発生し、感染中のAMPの合成と分泌を維持する可能性があります。これらの酵素の誘導は、変性タンパク質応答メディエーターXbp1に依存します。アクティブなTollシグナル伝達を伴う体細胞。 
[要旨]抗菌性シャン（アンプ）は、主要な栄養素貯蔵庫としても機能する脂肪体で生成されます。我々の発見は、脂肪体の料金シグナル伝達の遺伝的活性化が組織につながることを示しています-トリグリセリド貯蔵の自律的減少
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Applying a gene-suite approach to examine the physiological status of wild-caught walleye (Sander vitreus) -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-04/biorxiv.physiology/paper_3.html">
      Applying a gene-suite approach to examine the physiological status of wild-caught walleye (Sander vitreus)
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      全体として、本研究の結果は、デルタマーシュで開催されたスケトウダラが高温および低酸素条件に対して致死未満の反応を示している可能性があることを示唆しており、これらの影響を保全懸念の地元の種に仲介するために投資した管理者に貴重な情報を提供しています。野生魚の分子分析では、魚の生理学的状態の指標としての重要性だけでなく、致死的ではない生検も可能であるため、gは保全研究の有用なターゲットです。トランスクリプトーム技術を多変量統計と組み合わせて、野生の魚の測定された生理学的反応に影響を及ぼす可能性のある交絡因子に対処することの有用性。 
[要旨]デルタマーシュでの短期（1.5か月）および長期（3. 5か月）の保留後に、スケトウダラが非致死的にサンプリングされました。この研究の結果は、魚が高温に対して致死以下の反応を示している可能性を示唆しています低酸素状態
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
