<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-03-19の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Multi-Source DOA Estimation through Pattern Recognition of the Modal
  Coherence of a Reverberant Soundfield -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/cs.SD/paper_0.html">
      Multi-Source DOA Estimation through Pattern Recognition of the Modal
  Coherence of a Reverberant Soundfield
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この方法は、さまざまな音響基準を使用して、さまざまなシミュレートされた実用的なノイズおよび反響環境に対して評価され、DOA推定精度の観点からベースラインメソッドを上回ることがわかりました。畳み込みを使用した新しいマルチソース到来方向（DOA）推定手法を提案しますさらに、提案されたアルゴリズムは、影響を受けずにトレーニング効率を大幅に改善する$ 3 $ D空間での完全なDOA推定中に方位角と仰角の独立したトレーニングを可能にします。全体的な推定精度。 
[要約]単一ソースのトレーニングスキームにより、トレーニング時間とリソース要件が削減されます。異なるマルチソースの組み合わせに対して同じトレーニングモデルを再利用できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br>2020-03-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An Open-set Recognition and Few-Shot Learning Dataset for Audio Event
  Classification in Domestic Environments -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/cs.SD/paper_1.html">
      An Open-set Recognition and Few-Shot Learning Dataset for Audio Event
  Classification in Domestic Environments
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      オーディオ領域では、音楽詐欺や話者認識はFSLメソッドから明らかに恩恵を受けることができます。少数のポジティブサンプルでディープニューラルネットワークをトレーニングする問題は、少数ショット学習（FSL）として知られています。限られた数のサンプルを使用して、ドアベルや火災警報器などのさまざまなタイプの音響警報によって与えられる特定の意図的な音響イベントの検出へのFSLの適用。 
[ABSTRACT] fslは小さなデータセットを使用して、特定の意図的なイベントを検出します。これらには、ドアベル、火災警報器、ドアベルが含まれます。これらの音は、オープンセット認識（osr）問題と見なすことができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-26">
        <br>2020-02-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Detecting Replay Attacks Using Multi-Channel Audio: A Neural
  Network-Based Method -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/cs.SD/paper_2.html">
      Detecting Replay Attacks Using Multi-Channel Audio: A Neural
  Network-Based Method
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーでは、マルチチャネルオーディオの空間情報をさらに活用し、リプレイ攻撃の検出パフォーマンスを大幅に向上させることができる、新しいニューラルネットワークベースのリプレイ攻撃検出モデルを紹介します。音声を主入力として使用する場合、これらのシステムの潜在的な脆弱性をリプレイ攻撃に対処することがますます重要になります。 
[要約]この懸念に対処するためのこれまでの取り組みは、主にシングルチャンネルオーディオに焦点を当てていました。これは、最近の一連の最新情報です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br>2020-03-18
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Gender Representation in Open Source Speech Resources -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/cs.CL/paper_0.html">
      Gender Representation in Open Source Speech Resources
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人工知能（AI）の台頭と深層学習アーキテクチャの使用の増加に伴い、AIシステムの倫理、透明性、公平性の問題は、研究コミュニティの中心的な関心事になっています。コーパスは単純ではなく、性別のバランスは他のコーパスの特性（誘発/非誘発音声、低/高リソース言語、対象となる音声タスク）に依存します。そのようなコーパスを使用して構築された音声システムの。 
[ABSTRACT]音声リソースの性別表現に関する研究を提案することにより、話し言葉システムの透明性と公平性に取り組んでいます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br>2020-03-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Offensive Language Identification in Greek -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/cs.CL/paper_1.html">
      Offensive Language Identification in Greek
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      攻撃的な言葉がオンラインコミュニティやソーシャルメディアプラットフォームで高まる問題になっているため、研究者は虐待的なコンテンツに対処し、サイバーいじめ、差別的発言、攻撃などのさまざまなタイプを検出するシステムを開発する方法を調査しています。 、このトピックに関するこれまでの研究のほとんどは英語を扱っています。これは、主に英語の言語リソースが利用できるためです。 
[概要]このホワイトペーパーでは、攻撃的な言語識別のための最初のギリシャ語注釈付きデータセットを示します。攻撃的なギリシャ語のツイートデータセットには、データセットの詳細な説明が含まれています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-16">
        <br>2020-03-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: X-Stance: A Multilingual Multi-Target Dataset for Stance Detection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/cs.CL/paper_2.html">
      X-Stance: A Multilingual Multi-Target Dataset for Stance Detection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      多言語BERTのベースラインの結果は、このアプローチでは、姿勢検出のゼロショットのクロスリンガルおよびクロスターゲット転送が適度に成功することを示しています。ターゲット全体で学習できるように、ターゲットを表す自然な質問を追加します特定のターゲット問題を持つスタンス検出モデルとは異なり、データセットを使用して、すべての問題について単一のモデルをトレーニングします
[概要]データセットは、ドイツ語、フランス語、イタリア語のtext.itで構成され、スタンス検出の言語間評価が可能です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br>2020-03-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Anchor & Transform: Learning Sparse Representations of Discrete Objects -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/cs.CL/paper_3.html">
      Anchor & Transform: Learning Sparse Representations of Discrete Objects
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      離散オブジェクトの埋め込みは、変換マトリックスに従って重み付けされたアンカーの疎な線形結合であるため、メソッドをアンカー＆変換（ANT）と呼びます。テキスト分類および言語モデリングベンチマークでは、ANTはより少ないパラメーターでより強力なパフォーマンスを発揮します。既存の圧縮ベースラインへ。.小さい組のアンカー埋め込みとスパース変換行列を学習するための単純で自然なアルゴリズムを生成する、Small Variance Asymptoticsに基づいた近似推論アルゴリズムを導き出します。 
[ABSTRACT]このシステムは、小さな範囲の漸近線に基づいています。アンカー埋め込みとスパース変換行列の小さなセットを学習するためのシンプルで自然なアルゴリズムを提供します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br>2020-03-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Dual Multi-head Co-attention for Multi-choice Reading Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/cs.CL/paper_4.html">
      Dual Multi-head Co-attention for Multi-choice Reading Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      事前に訓練された最新の言語モデルは、マッチングネットワークのサポートがなくても十分に強力であり、最新のマッチングネットワークは十分に複雑であることが示されていますが、このように、私たちは、ネットワーク内のアテンションメカニズムとしてのMRC関係。多肢選択式機械読解（MRC）には、パッセージと質問が与えられたときに、回答オプションのセットから正しい回答を決定するモデルが必要です。 MRCタスク、DREAMおよびRACEを選択し、強力な言語モデルの観点から、DUMAがモデルをさらに強化して新しい最先端のパフォーマンスを達成できることを示しています。 
[概要]複数選択dumaには、事前にトレーニングされた言語モデルエンコーダが必要です。デュアルデュアルデュアルマルチヘッド共同注意（duma）は、シンプルだが効果的であることが示されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-26">
        <br>2020-01-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Pre-trained Models for Natural Language Processing: A Survey -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/cs.CL/paper_5.html">
      Pre-trained Models for Natural Language Processing: A Survey
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この調査は、さまざまなNLPタスクのPTMを理解、使用、開発するための実践的なガイドとなることを目的としています。最初に、言語表現学習とその研究の進歩について簡単に紹介します。次に、PTMの知識を下流のタスク。 
[ABSTRACT]最近の調査では、ptmsの包括的なレビューを提供しています。4つの観点を持つ分類に基づいて、既存のptmsを体系的に分類しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br>2020-03-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: TTTTTackling WinoGrande Schemas -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/cs.CL/paper_6.html">
      TTTTTackling WinoGrande Schemas
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      T5シーケンス間モデルを適用して、各例を仮説を含む2つの入力テキスト文字列に分解し、「含意」トークンに割り当てられた確率を仮説のスコアとして使用して、AI2 WinoGrande Challengeに取り組みます。公式リーダーボードへの最初の（そして唯一の）提出は、2020年3月13日に0.7673 AUCをもたらしました。これは、現時点で最もよく知られた結果であり、従来の最新技術を5ポイント以上上回りました。 
[概要]公式リーダーボードの最初の（そして唯一の）導入は、0。7673（0. 7673）になります。この結果は、この時点で最もよく知られた結果であり、5ポイント以上前の最新技術に勝っています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br>2020-03-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: GenNet : Reading Comprehension with Multiple Choice Questions using
  Generation and Selection model -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/cs.CL/paper_7.html">
      GenNet : Reading Comprehension with Multiple Choice Questions using
  Generation and Selection model
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このモデルでは、最初にパッセージから質問の回答を生成し、次に生成された回答を特定の回答と照合します。最適な選択肢は当社の回答になります。回答の生成には、S-net（Tan et al。 2017）SQuADでトレーニングされたモデルと私たちのモデルを評価するために、大規模なRACE（Reading Comprehension Dataset From Examinations）（Lai et al。、2017）を使用しました。ここでは、ニューラルネットワークベースのモデルであるGenNetモデルを提案しました。 
[ABSTRACT]特定のパッセージから正しい答えを選択する複数の方法。最良のオプションは、特定の質問から答えを選択することです。ここでは、ニューラルネットワークベースのモデルであるgennetモデルを提案しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Distant Supervision and Noisy Label Learning for Low Resource Named
  Entity Recognition: A Study on Hausa and Yorùbá -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/cs.CL/paper_8.html">
      Distant Supervision and Noisy Label Learning for Low Resource Named
  Entity Recognition: A Study on Hausa and Yorùbá
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、いくつかの開発途上国で広く話されている2つの言語であるHausaとYor \ `ub \ &#39;aの名前付きエンティティ認識を実行します。さまざまな埋め込みアプローチを評価し、現実的な低レベルで遠隔監視をうまく活用できることを示します-分類子のパフォーマンスを2倍以上にできるリソースシナリオ。より複雑なコンテキストワード埋め込みの出現により、モデルサイズとパフォーマンスの間に興味深いトレードオフが生じます。 
[要約]これらの手法は、高リソース設定でうまく機能することが示されています。しかし、低モデルシナリオでどのように機能するかを研究したいと思います。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br>2020-03-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The JDDC Corpus: A Large-Scale Multi-Turn Chinese Dialogue Dataset for
  E-commerce Customer Service -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/cs.CL/paper_9.html">
      The JDDC Corpus: A Large-Scale Multi-Turn Chinese Dialogue Dataset for
  E-commerce Customer Service
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、100万件以上のマルチターン対話、2,000万発の発言、1億5000万語を超える大規模な実シナリオ中国Eコマース会話コーパスJDDCを構築します。追加の意図情報と3つの注釈付き課題セットも提供されます。人間の会話は複雑であり、人間のような対話エージェントを構築することは非常に困難な作業です。 
[概要]データセットは、人間-人間の会話のさまざまな特性を反映しています。さまざまな特性には、目標駆動型、コンテキスト間の長期依存が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-22">
        <br>2019-11-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Survey on Deep Learning for Named Entity Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/cs.CL/paper_10.html">
      A Survey on Deep Learning for Named Entity Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、入力、コンテキストエンコーダ、タグデコーダの3つの軸に沿った分類に基づいて、既存の作品を体系的に分類します。最後に、NERシステムが直面する課題を読者に提示し、この分野の今後の方向性を示します。このペーパーでは、NERの既存のディープラーニングテクニックに関する包括的なレビューを提供します。 
[ABSTRACT] nerは、質問応答、テキスト要約、機械翻訳などの多くの自然言語アプリケーションの基盤です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-22">
        <br>2018-12-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Unsupervised Pidgin Text Generation By Pivoting English Data and
  Self-Training -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/cs.CL/paper_11.html">
      Unsupervised Pidgin Text Generation By Pivoting English Data and
  Self-Training
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      以前にリリースされた単一言語のピジン英語テキストと並列の英語データからテキストへのコーパスに基づいて、構造化データからピジン英語の説明を自動的に生成できるシステムを構築したいと考えています。実用的ではありませんが、ピボット+セルフトレーニングの手法により、Pidginのテキストの流encyさと関連性の両方が向上します。 
[概要]教師なしニューラル機械翻訳と自己トレーニングの手法を使用して、ピジン語から英語へのクロスリンガルアライメントを確立する前に、最初にデータを英語テキストにトレーニングします。pidgin英語はデータからテキストへの唯一のソースです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br>2020-03-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Distributional Semantics and Linguistic Theory -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/cs.CL/paper_12.html">
      Distributional Semantics and Linguistic Theory
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このレビューは、言語の理論的および計算的アプローチの相互受精を促進することを目的としており、それがどのように機能するかについての集合的知識を前進させる手段として提供します。分布セマンティクスは、計算言語学の多くの研究で示されているように、自然言語での意味。しかし、理論的言語学への影響はこれまでのところ限定的でした。このレビューは、3つの分野での理論的言語学に関連する方法と結果に重点を置いて、分布意味論に関する文献の重要な議論を提供します：意味変化、多義性および構成、および文法とセマンティクスのインターフェイス（具体的には、構文と派生形態を使用したセマンティクスのインターフェイス）。 
[要旨]このレポートは、オランダ語、オランダ語、オランダ語の研究者の研究の重要な議論を提供します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-06">
        <br>2019-05-06
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Overview of the TREC 2019 deep learning track -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/cs.CL/paper_13.html">
      Overview of the TREC 2019 deep learning track
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ドキュメント検索タスクには、367千のトレーニングクエリを含む320万のドキュメントのコーパスがあり、43のクエリの再利用可能なテストセットを生成します。ディープラーニングの実行は、従来のIRの実行を大幅に上回りました。トレーニングデータを使用し、そのようなデータでトレーニングされたディープモデルを審査プールに含めましたが、過去の一部の研究ではそのようなトレーニングデータやプーリングがありませんでした。 
[概要]ディープラーニングは、人間ベースの大規模なトレーニングセットを備えた最初のトラックです。これらには2つのタスクに対応する2つのセットが含まれます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-17">
        <br>2020-03-17
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Multi-Source DOA Estimation through Pattern Recognition of the Modal
  Coherence of a Reverberant Soundfield -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/eess.AS/paper_0.html">
      Multi-Source DOA Estimation through Pattern Recognition of the Modal
  Coherence of a Reverberant Soundfield
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この方法は、さまざまな音響基準を備えたさまざまなシミュレートされた実用的なノイズ環境および反響環境に対して評価され、DOA推定精度の点でベースラインメソッドを上回ることがわかります。さらに、提案されたアルゴリズムにより、全体的な推定精度に影響を与えることなく、トレーニング効率を大幅に改善する$ 3 $ Dスペース。提案手法は、単一ソースのトレーニングスキームを使用して、$ 3 $ Dスペースで同時にアクティブな複数の音源を推定できます。 
[要約]単一ソースのトレーニングスキームにより、トレーニング時間とリソース要件が削減されます。異なるマルチソースの組み合わせに対して同じトレーニングモデルを再利用できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br>2020-03-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An Open-set Recognition and Few-Shot Learning Dataset for Audio Event
  Classification in Domestic Environments -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/eess.AS/paper_1.html">
      An Open-set Recognition and Few-Shot Learning Dataset for Audio Event
  Classification in Domestic Environments
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      オーディオ領域では、音楽詐欺や話者認識はFSLメソッドから明らかに恩恵を受けることができます。少数のポジティブサンプルでディープニューラルネットワークをトレーニングする問題は、少数ショット学習（FSL）として知られています。さまざまなサウンドクラスに対応する多くのイベントが行われる家庭環境。 
[ABSTRACT] fslは小さなデータセットを使用して、特定の意図的なイベントを検出します。これらには、ドアベル、火災警報器、ドアベルが含まれます。これらの音は、オープンセット認識（osr）問題と見なすことができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-26">
        <br>2020-02-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Robust Audio Watermarking Using Graph-based Transform and Singular Value
  Decomposition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/eess.AS/paper_2.html">
      Robust Audio Watermarking Using Graph-based Transform and Singular Value
  Decomposition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、PSNR、PESQ、およびSTOI測定に基づいた埋め込み後、結果は良好な品質を示します。また、提案された方法のペイロードは、音声および音楽信号に対してそれぞれ800および1600であり、 DWT-SVDおよびDWT-DCTとして。グラフベースの変換（GT）は、特に圧縮目的のために、信号処理ドメインで最近うまく利用されています。 
[要約]新しい方法は、オーディオ透かしの堅牢性を向上させることです。psnr、pesq、およびstoiの測定に基づいて、埋め込み後の結果は良好な品質を示します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-11">
        <br>2020-03-11
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Deletion of Sphingosine 1-Phosphate Receptor 1 in cardiomyocytes during development leads to abnormal ventricular conduction and fibrosis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/biorxiv.physiology/paper_0.html">
      Deletion of Sphingosine 1-Phosphate Receptor 1 in cardiomyocytes during development leads to abnormal ventricular conduction and fibrosis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      スフィンゴシン1-リン酸受容体1（S1P1、S1pr1によってコードされる）は、内皮細胞や心筋細胞を含む複数の細胞タイプでシグナルを送るGタンパク質共役型受容体です。開発中の心筋細胞特異的なS1pr1の欠失は、3分の1の心室非圧縮につながります成人期まで生き残った突然変異体マウスの。心臓伝導は、心筋細胞S1pr1突然変異体マウスでは異常であり、同腹子対照マウスと比較して突然変異体ではQRS間隔が延長された。 
[要旨] s1pr1欠失の成人生存者は、心臓線維症の増加を示した。結果はまた、正常な収縮機能を伴う過剰骨梁形成の設定における伝導異常を明らかにする
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br>2020-03-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Depression of heart rate in fish at critically high temperatures is due to atrioventricular block -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-19/biorxiv.physiology/paper_1.html">
      Depression of heart rate in fish at critically high temperatures is due to atrioventricular block
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      イオンチャネルのレベルから生体内の心機能までの一連のイベントは、魚の臨界高温での心拍出量の低下の機構的説明を提供します。興奮性の低下は、入力抵抗の温度誘発性低下（筋鞘K +安静時の筋細胞の外向きIK1電流を介したリーク）、および活性筋細胞のNa +電流（INa）による内向きの電荷移動の減少..さらに加温すると、心房レートは188 {+/-} 22 bpmの+27でピーク値に増加しました。 {degrees} C、心室の速度が+25.3 {degrees} Cで124 {+/-} 10 bpmのピーク値に達した後、+ 27 {degrees} Cで111 {+/-} 15 bpmに低下しました。 。単一心室筋細胞では、+ 12 {degrees} Cから+25 {degrees} Cに加温すると、活動電位を誘発するのに必要なレオベース電流と重要な脱分極の増加から明らかなように、電気興奮性が減衰しました。 
[概要]徐脈の原因は、心臓の心臓では未解決のままです。単一心室のマイセルでは、12（度）cから25 
[度] cに加温すると、電気的興奮性が弱まりました。 、増加は心臓活動の減少に関連していた
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br>2020-03-18
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
