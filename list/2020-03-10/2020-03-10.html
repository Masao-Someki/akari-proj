<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-03-10の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Tackling real noisy reverberant meetings with all-neural source
  separation, counting, and diarization system -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/cs.SD/paper_0.html">
      Tackling real noisy reverberant meetings with all-neural source
  separation, counting, and diarization system
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、まず、全神経アプローチの堅牢性を向上させるために必要な実際的な問題を検討し、実際の会議シナリオでも、全神経アプローチが効果的な音声強調を実行し、同時に状態を上回ることを実験的に示します-最先端のシステム..ただし、このような全神経的アプローチが、より自然に話すスピーカー、激しいノイズと残響を含むより複雑な実際の会議データに正常に一般化されるかどうか、および状態と比較してどのように機能するかは明確ではありませんでしたこのようなシナリオでの最先端のシステム..スマートデバイスは会話に追従して応答します。 
[概要]この方法は、シミュレートされたクリーンな（ノイズレスおよび無響）ダイアログをうまく処理できます。いくつかの従来の方法と比較して、非常に優れたパフォーマンスを達成しました。この方法は、効果的な音声強調を実行し、同時に最先端のシステムを上回ることができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br>2020-03-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Semantic Object Prediction and Spatial Sound Super-Resolution with
  Binaural Sounds -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/cs.SD/paper_1.html">
      Semantic Object Prediction and Spatial Sound Super-Resolution with
  Binaural Sounds
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、純粋にバイノーラルサウンドに基づいて、サウンド作成オブジェクトの高密度セマンティックラベリングのアプローチを開発します。このように、人間の注釈を使用せずに聴覚システムをトレーニングできます。全体的なパフォーマンスを向上させることを目的とした、トレーニング可能なマルチタスクネットワーク。 
[概要]新しいセンサーのセットアップを提案し、8つのプロのバイノーラルマイクと360度カメラを備えた街路シーンの新しいオーディオ-ビジュアルデータセットを記録します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br>2020-03-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Enhancing End-to-End Multi-channel Speech Separation via Spatial Feature
  Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/cs.SD/paper_2.html">
      Enhancing End-to-End Multi-channel Speech Separation via Spatial Feature
  Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      手作りの空間機能（たとえば、チャネル間位相差、IPD）は、最近の深層学習ベースのマルチチャネル音声分離（MCSS）メソッドで基本的な役割を果たします。これらのフィルターは、2d畳み込み（conv2d）レイヤーとそのシミュレートされたマルチチャネル残響WSJ0 2ミックスデータセットの評価結果は、提案されたICDベースのMCSSモデルが全体の信号対歪み比を10.4改善することを示しています。 IPDベースのMCSSモデルの\％。 
[概要]このアーキテクチャでは、信号チャネルにまたがる時間領域フィルタが適応空間フィルタリングを実行するようにトレーニングされます。これらは、mcssシステムの極方向を区別するのに役立つように設計されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br>2020-03-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Spatial Attention for Far-field Speech Recognition with Deep Beamforming
  Neural Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/cs.SD/paper_3.html">
      Spatial Attention for Far-field Speech Recognition with Deep Beamforming
  Neural Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの実験結果は、空間的注意が注意なしの方法に比べて最大9％の相対単語誤り率の改善を達成することを示しています。ただし、ターゲットスピーチの方向のみが関連するため、このような方法で抽出された特徴には冗長な情報が含まれています。 
[要約]複数の視線方向を持つ空間ビームフォーマの以前のアプローチは、有望な結果を示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-05">
        <br>2019-11-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Toward Cross-Domain Speech Recognition with End-to-End Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/cs.SD/paper_4.html">
      Toward Cross-Domain Speech Recognition with End-to-End Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、ニューラルエンドツーエンドモデルを使用すると、認識中にドメイン適応言語モデルが不要になります。これは、入力ドメインが不明な場合に大きな利点です。マルチドメイン音声認識の分野では、ハイブリッドモデルでは、音響条件が一致しない他のドメインから追加のトレーニングデータを提供しても、特定のドメインのパフォーマンスが向上しないことを示しています。 
[ABSTRACT]ハイブリッドモデルの場合、音響条件が一致しない他のドメインから追加のトレーニングデータを提供しても、特定のドメインのパフォーマンスが向上することはありません。これは、ドメイン固有のもの
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br>2020-03-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The Effect of Silence Feature in Dimensional Speech Emotion Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/cs.SD/paper_5.html">
      The Effect of Silence Feature in Dimensional Speech Emotion Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      沈黙機能の計算におけるしきい値係数の適切な選択は、一致相関係数の観点から、次元音声感情認識パフォーマンスのパフォーマンスを改善しました。結果は、沈黙機能が他の感情次元よりも覚醒次元に影響を及ぼすことを明らかにします。一方、その要因を不適切に選択すると、同じアーキテクチャを使用することでパフォーマンスが低下します。 
[要約]人間の感情を音声で使用できるかどうかは明らかではありません。さらに、無音機能を音響機能のセットからの高い統計機能でグループ化しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving noise robust automatic speech recognition with single-channel
  time-domain enhancement network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/cs.SD/paper_6.html">
      Improving noise robust automatic speech recognition with single-channel
  time-domain enhancement network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実際、ほとんどのシングルチャネル音声強調（SE）メソッド（ノイズ除去）は、マルチコンディショントレーニングデータでトレーニングされた最先端のASRバックエンドよりも限られたパフォーマンスの向上しかもたらしませんでした。しかし、このような時間領域アプローチによって達成される高い強化性能は、ASRに変換できます。最近、時間領域で機能するニューラルネットワークベースのSEメソッドに関する多くの研究があり、これまで達成されなかった性能レベルを示しています。 
[概要]単一チャネルシステムのノイズの多い条件でのasrのパフォーマンスは満足のいくものではありません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br>2020-03-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Deep Neural Networks for Automatic Speech Processing: A Survey from
  Large Corpora to Limited Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/cs.SD/paper_7.html">
      Deep Neural Networks for Automatic Speech Processing: A Survey from
  Large Corpora to Limited Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      その意味で、我々はこの調査で焦点を絞ったスピーチ問題に少数ショット技術の概要とそのような技術を使用する視点を提案します。レビューされた技術が大規模なデータセットにうまく適合しないことが起こります。音声障害のデータ。 
[概要]これらのシステムは、大量のデータを学習する必要があります。これらのシステムは、これらのシステムから学習できる必要があります。しかし、文献からのいくつかの有望な結果は、そのような技術の使用を奨励します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br>2020-03-09
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Learning to Few-Shot Learn Across Diverse Natural Language
  Classification Tasks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/cs.CL/paper_0.html">
      Learning to Few-Shot Learn Across Diverse Natural Language
  Classification Tasks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      異なるクラス数のタスク間で最適化ベースのメタラーニングを可能にする新しいメソッドLEOPARDを開発し、さまざまなNLP分類タスクへの一般化に関するさまざまな方法を評価します。LEOPARDは、最先端のトランスフォーマーでトレーニングされます。トレーニング中にまったく見られなかったタスクのより良い一般化を示し、ラベルごとにわずか4例です。エンティティのタイピング、自然言語推論、センチメント分析、および他のいくつかのテキスト分類タスクのさまざまなドメインを含む17のNLPタスクで、 LEOPARDは、自己監視型の事前トレーニングまたはマルチタスクトレーニングよりも少ないショット学習の初期パラメーターを学習し、多くの強力なベースラインよりも優れていることを示します。たとえば、見えないタスクで14.5％の精度で平均相対ゲインが14.5％ラベル。 
[ABSTRACT] leopardはメタ学習でトレーニングされ、トレーニング中にまったく表示されないタスクのより良い一般化を示します。ラベルごとにわずか4つの例があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br>2019-11-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Shallow Discourse Annotation for Chinese TED Talks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/cs.CL/paper_1.html">
      Shallow Discourse Annotation for Chinese TED Talks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      現在、リソースは、書面によるテキストではなく、計画された話されたモノローグの談話レベルのプロパティに注釈を付けるという点でユニークです。注釈スキームは、信頼性の高い結果を達成できます。 
[要旨]英語版には存在しない中国語のテキストの特性に適応した、ペン談話ツリーバンクのスタイルの談話関係で、テッドトークに注釈が付けられています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br>2020-03-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Accessing Higher-level Representations in Sequential Transformers with
  Feedback Memory -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/cs.CL/paper_2.html">
      Accessing Higher-level Representations in Sequential Transformers with
  Feedback Memory
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      言語モデリング、ニューラルマシン翻訳、要約、強化学習のさまざまなベンチマークで、表現能力の向上によりTransformerベースラインを改善できることを実証します。現在のタイムステップの最低の表現が過去の最高レベルの抽象表現から形成されることを意味する表現。この並列化により計算効率が向上しますが、入力のシーケンシャルな性質をモデルが完全に活用することを制限します。特定のレイヤーは、以前のタイムステップで既に構築された上位レベルの表現ではなく、下位レイヤーの表現にのみアクセスできます。 
[ABSTRACT]モデルは、以前のタイムステップで既に構築されている上位レベルの表現ではなく、下位層の表現にのみアクセスできます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-21">
        <br>2020-02-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Sato: Contextual Semantic Type Detection in Tables -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/cs.CL/paper_3.html">
      Sato: Contextual Semantic Type Detection in Tables
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      コンテキストと列値からの信号を活用して、テーブルの列のセマンティックタイプを自動的に検出するハイブリッド機械学習モデルである佐藤を紹介します。佐藤は、大規模なテーブルコーパスでトレーニングされたディープラーニングモデルとトピックを組み合わせます最先端のパフォーマンスを大幅に超えて、それぞれ0.925および0.735のサポート加重およびマクロ平均F1スコアを達成するためのモデリングおよび構造化予測..佐藤の全体およびタイプごとのパフォーマンスを広範囲に分析し、個々のモデリングコンポーネントと機能カテゴリがそのパフォーマンスにどのように寄与するかを説明します。 
[ABSTRACT]既存の検出アプローチは、ダーティデータでは不十分なパフォーマンス、限られた数のセマンティックタイプのみをサポート、列のテーブルコンテキストの組み込みに失敗、またはトレーニングデータの大きなサンプルサイズに依存します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-14">
        <br>2019-11-14
      </time>
    </span>
  </h3>
</article>
<!-- paper0: An Empirical Investigation of Pre-Trained Transformer Language Models
  for Open-Domain Dialogue Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/cs.CL/paper_4.html">
      An Empirical Investigation of Pre-Trained Transformer Language Models
  for Open-Domain Dialogue Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      コンテキストと応答の両方の重み付き結合予測パラダイムは、コンテキスト予測の損失項の有無に関係なくモデルのパフォーマンスを評価するように設計されています。我々は、タスクの事前トレーニング済みトランスベースの自己回帰言語モデルの経験的調査を提示しますオープンドメインのダイアログ生成。貪欲検索、ビーム検索、トップkサンプリングなどのさまざまなデコード戦略。
[要約] pre-トレーニングおよび微調整-イーサンラーニングを実施するために使用されます。ダイアログコンテキストおよび応答が連結されます。単一のシーケンスに
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br>2020-03-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: TEDL: A Text Encryption Method Based on Deep Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/cs.CL/paper_5.html">
      TEDL: A Text Encryption Method Based on Deep Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      その後、SHA-256関数およびその他のトリックを使用して、自己更新コードブックがワードベクトルテーブル上に構築されます。通信の効率を低下させずに攻撃を強制します。最初に、両方の通信パーティは、指定されたハイパーパラメーターに従って深層学習モデルをトレーニングすることにより、単語ベクトルテーブルを確立します。 
[ABSTRACT]ハイパーパラメーターは、暗号化のセキュリティを向上させるために使用されます。これは、ハイパーパラメーターなどのハイパーパラメーターのためです。通信開始時、暗号化および復号化は、コードブックのインデックス作成および逆インデックス作成と同等です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br>2020-03-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Multi-Source Entity-Level Sentiment Corpus for the Financial Domain:
  The FinLin Corpus -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/cs.CL/paper_6.html">
      A Multi-Source Entity-Level Sentiment Corpus for the Financial Domain:
  The FinLin Corpus
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      注釈には、センチメント用に選択されたテキストスパンも含まれているため、アノテーターの推論に対する追加の洞察が得られます。全体として、FinLinは、新規で公開されている金融感情コーパスを提供することで現在の知識を補完し、金融感情分析のトピックに関する研究と行動科学の潜在的な応用を促進することを目指しています。 
[ABSTRACT]感情スコアと範囲内の関連性スコアで注釈付けされたfinlin。企業に対する見栄えの良い効果の予測で注釈付けされたfinlin
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br>2020-03-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SMArT: Training Shallow Memory-aware Transformers for Robotic
  Explainability -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/cs.CL/paper_7.html">
      SMArT: Training Shallow Memory-aware Transformers for Robotic
  Explainability
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、計算の要求を制限しながら、言語生成の最先端のパフォーマンスを提供できる完全に注意深いキャプションアルゴリズムを提案します。さらに、画像領域の新しいメモリ認識エンコーディングを組み込んでいます。視覚に基づいた自然言語の説明を生成することは、自分自身を説明し、人間とコミュニケーションをとることができる自律的なエージェントに向けた重要なステップです。 
[ABSTRACT]私たちのモデルは、トランスフォーマーモデルに触発されています。それは、編集およびデコード段階で2つのトランスフォーマーレイヤーのみを使用
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-07">
        <br>2019-10-07
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Overview of the CCKS 2019 Knowledge Graph Evaluation Track: Entity,
  Relation, Event and QA -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/cs.CL/paper_8.html">
      Overview of the CCKS 2019 Knowledge Graph Evaluation Track: Entity,
  Relation, Event and QA
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CCKS 2019は、6つのタスクで評価トラックを開催し、1,600以上のチームを引き付けました。知識グラフは、多くの実世界のタスクで広く使用されている概念、エンティティ、およびそれらの関係として世界の知識をモデル化します。 CCKS 2019でナレッジグラフの評価領域の概要を説明します。
[概要] ccks 2019は、6つのタスクで評価トラックを開催し、1,600以上のチームを集めました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br>2020-03-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Sentence Analogies: Exploring Linguistic Relationships and Regularities
  in Sentence Embeddings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/cs.CL/paper_9.html">
      Sentence Analogies: Exploring Linguistic Relationships and Regularities
  in Sentence Embeddings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの実験では、BERTスタイルのコンテキスト埋め込みに基づくものを含む、広範囲の文の埋め込み方法を検討します。単語ベクトル表現の重要な特性は広く研究されていますが、文ベクトル表現の特性についてはあまり知られていません。語彙の類推データおよび文間の意味関係に基づいて、評価データを誘導するスキームの数。 
[概要]単語は、それらが規則性を示す程度を評価することによって評価されることがよくあります。評価データを誘導するための多くのスキームを提案します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br>2020-03-09
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Tackling real noisy reverberant meetings with all-neural source
  separation, counting, and diarization system -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/eess.AS/paper_0.html">
      Tackling real noisy reverberant meetings with all-neural source
  separation, counting, and diarization system
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      スマートデバイスは会話を追跡し、応答します。しかし、このような全神経的アプローチが、より自然に話すスピーカー、激しいノイズと残響、およびそれがどのように機能するかを含むより複雑な実際の会議データにうまく一般化されるかどうかは明確ではありません最適な自動会議分析を実現するために、以前に、音源分離、話者ダイアライゼーション、音源カウントの問題を最適な方法で共同で解決する全神経アプローチを提案しました（エラーの逆伝播により、3つのタスクすべてを共同で最適化できることを感じてください）。 
[概要]この方法は、シミュレートされたクリーンな（ノイズレスおよび無響）ダイアログをうまく処理できます。いくつかの従来の方法と比較して、非常に優れたパフォーマンスを達成しました。この方法は、効果的な音声強調を実行し、同時に最先端のシステムを上回ることができます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br>2020-03-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Semantic Object Prediction and Spatial Sound Super-Resolution with
  Binaural Sounds -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/eess.AS/paper_1.html">
      Semantic Object Prediction and Spatial Sound Super-Resolution with
  Binaural Sounds
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      次に、3つのタスクを1つのエンドツーエンドのトレーニング可能なマルチタスクネットワークに定式化して、全体的なパフォーマンスを向上させます。この作品は、純粋にバイノーラルサウンドに基づいて、サウンド作成オブジェクトの高密度セマンティックラベリングのアプローチを開発します。すなわち、a）音の空間分解能を高めるための空間音超解像に関する新しいタスク、およびb）シーンの高密度深度予測を提案します。 
[概要]新しいセンサーのセットアップを提案し、8つのプロのバイノーラルマイクと360度カメラを備えた街路シーンの新しいオーディオ-ビジュアルデータセットを記録します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br>2020-03-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multitask Learning and Multistage Fusion for Dimensional Audiovisual
  Emotion Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/eess.AS/paper_2.html">
      Multitask Learning and Multistage Fusion for Dimensional Audiovisual
  Emotion Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ユニモーダルおよび初期融合法で使用されるマルチタスク学習を使用したアプローチでは、0.297と比較して平均CCCスコアが0.431のシングルタスク学習よりも改善が見られます。次に、さまざまなモダリティの最終予測の結果を組み合わせるマルチステージ融合が提案されています。後期融合アプローチで採用された多段階法は、覚醒、価数の開発データセットの真の値と予測値の間の一致スコアを大幅に改善しました（
[0.537、0.565、0.083]から
[0.68、0.656、0.443]） 、好きです。 
[要旨]この論文では、音声データと視覚データから感情属性を予測する2つの方法を提案します。まず、さまざまなモダリティの最終予測の結果を結合する多段階融合を提案します。正の値と予測値の間のスコア
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-26">
        <br>2020-02-26
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Enhancing End-to-End Multi-channel Speech Separation via Spatial Feature
  Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/eess.AS/paper_3.html">
      Enhancing End-to-End Multi-channel Speech Separation via Spatial Feature
  Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのフィルターは2d畳み込み（conv2d）レイヤーによって実装され、そのパラメーターは音声分離目的関数を使用して純粋にデータ駆動型で最適化されます。シミュレートされたマルチチャンネル残響WSJ0 2ミックスデータセットの評価結果は、提案されたICDベースのMCSSモデルは、IPDベースのMCSSモデルよりも全体の信号対歪み比を10.4 \％向上させます。ただし、これらの手動で設計された空間機能は、エンドツーエンドの最適化MCSSフレームワークに組み込むのが困難です。 
[概要]このアーキテクチャでは、信号チャネルにまたがる時間領域フィルタが適応空間フィルタリングを実行するようにトレーニングされます。これらは、mcssシステムの極方向を区別するのに役立つように設計されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br>2020-03-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Spatial Attention for Far-field Speech Recognition with Deep Beamforming
  Neural Networks -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/eess.AS/paper_4.html">
      Spatial Attention for Far-field Speech Recognition with Deep Beamforming
  Neural Networks
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの実験結果は、空間的注意が、注意のない方法よりも最大9％の相対単語誤り率の改善を達成することを示しています。そのような方法で抽出された特徴には、ターゲット音声の方向のみが関連するため、冗長な情報が含まれています。 
[要約]複数の視線方向を持つ空間ビームフォーマの以前のアプローチは、有望な結果を示しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-05">
        <br>2019-11-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Toward Cross-Domain Speech Recognition with End-to-End Models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/eess.AS/paper_5.html">
      Toward Cross-Domain Speech Recognition with End-to-End Models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、ニューラルエンドツーエンドモデルを使用すると、認識中にドメインに適応した言語モデルが不要になります。これは、入力ドメインが不明な場合に大きな利点になります。マルチドメイン音声認識の分野では、クロスドメインおよびドメイン不変の音声認識システムを構築するために、過去の研究ではハイブリッド音響モデルに焦点が当てられていました。 
[ABSTRACT]ハイブリッドモデルの場合、音響条件が一致しない他のドメインから追加のトレーニングデータを提供しても、特定のドメインのパフォーマンスが向上することはありません。これは、ドメイン固有のもの
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br>2020-03-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The Effect of Silence Feature in Dimensional Speech Emotion Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/eess.AS/paper_6.html">
      The Effect of Silence Feature in Dimensional Speech Emotion Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      結果は、沈黙の特徴が他の感情の次元よりも覚醒の次元に影響することを示しています。反対に、その要素の不適切な選択は同じアーキテクチャを使用することによるパフォーマンスの低下につながります。一連の音響的特徴からの高い統計関数で無音の特徴をグループ化しました。 
[要約]人間の感情を音声で使用できるかどうかは明らかではありません。さらに、無音機能を音響機能のセットからの高い統計機能でグループ化しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-03">
        <br>2020-03-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Improving noise robust automatic speech recognition with single-channel
  time-domain enhancement network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/eess.AS/paper_7.html">
      Improving noise robust automatic speech recognition with single-channel
  time-domain enhancement network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      しかし、このような時間領域アプローチによって達成される高い強化性能をASRに変換できるかどうかは確立されていません。これらの肯定的な結果は、シングルチャネルノイズの低減がASR性能をさらに改善できることを示しています。実際、ほとんどのシングルチャネル音声強調（SE）メソッド（ノイズ除去）は、マルチコンディショントレーニングデータでトレーニングされた最先端のASRバックエンドに比べて、限られたパフォーマンスの向上しかもたらしていません。 
[概要]単一チャネルシステムのノイズの多い条件でのasrのパフォーマンスは満足のいくものではありません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br>2020-03-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Deep Neural Networks for Automatic Speech Processing: A Survey from
  Large Corpora to Limited Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-10/eess.AS/paper_8.html">
      Deep Neural Networks for Automatic Speech Processing: A Survey from
  Large Corpora to Limited Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      限られたデータの問題を評価するために、最も困難なタスクを表す最新の自動音声認識システムを最初に調査します（各言語に大きなばらつきがあるため）。最後のセクションでは、少数ショット手法を調査します。リソース不足のスピーチを数ショットの問題として解釈しているため、レビュー済みの手法が大規模なデータセットにうまく適合しないことがあります。 
[概要]これらのシステムは、大量のデータを学習する必要があります。これらのシステムは、これらのシステムから学習できる必要があります。しかし、文献からのいくつかの有望な結果は、そのような技術の使用を奨励します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-09">
        <br>2020-03-09
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本日更新された論文はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br>
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
