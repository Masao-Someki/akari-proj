<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-12-08の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: MLS: A Large-Scale Multilingual Dataset for Speech Research -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.SD/paper_0.html">
      <font color="black">MLS: A Large-Scale Multilingual Dataset for Speech Research</font>
    </a>
  </h2>
  <font color="black">さらに、言語モデル（LM）とベースライン自動音声認識（ASR）モデル、およびデータセット内のすべての言語を提供します。データセットは、http：//www.openslr.orgで誰でも無料で利用できるようになります。このような大規模な転写データセットは、ASRおよびText-To-Speech（TTS）研究に新しい道を開くと信じています。 
[ABSTRACT]データセットは8つの言語で構成されており、英語は44.5k時間、その他の言語は6k時間です。データセットは、asrとテキスト読み上げの研究に新しい道を開きます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Instrumentalist Net: Unsupervised Generation of Music from Body
  Movements -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.SD/paper_1.html">
      <font color="black">Multi-Instrumentalist Net: Unsupervised Generation of Music from Body
  Movements</font>
    </a>
  </h2>
  <font color="black">事前の身体運動エンコーダーとの共同トレーニングは、音楽を音楽コンポーネントと楽器の特徴を示す潜在的な特徴に解きほぐすことに成功します。パイプラインが正確なコンテンツを生成するように、Midiが潜在的な空間をさらに調整できることを示します。次に、パイプラインは、反復神経ネットワークによってエンコードされたミュージシャンの体のキーポイントの動きを条件とする自動回帰事前条件とともにトレーニングされます。 
[概要]パイプラインは、ログからさまざまな楽器の音楽の離散潜在表現を学習します-スペクトログラム。vq-vaeアーキテクチャは、追加の条件付けで詳細な音楽生成をサポートします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Limitations of weak labels for embedding and tagging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.SD/paper_2.html">
      <font color="black">Limitations of weak labels for embedding and tagging</font>
    </a>
  </h2>
  <font color="black">埋め込みまたはエンドツーエンドの分類器をトレーニングするときの弱いラベルの影響を調査します。さまざまな実験シナリオについて説明し、弱いラベルのデータに最も敏感なアプリケーションについての洞察を提供します。周囲の音の分析における多くのデータセットとアプローチは、弱いラベルを使用します。ラベル付けされたデータ：すべてのデータサンプルに強いラベルを付けるのはコストがかかりすぎるため、弱いラベルが使用されますが、強いラベルと比較した場合のパフォーマンスへの影響は不明です。実際、弱いラベルは他のラベルと同時に処理する必要があります。課題、つまりサンプルごとの複数のラベル、不均衡なクラス、および/または重複するイベント。この論文では、弱いラベルを含む教師あり学習問題を定式化します。他の課題とは対照的に、強いラベルと弱いラベルの違いに焦点を当てたデータセットを作成します。 。 
[ABSTRACT] cnn&#39;s ann ann annは、弱いデータと同じ質問を扱っています。これは、同じものが紙と同じである必要があるためです。さまざまな実験シナリオについて説明し、どのアプリケーションが最も敏感であるかについての洞察を提供します。弱いデータ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-05">
        <br><font color="black">2020-02-05</font>
      </time>
    </span>
</section>
<!-- paper0: EfficientTTS: An Efficient and High-Quality Text-to-Speech Architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.SD/paper_3.html">
      <font color="black">EfficientTTS: An Efficient and High-Quality Text-to-Speech Architecture</font>
    </a>
  </h2>
  <font color="black">EfficientTTSは、新しい単調アラインメントモデリングアプローチ（この作業でも導入）によって動機付けられています。これは、計算をほとんど増やすことなく、シーケンスアラインメントに単調な制約を指定します。提案されたモデルがTacotron2やTacotron2などの対応するモデルよりも大幅に優れていることを実験的に示します。 Glow-TTSは、音声品質、トレーニング効率、合成速度の観点から、強力な堅牢性と多様性に優れた音声を生成します。EfficientTTSをさまざまなフィードフォワードネットワーク構造と組み合わせることで、両方のテキストを含むTTSモデルのファミリーを開発します。 -to-melspectrogramおよびtext-to-waveformネットワーク。 
[ABSTRACT] efficientttsは、安定したエンドツーエンドのトレーニング手順ですべてのパラメータを最適化すると同時に、高品質の音声を高速かつ効率的に合成できるようにします。提案されたアプローチは、タコトロン2などの自己回帰モデルに簡単に拡張できることを示しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: F3RNet: Full-Resolution Residual Registration Network for Deformable
  Image Registration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.IV/paper_0.html">
      <font color="black">F3RNet: Full-Resolution Residual Registration Network for Deformable
  Image Registration</font>
    </a>
  </h2>
  <font color="black">もう一方のストリームは、深いマルチスケール残余表現を学習して、ロバストな認識を取得します。提案された方法は、残余学習方式で2つの並列処理ストリームを組み合わせます。アートアプローチ。 
[概要]ディープラーニングアプローチはかなりの人気と成功を収めていますが、一部の重度の変形領域の正確な位置合わせは見過ごされがちです。これらの領域は、手術対象を特定するために重要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Physics-informed neural networks for myocardial perfusion MRI
  quantification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.IV/paper_1.html">
      <font color="black">Physics-informed neural networks for myocardial perfusion MRI
  quantification</font>
    </a>
  </h2>
  <font color="black">トレーサー動態モデルは、動的造影剤増強磁気共鳴（MR）画像からの血流などの動態パラメーターの定量化を可能にします。この研究では、心筋灌流MR定量化を実行する手段として、物理情報に基づく神経ネットワーク（PINN）を紹介します。動的パラメータを推測するための用途の広いスキームを提供します。これにより、パラメータの推定が不正確になる可能性があります。 
[概要]これらのニューラルネットワークは、ピンの観測データに適合するようにトレーニングできます。これは、動的であり、血流と微小血管機能を直接解決するためです。ただし、これにより、モデルモデルモデルモデルが不正確になる可能性があります。これにより、モデルモデルが改善される可能性があります。インシリコとマウスの両方のモデルモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Tubular Shape Aware Data Generation for Semantic Segmentation in Medical
  Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.IV/paper_2.html">
      <font color="black">Tubular Shape Aware Data Generation for Semantic Segmentation in Medical
  Imaging</font>
    </a>
  </h2>
  <font color="black">この作業では、人工データを使用して注釈付き画像の不足を軽減することを目指しています。他の医用画像タスクと同様に、チューブの手動ピクセル単位の注釈はリソースを消費するプロセスです。具体的には、チューブ状のオブジェクトの合成データ生成のためのアプローチ。生成的敵対的ネットワークは、事前の形状の制約で正規化されます。 
[要約]インターベンショナルラジオロジーでは、X線画像の使用は、オブジェクトのようなさまざまなチューブを視覚化する必要性と関連していることがよくあります。目的は、X線やカテーテルなどの一連の画像を作成することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-02">
        <br><font color="black">2020-10-02</font>
      </time>
    </span>
</section>
<!-- paper0: LORCK: Learnable Object-Resembling Convolution Kernels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.IV/paper_3.html">
      <font color="black">LORCK: Learnable Object-Resembling Convolution Kernels</font>
    </a>
  </h2>
  <font color="black">この結果は、セグメント化されたオブジェクトの形状を使用して、セグメント化の結果を高めるための適切な畳み込みカーネルを形成できる、他のドメイン固有の深層学習アプリケーションへの道を開きます。具体的には、拡張された中空カーネルアーキテクチャが現状を上回ります。 -アート空間セグメンテーションモデル、たとえばBi-LSTMを使用した時間ブロックの追加により、膀胱セグメンテーションチャレンジの新しいマルチクラスベースラインが確立されます。この問題に対処するために、次のことを学習する新しいクラスの中空カーネルを提案します。セグメント化された器官の輪郭を「模倣」し、その形状と構造の複雑さを効果的に複製します。 
[概要]一連のuツアーをトレーニングして、オストロールシステムを開発します。さまざまな組織でこのアイデアの利点を実証しました。ただし、壁とがん領域の正確な位置特定は、腫瘍学の重要なステップです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Navigator-Free Submillimeter Diffusion Imaging using Multishot-encoded
  Simultaneous Multi-slice (MUSIUM) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.IV/paper_4.html">
      <font color="black">Navigator-Free Submillimeter Diffusion Imaging using Multishot-encoded
  Simultaneous Multi-slice (MUSIUM)</font>
    </a>
  </h2>
  <font color="black">サブミリメータの等方性解像度拡散MR画像（dMRI）を実現する機能は、特に皮質における微細な脳構造を研究するために非常に重要です。一方、gSliderシーケンスは、比較的高いRFパワーとピーク振幅を必要とし、SARを増加させます。この作業では、3T MRスキャナーでナビゲーターフリーのマルチショットエンコード同時マルチスライス（MUSIUM）イメージングアプローチを開発し、SNRの向上、低RFパワーとピーク振幅を実現し、スラブ境界アーティファクト。 
[概要]プロジェクトは、強化されたsnr、低rf電力、およびピーク持続時間を達成するために3,000米ドル（博物館）によって開発されました。博物館のイメージングは、動きによる影響を最小限に抑えました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-01">
        <br><font color="black">2020-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Resolution 3D Convolutional Neural Networks for Automatic Coronary
  Centerline Extraction in Cardiac CT Angiography Scans -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.IV/paper_5.html">
      <font color="black">Multi-Resolution 3D Convolutional Neural Networks for Automatic Coronary
  Centerline Extraction in Cardiac CT Angiography Scans</font>
    </a>
  </h2>
  <font color="black">反復トラッカーは、心臓のモデルベースのセグメンテーションから導出された2つの小孔ランドマークのみに基づいて左右の冠状動脈ツリー全体を検出します。3DCNNは、43のCCTAスキャンで構成される独自のデータセットでトレーニングされました。洗練された手動セグメンテーションと比較して、87.1％および臨床的に関連する89.1％のオーバーラップが得られました。 
[ABSTRACT]デュアルパスウェイ畳み込みニューラルネットワーク（cnn）は、冠状動脈の方向と分岐の存在を予測します。提案された方法は、cat08データセットの最新の自動中心線抽出技術よりも優れたオーバーラップスコアを達成しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-02">
        <br><font color="black">2020-10-02</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervision Closes the Gap Between Weak and Strong Supervision in
  Histology -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.IV/paper_6.html">
      <font color="black">Self-Supervision Closes the Gap Between Weak and Strong Supervision in
  Histology</font>
    </a>
  </h2>
  <font color="black">これらの実験を通じて、自己教師あり学習を介してトレーニングされた特徴抽出器が、組織学における既存の機械学習技術を大幅に改善するためのドロップイン代替として機能できることを示します。機械学習を組織病理学に適用するための最大の課題の1つは、弱い教師ありです。スライド画像には数十億のピクセルがありますが、多くの場合1つのグローバルラベルしかありません。最後に、学習した埋め込みスペースが生物学的に意味のある組織構造の分離を示すことを示します。 
[要約]最先端技術は、強く-教師ありモデルのトレーニングに依存しています。これらには、99に達する弱い-教師ありモデルが含まれます。3％auc</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Recovery of surfaces and functions in high dimensions: sampling theory
  and links to neural networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.IV/paper_7.html">
      <font color="black">Recovery of surfaces and functions in high dimensions: sampling theory
  and links to neural networks</font>
    </a>
  </h2>
  <font color="black">特徴の低ランクのプロパティは、表面を回復するために必要な測定の数を決定するために使用されます。この論文では、表面の結合に存在する信号の回復に焦点を当てます。指数マッピングが変換されることを示します。低次元部分空間の和集合へのデータ。 
[概要]多様体に存在する信号と機能の回復の理解はあまり理解されていません。特に、滑らかな帯域の結合に存在する信号を考慮します-高次元の限られた表面</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-26">
        <br><font color="black">2020-05-26</font>
      </time>
    </span>
</section>
<!-- paper0: Noise2Kernel: Adaptive Self-Supervised Blind Denoising using a Dilated
  Convolutional Kernel Architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.IV/paper_8.html">
      <font color="black">Noise2Kernel: Adaptive Self-Supervised Blind Denoising using a Dilated
  Convolutional Kernel Architecture</font>
    </a>
  </h2>
  <font color="black">提案手法を様々な例を用いて最先端のノイズ除去手法と比較することにより、その有効性を実証した。本論文では、不変特性を満たし、ランダムなしで効率的なカーネルベースのトレーニングを可能にする拡張畳み込みネットワークを提案する。マスキング..この仮定により、ブラインドノイズ除去技術は、ソルトアンドペッパーノイズなどの極端なノイズによって大幅に破損した画像の輝度シフトの問題を抱えます。 
[概要]現在の教師なしノイズ除去方法のほとんどは、ゼロ（信号下の平均ノイズ）に依存しない条件で構築されています。したがって、ブラインドノイズ除去方法では、ノイズ除去プロセスの不変性を確保するためのトレーニングにランダムマスキングネットワークが必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Kernel based Matched Filter Approach for Segmentation of
  Retinal Blood Vessels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.IV/paper_9.html">
      <font color="black">Efficient Kernel based Matched Filter Approach for Segmentation of
  Retinal Blood Vessels</font>
    </a>
  </h2>
  <font color="black">得られた結果は、提案された方法が他よりも優れた性能を有することを確認します。取得したMFR画像に大津しきい値法を適用して血管を抽出しました。提案されたアプローチは、2つのオンラインで利用可能なDRIVEおよびSTAREデータセットで調査および検証されました。 
[概要]提案された整合フィルターカーネルは、網膜血管プロファイルをより正確に照合します。新しい整合フィルターは、整合フィルター応答（mfr）画像を生成するために使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: MoGlow: Probabilistic and controllable motion synthesis using
  normalising flows -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.IV/paper_10.html">
      <font color="black">MoGlow: Probabilistic and controllable motion synthesis using
  normalising flows</font>
    </a>
  </h2>
  <font color="black">このアプローチは、モーションやキャラクターの形態に関して制限的なタスク固有の仮定を行わないため、原則としてあらゆるタイプのモーションに適用できます。人間と四足歩行のモーションキャプチャデータセットでモデルを評価します。モデルは自動回帰であり、LSTMを使用して任意の長い時間依存性を有効にします。 
[要約]提案された方法は、制限的なタスクを行わないため、あらゆるタイプのモーションに適用できます-モーションに関する特定のアプリケーション</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-16">
        <br><font color="black">2019-05-16</font>
      </time>
    </span>
</section>
<!-- paper0: Extraction of hierarchical functional connectivity components in human
  brain using resting-state fMRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.IV/paper_11.html">
      <font color="black">Extraction of hierarchical functional connectivity components in human
  brain using resting-state fMRI</font>
    </a>
  </h2>
  <font color="black">また、私たちの方法を既存の階層的コミュニティ検出アプローチと比較します。この論文の目的は、高ランク分解の線形結合によって低ランク分解が形成される相関行列を使用して、解釈可能な階層パターンを抽出することです。人間の脳の機能的組織への洞察。 
[概要]このメソッドは、2つの異なる実世界のデータセットで開発されました。これは、安静時fmriを使用して人間の脳内のワイヤレス接続コンポーネントを抽出するための新しいメソッドを提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-19">
        <br><font color="black">2019-06-19</font>
      </time>
    </span>
</section>
<!-- paper0: The Role of Regularization in Shaping Weight and Node Pruning Dependency
  and Dynamics -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.IV/paper_12.html">
      <font color="black">The Role of Regularization in Shaping Weight and Node Pruning Dependency
  and Dynamics</font>
    </a>
  </h2>
  <font color="black">小さい重みのゼロ化に有利な確率関数からサンプリングすることにより、重みの剪定の新しいフレームワークを提示します。次に、一般的な分類モデルで重み減衰正規化子と組み合わせて使用した場合の、提案された確率的フレームワークの有効性を示します。 MNIST分類用のMLPのノード、CIFAR10分類用のVGG-16のフィルターの60％、およびU-Netのチャネルの60％（たとえば、セグメンテーション）とCNNのチャネルの50％を削除する医療画像モデルCOVID-19検出のモデル..これらのノードプルーニングネットワークについて、元の高密度ネットワークよりもわずかに精度が低い、競争力のある重みプルーニング結果も示します。 
[要約]ノードの剪定されたネットワークについては、元の密なネットワークよりもわずかに精度が低い、競争力のある重みの剪定結果も示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Robustness Investigation on Deep Learning CT Reconstruction for
  Real-Time Dose Optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.IV/paper_13.html">
      <font color="black">Robustness Investigation on Deep Learning CT Reconstruction for
  Real-Time Dose Optimization</font>
    </a>
  </h2>
  <font color="black">2つの投影または4つの投影から直接画像再構成用のAUTOMAPモデルをトレーニングします。テスト結果では、再構成に2つの投影を使用すると、数字「2」が「3」または「5」と誤って予測され、誤った率に達します。 94.4％の..後続の実験では、MNISTデータセットは、トレーニングセットに9桁のみが含まれ、テストセットには除外された桁のみが含まれるように分割されます（例：「2」）。 
[ABSTRACT] automapは、ほとんどの数字をそれぞれ1.6％と6.8％の偽率でうまく再構築できます。テスト結果では、数字「2」は「3」または「5」と誤って予測されます。再構成に2つの投影を使用</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Fast Pattern Recognition for Electron Emission Micrograph Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.IV/paper_14.html">
      <font color="black">Fast Pattern Recognition for Electron Emission Micrograph Analysis</font>
    </a>
  </h2>
  <font color="black">アルゴリズムは高速で、Intel Core i5のリソースを使用して1つの顕微鏡写真を処理および分析するのに$ \ sim $ 10秒しかかかりません。この作業では、電子放出顕微鏡写真を処理および分析するためのパターン認識アルゴリズムが開発されました。dcのさまざまな例エミッタの空間位置と分布を決定し、見かけの放射領域を計算するためのこのアルゴリズムの適用性を示すrf放射が与えられています。 
[要約]アルゴリズムは、見かけのIntel Coreを決定するための適用性です。アルゴリズムは、プロセスがどのように処理されたかを調べます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Memory-based Jitter: Improving Visual Recognition on Long-tailed Data
  with Diversity In Memory -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_0.html">
      <font color="black">Memory-based Jitter: Improving Visual Recognition on Long-tailed Data
  with Diversity In Memory</font>
    </a>
  </h2>
  <font color="black">その結果、入力と同じ画像が与えられた場合、モデルの2つの履歴エディションは、深く埋め込まれた空間に2つの異なる特徴を生成し、\ emph {特徴ジッター}をもたらします。蓄積されたジッターはテールクラスのクラス内多様性を強化します。その結果、ロングテールの視覚認識が向上します。ロングテールのデータ分布では、大多数のクラス（つまり、テールクラス）は比較的少数のサンプルしか占有せず、クラス内の多様性が不足する傾向があります。 
[概要]根本的な解決策は、より高い多様性でテールクラスを拡張することです。一般的には、深い分類と深いメトリック学習の2つの機能を検討します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-22">
        <br><font color="black">2020-08-22</font>
      </time>
    </span>
</section>
<!-- paper0: CompFeat: Comprehensive Feature Aggregation for Video Instance
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_1.html">
      <font color="black">CompFeat: Comprehensive Feature Aggregation for Video Instance
  Segmentation</font>
    </a>
  </h2>
  <font color="black">集約プロセスは、学習された特徴の識別力を大幅に向上させる新しい注意メカニズムを使用して慎重に設計されています。単一フレームの特徴のみを使用することによって生じるあいまいさを排除するために、新しい包括的な特徴集約アプローチ（CompFeat）を提案して、フレームレベルとオブジェクトレベルの両方で、時間的および空間的なコンテキスト情報を使用します。機能の類似性と空間の類似性の両方を組み込むことにより、シャムデザインを通じてモデルの追跡機能をさらに向上させます。 
[概要]以前のアプローチでは、オブジェクトの検出、セグメンテーション、追跡に単一フレーム機能のみを使用していました。これらには、モーションブラーや大幅な外観の変更が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: F3RNet: Full-Resolution Residual Registration Network for Deformable
  Image Registration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_2.html">
      <font color="black">F3RNet: Full-Resolution Residual Registration Network for Deformable
  Image Registration</font>
    </a>
  </h2>
  <font color="black">もう一方のストリームは、深いマルチスケール残余表現を学習して、ロバストな認識を取得します。提案された方法は、残余学習方式で2つの並列処理ストリームを組み合わせます。臨床的に取得された患者内腹部CT-MRIデータセットで提案された方法を検証します。公共の吸気および呼気胸部CTデータセット。 
[概要]ディープラーニングアプローチはかなりの人気と成功を収めていますが、一部の重度の変形領域の正確な位置合わせは見過ごされがちです。これらの領域は、手術対象を特定するために重要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-15">
        <br><font color="black">2020-09-15</font>
      </time>
    </span>
</section>
<!-- paper0: Physics-informed neural networks for myocardial perfusion MRI
  quantification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_3.html">
      <font color="black">Physics-informed neural networks for myocardial perfusion MRI
  quantification</font>
    </a>
  </h2>
  <font color="black">トレーサー動態モデルは、動的造影剤増強磁気共鳴（MR）画像からの血流などの動態パラメーターの定量化を可能にします。この研究では、心筋灌流MR定量化を実行する手段として、物理情報に基づく神経ネットワーク（PINN）を紹介します。動的パラメータを推測するための用途の広いスキームを提供します。これにより、パラメータの推定が不正確になる可能性があります。 
[概要]これらのニューラルネットワークは、ピンの観測データに適合するようにトレーニングできます。これは、動的であり、血流と微小血管機能を直接解決するためです。ただし、これにより、モデルモデルモデルモデルが不正確になる可能性があります。これにより、モデルモデルが改善される可能性があります。インシリコとマウスの両方のモデルモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Tubular Shape Aware Data Generation for Semantic Segmentation in Medical
  Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_4.html">
      <font color="black">Tubular Shape Aware Data Generation for Semantic Segmentation in Medical
  Imaging</font>
    </a>
  </h2>
  <font color="black">胸部X線検査は人体で最も普及している検査の1つです。この作業では、人工データを使用して注釈付き画像の不足を軽減することを目指しています。具体的には、チューブの合成データ生成のアプローチを示します。事前の形状制約で正規化された生成的敵対的ネットワークを持つ形状のオブジェクト。 
[要約]インターベンショナルラジオロジーでは、X線画像の使用は、オブジェクトのようなさまざまなチューブを視覚化する必要性と関連していることがよくあります。目的は、X線やカテーテルなどの一連の画像を作成することです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-02">
        <br><font color="black">2020-10-02</font>
      </time>
    </span>
</section>
<!-- paper0: Devil's in the Details: Aligning Visual Clues for Conditional Embedding
  in Person Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_5.html">
      <font color="black">Devil's in the Details: Aligning Visual Clues for Conditional Embedding
  in Person Re-Identification</font>
    </a>
  </h2>
  <font color="black">実験は、CACE-Netが3つの公開データセットで最先端のパフォーマンスを達成することを示しています。全体的な視覚的特徴に加えて、詳細情報の照合と比較もこれらの課題に取り組むために不可欠です。次に、条件付き特徴の埋め込みには全体的なものが必要です。クエリ画像の機能は、一致するギャラリー画像に基づいて動的に調整されますが、既存のメソッドのほとんどは参照画像を無視します。 
[ABSTRACT]新しいメソッドは、視覚的な機能を統合されたフレームワークに結合します。新しいメソッドは、cace-net（3）lue（a）lignmentおよび（c）onditional（e）mbeddingと呼ばれます）</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-11">
        <br><font color="black">2020-09-11</font>
      </time>
    </span>
</section>
<!-- paper0: LORCK: Learnable Object-Resembling Convolution Kernels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_6.html">
      <font color="black">LORCK: Learnable Object-Resembling Convolution Kernels</font>
    </a>
  </h2>
  <font color="black">具体的には、拡張された中空カーネルアーキテクチャは、最先端の空間セグメンテーションモデルよりも優れていますが、Bi-LSTMなどの時間ブロックを追加すると、膀胱セグメンテーションの課題に対する新しいマルチクラスベースラインが確立されます。結果セグメント化されたオブジェクトの形状を使用して、セグメンテーションの結果を高めるための適切な畳み込みカーネルを形成できる、他のドメイン固有の深層学習アプリケーションへの道を開きます。中空カーネルに基づく時空間モデルは、の平均ダイススコアに達します。膀胱の内壁、外壁、および腫瘍領域について、それぞれ0.936、0.736、および0.712。 
[概要]一連のuツアーをトレーニングして、オストロールシステムを開発します。さまざまな組織でこのアイデアの利点を実証しました。ただし、壁とがん領域の正確な位置特定は、腫瘍学の重要なステップです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-09">
        <br><font color="black">2020-07-09</font>
      </time>
    </span>
</section>
<!-- paper0: Super-Selfish: Self-Supervised Learning on Images with PyTorch -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_7.html">
      <font color="black">Super-Selfish: Self-Supervised Learning on Images with PyTorch</font>
    </a>
  </h2>
  <font color="black">フレームワークは使いやすく、わずか2行のコードでPyTorchニューラルネットワークを事前トレーニングできます。同時に、モジュラー設計の選択により完全な柔軟性が維持されます。コードはhttps://github.com/MECLabTUDA/にあります。 Super_Selfishであり、pip installsuper-selfishを使用してインストールされます。 
[抽象]学習は、単純な分類からより複雑な最先端の対照的な口実タスクに及ぶ13のアルゴリズムで学習できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-04">
        <br><font color="black">2020-12-04</font>
      </time>
    </span>
</section>
<!-- paper0: Rethinking movie genre classification with fine-grained semantic
  clustering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_8.html">
      <font color="black">Rethinking movie genre classification with fine-grained semantic
  clustering</font>
    </a>
  </h2>
  <font color="black">対照的な損失を使用して、この「粗い」ジャンル分類ネットワークを引き続き微調整し、すべてのジャンルラベルにわたる映画間の高レベルのテキスト間類似性を識別します。これにより、に基づいて、より「きめ細かい」詳細なクラスタリングが実現します。一部のジャンル情報を保持しながら、セマンティックの類似性。映画のマルチモーダルコンテンツ内の「きめ細かい」セマンティック情報を識別することにより、これらの「粗い」ジャンルラベルを拡張します。 
[ABSTRACT]ユニバーサルユニバーサルユニバーサル情報は単一のジャンル内で開発できますが、「マルチラベルジャンル」のバリエーションが多数存在する可能性があります。これにより、より「きめ細かい」分類が可能になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-04">
        <br><font color="black">2020-12-04</font>
      </time>
    </span>
</section>
<!-- paper0: TinyTL: Reduce Memory, Not Parameters for Efficient On-Device Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_9.html">
      <font color="black">TinyTL: Reduce Memory, Not Parameters for Efficient On-Device Learning</font>
    </a>
  </h2>
  <font color="black">適応能力を維持するために、新しいメモリ効率の高いバイアスモジュールであるライト残余モジュールを導入し、わずか3.8％のメモリオーバーヘッドを追加する小さな残余特徴マップを学習することで特徴抽出器を改良します。広範な実験により、TinyTLはメモリを大幅に節約することが示されています（最大6.5x）、ネットワーク全体を微調整する場合と比較して、精度の低下はほとんどありません。TinyTLは、バイアスモジュールのみを学習する一方で、重みをフリーズするため、中間アクティベーションを保存する必要はありません。 
[ABSTRACT] tiny-転送-メモリの学習（tinytl）-効率的-デバイス学習。実行中、tinytlは大幅な精度の向上を提供します。新しいメモリを提供します-特徴抽出器を改良するための効率バイアスモジュール</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-22">
        <br><font color="black">2020-07-22</font>
      </time>
    </span>
</section>
<!-- paper0: Scaling Out-of-Distribution Detection for Real-World Settings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_10.html">
      <font color="black">Scaling Out-of-Distribution Detection for Real-World Settings</font>
    </a>
  </h2>
  <font color="black">私たちの新しいベンチマークは、リアリズムと異常の多様性の両方を組み込んだ異常セグメンテーションの2つのデータセットを組み合わせたものです。これらの結果は、新しい異常セグメンテーションベンチマークとともに、分布外検出の将来の研究への扉を開きます。現実的な分布外検出では、小規模な設定から離れて、高解像度の画像と数百のクラスを使用して、大規模なマルチクラスおよびマルチラベル設定を調査します。 
[ABSTRACT]既存の研究は主に単純な小規模設定に焦点を当てています。異常なオブジェクトセグメンテーションベンチマークを組み合わせることによって導入された新しいベンチマーク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-25">
        <br><font color="black">2019-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Meta Ordinal Regression Forest For Learning with Unsure Lung Nodules -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_11.html">
      <font color="black">Meta Ordinal Regression Forest For Learning with Unsure Lung Nodules</font>
    </a>
  </h2>
  <font color="black">肺結節分類の順序関係をさらに調査するために、この論文では、メタ順序回帰フォレスト（MORF）を提案します。これは、最先端の順序回帰手法である深順序回帰フォレスト（DORF）を3つの主要な方法で改善します。 ..まず、MORFは深い特徴を最大限に活用することで予測の偏りを軽減できますが、DORFはトレーニング前に決定ツリーの構成を修正する必要があります。LIDC-IDRIデータセットの実験結果は、以下を含む既存の方法よりも優れたパフォーマンスを示しています。最先端のDORF。 
[概要]システムは、不確実な人々を支援するように設計されています。これらには、分類の影響を軽減できる深い機能が含まれています。morfは、深い機能を最大限に活用することで分類の技術を軽減することもできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Revisiting Street-to-Aerial View Image Geo-localization and Orientation
  Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_12.html">
      <font color="black">Revisiting Street-to-Aerial View Image Geo-localization and Orientation
  Estimation</font>
    </a>
  </h2>
  <font color="black">近似回転不変活性化マップに関する発見により、位置合わせ情報が不明なクロスビュー画像のペア間の方向/位置合わせを推定する新しい方法を提案します。ストリートから空中の画像の地理的位置特定。ストリートビュー画像をリファレンスセットのGPSタグ付き航空画像にクエリすることは、最近ますます注目を集めています。単純なシャムネットワークのパフォーマンスはアライメント設定に大きく依存し、以前の作品の比較は不公平になる可能性があることを示しますそれらが異なる仮定を持っている場合。 
[概要]この論文では、画像の位置合わせ情報の問題を再検討します。特徴抽出に焦点を当てるのではなく、改善により、位置合わせに関係なくパフォーマンスが大幅に向上することを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-23">
        <br><font color="black">2020-05-23</font>
      </time>
    </span>
</section>
<!-- paper0: VideoMix: Rethinking Data Augmentation for Video Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_13.html">
      <font color="black">VideoMix: Rethinking Data Augmentation for Video Classification</font>
    </a>
  </h2>
  <font color="black">VideoMixは、ビデオ直方体を別のビデオに挿入することにより、新しいトレーニングビデオを作成します。VideoMixは、Kineticsおよび挑戦的なSomething-Something-V2ベンチマークで他の拡張ベースラインを一貫して上回ります。また、THUMOS&#39;14での弱く監視されたアクションローカリゼーションパフォーマンスも向上します。 
[ABSTRACT] videomixは、グラウンドトゥルースラベルを分析して、各ビデオのオブジェクトの数を示します。videomixは、反応速度論および挑戦的な何か-何か-v2ベンチマークで他の拡張ベースラインを一貫して上回っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Geo-PIFu: Geometry and Pixel Aligned Implicit Functions for Single-view
  Human Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_14.html">
      <font color="black">Geo-PIFu: Geometry and Pixel Aligned Implicit Functions for Single-view
  Human Reconstruction</font>
    </a>
  </h2>
  <font color="black">クエリポイントのエンコードと潜在的なボクセル機能を使用したグローバル形状の制約の両方により、衣服を着た人間のメッシュに対して取得した再構成は、競合する方法と比較して、形状の歪みが少なく、表面の詳細が改善されていることを示します。最近の人間のメッシュでGeo-PIFuを評価します。 PIFuおよび以前の派生作業で使用されたプライベート商用データセットよりも$ 10 \ times $大きいパブリックデータセット。服を着た人物の単眼カラー画像から3Dメッシュを復元する方法であるGeo-PIFuを提案します。 
[ABSTRACT]私たちの方法は、深い陰関数に基づいています-構造を使用して潜在的なボクセルの特徴を学習するための表現に基づいています-認識3d u-net.2つの方法でモデルを制約します：問題点の特徴のあいまいさを解決するため、2番目、高解像度メッシュを規則化し、グローバルな形状の規則性を促進するための大まかな人間の形状プロキシとして機能する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Resolution 3D Convolutional Neural Networks for Automatic Coronary
  Centerline Extraction in Cardiac CT Angiography Scans -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_15.html">
      <font color="black">Multi-Resolution 3D Convolutional Neural Networks for Automatic Coronary
  Centerline Extraction in Cardiac CT Angiography Scans</font>
    </a>
  </h2>
  <font color="black">Wolterink（arXiv：1810.03143）によって血管トラッカーを拡張するディープラーニングベースの自動冠状動脈ツリー中心線トラッカー（AuCoTrack）を提案します。3DCNNは、43のCCTAスキャンで構成される独自のデータセットでトレーニングされました。平均感度87.1洗練された手動セグメンテーションと比較して、89.1％の％および臨床的に関連するオーバーラップが得られました。 
[ABSTRACT]デュアルパスウェイ畳み込みニューラルネットワーク（cnn）は、冠状動脈の方向と分岐の存在を予測します。提案された方法は、cat08データセットの最新の自動中心線抽出技術よりも優れたオーバーラップスコアを達成しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-02">
        <br><font color="black">2020-10-02</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Instrumentalist Net: Unsupervised Generation of Music from Body
  Movements -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_16.html">
      <font color="black">Multi-Instrumentalist Net: Unsupervised Generation of Music from Body
  Movements</font>
    </a>
  </h2>
  <font color="black">パイプラインがビデオ内の楽器によって再生されている音楽の正確なコンテンツを生成するように、Midiが潜在空間をさらに調整できることを示します。体の動きのエンコーダーとの事前の共同トレーニングは、音楽のもつれを解くことに成功します。音楽コンポーネントと楽器の特徴を示す潜在的な特徴に..楽器にラベルを付けずにビデオからマルチ楽器の音楽を生成することを学ぶことは挑戦的な問題です。 
[概要]パイプラインは、ログからさまざまな楽器の音楽の離散潜在表現を学習します-スペクトログラム。vq-vaeアーキテクチャは、追加の条件付けで詳細な音楽生成をサポートします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Attention-based Saliency Hashing for Ophthalmic Image Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_17.html">
      <font color="black">Attention-based Saliency Hashing for Ophthalmic Image Retrieval</font>
    </a>
  </h2>
  <font color="black">ASHは、空間的注意モジュールを組み込んで、顕著な領域の表現にさらに焦点を当て、眼科画像の差別化におけるそれらの重要な役割を強調します。眼科画像データセットの2つの異なるモダリティに関する広範な実験は、提案されたASHが比較して検索パフォーマンスをさらに改善できることを示しています。空間注意モジュールの多大な貢献による最先端のディープハッシュ法..ディープハッシュ法は、臨床医の参照ベースの診断を支援する大規模な医療画像検索に効果的であることが証明されています。 
[ABSTRACT]ディープハッシュは、ディープネットワークの学習能力を十分に活用して顕著な領域の特徴をキャプチャするわけではありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Differentiable Augmentation for Data-Efficient GAN Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_18.html">
      <font color="black">Differentiable Augmentation for Data-Efficient GAN Training</font>
    </a>
  </h2>
  <font color="black">DiffAugmentを使用すると、ImageNet 128x128でISが100.8、FFHQとLSUNで1,000枚の画像が与えられた場合にFIDを2〜4倍削減して6.80の最先端のFIDを実現できます。コードはhttps：// githubで入手できます。 com / mit-han-lab / data-efficient-gans ..さらに、わずか20％のトレーニングデータで、CIFAR-10とCIFAR-100の最高のパフォーマンスに匹敵することができます。 
[ABSTRACT] diffaugmentを使用すると、生成されたサンプルに微分可能な拡張を採用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br><font color="black">2020-06-18</font>
      </time>
    </span>
</section>
<!-- paper0: PFA-GAN: Progressive Face Aging with Generative Adversarial Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_19.html">
      <font color="black">PFA-GAN: Progressive Face Aging with Generative Adversarial Network</font>
    </a>
  </h2>
  <font color="black">提案されたフレームワークは、蓄積されたアーティファクトとぼやけを排除するためにエンドツーエンドの方法でトレーニングできます。顔の老化は、特定の顔をレンダリングして将来の外観を予測することです。これは、情報フォレンジックとセキュリティの分野で重要な役割を果たします。顔の外観は通常、年齢によって異なります。既存のcGANベースの方法とは異なり、提案されたフレームワークには、若いものから古いものへの顔の老化プロセスを模倣するいくつかのサブネットワークが含まれ、それぞれが2つの隣接する年齢の間の特定の老化効果のみを学習します。グループ。 
[概要]新しい論文は、古いバージョンのエイジングシステムに基づく新しい顔のエイジングフレームワークを提案しています。新しい方法は、単一のネットワークを使用して、2つの異なる年齢グループ間のさまざまなエイジング効果を学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: An Approach to Intelligent Pneumonia Detection and Integration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_20.html">
      <font color="black">An Approach to Intelligent Pneumonia Detection and Integration</font>
    </a>
  </h2>
  <font color="black">また、さまざまな技術的、法的、倫理的、およびロジスティックスの問題に対処し、可能な解決策の青写真を示します。毎年、250万人以上が肺炎で亡くなっていますが、そのほとんどが先進国です
[1]。肺炎の検出におけるAIの使用は、特に、局所的に達成された結果を一般化する際の課題のために制限されています。 
[概要]多くの診断支援が開発されており、AIベースの方法で高精度を実現しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: PMP-Net: Point Cloud Completion by Learning Multi-step Point Moving
  Paths -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_21.html">
      <font color="black">PMP-Net: Point Cloud Completion by Learning Multi-step Point Moving
  Paths</font>
    </a>
  </h2>
  <font color="black">不完全な入力の各ポイントを移動してポイントクラウドを完成させます。ポイントクラウドでは、ポイント移動パス（PMP）の合計距離が最短になります。具体的には、PMP-Netという名前の新しいニューラルネットワークを設計して、の動作を模倣します。アースムーバー..したがって、PMP-Netは、合計ポイント移動距離の制約に従って、各ポイントの一意のポイント移動パスを予測します。 
[概要]広く使用されている戦略は、不完全な点群から完全な点群を生成することです。これは、点移動パスの合計距離（pmp）が最短になる点群を作成することを目的としています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Siamese Basis Function Networks for Defect Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_22.html">
      <font color="black">Siamese Basis Function Networks for Defect Classification</font>
    </a>
  </h2>
  <font color="black">基本的な考え方は、類似性スコアを使用して比較によって分類することです。次に、カーネルは、データセット内の他の画像から中心を区別できるようにエンコーディングを生成するようにトレーニングされます。このアプローチを使用して、作成者はある種のクラスを作成しました。シャムカーネル内の認識。 
[概要]シャムカーネルは基底関数ネットワークで使用されます。次に、データセット内の他の画像から中心を区別する方法でソロモンを生成するようにトレーニングされます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-02">
        <br><font color="black">2020-12-02</font>
      </time>
    </span>
</section>
<!-- paper0: Seesaw Loss for Long-Tailed Instance Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_23.html">
      <font color="black">Seesaw Loss for Long-Tailed Instance Segmentation</font>
    </a>
  </h2>
  <font color="black">一方、補正要素は、テールカテゴリの誤検知を回避するために、誤分類されたインスタンスのペナルティを増やします。緩和要素は、テールカテゴリへの罰を減らします。その結果、テールカテゴリのオブジェクトは、背景またはヘッドカテゴリとして誤って分類される可能性が高くなります。 
[要約]テールクラスの負のサンプルの圧倒的なスケールは、分類器の偏った学習プロセスにつながります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-23">
        <br><font color="black">2020-08-23</font>
      </time>
    </span>
</section>
<!-- paper0: A Comprehensive Review for MRF and CRF Approaches in Pathology Image
  Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_24.html">
      <font color="black">A Comprehensive Review for MRF and CRF Approaches in Pathology Image
  Analysis</font>
    </a>
  </h2>
  <font color="black">次に、病理画像解析のMRFとCRFに関する最近の研究の徹底的なレビューを示します。最初に、2つの確率場と病理画像の背景を紹介します。次に、MRFとCRFの基本的な数学的知識を要約します。モデリングから最適化。 
[概要]コンピュータ支援診断（cad）システムの数が提案されています。その中で、mrfsと条件付き確率場（crfs）は2つの人気のある確率場モデルです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-29">
        <br><font color="black">2020-09-29</font>
      </time>
    </span>
</section>
<!-- paper0: Referring Expression Comprehension: A Survey of Methods and Datasets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_25.html">
      <font color="black">Referring Expression Comprehension: A Survey of Methods and Datasets</font>
    </a>
  </h2>
  <font color="black">この調査の第2部では、RECシステムのトレーニングと評価に使用できるデータセットを確認します。クエリされたオブジェクトラベルが事前定義されているオブジェクト検出タスクとは異なり、REC問題はテスト中にクエリを監視することしかできません。このタスクは、コンピュータビジョンと自然言語処理コミュニティの両方から多くの注目を集めており、CNN-RNNモデル、モジュラーネットワークから複雑なグラフベースのモデルまで、いくつかの作業ラインが提案されています。 
[概要] rec問題はテスト中にのみクエリを観察できます。このタスクはコンピュータビジョンと自然言語処理コミュニティから多くの注目を集めています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-19">
        <br><font color="black">2020-07-19</font>
      </time>
    </span>
</section>
<!-- paper0: Interpreting Deep Neural Networks with Relative Sectional Propagation by
  Analyzing Comparative Gradients and Hostile Activations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_26.html">
      <font color="black">Interpreting Deep Neural Networks with Relative Sectional Propagation by
  Analyzing Comparative Gradients and Hostile Activations</font>
    </a>
  </h2>
  <font color="black">結果は、私たちの方法が、独特で直感的な視覚化を含む既存の後方分解方法よりも優れていることを示しています。その結果、各属性を維持しながら、ターゲット（正）および敵対（負）の属性の双極関連性スコアを割り当てることができます。重要性に合わせて..検証済みの実験環境で、評価の結果を報告します：（i）ポインティングゲーム、（ii）mIoU、および（iii）PASCAL VOC 2007、MS COCO 2014、およびImageNetデータセットを使用したモデル感度。 
[概要]この論文では、クラスの特性（識別属性と明確な客観性）を使用して予測を完全に分解するための新しい属性方法を提案します。敵対的要因を、属性の検索を妨害し、識別可能な方法で伝播する要素として定義します。活性化されたニューロンの抑制されていない性質を克服する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Rethinking Learnable Tree Filter for Generic Feature Transform -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_27.html">
      <font color="black">Rethinking Learnable Tree Filter for Generic Feature Transform</font>
    </a>
  </h2>
  <font color="black">オブジェクト検出/インスタンスセグメンテーションに関する広範な実験により、元のバージョンに対する一貫した改善が実証されています。コードはhttps://github.com/StevenGrove/LearnableTreeFilterV2で入手できます。セマンティックセグメンテーションについては、ベルとホイッスルのないCityscapesベンチマーク。 
[概要]アルゴリズムは、元の微分不可能なものを置き換えるように設計されています。また、時間の柔軟性と堅牢性も向上します。新しいコードはgithubで入手できます。 com / learnabletreefilterv2</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Joint Encoding of Motion and Appearance for First Person
  Action Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_28.html">
      <font color="black">Self-Supervised Joint Encoding of Motion and Appearance for First Person
  Action Recognition</font>
    </a>
  </h2>
  <font color="black">この論文では、これら2つの情報チャネルから共同で機能を学習することが、2つの間の時空間相関をより適切にキャプチャするのに有益であると主張します。この目的のために、口実の動き予測タスクを使用して動きと外観の知識を絡み合わせる自己監視ブロック。エゴセントリックアクション認識の未解決の課題は、ビデオが主な俳優のポーズに関する詳細な情報を欠いているため、焦点を合わせるときに動きの一部のみを記録する傾向があることです。操作タスクについて。 
[概要]ビデオには、主演俳優のポーズに関する詳細な情報がありません。これは、動きの一部のみを記録する傾向があるためです。これらには、動きと外観の知識が絡み合う自己監視ブロックが含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-10">
        <br><font color="black">2020-02-10</font>
      </time>
    </span>
</section>
<!-- paper0: Classification of Chinese Handwritten Numbers with Labeled Projective
  Dictionary Pair Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_29.html">
      <font color="black">Classification of Chinese Handwritten Numbers with Labeled Projective
  Dictionary Pair Learning</font>
    </a>
  </h2>
  <font color="black">さらに、HOG機能と辞書学習の組み合わせにより、ピクセルドメインデータのみを使用する場合と比較して、精度が$ 11 \％$向上します。辞書の設計にHOG機能を使用する理由は、混雑した詳細を記述する際の強みです。画像..これらのメトリックを統一されたコスト関数に統合し、新しい特徴空間、つまり方向付けられた勾配のヒストグラム（HOG）を採用して、辞書アトムを生成しました。 
[概要]提案された方法は、辞書の辞書を最大化することです。学習した辞書の識別可能性を同時に最大化することです。これらのメトリックを結合コスト関数に統合し、新しい特徴空間を採用して辞書アトムを作成しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-26">
        <br><font color="black">2020-03-26</font>
      </time>
    </span>
</section>
<!-- paper0: Boosting Image Super-Resolution Via Fusion of Complementary Information
  Captured by Multi-Modal Sensors -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_30.html">
      <font color="black">Boosting Image Super-Resolution Via Fusion of Complementary Information
  Captured by Multi-Modal Sensors</font>
    </a>
  </h2>
  <font color="black">次に、特徴レベルのマルチスペクトル融合残余ネットワークモデルを設計し、マルチスペクトル画像で提示される共起特徴を適応的に統合することにより、熱画像の高精度SRを実行します。画像超解像（SR）は、画像を強化するための有望な手法を提供します。低解像度の光学センサーの品質により、幅広いロボット工学アプリケーションでより優れたターゲット検出と自律ナビゲーションが容易になります。この論文では、低コストのチャネル（可視/深度）からの補完的な情報を活用して画像を強調することを試みます。より少ないパラメータを使用する高価なチャネル（熱）の品質。 
[概要]この方法は通常、単一チャネル入力を使用してトレーニングおよびテストされます。これは、高解像度画像をキャプチャするコストが大幅に異なるためです。新しい方法では、ピクセル単位で位置合わせされた可視画像と熱画像を効果的に生成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Hyperspectral Classification Based on Lightweight 3-D-CNN With Transfer
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_31.html">
      <font color="black">Hyperspectral Classification Based on Lightweight 3-D-CNN With Transfer
  Learning</font>
    </a>
  </h2>
  <font color="black">従来の3-D-CNNモデルと比較して、提案された3-D-LWNetは、ネットワーク構造が深く、パラメーターが少なく、計算コストが低いため、分類パフォーマンスが向上します。小さなサンプルの問題をさらに軽減するために、2つも提案します。転送学習戦略：1）クロスセンサー戦略。より多くのラベル付きサンプルを含むソースHSIデータセットで3Dモデルを事前トレーニングし、それをターゲットHSIデータセットに転送します。2）クロスモーダル戦略、ここでは、多数のサンプルを含む2D RGB画像データセットで3Dモデルを事前トレーニングし、それをターゲットHSIデータセットに転送します。以前のアプローチとは対照的に、制限を課しません。ソースデータセット。ターゲットデータセットと同じセンサーで収集する必要はありません。 
[概要]提案された3-d-lwnetは、ネットワーク構造が深く、パラメーターが少なく、ブラウザーが少ないため、分類パフォーマンスが向上します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Selective Pseudo-Labeling with Reinforcement Learning for
  Semi-Supervised Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CV/paper_32.html">
      <font color="black">Selective Pseudo-Labeling with Reinforcement Learning for
  Semi-Supervised Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">この制限に対処するために、正確な疑似ラベル付きインスタンスと代表的な疑似ラベル付きインスタンスの両方を選択するための深いQ学習モデルを開発します。従来の疑似ラベル付け方法では、疑似ラベル付きデータの正確性と代表性のバランスを取ることは困難です。わずかなデータで識別機能を学習する際の大きなマージン損失の能力により、さらに、その識別可能性を改善するための基本モデルトレーニングの新しいターゲットマージン損失を提案します。 
[ABSTRACT]半教師ありドメイン適応（ssda）で開発されたシステム。従来の疑似ラベル付け方法では、疑似ラベル付けされたデータの正確性と選択性のバランスをとることは困難です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Analysis of Word Embeddings Using Fuzzy Clustering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CL/paper_0.html">
      <font color="black">Analysis of Word Embeddings Using Fuzzy Clustering</font>
    </a>
  </h2>
  <font color="black">異なる次元のGloVeとして知られるカウントベースの単語埋め込みで2つの一般的なファジークラスタリングアルゴリズムを使用します。そのような表現を生成するために使用されるいくつかのアプローチがあります。さらに、ファジークラスタリングがメンバーシップに関して興味深い結果を提供できることを示します。異なるクラスターへの単語の。 
[要約] wordsimからの単語-ゴールドスタンダードと呼ばれる353は、埋め込みとして表されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-17">
        <br><font color="black">2019-07-17</font>
      </time>
    </span>
</section>
<!-- paper0: From syntactic structure to semantic relationship: hypernym extraction
  from definitions by recurrent neural networks using the part of speech
  information -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CL/paper_1.html">
      <font color="black">From syntactic structure to semantic relationship: hypernym extraction
  from definitions by recurrent neural networks using the part of speech
  information</font>
    </a>
  </h2>
  <font color="black">上位概念抽出の既存のツールは、特定の意味パターンに依存するか、単語表現に焦点を合わせます。これらはすべて、特定の制限を示します。定義から上位概念を識別することは、自然言語処理および意味分析における重要なタスクです。 WordNetは一般的な単語に対して機能し、ドメイン固有のシナリオでのアプリケーションは制限されています。 
[要約]定義から上位概念を特定することは重要なタスクです。上位概念抽出のための既存のツールは、特定の意味パターンに依存するか、単語アプリケーションに焦点を合わせます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Emotion from 100 Observations: Unexpected Robustness of Deep
  Learning under Strong Data Limitations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CL/paper_2.html">
      <font color="black">Learning Emotion from 100 Observations: Unexpected Robustness of Deep
  Learning under Strong Data Limitations</font>
    </a>
  </h2>
  <font color="black">私たちの分析は、高品質で事前に訓練された単語の埋め込みがこれらの結果を達成するための主な要因であることを示唆しています。感情分析の研究者の大多数が、データを訓練するときに従来の機械学習よりも神経モデルが劣っていると実際に見なしていることを示すアンケート調査を実施します限られています。ディープラーニングの主な欠点の1つは、膨大な量のトレーニングデータが必要になることです。 
[概要]この手法は、リソースの少ない言語や感情分析など、注釈付きデータが限られている領域には適していないようです。英語、ポーランド語、ポルトガル語の証拠を提供し、一般的に使用されるニューラルアーキテクチャを驚くほど少ない観測でトレーニングできることを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-10-25">
        <br><font color="black">2018-10-25</font>
      </time>
    </span>
</section>
<!-- paper0: Clustering-based Automatic Construction of Legal Entity Knowledge Base
  from Contracts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CL/paper_3.html">
      <font color="black">Clustering-based Automatic Construction of Legal Entity Knowledge Base
  from Contracts</font>
    </a>
  </h2>
  <font color="black">ただし、そのようなKBは常に存在するわけではなく、短時間で作成することもできません。15のクライアントからのさまざまな品質の800の実際の契約で構成されるデータセットでメソッドを評価します。収集されたグラウンドトゥルースデータと比較して、メソッドは知識の84 \％を思い出すことができます。 
[概要]提案された方法は、前処理によってもたらされるさまざまなタイプのエラーに対してロバストです。これらには、光学式文字認識（ocr）と固有表現抽出（ner）が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-18">
        <br><font color="black">2020-11-18</font>
      </time>
    </span>
</section>
<!-- paper0: MLS: A Large-Scale Multilingual Dataset for Speech Research -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CL/paper_4.html">
      <font color="black">MLS: A Large-Scale Multilingual Dataset for Speech Research</font>
    </a>
  </h2>
  <font color="black">データセットは、http：//www.openslr.orgで誰でも無料で利用できるようになります。さらに、言語モデル（LM）とベースラインの自動音声認識（ASR）モデル、およびデータセット内のすべての言語を提供します。このような大規模な転写データセットは、ASRおよびText-To-Speech（TTS）研究に新しい道を開くと信じています。 
[ABSTRACT]データセットは8つの言語で構成されており、英語は44.5k時間、その他の言語は6k時間です。データセットは、asrとテキスト読み上げの研究に新しい道を開きます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Dialogue Discourse-Aware Graph Convolutional Networks for Abstractive
  Meeting Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CL/paper_5.html">
      <font color="black">Dialogue Discourse-Aware Graph Convolutional Networks for Abstractive
  Meeting Summarization</font>
    </a>
  </h2>
  <font color="black">最後に、リカレントニューラルネットワークを使用して要約を生成します。最初に、対話談話関係を含む会議テキスト全体を談話グラフに変換し、次にDDA-GCNを使用してグラフの意味表現をエンコードします。AMIでの実験結果データセットは、モデルがさまざまなベースラインを上回り、最先端のパフォーマンスを達成できることを示しています。 
[要約]要約を満たすための対話談話認識グラフ畳み込みネットワーク（dda-gcn）を開発します。対話談話を使用して、各発話間の事前定義された意味関係を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Predict and Use Latent Patterns for Short-Text Conversation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CL/paper_6.html">
      <font color="black">Predict and Use Latent Patterns for Short-Text Conversation</font>
    </a>
  </h2>
  <font color="black">割り当てられたセマンティクスがないと、投稿と応答の間のセマンティックマッピングがエンドツーエンドの方法でオンザフライで隠されるため、モデルは応答をきめ細かく制御できません。このペーパーでは、より詳細なセマンティックフォームを使用することを提案します。 、生成を導くための制御可能なセマンティクスとして、潜在的な応答と対応する分布からサンプリングされた品詞シーケンスを含みます。私たちの結果は、より豊富なセマンティクスが有益で多様な応答を提供できるだけでなく、全体を増加させることを示しています流暢さと一貫性を含む応答品質のパフォーマンス。 
[概要]それらのほとんどは、応答を作成するためにエンコーダーとデコーダーに依存しています。それらがない場合、それらの大部分は、投稿を理解するためにエンコーダーを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-27">
        <br><font color="black">2020-10-27</font>
      </time>
    </span>
</section>
<!-- paper0: Toward Micro-Dialect Identification in Diaglossic and Code-Switched
  Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CL/paper_7.html">
      <font color="black">Toward Micro-Dialect Identification in Diaglossic and Code-Switched
  Environments</font>
    </a>
  </h2>
  <font color="black">モデリングについては、空間的および言語的に動機付けられた一連の新しいマルチタスク学習モデルを提供します。モデルの有用性を示すために、アラビア語の微小品種（低リソース）の新しい大規模データセットを紹介します。私たちのタスク..私たちの新しい言語モデルはまた、いくつかの外部タスクに関する新しい最先端を確立します。 
[概要]マイクロ方言識別（mdi）のタスクは、ジオロケーション調査に基づいています。印象的な能力を備えた新しい言語モデルであるマーバートは、きめ細かい多様性を予測します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-10">
        <br><font color="black">2020-10-10</font>
      </time>
    </span>
</section>
<!-- paper0: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CL/paper_8.html">
      <font color="black">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</font>
    </a>
  </h2>
  <font color="black">検索拡張生成（RAG）の汎用微調整レシピ（言語生成用に事前にトレーニングされたパラメトリックメモリとノンパラメトリックメモリを組み合わせたモデル）を検討します。言語生成タスクの場合、RAGモデルがより具体的に生成することがわかります。 、最先端のパラメトリックのみのseq2seqベースラインよりも多様で事実に基づく言語。パラメトリックメモリが事前トレーニング済みのseq2seqモデルであり、ノンパラメトリックメモリがWikipediaの高密度ベクトルインデックスであるRAGモデルを紹介します。事前にトレーニングされたニューラルリトリーバーでアクセスします。 
[概要]私たちのモデルには、明示的なノンパラメトリックメモリへの微分可能なアクセスメカニズムがありますが、これまでのところ、実際に抽出されたダウンストリームタスクについてのみ調査されています。幅広い知識に基づいてモデルを微調整および評価します-集中的なnlpタスク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-22">
        <br><font color="black">2020-05-22</font>
      </time>
    </span>
</section>
<!-- paper0: Generating Word and Document Embeddings for Sentiment Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CL/paper_9.html">
      <font color="black">Generating Word and Document Embeddings for Sentiment Analysis</font>
    </a>
  </h2>
  <font color="black">映画ドメインとトルコ語のTwitterデータセットの2つのコーパスに対して、ドメイン固有の感傷的なベクトルを誘導します。単語の監視対象の特徴と辞書の定義から抽出された特徴を組み合わせると、成功率の増加が見られます。言葉の感情はコーパスごとに異なります。 
[概要]言語の一般的な感情レキシコンを誘導し、それらを使用すると、一般に、さまざまなドメインで意味のある結果を生成できます。コンテキスト、教師あり、辞書ベースのアプローチの組み合わせを試し、originalarsを生成します。 2つの英語のコーパスも同様に、これらもword2vecアプローチを上回りました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-05">
        <br><font color="black">2020-01-05</font>
      </time>
    </span>
</section>
<!-- paper0: Text Segmentation by Cross Segment Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CL/paper_10.html">
      <font color="black">Text Segmentation by Cross Segment Attention</font>
    </a>
  </h2>
  <font color="black">ドキュメントと談話のセグメンテーションは、テキストを構成要素に分割することに関する2つの基本的なNLPタスクであり、情報検索やテキスト要約などのダウンストリームタスクを支援するために一般的に使用されます。モデルサイズをさらに分析すると、はるかに少ないパラメータでモデルを構築できることがわかります。優れたパフォーマンスを維持しながら、実際のアプリケーションを容易にします。この作業では、3つのトランスベースのアーキテクチャを提案し、3つの標準データセットで以前に提案されたアプローチとの包括的な比較を提供します。 
[概要]この作業では、3つのトランスベースアーキテクチャを提案します。これらには、3つの標準データセットで以前に提案された提案との比較が含まれます。モデルサイズをさらに分析し、優れたパフォーマンスを維持しながら、より少ない質問でモデルを構築できることを確認します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-30">
        <br><font color="black">2020-04-30</font>
      </time>
    </span>
</section>
<!-- paper0: Back to the Future: Unsupervised Backprop-based Decoding for
  Counterfactual and Abductive Commonsense Reasoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CL/paper_11.html">
      <font color="black">Back to the Future: Unsupervised Backprop-based Decoding for
  Counterfactual and Abductive Commonsense Reasoning</font>
    </a>
  </h2>
  <font color="black">この論文では、DeLoreanを提案します。これは、既製の左から右への言語モデルのみを使用し、監視なしで過去と未来の両方のコンテキストを柔軟に組み込むことができる新しい教師なしデコードアルゴリズムです。 、DeLoreanは、左と右の両方のコンテキストを反映する出力表現をデコードできます。アルゴリズムの重要な直感は、逆伝播を通じて未来を組み込むことです。その間、モデルパラメータを修正しながら、出力の内部表現のみを更新します。 
[要約]私たちのアプローチは一般的であり、2つの非単調推論タスクに適用されることを示しました：アブダクションテキスト生成と反事実的ストーリー改訂</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: Referring Expression Comprehension: A Survey of Methods and Datasets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CL/paper_12.html">
      <font color="black">Referring Expression Comprehension: A Survey of Methods and Datasets</font>
    </a>
  </h2>
  <font color="black">特に、共通の特徴空間への画像と表現の共同埋め込みの一般的なアプローチを検討します。この調査の第2部では、RECシステムのトレーニングと評価に使用できるデータセットを確認します。モジュラーアーキテクチャとグラフについても説明します。構造化されたグラフ表現と連動するベースのモデル。 
[概要] rec問題はテスト中にのみクエリを観察できます。このタスクはコンピュータビジョンと自然言語処理コミュニティから多くの注目を集めています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-19">
        <br><font color="black">2020-07-19</font>
      </time>
    </span>
</section>
<!-- paper0: An Empirical Survey of Unsupervised Text Representation Methods on
  Twitter Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CL/paper_13.html">
      <font color="black">An Empirical Survey of Unsupervised Text Representation Methods on
  Twitter Data</font>
    </a>
  </h2>
  <font color="black">最も注目すべきは、BERTなどの大規模な事前トレーニング済みのTransformerベースの言語モデルの出現により、テキスト表現が著しく改善されたことです。私たちの結果は、より高度なモデルが必ずしもツイートで最適に機能するとは限らないことを示しています。この分野でさらに調査が必要です。ただし、これらの改善が、ツイートなどのノイズの多いユーザー生成テキストにつながるかどうかは不明です。 
[概要]近年、テキスト表現に目立った改善が見られます。調査は全国の研究者によって実施されました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Document Graph for Neural Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CL/paper_14.html">
      <font color="black">Document Graph for Neural Machine Translation</font>
    </a>
  </h2>
  <font color="black">IWSLT英語-フランス語、中国語-英語、WMT英語-ドイツ語、Opensubtitle英語-ロシア語など、さまざまなNMTベンチマークでの実験は、ドキュメントグラフを使用すると、翻訳品質を大幅に向上できることを示しています。ただし、既存のドキュメントレベルのNMTメソッドのほとんどは前の文のいくつかのセットを超えてコンテキストを活用します。隣接、構文の依存関係、語彙の一貫性、共参照など、いくつかのタイプの関係を使用して、ドキュメントグラフを作成します。 
[概要]ほとんどの既存のドキュメント-レベルwtメソッドは期待に挑戦できませんでした。これらのツールを使用する代わりに、関連するコンテキストを接続するパターンを開発しました。目的はこの問題に対処することであり、ドキュメントは次のように表すことができると仮定します。グラフ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: MFST: A Python OpenFST Wrapper With Support for Custom Semirings and
  Jupyter Notebooks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CL/paper_15.html">
      <font color="black">MFST: A Python OpenFST Wrapper With Support for Custom Semirings and
  Jupyter Notebooks</font>
    </a>
  </h2>
  <font color="black">mFSTは、使い始めるのが簡単になるように設計されており、以前はNLPクラスの宿題の割り当てや、FSTとニューラルネットワークを統合するプロジェクトで使用されていました。このホワイトペーパーでは、mFSTAPIとmFSTを使用して構築する方法について説明します。 PyTorchを使用した単純なニューラルFST ..このペーパーでは、OpenFSTに基づく有限状態マシンを操作するための新しいPythonライブラリであるmFSTを紹介します。 
[概要] mfstはopenfstの薄いラッパーであり、fstを操作するためのopenfstのopenfstのすべてのメソッドを公開します。これにより、mfstは、fstの重みの学習やニューラル化されたfstの作成を含むモデルの開発に最適です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Addressing machine learning concept drift reveals declining vaccine
  sentiment during the COVID-19 pandemic -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/cs.CL/paper_16.html">
      <font color="black">Addressing machine learning concept drift reveals declining vaccine
  sentiment during the COVID-19 pandemic</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、ソーシャルメディア分析システムは、データの体系的な誤分類のリスクを回避するために、継続的に概念のドリフトに対処する必要があることを示唆しています。これは、基礎となるデータが突然急速に変化する可能性がある危機の際に特に発生する可能性があります。特にCOVID-19の大流行時に最も重要なトピックであるTwitterで表現されたワクチン感情に焦点を当てることによる、機械学習の概念のドリフトの影響。ソーシャルメディアの急速なダイナミクスは根本的な傾向をすばやく捉えることができますが、技術的な問題も引き起こします。過去に注釈付きデータでトレーニングされたアルゴリズムは、現在のデータに適用するとパフォーマンスが低下する可能性があります。 
[概要]ソーシャルメディアの投稿数の増加により、自然言語処理での最新の機械学習手法の使用が増加しています。コンセプトドリフトとして知られるこの現象は、関心のあるトピック自体のいずれかで急速な変化が発生した場合に特に問題になる可能性があります。またはトピックが議論される方法で</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-03">
        <br><font color="black">2020-12-03</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Modeling the effects of dynamic range compression on signals in noise -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.AS/paper_0.html">
      <font color="black">Modeling the effects of dynamic range compression on signals in noise</font>
    </a>
  </h2>
  <font color="black">信号エンベロープに関する統計的仮定を使用して、別の信号の存在下で1つの信号に適用される圧縮をモデル化する効果的な圧縮関数を定義します。このフレームワークは、以前に実験的に観察されたDRCに関する結果を証明するために使用されます。信号の混合に対して、無相関の信号エンベロープは負の相関になります。混合物の各音に適用される効果的な圧縮は、信号のみの場合よりも弱いこと。そして、その圧縮は、特定の条件での長期的な信号対雑音比を低下させる可能性があります。この作業では、ノイズにおけるDRCの動作を研究するための数学モデルを紹介します。 
[ABSTRACT]圧縮はリスニングの快適さを向上させることができますが、ノイズの多い環境でも歪みを引き起こす可能性があります。これは、以前に実験的に観察されたdrcに関する結果を証明するために使用されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: MLS: A Large-Scale Multilingual Dataset for Speech Research -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.AS/paper_1.html">
      <font color="black">MLS: A Large-Scale Multilingual Dataset for Speech Research</font>
    </a>
  </h2>
  <font color="black">データセットは、http：//www.openslr.orgで誰でも無料で利用できるようになります。さらに、言語モデル（LM）とベースラインの自動音声認識（ASR）モデル、およびデータセット内のすべての言語を提供します。これは論文では、音声研究に適した大規模な多言語コーパスである多言語LibriSpeech（MLS）データセットを紹介しています。 
[ABSTRACT]データセットは8つの言語で構成されており、英語は44.5k時間、その他の言語は6k時間です。データセットは、asrとテキスト読み上げの研究に新しい道を開きます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Diverse Melody Generation from Chinese Lyrics via Mutual Information
  Maximization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.AS/paper_2.html">
      <font color="black">Diverse Melody Generation from Chinese Lyrics via Mutual Information
  Maximization</font>
    </a>
  </h2>
  <font color="black">歌詞とメロディーのアラインメントを改善するために、スケジュールされたサンプリングと強制デコードの手法を採用しています。DiverseMelodyGeneration（DMG）と呼ばれるこの方法では、シーケンス間モデルは、入力スタイルに大きく依存して多様なメロディーを生成することを学習します。 ids、調性を維持し、アラインメントを改善します。この論文では、相互情報の最大化の方法を、生成の品質と多様性を改善するために、中国語の歌詞条件付きメロディ生成のタスクに適応させることを提案します。 
[概要]歌詞とメロディーのバランスを改善するためにdmgを採用しています。また、より心地よくコヒーレントな曲を生成できるdmgを採用しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Speech Imagery Classification using Length-Wise Training based on Deep
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.AS/paper_3.html">
      <font color="black">Speech Imagery Classification using Length-Wise Training based on Deep
  Learning</font>
    </a>
  </h2>
  <font color="black">提案手法は音声画像分類において競争力のある性能を示した。したがって、単語の長さが分類性能を改善する手がかりであることを示した。最近、言語を用いた直接通信のために音声画像が研究されている。 
[概要]音声画像は、言語を使用した直接コミュニケーションのために研究されています。運動画像とは異なり、音声画像にはまだ未知の特性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Instrumentalist Net: Unsupervised Generation of Music from Body
  Movements -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.AS/paper_4.html">
      <font color="black">Multi-Instrumentalist Net: Unsupervised Generation of Music from Body
  Movements</font>
    </a>
  </h2>
  <font color="black">パイプラインがビデオ内の楽器によって再生されている音楽の正確なコンテンツを生成するように、Midiが潜在空間をさらに調整できることを示します。潜在空間は、新しい音楽ができる別個の楽器にクラスター化された分布をもたらします。次に、パイプラインは、リカレントニューラルネットワークによってエンコードされたミュージシャンの体のキーポイントの動きを条件とする自動回帰の事前条件とともにトレーニングされます。 
[概要]パイプラインは、ログからさまざまな楽器の音楽の離散潜在表現を学習します-スペクトログラム。vq-vaeアーキテクチャは、追加の条件付けで詳細な音楽生成をサポートします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Limitations of weak labels for embedding and tagging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.AS/paper_5.html">
      <font color="black">Limitations of weak labels for embedding and tagging</font>
    </a>
  </h2>
  <font color="black">埋め込みまたはエンドツーエンドの分類器をトレーニングするときの弱いラベルの影響を調査します。さまざまな実験シナリオについて説明し、弱いラベルのデータに最も敏感なアプリケーションについての洞察を提供します。周囲の音の分析における多くのデータセットとアプローチは、弱いラベルを使用します。ラベル付けされたデータ：すべてのデータサンプルに強いラベルを付けるのはコストがかかりすぎるため、弱いラベルが使用されますが、強いラベルと比較した場合のパフォーマンスへの影響は不明です。実際、弱いラベルは他のラベルと同時に処理する必要があります。課題、つまりサンプルごとの複数のラベル、不均衡なクラス、および/または重複するイベント。この論文では、弱いラベルを含む教師あり学習問題を定式化します。他の課題とは対照的に、強いラベルと弱いラベルの違いに焦点を当てたデータセットを作成します。 。 
[ABSTRACT] cnn&#39;s ann ann annは、弱いデータと同じ質問を扱っています。これは、同じものが紙と同じである必要があるためです。さまざまな実験シナリオについて説明し、どのアプリケーションが最も敏感であるかについての洞察を提供します。弱いデータ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-05">
        <br><font color="black">2020-02-05</font>
      </time>
    </span>
</section>
<!-- paper0: EfficientTTS: An Efficient and High-Quality Text-to-Speech Architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.AS/paper_6.html">
      <font color="black">EfficientTTS: An Efficient and High-Quality Text-to-Speech Architecture</font>
    </a>
  </h2>
  <font color="black">提案されたモデルは、音声品質、トレーニング効率、合成速度の点でTacotron 2やGlow-TTSなどの対応するモデルを大幅に上回り、強力な堅牢性と多様性の高い音声を生成することを実験的に示しています。EfficientTTSをさまざまなフィードと組み合わせることにより-フォワードネットワーク構造では、テキスト読み上げネットワークとテキスト読み上げネットワークの両方を含むTTSモデルのファミリーを開発します。EfficientTTSは、単調性を指定する新しい単調なアライメントモデリングアプローチ（この作業でも導入）によって動機付けられています。計算の増加がほとんどないシーケンスアラインメントへの制約。 
[ABSTRACT] efficientttsは、安定したエンドツーエンドのトレーニング手順ですべてのパラメータを最適化すると同時に、高品質の音声を高速かつ効率的に合成できるようにします。提案されたアプローチは、タコトロン2などの自己回帰モデルに簡単に拡張できることを示しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Soft-Median Choice: An Automatic Feature Smoothing Method for Sound
  Event Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.AS/paper_7.html">
      <font color="black">Soft-Median Choice: An Automatic Feature Smoothing Method for Sound
  Event Detection</font>
    </a>
  </h2>
  <font color="black">勾配流の経路を浚渫し、ネットワークをより良く収束させるために、1つではなくすべてのデータを使用します。評価を通じて、提案された方法が参照アルゴリズムよりも大幅に優れたスコアを取得することを示します。中央値で構成されています。フィルタと線形選択レイヤーにより、さまざまな平滑化レベルの特徴の知識を自動的に取得します。 
[概要]システムは、中央値の選択に基づくシステムを作成するために提案されています。中央値の選択の新しいモジュールを抽出し、それをフィルターに追加する必要があります。ソフト平均関数は、中央値関数を置き換えるように設計されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-25">
        <br><font color="black">2020-11-25</font>
      </time>
    </span>
</section>
<!-- paper0: Defense for Black-box Attacks on Anti-spoofing Models by Self-Supervised
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.AS/paper_8.html">
      <font color="black">Defense for Black-box Attacks on Anti-spoofing Models by Self-Supervised
  Learning</font>
    </a>
  </h2>
  <font color="black">元のデータと区別がつかないが誤った予測をもたらす敵対的攻撃は、なりすまし防止モデルにとって危険であり、争うことなく、それらを検出する必要があります。自動話者検証（ASV）用の高性能なりすまし防止モデルは、テキスト読み上げ、音声変換、音声再生などによって意図的に生成されたなりすまし音声を識別およびフィルタリングすることにより、ASVを保護するために広く使用されています。ただし、敵対的攻撃に対する防御におけるそれらの効果はまだ調査されていません。 
[概要]アンチスプーフィングモデルは、敵対的攻撃に対して脆弱です。これは、ノイズの影響を検出できないためです。これは、敵対的攻撃に対抗するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-05">
        <br><font color="black">2020-06-05</font>
      </time>
    </span>
</section>
<!-- paper0: Reverberant Sound Localization with a Robot Head Based on Direct-Path
  Relative Transfer Function -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.AS/paper_9.html">
      <font color="black">Reverberant Sound Localization with a Robot Head Based on Direct-Path
  Relative Transfer Function</font>
    </a>
  </h2>
  <font color="black">さまざまな残響環境に配置されたロボットを使用した実験では、提案された方法が2つの最先端の方法よりも優れていることが示されています。短時間フーリエ変換でノイズの多い残響信号からDP-RTFを推定する方法を提案します。 （STFT）ドメイン..ダイレクトパス相対転送関数（DP-RTF）は、2つのマイクのダイレクトパス音響転送関数（ATF）の比率として定義され、SSLの重要な機能です。 
[概要]たとえば、音声ソースの検索に関心があります。これらは人間とロボットの相互作用に非常に関心があります。この応答は、ノイズと残響によって汚染されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: Towards end-to-end speech enhancement with a variational U-Net
  architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.AS/paper_10.html">
      <font color="black">Towards end-to-end speech enhancement with a variational U-Net
  architecture</font>
    </a>
  </h2>
  <font color="black">具体的には、PESQスコアは、残響シーンと非残響シーンでそれぞれ0.28と0.49の増加を示します。私たちの実験は、提案されたシステムの残りの（スキップ）接続が、エンドツーエンドの信号強調を成功させるために必要であることを示しています。フィルタマスク推定..ディープネットワーク音声強調システムは、通常、フィルタマスクを推定することを目的とするか、前処理ステップをスキップして波形信号を直接処理することを選択し、高次元のスペクトル時間的特徴間の関係を無視する可能性があります。 
[ABSTRACT]ディープネットワーク音声強調は、多くの場合、変分フィルターマスクの推定を目的としています。これらは、波形信号を処理するための前処理ステップをスキップするためにも使用されます。これにより、より高度な技術スペクトル（時間的特徴）間の関係も無視される可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
<!-- paper0: A CSMT challenge dataset for the identification of computer generated
  melodies -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-12-08/eess.AS/paper_11.html">
      <font color="black">A CSMT challenge dataset for the identification of computer generated
  melodies</font>
    </a>
  </h2>
  <font color="black">データセットの目的は、生成されたメロディーの特徴を学習することにより、コンピューターで生成されたメロディーを区別できるかどうかを調べることです。この論文では、音と音楽技術に関する会議（CSMT）が主催するデータチャレンジに使用されるデータセットを紹介します。 ..データセットは、開発データセットと評価データセットの2つの部分で構成されています。 
[概要] csmtデータチャレンジでは、参加者はメロディーの一部がコンピューターによって生成されたものか、人間によって作成されたものかを識別する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-12-07">
        <br><font color="black">2020-12-07</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
