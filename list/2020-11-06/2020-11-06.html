<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-11-06の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Speech Recognition and Multi-Speaker Diarization of Long Conversations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.SD/paper_0.html">
      <font color="black">Speech Recognition and Multi-Speaker Diarization of Long Conversations</font>
    </a>
  </h2>
  <font color="black">未知の発話境界を持つ長い会話を処理するために、モデルの事前トレーニングと組み合わせてASRとSDを改善するストライドアテンションデコードアルゴリズムとデータ拡張技術を導入します。音声認識（ASR）と話者のダイアリゼーション（SD）モデルは伝統的にスピーカーラベル付きの豊富な会話トランスクリプトを作成するために個別にトレーニングされています。毎週のThisAmerican Lifeラジオプログラムから収集された1時間のポッドキャストの新しいベンチマークを導入して、拡張マルチスピーカー会話に適用した場合のこれらのアプローチをよりよく比較します。 
[ABSTRACT] asrおよびsdモデルは、音声（語彙の相互依存）を活用して単語のダイアリゼーションのパフォーマンスを向上させる方法を学習できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-16">
        <br><font color="black">2020-05-16</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-class Spectral Clustering with Overlaps for Speaker Diarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.SD/paper_1.html">
      <font color="black">Multi-class Spectral Clustering with Overlaps for Speaker Diarization</font>
    </a>
  </h2>
  <font color="black">さらに、フレームレベルの分類を実行し、HMM状態遷移を通じて期間制約を適用するHMM-DNNベースのオーバーラップ検出器について詳しく説明します。この方法では、AMIの混合ヘッドセット設定で24.0％のテストダイアリゼーションエラー率（DER）を達成します。コーパスを満たすこと。これは、強力な凝集型階層的クラスタリングベースラインに対して15.2％の相対的な改善であり、他のオーバーラップ認識ダイアリゼーション手法と比べて遜色ありません。LibriCSSデータのさらなる分析は、高オーバーラップ条件での提案手法の有効性を示しています。 
[ABSTRACT]私たちの方法は、オーバーラップ検出器とスピーカー埋め込み抽出器を提供します。この方法は、テストのダイアリゼーションエラー率（der）に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Do not look back: an online beat tracking method using RNN and enhanced
  particle filtering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.SD/paper_2.html">
      <font color="black">Do not look back: an online beat tracking method using RNN and enhanced
  particle filtering</font>
    </a>
  </h2>
  <font color="black">そのため、チャンクの受信を最初に待つことなく、多くのOBTアプリケーションにとって重要な即時のビートトラッキング応答を提供します。DLBは、単方向RNNのアクティブ化を拡張モンテカルロローカリゼーションモデルにフィードして、ビート位置を推測します。 ..ほとんどの既存のOBTメソッドは、過去のデータを含む移動ウィンドウにオフラインアプローチを適用して将来のビート位置を予測するか、起動時に過去のデータでプライミングして初期化する必要があります。 
[概要]オンラインホームに戻る。元のページに戻る。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Anomalous Sound Detection as a Simple Binary Classification Problem with
  Careful Selection of Proxy Outlier Examples -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.SD/paper_3.html">
      <font color="black">Anomalous Sound Detection as a Simple Binary Classification Problem with
  Careful Selection of Proxy Outlier Examples</font>
    </a>
  </h2>
  <font color="black">プロキシ外れ値の候補は、正常音でも異常音でもないすべての録音が含まれる可能性があるため、豊富に用意されています。同様の音と一致する録音条件のデータがない場合は、これらの2つの次元で多様性が大きいデータセットが望ましいです。結果として、ほとんどの異常検出方法は、監視された機械学習方法ではなく、監視されていない機械学習方法を使用します。 
[概要]重要な障害は、外れ値の多様性と希少性です。これらは通常、異常音の代表的なセットを収集することを妨げます。しかし、異常音の検出は、教師あり分類問題として効果的に組み立てることができることを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Accent Adaptation based on Gate Mechanism -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.SD/paper_4.html">
      <font color="black">Multi-Accent Adaptation based on Gate Mechanism</font>
    </a>
  </h2>
  <font color="black">音響モデルとアクセント分類器を共同でトレーニングするために、ゲートメカニズムを使用したマルチタスク学習（MTL-G）を提案します。したがって、アクセント分類器を使用してアクセントラベルを予測します。ただし、ベースラインと比較してモデルでは、MTL-Gは5.1％の平均相対WER削減を達成します。 
[ABSTRACT] ast --gは、それぞれ9.8％と1.9％の平均相対ワー削減を達成します。ただし、アクセントパフォーマンスファイアはアクセントラベルに適応できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-supervised Learning for Singing Synthesis Timbre -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.SD/paper_5.html">
      <font color="black">Semi-supervised Learning for Singing Synthesis Timbre</font>
    </a>
  </h2>
  <font color="black">教師なしで新しい音声を学習するには、事前にトレーニングされた音響エンコーダーを使用して、ターゲット歌手のデコーダーをトレーニングします。リスニングテストでシステムを評価し、同等の教師ありアプローチで得られた結果と同等であることを示します。最後に、推論では、事前にトレーニングされた言語エンコーダーが新しい音声のデコーダーと一緒に使用され、言語入力から音響機能を生成します。 
[概要]両方のエンコーダーによって生成された埋め込みが類似していることを確認します。これにより、後で音響入力機能または言語入力機能のいずれかでモデルを使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: A Time-domain Monaural Speech Enhancement with Feedback Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.SD/paper_6.html">
      <font color="black">A Time-domain Monaural Speech Enhancement with Feedback Learning</font>
    </a>
  </h2>
  <font color="black">2番目の部分は畳み込みオートエンコーダです。TIMITコーパスで多数の実験が行われ、実験結果は、提案されたネットワークが2つの最先端の時間領域よりもPESQスコアとSTOIスコアの両方に関して一貫して優れたパフォーマンスを達成できることを示しています。さまざまな条件でのベースラインベース。フィードバック学習を採用してパラメーターの効率を向上させるため、パフォーマンスを犠牲にすることなく、トレーニング可能なパラメーターの数を効果的に減らすことができます。 
[概要]最初の部分はステージリカレントニューラルネットワークと呼ばれます。これは、メモリメカニズムを使用して、さまざまなステージにわたる深い特徴の依存関係を効果的に集約するために導入されました。2番目の部分は、一連の連結ゲート線形ユニットで構成されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-22">
        <br><font color="black">2020-03-22</font>
      </time>
    </span>
</section>
<!-- paper0: A Comparison Study on Infant-Parent Voice Diarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.SD/paper_7.html">
      <font color="black">A Comparison Study on Infant-Parent Voice Diarization</font>
    </a>
  </h2>
  <font color="black">また、logmel特徴の代わりに畳み込み特徴extractorを使用すると、神経ダイアリゼーションのパフォーマンスが大幅に向上することもわかりました。また、パラメーターを事前にトレーニングできる複数インスタンス学習手法を紹介します。境界ラベル。LENAソフトウェアで達成された55.4％DERと比較して、テストデータセットで最高のシステムが43.8％DERを達成したことがわかりました。システムのさまざまなコンポーネントを交換したり、損失関数を変更したりした場合の影響を調査します。 、最高のパフォーマンスを見つけるために。 
[概要]私たちのシステムは、時間応答機能エクストラクターとクラスサイファイアで構成されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Adaptation Using Class Similarity for Robust Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.SD/paper_8.html">
      <font color="black">Domain Adaptation Using Class Similarity for Robust Speech Recognition</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチでは、最初にソースモデルを使用してソースサンプルのフレームレベルの事後確率を計算します。DNNモデルの出力分布には、ソースドメインとターゲットドメインの両方に適用できるクラス間の類似性の知識が含まれているため、パフォーマンス向上のためのソースからターゲットへのモデル。次に、各クラスについて、このクラスの確率を使用して平均ベクトルを計算します。これを平均ソフトラベルと呼びます。 
[要約]クラスごとに、このクラスの確率を使用して、ソフトラベルという用語を取得します。このモデルは、パフォーマンスを向上させるためにソースモデルからターゲットモデルに転送できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Low-Complexity Models for Acoustic Scene Classification Based on
  Receptive Field Regularization and Frequency Damping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.SD/paper_9.html">
      <font color="black">Low-Complexity Models for Acoustic Scene Classification Based on
  Receptive Field Regularization and Frequency Damping</font>
    </a>
  </h2>
  <font color="black">提案されたフィルターダンピングを使用して、低複雑度の音響シーン分類のタスクでDCASE-2020チャレンジで1位を達成しました。さらに、モデルのアーキテクチャを変更せずにモデルのRFを正規化するフィルターダンピング手法を提案します。パラメータカウントの変更..この手法を組み込むと、プルーニングや分解された畳み込みなど、複雑さの低いさまざまな設定でのパフォーマンスが向上することを示します。 
[概要]カスタム削減方法と組み合わせて、rfsに特定の制限を適用することにより、高パフォーマンスの低複雑度モデルを実現できます。この手法を組み込むと、プルーニングや分解畳み込みなどのさまざまな低詳細設定でのパフォーマンスが向上することを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: BW-EDA-EEND: Streaming End-to-End Neural Speaker Diarization for a
  Variable Number of Speakers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.SD/paper_10.html">
      <font color="black">BW-EDA-EEND: Streaming End-to-End Neural Speaker Diarization for a
  Variable Number of Speakers</font>
    </a>
  </h2>
  <font color="black">スピーカーが3つ以上あると、オンラインとオフラインの精度の差が大きくなりますが、コンテキストサイズが無制限の1〜4スピーカーのベースラインオフラインクラスタリングダイアリゼーションシステムを上回り、コンテキストサイズが10秒の場合と同等の精度を示します。線形時間で入力を処理する待ち時間BW-EDA-EENDは、オフラインEDA-EENDと比較して10秒のコンテキストサイズを使用して、最大2人のスピーカーに対して中程度の劣化のみを示します。新しいオンラインエンドツーエンドニューラルを提示します。可変数の話者のデータを段階的に処理するダイアリゼーションシステム、BW-EDA-EEND。 
[概要]このシステムは、堀口らのedaアーキテクチャに基づいています。インクリメンタルトランスフォーマーエンコーダーを使用し、左側のスケジュールのみに対応し、隠された状態でブロックレベルの繰り返しを使用してブロック間で情報を伝達します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: From Note-Level to Chord-Level Neural Network Models for Voice
  Separation in Symbolic Music -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.SD/paper_11.html">
      <font color="black">From Note-Level to Chord-Level Neural Network Models for Voice
  Separation in Symbolic Music</font>
    </a>
  </h2>
  <font color="black">音声分離を、他のストリームからの高度な外部知覚分離と高度な内部知覚一貫性の両方を示すストリームに音楽を分解するタスクとして定義することにより、この連続性に対処します。音声ノート内の連続した抽出で評価した場合ペアの場合、両方のモデルは、エンベロープ抽出関数の反復アプリケーションに基づく強力なベースラインを上回り、コードレベルモデルは常にノートレベルモデルをエッジアウトします。2つのモデルは、音声を分離する以前のアプローチよりも優れていることも示されています。バッハ音楽。 
[概要]提案された音声分離タスクにより、音声を複数の音声に分岐させることができます。また、複数の音声を同じ音声に収束させることもできます。2つのモデルは、以前のアプローチよりも優れていることも示されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: GPR-based Model Reconstruction System for Underground Utilities Using
  GPRNet -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/eess.IV/paper_0.html">
      <font color="black">GPR-based Model Reconstruction System for Underground Utilities Using
  GPRNet</font>
    </a>
  </h2>
  <font color="black">このシステムは、次の3つのモジュールで構成されています。1）全方向ロボットによって提供される位置情報でGPR測定値にタグを付ける視覚慣性ベースのGPRデータ収集モジュール。 2）生のGPR Bスキャン画像をオブジェクトモデルの断面に解釈するためのディープニューラルネットワーク（DNN）移行モジュール。 3）DNNベースの3D再構成モジュール、つまりGPRNetは、細かい3D点群を使用して地下実用新案を生成します。合成データとフィールドテストデータの実験結果により、本手法の有効性が検証されました。私たちの方法は、さまざまなレベルの不完全性とノイズを伴う、まばらな入力、つまりGPR生データに基づいて、パイプ型ユーティリティの高密度で完全な点群モデルを生成できることを示しています。 
[ABSTRACT]ロボットシステムは、結果が悪い地下ユーティリティを再構築します。gpr生データと呼ばれ、ポイントクラウドモデルの作成に使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Benefiting from Bicubically Down-Sampled Images for Learning Real-World
  Image Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/eess.IV/paper_1.html">
      <font color="black">Benefiting from Bicubically Down-Sampled Images for Learning Real-World
  Image Super-Resolution</font>
    </a>
  </h2>
  <font color="black">次に、バイキュービックにダウンサンプリングされた画像でトレーニングされた汎用SRネットワークを使用して、変換されたLR画像を超解像します。超解像（SR）は、従来、高解像度画像（HR）とその低解像度（LR）のペアに基づいていました。 ）バイキュービックダウンサンプリングで人工的に取得された対応物..最初に、実際のLR / HRペアと合成ペアの両方を使用して、監視された方法で実際のLR画像をバイキュービックダウンサンプリング画像の空間に変換するネットワークをトレーニングします。 
[概要]実際のlr画像を双立方的にダウンサンプリングされた画像の空間に変換するネットワークをトレーニングします。パイプラインの最初のステップでは、よく理解されている共通の画像空間に画像を登録することで問題に対処します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: A Multi-resolution Model for Histopathology Image Classification and
  Localization with Multiple Instance Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/eess.IV/paper_2.html">
      <font color="black">A Multi-resolution Model for Histopathology Image Classification and
  Localization with Multiple Instance Learning</font>
    </a>
  </h2>
  <font color="black">グレードグループ&gt; = 2）予測、悪性スライドと良性スライドを区別するための98.2％の受信者動作特性曲線（AUROC）および97.4％の平均精度（AP）の下の領域..高価な領域またはピクセルに依存する代わりに-レベルの注釈により、モデルはスライドレベルのラベルのみでエンドツーエンドでトレーニングできます。モデルは、92.7％の精度、81.8％のCohen&#39;s Kappaを達成し、良性で低グレードです（つまり、
[ABSTRACT]多数の病理病理学的画像がデジタル化されています高解像度のスライド全体の画像に変換します。モデルは、830人の患者からの20、229枚のスライドを含む大規模な前立腺生検データセットで開発されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Adaptively Learning to Demoire from Focused and Defocused Image
  Pairs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/eess.IV/paper_3.html">
      <font color="black">Self-Adaptively Learning to Demoire from Focused and Defocused Image
  Pairs</font>
    </a>
  </h2>
  <font color="black">私たちの知る限り、これは実際のテクスチャモアレパターンを持つ最初のデータセットです。2つのサブネットワークは共同で最適化されています。モデルには2つのサブネットワークがあり、反復的に機能します。 
[概要]ディープラーニングベースのモアレパターンの処理には制限があります。これには、デジタルディスプレイで撮影した写真のモアレが含まれます。これは、実際のテクスチャモアレパターンを使用した最初のデータセットです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: CompressAI: a PyTorch library and evaluation platform for end-to-end
  compression research -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/eess.IV/paper_4.html">
      <font color="black">CompressAI: a PyTorch library and evaluation platform for end-to-end
  compression research</font>
    </a>
  </h2>
  <font color="black">したがって、学習されたエンドツーエンド圧縮に関する最先端の複数のモデルがPyTorchに再実装され、ゼロからトレーニングされました。特に、CompressAIには、学習された方法を従来のコーデックと比較するための事前トレーニング済みモデルと評価ツールが含まれています。 ..このフレームワークは現在、静止画圧縮のモデルを実装していますが、まもなくビデオ圧縮ドメインに拡張される予定です。 
[ABSTRACT] compressaiには、事前にトレーニングされたモデルと評価ツールが含まれています。compressaiは、学習したメソッドを従来のコーデックと比較するための事前にトレーニングされたモデルを提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: GPR-based Model Reconstruction System for Underground Utilities Using
  GPRNet -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_0.html">
      <font color="black">GPR-based Model Reconstruction System for Underground Utilities Using
  GPRNet</font>
    </a>
  </h2>
  <font color="black">このシステムは、次の3つのモジュールで構成されています。1）全方向ロボットによって提供される位置情報でGPR測定値にタグを付ける視覚慣性ベースのGPRデータ収集モジュール。 2）生のGPR Bスキャン画像をオブジェクトモデルの断面に解釈するためのディープニューラルネットワーク（DNN）移行モジュール。 3）DNNベースの3D再構成モジュール、つまりGPRNetは、細かい3D点群を使用して地下ユーティリティモデルを生成します。実験は、私たちの方法が、に基づいてパイプ形状のユーティリティの高密度で完全なポイントクラウドモデルを生成できることを示しています。さまざまなレベルの不完全性とノイズを伴うスパース入力、つまりGPR生データ。この問題に対処するために、このペーパーでは、GPRデータを収集し、地下ユーティリティをローカライズし、地下オブジェクトの密な点群モデルを再構築する新しいロボットシステムを紹介します。 。 
[ABSTRACT]ロボットシステムは、結果が悪い地下ユーティリティを再構築します。gpr生データと呼ばれ、ポイントクラウドモデルの作成に使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Benefiting from Bicubically Down-Sampled Images for Learning Real-World
  Image Super-Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_1.html">
      <font color="black">Benefiting from Bicubically Down-Sampled Images for Learning Real-World
  Image Super-Resolution</font>
    </a>
  </h2>
  <font color="black">超解像（SR）は、従来、バイキュービックダウンサンプリングで人工的に取得された高解像度画像（HR）とその低解像度（LR）のペアに基づいていました。次に、2番目のステップでは、バイキュービックダウンサンプリングでSRのすでに印象的なパフォーマンスを活用します。画像は、さまざまな画像劣化のあるデータセットでのエンドツーエンドトレーニングの問題を回避します。ただし、実際のSRには多種多様な現実的な画像劣化があり、これらの現実的な劣化を分析的にモデル化することは非常に困難です。 
[概要]実際のlr画像を双立方的にダウンサンプリングされた画像の空間に変換するネットワークをトレーニングします。パイプラインの最初のステップでは、よく理解されている共通の画像空間に画像を登録することで問題に対処します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Single Image Human Proxemics Estimation for Visual Social Distancing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_2.html">
      <font color="black">Single Image Human Proxemics Estimation for Visual Social Distancing</font>
    </a>
  </h2>
  <font color="black">提案された方法を、個人間の距離に関するグラウンドトゥルースを提供したパブリックドメインデータセットのベースラインに対して定量的および定性的に検証します。さらに、個人間の距離に関する統計が行われる実際のテストシナリオで展開された方法のアプリケーションを示します。現在、重要な環境での安全性を向上させるために使用されています。対人距離は、社会的距離規則の違反の可能性を検出するために、さらにローカルで検査されます。 
[概要]実際のテストシナリオで展開されたメソッドのアプリケーションを示しました。現在、個人間の距離に関する統計が重要な環境での安全性を向上させるために使用されていることを示しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Metric Learning with Spherical Embedding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_3.html">
      <font color="black">Deep Metric Learning with Spherical Embedding</font>
    </a>
  </h2>
  <font color="black">ディープメトリック学習、顔認識、および対照的な自己教師あり学習に関する広範な実験は、SECベースの角度空間学習戦略が最先端のパフォーマンスを大幅に改善することを示しています。ディープメトリック学習は、最近多くの注目を集めています。距離メトリック学習とディープニューラルネットワークをシームレスに組み合わせているため、何年もかかります。ただし、これらの従来の角度損失は、トレーニング段階ですべてのサンプルの埋め込みが同じハイパースフィアの表面にあることを保証できず、バッチの勾配が不安定になります。最適化され、埋め込み学習の迅速な収束に影響を与える可能性があります。 
[概要]ディープメトリック学習は、ビンを埋め込むための大きさと方向の情報を切り離す傾向があります。これらは、高血圧のトレーニングとテストを確実にするように設計されています。これらの測定は、同じグラスゴーシステムのテストが維持されることを保証します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Disentangling Latent Space for Unsupervised Semantic Face Editing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_4.html">
      <font color="black">Disentangling Latent Space for Unsupervised Semantic Face Editing</font>
    </a>
  </h2>
  <font color="black">顔の属性をさらに解きほぐすために、STGAN-WOは、2つの独立して同一に分散された（iid）を利用する構造テクスチャに依存しないアーキテクチャを導入します。この論文では、潜在空間を解きほぐすために、重み分解と直交正則化を備えた構造-テクスチャ非依存アーキテクチャ（STIA-WO）と呼ばれる新しい手法を紹介します。STIA-WOを適用するGANモデルはSTGAN-WOと呼ばれます。 
[概要]きちんとしたセマンティック制御を開発するための鍵は、潜在空間を解きほぐし、教師なしで画像編集を実行することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Robotic Grasping on Monocular Images Via Multi-Task Learning
  and Positional Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_5.html">
      <font color="black">Improving Robotic Grasping on Monocular Images Via Multi-Task Learning
  and Positional Loss</font>
    </a>
  </h2>
  <font color="black">マルチタスクCNNモデルは、補足的な深度再構築タスクを実行するときに、大規模なJacquard把握データセットのベースライン平均72.04％から78.14％に把握パフォーマンスを向上させます。2つ目は、2次パラメーターのピクセルあたりの損失を強調する位置損失関数を導入することです。 （グリッパーの角度と幅）正常に把握できるオブジェクトのポイントのみ。これにより、パフォーマンスがベースライン平均の72.04％から78.92％に向上し、必要なトレーニングエポックの数が削減されます。 
[概要] 1つ目は、モデルトレーニング中に補助タスクを追加することです。他の方法には、把握が成功する可能性のあるオブジェクトのポイントでのみピクセルあたりの損失を強調する位置損失関数が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Imagining Grounded Conceptual Representations from Perceptual
  Information in Situated Guessing Games -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_6.html">
      <font color="black">Imagining Grounded Conceptual Representations from Perceptual
  Information in Situated Guessing Games</font>
    </a>
  </h2>
  <font color="black">私たちの想像力モジュールは、CompGuessWhat ？！で8.26％のゲームプレイ精度で最先端の競合他社を上回っています。これは、推論時のカテゴリがトレーニング時のカテゴリと一致する場合に不自然なパフォーマンス上の利点を提供し、ドメイン外のオブジェクトカテゴリが含まれるより現実的な「ゼロショット」シナリオでモデルが失敗する原因になります。この問題を克服するために、推論時にカテゴリラベルに依存することなく、コンテキスト認識およびカテゴリ認識の潜在的な埋め込みを学習する、正規化されたオートエンコーダに基づく新しい「想像力」モジュールを導入します。 
[概要] 2020年、既存のモデルは真のマルチモーダル表現を学習できません。これは、オブジェクトのゴールドカテゴリラベルに依存しているためです。「イマジネーション」モジュールは、正規化されたオートエンコーダに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: A Multi-resolution Model for Histopathology Image Classification and
  Localization with Multiple Instance Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_7.html">
      <font color="black">A Multi-resolution Model for Histopathology Image Classification and
  Localization with Multiple Instance Learning</font>
    </a>
  </h2>
  <font color="black">グレードグループ&gt; = 2）予測、悪性スライドと良性スライドを区別するための98.2％の受信者動作特性曲線（AUROC）および97.4％の平均精度（AP）の下の領域..スライド全体の画像分析に関するこれまでのほとんどの作業は事前に選択された小さな関心領域の分類またはセグメンテーションについて。これには、きめ細かい注釈が必要であり、大規模なスライド全体の分析に拡張するのは簡単ではありません。高価な領域レベルまたはピクセルレベルの注釈に依存する代わりに、私たちのモデルは、スライドレベルのラベルのみでエンドツーエンドでトレーニングできます。 
[概要]多数の組織病理学的画像が高解像度のスライド全体の画像にデジタル化されています。モデルは、830人の患者からの20、229枚のスライドを含む大規模な前立腺生検データセットで開発されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Deep-Dup: An Adversarial Weight Duplication Attack Framework to Crush
  Deep Neural Network in Multi-Tenant FPGA -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_8.html">
      <font color="black">Deep-Dup: An Adversarial Weight Duplication Attack Framework to Crush
  Deep Neural Network in Multi-Tenant FPGA</font>
    </a>
  </h2>
  <font color="black">新しい敵対的攻撃フレームワークを提案します。Deep-Dupでは、敵対的テナントがFPGAの被害者テナントのDNNモデルに障害を注入できます。さらに、特定の悪意のある目的に対して最も脆弱なDNNウェイトパッケージを特定するために、プログレッシブディファレンシャルエボリューションサーチ（P-DES）と呼ばれる、一般的な脆弱なウェイトパッケージ検索アルゴリズム。これは、初めて、ディープラーニングホワイトボックスとブラックボックスの両方の攻撃モデルに適応します。以前の作品とは異なり、ディープラーニングでのみ機能します。ホワイトボックスのセットアップを学習する場合、適応性は主に、提案されたP-DESがDNNモデルの勾配情報を必要としないという事実に由来します。 
[概要] fpga仮想化により、共有fpgaチップ内に複数のテナントが共存できます。このプロジェクトは、マルチテナントfpgasのdnnモデルの脆弱性を調査する最初のプロジェクトです。彼女は、悪意のある電力でfpgaの共有配電システムに積極的に過負荷をかけることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Adaptively Learning to Demoire from Focused and Defocused Image
  Pairs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_9.html">
      <font color="black">Self-Adaptively Learning to Demoire from Focused and Defocused Image
  Pairs</font>
    </a>
  </h2>
  <font color="black">2つのサブネットワークは共同で最適化されます。私たちの知る限り、これは実際のテクスチャモアレパターンを持つ最初のデータセットです。モデルには2つのサブネットワークがあり、反復的に機能します。 
[概要]ディープラーニングベースのモアレパターンの処理には制限があります。これには、デジタルディスプレイで撮影した写真のモアレが含まれます。これは、実際のテクスチャモアレパターンを使用した最初のデータセットです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: Intriguing Properties of Contrastive Losses -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_10.html">
      <font color="black">Intriguing Properties of Contrastive Losses</font>
    </a>
  </h2>
  <font color="black">明示的で制御可能な競合機能を使用してデータセットを構築し、対照学習の場合、学習しやすい共有機能の数ビットが他の競合機能セットの学習を抑制し、完全に防止できることを示します。既存の対照学習メソッドは、特定の機能セットを他の機能よりも優先するためにデータ拡張に大きく依存していますが、ネットワークがその容量が許す限りすべての競合する機能を学習することを望む場合があります。一般化された損失のさまざまなインスタンス化が、多層非線形投影ヘッド、および標準の対照損失で広く使用されている温度スケーリング（$ \ tau $）は、（範囲内で）2つの損失項間の重み付け（$ \ lambda $）に反比例します。 
[概要]新しい取り組みとして、まず標準的な損失の干し草を一般化します。これは、オートエンコーダーへの悪影響がはるかに少ない交差耐性の損失損失に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Utilizing Every Image Object for Semi-supervised Phrase Grounding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_11.html">
      <font color="black">Utilizing Every Image Object for Semi-supervised Phrase Grounding</font>
    </a>
  </h2>
  <font color="black">検出器の助けを借りて、LSEPを適用して、注釈のない画像の接地モデルをトレーニングします。RefCOCO、RefCOCO +、RefCOCOgの3つの公開データセットでMATtNetに基づいて方法を評価します。学習した場所とサブジェクト埋め込み予測子（LSEP）を使用して、トレーニングセットに注釈付きクエリがないオブジェクトに対応する言語埋め込みを生成します。 
[ABSTRACT]グラウンド予測子と埋め込み予測子（lsep）は、トレーニングセットに注釈付きクエリがないオブジェクトに対応する言語グラウンド埋め込みを生成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Revisiting Stereo Depth Estimation From a Sequence-to-Sequence
  Perspective with Transformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_12.html">
      <font color="black">Revisiting Stereo Depth Estimation From a Sequence-to-Sequence
  Perspective with Transformers</font>
    </a>
  </h2>
  <font color="black">私たちのコードはhttps://github.com/mli0603/stereo-transformerで公開されています。STereoTRansformer（STTR）という名前のこのアプローチには、いくつかの利点があります。1）固定視差範囲の制限を緩和します。2）識別します。遮蔽された領域と推定の信頼性を提供し、3）マッチングプロセス中に一意性の制約を課します。ステレオ深度推定は、深度を推測するために、左右の画像のエピポーラ線上のピクセル間の最適な対応マッチングに依存します。 
[概要]この作業では、シーケンスからシーケンスへの対応の観点から問題を再検討します。合成データセットと実世界データセットの両方で有望な結果を報告します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Metrics for Exposing the Biases of Content-Style Disentanglement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_13.html">
      <font color="black">Metrics for Exposing the Biases of Content-Style Disentanglement</font>
    </a>
  </h2>
  <font color="black">私たちの指標はタスクに依存しません。したがって、コンテンツスタイルの表現が役立つタスクでこの理想的な「スイートスポット」が達成されるように、新しい将来のモデルの設計または実行可能なモデルの選択をガイドするのに役立ちます。次に、メトリックを使用して、各バイアスの役割..この論文では、コンテンツとスタイルの表現がどの程度（非）相関していて有益であるかという観点から、解きほぐしの程度を特徴付けるそのようなメトリックを提案し、タスクのパフォーマンスとの関係をさらに調べます。 
[概要]これらのソリューションのほとんどは、表現に解きほぐされたという用語を使用しています。モデルデザイン、学習目標、データなど、さまざまな「バイアス」を採用しています。空間コンテンツの指標が不足しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Conflicting Bundles: Adapting Architectures Towards the Improved
  Training of Deep Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_14.html">
      <font color="black">Conflicting Bundles: Adapting Architectures Towards the Improved
  Training of Deep Neural Networks</font>
    </a>
  </h2>
  <font color="black">これらの調査結果に基づいて、パフォーマンスを低下させるレイヤーを自動的に削除する新しいアルゴリズムが導入されました。このアルゴリズムによって検出されたアーキテクチャは、最先端のアーキテクチャと比較した場合、競争力のある精度を実現します。最悪の場合、そのようなレイヤーまったくトレーニングできないネットワークにつながる可能性があります。 
[ABSTRACT]テストの精度を低下させるレイヤーのネットワークは、トレーニングの開始時に早くも実行されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Single Rotation Averaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_15.html">
      <font color="black">Robust Single Rotation Averaging</font>
    </a>
  </h2>
  <font color="black">第三に、Weiszfeldアルゴリズムを使用して弦の$ L_1 $ -meanを近似する方法を提案します。Weiszfeldアルゴリズムを使用して単一回転平均化の新しい方法を提案します。第二に、に組み込むことができる外れ値除去スキームを提案します。 $ L_1 $回転平均のロバスト性を改善するWeiszfeldアルゴリズム。 
[ABSTRACT]入力回転の要素ごとの中央値に基づくロバストな初期化を提案します。weiszfeldの方法と最先端技術は、提案された方法を使用して同等に良好に機能します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-01">
        <br><font color="black">2020-04-01</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Active Learning with Augmentation-based Consistency Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_16.html">
      <font color="black">Deep Active Learning with Augmentation-based Consistency Estimation</font>
    </a>
  </h2>
  <font color="black">アクティブラーニングでは、主に次の学習サイクルの一般化能力を強化するためのラベルなしデータの選択戦略に焦点を当てています。この事実により、データ拡張ベースの手法をアクティブラーニングに適用することにより、一般化能力を向上させる方法論を提案します。学習シナリオ..データ拡張ベースの正規化損失について、カットアウト（co）およびカットミックス（cm）戦略を定量的メトリックとして再定義し、モデルトレーニングとラベルなしデータ選択ステップの両方に適用しました。 
[ABSTRACT]分析学習理論からの正則化は、既存の不確かさ測定方法に基づく分類器の一般化機能に影響を与える可能性があります。提案されたデータ拡張ベースの正則化損失、カットアウト（co）およびカットミックス（cm）戦略を定量的メトリックとして再定義し、適用しましたモデルトレーニングとラベルなしデータ選択ステップの両方で</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Compositional Scalable Object SLAM -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_17.html">
      <font color="black">Compositional Scalable Object SLAM</font>
    </a>
  </h2>
  <font color="black">これを達成するために、明確な永続オブジェクトのランドマークを取得する新しい意味支援データ関連付け戦略と、信頼性の高いフレームからモデルへのRGB-D追跡を可能にする2.5D合成レンダリング方法を提案します。オープンソースの実装はhttpsで提供されます。 ：// placeholder ..屋内シーンをオブジェクトのグラフとして表す、高速でスケーラブルで正確な同時ローカリゼーションおよびマッピング（SLAM）システムを紹介します。 
[概要]システムは、1枚のグラフィックカードでほぼフレームレートで実行できるアップグレードを提供します。最先端のベースラインに対する包括的な評価を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Hyperrealistic Image Inpainting with Hypergraphs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_18.html">
      <font color="black">Hyperrealistic Image Inpainting with Hypergraphs</font>
    </a>
  </h2>
  <font color="black">さらに、予測画像の局所的な一貫性を強制するために、ディスクリミネーターにゲート畳み込みを導入します。この注意メカニズムは、グローバルコンテキストをキャプチャできないため、意味的にもっともらしいがぼやけた結果を生成します。Places2、CelebA-HQ、Paris StreetViewでの実験、およびFacadesデータセットは、私たちのアプローチが最先端の結果を達成していることを示しています。 
[概要]ハイパーグラフ畳み込みは、画像の空間的特徴に使用されたことはありません-ハイパーグラフタスク。システムを使用して、データ間の複雑な関係を学習できます。places2、celeba-hq、パリのストリートビュー、ファサードのデータセットでの実験、私たちのアプローチが最先端の結果を達成していることを示す</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: An analysis of the transfer learning of convolutional neural networks
  for artistic images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_19.html">
      <font color="black">An analysis of the transfer learning of convolutional neural networks
  for artistic images</font>
    </a>
  </h2>
  <font color="black">特に、ネットワークがいくつかの事前トレーニング済みフィルターを新しい画像モダリティに特化できること、および上位レイヤーがクラスを集中させる傾向があることを観察しました。このペーパーでは、手がかりを提供するために、最初にネットワーク内部表現を視覚化する手法を使用します。ネットワークが芸術的画像で何を学習したかを理解するために..次に、特徴空間とパラメータ空間の両方のメトリック、および最大値のセットで計算されたメトリックのおかげで、学習プロセスによって導入された変化の定量分析を提供しますアクティベーション画像。 
[概要]転移学習の効果はまだよくわかっていませんが、転移データがどのように機能するかを想像することは依然として困難です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Training EfficientNets at Supercomputer Scale: 83% ImageNet Top-1
  Accuracy in One Hour -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_20.html">
      <font color="black">Training EfficientNets at Supercomputer Scale: 83% ImageNet Top-1
  Accuracy in One Hour</font>
    </a>
  </h2>
  <font color="black">さらに、EfficientNetの動作を大規模に分析するために、ImageNetデータセットでトレーニングされたEfficientNetモデルのタイミングとパフォーマンスのベンチマークを示します。1024TPU-v3コアでトレーニングをバッチサイズ65536にスケーリングするために必要な最適化について説明します。大規模なバッチオプティマイザーと学習率スケジュールを選択し、分散評価とバッチ正規化手法を利用します。最適化により、ImageNetでEfficientNetを1時間4分で83％の精度でトレーニングできます。 
[概要]現在、efficiencynet-b0モデルのトレーニングには数日かかる場合があります。たとえば、efficiencynet-upモデルのトレーニングにはクラウドで23時間かかります。さらに、imagenetでefficiencynetを次の精度でトレーニングできます。 1時間4分で83％</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-30">
        <br><font color="black">2020-10-30</font>
      </time>
    </span>
</section>
<!-- paper0: Group Knowledge Transfer: Federated Learning of Large CNNs at the Edge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_21.html">
      <font color="black">Group Knowledge Transfer: Federated Learning of Large CNNs at the Edge</font>
    </a>
  </h2>
  <font color="black">FedGKTは、エッジノードで小さなCNNをトレーニングし、知識蒸留によって知識を定期的に大きなサーバー側CNNに転送するための交互最小化アプローチの変形を設計します。FedGKTは、エッジ計算の需要の削減、通信の削減など、いくつかの利点を単一のフレームワークに統合します。 FedAvgに匹敵するモデル精度を維持しながら、大規模なCNNの帯域幅と非同期トレーニング。FedAvgを使用したエッジトレーニングと比較して、FedGKTはエッジデバイスで必要な計算能力（FLOP）が9〜17倍少なく、必要なパラメーターが54〜105倍少なくなります。エッジCNNで。 
[ABSTRACT]フェデレーション学習（fl）は、プライバシーと機密性のプロパティプロパティのためにflが実際に強く必要とされている場合でも、エッジノードの計算機能に過度の負担をかける可能性があります。cnnsはfedavgと同等またはわずかに高い精度を得ることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-28">
        <br><font color="black">2020-07-28</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Data Augmentation for Consistency Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_22.html">
      <font color="black">Unsupervised Data Augmentation for Consistency Training</font>
    </a>
  </h2>
  <font color="black">コードはhttps://github.com/google-research/udaで入手できます。私たちの方法は、BERTから微調整する場合など、転送学習ともうまく組み合わせて、ImageNetなどの高データ体制を改善します。ラベル付きデータが10％しかない場合、またはラベルなしの例が130万個追加された完全なラベル付きセットを使用した場合。ラベル付きの例が20個しかないIMDbテキスト分類データセットでは、エラー率4.20を達成し、現在の状態を上回っています。 -25,000のラベル付きの例でトレーニングされた最先端のモデル。 
[ABSTRACT]高速追跡方式は、ノイズ処理と、ランダグメントや逆変換などの高度なデータ拡張方式を組み合わせたものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-29">
        <br><font color="black">2019-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: Learning a Decentralized Multi-arm Motion Planner -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_23.html">
      <font color="black">Learning a Decentralized Multi-arm Motion Planner</font>
    </a>
  </h2>
  <font color="black">この論文では、マルチエージェント強化学習でこの問題に取り組みます。分散型ポリシーは、マルチアームシステム内の1つのロボットアームを制御して、ワークスペースの状態とターゲットエンドの観察を前提として、ターゲットエンドエフェクタのポーズに到達するようにトレーニングされます。エフェクターポーズ..チームサイズに合わせてスケーラブルで柔軟な閉ループマルチアームモーションプランナーを紹介します。閉ループと分散型の定式化のおかげで、私たちのアプローチは5〜10のマルチアームシステムと動的な移動ターゲットに一般化されます。 （10アームシステムで&gt; 90％の成功率）静的ターゲットを使用した1〜4アーム計画タスクのみのトレーニングを受けているにもかかわらず。 
[ABSTRACT]システムは、ソフトアクター（サンプリングからの専門家によるデモンストレーションを伴う批評家）を使用してトレーニングされます。ベースのモーションプランニングアルゴリズム。システムは、さまざまなチームサイズのマルチアームシステムに展開できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: This Looks Like That, Because ... Explaining Prototypes for
  Interpretable Image Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_24.html">
      <font color="black">This Looks Like That, Because ... Explaining Prototypes for
  Interpretable Image Recognition</font>
    </a>
  </h2>
  <font color="black">また、視覚的に類似したプロトタイプでも同じ説明が可能であり、冗長性を示していることも明らかにします。モデルで重要と見なされる視覚的特性に関する追加情報を使用してプロトタイプを自動的に拡張することにより、解釈可能性を向上させます。このあいまいさに対処し、プロトタイプを説明する必要があると主張します。 
[概要]ユーザーは分類戦略を知らず、どの画像特性が決定の主要な特性であるかを知りません。プロトタイプを視覚化するだけでは、プロトタイプが正確に何を表しているのか、プロトタイプと画像が類似していると見なされる理由を理解するには不十分な場合があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: DTGAN: Dual Attention Generative Adversarial Networks for Text-to-Image
  Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_25.html">
      <font color="black">DTGAN: Dual Attention Generative Adversarial Networks for Text-to-Image
  Generation</font>
    </a>
  </h2>
  <font color="black">ベンチマークデータセットの実験結果は、多段階フレームワークを備えた最先端のモデルと比較して、提案された方法の優位性を示しています。提案されたモデルは、ジェネレータをに導くことができるチャネル認識およびピクセル認識の注意モジュールを導入します。グローバルセンテンスベクトルに基づいてテキスト関連のチャネルとピクセルに焦点を合わせ、注意の重みを使用して元の特徴マップを微調整します。さらに、新しいタイプの視覚的損失を利用して、鮮やかな形状と知覚を確保することで画質を向上させます。生成された画像の均一な色分布。 
[概要]デュアルアテンションgenuslネットワーク（dtgan）は、プロジェクトに基づく単一のジェネレーターまたはディスクリミネーターを使用するだけで、高品質で視覚的にリアルな画像を合成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Center-wise Local Image Mixture For Contrastive Representation Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_26.html">
      <font color="black">Center-wise Local Image Mixture For Contrastive Representation Learning</font>
    </a>
  </h2>
  <font color="black">特に、ResNet-50を介した線形評価で75.5％のトップ1精度に達し、1％のラベルのみで微調整すると59.3％のトップ1精度に達し、いくつかのダウンストリーム転送タスクで教師あり事前トレーニングを一貫して上回っています。CLIM類似の画像を取得しながら、ローカルの類似性とグローバルな集約の両方を促進します。さらに、画像の混合は、選択されたサンプルに対する過信を回避するための平滑化正則化として使用されます。 
[概要]この論文では、画像の50年代を拡張するために、中央方向のローカル画像混合と呼ばれる新しい種類のデータ拡張を提案します。これは、画像のローカルの類似サンプルを検索することによって実現され、より近い画像のみを選択します。対応するクラスターの中心。結果は、選択したサンプルに対する自信過剰を回避するための平滑化コントラストとしても使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: AOT: Appearance Optimal Transport Based Identity Swapping for Forgery
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_27.html">
      <font color="black">AOT: Appearance Optimal Transport Based Identity Swapping for Forgery
  Detection</font>
    </a>
  </h2>
  <font color="black">最適な輸送計画のソリューションをさらに洗練するために、ピクセル空間でのワッサースタイン距離を最小化するセグメンテーションゲームを開発します。ただし、複雑な外観マッピングのモデリングが難しいため、きめの細かい外観を適応的に転送することは困難です。アイデンティティ特性を維持しながら..最近の研究では、偽造検出のパフォーマンスは、多様でやりがいのあるDeepfakesデータセットを使用して改善できることが示されています。 
[概要]外観のギャップは主に外観の大きな不一致から生じますが、ディープフェイクのデータセットがないため、この状況では検出アルゴリズムが失敗する可能性があります。この記事では、両方でそれを定式化するための外観最適輸送モデル（aot）を提案します。潜在空間とピクセル空間</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Generating Unobserved Alternatives: A Case Study through
  Super-Resolution and Decompression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_28.html">
      <font color="black">Generating Unobserved Alternatives: A Case Study through
  Super-Resolution and Decompression</font>
    </a>
  </h2>
  <font color="black">その結果、観測された出力とは異なる高品質の出力を生成するために使用できます。この特性を持ついくつかの問題を調査し、同じ入力で複数の高品質の予測を生成できるアプローチを開発します。現在の設定に対する回帰法と条件付き生成モデルのいずれかは、多くの場合、入力ごとに1つの予測しかできないモデルになります。 
[要約]モデルは、同じ入力が与えられた場合に複数の高品質の予測を生成できます。また、複数の高品質の予測を生成することもできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: VEGA: Towards an End-to-End Configurable AutoML Pipeline -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_29.html">
      <font color="black">VEGA: Towards an End-to-End Configurable AutoML Pipeline</font>
    </a>
  </h2>
  <font color="black">c）ディープラーニングフレームワークの共通コンポーネントを統合インターフェースに抽象化します。この作業では、複数のハードウェアプラットフォームと互換性があり、最適化された効率的で包括的なAutoMLフレームワークであるVEGAを紹介します。複数のタスクでの広範なベンチマーク実験により、 VEGAは、既存のAutoMLアルゴリズムを改善し、SOTAメソッドに対して新しい高性能モデルを発見できます。たとえば
[ABSTRACT] automlは、us.vegaで開発できるautomlシステムであり、自動データ拡張、モデル圧縮など、automlの複数のモジュールで動作します。 、および完全にトレーニングする</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: The DongNiao International Birds 10000 Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_30.html">
      <font color="black">The DongNiao International Birds 10000 Dataset</font>
    </a>
  </h2>
  <font color="black">機械学習と鳥類学の研究を可能にするために作成されました。DongNiaoInternationalBirds10000（DIB-10K）は、1万種類以上の鳥がいる挑戦的な画像データセットです。DIB-10Kは著作権を所有していません。これらの画像の。 
[概要]このソフトウェアは、機械学習の学習を可能にするために作成されました。imagenetと同様の方法で、画像のサムネイルのみを提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-21">
        <br><font color="black">2020-09-21</font>
      </time>
    </span>
</section>
<!-- paper0: Defense-friendly Images in Adversarial Attacks: Dataset and Metrics
  forPerturbation Difficulty -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_31.html">
      <font color="black">Defense-friendly Images in Adversarial Attacks: Dataset and Metrics
  forPerturbation Difficulty</font>
    </a>
  </h2>
  <font color="black">データセットの偏りは、敵対的な機械学習、特に防御の評価において問題になります。ディープラーニングは、画像認識のための最先端のソリューションを提供しますが、ディープモデルは小さな摂動に対しても脆弱です。この調査エリアは主に敵対的な攻撃と防御アルゴリズムに焦点を当てています。敵対的な攻撃または防御アルゴリズムは、他のデータセットで複製できるよりも、報告されたデータセットでより良い結果を示す可能性があります。2つのアルゴリズムを比較した場合でも、それらの相対的なパフォーマンスは、データセット。 
[概要]堅牢な画像の割合が高いテストデータセットは、敵対的な攻撃または防御のパフォーマンスについて誤解を招く印象を与えます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Goal-driven Long-Term Trajectory Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_32.html">
      <font color="black">Goal-driven Long-Term Trajectory Prediction</font>
    </a>
  </h2>
  <font color="black">この結果は、人間の行動分析における視覚的および幾何学的特徴の適応構造化表現の有効性の別の証拠です。私たちは、目標駆動型軌道予測モデルを設計します。これは、そのような直感を実現するデュアルチャネルニューラルネットワークです。確かに、一貫性のある安定した予測軌道の終わりまでは、本質的に、その軌道の全体的な構造をより深く分析する必要があります。これは、旅行の目的地に対する歩行者の意図に関連しています。 
[要約]このシステムは、さまざまな設定、特に大規模な予測範囲において、最先端技術をしのぐことが示されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Post-Comparison Mitigation of Demographic Bias in Face Recognition Using
  Fair Score Normalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_33.html">
      <font color="black">Post-Comparison Mitigation of Demographic Bias in Face Recognition Using
  Fair Score Normalization</font>
    </a>
  </h2>
  <font color="black">私たちの仮説は、同様の個人を同様に扱うことにつながる正規化アプローチを設計することにより、個人の公平性の表記に基づいています。性別を考慮した場合、最大82.7％です。さらに、既存の認識システムに簡単に統合できます。顔のバイオメトリクスに限定されます。 
[概要]これまでの作業は、主に偏りの少ない顔の表現の学習に重点を置いていました。これにより、全体的な認識パフォーマンスが大幅に低下するリスクが軽減されます。ただし、新しいシステムは、偏りをより一貫して軽減します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-10">
        <br><font color="black">2020-02-10</font>
      </time>
    </span>
</section>
<!-- paper0: R-MNet: A Perceptual Adversarial Network for Image Inpainting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_34.html">
      <font color="black">R-MNet: A Perceptual Adversarial Network for Image Inpainting</font>
    </a>
  </h2>
  <font color="black">顔画像の修復は広く研究されている問題であり、近年、Generative Adversarial Networksの導入により、この分野の改善につながっています。公開されているデータセットで方法を評価し、最先端技術と比較します。メソッド..私たちのメソッドが高解像度の修復タスクに一般化できることを示し、最先端のメソッドと比較した場合に人間の視覚系にもっともらしいより現実的な出力をさらに示します。 
[概要]顔認識ソフトウェアを使用して新しい画像を作成できます。私たちの方法が高解像度の修復タスクに一般化できることを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-11">
        <br><font color="black">2020-08-11</font>
      </time>
    </span>
</section>
<!-- paper0: SketchEmbedNet: Learning Novel Concepts by Imitating Drawings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_35.html">
      <font color="black">SketchEmbedNet: Learning Novel Concepts by Imitating Drawings</font>
    </a>
  </h2>
  <font color="black">次に、それらを使用して、Omniglotおよびmini-ImageNetベンチマークでの教師なし数ショット分類の最先端のパフォーマンスを超えます。また、モデルの生成能力を活用して、以下に基づいた新しいクラスの高品質のスケッチを作成します。単一の例..この作業では、生成モデルをトレーニングして、スケッチドメイン内の多くのクラスのピクセル画像からスケッチを生成することによって開発された表現を調査します。 
[ABSTRACT]スケッチはリカレントニューラルネットワークによって開発されました。一度に1つまたは少数のクラスからスケッチ図面を作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-27">
        <br><font color="black">2020-08-27</font>
      </time>
    </span>
</section>
<!-- paper0: Fast Object Detection with Latticed Multi-Scale Feature Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_36.html">
      <font color="black">Fast Object Detection with Latticed Multi-Scale Feature Fusion</font>
    </a>
  </h2>
  <font color="black">この作業では、現在のマルチスケール融合方法の欠点を軽減し、マルチスケールオブジェクトの検出を容易にするために、新しいモジュールであるFluffブロックを紹介します。さらに、Fluffブロックの埋め込み方法を示すことにより、Fluffブロックの優れた一般性を示します。具体的には、Fluffは、拡張畳み込みを使用したマルチレベルスキームとマルチブランチスキームの両方を活用して、迅速で効果的かつきめ細かい特徴の融合を実現します。 
[ABSTRACT] fluffnetは、最先端のスケール精度で驚異的な効率を生み出します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Transforming Facial Weight of Real Images by Editing Latent Space of
  StyleGAN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_37.html">
      <font color="black">Transforming Facial Weight of Real Images by Editing Latent Space of
  StyleGAN</font>
    </a>
  </h2>
  <font color="black">最終的に、私たちのフレームワークは、行動が外観に与える将来の影響を視覚化することにより、個人がより健康的な食品を選択するように動機付ける介入の一部として利用できます。抽出された特徴軸に沿って正または負に移動することにより、反転潜在コードを編集します。私たちのフレームワークは、大量のラベル付き顔画像を使用してGANを最初からトレーニングする必要なしに、高品質でリアルな顔の重み変換を生成することが経験的に示されています。 
[概要]事前にトレーニングされたスタイルガンをメインジェネレーターとして使用して、入力画像をスタイルガンの潜在空間に反転します。次に、アルゴリズムベースの埋め込み方法を使用して、学習画像を潜在空間に反転します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: A Coarse-To-Fine (C2F) Representation for End-To-End 6-DoF Grasp
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_38.html">
      <font color="black">A Coarse-To-Fine (C2F) Representation for End-To-End 6-DoF Grasp
  Detection</font>
    </a>
  </h2>
  <font color="black">また、単一オブジェクトシーンでの成功率とクラッターシーンでの完了率の点で、それぞれ8％と40％正確です。エンドツーエンドの把握検出ネットワークである把握検出ネットワーク（GDN）を提案しました。点群に基づいて多様で正確な6-DoF把持を検出するために、新しい粗から微細（C2F）把持表現設計と協力しました。さらに、回転誤差と遷移誤差の両方を考慮した新しいAPベースのメトリックを提案します。把握検出モデルのためのより包括的な評価ツール。 
[概要]私たちのアーキテクチャは少なくとも20倍高速です。以前の2-fアプローチよりも正確です。私たちの方法は設定で優れた結果を示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-21">
        <br><font color="black">2020-10-21</font>
      </time>
    </span>
</section>
<!-- paper0: Universal Multi-Source Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_39.html">
      <font color="black">Universal Multi-Source Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">UMDAの主な課題は、各ソースドメインとターゲットドメインの間に設定された共通ラベルを識別し、ソースドメインの数が増えるにつれてモデルをスケーラブルに保つことです。UMANでは、共通ラベル内の既知の各クラスの信頼性を推定します。予測マージンを介して設定されます。これは、敵対者のトレーニングが共通のラベルセット内の複数のソースドメインとターゲットドメインの分布をより適切に調整するのに役立ちます。これらの課題に対処するために、ドメインを解決するためのユニバーサルマルチソース適応ネットワーク（UMAN）を提案します。さまざまなUMDA設定でモデルの複雑さを増すことなく適応問題。 
[ABSTRACT]ユニバーサルドメインアダプテーション（uda）は、ユニバーサルマルチソースドメインアダプテーションです。システムは、さまざまなumda設定でモデルの複雑さを増すことなく問題を解決するように設計されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-level Chaotic Maps for 3D Textured Model Encryption -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_40.html">
      <font color="black">Multi-level Chaotic Maps for 3D Textured Model Encryption</font>
    </a>
  </h2>
  <font color="black">認識への寄与が比較的小さいポリゴンとテクスチャの場合、それぞれ2Dアーノルドの猫写像と1Dロジスティック写像を使用して暗号化します。さらに、この方法は、統計攻撃、ブルートフォース攻撃、相関など、より多くの攻撃方法に抵抗できます。攻撃..仮想現実技術と拡張現実技術の急速な進歩により、3Dコンテンツは多くのアプリケーションで次に普及しているメディアです。 
[概要] 3Dモデルの保護は主に重要です。この方法は他のモデルと同様のパフォーマンスを得ることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2017-09-25">
        <br><font color="black">2017-09-25</font>
      </time>
    </span>
</section>
<!-- paper0: Lets Play Music: Audio-driven Performance Video Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_41.html">
      <font color="black">Lets Play Music: Audio-driven Performance Video Generation</font>
    </a>
  </h2>
  <font color="black">それらは、グラフベースの構造モジュールとCNN-GRUベースの高レベル時間モジュールを介してそれぞれ最終的なビデオ生成のために取得されます。この論文では、この新しいタスクを達成するための多段階フレームワークを提案し、 music ..包括的な実験により、提案されたフレームワークの有効性が検証されます。 
[概要]マルチミールアララルアララルアララルビデオへの挑戦です。致命的でないオーディオモダリティからこれらのビデオを作成するために使用できることをお勧めします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: UAV-AdNet: Unsupervised Anomaly Detection using Deep Neural Networks for
  Aerial Surveillance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_42.html">
      <font color="black">UAV-AdNet: Unsupervised Anomaly Detection using Deep Neural Networks for
  Aerial Surveillance</font>
    </a>
  </h2>
  <font color="black">コード、トレーニング済みモデル、データセット、およびビデオは、https：//bozcani.github.io/uavadnetで入手できます。次に、教師なし異常検出用のディープニューラルネットワークアーキテクチャ（UAV-AdNet）を提案します。バードビュー画像の環境表現とGPSラベルを共同で..文献の研究とは異なり、GPSと画像データを組み合わせて異常な観測を予測します。 
[概要]この論文では、全体的な異常検出システムを提案します。これは、鳥の環境表現とgpsラベルでトレーニングされ、画像を共同で表示します。これらの研究は、シーンの再構築といくつかの異常検出タスクで優れたパフォーマンスを発揮することを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: CompressAI: a PyTorch library and evaluation platform for end-to-end
  compression research -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_43.html">
      <font color="black">CompressAI: a PyTorch library and evaluation platform for end-to-end
  compression research</font>
    </a>
  </h2>
  <font color="black">このように、学習したエンドツーエンド圧縮に関する最先端の複数のモデルがPyTorchに再実装され、ゼロからトレーニングされました。このフレームワークは現在、静止画圧縮のモデルを実装していますが、間もなく拡張される予定です。特に、CompressAIには、学習した方法を従来のコーデックと比較するための事前トレーニング済みモデルと評価ツールが含まれています。 
[ABSTRACT] compressaiには、事前にトレーニングされたモデルと評価ツールが含まれています。compressaiは、学習したメソッドを従来のコーデックと比較するための事前にトレーニングされたモデルを提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Unsupervised Video Anomaly Detection by Multi-Path Frame
  Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_44.html">
      <font color="black">Robust Unsupervised Video Anomaly Detection by Multi-Path Frame
  Prediction</font>
    </a>
  </h2>
  <font color="black">CUHKアベニュー、上海科技大学、UCSD歩行者データセットで広範な実験が行われ、その結果は、提案された方法が既存の最先端のアプローチよりも優れていることを示しています。一方、フレーム予測ベースの異常検出方法は有望であることが示されています。パフォーマンス..バックグラウンドノイズによって引き起こされる干渉を軽減するために、トレーニング中にノイズ耐性損失が導入されます。 
[概要]最近のビデオ異常検出アプローチの大部分は、深い再構成モデルを使用していますが、パフォーマンスが不足しているため、パフォーマンスが不均衡になることがよくあります。現在、提案されている方法は、監視ビデオの特性とより一致しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: CIMON: Towards High-quality Hash Codes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_45.html">
      <font color="black">CIMON: Towards High-quality Hash Codes</font>
    </a>
  </h2>
  <font color="black">いくつかのベンチマークデータセットでの広範な実験により、提案された方法は、検索パフォーマンスと堅牢性の両方で、幅広い最先端の方法を一貫して上回っています。さらに、ほとんどのハッシュ方法は、衝突などのハッシュコードの基本的な特性を無視します。これにより、ハッシュコードが不安定になります。最近、ハッシュは、そのストレージと計算効率のために、近似最近傍検索で広く使用されています。 
[概要]ほとんどの研究は監視されていないハッシュに焦点を当てていますが、事前にトレーニングされたモデルの非効率的な表現能力のため、ローカルの意味的類似性に多くの誤検知と誤検知が導入されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: Few-Shot Object Detection in Real Life: Case Study on Auto-Harvest -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CV/paper_46.html">
      <font color="black">Few-Shot Object Detection in Real Life: Case Study on Auto-Harvest</font>
    </a>
  </h2>
  <font color="black">しかし、一般的に使用されるトレーニングデータセットと実際の農業シナリオで収集された画像との間にはコンテキストギャップがあるため、実際の農業アプリケーションに直接使用できるかどうかは依然として疑問です。実験結果は、1）状態-最先端の数ショットのオブジェクト検出モデルは、新しい「キュウリ」カテゴリではパフォーマンスが低下します。 2）提案された拡張戦略は、一般的に使用されているものよりも優れています。この目的のために、この研究では、新しいキュウリデータセットを提示し、コンテキストギャップを埋めるのに役立つ2つのデータ拡張戦略を提案します。 
[概要]たとえば、機械的収穫または自動-オブジェクト検出の収穫は緊急の必要性です。プロジェクトはコミュニティによって開発され、コンテキストを埋めるのに役立つ可能性があります-ギャップ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: LXPER Index 2.0: Improving Text Readability Assessment for L2 English
  Learners in South Korea -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_0.html">
      <font color="black">LXPER Index 2.0: Improving Text Readability Assessment for L2 English
  Learners in South Korea</font>
    </a>
  </h2>
  <font color="black">外国語英語トレーニング（ELT）カリキュラムのテキスト専用のテキスト可読性評価モデルの開発は、自然言語処理の分野ではこれまであまり注目されていませんでした。各テキストには、目標グレードレベルのラベルが付けられています。CoKECを使用してモデルをトレーニングします。 -テキストを作成し、韓国のELTカリキュラムのテキストの読みやすさ評価の精度を大幅に向上させます。 
[概要]韓国語のエルトカリキュラムのテキストコーパス（cokec-text）はこれまで見つかりませんでした。さまざまな英語英語英語研究を開発するために開発されました。しかし、l2英語テキストの不足は非常に少ないです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-26">
        <br><font color="black">2020-10-26</font>
      </time>
    </span>
</section>
<!-- paper0: Imagining Grounded Conceptual Representations from Perceptual
  Information in Situated Guessing Games -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_1.html">
      <font color="black">Imagining Grounded Conceptual Representations from Perceptual
  Information in Situated Guessing Games</font>
    </a>
  </h2>
  <font color="black">視覚的な推測ゲームでは、推測者はOracleに質問して、シーン内のターゲットオブジェクトを特定する必要があります。これにより、推論時のカテゴリがトレーニング時のカテゴリと一致する場合にパフォーマンスが不自然になり、モデルがより現実的に失敗します。ドメイン外のオブジェクトカテゴリが関係する「ゼロショット」シナリオ。ただし、Suglia etal。 
[概要] 2020年、既存のモデルは真のマルチモーダル表現を学習できません。これは、オブジェクトのゴールドカテゴリラベルに依存しているためです。「イマジネーション」モジュールは、正規化されたオートエンコーダに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: CliniQG4QA: Generating Diverse Questions for Domain Adaptation of
  Clinical Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_2.html">
      <font color="black">CliniQG4QA: Generating Diverse Questions for Domain Adaptation of
  Clinical Question Answering</font>
    </a>
  </h2>
  <font color="black">QAモデルのトレーニングに不可欠なさまざまなタイプの質問を生成するために、既存のほとんどのQGモデルと一緒に使用して生成を多様化できるseq2seqベースの質問フレーズ予測（QPP）モジュールをさらに導入します。この課題に対処するため、シンプルで効果的なフレームワーク、CliniQG4QAを提案します。これは、質問生成（QG）を活用して、新しい臨床コンテキストでQAペアを合成し、手動の注釈を必要とせずにQAモデルをブーストします。研究によると、1つのコーパスでトレーニングされたニューラルQAモデルは一般化されない可能性があります。大規模なQAペアを再トレーニングにすぐに利用できない別の研究所または別の患者グループからの新しい臨床テキストへ。 
[概要]新しい調査によると、単純な範囲の質問は再トレーニングに利用できません。これらには、seq2seqベースの質問フレーズ予測（qpp）モジュールが含まれており、ほとんどの既存のqgモデルと一緒に使用して世代を多様化できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-30">
        <br><font color="black">2020-10-30</font>
      </time>
    </span>
</section>
<!-- paper0: Quantifying Intimacy in Language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_3.html">
      <font color="black">Quantifying Intimacy in Language</font>
    </a>
  </h2>
  <font color="black">次に、3つの研究で、性別、社会的距離、聴衆に関する社会的規範に一致するように個人が親密さをどのように調整するかをさらに示し、それぞれが社会心理学の研究からの重要な発見を検証します。ここでは、言語における親密さの表現を研究するための新しい計算フレームワークと、質問の親密さのレベルを正確に予測するためのデータセットと深層学習モデルを紹介します（ピアソンのr = 0.87）。 
[要約]私たちの仕事は、親密さが言語の広範で影響力のある社会的側面であることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Knowing What You Know: Calibrating Dialogue Belief State Distributions
  via Ensembles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_4.html">
      <font color="black">Knowing What You Know: Calibrating Dialogue Belief State Distributions
  via Ensembles</font>
    </a>
  </h2>
  <font color="black">結果として得られる対話信念トラッカーは、精度の点でも以前の対話信念追跡モデルよりも優れています。一方、信念トラッカーは、可能な対話状態の分布を維持します。この作業では、キャリブレーションにおける最先端のパフォーマンスを示します。モデルのキャリブレーションされたアンサンブルを使用するマルチドメイン対話信念トラッカー用。 
[ABSTRACT]ダイアログ状態トラッカーは、現在の移動で55％をわずかに超える精度を達成します-ベンチマークに。ほぼ毎秒のダイアログターンで、誤ったダイアログ状態に完全な信頼を置きます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-06">
        <br><font color="black">2020-10-06</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Accent Adaptation based on Gate Mechanism -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_5.html">
      <font color="black">Multi-Accent Adaptation based on Gate Mechanism</font>
    </a>
  </h2>
  <font color="black">音響モデルとアクセント分類器を共同でトレーニングするために、ゲートメカニズムを使用したマルチタスク学習（MTL-G）を提案します。ただし、ベースラインモデルと比較して、MTL-Gは平均5.1％の相対WER削減を達成します。 、アクセント分類器を使用して適用し、アクセントラベルを予測します。 
[ABSTRACT] ast --gは、それぞれ9.8％と1.9％の平均相対ワー削減を達成します。ただし、アクセントパフォーマンスファイアはアクセントラベルに適応できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Entity Linking in 100 Languages -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_6.html">
      <font color="black">Entity Linking in 100 Languages</font>
    </a>
  </h2>
  <font color="black">この目的のために、設定に一致する大規模な新しい多言語データセット（http://goo.gle/mewsli-dataset）であるMewsli-9を提供し、頻度ベースの分析がモデルとトレーニングの機能強化に重要な洞察をどのように提供したかを示します。 。希少なエンティティとリソースの少ない言語は、この大規模な課題を提起するため、ゼロショットと少数ショットの評価にさらに重点を置くことを提唱します。このモデルは、はるかに限定されたクロスからの最先端の結果を上回ります。 -言語リンクタスク。 
[概要] 100の言語と2,000万のエンティティをカバーする単一のエンティティ検索モデルを作成するために、デュアルルックシステムをトレーニングします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: From Sentiment Annotations to Sentiment Prediction through Discourse
  Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_7.html">
      <font color="black">From Sentiment Annotations to Sentiment Prediction through Discourse
  Augmentation</font>
    </a>
  </h2>
  <font color="black">具体的には、大規模な感情依存のMEGA-DTツリーバンクと、ハイブリッドTreeLSTM階層的注意モデルに基づく感情予測のための新しいニューラルアーキテクチャを組み合わせています。単純なアンサンブルアプローチにより、選択的にパフォーマンスをさらに向上できることを示します。文書の長さに応じて、談話を使用します。感情分析、特に長い文書の場合、複雑な言語構造をキャプチャする方法が必要になる可能性があります。 
[要約]新しいモデルを使用して、感情分析のタスクのために「機能的に関連する」談話を活用することができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Conversational Machine Comprehension: a Literature Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_8.html">
      <font color="black">Conversational Machine Comprehension: a Literature Review</font>
    </a>
  </h2>
  <font color="black">会話型データセットへのモデル提出の量は毎年増加しているため、将来の研究を合理化するために、このドメインに散在する知識を統合する必要があります。この文献レビューでは、CMCの全体的な概要を提供し、全体の共通の傾向に重点を置いています。最近公開されたモデル、特に会話の歴史に取り組むアプローチにおいて。しかし、関心の高まりは、それぞれが異なるが構造的に類似したモデリングアプローチと周囲の文献の一貫性のない見方を持つ同時出版の急増につながりました。 
[ABSTRACT]マルチターンcmcは、自然言語理解の進歩のおかげで最近注目を集めています。研究を合理化するために、この領域に散在する知識を統合する必要があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br><font color="black">2020-06-01</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Commonsense Question Answering by Graph-based Iterative
  Retrieval over Multiple Knowledge Sources -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_9.html">
      <font color="black">Improving Commonsense Question Answering by Graph-based Iterative
  Retrieval over Multiple Knowledge Sources</font>
    </a>
  </h2>
  <font color="black">さらに、さらなるアブレーション研究は、複数の知識ソースから背景知識を検索および合成する際の、グラフベースの反復知識検索モジュールと回答選択認識注意モジュールの有効性を示しています。その後、事前にトレーニングされた言語モデルを使用してエンコードします。質問、検索された知識と選択、および前のモジュールのすべての隠された表現を融合するための回答選択認識注意メカニズムを提案します。CommonsenseQAデータセットの実験結果は、私たちの方法が他の競合方法を大幅に上回り、新しい状態を達成することを示しています-アート。 
[要約] conceptnet、wikipedia、およびcambridge辞書は、パフォーマンスの向上に役立つ可能性があります。このメソッドは、以前のモジュールのすべての隠された知識を組み合わせます。メソッドは、他の競合メソッドを大幅に上回り、新しい背景を実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: CLUE: A Chinese Language Understanding Evaluation Benchmark -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_10.html">
      <font color="black">CLUE: A Chinese Language Understanding Evaluation Benchmark</font>
    </a>
  </h2>
  <font color="black">CLUEは、いくつかの定評のある単一文/文ペア分類タスクにまたがる9つのタスクと、機械の読解をすべて元の中国語のテキストにまとめた、オープンエンドのコミュニティ主導のプロジェクトです。中国のNLUのさらなる進歩を促進するための補足データセットと追加ツールの一覧。これらのタスクの結果を確立するために、現在の最先端の事前トレーニング済み中国モデルの網羅的なセット（合計9）を使用してスコアを報告します。 
[概要]最初の大規模な中国語理解評価（手がかり）タスクが作成されました。結果を確立するために、事前にトレーニングされた中国語モデルの網羅的なセットを使用してスコアを報告します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-13">
        <br><font color="black">2020-04-13</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised Data Augmentation for Consistency Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_11.html">
      <font color="black">Unsupervised Data Augmentation for Consistency Training</font>
    </a>
  </h2>
  <font color="black">コードはhttps://github.com/google-research/udaで入手できます。私たちの方法は、BERTから微調整する場合など、転送学習ともうまく組み合わせて、ImageNetなどの高データ体制を改善します。ラベル付きデータが10％しかない場合、またはラベルなしの例が130万個追加された完全なラベル付きセットを使用した場合。ラベル付きの例が20個しかないIMDbテキスト分類データセットでは、エラー率4.20を達成し、現在の状態を上回っています。 -25,000のラベル付きの例でトレーニングされた最先端のモデル。 
[ABSTRACT]高速追跡方式は、ノイズ処理と、ランダグメントや逆変換などの高度なデータ拡張方式を組み合わせたものです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-29">
        <br><font color="black">2019-04-29</font>
      </time>
    </span>
</section>
<!-- paper0: Investigating Societal Biases in a Poetry Composition System -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_12.html">
      <font color="black">Investigating Societal Biases in a Poetry Composition System</font>
    </a>
  </h2>
  <font color="black">創造的な言語アプリケーションは、ユーザーとの直接の対話を目的としているため、これらのアプリケーションの社会的バイアスを定量化して軽減することが重要です。詩の構成システムで次の詩の提案を取得するときに、社会的バイアスを軽減するパイプラインに関する新しい研究を紹介します。私たちの結果は、感情スタイルの転送によるデータの増強が社会的バイアスを軽減する可能性があることを示唆しています。 
[概要]ある調査によると、データの増強は社会的偏見を緩和する可能性があります。創造的な言語アプリケーションは、ユーザーとの直接的な対話を目的としています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Competence-Level Prediction and Resume & Job Description Matching Using
  Context-Aware Transformer Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_13.html">
      <font color="black">Competence-Level Prediction and Resume & Job Description Matching Using
  Context-Aware Transformer Models</font>
    </a>
  </h2>
  <font color="black">このデータセットを前提として、2つのタスク用に新しいトランスフォーマーベースの分類モデルが開発されています。最初のタスクは履歴書を取得してCRCレベル（T1）に分類し、2番目のタスクは履歴書と職務記述書の両方を使用して適用してアプリケーションはジョブT2に適しています。私たちの分析によると、予測エラーは主に隣接するCRCレベル間で発生し、専門家でさえ区別するのが困難であり、実際のHRプラットフォームでのモデルの実用的な価値を示唆しています。セクションエンコーディングとマルチヘッドアテンションデコーディングを使用すると、T1で73.3％、T2で79.2％の結果が得られます。 
[概要]研究には合計6〜6、492の履歴書が必要です。これらには、臨床研究コーディネーターの4つのレベルの経験に指定された252のポジションの申請が含まれていました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: QMUL-SDS @ DIACR-ITA2020: Evaluating Unsupervised Diachronic Lexical
  Semantics Classification in Italian -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_14.html">
      <font color="black">QMUL-SDS @ DIACR-ITA2020: Evaluating Unsupervised Diachronic Lexical
  Semantics Classification in Italian</font>
    </a>
  </h2>
  <font color="black">私たちのモデルは、83.3 \％の精度で3位にランクされました。コンパスC-BOWモデルで時間的単語埋め込みを使用すると、ロジスティック回帰や精度を使用したフィードフォワードニューラルネットワークなどのさまざまなアプローチと比較して、より効果的であることを示します。 、DIACR-ITA2020タスクのシステムの結果と主な調査結果を示します。 
[概要]私たちのシステムは、トレーニングセットのバリエーションとさまざまなセマンティック検出方法の使用に重点を置いています。コンパスc-bowモデルを使用した単語の埋め込みは、ロジスティック野球や精度を使用したフィードフォワードニューラルネットワークなどのさまざまなアプローチと比較してより効果的です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Data Augmentation and Terminology Integration for Domain-Specific
  Sinhala-English-Tamil Statistical Machine Translation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_15.html">
      <font color="black">Data Augmentation and Terminology Integration for Domain-Specific
  Sinhala-English-Tamil Statistical Machine Translation</font>
    </a>
  </h2>
  <font color="black">この辞書用語のデータ拡張手法は、シンハラ語-英語SMTのBLEUスコアの改善を示しています。ただし、バイリンガルリストには基本形式の単語が含まれているため、シンハラ語やタミル語などの形態学的に豊富な言語の屈折形は翻訳されません。バイリンガルリストの統合OOV問題に対処するためのアプローチです。 
[概要]これにより、トレーニングデータよりも多くの単語を翻訳できます。言語を分析するため、さらに悪化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Context Aware Network Embeddings for Textual Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_16.html">
      <font color="black">Adversarial Context Aware Network Embeddings for Textual Networks</font>
    </a>
  </h2>
  <font color="black">実世界のデータセットでの広範な実験を通じて、モデルがいくつかの最先端のベンチマークを大幅に上回っていることを示しています。このホワイトペーパーでは、モダリティの融合と、見えないノードの埋め込みを学習する機能の両方を実現するアプローチを提案します。 ..テキストネットワークの表現学習は、（i）基盤となるネットワーク構造、および（ii）ノードのテキスト属性の2つのモダリティから統合された情報をキャプチャすることを伴うため、重大な課題をもたらします。 
[概要]これは、これらのアプローチが埋め込みを学習するためのエッジ情報を必要とすることを意味します。さらに、テキスト埋め込みを学習するための新しいアーキテクチャを提案します。トレーニングで見られないノードを含むリンクの予測を最大7％改善します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Comparison of Speaker Role Recognition and Speaker Enrollment Protocol
  for conversational Clinical Interviews -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_17.html">
      <font color="black">Comparison of Speaker Role Recognition and Speaker Enrollment Protocol
  for conversational Clinical Interviews</font>
    </a>
  </h2>
  <font color="black">最後に、結果がインタビュー対象者の人口統計に依存しないことを観察し、私たちの方法の臨床的関連性を強調しました。各タスクに適応し、同じメトリックの下で各アプローチを評価するために、エンドツーエンドのニューラルネットワークアーキテクチャをトレーニングしました。しかし、特に音声および言語障害のある個人の場合、話者の順番を検出および識別するためにどの音声処理パイプラインが最もパフォーマンスが高いかは明らかではありません。 
[要約]これらの声の自動分析は、新しい言語マーカーを抽出し、臨床医のレポートをスピードアップするのに役立ちます。これは、話者の役割の認識と音声登録方法の実行に役立つ可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-30">
        <br><font color="black">2020-10-30</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Adaptation Using Class Similarity for Robust Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_18.html">
      <font color="black">Domain Adaptation Using Class Similarity for Robust Speech Recognition</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチでは、最初にソースモデルを使用してソースサンプルのフレームレベルの事後確率を計算します。次に、各クラスについて、このクラスの確率を使用して平均ベクトルを計算します。これを平均ソフトラベルと呼びます。限られたターゲットドメインデータが利用可能であり、ドメイン適応は、十分に訓練されたソースモデルとターゲットドメインデータを活用することにより、ディープニューラルネットワーク（DNN）音響モデルのパフォーマンスを促進するために使用できます。 
[要約]クラスごとに、このクラスの確率を使用して、ソフトラベルという用語を取得します。このモデルは、パフォーマンスを向上させるためにソースモデルからターゲットモデルに転送できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Hallucinated Content in Conditional Neural Sequence Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_19.html">
      <font color="black">Detecting Hallucinated Content in Conditional Neural Sequence Generation</font>
    </a>
  </h2>
  <font color="black">また、自動的に挿入された幻覚を含む合成データで微調整された事前トレーニング済みの言語モデルに基づいて、幻覚検出をモデル化することを学習するための新しい方法を紹介します。機械翻訳と抽象的なテキストの要約に関する実験は、提案されたアプローチの有効性を示しています。すべてのベンチマークデータセットで平均F1が約0.6であり、ベースラインメソッドと比較して文レベルの幻覚スコアが大幅に向上しています。また、注釈付きのデータとコードを今後の調査用にhttps://github.com/violet-zct/でリリースします。 fairseq-detect-hallucination。 
[概要]マシン出力の忠実度をより適切に評価するために、各トークンがソース入力を条件として幻覚化されているかどうかを予測する新しいタスクを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Efficient Task-Specific Meta-Embeddings with Word Prisms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_20.html">
      <font color="black">Learning Efficient Task-Specific Meta-Embeddings with Word Prisms</font>
    </a>
  </h2>
  <font color="black">これらのプロパティは、埋め込みスペースに最も類似したベクトルを照会するとき、およびダウンストリームNLP問題を解決するためにトレーニングされたディープニューラルネットワークの入力レイヤーで使用されるときに現れます。6つの外部評価で他のメタ埋め込み方法と比較してワードプリズムを評価します。ワードプリズムは、トレーニング時に定義されたコンテキストの概念に応じて、すべてのタスクのパフォーマンスを向上させることに注意してください。 
[ABSTRACT]埋め込みは、異なるトレーニングを受けた単語埋め込みの複数のセットを組み合わせます。これらは、それらの1つのセットのみを使用する例に似ています。例には、これらの方法を組み合わせて非常に効率的な単語プリズムが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Context-Aware Answer Extraction in Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_21.html">
      <font color="black">Context-Aware Answer Extraction in Question Answering</font>
    </a>
  </h2>
  <font color="black">読解の実験により、BLANCは最先端のQAモデルよりも優れており、回答テキストの出現回数が増えるとパフォーマンスのギャップが大きくなることがわかります。この不一致は、回答の出現回数として特に重要になります。パッセージ内のテキストが増加します。ただし、正解のテキストを予測する結果になることもありますが、特定の質問とは無関係なコンテキストになります。 
[概要]これは、マルチタスク学習方式の補助タスクとしてのコンテキスト予測と、コンテキスト予測タスクを学習するブロックアテンション方式の2つの主要なアイデアに基づいています。また、分隊を使用してモデルをトレーニングし、予測する実験も行います。 hotpotqaに関する裏付けとなる事実</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Dark Jargon Interpretation in Underground Forums -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_22.html">
      <font color="black">Towards Dark Jargon Interpretation in Underground Forums</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、共有語彙上の確率分布の形で暗くてきれいな単語の解釈可能な表現を利用します。私たちの実験では、シミュレートされたデータの別の関連する方法よりも優れているため、暗い専門用語の識別に関して効果的であることが示されています。 ..手動評価を使用して、私たちの方法が実際の地下フォーラムデータセットで暗い専門用語を検出できることを示します。 
[要約]私たちの実験では、シミュレーションデータで他の関連する方法よりも優れているため、暗い専門用語の識別に関して効果的であることが私たちの方法を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Event Duration Prediction via Time-aware Pre-training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_23.html">
      <font color="black">Improving Event Duration Prediction via Time-aware Pre-training</font>
    </a>
  </h2>
  <font color="black">また、モデルが教師なし設定で期間予測が可能であり、ベースラインを上回っていることを示します。時間関連のニュース文を読むことによって外部の知識を組み込んだ、期間予測の2つの効果的なモデルを紹介します（時間認識事前トレーニング）。具体的には、1つのモデルは、期間の値が含まれる範囲/単位を予測します（R-pred）。もう1つは、正確な期間値E-predを予測します。 
[概要]期間予測用に2つのモデルを導入します。1つのモデル、e-predは、以前の作業を大幅に上回っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Beneath the Tip of the Iceberg: Current Challenges and New Directions in
  Sentiment Analysis Research -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_24.html">
      <font color="black">Beneath the Tip of the Iceberg: Current Challenges and New Directions in
  Sentiment Analysis Research</font>
    </a>
  </h2>
  <font color="black">現在の関連性の原因となる大きな飛躍を分析します。フィールドとしての感情分析は、20年近く前にタスクとして最初に導入されて以来、長い道のりを歩んできました。マーケティング、リスク管理など、さまざまな分野で幅広い商用アプリケーションがあります。いくつか例を挙げると、市場調査、および政治。 
[ABSTRACT]センチメントは、マーケティング、リスク管理、極性、および政治に広く行き渡っています。マーケティングやリスク管理などのさまざまな分野で幅広い商用アプリケーションがあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: MEGA RST Discourse Treebanks with Structure and Nuclearity from Scalable
  Distant Sentiment Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_25.html">
      <font color="black">MEGA RST Discourse Treebanks with Structure and Nuclearity from Scalable
  Distant Sentiment Supervision</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、確率的コンポーネントで拡張された効率的なヒューリスティックビーム検索戦略に依存することにより、任意の長さのドキュメントの構造と核性を組み込んだ談話ツリーを生成します。複数のデータセットでの実験は、MEGA-DTツリーバンクでトレーニングされた談話パーサーが有望であることを示しています人間が注釈を付けた談話コーパスでトレーニングされたパーサーと比較した場合、ドメイン間のパフォーマンスが向上します。大きくて多様な談話ツリーバンクがないため、深層学習などのデータ駆動型アプローチをRSTスタイルの談話解析に適用できません。 
[概要]メガ-dtは新しい大規模な談話-注釈付きコーパスです。感情からの遠い監視を使用します-注釈付きデータセット</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: BW-EDA-EEND: Streaming End-to-End Neural Speaker Diarization for a
  Variable Number of Speakers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_26.html">
      <font color="black">BW-EDA-EEND: Streaming End-to-End Neural Speaker Diarization for a
  Variable Number of Speakers</font>
    </a>
  </h2>
  <font color="black">スピーカーが3つ以上あると、オンラインとオフラインの精度の差が大きくなりますが、コンテキストサイズが無制限の1〜4スピーカーのベースラインオフラインクラスタリングダイアリゼーションシステムを上回り、コンテキストサイズが10秒の場合と同等の精度を示します。線形時間で入力を処理するレイテンシーBW-EDA-EENDは、オフラインEDA-EENDと比較して10秒のコンテキストサイズを使用して最大2人のスピーカーに対して中程度の劣化のみを示します。システムは堀口らのEDAアーキテクチャに基づいています。ただし、インクリメンタルTransformerエンコーダーを利用し、左側のコンテキストのみに注意を払い、非表示状態でブロックレベルの繰り返しを使用してブロックからブロックに情報を伝達し、アルゴリズムの複雑さを時間的に線形にします。 
[概要]このシステムは、堀口らのedaアーキテクチャに基づいています。インクリメンタルトランスフォーマーエンコーダーを使用し、左側のスケジュールのみに対応し、隠された状態でブロックレベルの繰り返しを使用してブロック間で情報を伝達します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Joint Entity and Relation Extraction with Set Prediction Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_27.html">
      <font color="black">Joint Entity and Relation Extraction with Set Prediction Networks</font>
    </a>
  </h2>
  <font color="black">さらに、2部マッチングを介して一意の予測を強制するセットベースの損失も設計します。このセット予測の問題を解決するために、非自己回帰並列デコードを備えた変圧器を特徴とするネットワークを提案します。小さなペナルティが高いクロスエントロピー損失と比較してトリプルオーダーでシフトすると、提案された2部マッチング損失は予測の順列に対して不変です。したがって、トリプルオーダーを無視し、関係タイプとエンティティに焦点を当てることで、提案されたネットワークに、より正確なトレーニング信号を提供できます。 
[概要]提案されたネットワークは、トリプルの最終セットをワンショットで直接出力します。これらのネットワークは、トリプルオーダーを無視し、関係タイプとエンティティに焦点を当てることにより、より正確なトレーニング信号を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-03">
        <br><font color="black">2020-11-03</font>
      </time>
    </span>
</section>
<!-- paper0: CODER: Knowledge infused cross-lingual medical term embedding for term
  normalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_28.html">
      <font color="black">CODER: Knowledge infused cross-lingual medical term embedding for term
  normalization</font>
    </a>
  </h2>
  <font color="black">CODERを用語の正規化、意味的類似性、および関係分類のベンチマークで評価しました。これにより、CODERは、さまざまな最先端の生物医学的単語の埋め込み、概念の埋め込み、およびコンテキストの埋め込みよりも優れていることが示されました。 al。、2018）トークンベクトル集約がUMLS Metathesaurus（Bodenreider、2004）のリレーションを使用してトレーニングされるという革新により、多言語サポートを備えた包括的な医療知識グラフです。リレーションを使用したトレーニングは、用語の埋め込みに医療知識を注入し、より優れた正規化パフォーマンスと潜在的に優れた機械学習機能を提供することを目的としています。 
[ABSTRACT]コーダーは医学用語の正規化用に設計されています。同じまたは類似の概念を表す用語に密接な埋め込みを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Language Model is All You Need: Natural Language Understanding as
  Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_29.html">
      <font color="black">Language Model is All You Need: Natural Language Understanding as
  Question Answering</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、同じパフォーマンスに必要なデータの量を最大10分の1に削減できることを示しています。さまざまな種類の転移学習が、機械学習の研究と応用の進歩に多大な影響を与えています。具体的には、自然言語理解をマッピングします。 （NLU）問題からQuestionAnswering（QA）問題へ。低データレジームでは、このアプローチがNLUの他のアプローチと比較して大幅な改善を提供することを示しています。 
[概要]新しい研究は、転移学習が問題に関連している可能性があることを示しています。研究は、マンチェスター大学米国によって実施されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: NUAA-QMUL at SemEval-2020 Task 8: Utilizing BERT and DenseNet for
  Internet Meme Emotion Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_30.html">
      <font color="black">NUAA-QMUL at SemEval-2020 Task 8: Utilizing BERT and DenseNet for
  Internet Meme Emotion Analysis</font>
    </a>
  </h2>
  <font color="black">私たちのモデルは、BERTを使用してテキストの埋め込みを学習し、DenseNetを使用して画像から特徴を抽出し、その後、連結によって両方の特徴を組み合わせます。私たちのシステムは、感情によってインターネットミームを分類するために、テキストと画像からマルチモーダル埋め込みを学習します。モデルはミームの分類に役立つ可能性があり、DenseNetはResNetよりも優れています。 
[概要]私たちのシステムは、テキストや画像からの埋め込みを使用してマルチモーダルを学習し、感情によってインターネットミームを分類します。また、densenetによって生成された結果、潜在的な分析を伴う画像と比較します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: PCP Theorems, SETH and More: Towards Proving Sub-linear Time
  Inapproximability -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/cs.CL/paper_31.html">
      <font color="black">PCP Theorems, SETH and More: Towards Proving Sub-linear Time
  Inapproximability</font>
    </a>
  </h2>
  <font color="black">劣線形時間アルゴリズムに関する新たな研究成果を考慮すると、劣線形PCP定理は、劣線形時間近似アルゴリズムの研究を導く上で重要です。この論文では、劣線形時間の非近似性に関するPCPのような定理を提案します。これらの結果は、この論文で提案された劣線形PCP定理の力を示しています。 
[要約]これらの結果は、劣線形pcpの力を示しています。劣線形性の劣性性は解決されていません。結果は、劣性性が機能しないことを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-04">
        <br><font color="black">2020-11-04</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Speech Recognition and Multi-Speaker Diarization of Long Conversations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/eess.AS/paper_0.html">
      <font color="black">Speech Recognition and Multi-Speaker Diarization of Long Conversations</font>
    </a>
  </h2>
  <font color="black">毎週のThisAmerican Lifeラジオ番組から収集された1時間のポッドキャストの新しいベンチマークを紹介し、拡張マルチスピーカー会話に適用した場合のこれらのアプローチをよりよく比較します。音声認識（ASR）およびスピーカーダイアリゼーション（SD）モデルは従来からトレーニングされてきました。話者ラベル付きの豊富な会話トランスクリプトを個別に生成します。未知の発話境界を持つ長い会話を処理するために、モデルの事前トレーニングと組み合わせてASRとSDを改善するストライドアテンションデコードアルゴリズムとデータ拡張技術を導入します。 
[ABSTRACT] asrおよびsdモデルは、音声（語彙の相互依存）を活用して単語のダイアリゼーションのパフォーマンスを向上させる方法を学習できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-16">
        <br><font color="black">2020-05-16</font>
      </time>
    </span>
</section>
<!-- paper0: Boosting Active Learning for Speech Recognition with Noisy
  Pseudo-labeled Samples -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/eess.AS/paper_1.html">
      <font color="black">Boosting Active Learning for Speech Recognition with Noisy
  Pseudo-labeled Samples</font>
    </a>
  </h2>
  <font color="black">一貫性の正則化に基づいて新しい教師なし損失を提案し、自動音声認識タスクで一貫性の正則化を採用するために発話に適切な拡張手法を構成します。実際のデータセットと実際の使用シナリオでの定性的および定量的実験から、提案されたトレーニングパイプラインがアクティブな学習アプローチの有効性を高め、それによって人間のラベリングコストの持続可能な量を首尾よく削減できることを示します。さらに一歩、ラベリングを超えて、ラベリングされていないサンプルを利用することでトレーニング効率をさらに改善できることを提案します。監視された損失を効果的に補完する高度に構成された監視されていない損失を導入することによる予算。 
[概要]新しいトレーニングパイプラインは、ラベルを対象とした従来のアクティブラーニングアプローチを強化します-効率的な学習。提案されたトレーニングパイプラインは、教師あり損失を効果的に補完する教師なし損失を導入することにより、ラベル付け予算を超えて、ラベル付けされていないサンプルを選択することでさらに改善できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-19">
        <br><font color="black">2020-06-19</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-class Spectral Clustering with Overlaps for Speaker Diarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/eess.AS/paper_2.html">
      <font color="black">Multi-class Spectral Clustering with Overlaps for Speaker Diarization</font>
    </a>
  </h2>
  <font color="black">さらに、フレームレベルの分類を実行し、HMM状態遷移を通じて期間制約を適用するHMM-DNNベースのオーバーラップ検出器について詳しく説明します。LibriCSSデータをさらに分析すると、高オーバーラップ条件での提案手法の有効性が実証されます。その後、離散化します。特異値分解と、オーバーラップ検出器の出力によって制約される非最大抑制の修正バージョンを交互に使用することによるソリューション。 
[ABSTRACT]私たちの方法は、オーバーラップ検出器とスピーカー埋め込み抽出器を提供します。この方法は、テストのダイアリゼーションエラー率（der）に基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Do not look back: an online beat tracking method using RNN and enhanced
  particle filtering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/eess.AS/paper_3.html">
      <font color="black">Do not look back: an online beat tracking method using RNN and enhanced
  particle filtering</font>
    </a>
  </h2>
  <font color="black">DLBは、単方向RNNのアクティブ化を拡張モンテカルロローカリゼーションモデルにフィードして、ビート位置を推測します。そのため、チャンクの受信を開始するのを待たずに、多くのOBTアプリケーションにとって重要な即時のビートトラッキング応答を提供します。 .. DLBは、最先端のOBTメソッドよりもビートトラッキングの精度を大幅に向上させ、オフラインメソッドと同様のパフォーマンスを実現します。 
[概要]オンラインホームに戻る。元のページに戻る。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Anomalous Sound Detection as a Simple Binary Classification Problem with
  Careful Selection of Proxy Outlier Examples -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/eess.AS/paper_4.html">
      <font color="black">Anomalous Sound Detection as a Simple Binary Classification Problem with
  Careful Selection of Proxy Outlier Examples</font>
    </a>
  </h2>
  <font color="black">プロキシ外れ値の候補は、正常音でも異常音でもないすべての録音が含まれる可能性があるため、豊富に用意されています。同様の音と一致する録音条件のデータがない場合は、これらの2つの次元で多様性が大きいデータセットが望ましいです。プロキシ外れ値を使用した監視付きトレーニングに基づくモデルは、DCASE2020チャレンジのタスク2でランク3を達成しました。 
[概要]重要な障害は、外れ値の多様性と希少性です。これらは通常、異常音の代表的なセットを収集することを妨げます。しかし、異常音の検出は、教師あり分類問題として効果的に組み立てることができることを示します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Accent Adaptation based on Gate Mechanism -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/eess.AS/paper_5.html">
      <font color="black">Multi-Accent Adaptation based on Gate Mechanism</font>
    </a>
  </h2>
  <font color="black">ただし、ベースラインモデルと比較すると、MTL-Gは平均5.1％の相対WER削減を達成します。アクセントラベルの予測が不正確になる可能性があるため、アクセント固有の適応よりもパフォーマンスが低下します。したがって、アクセント分類子を使用して適用します。アクセントラベルを予測します。 
[ABSTRACT] ast --gは、それぞれ9.8％と1.9％の平均相対ワー削減を達成します。ただし、アクセントパフォーマンスファイアはアクセントラベルに適応できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-supervised Learning for Singing Synthesis Timbre -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/eess.AS/paper_6.html">
      <font color="black">Semi-supervised Learning for Singing Synthesis Timbre</font>
    </a>
  </h2>
  <font color="black">教師なしで新しい音声を学習するには、事前にトレーニングされた音響エンコーダーを使用して、ターゲット歌手のデコーダーをトレーニングします。リスニングテストでシステムを評価し、同等の教師ありアプローチで得られた結果と同等であることを示します。 。最初のステップでは、システムは、ラベル付けされたマルチシンガーデータセットを使用して、教師ありの方法でトレーニングされます。 
[概要]両方のエンコーダーによって生成された埋め込みが類似していることを確認します。これにより、後で音響入力機能または言語入力機能のいずれかでモデルを使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: A Time-domain Monaural Speech Enhancement with Feedback Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/eess.AS/paper_7.html">
      <font color="black">A Time-domain Monaural Speech Enhancement with Feedback Learning</font>
    </a>
  </h2>
  <font color="black">パラメータ効率を向上させるためにフィードバック学習を採用しているため、性能を犠牲にすることなくトレーニング可能なパラメータの数を効果的に削減します。本論文では、モノラル音声強調のためのFTNetと呼ばれる時間領域でのフィードバック学習を備えたタイプのニューラルネットワークを提案します。 、提案されたネットワークは3つの主要コンポーネントで構成されます。最初の部分はステージ再帰ニューラルネットワークと呼ばれ、メモリメカニズムを使用してさまざまなステージ間の深い特徴の依存関係を効果的に集約し、ステージごとに干渉を除去するために導入されます。 
[概要]最初の部分はステージリカレントニューラルネットワークと呼ばれます。これは、メモリメカニズムを使用して、さまざまなステージにわたる深い特徴の依存関係を効果的に集約するために導入されました。2番目の部分は、一連の連結ゲート線形ユニットで構成されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-22">
        <br><font color="black">2020-03-22</font>
      </time>
    </span>
</section>
<!-- paper0: A Comparison Study on Infant-Parent Voice Diarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/eess.AS/paper_8.html">
      <font color="black">A Comparison Study on Infant-Parent Voice Diarization</font>
    </a>
  </h2>
  <font color="black">最高のパフォーマンスを見つけるために、システムのさまざまなコンポーネントを交換したり、損失関数を変更したりする効果を調べます。また、logmel機能の代わりに畳み込み機能エクストラクタを使用すると、ニューラルのパフォーマンスが大幅に向上することもわかりました。 diarization ..また、より粗いセグメント境界ラベルを持つより大きなデータセットでパラメーターを事前トレーニングできる複数インスタンス学習手法を提示します。最良のシステムは、テストデータセットで43.8％DERを達成したのに対し、55.4％DERを達成したことがわかりました。 LENAソフトウェアによる。 
[概要]私たちのシステムは、時間応答機能エクストラクターとクラスサイファイアで構成されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Comparison of Speaker Role Recognition and Speaker Enrollment Protocol
  for conversational Clinical Interviews -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/eess.AS/paper_9.html">
      <font color="black">Comparison of Speaker Role Recognition and Speaker Enrollment Protocol
  for conversational Clinical Interviews</font>
    </a>
  </h2>
  <font color="black">実験結果は、ハンチントン病のさまざまな段階での神経心理学者とインタビュー対象者の間の自然主義的な臨床会話について報告されています。しかし、特に音声と言語を持つ個人の場合、どの音声処理パイプラインが話者の順番を検出および識別するのに最もパフォーマンスが高いかは明らかではありません障害..各タスクに適応し、同じメトリックの下で各アプローチを評価するために、エンドツーエンドのニューラルネットワークアーキテクチャをトレーニングしました。 
[要約]これらの声の自動分析は、新しい言語マーカーを抽出し、臨床医のレポートをスピードアップするのに役立ちます。これは、話者の役割の認識と音声登録方法の実行に役立つ可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-30">
        <br><font color="black">2020-10-30</font>
      </time>
    </span>
</section>
<!-- paper0: Domain Adaptation Using Class Similarity for Robust Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/eess.AS/paper_10.html">
      <font color="black">Domain Adaptation Using Class Similarity for Robust Speech Recognition</font>
    </a>
  </h2>
  <font color="black">限られたターゲットドメインデータしか利用できない場合、ドメイン適応を使用して、十分にトレーニングされたソースモデルとターゲットドメインデータを活用することにより、ディープニューラルネットワーク（DNN）音響モデルのパフォーマンスを促進できます。私たちのアプローチでは、最初にフレームレベルを計算します。ソースモデルを使用したソースサンプルの確率。ただし、ドメインの不一致とデータの希薄性に悩まされているため、ドメインの適応は非常に困難です。 
[要約]クラスごとに、このクラスの確率を使用して、ソフトラベルという用語を取得します。このモデルは、パフォーマンスを向上させるためにソースモデルからターゲットモデルに転送できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: BW-EDA-EEND: Streaming End-to-End Neural Speaker Diarization for a
  Variable Number of Speakers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/eess.AS/paper_11.html">
      <font color="black">BW-EDA-EEND: Streaming End-to-End Neural Speaker Diarization for a
  Variable Number of Speakers</font>
    </a>
  </h2>
  <font color="black">スピーカーが3つ以上あると、オンラインとオフラインの精度の差が大きくなりますが、コンテキストサイズが無制限の1〜4スピーカーのベースラインオフラインクラスタリングダイアリゼーションシステムを上回り、コンテキストサイズが10秒の場合と同等の精度を示します。音声が到着するとブロックごとにダイアリゼーション出力を生成するレイテンシーBW-EDA-EENDは、オフラインクラスタリングベースのシステムに匹敵する精度を示します。線形時間で入力を処理する無制限レイテンシーBW-EDA-EENDの場合、オフラインEDA-EENDと比較して、10秒のコンテキストサイズを使用すると、最大2人のスピーカーで中程度の劣化しか示されません。 
[概要]このシステムは、堀口らのedaアーキテクチャに基づいています。インクリメンタルトランスフォーマーエンコーダーを使用し、左側のスケジュールのみに対応し、隠された状態でブロックレベルの繰り返しを使用してブロック間で情報を伝達します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: From Note-Level to Chord-Level Neural Network Models for Voice
  Separation in Symbolic Music -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-06/eess.AS/paper_12.html">
      <font color="black">From Note-Level to Chord-Level Neural Network Models for Voice
  Separation in Symbolic Music</font>
    </a>
  </h2>
  <font color="black">音楽は、音符または音声の同時ストリームの進行として経験されることがよくあります。提案された音声分離タスクにより、音声を複数の音声に分岐させ、複数の音声を同じ音声に収束させることができます。ボイスノートペア内で連続して、両方のモデルは、エンベロープ抽出機能の反復アプリケーションに基づく強力なベースラインを上回り、コードレベルモデルは一貫してノートレベルモデルをエッジアウトします。 
[概要]提案された音声分離タスクにより、音声を複数の音声に分岐させることができます。また、複数の音声を同じ音声に収束させることもできます。2つのモデルは、以前のアプローチよりも優れていることも示されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
