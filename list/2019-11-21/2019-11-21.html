<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<title>Akari-2019-11-21の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
  <div class="header-logo">
    <a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
  </div>
</header>
<input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">

<div class="menubar">
<span class="bar"></span>
<span class="bar"></span>
<span class="bar"></span>
</div>

<ul>
<li><a id="home" href="../../index.html">Home</a></li>
<li><a id="about" href="../../teamAkariとは.html">About</a></li>
<li><a id="contact" href="../../contact.html">Contact</a></li>
<li><a id="contact" href="../../list/newest.html">New Papers</a></li>
<li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
</ul>

</label>
<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Joint DNN-Based Multichannel Reduction of Acoustic Echo, Reverberation
  and Noise -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.SD/paper_0.html">
      Joint DNN-Based Multichannel Reduction of Acoustic Echo, Reverberation
  and Noise
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      反復ブロック座標上昇アルゴリズムを開発して、すべてのフィルターを更新します。提案されたアプローチは、全体的な歪みに関して、個々のアプローチのカスケードと、ターゲットおよび残留信号のスペクトルモデルに依存しないジョイントリダクションアプローチよりも優れています。 ..さまざまな状況でスマートスピーカーを使用して取得した音響エコー、残響、ノイズの実際の録音でシステムを評価します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Moving to Communicate, Moving to Interact: Patterns of Body Motion in
  Musical Duo Performance -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.SD/paper_1.html">
      Moving to Communicate, Moving to Interact: Patterns of Body Motion in
  Musical Duo Performance
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ピアノとクラリネットのデュオは、体の動きが記録されたときに新しい作品をリハーサルしました。不定期のパッセージ中の動きは、作品の他の場所よりもスムーズで、演奏者間の調整が強かったため、視覚的な相互作用が強化されたことが示唆されました。ただし、視覚的接触のない条件下で行われた最終パフォーマンス中に一貫性は再び低下しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Robust Target Linearly Constrained Minimum Variance Beamformer With
  Spatial Cues Preservation for Binaural Hearing Aids -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.SD/paper_2.html">
      A Robust Target Linearly Constrained Minimum Variance Beamformer With
  Spatial Cues Preservation for Binaural Hearing Aids
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      導入されたアルゴリズムは、指向性干渉源の方向の知識や推定も、ノイズのみのコンポーネントの2次統計も必要としません。堅牢なTLCMVは、現実的な条件下でのノイズ低減とターゲット歪みの低レベルを提供します。ポストプロセッサは、優れたレベルのノイズ低減を維持しながら、拡散器のようなバックグラウンドノイズと指向性干渉（競合スピーカー）の両方のバイノーラルキューを保持するために、ビームフォーマーの機能を強化します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-11-03">
        <br>2018-11-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transformation of low-quality device-recorded speech to high-quality
  speech using improved SEGAN model -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.SD/paper_3.html">
      Transformation of low-quality device-recorded speech to high-quality
  speech using improved SEGAN model
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、大規模なリスニングテストから、我々の方法がデバイス録音音声信号の品質を大幅に向上できることを示します。この論文では、最初に新しいデバイス録音音声データセットを紹介し、次にエンドツーエンドの改善を提案します。低品質のデバイスで録音された音声をプロの高品質音声に自動的に変換するための終了方法モデルのトレーニングをより堅牢で安定させるための2つの変更。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br>2019-11-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-Task Semi-Supervised Adversarial Autoencoding for Speech Emotion -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.SD/paper_4.html">
      Multi-Task Semi-Supervised Adversarial Autoencoding for Speech Emotion
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、提案されたモデルが2つの公開データセットで最先端のパフォーマンスを達成することを示しています。ラベル付きトレーニングサンプルが限られているシナリオで、同時にトレーニングを行うことにより、教師付き分類タスクのパフォーマンスを大幅に改善できることを示します大量のデータの可用性を備えた追加の補助タスク..ラベルなしデータの豊富な可用性を考慮して、本書では、音声のパフォーマンスを改善するためにマルチタスク学習方法でラベルなしデータを効果的に利用できる半教師ありモデルを提案しました感情認識。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-13">
        <br>2019-07-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Demystifying TasNet: A Dissecting Approach -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.SD/paper_5.html">
      Demystifying TasNet: A Dissecting Approach
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、ノイズのない単一チャネル環境でどのゲインがより現実的な残響条件に一般化されるかを批判的に評価します。さらに、TasNetで損失関数として使用されるスケール不変信号対歪み比（si-SDR）基準が対数平均二乗誤差基準に関連し、TasNetのパフォーマンスの利点に最も信頼できるのはこの基準であるということです。いくつかの中間バリアントは、TasNetに匹敵する信号対歪み比（SDR）ゲインを達成しますが、利点を保持します周波数領域処理の：周波数領域のビーム形成やマスクの人間の解釈可能性などの古典的な信号処理ツールとの互換性。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Perceptual Loss Function for Neural Modelling of Audio Systems -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.SD/paper_6.html">
      Perceptual Loss Function for Neural Modelling of Audio Systems
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      リスニングテストの結果は、A重み付けプリエンファシスフィルターの使用が、テスト済みフィルターの中で最高の改善を提供することを示しています。この研究では、高周波でのローパスフィルターを含む知覚的に関連性の高いプリエンファシスフィルターを検討します。 、ネットワークトレーニング中にエラー信号比損失関数が使用され、1次ハイパスプリエンファシスフィルターがターゲット信号とニューラルネットワーク出力の両方に適用されました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: FastSpeech: Fast, Robust and Controllable Text to Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.SD/paper_7.html">
      FastSpeech: Fast, Robust and Controllable Text to Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最も重要なことは、自己回帰トランスフォーマーTTSと比較して、このモデルは、メルスペクトログラムの生成を270倍、エンドツーエンドの音声合成を38倍高速化します。ニューラルネットワークベースのエンドツーエンドの音声合成（TTS）により、合成音声の品質。従来の連結および統計パラメトリックアプローチと比較して、ニューラルネットワークベースのエンドツーエンドモデルは推論速度が遅く、合成音声は通常ロバストではありません（つまり、一部の単語がスキップまたは繰り返されます）。制御性（音声速度または韻律制御）。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-22">
        <br>2019-05-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Does Speech enhancement of publicly available data help build robust
  Speech Recognition Systems? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.SD/paper_8.html">
      Does Speech enhancement of publicly available data help build robust
  Speech Recognition Systems?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このパフォーマンスは、ノイズが多くクリーンなバージョンでトレーニングされた場合の理想的なケースシナリオにも匹敵します。このホワイトペーパーでは、一般に利用可能なデータソースを使用してかなり大きなデータセットを最初にキュレートしました。ノイズの多いデータのトレーニングよりも単語誤り率が高く、クリーンなデータのトレーニングよりも9 \％優れています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-29">
        <br>2019-10-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CAT: CRF-based ASR Toolkit -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.SD/paper_9.html">
      CAT: CRF-based ASR Toolkit
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SwitchboardやAishellなどの中国語および英語のベンチマークの評価結果は、CATが既存のエンドツーエンドモデル間でより少ないパラメーターで最新の結果を取得し、ハイブリッドDNN-HMMモデルと比較して競争力があることを示しています。柔軟性に向けて、i-vectorベースのスピーカー対応認識およびレイテンシ制御メカニズムをCATで簡単かつ効果的に探索できることを示します。CATにはCTC-CRFの本格的な実装が含まれており、CRFベースのエンド音声認識を終了します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Semantics-aware BERT for Language Understanding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_0.html">
      Semantics-aware BERT for Language Understanding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SemBERTは、タスク固有の大幅な変更を行うことなく、BERT前駆体の便利な使いやすさを軽く微調整する方法で維持します。BERTと比較して、セマンティクス認識BERTは概念的には簡単ですが、より強力です。言語表現に豊富なセマンティクスを提供できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-05">
        <br>2019-09-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Global Greedy Dependency Parsing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_1.html">
      Global Greedy Dependency Parsing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、グラフモデルのようなグローバルな（文の範囲内）特徴抽出と、遷移モデルのような線形時間推論の両方が可能な新しい依存関係解析モデルをもたらす、新しい解析順序目標を提案します。 -射影アーク構築アクション、提案されたパーサーは非射影構文解析もスムーズにサポートする可能性があります。後者のグラフベースのモデルは、パフォーマンスは向上しますが、残念ながら多項式時間推論によって損なわれます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Discovering New Intents via Constrained Deep Adaptive Clustering with
  Cluster Refinement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_2.html">
      Discovering New Intents via Constrained Deep Adaptive Clustering with
  Cluster Refinement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、モデルに強制的に高信頼度の割り当てから学習させることにより、クラスターを改良します。3つのベンチマークデータセットの実験結果は、本手法が強力なベースラインに対して大幅な改善をもたらすことを示しています。クラスターの数。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Red Dragon AI at TextGraphs 2019 Shared Task: Language Model Assisted
  Explanation Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_3.html">
      Red Dragon AI at TextGraphs 2019 Shared Task: Language Model Assisted
  Explanation Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      リーダーボードの提出により、コンテストで3位になりましたが、ここでは、洗練度を高める3つの方法を紹介します。各方法は、コンテスト終了後のテストセットで連続して高得点を獲得しました。初等科学の質問に対する金の説明を再構築するために。RedDragon AIのエントリは、個別のグラフのような表現を構築するのではなく、質問の言語と説明テキストを直接使用しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Controlling Neural Machine Translation Formality with Synthetic
  Supervision -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_4.html">
      Controlling Neural Machine Translation Formality with Synthetic
  Supervision
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      総合的な自動評価と人間評価により、ソースの意味を維持しながら、目的の形式レベルによく一致する翻訳を生成することにより、既存のモデルよりも優れたモデルが得られることが示されます。しかし、実際には、利用可能なトレーニング例は、異なるスタイルの英語の文のペア、および形式が不明なバイリンガルのパラレル文に限定されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: KnowIT VQA: Answering Knowledge-Based Questions about Videos -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_5.html">
      KnowIT VQA: Answering Knowledge-Based Questions about Videos
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      主な調査結果は次のとおりです。（i）知識を組み込むことでビデオのVQAに顕著な改善がもたらされ、（ii）KnowIT VQAのパフォーマンスは依然として人間の精度よりかなり遅れており、現在のビデオモデリングの制限を研究するための有用性を示しています。視覚およびテキストのビデオコンテンツと番組に関する特定の知識を組み合わせることにより、ビデオ理解モデルを提案します。知識ベースとビデオ質問応答を融合することにより、新しいビデオ理解タスクを提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-23">
        <br>2019-10-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On Using SpecAugment for End-to-End Speech Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_6.html">
      On Using SpecAugment for End-to-End Speech Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      エンドツーエンドの音声翻訳タスクにSpecAugmentを適用し、LibriSpeech Audiobook En-&gt; Frで最大+2.2 \％\ BLEU、IWSLT TED-talk En-&gt; Deで+ 1.2％をある程度オーバーフィットすることで達成します。また、さまざまなデータシナリオでのメソッドの有効性を調べ、トレーニングデータの量に関係なく、メソッドがさまざまなデータ条件の大幅な改善にもつながることを示します。この作業では、単純なデータ拡張手法であるSpecAugmentを調査します-エンドツーエンドの音声翻訳。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Real-Time Emotion Recognition via Attention Gated Hierarchical Memory
  Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_7.html">
      Real-Time Emotion Recognition via Attention Gated Hierarchical Memory
  Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      会話におけるリアルタイム感情認識（RTER）は、感情的にインテリジェントなチャットマシンを開発するために重要です。歴史的な発話の間に..私たちは、AGHMNモデルの有効性を実証するために、広範な分析を伴う2つの感情会話データセットの実験を行っています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On using 2D sequence-to-sequence models for speech recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_8.html">
      On using 2D sequence-to-sequence models for speech recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Switchboard 300hの自動音声認識タスクの実験的評価は、エンドツーエンドのアテンションベースのモデルと競合する2DLSTMモデルの単語誤り率を示しています。提案モデルは、任意のタイプのアテンションを使用する代わりの代替モデルです。これらのアーキテクチャを使用して、1次元の入力および出力シーケンスはアテンションアプローチによって関連付けられているため、従来のHMM-ベースのモデリング。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Global Thread-Level Inference for Comment Classification in Community
  Question Answering -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_9.html">
      Global Thread-Level Inference for Comment Classification in Community
  Question Answering
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      スレッドレベルの情報を使用することの重要性を確認して、結果を最新の状態より改善しました。SemEval-2015タスク3のベンチマークデータセットに対するアプローチを評価しました。コミュニティの質問応答、Webコンテキストにおける質問応答の最近の進化、ユーザーが特定のトピックに関する多数の人々の意見をすばやく参照できるようにして、群衆の知恵を活用します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SG-Net: Syntax-Guided Machine Reading Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_10.html">
      SG-Net: Syntax-Guided Machine Reading Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      構文ガイドネットワーク（SG-Net）は、この追加のSDOI-SANと、元のトランスフォーマーエンコーダーからのSANと、言語にインスパイアされた表現を向上させるデュアルコンテキストアーキテクチャで構成されます。SQuAD2.0やRACEを含む一般的なベンチマークの広範な実験は、提案されたSG-Net設計は、強力なベースラインに対して大幅なパフォーマンス改善を達成するのに役立ちます。その有効性を検証するために、提案されたSG-Netは、Transformerエンコーダに基づく典型的な事前トレーニング言語モデルBERTに適用されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-14">
        <br>2019-08-14
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Natural Language Generation Challenges for Explainable AI -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_11.html">
      Natural Language Generation Challenges for Explainable AI
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの課題を自然言語生成（NLG）の観点から説明し、XAIの研究課題に関する4つの特定のNLGを強調します。人工知能（XAI）推論の質の高い説明は、説明目的で記述（および評価）する必要があります。読者は、優れた物語と因果構造を持ち、不確実性とデータ品質がAI出力に影響する場所を強調します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SemanticZ at SemEval-2016 Task 3: Ranking Relevant Answers in Community
  Question Answering Using Semantic Similarity Based on Fine-tuned Word
  Embeddings -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_12.html">
      SemanticZ at SemEval-2016 Task 3: Ranking Relevant Answers in Community
  Question Answering Using Semantic Similarity Based on Fine-tuned Word
  Embeddings
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      メインのサブタスクCでは、51.68のMAPと69.94の精度でプライマリサブミッションが3番目にランクされました。サブタスクAでは、77.58のMAPと73.39の精度でプライマリサブミッションも3番目でした。 SemEval-2016、コミュニティ質問回答に関するタスク3で定義されているコミュニティフォーラムで適切な回答を見つける。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Comparative Study on End-to-end Speech to Text Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_13.html">
      A Comparative Study on End-to-end Speech to Text Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、両方のタスクについて、現在のエンドツーエンドの最先端システムに対する改善を示します。また、事前トレーニング済みモデルを使用してモデルのさまざまなコンポーネントを初期化するなど、事前トレーニング済みバリアントとその影響についても調査します最終パフォーマンスでは、BLEUで最大4％、TERで5％のブーストが得られます。実験は、270時間IWSLT TEDトークEn-&gt; Deおよび100時間LibriSpeech Audiobooks En-&gt; Frで実行されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Zero-Shot Semantic Parsing for Instructions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_14.html">
      Zero-Shot Semantic Parsing for Instructions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ゼロショットセマンティック解析タスクを検討します。トレーニング中に見られなかったドメインで、命令を構成論理形式に解析します。ソースドメインのセットからの例でセマンティックパーサーをトレーニングすることを目的とする新しいトレーニングアルゴリズムを導入します。未知のターゲットドメインからの命令を効果的に解析できること。アルゴリズムをPasupat and Liang（2015）のフローティングパーサーに統合し、ゼロショット適応をサポートするために、パーサーを機能と論理フォーム候補フィルタリングロジックでさらに強化します。 。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Paraphrasing Verbs for Noun Compound Interpretation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_15.html">
      Paraphrasing Verbs for Noun Compound Interpretation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらの動詞を使用して、特別な種類のテキスト含意タスクを表す文のペアのデータセットをさらに構築します。ここでは、動詞と2つの名詞を含む表現を名詞複合語に変換できるかどうかについてバイナリ決定が行われます文の意味.. AmazonのMechanical Turkを使用して、言語文学で以前に提案された250の名詞と名詞の複合語の言い換え動詞を収集し、名詞複合解釈の貴重なリソースを作成します。関連する重みを持つ、考えられるすべての言い換え動詞、たとえば、マラリア蚊はキャリー（23）、広がり（16）、原因（12）、送信（9）など
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Joint Emotion Label Space Modelling for Affect Lexica -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_16.html">
      Joint Emotion Label Space Modelling for Affect Lexica
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文は、a）既存の感情検出リソースを自動的に統合する最初の研究を提示し、それらの関係についてさらに学習することにより、NLPの感情分析の分野に貢献します。 b）上記のタスクのための既存の語彙の使用を検討する。 c）感情語彙を自動的に結合するアプローチ、つまりマルチビュー変分オートエンコーダー（VAE）を提示します。これにより、データセットの共同感情ラベル空間へのマッピングが容易になります。最先端の感情検出モデルの追加機能として。結果として生じる感情検出リソースの異種の性質により、それらを利用するための統一されたアプローチが必要になります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CatGAN: Category-aware Generative Adversarial Networks with Hierarchical
  Evolutionary Learning for Category Text Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_17.html">
      CatGAN: Category-aware Generative Adversarial Networks with Hierarchical
  Evolutionary Learning for Category Text Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      カテゴリ対応モデルは、実際のサンプルと各カテゴリで生成されたサンプルとの間のギャップを直接測定し、このギャップを減らすことでモデルが高品質のカテゴリサンプルを生成するように導きます。実験結果は、CatGANが既存のほとんどの状態よりも優れていることを示していますさらに、通常はサンプルの品質にのみ焦点を合わせるとモード崩壊の問題が発生するため、CatGANのトレーニング中に階層的進化学習アルゴリズムを導入してトレーニング手順を安定させ、品質と多様性のトレードオフを取得します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-15">
        <br>2019-11-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Demystifying TasNet: A Dissecting Approach -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_18.html">
      Demystifying TasNet: A Dissecting Approach
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、我々は批判的に、より現実的な残響条件にノイズのない単一チャネル環境の一般化で利益が...中間バリアントの一部はタスネットに匹敵する信号対歪み比（SDR）の利益を達成した評価が、周波数ドメインの優位性を保持します処理：周波数領域ビームフォーミングなどの従来の信号処理ツールとの互換性およびマスクの人間の解釈可能性。近年、時間領域の音声分離は、シングルチャネルシナリオおよびノイズのない環境での周波数領域分離よりも優れています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Hitachi at MRP 2019: Unified Encoder-to-Biaffine Network for
  Cross-Framework Meaning Representation Parsing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_19.html">
      Hitachi at MRP 2019: Unified Encoder-to-Biaffine Network for
  Cross-Framework Meaning Representation Parsing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、評価後の実験では、ベースラインでは不可能だったマルチタスク学習を組み込むことで、提案システムのパフォーマンスを向上できることが示されました。5つのフレームワークすべてに対して、エンコーダーからビアフィンへの統合ネットワークを提案しました。豊富な入力機能を抽出する共有エンコーダー、UCCAおよびAMRでアンカーレスノードを生成するデコーダーネットワーク、エッジを予測するバイアフィンネットワーク。当社のシステムは、マクロ平均MRP F1スコア0.7604で5位にランク付けされ、ベースライン統一移行ベースのMRP。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-03">
        <br>2019-10-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Knowing What, How and Why: A Near Complete Solution for Aspect-based
  Sentiment Analysis -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_20.html">
      Knowing What, How and Why: A Near Complete Solution for Aspect-based
  Sentiment Analysis
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験では、フレームワークがこの新しいトリプレット抽出タスクのベンチマークパフォーマンスを設定しました。たとえば、「ウェイターは非常に友好的で、パスタは単純に平均的」からの1つのトリプレットは（「ウェイター」、ポジティブ、「フレンドリー」） ..特に、このタスクのソルバーは、入力からトリプレット（What、How、Why）を抽出する必要があります。これは、ターゲットアスペクトが何であるか、感情極性がどのようであり、そのような極性を持つ理由を示します（つまり、
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-05">
        <br>2019-11-05
      </time>
    </span>
  </h3>
</article>
<!-- paper0: KnowBias: Detecting Political Polarity in Long Text Content -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_21.html">
      KnowBias: Detecting Political Polarity in Long Text Content
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ツイートでトレーニングされたニュートラル検出器を使用して記事からニュートラルな文章を削除する2段階の分類スキームを提案し、意見の集中を調整して、そのドメインでの精度を向上させます。ツイートでトレーニングし、記事の推論を実行します。 https://knowbias.mlで公開されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-22">
        <br>2019-09-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On the Robustness of Unsupervised and Semi-supervised Cross-lingual Word
  Embedding Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_22.html">
      On the Robustness of Unsupervised and Semi-supervised Cross-lingual Word
  Embedding Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、評価のための特定の制御されたシナリオに焦点が当てられており、現在の最先端システムがノイズの多いテキストや言語の大きな違いがある言語ペアにどのように対応するかについての強力な証拠はありません。本書では、ターゲット言語などのさまざまな変数に関する長所と制限を分析し、複数の言語間埋め込みモデルに対する広範な評価を提示します。 、コーパスのトレーニングと監督の量。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-21">
        <br>2019-08-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer
  Sentence Selection -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_23.html">
      TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer
  Sentence Selection
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのアプローチは、2つの有名なベンチマークであるWikiQAとTREC-QAで最先端を確立し、MAPスコアをそれぞれ92％と94.3％に達成しました。これは、過去最高の83.4％と87.5％を大幅に上回り、最近の作業..最後に、さまざまなタイプのノイズの影響を受けるドメイン固有のデータセットを使用して、産業環境でのTANDAのプラスの影響も確認します。 -パラメーター。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-11">
        <br>2019-11-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Casting a Wide Net: Robust Extraction of Potentially Idiomatic
  Expressions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_24.html">
      Casting a Wide Net: Robust Extraction of Potentially Idiomatic
  Expressions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、大規模なコーパスは、慣用的な表現とその変動性に関する貴重な言語的洞察の潜在的なソースです。辞書ベースのPIEの抽出を事前に使用することの実現可能性を調査することにより、英語用の抽出ツール。補完的なPIE抽出方法を組み合わせることで、信頼性がさらに向上し、F1スコアが92％を超えます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CAIL2019-SCM: A Dataset of Similar Case Matching in Legal Domain -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_25.html">
      CAIL2019-SCM: A Dataset of Similar Case Matching in Legal Domain
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      CAIL2019-SCMには、中国最高裁判所が発行した8,964の3つのケースが含まれています。研究者がこのタスクをよりよく理解するのに役立つベースライン。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: FastSpeech: Fast, Robust and Controllable Text to Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_26.html">
      FastSpeech: Fast, Robust and Controllable Text to Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最も重要なことは、自己回帰トランスフォーマーTTSと比較して、このモデルは、メルスペクトログラムの生成を270倍、エンドツーエンドの音声合成を38倍高速化します。ニューラルネットワークベースのエンドツーエンドの音声合成（TTS）により、合成音声の品質。従来の連結および統計パラメトリックアプローチと比較して、ニューラルネットワークベースのエンドツーエンドモデルは推論速度が遅く、合成音声は通常ロバストではありません（つまり、一部の単語がスキップまたは繰り返されます）。制御性（音声速度または韻律制御）。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-22">
        <br>2019-05-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: EmpGAN: Multi-resolution Interactive Empathetic Dialogue Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_27.html">
      EmpGAN: Multi-resolution Interactive Empathetic Dialogue Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      特に、DailyDialogデータセットの特徴は129％まで向上します。さらに、対話履歴とユーザーフィードバックの両方に関して、生成された応答が対話の感情知覚を喚起するかどうかをさらに識別するために、対話型敵対学習フレームワークが導入されます。上記の課題に対して、より適切で共感的な応答を生成するための多重解像度敵対的共感対話生成モデルであるEmpGANを提案します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Framework for Building Closed-Domain Chat Dialogue Systems -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_28.html">
      A Framework for Building Closed-Domain Chat Dialogue Systems
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      その結果は、HRIChatを使用してかなり良いシステムを開発できることを示唆しています。FoodChatbotは、食品およびレストランの分野でのアプリケーションであり、ユーザー調査を通じて開発および評価されています。 FoodChatbot。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-30">
        <br>2019-10-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Does Speech enhancement of publicly available data help build robust
  Speech Recognition Systems? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_29.html">
      Does Speech enhancement of publicly available data help build robust
  Speech Recognition Systems?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ノイズの多いクリーンなバージョンでトレーニングした場合のパフォーマンスも理想的なケースシナリオに匹敵します。クリーンなデータ..音声強調を使用してノイズの多いデータを最初にクリーンアップし、次にクリーンなバージョンと一緒に使用してASRシステムをトレーニングしました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-29">
        <br>2019-10-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Characterizing Scalability of Sparse Matrix-Vector Multiplications on
  Phytium FT-2000+ Many-cores -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_30.html">
      Characterizing Scalability of Sparse Matrix-Vector Multiplications on
  Phytium FT-2000+ Many-cores
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      科学およびHPCアプリケーションで一般的な操作であるSpMVを研究することを選択します。ARMベースのメニーコアアーキテクチャの新しさのため、そのようなハードウェア設計のSpMVスケーラビリティを理解する作業はほとんどありません。ソフトウェアとハードウェアのパラメーターは、特定のSpMVカーネルのスケーラビリティを決定するために最も重要です。回帰ツリーに基づいてパフォーマンス分析モデルを開発します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Knowledge Graph Alignment Network with Gated Multi-hop Neighborhood
  Aggregation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_31.html">
      Knowledge Graph Alignment Network with Gated Multi-hop Neighborhood
  Aggregation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      エンティティ表現を洗練するために、関係損失をさらに提案します。カウンターパーティエンティティの直接隣接は通常、スキーマの不均一性により異なるため、AliNetは、隣接構造間のオーバーラップを拡張するために、隣接を導入します。遠くの隣人とノイズを減らします。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Rule-Guided Compositional Representation Learning on Knowledge Graphs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_32.html">
      Rule-Guided Compositional Representation Learning on Knowledge Graphs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、ホーン節の形式の異なる長さ（ルール本体の関係の数）の論理規則は、まずKGからマイニングされ、表現学習のために精巧にエンコードされます。次に、長さ2の規則が適用され、長さ1のルールは、関係間のセマンティックな関連付けを作成し、関係の埋め込みを制約するために明示的に使用されます。さらに、ルールの表現学習への適用の可用性を保証する最適化において、各ルールの信頼レベルも考慮されます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploring Neural Net Augmentation to BERT for Question Answering on
  SQUAD 2.0 -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_33.html">
      Exploring Neural Net Augmentation to BERT for Question Answering on
  SQUAD 2.0
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、事前出力されたBERT言語モデルをさまざまな出力ニューラルネットアーキテクチャで強化することに焦点を当て、Stanford Question Answering Dataset 2.0（SQUAD 2.0）[3]によって提起された質問応答タスクのパフォーマンスを比較しました。事前にトレーニングされたBERTモデルのパラメーターを微調整して、特殊な言語タスクへの適応の有効性を実証しました。言語モデル（ELMo）からの埋め込み（1）およびトランスフォーマーからの双方向エンコーダー表現（BERT）[2]多数のダウンストリーム言語タスク用に最適化できる汎用言語モデルの開発に成功しました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-04">
        <br>2019-08-04
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Co-Attention Hierarchical Network: Generating Coherent Long Distractors
  for Reading Comprehension -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_34.html">
      Co-Attention Hierarchical Network: Generating Coherent Long Distractors
  for Reading Comprehension
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2番目の問題を軽減するために、追加のセマンティック類似性損失を追加して、生成されたディストラクタを記事により関連するようにします。さらなる人間の評価は、ベースラインによって生成されたディストラクタと比較して、生成されたディストラクタがより一貫性があり、より教育的であることを示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Joint Embedding Learning of Educational Knowledge Graphs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_35.html">
      Joint Embedding Learning of Educational Knowledge Graphs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、教育知識グラフを処理する際のモデルの有効性と他のベースラインに対するその優位性を証明した。本論文では、この問題に焦点を当て、教育知識グラフの学習を埋め込むための新しいモデルを提案する。知識組織では、知識グラフは生物医学、社会学、教育などのいくつかの分野で広く採用されています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Table-Of-Contents generation on contemporary documents -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_36.html">
      Table-Of-Contents generation on contemporary documents
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、テンプレートとしてエンコードされた外部知識を使用した場合の影響を分析します。最後に、実世界のドキュメントでのTOC生成の難しさを明らかにする新しいドメイン固有のデータセットを提案します。パブリックデータセットおよび新しくリリースされたデータセットの最先端よりも。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Exploiting Cross-Lingual Subword Similarities in Low-Resource Document
  Classification -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/cs.CL/paper_37.html">
      Exploiting Cross-Lingual Subword Similarities in Low-Resource Document
  Classification
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ソース言語とターゲット言語の両方に共通の文字表現を使用します。これにより、埋め込み元はソース言語の単語に関する知識を一般的なターゲット言語の単語に一般化することができます。追加のクロスリンガルまたはモノリンガルのリソースが利用可能です。エンベダーは、記述されたフォームから入力単語のベクトル表現を導き出し、分類器は単語ベクトルに基づいて予測を行います。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-22">
        <br>2018-12-22
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Joint DNN-Based Multichannel Reduction of Acoustic Echo, Reverberation
  and Noise -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/eess.AS/paper_0.html">
      Joint DNN-Based Multichannel Reduction of Acoustic Echo, Reverberation
  and Noise
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのフィルターは相互に作用するため、共同で最適化する必要があります。すべてのフィルターを更新する反復ブロック座標上昇アルゴリズムを開発します。音響エコー、残響、ノイズの同時低減の問題を検討します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Moving to Communicate, Moving to Interact: Patterns of Body Motion in
  Musical Duo Performance -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/eess.AS/paper_1.html">
      Moving to Communicate, Moving to Interact: Patterns of Body Motion in
  Musical Duo Performance
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ピアノとクラリネットのデュオは、体の動きが記録されたときに新しい曲をリハーサルしました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Robust Target Linearly Constrained Minimum Variance Beamformer With
  Spatial Cues Preservation for Binaural Hearing Aids -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/eess.AS/paper_2.html">
      A Robust Target Linearly Constrained Minimum Variance Beamformer With
  Spatial Cues Preservation for Binaural Hearing Aids
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      導入されたアルゴリズムは、指向性干渉源の方向の知識や推定も、ノイズのみのコンポーネントの2次統計も必要としません。堅牢なTLCMVは、現実的な条件下でのノイズ低減とターゲット歪みの低レベルを提供します。ポストプロセッサは、優れたレベルのノイズ低減を維持しながら、拡散器のようなバックグラウンドノイズと指向性干渉（競合スピーカー）の両方のバイノーラルキューを保持するために、ビームフォーマーの機能を強化します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-11-03">
        <br>2018-11-03
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Transformation of low-quality device-recorded speech to high-quality
  speech using improved SEGAN model -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/eess.AS/paper_3.html">
      Transformation of low-quality device-recorded speech to high-quality
  speech using improved SEGAN model
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、大規模なリスニングテストから、私たちの方法がデバイス録音音声信号の品質を大幅に向上できることを示します。この方法は、音声強調GANと呼ばれる生成的敵対ネットワーク（GAN）ベースの音声強調モデルの拡張です。 （SEGAN）、およびモデルトレーニングをより堅牢で安定させるための2つの変更を提示します。このホワイトペーパーでは、最初に新しいデバイス録音音声データセットを紹介し、低品質を自動的に変換するための改善されたエンドツーエンドの方法を提案しますデバイスで録音された音声をプロの高品質音声に変換します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br>2019-11-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-Task Semi-Supervised Adversarial Autoencoding for Speech Emotion -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/eess.AS/paper_4.html">
      Multi-Task Semi-Supervised Adversarial Autoencoding for Speech Emotion
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたモデルは、カテゴリおよび次元の感情分類タスクの両方について厳密に評価されます。ラベル付きトレーニングサンプルが限られているシナリオでは、利用可能な追加の補助タスクを同時にトレーニングすることにより、教師付き分類タスクのパフォーマンスを大幅に改善できることを実証します大量のデータ。実験結果は、提案されたモデルが2つの公開データセットで最先端のパフォーマンスを達成することを示しています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-13">
        <br>2019-07-13
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Demystifying TasNet: A Dissecting Approach -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/eess.AS/paper_5.html">
      Demystifying TasNet: A Dissecting Approach
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最後に、ノイズのない単一チャネル環境でどのゲインがより現実的な残響条件に一般化されるかを批判的に評価します。いくつかの中間バリアントは、TasNetに匹敵する信号対歪み比（SDR）ゲインを達成しますが、周波数ドメインの利点を保持します処理：周波数領域ビームフォーミングなどの従来の信号処理ツールとの互換性およびマスクの人間の解釈可能性。さらに、TasNetで損失関数として使用されるスケール不変の信号対歪み比（si-SDR）基準が対数平均二乗誤差の基準に関連しており、TasNetのパフォーマンス上の利点に最も信頼できるのはこの基準であるということです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Perceptual Loss Function for Neural Modelling of Audio Systems -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/eess.AS/paper_6.html">
      Perceptual Loss Function for Neural Modelling of Audio Systems
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案された知覚損失関数は、計算コストに影響を与えることなく、音声処理におけるニューラルネットワークモデルの音質を向上させます。仕事では、知覚的に関連性の高いプリエンファシスフィルターを検討します。これには、高周波数でのローパスフィルターが含まれます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: FastSpeech: Fast, Robust and Controllable Text to Speech -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/eess.AS/paper_7.html">
      FastSpeech: Fast, Robust and Controllable Text to Speech
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ニューラルネットワークベースのエンドツーエンドの音声合成（TTS）により、合成音声の品質が大幅に向上しました。最も重要なことは、自己回帰トランスフォーマーTTSと比較して、このモデルはメルスペクトログラムの生成を270xおよびエンドツーエンドで高速化します38xによる音声合成。従来の連結および統計パラメトリックアプローチと比較して、ニューラルネットワークベースのエンドツーエンドモデルは推論速度が遅く、合成音声は通常堅牢ではありません（つまり、一部の単語がスキップまたは繰り返されます）。制御性（音声速度または韻律制御）。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-22">
        <br>2019-05-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Does Speech enhancement of publicly available data help build robust
  Speech Recognition Systems? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/eess.AS/paper_8.html">
      Does Speech enhancement of publicly available data help build robust
  Speech Recognition Systems?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ノイズの多いクリーンなバージョンでトレーニングした場合のパフォーマンスも理想的なケースシナリオに匹敵します。クリーンなデータ..音声強調を使用してノイズの多いデータを最初にクリーンアップし、次にクリーンなバージョンと一緒に使用してASRシステムをトレーニングしました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-29">
        <br>2019-10-29
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CAT: CRF-based ASR Toolkit -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/eess.AS/paper_9.html">
      CAT: CRF-based ASR Toolkit
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      柔軟性に向けて、i-vectorベースのスピーカー対応認識およびレイテンシ制御メカニズムをCATで簡単かつ効果的に探索できることを示します。CATにはCTC-CRFの本格的な実装が含まれており、CRFベースのエンドエンドツーエンドの音声認識.. CAT、特にCRFベースのフレームワークとソフトウェアがコミュニティに広く関心を持たれ、さらに調査および改善できることを願っています。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Radiosafe micro-computed tomography for longitudinal evaluation of murine disease models -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/biorxiv.physiology/paper_0.html">
      Radiosafe micro-computed tomography for longitudinal evaluation of murine disease models
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      4D CTを繰り返した後、循環血小板とリンパ球の疾患に依存しない減少を発見しました。毎週の全身取得のCT安全限界とプロトコルを確立し、全体的な健康状態、肺、疾患プロセス、放射線感受性血液細胞コンパートメントを含む調査。線量効果は、in vivo CTおよび生物発光イメージング読み出し、ゴールドスタンダードエンドポイント評価、および血球数によって評価されました。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Restriction of essential amino acids dictates the systemic response to dietary protein dilution -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2019-11-21/biorxiv.physiology/paper_1.html">
      Restriction of essential amino acids dictates the systemic response to dietary protein dilution
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      Thrは、低タンパク食を与えられたヒトでも潜在的に制限されており、食事性Thr制限（DTR）は、マウスにおける肥満関連代謝機能障害の発症を遅らせました。さらに、総AA供給とは無関係に、ThrおよびTrpの全身的欠乏は、食事および遺伝的AA輸送損失の両方にAA代謝制限をもたらす全身代謝応答を与えるのに十分かつ必要である。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-20">
        <br>2019-11-20
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
