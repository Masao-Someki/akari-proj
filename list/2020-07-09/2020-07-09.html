<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-07-09の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Learning Speech Representations from Raw Audio by Joint Audiovisual
  Self-Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.SD/paper_0.html">
      <font color="black">Learning Speech Representations from Raw Audio by Joint Audiovisual
  Self-Supervision</font>
    </a>
  </h2>
  <font color="black">特に、私たちの方法は完全に監視されたトレーニングよりも優れているため、音声関連タスクの強力な初期化を提供します。視覚的口実タスクは、音声表現を駆動して唇の動きに関連する情報をキャプチャします。これにより、オーディオエンコーダーが視覚情報で強化され、エンコーダーは視覚モダリティなしの評価に使用できます。 
[ABSTRACT]このコンセプトは、ビデオアクション認識や音響シーン分類などの一般的なオーディオビジュアルタスクで実証されています。生のオーディオ波形から自己監視型音声表現を学習する方法を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Audio Inpainting: Revisited and Reweighted -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.SD/paper_1.html">
      <font color="black">Audio Inpainting: Revisited and Reweighted</font>
    </a>
  </h2>
  <font color="black">新しいアイデアは、係数と時間領域の両方で、さまざまなタイプの重み付けに基づいています。私たちの提案は、SNRとODGの両方に関して修復パフォーマンスを向上させることを示しています。数学的最適化に基づくアプローチの結果は、満たされたギャップ内の信号の不十分な振幅。 
[要約]私たちは、このようなエネルギー損失を補うことを目的として、オーディオ修復の改善を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-08">
        <br><font color="black">2020-01-08</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Sound Event Detection In Domestic Environments Using Sound
  Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.SD/paper_2.html">
      <font color="black">Improving Sound Event Detection In Domestic Environments Using Sound
  Separation</font>
    </a>
  </h2>
  <font color="black">さらに、サウンド分離とサウンドイベント検出の両方で、サウンド分離モデルをサウンドイベント検出データに適合させることの影響を調査します。分離した音源とサウンドイベント検出内の元の混合を組み合わせるさまざまな方法を検討します。現実世界の録音でサウンドイベント検出を実行すると、多くの場合、干渉またはノイズとも呼ばれる、重複するターゲットサウンドイベントと非ターゲットサウンドを処理することになります。 
[要約]音分離モデルは、無料のユニバーサル音分離データセットとdcase 2020タスク4音イベント検出ベースラインでトレーニングされます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Streaming End-to-End Bilingual ASR Systems with Joint Language
  Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.SD/paper_3.html">
      <font color="black">Streaming End-to-End Bilingual ASR Systems with Joint Language
  Identification</font>
    </a>
  </h2>
  <font color="black">全体として、ユーザーが言語を動的に切り替えるシナリオでは、提案されたアーキテクチャは、複数の単一言語ASRモデルとLID分類器を並行して実行することを約束する簡素化を提供します。入力側では、事前トレーニングされた音響のみのLID分類器からの埋め込みを使用して、RNNをガイドします-Tトレーニングと推論、出力側では、言語ターゲットはASRターゲットと共同でモデル化されます。提案された方法は、2つの言語ペアに適用されます。米国で話されている英語とスペイン語、インドで話されている英語とヒンディー語。 
[ABSTRACT] asrと言語の識別を実行するシステム（lid）が提案されています。これは、米国で話される英語とスペイン語、インドで話される英語とヒンディー語の2つの言語ペアに適用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Training Sound Event Detection On A Heterogeneous Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.SD/paper_4.html">
      <font color="black">Training Sound Event Detection On A Heterogeneous Dataset</font>
    </a>
  </h2>
  <font color="black">DCASE 2020タスク4サウンドイベント検出ベースラインの詳細な分析を、トレーニングに使用されるデータのタイプ、平均教師のパラメーター、または合成サウンドスケープの生成中に適用される変換などのいくつかの側面に関して実行することを提案します。技術的な選択は、質問されることなく、あるシステムから別のシステムに渡されることがよくあります。さまざまなラベリングの粒度を持つことができる録音されたサウンドスケープと合成サウンドスケープの両方を含む異種データセットでサウンドイベント検出アルゴリズムをトレーニングすることは、いくつかのシステムを必要とするシステムにつながる可能性がある重要なタスクです。技術的な選択。 
[ABSTRACT]これらの技術的な選択は、質問されることなく1つのシステムから別のシステムに渡された可能性があります。これらの技術的な決定は、システムのさまざまな部分とともに渡されることがよくあります。これらには、可能な限り分類できる技術的な決定が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Resolution Beta-Divergence NMF for Blind Spectral Unmixing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.SD/paper_5.html">
      <font color="black">Multi-Resolution Beta-Divergence NMF for Blind Spectral Unmixing</font>
    </a>
  </h2>
  <font color="black">この問題を解決するために、メジャー化最小化アルゴリズムに基づく乗算更新を提案します。多くのNMFベースの方法は、2つの敵対する次元間の解像度のトレードオフの結果であるデータマトリックスを因数分解します。.MR-$ \ beta $ -NMFは、$ \ beta $ -divergenceに基づいた非負の共同因数分解の形式を実行します。 
[ABSTRACT]非負行列因数分解は標準であり、最先端のテクニックです。mr-$ $ beta $-多様化は非負の共同因数分解の形式です。これらには、2つのオーディオスペクトログラムの共同因数分解が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Graph Random Process for Relational-Thinking-Based Speech
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.SD/paper_6.html">
      <font color="black">Deep Graph Random Process for Relational-Thinking-Based Speech
  Recognition</font>
    </a>
  </h2>
  <font color="black">CHiME-2とCHiME-5を含むASRタスクの実験的評価は、私たちの方法の有効性と利点を実証します。私たちのアプローチは、トレーニング中に関係データを使用せずに発話間の関係をうまく推論できます。この論文では、ベイジアンを提示します。知覚を表す無数の確率グラフを生成できる、ディープグラフランダムプロセス（DGP）と呼ばれるノンパラメトリックディープラーニングメソッド。 
[ABSTRACT]会話型自動音声認識（asr）などの現実的な問題では、精神的なプロセスをモデル化することが困難です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-04">
        <br><font color="black">2020-07-04</font>
      </time>
    </span>
</section>
<!-- paper0: Listen carefully and tell: an audio captioning system based on residual
  learning and gammatone audio representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.SD/paper_7.html">
      <font color="black">Listen carefully and tell: an audio captioning system based on residual
  learning and gammatone audio representation</font>
    </a>
  </h2>
  <font color="black">このタスクは、自動コンテンツ記述やマシン間の相互作用など、多くのアプリケーションで役立ちます。自動オーディオキャプションシステムは、オーディオを入力として受け入れ、テキスト記述として出力するため、つまり、信号。エンコーダーフェーズは、さまざまな残余ネットワーク構成を介して実装されます。 
[ABSTRACT]自動音声字幕システムは、音声を入力として受け入れ、信号の字幕としてエクスポートされるため、実装する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-27">
        <br><font color="black">2020-06-27</font>
      </time>
    </span>
</section>
<!-- paper0: Massively Multilingual ASR: 50 Languages, 1 Model, 1 Billion Parameters -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.SD/paper_8.html">
      <font color="black">Massively Multilingual ASR: 50 Languages, 1 Model, 1 Billion Parameters</font>
    </a>
  </h2>
  <font color="black">関節モデル、言語入力のある関節モデル、および多頭モデルの単一言語ベースラインと比較して、それぞれ20.9％、23％、および28.8％の平均WER相対減少が見られます。自動の改善を目的として、複数言語の単一音響モデルのトレーニングを研究します。低リソース言語での音声認識（ASR）パフォーマンス、および多様な言語をサポートするASRシステムの全体的な簡素化デプロイメント。私たちの知る限り、これは50以上の言語を含む大規模な多言語ASRの最初の研究ですそれら全体で16,000時間を超えるオーディオ。 
[ABSTRACT] 51言語で広範なベンチマークを実行し、言語ごとに単一のトレーニングデータを使用します。asrモデルの多言語トレーニングにより、低リソース言語での認識入力を改善できることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: GRNet: Gridding Residual Network for Dense Point Cloud Completion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.IV/paper_0.html">
      <font color="black">GRNet: Gridding Residual Network for Dense Point Cloud Completion</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案されたGRNetが、ShapeNet、Completion3D、およびKITTIベンチマークの最先端のメソッドに対して有利に機能することを示しています。また、コンテキスト情報を保持する、隣接ポイントの特徴を抽出するための微分可能な3次特徴サンプリングレイヤーを提示します。特に、構造情報を失うことなく点群と3Dグリッドの間で変換するために、GriddingとGridding Reverseという2つの新しい区別可能なレイヤーを考案しました。 
[要旨]主流の方法では、多層パーセプトロン（mlps）を使用して点群を直接処理します。点群の構造とコンテキストが完全に考慮されていないため、詳細が失われる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-06">
        <br><font color="black">2020-06-06</font>
      </time>
    </span>
</section>
<!-- paper0: A Data and Compute Efficient Design for Limited-Resources Deep Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.IV/paper_1.html">
      <font color="black">A Data and Compute Efficient Design for Limited-Resources Deep Learning</font>
    </a>
  </h2>
  <font color="black">この作業では、MobileNetV2の同変バージョンを設計およびテストし、さらにモデル量子化で最適化して、より効率的な推論を可能にします。それらは、データの対称性を効果的に活用してより正確で堅牢なモデルを構築できる医療分野での利用に成功しています。 
[ABSTRACT]同変モデルは一般にモバイルデバイスで開発されます。より正確で堅牢なモデルを構築するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br><font color="black">2020-04-21</font>
      </time>
    </span>
</section>
<!-- paper0: Phase Retrieval Using Conditional Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.IV/paper_2.html">
      <font color="black">Phase Retrieval Using Conditional Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">トレーニング時に測定プロセスの知識を含めると、生成時モデルを含む既存のアプローチよりも初期化に対してロバストなテスト時の最適化につながることを示しています。他のディープラーニング手法と同様に、このアプローチはノイズに対して非常にロバストであるため、実世界のアプリケーションに非常に役立ちます。この論文では、条件付き生成敵対ネットワークのアプリケーションを提案し、さまざまな位相検索問題を解決します。 
[要約]私たちの方法は、確立された投影法に基づく方法を上回っています。他の方法は、ニューラルネットワークに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-10">
        <br><font color="black">2019-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Overcoming information reduced data and experimentally uncertain
  parameters in ptychography with regularized optimization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.IV/paper_3.html">
      <font color="black">Overcoming information reduced data and experimentally uncertain
  parameters in ptychography with regularized optimization</font>
    </a>
  </h2>
  <font color="black">ピコグラフィーの根底にある数学的問題の過決定は、多くの実験的に望ましい設定によって軽減されます。さらに、サンプル誘起位相シフトの再構成は、通常、実験パラメーターの不確実性と有限サンプル厚によって制限されます。降下アルゴリズム、タイコグラフィーの正規化最適化（ROP）、位相シフトとともに部分的に既知の実験パラメーターを回復し、有限のサンプル厚を処理するマルチスライス形式を組み込んで解像度を改善し、最適化プロセスに正則化を含めることで、情報が大幅に削減され、決定が不十分なノイズの多いデータ。 
[ABSTRACT]位相シフトの再構築は、通常、実験条件の不確実性によって制限されます。「不適切」と呼ばれるプロセスは大幅に削減されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-04">
        <br><font color="black">2020-05-04</font>
      </time>
    </span>
</section>
<!-- paper0: SiENet: Siamese Expansion Network for Image Extrapolation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.IV/paper_4.html">
      <font color="black">SiENet: Siamese Expansion Network for Image Extrapolation</font>
    </a>
  </h2>
  <font color="black">さらに、ネットワークに事前知識を導入し、エンコーダーの推論能力を強化するために、シャム敵対機構は、カバーされていない画像機能の分布に対するカバーされた長距離機能の分布をモデル化できるように設計されています。画像の修復とは異なり、画像の塗りつぶしは、キャプチャする画像センターでのコンテキストが比較的少なく、予測する画像境界でのコンテンツが多くなります。この論文では、Siamese Expansion Network（SiENet）という名前の、画像外挿用の新しい2ステージシャム敵対モデルを提案します。 
[ABSTRACT] 2つの段階で、未知のコンテンツを予測することを可能にし、センターの負担を軽減するために、新しいボーダーセンシティブなたたみ込み</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-image Super Resolution of Remotely Sensed Images using Residual
  Feature Attention Deep Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.IV/paper_5.html">
      <font color="black">Multi-image Super Resolution of Remotely Sensed Images using Residual
  Feature Attention Deep Neural Networks</font>
    </a>
  </h2>
  <font color="black">単一またはマルチ画像の超解像に関する他の利用可能なソリューションに対する広範な実験と評価により、提案された深層学習ベースのソリューションは、リモートセンシングのマルチ画像超解像の最先端と見なすことができることが実証されていますさらに、同じシーンで複数の入力がある場合、表現学習ネットワークは、入れ子になった残余接続を広範囲に使用して、冗長な低周波信号を流し、より重要な高周波成分に計算を集中させます。複数の低解像度画像の認識可能なデータ融合と情報抽出を得るために、3D畳み込みによる視覚的特徴の注意、畳み込み演算の局所領域の制限を超えています。 
[要約]提示された研究は、マルチ画像超解像タスクに効率的に取り組む新しいモデルを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Resolution Beta-Divergence NMF for Blind Spectral Unmixing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.IV/paper_6.html">
      <font color="black">Multi-Resolution Beta-Divergence NMF for Blind Spectral Unmixing</font>
    </a>
  </h2>
  <font color="black">この問題を解決するために、マジョライゼーション最小化アルゴリズムに基づく乗算更新を提案します。このホワイトペーパーでは、マルチ解像度$ \ beta $ -NMF（MR-$ \ beta $と呼ばれる）と呼ばれる新しいNMFベースの方法を提案します。 -NMF）、すべての次元で高解像度の因数分解を生成するために、異なる解像度の複数のデータからの情報を融合することにより、この問題に対処します。このタスクを実行するには、$ \に基づく非負行列因数分解（NMF） $ \ beta $ -NMFと呼ばれるbeta $ -divergenceは、標準の最先端技術です。 
[ABSTRACT]非負行列因数分解は標準であり、最先端のテクニックです。mr-$ $ beta $-多様化は非負の共同因数分解の形式です。これらには、2つのオーディオスペクトログラムの共同因数分解が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Quantifying and Leveraging Predictive Uncertainty for Medical Image
  Assessment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.IV/paper_7.html">
      <font color="black">Quantifying and Leveraging Predictive Uncertainty for Medical Image
  Assessment</font>
    </a>
  </h2>
  <font color="black">ただし、実際には、これにより、目に見えないデータの一般化が不十分で、システムの信頼性が高くなります。さらに、不確実性に基づくブートストラップを使用してトレーニングデータをフィルタリングすると、堅牢性と精度が大幅に向上することを示しています。疾患の出現のデータまたは主観的な定義における決定的な証拠のため。 
[ABSTRACT]これらの問題は通常、確率的予測を提供することに限定されます。これらには、予測された出力でのシステムの信頼度を取得する明示的な不確実性測度を持つシステムが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Dense Recurrent Neural Networks for Accelerated MRI: History-Cognizant
  Unrolling of Optimization Algorithms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.IV/paper_8.html">
      <font color="black">Dense Recurrent Neural Networks for Accelerated MRI: History-Cognizant
  Unrolling of Optimization Algorithms</font>
    </a>
  </h2>
  <font color="black">次に、展開されたネットワーク全体をエンドツーエンドでトレーニングして、ネットワークのパラメーターを学習します。最近、データ駆動型の正則化にニューラルネットワークを使用するために、物理駆動型の深層学習（DL）法が提案されています。加速MRIの逆問題通常は、正符号化演算子に関するドメイン固有の知識を、正規化された再構成フレームワークに組み込みます。 
[要約]最近の物理学-駆動型ディープラーニング（dl）メソッドは、データ駆動型の正則化にニューラルネットワークを使用するために提案されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-16">
        <br><font color="black">2019-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient and Phase-aware Video Super-resolution for Cardiac MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.IV/paper_9.html">
      <font color="black">Efficient and Phase-aware Video Super-resolution for Cardiac MRI</font>
    </a>
  </h2>
  <font color="black">具体的には、CMRの循環特性を満たすように調整された周期関数として心臓の知識を定式化します。さらに、提案された残差学習スキームにより、ネットワークはLR-HRマッピングをプログレッシブリファインメント方式で学習しやすくなります。心臓磁気共鳴画像法（CMR）は、心臓の構造と機能を非侵襲的で痛みのない方法で説明できるため、広く使用されています。 
[要約]心臓の知識は、ネットワークがlr-hr構造を学習できるようにするために提案されています。このテクノロジーを使用して、このテクノロジーの効果を検出することが可能です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br><font color="black">2020-05-21</font>
      </time>
    </span>
</section>
<!-- paper0: Guidestar-free image-guided wavefront-shaping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.IV/paper_10.html">
      <font color="black">Guidestar-free image-guided wavefront-shaping</font>
    </a>
  </h2>
  <font color="black">顕微鏡から内視鏡まで、さまざまなアプリケーションでの非侵襲的イメージングへの道を開く、高度に散乱するレイヤーとマルチコアファイバーを介した拡張オブジェクトのイメージングを示します。ここでは、新しい概念、画像誘導波面成形、照明制御なしで、非常に散乱する層を通して非侵襲的、ガイドスターフリー、広視野、インコヒーレントイメージングを可能にします。最も重要なことに、波面補正は、メモリ効果の範囲よりも大きいオブジェクトに対しても、画像を盲目的に最適化することで見つかります。品質指標。 
[ABSTRACT]波面-技術を使用することで、生体組織を介して画像を形成し、隅を見ることができます。スペックル相関をキャプチャするための新しい代替代替方法、ガイド-星と波面制御を回避しますが、内部に含まれる小さなオブジェクトに限定されますメモリ-効果の相関範囲</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Depth-Aware Arbitrary Style Transfer Using Instance Normalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.IV/paper_11.html">
      <font color="black">Depth-Aware Arbitrary Style Transfer Using Instance Normalization</font>
    </a>
  </h2>
  <font color="black">（2017）別のモデルをトレーニングせずに任意のスタイルを効率的に転送できますが、コンテンツ画像の深度マップを再現することはできません。ただし、HuangらのAdaINメソッド。ただし、これらの従来の方法は、計算効率が悪いか、個別のトレーニングが必要です各スタイルのニューラルネットワーク。 
[ABSTRACT]最近の研究では、最適化された損失関数に追加の正則化機能を使用して深度マップを保存し、深度マップの保存を強制することが推奨されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-03">
        <br><font color="black">2019-06-03</font>
      </time>
    </span>
</section>
<!-- paper0: Designing and Training of A Dual CNN for Image Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.IV/paper_12.html">
      <font color="black">Designing and Training of A Dual CNN for Image Denoising</font>
    </a>
  </h2>
  <font color="black">最後に、再構成ブロックを使用して、ノイズ除去された画像を再構成します。拡張ブロックは、グローバル機能とローカル機能を収集して融合し、後者のネットワークに補足情報を提供します。スパースメカニズムを備えた機能抽出ブロックは、2つの方法でグローバル機能とローカル機能を抽出します。サブネットワーク。 
[ABSTRACT] dudenetは4つのモジュールで構成されています：特徴抽出ブロック、拡張ブロック、圧縮ブロック、再構成ブロック</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Low-dimensional Manifold Constrained Disentanglement Network for Metal
  Artifact Reduction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.IV/paper_13.html">
      <font color="black">Low-dimensional Manifold Constrained Disentanglement Network for Metal
  Artifact Reduction</font>
    </a>
  </h2>
  <font color="black">具体的には、LDM-DN学習アルゴリズムを設計して、回復した画像を低次元のパッチ多様体上にあるように制約しながら、相乗的ネットワーク損失関数を最適化することにより、絡み合い解消ネットワークを強化します。ペアの学習設定および/またはペアのない学習設定でMARのパフォーマンスを改善し、合成データセットと臨床データセットで競合するメソッドよりも優れています。ただし、十分な監督なしでは、ADNが敵対的な損失のみに基づいてアーティファクトに影響を受けたCT画像の構造の詳細を回復することは困難です。 
[要約]目を引くネットワーク（adn）が対になっていない画像で直接提案され、臨床データセットで有望な結果が得られました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Simultaneous Estimation of X-ray Back-Scatter and Forward-Scatter using
  Multi-Task Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.IV/paper_14.html">
      <font color="black">Simultaneous Estimation of X-ray Back-Scatter and Forward-Scatter using
  Multi-Task Learning</font>
    </a>
  </h2>
  <font color="black">前方散乱がわかっているので、X線投影を修正できますが、後方散乱成分を適切に推定すると、皮膚線量評価を改善できます。理論的には、どちらの場合も非常に正確な散乱推定が可能であることを示しています。ここでは、検出器に到達する前方散乱と患者の皮膚線量に影響を与える後方散乱を同時に推定するために、従来の手法と学習ベースの方法を組み合わせた新しいアプローチを提案します。 
[ABSTRACT]戻る-散乱は患者（皮膚）の線量に大きく影響します。検出器の散乱防止グリッドによる追加の減衰は、より高い患者の入射線量によって補償する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Biomechanics-informed Neural Networks for Myocardial Motion Tracking in
  MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.IV/paper_15.html">
      <font color="black">Biomechanics-informed Neural Networks for Myocardial Motion Tracking in
  MRI</font>
    </a>
  </h2>
  <font color="black">提案された方法は、2つの異なるデータセットからの心臓MRIデータの2Dスタックでの心筋運動追跡のコンテキストで検証されます。このようなアプローチは、アプリケーション固有の事前知識をディープラーニングベースの登録に組み込むことができます。次に、学習したVAEレギュライザーを結合できます。深層学習ベースの登録ネットワークを使用して、ソリューションスペースを生体力学的に妥当なものに正規化します。 
[要約]提案された方法はバイオメカニクスを学習できる-情報に基づいた正則化。このような方法は心筋運動追跡のコンテキストで検証されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-08">
        <br><font color="black">2020-06-08</font>
      </time>
    </span>
</section>
<!-- paper0: Mining Cross-Image Semantics for Weakly Supervised Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.IV/paper_16.html">
      <font color="black">Mining Cross-Image Semantics for Weakly Supervised Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">特に、1組のトレーニング画像が与えられた場合、1つの共同注意は分類子に強制的オブジェクトからの共通のセマンティクスを認識させる一方、他の1つは対照的な共同注意と呼ばれ、分類子を駆動して残りの非共有セマンティクスを識別します、珍しいオブジェクト..これは、分類器が画像領域でより多くのオブジェクトパターンとより優れたグラウンドセマンティクスを発見するのに役立ちます。さらに、私たちのアプローチは、不完全データチャレンジからのCVPR2020学習の弱監視セマンティックセグメンテーショントラックで1位にランクされました。 
[ABSTRACT]これは、オブジェクトのローカリゼーションレベルを学習する最新の方法です。2つのニューラルコアテンションを使用して、クロスイメージのセマンティックの類似点と相違点をキャプチャします。これにより、分類器がより多くのオブジェクトパターンを発見するのに役立ちます。さらに、このアルゴリズムは統合されたフレームワークを提供しますよく異なるwsss設定を処理する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-03">
        <br><font color="black">2020-07-03</font>
      </time>
    </span>
</section>
<!-- paper0: A Convolutional Approach to Vertebrae Detection and Labelling in Whole
  Spine MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.IV/paper_17.html">
      <font color="black">A Convolutional Approach to Vertebrae Detection and Labelling in Whole
  Spine MRI</font>
    </a>
  </h2>
  <font color="black">最後に、腰椎と脊柱全体のMRスキャンで脊柱側弯症の自動検出に使用するこの方法の臨床的適用性を示します。この方法は、さまざまなMRシーケンスの範囲にわたって腰椎、頸部、および胸部のみのスキャンに変更を加えずに適用できます。 ..結果として得られるシステムは、脊椎全体のスキャンの困難な臨床データセットで98.1％の検出率と96.5％の識別率を達成し、腰椎のみのスキャンでの以前のシステムのパフォーマンスに匹敵するか、それを超えます。 
[要約]システムを使用して、椎体の椎骨の角を特定できます。次に、システムを使用して、自己整合的な方法で椎骨のレベルを特定できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: CycleGAN with a Blur Kernel for Deconvolution Microscopy: Optimal
  Transport Geometry -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.IV/paper_18.html">
      <font color="black">CycleGAN with a Blur Kernel for Deconvolution Microscopy: Optimal
  Transport Geometry</font>
    </a>
  </h2>
  <font color="black">2つのディープジェネレーターを必要とする従来のcycleGANアプローチとは対照的に、提案されたcycleGANアプローチは、単一のディープジェネレーターと線形ブラーカーネルのみを必要とするため、ネットワークトレーニングの堅牢性と効率が大幅に向上します。アルゴリズムの有効性。提案されたアーキテクチャは、実際に、トランスポートコストとしてペナルティ付き最小二乗コストの特殊な形式を使用する最適なトランスポート問題の二重公式であることを示します。 
[ABSTRACT]畳み込みニューラルネットワーク（cnn）アプローチは、高速で高性能な代替手段として研究されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-26">
        <br><font color="black">2019-08-26</font>
      </time>
    </span>
</section>
<!-- paper0: Labelling imaging datasets on the basis of neuroradiology reports: a
  validation study -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.IV/paper_19.html">
      <font color="black">Labelling imaging datasets on the basis of neuroradiology reports: a
  validation study</font>
    </a>
  </h2>
  <font color="black">このレポートでは、5000を超えるMRI神経放射線学レポートにプロジェクトの一部としてラベルを付けた神経放射線科医のチームの経験を利用して、専用の深層学習ベースの神経放射線学レポートを作成します。分類子..ただし、バイナリラベルとは対照的に、より詳細なラベル付けの精度はカテゴリに依存し、この不一致の理由を強調しています。 
[要約]ただし、これまでのところ、このアプローチの有効性について徹底的な調査は行われていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Guided Fine-Tuning for Large-Scale Material Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_0.html">
      <font color="black">Guided Fine-Tuning for Large-Scale Material Transfer</font>
    </a>
  </h2>
  <font color="black">2番目のワークフローでは、既存の事前設計されたSVBRDFの外観を転送することにより、ユーザーがインターネット画像から大規模なSVBRDFを作成するための強力な方法を提供します。この単純なアプローチの強みを示す2つの新しいマテリアルキャプチャおよび設計ワークフローを紹介します。最初のワークフローでは、数枚の写真から大規模なオブジェクトのもっともらしいSVBRDFを作成できます。 
[ABSTRACT]細かい外観を調整します-提供されたエグザンプラでネットワークをキャプチャして、ターゲットイメージから同様のsvbrdf値を抽出することを学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: On the Importance of Stereo for Accurate Depth Estimation: An Efficient
  Semi-Supervised Deep Neural Network Approach -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_1.html">
      <font color="black">On the Importance of Stereo for Accurate Depth Estimation: An Efficient
  Semi-Supervised Deep Neural Network Approach</font>
    </a>
  </h2>
  <font color="black">ディープステレオニューラルネットワークをトレーニングするための新しい半教師あり学習アプローチと、機械学習されたargmaxレイヤーとカスタムランタイム（公開される）を含む新しいアーキテクチャを提案します。組み込みGPUで実行します。また、さまざまな設計基準の精度への影響を測定することにより、ステレオアルゴリズムの最近の進歩を評価します。その結果、私たちはステレオによる深度推定に注力しています。 
[ABSTRACT]単眼とステレオの深度の精度の差は依然として大きいことを示しています。これは、自動運転が予想される車両が単眼カメラに広く依存しているためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-03-26">
        <br><font color="black">2018-03-26</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Enriched Features for Real Image Restoration and Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_2.html">
      <font color="black">Learning Enriched Features for Real Image Restoration and Enhancement</font>
    </a>
  </h2>
  <font color="black">一言で言えば、私たちのアプローチは、複数のスケールからのコンテキスト情報を組み合わせながら、高解像度の空間詳細を維持する豊富な機能のセットを学習します。劣化したバージョンから高品質の画像コンテンツを復元することを目的として、画像の復元は多くのことを楽しんでいます監視、計算写真、医用画像、リモートセンシングなどのアプリケーション。このペーパーでは、ネットワーク全体で空間的に正確な高解像度表現を維持し、強力なコンテキスト情報を受信するという集合的な目標を持つ新しいアーキテクチャを提示します。低解像度表現。 
[ABSTRACT]畳み込みニューラルネットワーク（cnns）は、画像復元タスクの従来のアプローチに比べて劇的な改善を達成しました。前者の場合、空間的に正確ですが、状況的にロバストな結果が得られますが、後者の場合、意味的に信頼性が高く、空間的に正確ではありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-15">
        <br><font color="black">2020-03-15</font>
      </time>
    </span>
</section>
<!-- paper0: Enhancing Underexposed Photos using Perceptually Bidirectional
  Similarity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_3.html">
      <font color="black">Enhancing Underexposed Photos using Perceptually Bidirectional
  Similarity</font>
    </a>
  </h2>
  <font color="black">特に、Retinex理論を採用し、強化問題を制約付き照明推定最適化としてキャストします。ここでは、知覚的に双方向の類似性を照明の制約として定式化し、アーチファクトのない望ましい拡張結果を回復できる照明を解決します。このために、ベイズ最大最大事後確率問題に取り組むことにより、サンプリングされたキーフレームのイルミネーションをビデオ全体に伝播する確率論的アプローチが導入されています。これは、知覚の一貫性を確保する方法を明示的に説明する知覚双方向類似性と呼ばれる効果的な基準を提案することで実現します。 。 
[ABSTRACT]これは、露出不足のソース画像とその拡張出力の間の視覚情報の知覚的一貫性を保証できないためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-25">
        <br><font color="black">2019-07-25</font>
      </time>
    </span>
</section>
<!-- paper0: RP2K: A Large-Scale Retail Product Dataset for Fine-Grained Image
  Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_4.html">
      <font color="black">RP2K: A Large-Scale Retail Product Dataset for Fine-Grained Image
  Classification</font>
    </a>
  </h2>
  <font color="black">（3）サイズ、形状、フレーバー/香りなど、各オブジェクトに豊富な注釈を提供します。（2）すべての画像は、実際のアプリケーションのシナリオと一致する自然光のある小売店で手動でキャプチャされます。 https://www.pinlandata.com/rp2k_datasetで入手できます。 
[ABSTRACT]私たちは、2000の異なる製品に属する棚にある小売製品の500,00を超える画像を収集します。当社のデータセットは、製品カテゴリの点で群を抜いて最大規模のデータセットです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-22">
        <br><font color="black">2020-06-22</font>
      </time>
    </span>
</section>
<!-- paper0: MCU-Net: A framework towards uncertainty representations for decision
  support system patient referrals in healthcare contexts -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_5.html">
      <font color="black">MCU-Net: A framework towards uncertainty representations for decision
  support system patient referrals in healthcare contexts</font>
    </a>
  </h2>
  <font color="black">したがって、4つの異なる不確実性メトリックで評価されたU-Netとモンテカルロドロップアウトを組み合わせたMCU-Netを使用して、医療画像のセグメンテーションについて評価された不確実性表現のフレームワークを提示します。このアプリケーション用に調整された不確実性しきい値は、個々の患者レベルで自動化されたパフォーマンスを最大化しながら、本当に不確かなケースを参照します。フレームワークは、不確実性ケースの自動照会の不確実性しきい値に基づいてループ中の人間の側面を医療専門家。 
[要約]ディープラーニングフレームワークは、不確実性の表現がないため、この患者ベースのアプローチを許可しません。これは、不確実なケースを医療専門家に自動紹介するためのステップです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: SLAP: Improving Physical Adversarial Examples with Short-Lived
  Adversarial Perturbations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_6.html">
      <font color="black">SLAP: Improving Physical Adversarial Examples with Short-Lived
  Adversarial Perturbations</font>
    </a>
  </h2>
  <font color="black">近年、敵対的な例（AE）に関する重要な研究努力が行われていますが、現実世界でこれらの攻撃を実現するための主な手段は、現在、静的な敵対的なパッチに依存しています。オブジェクト検出と交通標識認識タスクの両方をターゲットにして、自動運転シナリオでSLAPの実現可能性を調査します。これにより、敵対的なパッチと比較して敵が攻撃をより強力に制御できるようになります。（i）投影を動的にオンまたはオフにしたり、 （ii）投影はパッチによって課される局所性制約の影響を受けないため、検出が難しくなります。 
[ABSTRACT]短命の敵対的摂動（スラップ）は、敵が遠くからロバストで動的な現実世界のaeを実現できるようにする斬新な手法です。敵対者は、敵対的パッチと比較して攻撃を照らすことができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Adaptive Curriculum Generation from Demonstrations for Sim-to-Real
  Visuomotor Control -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_7.html">
      <font color="black">Adaptive Curriculum Generation from Demonstrations for Sim-to-Real
  Visuomotor Control</font>
    </a>
  </h2>
  <font color="black">ピックアンドストウとブロックスタッキングの2つの実際の操作タスクのゼロショット転送を示します。シミュレーションでビジョンベースの制御ポリシーをトレーニングしながら、ACGDを介してタスクの難易度を徐々に上げて、ポリシー転送を現実の世界..ドメインのランダム化の程度も、タスクの難易度によって徐々に増加します。 
[ABSTRACT] acgdは学習者に適切なタスクの難易度を適応的に設定します。デモの難易度からサンプリングする場所と使用するシミュレーションパラメーターのセットを制御します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-17">
        <br><font color="black">2019-10-17</font>
      </time>
    </span>
</section>
<!-- paper0: Distance-Geometric Graph Convolutional Network (DG-GCN) -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_8.html">
      <font color="black">Distance-Geometric Graph Convolutional Network (DG-GCN)</font>
    </a>
  </h2>
  <font color="black">私たちの仕事は、3DグラフでのエンドツーエンドのディープラーニングにおけるDG-GCNの有用性と価値を示しています。これは、グラフの回転と変換に不変であり、ペアワイズノードの相互作用と一般的にローカルな性質を反映しています。 ESOLおよびFreeSolvデータセットの結果は、標準のグラフの畳み込みの結果よりも大幅に改善されています。 
[ABSTRACT]パターンは連続に基づいています-畳み込みレイヤーをフィルターします。これは、ペアの賢明なユーザー接続を示唆し、3D畳み込みを示唆します。また、幾何学的グラフの畳み込みよりも大幅に改善されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: ReMOTS: Self-Supervised Refining Multi-Object Tracking and Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_9.html">
      <font color="black">ReMOTS: Self-Supervised Refining Multi-Object Tracking and Segmentation</font>
    </a>
  </h2>
  <font color="black">（2）隣接フレーム全体の観測値を関連付けて短期トラックレットを形成します。（3）信頼性の高い疑似ラベルとして短期トラックレットを使用して外観エンコーダをトレーニングします。（1）予測マスクを使用して外観エンコーダをトレーニングします。 
[ABSTRACT] remotsは、データ関連付けの観点からmotsの結果を絞り込むために主に4つのステップを実行します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Speech Representations from Raw Audio by Joint Audiovisual
  Self-Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_10.html">
      <font color="black">Learning Speech Representations from Raw Audio by Joint Audiovisual
  Self-Supervision</font>
    </a>
  </h2>
  <font color="black">特に、この方法は完全に監視されたトレーニングよりも優れているため、音声関連タスクの強力な初期化を提供します。これにより、オーディオエンコーダーに視覚情報が豊富になり、エンコーダーを視覚モダリティなしで評価に使用できます。 （有益なオーディオ属性を予測することによる）オーディオのみの自己監督と（オーディオから話している顔を生成することによる）視覚的な自己監督を組み合わせる。 
[ABSTRACT]このコンセプトは、ビデオアクション認識や音響シーン分類などの一般的なオーディオビジュアルタスクで実証されています。生のオーディオ波形から自己監視型音声表現を学習する方法を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: AlignShift: Bridging the Gap of Imaging Thickness in 3D Anisotropic
  Volumes -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_11.html">
      <font color="black">AlignShift: Bridging the Gap of Imaging Thickness in 3D Anisotropic
  Volumes</font>
    </a>
  </h2>
  <font color="black">ビデオ分析の最近の進歩に触発されて、理論的にあらゆる2D事前学習済みネットワークを厚み認識3Dネットワークに変換する新しいパラメーターフリーオペレーターであるAlignShiftを提案します。このペーパーでは、3D医用画像処理の基本的な課題に対処します。厚さ..注目すべきことに、変換されたネットワークは、薄いスライスでは3Dのように動作しますが、それでも厚いスライスでは2Dに順応して縮退します。 
[ABSTRACT]私たちは、薄いスライスと厚いスライスの両方の医療ボリュームに対する統一されたアプローチを目指しています。最近のテストでは、笛とベルのないかなりのマージンで以前の技術を上回っている私たちの方法の有効性を検証しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br><font color="black">2020-05-05</font>
      </time>
    </span>
</section>
<!-- paper0: Winning with Simple Learning Models: Detecting Earthquakes in Groningen,
  the Netherlands -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_12.html">
      <font color="black">Winning with Simple Learning Models: Detecting Earthquakes in Groningen,
  the Netherlands</font>
    </a>
  </h2>
  <font color="black">単純なモデルの追加の利点は、選択した機能により、データセットに存在するノイズおよびイベントクラスの理解が深まることです。単純なモデルは、保守、デバッグ、理解、およびトレーニングが容易であるため、この調査を通じて、より単純な代替案を慎重に検討せずにディープラーニングを使用することは危険な追求かもしれません。学際的な時系列分析手法から収集された時系列操作の巨大なデータベースから、優れた特徴を選択します。 
[要約]ディープラーニングの過剰使用は多くの機械学習の実践者に影響を与えています。地震イベントの検出の問題を再検討しますが、特徴抽出を備えたロジスティックモデルを使用します。フローニンゲンのガス田から存在しない低マグニチュードの地震をいくつか検出しますカタログ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: GRNet: Gridding Residual Network for Dense Point Cloud Completion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_13.html">
      <font color="black">GRNet: Gridding Residual Network for Dense Point Cloud Completion</font>
    </a>
  </h2>
  <font color="black">特に、構造情報を失うことなく点群と3Dグリッド間で変換するために、GriddingとGridding Reverseという2つの新しい区別可能なレイヤーを考案します。また、隣接するポイントの特徴を抽出するために、区別可能なキュービックフィーチャサンプリングレイヤーを提示して、コンテキスト情報を保持します。 ..実験結果は、提案されたGRNetが、ShapeNet、Completion3D、およびKITTIベンチマークでの最先端のメソッドに対して有利に機能することを示しています。 
[要旨]主流の方法では、多層パーセプトロン（mlps）を使用して点群を直接処理します。点群の構造とコンテキストが完全に考慮されていないため、詳細が失われる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-06">
        <br><font color="black">2020-06-06</font>
      </time>
    </span>
</section>
<!-- paper0: Single-Frame based Deep View Synchronization for Unsynchronized
  Multi-Camera Surveillance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_14.html">
      <font color="black">Single-Frame based Deep View Synchronization for Unsynchronized
  Multi-Camera Surveillance</font>
    </a>
  </h2>
  <font color="black">非同期のマルチカメラの問題を処理するために、このホワイトペーパーでは、既存のDNNベースのマルチビューモデルと連携して機能する同期モデルを提案し、モデル全体の再設計を回避します。モデルの2つのバリアントを検討します。 、パイプラインのどこで同期が行われるかに基づいて、シーンレベルの同期とカメラレベルの同期。ビューの同期モデルは、マルチビューのカウントや3Dを含む、非同期の設定でさまざまなDNNベースのマルチカメラビジョンタスクに適用されます。推定をポーズし、ベースラインと比較して良いパフォーマンスを達成します。 
[ABSTRACT]マルチカメラは、より大きなモデルのビューとより多くのオブジェクトキューを提供します。これらのアプリケーションには、マルチビューのカウント、3Dポーズの推定、または3Dの再構成が含まれます。ただし、この仮定は、特にネットワーク伝送遅延のあるマルチカメラシステムでは常に有効であるとは限りませんおよび低いフレーム-制限されたネットワーク帯域幅によるレート</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Modeling Lost Information in Lossy Image Compression -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_15.html">
      <font color="black">Modeling Lost Information in Lossy Image Compression</font>
    </a>
  </h2>
  <font color="black">具体的には、ILCは可逆的なエンコードモジュールを導入して、エンコーダーデコーダー構造を置き換え、低次元の情報潜在的表現を生成します。その一方で、失われた情報を、さらにコード化または保存されない補助的な潜在的変数に変換します。このように、元の画像の回復は、代理の潜在変数を簡単に描画し、サンプル変数と復号化された潜在特徴を使用してモジュールの逆パスを適用することによって扱いやすくなります。この作業では、Invertible Lossy Compression（ILC）という新しい可逆フレームワークを情報損失の問題を大幅に軽減します。 
[ABSTRACT]画像圧縮方法の自動エンコーダーを置き換える可逆コンポーネント、ILCは、広範なベンチマークデータセットのベースライン方法を大幅に上回ることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-22">
        <br><font color="black">2020-06-22</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic Group Convolution for Accelerating Convolutional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_16.html">
      <font color="black">Dynamic Group Convolution for Accelerating Convolutional Neural Networks</font>
    </a>
  </h2>
  <font color="black">CIFAR-10、CIFAR-100、ImageNetを含む複数の画像分類ベンチマークでの広範な実験は、既存のグループ畳み込み手法や動的実行方法よりも優れていることを示しています。大幅な精度の低下.. DGCは元のネットワーク構造を維持し、従来のグループの畳み込みと同様の計算効率を同時に実現します。 
[ABSTRACT]コードはwwwから入手できます。 github。 com / zhuogege1943 / dgc。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: LandCover.ai: Dataset for Automatic Mapping of Buildings, Woodlands and
  Water from Aerial Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_17.html">
      <font color="black">LandCover.ai: Dataset for Automatic Mapping of Buildings, Woodlands and
  Water from Aerial Imagery</font>
    </a>
  </h2>
  <font color="black">航空写真は通常、衛星データよりもはるかに高いピクセル解像度で画像を提供し、より詳細なマッピングを可能にします。さらに、シンプルなベンチマーク結果を報告し、テストセットのユニオン上の平均交差の90.18％を達成します。データセットはhttp：/で公開されています。 /landcover.ai 
[要約]航空写真は通常、衛星データよりもはるかに高いピクセル解像度で画像を提供し、より詳細なマッピングを可能にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-05">
        <br><font color="black">2020-05-05</font>
      </time>
    </span>
</section>
<!-- paper0: Phase Retrieval Using Conditional Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_18.html">
      <font color="black">Phase Retrieval Using Conditional Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">さらに、ジェネレーターネットワークを測定で調整することで、より詳細な結果を得ることができます。他のディープラーニング手法と同様に、このアプローチはノイズに対して非常に堅牢であるため、実際のアプリケーションに非常に役立ちます。トレーニング時の測定プロセスの知識は、生成モデルを含む既存のアプローチよりも初期化に対してより堅牢なテスト時の最適化につながります。 
[要約]私たちの方法は、確立された投影法に基づく方法を上回っています。他の方法は、ニューラルネットワークに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-10">
        <br><font color="black">2019-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Superpixel Segmentation using Dynamic and Iterative Spanning Forest -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_19.html">
      <font color="black">Superpixel Segmentation using Dynamic and Iterative Spanning Forest</font>
    </a>
  </h2>
  <font color="black">ステップ（c）では、スーパーピクセル分析に基づいてDISFが関連性の値をシードに割り当て、最も重要でないものを削除します.. DISFには、領域マージアルゴリズムと比較して、各反復後に関連するエッジを再構築する機会があります。また、動的アークを導入します。より効果的なスーパーピクセル描写のためのISFフレームワークでの重量推定。異なるオブジェクトプロパティを持つ3つのデータセットですべての結果を示します。 
[ABSTRACT]これは、次の手順に基づいています。動的isf（disf）を提示します。手順は、スーパーピクセルの目的の数に達するまで繰り返されます。disfは、関連するシードを見つける可能性が高くなります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: DeepACEv2: Automated Chromosome Enumeration in Metaphase Cell Images
  Using Deep Convolutional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_20.html">
      <font color="black">DeepACEv2: Automated Chromosome Enumeration in Metaphase Cell Images
  Using Deep Convolutional Neural Networks</font>
    </a>
  </h2>
  <font color="black">次に、新たに提案されたハードネガティブアンカーサンプリングを追加して、領域の提案ネットワークの機能を強化し、非常に混乱しやすい部分染色体に関する見かけではないが重要な情報を抽出します。提案された各モジュールの有効性を検証します。最後に、切り捨て正規化反発損失を設計し、それを損失関数に追加して、オクルージョンによって引き起こされる不正確な位置特定を回避します。 
[要旨]領域ベースのオブジェクト検出スキームに基づいて、染色体列挙フレームワークdeepacev2を開発します。フレームワークは、領域ベースのオブジェクト検出システムに基づいています。列挙プロセスを容易にするように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-12">
        <br><font color="black">2019-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: HKR For Handwritten Kazakh & Russian Database -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_21.html">
      <font color="black">HKR For Handwritten Kazakh & Russian Database</font>
    </a>
  </h2>
  <font color="black">このデータセットはフォームのコレクションです。データベースは1400以上の入力済みフォームで構成されています。データセット内のすべてのフォームのソースは、\ LaTeXによって生成され、その後、手書きで人が入力しました。 
[要約]約63000文、約200人の異なる作家によって生成された7156999個以上の記号がある</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Marginal loss and exclusion loss for partially supervised multi-organ
  segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_22.html">
      <font color="black">Marginal loss and exclusion loss for partially supervised multi-organ
  segmentation</font>
    </a>
  </h2>
  <font color="black">部分的にラベル付けされた画像の背景ラベルは、実際には、ラベル付けされていないすべての臓器の「マージされた」ラベルと「フル」ラベルの意味での「真の」背景であるため、この「マージされた」背景ラベルの確率は限界確率です、マージする前に関連確率を合計します。限界損失を形成します。この限界確率は、既存の損失関数（クロスエントロピー損失、ダイス損失など）に組み込むことができます。
[要約]論文で、このようなデータセットの和集合から単一の複数臓器セグメンテーションネットワークを学習します。これは、部分的にラベル付けされた画像の背景ラベルが、実際には、すべてのラベル付けされていない臓器の「マージされた」ラベルであり、「真の」背景であることを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: SiENet: Siamese Expansion Network for Image Extrapolation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_23.html">
      <font color="black">SiENet: Siamese Expansion Network for Image Extrapolation</font>
    </a>
  </h2>
  <font color="black">さらに、ネットワークに事前知識を導入し、エンコーダーの推論能力を強化するために、シャム敵対機構は、カバーされていない画像機能の分布に対するカバーされた長距離機能の分布をモデル化できるように設計されています。アダプティブフィルコンボリューションと呼ばれる畳み込みは、エンコーダーが未知のコンテンツを予測できるように設計されており、デコーダーの負担を軽減します。この論文では、シャム拡張ネットワーク（SiENet）という名前の、画像外挿用の新しい2ステージシャム敵対モデルを提案します。 
[ABSTRACT] 2つの段階で、未知のコンテンツを予測することを可能にし、センターの負担を軽減するために、新しいボーダーセンシティブなたたみ込み</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Evaluation for Weakly Supervised Object Localization: Protocol, Metrics,
  and Datasets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_24.html">
      <font color="black">Evaluation for Weakly Supervised Object Localization: Protocol, Metrics,
  and Datasets</font>
    </a>
  </h2>
  <font color="black">私たちのプロトコルでは、最新の5つのWSOLメソッドはCAMベースラインを大幅に改善していないことがわかります。さらに、既存のWSOLメソッドは数ショットの学習ベースラインに達していないと報告しています。検証時間は、代わりにモデルのトレーニングに使用されます。調査結果に基づいて、WSOLの今後の方向性について説明します。 
[ABSTRACT]この分野では、アテンションメーターを拡張してオブジェクトをより広くカバーし、それらをよりよくローカライズする方法に焦点を当てています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Multimodal Shape Completion via Conditional Generative Adversarial
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_25.html">
      <font color="black">Multimodal Shape Completion via Conditional Generative Adversarial
  Networks</font>
    </a>
  </h2>
  <font color="black">したがって、1対多のマッピングを学習することにより、複数の出力で部分形状を完成しようとするマルチモーダル形状完了問題を提起します。このアプローチは、学習したマルチモーダル分布の完了を条件付けすることにより、あいまいさを解消します。考えられる結果..さまざまな形の形状の不完全性を含むいくつかのデータセットに対するアプローチを広範囲に評価し、いくつかのベースラインメソッドとメソッドのバリアントを定性的および定量的に比較して、多様性と品質の両方で部分的なシェイプを完成させる方法のメリットを示します。 
[ABSTRACT]条件付きzative学習を介して部分的な形状を完成させる最初のマルチモーダル形状完成方法を開発します。さまざまな形の形状の不完全性を含む複数のデータセットに対するアプローチを広範囲に評価します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-17">
        <br><font color="black">2020-03-17</font>
      </time>
    </span>
</section>
<!-- paper0: A Multi-Level Approach to Waste Object Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_26.html">
      <font color="black">A Multi-Level Approach to Waste Object Segmentation</font>
    </a>
  </h2>
  <font color="black">さらに、新しいRGBD廃棄物オブジェクトセグメンテーションデータセット、MJU-Wasteを作成します。このデータセットは、この分野での将来の研究を容易にするために公開されます。 ）データセット..最初に、シーンレベルのディープネットワークが初期の粗いセグメンテーションを生成します。これに基づいて、ズームインするためにいくつかの潜在的なオブジェクト領域を選択し、細かいセグメンテーションを実行します。 
[ABSTRACT]私たちの方法は、潜在的なオブジェクトの複数のレベルの強度と深度の情報を統合します。結果は、外観、深度、および空間的類似性を尊重することを学習する密に接続された条件付きランダムフィールドにさらに統合されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Segment Anatomical Structures Accurately from One Exemplar -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_27.html">
      <font color="black">Learning to Segment Anatomical Structures Accurately from One Exemplar</font>
    </a>
  </h2>
  <font color="black">これにより、臨床医が設計した画像ベースのバイオマーカー評価（パーソナライズされた定量的臨床診断をサポートするため）が容易になり、完全に監視されたベースラインよりも優れています。完全に注釈が付けられた大量のトレーニング画像を使用せずに正確な解剖学的構造のセグメンテーションを生成することは非常に望ましいです。 
[ABSTRACT]コンタートランスフォーマーネットワーク（ctn）は、自然に組み込まれた人間のループメカニズムに基づくワンショットの解剖学的セグメンターです。ctnモデルのトレーニングには、ラベルが付けられた画像の例が1つだけ必要で、ラベル付けされていない追加のデータを活用します。失われた機能</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: AutoML: A Survey of the State-of-the-Art -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_28.html">
      <font color="black">AutoML: A Survey of the State-of-the-Art</font>
    </a>
  </h2>
  <font color="black">自動機械学習（AutoML）は、人間の支援なしでDLシステムを構築する有望なソリューションになり、ますます多くの研究者がAutoMLに注力しています。NASは、現在AutoMLの非常にホットなサブトピックであるため、NASにさらに注力しています。 、パイプラインに応じたAutoMLメソッドを紹介し、データの準備、機能エンジニアリング、ハイパーパラメーターの最適化、ニューラルアーキテクチャ検索（NAS）をカバーします。 
[ABSTRACT] automlは特定のタスク用の高速学習システムですが、人間の専門知識により、dlのより多くの領域への適用が妨げられています。将来の研究のために、既存のautomlメソッドの未解決の問題について説明します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-02">
        <br><font color="black">2019-08-02</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning for Anomaly Detection: A Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_29.html">
      <font color="black">Deep Learning for Anomaly Detection: A Review</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、3つの高レベルのカテゴリと11の細かいカテゴリのメソッドの進歩をカバーする、検出方法の包括的な分類法を使用した深部異常検出の調査をレビューします。高度なアプローチを必要とする独特の問題の複雑さと課題がまだあります。 。さらに、一連の可能な将来の機会と課題への対処に関する新しい視点について説明します。 
[要約]ディープラーニングにより異常検出が可能になったことは重要な方向性として浮上しています。ディープラーニングにより異常検出が可能になりました。つまり、ディープイノベーションが数十年にわたってトピックになっています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Combating Domain Shift with Self-Taught Labeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_30.html">
      <font color="black">Combating Domain Shift with Self-Taught Labeling</font>
    </a>
  </h2>
  <font color="black">適応中、この分類子は\ emph {バイアスのない正確な}疑似ラベルを提供することにより、ターゲットドメイン自体を教えることができます。特に、各ターゲットデータに対して、メモリバンクを使用して、ドメインからのソフトラベルとともに機能を格納します-共有分類子。1つのドメインでトレーニングされた分類モデルを、ターゲットラベルがほとんどないかまったくない他の新しいドメインに適応させるときに、ドメインシフトに対処する新しい方法を提示します。 
[要約]代わりに、自己学習型ラベリング（setl）を提案します。これは、ラベル付けされていないデータの補助ターゲット固有の分類子を見つける新しい正則化アプローチです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Consistency Regularization with Generative Adversarial Networks for
  Semi-Supervised Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_31.html">
      <font color="black">Consistency Regularization with Generative Adversarial Networks for
  Semi-Supervised Image Classification</font>
    </a>
  </h2>
  <font color="black">この作業では、この重要な制限に対処するために一貫性の正則化をバニラセミGANに組み込みます。2つのSSL画像分類ベンチマークデータセット、SVHNおよびCIFAR-10に対するアプローチの有効性を示します。特に、新しい複合一貫性正則化手法は、精神的に、2つのよく知られた一貫性ベースの手法、平均教師と補間一貫性トレーニングを組み合わせたものです。 
[ABSTRACT]新しい複合整合性正則化方法は、2つのよく知られた整合性に基づく手法-平均的な教師と補間整合性トレーニングを組み合わせたものです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Synthetic-to-Real Domain Adaptation for Lane Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_32.html">
      <font color="black">Synthetic-to-Real Domain Adaptation for Lane Detection</font>
    </a>
  </h2>
  <font color="black">たとえば、ラマとtuSimpleレーンデータセットに対して提案されたオートエンコーダアプローチを使用すると、ラベル付きデータの10％だけで完全に監視された精度をほぼ回復できます。これは、非現実的な合成ドメインで学習したモデルを実際の画像に適合させるという課題をもたらします..さらに、画像の翻訳や自己監視などの既存のドメイン適応アプローチを探索し、レーン検出タスクに合わせて調整します。 
[ABSTRACT]これにより、非現実的な合成ドメインで学習したモデルを実際の画像に適応させるという課題が生じます。コストのかかるターゲットドメインのラベル付け作業を節約できる可能性を示しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-image Super Resolution of Remotely Sensed Images using Residual
  Feature Attention Deep Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_33.html">
      <font color="black">Multi-image Super Resolution of Remotely Sensed Images using Residual
  Feature Attention Deep Neural Networks</font>
    </a>
  </h2>
  <font color="black">単一またはマルチ画像の超解像に関する他の利用可能なソリューションに対する広範な実験と評価により、提案された深層学習ベースのソリューションは、リモートセンシングのマルチ画像超解像の最先端と見なすことができることが実証されていますさらに、同じシーンで複数の入力があるため、表現学習ネットワークは、冗長な低周波信号を流し、より重要な高周波成分に計算を集中させるために、入れ子になった残余接続を広範囲に使用します。しかし、ほとんどの文献に掲載された作品は、これまで単一画像の超解像問題に焦点を当ててきました。 
[要約]提示された研究は、マルチ画像超解像タスクに効率的に取り組む新しいモデルを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: A study of Neural networks point source extraction on simulated
  Fermi/LAT Telescope images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_34.html">
      <font color="black">A study of Neural networks point source extraction on simulated
  Fermi/LAT Telescope images</font>
    </a>
  </h2>
  <font color="black">フェルミ大面積望遠鏡からの画像を模倣する独自の人工データセットでトレーニングされた畳み込みニューラルネットワーク（CNN）を使用して点光源を抽出する方法を提示します。精度が約15％向上し、推論時間は、類似の最新のモデルに対して少なくとも4倍の精度向上です。特定のケースでは、画像上の点ソースを見つけることも重要な作業になります。 
[要旨]場合によっては、画像上の点光源を見つけることも重要なタスクになります。たとえば、この方法を使用して、点をポイントポイントリソースにすることができます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Fine-grained Vibration Based Sensing Using a Smartphone -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_35.html">
      <font color="black">Fine-grained Vibration Based Sensing Using a Smartphone</font>
    </a>
  </h2>
  <font color="black">VibroTagの精度は、VibroTagとの比較のために実装した最先端のIMUベースのスキームの1つによって達成された49.25％の平均精度より37％高いです。結果は、VibroTagが86.55％の平均精度を達成していることを示しています。 24の異なる場所/表面を認識しながら、それらの表面の一部が同様の材料でできていても。それらの振動シグネチャに基づいて表面を認識することは、Near Field Communication（NFC）などの追加のハードウェアを必要とせずに異なる場所のタグ付けを可能にするので便利です。 ）タグ。 
[ABSTRACT] vibrotagの精度は、最新の1つによって達成された49.25％の平均精度より37％高い-最先端のimusベースのスキーム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: PaMIR: Parametric Model-Conditioned Implicit Representation for
  Image-based Human Reconstruction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_36.html">
      <font color="black">PaMIR: Parametric Model-Conditioned Implicit Representation for
  Image-based Human Reconstruction</font>
    </a>
  </h2>
  <font color="black">最後に、パラメトリックモデルの推定精度を向上させ、パラメトリックモデルと陰関数の整合性を高めるためのボディリファレンス最適化手法を提案します。PaMIRベースの再構成フレームワークでは、新しいディープニューラルネットワークを提案して、パラメトリックモデルのセマンティック機能を使用して深い陰関数を形成します。これにより、困難なポーズやさまざまな衣服トポロジのシナリオの下での汎化能力が向上します。不適切な問題とは、人間モデルの3D表現です。 
[ABSTRACT]パラメトリックモデル-条件付き暗黙的表現（pamir）は、パラメトリックボディモデルを自由形式のディープディープディープインジェクションに組み合わせます。3Dモデルを含む通常の3Dモデルの制限を克服するように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: AVP-SLAM: Semantic Visual Mapping and Localization for Autonomous
  Vehicles in the Parking Lot -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_37.html">
      <font color="black">AVP-SLAM: Semantic Visual Mapping and Localization for Autonomous
  Vehicles in the Parking Lot</font>
    </a>
  </h2>
  <font color="black">正確な位置特定機能は非常に重要です。これらのセマンティック機能は、従来の機能と比較して、長期的に安定しており、遠近法や照明の変化に対して堅牢です。IMU（慣性測定ユニット）とホイールエンコーダーによって支援され、提案されたシステムはグローバルな視覚的意味マップ。 
[ABSTRACT]詳細な機能には、通常駐車場に表示される案内標識、駐車場の線、スピードバンプなどが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-03">
        <br><font color="black">2020-07-03</font>
      </time>
    </span>
</section>
<!-- paper0: Quantifying and Leveraging Predictive Uncertainty for Medical Image
  Assessment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_38.html">
      <font color="black">Quantifying and Leveraging Predictive Uncertainty for Medical Image
  Assessment</font>
    </a>
  </h2>
  <font color="black">ただし、実際には、これは目に見えないデータの一般化が不十分な自信過剰なシステムにつながります。このアプローチは、コンピュータラジオグラフィー、超音波検査、磁気共鳴イメージングなどの異なる放射線検査からの医用画像に固有のあいまいさを説明するために不可欠であると主張します。これを説明するために、分類のための確率論的推定だけでなく、予測された出力でのシステムの信頼度を取得する明示的な不確実性の尺度も学習するシステムを提案します。 
[ABSTRACT]これらの問題は通常、確率的予測を提供することに限定されます。これらには、予測された出力でのシステムの信頼度を取得する明示的な不確実性測度を持つシステムが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Dense Recurrent Neural Networks for Accelerated MRI: History-Cognizant
  Unrolling of Optimization Algorithms -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_39.html">
      <font color="black">Dense Recurrent Neural Networks for Accelerated MRI: History-Cognizant
  Unrolling of Optimization Algorithms</font>
    </a>
  </h2>
  <font color="black">加速MRIの逆問題は、通常、正符号化演算子に関するドメイン固有の知識を正則化された再構成フレームワークに組み込んでいます。これらの方法は、反復最適化アルゴリズムを展開して、ドメイン固有のデータ整合性とデータ駆動正則化を交互に行うことにより、逆問題目的関数を解決しますニューラルネットワークを介して。以前の反復の履歴を使用するPGDメソッドの効率的なバリアントに触発され、パフォーマンスを向上させるために、反復全体で密な接続を持つ最適化アルゴリズムの履歴を認識した展開を提案します。 
[要約]最近の物理学-駆動型ディープラーニング（dl）メソッドは、データ駆動型の正則化にニューラルネットワークを使用するために提案されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-16">
        <br><font color="black">2019-12-16</font>
      </time>
    </span>
</section>
<!-- paper0: Single Path One-Shot Neural Architecture Search with Uniform Sampling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_40.html">
      <font color="black">Single Path One-Shot Neural Architecture Search with Uniform Sampling</font>
    </a>
  </h2>
  <font color="black">包括的な実験により、私たちのアプローチが柔軟で効果的であることが確認されています。すべてのアーキテクチャ（およびそれらの重み）は、完全かつ均等にトレーニングされています。トレーニングは簡単で、検索も高速です。 
[ABSTRACT]ただし、既存のワンショット手法はトレーニングが困難です。大規模なデータネットではまだ効果的ではありません。トレーニングが簡単で、検索が高速です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-03-31">
        <br><font color="black">2019-03-31</font>
      </time>
    </span>
</section>
<!-- paper0: Delving into the Adversarial Robustness on Face Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_41.html">
      <font color="black">Delving into the Adversarial Robustness on Face Recognition</font>
    </a>
  </h2>
  <font color="black">顔認識は最近大幅な進歩を遂げ、深い畳み込みニューラルネットワーク（CNN）の開発に基づいた標準的なベンチマークで高精度を達成しました。これらの評価は、覆い焼きやなりすまし攻撃、$ \ ell_2 $および$ \ ell_ \ infty $攻撃、ホワイトボックス攻撃およびブラックボックス攻撃を含む、さまざまな敵対的な設定の下で行われます。 
[要約]敵対的な例に対する深いCNNの堅牢性の欠如により、巨大な顔認識アプリケーションにセキュリティ上の懸念が生じている</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: A Benchmark of Medical Out of Distribution Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_42.html">
      <font color="black">A Benchmark of Medical Out of Distribution Detection</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、胸部X線、眼底画像、組織学スライドなど、医療画像の3つのドメインで人気のあるOoDDメソッドのベンチマークについて説明します。これらの画像は、診断の前に分布外検出（OoDD）メソッドで除外する必要があります。実験は、いくつかのタイプの分布外サンプルで良好な結果をもたらす方法にもかかわらず、トレーニング分布に近い画像を認識できないことを示しています。 
[要約]システムは患者からの画像を使用して疾患を診断します。これらの画像は、診断前に分布外検出（oodd）法で除外する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: PathGAN: Local Path Planning with Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_43.html">
      <font color="black">PathGAN: Local Path Planning with Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">最後に、ETRIDrivingを紹介します。これは、記録された感覚データが個別の高レベルの運転アクションでラベル付けされた自動運転のデータセットであり、精度との観点から、ETRIDrivingで提案されたモデルの最先端のパフォーマンスを示します。多様性..さらに、生成されたパスの精度と多様性をさらに高めるために、パスの位置に隠された意図をPGNがキャプチャし、識別器にシーケンシャルな意図がどれほど現実的かを評価させるようにします。生成モデルは2つのニューラルネットワークで構成されます、特徴抽出ネットワーク（FEN）およびパス生成ネットワーク（PGN）。 
[要約]自動運転データセットetridrivingを紹介します。彼らは、精度と多様性の観点から、提案されたモデルのetridrivingに関する最先端のパフォーマンスを実証しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient and Phase-aware Video Super-resolution for Cardiac MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_44.html">
      <font color="black">Efficient and Phase-aware Video Super-resolution for Cardiac MRI</font>
    </a>
  </h2>
  <font color="black">心臓磁気共鳴画像法（CMR）は、心臓の構造と機能を非侵襲的で痛みのない方法で示すことができるため、広く使用されています。さらに、提案された残差学習方式の残差により、ネットワークはLR-HRマッピングを学習しやすくなります。このために、ハードウェアをアップグレードしたり、スキャンプロトコルを変更したりせずに、CMRビデオの超解像問題を解決するための新しいエンドツーエンドのトレーニング可能なネットワークを提案します。 
[要約]心臓の知識は、ネットワークがlr-hr構造を学習できるようにするために提案されています。このテクノロジーを使用して、このテクノロジーの効果を検出することが可能です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br><font color="black">2020-05-21</font>
      </time>
    </span>
</section>
<!-- paper0: Guidestar-free image-guided wavefront-shaping -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_45.html">
      <font color="black">Guidestar-free image-guided wavefront-shaping</font>
    </a>
  </h2>
  <font color="black">ここでは、新しい概念、イメージガイド波面成形を紹介します。照明制御なしで、高度に散乱するレイヤーを介して非侵襲的で、ガイドスターなしの広視野、インコヒーレントイメージングを可能にします。高度に散乱するレイヤーを介して拡張オブジェクトのイメージングを示し、マルチコアファイバーは、顕微鏡から内視鏡検査まで、さまざまなアプリケーションでの非侵襲的イメージングへの道を開きます。最近、波面成形アプローチを使用することで、生体組織のイメージングや角の周りの観察などの大幅な進歩が見られます。 
[ABSTRACT]波面-技術を使用することで、生体組織を介して画像を形成し、隅を見ることができます。スペックル相関をキャプチャするための新しい代替代替方法、ガイド-星と波面制御を回避しますが、内部に含まれる小さなオブジェクトに限定されますメモリ-効果の相関範囲</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: NVAE: A Deep Hierarchical Variational Autoencoder -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_46.html">
      <font color="black">NVAE: A Deep Hierarchical Variational Autoencoder</font>
    </a>
  </h2>
  <font color="black">私たちは、深さ方向の分離可能な畳み込みとバッチ正規化を使用して画像生成用に構築された深い階層型VAEであるNouveau VAE（NVAE）を提案します。私たちの知る限りでは、NVAEは256 $ \ times $ 256ピクセルの自然画像に適用された最初の成功したVAEです。 
[要旨]血管の研究の大部分は統計的な課題に焦点を当てていますが、血管を再形成するためのニューラルアーキテクチャを注意深く設計するという方向性を探ります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Depth-Aware Arbitrary Style Transfer Using Instance Normalization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_47.html">
      <font color="black">Depth-Aware Arbitrary Style Transfer Using Instance Normalization</font>
    </a>
  </h2>
  <font color="black">（2017）別のモデルをトレーニングせずに任意のスタイルを効率的に転送できますが、コンテンツ画像の深度マップを再現することはできません。ただし、HuangらのAdaINメソッド。ただし、これらの従来の方法は、計算効率が悪いか、個別のトレーニングが必要です各スタイルのニューラルネットワーク。 
[ABSTRACT]最近の研究では、最適化された損失関数に追加の正則化機能を使用して深度マップを保存し、深度マップの保存を強制することが推奨されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-03">
        <br><font color="black">2019-06-03</font>
      </time>
    </span>
</section>
<!-- paper0: Naive-Student: Leveraging Semi-Supervised Learning in Video Sequences
  for Urban Scene Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_48.html">
      <font color="black">Naive-Student: Leveraging Semi-Supervised Learning in Video Sequences
  for Urban Scene Segmentation</font>
    </a>
  </h2>
  <font color="black">この作業では、ラベルなしのビデオシーケンスと追加の画像で半教師あり学習を活用して、都市のセグメンテーションのパフォーマンスを向上させ、同時にセマンティック、インスタンス、およびパノプティックセグメンテーションに取り組むことができるかどうかを尋ねます。その結果、私たちの素朴なモデル、そのようなシンプルでありながら効果的な反復半教師あり学習で訓練され、3つのCityscapesベンチマークすべてで最先端の結果を達成し、テストセットで67.8％PQ、42.6％AP、および85.2％mIOUのパフォーマンスに達します。大規模な識別モデルでの教師あり学習は、現代のコンピュータービジョンの主力です。 
[ABSTRACT]この制限は特に人間の注釈で顕著ですが、ラベル付けされていないデータが大量に存在する可能性があります。これらの作業は、学習したアーキテクチャの構築を回避するためのものです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br><font color="black">2020-05-20</font>
      </time>
    </span>
</section>
<!-- paper0: Designing and Training of A Dual CNN for Image Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_49.html">
      <font color="black">Designing and Training of A Dual CNN for Image Denoising</font>
    </a>
  </h2>
  <font color="black">スパースメカニズムを備えた特徴抽出ブロックは、2つのサブネットワークを介してグローバルとローカルの特徴を抽出します。（3）小型フィルターを使用してノイズ除去の複雑さを軽減します。拡張ブロックは、グローバルとローカルの特徴を収集して融合します。後者のネットワークの補足情報を提供します。 
[ABSTRACT] dudenetは4つのモジュールで構成されています：特徴抽出ブロック、拡張ブロック、圧縮ブロック、再構成ブロック</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Open Set Domain Adaptation with Multi-Classifier Adversarial Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_50.html">
      <font color="black">Open Set Domain Adaptation with Multi-Classifier Adversarial Network</font>
    </a>
  </h2>
  <font color="black">ただし、ソースドメインには「既知のクラス」のラベルスペースしかありません。この特定のオープンセットドメイン適応設定に対処するために、事前の研究では、偽陰性の転送の処理に欠けている経験的な固定しきい値を持つドメイン敵対モデルを導入しています。マッチングドメインの適応方法は、より小さなソースドメインからより多くのクラスを持つより大きく多様なターゲットドメインへの適応を必要とするような設定では不十分です。 
[要約]既存のドメイン適応方法の大部分は、ソースドメインとターゲットドメイン全体で同一のラベルスペースを持っているという仮定に依存しているため、実際のシナリオでのアプリケーションが制限されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-01">
        <br><font color="black">2020-07-01</font>
      </time>
    </span>
</section>
<!-- paper0: Spatio-Temporal Scene Graphs for Video Dialog -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_51.html">
      <font color="black">Spatio-Temporal Scene Graphs for Video Dialog</font>
    </a>
  </h2>
  <font color="black">生成された回答の品質に関する人間の評価では、従来の方法と比較して12％の相対的な改善が見られます。このために、ビデオ内のきめの細かい情報フローをモデル化する新しい時空間シーングラフ表現（STSGR）を提案します。 AVSDデータセットにアクセスして、最先端の結果を示します。 
[要約]生成された回答の質に関する人間の評価では、以前の方法と比較して12％改善されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Policy Adaptation during Deployment -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_52.html">
      <font color="black">Self-Supervised Policy Adaptation during Deployment</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、さまざまなタスクにわたって30の環境のうち25の一般化を改善し、大部分の環境でドメインのランダム化よりも優れています。自然な解決策は、新しい環境での展開後もトレーニングを継続することですが、新しい環境が提供する場合はこれを実行できません報酬信号はありません。DeepMindControlスイートとViZDoomのさまざまな環境で実証的評価が行われます。 
[ABSTRACT]自己監督により、ポリシーは、報酬を使用せずに展開後にトレーニングを続行できます。調査はさまざまな異なる環境で実行されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: AUSN: Approximately Uniform Quantization by Adaptively Superimposing
  Non-uniform Distribution for Deep Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_53.html">
      <font color="black">AUSN: Approximately Uniform Quantization by Adaptively Superimposing
  Non-uniform Distribution for Deep Neural Networks</font>
    </a>
  </h2>
  <font color="black">量子化は、エッジアプリケーションでのDNN推論を簡略化するために不可欠です。AUSNは、ビット幅を極限まで効率的に活用するデコーダーなしのコーディングスキーム、コーディングスキームをさまざまなDNNレイヤー、モデル、追加のハードウェア設計作業なしのタスク、およびよく知られているビット幅オーバーフローと再量子化の問題を排除できる丸めスキーム。したがって、重みとアクティブ化を量子化する新しい量子化方法を提案します。 
[ABSTRACT]ただし、既存の均一および非均一の量子化方法では、表現範囲と表現解像度の間に固有の矛盾が見られます。これらのエラーは、ビット幅が十分に活用されていないか、精度が大幅に低下しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Graph2Kernel Grid-LSTM: A Multi-Cued Model for Pedestrian Trajectory
  Prediction by Learning Adaptive Neighborhoods -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_54.html">
      <font color="black">Graph2Kernel Grid-LSTM: A Multi-Cued Model for Pedestrian Trajectory
  Prediction by Learning Adaptive Neighborhoods</font>
    </a>
  </h2>
  <font color="black">\ textit {Grid-LSTM}をエンコーダーとして使用して、潜在的な将来の近隣と、視覚的および空間的境界が与えられた場合の歩行者の動きへの影響について学習します。歩行者の近隣が設計..歩行者軌道予測は、群集の社会的および文脈的相互作用のモデリングに向かって進んだ著名な調査トラックであり、歩行軌道の時間的表現のための長期短期記憶（LSTM）の広範な使用法を備えています。 
[ABSTRACT]既存のアプローチは、仮想近隣を歩行者の社会的状態をプールするための固定グリッドとして使用します。この実験は、シーンの特徴や群衆のダイナミクスが異なるデータセット全体でのアプローチの一般化を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-03">
        <br><font color="black">2020-07-03</font>
      </time>
    </span>
</section>
<!-- paper0: Remix: Rebalanced Mixup -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_55.html">
      <font color="black">Remix: Rebalanced Mixup</font>
    </a>
  </h2>
  <font color="black">実験結果により、Remixは以前の最先端技術に比べて一貫した大幅な改善を提供することが確認されました。特に、2つのサンプルを混合する場合、Mixupメソッドと同じ方法で機能が比例して混合されると、Remixはラベルを優先的に割り当てますマイノリティクラスに偏って高いウェイトを提供することによるマイノリティクラスの評価。そうすることで、分類子は決定境界を多数派クラスに押しやることを学び、多数派クラスと少数派クラスの間の汎化誤差のバランスをとります。 
[ABSTRACT] remixは、Mixupのプレゼンテーションを緩和する新しい正則化手法です。これにより、フィーチャとラベルの混合要素を解きほぐすことができます。これにより、分類子は決定の境界を押し広げることを学習します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Operation-Aware Soft Channel Pruning using Differentiable Masks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_56.html">
      <font color="black">Operation-Aware Soft Channel Pruning using Differentiable Masks</font>
    </a>
  </h2>
  <font color="black">提案されたフレームワークにより、微調整の追加手順なしで、モデルパラメーターとチャネルプルーニングの共同学習を介して圧縮モデルを識別できます。私たちは、広範な実験を行い、同じ量の出力ネットワークの精度の面で優れたパフォーマンスを実現します。最先端の方法と比較した場合のリソース。提案されているアプローチでは、チャネルプルーニング用のバッチ正規化（BN）と修正線形ユニット（ReLU）を組み合わせて検討します。 2つの連続する操作が各機能マップを非アクティブ化する可能性がどの程度あるかを推定し、高い確率でチャネルをプルーニングします。 
[ABSTRACT]提案されたシステムは、モデルの学習とチャネルの剪定を通じてモデルを識別することを可能にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Predicting the Accuracy of a Few-Shot Classifier -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_57.html">
      <font color="black">Predicting the Accuracy of a Few-Shot Classifier</font>
    </a>
  </h2>
  <font color="black">各設定について、検討した分類子の一般化能力と相関することを経験的に実証する合理的な尺度を提案します。標準的な少数ショットビジョンデータセットで実験を行います。最初に、一般化パフォーマンスの変動の理由を分析します。 
[要約]単純な測度を使用して、特定の信頼度まで一般化を予測できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Making Adversarial Examples More Transferable and Indistinguishable -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_58.html">
      <font color="black">Making Adversarial Examples More Transferable and Indistinguishable</font>
    </a>
  </h2>
  <font color="black">この問題に対処するために、ADAM反復高速勾配タン法（AI-FGTM）を提案して、高い転送可能性を備えた区別できない敵対的な例を生成します。最高の攻撃であるTI-DI-AITMは、平均で6つのブラックボックス防御モデルをだますことができます。 88.0 \％の成功率。この方法が、より多くの転送可能性と区別不可能性を備えた敵対的な例を生成するための新しいベースラインとして機能することを期待しています。 
[要約]私たちの方法は、より多くの転送可能性と区別不可能性を備えた敵対的な例を生成するための新しいベースラインとして機能することを期待しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: When Perspective Comes for Free: Improving Depth Prediction with Camera
  Pose Encoding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_59.html">
      <font color="black">When Perspective Comes for Free: Improving Depth Prediction with Camera
  Pose Encoding</font>
    </a>
  </h2>
  <font color="black">トレーニングにカメラポーズの監視のみを必要とする私たちの因数分解アプローチは、10倍以上のデータのフルシーン深度モニタリングでトレーニングされた最新の最先端の方法よりも優れています。エンドツーエンドのトレーニングに必要な高価なグラウンドトゥルースの深度を収集する必要なしに、ポーズの監視のみを行います。実際のテストセットでポーズ条件付き深度予測子（屋内の合成シーンでトレーニング）を評価します。 
[ABSTRACT]モデルは、トレーニング中に見られるカメラポーズの分布によって強くバイアスされていることを観察しました。シーンアートの分布が固定されている場合でも、モデルはノベルフォームに一般化できません。強力なテスト時間のポーズが無料で提供されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Deformable spatial propagation network for depth completion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_60.html">
      <font color="black">Deformable spatial propagation network for depth completion</font>
    </a>
  </h2>
  <font color="black">この問題に取り組むために、このホワイトペーパーでは、変形可能な空間伝播ネットワーク（DSPN）を提案し、各ピクセルに異なる受容野とアフィニティマトリックスを適応的に生成します。これにより、ネットワークは、伝播に関連するピクセルがはるかに少ないが関連性の高い情報を取得できます。ただし、各ピクセルの伝播は固定受容野で発生します。 
[要旨]畳み込み空間通信ネットワーク（cspn）は、このタスクの最先端の方法の1つです。線形通信モデルを使用して、ローカルコンテキストで3Dマップを洗練します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Object-Contextual Representations for Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_61.html">
      <font color="black">Object-Contextual Representations for Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">最後に、表現の類似性％各ピクセルと各オブジェクト領域の関係を計算し、各ピクセルの表現を、ピクセルとの関係に従ってすべてのオブジェクト領域表現の重み付き集約であるオブジェクトコンテキスト表現で拡張します。 。私たちは、提案されたアプローチが、Cityscapes、ADE20K、LIP、PASCAL-Context、COCO-Stuffなど、さまざまな難しいセマンティックセグメンテーションベンチマークで競争力のあるパフォーマンスを達成することを実証的に実証します。オブジェクト領域内。 
[要旨]動機は、ピクセルのラベルが、ピクセルが属しているオブジェクトのカテゴリであるということです。単純なオブジェクトの領域で、グラウンドトゥルースピクセルの監視下にあります。second.last、％このタイプの表現。オブジェクトを使用して各ピクセルの表現を拡張します-コンテキスト表現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-24">
        <br><font color="black">2019-09-24</font>
      </time>
    </span>
</section>
<!-- paper0: SegFix: Model-Agnostic Boundary Refinement for Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_62.html">
      <font color="black">SegFix: Model-Agnostic Boundary Refinement for Segmentation</font>
    </a>
  </h2>
  <font color="black">境界ピクセルから内部ピクセルへの方向を学習して対応を構築します。この方法では、セグメンテーションモデルの事前情報が不要で、ほぼリアルタイムの速度を実現します。このアプローチでは、2つのステップで入力画像のみを処理します：（ i）境界ピクセルをローカライズし、（ii）各境界ピクセルに対応する内部ピクセルを識別します。 
[ABSTRACT]元の-信頼できない境界ピクセルの予測を置き換えることをお勧めします。境界ピクセルから内部ピクセルへの方向を学習して対応を構築します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: KIT MOMA: A Mobile Machines Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_63.html">
      <font color="black">KIT MOMA: A Mobile Machines Dataset</font>
    </a>
  </h2>
  <font color="black">KIT MOMAの画像のほとんどは実際のシーンにありますが、一部の画像は一流建設機械会社の公式ウェブサイトからのものです。地上に固定カメラがあると信じているため、収集された画像のビューはモバイルマシンの外にあります。興味深いマシンがすべて閉鎖されたサイトで動作している場合は、より適しています。また、データセットでのYOLO v3のパフォーマンスを評価しました。作業現場。 
[ABSTRACT]解決すべき最も緊急の問題は、公開された、やりがいのあるビジュアルデータセットがないことです。データセット、トレーニングされた重み、および更新は、私たちのGisetで見つけることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Low-dimensional Manifold Constrained Disentanglement Network for Metal
  Artifact Reduction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_64.html">
      <font color="black">Low-dimensional Manifold Constrained Disentanglement Network for Metal
  Artifact Reduction</font>
    </a>
  </h2>
  <font color="black">広範な実験により、提案されたLDM-DNアプローチは、ペアおよび/またはペアではない学習設定でMARのパフォーマンスを一貫して改善でき、合成データセットと臨床データセットで競合するメソッドよりも優れていることが実証されています。回復した画像を低次元のパッチマニホールド上に制限しながら、相乗的なネットワーク損失関数を最適化することで。さらに、ペアデータと非ペアデータの両方から学習するため、効率的なハイブリッド最適化スキームが提案され、臨床データセットのMARパフォーマンスがさらに向上します。 
[要約]目を引くネットワーク（adn）が対になっていない画像で直接提案され、臨床データセットで有望な結果が得られました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: RGBT Salient Object Detection: A Large-scale Dataset and Benchmark -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_65.html">
      <font color="black">RGBT Salient Object Detection: A Large-scale Dataset and Benchmark</font>
    </a>
  </h2>
  <font color="black">この作業は、グラウンドトゥルースアノテーション付きの空間的に配置された5000個のRGBT画像ペアを含む、VT5000という名前のこのようなRGBT画像データセットに貢献します。 .. VT5000には、アルゴリズムの堅牢性を探索するために、さまざまなシーンや環境で収集された11の課題があります。 
[ABSTRACT]ほとんどの作品は、実際のアプリケーションのパフォーマンスを制限するRGBベースのデータセットに焦点を当てています。新しい研究の利点は、大規模なデータセットと包括的なベンチマークの欠如によって制限されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: A Distilled Model for Tracking and Tracker Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_66.html">
      <font color="black">A Distilled Model for Tracking and Tracker Fusion</font>
    </a>
  </h2>
  <font color="black">広範な検証は、提案されたアルゴリズムがリアルタイムで実行されている間、最先端のトラッカーと競合することを示しています。コンパクトな学生モデルは、知識の蒸留と強化学習の融合によってトレーニングされます。2番目は、評価指標の学習を可能にします。その後、オンラインで悪用されます。 
[ABSTRACT]新しい調査では、オフラインおよびオンラインの他のビジュアルトラッカーを利用する新しい追跡方法を提案しています。最初の調査では、他のトラッカーの追跡知識を転送および圧縮できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Adaptive 3D Face Reconstruction from a Single Image -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_67.html">
      <font color="black">Adaptive 3D Face Reconstruction from a Single Image</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、3Dランドマークの深度を組み合わせて不可視のランドマークの不確実な検出を解決する、単一の画像から3D顔の形状を適応的に再構築する新しい2Dおよび3D最適化手法を提案します。複数のデータセットに関する実験結果は、この方法は、単一のカラー画像から高品質の再構成を生成でき、自己閉塞と大きなポーズに対してロバストです。この方法の戦略には、2Dランドマークと3Dランドマークの両方を使用した粗から微細のポーズ推定、および正確な3D面を復元するために、洗練されたポーズパラメータに基づく2Dおよび3Dアダプティブリウェイト。 
[要約]推定された2Dランドマークの不確実性は、顔再構成の品質に影響します。これは、洗練された画像に基づく2Dおよび3Dの再重み付けを意味します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Gradient Origin Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_68.html">
      <font color="black">Gradient Origin Networks</font>
    </a>
  </h2>
  <font color="black">この論文では、明示的なエンコーダーなしで潜在表現をすばやく学習できる新しいタイプの暗黙の生成モデルを提案します。このゼロベクトルに関するデータフィッティング損失の勾配は、データをキャプチャする潜在点として機能するように共同で最適化されます。多様体..これは、ゼロで初期化された潜在ベクトルと並んで座標空間内の点を入力として取る暗黙的なニューラルネットワークで実現されます。 
[ABSTRACT]結果はオートエンコーダと同様の特性を示していますが、パラメータは少なくなっています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Count in the Crowd from Limited Labeled Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_69.html">
      <font color="black">Learning to Count in the Crowd from Limited Labeled Data</font>
    </a>
  </h2>
  <font color="black">具体的には、ラベル付けされていないデータの擬似グラウンドトゥルースの推定を含むガウスプロセスベースの反復学習メカニズムを提案します。これは、ネットワークのトレーニングの監視として使用されます。最近の群集カウントアプローチは、優れたパフォーマンスを実現しています。提案された方法は、ShanghaiTech、UCF-QNRF、WorldExpo、UCSDなどのいくつかのデータセットの削減データ（半教師あり）設定で有効であることが示されています。
[要約]提案された方法は、削減データ（半教師あり）で有効であることが示されています） 設定</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
<!-- paper0: Lightweight Temporal Self-Attention for Classifying Satellite Image Time
  Series -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_70.html">
      <font color="black">Lightweight Temporal Self-Attention for Classifying Satellite Image Time
  Series</font>
    </a>
  </h2>
  <font color="black">各頭は、高度に専門化された時間的特徴を抽出し、次にそれを単一の表現に連結します。リモートセンシングの時間シーケンスを分類するためにマルチヘッドの自己注意メカニズムを採用する最近の研究に基づいて、時間的注意エンコーダーの変更を提案します。ただし、グローバル規模で時系列を処理できる効率的なメソッドが必要です。 
[ABSTRACT]これは、時間を処理できる効率的な方法のために呼び出されます-地球規模でのシリーズ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-01">
        <br><font color="black">2020-07-01</font>
      </time>
    </span>
</section>
<!-- paper0: Biomechanics-informed Neural Networks for Myocardial Motion Tracking in
  MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_71.html">
      <font color="black">Biomechanics-informed Neural Networks for Myocardial Motion Tracking in
  MRI</font>
    </a>
  </h2>
  <font color="black">提案された方法は、2つの異なるデータセットからの心臓MRIデータの2Dスタックでの心筋運動追跡のコンテキストで検証されます。特に、提案された生体力学に基づいた正則化は、変分オートエンコーダ（VAE）を活用して生体力学的にもっともらしい変形の多様体を学習し、バイオメカニカルシミュレーションを再構築することにより、暗黙的にそれらの基本的なプロパティをキャプチャします。画像のレジストレーションは不適切な逆問題であり、解空間での正則化が必要になることがよくあります。 
[要約]提案された方法はバイオメカニクスを学習できる-情報に基づいた正則化。このような方法は心筋運動追跡のコンテキストで検証されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-08">
        <br><font color="black">2020-06-08</font>
      </time>
    </span>
</section>
<!-- paper0: Mining Cross-Image Semantics for Weakly Supervised Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_72.html">
      <font color="black">Mining Cross-Image Semantics for Weakly Supervised Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">画像内の情報に主に焦点を当てた以前の取り組みではなく、包括的なオブジェクトパターンマイニングのための画像間の意味関係の価値に取り組みます。より本質的には、このアルゴリズムは、さまざまなWSSS設定、つまりWSSSの学習を処理する統合フレームワークを提供します（1）正確な画像レベルの監視のみ、（2）追加の単純な単一ラベルデータ、および（3）追加のノイズの多いWebデータ。これは、分類器が画像領域でより多くのオブジェクトパターンとより優れたグラウンドセマンティクスを発見するのに役立ちます。 
[ABSTRACT]これは、オブジェクトのローカリゼーションレベルを学習する最新の方法です。2つのニューラルコアテンションを使用して、クロスイメージのセマンティックの類似点と相違点をキャプチャします。これにより、分類器がより多くのオブジェクトパターンを発見するのに役立ちます。さらに、このアルゴリズムは統合されたフレームワークを提供しますよく異なるwsss設定を処理する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-03">
        <br><font color="black">2020-07-03</font>
      </time>
    </span>
</section>
<!-- paper0: A Convolutional Approach to Vertebrae Detection and Labelling in Whole
  Spine MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_73.html">
      <font color="black">A Convolutional Approach to Vertebrae Detection and Labelling in Whole
  Spine MRI</font>
    </a>
  </h2>
  <font color="black">最後に、腰椎と脊柱全体のMRスキャンで脊柱側弯症の自動検出に使用するこの方法の臨床的適用性を示します。この方法は、さまざまなMRシーケンスの範囲にわたって腰椎、頸部、および胸部のみのスキャンに変更を加えずに適用できます。 ..結果として得られるシステムは、脊椎全体のスキャンの困難な臨床データセットで98.1％の検出率と96.5％の識別率を達成し、腰椎のみのスキャンでの以前のシステムのパフォーマンスに匹敵するか、それを超えます。 
[要約]システムを使用して、椎体の椎骨の角を特定できます。次に、システムを使用して、自己整合的な方法で椎骨のレベルを特定できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: BS4NN: Binarized Spiking Neural Networks with Temporal Coding and
  Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_74.html">
      <font color="black">BS4NN: Binarized Spiking Neural Networks with Temporal Coding and
  Learning</font>
    </a>
  </h2>
  <font color="black">同様の戦略が（非スパイク）2値化ニューラルネットワークをトレーニングするために使用されています。また、BS4NNがこれらの2つのデータセット（それぞれ0.2％と0.9％）で同じアーキテクチャで単純なBNNよりも優れていることを示しました。ディメンション.. 2つの一般的なベンチマークであるMNISTとファッションMNISTでBS4NNを検証し、この種類のネットワークの最先端の精度（それぞれ97.0％と87.3％）を取得しました。重み（それぞれ0.4％と0.7％）。 
[ABSTRACT]これは、データに基づく2セットの重みを使用して行われました。これらには、実際のニューラル重みと、転送パスで使用される符号が含まれます。主な違いは、bs4nnが時間領域で動作することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: CycleGAN with a Blur Kernel for Deconvolution Microscopy: Optimal
  Transport Geometry -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_75.html">
      <font color="black">CycleGAN with a Blur Kernel for Deconvolution Microscopy: Optimal
  Transport Geometry</font>
    </a>
  </h2>
  <font color="black">2つのディープジェネレーターを必要とする従来のcycleGANアプローチとは対照的に、提案されたcycleGANアプローチは、単一のディープジェネレーターと線形ブラーカーネルのみを必要とするため、ネットワークトレーニングの堅牢性と効率が大幅に向上します。アルゴリズムの有効性..残念ながら、CNNアプローチは通常、教師ありトレーニングのために一致する高解像度画像を必要とします。 
[ABSTRACT]畳み込みニューラルネットワーク（cnn）アプローチは、高速で高性能な代替手段として研究されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-26">
        <br><font color="black">2019-08-26</font>
      </time>
    </span>
</section>
<!-- paper0: Labelling imaging datasets on the basis of neuroradiology reports: a
  validation study -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_76.html">
      <font color="black">Labelling imaging datasets on the basis of neuroradiology reports: a
  validation study</font>
    </a>
  </h2>
  <font color="black">ただし、バイナリラベルとは対照的に、より詳細なラベル付けの精度はカテゴリに依存し、この不一致の理由を強調します。正常から異常まで）レポートからの画像のみが非常に正確です。この作業では、専用の深層学習ベースの神経放射線学レポート分類子を構築するプロジェクトの一環として、5000を超えるMRI神経放射線学レポートにラベルを付けた神経放射線科医のチームの経験について。 
[要約]ただし、これまでのところ、このアプローチの有効性について徹底的な調査は行われていません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Robust Re-Identification by Multiple Views Knowledge Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CV/paper_77.html">
      <font color="black">Robust Re-Identification by Multiple Views Knowledge Distillation</font>
    </a>
  </h2>
  <font color="black">人、車両、および動物の再IDに関する徹底的な分析により、質的および量的観点からVKDの特性が調査されます。最近の研究では、ビデオベースのネットワークから画像ベースのネットワークに時間情報を転送することにより、この深刻な劣化に対処しています。結果として、生徒は教師だけでなく、Image-To-Videoの現在の最先端技術よりもはるかに優れています（MARSで6.3％mAP、Duke-Video-ReIdで8.6％、5 VeRi-776の％）。 
[ABSTRACT]トレーニング戦略により、ターゲットオブジェクトのビューに基づいて優れた知識を伝達できます。これにより、学生は現在の最先端の技術を画像からビデオへと大幅に上回ります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Learning Speech Representations from Raw Audio by Joint Audiovisual
  Self-Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CL/paper_0.html">
      <font color="black">Learning Speech Representations from Raw Audio by Joint Audiovisual
  Self-Supervision</font>
    </a>
  </h2>
  <font color="black">音声のみの自己監視（有益な音声属性を予測すること）と視覚的な自己監視（音声から話し顔を生成すること）を組み合わせることにより、生の音声エンコーダをトレーニングします。特に、この方法は完全に監視されたトレーニングよりも優れているため、強力なトレーニングを提供します音声関連タスクの初期化。これにより、オーディオエンコーダーが視覚情報で強化され、エンコーダーは視覚モダリティなしで評価に使用できます。 
[ABSTRACT]このコンセプトは、ビデオアクション認識や音響シーン分類などの一般的なオーディオビジュアルタスクで実証されています。生のオーディオ波形から自己監視型音声表現を学習する方法を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Conversational Recommender Systems via Knowledge Graph based
  Semantic Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CL/paper_1.html">
      <font color="black">Improving Conversational Recommender Systems via Knowledge Graph based
  Semantic Fusion</font>
    </a>
  </h2>
  <font color="black">これらの問題に対処するために、CRSのデータ表現を強化するために、単語指向とエンティティ指向の両方のナレッジグラフ（KG）を組み込み、相互情報の最大化を採用して、単語レベルとエンティティレベルのセマンティックスペースを調整します。 CRSのために作成されましたが、2つの主要な問題がまだ解決されていません。整合されたセマンティック表現に基づいて、正確な推奨を作成するためのKG拡張推奨コンポーネント、および有益なキーワードを生成できるKG拡張ダイアログコンポーネントをさらに開発します。応答テキスト内のエンティティ。 
[ABSTRACT]ソーシャルネットワークサイトcrs.topicsにはトピックのリストが作成され、自然言語表現とユーザー設定の間に意味的なギャップが含まれています。目的は、ユーザー向けの詳細な詳細リストを作成することです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Public discourse and sentiment during the COVID-19 pandemic: using
  Latent Dirichlet Allocation for topic modeling on Twitter -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CL/paper_2.html">
      <font color="black">Public discourse and sentiment during the COVID-19 pandemic: using
  Latent Dirichlet Allocation for topic modeling on Twitter</font>
    </a>
  </h2>
  <font color="black">この研究の目的は、COVID-19に対するTwitterユーザーの言説と心理的反応を理解することです。合計11のトピックが特定され、「確認された症例に関する最新情報」、「COVID-19関連の死亡」など、10のテーマに分類されます。中国以外のケース（全世界）、「韓国でのCOVID-19の発生」、「ニューヨークでの発生の初期の兆候」、「ダイヤモンドプリンセスクルーズ」、「経済への影響」、「予防策」、「当局」、 &quot;サプライチェーン。&quot;。感情分析は、コロナウイルスの未知の性質に対する恐怖がすべてのトピックで支配的であることを示しています。 
[要約]科学者はコロナウイルスに関連する約190万件のツイートを分析します。結果はTwitterで治療や症状に関連するメッセージを明らかにしません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-18">
        <br><font color="black">2020-05-18</font>
      </time>
    </span>
</section>
<!-- paper0: User Intent Inference for Web Search and Conversational Agents -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CL/paper_3.html">
      <font color="black">User Intent Inference for Web Search and Conversational Agents</font>
    </a>
  </h2>
  <font color="black">2番目の研究トピックでは、次の方法で、Web検索インテント予測の既存の最先端の方法をeコマースドメインに拡張する予定です。1）検索クエリのインテントと関連する製品カテゴリを予測する共同学習モデルを開発するそれら、2）新しい隠れたユーザーの意図の発見..これらの研究の結果を活用して、自然言語の理解、クエリのスコープ、クエリの提案、ランキングなどのさまざまなタスクのパフォーマンスを向上させ、ユーザーエクスペリエンスを充実させることができます。すべてモデルは、主要なeコマースサイトの検索エンジンから利用可能な実際のクエリで評価されます。 
[ABSTRACT]検索エンジンは、検索エンジンの意図を検索するユーザーの意図を予測します。これらのモデルは、eコマースサイトの検索エンジンで利用可能な実際のクエリで評価されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-28">
        <br><font color="black">2020-05-28</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Detection of Sexist Statements Commonly Used at the Workplace -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CL/paper_4.html">
      <font color="black">Automatic Detection of Sexist Statements Commonly Used at the Workplace</font>
    </a>
  </h2>
  <font color="black">したがって、「敵意のある」性差別のステートメントがコンテキストに関係なく、モデルにヒントを与えるいくつかの単語に依存する可能性があるため、大量の「敵意のある」性差別を含むデータセットの検出タスクはやや簡単です。以前の研究により、単にTwitterデータの集計に基づいて「敵対的」と「慈悲深い」性差別を区別するための最新のモデル。この論文では、職場だけでなく職場でも発言される可能性が高い性差別ステートメントのデータセットを提示します。最先端の結果を達成できるディープラーニングモデル。 
[要約]ソーシャルメディアは職場よりも匿名であるため、より積極的で「敵対的な」バージョンの性差別に向いている傾向があります。職場やディープラーニングで言われる可能性が高い性差別ステートメントのデータセット最先端の結果を実現できるモデル</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Streaming End-to-End Bilingual ASR Systems with Joint Language
  Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CL/paper_5.html">
      <font color="black">Streaming End-to-End Bilingual ASR Systems with Joint Language
  Identification</font>
    </a>
  </h2>
  <font color="black">入力側では、事前トレーニング済みの音響のみのLID分類器からの埋め込みを使用して、RNN-Tトレーニングと推論をガイドしますが、出力側では、言語ターゲットがASRターゲットと共同でモデル化されます。実験では、英語-スペイン語、バイリンガルジョイントASR-LIDアーキテクチャは、単一言語ASRおよび音響のみのLID精度に一致します。英語-ヒンディー語の（発話内コードの切り替えにより）より困難なケースでは、英語のASRおよびLIDメトリックは低下を示します。 
[ABSTRACT] asrと言語の識別を実行するシステム（lid）が提案されています。これは、米国で話される英語とスペイン語、インドで話される英語とヒンディー語の2つの言語ペアに適用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Language Modeling with Reduced Densities -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CL/paper_6.html">
      <font color="black">Language Modeling with Reduced Densities</font>
    </a>
  </h2>
  <font color="black">カーテンを引き戻すと、割り当ては確率よりも豊富なカテゴリー間の関手であることが示されます。これらの演算子は、これらの式の意味の一部をキャプチャし、正の半定値演算子のロウナー次数の下で、両方の単純な含意を保持します。その中の関連する統計..密度演算子を使用して自然言語で単語、フレーズ、およびより長い表現をモデル化するためのフレームワークを示します。 
[ABSTRACT]正の半定値演算子のloewner順序は、含意の単純な形式と関連する統計の両方を保持します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Best-First Beam Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CL/paper_7.html">
      <font color="black">Best-First Beam Search</font>
    </a>
  </h2>
  <font color="black">最適性（モジュロビームサイズ）を保証するためのスコアリング関数呼び出しの最小数ではありますが、標準のビーム検索と同じ結果セットを返す可能性があるアルゴリズムであるベストファーストビーム検索を提案します。この作業では、その標準を示します。ビーム検索は、多くのデコードタスクにとって計算効率の悪い選択肢です。具体的には、スコアリング関数がシーケンス長の単調関数である場合、他の検索アルゴリズムを使用して、スコアリング関数（ニューラルネットワークなど）の呼び出し回数を減らすことができます。これは、多くの場合、ボトルネックの計算です。 -ファーストビームサーチは、他のスコアリング機能の中でも、長さの正規化と相互情報のデコードで使用できます。 
[ABSTRACT]このジョブのデフォルトのアルゴリズムはビーム検索です。幅の剪定バージョン-最初の検索です。実際には、正確な可能性よりも優れた結果が返されます。これは有益な検索バイアスがあるためです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Adaptive Transformers for Learning Multimodal Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CL/paper_8.html">
      <font color="black">Adaptive Transformers for Learning Multimodal Representations</font>
    </a>
  </h2>
  <font color="black">この作業では、モデルの解釈可能性と計算効率についてさらに学習するために、適応型アプローチを拡張します。さらに、これらのアプローチが、ネットワークが入力シーケンスの複雑さ、さまざまなモダリティのスパース性の設定、およびその他の関連の知覚方法についてさらに学習するのに役立つことを示します現象..これらのアーキテクチャは、多くの場合、過度にパラメータ化されており、大量の計算を必要とします。 
[ABSTRACT]これらのアーキテクチャは、多くの場合、過剰にパラメータ化されており、大量の計算が必要です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-15">
        <br><font color="black">2020-05-15</font>
      </time>
    </span>
</section>
<!-- paper0: Generalizing Tensor Decomposition for N-ary Relational Knowledge Bases -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CL/paper_9.html">
      <font color="black">Generalizing Tensor Decomposition for N-ary Relational Knowledge Bases</font>
    </a>
  </h2>
  <font color="black">既存の負のサンプリング手法は、GETDのn-aryケースにも一般化されています。さらに、GETDはさらに、ベンチマークのバイナリリレーショナルKBデータセットに関する最新の結果を取得します。しかし、ユビキタスn-aryリレーショナルKBよりアリティの高い関係の事実はあまり注目されず、既存の翻訳ベースおよびニューラルネットワークベースのアプローチは、さまざまな関係のモデル化において表現力が弱く、複雑さが高いです。 
[ABSTRACT] tucker分解に基づく基本モデルであるgetdは、n-arymar.itの広範なモデルであり、ベンチマークバイナリの最先端のデータセットに関する最新の結果も含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Analysis of Predictive Coding Models for Phonemic Representation
  Learning in Small Datasets -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CL/paper_10.html">
      <font color="black">Analysis of Predictive Coding Models for Phonemic Representation
  Learning in Small Datasets</font>
    </a>
  </h2>
  <font color="black">私たちの実験は、2つのデータセットで自己回帰損失と音素識別スコアの間に強い相関関係を示しています。さらに、そのようなモデルが効果的な音素特徴学習器であることが示されているにもかかわらず、これらのモデルの予測損失関数の最小化が不明確かどうかは不明ですまた、本研究では、データセットサイズが異なる2つの言語の音素識別タスク（ABXタスク）で、2つの予測コーディングモデル、Autoregressive Predictive CodingおよびContrastive Predictive Codingの動作を調査します。 
[要約] 2つの予測コーディングベースの学習アルゴリズムが文献で提案されていますが、それらがさまざまな言語およびトレーニングデータセットのサイズにどれほど一般化しているかは不明です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Neural Textual Representations for Citation Recommendation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CL/paper_11.html">
      <font color="black">Learning Neural Textual Representations for Citation Recommendation</font>
    </a>
  </h2>
  <font color="black">このため、この論文では、サブモジュラースコアリング関数でシャムおよびトリプレットネットワークとカスケード接続されたドキュメント（Sentence-BERT）のディープシーケンシャル表現を活用する、推奨される新しいアプローチを提案します。結果は、提案されたアプローチが科学文献の急速な成長に伴い、論文に適切な引用を手動で選択することは、ますます困難になり、時間がかかるようになっています。 
[要約]提案されたアプローチは、すべての測定されたメトリックで比較されたすべてのアプローチよりも優れている</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Spatio-Temporal Scene Graphs for Video Dialog -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CL/paper_12.html">
      <font color="black">Spatio-Temporal Scene Graphs for Video Dialog</font>
    </a>
  </h2>
  <font color="black">この目的のために、ビデオ内のきめの細かい情報フローをモデル化する、新しい時空間シーングラフ表現（STSGR）を提案します。これらの視覚的記憶は、他のモダリティと組み合わせられ、新しいセマンティクス制御マルチヘッドシャッフルを使用して質問の埋め込みが行われます。具体的には、入力ビデオシーケンスで、STGSRは（i）すべてのフレームに2ストリームの視覚的およびセマンティックシーングラフを作成します。（ii）ノードとエッジの畳み込み生成を使用してグラフ内推論を行います。視覚的記憶、（iii）グラフ間の集約を適用して、それらの時間的進化をキャプチャします。 
[要約]生成された回答の質に関する人間の評価では、以前の方法と比較して12％改善されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Text-based depression detection on sparse data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CL/paper_13.html">
      <font color="black">Text-based depression detection on sparse data</font>
    </a>
  </h2>
  <font color="black">最初に、単語レベルのテキストベースのうつ病検出に事前トレーニングが役立つことを示します。臨床会話などの疎シナリオはあまり調査されません。調査結果を強化するために、疎データでの多数の独立した実行の平均結果を報告します。 
[ABSTRACT]メインアプローチは、うつ病の重症度とバイナリの健康状態の両方をモデル化することを目的とした、新しいマルチタスク損失関数を使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-08">
        <br><font color="black">2019-04-08</font>
      </time>
    </span>
</section>
<!-- paper0: Working Memory Graphs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CL/paper_14.html">
      <font color="black">Working Memory Graphs</font>
    </a>
  </h2>
  <font color="black">WMGは、Transformerベースのモデルが、観察を因数分解できるRL環境でサンプル効率を劇的に向上させる方法を示しています。私たちは、ワーキングメモリグラフ（WMG）を提示します。観測された状態と再発状態を表すベクトル。この傾向に触発されて、Transformerベースのモデルが逐次意思決定エージェントのパフォーマンスをどのように改善できるかという問題を研究します。 
[ABSTRACT]変圧器-ベースのモデルは視覚的な理由のパフォーマンスを向上させることができます。変圧器の例を評価します-ベースのモデルはそのパフォーマンスを向上させることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-17">
        <br><font color="black">2019-11-17</font>
      </time>
    </span>
</section>
<!-- paper0: KQA Pro: A Large Diagnostic Dataset for Complex Question Answering over
  Knowledge Base -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CL/paper_15.html">
      <font color="black">KQA Pro: A Large Diagnostic Dataset for Complex Question Answering over
  Knowledge Base</font>
    </a>
  </h2>
  <font color="black">SPARQLとプログラムは、推論プロセスをさまざまな方法で描写します。これにより、QA手法の広い範囲に利益をもたらすことができます。統一されたコードベースに貢献し、ベースラインと最先端の技術に対して広範な評価を行います。ブラインドGRUは31.58 \％を取得します、最高のモデルは35.15 \％しか達成せず、人間は97.5 \％を達成しています。これは、ギャップを埋めるための優れた研究の可能性を提供します。 
[ABSTRACT] complex kbqaには、complexの開発を制限する3つの欠点があります。これらには、複雑な質問、sparqls、関数型プログラムが含まれます。質問を生成し、クラウドソーシングによって質問を言い換えます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Research on multi-dimensional end-to-end phrase recognition algorithm
  based on background knowledge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CL/paper_16.html">
      <font color="black">Research on multi-dimensional end-to-end phrase recognition algorithm
  based on background knowledge</font>
    </a>
  </h2>
  <font color="black">これらの問題を解決するために、フレーズウィンドウに基づく注釈ルールが提案され、対応する多次元エンドツーエンドフレーズ認識アルゴリズムが設計されています。現在、教師あり学習に基づくディープエンドツーエンド方法エンティティの認識と依存関係の分析で使用されます。このアルゴリズムは、背景知識を導入するだけでなく、文内のあらゆる種類のネストされたフレーズを認識するだけでなく、フレーズ間の依存関係も認識できます。 
[ABSTRACT]このアノテーションルールは、文を7つのタイプのネストされたフレーズに分割し、フレーズ間の依存関係を示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Audio-Visual Understanding of Passenger Intents for In-Cabin
  Conversational Agents -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CL/paper_17.html">
      <font color="black">Audio-Visual Understanding of Passenger Intents for In-Cabin
  Conversational Agents</font>
    </a>
  </h2>
  <font color="black">マルチモーダルアプローチでインテント検出のパフォーマンスが向上したため、実験結果はテキストのみのベースラインを上回りました。この目標に向けて、マルチモーダル乗客の処理を担当するキャビン内エージェントであるAMIE（Automated-vehicle Multimodal In-cabin Experience）を探索します。 -車両の相互作用..この作業では、車両内外の非言語的/音響的および視覚的な手がかりとともに言語/言語入力を組み込むことにより、車内発話のマルチモーダル理解の利点について説明します。 
[要約]乗客の意図のマルチモーダル理解の利点について説明します。これらには、強化された乗客の意図とナビゲーションシステムが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Massively Multilingual ASR: 50 Languages, 1 Model, 1 Billion Parameters -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/cs.CL/paper_18.html">
      <font color="black">Massively Multilingual ASR: 50 Languages, 1 Model, 1 Billion Parameters</font>
    </a>
  </h2>
  <font color="black">共同モデル、言語入力のある共同モデル、および多頭モデルの単言語ベースラインと比較して、それぞれ20.9％、23％、および28.8％の平均WER相対削減が見られます。私たちの知る限り、これは大規模な多言語ASRの最初の研究です。 50以上の言語と16,000時間以上のオーディオを使用します。低リソース言語での自動音声認識（ASR）パフォーマンスを改善し、全体的に展開を簡略化することを目的として、複数の言語の単一の音響モデルのトレーニングを研究します多様な言語をサポートするASRシステムの例。 
[ABSTRACT] 51言語で広範なベンチマークを実行し、言語ごとに単一のトレーニングデータを使用します。asrモデルの多言語トレーニングにより、低リソース言語での認識入力を改善できることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Learning Speech Representations from Raw Audio by Joint Audiovisual
  Self-Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.AS/paper_0.html">
      <font color="black">Learning Speech Representations from Raw Audio by Joint Audiovisual
  Self-Supervision</font>
    </a>
  </h2>
  <font color="black">音声のみの自己監視（有益な音声属性を予測する）と視覚的な自己監視（音声から会話の顔を生成する）を組み合わせることにより、生の音声エンコーダーをトレーニングします。特に、この方法は完全に監視されたトレーニングよりも優れているため、強力なトレーニングを提供します音声関連タスクの初期化..私たちの方法は、確立された孤立語分類ベンチマークで既存の自己監視オーディオ機能に関して競争力のあるパフォーマンスを達成し、少ないラベルから学習することで他の方法を大幅に上回ります。 
[ABSTRACT]このコンセプトは、ビデオアクション認識や音響シーン分類などの一般的なオーディオビジュアルタスクで実証されています。生のオーディオ波形から自己監視型音声表現を学習する方法を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Audio Inpainting: Revisited and Reweighted -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.AS/paper_1.html">
      <font color="black">Audio Inpainting: Revisited and Reweighted</font>
    </a>
  </h2>
  <font color="black">新しいアイデアは、係数と時間領域の両方で、さまざまなタイプの重み付けに基づいています。私たちの提案は、SNRとODGの両方に関して修復パフォーマンスを向上させることを示しています。スパース性ベースのオーディオの問題に対処します。インペインティング、つまり
[ABSTRACT]オーディオのインペインティングの改善を提案し、そのようなエネルギー損失を補償することを目指します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-08">
        <br><font color="black">2020-01-08</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Sound Event Detection In Domestic Environments Using Sound
  Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.AS/paper_2.html">
      <font color="black">Improving Sound Event Detection In Domestic Environments Using Sound
  Separation</font>
    </a>
  </h2>
  <font color="black">さらに、サウンド分離とサウンドイベント検出の両方で、サウンド分離モデルをサウンドイベント検出データに適合させることの影響を調査します。分離した音源とサウンドイベント検出内の元の混合を組み合わせるさまざまな方法を検討します。サウンドイベント検出の前処理として、サウンド分離を使用することを提案します。 
[要約]音分離モデルは、無料のユニバーサル音分離データセットとdcase 2020タスク4音イベント検出ベースラインでトレーニングされます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Streaming End-to-End Bilingual ASR Systems with Joint Language
  Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.AS/paper_3.html">
      <font color="black">Streaming End-to-End Bilingual ASR Systems with Joint Language
  Identification</font>
    </a>
  </h2>
  <font color="black">提案された方法は、2つの言語ペアに適用されます。米国で話されている英語とスペイン語、およびインドで話されている英語とヒンディー語です。全体的に、ユーザーが言語を動的に切り替えるシナリオでは、提案されたアーキテクチャは実行よりも単純化が期待できます。複数の単一言語ASRモデルとLID分類子を並行して使用します。さらに、音声起動スマートアシスタントシステムでは、ASR出力のダウンストリーム処理にも言語IDが必要です。 
[ABSTRACT] asrと言語の識別を実行するシステム（lid）が提案されています。これは、米国で話される英語とスペイン語、インドで話される英語とヒンディー語の2つの言語ペアに適用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Training Sound Event Detection On A Heterogeneous Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.AS/paper_4.html">
      <font color="black">Training Sound Event Detection On A Heterogeneous Dataset</font>
    </a>
  </h2>
  <font color="black">さまざまなラベリングの粒度を持つことができる、記録されたサウンドスケープと合成サウンドスケープの両方を含む異種データセットでサウンドイベント検出アルゴリズムをトレーニングすることは、いくつかの技術的な選択を必要とするシステムにつながる可能性がある重要なタスクです。DCASE2020タスクの詳細な分析を実行することを提案します。トレーニングに使用されるデータのタイプ、平均教師のパラメーター、または合成サウンドスケープの生成中に適用される変換など、いくつかの側面に関する4つのサウンドイベント検出ベースライン。通常、デフォルトとして使用されるいくつかのパラメーターが表示されます。次善である。 
[ABSTRACT]これらの技術的な選択は、質問されることなく1つのシステムから別のシステムに渡された可能性があります。これらの技術的な決定は、システムのさまざまな部分とともに渡されることがよくあります。これらには、可能な限り分類できる技術的な決定が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Resolution Beta-Divergence NMF for Blind Spectral Unmixing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.AS/paper_5.html">
      <font color="black">Multi-Resolution Beta-Divergence NMF for Blind Spectral Unmixing</font>
    </a>
  </h2>
  <font color="black">多くのNMFベースの方法は、2つの敵対する次元間の解像度のトレードオフの結果であるデータマトリックスを因数分解します。短時間のフーリエ変換であり、周波数分解能と時間分解能の間のトレードオフの結果であり、（2）〜場所ごとの波長データマトリックスが次の数の間のトレードオフであるブラインドハイパースペクトルアンミキシング測定された波長と空間分解能.. MR-$ \ beta $ -NMFは、$ \ beta $ -divergenceに基づいて非負の共同因数分解の形式を実行します。 
[ABSTRACT]非負行列因数分解は標準であり、最先端のテクニックです。mr-$ $ beta $-多様化は非負の共同因数分解の形式です。これらには、2つのオーディオスペクトログラムの共同因数分解が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Graph Random Process for Relational-Thinking-Based Speech
  Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.AS/paper_6.html">
      <font color="black">Deep Graph Random Process for Relational-Thinking-Based Speech
  Recognition</font>
    </a>
  </h2>
  <font color="black">この論文では、知覚を表す確率グラフを無数に生成できるディープグラフランダムプロセス（DGP）と呼ばれるベイジアンノンパラメトリックディープラーニング手法を紹介します。CHiME-2とCHiME-5を含むASRタスクの実験的評価は有効性を示し、私たちの方法の利点..私たちのアプローチは、トレーニング中にリレーショナルデータを使用せずに、発話間の関係を正常に推論することができます。 
[ABSTRACT]会話型自動音声認識（asr）などの現実的な問題では、精神的なプロセスをモデル化することが困難です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-04">
        <br><font color="black">2020-07-04</font>
      </time>
    </span>
</section>
<!-- paper0: COALA: Co-Aligned Autoencoders for Learning Semantically Enriched Audio
  Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.AS/paper_7.html">
      <font color="black">COALA: Co-Aligned Autoencoders for Learning Semantically Enriched Audio
  Representations</font>
    </a>
  </h2>
  <font color="black">埋め込みモデルの品質を評価し、3つの異なるタスク（つまり、サウンドイベントの認識、音楽のジャンルと楽器の分類）での特徴抽出としてのパフォーマンスを測定し、モデルがキャプチャする特性のタイプを調査します。結果は音響の音響的および意味的特性を反映する音声埋め込みモデル。整合は、コントラスト損失を使用して、音声とタグの潜在表現の一致を最大化することによって行われます。 
[要約]埋め込みモデルの品質を評価し、3つの異なるタスクでの特徴抽出としてのパフォーマンスを測定し、モデルがキャプチャする特性のタイプを調査します。また、モデルの特性をキャプチャする機能のタイプもチェックします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
</section>
<!-- paper0: Listen carefully and tell: an audio captioning system based on residual
  learning and gammatone audio representation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.AS/paper_8.html">
      <font color="black">Listen carefully and tell: an audio captioning system based on residual
  learning and gammatone audio representation</font>
    </a>
  </h2>
  <font color="black">エンコーダーフェーズは、さまざまな残余ネットワーク構成を介して実装されます。選択されたオーディオ表現はGammatoneです。デコーダーフェーズ（キャプションを作成）は、リカレントレイヤーと注意メカニズムを使用して実行されます。 
[ABSTRACT]自動音声字幕システムは、音声を入力として受け入れ、信号の字幕としてエクスポートされるため、実装する必要があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-27">
        <br><font color="black">2020-06-27</font>
      </time>
    </span>
</section>
<!-- paper0: Massively Multilingual ASR: 50 Languages, 1 Model, 1 Billion Parameters -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-09/eess.AS/paper_9.html">
      <font color="black">Massively Multilingual ASR: 50 Languages, 1 Model, 1 Billion Parameters</font>
    </a>
  </h2>
  <font color="black">ジョイントモデル、言語入力のあるジョイントモデル、マルチヘッドモデルの単一言語ベースラインと比較して、それぞれ20.9％、23％、28.8％の平均WER相対減少が見られます。51の言語で広範なベンチマークを実行します。言語（100時間から1100時間まで）。私たちの知る限り、これは大規模な多言語ASRを研究する最初の作業であり、50を超える言語と16,000時間を超えるオーディオを網羅しています。 
[ABSTRACT] 51言語で広範なベンチマークを実行し、言語ごとに単一のトレーニングデータを使用します。asrモデルの多言語トレーニングにより、低リソース言語での認識入力を改善できることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
