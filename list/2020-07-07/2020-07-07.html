<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-07-07の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="./index.html"><img src="./images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="./index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="./teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="./contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="./list/newest.html"><font color="white">New Papers</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
eess.IV
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
cs.CV
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
eess.AS
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Temporal Sub-sampling of Audio Feature Sequences for Automated Audio
  Captioning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.SD/paper_0.html">
      <font color="black">Temporal Sub-sampling of Audio Feature Sequences for Automated Audio
  Captioning</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">エンコーダーからの出力として固定長ベクトルを使用するシーケンスツーシーケンス方式を採用し、エンコーダーのRNN間に時間サブサンプリングを適用します。結果は、考慮されるすべてのメトリックの改善を示しています。この作業では、オーディオ入力シーケンスに時間的サブサンプリングを適用することにより、シーケンス間のこの長さの違いを明示的に利用することに焦点を当てたアプローチを示します。 
[ABSTRACT]通常、オーディオキャプション方法はディープニューラルネットワークに依存します（私たち）。この方法は、入力オーディオシーケンスを単語の出力シーケンスにマップすることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Improved Large-margin Softmax Loss for Speaker Diarisation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.SD/paper_1.html">
      <font color="black">Improved Large-margin Softmax Loss for Speaker Diarisation</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">話者ダイアライゼーションシステムは現在、ボトルネックレイヤーの音声セグメントから生成された埋め込みを使用しています。これは、見えない話者を区別するために必要です。差別的な埋め込みを作成します。損失のすべてのハイパーパラメータを統一した方法で使用することにより、ベースラインに対して24.6％の相対的なSER削減に達するさらなる改善が達成されました。 
[ABSTRACT]マージンが大きいソフトマックスを使用すると、話者のエラー率（ser）が大幅に改善されます。オーバーラップをトレーニングし、マージンが異なる単一話者の音声サンプルをトレーニングすることにより、最良の結果が得られ、全体で29.5％のser削減が実現しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br><font color="black">2019-11-10</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Depthwise Separable Convolutions Versus Recurrent Neural Networks for
  Monaural Singing Voice Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.SD/paper_2.html">
      <font color="black">Depthwise Separable Convolutions Versus Recurrent Neural Networks for
  Monaural Singing Voice Separation</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">この論文では、RNNを典型的な畳み込みの軽量で高速なバリアントである深度方向分離可能（DWS）畳み込みに置き換えるユースケースを示します。アブレーション研究を行い、チャネル数の影響と信号対アーチファクト、信号対干渉、および信号対歪み比の標準メトリックを利用することによる、音源分離パフォーマンスに関するDWS-CNNのレイヤー。ニューラルネットワーク、主にリカレントニューラルネットワーク（RNN）を採用。 
[要約] rnnアーキテクチャを採用して、歌声の分離に焦点を当てます。rnnsをdws畳み込み（dws-source）に置き換えます。この方法では、20のみを使用します。rnnアーキテクチャのパラメータ量の57％</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: ResNeXt and Res2Net Structure for Speaker Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.SD/paper_3.html">
      <font color="black">ResNeXt and Res2Net Structure for Speaker Verification</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">このホワイトペーパーでは、スピーカーの検証タスクにおけるResNeXtとRes2Netの2つの新しい構造の有効性を調査します。その標準的なトポロジとモジュール化された設計により、人間によるハイパーパラメータの調整が容易になります。したがって、幅と深さは2つのままです。 ResNetの表現力をさらに向上させる主要な次元。 
[要約] resnextおよびres2netアーキテクチャは新しいシステムに基づいています。モデルの表現能力を向上させるために使用できます。ただし、単に幅または深さを増やすだけでは効率的ではありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Optimal Transport, CycleGAN, and Penalized LS for Unsupervised Learning
  in Inverse Problems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_0.html">
      <font color="black">Optimal Transport, CycleGAN, and Penalized LS for Unsupervised Learning
  in Inverse Problems</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">最適な輸送の定式化の輸送コストとして使用すると、この新しいPLSの定式化は、KantorovichデュアルOTの定式化として、新しいcycleGANアーキテクチャにつながることを示します。監視付きトレーニングが不要である点は似ていますが、アルゴリズムは異なって見えるため、数学これらのアプローチ間の関係は明確ではありません。ペナルティ付き最小二乗（PLS）は、正解項を追加して解を安定させる逆問題を解決する古典的な方法です。 
[要約]新しいcycleganモデルは高度な高度な高度なpls.itに基づいており、監視されていない方法でcycleganを別の場所に輸送する方法を提供します。ただし、監視されたトレーニングはなく、アルゴリズムは異なって見えます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-25">
        <br><font color="black">2019-09-25</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Learning Graph-Convolutional Representations for Point Cloud Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_1.html">
      <font color="black">Learning Graph-Convolutional Representations for Point Cloud Denoising</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">学習に基づく点群処理方法が遭遇する順列不変性の問題にエレガントに対処できるグラフ畳み込み層に基づくディープニューラルネットワークを提案します。特に、面取り測度と品質の面で改善できます。ノイズ除去されたデータから推定できる表面法線。ネットワークは完全にたたみ込みであり、ポイントの高次元の特徴表現間の類似性から近傍グラフを動的に構築することにより、特徴の複雑な階層を構築できます。 
[要約]グラフに基づくネットワーク-たたみ込み層は順列を処理できます-点群処理を構築します。状態を上回ることができます-さまざまなメトリックの最先端の方法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Compressive MR Fingerprinting reconstruction with Neural Proximal
  Gradient iterations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_2.html">
      <font color="black">Compressive MR Fingerprinting reconstruction with Neural Proximal
  Gradient iterations</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">これに対処するために、順方向獲得とブロッホ動的モデルを反復学習メカニズム内に直接組み込んだ学習済みの近接勾配降下フレームワークであるProxNetを提案します。私たちの数値実験は、ProxNetが優れた定量的推論精度とはるかに小さいストレージ要件を達成できることを示しています、および最近のディープラーニングMRFベースラインと同等のランタイムでありながら、辞書マッチングスキームよりもはるかに高速です。コードはhttps://github.com/edongdongchen/PGD-Netでリリースされました。 
[要約] proxnetは、エイリアスと定量的結論にコンパクトな神経近位モデルを採用しています。mrfは、磁気共鳴フィンガープリント（mrf）の問題です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-27">
        <br><font color="black">2020-06-27</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: $S^2$-$cGAN$: Self-Supervised Adversarial Representation Learning for
  Binary Change Detection in Multispectral Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_3.html">
      <font color="black">$S^2$-$cGAN$: Self-Supervised Adversarial Representation Learning for
  Binary Change Detection in Multispectral Images</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">提案された$ S ^ 2 $-$ cGAN $は、変更されていないサンプルの分布のみを生成するようにトレーニングされています。既存のGANベースの方法（敵のトレーニング中に識別器を使用してジェネレーターを監視するだけ）とは異なり、$ S ^ 2 $-$ cGAN $は、ディスクリミネーターの可能性を直接利用して、バイナリCDタスクを解決します。実験結果は、最新のCDメソッドと比較した場合、提案された$ S ^ 2 $-$ cGAN $の有効性を示しています。 
[要約]提案された方法は、敵対的なゲームを通じて変更されていないサンプルの分布を学習することを含みます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Medical Image Segmentation via Unsupervised Convolutional Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_4.html">
      <font color="black">Medical Image Segmentation via Unsupervised Convolutional Neural Network</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">別の設定（半教師あり）では、補助セグメンテーションのグラウンドトゥルースがトレーニング中に使用されます。このホワイトペーパーでは、半教師ありまたは教師なしでトレーニングできる新しい学習ベースのセグメンテーションモデルを示します。単一光子放出コンピューター断層撮影（SPECT）画像のコンテキストで高速かつ高品質の骨セグメンテーションを提供します。 
[ABSTRACT]新しい論文で、半教師付きまたは教師なしでトレーニングできる新しい学習ベースのモデルを紹介します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-28">
        <br><font color="black">2020-01-28</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: BiO-Net: Learning Recurrent Bi-directional Connections for
  Encoder-Decoder Architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_5.html">
      <font color="black">BiO-Net: Learning Recurrent Bi-directional Connections for
  Encoder-Decoder Architecture</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">さまざまな医用画像解析タスクでメソッドを評価した結果、BiO-NetがバニラU-Netや他の最先端のメソッドよりも大幅に優れていることがわかりました。コードはhttps：// githubで入手できます。 .com / tiangexiang / BiO-Net ..以前のU-Netの拡張は、主に既存のビルディングブロックの変更またはパフォーマンス向上のための新しい機能モジュールの開発に焦点を当てていました。 
[要約] u-netの以前の拡張機能は、主に既存のビルディングブロックの変更またはパフォーマンス向上のための新しい機能モジュールの開発に焦点を当ててきました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-01">
        <br><font color="black">2020-07-01</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Coronary Heart Disease Diagnosis Based on Improved Ensemble Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_6.html">
      <font color="black">Coronary Heart Disease Diagnosis Based on Improved Ensemble Learning</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">5およびRIPPERアルゴリズムがメタレベルアルゴリズムとして使用され、Naive Bayesがベースレベルアルゴリズムとして使用されました。 
[ABSTRACT]冠状動脈性心臓病の診断の精度を向上させるために機械学習法が提案されています。方法はアンサンブル学習とカスケード一般化に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Exploiting context dependence for image compression with upsampling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_7.html">
      <font color="black">Exploiting context dependence for image compression with upsampling</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">残りの節約は、最小二乗線形回帰だけを使用して、このラプラス分布の幅をさらに予測することによって得られました。ここに示した単純で安価な一般的な方法は、非可逆画像圧縮におけるDCT係数などのさまざまなタイプのデータにも使用できます。画像圧縮アップサンプリングを使用すると、情報をエンコードして、たとえばFUIFとJPEG XLの違いをエンコードすることにより、画像の解像度を連続的に高めます。 
[ABSTRACT]シンプルな一般的な方法は、さまざまなタイプのデータに使用できます。たとえば、圧縮は平均0ドルでした。rgb画像の場合、393。色変換の強化だけで平均1.69ドルが得られました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: 4D MRI: Robust sorting of free breathing MRI slices for use in
  interventional settings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_8.html">
      <font color="black">4D MRI: Robust sorting of free breathing MRI slices for use in
  interventional settings</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">検索領域は再構成時間を短縮します。方法を検証するために、13人の健康な被験者の合計37の4D MRIが再構成されました。新しい方法とベースライン方法の両方の再構成率と速度の定量的評価が行われました。 
[ABSTRACT]新しい方法は、任意の数の呼吸状態をキャプチャすることです。これは、空間解像度で255 mm x 320 mm x 228 mmのfovをキャプチャします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-04">
        <br><font color="black">2019-10-04</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Automatic semantic segmentation for prediction of tuberculosis using
  lens-free microscopy images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_9.html">
      <font color="black">Automatic semantic segmentation for prediction of tuberculosis using
  lens-free microscopy images</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">したがって、私たちは結核を予測するために収集したデータセットでU-Netネットワークを使用して結核コードの自動セグメンテーションを実行します。結核菌（TB）は結核菌と呼ばれる細菌によって引き起こされ、最も深刻な公衆衛生の1つです。ペルーと世界の問題..このプロジェクトの開発は、MODS法とレンズ不要の顕微鏡を使用して結核の診断を容易にし、自動化することを目的としています。レンズ顕微鏡付き。 
[要約]このプロジェクトの開発はmods法による結核の診断を容易にし、自動化することを目指しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: AutoGAN-Distiller: Searching to Compress Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_10.html">
      <font color="black">AutoGAN-Distiller: Searching to Compress Generative Adversarial Networks</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">AGDは、特別に設計された効率的な検索スペースから始まり、ターゲットの計算リソースの制約を前提として、新しい効率的なジェネレーターのエンドツーエンドのディスカバリーを実行します。代替案.. 2つの代表的なGANタスクでAGDを評価します。画像変換と超解像です。 
[要約]ガンの圧縮に関する研究はまだ初期段階にあります。この研究は、深部圧縮におけるautomlの最近の成功に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Adversarial Uni- and Multi-modal Stream Networks for Multimodal Image
  Registration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_11.html">
      <font color="black">Adversarial Uni- and Multi-modal Stream Networks for Multimodal Image
  Registration</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">画像から画像への変換により、マルチモーダル問題（CTからMRなど）を単峰問題（MRからMRなど）に変換しようとする他の変換ベースの方法とは異なり、変形フィールドを活用します（i）翻訳されたMR画像と（ii）元のCT画像をデュアルストリーム方式で推定し、それらを融合してより良い登録パフォーマンスを実現する方法を自動的に学習します。計算機トモグラフィー（CT）画像間の変形可能な画像登録と磁気共鳴（MR）イメージングは多くの画像誘導療法に不可欠です。.私たちの方法は2つの臨床データセットで評価されており、最先端の伝統的な学習ベースの方法と比較して有望な結果を示しています。 
[ABSTRACT]変形可能な認識方法は、変形可能な画像登録方法を作成するために使用できます。変形可能な画像認識方法を使用する新しい方法に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Constrained Linear Data-feature Mapping for Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_12.html">
      <font color="black">Constrained Linear Data-feature Mapping for Image Classification</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">この論文では、ResNetなどの畳み込みニューラルネットワーク（CNN）を使用した画像分類のための解釈可能な数学モデルとして、制約付き線形データ機能マッピングモデルを提案します。この観点から、技術レベルで詳細な接続を確立します。制約付き線形システムの従来の反復方式とResNetの基本ブロックのアーキテクチャ。これらの接続の下で、パラメータが少なくても、対応する元のモデルとほぼ同じ精度を維持するResNetタイプモデルのいくつかの自然な変更を提案します。 
[ABSTRACT]従来のシステムとresnetの基本ブロックのアーキテクチャとの間に技術レベルでの接続を確立します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-23">
        <br><font color="black">2019-11-23</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: On the Influence of Ageing on Face Morph Attacks: Vulnerability and
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_13.html">
      <font color="black">On the Influence of Ageing on Face Morph Attacks: Vulnerability and
  Detection</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">顔モーフィング攻撃は、国境管理アプリケーションに広く展開されている顔認識システム（FRS）の新しい脆弱性を示しているため、重大な懸念を引き起こしています。生成されたモーフィング画像は、貢献したデータ主体のバイオメトリック特性に対応する同様の視覚特性を示します合成画像に追加し、人間とFRSの両方がそのような攻撃を検出するのを困難にします。この範囲で、公開されているMORPH II顔データセットから派生したエージングを伴う新しいモーフィング顔データセットを導入しました。 MorphAgeデータセット。 
[要約]顔モーフィングプロセスは、複数のデータ主体の画像を使用します。このプロセスは、高品質のモーフィング画像を作成します。データセットには、年齢間隔に基づいて2つのビンがあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Deep Low-rank Prior in Dynamic MR Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_14.html">
      <font color="black">Deep Low-rank Prior in Dynamic MR Imaging</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">プラグアンドプレイの方法では、ネットワークパラダイムを変更せずに他の動的MRニューラルネットワークに簡単に組み込むことができるプラグアンドプレイLRネットワークモジュールを提案します。実験結果は、2つのスキームの両方がさらに質的および量的に関係なく、再構成の結果を改善します。特に、学習可能な低ランクをディープネットワークアーキテクチャにアンローリング方式とプラグアンドプレイ方式でそれぞれ導入するための、2つの新しい明確な方式を提案します。 
[ABSTRACT]これは、動的なmrイメージングで深い低ランクの事前適用が適用された初めての例です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-22">
        <br><font color="black">2020-06-22</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Can Un-trained Neural Networks Compete with Trained Neural Networks at
  Image Reconstruction? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_15.html">
      <font color="black">Can Un-trained Neural Networks Compete with Trained Neural Networks at
  Image Reconstruction?</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">この問題に対処するために、ディープラーニングコミュニティから大きな注目を集めており、専用のトレーニングセットが存在する重要な医療用画像問題である、加速磁気共鳴画像（MRI）を検討します。他のトレーニングされていない方法よりも優れており、最も重要なことには、ディープラーニングベースの再構築方法のベンチマーク用の新しいデータセットであるFastMRIデータセットで、標準のトレーニング済みベースラインであるU-netを使用して、同等のパフォーマンスを実現します。トレーニングを受けていないアーキテクチャを調査して最適化し、その結果、ディープイメージの事前アーキテクチャとディープデコーダのアーキテクチャのバリエーションを提案します。 
[ABSTRACT] cnnsは大量のトレーニング画像でトレーニングされているとcnnsは言います。この成功は、トレーニングされていないニューラルネットワークが問題と競合できるかどうかという問題を提起します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: An Elastic Interaction-Based Loss Function for Medical Image
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_16.html">
      <font color="black">An Elastic Interaction-Based Loss Function for Medical Image
  Segmentation</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">提案された損失の監視下では、予測領域の境界はオブジェクトの境界によって強く引き付けられ、接続されたままになる傾向があります。実験結果は、一般的に使用されるピクセル単位の損失関数と比較して、本手法がかなりの改善を達成できることを示しています（クロスエントロピーとサイコロ損失）、および3つの網膜血管セグメンテーションデータセット、DRIVE、STARE、CHASEDB1での他の最近の損失関数。これにより、これらのモデルがボトルネックになり、医用画像の複雑な構造の高精度を達成できます。 
[ABSTRACT]このメソッドは、データデータdataへのアクセスを取得するために使用されることが期待されています。複数の領域のデータを取得するツールを開発するためにすでに使用されています。このメソッドは、ターゲットに関するさらに多くの情報を取得できる</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Complex Human Action Recognition in Live Videos Using Hybrid FR-DL
  Method -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_17.html">
      <font color="black">Complex Human Action Recognition in Live Videos Using Hybrid FR-DL
  Method</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">さらに、全体の特徴ではなく、代表的なフレームの主要な特徴を抽出します。モデルを特徴削減とディープラーニングに基づくアクション認識方法、またはFR-DLと略します。背景の減算を使用したハイブリッド手法を提案し、 HOG、続いてディープニューラルネットワークと骨格モデリング手法の適用。 
[ABSTRACT]人間の行動のラベル付けは、ビデオシーケンスの動きの外観とパターンに基づいています。ただし、従来の方法と従来のニューラルネットワークでは、ビデオシーケンスの次のフレームでの行動認識予測に情報を使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: A Convolutional Approach to Vertebrae Detection and Labelling in Whole
  Spine MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_18.html">
      <font color="black">A Convolutional Approach to Vertebrae Detection and Labelling in Whole
  Spine MRI</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">最後に、腰椎と脊椎全体のMRスキャンにおける脊柱側弯症の自動検出にこの方法を使用して、この方法の臨床的適用性を示します。脊椎全体のMRIで椎骨を検出および識別するための新しい畳み込み法を提案します。さまざまなMRシーケンスの範囲にわたって、腰部、子宮頸部、胸部のみのスキャンに変更なしで適用されます。 
[要約]システムを使用して、椎体の椎骨の角を特定できます。次に、システムを使用して、自己整合的な方法で椎骨のレベルを特定できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Optimal Transport, CycleGAN, and Penalized LS for Unsupervised Learning
  in Inverse Problems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_0.html">
      <font color="black">Optimal Transport, CycleGAN, and Penalized LS for Unsupervised Learning
  in Inverse Problems</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">この記事では、ミッシングリンクを明らかにするための重要な進歩について説明します。具体的には、ディープラーニングベースのインバースパスを正則化用語として課すことにより、新しいPLSコストを提案します。より少ないモードの折りたたみ動作でターゲット分布を学習するためのGANの最近の拡張。 
[要約]新しいcycleganモデルは高度な高度な高度なpls.itに基づいており、監視されていない方法でcycleganを別の場所に輸送する方法を提供します。ただし、監視されたトレーニングはなく、アルゴリズムは異なって見えます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-25">
        <br><font color="black">2019-09-25</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Learning Graph-Convolutional Representations for Point Cloud Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_1.html">
      <font color="black">Learning Graph-Convolutional Representations for Point Cloud Denoising</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">特に、面取りの測定とノイズ除去されたデータから推定できる表面法線の品質の点で改善できます。順列を優雅に処理できるグラフ畳み込み層に基づくディープニューラルネットワークを提案します。学習ベースの点群処理方法で発生する不変性の問題。ネットワークは完全にたたみ込みであり、点の高次元の特徴表現間の類似性から近傍グラフを動的に作成することにより、特徴の複雑な階層を構築できます。 
[要約]グラフに基づくネットワーク-たたみ込み層は順列を処理できます-点群処理を構築します。状態を上回ることができます-さまざまなメトリックの最先端の方法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Lightweight Temporal Self-Attention for Classifying Satellite Image Time
  Series -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_2.html">
      <font color="black">Lightweight Temporal Self-Attention for Classifying Satellite Image Time
  Series</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">私たちのアプローチは、オープンアクセス衛星画像データセットで他の最先端の時系列分類アルゴリズムよりも優れていますが、使用するパラメーターは大幅に少なく、計算の複雑さも軽減されています。リモートセンシングの時間シーケンスを分類し、Temporal Attention Encoderの変更を提案します。各ヘッドは、高度に専門化された時間的特徴を抽出し、それを順に単一の表現に連結します。 
[ABSTRACT]これは、時間を処理できる効率的な方法のために呼び出されます-地球規模でのシリーズ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-01">
        <br><font color="black">2020-07-01</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: EDSL: An Encoder-Decoder Architecture with Symbol-Level Features for
  Printed Mathematical Expression Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_3.html">
      <font color="black">EDSL: An Encoder-Decoder Architecture with Symbol-Level Features for
  Printed Mathematical Expression Recognition</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">セグメンテーションモジュールを実行することにより、監視されていない方法で画像からすべてのシンボルとその空間情報を識別します。特に、位置補正注意メカニズムを使用して、シンボル間の空間関係をキャプチャします。次に、新しい再構成モジュールを設計して、シンボル分割後のシンボル依存関係。 
[ABSTRACT]これらの方法は、マーの問題を解決するのに最適ではない可能性があります。これらには、検死、インタラクティブな問題解決、学生の分析が含まれます。結果は、edslが92.7 / 2.5パーセントで達成したことを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Closing the Dequantization Gap: PixelCNN as a Single-Layer Flow -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_4.html">
      <font color="black">Closing the Dequantization Gap: PixelCNN as a Single-Layer Flow</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">フロー定式化を使用して、正確な尤度またはその逆量子化下限のいずれかでトレーニングおよび評価されたモデルを比較します。最後に、PixelCNNと非自己回帰結合層で構成される多層フローを研究し、CIFARの最先端の結果を示します-10は、逆量子化でトレーニングされたフローモデルです。このペーパーでは、サブセットフローを紹介します。サブセットフローは、有限ボリュームを扱いやすく変換できるため、離散データの尤度を正確に計算できるフローのクラスです。 
[ABSTRACT]逆量子化は通常、そのようなデータに使用するときに適用され、その結果、尤度の下限推定値が得られます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br><font color="black">2020-02-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Compressive MR Fingerprinting reconstruction with Neural Proximal
  Gradient iterations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_5.html">
      <font color="black">Compressive MR Fingerprinting reconstruction with Neural Proximal
  Gradient iterations</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">私たちの数値実験は、ProxNetが優れた定量的推論精度、はるかに小さいストレージ要件、および最近のディープラーニングMRFベースラインに匹敵するランタイムを達成しながら、辞書マッチングスキームよりもはるかに高速であることを示しています。これに対処するために、ProxNet 、再帰学習メカニズム内に前方取得とブロッホ動的モデルを直接組み込む学習された近位勾配降下フレームワーク。物理的前方モデルに関する予測の一貫性は、逆問題を確実に解決するために極めて重要です。 
[要約] proxnetは、エイリアスと定量的結論にコンパクトな神経近位モデルを採用しています。mrfは、磁気共鳴フィンガープリント（mrf）の問題です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-27">
        <br><font color="black">2020-06-27</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Revealing Stable and Unstable Modes of Generic Denoisers through
  Nonlinear Eigenvalue Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_6.html">
      <font color="black">Revealing Stable and Unstable Modes of Generic Denoisers through
  Nonlinear Eigenvalue Analysis</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">また、ノイズ除去器が強く抑制する補完的で最も不安定なモードを生成する方法も提供します。全変動（TV）を使用して方法を検証し、EPLLノイズ除去器（Zoran-Weiss）でそれを実証します。線形と同様にケース（ローパスフィルター）の場合、このような安定モードは大きな固有値に対応する固有関数であり、大きなピースワイズスムーズ構造によって特徴付けられます。 
[ABSTRACT]ブラックボックスノイズ除去器の出力が入力に比例する画像を見つけようとします。これは、ほとんどの画像処理アルゴリズムを一般的な線形演算子と見なすことができるため、潜在的に広い意味を持ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-12">
        <br><font color="black">2019-09-12</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Medical Image Segmentation via Unsupervised Convolutional Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_7.html">
      <font color="black">Medical Image Segmentation via Unsupervised Convolutional Neural Network</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">具体的には、監視なしの設定では、畳み込みニューラルネットワーク（ConvNet）を介してエッジなしのアクティブ輪郭（ACWE）フレームワークをパラメーター化し、自己監視法を使用してConvNetのパラメーターを最適化します。別の設定（半監視あり） 、補助セグメンテーショングラウンドトゥルースがトレーニング中に使用されます。この方法により、単一光子放出コンピューター断層撮影（SPECT）画像のコンテキストで高速かつ高品質の骨セグメンテーションが提供されることがわかります。 
[ABSTRACT]新しい論文で、半教師付きまたは教師なしでトレーニングできる新しい学習ベースのモデルを紹介します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-28">
        <br><font color="black">2020-01-28</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Understanding and Improving Fast Adversarial Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_8.html">
      <font color="black">Understanding and Improving Fast Adversarial Training</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">（2020）、破滅的な過剰適合を防止せず、そのランダム性自体は重要ではありません。その主な役割は、単に摂動の大きさを減らすことです。さらに、壊滅的な過剰適合は、深く過大なパラメーター化されたネットワークに固有のものではないことを示していますただし、GradAlignでは、より大きな$ \ ell_ \ infty $ -perturbationsにもFGSMトレーニングを正常に適用し、マルチステップの敵対的なトレーニングとのギャップを減らすことができます。 
[要旨] f fgsmは、 `f fg &#39;と呼ばれる新しいメソッドを提案しました。fgsmに加えて、fgsmへのパターンパターンがあります。このメソッドは、新しいパターンの開発に使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Learning to Adapt Structured Output Space for Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_9.html">
      <font color="black">Learning to Adapt Structured Output Space for Semantic Segmentation</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">ラベル付けプロセスは面倒で手間がかかるため、ソースグラウンドトゥルースラベルをターゲットドメインに適応できるアルゴリズムの開発は非常に重要です。適応されたモデルをさらに強化するために、出力空間ドメインを効果的に実行するマルチレベルの敵対的ネットワークを構築しますさまざまな機能レベルでの適応..広範囲にわたる実験とアブレーション研究は、合成から現実へのシナリオや都市間のシナリオなど、さまざまなドメイン適応設定の下で行われます。 
[要約]マッピングプロセスは面倒で手間がかかります。これらのアルゴリズムが情報をターゲットドメインに適合させることができるのは初めてです。これは、情報を適合させる新しい方法を開発するために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-02-28">
        <br><font color="black">2018-02-28</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Dynamic memory to alleviate catastrophic forgetting in continuous
  learning settings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_10.html">
      <font color="black">Dynamic memory to alleviate catastrophic forgetting in continuous
  learning settings</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">実験は、動的メモリが、これらのシフトがいつ発生するかについての明確な知識を必要とせずに、複数のデータシフトがある状況で壊滅的な忘却に対抗することを示しています。この方法は、動的メモリを使用して、多様なトレーニングデータサブセットのリハーサルを容易にし、忘却を軽減します。 2つの異なるスキャナープロトコルと合成分類タスクで取得された日常の臨床CTデータに対する私たちのアプローチ。 
[ABSTRACT] mitのソフトウェア会社は、継続学習マシンの変化のパターンを使用します。このツールは、モデルを使用してソースドメインの目に見えない変化を使用します。2つの異なるスキャナープロトコルと合成分類で取得されたルーチンの臨床ctデータに対するアプローチを評価タスク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: BiO-Net: Learning Recurrent Bi-directional Connections for
  Encoder-Decoder Architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_11.html">
      <font color="black">BiO-Net: Learning Recurrent Bi-directional Connections for
  Encoder-Decoder Architecture</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">私たちのコードはhttps://github.com/tiangexiang/BiO-Net。で入手できます。私たちが提案する双方向スキップ接続は、エンコーダー/デコーダーアーキテクチャーに直接採用して、さまざまなタスクドメインでの機能をさらに強化することができます。さまざまな医用画像分析タスクに関する私たちの方法とその結果は、BiO-NetがバニラU-Netおよび他の最先端の方法よりも大幅に優れていることを示しています。 
[要約] u-netの以前の拡張機能は、主に既存のビルディングブロックの変更またはパフォーマンス向上のための新しい機能モジュールの開発に焦点を当ててきました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-01">
        <br><font color="black">2020-07-01</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: It Is Not the Journey but the Destination: Endpoint Conditioned
  Trajectory Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_12.html">
      <font color="black">It Is Not the Journey but the Destination: Endpoint Conditioned
  Trajectory Prediction</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">PECNetは、スタンフォードドローンの軌道予測ベンチマークで最高19.5％、ETH / UCYベンチマークで最高40.8％の最先端のパフォーマンスを向上させることを示しています。プロジェクトのホームページ：https://karttikeya.github.io/出版物/ htf /。さらに、少数ショットのマルチモーダル軌道予測パフォーマンスを改善するための単純な「切り捨てトリック」を提示します。 
[要旨]柔軟な人間の軌跡を予測するために予測される条件付きネットワーク（pecnet）を提示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-04">
        <br><font color="black">2020-04-04</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: 4D MRI: Robust sorting of free breathing MRI slices for use in
  interventional settings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_13.html">
      <font color="black">4D MRI: Robust sorting of free breathing MRI slices for use in
  interventional settings</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">検索領域は再構成時間を短縮します。13人の健康な被験者の合計37の4D MRIが再構成され、メソッドを検証しました。ナビゲータースライスと検索領域のテンプレート更新を使用して、高速で堅牢な血管断面追跡を行います。 
[ABSTRACT]新しい方法は、任意の数の呼吸状態をキャプチャすることです。これは、空間解像度で255 mm x 320 mm x 228 mmのfovをキャプチャします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-04">
        <br><font color="black">2019-10-04</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Adversarial Ranking Attack and Defense -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_14.html">
      <font color="black">Adversarial Ranking Attack and Defense</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">実験結果は、典型的なディープランキングシステムが攻撃によって効果的に侵害される可能性があることを示しています。さらに、攻撃者の転送可能な普遍的なプロパティは、現実的なブラックボックス攻撃の可能性を示しています。逆に、提案されたすべての攻撃を同時に軽減できる、システムの堅牢性のランク付け。 
[ABSTRACT] dnnの脆弱性-ベースの画像ランキングシステムが未解決のまま-調査済み。システムの堅牢性は、防御策により適度に改善できる</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-26">
        <br><font color="black">2020-02-26</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Automatic semantic segmentation for prediction of tuberculosis using
  lens-free microscopy images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_15.html">
      <font color="black">Automatic semantic segmentation for prediction of tuberculosis using
  lens-free microscopy images</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">したがって、私たちは結核を予測するために収集したデータセットでU-Netネットワークを使用して結核コードの自動セグメンテーションを実行します。結核菌（TB）は結核菌と呼ばれる細菌によって引き起こされ、最も深刻な公衆衛生の1つです。ペルーと世界の問題..私たちの最初の結果は、結核コードの自動セグメンテーションの有望な証拠を示しています。 
[要約]このプロジェクトの開発はmods法による結核の診断を容易にし、自動化することを目指しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Understanding More about Human and Machine Attention in Deep Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_16.html">
      <font color="black">Understanding More about Human and Machine Attention in Deep Neural
  Networks</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">しかし、最近の研究は、人工注意マップが常に一般的な直感と一致するとは限らないことを示しています。人間の視覚システムは、人間の注意として知られる生物学的メカニズムである、迅速な知覚のためにシーンの一部に選択的に対応できます。代表的なバックボーン、有名なアーキテクチャ、対応する実際の人間の視線データ、体系的に実施された大規模な定量的研究、人工的な注意と人間の視覚的注意の間の一貫性を定量化し、いくつかの重要な質問に予備的な回答を与えることにより、既存の人工的な注意メカニズムに対する新しい洞察を提供します人間と人工の注意メカニズムに関連しています。 
[ABSTRACT]人間の注意は、注意駆動型のタスクで意味のある「グラウンドトゥルース」をベンチマークできます。人工的な注意が人間の注意に近ければ近いほど、パフォーマンスは向上します。研究は、ニューラルネットワークがどこに見えるかを説明するのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-20">
        <br><font color="black">2019-06-20</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: NAPPO: Modular and scalable reinforcement learning in pytorch -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_17.html">
      <font color="black">NAPPO: Modular and scalable reinforcement learning in pytorch</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">完全なソースコードが利用可能です。ここでは、シンプルでモジュール化されたパッケージでスケーラブルな近位ポリシー最適化（PPO）実装を提供するRLのpytorchベースのライブラリであるNAPPOを示します。最後に、最新の最高値を取得してNAPPOを紹介します。 Obstacle Tower Unity3Dチャレンジ環境でパフォーマンスをテストします。 
[ABSTRACT] rlアルゴリズムの効率を高めるために新しいメソッドが調査されていますが、コードを使用しています-メソッドの実験を可能にするのに十分な柔軟性のあるベースです。mujocoおよびatari環境での以前の結果を検証します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: In the Wild: From ML Models to Pragmatic ML Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_18.html">
      <font color="black">In the Wild: From ML Models to Pragmatic ML Systems</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">NEDは、過去の設定の制限的な設計決定を緩和することにより、より一般的なパラダイムとなるように設計されています（たとえば、そのような実用的なMLシステムは、現実の世界に固有の開放性と柔軟性に対応できる必要があります。事前定義されたトレーニングおよびテスト段階）。 
[ABSTRACT] nedは、過去の設定の制限的な設計の決定を緩めることにより、より一般的なツールになるように設計されています。これらには、sota自己管理法などのより厳密な学習法が含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: On the Connection between Dynamical Optimal Transport and Functional
  Lifting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_19.html">
      <font color="black">On the Connection between Dynamical Optimal Transport and Functional
  Lifting</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">興味深いことに、このアプローチは、動的最適輸送の理論の一般化として導出できます。確立された連続方程式を制約として課すことは、1次の正則化を伴う変分モデルに対応します。連続方程式を修正することにより、アプローチを拡張することもできます。高次の正則化を持つモデルに。 
[ABSTRACT]シンプルシンプルシンプルシステムは、固定範囲の点ごとの確率測度の空間への埋め込みに基づいています。これらには、可能な限りシンプルに見えるシステムへの埋め込みが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Progressive Cluster Purification for Unsupervised Feature Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_20.html">
      <font color="black">Progressive Cluster Purification for Unsupervised Feature Learning</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">この作業では、プログレッシブクラスター形成中にクラスの一貫性のないサンプルを繰り返し除外することにより、ノイズサンプルの影響をシンプルかつ効果的な方法で軽減する、新しいクラスタリングベースの方法を提案します。適切に設計されたクラスター精製メカニズムにより、さらに、ノイズサンプルをフィルタリングすることでクラスターを精製し、洗練されたクラスターを疑似ラベルとして利用することで、後続の機能学習を容易にします。コードはhttps://github.com/zhangyifei0115/PCPで入手できます。 
[ABSTRACT]「プログレッシブクラスター精製」には、不愉快な大量のデータが含まれます。これらの方法は、完全なクラス境界情報を探索するのに複雑です。これは、各クラスターでの不可避なクラスの一貫性のないサンプルが原因です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Probabilistic Multi-modal Trajectory Prediction with Lane Attention for
  Autonomous Vehicles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_21.html">
      <font color="black">Probabilistic Multi-modal Trajectory Prediction with Lane Attention for
  Autonomous Vehicles</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">この論文では、車線表現のための新しいインスタンス認識表現を提案します。最も重要なのは、生成された各軌跡が不確実性を処理する確率に関連付けられていることです。異なる車線を区別します。 
[要約]提案された方法は、車両の将来の位置を予測するために使用できます。既存の作業のほとんどは、異なる車線を区別しない道路情報を探索するためにラスタライズされたマップを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: AutoGAN-Distiller: Searching to Compress Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_22.html">
      <font color="black">AutoGAN-Distiller: Searching to Compress Generative Adversarial Networks</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">AGDは、特別に設計された効率的な検索スペースから始まり、ターゲットの計算リソースの制約を前提として、新しい効率的なジェネレーターのエンドツーエンドのディスカバリーを実行します。AGDは完全に自動でスタンドアロン（つまり、訓練された弁別器を必要としない）であり、一般的にさまざまなGANモデル..ベルとホイッスルがなければ、AGDは非常に軽量でありながら、競争力のある圧縮モデルを生み出し、既存の代替モデルを大幅に上回ります。 
[要約]ガンの圧縮に関する研究はまだ初期段階にあります。この研究は、深部圧縮におけるautomlの最近の成功に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Non-Volume Preserving-based Feature Fusion Approach to Group-Level
  Expression Recognition on Crowd Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_23.html">
      <font color="black">Non-Volume Preserving-based Feature Fusion Approach to Group-Level
  Expression Recognition on Crowd Videos</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">各ビデオには、3つのレベルの感情カテゴリのラベルが付けられています。個々の顔、人々のグループ、ビデオフレーム全体です。提案されたアプローチで各コンポーネントの堅牢性と有効性を実証するために、3つの実験が行われました。顔の表情を認識するために提案されたEmoNetをベンチマークするAffectNetデータベース。 （ii）提案されたディープフィーチャーレベルのフュージョンメカニズムNVPFをベンチマークするEmotiW2018の評価。 （iii）公的に入手可能なソースから収集された627本のビデオで構成される革新的なグループレベルの群集ビデオ（GECV）データセットで提案されたTNVPFを調べます。グループレベルの感情認識（ER）は、要求として成長している研究分野です。あらゆる規模の群衆を評価するために、セキュリティアリーナとソーシャルメディアの両方に関心が集まっています。 
[ABSTRACT]この作品は、グループを完全に調査することで以前のerの調査を拡張します-群衆の動画でのレベル表現の認識</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-11-28">
        <br><font color="black">2018-11-28</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Constrained Linear Data-feature Mapping for Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_24.html">
      <font color="black">Constrained Linear Data-feature Mapping for Image Classification</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">この観点から、制約付き線形システムの従来の反復方式とResNetの基本ブロックのアーキテクチャとの間の技術レベルで詳細な接続を確立します。この制約付き学習データ機能マッピングの有効性を示すために、いくつかの数値実験が示されていますこれらの接続の下で、ResNetタイプモデルのいくつかの自然な変更を提案します。これにより、パラメーターは少なくなりますが、対応する元のモデルとほぼ同じ精度が維持されます。 
[ABSTRACT]従来のシステムとresnetの基本ブロックのアーキテクチャとの間に技術レベルでの接続を確立します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-23">
        <br><font color="black">2019-11-23</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Tree-Augmented Cross-Modal Encoding for Complex-Query Video Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_25.html">
      <font color="black">Tree-Augmented Cross-Modal Encoding for Complex-Query Video Retrieval</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">大規模なビデオ検索ベンチマークデータセットでの広範な実験は、私たちのアプローチの有効性を示しています。複雑なクエリでのビデオ検索を容易にするために、クエリの言語構造とビデオの時間表現を共同で学習することにより、ツリー拡張クロスモーダルエンコーディング手法を提案します。 ..最近、埋め込みベースのパラダイムが人気のあるアプローチとして登場しました。 
[要約]高速検索システムは、単純なクエリの欠如に基づいています。クエリとビデオを共有の埋め込みスペースにマッピングすることを目的としています。これは、意味的に-類似のテキストとビデオが人気がある場所です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Learning a Domain Classifier Bank for Unsupervised Adaptive Object
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_26.html">
      <font color="black">Learning a Domain Classifier Bank for Unsupervised Adaptive Object
  Detection</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">具体的には、まず平均教師パラダイムを使用して、ラベルのないサンプルの疑似ラベルを生成します。次に、クラスレベルのドメイン分類子を実装し、それらをグループ化します。ドメイン分類子バンクと呼ばれ、各ドメイン分類子が特定のクラス..適応型検出器として提案された細粒度ドメインアライメントメカニズムを使用してベアオブジェクト検出器を組み立て、開発された交差型適応重み付けメカニズムを使用して最適化します。 
[ABSTRACT]最近の技法は、ソースドメインとラベルなしターゲットドメイン間で細かいドメイン機能を調整することによって提案されています。この方法では、特定のクラスの機能と一致するクラスベースのドメイン分類バンクを作成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: EagleEye: Fast Sub-net Evaluation for Efficient Neural Network Pruning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_27.html">
      <font color="black">EagleEye: Fast Sub-net Evaluation for Efficient Neural Network Pruning</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">MobileNet V1のコンパクトモデルの剪定のより困難な実験でさえ、EagleEyeは70.9％の最高精度を達成し、全体で50％の操作（FLOP）を剪定します。EagleEyeは、実験で調査したすべての剪定アルゴリズムよりも優れた剪定パフォーマンスを達成します。 ..このモジュールは、既存の剪定アルゴリズムをプラグインして改善するためにも一般的です。 
[ABSTRACT]多くのアルゴリズムは、さまざまな評価方法を導入することにより、枝刈りされたサブネットのモデルパフォーマンスを予測しようとします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Adversarial T-shirt! Evading Person Detectors in A Physical World -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_28.html">
      <font color="black">Adversarial T-shirt! Evading Person Detectors in A Physical World</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">対照的に、人検出器をだますための最先端の物理的攻撃方法では、18％の攻撃成功率しか達成されません。提案された方法では、デジタル世界と物理世界でそれぞれ74％と57％の攻撃成功率が達成されることを示しています。 YOLOv2 ..知る限りでは、これはTシャツなどの剛体オブジェクトに関する物理的な敵対例を設計するための変形の影響をモデル化した最初の作品です。 
[ABSTRACT]いわゆる物理的な敵対的な例は機能しません。デジタルおよび物理的な世界の人々を対象とするように設計されています。提案された方法は、敵対的な成功率74％および57％を達成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-18">
        <br><font color="black">2019-10-18</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: On the Influence of Ageing on Face Morph Attacks: Vulnerability and
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_29.html">
      <font color="black">On the Influence of Ageing on Face Morph Attacks: Vulnerability and
  Detection</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">この範囲で、私たちはMorphAgeデータセットと呼ばれる、一般に入手可能なMORPH II顔データセットから派生したエージングを使用した新しいモーフィング顔データセットを導入しました。さらに、5つの異なるMorph Attack Detection（MAD）手法を評価して、経年変化による検出性能.. 2つの異なるCOTS FRS（COTS I-CognitecおよびCOTS II-Neurotechnology）を使用して広範な実験を行い、経年変化による脆弱性を定量化します。 
[要約]顔モーフィングプロセスは、複数のデータ主体の画像を使用します。このプロセスは、高品質のモーフィング画像を作成します。データセットには、年齢間隔に基づいて2つのビンがあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Traffic Agent Trajectory Prediction Using Social Convolution and
  Attention Mechanism -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_30.html">
      <font color="black">Traffic Agent Trajectory Prediction Using Social Convolution and
  Attention Mechanism</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">軌道シーケンスが与えられると、LSTMネットワークは最初にすべてのエージェントの特徴を抽出するために利用され、それに基づいてアテンションマスクとソーシャルマップが形成されます。次に、アテンションマスクとソーシャルマップが融合されてフュージョンフィーチャマップが取得されます。フュージョン機能表現を取得するためにソーシャルコンボリューションによって処理されます。可変長LSTMを使用すると、センシングスコープ内のエージェントの数が交通シーンで非常に動的であるケースを処理できるようになります。 
[ABSTRACT]たとえば、ターゲットエージェントの履歴トラジェクトリをアテンションマスクとしてエンコードし、ソーシャルマップを作成します。フュージョンフィーチャーマップは、ソーシャルコンボリューションによって処理され、フュージョンフィーチャー表現を取得します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Deep Low-rank Prior in Dynamic MR Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_31.html">
      <font color="black">Deep Low-rank Prior in Dynamic MR Imaging</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">プラグアンドプレイの方法では、ネットワークパラダイムを変更せずに他の動的MRニューラルネットワークに簡単に組み込むことができるプラグアンドプレイLRネットワークモジュールを提案します。動的MRイメージングで深い低ランクの事前計算が適用された時間。この論文では、学習された特異値しきい値処理（Learned-SVT）操作が、動的MRイメージングで深い低ランクの事前計算を探索して再構成結果を改善するために提案されています。 。 
[ABSTRACT]これは、動的なmrイメージングで深い低ランクの事前適用が適用された初めての例です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-22">
        <br><font color="black">2020-06-22</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: TLIO: Tight Learned Inertial Odometry -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_32.html">
      <font color="black">TLIO: Tight Learned Inertial Odometry</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">このペーパーは、3D変位推定とその不確実性を後退させるネットワークを示し、相対状態測定を確率的クローニングEKFにしっかりと融合して、ポーズ、速度、センサーバイアスを解決する機能を提供します。ただし、測定の統合はセンサーに敏感ですバイアスとノイズにより、数秒以内に大きなドリフトが発生します。（IONet）は、訓練されたニューラルネットワークを使用して、IMUデータのセグメントから正確な2D変位推定を取得し、それらを連結することで適切な位置推定を取得する機能を示しました。 
[ABSTRACT]ストラップダウンimu測定は、imu運動学的運動モデルに基づいて相対的な状態推定を提供します。ヘッドセットからの歩行者データでトレーニングされたネットワークは、ハマグリと不確実性を生成する可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Pedestrian Detection: The Elephant In The Room -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_33.html">
      <font color="black">Pedestrian Detection: The Elephant In The Room</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">CityPersonsデータセットのリーズナブル/ヘビーサブセットで以前の最新技術を1.3％/ 1.7％改善し、Caltechでログ平均ミス率（MR ^ 2）ポイントを罰金なしで1.8％/ 14.9％改善します。 -テストセットのチューニング..さらに、プログレッシブトレーニングパイプラインが自動運転指向の検出器に適していることがわかります。この傾向には2つの理由があることを示しています。 
[ABSTRACT]既存の状態-最先端の歩行者検出器は、あるデータセットから別のデータセットへの一般化が不十分です。直接的なデータセット間評価では、汎用オブジェクト検出器がうまく機能するという懸念もあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-19">
        <br><font color="black">2020-03-19</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Joint learning of Social Groups, Individuals Action and Sub-group
  Activities in Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_34.html">
      <font color="black">Joint learning of Social Groups, Individuals Action and Sub-group
  Activities in Videos</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">ビデオストリームから人間の活動を理解するための最新のソリューションは、タスクを時空間問題として定式化します。この問題は、シーン内のすべての個人の共同位置特定と、時間の経過に伴う彼らの行動またはグループ活動の分類を必要とします。主な貢献i）私たちは、社会的課題のためのエンドツーエンドのトレーニング可能なフレームワークを提案します。 ii）私たちの提案する方法は、従来のグループアクティビティ認識タスクに広く採用されている2つのベンチマーク（シーンの個人が単一グループを形成し、シーンの単一グループアクティビティラベルを予測する）に最先端の結果を設定します。 iii）既存のグループアクティビティデータセットに新しい注釈を導入し、それをソーシャルタスクに転用します。人々をソーシャルグループと呼ぶサブグループに分割するのが最善のシナリオがあり、各ソーシャルグループは別の社会活動に従事。 
[ABSTRACT]ソーシャルタスクは、サブグループに分割するのが最適な人々によって提案されます。これは、ソーシャルグループと呼ばれ、各ソーシャルグループは異なるソーシャルアクティビティに従事している可能性があります。従来のグループ活動認識タスクに採用されたベンチマーク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Can Un-trained Neural Networks Compete with Trained Neural Networks at
  Image Reconstruction? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_35.html">
      <font color="black">Can Un-trained Neural Networks Compete with Trained Neural Networks at
  Image Reconstruction?</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">この問題に対処するために、ディープラーニングコミュニティから大きな注目を集めており、専用のトレーニングセットが存在する重要な医療用画像問題である、加速磁気共鳴画像（MRI）を検討します。アーキテクチャ、そして結果として、ディープイメージの事前アーキテクチャとディープデコーダのアーキテクチャのバリエーションを提案します。この成功は、訓練されていないニューラルネットワークが訓練されたニューラルネットワークと実際のイメージングタスクを競うことができるかどうかという問題を提起します。 
[ABSTRACT] cnnsは大量のトレーニング画像でトレーニングされているとcnnsは言います。この成功は、トレーニングされていないニューラルネットワークが問題と競合できるかどうかという問題を提起します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: An Elastic Interaction-Based Loss Function for Medical Image
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_36.html">
      <font color="black">An Elastic Interaction-Based Loss Function for Medical Image
  Segmentation</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">提案された損失の監視下では、予測領域の境界はオブジェクトの境界に強く引き付けられ、接続されたままになる傾向があります。このホワイトペーパーでは、長距離弾性相互作用ベースのトレーニング戦略を導入することでこの問題に対処しています。この戦略では、たたみ込みニューラルネットワーク（CNN）は、予測領域の境界と実際のオブジェクトの境界との間の弾性相互作用エネルギーのガイダンスの下でターゲット領域を学習します。 
[ABSTRACT]このメソッドは、データデータdataへのアクセスを取得するために使用されることが期待されています。複数の領域のデータを取得するツールを開発するためにすでに使用されています。このメソッドは、ターゲットに関するさらに多くの情報を取得できる</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Learning Motion Flows for Semi-supervised Instrument Segmentation from
  Robotic Surgical Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_37.html">
      <font color="black">Learning Motion Flows for Semi-supervised Instrument Segmentation from
  Robotic Surgical Video</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">ラベル付けされていないフレームを個別に使用するほとんどの以前の方法とは異なり、時間ダイナミクスを活用してセグメンテーション拡張のモーションフローを賢く学習するデュアルモーションベースの方法を提案します。まず、フロープレディクターを設計して、現在のラベル付きフレーム..高速機器の動きを考慮して、フロー補償器をさらに導入し、新しいサイクル学習戦略を使用して、連続フレーム内の中間の動きを推定します。 
[ABSTRACT]メソッドは、最先端の半教師付きメソッドを大幅に上回っており、2つのタスクで完全に教師付きのトレーニングを超えています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Toward unsupervised, multi-object discovery in large-scale image
  collections -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_38.html">
      <font color="black">Toward unsupervised, multi-object discovery in large-scale image
  collections</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">（2）提案の固有の階層構造を、〜\ cite {Vo2019UnsupOptim}のオブジェクト検出へのアプローチの効果的な正則化子として活用し、そのパフォーマンスを向上させて、いくつかの標準的なベンチマークで最先端の技術を大幅に改善します。（3）画像コレクション全体を使用して描写するオブジェクトを発見する前に、小さなランダムな画像セットを使用して有望な提案を選択する2段階の戦略を採用し、初めて（私たちの知る限り）発見に取り組むことができます最大20,000画像のデータセットを構成する各画像の複数のオブジェクトの数、既存の方法と比較して5倍以上の増加、真の大規模な教師なし画像解釈への最初のステップ..}〜\ cite {Vo2019UnsupOptim}いくつかの重要な新奇性：（1）他の競合手法よりもグラウンドトゥルースオブジェクトとの大幅に高いオーバーラップを実現する、新しい顕著性ベースの領域提案アルゴリズムを提案します。 
[ABSTRACT] cnnが新しいメソッドとチームを組んだのはこれが初めてです。2つの監視された戦略を使用して、複数のオブジェクトを削除します。真の大規模な監視されていない画像解釈への最初のステップです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Geometric Attention for Prediction of Differential Properties in 3D
  Point Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_39.html">
      <font color="black">Geometric Attention for Prediction of Differential Properties in 3D
  Point Clouds</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">法線ベクトルの予測と特徴線の抽出に関するいくつかの実験により、提案された手法の有用性を確立します。離散3Dデータ表現における微分幾何量の推定は、形状処理パイプラインの重要なステップの1つです。具体的には、生の点群から法線とシャープな計画線を推定すると、メッシュの品質が向上し、より正確な表面再構成手法を使用できるようになります。 
[要約]合成的に現実的な幾何学的情報を点群で使用できます。この研究の結果は生の点群で開発されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Deep Learning for Anomaly Detection: A Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_40.html">
      <font color="black">Deep Learning for Anomaly Detection: A Review</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">このホワイトペーパーでは、検出方法の包括的な分類法を使用した深部異常検出の研究をレビューし、3つの高レベルのカテゴリと11の細かいカテゴリの方法の進歩をカバーしています。主な直観、目的関数、根本的な仮定、利点、および欠点、および前述の課題への対処方法について話し合います。高度なアプローチを必要とする独特の問題の複雑さと課題がまだいくつかあります。 
[要約]ディープラーニングにより異常検出が可能になったことは重要な方向性として浮上しています。ディープラーニングにより異常検出が可能になりました。つまり、ディープイノベーションが数十年にわたってトピックになっています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: A Convolutional Approach to Vertebrae Detection and Labelling in Whole
  Spine MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_41.html">
      <font color="black">A Convolutional Approach to Vertebrae Detection and Labelling in Whole
  Spine MRI</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">最後に、腰椎および脊椎全体のMRスキャンで脊柱側弯症の自動検出に使用するこの方法の臨床的適用性を示します。この方法は、さまざまなMRシーケンスの範囲にわたって腰椎、頸部、および胸部のみのスキャンに変更なしで適用できます。 ..脊椎全体のMRIで椎骨を検出および識別するための新しい畳み込み法を提案します。 
[要約]システムを使用して、椎体の椎骨の角を特定できます。次に、システムを使用して、自己整合的な方法で椎骨のレベルを特定できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: TableBank: A Benchmark Dataset for Table Detection and Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_42.html">
      <font color="black">TableBank: A Benchmark Dataset for Table Detection and Recognition</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">417Kの高品質のラベル付きテーブルを含むTableBankを使用して、ディープニューラルネットワークを備えた最先端のモデルを使用していくつかの強力なベースラインを構築します。タスク.. TableBankを紹介します。これは、インターネット上のWordおよびLatexドキュメントからの新しい弱い監視機能で構築された新しい画像ベースのテーブル検出および認識データセットです。 
[ABSTRACT]テーブルバンクを一般公開し、より深い学習技術を強化できることを願っています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-03-05">
        <br><font color="black">2019-03-05</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Federated Visual Classification with Real-World Data Distribution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_43.html">
      <font color="black">Federated Visual Classification with Real-World Data Distribution</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">そのために、種とランドマークの分類用に2つの新しい大規模データセットを導入し、実際のエッジ学習シナリオをシミュレートする現実的なユーザーごとのデータ分割を行います。データセットはオンラインで利用可能です。また、2つの新しいアルゴリズム（ FedVC、FedIR）をクライアントプールでインテリジェントにリサンプリングして再重み付けし、トレーニングの精度と安定性を大幅に向上させます。 
[ABSTRACT]データセンターのデータによると、ソースのデータは通常iidから遠く離れています。また、クライアントプールでインテリジェントにリサンプリングおよび再重み付けする2つの新しいアルゴリズムを開発し、トレーニングの精度と安定性を大幅に改善しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br><font color="black">2020-03-18</font>
      </time>
    </span>
  </h3>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Crossing Variational Autoencoders for Answer Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_0.html">
      <font color="black">Crossing Variational Autoencoders for Answer Retrieval</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">この作業では、アラインメント付きの質問を生成し、アラインメントされた質問を使用して回答を生成することにより、変分オートエンコーダーをクロスすることを提案します。実験により、この方法がSQuADの最先端の回答検索方法よりも優れていることが示されています。配置と質問/回答のセマンティクスは、表現を学習するための2つの重要なシグナルです。 
[ABSTRACT]自動トラックまたは自動エンコーダを学習することは、回答を見つけるための重要な要素です。現在の方法は、二重回答の回答で意味表現を学習しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br><font color="black">2020-05-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Improving Non-autoregressive Neural Machine Translation with Monolingual
  Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_1.html">
      <font color="black">Improving Non-autoregressive Neural Machine Translation with Monolingual
  Data</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">強力なNARベースラインに加えて、WMT14 En-DeおよびWMT16 En-Roニュース翻訳タスクに関する実験結果は、単一言語のデータ拡張が一貫してNARモデルのパフォーマンスを向上させ、教師のARモデルのパフォーマンスに近づき、同等以上の結果をもたらすことを確認しています文献で最も優れた非反復NARメソッドよりも結果が高く、トレーニングプロセスでの過剰適合を減らすのに役立ちます。非自己回帰（NAR）ニューラル機械翻訳は、通常、自己回帰（AR）モデルからの知識蒸留によって行われます。このフレームワークでは、大規模な単一言語コーパスを活用して、NARモデルのパフォーマンスを向上させ、過剰適合を防止しながらARモデルの汎化能力を転送することを目標としています。 
[ABSTRACT] arモデルのパフォーマンスは多数の剖検と比較されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-02">
        <br><font color="black">2020-05-02</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Bilingual Dictionary Based Neural Machine Translation without Using
  Parallel Sentences -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_2.html">
      <font color="black">Bilingual Dictionary Based Neural Machine Translation without Using
  Parallel Sentences</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">ATは、バイリンガル辞書を使用して、ソース言語とターゲット言語の間のギャップを埋めるためのアンカーポイントを確立します。さまざまな言語のペアでの実験により、辞書ベースの単語ごとの翻訳、辞書を含むさまざまなベースラインよりもアプローチが大幅に優れていることが示されています。教師ありクロスリンガル単語埋め込み変換、教師なしMT.。タスクに取り組むためのアンカートレーニング（AT）を提案します。 
[要約]我々は、mtシステムが対訳辞書と大規模な単言語コーパスを使用してどの程度の可能性を達成できるかを確認するタスクを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Improved Large-margin Softmax Loss for Speaker Diarisation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_3.html">
      <font color="black">Improved Large-margin Softmax Loss for Speaker Diarisation</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">統一された方法で損失のすべてのハイパーパラメーターを使用することにより、ベースラインに対して24.6％の相対的なSER削減に到達するさらなる改善が達成されました。最後に、重複するスピーチの影響に対抗するために、負の重複する音声が差別的な埋め込みの作成に及ぼす影響。AMI会議コーパスでの実験により、マージンが大きいソフトマックスを使用すると、話者の誤り率（SER）が大幅に向上することが示されています。 
[ABSTRACT]マージンが大きいソフトマックスを使用すると、話者のエラー率（ser）が大幅に改善されます。オーバーラップをトレーニングし、マージンが異なる単一話者の音声サンプルをトレーニングすることにより、最良の結果が得られ、全体で29.5％のser削減が実現しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br><font color="black">2019-11-10</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: TriggerNER: Learning with Entity Triggers as Explanations for Named
  Entity Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_4.html">
      <font color="black">TriggerNER: Learning with Entity Triggers as Explanations for Named
  Entity Recognition</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">このペーパーでは、「エンティティトリガー」を紹介します。これは、NERモデルのラベル効率の良い学習を促進するための人間による説明の効果的なプロキシです。2つのよく研究されたNERデータセットに対して14kエンティティトリガーをクラウドソーシングしました。トリガー注釈付き文の％は、従来の注釈付き文の70％を使用した場合と同等のパフォーマンスになります。 
[要約]提案されたモデルであるトリガーマッチングネットワークは、文章内のオブジェクトを人々が認識できるようにすることを目的としています。コスト効果の高い方法で監督を提供することが可能です。人間が文章内のエンティティを認識する方法を説明するのに役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br><font color="black">2020-04-16</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Relevance Transformer: Generating Concise Code Snippets with Relevance
  Feedback -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_5.html">
      <font color="black">Relevance Transformer: Generating Concise Code Snippets with Relevance
  Feedback</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">Django、Hearthstone、CoNaLaなど、コード生成用の複数の標準ベンチマークデータセットで実験を行います。RelevanceTransformerモデルは、Transformerベースのアーキテクチャによるコード生成の可能性を示し、推論中に疑似関連性フィードバックを組み込む方法を紹介します。結果は、BLEU評価に基づいた最先端の方法に対する改善を示しています。 
[要約]新世代のコード駆動型ツールが多くのideに組み込まれています。結果は、ブルー評価の使用のためのアプリケーションのモデルを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: TICO-19: the Translation Initiative for Covid-19 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_6.html">
      <font color="black">TICO-19: the Translation Initiative for Covid-19</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">チームは9つのリソースの多い「ピボット」言語に加えて、リソースの少ない26言語、特にアフリカ、南アジア、東南アジアの言語をターゲットにしています。これらの言語の人口はウイルスの蔓延に対して最も脆弱な可能性があります。 。同じデータは、表示されているすべての言語に翻訳されます。つまり、テストまたは開発は、セット内のどの言語の組み合わせでも行うことができます。COVID-19パンデミックは、1世紀以上にわたって世界を襲った最悪のパンデミックです。 
[ABSTRACT]チームは26のリソースの少ない言語をターゲットにしています。これらには、9つの高および「ピボット」言語を含む高「ピボット」言語が含まれます。これには、アフリカ、南アジア、および東南アジアの言語が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-03">
        <br><font color="black">2020-07-03</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: LMVE at SemEval-2020 Task 4: Commonsense Validation and Explanation
  using Pretraining Language Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_7.html">
      <font color="black">LMVE at SemEval-2020 Task 4: Commonsense Validation and Explanation
  using Pretraining Language Model</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">私たちのシステムの精度スコアは、公式テストセットでは95.6 / 94.9で、評価後リーダーボードでは7 $ ^ {th} $ / 2 $ ^ {nd} $です。このペーパーでは、SemEvalのサブタスクaおよびbへの提出について説明します。 -2020タスク4 ..サブタスクbについて、ヒント文メカニズムによって拡張された複数選択モデルを使用して、ステートメントが常識に反する理由について、与えられたオプションから理由を選択します。 
[ABSTRACT] subtasd aの場合、albertベースのモデルを使用して、2つのステートメント候補から常識ステートメントを抽出します。パフォーマンスの向上に役立つサブタスク間の新しい転移学習戦略を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Reflection-based Word Attribute Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_8.html">
      <font color="black">Reflection-based Word Attribute Transfer</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">実験結果は、提案された方法が、ターゲット属性を持たない単語を変更せずに、指定された単語の単語属性を転送できることを示しています。しばしば、キング-男性+女性=クイーンなどの類推関係を表す単語の埋め込みを使用できます。性別を含む単語の属性を変更します。ただし、そのような知識の開発は、単語と属性にとって非常にコストがかかります。 
[ABSTRACT]この作品では、王は男性であるという知識に基づいて女性を差し引きます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Learning Spoken Language Representations with Neural Lattice Language
  Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_9.html">
      <font color="black">Learning Spoken Language Representations with Neural Lattice Language
  Modeling</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">意図検出と対話行動認識データセットの実験は、提案された方法が音声入力で評価された場合、一貫して強力なベースラインよりも優れていることを示しています。訓練された言語モデルにより、多くのNLPタスクが大幅に改善されました。 
[要約]私たちは、音声言語理解タスクに文脈化された表現を提供するために神経格子言語モデルをトレーニングするフレームワークを提案します。提案された方法は、音声入力で評価した場合、一貫して強力なベースラインよりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: A Broad-Coverage Deep Semantic Lexicon for Verbs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_10.html">
      <font color="black">A Broad-Coverage Deep Semantic Lexicon for Verbs</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">手動で作成されたレキシコンとオントロジー、新しいオントロジーの概念と語彙のエントリからのブートストラップは、セマンティックロールの優先順位と含意公理とともに、辞書の定義と例の解析から複数の制約を組み合わせることによって自動的に導出されます。COLLIE-Vは一般公開されています。さまざまな次元に沿って手法の精度を評価し、新しい概念と語彙のエントリを導出する際に高い精度を得ることができました。 
[ABSTRACT] verb.itの深い字句リソースであるcollie-vを開発しました。既存のリソースと一致するか、それを超えるワードネットとアイデアのカバレッジを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Hinting Semantic Parsing with Statistical Word Sense Disambiguation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_11.html">
      <font color="black">Hinting Semantic Parsing with Statistical Word Sense Disambiguation</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">セマンティックパーシングのタスクは、発話を論理形式のグラフに変換することで近似できます。ここで、エッジはセマンティックロールを表し、ノードは単語の意味を表します。この作業では、統計セマンティックパーサーをヒントにして、結果の論理形式の健全性を維持しながら、より適切なセマンティックタイプの割り当てを生成します。Fスコアで最大10.5％の改善が見られますが、この改善は解析の構造的整合性を犠牲にすることになります
[要約]結果の表現は感覚の意味を捉えたものでなければなりません。ただし、この改善は解析の構造的完全性を犠牲にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-29">
        <br><font color="black">2020-06-29</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: PLATO-2: Towards Building an Open-Domain Chatbot via Curriculum Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_12.html">
      <font color="black">PLATO-2: Towards Building an Open-Domain Chatbot via Curriculum Learning</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">最初の段階では、1対1マッピングの簡略化されたフレームワークの下で応答生成を学習するために、粗粒度生成モデルがトレーニングされます。PLATO-2は、中国語と英語の両方のデータでトレーニングされ、その有効性と優位性は包括的な評価、新しい最先端の結果の達成..高品質のオープンドメインチャットボットを構築するために、カリキュラム学習によるPLATO-2の効果的なトレーニングプロセスを紹介します。 
[要約]学習プロセスには2つの段階があります。1つの段階は、きめの細かい生成モデルと評価モデルです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br><font color="black">2020-06-30</font>
      </time>
    </span>
  </h3>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Revisiting Representation Learning for Singing Voice Separation with
  Sinkhorn Distances -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.AS/paper_0.html">
      <font color="black">Revisiting Representation Learning for Singing Voice Separation with
  Sinkhorn Distances</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">この作業では、歌声分離のタスクに焦点を当てた、音声表現の教師なし学習の方法を示します。エントロピー正則化の強度を上げることにより、混合信号の学習表現は、ほぼ完全に相加的で明確に構造化されたソースで構成されます。 。私たちは、プロが制作した音楽録音の無料で利用可能なMUSDB18データセットでメソッドを評価し、エントロピー正則化の強度が小さいシンクホーン距離が、情報に基づく歌声分離のパフォーマンスをわずかに改善していることを示しています。 
[ABSTRACT]時間の表現を学習するために以前に提案された方法に基づいて構築します-ドメインの音楽信号を再パロイジングオートエンコーダーで</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Temporal Sub-sampling of Audio Feature Sequences for Automated Audio
  Captioning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.AS/paper_1.html">
      <font color="black">Temporal Sub-sampling of Audio Feature Sequences for Automated Audio
  Captioning</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">エンコーダーからの出力として固定長ベクトルを使用するシーケンスツーシーケンス方式を採用し、エンコーダーのRNN間に時間サブサンプリングを適用します。結果は、考慮されるすべてのメトリックの改善を示しています。キャプション。 
[ABSTRACT]通常、オーディオキャプション方法はディープニューラルネットワークに依存します（私たち）。この方法は、入力オーディオシーケンスを単語の出力シーケンスにマップすることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Improved Large-margin Softmax Loss for Speaker Diarisation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.AS/paper_2.html">
      <font color="black">Improved Large-margin Softmax Loss for Speaker Diarisation</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">統一された方法で損失のすべてのハイパーパラメーターを使用することにより、ベースラインに対して24.6％の相対的なSER削減に到達するさらなる改善が達成されました。最後に、重複するスピーチの影響に対抗するために、負の重なり合う音声が弁別的な埋め込みの作成に及ぼす影響。したがって、このホワイトペーパーでは、ダイアライゼーションのためのスピーカーの埋め込みの品質を向上させるために、近似を行わずにマージンの大きいソフトマックス損失への一般的なアプローチを紹介します。 
[ABSTRACT]マージンが大きいソフトマックスを使用すると、話者のエラー率（ser）が大幅に改善されます。オーバーラップをトレーニングし、マージンが異なる単一話者の音声サンプルをトレーニングすることにより、最良の結果が得られ、全体で29.5％のser削減が実現しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br><font color="black">2019-11-10</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: Depthwise Separable Convolutions Versus Recurrent Neural Networks for
  Monaural Singing Voice Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.AS/paper_3.html">
      <font color="black">Depthwise Separable Convolutions Versus Recurrent Neural Networks for
  Monaural Singing Voice Separation</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">信号対アーチファクト、信号対干渉、信号対歪みの標準メトリックを利用して、アブレーション研究を実施し、DWS-CNNのチャネルとレイヤーの数が信号源分離性能に及ぼす影響を調べます比率..私たちは、RNNアーキテクチャを採用した歌声の分離に焦点を当て、RNNをDWS畳み込み（DWS-CNN）に置き換えます。結果は、RNNをDWS-CNNに置き換えることにより、1.20、0.06、0.37の改善が得られることを示しています。それぞれ、dB、RNNアーキテクチャのパラメーター量の20.57％のみを使用しています。 
[要約] rnnアーキテクチャを採用して、歌声の分離に焦点を当てます。rnnsをdws畳み込み（dws-source）に置き換えます。この方法では、20のみを使用します。rnnアーキテクチャのパラメータ量の57％</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
<!-- paper0: ResNeXt and Res2Net Structure for Speaker Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.AS/paper_4.html">
      <font color="black">ResNeXt and Res2Net Structure for Speaker Verification</font>
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      <font color="black">その標準的なトポロジーとモジュール化された設計により、ハイパーパラメーターチューニングに対する人間の労力が軽減されます。したがって、ResNetの表現力をさらに向上させるために、幅と深さは2つの主要な次元として残されます。それぞれスケール。 
[要約] resnextおよびres2netアーキテクチャは新しいシステムに基づいています。モデルの表現能力を向上させるために使用できます。ただし、単に幅または深さを増やすだけでは効率的ではありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
  </h3>
</section>
</div>
</main>

	<!-- Footer -->
	<footer role="contentinfo" class="fixed-bottom">
			<hr>
			<address>
				<div class="avatar-bottom">
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" width="128" hight="128">
					</a>
				</div>
	  		<div class="avatar-bottom">
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128" width="128">
	  			</a>
	  		</div>

			<div class="copyright">
				<font color="black">Copyright
	&#064;Akari All rights reserved.
			</div>
			</address>
		</footer>
<!-- Footer -->
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
