<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-07-07の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Temporal Sub-sampling of Audio Feature Sequences for Automated Audio
  Captioning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.SD/paper_0.html">
      <font color="black">Temporal Sub-sampling of Audio Feature Sequences for Automated Audio
  Captioning</font>
    </a>
  </h2>
  <font color="black">エンコーダーからの出力として固定長ベクトルを使用するシーケンスツーシーケンス方式を採用し、エンコーダーのRNN間に時間サブサンプリングを適用します。結果は、考慮されるすべてのメトリックの改善を示しています。この作業では、オーディオ入力シーケンスに時間的サブサンプリングを適用することにより、シーケンス間のこの長さの違いを明示的に利用することに焦点を当てたアプローチを示します。 
[ABSTRACT]通常、オーディオキャプション方法はディープニューラルネットワークに依存します（私たち）。この方法は、入力オーディオシーケンスを単語の出力シーケンスにマップすることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Improved Large-margin Softmax Loss for Speaker Diarisation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.SD/paper_1.html">
      <font color="black">Improved Large-margin Softmax Loss for Speaker Diarisation</font>
    </a>
  </h2>
  <font color="black">損失のすべてのハイパーパラメータを統一した方法で使用することにより、ベースラインに対して24.6％の相対的なSER削減に達するさらなる改善が達成されました。最後に、重なり合う音声の影響に対抗するために、異なるトレーニングマージンを使用して、重なり合う音声が差別的な埋め込みを作成する際の悪影響を減らします。 
[ABSTRACT]マージンが大きいソフトマックスを使用すると、話者のエラー率（ser）が大幅に改善されます。オーバーラップをトレーニングし、マージンが異なる単一話者の音声サンプルをトレーニングすることにより、最良の結果が得られ、全体で29.5％のser削減が実現しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br><font color="black">2019-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Depthwise Separable Convolutions Versus Recurrent Neural Networks for
  Monaural Singing Voice Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.SD/paper_2.html">
      <font color="black">Depthwise Separable Convolutions Versus Recurrent Neural Networks for
  Monaural Singing Voice Separation</font>
    </a>
  </h2>
  <font color="black">この論文では、RNNを典型的な畳み込みの軽量で高速なバリアントである深度方向分離可能（DWS）畳み込みに置き換えるユースケースを示します。アブレーション研究を行い、チャネル数の影響と信号対アーチファクト、信号対干渉、信号対歪みの比率の標準的な指標を利用することにより、音源分離性能に関するDWS-CNNのレイヤー。多くの場合、RNNは他のタイプの深いシーケンス処理用のニューラルネットワークは、特に音楽ソースの分離で遭遇する一般的に長いシーケンスの場合、トレーニングと並列化に特定の問題があることが知られています。 
[要約] rnnアーキテクチャを採用して、歌声の分離に焦点を当てます。rnnsをdws畳み込み（dws-source）に置き換えます。この方法では、20のみを使用します。rnnアーキテクチャのパラメータ量の57％</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: ResNeXt and Res2Net Structure for Speaker Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.SD/paper_3.html">
      <font color="black">ResNeXt and Res2Net Structure for Speaker Verification</font>
    </a>
  </h2>
  <font color="black">それらは、カーディナリティとスケールとそれぞれ呼ばれるモデルの表現能力を改善するために別の2つの効果的な次元を導入します。特に、Res2Net構造では、EERを相対値で18.5％削減することにより、VoxCeleb1テストセットで最先端のパフォーマンスを達成しました。 .. VoxCelebデータの実験結果は、これらの2つの次元を増やすことは、より深くまたはより広くすることよりも効率的であることを示しました。 
[要約] resnextおよびres2netアーキテクチャは新しいシステムに基づいています。モデルの表現能力を向上させるために使用できます。ただし、単に幅または深さを増やすだけでは効率的ではありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Optimal Transport, CycleGAN, and Penalized LS for Unsupervised Learning
  in Inverse Problems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_0.html">
      <font color="black">Optimal Transport, CycleGAN, and Penalized LS for Unsupervised Learning
  in Inverse Problems</font>
    </a>
  </h2>
  <font color="black">最適な輸送（OT）は、あるビジョンを監視されていない方法で別のディストリビューションに輸送する手段を提供するため、最近コンピュータービジョンコミュニティによって大きな注目を集めている別の数学フレームワークです。最適な輸送の定式化の輸送コストとして使用すると、この新しいPLSの定式化は、KantorovichデュアルOT定式化としての新しいcycleGANアーキテクチャをもたらします。この定式化の最も重要な利点の1つは、前向きの問題の知識に応じて、cycleGANアーキテクチャの明確なバリエーションを導出できることです。たとえば、 1つは2組のジェネレータとディスクリミネータ、もう1つは1組のジェネレータとディスクリミネータのみです。 
[要約]新しいcycleganモデルは高度な高度な高度なpls.itに基づいており、監視されていない方法でcycleganを別の場所に輸送する方法を提供します。ただし、監視されたトレーニングはなく、アルゴリズムは異なって見えます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-25">
        <br><font color="black">2019-09-25</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Graph-Convolutional Representations for Point Cloud Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_1.html">
      <font color="black">Learning Graph-Convolutional Representations for Point Cloud Denoising</font>
    </a>
  </h2>
  <font color="black">点群はますます関連性の高いデータタイプですが、ノイズによって破損することがよくあります。特に、面取りの測定値とノイズ除去されたデータから推定できる表面法線の品質の点で改善できます。また、これは、高ノイズレベルでも、実際のLiDARスキャンで発生するような構造化ノイズの存在下でも、特に堅牢です。 
[要約]グラフに基づくネットワーク-たたみ込み層は順列を処理できます-点群処理を構築します。状態を上回ることができます-さまざまなメトリックの最先端の方法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Compressive MR Fingerprinting reconstruction with Neural Proximal
  Gradient iterations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_2.html">
      <font color="black">Compressive MR Fingerprinting reconstruction with Neural Proximal
  Gradient iterations</font>
    </a>
  </h2>
  <font color="black">これに対処するために、順方向獲得とブロッホ動的モデルを反復学習メカニズム内に直接組み込んだ学習済みの近位勾配降下フレームワークであるProxNetを提案します。 、および最近のディープラーニングMRFベースラインに匹敵するランタイムでありながら、辞書マッチングスキームよりもはるかに高速です。物理的フォワードモデルに関する予測の一貫性は、逆問題を確実に解決するために極めて重要です。 
[要約] proxnetは、エイリアスと定量的結論にコンパクトな神経近位モデルを採用しています。mrfは、磁気共鳴フィンガープリント（mrf）の問題です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-27">
        <br><font color="black">2020-06-27</font>
      </time>
    </span>
</section>
<!-- paper0: $S^2$-$cGAN$: Self-Supervised Adversarial Representation Learning for
  Binary Change Detection in Multispectral Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_3.html">
      <font color="black">$S^2$-$cGAN$: Self-Supervised Adversarial Representation Learning for
  Binary Change Detection in Multispectral Images</font>
    </a>
  </h2>
  <font color="black">提案された$ S ^ 2 $-$ cGAN $は、変更されていないサンプルの分布のみを生成するようにトレーニングされています。このため、提案された方法は2つの主要なステップで構成されています。1）再構成されたバージョンの入力画像を変更されていない画像として生成する2）敵対的なゲームを通じて変更されていないサンプルの分布を学習します。この問題に対処するために、自己監視条件付き生成的敵対的ネットワーク（$ S ^ 2 $-$ cGAN $）を提案します。 
[要約]提案された方法は、敵対的なゲームを通じて変更されていないサンプルの分布を学習することを含みます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Medical Image Segmentation via Unsupervised Convolutional Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_4.html">
      <font color="black">Medical Image Segmentation via Unsupervised Convolutional Neural Network</font>
    </a>
  </h2>
  <font color="black">この方法は、単一光子放出計算機トモグラフィー（SPECT）画像のコンテキストで高速かつ高品質の骨セグメンテーションを提供することを示します。特に、教師なし設定では、畳み込みを介してエッジなしのアクティブ輪郭（ACWE）フレームワークをパラメーター化します。ニューラルネットワーク（ConvNet）、および自己監視法を使用してConvNetのパラメーターを最適化します。大部分の学習ベースのセグメンテーション法では、大量の高品質のトレーニングデータが必要です。 
[ABSTRACT]新しい論文で、半教師付きまたは教師なしでトレーニングできる新しい学習ベースのモデルを紹介します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-28">
        <br><font color="black">2020-01-28</font>
      </time>
    </span>
</section>
<!-- paper0: BiO-Net: Learning Recurrent Bi-directional Connections for
  Encoder-Decoder Architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_5.html">
      <font color="black">BiO-Net: Learning Recurrent Bi-directional Connections for
  Encoder-Decoder Architecture</font>
    </a>
  </h2>
  <font color="black">私たちが提案する双方向スキップ接続は、あらゆるエンコーダ/デコーダアーキテクチャに直接採用して、さまざまなタスクドメインでの機能をさらに強化できます。このようなU-Netバリアントでこの問題に取り組むために、このホワイトペーパーでは、新しい双方向追加のパラメーターを導入せずにビルディングブロックを繰り返し使用するOシェイプネットワーク（BiO-Net）。以前のU-Netの拡張は、主に既存のビルディングブロックの変更または新しい機能モジュールの開発に焦点を当てていましたパフォーマンスの向上。 
[要約] u-netの以前の拡張機能は、主に既存のビルディングブロックの変更またはパフォーマンス向上のための新しい機能モジュールの開発に焦点を当ててきました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-01">
        <br><font color="black">2020-07-01</font>
      </time>
    </span>
</section>
<!-- paper0: Coronary Heart Disease Diagnosis Based on Improved Ensemble Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_6.html">
      <font color="black">Coronary Heart Disease Diagnosis Based on Improved Ensemble Learning</font>
    </a>
  </h2>
  <font color="black">この研究では、疎結合戦略によるカスケード汎化法が提案されています。冠状動脈性心臓病の適切な治療を行う前に、正確な診断が必要です。5およびRIPPERアルゴリズムがメタレベルアルゴリズムとして使用され、Naive Bayesがベースレベルアルゴリズムとして使用されました。 
[ABSTRACT]冠状動脈性心臓病の診断の精度を向上させるために機械学習法が提案されています。方法はアンサンブル学習とカスケード一般化に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Exploiting context dependence for image compression with upsampling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_7.html">
      <font color="black">Exploiting context dependence for image compression with upsampling</font>
    </a>
  </h2>
  <font color="black">ただし、現在使用されているソリューションでは、このようなアップスケーリング情報のエンコードにコンテキスト依存性を活用していません。提示された単純で安価な一般的な方法は、非可逆画像圧縮のDCT係数などのさまざまなタイプのデータにも使用できます。非可逆のDC係数。 
[ABSTRACT]シンプルな一般的な方法は、さまざまなタイプのデータに使用できます。たとえば、圧縮は平均0ドルでした。rgb画像の場合、393。色変換の強化だけで平均1.69ドルが得られました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-06">
        <br><font color="black">2020-04-06</font>
      </time>
    </span>
</section>
<!-- paper0: 4D MRI: Robust sorting of free breathing MRI slices for use in
  interventional settings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_8.html">
      <font color="black">4D MRI: Robust sorting of free breathing MRI slices for use in
  interventional settings</font>
    </a>
  </h2>
  <font color="black">メソッドを検証するために、13人の健康な被験者の37の4D MRIの合計が再構築されました。検索領域は再構築時間を短縮します。新しい方法とベースライン方法の両方の再構築率と速度の定量的評価が行われました。 
[ABSTRACT]新しい方法は、任意の数の呼吸状態をキャプチャすることです。これは、空間解像度で255 mm x 320 mm x 228 mmのfovをキャプチャします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-04">
        <br><font color="black">2019-10-04</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic semantic segmentation for prediction of tuberculosis using
  lens-free microscopy images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_9.html">
      <font color="black">Automatic semantic segmentation for prediction of tuberculosis using
  lens-free microscopy images</font>
    </a>
  </h2>
  <font color="black">したがって、私たちは結核を予測するために収集したデータセットでU-Netネットワークを使用して結核コードの自動セグメンテーションを実行します。結核菌（TB）は結核菌と呼ばれる細菌によって引き起こされ、最も深刻な公衆衛生の1つです。ペルーと世界の問題..私たちの最初の結果は、結核コードの自動セグメンテーションの有望な証拠を示しています。 
[要約]このプロジェクトの開発はmods法による結核の診断を容易にし、自動化することを目指しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: AutoGAN-Distiller: Searching to Compress Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_10.html">
      <font color="black">AutoGAN-Distiller: Searching to Compress Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">AGDは、特別に設計された効率的な検索スペースから始まり、ターゲットの計算リソースの制約を前提として、新しい効率的なジェネレーターのエンドツーエンドのディスカバリーを実行します。 2つの代表的なGANタスクであるAGDを評価します。画像変換と超解像です。 
[要約]ガンの圧縮に関する研究はまだ初期段階にあります。この研究は、深部圧縮におけるautomlの最近の成功に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Uni- and Multi-modal Stream Networks for Multimodal Image
  Registration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_11.html">
      <font color="black">Adversarial Uni- and Multi-modal Stream Networks for Multimodal Image
  Registration</font>
    </a>
  </h2>
  <font color="black">コンピュータ断層撮影（CT）画像と磁気共鳴（MR）画像の間の変形可能な画像登録は、多くの画像誘導療法に不可欠です。マルチモーダル登録ネットワークは、グラウンドトゥルースの変形なしに、計算効率の高い類似性メトリックによって効果的にトレーニングできます。 2つの臨床データセットで評価されており、最先端の伝統的な学習ベースの方法と比較して有望な結果を示しています。 
[ABSTRACT]変形可能な認識方法は、変形可能な画像登録方法を作成するために使用できます。変形可能な画像認識方法を使用する新しい方法に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Constrained Linear Data-feature Mapping for Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_12.html">
      <font color="black">Constrained Linear Data-feature Mapping for Image Classification</font>
    </a>
  </h2>
  <font color="black">この観点から、制約付き線形システムの従来の反復方式とResNetの基本ブロックのアーキテクチャとの間に技術レベルで詳細な接続を確立します。このホワイトペーパーでは、解釈可能な線形データ機能マッピングモデルを提案します。 ResNetなどの畳み込みニューラルネットワーク（CNN）を使用した画像分類の数学モデル。これらの接続の下で、パラメーターが少なくても対応する元のモデルとほぼ同じ精度を維持するResNetタイプモデルのいくつかの自然な変更を提案します。 
[ABSTRACT]従来のシステムとresnetの基本ブロックのアーキテクチャとの間に技術レベルでの接続を確立します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-23">
        <br><font color="black">2019-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: On the Influence of Ageing on Face Morph Attacks: Vulnerability and
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_13.html">
      <font color="black">On the Influence of Ageing on Face Morph Attacks: Vulnerability and
  Detection</font>
    </a>
  </h2>
  <font color="black">この範囲で、私たちはMorphAgeデータセットと呼ばれる、一般に入手可能なMORPH II顔データセットから派生したエージングを使用して、新しいモーフィングされた顔データセットを導入しました。これは、合成画像に寄与し、人間とFRSの両方がそのような攻撃を検出することを困難にしました。さらに、5つの異なるモーフ攻撃検出（MAD）手法を評価して、経年変化による検出パフォーマンスのベンチマークを行います。 
[要約]顔モーフィングプロセスは、複数のデータ主体の画像を使用します。このプロセスは、高品質のモーフィング画像を作成します。データセットには、年齢間隔に基づいて2つのビンがあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Low-rank Prior in Dynamic MR Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_14.html">
      <font color="black">Deep Low-rank Prior in Dynamic MR Imaging</font>
    </a>
  </h2>
  <font color="black">プラグアンドプレイ方式で、ネットワークパラダイムを変更せずに、他の動的MRニューラルネットワークに簡単に組み込むことができるプラグアンドプレイLRネットワークモジュールを提案します。この論文では、学習した特異値しきい値処理（学習済み-SVT）操作は、動的MRイメージングで事前に深い低ランクを探索して、改善された再構成結果を取得するために提案されています。実験結果は、2つのスキームの両方が質的および量的に関係なく再構成結果をさらに改善できることを示しています。 
[ABSTRACT]これは、動的なmrイメージングで深い低ランクの事前適用が適用された初めての例です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-22">
        <br><font color="black">2020-06-22</font>
      </time>
    </span>
</section>
<!-- paper0: Can Un-trained Neural Networks Compete with Trained Neural Networks at
  Image Reconstruction? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_15.html">
      <font color="black">Can Un-trained Neural Networks Compete with Trained Neural Networks at
  Image Reconstruction?</font>
    </a>
  </h2>
  <font color="black">この問題に対処するために、ディープラーニングコミュニティから大きな注目を集めており、専用のトレーニングセットが存在する重要な医療用画像問題である、加速磁気共鳴画像（MRI）を検討します。他のトレーニングされていない方法よりも優れており、最も重要なことには、ディープラーニングベースの再構築方法のベンチマーク用の新しいデータセットであるFastMRIデータセットで、標準のトレーニング済みベースラインであるU-netを使用して、同等のパフォーマンスを実現します。しかし、最近、Deep Image PriorやDeep Decoderなどのトレーニングされていないニューラルネットワークが、トレーニングデータを使用せずに、画像のノイズ除去や画像修復などの標準的な画像再構成問題に対して優れた画像再構成パフォーマンスを実現しました。 
[ABSTRACT] cnnsは大量のトレーニング画像でトレーニングされているとcnnsは言います。この成功は、トレーニングされていないニューラルネットワークが問題と競合できるかどうかという問題を提起します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: An Elastic Interaction-Based Loss Function for Medical Image
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_16.html">
      <font color="black">An Elastic Interaction-Based Loss Function for Medical Image
  Segmentation</font>
    </a>
  </h2>
  <font color="black">提案された損失の監視下では、予測領域の境界はオブジェクトの境界に強く引き付けられ、接続されたままになる傾向があります。たとえば、網膜画像の予測された小血管は、しばしば切断されたり、監視されなかったりします。ピクセルごとの損失。実験結果は、3つの網膜血管セグメンテーションデータセット、DRIVE、STARE、および他の最近の損失関数である一般的なピクセルごとの損失関数（クロスエントロピーおよびダイス損失）と比較して、本手法がかなりの改善を達成できることを示しています。 CHASEDB1。 
[ABSTRACT]このメソッドは、データデータdataへのアクセスを取得するために使用されることが期待されています。複数の領域のデータを取得するツールを開発するためにすでに使用されています。このメソッドは、ターゲットに関するさらに多くの情報を取得できる</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Complex Human Action Recognition in Live Videos Using Hybrid FR-DL
  Method -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_17.html">
      <font color="black">Complex Human Action Recognition in Live Videos Using Hybrid FR-DL
  Method</font>
    </a>
  </h2>
  <font color="black">提案された方法を評価するために、アクション認識研究の研究者の間で広く使用されているベンチマークにUCFデータセットを使用します。CNNとLSTM再帰ネットワークの組み合わせは、機能の選択と以前の情報の維持のために考慮され、最後に、Softmax-KNN分類器は、人間の活動のラベル付けに使用されます。さらに、特徴全体ではなく、代表的なフレームの主要な特徴を抽出します。 
[ABSTRACT]人間の行動のラベル付けは、ビデオシーケンスの動きの外観とパターンに基づいています。ただし、従来の方法と従来のニューラルネットワークでは、ビデオシーケンスの次のフレームでの行動認識予測に情報を使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: A Convolutional Approach to Vertebrae Detection and Labelling in Whole
  Spine MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.IV/paper_18.html">
      <font color="black">A Convolutional Approach to Vertebrae Detection and Labelling in Whole
  Spine MRI</font>
    </a>
  </h2>
  <font color="black">最後に、腰椎と脊椎全体のMRスキャンで脊柱側弯症を自動検出するためにこの方法を使用して、この方法の臨床的適用性を示します。この方法は、さまざまなMRシーケンスの範囲にわたって腰椎、頸部、および胸部のみのスキャンに変更なしで適用できます。 ..結果として得られるシステムは、脊椎全体のスキャンの困難な臨床データセットで98.1％の検出率と96.5％の識別率を達成し、腰椎のみのスキャンでの以前のシステムのパフォーマンスと同等かそれ以上です。 
[要約]システムを使用して、椎体の椎骨の角を特定できます。次に、システムを使用して、自己整合的な方法で椎骨のレベルを特定できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Optimal Transport, CycleGAN, and Penalized LS for Unsupervised Learning
  in Inverse Problems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_0.html">
      <font color="black">Optimal Transport, CycleGAN, and Penalized LS for Unsupervised Learning
  in Inverse Problems</font>
    </a>
  </h2>
  <font color="black">Optimal Transport（OT）は、あるビジョンを監視なしの方法で別のディストリビューションに転送する手段を提供するため、最近コンピュータービジョンコミュニティによって大きな注目を集めている別の数学的フレームワークです。OT-cycleGANと呼ばれる新しいcycleGANの公式には、加速磁気共鳴画像法（MRI）、超解像顕微鏡法、低線量X線コンピュータ断層撮影法（CT）など、さまざまな生物医学画像診断の問題に適用されています。具体的には、深層学習を課すことによって新しいPLSコストを提案します正則化用語としてのベースの逆パス。 
[要約]新しいcycleganモデルは高度な高度な高度なpls.itに基づいており、監視されていない方法でcycleganを別の場所に輸送する方法を提供します。ただし、監視されたトレーニングはなく、アルゴリズムは異なって見えます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-25">
        <br><font color="black">2019-09-25</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Graph-Convolutional Representations for Point Cloud Denoising -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_1.html">
      <font color="black">Learning Graph-Convolutional Representations for Point Cloud Denoising</font>
    </a>
  </h2>
  <font color="black">学習ベースの点群処理方法で発生する順列不変性の問題にエレガントに対処できるグラフ畳み込み層に基づくディープニューラルネットワークを提案します。ネットワークは完全に畳み込みであり、近傍を動的に構築することにより、複雑な機能の階層を構築できます。ポイントの高次元の特徴表現間の類似性からのグラフ。ポイントクラウドはますます関連性の高いデータタイプですが、ノイズによって破損することがよくあります。 
[要約]グラフに基づくネットワーク-たたみ込み層は順列を処理できます-点群処理を構築します。状態を上回ることができます-さまざまなメトリックの最先端の方法</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Lightweight Temporal Self-Attention for Classifying Satellite Image Time
  Series -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_2.html">
      <font color="black">Lightweight Temporal Self-Attention for Classifying Satellite Image Time
  Series</font>
    </a>
  </h2>
  <font color="black">各頭は、高度に専門化された時間的特徴を抽出し、それが単一の表現に連結されます。リモートセンシングの時間シーケンスを分類するためにマルチヘッドの自己注意メカニズムを採用する最近の研究に基づいて、時間的注意エンコーダーの変更を提案します。アプローチは、オープンアクセスの衛星画像データセットで他の最先端の時系列分類アルゴリズムよりも優れていますが、使用するパラメーターは大幅に少なく、計算の複雑さも軽減されます。 
[ABSTRACT]これは、時間を処理できる効率的な方法のために呼び出されます-地球規模でのシリーズ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-01">
        <br><font color="black">2020-07-01</font>
      </time>
    </span>
</section>
<!-- paper0: EDSL: An Encoder-Decoder Architecture with Symbol-Level Features for
  Printed Mathematical Expression Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_3.html">
      <font color="black">EDSL: An Encoder-Decoder Architecture with Symbol-Level Features for
  Printed Mathematical Expression Recognition</font>
    </a>
  </h2>
  <font color="black">セグメンテーションモジュールを実行することにより、教師なしの方法で画像からすべてのシンボルとその空間情報を識別します。次に、シンボル再分割モジュールを設計して、シンボルのセグメンテーション後にシンボルの依存関係を回復します。この論文では、EDSLという新しい方法を提案します。 、シンボルレベルの機能を備えたエンコーダ/デコーダの略で、画像から印刷された数式を識別します。 
[ABSTRACT]これらの方法は、マーの問題を解決するのに最適ではない可能性があります。これらには、検死、インタラクティブな問題解決、学生の分析が含まれます。結果は、edslが92.7 / 2.5パーセントで達成したことを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Closing the Dequantization Gap: PixelCNN as a Single-Layer Flow -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_4.html">
      <font color="black">Closing the Dequantization Gap: PixelCNN as a Single-Layer Flow</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、サブセットフローを紹介します。これは、有限体積を扱いやすく変換し、離散データの尤度を正確に計算できるフローのクラスです。最後に、PixelCNNと非自己回帰結合層で構成される多層フローを研究し、状態を示します。逆量子化でトレーニングされたフローモデルに対するCIFAR-10の最新の結果。フロー定式化を使用して、正確な尤度またはその逆量子化の下限でトレーニングおよび評価されたモデルを比較します。 
[ABSTRACT]逆量子化は通常、そのようなデータに使用するときに適用され、その結果、尤度の下限推定値が得られます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-06">
        <br><font color="black">2020-02-06</font>
      </time>
    </span>
</section>
<!-- paper0: Compressive MR Fingerprinting reconstruction with Neural Proximal
  Gradient iterations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_5.html">
      <font color="black">Compressive MR Fingerprinting reconstruction with Neural Proximal
  Gradient iterations</font>
    </a>
  </h2>
  <font color="black">これに対処するために、順方向獲得とブロッホ動的モデルを反復学習メカニズム内に直接組み込んだ学習済みの近接勾配降下フレームワークであるProxNetを提案します。私たちの数値実験は、ProxNetが優れた定量的推論精度とはるかに小さいストレージ要件を達成できることを示しています、および最近のディープラーニングMRFベースラインに匹敵するランタイム、ディクショナリマッチングスキームよりもはるかに高速です。ProxNetは、エイリアス除去と定量的推論にコンパクトなニューラル近位モデルを採用しており、希少なMRFトレーニングデータセットで柔軟にトレーニングできます。 。 
[要約] proxnetは、エイリアスと定量的結論にコンパクトな神経近位モデルを採用しています。mrfは、磁気共鳴フィンガープリント（mrf）の問題です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-27">
        <br><font color="black">2020-06-27</font>
      </time>
    </span>
</section>
<!-- paper0: Revealing Stable and Unstable Modes of Generic Denoisers through
  Nonlinear Eigenvalue Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_6.html">
      <font color="black">Revealing Stable and Unstable Modes of Generic Denoisers through
  Nonlinear Eigenvalue Analysis</font>
    </a>
  </h2>
  <font color="black">このようなブラックボックスオペレーターの固有問題を解決するための一般化された非線形パワー法を紹介します。これらのモードはノイズ除去の最適入力であり、ノイズ除去で優れたPSNRを実現します。この方法を使用して、非線形デノイザーの安定モードを明らかにします。 
[ABSTRACT]ブラックボックスノイズ除去器の出力が入力に比例する画像を見つけようとします。これは、ほとんどの画像処理アルゴリズムを一般的な線形演算子と見なすことができるため、潜在的に広い意味を持ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-12">
        <br><font color="black">2019-09-12</font>
      </time>
    </span>
</section>
<!-- paper0: Medical Image Segmentation via Unsupervised Convolutional Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_7.html">
      <font color="black">Medical Image Segmentation via Unsupervised Convolutional Neural Network</font>
    </a>
  </h2>
  <font color="black">この方法は、単一光子放出計算機トモグラフィー（SPECT）画像のコンテキストで高速かつ高品質の骨セグメンテーションを提供することを示します。特に、教師なし設定では、畳み込みを介してエッジなしのアクティブ輪郭（ACWE）フレームワークをパラメーター化します。ニューラルネットワーク（ConvNet）、および自己監視メソッドを使用してConvNetのパラメーターを最適化します。別の設定（半監視あり）では、補助セグメンテーショングラウンドトゥルースがトレーニング中に使用されます。 
[ABSTRACT]新しい論文で、半教師付きまたは教師なしでトレーニングできる新しい学習ベースのモデルを紹介します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-28">
        <br><font color="black">2020-01-28</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding and Improving Fast Adversarial Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_8.html">
      <font color="black">Understanding and Improving Fast Adversarial Training</font>
    </a>
  </h2>
  <font color="black">その結果、GradAlignは、FGSMトレーニングをより大きな$ \ ell_ \ infty $ -perturbationsにも正常に適用し、マルチステップの敵対的トレーニングとのギャップを減らすことができます。最近の一連の作業は、敵対的なトレーニングをディープラーニングモデルに対して計算的に効率的にすることに焦点を当てています。 ..さらに、壊滅的なオーバーフィッティングは、深層で過剰パラメーター化されたネットワークに固有のものではなく、いくつかのフィルターを持つ単一層の畳み込みネットワークで発生する可能性があることを示します。 
[要旨] f fgsmは、 `f fg &#39;と呼ばれる新しいメソッドを提案しました。fgsmに加えて、fgsmへのパターンパターンがあります。このメソッドは、新しいパターンの開発に使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Adapt Structured Output Space for Semantic Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_9.html">
      <font color="black">Learning to Adapt Structured Output Space for Semantic Segmentation</font>
    </a>
  </h2>
  <font color="black">適応モデルをさらに強化するために、さまざまな機能レベルで出力空間ドメイン適応を効果的に実行するマルチレベル敵対的ネットワークを構築します。ソースドメインとターゲットドメイン間の空間的類似性を含む構造化出力としてのセマンティックセグメンテーションを考慮して、出力空間。セマンティックセグメンテーションのための畳み込みニューラルネットワークベースのアプローチは、ピクセルレベルのグラウンドトゥルースによる監視に依存しますが、見えない画像ドメインにうまく一般化できない場合があります。 
[要約]マッピングプロセスは面倒で手間がかかります。これらのアルゴリズムが情報をターゲットドメインに適合させることができるのは初めてです。これは、情報を適合させる新しい方法を開発するために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-02-28">
        <br><font color="black">2018-02-28</font>
      </time>
    </span>
</section>
<!-- paper0: Dynamic memory to alleviate catastrophic forgetting in continuous
  learning settings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_10.html">
      <font color="black">Dynamic memory to alleviate catastrophic forgetting in continuous
  learning settings</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、ダイナミックメモリを使用して、さまざまなトレーニングデータサブセットのリハーサルを容易にし、忘却を緩和します。医療画像処理では、技術の進歩または診断手順の変更により、画像の外観が継続的に変化します。これらのシフトがいつ発生するかについての明確な知識を必要としない、複数のデータシフトを伴う設定。 
[ABSTRACT] mitのソフトウェア会社は、継続学習マシンの変化のパターンを使用します。このツールは、モデルを使用してソースドメインの目に見えない変化を使用します。2つの異なるスキャナープロトコルと合成分類で取得されたルーチンの臨床ctデータに対するアプローチを評価タスク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: BiO-Net: Learning Recurrent Bi-directional Connections for
  Encoder-Decoder Architecture -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_11.html">
      <font color="black">BiO-Net: Learning Recurrent Bi-directional Connections for
  Encoder-Decoder Architecture</font>
    </a>
  </h2>
  <font color="black">私たちのコードはhttps://github.com/tiangexiang/BiO-Net。で入手できます。私たちが提案する双方向スキップ接続は、さまざまなタスクドメインでの機能をさらに強化するために、エンコーダー/デコーダーアーキテクチャに直接採用できます。ネットは、セマンティックセグメンテーション、超解像度、画像のノイズ除去、修復などの最新のコンピュータービジョンタスクのための最先端のディープラーニングベースのアプローチの1つになりました。 
[要約] u-netの以前の拡張機能は、主に既存のビルディングブロックの変更またはパフォーマンス向上のための新しい機能モジュールの開発に焦点を当ててきました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-01">
        <br><font color="black">2020-07-01</font>
      </time>
    </span>
</section>
<!-- paper0: It Is Not the Journey but the Destination: Endpoint Conditioned
  Trajectory Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_12.html">
      <font color="black">It Is Not the Journey but the Destination: Endpoint Conditioned
  Trajectory Prediction</font>
    </a>
  </h2>
  <font color="black">プロジェクトのホームページ：https://karttikeya.github.io/publication/htf/。 PECNetは、スタンフォードドローンの軌道予測ベンチマークで最高19.5％、ETH / UCYベンチマークで最高40.8％の最先端のパフォーマンスを向上させることを示しています。この作業では、予測エンドポイント条件付きネットワーク（PECNet）を示します。柔軟な人間の軌道予測のため。 
[要旨]柔軟な人間の軌跡を予測するために予測される条件付きネットワーク（pecnet）を提示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-04">
        <br><font color="black">2020-04-04</font>
      </time>
    </span>
</section>
<!-- paper0: 4D MRI: Robust sorting of free breathing MRI slices for use in
  interventional settings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_13.html">
      <font color="black">4D MRI: Robust sorting of free breathing MRI slices for use in
  interventional settings</font>
    </a>
  </h2>
  <font color="black">メソッドを検証するために、13人の健康な被験者の合計37個の4D MRIが再構築されました。新しいメソッドとベースラインメソッドの両方の再構築率と速度の定量的評価が実行されました。高速のナビゲータースライスと検索領域でテンプレート更新を使用します堅牢な血管断面追跡。 
[ABSTRACT]新しい方法は、任意の数の呼吸状態をキャプチャすることです。これは、空間解像度で255 mm x 320 mm x 228 mmのfovをキャプチャします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-04">
        <br><font color="black">2019-10-04</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Ranking Attack and Defense -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_14.html">
      <font color="black">Adversarial Ranking Attack and Defense</font>
    </a>
  </h2>
  <font color="black">逆に、提案されたすべての攻撃を同時に軽減できる、ランキングシステムのロバスト性を改善するための防御方法も提案されます。具体的には、期待されるランキング順序が最初に不等式のセットとして表され、次にトリプレットのような目的関数が設計されます。最適な摂動を得るために..一方、システムの堅牢性は、防御によって適度に改善できます。 
[ABSTRACT] dnnの脆弱性-ベースの画像ランキングシステムが未解決のまま-調査済み。システムの堅牢性は、防御策により適度に改善できる</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-26">
        <br><font color="black">2020-02-26</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic semantic segmentation for prediction of tuberculosis using
  lens-free microscopy images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_15.html">
      <font color="black">Automatic semantic segmentation for prediction of tuberculosis using
  lens-free microscopy images</font>
    </a>
  </h2>
  <font color="black">したがって、私たちは結核を予測するために収集したデータセットでU-Netネットワークを使用して結核コードの自動セグメンテーションを実行します。結核菌（TB）は結核菌と呼ばれる細菌によって引き起こされ、最も深刻な公衆衛生の1つです。ペルーと世界の問題..私たちの最初の結果は、結核コードの自動セグメンテーションの有望な証拠を示しています。 
[要約]このプロジェクトの開発はmods法による結核の診断を容易にし、自動化することを目指しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Understanding More about Human and Machine Attention in Deep Neural
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_16.html">
      <font color="black">Understanding More about Human and Machine Attention in Deep Neural
  Networks</font>
    </a>
  </h2>
  <font color="black">3つの例のコンピュータービジョンタスク、多様な代表的なバックボーン、有名なアーキテクチャ、対応する実際の人間の視線データ、体系的に実施された大規模な定量的研究により、人工的な注意と人間の視覚的注意の一貫性を定量化し、既存の人工的な注意メカニズムへの新しい洞察を提供します人間と人工の注意メカニズムに関連するいくつかの重要な質問に予備的な回答を与えることによって。しかし、最近の研究は人工注意マップが常に一般的な直感と一致するとは限らないことを示しています。これらの相反する証拠に鑑み、ここで使用に関する体系的な研究を行いますニューラルネットワーク設計における人工的注意と人間の注意。 
[ABSTRACT]人間の注意は、注意駆動型のタスクで意味のある「グラウンドトゥルース」をベンチマークできます。人工的な注意が人間の注意に近ければ近いほど、パフォーマンスは向上します。研究は、ニューラルネットワークがどこに見えるかを説明するのに役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-20">
        <br><font color="black">2019-06-20</font>
      </time>
    </span>
</section>
<!-- paper0: NAPPO: Modular and scalable reinforcement learning in pytorch -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_17.html">
      <font color="black">NAPPO: Modular and scalable reinforcement learning in pytorch</font>
    </a>
  </h2>
  <font color="black">さらに、同期および非同期の通信パターンを備えたさまざまな分散トレーニングスキームがどのように実行されるかについての洞察を提供します。完全なソースコードが利用可能です。最後に、Obstacle Tower Unity3Dチャレンジ環境で最高の最新のテストパフォーマンスを得ることにより、NAPPOを紹介します。 。 
[ABSTRACT] rlアルゴリズムの効率を高めるために新しいメソッドが調査されていますが、コードを使用しています-メソッドの実験を可能にするのに十分な柔軟性のあるベースです。mujocoおよびatari環境での以前の結果を検証します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: In the Wild: From ML Models to Pragmatic ML Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_18.html">
      <font color="black">In the Wild: From ML Models to Pragmatic ML Systems</font>
    </a>
  </h2>
  <font color="black">機械学習コミュニティは、この困難なタスクを、監視あり、少数ショット、継続的、および自己監視付き学習などの管理可能なサブタスクに有機的に分解しました。それぞれが固有の課題を提供し、独自の方法のセットにつながります。野生で堅牢なインテリジェンスを有効にすると、中断のない推論を提供しながら、さまざまな量のデータと監視を備えた継続的なトレーニングを提供する学習システムが必要になります。MLモデルの拡張に必要な研究を促進するMLシステムには、統合された学習と評価のフレームワーク-広域（NED）を導入します。 
[ABSTRACT] nedは、過去の設定の制限的な設計の決定を緩めることにより、より一般的なツールになるように設計されています。これらには、sota自己管理法などのより厳密な学習法が含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: On the Connection between Dynamical Optimal Transport and Functional
  Lifting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_19.html">
      <font color="black">On the Connection between Dynamical Optimal Transport and Functional
  Lifting</font>
    </a>
  </h2>
  <font color="black">連続方程式を変更することにより、アプローチを高次の正則化を伴うモデルに拡張することもできます。確立された連続方程式を制約として課すことは、1次の正則化を伴う変分モデルに対応します。興味深いことに、このアプローチは一般化として導出できます。動的最適輸送の理論の概要。 
[ABSTRACT]シンプルシンプルシンプルシステムは、固定範囲の点ごとの確率測度の空間への埋め込みに基づいています。これらには、可能な限りシンプルに見えるシステムへの埋め込みが含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Progressive Cluster Purification for Unsupervised Feature Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_20.html">
      <font color="black">Progressive Cluster Purification for Unsupervised Feature Learning</font>
    </a>
  </h2>
  <font color="black">教師なし特徴学習では、サンプル特異性ベースのメソッドは、クラス間情報を無視します。これは、表現モデルの識別能力を低下させます。この作業では、進行性クラスター形成中にクラスの一貫性のないサンプルを反復的に除外する、新しいクラスタリングベースの方法を提案します。 、ノイズサンプルの影響をシンプルかつ効果的な方法で軽減します。プログレッシブクラスター浄化（PCP）と呼ばれるこのアプローチは、クラスターのサイズを継続的に拡大しながら、トレーニング中にクラスターの数を徐々に減らすことでプログレッシブクラスタリングを実装します。モデル表現機能の成長と一貫して。 
[ABSTRACT]「プログレッシブクラスター精製」には、不愉快な大量のデータが含まれます。これらの方法は、完全なクラス境界情報を探索するのに複雑です。これは、各クラスターでの不可避なクラスの一貫性のないサンプルが原因です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Probabilistic Multi-modal Trajectory Prediction with Lane Attention for
  Autonomous Vehicles -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_21.html">
      <font color="black">Probabilistic Multi-modal Trajectory Prediction with Lane Attention for
  Autonomous Vehicles</font>
    </a>
  </h2>
  <font color="black">最も重要なのは、生成された各軌道が不確実性を処理する確率に関連付けられていることです。この方法は、1つの動作モーダルへの崩壊に悩まされず、さまざまな可能性をカバーできます。この論文では、レーン表現のための新しいインスタンス認識表現を提案します。 。 
[要約]提案された方法は、車両の将来の位置を予測するために使用できます。既存の作業のほとんどは、異なる車線を区別しない道路情報を探索するためにラスタライズされたマップを使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: AutoGAN-Distiller: Searching to Compress Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_22.html">
      <font color="black">AutoGAN-Distiller: Searching to Compress Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">AGDは、特別に設計された効率的な検索スペースから始めて、ターゲットの計算リソースの制約を考慮して、新しい効率的なジェネレーターのエンドツーエンドのディスカバリーを実行します。需要の増加により、生成的敵対ネットワーク（GAN）の圧縮が最近注目を集めていますGANをモバイルデバイスに展開して、画像の翻訳、拡張、編集などの多数のアプリケーションに使用できます。AGDは、画像の翻訳と超解像という2つの代表的なGANタスクで評価されます。 
[要約]ガンの圧縮に関する研究はまだ初期段階にあります。この研究は、深部圧縮におけるautomlの最近の成功に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br><font color="black">2020-06-15</font>
      </time>
    </span>
</section>
<!-- paper0: Non-Volume Preserving-based Feature Fusion Approach to Group-Level
  Expression Recognition on Crowd Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_23.html">
      <font color="black">Non-Volume Preserving-based Feature Fusion Approach to Group-Level
  Expression Recognition on Crowd Videos</font>
    </a>
  </h2>
  <font color="black">提案されたアプローチにおける各コンポーネントの堅牢性と有効性を実証するために、3つの実験が行われました。（i）顔の表情を認識するために提案されたEmoNetをベンチマークするためのAffectNetデータベースの評価。 （ii）提案されたディープフィーチャーレベルのフュージョンメカニズムNVPFをベンチマークするEmotiW2018の評価。 （iii）公開されているソースから収集された627本のビデオで構成される革新的なグループレベルの群集ビデオ（GECV）データセットで提案されたTNVPFを調べます。各ビデオは、3つのレベルの感情カテゴリでラベル付けされています人とビデオフレーム全体..この作業は、群集ビデオのグループレベルの表現認識を完全に調査することにより、単一の画像またはビデオ内のグループレベルのERに焦点を当てた以前のER調査を拡張します。 
[ABSTRACT]この作品は、グループを完全に調査することで以前のerの調査を拡張します-群衆の動画でのレベル表現の認識</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-11-28">
        <br><font color="black">2018-11-28</font>
      </time>
    </span>
</section>
<!-- paper0: Constrained Linear Data-feature Mapping for Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_24.html">
      <font color="black">Constrained Linear Data-feature Mapping for Image Classification</font>
    </a>
  </h2>
  <font color="black">この論文では、ResNetなどの畳み込みニューラルネットワーク（CNN）を使用した画像分類のための解釈可能な数学的モデルとして、制約付き線形データフィーチャマッピングモデルを提案します。この制約付き学習データの有効性を示すために、いくつかの数値実験が示されています。機能マッピングの仮定..これらの接続の下で、ResNetタイプモデルのいくつかの自然な変更を提案します。これにより、パラメーターは少なくなりますが、これらの対応する元のモデルとほぼ同じ精度が維持されます。 
[ABSTRACT]従来のシステムとresnetの基本ブロックのアーキテクチャとの間に技術レベルでの接続を確立します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-23">
        <br><font color="black">2019-11-23</font>
      </time>
    </span>
</section>
<!-- paper0: Tree-Augmented Cross-Modal Encoding for Complex-Query Video Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_25.html">
      <font color="black">Tree-Augmented Cross-Modal Encoding for Complex-Query Video Retrieval</font>
    </a>
  </h2>
  <font color="black">最近、埋め込みベースのパラダイムが人気のあるアプローチとして登場しました。このアプローチでは、複雑なクエリの理解とモデリングが向上し、ビデオ検索のパフォーマンスが向上しています。インターネット上でのユーザー生成ビデオの急速な成長テキストベースのビデオ検索システムの必要性が高まっています。 
[要約]高速検索システムは、単純なクエリの欠如に基づいています。クエリとビデオを共有の埋め込みスペースにマッピングすることを目的としています。これは、意味的に-類似のテキストとビデオが人気がある場所です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Learning a Domain Classifier Bank for Unsupervised Adaptive Object
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_26.html">
      <font color="black">Learning a Domain Classifier Bank for Unsupervised Adaptive Object
  Detection</font>
    </a>
  </h2>
  <font color="black">ベアオブジェクト検出器を、適応検出器として提案された細粒度ドメインアライメントメカニズムで組み立て、開発された交差適応重み付けメカニズムで最適化します。具体的には、まず平均教師パラダイムを使用して、ラベルのないサンプルの疑似ラベルを生成します。実際のアプリケーションでは、ディープネットワークに基づくオブジェクト検出器は、ラベル付けされたトレーニングデータとラベル付けされていないテストデータの間の大きなドメインギャップの課題に依然として直面しています。 
[ABSTRACT]最近の技法は、ソースドメインとラベルなしターゲットドメイン間で細かいドメイン機能を調整することによって提案されています。この方法では、特定のクラスの機能と一致するクラスベースのドメイン分類バンクを作成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: EagleEye: Fast Sub-net Evaluation for Efficient Neural Network Pruning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_27.html">
      <font color="black">EagleEye: Fast Sub-net Evaluation for Efficient Neural Network Pruning</font>
    </a>
  </h2>
  <font color="black">EagleEyeは、実験で検討したすべての剪定アルゴリズムよりも優れた剪定パフォーマンスを実現します。MobileNetV1のコンパクトモデルを剪定するより困難な実験でも、EagleEyeは、全体で50％の演算（FLOP）を剪定して70.9％の最高精度を達成します..しかし、それらは一般的なアプリケーションに対して不正確または非常に複雑です。 
[ABSTRACT]多くのアルゴリズムは、さまざまな評価方法を導入することにより、枝刈りされたサブネットのモデルパフォーマンスを予測しようとします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial T-shirt! Evading Person Detectors in A Physical World -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_28.html">
      <font color="black">Adversarial T-shirt! Evading Person Detectors in A Physical World</font>
    </a>
  </h2>
  <font color="black">私たちの知る限りでは、これはTシャツなどの剛体オブジェクトに関する物理的な敵対例を設計するための変形の影響をモデル化した最初の作品です。提案された方法が74％および57％の攻撃成功率を達成することを示します。この作業では、動いている人の姿勢の変化によって非剛体の変形が発生する可能性がある場合でも、人の検出器を回避するための堅牢な物理的な敵の例である敵対的なTシャツを提案しました。 
[ABSTRACT]いわゆる物理的な敵対的な例は機能しません。デジタルおよび物理的な世界の人々を対象とするように設計されています。提案された方法は、敵対的な成功率74％および57％を達成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-18">
        <br><font color="black">2019-10-18</font>
      </time>
    </span>
</section>
<!-- paper0: On the Influence of Ageing on Face Morph Attacks: Vulnerability and
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_29.html">
      <font color="black">On the Influence of Ageing on Face Morph Attacks: Vulnerability and
  Detection</font>
    </a>
  </h2>
  <font color="black">この範囲で、私たちはMorphAgeデータセットと呼ばれる、一般に入手可能なMORPH II顔データセットから派生したエージングを使用して、新しいモーフィングされた顔データセットを導入しました。これは、合成画像に寄与し、人間とFRSの両方がそのような攻撃を検出することを困難にしました。さらに、5つの異なるモーフ攻撃検出（MAD）手法を評価して、経年変化による検出パフォーマンスのベンチマークを行います。 
[要約]顔モーフィングプロセスは、複数のデータ主体の画像を使用します。このプロセスは、高品質のモーフィング画像を作成します。データセットには、年齢間隔に基づいて2つのビンがあります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Traffic Agent Trajectory Prediction Using Social Convolution and
  Attention Mechanism -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_30.html">
      <font color="black">Traffic Agent Trajectory Prediction Using Social Convolution and
  Attention Mechanism</font>
    </a>
  </h2>
  <font color="black">軌道シーケンスが与えられると、LSTMネットワークは最初にすべてのエージェントの特徴を抽出するために利用され、それに基づいてアテンションマスクとソーシャルマップが形成されます。次に、アテンションマスクとソーシャルマップが融合されてフュージョンフィーチャマップが取得されます。私たちの方法の有効性を検証するために、パブリックデータセットのいくつかの方法と広く比較して、20％のエラーの減少を達成しています。 
[ABSTRACT]たとえば、ターゲットエージェントの履歴トラジェクトリをアテンションマスクとしてエンコードし、ソーシャルマップを作成します。フュージョンフィーチャーマップは、ソーシャルコンボリューションによって処理され、フュージョンフィーチャー表現を取得します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Low-rank Prior in Dynamic MR Imaging -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_31.html">
      <font color="black">Deep Low-rank Prior in Dynamic MR Imaging</font>
    </a>
  </h2>
  <font color="black">プラグアンドプレイの方法では、ネットワークパラダイムを変更せずに他の動的MRニューラルネットワークに簡単に組み込むことができるプラグアンドプレイLRネットワークモジュールを提案します。実験結果は、2つのスキームの両方がさらに質的および量的に関係なく、再構成の結果を改善します。特に、学習可能な低ランクをディープネットワークアーキテクチャにアンローリング方式とプラグアンドプレイ方式でそれぞれ導入するための、2つの新しい明確な方式を提案します。 
[ABSTRACT]これは、動的なmrイメージングで深い低ランクの事前適用が適用された初めての例です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-22">
        <br><font color="black">2020-06-22</font>
      </time>
    </span>
</section>
<!-- paper0: TLIO: Tight Learned Inertial Odometry -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_32.html">
      <font color="black">TLIO: Tight Learned Inertial Odometry</font>
    </a>
  </h2>
  <font color="black">ただし、測定値の統合はセンサーバイアスとノイズに敏感で、数秒以内に大幅なドリフトを引き起こします。このペーパーは、3D変位推定とその不確実性を後退させるネットワークを示し、相対状態測定値を確率的クローニングEKFにしっかりと融合する機能を提供します姿勢、速度、センサーのバイアスを解決するために。Yanet al。による最近の研究。 
[ABSTRACT]ストラップダウンimu測定は、imu運動学的運動モデルに基づいて相対的な状態推定を提供します。ヘッドセットからの歩行者データでトレーニングされたネットワークは、ハマグリと不確実性を生成する可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Pedestrian Detection: The Elephant In The Room -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_33.html">
      <font color="black">Pedestrian Detection: The Elephant In The Room</font>
    </a>
  </h2>
  <font color="black">第2に、トレーニングソースは一般に歩行者が密集しておらず、シナリオが多様です。第1に、従来の単一データセットのトレーニングおよびテストパイプラインの一般的なデータセットに適合しすぎています。この傾向には2つの理由があることを示しています。 
[ABSTRACT]既存の状態-最先端の歩行者検出器は、あるデータセットから別のデータセットへの一般化が不十分です。直接的なデータセット間評価では、汎用オブジェクト検出器がうまく機能するという懸念もあります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-19">
        <br><font color="black">2020-03-19</font>
      </time>
    </span>
</section>
<!-- paper0: Joint learning of Social Groups, Individuals Action and Sub-group
  Activities in Videos -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_34.html">
      <font color="black">Joint learning of Social Groups, Individuals Action and Sub-group
  Activities in Videos</font>
    </a>
  </h2>
  <font color="black">私たちの主な貢献は次のとおりです。i）ソーシャルタスクのエンドツーエンドのトレーニング可能なフレームワークを提案します。 ii）私たちの提案する方法は、従来のグループアクティビティ認識タスクに広く採用されている2つのベンチマーク（シーンの個人が単一グループを形成し、シーンの単一グループアクティビティラベルを予測する）に最先端の結果を設定します。 iii）既存のグループ活動データセットに新しい注釈を導入し、それを社会的タスクに転用します。この論文では、人々を彼らの社会的相互作用によって同時にグループ化し、個々の行動とそれぞれの社会活動を予測する問題を解決します。ソーシャルグループと呼ばれるソーシャルタスクは、キュー内の全員が互いに対話しているわけではないため、予測されないことがよくあります。 
[ABSTRACT]ソーシャルタスクは、サブグループに分割するのが最適な人々によって提案されます。これは、ソーシャルグループと呼ばれ、各ソーシャルグループは異なるソーシャルアクティビティに従事している可能性があります。従来のグループ活動認識タスクに採用されたベンチマーク</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Can Un-trained Neural Networks Compete with Trained Neural Networks at
  Image Reconstruction? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_35.html">
      <font color="black">Can Un-trained Neural Networks Compete with Trained Neural Networks at
  Image Reconstruction?</font>
    </a>
  </h2>
  <font color="black">この問題に対処するために、ディープラーニングコミュニティから大きな注目を集めており、専用のトレーニングセットが存在する重要な医療用画像問題である、加速磁気共鳴画像（MRI）を検討します。他のトレーニングされていない方法よりも優れており、最も重要なことには、ディープラーニングベースの再構築方法のベンチマーク用の新しいデータセットであるFastMRIデータセットで、標準のトレーニング済みベースラインであるU-netを使用して、同等のパフォーマンスを実現します。しかし、最近、Deep Image PriorやDeep Decoderなどのトレーニングされていないニューラルネットワークが、トレーニングデータを使用せずに、画像のノイズ除去や画像修復などの標準的な画像再構成問題に対して優れた画像再構成パフォーマンスを実現しました。 
[ABSTRACT] cnnsは大量のトレーニング画像でトレーニングされているとcnnsは言います。この成功は、トレーニングされていないニューラルネットワークが問題と競合できるかどうかという問題を提起します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: An Elastic Interaction-Based Loss Function for Medical Image
  Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_36.html">
      <font color="black">An Elastic Interaction-Based Loss Function for Medical Image
  Segmentation</font>
    </a>
  </h2>
  <font color="black">提案された損失の監視下では、予測領域の境界はオブジェクトの境界によって強く引き付けられ、接続されたままになる傾向があります。実験結果は、一般的に使用されるピクセル単位の損失関数と比較して、本手法がかなりの改善を達成できることを示しています（クロスエントロピーとサイコロ損失）、および3つの網膜血管セグメンテーションデータセット、DRIVE、STARE、CHASEDB1での他の最近の損失関数。これにより、これらのモデルがボトルネックになり、医用画像の複雑な構造の高精度を達成できます。 
[ABSTRACT]このメソッドは、データデータdataへのアクセスを取得するために使用されることが期待されています。複数の領域のデータを取得するツールを開発するためにすでに使用されています。このメソッドは、ターゲットに関するさらに多くの情報を取得できる</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Motion Flows for Semi-supervised Instrument Segmentation from
  Robotic Surgical Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_37.html">
      <font color="black">Learning Motion Flows for Semi-supervised Instrument Segmentation from
  Robotic Surgical Video</font>
    </a>
  </h2>
  <font color="black">ラベル付けされていないフレームを個別に使用する以前のほとんどの方法とは異なり、時間的ダイナミクスを活用してセグメンテーション強化のためにモーションフローを賢く学習するデュアルモーションベースの方法を提案します。外科用ビデオに低ヘルツラベリングを間隔で実行すると、外科医の負担を大幅に軽減できます。生成されたデータのペアを使用すると、フレームワークが回復し、トレーニングシーケンスの時間的一貫性を強化してセグメンテーションに役立てることができます。 
[ABSTRACT]メソッドは、最先端の半教師付きメソッドを大幅に上回っており、2つのタスクで完全に教師付きのトレーニングを超えています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Toward unsupervised, multi-object discovery in large-scale image
  collections -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_38.html">
      <font color="black">Toward unsupervised, multi-object discovery in large-scale image
  collections</font>
    </a>
  </h2>
  <font color="black">（2）提案の固有の階層構造を、〜\ cite {Vo2019UnsupOptim}のオブジェクト検出へのアプローチの効果的な正則化子として活用し、そのパフォーマンスを向上させて、いくつかの標準的なベンチマークで最先端の技術を大幅に改善します。（3）画像コレクション全体を使用して描写するオブジェクトを発見する前に、小さなランダムな画像セットを使用して有望な提案を選択する2段階の戦略を採用し、初めて（私たちの知る限り）発見に取り組むことができます最大20,000画像のデータセットを構成する各画像の複数のオブジェクトの数、既存の方法と比較して5倍以上の増加、真の大規模な教師なし画像解釈への最初のステップ..}〜\ cite {Vo2019UnsupOptim}いくつかの重要な新奇性：（1）他の競合手法よりもグラウンドトゥルースオブジェクトとの大幅に高いオーバーラップを実現する、新しい顕著性ベースの領域提案アルゴリズムを提案します。 
[ABSTRACT] cnnが新しいメソッドとチームを組んだのはこれが初めてです。2つの監視された戦略を使用して、複数のオブジェクトを削除します。真の大規模な監視されていない画像解釈への最初のステップです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Geometric Attention for Prediction of Differential Properties in 3D
  Point Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_39.html">
      <font color="black">Geometric Attention for Prediction of Differential Properties in 3D
  Point Clouds</font>
    </a>
  </h2>
  <font color="black">法線ベクトルの予測と特徴線の抽出に関するいくつかの実験により、提案された手法の有用性を確立します。離散3Dデータ表現における微分幾何量の推定は、形状処理パイプラインの重要なステップの1つです。研究では、学習可能な方法でそのような特性を提供できる幾何学的注意メカニズムを提示します。 
[要約]合成的に現実的な幾何学的情報を点群で使用できます。この研究の結果は生の点群で開発されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning for Anomaly Detection: A Review -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_40.html">
      <font color="black">Deep Learning for Anomaly Detection: A Review</font>
    </a>
  </h2>
  <font color="black">主要な直観、目的関数、根底にある仮定、長所と短所を検討し、それらが前述の課題にどのように対処するかについて議論します。近年、ディープラーニングによって異常検出が可能になりました。つまり、深い異常検出が重要な方向性として浮上しています。高度なアプローチを必要とする独自の問題の複雑さと課題がまだいくつかあります。 
[要約]ディープラーニングにより異常検出が可能になったことは重要な方向性として浮上しています。ディープラーニングにより異常検出が可能になりました。つまり、ディープイノベーションが数十年にわたってトピックになっています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: A Convolutional Approach to Vertebrae Detection and Labelling in Whole
  Spine MRI -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_41.html">
      <font color="black">A Convolutional Approach to Vertebrae Detection and Labelling in Whole
  Spine MRI</font>
    </a>
  </h2>
  <font color="black">最後に、腰椎と脊椎全体のMRスキャンで脊柱側弯症の自動検出に使用するこの方法の臨床的適用性を示します。結果として得られるシステムは、脊椎全体のスキャンの挑戦的な臨床データセットで98.1％の検出率と96.5％の識別率を実現します。腰部のみのスキャンでの以前のシステムのパフォーマンスと同等またはそれ以上です。この方法は、さまざまなMRシーケンスの範囲にわたる腰部、頸部、および胸部のみのスキャンに変更なしで適用できます。 
[要約]システムを使用して、椎体の椎骨の角を特定できます。次に、システムを使用して、自己整合的な方法で椎骨のレベルを特定できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: TableBank: A Benchmark Dataset for Table Detection and Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_42.html">
      <font color="black">TableBank: A Benchmark Dataset for Table Detection and Recognition</font>
    </a>
  </h2>
  <font color="black">417Kの高品質のラベル付きテーブルを含むTableBankでは、ディープニューラルネットワークを備えた最先端のモデルを使用して、いくつかの強力なベースラインを構築しています。データセットとモデルは、\ url {https://github.com/doc- TableBankを公開し、テーブルの検出と認識のタスクでより深い学習アプローチを強化できることを願っています。 
[ABSTRACT]テーブルバンクを一般公開し、より深い学習技術を強化できることを願っています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-03-05">
        <br><font color="black">2019-03-05</font>
      </time>
    </span>
</section>
<!-- paper0: Federated Visual Classification with Real-World Data Distribution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CV/paper_43.html">
      <font color="black">Federated Visual Classification with Real-World Data Distribution</font>
    </a>
  </h2>
  <font color="black">そのために、種とランドマークの分類用に2つの新しい大規模データセットを導入し、実際のエッジ学習シナリオをシミュレートする現実的なユーザーごとのデータ分割を行います。データセットはオンラインで利用可能です。また、2つの新しいアルゴリズム（ FedVC、FedIR）をクライアントプールでインテリジェントにリサンプリングして再重み付けし、トレーニングの精度と安定性を大幅に向上させます。 
[ABSTRACT]データセンターのデータによると、ソースのデータは通常iidから遠く離れています。また、クライアントプールでインテリジェントにリサンプリングおよび再重み付けする2つの新しいアルゴリズムを開発し、トレーニングの精度と安定性を大幅に改善しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br><font color="black">2020-03-18</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Crossing Variational Autoencoders for Answer Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_0.html">
      <font color="black">Crossing Variational Autoencoders for Answer Retrieval</font>
    </a>
  </h2>
  <font color="black">この作業では、整列された回答で質問を生成し、整列された質問で回答を生成することにより、変分オートエンコーダーをクロスすることを提案します。意味論的情報は、言語モデルまたは質問から質問（回答から回答）の生成プロセスから学習しました。質問/回答のベクトル表現を学習することが重要な要素です。 
[ABSTRACT]自動トラックまたは自動エンコーダを学習することは、回答を見つけるための重要な要素です。現在の方法は、二重回答の回答で意味表現を学習しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br><font color="black">2020-05-06</font>
      </time>
    </span>
</section>
<!-- paper0: Improving Non-autoregressive Neural Machine Translation with Monolingual
  Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_1.html">
      <font color="black">Improving Non-autoregressive Neural Machine Translation with Monolingual
  Data</font>
    </a>
  </h2>
  <font color="black">非自己回帰（NAR）ニューラル機械翻訳は、通常、自己回帰（AR）モデルからの知識抽出によって行われます。強力なNARベースラインに加えて、WMT14 En-DeおよびWMT16 En-Roニュース翻訳タスクの実験結果が確認されますその単一言語のデータ拡張により、NARモデルのパフォーマンスが一貫して改善され、教師のARモデルのパフォーマンスに近づき、文献にある最良の非反復NARメソッドよりも同等または優れた結果が得られ、トレーニングプロセスの過適合を減らすのに役立ちます。このフレームワークでは、大規模な単一言語コーパスを活用して、NARモデルのパフォーマンスを向上させ、過剰適合を防止しながらARモデルの汎化能力を転送することを目標としています。 
[ABSTRACT] arモデルのパフォーマンスは多数の剖検と比較されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-02">
        <br><font color="black">2020-05-02</font>
      </time>
    </span>
</section>
<!-- paper0: Bilingual Dictionary Based Neural Machine Translation without Using
  Parallel Sentences -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_2.html">
      <font color="black">Bilingual Dictionary Based Neural Machine Translation without Using
  Parallel Sentences</font>
    </a>
  </h2>
  <font color="black">対訳辞書を検索して翻訳を学習する単言語話者の能力を動機として、対訳辞書と大規模な単言語コーパスを使用してMTシステムが達成できる潜在能力を、並列文に依存せずに確認するタスクを提案します。 ATは、バイリンガル辞書を使用して、ソース言語とターゲット言語の間のギャップを埋めるためのアンカーポイントを確立します。この課題に取り組むためにアンカートレーニング（AT）を提案します。 
[要約]我々は、mtシステムが対訳辞書と大規模な単言語コーパスを使用してどの程度の可能性を達成できるかを確認するタスクを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Improved Large-margin Softmax Loss for Speaker Diarisation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_3.html">
      <font color="black">Improved Large-margin Softmax Loss for Speaker Diarisation</font>
    </a>
  </h2>
  <font color="black">話者ダイアライゼーションシステムは現在、ボトルネックレイヤーの音声セグメントから生成された埋め込みを使用しています。これは、見えない話者を区別するために必要です。弁別的埋め込みの作成..したがって、このホワイトペーパーでは、ダイアライゼーション用のスピーカー埋め込みの品質を向上させるために、近似なしでマージンが大きいソフトマックス損失への一般的なアプローチを紹介します。 
[ABSTRACT]マージンが大きいソフトマックスを使用すると、話者のエラー率（ser）が大幅に改善されます。オーバーラップをトレーニングし、マージンが異なる単一話者の音声サンプルをトレーニングすることにより、最良の結果が得られ、全体で29.5％のser削減が実現しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br><font color="black">2019-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: TriggerNER: Learning with Entity Triggers as Explanations for Named
  Entity Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_4.html">
      <font color="black">TriggerNER: Learning with Entity Triggers as Explanations for Named
  Entity Recognition</font>
    </a>
  </h2>
  <font color="black">十分に研究された2つのNERデータセットに対して14kエンティティトリガーをクラウドソーシングしました。実験では、トリガー付き注釈付き文の20％だけを使用すると、従来の注釈付き文の70％を使用した場合と同等のパフォーマンスが得られます。 -従来のニューラルNERフレームワークよりも効果的です。 
[要約]提案されたモデルであるトリガーマッチングネットワークは、文章内のオブジェクトを人々が認識できるようにすることを目的としています。コスト効果の高い方法で監督を提供することが可能です。人間が文章内のエンティティを認識する方法を説明するのに役立ちます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-16">
        <br><font color="black">2020-04-16</font>
      </time>
    </span>
</section>
<!-- paper0: Relevance Transformer: Generating Concise Code Snippets with Relevance
  Feedback -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_5.html">
      <font color="black">Relevance Transformer: Generating Concise Code Snippets with Relevance
  Feedback</font>
    </a>
  </h2>
  <font color="black">Django、Hearthstone、CoNaLaなど、コード生成用の複数の標準ベンチマークデータセットで実験を行います。RelevanceTransformerは、多様性を適用しながら、デコードプロセスを既存の取得コードと同様にバイアスします。RelevanceTransformerと呼ばれる新しいモデルをさらに提案します。疑似関連性フィードバックを使用して外部知識を組み込みます。 
[要約]新世代のコード駆動型ツールが多くのideに組み込まれています。結果は、ブルー評価の使用のためのアプリケーションのモデルを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: TICO-19: the Translation Initiative for Covid-19 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_6.html">
      <font color="black">TICO-19: the Translation Initiative for Covid-19</font>
    </a>
  </h2>
  <font color="black">チームは9つのリソースの多い「ピボット」言語に加えて、リソースの少ない26言語、特にアフリカ、南アジア、東南アジアの言語をターゲットとしています。 。同じデータが表現されたすべての言語に翻訳されます。つまり、セット内の任意の言語の組み合わせに対してテストまたは開発を実行できます。さらに、チームはテストおよび開発データを翻訳メモリ（TMX）に変換します。ローカライザが任意の言語を使用する。 
[ABSTRACT]チームは26のリソースの少ない言語をターゲットにしています。これらには、9つの高および「ピボット」言語を含む高「ピボット」言語が含まれます。これには、アフリカ、南アジア、および東南アジアの言語が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-03">
        <br><font color="black">2020-07-03</font>
      </time>
    </span>
</section>
<!-- paper0: LMVE at SemEval-2020 Task 4: Commonsense Validation and Explanation
  using Pretraining Language Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_7.html">
      <font color="black">LMVE at SemEval-2020 Task 4: Commonsense Validation and Explanation
  using Pretraining Language Model</font>
    </a>
  </h2>
  <font color="black">サブタスクaについては、入力フォームが改善されたALBERTベースのモデルを使用して、2つのステートメント候補から常識ステートメントを抽出します。サブタスクbについては、ヒント文メカニズムによって拡張された多肢選択モデルを使用して、与えられたオプションから理由を選択します。なぜステートメントが常識に反するのでしょうか？システムの精度スコアは公式テストセットで95.6 / 94.9であり、評価後リーダーボードで7 $ ^ {th} $ / 2 $ ^ {nd} $ランク付けされています。 
[ABSTRACT] subtasd aの場合、albertベースのモデルを使用して、2つのステートメント候補から常識ステートメントを抽出します。パフォーマンスの向上に役立つサブタスク間の新しい転移学習戦略を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Reflection-based Word Attribute Transfer -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_8.html">
      <font color="black">Reflection-based Word Attribute Transfer</font>
    </a>
  </h2>
  <font color="black">実験結果は、我々の提案された方法が、対象の属性を持たない単語を変更することなく、与えられた単語の単語属性を転送できることを示している。しかし、そのような知識の開発は、単語と属性にとって非常にコストがかかる。この研究では、このような類推操作なしのリフレクションマッピングに基づく単語属性転送の新しい方法。 
[ABSTRACT]この作品では、王は男性であるという知識に基づいて女性を差し引きます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Spoken Language Representations with Neural Lattice Language
  Modeling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_9.html">
      <font color="black">Learning Spoken Language Representations with Neural Lattice Language
  Modeling</font>
    </a>
  </h2>
  <font color="black">意図検出と対話行動認識データセットの実験は、提案された方法が音声入力で評価された場合、強いベースラインより常に優れていることを示しています。コードはhttps://github.com/MiuLab/Lattice-ELMo。で入手できます。事前トレーニングアプローチは、音声データの需要を減らし、効率が向上します。 
[要約]私たちは、音声言語理解タスクに文脈化された表現を提供するために神経格子言語モデルをトレーニングするフレームワークを提案します。提案された方法は、音声入力で評価した場合、一貫して強力なベースラインよりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: A Broad-Coverage Deep Semantic Lexicon for Verbs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_10.html">
      <font color="black">A Broad-Coverage Deep Semantic Lexicon for Verbs</font>
    </a>
  </h2>
  <font color="black">手動で作成されたレキシコンとオントロジー、新しいオントロジーの概念と語彙のエントリからのブートストラップは、セマンティックロールの優先順位と含意公理とともに、辞書定義と例の解析から複数の制約を組み合わせることによって自動的に導出されます。COLLIE-Vは一般公開されています。進行状況言語の振る舞いをオントロジーの概念や公理に結び付ける幅広いカバレッジの語彙がないことで、深い言語理解が妨げられています。 
[ABSTRACT] verb.itの深い字句リソースであるcollie-vを開発しました。既存のリソースと一致するか、それを超えるワードネットとアイデアのカバレッジを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Hinting Semantic Parsing with Statistical Word Sense Disambiguation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_11.html">
      <font color="black">Hinting Semantic Parsing with Statistical Word Sense Disambiguation</font>
    </a>
  </h2>
  <font color="black">この作業では、統計WSDシステムからヒントを提供して、論理セマンティックパーサーがより良いセマンティックタイプの割り当てを生成し、結果の論理フォームの健全性を維持できるようにします。単語の意味と意味の役割は相互に依存しているため、単語の意味の割り当てのエラーにより、セマンティックロールの割り当てでエラーが発生します。その逆も同様です。Fスコアで最大10.5％の改善が見られますが、この改善は解析の構造的整合性を犠牲にして行われます。
[要約]結果の表現は感覚の意味を捉えます。しかし、この改善は解析の構造的完全性を犠牲にします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-29">
        <br><font color="black">2020-06-29</font>
      </time>
    </span>
</section>
<!-- paper0: PLATO-2: Towards Building an Open-Domain Chatbot via Curriculum Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/cs.CL/paper_12.html">
      <font color="black">PLATO-2: Towards Building an Open-Domain Chatbot via Curriculum Learning</font>
    </a>
  </h2>
  <font color="black">PLATO-2は中国語と英語の両方のデータでトレーニングされ、その有効性と優位性は包括的な評価によって検証され、新しい最先端の結果が得られます。最初の段階では、粗視化生成モデルがトレーニングされて応答を学習します1対1マッピングの簡素化されたフレームワークの下での生成。学習プロセスには2つの段階があります。 
[要約]学習プロセスには2つの段階があります。1つの段階は、きめの細かい生成モデルと評価モデルです</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-30">
        <br><font color="black">2020-06-30</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Revisiting Representation Learning for Singing Voice Separation with
  Sinkhorn Distances -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.AS/paper_0.html">
      <font color="black">Revisiting Representation Learning for Singing Voice Separation with
  Sinkhorn Distances</font>
    </a>
  </h2>
  <font color="black">エントロピー正則化の強度を高めることにより、混合信号の学習表現は、ほぼ完全に付加的で明確に構造化されたソースで構成されます。この作業では、歌声分離のタスクに焦点を当てた、音声表現の教師なし学習の方法を示します。 。私たちは、プロが制作した音楽録音の無料で利用可能なMUSDB18データセットでメソッドを評価し、エントロピー正則化の強度が小さいシンクホーン距離が、情報に基づく歌声分離のパフォーマンスをわずかに改善していることを示しています。 
[ABSTRACT]時間の表現を学習するために以前に提案された方法に基づいて構築します-ドメインの音楽信号を再パロイジングオートエンコーダーで</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Temporal Sub-sampling of Audio Feature Sequences for Automated Audio
  Captioning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.AS/paper_1.html">
      <font color="black">Temporal Sub-sampling of Audio Feature Sequences for Automated Audio
  Captioning</font>
    </a>
  </h2>
  <font color="black">エンコーダーからの出力として固定長ベクトルを使用するシーケンスツーシーケンス方式を採用し、エンコーダーのRNN間で時間サブサンプリングを適用します。結果は、考慮されたすべてのメトリックの改善を示しています。典型的なオーディオキャプション方法はディープニューラルネットワーク（DNN）に依存しており、DNNのターゲットは入力オーディオシーケンスを出力シーケンスの単語にマッピングすることです。 。メソッドは、入力オーディオシーケンスを出力ワードシーケンスにマップすることです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Improved Large-margin Softmax Loss for Speaker Diarisation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.AS/paper_2.html">
      <font color="black">Improved Large-margin Softmax Loss for Speaker Diarisation</font>
    </a>
  </h2>
  <font color="black">最後に、オーバーラップするスピーチの影響に対処するために、異なるトレーニングマージンを使用して、オーバーラップするスピーチが差別的な埋め込みの作成に及ぼす悪影響を減らします。ダイアライゼーションのためのスピーカー埋め込みの品質。AMI会議コーパスでの実験では、マージンが大きいソフトマックスを使用すると、スピーカーエラーレート（SER）が大幅に向上することが示されています。 
[ABSTRACT]マージンが大きいソフトマックスを使用すると、話者のエラー率（ser）が大幅に改善されます。オーバーラップをトレーニングし、マージンが異なる単一話者の音声サンプルをトレーニングすることにより、最良の結果が得られ、全体で29.5％のser削減が実現しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-10">
        <br><font color="black">2019-11-10</font>
      </time>
    </span>
</section>
<!-- paper0: Depthwise Separable Convolutions Versus Recurrent Neural Networks for
  Monaural Singing Voice Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.AS/paper_3.html">
      <font color="black">Depthwise Separable Convolutions Versus Recurrent Neural Networks for
  Monaural Singing Voice Separation</font>
    </a>
  </h2>
  <font color="black">信号対アーチファクト、信号対干渉、信号対歪みの標準メトリックを利用して、アブレーション研究を実施し、DWS-CNNのチャネル数とレイヤーがソース分離性能に及ぼす影響を調べますratio ..このホワイトペーパーでは、RNNを典型的な畳み込みの軽量で高速なバリアントである深度方向分離可能（DWS）畳み込みに置き換えるユースケースを示します。RNNアーキテクチャを使用して、歌声の分離に焦点を当てます。そして、RNNをDWS畳み込み（DWS-CNN）に置き換えます。 
[要約] rnnアーキテクチャを採用して、歌声の分離に焦点を当てます。rnnsをdws畳み込み（dws-source）に置き換えます。この方法では、20のみを使用します。rnnアーキテクチャのパラメータ量の57％</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: ResNeXt and Res2Net Structure for Speaker Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-07/eess.AS/paper_4.html">
      <font color="black">ResNeXt and Res2Net Structure for Speaker Verification</font>
    </a>
  </h2>
  <font color="black">VoxCelebデータの実験結果は、これらの2つの次元を増やすことはより深くまたはより広くするよりも効率的であることを実証しました。 ..モデルの表現能力を向上させるために、それぞれカーディナリティとスケールと呼ばれる別の2つの効果的な次元を導入します。 
[要約] resnextおよびres2netアーキテクチャは新しいシステムに基づいています。モデルの表現能力を向上させるために使用できます。ただし、単に幅または深さを増やすだけでは効率的ではありません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="<<rooot>>images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
