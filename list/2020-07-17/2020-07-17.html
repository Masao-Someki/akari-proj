<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-07-17の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Device-Robust Acoustic Scene Classification Based on Two-Stage
  Categorization and Data Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.SD/paper_0.html">
      <font color="black">Device-Robust Acoustic Scene Classification Based on Two-Stage
  Categorization and Data Augmentation</font>
    </a>
  </h2>
  <font color="black">コードが利用可能です：https://github.com/MihawkHu/DCASE2020_task1 ..タスク1bの開発データセットでは、モデルサイズが500KB未満で96.7 \％の精度を達成しています。4つの異なるCNNベースのアーキテクチャが検討されています2ステージの分類器を実装し、いくつかのデータ拡張手法も調査します。 
[要約]タスク1には、複数のデバイスで記録されたオーディオ信号のascが含まれます。10の異なる細かいクラスがタスク1に含まれます。4つの異なるcnnベースのアーキテクチャが、2ステージの分類器を実装するために検討されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Temporal-Framing Adaptive Network for Heart Sound Segmentation without
  Prior Knowledge of State Duration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.SD/paper_1.html">
      <font color="black">Temporal-Framing Adaptive Network for Heart Sound Segmentation without
  Prior Knowledge of State Duration</font>
    </a>
  </h2>
  <font color="black">このアプローチによって診断パフォーマンスがどの程度向上するかを理解するには、さらに作業が必要です。ただし、優れたセグメンテーションが診断の改善につながると想定するのは当然です。TFANベースの方法は、トレーニングセットAからランダムに選択された50の記録でトレーニングされました。 2016 PhysioNet / Computer in Cardiologyチャレンジおよび他の12の独立したトレーニングおよびテストデータベース（2099録音および52180ビート）でテストされました。結果：TFANベースのメソッドは、「Test-B」を除く12のデータベースすべてで優れたF1スコアを達成しました。 、平均96.7％で、最新の方法では94.6％です。 
[ABSTRACT] tfanベースの方法は、心音の状態の持続時間に関する知識を必要としないため、非洞調律に一般化される可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-09">
        <br><font color="black">2020-05-09</font>
      </time>
    </span>
</section>
<!-- paper0: Streaming Transformer ASR with Blockwise Synchronous Inference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.SD/paper_2.html">
      <font color="black">Streaming Transformer ASR with Blockwise Synchronous Inference</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、ニューラルトランスデューサーからヒントを得たブロック単位の同期復号化プロセスをトランスフォーマーデコーダーに導入することにより、追加のトレーニングなしでストリーミングE2E ASRシステム全体にブロック処理を拡張します。トランスフォーマーは、通常のバッチトランスフォーマーモデルによってガイドされます。また、知識蒸留技術によって精度がさらに向上することも確認しています。 
[ABSTRACT] transformerには、トランスフォーマーシステムを使用する新しいシステムがあります。これは、トランスフォーマーを使用してトランスフォーマーを変換するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-25">
        <br><font color="black">2020-06-25</font>
      </time>
    </span>
</section>
<!-- paper0: A time-scale modification dataset with subjective quality labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.SD/paper_3.html">
      <font color="black">A time-scale modification dataset with subjective quality labels</font>
    </a>
  </h2>
  <font color="black">2つの部分で構成されるトレーニングコンポーネントには、10のタイムスケールで6つのTSMメソッドを使用して処理された88のソースファイルが含まれ、テストコンポーネントには、4つのタイムスケールで3つの追加のメソッドを使用して処理された20のソースファイルが含まれます。結果の分析では、年齢と評価の質;エキスパートリスナーと非エキスパートリスナーが同等であること。聴覚に問題がある場合とない場合の参加者のわずかな違い。とモダリティのテスト間の最小限の違い..ラベル付きのデータセットは、http：//ieee-dataport.org/1987で入手できます。 
[ABSTRACT]データセットの分析では、年齢と評価の品質の間に相関関係はありません。結果の分析は、testing.datasetに使用するデータセットの分析の分析に基づいています。データセットには、スピーチ、ソロハーモニック、パーカッシブコンポーネントが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br><font color="black">2020-06-01</font>
      </time>
    </span>
</section>
<!-- paper0: Vibration Analysis in Bearings for Failure Prevention using CNN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.SD/paper_4.html">
      <font color="black">Vibration Analysis in Bearings for Failure Prevention using CNN</font>
    </a>
  </h2>
  <font color="black">提案された戦略の有効性は優れており、最先端の他のアプローチよりも優れていることがわかりました。これに続いて、摩耗レベルを分類し、回転システムを診断するためのAlexNetアーキテクチャに基づくCNNモデルを提案します。最初に、生の振動データの自動ラベル付けが実行され、シャノンのエントロピーと一緒に二乗平均平方根の特徴を使用してさまざまなレベルのベアリング摩耗を取得し、生のデータから特徴を抽出し、7つの異なるグループにグループ化します。ラベルを取得するためにK平均アルゴリズムを使用するクラス。 
[要約]畳み込みニューラルネットワークに基づく方法を提案します。この方法はcnnの情報システムに基づいています。この方法は、センサーの組み合わせに基づく可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br><font color="black">2020-05-06</font>
      </time>
    </span>
</section>
<!-- paper0: Audio Tagging by Cross Filtering Noisy Labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.SD/paper_5.html">
      <font color="black">Audio Tagging by Cross Filtering Noisy Labels</font>
    </a>
  </h2>
  <font color="black">複数の表現（LogmelやMFCCなど）は、オーディオの補足情報を提供するためのフレームワークの入力として使用されます。次に、2つのニューラルネットワークの連携と相互作用を介して、データセットをキュレートされたノイズの多いサブセットに分割します。ノイズの多いデータから正しくラベル付けされている可能性のあるデータを段階的に選択します。オーディオタグ付けデータセットFSDKaggle2018とFSDKaggle2019の両方で、他の競合するアプローチと比較して、実証結果がパフォーマンスの向上を示しています。 
[要約]このペーパーでは、ノイズの多いラベルの問題に対処するための新しいフレームワークを紹介します。これらには、正しくラベル付けされている可能性のあるデータを段階的に選択することが含まれます。ノイズの多いロバストな損失関数を使用して、誤ったラベルの悪影響を緩和します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Translate Reverberated Speech to Anechoic Ones: Speech Dereverberation
  with BERT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.SD/paper_6.html">
      <font color="black">Translate Reverberated Speech to Anechoic Ones: Speech Dereverberation
  with BERT</font>
    </a>
  </h2>
  <font color="black">私たちの方法を評価するために、3番目のCHiMEチャレンジからのデータを使用し、結果を他の方法と比較します。基本的なBERTモデルのバリエーションを提示します。ローカルのスペクトル時間情報を抽出するプレシーケンスネットワークおよび/またはバックボーンシーケンスモデルの前に、順序情報を提供します。この作業では、単一チャネルの音声残響除去が考慮されます。 
[要約]提案された方法は従来の方法wpeよりも優れており、最先端のblstmベースのシーケンスモデルと同等のパフォーマンスを実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: SoK: The Faults in our ASRs: An Overview of Attacks against Automatic
  Speech Recognition and Speaker Identification Systems -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.SD/paper_7.html">
      <font color="black">SoK: The Faults in our ASRs: An Overview of Attacks against Automatic
  Speech Recognition and Speaker Identification Systems</font>
    </a>
  </h2>
  <font color="black">その際、このスペースで適切な緩和策を提供するには、かなりの追加作業が必要であると主張します。このスペースの既存の研究を体系化し、コミュニティが将来の作業を評価できる分類法を提供することで、これを最初に示します。ニューラルネットワークでは、最近の研究により、音声および話者認識システムが、操作された入力を使用した攻撃に対して脆弱であることが示されています。 
[要約]音声およびスピーカーシステムの幅広い使用が、ニューラルネットワークの精度の向上によって可能になりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-13">
        <br><font color="black">2020-07-13</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Detection of Cue Points for DJ Mixing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.SD/paper_8.html">
      <font color="black">Automatic Detection of Cue Points for DJ Mixing</font>
    </a>
  </h2>
  <font color="black">プロのDJとのインタビューから確立したいくつかの一般的なルールを具体化するスイッチポイントの検出方法を紹介します。これらのルールの実装は、特徴抽出とノベルティ分析に基づいています。この方法で生成されたポイントの約96 \％は、DJミックスで使用するのに適した品質であることがわかりました。生成されたスイッチポイントの品質が評価されますそれらを、私たちがキュレーションした手動で注釈を付けたデータセットと比較し、それらを個別に評価します。 
[要約]キューポイントの品質は、手動で注釈を付けたデータセットと比較し、個別に評価することによって評価されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Flowtron: an Autoregressive Flow-based Generative Network for
  Text-to-Speech Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.SD/paper_9.html">
      <font color="black">Flowtron: an Autoregressive Flow-based Generative Network for
  Text-to-Speech Synthesis</font>
    </a>
  </h2>
  <font color="black">Flowtronは、音声合成の多くの側面（ピッチ、トーン、スピーチレート、リズム、アクセント）を制御するために操作できる潜在空間へのデータの可逆マッピングを学習します。平均見解スコア（MOS）は、Flowtronが最新の状態に一致することを示しています。音声品質の観点から最新のTTSモデル。さらに、音声変動の制御、サンプル間の補間、およびトレーニング中に見られるおよび見られない話者間のスタイル転送に関する結果を提供します。 
[ABSTRACT] flowgreはiafから洞察を借用し、高品質で表現力豊かなメルの予約注文に利用できるtacotron.itを改良しました-spectrovid</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br><font color="black">2020-05-12</font>
      </time>
    </span>
</section>
<!-- paper0: Neural MOS Prediction for Synthesized Speech Using Multi-Task Learning
  With Spoofing Detection and Spoofing Type Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.SD/paper_10.html">
      <font color="black">Neural MOS Prediction for Synthesized Speech Using Multi-Task Learning
  With Spoofing Detection and Spoofing Type Classification</font>
    </a>
  </h2>
  <font color="black">音声変換チャレンジ2018の結果を使用した実験は、2つの補助タスクを持つ提案されたMTLがMOS予測を改善することを示しています。このホワイトペーパーでは、スプーフィング検出（SD）およびスプーフィングタイプ分類（マルチタスク学習（MTL）を使用する方法を提案します。 STC）を使用してMOS予測モデルの一般化能力を改善します。さらに、焦点損失を使用して、MOS予測のSDとSTC間の相乗効果を最大化します。 
[ABSTRACT] mosデータは、mosデータがmossで見つからなかったことを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: CURL: Neural Curve Layers for Global Image Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_0.html">
      <font color="black">CURL: Neural Curve Layers for Global Image Enhancement</font>
    </a>
  </h2>
  <font color="black">広範な実験的評価で、CURLが最新の画像品質と最近提案されたディープラーニングアプローチを客観的および知覚的なメトリックの両方で生成し、複数のパブリックデータセットに新しい最先端のパフォーマンスを設定することを示します。と呼ばれるニューラルCURveレイヤー（CURL）は、新しいマルチカラースペースロスによって導かれる3つの異なるカラースペース（HSV、CIELab、RGB）で共同トレーニングされたマルチカラースペースニューラルレタッチブロックとして設計されています。 CURLは、このグローバルな画像変換ブロックをピクセルレベル（ローカル）の画像マルチスケールエンコーダーデコーダーバックボーンネットワークと組み合わせます。 
[ABSTRACT]私たちの方法は、ニューラルカーブレイヤーと呼ばれ、マルチカラースペースのニューラルレタッチブロックとして設計されています。人間ベースのプログラムを使用して、グローバル画像変換ブロックと信号を組み合わせます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-29">
        <br><font color="black">2019-11-29</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Nuclei Segmentation in Histopathological Images Using
  Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_1.html">
      <font color="black">Self-Supervised Nuclei Segmentation in Histopathological Images Using
  Attention</font>
    </a>
  </h2>
  <font color="black">組織病理学的画像における核のセグメンテーションと正確な位置特定は非常に困難な問題であり、ほとんどの既存のアプローチは監視付き戦略を採用しています。標準的な後処理を使用すると、私たちの方法は他の監視なしの核セグメンテーションアプローチよりも優れ、監視付きの同様のパフォーマンスを報告できることがわかります公開されているMoNuSegデータセットのデータ。タイルの拡大レベルを特定すると、核を特定するための予備的な自己監視信号を生成できることを示しています。 
[要旨]私たちの方法は、核のサイズと質感がパッチを抽出する倍率を決定できるという仮定に基づいて機能します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Iterative X-ray Spectroscopic Ptychography -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_2.html">
      <font color="black">Iterative X-ray Spectroscopic Ptychography</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、SPA（ADMMを使用した分光Ptychography）を紹介します。これは、分光ブラインドタイコグラフィー問題を反復的に解決する新しいアルゴリズムです。さまざまなスペクトル測定にわたって冗長性を組み合わせることにより、提案されたアルゴリズムは、標準の状態と比較して、より高い再構成品質を実現できます。 -アートの2段階の方法。調査中の材料の各化学成分には、光子エネルギーの関数として、特徴的な吸収と位相差があります。 
[ABSTRACT]分光法-タイコグラフィーでは、サンプルはさまざまなフォトンエネルギーで集束されたX線ビームを介してラスタライズされ、一連の無位相データが記録されます。提案されたアルゴリズムは、2ステップ法と比較してより高い再構成品質を実現できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-31">
        <br><font color="black">2019-05-31</font>
      </time>
    </span>
</section>
<!-- paper0: A review: Deep learning for medical image segmentation using
  multi-modality fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_3.html">
      <font color="black">A review: Deep learning for medical image segmentation using
  multi-modality fusion</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、マルチモーダル医療画像セグメンテーションタスクのためのディープラーニングベースのアプローチの概要を説明します。最初に、ディープラーニングとマルチモーダル医療画像セグメンテーションの一般的な原理を紹介します。異なるモダリティ間の複雑な関係を学ぶための融合戦略に注意。 
[ABSTRACT]ディープラーニングは最近、マルチモーダル医療画像セグメンテーションにも大きな関心を集めています。これは、大量のデータに対する自己学習と一般化能力のためです。一般に、以前のフュージョンと比較して、後の学習は融合法が十分に効果的である場合、より正確な結果</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-22">
        <br><font color="black">2020-04-22</font>
      </time>
    </span>
</section>
<!-- paper0: Unsupervised machine learning via transfer learning and k-means
  clustering to classify materials image data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_4.html">
      <font color="black">Unsupervised machine learning via transfer learning and k-means
  clustering to classify materials image data</font>
    </a>
  </h2>
  <font color="black">教師なし機械学習は、ラベルなしデータセットから知識を抽出し、最大の機械学習パフォーマンスを達成するための重要な機会を提供します。感度分析は、分類パフォーマンスに対する各ステップの影響をよりよく理解するために行われます。ノースイースタン大学鋼表面欠陥データベースには顕微鏡写真が含まれています画像分類のモデルのトレーニングと評価に便利な形式で、熱間圧延鋼で観察された6つの異なる欠陥の組み合わせ。 
[要約]人気のある微細構造データセットで画像を分類するための教師なし機械学習システム。モデルを使用して、再トレーニングせずに新しい画像を分類できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: SSN: Soft Shadow Network for Image Compositing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_5.html">
      <font color="black">SSN: Soft Shadow Network for Image Compositing</font>
    </a>
  </h2>
  <font color="black">この直感に従い、SSNをトレーニングして、オブジェクトのアイコンビューのソフトシャドウをレンダリングします。パイプラインは、最初にハードシャドウをサンプリングしてソフトシャドウベースのセットを計算します。SSNは入力としてオブジェクトカットアウトマスクを使用するため、イメージタイプに依存しません。絵画やベクターアートなど。 
[要約]オブジェクトの3D形状をそのシルエットから推測することは不明確になる可能性があります。アイコン表示の場合、人間が2D投影から3D彫刻を取得するのは簡単です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: SHE-MTJ Circuits for Convolutional Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_6.html">
      <font color="black">SHE-MTJ Circuits for Convolutional Neural Networks</font>
    </a>
  </h2>
  <font color="black">このネットワークを使用したMNIST手書き数字データセットを使用した画像分類の研究は、シミュレーションによって提供されます。エミュレートされたネットワークは、画像ごとに約100 nJのコストで90〜95 \％の画像分類精度を実現します。重みの変更の影響表現精度、MAAPセット内のデバイスプロセス変動の重大度、および計算の冗長性が提供されます。 
[要約]エミュレートされたネットワークは、画像あたり約100 njのコストで90〜95％の画像分類精度を実現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Quantization Guided JPEG Artifact Correction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_7.html">
      <font color="black">Quantization Guided JPEG Artifact Correction</font>
    </a>
  </h2>
  <font color="black">これにより、特定の品質設定用にトレーニングされたモデルよりも優れた最先端のパフォーマンスを単一のモデルで実現できます。積極的な量子化設定の場合、これにより画像品質が著しく低下します。 JPEGファイルの量子化マトリックスによってパラメーター化されます。 
[ABSTRACT]現在の状態-最新の方法では、品質設定ごとに異なるモデルをトレーニングする必要があり、実際のアプリケーションが大幅に制限されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-17">
        <br><font color="black">2020-04-17</font>
      </time>
    </span>
</section>
<!-- paper0: Joint Cross-Modality Super Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_8.html">
      <font color="black">Joint Cross-Modality Super Resolution</font>
    </a>
  </h2>
  <font color="black">CMSRが入力画像の解像度を向上させ、アーティファクトや無関係な詳細を導入することなく、控えめな方法でRGBの対応物から貴重な情報を得ることに成功したことを示します。は、以前の方法とは異なり、弱く位置合わせされた画像を処理するように設計されています。さらに、入力画像が完全に位置合わせされることはないため、フュージョンプロセス中にさらにアーティファクトが発生します。 
[ABSTRACT]システムは、クロスモダリティの超解像のためのネットワークです。弱い整列画像を処理するように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br><font color="black">2020-04-21</font>
      </time>
    </span>
</section>
<!-- paper0: EfficientHRNet: Efficient Scaling for Lightweight High-Resolution
  Multi-Person Pose Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_9.html">
      <font color="black">EfficientHRNet: Efficient Scaling for Lightweight High-Resolution
  Multi-Person Pose Estimation</font>
    </a>
  </h2>
  <font color="black">ベースラインEfficientHRNetは、HRNetと比較して0.4％の精度向上を実現しながら、浮動小数点演算を34％削減します。さらに、バックボーンEfficientNetをベースラインB0と残りのEfficientHRNetの下で共同でスケーリングするための公式を提供します。 EfficientHRNetは、あらゆるレベルで、他のボトムアップ2D人間の姿勢推定アプローチよりも計算効率が高く、競争力の高い精度を実現しています。 
[ABSTRACT] efficienthrnetは軽量の2D人間の姿勢推定器のファミリーです。他の最先端のアプローチと比較して大幅にコストを削減して、高解像度モデルを作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: An Efficient Mixture of Deep and Machine Learning Models for COVID-19
  and Tuberculosis Detection Using X-Ray Images in Resource Limited Settings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_10.html">
      <font color="black">An Efficient Mixture of Deep and Machine Learning Models for COVID-19
  and Tuberculosis Detection Using X-Ray Images in Resource Limited Settings</font>
    </a>
  </h2>
  <font color="black">最前線の臨床医は、症状のある患者が確かにCOVID-19を持っているかどうかを迅速に評価する必要があります。さらに、結核（TB）はいくつかの低中所得国で依然として主要な健康問題であり、その一般的な症状には発熱、咳などがありますCOVID-19と同様に、疲労感。COVID-19、ウイルス性肺炎、細菌性肺炎、結核、および健康な症例のバランスの取れた数を含む、X線胸部画像の5つのクラスのデータセットをまとめました。 
[ABSTRACT]このタスクの難しさは、バイオテクノロジーテストにアクセスできない可能性のある低リソース設定では健全です。これらの要因には、TBおよび健全なケースとCovidが含まれます。 -特にリソース-限られた設定</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: DeepInit Phase Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_11.html">
      <font color="black">DeepInit Phase Retrieval</font>
    </a>
  </h2>
  <font color="black">このペーパーでは、データ駆動型の深生成モデルを使用して、いくつかの強度測定のみから信号を再構築したいという、困難な位相回復問題を解決する方法を示します。私たちのハイブリッドアプローチが非常に高い再構築結果を提供できることを経験的に示しています。重大なジェネレーターモデルのエラーがある場合でも、低いサンプリングレートで。 
[ABSTRACT]これらの単純なアルゴリズムは、最適化に近い状態で初期化された場合に適切に機能することが知られていますが、それ以外の場合は非営利に苦しんでいます。最適</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Cloud Rendering-based Volumetric Video Streaming System for Mixed
  Reality Services -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_12.html">
      <font color="black">Cloud Rendering-based Volumetric Video Streaming System for Mixed
  Reality Services</font>
    </a>
  </h2>
  <font color="black">ブラウザーベースのクライアントとMicrosoft HoloLensクライアントの両方を使用してシステムをデモします。これを軽減するために、レンダリングを強力なクラウド/エッジサーバーにオフロードし、レンダリングされた2Dビューのみをクライアントに送信するボリュームビデオストリーミングシステムを提案します私たちのアプリケーションには、同じサーバー実装を使用して、さまざまな拡張現実/複合現実クライアントを簡単に展開できる汎用インターフェースが含まれています。 
[要旨] 6dofの頭の動きを予測する手法を使用して、処理チェーンのさまざまな部分でのレイテンシを低く抑えます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-05">
        <br><font color="black">2020-03-05</font>
      </time>
    </span>
</section>
<!-- paper0: Layer-Wise Adaptive Updating for Few-Shot Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_13.html">
      <font color="black">Layer-Wise Adaptive Updating for Few-Shot Image Classification</font>
    </a>
  </h2>
  <font color="black">少数ショット画像分類（FSIC）は、これらのカテゴリのいくつかの画像からの学習によって新しいカテゴリを認識するモデルを必要とし、多くの注目を集めています。最近、メタ学習ベースの方法がFSICの有望な方向として示されています。 。一般的に、彼らは簡単な微調整の重みを学習するようにメタ学習者（メタ学習モデル）をトレーニングし、FSICタスクを解くとき、メタ学習者は少数の自身で更新することにより、タスク固有のモデルに効率的に微調整しますタスクの画像。 
[ABSTRACT]調査により、メタ学習者はfsicのパフォーマンスを向上させるために、これらの最下層を更新するよりも最上位層を更新することを大いに好む可能性があることがわかりました。メタ学習ベースのツール-fsicの適応的更新（lwau）メソッド。より効率的に学習することが可能です。少なくとも5回</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: U-Net Based Architecture for an Improved Multiresolution Segmentation in
  Medical Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_14.html">
      <font color="black">U-Net Based Architecture for an Improved Multiresolution Segmentation in
  Medical Images</font>
    </a>
  </h2>
  <font color="black">さらに、mrU-Netを使用すると、U-Netと比較して、LUNAおよびDRIVEデータセットのトレーニングレートが速くなりました。U-Netをベースアーキテクチャとして使用し、それを変更して、イメージセグメンテーションパフォーマンスを向上させました。皮膚病変写真、肺コンピュータ断層撮影（CT）画像（LUNAデータセット）、網膜画像（DRIVEデータセット）、前立腺磁気共鳴（MR）画像（PROMISE12データセット）など、4つの異なる医療データセットのネットワーク。 
[要約]提案されたアーキテクチャは、u-netのマルチ解像度画像セグメンテーションパフォーマンスを向上させるように設計されています。印象的な機能は、mru-netと比較して、画像-派生機能を抽出する機能が高いことです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Benchmarking Differentially Private Residual Networks for Medical
  Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_15.html">
      <font color="black">Benchmarking Differentially Private Residual Networks for Medical
  Imagery</font>
    </a>
  </h2>
  <font color="black">モデルの精度とそれが保証するプライバシーのレベルとの間のトレードオフを分析し、これらの理論的なプライバシーの保証が実際の医療環境で実際にどれほど有用であるかを評価するために、さらに詳しく調べます。このホワイトペーパーでは、医療画像に適用した場合の$ \ epsilon $ -Differential Privacy（DP）の有効性。Local-DPとDP-SGDの2つの堅牢な差分プライバシーメカニズムを比較し、医療画像記録を分析する際のパフォーマンスをベンチマークします。 
[要約] 2つの堅牢なプライバシーメカニズムを比較します：ローカル-dpとdp-sgd</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-27">
        <br><font color="black">2020-05-27</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Task Pruning for Semantic Segmentation Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_16.html">
      <font color="black">Multi-Task Pruning for Semantic Segmentation Networks</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、セマンティックセグメンテーションネットワークのチャネルプルーニングに焦点を当てます。したがって、セグメンテーションネットワークの冗長性を特定するために、マルチタスクチャネルプルーニングアプローチを紹介します。任意のレイヤーのチャネルに対する各畳み込みフィルターの重要性は、分類およびセグメンテーションタスク。 
[要約]ディープニューラルネットワークを圧縮および高速化する作業は多数ありますが、セマンティックセグメンテーションネットワークに直接適用することはできません。セグメンテーションネットワークの冗長性を識別するには、ブーストが必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Image Processing and Quality Control for Abdominal Magnetic Resonance
  Imaging in the UK Biobank -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_17.html">
      <font color="black">Image Processing and Quality Control for Abdominal Magnetic Resonance
  Imaging in the UK Biobank</font>
    </a>
  </h2>
  <font color="black">2点のディクソン取得の約98.1％が正常に処理され、品質管理に合格し、高解像度T1加重3Dボリュームの99.98％が成功しました。ディクソンシリーズの脂肪水交換の検出は、ディープラーニングによって実行されます。モデルと自動的に修正されます。生データの問題を検出し、可能な場合は修正するために品質管理手順が組み込まれています。 
[要約]ここで提示された発見は、画像を使用しようとする科学者にとって非常に貴重です-腹部のMRIプロトコルから派生した表現型。約99。肝臓をカバーするシングルスライスマルチエコー取得の98％が正常に処理され、品質管理に合格しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-02">
        <br><font color="black">2020-07-02</font>
      </time>
    </span>
</section>
<!-- paper0: Low-latency Cloud-based Volumetric Video Streaming Using Head Motion
  Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_18.html">
      <font color="black">Low-latency Cloud-based Volumetric Video Streaming Using Head Motion
  Prediction</font>
    </a>
  </h2>
  <font color="black">私たちの結果は、提示されたモデルが、予測が実行されないベースラインシステムと比較して、M2Pレイテンシによって引き起こされるレンダリングエラーを低減することを示しています。ヘッドモーション予測モデルを開発し、さまざまな先読みのM2Pレイテンシを削減する可能性を調査しました時間..追加されたレイテンシを補正するために、将来のユーザーポーズの予測が必要です。 
[ABSTRACT]システムはmitの頭の動き予測モデルによって開発されました。異なるルックのm2pレイテンシを削減する可能性を検討しました。これは、時代遅れです。また、モバイルデバイスの資金調達額を削減することもできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-17">
        <br><font color="black">2020-01-17</font>
      </time>
    </span>
</section>
<!-- paper0: Enhanced detection of fetal pose in 3D MRI by Deep Reinforcement
  Learning with physical structure priors on anatomy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_19.html">
      <font color="black">Enhanced detection of fetal pose in 3D MRI by Deep Reinforcement
  Learning with physical structure priors on anatomy</font>
    </a>
  </h2>
  <font color="black">胎児MRIは、画像のアーチファクトを引き起こし、実行可能な診断画像のコントラストのセットを制限する、予測不可能な実質的な胎児の動きによって大きく制約されます。モーションアーティファクトの現在の軽減策は、主に高速なシングルショットMRIと遡及的なモーション補正によって実行されます。このタスクでは15のエージェントが展開され、DRLによって15のランドマークを同時に検出します。 
[ABSTRACT]モーションアーティファクトの現在の軽減は、通常、高速のシングルショットmriと遡及的なモーション補正によって実行されます。現在、高速のシングルショットmriに基づいており、新しいdrlは胎児のランドマーク検出に新しいアプローチを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: 6D Camera Relocalization in Ambiguous Scenes via Continuous Multimodal
  Inference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.IV/paper_20.html">
      <font color="black">6D Camera Relocalization in Ambiguous Scenes via Continuous Multimodal
  Inference</font>
    </a>
  </h2>
  <font color="black">$ \ href {https://multimodal3dvision.github.io} {multimodal3dvision.github.io} $でコードとデータセットをリリースする予定です。Winner-Takes-Allトレーニングスキームを組み込むことにより、最終的に混合モデルを取得しますこれは、シーンのあいまいさを説明するのに適していますが、混合密度ネットワークでよくある問題であるモードの崩壊に悩まされることはありません。曖昧な環境でカメラのローカリゼーションの研究を促進するために特別に設計された新しいデータセットを紹介し、また、あいまいなシーンとあいまいでないベンチマークデータセットの両方の実際のデータ。 
[ABSTRACT]新しいデータセットは、あいまいな環境でのカメラのローカリゼーション調査を促進するように設計されています。「ビンガム」と多変量ガウスの混合を使用して、カメラのポーズの位置をモデル化します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Augmenting Visual Place Recognition with Structural Cues -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_0.html">
      <font color="black">Augmenting Visual Place Recognition with Structural Cues</font>
    </a>
  </h2>
  <font color="black">具体的には、これらの構造的手がかりは、構造認識モーションを使用して取得されるため、場所の認識に追加のセンサーは必要ありません。特に、記述子の次元が低い場合は、最先端の記述子を最大90％アウトパフォームします。は、構造ベースのモーションポイントクラウドから派生したボクセルグリッドを入力として取る3D CNNを使用して、画像ベースの場所認識に通常使用される2D畳み込みニューラルネットワーク（CNN）を拡張することによって実現されます。 
[ABSTRACT]これらの構造的手がかりの除去は、動きに基づく構造に基づいています。これは、場所の認識にセンサーが不要であることを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-29">
        <br><font color="black">2020-02-29</font>
      </time>
    </span>
</section>
<!-- paper0: Face Identification using Local Ternary Tree Pattern based Spatial
  Structural Components -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_1.html">
      <font color="black">Face Identification using Local Ternary Tree Pattern based Spatial
  Structural Components</font>
    </a>
  </h2>
  <font color="black">LTTPパターンは、LTTP左奥行き（LTTP LD）、LTTP左奥行き（LTTP LB）、LTTP右奥行き（LTTP RD）、LTTP右奥行き（LTTP RB）などの4つの形式で生成できます。機能を抽出するために、ツリーは、各ブロックに8つの隣接ピクセルがある各ピクセルに対して形成されます。実験的評価は、さまざまな環境でキャプチャされたさまざまな顔を考慮した最も有望な結果を示しています。 
[要約]実験的評価は、さまざまな環境でキャプチャされたさまざまな顔に基づいて最も有望な結果を示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-05-02">
        <br><font color="black">2019-05-02</font>
      </time>
    </span>
</section>
<!-- paper0: Efficiently Calibrating Cable-Driven Surgical Robots with RGBD Fiducial
  Sensing and Recurrent Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_2.html">
      <font color="black">Efficiently Calibrating Cable-Driven Surgical Robots with RGBD Fiducial
  Sensing and Recurrent Neural Networks</font>
    </a>
  </h2>
  <font color="black">提案された方法では、1800サンプルのデータ収集には31分かかり、モデルトレーニングには1分未満かかります。FLSペグ転送外科医トレーニングタスクの開ループ軌道の実行結果は、最良のモデルが成功率を39.4％から増加させることを示唆しています。基準軌道のテストセットの結果は、訓練されたモデルが物理ロボットの平均追跡誤差を2.96 mmから0.65 mmに減らすことができることを示唆しています。 
[要約]総合的に調整されたロボットは、新しいモデルを開発するために使用できます。センサーは、ロボットの効果を追跡するために使用されます。これらのモデルには、データ分析とデータ分析が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-19">
        <br><font color="black">2020-03-19</font>
      </time>
    </span>
</section>
<!-- paper0: FoveaBox: Beyond Anchor-based Object Detector -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_3.html">
      <font color="black">FoveaBox: Beyond Anchor-based Object Detector</font>
    </a>
  </h2>
  <font color="black">FoveaBoxでは、インスタンスを隣接する機能レベルに割り当てて、モデルをより正確にします。標準的なベンチマークでその効果を実証し、広範な実験分析を報告します。シンプルで効果的なアプローチは、強固なベースラインとして役立ち、将来の研究を容易にするのに役立ちますオブジェクト検出用..コードはhttps://github.com/taokong/FoveaBoxで公開されています。 
[ABSTRACT]コードは無料で公開されています。foveaboxは、モデルをより正確にするために近くの機能レベルに割り当てられているオブジェクトの例です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-08">
        <br><font color="black">2019-04-08</font>
      </time>
    </span>
</section>
<!-- paper0: An Uncertainty-based Human-in-the-loop System for Industrial Tool Wear
  Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_4.html">
      <font color="black">An Uncertainty-based Human-in-the-loop System for Industrial Tool Wear
  Analysis</font>
    </a>
  </h2>
  <font color="black">特に、機械加工業界における摩耗分析の実際のマルチクラス画像セグメンテーションタスクで上記の利点を実証します。一般化可能性を確保するために、提示されたアプローチが、一般に入手可能なCityscapesデータセットで同様の結果を達成することを示します。システムは人間の専門家を利用して、これらの失敗した予測に手動でラベルを付けます。 
[ABSTRACT]以前の研究は、予測の質がモデルの不確実性と相関していることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-14">
        <br><font color="black">2020-07-14</font>
      </time>
    </span>
</section>
<!-- paper0: FeatMatch: Feature-Based Augmentation for Semi-Supervised Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_5.html">
      <font color="black">FeatMatch: Feature-Based Augmentation for Semi-Supervised Learning</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、CIFAR-100やmini-Imagenetなどのより大きなデータセットにスケールアップしながら、より小さなデータセット（CIFAR-10およびSVHN）の現在の最先端技術に匹敵することを実証します。 （\ textit {eg、} mini-ImageNetでの絶対17.44 \％の増加）。最近の最先端の半教師あり学習（SSL）方式では、コアコンポーネントとして画像ベースの変換と整合性の正則化を組み合わせて使用しています。 。DomainNetでメソッドをさらにテストし、ドメイン外のラベルなしデータに対する堅牢性を実証し、厳密なアブレーションと分析を実行してメソッドを検証します。 
[要約]以前の方法は、従来のデータ拡張などの単純な変換に限定されています。これらには、2つの画像の軽量な組み合わせが含まれます。これらは、一貫性ベースの正則化損失の一部として使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: CURL: Neural Curve Layers for Global Image Enhancement -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_6.html">
      <font color="black">CURL: Neural Curve Layers for Global Image Enhancement</font>
    </a>
  </h2>
  <font color="black">曲線は完全に区別可能であり、写真の強化（RGBからRGB）を含むさまざまなコンピュータービジョンの問題に対してエンドツーエンドでトレーニングされ、画像形成のための画像信号処理パイプライン（RAWからRGB）の一部としてトレーニングされます。ニューラルCURveレイヤー（CURL）と呼ばれる方法は、新しいマルチカラースペースロスによって導かれる3つの異なるカラースペース（HSV、CIELab、RGB）で共同トレーニングされたマルチカラースペースニューラルレタッチブロックとして設計されています。評価では、CURLが客観的および知覚的メトリックの両方で最新の画像品質と最近提案されたディープラーニングアプローチを生成し、複数のパブリックデータセットに新しい最先端のパフォーマンスを設定していることを示しています。 
[ABSTRACT]私たちの方法は、ニューラルカーブレイヤーと呼ばれ、マルチカラースペースのニューラルレタッチブロックとして設計されています。人間ベースのプログラムを使用して、グローバル画像変換ブロックと信号を組み合わせます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-29">
        <br><font color="black">2019-11-29</font>
      </time>
    </span>
</section>
<!-- paper0: VIPriors Object Detection Challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_7.html">
      <font color="black">VIPriors Object Detection Challenge</font>
    </a>
  </h2>
  <font color="black">私たちは、softnmsとモデルフュージョンを巧みに使用することで多くの利益を得ます。ゼロからのトレーニングにより適したモデルを慎重に選択します。オブジェクト検出は、その完全なアプリケーションで多くの研究者の注目を集めていますが、それでも難しい課題です。 
[ABSTRACT]モデルモデルモデルは、ゼロからトレーニングできるモデルモデルです。モデルは現在マンチェスター大学でテスト中です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Cascade Network with Guided Loss and Hybrid Attention for Two-view
  Geometry -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_8.html">
      <font color="black">Cascade Network with Guided Loss and Hybrid Attention for Two-view
  Geometry</font>
    </a>
  </h2>
  <font color="black">次に、ベイジアン注意深いコンテキストの正規化（BACN）とチャネル単位の注意（CA）を統合する機能を抽出するハイブリッド注意ブロックを提案します。このホワイトペーパーでは、2ビュージオメトリの高性能ネットワークの設計に取り組んでいます..最後に、ガイド付き損失とハイブリッドアテンションブロックに基づいて、カスケードネットワークは、より優れたパフォーマンスのために結果を徐々に最適化するように設計されています。 
[ABSTRACT]最初に誘導損失を提案し、理論的に損失とfnの間の直接的な負の相関を確立します-正と負のクラスの重みを動的に調整して測定します。ネットワークは、より優れたパフォーマンスのために結果を徐々に最適化するように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-11">
        <br><font color="black">2020-07-11</font>
      </time>
    </span>
</section>
<!-- paper0: Odyssey: Creation, Analysis and Detection of Trojan Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_9.html">
      <font color="black">Odyssey: Creation, Analysis and Detection of Trojan Models</font>
    </a>
  </h2>
  <font color="black">さまざまな現実世界の問題の解決におけるディープニューラルネットワーク（DNN）モデルの成功に加えて、完全性を低下させることを目的とするこれらのモデルへの脅威を高めます。トロイの木馬攻撃は、モデルの操作や変更を伴う最近のデータ汚染攻撃の1つです。既存のトロイの木馬検出器とは異なり、堅牢な検出器はトロイの木馬攻撃に関する想定に依存すべきではありません。 
[要約]トロイの木馬攻撃の影響を検出する新しいシステムが開発されています。これは、攻撃の影響を受ける可能性のあるdnnモデルの分析に基づいています。これらのモデルは、これらのdnnモデルの分析に基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Applying Deep-Learning-Based Computer Vision to Wireless Communications:
  Methodologies, Opportunities, and Challenges -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_10.html">
      <font color="black">Applying Deep-Learning-Based Computer Vision to Wireless Communications:
  Methodologies, Opportunities, and Challenges</font>
    </a>
  </h2>
  <font color="black">並行開発として、視覚データは日常生活で普遍的になり、ユビキタス低コストカメラによって簡単に生成されました。実験結果は、当社のフレームワークがベースライン法よりもはるかに高い精度を達成し、その視覚データがMIMOビームフォーミングシステム。最後に、ワイヤレス通信にDLベースのCVを適用する機会と課題について説明します。 
[要約]この記事の主な目的は、無線通信で使用されたdlの適用に関するアイデアを紹介することです。resnet、3-実際の出力を使用して、既存のシステムから将来のビームオブジェクトを予測することができます。この方法を使用して開発できます。たとえば新しいシステム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-10">
        <br><font color="black">2020-06-10</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Nuclei Segmentation in Histopathological Images Using
  Attention -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_11.html">
      <font color="black">Self-Supervised Nuclei Segmentation in Histopathological Images Using
  Attention</font>
    </a>
  </h2>
  <font color="black">私たちの実験は、標準の後処理により、他の教師なしの核セグメンテーションアプローチよりも優れた方法で、公的に入手可能なMoNuSegデータセットで教師付きの核セグメンテーションアプローチと同様のパフォーマンスを報告できることを示しています。この研究では、スライド全体の組織病理学の画像。私たちの方法は、核のサイズとテクスチャーがパッチを抽出する倍率を決定できるという仮定に基づいて機能します。 
[要旨]私たちの方法は、核のサイズと質感がパッチを抽出する倍率を決定できるという仮定に基づいて機能します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: TrashCan: A Semantically-Segmented Dataset towards Visual Detection of
  Marine Debris -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_12.html">
      <font color="black">TrashCan: A Semantically-Segmented Dataset towards Visual Detection of
  Marine Debris</font>
    </a>
  </h2>
  <font color="black">これらは可能な最良の検出結果を表すものではありませんが、TrashCanデータセットでのインスタンスセグメンテーションとオブジェクト検出における将来の作業の初期ベースラインを提供します。データセットには、異なるオブジェクトクラス構成に対応する2つのバージョン、TrashCan-MaterialとTrashCan-Instanceがあります。最終的な目標は、搭載ロボットの展開に適した効率的で正確なゴミ検出方法を開発することです。 
[ABSTRACT]データセットには2つのバージョンtrashcan-materialとgarbagecan-examplesがあり、さまざまなオブジェクトクラス構成のさまざまな開発に対応しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Neuro-Endo-Trainer-Online Assessment System (NET-OAS) for
  Neuro-Endoscopic Skills Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_13.html">
      <font color="black">Neuro-Endo-Trainer-Online Assessment System (NET-OAS) for
  Neuro-Endoscopic Skills Training</font>
    </a>
  </h2>
  <font color="black">Neuro-Endo-Trainerは、ビデオベースのオフライン評価システムを使用した経鼻的経蝶形骨手術スキルトレーニング用に開発されたボックストレーナーでした。15人の初心者参加者のグループに関する検証研究では、神経内視鏡の取り扱いに関する技術スキルの向上が示されています。ピックアンドプレイスアクティビティを実行する際のツールです。現在の調査の目的は、スタンドアロンのシステムにオンライン評価を提供することにより、修正バージョン（Neuro-Endo-Trainer-Online Assessment System（NET-OAS））を開発することでした。リアルタイムのフィードバック。 
[ABSTRACT] neuro-エンド-トレーナー-オンライン評価システム（net-oas）には既存のトレーニングシステムが必要です。他のトレーニングシステムには、神経-内視鏡検査とニューロザコピーが含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Provable Worst Case Guarantees for the Detection of Out-of-Distribution
  Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_14.html">
      <font color="black">Provable Worst Case Guarantees for the Detection of Out-of-Distribution
  Data</font>
    </a>
  </h2>
  <font color="black">トレーニング時に見られるOODデータセットを超えて一般化するOODデータの信頼性に重要な境界がある可能性があることを示します。このホワイトペーパーでは、OODの信頼性が低いだけでなく、ポイントだけでなく、その周りの$ l_ \ infty $ボールにもあります。さらに、通常予測パフォーマンスの大幅な低下を伴う認定された敵対的な堅牢性とは対照的に、精度を大幅に損なうことなく、最悪の場合のOOD検出の認定された保証が可能です。 
[ABSTRACT]これは安全性の問題です-重要なアプリケーション。分類子の不確実性の信頼できる評価は重要な特性です。これは人間の介入をトリガーしたり、低い状態に移行したりする可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: World-Consistent Video-to-Video Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_15.html">
      <font color="black">World-Consistent Video-to-Video Synthesis</font>
    </a>
  </h2>
  <font color="black">制限に対処するために、レンダリング中に過去に生成されたすべてのフレームを効率的かつ効果的に利用する新しいvid2vidフレームワークを導入します。いくつかの困難なデータセットに対する広範な実験結果は、世界の一貫性を達成する上でのアプローチの有効性を検証します-出力ビデオは全体で一貫していますレンダリングされた3Dワールド.. https://nvlabs.github.io/wc-vid2vid/ 
[ABSTRACT]これに加えて、レンダリング中に過去に生成されたすべてのフレームを効率的かつ効果的に利用する新しいvid2vidフレームワークを導入します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: A review: Deep learning for medical image segmentation using
  multi-modality fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_16.html">
      <font color="black">A review: Deep learning for medical image segmentation using
  multi-modality fusion</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、マルチモーダル医療画像セグメンテーションタスクのためのディープラーニングベースのアプローチの概要を説明します。最初に、ディープラーニングとマルチモーダル医療画像セグメンテーションの一般的な原理を紹介します。融合、融合方法が十分に効果的である場合、後の融合はより正確な結果を与えることができます。 
[ABSTRACT]ディープラーニングは最近、マルチモーダル医療画像セグメンテーションにも大きな関心を集めています。これは、大量のデータに対する自己学習と一般化能力のためです。一般に、以前のフュージョンと比較して、後の学習は融合法が十分に効果的である場合、より正確な結果</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-22">
        <br><font color="black">2020-04-22</font>
      </time>
    </span>
</section>
<!-- paper0: SAILenv: Learning in Virtual Visual Environments Made Simple -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_17.html">
      <font color="black">SAILenv: Learning in Virtual Visual Environments Made Simple</font>
    </a>
  </h2>
  <font color="black">オプティカルフローの計算負荷は、最新のGPUベースのたたみ込みネットワークまたはより古典的な実装を使用して実行された推定に匹敵します。科学コミュニティは、新しく提案されたアルゴリズムを評価するためのフレームワークの容易さと高品質から恩恵を受けると信じています独自のカスタマイズされた現実的な条件。このペーパーでは、シンプルでカスタマイズ可能に設計され、仮想3Dシーンで視覚認識を実験できる新しいプラットフォームSAILenvを紹介します。 
[要旨]すべてのアルゴリズムをインターフェースするために数行のコードが必要です。これにより、科学者は環境を簡単にカスタマイズでき、写実的な写実的な写実的な画像を活用できます。プロジェクトは高度な高度な高度なテクノロジーに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: SSN: Soft Shadow Network for Image Compositing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_18.html">
      <font color="black">SSN: Soft Shadow Network for Image Compositing</font>
    </a>
  </h2>
  <font color="black">私たちのパイプラインは、最初にハードシャドウをサンプリングして一連のソフトシャドウベースを計算します。この直感に従い、SSNをトレーニングして、オブジェクトのアイコンビューのソフトシャドウをレンダリングします。これにより、モデルで複雑な照明パターンを確認し、相互作用を学習できますライトと3Dジオメトリの間。 
[要約]オブジェクトの3D形状をそのシルエットから推測することは不明確になる可能性があります。アイコン表示の場合、人間が2D投影から3D彫刻を取得するのは簡単です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Negative Pseudo Labeling using Class Proportion for Semantic
  Segmentation in Pathology -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_19.html">
      <font color="black">Negative Pseudo Labeling using Class Proportion for Semantic
  Segmentation in Pathology</font>
    </a>
  </h2>
  <font color="black">実験は、提案された方法が共同検出CNNを分析することによって位置を一致させることができることを実証しました。この方法は弱い監視のみを使用しますが、私たちの方法のパフォーマンスは、最先端の監視された方法とほぼ同じでした。重要な前提は、共検出CNNが検出に加えて関連付けを暗黙的に学習することです。 
[ABSTRACT]細胞検出では、弱い-ラベルを使用して連続するフレームの細胞を検出できます。この方法は、最先端の監視方法とほぼ同じでした</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Complete & Label: A Domain Adaptation Approach to Semantic Segmentation
  of LiDAR Point Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_20.html">
      <font color="black">Complete & Label: A Domain Adaptation Approach to Semantic Segmentation
  of LiDAR Point Clouds</font>
    </a>
  </h2>
  <font color="black">LiDARデータのクロスドメインセマンティックラベリングの新しいベンチマークを使用した実験とアブレーション研究により、提案されたアプローチは、以前のドメイン適応手法よりも8.2〜36.6％優れたパフォーマンスを提供することが示されています。 、疎なボクセル補完ネットワーク（SVCN）を設計して、疎な点群の3Dサーフェスを完成させます。 
[要旨] 3dサーフェスを回復するために完全なラベルアプローチを使用します。次に、それらをポイントポイントポイントネットワークに渡します。3dサーフェスを回復するための詳細なアプローチも使用します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Unseen Object Instance Segmentation for Robotic Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_21.html">
      <font color="black">Unseen Object Instance Segmentation for Robotic Environments</font>
    </a>
  </h2>
  <font color="black">驚くべきことに、私たちのフレームワークは、RGBが非写実的である合成RGB-Dデータから学習することができます。この方法は、鋭く正確なセグメンテーションマスクを生成し、目に見えないオブジェクトインスタンスのセグメンテーションに対して最先端の方法よりも優れていることを示しています。 .. UOIS-Netは2つの段階で構成されます。最初に、深度でのみ動作して、2Dまたは3Dでオブジェクトインスタンスの中心投票を生成し、それらを大まかな初期マスクに組み立てます。 
[要約]提案された方法、uois-net、独立して利用された人工rgb。これらの初期環境はrgb.surprisinglyを使用して洗練されていますが、これらの初期マスクは洗練されていますが、</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Learning End-to-End Action Interaction by Paired-Embedding Data
  Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_22.html">
      <font color="black">Learning End-to-End Action Interaction by Paired-Embedding Data
  Augmentation</font>
    </a>
  </h2>
  <font color="black">具体的には、この方法では、まずペアの関係を使用して、埋め込みスペースで個々のアクションをクラスタリングします。次に、最初にペアにされた2つのアクションを、それぞれの近傍で他のアクションに置き換えて、新しいペアに組み立てることができます。2つのデータセットの実験結果は、印象的な効果と幅広い私たちの方法の応用展望。 
[ABSTRACT]新しいインタラクティブアクション翻訳タスクは、埋め込みスペースからエンドツーエンドのアクションインタラクションを学習することを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Black-Box Watermarking for Generative Adversarial Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_23.html">
      <font color="black">Black-Box Watermarking for Generative Adversarial Networks</font>
    </a>
  </h2>
  <font color="black">GANモデルの最初の透かしソリューションを提案します。ステガノグラフィ技術を利用して、GANトレーニングデータセットに透かしを入れ、データセットからGANモデルに透かしを転送し、生成された画像から透かしを検証します。透かしアプリケーションを生成された画像にさらに拡張します検出と帰属。これは、GANの誤用の深い偽物と責任の追跡に対するフォレンジックを促進する実用的な可能性を提供します。 
[要約]識別モデルを保護するために、いくつかの透かし手法が提案されています。ガンモデルには緊急の透かしソリューションを提案します。ステガノグラフィーのディープテクノラーニング特性は、ステガナリシス攻撃から透かし機密をサポートします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Defocus Blur Detection via Depth Distillation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_24.html">
      <font color="black">Defocus Blur Detection via Depth Distillation</font>
    </a>
  </h2>
  <font color="black">したがって、DBDのおおよそのソフトラベルとして深度情報を考慮し、知識の抽出に触発された共同学習フレームワークを提案します。 -wisely ..私たちの方法も、単一のGPUで30 fps以上で実行されます。これは、以前の作業より2倍高速です。 
[ABSTRACT]深度情報に加えて、深度情報をdbdに初めて導入します。シャープな領域は、深度推定のための強力な事前情報を提供します。ぼかし検出も、抽出された深度からメリットを得ます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: D2D: Learning to find good correspondences for image matching and
  manipulation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_25.html">
      <font color="black">D2D: Learning to find good correspondences for image matching and
  manipulation</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチの2つの重要な部分は、（i）両方の画像で学習した特徴を調整すること、および（ii）テスト時に最適な一致を選択するために使用される識別スコアを学習することです。ローカルマッチング、カメラローカリゼーション、3D再構成、画像のスタイル設定など、幅広いタスクで最先端の技術や競争力のある結果を達成するために使用されます。照明、視点、コンテキスト、および材料。 
[ABSTRACT]このモデルを使用して、幅広いタスクで最先端の技術または競争力を実現できることを実証しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Implicit Mesh Reconstruction from Unannotated Image Collections -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_26.html">
      <font color="black">Implicit Mesh Reconstruction from Unannotated Image Collections</font>
    </a>
  </h2>
  <font color="black">私たちのアプローチは、同様の監督を活用する以前の作業よりも改善され、実際にはより強力な監督を使用する方法と競争的に機能することを経験的に示しています。オブジェクトカテゴリ..学習の監視信号を導き出すために、a）レンダリング時の予測は利用可能な画像の証拠を説明する必要があり、b）推定された3D構造は、学習したピクセルからサーフェスへのマッピングと幾何学的に一致している必要があります。 
[ABSTRACT]私たちのアプローチは、同様の監督を活用する以前の作業よりも改善され、実際にはstronggroundを使用するメソッドに対して競合的に機能することを示しています。その結果、球の形状を予測することができるはずであることを実証しました。予測メッシュ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: CNN based Road User Detection using the 3D Radar Cube -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_27.html">
      <font color="black">CNN based Road User Detection using the 3D Radar Cube</font>
    </a>
  </h2>
  <font color="black">このレターは、低レベルのレーダーキューブデータを利用する、道路ユーザー（歩行者、自転車、自動車）を移動するための、レーダーベースの単一フレーム、マルチクラス検出方法を紹介します。レーダーターゲットは、ターゲットフィーチャを拡張して個別に分類されます。 3Dレーダーキューブのトリミングされたブロックをその位置の周囲に配置することで、局所的な速度分布における可動部品の動きをキャプチャします。 
[ABSTRACT]このメソッドは、レーダーターゲットとオブジェクトレベルのクラス情報を提供します。これらには、レーダーレーダーレーダー、レーダー、レーダーレーダー、オブジェクトレベルが含まれます。この分類ステップでは、畳み込みニューラルネットワークが提案されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-25">
        <br><font color="black">2020-04-25</font>
      </time>
    </span>
</section>
<!-- paper0: ATSO: Asynchronous Teacher-Student Optimization for Semi-Supervised
  Medical Image Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_28.html">
      <font color="black">ATSO: Asynchronous Teacher-Student Optimization for Semi-Supervised
  Medical Image Segmentation</font>
    </a>
  </h2>
  <font color="black">この問題を緩和するために、教師と生徒の最適化の非同期バージョンであるATSOを提案します。ATSOを2つの一般的な医用画像セグメンテーションデータセットで評価し、さまざまな半教師付き設定でその優れたパフォーマンスを示します。わずかな変更により、ATSOは自動運転データの自然画像セグメンテーション。 
[ABSTRACT]これは、自己学習と呼ばれる効果的な方法の働きです。それは、モデル自体が生成した疑似ラベルからモデルが学習することの難しさを指す、遅延学習と呼ばれる弱点を指摘します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-24">
        <br><font color="black">2020-06-24</font>
      </time>
    </span>
</section>
<!-- paper0: RetrieveGAN: Image Synthesis via Differentiable Patch Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_29.html">
      <font color="black">RetrieveGAN: Image Synthesis via Differentiable Patch Retrieval</font>
    </a>
  </h2>
  <font color="black">提案された方法が現実的で多様な画像を生成できることを実証するために、広範な定量的および定性的な実験を行います。ここで、取得したパッチは合理的で相互に互換性があります。コンテンツの作成や画像の編集など。この作品では、検索されたパッチを参照してシーンの説明から画像を合成することを目指しています。 
[ABSTRACT]検索されたパッチを参照としてシーンの説明から画像を合成することを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Quantization Guided JPEG Artifact Correction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_30.html">
      <font color="black">Quantization Guided JPEG Artifact Correction</font>
    </a>
  </h2>
  <font color="black">JPEGファイルの量子化マトリックスによってパラメーター化される新しいアーキテクチャーを作成することにより、この問題を解決します。これにより、単一のモデルで、特定の品質設定用にトレーニングされたモデルよりも最先端のパフォーマンスを実現できます。JPEG画像圧縮アルゴリズムは大きな圧縮率に対応できるため、最も一般的な画像圧縮方法。 
[ABSTRACT]現在の状態-最新の方法では、品質設定ごとに異なるモデルをトレーニングする必要があり、実際のアプリケーションが大幅に制限されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-17">
        <br><font color="black">2020-04-17</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Robust Learning with Different Label Noise Distributions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_31.html">
      <font color="black">Towards Robust Learning with Different Label Noise Distributions</font>
    </a>
  </h2>
  <font color="black">異なるラベルノイズ分布による表現学習の結果をよりよく理解するためにImageNet32 / 64に基づいた実験的なセットアップを設計し、不均一な分布外ノイズが実際のノイズによく似ており、ほとんどの場合、中間機能はそうではないことを発見しますラベルノイズの破損の影響を受けます。ノイズの多いラベルを破棄すると有害な記憶が回避されますが、関連する画像コンテンツは半教師あり学習（SSL）の設定で引き続き利用できます。通常、クリーンなサンプルは小さな損失トリックを使用して識別されます。つまり、
[ABSTRACT ]ノイズの多いラベルを破棄しても、半教師付き学習（ssl）の設定で悪用される可能性があります。clean-ノイズの多い伝送を2回適用して、1回はクリーンでノイズの多い検出を改善し、もう一度ノイズの最終モデルをトレーニングすることができます。提案されたラベルノイズ分布ロバストな疑似ラベル付け（drpl）アプローチにより、最新の最先端技術を大幅に改善</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-18">
        <br><font color="black">2019-12-18</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Exploit Multiple Vision Modalities by Using Grafted Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_32.html">
      <font color="black">Learning to Exploit Multiple Vision Modalities by Using Grafted Networks</font>
    </a>
  </h2>
  <font color="black">強化されたグラフテッドネットワークは、推論コストの増加なしに、熱およびイベントカメラデータセットを使用したオブジェクト検出タスクで、事前トレーニング済みネットワークの競争平均精度（AP50）スコアに到達することを示しています。全体のパラメータの1つであり、ラベル付きデータからオブジェクト検出器全体をトレーニングするのに必要な時間の5％に相当する単一のGPUで数時間でトレーニングできます。特に、サーマルフレームによって駆動されるグラフトネットワークは、強度フレームの使用に比べて49.11％の改善。 
[ABSTRACT]移植されたネットワークは、強度フレームの使用に対して49. 11％の相対的な改善を示しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-24">
        <br><font color="black">2020-03-24</font>
      </time>
    </span>
</section>
<!-- paper0: Self-supervision on Unlabelled OR Data for Multi-person 2D/3D Human Pose
  Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_33.html">
      <font color="black">Self-supervision on Unlabelled OR Data for Multi-person 2D/3D Human Pose
  Estimation</font>
    </a>
  </h2>
  <font color="black">教師ネットワークは、ラベルなしデータを活用して、生徒の予測の改善に役立つハードラベルとソフトラベルの両方を生成します。臨床活動を分析およびサポートできる手術室用の新しいインテリジェントツールを開発するには、2D / 3Dの人間の姿勢推定が必要です。この効果的な自己監視戦略を使用してトレーニングされた簡単に展開可能なネットワークは、\ emph {MVOR +}の教師ネットワークと同等に機能します。これは、すべての人に完全に注釈が付けられたパブリックMVORデータセットの拡張であり、リアルタイムの実行可能なソリューションを提供しますORでの2D / 3D人間の姿勢推定。 
[要旨]注釈付きデータの欠如はorまたはorで使用できます。システムは3dおよび2dデータを使用してハードラベルとソフトラベルの両方を作成します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Joint Cross-Modality Super Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_34.html">
      <font color="black">Joint Cross-Modality Super Resolution</font>
    </a>
  </h2>
  <font color="black">CMSRは、アーティファクトや無関係な詳細を導入することなく、保守的な方法で、RGBの対応物から貴重な情報を取得し、入力画像の解像度を向上させることに成功したことを示しています。フュージョンプロセス中のアーティファクト.. CMSRには、明示的な監視なしに、アップサンプリングプロセス自体と共にオンザフライでトレーニングされる内部トランスフォーマーが含まれています。 
[ABSTRACT]システムは、クロスモダリティの超解像のためのネットワークです。弱い整列画像を処理するように設計されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-21">
        <br><font color="black">2020-04-21</font>
      </time>
    </span>
</section>
<!-- paper0: Appearance-Preserving 3D Convolution for Video-based Person
  Re-identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_35.html">
      <font color="black">Appearance-Preserving 3D Convolution for Video-based Person
  Re-identification</font>
    </a>
  </h2>
  <font color="black">不完全な人物の検出結果と姿勢の変化により、ビデオベースの人物の再識別（ReID）では、一時的な外観のずれが避けられません。コードは、https：//github.com/guxinqian/AP3D ..で入手できます。この場合、3Dたたみ込みは人物のビデオクリップの外観表現を破壊する可能性があるため、ReIDに有害です。 
[ABSTRACT]人のビデオクリップの外観表現を使用するap3dは、最先端の技術に有害です。広く使用されている3つのデータセットの結果は、最新の技術を上回っています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Weighing Counts: Sequential Crowd Counting by Reinforcement Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_36.html">
      <font color="black">Weighing Counts: Sequential Crowd Counting by Reinforcement Learning</font>
    </a>
  </h2>
  <font color="black">広範な実験により、設計の選択の有効性が示され、少数の群集カウントベンチマークで最先端の結果が報告されます。群集画像をスケールの片側に仮想的に配置することにより、LibraNet（エージェント）は適切な重みを配置することを順次学習します反対側で群集数を一致させます。各ステップで、LibraNetは現在の群集画像の特徴とスケールパンに置かれた重み（状態）に従って、重みボックス（事前定義されたアクションプール）から1つの重み（アクション）を選択します。 ）。 
[ABSTRACT] libranetは、libranetがアクションを選択する方法の決定プロセスを視覚化することにより、スケール計量を正確に実装します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Implicit Diversity in Image Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_37.html">
      <font color="black">Implicit Diversity in Image Summarization</font>
    </a>
  </h2>
  <font color="black">視覚的に多様な画像のセットを入力として受け取り、このセットを使用してクエリに応答して人物の画像のセットを選択する新しいアプローチを開発します。さらに、これらのラベルを推測する自動化技術を使用して、許容範囲の精度範囲であり、このプロセスで発生する可能性がある追加のバイアスのために望ましくない場合があります。しかし、そのようなラベルはしばしば不明です。 
[要約]この種のバイアスを修正するための新しいアプローチは、人々の画像に社会的に顕著な属性ラベルが含まれていることを前提としています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-01-29">
        <br><font color="black">2019-01-29</font>
      </time>
    </span>
</section>
<!-- paper0: Evolving Robust Neural Architectures to Defend from Adversarial Attacks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_38.html">
      <font color="black">Evolving Robust Neural Architectures to Defend from Adversarial Attacks</font>
    </a>
  </h2>
  <font color="black">したがって、ここでの結果は、より堅牢なアーキテクチャが存在することを確認するとともに、ニューラルネットワークの開発と探索の実現可能性の新しい領域を切り開きます。興味深いことに、進化したアーキテクチャのこの固有の堅牢性は、このような最先端の防御に匹敵します。非敵対的サンプルでのみ訓練されている敵対的訓練として。文献からの神経構造探索アルゴリズムに関する実験は、正確ではあるが、堅牢な構造を見つけることができないことを示しています。 
[ABSTRACT]ニューラルアーキテクチャ検索アルゴリズムの実験は、堅牢なアーキテクチャを見つけることができなかったことを示しています。敵対的なサンプルに基づくアーキテクチャを開発できました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-27">
        <br><font color="black">2019-06-27</font>
      </time>
    </span>
</section>
<!-- paper0: PerMO: Perceiving More at Once from a Single Image for Autonomous
  Driving -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_39.html">
      <font color="black">PerMO: Perceiving More at Once from a Single Image for Autonomous
  Driving</font>
    </a>
  </h2>
  <font color="black">インスタンスのセグメンテーションに使用される新しいパーツベースの変形可能な車両モデルを提示し、2D画像と3Dモデル間の密な対応を含むデータセットを自動的に生成します。完全なテクスチャ3Dモデルを検出、セグメント化、再構築する新しいアプローチを提示します。自動運転のための単一の画像からの車両。密なマッピングに基づいて、商品GPUでほぼインタラクティブなレートで正確な6-DoFポーズと3D再構成結果を計算できます。 
[概要]当社のアプローチは、ディープラーニングの長所と伝統的な技術の優雅さを組み合わせたものです。オクルージョンの存在下で高品質の3Dモデルを作成できます。また、密な2dsを予測する新しいエンド-トゥディープニューラルネットワークを提示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: EfficientHRNet: Efficient Scaling for Lightweight High-Resolution
  Multi-Person Pose Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_40.html">
      <font color="black">EfficientHRNet: Efficient Scaling for Lightweight High-Resolution
  Multi-Person Pose Estimation</font>
    </a>
  </h2>
  <font color="black">ベースラインEfficientHRNetは、HRNetと比較して0.4％の精度向上を実現しながら、浮動小数点演算を34％削減します。さらに、バックボーンEfficientNetをベースラインB0と残りのEfficientHRNetの下で共同でスケーリングするための公式を提供します。 EfficientHRNetは、あらゆるレベルで、他のボトムアップ2D人間の姿勢推定アプローチよりも計算効率が高く、競争力の高い精度を実現しています。 
[ABSTRACT] efficienthrnetは軽量の2D人間の姿勢推定器のファミリーです。他の最先端のアプローチと比較して大幅にコストを削減して、高解像度モデルを作成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Structured Landmark Detection via Topology-Adapting Deep Graph Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_41.html">
      <font color="black">Structured Landmark Detection via Topology-Adapting Deep Graph Learning</font>
    </a>
  </h2>
  <font color="black">3つの公開顔画像データセット（WFLW、300W、COFW-68）と3つの実世界のX線医療データセット（頭蓋計測（パブリック）、手および骨盤）で広範な実験が行われています。研究されたすべてのデータセットにわたる最先端のアプローチは、堅牢性と精度の両方で優れたパフォーマンスを示します。アダプティブグラフトポロジは、2つのグラフたたみ込みネットワーク（ GCN）。 
[要約]提案された方法は、ローカル画像機能とグローバル形状機能の両方を活用してグラフ信号を構築します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-17">
        <br><font color="black">2020-04-17</font>
      </time>
    </span>
</section>
<!-- paper0: An Efficient Mixture of Deep and Machine Learning Models for COVID-19
  and Tuberculosis Detection Using X-Ray Images in Resource Limited Settings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_42.html">
      <font color="black">An Efficient Mixture of Deep and Machine Learning Models for COVID-19
  and Tuberculosis Detection Using X-Ray Images in Resource Limited Settings</font>
    </a>
  </h2>
  <font color="black">このタスクの難しさは、バイオテクノロジーテストにアクセスできない可能性のある低リソース設定で悪化します。最前線の臨床医は、症状のある患者が実際にCOVID-19を持っているかどうかを迅速に評価する必要があります。この結果は、 COVID-19の検出にパイプラインを使用し、特にリソースが限られた設定で、限られた計算リソースで実行できます。 
[ABSTRACT]このタスクの難しさは、バイオテクノロジーテストにアクセスできない可能性のある低リソース設定では健全です。これらの要因には、TBおよび健全なケースとCovidが含まれます。 -特にリソース-限られた設定</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Graph-Based Social Relation Reasoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_43.html">
      <font color="black">Graph-Based Social Relation Reasoning</font>
    </a>
  </h2>
  <font color="black">実験結果は、私たちの方法が合理的で一貫した社会関係グラフを生成し、精度と効率の両方のパフォーマンスを向上させることを示しています。さらに、提案されたGR2Nは、さまざまなタイプの社会関係間の強い論理制約を明示的に把握するためにいくつかの仮想関係グラフを構築します。画像から社会的関係を理解することは、ソーシャルチャットボットやパーソナルアシスタントなどのインテリジェントシステムにとって大きな可能性を秘めています。 
[ABSTRACT]私たちの方法は、合理的で一貫性のある社会関係グラフを生成します。合理的で一貫性のある社会関係グラフを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-15">
        <br><font color="black">2020-07-15</font>
      </time>
    </span>
</section>
<!-- paper0: Explaining Deep Neural Networks using Unsupervised Clustering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_44.html">
      <font color="black">Explaining Deep Neural Networks using Unsupervised Clustering</font>
    </a>
  </h2>
  <font color="black">事前トレーニング済みのDNNが与えられた画像データセットで、類似のトレーニングサンプルを見つけ、DNNが決定の基礎とする概念に光を当てる方法の強さを示します。トレーニング済みのディープニューラルネットワーク（DNN）を説明する新しい方法を提案します。 、教師なしクラスタリングを使用してそれらを代理モデルに蒸留することにより。ユーザーの研究を通じて、私たちのモデルがモデルの予測におけるユーザーの信頼を改善できることを示しています。 
[ABSTRACT]私たちの方法は、柔軟なdnnアーキテクチャのレイヤーのサブセットに適用できます。低レベルおよび高レベルの情報を組み込むことができます。これらのデータは、情報を提供するために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-15">
        <br><font color="black">2020-07-15</font>
      </time>
    </span>
</section>
<!-- paper0: openDD: A Large-Scale Roundabout Drone Dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_45.html">
      <font color="black">openDD: A Large-Scale Roundabout Drone Dataset</font>
    </a>
  </h2>
  <font color="black">openDDデータセットは、501の別々のフライトでドローンが撮影した画像を使用して注釈が付けられ、合計で62時間以上の軌道データになります。現在、openDDは、ドローンの観点から記録された、公に利用可能な最大の軌道データセットです。最長17時間.. 7つの異なるラウンドアバウトの正確に追跡された84,774の軌跡とHDマップデータを含むopenDDデータセットを紹介します。 
[要約] 84、774を含むopenddデータセット、7つの異なるラウンドアバウトの正確に追跡された軌道とhdマップデータ。このデータセットは、ドローンの観点から記録された、公的に利用可能な最大の軌道データセットです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Unpaired Image-to-Image Translation using Adversarial Consistency Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_46.html">
      <font color="black">Unpaired Image-to-Image Translation using Adversarial Consistency Loss</font>
    </a>
  </h2>
  <font color="black">この損失により、変換された画像を特定のソース画像に変換する必要はありませんが、変換された画像がソース画像の重要な機能を保持し、上記のサイクルの一貫性の損失の欠点を克服するように促すことができます。画像変換は、視覚化の問題の一種であり、その目的は、ペアになっていないトレーニングデータを使用して、異なる画像ドメイン間のマッピングを見つけることです。サイクル整合性の損失は、このような問題に広く使用されている制約です。 
[ABSTRACT]この方法は、画像から画像への変換のための新しいレベルの「一貫性の損失」に基づいています。これは、ソースがビジョンの状態を達成するために管理するのが初めてである。方法はまた、成功を達成する画像と自撮りのマッピング結果-アニメ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-10">
        <br><font color="black">2020-03-10</font>
      </time>
    </span>
</section>
<!-- paper0: The Best of Both Modes: Separately Leveraging RGB and Depth for Unseen
  Object Instance Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_47.html">
      <font color="black">The Best of Both Modes: Separately Leveraging RGB and Depth for Unseen
  Object Instance Segmentation</font>
    </a>
  </h2>
  <font color="black">また、私たちの方法がロボットの把握のために見えないオブジェクトをセグメント化できることも示しています。しかし、このタスクに必要な大規模な実世界のデータセットのタイプは、合成データの使用を動機づけるほとんどのロボット設定には通常存在しません。 、私たちのフレームワークは、RGBが非写実的である合成RGB-Dデータから学ぶことができます。 
[ABSTRACT]新しいメソッドは、エンカウンターエンカウンターに合成RGBとロボット深度を使用します。メソッドは、見えないオブジェクトが非写実的である合成RGB-Dデータから学習できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-30">
        <br><font color="black">2019-07-30</font>
      </time>
    </span>
</section>
<!-- paper0: Memory Based Attentive Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_48.html">
      <font color="black">Memory Based Attentive Fusion</font>
    </a>
  </h2>
  <font color="black">私たちのレイヤーへの入力は、注意深い構成と変換によって融合され、変換された機能が入力と結合されて、融合レイヤー出力が生成されます。現在の機能と長期的な依存関係の両方をデータに組み込むことにより、モデルが時間の経過に伴うモードの相対的な重要性を理解できるようにします。既存の最先端の方法に従って、パフォーマンスと一般化可能性を評価しましたモダリティが異なるIEMOCAPおよびPhysioNet-CMEBSデータセットに対する提案されたアプローチ。 
[ABSTRACT]ほとんどの状態-最先端の方法は単純なFusionを使用します。特定の時間からの機能ストリームを処理します-ステップし、長期的な依存関係を無視します。これにより、Fusion Layer内に明示的なメモリブロックが作成されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: DeepInit Phase Retrieval -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_49.html">
      <font color="black">DeepInit Phase Retrieval</font>
    </a>
  </h2>
  <font color="black">また、私たちのアイデアは、従来の勾配ベースの再構成方法よりも優れた実行時パフォーマンスを示しています。ハイブリッドアプローチは、重大なジェネレータモデルエラーがある場合でも、低いサンプリングレートで非常に高い再構成結果を提供できることを経験的に示しています。したがって、DeepInitを提案します。高速な古典的アルゴリズムのトレーニングされた初期化を計算する前に、深い生成データの下で正規化された勾配降下法を使用するフェーズ検索（例：
[ABSTRACT]これらの単純なアルゴリズムは、最適化に近い初期化でうまく機能することが知られていますが、それ以外の場合は、次に、これらは、グローバル最適に近い従来の降下ステップを開始することにより、認識できない問題を克服する方法を知らせるために使用されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Interactive Video Object Segmentation Using Global and Local Transfer
  Modules -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_50.html">
      <font color="black">Interactive Video Object Segmentation Using Global and Local Transfer
  Modules</font>
    </a>
  </h2>
  <font color="black">グローバル転送モジュールは、注釈付きフレームのセグメンテーション情報をターゲットフレームに伝達し、ローカル転送モジュールは、時間的に隣接するフレームのセグメンテーション情報をターゲットフレームに伝達します。インタラクティブビデオオブジェクトセグメンテーションアルゴリズム。クエリで落書きアノテーションを取得します。入力としてのオブジェクトは、このペーパーで提案されています。A-NetとT-Netを交互に適用することにより、ユーザーは最小限の労力で目的のセグメンテーション結果を得ることができます。 
[ABSTRACT]ディープニューラルネットワークは、アノテーションネットワーク（a-ネット）と転送ネットワーク（sc）で構成されます。これにより、最先端の従来のアルゴリズムを上回る、インタラクティブなビデオオブジェクトセグメントネットアルゴリズムが作成されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Bottom-Up Temporal Action Localization with Mutual Regularization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_51.html">
      <font color="black">Bottom-Up Temporal Action Localization with Mutual Regularization</font>
    </a>
  </h2>
  <font color="black">コード：https://github.com/PeisenZhao/Bottom-Up-TAL-with-MR。提案された正則化は、他のTALメソッド（TSA-NetやPGCNなど）にも一般化されます。私たちのアプローチは、定量的および定性的にベースラインを明らかに上回っています。 
[要約]この論文では、このメカニズムについて詳しく説明し、既存の方法では潜在的なフレームが無視されていると主張します。この方法では、3つのアクションを示すフェーズのフレームレベルの確率を評価します。提案されている正則化は、他のtalメソッドにも一般化されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br><font color="black">2020-02-18</font>
      </time>
    </span>
</section>
<!-- paper0: A high fidelity synthetic face framework for computer vision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_52.html">
      <font color="black">A high fidelity synthetic face framework for computer vision</font>
    </a>
  </h2>
  <font color="black">顔の分析は、コンピュータビジョンのコアアプリケーションの1つで、ランドマークの位置合わせ、頭の姿勢の推定、表情の認識、顔の認識など、さまざまなタスクがあります。合成データを使用して可能な一貫性とスケールで手動アノテーションを介して取得することはほとんど不可能です。パラメトリックフェイスモデルと手作りのアセットを使用して、これまでにない品質と多様性（形状、テクスチャー、変化する変化）を備えたトレーニングデータを生成できます。表情、ポーズ、照明、髪）。 
[ABSTRACT]パラメトリックフェイスモデルと手作りのアセットを使用して、前例のない品質と多様性を持つトレーニングデータを生成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Vehicle Detection of Multi-source Remote Sensing Data Using Active
  Fine-tuning Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_53.html">
      <font color="black">Vehicle Detection of Multi-source Remote Sensing Data Using Active
  Fine-tuning Network</font>
    </a>
  </h2>
  <font color="black">2つのオープンISPRSベンチマークデータセット、すなわちヴァイヒンゲン村とポツダム市のデータセットで行われた広範な実験結果は、車両検出のための提案されたMs-AFtの優位性と有効性を示しています。提案されたMs-AFtは、最初に生成する微調整ネットワークを採用しています。さらに、リモートセンシングデータソースのリストが利用できるため、マルチソースデータからの有用な情報を効率的に活用して車両をより適切に検出することは困難です。 
[ABSTRACT]車両検出（ms-aft）は、自動ラベル付けと検出のために提案されています。車両の検出を微調整して統合フレームワークに組み合わせます。ms-リチャードソンとms-を組み合わせて検出します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Layer-Wise Adaptive Updating for Few-Shot Image Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_54.html">
      <font color="black">Layer-Wise Adaptive Updating for Few-Shot Image Classification</font>
    </a>
  </h2>
  <font color="black">最近、メタ学習ベースの方法がFSICの有望な方向として示されています。少数の画像の分類（FSIC）は、これらのカテゴリのいくつかの画像から学習して新しいカテゴリを認識するためのモデルを必要とし、多くの注目を集めています。 。一般的に、彼らは簡単な微調整の重みを学習するようにメタ学習者（メタ学習モデル）をトレーニングし、FSICタスクを解くとき、メタ学習者は少数の自身で更新することにより、タスク固有のモデルに効率的に微調整しますタスクの画像。 
[ABSTRACT]調査により、メタ学習者はfsicのパフォーマンスを向上させるために、これらの最下層を更新するよりも最上位層を更新することを大いに好む可能性があることがわかりました。メタ学習ベースのツール-fsicの適応的更新（lwau）メソッド。より効率的に学習することが可能です。少なくとも5回</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Semi-Siamese Training for Shallow Face Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_55.html">
      <font color="black">Semi-Siamese Training for Shallow Face Learning</font>
    </a>
  </h2>
  <font color="black">このホワイトペーパーでは、セミシャムトレーニング（SST）という名前の新しいトレーニング方法を導入することで問題に対処することを目指しています。セミシャムネットワークのペアは、順方向伝播構造を構成し、トレーニングロスは更新ギャラリーキューで計算されます。 、浅いトレーニングデータに対して効果的な最適化を実行します。各IDで使用できる顔画像は2つだけです。 
[ABSTRACT]浅い顔の学習では、既存のトレーニング方法の深さが制限されます。これにより、特徴の次元が崩壊する可能性があるため、学習されたネットワークは簡単に縮退します。提案された方法は、深い顔のデータだけでなく、トレーニングを大幅に改善します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Where to Focus for Efficient Video Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_56.html">
      <font color="black">Learning Where to Focus for Efficient Video Object Detection</font>
    </a>
  </h2>
  <font color="black">サンプリングされた場所は、最初にランダムに初期化され、次に逐次的に更新されて、検出の監視によって徐々に改善される空間対応を見つけます。コードはhttps://github.com/jiangzhengkai/LSTS。で利用できるようになります。したがって、Learnable Spatioと呼ばれる新しいモジュール-時間サンプリング（LSTS）は、隣接するフレームの特徴間の意味レベルの対応を正確に学習するために提案されました。 
[ABSTRACT]システムは以前、アートフローを使用してビデオフレーム全体に機能を伝播および集約するために使用されていました-ワーピング</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-13">
        <br><font color="black">2019-11-13</font>
      </time>
    </span>
</section>
<!-- paper0: Adversarial Robustness Assessment: Why both $L_0$ and $L_\infty$ Attacks
  Are Necessary -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_57.html">
      <font color="black">Adversarial Robustness Assessment: Why both $L_0$ and $L_\infty$ Attacks
  Are Necessary</font>
    </a>
  </h2>
  <font color="black">さらに、数学的導出および反例は、$ L_1 $および$ L_2 $メトリックだけでは、偽の敵対的なサンプルを回避するのに十分ではないことを示唆しています。最先端のニューラルに関する二重品質評価を検証しますネットワーク（WideResNet、ResNet、AllConv、DenseNet、NIN、LeNet、およびCapsNet）だけでなく、画像分類の問題に対する防御策も提案されています。提案された堅牢性評価では、使用されているメトリック（つまり、$ L_0 $または$ L_ \ infty $ ）、堅牢性は大幅に異なる場合があります。 
[ABSTRACT]これらの敵対的なアルゴリズムには固有のバイアスがあります。これらはこれに基づいており、モデル診断の二重品質評価方法を、堅牢性レベルの概念とともに提案します。validnetnetnetnet、ネットワークおよび防御は、堅牢性のすべてのレベルで脆弱です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-14">
        <br><font color="black">2019-06-14</font>
      </time>
    </span>
</section>
<!-- paper0: Train Your Data Processor: Distribution-Aware and Error-Compensation
  Coordinate Decoding for Human Pose Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_58.html">
      <font color="black">Train Your Data Processor: Distribution-Aware and Error-Compensation
  Coordinate Decoding for Human Pose Estimation</font>
    </a>
  </h2>
  <font color="black">最近、人間の姿勢推定の主要なパフォーマンスは、ヒートマップに基づく方法によって支配されています。この作業は、予測プロセス全体で導入されたエラーに特に焦点を当ててヒートマップのデコード処理を研究することによってギャップを埋めます。発見された重要性を考慮して、さらに、以前に広く使用されているヒートマップデコード方法の本質的な制限を明らかにし、配布認識およびエラー補償座標デコード（DAEC）を提案します。 
[ABSTRACT]最近使用されたヒートマップデコード。ヒートマップが優勢です。これは、デコードプロセスを分析する作業です。また、分布を認識し、エラーを補正する補正座標デコード</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-12">
        <br><font color="black">2020-07-12</font>
      </time>
    </span>
</section>
<!-- paper0: Do Adversarially Robust ImageNet Models Transfer Better? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_59.html">
      <font color="black">Do Adversarially Robust ImageNet Models Transfer Better?</font>
    </a>
  </h2>
  <font color="black">さらなる分析により、転移学習のコンテキストでのロバストモデルと標準モデルの違いがさらに明らかになります。私たちのコードとモデルはhttps://github.com/Microsoft/robust-models-transferで入手できます。事実、）堅牢性は特徴表現の改善につながるという最近の仮説に追加してください。 
[ABSTRACT]広く訓練されたモデルはスキルで自分自身を識別できます。これは、初期精度が転移学習の重要な側面であることを示唆しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Looking back to lower-level information in few-shot learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_60.html">
      <font color="black">Looking back to lower-level information in few-shot learning</font>
    </a>
  </h2>
  <font color="black">2つの人気のある少数ショット学習データセットであるminiImageNetとtieredImageNetでの実験は、この手法がネットワーク内の低レベルの情報を利用して、最新の分類パフォーマンスを向上できることを示しています。ただし、少数ショットに関する既存の研究学習は、ニューラルネットワークの最後の層によって生成された特徴の埋め込みにのみ焦点を当てています。この作業では、下位レベルのサポート情報、つまり、隠れたニューラルネットワーク層の特徴の埋め込みを利用して、分類子の精度を向上させることを提案します。 。 
[ABSTRACT] fewgenの学習は、多くの実在の問題に対するその重要性のため、注目を集めています。しかし、既存の構造は、ニューラルネットワークの最後の層によって生成された特徴の埋め込みにのみ焦点を当てています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-27">
        <br><font color="black">2020-05-27</font>
      </time>
    </span>
</section>
<!-- paper0: U-Net Based Architecture for an Improved Multiresolution Segmentation in
  Medical Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_61.html">
      <font color="black">U-Net Based Architecture for an Improved Multiresolution Segmentation in
  Medical Images</font>
    </a>
  </h2>
  <font color="black">さらに、mrU-Netを使用すると、U-Netと比較して、LUNAおよびDRIVEデータセットのトレーニング率が向上しました。結果：結果を手動のセグメンテーションラベルと比較すると、mrU-Netは、平均ダイス類似度係数70.6％、97.9％、皮膚病変、LUNA、DRIVE、およびPROMISE12セグメンテーションのそれぞれ73.6％、77.9％。提案されたアーキテクチャー（mrU-Net）では、入力画像とそのダウンサンプリングされたバージョンがネットワーク入力として使用されました。 
[要約]提案されたアーキテクチャは、u-netのマルチ解像度画像セグメンテーションパフォーマンスを向上させるように設計されています。印象的な機能は、mru-netと比較して、画像-派生機能を抽出する機能が高いことです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Human-Expert-Level Brain Tumor Detection Using Deep Learning with Data
  Distillation and Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_62.html">
      <font color="black">Human-Expert-Level Brain Tumor Detection Using Deep Learning with Data
  Distillation and Augmentation</font>
    </a>
  </h2>
  <font color="black">これらの課題を克服するために、ディープニューラルネットワークをトレーニングするための新しい方法を提案します。これは、特に代表的なトレーニング例を抽出し、あるクラスのサンプルと同じクラスおよび他のクラスのサンプルを混合して追加のトレーニングサンプルを作成することにより、トレーニングデータを補強します。医療診断へのディープラーニング（DL）の適用は、多くの場合、2つの問題によって妨げられます。次に、トレーニングデータは、さまざまな種類のノイズによって破損する可能性があります。 
[ABSTRACT]トレーニングデータの量は、診断対象の状態と診断された患者の数に限られているため、不足している場合があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br><font color="black">2020-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: Autoregressive Unsupervised Image Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_63.html">
      <font color="black">Autoregressive Unsupervised Image Segmentation</font>
    </a>
  </h2>
  <font color="black">トレーニング中にマスクされた畳み込みが使用されますが、推論では、マスキングは適用されず、モデルは完全な入力にアクセスできる標準の畳み込みにフォールバックします。特定の入力に対して、モデルは2つの有効な順序で予測のペアを生成します、および2つの出力間の相互情報を最大化するようにトレーニングされます。この作業では、入力の異なる構成ビュー間の相互情報最大化に基づく新しい教師なし画像セグメンテーションアプローチを提案します。 
[要約]提案された方法は、現在の状態より優れています-教師なし画像セグメンテーションの最先端</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Challenge report:VIPriors Action Recognition Challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_64.html">
      <font color="black">Challenge report:VIPriors Action Recognition Challenge</font>
    </a>
  </h2>
  <font color="black">また、残差フレームを入力として使用してビデオからモーション機能を抽出するために高速で効果的な方法を使用します。3D畳み込み（SlowFast）と2D畳み込み（TSM）を組み合わせることにより、より良いパフォーマンスが得られます。そして私たちの方法を提案します。 
[ABSTRACT]アクション認識は、その完全なアプリケーションのために多くの研究者の注目を集めていますが、この方法の注目を集めることは依然として困難です。主に低速ネットワークの改善とtsmとの融合を行っています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Accelerating 3D Deep Learning with PyTorch3D -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_65.html">
      <font color="black">Accelerating 3D Deep Learning with PyTorch3D</font>
    </a>
  </h2>
  <font color="black">また、PyTorch3Dを使用して、ShapeNet上の2D画像からの監視されていない3Dメッシュおよび点群予測の最先端技術を改善します。これには、メッシュおよび点群用の高速でモジュール式の微分可能なレンダラーが含まれ、合成による分析アプローチを可能にします.. 3Dディープラーニング用のモジュール式で効率的で微分可能な演算子のライブラリであるPyTorch3Dを導入することにより、これらの課題に対処します。 
[ABSTRACT]ディープラーニングは、自動運転車、仮想現実、拡張現実、3Dコンテンツのオーサリング、さらには2D認識の改善など、新しいアプリケーションにつながる可能性があります。この格差の一部は、異種混合の効率的な処理など、3Dディープラーニングに伴うエンジニアリングの課題によるものです。差別化できるようにデータとグラフィックを再構成する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Design and Interpretation of Universal Adversarial Patches in Face
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_66.html">
      <font color="black">Design and Interpretation of Universal Adversarial Patches in Face
  Detection</font>
    </a>
  </h2>
  <font color="black">私たちは、偽陽性を導入することなく真陽性が抑制されるシナリオを含む、攻撃のさまざまな目標のためのユニバーサル敵対パッチの自動設計への新しい最適化ベースのアプローチを提案します。提案されたアルゴリズムは、現実世界のデータセットでうまく機能し、 -複数の精度/リコールメトリックと転送可能性の観点から、最新の顔検出器。現象を調査します。実際の顔の検出を抑制するように設計されたパッチが顔のように見えます。 
[ABSTRACT]これらのパッチは、最新の顔検出器が実際の顔を検出できないようにすることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-30">
        <br><font color="black">2019-11-30</font>
      </time>
    </span>
</section>
<!-- paper0: Object Segmentation Tracking from Generic Video Cues -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_67.html">
      <font color="black">Object Segmentation Tracking from Generic Video Cues</font>
    </a>
  </h2>
  <font color="black">データセットDAVIS 16,17およびSegTrack v2でメソッドを評価します。このような手がかりは通常、ロボットのナビゲーションや把握の推定などのタスクに必要です。このシンプルな方法は、パラメーター調整を伴う高価なCNNベースの方法と比較して競争力のある結果を提供できます。 。 
[ABSTRACT]モーションとカラーからの一般的なビデオ情報に基づいて、変分モデルの可能性を示します。競合するCNNベースのセグメンテーションと組み合わせて、それぞれの結果を改善できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-05">
        <br><font color="black">2019-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Rethinking Anticipation Tasks: Uncertainty-aware Anticipation of Sparse
  Surgical Instrument Usage for Context-aware Assistance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_68.html">
      <font color="black">Rethinking Anticipation Tasks: Uncertainty-aware Anticipation of Sparse
  Surgical Instrument Usage for Context-aware Assistance</font>
    </a>
  </h2>
  <font color="black">私たちの知る限りでは、手術で器具を予測する方法を最初に提案します。これらの制限を克服する腹腔鏡ビデオで器具の使用を予測するための新しい学習タスクを提案します。将来の出来事に関連する不確実性。 
[ABSTRACT]現在のアプローチは、将来のアクションのラップに関する知識を想定している、またはトレーニング中に高密度の空間セグメンテーションを必要とするため、制限されています。長期的な課題に対する長期的な代替案を提案する最初の手段です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-01">
        <br><font color="black">2020-07-01</font>
      </time>
    </span>
</section>
<!-- paper0: PT2PC: Learning to Generate 3D Point Cloud Shapes from Part Tree
  Conditions -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_69.html">
      <font color="black">PT2PC: Learning to Generate 3D Point Cloud Shapes from Part Tree
  Conditions</font>
    </a>
  </h2>
  <font color="black">3D生成形状モデリングは、多くの現実世界のアプリケーションを備えたコンピュータービジョンとインタラクティブコンピューターグラフィックスの基本的な研究領域です。また、生成された形状点群がパーツツリーの条件を満たしているかどうかを評価するための新しい構造的尺度を提案します。ユーザー調査は、パーツツリーの状態を前提として、知覚的にもっともらしい多様な3D点群を生成する方法の利点を示しています。 
[ABSTRACT]提案されたモデルは、パーツのグラフィックに沿ってメッセージを上から下、下から上に渡すことを含みます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-19">
        <br><font color="black">2020-03-19</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Full Image Interactive Segmentation by Leveraging Within-image
  Appearance Similarity -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_70.html">
      <font color="black">Efficient Full Image Interactive Segmentation by Leveraging Within-image
  Appearance Similarity</font>
    </a>
  </h2>
  <font color="black">COCOパノプティックチャレンジデータセットで人間のアノテーターを使った実験では、優れた手動インターフェースと新しい自動伝播メカニズムの組み合わせにより、ポリゴン描画に比べて注釈時間が2倍以上削減されることが示されています。長距離伝播を有効にするには、アプローチでは、まず、画像全体のラベル付きピクセルとラベルなしピクセル間の外観の類似性をグローバルに測定します。これまでに見えなかったセマンティッククラスを持つ新しいデータセットのトレーニングデータをすばやく収集できるインタラクティブなフルイメージセマンティックセグメンテーションへの新しいアプローチを提案します（デモはhttpsで利用できます） ：//youtu.be/yUk8D5gEX-o）。 
[ABSTRACT]ラベル付きピクセルからラベルなしピクセルへの通信には、必ずしもクラス固有の知識は必要ありませんが、画像内の外観の類似性のみに基づいて行うことができます。従来のポリゴン描画ツールを便利な追加のスイートで拡張する効率的な手動注釈インターフェイスを構築します特徴</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Label Efficient Visual Abstractions for Autonomous Driving -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_71.html">
      <font color="black">Label Efficient Visual Abstractions for Autonomous Driving</font>
    </a>
  </h2>
  <font color="black">いくつかのセグメンテーションベースの中間表現を分析します。セマンティックセグメンテーションは、運転方針を学習するための効果的な中間表現として使用できることはよく知られています。さらに、セグメンテーションアルゴリズムは、実際の運転タスクに関係なく、補助画像空間を使用してトレーニングされることがよくあります。安全性や介入ごとの移動距離などの運転基準の最大化が保証されていない損失関数。 
[ABSTRACT]これらの視覚的解釈を使用して、注釈の効率と運転パフォーマンスのトレードオフを研究します。ラベル付きクラスのタイプ、視覚的アナロジーモデルの学習に使用される画像サンプルの数、およびそれらの粒度が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-20">
        <br><font color="black">2020-05-20</font>
      </time>
    </span>
</section>
<!-- paper0: In-Domain GAN Inversion for Real Image Editing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_72.html">
      <font color="black">In-Domain GAN Inversion for Real Image Editing</font>
    </a>
  </h2>
  <font color="black">結果として、再構築された画像は、反転コードの変更によるセマンティック編集を十分にサポートできません。最近の研究では、画像を合成するようにトレーニングされると、さまざまなセマンティクスが生成的敵対的ネットワーク（GAN）の潜在空間に出現することが示されています。実画像を訓練されたGANジェネレーターにフィードする習慣は、それを反転させて潜在コードに戻すことです。 
[ABSTRACT]以前の反転方法は、通常、ピクセル値によるターゲット画像の再構築に焦点を当てていますが、反転したコードを元の潜在空間のセマンティックドメインに配置できませんでした</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br><font color="black">2020-03-31</font>
      </time>
    </span>
</section>
<!-- paper0: Probabilistic Anchor Assignment with IoU Prediction for Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_73.html">
      <font color="black">Probabilistic Anchor Assignment with IoU Prediction for Object Detection</font>
    </a>
  </h2>
  <font color="black">さらに、トレーニングとテストの目的間のギャップを調査し、不一致を減らすためのローカリゼーション品質の尺度として、検出されたボックスのIntersection-over-Unionsを予測することを提案します。は、場所ごとに複数のアンカーを必要としないので効率的です。オブジェクト検出では、アンカーの割り当てと呼ばれる、どのアンカーをポジティブサンプルまたはネガティブサンプルとして割り当てるかを決定することが、モデルのパフォーマンスに大きな影響を与えるコアプロシージャとして明らかになりました。 
[ABSTRACT]提案されたアンカー割り当て戦略は米国で開発されています。モデルは、確率に従って陽性サンプルと陰性サンプルに分離されたアンカーでトレーニングされます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Benchmarking Differentially Private Residual Networks for Medical
  Imagery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_74.html">
      <font color="black">Benchmarking Differentially Private Residual Networks for Medical
  Imagery</font>
    </a>
  </h2>
  <font color="black">モデルの精度とそれが保証するプライバシーのレベルとの間のトレードオフを分析し、これらの理論的なプライバシーの保証が実際の医療環境で実際にどれほど有用であるかを評価するために、さらに詳しく調べます。このホワイトペーパーでは、医療画像に適用した場合の$ \ epsilon $ -Differential Privacy（DP）の有効性。Local-DPとDP-SGDの2つの堅牢な差分プライバシーメカニズムを比較し、医療画像記録を分析する際のパフォーマンスをベンチマークします。 
[要約] 2つの堅牢なプライバシーメカニズムを比較します：ローカル-dpとdp-sgd</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-27">
        <br><font color="black">2020-05-27</font>
      </time>
    </span>
</section>
<!-- paper0: Geometric Attention for Prediction of Differential Properties in 3D
  Point Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_75.html">
      <font color="black">Geometric Attention for Prediction of Differential Properties in 3D
  Point Clouds</font>
    </a>
  </h2>
  <font color="black">具体的には、生の点群から法線と鋭い特徴線を推定すると、メッシュ品質が向上し、より正確な表面再構成手法を使用できるようになります。行..この研究では、学習可能な方法でそのような特性を提供できる幾何学的注意メカニズムを提示します。 
[要約]合成的に現実的な幾何学的情報を点群で使用できます。この研究の結果は生の点群で開発されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-06">
        <br><font color="black">2020-07-06</font>
      </time>
    </span>
</section>
<!-- paper0: Controllable Image Synthesis via SegVAE -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_76.html">
      <font color="black">Controllable Image Synthesis via SegVAE</font>
    </a>
  </h2>
  <font color="black">また、既製の画像から画像への変換モデルを適用して、リアルなRGB画像を生成し、合成されたセマンティックマップの品質をよりよく理解します。さらに、オブジェクトの削除、オブジェクト挿入、およびオブジェクト置換。定量的および定性的実験は、提案されたモデルが現実的で多様なセマンティックマップを生成できることを示しています。 
[要約]意味マップは、条件付き画像生成の中間表現として一般的に使用されます。提案されたモデルは、現実的で多様なマップを生成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Event Enhanced High-Quality Image Recovery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_77.html">
      <font color="black">Event Enhanced High-Quality Image Recovery</font>
    </a>
  </h2>
  <font color="black">スパース学習のフレームワークを活用して、イベントと低解像度の強度観測を一緒に検討できます。合成データセットでトレーニングした後、提案されたeSL-Netは、最先端のパフォーマンスを7まで大幅に改善できます。 -12 dB ..これに基づいて、イベントカメラから高品質の画像を復元するための説明可能なネットワーク、イベント強化スパース学習ネットワーク（eSL-Net）を提案します。 
[ABSTRACT]ネットワーク、イベント強化型高密度学習ネットワーク（esl-net）は、イベントカメラから高品質の画像を復元できます。簡単に拡張して、イベントのイベントと同程度のフレームレートで連続フレームを生成できます。代わりに、提案されたeslnetを拡張して連続フレームを作成できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: AutoSTR: Efficient Backbone Search for Scene Text Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_78.html">
      <font color="black">AutoSTR: Efficient Backbone Search for Scene Text Recognition</font>
    </a>
  </h2>
  <font color="black">実験では、データ依存のバックボーンを検索することにより、AutoSTRが標準ベンチマークの最先端のアプローチよりもはるかに少ないFLOPSとモデルパラメーターで優れたパフォーマンスを発揮できることを示しています。次に、操作を切り離し、指定されたスペースで効率的な検索を行うためのダウンサンプリングパス。最初に、STRのドメイン固有の検索スペースを設計します。これには、操作の選択とダウンサンプリングパスの制約の両方が含まれます。 
[ABSTRACT]このプロジェクトは、ニューラルアーキテクチャ検索の成功に触発されました。データに依存するバックボーンを検索する自動化されたstrを提案します。次に、操作とダウンサンプリングパスを分離する2段階の検索アルゴリズムを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-14">
        <br><font color="black">2020-03-14</font>
      </time>
    </span>
</section>
<!-- paper0: Multi-Task Pruning for Semantic Segmentation Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_79.html">
      <font color="black">Multi-Task Pruning for Semantic Segmentation Networks</font>
    </a>
  </h2>
  <font color="black">したがって、セグメンテーションネットワークの冗長性を識別するために、マルチタスクチャネルプルーニングアプローチを紹介します。このホワイトペーパーでは、セマンティックセグメンテーションネットワークのチャネルプルーニングに焦点を当てています。さらに、ネットワーク全体でフィルターの重要度スコアを最適化するための代替スキームを開発します。 。 
[要約]ディープニューラルネットワークを圧縮および高速化する作業は多数ありますが、セマンティックセグメンテーションネットワークに直接適用することはできません。セグメンテーションネットワークの冗長性を識別するには、ブーストが必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: RepPoints V2: Verification Meets Regression for Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_80.html">
      <font color="black">RepPoints V2: Verification Meets Regression for Object Detection</font>
    </a>
  </h2>
  <font color="black">RepPoints v2は、単一モデルによってCOCO \ texttt {test-dev}で52.1 mAPも達成します。RepPointsは高いパフォーマンスを提供しますが、オブジェクトのローカリゼーションの回帰に大きく依存しているため、改善の余地があります。検証と回帰は、一般的に2つあります。ニューラルネットワークでの予測の方法論。 
[要約]提案されたアプローチは、より一般的には他のオブジェクト検出フレームワークを向上させることができます。インスタンスのセグメンテーションなどのアプリケーションも向上させることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Image Processing and Quality Control for Abdominal Magnetic Resonance
  Imaging in the UK Biobank -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_81.html">
      <font color="black">Image Processing and Quality Control for Abdominal Magnetic Resonance
  Imaging in the UK Biobank</font>
    </a>
  </h2>
  <font color="black">エンドツーエンドの画像分析パイプラインが、英国のバイオバンクで使用された腹部MRIプロトコル用に最初の38,971人の参加者に提示されます。Dixonシリーズの脂肪水スワップの検出は、深層学習モデルによって実行され、自動的に修正されます。骨関節は、肩、腰、膝のハイブリッドアトラスベースの登録とディープラーニングモデルを使用して予測されます。 
[要約]ここで提示された発見は、画像を使用しようとする科学者にとって非常に貴重です-腹部のMRIプロトコルから派生した表現型。約99。肝臓をカバーするシングルスライスマルチエコー取得の98％が正常に処理され、品質管理に合格しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-02">
        <br><font color="black">2020-07-02</font>
      </time>
    </span>
</section>
<!-- paper0: Few-shot Compositional Font Generation with Dual Memory -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_82.html">
      <font color="black">Few-shot Compositional Font Generation with Dual Memory</font>
    </a>
  </h2>
  <font color="black">生成機能を活用するために、ジェネレータではメモリコンポーネントとグローバルコンテキスト認識を採用しています。このホワイトペーパーでは、各グリフを複数のコンポーネントで分解できる世界で広く使用されている文字システムである合成スクリプトに焦点を当てます。ソースコードはhttps://github.com/clovaai/dmfontで入手できます。 
[ABSTRACT]新しいフォント生成方法では、新しいフォントセットを生成するために多数の参照画像を必要とするか、いくつかのサンプルだけでは詳細なスタイルをキャプチャできません</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-21">
        <br><font color="black">2020-05-21</font>
      </time>
    </span>
</section>
<!-- paper0: Video-based Remote Physiological Measurement via Cross-verified Feature
  Disentangling -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_83.html">
      <font color="black">Video-based Remote Physiological Measurement via Cross-verified Feature
  Disentangling</font>
    </a>
  </h2>
  <font color="black">次に、2つのエンコーダー（1つは生理学的信号用、もう1つは非生理学的情報用）を備えたオートエンコーダアーキテクチャへの入力としてペアワイズMSTmapを取得し、クロス検証スキームを使用して、非生理学的機能と絡み合っていない生理学的機能を取得します。最終的に、平均HR値やrPPG信号などの複数の生理学的信号の同時予測に機能が使用されます。生理学的信号の振幅は非常に小さいため、頭部の動き、照明条件、センサーの多様性の影響を受けやすくなります。 
[ABSTRACT]測定が行われると、まず生理学的信号のビデオのもつれを解きます。次に、それらを使用して複数のサーマルマップ（msppp）を作成します。これにより、無関係なバックグラウンドとノイズの機能を抑制し、周期的な生理学的影響を保持できます。信号</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Generative Latent Implicit Conditional Optimization when Learning from
  Small Sample -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_84.html">
      <font color="black">Generative Latent Implicit Conditional Optimization when Learning from
  Small Sample</font>
    </a>
  </h2>
  <font color="black">実際、GLICOは、クラスごとにわずか5または10の例を使用して、すべてのクラスの完全に新しいサンプルを合成することを学習します。このようなクラスはわずか10で、未知のクラスからのデータはありません。小規模から学習するという長年の問題を再検討しますサンプル..ラベルの付いていない大量のデータへのアクセスに依存する最新の作業とは異なり、GLICOはラベル付きポイントの小さなセット以外の追加データへのアクセスを必要としません。 
[ABSTRACT] glicoは、ラベル付きポイントの小さなトレーニングセットから新しいサンプルをテストする新しい方法で、近年注目を集めています。実際、glicoは、わずか5または10を使用して、すべてのクラスの完全に新しいサンプルを合成することを学びますクラスごとの例</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-31">
        <br><font color="black">2020-03-31</font>
      </time>
    </span>
</section>
<!-- paper0: Training Interpretable Convolutional Neural Networks by Differentiating
  Class-specific Filters -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_85.html">
      <font color="black">Training Interpretable Convolutional Neural Networks by Differentiating
  Class-specific Filters</font>
    </a>
  </h2>
  <font color="black">具体的には、学習可能なスパースクラス固有ゲート（CSG）構造を設計して、各フィルターに1つ（またはいくつか）のクラスを柔軟に割り当てます。主な理由の1つは、フィルタークラスの絡み合いにあります。フィルターとクラス間の多くの対応。広範な実験により、入力のスパースで高度なクラス関連の表現を生成する方法の優れたパフォーマンスが実証され、より強力な解釈が可能になります。 
[ABSTRACT]クラス固有のフィルターを奨励することにより、解釈可能なcnnをトレーニングする新しい戦略を提案します。そのうちの1つのクラスにのみ応答します。ゲートにより、入力サンプルが特定のクラスからのものである場合にのみフィルターのアクティブ化を通過させることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Fair DARTS: Eliminating Unfair Advantages in Differentiable Architecture
  Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_86.html">
      <font color="black">Fair DARTS: Eliminating Unfair Advantages in Differentiable Architecture
  Search</font>
    </a>
  </h2>
  <font color="black">現在、Differentialable Architecture Search（DARTS）は、広く普及している重み共有ニューラルアーキテクチャ検索方法です。これにより、排他的な競争が緩和されて協調的であるFair DARTSと呼ばれる新しいアプローチを示します。具体的には、各操作のアーキテクチャの重みを他から独立しています。 
[ABSTRACT]アーキテクチャの根本は異なる方法で実行されています。ただし、パフォーマンスの崩壊の欠如に苦しんでいます。テストでは、2つの条件のいずれかが壊れている場合、崩壊が消えることを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-27">
        <br><font color="black">2019-11-27</font>
      </time>
    </span>
</section>
<!-- paper0: CenterNet3D:An Anchor free Object Detector for Autonomous Driving -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_87.html">
      <font color="black">CenterNet3D:An Anchor free Object Detector for Autonomous Driving</font>
    </a>
  </h2>
  <font color="black">KITTIベンチマークでは、提案されたCenterNet3Dは、提案された中心点表現の有効性を示す他の1ステージアンカーベースの方法で競争力のあるパフォーマンスを実現します。点群からの正確で高速な3Dオブジェクト検出は、自動運転の主要なタスクです。 、点群の固有のスパース性のため、3Dオブジェクトの中心点は空のスペースにある可能性が高く、正確な境界を推定することが困難になります。 
[ABSTRACT]中心点に基づいて、アンカーなしの3次元オブジェクト検出をその境界なしで実行する、アンカーのないcenternet3dネットワークを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-13">
        <br><font color="black">2020-07-13</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Object Permanence from Video -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_88.html">
      <font color="black">Learning Object Permanence from Video</font>
    </a>
  </h2>
  <font color="black">次に、これらの4つのシナリオでオブジェクトの場所を予測することを学習する統合されたディープアーキテクチャを示します。この学習問題を4つのコンポーネントに分解する必要がある理由を説明します。別のオブジェクトと（4）包含オブジェクトによって運ばれます。ここでは、データからオブジェクトの永続性を学習する設定を紹介します。 
[ABSTRACT]オブジェクトの永続性を学習するタスクは、世界のモデルを構築するために重要です。これは、自然な視覚シーン内のオブジェクトが隠れて互いに含まれているためです。このタスクは、データからオブジェクトを学習するために必要です。見えない物体の移動位置を説明するシステム</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-23">
        <br><font color="black">2020-03-23</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchical Dynamic Filtering Network for RGB-D Salient Object
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_89.html">
      <font color="black">Hierarchical Dynamic Filtering Network for RGB-D Salient Object
  Detection</font>
    </a>
  </h2>
  <font color="black">密に接続された構造を通じてさまざまなモダリティの機能を統合し、それらの混合機能を使用して、さまざまなサイズの受容野を持つ動的フィルターを生成します。6つのメトリックに関して、提案された方法は、8つの困難なベンチマークデータセットで既存の12の方法よりも優れています。最後に、一種のより柔軟で効率的なマルチスケールのクロスモーダル機能処理を実装します。つまり、
[要約]提案された方法は、8つの挑戦的なベンチマークデータセットで既存の12の方法よりも優れています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-13">
        <br><font color="black">2020-07-13</font>
      </time>
    </span>
</section>
<!-- paper0: REPrune: Filter Pruning via Representative Election -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_90.html">
      <font color="black">REPrune: Filter Pruning via Representative Election</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、精度をより迅速に回復し、微調整時にフィルターのシフトを少なくする必要があります。また、REPruneは、41.8％以上のFLOPを削減し、ResNet-18 for ImageNetで1.67％のトップ1検証損失を削減します。経験的に、REPruneは49％以上のFLOPを削減し、CIFAR-10のResNet-110で0.53％の精度向上を実現します。 
[ABSTRACT] repruneは49％以上のフロップを削減し、0。53％の精度をresnetで-110はcifar-10.itはまた、再プルーニングプロセスの他のフィルターの数を減らします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-14">
        <br><font color="black">2020-07-14</font>
      </time>
    </span>
</section>
<!-- paper0: AdvPC: Transferable Adversarial Perturbations on 3D Point Clouds -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_91.html">
      <font color="black">AdvPC: Transferable Adversarial Perturbations on 3D Point Clouds</font>
    </a>
  </h2>
  <font color="black">この点で、自動エンコーダ再構築後、最適化の目的に敵対的な損失を追加することにより、入力データの分布を悪用する新しい点群攻撃（AdvPCと呼ばれます）を開発します。AdvPCは、現在の防御に対して回復力のある摂動をもたらします。 、最先端の攻撃と比較して高度に転送可能であり続けます。現在の3D点群敵対攻撃における次の問題に対処することを目的としています。これらは異なるネットワーク間でうまく転送されず、シンプルな方法で簡単に防御できます。統計的手法。 
[要約]現在の3D点群敵対攻撃の問題に対処することを目的としています。これらは、異なるネットワーク間でうまく転送されず、単純な統計手法を使用して簡単に防御できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-01">
        <br><font color="black">2019-12-01</font>
      </time>
    </span>
</section>
<!-- paper0: Representation Quality Of Neural Networks Links To Adversarial Attacks
  and Defences -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_92.html">
      <font color="black">Representation Quality Of Neural Networks Links To Adversarial Attacks
  and Defences</font>
    </a>
  </h2>
  <font color="black">http://bit.ly/RepresentationMetrics ..で利用可能なコード。実験により、メトリックと敵対的攻撃の間の強い関連性（高いピアソン相関と低いp値）も明らかになります。1つはクラスター間検証手法（Davies -Bouldin Index）、そしてもう1つは近似されたグラウンドトゥルースまでの距離に基づいています。 
[要約]この堅牢性の欠如の根拠を理解するための重要なステップは、ニューラルネットワークの表現が既存の機能をエンコードする可能性を評価することです。主な考え方は、アルゴリズムが豊富な機能を学習する場合、そのような機能は「不明な」クラスを解釈する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-15">
        <br><font color="black">2019-06-15</font>
      </time>
    </span>
</section>
<!-- paper0: FakeSpotter: A Simple yet Robust Baseline for Spotting AI-Synthesized
  Fake Faces -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_93.html">
      <font color="black">FakeSpotter: A Simple yet Robust Baseline for Spotting AI-Synthesized
  Fake Faces</font>
    </a>
  </h2>
  <font color="black">ニューロンのカバレッジと相互作用に関する研究は、特に敵対的な攻撃にさらされている状況下で、ディープラーニングシステムのテスト基準として使用できることを示しています。4つのタイプの偽の顔を検出する実験結果は、最先端のGANと4つの摂動攻撃を回避することで、アプローチの有効性と堅牢性が示されます。ここでは、レイヤーごとのニューロンの活性化パターンがより多くのキャプチャを行う可能性があるため、ニューロンの動作を監視することも偽の顔を検出するための資産として役立つと推測偽の検出器にとって重要な微妙な機能。 
[ABSTRACT]私たちはAIクリスタルの偽の顔を見つけるためにニューロンの動作を監視することに基づいて、fakespotterと名付けられた新しいアプローチを提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-09-13">
        <br><font color="black">2019-09-13</font>
      </time>
    </span>
</section>
<!-- paper0: Suppress and Balance: A Simple Gated Network for Salient Object
  Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_94.html">
      <font color="black">Suppress and Balance: A Simple Gated Network for Salient Object
  Detection</font>
    </a>
  </h2>
  <font color="black">新しいゲートデュアルブランチ構造を設計して、さまざまなレベルの機能間の連携を構築し、ネットワーク全体の識別性を向上させます。さらに、提案された「フォールド」操作（フォールドASPP）に基づいて、アストロ空間ピラミッドプーリングを採用します。さまざまな縮尺の顕著オブジェクトを正確にローカライズするため。.デュアルブランチの設計により、顕著マップの詳細をさらに復元できます。 
[ABSTRACT]プールに加えて、顕著性マップの詳細をさらに復元できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Cross-Task Transfer for Geotagged Audiovisual Aerial Scene Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_95.html">
      <font color="black">Cross-Task Transfer for Geotagged Audiovisual Aerial Scene Recognition</font>
    </a>
  </h2>
  <font color="black">ソースコードは再現性の目的で公開されています。この目的のために、AuDio Visual Aerial sceNe reCognition datasEt（ADVANCE）という名前の新しいデータセットを作成しました。このデータセットを使用して、サウンドイベントを転送するための3つのアプローチを評価しますマルチモーダル学習フレームワークでの空中シーン認識タスクに関する知識、および空中シーン認識にオーディオ情報を活用する利点を示します。 
[ABSTRACT]これは、特定のサウンドイベントが特定の場所で聞こえる可能性が高いという観察に基づいています。サウンドイベントからの知識を活用して、空中シーン認識のパフォーマンスを向上させることを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-18">
        <br><font color="black">2020-05-18</font>
      </time>
    </span>
</section>
<!-- paper0: Improving rigid 3D calibration for robotic surgery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_96.html">
      <font color="black">Improving rigid 3D calibration for robotic surgery</font>
    </a>
  </h2>
  <font color="black">さらに、私たちの校正方法は、標準の外科用内視鏡に簡単に拡張して、実際の外科シナリオでの使用を促すことができます。自律性の基本的な要件の1つは、視覚センサーによる高度な知覚能力です。 
[ABSTRACT]カメラとロボットのキャリブレーションは、高性能の外科医をエミュレートするためにツールを正確に配置するために必要です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Kronecker Attention Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_97.html">
      <font color="black">Kronecker Attention Networks</font>
    </a>
  </h2>
  <font color="black">これにより、計算リソースに過剰な要件が発生するだけでなく、データの構造を保持することもできません。実験結果は、私たちの方法が必要な計算リソースの量を数百倍削減し、高次元および高次の要素が大きいことを示しています。データ..注意演算子は、テキストなどの1次元データと、画像や動画などの高次データの両方に適用されています。 
[要約]この作業では、データが行列に従うと仮定することで平坦化を回避することを提案します-提案されたカオスに基づく変量正規分布、それは認知リソースの劇的な削減につながります。オリジナルのアテンションオペレーターと同等の競争力を実現</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: A Balanced and Uncertainty-aware Approach for Partial Domain Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_98.html">
      <font color="black">A Balanced and Uncertainty-aware Approach for Partial Domain Adaptation</font>
    </a>
  </h2>
  <font color="black">一方では、負の転送は、ソースサンプルにのみ存在するクラスへのターゲットサンプルの誤分類を引き起こします。この問題に対処するために、BAAはドメイン全体のラベル分布間のバランスをかなり単純な方法で追求します。具体的には、ランダムに異なるドメインのクラスが対称になるように、ドメインの調整中に小さいターゲットドメインを拡大するいくつかのソースサンプル。 
[ABSTRACT]転送が悪いと、ターゲットサンプルがソースドメインにのみ存在するクラスに誤って分類されます。nukekekekekekekekekekekekekekekekekekekeによると、システムは以前の方法で開発されたほど悪くはないとしています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-05">
        <br><font color="black">2020-03-05</font>
      </time>
    </span>
</section>
<!-- paper0: Kernelized Memory Network for Video Object Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_99.html">
      <font color="black">Kernelized Memory Network for Video Object Segmentation</font>
    </a>
  </h2>
  <font color="black">以前の作品とは異なり、事前トレーニングでHide-and-Seek戦略を使用して、オクルージョンの処理とセグメント境界の抽出で最良の結果を取得します。STMとVOSの不一致を解決するために、カーネル化メモリネットワーク（KMN ..提案されたKMNは、標準的なベンチマークの最先端技術を大幅に上回っています（DAVIS 2017 test-devセットで+ 5％）。 
[要旨]時空間メモリネットワーク（stm）は、半監視付きvosの有望なソリューションとして大きな注目を集めています。これは、ネットワークが初めて宇宙監視付きvosに設定されたときです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Enhanced detection of fetal pose in 3D MRI by Deep Reinforcement
  Learning with physical structure priors on anatomy -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_100.html">
      <font color="black">Enhanced detection of fetal pose in 3D MRI by Deep Reinforcement
  Learning with physical structure priors on anatomy</font>
    </a>
  </h2>
  <font color="black">現在のモーションアーティファクトの軽減は、主に高速のシングルショットMRIと遡及的なモーション補正によって実行されます。このタスクでは、15のエージェントが展開され、DRLによって15のランドマークを同時に検出します。推定された胎児の動きが低遅延の意思決定を伴うオンラインスライス処方と組み合わされている場合に、胎児の動きのアーチファクトを検出して軽減する方法。 
[ABSTRACT]モーションアーティファクトの現在の軽減は、通常、高速のシングルショットmriと遡及的なモーション補正によって実行されます。現在、高速のシングルショットmriに基づいており、新しいdrlは胎児のランドマーク検出に新しいアプローチを提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Evaluating Driver Fatigue with Robust Deep Learning Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_101.html">
      <font color="black">Towards Evaluating Driver Fatigue with Robust Deep Learning Models</font>
    </a>
  </h2>
  <font color="black">新しいまばたきデータセットを使用して目モデルを開発し、野生のクローズドアイ（CEW）を使用して顔モデルを開発します。まばたきを検出する目モデルで95.84％の精度、顔モデルで80.01％の精度を達成します。このホワイトペーパーでは、ドライバーの疲労を検出するためのさまざまなディープラーニングベースのアプローチを探索します。 
[要約]私たちは、眠気を検出するためのゲートウェイとして、キャプチャされたカメラフレームの目の閉まりを検出するフレームワークを提案します。95.84％の精度を達成します。まばたきと80.01％のノイズノイズノイズを検出します。仕事は、眠気のある運転に関連する潜在的な車両事故を回避するためのドライバー疲労検出の分野に役立ちます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Learning from Noisy Labels with Deep Neural Networks: A Survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_102.html">
      <font color="black">Learning from Noisy Labels with Deep Neural Networks: A Survey</font>
    </a>
  </h2>
  <font color="black">次に、46の最先端の堅牢なトレーニング方法の包括的なレビューを提供します。これらはすべて、方法論の違いに従って7つのグループに分類され、その後、その優位性を評価するために使用される6つのプロパティの体系的な比較が続きます。ノイズの多いラベルはディープニューラルネットワークの一般化パフォーマンスを大幅に低下させます。ノイズの多いラベルからの学習（堅牢なトレーニング）は、現代のディープラーニングアプリケーションで重要なタスクになりつつあります。 
[ABSTRACT]高品質のリサーチが不足しているため、データラベルの品質が懸念されています。データ品質が低いため、品質の悪いデータが心配されています。リサーチの質が低いため、データラベルが心配されています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Learning Depth With Very Sparse Supervision -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_103.html">
      <font color="black">Learning Depth With Very Sparse Supervision</font>
    </a>
  </h2>
  <font color="black">提案されたネットワークは、連続する2つの画像から、画像と密な深度マップの間の観察者の動きの潜在的な表現を出力します。複数のデータセットでの実験により、グラウンドトゥルースが画像ピクセルの1つでも利用できる場合、提案されたネットワークは、最先端のアプローチよりも正確に最大22.5％単眼密深度推定を学習できます。具体的には、環境と相互作用するロボットが利用できるものを使用して、特殊なグローバルローカルネットワークアーキテクチャをトレーニングします。画像ごとに1ピクセルまでの非常にまばらな深度測定。 
[ABSTRACT]提案されたネットワークは、最先端のアプローチよりも正確に最大22.5％の密な深度推定を学習できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-02">
        <br><font color="black">2020-03-02</font>
      </time>
    </span>
</section>
<!-- paper0: Learning to Restore a Single Face Image Degraded by Atmospheric
  Turbulence using CNNs -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_104.html">
      <font color="black">Learning to Restore a Single Face Image Degraded by Atmospheric
  Turbulence using CNNs</font>
    </a>
  </h2>
  <font color="black">乱流で劣化した顔画像を復元する問題に対するディープラーニングベースのソリューションを提示します。顔画像の各位置での幾何学的歪みとぼかしの量に関する事前情報は、最初に2つの個別のネットワークを使用して推定されます。損失はTDRNをトレーニングするために提案され、乱流の劣化の影響を軽減するために1次および2次の画像勾配が信頼マップとともに計算されます。次に、推定された事前情報は、乱流歪み除去ネットワーク（TDRN）と呼ばれるネットワークによって使用されます。幾何学的な歪みを修正し、顔画像のぼけを減らします。 
[ABSTRACT]と呼ばれる乱流歪み除去ネットワーク（tdrn）は、ぼやけを軽減できます。このフレームワークは、大気の乱気流によって引き起こされるぼやけや幾何学的歪みを軽減できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Angle-based Search Space Shrinking for Neural Architecture Search -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_105.html">
      <font color="black">Angle-based Search Space Shrinking for Neural Architecture Search</font>
    </a>
  </h2>
  <font color="black">この作業では、ニューラルアーキテクチャ検索（NAS）のために、角度ベースの検索スペース縮小（ABS）と呼ばれるシンプルで一般的な検索スペース縮小方法を紹介します。特に、縮小プロセスをガイドする角度ベースのメトリックを提案します.. SPOS、FairNAS、ProxylessNAS、DARTSおよびPDARTS）。 
[ABSTRACT]私たちのアプローチは、見込みのない候補を削除することにより、元の検索スペースを徐々に簡素化し、既存のnasメソッドが優れたアーキテクチャを見つける困難を軽減します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-28">
        <br><font color="black">2020-04-28</font>
      </time>
    </span>
</section>
<!-- paper0: 6D Camera Relocalization in Ambiguous Scenes via Continuous Multimodal
  Inference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_106.html">
      <font color="black">6D Camera Relocalization in Ambiguous Scenes via Continuous Multimodal
  Inference</font>
    </a>
  </h2>
  <font color="black">$ \ href {https://multimodal3dvision.github.io} {multimodal3dvision.github.io} $。でコードとデータセットをリリースする予定です。代わりに、複数のカメラポーズ仮説と各予測のそれぞれの不確実性を予測します。 。カメラポーズの多様体で定義された連続混合モデルで曖昧性と不確実性をキャプチャするマルチモーダルカメラ再配置フレームワークを提示します。 
[ABSTRACT]新しいデータセットは、あいまいな環境でのカメラのローカリゼーション調査を促進するように設計されています。「ビンガム」と多変量ガウスの混合を使用して、カメラのポーズの位置をモデル化します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-09">
        <br><font color="black">2020-04-09</font>
      </time>
    </span>
</section>
<!-- paper0: Comprehensive Facial Expression Synthesis using Human-Interpretable
  Language -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_107.html">
      <font color="black">Comprehensive Facial Expression Synthesis using Human-Interpretable
  Language</font>
    </a>
  </h2>
  <font color="black">自然言語の有効性を検証するために、広範な定性的および定量的評価が実施されました。本手法は、詳細な表情で顔画像を合成できます。顔の表情合成における最近の進歩は、顔のアクションユニットを含む多様な表情表現を使用して有望な結果を示しています。 
[ABSTRACT]言語ベースの表情記述から新しい表情合成モデルを提案します。この方法では、個々の単語を制御して顔の動きの各部分を処理できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Shape Prior Deformation for Categorical 6D Object Pose and Size
  Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_108.html">
      <font color="black">Shape Prior Deformation for Categorical 6D Object Pose and Size
  Estimation</font>
    </a>
  </h2>
  <font color="black">さらに、私たちのネットワークは、オブジェクトインスタンスの深度観測と再構築された3Dモデル間の密な対応を推測して、6Dオブジェクトのポーズとサイズを共同で推定します。6Dポーズと見えないオブジェクトインスタンスのサイズをRGB-D画像。オブジェクトモデルのコレクションをトレーニングするオートエンコーダを設計し、各カテゴリの平均潜在埋め込みを計算して、カテゴリ形状の事前分布を学習します。 
[ABSTRACT]事前に学習したカテゴリカル形状からオブジェクトを明示的にモデル化して、3Dオブジェクトモデルを再構築するネットワークを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Natural Graph Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_109.html">
      <font color="black">Natural Graph Networks</font>
    </a>
  </h2>
  <font color="black">基本カテゴリー理論を使用して、多くの異なる同変ニューラルネットワークを自然ネットワークとして形式化し、それらのカーネルが2つのファンクター間の「単なる」自然変換であることを示します。等変メッセージネットワークを使用するグラフ上で、自然ネットワークの1つの実際のインスタンス化を行いますパラメータ化により、いくつかのベンチマークで良好なパフォーマンスが得られます。従来のニューラルメッセージパッシングアルゴリズムは、メッセージの順列に対して不変であり、したがって、情報がネットワークをどのように流れるかを忘れます。 
[ABSTRACT]ネットワークはローカルネットワークおよびグローバルネットワークと同等です。これらには、同等のメッセージネットワークリソースリソースリソースが含まれます。このメソッドを使用して、ネットワークの応答性を高めることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Human Pose Estimation on Privacy-Preserving Low-Resolution Depth Images -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_110.html">
      <font color="black">Human Pose Estimation on Privacy-Preserving Low-Resolution Depth Images</font>
    </a>
  </h2>
  <font color="black">異なる超解像で生成された中間特徴マップを利用することにより、私たちのアプローチは、フル解像度画像（サイズ640x480）でトレーニングおよびテストされたアプローチと同等の低解像度画像（サイズ64x48）でボディポーズ結果を実現します..低解像度のプライバシー保護画像を単独で使用できることは、これらの懸念に対処し、そのようなデータに依存するコンピューター支援アプローチをより多くのORにスケールアップするのに役立ちます。人間の姿勢推定（HPE）は重要な構築です手術室（OR）内でAIベースのコンテキスト認識システムを開発するためのブロック。 
[ABSTRACT] rgb-dセンサーでキャプチャされた奥行きのある画像でも、人間のポーズデータを使用してプライバシーを保護できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: 3D CNN-PCA: A Deep-Learning-Based Parameterization for Complex Geomodels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_111.html">
      <font color="black">3D CNN-PCA: A Deep-Learning-Based Parameterization for Complex Geomodels</font>
    </a>
  </h2>
  <font color="black">最後に、CNN-PCAは、バイモーダルチャネライズドシステムのESMDAとの履歴マッチングに正常に適用されます。ここで示す3D処理は、2D CNN-PCA手順で使用されるものとは多少異なります。生成には3D CNN-PCAアルゴリズムが適用されます。 $ 60 \ times60 \ times40 $グリッドで定義された条件付き3D実現の3つの地質学的シナリオ（バイナリおよびバイモーダルチャネル化システム、および3相チャネル-堤防-泥システム）。 
[ABSTRACT] cnn-pcaは、ジオモデルの低剛性主成分分析表現のポストプロセッサーとしての畳み込みニューラルネットワークの使用を伴います。処理には、スタイルと組み合わせて使用される新しい監視あり学習ベースの再構成損失が含まれます。損失とハードデータの損失</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: An Empirical Study on the Robustness of NAS based Architectures -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_112.html">
      <font color="black">An Empirical Study on the Robustness of NAS based Architectures</font>
    </a>
  </h2>
  <font color="black">さまざまなサイズのデータセットの実験を通じて、現在のNAS手法が敵対的な攻撃に対処する能力についていくつかの重要な結論を導き出します。ニューラルアーキテクチャ検索（NAS）のほとんどの既存の手法は、最新の（SOTA）パフォーマンスを標準のデータセットを使用し、敵対的に堅牢なモデルを明示的に検索しません。この作業では、既存のNASアーキテクチャの敵対的な堅牢性を調査し、それを最先端の手作りアーキテクチャと比較し、それが不可欠である理由を示します。 
[ABSTRACT]新しいアートワークは、既存のNASアーキテクチャと最先端の技術を示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Patch-wise Attack for Fooling Deep Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CV/paper_113.html">
      <font color="black">Patch-wise Attack for Fooling Deep Neural Network</font>
    </a>
  </h2>
  <font color="black">具体的には、各反復のステップサイズに増幅係数を導入し、$ \ epsilon $ -constraintをオーバーフローする1ピクセルの全体的な勾配が、プロジェクトカーネルによってその周囲の領域に適切に割り当てられます。これを動機として、パッチ-賢明な反復アルゴリズム-通常訓練された主流の防御モデルに対するブラックボックス攻撃。これは、ピクセル単位のノイズを操作する既存の攻撃方法とは異なります。このように、ホワイトボックス攻撃のパフォーマンスを犠牲にすることなく、私たちの敵対的な例は譲渡性が強い。 
[要旨]私たちのツールは、一般に、あらゆる勾配ベースのフロー攻撃に統合できます。また、ホワイトボックス攻撃の敵対的なバージョンを作成するために使用することもできます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-14">
        <br><font color="black">2020-07-14</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: On Emergent Communication in Competitive Multi-Agent Teams -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CL/paper_0.html">
      <font color="black">On Emergent Communication in Competitive Multi-Agent Teams</font>
    </a>
  </h2>
  <font color="black">テストベッドとして2つの協力エージェント間の以前に提案された参照ゲームであるTask＆Talkから開始し、それをTask、Talk＆Competeに拡張します。マルチエージェントチームへの競争力の影響を実証する実証的研究を提供します。私たちの結果は、外部の競争力の影響により、精度と一般化が向上し、より有益で構成的なコミュニケーション言語がより早く出現することを示しています。 
[要約]人間の集団は、コミュニケーション行動を含む複雑なタスクを解決することを学びます。外部の競争の影響により、精度と一般化が向上し、より有益で構成的なコミュニケーション言語の形成が速くなります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-04">
        <br><font color="black">2020-03-04</font>
      </time>
    </span>
</section>
<!-- paper0: LogiQA: A Challenge Dataset for Machine Reading Comprehension with
  Logical Reasoning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CL/paper_1.html">
      <font color="black">LogiQA: A Challenge Dataset for Machine Reading Comprehension with
  Logical Reasoning</font>
    </a>
  </h2>
  <font color="black">人間の論理的推論をテストするために専門家が作成した質問から得られるLogiQAという名前の包括的なデータセットを構築します。機械読み取りは、自然言語理解の機能をテストするための基本的なタスクであり、多くの点で人間の認識と密接に関連しています。データセットは、https：//github.com/lgw863/LogiQA-datasetで無料で入手できます。
[ABSTRACT] logiqaという名前の新しいデータセットは、githubで入手できます。 com.itは、人間の推論をテストするための67の質問で構成されています。データセットはインターネットで入手できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Implicit Diversity in Image Summarization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CL/paper_2.html">
      <font color="black">Implicit Diversity in Image Summarization</font>
    </a>
  </h2>
  <font color="black">視覚的に多様な画像のセットを入力として受け取り、このセットを使用してクエリに応じて人物の画像のセットを選択する新しいアプローチを開発します。重要なのは、このアプローチでは画像にラベルを付ける必要がないことです。効果的には、選択された画像のセットを暗黙的に多様化する方法を提供します。さらに、これらのラベルを推測するための自動化技術の使用は、許容可能な精度範囲内では不可能であることが多く、このプロセスで発生する可能性がある追加のバイアスのために望ましくない場合があります。 
[要約]この種のバイアスを修正するための新しいアプローチは、人々の画像に社会的に顕著な属性ラベルが含まれていることを前提としています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-01-29">
        <br><font color="black">2019-01-29</font>
      </time>
    </span>
</section>
<!-- paper0: Investigating Pretrained Language Models for Graph-to-Text Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CL/paper_3.html">
      <font color="black">Investigating Pretrained Language Models for Graph-to-Text Generation</font>
    </a>
  </h2>
  <font color="black">特にKGからテキストを生成するときに、世界についての知識が彼らに大きな利点をもたらすという証拠を見つけます。データからテキストへの生成のサブタスクであるグラフからテキストへの生成は、グラフベースのデータから流暢なテキストを生成することを目的としています..意味表現、ウィキペディアの知識グラフ（KG）、科学的KGの3つのグラフドメインにわたる研究を提示します。 
[ABSTRACT]多くのグラフからテキストモデルは、専用のグラフエンコーダーを使用して、このタスクで強力なパフォーマンスを示しています。成功したplmsの数を調べるために、大きなplmsからテキストの生成の影響を調査することを目的としています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Translate Reverberated Speech to Anechoic Ones: Speech Dereverberation
  with BERT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CL/paper_4.html">
      <font color="black">Translate Reverberated Speech to Anechoic Ones: Speech Dereverberation
  with BERT</font>
    </a>
  </h2>
  <font color="black">私たちの方法を評価するために、3番目のCHiMEチャレンジからのデータを使用し、結果を他の方法と比較します。基本的なBERTモデルのバリエーションを提示します。ローカルのスペクトル時間情報を抽出するプレシーケンスネットワークおよび/またはバックボーンシーケンスモデルの前に、順序情報を提供します。この作業では、単一チャネルの音声残響除去が考慮されます。 
[要約]提案された方法は従来の方法wpeよりも優れており、最先端のblstmベースのシーケンスモデルと同等のパフォーマンスを実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Flowtron: an Autoregressive Flow-based Generative Network for
  Text-to-Speech Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CL/paper_5.html">
      <font color="black">Flowtron: an Autoregressive Flow-based Generative Network for
  Text-to-Speech Synthesis</font>
    </a>
  </h2>
  <font color="black">Flowtronは、音声合成の多くの側面（ピッチ、トーン、スピーチレート、リズム、アクセント）を制御するために操作できる潜在空間へのデータの可逆マッピングを学習します。コードと事前トレーニング済みモデルは、https：で公開されます。 //github.com/NVIDIA/flowtron。平均オピニオンスコア（MOS）は、Flowtronが音声品質の面で最新のTTSモデルと一致することを示しています。 
[ABSTRACT] flowgreはiafから洞察を借用し、高品質で表現力豊かなメルの予約注文に利用できるtacotron.itを改良しました-spectrovid</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br><font color="black">2020-05-12</font>
      </time>
    </span>
</section>
<!-- paper0: Coupling Distant Annotation and Adversarial Training for Cross-Domain
  Chinese Word Segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CL/paper_6.html">
      <font color="black">Coupling Distant Annotation and Adversarial Training for Cross-Domain
  Chinese Word Segmentation</font>
    </a>
  </h2>
  <font color="black">遠方のアノテーションについては、「中国語の単語」の本質を再考し、ターゲットドメインからの監督や事前定義済みの辞書を必要としない自動遠方アノテーションメカニズムを設計します。このアプローチは、ドメイン固有の単語を効果的に探索し、ターゲットドメインの生のテキスト..パフォーマンスの低下は、ドメイン間の分散ギャップとボキャブラリー（OOV）の問題が原因で発生します。 
[ABSTRACT]このペーパーでは、クロスドメインcwsの遠方のアノテーションと敵対的なトレーニングを組み合わせることが提案されています。このアプローチは、タスクを効果的に探索し、ターゲットドメインの生のテキストに遠方のアノテーションを付けることができます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Debiasing Sentence Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CL/paper_7.html">
      <font color="black">Towards Debiasing Sentence Representations</font>
    </a>
  </h2>
  <font color="black">Sent-Debiasはバイアスの除去に効果的であると同時に、感情分析、言語的受容性、自然言語理解などの文レベルのダウンストリームタスクのパフォーマンスを維持することを示しています。レベル埋め込み、ELMoやBERTなどの文脈化された新しい文表現への最近のシフトを考えると、文レベルでデバイアスを実行する必要があります。より公正なNLPの表現。 
[ABSTRACT] debiasで送信された新しい方法は、社会的偏見を減らすことを目的としています。それは、社会的偏見の特徴付けと削除に関するより多くの研究につながる可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Hierarchical Interaction Networks with Rethinking Mechanism for
  Document-level Sentiment Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CL/paper_8.html">
      <font color="black">Hierarchical Interaction Networks with Rethinking Mechanism for
  Document-level Sentiment Analysis</font>
    </a>
  </h2>
  <font color="black">実験結果は、提案されたモデルの有効性を一貫して示し、HIN-SRがさまざまな最先端の方法よりも優れていることを示しています。その結果、表現を制限して、ドキュメント内の主要なポイントを表現しました。これは、主要な感情..さらに、感情ラベル情報を使用してHINを改良することにより、感情ベースの再考メカニズム（SR）を設計し、より感情を意識したドキュメント表現を学習します。 
[ABSTRACT]要約とドキュメント間の識別的相互作用を調査するための新しいシステムが提案されています。この概念は、ユーザーがデータの知覚された使用に関する情報を共有できるシステムを開発するために使用できます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: SLK-NER: Exploiting Second-order Lexicon Knowledge for Chinese NER -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CL/paper_9.html">
      <font color="black">SLK-NER: Exploiting Second-order Lexicon Knowledge for Chinese NER</font>
    </a>
  </h2>
  <font color="black">レキシコンを使用した文字ベースのモデルは、中国語の名前付きエンティティ認識（NER）タスクで有望な結果を達成しましたが、一部の語彙は、誤って一致する単語が原因で誤った情報を導入します。これら、我々は上記の辞書の知識を統合する新しい戦略とSLKベースのモデルを提案します。 
[要約]提案されたモデルは、グローバルコンテキストの助けを借りて、より識別可能な語彙情報を活用できます。このモデルは、最新の比較方法よりも優れたパフォーマンスを実現します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Span-ConveRT: Few-shot Span Extraction for Dialog with Pretrained
  Conversational Representations -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CL/paper_10.html">
      <font color="black">Span-ConveRT: Few-shot Span Extraction for Dialog with Pretrained
  Conversational Representations</font>
    </a>
  </h2>
  <font color="black">スロットフィリングタスクのスパン抽出に関する作業をさらに刺激するために、レストラン予約ドメインでの実際の会話からコンパイルされた8,198発話の新しい挑戦的なデータセットであるRESTAURANTS-8Kもリリースします。このような知識を活用して、 Span-ConveRTは、数ショットの学習シナリオで特に有用です。1）ターゲットドメインでゼロから表現をトレーニングするスパンエクストラクタ、および2）BERTベースのスパンエクストラクタの一貫したゲインを報告します。この定式化により、簡単なConveRT（Henderson et al。、2019）などの大規模な事前トレーニング済み会話モデルでコーディングされた会話知識の統合。 
[ABSTRACT]レストランもリリース-8k、8、198発話の新しいチャレンジデータセット。新しいチャレンジデータセットは、レストラン予約ドメインでの実際の会話からコンパイルされます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-18">
        <br><font color="black">2020-05-18</font>
      </time>
    </span>
</section>
<!-- paper0: Anchor & Transform: Learning Sparse Representations of Discrete Objects -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/cs.CL/paper_11.html">
      <font color="black">Anchor & Transform: Learning Sparse Representations of Discrete Objects</font>
    </a>
  </h2>
  <font color="black">ANTはスケーラブルで柔軟なエンドツーエンドのトレーニングが可能であり、ユーザーはオブジェクトの関係に関するドメイン知識を組み込むことができます。小分散漸近法に基づいて近似推論アルゴリズムを導出することにより、最適なものを自動的に学習するシンプルで自然な拡張を取得しますハイパーパラメーターとして調整する代わりに、アンカーの数。埋め込みを事前にベイズノンパラメトリックとしてアルゴリズムの統計的解釈を提供し、オブジェクト間のスパース性を促進し、自然なグループ化を活用します。 
[ABSTRACT]個別のオブジェクトの埋め込みはアンカーの疎な線形結合であるため、メソッドをアンカー＆変換（ant）と呼びます。さらに、オブジェクト間の自然なグループ化を組み込む埋め込みのバイリタノンパラメトリックとしてアルゴリズムの統計的解釈を提供します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br><font color="black">2020-03-18</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Device-Robust Acoustic Scene Classification Based on Two-Stage
  Categorization and Data Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.AS/paper_0.html">
      <font color="black">Device-Robust Acoustic Scene Classification Based on Two-Stage
  Categorization and Data Augmentation</font>
    </a>
  </h2>
  <font color="black">コードが利用可能です：https://github.com/MihawkHu/DCASE2020_task1 .. 2ステージの分類器を実装するために4つの異なるCNNベースのアーキテクチャが検討されており、いくつかのデータ拡張手法も調査されています。タスク1b開発データセットでは、 500KB未満のモデルサイズで96.7 \％の精度を実現します。 
[要約]タスク1には、複数のデバイスで記録されたオーディオ信号のascが含まれます。10の異なる細かいクラスがタスク1に含まれます。4つの異なるcnnベースのアーキテクチャが、2ステージの分類器を実装するために検討されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Temporal-Framing Adaptive Network for Heart Sound Segmentation without
  Prior Knowledge of State Duration -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.AS/paper_1.html">
      <font color="black">Temporal-Framing Adaptive Network for Heart Sound Segmentation without
  Prior Knowledge of State Duration</font>
    </a>
  </h2>
  <font color="black">TFANベースのメソッドは、2016 PhysioNet / Computer in Cardiology ChallengeのトレーニングセットAからランダムに選択された50のレコーディングでトレーニングされ、他の12の独立したトレーニングおよびテストデータベースでテストされました（2099レコーディングおよび52180ビート）。メソッド：以前の最先端のアプローチでは、TFANベースの方法は心音の状態の持続時間に関する知識を必要としないため、非洞調律に一般化される可能性があります。このアプローチの範囲を理解するには、さらに作業が必要です。優れたセグメンテーションが診断の改善につながると想定するのは当然ですが、診断パフォーマンスが向上します。 
[ABSTRACT] tfanベースの方法は、心音の状態の持続時間に関する知識を必要としないため、非洞調律に一般化される可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-09">
        <br><font color="black">2020-05-09</font>
      </time>
    </span>
</section>
<!-- paper0: Streaming Transformer ASR with Blockwise Synchronous Inference -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.AS/paper_2.html">
      <font color="black">Streaming Transformer ASR with Blockwise Synchronous Inference</font>
    </a>
  </h2>
  <font color="black">トランスフォーマーエンコーダーのブロック処理方法を、コンテキストアウェアな継承メカニズムを導入することで提案しました。このホワイトペーパーでは、追加のトレーニングなしで、ストリーミングE2E ASRシステム全体に向けてブロック処理を拡張し、トランスフォーマーデコーダーへのニューラルトランスデューサー。私たちのストリーミングASRモデルは、すべてのタスクでバッチモデルや他のストリーミングベースのトランスフォーマーメソッドに匹敵する/優れたパフォーマンスを実現します。 
[ABSTRACT] transformerには、トランスフォーマーシステムを使用する新しいシステムがあります。これは、トランスフォーマーを使用してトランスフォーマーを変換するために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-25">
        <br><font color="black">2020-06-25</font>
      </time>
    </span>
</section>
<!-- paper0: A time-scale modification dataset with subjective quality labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.AS/paper_3.html">
      <font color="black">A time-scale modification dataset with subjective quality labels</font>
    </a>
  </h2>
  <font color="black">結果の分析では、年齢と評価の質の間に相関関係はありません。エキスパートリスナーと非エキスパートリスナーが同等であること。聴覚に問題がある場合とない場合の参加者のわずかな違い。 2つの部分で構成されるトレーニングコンポーネントには、10のタイムスケールで6つのTSMメソッドを使用して処理された88のソースファイルが含まれ、テストコンポーネントには、4つのタイムスケールで3つの追加のメソッドを使用して処理された20のソースファイルが含まれています。ラベル付きのデータセットは、http：//ieee-dataport.org/1987で入手できます。 
[ABSTRACT]データセットの分析では、年齢と評価の品質の間に相関関係はありません。結果の分析は、testing.datasetに使用するデータセットの分析の分析に基づいています。データセットには、スピーチ、ソロハーモニック、パーカッシブコンポーネントが含まれています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-01">
        <br><font color="black">2020-06-01</font>
      </time>
    </span>
</section>
<!-- paper0: Vibration Analysis in Bearings for Failure Prevention using CNN -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.AS/paper_4.html">
      <font color="black">Vibration Analysis in Bearings for Failure Prevention using CNN</font>
    </a>
  </h2>
  <font color="black">提案された戦略の有効性は優れており、最先端の他のアプローチよりも優れていることがわかりました。これに続いて、摩耗レベルを分類し、回転システムを診断するためのAlexNetアーキテクチャに基づくCNNモデルを提案します。次に、未加工の振動データが小さな正方形の画像に変換されます。データの各サンプルは画像の1ピクセルを表します。 
[要約]畳み込みニューラルネットワークに基づく方法を提案します。この方法はcnnの情報システムに基づいています。この方法は、センサーの組み合わせに基づく可能性があります</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-06">
        <br><font color="black">2020-05-06</font>
      </time>
    </span>
</section>
<!-- paper0: Audio Tagging by Cross Filtering Noisy Labels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.AS/paper_5.html">
      <font color="black">Audio Tagging by Cross Filtering Noisy Labels</font>
    </a>
  </h2>
  <font color="black">オーディオタグ付けデータセットFSDKaggle2018とFSDKaggle2019の両方で、実験結果は他の競合するアプローチと比較してパフォーマンスが向上していることを示しています。次に、2つのニューラルネットワークの連携と相互作用を介して、データセットをキュレートされたノイズの多いサブセットに分割します。ノイズの多いデータから正しくラベル付けされたデータ。高品質のラベル付けされたデータセットにより、ディープラーニングは多くのサウンド分析タスクで印象的な結果を達成できました。 
[要約]このペーパーでは、ノイズの多いラベルの問題に対処するための新しいフレームワークを紹介します。これらには、正しくラベル付けされている可能性のあるデータを段階的に選択することが含まれます。ノイズの多いロバストな損失関数を使用して、誤ったラベルの悪影響を緩和します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Translate Reverberated Speech to Anechoic Ones: Speech Dereverberation
  with BERT -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.AS/paper_6.html">
      <font color="black">Translate Reverberated Speech to Anechoic Ones: Speech Dereverberation
  with BERT</font>
    </a>
  </h2>
  <font color="black">私たちの方法を評価するために、3番目のCHiMEチャレンジからのデータを使用し、他の方法と結果を比較します。基本的なBERTモデルのバリエーションを提示します。ローカルのスペクトル時間情報および/またはは、バックボーンシーケンスモデルの前に注文情報を提供します。実験は、提案された方法が従来の方法WPEよりも優れており、最先端のBLSTMベースのシーケンスモデルと同等のパフォーマンスを達成することを示しています。 
[要約]提案された方法は従来の方法wpeよりも優れており、最先端のblstmベースのシーケンスモデルと同等のパフォーマンスを実現します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Automatic Detection of Cue Points for DJ Mixing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.AS/paper_7.html">
      <font color="black">Automatic Detection of Cue Points for DJ Mixing</font>
    </a>
  </h2>
  <font color="black">プロのDJとのインタビューから確立したいくつかの一般的なルールを具体化するスイッチポイントの検出方法を紹介します。これらのルールの実装は、機能の抽出とノベルティ分析に基づいています。キューポイントの自動識別は、音楽のサムネイル、マッシュアップの生成、DJミキシングなど、さまざまなアプリケーションの中心的なタスクです。生成されたスイッチポイントの品質それらを、私たちがキュレーションした手動で注釈を付けたデータセットと比較することと、それらを個別に評価することの両方によって評価されます。 
[要約]キューポイントの品質は、手動で注釈を付けたデータセットと比較し、個別に評価することによって評価されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
<!-- paper0: Flowtron: an Autoregressive Flow-based Generative Network for
  Text-to-Speech Synthesis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.AS/paper_8.html">
      <font color="black">Flowtron: an Autoregressive Flow-based Generative Network for
  Text-to-Speech Synthesis</font>
    </a>
  </h2>
  <font color="black">さらに、音声変動の制御、サンプル間の補間、トレーニング中に見られたスピーカーと見られなかったスピーカー間のスタイル転送に関する結果を提供します。Flowtronは、IAFからの洞察を取り入れ、Tacotronを改良して、高品質で表現力豊かなメルスペクトログラム合成を提供します。平均オピニオンスコア（MOS）は、Flowtronが音声品質の面で最新のTTSモデルと一致することを示しています。 
[ABSTRACT] flowgreはiafから洞察を借用し、高品質で表現力豊かなメルの予約注文に利用できるtacotron.itを改良しました-spectrovid</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-12">
        <br><font color="black">2020-05-12</font>
      </time>
    </span>
</section>
<!-- paper0: Neural MOS Prediction for Synthesized Speech Using Multi-Task Learning
  With Spoofing Detection and Spoofing Type Classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-07-17/eess.AS/paper_9.html">
      <font color="black">Neural MOS Prediction for Synthesized Speech Using Multi-Task Learning
  With Spoofing Detection and Spoofing Type Classification</font>
    </a>
  </h2>
  <font color="black">ただし、MOSの評価者間および評価者内の変動性により、モデルの一般化能力を保証することが困難になります。VoiceConversion Challenge 2018の結果を使用した実験では、2つの補助タスクを持つ提案されたMTLがMOS予測を改善することが示されています。焦点損失を使用して、MOS予測のSDとSTC間の相乗効果を最大化します。 
[ABSTRACT] mosデータは、mosデータがmossで見つからなかったことを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-16">
        <br><font color="black">2020-07-16</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
