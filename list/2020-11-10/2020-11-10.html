<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/normalize.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<title>Akari-2020-11-10の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<body>
<div class="container">
<!--
	header
	-->

	<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
	  <a class="navbar-brand" href="index.html" align="center">
			<font color="white">Akari<font></a>
	</nav>

<br>
<br>
<div class="container" align="center">
	<header role="banner">
			<div class="header-logo">
				<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
			</div>
	</header>
<div>

<br>
<br>

<nav class="navbar navbar-expand-lg navbar-light bg-dark">
  Menu
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">

        <a class="nav-link" href="../../index.html"><font color="white">Home</font></a>
      </li>
			<li class="nav-item">
				<a id="about" class="nav-link" href="../../teamAkariとは.html"><font color="white">About</font></a>
			</li>
			<li class="nav-item">
				<a id="contact" class="nav-link" href="../../contact.html"><font color="white">Contact</font></a>
			</li>
			<li class="nav-item">
				<a id="newest" class="nav-link" href="../../list/newest.html"><font color="white">New Papers</font></a>
			</li>
			<li class="nav-item">
				<a id="back_number" class="nav-link" href="../../list/backnumber.html"><font color="white">Back Number</font></a>
			</li>
    </ul>
  </div>
</nav>


<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
<font color="black">cs.SD</font>
  </label></li>
<!-- field: eess.IV -->
  <li class="hidden_box">
    <label for="label1">
<font color="black">eess.IV</font>
  </label></li>
<!-- field: cs.CV -->
  <li class="hidden_box">
    <label for="label2">
<font color="black">cs.CV</font>
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label3">
<font color="black">cs.CL</font>
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label4">
<font color="black">eess.AS</font>
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<br><hr><br>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Statistical feature embedding for heart sound classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.SD/paper_0.html">
      <font color="black">Statistical feature embedding for heart sound classification</font>
    </a>
  </h2>
  <font color="black">その後、主成分分析（PCA）変換と変分オートエンコーダー（VAE）がiベクトルに適用され、次元削減が実現されます。最終的に、削減されたサイズのベクトルはガウス混合モデル（GMM）とサポートベクターマシン（SVM）に送られます。分類の目的で..この研究では、Physionetチャレンジ2016データセットの正常/異常な心臓音分類のためのアプローチが提案されています。 
[概要]病気の診断のための心音のパターンが増加しました。研究者は心音の改善システムを開発しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-26">
        <br><font color="black">2019-04-26</font>
      </time>
    </span>
</section>
<!-- paper0: Improving RNN Transducer Based ASR with Auxiliary Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.SD/paper_1.html">
      <font color="black">Improving RNN Transducer Based ASR with Auxiliary Tasks</font>
    </a>
  </h2>
  <font color="black">次に、両方の補助タスクがRNN-T基準のディープトランスフォーマーエンコーダーの学習に有効性を示し、以前の最高のパフォーマンスモデルと比較して競争力のある結果（LibriSpeechテストクリーン/その他で2.0％/ 4.2％WER）を達成することを確認します。さまざまなトレーニングデータサイズでソーシャルメディアビデオを転記する場合、まず、ルーマニア語、トルコ語、ドイツ語の3つの言語でストリーミングASRパフォーマンスを評価します。（i）プライマリRNN-T ASRタスクと同じ補助タスクを使用すること、および（ii）従来のハイブリッドモデリングと同様に、コンテキスト依存のグラフェミック状態予測を実行します。 
[概要]このモデルは、さまざまなベンチマークで競争力のあるasrパフォーマンスを示しています。プライマリrnnと同じ補助的な方法を使用することを提案します-tasr。両方の提案された方法は一貫した改善を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: A Hierarchical Subspace Model for Language-Attuned Acoustic Unit
  Discovery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.SD/paper_2.html">
      <font color="black">A Hierarchical Subspace Model for Language-Attuned Acoustic Unit
  Discovery</font>
    </a>
  </h2>
  <font color="black">転写された言語のセットでハイパー部分空間をトレーニングし、それをターゲット言語に転送します。ターゲット言語では、監視されていない方法で言語とユニットの埋め込みの両方を推測します。そうすることで、同時に次の部分空間を学習します。その言語に固有のユニットとそれに住むユニット..この作業では、音響ユニット発見のための階層型部分空間モデルを提案します。 
[概要]私たちのモデルは、クラスタリング品質とセグメンテーション精度の両方の点で、主要な音響ユニット発見技術よりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-04">
        <br><font color="black">2020-11-04</font>
      </time>
    </span>
</section>
<!-- paper0: Multichannel Online Dereverberation based on Spectral Magnitude Inverse
  Filtering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.SD/paper_3.html">
      <font color="black">Multichannel Online Dereverberation based on Spectral Magnitude Inverse
  Filtering</font>
    </a>
  </h2>
  <font color="black">音声強調と自動音声認識の両方に関する実験が行われ、提案された方法が、移動する話者の困難な場合でも、残響を効果的に抑制できることを実証します。複素数値のCTF畳み込みモデルの代わりに、非負の畳み込みモデルを使用します。ソース信号のSTFTの大きさとCTFの大きさの間。これは前者のモデルの大まかな近似ですが、CTFの摂動に対してよりロバストであることが示されています。CTFの大きさの逆フィルターは、複数に基づいて定式化されます。 -入力/出力逆定理（MINT）、および勾配降下基準に基づいて適応的に推定されます。 
[概要]提案された方法は、短いctfで実行され、周波数帯域ごとに基づいています。これは、相互関係法に基づいており、非負のモデルを使用します。このモデルを使用して、ワイヤレスWi-Fiを除外できます。 wi wi-fi</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-20">
        <br><font color="black">2018-12-20</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: An Empirical Study of Visual Features for DNN based Audio-Visual Speech
  Enhancement in Multi-talker Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.IV/paper_0.html">
      <font color="black">An Empirical Study of Visual Features for DNN based Audio-Visual Speech
  Enhancement in Multi-talker Environments</font>
    </a>
  </h2>
  <font color="black">私たちの調査によると、埋め込みベースの機能の全体的なパフォーマンスは向上していますが、計算量の多い前処理により、低リソースシステムでの使用が困難になっています。ただし、適切なオーディオ入力機能とネットワークアーキテクチャについては、さまざまな調査が行われています。私たちの知る限り、この特定のタスクに最適な視覚的特徴を調査した研究は公開されていません。この作業では、DNNベースのAVSEで最も一般的に使用される視覚的特徴である前処理要件の実証的研究を行います。これらの機能のそれぞれについて、パフォーマンスへの影響を調査します。 
[概要]ディープニューラルネットワーク（dnn）ベースのavseメソッドの大部分では、オーディオデータとビジュアルデータは最初に異なるサブネットワークを使用して別々に処理されます。学習された機能は、両方のモダリティからの情報を利用するために融合されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Cognitive Biomarker Prioritization in Alzheimer's Disease using Brain
  Morphometric Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.IV/paper_1.html">
      <font color="black">Cognitive Biomarker Prioritization in Alzheimer's Disease using Brain
  Morphometric Data</font>
    </a>
  </h2>
  <font color="black">方法：新しく開発されたランク付け学習法PLTRを採用して、パラダイムを実装します。この方法は、最も効果的な認知評価を優先順位リストの上にプッシュする潜在スコアリング関数を学習します。相互検証とレベルで実験を行います。 -検証設定を出力します。 
[概要]パーソナライズされた認知評価の優先順位付けを可能にする機械学習ツールを開発します。この方法は、最も効果的な認知評価を優先順位付けリストに追加する潜在的なスコアリング関数を学習します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-18">
        <br><font color="black">2020-02-18</font>
      </time>
    </span>
</section>
<!-- paper0: Deep learning for photoacoustic imaging: a survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.IV/paper_2.html">
      <font color="black">Deep learning for photoacoustic imaging: a survey</font>
    </a>
  </h2>
  <font color="black">ディープニューラルネットワークは、医用画像技術、医療データ分析、医療診断、その他の医療問題において大きな可能性を秘めており、前臨床段階と臨床段階の両方で推進されています。その後、学界や業界で広く使用されました。画像分析から自然言語処理まで、その魔法を完全に発揮し、今では最先端の機械学習モデルになっています。 
[概要]深い人工ニューラルネットワークは、最先端の機械学習モデルになりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: PAMS: Quantized Super-Resolution via Parameterized Max Scale -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.IV/paper_3.html">
      <font color="black">PAMS: Quantized Super-Resolution via Parameterized Max Scale</font>
    </a>
  </h2>
  <font color="black">以前の取り組みは主に固定小数点演算に頼っていましたが、重みとアクティブ化の両方を固定コーディング長で量子化すると、特に低ビットでパフォーマンスが大幅に低下する可能性があります。広範な実験により、提案されたPAMSスキームが既存のSRモデルを十分に圧縮および加速できることが実証されています。 EDSRおよびRDNとして..これら2つの問題に対処するために、PArameterized Max Scale（PAMS）と呼ばれる新しい量子化スキームを提案します。これは、トレーニング可能な切り捨てパラメータを適用して、量子化範囲の上限を適応的に探索します。 
[概要]これは、量子化が多すぎることと新しいセーフガードが原因です。これらには、set5ベンチマークでpsnrを改善する `pams --edsr &#39;が含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Comprehensive evaluation of no-reference image quality assessment
  algorithms on KADID-10k database -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.IV/paper_4.html">
      <font color="black">Comprehensive evaluation of no-reference image quality assessment
  algorithms on KADID-10k database</font>
    </a>
  </h2>
  <font color="black">この研究では、利用可能な最大のベンチマークデータベースの1つである最近公開されたKADID-10kデータベースを使用して、元のソースコードがオンラインで利用できる参照なしの画質評価アルゴリズムに関する包括的な評価を行うことを目標としています。20％参照画像に関して）。したがって、これら2つのセット間でセマンティックコンテンツの重複はありませんでした。 
[概要]客観的な画質評価アルゴリズムの評価は、公開されているベンチマークデータベースで実施された実験に基づいています。テストシステムを使用して、メインのテストテストシステムは100以上のランダムトレインで測定されます-テスト分割</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-19">
        <br><font color="black">2020-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: OverNet: Lightweight Multi-Scale Super-Resolution with Overscaling
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.IV/paper_5.html">
      <font color="black">OverNet: Lightweight Multi-Scale Super-Resolution with Overscaling
  Network</font>
    </a>
  </h2>
  <font color="black">次に、特徴抽出器のパフォーマンスを最大化するために、オーバースケールされた特徴マップから正確な高解像度画像を生成し、既存のアーキテクチャを改善するために独立して使用できる再構成モジュールを提案します。まず、軽量の再帰を導入します。スキップ接続と高密度接続の新しい再帰的構造を通じて情報の効率的な再利用を強制する特徴抽出器。超解像度（SR）は、深い畳み込みニューラルネットワーク（CNN）の開発により大きな成功を収めました。 
[ABSTRACT] cnnベースのsrメソッドは、実際の計算の複雑さという課題に直面しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Painting Outside as Inside: Edge Guided Image Outpainting via
  Bidirectional Rearrangement with Progressive Step Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.IV/paper_6.html">
      <font color="black">Painting Outside as Inside: Edge Guided Image Outpainting via
  Bidirectional Rearrangement with Progressive Step Learning</font>
    </a>
  </h2>
  <font color="black">より多くの方向情報を反映することにより、画像修復タスクの恩恵を受けるように画像を再配置します。双方向境界領域再配置により、画像修復タスクと同様の双方向情報を使用して欠落領域を生成できるため、従来よりも高品質が生成されます。一方向情報を使用する方法..アウトペインティング問題の難しさを軽減するために、双方向境界領域再配置を使用する新しい画像アウトペインティング方法を提案します。 
[概要]双方向境界領域の再配置により、画像修復タスクと同様の双方向情報を使用して、欠落領域を生成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: AMPA-Net: Optimization-Inspired Attention Neural Network for Deep
  Compressed Sensing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.IV/paper_7.html">
      <font color="black">AMPA-Net: Optimization-Inspired Attention Neural Network for Deep
  Compressed Sensing</font>
    </a>
  </h2>
  <font color="black">AMP-Netは、近似メッセージパッシング（AMP）アルゴリズムとニューラルネットワークの融合を実現します。そのすべてのパラメーターは自動的に学習されます。最後に、4つの標準CS再構成ベンチマークデータに対するAMP-NetとAMPA-Netの有効性を示します。セット。 
[ABSTRACT] amp-netとampa-netは、4つの標準的なcs再構成ベンチマークデータセットにあります。ネットワークは、amp-ampの頭脳の発案-新しいシステムと呼ばれます。これは初めてのamp-amp-です。限られたシステムを使用することができました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: MPRNet: Multi-Path Residual Network for Lightweight Image Super
  Resolution -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.IV/paper_8.html">
      <font color="black">MPRNet: Multi-Path Residual Network for Lightweight Image Super
  Resolution</font>
    </a>
  </h2>
  <font color="black">この問題を克服するために、新しい軽量超解像ネットワークが提案されます。これは、軽量SRでのSOTAパフォーマンスを改善し、計算コストの高いネットワークとほぼ同じように機能します。軽量超解像ネットワークは、実際のアプリケーションにとって非常に重要です。提案されたアーキテクチャもモデルの表現能力を最大化するための新しいアテンションメカニズムである2つ折りアテンションモジュールが含まれています。 
[概要]メモリとコストを犠牲にすることで、優れた成果を上げた多くのsrディープラーニングアプローチが導入されました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Fine Perceptive GANs for Brain MR Image Super-Resolution in Wavelet
  Domain -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.IV/paper_9.html">
      <font color="black">Fine Perceptive GANs for Brain MR Image Super-Resolution in Wavelet
  Domain</font>
    </a>
  </h2>
  <font color="black">さらに、逆離散ウェーブレット変換（IDWT）がモデルに統合され、画像全体の再構成が考慮されます。具体的には、FP-GANは、最初にMR画像をウェーブレットドメインの低周波グローバル近似と高周波解剖学的テクスチャに分割します。 ..この論文では、低解像度の対応物からHR MR画像を生成するために、微細な知覚生成敵対ネットワーク（FP-GAN）が提案されています。 
[ABSTRACT] fp-gansは、競合する方法よりも離散的かつ定性的に優れています。たとえば、特徴マップの代わりにサブバンド画像に焦点を合わせて、fpgansの解剖学的再構成能力をさらに強化できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Regularized Compression of MRI Data: Modular Optimization of Joint
  Reconstruction and Coding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.IV/paper_10.html">
      <font color="black">Regularized Compression of MRI Data: Modular Optimization of Joint
  Reconstruction and Coding</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、モジュラー最適化構造を持ち、乗数の交互方向法（ADMM）技術と、反復的に適用されるブラックボックスモジュールとしての最先端の画像圧縮技術（BPG）を使用して実装されます。磁気共鳴イメージング（ MRI）処理チェーンは、医療診断用の画像を再構成するための生データを提供する重要な取得段階から始まります。これにより、選択した損失のある圧縮標準と互換性のある医療データ圧縮アプローチが確立されます。 
[要約]研究によると、非可逆圧縮は再構成の品質を向上させることさえできます。方法は可逆圧縮に基づいています。方法は再構成の品質を向上させるために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: LIFI: Towards Linguistically Informed Frame Interpolation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.IV/paper_11.html">
      <font color="black">LIFI: Towards Linguistically Informed Frame Interpolation</font>
    </a>
  </h2>
  <font color="black">この動機付けにより、音声ビデオ補間の問題を特に対象とした、言語情報に基づいた新しいメトリックのセットを提供します。いくつかの深層学習ビデオ生成アルゴリズムを使用して欠落フレームを生成することにより、この問題の解決を試みます。オンラインコミュニケーションの主要な形態。 
[概要]音声理解のコンピュータービジョンビデオ生成モデルをテストするためのいくつかのデータセットもリリースします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-30">
        <br><font color="black">2020-10-30</font>
      </time>
    </span>
</section>
<!-- paper0: Unified Quality Assessment of In-the-Wild Videos with Mixed Datasets
  Training -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.IV/paper_12.html">
      <font color="black">Unified Quality Assessment of In-the-Wild Videos with Mixed Datasets
  Training</font>
    </a>
  </h2>
  <font color="black">品質評価モデルのパフォーマンスを向上させるために、人間の知覚、具体的には人間の視覚系のコンテンツ依存性と時間的記憶効果から直感を借ります。クロスデータセット評価の課題に直面するために、トレーニングのための混合データセットトレーニング戦略を検討します。複数のデータセットを持つ単一のVQAモデル..提案された統合フレームワークには、相対品質、知覚品質、および主観的品質を共同で予測するために、相対品質評価、非線形マッピング、およびデータセット固有の知覚スケール調整の3つの段階が明示的に含まれます。 
[ABSTRACT]テストは、野生のvqaについて公開されている4つのデータセットで実施されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Poisoning: Towards Robust Image Data Sharing against Visual
  Disclosure -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.IV/paper_13.html">
      <font color="black">Deep Poisoning: Towards Robust Image Data Sharing against Visual
  Disclosure</font>
    </a>
  </h2>
  <font color="black">画像分類に関する実験結果は、提案された方法の有効性を証明します。DPMは、画像の再構成を防ぐために畳み込み画像の特徴を意図的に汚染し、変更された画像データが特定の視覚タスクの非汚染データと機能的に同等であることを保証します。 、各エンティティはプライベートディープポイズニングモジュール（DPM）を学習し、特定のビジョンタスクを実行するように設計された事前トレーニング済みのディープネットワークに挿入します。 
[概要]新しいビジョンタスクにより、さまざまなエンティティがタスク（特定および再構成）を共有して、画像データ共有のための画像表現を証明できます。dpmは、畳み込み画像の特徴を意図的にポイズニングして、ビジョンタスクを防止します。これは、変更された画像データが機能的に同等であることを意味します。特定のビジョンタスクの無毒データ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-14">
        <br><font color="black">2019-12-14</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Effective Fusion Factor in FPN for Tiny Object Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_0.html">
      <font color="black">Effective Fusion Factor in FPN for Tiny Object Detection</font>
    </a>
  </h2>
  <font color="black">TinyPersonやTinyCityPersonsなどの小さなオブジェクト検出データセットに対して包括的な実験が行われます。コードとモデルがリリースされます。一連の実験と分析の後、特定のデータセットの融合係数の有効値を推定する方法を検討します。統計的方法。 
[ABSTRACT] fpnは、小さなオブジェクトの検出に適応するための新しい概念です。これは、各レイヤーに分散されたオブジェクトの数に基づいています。適切な融合係数でfpnを構成すると、ネットワークは大幅なパフォーマンスの向上を実現できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-04">
        <br><font color="black">2020-11-04</font>
      </time>
    </span>
</section>
<!-- paper0: Two-Stream Appearance Transfer Network for Person Image Generation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_1.html">
      <font color="black">Two-Stream Appearance Transfer Network for Person Image Generation</font>
    </a>
  </h2>
  <font color="black">前者は、2ストリームの特徴マップ間の密な対応を見つけて、外観情報をソースストリームからターゲットストリームに転送します。ただし、画像の生成と変換に広く使用されている生成的敵対的ネットワーク（GAN）は、空間的にローカルであり、大きな画像変形を処理できない並進等変演算子、すなわち、畳み込み、プーリング、およびアンプーリング。ポーズ誘導人物画像生成とは、入力人物画像および所望のポーズを条件とする写真現実的な人物画像を生成することを意味する。 
[概要]このホワイトペーパーでは、この課題に対処できる新しい2つのストリーム外観転送ネットワーク（2s-atn）を紹介します。パフォーマンスは優れていますが、広く使用されている2つのベンチマークを使用していません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: SMPLpix: Neural Avatars from 3D Human Models -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_2.html">
      <font color="black">SMPLpix: Neural Avatars from 3D Human Models</font>
    </a>
  </h2>
  <font color="black">この作業では、古典的なジオメトリベースのレンダリングとピクセル空間で動作する最新の生成ネットワークとの間のギャップを埋めることを提案します。同時に、SMPLやその後継のような変形可能な人体モデルは、ポーズと形状を完全に制御できますが、レンダリング用の従来のコンピューターグラフィックスパイプラインで..このようなレンダリングパイプラインには、（a）元の3Dジオメトリのアーティファクトやリアリズムの欠如を修正する可能性がなく、（b）最近まで、ディープに完全に組み込まれていなかった明示的なメッシュラスター化が必要です。学習フレームワーク。 
[概要]スパースな3Dメッシュのセットをフォトリアリスティックな画像に直接変換するネットワークをトレーニングし、従来のラスリアリスティックなレンダリングの必要性を軽減します。被写体のアイデンティティを維持しながら、カメラと人間のポーズを変更できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-16">
        <br><font color="black">2020-08-16</font>
      </time>
    </span>
</section>
<!-- paper0: Occlusion-Robust Online Multi-Object Visual Tracking using a GM-PHD
  Filter with CNN-Based Re-Identification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_3.html">
      <font color="black">Occlusion-Robust Online Multi-Object Visual Tracking using a GM-PHD
  Filter with CNN-Based Re-Identification</font>
    </a>
  </h2>
  <font color="black">大規模な個人再識別データセットで識別ネットワーク（IdNet）をトレーニングすることにより、深いCNN外観表現を学習します。GM-PHDフィルターは、の状態とカーディナリティを推定しながら、オブジェクトと観測値の数と線形の複雑さを持ちます。シーン内の未知の時間変化するオブジェクトの数..統一されたフレームワークでオブジェクトの誕生、死、混乱を処理しますが、誤検出の影響を受けやすく、オブジェクトのIDは含まれません。 
[概要] gm-phdフィルターは、シーン内の未知の被写体と時間-被写体の状態とカーディナリティを推定しながら、オブジェクトと観測値の数に線形の複雑さを持っています。オブジェクトの境界ボックスから取得した視覚-空間-時間情報を使用します。推定を実行するために学習された外観表現-から-外観を介して予測するためのデータ関連付けを追跡します。また、データ関連付けステップの後に追加の委託トラック予測を採用して、ミスに対する遺伝的に変更されたフィルターの感受性を克服します-閉塞によって引き起こされる検出</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-10">
        <br><font color="black">2019-12-10</font>
      </time>
    </span>
</section>
<!-- paper0: Deep learning for photoacoustic imaging: a survey -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_4.html">
      <font color="black">Deep learning for photoacoustic imaging: a survey</font>
    </a>
  </h2>
  <font color="black">ディープニューラルネットワークは、医用画像技術、医療データ分析、医療診断、その他の医療問題において大きな可能性を秘めており、前臨床段階と臨床段階の両方で推進されています。機械学習は劇的に開発され、さまざまな分野で多くのアプリケーションが見られます。過去数年間の分野..このレビューの目的は3つあります：（i）いくつかの重要な基礎を備えた深層学習の導入、（ii）画像再構成から画像再構成までの光音響イメージングの生態学的チェーン全体に深層学習を適用する最近の研究のレビュー疾患診断、（iii）深層学習を光音響イメージングに適用することに関心のある研究者にいくつかのオープンソース資料およびその他のリソースを提供します。 
[概要]深い人工ニューラルネットワークは、最先端の機械学習モデルになりました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-10">
        <br><font color="black">2020-08-10</font>
      </time>
    </span>
</section>
<!-- paper0: PAMS: Quantized Super-Resolution via Parameterized Max Scale -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_5.html">
      <font color="black">PAMS: Quantized Super-Resolution via Parameterized Max Scale</font>
    </a>
  </h2>
  <font color="black">以前の取り組みは主に固定小数点演算に頼っていましたが、固定コーディング長で重みとアクティブ化の両方を量子化すると、特に低ビットでパフォーマンスが大幅に低下する可能性があります。広範な実験により、提案されたPAMSスキームが既存のSRモデルを十分に圧縮および加速できることが実証されています。 EDSRおよびRDNとして..ディープ畳み込みニューラルネットワーク（DCNN）は、超解像度（SR）のタスクで卓越したパフォーマンスを示しています。 
[概要]これは、量子化が多すぎることと新しいセーフガードが原因です。これらには、set5ベンチマークでpsnrを改善する `pams --edsr &#39;が含まれています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Specular- and Diffuse-reflection-based Face Spoofing Detection for
  Mobile Devices -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_6.html">
      <font color="black">Specular- and Diffuse-reflection-based Face Spoofing Detection for
  Mobile Devices</font>
    </a>
  </h2>
  <font color="black">このコードはhttps://github.com/Akinori-F-Ebihara/SpecDiff-spoofing-detectorで公開されています。$ SpecDiff $記述子でトレーニングされた分類子は、社内データベースとオンの両方で他のフラッシュベースのPADアルゴリズムよりも優れています。公開されているNUAA、Replay-Attack、およびSiWデータベース。生体認証システムに対する需要の高まりに照らして、顔のなりすまし攻撃を防ぐことは、顔認識システムを安全に展開するための重要な問題です。 
[概要]提案された$ specdiffアルゴリズムは、最小限のハードウェアと小さなデータベースのみを必要とし、携帯電話などのリソースに制約のあるデバイスに適しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-29">
        <br><font color="black">2019-07-29</font>
      </time>
    </span>
</section>
<!-- paper0: HyNet: Learning Local Descriptor with Hybrid Similarity Measure and
  Triplet Loss -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_7.html">
      <font color="black">HyNet: Learning Local Descriptor with Hybrid Similarity Measure and
  Triplet Loss</font>
    </a>
  </h2>
  <font color="black">HyNetは、パッチマッチング、検証、検索を含む標準ベンチマークで以前の方法を大幅に上回り、3D再構成タスクで完全なエンドツーエンドの方法を上回っています。HyNetは、トリプレットマージン損失のハイブリッド類似性測定を導入します。記述子ノルムを制約する正則化項、およびすべての中間特徴マップと出力記述子のL2正規化を実行する新しいネットワークアーキテクチャ。私たちの観察に基づいて、最先端の新しいローカル記述子であるHyNetを提案します。結果は一致します。 
[ABSTRACT]研究は、l2正規化がトレーニング中に背中の再伝播された記述子勾配にどのように影響するかを示しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-17">
        <br><font color="black">2020-06-17</font>
      </time>
    </span>
</section>
<!-- paper0: R-MNet: A Perceptual Adversarial Network for Image Inpainting -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_8.html">
      <font color="black">R-MNet: A Perceptual Adversarial Network for Image Inpainting</font>
    </a>
  </h2>
  <font color="black">さらに、敵対的トレーニングと組み合わせて有効なピクセルのみをターゲットにするために、特徴空間で計算された新しい損失関数を提案します。公開されているデータセットでメソッドを評価し、最先端のメソッドと比較します。顔の画像の修復は広く研究されている問題、そして近年、Generative Adversarial Networksの導入は、この分野の改善につながっています。 
[概要]顔認識ソフトウェアを使用して新しい画像を作成できます。私たちの方法が高解像度の修復タスクに一般化できることを示します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-11">
        <br><font color="black">2020-08-11</font>
      </time>
    </span>
</section>
<!-- paper0: Comprehensive evaluation of no-reference image quality assessment
  algorithms on KADID-10k database -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_9.html">
      <font color="black">Comprehensive evaluation of no-reference image quality assessment
  algorithms on KADID-10k database</font>
    </a>
  </h2>
  <font color="black">参照画像に対して20％の画像）。私たちの評価結果は、最先端の非参照画像品質評価方法の状況を明確に理解するのに役立つ可能性があります。さらに、データベースは分割されました。列車に（約
[ABSTRACT]客観的な画質評価アルゴリズムの評価は、公開されているベンチマークデータベースで実施された実験に基づいています。テストシステムを使用して、メインのテストテストシステムは100以上のランダムな列車で測定されます-テスト分割</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-19">
        <br><font color="black">2020-10-19</font>
      </time>
    </span>
</section>
<!-- paper0: OverNet: Lightweight Multi-Scale Super-Resolution with Overscaling
  Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_10.html">
      <font color="black">OverNet: Lightweight Multi-Scale Super-Resolution with Overscaling
  Network</font>
    </a>
  </h2>
  <font color="black">次に、特徴抽出器のパフォーマンスを最大化するために、オーバースケールされた特徴マップから正確な高解像度画像を生成し、既存のアーキテクチャを改善するために独立して使用できる再構成モジュールを提案します。まず、軽量の再帰を導入します。スキップ接続と密接続の新しい再帰的構造を通じて情報の効率的な再利用を強制する特徴抽出器。第3に、スケール間の一般化を実現するためのマルチスケール損失関数を導入します。 
[ABSTRACT] cnnベースのsrメソッドは、実際の計算の複雑さという課題に直面しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-05">
        <br><font color="black">2020-08-05</font>
      </time>
    </span>
</section>
<!-- paper0: Detecting Outliers with Foreign Patch Interpolation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_11.html">
      <font color="black">Detecting Outliers with Foreign Patch Interpolation</font>
    </a>
  </h2>
  <font color="black">具体的には、2つの独立したサンプルから同じパッチ領域が抽出され、両方のパッチ間の補間に置き換えられます。パッチとその補間係数をピクセル単位で予測できるように、ワイド残差エンコーダデコーダがトレーニングされます。ただし、これは難しいためです。考えられるさまざまな異常と、正常な解剖学的構造が自然に変化する可能性のある方法の数について説明します。 
[概要]ハイパーポリティ係数、パッチサイズ、パッチ位置は、均一な分布からランダムにサンプリングされます。ピクセル単位の出力により、同じモデルを使用したピクセルレベルとサブジェクトレベルの予測が可能になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Towards Visually Explaining Video Understanding Networks with
  Perturbation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_12.html">
      <font color="black">Towards Visually Explaining Video Understanding Networks with
  Perturbation</font>
    </a>
  </h2>
  <font color="black">この論文では、ビデオ理解ネットワークを視覚的に説明するための一般的な摂動ベースの方法を調査します。実験的な比較結果により、私たちの方法の有効性が検証されました。学習ネットワーク。 
[概要]使いやすい視覚的説明方法を提供することは、依然として未解決の課題です。結果の滑らかさを制限することによって方法を強化するための新しい損失関数を提案します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-01">
        <br><font color="black">2020-05-01</font>
      </time>
    </span>
</section>
<!-- paper0: Self-Supervised Learning for Large-Scale Unsupervised Image Clustering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_13.html">
      <font color="black">Self-Supervised Learning for Large-Scale Unsupervised Image Clustering</font>
    </a>
  </h2>
  <font color="black">この論文では、自己教師あり表現に基づく教師なし分類の簡単なスキームを提案します。教師なし評価を、教師あり学習の標準ベンチマークのセットに追加することをお勧めします。教師あり深層学習は、コンピュータビジョンにおける表現学習。 
[概要]複雑なデータの教師なし学習は困難です。最良のアプローチでさえ、教師ありのアプローチよりもはるかに弱いパフォーマンスを示します。しかし、教師なし学習は、完全に教師ありの設定では評価されていません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-24">
        <br><font color="black">2020-08-24</font>
      </time>
    </span>
</section>
<!-- paper0: Watch out! Motion is Blurring the Vision of Your Deep Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_14.html">
      <font color="black">Watch out! Motion is Blurring the Vision of Your Deep Neural Networks</font>
    </a>
  </h2>
  <font color="black">視覚的により自然でもっともらしい例を生成するために、顕著領域が移動オブジェクトとして機能し、予測されたカーネルが自然に視覚効果を達成するように正規化される、顕著性が正規化された敵対カーネル予測をさらに提案します。コードをhttpsにリリースします。 //github.com/tsingqguo/ABBA .. NeurIPS&#39;17の敵対的競争データセットの包括的な評価は、さまざまなカーネルサイズ、変換、および領域を考慮することにより、ABBAの有効性を示しています。 
[ABSTRACT]敵対的生成ネットワーク（abba）は、新しい敵対的攻撃方法です。視覚的に自然な動きを生成できます-ぼやけた敵対的例。これらの例には、自然な視覚効果を実現するために正規化されたカーネル予測が含まれます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-10">
        <br><font color="black">2020-02-10</font>
      </time>
    </span>
</section>
<!-- paper0: An improved helmet detection method for YOLOv3 on an unbalanced dataset -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_15.html">
      <font color="black">An improved helmet detection method for YOLOv3 on an unbalanced dataset</font>
    </a>
  </h2>
  <font color="black">効率的な前処理により、YOLOv3の信頼水準は、YOLOv3の認識速度を変更することなく、一般に0.01〜0.02向上します。また、処理された画像は、効果的な特徴融合により、画像のローカリゼーションにおいても優れたパフォーマンスを発揮します。生産における認識速度と精度の要件..YOLOv3ターゲット検出アルゴリズムは、その高速性と高精度のために業界で広く使用されていますが、不均衡なデータセットの精度低下など、いくつかの制限があります。YOLOv3ターゲット検出アルゴリズムは、データセットを前処理し、YOLOv3ターゲット検出アルゴリズムを改善するためのガウスファジーデータ拡張アプローチに基づいています。 
[概要] yolov3ターゲット検出アルゴリズムはガウスシステムに基づいています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: A Flexible Framework for Designing Trainable Priors with Adaptive
  Smoothing and Game Encoding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_16.html">
      <font color="black">A Flexible Framework for Designing Trainable Priors with Adaptive
  Smoothing and Game Encoding</font>
    </a>
  </h2>
  <font color="black">フォワードパスが滑らかでない凸最適化問題を解くと解釈でき、アーキテクチャが最適化アルゴリズムから派生しているニューラルネットワークレイヤーを設計およびトレーニングするための一般的なフレームワークを紹介します。 ..グラフのノードで表され、正規化関数を介して相互作用するローカルエージェントによって解決される凸ゲームに焦点を当てます。 
[要約]実験は、多種多様なタスクでの有効性を実証しました。これらには、グラフのノードによって表されるローカルエージェントによって解決され、正則化関数を介して相互作用する問題の発見が含まれます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-26">
        <br><font color="black">2020-06-26</font>
      </time>
    </span>
</section>
<!-- paper0: MFIF-GAN: A New Generative Adversarial Network for Multi-Focus Image
  Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_17.html">
      <font color="black">MFIF-GAN: A New Generative Adversarial Network for Multi-Focus Image
  Fusion</font>
    </a>
  </h2>
  <font color="black">Multi-Focus Image Fusion（MFIF）は、視覚的ニーズを満たす全焦点画像を取得するための有望な画像強調技術であり、他のコンピュータービジョンタスクの前提条件です。トレーニング条件の事前知識を組み合わせることにより、このネットワークはトレーニングされます。 {\ alpha}マットモデルに基づく合成データセットで..MFIFの研究動向の1つは、焦点/焦点ぼけ境界（FDB）周辺の焦点ぼけ拡散効果（DSE）を回避することです。 
[ABSTRACT] mfifは、フォーカスの周りのデフォーカス拡散効果（dse）を回避するためのものです。この方法で生成されたdse.focusマップは、ピクセルレベルで正確です。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-21">
        <br><font color="black">2020-09-21</font>
      </time>
    </span>
</section>
<!-- paper0: And the Bit Goes Down: Revisiting the Quantization of Neural Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_18.html">
      <font color="black">And the Bit Goes Down: Revisiting the Quantization of Neural Networks</font>
    </a>
  </h2>
  <font color="black">ImageNetオブジェクト分類でトップ1の精度76.1％を維持しながら、高性能のResNet-50モデルを5MBのメモリサイズ（20倍の圧縮率）に量子化し、マスクR-CNNを26倍の係数で圧縮することにより、アプローチを検証します。 ..このペーパーでは、畳み込みネットワークアーキテクチャのメモリフットプリントを削減する問題に対処します。この方法では、量子化時にラベルのないデータのセットのみが必要であり、バイト整列コードブックを使用して圧縮を保存することにより、CPUで効率的な推論が可能になります。重み。 
[ABSTRACT] wexxxxxxxは、メモリ損失を改善するための概念を導入します。wexxxxxxのメソッドは、ラベルのないデータのセットのみを必要とします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-07-12">
        <br><font color="black">2019-07-12</font>
      </time>
    </span>
</section>
<!-- paper0: SSP: Single Shot Future Trajectory Prediction -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_19.html">
      <font color="black">SSP: Single Shot Future Trajectory Prediction</font>
    </a>
  </h2>
  <font color="black">第三に、シーンのセマンティックコンテキストがモデル化され、将来の動きに影響を与える可能性のある環境制約が考慮されます。この目的のために、ETH、UCY、およびSDDデータセットを使用して、提案されたアプローチの堅牢性を検証し、その実用性を強調します。現在の最先端の方法と比較した機能性..このために、このペーパーでは3つの側面について特に取り上げます。 
[概要]提案されたアプローチは、エージェント間の自律的な相互作用を予測します。彼らは、これが現在のシステムの将来に役立つ可能性があると述べていますが、将来への有用な解決策になる可能性があると述べています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-13">
        <br><font color="black">2020-04-13</font>
      </time>
    </span>
</section>
<!-- paper0: Painting Outside as Inside: Edge Guided Image Outpainting via
  Bidirectional Rearrangement with Progressive Step Learning -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_20.html">
      <font color="black">Painting Outside as Inside: Edge Guided Image Outpainting via
  Bidirectional Rearrangement with Progressive Step Learning</font>
    </a>
  </h2>
  <font color="black">より多くの方向情報を反映することにより、画像修復タスクの恩恵を受けるように画像を再配置します。双方向境界領域再配置により、画像修復タスクと同様の双方向情報を使用して欠落領域を生成できるため、従来よりも高品質が生成されます。一方向情報を使用する方法..実験結果は、私たちの方法が他の方法よりも優れており、360 {\ deg}パノラマ特性を持つ新しい画像を生成することを示しています。 
[概要]双方向境界領域の再配置により、画像修復タスクと同様の双方向情報を使用して、欠落領域を生成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-05">
        <br><font color="black">2020-10-05</font>
      </time>
    </span>
</section>
<!-- paper0: Self-paced and self-consistent co-training for semi-supervised image
  segmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_21.html">
      <font color="black">Self-paced and self-consistent co-training for semi-supervised image
  segmentation</font>
    </a>
  </h2>
  <font color="black">注釈付きデータが不足している場合の画像セグメンテーションの効果的なアプローチとして、最近、ディープコトレーニングが提案されました。結果は、標準のコトレーニングベースラインおよび最近提案された最先端のアプローチと比較して、パフォーマンスの点で明らかな利点を示しています。半教師ありセグメンテーション。ラベルのない画像から情報を抽出するために、最初に共同トレーニング用の自己ペース学習戦略を設計します。これにより、共同トレーニングされたニューラルネットワークは、最初にセグメント化が容易な領域に焦点を合わせ、次に難しい領域を徐々に検討します。これは、一般化されたJensenShannon Divergence（JSD）の形でのエンドツーエンドの微分可能な損失。 
[概要]新しい論文では、半教師ありセグメンテーションの既存のアプローチを自己一貫性のある学習方法で改善します。さまざまなネットワークからの予測が一貫性と信頼性の両方になるように、効果的な方法を強化します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-31">
        <br><font color="black">2020-10-31</font>
      </time>
    </span>
</section>
<!-- paper0: AMPA-Net: Optimization-Inspired Attention Neural Network for Deep
  Compressed Sensing -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_22.html">
      <font color="black">AMPA-Net: Optimization-Inspired Attention Neural Network for Deep
  Compressed Sensing</font>
    </a>
  </h2>
  <font color="black">圧縮センシング（CS）は、限られた測定からほぼ完全な画像を再構築するため、画像処理における困難な問題です。AMP-Netは、近似メッセージパッシング（AMP）アルゴリズムとニューラルネットワークの融合を実現します。最後に、 4つの標準CS再構成ベンチマークデータセットに対するAMP-NetおよびAMPA-Netの有効性。 
[ABSTRACT] amp-netとampa-netは、4つの標準的なcs再構成ベンチマークデータセットにあります。ネットワークは、amp-ampの頭脳の発案-新しいシステムと呼ばれます。これは初めてのamp-amp-です。限られたシステムを使用することができました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-14">
        <br><font color="black">2020-10-14</font>
      </time>
    </span>
</section>
<!-- paper0: Attentional Feature Fusion -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_23.html">
      <font color="black">Attentional Feature Fusion</font>
    </a>
  </h2>
  <font color="black">コードとトレーニング済みモデルはオンラインで入手できます。また、機能マップの初期統合がボトルネックになる可能性があり、この問題は、反復注意機能融合と呼ばれる別のレベルの注意を追加することで軽減できることも示しています。機能異なるレイヤーまたはブランチからの機能の組み合わせであるフュージョンは、現代のネットワークアーキテクチャの遍在する部分です。 
[ABSTRACT]機能の融合を使用して、マルチスケールチャネルアテンションモジュールを作成できます。これは、異なるスケールで与えられた機能を融合するときに発生する問題を説明します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-29">
        <br><font color="black">2020-09-29</font>
      </time>
    </span>
</section>
<!-- paper0: Resolution Switchable Networks for Runtime Efficient Image Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_24.html">
      <font color="black">Resolution Switchable Networks for Runtime Efficient Image Recognition</font>
    </a>
  </h2>
  <font color="black">提案された方法でトレーニングされたネットワークは、Resolution Switchable Networks（RS-Nets）と呼ばれます。多重解像度アンサンブル蒸留がさらに設計され、教師は解像度に対する加重アンサンブルとしてその場で学習されます。ImageNetデータセットでの広範な実験が提供され、さらに量子化の問題も考慮します。 
[概要]基本的なトレーニングフレームワークは、解像度が異なる画像を処理するための設計のヒントを共有しますが、個別のバッチ正規化レイヤーを保持します。マルチ解像度のアンサンブル蒸留がさらに設計され、教師は解像度に対する加重アンサンブルとして学習されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-19">
        <br><font color="black">2020-07-19</font>
      </time>
    </span>
</section>
<!-- paper0: Illumination Normalization by Partially Impossible Encoder-Decoder Cost
  Function -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_25.html">
      <font color="black">Illumination Normalization by Partially Impossible Encoder-Decoder Cost
  Function</font>
    </a>
  </h2>
  <font color="black">顕著な特徴の再構築に焦点を当てるための環境的特徴および照明の変化（例えば、私たちの方法は、部分的に不可能な再構築ターゲットを定式化する異なる照明および環境条件下での同一のシーンの可用性を利用します：入力画像は十分な情報を伝えません前述の後処理の重要性は、自動車アプリケーションで強調されています。
[ABSTRACT]私たちの方法は、部分的に不可能な再構成ターゲットを作成するために、異なる照明および環境条件下で同一のシーンの可用性を活用します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-06">
        <br><font color="black">2020-11-06</font>
      </time>
    </span>
</section>
<!-- paper0: Geometric Structure Aided Visual Inertial Localization -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_26.html">
      <font color="black">Geometric Structure Aided Visual Inertial Localization</font>
    </a>
  </h2>
  <font color="black">この目的のために、マップコンポーネントをローカルフィーチャに関連付けるための効率的なデータ関連付けモジュールを開発します。これは、一時的なランドマークを生成するのに2ドルしかかかりません。EuRoCMAVデータセットの実験結果は、最先端技術と比較して競争力のあるパフォーマンスを示しています。 ..バッチ最適化では、視覚的要因を使用する代わりに、インスタントローカリゼーションの結果からポーズを推定してポーズを制約するモジュールを開発します。 
[ABSTRACT]既存のアプローチは、slam / sfmの視覚的構造、または密なマッピングの幾何学的状態に基づいています。削減するために、システムは100％のリコールで1.7cmの平均位置誤差を達成します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Fine Perceptive GANs for Brain MR Image Super-Resolution in Wavelet
  Domain -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_27.html">
      <font color="black">Fine Perceptive GANs for Brain MR Image Super-Resolution in Wavelet
  Domain</font>
    </a>
  </h2>
  <font color="black">さらに、逆離散ウェーブレット変換（IDWT）は、画像全体の再構成を考慮に入れるためのモデルに統合されます。次に、各サブバンド生成敵対的ネットワーク（サブバンドGAN）は、各単一サブの超解像度手順を征服します。バンド画像..磁気共鳴画像は、コンピュータ支援診断と脳探査において重要な役割を果たします。 
[ABSTRACT] fp-gansは、競合する方法よりも離散的かつ定性的に優れています。たとえば、特徴マップの代わりにサブバンド画像に焦点を合わせて、fpgansの解剖学的再構成能力をさらに強化できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Pruning neural networks without any data by iteratively conserving
  synaptic flow -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_28.html">
      <font color="black">Pruning neural networks without any data by iteratively conserving
  synaptic flow</font>
    </a>
  </h2>
  <font color="black">最初に、初期化時の既存の勾配ベースのプルーニングアルゴリズムがレイヤーの崩壊、ネットワークをトレーニング不能にするレイヤー全体の時期尚早なプルーニングに悩まされる理由を説明する保存則を数学的に定式化し、実験的に検証します。したがって、データに依存しないプルーニングアルゴリズムは既存のプルーニングアルゴリズムに挑戦します。初期化時に、どのシナプスが重要であるかを定量化するためにデータを使用する必要があるというパラダイム。この理論は、レイヤーの崩壊を完全に回避する方法も解明し、新しいプルーニングアルゴリズムである反復シナプスフロープルーニング（SynFlow）を動機付けます。 
[概要]以前の作品では、当選した宝くじの存在が確認されています。これは、トレーニングと剪定のサイクルの激しいプロセスを通じて説明できます。これは、レイヤーの崩壊を完全に回避する方法を説明しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-09">
        <br><font color="black">2020-06-09</font>
      </time>
    </span>
</section>
<!-- paper0: PLACE: Proximity Learning of Articulation and Contact in 3D Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_29.html">
      <font color="black">PLACE: Proximity Learning of Articulation and Contact in 3D Environments</font>
    </a>
  </h2>
  <font color="black">そのために、人体とその周囲の3Dシーンとの近接性を明示的にモデル化するPLACE（3D環境におけるアーティキュレーションと接触の近接学習）という名前の新しいインタラクション生成方法を提案します。具体的には、一連の基礎が与えられます。シーンメッシュ上のポイントでは、条件付き変分オートエンコーダーを利用して、基点から人体表面までの最小距離を合成します。コードとモデルは、https：//sanweiliti.github.io/PLACE/PLACEで調査できます。 .html。 
[ABSTRACT]人間モデルとパラメトリック人間モデルを使用してシーンを表現します。これらには、人間が身体を介して世界と相互作用する3D世界が含まれます-シーンの接触。場所という名前の方法により、現実的かつ現実的になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-12">
        <br><font color="black">2020-08-12</font>
      </time>
    </span>
</section>
<!-- paper0: Regularized Compression of MRI Data: Modular Optimization of Joint
  Reconstruction and Coding -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_30.html">
      <font color="black">Regularized Compression of MRI Data: Modular Optimization of Joint
  Reconstruction and Coding</font>
    </a>
  </h2>
  <font color="black">私たちの方法は、モジュラー最適化構造を持ち、乗数の交互方向法（ADMM）技術と、反復的に適用されるブラックボックスモジュールとしての最先端の画像圧縮技術（BPG）を使用して実装されます。磁気共鳴イメージング（ MRI）処理チェーンは、医療診断用の画像を再構成するための生データを提供する重要な取得段階から始まります。これにより、選択した損失のある圧縮標準と互換性のある医療データ圧縮アプローチが確立されます。 
[要約]研究によると、非可逆圧縮は再構成の品質を向上させることさえできます。方法は可逆圧縮に基づいています。方法は再構成の品質を向上させるために使用できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-08">
        <br><font color="black">2020-10-08</font>
      </time>
    </span>
</section>
<!-- paper0: Revisiting Batch Normalization for Improving Corruption Robustness -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_31.html">
      <font color="black">Revisiting Batch Normalization for Improving Corruption Robustness</font>
    </a>
  </h2>
  <font color="black">さらに、この手法により、最先端の堅牢なモデルを58.1％から63.3％にさらに改善できることがわかります。再トレーニングせずに、いくつか（たとえば、32）の表現サンプルのBN統計を単純に推定して適応させることがわかります。モデルは、幅広いモデルアーキテクチャを備えたいくつかのベンチマークデータセットで破損の堅牢性を大幅に改善します。この作業では、破損の堅牢性をドメインシフトとして解釈し、モデルの堅牢性を向上させるためにバッチ正規化（BN）統計を修正することを提案します。 。 
[概要]破損の堅牢性をドメインシフトとして解釈し、モデルの堅牢性を大幅に改善するためにバッチ正規化（bn）統計を修正することを提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-07">
        <br><font color="black">2020-10-07</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Learning based Monocular Depth Prediction: Datasets, Methods and
  Applications -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_32.html">
      <font color="black">Deep Learning based Monocular Depth Prediction: Datasets, Methods and
  Applications</font>
    </a>
  </h2>
  <font color="black">この調査では、最初に深度推定用のデータセットを紹介し、次に、教師あり学習ベースの方法、教師なし学習ベースの方法、およびスパースサンプルガイダンスベースの方法の3つの観点から方法を包括的に紹介します。進歩の恩恵を受ける下流のアプリケーションも示されています。最近、深層学習技術の急速な発展により、単眼深度推定は大きな進歩を遂げています。 
[ABSTRACT]深層学習技術の急速な発展により、単眼深度推定は大きな進歩を遂げました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Synthetic-to-Real Domain Adaptation for Lane Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_33.html">
      <font color="black">Synthetic-to-Real Domain Adaptation for Lane Detection</font>
    </a>
  </h2>
  <font color="black">たとえば、ラマとtuSimpleレーンデータセットで提案されたオートエンコーダアプローチを使用すると、ラベル付けされたデータのわずか10％で、完全に監視された精度をほぼ回復できます。さらに、画像変換や自己などの既存のドメイン適応アプローチを検討します。 -監視し、車線検出タスクに合わせて調整します。自律運転の重要なイネーブラーである正確な車線検出は、現在、大規模で多様なラベル付きトレーニングデータセットの取得に依存しています。 
[概要]これにより、非現実的な合成ドメインで学習したモデルを実際の画像に適応させるという課題が生じます。コストのかかるターゲットドメインのラベル付けの労力を節約できる可能性を示しました。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-08">
        <br><font color="black">2020-07-08</font>
      </time>
    </span>
</section>
<!-- paper0: LIFI: Towards Linguistically Informed Frame Interpolation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_34.html">
      <font color="black">LIFI: Towards Linguistically Informed Frame Interpolation</font>
    </a>
  </h2>
  <font color="black">この動機で、特に音声ビデオ補間の問題を対象とした言語情報に基づく新しいメトリックのセットを提供します。このようなコンテンツは今日、オンラインコミュニケーションの主要な形式を形成しています。また、コンピュータビジョンビデオ生成モデルをテストするためのいくつかのデータセットをリリースします。彼らのスピーチの理解。 
[概要]音声理解のコンピュータービジョンビデオ生成モデルをテストするためのいくつかのデータセットもリリースします</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-30">
        <br><font color="black">2020-10-30</font>
      </time>
    </span>
</section>
<!-- paper0: Action-Based Representation Learning for Autonomous Driving -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_35.html">
      <font color="black">Action-Based Representation Learning for Autonomous Driving</font>
    </a>
  </h2>
  <font color="black">さらに、この戦略が、逆ダイナミクスモデルの学習に基づく以前の方法や、人間による重い監視（ImageNet）に基づく他の方法よりも優れていることを示します。あるいは、この種のアクションベースの運転データを表現の学習に使用することを提案します。私たちの実験は、このアプローチで事前にトレーニングされたアビリティベースの運転モデルが、比較的少量の弱く注釈が付けられた画像を活用し、より解釈しやすく、純粋なエンドツーエンドの運転モデルよりも優れていることを示しています。 
[ABSTRACT]センサーを直接運転にマッピングするモデルは、疑似相関を処理するのが困難です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-08-21">
        <br><font color="black">2020-08-21</font>
      </time>
    </span>
</section>
<!-- paper0: Localising In Complex Scenes Using Balanced Adversarial Adaptation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_36.html">
      <font color="black">Localising In Complex Scenes Using Balanced Adversarial Adaptation</font>
    </a>
  </h2>
  <font color="black">屋内生息地シミュレーション環境（Matterport3Dおよびレプリカ）用に最適化された表現を実際の屋内環境（アクティブビジョンデータセット）に適合させることによって方法を評価し、完全に監視されたアプローチと比較して有利であることを示します。私たちの方法は対称的な敵対的アプローチを使用します。これにより、表現抽出機能は、特徴が抽出されたドメインを隠蔽すると同時に、ローカリゼーションに役立つソースドメインとターゲットドメイン間の堅牢な属性を保持します。ドメインの適応と生成モデリングは、データ収集とラベル付けのコストのかかる性質を、シミュレーション環境での豊富な正確なラベル付きデータ。 
[ABSTRACT]私たちの方法は、さまざまな環境のモデルを現実世界の屋内環境に適応させています。私たちの方法は、表現抽出機能を使用して、仮想表現と実際の表現の両方を共有表現空間に投影します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: RELATE: Physically Plausible Multi-Object Scene Synthesis Using
  Structured Latent Spaces -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_37.html">
      <font color="black">RELATE: Physically Plausible Multi-Object Scene Synthesis Using
  Structured Latent Spaces</font>
    </a>
  </h2>
  <font color="black">RELATEは、物理的にリアルなシーン編集にも適していること、および合成（CLEVR、ShapeStacks）と実世界のデータ（車）の両方でオブジェクト中心のシーン生成において従来技術を大幅に上回っていることを発見しました。ソースコード、データセット、その他の結果http://geometry.cs.ucl.ac.uk/projects/2020/relate/で入手できます。さらに、オブジェクトの位置とアイデンティティを解きほぐす方法を学ぶには、オブジェクトの相関関係のモデリングが必要であることを示します。 
[ABSTRACT] relatedは、ラベルのない生データに基づくモデルによってトレーニングされます。モデルを組み合わせてリアルなシーンとビデオを作成します。これにより、モデルでリアルなシーンを生成できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-02">
        <br><font color="black">2020-07-02</font>
      </time>
    </span>
</section>
<!-- paper0: Distance-Based Anomaly Detection for Industrial Surfaces Using Triplet
  Networks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_38.html">
      <font color="black">Distance-Based Anomaly Detection for Industrial Surfaces Using Triplet
  Networks</font>
    </a>
  </h2>
  <font color="black">この論文では、代わりに距離ベースの異常検出目標を使用して表面テクスチャパッチでCNNをトレーニングすることにより、この課題に対処します。近年、人間の専門家の代わりに機械ベースの目視検査を利用してこのタスクを実行しています。評価結果トレーニングデータの一部である既知の表面と目に見えない新しい表面について、曲がった、壊れた、またはひびの入った表面など、さまざまなタイプの異常を検出するアプローチの強みを示します。 
[要約]分類目標のcnnは、十分に大量の欠陥データを必要としますが、これは多くの場合利用できません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Deep Poisoning: Towards Robust Image Data Sharing against Visual
  Disclosure -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_39.html">
      <font color="black">Deep Poisoning: Towards Robust Image Data Sharing against Visual
  Disclosure</font>
    </a>
  </h2>
  <font color="black">画像分類に関する実験結果は、提案された方法の有効性を証明します。具体的には、各エンティティはプライベートディープポイズニングモジュール（DPM）を学習し、特定の視覚タスクを実行するように設計された事前トレーニング済みのディープネットワークに挿入します。 DPMは、変更された画像データが特定の視覚タスクの非汚染データと機能的に同等であることを保証しながら、画像の再構成を防ぐために意図的に畳み込み画像機能を汚染します。 
[概要]新しいビジョンタスクにより、さまざまなエンティティがタスク（特定および再構成）を共有して、画像データ共有のための画像表現を証明できます。dpmは、畳み込み画像の特徴を意図的にポイズニングして、ビジョンタスクを防止します。これは、変更された画像データが機能的に同等であることを意味します。特定のビジョンタスクの無毒データ</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-14">
        <br><font color="black">2019-12-14</font>
      </time>
    </span>
</section>
<!-- paper0: A Variational Information Bottleneck Based Method to Compress Sequential
  Networks for Human Action Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_40.html">
      <font color="black">A Variational Information Bottleneck Based Method to Compress Sequential
  Networks for Human Action Recognition</font>
    </a>
  </h2>
  <font color="black">広く使用されている3つの行動認識データセットで実験を行います。つまり、Variational Information Bottleneck（VIB）理論ベースのプルーニングアプローチを使用して、RNNのシーケンシャルセルを通過する情報フローを小さなサブセットに制限します。この問題に対処し、HARに使用されるゲート付きリカレントユニット（GRU）やロングショートタームメモリユニット（LSTM）などのリカレントニューラルネットワーク（RNN）を効果的に圧縮する方法を提案します。 
[要約]提案された手法は、検証精度をほとんどまたはまったく低下させることなく、潜在表現からモデルパラメータとメモリフットプリントを削減します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-03">
        <br><font color="black">2020-10-03</font>
      </time>
    </span>
</section>
<!-- paper0: RGBT Salient Object Detection: A Large-scale Dataset and Benchmark -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CV/paper_41.html">
      <font color="black">RGBT Salient Object Detection: A Large-scale Dataset and Benchmark</font>
    </a>
  </h2>
  <font color="black">この作業は、グラウンドトゥルースアノテーションを備えた5000の空間的に整列されたRGBT画像ペアを含むVT5000という名前のRGBT画像データセットに貢献します。VT5000には、アルゴリズムの堅牢性を調査するためにさまざまなシーンと環境で収集された11の課題があります。広範な実験により、提案されたベースラインアプローチが示されています。 VT5000データセットおよび他の2つのパブリックデータセットの最先端の方法よりも優れています。 
[概要]ほとんどの作品は、実際のアプリケーションのパフォーマンスを制限するrgbベースのデータセットに焦点を当てています。新しい研究の利点は、大規模なデータセットと包括的なベンチマークの欠如によって制限されています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-07">
        <br><font color="black">2020-07-07</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: Learning a Simple and Effective Model for Multi-turn Response Generation
  with Auxiliary Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_0.html">
      <font color="black">Learning a Simple and Effective Model for Multi-turn Response Generation
  with Auxiliary Tasks</font>
    </a>
  </h2>
  <font color="black">これにより、コンテキストの理解に関連する補助タスクは、生成モデルの学習をガイドして、より良い局所最適を達成できます。3つのベンチマークを使用した実証研究は、モデルが最新の生成モデルを大幅に上回ることができることを示しています。自動評価と人間の判断の両方での応答品質の点で、同時にはるかに高速なデコードプロセスを楽しんでいます。これらのモデルは応答品質を改善しましたが、その複雑さも実際のシステムでのモデルの適用を妨げています。 
[要約]既存の状態-3回で、深い神経アーキテクチャの問題に対処できます。このモデルは、応答生成のために会話環境を効果的に活用できます。つまり、コンテキスト理解に関連する補助タスクは、生成モデルの学習をより良い局所最適を達成する</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-04-04">
        <br><font color="black">2020-04-04</font>
      </time>
    </span>
</section>
<!-- paper0: OTEANN: Estimating the Transparency of Orthographies with an Artificial
  Neural Network -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_1.html">
      <font color="black">OTEANN: Estimating the Transparency of Orthographies with an Artificial
  Neural Network</font>
    </a>
  </h2>
  <font color="black">15の正書法で得られたスコアは、他の研究の推定と一致していました。興味深いことに、このモデルは、読み書きの音素規則のみを考慮している学習者が犯した典型的な間違いについての洞察も提供しました。ほとんどのアルファベットは、明確な音から文字への規則を可能にします。 
[概要]モデルはウィキメディア辞書のデータセットに基づいていました。音素から音素への翻訳タスクでの誤った予測の割合をスコアリングするために使用されました。また、音素の翻訳タスクのみを考慮した学習者が犯した典型的な間違いについての洞察も提供しました。読み書きの音素規則</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-12-31">
        <br><font color="black">2019-12-31</font>
      </time>
    </span>
</section>
<!-- paper0: Do Language Embeddings Capture Scales? -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_2.html">
      <font color="black">Do Language Embeddings Capture Scales?</font>
    </a>
  </h2>
  <font color="black">この文脈でまだ研究されていない知識の1つの形式は、オブジェクトのスカラーの大きさに関する情報です。事前トレーニング済み言語モデル（LM）は、重要な言語、常識、および事実に関する知識を持っていることが示されています。事前トレーニング済み言語を示します。モデルはこの情報のかなりの量をキャプチャしますが、一般的な常識的な推論に必要な機能が不足しています。 
[概要]事前トレーニングと計算能力を2つの重要な要素として特定します。数値をバインドする簡単な方法は、結果に大きな影響を与える可能性があります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-11">
        <br><font color="black">2020-10-11</font>
      </time>
    </span>
</section>
<!-- paper0: Improving RNN Transducer Based ASR with Auxiliary Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_3.html">
      <font color="black">Improving RNN Transducer Based ASR with Auxiliary Tasks</font>
    </a>
  </h2>
  <font color="black">次に、両方の補助タスクがRNN-T基準のディープトランスフォーマーエンコーダーの学習に有効性を示し、以前の最高のパフォーマンスモデルと比較して競争力のある結果（LibriSpeechテストクリーン/その他で2.0％/ 4.2％WER）を達成することを確認します。提案された両方の方法が一貫した改善を提供することを発見します。さまざまなトレーニングデータサイズでソーシャルメディアビデオを転記する際、まず、ルーマニア語、トルコ語、ドイツ語の3つの言語でストリーミングASRパフォーマンスを評価します。 
[概要]このモデルは、さまざまなベンチマークで競争力のあるasrパフォーマンスを示しています。プライマリrnnと同じ補助的な方法を使用することを提案します-tasr。両方の提案された方法は一貫した改善を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Profile Consistency Identification for Open-domain Dialogue Agents -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_4.html">
      <font color="black">Profile Consistency Identification for Open-domain Dialogue Agents</font>
    </a>
  </h2>
  <font color="black">また、プロファイルの整合性を識別するためのKey-Value構造情報が豊富なBERTモデルを提案し、強力なベースラインよりも改善されました。プロファイルの整合性の識別の研究を容易にするために、110Kを超える単一の大規模な人間の注釈付きデータセットを作成します。 -会話とそのKey-Value属性プロファイルを有効にします。応答とプロファイルの間の明示的な関係は手動でラベル付けされます。 
[要約]人間との一貫性のある一貫性は、対話の一貫性を向上させるための鍵です。応答とユーザーの間の一貫性を特定する必要はありません。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-09-21">
        <br><font color="black">2020-09-21</font>
      </time>
    </span>
</section>
<!-- paper0: The UCF Podcast Summarization System at TREC 2020 -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_5.html">
      <font color="black">The UCF Podcast Summarization System at TREC 2020</font>
    </a>
  </h2>
  <font color="black">システムの背後にある設計上の考慮事項を強調し、神経抽象システムの長所と短所に関する重要な洞察を提供します。私たちの最高のシステムは、NIST評価者によって判断された1.559の品質評価を達成しました---絶対値0.268（+ 21％）以上作成者の説明..私たちの結果は、抽象的なサマライザーへの入力として使用するトランスクリプトから重要なセグメントを識別することが、長いドキュメントを要約するのに有利であることを示唆しています。 
[要約]重要な情報を収集する簡潔な文学的要約は、ユーザーがポッドキャストを聞くかどうかを決定するために重要です。代わりに、神経抽象要約のいくつかのあまり研究されていない側面を調査します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Chapter Captor: Text Segmentation in Novels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_6.html">
      <font color="black">Chapter Captor: Text Segmentation in Novels</font>
    </a>
  </h2>
  <font color="black">長いテキストをセグメント化する一般的なタスクのプロキシとして、章の境界を予測するタスクを調査します。神経推論とルールマッチングを組み合わせて章のタイトルを認識するハイブリッドアプローチを使用して、9,126の英語の小説のProjectGutenberg章のセグメント化データセットを構築します。本のヘッダー、このタスクで0.77のF1スコアを達成します。本は通常、一貫したサブナラティブとトピックを表す章とセクションに分割されます。 
[概要]長いテキストを組み合わせる一般的なタスクのプロキシとして、章の境界を予測するタスクを調査します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: MultiWOZ 2.3: A multi-domain task-oriented dataset enhanced with
  annotation corrections and co-reference annotation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_7.html">
      <font color="black">MultiWOZ 2.3: A multi-domain task-oriented dataset enhanced with
  annotation corrections and co-reference annotation</font>
    </a>
  </h2>
  <font color="black">対話行為と対話状態の間の一貫性を確保するために、共参照機能を実装し、対話行為と対話状態の注釈を統合します。MultiWOZ2.3での自然言語理解と対話状態追跡の最先端のパフォーマンスを更新します。以前のバージョンのMultiWOZデータセット（2.0-2.2）よりも大幅に改善されています。元のMultiWOZデータセットに表示された注釈エラーを修正するためにさまざまな努力が払われています。 
[ABSTRACT]ダイアログ状態の注釈は、ダイアログ状態からのダイアログ動作で表示されます。結果は、multiwozデータセットの以前のバージョンよりも大幅に改善されていることを示しています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-12">
        <br><font color="black">2020-10-12</font>
      </time>
    </span>
</section>
<!-- paper0: PubSqueezer: A Text-Mining Web Tool to Transform Unstructured Documents
  into Structured Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_8.html">
      <font color="black">PubSqueezer: A Text-Mining Web Tool to Transform Unstructured Documents
  into Structured Data</font>
    </a>
  </h2>
  <font color="black">新しいトピックの探索を開始したい場合は、たくさんの記事を読まずに全体像を把握することは困難です。可用性：http：//www.pubsqueezer.com。特に、2つのデータサイエンス分析を示します。 
[要約]新しい質問をするためには、精神的なつながりを作ることが重要です。pubsqueezerで生成されたデータにより、科学的知識を使いやすくなります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: What time is it? Temporal Analysis of Novels -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_9.html">
      <font color="black">What time is it? Temporal Analysis of Novels</font>
    </a>
  </h2>
  <font color="black">このアプローチは、ベースラインを2時間以上改善します。さらに、ブレークポイントの動的計画法を使用して本全体を分析することにより、それぞれが特定の時刻に対応するセグメントに本を大まかに分割できることを示します。 、私たちは、過去の時間ごとの活動の興味深い傾向を示すために、歴史のさまざまな期間によって分類された文献のコーパスにモデルを適用します。 
[概要]時間に関連する以前の作業は、さまざまな異なる履歴パターンのキャプチャに焦点を当てていました。ただし、明示的な時間（派生フレーズ）の代わりに、平均エラー2.27時間を達成する時刻分類モデルを作成します。このアプローチは改善されます。 2時間以上のベースライン</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient End-to-End Speech Recognition Using Performers in Conformers -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_10.html">
      <font color="black">Efficient End-to-End Speech Recognition Using Performers in Conformers</font>
    </a>
  </h2>
  <font color="black">提案された注意ベースの効率的なエンドツーエンド音声認識モデルは、1000万のパラメータと線形計算の複雑さを備えたLibriSpeechコーパスで競争力のあるパフォーマンスをもたらします。デバイス上のエンドツーエンド音声認識は、モデルの効率に高い要件をもたらします。提案されたモデルは、以前の軽量エンドツーエンドモデルよりも、単語エラー率が比較的20％優れています。 
[概要]提案されたモデルは、以前の軽量モデルよりもパフォーマンスが高く、単語誤り率が比較的20％高くなっています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: How Domain Terminology Affects Meeting Summarization Performance -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_11.html">
      <font color="black">How Domain Terminology Affects Meeting Summarization Performance</font>
    </a>
  </h2>
  <font color="black">会議の要約の研究を進めるために、すべてのドメイン用語を公開します。次に、専門用語を使用した場合と使用しない場合の会議の要約システムのパフォーマンスを分析します。これまで、ドメインの用語が会議の要約のパフォーマンスに与える影響については、まだ調査されていません。会議はドメインの知識が豊富です。 
[概要]新しい調査によると、ドメイン定義は要約パフォーマンスのパフォーマンスパフォーマンスに大きな影響を与える可能性があります。ゴールドを作成します。大規模な会議コーパスのドメインワードの標準的な注釈です。専門用語として知られています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-02">
        <br><font color="black">2020-11-02</font>
      </time>
    </span>
</section>
<!-- paper0: "What Do You Mean by That?" A Parser-Independent Interactive Approach
  for Enhancing Text-to-SQL -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_12.html">
      <font color="black">"What Do You Mean by That?" A Parser-Independent Interactive Approach
  for Enhancing Text-to-SQL</font>
    </a>
  </h2>
  <font color="black">実験は、WikiSQLとより複雑なSpiderの2つのクロスドメインデータセットで、5つの最先端のパーサーを使用して実施されました。これらは、PIIAが限られたインタラクションターンでテキストからSQLへのパフォーマンスを向上できることを示しました。シミュレーションと人間による評価の両方を使用します。主な理由の1つは、ユーザーの自然な言語の質問を完全に理解することが難しいことに起因します。 
[概要]新しい論文で、新しいパーサー（複数選択の質問を使用してユーザーと対話し、任意のパーサーを簡単に操作できる独立したインタラクティブなアプローチ（piia））を紹介します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Phoneme Based Neural Transducer for Large Vocabulary Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_13.html">
      <font color="black">Phoneme Based Neural Transducer for Large Vocabulary Speech Recognition</font>
    </a>
  </h2>
  <font color="black">また、さまざまなデコードアプローチを簡単に比較します。さらに改善するために、簡略化されたスケジュールサンプリングアプローチが適用されます。最高のパフォーマンスを得るには、音声コンテキストサイズが1で十分であることが示されています。 
[概要]私たちの最高のモデルの全体的なパフォーマンスは、テッドの最先端の結果に匹敵します-リウムリリース2と配電盤コーパス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-30">
        <br><font color="black">2020-10-30</font>
      </time>
    </span>
</section>
<!-- paper0: Text Classification through Glyph-aware Disentangled Character Embedding
  and Semantic Sub-character Augmentation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_14.html">
      <font color="black">Text Classification through Glyph-aware Disentangled Character Embedding
  and Semantic Sub-character Augmentation</font>
    </a>
  </h2>
  <font color="black">本論文では、日本語のテキスト分類タスクを使用して、ドキュメントレベルおよび文レベルでフレームワークを評価しました。GDCEおよびSSAが埋め込みの解釈可能性を提供するだけでなく、分類パフォーマンスも向上させることを確認しました。新しい文字ベースの提案中国語や日本語などのアルファベット以外の言語のテキスト分類フレームワーク。 
[概要]システムは、絡み合った変分文字で構成されています-embedding.itは、解釈可能なデータ拡張（ssa）に適用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Latent Compositional Representations Improve Systematic Generalization
  in Grounded Question Answering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_15.html">
      <font color="black">Latent Compositional Representations Improve Systematic Generalization
  in Grounded Question Answering</font>
    </a>
  </h2>
  <font color="black">この作業では、CKYスタイルのパーサーを使用して、ボトムアップの構成的な方法ですべての質問スパンの表現と表示を計算するモデルを提案します。多段階の推論を含む質問に答えるには、それらを分解し、の答えを使用する必要があります。最終的な答えに到達するための中間ステップ..ツリー構造に対するこの誘導バイアスは、算術式ベンチマークおよび系統的に焦点を当てたデータセットであるCLOSUREの強力なベースラインと比較して、分布外の例への系統的一般化を劇的に改善することを示します根拠のある質問回答のためのモデルの一般化。 
[ABSTRACT]質問応答では、明示的に分解を実行しないため、分布の例から外への一般化が困難になります。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-07-01">
        <br><font color="black">2020-07-01</font>
      </time>
    </span>
</section>
<!-- paper0: A Primer in BERTology: What we know about how BERT works -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_16.html">
      <font color="black">A Primer in BERTology: What we know about how BERT works</font>
    </a>
  </h2>
  <font color="black">BERTがどのように機能するか、どのような種類の情報を学習し、どのように表現されるか、トレーニングの目的とアーキテクチャに対する一般的な変更、パラメータ設定の問題、圧縮へのアプローチに関する現在の知識の状態を確認します。トランスベースのモデルは、 NLPの多くの分野での技術ですが、成功の背後にあるものについての私たちの理解はまだ限られています。次に、将来の研究の方向性について概説します。 
[概要]新しい論文は、人気のあるバートモデルの150を超える研究の最初の調査です</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-27">
        <br><font color="black">2020-02-27</font>
      </time>
    </span>
</section>
<!-- paper0: Refining Implicit Argument Annotation for UCCA -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_17.html">
      <font color="black">Refining Implicit Argument Annotation for UCCA</font>
    </a>
  </h2>
  <font color="black">提案された暗黙の引数の分類は、暗黙の役割解釈の理論によって推進され、6つのタイプで構成されます：直示的、一般的、ジャンルベース、タイプ識別可能、非特定、および反復セット..の一部を再検討することにより、設計を例示します。 UCCA EWTコーパス、リファインメントレイヤーで注釈が付けられた新しいデータセットを提供し、他のスキームとの比較分析を行います。ただし、NLUの暗黙の役割を表すリソースはごくわずかであり、NLPの既存の研究では、省略された引数のカテゴリを大まかに区別するだけです。言語形式。 
[ABSTRACT] ucca ewtコーパスの分析は、言語理解に不確実性をもたらします。しかし、一部の引数が文で明示的に言及されていないという事実は、中央言語理解にあいまいさを引き起こします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-26">
        <br><font color="black">2020-05-26</font>
      </time>
    </span>
</section>
<!-- paper0: Token Sequence Labeling vs. Clause Classification for English Emotion
  Stimulus Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_18.html">
      <font color="black">Token Sequence Labeling vs. Clause Classification for English Emotion
  Stimulus Detection</font>
    </a>
  </h2>
  <font color="black">そのために、2つの異なるアプローチを比較可能に評価し、北京語の最先端のアプローチに触発されたモデルを実装し、異なるドメインの4つの英語データセットでテストできる統合フレームワークを提案します。句の分類またはシーケンスのラベル付けが英語での感情刺激の検出に適しているかどうかを回答することを目的としています。感情刺激の検出は、感情分析のターゲットまたはアスペクトの検出と同様に、テキストの説明で感情の原因を見つけるタスクです。 
[要約]私たちは、句の分類またはシーケンスのラベル付けが英語での感情刺激の説明に適しているかどうかに答えることを目指しています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-15">
        <br><font color="black">2020-10-15</font>
      </time>
    </span>
</section>
<!-- paper0: What's New? Summarizing Contributions in Scientific Literature -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_19.html">
      <font color="black">What's New? Summarizing Contributions in Scientific Literature</font>
    </a>
  </h2>
  <font color="black">データセットとともに、3つのベースラインアプローチを紹介して分析します：1）入力コードプレフィックスによって制御される統合モデル、2）解きほぐされた出力の生成に特化した個別の生成ヘッドを備えたモデル、3）を使用してモデルをガイドするトレーニング戦略インバウンドおよびアウトバウンドの引用からの追加の監督..この問題を克服するために、紙の寄稿と作業のコンテキストについて個別の要約を生成し、主要な調査結果を簡単に特定できるようにする、解きほぐされた紙の要約の新しいタスクを導入します記事で共有..また、生成された出力の関連性、新規性、および解きほぐしを報告する包括的な自動評価プロトコルを提案します。 
[要約]解きほぐされた紙の要約は、紙の貢献と作業のコンテキストについて個別の要約を生成しようとします。79％の場合、新しいタスクは従来の科学的な紙の要約よりも役立つと考えられています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-06">
        <br><font color="black">2020-11-06</font>
      </time>
    </span>
</section>
<!-- paper0: CxGBERT: BERT meets Construction Grammar -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_20.html">
      <font color="black">CxGBERT: BERT meets Construction Grammar</font>
    </a>
  </h2>
  <font color="black">この作業では、いくつかのプローブを設計し、この質問に答えるために広範な実験を行います。私たちの結果により、BERTは実際にかなりの量の情報にアクセスでき、その多くは言語学者が通常構造情報と呼んでいると結論付けることができます。この影響観察は、深層学習法がテキストから何を学習するかについての洞察を提供すると同時に、構造に含まれる情報が言語学で冗長にエンコードされていることを示すため、潜在的に広範囲に及ぶ可能性があります。 
[ABSTRACT]構築主義者は、言語は構造、フォームと機能の学習されたペア、またはその構成要素の部分からは予測できない頻繁な意味を持つと結論付けています。この観察の影響は潜在的に遠いです。ディープラーニング手法がテキストから何を学ぶかについての洞察を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Generalized End-to-End Loss for Speaker Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_21.html">
      <font color="black">Generalized End-to-End Loss for Speaker Verification</font>
    </a>
  </h2>
  <font color="black">これらの特性により、新しい損失関数を使用したモデルでは、話者検証EERが10％以上減少し、同時にトレーニング時間が60％減少します。また、ドメイン適応を可能にするMultiReader手法も導入します。複数のキーワード（「OKGoogle」と「HeyGoogle」）と複数の方言をサポートする、より正確なモデルのトレーニング。 
[概要] ge2e損失関数は、トレーニングプロセスの各ステップで検証するのが難しい例を強調する方法でネットワークを更新します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2017-10-28">
        <br><font color="black">2017-10-28</font>
      </time>
    </span>
</section>
<!-- paper0: NUAA-QMUL at SemEval-2020 Task 8: Utilizing BERT and DenseNet for
  Internet Meme Emotion Analysis -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/cs.CL/paper_22.html">
      <font color="black">NUAA-QMUL at SemEval-2020 Task 8: Utilizing BERT and DenseNet for
  Internet Meme Emotion Analysis</font>
    </a>
  </h2>
  <font color="black">私たちのモデルは、BERTを使用してテキストの埋め込みを学習し、DenseNetを使用して画像から特徴を抽出し、その後、連結によって両方の特徴を組み合わせます。ただし、テキストの特徴を追加すると、Memotion Analysisに必ずしも役立つとは限りません。結果は、画像分類モデルがミームの分類に役立つ可能性があることを示しています。 、DenseNetがResNetを上回っています。 
[概要]私たちのシステムは、テキストや画像からの埋め込みを使用してマルチモーダルを学習し、感情によってインターネットミームを分類します。また、densenetによって生成された結果、潜在的な分析を伴う画像と比較します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label4"/>
    <div class="hidden_show">
<!-- paper0: Data Augmentation For Children's Speech Recognition -- The "Ethiopian"
  System For The SLT 2021 Children Speech Recognition Challenge -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.AS/paper_0.html">
      <font color="black">Data Augmentation For Children's Speech Recognition -- The "Ethiopian"
  System For The SLT 2021 Children Speech Recognition Challenge</font>
    </a>
  </h2>
  <font color="black">チャレンジ後の分析では、システムが実際にトラック1の評価セットで18.82％のCERを達成していることが示されていますが、トラック1のチャレンジオーガナイザーに間違ったバージョンを送信しました。ステップバイステップで、最終的なシステムをどのように考え出すかを説明します。これは、SLT 2021子供音声認識チャレンジで最先端の結果を提供します。トラック1評価セットで21.66％CER（全体で4位）、トラック2評価セットで16.53％CER（全体で1位）です。 ..子供の音声認識問題、特に子供の音声認識トレーニングデータの問題に取り組むために、さまざまなデータ処理および拡張技術が提案されています。 
[概要] slt2021子供音声認識チャレンジは結果を提供します。結果は競争の結果に提示されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: An Empirical Study of Visual Features for DNN based Audio-Visual Speech
  Enhancement in Multi-talker Environments -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.AS/paper_1.html">
      <font color="black">An Empirical Study of Visual Features for DNN based Audio-Visual Speech
  Enhancement in Multi-talker Environments</font>
    </a>
  </h2>
  <font color="black">適切なオーディオ入力機能とネットワークアーキテクチャに関するさまざまな研究がありますが、私たちの知る限り、この特定のタスクに最適な視覚機能を調査した研究は公開されていません。埋め込みベースの機能のパフォーマンスが向上し、計算量の多い前処理により、低リソースシステムでの使用が困難になります。オーディオビジュアルスピーチエンハンスメント（AVSE）メソッドは、スピーチエンハンスメントとビジュアルの使用のタスクにオーディオ機能とビジュアル機能の両方を使用します。機能は、マルチスピーカーのシナリオで特に効果的であることが示されています。 
[概要]ディープニューラルネットワーク（dnn）ベースのavseメソッドの大部分では、オーディオデータとビジュアルデータは最初に異なるサブネットワークを使用して別々に処理されます。学習された機能は、両方のモダリティからの情報を利用するために融合されます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: COVID-19 Patient Detection from Telephone Quality Speech Data -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.AS/paper_2.html">
      <font color="black">COVID-19 Patient Detection from Telephone Quality Speech Data</font>
    </a>
  </h2>
  <font color="black">YouTubeビデオから収集された小さなデータセットでの実験では、このデータセットのSVM分類器が88.6％の精度と92.7％のF1スコアを達成できることが示されています。さらに調査すると、鼻などの一部の電話クラスが停止し、中央母音は、2つのクラスを他のクラスよりもよく区別できます。各文は、各音声の短期メルフィルターバンク機能のスーパーベクターとして表されます。 
[概要]これらの機能は、covid-19スピーチを通常から分離するための2つの分類子を学習するために使用されます</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Guided Source Separation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.AS/paper_3.html">
      <font color="black">Guided Source Separation</font>
    </a>
  </h2>
  <font color="black">ただし、AWメソッドは、時不変信号特性（SC）を示すために参照スニペットと目的の信号を必要とし、スピーカー分離にのみ適用されています。これらのAWメソッドがユニバーサルソース分離に使用できることを示し、AWを提案します。参照信号から時変補助情報を抽出する方法。このようにして、SCは参照と混合で時間とともに変化することができます。 
[ABSTRACT]目的のコンポーネントのスニペットはトレーニング時に定義されます。dnnは最初のdnnの適応重み（aw）のセットを推定します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Statistical feature embedding for heart sound classification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.AS/paper_4.html">
      <font color="black">Statistical feature embedding for heart sound classification</font>
    </a>
  </h2>
  <font color="black">最終的に、縮小されたサイズのベクトルは、分類の目的でガウス混合モデル（GMM）とサポートベクターマシン（SVM）に供給されます。実験結果は、提案された方法が、修正精度（MAcc）に基づいて16％のパフォーマンス改善を達成できることを示しています。 Physoinetデータセットのベースラインシステム。その後、主成分分析（PCA）変換と変分自動エンコーダー（VAE）がiベクトルに適用され、次元の縮小が実現されます。 
[概要]病気の診断のための心音のパターンが増加しました。研究者は心音の改善システムを開発しました</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-04-26">
        <br><font color="black">2019-04-26</font>
      </time>
    </span>
</section>
<!-- paper0: Improving RNN Transducer Based ASR with Auxiliary Tasks -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.AS/paper_5.html">
      <font color="black">Improving RNN Transducer Based ASR with Auxiliary Tasks</font>
    </a>
  </h2>
  <font color="black">次に、両方の補助タスクがRNN-T基準のディープトランスフォーマーエンコーダーの学習に有効性を示し、以前の最高のパフォーマンスモデルと比較して競争力のある結果（LibriSpeechテストクリーン/その他で2.0％/ 4.2％WER）を達成することを確認します。この作業では、RNN-Tが補助タスクを実行することでASRの精度を向上させる方法を検討します。具体的には、リカレントニューラルネットワークトランスデューサー（RNN-T）は、さまざまなベンチマークで競争力のあるASRパフォーマンスを示しています。 
[概要]このモデルは、さまざまなベンチマークで競争力のあるasrパフォーマンスを示しています。プライマリrnnと同じ補助的な方法を使用することを提案します-tasr。両方の提案された方法は一貫した改善を提供します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-05">
        <br><font color="black">2020-11-05</font>
      </time>
    </span>
</section>
<!-- paper0: Efficient Training Data Generation for Phase-Based DOA Estimation -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.AS/paper_6.html">
      <font color="black">Efficient Training Data Generation for Phase-Based DOA Estimation</font>
    </a>
  </h2>
  <font color="black">データ生成方法は、直接経路の決定論的モデルと部屋の伝達関数の遅い残響の統計モデルを採用することにより、周波数領域でのマイクロフォン信号の位相をモデル化します。深層学習（DL）ベースの到着方向（DOA） ）推定は活発な研究トピックであり、現在の最先端を表しています。測定された部屋のインパルス応答からのデータを使用した評価により、提案されたトレーニングデータ生成方法でトレーニングされたモデルがでトレーニングされたモデルと同等に機能することを示します。ソースイメージ法に基づいて生成されたデータ。 
[概要]フェーズベースの特徴入力を使用してdlモデルをトレーニングするための複雑度の低いオンラインデータ生成方法を提案します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Mask Proxy Loss for Text-Independent Speaker Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.AS/paper_7.html">
      <font color="black">Mask Proxy Loss for Text-Independent Speaker Recognition</font>
    </a>
  </h2>
  <font color="black">プロキシベースの損失は両方の欠点を軽減しますが、エンティティ間のきめ細かい接続は活用されないか、間接的に活用されます。エンティティとエンティティのペアの硬さを活用するために、多項マスクプロキシ（MMP）損失をさらに提案します。既存のほとんどContrastive、Triplet、Prototypical、GE2Eなどのメトリック学習目標はすべて前の部門に属しており、そのパフォーマンスはサンプルマイニング戦略に大きく依存しているか、ミニバッチのラベル情報が不十分であるために制限されています。 
[ABSTRACT]教師あり学習は、エンティティベースの学習とプロキシベースの学習に定義できます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: A Hierarchical Subspace Model for Language-Attuned Acoustic Unit
  Discovery -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.AS/paper_8.html">
      <font color="black">A Hierarchical Subspace Model for Language-Attuned Acoustic Unit
  Discovery</font>
    </a>
  </h2>
  <font color="black">転写された言語のセットでハイパー部分空間をトレーニングし、それをターゲット言語に転送します。このアプローチでは、タスクを低次元の音声部分空間への埋め込みの学習の1つとしてフレーム化し、同時に部分空間自体をとして指定します。ハイパー部分空間への埋め込み..TIMITと2つの低リソース言語であるMboshiとYorubaで実験を行います。 
[概要]私たちのモデルは、クラスタリング品質とセグメンテーション精度の両方の点で、主要な音響ユニット発見技術よりも優れています</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-04">
        <br><font color="black">2020-11-04</font>
      </time>
    </span>
</section>
<!-- paper0: Phoneme Based Neural Transducer for Large Vocabulary Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.AS/paper_9.html">
      <font color="black">Phoneme Based Neural Transducer for Large Vocabulary Speech Recognition</font>
    </a>
  </h2>
  <font color="black">また、さまざまなデコードアプローチを簡単に比較します。音声認識の従来のアプローチとエンドツーエンドのアプローチの利点を組み合わせるために、音素ベースのニューラルトランスデューサモデリングのシンプルで斬新で競争力のあるアプローチを紹介します。モデルは、TED-LIUMリリース2およびSwitchboardコーパスの最先端の結果に匹敵します。 
[概要]私たちの最高のモデルの全体的なパフォーマンスは、テッドの最先端の結果に匹敵します-リウムリリース2と配電盤コーパス</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-10-30">
        <br><font color="black">2020-10-30</font>
      </time>
    </span>
</section>
<!-- paper0: Knowledge Distillation for Singing Voice Detection -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.AS/paper_10.html">
      <font color="black">Knowledge Distillation for Singing Voice Detection</font>
    </a>
  </h2>
  <font color="black">ただし、私たちの知る限り、このような方法はSVDの領域ではまだ検討されていません。公開されているJamendoデータセットでの広範な実験を通じて、はるかに小さいモデルで同等の精度を達成できるだけでなく、パラメータの点で最大1000分の1になります）が、魅力的なことに、蒸留でトレーニングされた小さなモデルは、音声検出パフォーマンスに関して現在の最先端モデルを上回っています。この問題に対処する最も一般的な方法は知られています。 （モデル圧縮に加えて）深層学習文献の知識蒸留として、教師と呼ばれる事前にトレーニングされた大規模なネットワークを使用して、小規模な学生ネットワークをトレーニングします。 
[概要]現在、cnnとrnnに基づく2つのディープニューラルネットワークが、音声検出タスクの最適化された機能を学習する文献に存在します。これらには、データセットでの音声検出とジャムパフォーマンスの状態が含まれます。最も一般的な方法が知られています。知識蒸留として、教師と呼ばれる事前にトレーニングされた大規模なネットワークを使用して、小規模な学生ネットワークをトレーニングします。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: FUN! Fast, Universal, Non-Semantic Speech Embeddings -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.AS/paper_11.html">
      <font color="black">FUN! Fast, Universal, Non-Semantic Speech Embeddings</font>
    </a>
  </h2>
  <font color="black">これらの埋め込みモデルは、さまざまなモバイルデバイスでリアルタイムに実行するのに十分な速度であり、最近公開された非セマンティック音声タスクのベンチマークで、ほとんどのタスクで無視できるパフォーマンスの低下を示すことを示します。さらに、これらの表現が音声中のマスク検出や非音声の人間の音の検出などのモバイルヘルスタスクに役立ちます。モバイルデバイス上で効率的に実行されるように設計された、MobileNetに基づく軽量ユニバーサル音声埋め込みモデルのクラスを提案します。 
[ABSTRACT]埋め込み埋め込み埋め込みは知識蒸留によってトレーニングされます。これらの埋め込み埋め込みは、知識蒸留によってトレーニングされます。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Gated Recurrent Fusion with Joint Training Framework for Robust
  End-to-End Speech Recognition -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.AS/paper_12.html">
      <font color="black">Gated Recurrent Fusion with Joint Training Framework for Robust
  End-to-End Speech Recognition</font>
    </a>
  </h2>
  <font color="black">まず、マスクベースの音声強調ネットワークを適用して入力音声を強調します。次に、ASRのパフォーマンスを向上させるために、最先端の音声変換アルゴリズムを音声認識コンポーネントとして使用します。次に、GRF音声歪みの問題に対処するために適用されます。 
[概要]提案手法は、音声強調、grf、音声認識を使用します。音声歪み問題の影響を受ける拡張機能と組み合わせることができます。これは、音声認識コンポーネントの入力として拡張機能のみを使用するためです。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Musical analysis of Stravinski's "The Rite of Spring" based on
  computational methods -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.AS/paper_13.html">
      <font color="black">Musical analysis of Stravinski's "The Rite of Spring" based on
  computational methods</font>
    </a>
  </h2>
  <font color="black">この意味で、私はここで、同様の分析を見つけることを目的とした独自の手動分析と計算アプローチを提案し、新しい可能性のある視点を発見し、Musi &quot;cComputingの一般的な分析システムの現在の欠陥を提供する機会を与えました。 、その分析は、その構造と構成の基礎の中でさまざまな意見を引き起こしました。ストラヴィンスキーの「春の儀式」は、古典的な現代音楽のレパートリーから最も有名な作品の1つです。
[要約]分析は、構成についてさまざまな質問を引き起こしました建物の構造。調査結果は、ノルウェー大学のデータに基づいています。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: STOI-Net: A Deep Learning based Non-Intrusive Speech Intelligibility
  Assessment Model -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.AS/paper_14.html">
      <font color="black">STOI-Net: A Deep Learning based Non-Intrusive Speech Intelligibility
  Assessment Model</font>
    </a>
  </h2>
  <font color="black">実験結果は、STOI-Netによって推定されたSTOIスコアが、ノイズの多い強化された音声発話でテストされた場合、実際のSTOIスコアと良好な相関関係があることを示しています。モデルは、畳み込みニューラルネットワークと双方向の長期短期記憶の組み合わせによって形成されます。 （CNN-BLSTM）乗法的注意メカニズムを備えたアーキテクチャ..結果は、クリーンな音声を参照せずにSTOIスコアを正確に予測するSTOI-Netの機能を確認します。 
[ABSTRACT] stgibilityには、実際のシナリオでの音声のテストが必要です。testは、stireスコアが実際のstoiスコアと良好な相関関係があることを示しています。テスト結果は、stoi-netがstoiスコアを正確に予測する能力を確認します。</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-11-09">
        <br><font color="black">2020-11-09</font>
      </time>
    </span>
</section>
<!-- paper0: Multichannel Online Dereverberation based on Spectral Magnitude Inverse
  Filtering -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.AS/paper_15.html">
      <font color="black">Multichannel Online Dereverberation based on Spectral Magnitude Inverse
  Filtering</font>
    </a>
  </h2>
  <font color="black">提案手法は短時間フーリエ変換（STFT）領域で、周波数帯域ごとに独立して実行されます。音声強調と自動音声認識の両方に関する実験が行われ、提案手法が残響を効果的に抑制できることを示しています。移動するスピーカーの難しいケースの場合..複素数値のCTFコンボリューションモデルの代わりに、ソース信号のSTFTマグニチュードとCTFマグニチュードの間の非負のコンボリューションモデルを使用します。これは、前者のモデルの大まかな近似です。ただし、CTF摂動に対してより堅牢であることが示されています。 
[概要]提案された方法は、短いctfで実行され、周波数帯域ごとに基づいています。これは、相互関係法に基づいており、非負のモデルを使用します。このモデルを使用して、ワイヤレスWi-Fiを除外できます。 wi wi-fi</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2018-12-20">
        <br><font color="black">2018-12-20</font>
      </time>
    </span>
</section>
<!-- paper0: Generalized End-to-End Loss for Speaker Verification -->
<section>
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-11-10/eess.AS/paper_16.html">
      <font color="black">Generalized End-to-End Loss for Speaker Verification</font>
    </a>
  </h2>
  <font color="black">また、ドメインの適応を可能にするマルチリーダー技術も紹介します。これにより、複数のキーワード（つまり、「OKGoogle」と「HeyGoogle」）と複数の方言をサポートするより正確なモデルをトレーニングできます。さらに、GE2Eの損失はサンプル選択の初期段階は必要ありません。 
[概要] ge2e損失関数は、トレーニングプロセスの各ステップで検証するのが難しい例を強調する方法でネットワークを更新します</font>
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2017-10-28">
        <br><font color="black">2017-10-28</font>
      </time>
    </span>
</section>
</div>
</main>
	<!-- Footer -->
	<footer role="contentinfo" class="footer">
		<div class="container">
			<hr>
				<div align="center">
					<font color="black">Copyright
							&#064;Akari All rights reserved.</font>
					<a href="https://twitter.com/akari39203162">
						<img src="../../images/twitter.png" hight="128px" width="128px">
					</a>
	  			<a href="https://www.miraimatrix.com/">
	  				<img src="../../images/mirai.png" hight="128px" width="128px">
	  			</a>
	  		</div>
		</div>
		</footer>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>
</html>
