<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-03-25の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: A Simplified Fully Quantized Transformer for End-to-end Speech
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/cs.SD/paper_0.html">
      A Simplified Fully Quantized Transformer for End-to-end Speech
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの実験では、完全精度モデルのパラメーターの数を減らし、8ビットの固定小数点精度に完全に量子化することで、モデルをさらに4倍に圧縮できることを示しています。経験的に、モデルのパフォーマンスで特定のモジュールを破棄します。さらに、完全精度モデルのパフォーマンスを維持しながら、ネットワークの重みとアクティブ化の数値精度を下げることを評価します。 
[ABSTRACT]トランスフォーマーベースのエンコーダー-エンドツーエンドツーエンドのasrタスクのデコーダアーキテクチャの簡略化と圧縮に取り組んでいます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-09">
        <br>2019-11-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Bulbar ALS Detection Based on Analysis of Voice Perturbation and Vibrato -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/cs.SD/paper_1.html">
      Bulbar ALS Detection Based on Analysis of Voice Perturbation and Vibrato
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、持続性母音発声における病理学的ビブラート症状を定量的に評価する方法を提案しました。この作業の目的は、ALS患者の自動検出のための持続性母音発声テストの持続可能性を検証することでした。摂動測定（ジッターやシマーなど）の計算に必要な基本周期に信号を送ります。 
[要約]音響分析に基づく自動音声評価を使用できます。システムを使用して診断プロセスを改善できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-24">
        <br>2020-03-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Time-domain Monaural Speech Enhancement with Recursive Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/cs.SD/paper_2.html">
      A Time-domain Monaural Speech Enhancement with Recursive Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      コードはhttps://github.com/ Andong-Li-speech / RTNet。で提供されています。再帰的学習が採用されてパラメーター効率が向上しているため、トレーニング可能なパラメーターの数は、パフォーマンスを犠牲にすることなく効果的に削減されます。一部は畳み込みオートエンコーダです。 
[ABSTRACT]最初の部分はステージ再帰型ニューラルネットワークと呼ばれます。さまざまなステージ間で深い機能の依存関係を効果的に集約するために導入されます。また、ステージごとに干渉を削除します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-22">
        <br>2020-03-22
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: FGN: Fusion Glyph Network for Chinese Named Entity Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/cs.CL/paper_0.html">
      FGN: Fusion Glyph Network for Chinese Named Entity Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      FGNの主な革新は次のとおりです。（1）CGS-CNNと呼ばれる新しいCNN構造が、隣接する文字からのグリフ情報とグリフ間のインタラクティブ情報の両方をキャプチャするために提案されています。さらに、より多くの実験が行われ、 FGNのさまざまなコンポーネントと設定の影響。（2）BERT表現と文字のグリフ表現を融合するスライディングウィンドウとスライスアテンションを備えたメソッドを提供します。これにより、コンテキストとグリフの間に潜在的なインタラクティブな知識を取り込むことができます。 
[ABSTRACT]漢字には潜在的なグリフ情報が含まれているため、見過ごされがちです。この方法では、フュージョンメカニズムを使用してインタラクティブなinfor --c-を追加することもできます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-01-15">
        <br>2020-01-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Pre-trained Models for Natural Language Processing: A Survey -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/cs.CL/paper_1.html">
      Pre-trained Models for Natural Language Processing: A Survey
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      最初に、言語表現学習とその研究の進捗状況を簡単に紹介します。この調査は、さまざまなNLPタスクのPTMを理解、使用、および開発するための実践的なガイドとなることを目的としています。次に、PTMの知識を下流のタスク。 
[ABSTRACT]最近の調査は、ptmsの包括的なレビューを提供していることを示しています。4つの視点での分類に基づいて、既存のptmsを体系的に分類します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-18">
        <br>2020-03-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning Compact Reward for Image Captioning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/cs.CL/paper_2.html">
      Learning Compact Reward for Image Captioning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      MS COCOとFlickr30Kに関する実験では、この方法が画像キャプションに対するコンパクトな報酬を学習できることを示しています。さらに、損失関数に条件項を導入して、モードの折りたたみを軽減し、生成された説明の多様性を高めます。ただし、既存の敵対的な方法の学習された報酬は、報酬のあいまいさの問題のために曖昧で不明確です。 
[ABSTRACT]既存の敵対的な方法の学習した報酬は、報酬のあいまいさの問題のために、あいまいでよく知られていない
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-24">
        <br>2020-03-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Generating Chinese Poetry from Images via Concrete and Abstract
  Information -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/cs.CL/paper_3.html">
      Generating Chinese Poetry from Images via Concrete and Abstract
  Information
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      自動評価と人間評価の両方の結果から、私たちのアプローチでは、品質を損なうことなく、画像との整合性がより優れた詩を生成できることがわかります。これらのモデルをトレーニングする場合、データセットを構築することは困難です。生成された詩の品質の向上に焦点を当てる以外に、画像から詩を生成することに関する新しいトピックがあります。 
[ABSTRACT]新しいトピックを使用して、画像から詩を生成できます。このペーパーでは、画像から具体的で抽象的な情報を抽出して統合し、これらの問題に対処します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-24">
        <br>2020-03-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: TArC: Incrementally and Semi-Automatically Collecting a Tunisian Arabish
  Corpus -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/cs.CL/paper_4.html">
      TArC: Incrementally and Semi-Automatically Collecting a Tunisian Arabish
  Corpus
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ここ数年で、NLP分野でのアラビア語方言への注目はかなり高まりました。このコードシステムは、コンピューターを介した通信（CMC）での記述を容易にするために、ソーシャルメディアのアラビア語を話すユーザーによって開発されました。テキストメッセージング非公式フレームワーク..方言の中でアラビア語の実現には多様性があり、ほとんどのアラビア語方言と同じように、各アラビア語のコードシステムはリソース不足です。 
[ABSTRACT] arabish（別名arabizi）は、アラビア語の方言をラテン文字と算数グラフで自発的にコーディングしたものです。システムは、ほとんどのアラビア語の方言と同じように、リソースが不足しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-20">
        <br>2020-03-20
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Cross-Lingual Adaptation Using Universal Dependencies -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/cs.CL/paper_5.html">
      Cross-Lingual Adaptation Using Universal Dependencies
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      提案されたアプローチは、UD解析を活用して同様のクロスリンガルタスクを解決するための道を開きます。これは、ラベル付けされたデータが利用できない言語に非常に役立ちます。フランス語、ペルシア語、アラビア語..言い換えの2つのタスクを研究し、事例研究としての意味関係抽出。 
[要約] ud解析のアイデアは、類型-異なる言語で類似性と特異性を示すことです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-24">
        <br>2020-03-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: The JDDC Corpus: A Large-Scale Multi-Turn Chinese Dialogue Dataset for
  E-commerce Customer Service -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/cs.CL/paper_6.html">
      The JDDC Corpus: A Large-Scale Multi-Turn Chinese Dialogue Dataset for
  E-commerce Customer Service
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      人間の会話は複雑であり、人間のような対話エージェントを構築することは非常に困難なタスクです。また、タスク指向、雑談、質問応答などのさまざまな対話タイプもカバーします。次に、いくつかの検索ベースの生成モデルを評価して、 JDDCコーパスの基本的なベンチマークパフォーマンス。 
[ABSTRACT]データセットは、人間のいくつかの特性を反映しています-人間の会話。さまざまな特性には、目標駆動型、およびコンテキスト間の長期依存性が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-22">
        <br>2019-11-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Simplified Fully Quantized Transformer for End-to-end Speech
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/cs.CL/paper_7.html">
      A Simplified Fully Quantized Transformer for End-to-end Speech
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの実験では、完全精度モデルのパラメーターの数を減らし、8ビットの固定小数点精度に完全に量子化することでモデルをさらに4倍に圧縮できることを示しています。さらに、ネットワークの重みとアクティブ化の数値精度を下げて評価します。フルプレシジョンモデルのパフォーマンスを維持しながら..とは言え、このホワイトペーパーでは、エンドツーエンドのASRタスク用のトランスフォーマーベースのエンコーダーデコーダーアーキテクチャの簡略化と圧縮に取り組んでいます。 
[ABSTRACT]トランスフォーマーベースのエンコーダー-エンドツーエンドツーエンドのasrタスクのデコーダアーキテクチャの簡略化と圧縮に取り組んでいます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-09">
        <br>2019-11-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Investigating Software Usage in the Social Sciences: A Knowledge Graph
  Approach -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/cs.CL/paper_8.html">
      Investigating Software Usage in the Social Sciences: A Knowledge Graph
  Approach
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このような分析は手動で行うことができますが、大規模な分析では、情報抽出とリンクの自動化された方法を適用する必要があります。遠方の弱い監督アプローチによって作成されたシルバー標準コーパスと、手動アノテーションによって作成されたゴールド標準コーパスは、 LSTMベースのニューラルネットワークをトレーニングして、科学記事でソフトウェアの言及を特定するために使用されます。さらに、ナレッジグラフのエンティティを、Microsoft Academic Knowledge Graph、Software Ontology、Wikidataなどの他のナレッジベースにリンクしました。 
[ABSTRACT] softwarekgは、社会科学におけるソフトウェアの役割を評価するために使用できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-24">
        <br>2020-03-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Towards Neural Machine Translation for Edoid Languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/cs.CL/paper_9.html">
      Towards Neural Machine Translation for Edoid Languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      トレーニング済みのモデル、コード、データセットはオープンソース化されており、Edoid言語テクノロジーに関する将来の研究努力を推進しています。数百万の先住民言語のL1話者にとって、情報、通信、ヘルスケア、セキュリティへの不平等なアクセスとして現れる不平等がありますまた、政治生活や市民生活への参加を減らしました。新しいJW300パブリックデータセットを使用して、このグループの4つの広く話されている言語（\ `Ed \ &#39;o、\&#39; Es \ &#39;an、Urhobo）のベースライン翻訳モデルをトレーニングおよび評価しましたそして磯子。 
[ABSTRACT]先住民の言語を話す何百万人もの人々にとって、情報、通信、ヘルスケア、セキュリティへの不平等なアクセスとして現れる不平等があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-24">
        <br>2020-03-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Felix: Flexible Text Editing Through Tagging and Insertion -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/cs.CL/paper_10.html">
      Felix: Flexible Text Editing Through Tagging and Insertion
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これらのモデルは両方とも、より高速な推論を保証するために非自己回帰であるように選択されています。これを実現するには、テキスト編集タスクを2つのサブタスクに分解します。出力トークン内の入力トークンのサブセットとその順序を決定するタグ付けと、入力に存在しない出力で欠落しているトークンを埋め込むための挿入。4つのNLGタスクで評価されるとき、Felixは最近のテキスト編集方法および強力なseq2seqベースラインと比較して有利に機能します。SentenceFusion、機械翻訳自動ポスト編集、要約、およびテキストの簡略化。 
[ABSTRACT] felixは低テキスト編集と新しいモデルで効率的です。編集モデルはマスクに基づいていますが、タグ付けモデルは新しいポインターメカニズムを使用しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-24">
        <br>2020-03-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Video Object Grounding using Semantic Roles in Language Description -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/cs.CL/paper_11.html">
      Video Object Grounding using Semantic Roles in Language Description
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ASRLの実験では、VOGでオブジェクト関係をエンコードする必要性が検証され、VOGNetは競合ベースラインを大幅に上回っています。ここでは、VOGでオブジェクト関係の役割を調査し、マルチモーダルオブジェクト関係をエンコードする新しいフレームワークVOGNetを提案します。相対位置エンコーディングによる自己注意..自然言語の説明で参照されているビデオ内のオブジェクトを接地するビデオオブジェクトグラウンディング（VOG）のタスクを探ります。 
[ABSTRACT]新しいデータセットは、既存のキャプションと固定データセットに基づいています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-24">
        <br>2020-03-24
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Reducing the Latency of End-to-End Streaming Speech Recognition Models
  with a Scout Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/eess.AS/paper_0.html">
      Reducing the Latency of End-to-End Streaming Speech Recognition Models
  with a Scout Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちのモデルは、Librispeechのtest-cleanおよびtest-otherデータセットでわずか6億3900万秒のレイテンシで最高のパフォーマンス（2.7 / 6.4 WER）を達成します。スカウトネットワークは、将来のフレームを確認せずに単語境界全体を検出し、認識ネットワークは、予測された境界の前のすべてのフレームを考慮することにより、次のサブワードを予測します。注意ベースのトランスフォーマーモデルは、オフライン音声認識（SR）で有望な結果を達成しました。 
[ABSTRACT]トランスフォーマーベースのストリーミングは、業界や学術機関から注目を集めていますが、そのレイテンシーはエンコーダーレイヤーの数に比例して増加します。スカウトネットワークは、将来のフレームを見ることなく単語境界全体を検出します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-23">
        <br>2020-03-23
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Audio Impairment Recognition Using a Correlation-Based Feature
  Representation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/eess.AS/paper_1.html">
      Audio Impairment Recognition Using a Correlation-Based Feature
  Representation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、特徴のペアの相関に基づく手作りの特徴の新しい表現を提案します。提案した相関に基づく特徴表現を、機械学習で使用される典型的な生の特徴表現と実験的に比較し、優れたパフォーマンスを示します。同等の精度を達成しながら、コンパクトな機能の次元とテスト段階での計算速度の向上という点で。さまざまな音楽スタイルが存在する場合、手作りの機能はオーディオの劣化特性をキャプチャする効率が低く、認識時に失敗する傾向があります。音声障害であり、障害タイプではなく音楽の概念を誤って学習する可能性があります。 
[ABSTRACT]音声障害は音声劣化特性のキャプチャにあまり効率的ではありません。音声障害を認識すると失敗する傾向があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-22">
        <br>2020-03-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Simplified Fully Quantized Transformer for End-to-end Speech
  Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/eess.AS/paper_2.html">
      A Simplified Fully Quantized Transformer for End-to-end Speech
  Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの実験では、完全精度モデルのパラメーターの数を減らし、8ビットの固定小数点精度に完全に量子化することで、モデルをさらに4倍に圧縮できることを示しています。経験的に、モデルのパフォーマンスで特定のモジュールを破棄します。さらに、完全精度モデルのパフォーマンスを維持しながら、ネットワークの重みとアクティブ化の数値精度を下げることを評価します。 
[ABSTRACT]トランスフォーマーベースのエンコーダー-エンドツーエンドツーエンドのasrタスクのデコーダアーキテクチャの簡略化と圧縮に取り組んでいます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-09">
        <br>2019-11-09
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Evaluation of Error and Correlation-Based Loss Functions For Multitask
  Learning Dimensional Speech Emotion Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/eess.AS/paper_3.html">
      Evaluation of Error and Correlation-Based Loss Functions For Multitask
  Learning Dimensional Speech Emotion Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      これら2つの損失関数によるテスト予測の散布図も、CCCスコアによって測定された結果を確認しました。相関相関係数（CCC）損失で相関ベースの損失関数を使用すると、エラーベースの損失関数よりもパフォーマンスが向上することがわかりました。平均CCCスコアによる平均二乗誤差（MSE）損失。損失関数の選択は、機械学習の重要な部分です。 
[要約]結果は2つのデータセットとデータセットと一致しています。結果はデータセットのデータに基づいていました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-24">
        <br>2020-03-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Frequency-Sliding Generalized Cross-Correlation: A Sub-band Time Delay
  Estimation Approach -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/eess.AS/paper_4.html">
      Frequency-Sliding Generalized Cross-Correlation: A Sub-band Time Delay
  Estimation Approach
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーの主な貢献は次のとおりです。1）時間分解能が低下しているにもかかわらず、真のTDOAを推定するためのより適切な表現を提供する、クロスパワースペクトル位相のサブバンドGCC表現。 2）そのような行列表現は、理想的なノイズのない場合にランク1であることが示されています。このプロパティは、より堅牢で正確なGCCを取得するために、より不利なシナリオで利用されます。 3）サブバンドGCC行列を処理するための一連の低ランク近似代替案を提案します。これにより、より良いTDOA推定と音源定位性能が得られます。さらに、GCCは、ステアリング応答電力（SRP）測位アルゴリズムでも重要な役割を果たします。ここで、SRP関数は、複数のセンサーペアから計算されたGCCの累積として記述できます。提案された方法は、スライディングウィンドウ方式でクロスパワースペクトルフェーズの異なる周波数帯域に対応する複数のGCCの抽出に基づいています。 
[要約]提案された方法は複数のgccの抽出に基づいています。これらはスライディングウィンドウ方式に基づいています。この方法を使用して新しい方法を開発できます。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-19">
        <br>2019-10-19
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Bulbar ALS Detection Based on Analysis of Voice Perturbation and Vibrato -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/eess.AS/paper_5.html">
      Bulbar ALS Detection Based on Analysis of Voice Perturbation and Vibrato
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、持続性母音発声における病理学的ビブラート症状の定量的評価のための方法を提案しました。この作業の目的は、ALS患者の自動検出のための持続性母音発声テストの持続可能性を検証することでした。この研究の実験では、音響分析法では、線形判別分析に基づく分類器は、90.7 \％の精度と86.7 \％の感度と92.2 \％の特異性を実現します。 
[要約]音響分析に基づく自動音声評価を使用できます。システムを使用して診断プロセスを改善できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-24">
        <br>2020-03-24
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Time-domain Monaural Speech Enhancement with Recursive Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-03-25/eess.AS/paper_6.html">
      A Time-domain Monaural Speech Enhancement with Recursive Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      コードはhttps://github.com/ Andong-Li-speech / RTNet。で提供されています。3番目の部分は、一連の連結されたゲート線形ユニットで構成され、情報の流れを促進し、受容野を徐々に増やします。パラメータの効率を向上させるために再帰学習が採用されているため、パフォーマンスを犠牲にすることなく、トレーニング可能なパラメータの数が効果的に削減されます。 
[ABSTRACT]最初の部分はステージ再帰型ニューラルネットワークと呼ばれます。さまざまなステージ間で深い機能の依存関係を効果的に集約するために導入されます。また、ステージごとに干渉を削除します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-03-22">
        <br>2020-03-22
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="">
      
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      本日更新された論文はありません
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="">
        <br>
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
