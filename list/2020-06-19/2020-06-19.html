<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Akari" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157706143-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157706143-1');
</script>

<title>Akari-2020-06-19の記事</title>
<link rel='stylesheet' type='text/css' href='../../css/normalize.css'>
<link rel='stylesheet' type='text/css' href='../../css/skelton.css'>
<link rel='stylesheet' type='text/css' href='../../css/menu_bar.css'>
<link rel='stylesheet' type='text/css' href='../../css/field.css'>
<link rel='stylesheet' type='text/css' href='../../css/custom.css'>

</head>
<body>
<div class="container">
<!--
	header
	-->
<header role="banner">
		<div class="header-logo">
			<a href="../../index.html"><img src="../../images/akari.png" width="100" height="100"></a>
		</div>
	</header>
  <input type="checkbox" id="cp_navimenuid">
<label class="menu" for="cp_navimenuid">
<div class="menubar">
	<span class="bar"></span>
	<span class="bar"></span>
	<span class="bar"></span>
</div>
  <ul>
    <li><a id="home" href="../../index.html">Home</a></li>
    <li><a id="about" href="../../teamAkariとは.html">About</a></li>
    <li><a id="contact" href="../../contact.html">Contact</a></li>
    <li><a id="contact" href="../../list/newest.html">New Papers</a></li>
    <li><a id="contact" href="../../list/back_number.html">Back Numbers</a></li>
  </ul>

</label>

<!--
	fields
	-->
<div class="topnav">
<!-- field: cs.SD -->
  <li class="hidden_box">
    <label for="label0">
cs.SD
  </label></li>
<!-- field: cs.CL -->
  <li class="hidden_box">
    <label for="label1">
cs.CL
  </label></li>
<!-- field: eess.AS -->
  <li class="hidden_box">
    <label for="label2">
eess.AS
  </label></li>
<!-- field: biorxiv.physiology -->
  <li class="hidden_box">
    <label for="label3">
biorxiv.physiology
  </label></li>
</div>

<!--
 horizontal line between field and titles.
 -->
<!--
分野と論文の間の線
-->

<svg class='line_field-papers' viewBox='0 0 390 2'>
  <path fill='transparent'  id='__1' d='M 0 2 L 390 0'>
  </path>
</svg>
<!-- 
 papers 
 -->
<main role="main">
  <div class="hidden_box">
    <input type="checkbox" id="label0"/>
    <div class="hidden_show">
<!-- paper0: Boosting Objective Scores of Speech Enhancement Model through MetricGAN
  Post-Processing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.SD/paper_0.html">
      Boosting Objective Scores of Speech Enhancement Model through MetricGAN
  Post-Processing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、提案されたシステムが主観的評価と客観的評価の両方でチャレンジベースラインを大幅に上回っていることを示しています。具体的には、位置エンコーディングは必要ない可能性があるため、畳み込み層に置き換えられます。拡張音声のPESQスコアをさらに改善するには、 L_1の事前トレーニング済みトランスフォーマーは、MetricGANフレームワークによって微調整されています。 
[要約]変更されたアーキテクチャは、強化された音声のpesqスコアを改善するのに役立ちます。研究では、音声変換タスクに変更された変換を適用します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Self-supervised Learning for Speech Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.SD/paper_1.html">
      Self-supervised Learning for Speech Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      まず、クリーンな音声の限られたトレーニングセットを使用し、それらのマグニチュードスペクトログラムを自動エンコードすることで潜在表現を学習します。トレーニングデータの条件を緩和するために、音声監視ネットワークを自己監視方式でトレーニングするタスクを検討します。次に、ノイズの多い環境で録音された音声混合を自動エンコードし、結果のオートエンコーダをトレーニングして、潜在的な表現をクリーンな例と共有します。 
[ABSTRACT]ノイズの多い環境で録音された音声の混合物を自動エンコードします。結果のオートエンコーダをトレーニングして、潜在的な表現をクリーンな例と共有します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Time-Domain Multi-modal Bone/air Conducted Speech Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.SD/paper_2.html">
      Time-Domain Multi-modal Bone/air Conducted Speech Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ただし、ビデオクリップには通常、大量のデータが含まれ、計算リソースの点で高いコストがかかるため、SEシステムが複雑になる可能性があります。さらに、2つのアンサンブル学習ベースの戦略である早期融合（EF）と遅延融合を検討します。 （LF）、2種類の音声信号を統合し、ディープラーニングベースの完全たたみ込みネットワークを採用して強化を行います。マンダリンコーパスの実験結果は、この新たに提示されたマルチモーダル（骨と空気を統合した） -伝導信号）SE構造は、さまざまな音声評価メトリックにおいて、単一ソースのSE構造（骨伝導または空気伝導信号のみ）を大幅に上回ります。 
[ABSTRACT]ビデオクリップとビデオクリップには大量のデータが含まれる可能性があります。ただし、コンピューティングリソースの点でコストが高くなります。これは、骨伝導と空気伝導の信号を使用するseシステムが原因です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-22">
        <br>2019-11-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Automatic Speech Recognition Benchmark for Air-Traffic Communications -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.SD/paper_3.html">
      Automatic Speech Recognition Benchmark for Air-Traffic Communications
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーでは、170時間を超えるATCo音声データでトレーニングされた最新のASRモデルの探索的ベンチマークを紹介します。ここでは、ASRベースの開発を目的としたプロジェクトであるCleanSky EC-H2020 ATCO2を紹介します。空域からATCo音声データを収集、整理、および自動的に前処理するプラットフォーム。過去10年間の自動音声認識（ASR）の進歩により、航空管制（ATC）環境などの音声ベースの自動化の新しい領域が開かれました。 。 
[ABSTRACT]航空管制官はパイロットと航空管制官（atco）の間の唯一の接触方法です。前者は最も広く使用されており、後者は海洋メッセージに必須であり、一部の国内問題には限定された非音声法です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Adversarially Trained Multi-Singer Sequence-To-Sequence Singing
  Synthesizer -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.SD/paper_4.html">
      Adversarially Trained Multi-Singer Sequence-To-Sequence Singing
  Synthesizer
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      客観的評価と主観的評価の両方により、提案されたシンセサイザはベースラインより高い品質の歌声を生成できることが示されています（MOSでは4.12対3.53）。さらに、生成された音響機能に複数のランダムウィンドウ弁別器（MRWD）を適用して、ネットワークをGANにします..歌手間の楽譜の不均衡の問題を軽減するために、歌手の分類という敵対的なタスクを組み込んで、エンコーダの出力が歌手に依存しないようにします。 
[ABSTRACT]コンピューターシステムを使用して、マルチ歌手フレームワークを作成します。システムは、シーケンスからシーケンスへの歌唱モデルに基づいています。複数のランダムウィンドウアドミネーターを使用して、ネットワークに依存させます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-Encoder-Decoder Transformer for Code-Switching Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.SD/paper_5.html">
      Multi-Encoder-Decoder Transformer for Code-Switching Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      各エンコーダーとデコーダー内の対応するアテンションモジュールは、限定されたCSトレーニングデータの影響を軽減することを目的に、大きなモノリンガルコーパスを使用して事前トレーニングされています。このようなネットワークをマルチエンコーダーデコーダー（MED）アーキテクチャと呼びます。切り替え（CS）は、話し手が単一の文内または複数の文にわたって2つ以上の言語の単語を交互に使用するときに発生します。 
[ABSTRACT]自動言語認識は、同時に特定の言語を処理する必要があります。システムは、デコーダの事前特定のマルチヘッドアテンションメカニズムを使用します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Self-and-Mixed Attention Decoder with Deep Acoustic Structure for
  Transformer-based LVCSR -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.SD/paper_6.html">
      Self-and-Mixed Attention Decoder with Deep Acoustic Structure for
  Transformer-based LVCSR
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、複数レベルの音響抽象化のための多層の深層音響構造を学習する自己注意メカニズムを導入します。また、異なるレベルの音響抽象化とそれに対応する言語情報との間のアライメントを同時に学習する混合注意メカニズムを設計します。共有埋め込みスペース..自己注目のエンコーダーデコーダー構造を使用して、ソース入力の高レベル表現とターゲット出力の埋め込みの間の関係を学習します。 
[要旨]ソースとターゲットの埋め込みの間の関係を学習するために自己注意をもってエンコーダー/デコーダー構造を使用します。提案された構造は、開発セットで4.8％、デバイスで5.1％のCERSを達成します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Deep Dense and Convolutional Autoencoders for Unsupervised Anomaly
  Detection in Machine Condition Sounds -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.SD/paper_7.html">
      Deep Dense and Convolutional Autoencoders for Unsupervised Anomaly
  Detection in Machine Condition Sounds
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      チャレンジの6つのマシンタイプデータセットを使用して実験が行われました。全体的に、提案された密集および畳み込みAEによって競争力のある結果が達成され、ベースラインチャレンジメソッドよりも優れています。このテクニカルレポートでは、 DCASE 2020チャレンジ。 
[ABSTRACT]課題には、無秩序な音を検出するための教師なし学習が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label1"/>
    <div class="hidden_show">
<!-- paper0: Approximating Stacked and Bidirectional Recurrent Architectures with the
  Delayed Recurrent Neural Network -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_0.html">
      Approximating Stacked and Bidirectional Recurrent Architectures with the
  Delayed Recurrent Neural Network
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、入力と出力の間に遅延がある単一層のRNNである遅延RNNについて説明します。また、遅延により、双方向ネットワークと同様に、部分的な因果関係が生じることも示します。さらに、実際の自然言語処理タスクで双方向ネットワークと同様のパフォーマンスを示します。 
[ABSTRACT] delayed-rnnsはbidnsを模倣し、同様の因果関係のあるタスクを解決し、他のタスクでそれらをしのぐことができます。合成実験では、delayed-rnnがbidnsを複製できることを確認していますが、ランタイムは同等または高速です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-08-30">
        <br>2019-08-30
      </time>
    </span>
  </h3>
</article>
<!-- paper0: AMALGUM -- A Free, Balanced, Multilayer English Web Corpus -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_1.html">
      AMALGUM -- A Free, Balanced, Multilayer English Web Corpus
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      「NLPより優れた」ベンチマークを達成し、結果として得られるリソースの精度を評価するために、複数のアノテーションレイヤーの知識を活用します。合計4Mのトークンを自由に利用できる、ジャンルバランスのとれた英語のWebコーパスを提示し、多数の依存関係ツリー、非名前付きエンティティアノテーション、共参照解決、および修辞構造理論の談話ツリーを含む、高品質の自動アノテーションレイヤー。開いているオンラインデータソースをタップすることにより、コーパスは、手動で作成された小さなアノテーション付きデータに代わる、よりサイズの大きい代替手段を提供します。セット、アンバランスまたは不明な構成、ライセンスの問題、低品質の自然言語処理などの落とし穴を回避します。 
[要約]コーパスは、注釈付きデータのより実行可能な代替手段を提供することを目的としています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: STEAM: Self-Supervised Taxonomy Expansion with Mini-Paths -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_2.html">
      STEAM: Self-Supervised Taxonomy Expansion with Mini-Paths
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ノード接続タスクを解決するために、複数のビューからクエリアンカーペアの機能表現を学習し、予測のためにマルチビューの共同トレーニングを実行します。分類法は、日常的に多数のアプリケーションを支える重要な知識オントロジーですが、多くの分類法はカバレッジの低さという問題に悩まされています。STEAMという名前の自己監視型分類法拡張モデルを提案します。これは、拡張のために既存の分類法の自然な監視を活用します。 
[ABSTRACT]蒸気は蒸気を使用して自然な自己監視信号を生成します。アンカーミニ-パスと質問項の間のノード接続予測タスクを生成します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Dispersed EM-VAEs for Interpretable Text Generation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_3.html">
      Dispersed EM-VAEs for Interpretable Text Generation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、私たちの手法が適切に構造化された潜在空間を取得することを示しています。これにより、解釈可能なテキスト生成ベンチマークの強力なベースラインよりも優れた方法が実現します。 。我々は、よく分散された潜在空間を誘導するために追加の分散項を導入するDEM-VAEを提案します。 
[ABSTRACT] auto-以前のガウス分布のエンコーダー（vae）は、テキストメッセージで正常に適用されています。ただし、潜在的なtexterの意味を解釈することは困難です。この方法では、データの混合が発生する可能性があります
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-06-16">
        <br>2019-06-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Octet: Online Catalog Taxonomy Enrichment with Self-Supervision -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_4.html">
      Octet: Online Catalog Taxonomy Enrichment with Self-Supervision
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      タクソノミーエンリッチメントは、出現する用語に対処するための堅牢性だけでなく、既存のタクソノミー構造と新しい用語のアタッチメントの間の一貫性も必要とします。用語抽出のためにシーケンスラベリングモデルを遠隔トレーニングし、グラフニューラルネットワーク（GNN）を使用してタクソノミーをキャプチャすることを提案します。構造、および用語のアタッチメントに対するquery-item-taxonomyの相互作用..特に、Octetは、実稼働環境でのオンラインカタログの分類法を、オープンワールドの評価で2倍に拡張します。 
[要約]これは、オンラインカタログ分類の一般的な使用にもかかわらずです。実際には、それらのほとんどは人間によって管理されており、労働力がなく、スケーリングが困難です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Pre-trained Language Models as Symbolic Reasoners over Knowledge? -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_5.html">
      Pre-trained Language Models as Symbolic Reasoners over Knowledge?
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      暗記のために、スキーマの適合性（他の事実によって体系的にサポートされる事実）と頻度をその成功の主要な要因として特定します。以前の研究では、PLMが学習する事実の数を定量化しようとしましたが、合成データを使用して、トレーニングに存在するファクトとPLMによって学習されたファクトとの因果関係を確立します。事前トレーニング済みの言語モデル（PLM）は、トレーニングセットから実際の知識をどのように学習できますか？ 
[ABSTRACT] plmsはいくつかのシンボリックな推論規則を適用することを学びますが、特に、2ホップの推論に苦労しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Shapeshifter Networks: Cross-layer Parameter Sharing for Scalable and
  Effective Deep Learning -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_6.html">
      Shapeshifter Networks: Cross-layer Parameter Sharing for Scalable and
  Effective Deep Learning
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SSNは、ニュートラルネットワーク内のレイヤー間でパラメーターを共有する場所と方法を学習することでこれに対処し、フィッティングの低下を招く縮退したソリューションを回避します。ShapeshifterNetworks（SSNs）を紹介します。標準ニューラルネットワーク上のシナリオのセット。次に、各グループの重みをマップして、共有パラメータープールから候補の学習された組み合わせを含むレイヤーを構築します。 
[要旨]私たちのアプローチは、多くのニューラルネットワークが非常に過剰にパラメーター化されているという分類に基づいているため、認知リソースが大幅に浪費されるだけでなく、過剰適合しやすくなります。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Extraction and Evaluation of Formulaic Expressions Used in Scholarly
  Papers -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_7.html">
      Extraction and Evaluation of Formulaic Expressions Used in Scholarly
  Papers
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この論文では、スパンの変化や公式表現の形式にロバストな新しいアプローチを提案します。抽出された式を既存のレキシコンと比較する。このようなスパンとフォームの多様性により、式式の抽出と評価の両方で問題が発生します。 
[ABSTRACT]式の表現は論文で簡単に検索できます。コーパス全体から式の式を抽出する代わりに、さまざまな形式を一度に処理できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Automatic Validation of Textual Attribute Values in E-commerce Catalog
  by Learning with Limited Labeled Data -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_8.html">
      Automatic Validation of Textual Attribute Values in E-commerce Catalog
  by Learning with Limited Labeled Data
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      具体的には、次の貢献をします。前述の課題に対処するために、メタブリッジと呼ばれる新しいメタ学習潜在変数アプローチを提案します。これは、ラベル付きデータが限られているカテゴリのサブセットから転送可能な知識を学習し、絶対的な不確実性をキャプチャできます。 -ラベルのないデータを含むカテゴリを参照してください。（2）さまざまなカテゴリの不確実性を効果的にキャプチャするために、メタ学習と潜在変数を統合モデルに統合することを提案します。 
[ABSTRACT]これらのタイプの短いテキストのコンセプトは、いくつかのモデルに統合する必要があります。これらのモデルには、Tシャツ、Tシャツ、Tシャツなどが含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-15">
        <br>2020-06-15
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Compositional Generalization by Learning Analytical Expressions -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_9.html">
      Compositional Generalization by Learning Analytical Expressions
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      よく知られているベンチマークSCANでの実験は、私たちのモデルが100％の精度で以前の研究によって対処されたすべての課題を解決し、構成の一般化の優れた能力を獲得していることを示しています。しかし、既存のニューラルネットワークベースのモデルは、そのようなモデルでは非常に不十分であることが証明されています機能..シンボリック機能を備えた可変スロットによって構成性を捉えることができると主張する認識における作業に触発されて、メモリ拡張ニューラルモデルと分析式を接続して構成の一般化を実現するリフレッシュビューを提示します。 
[要旨]私たちのモデルは、作曲家とソルバーの2つの協調型ニューラルモジュールで構成されています。これらは認知的議論にうまく適合するように設計されています。しかし、既存のモデルは非常に不十分であることが証明されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: SEAL: Segment-wise Extractive-Abstractive Long-form Text Summarization -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_10.html">
      SEAL: Segment-wise Extractive-Abstractive Long-form Text Summarization
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      SEALモデルは、既存の長い形式の要約タスクで最新の結果を達成し、私たちが紹介する新しいデータセット/タスクであるSearch2Wikiの強力なベースラインモデルよりもはるかに長い入力テキストで優れたパフォーマンスを発揮します。ベースのモデルは、入力スニペットを動的に抽出/選択して、各出力セグメントにまばらに対応する新しいエンコーダー/デコーダーアテンションを備えています。SEALモデルではコンテンツの選択が明示的であるため、選択を検査して拡張を確認できます。解釈可能性。 
[ABSTRACT]以前のドキュメントと要約では、抽出レイヤーの監視が弱いため、テキストからの解釈性を高めるためにこのモデルを使用できます。このモデルを使用すると、選択範囲を検査して、拡張された使用を可能にします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: CERT: Contrastive Self-supervised Learning for Language Understanding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_11.html">
      CERT: Contrastive Self-supervised Learning for Language Understanding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      データとコードはhttps://github.com/UCSD-AI4H/CERTで入手できます。 CERTは簡単に使用でき、事前トレーニングの微調整NLPパイプラインに柔軟にプラグインできます。次に、2つの拡張された文が同じ文に由来するかどうかを予測することにより、事前トレーニングされた言語エンコーダー（BERTなど）を微調整します。 
[ABSTRACT] certは、back-translation.itを使用して元の文の拡張を作成します。これは、あらゆる事前トレーニングに簡単にプラグインできます-NLPパイプラインの微調整
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-16">
        <br>2020-05-16
      </time>
    </span>
  </h3>
</article>
<!-- paper0: On the Generation of Medical Dialogues for COVID-19 -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_12.html">
      On the Generation of Medical Dialogues for COVID-19
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      2つのCOVID-19対話データセットはサイズが小さいため、過剰適合のリスクが高いため、転移学習を利用してデータ不足を軽減します。結果は、生成された応答が会話の履歴に関連して医師のようであることを約束していることを示しています具体的には、トランスフォーマー、GPT、BERT-GPTの事前トレーニング済みモデルをダイアログデータセットやその他の大規模テキストに適用し、CovidDialogタスクでそれらを微調整します。 
[ABSTRACT]これは病院の閉鎖によるものです。多くのコンサルティングサービスがオンラインに移行しました。病院のレバレッジのため、医療対話システムの開発を目指しています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-05-11">
        <br>2020-05-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: A Monolingual Approach to Contextualized Word Embeddings for
  Mid-Resource Languages -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_13.html">
      A Monolingual Approach to Contextualized Word Embeddings for
  Mid-Resource Languages
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      特に、それらは多言語のWikipediaベースのコンテキスト埋め込み（多言語BERT）を改善します。これはほとんど常に以前の最先端技術であり、それにより、より大規模で多様なコーパスの利点が多言語埋め込みの言語間の利点を上回ることを示しています。アーキテクチャ.. Common-CrawlベースのOSCARデータのノイズにもかかわらず、OSCARでトレーニングされた埋め込みは、Wikipediaでトレーニングされた単一言語の埋め込みよりもはるかに優れていることを示しています。CommonCrawlから言語分類によって抽出された多言語OSCARコーパスを使用します。フィルタリングとクリーニング、5つの中間リソース言語の単一言語の文脈化された単語埋め込み（ELMo）をトレーニングします。 
[ABSTRACT]タグ付けと解析のタスクでこれらの言語のelmo埋め込み。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-11">
        <br>2020-06-11
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-branch Attentive Transformer -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_14.html">
      Multi-branch Attentive Transformer
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      マルチブランチアーキテクチャは、コンピュータービジョンタスクの成功の主要な要素の1つですが、自然言語処理、特にシーケンス学習タスクでは十分に調査されていません。コードは\ url {https：// githubで入手できます。 .com / HA-Transformer} ..トレーニングを正規化する2つのトレーニング手法を利用します。トレーニング中に個々のブランチをランダムにドロップするドロップブランチと、事前トレーニング済みのトランスフォーマモデルを使用して複数のブランチを初期化する近位初期化です。 
[ABSTRACT]変圧器の単純な変種はマルチブランチ注意力変圧器と呼ばれます。これらは変圧器のタイプの単純でありながら効果的な変種です。これはデュアルブランチなどの非親の変種のタイプです
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: FUSE: Multi-Faceted Set Expansion by Coherent Clustering of Skip-grams -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_15.html">
      FUSE: Multi-Faceted Set Expansion by Coherent Clustering of Skip-grams
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      （1）ファセット検出モジュール：スキップグラムを抽出してクラスタリングすることにより、各シードエンティティのすべてのセマンティックファセットを識別し、（2）ファセット融合モジュール：共有セマンティックを検出します。最適化の定式化によるシードセット全体のファセット、および（3）エンティティ拡張モジュール：事前トレーニング済みのBERTモデルでマスクされた言語モデルを利用して、各セマンティックファセットを拡張します。その結果、シードセット{&quot;Canon&quot;、 「Sony」、「Nikon」}、以前のモデルは、カメラブランドまたは日本企業の1つの混合エンティティセットを返します。広範な実験により、FUSEがシードセットの複数のセマンティックファセットを正確に識別し、各ファセットの高品質エンティティを生成できることが実証されています。 
[要約]ほとんどの既存のアプローチの一部は、入力フレームワークが明確であることを前提としています。ただし、シードエンティティの多面的なモデルは必要ありません。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-10-10">
        <br>2019-10-10
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Learning Dynamic Belief Graphs to Generalize on Text-Based Games -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_16.html">
      Learning Dynamic Belief Graphs to Generalize on Text-Based Games
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      この作業では、生のテキストからエンドツーエンドで学習したグラフ構造化表現を使用して、エージェントがテキストベースのゲームでどのように計画および一般化できるかを調査します。この作業は、学習したグラフベースの表現がエージェントがより良いポリシーに収束するのに役立つことを示していますテキストのみの対応物よりも効果的で、ゲーム構成全体で効果的な一般化を促進します。GATAは、強化と自主学習の組み合わせを使用してトレーニングされます。 
[ABSTRACT]小説のグラフ支援変圧器エージェント（gata）は、リサーチの一種です。gataは潜在的な信念パターンを分析して、基礎となるゲームダイナミクスをキャプチャすることで効果的なアクション選択を可能にします
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-02-21">
        <br>2020-02-21
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Zero-Shot Learning with Common Sense Knowledge Graphs -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_17.html">
      Zero-Shot Learning with Common Sense Knowledge Graphs
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      グラフニューラルネットワークに関するこれまでのほとんどの作業では、線形関数を使用して隣接ノードからの情報を集約していましたが、LSTMやトランスフォーマーなどの非線形集約器は、ゼロショットタスクの大幅な改善につながることがわかりました。さらに、オブジェクト分類タスクでは、 ZSL-KGは、手動で作成されたクラス表現を必要としない最良の方法と比較して、2.2の精度ポイントの改善を示しています。ゼロショット学習は、属性や事前トレーニングされた埋め込みなどのセマンティッククラス表現に依存して、ラベル付きの例なしでクラスを予測します。 
[ABSTRACT]クラス表現を作成するために常識知識グラフに依存しています。これらにはzsl-kgが含まれます。これは、クラス集約を生成するための非線形集約を備えたグラフニューラルネットワークに基づくフレームワークです。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Automatic Speech Recognition Benchmark for Air-Traffic Communications -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_18.html">
      Automatic Speech Recognition Benchmark for Air-Traffic Communications
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      データ量が多いため、話者のアクセントによるクロスアクセントの欠陥が最小限に抑えられ、システムがATC環境で実現可能になることを示しています。このペーパーでは、トレーニングされた最新のASRモデルの探索的ベンチマークを紹介します。 170時間以上のATCo音声データ..これにより、空域からATCo音声データを収集、整理、および自動的に前処理するASRベースのプラットフォームの開発を目的とするプロジェクトであるCleanSky EC-H2020 ATCO2を紹介します。 
[ABSTRACT]航空管制官はパイロットと航空管制官（atco）の間の唯一の接触方法です。前者は最も広く使用されており、後者は海洋メッセージに必須であり、一部の国内問題には限定された非音声法です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Explainable and Discourse Topic-aware Neural Language Understanding -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_19.html">
      Explainable and Discourse Topic-aware Neural Language Understanding
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      トピックと言語モデルの共同学習フレームワークで、文レベルのトピックの談話とともに潜在的なトピックと説明可能なトピックの両方を活用する新しいニューラル複合言語モデルを提示します。言語モデリング、単語の意味の曖昧性解消など、さまざまなタスクの実験、ドキュメントの分類、検索、テキスト生成は、言語理解を改善する提案されたモデルの能力を実証します。さらに、ドキュメント内のすべての文のトピックの談話をモデル化することにより、ドキュメントとトピックの関連付けとともに文とトピックの関連付けを保持します。 
[要約]提案されたモデルは言語理解の改善に役立つ可能性があります。新しいモデルを使用して新しいモデルを開発できます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Deep Encoder, Shallow Decoder: Reevaluating the Speed-Quality Tradeoff
  in Machine Translation -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/cs.CL/paper_20.html">
      Deep Encoder, Shallow Decoder: Reevaluating the Speed-Quality Tradeoff
  in Machine Translation
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      私たちの広範な実験は、十分に深いエンコーダーが与えられた場合、1層の自己回帰デコーダーが強力な非自己回帰モデルに匹敵するレイテンシで最先端の精度をもたらすことを示しています。一方、非自己回帰変換手法は生成を並列化します翻訳の品質を犠牲にして位置を超えて推論を高速化します。具体的には、深度が異なるエンコーダーとデコーダーを使用した自己回帰モデルを研究します。 
[ABSTRACT]自己回帰モデルは、さまざまなレベルのデコードレイテンシに基づいています。最適なレイヤー割り当てを選択していないため、自己回帰変換は過大評価されています
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label2"/>
    <div class="hidden_show">
<!-- paper0: Boosting Objective Scores of Speech Enhancement Model through MetricGAN
  Post-Processing -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/eess.AS/paper_0.html">
      Boosting Objective Scores of Speech Enhancement Model through MetricGAN
  Post-Processing
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      実験結果は、提案されたシステムが主観的評価と客観的評価の両方でチャレンジベースラインを大幅に上回っていることを示しています。具体的には、位置エンコーディングは必要ない可能性があるため、畳み込みレイヤーに置き換えられます。関心のある客観的スコアをさらに高めるための後処理モジュール。 
[要約]変更されたアーキテクチャは、強化された音声のpesqスコアを改善するのに役立ちます。研究では、音声変換タスクに変更された変換を適用します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Self-supervised Learning for Speech Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/eess.AS/paper_1.html">
      Self-supervised Learning for Speech Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このトレーニングスキーマを使用すると、ラベル付きのトレーニング例や人間の介入を必要とせずに自律的にトレーニング可能なネットワークを使用して、ノイズの多い音声をクリーンバージョンにマッピングできるようになります。シングルチャネル音声強調の教師あり学習には、注意深くラベル付きのトレーニング例が必要です。ノイズの多い混合がネットワークに入力され、ネットワークは理想的なターゲットに近い出力を生成するようにトレーニングされます。最初に、クリーンな音声の限られたトレーニングセットを使用し、マグニチュードスペクトログラムを自動エンコードして潜在表現を学習します。 
[ABSTRACT]ノイズの多い環境で録音された音声の混合物を自動エンコードします。結果のオートエンコーダをトレーニングして、潜在的な表現をクリーンな例と共有します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Time-Domain Multi-modal Bone/air Conducted Speech Enhancement -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/eess.AS/paper_2.html">
      Time-Domain Multi-modal Bone/air Conducted Speech Enhancement
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      さらに、この新しいSEマルチモーダル構造でEF以外のLF戦略を採用すると、より良い結果が得られます。さらに、早期融合（EF）と後期融合（LF）の2つのアンサンブル学習ベースの戦略を検討します。 、2種類の音声信号を統合し、ディープラーニングベースの完全畳み込みネットワークを採用して強化を行います。マンダリンコーパスでの実験結果は、この新たに提示されたマルチモーダル（骨伝導信号と空気伝導信号を統合した） ）SE構造は、さまざまな音声評価メトリックにおいて、単一ソースのSEの対応物（骨または空気伝導信号のみ）を大幅に上回っています。 
[ABSTRACT]ビデオクリップとビデオクリップには大量のデータが含まれる可能性があります。ただし、コンピューティングリソースの点でコストが高くなります。これは、骨伝導と空気伝導の信号を使用するseシステムが原因です。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2019-11-22">
        <br>2019-11-22
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Automatic Speech Recognition Benchmark for Air-Traffic Communications -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/eess.AS/paper_3.html">
      Automatic Speech Recognition Benchmark for Air-Traffic Communications
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      このペーパーは、170時間以上のATCo音声データでトレーニングされたいくつかの最新のASRモデルの探索的ベンチマークを伝えています。スピーカーのアクセントによるクロスアクセントの欠陥は、データをATC環境で実現可能にします。バイトペアエンコーディングでTDNNFシステムをトレーニングすると、1つのテストセットでWERがさらに35％向上します。 
[ABSTRACT]航空管制官はパイロットと航空管制官（atco）の間の唯一の接触方法です。前者は最も広く使用されており、後者は海洋メッセージに必須であり、一部の国内問題には限定された非音声法です
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Adversarially Trained Multi-Singer Sequence-To-Sequence Singing
  Synthesizer -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/eess.AS/paper_4.html">
      Adversarially Trained Multi-Singer Sequence-To-Sequence Singing
  Synthesizer
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      歌手間の楽譜の不均衡の問題を緩和するために、シンガー分類の敵対的なタスクを組み込んで、エンコーダーの出力を歌手に依存しないようにします。シーケンス間のシーケンスの歌唱モデルに基づいて、すべてのシンガーフレームワークを設計して、さまざまな歌手の既存の歌唱データ。特に、高音の母音の明瞭度が大幅に向上しています。 
[ABSTRACT]コンピューターシステムを使用して、マルチ歌手フレームワークを作成します。システムは、シーケンスからシーケンスへの歌唱モデルに基づいています。複数のランダムウィンドウアドミネーターを使用して、ネットワークに依存させます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Multi-Encoder-Decoder Transformer for Code-Switching Speech Recognition -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/eess.AS/paper_5.html">
      Multi-Encoder-Decoder Transformer for Code-Switching Speech Recognition
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      各エンコーダーとそれに対応するデコーダーのアテンションモジュールは、限定されたCSトレーニングデータの影響を軽減することを目的に、大きなモノリンガルコーパスを使用して事前トレーニングされています。このようなネットワークをマルチエンコーダーデコーダー（MED）アーキテクチャと呼びます。 SEAMEコーパスは、提案されたMEDアーキテクチャが、マトリックス言語としてマンダリンと英語をそれぞれ使用したCS評価セットで10.2％と10.8％の相対エラー率の低減を達成することを示しています。 
[ABSTRACT]自動言語認識は、同時に特定の言語を処理する必要があります。システムは、デコーダの事前特定のマルチヘッドアテンションメカニズムを使用します
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Self-and-Mixed Attention Decoder with Deep Acoustic Structure for
  Transformer-based LVCSR -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/eess.AS/paper_6.html">
      Self-and-Mixed Attention Decoder with Deep Acoustic Structure for
  Transformer-based LVCSR
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      また、音響埋め込みのさまざまなレベルとそれに対応する言語情報の間のアライメントを共有埋め込み空間で同時に学習する混合注意メカニズムも設計します。音響抽象化のレベル.. Aishell-1のASR実験は、提案された構造が、開発セットで4.8％、テストセットで5.1％のCERを達成することを示しました。これは、このタスクで得られた最良の結果であり、私たちの知る限りです。 。 
[要旨]ソースとターゲットの埋め込みの間の関係を学習するために自己注意をもってエンコーダー/デコーダー構造を使用します。提案された構造は、開発セットで4.8％、デバイスで5.1％のCERSを達成します。
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
<!-- paper0: Deep Dense and Convolutional Autoencoders for Unsupervised Anomaly
  Detection in Machine Condition Sounds -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/eess.AS/paper_7.html">
      Deep Dense and Convolutional Autoencoders for Unsupervised Anomaly
  Detection in Machine Condition Sounds
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      チャレンジの6つのマシンタイプデータセットを使用して実験が行われました。2つの方法には、メルスペクトグラム処理されたサウンド機能を使用する密集および畳み込みアーキテクチャに基づくディープオートエンコーダが含まれます。このテクニカルレポートでは、 DCASE 2020チャレンジ。 
[ABSTRACT]課題には、無秩序な音を検出するための教師なし学習が含まれます
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
</div>
  <div class="hidden_box">
    <input type="checkbox" id="label3"/>
    <div class="hidden_show">
<!-- paper0: BPIFB1 loss alters airway mucus properties and diminishes mucociliary clearance. -->
<article itemscope itemtype="https://schema.org/Blog">
  <h2 class="entry-title" itemprop="headline">
    <a href="../../list/2020-06-19/biorxiv.physiology/paper_0.html">
      BPIFB1 loss alters airway mucus properties and diminishes mucociliary clearance.
    </a>
  </h2>
  <h3 class="entry-abstract" itemprop="abstract">
      ここでは、BPIFB1がBpifb1ノックアウト（KO）マウスを使用してin vivoでの通常の粘液線毛クリアランスに必要であることを示します。遺伝子Bpifb1は、遺伝的アプローチを使用して気道内のMUC5Bのレベルのレギュレーターとして識別されていました。最後に、BPIFB1タンパク質が局在しました分泌顆粒にMUC5Bを含み、気道表面の粘液に存在した。 
[要約]遺伝子bpifb1は、遺伝的アプローチを使用して気道のmuc5bのレベルのレギュレーターとして同定されました。マウスは、ナトリウムまたは塩化物イオン輸送の欠陥または毛様体拍動周波数の変化がない場合に発生しました
    <span class="entry-meta">
      <time itemprop="datePublished" datetime="2020-06-18">
        <br>2020-06-18
      </time>
    </span>
  </h3>
</article>
</div>
</main>
<footer role="contentinfo">
  <div class="hr"></div>
  <address>
    <div class="avatar-bottom">
      <a href="https://twitter.com/akari39203162">
        <img src="../../images/twitter.png">
      </a>
    </div>
    <div class="avatar-bottom">
      <a href="https://www.miraimatrix.com/">
        <img src="../../images/mirai.png">
      </a>
    </div>

  <div class="copyright">Copyright &copy;
    <a href="../../teamAkariについて">Akari</a> All rights reserved.
  </div>
  </address>
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
       HTML: ["input/TeX","output/HTML-CSS"],
       TeX: {
              Macros: {
                       bm: ["\\boldsymbol{#1}", 1],
                       argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                       argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
              extensions: ["AMSmath.js","AMSsymbols.js"],
              equationNumbers: { autoNumber: "AMS" } },
       extensions: ["tex2jax.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                  processEscapes: true },
       "HTML-CSS": { availableFonts: ["TeX"],
                     linebreaks: { automatic: true } }
   });
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     }
   });
</script>

<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


</body>
</html>
